{
  "article_text": [
    "markov chain monte carlo ( mcmc ) has revolutionized statistical , particularly , bayesian computation . in the bayesian paradigm , however complicated the posterior distribution may be , it is always possible , in principle , to obtain as many ( dependent ) samples from the posterior as desired , to make inferences about posterior characteristics .",
    "but in spite of the obvious success story enjoyed by the theoretical side of mcmc , satisfactory practical implementation of mcmc often encounters severe challenges , particularly in very high - dimensional problems .",
    "these challenges may arise in the form of the requirement of enormous computational effort , often requiring inversions of very high - dimensional matrices , implying the requirement of enormous computation time , even for a single iteration .",
    "given that such high - dimensional problems typically converge extremely slowly to the target distribution triggered by complicated posterior dependence structures between the unknown parameters , astronomically large number of iterations ( of the order of millions ) are usually necessary .",
    "this , coupled with the computational expense of individual iterations , generally makes satisfactory implementation of mcmc , and hence , satisfactory bayesian inference , infeasible . that this is the situation despite steady technological advancement , is somewhat disconcerting .      in an attempt to overcome the problems mentioned above , in this paper we propose a novel methodology that can jointly update all the unknown parameters without compromising the acceptance rate , unlike in metropolis - hastings ( mh ) algorithm .",
    "in fact , we show that even though a very large number of parameters are to be updated , these can be updated by simple deterministic transformations of a single , one - dimensional random variable , the distribution of which can be chosen very flexibly .",
    "as can be already anticipated from this brief description , indeed , this yields an extremely fast simulation algorithm , thanks to the singleton random variable to be flexibly simulated , and the subsequent simple deterministic transformation , for example , additive transformation .",
    "it is also possible , maybe more efficient sometimes , to generate more than one , rather than a single , random variables , from a flexible multivariate ( generally independent ) , but low - dimensional distribution .",
    "we refer to our new methodology as transformation - based mcmc ( tmcmc ) .",
    "we show that by generating as many random variables as the number of parameters , instead of a single / few random variables , tmcmc can be reduced to a mh algorithm with a specialized proposal distribution .",
    "another popular mcmc methodology , the hybrid monte carlo ( hmc ) method , which relies upon a specialized deterministic transformation , will be shown to be a special case of tmcmc .",
    "we also provide a brief overview of the transformation - based generalized gibbs and metropolis methods of liu99 , liu00 and kou05 , and point out their differences with tmcmc , also arguing that tmcmc can be far more efficient at least in terms of computational gains . apart from illustrating tmcmc on the well - known challenger data set , and demonstrating its superiority over existing mh methods , we successfully apply tmcmc with the mere simulation of a single random variable , to update 160 unknown parameters in every iteration , in the challenging geospatial problem of diggle98 .",
    "the computational challenges involved with this and similar geospatial problems have motivated varieties of mcmc algorithms and deterministic approximations to the posterior in the literature ( see , _ e. g. _ rue09 , chris06 and the references therein ) . with our tmcmc algorithm",
    "we have been able to perform @xmath5 iterations ( in a few days ) and obtain reasonable convergence .",
    "we also show how tmcmc can be adopted to significantly improve computational efficiency in doubly intractable problems , where the posterior , apart from being intractable , also involves the normalizing constant of the likelihood  the crucial point being that the normalizing constant , which depends upon unknown parameters , is also intractable .",
    "the rest of this article is structured as follows . in section [ sec : gtm ] we introduce our new tmcmc method based on transformations .",
    "the univariate and the multivariate cases are considered separately in sections [ sec : gtm : univar ] and [ sec : gtm : multivar ] respectively . in section [ sec : single_e ]",
    "we study in details the role and efficiency of a singleton @xmath6 in updating high - dimensional markov chains using tmcmc . in section [ sec : hmc ] we provide a brief overview of hmc , and show that it is a special case of tmcmc . in section",
    "[ sec : liu ] we provide a brief overview of the generalized gibbs and metropolis methods of liu99 , liu00 and kou05 , discuss their differences with tmcmc , and argue that the latter offers more advantages than generalized gibbs / metropolis in terms of computational savings .",
    "illustration of tmcmc with singleton @xmath6 using the challenger data and comparison with a popular mcmc technique are provided in section [ sec : appl : logistic ] .",
    "application of tmcmc with single @xmath6 to the 160-dimensional geospatial problem of diggle98 is detailed in section [ sec : appl : dtm ] .",
    "section [ sec : doublyintract ] shows how tmcmc may be applied to the bridge - exchange algorithm of @xcite in doubly intractable problems to speed - up computation .",
    "finally , conclusions and overview of future work are provided in section [ sec : conclusions ] .",
    "in this section we propose and study the tmcmc algorithms .",
    "first , we construct it for state - spaces of dimension one .",
    "this case is not of much interest because the state space is similar to the real line and numerical integration is quite efficient in this scenario .",
    "nevertheless , construction of the tmcmc algorithm for one dimensional problems helps to generalize it to higher dimensions and points out its connections ( similarities in one - dimension and dissimilarities in higher dimensions ) with the mh algorithm . in section [ sec : gtm : multivar ] the tmcmc algorithm is generalized to higher dimensional state - spaces .      before providing the formal theory we first provide an informal discussion of our ideas with a simple example involving the additive transformation .      in order to obtain a valid algorithm based on transformations ,",
    "we need to design appropriate  move types \" so that detailed balance and irreducibility hold .",
    "given that we are in the current state @xmath7 , we can propose the  forward move \" @xmath8 ; here @xmath9 is a simulation from some arbitrary density of the form @xmath10 . to move back to @xmath7 from @xmath11 , we need to apply the  backward transformation \" @xmath12 .",
    "in general , given @xmath6 and the current state @xmath7 , we shall denote the forward transformation by @xmath13 , and the backward transformation by @xmath14 .",
    "the forward and the backward transformations need to be 1-to-1 . in other words , for any fixed @xmath6 , given @xmath11 the backward transformation must be such that @xmath7 can be retrieved uniquely . since this must hold good for every @xmath7 in the state space , the transfomation must be onto as well .",
    "similarly , for any fixed @xmath6 , there must exist @xmath7 such that the forward transformation leads to arbitrarily chosen @xmath11 in the state space uniquely , implying that this transformation is 1-to-1 , onto as well .",
    "if , given @xmath6 and @xmath11 , say , more than one solution exist , then return to the current value @xmath7 can not be ensured , and this makes detailed balance , a requirement for stationarity of the underlying markov chain , hard to satisfy .",
    "the detailed balance requirement also demands that , given @xmath7 , the regions covered by the forward and the backward transformations are disjoint .",
    "on the other hand , the backward move covers the region where all the values are less than @xmath7 .",
    "for example , in our additive transformation case , the forward transformation always takes @xmath7 to some unique @xmath11 , where @xmath15 . to return from @xmath11 to @xmath7 ,",
    "it is imperative that the backward transformation decreases the value of @xmath11 to give back @xmath7 . thus , if the forward transformation always increases the current value @xmath7 , the backward transformation must always decrease @xmath7 . in other words , the regions covered by the two transformations are disjoint .",
    "since @xmath7 is led to @xmath11 by the forward transformation and @xmath11 is taken back to @xmath7 by the backward transformation , we must have @xmath16 .",
    "also , the sequence of forward and backward transformations can be changed to achieve the same effect , that is , we must also have @xmath17 . in the above discussion we indicated the use the same @xmath6 for updating @xmath7 to @xmath11 and for moving back from @xmath11 to @xmath7 .",
    "an important advantage associated with this strategy is that whatever the choice of the density @xmath10 , it will cancel in the acceptance ratio of our tmcmc algorithm , resulting in a welcome simplication .",
    "thanks to bijection each of the forward and the backward transformations will be equipped with their respective inverses . in general , we denote by @xmath13 and @xmath14 the forward and the backward transformations , and by @xmath18 and @xmath19 their respective inverses .",
    "note that for fixed @xmath6 , @xmath20 , and @xmath21 , but the general inverses must be defined by eliminating @xmath6 .",
    "for instance , writing @xmath22 for the forward transformation yields @xmath23 . defining @xmath24 , it then follows that @xmath25@xmath26@xmath27@xmath28 , showing that @xmath29 is the inverse of @xmath0 in the above sense .",
    "similarly , @xmath30 can also be defined .",
    "suppose @xmath31 for some @xmath32 ( possibly a subset of @xmath33 ) is a totally differentiable transformation such that    1 .   for every fixed @xmath34 ,",
    "the transform @xmath35 is bijective and differentiable and that the inverse is also differentiable .",
    "2 .   for every fixed @xmath36",
    ", the transform @xmath37 is injective .    where @xmath38 and @xmath39 are @xmath40-negiligible sets .",
    "further suppose that the jacobian @xmath41 is non - zero almost everywhere .",
    "suppose there is a subset @xmath42 of @xmath3 such that @xmath43 the sets @xmath44 and @xmath45 are disjoint , where @xmath14 is the backward transformation defined by : @xmath46 * example : transformations on one dimensional state  space *    1 .",
    "( additive transformation ) suppose @xmath47 and @xmath48 .",
    "let @xmath49 .",
    "this transformation is basically the random walk if @xmath6 is a random quantity .",
    "notice that if we may choose @xmath50 , then @xmath51 , @xmath52 and we can characterize the transformation as a forward move or a backward move according as @xmath53 or @xmath54 .",
    "notice that here @xmath55 is the empty set and for all @xmath56 the map @xmath57 is a bijection .",
    "( log  additive transformation ) suppose @xmath58 and @xmath59 . for all @xmath56 , @xmath60 .",
    "( multiplicative transformation ) let @xmath62 , @xmath59 .",
    "then @xmath63 , for all @xmath64 , @xmath60 .",
    "@xmath65 .",
    "suppose further that @xmath66 is a density on @xmath42 and that @xmath67 .",
    "then the mcmc algorithm based on transformation is given in algorithm [ algo : gtm : univar ]    [ algo : gtm : univar ]    ' '' ''    height 1pt width    mcmc algorithm based on transformation ( univariate case )    ' '' ''    height 1pt width    * input : intial value @xmath68 , and number of iterations @xmath69 . * for @xmath70 1 .",
    "generate @xmath71 and @xmath72 u@xmath73 independently 2 .",
    "if @xmath74 , set @xmath75 3 .",
    "else if @xmath76 set @xmath77 4 .",
    "set @xmath78 * end for    ' '' ''    height 1pt width    notably , the acceptance probability is independent of the distribution @xmath79 , even if it is not symmetric .",
    "the algorithm can be shown to be a special case of mh algorithm with the mixture proposal density : @xmath80 where the _ inverses _ are defined by    1 .",
    "@xmath81 2 .",
    "@xmath82    hence detailed balance holds for the above algorithm .",
    "this ensures that our tmcmc methodology has @xmath40 as the stationary distribution .",
    "although in this univariate case tmcmc is an mh algorithm with the specialised mixture density ( [ eqn : mixturepro_equiv ] ) as the proposal mechanism , this proposal distribution becomes singular in general in higher dimensions .",
    "we remark that tmcmc maybe particularly useful for improving the mixing properties of the markov chain .",
    "for instance , if there are distinct modes in several disjoint regions of state space , then standard mh algorithms tend to get trapped in some modal regions , particularly if the proposal distribution has small variance .",
    "higher variance , on the other hand , may lead to poor acceptance rates in standard mh algorithms .",
    "gibbs sampling is perhaps more prone to mixing problems due to the lack of tuning facilities . for multimodal target distributions , mixture proposal densities",
    "are often recommended .",
    "for instance , guan07 theoretically prove that a mixture of two proposal densities results in a  rapidly mixing \" markov chain when the target distribution is multimodal .",
    "our proposal , which we have shown to be a mixture density in the one - dimensional case , seems to be appropriate from this perspective .",
    "indeed , in keeping with this discussion , dutta10 , apart from showing that the multiplicative transformation is geometrically ergodic even in situations where the standard proposals fail to be so , demonstrated that it is very effective for bimodal distributions .",
    "these arguments demonstrate that a real advantage of tmcmc ( also of other transformation - based methods as in liu01 ) comes forth when the transformations associated with our method identify a subspace moving within which allows to explore regions that are otherwise separated by valleys in the probability function .",
    "efficient choice of transformations of course depends upon the target distribution .    in higher dimensions",
    "our proposal does not admit a mixture form but since the principles are similar , it is not unreasonable to expect good convergence properties of tmcmc in the cases of high - dimensional and/or multimodal target densities . in the multidimensional case , which makes use of multivariate transformations ( which we introduce next ) , reasonable acceptance rates",
    "can also be ensured , in spite of the high dimensionality .",
    "this we show subsequently in section [ subsec : accept_rate ] , and illustrate with the challenger data problem and particularly with the geostatistical problem .",
    "moreover , the multivariate transformation method brings out other significant advantages of our method , for instance , computational speed and the ability to overcome mixing problems caused by highly correlated variables .",
    "suppose now that @xmath1 is a @xmath83-dimensional space of the form @xmath84 so that @xmath85 where each @xmath86 , for some set @xmath32 , are transformations as in section [ sec : gtm : univar ] .",
    "then for each nonempty subset @xmath87 of @xmath88 , let @xmath89 be the backward transformations in @xmath87coordinates of the map @xmath90 , i.e. @xmath91 where @xmath92 and define @xmath93 .",
    "we see that @xmath0 induces @xmath94 many types of ` moves ' on the state  space .",
    "suppose now that there is a subset @xmath42 of @xmath1 such that the sets @xmath95 and @xmath96 are disjoint for every subsets @xmath97 of @xmath88    * examples : transformations on higher dimensional state  space *    1 .   ( additive transformation ) suppose @xmath98 , @xmath99 where @xmath100 and @xmath101 are two ( positive ) scale parameters .",
    "then @xmath102 , @xmath103 and @xmath104 .",
    "we may choose @xmath105 .",
    "2 .   ( multiplicative transformation ) suppose @xmath106 , @xmath107 .",
    "then @xmath108 , @xmath109 and @xmath110 .",
    "we may let @xmath111 .",
    "3 .   ( additive - multiplicative transformation ) suppose @xmath106 , @xmath112 .",
    "then @xmath113 , @xmath114 and @xmath115 .",
    "we may let @xmath116 .",
    "the above examples can of course be generalized to arbitrary dimensions .",
    "also , it is clear that it is possible to construct valid transformations in high - dimensional spaces using combinations of valid transformations on one - dimensional spaces .",
    "now suppose that @xmath66 is a density on @xmath42 , and let @xmath117 be all the subsets of @xmath88 with @xmath118 and @xmath119 .",
    "let @xmath120 be positive numbers summing to @xmath121 .",
    "the mcmc algorithm based on transformations is given in algorithm [ algo : gtm : multivar ] .",
    "[ algo : gtm : multivar ]    ' '' ''    height 1pt width    mcmc algorithm based on transformation ( multivariate case )    ' '' ''    height 1pt width    * input : intial value @xmath122 , and number of iterations @xmath69 . * for @xmath70 1 .",
    "generate @xmath123 and an index @xmath124 independently .",
    "actually , simulation from the multinomial distribution is not necessary ; see section [ subsec : movetypeprob ] for an efficient and computationally inexpensive method of generating the index even when the number of move - types far exceeds @xmath94 .",
    "2 .   @xmath125 3 .",
    "set @xmath126 * end for    ' '' ''    height 1pt width    in light of the above algorithm , it can be seen that for each of the transformations in the above examples , a mixture proposal of the form ( [ eqn : mixturepro_equiv ] ) is induced .",
    "it will , however , be pointed out in section [ sec : single_e ] that a singleton @xmath6 suffices for updating multiple random variables simultaneously , which would imply singularity of the underlying proposal distribution .",
    "notice that for arbitrary dimensions the additive transformation reduces to the random walk mh ( rwmh ) .",
    "the detailed balance condition is proved as follows : suppose @xmath127 , then @xmath128 .",
    "hence , the kernel @xmath129 satisfies , @xmath130 and @xmath131 where @xmath132 satisfies @xmath133    algorithm [ algo : gtm : multivar ] indicates that updating highly correlated variables can be done naturally with tmcmc : for instance , in example 1 of this section one may select @xmath134 and @xmath135 with high probabilties if @xmath136 and @xmath137 are highly positively correlated and @xmath138 may be selected with high probability if @xmath136 and @xmath137 are highly negatively correlated .",
    "crucially , a singleton @xmath6 suffices to ensure the validity of our algorithm , even though many variables are to be updated .",
    "this indicates a very significant computational advantage over all other mcmc - based methods : for instance , complicated simulation of hundreds of thousands of variables may be needed for any mcmc - based method , while , for the same problem , a single simulation of our methodology will do .",
    "indeed , in section [ sec : appl : dtm ] we update 160 variables using a single @xmath6 in the geostatistical problem of diggle98 .",
    "this singleton @xmath6 also ensures that a mixture mh proposal density corresponding to our tmcmc method does not exist .",
    "the last fact shows that tmcmc can not be a special case of the mh algorithm . on the other hand , assuming that instead of singleton @xmath6 , there is an @xmath139 associated with each of the variables @xmath140 ; @xmath141 , then again tmcmc boils down to the mh algorithm , and , as in the univariate case , here also our transformations would induce a mixture proposal distribution for the algorithm , consisting of @xmath94 mixture components each corresponding to a multivariate transformation .    using singleton @xmath6 , for transformations",
    "other than the additive transformation , it is necessary to incorporate extra move types having positive probability which change one variable using forward or backward transformation , keeping the other variables fixed at their current values .",
    "consider for instance , example 3 of section [ sec : gtm : multivar ] .",
    "the example indicates that , with a singleton @xmath6 , it is only possible to move from @xmath142 to either of the following states : @xmath143 , @xmath144 , @xmath145 and @xmath146 with positive probabilities .",
    "in addition , we could specify that the states @xmath147 , @xmath148 , @xmath149 and @xmath150 also have positive probabilities to be visited from @xmath142 in one step .",
    "we will need to specify the visiting probabilities @xmath151 such that @xmath152 .",
    "a general method of specifying the move - type probabilities , which also preserves computational efficiency , is dicussed in section [ subsec : movetypeprob ] .",
    "inclusion of the extra move types ensures irreducibility and aperiodicity ( the definitions are provided in the appendix ) of the markov chain .",
    "it is easy to see that even for higher dimensions irreducibility and aperiodicity can be enforced by bringing in move types of similar forms that updates one variable keeping the remaining variables fixed .",
    "one only needs to bear in mind that the move types must be included in pairs , that is , a move type that updates only the @xmath153-th co - ordinate @xmath140 using forward transformation and the conjugate move type that updates only @xmath140 using the backward transformation both must have positive probability of selection .",
    "this strategy works for all transformations , including the examples in section [ sec : gtm : multivar ] where we now assume equality of all the components of @xmath154 .",
    "only additional move types are involved for transformations in general . however , we prove in the appendix that the additive transformation does not require the additional move types . also taking account of the inherent simplicity of this transformation ,",
    "this is our automatic choice for the applications reported in this paper .",
    "consider a @xmath83 @xmath155-dimensional target distribution , with associated random variables @xmath156 .",
    "then , in order to specify the move - type probabilities , we can implement the following simple rule .",
    "given @xmath157 , let the forward and the backward transformations be applied to @xmath140 with probabilities @xmath158 and @xmath159 , respectively . with probability @xmath160",
    ", @xmath140 remains unchanged . for computational convenience ,",
    "one may define a random variable @xmath161 that takes values @xmath162 , with probabilities @xmath163 , respectively .",
    "the values @xmath162 corresponds to backward transformation , no change , and forward transformation , respectively .",
    "this rule is to be applied to each of @xmath141 coordinates .",
    "this rule then includes all possible move types , including the one where none of the @xmath140 is updated , that is , @xmath157 is taken to @xmath157 . since the move - type @xmath164 is redundant , this is to be rejected whenever it appears . in other words , we would keep simulating the discrete random vector @xmath165 until at least one @xmath166 , and would then select the corresponding move type . for any dimension ,",
    "this is a particularly simple and computationally efficient exercise , since the rejection region is a singleton , and has very small probability ( particularly in high dimensions ) if either of @xmath158 and @xmath159 is high for at least one @xmath153 .",
    "the above method implies that the probability of a move - type is of the form @xmath167 , where @xmath168 and @xmath169 is the normalizing constant , which arose due to rejection of the move type @xmath164 .",
    "this normalizing constant cancels in the acceptance ratio , and so it is not required to calculate it explicitly , another instance of preservation of computational efficiency .    for the additive transformation ,",
    "the issues are further simplified .",
    "the random variable @xmath161 here takes the value @xmath170 and 1 with probabilities @xmath158 and @xmath171 , respectively .",
    "so , only @xmath158 needs to be specified .",
    "since @xmath172 has probability zero in this setup , there is no need to perform rejection sampling to reject any move - type .",
    "interestingly , the ideas developed in this section provides us with a handle to control the move - type probabilities , by simply controlling @xmath158 and @xmath159 for each @xmath153 .",
    "for instance , if some pilot mcmc analysis tells us that @xmath140 and @xmath173 are highly positively correlated , then we could set @xmath158 and @xmath174 ( or @xmath159 and @xmath175 ) to be high .",
    "on the other hand , if @xmath140 and @xmath173 are highly negatively correlated , then we can set @xmath158 to be high ( low ) and @xmath175 to be low ( high ) .      consider a continuous target density of @xmath176 random variables , denoted @xmath177 , where @xmath156 . assume further that @xmath178 is uniformly continuous function of @xmath157 .",
    "the joint random walk mh algorithm generates @xmath179 independently from @xmath180 , and then uses the transformation @xmath181 ; we assume that @xmath182 for each @xmath153 .",
    "thus , the random walk mh updates @xmath183 simultaneously in a single block . on the other hand",
    ", the additive - transformation based tmcmc also updates @xmath183 simulatenously in a single block , but instead of using @xmath83 different @xmath139 , it uses a single @xmath6 for updating all the @xmath140 variables . in other words , for tmcmc based on additive transformation @xmath184 is of the form @xmath185 , where @xmath186 .",
    "finding the exact or asymptotic acceptance rate for a random walk mh algorithm for a general target density is still an unsolved problem in mcmc literature . in this article",
    "we try to give reasonable upper bounds to the acceptance rate of the additive tmcmc with singleton @xmath6 and the random walk mh algorithm and show how the acceptance rate for the latter converges to zero faster than that for the former .",
    "now , if @xmath187 is the acceptance probability of @xmath188 given the current value @xmath157 , then , for every @xmath189 , due to the assumptions regarding the target density @xmath178 , @xmath190 & \\leq pr\\left(\\parallel{\\mathbf x}'-{\\mathbf",
    "x}\\parallel > c_2(r),\\pi({\\mathbf x}')<\\pi({\\mathbf x})\\right ) \\label{eq : accept_prob}\\end{aligned}\\ ] ]    now , for any positive constants @xmath169 and @xmath191 , @xmath192 & \\leq pr\\left(\\sum_{i=1}^k{\\ensuremath{\\epsilon}}^2_i <",
    "c^2/k^2\\right ) \\notag \\\\[1ex ] & \\leq \\phi\\left(\\frac{\\left(c^2/k^2\\right)-k}{\\sqrt{2k}}\\right)+{\\ensuremath{\\epsilon}}_0 , \\ \\ \\mbox{for } \\ \\ k\\geq",
    "k_0({\\ensuremath{\\epsilon}}_0 ) , \\label{eq : rwmh}\\end{aligned}\\ ] ] @xmath193 being the distribution function of @xmath180 distribution . hence , for any @xmath194 , @xmath195 & \\geq 1- \\phi\\left(\\frac{\\left(c^2/k^2\\right)-k}{\\sqrt{2k}}\\right)-{\\ensuremath{\\epsilon}}_0 ,   \\ \\ \\mbox{for } \\ \\ k\\geq",
    "k_0({\\ensuremath{\\epsilon}}_0 ) .",
    "\\label{eq : ineq2}\\end{aligned}\\ ] ]    on the other hand , for additive tmcmc with singleton @xmath196 , @xmath197 & = 2\\phi\\left(\\frac{c}{\\sqrt{k}k}\\right)-1.\\label{eq : additive_tmcmc}\\end{aligned}\\ ] ] this implies that even in tmcmc with singleton @xmath6 , for any @xmath189 it holds that @xmath198 .",
    "\\label{eq : ineq3}\\end{aligned}\\ ] ] inequalities ( [ eq : ineq2 ] ) and ( [ eq : ineq3 ] ) show that under both rwmh and tmcmc , the acceptance probabilities are small with probability tending to 1 as the dimension @xmath199 .",
    "however , under rwmh this goes to zero at a much faster rate than that under tmcmc .",
    "this is clear because the ratio of the argument of the increasing distribution function @xmath193 in ( [ eq : rwmh ] ) to that in ( [ eq : additive_tmcmc ] ) is @xmath200 , which goes to @xmath201 as @xmath199 .",
    "now , letting @xmath202 , the acceptance rate is given by @xmath203 & = \\int pr\\left(u < r({\\mathbf x}'|{\\mathbf x})\\right)q({\\mathbf x}'|{\\mathbf",
    "x})\\pi({\\mathbf x})d{\\mathbf x}d{\\mathbf x}'\\notag \\\\[1ex ] & = \\int \\left[\\int pr\\left(u <",
    "r({\\mathbf x}'|{\\mathbf x})\\right)q({\\mathbf x}'|{\\mathbf x})d{\\mathbf x}'\\right]\\pi({\\mathbf x})d{\\mathbf x}\\notag \\\\[1ex ] & = \\int \\left[\\int_0 ^ 1 pr\\left(r({\\mathbf x}'|{\\mathbf x})>u\\right)du\\right]\\pi({\\mathbf x})d{\\mathbf x}\\label{eq : ineq4}\\end{aligned}\\ ] ] since @xmath204 is bounded above by 1 , which is integrable in this set up , the dominated convergence theorem holds , showing that @xmath205 as @xmath199 .",
    "in fact , for large @xmath83 , ( [ eq : ineq2 ] ) implies that the following inequality holds in the case of rwmh : @xmath206 \\pi({\\mathbf x})d{\\mathbf x}\\leq   \\sup_{u\\in ( 0,1)}\\phi\\left(\\frac{\\left(c^2_2(u)/k^2\\right)-k}{\\sqrt{2k}}\\right)+{\\ensuremath{\\epsilon}}_0 , \\label{eq : ar_rwmh}\\end{aligned}\\ ] ] and , ( [ eq : ineq3 ] ) implies that for any @xmath83 , the following inequality holds for tmcmc : @xmath207 \\pi({\\mathbf x})d{\\mathbf x}\\leq   \\sup_{u\\in ( 0,1)}\\left\\{2\\phi\\left(\\frac{c_2(u)}{\\sqrt{k}k}\\right)-1\\right\\}. \\label{eq : ar_tmcmc}\\end{aligned}\\ ] ] comparison of the upper bounds in ( [ eq : ar_rwmh ] ) and ( [ eq : ar_tmcmc ] ) shows that for large @xmath83 , additive tmcmc will have a much higher upper acceptance rate as compared to that of joint rwmh .",
    "standard methods like sequential rwmh may tend to be computationally infeasible in high dimensions while inducing mixing problems due to posterior dependence between the parameters , whereas tmcmc remains free from the aforementioned problems thanks to singleton @xmath6 and joint updating of all the parameters .",
    "specialised proposals for joint updating may be constructed for specific problems only , for instance , block updating proposals for gaussian markov random fields are available ( rue01 ) .",
    "but generally , efficient block updating proposals are not available . moreover , even in the specific problems , simulation from the specialized block proposals and calculating the resulting acceptance ratio are generally computationally very expensive .",
    "in contrast , tmcmc with singleton @xmath6 seems to be much more general and efficient .",
    "moreover , we demonstrate in section [ sec : appl : logistic ] in connection with the challenger data problem that tmcmc can outperform well - established block proposal mechanisms , usually based on the asymptotic covariance matrix of the maximum likelihood estimator ( mle ) , in terms of acceptance rate . but before illustrating tmcmc with real examples , we first investigate the relationship of hmc , another specialized mcmc method based on deterministic updating proposal , with tmcmc .",
    "motivated by hamiltonian dynamics , duane87 introduced hmc , an mcmc algorithm with deterministic proposals based on approximations of the hamiltonian equations .",
    "we will show that this algorithm is a special case of tmcmc , but first we provide a brief overview of hmc .",
    "more details can be found in liu01 , cheung09 and the references therein .",
    "if @xmath177 is the target distribution , a fictitious dynamical system may be considered , where @xmath208 can be thought of as the @xmath209-dimensional position vector of a body of particles at time @xmath210 .",
    "if @xmath211 is the speed vector of the particles , @xmath212 is its acceleration vector , and @xmath213 is the force exerted on the particle ; then , by newton s law of motion @xmath214 , where @xmath215 is a mass vector .",
    "the momentum vector , @xmath216 , often used in classical mechanics , can be thought of as a vector of auxiliary variables brought in to facilitate simulation from @xmath177 .",
    "the kinetic energy of the system is defined as @xmath217 , @xmath218 being the mass matrix .",
    "usually , @xmath218 is taken as @xmath219 .",
    "the target density @xmath177 is linked to the dynamical system via the potential energy field of the system , defined as @xmath220 . the total energy ( hamiltonian function ) ,",
    "is given by @xmath221 .",
    "a joint distribution over the phase - space @xmath222 is then considered , given by @xmath223 since the marginal density of @xmath224 is @xmath177 , it now remains to provide a joint proposal mechanism for simulating @xmath222 jointly ; ignoring @xmath225 yields @xmath157 marginally from @xmath178 .",
    "for the joint proposal mechanism , hmc makes use of newton s law of motion , derived from the law of conservation of energy , and often written in the form of hamiltonian equations , given by @xmath226 where @xmath227 .",
    "the hamiltonian equations can be approximated by the commonly used leap - frog algorithm ( hockney70 ) , given by , @xmath228 { \\mathbf p}(t+{\\ensuremath{\\delta}}t)&={\\mathbf p}(t)-\\frac{{\\ensuremath{\\delta}}t}{2}\\left\\{\\nabla u\\left({\\mathbf x}(t)\\right)+\\nabla u\\left({\\mathbf x}(t+{\\ensuremath{\\delta}}t)\\right)\\right\\}\\label{eq : frog2}\\end{aligned}\\ ] ] given choices of @xmath218 , @xmath229 , and @xmath230 , the hmc is then given by the following algorthm :    [ algo : hmc ]    ' '' ''    height 1pt width    hmc    ' '' ''    height 1pt width    * initialise @xmath157 and draw @xmath231 .",
    "* assuming the current state to be @xmath222 , do the following : 1 .",
    "generate @xmath232 ; 2 .   letting @xmath233 ,",
    "run the leap - frog algorithm for @xmath230 time steps , to yield @xmath234 ; 3 .",
    "accept @xmath235 with probability @xmath236 and accept @xmath237 with the remaining probability .    ' '' ''    height 1pt width    in the above algorithm , it is not required to store simulations of @xmath225 .",
    "next we show that hmc is a special case of tmcmc .      to see that hmc is a special case of tmcmc , note that the leap - frog step of the hmc algorthm ( algorithm [ algo : hmc ] ) is actually a deterministic transformation of the form @xmath238 ( see liu01 ) .",
    "this transformation satisfies the following : if @xmath239 , then @xmath240 .",
    "the jacobian of this transformation is 1 because of the volume preservation property , which says that if @xmath241 is a subset of the phase space , and if @xmath242 , then the volume @xmath243 . as a result ,",
    "the jacobian does not feature in the hmc acceptance probability ( [ eq : hmc_accept ] ) .    for any dimension , there is only one move type defined for hmc , which is the forward transformation @xmath244 .",
    "hence , this move type has probability one of selection , and all other move types which we defined in general terms in connection with tmcmc , have zero probability of selection . as a result ,",
    "the corresponding tmcmc acceptance ratio needs slight modification ",
    "it must be made free of the move - type probabilities , which is exactly the case in ( [ eq : hmc_accept ] ) .",
    "the momentum vector @xmath225 can be likened to @xmath184 of tmcmc , but note that @xmath225 must always be of the same dimensionality as @xmath157 ; this is of course , permitted by tmcmc as a special case .      for @xmath245 , the proposal corresponding to hmc",
    "is given by ( see cheung09 ) @xmath246 where ( [ eq : hmc_proposal ] ) is a normal distribution with mean and variance given , respectively , by the following : @xmath247 { \\mbox{\\boldmath $ \\sigma$}}(t)&={\\ensuremath{\\delta}}t{\\mathbf m}^{-1}\\label{eq : hmc_var}\\end{aligned}\\ ] ] assuming diagonal @xmath218 with @xmath248 being the @xmath153-th diagonal element , the proposal can be re - written in the following more convenient manner : for @xmath141 , @xmath249 where @xmath250 denotes the @xmath153-th component of @xmath251 , and @xmath252 .",
    "assuming , as is usual , that @xmath253 for each @xmath153 , it follows that @xmath254 where @xmath255 is a non - central @xmath256 distribution with @xmath83 degrees of freedom and non - centrality parameter @xmath257 .",
    "since , as either @xmath199 or @xmath258 , @xmath259 it follows that for any positive constants @xmath169 and @xmath191 , @xmath192 & = pr\\left(\\sum_{i=1}^k{\\ensuremath{\\epsilon}}'^2_i<\\frac{c^2}{{\\ensuremath{\\delta}}t^2}\\right ) \\notag \\\\[1ex ] & \\leq \\phi\\left(\\frac{c^2/{\\ensuremath{\\delta}}t^2-(k+\\lambda)}{\\sqrt{2(k+2\\lambda)}}\\right)+{\\ensuremath{\\epsilon}}_0 , \\ \\ \\mbox{for } \\ \\",
    "k\\geq k_0({\\ensuremath{\\epsilon}}_0 ) .",
    "\\label{eq : clt2}\\end{aligned}\\ ] ] comparing with ( [ eq : rwmh ] ) it follows that the ratio of @xmath260 in ( [ eq : clt2 ] ) to @xmath261 is @xmath262 if @xmath263 .",
    "thus , compared to ( [ eq : rwmh ] ) , ( [ eq : clt2 ] ) goes to zero at a much faster rate .",
    "hence , as in ( [ eq : ineq2 ] ) , using the same assumptions as in section [ subsec : accept_rate ] , @xmath264    it follows that for @xmath265 , @xmath266 \\pi({\\mathbf x})d{\\mathbf x}\\leq   \\sup_{u\\in ( 0,1)}\\phi\\left(\\frac{\\left(c^2_2(u)/{\\ensuremath{\\delta}}t^2\\right)-k-\\lambda } { \\sqrt{2(k+2\\lambda)}}\\right)+{\\ensuremath{\\epsilon}}_0 , \\label{eq : ar_hmc}\\end{aligned}\\ ] ] by the above arguments , if @xmath267 as @xmath199 , then @xmath268 tends to 0 at a rate much faster than @xmath269 , while @xmath270 goes to zero at the slowest rate .",
    "it is important to make it clear at the outset of this discussion that the goals of tmcmc and generalized gibbs / metropolis methods are different , even though both use moves based on transformations .",
    "while the strength of the latter lies in improving mixing of the standard gibbs / mh algorithms by adding transformation - based steps to the underlying collection of usual gibbs / mh steps , tmcmc is an altogether general method of simulating from the target distribution which does not require any underlying step of gibbs or mh .",
    "the generalized gibbs / mh methods work in the following manner .",
    "suppose that an underlying gibbs or mh algorithm for exploring a target distribution has poor mixing properties .",
    "then in order to improve mixing , one may consider some suitable transformation of the random variables being updated such that mixing is improved under the transformation .",
    "such a transformation needs to chosen carefully since it is important to ensure that invariance of the markov chain is preserved under the transformation .",
    "it is convenient to begin with an overview of the generalized gibbs method with a sequential updating scheme and then proceed to the discussion on the issues and the importance of the block updating idea in the context of improving mixing of standard gibbs / mh methods .",
    "liu00 ( see also liu99 ) propose simulation of a transformation from some appropriate probability distribution , and then applying the transformation to the co - ordinate to be updated .",
    "for example , in a @xmath209-dimensional target distribution , for updating @xmath271 to @xmath272 , using an additive transformation , one can select @xmath6 from some appropriate distribution and set @xmath273 .",
    "similarly , if a scale transformation is desired , then one can set @xmath274 , where @xmath275 must be sampled from some suitable distribution .",
    "the suitable distributions of @xmath6 and @xmath275 are chosen such that the target distribution is invariant with respect to the move @xmath188 , the forms of which are provided in liu00 . for instance , if @xmath178 denotes the target distribution , then for the additive transformation , @xmath6 may be sampled from @xmath276 , and for the multiplicative transformation , one may sample @xmath275 from @xmath277 . since direct sampling from such distributions may be impossible , liu00 suggest a metropolis - type move with respect to a transformation - invariant transition kernel .",
    "thus , in the generalized gibbs method , sequentially all the variables must be updated , unlike tmcmc , where all the variables can be updated simultaneously in a single block . here",
    "we note that for irreducibility issues the generalized gibbs approach is not suitable for updating the variables blockwise using some transformation that acts on all the variables in a given block . to consider a simple example , with say , @xmath278 and a single block consisting of both the variables , if one considers the additive transformation , then starting with @xmath279 , where @xmath280",
    ", one can not ever reach @xmath281 , where @xmath282 .",
    "this is because @xmath283 and @xmath284 , for some @xmath285 , and @xmath286 implies @xmath287 and @xmath288 , which is a contradiction .",
    "the scale transformation implies the move @xmath289 .",
    "if one initialises the markov chain with all components positive , for instance , then in every iteration , all the variables will have the same sign .",
    "the spaces where some variables are positive and some negative will never be visited , even if those spaces have positive ( in fact , high ) probabilities under the target distribution .",
    "this shows that the markov chain is not irreducible .",
    "in fact , with the aforementoned approach , no transformation , whatever distribution they are generated from , can guarantee irreducibility in general if blockwise updates using the transformation strategy of generalized gibbs is used .",
    "although blockwise transformations are proposed in liu00 ( see also kou05 who propose a mh - based rule for blockwise transformation ) , they are meant for a different purpose than that discussed above .",
    "the strength of such blockwise transformations lies in improving the mixing behaviour of standard gibbs or mh algorithms .",
    "suppose that an underlying gibbs or mh algorithm for exploring a target distribution has poor mixing properties .",
    "then in order to improve mixing , one may consider some suitable transformation of the set of random variables being updated such that mixing is improved under the transformation .",
    "this additional step involving transformation of the block of random variables can be obtained by selecting a transformation from the appropriate probability distribution provided in liu00",
    ". this  appropriate \" probability distribution guarantees that stationarity of the transformed block of random variables is preserved .",
    "examples reported in liu00 , muller05 , kou05 , etc .",
    "demonstrate that this transformation also improves the mixing behaviour of the chain , as desired .",
    "thus , to improve mixing using the methods of liu00 or kou05 one needs to run the usual gibbs / mh steps , with an additional step involving transformations as discussed above .",
    "this additional step induces more computational burden compared to the standard gibbs / mh steps , but improved mixing may compensate for the extra computational labour . in very high dimensions",
    ", of course , this need not be a convenient approach since computational complexity usually makes standard gibbs / mh approaches infeasible .",
    "since the additional transformation - based step works on the samples generated by standard gibbs / mh , impracticality of the latter implies that the extra transformation - based step of liu00 for improving mixing is of little value in such cases .",
    "it is important to point out that the generalized gibbs / mh methods can be usefully employed by even tmcmc to further improve its mixing properties . in other words , a step of generalized",
    "gibbs / mh can be added to the computational fast tmcmc .",
    "this additional step can significantly improve the mixing properties of tmcmc . that tmcmc is much faster computationally than standard gibbs / mh methods",
    "imply that even in very high - dimensional situations the generalized gibbs / mh step can ve very much successful while working in conjunction with tmcmc .    in the next section",
    "we illustrate implementation of tmcmc with singleton @xmath6 using the much - studied challenger data .",
    "in 1986 , the space shuttle challenger exploded during take off , killing the seven astronauts aboard .",
    "the explosion was the result of an o - ring failure , a splitting of a ring of rubber that seals the parts of the ship together .",
    "the accident was believed to be caused by the unusually cold weather ( @xmath290f or @xmath291c ) at the time of launch , as there is reason to believe that the o - ring failure probabilities increase as temperature decreases .",
    "the data are provided in table [ tab : challenger ] for ready reference .",
    "we shall analyze the data with the help of well  known logit model .",
    "our main aim is not analyzing and drawing inference since it is done already in dalal89 , martz92 and robert04 .",
    "we shall rather compare the different mcmc methodologies used in bayesian inference for logit  model .",
    ".challenger data .",
    "temperature at flight time ( degrees f ) and failure of o - rings ( 1 stands for failure , 0 for success ) . [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     let @xmath292 where @xmath293 , @xmath294 s being the temperature at flight time ( degrees f ) , @xmath295 . and @xmath296 .",
    "also suppose @xmath297 is the indicator variable denoting failure of 0-ring .",
    "we suppose @xmath297 s independently follow bernoulli(@xmath298 ) .    in the logit model",
    "we suppose that the log - odd ratio is a linear function of temperature at flight time , i.e. , @xmath299 which gives @xmath300 we construct an appropriate additive transformation @xmath301 as follows .",
    "first , we consider the form @xmath302 , where @xmath303 is a diagonal matrix with tuning parameters on its diagonal , and @xmath304 is a @xmath305 vector , obtained using cholesky decomposition , is such that @xmath306 , the large sample covariance matrix of the maximum likelihood estimator of @xmath307 .",
    "so the entries of @xmath304 are approximate variances of the m.l.e of @xmath308 . for our purpose , we set @xmath303 equal to the identity matrix .",
    "thus , we finally obtain the transformation @xmath309 and use algorithm [ algo : gtm : multivar ] with @xmath50 and @xmath310 i.e. the @xmath180 distribution truncated to the left at zero . from the covariance matrix @xmath311 we observe that the correlation of @xmath312 and @xmath313 is approximately @xmath314 and hence from our discussion towards the end of section [ sec : gtm : multivar ] setting high probabilities to the moves @xmath315 and @xmath316 should facilitate good mixing . for our purpose we set @xmath317 and @xmath318 .",
    "also for comparison we use the rwmh algorithm ( both joint and sequential updation ) and also the mh algorithm with proposal @xmath319 where @xmath320 ( we take @xmath321 for our purpose ) with @xmath311 being the large sample covariance matrix of the mle @xmath322 of @xmath323 .",
    "table [ tab : challenger : analysis ] gives the posterior summaries and figure [ fig : challenger : trace ] gives the traceplots of @xmath324 and @xmath325 for tmcmc sampler and the mh sampler .",
    "it is seen that the mixing is excellent even though a single @xmath6 has been used .",
    "z|z|z|z|z|z|z|z|z|z & method & acceptance rate ( % ) & mean & std & 2.5% & 25% & 50% & 75% & 97.5% + & rwmh & 42.17 & 19.119 & 8.078 & 4.909 & 13.481 & 18.475 & 24.227 & 38.176 + @xmath324 & mh & 42.60 & 18.930 & 8.513 & 5.011 & 12.823 & 17.981 & 23.957 & 38.206 + & tmcmc & 73.23 & 18.973 & 7.944 & 4.970 & 12.881 & 16.210 & 21.685 & 37.877 + & rwmh & 48.14 & -23.724 & 9.613 & -46.272 & -29.786 & -22.984 & -17.019 & -6.7792 + @xmath325 & mh & 42.60 * * & -23.491 & 10.128 & -46.461 & -29.464 & -22.353 & -16.261 & -6.956 + & tmcmc & 73.23 * * & -23.165 & 9.762 & -46.404 & -28.891 & -22.282 & -16.446 & -7.026 +    rwmh = random walk metropolis - hastings , mh = metropolis - hastings with bivariate normal proposal , tmcmc = mcmc based on transformation + * : posterior sample quantiles . + * * : same as acceptance ratio for @xmath326 since updated jointly . [",
    "tab : challenger : analysis ]     and @xmath325 ( a ) tmcmc ( b ) mh , title=\"fig : \" ] ( a )   and @xmath325 ( a ) tmcmc ( b ) mh , title=\"fig : \" ] ( b )    notice the excellent result of the mcmc based on transformations .",
    "the acceptance ratio is almost twice as large as those for other two mh algorithms .",
    "as remarked towards the end of section [ subsec : accept_rate ] , indeed tmcmc outperformed the mh block proposal based on the large sample covariance matrix of the mle of @xmath323 in terms of acceptance rate .",
    "also for implementing tmcmc we need to simulate only one @xmath6 in each step . in the rwmh with sequential updation and in mh based on bivariate normal proposal",
    "we need two such @xmath327 s . in the rwmh",
    "we need to calculate the likelihood twice in each iteration .",
    "so , tmcmc dominates the other two in this respect .",
    "it can be easily anticipated , in light of the theoretical arguments in section [ subsec : accept_rate ] , that for joint rwmh the acceptance rate would be even lower . in section [ sec : appl : dtm ] , where we consider a 160-dimensional problem , we show as indicated by the calculations in section [ subsec : accept_rate ] , that tmcmc outperforms joint rwmh by a substantially large margin in terms of acceptance rate .",
    "we now consider the much analysed radionuclide count data on rongelap island ( see , for example , diggle97 , diggle98 , chris04 , chris06 ) , and illustrate the performance of tmcmc with a singleton @xmath6 . for @xmath328 , diggle98 model the count data as @xmath329 where @xmath330 @xmath294 is the duration of observation at location @xmath331 , @xmath332 is an unknown parameter and @xmath333 is a zero - mean gaussian process with isotropic covariance function of the form @xmath334 for any two locations @xmath335 . in the above",
    ", @xmath336 denotes the euclidean distance between two locations , and @xmath337 are unknown parameters .",
    "typically in the literature @xmath338 is set equal to 1 ( see , _",
    "e. g. _ chris06 ) , which we adopt .",
    "we assume uniform priors on the entire parameter space corresponding to @xmath339 .",
    "we remark that since the gaussian process @xmath333 does not define a markov random field , the block updating proposal developed by rue01 is not directly applicable here .",
    "rue09 attempt to develop deterministic approximations to latent gaussian models , but the scope of such approximations is considerably restricted by the conditional independence ( gaussian markov random field ) assumption ( banerjee09 ) . thanks to the generality and efficiency of our proposed methodology , it seems most appropriate to fit the rongelap island model using tmcmc with singleton @xmath6 .",
    "drawing @xmath196 , we considered the following additive transformation @xmath340 the scaling factors associated with @xmath6 in each of the transformations are chosen on a trial - and - error basis after experimenting with several initial ( pilot ) runs of tmcmc .",
    "we assigned equal probabilities to all the @xmath341 move types .",
    "move types are selected by simply generating ` @xmath342 ' or ` @xmath343 ' with equal probabilities and plugging in the sign in each of the 160 individual transformations .    after discarding the first @xmath344 iterations as burn - in",
    ", we stored 1 in every 100 iterations in the next @xmath345 iterations .",
    "this entire simulation took about a week to run on an ordinary laptop machine and about 3 days on a workstation .",
    "the autocorrelation functions of the variables ( after further thinning by 10 ) of our tmcmc run , displayed in figure [ fig : tmcmc_dtm ] , indicates reasonable mixing properties .",
    "the acceptance rate , after discarding the burn - in period , is 0.43% ( considering the complete run of tmcmc after burn - in , that is , including thinning as well ) .    , @xmath332 , @xmath346 ( left - panel ) and @xmath347 ( right - panel ) in the tmcmc run.,title=\"fig:\",scaledwidth=40.0% ] , @xmath332 , @xmath346 ( left - panel ) and @xmath347 ( right - panel ) in the tmcmc run.,title=\"fig:\",scaledwidth=40.0% ]      we also implemented a joint rwmh using the same additive transformation as in section [ subsec : tmcmc_results ] but with different @xmath6 s for each unknown .",
    "now the acceptane rate reduced to 0.0005% .",
    "these observations are exactly in keeping with the theoretical discussion presented in section [ subsec : accept_rate ] . in fact , referring to the calculations presented in that section , note that , with @xmath348 , @xmath349 , and @xmath350 , @xmath351 , which corresponds to rwmh , while @xmath352 , corresponding to tmcmc .",
    "doubly  intractable distributions arise quite frequently in fields like circular statistics , directed graphical models , markov point processes etc .",
    "even some standard distributions like gamma and beta involve untractable normalizing constants .",
    "formally , a density @xmath353 of the data set @xmath354 is said to be doubly ",
    "intractable if it is of the form @xmath355 where @xmath356 is a function that is not available in closed form .",
    "so if we put a prior @xmath357 on @xmath358 , then the posterior is given by @xmath359 thus , if we try to apply mh like algorithms then the acceptance ratio will involve ratio of the function @xmath360 at two paramter points @xmath358 and @xmath361 . hence directly applying mh may not be feasible .",
    "works by @xcite and @xcite are significant in this field . a double mh sampler approach is taken in @xcite . in this section",
    "we briefly discuss the bridge  exchange algorithm by @xcite and show how our application of tmcmc in the bridge  exchange algorithm may facilitate fast computation .",
    "suppose @xmath362 is the _ bridge size _",
    ", @xmath363 .",
    "define the density @xmath364 obviously , @xmath157 is of the same dimensionality as @xmath365 ; that is , @xmath366 .",
    "further suppose that for each @xmath367 , @xmath368 is a kernel satisfying the detailed balance condition @xmath369 now with a proposal density @xmath370 for the parameter , the bridge  exchange algorithm is given below .",
    "[ algo : bridgexchange ]    ' '' ''    height 1pt width    the bridge  exchange algorithm    ' '' ''    height 1pt width    * input : initial state @xmath371 , length of the chain @xmath69 , # bridge + levels @xmath372 . * * for * @xmath373 * * propose @xmath374 * * generate an auxiliary variable with exact sampling : @xmath375 * * generate m further auxiliary variables with transition + operators : @xmath376 * * compute @xmath377 * * set @xmath378 * * end for *    ' '' ''    height 1pt width    now we see that , since each of the auxiliary variables @xmath379 , is @xmath380-dimensional , generation of these auxiliary variables may be computationally demanding if the sample size @xmath380 is moderate or large especially when one has to simulate from the sample space using accept - reject algorithms as in the case of circular variables . for any kernel @xmath381 which is not based on tmcmc , @xmath382 variables are required to be generated from the state  space per iteration . appealing to tmcmc , recall that with the additive transformation with a single @xmath6 , the kernel still satisfies the detailed balance condition .",
    "we assume that @xmath1 is a group under some binary operation and that there is a homomorphism from @xmath383 to @xmath1 for some @xmath384 .",
    "so we denote the binary operation on @xmath1 by ` @xmath342 ' itself .",
    "let @xmath66 be a density on @xmath1 .",
    "we construct the kernels @xmath381 as follows :    [ algo : t_k ]    ' '' ''    height 1pt width    construction of @xmath381    ' '' ''    height 1pt width    * generate @xmath385 and a subset @xmath386 of @xmath387 * define the vector @xmath188 by @xmath388 * set @xmath389 * set @xmath390    ' '' ''    height 1pt width    in this way we need only @xmath391 simulations per iteration .",
    "homomorphism from @xmath383 to @xmath1 holds in many cases , for example , in circular models where the state  space is @xmath392 $ ] is a group with respect to addition modulo @xmath40 .",
    "( solid line ) and it s estimate ( dash - dotted line).,scaledwidth=90.0% ]      here we illustrate our method for a circular model of the form @xmath393 we generate a sample of size 20 from @xmath394 and estimate the parameter @xmath395 based on this sample .",
    "the prior chosen on @xmath395 is the uniform distribution on @xmath392 $ ] and @xmath79 is chosen to be the normal distribution with mean 0 and variance 1 restricted on the set @xmath396 $ ] . since the components of @xmath397 are @xmath398 , we used @xmath399 for each subset @xmath87 of @xmath387 and @xmath400 for each @xmath153 .",
    "we set @xmath401 and chose @xmath402 to be the von - mises distribution with mean @xmath395 and concentration 0.5 to keep the acceptance level around 63% .",
    "the right panel of figure [ fig : bridgetmcmc_nu ] shows that the estimated posterior density of @xmath395 is very close to the exact posterior density .",
    "the little discrepancy at the tails are due to the fact that @xmath395 is a circular variable and hence its support is @xmath392 $ ] and the density is _ not _ zero at the end points  a fact that is not incorporated in the kernel density estimator .",
    "the left panel of the same figure shows that the mixing is excellent .",
    "notice that here we have saved @xmath403 = 95% simulations .",
    "in this paper we have proposed a novel mcmc method that uses deterministic transformations and move types to update the markov chain .",
    "we have shown that our algorithm tmcmc generalizes the mh algorithm boiling down to mh with a specialized proposal density in one - dimensional cases . for higher dimensions if each component @xmath140 of the random vector to be updated is associated with a distinct @xmath139 , then tmcmc again boils down to the mh algorithm with a specialised proposal density .",
    "but in dimensions greater than one , with less number of distinct @xmath139 than the size of the random vector to be updated , tmcmc does not admit any mh representation . that hmc is also a special case of tmcmc ,",
    "is also explained .",
    "we also contrasted tmcmc with the transformation - based methods of liu99 , liu00 , and kou05 .",
    "the advantages of tmcmc are more prominent in high dimensions , where simulating a single random variable can update many parameters at the same time , thus saving a lot of computing resources . that many variables can be updated in a single block without compromising much on the acceptance rate ,",
    "seems to be another quite substantial advantage provided by our algorithm .",
    "we illustrated with examples that tmcmc can outperform mh significantly , particularly in high dimensions .",
    "the computational gain of using tmcmc for simulations from doubly intractable distributions , is also significant , and is illustrated with an example .",
    "the ideas developed in this paper are not confined to continuous target distributions , but also to discrete cases . for the sake of illustration",
    ", we consider two examples below .    *",
    "consider an ising model , where , for @xmath141 @xmath404 , the discrete random variable @xmath140 takes the value @xmath405 or @xmath170 with positive probabilities .",
    "we then have @xmath406 . to implement tmcmc , consider the forward transformation @xmath407 with probability @xmath158 , and choose the backward transformation as @xmath408 with probability @xmath409 .",
    "here @xmath410 accordingly as @xmath411 or @xmath412 , and @xmath413 .",
    "note the difference with the continuous cases . here even though neither of the transformations is 1-to-1 or onto , tmcmc works because of discreteness ; the algorithm can easily be seen to satisfy detailed balance , irreducibility and aperiodicity .",
    "however , if @xmath414 with @xmath136 being the only variable , then , if @xmath415 , it is possible to choose , with probability one , the backward move - type , yielding @xmath416 . on the other hand ,",
    "if @xmath417 , with probability one , we can choose the forward move - type , yielding @xmath418 .",
    "only @xmath94 move - types are necessary for the @xmath83-dimensional case for one - step irreducibility .",
    "in discrete cases , however , there will be no jacobian of transformation , thereby simplifying the acceptance ratio .",
    "* for discrete state spaces like @xmath419 , ( @xmath420 ) the additive transformation with single epsilon does not work .",
    "for example , with @xmath421 , if the starting state is @xmath422 then the chain will never reach any states @xmath423 where @xmath7 and @xmath424 have same parity ( i.e. both even or both odd ) resulting a reducible markov chain .",
    "thus in this case we need to have more move - types than @xmath94 .",
    "for example , with some positive probability ( say @xmath425 ) we may select a random coordinate and update it leaving other states unchanged . with the remaining probability ( i.e. @xmath426 )",
    "we may do the analogous version of the additive transformation : + let @xmath427 .",
    "then , can choose the forward transformation for each coordinate as @xmath428 $ ] and the backward transformation as @xmath429 $ ] , where @xmath430 $ ] denotes the largest integer not exceeding @xmath431 .",
    "+ this chain is clearly ergodic and we still need only _ one _ epsilon to update the states",
    ".    however , in discrete cases , tmcmc reduces to metropolis - hastings with a mixture proposal .",
    "but it is important to note that the implementation is much efficient and computationally cheap when tmcmc - based methodologies developed in this paper , are used .",
    "conversations with dr .",
    "ranjan maitra has led to improved presentation of some of the ideas .",
    "* appendix *",
    "in this section we prove some convergence properties of the tmcmc in the case of the additive transformation . before going into our main result",
    "we first borrow some definitions from the mcmc literature .",
    "a markov transition kernel @xmath129 is @xmath432irreducible , where @xmath433 is a nontrivial measure , if for every @xmath56 and for every measurable set @xmath434 of @xmath1 with @xmath435 , there exists @xmath436 , such that @xmath437            consider now the case where @xmath447 , @xmath448 and @xmath449 where @xmath450 is a @xmath83-vector with strictly positive entries . in this case",
    "suppose that @xmath66 is a density on @xmath42 .",
    "suppose that @xmath40 is bounded and positive on every compact subset of @xmath452 and that @xmath66 is positive on every compact subset of @xmath453 .",
    "then the chain is @xmath454-irreducible , aperiodic .",
    "moreover every nonempty compact subset of @xmath452 is small .",
    "without loss we may assume all the entries of @xmath450 are 1 s .",
    "for notational convenience we shall prove the theorem for @xmath455 .",
    "the general case can be seen to hold with suitably defined ` rotational ' matrices on @xmath452 similar to .",
    "suppose @xmath438 is a nonempty compact subset of @xmath452 .",
    "let @xmath456 be a compact rectangle whose sides are parallel to the diagonals @xmath457 and containing @xmath438 such that @xmath458 .",
    "we shall show that @xmath438 is small , i.e. , @xmath459 such that @xmath460 it is clear that the points reachable from @xmath157 _ in two steps _ are of the form @xmath461 thus , if we define the matrices @xmath462 then the points reachable from @xmath157 _ in two steps _ , other than the points lying on the diagonals passing through @xmath157 itself , are of the form @xmath463    define @xmath464 where @xmath465 is the length of the diagonal of the rectangle @xmath456 suffices . ] . fix an element @xmath466 . for any set @xmath467 ,",
    "let @xmath468 and define , @xmath469 the need for defining such sets illustrated in the following example : to make a transition from the state @xmath157 to a state in @xmath470 in two steps , first making a forward transition in both coordinates and then a forward transition in first coordinate and a backward transition in the second coordinate is same as applying the transformation @xmath471 for some @xmath472 in two steps , i.e. first @xmath473 also note that for any @xmath474 , @xmath475 implies that the intermediate point @xmath476 and similarly for @xmath477 .",
    "now , with @xmath478 and @xmath479 as the minimum and maximum of the move probabilities @xmath480 @xmath481 since @xmath482 , so that , @xmath483 . now notice that , if we define for @xmath484 @xmath485 and @xmath486 then , @xmath487 since , @xmath488 s are pairwise disjoint , @xmath489 and @xmath490 for @xmath491 .",
    "it follows from that @xmath492 where @xmath493 . +",
    "this completes the proof that @xmath438 is small .",
    "that the chain is irreducible , follows easily , for any @xmath157 , the set @xmath494 is a compact set and for a measurable set @xmath434 with @xmath495 we may choose @xmath456 in the first part of the proof such that @xmath496 .",
    "now , @xmath497 also aperiodicity follows trivially from the observation that any set with positive @xmath454-measure can be accessed in at most 2 steps .",
    "diggle , p.  j. , tawn , j.  a , and moyeed , j.  a. ( 1997 ) .",
    "eostatistical analysis of residual contamination from nuclear weapons testing . in v.",
    "barnet and k.  f. turkman , editors , _ statistics for the environment 3 : pollution assessment and control _ , pages 89107 .",
    "chichester : wiley .",
    "mller , j. , pettitt , a. n. , berthelsen , k. k. and reeves , r. w. ( 2004 ) .",
    "n efficient markov chain monte carlo method for distributions with intractable normalising constants . _",
    "technical report r-2004 - 02 , department of mathematical sciences , aalborg university_.      murray , i. , ghahramani , z. , and mackay , d. j.  c. ( 2006 ) . for doubly - intractable distributions . in r.",
    "dechter and t.  s. richardson , editors , _ proceedings of the 22nd annual conference on uncertainty in artificial intelligence ( uai-06 ) _ , pages 359366 .",
    "auai press ."
  ],
  "abstract_text": [
    "<S> in this article we propose a novel mcmc method based on deterministic transformations @xmath0 : @xmath1@xmath2@xmath3 @xmath4 @xmath1 where @xmath1 is the state - space and @xmath3 is some set which may or may not be a subset of @xmath1 . </S>",
    "<S> we refer to our new methodology as transformation - based markov chain monte carlo ( tmcmc ) . </S>",
    "<S> one of the remarkable advantages of our proposal is that even if the underlying target distribution is very high - dimensional , deterministic transformation of a one - dimensional random variable is sufficient to generate an appropriate markov chain that is guaranteed to converge to the high - dimensional target distribution . </S>",
    "<S> apart from clearly leading to massive computational savings , this idea of deterministically transforming a single random variable very generally leads to excellent acceptance rates , even though all the random variables associated with the high - dimensional target distribution are updated in a single block . since it is well - known that joint updating of many random variables using metropolis - hastings ( mh ) algorithm generally leads to poor acceptance rates , tmcmc , in this regard , seems to provide a significant advance . </S>",
    "<S> we validate our proposal theoretically , establishing the convergence properties . </S>",
    "<S> furthermore , we show that tmcmc can be very effectively adopted for simulating from doubly intractable distributions .    </S>",
    "<S> we show that tmcmc includes hybrid monte carlo ( hmc ) as a special case . </S>",
    "<S> we also contrast tmcmc with the generalized gibbs and metropolis methods of liu99 , liu00 and kou05 , pointing out that even though the latter also use transformations , their goal is to seek improvement of the standard gibbs and metropolis hastings algorithms by adding a transformation - based step , while tmcmc is an altogether new and general methodology for simulating from intractable , particularly , high - dimensional distributions . </S>",
    "<S> tmcmc is compared with mh using the well - known challenger data , demonstrating the effectiveness of of the former in the case of highly correlated variables . </S>",
    "<S> moreover , we apply our methodology to a challenging posterior simulation problem associated with the geostatistical model of diggle98 , updating 160 unknown parameters jointly , using a deterministic transformation of a one - dimensional random variable . </S>",
    "<S> remarkable computational savings as well as good convergence properties and acceptance rates are the results .    </S>",
    "<S> # 1    0    0    1    0    * markov chain monte carlo based on deterministic transformations *    _ keywords : _ geostatistics ; high dimension ; inverse transfromation ; jacobian ; metropolis - hastings algorithm ; mixture proposal </S>"
  ]
}