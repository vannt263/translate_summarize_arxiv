{
  "article_text": [
    "astrophysical simulations commonly need to solve the poisson equation , @xmath0 for the gravitational potential @xmath1 given a density distribution @xmath2 .",
    "similar equations also arise in other contexts , such as incompressible flow problems and divergence - cleaning methods for magnetohydrodynamics .",
    "self - gravitating problems offer special challenges because they frequently develop structure spanning large spatial dynamic ranges .",
    "the problem of spatial dynamic range is particularly acute for grid - based schemes for solving the euler equations of hydrodynamics .    within the context of grid - based methods for solving the poisson equation ,",
    "several approaches to the problem of spatial dynamic range have arisen .",
    "the simplest approach is to use fourier transforms , multigrid methods , or sparse iterative solvers on uniform eulerian grids .",
    "the maximum dynamic range is then limited by the available memory .",
    "recently trac and pen ( 2006 ) have demonstrated an out - of - core uniform - grid poisson solver that exceeds this limit by making use of disk space ; the largest published calculations with this solver have used @xmath3 zones .",
    "however , storage resource consumption still increases with the third power of the resolution , putting grids with @xmath4 zones on a side or larger out of reach for now .    if high resolution is not needed everywhere in the domain , as is frequently the case in cosmological structure formation simulations , it is also possible to employ nonuniform eulerian or lagrangian grids .",
    "examples include cosmos ( ricker , dodelson , & lamb 2000 ) , which uses a nonuniform multigrid solver , and mmh ( pen 1998 ) , which uses a deformable mesh .",
    "these methods work best when the region to be resolved is known beforehand , although fully lagrangian codes like pen s can follow the development of structures and adjust zone spacing appropriately .",
    "nonuniform grids , however , introduce complicated position - dependent stencils and generally can not be used with fast transform - based solvers .",
    "in addition , coupled numerical hydrodynamics methods generally place constraints on the allowed mesh anisotropy and nonuniformity , since numerical dissipation increases with zone spacing .    the greatest spatial dynamic ranges in grid - based astrophysical simulations",
    "have been achieved using adaptive mesh refinement ( amr ) techniques .",
    "modern amr techniques for solving hyperbolic systems of equations were first developed by berger and oliger ( 1984 ) and berger and colella ( 1989 ) . in the berger and colella formulation ,",
    "amr involves the construction of a hierarchical set of mesh `` patches '' with decreasing zone spacing .",
    "the coarsest mesh covers the entire computational domain , while more highly refined meshes cover only a portion .",
    "generally refined meshes are taken to be nested ; that is , each refined mesh lies completely within its coarser parent mesh .",
    "examples of astrophysical codes employing patch - based amr meshes include the code of truelove et al .",
    "( 1998 ) , amra ( plewa & mller 2001 ) , riemann ( balsara 2001 ) , enzo ( oshea et al .  2004 ) , and charm ( miniati & colella 2007 ) .",
    "to date self - gravitating amr calculations have achieved effective spatial resolutions greater than @xmath5 .    a considerable simplification of the berger and colella method was introduced by quirk ( 1991 ) and de  zeeuw and powell ( 1993 ) .",
    "known as `` oct - tree '' amr , this method requires that each refined patch contain the same number of zones , that each refinement level have zones a factor of two smaller in each dimension than the next coarser level , and that each refined patch be no more than one level removed from its immediate neighbor .",
    "mesh data can then be stored in an oct - tree data structure , allowing for extremely efficient parallel implementations , even on high - latency systems ( warren & salmon 1993 ) . also , because each mesh patch ( often called a `` block '' in this context ) contains the same number of zones , it is possible to achieve high levels of cache re - use when iterating over zones .",
    "unless each block contains a very small number of zones , this efficiency comes with the price that refined blocks often must cover more of the volume than they would in a patch - based method .",
    "the primary astrophysical simulation code employing oct - tree amr is flash ( fryxell et al .",
    "2000 ) , which uses the paramesh library ( macneice et al .",
    "2000 ) to handle its amr mesh .",
    "( the art ( kravtsov , klypin , & khoklov 1997 ) , mlapm ( knebe , green , & binney 2001 ) , and ramses ( teyssier 2002 ) codes also use tree structures to manage amr meshes , but in these codes the refined blocks consist of a single zone each , and the base mesh generally contains a large number of zones , so these codes do not employ oct - trees . a block - based amr approach that allows for `` incomplete families",
    "'' has also recently been implemented within the vac code ( van der holst & keppens 2007 ) ; the oct - trees discussed in the current paper require complete `` families '' of child blocks . ) by default paramesh uses blocks containing @xmath6 interior zones as a compromise between adaptive flexibility and memory efficiency , but any size larger than the differencing stencil and small enough to fit in the memory attached to a single processor can be employed .",
    "poisson solvers on oct - tree meshes generally employ some type of multigrid or sparse linear solver iteration scheme .",
    "transform methods can not be employed directly because of the varying mesh resolution and non - tensor - product character of the composite mesh .",
    "for example , matsumoto and hanawa ( 2003 ) describe a relaxation - based method for solving the poisson equation on nested grids . within the flash framework ,",
    "we have employed the martin and cartwright ( 1996 ) multigrid algorithm for several years .",
    "however , the speed and scalability of this algorithm have been limited because of the need to apply multiple relaxation iterations on each level , together with the communication of block boundary data that such iterations require . because the cost of this algorithm dominates the cost of most self - gravitating simulations with flash",
    ", we are motivated to develop more efficient methods that require less communication .    in this paper",
    "we describe one such method , based on the direct multigrid algorithm of huang and greengard ( 2000 , hereafter hg ) .",
    "this algorithm improves considerably upon relaxation - based multigrid solvers by allowing refined patches to be solved directly using `` black - box '' uniform - grid solvers . unlike the direct method described by couchman ( 1991 ) ,",
    "the hg algorithm properly minimizes the global residual by allowing information to flow back from fine meshes to coarse meshes .",
    "however , it is formulated on a finite - difference mesh in which refined patches are not permitted to touch . here",
    "we describe a modified version of the hg algorithm suitable for finite - volume oct - tree amr meshes .",
    "we have implemented this algorithm within the flash framework , and we present test results that demonstrate the solver s accuracy .",
    "the present paper should be regarded as a companion to fryxell et al .",
    "( 2000 ) and a methodological description for future flash - based simulation papers in the areas of cosmic structure formation , galaxy cluster physics , star cluster formation , and binary star evolution , among others .",
    "the paper is organized as follows . in ",
    "[ sec : algorithm ] we give a precise description of the algorithm . in ",
    "[ sec : tests ] we present the results of test problems run with the new solver .",
    "we conclude in   [ sec : conclusions ] with some remarks on performance .",
    "all calculations described in this paper were performed using version 2.4 of flash .",
    "before describing the algorithm , let us first define some terms .",
    "we work with approximations @xmath7 to the solution to equation  ( [ eqn : poisson ] ) .",
    "the residual is a loose measure of the error in @xmath7 ; it is given by @xmath8 the first term on the right - hand side is the source @xmath9 . since the poisson equation is linear , the residual satisfies the equation @xmath10 whose solution @xmath11 is the correction which must be added to @xmath7 to yield the correct solution @xmath1 .",
    "the source , solution , residual , and correction are all approximated by zone - averaged values on a hierarchy of mesh blocks .",
    "where a given mesh block is not a `` leaf node ''  ie .",
    ", it is overlain by another block at a higher level of refinement  only the residual and correction are defined ( though storage may be allocated for the other variables as well ) .",
    "when discussing discretized quantities such as the solution @xmath12 , we will refer to them in the form @xmath13 , where @xmath14 is the block number at the @xmath15th level of refinement ( @xmath16 being the coarsest level ) , and @xmath17 are zone indices within the block @xmath14 .",
    "the notation @xmath18 will refer to the parent ( coarser ) block containing block @xmath14 , while @xmath19 will refer to the @xmath20th child ( finer ) block associated with @xmath14 ( @xmath21 in @xmath22 dimensions ) .",
    "zone indices are assumed to run between @xmath23 , @xmath24 , and @xmath25 in each block , where @xmath26 is the number of ghost zones ( `` guard cells '' in paramesh parlance ) on each boundary . between adjacent levels",
    "there is a factor of two in refinement .",
    "the generalization to different block / patch sizes and different refinement factors should be fairly straightforward .",
    "a cartesian mesh is assumed .    on each block",
    "we will also define several operators . on level @xmath15 , which has zone spacings @xmath27 , @xmath28 , and @xmath29 in the @xmath30- , @xmath31- , and @xmath32-directions",
    ", we define the second - order difference operator approximating @xmath33 via @xmath34 this operator is only applied for @xmath35 within block interiors .",
    "the difference we use is second - order accurate , but there is nothing about the hg algorithm that limits us to second order . when values of @xmath12 in boundary zones are needed , they are set in one of three ways : by restriction from interior zones of a finer neighbor block , by copying from a neighboring block at the same level of refinement , or by prolongation from the block s parent . the difference operator is needed for two purposes : to compute the residual using the finite - volume version of equation  ( [ eqn : residual ] ) , and in the single - block direct solver .    because we are using finite - volume quantities",
    ", we can define the restriction operator @xmath36 for block interior zones @xmath35 exactly as @xmath37 where the indices @xmath38 refer to the zones in block @xmath39 that lie within zone @xmath35 of block @xmath40 .",
    "we apply the restriction operator throughout the interiors of blocks , but its opposite , the prolongation operator @xmath41 , need only be defined on the edges of blocks , because it is only used to set boundary values for the direct single - block poisson solver : @xmath42 when needed , boundary zone values are set as for the difference operator .",
    "we use conservative quartic interpolation to set edge values , then solve with homogeneous dirichlet boundary conditions after using second - order boundary - value elimination .",
    "( quadratic interpolants will sometimes work , but experimentation revealed better convergence with quartic interpolation . )",
    "the coefficients @xmath43 determine the interpolation scheme . for the @xmath44 face in 3d ,",
    "@xmath45 interpolation coefficients are defined analogously for the other faces .",
    "note that we use half - integer zone indices to refer to averages over the faces of a zone ; integer zone indices refer to zone averages .",
    "in addition to the above operator definitions , we need a poisson solver that can solve problems with given boundary values on uniform cartesian meshes .",
    "fortunately , many different algorithms are available to solve this class of problems , ranging from the easy - to - implement but slow relaxation methods to fast fourier transform ( fft ) methods and conjugate gradient algorithms . indeed , one of the advantages of the hg algorithm is that it treats the solution on individual blocks as a ` black box . '",
    "for our purposes we will use the @xmath22-dimensional fast sine transform for homogeneous dirichlet boundary conditions with the transform - space green s function @xmath46^{-1}\\ .\\ ] ] note that any second - order solver that can handle homogeneous dirichlet boundaries can be modified to work with inhomogeneous ( given - value ) boundaries using boundary - value elimination .",
    "for example , at the @xmath44 boundary , the @xmath30 part of the difference operator refers to @xmath47 , which is unknown for @xmath48 .",
    "however , if @xmath49 is given , then to second order @xmath50 ( we have dropped the block and level superscripts for clarity ) .",
    "the second term on the right - hand side is the same for homogeneous boundaries , so we can recast the problem as a homogeneous one by replacing the source term as follows : @xmath51 corresponding replacements can be made at the other boundaries .    for periodic problems , we need only apply the periodic boundary conditions to the coarsest ( level 1 ) block . for this purpose",
    "we use a real - to - complex fft with green s function @xmath52^{-1}}\\\\ \\\\",
    "\\hfill i , j , { \\rm\\ or\\ } k \\ne 1 \\\\ \\\\",
    "\\displaystyle                     0\\hfill i = j = k = 1                     \\end{array } \\right.\\ ] ] however , this is not all that is required .",
    "the poisson difference operator with periodic boundary conditions is singular ; if the zero - wavenumber component of the source function is not set exactly to zero , the resulting solution will not be unique .",
    "if the average of the source is zeroed only for the coarsest block , errors in interpolation to higher levels of refinement will quickly cause a nonzero dc component to creep into the residual , with the result that the multigrid v - cycle iteration ( described below ) will converge slowly or not at all .",
    "hence when using periodic boundary conditions we explicitly subtract the average from the residual on all levels , not just the coarsest . for each level",
    "that is not fully refined , we compute the average for that level by summing over blocks on that level and leaf - node blocks on coarser levels .",
    "the use of dirichlet boundaries on individual blocks allows for matching of the value of the solution across block boundaries at the same level of refinement , but not its normal derivative .",
    "hence at block corners the residual converges only at first order .",
    "we have tried several different methods to accelerate the method s convergence at these locations ; the simplest and most effective remedy while preserving second - order differencing is obtained if we apply two gauss - seidel relaxations to the outer two layers of zones in each block . while this removes some of the `` directness '' of the method , it is still significantly faster than using relaxation alone .",
    "when periodic boundaries are used , we subtract the average from the solution following this relaxation step .",
    "it is possible that a higher - order differencing scheme ( requiring more boundary information ) could dispense with this additional smoothing .",
    "the two - grid solution procedure for the hg algorithm begins with a coarse - grid solution @xmath53 of the discretized poisson equation .",
    "this solution is used to provide boundary conditions to a finer mesh which may not span the entire domain ( figure  [ fig : meshes ] ) .",
    "since the original algorithm uses a finite - difference mesh in which the coarse and fine meshes share some mesh points , interpolation is needed only at intermediate points .",
    "we will refer to the resulting fine - mesh solution as @xmath54 .",
    "the `` composite '' solution @xmath55 is then taken to be equal to @xmath53 on the coarse - grid points and @xmath54 on the fine - grid points . by construction",
    "the composite solution is continuous across the mesh interface , but its normal derivative is not .",
    "this discontinuity gives rise to a single - layer potential , which when added to the composite solution yields the corrected solution @xmath56 .",
    "hg make use of a lemma that allows one to compute the single - layer potential simply using the discontinuity .",
    "one first computes a source function @xmath57 on the coarse mesh by applying the difference operator on the coarse mesh to @xmath58 for points on the mesh interface .",
    "away from the interface , @xmath59 .",
    "( note that no interpolation is required for this step . )",
    "the poisson equation is solved on the coarse mesh using @xmath57 as a source function , and the result is used to correct @xmath53 .",
    "the corrected coarse - grid solution is then used to provide new boundary conditions for a corrected fine - grid solution .",
    "the hg algorithm is unsuitable for finite - volume oct - tree meshes for two reasons .",
    "first , as figure  [ fig : meshes ] shows , the coarse and fine meshes share no discretely sampled points in common .",
    "( the finite - volume mesh stores zone averages , not zone - center values , but to second order the two are equivalent . ) hence boundary conditions must be supplied to the fine mesh via interpolation ( points marked with @xmath60 in figure  [ fig : meshes ] ) , and @xmath55 therefore is not guaranteed to be continuous at the boundary .",
    "if we wish to compute the resulting single - layer potential on the coarse mesh , we must restrict the fine - mesh potential back to the coarse mesh .",
    "the resulting errors in the single - layer potential delay or prevent convergence .",
    "second , the meshes used by the hg algorithm do not share boundaries ( except possibly an external boundary ) .",
    "oct - tree meshes , on the other hand , usually have internal boundaries that are shared by blocks at the same level of refinement .",
    "we wish to apply the direct solver independently to each block regardless of whether its boundaries correspond to jumps in refinement .",
    "we can address both issues by realizing that the single - layer potential source @xmath57 can be replaced with a residual if the direct solver reduces the residual to machine zero away from jumps in refinement .",
    "for example , consider the mesh depicted at the left of figure  [ fig : meshes ] , taking @xmath61 to be the fine - mesh spacing and indexing points on both meshes using the same system .",
    "the points along the mesh interface correspond to @xmath62 .",
    "hence the first column of coarse - grid points to the right of the interface is at @xmath63 , while the first column of fine - grid points to the left of the interface is at @xmath64 .",
    "for this situation , @xmath57 is given by @xmath65 the residual in @xmath55 , on the other hand , is for points on the boundary , @xmath66 whereas for @xmath67 it is effectively zero .",
    "( it is not necessarily zero for @xmath68 , since the coarse - grid difference operator would be applied to @xmath54 there . )",
    "the coarse - grid solution was obtained using the direct solver , so the coarse - grid residual on the interface is also effectively zero : @xmath69 combining these equations to eliminate @xmath70 yields @xmath71 which is the same as @xmath72 . if @xmath73 is forced to be zero also for @xmath68 ( e.g.  by computing the residual on the fine mesh and restricting it ) , the correction generated by solving the poisson equation with @xmath73 as a source function should therefore be equal to the single - layer potential .",
    "we can use this insight to create a finite - volume version of the hg algorithm that uses the residual to construct the correction .",
    "referring to the right part of figure  [ fig : meshes ] , we begin by solving for @xmath53 on the coarse mesh , subject to the external boundary conditions , and use conservative quartic interpolation on @xmath53 to set boundary values at the mesh interface .",
    "we solve for @xmath54 on the fine mesh with these boundary conditions and compute the residual on the fine mesh .",
    "computing the residual in the fine - mesh zones adjacent to the interface requires boundary values interpolated from the coarse mesh ; we again use quartic interpolation , but instead of interpolating interface values , we interpolate average values over the quarter of each coarse - mesh zone adjacent to each fine - mesh zone . this allows us to use the same centered difference operator as implied by the green s function . it also allows us to treat boundaries involving jumps in refinement in the same way as boundaries separating blocks at the same refinement level .",
    "we next restrict the fine - mesh residual to the part of the coarse mesh that underlies it and compute the coarse - mesh residual throughout the remainder of the coarse mesh .",
    "we should now have a very small residual everywhere except for the coarse - mesh zones just to the left of the mesh interface ( ie .",
    "underlying the fine mesh ) .",
    "we solve the correction equation on the coarse mesh using this residual as a source function , subject to homogeneous dirichlet boundary conditions .",
    "we use the solution to correct @xmath53 , interpolate the coarse - mesh correction to the mesh interface , and use these boundary conditions to solve the correction equation on the fine mesh . applying",
    "the fine - mesh correction to @xmath54 completes the two - grid iteration .",
    "we recompute the residual on both levels and use its norm to determine whether to apply another correction .",
    "we can construct an algorithm for arbitrary numbers of refinement levels by recursively extending our two - grid iteration . in terms of the operators",
    "defined previously , here are the steps in our modified hg algorithm :    1 .",
    "begin by restricting the source function @xmath74 on all levels so that it is defined on every block .",
    "if using periodic boundary conditions , subtract the global average .",
    "interpolation step : _ for each level @xmath15 from 1 to the maximum level @xmath75 , 1 .",
    "if @xmath76 and using external dirichlet boundaries , set external boundary ( face ) values of @xmath13 for all blocks @xmath14 on level @xmath15 to 0 . 2 .",
    "solve @xmath77 for all blocks @xmath14 on level @xmath15 .",
    "( the edge relaxation mentioned in ",
    "[ sec : direct solver ] is applied immediately after the direct solver here . )",
    "compute the residual @xmath78 for all blocks @xmath14 on level @xmath15 . in setting boundary values for this step , ignore levels @xmath79 , copy data from neighboring blocks at level @xmath15 , and interpolate from neighboring blocks at levels @xmath80 .",
    "4 .   for each block @xmath14 on level @xmath15 that has children , interpolate face boundary values of @xmath13 for each child .",
    "residual propagation step : _ restrict the residual on all levels so that @xmath81 contains either a `` coarse grid '' residual if @xmath14 is a leaf - node block or a restricted `` fine grid '' residual if @xmath14 is not .",
    "correction step : _ compute the discrete l2 norm of the residual over all leaf - node blocks and divide it by the discrete l2 norm of the source over the same blocks .",
    "if the result is greater than a preset threshold value , proceed with a correction step : for each level @xmath15 from 1 to @xmath75 , 1 .",
    "if @xmath76 , set external boundary ( face ) values of @xmath82 for all blocks @xmath14 on level @xmath15 to 0 . 2 .",
    "solve @xmath83 for all blocks @xmath14 on level @xmath15 .",
    "( the edge relaxation mentioned in   [ sec : direct solver ] is applied immediately after the direct solver here . )",
    "overwrite @xmath81 with the new residual @xmath84 for all blocks @xmath14 on level @xmath15 . in setting boundary values for this step ,",
    "ignore levels @xmath79 , copy data from neighboring blocks at level @xmath15 , and interpolate from neighboring blocks at levels @xmath80 .",
    "4 .   correct the solution on all leaf - node blocks @xmath14 on level @xmath15 : @xmath85 .",
    "5 .   for each block @xmath14 on level @xmath15 that has children , interpolate face boundary values of @xmath82 for each child . 5 .   if a correction step was performed , return to the residual propagation step .",
    "the above procedure requires storage for @xmath12 , @xmath86 , @xmath87 , and @xmath88 on each block , for a total storage requirement of @xmath89 floating - point values per block ( not including boundary zones ) .",
    "although it is expressed as a serial algorithm , a parallel version can be constructed straightforwardly ( as in the flash implementation ) by using a space - filling curve to allocate blocks to processors .",
    "parallel communication is required when interpolating , restricting , or copying boundary values between blocks that are stored on different processors .",
    "computation of l2 norms and averages also requires a global reduction operation .",
    "it should be emphasized that our algorithm differs in a crucial way from the hg algorithm in its treatment of single - layer potential propagation from fine to coarse meshes . rather than explicitly propagating single - layer potentials from level to level and computing new single - layer sources as we go ( as in hg s step  3 ) , we propagate residuals from the previous interpolation or correction step and rely on nested iteration to communicate the fine - mesh corrections throughout the mesh .",
    "although this method converges more slowly than the hg algorithm , it is much easier to code and parallelize for an oct - tree mesh .",
    "in this section we describe the results of two astrophysically motivated test problems solved using the modified hg algorithm as implemented within flash version 2.4 : the potential of a homogeneous oblate spheroid , with isolated boundary conditions , and a snapshot from a simulation of galaxy cluster formation within a @xmath90cdm universe , using periodic boundary conditions .      the potential of a homogeneous ellipsoid was first derived independently by gauss ( 1813 ) and rodrigues ( 1815 ) .",
    "it is used in the construction of equilibrium solutions for rotating fluid bodies , such as the sequences of maclaurin spheroids and jacobi and dedekind ellipsoids .    consider a homogeneous ellipsoid of density @xmath88 centered on the origin with principal axes @xmath91 , @xmath92 , and @xmath93 aligned with the @xmath30- , @xmath31- , and @xmath32-axes , respectively . the gravitational potential at a point @xmath94 interior to the ellipsoid is ( chandrasekhar 1969 ) @xmath95\\ , \\ ] ] where @xmath96^{1/2}\\ .\\end{aligned}\\ ] ] in general the expressions for @xmath97 can be written in terms of incomplete elliptic integrals , but for oblate spheroids , @xmath98 , and the expressions simplify to @xmath99 where @xmath100 is the ellipticity of the spheroid .",
    "if the point @xmath101 is external to the ellipsoid , the potential is given by @xmath102 where @xmath103 is the positive root of the equation @xmath104 for oblate spheroids this simplifies to @xmath105\\ , \\ ] ] where @xmath106 ( broucke & scheeres 1994 ) .",
    "using our modified hg solver within flash , we computed potentials for oblate spheroids of fixed density ( @xmath107 ) , fixed semimajor axis ( @xmath108 ) , and varying eccentricity ( @xmath109 , 0.5 , 0.96 ) .",
    "the spheroids were centered in a box with unit dimensions . for this test we used the known analytical solution to set external boundary conditions in order to study the convergence properties of the multigrid solver by itself .",
    "( for general isolated problems we use a variant of james ( 1977 ) image - mass method to implement the boundary conditions .",
    "this involves two calls to the poisson solver , plus an external boundary value computation for the image mass distribution .",
    "this boundary value computation is carried out in flash using a separate multipole poisson solver . )",
    "we used maximum refinement levels between 1 and 6 , with blocks containing @xmath6 zones , giving @xmath6  @xmath110 effective resolution .",
    "an example of the potential for @xmath111 , computed with maximum refinement level 6 , is shown in figure  [ fig : spheroid potential ] .",
    "for partially refined calculations , blocks that contain any points within the spheroid are marked for refinement .",
    "this type of refinement is frequently beneficial when solving azimuthally symmetric problems on cartesian meshes .",
    "since this problem has an analytic solution , we can examine the absolute convergence properties of the solver .",
    "here we use the term `` convergence '' in two ways .",
    "iteration convergence rate _ is the rate at which multigrid v - cycles converge to a solution and is given by @xmath112/{\\cal e}[r_{n-1}]$ ] , where @xmath113 is the residual after @xmath114 v - cycles .",
    "following briggs et al .",
    "( 2000 ) , we define the l2 norm of a quantity @xmath115 defined on zones @xmath17 of block @xmath14 to be @xmath116 \\equiv \\left[{1\\over v}\\sum_{ijkb } ( { u^b_{ijk}})^2\\delta v^b_{ijk }     \\right]^{1/2}\\ , \\ ] ] where @xmath117 is the volume of the domain , @xmath118 is the volume of the @xmath17th zone of block @xmath14 , and the sum is taken over all leaf - node blocks and their interior zones . for this test ,",
    "unless otherwise specified , we allowed the solver to iterate until the residual norm dropped below @xmath119 of the source norm . the _ mesh convergence rate _",
    ", on the other hand , is the rate at which the solution converges to the correct solution on meshes of decreasing minimum zone size .",
    "we compute the mesh convergence rate by injecting adaptive - mesh solutions at different maximum refinement levels onto a @xmath120 uniform mesh , then comparing them to the analytical solution computed on the same mesh .",
    "the error should scale as @xmath121 , where @xmath122 is the smallest zone spacing on each adaptive mesh and @xmath123 is the mesh convergence rate .",
    "for uniform meshes this error should be simply the truncation error of the differencing scheme used to solve the poisson equation .",
    "ideally our adaptive mesh scheme should not degrade this performance significantly .",
    "figure  [ fig : spheroid conv ] shows the iteration convergence for the @xmath124 case .",
    "( the other cases show nearly identical behavior . )",
    "the residual is reduced by about a factor of twenty during the first v - cycle ; thereafter the convergence factor increases before flattening to an asymptotic value of about 0.135 .",
    "the overall convergence behavior does not vary significantly with maximum refinement level ; each case reaches the single - precision convergence threshold ( @xmath125 ) within three iterations and the @xmath126 level within seven iterations .",
    "this behavior  initially rapid reduction of residuals followed by approach to a resolution - independent convergence factor  is typical for multigrid algorithms ( briggs et al .",
    "2000 ) ; indeed , it is what permits multigrid algorithms to achieve optimal problem - size scaling for elliptic problems .",
    "although iteration convergence is necessary for a usable algorithm , it does not by itself guarantee a correct solution . in figure  [ fig : spheroid error ]",
    "we show the mesh convergence of our numerical solution relative to the analytical solution ( equations ( [ eqn : ellipsoid potential start ] )  ( [ eqn : ellipsoid potential end ] ) ) for both uniformly refined and partially refined meshes . as expected , the convergence of the uniformly refined meshes reflects the @xmath127 truncation error of our differencing scheme . for partially refined meshes ,",
    "the convergence rate depends on the fraction of the volume occupied by zones adjacent to jumps in refinement . for @xmath109 and @xmath124 at 5 levels of refinement , this fraction is about 4.7% , and the error converges as @xmath128 when compared with the error at 4 levels of refinement .",
    "for @xmath129 about 13% of the volume is adjacent to refinement jumps , and the error converges as @xmath130 . for six levels of refinement the fractions change to 8.8% and 6.4% , respectively , and this change is reflected in a decrease in the convergence rate for @xmath109 and @xmath124 and an increase for @xmath129 .",
    "the cosmological simulation test uses a snapshot from the `` small box '' galaxy cluster simulation described by heitmann et al .",
    "this simulation followed the evolution of a @xmath131 volume in a spatially flat @xmath90cdm cosmology with matter density parameter @xmath132 , power spectrum normalization @xmath133 , and hubble parameter @xmath134 . to examine the self - convergence of the solver ,",
    "we ran the test on several different partially- and fully - refined meshes and compared them with a @xmath135 uniform - mesh solution obtained using the same solver .. the dataset consists of @xmath110 particles , each with mass @xmath136 , at redshift zero .",
    "periodic boundary conditions were used .",
    "we computed potentials using flash with both partially refined and fully refined ( uniform ) meshes . to determine whether to refine each block in the partially refined cases , we computed the number of particles in each zone and took the maximum of the values within the block . blocks with a maximum number of particles per zone greater than 200 were allowed to refine .",
    "we repeated the refinement step until no further refinements occurred .",
    "this refinement criterion corresponds to a varying - interval logarithmic density threshold .",
    "while other density - based criteria are possible , it is beyond the scope of this paper to choose an optimal criterion ; we will present such a comparison in a future paper .",
    "figure  [ fig : lcdm slice ] shows the distribution of dark matter particles within a slice @xmath137 thick passing through the most massive halo in this dataset . also shown",
    "are the potential and the residual in the same slice as computed using the modified hg algorithm in flash with seven levels of refinement . using blocks containing @xmath138 zones",
    ", this corresponds to an effective resolution of @xmath135 .",
    "the potential plot shows the expected correspondence of local potential wells with massive clusters .",
    "the residual plot shows that most of the residual is contained in the zones adjacent to block boundaries , with local peaks at the corners of maximally refined blocks in high - density regions . throughout most of the volume , however ,",
    "the residual is less than @xmath126 of the maximum density , despite the fact that the termination criterion specified that the residual norm drop only below @xmath125 of the source norm .",
    "the residual can be reduced to double - precision round - off level everywhere through additional correction cycles , but this level is adequate for most simulation purposes .    in figure  [ fig : lcdms error ] we examine the mesh convergence of the modified hg solver . the flash potential from each run was injected onto a uniform @xmath135 mesh for this comparison .",
    "the self - difference norm shows the expected second - order convergence in both the partially refined and uniformly refined cases up to @xmath120 effective resolution . at @xmath135",
    "the use of density - based refinement degrades the convergence rate for partially refined meshes to first order .",
    "iteration convergence results for this periodic problem are nearly identical to those for the isolated maclaurin spheroid problem discussed in the previous section ; the @xmath125 level is always reached within five iterations .",
    "we have detailed the modifications needed in order to use the huang & greengard ( 2000 ) algorithm for poisson s equation on oct - tree amr meshes .",
    "this method allows us to use a local direct poisson solver with dirichlet boundary conditions on each block , yet it correctly minimizes the residual across the composite amr mesh . the hg algorithm must be modified to take into account the fact that mesh quantities represent zone - averaged values and the fact that block boundaries can coincide on an oct - tree mesh . because adjacent coarse and fine blocks do not share points in common for oct - tree meshes , additional interpolation ( as compared to hg )",
    "is needed to set boundary values .",
    "the resulting errors at block corners reduce convergence to first order , but a fixed small number of boundary - zone relaxation steps restores the desired second - order convergence rate for block corners in uniformly refined regions . a higher - order scheme may be able to eliminate the need for such relaxation .",
    "our test results show that , while jumps in refinement degrade convergence somewhat in comparison with solving on a uniform mesh , the effect is manageable because oct - tree meshes are usually fully refined up to some level .",
    "thus first - order convergence takes over only once the error has been significantly reduced at second order on fully refined levels .    the parallel scaling of this solver ,",
    "as implemented using the message passing interface ( mpi ) in the flash code , is comparable to or slightly better than that of the relaxation multigrid solver distributed with flash 2.@xmath30 . with constant total work and increasing processor count ,",
    "parallel efficiency is close to 100% up to 8  16 times the smallest number of processors on which a run can fit .",
    "when gasdynamics is included , the poisson solver requires @xmath13950% of the execution time ; for particle - only simulations the amount is @xmath14070  80% . in comparison with the older solver , a factor of 2  5 improvement in performance",
    "is often seen .",
    "the solver described here will be made available to the public as part of flash  3.0 .",
    "the primary scaling bottleneck for this and other multigrid algorithms is the fact that on the coarsest level there are too few zones to distribute among all of the processors .",
    "since each v - cycle descends to the coarsest level , processors controlling blocks on finer levels must wait until the coarsest level is finished before proceeding . to counteract this work starvation ,",
    "we are investigating the use of a uniform - grid parallel fft solver ( t.  theuns , private communication ) to handle the coarsest level in a distributed fashion .",
    "additional strategies may be necessary to make optimal use of the petaflop computing resources now beginning to become available .",
    "the author would like to thank t.  plewa for calling his attention to the huang and greengard paper and the anonymous referee for helpful comments .",
    "portions of this work were completed at the aspen center for physics .",
    "this work was supported by the university of illinois at urbana - champaign and the national center for supercomputing applications , which also provided supercomputing resources .",
    "additional support was provided under a presidential early career award for scientists and engineers by lawrence livermore national laboratory contract lll b532720 .",
    "development of flash was supported by doe under contract b341495 to the asc center for astrophysical thermonuclear flashes at the university of chicago .",
    "balsara , d.  2001 , jcp , 174 , 614 berger , m.  j.  &  collela , p.  1989 , jcp , 82 , 64 berger , m.  j.  &  oliger , j.  1984 , jcp , 53 , 484 brandt , a.  1977 , math .  comp . , 31 , 333 briggs , w.  l. , henson , v.  e. ,  &  mccormick , s.  f.  2000 , a multigrid tutorial , 2d ed .",
    "( philadelphia : siam ) broucke , r.  a.  &  scheeres , d.  j.  1994 , adv .",
    ", 87 , 423 chandrasekhar , s.  1969 , ellipsoidal figures of equilibrium ( new haven : yale ) couchman , h.  m.  p.  1991",
    ", apj , 368 , l23 de  zeeuw , d.  and powell , k.  g.  1993 , jcp , 104 , 56 fryxell , b. , olson , k. , ricker , p.  m. , et al .",
    "2000 , apjs , 131 , 273 heitmann , k. , ricker , p.  m. , warren , m.  s. , and habib , s.  2005 , apjs , 160 , 28 huang , j.  &  greengard , l.  2000 , siam .",
    "j.  sci .",
    "comput . , 21 , 1551 james , r.  a.  1977 , jcp , 25 , 71 kravtsov , a.  v. , klypin , a.  a. , & khokhlov , a.  m.  1997 , apjs , 111 , 73 knebe , a. , green , a. , & binney , j.  2001 , mnras , 325 , 845 maclaurin , c.  1742 , a treatise on fluxions .",
    "macneice , p. , olson , k.  m. , mobarry , c. , de fainchtein , r. ,  &  packer , c.  2000 , cpc , 126 , 330 martin , d. ,  &  cartwright , k.  1996 , tech .  rep .",
    "ucb / erl m96/66 ( uc berkeley ) matsumoto , t. ,  &  hanawa , t.  2003 , apj , 583 , 296 miniati , f. ,  &  colella , p.  2007 , jcp , 227 , 400 oshea , b.  w. , bryan , g. , bordner , j. , norman , m.  l. , abel , t. , harkness , r. , and kritsuk , a.  2004 , in adaptive mesh refinement  theory and applications , eds .",
    "t.  plewa , t.  linde , and v.  g.  weirs ( springer ) pen , u .- l . , 1998 ,",
    "apjs , 115 , 19 plewa , t. , & mller , e.  2000 , comp .",
    "comm . , 138",
    ", 101 quirk , j.  j.  1991 , phd thesis , cranfield inst .",
    "ricker , p.  m. , dodelson , s. ,  &  lamb , d.  q.  2000 , apj , 536 , 122 teyssier , r.  2002 , a&a , 385 , 337 trac , h. ,  &  pen , u .- l .",
    "2006 , new astr . , 11",
    ", 273 truelove , j.  k. , klein , r.  i. , mckee , c.  f. , holliman , j.  h. , howell , l.  h. , greenough , j.  a. , & woods , d.  t.  1998 , apj , 496 , 821 van der holst , b. ,  &  keppens , r.  2007 , jcp , 226 , 925 warren , m.  s. , and salmon , j.  k.  1993 , in proc .",
    "supercomputing 1993 ( ieee computer society ) , 12"
  ],
  "abstract_text": [
    "<S> we describe a finite - volume method for solving the poisson equation on oct - tree adaptive meshes using direct solvers for individual mesh blocks . </S>",
    "<S> the method is a modified version of the method presented by huang and greengard ( 2000 ) , which works with finite - difference meshes and does not allow for shared boundaries between refined patches . </S>",
    "<S> our algorithm is implemented within the flash code framework and makes use of the paramesh library , permitting efficient use of parallel computers . </S>",
    "<S> we describe the algorithm and present test results that demonstrate its accuracy . </S>"
  ]
}