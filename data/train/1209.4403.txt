{
  "article_text": [
    "shape matching is a fundamental problem in computational geometry , computer vision , and image processing .",
    "a simple version can be stated as follows : given a database @xmath6 of shapes ( or images ) and a query shape @xmath7 , find the shape in @xmath6 that most resembles @xmath7 .",
    "however , before we can solve this problem , we first need to address a much more fundamental issue : what does it mean for two shapes to be similar ? in the mathematical literature , there are many different notions of distance between two sets , a prominent example being the _ hausdorff distance_. for two planar sets @xmath8 and @xmath9 , the ( undirected ) hausdorff distance is defined as @xmath10 where @xmath11 denotes the euclidean distance .",
    "it has the advantage of being simple to describe and easy to compute for discrete sets . in the context of shape matching",
    ", however , the hausdorff distance often turns out to be unsatisfactory .",
    "there are well known examples where the distance fails to capture the similarity of shapes as perceived by human observers  @xcite .",
    "the problem is that it does not take the continuity of the shapes into account .",
    "figure  [ fig : hausdorff ] shows an example .        in order to address this issue ,",
    "alt and godau introduced the frchet distance into the computational geometry literature  @xcite .",
    "they argue that the frchet distance is better suited as a similarity measure , and they describe an @xmath12 time algorithm to compute it on a real ram or pointer machine .. ] since alt and godau s seminal paper , there has been a wealth of research in various directions , such as extensions to higher dimensions  @xcite , approximation algorithms  @xcite , the geodesic and the homotopic frchet distance  @xcite , and much more  @xcite .",
    "all known approximation algorithms make further assumptions on the curves , and no @xmath13-time approximation algorithm is known for arbitrary polygonal curves .",
    "the frchet distance and its variants , such as dynamic time - warping  @xcite , have found various applications , with recent work particularly focusing on geographic applications such as map - matching tracking data  @xcite and moving objects analysis  @xcite .    despite the large amount of published research ,",
    "the original algorithm by alt and godau has not been improved , and the quadratic barrier on the running time of the associated decision problem remains unbroken . if we can not improve on a quadratic bound for a geometric problem despite many efforts , a possible culprit may be the underlying 3sum - hardness  @xcite .",
    "this situation induced helmut alt to make the following conjecture .",
    "let @xmath14 and @xmath15 be two polygonal curves in the plane .",
    "then it is -hard to decide whether the frchet distance between @xmath14 and @xmath15 is at most @xmath16 .    here",
    ", 1 can be considered as an arbitrary constant , which can be changed to any other bound by scaling the curves .",
    "so far , we know only that this problem takes @xmath17 steps in the algebraic computation tree model  @xcite",
    ".    recently , agarwal  _ et  al . _",
    "@xcite showed how to achieve a subquadratic running time for the _ discrete _ version of the frchet distance .",
    "their approach relies on reusing small parts of the solution .",
    "we follow a similar approach based on the so - called four - russian - trick which precomputes small recurring parts of the solution and uses table - lookup to speed up the whole computation .",
    "the result by agarwal  _ et  al . _",
    "is stated in the word ram model of computation .",
    "they ask whether their result can be generalized to the case of the original ( continuous ) frchet distance .",
    "[ [ our - contribution ] ] our contribution + + + + + + + + + + + + + + + +    we address the question by agarwal  _ et  al .",
    "_  and show how to extend their approach to the frchet distance between two polygonal curves .",
    "our algorithm requires total expected time @xmath18 .",
    "this is the first algorithm to achieve a running time of @xmath13 and constitutes the first improvement for the general case since the original paper by alt and godau  @xcite .",
    "we emphasize that our algorithm runs on a real ram / pointer machine and does not require any bit manipulation tricks to achieve the speedup .",
    "if we relax the model to allow constant time table - lookups , the running time can be improved to be almost quadratic , up to @xmath19 factors . as in agarwal",
    "_ et  al .",
    "_ , our results are achieved by first giving a faster algorithm for the decision version , and then performing an appropriate search over the critical values to solve the optimization problem .",
    "in addition , we show that _ non - uniformly _ , the frchet distance can be computed in subquadratic time .",
    "more precisely , we prove that the decision version of the problem can be solved by an algebraic decision tree  @xcite of depth @xmath4 , for some fixed @xmath5 .",
    "this makes it unlikely that the frchet distance is 3sum - hard , since it is conjectured that no such decision tree exists for 3sum  @xcite .",
    "however , it is not clear how to implement this decision tree in subquadratic time , which hints at a discrepancy between the decision tree and the uniform complexity of the frchet problem .",
    "this puts it into the illustrious company of such notorious problems as sorting @xmath20  @xcite , min - plus - convolution  @xcite , or finding the delaunay triangulation for a point set that has been sorted in two orthogonal directions  @xcite .",
    "we find that this aspect of the frchet distance is highly intriguing and deserves further study .",
    "let @xmath14 and @xmath15 be two polygonal curves in the plane , defined by their vertices @xmath21 and @xmath22 . depending on the context , we interpret @xmath14 and @xmath15 either as sequences of @xmath1 edges , or as continuous functions @xmath23\\rightarrow { { \\mathbb r}}^2 $ ] . in the latter case , we have @xmath24 for @xmath25 and @xmath26 $ ] , and similarly for @xmath15 .",
    "let @xmath27 be the set of all continuous and nondecreasing functions @xmath28 \\rightarrow [ 0,n]$ ] with @xmath29 and @xmath30 .",
    "the _ frchet distance _ between @xmath14 and @xmath15 is defined as @xmath31 } \\| p(x ) - q(\\sigma(x ) ) \\|,\\ ] ] where @xmath11 denotes the euclidean distance .",
    "[ [ the - free - space - diagram ] ] the free - space diagram + + + + + + + + + + + + + + + + + + + + + +    the classic approach to compute @xmath32 uses the _ free - space diagram _ @xmath33 .",
    "it is defined as @xmath34 ^ 2 \\mid \\|p(x ) - q(y ) \\|",
    "\\leq 1\\}.\\ ] ] in other words , @xmath33 is the subset of the joint parameter space for @xmath14 and @xmath15 where the corresponding points on the curves have distance at most @xmath16 , see figure  [ fig : freespace ] .     and @xmath15 and their associated free - space diagram .",
    "for example , the white area in @xmath35 , denoted @xmath36 , corresponds to all points on the third edge of @xmath14 and the second edge of @xmath15 that have distance at most @xmath16 .",
    "the region @xmath37 is shown in blue . since @xmath38 is reachable from @xmath39 , we have @xmath40 . ]",
    "the structure of @xmath33 is easy to describe .",
    "let @xmath41 ^ 2 $ ] be the ground set .",
    "we subdivide @xmath42 into @xmath43 _ cells _",
    "@xmath44 \\times [ j , j+1]$ ] , for @xmath45 .",
    "the cell @xmath46 corresponds to the edge pair @xmath47 and @xmath48 , where @xmath47 is the @xmath49^th^ edge of @xmath14 and @xmath48 is the @xmath50^th^ edge of @xmath15 .",
    "then the set @xmath51 represents all pairs of points on @xmath52 with distance at most @xmath16 .",
    "elementary geometry shows that @xmath53 is the intersection of @xmath46 with an ellipse  @xcite . in particular , the set @xmath53 is convex , and the intersection of @xmath33 with the boundary of @xmath46 consists of four ( possibly empty ) intervals , one on each side of @xmath54 .",
    "we call these intervals the _ doors _ of @xmath46 in @xmath33 .",
    "a door is said to be _ closed _ if the interval is empty , and _",
    "open _ otherwise .",
    "a path @xmath55 in @xmath33 is _ bimonotone _ if it is both @xmath56- and @xmath57-monotone , i.e. , every vertical and every horizontal line intersects @xmath55 in at most one connected component . alt and godau observed that it suffices to determine whether there exists a bimonotone path from @xmath39 to @xmath58 inside @xmath33 .",
    "more precisely , define @xmath59 then @xmath40 if and only if @xmath60 .",
    "it is not necessary to compute all of @xmath37 : since @xmath33 is convex inside each cell , we actually need just the intersections @xmath61 .",
    "the sets defined by @xmath61 are subintervals of the doors of the free - space diagram , and they are defined by endpoints of doors in the free - space diagram in the same row or column .",
    "we call the intersection of a door with @xmath37 a _ reach - door_. the intersections can be found in @xmath62 time through a simple traversal of the cells  @xcite . in the next sections ,",
    "we show how to obtain the crucial information , namely whether @xmath60 , in @xmath63 instead .",
    "[ [ basic - approach - and - intuition ] ] basic approach and intuition + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in our algorithm for the decision problem , we basically want to compute @xmath37 . but instead of propagating the reachability information cell by cell , we always group @xmath64 by @xmath64 cells ( with @xmath65 ) into an _ elementary box _ of cells .",
    "when processing a box , we can assume that we know which parts of the left and the bottom boundary of the box are reachable .",
    "that is , we know the reach - doors on the bottom and left boundary , and we need to compute the reach - doors on the top and right boundary of the elementary box .",
    "the reach - doors on the top and right are determined by the combinatorial structure of the box .",
    "more specifically , if we know for every row and column the order of the door endpoints ( including the reach - doors on the left and bottom boundary ) , we know which door boundaries determine the reach - doors on the top and right boundary .",
    "we will call the sequence of these orders , the _ ( full ) signature _ of the box .",
    "the total number of possible signatures is bounded by an expression in @xmath64 .",
    "thus , if we pick @xmath64 sufficiently small compared to @xmath1 , we can pre - compute for all possible signatures the reach - doors on the top and right boundary , and build a data structure to query these quickly ( section  [ sec : lookup ] ) . since the reach - doors on the bottom and left boundary are required to make the signature , we initially have only partial signatures . in section  [ sec : preproc2 ] , we describe how to compute these efficiently .",
    "the partial signatures are then used to preprocess the data structure such that we can quickly find the full signature once we know the reach - doors of an elementary box . after building and preprocessing the data structure ,",
    "it is possible to determine @xmath40 efficiently by traversing the free - space diagram elementary box by elementary box , as explained in section  [ sec : procfsd ] .",
    "is shown in white .",
    "the left vertical boundaries @xmath66 and @xmath67 are red , the horizontal boundaries @xmath68 and @xmath69 are orange . ]    before even considering the input , our algorithm builds a lookup table . as mentioned above , the purpose of this table is to speed up the computation of small parts of the free - space diagram .",
    "let @xmath70 be a parameter .. ] the _ elementary box _ is a subdivision of @xmath71 ^ 2 $ ] into @xmath64 columns and rows , thus @xmath72 cells . for @xmath73",
    ", we denote the cell @xmath74 \\times [ j , j+1]$ ] with @xmath75 .",
    "we denote the left side of the boundary @xmath76 by @xmath77 and the bottom side by @xmath78 .",
    "note that @xmath77 coincides with the right side of @xmath79 and that @xmath78 coincides with the top of @xmath80 .",
    "thus , we write @xmath81 for the _",
    "right _ side of @xmath82 and @xmath83 for the _ top _ side of @xmath84 .",
    "figure  [ fig : elemgrid ] shows the elementary box .",
    "the _ door - order _",
    "@xmath85 for a row @xmath86 is a permutation of @xmath87 , thus having @xmath88 elements . for @xmath89 ,",
    "the element @xmath90 represents the lower endpoint of the door on @xmath77 , and @xmath91 represents the upper endpoint .",
    "the elements @xmath92 and @xmath93 are an exception : they describe the reach - door on the left boundary @xmath94 ( that is , its intersection with @xmath37 ) .",
    "the door - order @xmath85 represents the combinatorial order of these endpoints , as projected onto a vertical line ( see figure  [ fig : signature ] ) .",
    "note that some door - orders may encode the same combinatorial structure .",
    "in particular when door @xmath95 is closed , the exact position of @xmath90 and @xmath91 in a door - order is irrelevant , up to @xmath91 being before @xmath90 . for a closed door @xmath95 ( @xmath96 ) , we assign @xmath90 to the upper endpoint of @xmath77 and @xmath91 to the lower endpoint .",
    "the values of @xmath92 and @xmath93 are defined by the reach - door and their relative order is thus a result of computation .",
    "we break ties between @xmath90 and @xmath97 by placing @xmath90 before @xmath97 , and any other ties are resolved by index .",
    "a door - order @xmath98 is defined analogously for a column @xmath95 .",
    "we write @xmath99 if @xmath56 comes before @xmath57 in @xmath98 , and @xmath100 if @xmath56 comes before @xmath57 in @xmath85 .",
    "partial door - order _ is a door - order in which @xmath92 and @xmath93 are omitted ( i.e. the intersection of @xmath37 with the door is still unknown ) .    .",
    "note that @xmath92 and @xmath93 represent the reach - door , which is empty in this case .",
    "these are omitted in the partial door - order . ]",
    "we define the _",
    "( full ) signature _ of the elementary box as the aggregation of the door - orders of its rows and columns .",
    "hence , a signature @xmath101 consists of @xmath102 door - orders : one door - order @xmath98 for each column @xmath95 and one door - order @xmath85 for each row @xmath86 of the elementary box .",
    "similarly , a _ partial signature _ is the aggregation of partial door - orders .",
    "for a given signature , we define the _ combinatorial reachability structure _ of the elementary box as follows . for each column @xmath95 and for each row",
    "@xmath86 , the combinatorial reachability structure indicates which door boundaries in the respective column or row define the reach - door of @xmath103 or @xmath104 .",
    "let @xmath105 be a signature for the elementary box",
    ". then we can determine the combinatorial reachability structure of @xmath105 in total time @xmath106 .",
    "we use dynamic programming , very similar to the algorithm by alt and godau  @xcite . for each vertical edge",
    "@xmath77 we define a variable @xmath107 , and for each horizontal edge @xmath78 we define a variable @xmath108 .",
    "the @xmath107 are pairs of the form @xmath109 , representing the reach - door @xmath110 .",
    "if this reach - door is closed , then @xmath111 holds .",
    "if the reach - door is open , then it is bounded by the lower endpoint of the door on @xmath112 and by the upper endpoint of the door on @xmath113 .",
    "( note that in this case we have @xmath114 . )",
    "once again @xmath92 and @xmath93 are special and represent the reach - door on @xmath115 .",
    "the variables @xmath108 are defined analogously .",
    "now we can compute @xmath107 and @xmath108 recursively as follows : first , we set @xmath116 next , we describe how to find @xmath107 given @xmath117 and @xmath118 , see figure  [ fig : recursion ] .    .",
    "if the lower boundary is reachable , we can reach the whole right door ( left ) .",
    "if neither the lower nor the left boundary is reachable , the right door is not reachable either ( middle ) . otherwise , the lower boundary is the maximum of @xmath119 and the lower boundary of the right door ( right ) . ]",
    "* case 1 : * suppose @xmath118 is open .",
    "this means that @xmath120 intersects @xmath37 , so @xmath110 is limited only by the door on @xmath77 , and we can set @xmath121 .    * case 2 : * if both @xmath118 and @xmath117 are closed , it is impossible to reach @xmath77 and thus we set @xmath122 .",
    "* case 3 : * if @xmath118 is closed and @xmath117 is open , we may be able to reach @xmath77 via @xmath123 .",
    "let @xmath124 be the lower endpoint of @xmath117 .",
    "we need to pass @xmath77 above @xmath124 and @xmath90 and below @xmath91 , and therefore set @xmath125 , where the maximum is taken according to the order @xmath126 .",
    "the recursion for the variable @xmath108 is defined similarly .",
    "now it is easy to see that we can implement the recursion in time @xmath106 for any given signature , for example by traversing the elementary box column by column , while processing each column from bottom to top .    clearly , there are at most @xmath127 distinct signatures for the elementary box .",
    "we will choose @xmath128 for a sufficiently small constant @xmath129 , so that this number becomes @xmath130 .",
    "thus , during the preprocessing stage we have time to enumerate all possible signatures and determine the corresponding combinatorial reachability structure inside the elementary box .",
    "this information is then stored in an appropriate data structure .      before we can describe this data structure",
    ", we must first explain how the door - orders are represented .",
    "this depends on the computational model .",
    "note that by our choice of @xmath64 , there are @xmath130 distinct door - orders . on the word ram",
    ", we can represent each door - order and partial door - order by an integer between @xmath16 and @xmath131 .",
    "this certainly fits into a word of @xmath132 bits . on the pointer machine",
    ", we create a record for each door - order and each partial door - order .",
    "then , we can represent an order by a pointer to the corresponding record .",
    "we now explain how we organize the data structure .",
    "it consists of two _ stages _ , as schematized in figure  [ fig : datastructure ] . in the first stage",
    "( figure  [ fig : datastructure ] a - b ) , we assume we know the partial door - order for each row and for each column of the elementary box , and we wish to determine the partial signature . in the second stage ( figure  [ fig : datastructure ] c - d ) , we have obtained the reach - doors for the left and bottom sides of the elementary box , and we are looking for the full signature .",
    "the details of our method depend on the computational model .",
    "one way uses table lookup and requires the word ram , the other way works on the pointer machine , but is a bit more involved .",
    "[ [ word - ram ] ] word ram + + + + + + + +    we organize the lookup table as a large tree @xmath133 . in the first stage , each level of @xmath133 corresponds to a row or column of the elementary box .",
    "thus , there are @xmath102 levels .",
    "each node has @xmath131 children , representing the possible partial door - orders for the next row or column . since we represent door - orders by positive integers , each node of @xmath133 may store an array for its children , and we can choose the appropriate child for a given partial door - order in constant time .",
    "thus , to determine the partial signature for an elementary box requires @xmath134 steps on a word ram .    for the second stage , we again use a tree structure .",
    "now , however , the tree has @xmath134 _ layers _ , each with @xmath135 levels .",
    "again , each layer corresponds to a row or column of the elementary box .",
    "the levels inside each layer then implement a balanced binary search tree that allows us to locate the endpoints of the reach - door within the partial signature .",
    "since there are @xmath102 endpoints , this requires @xmath135 levels .",
    "thus , it takes @xmath136 time to find the full signature of a given elementary box .",
    "[ [ pointer - machine ] ] pointer machine + + + + + + + + + + + + + + +    now we are not allowed to store a lookup table on every level of the tree @xmath133 , and there is no way to quickly find the appropriate child for a given door - order .",
    "instead , we must rely on batch processing to achieve a reasonable running time .",
    "thus , suppose that during the first stage we want to find the partial signatures for a set @xmath9 of @xmath137 elementary boxes , where again for each box in @xmath9 we know the partial door - order for each row and each column . recall that we represent the door - order by a pointer to the corresponding record . with each such record , we store a queue of elementary boxes that is empty initially .",
    "we simultaneously propagate the boxes in @xmath9 through @xmath133 , proceeding level by level . in the first level ,",
    "all of @xmath9 is assigned to the root of @xmath133 .",
    "then , we go through the nodes of one level of @xmath133 , from left to right . let @xmath138 be the current node of @xmath133 .",
    "we consider each elementary box @xmath139 assigned to @xmath138 .",
    "we determine the next partial door - order for @xmath139 , and we append @xmath139 to the queue for this partial door - order  the queue is addressed through the corresponding record , so all elementary boxes with the same next partial door - order end up in the same queue .",
    "next , we go through the nodes of the next level , again from left to right .",
    "let @xmath140 be the current node .",
    "the node @xmath140 corresponds to a next partial door - order @xmath141 that extends the known signature of its parents .",
    "we consider the queue stored at the record for @xmath141 . by construction , the elementary boxes that should be assigned to @xmath140",
    "appear consecutively at the beginning of this queue .",
    "we remove these boxes from the queue and assign them to @xmath140 . after this , all the queues are empty , and we can continue by propagating the boxes to the next level . during this procedure , we traverse each node of @xmath133 a constant number of times , and in each level of the @xmath133 we consider all the boxes in @xmath9 . since @xmath133 has @xmath130 nodes , the total running time is @xmath142 .    for the second stage ,",
    "the data structure works just as in the word ram case , because no table lookup is necessary .",
    "again , we need @xmath136 steps to process one box .",
    "after the second stage we obtain the combinatorial reachability structure of the box in constant time since we precomputed this information for each box .",
    "thus , we have shown the following lemma , independently of the computational model .",
    "[ lem : data - struct ] for @xmath128 with a sufficiently small constant @xmath129 , we can construct in @xmath130 time a data structure of size @xmath130 such that    * given a set of @xmath137 elementary boxes where the partial door - orders are known , we can find the partial signature of each box in total time @xmath143 ; * given the partial signature and the reach - doors on the bottom and left boundary of an elementary box , we can find the full signature in @xmath136 time ; * given the full signature of an elementary box , we can find the combinatorial reachability structure of the box in constant time .",
    "next , we perform a second preprocessing phase that actually considers the input curves @xmath14 and @xmath15 . our eventual goal is to compute the intersection of @xmath37 with the cell boundaries , while taking advantage of the data structure from section  [ sec : lookup ] . for this , we aggregate the cells of @xmath33 into ( concrete ) elementary boxes consisting of @xmath144 cells .",
    "there are @xmath145 such boxes .",
    "note that we can avoid rounding issues by either duplicating vertices or handling a small part of @xmath33 without lookup tables .",
    "elementary boxes of size @xmath144 .",
    "a strip is a column of elementary boxes , and it corresponds to a subcurve of @xmath14 with @xmath64 edges . ]    the goal is to determine the signature for each elementary box @xmath7 .",
    "however , at this point this is not quite possible yet , because the full signature of @xmath7 depends on the intersection of @xmath37 with the lower and left boundary of @xmath7 .",
    "nonetheless , we can find the partial signature , in which the positions of @xmath146 ( the reach - door ) in the ( partial ) door - orders @xmath147 , @xmath148 are still to be determined .",
    "we aggregate the columns of @xmath33 into vertical _ strips _ , each corresponding to a single column of elementary boxes ( that is , @xmath64 consecutive columns of cells in @xmath33 ) .",
    "see figure  [ fig : fsdstrips ] .",
    "let @xmath8 be such a strip .",
    "it corresponds to a subcurve @xmath149 of @xmath14 with @xmath64 edges .",
    "the following lemma implies that we can build a data structure for @xmath8 such that , given any segment of @xmath15 , we can efficiently find its partial door - order within the elementary box in @xmath8 .    [ lem : preprocess_input ] there exists a constant @xmath150 , such that the following holds : given a subcurve @xmath149 with @xmath64 edges , we can compute in @xmath151 time a data structure that requires @xmath151 space and that allows us to determine the partial door - order of any line segment on @xmath15 in time @xmath135 .",
    "consider the arrangement @xmath152 of unit circles whose centers are the vertices of @xmath149 ( see figure  [ fig : arranagement ] ) .",
    "the partial door - order of a line segment @xmath153 is determined by the intersections of @xmath153 with the arcs of @xmath152 ( and for a circle not intersecting @xmath153 by whether @xmath153 lies inside or outside of the circle ) .",
    "let @xmath154 be the line spanned by line segment @xmath153 .",
    "let @xmath155 be the line parallel to @xmath154 that lies above @xmath154 and has distance @xmath16 from @xmath154 .",
    "let @xmath156 be defined similarly , but below @xmath154 .",
    "suppose we wiggle @xmath154 ( and the corresponding @xmath155 , @xmath156 ) .",
    "then the order of intersections of @xmath157 and the arcs of @xmath152 changes only when @xmath154 moves over a vertex of @xmath152 or if @xmath154 leaves or enters a circle .",
    "the latter case corresponds to @xmath155 or @xmath156 moving over the center of a circle .    ,",
    "defined by unit circles centered at vertices of @xmath149 , we can determine the partial door - order of each segment @xmath153 on @xmath15 .",
    "this is done by locating the dual points of @xmath158 , @xmath159 , and @xmath160 in the dual arrangement @xmath161 . to make this process efficient , the dual arrangement is split into so - called slabs . ]",
    "let @xmath162 be the set of all vertices of @xmath152 , and let @xmath163 be the union of @xmath162 with the vertices of @xmath149 .",
    "we compute the arrangement @xmath161 of the lines dual to @xmath163 .",
    "the arrangement @xmath161 has @xmath164 vertices .",
    "we build a point location structure for @xmath161 that is very similar to the structure by dobkin and lipton  @xcite . for this , we subdivide @xmath161 into strips by drawing a vertical line through each vertex of @xmath161 .",
    "call the resulting _ slab subdivision _ @xmath165 .",
    "there are @xmath164 slabs , and each slab has @xmath106 cells .",
    "now , consider the triple @xmath166 of cells in @xmath165 that contain the dual points @xmath167 , @xmath168 , and @xmath169 .",
    "the cells in @xmath166 lie in the same slab , and they completely determine the combinatorial structure of the intersection between @xmath154 and @xmath152 .",
    "thus , for every possible triple @xmath166 of cells in a strip of @xmath165 , we construct a list @xmath170 that represents the combinatorial structure of @xmath171 .",
    "there are @xmath172 such lists , each having size @xmath134 .",
    "we can compute @xmath170 by traversing the zone of @xmath154 in @xmath152 .",
    "since circles intersect at most twice and also a line intersects any circle at most twice , the zone has complexity @xmath173 , where @xmath174 denotes the inverse ackermann function  ( * ? ? ?",
    "* theorem 5.11 ) . since @xmath175",
    ", we can compute all lists in @xmath176 time .",
    "given the list @xmath170 , the partial door - order of @xmath153 is determined by the position of the endpoints of @xmath153 in @xmath170 .",
    "there are @xmath106 possible ways for this , and we build a table @xmath177 that represents them . for each entry in @xmath177 , we store a representative for the corresponding partial door - order . as described in the previous section , the representative is a positive integer in the word ram model and a pointer to the appropriate record on a pointer machine .    the total size of the data structure is @xmath176 and it can be constructed in the same time .",
    "a query works as follows : given @xmath153 , we can compute @xmath178 , @xmath168 and @xmath169 in constant time .",
    "our data structure contains a balanced binary search tree for the point location .",
    "the tree is layered : the first layer helps us find the vertical slab containing the dual points , the next three layers allow us to determine @xmath166 , and the last two layers determine the position of the endpoints of @xmath153 in the list @xmath170 . in total , there are a constant number of layers of depth @xmath135 , so we can find a representative for the door - order for @xmath153 in @xmath135 time .",
    "this bound holds both on the word ram and on the pointer machine .",
    "we can now prove the following lemma , independent of the computational model .",
    "[ lem : partial ] given the data structure of lemma  [ lem : data - struct ] , the partial signature for each elementary box can be determined in time @xmath179 for some constant @xmath150 .    by building and using the data structure from lemma  [ lem : preprocess_input ]",
    ", we can determine the partial door - order for each row in each vertical @xmath64-strip in total time proportional to @xmath180    we repeat the procedure with the horizontal strips .",
    "now we know for each elementary box in @xmath33 the partial door - order for each row and each column .",
    "we can then use the data structure of lemma  [ lem : data - struct ] to put these together .",
    "since there are @xmath181 boxes , the number of steps is @xmath182 .",
    "hence , the partial signature for each elementary box can be computed in @xmath179 .",
    "with the data structures and preprocessing from the previous sections , we have all elements in place to determine whether @xmath40 . we know for each elementary box its partial signature and we have a data structure to derive its full signature ( and with it , the combinatorial reachability structure ) when its reach - doors are known .",
    "what remains to be shown is that we can efficiently process the free - space diagram to determine whether @xmath60 .",
    "this is captured in the following lemma .",
    "[ lem : procfsd ] if the partial signature for each elementary box is known , we can determine whether @xmath60 in time @xmath183 .",
    "we go through all of the elementary boxes of @xmath33 , processing them one column at a time , going from bottom to top in each column .",
    "initially , we know the full signature for the box @xmath7 in the lower left corner of @xmath33 .",
    "we use the signature to determine the intersections of @xmath37 with the upper and right boundary of @xmath7 .",
    "there is a subtlety here : the signature gives us only the combinatorial reachability structure , and we need to map the resulting @xmath184 back to the corresponding vertices on the curves . on the word ram ,",
    "this can be done easily through table lookups . on the pointer machine ,",
    "we use representative records for the @xmath185 elements and use @xmath134 time before processing the box to store a pointer from each representative record to the appropriate vertices on @xmath14 and @xmath15 .",
    "we proceed similarly for the other boxes . by the choice of the processing order of the elementary boxes we always know the incoming reach - doors on the bottom and left boundary when processing a box .",
    "given the incoming reach - doors , we can determine the full signature and find the structure of the outgoing reach - doors in total time @xmath136 , using lemma  [ lem : data - struct ] .",
    "again , we need @xmath134 additional time on the pointer machine to establish the mapping from the abstract @xmath90 , @xmath91 elements to the concrete vertices of @xmath14 and @xmath15 . in total",
    ", we spend @xmath136 time per box .",
    "thus , it takes time @xmath183 to process all boxes , as claimed .    as a result",
    ", we obtain the following theorem for a pointer machine ( and by extension , for the real ram model ) . for the word ram model",
    ", we can obtain an even faster algorithm , as described in the next section .",
    "the decision version of the frchet problem can be solved in time @xmath186 on a pointer machine .    set @xmath187 for a sufficiently small constant @xmath129 .",
    "the theorem follows by applying lemmas  [ lem : data - struct ] ,  [ lem : partial ] and  [ lem : procfsd ] in sequence .",
    "we now explain how the running time of our algorithm can be improved if our computational model allows for constant time table - lookup .",
    "we use the same @xmath64 as above ( up to a constant factor ) .",
    "however , we change a number of things .",
    "`` signatures '' are represented differently and the data structure to obtain combinatorial reachability structures is changed accordingly .",
    "furthermore , we aggregate elementary boxes into clusters and determine `` partial door - orders '' for multiple boxes at the same time .",
    "finally , we walk the free - space diagram based on the clusters to decide @xmath40 .    [ [ clusters - and - extended - signatures ] ] clusters and extended signatures + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we introduce a second level of aggregation in the free - space diagram ( see figure  [ fig : cluster ] ) : a _ cluster _ is a collection of @xmath144 elementary boxes , that is , @xmath188 cells in @xmath33 . let @xmath42 be a row of cells in @xmath33 of a certain cluster . as before , the row @xmath42 corresponds to an edge @xmath189 on @xmath15 and a subcurve @xmath149 of @xmath14 with @xmath72 edges .",
    "we associate with @xmath42 an ordered set @xmath190 with @xmath191 elements . here",
    "@xmath192 is the number of intersections of @xmath189 with the unit circles centered at the @xmath64 vertices of @xmath149 ( all but the very first ) .",
    "hence , @xmath192 is bounded by @xmath193 and @xmath194 is bounded by @xmath195 .",
    "the order of @xmath196 indicates the order of these intersections with @xmath189 directed along @xmath15 .",
    "the elements @xmath197 and @xmath198 represent the endpoints of @xmath189 and take a special role .",
    "in particular , these elements are used to represent closed doors and snap open doors to the edge @xmath189 .",
    "the elements @xmath199 are placeholders for the positions of the endpoints of the reach - doors : @xmath200 represents a possible reach - door endpoint between @xmath197 and @xmath201 , the element @xmath202 is an endpoint between @xmath201 and @xmath203 , etc .     elementary boxes , thus of @xmath188 cells . a row @xmath42 and its corresponding @xmath204 for the central elementary box are indicated . ]",
    "consider a row @xmath204 of an elementary box inside the row @xmath42 of a cluster , corresponding to an edge @xmath189 of @xmath15 .",
    "the _ door - index _ of @xmath204 is an ordered set @xmath205 of size @xmath206 .",
    "similar to a door - order , elements @xmath92 and @xmath93 represent the reach - door at the leftmost boundary of @xmath204 ; the elements @xmath90 and @xmath91 ( @xmath207 ) represent the door at the right boundary of the @xmath95^th^ cell in @xmath204 .",
    "however , instead of rearranging the set to indicate relative positions , the elements @xmath90 and @xmath91 simply refer to an element in @xmath196 .",
    "if the door is open , then they refer to the intersections with @xmath189 ( possibly snapped to @xmath197 or @xmath198 ) .",
    "if the door is closed , then @xmath90 is set to @xmath198 and @xmath91 is set to @xmath197 .",
    "again , the elements @xmath92 and @xmath93 are special , representing the reach - door and thus refer to one of the elements @xmath199 . a _ partial door - index _ is a door - index without @xmath92 and @xmath93 .",
    "the advantage of a door - index over a door - order is that the reach - door is always at the start .",
    "hence , completing a partial door - index to a full door - index can be done in constant time .",
    "since a door - index has size @xmath206 , the number of possible door - indices for @xmath204 is @xmath208 .",
    "we define the door - indices for the columns analogously , and we concatenate the door - indices for the rows and the columns to obtain the _",
    "indexed signature _ for an elementary box .",
    "similarly , we define the _ partial indexed signature_. the total number of possible indexed signatures remains @xmath209 .    for each possible partial indexed signature @xmath105",
    "we build a lookup table @xmath210 as follows : the input is a word with @xmath211 fields of @xmath135 bits each .",
    "each field stores the positions in @xmath196 of the endpoints of the ingoing reach - doors for the elementary box : @xmath102 fields for the left side , @xmath102 fields for the lower side .",
    "the output consists of a word that represents the indices for the elements in @xmath196 that represent the outgoing reach - doors for the upper and right boundary of the box .",
    "thus , the input of @xmath210 is a word of @xmath136 bits , and @xmath210 has size @xmath208 .",
    "hence , for all partial indexed signatures combined , the size is @xmath212 by our choice of @xmath64 .    [",
    "[ preprocessing - a - given - input ] ] preprocessing a given input + + + + + + + + + + + + + + + + + + + + + + + + + + +    during the preprocessing for a given input @xmath213 , we use _ superstrips _ consisting of @xmath64 strips .",
    "that is , a superstrip is a column of clusters and consists of @xmath72 columns of the free - space diagram .",
    "lemma  [ lem : preprocess_input ] still holds , albeit with a larger constant @xmath150 .",
    "the data structure gets as input a query edge @xmath189 , and it returns in @xmath135 time a word that contains @xmath64 fields .",
    "each field represents the partial door - index for @xmath189 in the corresponding elementary box and thus consists of @xmath136 bits .",
    "hence , the word size is @xmath214 by our choice of @xmath64 . thus",
    ", the total time for building a data structure for each superstrip and for processing all rows is @xmath215 .",
    "we now have parts of the partial indexed signature for each elementary box packed into different words . to obtain the partial indexed signature ,",
    "we need to rearrange the information such that the partial door - indices of the rows in one elementary box are in a single word .",
    "this corresponds to computing a transposition of a matrix , as is illustrated in figure  [ fig : transposition ] . for this , we need the following lemma , which can be found  in slightly different form  in thorup  ( * ? ? ?",
    "* lemma  9 ) .",
    "let @xmath216 be a sequence of @xmath64 words that contain @xmath64 fields each , so that @xmath216 can be interpreted as a @xmath144 matrix .",
    "then we can compute in time @xmath136 on a word ram a sequence @xmath217 of @xmath64 words with @xmath64 fields each that represents the _ transposition _ of @xmath216 .",
    "the algorithm is recursive and solves a more general problem : let @xmath216 be a sequence of @xmath218 words that represents a sequence @xmath219 of @xmath139 different @xmath220 matrices , such that the @xmath95^th^ word in @xmath216 contains the fields of the @xmath95^th^ row of each matrix in @xmath219 from left to right . compute a sequence of words @xmath217 that represents the sequence @xmath221 of the transposed matrices in @xmath219 .",
    "the recursion works as follows : if @xmath222 , there is nothing to be done .",
    "otherwise , we split @xmath216 into the sequence @xmath223 of the first @xmath224 words and the sequence @xmath225 of the remaining words .",
    "@xmath223 and @xmath225 now represent a sequence of @xmath226 @xmath227 matrices , which we transpose recursively .",
    "after the recursion , we put the @xmath227 submatrices back together in the obvious way .",
    "to finish , we need to transpose the off - diagonal submatrices .",
    "this can be done simultaneously for all matrices in time @xmath228 , by using appropriate bit - operations ( or table lookup ) .",
    "hence , the running time obeys a recursion of the form @xmath229 , giving @xmath230 , as desired .    by applying the lemma to the words that represent @xmath64 consecutive rows in a superstrip",
    ", we obtain the partial door - indices of the rows for each elementary box .",
    "this takes total time @xmath231 .",
    "we repeat this procedure for the horizontal superstrips . by using an appropriate lookup table to combine the partial door - indices of the rows and columns , we obtain the partial indexed signature for each elementary box in total time @xmath232 .    [",
    "[ the - actual - computation ] ] the actual computation + + + + + + + + + + + + + + + + + + + + + +    we traverse the free - space diagram cluster by cluster ( recall that a cluster consists of @xmath144 elementary boxes ) .",
    "the clusters are processed column by column from left to right , and inside each column from bottom to top . before processing a cluster ,",
    "we walk along the left and lower boundary of the cluster to determine the incoming reach - doors .",
    "this is done by performing a binary search for each box on the boundary , and determining the appropriate elements @xmath199 which correspond to the incoming reach - doors .",
    "using this information , we assemble the appropriate words that represent the incoming information for each elementary box .",
    "since there are @xmath233 clusters , this step requires time @xmath234 .",
    "we then process the elementary boxes inside the cluster , in a similar fashion .",
    "now , however , we can process each elementary box in constant time through a single table lookup , so the total time is @xmath235 .",
    "hence , the total running time of our algorithm is @xmath232 . by our choice of @xmath236 for a sufficiently small @xmath129 ,",
    "we obtain the following theorem .    the decision version of the frchet problem can be solved in time @xmath237 on a word ram machine .",
    "the optimization version of the frchet problem , that is , computing the frchet distance , can be done in @xmath0 time using parametric search with the decision version as a subroutine  @xcite .",
    "we showed that the decision problem can be solved in @xmath63 time .",
    "this however does not directly yield a faster algorithm for the optimization problem : if the running time of the decision problem is @xmath238 steps , parametric search results in an @xmath239 time algorithm  @xcite .",
    "there is an alternative randomized algorithm by raichel and har - peled  @xcite , which however also runs in @xmath239 time .",
    "we adapt this algorithm to speed up the optimization problem .    before we do so",
    ", we recall that possible values of the frchet distance are limited to a certain set of _ critical values _",
    "@xcite :    1 .   the distance between a vertex of the one curve and a vertex of the other curve ( * vertex - vertex * ) , 2 .",
    "the distance between a vertex of the one curve and an edge of the other curve ( * vertex - edge * ) , 3 .   for two vertices of one curve and an edge of the other curve , the distance between one of the vertices and the intersection of @xmath189 with the bisector of the two vertices ( if this intersection exists ) ( * vertex - vertex - edge * ) .",
    "if we also include vertex - vertex - edge tuples with no intersection , we can sample a critical value uniformly at random in constant time .",
    "the algorithm now works as follows ( see har - peled and raichel  @xcite for more details ) : it first samples @xmath240 critical values uniformly at random .",
    "next the algorithm finds the interval @xmath241 $ ] with @xmath218 and @xmath139 being two critical values in the sample such that the frchet distance lies in @xmath242 $ ] , and no other critical value of the sample lies in @xmath241 $ ] . in the original algorithm this is done by sorting the critical values and performing a binary search using the decision version . by using median - finding instead",
    ", this step can be done in @xmath243 time .",
    "we note that , alternatively , the running time of this step could be reduced by picking a smaller @xmath244 .",
    "however , this does not improve the final bound , since it is dominated by a @xmath245 component .",
    "this atomic interval @xmath242 $ ] of the sampled critical values with high probability contains only a small number of the remaining critical values .",
    "more specifically , for @xmath240 the probability that the interval contains more than @xmath246 critical values at most @xmath247  ( * ? ? ?",
    "* lemma 6.2 ) .",
    "the remainder of the algorithm first determines the @xmath248 critical values in the interval @xmath242 $ ] , then again sorts them and performs a binary search . excluding the time to determine the critical values",
    ", this takes @xmath249 time with mean - finding .",
    "thus the crucial part is to determine the @xmath248 critical values fast .    in @xmath62 time we can check for any vertex - vertex and vertex - edge pair whether the corresponding critical value lies in",
    "@xmath242 $ ] .",
    "it remains to determine the critical values corresponding to vertex - vertex - edge tuples .",
    "these critical values are determined by a variant of the standard sweepline algorithm . for",
    "this take an edge @xmath189 of @xmath14 and the vertices of @xmath15 .",
    "the sweep starts with circles of radius @xmath218 around the vertices of @xmath15 and increases the radii until they reach @xmath139 . during this sweep",
    "the algorithm maintains the order in which the circle arcs intersect @xmath189 . a critical value of the vertex - vertex - edge type corresponds to the event that two different circles intersect @xmath189 in the same point . next to these events the sweepline algorithm requires the following events : a circle intersects @xmath189 for the first time , or a circle intersects one of the vertices of @xmath189 .",
    "both of these event types correspond to critical values involving @xmath189 or a vertex of @xmath189 . thus if we perform such a sweep for all edges of @xmath14 ( and similarly for the edges of @xmath15 ) , the total number of events is @xmath250 , thus the overall running time of all sweeps ignoring the time for initialization is @xmath251 .",
    "it remains to show that we can compute the initial order in which the circle arcs intersect @xmath189 fast .",
    "first compute the arrangement @xmath152 of circles with radius @xmath218 around the vertices of @xmath15 .",
    "this can be done in @xmath62 time  @xcite .",
    "we need to determine in which order the arcs of the circles intersect @xmath189 .",
    "we can determine the order of intersections by traversing in @xmath152 the zone of the line @xmath252 spanned by @xmath189 .",
    "the time for the traversal can be bounded by the complexity of the zone .",
    "using that the circles pairwise intersect at most twice and the line intersects each circle also only twice , the complexity of the zone can be bounded by @xmath253  ( * ? ? ?",
    "* theorem 5.11 ) . summing over all edges",
    "@xmath189 this adds a total of @xmath245 to the running time .",
    "thus the overall running time is @xmath254 .",
    "the case that @xmath255 happens with probability less than @xmath256 , and also in this case @xmath248 is still in @xmath257 .",
    "thus , this case adds @xmath258 to the expected running time .",
    "the case @xmath259 adds @xmath260 to the expected running time . as a consequence",
    "we obtain the following lemma .",
    "[ lem : opt ] the frchet distance of two polygonal curves with @xmath1 vertices each can be computed by a randomized algorithm in @xmath261 expected time , where @xmath238 is the running time for the decision problem .",
    "we plug in our new bounds on @xmath238 .",
    "the frchet distance of two polygonal curves with @xmath1 vertices each can be computed by a randomized algorithm in time @xmath2 on a pointer machine and in time @xmath3 on a word ram .",
    "our results also have implications for the decision - tree complexity of the frchet problem .",
    "since in that model we account only for comparisons between the input elements , the preprocessing comes for free , and hence the size of the elementary boxes can be increased .",
    "before we consider the continuous frchet problem , we first note that the techniques of agarwal  _ et  al .",
    "_ can be used to obtain a similar result for the _ discrete _ frchet problem : suppose we have two sequences @xmath262 and @xmath263 . for @xmath264 , we define a directed graph @xmath265 with vertex set @xmath266 . in @xmath265 , there is an edge between two vertices @xmath267 , @xmath268 if and only if both @xmath269 and @xmath270 .",
    "the condition is similar for an edge between vertices @xmath267 and @xmath271 , and vertices @xmath267 and @xmath272 .",
    "there are no further edges in @xmath265 . now",
    "the problem is to find the smallest @xmath273 for which @xmath265 has a path from @xmath274 to @xmath275 .    using the techniques from agarwal  _ et  al .",
    "_ we can obtain the following theorem .",
    "( pronounced `` soft - oh '' ) stands for @xmath276 up to poly - logarithmic factors . ]",
    "there is an algebraic computation tree for the _ discrete _ frchet problem of depth @xmath277 .",
    "we first discuss the decision problem , where we are given @xmath14 , @xmath15 and a @xmath273 , and we need to decide whether we can reach @xmath275 from @xmath274 . for the discrete case ,",
    "the analogue of the reachable free - space is just an @xmath278 boolean matrix @xmath219 , where the bit in the @xmath95^th^ row and the @xmath86^th^ column indicates whether the pair @xmath267 can be reached from @xmath274 in @xmath265 .",
    "we set @xmath279 and subdivide the columns of @xmath219 into strips of width @xmath64 , as above .",
    "each strip corresponds to a subsequence @xmath280 of @xmath64 points @xmath281 , and we compute the arrangement of unit disks with centers in @xmath280 .",
    "this takes @xmath106 time .",
    "then we locate each point of @xmath14 in this arrangement , in total time @xmath282 .",
    "we do this for every strip , resulting in a total running time of @xmath283 , by our choice of @xmath64 . as observed by agarwal",
    "_ et  al .",
    "_ , the information we gain in this way suffices to complete @xmath219 without further comparisons . as shown by agarwal",
    "_ et  al .",
    "_ , one can then solve the optimization problem at the cost of another @xmath284-factor , which is absorbed into the @xmath285-notation .",
    "given our results from above , we can prove an analogous statement for the continuous frchet distance .",
    "there exists an algebraic decision tree for the frchet problem ( decision version ) of depth @xmath286 , for a fixed constant @xmath5 .",
    "we reconsider the steps of our algorithm .",
    "the only phases that actually involve the input are the second preprocessing phase and the traversal of the elementary boxes .",
    "the reason of our choice for @xmath64 was to keep the time for the first preprocessing phase polynomial .",
    "this is no longer a problem . by lemmas  [ lem : partial ] and [ lem : procfsd ] ,",
    "the cost for the remaining algorithm is bounded by @xmath287 , where @xmath150 is the constant from lemma  [ lem : preprocess_input ] .",
    "choosing @xmath288 , we get a decision tree of depth @xmath289 for , say , @xmath290 .    assuming linear time reductions , this has the following consequence for alt s conjecture :",
    "if the decision version of the frchet problem is -hard , then has an algebraic decision tree of depth @xmath4 .    we leave it to the reader to judge the implications on the status of the conjecture",
    "in this paper we have broken the long - standing quadratic upper bound for the decision version of the frchet problem . moreover , we have shown that this problem has an algebraic decision tree of depth @xmath4 , for some @xmath5 and where @xmath1 is the number of vertices of the polygonal curves .",
    "this strongly indicates that the problem is not 3sum hard after all .",
    "we have shown how our faster algorithm for the decision version can be used for a faster algorithm to compute the frchet distance .",
    "if we allow constant - time table - lookup , we obtain a running time in close reach of @xmath62 .",
    "this leaves us with intriguing open research questions .",
    "can we reduce the time needed for the decision version to @xmath4 , the bound we obtain from the algebraic decision tree ?",
    "can we devise a quadratic or even subquadratic algorithm for the optimization version ?",
    "can we devise such an algorithm on the word ram , that is , with constant - time table - lookup ? or , on the other hand , can we establish a connection between the frchet distance and other problems which exhibit a discrepancy between the decision tree and the uniform complexity , such as , e.g. , min - plus - convolution ?",
    "we would like to thank natan rubin for pointing out to us that frchet - related papers require a witty title involving a dog , bettina speckmann for inspiring discussions during the early stages of this research , gnter rote for providing us with his ipelet for the free - space diagram , and otfried cheong for ipe .",
    "10    p.  k. agarwal , r.  b. avraham , h.  kaplan , and m.  sharir .",
    "computing the discrete frchet distance in subquadratic time . to appear in _ proc .",
    "acm - siam sympos .",
    "discrete algorithms ( soda ) _ , 2013 .",
    "` arxiv:1204.5333 ` .",
    "k. agarwal , s.  har - peled , n.  h. mustafa , and y.  wang . near - linear time approximation algorithms for curve simplification .",
    ", 42(34):203219 , 2005 .",
    "n.  ailon and b.  chazelle .",
    "lower bounds for linear degeneracy testing . , 52(2):157171 , 2005 .",
    "h.  alt . the computational geometry of comparing shapes . in _ efficient algorithms _ , volume 5760 of _ lecture notes in computer science _ , pages 235248",
    "springer - verlag , 2009 .",
    "h.  alt and m.  buchin .",
    "can we compute the similarity between surfaces ?",
    ", 43(1):7899 , 2010 .",
    "h.  alt and m.  godau .",
    "computing the frchet distance between two polygonal curves .",
    ", 5(12):7899 , 1995 .",
    "h.  alt , c.  knauer , and c.  wenk . comparison of distance measures for planar curves .",
    ", 38(1):4558 , 2003 .",
    "b.  aronov , s.  har - peled , c.  knauer , y.  wang , and c.  wenk . .",
    "in _ proc .",
    "14th annu .",
    "european sympos .",
    "algorithms ( esa ) _ ,",
    "pages 5263 , 2006 .",
    "s.  arora and b.  barak . .",
    "cambridge university press , cambridge , 2009 .",
    "r.  bellman and r.  kalaba . on adaptive control processes .",
    ", 4(2):19 , 1959 .",
    "s.  brakatsoulas , d.  pfoser , r.  salas , and c.  wenk . .",
    "in _ proc .",
    "31st int . conf . on very large data bases",
    "_ , pages 853864 .",
    "acm , 2005 .",
    "d.  bremner , t.  m. chan , e.  d. demaine , j.  erickson , f.  hurtado , j.  iacono , s.  langerman , and p.  taslakian .",
    "necklaces , convolutions , and @xmath20 . in _ proc .",
    "14th annu .",
    "european sympos .",
    "algorithms ( esa ) _ , pages 160171 .",
    "springer - verlag , 2006 .",
    "k.  buchin , m.  buchin , and j.  gudmundsson . .",
    ", 24(7):11011125 , 2010 .",
    "k.  buchin , m.  buchin , j.  gudmundsson , m.  lffler , and j.  luo . detecting commuting patterns by clustering subtrajectories .",
    ", 21(3):253282 , 2011 .",
    "k.  buchin , m.  buchin , c.  knauer , g.  rote , and c.  wenk .",
    "how difficult is it to walk the dog ? in _ proc .",
    "23rd european workshop comput .",
    "( ewcg ) _ , pages 170173 , 2007 .",
    "k.  buchin , m.  buchin , w.  meulemans , and b.  speckmann .",
    "locally correct frchet matchings . in _ proc .",
    "20th annu .",
    "european sympos .",
    "algorithms ( esa ) _ , volume 7501 of _ lecture notes in computer science _ , pages 229240 , 2012 .",
    "k.  buchin , m.  buchin , and a.  schulz .",
    "rchet distance of surfaces : some simple hard cases . in _ proc .",
    "18th annu .",
    "european sympos .",
    "algorithms ( esa ) _ , pages 6374 , 2010 .",
    "k.  buchin , m.  buchin , and y.  wang . .",
    "in _ proc .",
    "20th annu .",
    "acm - siam sympos .",
    "discrete algorithms ( soda ) _ , pages 645654 , 2009 .",
    "k.  buchin , m.  buchin , and c.  wenk . computing the frchet distance between simple polygons .",
    ", 41(12):220 , 2008 .",
    "k.  buchin and w.  mulzer .",
    "elaunay triangulations in @xmath291 time and more . ,",
    "58(2):art . 6 , 27 , 2011 .",
    "m.  buchin . .",
    "phd thesis , free university berlin , institute of computer science , 2007 .",
    "e.  chambers ,  .",
    "de  verdire , j.  erickson , s.  lazard , f.  lazarus , and s.  thite .",
    "homotopic frchet distance between curves or , walking your dog in the woods in polynomial time .",
    ", 43(3):295311 , 2010 .",
    "b.  m. chazelle and d.  t. lee . on a circle placement problem .",
    ", 36(12):116 , 1986 .    a.  f. cook , a.  driemel , s.  har - peled , j.  sherette , and c.  wenk . computing the frchet distance between folded polygons . in _ proc .",
    "12th international symposium on algorithms and data structures ( wads ) _ , pages 267278 , 2011 .",
    "a.  f. cook and c.  wenk .",
    "geodesic frchet distance inside a simple polygon .",
    ", 7(1):art . 9 , 9 , 2010 .",
    "m.  de  berg , a.  f. cook iv , and j.  gudmundsson .",
    "fast frchet queries . in _ proc .",
    "22nd annu .",
    "algorithms comput .",
    "( isaac ) _ , pages 240249 , 2011 .",
    "d.  dobkin and r.  j. lipton .",
    "multidimensional searching problems .",
    ", 5(2):181186 , 1976 .",
    "a.  driemel and s.  har - peled .",
    "jaywalking your dog : computing the frchet distance with shortcuts . in _ proc .",
    "23rd annu .",
    "acm - siam sympos .",
    "discrete algorithms ( soda ) _ , pages 318337 , 2012 .",
    "a.  driemel , s.  har - peled , and c.  wenk . .",
    "in _ proc .",
    "26th annu .",
    "acm sympos .",
    "( socg ) _ , pages 365374 .",
    "acm , 2010 .",
    "a.  efrat , l.  guibas , s.  har - peled , j.  mitchell , and t.  murali . .",
    ", 28(4):535569 , 2002 .",
    "m.  l. fredman .",
    "how good is the information theory bound in sorting ?",
    ", 1(4):355361 , 1975/76 .",
    "a.  gajentaan and m.  h. overmars . on a class of @xmath292 problems in computational geometry . , 5(3):165185 , 1995 .",
    "m.  godau .",
    "a natural metric for curves - computing the distance for polygonal chains and approximation algorithms . in _ proc .",
    "8th sympos .",
    "aspects comput .",
    "( stacs ) _ , pages 127136 , 1991 .",
    "m.  godau . .",
    "phd thesis , freie universitt berlin , germany , 1998 .",
    "j.  gudmundsson and t.  wolle . .",
    "in _ proc .",
    "10th australasian conf . on mathematics and computers in sport _ , 2010 .",
    "s.  har - peled , a.  nayyeri , m.  salavatipour , and a.  sidiropoulos . how to walk your dog in the mountains with no magic leash . in _ proc",
    "28th annu .",
    "acm sympos .",
    "comput . geom .",
    "( socg ) _ , pages 121130 .",
    "acm , 2012 .",
    "s.  har - peled and b.  raichel . the frchet distance revisited and extended . in _ proc .",
    "27th annu .",
    "acm sympos .",
    "( socg ) _ , pages 448457 .",
    "acm , 2011 .",
    "p.  indyk .",
    "approximate nearest neighbor algorithms for frechet distance via product metrics . in _ proc .",
    "18th annu .",
    ". comput . geom .",
    "( socg ) _ , pages 102106 .",
    "acm , 2002 .",
    "a.  maheshwari , j .-",
    "sack , k.  shahbaz , and h.  zarrabi - zadeh .",
    "frchet distance with speed limits .",
    ", 44(2):110120 , 2011 .",
    "a.  maheshwari , j .-",
    "sack , k.  shahbaz , and h.  zarrabi - zadeh . improved algorithms for partial curve matching . in _ proc .",
    "19th annu .",
    "european sympos .",
    "algorithms ( esa ) _ , pages 518529 , 2011 .",
    "m.  sharir and p.  k. agarwal . .",
    "cambridge university press , 1995 .",
    "m.  thorup .",
    "randomized sorting in @xmath293 time and linear space using addition , shift , and bit - wise boolean operations .",
    ", 42(2):205230 , 2002 .    c.  wenk , r.  salas , and d.  pfoser .",
    ". in _ proc",
    "18th int . conf . on sci . and stat .",
    "database management _ ,",
    "pages 379388 , 2006 .",
    "[ [ real - ram . ] ] real ram .",
    "+ + + + + + + + +    the standard machine model in computational geometry is the _ real ram_. here , data is represented as an infinite sequence of storage cells .",
    "these cells can be of two different types : they can store real numbers or integers .",
    "the model supports standard operations on these numbers in constant time , including addition , multiplication , and elementary functions like square - root , sine or cosine .",
    "furthermore , the integers can be used as indices to memory locations .",
    "integers can be converted to real numbers in constant time , but we need to be careful about the reverse direction . the _ floor _ function can be used to truncate a real number to an integer , but if we were allowed to use it arbitrarily , the real ram could solve pspace - complete problems in polynomial time .",
    "therefore , we usually have only a restricted floor function at our disposal .",
    "the _ word ram _ is essentially a real ram without support for real numbers .",
    "however , on a real ram , the integers are usually treated as atomic , whereas the word ram allows for powerful bit - manipulation tricks .",
    "more precisely , the word ram represents the data as a sequence of @xmath294-bit words , where @xmath295 .",
    "data can be accessed arbitrarily , and standard operations , such as boolean operations ( ` and ` , ` xor ` , ` shl ` , @xmath296 ) , addition , or multiplication take constant time .",
    "there are many variants of the word ram , depending on precisely which instructions are supported in constant time .",
    "the general consensus seems to be that any function in @xmath297 is acceptable .",
    "is the class of all functions @xmath298 that can be computed by a family of circuits @xmath299 with the following properties : ( i ) each @xmath300 has @xmath1 inputs ; ( ii ) there exist constants @xmath301 , such that @xmath300 has at most @xmath302 gates , for @xmath303 ; ( iii ) there is a constant @xmath304 such that for all @xmath1 the length of the longest path from an input to an output in @xmath300 is at most @xmath304 ( ie , the circuit family has bounded depth ) ; ( iv ) each gate has an arbitrary number of incoming edges ( ie , the fan - in is unbounded ) .",
    "] however , it is always preferable to rely on a set of operations as small , and as non - exotic , as possible .",
    "note that multiplication is not in @xmath297 , but nevertheless is usually included in the word ram instruction set .      the _ pointer machine _",
    "model disallows the use of constant time table lookup , and is therefore a restriction of the ( real ) ram model .",
    "the data structure is modeled as a directed graph @xmath305 with bounded out - degree .",
    "each node in @xmath305 represents a _ record _ , with a bounded number of pointers to other records and a bounded number of ( real or integer ) data items .",
    "the algorithm can access data only by following pointers from the inputs ( and a bounded number of global entry records ) ; random access is not possible .",
    "the data can be manipulated through the usual real ram operations , but without support for the floor function , for reasons mentioned above .",
    "_ algebraic computation trees _ ( acts )  @xcite are the computational geometry analogue of binary decision trees , and like these they are mainly used for proving lower bounds .",
    "let @xmath306 be the inputs .",
    "an act is a binary tree with two different kinds of nodes : _ computation nodes _ and _ branch nodes_. a computation node @xmath138 has one child and is labeled with an expression of the type @xmath307 , where @xmath308 is a operation and @xmath309 is either an input variable @xmath310 or corresponds to a computation node that is an ancestor of @xmath138 .",
    "a branch node has degree 2 and is labeled by @xmath311 or @xmath312 , where again @xmath313 is either an input or a variable corresponding to an ancestor .",
    "a family of algebraic computation trees @xmath314 solves a computational problem ( like delaunay triangulation or convex hulls computation ) , if for each @xmath315 , the tree @xmath316 accepts inputs of size @xmath1 , and if for any such input @xmath310 the corresponding path in @xmath316 ( where the children of the branch nodes are determined according the conditions they represent ) constitutes a computation which represents the answer in the variables @xmath317 encountered during the path ."
  ],
  "abstract_text": [
    "<S> given two polygonal curves in the plane , there are many ways to define a notion of similarity between them . </S>",
    "<S> one measure that is extremely popular is the frchet distance . </S>",
    "<S> since it has been proposed by alt and godau in 1992 , many variants and extensions have been studied . </S>",
    "<S> nonetheless , even more than 20 years later , the original @xmath0 algorithm by alt and godau for computing the frchet distance remains the state of the art ( here @xmath1 denotes the number of vertices on each curve ) . </S>",
    "<S> this has led helmut alt to conjecture that the associated decision problem is 3sum - hard .    in recent work , </S>",
    "<S> agarwal _ et  al . </S>",
    "<S> _  </S>",
    "<S> show how to break the quadratic barrier for the _ discrete _ version of the frchet distance , where one considers sequences of points instead of polygonal curves . </S>",
    "<S> building on their work , we give a randomized algorithm to compute the frchet distance between two polygonal curves in time @xmath2 on a pointer machine and in time @xmath3 on a word ram . </S>",
    "<S> furthermore , we show that there exists an algebraic decision tree for the decision problem of depth @xmath4 , for some @xmath5 . </S>",
    "<S> this provides evidence that the decision problem may not be 3sum - hard after all and reveals an intriguing new aspect of this well - studied problem . </S>"
  ]
}