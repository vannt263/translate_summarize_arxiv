{
  "article_text": [
    "at ( -4,-1 ) ( a ) ; at ( 0,-1 ) ( n11 ) _ book _ ; at ( -2.5 , -2 ) ( m111 ) _ author_edge[- ] ( n11 ) ; at ( -2.5,-2.8 ) `` @xmath0 '' edge[-](m111 ) ;    at ( 2.5 , -2.1 ) ( m112 ) _ year_edge[- ] ( n11 ) ; at ( 2.5,-2.8 ) `` @xmath1 '' edge[- ] ( m112 ) ;    at ( 0 , -2 ) ( m113 ) _ title_edge[- ] ( n11 ) ; at ( 0,-2.8 ) ",
    "@xmath2 edge[- ] ( m113 ) ; at ( 0,-3.2 ) @xmath3  ;     +    at ( -4,-1 ) ( a ) ; at ( 0,-1 ) ( n10 ) _ book _ ; at ( 2.5 , -2 ) ( m111 ) _ author_edge[- ] ( n10 ) ; at ( 0 , -2 ) ( m115 ) _ author_edge[- ] ( n10 ) ; at ( -2.5 , -2 ) ( m112 ) _ title_edge[- ] ( n10 ) ; at ( 2.5,-2.8 ) `` @xmath4 '' edge[-](m111 ) ; at ( 0,-2.8 ) `` @xmath5 '' edge[-](m115 ) ; at ( -2.5,-2.8 ) ",
    "@xmath2 edge[- ] ( m112 ) ; at ( -2.5,-3.2 ) @xmath6  ;     +    at ( 0,-1 ) ( r ) _ book _ ; at ( 1.2 , -2 ) ( n1 ) _ editor _ edge[- ] ( r ) ; at ( 1.2 , -2.8 ) `` @xmath7 '' edge[- ] ( n1 ) ; at ( 2.5 , -2 ) ( n2 ) _ editor _ edge[- ] ( r ) ; at ( 2.5 , -2.8 ) `` @xmath8 '' edge[- ] ( n2 ) ; at ( 0.1 , -2 ) ( n3 ) _ editor _ edge[- ] ( r ) ; at ( 0.1 , -2.8 ) `` @xmath9 '' edge[- ] ( n3 ) ; at ( -1.3 , -2 ) ( n4 ) _ title _ edge[- ] ( r ) ; at ( -1.3 , -2.8 ) ",
    "@xmath10 edge[- ] ( n4 ) ; at ( -1.3 , -3.2 ) @xmath11  ; at ( -2.5 , -2.1 ) ( n5 ) _ year _ edge[- ] ( r ) ; at ( -2.5 , -2.8 ) `` @xmath12 '' edge[- ] ( n5 ) ;    when xml is used for _ document - centric _ applications , the relative order among the elements is typically important e.g. , the relative order of paragraphs and chapters in a book . on the other hand , in case of _ data - centric _ xml applications , the order among the elements may be unimportant  @xcite . in this paper we focus on the latter use case . as an example , take in figure  [ fig : dblp ] three xml documents storing information about books . while the order of the elements _ title _ , _ year _ , _ author _ , and",
    "_ editor _ may differ from one _ book _ to another , it has no impact on the semantics of the data stored in this semi - structured database .",
    "a _ schema _ for xml is a description of the type of admissible documents , typically defining for every node its content model i.e. , the children nodes it must , may , or can not contain . in this paper",
    "we study the problem of _ learning _ unordered schemas from document examples given by the user .",
    "for instance , consider the three xml documents from figure  [ fig : dblp ] and assume that the user wants to obtain a schema which is satisfied by all the three documents .",
    "a desirable solution is a schema which allows a _ book _ to have , in any order , exactly one _ title _ , optionally one _ year _ , and either at least one _ author _ or at least one _ editor_.    studying the theoretical foundations of learning unordered schemas has several practical motivations .",
    "a schema serves as a reference for users who do not know yet the structure of the xml document , and attempt to query or modify its contents .",
    "if the schema is not given explicitly , it can be learned from document examples and then read by the users . from another point of view , florescu  @xcite pointed out the need to automatically infer good - quality schemas and to apply them in the process of _ data integration_. this is clearly a data - centric application , therefore unordered schemas might be more appropriate .",
    "another motivation of learning the unordered schema of a xml collection is _ query minimization _",
    "@xcite i.e. , given a query and a schema , find a smaller yet equivalent query in the presence of the schema .",
    "furthermore , we want to use inferred unordered schemas and optimization techniques to boost the learning algorithms for twig queries  @xcite , which are order - oblivious .",
    "previously , schema learning has been studied from _ positive examples _ only i.e. , documents which must satisfy the schema . for instance",
    ", we have already shown a schema learned from the three documents from figure  [ fig : dblp ] given as positive examples . however , it is conceivable to find applications where _ negative examples _",
    "( i.e. , documents that must not satisfy the schema ) might be useful . for instance ,",
    "assume a scenario where the schema of a data - centric xml collection evolves over time and some documents may become obsolete w.r.t .  the new schema .",
    "a user can employ these documents as negative examples to extract the new schema of the collection .",
    "thus , the _ schema maintenance _",
    "@xcite can be done incrementally , with little feedback needed from the user .",
    "this kind of application motivates us to investigate the problem of learning unordered schemas when we also allow negative examples .",
    "we focus our research on learning the unordered schema formalisms recently proposed in  @xcite : the _ disjunctive multiplicity schemas _",
    "( dms ) and its restriction , _ disjunction - free multiplicity schemas _ ( ms ) .",
    "while they employ a user - friendly syntax inspired by dtds , they define unordered content model only , and , therefore , they are better suited for unordered xml .",
    "they also retain much of the expressiveness of dtds without an increase in computational complexity . essentially , a dms is a set of rules associating with each label the possible number of occurrences for all the allowed children labels by using _ multiplicities _ : `` @xmath13 '' ( 0 or more occurrences ) , `` @xmath14 '' ( 1 or more ) , `` @xmath15 '' ( 0 or 1 ) , `` @xmath16 '' ( exactly one occurrence ; often omitted for brevity ) .",
    "additionally , alternatives can be specified using restricted _ disjunction _ ( `` @xmath17 '' ) and all the conditions are gathered with _ unordered concatenation _",
    "( `` @xmath18 '' ) .",
    "for example , the following schema is satisfied by the three documents from figure  [ fig : dblp ] .",
    "@xmath19 this dms allows a _ book _ to have , in any order , exactly one _ title _ , optionally one _ year _ , and either at least one _ author _ or at least one _ editor_. moreover , this is a _",
    "minimal _ schema satisfied by the documents from figure  [ fig : dblp ] because it captures the most specific schema satisfied by them . on the other hand ,",
    "the following schema is also satisfied by the documents from figure  [ fig : dblp ] , but it is more general : @xmath20 this schema allows a _ book _ to have , in any order , exactly one _ title _ , optionally one _ year _ , and any number of _ author _ s and _ editor _ s .",
    "it is not minimal because it accepts a _ book _ having at the same time _",
    "author _ s and _ editor _ s , unlike the first example of schema . moreover , the second schema is a ms because it does not use the disjunction operation .    in this paper",
    "we address the problem of learning dms and ms from examples given by the user .",
    "we propose a definition of the learnability influenced by computational learning theory  @xcite , in particular by the inference of languages  @xcite .",
    "a learning algorithm takes as input a set of xml documents which must satisfy the schema ( i.e. , _ positive examples _ ) , and a set of xml documents which must not satisfy the schema ( i.e. , _ negative examples _ ) .",
    "essentially , a class of schemas is _ learnable _ if there exists an algorithm which takes as input a set of examples given by the user and returns a schema which is consistent with the examples .",
    "moreover , the learning algorithm should be _ sound _ i.e. , always return a schema consistent with the examples given by the user , _ complete _ i.e. , able to produce every schema with a sufficiently rich set of examples , and _ efficient _ i.e. , polynomial in the size of the input .",
    "our approach is novel in two directions :    * previous research on schema learning has been done in the context of ordered xml , typically on learning restricted classes of regular expressions as content models of the dtds .",
    "we focus on learning unordered schema formalisms and the results are positive : the dms and the ms are learnable from positive examples only . *",
    "the learning frameworks investigated before in the literature typically infer a schema using a collection of documents serving as positive examples .",
    "we study the impact of negative examples in the process of schema learning . in this case , the learning algorithm should return a schema satisfied by all the positive examples and by none of the negative ones . we show that the ms are learnable in the presence of both positive and negative examples , while the dms are not .",
    "we summarize our learnability results in table  [ tab : learnability ] .",
    "for the learnable cases , we propose learning algorithms which return a minimal schema consistent with the examples .",
    ".[tab : learnability]summary of learnability results . [ cols=\"^,^,^\",options=\"header \" , ]     * related work . * the _ document type definition ( dtd ) _ , the most widespread xml schema formalism @xcite , is essentially a set of rules associating with each label a regular expression that defines the admissible sequences of children .",
    "therefore , learning dtds reduces to learning regular expressions .",
    "gold  @xcite showed that the entire class of regular languages is not identifiable in the limit .",
    "consequently , research has been done on restricted classes of regular expressions which can be efficiently learnable  @xcite .",
    "hegewald et al .",
    "@xcite extended the approach from  @xcite and proposed a system which infers one - unambiguous regular expressions  @xcite as the content models of the labels .",
    "garofalakis et al .",
    "@xcite designed a practical system which infers concise and semantically meaningful dtds from document examples .",
    "bex et al .",
    "@xcite proposed learning algorithms for two classes of regular expressions which capture many practical dtds and are succinct by definition : _ single occurrence regular expressions _ ( sores ) and its subclass consisting of _ chain regular expressions _ ( chares ) .",
    "bex et al .",
    "@xcite also studied learning algorithms for the subclass of deterministic regular expressions in which each alphabet symbol occurs at most @xmath21 times ( @xmath21-ores ) .",
    "more recently , freydenberger and ktzing  @xcite proposed more efficient algorithms for the above mentioned restricted classes of regular expressions .",
    "since the dms disallow repetitions of symbols among the disjunctions , they can be seen as restricted sores interpreted under commutative closure i.e. , an unordered collection of children matches a regular expression if there exists an ordering that matches the regular expression in the standard way . the algorithms proposed for the inference of sores  @xcite",
    "are typically based on constructing an automaton and then transforming it into an equivalent sore .",
    "being based on automata techniques , the algorithms for learning sores take ordered input , therefore an additional input that the dms do not have i.e. , the order among the labels .    for this reason , we can not reduce learning dms to learning sores .",
    "consequently , we have to investigate new techniques to solve the problem of learning unordered schemas .",
    "moreover , all the existing learning algorithms take into account only positive examples .",
    "we also mention some of the related work on learning schema formalisms more expressive than dtds .",
    "_ xml schema _ , the second most widespread schema formalism  @xcite , allow the content model of an element to depend on the context in which it is used , therefore it is more difficult to learn .",
    "bex et al .",
    "@xcite proposed efficient algorithms to automatically infer a concise xml schema describing a given set of xml documents . in a different approach , chidlovskii  @xcite used _ extended context - free grammars _ to model schemas for xml and proposed a schema extraction algorithm . + * organization .",
    "* this paper is organized as follows . in section  [ sec : preliminaries ] we present preliminary notions . in section  [ sec : framework ] we formally define the learning framework . in section  [ sec : dms : pos ] and section  [ sec : ms ] we present the learnability results for dms and ms , respectively , when only positive examples are allowed . in section  [ sec : dms :",
    "pos : neg ] we discuss the impact of negative examples on learning .",
    "finally , we summarize our results and outline further directions in section  [ sec : conclusions ] .",
    "throughout this paper we assume an alphabet @xmath22 which is a finite set of symbols .",
    "we also assume that @xmath22 has a total order @xmath23 , that can be tested in constant time . +",
    "* trees . *",
    "we model xml documents with unordered labeled trees . formally ,",
    "@xmath24 is a tuple @xmath25 , where @xmath26 is a finite set of nodes , @xmath27 is a distinguished root node , @xmath28 is a labeling function , and @xmath29 is the parent - child relation .",
    "we assume that the relation @xmath30 is acyclic and require every non - root node to have exactly one predecessor in this relation . by @xmath31",
    "we denote the set of all finite trees .",
    "we present an example of tree in figure  [ fig : tree ] .",
    "( -1.25,.25 ) rectangle ( 1.25,-3.25 ) ; at ( 0,0 ) ( n0 ) @xmath32 ; at ( -0.75,-1 ) ( n1 ) @xmath33 ; at ( 0,-1 ) ( n4 ) @xmath34 ; at ( 0,-2 ) ( n5 ) @xmath33 ; at ( 0.75,-1 ) ( n2 ) @xmath35 ; at ( 0.75,-2 ) ( n3 ) @xmath34 ; at ( 0.75,-3 ) ( n6 ) @xmath33 ; at ( -0.75,-2 ) ( n7 ) @xmath34 ; ( n1 )  ( n7 ) ; ( n0 )  ( n1 ) ; ( n0 )  ( n1 ) ; ( n0 )  ( n2 ) ; ( n2 )  ( n3 ) ; ( n3 )  ( n6 ) ; ( n0 )  ( n4 ) ; ( n4 )  ( n5 ) ;    * unordered words . * an _ unordered word _ is essentially a multiset of symbols i.e. , a function @xmath36 mapping symbols from the alphabet to natural numbers , and we call @xmath37 the number of occurrences of the symbol @xmath33 in @xmath38 .",
    "we denote by @xmath39 the set containing all the unordered words over the alphabet @xmath22 .",
    "we also write @xmath40 as a shorthand for @xmath41 .",
    "an empty word @xmath42 is an unordered word that has @xmath43 occurrences of every symbol i.e. , @xmath44 for every @xmath45 .",
    "we often use a simple representation of unordered words , writing each symbol in the alphabet the number of times it occurs in the unordered word .",
    "for example , when the alphabet is @xmath46 , @xmath47 stands for the function @xmath48 , @xmath49 , and @xmath50 .",
    "the ( unordered ) concatenation of two unordered words @xmath51 and @xmath52 is defined as the multiset union @xmath53 i.e. , the function defined as @xmath54 for all @xmath45 . for instance , @xmath55 .",
    "note that @xmath42 is the identity element of the unordered concatenation @xmath56 for all unordered word @xmath38 .",
    "also , given an unordered word @xmath38 , by @xmath57 we denote the concatenation @xmath58 ( @xmath59 times ) .",
    "a _ language _ is a set of unordered words .",
    "the unordered concatenation of two languages @xmath60 and @xmath61 is a language @xmath62 .",
    "for instance , if @xmath63 and @xmath64 , then @xmath65 . + * multiplicity schemas . *",
    "a _ multiplicity _ is an element from the set @xmath66 .",
    "we define the function @xmath67 mapping multiplicities to sets of natural numbers .",
    "more precisely : @xmath68 given a symbol @xmath45 and a multiplicity @xmath69 , the language of @xmath70 , denoted @xmath71 , is @xmath72 .",
    "for example , @xmath73 , @xmath74 , and @xmath75 .    a _ disjunctive multiplicity expression _",
    "@xmath76 is : @xmath77 where for all @xmath78 , @xmath79 is a multiplicity and each @xmath80 is : @xmath81 where for all @xmath82 , @xmath83 is a multiplicity and @xmath84 .",
    "moreover , we require that every symbol @xmath85 is present at most once in a disjunctive multiplicity expression .",
    "for instance , @xmath86 is a disjunctive multiplicity expression , but @xmath87 is not because @xmath33 appears twice .",
    "disjunction - free multiplicity expression _ is an expression which uses no disjunction symbol `` @xmath17 '' i.e. , an expression of the form @xmath88 , where the @xmath89 s are pairwise distinct symbols in the alphabet and the @xmath79 s are multiplicities ( with @xmath90 ) .",
    "we denote by @xmath91 the set of all the disjunctive multiplicity expressions and by @xmath92 the set of all the disjunction - free multiplicity expressions .",
    "the language of a disjunctive multiplicity expression is : @xmath93 if an unordered word @xmath38 belongs to the language of a disjunctive multiplicity expression @xmath76 , we denote it by @xmath94 , and we say that @xmath38 _ satisfies _ @xmath76 .",
    "when a symbol @xmath33 ( resp .",
    "a disjunctive multiplicity expression @xmath76 ) has multiplicity @xmath16 , we often write @xmath33 ( resp .",
    "@xmath76 ) instead of @xmath95 ( resp .",
    "@xmath96 ) . moreover , we omit writing symbols and disjunctive multiplicity expressions with multiplicity @xmath43 .",
    "take , for instance , @xmath97 and note that both the symbols @xmath34 and @xmath35 as well as the disjunction @xmath98 have an implicit multiplicity @xmath16 .",
    "the language of @xmath99 is : @xmath100 next , we recall the unordered schema formalisms from  @xcite :    a _ disjunctive multiplicity schema ( dms ) _ is a tuple @xmath101 , where @xmath102 is a designated root label and @xmath103 maps symbols in @xmath22 to disjunctive multiplicity expressions . by @xmath104",
    "we denote the set of all disjunctive multiplicity schemas .",
    "a _ disjunction - free multiplicity schema ( ms ) _",
    "@xmath101 is a restriction of the @xmath104 , where @xmath103 maps symbols in @xmath22 to disjunction - free multiplicity expressions . by @xmath105",
    "we denote the set of all disjunction - free multiplicity schemas .    to define satisfiability of a dms @xmath106 by a tree @xmath24 we first define the unordered word @xmath107 of children of a node @xmath108 i.e. , @xmath109 now , a tree @xmath24 _ satisfies _ @xmath106 , in symbols @xmath110 , if @xmath111 and for any node @xmath112 , @xmath113 . by @xmath114",
    "we denote the set of all the trees satisfying @xmath106 .    in the sequel",
    ", we present a schema @xmath115 as a set of rules of the form @xmath116 , for any @xmath45 . if @xmath117 , then we write @xmath118 or we simply omit writing such a rule .",
    "note that there exist dms such that the smallest tree in their language has a size exponential in the size of the alphabet , as we observe in the following example .",
    "[ example : exponential ] we consider for @xmath125 the alphabet @xmath126 and the dms @xmath127 having the root label @xmath32 and the following rules :    & r a_1 b_1 , + & a_ia_i+1 b_i+1  ( 1i < n ) , + & b_ia_i+1 b_i+1  ( 1i < n ) , + & a_n , + & b_n .    we present in figure  [ fig : compression ] the unique tree satisfying this schema and we observe that its size is exponential in the size of the alphabet .    at ( 0,0 ) ( n0 ) @xmath32 ; at ( -1,-1.25 ) ( n1 ) @xmath128 ; at ( 1,-1.25 ) ( n2 ) @xmath129 ; at ( -1.5,-2.5 ) ( n3 ) @xmath130 ; at ( -0.5,-2.5 ) ( n4 ) @xmath131 ; at ( 0.5,-2.5 ) ( n30 ) @xmath130 ; at ( 1.5,-2.5 ) ( n40 ) @xmath131 ; at ( -1.75,-3.75 ) ( n5 ) @xmath132 ; at ( -1.25,-3.75 ) ( n6 ) @xmath133 ; at ( -0.75,-3.75 ) ( n50 ) @xmath132 ; at ( -0.25,-3.75 ) ( n60 ) @xmath133 ; at ( 0.25,-3.75 ) ( n500 ) @xmath132 ; at ( 0.75,-3.75 ) ( n600 ) @xmath133 ; at ( 1.25,-3.75 ) ( n5000 ) @xmath132 ; at ( 1.75,-3.75 ) ( n6000 ) @xmath133 ; at ( -1.85,-5 ) ( n7 ) @xmath134 ; at ( -1.65,-5 ) ( n71 ) @xmath134 ; at ( -1.35,-5 ) ( n8 ) @xmath134 ; at ( -1.15,-5 ) ( n81 ) @xmath134 ; at ( -0.85,-5 ) ( n70 ) @xmath134 ; at ( -0.65,-5 ) ( n701 ) @xmath134 ; at ( -0.35,-5 ) ( n80 ) @xmath134 ; at ( -0.15,-5 ) ( n801 ) @xmath134 ; at ( 0.15,-5 ) ( n700 ) @xmath134 ; at ( 0.35,-5 ) ( n7001 ) @xmath134 ; at ( 0.65,-5 ) ( n800 ) @xmath134 ; at ( 0.85,-5 ) ( n8001 ) @xmath134 ; at ( 1.15,-5 ) ( n7000 ) @xmath134 ; at ( 1.35,-5 ) ( n70001 ) @xmath134 ; at ( 1.65,-5 ) ( n8000 ) @xmath134 ; at ( 1.85,-5 ) ( n80001 ) @xmath134 ;    at ( -1.85,-5.5 ) ( n7x ) @xmath135 ; at ( -1.65,-5.5 ) ( n71x ) @xmath136 ; at ( -1.35,-5.5 ) ( n8x ) @xmath135 ; at ( -1.15,-5.5 ) ( n81x ) @xmath136 ; at ( -0.85,-5.5 ) ( n70x ) @xmath135 ; at ( -0.65,-5.5 ) ( n701x ) @xmath136 ; at ( -0.35,-5.5 ) ( n80x ) @xmath135 ; at ( -0.15,-5.5 ) ( n801x ) @xmath136 ; at ( 0.15,-5.5 ) ( n700x ) @xmath135 ; at ( 0.35,-5.5 ) ( n7001x ) @xmath136 ; at ( 0.65,-5.5 ) ( n800x ) @xmath135 ; at ( 0.85,-5.5 ) ( n8001x ) @xmath136 ; at ( 1.15,-5.5 ) ( n7000x ) @xmath135 ; at ( 1.35,-5.5 ) ( n70001x ) @xmath136 ; at ( 1.65,-5.5 ) ( n8000x ) @xmath135 ; at ( 1.85,-5.5 ) ( n80001x ) @xmath136 ;    ( n0 )  ( n1 ) ; ( n0 )  ( n2 ) ; ( n1 )  ( n3 ) ; ( n2 )  ( n30 ) ; ( n1 )  ( n4 ) ; ( n2 )  ( n40 ) ; ( n3 ) ",
    "( n5 ) ; ( n3 )  ( n6 ) ; ( n4 )  ( n50 ) ; ( n4 )  ( n60 ) ; ( n30 )  ( n500 ) ; ( n30 )  ( n600 ) ; ( n40 )  ( n5000 ) ; ( n40 )  ( n6000 ) ; ( n5 )  ( n7 ) ; ( n5 )  ( n71 ) ; ( n6 ) ",
    "( n8 ) ; ( n50 )  ( n70 ) ; ( n60 )  ( n80 ) ; ( n500 )  ( n700 ) ; ( n600 )  ( n800 ) ; ( n5000 )  ( n7000 ) ; ( n6000 )  ( n8000 ) ; ( n6 )  ( n81 ) ; ( n50 ) ",
    "( n701 ) ; ( n60 ) ",
    "( n801 ) ; ( n500 )  ( n7001 ) ; ( n600 )  ( n8001 ) ; ( n5000 )  ( n70001 ) ; ( n6000 )  ( n80001 ) ;    * alternative definition with characterizing triples . *",
    "any disjunctive multiplicity expression @xmath76 can be expressed alternatively by its _ _ _ ( _ _ characterizing _ ) _ triple _ @xmath137 consisting of the following sets :    * the _ conflicting pairs of siblings _ @xmath138 contains pairs of symbols in @xmath22 such that @xmath76 defines no word using both symbols simultaneously : @xmath139 * the _ extended cardinality map _ @xmath140 captures for each symbol in the alphabet the possible numbers of its occurrences in the unordered words defined by @xmath76 : @xmath141 * the _ sets of required symbols _",
    "@xmath142 which captures symbols that must be present in every word ; essentially , a set of symbols @xmath143 belongs to @xmath142 if every word defined by @xmath76 contains at least one element from @xmath143 : @xmath144    as an example we take @xmath97 .",
    "because @xmath142 is closed under supersets , we list only its minimal elements : @xmath145 two equivalent disjunctive multiplicity expressions yield the same triples and hence @xmath137 can be viewed as the _ normal form _ of a given expression @xmath76  @xcite .",
    "moreover , each set has a compact representation of size polynomial in the size of the alphabet and computable in ptime .",
    "we illustrate them on the same @xmath97 :    * @xmath146 consists of sets of symbols present in @xmath76 such that any pairwise two of them are conflicting : @xmath147 * @xmath148 is a function mapping symbols to multiplicities such that for any unordered word @xmath149 , and for any symbol @xmath45 , @xmath150 : @xmath151 * @xmath152 contains only the @xmath153-minimal elements of @xmath142 : @xmath154    also note that we can easily construct a disjunctive multiplicity expression from its characterizing triple .",
    "a simple algorithm has to loop over the sets from @xmath146 and @xmath152 to compute for each label with which other labels it is linked by the disjunction operator .",
    "then , using @xmath148 , the algorithm associates to each label and each disjunction the correct multiplicity .",
    "for example , take the following compact triples : @xmath155 note that they characterize the expression : @xmath156 we have introduced the alternative definition with characterizing triples because we later propose an algorithm which learns characterizing triples from unordered word examples ( algorithm  [ alg1 ] from section  [ sec : dms : pos ] ) .",
    "then , from this information , the corresponding disjunctive multiplicity expression can be constructed in a straightforward manner .",
    "we use a variant of the standard language inference framework  @xcite adapted to learning disjunctive multiplicity expressions and schemas .",
    "a _ learning setting _ is a tuple containing the set of _ concepts _ that are to be learned , the set of _ instances _ of the concepts that are to serve as examples in learning , and the _ semantics _ mapping every concept to its set of instances .",
    "a _ learning setting _ is a tuple @xmath157 , where @xmath158 is a set of examples , @xmath159 is a class of concepts , and @xmath160 is a function that maps every concept in @xmath159 to the set of all its examples ( a subset of @xmath158 ) .",
    "for example , the setting for learning disjunctive multiplicity expressions from positive examples is the tuple @xmath161 and the setting for learning disjunctive multiplicity schemas from positive examples is @xmath162 .",
    "we obtain analogously the learning settings for disjunction - free multiplicity expressions and schemas : @xmath163 and @xmath164 , respectively .",
    "the general formulation of the definition allows us to easily define settings for learning from both positive and negative examples , which we present in section  [ sec : dms : pos : neg ] .    to define a learnable concept , we fix a learning setting @xmath165 and we introduce some auxiliary notions .",
    "sample _ is a finite nonempty subset @xmath166 of @xmath158 i.e. , a set of examples .",
    "a sample @xmath166 is _ consistent _ with a concept @xmath167 if @xmath168 . a _ learning algorithm _ is an algorithm that takes a sample and returns a concept in @xmath159 or a special value _",
    "null_.    [ def : learnable ] a class of concepts",
    "@xmath159 is _ learnable in polynomial time and data _ in the setting @xmath169 if there exists a polynomial learning algorithm @xmath170 satisfying the following two conditions :    1 .",
    "* soundness .",
    "* for any sample @xmath166 , the algorithm @xmath171 returns a concept consistent with @xmath166 or a special _ null _ value if no such concept exists .",
    "* completeness .",
    "* for any concept @xmath167 there exists a sample @xmath172 such that for every sample @xmath166 that extends @xmath172 consistently with @xmath35 i.e. , @xmath173 , the algorithm @xmath171 returns a concept equivalent to @xmath35 .",
    "furthermore , the cardinality of @xmath172 is polynomially bounded by the size of the concept .",
    "the sample @xmath172 is called the _",
    "characteristic sample _ for @xmath35 w.r.t .",
    "@xmath170 and @xmath174 . for",
    "a learning algorithm there may exist many such samples .",
    "the definition requires that one characteristic sample exists .",
    "the soundness condition is a natural requirement , but alone it is not sufficient to eliminate trivial learning algorithms .",
    "for instance , if we want to learn disjunctive multiplicity expressions from positive examples over the alphabet @xmath175 , an algorithm always returning @xmath176 is sound",
    ". consequently , we require the algorithm to be complete analogously to how it is done for grammatical language inference  @xcite .",
    "typically , in the case of polynomial grammatical inference , the _ size _ of the characteristic sample is required to be polynomial in the size of the concept to be learned  @xcite , where the size of a sample is the sum of the sizes of the examples that it contains . from the definition of the dms , since repetitions of symbols are discarded among the disjunctions , the size of a schema is polynomial in the size of the alphabet .",
    "thus , a natural requirement would be that the size of the characteristic sample is polynomially bounded by the size of the alphabet .",
    "there exist dms such that the smallest tree in their language is exponential in the size of the alphabet ( cf .",
    "example  [ example : exponential ] ) . because of space restrictions , we have imposed in the definition of learnability that the _ cardinality _ ( and not the size ) of the characteristic sample is polynomially bounded by the size of the concept , hence by the size of the alphabet .",
    "however , we are able to obtain characteristic samples of size polynomial in the size of the alphabet by using a _ compressed _ representation of the xml trees , for example with _ directed acyclic graphs _  @xcite",
    ". we will provide in the full version of the paper the details about this compression technique and the new definition of the learnability .",
    "the algorithms that we propose in this paper transfer without any alteration for the definition using compressed trees .    additionally to the conditions imposed by the definition of learnability , we are interested in the existence of learning algorithms which return _ minimal _ concepts for a given set of examples .",
    "it is important to emphasize that we mean minimality in terms on language inclusion .",
    "when only positive examples are allowed , a dms @xmath106 is a _ minimal _ dms consistent with a set of trees @xmath166 iff @xmath177 , and , for any @xmath178 , if @xmath179 , then @xmath180 . we similarly obtain the definition of minimality for learning disjunctive multiplicity expressions . intuitively , a minimal schema consistent with a set of examples is the most specific schema consistent with them .",
    "for example , recall the three xml documents storing information about books from figure  [ fig : dblp ] .",
    "assume that the user provides the three documents as positive examples to a learning algorithm .",
    "the most specific schema consistent with the examples is : @xmath19 another possible solution is the schema : @xmath181 it is less likely that a user wants to obtain such a schema which allows a _ book _ to have at the same time _",
    "author _ s and _ editor _ s . in this case",
    ", the most specific schema also corresponds to the natural requirements that one might want to impose on a xml collection storing information about books , in particular a _ book _ has either at least one _ author _ or at least one _ editor_. minimality is often perceived as a better fitted learning solution  @xcite , and this motivates our requirement for the learning algorithms to return minimal concepts consistent with the examples .",
    "the main result of this section is the learnability of the disjunctive multiplicity schemas from positive examples i.e. , in the setting @xmath162 .",
    "we present a learning algorithm that constructs a _",
    "minimal _ schema consistent with the input set of trees .",
    "first , we study the problem of learning a disjunctive multiplicity expression from positive examples i.e. , in the setting @xmath182 . we present a learning algorithm that constructs a minimal disjunctive multiplicity expression consistent with the input collection of unordered words . given a set of unordered words",
    ", there may exist many consistent minimal disjunctive multiplicity expressions .",
    "in fact , for some sets of positive examples there may be an exponential number of such expressions ( cf .",
    "the proof of lemma  [ lemma : cons ] ) .",
    "take in example  [ ex : minimal ] a sample and two consistent minimal disjunctive multiplicity expressions .",
    "[ ex : minimal]consider the alphabet @xmath183 and the set of unordered words @xmath184 .",
    "take the following two disjunctive multiplicity expressions : @xmath185 note that @xmath186 and @xmath187 . also note that @xmath188 ( because of @xmath189 ) and @xmath190 ( because of @xmath191 ) .",
    "on the other hand , we easily observe that both @xmath192 and @xmath193 are minimal disjunctive multiplicity expressions with languages including @xmath166 .",
    "before we present the learning algorithms , we have to introduce additional notions .",
    "first , we define the function @xmath194 which , given a set of unordered words @xmath166 and a label @xmath45 , computes the multiplicity @xmath69 such that @xmath195 and there does not exist another multiplicity @xmath196 such that @xmath197 and @xmath198 . for example , given the set of unordered words @xmath184 , we have : @xmath199 next , we introduce the notion of _ maximal - clique partition of a graph_. given a graph @xmath200 , a maximal - clique partition of @xmath201 is a graph partition @xmath202 such that :    * the subgraph induced in @xmath201 by any @xmath203 is a clique ( with @xmath204 ) , * the subgraph induced in @xmath201 by the union of any @xmath203 and @xmath205 is not a clique ( with @xmath206 ) .    in figure",
    "[ fig : cuts ] we present a graph and a maximal - clique partition of it i.e. , @xmath207 .",
    "note that the graph from figure  [ fig : cuts ] allows one other maximal - clique partition i.e. , @xmath208 . on the other hand",
    ", @xmath209 is not a maximal - clique partition because it contains two sets such that their union induces a clique i.e. , @xmath210 and @xmath211 .    at ( -0.75 , 0.75 ) ( a ) @xmath33 ; at ( 0.75 , 0.75 ) ( e ) @xmath212 ; at ( -0.75,-0.75 ) ( c ) @xmath35 ; at ( 0.75,-0.75 ) ( d ) @xmath213 ; at ( -2,0 ) ( b ) @xmath34 ; ( a ) edge[- ] ( e ) ; ( e ) edge[- ] ( c ) ; ( e ) edge[- ] ( d ) ; ( c ) edge[- ] ( d ) ; ( -1.1 , 1.1 ) rectangle ( 1.1 , 0.4 ) ; ( 1.1 , -1.1 ) rectangle ( -1.1 , -0.4 ) ; ( -2.35,-0.35 ) rectangle ( -1.65 , 0.35 ) ;    unlike the _ clique _ problem , which is known to be np - complete  @xcite , we can partition in ptime a graph in maximal cliques with a greedy algorithm . in the sequel , we assume that the vertices of the graph are labels from @xmath22 . for a given graph there may exist many maximal - clique partitions and we use the total order @xmath23 to propose a deterministic algorithm constructing a maximal - clique partition .",
    "the algorithm works as follows : we take the smallest label from @xmath22 w.r.t .",
    "@xmath23 and not yet used in a clique , and we iteratively extend it to a maximal clique by adding connected labels .",
    "every time when we have a choice to add a new label to the current clique , we take the smallest label w.r.t .  @xmath23 .",
    "we repeat this until all the labels are used .",
    "this algorithm yields to a unique maximal - clique partition .",
    "for example , for the graph from figure  [ fig : cuts ] , we compute the maximal - clique partition marked on the figure i.e. , @xmath207 . we additionally define the function @xmath214 which takes as input a graph , computes a maximal - clique partition using the greedy algorithm described above and , at the end , for technical reasons , the algorithm discards the singletons .",
    "for example , for the graph from figure  [ fig : cuts ] , the function @xmath214 returns @xmath215 .",
    "clearly , the function @xmath214 works in ptime .",
    "next , we present algorithm  [ alg1 ] and we claim that , given a set of unordered words @xmath166 , it computes in polynomial time a disjunctive multiplicity expression @xmath76 consistent with @xmath166 .    @xmath216 + : a set of unordered words @xmath217 + : a minimal disjunctive multiplicity expression @xmath76 consistent with @xmath166 + @xmath45 + @xmath218 + @xmath219 + @xmath220 + @xmath221 + @xmath222 + @xmath76 characterized by the triple @xmath223    algorithm  [ alg1 ] works in three steps and we illustrate each of them on the sample @xmath224 from example  [ ex : minimal ] .",
    "the first step ( lines 1 - 2 ) computes the compact representation of the extended cardinality map for each symbol from @xmath22 , using the function @xmath194 .",
    "we ignore in the sequel the symbols never occurring in words from @xmath166 ( line 3 ) .",
    "for the sample from example  [ ex : minimal ] , we infer : @xmath225 the second step of the algorithm ( lines 4 - 5 ) computes the compact sets of conflicting siblings .",
    "first , we construct the graph @xmath201 having as set of vertices the labels occurring at least once in unordered words from @xmath166 .",
    "two labels are linked by an edge in @xmath201 if there does not exist an unordered word in @xmath166 where both of them are present at the same time , in other words the two labels are a candidate pair of conflicting siblings .",
    "next , we apply the function @xmath214 on the graph @xmath201 . for the unordered words from example",
    "[ ex : minimal ] we obtain the graph from figure  [ fig : cuts ] , and we infer @xmath226 .",
    "note that the maximal - clique partition implies the minimality of the disjunctive multiplicity expression constructed later using the inferred @xmath146 .",
    "the third step of the algorithm ( line 6 ) computes the @xmath153-minimal sets of required symbols @xmath152 .",
    "each symbol having associated a multiplicity @xmath16 or @xmath14 belongs to a required set of symbols containing only itself because it is present in all the unordered words from @xmath166 and we want to learn a minimal concept .",
    "moreover , we add in @xmath152 the sets of conflicting siblings inferred at the previous step with the property that one of them is present in any unordered word from @xmath166 , to guarantee the minimality of the inferred language . for the sample from example  [ ex : minimal ] , @xmath227 belongs to @xmath152 .",
    "since from the previous step we have @xmath228 , at this step we have to add @xmath229 to @xmath152 because all the words in the sample contain either @xmath33 or @xmath212 .",
    "on the other hand , we do not add @xmath230 because the sample contains the word @xmath231 .",
    "the inferred @xmath152 is @xmath232 .    finally , the algorithm returns the disjunctive multiplicity expression characterized by the inferred triple ( line 7 ) . for the sample @xmath166 ,",
    "it returns @xmath233 .",
    "note that if at step 2 we take a partition which is not a maximal - clique one , for example @xmath209 , and we later construct a disjunctive multiplicity expression using it , we get @xmath234 , which includes both @xmath192 and @xmath193 from example  [ ex : minimal ] , therefore is not minimal .",
    "also note that at step 3 , without @xmath229 added to @xmath152 , the resulting schema would accept an unordered word without any @xmath33 and @xmath212 , so the learned language would not be minimal .    algorithm  [ alg1 ] is sound and each of its three steps requires polynomial time .",
    "next , we prove the completeness of the algorithm . given a disjunctive multiplicity expression @xmath76 , we construct in three steps its characteristic sample @xmath235 . at the same time",
    ", we illustrate the construction on the disjunctive multiplicity expression @xmath236 :    1 .",
    "we take the pairs of symbols which can be found together in an unordered word in @xmath237 . for each of them , we add in @xmath235 an unordered word containing only the two symbols .",
    "next , for each symbol occurring in the disjunctions from @xmath76 , we add in @xmath235 an unordered word containing only one occurrence of that symbol .",
    "we also add in @xmath235 the empty word . for @xmath192",
    "we obtain : @xmath238 .",
    "we replace each unordered word @xmath38 obtained at the previous step with @xmath239 , where @xmath240 is a minimal unordered word such that @xmath241 .",
    "the newly obtained @xmath235 contains unordered words from @xmath237 . for @xmath192",
    "we obtain : @xmath242 .",
    "3 .   for each symbol",
    "@xmath33 from the alphabet such that @xmath243 is @xmath13 or @xmath14 , we randomly take an unordered word @xmath38 from @xmath235 and containing @xmath33 and we add to @xmath235 the unordered word @xmath244 . in the worst case , at this step",
    "the number of words in the characteristic sample is doubled , but it remains polynomial in the size of the alphabet .",
    "for @xmath192 we obtain : @xmath245 .",
    "note that there may exist many equivalent characteristic samples .",
    "the first step of the construction implies that the only potential conflicts to be considered in algorithm  [ alg1 ] are the conflicts implied by the expression .",
    "in other words , all the connected components of the graph of potential conflicts from algorithm  [ alg1 ] are cliques .",
    "thus , there is only one possible maximal - clique partition to be done in the algorithm .",
    "moreover , the second and third steps of the construction ensure that , for any sample consistently extending the characteristic sample , algorithm  [ alg1 ] infers the correct sets of required symbols and the extended cardinality map , respectively .",
    "we have proposed algorithm  [ alg1 ] , which is a sound and complete algorithm for learning minimal disjunctive multiplicity expressions from unordered words positive examples .",
    "thus , we can state the following result :    the concept class @xmath91 is learnable in polynomial time and data from positive examples i.e. , in the setting @xmath246 .",
    "next , we extend the result for dms .",
    "we propose algorithm  [ alg2 ] , which learns a disjunctive multiplicity schema from a set of trees .",
    "we assume w.l.o.g . that all the trees from the sample have as root label the same label @xmath32 .",
    "if this assumption is not satisfied , the sample is not consistent .",
    "the algorithm infers , for each label @xmath33 from the alphabet , the minimal disjunctive multiplicity expression consistent with the children of all the nodes labeled @xmath33 from the trees from the sample .    : @xmath247 + : a set of trees @xmath248 s.t .",
    "@xmath249 ( with @xmath250 + : a minimal dms @xmath106 consistent with @xmath166 + @xmath45 + @xmath251 + @xmath252 + @xmath253    algorithm  [ alg2 ] returns a minimal disjunctive multiplicity schema consistent with the sample because the inferred rule for each label represents a minimal disjunctive multiplicity expression obtained using algorithm  [ alg1 ] .",
    "next , we show that algorithm  [ alg2 ] is also complete by providing a construction of a characteristic sample of cardinality polynomial in the size of the alphabet . for this purpose , we have to define first two additional notions .",
    "given a dms @xmath115 and a label @xmath45 , we define the following two trees :    * @xmath254 is a minimal tree satisfying @xmath106 and containing a node labeled @xmath33 , * @xmath255 is a minimal tree satisfying @xmath256 .",
    "it is equivalent to @xmath257 .",
    "we illustrate the two notions defined above in the following example :    [ ex : min : tree]consider the dms @xmath106 having the root label @xmath32 and the rules : @xmath258 we present in figure  [ fig : min : trees ] some trees and we explain for each of them how it can be used .",
    "next , we present the construction of the characteristic sample for learning a dms from positive examples .",
    "we take a dms @xmath115 over an alphabet @xmath22 and we assume w.l.o.g .  that any symbol of the alphabet can be present in at least one tree from @xmath259 .",
    "for each @xmath45 , for each @xmath260 , we compute a tree @xmath24 as follows : we generate a tree @xmath254 , we take the node labeled by @xmath33 ( let it @xmath261 ) , and for any @xmath262 , while @xmath263 we fuse in @xmath261 a copy of @xmath264 .",
    "we obtain a sample of cardinality polynomially bounded by the size of the alphabet . given a dms @xmath106",
    ", there may exist many characteristic samples @xmath265 .",
    "each of them has the property that , if we construct a sample @xmath166 which extends @xmath265 consistently with @xmath106 , then @xmath247 returns @xmath106 .",
    "this proves the completeness of algorithm  [ alg2 ] .",
    "we illustrate the construction of the characteristic sample on the schema @xmath106 from example  [ ex : min : tree ] .",
    "recall that we have already presented the trees @xmath254 and @xmath255 for each @xmath33 from the alphabet .",
    "we also construct the characteristic samples for the disjunctive multiplicity expressions from the rules of @xmath106 :    * @xmath266 , * @xmath267 , * @xmath268 , * @xmath269 .    in figure",
    "[ fig : cs ] we present a characteristic sample @xmath265 for the dms @xmath106 and we explain the purpose of each tree :    * ( a ) , ( b ) , ( c ) , ( d ) , and ( e ) ensure that there is inferred the correct rule for the root i.e. , @xmath270 , * \\(b ) and ( f ) ensure that there is inferred the correct @xmath271 , * \\(d ) and ( g ) ensure that there is inferred the correct @xmath272 , * \\(e ) and ( h ) ensure that there is inferred the correct @xmath273 , * the nodes labeled by @xmath213 and @xmath212 never have children in the trees from @xmath265 , so there are inferred the correct rules for @xmath274 and @xmath275 .",
    "we have proposed algorithm  [ alg2 ] , which is a sound and complete algorithm for learning disjunctive multiplicity schemas from trees positive examples .",
    "thus , we can state the main result of this section :    [ th : dms : pos ] the concept class @xmath104 is learnable in polynomial time and data from positive examples i.e. , in the setting @xmath162 .",
    "in this section we show that the ms are learnable from positive examples i.e. , in the setting @xmath276 . recall that the ms allow no disjunction in the rules , in other words they use expressions of the form @xmath277 . due to this very particular form",
    ", we can _ capture _ a ms @xmath115 using a function @xmath278 obtained directly from the rules of @xmath106 : @xmath279 for example , given the schema @xmath106 having the root @xmath32 and the rules : @xmath280 we have : @xmath281 note that given the function @xmath282 we can easily construct the initial @xmath106 .",
    "we use this characterization in algorithm  [ alg3 ] , a polynomial and sound algorithm which learns a minimal ms from a set of trees .",
    "we assume w.l.o.g . that all the trees from the sample have as root label the same label @xmath32 .",
    "if this assumption is not satisfied , the sample is not consistent .",
    "the minimality of the algorithm follows from the minimality of the inferred multiplicity for each pair of labels @xmath283 , using the function @xmath194 ( cf .",
    "section  [ sec : dms : pos ] ) . moreover , algorithm  [ alg3 ] is complete .",
    "we can easily construct a characteristic sample of cardinality polynomial in the size of the alphabet by using the same steps provided in the previous section , for unordered words and for trees .",
    "@xmath284 + a set of trees @xmath248 s.t .",
    "@xmath249 ( with @xmath250 + a minimal ms @xmath106 consistent with @xmath166 + @xmath45 + @xmath251 + @xmath262 + @xmath285 + @xmath106 having the root label @xmath32 and captured by @xmath286    we have proposed a sound and complete algorithm which learns a minimal ms consistent with a set of positive examples , so we can state the following result :    [ th : ms : pos ] the concept class @xmath105 is learnable in polynomial time and data from positive examples i.e. , in the setting @xmath287 .",
    "in the previous sections , we have considered the settings where the user provides positive examples only . in this section",
    ", we allow the user to additionally specify negative examples .",
    "the main results of this section are that the ms are learnable in polynomial time and data in the presence of both positive and negative examples , while the dms are not .",
    "we use two symbols @xmath14 and @xmath288 to mark whether an example is positive or negative , and we define :    * @xmath289 , * @xmath290 , where @xmath76 is a disjunctive multiplicity expression , * @xmath291 , * @xmath292 , where @xmath106 is a disjunctive multiplicity schema .",
    "formally , the setting for learning disjunctive multiplicity expressions from positive and negative examples is @xmath293 , while for learning dms from positive and negative examples we have @xmath294 .",
    "we obtain analogously the settings for disjunction - free multiplicity expressions and schemas : @xmath295 and @xmath296 , respectively .",
    "we study the problem of checking whether there exists a concept consistent with the input sample because any sound learning algorithm needs to return _ null _ if and only if there is no such concept .",
    "therefore , consistency checking is an easier problem than learning and its intractability precludes learnability .",
    "formally , given a learning setting @xmath165 , the @xmath174__-consistency _ _ is the following decision problem : @xmath297 note that the consistency checking is trivial when only positive examples are allowed .",
    "for instance , if we want to learn disjunctive multiplicity expressions from positive examples over the alphabet @xmath175 , the disjunctive multiplicity expression @xmath176 is always consistent with the examples .",
    "when we also allow negative examples , the problem becomes more complex , particularly in the case of disjunctive multiplicity expressions and schemas , where this problem is not tractable .",
    "first , we show that the consistency checking is tractable for ms . in section  [ sec : ms ] , we have proposed algorithm  [ alg3 ] , which learns a minimal ms consistent with a set of positive examples .",
    "note that , given a set of trees , there exists a _",
    "unique minimal ms _ consistent with them .",
    "the argument is that algorithm  [ alg3 ] uses the function @xmath194 ( cf .",
    "section  [ sec : dms : pos ] ) to infer minimal multiplicities which are unique and sufficient to capture a ms .",
    "thus , the consistency checking becomes trivial for ms : given a sample containing positive and negative examples , there exists a ms consistent with them iff no tree used as negative example satisfies the minimal ms returned by algorithm  [ alg3 ] .",
    "consequently , we easily adapt algorithm  [ alg3 ] to handle both positive and negative examples and we propose algorithm  [ alg4 ] .",
    "@xmath298 + a sample @xmath299 + a minimal ms @xmath106 such that @xmath300 , or _ null _ if no such schema exists + @xmath301 + @xmath302 + @xmath303 + _ null _",
    "+ @xmath106    essentially , algorithm  [ alg4 ] returns the minimal schema consistent with the positive examples iff there is no negative example satisfying it , and otherwise it returns _ null_. note that algorithm  [ alg4 ] is sound and works in polynomial time in the size of the input .",
    "the completeness of algorithm  [ alg4 ] follows from the completeness of algorithm  [ alg3 ] . given a ms @xmath106",
    ", we can construct a characteristic sample @xmath265 that contains only positive examples , analogously to how it is done for algorithm  [ alg3 ] .",
    "we have proposed a polynomial , sound , and complete algorithm which learns minimal ms from positive and negative examples , so we state the first result of this section :    [ th : ms : posneg ] the concept class @xmath105 is learnable in polynomial time and data from positive and negative examples i.e. , in the setting @xmath304 .",
    "next , we prove that the concept class @xmath104 is not learnable in polynomial time and data in the setting @xmath305 . for this purpose",
    ", we first show the intractability of learning disjunctive multiplicity expressions from positive and negative examples i.e. , in the setting @xmath306 .",
    "we study the complexity of checking the consistency of a set of positive and negative examples and we prove the intractability of @xmath307 .",
    "intuitively , this follows from the fact that , given a set of unordered words , there may exist an exponential number of minimal consistent disjunctive multiplicity expressions , and we may need to check all of them to decide whether there exist negative examples satisfying them .",
    "formally , we have the following result :    [ lemma : cons ] @xmath307 is np - complete .",
    "we prove the np - hardness by reduction from @xmath308 which is known as being np - complete .",
    "we take a formula @xmath309 in 3cnf containing the clauses @xmath310 over the variables @xmath311 .",
    "we generate a sample @xmath312 over the alphabet @xmath313 such that :    * @xmath314 , * @xmath315 , * @xmath316 , for @xmath317 , * @xmath318 , where @xmath319 , for any @xmath320 such that @xmath321 , where @xmath322 are the literals used in the clause @xmath323 and for any @xmath324 such that @xmath325 , @xmath326 is @xmath327 if @xmath328 is a negative literal in @xmath323 , and @xmath329 otherwise .",
    "for example , for the formula @xmath330 , we generate the sample : @xmath331 for a given @xmath309 , a valuation is a function @xmath332 .",
    "each of the @xmath333 possible valuations encodes a minimal disjunctive multiplicity expression @xmath334 consistent with the positive examples from @xmath312 , constructed as follows : @xmath335 where , for @xmath317 , if @xmath336 then @xmath337 and @xmath338 .",
    "otherwise , @xmath339 and @xmath340 .",
    "next , we show that , for any valuation @xmath341 , @xmath342 iff @xmath334 is consistent with @xmath312 .    for the _ only if _ case , consider a valuation @xmath341 such that @xmath342 and we take the corresponding expression @xmath343 .",
    "note that @xmath344 and all @xmath345 s ( with @xmath317 ) satisfy @xmath334 , while @xmath42 does not satisfy @xmath334 .",
    "also note that for @xmath317 , one symbol between @xmath346 and @xmath347 occurs at least once , while the other occurs at most once , so all @xmath348 s do not satisfy @xmath334 .",
    "assume that there is a @xmath349 ( with @xmath321 ) such that @xmath349 satisfies @xmath334 , which by construction implies that the clause @xmath323 is not satisfied by the valuation @xmath341 , which implies a contradiction .",
    "hence , @xmath349 does not satisfy @xmath334 for any @xmath321 .",
    "therefore , @xmath334 is consistent with @xmath312 .",
    "for the _ if _ case , we assume that @xmath334 is consistent with the sample @xmath312 .    since the @xmath349 s ( with @xmath321 )",
    "encode the valuations making the clauses @xmath323 s false and none of the @xmath349 s satisfies @xmath334 , then the valuation @xmath341 encoded in @xmath334 makes the formula @xmath309 satisfiable .",
    "the construction of @xmath312 also ensures that if there exists a disjunctive multiplicity expression consistent with @xmath312 , it has the form of @xmath334 . therefore , @xmath350 iff @xmath351 .    to prove the membership of @xmath307 to np",
    ", we point out that a turing machine guesses a disjunctive multiplicity expression @xmath76 , whose size is linear in @xmath352 since repetitions are discarded among the disjunctions of @xmath76 . moreover ,",
    "checking whether @xmath76 is consistent with the sample can be easily done in polynomial time .",
    "we extend the above result to @xmath353 :    @xmath353 is np - complete .",
    "the np - hardness of @xmath307 implies the np - hardness of @xmath353 : it is sufficient to consider flat trees having all the same root label .    moreover , to prove the membership of @xmath353 to np , a turing machine guesses a disjunctive multiplicity schema @xmath106 , whose size is polynomial in @xmath352 , and checks whether @xmath106 is consistent with the sample ( which can be done in polynomial time ) .",
    "since consistency checking in the presence of positive and negative examples is intractable for dms , we conclude that :    [ th : dms : pos - neg ] unless p = np , the concept class @xmath104 is not learnable in polynomial time and data from positive and negative examples i.e. , in the setting @xmath354 .",
    "we have studied the problem of learning unordered xml schemas from examples given by the user . we have investigated the learnability of dms and ms in two settings : one allowing positive examples only , and one that allows both positive and negative examples . to the best of our knowledge",
    ", no research has been done on learning unordered xml schema formalisms , nor on allowing both positive and negative examples in the process of schema learning .",
    "we have proven that the dms are learnable only from positive examples , and we have shown that they are not learnable from positive and negative examples by using the intractability of the consistency checking . moreover , we have proven that the ms are learnable in both settings : from only positive examples , and also from positive and negative examples .",
    "for all the learnable cases we have proposed learning algorithms that return minimal schemas consistent with the examples .    as future work , we want to use a more specific learnability condition i.e. , to require the size ( instead of the cardinality ) of the characteristic sample to be polynomial in the size of the alphabet .",
    "thus , we will fully adhere to the classical definition of the characteristic sample in the context of grammatical inference  @xcite .",
    "our preliminary research indicates that we are able to do this by using a compressed representation of the xml documents with directed acyclic graphs  @xcite .",
    "the learning algorithms that we propose in this paper will work without any alteration .",
    "moreover , we would like to extend our learning algorithms for more expressive unordered schemas , for instance schemas which allow _ numeric occurrences",
    "_  @xcite of the form @xmath355}$ ] that generalize multiplicities by requiring the presence of at least @xmath356 and at most @xmath357 elements @xmath33 . additionally , we want to use the learning algorithms for unordered schemas to boost the existing learning algorithms for twig queries  @xcite . for this purpose",
    ", we have to investigate first the problem of query minimization  @xcite in the presence of dms .",
    "next , we want to propose a twig query learning algorithm which infers the schema of the documents and then it uses the schema to improve the quality of the learned twig query ."
  ],
  "abstract_text": [
    "<S> we consider unordered xml , where the relative order among siblings is ignored , and we investigate the problem of learning schemas from examples given by the user . </S>",
    "<S> we focus on the schema formalisms proposed in  @xcite : _ disjunctive multiplicity schemas _ ( dms ) and its restriction , _ disjunction - free multiplicity schemas _ ( ms ) . </S>",
    "<S> a learning algorithm takes as input a set of xml documents which must satisfy the schema ( i.e. , _ positive examples _ ) and a set of xml documents which must not satisfy the schema ( i.e. , _ negative examples _ ) , and returns a schema consistent with the examples . </S>",
    "<S> we investigate a learning framework inspired by gold  @xcite , where a learning algorithm should be _ sound _ i.e. , always return a schema consistent with the examples given by the user , and _ complete _ i.e. , able to produce every schema with a sufficiently rich set of examples . additionally , the algorithm should be _ efficient _ i.e. , polynomial in the size of the input . </S>",
    "<S> we prove that the dms are learnable from positive examples only , but they are not learnable when we also allow negative examples . moreover , we show that the ms are learnable in the presence of positive examples only , and also in the presence of both positive and negative examples . furthermore , for the learnable cases , the proposed learning algorithms return minimal schemas consistent with the examples . </S>"
  ]
}