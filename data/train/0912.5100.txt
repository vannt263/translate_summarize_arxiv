{
  "article_text": [
    "in this paper , we have analyzed the nuclear norm relaxation for a general class of noisy observation models , and obtained non - asymptotic error bounds on the frobenius norm that hold under high - dimensional scaling .",
    "in contrast to most past work , our results are applicable to both exactly and approximately low - rank matrices .",
    "we stated a main theorem that provides high - dimensional rates in a fairly general setting , and then showed how by specializing this result to some specific model classes  namely , low - rank multivariate regression , estimation of autoregressive processes , and matrix recovery from random projections ",
    "it yields concrete and readily interpretable rates .",
    "lastly , we provided some simulation results that showed excellent agreement with the predictions from our theory .",
    "this paper has focused on achievable results for low - rank matrix estimation using a particular polynomial - time method .",
    "it would be interesting to establish matching lower bounds , showing that the rates obtained by this estimator are minimax - optimal .",
    "we suspect that this should be possible , for instance by using the techniques exploited in raskutti et al .",
    "@xcite in analyzing minimax rates for regression over @xmath4-balls .",
    "[ secdiscussion ]",
    "this work was partially supported by a sloan foundation fellowship , afosr-09nl184 grant , and an nsf - ccf-0545862 career grant to mjw .",
    "part ( a ) of the claim was proved in recht et al .",
    "@xcite ; we simply provide a proof here for completeness .",
    "we write the svd as @xmath5 , where @xmath6 and @xmath7 are orthogonal matrices , and @xmath8 is the matrix formed by the singular values of @xmath9 . by re - ordering",
    "as needed , we may assume without loss of generality that the first @xmath10 columns of @xmath11 ( respectively @xmath12 ) correspond to the matrices @xmath13 ( respectively @xmath14 ) from the statement .",
    "we then define the matrix @xmath15 , and write it in block form as @xmath16 we now define the matrices @xmath17 note that we have @xmath18 which establishes lemma  [ lemrestricted](a ) .",
    "moreover , we note for future reference that by construction of @xmath19 , the nuclear norm satisfies the decomposition @xmath20    we now turn to the proof of lemma  [ lemrestricted](b ) .",
    "recall that the error @xmath21 associated with any optimal solution must satisfy the inequality  , which implies that @xmath22 where we have used the bound  .    using the triangle inequality and the relation  ,",
    "we have @xmath23 consequently , we have @xmath24 substituting this inequality into the bound  , we obtain @xmath25 finally , since @xmath26 by assumption , we conclude that @xmath27 from which the bound   follows .",
    "let @xmath28 denote the euclidean sphere in @xmath29-dimensions .",
    "the operator norm of interest has the variational representation @xmath30 for positive scalars @xmath31 and @xmath32 , define the ( random ) quantity @xmath33 and note that our goal is to upper bound @xmath34 .",
    "note moreover that @xmath35 , a relation which will be useful in the analysis .",
    "let @xmath36 and @xmath37 denote @xmath38 coverings of @xmath39 and @xmath40 , respectively .",
    "we now claim that we have the upper bound @xmath41 to establish this claim , we note that since the sets @xmath42 and @xmath43 are @xmath38-covers , for any pair @xmath44 , there exists a pair @xmath45 such that @xmath46 and @xmath47 , with @xmath48 .",
    "consequently , we can write @xmath49 by construction , we have the bound @xmath50 , and similarly @xmath51 as well as @xmath52 . substituting these bounds into the decomposition   and taking suprema over the left and right - hand sides ,",
    "we conclude that @xmath53 from which the bound   follows .",
    "we now apply the union bound to control the discrete maximum",
    ". it is known ( e.g. ,  @xcite ) that there exists a @xmath38 covering of @xmath39 and @xmath40 with at most @xmath54 and @xmath55 elements respectively .",
    "consequently , we have @xmath56 & \\leq 8^{{\\ensuremath{k}}+ { \\ensuremath{{\\ensuremath{p } } } } } \\max_{u^a , v^b } \\ ; \\ ; { \\ensuremath{\\mathbb{p}}}\\left [ \\frac { |\\inprod{{\\ensuremath{x}}v^b}{{\\ensuremath{w}}u^a}|}{{\\ensuremath{n } } } \\geq \\delta \\right ] .\\end{aligned}\\ ] ] it remains to obtain a good bound on the quantity @xmath57 , where @xmath58 are arbitrary but fixed . since @xmath59 has i.i.d . @xmath60 elements and @xmath61 is fixed , we have @xmath62 for each @xmath63 . these variables are independent of one another , and of the random matrix @xmath64 . therefore , conditioned on @xmath64 ,",
    "the sum @xmath65 is zero - mean gaussian with variance @xmath66 define the event @xmath67 . using lemma  [ lemmultivarrsc ]",
    ", we have @xmath68 with probability at least @xmath69 , which implies that @xmath70 \\leq 2 \\exp(-{\\ensuremath{n}}/2)$ ]",
    ". therefore , conditioning on the event @xmath71 and its complement @xmath72 , we obtain @xmath73 & \\leq { \\ensuremath{\\mathbb{p}}}\\big [ |z| \\geq t \\mid { \\ensuremath{\\mathcal{t}}}\\big ] + { \\ensuremath{\\mathbb{p}}}[{\\ensuremath{\\mathcal{t}}}^c ] \\\\ & \\leq \\exp \\left ( -{\\ensuremath{n}}\\frac{t^2}{2 { \\ensuremath{\\nu}}^2 \\,(4 + { \\ensuremath{\\matsnorm{\\sigma}{{\\ensuremath{\\operatorname{op } } } } } } ) } \\right ) + 2 \\exp(-{\\ensuremath{n}}/2).\\end{aligned}\\ ] ] combining this tail bound with the upper bound  , we have @xmath74 & \\leq 8^{{\\ensuremath{k}}+ { \\ensuremath{{\\ensuremath{p } } } } } \\left \\ { \\exp \\left ( -{\\ensuremath{n}}\\frac{t^2}{18 { \\ensuremath{\\nu}}^2 { \\ensuremath{\\matsnorm{\\sigma}{{\\ensuremath{\\operatorname{op } } } } } } } \\right ) + 2 \\exp(-{\\ensuremath{n}}/2 ) \\right \\}.\\end{aligned}\\ ] ] setting @xmath75 , this probability vanishes as long as @xmath76 .",
    "in this appendix , we collect the proofs of lemmas  [ lemautoregressiversc ] and  [ lemautoregressivenoise ] .      recalling that @xmath77 denotes the unit - norm euclidean sphere in @xmath29-dimensions , we first observe that @xmath78 .",
    "our next step is to reduce the supremum to a maximization over a finite set , using a standard covering argument .",
    "let denote a @xmath79-cover of it . by definition , for any @xmath80",
    ", there is some @xmath81 such that @xmath82 , where @xmath83 .",
    "consequently , for any @xmath84 , the triangle inequality implies that @xmath85 and hence that @xmath86 .",
    "re - arranging yields the useful inequality @xmath87    using inequality  , we have @xmath88    & \\leq { \\ensuremath{\\mathbb{p}}}\\biggr [ \\max_{u^a \\in { \\ensuremath{\\mathcal{a } } } } \\frac{1}{{\\ensuremath{n } } }    \\sum_{i=1}^{\\ensuremath{n}}(\\inprod{u^a}{{\\ensuremath{x}}_i})^2 >",
    "\\frac{t}{2 } \\biggr ]    \\nonumber \\\\ &   \\label{eqnunionroma } \\leq 4^{\\ensuremath{p}}\\ , \\max_{u^a \\in { \\ensuremath{\\mathcal{a } } } } \\ ,   { \\ensuremath{\\mathbb{p}}}\\biggr [      \\frac{1}{{\\ensuremath{n } } } \\sum_{i=1}^{\\ensuremath{n}}(\\inprod{u^a}{{\\ensuremath{x}}_i})^2 >      \\frac{t}{2 } \\biggr ] .\\end{aligned}\\ ] ] where the last inequality follows from the union bound , and the fact  @xcite that there exists a @xmath79-covering of @xmath77 with at most @xmath89 elements .    in order to complete the proof",
    ", we need to obtain a sharp upper bound on the quantity valid for any fixed @xmath80 .",
    "define the random vector @xmath90 with elements @xmath91 . note that @xmath92 is zero mean , and its covariance matrix @xmath93 has elements in order to bound the spectral norm of @xmath93",
    ", we note that since it is symmetric , we have and moreover @xmath94 combining the pieces , we obtain @xmath95 . applying lemma  [ lemmeta ] with @xmath96 , we conclude that @xmath97 \\ ; \\leq \\ ; 2 \\exp \\big ( - 5 { \\ensuremath{p}}\\big ) + 2 \\exp -{\\ensuremath{n}}/2 ) .. \\end{aligned}\\ ] ]    combined with the bound  , we obtain @xmath98 with probability at least @xmath99 , which establishes the upper bound  ( a ) .    turning to the lower bound  ( b ) , we let @xmath100 be an @xmath101-cover of @xmath77 for some @xmath102 to be chosen .",
    "thus , for any @xmath103 , there exists some @xmath104 such that @xmath105 , and @xmath106 .",
    "define the function @xmath107 via @xmath108 , and note that @xmath109 . with this notation",
    ", we have @xmath110 since @xmath111 . since @xmath112",
    ", we obtain the lower bound @xmath113 by the previously established upper bound(a ) , have @xmath114 with high probability .",
    "hence , choosing @xmath115 ensures that    consequently , it suffices to lower bound the minimum over the covering set .",
    "we first establish a concentration result for the function @xmath116 that holds for any fixed @xmath117 .",
    "note that we can write @xmath118 as before , if we define the random vector @xmath90 with elements @xmath119 , then @xmath120 with @xmath121 .",
    "moreover , we have @xmath122 .",
    "consequently , applying lemma  [ lemmeta ] yields @xmath123 &    \\leq 2 \\exp \\big ( - { \\ensuremath{n}}(t- 2/\\sqrt{{\\ensuremath{n}}})^2/2 \\big ) + 2    \\exp ( -\\frac{{\\ensuremath{n}}}{2}),\\end{aligned}\\ ] ] note that this bound holds for any fixed @xmath117 .",
    "setting @xmath124 and applying the union bound yields that @xmath125 & \\leq \\ ; \\big ( \\frac{4}{\\epsilon }    \\big)^{\\ensuremath{p}}\\ ; \\biggr \\ { 2 \\exp \\big ( - { \\ensuremath{n}}(t^*-    2/\\sqrt{{\\ensuremath{n}}})^2/2 \\big ) + 2 \\exp ( -\\frac{{\\ensuremath{n}}}{2 } ) \\biggr    \\},\\end{aligned}\\ ] ] which vanishes as long as @xmath126 .",
    "let @xmath28 denote the euclidean sphere in @xmath29-dimensions , and for positive scalars @xmath31 and @xmath32 , define the random variable @xmath127 . note that our goal is to upper bound @xmath34 .",
    "let @xmath36 and @xmath128 denote @xmath38 coverings of @xmath77 and @xmath77 , respectively .",
    "following the same argument as in the proof of lemma  [ lemmultivarnoise ] , we obtain the upper bound @xmath129 we now apply the union bound to control the discrete maximum",
    ". it is known ( e.g. ,  @xcite ) that there exists a @xmath38 covering of @xmath77 with at most @xmath130 elements .",
    "consequently , we have @xmath131 & \\leq 8^{2 { \\ensuremath{p } } } \\max_{u^a , v^b } \\ ; \\ ; { \\ensuremath{\\mathbb{p}}}\\big [ \\frac{|\\inprod{{\\ensuremath{x}}v^b}{{\\ensuremath{w}}u^a}|}{{\\ensuremath{n } } } \\geq \\delta \\big].\\end{aligned}\\ ] ] it remains to obtain a tail bound on the quantity @xmath132 $ ] , for any fixed pair    for each @xmath133 , let @xmath134 and @xmath135 denote the @xmath136 row of @xmath64 and @xmath137 . following some simple algebra",
    ", we have the decomposition @xmath138 , where @xmath139 we may now bound each @xmath140 in turn ; in doing so , we make repeated use of lemma  [ lemmeta ] , which provides concentration bounds for a random variable of the form @xmath141 , where for some matrix @xmath142 .    [",
    "[ bound - on - ensurematht_2 ] ] bound on @xmath143 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we begin with @xmath143 , which the easiest to control since ( up to scaling by @xmath144 ) , it corresponds to the deviation away from the mean of @xmath145-variable with @xmath146 degrees of freedom .",
    "consequently , applying lemma  [ lemmeta ] with @xmath147 , we obtain @xmath148 & \\leq 2 \\exp \\big   ( -\\frac{{\\ensuremath{n}}\\ , ( t - 2/\\sqrt{{\\ensuremath{n}}})^2}{2 } \\big ) + 2 \\exp (   -{\\ensuremath{n}}/2).\\end{aligned}\\ ] ]    [ [ bound - on - ensurematht_3 ] ] bound on @xmath149 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we can write the term @xmath149 as a deviation of @xmath150 from its mean , where in this case the covariance matrix @xmath151 is no longer the identity . in concrete terms , let us define a random vector @xmath90 with elements @xmath119 . as seen in the proof of lemma  [ lemautoregressiversc ] from appendix  [ applemautoregressiversc ] ,",
    "the vector @xmath92 is zero - mean gaussian with covariance matrix @xmath93 such that @xmath152 ( see equation  ) .",
    "since we have @xmath153 , applying lemma  [ lemmeta ] yields that @xmath154 & \\leq \\ ; 2 \\exp \\big ( - \\frac{{\\ensuremath{n}}\\ , ( t \\ , -\\",
    ", 2/\\sqrt{{\\ensuremath{n}}})^2}{2 }",
    "\\big ) + 2 \\exp ( -{\\ensuremath{n}}/2).\\end{aligned}\\ ] ]    [ [ bound - on - ensurematht_1 ] ] bound on @xmath155 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    to control this quantity , let us define a zero - mean gaussian random vector @xmath156 with elements @xmath157 .",
    "this random vector has covariance matrix @xmath158 with elements @xmath159 = { \\ensuremath{\\nu}}^2 \\delta_{ij } + ( 1-\\delta_{ij } )    { \\ensuremath{\\nu}}^2 v^t ( { \\ensuremath{{\\ensuremath{\\theta^*}}}})^{|i - j|-1 } u + v^t ( { \\ensuremath{{\\ensuremath{\\theta^*}}}})^{|i - j| }    \\sigma v,\\ ] ] where @xmath160 is the kronecker delta for the event @xmath161 .",
    "as before , by symmetry of @xmath158 , we have @xmath162 , and hence @xmath163",
    "morever , we have @xmath164 , so that by applying lemma  [ lemmeta ] , we conclude that @xmath165 \\ ; \\leq \\ ;   2    \\exp \\big ( - \\frac{{\\ensuremath{n}}\\ , ( t \\ , -\\ , 2/\\sqrt{{\\ensuremath{n}}})^2}{2 }",
    "\\big ) + 2 \\exp(-{\\ensuremath{n}}/2),\\ ] ] which completes the analysis of this term .    combining the bounds  ,   and",
    ", we conclude that for all @xmath166 , @xmath167 & \\leq 6 \\exp \\big ( - \\frac{{\\ensuremath{n}}\\ , ( t \\ , -\\ , 2/\\sqrt{{\\ensuremath{n}}})^2}{2 } \\big ) + 6 \\exp(-{\\ensuremath{n}}/2).\\end{aligned}\\ ] ] setting @xmath168 and combining with the bound  , we conclude that @xmath169 & \\leq 8^{2 { \\ensuremath{p } } } \\ : \\big \\ { 6 \\exp(-16 { \\ensuremath{p } } ) + 6 \\exp(-{\\ensuremath{n}}/2 ) \\big \\ } \\ ; \\leq 12 \\exp(-{\\ensuremath{p } } ) \\end{aligned}\\ ] ] as long as @xmath170 .",
    "note that @xmath171 , and that since the claim   is invariant to rescaling , it suffices to prove it for all @xmath172 with @xmath173 . letting @xmath174 be a given radius , we seek lower bounds on the quantity @xmath175 in particular , our goal is to prove that for any @xmath174 , the lower bound @xmath176^{1/2 } \\;{\\ensuremath{t}}\\ ] ] holds with probability at least @xmath177 . by a standard peeling argument ( see raskutti et al .",
    "@xcite for details ) , this lower bound implies the claim  .",
    "we establish the lower bound   using gaussian comparison inequalities  @xcite and concentration of measure ( see lemma  [ lemconcentration ] ) . for each pair @xmath178 , consider the random variable @xmath179 , and note that it is gaussian with zero mean .",
    "for any two pairs @xmath180 and @xmath181 , some calculation yields @xmath182 & =   \\matsnorm{u \\otimes    \\theta - u ' \\otimes \\theta'}{f}^2.\\end{aligned}\\ ] ] we now define a second gaussian process @xmath183 via @xmath184 where @xmath185 and @xmath186 are independent with i.i.d .",
    "@xmath187 entries . by construction",
    ", @xmath188 is zero - mean , and moreover , for any two pairs @xmath180 and @xmath189 , we have @xmath190 & =   \\|u - u'\\|_2 ^ 2 + \\matsnorm{\\theta - \\theta'}{f}^2.\\end{aligned}\\ ] ] it can be shown that for all pairs @xmath191 , we have @xmath192 moreover , equality holds whenever @xmath193 .",
    "the conditions of the gordon - slepian inequality  @xcite are satisfied , so that we are guaranteed that @xmath194\\ ; = \\ ; \\exs \\biggr[\\inf_{\\theta \\in { \\ensuremath{\\mathcal{r}}}({\\ensuremath{t } } ) } \\sup_{u \\in      { \\ensuremath{s^{{\\ensuremath{n}}-1 } } } } z_{u , \\theta } \\biggr ] & \\geq \\exs \\biggr[\\inf_{\\theta \\in { \\ensuremath{\\mathcal{r}}}({\\ensuremath{t } } ) } \\sup_{u \\in      { \\ensuremath{s^{{\\ensuremath{n}}-1 } } } } y_{u , \\theta } \\biggr]\\end{aligned}\\ ] ] we compute @xmath195 & = \\exs \\biggr [ \\sup_{u \\in      { \\ensuremath{s^{{\\ensuremath{n}}-1 } } } } \\inprod{g}{u } \\biggr ] + \\exs \\biggr [ \\inf_{\\theta \\in      { \\ensuremath{\\mathcal{r}}}({\\ensuremath{t } } ) } \\tracer{g}{\\theta } \\biggr ] \\\\ & = \\exs[\\|g\\|_2 ] - \\exs[\\sup_{\\theta \\in { \\ensuremath{\\mathcal{r}}}({\\ensuremath{t } } ) }    \\tracer{g}{\\theta } ] \\\\ & \\geq \\frac{1}{2 } \\sqrt{{\\ensuremath{n } } } - { \\ensuremath{t}}\\ , \\exs[{\\ensuremath{\\matsnorm{g}{{\\ensuremath{\\operatorname{op}}}}}}].\\end{aligned}\\ ] ] since @xmath186 has i.i.d .",
    "@xmath187 entries , standard random matrix theory  @xcite implies that @xmath196 \\leq \\sqrt{{\\ensuremath{k } } } + \\sqrt{{\\ensuremath{{\\ensuremath{p}}}}}$ ] .",
    "putting together the pieces , we conclude that @xmath197 & \\geq \\frac{1}{2 } - \\frac{\\sqrt{{\\ensuremath{k } } } + \\sqrt{{\\ensuremath{{\\ensuremath{p}}}}}}{\\sqrt{{\\ensuremath{n } } } } \\ , { \\ensuremath{t}}.\\end{aligned}\\ ] ]    finally , we need to establish sharp concentration around the mean .",
    "note that the function @xmath198 is lipschitz with constant @xmath199 , so that lemma  [ lemconcentration ] implies that @xmath200 &    \\leq 2 \\exp(-{\\ensuremath{n}}\\delta^2/2 ) \\qquad \\mbox{for all $ \\delta > 0$.}\\end{aligned}\\ ] ] setting @xmath201 yields the claim .",
    "the following lemma is classical  @xcite , and yields sharp concentration of a lipschitz function of gaussian random variables around its mean .",
    "[ lemconcentration ] let @xmath202 have i.i.d .",
    "@xmath187 entries , and let and @xmath203 be lipschitz with constant @xmath204 ( i.e. , @xmath205 @xmath206 ) . then for all @xmath166",
    ", we have @xmath207 \\ ; \\leq    \\ ; 2 \\exp{\\big ( -\\frac{t^2}{2 l^2 } \\big ) } .\\ ] ] by exploiting this lemma , we can prove the following result , which yields concentration of the squared @xmath208-norm of an arbitrary gaussian vector : + [ lemmeta ] given a gaussian random vector @xmath209 , for all @xmath210 , we have @xmath211 \\ ; \\leq \\ ;     2 \\exp{\\left ( -    \\frac{{\\ensuremath{n}}(t- \\frac{2}{\\sqrt{{\\ensuremath{n}}}})^2}{2 } \\right ) } + 2    \\exp{(-{\\ensuremath{n}}/2)}.\\ ] ]    let @xmath212 be the symmetrix matrix square root , and consider the function since it is lipschitz with constant @xmath213 , lemma  [ lemconcentration ] implies that @xmath214 \\leq 2 \\exp \\left ( -\\frac{{\\ensuremath{n}}\\delta^2}{2 { \\ensuremath{\\matsnorm{q}{{\\ensuremath{\\operatorname{op } } } } } } } \\right ) \\qquad \\mbox{for all $ \\delta > 0$.}\\ ] ] by integrating this tail bound , we find that the variable @xmath215 satisfies the bound @xmath216 , and hence conclude that @xmath217 } - |\\exs[z]| \\big| & = \\big| \\sqrt{\\trace(q)/{\\ensuremath{n } } } - \\exs[\\|\\sqrt{q } x\\|_2/\\sqrt{{\\ensuremath{n}}}]\\big| \\ ; \\leq \\ ; \\frac{2 \\sqrt{{\\ensuremath{\\matsnorm{q}{{\\ensuremath{\\operatorname{op}}}}}}}}{\\sqrt{{\\ensuremath{n}}}}.\\end{aligned}\\ ] ] combining this bound with the tail bound  , we conclude that @xmath218 \\leq 2    \\exp \\left ( -\\frac{{\\ensuremath{n}}\\delta^2}{2 { \\ensuremath{\\matsnorm{q}{{\\ensuremath{\\operatorname{op } } } } } } } \\right )    \\qquad \\mbox{for all    $ \\delta > 0$.}\\ ] ]    setting @xmath219 in the bound   yields that @xmath220 \\leq 2    \\exp \\left ( -\\frac{{\\ensuremath{n}}(t-2/\\sqrt{{\\ensuremath{n}}})^2}{2 } \\right ) .\\end{aligned}\\ ] ] similarly , setting @xmath221 in the tail bound   yields that with probability greater than @xmath69 , we have @xmath222 using these two bounds , we obtain @xmath223 with the claimed probability .",
    "s.  negahban , p.  ravikumar , m.  j. wainwright , and b.  yu . a unified framework for high - dimensional analysis of m - estimators with decomposable regularizers . in _ proceedings of the nips",
    "conference _ , vancouver ,",
    "canada , december 2009 .",
    "g.  raskutti , m.  j. wainwright , and b.  yu .",
    "minimax rates of estimation for high - dimensional linear regression over @xmath224-balls .",
    "technical report arxiv:0910.2042 , uc berkeley , department of statistics , 2009 . presented in part at allerton conference ,",
    "p.  ravikumar , m.  j. wainwright , g.  raskutti , and b.  yu .",
    "high - dimensional covariance estimation : convergence rates of @xmath225-regularized log - determinant divergence . technical report , department of statistics , uc berkeley , september 2008 . presented in part at nips 2008 ."
  ],
  "abstract_text": [
    "<S> high - dimensional inference refers to problems of statistical estimation in which the ambient dimension of the data may be comparable to or possibly even larger than the sample size . </S>",
    "<S> we study an instance of high - dimensional inference in which the goal is to estimate a matrix @xmath0 on the basis of @xmath1 noisy observations , and the unknown matrix @xmath2 is assumed to be either exactly low rank , or `` near '' low - rank , meaning that it can be well - approximated by a matrix with low rank . </S>",
    "<S> we consider an @xmath3-estimator based on regularization by the trace or nuclear norm over matrices , and analyze its performance under high - dimensional scaling . </S>",
    "<S> we provide non - asymptotic bounds on the frobenius norm error that hold for a general class of noisy observation models , and then illustrate their consequences for a number of specific matrix models , including low - rank multivariate or multi - task regression , system identification in vector autoregressive processes , and recovery of low - rank matrices from random projections . </S>",
    "<S> simulation results show excellent agreement with the high - dimensional scaling of the error predicted by our theory .    * *    [ cols=\"^ \" , ] </S>"
  ]
}