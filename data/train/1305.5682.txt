{
  "article_text": [
    "while the average treatment effect can be easily estimated without bias in randomized experiments , treatment effect heterogeneity plays an essential role in evaluating the efficacy of social programs and medical treatments .",
    "we define treatment effect heterogeneity as the degree to which different treatments have differential causal effects on each unit . for example , ascertaining subpopulations for which a treatment is most beneficial ( or harmful ) is an important goal of many clinical trials .",
    "however , the most commonly used method , subgroup analysis , is often inappropriate and remains one of the most debated practices in the medical research community [ e.g. , @xcite ] .",
    "estimation of treatment effect heterogeneity is also important when ( 1 ) selecting the most effective treatment among a large number of available treatments , ( 2 ) designing optimal treatment regimes for each individual or a group of individuals [ e.g. , @xcite ] , ( 3 ) testing the existence or lack of heterogeneous treatment effects [ e.g. , @xcite ] , and ( 4 ) generalizing causal effect estimates obtained from an experimental sample to a target population [ e.g. , @xcite ] . in all of these cases , the researchers must infer how treatment effects vary across individual units and/or how causal effects differ across various treatments .",
    "two well - known randomized evaluation studies in the social sciences serve as the motivating applications of this paper .",
    "earlier analyses of these data sets focused upon the estimation of the overall average treatment effects and did not systematically explore treatment effect heterogeneity .",
    "first , we analyze the get - out - the - vote ( gotv ) field experiment where many different mobilization techniques were randomly administered to registered new haven voters in the 1998 election [ @xcite ] .",
    "the original experiment used an incomplete , unbalanced factorial design , with the following four factors : a personal visit , 7 possible phone messages , 0 to 3 mailings , and one of three appeals applied to visit and mailings ( civic duty , neighborhood solidarity , or a close election ) .",
    "the voters in the control group did not receive any of these gotv messages .",
    "additional information on each voter includes age , residence ward , whether registered for a majority party , and whether the voter abstained or did not vote in the 1996 election . here",
    ", our goal is to identify a set of gotv mobilization strategies that can best increase turnout . given the design , there exist 193 unique treatment combinations , and the number of observations assigned to each treatment combination ranges dramatically , from the minimum of 4 observations ( visited in person , neighbor / civic - neighbor phone appeal , two mailings , with a civic appeal ) to the maximum of @xmath0 ( being visited in person , with any appeal ) .",
    "the methodological challenge is to extract useful information from such sparse data .",
    "the second application is the evaluation of the national supported work ( nsw ) program , which was conducted from 1975 to 1978 over 15 sites in the united states .",
    "disadvantaged workers who qualified for this job training program consisted of welfare recipients , ex - addicts , young school dropouts , and ex - offenders .",
    "we consider the binary outcome indicating whether the earnings increased after the job training program ( measured in 1978 ) compared to the earnings before the program ( measured in 1975 ) .",
    "the pre - treatment covariates include the 1975 earnings , age , years of education , race , marriage status , whether a worker has a college degree , and whether the worker was unemployed before the program ( measured in 1975 ) .",
    "our analysis considers two aspects of treatment effect heterogeneity .",
    "first , we seek to identify the groups of workers for whom the training program is beneficial .",
    "the program was administered to the heterogeneous group of workers and , hence , it is of interest to investigate whether the treatment effect varies as a function of individual characteristics .",
    "second , we show how to generalize the results based on this experiment to a target population . such an analysis is important for policy makers who wish to use experimental results to decide whether and how to implement this program in a target population .    to address these methodological challenges ,",
    "we formulate the estimation of heterogeneous treatment effects as a variable selection problem [ see also @xcite ] .",
    "we propose the squared loss support vector machine ( l2-svm ) with separate lasso constraints over the pre - treatment and causal heterogeneity parameters ( section  [ secmodel ] ) .",
    "the use of two separate constraints ensures that variable selection is performed separately for variables representing alternative treatments ( in the case of the gotv experiment ) and/or treatment - covariate interactions ( in the case of the job training experiment ) . not only",
    "do these variables differ qualitatively from others , they often have relatively weak predictive power .",
    "the proposed model avoids the ad - hoc variable selection of existing procedures by achieving optimal classification and variable selection in a single step [ e.g. , @xcite ] .",
    "the model also directly incorporates sampling weights into the estimation procedure , which are useful when generalizing the causal effects estimates obtained from an experimental sample to a target population .    to fit the proposed model with multiple regularization constraints , we develop an estimation algorithm based on a generalized cross - validation ( gcv ) statistic .",
    "when the derivation of an optimal treatment regime rather than the description of treatment effect heterogeneity is of interest , we can replace the gcv statistic with the average effect size of the optimal treatment rule [ @xcite ] . the proposed methodology with the gcv statistic does not require cross - validation and hence is more computationally efficient than the commonly used methods for estimation of treatment effect heterogeneity such as boosting [ @xcite ] , bayesian additive regression trees ( bart ) [ @xcite ] , and other tree - based approaches [ e.g. , @xcite , @xcite ] . while most similar to a bayesian logistic regression with noninformative prior [ @xcite ] , the proposed method uses lasso constraints to produce a parsimonious model .",
    "to evaluate the empirical performance of the proposed method , we analyze the aforementioned two randomized evaluation studies ( section  [ secapplications ] ) .",
    "we find that personal visits are uniformly more effective than any other treatment method , while sending three mailings with a civic duty message is the most effective treatment without a visit . in addition , every mobilization strategy with a phone call , but no personal visit , is estimated to have either a negative or negligible positive effect . for the job training study , we find that the program is most effective for low - education , high income non - hispanics , unemployed blacks with some college , and unemployed hispanics with some high school .",
    "in contrast , the program would be least effective when administered to old , unemployed recipients , unmarried whites with a high school degree but no college , and high earning hispanics with no college .    finally , we conduct simulation studies to compare the performance of the proposed methodology with that of various alternative methods ( section  [ secsimulations ] ) .",
    "the proposed method admits the possibility of no treatment effect and yields a low false discovery rate , when compared to the nonsparse alternative methods that _ always _ estimate some effects . despite reductions in false discovery ,",
    "the method remains statistically powerful .",
    "we find that the proposed method has a comparable discovery rate and competitive predictive properties to these commonly used alternatives .",
    "in this section we describe the proposed methodology by presenting the model and developing a computationally efficient estimation algorithm to fit the model .      we describe our method within the potential outcomes framework of causal inference .",
    "consider a simple random sample of @xmath1 units from population @xmath2 , with a possibly different target population of inference @xmath3 .",
    "for example , the researchers and policy makers may wish to apply the gotv mobilization strategies and the job training program to a population , of which the study sample is not representative .",
    "we consider a multi - valued treatment variable @xmath4 , which takes one of @xmath5 values from @xmath6 where @xmath7 means that unit @xmath8 is assigned to the control condition . in the gotv study",
    ", we have a total of 193 treatment combinations ( @xmath9 ) , whereas the job training program corresponds to a binary treatment variable ( @xmath10 ) .",
    "the potential outcome under treatment @xmath11 is denoted by @xmath12 , which has support @xmath13 .",
    "thus , the observed outcome is given by @xmath14 and we define the causal effect of treatment @xmath15 for unit  @xmath8 as @xmath16 .    throughout",
    ", we assume that there is no interference among units , there is a unique version of each treatment , each unit has nonzero probability of assignment to each treatment level , and the treatment level is independent of the potential outcomes , possibly conditional on observed covariates [ @xcite ] .",
    "such assumptions are met in randomized experiments , which are the focus of this paper . under these assumptions",
    ", we can identify the average treatment effect ( ate ) for each treatment @xmath15 , @xmath17 .",
    "in observational studies , additional difficulty arises due to the possible existence of unmeasured confounders .",
    "one commonly encountered problem related to treatment effect heterogeneity requires selecting the most effective treatment from a large number of alternatives using the causal effect estimates from a finite sample .",
    "that is , we wish to identify the treatment condition @xmath15 such that @xmath18 is the largest , that is , @xmath19",
    ". we may also be interested in identifying a subset of the treatments whose ates are positive .",
    "when the number of treatments @xmath20 is large as in the gotv study , a  simple strategy of subsetting the data and conducting a separate analysis for each treatment suffers from the lack of power and multiple testing problems .",
    "another common challenge addressed in this paper is identifying groups of units for which a treatment is most beneficial ( or most harmful ) , as in the job training program study .",
    "often , the number of available pre - treatment covariates , @xmath21 , is large , but the heterogeneous treatment effects can be characterized parsimoniously using a subset of these covariates , @xmath22 . this problem can be understood as identifying a sparse representation of the conditional average treatment effect ( cate ) , using only a subset of the covariates .",
    "we denote the cate for a unit with covariate profile @xmath23 as @xmath24 , which can be estimated as the difference in predicted values under @xmath11 and @xmath7 with @xmath25 .",
    "the sparsity in covariates greatly eases interpretation of this model .",
    "we next turn to the description of the proposed model that combines optimal classification and variable selection to estimate treatment effect heterogeneity . for the remainder of the paper",
    ", we focus on the case of binary outcomes , that is , @xmath26 .",
    "however , the proposed model and algorithm can be extended easily to nonbinary outcomes by modifying the loss function .",
    "we choose to model binary outcomes with the l2-svm to illustrate our proposed methodology because it presents one of the most difficult cases for implementing two separate lasso constraints .",
    "as we discuss below , our method can be simplified when the outcome is nonbinary ( e.g. , continuous , counts , multinomial , hazard ) or the causal estimand of interest is characterized on a log - odds scale ( with a logistic loss ) . in particular , readily available software can be adapted to handle these cases [ @xcite ] .      in modeling treatment effect heterogeneity",
    ", we transform the observed binary outcome to @xmath27 .",
    "we then relate the estimated outcome @xmath28 and the estimated latent variable @xmath29 , as @xmath30 @xmath31 is an @xmath32 dimensional vector of treatment effect heterogeneity variables , and @xmath33 is an @xmath34 dimensional vector containing the remaining covariates .",
    "for example , when identifying the most efficacious treatment condition among many alternative treatments , @xmath31 would consist of @xmath20 indicator variables ( e.g. , different combinations of mobilization strategies ) , each of which is representing a different treatment condition .",
    "in contrast , @xmath33 would include pre - treatment variables to be adjusted ( e.g. , age , party registration , turnout history ) .",
    "similarly , when identifying groups of units most helped ( or harmed ) by a treatment , @xmath31 would include variables representing interactions between the treatment variable ( e.g. , the job training program ) and the pre - treatment covariates of interest ( e.g. , age , education , race , prior employment status and earnings ) . in this case",
    ", @xmath33 would include all the main effects of the pre - treatment covariates .",
    "thus , we separate the causal heterogeneity variables of interest from the rest of the variables .",
    "we do not impose any restriction between main and interaction effects because some covariates may not predict the baseline outcome but do predict treatment effect heterogeneity .",
    "finally , we choose the linear model because it allows for easy interpretation of interaction terms .",
    "however , the researchers may also use the logistic or other link function within our framework .    in estimating @xmath35 , we adapt the support vector machine ( svm ) classifier and place separate lasso constraints over each set of coefficients [ @xcite ] .",
    "our model differs from the standard model by allowing @xmath36 and @xmath37 to have separate lasso constraints .",
    "the model is motivated by the qualitative difference between the two parameters , and also by the fact that often causal heterogeneity variables have weaker predictive power than other variables .",
    "specifically , we formulate the svm as a penalized squared hinge - loss objective function ( hereafter l2-svm ) where the hinge - loss is defined as @xmath38 [ @xcite ] .",
    "we focus on the l2-svm , rather than the l1-svm , because it returns the standard difference - in - means estimate for the treatment effect in the absence of pre - treatment covariates .    with two separate @xmath39 constraints to generate sparsity in the covariates , our estimates",
    "are given by @xmath40 are pre - determined separate lasso penalty parameters for @xmath36 and @xmath37 , respectively , and @xmath41 is an optional sampling weight , which may be used when generalizing the results obtained from one sample to a target population .",
    "our objective function is similar to several existing lasso variants but there exist important differences .",
    "for example , the elastic net introduced by @xcite places the same set of covariates under both a lasso and ridge constraint to help reduce mis - selections among correlated covariates .",
    "in addition , the group lasso introduced by @xcite groups different levels of the same factor together so that all levels of a factor are selected without sacrificing rotational invariance . in contrast , the proposed method places separate lasso constraints over the qualitatively distinct groups of variables .",
    "the l2-svm offers two different means to estimate heterogeneous treatment effects .",
    "first , we can predict the potential outcomes @xmath12 directly from the fitted model and estimate the conditional treatment effect ( cte ) as the difference between the predicted outcome under the treatment status @xmath15 and that under the control condition , that is , @xmath42 .",
    "this quantity utilizes the fact that the l2-svm is an optimal classifier [ @xcite ] .",
    "second , we can also estimate the cate . to do this",
    ", we interpret the l2-svm as a truncated linear probability model over a subinterval of @xmath43 $ ] .",
    "while it is known that the svm does not return explicit probability estimates [ @xcite ] , we follow work that transforms the values @xmath44 to approximate the underlying probability [ @xcite ] .",
    "specifically , let @xmath45 denote the predicted value @xmath44 truncated at positive and negative one .",
    "we estimate the cate as the difference in truncated values of the predicted outcome variables , that is , @xmath46 . while this cate estimate is not precisely a difference in probabilities , the method provides a useful approximation and returns sensible results that comport with probabilistic estimates of the cate . with an estimated cate for each covariate profile",
    ", the cate for any covariate profile can be estimated by simply aggregating these estimates among corresponding observations .",
    "our algorithm proceeds in three steps : the data are rescaled , the model is fitted for a given value of @xmath47 , and each fit is evaluated using a generalized cross - validation statistic .",
    "_ rescaling the covariates_. lasso regularization requires rescaling covariates [ @xcite ] . following standard practice ,",
    "we standardize all pre - treatment main effects by centering them around the mean and dividing them by standard deviation .",
    "higher - order terms are recomputed using these standardized variables . for causal heterogeneity variables ,",
    "we do not standardize them when they are indicator variables representing different treatments .",
    "when they represent the interactions between a treatment indicator variable and pre - treatment covariates , we interact the ( unstandardized ) treatment indicator variable with the standardized pre - treatment variables .",
    "_ fitting the model_. the l2-svm is fitted through a series of iterated lasso fits , based on the following two observations .",
    "first , we note that for a given outcome @xmath48 , @xmath49 .",
    "thus , the svm is a least squares problem on a subset of the data .",
    "second , for a given value of @xmath50 , rescaling @xmath51 and @xmath52 allows the objective function to be written as a lasso problem , with a tuning parameter of 1 , as @xmath53 where @xmath54 , @xmath55 , @xmath56 , and @xmath57 .",
    "this allows a fitting strategy via the efficient lasso algorithm of @xcite .",
    "specifically , each iteration of our algorithm consists of fitting a model on the set of `` active '' observations @xmath58 and updating this set .",
    "we now describe the proposed algorithm in greater detail .",
    "first , the values of tuning parameters are selected , @xmath59 .",
    "we then select the initial values of the coefficients and fitted values as follows , @xmath60 and @xmath61 for all @xmath8 .",
    "this places all observations in the initial active set , so that @xmath62 .",
    "next , for each iteration @xmath63 let @xmath64 denote the set of active observations , and @xmath65 represent the number of observations in this set . define @xmath66 and @xmath67 as the centered versions of @xmath68 and @xmath69 ( around their respective mean ) , respectively , using only the observations in the current active set @xmath70 .",
    "similarly , we use @xmath71 to denote the centered value of @xmath72 using only the observations in @xmath70 .",
    "then , at each iteration @xmath73 , the algorithm progresses in three steps .",
    "we update the lasso coefficients  as @xmath74 the fitted value is updated as @xmath75 where the intercept is @xmath76 .",
    "these steps are repeated until @xmath35 converges .",
    "work concurrent to ours has developed an algorithm for the regularization path of the l2-svm [ @xcite ] .",
    "future work can combine our work and that of @xcite in order to estimate the whole `` regularization surface '' implied by a model with two constraints .    _ selecting the optimal values of the tuning parameters_. we choose the optimal values of the tuning parameters , @xmath77 , based on a generalized cross - validation ( gcv ) statistic [ @xcite ] , so that the model fit is balanced against model dimensionality .",
    "the number of nonzero elements of @xmath78 provides an unbiased degree - of - freedom estimate for the lasso [ @xcite ] .",
    "our gcv statistic is defined over the observation in the active set @xmath79 , as follows : @xmath80 where the second equality follows from the fact that the observations outside of @xmath79 does not affect the model fit , that is , @xmath81 for @xmath82 .    given this gcv statistic , we use an alternating line search to find the optimal values of the tuning parameters .",
    "first , we fix @xmath83 at a large value , for example , @xmath84 , effectively setting all causal heterogeneity parameters to zero [ @xcite ] .",
    "next , @xmath85 is evaluated along the set of widely spaced grids , for example , @xmath86 , with the value producing the smallest gcv statistic selected .",
    "given the current estimate of @xmath85 , @xmath83 is evaluated along the set of widely spaced grids , for example , @xmath86 , and the @xmath85 that produces the smallest gcv statistic is selected .",
    "we alternate in a line search between the two parameters to convergence .",
    "after convergence , the radius is decreased based on these converged parameter values , and the precision is increased to the desired level , for example , @xmath87 .",
    "the final estimates of coefficients are estimated given the converged value of @xmath47 .",
    "the use of this gcv statistic is reasonable when exploring the degree to which the treatment effects are heterogeneous .",
    "however , if the goal is to derive the optimal treatment rule , the researchers may wish to directly target a particular measure of the performance of the learned policy .",
    "for example , following @xcite and @xcite , we could use the largest average treatment effect as the statistic ( known as `` value statistic '' ) for cross - validation .",
    "in addition to its computational burden , one practical difficulty of cross - validation based on the value statistic is that when the total number of causal heterogeneity variables is large and the sample size is relatively small as in our applications , we may not have many observations in the test sample that actually received the same treatment as the one prescribed by the optimal treatment rule .",
    "in addition , the training sample may have empty cells so that they do not predict treatment effects for some individuals in the test set .",
    "this makes it difficult to apply this procedure in some situations .",
    "the use of the gcv statistic is also computationally efficient as it avoids cross - validation .",
    "comparing computation times across competitors is difficult , as they can vary dramatically depending on the number of cross - validating folds ( boosting , lasso ) , iterations ( boosting ) , the number of mcmc draws and number of trees ( bart ) , and desired precision in estimating the tuning parameters ( lasso , svm ) .",
    "the general pattern from our simulations is that the computational time for the proposed method is significantly greater than the bayesian glm , tree , and the cross - validated logistic lasso with a single constraint .",
    "it is comparable to bart and significantly less than cross - validated boosting .",
    "finally , in a recent paper , @xcite propose a method that is related to ours .",
    "there are several important differences between the two methods .",
    "first , we are primarily interested in feature selection using lasso penalties , whereas @xcite focus on prediction using an @xmath88 penalty . while we use a simple parametric model with a large number of features , @xcite place their method within a nonparametric , reproducing kernel framework . in kernelizing the covariates",
    ", they achieve better prediction but at the cost of difficulty in interpreting precisely which features are driving the treatment rule .",
    "second , we use two separate lasso penalties for causal heterogeneity variables and pre - treatment covariates , whereas @xcite do not make this distinction .",
    "third , our tuning parameter is a gcv statistic , which eliminates the computational burden of cross - validation as used by @xcite",
    "in this section we apply the proposed method to two well - known field experiments in the social sciences .",
    "first , we analyze the get - out - the - vote ( gotv ) field experiment where 69 mobilization techniques were randomly administered to registered new haven voters in the 1998 election [ @xcite ] .",
    "it is known in the gotv literature that there is substantial interference among voters in the same household [ @xcite ] .",
    "thus , to avoid the problem of possible interference between voters , we focus on @xmath89 voters in single voter households where @xmath90 voters of them belong to the control group and hence did not receive any of these gotv messages . addressing this interference issue fully requires an alternative experimental design where the treatment conditions correspond to different number of voters within the same household who receive the gotv message ( our method is still applicable to the data from this experimental design because it can handle multi - valued treatments ) .",
    "for the purpose of illustration , we also ignore the implementation problems documented in @xcite and analyze the most recent data set .    in our specification , the causal heterogeneity variables @xmath31 include the binary indicator variables of 192 treatment combinations , that is , @xmath91 .",
    "we include a set of noncausal variables @xmath33 , which consist of the main effect terms of four pre - treatment covariates ( age , member of a majority party , voted in 1996 , abstained in 1996 ) , their two - way interaction terms , and the square of the age variable , that is , @xmath92 .",
    "@lcccd2.2@ & + & + * visit * & * phone * & * mailings * & * appeal type * & + yes & no & 0 & any & 3.06 + yes & no & 3 & civic & 2.64 + yes & no & 3 & close & 2.31 + yes & civic , close & 0 & close , neighbor & 2.04 + yes & no & 12 & close & 1.60 + yes & no & 3 & civic & 1.50 + yes & civic , close & 13 & civic , close & 1.46 + yes & none , civic / neighbor , neighbor & 12 & neighbor & 1.46 + yes & none , civic & @xmath93 & civic , neighbor & 1.46 + no & no & 3 & civic & 1.17 + no & no & 2 & civic & 1.14 + no & close & @xmath94 & close & 0.81 + yes & civic / blood , neighbor , neighbor / civic & 3 & civic , neighbor & 0.80 + no & close & 2 & close & 0.74 + no & no & 3 & close & 0.70 + yes & civic / blood , civic & 13 & civic & 0.53 + no & no & 3&neighbor & 0.04 + yes & civic / blood & 13 & civic & -0.64 + no & neighbor / civic & 3 & neighbor&-0.65 + no & civic / blood & @xmath95 & civic & -0.91 + no & civic / blood & 2 & civic & -0.99 + no & civic / blood , civic & @xmath95 & civic & -2.07 + no & no & 2 & close&-2.08 + no & civic / blood & 2 & civic & -2.14 + no & civic , civic / blood , neighbor & 1 & civic , neighbor & -2.60 + no & neighbor & 2 & neighbor & -2.67 + no & neighbor & 3 & neighbor & -3.24 + no & civic & 01 & neighbor & -3.49 + no & civic & 2 & neighbor & -3.56 + no&civic & 3 & neighbor & -4.12 +    of the 192 possible treatment effect combinations , 15 effects are estimated as nonzero ( see table  [ ggcoefs ] in ) .",
    "as these coefficients range from main effects to four - way interactions , they are difficult to interpret . instead , we present the estimated treatment effect for every treatment combination in table [ ggeffects ] . some of our results are consistent with the prior analysis .",
    "first , canvassing in person is the most effective gotv technique .",
    "this result can be obtained even from a simple use of the difference - in - means estimator ( estimated 2.69 percentage point with @xmath15-statistic of 2.68 ) .",
    "second , every mobilization strategy that consists of a phone call and no personal visit is estimated with a nonpositive sign , suggesting that the marginal effect of a phone call is either zero or slightly negative .",
    "most prominently , phone messages with a neighborhood appeal or civic appeal decrease turnout .",
    "the proposed method also yields finer findings than the existing analyses .",
    "for example , since personal canvassing is expensive , campaigns may be interested in the most effective treatment that does not include canvassing .",
    "we find that three mailings with a civic responsibility message and no phone calls or personal visits increase turnout marginally by 1.17 percentage point .",
    "this result is similar to the one independently obtained in another study [ @xcite ] .",
    "three mailings with other appeals produce smaller effects ( 1.17 and 0.04 percentage point increase , resp . ) .",
    "finally , the proposed method , upon considering all possible treatments , produces clear prescriptions .",
    "first , in the presence of canvassing , any additional treatment ( phone call , mailing ) will lessen the canvassing s effectiveness .",
    "if voters are canvassed , they should not receive additional treatments .",
    "second , if voters are not canvassed , they should be targeted with three mailings with a civic duty appeal .",
    "any other treatment combination will be less cost - effective , and may even suppress turnout .",
    "next , we apply the proposed methodology to the national supported work ( nsw ) program .",
    "our analysis focuses upon the subset of these individuals previously used by other researchers [ @xcite ] where the ( randomly selected ) treatment and control groups consist of 297 and 425 such workers , respectively .",
    "we consider two aspects of treatment effect heterogeneity .",
    "first , we seek to identify the groups of workers for whom the training program is beneficial .",
    "the program was administered to a heterogeneous group of workers and , hence , it is of interest to investigate whether the treatment effect varies as a function of individual characteristics .",
    "second , we show how to generalize the results based on this experiment to a target population . such an analysis is important for policy makers who wish to use experimental results to decide whether and how to implement this program in a target population .    for illustration , we generalize the experimental results to the 1978 panel study of income dynamics ( psid ) , which oversamples low - income individuals . within this psid sample",
    ", we focus on 253 workers who had been unemployed at some point in the previous year to avoid severe extrapolation .",
    "this subsample is labeled psid-2 in @xcite .",
    "the differences across the two samples are substantial .",
    "the psid respondents are on average older ( @xmath96 vs. @xmath97 years old ) and more likely to be married ( @xmath98 vs. @xmath99 ) and have a college degree ( @xmath100 vs. @xmath101 ) than nsw participants .",
    "the proportion of blacks in the psid sample ( @xmath102 ) is much less than in the nsw sample ( @xmath103 ) .",
    "in addition , on average , psid respondents earned more income ( $ 7600 ) than nsw participants ( $ 3000 ) .",
    "all differences , except for proportion hispanic , are statistically significant at the 5% level .    in our model ,",
    "the matrix of noncausal variables , @xmath52 , consists of 45 pre - treatment covariates .",
    "these include the main effects of age , years of education , and the log of one plus 1975 earnings , as well as binary indicators for race , marriage status , college degree , and whether the individual was unemployed in 1975 .",
    "we also use square terms for age and years of education , and every possible two - way interactions among the pre - treatment covariates are included .",
    "the matrix of causal heterogeneity variables @xmath51 includes the binary treatment and interactions between this treatment variable and each of the 39 pre - treatment covariates .",
    "this yields @xmath104 and @xmath105 .",
    "using this specification , we first fit the model to the nsw sample to identify the subpopulations of workers for whom the job training program is beneficial .",
    "second , we generalize these results to the psid sample and estimate the ate and cate for these low - income workers .",
    "unfortunately , sampling weights are not available in the original data and , hence , for the purpose of illustration , we construct them by fitting a bart model , using @xmath52 as predictors [ @xcite ] .",
    "we then take the inverse estimated probability of being in the nsw sample as the weights for the proposed method [ @xcite ] . to facilitate comparison between the unweighted and weighted models , we standardize the weights to have a mean equal to one . a weight greater than one signifies an observation that is weighted more highly in the psid model than in the nsw model .",
    "this allows us to assess the extent to which differences in identified heterogeneous effects reflect underlying differences in the covariate distributions between the nsw and psid samples .    after fitting the model to the unweighted and weighted nsw samples",
    ", the cate is estimated using the covariate value of each observation , that is , @xmath106 .",
    "the sample average of these cates yields an ate estimate of @xmath107 and @xmath108 percentage points for the nsw and psid samples , respectively .",
    "nonzero coefficients from the fitted models are shown in table  [ lalondecoefs ] of the .",
    "as with the previous example , interpreting high order interactions is difficult . thus , we present the groups of workers who are predicted to experience the ten highest and lowest treatment effects of the job training program in the nsw ( table  [ nswhighlow ] ) and psid sample ( table  [ psidhighlow ] ) .",
    "the groups most helped , and hurt , by the treatment were identified by matching the observations in these tables to the nonzero coefficients .    across both tables , unemployed hispanics and",
    "highly educated , low - earning non - hispanics are predicted to benefit from the program .",
    "similarly , workers who were older and employed and whites with a high school degree are identified as those who are negatively affected by the program .",
    "weights marked with asterisks in each table indicate heterogeneous effects that are not identified in the other table .",
    "for example , unemployed blacks with some college are identified as beneficiaries only in table  [ nswhighlow ] , while married whites with no high school degree only appear in table  [ psidhighlow ] .",
    "this difference is explained by the fact that unemployed blacks with some college make up 2.7% of the nsw sample but only 0.4% of the psid sample .",
    "similarly , married whites with no high school degree make up 15.8% of the psid sample and are identified in table  [ psidhighlow ] , but only make up 0.1% of the nsw sample and are not identified in table  [ nswhighlow ] .",
    "indeed , when generalizing the results to a different population , large groups in that population are more likely to be selected for heterogeneous treatment effects .",
    "weighting allows us to efficiently estimate heterogeneous treatment effects in a target population .",
    "in this section we conduct two simulation studies to evaluate the performance of the proposed method relative to the commonly used methods : bart ( r package ` bayestree ` ) , bayesian logistic regression with a noninformative prior ( r package ` arm ` ) , conditional inference trees [ @xcite ; r package ` party ` ] , boosting with the number of iterations selected by cross - validation ( as implemented in r package ` ada ` ) , and logistic regression with a single lasso constraint and cross - validation on the `` value '' statistic [ @xcite ; r package ` glmnet ` ] .",
    "the first set of simulations corresponds to the situation where the goal is to select a set of the most effective treatments among many alternatives .",
    "the second set considers the case where we wish to identify a subpopulation of units for which a treatment is most effective . in both cases ,",
    "we assume that the treatment @xmath4 is independent of the observed pre - treatment covariates @xmath109 .",
    "the logistic lasso method is only applied to the second set of simulations for the reason mentioned in section  [ subsecalgorithm ] . finally ,",
    "for each scenario , we examine 4 different sample sizes between @xmath110 and @xmath111 and run @xmath112 simulations .",
    "we conduct simulations for selecting a set of the best treatments among a large number of available treatments .",
    "we use two settings , one with the correct model specification and the other with misspecified models , where un - modeled nonlinear terms are added to the data generating process . in the simulations with correct model specification , we have one control condition , 49 distinct treatment conditions , and  3 pre - treatment covariates .",
    "that is , @xmath31 consists of 49 treatment indicator variables and @xmath33 is a vector of 3 pre - treatment covariates plus an intercept , that is , @xmath113 and @xmath114 . among 49 treatments , 3 of them",
    "have substantive effects ; the ate is approximately equal to @xmath115 , @xmath116 , and @xmath117 percentage points , respectively .",
    "the remaining  46 treatment indicator variables have nonzero but negligible effects , with the average effect sizes ranging within @xmath118 percentage point .",
    "in contrast , all pre - treatment covariates are assumed to have substantial predictive power .",
    "we independently sample the pre - treatment covariates from a multivariate normal distribution with mean zero and a randomly generated covariance matrix .",
    "specifically , an @xmath119 matrix , @xmath120 $ ] , was generated with @xmath121 and the covariance matrix is given by @xmath122 .",
    "the design matrix for the 49 treatment variables is orthogonal and balanced .",
    "the true values of the coefficients are set as @xmath123 and @xmath124 , where @xmath125 denotes 47 remaining coefficients drawn from a uniform distribution on @xmath126 $ ] .",
    "finally , the outcome variable @xmath127 is sampled according to the following model ; @xmath128 with @xmath129 selected such that the magnitude of the ates roughly equals the values specified above .",
    "for the simulations with an incorrectly specified model , we include unmodeled nonlinear terms based on the pre - treatment covariates in the data generating process .",
    "specifically , @xmath33 now includes the interaction term between the first and second pre - treatment covariates and the square term of the third pre - treatment covariate as well as the main effect term for each of the three covariates .",
    "these higher - order terms are used to generate the data , but not included as covariates in fitting any model . as before , the outcome variable is generated after an affine transformation in order to keep the size of the ates approximately equal to the pre - specified levels given above .",
    "figure  [ figfirstsims ] summarizes the results in terms of false discovery rate ( fdr ) and discovery rate ( dr ) separately for the largest and substantive effects .",
    "we define discovery as estimating the largest effect ( three largest effects ) as the largest effect ( nonzero effects ) with the correct sign .",
    "similarly , false discovery occurs when the largest effect is not correctly discovered _ and _ at least one coefficient is estimated to be nonzero .",
    "fdr may not equal one minus dr because the former is based only on the simulations where at least one coefficient is estimated to be nonzero .",
    "the first row presents fdr for the largest effect whereas the second row presents its dr .",
    "similarly , the third row plots the fdr for the three largest effects while the fourth row presents their dr .",
    "note that fewer than three nonzero effects may be estimated.=-1    the results show that across simulations the proposed method ( ` svm ` ; solid lines ) has a smaller fdr while its dr is competitive with other methods .",
    "the comparison with bart reveals a key feature of our method .",
    "the proposed method dominates bart in fdr regardless of model specification .",
    "the largest estimated effect from bart identifies the largest effect slightly more frequently , but at the cost of a higher fdr . despite its low fdr ,",
    "our method maintains a competitive dr . for many methods ,",
    "model misspecification increases fdr and reduces dr .",
    "for this reason , we recommend erring in favor of including too many rather than too few pre - treatment covariates in the model .    unlike three of its competitors , boosting , conditional inference trees , and bayesian glm",
    ", the performance of the proposed method improves as the sample size increases . boosting and trees",
    "both attain an fdr and dr of zero as the sample size grows .",
    "the tree focuses in on the largest effects , not identifying any small effects as the sample size grows .",
    "this may be due to the fact that trees do not converge asymptotically to the true conditional mean function unless the underlying function is piecewise constant ( though they converge to the minimal risk ) [ see , e.g. , @xcite ] .",
    "the boosting algorithm uses trees as base learners , which may be leading to the deteriorating performance in identifying small effects .",
    "the performance of bayesian glm also declines with increasing sample size , because we are not considering uncertainty in the posterior mean estimates . to address this issue",
    ", one must use some @xmath130-value based regularization , such as using a @xmath130-value threshold of @xmath131 ( see figure [ figusvsbayes ] in the next set of simulations for illustration ) .      in the second set of simulations , we consider the problem of identifying groups of units for which a treatment is beneficial ( or harmful ) . here",
    ", we are interested in identifying interactions between a treatment and observed pre - treatment covariates .",
    "the key difference between this simulation and the previous one is that in the current setup causal heterogeneity variables ( treatment - covariate interactions ) may be correlated with each other as well as other noncausal variables .",
    "the previous simulation setting assumes that causal heterogeneity variables ( treatment indicators ) are independent of each other and other variables . in this simulation",
    ", we also include a comparison with the logistic regression with a single lasso constraint and the maximal ten - fold cross - validation on the `` value '' statistic [ @xcite ] .",
    "this statistic is the expected benefit from a particular treatment rule [ see also @xcite ] . note that in the previous simulation , due to a large number of treatments , cross - validation on this statistic is not feasible .",
    "-value less than @xmath132 ) . here",
    ", discovery is defined as estimating the largest effect ( four largest effects ) as the largest effect ( nonzero effects ) with the correct sign .",
    "the top and bottom plots in the first ( second ) column present the fdr and dr for the largest effect ( three largest effects ) , respectively . ]    in the current simulation , we have a single treatment condition , that is , @xmath133 , and 20 pre - treatment covariates @xmath109 .",
    "the pre - treatment covariates are all based on the multivariate normal distribution with mean zero and a random variance - covariance matrix as in the previous simulation study , with five covariates then discretized using 0.5 as a threshold .",
    "causal heterogeneity variables @xmath31 consist of 20 treatment - covariate interactions plus the main effect for the treatment indicator ( @xmath134 ) , while @xmath33 is composed of the main effects for the pre - treatment covariates ( @xmath135 ) .    given this setup ,",
    "we generate the outcome variable @xmath136 in the same way as in section  [ subsecbest ] according to the linear probability model .",
    "there are 4 pre - treatment covariates that interact with the treatment in a systematic manner .",
    "as before , we apply an affine transformation so that an observation whose values for these two covariates are one standard deviation above the mean has the cate of roughly  @xmath137 and @xmath138 percentage points .",
    "that is , we set @xmath139 and @xmath140 where the @xmath125 denotes uniform draws from @xmath126 $ ] .",
    "figure  [ figusvsbayes ] compares the fdr and dr for our proposed method ( ` svm ` ; solid lines ) with those for the logistic lasso ( ` lasso ` ) and bayesian logistic regression ( ` glm ` ; dotted and dashed lines ) .",
    "for the bayesian glm , we consider two rules : one based on posterior means of coefficients ( dashed lines ) and the other selecting coefficients with @xmath130-values below @xmath132 ( dotted lines ) . unlike the simulations given in section  [ subsecbest ] , neither bart , boosting , nor conditional inference trees provide a simple rule for variable selection in this setting and hence no results are reported .",
    "the interpretation of these plots is identical to that of the plots in figure  [ figfirstsims ] . in the left column , the top ( bottom ) plot presents fdr ( dr ) for the largest effect , whereas that of the right column presents fdr ( dr ) for the four largest effects .",
    "when compared with the bayesian glm , the proposed method has a lower fdr for both largest and four largest estimated effects .",
    "the @xmath130-value thresholding improves the bayesian glm , and yet the proposed method maintains a much lower fdr and comparable dr .",
    "relative to the lasso , the proposed method is not as effective in considering the largest estimated effect except that it has a lower fdr when the sample size is small .",
    "however , when considering the four largest estimated effects , the proposed method maintains a lower fdr than the lasso , and a comparable dr .",
    "this result is consistent with the fact that the value statistic targets the largest treatment effect while the gcv statistic corresponds to the overall fit.=-1    to further evaluate our method , we consider a situation where each method is applied to a sample and then used to generate a treatment rule for each individual in another sample . for each method ,",
    "a payoff , characterized by the net number of people in the new sample who are assigned to treatment and are in fact helped by the treatment , is calculated .",
    "to represent a budget constraint faced by most researchers , we specify the total number of individuals who can receive the treatment and vary this number within the simulation study.=-1    specifically , after fitting each model to an initial sample , we draw another simple random sample of 2000 observations from the same data generating process . using the result from each method , we calculate the predicted cate for each observation of the new sample , @xmath141 , and give the treatment to those with highest predicted cates until the number of treated observations reaches the pre - specified limit . finally , a payoff of the form @xmath142 is calculated for all treated observations of the new sample where @xmath143 is the true cate .",
    "this produces a payoff of @xmath144 if a treated observation is actually helped by the treatment , @xmath145 if the observation is harmed , and @xmath146 for untreated observations . as a baseline , we compare each method to the `` oracle '' treatment rule , @xmath147 , which administers the treatment only when helpful . we have also considered an alternative payoff of the form @xmath148 , representing how much ( rather than whether ) the treatment helps or harms .",
    "the results were qualitatively similar to those presented here.=-1    @ld4.0d3.0d3.0d3.0@ & + & + & & & & + & -2 & 11 & 22 & 42 + & -19 & -4 & 8 & 21 + & -18 & 2 & 15 & 28 + & -20 & -7 & 7 & 34 + & -1 & 10 & 18 & 40 + & 2 & 2 & 2 & 5 + & -123 & -121 & -121 & -116 +",
    "the results from the simulation are presented in table [ tabpayoff ] .",
    "the table presents a comparison of payoffs , by method , as a percentage of the optimal oracle rule , which is considered as @xmath149 .",
    "the bottom row presents the outcome if every observation were treated , indicating that in this simulation the average treatment effect is negative but there exists a subgroup for which treatment is beneficial . the proposed method ( ` svm ` )",
    "narrowly dominates boosting ( ` boost ` ) , and both the proposed method and boosting noticeably outperform all other competitors , except conditional inference trees ( ` tree ` ) at sample size 250 . at larger sample sizes ,",
    "however , the tree severely underfits .",
    "while the proposed method and boosting perform similarly by a predictive criterion , boosting does not return an interpretable model .",
    "we also find that ` svm ` outperforms ` lasso ` , which is consistent with the fact that the gcv statistic targets the overall performance while the value statistic focuses on the largest treatment effect . if administering the treatment is costless , the proposed method generates the most beneficial treatment rule among its competitors .",
    "figure  [ figposneg ] presents the results across methods and sample sizes in the presence of a budget constraint .",
    "the left column shows the proportion of treated units that actually benefit from the treatment for each observation considered for the treatment in the order of predicted cate ( the horizontal axis ) .",
    "the oracle identifies those who certainly benefit from the treatment and treats them first .",
    "the middle column shows the proportion of treated units that are hurt by the treatment . here , the oracle never hurts observations and hence is represented by the horizontal line at zero .",
    "the right column presents the net benefit by treatment rule , which can be calculated as the difference between the positive ( left column ) and negative ( middle column ) effects .",
    "each row presents a different sample size to which each method is applied .",
    "the figure shows that when the sample size is small , the proposed method assigns fewer observations a harmful treatment , relative to its competitors . for moderate and large sample sizes",
    ", the proposed method dominates its competitors in both identifying a group that would benefit from the treatment and avoiding treating those who would be hurt .",
    "this can be seen from the plots in the middle column where the result based on the proposed method ( ` svm ` ; solid thick lines ) stays close to the horizontal zero line when compared to other methods .",
    "similarly , in the right column , the results based on the proposed method stay above other methods .",
    "when these lines go below zero , it implies that a majority of treated observations would be harmed by the treatment .",
    "the disadvantage of the proposed method is its conservativeness .",
    "this can be seen in the left column where at the beginning of the percentile the solid thick line is below its competitors for small sample sizes .",
    "this difference vanishes as the sample size increases , with the proposed method outperforming its competitors . in sum , when used to predict a treatment rule for out - of - sample observations , the proposed method makes fewer harmful prescriptions and often yields a larger net benefit than its competitors .",
    "estimation of heterogeneous treatment effects plays an essential role in scientific research and policy making . in particular , researchers often wish to select the most efficacious treatments from a large number of possible treatments and to identify individuals who benefit most ( or are harmed ) by treatments .",
    "estimation of treatment effect heterogeneity is also important when generalizing experimental results to a target population of interest .",
    "the key insight of this paper is to formulate the identification of heterogeneous treatment effects as a variable selection problem . within this framework ,",
    "we develop a support vector machine with two separate sparsity constraints , one for a set of treatment effect heterogeneity parameters of interest and the other for observed pre - treatment effect parameters .",
    "this setup addresses the fact that in many applications , pre - treatment covariates are much more powerful predictors than treatment variables of interest or their interactions with covariates . in addition , unlike the existing techniques such as boosting and bart , the proposed method yields a parsimonious model that is easy to interpret .",
    "our simulation studies show that the proposed method has low false discovery rates while maintaining competitive discovery rates .",
    "the simulation study also shows that the use of our gcv statistic is appropriate when exploring the treatment effect heterogeneity rather than identifying the single optimal treatment rule .",
    "@ld3.2d3.2@ & & + treatment intercept & 6.92 & 6.67 + _ main effects _ + age & 0.00 & -0.83 + married & 1.32 & 3.39 + white & 0.00 & 0.10 + _ squared terms _",
    "+ age@xmath150 & -0.03 & -0.09 + education@xmath150 & 0.89 & 0.86 + _ interaction terms _ + no hs degree , unemployed in 1975 & -1.06 & 0.00 + white , married & 0.00 & 26.16 + white , no hs degree & 25.35 & 30.65 + hispanic , logged 1975 earnings & -49.36 & -62.15 + black , logged 1975 earnings & 8.29 & 0.00 + white , education & 0.00 & -1.41 + married , education & 4.90 & 12.11 + married , logged 1975 earnings & 0.00 & 5.72 + education , unemployed in 1975 & 7.52 & 9.59 + age , education & 0.00 & -0.47 + age , black & -0.56 & 0.00 + age , hispanic & 0.00 & 0.34 + age , unemployed in 1975 & 3.30 & 4.79 +    a number of extensions of the method developed in this paper are possible .",
    "for example , we can accommodate other types of outcome variables by considering different loss functions . instead of the gcv statistic we use ,",
    "alternative criteria such as aic or bic statistics as well as more targeted quantities such as the average treatment effect for the target population can be employed .",
    "while we use lasso constraints , researchers may prefer alternative penalty functions such as the scad or adaptive lasso penalty .",
    "furthermore , although not directly examined in this paper , the proposed method can be extended to the situation where the goal is to choose the best treatment for each individual from multiple alternative treatments . finally , it is of interest to consider how the proposed method can be applied to observational data [ e.g. , see @xcite who develop a doubly robust estimator for optimal treatment regimes ] and longitudinal data settings where the derivation of optimal dynamic treatment regimes is a frequent goal [ e.g. , @xcite ] .",
    "the development of such methods helps applied researchers avoid the use of ad hoc subgroup analysis and identify treatment effect heterogeneity in a statistically principled manner .",
    "an earlier version of this paper was circulated under the title of `` identifying treatment effect heterogeneity through optimal classification and variable selection '' and received the tom ten have memorial award at the 2011 atlantic causal inference conference .",
    "we thank charles elkan , jake bowers , kentaro fukumoto , holger kern , michael rosenbaum , and sherry zaks for useful comments . the editor , associate editor , and two anonymous reviewers provided useful advice ."
  ],
  "abstract_text": [
    "<S> when evaluating the efficacy of social programs and medical treatments using randomized experiments , the estimated overall average causal effect alone is often of limited value and the researchers must investigate when the treatments do and do not work . </S>",
    "<S> indeed , the estimation of treatment effect heterogeneity plays an essential role in ( 1 ) selecting the most effective treatment from a large number of available treatments , ( 2 ) ascertaining subpopulations for which a treatment is effective or harmful , ( 3 ) designing individualized optimal treatment regimes , ( 4 ) testing for the existence or lack of heterogeneous treatment effects , and ( 5 ) generalizing causal effect estimates obtained from an experimental sample to a target population . in this paper , we formulate the estimation of heterogeneous treatment effects as a variable selection problem . </S>",
    "<S> we propose a method that adapts the support vector machine classifier by placing separate sparsity constraints over the pre - treatment parameters and causal heterogeneity parameters of interest . </S>",
    "<S> the proposed method is motivated by and applied to two well - known randomized evaluation studies in the social sciences . </S>",
    "<S> our method selects the most effective voter mobilization strategies from a large number of alternative strategies , and it also identifies the characteristics of workers who greatly benefit from ( or are negatively affected by ) a job training program . in our simulation studies , </S>",
    "<S> we find that the proposed method often outperforms some commonly used alternatives . </S>"
  ]
}