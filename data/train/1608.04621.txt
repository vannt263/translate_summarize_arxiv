{
  "article_text": [
    "the aim of this paper is to develop efficient and easy to implement importance sampling estimators of expectations of functionals of lvy processes , corresponding to option prices in exponential lvy models .",
    "lvy processes are stochastic processes with stationary independent increments .",
    "they are used as models for asset prices when jump risk is important , either directly ( as in the variance gamma model @xcite , normal inverse gaussian process @xcite , cgmy model @xcite ) or as building blocks for other models ( affine processes , stochastic volatility models with jumps , local lvy models @xcite etc . ) . to model a financial market with a lvy process , we assume that the market consists of a risk - free asset @xmath0 and @xmath1 risky assets @xmath2 such that @xmath3 where @xmath4 is a lvy process under the risk - neutral probability @xmath5 .",
    "we consider a derivative written on @xmath6 with pay - off @xmath7 which depends of the entire trajectory of the stocks .",
    "we are interested in computing the price of this derivative , given by the risk - neutral expectation @xmath8 $ ] .",
    "several methods for computing this expectation are available in the literature .",
    "when the price process @xmath9 is one - dimensional and the pay - off @xmath10 only depends on the terminal value @xmath11 , the fourier method of carr and madan @xcite may be used .",
    "when the dimension of @xmath9 is low ( say , up to 3 - 4 ) , and the pay - off is only weakly path - dependent , such as for barrier or american options , one can use deterministic numerical methods for partial integro - differential equations @xcite , fourier time stepping @xcite and related deterministic methods .",
    "finally , for high dimensional problems , or in the case of strong path dependence , the monte carlo method , on which we focus in this paper is the only one available .",
    "the standard monte carlo estimator of @xmath8 $ ] is defined as the empirical mean @xmath12 where @xmath13 are i.i.d .",
    "samples with the same law as @xmath9 .",
    "note that simulation methods exist for all parametric lvy models , including multidimensional lvy processes ( see chapter 6 of @xcite for a review ) .",
    "the precision of standard monte carlo is often too low for real - time applications , particularly when @xmath14 $ ] is small compared to @xmath15 and various error reduction techniques must be applied .    * the multilevel monte carlo method ( see @xcite for a general introduction and @xcite for an application to lvy models )",
    "reduces the variance by optimizing the number of discretization steps for each path . in practice",
    ", a large number of paths are simulated with a coarse discretization , and only a small number of paths are discretized finely . *",
    "the quasi monte carlo method ( see @xcite for the case of jump diffusions / lvy processes ) replaces the i.i.d .",
    "samples of @xmath9 with well - chosen deterministic samples ( low - discrepancy sequences ) . * finally , the importance sampling method , which is the focus of this paper , consists in simulating the paths of @xmath9 under a different probability measure , which allows a better exploration of the region of interest .",
    "see e.g. , @xcite for an application in the context of gaussian vectors , @xcite for the case of path - dependent options in the black - scholes model , @xcite for an application to stochastic volatility models , and @xcite for applications to lvy processes / jump - diffusions .",
    "the importance sampling estimator is based on the following identity , valid for any probability measure @xmath16 , with respect to which @xmath5 is absolutely continuous .",
    "@xmath17 = \\mathbb e^{\\mathbb q}\\left[\\frac{d\\mathbb      p}{d\\mathbb q}p(s)\\right].\\ ] ] this allows one to define the importance sampling estimator @xmath18^{(j ) } p(s^{(j)}_{\\mathbb q}),\\ ] ] where @xmath19 are i.i.d .",
    "sample trajectories of @xmath9 under the measure @xmath16 . for efficient variance reduction",
    ", one needs then to find a probability measure @xmath16 such that @xmath9 is easy to simulate under @xmath16 and the variance @xmath20\\ ] ] is considerably smaller than the original variance @xmath21 $ ] .    for lvy processes , a natural choice of probability measure for importance sampling is given by the esscher transform @xmath22},\\ ] ] which is well defined for all @xmath23 such that",
    "@xmath24 $ ] .",
    "this choice was studied , e.g. , in @xcite , where the optimal variance reduction parameter @xmath25 was estimated numerically .    in this paper , to allow for more freedom in choosing the importance sampling probability for path - dependent payoffs , we propose to use the path - dependent esscher transform , @xmath26 } x_t      \\cdot \\theta(dt)}}{\\mathbb e\\left[e^{\\int_{[0,t ] } x_t      \\cdot \\theta(dt)}\\right]},\\ ] ] where @xmath27 is a ( deterministic ) bounded @xmath28-valued signed measure on @xmath29 $ ] . under @xmath30 , the process @xmath31 has independent increments and is thus easy to simulate .",
    "the optimal choice of @xmath27 should minimize the variance of the estimator under @xmath30 , @xmath32 - \\mathbb e\\left[p\\right]^2.\\ ] ]    importance sampling is most effective in the context of _ rare event simulation _",
    ", e.g. , when @xmath33 for most of the trajectories of @xmath9 under the original measure @xmath5 . since the theory of large deviations is concerned with the study of probabilities of rare events , it is natural to use measure changes appearing in or inspired by the large deviations theory for importance sampling .",
    "we refer , e.g. , to @xcite and references therein for a review of this approach and to the above quoted references @xcite for specific applications to financial models .",
    "the main contribution of this paper , inspired by the work of guasoni and robertson @xcite in the setting of the black - scholes model , is to use the large deviations theory to construct an easily computable approximation to the optimal importance sampling measure @xmath34 .",
    "namely , we use varadhan s lemma and the pathwise large deviation principle for lvy processes due to leonard @xcite to derive a proxy for the variance of the importance sampling estimator which is much easier to compute than the true variance .",
    "we propose then to use the parameter @xmath25 , obtained by minimizing this proxy , in the importance sampling estimator .",
    "numerical illustrations in section [ num.sec ] show that the variance obtained by using @xmath25 instead of @xmath34 is very close to the optimal one , and that a considerable variance reduction is obtained in all examples with very little computational overhead .    when the logarithm of the pay - off @xmath10 is concave , which is the case in many applications , the proxy for the variance may be further simplified using convex duality .",
    "the computation of the asymptotically optimal parameter @xmath25 then reduces to one finite - dimensional optimization problem for european options and to the solution of one ode system ( euler - lagrange equations ) for the path - dependent ones .",
    "in other words , additional complexity is the same as in the case of the black - scholes model studied in @xcite , even though our model is much more general and complex .",
    "the rest of this paper is structured as follows . in section [ ld.sec ]",
    "we recall the notation and results from the theory of large deviations which are used in the paper .",
    "section [ main.sec ] provides a representation for the proxy of the variance , a simplified representation in the case of concave log - payoffs and an easy to verify criterion for concavity .",
    "section [ ex.sec ] presents explicit computations for european basket and asian options .",
    "numerical illustrations of these examples , in the context of the variance gamma model , are provided in section [ num.sec ] .",
    "lastly , the appendix contains a technical lemma .",
    "in this section we recall the known results on large deviations for lvy processes , which will be used in the sequel , and introduce all the necessary notation .",
    "we first formulate the large deviations principle ( ldp ) on abstract spaces .",
    "let @xmath35 be a haussdorf topological space endowed with its borel @xmath36-field .",
    "a rate function is a @xmath37$]-valued lower semi - continuous function on @xmath35 .",
    "it is said to be a good rate function is its level sets are compact .",
    "a family @xmath38 of @xmath35-valued random variables is said to obey a ldp in @xmath35 with rate function @xmath39 if for each open subset @xmath40 and each closed subset @xmath41 @xmath42 \\leq - \\inf_{x\\in f}i(x)\\ ] ] and @xmath43 \\geq - \\inf_{x\\in f}i(x).\\ ] ]    the following result is the famous varadhan s lemma , which allows to evaluate limits of functions of @xmath44 in the large deviations asymptotics .",
    "more precisely , we need an extension of this lemma , given in @xcite , which allows the function @xmath45 to take value @xmath46 .",
    "this is necessary since the pay - off of the option may take zero value on part of the domain , and the function @xmath45 will contain the log - pay - off in the sequel .",
    "suppose that @xmath47 satisfies the ldp with a good rate function @xmath48 and let @xmath49 be such that the set @xmath50 is open and @xmath45 is continuous on this set . assume further that for some @xmath51 ,",
    "@xmath52 < \\infty.\\ ] ] then , @xmath53 = \\sup_{x\\in \\mathcal x } \\left\\ { \\phi(x ) - i(x)\\right\\}.\\ ] ]    we shall next recall the pathwise large deviation principle for lvy processes , but first , following @xcite , we need to introduce specific topological spaces well suited for this application , and recall some preliminary results on lvy processes .    [ [ spaces - and - topologies ] ] spaces and topologies + + + + + + + + + + + + + + + + + + + + +    as usual , @xmath54 denotes the space of right - continuous functions with left limits ( rcll ) on the interval @xmath29 $ ] .",
    "the subspace of @xmath54 containing all functions on @xmath29 $ ] with bounded variation will be denoted by @xmath55 .",
    "the symbol @xmath56 will denote the class of bounded @xmath28-valued measures on @xmath29 $ ] .",
    "note that there is a one - to - one correspondence between elements of @xmath55 and those of @xmath56 : in particular , for every @xmath57 , the function @xmath58)$ ] belongs to @xmath55 .",
    "let @xmath59 denote the topology on @xmath54 defined by @xmath60 } y_n d\\mu = \\int_{[0,t ] } y d\\mu.\\ ] ] this topology is stronger than the topology of pointwise convergence but weaker than the uniform topology . for future reference , we let @xmath61 denote the subspace of @xmath55 consisting of absolutely continuous functions @xmath62 such that @xmath63 and @xmath64 , equipped with the norm @xmath65 .    [ [ preliminaries - on - lvy - processes ] ] preliminaries on lvy processes + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    recall that the law of an @xmath28-valued lvy process @xmath31 is characterized by its lvy triplet @xmath66 via the lvy - khintchine formula @xmath67 = \\exp t \\left(i\\langle u , { \\gamma}\\rangle - \\frac{\\langle{a } u , u\\rangle}{2 }    + \\int_{\\mathbb r^n } ( e^{i\\langle u , x\\rangle}-1-i\\langle u , x\\rangle 1_{|x|\\leq 1 } ) { \\nu}(dx)\\right)\\ ] ] here , the lvy measure @xmath68 is a positive measure on @xmath28 , which satisfies @xmath69 and governs the intensity of jumps , the matrix @xmath70 is a positive definite @xmath71 matrix , which corresponds to the covariance matrix of the diffusion component and the vector @xmath72 is related to the deterministic linear component of @xmath31 .",
    "we shall need the following lemma , which is a direct consequence of propositions 2.2 and b.1 in @xcite .",
    "[ gfunc.lm ] let @xmath73 and let @xmath31 be a lvy process .",
    "then , @xmath74 } x_t \\cdot \\theta(dt)}\\right ] = \\int_0^t g(\\theta([t , t ] ) ) dt \\ \\in [ 0,\\infty],\\ ] ] where @xmath75.\\ ] ]    in the sequel , we shall make use of the following two assumptions on the lvy process @xmath31 .",
    "* there exists @xmath76 with @xmath77 . *",
    "the function @xmath78 is lower semicontinuous and its effective domain is bounded .",
    "[ [ a - large - deviations - principle - for - lvy - processes ] ] a large deviations principle for lvy processes + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in the following , we let @xmath31 denote a @xmath28-valued lvy process on @xmath29 $ ] with lvy measure @xmath68 and without diffusion part @xmath79 .",
    "we introduce a family of lvy processes @xmath80 defined by @xmath81 .",
    "the following theorem can be found in @xcite .",
    "[ leonard.thm ] suppose that assumption ( a1 ) holds true .",
    "then the family @xmath38 satisfies the ldp in @xmath54 for the @xmath59-topology with the good rate function @xmath82 where @xmath83 } x_t \\mu(dt ) - \\int_0^t    g(\\mu([t , t ] ) ) dt\\right\\ } & \\text{if }  x \\in v_r \\\\ & + \\infty & \\text{otherwise . }",
    "\\end{aligned } \\right.\\ ] ]    note that de acosta @xcite proves an ldp for the uniform topology under the assumption that all exponential moments are finite . however , this assumption is too strong in practice , since most financial models are based on lvy processes with exponential tail decay .",
    "the rate function appearing in theorem [ leonard.thm ] admits a more explicit expression ( see section 6 in @xcite ) .",
    "define the fenchel conjugate of @xmath78 : @xmath84 and its recession function @xmath85 then , @xmath86 } l_a(\\frac{d\\dot x_a}{dt}(t))dt + \\int_{[0,t ] } l_s(\\frac{d\\dot x_s}{d\\mu}(t))d\\mu & \\text{if }  x \\in v_r \\\\ & + \\infty & \\text{otherwise , } \\end{aligned } \\right.\\ ] ] where @xmath87 is the decomposition of the measure @xmath88 in absolutely continuous and singular pars with respect to @xmath89 and @xmath90 in any nonnegative measure on @xmath29 $ ] , with respect to which @xmath91 in absolutely continuous .",
    "as mentioned in the introduction , our importance sampling estimator is based on the path - dependent esscher transform , @xmath26 } x_t      \\cdot \\theta(dt)}}{\\mathbb e\\left[e^{\\int_{[0,t ] } x_t      \\cdot \\theta(dt)}\\right]}\\ ] ] where @xmath27 is a ( deterministic ) bounded @xmath28-valued signed measure on @xmath29 $ ] .    the optimal choice of @xmath27 should minimize the variance of the estimator under @xmath30 , @xmath32 - \\mathbb e\\left[p\\right]^2\\ ] ] denote @xmath92 .",
    "then , using lemma [ gfunc.lm ] , the minimization problem writes @xmath93 } x_t      \\cdot \\theta(dt ) + \\int_0^t g(\\theta([t , t]))dt \\right\\}\\right],\\ ] ] where @xmath94    given the possibly complex form of the log - payoff @xmath95 , the above expression for the variance is difficult to minimize .",
    "our approach is instead to minimize a proxy of the variance , which has a more tractable form .",
    "our first main result provides an expression for such a proxy , which we aim to minimize to obtain an asymptotically optimal variance reduction .",
    "[ varadhanapplies ] let assumption ( a1 ) hold true , and suppose that the set @xmath96 is open and that @xmath95 is continuous on this set for the @xmath59-topology and satisfies @xmath97 } \\sum_{i=1}^n |x^i_s|\\ ] ] with @xmath98 . then , for every @xmath73 such that @xmath99)| < \\lambda_0 - 4nb,\\ ] ] it holds that @xmath100 }   x^\\varepsilon_t \\cdot \\theta(dt ) } { \\varepsilon } } \\right ]   =   \\sup_{x \\in d } \\left\\{2h(x ) - \\int_{[0,t ] }   x_t \\cdot \\theta(dt )   - \\bar j(x ) \\right\\}.   % \\\\ % & = \\sup_{x\\in v_r } \\left\\{2h(x ) - \\int_{[0,t ] }   x_t \\cdot \\theta(dt )   - \\int_{[0,t ] } l_a(\\frac{d\\dot x_a}{dt}(t))dt - \\int_{[0,t ] } l_s(\\frac{d\\dot x_s}{d\\mu}(t))d\\mu \\right\\}.\\end{aligned}\\ ] ]    since the pay - off @xmath95 is assumed to be continuous , the continuity of the mapping @xmath101 }   x_t \\cdot \\theta(dt)\\ ] ] for the @xmath59-topology follows from the definition of this topology .",
    "it remains to check the integrability condition of varadhan s lemma . by assumptions of the proposition",
    ", we may choose @xmath102 and @xmath103 with @xmath104 , as well as @xmath105 , such that @xmath106)| < \\lambda_0 \\quad \\text{and}\\quad 4 pn b < \\lambda_0 .",
    "\\end{aligned}\\ ] ] moreover , there exists @xmath107 with @xmath108<0\\quad \\text{and}\\quad \\mathbb e\\left [ ( -x^i_{t}-bt)e^{4b\\gamma pn ( -x^i_{t}-bt)}\\right]<0\\ ] ] for all @xmath109 .",
    "then , by the assumption on @xmath95 , the cauchy - schwarz inequality , and lemma [ wienerhopf.lm ] , the following estimates hold true : @xmath110 }   x^\\varepsilon_t \\cdot \\theta(dt ) ) } { \\varepsilon}}\\right ] \\\\ & \\leq 2a\\gamma + \\lim\\sup_{\\varepsilon\\to 0 } \\varepsilon \\log \\mathbb e  \\left[e^{\\frac{\\gamma(2b\\sup_{s\\in [ 0,t ] } \\sum_{i=1}^n|x^{\\varepsilon , i}_s| - \\int_{[0,t ] }   x^\\varepsilon_t \\cdot \\theta(dt ) ) } { \\varepsilon}}\\right]\\\\ & = 2a\\gamma + \\lim\\sup_{\\varepsilon\\to 0 } \\varepsilon \\log \\mathbb e  \\left[e^{{\\gamma(2b\\sup_{s\\in [ 0,t]}\\sum_{i=1}^n |x^i_{s/\\varepsilon}| - \\int_{[0,t ] }   x_{t/\\varepsilon } \\cdot \\theta(dt ) ) } } \\right]\\\\ & \\leq 2a\\gamma + 2bnt+ \\sum_{i=1}^n \\lim\\sup_{\\varepsilon\\to 0 } \\varepsilon \\log \\mathbb e\\left[e^{4b\\gamma pn\\sup_{s\\in [ 0,t ] } ( x^i_{s/\\varepsilon}-bs/\\varepsilon)}\\right ] \\\\&+\\sum_{i=1}^n\\lim\\sup_{\\varepsilon\\to 0 } \\varepsilon \\log \\mathbb",
    "e\\left[e^{4b\\gamma pn\\sup_{s\\in [ 0,t ] } ( -x^i_{s/\\varepsilon}-bs/\\varepsilon)}\\right]\\\\ & + \\lim\\sup_{\\varepsilon\\to 0 } \\varepsilon \\log \\mathbb e \\left[e^{- q\\gamma\\int_{[0,t ] }   x_{t/\\varepsilon } \\cdot \\theta(dt )   } \\right]\\\\ & \\leq   2a\\gamma + 2bnt+ \\sum_{i=1}^n \\lim\\sup_{\\varepsilon\\to 0 } \\varepsilon \\log \\mathbb e\\left[e^{4b\\gamma pn\\sup_{s\\geq 0 } ( x^i_{s}-bs)}\\right ] \\\\ & + \\sum_{i=1}^n\\lim\\sup_{\\varepsilon\\to 0 } \\varepsilon \\log \\mathbb e\\left[e^{4b\\gamma pn\\sup_{s\\geq 0 } ( -x^i_{s}-bs)}\\right ] + \\int_{[0,t ] } g(-q\\gamma\\theta([t , t ] ) ) < \\infty . \\end{aligned}\\ ] ]    the result of proposition [ varadhanapplies ] leads us to introduce the following definition .",
    "[ optvar.def ] we say that the variance reduction parameter @xmath25 is asymptotically optimal if it minimizes @xmath111 }   x_t \\cdot \\theta(dt )   + \\int_{[0,t ] } g(\\theta([t , t]))dt- \\bar j(x ) \\right\\}\\ ] ] over @xmath73 .",
    "the optimization functional in the definition [ optvar.def ] is difficult to compute in practice , since the rate function @xmath112 is usually not known explicitly .",
    "the following theorem shows that for concave log - payoffs , the computation of the optimal parameter @xmath25 is greatly simplified .",
    "european basket put options and many paht - dependent put - like payoffs encountered in practice are indeed concave .",
    "[ maindual.thm ] let @xmath95 be concave and upper semicontinuous on @xmath61 and assume that for every @xmath113 there is a sequence @xmath114 converging to @xmath62 in the @xmath59-topology and such that @xmath115 .",
    "let assumption ( a2 ) be satisfied .",
    "then , @xmath116 }   x_t \\cdot \\theta(dt ) + \\int_{[0,t ] } g(\\theta([t , t]))dt - \\bar j(x ) \\right\\ }   \\\\= 2\\inf_{\\theta \\in m}\\{\\widehat h(\\theta ) + \\int_{[0,t ] } g(\\theta([t , t]))dt\\}\\label{dualtheta}\\end{gathered}\\ ] ] where @xmath117 } x_t \\theta ( dt)\\}.\\ ] ] moreover , if the infimum in the left - hand side of is attained by @xmath25 then the same value @xmath25 attains the infimum in the right - hand side of .",
    "the assumption that the effective domain of @xmath78 is bounded is the most restrictive .",
    "it is satisfied by models where the tail decay is exactly exponential , such as variance gamma , normal inverse gaussian , cgmy and their multidimensional versions .",
    "however , it rules out models with faster than exponential tail decay such as the celebrated merton s model .",
    "we expect that for such models a similar result may still be shown , but one would need to use different , and slightly more complex methods ( orlicz spaces instead of @xmath118 ) . to keep the length of the proof reasonable , we have chosen to present the argument in the case of a bounded domain .",
    "step 1 . by assumption of the proposition",
    ", @xmath119 } x_t\\cdot \\mu(dt)+ \\int_{[0,t ] }    g(\\mu([t , t ] ) ) dt\\ } \\notag\\\\&\\qquad= { \\sup_{x\\in v^{ac}_r}\\inf_{\\mu\\in m}}\\{2h(x ) - \\int_{[0,t ] } x_t\\cdot \\mu(dt)+ \\int_{[0,t ] }    g(\\mu([t , t ] ) ) dt\\}\\notag\\\\ & \\qquad=   { \\sup_{x\\in v^{ac}_r}\\inf_{\\mu\\in m}}\\{2h(x ) - \\int_{[0,t ] } \\dot x_t\\cdot \\mu([t , t])dt + \\int_{[0,t ] }    g(\\mu([t , t ] ) ) dt\\}\\notag\\\\ &   \\qquad=   { \\sup_{x\\in v^{ac}_r}\\inf_{y\\in l^\\infty([0,t])}}\\{2h(x ) - \\int_{[0,t ] } \\dot x_t\\cdot y_t dt + \\int_{[0,t ] }    g(y_t ) dt\\},\\label{step1minimax}\\end{aligned}\\ ] ] where the last equality follows by approximating an @xmath120 function with a sequence of continuous functions with bounded variations , and using the dominated convergence theorem .",
    "our aim in this step is to show that @xmath121 and @xmath122 in may be exchanged .",
    "we adapt the classical argument , which may be found , e.g. , in @xcite .",
    "fix @xmath123 and define , for @xmath124 and @xmath125)$ ] , @xmath126 } \\dot x_t \\cdot y_t dt+ \\int_{[0,t ] }    g(y_t ) dt,\\ ] ] and @xmath127 . for @xmath124 ,",
    "let @xmath128)}l_\\varepsilon(x , y).\\ ] ] the @xmath122 is attained by @xmath129 such that for each @xmath130 , @xmath131 is the minimizer of @xmath132 .",
    "the function @xmath133 is concave , upper semicontinuous and satisfies @xmath134 whenever @xmath135 .",
    "therefore , it attains its upper bound at the point @xmath136 .",
    "let @xmath124 and @xmath137 . by the optimality of @xmath136 and @xmath138 and the concavity of @xmath139 with respect to the first argument , @xmath140 which implies that @xmath141 since the effective domain of @xmath78 is bounded , the function @xmath142 is lipschitz continuous , and therefore , as @xmath143 , @xmath144 which implies that for all @xmath124 , @xmath145 and therefore",
    ", for all @xmath124 and @xmath146)$ ] , @xmath147 since the family @xmath138 is bounded in @xmath118 , by banach - alaoglu theorem there exists a sequence @xmath148 and a point @xmath149 such that @xmath150 in the weak@xmath151 topology of @xmath118 and hence in the weak topology of @xmath152 for all @xmath102 . since @xmath153 }",
    "g(y_t ) dt\\ ] ] is convex and lower semicontinuous in the strong topology of @xmath152 ( see @xcite ) , it is also weakly lower semicontinuous and from it follows that for @xmath124 , @xmath154 ) } l_{\\varepsilon_j}(x , y ) \\leq",
    "\\sup_{x\\in v^{ac}_r } \\inf_{y\\in l^\\infty([0,t ] ) } l(x , y),\\end{aligned}\\ ] ] which , together with the standard minimax inequality , proves that @xmath155 ) } l(x , y ) = \\inf_{y\\in l^\\infty([0,t ] ) } \\sup_{x\\in v^{ac}_r }   l(x , y)\\\\ & = \\inf_{y\\in l^\\infty([0,t ] ) } \\sup_{x\\in v^{ac}_r }   \\{2h(x ) - \\int_{[0,t ] } \\dot x_t\\cdot   y_t   dt + \\int_{[0,t ] } g(y_t ) dt \\}.\\end{aligned}\\ ] ]    step 3 .",
    "given @xmath146)$ ] , we can find a sequence of functions @xmath156 belonging to @xmath55 with @xmath157 , which converges to @xmath158 in lebesgue measure on @xmath29 $ ] ( use lusin s theorem plus an approximation of continuous functions with functions of bounded variation ) . then , by the dominated convergence theorem , as @xmath159 , @xmath160 } \\dot x_t \\cdot y^n_t dt   \\to \\int_{[0,t ] } \\dot x_t \\cdot y_t dt.\\ ] ] on the other hand , letting @xmath161 , we have that , for each @xmath162 , @xmath160 } g(y^n_t\\mathbf 1_{y^n_t \\in a_m } ) dt \\to \\int_{[0,t ] } g(y_t\\mathbf 1_{y^n_t \\in a_m } ) dt\\ ] ] by dominated convergence and , for each @xmath163 , @xmath160 } g(y^n_t\\mathbf 1_{y^n_t \\in a_m } ) dt \\to \\int_{[0,t ] } g(y^n_t ) dt\\ ] ] by monotone convergence .",
    "these two observations together with an integration by parts for the second term , imply that @xmath164 ) } \\sup_{x\\in v^{ac}_r }   l(x , y ) = \\inf_{\\mu \\in m } \\sup_{x\\in v^{ac}_r }   \\{2h(x ) - \\int_{[0,t]}x_t\\cdot d\\mu + \\int_{[0,t ] } g(\\mu([t , t ] ) ) dt \\}.\\ ] ] in addition , the assumption of the proposition implies that the inner supremum may also be computed over @xmath113 .",
    "finally , the following computation allows to finish the proof .",
    "@xmath165 }   x_t \\cdot \\theta(dt ) + \\int_{[0,t ] } g(\\theta([t , t]))dt   - \\bar j(x)\\}\\\\ & \\qquad=   \\inf_{\\theta\\in m } { \\sup_{x\\in v_r}\\inf_{\\mu\\in m}}\\{2h(x ) - \\int_{[0,t ] } x_t ( \\theta(dt)+ \\mu(dt ) ) \\\\ & \\qquad\\qquad \\qquad + \\int_{[0,t ] } g(\\theta([t , t]))dt + \\int_{[0,t ] }    g(\\mu([t , t ] ) ) dt\\}\\\\ & \\qquad= \\inf_{\\theta\\in m } { \\inf_{\\mu\\in m}\\sup_{x\\in v_r}}\\{2h(x ) - \\int_{[0,t ] } x_t ( \\theta(dt)+ \\mu(dt ) ) \\\\ &",
    "\\qquad\\qquad \\qquad + \\int_{[0,t ] } g(\\theta([t , t]))dt + \\int_{[0,t ] }    g(\\mu([t , t ] ) ) dt\\ } \\\\ &",
    "\\qquad = \\inf_{\\theta\\in m } \\inf_{\\mu\\in m}\\{2\\widehat h\\left(\\frac{\\theta+\\mu}{2}\\right ) + \\int_{[0,t ] } g(\\theta([t , t]))dt + \\int_{[0,t ] }    g(\\mu([t , t ] ) ) dt\\ } \\\\ & \\qquad=2\\inf_{\\theta \\in m}\\{\\widehat h(\\theta ) + \\int_{[0,t ] } g(\\theta([t , t]))dt\\},\\end{aligned}\\ ] ] where the last equality follows by convexity of @xmath78 , taking @xmath166 .",
    "[ [ concavity - of - the - log - payoff ] ] concavity of the log - payoff + + + + + + + + + + + + + + + + + + + + + + + + + + +    the concavity of the log - payoff function @xmath167 may be tested using the following simple lemma .",
    "we recall that @xmath168 for @xmath169 .",
    "[ conc.lm ] let @xmath170 and assume that @xmath171 is concave on the set @xmath172 and that the set @xmath173 is convex .",
    "then the log - payoff @xmath174 is concave in @xmath62 .",
    "let @xmath175 and choose @xmath176 .",
    "then , @xmath177 which shows that @xmath95 is concave on @xmath173 .",
    "since @xmath178 for @xmath179 and the set @xmath173 is convex , @xmath95 is also concave on the whole space .",
    "in this section , we specialize the results of the previous section to several option pay - offs encountered in practice . throughout this section",
    "we assume that the lvy process satisfies the assumptions ( a1 ) and ( a2 ) . for each considered pay - off",
    ", we need to check the assumptions of proposition [ varadhanapplies ] to ensure that the asymptotically optimal variance reduction measure @xmath25 may indeed be defined as in definition [ optvar.def ] , and the assumptions of theorem [ maindual.thm ] , to ensure that one can use the simplified formula to compute @xmath25 .",
    "[ [ general - european - pay - off ] ] general european pay - off + + + + + + + + + + + + + + + + + + + + + + + +    we first check the assumptions of theorem [ maindual.thm ] and show that the problem of finding the optimal parameter @xmath25 becomes finite - dimensional .",
    "the assumptions of proposition [ varadhanapplies ] can be checked on a case - by - case basis as will be illustrated below .",
    "[ euro.prop ] assume that @xmath180 with @xmath181 concave and upper semicontinuous .",
    "then , assumptions of theorem [ maindual.thm ] are satisfied and @xmath182 , where @xmath183 is the dirac measure at @xmath184 , and @xmath185 where @xmath186 .",
    "the log - payoff @xmath95 clearly satisfies the assumptions of theorem [ maindual.thm ] . if @xmath187 , then @xmath188 since one can choose @xmath189 with @xmath190 arbitrary .",
    "this means that one can restrict the optimization in to measures of the form @xmath191 where @xmath23 , and the rest of the proof follows easily .",
    "we observe that the function @xmath192 is known explicitly in most models .",
    "in addition , under the measure @xmath30 , @xmath31 is still a lvy process which often falls into the same parametric class ( see e.g. , the variance gamma example in the following section ) . thus , the only overhead of using the importance sampling estimator proposed in this paper for european options is due to the additional time needed to solve an explicit convex optimization problem in dimension @xmath1 , which is usually negligible .",
    "[ [ european - basket - put - option ] ] european basket put option + + + + + + + + + + + + + + + + + + + + + + + + + +    now consider a specific european pay - off of the form @xmath193 .",
    "then , using the notation of the previous paragraph , @xmath194 since this functions is bounded from above and continuous on the set where it is not equal to @xmath46 , assumptions of proposition [ varadhanapplies ] are satisfied and one can define the asymptotically optimal variance reduction measure . on the other hand ,",
    "the function @xmath195 is concave on @xmath196 by convexity of the exponential and the set @xmath197 is convex .",
    "therefore , by lemma [ conc.lm ] , the function @xmath198 is concave . since it is also clearly upper semicontinuous , the optimal measure @xmath25",
    "is given in proposition [ euro.prop ] , where the convex conjugate of @xmath198 is easily shown to be explicit and given by @xmath199 numerical examples for the european basket put option are given in the next section .",
    "[ [ asian - put - option ] ] asian put option + + + + + + + + + + + + + + + +    in this example we consider the asian option with log - payoff @xmath200 first note that @xmath95 may not be continuous in the @xmath59-topology even on the set where it is finite .",
    "we shall nevertheless use the definition of the asymptotically optimal variance reduction parameter .",
    "this may be justified by the fact the discretely sampled asian option is @xmath59-continuous , and the variance of the discretely sampled asian pay - off converges to that of the continuously sampled pay - off as the discretization step tends to zero .    let us now check the assumptions of theorem [ maindual.thm ] .",
    "remark that @xmath201 is concave by convexity of the exponential , and for @xmath202 such that @xmath203 and @xmath204 , @xmath205 which implies that the set @xmath196 is convex .",
    "therefore , by lemma [ conc.lm ] , @xmath95 is concave .",
    "moreover , assume that @xmath206 in @xmath61 . then , by fatou s lemma @xmath207 which shows that @xmath95 is upper semicontinuous .",
    "finally , @xmath113 may be approximated by a uniformly bounded sequence of @xmath208 , so that @xmath209 by the dominated convergence theorem .",
    "therefore , all assumptions of theorem [ maindual.thm ] are satisfied by the asian put option .",
    "the convex conjugate of @xmath95 and the asymptotically optimal parameter @xmath25 are described by the following proposition .",
    "@xmath210    * if @xmath27 is absolutely continuous , with density ( also denoted by @xmath211 ) satisfying @xmath212 for all @xmath213 $ ] , then @xmath214 is given by @xmath215 otherwise @xmath216 .",
    "* the function @xmath217 is the solution of the boundary value problem @xmath218    this system can be integrated explicitly : @xmath219 where the constant @xmath220 is determined from the terminal condition .    by definition ,",
    "@xmath221 } x_t \\theta(dt)\\right\\}.\\ ] ] first , assume that there is an interval @xmath222 $ ] such that @xmath223 .",
    "then , letting @xmath224 for @xmath225 and @xmath226 for @xmath227 , and making @xmath228 tend to @xmath229 , we see that @xmath188 .",
    "therefore , from now on we may assume that @xmath27 is a negative measure .",
    "assume that it is not absolutely continuous .",
    "then , there exists @xmath123 such that for all @xmath230 , there exists a finite sequence of pairwise disjoint sub - intervals @xmath231 of @xmath29 $ ] satisfying @xmath232 such that @xmath233 we define @xmath234 .",
    "let @xmath235 when @xmath236 and @xmath237 otherwise .",
    "then , @xmath238 } x_t \\theta(dt)\\geq \\log \\left(k/2 - \\frac{\\delta}{t}e^n \\right)^+ - \\theta(i^c)\\log \\frac{k}{2 }   + n\\varepsilon.\\ ] ] taking @xmath228 sufficiently large and @xmath239 sufficiently small , we see that @xmath216 in this case as well .",
    "we may therefore assume that @xmath27 is an absolutely continuous negative measure , and , with an abuse of notation , its density will also be denoted by @xmath211 .",
    "the computation of @xmath214 reduces to computing the supremum @xmath240 } x_t \\theta_tdt\\right\\},\\label{asianhhat}\\end{aligned}\\ ] ] where with no loss of generality we may consider only those @xmath113 for which the expression under the sign of logarithm is positive .",
    "the first order condition for this optimization problem writes @xmath241 integrating this expression from @xmath242 to @xmath184 , we find @xmath243 and so @xmath244 substituting this into , we obtain the first part of the proposition .",
    "to compute the optimal importance sampling measure @xmath25 , we need to solve @xmath245 ) ) dt\\}\\notag\\\\ & = \\min_{\\theta_t \\leq 0}\\big(1-\\int_0^t \\theta_s ds\\big)\\log \\frac{k}{1 - \\int_0^t \\theta_t dt }   - \\int_0^t \\theta_t \\log(-t \\theta_t ) dt +   \\int_0^t g\\big(\\int_t^t\\theta_s\\big)dt\\end{aligned}\\ ] ] introducing the function @xmath246 , the optimization problem becomes @xmath247 by pontryagin s maximum principle for deterministic control problems , for every @xmath213 $ ] , the optimal @xmath248 is the minimizer of @xmath249 where @xmath250 is the `` adjoint state '' satisfying @xmath251    numerical examples for the asian put option are given in the next section .",
    "in this section , we illustrate the results of this paper with numerical computations in the multivariate variance gamma model .",
    "let @xmath252 , @xmath253 be a positive definite @xmath71 matrix , and define @xmath254 where @xmath255 is a standard brownian motion in dimension @xmath1 , @xmath256 is a gamma process with @xmath257 = t$ ] and @xmath258 , and @xmath90 is chosen to have @xmath259 = 1 $ ] for all @xmath130 and @xmath169 .",
    "then , the cumulant generating function @xmath260 under the original measure is given by @xmath261 with @xmath262 under the measure @xmath30 , the cumulant generating function of @xmath260 can be written as @xmath263 therefore , under the measure @xmath30 , the process @xmath264 is also a variance gamma process with parameters @xmath265 , @xmath266 , @xmath267 and @xmath268 .    [ [ vanilla - put - in - the - variance - gamma - model ] ] vanilla put in the variance gamma model + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in the first example , we let @xmath269 and price a european put option with pay - off @xmath270 .",
    "the model parameters are @xmath271 , @xmath272 and @xmath273 , which corresponds to annualized volatility of @xmath274 , skewness of @xmath275 and excess kurtosis of @xmath276 .",
    "table [ vred1d.tab ] shows the variance reduction ratios and the values of the asymptotically optimal parameter @xmath25 as function of strike and time to maturity .",
    "we see that the highest ratios are attained for out - of - the - money options , whose exercise is a rare event , but that even for at - the - money options , the variance reduction ratios remain quite significant .",
    "it is also important to understand , how close are these ratios to the optimal ones which would have been obtained by minimizing the actual variance of the estimator rather than its asymptotic proxy .",
    "this is illustrated in figure [ vred1d.fig ] , which plots the variance of the importance sampling estimator ( evaluated by monte carlo ) as function of the parameter @xmath27 .",
    "we see that for the chosen parameter values @xmath25 is very close to optimality .",
    ".single - asset european put option .",
    "top : variance reduction ratios as function of time to maturity @xmath184 , for @xmath277 .",
    "bottom : variance reduction ratios as function of strike @xmath278 , for @xmath279 . [ cols=\"<,^,^,^,^,^,^\",options=\"header \" , ]     , for @xmath277 and @xmath279.,scaledwidth=60.0% ]",
    "[ wienerhopf.lm ] let @xmath31 be a lvy process .",
    "we denote @xmath280 .",
    "let @xmath281 be such that @xmath282<\\infty$ ] and @xmath283 < 0 $ ] . then ,",
    "@xmath284 < \\infty\\ ] ] for all @xmath285 .    by the wiener - hopf factorization ( theorem 6.16 in @xcite ,",
    "see also equation ( 47.9 ) in @xcite ) , @xmath286 dt = \\exp\\left(\\int_0^\\infty \\frac{e^{-qt}}{t } dt      \\int_0^\\infty ( e^{\\beta x } - 1 )   \\mathbb p[x_t\\in      dx ] \\right).\\ ] ] letting @xmath287 and using the cauchy - schwarz inequality , we get @xmath288 & = \\exp\\left(\\int_0^\\infty \\frac{1}{t } dt      \\int_0^\\infty ( e^{\\beta x } - 1 )   \\mathbb p[x_t\\in      dx ] \\right)\\\\ & = \\exp\\left(\\int_0^\\infty \\frac{1}{t } dt\\ ,       \\mathbb e[(e^{\\beta x_t}-1)\\mathbf 1_{x_t \\geq 0 } ] \\right)\\\\ & \\leq \\exp\\left(\\int_0^\\infty \\frac{\\beta}{t } dt\\ ,",
    "\\mathbb e[x_t\\,e^{\\beta x_t}\\mathbf 1_{x_t \\geq 0 } ] \\right)\\\\ & \\leq \\exp\\left(\\int_0^\\infty \\frac{\\beta}{t } dt\\ , \\mathbb    e[|x_t|^{\\frac{\\beta'}{\\beta'-\\beta}}\\mathbf 1_{x_t\\geq 0}]^{1-\\frac{\\beta}{\\beta'}}\\ ,      \\mathbb e[e^{\\beta ' x_t}\\mathbf 1_{x_t \\geq 0}]^{\\frac{\\beta}{\\beta ' } } \\right)\\end{aligned}\\ ] ]    let @xmath289 .",
    "then , all moments of @xmath290 are finite and @xmath291 \\leq    \\mathbb e[|\\widehat x_t|^{\\frac{\\beta'}{\\beta'-\\beta}}].\\ ] ] let @xmath292 . then , @xmath293 \\leq \\mathbb e[|\\widehat x_t|^{n^*}]^{^{\\frac{\\beta'}{n^*(\\beta'-\\beta ) } } } \\leq c t^{^{\\frac{\\beta'}{n^*(\\beta'-\\beta)}}}\\ ] ] for some @xmath294 .",
    "thus , @xmath288 \\leq \\exp\\left(\\beta    c\\int_0^\\infty dt\\ , t^{\\frac{1}{n^*}-1}\\ ,      \\mathbb e[e^{\\beta ' x_t}\\mathbf 1_{x_t \\geq 0}]^{\\frac{\\beta}{\\beta ' } } \\right)\\label{int}.\\end{aligned}\\ ] ]    further , @xmath295 = e^{t\\psi(\\beta ) } \\widehat{\\mathbb p}[x_t\\geq 0],\\ ] ] where @xmath296}. $ ] by cramer s theorem , @xmath297 = -\\inf_{x\\geq    0}\\lambda^*(x ) = - \\lambda^*(0),\\ ] ] where @xmath298\\ } = \\sup_{\\lambda } \\{\\lambda x - \\psi(\\lambda + \\beta ) + \\psi(\\beta)\\}.\\ ] ] therefore , @xmath299 \\right ) = \\inf_{\\lambda } \\psi(\\lambda + \\beta ) < 0,\\ ] ] which shows that the integral in converges ."
  ],
  "abstract_text": [
    "<S> we develop generic and efficient importance sampling estimators for monte carlo evaluation of prices of single- and multi - asset european and path - dependent options in asset price models driven by lvy processes , extending earlier works which focused on the black - scholes and continuous stochastic volatility models @xcite . using recent results from the theory of large deviations on the path space for processes with independent increments @xcite , </S>",
    "<S> we compute an explicit asymptotic approximation for the variance of the pay - off under an esscher - style change of measure . minimizing this asymptotic variance using convex duality , </S>",
    "<S> we then obtain an easy to compute asymptotically efficient importance sampling estimator of the option price . </S>",
    "<S> numerical tests for european baskets and for asian options in the variance gamma model show consistent variance reduction with a very small computational overhead .    </S>",
    "<S> * key words : * lvy processes , option pricing , variance reduction , importance sampling , large deviations    * msc2010 : * 91g60 , 60g51 </S>"
  ]
}