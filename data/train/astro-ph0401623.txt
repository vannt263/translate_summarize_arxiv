{
  "article_text": [
    "signal reconstruction from noisy data is one of the _ raisons dtre _ of applied statistics .",
    "if the signal is a gaussian random field , and the signal and noise covariances are known in advance , wiener filtering @xcite is the theoretically optimal method for estimating the signal from noisy data . in this simple case",
    "the solution is a linear operator that acts on the data vector and returns the minimum variance , maximum likelihood and maximum a posteriori estimator of the signal given the data .    what ought to be done , however , if the signal covariance is not known in advance , and the signal covariance must be estimated from the data ?",
    "in fact there are applications where covariance estimation is the primary goal and signal reconstruction is secondary .",
    "these cases have traditionally been treated separately . for stationary signals ,",
    "the covariance of the signal is best specified in the fourier basis since this basis diagonalizes the covariance matrix . in these cases",
    "covariance estimation becomes power spectrum estimation .",
    "one such example is cosmic microwave background data ( cmb ) analysis which motivated this analysis .",
    "i will return to it in section [ cmb ] .",
    "other examples are time series analysis , spatial analysis of censored data , such as geological surveys , power spectrum estimation and signal reconstruction for helioseismology , image reconstruction based on a stochastic model of the form of pixel - pixel correlations , etc .",
    "the method described here generalizes the results of @xcite and should therefore also be useful for the applications discussed there .    in this talk i will first review the common structure that underlies these apparently different statistical problems ( section [ review ] ) .",
    "i will then summarize the main advances realized by the new method in section [ method ] .",
    "the subsequent section contains the results from the application of this new approach to the first all - sky cmb data set .",
    "further details and examples can be found in our paper @xcite and online materials at the conference www site .",
    "the ideas in this paper were developed from a bayesian perspective .",
    "there are pros and cons of bayesian estimation .",
    "the pros are many : it maximizes the use of all available information and treats measurements , constraints and model on the same footing as information .",
    "the result of a bayesian estimation is a probability density , not just a number , so one automatically obtains uncertainty information about the estimate .",
    "however , if bayesian methods are implemented naively , these advantages come at the price of heavy computation especially for multivariate problems . however the results presented in this paper are an example that it is possible to overcome these computational challenges and make bayesian techniques work in a highly multivariate ( @xmath0 ) problem .",
    "in this section i will review the problems of signal reconstruction and covariance estimation from a bayesian perspective .",
    "first , some notation .",
    "let us assume that the data were taken according to the model equation @xmath1 where the @xmath2-vector @xmath3 contains the data samples , the ( @xmath4 ) matrix @xmath5 is the observation matrix , the @xmath6-vector @xmath7 is the ( discretized ) signal , the @xmath6-vector @xmath8 represents any contaminants ( `` foregrounds '' ) one has to contend with , and the @xmath2-vector @xmath9 is the instrumental noise .",
    "i model the signal stochastically ( vs. a deterministic functional form ) and `` infer '' its covariance properties from the data . in particular , the signal is modeled through its covariance properties , encoded in @xmath10 , the signal covariance matrix .",
    "then i can write the bayesian posterior as @xmath11 where @xmath12 is the noise covariance matrix @xmath13 .",
    "i will now discuss the various terms in eq .",
    "[ bayes ] .",
    "the likelihood @xmath14 specifies how the data is related to the quantities in the model .",
    "given the model equation eq .",
    "[ model ] specifies that @xmath15 as a shorthand for the multivariate gaussian density @xmath16 ] .",
    "the other terms in eq .",
    "[ bayes ] specify information about the components of the model .",
    "the term @xmath17 contains information about the covariance of @xmath7 .",
    "if @xmath7 is a gaussian random field with zero mean ( examples from cosmology are the cmb or other probes of the density fluctuations of matter on cosmological scales ) @xmath18 .",
    "note that it is not assumed that @xmath19 is known .",
    "partial knowledge ( or ignorance ) about @xmath19 is quantified in terms of the prior @xmath20 . for a stationary field @xmath20",
    "might simply represent the fact that i parameterize the covariance matrix in terms of power spectrum coefficients .",
    ".  [ bayes ] also assumes that the signal , noise and the contaminants are stochastically independent of each other .",
    "further , the equations as written are conditioned on perfect knowledge of the noise covariance . and @xmath12 can be usefully obtained from the data is determined by the structure of the observation matrix @xmath5 . ]",
    "lastly , @xmath21 encodes the knowledge or ignorance about foregrounds .",
    "note that from a bayesian perspective all that is required is that @xmath21 accurately represents knowledge about @xmath8 . therefore assuming a gaussian form for @xmath8 does not assume that @xmath8 actually has gaussian statistics .",
    "in particular the mode of the gaussian corresponds to the most probable ( a priori ) foreground model and the covariance to the uncertainty in the model .",
    "the ability to specify uncertainties in the foregrounds ( which will then be taken into account when the method is applied ) is a key feature of this approach which guards against biases from including incorrect foreground templates without the ability to account for the uncertainty in these templates .",
    "having specified the forms of the various terms on the right hand side of eq .",
    "[ bayes ] , the task is to explore the joint posterior density @xmath22 .",
    "however , traditionally the problem is treated in three different limits .",
    "if , as an expression of prior ignorance , i take @xmath23 and @xmath24 then all the information is in the likelihood @xmath14 . in this case",
    "the best one can do if @xmath9 is gaussian , is to summarize what is known about @xmath25 in terms of the maximum likelihood estimate @xmath26 and quote the associated noise covariance matrix @xmath27 . in the cmb literature",
    "the process of obtaining @xmath28 and @xmath29 from the data are known as `` map making . ''",
    "if on the other hand , the signal covariance @xmath19 is perfectly known and foregrounds are neglected then the joint posterior becomes @xmath30 where @xmath31 this posterior for @xmath7 peaks at @xmath32 , the well - known wiener filter reconstruction of @xmath7 , so this is known as `` wiener filtering . ''    in the third limit , `` power spectrum estimation , '' one does not know @xmath19 but have some information about how it is parameterized , namely that in the fourier basis @xmath19 is diagonal with the diagonal elements equal to the power spectrum coefficients @xmath33 .",
    "if we ignore foregrounds again and set @xmath34 we can integrate out ( `` marginalize over '' ) @xmath7 and obtain the usual starting point for maximum likelihood power spectrum estimation @xmath35    the density @xmath36 is considered as a multivariate function of all the power spectrum coefficients up to some band limit @xmath37 .",
    "it represents all the information about @xmath38 contained in the data .",
    "one can again summarize what is known about @xmath19 by quoting the set of power spectrum estimates @xmath39 for which @xmath40 is maximum ( equivalent to the maximum likelihood estimates ) and include a summary of the width of the marginal distribution of @xmath40 for each power spectrum coefficient .    however , in this case for any @xmath6 larger than a few thousand this procedure is computationally prohibitive . since the determinant in eq .",
    "[ pofsgivend ] depends on @xmath19 , it needs to be evaluated if the shape of the likelihood is to be explored .",
    "determinant evaluation scales as @xmath41 . as a result , to evaluate eq .",
    "[ pofsgivend ] just once for a million pixel map would take several years , even if one achieved perfect parallelization across thousands of processors on the most powerful supercomputing platforms in the world . to find its maximum in a parameterization of 1000 power spectrum coefficients and compute marginalized confidence intervals for each @xmath33 by integrating out all others is a lost cause .",
    "the maximum likelihood techniques that are currently described in the literature @xcite avoid the determinant calculation in eq .",
    "[ pofsgivend ] by finding the zero of the first derivative of @xmath40 using an approximate newton - raphson iteration scheme .",
    "however , for realistic data , the computational complexity is not reduced because the first derivative contains traces of matrix products that also require of order @xmath41 operations . in these treatments",
    "the error bars on the power spectrum coefficients are approximated by the second derivative of the likelihood at the peak even though the likelihood of @xmath19 is non - gaussian .",
    "this second derivative is again hard to compute , requiring of order @xmath41 operations .",
    "even these expensive methods do not provide a way of accurately summarizing and publishing the `` data product , ''",
    ". there are various approximate techniques for doing this in the literature @xcite but it is not well understood how good these approximations are away from the peak of the likelihood @xcite .",
    "how does one overcome these computational challenges ?",
    "the answer i propose is to _ sample _ from the full joint density @xmath22 .",
    "this may seem even more challenging , since this a function of millions arguments and general techniques of generating samples from complicated multivariate densities are very computationally intensive .",
    "however , the special structure of the gaussian priors in eq . [ bayes ] allows exact sampling from the conditional densities of @xmath22 .",
    "exact sampling is made possible by solving systems of equations using the preconditioned conjugate gradient method @xcite .",
    "this means the _ gibbs sampler _",
    "@xcite can be used to construct a markov chain which will converge to sampling from @xmath22 .",
    "the gibbs sampler is an iterative scheme for generating samples from a joint posterior density by iterating over the components of the density ( such as @xmath7 , @xmath19 , and @xmath8 ) and sampling each of them in turn from their conditional distributions while keeping the other components fixed .",
    "given a set of monte carlo samples from the joint posterior , any desired feature of the posterior density can be computed with accuracy only limited by the sample size .    after having obtained a sample from the joint posterior @xmath22 , it is trivial to generate samples from the marginal posteriors @xmath42 or @xmath40 .",
    "integration over a sampled representation of a function just corresponds to ignoring the dimensions that are being integrated over ! for the problem at hand things are even better than this , since the conditional density @xmath43 has a very simple analytical form . as a result , one can compute an analytical approximation to @xmath40 using the monte carlo samples @xmath44 @xmath45 this is known as the blackwell - rao estimator of @xmath40 which is guaranteed to have lower variance than a binned estimator .",
    "in fact one can show that for perfect data ( complete and without noise ) this approximation is exact for a monte carlo sample of size 1 ! for realistic data",
    ", the approximation converges to the true power spectrum posterior given enough samples .",
    "my collaborators and i call the approach and the set of tools we have developed to implement this approach the `` magic '' method , since magic allows global inference from correlated data .",
    "we give a detailed description of the technique in the context of cmb covariance analysis in @xcite .",
    "figure  [ performance ] shows the performance of magic compared to power spectrum estimation techniques ( which do not include the signal reconstruction and foreground separation features of magic).the main advantages of the magic method are the following :     for @xmath46 from the top to the bottom on the right side of the figure .",
    "brute force methods require @xmath47 and approximate methods require @xmath48 computational time .",
    "for the wmap data @xmath49 pixels.,width=302 ]    1 .   massive speed - up compared to brute force methods . for an ( unrealistic )",
    "pre - factor of 1 a single @xmath50 operation would take @xmath51 seconds on a 1 gflop computer .",
    "an unoptimized implementation running in the background on a desktop athlonxp1800 + cpu currently requires less than @xmath52 seconds per sample .",
    "massive reduction in memory use : since we only need to compute matrix - vector products ( not matrix - matrix products , matrix inverses or determinants ) only the parametrizations of the covariance matrices need to be stored ( e.g. noise power spectrum for @xmath12 and the signal power spectrum for @xmath19 ) .",
    "this reduces the memory requirements from order @xmath53 to at most order @xmath2 which is usually many orders of magnitude less .",
    "3 .   allows modeling realistic observational strategies and instruments .",
    "straightforward parallelization ( run several magic codes on separate processors to generate several times the number of samples in the same time ) .",
    "allows treating the statistical inference problem globally , that is it keeps the full set of statistical dependencies in the joint posterior given the data .",
    "generalizes wiener filter signal reconstruction to situations where the signal covariance is not known a priori but automatically discovered from the data at the same time as the actual signal is reconstructed .",
    "allows computing marginal credible intervals , either for individual power spectrum estimates or for combinations of any set of dimensions in the very high dimensional parameter space .",
    "allows incorporating uncertainties ( e.g. about the foregrounds ) in the analysis in such a way that they are propagated correctly through to the results .",
    "makes it possible to build in physical constraints in a straightforward way .",
    "10 . generates an unbiased functional approximation to @xmath54 , as shown in eq .",
    "it has the advantage of being a controlled and improvable approximation and removes the need for parametric fitting functions such as the offset log - normal or hybrid approximations .",
    "11 . generates a _ sampled _ representation of the joint posterior eq .",
    "[ bayes ] , which simplifies further statistical analyses .",
    "since magic is a markov chain method , one also has to discuss the issue of burn - in and correlations of subsequent steps in the chain .",
    "steps in the power spectrum coefficients @xmath33 are proportional to the width of the perfect data posterior @xcite . in other words ,",
    "the number of steps it takes to generate two uncorrelated power spectrum samples is proportional to @xmath55 where @xmath56 is the rms signal to noise ratio for the @xmath57 power spectrum coefficient .",
    "conveniently , the samples are nearly uncorrelated over the range in @xmath58 where the data is informative . in numerical experiments with the wmap data it took about 15 - 20 steps for the chain to burn - in ( for the range in @xmath58 where @xmath59 or greater ) from a wildly wrong initial guess of the power spectrum ( @xmath60 ) .     for the cobe - dmr data .",
    "this is a generalized wiener filter which does not require knowing the signal covariance a priori .",
    "b : one sample drawn from the conditional posterior @xmath61 .",
    "the posterior mean signal map , shown in panel a , has been removed .",
    "c : the sample pure signal sky at the same iteration .",
    "this is the pixel - by - pixel sum of the maps in panels a and b. d : the wmap data smoothed to 5 degrees ( less than a , more than c ) .",
    "the corresponding features in parts a and d are clearly visible.,width=234 ]",
    "in the online materials for this talk ( see footnote 1 ) i present the results of applying the magic method to a synthetic data set which covers an unsymmetrically shaped part on the celestial sphere .",
    "i used magic to reconstruct the signal on the full sky and to make movies of the gibbs sampler iterations .",
    "this is an example where the signal is automatically discovered in the data by the algorithm , without specification of the signal covariance .",
    "figures  2 and 3 show the results of analyzing the cobe - dmr data @xcite , one of the most analyzed astronomical data sets .",
    "this allowed us to perform consistency checks between the magic method , other methods and the recent results from the wilkinson microwave anisotropy probe ( wmap ) @xcite .     from the cobe - dmr data .",
    "at each @xmath62 the fluctuations in the @xmath63 at all other @xmath62 were integrated out .",
    "the axis ranges are the same for all panels.,width=302 ]    i am also very interested in evaluating claims that the wmap data favors theories which predict a lack of large scale fluctuation power in the cmb .",
    "this claim , if true , would have far - reaching consequences for our understanding of the universe . since cosmologists only have one sky to study , we have to be very careful to account for our limited ability to know the ensemble averaged power spectrum on large scales .",
    "the wmap team estimated the fluctuation power on large scales using several techniques and consistently found it to be low .",
    "however , in all of these techniques , the variance of the estimates was computed in an approximate way ( e.g. in terms of the curvature at the peak ) and relies on theory for the assessment of statistical significance . using magic",
    "one can easily integrate over the posterior density of the power spectrum given the data .",
    "therefore it is easy to compute the probability for the power spectrum coefficients in any given @xmath58-range to be smaller than any given value .    using the magic method it was straightforward to generate a preliminary sample of the power spectrum coefficients from the wmap posterior using only the w1 channel , one of the cleanest channels in the wmap data , in terms of systematic error estimates . for the cleaned w1 data and masking regions of galactic emission ( mask _ kp0 _ in the wmap data release ) the quadrupole and octopole power is not obviously discrepant from theoretical expectations . choosing a more aggressive mask could change this since that reduces the sampling variance .",
    "one should bear in mind that the power spectrum likelihood @xmath54 has infinite variance for @xmath64 even for perfect all - sky data , unless a prior is put on @xmath65 s value .",
    "therefore , in an exact assessment of the quadrupole issue claims of a significant discrepancy ought to be based on the actual shapes of posterior density , not a chi - square test ( compare the detailed discussion of cosmic variance in @xcite ) .",
    "i will address the issue of low power in the low cosmological multipoles in a future publication .",
    "of course , if desired , additional prior information about our universe can be added to the analysis .",
    "for example instead of viewing the power spectrum as the quantity of interest , its shape could be parameterized as a function of the @xmath66 cosmological parameters which span the space of cosmological theories .",
    "then instead of sampling from the power spectrum coefficients given the signal , one would run a short metropolis - hastings markov chain at each gibbs iteration to obtain a sample from the space of cosmological parameters given the data .",
    "these parameter samples , in turn define a density over the space of power spectra with considerably tighter error bars .",
    "the result is the non - linearly optimal filter for reconstructing the mean of the power spectrum incorporating physical information about the origin of the cmb anisotropies .",
    "another important direction is the analysis of image distortions .",
    "the treatment as detailed so far does not allow for the cmb to be lensed gravitationally by the mass distribution through which it streams on its way to us .",
    "this distortion itself contains very valuable cosmological information . extending the formalism to account for lensing of the cmb and",
    "estimate the statistical properties of the lensing masses from the lensed cmb would be an important extension of this approach .",
    "i thank my students and collaborators arun lakshminarayanan , david larson , and ian odwyer , as well as tom loredo for his suggestions .",
    "this work has been partially supported by the national computational science alliance under grant number ast020003n and the university of illinois at urbana - champaign .",
    "n. wiener , `` extrapolation , interpolation , and smoothing of stationarytime series with engineering applications , '' mit press , cambridge , ma,1949 .",
    "g. b. rybicki and w. h. press , `` interpolation , realization , andreconstruction of noisy , irregularly sampled data , '' apj 398 , 169 ( 1992 ) m. tegmark , phys .",
    "d55 , 5895 ( 1997 ) j.  r.  bond , a.  h.  jaffe , and l.  knox , physical review d 57 , 2117 ( 1998 ) j.  r.  bond , a.  h.  jaffe , and l.  knox , astrophys .",
    "j. 533 , 19 ( 2000 ) l. verde , _ et al .",
    "_ , ap.j.suppl .",
    "148 , 195 ( 2003 ) lewis , a. , astro - ph/0310186 william h. press , _ et al .",
    "_ , _ numerical recipes _ , cambridge university press , cambridge , uk .",
    "( 1992 ) tanner , _",
    "tools for statistical inference : methods for the exploration of posterior distributions and likelihood functions _ , springer verlag , heidelberg , germany .",
    "( 1996 ) c.  l.  bennett _ et al .",
    "j. 464 , l1 ( 1996 ) c.  l.  bennett _ et al .",
    "_ , ap.j.suppl .",
    "148 , 1 ( 2003 )"
  ],
  "abstract_text": [
    "<S> in this talk i describe magic @xcite , an efficient approach to covariance estimation and signal reconstruction for gaussian random fields ( magic allows global inference of covariance ) . </S>",
    "<S> it solves a long - standing problem in the field of cosmic microwave background ( cmb ) data analysis but is in fact a general technique that can be applied to noisy , contaminated and incomplete or censored measurements of either spatial or temporal gaussian random fields . in this talk </S>",
    "<S> i will phrase the method in a way that emphasizes its general structure and applicability but i comment on applications in the cmb context . </S>",
    "<S> the method allows the exploration of the full non - gaussian joint posterior density of the signal and parameters in the covariance matrix ( such as the power spectrum ) given the data . </S>",
    "<S> it generalizes the familiar wiener filter in that it automatically discovers signal correlations in the data as long as a noise model is specified and priors encode what is known about potential contaminants . </S>",
    "<S> the key methodological difference is that instead of attempting to evaluate the likelihood ( or posterior density ) or its derivatives , this method generates an asymptotically exact monte carlo sample from it . </S>",
    "<S> i present example applications to power spectrum estimation and signal reconstruction from measurements of the cmb . for these applications </S>",
    "<S> the method achieves speed - ups of many orders of magnitude compared to likelihood maximization techniques , while offering greater flexibility in modeling and a full characterization of the uncertainty in the estimates . </S>"
  ]
}