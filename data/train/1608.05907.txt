{
  "article_text": [
    "consider the linear discrete ill - posed problem @xmath9 where the norm @xmath10 is the 2-norm of a vector or matrix , and @xmath3 is extremely ill conditioned with its singular values decaying to zero without a noticeable gap",
    ". mainly arises from the discretization of the first kind fredholm integral equation @xmath11 where the kernel @xmath12 and @xmath13 are known functions , while @xmath14 is the unknown function to be sought .",
    "if @xmath15 is non - degenerate and @xmath13 satisfies the picard condition , there exists the unique squares integrable solution @xmath14 ; see @xcite . here for brevity we assume that @xmath16 and @xmath17 belong to the same set @xmath18 with @xmath19 .",
    "applications include image deblurring , signal processing , geophysics , computerized tomography , heat propagation , biomedical and optical imaging , groundwater modeling , and many others ; see , e.g. , @xcite .",
    "the theory and numerical treatments of integral equations can be found in @xcite .",
    "the right - hand side @xmath20 is noisy and assumed to be contaminated by a white noise @xmath21 , caused by measurement , modeling or discretization errors , where @xmath22 is noise - free and @xmath23 . because of the presence of noise @xmath21 and the extreme ill - conditioning of @xmath3 , the naive solution @xmath24 of bears no relation to the true solution @xmath25 , where @xmath26 denotes the moore - penrose inverse of a matrix",
    "therefore , one has to use regularization to extract a best possible approximation to @xmath27 .",
    "the most common regularization , in its simplest form , is the direct standard - form tikhonov regularization @xmath28 with @xmath29 the regularization parameter @xcite .",
    "the solutions to and can be fully analyzed by the singular value decomposition ( svd ) of @xmath3 .",
    "let @xmath30 be the svd of @xmath3 , where @xmath31 and @xmath32 are orthogonal , @xmath33 with the singular values @xmath34 assumed to be simple throughout the paper except section [ multiple ] , and the superscript @xmath35 denotes the transpose of a matrix or vector .",
    "then @xmath36 with @xmath37 .    throughout the paper",
    ", we always assume that @xmath22 satisfies the discrete picard condition @xmath38 with some constant @xmath39 for @xmath40 arbitrarily large @xcite .",
    "it is an analogue of the picard condition in the finite dimensional case ; see , e.g. , @xcite , @xcite , @xcite and @xcite , where it is known that this condition amounts to assuming that , on average , the fourier coefficients @xmath41 decay faster than @xmath42 and is necessary to enable regularization to compute useful approximations to it . for the ease of analysis",
    ", we assume that the coefficients satisfy a widely used model in the literature , e.g. , ( * ? ? ?",
    "* and 153 ) and @xcite : @xmath43 where @xmath44 is a model parameter that controls the decay of the fourier coefficients .    the white noise @xmath21 has a number of attractive properties which play an important role in the regularization analysis : its covariance matrix is @xmath45 , the expected values @xmath46 and @xmath47 , and @xmath48 and @xmath49 ; see , e.g. , @xcite and @xcite .",
    "the noise @xmath21 thus affects @xmath50 _ more or less equally_. with , relation shows that for large singular values @xmath51 is dominant relative to @xmath52 .",
    "once @xmath53 from some @xmath54 onwards , the small singular values magnify @xmath52 , and the noise term dominates @xmath55 and must be suppressed .",
    "the transition point @xmath56 is such that @xmath57 see @xcite and a similar description @xcite .",
    "the @xmath58 are then divided into the @xmath56 large ones and the @xmath59 small ones .",
    "the truncated svd ( tsvd ) method @xcite computes the tsvd regularized solutions @xmath60 it is known from @xcite and @xcite that @xmath61 is the best tsvd regularized solution to and balances the regularization and perturbation errors optimally .",
    "the parameter @xmath5 is a regularization parameter that determines how many large svd components of @xmath3 are used to compute a regularized solution @xmath62 to .",
    "let @xmath63 , @xmath64 and @xmath65 , and define @xmath66 .",
    "then @xmath67 is the best rank @xmath5 approximation to @xmath3 with @xmath68 ( cf .",
    "@xcite ) , and @xmath69 is the minimum - norm least squares solution to @xmath70 that perturbs @xmath3 to @xmath67 in .",
    "this interpretation will be often exploited later .",
    "the solution @xmath71 of the tikhonov regularization has a filtered svd expansion @xmath72 where the @xmath73 are called filters .",
    "the tsvd method is a special parameter filtered method , where , in @xmath62 , we take @xmath74 and @xmath75 . the error @xmath76 can be written as the sum of the regularization and perturbation errors , and an optimal @xmath77 aims to balance these two errors and make the sum of their norms minimized @xcite .",
    "the best possible regularized solution @xmath78 retains the @xmath56 dominant svd components and dampens the other @xmath59 small svd components as much as possible @xcite . apparently , the ability to acquire only the largest svd components of @xmath3 is fundamental in solving .",
    "a number of parameter - choice methods have been developed for finding @xmath77 or @xmath56 , such as the discrepancy principle @xcite , the l - curve criterion , whose use goes back to miller @xcite and lawson and hanson @xcite and is termed much later and studied in detail in @xcite , and the generalized cross validation ( gcv ) @xcite ; see , e.g. , @xcite for numerous comparisons .",
    "all parameter - choice methods aim to make @xmath79 not small for @xmath80 and @xmath81 for @xmath82 .",
    "each of these methods has its own merits and disadvantages and no one is absolutely reliable for all ill - posed problems .",
    "for example , some of the mentioned parameter - choice methods may fail to find accurate approximations to @xmath77 ; see @xcite for an analysis on the l - curve method and @xcite for some other parameter - choice methods .",
    "the tsvd method is important in its own right and plays a central role in analyzing .",
    "it and the standard - form tikhonov regularization produce very similar solutions with essentially the minimum 2-norm error , i.e. , the worst - case error @xcite ; see @xcite , @xcite , @xcite and ( * ? ? ?",
    "* sections 4.2 and 4.4 ) .",
    "indeed , for a linear compact equation @xmath83 including with the noisy @xmath84 and true solution @xmath85 , under the source condition that its solution @xmath86 or @xmath87 , the range of the adjoint @xmath88 of @xmath89 or that of @xmath90 , which amounts to assuming that @xmath85 or its derivative is squares integrable , the best regularized solutions by the tsvd method and the tikhonov regularization not only converge to @xmath85 as the noise tends to zero , but also are _ order optimal , i.e. , the same order as the worst - case error _ ; see , e.g. , @xcite , @xcite and @xcite .",
    "these conclusions carries over to the discrete @xcite .",
    "the tsvd method has been widely used as a general - purpose numerical method for small or medium sized ; see @xcite and the references therein as well as many others .",
    "therefore , we will take @xmath61 as standard reference when assessing the regularizing effects of the iterative solvers under consideration in this paper .    for large , the tsvd method and the tikhonov regularization method",
    "are generally too demanding , and only iterative regularization methods are computationally viable .",
    "a major class of methods has been krylov iterative solvers that project onto a sequence of low dimensional krylov subspaces and computes iterates to approximate @xmath27 ; see , e.g. , @xcite .",
    "of krylov iterative solvers , the cgls ( or cgnr ) method , which implicitly applies the conjugate gradient ( cg ) method @xcite to the normal equations @xmath6 of , and its mathematically equivalent lsqr algorithm @xcite have been most commonly used .",
    "the krylov solvers cgme ( or cgne ) @xcite and lsmr @xcite are also choices , which amount to the cg method applied to @xmath7 with @xmath8 and minres @xcite applied to @xmath6 , respectively .",
    "these krylov solvers have been intensively studied and known to have regularizing effects @xcite and exhibit semi - convergence @xcite ; see also @xcite , @xcite , @xcite and @xcite : the iterates converge to @xmath27 and their norms increase steadily , and the residual norms decrease in an initial stage ; then afterwards the noise @xmath21 starts to deteriorate the iterates so that they start to diverge from @xmath27 and instead converge to @xmath55 , while their norms increase considerably and the residual norms stabilize .",
    "if we stop at the right time , then , in principle , we have a regularization method , where the iteration number plays the role of parameter regularization .",
    "semi - convergence is due to the fact that the projected problem starts to inherit the ill - conditioning of from some iteration onwards , and the appearance of a small singular value of the projected problem amplifies the noise considerably .",
    "the regularizing effects of cg type methods were noticed by lanczos @xcite and were rediscovered in @xcite . based on these works and motivated by a heuristic explanation on good numerical results with very few iterations using cgls in @xcite , and realizing that such an excellent performance can only be expected",
    "if convergence to the regular part of the solution , i.e. , @xmath61 , takes place before the effects of ill - posedness show up , on page 13 of @xcite , bjrck and eldn in 1979 foresightedly expressed a fundamental concern on cgls ( and lsqr ) : _ more research is needed to tell for which problems this approach will work , and what stopping criterion to choose .",
    "_ see also @xcite . as remarked by hanke and hansen @xcite ,",
    "the paper @xcite was the only extensive survey on algorithmic details until that time and was for the conference proceedings that unfortunately never appeared , and a strict proof of the regulariziing properties of conjugate gradients is extremely difficult .",
    "an enormous effort has long been made to the study of regularizing effects of lsqr and cgls ( cf .",
    "@xcite and many references therein ) in the hilbert or finite dimensional space setting , but a rigorous regularization theory of lsqr and cgls for is still lacking , and hitherto there has been no definitive answer to the above long - standing fundamental question , and the same is for lsmr and cgme .    for @xmath3 symmetric ,",
    "minres and mr - ii applied to directly are alternatives and have been shown to have regularizing effects @xcite , but mr - ii seems preferable since the noisy @xmath2 is excluded in the underlying subspace @xcite . for @xmath3 nonsymmetric or multiplication with @xmath91 difficult to compute , gmres and rrgmres are candidate methods @xcite , and the latter may be better @xcite .",
    "the hybrid approaches based on the arnoldi process have been first proposed in @xcite and studied in @xcite .",
    "gazzola and her coauthors @xcite@xcite have described a general framework of the hybrid methods and presented various krylov - tikhonov methods with different parameter choice strategies .",
    "unfortunately , these methods are not general - purpose regularization methods , and their success is highly problem dependent ; see , e.g. , @xcite and @xcite .",
    "the fundamental cause is that the underlying krylov subspaces generally favor a possibly dominant eigenspace of @xmath3 other than its dominant right singular subspace , which is exactly desired in solving .",
    "the behavior of ill - posed problems critically depends on the decay rate of @xmath92 .",
    "the following characterization of the degree of ill - posedness of was introduced in @xcite and has been widely used @xcite : if @xmath93 , then is mildly or moderately ill - posed for @xmath94 or @xmath95 .",
    "if @xmath96 with @xmath97 , @xmath98 , then is severely ill - posed . here for mildly ill - posed problems we add the requirement @xmath99 , which does not appear in @xcite but must be met for @xmath12 in @xcite . actually , in the one - dimensional @xmath100 case , is severely ill - posed with @xmath15 sufficiently smooth , and it is moderately ill - posed with @xmath101 , where @xmath102 is the highest order of continuous derivatives of @xmath15 ; see , e.g. , @xcite and @xcite .",
    "clearly , the singular values @xmath92 for a severely ill - posed problem decay exponentially at the same rate @xmath103 , while those of a moderately or mildly ill - posed problem decay at the decreasing rate @xmath104 that approaches one with @xmath105 and , for the same @xmath105 , is smaller for the moderately ill - posed problem than for the mildly ill - posed problem .    if a regularized solution to is at least as accurate as @xmath61 , then it is called a best possible regularized solution . given , if the semi - convergence of an iterative solver means that a best possible regularized solution has been found , then , by the words of bjrck and eldn , the solver _ works _ for the problem and is claimed to have the _ full _ regularization . otherwise , the solver is said to have the _ partial _ regularization .    because of the lack of solid and complete regularization theory , it has been unknown whether or not lsqr , cgls , lsmr and cgme have the full regularization for a given . to this end ,",
    "one commonly combines them with some explicit regularization , so that the resulting hybrid variants ( hopefully ) find best possible regularized solutions @xcite .",
    "a hybrid cgls is to run cgls for several hopefully good regularization parameters @xmath106 and picks up a best regularized solution @xcite .",
    "its disadvantage is that regularized solutions can not be updated with different @xmath106 .",
    "the hybrid lsqr variants have been advocated by bjrck and eldn @xcite and oleary and simmons @xcite , and improved and developed by bjrck @xcite and bjrck , grimme and van dooren @xcite . a hybrid lsqr",
    "first projects onto krylov subspaces and then regularizes the projected problems explicitly .",
    "it aims to remove the effects of small ritz values and expands a krylov subspace until it captures the @xmath56 dominant svd components of @xmath3 @xcite .",
    "the hybrid lsqr and cgme have been intensively studied in , e.g. , @xcite and @xcite .",
    "hybrid lsqr variants are sophisticated or cumbersome , and it is hard to find a near - optimal regularization parameter @xcite .",
    "in contrast , if an iterative solver has the full regularization , it is then straightforward to stop it after semi - convergence , and it is unnecessary to introduce its hybrid variant .",
    "obviously , we can not emphasize too much the importance of completely understanding the regularization of lsqr , cgls , lsmr and cgme . by the definition of the full or partial regularization",
    ", we now modify the concern by bjrck and eldn as : _ do lsqr , cgls , lsmr and cgme have the full or partial regularization for severely , moderately and mildly ill - posed problems ? how to identify their full or partial regularization in practice ?",
    "_    in this paper , assuming exact arithmetic , we first focus on lsqr and make a rigorous and complete analysis on its regularization for severely , moderately and mildly ill - posed problems . due to the mathematical equivalence of cgls and lsqr , the assertions on the full or partial regularization of lsqr",
    "apply to cgls as well .",
    "we then analyze the regularizing effects of lsmr and cgme and draw definitive conclusions .",
    "we prove that lsqr has the full regularization for severely and moderately ill - posed problems with @xmath97 and @xmath95 suitably , and it generally has only the partial regularization for mildly ill - posed problems . in section [ lsqr ] , we describe the lanczos bidiagonalization process and lsqr , and make an introductory analysis . in section [ sine ] ,",
    "we establish accurate @xmath4 theorems for the 2-norm distance between the underlying @xmath5-dimensional krylov subspace and the @xmath5-dimensional dominant right singular subspace of @xmath3 .",
    "we then derive some follow - up results that play a central role in analyzing the regularization of lsqr . in section [ rankapp ]",
    ", we prove that a @xmath5-step lanczos bidiagonalization always generates a near best rank @xmath5 approximation to @xmath3 , and the @xmath5 ritz values always approximate the first @xmath5 large singular values in natural order , and no small ritz value appears before iteration @xmath107 .",
    "this will show that lsqr has the full regularization . in the meantime",
    ", we prove that , for @xmath107 , the @xmath5 ritz values generally do not approximate the first @xmath5 large singular values in natural order and lsqr generally has only the partial regularization for mildly ill - posed problems . in section [ alphabeta ]",
    ", we derive bounds for the entries of bidiagonal matrices generated by lanczos bidiagonalization , which prove how fast they decay and are of practical importance to reliably identify whether or not lsqr has the full regularization without extra cost when the degree of ill - posedness of is unknown in advance . exploiting some of the results on lsqr , we analyze the regularization of lsmr and cgme and prove that lsmr has similar regularizing effects to lsqr for each kind of problem and both of them are superior to cgme . in section",
    "[ compare ] , we present some perturbation results and prove that lsqr resembles the tsvd method for severely and moderately ill - posed problems . in section [ multiple ] , with a number of nontrivial changes and reformulations ,",
    "we extend all the results to the case that @xmath3 has multiple singular values . in section [ numer ] , we report numerical experiments to confirm our theory on lsqr .",
    "finally , we summarize the paper with further remarks in section [ concl ] .    throughout the paper , denote by @xmath108 the @xmath5-dimensional krylov subspace generated by the matrix @xmath109 and the vector @xmath110 , and by @xmath111 and the bold letter @xmath112 the identity matrix and the zero matrix with orders clear from the context , respectively . for @xmath113 , we define the nonnegative matrix @xmath114 , and for @xmath115 , @xmath116 means @xmath117 componentwise .",
    "lsqr is based on the lanczos bidiagonalization process , which computes two orthonormal bases @xmath118 and @xmath119 of @xmath120 and @xmath121 for @xmath122 , respectively .",
    "we describe the process as algorithm 1 .",
    "* algorithm 1 :   @xmath5-step lanczos bidiagonalization process *    take @xmath123 , and define @xmath124 .    for @xmath125    @xmath126    @xmath127    @xmath128    @xmath129    algorithm 1 can be written in the matrix form @xmath130 where @xmath131 denotes the @xmath132-th canonical basis vector of @xmath133 , @xmath134 , @xmath135 and @xmath136 it is known from that @xmath137 we remind that the singular values of @xmath138 are all simple , provided that lanczos bidiagonalization does not break down .",
    "this basic fact will often be used later .    at iteration @xmath5",
    ", lsqr solves the problem @xmath139 and computes the approximate solution @xmath140 with @xmath141 where @xmath142 is the first canonical basis vector of @xmath133 , and the residual norm @xmath143 decreases monotonically with respect to @xmath5 .",
    "we have @xmath144 and @xmath145 , both of which can be cheaply computed .",
    "note that @xmath146 .",
    "we have @xmath147 i.e. , the iterate @xmath148 by lsqr is the minimum - norm least squares solution to the perturbed problem that replaces @xmath3 in by its rank @xmath5 approximation @xmath149 .",
    "recall that the best rank @xmath5 approximation @xmath67 to @xmath3 satisfies @xmath68 .",
    "we can relate lsqr and the tsvd method from two perspectives .",
    "one of them is to interpret lsqr as solving a nearby problem that perturbs @xmath67 to @xmath149 , provided that @xmath149 is a near best rank @xmath5 approximation to @xmath3 with an approximate accuracy @xmath150 .",
    "the other is to interpret @xmath62 and @xmath148 as the solutions to the two perturbed problems of that replace @xmath3 by the rank @xmath5 approximations with the same quality to @xmath3 , respectively .",
    "both perspectives lead to the consequence : the lsqr iterate @xmath151 is as accurate as @xmath61 and is thus a best possible regularized solution to , provided that @xmath149 is a near best rank @xmath5 approximation to @xmath3 with the approximate accuracy @xmath150 and the @xmath5 singular values of @xmath138 approximate the first @xmath5 large ones of @xmath3 in natural order for @xmath152 .",
    "otherwise , as will be clear later , @xmath151 can not be as accurate as @xmath61 if either @xmath153 is not a near best rank @xmath56 approximation to @xmath3 or @xmath154 has at least one singular value smaller than @xmath155",
    ". we will give a precise definition of a near best rank @xmath5 approximation later .",
    "as stated in the introduction , the semi - convergence of lsqr must occur at some iteration @xmath5 . under the discrete picard condition , if semi - convergence occurs at iteration @xmath56 , we are sure that lsqr has the full regularization because @xmath151 has captured the @xmath56 dominant svd components of @xmath3 and effectively suppressed the other @xmath59 svd components ; if semi - convergence occurs at some iteration @xmath156 , then lsqr has only the partial regularization since it has not yet captured the needed @xmath56 dominant svd components of @xmath3 .",
    "van der sluis and van der vorst @xcite prove the following result , which has been used in hansen @xcite and the references therein to illustrate and analyze the regularizing effects of lsqr and cgls .",
    "we will also exploit it in our paper .",
    "[ help ] for lsqr to solve with the starting vector @xmath159 and cgls to solve the normal equations @xmath6 with the starting vector @xmath160 , the iterate @xmath148 satisfies @xmath161 where @xmath162 and the @xmath163 are the singular values of @xmath138 labeled as @xmath164 .",
    "shows that @xmath148 has a filtered svd expansion of form . if all the @xmath163 , called the ritz values , approximate the first @xmath5 singular values @xmath92 of @xmath3 in natural order , the filters @xmath165 and the other @xmath166 monotonically decay to zero with @xmath167 .",
    "if this is the case until @xmath168 , the @xmath56-step lsqr has the full regularization and computes a best possible regularized solution @xmath151 .",
    "however , if a small ritz value appears before some @xmath107 , i.e. , @xmath169 and @xmath170 with the smallest integer @xmath171 , then @xmath172 tends to zero monotonically with respect to @xmath173 ; on the other hand , we have @xmath174 since the first factor is non - positive and the second factor is positive .",
    "then we get @xmath175 , causing that @xmath148 is deteriorated and lsqr has only the partial regularization .",
    "hansen @xcite summarizes the known results on @xmath166 , where a complicated bound for @xmath176 is given in @xcite but there is no way of estimating the bound itself accurately . as we will see in section [ compare ] , the results to be established in this paper can be used for this purpose , and , more importantly , we will show that the bound there can be sharpened substantially .",
    "the standard @xmath5-step lanczos bidiagonalization method computes the @xmath5 ritz values @xmath163 , which are used to approximate some of the singular values of @xmath3 , and it is mathematically equivalent to the symmetric lanczos method for the eigenvalue problem of @xmath177 starting with @xmath178 ; see @xcite or @xcite for several variations that are based on standard , harmonic , refined projection @xcite or a combination of them .",
    "a general convergence theory of harmonic and refined harmonic projection methods was lacking in the books @xcite and has later been established in @xcite . as is known from @xcite , for a general singular value distribution and a general vector @xmath2 , some of the @xmath5 ritz values become good approximations to the largest and smallest singular values of @xmath3 as @xmath5 increases . if large singular values are well separated but small singular values are clustered , large ritz values converge fast but small ritz values converge very slowly .    for",
    ", we see from that @xmath179 contains more information on dominant right singular vectors than on the ones corresponding to small singular values .",
    "therefore , @xmath157 hopefully contains richer information on the first @xmath5 right singular vectors @xmath180 than on the other @xmath181 ones , at least for @xmath5 small .",
    "furthermore , note that @xmath3 has many small singular values clustered at zero . due to these two basic facts ,",
    "all the ritz values are expected to approximate the large singular values of @xmath3 in natural order until some iteration @xmath5 , at which a small ritz value shows up and the regularized solutions then start to be contaminated by the noise @xmath21 dramatically after that iteration .",
    "these qualitative arguments are frequently used to analyze and elaborate the regularizing effects of lsqr and cgls ; see , e.g. , @xcite and the references therein . clearly , these arguments , though helpful to show that lsqr and cgls have regularizing effects , are uncertain , and they are useless to draw any definitive conclusion on the full or partial regularization of lsqr . for a severely ill - posed example from seismic tomography , it is reported in @xcite that the desired convergence of the ritz values actually holds as long as the discrete picard condition is satisfied and there is a good separation among the large singular values of @xmath3 .",
    "unfortunately , there has been no mathematical justification on these observations .",
    "rigorously and quantitatively speaking , a complete understanding of the regularization of lsqr includes accurate solutions of the following basic problems : how well or accurately does @xmath182 approximate or capture the @xmath5-dimensional dominant right singular subspace of @xmath3 ?",
    "how accurate is the rank @xmath5 approximation @xmath183 to @xmath3 ? can it be a near best rank @xmath5 approximation to @xmath3 ? how does the noise level @xmath184 affects the approximation accuracy of @xmath182 and @xmath183 for @xmath107 and @xmath185 , respectively ?",
    "what sufficient conditions on @xmath186 and @xmath187 are needed to guarantee that @xmath183 is a near best rank @xmath5 approximation to @xmath3 ? when do the ritz values @xmath188 approximate @xmath189 in natural order ?",
    "when does at least a small ritz value appear , i.e. , @xmath190 before some @xmath107",
    "? we will make a rigorous and detailed analysis on these problems and some others related closely , present our results , and draw definitive assertions on the regularization of lsqr for three kinds of ill - posed problems .    in terms of the canonical angles @xmath191 between two subspaces @xmath192 and @xmath193 of the same dimension @xcite , we first present the following @xmath4 theorem , showing how the @xmath5-dimensional krylov subspace @xmath182 captures or approximates the @xmath5-dimensional dominant right singular subspace of @xmath3 for severely ill - posed problems .",
    "[ thm2 ] let the svd of @xmath3 be as .",
    "assume that is severely ill - posed with @xmath96 and @xmath97 , @xmath98 , and the discrete picard condition is satisfied .",
    "let @xmath194 be the subspace spanned by the columns of @xmath195 and @xmath196 .",
    "then for @xmath197 we have @xmath198 with @xmath199 to be defined by and @xmath200 @xmath201 where @xmath202 whose columns are the first @xmath40 left singular vectors of @xmath3 defined by . then the krylov subspace @xmath203 with @xmath204 partition the diagonal matrix @xmath205 and the matrix @xmath206 as follows : @xmath207 where @xmath208 .",
    "since @xmath209 is a vandermonde matrix with @xmath92 supposed to be distinct for @xmath125 , it is nonsingular .",
    "therefore , from @xmath210 we have @xmath211 where @xmath212 write @xmath213 , and define @xmath214 then @xmath215 , and the columns of @xmath216 form an orthonormal basis of @xmath217 .",
    "so we get an orthogonal direct sum decomposition of @xmath218 : @xmath219 by definition and , for the matrix 2-norm we obtain @xmath220 which is .",
    "next we estimate @xmath221 .",
    "for @xmath222 , it is easily justified that the @xmath105-th column of @xmath223 consists of the coefficients of the @xmath105-th lagrange polynomial @xmath224 that interpolates the elements of the @xmath105-th canonical basis vector @xmath225 at the abscissas @xmath226 .",
    "consequently , the @xmath105-th column of @xmath227 is @xmath228 from which we obtain @xmath229 since @xmath230 is monotonically decreasing for @xmath231 , it is bounded by @xmath232 . with this property and the definition of @xmath233 by",
    ", we get @xmath234 where @xmath235 is a rank one matrix . therefore , by @xmath236 ( cf .",
    "@xcite ) , we get @xmath237    by the discrete picard condition , and the description between them , for the white noise @xmath21 , it is known from @xcite and @xcite that @xmath238 decrease as @xmath105 increases up to @xmath56 and then become stabilized as @xmath238 a constant for @xmath239 . in order to simplify the derivation and",
    "present our results compactly , in terms of these assumptions and properties , in later proofs we will use the precise relationships @xmath240 , for @xmath197 we obtain @xmath241 with @xmath242 replaced by one for @xmath243 . in a similar manner , for @xmath222 ,",
    "from we get @xmath244 from the above and , we finally obtain @xmath245 which proves .",
    "note that the langrange polynomials @xmath246 require @xmath247 .",
    "so , we need to treat the case @xmath248 independently : from and , observe that @xmath249 therefore , we have @xmath250 from which and for @xmath248 it is direct to get .    in terms of the discrete picard condition , , and , we have @xmath251 and @xmath252 applying them to and establishes , and , respectively .",
    "we next estimate the factor @xmath253 accurately .",
    "[ estlk ] for the severely ill - posed problem and @xmath222 , we have @xmath254    _ proof_. exploiting the taylor series expansion and @xmath255 for @xmath256 , by definition , for @xmath257 we have @xmath258 by absorbing those higher order terms into the two @xmath259 in the numerator . for @xmath260 , we get @xmath261 which is",
    ".    note that for the numerator of we have @xmath262 and @xmath263 whose product for any @xmath5 is @xmath264 on the other hand , note that the denominator of is defined by @xmath265 which , together with the above estimate for the numerator of , proves .",
    "notice that @xmath266 is always _",
    "bigger than one _ for @xmath257 .",
    "therefore , for any @xmath5 , combining and gives .",
    "[ severerem ] and have essentially been shown in @xcite . here",
    "we have given a general and complete proof . from , we get @xmath267 so the results in theorem  [ thm2 ] are simplified as @xmath268    and its proof illustrate that @xmath232 exhibits monotonically increasing tendency with respect to @xmath105 . and indicate that @xmath217 captures @xmath269 better for @xmath107 than for @xmath185 .",
    "that is , after iteration @xmath56 , the noise @xmath21 starts to deteriorate @xmath217 and impair its ability to capture @xmath269 .    in what follows",
    "we establish accurate estimates for @xmath270 for moderately and mildly ill - posed problems .",
    "[ moderate ] assume that is moderately ill - posed with @xmath271 , where @xmath99 and @xmath272 is some positive constant , and other assumptions and notation the same as in theorem  [ thm2 ] . then holds with @xmath273",
    "particularly , we have @xmath274    _ proof_. following the proof of theorem  [ thm2 ] , we know that @xmath275 defined by .",
    "so we only need to bound the right - hand side of . for @xmath276 , from we get @xmath277 since the function @xmath278 with any @xmath279 is convex over the interval @xmath280 $ ] , for @xmath281 , from we obtain @xmath282 substituting the above and into establishes , from which and , it follows that and hold . for @xmath248",
    ", we still have , from which and we obtain . from and we get .    for a purely technical reason and precise presentation and for the ease of analysis",
    ", we have used the simplified singular value model @xmath283 to replace the general form @xmath93 , where the constant in each @xmath259 is qualitative and implicit .",
    "this model , though simple , reflects the essence of moderately and mildly ill - posed problems and avoids some troublesome derivations and non - transparent formulations .    in the spirit of the proof of theorem  [ estlk ] , exploiting the first order taylor expansion , we have an estimate @xmath284 where the right - hand side of increases linearly with respect to @xmath5 .    [ rem3.5 ] and indicate that @xmath285 is guaranteed for moderately ill - posed problems with @xmath95 .",
    "one may worry that the upper bounds and overestimate @xmath221 and thus @xmath270 because , in the proof , we have bounded the opaque @xmath286 in from above by the compact integral nearest to it , which can be overestimates for @xmath152 .",
    "it is not the case only if @xmath56 is not very small .",
    "in fact , since @xmath99 , we can bound from below by the integral nearest to it : @xmath287 which is near to once @xmath107 is not very small",
    ". the smaller @xmath187 , the smaller the difference between the upper and lower bounds , i.e. , the sharper .",
    "it is easily seen from that @xmath270 increases monotonically with respect to @xmath221 . for @xmath221",
    "reasonably small and @xmath221 large we have @xmath288 respectively . from and , we obtain @xmath289 , where @xmath290 is the gaussian function .",
    "for the white noise @xmath21 , we have @xmath291 . as a result , for moderately ill - posed problems with @xmath95",
    ", @xmath56 is typically small and at most modest for a practical noise @xmath21 , whose relative size @xmath292 typically ranges from @xmath293 to @xmath294 .",
    "this means that for this kind of problem @xmath221 is at most modest and can not be large , so that @xmath295 fairly .    for severely ill - posed problems , since all the @xmath296 , a constant , and indicate that @xmath270 is essentially unchanged for @xmath152 and @xmath297 , respectively , that is , @xmath217 captures @xmath269 with almost the same accuracy for @xmath107 and @xmath185 , respectively .",
    "however , the situation is different for moderately ill - posed problems . for them",
    ", @xmath298 increases slowly as @xmath5 increases , and the factor latexmath:[$\\sqrt{\\frac{k^2}{4\\alpha^2 - 1}+\\frac{k}{2\\alpha-1 } }    illustrate that @xmath270 increases slowly with @xmath107 and @xmath300 , respectively .",
    "this means that @xmath217 may not capture @xmath269 so well as it does for severely ill - posed problems as @xmath5 increases . in particular , starting with some @xmath185 , @xmath270 starts to approach one , which indicates that , for @xmath5 big , @xmath217 will contain substantial information on the right singular vectors corresponding to the @xmath181 small singular values of @xmath3 .",
    "[ mildrem ] for mildly ill - posed problems with @xmath301 , there are some distinctive features .",
    "note from and that @xmath56 is now considerably bigger than that for a severely or moderately ill - posed problem with the same noise level @xmath184 and @xmath44 . as a result ,",
    "firstly , for @xmath302 and the same @xmath5 , the factor @xmath303 is bigger than that for the moderately ill - posed problem ; secondly , @xmath304 if @xmath305 and is much bigger than @xmath5 and can be arbitrarily large if @xmath306 ; thirdly , since @xmath307 , for @xmath308 that ensures @xmath309 , we have @xmath310 which also holds for moderately ill - posed problems and is bigger than one considerably for @xmath307 as @xmath5 increases up to @xmath56 .",
    "our accurate bound thus becomes increasingly large as @xmath5 increases up to @xmath56 for mildly ill - posed problems , causing that @xmath221 is large and @xmath311 starting with some @xmath107 .",
    "consequently , @xmath312 can not effectively capture the @xmath56 dominant right singular vectors and contains substantial information on the right singular vectors corresponding to the @xmath59 small singular values .    in ( * ?",
    "* thm 2.1 ) , the authors have derived some rough bounds for @xmath221 and thus @xmath270 . there , without realizing the crucial fact that @xmath313 can be effectively bounded by a rank one matrix and the key point that @xmath314 must be treated as a whole other than separately , by the authors made use of @xmath315 and @xmath316 ( cf . ) to obtain bounds for @xmath221 and thus @xmath270 .",
    "these bounds are too pessimistic because of the appearance of the fatal factor @xmath317 , which ranges from @xmath318 to @xmath319 for @xmath222 , too large amplification for @xmath40 large . in contrast , our new estimates , which hold for both @xmath221 and @xmath320 , are much more accurate and @xmath317 has been removed .    before proceeding ,",
    "we tentatively investigate how @xmath270 affects the smallest ritz value @xmath321 .",
    "this problem is of central importance for understanding the regularizing effects of lsqr .",
    "we aim to lead the reader to a first manifestation that ( i ) we may have @xmath322 when @xmath295 fairly , that is , no small ritz value may appear only if @xmath217 captures @xmath269 with only _ some _ other than high accuracy , and ( ii ) we must have @xmath323 , that is , @xmath321 can not approximate @xmath58 in natural order , once @xmath270 is sufficiently close to one .    [ initial ]",
    "let @xmath324 with @xmath325 , @xmath197 , and let the unit - length @xmath326 be a vector that has the smallest acute angle with @xmath327 , i.e. , the closest to @xmath327 , where @xmath328 is the matrix consisting of the last @xmath181 columns of @xmath329 defined by .",
    "then it holds that @xmath330 if @xmath331 , then @xmath332 if @xmath333 for a given arbitrarily small @xmath334 , then @xmath335    _ proof_. since the columns of @xmath336 generated by lanczos bidiagonalization form an orthonormal basis of @xmath217 , by definition and the assumption on @xmath337 we have @xmath338 with @xmath339 and @xmath340 . since @xmath269 is the orthogonal complement of @xmath327 , by definition we know that @xmath341 has the largest acute angle with @xmath269 , that is , it contains the least information from @xmath269 .",
    "expand @xmath337 as the following orthogonal direct sum decomposition : @xmath342 then from @xmath343 and we obtain @xmath344 from , we next bound the rayleigh quotient of @xmath337 with respect to @xmath177 from below . by the svd of @xmath3 , we partition @xmath345 and @xmath346 where @xmath347 and @xmath348 . making use of @xmath349 and @xmath350 as well as @xmath351",
    ", we obtain @xmath352 observe that it is impossible for @xmath353 and @xmath354 to be the right singular vectors of @xmath355 and @xmath356 associated with the smallest singular values @xmath357 and @xmath358 of @xmath359 and @xmath360 simultaneously , which are the @xmath361-th canonical vector @xmath362 of @xmath363 and the @xmath5-th canonical vector @xmath364 of @xmath365 , respectively ; otherwise , we have @xmath366 and @xmath367 simultaneously , which are impossible as @xmath368 .",
    "therefore , from we obtain the strict inequality @xmath369 from which it follows that the lower bound of holds .",
    "similarly , from we obtain the upper bound of : @xmath370    from the lower bound of , we see that if @xmath371 satisfies @xmath372 , i.e. , @xmath331 , then @xmath373 , i.e. , holds .    from and",
    ", we get @xmath374 .",
    "note that @xmath375 is the smallest singular value , i.e. , eigenvalue , of the symmetric positive definite matrix @xmath376 .",
    "therefore , we have @xmath377 where @xmath378 is , in fact , the ritz vector of @xmath177 from @xmath217 corresponding to the smallest ritz value @xmath375 .",
    "therefore , for @xmath337 defined in theorem  [ initial ] we have @xmath379 from which it follows from that @xmath380 . as a result , for any @xmath334",
    ", we can choose @xmath381 such that @xmath382 i.e. , holds , solving which for @xmath383 gives @xmath333 .",
    "we analyze @xmath321 when @xmath331 .",
    "a key observation and interpretation is that , in the sense of @xmath384 in , @xmath385 is the optimal vector that extracts the least information from @xmath269 and the richest information from @xmath327 . from theorem  [ initial ] , since @xmath269 is the orthogonal complement of @xmath327 , we know that @xmath341 has the largest acute angle with @xmath269 , that is , it contains the least information from @xmath269 and the richest information from @xmath327 .",
    "therefore , @xmath378 and @xmath337 have a similar optimality , so that we have @xmath386 combining this estimate with , we may have @xmath322 when @xmath331 .",
    "we inspect the condition @xmath387 for and get insight into whether or not the true @xmath371 resulting from three kinds of ill - posed problems satisfies it . for severely ill - posed problems ,",
    "this lower bound is basically the constant @xmath103 ; for moderately ill - posed problems with @xmath95 , the bound increases with increasing @xmath107 , and it can not be close to one provided that @xmath95 suitably or @xmath56 not big ; for mildly ill - posed problems with @xmath388 , the bound increases faster than it does for moderately ill - posed problems , and it may well approach one for @xmath107 . therefore , means that @xmath270 is not close to one for severely and moderately ill - posed problems , but it requires that @xmath270 must be close to zero for mildly ill - posed problems . in view of and @xmath324",
    ", we have @xmath389 .",
    "thus , the condition @xmath387 for amounts to requiring that @xmath221 is at most modest and can not be large for severely and moderately ill - posed problems but it must be fairly small for mildly ill - posed problems .",
    "unfortunately , theorems  [ thm2][moderate ] and the remarks followed indicate that @xmath221 increases with increasing @xmath5 and is generally large for a mildly ill - posed problem , while it increases slowly with @xmath107 for a moderately ill - posed problem with @xmath95 suitably , and by it is approximately a constant @xmath390 considerably for a severely ill - posed problem with @xmath97 not close to one .",
    "consequently , for mildly ill - posed problems , because the actual @xmath221 can hardly be small and is generally large , the true @xmath371 is small and may well be close to one , so that the condition @xmath391 generally fails to meet as @xmath5 increases , while it is satisfied for severely or moderately ill - posed problems with @xmath97 or @xmath95 suitably .",
    "[ appear ] shows that there is at least one ritz value @xmath323 when @xmath270 is sufficiently close to one since we can choose @xmath392 small enough such that @xmath393 is close to @xmath150 arbitrarily .",
    "as we have shown , @xmath270 can not be close to one for severely or moderately ill - posed problems with @xmath97 or @xmath95 suitably , but it is generally so for mildly ill - posed problems .",
    "this means that for some @xmath107 it is very possible to have @xmath323 for mildly ill - posed problems .",
    "however , we must be aware that our above analysis on @xmath322 is not rigorous because we can not quantify _ how small _ @xmath394 is . from @xmath395 , it is apparent that the condition @xmath391 may not be sufficient for @xmath322 though it is so for @xmath373 .",
    "we delay our detailed and rigorous analysis to section [ rankapp ] , where we present a number of deep - going and accurate results on the key problems stated in the last second paragraph before theorem  [ thm2 ] , including the precise behavior of @xmath321 .",
    "one of the results will be on the sufficient conditions for @xmath322 , which are satisfied when certain deterministic and mild restrictions on @xmath186 or @xmath187 are imposed for severely or moderately ill - posed problems .",
    "however , we will see that @xmath388 for mildly ill - posed problems never meets the sufficient conditions to be presented there .",
    "theorems  [ thm2][moderate ] establish necessary background for answering the fundamental concern by bjrck and eldn , and their proof approaches also provide key ingredients for some of the later results .",
    "we next present the following results , which will play a central role in our later analysis .",
    "[ thm3 ] assume that the dicrete picard condition is satisfied , let @xmath396 be defined as and @xmath397 be defined as , and write @xmath398 . then for severely ill - posed problems and @xmath197 we have @xmath399 and @xmath400 for moderately or mild ill - posed problems with the singular values @xmath283 and @xmath272 a positive constant we have @xmath401 and @xmath402    _ proof_. from and , for @xmath125 and @xmath403 we have @xmath404 and from , for @xmath248 we have @xmath405 therefore , for severely ill - posed problems , @xmath197 and @xmath125 , from we obtain @xmath406 for moderately or mildly ill - posed problems , @xmath197 and @xmath125 , from we obtain @xmath407 combining the above with , and , we obtain , while follows from the above and directly . for @xmath248 , from and the above we get and , respectively .    by , for @xmath403 we have @xmath408 therefore ,",
    "we get @xmath409 by for @xmath248 we have @xmath410 we have derived the bounds and for @xmath411 for severely and moderately or mildly ill - posed problems , respectively , from which we obtain and for @xmath248 . in order to bound @xmath412 for @xmath403",
    ", we also need to estimate @xmath413 .",
    "we next carry out this task for severely and moderately ill - posed problems , respectively , for each kind of which we study @xmath107 and @xmath185 separately .",
    "case of @xmath107 for severely ill - posed problems : from the discrete picard condition and , we obtain @xmath414    case of @xmath300 for severely ill - posed problems : from above and , , we obtain @xmath415 substituting the above two relations for the two cases into and combining them with and , we get .",
    "case of @xmath107 for moderately or mildly ill - posed problems : from we have @xmath416    case of @xmath300 for moderately or mildly ill - posed problems : from and we have @xmath417 substituting the above two bounds for the two cases into and combining them with , we get .    and",
    "indicate that @xmath412 decays swiftly as @xmath5 increases .",
    "as has been seen , we must take some cares to accurately bound @xmath412 .",
    "indeed , for @xmath418 , if we had simply bounded it by @xmath419 the factors @xmath150 in and @xmath58 in would have become @xmath420 and @xmath421 , fixed constants , by substituting the estimates and for @xmath221 into the above .",
    "this way will overestimate @xmath412 too much as @xmath5 increases , and the resulting bounds for @xmath412 are useless to precisely analyze the regularization of lsqr , cgme and lsmr for ill - posed problems since they make us impossible to get those predictively accurate results which will be presented in section [ rankapp]section [ compare ] .    as a byproduct",
    ", we consider an interesting problem that has its own right , though its solution will not be used in this paper : how close to the krylov subspace @xmath217 is the individual right singular vector @xmath422 for @xmath423 and @xmath197 ?",
    "denote by @xmath424 the distance between @xmath422 and @xmath217 , which is defined as @xmath425 with @xmath426 the orthogonal projector onto @xmath217 .",
    "then we present the following result .",
    "[ indiv ] let @xmath398 be defined by .",
    "then for @xmath197 and @xmath125 we have @xmath427 where @xmath428 denotes the smallest singular value of a matrix .    _",
    "proof_. we first prove the upper bound of . since the columns of @xmath429 defined by form a basis of @xmath217 , its @xmath105-th column @xmath430 . as a result",
    ", we get @xmath431 recall from that the columns of @xmath218 form an orthonormal basis of @xmath217 , and suppose that @xmath432 is orthogonal . then the columns of @xmath433 are an orthonormal basis of the orthogonal complement of @xmath217 with respect to @xmath434 .",
    "particularly , @xmath435 meets the requirement . by definition ,",
    "we obtain @xmath436 from which and @xmath437 it follows that @xmath438 by taking @xmath439 .",
    "so the upper bound of holds .",
    "we next derive the lower bound of .",
    "we obtain from above that @xmath440    we remark that the lower bound in is just the sine of the smallest canonical angle of @xmath269 and @xmath217 . since @xmath441 , it is natural that @xmath442 lies between the smallest and largest angles of @xmath269 and @xmath217 , as indicates . combining with and",
    ", we see that the smaller @xmath105 , the closer @xmath422 is to @xmath217 .",
    "meanwhile , for fixed @xmath5 , since , from , the bounds and for @xmath443 tend to increase monotonically with respect to @xmath105 , indicates that the subspace @xmath444 is as close to @xmath217 as the last column @xmath422 of @xmath445 .",
    "making use of theorems  [ thm2][thm3 ] , we are able to solve those key problems stated before theorem  [ thm2 ] and give definitive answers to the fundamental concern by bjrck and eldn , proving that lsqr has the full regularization for severely or moderately ill - posed problems with @xmath97 or @xmath95 suitably and it , in general , has only the partial regularization for mildly ill - posed problems .    define @xmath446 which measures the accuracy of the rank @xmath5 approximation @xmath183 generated by lanczos bidiagonalization to @xmath3 .",
    "recall and the comments followed .",
    "it is known that the full or partial regularization of lsqr uniquely depends on whether or not @xmath447 holds , where the precise meaning ` @xmath448 ' will be clear by introducing the definition of near best rank @xmath5 approximation to @xmath3 , and on whether or not the @xmath5 singular values @xmath188 ,",
    "i.e. , ritz values , of @xmath138 , approximate the @xmath5 large singular values @xmath42 of @xmath3 in natural order for @xmath449 .",
    "if both of them hold , lsqr has the full regularization ; if either of them is not satisfied , lsqr has only the partial regularization .",
    "this section consists of three subsections . in section [ rankaccur ] ,",
    "we present accurate estimates for @xmath450 for three kinds of ill - posed problems under consideration .",
    "we prove that , under some reasonable conditions on @xmath186 or @xmath187 , the matrix @xmath183 is a near best rank @xmath5 approximation to @xmath3 . in section [ ritzapprox ] , we deepen the results in section [ rankaccur ] and show how the @xmath5 ritz values @xmath188 behave .",
    "we derive the sufficient conditions on @xmath186 and @xmath187 for which they approximate the first @xmath5 large singular values @xmath42 of @xmath3 in natural order . in section [ morerank ] ,",
    "we consider general best and near best rank approximations to @xmath3 with respect to the 2-norm . for @xmath3 with @xmath451",
    ", we analyze the nonzero singular values of such a rank @xmath5 approximation , and prove that they approximate the first @xmath5 large singular values of @xmath3 for @xmath95 suitably but can fail to do so for @xmath452 .",
    "these results will help understand the regularization of lsqr .",
    "we first present one of the main results in this paper .",
    "[ main1 ] assume that the discrete picard condition is satisfied .",
    "then for @xmath197 we have @xmath453 with @xmath454 for severely ill - posed problems and @xmath455 for moderately or mildly ill - posed problems with @xmath456 , where @xmath457 for @xmath458 and @xmath459 for @xmath460 with @xmath461 defined by .    _",
    "proof_. since @xmath67 is the best rank @xmath5 approximation to @xmath3 for the 2-norm and @xmath68 , the lower bound in holds .",
    "next we prove the upper bounds .    from",
    ", we obtain @xmath462 from algorithm 1 , , and , we obtain @xmath463 with @xmath336 and @xmath218 being orthonormal , and the orthogonal projector onto @xmath217 is thus @xmath464 keep in mind that @xmath66 .",
    "it is direct to justify that @xmath465 .",
    "therefore , exploiting this and noting that @xmath466 and @xmath351 , we get from , and that @xmath467 where the last inequality follows by using @xmath468 and the definition of the induced matrix 2-norm to amplify the second term in .",
    "we estimate @xmath371 accurately below . to this end",
    ", we need to use two key identities and some results related . by the svd of @xmath461 ,",
    "it is direct to justify that @xmath469 and @xmath470 define the function @xmath471 with @xmath472 . since the derivative @xmath473",
    ", @xmath474 is monotonically increasing for @xmath475 $ ] and decreasing for @xmath476 , and the maximum of @xmath474 over @xmath472 is @xmath477 , which attains at @xmath478 .",
    "based on these properties and exploiting the svd of @xmath461 , for the matrix 2-norm we get @xmath479 for @xmath458 and @xmath480 for @xmath460 ( note : in this case , since @xmath461 may have at least one singular value smaller than one when @xmath460 , we do not have an expression like ) .",
    "it then follows from , , and @xmath481 that @xmath482 for @xmath458 and @xmath483 for @xmath460 .",
    "replace @xmath412 by its bounds and in the above , and insert the resulting bounds for @xmath484 into .",
    "let @xmath485 .",
    "then we obtain with @xmath486 satisfying and for severely and moderately or mildly ill - posed problems , respectively .",
    "note from that @xmath487 therefore , in @xmath486 of , for @xmath107 we have @xmath488    [ decayrate ] for severely ill - posed problems , from , and the definition of @xmath489 we know that @xmath490 for both @xmath107 and @xmath185 .",
    "from and , for @xmath107 we have @xmath491 by ignoring the smaller term @xmath492 , and for @xmath185 we have @xmath493 which increases slowly with @xmath5 .    for the moderately or mildly ill - posed problems with @xmath283 , from the derivation on @xmath486 and its estimate , by comparing and with , for @xmath107 we approximately have @xmath494 and for @xmath185 , from and we approximately have @xmath495 which increases faster than the right - hand side of with respect to @xmath5 .    [ decayrate2 ] from , and , for severely ill - posed problems we have @xmath496 and",
    "@xmath450 is an accurate approximation to @xmath150 for @xmath107 and marginally less accurate for @xmath185 .",
    "thus , the rank @xmath5 approximation @xmath183 is as accurate as the best rank @xmath5 approximation @xmath67 within the factor @xmath497 for @xmath107 and @xmath97 suitably . for",
    "moderately ill - posed problems , @xmath450 is still an excellent approximation to @xmath150 , and the rank @xmath5 approximation @xmath183 is almost as accurate as the best rank @xmath5 approximation @xmath67 for @xmath107 .",
    "therefore , @xmath183 plays the same role as @xmath67 for these two kinds of ill - posed problems and @xmath107 , it is known from the clarification in section [ lsqr ] that lsqr may have the full regularization .",
    "we will , afterwards , deepen this theorem and derive more results , proving that lsqr must have the full regularization for these two kinds of problems provided that @xmath97 and @xmath95 suitably .    for both severely and moderately ill - posed problems , we note that the situation is not so satisfying for increasing @xmath185 .",
    "but at that time , a possibly big @xmath486 does not do harm to our regularization purpose , since lsqr has already found a best possible regularized solution at iteration @xmath56 and we simply stop performing it .    [ mildre ] for mildly ill - posed problems , the situation is fundamentally different . as clarified in remark  [ mildrem ] , we have @xmath498 and @xmath499 considerably as @xmath5 increases up to @xmath56 because of @xmath307 , leading to @xmath500 substantially .",
    "this means that @xmath501 is substantially bigger than @xmath155 and can well lie between @xmath502 and @xmath503 , so that the rank @xmath56 approximation @xmath504 is much less accurate than the best rank @xmath56 approximation @xmath505 and lsqr has only the partial regularization .    for a given ill - posed problem",
    ", the noise level @xmath184 only affects @xmath56 but has no effect on the overall decay rate of @xmath450 .",
    "there are several subtleties in the proof of this theorem , each of which turns out to be absolutely necessary .",
    "ignoring or missing any one of them would be fatal and make us fail to obtain accurate estimates for @xmath484 defined by : the first is the careful treatment of @xmath506 . by the definition of @xmath270 , if we had amplified it by @xmath507 we would have obtained a too large overestimate , which is almost a fixed constant for severely ill - posed problems and @xmath152 and increases with @xmath152 for moderately and mildly ill - posed problems .",
    "such rough estimates are useless to get a meaningful bound for @xmath450 .",
    "the key is to treat @xmath508 as a whole in order to bound it accurately .",
    "the second is use of and .",
    "the third is the extraction of @xmath412 from as a whole , and one must not amplify it to @xmath509 . the fourth is accurate estimates for it ; see and in theorem  [ thm3 ] and the comment on its fatal overestimate .",
    "for example , without using and , we would have no way but to obtain @xmath510 from , and the previous estimates for @xmath221 , such bound is too pessimistic and completely useless in our context , and it even does not decrease and could not be small as @xmath5 increases , while our new estimates for @xmath485 in theorem  [ main1 ] are much more accurate and decay swiftly as @xmath5 increases , as indicated by and .    to make things clearer and",
    "rigorously prove the full or partial regularization of lsqr for , we need to introduce a precise definition of the near best rank @xmath5 approximation @xmath183 to @xmath3 , i.e. , the precise meaning of @xmath447 . by definition ,",
    "we call @xmath183 a near best rank @xmath5 approximation to @xmath3 if it satisfies @xmath511 that is , @xmath450 lies between @xmath58 and @xmath150 and is closer to @xmath150 . for an ill - posed problem ,",
    "since there is no considerable gap of @xmath58 and @xmath150 , the definition means that @xmath450 must approximate @xmath150 more accurately as @xmath5 increases .",
    "we mention in passing that a near best rank @xmath5 approximation to @xmath3 from an ill - posed problem is much more stringent than it is for a matrix from a ( numerically ) rank - deficient problem where the large singular values are very well separated from the small ones and there is a substantial gap between two groups of singular values .",
    "it is naturally deduced that obtaining a near best @xmath5 rank approximation to @xmath3 from the ill - posed problem is much harder than doing so for the ( numerical ) rank deficient matrix .    based on theorem",
    "[ main1 ] , for the severely and moderately or mildly ill - posed problems with the singular value models @xmath512 and @xmath513 , we next derive the sufficient conditions on @xmath186 and @xmath187 that guarantee that @xmath183 is a near best rank @xmath5 approximation to @xmath3 for @xmath152 .",
    "we also analyze if and how the sufficient conditions are satisfied for three kinds of ill - posed problems .",
    "[ nearapprox ] for a given , assume that the discrete picard condition is satisfied .",
    "then , in the sense of , @xmath183 is a near best rank @xmath5 approximation to @xmath3 for @xmath152 if @xmath186 or @xmath187 satisfies @xmath514 for the severely ill - posed problems with @xmath512 and the moderately or mildly ill - posed problems with @xmath513 , @xmath183 is a near best rank @xmath5 approximation to @xmath3 for @xmath152 if @xmath515 and @xmath187 satisfies @xmath516    _",
    "proof_. by , we see that @xmath517 .",
    "therefore , @xmath183 is a near best rank @xmath5 approximation to @xmath3 in the sense of provided that @xmath518 and @xmath519 from which follows .    from , for the severely ill - posed problems with @xmath512 and @xmath515 we have @xmath520 from which it follows that @xmath521 since @xmath522 , holds provided that @xmath523 i.e. , @xmath524 , solving which for @xmath186 we get @xmath515 . for the moderately or mildly ill - posed problems with @xmath513 , it is direct from to get @xmath525 since @xmath526 decreases monotonically as @xmath5 increases , its minimum over @xmath152 is @xmath527 . therefore , we obtain from the above .    given the noise level @xmath184 , the discrete picard condition and , from the bound for @xmath528 , we see that the bigger @xmath95 is , the smaller @xmath56 and @xmath486 are . therefore , there must be @xmath95 such that holds . here",
    "we should remind that it is more suitable to regard the conditions on @xmath186 and @xmath187 as an indication that @xmath186 and @xmath187 must not be close to one other than precise requirements since we have used the bigger and simplified models @xmath529 and @xmath513 .",
    "for the mildly ill - posed problems with @xmath513 , theorem  [ moderate ] has shown that @xmath221 is generally not small and can be arbitrarily large for @xmath152 . from , we see that @xmath486 has comparable size to @xmath221 .",
    "note that the right - hand side @xmath530 of for @xmath152 and @xmath307 .",
    "consequently , can not be met generally for mildly ill - posed problems .",
    "the rare possible exceptions are that @xmath56 is only very few and @xmath187 is close to one .",
    "so , @xmath183 is generally not a near best rank @xmath5 approximation to @xmath3 for @xmath449 for this kind of problem .      in what follows , starting with theorem  [ main1 ]",
    ", we prove that , under certain sufficient conditions on @xmath186 and @xmath187 for the severely and moderately ill - posed problems with the models @xmath531 and @xmath532 , respectively , the @xmath5 ritz values @xmath188 approximate the first @xmath5 large singular values @xmath42 in natural order for @xmath152 and no small ritz value appears . combining this with theorem  [ nearapprox ]",
    ", we draw the definitive conclusion that lsqr must have the full regularization for these two kinds of problems provided that @xmath97 and @xmath95 suitably .",
    "[ ritzvalue ] assume that is severely ill - posed with @xmath531 and @xmath97 or moderately ill - posed with @xmath532 and @xmath95 , and the discrete picard condition is satisfied .",
    "let the ritz values @xmath188 be labeled as @xmath533 .",
    "then @xmath534 if @xmath535 or @xmath95 satisfies @xmath536 then the @xmath188 strictly interlace the first large @xmath537 singular values of @xmath3 and approximate the first @xmath5 large ones in natural order for @xmath152 : @xmath538 meaning that no ritz value smaller than @xmath155 appears for @xmath107 .",
    "_ proof_. note that for @xmath152 the @xmath539 are just the nonzero singular values of @xmath183 , whose other @xmath181 singular values are zeros .",
    "we write @xmath540 the sum of @xmath3 and @xmath541 with @xmath542 by definition . then by the mirsky s theorem of singular values ( * ? ? ?",
    "* , thm 4.11 ) , we have @xmath543 since the singular values of @xmath3 are simple and @xmath2 has components in all the left singular vectors @xmath544 of @xmath3 , lanczos bidiagonalization , i.e. , algorithm 1 , can be run to completion , producing @xmath545 and the lower bidiagonal @xmath546 such that @xmath547 with the @xmath548 matrix @xmath549 and @xmath550 matrix @xmath551 orthogonal and all the @xmath552 and @xmath553 , @xmath256 , of @xmath554 being positive .",
    "note that the singular values of @xmath555 are all simple and that @xmath138 consists of the first @xmath5 columns of @xmath554 with the last @xmath181 _ zero _ rows deleted .",
    "applying the cauchy s _ strict _ interlacing theorem ( * ? ? ?",
    "* , corollary 4.4 ) to the singular values of @xmath138 and @xmath554 , we have @xmath556 therefore , becomes @xmath557 which proves .",
    "that is , the @xmath188 approximate @xmath42 from below for @xmath558 with the errors no more than @xmath517 . for @xmath558 ,",
    "notice that @xmath559 .",
    "then for @xmath515 , from , and @xmath531 we obtain @xmath560 provided that @xmath561 , solving which we get @xmath535 .",
    "together with the upper bound of , the above proves .    for the moderately ill - posed problems with @xmath562 and @xmath152 , we get @xmath563 i.e.",
    ", holds , provided that @xmath564 and @xmath95 is such that @xmath565 which means that @xmath566 it is easily verified that the above right - hand side monotonically decreases with respect to @xmath558 , whose minimum attains at @xmath567 and equals @xmath568 .",
    "furthermore , since @xmath568 decreases monotonically as @xmath5 increases , its minimum over @xmath152 is @xmath569 , which is just the condition .",
    "similar to , there must be @xmath95 such that holds .",
    "again , we stress that the conditions on @xmath186 and @xmath187 should be regarded as an indicator that @xmath186 and @xmath187 must not be close to one other than precise requirements since we have used the amplified and the simplified models @xmath570 and @xmath532 . comparing theorem  [ nearapprox ] with theorem  [ ritzvalue ] ,",
    "we find out that , as far as the severely or moderately ill - posed problems is concerned , for @xmath152 the near best rank approximation @xmath183 essentially means that the singular values @xmath188 of @xmath138 approximate the first @xmath5 large singular values @xmath42 of @xmath3 in natural order , provided that @xmath97 or @xmath95 suitably .    under the conditions of theorems  [ nearapprox][ritzvalue ] ,",
    "let us explore how the results in them depend on @xmath270 . and indicate that , for the severely ill - posed problems with @xmath512 , ignoring higher order small terms , we have @xmath571 and @xmath572 for @xmath107 ; for the moderately ill - posed problems with @xmath513 , indicates that @xmath486 and @xmath221 are comparable in size for @xmath107 , while shows that @xmath221 is at most of modest size for @xmath107 . as a result ,",
    "theorem  [ thm2 ] and theorem  [ moderate ] demonstrate that @xmath573 and @xmath295 fairly for severely and moderately ill - posed problems , respectively .",
    "in other words , the largest canonical angle between @xmath217 and @xmath269 does not exceed @xmath574 and is considerably smaller than @xmath575 for these two kinds of problems , respectively .",
    "[ extract ] theorems  [ main1][ritzvalue ] show that , for @xmath152 , the @xmath5-step lanczos bidiagonalization is guaranteed to extract or acquire the first @xmath5 dominant svd components for the severely or moderately ill - posed problems with @xmath97 or @xmath95 suitably , so that lsqr has the full regularization for these two kinds of ill - posed problems and can obtain best possible regularized solutions @xmath151 at semi - convergence .",
    "let us have a closer look at the regularization of lsqr for mildly ill - posed problems .",
    "we observe that the sufficient condition for is never met for this kind of problem because @xmath576 for any @xmath56 and @xmath577 .",
    "this implies that the @xmath56 ritz values @xmath578 may not approximate the the first @xmath56 large singular values @xmath42 in natural order and there is at least one ritz value @xmath579 , causing that @xmath151 is already deteriorated and can not be as accurate as the best tsvd solution @xmath61 .",
    "we can also make use of theorem  [ initial ] to explain the partial regularization of lsqr : theorem  [ moderate ] has shown that @xmath221 is generally not small and can become arbitrarily large as @xmath5 increases up to @xmath56 for mildly ill - posed problems , meaning that @xmath311 for @xmath307 and some @xmath107 , as the sharp bound indicates , from which it follows that a small ritz value @xmath579 generally appears .",
    "we investigate the general best or near best rank @xmath5 approximations to @xmath3 with @xmath513 and @xmath99 .",
    "we aim to show that , for each of such rank @xmath5 approximations , its smallest nonzero singular value may be smaller than @xmath150 for @xmath307 , that is , its nonzero singular values may not approximate the @xmath5 large singular values of @xmath3 in natural order , while the smallest nonzero singular value of such a rank @xmath5 approximation is guaranteed to be bigger than @xmath150 if only @xmath95 suitably . as it will turn out ,",
    "this can help us further understand the regularization of lsqr for mildly and moderately ill - posed problems .",
    "finally , we investigate the behavior of the ritz values @xmath539 when @xmath183 is not a near best rank @xmath5 approximation to @xmath3 for mildly ill - posed problems .",
    "first of all , we point out an intrinsic fact that the best rank @xmath5 approximations to @xmath3 with respect to the 2-norm are _ not _ unique , let alone its near best rank @xmath5 approximations .",
    "this subtlety is important for further understanding theorem  [ ritzvalue ] .",
    "let @xmath580 be a best or near best rank @xmath5 approximation to @xmath3 with @xmath581 with any @xmath582 satisfying @xmath583 , i.e. , @xmath584 is between @xmath150 and @xmath58 and closer to @xmath150 , by which we get @xmath585 it is remarkable to note that @xmath580 is not unique .",
    "for example , among others , all the @xmath586 with any @xmath587 and @xmath588 is a family of best or near best rank @xmath5 approximations to @xmath3 .",
    "the smallest nonzero singular value of @xmath589 is @xmath590 . since @xmath513 and @xmath591 for any @xmath403 and @xmath307",
    ", we obtain @xmath592 for @xmath593 sufficiently close to one .",
    "this shows that @xmath590 does not lie between @xmath150 and @xmath58 and interlace them for @xmath403 .",
    "furthermore , for a given @xmath594 $ ] , the bigger @xmath5 is , the smaller @xmath595 is , and the further is @xmath590 away from @xmath150 . on the other hand , for @xmath593 sufficiently small we have @xmath596 that is , @xmath590 interlaces @xmath150 and @xmath58 for @xmath593 sufficiently small .    for @xmath3 with @xmath513 and @xmath95 ,",
    "the situation is much better since , for any @xmath5 , the requirement is met for _ any _ @xmath587 provided that @xmath95 suitably , leading to @xmath597 , meaning that the smallest singular value @xmath590 of a near best rank approximation @xmath589 interlaces @xmath150 and @xmath58 .",
    "however , we should be aware that the above analysis is made for the _ worst - case _ : for any best or a near best rank @xmath5 approximation @xmath580 to @xmath3 , the minimum of the smallest nonzero singular values of all the @xmath580 is exactly @xmath598 .",
    "we now prove this .",
    "suppose that @xmath599 is the smallest nonzero singular value of a given such @xmath580 .",
    "then from @xmath581 , by the standard perturbation theory we have @xmath600 clearly , the minimum of all the @xmath599 is attained if and only if the above equality holds , which is exactly @xmath598 . on the other side , by construction",
    ", we also see that the smallest singular value @xmath590 of @xmath580 is arbitrarily close to or equal to @xmath58 by taking @xmath593 arbitrarily small or zero , which means that holds . in this case",
    ", we observe from the equality in that @xmath601 and interlaces @xmath150 and @xmath58 .    as far as lsqr is concerned ,",
    "notice that the condition for the interlacing property is derived by assuming the worst case that @xmath602 , i.e. , @xmath321 is supposed to be the smallest possible nonzero one among all the @xmath599 , where @xmath580 belongs to the set of near best @xmath5 approximations that satisfy @xmath603 . for mildly ill - posed problems ,",
    "the above arguments indicate that although in the worst case some of the @xmath5 ritz values @xmath188 may not approximate the first @xmath5 large singular values @xmath42 of @xmath3 in natural order , it is possible so in practice in case @xmath183 is _ occasionally _ a near best rank @xmath5 approximation to @xmath3 for some small @xmath107 .    unfortunately , as we have shown previously , @xmath183 is rarely a near best rank @xmath5 approximation to @xmath3 for mildly ill - posed problems , i.e. , @xmath604 generally .",
    "recall the second part of theorem  [ initial ] and remark  [ appear ] , which have shown rigorously that there is at least one ritz value @xmath605 if @xmath371 is sufficiently small there , i.e. , @xmath486 or equivalently @xmath221 is large .",
    "this is exactly the case that @xmath183 is not a near best rank @xmath5 approximation to @xmath3 , causing that lsqr has only the partial regularization .",
    "we can make a further analysis on the behavior of @xmath539 when is mildly ill - posed .",
    "suppose that @xmath606 $ ] for some @xmath423 , which means that @xmath183 is definitely not a near best rank @xmath5 approximation to @xmath3 when @xmath607 .",
    "below we derive the smallest upper bound for @xmath608 and obtain the biggest lower bound for @xmath163 . for @xmath283 with @xmath307",
    "we have @xmath609 in which @xmath610 decreases with increasing @xmath105 for @xmath388 and is one for @xmath611 . therefore ,",
    "the smallest upper bound for @xmath608 is no more than @xmath612 , which is smaller than @xmath150 once @xmath613 . in view of the above and , for",
    "@xmath606 $ ] , since @xmath614 and has the biggest lower bound @xmath612 , we may have @xmath615 provided that @xmath613 . moreover , when @xmath615 , by the labeling rule there are @xmath616 ritz values @xmath617 smaller than @xmath150 . as a result , for @xmath168 , there are @xmath618 ritz values smaller than @xmath155 that deteriorate the lsqr iterate @xmath151 , so that lsqr has only the partial regularization .",
    "in this section , we will present some results on the decay rates of @xmath621 and @xmath450 and on certain other rank @xmath5 approximations to @xmath3 and @xmath177 constructed by lanczos bidiagonalization .",
    "the decay rates of @xmath619 and @xmath620 turn out to be particularly useful for practically detecting the degree of ill - posedness of and identifying the full or partial regularization of lsqr and lsmr .",
    "the results on the new rank @xmath5 approximations will play a central role in analyzing the regularization of the krylov iterative regularization solvers lsmr @xcite and cgme @xcite . in section [ decay ] , we prove how @xmath619 and @xmath620 decay by relating them to @xmath450 and the estimates established for it .",
    "then we show how to exploit the decay rate of @xmath622 to identify the degree of ill - posedness of m and the regularization of lsqr . in section [ lsmr ]",
    ", we prove that the regularization of lsmr resembles lsqr for each of the three kinds of ill - posed problems . in section [ cgme ]",
    ", we prove that the regularizing effects of cgme have intrinsic indeterminacy and are inferior to those of lsqr and lsmr . in section [ rrqr ] ,",
    "we compare lsqr with some standard randomized algorithms @xcite and strong rank - revealing qr , i.e. , rrqr , factorizations @xcite , and show that the former solves ill - posed problems more accurately than the latter two ones at no more cost .",
    "we consider how @xmath619 and @xmath620 decay in certain pronounced manners and show how to use them to identify the full or partial regularization of lsqr in practice .",
    "[ main2 ] with the notation defined previously , the following results hold : @xmath623    _ proof_. from , since @xmath624 and @xmath551 are orthogonal matrices , we have @xmath625 with @xmath626 resulting from deleting the @xmath627 leading principal matrix of @xmath554 and the first @xmath628 zero rows and @xmath5 zero columns of the resulting matrix . from the above , for @xmath197 we have @xmath629 which shows that @xmath630 and @xmath631 since @xmath632 and @xmath633 .",
    "so from , we get and . on the other hand , noting that @xmath634 we get .",
    "note that @xmath635 and @xmath636 .",
    "by @xmath637 and , note that @xmath638 equals the 2-norm of the submatrix deleting the first column of @xmath639 .",
    "applying the cauchy s strict interlacing theorem to the singular values of this submatrix and @xmath639 , we obtain .",
    "for severely and moderately ill - posed problems , based on the results in the last section , and show that @xmath640 and @xmath641 decay as fast as @xmath150 for @xmath107 and they may slow down a little bit for @xmath185 .",
    "for mildly ill - posed problems , since @xmath486 are generally bigger than one considerably for @xmath107 , @xmath640 and @xmath641 can not generally decay as fast as @xmath150 , and their decays become slower for @xmath185 .",
    "gazzola and his coauthors @xcite claim without rigorous proofs that @xmath642 and @xmath643 for severely ill - posed problems with the constants in @xmath259 unknown ( see proposition 4 of @xcite ) , but they do not show how fast each of them decays ; see proposition 6 of @xcite .",
    "in contrast , our , and are rigorous and quantitative for all three kinds of ill - posed problems . in (",
    "* corollary 3.1 ) , the authors have derived the product inequality @xmath644 whether or not this inequality is sharp is unknown , as they point out . by it , they empirically claim that @xmath645 may decay as fast as @xmath358 when the inequality is sharp ; conversely , if it is not sharp , nothing can be said on how fast @xmath645 decays .",
    "we now shed light on and . for a given",
    ", its degree of ill - posedness is either known or unknown .",
    "if it is unknown , is of practical importance and can be exploited to identify whether or not lsqr has the full regularization without extra cost in an automatic and reliable way , so is . from the proofs of and , we find that @xmath640 and @xmath641 are as small as @xmath450 .",
    "since our theory and analysis in section [ rankapp ] have proved that @xmath450 decays as fast as @xmath150 for severely or moderately ill - posed problems with @xmath97 or @xmath95 suitably and it decays more slowly than @xmath150 for mildly il - posed problems , the decay rate of @xmath58 can be judged by that of @xmath619 or @xmath620 or better judged by that of @xmath622 reliably , as shown below .    given ,",
    "run lsqr until semi - convergence occurs at iteration @xmath646 .",
    "check how @xmath622 decays as @xmath5 increases during the process .",
    "if , on average , it decays in an obviously exponential way , then is a severely ill - posed problem . in this case",
    ", lsqr has the full regularization , and semi - convergence means that we have found a best possible regularized solution .",
    "if , on average , @xmath619 decays as fast as @xmath647 with @xmath95 considerably , then is surely a moderately ill - posed problem , and lsqr also has found a best possible regularized solution to it at semi - convergence . if , on average , it decays at most as fast as or more slowly than @xmath647 with @xmath187 no more than one , is a mildly ill - posed problem .",
    "if a hybrid lsqr is used , regularization applied to projected problems is performed only from iteration @xmath648 onwards until a best possible regularized solution is found , and , for a hybrid lsmr , regularization is applied to projected problems resulting from lsmr in the same way .",
    "based on the previous results , we can rigorously analyze the regularizing effects of of lsmr @xcite and draw definitive conclusions on its regularization for three kinds of ill - posed problems .",
    "lsmr is mathematically equivalent to minres applied to @xmath6 , and its iterate @xmath649 minimizes @xmath650 over @xmath651 , and the residual norm @xmath652 decreases monotonically with respect to @xmath5 . in our notation , noting from algorithm 1 that @xmath653 with rank @xmath5 , it is known from section 2.2 of @xcite that @xmath654 which can be efficiently computed and updated .",
    "so lsmr amounts to solving the modified problem that perturbs the matrix @xmath177 in @xmath6 to its rank @xmath5 approximation @xmath655 , and the iterate @xmath649 is the minimum - norm least squares solution to the modified problem @xmath656 it is direct to verify that the tsvd solution @xmath62 is exactly the minimum - norm least squares solution to the modified problem @xmath657 that replaces @xmath177 by its 2-norm best rank @xmath5 approximation @xmath658 in @xmath6 . as a result ,",
    "the regularization problem for lsmr now becomes that of accurately estimating @xmath659 , investigates how close it is to @xmath660 and analyzes whether or not the singular values of @xmath661 approximate the @xmath5 large singular values @xmath662 of @xmath177 .    [ aprod ] for lsmr and @xmath663 , we have @xmath664 with @xmath665 .    _",
    "proof_. for the orthogonal matrix @xmath551 generated by algorithm 1 , noticing that @xmath666 , from and we obtain @xmath667 and @xmath668 where @xmath669 is the @xmath670 matrix that results from deleting the @xmath627 leading principal matrix of the symmetric tridiagonal matrix @xmath671 and the first @xmath628 zero rows and @xmath5 zero columns of the resulting matrix . note that @xmath671 has the diagonals @xmath672 , @xmath122 and the super- and sub - diagonals @xmath673 .",
    "we have @xmath674 according to , it is direct to check that the @xmath675 symmetric tridiagonal matrix @xmath676 is a submatrix of @xmath669 that deletes its first row @xmath677 .",
    "therefore , we have @xmath678 with the last equality from , which proves the lower bound of .    on the other hand , noting the strict inequalities in and , since @xmath679 from @xcite we obtain @xmath680 with @xmath681 and @xmath682 if @xmath683 , from which the upper bound of follows directly .",
    "recall that lsqr is mathematically equivalent to cgls that implicitly applies the cg method to @xmath6 . by , , and , noting that @xmath684 , we obtain the lsqr iterates @xmath685 which is the minimum - norm least squares solution to the modified problem @xmath686 that replaces @xmath177 by its rank @xmath5 approximation @xmath687 in @xmath6 . as a result , in the sense of solving the @xmath6 , the regularization of lsqr becomes that of estimating @xmath688",
    ". we can establish the following result which relates this quantity to the counterpart of lsmr .",
    "[ lsqrmr ] for the rank @xmath5 approximations in lsmr and lsqr , we have @xmath689    similar to the proof of theorem  [ aprod ] , it is direct to verify that @xmath690 where @xmath691 is an @xmath692 matrix whose first column is @xmath693 and last @xmath181 columns are just the matrix @xmath669 defined by",
    ". therefore , we have @xmath694 , which is just .",
    "this theorem indicates that , as far as solving the normal equations @xmath6 is concerned , the rank @xmath5 approximation used by lsmr is at least as accurate as that used by lsqr .",
    "however , regarding lsqr , theorem  [ main1 ] is much more attractive since it not only deals with the rank @xmath5 approximation to @xmath3 directly but also estimates the accuracy of the rank @xmath5 approximation in terms of @xmath150 more compactly and informatively .    according to the results and analysis in section [ rankapp ] , we have @xmath695 for severely ill - posed problems , and @xmath696 at most for moderately and mildly ill - posed problems . in comparison with theorem  [ main1 ] , noting the form of the lower and upper bounds of , we see that @xmath697 as a rank @xmath5 approximation to @xmath177 is basically as accurate as @xmath183 as a rank @xmath5 approximation to @xmath3 .    from @xcite ,",
    "the singular values of @xmath698 are correspondingly bigger than those of @xmath376 , i.e. , @xmath699 .",
    "therefore , the smallest singular value of @xmath698 is bigger than or equal to @xmath375 . as a result",
    ", @xmath698 has no singular values smaller than @xmath700 before @xmath107 , provided that @xmath701 for @xmath107 .",
    "this implies that the noise deteriorates the lsmr iterates @xmath649 no sooner than it does for the lsqr iterates @xmath148 .",
    "a combination of theorem  [ lsqrmr ] and the above two remarks means that the regularizing effects of lsmr are highly competitive with and not inferior to those of lsqr for each kind of ill - posed problem .",
    "consequently , from the theory of lsqr in section [ rankapp ] , we conclude that lsmr has the full regularization for severely or moderately ill - posed problems with @xmath97 or @xmath95 suitably .",
    "however , theorem  [ aprod ] indicates that lsmr generally has only the partial regularization for mildly ill - posed problems since @xmath501 is generally bigger than @xmath155 considerably ; see remark  [ mildre ] .    we can define a near best rank @xmath5 approximation to @xmath177 similar to .",
    "based on , if , in lsmr , we simply take @xmath702 for the ease of presentation , we can establish an analog of theorem  [ nearapprox ] for lsmr .",
    "in the meantime , completely parallel to the proof of theorem  [ ritzvalue ] , we can also derive an analog of theorem  [ ritzvalue ] for lsmr , in which the sufficient conditions on @xmath486 that ensure that the singular values of @xmath698 approximate the first @xmath5 large singular values of @xmath177 in natural order are found to be @xmath703 for @xmath3 with @xmath532 .",
    "since lsmr and lsqr have similar regularizing effects for each kind of ill - posed problem , we can judge the full or partial regularization of lsmr by inspecting the decay rate of @xmath622 with respect to @xmath5 , as has been done for lsqr ,    in section [ rankapp ] we have interpreted lsqr as solving the modified problem that perturbs @xmath3 in to its rank @xmath5 approximation @xmath183 , and the regularization of lsqr has been related to the accuracy of such rank @xmath5 approximation to @xmath3 and how the @xmath5 large singular values of @xmath3 are approximated by the nonzero singular values of @xmath138 .",
    "we will treat cgme in the same way later",
    ". it might be hopeful to treat lsmr in this preferable and more direct way . from , lsmr is also equivalent to computing the minimum - norm least squares solution to the modified problem @xmath704 which perturbs @xmath3 in to its rank @xmath5 approximation @xmath705 .",
    "however , an analysis of such formulation appears intractable because there is no explicit way to remove two generalized inverses @xmath26 in such rank @xmath5 approximation , which makes it impossible to accurately estimate @xmath706 in terms of @xmath150 .      by and , we get @xmath707 where @xmath708 , and @xmath709 is lower bidiagonal with rank @xmath537 .",
    "thus , it follows from that    cgme is the cg method applied to @xmath7 and @xmath8 , where the @xmath5-th iterate @xmath710 minimizes the error @xmath711 , i.e. , @xmath712 , over @xmath651 , and the error norm @xmath713 decreases monotonically with respect to @xmath5 . by lanczos bidiagonalization",
    ", it is known from @xcite that @xmath714 with @xmath715 and the residual norm @xmath716 with @xmath364 the @xmath5-th canonical vector of dimension @xmath5 .",
    "noting that @xmath717 , we have @xmath718 therefore , @xmath710 is the minimum - norm least squares solution to the modified problem that replaces @xmath3 in by its rank @xmath5 approximation @xmath719 .",
    "[ cgmeappr ] for the rank @xmath537 approximation @xmath720 and the rank @xmath5 approximation in cgme , we have @xmath721    since @xmath722 , we obtain @xmath723 which , together with , establishes .    from and",
    "we obtain @xmath724    the upper bound of is direct and by noting that @xmath725 along the proof path of theorem  [ main2 ] , we obtain @xmath726 with @xmath639 defined by . it is straightforward to justify that the singular values of @xmath727 strictly interlace those of @xmath728 by noting that @xmath729 is an _ unreduced _ symmetric tridiagonal matrix ,",
    "from which we get the lower bound of .    by the definition of @xmath450",
    ", this theorem says that @xmath730 is a less accurate rank @xmath5 approximation than @xmath183 in lsqr .",
    "moreover , a combination of it and theorem  [ main1 ] indicates that @xmath730 may never be a near best rank @xmath5 approximation to @xmath3 even for severely and moderately ill - posed problems because , unlike lsqr , there do not exist sufficient conditions on @xmath97 and @xmath95 to guarantee this . for mildly ill - posed problems ,",
    "cgme generally has only the partial regularization since @xmath450 has been proved to be generally bigger than @xmath150 substantially and is rarely close to @xmath150 .",
    "next we consider the equally important issue : the behavior of the singular values of @xmath731 .",
    "let @xmath732 be its singular values labeled in the decreasing order , and observe that @xmath731 consists of the first @xmath5 rows of @xmath138 .",
    "since @xmath733 is an @xmath734 unreduced symmetric tridiagonal matrix , whose eigenvalues are @xmath735 , and @xmath736 is the @xmath737 leading principal submatrix of @xmath733 , whose eigenvalues are @xmath738 , by the strict interlacing property of eigenvalues , we obtain @xmath739 on the other hand , note that @xmath666 and @xmath740 , i.e. , the singular values of @xmath741 are @xmath742 and zero , which is denoted by @xmath743 . observe that @xmath744 , and the first rows of @xmath741 are @xmath745 , whose singular values are @xmath746 .",
    "therefore , applying the strict interlacing property of singular values to @xmath747 and @xmath741 , we have @xmath748 from which it follows that @xmath749    and indicate that , unlike @xmath321 that lies between @xmath150 and @xmath58 and approximates @xmath58 for severely or moderately ill - posed problems with @xmath97 or @xmath95 suitably ( cf . ) , the lower bound for @xmath750 is simply zero , a seemingly trivial one , and there does not exist a better one for it .",
    "this means that @xmath750 may be much smaller than @xmath155 and actually it can be arbitrarily small , independently of the degree @xmath186 or @xmath187 of ill - posedness .",
    "in other words , the size of @xmath186 or @xmath187 does not have any intrinsic effects on the lower bound of @xmath750 , and one can not control @xmath750 from below by choosing @xmath186 or @xmath187 . in the meantime , tells us that @xmath751 .",
    "these facts , together with theorem  [ cgmeappr ] , show that the regularization of cgme is inferior to that of lsqr and lsmr for each kind of problem . on the one hand , they mean that cgme has the partial regularization for mildly ill - posed problems ; on the other hand , the regularizing effects of cgme have indeterminacy for severely and moderately ill - posed problems , that is , it may or may not have the full regularization for these two kinds of problems . clearly , cgme has the full regularization only when @xmath730 is as accurate as the rank @xmath5 approximation @xmath183 and @xmath752 for these two kinds of problems with @xmath97 and @xmath95 considerably , but unfortunately there is no guarantee that these requirements are satisfied mathematically .",
    "the above analysis indicates that cgme itself is not reliable and can not be trusted to compute best possible regularized solutions . in principle",
    ", one can detect the full or partial regularization of cgme in the following way : one first exploits the decay rate of @xmath622 to identify the degree of ill - posedness of .",
    "if is detected to be mildly ill - posed , cgme has only the partial regularization .",
    "if is recognized as severely or moderately ill - posed , one then needs to compute the singular values of both @xmath138 and @xmath731 and check if @xmath753 using some reliable criterion .",
    "if yes , cgme has the full regularization , otherwise it has only the partial regularization .",
    "we can informally deduce more features on cgme .",
    "for the lsqr iterate @xmath148 , note that the optimality requirement of cgme means that @xmath754 .",
    "since @xmath755 and @xmath756 with the first terms in the right - hand sides being the same constant , it is normal that @xmath757 until the semi - convergence of cgme . keep in mind that the regularizing effects of cgme are inferior to or are at most as good as lsqr for each kind of ill - posed problem .",
    "both @xmath758 and @xmath759 first decrease until their respective semi - convergence and then become increasingly large as @xmath5 increases . as a result",
    ", we deduce that ( i ) @xmath710 is at least as accurate as @xmath148 until the semi - convergence of cgme and ( ii ) cgme reaches semi - convergence faster and at least no later than lsqr ; otherwise , indicates that the optimal regularized solution by cgme at semi - convergence would be more accurate than that by lsqr at semi - convergence , which contradicts the property that lsqr has better regularization than cgme .",
    "the experiments in @xcite justify this assertions ; see figure 3.1 and figure 5.2 there .",
    "next let us return to and show how to extract a rank @xmath5 approximation to @xmath3 from the rank @xmath537 approximation @xmath760 as best as possible .",
    "[ approx ] let @xmath761 be the best rank @xmath5 approximation to @xmath762 with respect to the 2-norm",
    ". then @xmath763 where @xmath764 is the smallest singular value of @xmath762 .    _",
    "proof_. write @xmath765 . then from we obtain @xmath766 by the assumption on @xmath580 and",
    ", @xmath767 is the best rank @xmath5 approximation to @xmath768 .",
    "keep in mind that @xmath67 is the best rank @xmath5 approximation to @xmath3 . since @xmath769 is a rank @xmath5 approximation to @xmath720 ,",
    "we get @xmath770 from which , and it follows that holds .    note that @xmath771 therefore , from it follows that holds .",
    "we point out that may be conservative since we have amplified @xmath772 twice and obtained its bound @xmath150 , which can be a considerable overestimate . in comparison with and",
    ", the bound indicates that @xmath767 may not be as accurate as @xmath183 .",
    "illustrates that @xmath767 can be as accurate as @xmath183 because @xmath773 from and .",
    "moreover , as we have explained , @xmath764 can be arbitrarily small , so that @xmath764 is negligible in and @xmath767 is at least as accurate as @xmath183 .",
    "we now present an informal analysis to show that @xmath767 may be at least as accurate as @xmath183 as a rank @xmath5 approximation to @xmath3 .",
    "keep in mind that @xmath774 be the singular values of @xmath762 .",
    "then the singular values of @xmath761 are @xmath775 .",
    "since @xmath632 for @xmath776 , applying the strict interlacing property of singular values to @xmath138 and @xmath762 , we have @xmath777 the above relationships , together with , prove that @xmath778 that is , the @xmath779 are more accurate than @xmath188 as approximations to @xmath189 . by the standard perturbation theory , note from that @xmath780 while the singular value differences between @xmath3 and @xmath767 are @xmath781 and @xmath782 , all of which , from and , are no more than @xmath450 . based on these rigorous facts and the relationship between @xmath580 and @xmath762 , it is well possible that @xmath783 , and if it is so , then by definition @xmath767 is a more accurate rank @xmath5 approximation to @xmath3 than @xmath183 is .",
    "we compare the rank approximations @xmath183 and @xmath767 by lanczos bidiagonalization with those by some standard randomized algorithms and rrqr factorizations , and demonstrate that the former ones are much more accurate than the latter ones for severely and moderately ill - posed problems .    note .",
    "compare , and or with the corresponding results ( 1.9 ) , ( 5.6 ) , ( 6.3 ) and theorem 9.3 in @xcite for standard randomized algorithms and those on the strong rrqr factorization @xcite , where the constants in front of @xmath150 are like @xmath784 and @xmath785 , respectively , which are far bigger than one . within the framework of the rrqr factorizations ,",
    "it is known from @xcite that the optimal factor of such kind is @xmath786 but to find corresponding permutations is an np - hard problem , whose cost increases exponentially with @xmath40 ; see also @xcite .",
    "clearly , the strong rrqr factorizations are near - optimal within the framework , and they suit well for finding a hight - quality low rank @xmath5 approximation to a matrix whose @xmath5 large singular values are much bigger than the @xmath181 small ones .    unfortunately , the standard randomized algorithms and rrqr factorization do not very nicely fit into solving ill - posed problems . since there are no considerable gaps of singular values , the rrqr factorization techniques can hardly find a near best rank @xmath5 approximation to @xmath3 in the sense of for three kinds of ill - posed problems , which is vital to solve reliably and makes us possible to ultimately find a best possible regularized solution .",
    "in contrast , for the first two kinds of problems , the rank @xmath5 approximation @xmath183 can be near best for @xmath107 and no singular value smaller than @xmath155 appears . besides , it is easy to check that the @xmath5-step lanczos bidiagonalization costs fewer flops than the standard randomized algorithms do for a sparse @xmath3 , and it is more efficient than the strong rrqr factorization for a dense @xmath3 , which includes @xmath787 flops and the overhead cost of searching permutations .    for further developments and recent advances on randomized algorithms , we refer to gu s work @xcite , where he has considered randomized algorithms within the subspace iteration framework proposed in @xcite , presented a number of new results and improved the error bounds for the rank @xmath5 approximations that are iteratively extracted .",
    "such approaches may be promising to solve ill - posed problems .",
    "based on proposition  [ help ] , exploiting theorem  [ main1 ] , theorem  [ ritzvalue ] and theorem  [ main2 ] , we present the following results , which , from the viewpoint of tikhonov regularization , explain why lsqr has the full regularization for severely and moderately ill - posed problems and it generally has the partial regularization for mildly ill - posed problems .",
    "[ main3 ] for the severely or moderately ill - posed problems with @xmath97 or @xmath95 , under the assumptions of theorem  [ ritzvalue ] , let @xmath166 be defined by .",
    "then for @xmath152 we have @xmath788    _",
    "proof_. for @xmath152 , it follows from that @xmath789 to simplify presentations and illuminate the essence , from theorem  [ ritzvalue ] we simply replace @xmath790 by one and @xmath188 by @xmath42 in the above . then by we have @xmath791 for @xmath125 but @xmath54 , replace @xmath163 by @xmath92 approximately . then follows .    by , since @xmath792 for @xmath793 , the factors @xmath794 and decay to zero with increasing @xmath54 for each fixed @xmath423",
    "therefore , for @xmath793 we get @xmath795 replace the @xmath163 by @xmath796 in the above , and note that the second term is higher order small , compared with the first term",
    ". then follows .    for @xmath152 ,",
    "since @xmath797 are dominant singular values , the factors @xmath798 are modest .",
    "consequently , indicates that the @xmath799 with the errors @xmath800 for @xmath558 , while shows that the @xmath166 are at least as small as @xmath801 for @xmath793 and decrease with increasing @xmath54 .    for mildly ill - posed problems and @xmath152 ,",
    "as we have shown in remark  [ appear ] and section [ rankapp ] , it is generally the case that @xmath802 .",
    "suppose @xmath803 with the smallest integer @xmath171 .",
    "then we have shown in the paragraph after proposition  [ help ] that @xmath804 . as a result",
    ", lsqr has only the partial regularization .",
    "recall that @xmath398 , and define @xmath805 . in terms of  , hansen ( * ? ? ?",
    "* , theorems 6.4.1 - 2 ) presents the following bounds @xmath806 @xmath807 and @xmath808 where @xmath809 is the infinity norm of a vector .",
    "we now address a few points on the bounds and .",
    "first , there had no estimates for @xmath221 and @xmath810 ; second , what we need is @xmath811 other than @xmath812 , and as is seen from its proof in @xcite , it is relatively easy to obtain the accurate bound for @xmath813 , whereas it is hard to derive an accurate one for @xmath814 .",
    "because of lacking accurate estimates , it is unclear how small or large the bound and are .",
    "moreover , as it will appear soon , the factor @xmath815 in the numerator of may be a too crude overestimate , such that the bound is pessimistic and is useless to estimate @xmath816 and thus @xmath817 .",
    "let us have a closer look at these points",
    ". obviously , exploiting , we can only obtain the bounds @xmath818 from which it follows that @xmath819 as a result , the estimates for both @xmath814 and @xmath221 are too crude for @xmath40 large and @xmath5 small . indeed , as we have seen previously , their accurate estimates are much involved and complicated . in theorem",
    "[ thm3 ] , we have derived accurate estimates for @xmath820 ; see , for severely ill - posed problems and , for moderately and mildly ill - posed problems . theorems  [ thm2][moderate ] have given sharp estimates for @xmath221 for three kinds of problems , respectively .",
    "the factor @xmath815 itself , though simple and elegant in form , does not give clear and quantitative information on its size . as a matter of fact , one must analyze its size carefully for the two cases @xmath107 and @xmath185 , respectively , for each kind of ill - posed problem ; see the discrete picard condition and .",
    "for each of these two cases , using our proof approach used for theorems  [ thm2 ] , [ moderate ] and [ thm3 ] , we can obtain accurate estimates for @xmath821 for three kinds of ill - posed problems , respectively . however , the point is that the factor @xmath815 results from a substantial amplification in the derivation .",
    "it is seen from the last line of @xcite that this factor results from simply bounding it by @xmath822 where @xmath823 . for our context , this amplification is fatal , and it is subtle to obtain sharp bounds for @xmath824 .",
    "we observe that @xmath825 is nothing but the first square root factor in , for which we have established the accurate estimates and for severely , moderately and mildly ill - posed problems , respectively , which hold for @xmath197 and are _ independent _ of @xmath40 .",
    "it can be checked that these bounds are substantially smaller than @xmath826 .    after the above substantial improvements on and",
    ", we can exploit the accurate bounds for @xmath221 and @xmath814 in theorems  [ thm2][moderate ] and theorem  [ thm3 ] , as well as the remarks on them , to accurately estimate the bounds and . from them",
    "we can draw the full regularization lsqr for severely and moderately ill - posed problems with @xmath97 and @xmath95 suitably and its partial regularization for mildly ill - posed problems .",
    "making use of some standard perturbation results from hansen  @xcite , we can quantitatively relate lsqr to the tsvd method and analyze the differences of their corresponding regularized solutions and differences of @xmath827 and @xmath828 predicting the right - hand side @xmath2 for @xmath152 .",
    "[ lsqrtsvd ] for the severely or moderately ill - posed problem  , let @xmath67 be the rank @xmath5 best approximation to @xmath3 , and assume that @xmath829 . then for @xmath152 we have @xmath830 @xmath831 where @xmath832    _ proof_. for the problem @xmath833 that replaces @xmath3 by @xmath67 in , we regard the rank @xmath5 matrix @xmath183 as a perturbed @xmath67 with the perturbation matrix @xmath834 . then by the standard perturbation results on the tsvd solutions @xcite ,",
    "we obtain and directly .",
    "write @xmath835 . since the rank @xmath5 matrices @xmath183 and @xmath67 have the @xmath5 nonzero singular values @xmath188 and @xmath42 , @xmath558 , respectively , from mirsky s theorem ( * ? ? ?",
    "* , theorem 4.11 ) we get the bounds @xmath836 where the lower bound in is no more than the one in .",
    "it is then expected that @xmath837 for severely and moderately ill - posed problems .",
    "therefore , we have @xmath838 , and indicates that @xmath839 , is basically no more than @xmath484 , @xmath152 .    from ,",
    "since the possibly not small factor @xmath840 enters the bound , two regularized solutions @xmath148 and @xmath62 may differ considerably even though @xmath827 and @xmath828 predict the right - hand side @xmath2 with similar accuracy for @xmath152 .",
    "this is the case for the inconsistent ill - posed problem @xmath0 with @xmath841 , where @xmath842 decreases with respect to @xmath5 until @xmath843 with @xmath844 and @xmath845 the first @xmath40 columns of the @xmath548 left singular vector matrix @xmath846 and @xmath847 the incompatible part of @xmath2 lying outside of the range of @xmath3 ( cf .",
    "@xcite ) , which may be not much smaller than @xmath848 . here",
    "we remark that the term @xmath847 appears in the relation ( 4.17 ) of @xcite but is missing in the above right - hand side @xcite . for the consistent @xmath1 , since @xmath849 ,",
    "the right - hand side of is @xmath850 we see from the above and that two different regularized solutions can be quite different even if their residual norms are of similar very sizes , as addressed by hansen ( * ? ? ?",
    "* , theorem 5.7.1 ) . however , we point out that the accuracy of different regularized solutions as approximations to @xmath27 can be compared .",
    "if the norms of errors of them and @xmath27 have very comparable sizes , they are equally accurate regularized solutions to .",
    "note that the assumption @xmath829 is only for severely and moderately ill - posed problems . as the previous analysis has indicated",
    ", we have @xmath851 .",
    "furthermore , for these two kinds of problems , we have shown @xmath852 .",
    "as a result , it is easily justified that this assumption is valid for these two kinds of problems provided that @xmath97 and @xmath95 suitably .",
    "however , the assumption generally fails to hold for the mildly ill - posed problems with @xmath451 and @xmath307 since , for @xmath403 , we have @xmath853",
    "previously , under the assumption that the singular values of @xmath3 are simple , we have proved the results and made a detailed analysis on them .",
    "recall the basic fact that the singular values @xmath539 of @xmath138 are always simple mathematically , independent of whether the singular values of @xmath3 are simple or multiple .",
    "in other words , the lanczos bidiagonalization process works as if the singular values of @xmath3 are simple , and the ritz values @xmath539 , are the approximations to some of the _ distinct _ singular values of @xmath3 . in this section",
    ", we will show that , by making a number of suitable and nontrivial changes and reformulations , our previous results and analysis can be extended to the case that @xmath3 has multiple singular values .",
    "assume that @xmath3 has @xmath16 distinct singular values @xmath854 with @xmath42 being @xmath855 multiple and @xmath856 . in order to treat this situation",
    ", we need to make a number of preliminary preparations and necessary modifications or reformulations .",
    "below let us show the detail .",
    "first of all , we need to take @xmath2 into consideration and present a new form svd of @xmath3 by selecting a specific set of left and right singular vectors corresponding to a multiple singular value @xmath42 of @xmath3 , so that holds for one particularly chosen left singular vector associated with @xmath42 .",
    "specifically , for the @xmath855 multiple @xmath42 , the orthonormal basis of the corresponding left singular subspace , which is unique , can be chosen so that @xmath2 has a nonzero orthogonal projection on just one unit length left singular vector @xmath857 in the singular subspace and no components in the remaining @xmath858 ones .",
    "precisely , let the columns of @xmath859 form an orthonormal basis of the left singular subspace associated with @xmath42 , each of which satisfies the discrete picard condition .",
    "then we take @xmath860 where @xmath861 is the orthogonal projector onto the left singular subspace with @xmath42 , and define the corresponding unit length right singular vector by @xmath862 .",
    "we select the other @xmath858 orthonormal left singular vectors which are orthogonal to @xmath857 and , together with @xmath857 , form the left singular subspace associated with @xmath42 , and define the corresponding unit length right singular vectors in the same way as @xmath180 , which and @xmath180 form an orthonormal basis of the unique right singular subspace with @xmath42 .",
    "after such treatment , we get the desired svd of @xmath3 .",
    "we stress that @xmath857 defined above is unique since the orthogonal projection of @xmath2 onto the left singular subspace with @xmath42 is unique and equal to @xmath863 for a given orthonormal @xmath859 .",
    "now we need to prove that @xmath857 satisfies the discrete picard condition essentially . to see this , by the cauchy ",
    "schwarz inequality , and the assumption that each column of @xmath859 satisfies the discrete picard condition , we get @xmath864 therefore , the fourier coefficients @xmath865 , on average , decay faster than the singular values @xmath866 .",
    "this is exactly what the discrete picard condition means ; see the description before .",
    "recall that is a simplified model of this condition .",
    "based on the estimate , we recover by simply resetting as latexmath:[\\[\\label{newpicard }     with help of the svd of @xmath3 described above , it is crucial to observe that @xmath62 in is now the sum consisting of the first @xmath5 _ distinct _ dominant svd components of @xmath3 .",
    "furthermore , for and such reformulation of , the matrix @xmath3 in them can be equivalently replaced by the new @xmath868 matrix @xmath869 where @xmath870 , @xmath871 and @xmath872 are the first @xmath16 columns of @xmath846 and @xmath329 , respectively , the last @xmath873 columns of @xmath846 are the other columns of the left singular vector matrix of @xmath3 excluding @xmath874 , which are orthogonal to @xmath2 by the construction stated above , and the last @xmath873 columns of @xmath329 are the other corresponding columns of the right singular vector matrix of @xmath3 . obviously , for the new svd of @xmath3 defined above , @xmath875 is of rank @xmath16 with the @xmath16 simple nonzero singular values @xmath876 , its left and right singular vector matrices @xmath846 and @xmath329 are the corresponding ones of @xmath3 with proper column exchanges , respectively .",
    "we have @xmath877 and the tsvd regularized solutions @xmath878 , where @xmath879 is the best rank @xmath5 approximation to @xmath875 with respect to the 2-norm .",
    "in addition , we comment that from the discrete picard condition @xmath880 independently of @xmath40 and @xmath16 , we can obtain directly in the same way as the introduction of for .",
    "another fundamental change is that the @xmath5-dimensional dominant right singular space of @xmath3 now becomes that of @xmath875 , i.e. , @xmath194 with @xmath195 associated with the first @xmath5 large singular values of @xmath875 .",
    "it is the subspace of concern in the case that @xmath3 has multiple singular values .",
    "we will also denote @xmath881 and @xmath882 .",
    "as for krylov subspaces , by the svd of @xmath3 and that of @xmath875 , expanding @xmath2 as @xmath883 , we easily justify @xmath884 and @xmath885 by noting that @xmath886 for any integer @xmath887 and @xmath888 for any integer @xmath889 . thus , for the given @xmath2 , lanczos bidiagonalization works on @xmath3 exactly as if it does on @xmath875 .",
    "that is ,  generated by algorithm 1 hold when @xmath3 is replaced by @xmath875 , and the @xmath5 ritz values @xmath188 approximate @xmath5 nonzero singular values of @xmath875 . moreover , and indicate @xmath890 as a result , since @xmath891 has nonzero components in all the eigenvectors @xmath892 of @xmath893 associated with its nonzero distinct eigenvalues @xmath894 , lanczos bidiagonalization can not break down until step @xmath895 , and the singular values @xmath896 of @xmath897 are exactly the singular values @xmath876 of @xmath875 . at step @xmath16",
    ", lanczos bidiagonalization on @xmath3 generates the @xmath898 lower bidiagonal matrix @xmath899 and @xmath900    having done the above , what we need is to estimate how @xmath901 approximates or captures the @xmath5-dimensional dominant right subspaces @xmath269 , @xmath902 .",
    "this is a crucial step and the starting point of all the later analysis . in what follows",
    "let us show how to adapt the beginning part of the proof of theorem  [ thm2 ] to the case that @xmath3 has multiple singular values .",
    "observe the krylov subspace @xmath903 with @xmath904 and @xmath905 partition the diagonal matrix @xmath205 and the matrix @xmath206 into the forms @xmath906 where @xmath208 and @xmath907 .",
    "since @xmath209 is a vandermonde matrix with @xmath92 distinct for @xmath125 , it is nonsingular .",
    "therefore , from @xmath908 and the structures of @xmath909 and @xmath910 , we obtain @xmath911 with @xmath912 meaning that @xmath913 is orthogonal to the last @xmath873 columns of @xmath329 .",
    "write @xmath914 and define @xmath915 then @xmath215 , the columns of @xmath216 form an orthonormal basis of @xmath913 , and we get the orthogonal direct sum decomposition @xmath916    denote @xmath917 . for @xmath918 , based on the above",
    ", we get by replacing @xmath328 in by @xmath919 defined as and noting that @xmath218 is orthogonal to @xmath920 .",
    "then it is direct to derive the same bounds for @xmath918 as those established previously in completely the same way .    as for the extension of theorem  [ initial ] , by definition and",
    ", we need to replace @xmath328 in by @xmath919 defined as .",
    "the unit - length @xmath326 is now a vector that has the smallest acute angle with @xmath921 , and we modify as @xmath922 recall that the columns of @xmath920 are the right singular vectors of @xmath875 corresponding to zero singular values .",
    "it disappears when forming the rayleigh quotient of @xmath923 with respect to @xmath337 .",
    "the proof of theorem  [ initial ] then carries over to @xmath875 , and the results hold for the case that @xmath3 has multiple singular values .",
    "another fundamental change is that , when speaking of a rank @xmath5 approximation , we now mean that for @xmath875 . note that the best rank @xmath5 approximation @xmath924 to @xmath875 is @xmath925 , @xmath926 , where @xmath927 and @xmath928 are defined as before , and @xmath929 .",
    "the @xmath5-step lanczos bidiagonalzation process on @xmath3 now generates rank @xmath5 approximations @xmath183 in lsqr and @xmath930 in cgme to @xmath875 and the rank @xmath5 approximation @xmath931 in lsmr to @xmath893 , where @xmath932 and @xmath336 are the first @xmath537 and @xmath5 columns of @xmath933 and @xmath934 in .",
    "we then need to estimate the approximation accuracy of these rank @xmath5 approximations and compare them with that of @xmath879 and @xmath893 , respectively .",
    "meanwhile , for each of these three rank @xmath5 approximation matrices , we need to analyze how its @xmath5 nonzero singular values approximate @xmath5 singular values of @xmath875 or @xmath923 .    for the rank @xmath5 approximation @xmath183 to @xmath875 in lsqr ,",
    "similar to , we define @xmath935 then , without any changes but the replacement of the index @xmath40 by @xmath16 , all the results in section [ rankapp ] and in theorem  [ main2 ] carry over to the multiple singular value case .    the final important note is how to extend the results presented section [ decay][cgme ] to the multiple singular value case .",
    "we have to derive the three key relations similar to , and , where the fact that lanczos bidiagonalization can be run to @xmath40 steps without breakdown is exploited . in the case",
    "that @xmath3 has multiple singular values , since lanczos diagonalization on @xmath3 must break down at step @xmath895 , there are no @xmath936 and @xmath551 as in . to this end , from we augment @xmath933 and @xmath934 to the @xmath548 and @xmath550 orthogonal matrices @xmath937 and @xmath938 , respectively , from which and we obtain @xmath939 having this relation , like and , we get @xmath940 where @xmath639 is the right bottom @xmath941 matrix of @xmath897 , similar to @xmath639 in .",
    "then theorem  [ main2 ] extends naturally to the multiple singular value case without any change but the replacement of the index @xmath40 by @xmath16 , and all the other results and analysis in section [ decay][cgme ] carry over to this case as well .",
    "the results in section [ compare ] hold without any change whenever @xmath3 , @xmath67 and the index @xmath40 are replaced by @xmath875 , @xmath924 and @xmath16 , respectively .    in summary , based on the above reformulations , changes and preliminary work , except section [ rrqr ]",
    ", we have extended all the results and analysis in sections [ lsqr][compare ] to the case that @xmath3 has multiple singular values , just as we have done for the simple singular value case . in the analysis , derivation and results ,",
    "the index @xmath40 is often replaced by @xmath16 whenever needed , and when this is necessary is clear from the context related .",
    "for a number of problems from hansen s regularization toolbox @xcite , huang and jia @xcite have numerically justified the full regularization of lsqr for severely and moderately ill - posed problems and its partial regularization for mildly ill - posed problems , where each @xmath3 is @xmath942 . in this section , we report numerical experiments to confirm our theory and illustrate the full or partial regularization of lsqr in much more detail .",
    "for the first two kinds of problems , we demonstrate that @xmath943 and @xmath641 decay as fast as @xmath150 .",
    "we compare lsqr and the hybrid lsqr with the tsvd method applied to projected problems . in the experiments",
    ", we use the l - curve criterion , the function @xmath944 in @xcite , to determine an actually optimal regularization parameter and depict the l - curve . for each of",
    "severely and moderately ill - posed problems , we show that the regularized solution obtained by lsqr at semi - convergence is at least as accurate as the best tsvd regularized solution , indicating that lsqr has the full regularization . in the meantime , we show that the regularized solution obtained by lsqr at semi - convergence is considerably less accurate than that by the hybrid lsqr for mildly ill - posed problems , demonstrating that lsqr only has the partial regularization . as a byproduct , we compare lsqr with gmres and rrgmres and illustrate the failure of the latter ones for general nonsymmetric ill - posed problems .",
    "we choose several ill - posed problems from hansen s regularization toolbox @xcite , which include the severely ill - posed problems @xmath945 , the moderately ill - posed problems @xmath946 , and the mildly ill - posed problem @xmath947 .",
    "all the codes are from @xcite , and the problems arise from discretizations of .",
    "we remind that , as far as is concerned , our primary goal consists in justifying the regularizing effects of iterative solvers for , which are _ unaffected by the size _ of and only depends on the degree of ill - posedness , the noise level @xmath184 and the actual discrete picard condition , provided that the condition number of , measured by the ratio between the largest and smallest singular values of each @xmath3 , is large enough . therefore , for this purpose , as extensively done in the literature ( see , e.g. , @xcite and the references therein as well as many other papers ) , it is enough to report the results on small and/or moderate discrete ill - posed problems since the condition numbers of these @xmath3 are already huge or large , which , in finite precision arithmetic , are roughly @xmath948 and @xmath949 for severely , moderately and mildly ill - posed problems with @xmath950 , respectively . indeed , for @xmath40 large , say , 10,000 or more , we have observed the same behavior as that for small @xmath40 , e.g. , @xmath950 used in this paper . also , an important reason is that such choice enables us to fully justify the regularization effects of lsqr by comparing it with the tsvd method , which suits only for small and/or medium sized problems because of its computational complexity for @xmath40 large . for each example",
    ", we generate a @xmath951 matrix @xmath3 , the true solution @xmath27 and noise - free right - hand side @xmath22 . in order to simulate the noisy data , we generate white noise vectors @xmath21 such that the relative noise levels @xmath952 , respectively .",
    "we mention that , to illustrate the behavior of the hybrid lsqr more generally , after this section we , in the concluding section , will report some important observations on @xmath953 and @xmath947 of @xmath954 and @xmath955 , whose condition numbers are as large as @xmath956 and @xmath957 for @xmath958 , respectively .",
    "to simulate exact arithmetic , lsqr uses full reorthogonalization in lanczos bidiagonalization .",
    "all the computations are carried out in matlab 7.8 with the machine precision @xmath959 under the miscrosoft windows 7 64-bit system .      * example 1*. this problem @xmath960 arises from one - dimensional image restoration and is obtained by discretizing with @xmath961 $ ] as the domains of @xmath16 and @xmath17 , where @xmath962    * example 2*. this problem @xmath963 has a discontinuous solution and is obtained by discretizing with @xmath964 $ ] as the domains of @xmath16 and @xmath17 , where @xmath965    the problems @xmath960 and @xmath963 are severely ill - posed with the singular values @xmath966 for @xmath960 and @xmath967 for @xmath963 , respectively .    in figure  [ fig1 ] , we display the decay curves of the @xmath450 for @xmath968 , respectively .",
    "we observe that the three curves with different @xmath969 are almost unchanged .",
    "this is in accordance with our remark  [ decayrate ] , where it is stated that the decay rate of @xmath450 is little affected by noise levels for severely ill - posed problems , since @xmath450 primarily depends on the decay rate of @xmath150 and different noise levels only affect the value of @xmath56 other than the decay rate of @xmath450 .",
    "in addition , we have observed that @xmath450 and @xmath150 decay until they level off at @xmath970 due to round - off errors in finite precision arithmetic .",
    "most importantly , the results clearly illustrate that @xmath450 decreases as fast as @xmath150 , and we have @xmath852 , whose decay curves are almost indistinguishable .",
    "these results are in accordance with our theory .    in figure",
    "[ fig2 ] , we plot the relative errors @xmath971 with different @xmath969 for these two problems . as we see , lsqr exhibits the clear semi - convergence .",
    "moreover , for a smaller @xmath969 , we get a more accurate regularized solution at cost of more iterations , as @xmath56 is bigger from and .     and",
    "@xmath150 for the problem @xmath960 with @xmath972 ( left ) and @xmath973 ( right ) ; ( c)-(d ) : decay curves of the sequences @xmath450 and @xmath150 for @xmath963 with @xmath973 ( left ) and @xmath974 ( right).,width=226,height=188 ]    ( a )     and @xmath150 for the problem @xmath960 with @xmath972 ( left ) and @xmath973 ( right ) ; ( c)-(d ) : decay curves of the sequences @xmath450 and @xmath150 for @xmath963 with @xmath973 ( left ) and @xmath974 ( right).,width=226,height=188 ]    ( b )     and @xmath150 for the problem @xmath960 with @xmath972 ( left ) and @xmath973 ( right ) ; ( c)-(d ) : decay curves of the sequences @xmath450 and @xmath150 for @xmath963 with @xmath973 ( left ) and @xmath974 ( right).,width=226,height=188 ]    ( c )     and @xmath150 for the problem @xmath960 with @xmath972 ( left ) and @xmath973 ( right ) ; ( c)-(d ) : decay curves of the sequences @xmath450 and @xmath150 for @xmath963 with @xmath973 ( left ) and @xmath974 ( right).,width=226,height=188 ]    ( d )     with @xmath968 for @xmath960 ( left ) and @xmath963 ( right).,width=226,height=188 ]    ( a )     with @xmath968 for @xmath960 ( left ) and @xmath963 ( right).,width=226,height=188 ]    ( b )    * example 3*. this problem @xmath975 arises from the inverse heat equation and is obtained by discretizing with @xmath964 $ ] as integration interval , where the kernel @xmath976 with @xmath977 this is a moderately ill - posed problem .",
    "* example 4*. this problem is the @xmath953 famous problem , a moderately ill - posed one .",
    "it is obtained by discretizing with @xmath978 $ ] as the domains of @xmath16 and @xmath17 , where @xmath979     and @xmath150 for the problem @xmath975 with ( left ) and ( b ) : decay curves of the sequences @xmath450 and @xmath150 for @xmath953 with @xmath973 ( right).,width=226,height=188 ]    ( a )     and @xmath150 for the problem @xmath975 with ( left ) and ( b ) : decay curves of the sequences @xmath450 and @xmath150 for @xmath953 with @xmath973 ( right).,width=226,height=188 ]    ( b )    from figure  [ fig3 ] , we see that @xmath450 decreases almost as fast as @xmath150 for moderately ill - posed problems . however ,",
    "slightly different from severely ill - posed problems , @xmath450 , though very good approximations to @xmath150 , may not be so accurate .",
    "this is expected , as the constants @xmath486 in are generally bigger than those in for severely ill - posed problems .",
    "also , different from figure  [ fig1 ] , we observe from figure  [ fig3 ] that @xmath450 deviates more from @xmath150 with increasing @xmath5 , especially for the problem @xmath953 .",
    "this confirms remarks  [ decayrate][decayrate2 ] on moderately ill - posed problems .    in figure  [ fig4 ]",
    ", we depict the relative errors of @xmath148 , and from them we observe analogous phenomena to those for severely ill - posed problems .",
    "the only distinction is that lsqr now needs more iterations , i.e. , a bigger @xmath56 is needed for moderately ill - posed problems with the same @xmath969 , as is seen from and .",
    "with @xmath968 for @xmath975 ( left ) and @xmath953 ( right).,width=226,height=188 ]    ( a )     with @xmath968 for @xmath975 ( left ) and @xmath953 ( right).,width=226,height=188 ]    ( b )    * example 5*. the mildly ill - posed problem @xmath947 is obtained by discretizing with @xmath964 $ ] as the domains of @xmath16 and @xmath17 , where the kernel @xmath15 is the green s function for the second derivative : @xmath980 and the solution @xmath14 and the right - hand side @xmath13 are given by @xmath981     and @xmath150 for @xmath947 with @xmath973,width=226,height=188 ]    ( a )     and @xmath150 for @xmath947 with @xmath973,width=226,height=188 ]    ( b )    figure  [ figmild ] ( a)-(b ) display the decay curves of the partial and complete sequences @xmath450 and @xmath150 .",
    "we see that , different from severely and moderately ill - posed problems , @xmath450 does not decay so fast as @xmath150 and deviates from @xmath150 significantly .",
    "recall that theorem  [ main1 ] holds for mildly ill - posed problems , where @xmath486 defined by is considerably bigger than one .",
    "these observations justify our theory and confirm that the rank @xmath5 approximations to @xmath3 generated by lanczos bidiagonalization are not as accurate as those for severely and moderately problems .",
    "consequently , lsqr has only the partial regularization .      for the severely ill - posed @xmath960 , @xmath963 and the moderately ill - posed @xmath975 , @xmath953",
    ", we compare the regularizing effects of lsqr and the hybrid lsqr with the tsvd method applied to the projected problems , and demonstrate that they compute the same best possible regularized solution for each problem and lsqr thus has the full regularization . for the mildly ill - posed problem @xmath947 ,",
    "we show that lsqr has only the partial regularization and a hybrid lsqr can compute a best possible regularized solution .    in the sequel , we only report the results for the noise level @xmath973 .",
    "results for the other two @xmath969 are analogous and thus omitted unless stated otherwise .",
    "we first have a close look at the severely and moderately ill - posed problems .",
    "figure  [ fig5a ] ( a)-(b ) and figure  [ fig6 ] ( a)-(b ) plot the relative errors of regularized solutions obtained by the two methods for @xmath982 and @xmath946 .",
    "clearly , we see that for each problem the relative errors reach the same minimum level .",
    "after semi - convergence of lsqr , the tsvd method applied to projected problems simply stabilizes the regularized solutions with the minimum error and does not improve them .",
    "this means that lsqr has already found best possible regularized solutions at semi - convergence and has the full regularization , and regularization applied to projected problems does not help and is unnecessary at all . in practice",
    ", we simply stop lsqr after its semi - convergence for severely and moderately ill - posed problems .",
    "for these four problems , for test purposes we choose @xmath983 for lsqr .",
    "figure  [ fig5a ] ( c)-(d ) and figure  [ fig6 ] ( c)-(d ) show that the regularized solutions @xmath984 are generally excellent approximations to the true solutions @xmath27 .",
    "the exception is the problem @xmath963 with a discontinuous solution , as depicted in figure  [ fig5a ] ( d ) . for it ,",
    "the regularized solution deviates from @xmath27 considerably and the relative error is not small .",
    "this is because all cg type methods applied to either or its normal equations @xmath6 or @xmath7 with @xmath8 compute smooth regularized solutions .",
    "in some sense , lsqr and cgls are equivalent to implicitly solving the tikhonov regularization problem , and their regularized solutions are of the filtered form .",
    "it is well known that the regularization term @xmath985 in tikhonov regularization does not suit for the discontinuous solution .",
    "the ill - posed problems with discontinuous or non - smooth solutions are from numerous important applications , including linear regression , barcode reading , gravity surveying in geophysics , image restoration and some others @xcite . for them",
    ", a better alternative is use the 1-norm @xmath986 as the regularization term , which leads to the total variation regularization @xcite or errors - in - variables modeling called in @xcite , where @xmath987 is some @xmath988 matrix with no restriction to @xmath102 and is typically taken to be the discrete approximation to the first or second derivative operator ( * ? ? ? * ch.8 ) .     by lsqr and the hybrid lsqr for @xmath973 ; ( c)-(d ) : the best possible regularized solutions @xmath984 , i.e. , @xmath151 , by lsqr for @xmath960 ( left ) and @xmath963 ( right).,width=226,height=188 ]    ( a )     by lsqr and the hybrid lsqr for @xmath973 ; ( c)-(d ) : the best possible regularized solutions @xmath984 , i.e. , @xmath151 , by lsqr for @xmath960 ( left ) and @xmath963 ( right).,width=226,height=188 ]    ( b )     by lsqr and the hybrid lsqr for @xmath973 ; ( c)-(d ) : the best possible regularized solutions @xmath984 , i.e. , @xmath151 , by lsqr for @xmath960 ( left ) and @xmath963 ( right).,width=226,height=188 ]    ( c )     by lsqr and the hybrid lsqr for @xmath973 ; ( c)-(d ) : the best possible regularized solutions @xmath984 , i.e. , @xmath151 , by lsqr for @xmath960 ( left ) and @xmath963 ( right).,width=226,height=188 ]    ( d )     by lsqr and the hybrid lsqr for @xmath973 ; ( c)-(d ) : the best possible regularized solutions @xmath984 by lsqr for @xmath975 ( left ) and @xmath953 ( right).,width=226,height=188 ]    ( a )     by lsqr and the hybrid lsqr for @xmath973 ; ( c)-(d ) : the best possible regularized solutions @xmath984 by lsqr for @xmath975 ( left ) and @xmath953 ( right).,width=226,height=188 ]    ( b )     by lsqr and the hybrid lsqr for @xmath973 ; ( c)-(d ) : the best possible regularized solutions @xmath984 by lsqr for @xmath975 ( left ) and @xmath953 ( right).,width=226,height=188 ]    ( c )     by lsqr and the hybrid lsqr for @xmath973 ; ( c)-(d ) : the best possible regularized solutions @xmath984 by lsqr for @xmath975 ( left ) and @xmath953 ( right).,width=226,height=188 ]    ( d )    now we investigate the behavior of lsqr and the hybrid lsqr for @xmath947 .",
    "figure  [ figmild2 ] ( a ) indicates that the relative errors of @xmath148 by the hybrid lsqr reach a considerably smaller minimum level than those by lsqr , illustrating that lsqr has only the partial regularization . precisely , we find that the semi - convergence of lsqr occurs at iteration @xmath989 , but the regularized solution is not acceptable .",
    "the hybrid lsqr uses a larger six dimensional krylov subspace @xmath990 to construct a more accurate regularized solution .",
    "we also choose @xmath983 for lsqr and the hybrid lsqr , respectively .",
    "figure  [ figmild2 ] ( b ) indicates that the best regularized solution by the hybrid lsqr is a considerably better approximation to @xmath27 than that by lsqr , especially in the non - smooth middle part of @xmath27 .     and",
    "the regularized solutions @xmath984 by lsqr at semi - convergence and the best possible regularized solution by the hybrid lsqr for deriv2.,width=226,height=188 ]    ( a )     and the regularized solutions @xmath984 by lsqr at semi - convergence and the best possible regularized solution by the hybrid lsqr for deriv2.,width=226,height=188 ]    ( b )      for the severely ill - posed @xmath991 and the moderately ill - posed @xmath992 , we now illustrate that @xmath619 and @xmath620 decay as fast as the singular values @xmath58 of @xmath3 .",
    "we take the noise level @xmath973 .",
    "the results are similar for @xmath972 and @xmath293 .",
    "figure  [ fig7 ] illustrates that @xmath619 and @xmath620 both decay as fast as @xmath58 , and for @xmath960 and @xmath963 all of them decay swiftly and level off at @xmath970 due to round - off errors in finite precision arithmetic .",
    "precisely , they reach the level of @xmath970 at @xmath993 and @xmath994 for @xmath960 and @xmath963 , respectively . such decay behavior has also been observed in @xcite , but no theoretical support was given .",
    "these experiments confirm theorem  [ main1 ] and theorem  [ main2 ] , which have proved that @xmath450 decreases as fast as @xmath150 and that @xmath619 and @xmath620 decay as fast as @xmath58 .",
    ", @xmath620 and @xmath58 for @xmath995 ( from top left to bottom right).,width=226,height=188 ]    ( a )    , @xmath620 and @xmath58 for @xmath995 ( from top left to bottom right).,width=226,height=188 ]    ( b )    , @xmath620 and @xmath58 for @xmath995 ( from top left to bottom right).,width=226,height=188 ]    ( c )    , @xmath620 and @xmath58 for @xmath995 ( from top left to bottom right).,width=226,height=188 ]    ( d )      we compare the performance of lsqr and the tsvd method for the severely ill - posed @xmath982 and moderately ill - posed @xmath946 .",
    "we take @xmath973 . for each problem , we compute the norms of regularized solutions , their relative errors and the residual norms obtained by the two methods .",
    "we plot the l - curves of the residual norms versus those of regularized solutions in the @xmath996-@xmath996 scale .",
    "figures  [ lsqrtsvd1][lsqrtsvd2 ] indicate lsqr and the tsvd method behave very similarly for @xmath960 and @xmath963 .",
    "they illustrate that , for @xmath963 , the norms of approximate solutions and the relative errors by the two methods are almost indistinguishable for the same @xmath5 , and , for @xmath960 , the residual norms by lsqr decreases more quickly than the ones by the tsvd method for @xmath997 and then they become almost identical starting from @xmath989 .",
    "the l - curves tell us that the two methods obtain the best regularized solutions when @xmath998 and @xmath999 for @xmath960 and @xmath963 , respectively .",
    "the values of @xmath56 determined by the l - curves are exactly the ones at which semi - convergence occurs , as indicated by ( b ) and ( c ) in figures  [ lsqrtsvd1][lsqrtsvd2 ] .",
    "these results demonstrate that lsqr has the full regularization and resembles the tsvd method very much .    for each of @xmath975 and @xmath953 , figures  [ lsqrtsvd3][lsqrtsvd4 ] demonstrate that the best regularized solution obtained by lsqr is at least as accurate as , in fact , a little bit more accurate than that by the tsvd method , and the corresponding residual norms decreases and drop below at least the same level as those by the tsvd method .",
    "the residual norms by the two methods then stagnate after the best regularized solutions are found .",
    "all these confirm that lsqr has the full regularization .",
    "the fact that the best regularized solutions by lsqr can be more accurate than the best tsvd solutions is not unusual .",
    "we can explain why .",
    "we deduce from figure  [ fig6 ] that the true solutions of the problems @xmath975 and @xmath953 are at least first order differentiable . as a matter of fact , in the hilbert space setting , for a linear compact operator equation @xmath83",
    ", the tsvd method and standard - form tiknonov regularization method have been shown to be order optimal only when the true solution is continuous or first order differentiable , and they are not order optimal for stronger smoothness assumptions on the true solutio .",
    "in contrast , cgls is order optimal , and the smallest error of the iterates is of the same order as the worst - case error for the arbitrarily smooth true solution , that is , given the same noise level , the smoother the true solution is , the more accurate the best regularized solution is .",
    "in other words , for the smoother true solution , the best regularized solution by cgls is generally more accurate than the counterpart corresponding to the continuous or first order differentiable true solution ; see , e.g. , @xcite and @xcite .",
    "consequently , in the finite dimensional space case , provided that the mathematically equivalent lsqr has the full regularization , its best regularized solution is at least as accurate as and can be more accurate than the best regularized solution by the tsvd method or the standard - form tiknonov regularization method when the true solution is smoother than only continuous or first order differentiable .    from the figures we observe some obvious differences between moderately and severely ill - posed problems . for @xmath975",
    ", it is seen that the relative errors and residual norms converge considerably more quickly for the lsqr solutions than for the tsvd solutions .",
    "figure  [ lsqrtsvd3 ] ( b ) tells us that lsqr only uses @xmath1000 iterations to find the best regularized solution and the tsvd method finds the best regularized solution for @xmath1001 , while the l - curve gives @xmath1002 and @xmath1003 , respectively .",
    "similar differences are observed for @xmath953 , where figure  [ lsqrtsvd4 ] ( b ) indicates that both lsqr and the tsvd method find the best regularized solutions at @xmath998 , while the l - curve shows that @xmath1004 for lsqr and @xmath1005 for the tsvd method .",
    "therefore , unlike for severely ill - posed problems , the l - curve criterion is not very reliable to determine correct @xmath56 for moderately ill - posed problems .",
    "we can observe more .",
    "figure  [ lsqrtsvd3 ] shows that the tsvd solutions improve little and their residual norms decrease very slowly for the indices @xmath1006 .",
    "this implies that the @xmath180 corresponding to these indices @xmath54 make very little contribution to the tsvd solutions .",
    "this is due to the fact that the fourier coefficients @xmath1007 are very small relative to @xmath42 for these indices @xmath54 .",
    "note that @xmath157 adapts itself in an optimal way to the specific right - hand side @xmath2 , while the tsvd method uses all @xmath1008 to construct a regularized solution , independent of @xmath2 .",
    "therefore , @xmath157 picks up only those svd components making major contributions to @xmath27 , such that lsqr uses possibly fewer @xmath5 iterations than @xmath56 needed by the tsvd method to capture those truly needed dominant svd components .",
    "the fact that lsqr ( cgls ) includes fewer svd components than the tsvd solution with almost the same accuracy was first noticed by hanke @xcite . generally , for severely and moderately ill - posed problems , we may deduce that lsqr uses possibly fewer than @xmath56 iterations to compute a best possible regularized solution if , in practice , some of @xmath1009 , @xmath80 are considerably bigger than the corresponding @xmath42 and some of them are reverse . for @xmath953 ,",
    "as noted by hansen @xcite , half of the svd components satisfy @xmath1010 for @xmath54 even , only the odd indexed @xmath1011 make contributions to @xmath27 .",
    "this is why the relative errors and residual norms of tsvd solutions do not decrease at even indices before @xmath61 is found .",
    ".,width=226,height=188 ]    ( a )    .,width=226,height=188 ]    ( b )    .,width=226,height=188 ]    ( c )    .,width=226,height=188 ]    ( d )    .,width=226,height=188 ]    ( a )    .,width=226,height=188 ]    ( b )    .,width=226,height=188 ]    ( c )    .,width=226,height=188 ]    ( d )    .,width=226,height=188 ]    ( a )    .,width=226,height=188 ]    ( b )    .,width=226,height=188 ]    ( c )    .,width=226,height=188 ]    ( d )    .,width=226,height=188 ]    ( a )    .,width=226,height=188 ]    ( b )    .,width=226,height=188 ]    ( c )    .,width=226,height=188 ]    ( d )      gmres applied to solving with @xmath3 square computes the iterate @xmath1012 the quantity @xmath1013 measures the accuracy of the rank @xmath5 approximation @xmath1014 to @xmath3 , where the columns of @xmath1015 and @xmath1016 are orthonormal bases of @xmath1017 and @xmath1018 , respectively , generated by the arnoldi process starting with @xmath1019 , and @xmath1020 is the @xmath627 upper hessenberg matrix .",
    "the sizes of @xmath1021 measure the regularizing effects of gmres for solving . we should address that , different from @xmath450 defined by for lsqr , which has been proved to decrease monotonically as @xmath5 increases ( cf . ) , mathematically @xmath1021 has no monotonic property .",
    "similar to the lsqr iterates @xmath148 and @xmath450 , qualitatively speaking , if @xmath1021 decays smoothly in some definitive manner , then , to some extent , gmres has regularizing effects ; if they do not decay at all or behave irregularly , then gmres does not have regularizing effects and fails to work for .",
    "we test gmres on the general nonsymmetric @xmath975 and the following example 6 , and compare it with lsqr .",
    "* example 6*. consider the general nonsymmetric ill - posed problem @xmath1022 , which is severely ill - posed and arises from inverse laplace transformation .",
    "it is obtained by discretizing the first kind fredholm integral equation with @xmath1023 the domains of @xmath16 and @xmath17 .",
    "the kernel @xmath15 , the right - hand side @xmath13 and the solution @xmath14 are given by @xmath1024    we investigate the regularizing effects of gmres with @xmath973 .",
    "let @xmath1025 denote the upper hessenberg matrix obtained by the @xmath5-step arnoldi process .",
    "we notice that the @xmath1026 decay quickly with @xmath5 increasing , generally faster than @xmath58 ; see figure  [ fig8 ] ( a)-(b ) .",
    "this phenomenon may lead to a misbelief that gmres has general regularizing effects .",
    "however , it is not the case .",
    "in fact , a small @xmath1026 exactly indicates that all the eigenvalues of @xmath1027 may approximate some @xmath5 eigenvalues of @xmath3 well and the arnoldi method finds an approximate @xmath5-dimensional invariant subspace or eigenspace @xcite .",
    "we also refer to @xcite for a detailed convergence analysis of the arnoldi method .",
    "unfortunately , for a general nonsymmetric matrix @xmath3 , a small @xmath1026 does not mean that the singular values , i.e. , the ritz values , of @xmath1028 are also good approximations to some @xmath5 singular values of @xmath3 . as a matter of fact , as our analysis in section [ rankapp ] and section [ alphabeta ] has indicated , the accuracy of the singular values of a rank @xmath5 approximation matrix , here the singular values of @xmath1028 , as approximations to the @xmath5 large singular values of @xmath3 heavily relies on the size of @xmath1021 defined by other than @xmath1026 .",
    "indeed , as indicated by figure  [ fig8 ] ( c)-(d ) , though @xmath1026 is small , some of the singular values of @xmath1028 are very poor approximations to singular values of @xmath3 , and some of those good approximations are much smaller than @xmath150 and approximate the singular values of @xmath3 in disorder rather than in natural order .",
    "it is important to note that , for a general nonsymmetric or , more rigorously , non - normal @xmath3 , the @xmath5-dimensional krylov subspace @xmath1017 that underlies the arnoldi process mixes all the left and right singular vectors of @xmath3 , and the arnoldi process generally fails to extract the dominant svd components and can not generate a high quality rank @xmath5 approximation to @xmath3 , causing that gmres has no good regularizing effects .     and",
    "@xmath150 ; ( c)-(d ) : the singular values ( star ) of @xmath1028 and the ones ( solid line ) of @xmath3 for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( a )     and @xmath150 ; ( c)-(d ) : the singular values ( star ) of @xmath1028 and the ones ( solid line ) of @xmath3 for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( b )     and @xmath150 ; ( c)-(d ) : the singular values ( star ) of @xmath1028 and the ones ( solid line ) of @xmath3 for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( c )     and @xmath150 ; ( c)-(d ) : the singular values ( star ) of @xmath1028 and the ones ( solid line ) of @xmath3 for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( d )    figure  [ fig5 ] ( a)-(b ) gives more justifications .",
    "we have a few important observations : for the two test problems , the quantities @xmath450 decay as fast as the @xmath150 for lsqr , while the @xmath1021 diverge quickly from the @xmath150 for gmres and do not exhibit any regular decreasing tendency . for @xmath1022 , the @xmath1021 decrease very slowly until @xmath1029 , then basically stabilize for three iterations followed , and finally start to increase from @xmath993 onwards . as for @xmath975 , the @xmath1021 are almost constant from beginning to end .",
    "since all the @xmath1021 are not small , they indicate that the arnoldi process can not generate any reasonable and meaningful rank @xmath5 approximations to @xmath3 for @xmath1030 .",
    "this is especially true for @xmath975 .",
    "consequently , we are sure that gmres fails and does not have regularizing effects for the two test problems",
    ".    we plot @xmath1031 by lsqr and @xmath1032 by gmres in figure  [ fig5 ] ( c)-(d ) .",
    "obviously , lsqr exhibits semi - convergence , but gmres does not and the relative errors obtained by it even increase from the beginning ; see figure  [ fig5 ] ( d ) .",
    "this again demonstrates that gmres can not provide meaningful regularized solutions for these two problems .",
    "let @xmath983 .",
    "figure  [ fig5 ] ( e ) and ( f ) show that lsqr obtains excellent regularized solutions , while gmres fails .",
    "it is known that mr - ii @xcite for @xmath3 symmetric and rrgmres @xcite for @xmath3 nonsymmetric work on the subspace @xmath1033 .",
    "they were originally designed to solve singular or inconsistent systems , restricted to a subspace of range of @xmath3 , and compute the minimum - norm least squares solutions when the ranges of @xmath3 and @xmath1034 are identical . however , for the preferred rrgmres @xcite , we have observed phenomena similar to those gmres , illustrating that rrgmres does not have regularizing effects for the test problems . from these typical experiments ,",
    "we conclude that gmres and rrgmres are susceptible to failure for general nonsymmetric ill - posed problem and they are not general - purpose regularization methods .",
    "in fact , as addressed in @xcite and @xcite , gmres and rrgmres may only work well when either the mixing of svd components is weak or the krylov basis vectors are just well suited for the ill - posed problem , as addressed in @xcite .",
    ", @xmath1021 , denoted by @xmath450-lsqr and @xmath450-gmres in the figure , and @xmath150 ; ( c)-(d ) : the relative errors @xmath1031 ; ( e)-(f ) : the regularized solutions @xmath984 obtained by lsqr and gmres for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( a )    , @xmath1021 , denoted by @xmath450-lsqr and @xmath450-gmres in the figure , and @xmath150 ; ( c)-(d ) : the relative errors @xmath1031 ; ( e)-(f ) : the regularized solutions @xmath984 obtained by lsqr and gmres for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( b )    , @xmath1021 , denoted by @xmath450-lsqr and @xmath450-gmres in the figure , and @xmath150 ; ( c)-(d ) : the relative errors @xmath1031 ; ( e)-(f ) : the regularized solutions @xmath984 obtained by lsqr and gmres for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( c )    , @xmath1021 , denoted by @xmath450-lsqr and @xmath450-gmres in the figure , and @xmath150 ; ( c)-(d ) : the relative errors @xmath1031 ; ( e)-(f ) : the regularized solutions @xmath984 obtained by lsqr and gmres for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( d )    , @xmath1021 , denoted by @xmath450-lsqr and @xmath450-gmres in the figure , and @xmath150 ; ( c)-(d ) : the relative errors @xmath1031 ; ( e)-(f ) : the regularized solutions @xmath984 obtained by lsqr and gmres for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( e )    , @xmath1021 , denoted by @xmath450-lsqr and @xmath450-gmres in the figure , and @xmath150 ; ( c)-(d ) : the relative errors @xmath1031 ; ( e)-(f ) : the regularized solutions @xmath984 obtained by lsqr and gmres for @xmath1022 ( left ) and @xmath975 ( right).,width=226,height=188 ]    ( f )",
    "for the large - scale ill - posed problem , iterative methods are the only viable approaches . of them , lsqr and cgls are most popularly used for general purposes , and cgme and lsmr are also choices .",
    "they have regularizing effects and exhibit semi - convergence .",
    "however , if a small ritz value appears before they capture all the needed dominant svd components , then semi - convergence is not enough and the methods have only the partial regularization . in this case ,",
    "their hybrid variants have often been used to compute best possible regularized solutions . if semi - convergence means that they have already found best possible regularized solutions , they have the full regularization , and we simply stop them after semi - convergence .",
    "we have considered the fundamental open question in depth : do lsqr , cgls , lsmr and cgme have the full or partial regularization for severely , moderately and mildly ill - posed problems ? we have first considered the case that all the singular values of @xmath3 are simple . as a key and indispensable step ,",
    "we have established accurate bounds for the 2-norm distances between the underlying @xmath5 dimensional krylov subspace and the @xmath5 dimensional dominant right singular subspace for the three kinds of ill - posed problems under consideration .",
    "then we have provided other absolutely necessary background and ingredients . based on them ,",
    "we have proved that , for severely or moderately ill - posed problems with @xmath97 or @xmath95 suitably , lsqr has the full regularization .",
    "precisely , for @xmath107 we have proved that a @xmath5-step lanczos bidiagonalization produces a near best rank @xmath5 approximation of @xmath3 and the @xmath5 ritz values approximate the first @xmath5 large singular values in natural order , and no small ritz value smaller than @xmath155 appears before lsqr captures the @xmath56 needed dominant svd components , so that the noise @xmath21 in @xmath2 can not come into play deteriorating regularized solutions until a best possible regularized solution has been found .",
    "furthermore , we have shown that lsqr resembles the tsvd method .",
    "for mildly ill - posed problems , we have proved that lsqr generally has only the partial regularization since a small ritz value generally appears before all the needed dominant svd components are captured .",
    "since cgls is mathematically equivalent to lsqr , our assertions on the full or partial regularization of lsqr apply to cgls as well .",
    "we have given bounds for the diagonals and subdiagonals of bidiagonal matrices generated by lanczos bidiagonalization for a general ill - posed problem .",
    "particularly , we have proved that they decay as fast as the singular values of @xmath3 for the severely ill - posed problems or moderately ill - posed problems with @xmath97 or @xmath95 suitably and decay more slowly than the singular values of @xmath3 for mildly ill - posed problems .",
    "these bounds are of practical value and can be used to identify the degree of ill - posedness without extra cost and decide the full or partial regularization of lsqr .",
    "based on some of the results established for lsqr , we have derived accurate estimates for the quality of the rank @xmath5 approximations to @xmath3 and @xmath177 that are involved in cgme and lsmr , respectively .",
    "we have analyzed the behavior of the smallest singular values of the projected matrices associated with cgme and lsmr . using these results",
    ", we have shown that lsmr has the full regularization for severely and moderately ill - posed problems with @xmath95 and @xmath95 suitably , and it generally has only the partial regularization for mildly ill - posed probolems . in the meantime , we have shown that the regularization of cgme has indeterminacy and is inferior to lsqr and lsmr .",
    "in addition , our results have indicated that the rank @xmath5 approximations to @xmath3 generated by lanczos bidiagonalization are substantially more accurate than those obtained by standard randomized algorithms @xcite at less cost of flops and the strong rrqr factorizations @xcite at comparable cost of flops .",
    "remarkably , with a number of nontrivial modifications and reformulations , we have shown how to extend all the results obtained for lsqr , cgme and lsmr to the case that @xmath3 has multiple singular values .",
    "we have made illuminating numerical experiments and confirmed our assertions on lsqr .",
    "we have also compared lsqr with gmres and rrgmres , showing that the latter two methods do not have general regularizing effects and fail to deliver regularized solutions for general nonsymmetric ill - posed problems .",
    "rrgmres may work well only for ( nearly ) symmetric or , more generally , ( nearly ) normal ill - posed problems , for which the left and right singular vectors are ( nearly ) identical to with the eigenvectors of @xmath3 .",
    "our analysis approach can be adapted to mr - ii for symmetric ill - posed problems , and similar results and assertions are expected for three kinds of symmetric ill - posed problems . using a similar approach to that in @xcite ,",
    "the authors @xcite has made an initial regularization analysis of mr - ii and derived the corresponding @xmath4 bounds , which are too large overestimates .",
    "our approach are applicable to the preconditioned cgls ( pcgls ) and lsqr ( plsqr ) @xcite by exploiting the transformation technique originally proposed in @xcite and advocated in @xcite or the preconditioned mr - ii @xcite , all of which correspond to a general - form tikhonov regularization of the matrix pair @xmath1035 , in which the regularization term @xmath1036 is replaced by @xmath1037 with some @xmath988 matrix @xmath987 .",
    "it should also be applicable to the mathematically equivalent lsqr variant @xcite that is based on a joint bidiagonalization of the matrix pair @xmath1035 that corresponds to the above general - form tikhonov regularization . in this setting , the generalized svd ( gsvd ) of @xmath1035 or the mathematically equivalent svd of @xmath1038 will replace the svd of @xmath3 to play a central role in analysis , where @xmath1039 is call the _ @xmath3-weighted generalized inverse of @xmath1040 _ and @xmath1041 if @xmath1040 is square and invertible ; see @xcite and @xcite .    finally , we highlight on hybrid krylov iterative solvers and make some remarks , which deserve particular and enough attention in our opinion . because of lack of solid and rigorous regularized theory on lsqr , in order to find a best possible regularized solution for a given , one has commonly been using some hybrid lsqr variants without considering the degree of ill - posedness of ; see , e.g. , @xcite and the related papers mentioned in the introduction . the hybrid cgme @xcite and cgls @xcite",
    "have also been proposed and used .",
    "however , bjrck @xcite has addressed that the hybrid lsqr variants are mathematically complicated , and pointed out that it is hard to find reasonable regularization parameters and tell when to stop them reliably .    for a hybrid lsqr variant , or more generally , for any hybrid krylov solver that first projects and then regularizes @xcite",
    ", the situation is much more serious than what one might think .",
    "it has long commonly accepted that _",
    "`` first - regularize - then - project '' _ is equivalent to _",
    "`` first - project - then - regularize '' _ and they produce the same solution ; see section 6.4 and figure 6.10 of @xcite .",
    "this equivalence seems natural . as a matter of fact",
    ", it is not the case , and they are generally _ not _ equivalent when solving .",
    "assume that the same regularization parameter @xmath106 in tikhonov regularization is _",
    "given_. both of them solve the the same well - posed problem and compute the same regularized solution . however , the fundamental point is that each of them must determine the _ unknown _ regularization parameter @xmath106 which is not given in advance .",
    "mathematically , the approach of `` first - regularize - then - project '' can determine an optimal @xmath106 since satisfies the picard condition , though it is generally not computationally viable for a large .",
    "on the contrary , for the approach of `` first - project - then - regularize '' , one must determine its optimal @xmath106 for each projected problem , so one will have a sequence of @xmath106 . for the discrete regularization parameter involved in the tsvd method for and projected problems ,",
    "the situation is similar .",
    "unfortunately , this may lead to fatal mathematical difficulties , as we will explain below .",
    "as is well known , the picard condition is an absolutely necessary condition for the existence of the squares integrable solution to a linear compact operator equation ; without it , regularization would be out of the question ; see , e.g. , @xcite .",
    "this is also true for the discrete linear ill - posed problem , where the discrete picard condition means that @xmath1042 uniformly with some ( not large ) constant @xmath39 such that regularization is useful to compute a meaningful approximation to it @xcite .",
    "nevertheless , to the best of our knowledge , the discrete picard conditions for projected problems arising from lsqr or any other krylov iterative solver have been paid little attention until very recently @xcite .",
    "unfortunately , a fatal problem is that _ the discrete picard conditions are not necessarily satisfied for the projected problems_. in @xcite , under the assumption that the right - hand side @xmath2 of is _ noise free _",
    ", i.e. , the noise @xmath1043 and @xmath1044 , the authors have proved that the discrete picard conditions are satisfied or inherited for the projected problems under the _ absolutely necessary assumption _ that the @xmath5 ritz values , i.e. , the singular values of the projected matrix at iteration @xmath5 , approximate the @xmath5 large singular values of @xmath3 in natural order , regularization makes sense and can be used to solve the projected problems . however , as have been stated in @xcite and highlighted in this paper , under such assumption , krylov solvers themselves will find best possible regularized solutions at semi - convergence , and there is no need to continue iterating and regularize the projected problems at all . on the other hand , if the @xmath5 ritz values do not approximate the @xmath5 large singular values of @xmath3 in natural order and at least one ritz value smaller than @xmath155 appears before @xmath107 , the discrete picard conditions are _ essentially not satisfied any longer _ for the projected problems starting from such @xmath5 onwards .",
    "if so , regularization applied to projected problems is mathematically groundless and meaningless , leading to invincible failure .",
    "we take lsqr as an example for a precise statement on the discrete picard conditions for projected problems .",
    "recall that , in the projected problem , the noisy right - hand side is @xmath1045 with @xmath20 and the noise - free right - hand side is @xmath1046 .",
    "then for @xmath197 and for @xmath40 arbitrarily large and @xmath1047 ( cf .",
    "@xcite ) , the discrete picard conditions for the projected problems are @xmath1048 uniformly with some constant @xmath39 . numerically , for a given @xmath40 , once @xmath1049 is large for some @xmath5 , then the discrete picard condition actually fails for the corresponding projected problem , such that regularization applied to the projected problem may work poorly .",
    "indeed , for the moderately ill - posed phillips and mildly ill - posed deriv2 of order @xmath954 and @xmath955 , we have observed that the hybrid lsqr exhibits considerable _",
    "erratic _ other than smooth curves of the errors between the regularized solutions and @xmath27 in the dampening and stabilizing stage , causing that the hybrid lsqr is unreliable to obtain a best regularized solutions to the problems ; see figure  [ figerratic ] .",
    "actually , the regularized solutions obtained by the hybrid lsqr after its stabilization are considerably less accurate than those by the pure lsqr itself .",
    "for deriv2 of order @xmath954 , similar phenomena have also been noticed for the hybrid minres and mr - ii @xcite .     by lsqr and the hybrid lsqr for phillips of @xmath954 and @xmath955 with @xmath973 and @xmath293 , respectively ; ( c)-(d ) : the relative errors @xmath1031 by lsqr and the hybrid lsqr for deriv2 of @xmath954 and @xmath955 with @xmath973.,width=226,height=188 ]    ( a )     by lsqr and the hybrid lsqr for phillips of @xmath954 and @xmath955 with @xmath973 and @xmath293 , respectively ; ( c)-(d ) : the relative errors @xmath1031 by lsqr and the hybrid lsqr for deriv2 of @xmath954 and @xmath955 with @xmath973.,width=226,height=188 ]    ( b )     by lsqr and the hybrid lsqr for phillips of @xmath954 and @xmath955 with @xmath973 and @xmath293 , respectively ; ( c)-(d ) : the relative errors @xmath1031 by lsqr and the hybrid lsqr for deriv2 of @xmath954 and @xmath955 with @xmath973.,width=226,height=188 ]    ( c )     by lsqr and the hybrid lsqr for phillips of @xmath954 and @xmath955 with @xmath973 and @xmath293 , respectively ; ( c)-(d ) : the relative errors @xmath1031 by lsqr and the hybrid lsqr for deriv2 of @xmath954 and @xmath955 with @xmath973.,width=226,height=188 ]    ( d )    this is due to the actual failure of the discrete picard conditions for the projected problems resulting from krylov solvers because each of the projected matrices starts to have at least one singular value _",
    "considerably _ smaller than @xmath155 from some iteration @xmath107 onwards , which and whose corresponding ( left and right ) ritz vectors does not approximate any singular triplet of @xmath3 well .",
    "a consequence of such actual failure is that it is hard to reliably stop the hybrid variants at right iteration in order to find best regularized solutions .",
    "therefore , for mildly or moderately ill - posed problems with @xmath95 not enough , it is appealing to seek other mathematically solid and computationally viable variants of lsqr , lsmr and mr - ii in order to find best possible regularized solutions .",
    "i thank dr . yi huang and mrs .",
    "yanfei yang for running the numerical experiments in this paper .                          , _ methods in numerical algebra for ill - posed problems _",
    ", report lith - r-33 - 1979 , dept . of mathematics , linkping univeristy , sweden , 1979 .",
    "proceedings of the international symposium on ill - posed problems : theory and practice , university of delaware , newark , delaware , oct . 26 , 1979 .                                                                                                                          ,",
    "_ a refined harmonic lanczos bidiagonalization method and an implicitly restarted algorithm for computing the smallest singular triplets of large matrices _ , siam j. sci .",
    "comput . , 32 ( 2010 ) ,"
  ],
  "abstract_text": [
    "<S> for the large - scale linear discrete ill - posed problem @xmath0 or @xmath1 with a noisy @xmath2 , lsqr , which is a krylov iterative solver based on lanczos bidiagonalization , and its mathematically equivalent cgls are most commonly used . </S>",
    "<S> they have intrinsic regularizing effects , where the number of iterations plays the role of regularization parameter . </S>",
    "<S> however , there has been no answer to the long - standing fundamental concern : _ for which kinds of problems lsqr and cgls can find best possible regularized solutions _ ? </S>",
    "<S> the concern was actually expressed foresightedly by bjrck and eldn in 1979 . here </S>",
    "<S> a best possible regularized solution means that it is at least as accurate as the best regularized solution obtained by the truncated singular value decomposition ( tsvd ) method , which and the best possible solution of standard - form tikhonov regularization are both of the same order of the worst - case error and can not be improved under the assumption that the solution to an underlying linear compact operator equation is continuous or its derivative squares integrable . in this paper </S>",
    "<S> we make a complete analysis on the regularization of lsqr for severely , moderately and mildly ill - posed problems . </S>",
    "<S> we first consider the case that the singular values of @xmath3 are simple . </S>",
    "<S> we establish accurate @xmath4 theorems for the 2-norm distance between the underlying @xmath5-dimensional krylov subspace and the @xmath5-dimensional dominant right singular subspace of @xmath3 . </S>",
    "<S> based on them and some follow - up results , for the first two kinds of problems , we prove the following results : ( i ) the @xmath5-step lanczos bidiagonalization always generates a near best rank @xmath5 approximation to @xmath3 ; ( ii ) the @xmath5 ritz values always approximate the first @xmath5 large singular values in natural order ; ( iii ) the @xmath5-step lsqr always captures the @xmath5 dominant svd components of @xmath3 , so that lsqr can find a best possible regularized solution ; ( iv ) the diagonals and subdiagonals of the bidiagonal matrices generated by lanczos bidiagonalization decay as fast as the singular values of @xmath3 . however , for the third kind of problem , the above results do not hold generally . the decay rates of diagonals and subdiagonals of the bidiagonal matrices can be used to decide if lsqr can find a best possible regularization solution . </S>",
    "<S> we also analyze the regularization of other two krylov solvers lsmr and cgme that amount to minres and the cg method and minres applied to @xmath6 and @xmath7 with @xmath8 , respectively , proving that lsmr has similar regularizing effects to lsqr for each kind of problem and both are superior to cgme . </S>",
    "<S> we extend all the results to the case that @xmath3 has multiple singular values . </S>",
    "<S> numerical experiments confirm our theory on lsqr .    discrete ill - posed , full or partial regularization , best or near best rank @xmath5 approximation , tsvd solution , ritz value , lanczos bidiagonalization , lsqr , cgls , lsmr , cgme    65f22 , 65f10 , 65j20 , 65r30 , 15a18 </S>"
  ]
}