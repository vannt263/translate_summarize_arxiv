{
  "article_text": [
    "after many years of preparation , interferometric gravitational wave ( gw ) detectors have now begun an era of long - duration observing .",
    "the three detectors of the laser interferometer gravitational - wave observatory ( ligo )  @xcite reached their design sensitivity levels in 2005 and began a `` science run '' that collected data through late 2007 .",
    "this run is called `` s5 '' since it followed a sequence of four shorter science runs that began in 2002 .",
    "the german / british geo600 detector  @xcite joined the s5 run in january 2006 , and the italian / french virgo detector  @xcite began its first science run ( denoted vsr1 ) in may 2007 , overlapping the last @xmath3 months of the s5 run .",
    "the data collected by these detectors provide the best opportunity yet to identify a gw signal  though detection is still far from certain  and is a baseline for future coordinated data collection with upgraded detectors .",
    "gravitational waves in the frequency band of ligo and the other ground - based detectors may be produced by a variety of astrophysical processes  @xcite .",
    "see for example  @xcite for inspiralling compact binaries ,  @xcite for spinning neutron stars ,  @xcite for binary mergers , and  @xcite for core - collapse supernovae .",
    "the gw waveform emitted by a compact binary system during the inspiral phase can be calculated accurately in many cases , allowing searches with optimal matched filtering ; see , for example , @xcite .",
    "the waveform from the subsequent merger of two black holes is being modeled with ever - increasing success using numerical relativity calculations , but is highly dependent on physical parameters and the properties of strong - field gravity .",
    "the uncertainties for the waveforms of other transient sources are even larger .",
    "it is thus desirable to explore more generic search algorithms capable of detecting a wide range of short - duration gw signals from poorly - modeled sources  such as stellar core collapse to a neutron star or black hole  or unanticipated sources .",
    "as gw detectors extend the sensitivity frontier , it is important to not rely too heavily on assumptions about source astrophysics or about the true nature of strong - field gravity , and to search as broadly as possible .    in this paper",
    ", we report on a search for gw `` burst '' signals in the ligo data that were collected during the first 12 months of the s5 science run .",
    "a search for gw bursts in the remainder of the s5 data set , along with the virgo vsr1 data , will be published jointly by the lsc and virgo collaborations at a later date .",
    "the gw burst signals targeted are assumed to have signal power within ligo s frequency band and durations shorter than @xmath41s , but are otherwise arbitrary .",
    "this analysis , like most of our previously published searches for gw bursts , focuses on low frequencies  in this case 64hz to 2000hz  where the detectors are the most sensitive . a dedicated search for bursts above 2000hz",
    "is presented in a companion paper @xcite .",
    "interferometric gw detectors collect stable , high - sensitivity ( `` science mode '' ) data typically for several hours at a time , with interruptions due to adverse environmental conditions , maintenance , diagnostics , and the need to occasionally regain the `` locked '' state of the servo controls . in this analysis we searched the data at all times when two or more ligo detectors were operating , a departure from the all - sky gw burst searches from earlier science runs  @xcite , which required coincidence among three ( or more ) detectors . in this paper ,",
    "the term `` network '' is used to describe a set of detectors operating in science mode at a given time .",
    "a network may include any combination of the hanford 4 km ( h1 ) and 2 km ( h2 ) detectors , the livingston 4 km ( l1 ) detector and geo600 .",
    "because the geo600 detector was significantly less sensitive than ligo during the s5 run ( a factor of 3 at 1000hz , and almost two orders of magnitude at 100hz ) , we do not use its data in the initial search but reserve it for evaluating any event candidates found in the ligo data .",
    "this paper presents results from three different `` analysis pipelines '' , each representing a complete search . while the pipelines analyzed the data independently , they began with a common selection of good - quality data and applied a common set of vetoes to reject identifiable artifacts .",
    "each pipeline was tuned to maximize the sensitivity to simulated gw signals while maintaining a fixed , low false alarm rate .",
    "the tuning of the pipelines , the choice of good data and the decision on the veto procedure were made before looking at potential candidates .",
    "no gw signal candidates were identified by any of the analysis pipelines with the chosen thresholds . in order to interpret this non - detection",
    ", we evaluate the sensitivity of each pipeline for simulated signals of various morphologies , randomly distributed over the sky and over time .",
    "as expected , there are some sensitivity differences among the pipelines , although the sensitivities rarely differ by more than a factor of 2 ( see section  [ sec : simulations ] ) and no single pipeline performs best for all of the simulated signals considered .",
    "we combine the results of the pipelines to calculate upper limits on the rate of gw bursts as a function of signal morphology and strength .",
    "the rest of the paper is organized as follows : after specifying the periods of data , forming the first year of the s5 science run in sec .",
    "[ sec : ligos5run ] , sec .",
    "[ sec : s5detectors ] describes the state of the detectors during that period .",
    "section iv summarizes the elements of this gw burst search which are common to all of the analysis pipelines .",
    "the analysis pipelines themselves are detailed in sec .",
    "[ sec : algorithms ] and appendices c , d and  e. section  [ sec : tuning ] describes how each pipeline is tuned , while sec .",
    "[ sec : simulations ] presents the sensitivity curves for simulated signals and sec .  [",
    "sec : systematics ] describes the systematic errors in these sensitivity curves .",
    "the results of the search are given in sec .",
    "[ sec : results ] , and some discussion including estimates of the astrophysical reach for burst candidates in sec .",
    "[ sec : summaries ] .",
    "the search described in this paper uses data from approximately the first calendar year of s5 , specifically from november 4 , 2005 at 16:00 utc through november 14 , 2006 at 18:00 utc .",
    "+     figure  [ figure : venn ] shows the amount of science - mode data collected ( `` livetime '' ) for each mutually - exclusive network of detectors along with percentages of the experiment calendar duration ( duty cycle ) . the top venn diagram represents the data with basic data quality and veto conditions ( see sec .",
    "iv and appendices  [ sec : dataquality ] and  [ sec : vetoes ] ) , including @xmath5 days of data during which two or more ligo detectors were in science mode ; this is the sample which is searched for gw burst signals .",
    "an explicit list of the analyzed intervals after category 2 dqfs is available at  @xcite .",
    "the bottom venn diagram shows the livetimes after the application of additional data quality cuts and vetoes that provide somewhat cleaner data for establishing upper limits on gw burst event rates . in practice ,",
    "only the h1h2l1 and h1h2 ( not l1 ) networks  encompassing most of the livetime , 224 days ",
    "are used to set upper limits .",
    "the high sensitivity ( see fig .  [ fg : ligo - noise ] ) and duty cycles ( 78.0% for h1 , 78.5% for h2 , and 66.9% for l1 ) achieved during the s5 run were the result of a number of improvements made prior to the run  @xcite .",
    "the major changes were the successful operation at livingston of a hydraulic external pre - isolator ( hepi ) to suppress seismic disturbances , and the implementation at both sites of a thermal compensation system ( tcs ) to reduce thermal lensing effects in the interferometer arm cavities due to optical absorption in mirror coatings and substrates .",
    "the hepi system provides a reduction of the seismic noise by an order of magnitude in the band 0.22.0hz , and thus significantly improves the duty cycle of the l1 detector .",
    "another significant improvement was the extension of the wave - front sensing ( wfs ) subsystem to control all alignment degrees of freedom of the core interferometer optics , leading to significantly reduced alignment fluctations .",
    "several improvements were made to the length sensing and control subsystem , enabling the photodetectors to take more power without saturation and thus allowing the laser power to be increased . a new method to calibrate the detectors",
    "was introduced , based on direct actuation of the test masses via radiation pressure from an auxiliary laser beam .",
    "unlike the traditional coil - drive calibration method @xcite , which requires rather large test mass displacements , the new technique allows calibration of the detectors at a level closer to the anticipated signal strength .",
    "other improvements included modifications to acoustic and seismic isolation of optical tables with detection photodiodes , changes to the safety shutters to protect photodiodes from damage when interferometers fall out of lock , and improved detection of impending saturation of photodiodes to prevent lock losses .",
    "finally , a number of physical effects which led to spurious transients and spectral lines in the data during previous science runs have been diagnosed and mitigated .",
    "the geo600 detector , located near hannover , germany , was also operational during the s5 run , though with a lower sensitivity than the ligo detectors .",
    "the geo600 data were not used in the current study as the modest gains in the sensitivity to gw signals would not have offset the increased complexity of the analysis .",
    "the geo600 data were held in reserve , and could have been used to follow up on detection candidates from the ligo - only analysis .",
    "geo600 began its participation in s5 on january  21 , 2006 , operating in a night - and - weekend mode . in this mode ,",
    "science data were acquired during nights and weekends while commissioning work was performed during the day time .",
    "the commissioning work focused mainly on gaining a better understanding of the detector and improving data quality .",
    "it was performed in a manner that avoided disrupting science periods and allowed for well - calibrated data to be acquired . between",
    "may  1 and october  6 , 2006 , geo600 operated in so - called 24/7-mode , during which the detector s duty cycle in science - mode operation was maximized and only very short maintenance periods took place .",
    "overall in 24/7-mode an instrumental duty cycle of about 95% and a science - mode duty cycle of more than 90% were achieved .",
    "geo600 returned to night - and - weekend mode on october  16 , 2006 , and work began on further improving the reliability of the instrumentation and reducing the glitch rate .",
    "the detector was operated in night - and - weekend mode until the end of s5 in october 2007 .",
    "overall , geo600 collected about 415 days of well - calibrated and characterized science data in the period between january 2006 and october 2007 .",
    "in this search for gw bursts , three independent end - to - end analysis pipelines have been used to analyze the data .",
    "these pipelines were developed and implemented separately , building upon many of the techniques that were used in previous searches for bursts in the s1 , s2 , s3 and s4 runs of ligo and geo600  @xcite , and prove to have comparable sensitivities ( within a factor of @xmath4@xmath6 ; see sec .",
    "[ sec : simulations ] ) .",
    "one of these pipelines is fully coherent in the sense of combining data ( amplitude and phase ) from all detectors and accounting appropriately for time delays and antenna responses for a hypothetical gravitational - wave burst impinging upon the network .",
    "this provides a powerful test to distinguish gw signals from noise fluctuations .",
    "here we give an overview of the basic building blocks common to all of the pipelines .",
    "the detailed operation of each pipeline will be described later .",
    "gravitational - wave burst searches are occasionally affected by instrumental or data acquisition problems as well as periods of degraded sensitivity or nonstationary noise due to bad weather or other environmental conditions .",
    "these may produce transient signals in the data and/or may complicate the evaluation of the significance of other candidate events .",
    "conditions which may adversely affect the quality of the data are catalogued during and after the run by defining `` data quality flags '' ( dqfs ) for lists of time intervals .",
    "dqfs are categorized according to their seriousness ; some are used immediately to select the data to be processed by the analysis pipelines ( a subset of the nominal science - mode data ) , while others are applied during post - processing .",
    "these categories are described in more detail in appendix a. in all cases the dqfs were defined and categorized before analyzing unshifted data to identify event candidates .",
    "data that satisfies the initial selection criteria are passed to algorithms that perform the signal - processing part of the search , described in the following section and in three appendices .",
    "these algorithms decompose the data stream into a time - frequency representation and look for statistically significant transients , or `` triggers '' .",
    "triggers are accepted over a frequency band that spans from 64hz to 2000hz .",
    "the lower frequency cut - off is imposed by seismic noise which sharply reduces sensitivity at low frequencies , while the upper cut - off corresponds roughly to the frequency at which the sensitivity degrades to the level found at the low frequency cut - off .",
    "( a dedicated search for bursts with frequency content above 2000hz is presented in a companion paper  @xcite . )      after gravitational - wave triggers have been identified by an analysis pipeline , they are checked against additional dqfs and `` veto '' conditions to see if they occurred within a time interval which should be excluded from the search .",
    "the dqfs applied at this stage consist of many short intervals which would have fragmented the data set if applied in the initial data selection stage .",
    "event - by - event veto conditions are based on a statistical correlation between the rate of transients in the gw channel and noise transients , or `` glitches '' , in environmental and interferometric auxiliary channels .",
    "the performance of vetoes ( as well as dqfs ) are evaluated by the extent to which they remove the gw channel transients of each interferometer , as identified by the kleinewelle ( kw )  @xcite algorithm .",
    "kw looks for excess signal energy by decomposing a timeseries into the haar wavelet domain . for each transient",
    ", kw calculates a significance defined as the negative of the natural logarithm of the probability , in gaussian noise , of observing an event as energetic or more than the one in consideration .",
    "the veto conditions , like the dqfs , were completely defined before unshifted data was analyzed to identify gravitational - wave event candidates .",
    "a detailed description of the implementation of the vetoes is given in appendix b.      in order to estimate the false trigger rate from detector noise fluctuations and artifacts , data from the various detectors are artificially shifted in time so as to remove any coincident signals .",
    "these time - shifts have strides much longer than the intersite time - of - flight for a true gravitational - wave signal and thus are unlikely to preserve any reconstructable astrophysical signal when analyzed .",
    "we refer to these as time - shifted data .",
    "both unshifted and time - shifted data are analyzed by identical procedures , yielding the candidate sample and the estimated background of the search , respectively . in order to avoid any biases , no unshifted data are used in the tuning of the methods . instead , combined with simulations ( see below ) ,",
    "background data are used as the test set over which all analysis cuts are defined * prior * to examining the unshifted data - set . in this way ,",
    "our analyses are `` blind '' .      during the s5 run",
    ", simulated gw signals were occasionally injected into the data by applying an actuation to the mirrors at the ends of the interferometer arms .",
    "the waveforms and times of the injections were cataloged for later study .",
    "these were analyzed as an end - to - end validation of the interferometer readout , calibration , and detection algorithms .",
    "in addition to analyzing the recorded data stream in its original form , many simulated signals are injected in software  by adding the signal to the digital data stream  in order to to simulate the passage of gravitational - wave bursts through the network of detectors .",
    "the same simulated signals are analyzed by all three analysis pipelines .",
    "this provides a means for establishing the sensitivity of the search by measuring the probability of detection as a function of the signal morphology and strength .",
    "these will also be referred to as efficiency curves .",
    "unmodeled gw bursts can be distinguished from instrumental noise if they show consistency in time , frequency , shape , and amplitude among the ligo detectors .",
    "the time constraints , for example , follow from the maximum possible propagation delay between the hanford and livingston sites which is 10ms .",
    "this s5 analysis employs three algorithms to search for gw bursts : blocknormal @xcite , qpipeline  @xcite , and coherent waveburst  @xcite .",
    "a detailed description of each algorithm can be found in the appendices .",
    "here we limit ourselves to a brief summary of the three techniques .",
    "all three algorithms essentially look for excess power  @xcite in a time - frequency decomposition of the data stream .",
    "events are ranked and checked for temporal coincidence and coherence ( defined differently for the different algorithms ) across the network of detectors .",
    "the three techniques differ in the details of how the time - frequency decompositions are performed , how the excess power is computed , and how coherence is assessed .",
    "each analysis pipeline was independently developed , coded and tuned . because the three pipelines have different sensitivities to different types of gw signals and instrumental artifacts , the results of the three searches can be combined to produce stronger statements about event candidates and upper limits .",
    "blocknormal ( bn ) performs a time - frequency decomposition by taking short segments of data and applying a heterodyne basebanding procedure to divide each segment into frequency bands .",
    "a change - point analysis is used to identify events with excess power in each frequency band for each detector , and events are clustered to form single - interferometer triggers .",
    "triggers from the various interferometers that fall within a certain coincidence window are then combined to compute the `` combined power '' , @xmath7 , across the network .",
    "these coincident triggers are then checked for coherence using corrpower , which calculates a cross - correlation statistic @xmath8 that was also used in the s4 search  @xcite .",
    "a detailed description of the bn algorithm can be found in appendix  [ sec : blocknormal ] .",
    "qpipeline ( qp ) performs a time - frequency decomposition by filtering the data against bisquare - enveloped sine waves , in what amounts to an over - sampled wavelet transform .",
    "the filtering procedure yields a standard matched filter signal to noise ratio ( snr ) , @xmath9 , which is used to identify excess power events in each interferometer ( quoted in terms of the quantity @xmath10 ) .",
    "triggers from the various interferometers are combined to give candidate events if they have consistent central times and frequencies .",
    "qpipeline also looks for coherence in the response of the h1 and h2 interferometers by comparing the excess power of sums ( the coherent combination @xmath11 ) and differences ( the null combination @xmath12 ) of the data . rather than using the single - interferometer h1 , h2 , l1 , signal to noise ratios",
    ", the qpipeline analysis uses the snrs in the transformed channels @xmath11 , @xmath12 , and l1 .",
    "a detailed description of the qpipeline algorithm can be found in appendix  [ sec : qpipeline ] .",
    "coherent waveburst ( cwb ) performs a time - frequency decomposition using critically sampled meyer wavelets .",
    "the cwb version used in s5 replaces the separate coincidence and correlation test ( corrpower ) used in the s4 analysis  @xcite by a single coherent search statistic based on a gaussian likelihood function .",
    "constrained waveform reconstruction is used to compute the _ network _ likelihood and a coherent network amplitude .",
    "this coherent analysis has the advantage that it is not limited by the performance of the least sensitive detector in the network . in the cwb analysis ,",
    "various signal combinations are used to measure the signal consistency among different sites : a network correlation statistic @xmath13 , network energy disbalance @xmath14 , h1-h2 disbalance @xmath15 and a penalty factor @xmath16 .",
    "these quantities are used in concert with the coherent network amplitude @xmath17 to develop efficient selection cuts that can eliminate spurious events with a very limited impact on the sensitivity .",
    "it is worth noting that the version of cwb used in the s5 search is more advanced than the one used on ligo and geo data in s4  @xcite .",
    "a detailed description of the cwb algorithm can be found in appendix  [ sec : cwb ] .    both qpipeline and coherent waveburst use the freedom to form linear combinations of the data to construct `` null streams '' that are insensitive to gws .",
    "these null streams provide a powerful tool for distinguishing between genuine gw signals and instrument artifacts  @xcite .",
    "as mentioned in sec .",
    "iv , the statistical properties of the noise triggers ( background ) are studied for all network combinations by analyzing time - shifted data , while the detection capabilities of the search pipelines for various types of gw signals are studied by analyzing simulated signals ( described in the following section ) injected into actual detector noise .",
    "plots of the parameters for noise triggers and signal injections are then examined to tune the searches .",
    "thresholds on the parameters are chosen to maximize the efficiency in detecting gws for a predetermined , conservative false alarm rate of roughly 5 events for every 100 time shifts of the full data set , _",
    "@xmath4@xmath18 events expected for the duration of the data set .    for a given energy threshold , all three pipelines observed a much larger rate of triggers with frequencies below 200hz than at higher frequencies .",
    "therefore , each pipeline set separate thresholds for triggers above and below 200hz , maintaining good sensitivity for higher - frequency signals at the expense of some sensitivity for low - frequency signals .",
    "the thresholds were tuned separately for each detector network , and the cwb pipeline also distinguished among a few distinct epochs with different noise properties during the run . a more detailed description of the tuning process can be found in appendices c , d , and e.",
    "in this section we present the efficiencies of the different algorithms in detecting simulated gws . as in previous science runs , we do not attempt to survey the complete spectrum of astrophysically motivated signals . instead , we use a limited number of ad hoc waveforms that probe the range of frequencies of interest , different signal durations , and different gw polarizations .",
    "we choose three families of waveforms : sine - gaussians , gaussians , and `` white noise bursts '' .",
    "an isotropic sky distribution was generated in all cases .",
    "the gaussian and sine - gaussian signals have a uniformly distributed random linear polarization , while the white noise bursts contain approximately equal power in both polarizations .",
    "we define the amplitude of an injection in terms of the total signal energy at the earth observable by an ideal optimally oriented detector able to independently measure both signal polarizations : @xmath19    in reality , the signal observed at an individual detector depends on the direction @xmath20 to the source and the polarization angle @xmath21 through `` antenna factors '' @xmath22 and @xmath23 : @xmath24    in order to estimate the detection efficiency as a function of signal strength , the simulated signals were injected at 22 logarithmically spaced values of @xmath25 ranging from @xmath26 to @xmath27 , stepping by factors of @xmath4@xmath28 .",
    "injections were performed at quasi - random times regardless of data quality or detector state , with an average rate of one injection every 100 seconds .",
    "the efficiency of a method is then defined as the fraction of waveforms that are detected out of all that were injected into the data analyzed by the method .",
    "the first family of injected signals are sine - gaussians .",
    "these are sinusoids with a central frequency @xmath29 , dimensionless width @xmath30 and arrival time @xmath31 , defined by : @xmath32.\\ ] ] more specifically @xmath29 was chosen to be one of ( 70 , 100 , 153 , 235 , 361 , 554 , 849 , 945 , 1053 , 1172 , 1304 , 1451 , 1615 , 1797 , 2000 ) hz ; and @xmath30 to be one of 3 , 9 , or 100 .",
    "the second family consists of gaussian pulses described by the following expression : @xmath33 where @xmath34 is chosen to be one of ( 0.05 , 0.1 , 0.25 , 0.5 , 1.0 , 2.5 , 4.0 , 6.0 , 8.0 ) ms .",
    "the third family are the `` white noise bursts '' ( wnbs ) .",
    "these were generated by bandpassing white noise in frequency bands starting at 100hz , 250hz , or 1000hz , with bandwidth 10hz , 100hz , or 1000hz , and by time windowing with gaussian profiles of duration ( half of the interval between the inflection points ) equal to 100ms , 10ms , or 1ms .",
    "for each waveform type ( a choice of central frequency , bandwidth , and duration ) , 30 waveform files with random data content were created .",
    "the injections for each waveform type use random pairs selected from the 30 created waveforms for the @xmath35 and @xmath36 polarizations ( the selection avoids pairs with identical waveforms ) .",
    "this results in unpolarized injections with equal amounts of power on average in each polarization state .",
    "combined efficiencies of the three pipelines and two networks ( h1h2l1 and h1h2 ) used in the upper limit analysis for selected sine - gaussian waveforms with ( a ) @xmath37 , ( b ) @xmath38 , ( c ) @xmath39 .",
    "these efficiencies have been calculated using the logical or of the pipelines and networks for the subset of simulated signals that were injected in time intervals that were actually analyzed , and thus approach unity for large amplitudes .",
    ", title=\"fig:\",width=288 ] +    combined efficiencies of the three pipelines and two networks ( h1h2l1 and h1h2 ) used in the upper limit analysis for selected sine - gaussian waveforms with ( a ) @xmath37 , ( b ) @xmath38 , ( c ) @xmath39 .",
    "these efficiencies have been calculated using the logical or of the pipelines and networks for the subset of simulated signals that were injected in time intervals that were actually analyzed , and thus approach unity for large amplitudes .",
    ", title=\"fig:\",width=288 ] +    combined efficiencies of the three pipelines and two networks ( h1h2l1 and h1h2 ) used in the upper limit analysis for selected sine - gaussian waveforms with ( a ) @xmath37 , ( b ) @xmath38 , ( c ) @xmath39 .",
    "these efficiencies have been calculated using the logical or of the pipelines and networks for the subset of simulated signals that were injected in time intervals that were actually analyzed , and thus approach unity for large amplitudes .",
    ", title=\"fig:\",width=288 ]     combined efficiency of the three pipelines and two networks ( h1h2l1 and h1h2 ) used in the upper limit analysis for ( a ) selected linearly - polarized gaussian waveforms ; ( b ) selected band - limited white - noise bursts with two independent polarization components .",
    "these efficiencies have been calculated using the logical or of the pipelines and networks for the subset of simulated signals that were injected in time intervals that were actually analyzed , and thus approach unity for large amplitudes .",
    ", title=\"fig:\",width=288 ] +    combined efficiency of the three pipelines and two networks ( h1h2l1 and h1h2 ) used in the upper limit analysis for ( a ) selected linearly - polarized gaussian waveforms ; ( b ) selected band - limited white - noise bursts with two independent polarization components .",
    "these efficiencies have been calculated using the logical or of the pipelines and networks for the subset of simulated signals that were injected in time intervals that were actually analyzed , and thus approach unity for large amplitudes .",
    ", title=\"fig:\",width=288 ]    each efficiency curve , consisting of the efficiencies determined for a given signal morphology at each of the 22 @xmath25 values , was fitted with an empirical four - parameter function .",
    "the efficiency curves for the logical or combination of the three pipelines and for the combined h1h2 and h1h2l1 networks are shown for selected waveforms in figs .",
    "[ figure : efficiencies_combined_1 ] and  [ figure : efficiencies_combined_2 ] .",
    "the @xmath25 values yielding 50% detection efficiency , @xmath40 , are shown in tables i and ii for sine - gaussians with @xmath38 and for white noise bursts injected and analyzed in h1h2l1 data .",
    "the study of the efficiency for all the waveforms shows that the combination of the methods is slightly more sensitive than the best performing one , which is qpipeline for some of the sine - gaussians , and cwb for all other waveforms considered .",
    ".@xmath25 values yielding 50% detection efficiency , in units of @xmath41 , for different sine - gaussian waveforms and pipelines in the h1h2l1 network .",
    "the first column is the central frequency , the second the quality factor , the third the @xmath40 of the logical or of the pipelines , and the remaining three columns the @xmath40 of the individual pipelines .",
    "these @xmath42 values include an adjustment of 11.1% to take into account calibration and statistical uncertainties as explained in sec .",
    "[ sec : systematics ] . [ cols=\">,>,>,>,>,>\",options=\"header \" , ]     the division into the twelve frequency bands was done using a basebanding procedure .",
    "any calibration lines within the band were removed by low - order regression filtering against the calibration line injection channel data .",
    "a final whitening filter of modest order was applied in each band to satisfy the blocknormal statistic s assumption of gaussianity in the background noise .",
    "the data conditioning procedures also had to minimize mixing noise characteristics between different time periods for the change - point analysis , and thus could not rely on predictive filtering .",
    "the blocknormal algorithm uses a bayesian statistic termed @xmath43 to perform a change - point analysis using the noise characteristics of time - series data . for an interval of @xmath44 time - series samples",
    "@xmath45 $ ] , this statistic measures the statistical likelihood ( at each sample @xmath46 within that interval ) that the data prior to that point are more consistent with a different gaussian - distributed ( or normal ) noise source than are the data following that point .",
    "it is defined as @xmath47\\\\ \\nonumber & & \\times \\left[\\frac{y_{1,k}^{-k/2 } y_{k+1,n}^{-(n - k)/2}}{y_{1,n}^{-n/2}}\\right ] \\left[\\frac{\\gamma(k/2 ) \\gamma((n - k)/2)}{\\gamma(n/2)}\\right]\\end{aligned}\\ ] ] where @xmath48 \\\\ \\overline{x_{i , j}^2 } : = \\frac{1}{j - i+1 } \\sum_{l = i}^{j } x[l]^2 \\,.\\end{aligned}\\ ] ] the quantity @xmath49 is a constant proportional to @xmath50 , where @xmath51 is the prior probability , r the desired rate of blocks , and @xmath52 the sample rate .",
    "in fact each interval is searched for all change - points where @xmath53 exceeds a threshold value @xmath54 , where @xmath54 is implemented as a number times @xmath49 .",
    "the sub - intervals between change - points are termed `` blocks '' .",
    "the statistical significance of each such block is based on its `` excess power '' @xmath55 defined as @xmath56 where the block has mean @xmath57 and variance @xmath58 against a background of mean @xmath59 and variance @xmath60 .",
    "events were selected by requiring the negative - log - likelihood of @xmath55 ( termed @xmath61 ) to exceed a threshold . here",
    "@xmath62)\\ ] ] where @xmath63 = \\gamma(n/2,\\xi^{*}/2)/\\gamma(n/2).\\ ] ]    the variance - weighted time centroid , @xmath64 , of each event of @xmath65 samples of amplitude @xmath66 and time @xmath67 was calculated : @xmath68 the calibrated band - limited strain energy of each event was estimated using the frequency - averaged response @xmath69 over that band : @xmath70 the blocknormal algorithm was applied separately to the data in each frequency band ( table  [ table : freqbands ] ) to select candidate gw burst events .",
    "the burst event generation was done on relatively long - duration epochs ( up to 1200s ) of continuous data to provide the best measure of the background noise characteristics .",
    "prior to the network coincidence step , events within each frequency band that are nearly adjacent were clustered into composite events .",
    "then , events between adjacent frequency bands whose time centroids were close were clustered into composite multiband events .",
    "all events were then characterized by their frequency coverage . for composite events ,",
    "the effective time centroid was the energy - weighted average of the time centroid of the constituent events .",
    "the band - limited energy for composite events was simply the sum of the per - event energies .",
    "the central frequency for events in a single band was estimated by the average frequency of that band .",
    "for multi - band events , the energy - weighted average of these central frequencies was used .",
    "the signals from actual gw bursts in the ligo interferometers should be separated in time by no more than the maximum transit time ( @xmath71ms ) for gw between the hanford and livingston sites . for the co - located interferometers at hanford , there should be no time separation .",
    "the separation observed in the reconstructed events is larger due to limited time resolution , phase - delays in filtering , etc . for a candidate trigger",
    ", the time difference between candidate events in each pair of interferometers , @xmath72 , was required to fall within a fixed coincidence window , @xmath73 , for that pair of interferometers .",
    "this coincidence window had to be much broader than the transit time to account for limited time resolution and skewing of the time distributions from differential antenna response to @xmath74 and @xmath75 waveforms .",
    "the signals from actual gw bursts should also have similar strain amplitude ( and hence statistical significance ) in each interferometer .",
    "we derived a measure of coincident significance from the excess power significance @xmath61 in each candidate event in the trigger .",
    "this measure must correct for the lower significance for gw signals in the shorter h2 interferometer ( as compared to the h1 interferometer ) as well as the fluctuation of the relative gw signal strengths at the two ligo sites due to modulation from the antenna factors .",
    "the chosen metric for coincident significance , termed `` combined power '' or @xmath7 , was defined as @xmath76 this formulation was found to have the best performance in optimizing sensitivity to gw burst signals as a function of the background trigger rate .",
    "the coincidence procedure first identified events from each of the three detectors that had overlapping frequency coverage .",
    "these events then had to have time centroids whose difference @xmath77 was less than @xmath78ms .",
    "such time - coincidence events were retained as gw burst triggers if their combined power @xmath7 was above a threshold of 22 .      the signals from gw bursts in each interferometer result from the same parent waveforms , and thus should have a large correlation sample - by - sample ( after correction for propagation delay ) .",
    "the cross - correlation statistic @xmath8 reported by the corrpower  @xcite package is the maximum of the average correlation confidence of pair - wise correlation tests .",
    "it is positive - definite .",
    "larger values denote greater statistical certainty of coherence .",
    "the corrpower package was run on the list of candidate trigger times produced in the coincidence step .",
    "it retrieved the full time - series data from each interferometer around that time , calibrated the data , and calculated the @xmath8 cross - correlation statistic .",
    "for the three ligo interferometers , cuts were also made on the three pair - wise correlation tests .",
    "additional selection criteria took advantage of the special relationship for gw signals from the co - located interferometers h1 and h2 .",
    "one was the signed correlation factor between the h1 and h2 interferometers from the corrpower processing , termed @xmath79 . for triggers from gw bursts",
    ", this correlation factor should be positive . for triggers from a background of random coincidences",
    ", there should be an equal number of positive and negative correlation factors .",
    "also , since the h1 and h2 interferometers receive the same gw signal , the ratio of @xmath80 to @xmath81 should be close to one for a true gw burst .",
    "in contrast , for triggers from a random background this ratio will be centered around one - half .",
    "this arises because the h2 interferometer is approximately half as sensitive as h1 , so signals of the same statistical significance ( near the threshold ) will have only one - half the amplitude in h2 as they do in h1 . to simplify thresholding ,",
    "the absolute value of the logarithm of the ratio was calculated @xmath82 for later use .",
    "the choices of tuning parameters are described in table  [ tab : tuningcpbn ] .",
    "figure [ fg : tuningbn ] illustrates an example of plots used to tune the figures of merit for the h1h2l1 network .",
    "l + @xmath83 + @xmath84 for @xmath85hz + @xmath86 for @xmath87hz + @xmath88 , @xmath89 , @xmath90 + @xmath91 + @xmath92 +    .",
    "the narrow black histogram represents the background ( noise ) triggers while the broader histogram represents the distribution of the injections .",
    "these triggers were generated in the h1h2l1 network and contain frequencies below 200hz .",
    "the vertical line indicates the cut made on this quantity.,height=226 ]",
    "qpipeline is an analysis pipeline for the detection of gw bursts in data from interferometric gravitational wave detectors  @xcite .",
    "it is based on the q transform  @xcite , a multi - resolution time - frequency transform that projects the data under test onto the space of bisquare - windowed complex exponentials characterized by central time @xmath34 , central frequency @xmath29 , and quality factor @xmath30 :    @xmath93    where the bisquare window @xmath94 is @xmath95 ^ 2    & \\text{for}~\\displaystyle f < \\frac{f_0\\sqrt{5.5}}{q } \\\\    0 & \\text{otherwise }    \\end{array }    \\right.\\ ] ] with @xmath96    the bisquare window is a close approximation to a gaussian window in frequency space ; the qpipeline is effectively a templated matched filter search  @xcite for signals that are gaussian enveloped sinusoids in the whitened signal space .      before applying the q transform",
    ", the data are first whitened by zero - phase linear predictive filtering  @xcite . in linear",
    "predictive whitening , the @xmath65th sample of a discrete data sequence is assumed to be well modeled by a linear combination of the previous @xmath97 samples : @xmath98 = \\sum_{m=1}^{m } c[m ] x[n - m ] \\ , .\\ ] ] the resulting whitened data stream is the prediction error sequence @xmath99 = \\hat{x}[n ] - x[n]$ ] that remains after selecting the coefficients @xmath100 $ ] to minimize the error in the least - squares sense .",
    "the prediction error length @xmath97 is taken to be equal to the length of the longest basis function under test , which is approximately 1 second .",
    "this ensures that the data are uncorrelated on the time scales of the analysis .    in order to avoid introducing phase errors between detectors ,",
    "a modified zero - phase whitening filter is constructed by zero - padding the initial filter , converting to the frequency domain , and discarding all phase information .",
    "the space of gaussian enveloped complex exponentials is an over - complete basis of waveforms , whose duration @xmath101 and bandwidth @xmath102 have the minimum possible time - frequency uncertainty , @xmath103 , where @xmath104 . as a result , they provide the tightest possible constraints on the time - frequency area of a signal , maximizing the measured signal to noise ratio ( snr ) and minimizing the probability that false triggers are coincident in time and frequency between multiple detectors .    in practice ,",
    "the q transform is evaluated only for a finite number of basis functions , which are more commonly referred to as templates or tiles .",
    "these templates are selected to cover a targeted region of signal space , and are spaced such that the fractional signal energy loss @xmath105 due to the mismatch @xmath106 , @xmath107 , and @xmath108 between an arbitrary basis function and the nearest measurement template , @xmath109 is no larger than @xmath110 .",
    "this naturally leads to a tiling of the signal space that is logarithmic in @xmath30 , logarithmic in frequency , and linear in time .    for this search ,",
    "the qpipeline was applied to search the space of sinusoidal gaussians with central frequency from 48hz to 2048hz , and with @xmath30 from @xmath111 to @xmath112 .",
    "the statistical significance of q transform projections are given by their normalized energy @xmath113 , defined as the ratio of squared projection magnitude to the mean squared projection magnitude of other templates with the same central frequency and @xmath30 .",
    "for the case of ideal white noise , @xmath113 is exponentially distributed and is related to the matched filter snr quantity @xmath9  @xcite by the relation @xmath114 = \\rho^2 / 2 \\ , .",
    "\\label{zdef}\\ ] ]    the q transform is applied to the whitened data and normalized energies are computed for each measurement template as a function of time",
    ". templates with statistically significant signal content are then identified by applying a threshold on the normalized energy . finally ,",
    "since a single event may potentially produce multiple overlapping triggers due to the overlap between measurement templates , only the most significant of overlapping templates are reported as triggers .",
    "clustering of nearby triggers is not used in evaluating the significance of events . as a result , the detectability of gw burst signals depends on their maximum projection onto the space of gaussian enveloped sinusoids .      for this search ,",
    "the qpipeline took advantage of the co - located nature of the two ligo hanford detectors to form two linear combinations of the data streams from the two detectors .",
    "this coherent analysis makes use of correlations in the data to distinguish true gw signals from instrumental glitches .",
    "the first combination is the coherent signal stream , @xmath11 , a frequency dependent weighted sum of the data from the hanford detectors which maximizes the effective snr .",
    "the weighting is inversely proportional to the noise power spectral density , @xmath115 :    @xmath116    the resulting combination is treated as the output of a new hybrid , `` coherent '' detector . under the assumption that the power spectral density is approximately flat across the window bandwidth , applying the q transform to this data stream leads to a coherent energy value , @xmath117 , which takes the following form : @xmath118 where @xmath119 , @xmath120 , and @xmath121 are functions of @xmath34 , @xmath29 , and @xmath30 , and the asterisk denotes complex conjugation .",
    "the last term represents the contribution of the cross - term , and is conceptually similar to a frequency domain representation of a cross - correlation of the h1 and h2 data streams .",
    "the energy expected in the coherent data stream if there were no correlations in the data can be characterized by the `` incoherent '' terms in eq .",
    "( [ cohdef ] ) : @xmath122 the coherent and incoherent energies can then be normalized in the manner of eq .",
    "( [ zdef ] ) : @xmath123 the correlation between the detectors can then be measured by the correlated energy , @xmath124 , given by @xmath125      the second combination is the difference between the calibrated data from the two detectors , known as the null stream , and is defined as @xmath126 by subtracting the co - located streams , any true gravitational wave signal should be canceled .",
    "the resulting combination is treated as the output of a new hybrid `` @xmath12 '' detector , which shows significant energy content in the presence of instrumental glitches but does not respond to gravitational waves .",
    "glitches are identified by thresholding on the corresponding normalized `` null energy '' , @xmath127 , calculated in an analogous manner to @xmath128 .",
    "signal tiles found to be in coincidence with significant null stream tiles are vetoed as instrumental glitches , and are not considered as candidate events .",
    "the threshold on @xmath127 can be expressed as @xmath129 where @xmath130 is chosen to limit the veto rate in gaussian noise to @xmath131 per 2048 tiles and @xmath51 is a parameter corresponding to the allowed tolerance in calibration uncertainty .",
    "this is an energy factor , and corresponds to an amplitude calibration uncertainty of approximately 22 percent .",
    "we expect that highly energetic instrumental glitches could leak energy into adjacent time - frequency bins , so the veto coincidence requirement between signal and null streams is scaled to give more - significant null stream tiles more area of veto influence in time - frequency space : @xmath132 @xmath133 where @xmath34 and @xmath29 are the central time and frequency of a tile , @xmath106 and @xmath134 are the duration and bandwidth of a tile , and the inflated null stream tile duration and bandwidth are defined as : @xmath135 @xmath136      coherent triggers from the two ligo hanford detectors were also tested for time - frequency coincidence with triggers from the ligo livingston detector using the following criteria , where @xmath137 is the speed of light travel time of 10ms between the two ligo sites : @xmath138 @xmath139    coincidence between the ligo hanford and livingston sites is not a requirement for detection , even if detectors at both sites are operational .",
    "the final trigger set is the union of triggers from the coherent h1h2 trigger set and the coincident h1h2l1 trigger set .",
    "the additional requirement of coincidence permits a lower threshold , and therefore greater detection efficiency , for the h1h2l1 data set .",
    "the choices of tuning parameters are described in table  [ tab : tuningq ] .",
    "figure [ fg : tuningq ] an example scatter plot used to tune the figures of merit for the h1h2l1 network .    @cll@c + & @xmath140 & & + & @xmath141{\\frac{12.5}{z_{\\text{l1}}}}\\right)$ ] & for @xmath85hz & + & @xmath142 & for @xmath87hz & + & @xmath143 & & +   + & @xmath140 & & + & @xmath144 & for @xmath85hz & + & @xmath145 & for @xmath87hz &    , [ defined in eq .",
    "( [ cor_energy ] ) ] , which measures the correlation of the strain at the two hanford interferometers , versus the l1 normalized energy [ defined in eq .",
    "( [ zdef ] ) ] .",
    "the distribution of the background triggers is displayed in black while the distribution of simulated gw signals in gray .",
    "this example tuning plot is for triggers generated for the h1h2l1 network and containing frequencies below 200hz .",
    "the cuts on these quantities are displayed on the plot as thick lines .",
    ", height=226 ]",
    "coherent waveburst ( cwb ) is an analysis pipeline for the detection and reconstruction of gw burst signals from a network of detectors .",
    "the reconstructed gravitational waveform @xmath146 that best describes the response of the network is used to compute the maximum likelihood ratio of the putative gw signal , which forms the main detection statistic for the search . in effect , cwb is equivalent to a matched filter search with a very large template bank representing all possible time - domain signals with short duration .",
    "the cwb pipeline is divided into three main stages : the generation of coherent triggers , the reconstruction of the gw signal and the computation of the maximum likelihood ratio , and a post - production stage where additional detection cuts are applied . by using weighted coherent combinations of the data streams ,",
    "cwb is not limited by the least sensitive detector in the network .",
    "the waveform reconstruction allows various physical properties of the signal to be estimated , including the sky location of the source .",
    "the coherent approach also allows for other statistics to be constructed , such as the null stream and coherent energy , to distinguish genuine gw signals from environmental and instrumental artifacts .",
    "the cwb analysis is performed in the wavelet domain .",
    "a discrete meyer wavelet transformation is applied to the sampled detector output to produce a discrete wavelet series @xmath147 $ ] , where @xmath148 is the time index , @xmath149 is the scale index and @xmath46 is the detector index .",
    "an important property of meyer wavelets is that they form an orthonormal basis that allow for the construction of wavelet filters with small spectral leakage  @xcite .",
    "wavelet series give a time - scale representation of data where each wavelet scale can be associated with a certain frequency band of the initial time series .",
    "therefore a wavelet time - scale spectrum can be displayed as a time - frequency ( tf ) scalogram , where the scale is replaced with the central frequency @xmath150 of the band .",
    "the time series sampling rate @xmath151 and the scale number @xmath149 determine the time resolution @xmath152 at this scale .",
    "the frequency resolution @xmath153 is defined as @xmath154 and determines the data bandwidth at the scale @xmath149 .",
    "the time - frequency resolution defines the tiling of the tf plane .",
    "the individual tiles ( pixels ) represent data samples in the wavelet domain . in the cwb pipeline",
    "a uniform tiling is used @xmath155 , where @xmath65 is the wavelet decomposition depth ) , which is obtained with the meyer packet transformation  @xcite . in this case",
    "the tf resolution is the same for all wavelet scales . for optimal localization of the gw energy in the tf plane ,",
    "the cwb analysis is performed at six different frequency resolutions : 8 , 16 , 32 , 64 , 128 and 256 hz .    before the coherent analysis is performed , two data conditioning algorithms",
    "are applied to the data in the wavelet domain : a linear prediction error ( lpe ) filter and a wavelet estimator of the power spectral density @xmath156 $ ] .",
    "lpe filters are used to remove `` predictable '' components from an input data series . in the cwb pipeline",
    "they are constructed individually for each wavelet layer and remove such components in the data as power line harmonics and violin - mode lines .",
    "a more detailed description of the lpe filters can be found elsewhere  @xcite .",
    "the wavelet estimator of the one - sided power spectral density associated with each wavelet layer @xmath149 is @xmath157 = 2\\frac{\\sigma^2_k[j]}{r}\\ ] ] where @xmath158 $ ] is the variance of the detector noise . in the analysis",
    "we assume that the detector noise is gaussian and quasi - stationary .",
    "the variance estimator may vary with time and therefore it is calculated for each sample in the wavelet layer : @xmath159 $ ] .",
    "the estimation of the noise variance is performed on data segments of length 60 seconds , with 40 seconds overlap .",
    "linear interpolation is used between two measurements to obtain @xmath159 $ ] .",
    "the first step in the analysis is to identify segments of data that may contain a signal .",
    "the triggers are evaluated using the whitened data vector @xmath160 $ ] @xmath161(\\theta,\\phi ) = \\left ( \\frac{a_1[i , j,\\tau_1(\\theta,\\phi)]}{\\sigma_1[i , j ] } , .. , \\frac{a_k[i , j,\\tau_k(\\theta,\\phi)]}{\\sigma_k[i , j ] } \\right ) \\;.\\ ] ] the sampled detector amplitudes in the wavelet domain @xmath162 $ ] take into account the time delays @xmath163 due to the time - of - flight between the detectors , which in turn depend on the source coordinates @xmath164 and @xmath165 .",
    "coherent triggers are generated for the entire network by maximizing the norm @xmath166|$ ] over the entire sky for each time - frequency location @xmath167 $ ] .",
    "to do this , the sky is divided into square degree patches and the quantity @xmath168 is calculated for each patch from the delayed detector amplitudes @xmath169 $ ] . by selecting clusters of pixels with the @xmath170 above some threshold , one can identify coherent triggers in the time - frequency plane .",
    "the data pixels @xmath171 $ ] selected by this procedure are then used to reconstruct the gw signal and compute the maximum likelihood statistic .",
    "for the case of gaussian quasi - stationary noise , the likelihood that data @xmath172 is purely instrumental noise is proportional to @xmath173 , while the likelihood that a gw signal @xmath146 is present is proportional to @xmath174 .",
    "the ratio of these likelihoods can be used as a detection statistic . here",
    "@xmath175 defines a noise weighted inner product , which for @xmath176 detectors with uncorrelated noise can be written in the wavelet domain as @xmath177 y_k[i , j]}{\\sigma^2_k[i , j ] } \\ , .\\ ] ] where time @xmath148 and frequency @xmath149 indices run over some time - frequency area @xmath178 selected for the analysis .",
    "the coherent waveburst pipeline defines @xmath179 as twice the ( log ) likelihood ratio , and treats it as a functional in @xmath180  @xcite : @xmath181 = 2(a \\vert h_{\\text{det}})- ( h_{\\text{det } } \\vert h_{\\text{det } } ) \\ , , \\ ] ] where @xmath182 $ ] are the detector responses ( eq .",
    "[ eq : hdet ] ) .",
    "the network sensitivity is characterized by the noise - scaled antenna pattern vectors @xmath183 and @xmath184 : @xmath185 =   \\left ( \\frac{f_{1,+(\\times)}(\\vec\\omega , \\psi ) } { \\sigma_1[i , j]}, .. ,\\frac{f_{k,+(\\times)}(\\vec\\omega , \\psi)}{\\sigma_k[i , j ] } \\right ) \\;.\\ ] ] since the detector responses @xmath186 are independent of rotation by an arbitrary polarization angle in the wave frame , it is convenient to perform calculations in the dominant polarization frame ( dpf )  @xcite . in this frame",
    "the antenna pattern vectors @xmath183 and @xmath184 are orthogonal to each other : @xmath187 and we refer to them as @xmath188 and @xmath189 respectively .",
    "the corresponding solutions for the gw waveforms , @xmath190 and @xmath191 , are found by variation of the likelihood functional ( eq .  ( [ eq : like ] ) ) that can be written as the sum of two terms , @xmath192 , where @xmath193   \\ ; , \\\\ \\label{eq : like2 } { \\cal{l}}_2 =   \\sum_{\\omega_{tf } } \\left [ 2({\\bf{w}}\\cdot{\\bf{f_2 } } ) h_2 - |{\\bf{f_2}}|^2 h^2_2 \\right ]   \\;. \\end{aligned}\\ ] ]",
    "the estimators of the gw waveforms for a particular sky location are then the solutions of the equations @xmath194 and @xmath195 : @xmath196 note , the norms @xmath197 and @xmath198 characterize the network sensitivity to the @xmath190 and @xmath199 polarizations respectively .",
    "the maximum likelihood ratio statistic for sky location @xmath200 is calculated by substituting the solution for @xmath146 into @xmath201 $ ] .",
    "the result can be written as @xmath202 where the matrix @xmath203 is the projection constructed from the components of the unit vectors @xmath204 and @xmath205 along the directions of the @xmath188 and @xmath189 respectively : @xmath206 the kernel of the projection @xmath203 is the _ signal _ plane defined by these two vectors .",
    "the null space of the projection @xmath203 defines the reconstructed detector noise which is referred to as the null stream .",
    "the projection matrix is invariant with respect to the rotation in the signal plane where any two orthogonal unit vectors can be used for construction of the @xmath207",
    ". therefore one can select vectors @xmath208 and @xmath209 such that @xmath210 and @xmath211 the unit vector @xmath208 defines the vector @xmath212 whose components are estimators of the noise - scaled detector responses @xmath182/\\sigma_k[i , j]$ ] .      in principle",
    "the likelihood approach outlined above can be used for the reconstruction of the gw waveforms and calculation of the maximum likelihood statistic . in practice the formal solutions ( [ eq : syst1 ] ) , ( [ eq : syst2 ] ) need to be regularized by constraints that account for the way the network responds to a generic gw signal  @xcite . for example , the network may be insensitive to gw signals with a particular sky location or polarization , resulting in an ill - posed inversion problem .",
    "these problems are addressed by using regulators and sky - dependent penalty factors .",
    "a classical example of a singular inversion problem is a network of aligned detectors where the detector responses @xmath186 are identical . in this case",
    "the algorithm can be constrained to search for one unknown function rather than for the two gw polarizations @xmath190 and @xmath191 , which span a larger parameter space .",
    "note that in this case @xmath213 , eq .  ( [ eq : syst2 ] ) is ill - conditioned and the solution for the @xmath191 waveform can not be found .",
    "regulators are important not only for aligned detectors , but also for networks of misaligned detectors , for example , the ligo and virgo network . depending on the source location",
    ", the network can be much less sensitive to the second gw component ( @xmath214 ) and the @xmath191 waveform may not be reconstructable from the noisy data .    in the coherent waveburst analysis",
    "we introduce a regulator by modifying the norm of the @xmath189 vector : @xmath215 is a tunable parameter .",
    "for example , if @xmath216 , the second gw component is entirely suppressed and the regulator corresponds to the `` hard constraint '' described in ref .",
    "@xcite . in this case the unit vector @xmath208 ( see eq .  ( [ eq : u ] ) ) is pointing along the @xmath183 direction . in the cwb analysis",
    "the parameter @xmath217 is chosen to be @xmath218 } } \\,.\\ ] ] this regulator is more stringent for weak events which are generated by the pipeline at much higher rate than the loud events .",
    "the introduction of the regulator creates an obvious problem for the construction of the projection matrix .",
    "namely , the vector @xmath219 and the corresponding vector @xmath220 obtained by rotation of @xmath204 and @xmath221 in the signal plane are not unit vectors if @xmath222 . to fix this problem we re - normalize the vector @xmath220 to unity and use it for calculation of the maximum likelihood ratio and other coherent statistics .",
    "when the detector noise is gaussian and stationary , the maximum likelihood @xmath223 is the only statistic required for detection and selection of the gw events . in this case",
    "the false alarm and the false dismissal probabilities are controlled by the threshold on @xmath223 which is an estimator of the total snr detected by the network . however , the real data are contaminated with instrumental and environmental artifacts and additional selection cuts should be applied to separate them from genuine gw signals  @xcite . in the coherent waveburst method",
    "these selection cuts are based on coherent statistics constructed from the elements of the likelihood and the null matrices .",
    "the diagonal terms of the matrix @xmath224 describe the reconstructed normalized incoherent energy .",
    "the sum of the off - diagonal terms is the coherent energy @xmath225 detected by the network .",
    "the next step is to optimize the solution over the sky .",
    "often , depending on the network configuration , the reconstruction of source coordinates is ambiguous . for example , for two separated detectors the relative time delay that yields maximum correlation between the data streams corresponds to an annulus on the sky . in this case , an `` optimal '' source location is selected , where the reconstructed detector responses are the most consistent with the output detector data streams . to properly account for the directional sensitivity of the network the optimization over sky locations has to be more than a simple maximization of @xmath226 . in the cwb analysis",
    "the statistic that is maximized has the form @xmath227 where @xmath16 is the penalty factor and @xmath228 is the network correlation coefficient . @xmath16 and",
    "@xmath228 are defined below in terms of the matrix @xmath229 and the diagonal matrices @xmath230 and @xmath231 which describe the normalized energy in the detectors , and the normalized reconstructed signal energy ( see eq .",
    "( [ eq : xi ] ) ) , with @xmath232    ideally , the reconstructed signal energy in each detector @xmath233 should not significantly exceed the energy @xmath234 .",
    "this requirement can be enforced by the constraint @xmath235 for each detector in the network .",
    "these constraints can be applied during the signal reconstruction by way of lagrange multipliers in the variational analysis , however this greatly increases the computational complexity of the algorithm .",
    "a simpler alternative is to introduce a penalty factor @xmath16 that penalizes sky locations violating the constraint equation  ( [ eq : ed ] ) : @xmath236 in addition to serving as a penalty factor in the position reconstruction , the ratio of reconstructed and detector energy were also used as a post - production cut .",
    "events with @xmath237 were discarded , as were events with large values of the network energy disbalance @xmath238 and the h1-h2 energy disbalance @xmath239 the latter cut was found to be particularly effective at rejecting correlated glitches in the two hanford interferometers .    the network correlation coefficient is also used to weight the overall likelihood for each sky location .",
    "it is defined as @xmath240 where @xmath241 is the sum of all elements in the null matrix @xmath242 which represents the normalized energy of the reconstructed noise . usually for glitches",
    "little coherent energy is detected and the reconstructed detector responses are inconsistent with the detector output , which results in a large value for the null energy .",
    "in addition to helping select the optimal sky location , the correlation coefficients @xmath228 are used for a signal consistency test based on the comparison of the null energy and the coherent energy .",
    "the coherent terms of the likelihood matrix can be also used to calculate the correlation coefficients @xmath243 which represent pearson s correlation coefficients in the case of aligned detectors .",
    "we use the coefficients @xmath244 to construct the reduced coherent energy @xmath245 combined with the network correlation coefficient @xmath228 and the number of detectors in the network , @xmath176 , it yields a quantity which we call the _ coherent network amplitude _ , @xmath246 figure  [ fg : tuningcwb ] shows the @xmath17@xmath13 distribution of the background events ( see sec .",
    "[ sec : tuning ] ) and simulated gw events ( see sec .  [",
    "sec : simulations ] ) for the l1h1h2 network .",
    "loud background events due to detector glitches with low values of the network correlation coefficient are rejected by a threshold on @xmath228 .",
    "relatively weak background events are rejected by a threshold on @xmath17 .",
    "table  [ tab : tuningcwb ] describes the full set of tuning parameters for cwb .",
    "l + @xmath247 , @xmath248 + @xmath249 for @xmath150@xmath250@xmath251 hz , up to dec 12 2005 03:19:29 +   + @xmath252 for @xmath150@xmath250@xmath251 hz , between dec 12 2005 03:19:29 +   + @xmath253 for @xmath150@xmath254@xmath251 hz + @xmath255 , @xmath256 +   + @xmath257 , @xmath248 + @xmath249 for @xmath150@xmath250@xmath251 hz + @xmath258 for @xmath150@xmath254@xmath251 hz , up to jul 17 2006 11:50:37 + @xmath253 for @xmath150@xmath254@xmath251 hz , after jul 17 2006 11:50:37 + @xmath255 , @xmath256 +   + @xmath247 , @xmath248 + @xmath259 for @xmath150@xmath250@xmath251 hz , up to oct 07 2006 08:58:06 + @xmath260 for @xmath150@xmath250@xmath251 hz , after oct 07 2006 08:58:06 + @xmath261 for @xmath150@xmath254@xmath251 hz + @xmath256 +   + @xmath247 , @xmath248 + @xmath259 for @xmath150@xmath250@xmath251 hz , up to mar 28 2006 04:23:06 +   + @xmath261 for @xmath150@xmath250@xmath251 hz , between mar 28 2006 04:23:06 +   + @xmath261 for @xmath150@xmath254@xmath251 hz + @xmath256 +"
  ],
  "abstract_text": [
    "<S> we present the results obtained from an all - sky search for gravitational - wave ( gw ) bursts in the 642000hz frequency range in data collected by the ligo detectors during the first year ( november 2005  </S>",
    "<S> november 2006 ) of their fifth science run.the total analyzed livetime was 268.6 days . </S>",
    "<S> multiple hierarchical data analysis methods were invoked in this search . </S>",
    "<S> the overall sensitivity expressed in terms of the root - sum - square ( rss ) strain amplitude @xmath0 for gravitational - wave bursts with various morphologies was in the range of @xmath1  to a few @xmath2 . </S>",
    "<S> no gw signals were observed and a frequentist upper limit of 3.75 events per year on the rate of strong gw bursts was placed at the 90% confidence level . as in our previous searches , we also combined this rate limit with the detection efficiency for selected waveform morphologies to obtain event rate versus strength exclusion curves . in sensitivity , these exclusion curves are the most stringent to date . </S>"
  ]
}