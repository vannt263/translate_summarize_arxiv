{
  "article_text": [
    "the great importance of the foreground problem for cmb studies has long been recognized in the cosmological community , and as a result a large number of algorithms have been proposed , implemented and applied to both simulated and real data .",
    "examples are the maximum entropy method @xcite , internal linear combination methods @xcite , wiener filtering @xcite , independent component analysis methods @xcite and spectral fitting approaches @xcite .    the main emphasis of most of these methods lies on establishing an optimal estimate of the cmb sky signal , and not so much on quantifying the uncertainty on that estimate .",
    "a different approach was taken by @xcite who simply adopted well - established likelihood parameter estimation techniques to solve the problem .",
    "ten years later this work was continued by @xcite , by taking advantage of recent statistical ( in particular markov chain monte carlo ) and computational developments .    in this paper",
    "we briefly review the algorithm as presented by @xcite .",
    "we then describe three applications , namely 1 ) an analysis of simulated planck + six - year wmap data , 2 ) a preliminary analysis of the first - year wmap data , and 3 ) a preliminary study of experimental design .",
    "the most straightforward method for producing reliable error bars is provided by standard parameter estimation techniques . in particular , the bayesian framework is particularly suited for this type of problem .    given a set of observed data @xmath2 and an assumed model @xmath3 , @xmath4 being a general set of parameters , we simply ask , what is the posterior distribution @xmath5 ? to answer this , we first recall bayes formula , @xmath6 where @xmath7 is the likelihood and @xmath8 is a prior summarizing our previous knowledge about @xmath4 . for gaussian data ,",
    "the likelihood is given by @xmath9^t \\mathbf{c}^{-1 } \\left[\\mathbf{d } -    \\mathbf{s}(\\theta)\\right],\\ ] ] where @xmath10 is the covariance matrix , up to an irrelevant constant .",
    "( in the current implementation , we assume no pixel - pixel correlations , and @xmath11 is defined to be the noise covariance matrix . )",
    "the problem is thus reduced to mapping out the posterior as a function of the free parameters @xmath4 using some computational tool , such as mcmc or grid evaluations .",
    "this machinery may be applied to microwave component reconstruction by noting that different signal components have different spectral and spatial behaviour . by observing the sky in different frequencies and directions",
    "one may disentangle the various contributions and isolate the cmb signal .",
    "the first step is therefore to choose a suitable parametric model . for cmb analysis ,",
    "a particularly convenient choice is that of a sum of independent modulated power - law components , @xmath12 here one typically would include a cmb term ( @xmath13 ; @xmath14 is the thermodynamic - to - antenna temperature conversion factor ; @xmath15 ) , a synchrotron and free - free term ( @xmath16 and/or @xmath17 free parameters ; @xmath18 ) , and a thermal dust term .",
    "these few simple definitions summarize the method quite succinctly .",
    "no a priori assumptions about the sky emission are required , except that it can be represented by a parametric model .",
    "the remaining discussion is concerned mostly about how to deal with real - world complications such as limited spectral information , low signal - to - noise ratio , and computational constraints .",
    "it is worth emphasizing that even an unrealistically simple sky model containing nothing but cmb , free - free , synchrotron , and dust emission requires at least six parameters , and that no cmb experiment to date has had even the eight frequencies required to fit such a minimal model .",
    "fortunately , the method can be extended easily to include other information , as will be seen in the next section .",
    "two major complications arise when trying to apply the above machinery to real - world data .",
    "first , spectral fits generally require that all sky maps are properly calibrated with respect to a common zero - point .",
    "this is not trivial for any cmb experiment , and certainly not for differential observatories such as the wmap satellite .",
    "second , as previously mentioned , the number of observed frequencies is often ( i.e. , in every experiment performed to date ! ) smaller than the number of parameters one might wish to include .",
    "for instance , wmap observes the sky at five frequencies , while , ideally , we would like to include at least six parameters in a reasonable model ( cmb , synchrotron , free - free and thermal dust amplitudes , and synchrotron and dust spectral indicies ) , still neglecting a possible anomalous dust contribution .",
    "a straightforward way to address both problems is to introduce template terms in the signal model , @xmath19 that is , in addition to the previously defined ( and usually rather complicated ) spectral models , we also fit for a small set of global ( and simple ) template amplitudes .",
    "common templates to include would be a monopole term , three dipole terms , and either reasonably well - behaved ( e.g , .",
    "free - free emission through an h@xmath20 template ) or sub - dominant ( e.g. , thermal dust emission for wmap ) foreground components . for each signal component one is able to handle this way , one saves one degree of freedom in all subsequent non - linear fits , thus obtaining very useful additional stability .",
    "the cost of this approach is that the problem becomes global , and the computational load is vastly increased . at present it",
    "is therefore only feasible to perform such an analysis at low resolution and with a non - linear search .",
    "nevertheless , since the main target at this stage is a relatively small number of global template amplitudes , little is lost by this approach .",
    "note that this extension of the method was discussed only briefly by @xcite in the context of monopole and dipole calibration , not general template fits , and it was also not implemented at that time .",
    "the analysis of the first - year wmap data presented in this paper is therefore the first application of the method .",
    "after calibrating and removing well - behaved components from the maps using the above description , the next step is to map out the full posterior for each pixel with low - resolution maps .",
    "the reasons for using low - resolution maps at this stage are two - fold : on the one hand , estimation of non - linear parameters such as spectral indices is quite sensitive to noise , and it is therefore highly desirable to have high signal - to - noise data .",
    "on the other hand , we use full - blown mcmc to map out the posteriors for each pixel , and with a computational cost of about 100 cpu - seconds per pixel it is currently not feasible to do this for mega - million pixel maps .    for these two reasons ,",
    "we smooth each map with a wide beam ( typically with a gaussian beam of , say , @xmath21 fwhm ) and downgrade the pixel resolution ( typically to , say , @xmath22 pixel size ; @xmath23 in healpix language ) prior to the mcmc analysis .",
    "the computational expense is then quite manageable with a modern - type cluster , with a total cost of about 500 cpu hours .",
    "the final product from this stage is a single joint probability distribution for each pixel , and from these we find the univariate distributions for each parameter by marginalizing over all others .",
    "examples of such univariate distributions are shown in figure [ fig : onedim_dist ] .",
    "finally , we store the posterior mean and variance for each parameter and each pixel in the form of two sky maps as our final data products .",
    "while the procedure described in the previous section gives a full representation of the posteriors for the low - resolution sky maps , we also want a good representation of the full - resolution posteriors . to obtain these , we make the assumption that the spectral indices vary more slowly than the amplitudes , and fix their distributions at the corresponding low - resolution values .",
    "_ given _ the values of all non - linear parameters , the likelihood becomes gaussian , and the analysis may be performed analytically with modest computational expenses . for details on this procedure , see @xcite .",
    "in the following sections , we show a few demonstrations of how this method performs in practice . first , we review the simulation described by @xcite .",
    "we then show the results from a preliminary analysis of the first - year wmap data .",
    "we emphasize that these results are preliminary , and will be revised with the currently available three - year data .",
    "finally , we show some early results from a currently on - going study of optimization of future experiments .      in order to test the algorithm , @xcite constructed a simulation corresponding to a combination of six planck channels ( 30 to 217 ghz ) and five wmap channels ( 23 to 94 ghz ) .",
    "the higher - frequency planck channels were not included because of modelling error confusion associated with including multiple dust components .",
    "the simulation took into account the beam and white noise characteristics of each channel separately .",
    "four signal components were included : a gaussian cmb realization drawn from the best - fit wmap @xmath24cdm power spectrum ; a semi - realistic synchrotron component , featuring a spatially varying spectral index @xcite ; a free - free component with fixed spectral index of @xmath25 @xcite ; and a two - component thermal dust model ( `` model 8 '' of finkbeiner et al .",
    "thus , the simulation includes two major complications that we must expect to find in real data , namely both spatially varying spectral indices and departures from simple power law spectra .",
    "three selected channel maps are shown in figure [ fig : simulation ] .",
    "these simulations were then analyzed using the machinery described above .",
    "the results are discussed in detail in the original paper ; two sample results are reprinted here . in figure",
    "[ fig : onedim_dist ] we show the marginal densities for one single pixel located exactly on the galactic plane , and the true values for each parameter is marked by a solid line . clearly , the posterior distributions agree very well with the input values , both in mean and variance .    in figure [",
    "fig : sim_fullres ] we show sky maps of the four component amplitudes that were estimated : posterior means are shown in the left column , actual residuals are shown in the middle column , and estimated errors are shown in the right column . again , the results agree very well with expectations .      in this section",
    "we present for the first time the results from a parametric foreground analysis of the first - year wmap data @xcite .",
    "these data comprise a set of full - sky temperature maps at five frequencies ( 23 , 33 , 41 , 61 and 94 ghz ) at angular resolutions between @xmath26 and @xmath27 fwhm .",
    "the noise is assumed to be white , and all beams are assumed to be circularly symmetric .",
    "as described above , the analysis was performed in three stages , two at low resolution ( @xmath21 fwhm for wmap ) , and the third at high resolution ( @xmath28 ) . in the first or calibration stage ,",
    "the free parameters were a monopole and dipole amplitude , a free - free template amplitude @xcite , and a dust template amplitude @xcite for each band , and a cmb temperature and a synchrotron amplitude and spectral index for each pixel .",
    "the fit was performed using a non - linear sequential quadratic programming ( sqp ) algorithm .    in the second stage ,",
    "the low - resolution posterior distributions are mapped out using .",
    "only cmb and synchrotron ( both amplitude and spectral index ) were included in this case .",
    "the main result from these computations is a synchrotron spectral index map , shown in the bottom panel of figure  [ fig : wmap1 ] .",
    "note that the most values lie between @xmath29 and @xmath30 , which is quite acceptable .",
    "( values larger than @xmath31 probably indicate residual free - free emission , rather than break - down in the synchrotron estimation . )    in the third stage , we estimate the cmb and synchrotron amplitudes analytically .",
    "the results from these calculations are shown in the two panels of figure  [ fig : wmap1 ] .",
    "( the synchrotron amplitude is normalized to k band . ) again , the results appear visually quite compelling , although a more quantitative analysis is warranted .",
    "however , we re - emphasize that these results are presented only to demonstrate the capabilities of the method , and not as definitive measurements .",
    "the analysis will soon be revisited based on the recently available three - year wmap data .",
    "the machinery described in section [ sec : algorithms ] is also very well suited to study optimization of future experiments .",
    "the question we want to answer is , given a set of instrumental constraints ( e.g. , focal plane area and power dissipation ) how should we distribute the number of detectors as a function of frequency in order to optimize our ability to extract the cmb signal",
    "?    one possible method for answering this question would be to apply the above machinery to a wide range of allowed instrument configurations , and study how the uncertainties ( or residuals ) change with configuration . in a currently on - going project",
    ", we try to do this in a systematic fashion , and in this section we present some very preliminary results from this study .    we consider a generalized version of the simulations described in section  [ sec : simulation ] , for which the frequency bands and the noise rms per frequency may be chosen freely .",
    "we then impose a set of constraints corresponding to the focal plane area of an optical system that could fly in space , and feeds at different frequencies of realistic size .",
    "based on these constraints , we generate a grid of possible instrument configurations , and run the analysis for a reasonable set of these .",
    "( most may be discarded by common sense . )",
    "a few example results are shown in figure [ fig : expdesign ] : the lines indicate the noise rms distribution as a function of frequency ( @xmath32 , where @xmath33 is the number of detectors at frequency @xmath34 ) for seven different configurations . the thickness ( and color ) of the lines",
    "indicates the resulting uncertainty / residual from the component separation : a thicker ( redder ) line means a better reconstruction .",
    "the optimal distribution of detectors among this set is therefore the solid red line .    from this simple exercise ,",
    "we may formulate a first design principle : _ the optimal noise distribution is the one that corresponds to a constant signal - to - noise ratio , where the signal is the sum of cmb and foregrounds . _",
    "second , the wider the frequency coverage , the better the reconstruction .",
    "however , there is a major caveat here : this principle only holds when any modelling errors ( i.e. , errors due to the fact that the assumed parametric model is different from the true signal ) are small . performing a similar exercise on simulations with significant modelling errors results in a competing principle : _ when the parametric shape of the foreground components are poorly known , the best reconstructions are obtained with configurations surrounding the foreground minimum . _",
    "the optimal total frequency span depends on the magnitude of the modelling errors .",
    "both of these principles sound rather obvious , but they are nevertheless worth making explicit .    in conclusion ,",
    "two competing effects are at work : reconstruction power is maximized by a wide frequency coverage , but limited by modelling errors . in a future publication , we will quantify these considerations in much greater detail , and attempt to provide some guidelines on the preferred frequency ranges for future cmb experiments .",
    "firm conclusions , however , will require an understanding of modelling errors based on better knowledge of the foregrounds themselves , knowledge that can come only from measurements of the polarized sky over a broad range of frequencies with great sensitivity .",
    "as the sensitivity of cmb observations continue to improve , the importance of properly characterizing the foreground contributions also increases .",
    "even with wmap we are already at a level where instrumental noise is negligible compared to the foreground uncertainties over a wide range of angular scales @xcite , and this will be even more true for planck and up - coming polarization experiments .",
    "simple template corrections will be hopelessly inadequate to reach the required sensitivity levels .",
    "further , it will be essential to propagate the foreground uncertainties through to the final products , namely the cmb power spectrum and cosmological parameters .    on this background ,",
    "we argue that the most appropriate solution will be based on traditional parameter estimation techniques , rather than image processing techniques .",
    "the reason is simply that such methods naturally provide the full posterior distributions , and are integrated easily with existing power spectrum and parameter estimation methods based on bayesian parameter estimation .",
    "an approach that appears particularly promising in this respect is that of gibbs sampling , which allows for joint global analysis of foregrounds , cmb power spectrum and even cosmological parameters @xcite .",
    "in fact , we end by emphasizing that the particular implementation we describe in this paper is of less importance than its underlying idea",
    ". many improvements can be made to the algorithm as such ( e.g. , introducing support for spatial correlation information would be of great value ) , but our main conclusion is independent of such details : cmb component separation is a probabilistic problem , and obtaining accurate uncertainties is a crucial part of the problem .",
    "parameter estimation techniques provide the most direct route for doing so ."
  ],
  "abstract_text": [
    "<S> the quality of cmb observations has improved dramatically in the last few years , and will continue to do so in the coming decade . over a wide range of angular scales , the uncertainty due to </S>",
    "<S> instrumental noise is now small compared to the cosmic variance . </S>",
    "<S> one may claim with some justification that we have entered the era of precision cmb cosmology . </S>",
    "<S> however , some caution is still warranted : the errors due to residual foreground contamination in the cmb power spectrum and cosmological parameters remain largely unquantified , and the effect of these errors on important cosmological parameters such as the optical depth @xmath0 and spectral index @xmath1 is not obvious . </S>",
    "<S> a major goal for current cmb analysis efforts must therefore be to develop methods that allows us to propagate such uncertainties from the raw data through to the final products . </S>",
    "<S> here we review a recently proposed method that may be a first step towards that goal .    </S>",
    "<S> cosmic microwave background , cosmology : observations , methods : numerical </S>"
  ]
}