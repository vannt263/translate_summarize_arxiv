{
  "article_text": [
    "during the last decade , most websites are providing the information generated from the structured data in an underlying database through certain predefined templates or layouts . following the great number of web pages available on the net ,",
    "these semi - structured web sources contain rich and unlimited valuable data for a variety of purposes . extracting those data and then rebuilding them into a structured database are a challenge to realize an automatic data mining from web sources .",
    "several methods for these purposes have been proposed previously in the literature .",
    "some of them can be classified as the so - called wrappers , for instance @xcite , and have been briefly surveyed in @xcite .",
    "the wrapper technique allows an automatic data extraction through predefined wrapper created for each target data source .",
    "the wrappers then accepts a quesry against the data source and returns a set of structured results to the calling application .    on the other hand ,",
    "there are several automatic methods without a manual initial learning process .",
    "for example , some methods are generating a template automatically from first multiple pages before extracting the rest of data based on the template @xcite .",
    "a more comprehensive method without requiring multiple pages has also been proposed using a page creation model which captures the main characteristics of semi - structured web pages to derive the set of properties @xcite .",
    "though , the last method is more intended to extract the lists of data records from a single web page with sibling subtrees .",
    "recently we have worked on extracting the semi - structured data from targeted web pages with specific topics , that is the so - called focused web - harvesting @xcite .",
    "the method is suitable for in particular the indirect data integration which is not tolerant to any error .",
    "the architecture is inspired and the combination of focused web - crawling and regular web - harvesting .",
    "the focused web - crawling does not indiscriminately crawl the web pages like general purpose search engines , but attempts to download pages that are similar to each other @xcite . according to the data integration purposes and its requirement of high accuracy , the focused web - harvesting technique adopts human intervention in the initial setup by providing the targeted url of list of data , for instance the publication list , and defining the template of the final page contains the relevant information by labeling the attributes . in the case of detail information of publication page as shown in fig . [",
    "fig : source ] , the relevant information and labeling are ranging from title , authors , abstract to the fulltext if available .",
    "the method has been applied to the indonesian scientific index ( isi ) which integrates the scientific data from scientific and academic institutions across indonesia through their websites @xcite .",
    "the system is also open for public under gnu license at sourceforge.net @xcite .",
    "obviously , in spite of its high accuracy and unnecessary machine - learning like system , the method is suffered from tedious labor time at its initial setup to determine the tokens , to label the attributes , and is lacking of the ability to detect effectively later changes of the targeted page templates . because the labels and tokens are represented as dom trees which are sensitive to later changes of targeted web templates @xcite .    in this paper ,",
    "in order to overcome the above - mentioned problems we present a new method to extract the tokens reversely from the region - of - interest ( roi ) at the final web pages , and further label each attribute as normal procedure .",
    "this technique is in contrast with the existing mechanism which always starts from the root of web source and also the root of roi . we argue that it is more efficient and accurate to extract the tokens , and on the other hand to detect the later template changes withour any ambiguities .",
    "we should also remark that the reverse method is applicable for any existing methods for data extraction , especially the ones which require initial setup by human intervention to define and label the attributes .",
    "this is actually similar to the previous method @xcite , but instead of using the pat tree @xcite we use the dom tree like mechanism @xcite .",
    "moreover we improve its accuracy by taking into account the lower part of tree and not only the trees from the root .",
    "the paper is organized as follows .",
    "first , after this brief introduction we describe our approach in sec .",
    "[ sec : tree ] . in the subsequent section , sec .",
    "[ sec : implementation ] , we present the implementation and the web interface to define the initial setup for each targeted web",
    ". finally we summarize the paper and provide some future issues and further development .",
    "no matter the method used to extract and to label the tokens from a web template or layout , correct initial setup is crucial for further data extraction .",
    "as mentioned before , this point plays an important role for indirect data integration which has no tolerance to any errors .",
    "this makes some methods based on the machine learning system are useless .",
    "from now , please note that we are not going to deal with the algorithms to mine the labeled data since the tasks after labeling can be done further using any existing methods , nor to find the relevant pages of data list which has been discussed in our previous work @xcite and many previous works elsewhere .",
    "the reverse mechanism can be outlined recursively as follows :    1 .",
    "determine the url of the final web page with desired information like fig .",
    "[ fig : source ] .",
    "2 .   provide the whole sentences of the roi by copying and pasting the displayed desired text. 3 .   provide the whole sentence(s ) of each sub - roi and assign the attributes for each of them .",
    "4 .   crawl the source .",
    "5 .   parse and clean the text - format html tags like ` < b > ` , ` < i > ` etc",
    "take the upper part of source from the top till the last one before the first sentence of roi .",
    "parse and clean all texts inside except the layout - format html tags , like ` < tr > ` etc , do the same thing for the lower part that is from the end of last sentence of roi till the bottom . 7 .",
    "calculate the number of open - tag ( @xmath0 ) and closed - tag ( @xmath1 ) from the deepest part in term of desired content , that is the nearest tags from the roi .",
    "we should stress here that there is no need for the administrators to provide the web page sources at all .",
    "open - tag here means the tags which have no pair in upper or lower part , while the closed - tag denotes the pairing tags within upper or lower part .",
    "of course , our interest is only in the open - tag which should describe the whole structure of web template .    following the above procedures , we can obtain a kind of dom tree as shown in fig .",
    "[ fig : tree ] .",
    "we can further calculate the number of trees according to the number of open - tags .",
    "please remind that the calculation is done horizontally , from left to right shown by the arrow in the figure .",
    "the number of trees in upper and lower parts are determined by , @xmath2    concerning all possibilities on the number of trees in upper and lower parts , therefore we can generally categorize the web structures through the discrepancies between both numbers as , @xmath3 fig .",
    "[ fig : tree ] provides an example of tree in the case of fig .",
    "[ fig : source ] which is accidently asymmetry .",
    "that means the number of trees in the upper and lower parts are not the same , @xmath4 .",
    "again , we can use one of the existing methods to calculate the number of trees like the pat tree algorithm @xcite and so forth .    through the discussion above ,",
    "it is clear that the present method has several advantages :    * we can separate independently the structure and the rules to obtain the roi and the structure inside .",
    "* we can find out the template changes and its relevance with the desired roi , since we can compare and see the pairing tokens between the upper and lower parts .",
    "we discuss these points in more detail through the real implementation at isi in the subsequent section .",
    "our approach to web page information extraction has been experimentally implemented into the system of isi . following the wrapper induction programs which are usually supplemented by a user friendly gui",
    ", we have also developed a web based interface to perform the initial setup .",
    "the example used at isi is given in fig .",
    "[ fig : gui ] which shows the web interface to define the content of roi from a choosen final page and the labels for each attribute .",
    "isi can now efficiently detect the changes of targeted web templates by comparing the old and new numbers of @xmath5 .",
    "it is done by executing the check procedure each time prior to the new crawling works into the same targeted web pages . since the parameter as in fig .",
    "[ fig : gui ] has been stored in the system , it can be used not only for the initial setup but also for rechecking the templates in a regular basis .",
    "the discrepancies between the old and new numbers of @xmath5 is usefull to detect easily the template changes time by time , and at the same time determine where the changes happened .",
    "it can be summarized as below ,    1 .",
    "no change at all : + @xmath6 ; @xmath7 ; @xmath8 2 .",
    "simultaneous changes with same size in both upper and lower trees : + @xmath6 ; @xmath9 ; @xmath10 3 .",
    "only one tree has changed : + @xmath11 ; @xmath9 ; @xmath8 + or : + @xmath11 ; @xmath7 ; @xmath10 + 4 .   both trees have changed differently : + @xmath11 ; @xmath9 ; @xmath10 +    apparently , in the case 1 no need to alter the saved intial parameter .",
    "in contrast , from the case 2 , 3 and 4 we can deduce that the templates have been changed , either in the upper , lower or both trees .",
    "the important point is , once the template changes have been detected , the system automatically replace the old version of template with the new one .",
    "furthermore , the reverse method can be used to rebuild the content of roi in terms of labels which enable us to restructure the database for further purposes .",
    "the procedure is completely the same as extracting the roi . tab . [",
    "tab : attr ] shows the delimiters extracted from the roi in fig .",
    "[ fig : source ] using the same interface as fig .",
    "[ fig : gui ] .",
    ".the delimiters extracted from the example in fig .",
    "[ fig : source ] using the reverse mechanism defined in fig .",
    "[ fig : gui ] . [ cols=\"^,^,^\",options=\"header \" , ]",
    "we have discussed a simple method based on the reverse algorithm and dom tree to extract the roi and label the relevant attributes in the initial setup .",
    "the resulted patterns can be used further to automatically extract the data from crawled targeted web pages .",
    "we argue that the method and its web interface reduce the administrator works significantly , while on the other hand improve the accuracy and speed of finding the tokens and labeling the attributes .",
    "we have found that this method is very effective to detect the template changes , for instance newly inserted advetorial in the middle of upper or lower tree which often occurs in any websites and leads to difficulties in existing methods .    the experimental works on applying the method to the available huge number of data stored at isi is still under progress .",
    "the expected results and its effectiveness to detect the altered web pages will be analysed and published in a more complete and detail paper elsewhere .",
    "however , according to our trial experiments using 10000 data from several web sources , the method performs very well .",
    "it succeeded in detecting any template changes and improved the speed of whole processes up to 20% .",
    "finally , we should remark that in principle the method is applicable for the web sources in a form of list of data .",
    "the work on this matter is also in progress .",
    "the work is partially supported by the riset kompetitif lipi in fiscal year 2009 .",
    "r. baumgartner , s. flesca , g. gottlob , visual web information extraction with lixto , proceedings of the 27th international conference on very large data bases , september 1114 , 2001 , pp .",
    "i. muslea , s. minton , c.a .",
    "knoblock , hierarchical wrapper induction for semistructured information sources , autonomous agents and multi - agent systems 4 ( 2001 ) 93114 .",
    "a. pan , j. raposo , m. lvarez , j. hidalgo , a. via , semi - automatic wrapper generation for commercial web sources , proceedings of the ifip tc8",
    "/ wg8.1 working conference on engineering information systems in the internet context , september 2527 , 2002 , pp .",
    "j. raposo , a. pan , m. lvarez , j. hidalgo , automatically maintaining wrappers for semi - structured web sources , data and knowledge engineering 61 ( 2007 ) 331358 .",
    "y. zhai , b. liu , extracting web data using instance - based learning , in : proceedings of web information systems engineering conference ( wise ) , 2005 , pp .",
    "318 - 331 .",
    "l. arlota , v. crescenzi , g. mecca , p. merialdo , automatic annotation of data extracted from large websites , in : proceedings of the webdb workshop , 2003 , pp .",
    ". n. kushmerick , regression testing for wrapper maintenance , proceedings of the sixteenth national conference on artificial intelligence and the eleventh innovative applications of artificial intelligence conference innovative applications of artificial intelligence , july 18 - 22 , 1999 , pp .",
    "j. wang , f.h .",
    "lochovsky , data extraction and label assignment for web databases , proceedings of the 12th international conference on world wide web , may 2024 , 2003 , pp . 187196",
    ". m. alvarez , a. pan , j. raposo , f. bellas , f. cacheda , extracting lists of data records from semi - structured web pages , data and knowledge engineering 64 ( 2007 ) 491509 .",
    "laender , b.a .",
    "ribeiro - neto , a. soares da silva , j.s .",
    "teixeira , a brief survey of web data extraction tools , acm sigmod record 31 ( 2002 ) 8493 .",
    "z. akbar , l.t .",
    "handoko , a simple mechanism for focused web - harvesting , proceeding of the international conference on advanced computational intelligence and its applications , may 1319 , 2008 . s. chakrabarti , m. van den berg and b. dom , _ focused crawling : a new approach to topic - specific web resource discovery _",
    ", computer networks 31 ( 1999 ) 16231640 . z. akbar _ et.al._ , indonesian scientific index - isi , _ http://www.isi.lipi.go.id_. z. akbar _ et.al._ , openisi , _",
    "http://sourceforge.net / projects / openisi/_. j. wang , f. lochovsky , data extraction and label assignment for web databases , proceeding of the 12th international world wide web conference , 2003 . the w3 consortium , the document object model , _ http://www.w3.org / dom/_. c - h .",
    "chang , c - n .",
    "hsu , s - c .",
    "lui , automatic information extraction from semi - structured web pages by pattern discovery , decision support system 35 ( 2003 ) 129147 .",
    "gonnet , r.a .",
    "baeza - yates , t. snider , new indices for text : pat trees and pat arrays in information retrieval : data structures and algorithms , prentice hall , 1992 ."
  ],
  "abstract_text": [
    "<S> we propose a new technique to infer the structure and extract the tokens of data from the semi - structured web sources which are generated using a consistent template or layout with some implicit regularities . </S>",
    "<S> the attributes are extracted and labeled reversely from the region of interest of targeted contents . </S>",
    "<S> this is in contrast with the existing techniques which always generate the trees from the root . </S>",
    "<S> we argue and show that our technique is simpler , more accurate and effective especially to detect the changes of the templates of targeted web pages . </S>",
    "<S> +    data extraction ; data mining ; web - based information system </S>"
  ]
}