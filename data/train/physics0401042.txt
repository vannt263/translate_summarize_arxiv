{
  "article_text": [
    "in the reporting of results from particle physics experiments it is common to see values given with errors with different positive and negative numbers , to denote a 68% central confidence region which is not symmetric about the central estimate . for example ( one of many ) the particle data group@xcite quote @xmath0    the purpose of this note is to describe how such errors arise and how they can properly be handled , particularly when two contributions are combined .",
    "current practice is to combine such errors separately , i.e. to add the @xmath1 values together in quadrature , and then do the same thing for the @xmath2 values .",
    "this is not , to my knowledge , documented anywhere and , as will be shown , is certainly wrong .",
    "there are two separate sources of asymmetry , which unfortunately require different treatments .",
    "we call these ` statistical ' and ` systematic ' ; the label is fairly accurate though not entirely so , and they could equally well be called ` frequentist ' and ` bayesian ' .",
    "asymmetric statistical errors arise when the log likelihood curve is not well described by a parabola  @xcite .",
    "the one sigma values ( or , equivalently , the 68% central confidence level interval limits ) are read off the points at which @xmath3 falls from its peak by @xmath4  or , equivalently , when @xmath5 rises by 1 .",
    "this is not strictly accurate , and corrections should be made using bartlett functions@xcite , but that lies beyond the scope of this note .",
    "asymmetric systematic errors arise when the dependence of a result on a ` nuisance parameter ' is non - linear .",
    "because the dependence on such parameters  theoretical values , experimental calibration constants , and so forth  is generally complicated , involving monte carlo simulation , this study generally has to be performed by evaluating the result @xmath6 at the @xmath7 and @xmath8 values of the nuisance parameter @xmath9 ( see  @xcite for a fuller account ) giving @xmath10 and @xmath11 .",
    "( @xmath12 gives @xmath13 or @xmath14 according to the sign of @xmath15 . )",
    "this note summarises a full account of the procedure for asymmetric systematic errors which can be found in  @xcite and describes what has subsequently been achieved for asymmetric statistical errors . for another critical account see  @xcite",
    "if @xmath10 and @xmath11 are different then this is a sign that the dependence of @xmath6 on @xmath9 is non - linear and the symmetric distribution in @xmath9 gives an asymmetric distribution in @xmath6 . in practice ,",
    "if the difference is not large , one might be well advised to assume a straight line dependence and take the error as symmetric , however we will assume that this is not a case where this is appropriate .",
    "we consider cases where a non - linear effect is not small enough to be ignored entirely , but not large enough to justify a long and intensive investigation .",
    "such cases are common enough in practice .      for simplicity",
    "we transform @xmath9 to the variable @xmath16 described by a unit gaussian , and work with @xmath17 .",
    "it is useful to define the mean @xmath18 , the difference @xmath19 , and the asymmetry @xmath20 : @xmath21 there are infinitely many non - linear relationships between @xmath16 and @xmath22 that will go through the three determined points .",
    "we consider two .",
    "we make no claim that either of these is ` correct ' . but working with asymmetric errors must involve some model of the non - linearity .",
    "practitioners must select one of these two models , or some other ( to which the same formalism can be applied ) , on the basis of their knowledge of the problem , their preference and experience .",
    "* model 1 : two straight lines + two straight lines are drawn , meeting at the central value @xmath23 * model 2 : a quadratic function + the parabola through the three points is + @xmath24    these forms are shown in figure  [ figmodels ] for a small asymmetry of 0.1 , and a larger asymmetry of 0.4 .    , width=188 ]    model 1 is shown as a solid line , and model 2 is dashed .",
    "both go through the 3 specified points .",
    "the differences between them within the range @xmath25 are not large ; outside that range they diverge considerably .",
    "the distribution in @xmath16 is a unit gaussian , @xmath26 , and the distribution in @xmath22 is obtained from @xmath27 .",
    "examples are shown in figure  [ figcom1 ] . for model 1 ( again a solid line ) this gives a dimidated gaussian - two gaussians with different standard deviation for @xmath28 and @xmath29 .",
    "this is sometimes called a ` bifurcated gaussian ' , but this is inaccurate .",
    "` bifurcated ' means ` split ' in the sense of forked . `",
    "dimidated ' means ` cut in half ' , with the subsidiary meaning of ` having one part much smaller than the other '  @xcite . for model 2 ( dashed ) with small asymmetries",
    "the curve is a distorted gaussian , given by @xmath30 with @xmath31 . for larger asymmetries and/or larger @xmath32 values",
    ", the second root also has to be considered .",
    ", width=188 ]    it can be seen that the model 1 dimidated gaussian and model 2 distorted gaussian are not dissimilar if the asymmetry is small , but are very different if the asymmetry is large .      if a nuisance parameter @xmath16 is distributed with a gaussian probability distribution , and the quantity @xmath33 is a nonlinear function of @xmath16 , then the expectation @xmath34 is not @xmath35 .    for model 1 one",
    "has @xmath36    for model 2 one has @xmath37    hence in these models , ( or any others ) , if the result quoted is @xmath38 , it is not the mean .",
    "it differs from it by an amount of the order of the difference in the positive and negative errors .",
    "it is perhaps defensible as a number to quote as the result as it is still the median - there is a 50% chance that the true value is below it and a 50% chance that it is above .",
    "if a derived quantity @xmath39 contains parts from two quantities @xmath6 and @xmath40 , so that @xmath41 , the distribution in @xmath39 is given by the convolution :    @xmath42        with model 1 the convolution can be done analytically .",
    "some results for typical cases are shown in figure  [ figcom2 ] .",
    "the solid line shows the convolution , the dashed line is obtained by adding the positive and negative standard deviations separately in quadrature ( the ` usual procedure ' ) .",
    "the dotted line is described later .",
    "the solid and dashed curves disagree markedly .",
    "the ` usual procedure ' curve has a larger skew than the convolution .",
    "this is obvious .",
    "if two distributions with the same asymmetry are added the ` usual procedure ' will give a distribution just scaled by @xmath43 , with the same asymmetry .",
    "this violates the central limit theorem , which says that convoluting identical distributions must result in a combined distribution which is more gaussian , and therefore more symmetric , than its components .",
    "this shows that the ` usual procedure ' for adding asymmetric errors is inconsistent .",
    "if a distribution for @xmath6 is described by some function , @xmath44 , which is a gaussian transformed according to model 1 or model 2 or anything else , then ` combination of errors ' involves a convolution of two such functions according to equation  [ eqnconvolute ] .",
    "this combined function is not necessarily a function of the same form : it is a special property of the gaussian that the convolution of two gaussians gives a third .",
    "the ( solid line ) convolution of two dimidated gaussians is not itself a dimidated gaussian .",
    "figure  [ figcom2 ] is a demonstration of this .",
    "although the form of the function is changed by a convolution , some things are preserved .",
    "the semi - invariant cumulants of thi ` ele ( the coefficients of the power series expansion of the log of the fourier transform ) add under convolution .",
    "the first two of these are the usual mean and variance .",
    "the third is the unnormalised skew : @xmath45 within the context of any model , a consistent approach to the combination of errors is to find the mean , variance and skew : @xmath46 , @xmath47 and @xmath48 , for each contributing function separately . adding these up gives the mean , variance and skew of the combined function .",
    "working within the model one then determines the values of @xmath49 , and @xmath50 that give this mean , variance and skew .      for model 1 ,",
    "for which @xmath51 we have @xmath52 \\label{eqndict1}\\end{aligned}\\ ] ] given several error contributions the equations  [ eqndict1 ] give the cumulants @xmath46 , @xmath47 and @xmath48 of each .",
    "adding these up gives the first three cumulants of the combined distribution .",
    "then one can find the set of parameters @xmath53 which give these values by using equations  [ eqndict1 ] in the other sense .",
    "it is convenient to work with @xmath54 , where @xmath54 is the difference between the final @xmath50 and the sum of the individual ones .",
    "the parameter is needed because of the bias mentioned earlier .",
    "even though each contribution may have @xmath55 , i.e. it describes a spread about the quoted result , it has non - zero @xmath56 through the bias effect ( c.f .",
    "equations  [ eqnbias1 ] and [ eqnbias2 ] )",
    ". the @xmath1 and @xmath2 of the combined distribution , obtained from the total @xmath47 and @xmath48 , will in general not give the right @xmath46 unless a location shift @xmath54 is added .",
    "_ the value of the quoted result will shift . _    recalling section b , for the original distribution one could defend quoting the central value as it was the median , even though it was not the mean .",
    "the convoluted distribution not only has a non - zero mean , it also ( as can be seen in figure  [ figcom2 ] ) has non - zero median .",
    "if you want to combine asymmetric errors then you have to accept that the quoted value will shift . to make this correction requires a real belief in the asymmetry of the error values . at this point practitioners , unless they are sure that their errors really do have a significant asymmetry , may be persuaded to revert to quoting symmetric errors .",
    "solving the equations  [ eqndict1 ] for @xmath57 and @xmath58 given @xmath46 , @xmath47 and @xmath48 has to be done numerically .",
    "a program for this is available on .",
    "some results are shown in the dotted curve of figure  [ figcom2 ] and table 1 .",
    ".adding errors in model 1 [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]     [ table2 ]    , width=188 ]    again the true curves ( solid ) are not well reproduced by the ` usual procedure ' ( dashed ) but the curves with the correct cumulants ( dotted ) do a good job .",
    "( the sharp behaviour at the edge of the curves is due to the turning point of the parabola . )      for model 1 the @xmath5 contribution from a discrepancy @xmath59 is just @xmath60 or @xmath61 as appropriate .",
    "this is manifestly inelegant , especially for minimisation procedures as the value goes through zero .    for model 2 one has @xmath62",
    "this can be considered as a quadratic for @xmath16 with solution which when squared gives @xmath63 , the @xmath5 contribution , as @xmath64 this is not really exact , in that it only takes one branch of the solution , the one approximating to the straight line , and does not consider the extra possibility that the @xmath59 value could come from an improbable @xmath16 value the other side of the turning point of the parabola .",
    "given this imperfection it makes sense to expand the square root as a taylor series , which , neglecting correction terms above the second power , leads to @xmath65    this provides a sensible form for @xmath5 from asymmetric errors .",
    "it is important to keep the @xmath66 term rather than stopping at @xmath67 to ensure @xmath5 stays positive ! adding higher orders does not have a great effect .",
    "we recommend it for consideration when it is required ( e.g. in fitting parton distribution functions ) to form a @xmath5 from asymmetric errors      the ` best ' estimate ( i.e. unbiassed and with smallest variance ) from several measurements @xmath68 with different ( symmetric ) errors @xmath69 is given by a weighted sum with @xmath70 .",
    "we wish to find the equivalent for asymmetric errors .",
    "as noted earlier , when sampling from an asymmetric distribution the result is biassed towards the tail .",
    "the expectation value @xmath71 is not the location parameter @xmath6 .",
    "so for an unbiassed estimator one must take @xmath72 where @xmath73 the variance of this is given by @xmath74 where @xmath75 is the variance of the @xmath76 measurement about its mean .",
    "differentiating with respect to @xmath77 to find the minimum gives @xmath78 which is satisfied by @xmath79 .",
    "this is the equivalent of the familiar weighting by @xmath80 .",
    "the weights are given , depending on the model , by ( see equations  [ eqndict1 ] and [ eqndict2 ] ) @xmath81    note that this is not the maximum liklelihood estimator - writing down the likelihood in terms of the @xmath5 and differentiating does not give a nice form - so in principle there may be better estimators , but they will not have the simple form of a weighted sum .",
    "as explained earlier , ( log ) likelihood curves are used to obtain the maximum likelihood estimate for a parameter and also the 68% central interval  taken as the values at which @xmath3 falls by @xmath4 from its peak . for large @xmath82",
    "this curve is a parabola , but for finite @xmath82 it is generally asymmetric , and the two points are not equidistant about the peak .    the bias , if any , is not connected to the form of the curve , which is a likelihood and not a pdf .",
    "evaluating a bias is done by integrating over the measured value not the theoretical parameter .",
    "we will assume for simplicity that these estimates are bias free .",
    "this means that when combining errors there will be no shift of the quoted value .",
    "suppose estimates @xmath83 and @xmath84 are obtained by this method for variables @xmath9 and @xmath85 .",
    "@xmath9 could typically be an estimate of the total number of events in a signal region , and @xmath85 the ( scaled and negated ) estimate of background , obtained from a sideband .",
    "we are interested in @xmath86 , taking @xmath87 .",
    "what are the errors to be quoted on @xmath88 ?",
    "we first consider the case where the likelihood functions @xmath89 and @xmath90 are given .",
    "for the symmetric gaussian case , the answer is well known .",
    "suppose that the likelihoods are both gaussian , and further that @xmath91 .",
    "the log likelihood term @xmath92 can be rewritten @xmath93 so the likelihood is the product of gaussians for @xmath86 and @xmath94 , with standard deviations @xmath95 .    picking a particular value of @xmath96 , one can then trivially construct the 68% confidence region for @xmath16 as @xmath97 $ ] . picking another value of @xmath96 , indeed any other value of @xmath96 ,",
    "one obtains the same region for @xmath16 .",
    "we can therefore say with 68% confidence that these limits enclose the true value of @xmath16 , whatever the value of @xmath96 .",
    "the uninteresting part of @xmath9 and @xmath85 has been ` parametrised away ' .",
    "this is , of course , the standard result from the combination of errors formula , but derived in a frequentist way using neyman - style confidence intervals .",
    "we could construct the limits on @xmath16 by finding @xmath98 such that the integrated probability of a result as small as or smaller than the data be 16% , and similarly for @xmath99 , rather than taking the @xmath100 shortcut , and it would not affect the argument .",
    "the question now is how to generalise this . for this to be possible",
    "the likelihood must factorise @xmath101 with a suitable choice of the parameter @xmath96 and the functions @xmath102 and @xmath103 .",
    "then we can use the same argument : for any value of @xmath96 the limits on @xmath16 are the same , depending only on @xmath104 . because they are true for any @xmath96 they are true for all @xmath96 , and thus in general .",
    "there are cases where this can clearly be done . for two gaussians with @xmath105",
    "the result is the same as above but with @xmath106 . for two",
    "poisson distributions @xmath96 is @xmath107 .",
    "there are cases ( with multiple peaks ) where it can not be done , but let us hope that these are artificially pathological .    on the basis",
    "that if it can not be done , the question is unanswerable , let us assume that it is possible in the case being studied , and see how far we can proceed . finding the form of @xmath96 is liable to be difficult , and as it is not actually used in the answer we would like to avoid doing so .",
    "the limits on @xmath16 are read off from the @xmath108 points where @xmath96 can have any value provided it is fixed .",
    "let us choose @xmath109 , the value at the peak .",
    "this is the value of @xmath96 at which @xmath110 is a maximum .",
    "hence when we consider any other value of @xmath16 , we can find @xmath109 by finding the point at which the likelihood is a maximum , varying @xmath111 , or @xmath9 , or @xmath85 , or any other combination , always keeping @xmath112 fixed .",
    "we can read the limits off a 1 dimensional plot of @xmath113 , where the ` max ' suffix denotes that at each value of @xmath16 we search the subspace to pick out the maximum value .",
    "this generalises to more complicated situations . if @xmath114 we again scan the @xmath113 function , where the subspace is now 2 dimensional .      in many cases",
    "the likelihood functions for @xmath9 and @xmath85 will not be given , merely estimates @xmath83 and @xmath84 and their asymmetric errors @xmath115 , @xmath116 , @xmath117 and @xmath118 .",
    "all we can do is to use these to provide best guess functions @xmath89 and @xmath90 .",
    "a parametrisation of suitable shapes , which for @xmath119 approximate to a parabola , must be provided . choosing a suitable parametrisation is not trivial .",
    "the obvious choice of introducing small higher - order terms fails as these dominate far from the peak .",
    "a likely candidate is : @xmath120 where @xmath121 and @xmath122 .",
    "this describes the usual parabola , but with the x - axis stretched by an amount that changes linearly with distance .",
    "figure  [ figparab ] shows two illustrative results .    ,",
    "width=151 ]    the first is the poisson likelihood from 5 observed events ( solid line ) for which the estimate using the @xmath123 points is @xmath124 , as shown .",
    "the dashed line is that obtained inserting these numbers into equation  [ parametrise ] .",
    "the second considers a measurement of @xmath125 , of which the logarithm has been taken , to give a value @xmath126 .",
    "again , the solid line is the true curve and the dashed line the parametrisation . in both cases",
    "the agreement is excellent over the range @xmath127 and reasonable over the range @xmath128 .    to check the correctness of the method we can use the combination of two poisson numbers , for which the result is known .",
    "first indications are that the errors obtained from the parametrisation are indeed closer to the true poisson errors than those obtained from the usual technique .",
    "a related problem is to find the combined estimate @xmath88 given estimates @xmath83 and @xmath84 ( which have asymmetric errors ) . here",
    "@xmath9 and @xmath85 could be results from different channels or different experiments .",
    "this can be regarded as a special case , constrained to @xmath129 , i.e. @xmath130 , but this is rather contrived .",
    "it is more direct just to say that one uses the log likelihood which is the sum of the two separate functions , and determines the peak and the @xmath100 points from that .",
    "if the functions are known this is unproblematic , if only the errors are given then the same parametrisation technique can be used .",
    "if asymmetric errrors can not be avoided they need careful handling .    a method is suggested and a program provided for combining asymmetric systematic errors .",
    "it is not ` rigorously correct ' but such perfection is impossible . unlike the usual method , it is at least open about its assumptions and mathematically consistent ."
  ],
  "abstract_text": [
    "<S> errors quoted on results are often given in asymmetric form . </S>",
    "<S> an account is given of the two ways these can arise in an analysis , and the combination of asymmetric errors is discussed . </S>",
    "<S> it is shown that the usual method has no basis and is indeed wrong . for asymmetric systematic errors , </S>",
    "<S> a consistent method is given , with detailed examples . </S>",
    "<S> for asymmetric statistical errors a general approach is outlined .    </S>",
    "<S> = cmcsc12 </S>"
  ]
}