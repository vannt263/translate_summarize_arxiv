{
  "article_text": [
    "visual object detection could be viewed as the combination of two tasks : object localization ( where the object is ) and visual recognition ( what the object looks like ) .",
    "while the deep convolutional neural networks ( cnns ) has witnessed major breakthroughs in visual object recognition  @xcite @xcite @xcite , the cnn - based object detectors have also achieved the state - of - the - arts results on a wide range of applications , such as face detection  @xcite @xcite , pedestrian detection  @xcite @xcite and etc  @xcite @xcite @xcite .",
    "currently , most of the cnn - based object detection methods  @xcite @xcite @xcite could be summarized as a three - step pipeline : firstly , region proposals are extracted as object candidates from a given image .",
    "the popular region proposal methods include selective search  @xcite , edgeboxes  @xcite , or the early stages of cascade detectors  @xcite ; secondly , the extracted proposals are fed into a deep cnn for recognition and categorization ; finally , the bounding box regression technique is employed to refine the coarse proposals into more accurate object bounds . in this pipeline , the region proposal algorithm constitutes a major bottleneck in terms of localization effectiveness , as well as efficiency . on one hand , with only low - level features ,",
    "the traditional region proposal algorithms are sensitive to the local appearance changes , e.g. , partial occlusion , where those algorithms are very likely to fail . on the other hand , a majority of those methods",
    "are typically based on image over - segmentation  @xcite or dense sliding windows  @xcite , which are computationally expensive and have hamper their deployments in the real - time detection systems .",
    "loss and @xmath0 loss for pixel - wise bounding box prediction.,scaledwidth=45.0% ]    to overcome these disadvantages , more recently the deep cnns are also applied to generate object proposals . in the well - known faster r - cnn scheme  @xcite ,",
    "a region proposal network ( rpn ) is trained to predict the bounding boxes of object candidates from the _ anchor _ boxes . however , since the scales and aspect ratios of _ anchor _ boxes are pre - designed and fixed , the rpn shows difficult to handle the object candidates with large shape variations , especially for small objects .",
    "another successful detection framework , densebox  @xcite , utilizes every pixel of the feature map to regress a 4-d distance vector ( the distances between the current pixel and the four bounds of object candidate containing it )",
    ". however , densebox optimizes the four - side distances as four independent variables , under the simplistic @xmath0 loss , as shown in figure  [ fig : introduction ] .",
    "it goes against the intuition that those variables are correlated and should be regressed jointly .",
    "besides , to balance the bounding boxes with varied scales , densebox requires the training image patches to be resized to a fixed scale . as a consequence",
    ", densebox has to perform detection on image pyramids , which unavoidably affects the efficiency of the framework .",
    "the paper proposes a highly effective and efficient cnn - based object detection network , called unitbox .",
    "it adopts a fully convolutional network architecture , to predict the object bounds as well as the pixel - wise classification scores on the feature maps directly .",
    "particularly , unitbox takes advantage of a novel intersection over union ( @xmath1 ) loss function for bounding box prediction .",
    "the @xmath1 loss directly enforces the maximal overlap between the predicted bounding box and the ground truth , and jointly regress all the bound variables as a whole unit ( see figure  [ fig : introduction ] ) .",
    "the unitbox demonstrates not only more accurate box prediction , but also faster training convergence .",
    "it is also notable that thanks to the @xmath1 loss , unitbox is enabled with variable - scale training .",
    "it implies the capability to localize objects in arbitrary shapes and scales , and to perform more efficient testing by just one pass on singe scale .",
    "we apply unitbox on face detection task , and achieve the best performance on fddb  @xcite among all published methods .",
    "before introducing unitbox , we firstly present the proposed @xmath1 loss layer and compare it with the widely - used @xmath0 loss in this section . some important denotations are claimed here : for each pixel @xmath2 in an image , the bounding box of ground truth could be defined as a 4-dimensional vector : @xmath3 where @xmath4 , @xmath5 , @xmath6 , @xmath7 represent the distances between current pixel location @xmath2 and the top , bottom , left and right bounds of ground truth , respectively . for simplicity , we omit footnote @xmath8 in the rest of this paper .",
    "accordingly , a predicted bounding box is defined as @xmath9 , as shown in figure  [ fig : introduction ] .",
    "@xmath0 loss is widely used in optimization . in  @xcite",
    "@xcite , @xmath0 loss is also employed to regress the object bounding box via cnns , which could be defined as : @xmath10 where @xmath11 is the localization error .    however , there are two major drawbacks of @xmath0 loss for bounding box prediction .",
    "the first is that in the @xmath0 loss , the coordinates of a bounding box ( in the form of @xmath12 , @xmath13 , @xmath14 , @xmath15 ) are optimized as four independent variables .",
    "this assumption violates the fact that the bounds of an object are highly correlated .",
    "it results in a number of failure cases in which one or two bounds of a predicted box are very close to the ground truth but the entire bounding box is unacceptable ; furthermore , from eqn .",
    "[ eqn : l2 ] we can see that , given two pixels , one falls in a larger bounding box while the other falls in a smaller one , the former will have a larger effect on the penalty than the latter , since the @xmath0 loss is unnormalized .",
    "this unbalance results in that the cnns focus more on larger objects while ignore smaller ones . to handle this , in previous work  @xcite the cnns",
    "are fed with the fixed - scale image patches in training phase , while applied on image pyramids in testing phase . in this way , the @xmath0 loss is normalized but the detection efficiency is also affected negatively .      in the following , we present a new loss function , named the @xmath1 loss , which perfectly addresses above drawbacks . given a predicted bounding box @xmath16 ( after relu layer , we have @xmath17 ) and the corresponding ground truth @xmath18 , we calculate the @xmath1 loss as follows :    * input : * @xmath18 as bounding box ground truth + * input : * @xmath19 as bounding box prediction + * output : * @xmath11 as localization error +    in algorithm 1 , @xmath20 represents that the pixel @xmath2 falls inside a valid object bounding box ; @xmath21 is area of the predicted box ; @xmath22 is area of the ground truth box ; @xmath23 , @xmath24 are the height and width of the intersection area @xmath25 , respectively , and @xmath26 is the union area .    note that with @xmath27 , @xmath28 is essentially a cross - entropy loss with input of @xmath1 : we can view @xmath1 as a kind of random variable sampled from bernoulli distribution , with @xmath29 , and the cross - entropy loss of the variable @xmath1 is @xmath30 .",
    "compared to the @xmath0 loss , we can see that instead of optimizing four coordinates independently , the @xmath1 loss considers the bounding box as a unit .",
    "thus the @xmath1 loss could provide more accurate bounding box prediction than the @xmath0 loss .",
    "moreover , the definition naturally norms the @xmath1 to @xmath31 $ ] regardless of the scales of bounding boxes .",
    "the advantage enables unitbox to be trained with multi - scale objects and tested only on single - scale image .      to deduce the backward algorithm of @xmath1 loss , firstly we need to compute the partial derivative of @xmath21 w.r.t .",
    "@xmath32 , marked as @xmath33 ( for simplicity , we notate @xmath32 for any of @xmath12 , @xmath13 , @xmath14 , @xmath15 if missing ) : @xmath34 @xmath35    to compute the partial derivative of @xmath25 w.r.t @xmath32 , marked as @xmath36 : @xmath37 @xmath38    finally we can compute the gradient of localization loss @xmath11 w.r.t .",
    "@xmath32 : @xmath39    from eqn .",
    "[ eqn : gradient ] , we can have a better understanding of the @xmath1 loss layer : the @xmath33 is the penalty for the predict bounding box , which is in a positive proportion to the gradient of loss ; and the @xmath36 is the penalty for the intersection area , which is in a negative proportion to the gradient of loss .",
    "so overall to minimize the @xmath1 loss , the eqn .",
    "[ eqn : gradient ] favors the intersection area as large as possible while the predicted box as small as possible .",
    "the limiting case is the intersection area equals to the predicted box , meaning a perfect match .",
    "based on the @xmath1 loss layer , we propose a pixel - wise object detection network , named unitbox .",
    "as illustrated in figure  [ fig : network ] , the architecture of unitbox is derived from vgg-16 model  @xcite , in which we remove the fully connected layers and add two branches of fully convolutional layers to predict the pixel - wise bounding boxes and classification scores , respectively . in training , unitbox is fed with three inputs in the same size : the original image , the confidence heatmap inferring a pixel falls in a target object ( positive ) or not ( negative ) , and the bounding box heatmaps inferring the ground truth boxes at all positive pixels .    to predict the confidence ,",
    "three layers are added layer - by - layer at the end of vgg stage-4 : _ a convolutional layer _ with stride @xmath40 , kernel size @xmath41 ; _ an up - sample layer _ which directly performs linear interpolation to resize the feature map to original image size ; _ a crop layer _ to align the feature map with the input image .",
    "after that , we obtain a 1-channel feature map with the same size of input image , on which we use the sigmoid cross - entropy loss to regress the generated confidence heatmap ; in the other branch , to predict the bounding box heatmaps we use the similar three stacked layers at the end of vgg stage-5 with convolutional kernel size 512 x 3 x 3 x 4 . additionally , we insert a relu layer to make bounding box prediction non - negative .",
    "the predicted bounds are jointly optimized with @xmath1 loss proposed in section  [ sec : iou_loss ] .",
    "the final loss is calculated as the weighted average over the losses of the two branches .",
    "some explanations about the architecture design of unitbox are listed as follows : 1 ) in unitbox , we concatenate the confidence branch at the end of vgg stage-4 while the bounding box branch is inserted at the end of stage-5 .",
    "the reason is that to regress the bounding box as a unit , the bounding box branch needs a larger receptive field than the confidence branch . and intuitively , the bounding boxes of objects could be predicted from the confidence heatmap . in this way",
    ", the bounding box branch could be regarded as a bottom - up strategy , abstracting the bounding boxes from the confidence heatmap ; 2 ) to keep unitbox efficient , we add as few extra layers as possible .",
    "compared to densebox  @xcite in which three convolutional layers are inserted for bounding box prediction , the unitbox only uses one convolutional layer . as a result ,",
    "the unitbox could process more than 10 images per second , while densebox needs several seconds to process one image ; 3 ) though in figure  [ fig : network ] the bounding box branch and the confidence branch share some earlier layers , they could be trained separately with unshared weights to further improve the effectiveness .    with the heatmaps of confidence and bounding box",
    ", we can now accurately localize the objects . taking the face detection for example , to generate bounding boxes of faces ,",
    "firstly we fit the faces by ellipses on the thresholded confidence heatmaps .",
    "since the face ellipses are too coarse to localize objects , we further select the center pixels of these coarse face ellipses and extract the corresponding bounding boxes from these selected pixels . despite its simplicity",
    ", the localization strategy shows the ability to provide bounding boxes of faces with high accuracy , as shown in figure  [ fig : observation ] .",
    "in this section , we apply the proposed @xmath1 loss as well as the unitbox on face detection task , and report our experimental results on the fddb benchmark  @xcite .",
    "the weights of unitbox are initialized from a vgg-16 model pre - trained on imagenet , and then fine - tuned on the public face dataset widerface  @xcite .",
    "we use mini - batch sgd in fine - tuning and set the batch size to 10 . following the settings in  @xcite ,",
    "the momentum and the weight decay factor are set to 0.9 and 0.0002 , respectively .",
    "the learning rate is set to @xmath42 which is the maximum trainable value .",
    "no data augmentation is used during fine - tuning .",
    "first of all we study the effectiveness of the proposed @xmath1 loss . to train a unitbox with @xmath0 loss , we simply replace the @xmath1 loss layer with the @xmath0 loss layer in figure  [ fig : network ] , and reduce the learning rate to @xmath43 ( since @xmath0 loss is generally much larger , @xmath43 is the maximum trainable value ) , keeping the other parameters and network architecture unchanged .",
    "figure  [ fig : convergence ] compares the convergences of the two losses , in which the x - axis represents the number of iterations and the y - axis represents the detection miss rate .",
    "as we can see , the model with @xmath1 loss converges more quickly and steadily than the one with @xmath0 loss . besides , the unitbox has a much lower miss rate than the unitbox-@xmath0 throughout the fine - tuning process .    in figure",
    "[ fig : performance_vs ] , we pick the best models of unitbox ( @xmath44 16k iterations ) and unitbox-@xmath0 ( @xmath44 29k iterations ) , and compare their roc curves . though with fewer iterations , the unitbox with @xmath1 loss still significantly outperforms the one with @xmath0 loss .",
    "loss , the @xmath1 loss is much more robust to scale variations for bounding box prediction.,scaledwidth=45.0% ]    moreover , we study the robustness of @xmath1 loss and @xmath0 loss to the scale variation .",
    "as shown in figure  [ fig : scale_invariant ] , we resize the testing images from 60 to 960 pixels , and apply unitbox and unitbox-@xmath0 on the image pyramids . given a pixel at the same position ( denoted as the red dot ) , the bounding boxes predicted at this pixel are drawn . from the result",
    "we can see that 1 ) as discussed in section  [ ssec : ssec2.1 ] , the @xmath0 loss could hardly handle the objects in varied scales while the @xmath1 loss works well ; 2 ) without joint optimization , the @xmath0 loss may regress one or two bounds accurately , e.g. , the up bound in this case , but could not provide satisfied entire bounding box prediction ; 3 ) in the x960 testing image , the face size is even larger than the receptive fields of the neurons in unitbox ( around 200 pixels ) .",
    "surprisingly , the unitbox can still give a reasonable bounding box in the extreme cases while the unitbox-@xmath0 totally fails .          to demonstrate the effectiveness of the proposed method",
    ", we compare the unitbox with the state - of - the - arts methods on fddb . as illustrated in section  [ sec : sec3 ] , here we train an unshared unitbox detector to further improve the detection performance .",
    "the roc curves are shown in figure  [ fig : performance ] . as a result",
    ", the proposed unitbox has achieved the best detection result on fddb among all published methods .    except that , the efficiency of unitbox is also remarkable . compared to the densebox  @xcite which needs seconds to process one image",
    ", the unitbox could run at about 12 fps on images in vga size .",
    "the advantage in efficiency makes unitbox potential to be deployed in real - time detection systems .",
    "the paper presents a novel loss , i.e. , the @xmath1 loss , for bounding box prediction .",
    "compared to the @xmath0 loss used in previous work , the @xmath1 loss layer regresses the bounding box of an object candidate as a whole unit , rather than four independent variables , leading to not only faster convergence but also more accurate object localization .",
    "based on the @xmath1 loss , we further propose an advanced object detection network , i.e. , the unitbox , which is applied on the face detection task and achieves the state - of - the - art performance .",
    "we believe that the @xmath1 loss layer as well as the unitbox will be of great value to other object localization and detection tasks .",
    "v.  belagiannis , x.  wang , h.  beny ben  shitrit , k.  hashimoto , r.  stauder , y.  aoki , m.  kranzfelder , a.  schneider , p.  fua , s.  ilic , h.  feussner , and n.  navab .",
    "parsing human skeletons in an operating room . , 2016 .",
    "h.  li , z.  lin , x.  shen , j.  brandt , and g.  hua . a convolutional neural network cascade for face detection . in _ proceedings of the ieee conference on computer vision and pattern recognition _ ,",
    "pages 53255334 , 2015 ."
  ],
  "abstract_text": [
    "<S> in present object detection systems , the deep convolutional neural networks ( cnns ) are utilized to predict bounding boxes of object candidates , and have gained performance advantages over the traditional region proposal methods . however </S>",
    "<S> , existing deep cnn methods assume the object bounds to be four independent variables , which could be regressed by the @xmath0 loss separately . </S>",
    "<S> such an oversimplified assumption is contrary to the well - received observation , that those variables are correlated , resulting to less accurate localization . to address the issue </S>",
    "<S> , we firstly introduce a novel intersection over union ( @xmath1 ) loss function for bounding box prediction , which regresses the four bounds of a predicted box as a whole unit . by taking the advantages of @xmath1 loss and deep fully convolutional networks , </S>",
    "<S> the unitbox is introduced , which performs accurate and efficient localization , shows robust to objects of varied shapes and scales , and converges fast . </S>",
    "<S> we apply unitbox on face detection task and achieve the best performance among all published methods on the fddb benchmark .    </S>",
    "<S> = 10000 = 10000 </S>"
  ]
}