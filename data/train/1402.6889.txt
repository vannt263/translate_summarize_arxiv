{
  "article_text": [
    "the world is filled with combinatorial problems .",
    "these include important combinatorial optimization tasks such as planning , scheduling and rostering , combinatorics problems such as extremal graph theory , and countless puzzles and games .",
    "solving combinatorial problems is hard , and all the methods we know to tackle them involve some kind of search .",
    "various _ declarative paradigms _ have been developed to solve such problems . in such approaches , objects and attributes that are searched for",
    "are represented by symbols , and constraints to be satisfied by those objects are represented as expressions over these symbols in a declarative language .",
    "solvers then search for values for these symbols that satisfy the constraints .",
    "this idea is found in the fields of   mycommoncitationcp @xcite ,   mycommoncitationasp @xcite , sat , mixed integer programming ( mip ) , etc . in the terminology of logic ,",
    "the declarative method amounts to expressing the desired properties of a problem class by sentences in a _",
    "logical theory_. the data of a particular problem instance corresponds naturally to a _ partial interpretation ( or structure)_. the solving process is to apply _ model generation _ , or more specifically _ model expansion _",
    "@xcite , the task of finding a structure that expands the input partial structure and satisfies the theory .",
    "the resulting structure is a solution to the problem .",
    "model generation / expansion , studied for example in the field of   mycommoncitationkr @xcite , is thus analogous to the task of solving constraint satisfaction problems , studied in , and that of generating answer sets of logic programs , studied in .",
    "the similarities between these areas go deeper and extend to the level of the used techniques .",
    "state - of - the - art approaches often follow a two - phase solving methodology . in a first phase , the input theory , in the rich language at hand ,",
    "is reduced into a fragment of the language that is supported by some search algorithm . in the second phase ,",
    "the search algorithm is applied to the reduced theory to effectively search for models .",
    "for example , model generation for the language minizinc   is performed by reducing to the ground language flatzinc , for which search algorithms are available .",
    "similarly , the language   mycommoncitationfodot @xcite is reduced to its propositional fragment  , and asp is reduced to propositional asp  .",
    "as the reduced theory is often in a ground fragment of the language , we refer to the resulting reduced theory as the _ grounding _ and to the first phase as the _ grounding _ phase ( where quantifiers are instantiated with elements in the domain ) . in other fields , grounding is also referred to as flattening , unrolling , splitting or propositionalization .",
    "the solving methodology itself is generally referred to as _ ground - and - solve_.    grounding becomes a bottleneck as users turn to applications with large domains and complex constraints .",
    "indeed , it is easy to see that the grounding size of an fo formula is exponential in the nesting depth of quantifiers and in the arity of predicates and polynomial in the size of the universe of discourse . there is an increasing number of applications where the size of the grounded theory is so large that it does not fit in memory .",
    "for example ,   discuss several applications where the ground - and - solve approach turns out to be inadequate .",
    "in this paper , we present a novel approach to remedy this bottleneck , called _ lazy model expansion _",
    ", where the grounding is generated lazily ( on - the - fly ) during search , instead of up - front .",
    "the approach works by associating _ justifications _ to the non - ground parts of the theory .",
    "a valid justification for a non - ground formula is a recipe to expand a partial structure into a more precise ( partial ) structure that satisfies the formula .",
    "of course , it is crucial that the recipe is a lot more compact than the grounding of the formula . given a partial structure and a valid justification for each of the non - ground formulas , a ( total ) structure is obtained by extending the partial structure with the literals in the justifications of the non - ground formulas .",
    "justifications are selected in such a way that this total structure is a model for the whole initial theory .",
    "consequently , model generation can be limited to the grounded part of the theory ; if a model is found for that part , it can be extended to a model of the whole theory .",
    "however , a new assignment during model generation can conflict with one of the justifications . in that case",
    ", an alternative justification needs to be sought .",
    "if none is found , the associated formula can be split in two parts , one part that is grounded and one part for which a valid justification is still available .",
    "[ ex : sokoban ] consider the ` sokoban ` problem , a planning problem where a robot has to push blocks around on a 2-d grid to arrange them in a given goal configuration .",
    "a constraint on the move action is that the target position @xmath0 of the moved block @xmath1 is currently ( at time @xmath2 ) empty , which can be expressed as @xmath3 as it is not known in advance how many time steps are needed , one ideally wants to assume a very large or even infinite number of steps . using ground - and - solve ,",
    "this blows up the size of the grounding .",
    "incremental grounding , iteratively extending the time domain until it is large enough to allow for a plan , has been developed to avoid the blow - up in the context of planning  .",
    "our approach is more general and does not depend on the presence of one domain that can be incrementally increased .",
    "returning to the example , instead of grounding sentence  ( [ ex : soko:1 ] ) , we associate with it a justification , a recipe to satisfy it .",
    "`` make @xmath4 false for all @xmath5 , @xmath6 and @xmath7 '' is such a recipe .",
    "when the search finds a model for the grounded part of the problem that is not in conflict with the recipe , the model can be extended with the literals in the recipe to obtain a model of the whole theory . however , if the search would decide to move block @xmath8 to position @xmath9 at time @xmath10 , a conflict is created with the recipe . to resolve it , the instance of sentence  ( [ ex : soko:1 ] ) that is in conflict with the partial model of the search is split off and sentence  ( [ ex : soko:1 ] ) is replaced by the equivalent sentences : @xmath11 sentence  ( [ ex : soko:2 ] ) is grounded and passed to the search component which will use it to check that @xmath12 holds .",
    "sentence  ( [ ex : soko:3 ] ) is non - ground and can be satisfied by the recipe `` @xmath4 is false except for @xmath13 '' .",
    "when the search makes more moves , more instances will be grounded , until the search finds a partial plan for the problem at hand .",
    "then the literals in the recipe of the remaining non - ground formula making @xmath4 false for all instances of sentence  ( [ ex : soko:1 ] ) that have not been grounded will complete the plan .",
    "the main contributions of this paper are :    * a theoretical framework for _ lazy model expansion_. by aiming at minimally instantiating quantified variables , it paves the way for a solution to the long - standing problem of handling quantifiers in search problems , encountered , e.g. , in the fields of  @xcite and sat modulo theories  @xcite .",
    "the framework also generalizes existing approaches that are related to the grounding bottleneck such as incremental domain extension  @xcite and lazy clause generation   mycommoncitationlazyclausegeneration @xcite . * a complete algorithm for lazy model expansion for the logic , the extension of with inductive definitions  .",
    "this includes efficient algorithms to derive consistent sets of justifications and to maintain them throughout changes in a partial structure ( e.g. , during search ) . *",
    "an implementation extending the knowledge - base system   and experiments that illustrate the power and generality of lazy grounding .",
    "lazy grounding is a new step in our ability to solve complex combinatorial problems . by avoiding the up - front grounding step of previous approaches",
    ", lazy grounding can ground enough of the problem to solve it . while our method is developed for the logic ,",
    "as will become clear , justifications are associated with rules , and these rules are very similar to the rules used by asp systems . hence ,",
    "as discussed towards the end of the paper , our framework and algorithms can be applied also in the context of .",
    "the paper is organized as follows . in section  [ sec : preliminaries ] , the necessary background and notations are introduced .",
    "formal definitions of lazy grounding with are presented in section  [ sec : theory ] , followed by a presentation of the relevant algorithms and heuristics in sections  [ sec : algorithms ] and  [ sec : optimizations ] .",
    "experimental evaluation is provided in section  [ sec : experiments ] , followed by a discussion on related and future work and a conclusion . a preliminary version of the paper appeared as the work of and of .",
    "in this section , we provide the necessary background on the logic , on the inference tasks model generation and model expansion for and on the ground - and - solve approach to model expansion .",
    "[ [ section ] ]    first , we define syntax and semantics of the logic _",
    "_   mycommoncitationfodot @xcite , the extension of with inductive definitions .",
    "we assume familiarity with . without loss of generality , we limit to the function - free fragment .",
    "function symbols can always be eliminated using graph predicates  @xcite .",
    "a ( function - free ) vocabulary @xmath14consists of a set of predicate symbols .",
    "propositional symbols are 0-ary predicate symbols ; these include the symbols @xmath15and @xmath16 , denoting _ true _ and _ false _ respectively .",
    "predicate symbols are usually denoted by @xmath17 , @xmath18 , @xmath19 ; atoms by @xmath20 , literals ( atoms or their negation ) by @xmath21 ; variables by @xmath22 , @xmath23 ; and domain elements by @xmath24 . with @xmath25",
    "we denote an ordered set of objects @xmath26 ; with @xmath27 a predicate @xmath17 of arity @xmath28 .    the methods for model generating developed below require that a ( possibly infinite ) domain @xmath29 is given and fixed .",
    "given a ( function - free ) vocabulary @xmath30 , a _ domain atom _ is an atom of the form @xmath31 with @xmath32 and @xmath33 , an @xmath28-tuple of domain elements .",
    "likewise , we consider _",
    "domain literals_.    a structure @xmath34interpreting @xmath14consists of the domain @xmath29 and an @xmath28-ary relation @xmath35 for all predicate symbols @xmath36 .",
    "alternatively , an @xmath28-ary relation can be viewed as a function @xmath37 .",
    "the propositional symbols @xmath15and @xmath16are respectively interpreted as @xmath38and @xmath39 .    model generation algorithms maintain _ partial _ structures and may ( temporarily ) find themselves in an _ inconsistent _ state , for example when a conflict arises . to represent such states , three - valued and four - valued structures @xmath40 are introduced ; they consist of the domain @xmath29 and , for each @xmath28-ary predicate @xmath17 in @xmath14 , of a three- or four - valued relation @xmath41 .",
    "this is a function @xmath42 .",
    "a structure is _ two - valued _ if the range of its relations is @xmath43 , _ partial _ or _ three - valued _ if the range is @xmath44 ) and four - valued in general .",
    "thus , two - valued structures are also three - valued and four - valued .",
    "when unqualified , the term _ structure _ stands for the most general , four - valued case .    given a fixed @xmath29 and @xmath30 , an alternative way to represent @xmath40 is as a set @xmath45 of domain literals .",
    "indeed , there is a one - to - one correspondence between such sets @xmath45 and @xmath30-structures @xmath40 with domain @xmath29 such that for a domain atom @xmath20 , @xmath46 ( inconsistent ) if both @xmath20 and @xmath47 are in @xmath45 , @xmath48 if only @xmath20 is in @xmath45 , @xmath49 if only @xmath47 is in @xmath45 and @xmath50 ( unknown ) otherwise .",
    "hence , we may treat four - valued structures as sets of domain literals and vice versa .",
    "a structure is _ inconsistent _ if at least one domain atom is inconsistent .",
    "a structure @xmath40 of a vocabulary @xmath30 can be naturally viewed as a structure of a larger vocabulary @xmath51 , namely by setting @xmath50 for any domain atom of a predicate in @xmath52 .    for a set @xmath53 of predicate symbols",
    ", we use @xmath54 to denote the restriction of @xmath40 to the symbols of @xmath53 . for a set @xmath45 of domain atoms",
    ", we use @xmath55 to denote the restriction of @xmath40 to @xmath45 : @xmath56 if @xmath57 and @xmath58 otherwise .",
    "we call @xmath40 a two - valued structure of @xmath45 if @xmath40 is two - valued on domain atoms of @xmath45 and unknown otherwise",
    ".    the inverse @xmath59 of a truth value @xmath60 is defined as follows : @xmath61 , @xmath62 , @xmath63 and @xmath64 .",
    "the _ truth _ order @xmath65 on truth values is defined by @xmath66 and @xmath67 .",
    "the _ precision _",
    "order @xmath68 is defined by @xmath69 and @xmath70 .",
    "both orders are pointwise extended to arbitrary @xmath14-structures .",
    "we say that @xmath34 is an _ expansion _ of @xmath34if @xmath71 , that is if for each domain atom @xmath20 , @xmath72 .",
    "viewing structures as sets of domain literals , this corresponds to @xmath73 .",
    "we assume familiarity with the syntax of ( function - free ) . to facilitate the reasoning with partially grounded formulas , we deviate from standard and quantify over explicitly specified subsets of the domain @xmath29",
    "this is denoted as @xmath74 and @xmath75 , with @xmath76 .",
    "we sometimes abbreviate @xmath77 as @xmath78 , and similarly for @xmath79 . given a formula @xmath80 ,",
    "@xmath81 $ ] indicates that @xmath82 are the free variables of @xmath80 .",
    "substitution of a variable @xmath22 in formula @xmath80by a term @xmath7 is denoted by @xmath83 $ ] .",
    "a _ ground formula _ ( in domain @xmath29 ) is a formula without variables ( hence without quantifiers ) .",
    "similar properties and notations are used for _ rules _ ( introduced below ) .",
    "we denote by @xmath84 the set of all predicate symbols that occur in theory @xmath85 . for a structure @xmath40",
    ", @xmath86 is the set of symbols interpreted by @xmath40 . unless specified otherwise , theories and structures range over the vocabulary @xmath14 .",
    "the language extends fo with ( inductive ) _",
    "definitions_. a theory in is a ( finite ) set of sentences and definitions . a definition @xmath87is a ( finite ) set of rules of the form @xmath88 , with @xmath17 a predicate symbol and @xmath80an fo formula . the atom @xmath89 is referred to as the _ head _ of the rule and @xmath80as the _",
    "body_. given a rule @xmath90 , we let @xmath91 and @xmath92 denote respectively the head and the body of @xmath90 .",
    "given a definition @xmath87 , a domain atom @xmath31 is _ defined _ by @xmath93 if there exists a rule @xmath94 in @xmath93 such that @xmath95 .",
    "otherwise @xmath31 is _ open _ in @xmath87 .",
    "a domain literal @xmath96 is defined by @xmath87if @xmath31 is defined by @xmath87 .",
    "the sets of defined and open domain atoms of @xmath87are denoted as @xmath97 and @xmath98 , respectively .    without loss of generality",
    ", we assume that in any definition a domain atom is defined by at most one rule .",
    "technically , this means that rules @xmath99 , @xmath100 are pairwise disjunct , that is @xmath101 .",
    "rules can always be made disjunct by transforming them in @xmath102 , @xmath103 , @xmath104 .",
    "the semantics of is a two - valued model semantics .",
    "nevertheless , we introduce concepts of three- and four - valued semantics which are useful in defining the semantics of definitions and in formalizing lazy grounding .",
    "we use the standard four - valued truth assignment function , defined by structural induction for pairs of domain formulas @xmath105 and structures @xmath40 that interpret @xmath105 :    * @xmath106 , * @xmath107 , * @xmath108 , * @xmath109 , * @xmath110^{{\\ensuremath{\\mathcal{i}}\\xspace}}\\mid d\\in d\\})$ ] , * @xmath111^{{\\ensuremath{\\mathcal{i}}\\xspace}}\\mid d\\in d\\})$ ] .",
    "the assignment function is monotonic in the precision order : if @xmath112 , then @xmath113 .",
    "hence , if a formula is true in a partial structure , it is true in all two - valued expansions of it .",
    "also , if @xmath40 is two - valued ( respectively three - valued , four - valued ) then @xmath114 is two - valued ( respectively three - valued , four - valued ) .",
    "a structure @xmath34is a _ model _ of / _ satisfies _ a sentence @xmath80(notation @xmath115 ) if @xmath34is two - valued and @xmath116 .",
    "the satisfaction relation can be defined for definitions as well .",
    "the semantics of definitions is based on the parametrized well - founded semantics , an extension of the well - founded semantics of logic programs informally described first in the work of  , and formally defined for s definitions by  .",
    "this semantics formalizes the informal semantics of rule sets as ( inductive ) definitions  @xcite .",
    "a structure @xmath34is a _ model _ of / _ satisfies _ a definition @xmath87(notation @xmath117 ) if @xmath34is two - valued and is the well - founded model denoted as @xmath118 of @xmath87 in the structure @xmath119  @xcite . in case @xmath118",
    "is not two - valued , @xmath93 has no model expanding @xmath120 .",
    "a structure @xmath34satisfies a theory @xmath121if @xmath34is two - valued and @xmath34is a model of all sentences and definitions in @xmath121 . in the next subsection , we present a formalization of the well - founded semantics using the notion of _ justification_.",
    "according to s methodology , ( formal ) definitions are used to express informal definitions . in the work of",
    ", it was shown that definitions offer a uniform representation of the most important types of informal definitions and that expressing informal definitions leads to rule sets that are _",
    "total_. formally , a definition @xmath87is called _ total _ if the well - founded model of @xmath87 in each two - valued structure @xmath34of @xmath122 is two - valued  @xcite .",
    "in general , totality is undecidable ; however broad , syntactically defined classes of definitions have been proven to be total  .",
    "inspection of current applications shows that in practice , non - total definitions occur rarely and almost always contain a modeling error .",
    "also , in most cases totality can be established through a simple syntactic check .",
    "totality can be usefully exploited during computation .",
    "the lazy grounding techniques introduced below exploit totality and should be applied only to total definitions .",
    "this restriction matches with s design and methodology and , in practice , this does not impose a strong limitation . in case",
    "the input theory does contain definitions that are not known to be total , all is not lost : those definitions can be grounded completely up - front , in which case lazy grounding can be applied safely to the remaining sentences and total definitions in the input .",
    "[ [ equivalence . ] ] equivalence .",
    "+ + + + + + + + + + + +    two theories @xmath85 and @xmath123 , which can be over different vocabularies , are _",
    "@xmath14-equivalent _ if each model of @xmath85 restricted to @xmath14 can be expanded to a model of @xmath123 and vice versa .",
    "two theories @xmath85 and @xmath123 are _ strongly @xmath14-equivalent _ if the above expansions are also unique . by extension , ( strong ) @xmath14-equivalence _ in a structure @xmath34 _ is defined similarly : if each model of @xmath85 expanding @xmath40 can be expanded to a model of @xmath123 expanding @xmath34and vice versa ; to obtain strong equivalence , these expansions have to be unique . from a theory @xmath85",
    ", we often derive a _ strongly _ @xmath84-equivalent theory @xmath123 in a given structure @xmath40 .",
    "such transformations preserve satisfiability and number of models _ and _ each model of @xmath123 can be directly mapped to a model of @xmath85 by projection on @xmath84 .",
    "[ [ canonical - theories . ] ] canonical theories .",
    "+ + + + + + + + + + + + + + + + + + +    to simplify the presentation , the lazy grounding techniques are presented here for theories of the form @xmath124 , with @xmath125 a propositional symbol , and @xmath93 a single definition with function - free rules .",
    "this is without loss of generality .",
    "first , as mentioned above , standard techniques  @xcite allow one to make a theory function - free .",
    "second , multiple definitions can always be combined into one as described by   and  .",
    "this is achieved by renaming defined predicates in some of the definitions , merging all rules into one set and adding equivalence constraints between predicates and their renamings .",
    "third , the theory @xmath126 resulting from the previous step can be translated to the strongly @xmath127-equivalent theory @xmath128 with @xmath129a new propositional symbol .",
    "this transformation results in a ground set of sentences and a definition consisting of a set of ( ground and non - ground ) rules , so lazy grounding has only to cope with non - ground rules .",
    "furthermore , we assume that rule bodies are in negation normal form ( negation only occurs in front of atoms ) and that , for each defined domain atom @xmath31 , there is a unique rule @xmath130 such that @xmath131 .",
    "the methods proposed below can be extended to full with functions , and such extended methods have been implemented in our system .",
    "however , this introduces a number of rather irrelevant technicalities which we want to avoid here .",
    "we assume the presence of a domain @xmath29 and a canonical theory @xmath132 as explained above .",
    "recall , structures with domain @xmath29 correspond one - to - one to sets of domain literals .",
    "a _ direct justification _ for a defined domain literal @xmath31 ( respectively @xmath133 ) is a consistent non - empty set @xmath45 of domain literals such that , for the rule @xmath134 of @xmath93 such that @xmath95 , it holds that @xmath135^s = { { { \\ensuremath{{\\bf t}}\\xspace}}}$ ] ( respectively @xmath135^s = { { { \\ensuremath{{\\bf f}}\\xspace}}}$ ] ) .",
    "any consistent superset @xmath136 of a direct justification @xmath45 of @xmath31 is a direct justification as well .",
    "indeed , a body @xmath135 $ ] true in @xmath45 is true in the more precise @xmath136 . also , a direct justification @xmath45 is not empty by definition ; if @xmath105 is true in every structure , then a minimal direct justification is @xmath137 .",
    "[ ex : justif1 ] consider a domain @xmath138 and the definition @xmath87@xmath139 a direct justification for @xmath140 is @xmath141 and for @xmath142 is @xmath143 .",
    "both domain literals have many other direct justifications , but those are the unique minimal ones under the subset relation .",
    "minimal direct justifications for @xmath144 are both @xmath145 and @xmath146 while the only minimal direct justification for @xmath147 is @xmath148 .",
    "atoms @xmath149 are open and have no direct justification .    a ( directed ) graph @xmath150 is a pair @xmath151 of a set @xmath152 of nodes and a set @xmath153 of directed edges , i.e. , ordered pairs @xmath154 of nodes .",
    "for any node @xmath155 , we denote by @xmath156 the set of children of @xmath60 , i.e. , @xmath157 .    a _ justification _ over a definition @xmath87is a graph @xmath158 over the set of domain literals of @xmath87such that for each domain literal @xmath21 , @xmath159 is either empty or a direct justification of @xmath21 .",
    "thus , a justification is a graph that encodes for every defined domain literal none or one direct justification . in the sequel",
    "we say that @xmath158 is _ defined in @xmath21 _ if @xmath160 .",
    "a justificationis denoted as a set of pairs @xmath161 , with @xmath45 a direct justification of @xmath21 .",
    "let @xmath162be a justificationover @xmath87 .",
    "the justification__for a literal _ _ @xmath21 is the subgraph @xmath163 of nodes and edges of @xmath158 reachable from @xmath21 .",
    "the justification__for a set of literals _ _ @xmath164 is the subgraph @xmath165 of nodes and edges of @xmath158 reachable from any @xmath166 .",
    "a justification@xmath162over @xmath87is _ total for _ @xmath21 if @xmath158 is defined in each literal that is reachable from @xmath21 and defined in @xmath87 ; it is _ total for a set of literals _ @xmath164 if it is total for each literal in @xmath164 . a justification@xmath162is _ consistent with _ a structure @xmath34if @xmath34is consistent and none of the literals for which @xmath162is defined is false in @xmath34 .",
    "if @xmath162is total for @xmath21 , then the leaves of @xmath163 are open domain literals .    a path in a justification@xmath162is a sequence @xmath167 such that , if @xmath168 , then there is an edge from @xmath169 to @xmath170 in @xmath162 .",
    "a path is _ positive _ if it consists of only positive literals ; it is _ negative _ if it consists of only negative literals ; it is _ mixed _ otherwise .",
    "cycle _ in a justification@xmath162is a set of domain literals on a path in @xmath162that starts and ends in the same domain literal .",
    "a cycle is positive ( respectively , negative ) if all domain literals are positive literals ( respectively , negative literals ) ; otherwise the cycle is mixed .",
    "an infinite path may be cyclic or not .",
    "if @xmath29 is finite , every infinite path is cyclic .",
    "intuitively , a justification @xmath158 containing a domain literal @xmath21 provides an argument for the truth of @xmath21 .",
    "the strength of this argument depends on the truth of the leaves and on the infinite paths and cycles in @xmath163 .",
    "if all leaves are true and every infinite path is negative , @xmath163 provides the argument that @xmath21 is true .",
    "if a leaf is false or unknown , or @xmath163 contains a positive or mixed loop , the argument for @xmath21 is weak .",
    "notice that other justifications for @xmath21 may still argue @xmath21 s truth .",
    "[ def : justifies ] we say that a defined literal @xmath21 is _ well - founded _ in the justification @xmath158 if every infinite path in @xmath163 is negative .",
    "otherwise @xmath21 is _ unfounded _ in @xmath162 .",
    "a justification@xmath158 over @xmath87__justifies _ _ a set of literals @xmath164 defined in @xmath87(the set @xmath164 of literals _ has a justification _",
    "@xmath158 ) if ( * i * ) @xmath165 is total for @xmath164 ; ( * ii * ) each literal of @xmath164 is well - founded in @xmath158 ; ( * iii * ) the set of literals in @xmath165 is consistent .",
    "[ ex : justif2 ]    ( pd1 ) @xmath171 ; ( qd1 ) @xmath172 ;    ( pd1 ) edge[->,bend left=-50 ] ( qd1 ) ; ( qd1 ) edge[->,bend left=-50 ] ( pd1 ) ;    \\(i ) ( i ) ; ( pd2 ) @xmath171 ; ( rd2 ) @xmath173 ; ( qd2 ) @xmath172 ;    ( pd2 ) edge[->,bend left=0 ] ( rd2 ) ; ( qd2 ) edge[->,bend left=0 ] ( pd2 ) ;    \\(ii ) ( ii ) ; ( pd3 ) @xmath171 ; ( qd3 ) @xmath172 ; ( qd3 ) edge[->,bend left=-50 ] ( pd3 ) ;    \\(iii ) ( iii ) ; ( npd4 ) @xmath174 ; ( nqd4 ) @xmath175 ; ( nrd4 ) @xmath176 ;    ( npd4 ) edge[->,bend left=0 ] ( nqd4 ) ; ( npd4 ) edge[->,bend left=0 ] ( nrd4 ) ; ( nqd4 ) edge[->,bend left=-50 ] ( npd4 ) ;    \\(iv ) ( iv ) ;    in figure  [ fig : justex ] , we show a few possible justifications ( ordered ( i)-(iv ) from left to right ) over definition @xmath87 in example  [ ex : justif1 ] that contain the defined domain atoms @xmath171 and @xmath172 ( @xmath177 ) . justification ( ii ) justifies @xmath171 and @xmath172 and ( iv ) justifies @xmath174 and @xmath175 ; ( iii ) , however , is not total for @xmath171 nor @xmath172 and ( i ) has a positive cycle and is unfounded for both @xmath171 and @xmath172 .    the relationship between justifications and the well - founded semantics has been investigated in different publications  @xcite . below we recall the results on which this paper relies .",
    "the first result states that if @xmath162justifies all literals in @xmath164 , then any model @xmath40 of @xmath93 in which the leaves of @xmath165 are true , satisfies all literals in @xmath164 and in @xmath165 .",
    "[ prop : just ] if @xmath162is a justificationover @xmath87that justifies a set of domain literals @xmath164 then all literals in @xmath165 are true in every model of @xmath93 in which the ( open ) leaves of @xmath165 are true .    for an interpretation @xmath178 that is two - valued for @xmath122 , the well - founded model @xmath179 can be computed in time polynomial in the size of the domain , as shown by  . in general",
    ", @xmath179 is a three - valued structure .",
    "if @xmath179 is two - valued , then it is the unique model of @xmath93 that expands @xmath178 ; otherwise , @xmath87has no model that expands @xmath178 .",
    "the above proposition follows from the fact that if a justification @xmath162justifies @xmath164 and all leaves of @xmath162are true in @xmath178 , then all literals of @xmath164 are true in @xmath179 .",
    "justification ( ii ) justifies @xmath180 and has a unique open leaf @xmath173 .",
    "for any structure @xmath178 interpreting the open predicates of @xmath93 , if @xmath173 is true in @xmath178 , then @xmath172 is true in @xmath179 . in particular , in any model of @xmath87 in which @xmath173 is true , @xmath172 is true .    [",
    "prop : justbis ] if @xmath40 is a model of @xmath87 , then a justification@xmath162over @xmath87exists that consists of literals true in @xmath34 , is defined for all defined domain literals true in @xmath40 and justifies each of them .",
    "[ cor : voila ] in case @xmath87is total , if a justification@xmath162over @xmath87justifies a set of domain literals @xmath164 , then every two - valued @xmath181-structure consistent with @xmath165 can be extended in a unique way to a model of @xmath87that satisfies all literals of @xmath164 .",
    "hence , for a canonical theory @xmath124 ( recall , @xmath87is total ) , the theory is satisfiable iff a justification @xmath162exists that justifies @xmath129 .",
    "_ model generation _ is the inference task that takes as input a theory @xmath121and returns as output a model of @xmath121 .",
    "was defined by   as the inference task that takes as input a theory @xmath121over vocabulary @xmath14and a two - valued structure @xmath34over a subvocabulary of @xmath30 , and returns an expansion @xmath182of @xmath34that satisfies @xmath121 . here , it will be the more general inference problem as defined by   that takes as input a ( potentially partial ) structure @xmath34over @xmath14 , and returns an expansion @xmath182of @xmath34that satisfies @xmath121 .    as already mentioned , the state - of - the - art approach to model expansion in is ( similar to ) grounding @xmath121 in the context of @xmath34and afterwards applying search to the resulting ground theory .",
    "the latter can , e.g. , be accomplished by the sat(id ) search algorithm  .",
    "below , we present the grounding algorithm that is the basis of the lazy algorithm .",
    "we assume familiarity with the basic algorithm of sat solvers  @xcite .",
    "for an overview of intelligent grounding techniques in , we refer the reader to the work of   and of  .",
    "below we present the basic principle .",
    "a grounder takes as input a theory @xmath121over vocabulary @xmath14 , a partial structure @xmath34with domain @xmath29 , interpreting at least @xmath15and @xmath16 , and returns a ground theory @xmath183 that is strongly @xmath30-equivalent with @xmath121 in @xmath34 .",
    "theory @xmath183 is then called a _ grounding _ of @xmath121given @xmath34 .",
    "recall that we assume that @xmath121is a canonical theory of the form @xmath124 .",
    "one way to compute the grounding is using a top - down process on the theory , iteratively applying grounding steps to direct subformulas of the rule or formula at hand .",
    "the grounding algorithm may replace subformulas by new predicate symbols as follows .",
    "let @xmath81 $ ] be a formula in @xmath121and let @xmath184be the domains of @xmath185 .",
    "a _ tseitin transformation _ replaces @xmath80by the atom @xmath186 , with @xmath187 a new @xmath188-ary predicate symbol called a _",
    "tseitin _ symbol , and extends @xmath87with the rule @xmath189 .",
    "the new theory is strongly @xmath14-equivalent to the original one  .",
    "the procedure , outlined in figure [ fig : onestepground ] , performs one step in the grounding process . called with a formula or rule @xmath105 in canonical form , the algorithm replaces all direct subformulas with tseitin symbols and returns a pair consisting of a ground part @xmath150 ( rules or formulas ) and a possibly non - ground part @xmath19 ( rules ) . if @xmath105 is a formula , then @xmath150 consists of ground formulas . replacing @xmath105 by the returned ground formulas and extending @xmath87with the returned rules produces a theory that is strongly @xmath127-equivalent to the original .",
    "if @xmath105 is a rule from @xmath87 , @xmath150 consists of ground rules , and replacing @xmath80by both sets of returned rules results again in a theory that is strongly @xmath127-equivalent to the original .",
    "grounding a theory then boils down to applying on the sentence @xmath129(which copies @xmath129to the ground part ) and on each rule of the theory and repeatedly applying on the returned rules @xmath19 ( all returned sentences and rules in @xmath150 are ground ) .",
    "we use to refer to the algorithm for this overall process .",
    "various improvements exist , such as returning @xmath15/@xmath16for atoms interpreted in @xmath34and returning @xmath16from conjunctions whenever a false conjunct is encountered ( analogously for disjunctions and quantifications ) .",
    "also , algorithm introduces a large number of tseitin symbols .",
    "state - of - the - art grounding algorithms use a number of optimizations to reduce the number of such symbols . as",
    "these optimizations are not directly applicable to the techniques presented in this paper , we start from the naive algorithm . in section",
    "[ sec : optimizations ] , we present an optimized version of that introduces fewer tseitin symbols and hence results in smaller groundings .",
    "we use the term _ lazy grounding _ to refer to the process of partially grounding a theory and the term _ lazy model expansion _",
    "( lazy mx ) for the process that interleaves lazy grounding with model expansion over the grounded part . in section",
    "[ sec : lazy - foid ] , we formalize a framework for lazy model expansion of theories ; in section  [ sec : default ] , we formalize the instance of this framework that is the basis of our current implementation ; in section  [ sec : lazyexample ] , we illustrate its operation .      given a canonical theory @xmath190 and an input structure @xmath191 , models expanding @xmath191are searched for by interleaving lazy grounding with search on the already grounded part .",
    "we first focus on the lazy grounding .",
    "apart from the initial step that moves @xmath129to the grounded part , the input of each step consists of a set of rules still to be grounded , an already grounded theory and a three - valued structure that is an expansion of the initial input structure .",
    "each subsequent grounding step can replace non - ground rules by ground rules and might introduce new rules .",
    "hence , the state of the grounding includes a set @xmath192of ground rules and a set @xmath193(the _ delayed definition _ ) of ( possibly ) non - ground rules .",
    "the definitions have the property that @xmath194 ( in what follows abbreviated as @xmath195 ) is @xmath196-equivalent with the original definition @xmath87and hence , @xmath195is total .",
    "the grounding procedure will guarantee that , at all times , @xmath192and @xmath193are total . given a partial structure @xmath191and the rule sets @xmath192and @xmath193 , the key idea behind",
    "lazy model expansion is ( * i * ) to use a search algorithm to search for a model @xmath34of @xmath192that is an expansion of @xmath191 in which @xmath129is true ; ( * ii * ) to maintain a justification@xmath162such that the literals true in @xmath34and defined in @xmath193are justified over @xmath195and that @xmath162is consistent with @xmath34 ; ( * iii * ) to interleave steps ( * i * ) and ( * ii * ) and to move parts of @xmath193to @xmath192when some literal defined in @xmath193that needs to be justified can not be justified .",
    "thus , to control lazy model expansion , it suffices to maintain a state @xmath197 consisting of the grounded rules @xmath192 , the rules @xmath193yet to be grounded , a justification@xmath162 , and a three - valued structure @xmath34 .",
    "initially , @xmath40 is @xmath198 , @xmath199 is @xmath93 , @xmath200 , and @xmath162is the empty graph",
    ".    lazy model expansion searches over the space of _ acceptable _ states .",
    "[ def : acc_state ] a tuple @xmath197 of a theory with an atomic sentence @xmath129 , a total definition @xmath87 , and an input structure @xmath191is an _ acceptable _ state if ( * i * ) @xmath195 , @xmath192and @xmath193are total definitions and @xmath195is strongly @xmath196-equivalent with @xmath87 , ( * ii * ) no domain atom is defined in both @xmath192and @xmath193 , ( * iii * ) @xmath162is a justificationover @xmath195 , ( * iv * ) @xmath34is an expansion of @xmath191 , ( * v * ) the set @xmath164 of literals true in @xmath34and defined in @xmath193is justified by @xmath162 , and ( * vi * ) @xmath165 , the justification of the literals in @xmath164 , is consistent with @xmath34 .",
    "[ ex : cons ] consider the theory @xmath124 , with @xmath87the definition     +   +   +   +    let @xmath34be the structure @xmath201 ( hence , @xmath202 and @xmath203 are unknown ) , and @xmath192and @xmath193the definitions consisting of the first rule and the remaining rules , respectively .",
    "furthermore , let @xmath162be @xmath204 .",
    "the tuple @xmath205 is then an acceptable state .",
    "indeed , @xmath206 is the only literal in @xmath34that is defined in @xmath193and it is justified by @xmath162 .",
    "as already said , the lazy model expansion algorithm starts from the initial state @xmath207 , which is acceptable if defined literals are unknown in @xmath198 . in each state",
    ", it either refines @xmath40 by propagation or choice , or it backjumps .",
    "if the resulting state is unacceptable , a repair operation restores acceptability ; these steps are described in section  [ sec : default ] .",
    "the algorithm tries to compute an acceptable state in which @xmath129is justified in @xmath208 . by corollary  [ cor : voila ] , this would entail that a model of @xmath121exists ; it can be computed efficiently through well - founded model computation . in intermediate states",
    ", the justification may be non - total for @xmath129 , contain unfounded literals , or be inconsistent .",
    "note that , in ( * iii * ) , the justificationmust be over @xmath195 . indeed , assume some literal @xmath21 is justified over @xmath193 .",
    "its justification graph can have a leaf that is defined in @xmath192and that depends positively or negatively on @xmath21 . then",
    "every attempt to extend this justification graph to a total justification graph that justifies @xmath21 over @xmath195might fail , e.g. , because of a forbidden cycle .",
    "consider , e.g. , the definitions @xmath209 and @xmath210 . in that case",
    ", it would not be correct to take @xmath17 as justification for @xmath18 being true , even though it is a valid justification within @xmath193 .",
    "indeed , no model exists that justifies @xmath18 in the full definition @xmath195 .",
    "[ prop : model ] let @xmath197 be an acceptable state .",
    "@xmath195has a well - founded model that expands the literals that are true in @xmath40 and defined in the ( delayed ) definition @xmath193 .",
    "let @xmath164 be the set of literals true in @xmath40 and defined in @xmath193 .",
    "as the state is acceptable , @xmath162justifies the literals of @xmath164 .",
    "hence , by corollary  [ cor : voila ] , there exists a well - founded model that expands @xmath164 .    the well - founded evaluation , after assigning @xmath15to the open literals of @xmath162(i.e .",
    ", to @xmath211 ) , derives that @xmath206 is true .",
    "moreover , because @xmath34is a model of @xmath192 , @xmath129is also true in such a well - founded model .",
    "note that @xmath19 can be interpreted randomly , as no @xmath19-atoms occur in @xmath34or @xmath162 .",
    "the following theorem states when the obtained expansion is also a model of @xmath121 .",
    "[ theo : acceptablemodel ] let @xmath197 be an acceptable state of a theory @xmath212 with input structure @xmath191such that @xmath129is true in @xmath34and @xmath213 is a model of @xmath192 .",
    "then there exists a model @xmath182of @xmath121that expands @xmath213 .",
    "@xmath213 is a model of @xmath214 .",
    "it follows from proposition  [ prop : justbis ] that there exists a justification @xmath215 over @xmath214 that justifies every true defined literal of @xmath214 and that consists of only domain literals true in @xmath213 .",
    "we now have two justifications : @xmath158 and @xmath215 .",
    "we combine them in one @xmath216 as follows : for each defined literal @xmath21 of @xmath208 , if @xmath158 is defined in @xmath21 , we set @xmath217 ; otherwise , we set @xmath218 . as @xmath219 takes edges from either @xmath162 or @xmath220 for each defined literal , it is a justification for @xmath195 .",
    "we verify that @xmath216 justifies @xmath129 .",
    "first , it is total in @xmath129 .",
    "indeed , any path from @xmath129either consists of literals defined in @xmath192 , and then it is a branch of the total @xmath215 over @xmath192 , or it passes to a literal @xmath221 defined in @xmath193 , which is justified by @xmath158 according to condition ( * v * ) and hence @xmath222 is total . as such , from @xmath129we can not reach a defined literal of @xmath195 in which @xmath216 is undefined .",
    "second , @xmath216 does not contain unfounded literals starting from @xmath129 .",
    "this is because any path from @xmath129is either a path in @xmath215 ( so well - founded as it justifies @xmath192 ) or it has a tail in @xmath162(well - founded by property ( * v * ) ) .",
    "finally , the set of literals reachable from @xmath129 in @xmath216 is consistent .",
    "also this we can see if we look at paths in @xmath216 from @xmath129 : at first we follow @xmath215 which consists of true literals in @xmath40 , then we may get into a path of @xmath162which contains literals that are consistent with @xmath40 . in any case , it is impossible to reach both a literal and its negation .",
    "it follows from proposition  [ prop : just ] that there exists a model of @xmath195that expands @xmath213 and in which @xmath129is true .",
    "since @xmath195is strongly equivalent with @xmath87 , the proposition follows .",
    "recall that effectively computing such a model @xmath182can be achieved by well - founded evaluation of @xmath195 , with polynomial data complexity , starting from any two - valued @xmath223-structure expanding @xmath213  @xcite .    in the above theorem",
    ", it is required that @xmath34is a model of @xmath192 .",
    "actually , we do not need to compute a two - valued model of @xmath192 .",
    "it suffices to search for a partial structure and a justificationthat justifies @xmath129 .",
    "so , we can relax this requirement at the expense of also maintaining justifications for literals true in @xmath34and defined in @xmath192 .",
    "[ col : acceptable ] let @xmath197 be an acceptable state of a theory @xmath224 with input structure @xmath191such that @xmath129is true in @xmath34and @xmath162justifies @xmath129over @xmath195",
    ". then there exists a model @xmath182of @xmath121that expands @xmath55 with @xmath45 the set of defined literals in @xmath225 .",
    "failure to find a model of @xmath192expanding @xmath191 in which @xmath129is true implies the lack of models of @xmath121expanding @xmath191 .",
    "indeed , if @xmath192has no model expanding @xmath191 , then it has an unsatisfiable core , i.e. , a set of rules from @xmath192such that no model exists that expands @xmath191 . hence , it is also an unsatisfiable core for @xmath226 . to find an unsatisfiable core , one can , for example , use techniques described by",
    "roughly speaking , our lazy model expansion framework consists of two components . on the one hand , a standard model expansion algorithm that operates on @xmath227 and , on the other hand , a justification manager that maintains a justificationover @xmath195and lazily grounds @xmath193 .",
    "lazy model expansion performs search over the space of acceptable states and aims at reaching a state where theorem  [ theo : acceptablemodel ] ( or corollary  [ col : acceptable ] ) is applicable . to avoid slowing down the search during model expansion , the work done by the justification manager and the lazy grounding must be limited . to achieve this ,",
    "we have designed a system in which the justification manager has no access to the grounded definition @xmath192and need not restore its state when the search algorithm backtracks over the current structure @xmath34 .",
    "the justification manager only has access to @xmath34and maintains justifications that are restricted to @xmath193 .",
    "in particular , a literal defined in @xmath192is not allowed in a direct justification . our justification manager maintains the following properties :    * literals in direct justifications are either open in @xmath195or defined in @xmath193 . *",
    "all direct justifications in @xmath162are kept consistent with each other and with the current structure @xmath34 .",
    "* the justification graph defined by @xmath162has no unfounded literals and is total .    to distinguish acceptable states that meet these additional requirements from acceptable states as defined in definition  [ def : acc_state ]",
    ", we call them _ default acceptable states _ ; we define them as :    [ def : default_acc_state ] a state @xmath197 is a default acceptable state if it is an acceptable state and , in addition , ( * i * ) literals in direct justifications are either open in @xmath195or defined in @xmath193 , and ( * ii * ) @xmath162justifies the set of all literals for which @xmath158 is defined .",
    "it follows that default acceptable states satisfy two extra conditions : they do not justify literals defined in @xmath193 in terms of literals defined in @xmath192 , and the set of all literals in @xmath162is consistent . for an acceptable state , it suffices that the literals in @xmath162that are true in @xmath34and defined in @xmath193 , are consistent . since default",
    "acceptable states are acceptable states , theorem  [ theo : acceptablemodel ] and corollary  [ col : acceptable ] also hold for default acceptable states .    during standard model expansion ,",
    "the main state - changing operations are to make @xmath34more precise ( by making literals true , either through choice or propagation ) and to make @xmath34less precise ( by backjumping ) .",
    "when @xmath228 is a default acceptable state and model expansion modifies @xmath34into @xmath34 , the new state @xmath229 is not necessarily a default acceptable state .",
    "the following propositions identify situations where acceptability is preserved .",
    "[ prop : forward ] let @xmath205 be a default acceptable state , @xmath164 a set of literals unknown in @xmath34and @xmath230 the consistent structure @xmath231 . if ( * i * ) literals of @xmath164 either are not defined in @xmath193or have a direct justification in @xmath162and ( * ii * ) no direct justification in @xmath162contains the negation of a literal in @xmath164 , then @xmath232 is a default acceptable state .    as the literals true in @xmath34and",
    "defined in @xmath193have a direct justification , it follows from ( * i * ) that all literals true in @xmath34 and defined in @xmath193have a direct justification . as justifications in @xmath162are consistent with @xmath34 , then , by ( * ii * ) , they are also consistent with @xmath34. hence , @xmath162justifies all literals true in @xmath34 and defined in @xmath193 .    [ prop : backward ] let @xmath205 be a default acceptable state",
    ". then @xmath232 with @xmath233 is a default acceptable state .",
    "the justification @xmath162justifies all literals defined in @xmath87and true in @xmath34 . as",
    "@xmath34 is a subset of @xmath34 , @xmath162 justifies all literals defined in @xmath87and true in @xmath34.    in a default acceptable state , literals defined in @xmath192are not allowed in direct justifications of literals defined in @xmath193 .",
    "this restriction is quite limiting ( see next section ) but is to avoid hidden loops over @xmath195 .",
    "such loops can only be detected by maintaining a justification over both @xmath192and @xmath193 , which our current implementation does not do .",
    "several methods exist to extend the class of default acceptable states .",
    "literals @xmath21 defined in @xmath192can be allowed in direct justifications of @xmath193 , provided it can be established that @xmath21 s justification can not loop over @xmath195 .",
    "one case is when the body of the rule of @xmath21 has no defined literals .",
    "a step further is to analyze the dependency graph : a literal defined in @xmath192can be allowed in the direct justification of a literal defined in @xmath193provided both literals do not belong to the same strongly connected component of the dependency graph . in that case , they can not be part of the same cycle .      in the rest of the section",
    ", we illustrate the behavior of lazy model expansion on an artificial example , constructed in such a way that all main features are illustrated . in the next section ,",
    "the processes involved are described in more detail .",
    "we focus on the operation of the justification manager and its interaction with the solving process .",
    "the manager is activated in an unacceptable state , either when the solver falsifies a literal that occurs in a direct justification of @xmath162or when a true literal @xmath21 defined in @xmath193is not justified by @xmath162 .",
    "one option for repair is to search for a justification for @xmath21 to extend @xmath162 . in general",
    "this problem is as hard as the model expansion problem itself , as shown by corollary  [ cor : voila ] .",
    "our manager only searches _ locally _ for a direct justification that justifies @xmath21 to extend @xmath162 , and if it does not find one , it grounds @xmath21 s definition and moves it to @xmath192 .",
    "our example uses a theory @xmath121which states that a symmetric graph ( @xmath234 ) exists where at least one node other than the root node ( predicate @xmath235 ) is reachable ( predicate @xmath236 ) from the root node .",
    "the input structure @xmath34interprets the domain as @xmath237 and the equality predicate as the identity relation on @xmath29 ( below omitted in @xmath34 ) .",
    "predicates @xmath238 and @xmath239are not interpreted ; @xmath19 and @xmath240 are defined .",
    "in particular , @xmath239is defined as the singleton @xmath241 , specifying the root as @xmath242 .",
    "@xmath243    the lazy algorithm proceeds as follows :    1 .   the initial default acceptable state is @xmath197 in which @xmath192 , @xmath34and @xmath162are empty , and @xmath244 .",
    "2 .   propagation over @xmath245 sets @xmath40 to @xmath246 .",
    "this expands the structure @xmath34 , but now the conditions of proposition  [ prop : forward ] are no longer satisfied .",
    "the resulting state is not acceptable since @xmath129is true and defined in @xmath193while it has no direct justification in @xmath162 .",
    "one option to repair acceptability is to extend @xmath162with a direct justification for @xmath129 .",
    "the atom @xmath129has a unique direct justification @xmath247 but extending @xmath162with it does not restore ( default ) acceptability since @xmath248 have no direct justification in @xmath162and @xmath129remains unjustified .",
    "therefore , the alternative is taken and rule ( 1 ) is moved to @xmath192 .",
    "now , a default acceptable state is obtained .",
    "unit propagation sets @xmath40 to @xmath249 .",
    "now @xmath250 and @xmath251 have to be justified .",
    "consider first @xmath251 and rule  ( 3 ) .",
    "as @xmath252 is open , our manager can build the direct justification @xmath253 , that sets all negative @xmath252 literals true , and extends @xmath162with it ( setting all positive @xmath252 literals true would be equally good ) .",
    "this justifies @xmath251 and avoids the grounding of the rule defining @xmath251 .",
    "literal @xmath250 can not be justified ( with the local approach ) since each of its direct justifications contains unjustified defined literals .",
    "however , as rule  ( 2 ) is existentially quantified , one can avoid grounding the whole rule by performing a tseitin transformation to isolate one instance and then only ground that instance .",
    "for the purpose of illustration , we make the ( bad ) choice of instantiating @xmath22 with @xmath242 : @xmath254 rule  ( 2a ) is moved to @xmath214 and a default acceptable state is reached .",
    "we are in an acceptable state in which no further propagation is possible , so a choice has to be made .",
    "as @xmath250 is true , the body of rule  ( 2a ) has to become true .",
    "preferably not selecting a tseitin ( this would trigger more grounding ) , the first disjunct is selected by model expansion and propagation extends the structure with @xmath255 and @xmath256 .",
    "the literal @xmath255 is defined in @xmath193by rule  ( 4 ) but can not be justified since its unique direct justification @xmath257 is false .",
    "the manager partially grounds the definition of @xmath258 and splits it up in a ground rule  ( 4a ) and a non - ground rule  ( 4b ) defining @xmath258 for the other domain elements : @xmath259 rule  ( 4a ) is moved to @xmath192 .",
    "note that @xmath260 is justified by @xmath261 in @xmath195 , hence it is safe to use @xmath260 in direct justifications in @xmath193 . whenever grounding has been done , the justification manager is interrupted by propagation , which can infer the truth of additional literals , or detect an inconsistency ( which will result in backjumping ) . in both cases ,",
    "the manager has to resume the revision of the justification afterwards , until an acceptable state is reached . here , even though the resulting state is still unacceptable ( due to the unjustified @xmath256 ) , the creation of the new rule  ( 4a ) in @xmath192interrupts the manager .",
    "propagation using the new rule derives @xmath260 and a conflict . after backtracking to @xmath262 ,",
    "the subsequent propagation sets the structure @xmath34to @xmath263 . still not in a default acceptable state (",
    "@xmath85 is not justified ) , rule  ( 2b ) is further transformed to split off another instance . @xmath264",
    "rule  ( 2ba ) is moved to @xmath214 , while rule  ( 2bb ) remains in @xmath193 .",
    "this state is default acceptable",
    "again , the search avoids the new tseitin @xmath202 , choosing the first disjunct in rule  ( 2ba ) which propagates @xmath265 and @xmath266 .",
    "the literal @xmath267 is defined in @xmath193 , but is justified by the direct justification @xmath268 .",
    "the literal @xmath266 can not be justified by a direct justification ( as all @xmath252 literals are false in the current justification graph ) and rule  ( 5 ) is transformed to split off the instance for @xmath269 . actually , this instance in turn has a disjunctive body with a complex subformula , so to avoid grounding the subformula , we break it up in two parts and introduce another tseitin . @xmath270 rule  ( 5aa ) is moved to @xmath214 , the others remain in @xmath199 . 7 .",
    "the current structure @xmath34is @xmath271 , hence propagation on rule  ( 5aa ) in @xmath192extends it with @xmath203 .",
    "there is no direct justification justifying @xmath203 and , hence , rule  ( 5ab ) is partially grounded by splitting off the @xmath242 case : @xmath272 rule",
    "( 5aba ) is moved to @xmath192while rule  ( 5abb ) remains in @xmath193 .",
    "the search selects the first disjunct of @xmath203 s rule body and propagates @xmath273 and @xmath256 .",
    "the literal @xmath256 is defined in @xmath193 , but @xmath274 is a direct justification for it . extending @xmath162with this direct justification yields an acceptable but not default acceptable state , since @xmath260 is defined in @xmath192 .",
    "however , @xmath260 is justified in @xmath195 , making it safe to extend @xmath162with this direct justification as discussed earlier .",
    "now the justification manager faces a new problem : the true literal @xmath273 is in conflict with the direct justification @xmath275 of @xmath251 ( rule  ( 3 ) ) . to handle this conflict , it splits off the affected instance ( @xmath276 ) from this rule : @xmath277 rule  ( 3a ) is moved to @xmath192while rule  ( 3b ) remains in @xmath193 .",
    "the direct justification of @xmath278 is set to @xmath279 , the unaffected part of the direct justification of @xmath251 .",
    "this restores acceptability .",
    "propagation on rule  ( 3a ) extends @xmath34with @xmath280 and @xmath278 . the literal @xmath280 , which is true , is in conflict with the direct justification for @xmath278 ( rule  ( 3b ) ) . to resolve it , the justification manager",
    "partially grounds rule  ( 3b ) and splits off the instance @xmath281 as follows .",
    "@xmath282 rule  ( 3ba ) is moved to @xmath192while rule  ( 3bb ) remains in @xmath193 ; @xmath283 inherits the direct justification of @xmath278 with @xmath284 removed .",
    "propagation on rule  ( 3ba ) extends @xmath34with @xmath283 .",
    "the resulting state is acceptable , with @xmath283 defined in @xmath193but justified .    by now , @xmath192consists of the rules ( 1 ) , ( 2a ) , ( 4a ) , ( 2ba ) , ( 5aa ) , ( 5aba ) , ( 3a ) , and ( 3ba ) , and the residual definition @xmath193consists of the rules ( 4b ) , ( 2bb ) , ( 5b ) , ( 5abb ) , and ( 3bb ) .",
    "the current structure @xmath34is @xmath285 @xmath286 @xmath287 , a model of @xmath288 .    of these literals , @xmath267 , @xmath256 and @xmath283",
    "are defined in @xmath193 .",
    "literal @xmath267 , defined by rule ( 4b ) has @xmath289 as direct justification .",
    "literal @xmath256 , defined by rule ( 5b ) , has @xmath290 as direct justification .",
    "literal @xmath283 , defined by rule ( 3bb ) has as direct justification the set of all negative @xmath252 literals over @xmath29 except @xmath280 and @xmath273 . to obtain a full model of the theory",
    ", @xmath34is extended with the literals of the above direct justifications . in this case",
    ", this assigns all open literals and the model can be completed by the well - founded model computation over @xmath195 .",
    "actually , this can be done without grounding the definition  @xcite .",
    "in section  [ sec : default ] , we have instantiated our general framework , developed in section  [ sec : lazy - foid ] , for a justification manager that only has access to @xmath193 . in the example of section  [ sec : lazyexample ]",
    ", the justification was constructed on demand , i.e. , each time some literal needed a ( different ) direct justification , the body of its defining rule was analyzed and a justification was extracted .",
    "if that failed , part of the rule was grounded .",
    "this was called the _",
    "local approach_. one can also imagine a _ global approach _",
    ", where more rules of @xmath193are considered at once in an attempt to select direct justifications that minimize the grounding of the rules as a whole .",
    "obviously , a global approach will be more time consuming , so should not be applied every time an adjustment of the justification is required . in this section , we describe both approaches .    before describing the algorithms ,",
    "we introduce some notations and assume some normalizations have been done .",
    "the function reduces a formula to its negation normal form . with @xmath45 a set and @xmath291 a single element , @xmath292 and @xmath293",
    "are used as shorthands for @xmath294 and @xmath295 . with @xmath162a justification , we denote by @xmath296 $ ] the graph identical to @xmath162except that @xmath21 is now justified by @xmath24 .",
    "we assume quantifiers range over a single variable and variable names are not reused in a formula .",
    "furthermore , we assume basic reductions have been applied to formulas , e.g. , @xmath297 reduces to @xmath80 , @xmath298 reduces to @xmath38 ,       algorithm  [ fig : lazymx ] shows the top level of the model expansion algorithm , taking as input theory @xmath124 and input structure @xmath191 .",
    "definitions @xmath193and @xmath192are initialized with @xmath87and the empty definition , respectively , and @xmath34is initialized as @xmath191 .",
    "the set of ground sentences @xmath299is initialized with the fact @xmath129and the initial justification @xmath162is empty .",
    "an auxiliary ( fifo ) queue @xmath300is initialized as empty .",
    "the latter keeps track of literals for which the direct justification needs to be checked .",
    "the main loop performs model expansion over @xmath301 , interleaved with work by the justification manager towards establishing a default acceptable state .",
    "the model expansion part consists of propagation ( the call to ) , the test on whether the current state is inconsistent ( with learning and backjumping ) , the test on whether a model of @xmath301 has been found ( returning the model and the justification ) and of the choice step that selects a literal unknown in @xmath301 and assigns it a value .",
    "propagation returns literals that are entailed by a ground theory over a ( partial ) structure , for example by applying unit propagation and unfounded / wellfoundedness propagation  .",
    "the test for a model is only performed in a default acceptable state(i.e .",
    ", when the queue @xmath300is empty ) .",
    "if the test succeeds , this ensures that the well - founded model computation can expand the current structure @xmath34  extended with the direct justifications of all literals into a model of the whole theory .",
    "also the choice step only takes place in a default acceptable state ; this ensures that the search space is limited to the state space of default acceptable states .",
    "the justification manager is activated when a propagation or choice step assigns a literal @xmath21 . by calling",
    ", it is checked whether the current justification remains valid .",
    "if @xmath21 is defined in @xmath193and has no justification , it needs a justification and is added to the queue @xmath300for further processing by the justification manager . if @xmath302 occurs in the justification of another literal @xmath221 , the justification becomes inconsistent with @xmath34and @xmath221 needs another justification so it is also added to @xmath300 .",
    "the further processing is done by selecting elements from the queue and calling the function .",
    "the latter function first attempts to find a ( different ) consistent direct justification for @xmath21 ; if that fails , it splits off the rule instance defining @xmath21 from @xmath193and partially grounds it , hence @xmath192is extended .",
    "the new clauses may trigger propagation ; therefore the processing of queued literals is interleaved with propagation and , possibly , with backtracking .",
    "note that backtracking might restore the consistency with @xmath34of the direct justification @xmath159 of a literal @xmath21 on @xmath300 .",
    "the function , algorithm  [ fig : lazyground ] , checks whether the literal @xmath21 needs a direct justification ; if not , it simply returns . otherwise , it checks whether @xmath21 has a valid justification , i.e. , one that satisfies the invariants detailed below .",
    "if so , it also returns ; otherwise , it passes the rule body that has to be used to construct a justification ( the negation of the defining rule when the literal is negative ) to , a function that attempts to find a valid direct justification . besides the literal and the rule body ,",
    "also an initial justification , derived from the rule body , is passed to .",
    "if the latter function is successful , the justification is updated and is done ; if not , the direct justification of the literal @xmath21 is set to @xmath303and is called to ground part of the rule defining @xmath21 .    before going into more details ,",
    "we first analyze which properties we want to maintain in the current justification @xmath162 .",
    "the direct justifications of literals in the @xmath300queue are not considered part of @xmath162since they might be invalid .",
    "the global invariants of @xmath162are :    * no literals are unfounded in @xmath162(recall , negative cycles are allowed ) , * the set of literals in @xmath162is consistent .    for each direct justification @xmath304 of @xmath162for",
    "some @xmath21 not on the queue , invariants of the lazy grounding process are :    * @xmath45 contains no literals defined in @xmath192(unless such a literal is safely justified in @xmath195 , as discussed before ) , * literals in @xmath45 that are defined in @xmath193either have a direct justification in @xmath158 or belong to the queue @xmath300 .",
    "these invariants imply that a default acceptable stateis reached when the @xmath300queue is empty .",
    "indeed , it follows from the invariants that the current justification is total in that situation and hence all literals that have a direct justification are justified ( definition  [ def : justifies ] ) . due to",
    "the policy followed to queue literals , the current justification is also consistent with @xmath34while all literals true in @xmath34and defined in @xmath193have a justification , hence @xmath197 is a default acceptable state .",
    "the purpose of , algorithm  [ fig : buildconstr ] , is to extend @xmath162with a suitable direct justification for literal @xmath21 defined in @xmath193 . here",
    "@xmath21 is a literal for which @xmath159 is currently undefined or is inconsistent with @xmath34 .",
    "it is a recursive function which takes three parameters : ( * i * ) the literal @xmath21 , ( * ii * ) the formula @xmath80to be made true by the direct justification ( initially the whole body of the rule defining the literal ; note that the initialization takes the negation of the rule when the literal is negative ) , ( * iii * ) a description of the direct justification derived so far , initialized through @xmath305 . for this algorithm ,",
    "we assume @xmath80is such that different quantifiers range over different variables .    before going into details ,",
    "we discuss how to represent direct justifications .",
    "basically , we could represent a direct justification as a set of ground literals .",
    "however , this set can be quite large and using a ground representation might hence defy the purpose of lazy grounding .",
    "instead , we represent a direct justification as a pair @xmath306 with @xmath164 a set of possibly non - ground literals and @xmath307 a set of bindings @xmath308 with @xmath309 a variable and @xmath310 a domain .",
    "a set of bindings @xmath311 represents the set of variable substitutions @xmath312\\}$ ] .",
    "the set of ground literals represented by @xmath306 is then @xmath313 .",
    "the direct justification of a literal @xmath314 , defined by a rule @xmath315 , is initialized by @xmath305 as @xmath316 . in effect",
    ", @xmath307 allows to identify the relevant rule instantiation by providing the appropriate variable instantiation from the domains , while the set of literals is empty .",
    "the algorithm searches for a set of literals making @xmath80true .",
    "it works by recursively calling itself on subformulas of @xmath80and composing the results afterwards into a larger justification for @xmath80 .",
    "when no such set of literals is found , for example because none exists that is consistent with all other direct justifications , @xmath317 is returned .    the base case is when the formula is a literal . to make that literal true , all instances of the literal under the set of bindings @xmath307 must be true , hence",
    ", the set of literals @xmath164 is extended with the literal itself .",
    "the resulting direct justification has to satisfy all invariants , which is checked by the call to : it returns @xmath318for a call @xmath319 if @xmath320 satisfies the invariants to be ( part of ) a direct justification for @xmath21 and @xmath321 $ ] satisfies the invariants on the justification .",
    "a universally quantified formula @xmath322 has to be true for each instance of the quantified variable .",
    "hence , in the recursive call , the set of bindings @xmath307 is extended with @xmath323 . for an existentially quantified formula",
    ", it suffices that one instance is true .",
    "hence , a minimal approach is to try each instance separately until one succeeds ; if all fail , @xmath303is returned .",
    "note however that we do not want to iterate over each domain element if @xmath29 is large , which would be similar to constructing the grounding itself . instead ,",
    "if @xmath29 is large , we extend the binding with @xmath324 .",
    "conjunction is similar to universal quantification , except that explicit iteration over each conjunct is needed .",
    "as soon as one conjunct fails , the whole conjunction fails .",
    "disjunction is similar to existential quantification with a small domain .",
    "note that is non - deterministic due to choices for a domain element to justify an existentially quantified formula , or for a disjunct to justify a disjunction .",
    "[ ex : build ] consider the following rule over a large domain @xmath29 .",
    "@xmath325 assume that @xmath162is empty and we have no loops to keep track of . applying to @xmath326 returns @xmath327 if the first disjunct @xmath328 in the body is chosen .",
    "this corresponds to the direct justification @xmath329 . alternatively , if the second disjunct is chosen , it returns @xmath330 , which represents the direct justification @xmath331 .",
    "the last bit of the lazy model expansion algorithm handles the case where no justification can be found and the definition of a literal @xmath21 is to be grounded .",
    "a straightforward way would be to call on the rule defining @xmath21 , and store the result in @xmath192and @xmath193 .",
    "however , in many cases such an operation results in too much grounding .    [ ex : splitting ]",
    "consider a rule @xmath332 of the form @xmath333 in a situation where no justification can be found for atom @xmath171 .",
    "applying to @xmath332 would instantiate @xmath22 with all elements in @xmath29 , resulting in @xmath334 rules , while in fact it suffices to split @xmath332 in two rules , one for the instance @xmath335 and one for the remainder .",
    "another example applies to a rule @xmath336 of the form @xmath337 and a direct justification @xmath338 . when @xmath172 becomes false",
    ", the justification manager may need to ground this rule . applying to it would instantiate the universally quantified @xmath22 with all elements in @xmath29 .",
    "instead , it is better to split off the instance for @xmath335 and to introduce a tseitin @xmath85 for the remainder , producing @xmath339 for @xmath192and @xmath340 for @xmath193 . the direct justification for @xmath85 can be obtained incrementally by removing @xmath172 from that of @xmath326 , as discussed in section  [ ssec : splitting ] .",
    "the algorithm ( algorithm  [ fig : splitandground ] ) has to ground part of the rule defining a given literal @xmath21 , say @xmath31 .",
    "the first step is to split off the rule instance for which the rule defining @xmath21 has to be grounded ( the call to ) .",
    "let @xmath315 be the rule in @xmath193that defines @xmath31 .",
    "we then replace that rule by @xmath341 in @xmath193and additionally return the rule @xmath342 $ ] .",
    "afterwards , we apply to the latter rule and add the computed rules to either @xmath192or @xmath193 .",
    "the result of is that definition @xmath195is `` more '' ground than the previous one .",
    "the limit is a ground definition @xmath195 in which @xmath193is empty and @xmath192is strongly @xmath343-equivalent with @xmath87 .    even if no justification was found , we can do better than just splitting off @xmath21 and applying , as shown in example  [ ex : splitting ] .",
    "first , splitting can be made significantly more intelligent , which is discussed in section  [ ssec : splitting ] .",
    "second , we can improve to only ground part of expressions if possible , which we describe below .",
    "[ [ improving- . ] ] improving .",
    "+ + + + + + + + + + +    applying to a rule @xmath344 iterates over all subformulas / instantiations of @xmath80 .",
    "for example if @xmath80is the sentence @xmath345 , the result consists of @xmath334 new rules and as many new tseitin symbols . instead , depending on the value of @xmath21 , it is sufficient to introduce only one ( or some ) of these subformulas , as shown in algorithm  [ algo : improveground ] , which extends the switch statement of with two higher - priority cases . if @xmath21 is true , it is sufficient to ground one disjunct / existential instantiation and to delay the rest by tseitin introduction .",
    "if @xmath21 is false , we take a similar approach for conjunction / universal quantification .",
    "correctness and termination of the presented algorithms is discussed in the following theorem .    if returns an interpretation @xmath34 , then expanding @xmath34with the literals in the direct justifications of @xmath162 , applying the well - founded evaluation over @xmath195and restricting it to @xmath127 results in a model of @xmath121 .",
    "if the algorithm returns @xmath303 , no interpretation exists that is more precise than @xmath191and satisfies @xmath121 .",
    "algorithm  terminates if @xmath34is over a finite domain @xmath29 .",
    "otherwise , termination is possible but not guaranteed .. ]    if returns an interpretation @xmath34 , @xmath34is a model of @xmath192and @xmath300is empty . given the properties of , after applying for a literal @xmath21 , either @xmath21 has a valid justification or is defined in @xmath192 .",
    "hence if @xmath300is empty , we are in a default acceptable state and , by theorem  [ theo : acceptablemodel ] , @xmath34can be expanded into a model of the whole theory .",
    "if returns @xmath303 , it has been proven that @xmath192has no models in @xmath191 . in that case",
    ", there can also be no models of @xmath195and hence @xmath121also has no models expanding @xmath191 .    without calls to",
    ", the search algorithm terminates for any finite @xmath192 ; the function itself produces an ever - increasing ground theory @xmath192with the full grounding as limit .",
    "hence , always terminates if @xmath29 is finite .",
    "if @xmath29 is infinite , the limit of @xmath192is an infinite grounding , so termination can not be guaranteed .",
    "the algorithms presented above are sound and complete .",
    "however , they can be further improved by taking the formulas from which justifications are derived into account .",
    "[ [ symbolic - justifications - and - incremental - querying . ] ] symbolic justifications and incremental querying .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    when multiple justifications exist for ( subformulas of ) a formula @xmath80 , grounding can be further delayed .",
    "consider the formula @xmath346 , where both @xmath347 and @xmath348 are justifications . from that",
    ", we could derive the justification : for each @xmath349 , make either @xmath171 _ or _",
    "@xmath172 true .",
    "hence , more grounding is necessary _ only _ when both @xmath171 and @xmath172 become false for the same @xmath24 .",
    "we can do this automatically by changing as follows :    * the algorithm is allowed to select multiple disjunctions / existential quantifications even if a valid justification was already found for one ( lines  [ buildconstr - enougha ] and [ buildconstr - enoughb ] ) .",
    "* no longer returns a justification , but a symbolic _ justification formula _ that entails the original formula .",
    "the formula is built during and reflects the subformulas / instantiations that have been selected . from @xmath350 ,",
    "the justification itself can be derived directly as the set of non - false literals in the ( full ) grounding of @xmath350 .",
    "for example , for a formula @xmath351 , instead of the justification @xmath352 , might now return the justification formula @xmath353 . * the validity check ( ) is extended to return false if the justification formula is false .    by allowing more complex formulas ( instead of a conjunction of universally quantified literals ) , the validity check whether a formula has become false after incremental changes to @xmath34 is now more expensive .",
    "this is in fact an _ incremental query _ problem . in the experiments , we limit the depth of the allowed formulas and use a straightforward ( expensive ) algorithm that evaluates the whole formula whenever an assignment can falsify it .    [ [ body - splitting . ] ] body splitting .",
    "+ + + + + + + + + + + + + + +    as described in algorithm  [ fig : lazyground ] of section  [ sec : splitandground ] , simply splits off the rule instance that defines @xmath21 , then grounds this rule instance step by step , in accordance with the structure of the formula .",
    "however , when the grounding is triggered by a conflict with the current justification , is blind for the origin of the conflict . by using the conflicting literals",
    ", one could focus on grounding the part of the formula that contributes to the conflict .",
    "one can do so by restructuring the rule in a part to be grounded , that contains the conflict , and a part not to be grounded , for which the old justification can be adjusted to still apply .",
    "the latter part can then be split off by introducing new tseitins and the transformation is called body splitting .",
    "this approach can be inserted in algorithm  [ fig : lazyground ] after the call to .",
    "for this , the original justification ( call it @xmath354 ) is passed as an extra argument to .",
    "consider the rule @xmath355 ; let @xmath347 be the justification for @xmath356 true in @xmath34 .",
    "when @xmath171 becomes false , it is easy to see that we can split off the `` violating instantiation '' by rewriting the original rule into @xmath357 and adding the rule @xmath358 .",
    "crucially , a justification for the second part can be derived from the original justification , namely @xmath359 .",
    "the second part can hence be added to @xmath193and its justification to @xmath162while the first part is added to @xmath214 .",
    "this revision of a rule @xmath90 and its direct justification @xmath354 can be done in an efficient way .",
    "assume that @xmath60 is a true domain literal in the partial structure and that the direct justification of rule @xmath90 contains its negation @xmath360 .",
    "the implementation is such that the binding(s ) for which the justification instantiates to @xmath360 can be extracted from the representation of the direct justification of the rule . for simplicity ,",
    "assume @xmath361 is the single such instance . a recursive algorithm visits the formula @xmath80 in the body of @xmath90 depth - first .",
    "whenever a quantification @xmath362 is encountered with @xmath22 equal to @xmath363 , it is replaced by @xmath364 $ ] .",
    "then a tseitin transformation is applied to the left - hand conjunct and the algorithm recurses on the right - hand conjunct with what remains of the binding .",
    "the new rule defining the new tseitin has @xmath365 as a direct justification .",
    "similarly , an existential quantification is replaced by a disjunction .",
    "the result is a set of new rules for which no new justification has to be sought and a smaller rule @xmath366 which is passed to .",
    "correctness follows from the fact the @xmath365 is a valid justification , none of the new rules contains @xmath60 , and from the correctness of the tseitin transformation .",
    "[ ex : bodysplit ] in example  [ ex : build ] , justifications were sought for @xmath326 in the rule @xmath367 assume we selected the justification @xmath368 .",
    "when @xmath369 is true in @xmath34 , and @xmath370 becomes false , @xmath158 is no longer consistent with @xmath34and can not be repaired .",
    "@xmath371 , however , is still consistent with @xmath34 , but is not a justification of the whole body . on the other hand , @xmath371 is a justification for the subformula @xmath372 for each instantiation of @xmath22 different from @xmath242 .",
    "consequently , we can split the quantification @xmath373 into @xmath374 and @xmath375 and apply a tseitin transformation to the former .",
    "afterwards , we recursively visit the latter formula and apply a similar reasoning to the existential quantification . the operations on the formula are illustrated in figure  [ fig : split ] .",
    "the result consists of the following rules , where the rule for @xmath326 is now even ground .",
    "+   +    child node [ node ] @xmath376 child[normal ] node [ node ] ( or ) @xmath377 child[halfline ] node [ r_node ] @xmath328 child node [ node ] @xmath378 child node [ node ] @xmath379 child node [ node ] @xmath380 child[halfline ] node [ r_node ] @xmath381 childnode [ empty_node ] .",
    "child node [ node ] ( or2 ) @xmath377 child[halfline ] node [ r_node ] ( ln ) @xmath382 child node [ empty_node ] at ( @xmath383 ) @xmath377 ( * split 2 * ) child[normal ] node [ node ] @xmath384 child[normal ] node [ node ] ( or3 ) @xmath379 child node [ node ] @xmath385 child[halfline ] node [ r_node ] @xmath386 childnode [ empty_node ] .",
    "child[normal ] node [ node ] at ( @xmath387 ) @xmath379 child node [ node ] @xmath388 child node [ node ] @xmath389 ;    to further optimize the traversal of the formula @xmath80 , can be extended to store the path taken through the parse tree of @xmath80and the direct justifications of the subformulas .",
    "assume the rule @xmath390 has to be justified , @xmath162is empty and @xmath34does not interpret @xmath252 .",
    "the algorithm recursively visits the body of the rule until @xmath391 is returned as it is a valid literal to use .",
    "going up one level , we store that for @xmath392 , we selected @xmath393 . assuming no more disjuncts are selected , @xmath391 is returned again .",
    "going back up through both quantifications , we store that , for both quantifications , we selected @xmath29 as the set of relevant domain elements , and returns the justification formula @xmath394 .",
    "if is given access to @xmath354 , similar optimizations are possible for repairing a direct justification .",
    "consider again example  [ ex : bodysplit ] , but assume @xmath369 is unknown in @xmath34 . in this case , the left branch of figure  [ fig : split ] can also be transformed in a rule with a still valid , direct justification .",
    "for the right branch , a repair is to select the disjunct @xmath382 as direct justification for the rule @xmath395 , where @xmath206 is as in example  [ ex : bodysplit ] .",
    "finding justifications using the greedy local approach can easily lead to more grounding than necessary .",
    "consider for example the sentences @xmath396 and @xmath397 . applying the local approach to the second sentence first ( with an empty @xmath162 ) , might result in the construction which makes atoms over @xmath17 false . then applying the local approach to the first sentence finds no valid justification for it",
    "; so it has to be fully grounded .",
    "the global approach takes a set of rules as input and tries to select direct justifications for them such that the _ expected _ grounding size of the whole set is minimal .",
    "we cast the task , called the _ optimal justification _ problem , as a problem on a graph as follows .",
    "the graph consists of two types of nodes , _ rule nodes _ @xmath19 and _ justification nodes _ @xmath162 .",
    "a justification node is a symbolic set of literals representing a possible justification ( for the literals defined by a rule in @xmath193 , given the current partial structure @xmath34 ) .",
    "a rule node is a pair @xmath398 of a rule @xmath90 in @xmath193and a truth value @xmath7 ( @xmath38 , @xmath39 , @xmath399 ) ; a pair @xmath400 for a rule @xmath90 with head @xmath21 expresses that there exists a direct justification for @xmath21 ; the pair @xmath401 that there exists a direct justification for @xmath402 and the pair @xmath403 that r has no justification",
    ".    there are three types of edges :    * _ valid edges _ between a rule node @xmath400 ( @xmath401 ) and a justification node @xmath404 where @xmath404 justifies ( the negation of ) the head of @xmath90 . *",
    "_ conflict edges _ between ( * i * ) rule nodes of the same rule with different truth value , ( * ii * ) justification nodes that contain opposite literals , ( * iii * ) a rule node @xmath400 ( @xmath405 ) where @xmath90 defines @xmath21 , and a justification node that contains @xmath402 ( @xmath21 ) , and ( * iv * ) a rule node @xmath406 , where @xmath90 defines @xmath21 , and a justification node that contains @xmath21 or @xmath402 ( a conflict because @xmath21 ( or @xmath402 ) needs a justification ) . *",
    "_ depends - on edges _ between a justification node @xmath404 and a rule node @xmath400 ( @xmath405 ) where @xmath404 contains negative ( positive ) literals defined by @xmath90 .",
    "the aim is then to select subsets @xmath407 and @xmath408 such that    * each selected rule node is connected with a valid edge to at least one selected justification node . *",
    "no conflict edges exist between pairs of selected nodes .",
    "* neither positive nor mixed cycles exist in the subgraph consisting of the valid and depends - on edges between the selected nodes .    from a selection @xmath409 satisfying these constraints , an initial",
    "justification @xmath162can be extracted as follows .",
    "a literal @xmath21 ( @xmath402 ) is given a direct justification if it is defined by a rule @xmath90 such that @xmath400 ( @xmath401 ) is a selected rule .",
    "its direct justification is the union of the justifications of the justification nodes in @xmath410 connected with @xmath400 ( @xmath401 ) through a valid edge .",
    "moreover , all literals defined by rules for which no rule node was selected can be added to the initial @xmath300queue , to be handled by the local approach , as a complete solution must have a justification for them .",
    "when @xmath403 is selected , it means that the grounding of instances of the rule is delayed until the literals it defines become assigned .",
    "this type of problem is somewhat related to the np - hard _ hitting set _ ( or _ set cover _ ) problem  @xcite : given a set of `` top '' and `` bottom '' nodes and edges between them , the task is to find a minimal set of bottom nodes such that each top node has an edge to at least one selected bottom node .    given a default acceptable state @xmath197 , the input for the optimal justification problem is generated as follows . for any rule in @xmath193 ,",
    "a node is constructed for each of the three truth values ( only one when the truth value is known in @xmath34 ) and also their conflict edges are added .",
    "valid edges and justification nodes are obtained using a ( straightforward ) adaptation of that returns a set of possible justifications that make the head of a rule true ( false ) .",
    "e.g. , for a rule @xmath315 , is called with the literal @xmath89 and the binding is initialized at @xmath411 .",
    "conflict and depends - on edges are derived by checking dependencies between justifications and between rules and justifications . to keep this efficient ,",
    "it is done on the symbolic level .",
    "[ ex : global ] consider the theory of our running example , after @xmath129 , @xmath250 and @xmath251 have been propagated to be true .",
    "definition @xmath193is then @xmath412    the associated optimal construction set input is shown in figure  [ fig : ocs ] .",
    "note that in rule nodes , we use the defined head literals to identify the rule .",
    "literal @xmath250 and @xmath251 are true in @xmath34 , hence there is only one rule node for rules ( 2 ) and ( 3 ) .",
    "neither @xmath413 nor @xmath414 can be justified for all @xmath415 , hence there is only a @xmath416 tuple .",
    "there are four solutions that are subset - maximal with respect to rule nodes , namely the following rule node selections : @xmath417    for each of these , multiple justification selections are possible ( also shown in figure  [ fig : ocs ] ) . for @xmath250 , we have to select justification @xmath418 , but for @xmath251 we can choose from @xmath419 or @xmath420 ( but not both ) .",
    "( rf ) @xmath421 ; ( jrfa ) @xmath422 ; ( jrfb ) @xmath423 ; ( ru ) @xmath424 ; ( rt ) @xmath425 ; ( jrt ) @xmath426 ;    ( c1 t ) @xmath427 ; ( jc1 t ) @xmath428 ;    ( c2 t ) @xmath429 ; ( jc2at ) @xmath430 ; ( jc2bt ) @xmath431 ;    ( rootu ) @xmath416 ;    ( rt ) edge[-,bend left=+60 ] ( rf ) ; ( rt ) edge[- ] ( ru ) ; ( rf ) edge[- ] ( ru ) ;    ( jrfb ) edge[- ] ( rt ) ; ( jc1 t ) edge[-,bend left=+20 ] ( rf ) ;    ( jc1 t ) edge[- ] ( c1 t ) ;    ( jc2at ) edge[- ] ( c2 t ) ; ( jc2bt ) edge[- ] ( c2 t ) ; ( jc2at ) edge[- ] ( jc2bt ) ; ( jc2at.east ) edge[-,bend left=-50 ] ( jrfa.east ) ;    ( jrt ) edge[- ] ( rt ) ;    ( jrfa ) edge[- ] ( rf ) ; ( jrfb ) edge[- ] ( rf ) ;    ( rt ) edge[- ] ( jc1t.west ) ; ( rf ) edge[- ] ( jrfb.west ) ;    the objective is then not to maximize the number of selected rule nodes , but to minimize the expected grounding size . to obtain an estimate of the expected grounding size",
    ", the following conditions were taken into account :    * it should depend on the size of the grounding of the rule . *",
    "assigning multiple justifications to a rule should result in a lower estimate as the rule will only be grounded when all are false .",
    "* variables occurring in multiple justifications result in less matching instantiations . * in most practical applications ,",
    "the number of false atoms far exceeds the number of true ones in any model .",
    "hence , positive literals in a justification should have a higher cost than negative ones .",
    "we approximate the expected grounding size with the function @xmath432 which takes as input a rule @xmath90 ( with head @xmath356 ) , the selected type of justification ( rule not selected ( * n * ) , no justification ( @xmath399 ) , a justification for @xmath356 ( @xmath38 ) or a justification for @xmath433 ( @xmath39 ) ) and the set of justifications @xmath162 .",
    "the function returns the expected grounding size of the rule ( @xmath434 , defined below ) weighted depending on the type of justification .",
    "the weights are derived from two estimates : @xmath435 is the probability an atom will become assigned and @xmath436 is the probability of an assigned atom to be true .",
    "hence , as defined formally below , for non - delayed rules ( * n * ) , the full size is used ; a rule without justification ( * u * ) is weighted by @xmath435 ; a true justification ( * t * ) is weighted by @xmath436 , a false one ( * f * ) by @xmath437 ; the latter two weights are multiplied by a product over the justifications @xmath404 in @xmath162 .",
    "each factor of this product is a sum of two terms , namely @xmath438 times the number of negative literals in @xmath404 and @xmath437 times the number of positive literals in @xmath404 .",
    "the effect is that the expected size decreases as the number of justifications increases and that the expected size increases as a justification has more literals .",
    "@xmath439 for the probabilities , we assumed @xmath435 to be small ( currently 0.1 ) to reflect the hope that lots of literals will not get a value , and @xmath436 is less than half , to reflect that atoms are more often assigned false than true .",
    "the function @xmath440 is defined below .",
    "the function returns the number of atoms in the grounding of a rule or formula , except for existential quantification and disjunction . for these ,",
    "we take into account that they can be grounded only partially using tseitin transformation , by taking the logarithm of the total grounding size .",
    "@xmath441}size({{\\ensuremath{\\varphi}\\xspace}}_i ) \\\\   size(\\exists { { \\ensuremath{x\\in d:}\\xspace } } { { \\ensuremath{\\varphi}\\xspace}})&=log(d)\\times size({{\\ensuremath{\\varphi}\\xspace } } ) \\\\ size(\\phi_1 \\lor \\ldots \\lor { { \\ensuremath{\\varphi}\\xspace}}_n)&=log(n)\\times\\frac{\\sum_{i \\in [ 1,n]}size({{\\ensuremath{\\varphi}\\xspace}}_i)}{n}\\end{aligned}\\ ] ] solutions to the optimal justification problem should minimize the term @xmath442 with @xmath443 the type ( @xmath38 , @xmath39 , or @xmath399 ) and @xmath444 the justification of the literal defined by @xmath90 .",
    "the size of rule @xmath250 is @xmath445 , that of @xmath251 is @xmath446 , that of @xmath239 is @xmath447 , and that of @xmath19 is @xmath448 .",
    "consider assigning justification ( iv ) to @xmath250 : this results in an expected cost for that rule of @xmath449 ( as the construction relies on making @xmath19 true ) .",
    "additionally , it would force the grounding of the rule defining @xmath19 , increasing the cost with the size of the rule for @xmath19 .",
    "the optimal solution for the problem in figure  [ fig : ocs ] is then rule node selection  ( [ rulenodea ] ) with justification ( vi ) for @xmath251 .",
    "its cost is the sum of @xmath450 ( for justification ( vi ) ) and @xmath451 ( the expected size of the rule for @xmath250 ) .",
    "now , only the rule for @xmath250 has to be passed to the local approach .    to solve the optimal justification problem , s optimization inference itself",
    "is applied to a ( meta - level ) declarative specification of the task . for larger theories @xmath121 ,",
    "the problem turns out to be quite hard , so two approximations were considered to reduce the search space .",
    "first , the number of selected justifications for any rule was limited to 2 .",
    "second , as the values of @xmath434 can grow quite large , the approximation @xmath452 is used ( a standard approach ) . rounding to integer values was applied as s support for floating point number is still preliminary .",
    "the resulting specification could be solved to optimality within seconds for all tested theories . during lazy model expansion",
    ", the global approach is applied in the initial phase when all tseitin literals representing sentences in the original theory have been propagated true .",
    "this section discusses how to tune the lazy grounding and the search heuristics of the underlying sat solver to obtain an effective implementation of lazy model expansion .",
    "we also describe a few other inferences tasks beyond model expansion that are useful in the context of lazy grounding .",
    "a few less important issues are discussed in appendix  [ app : furtherconsid ] .",
    "heuristics play an important role in the lazy grounding algorithms , as they serve to find the right balance between how much to ground and how long to search .",
    "we first discuss how our heuristics were chosen .",
    "afterwards , we discuss an alternative approach to minimize grounding .",
    "the algorithms leave room for a number of heuristic choices that can have an important effect on the performance .",
    "we now briefly discuss these choices . as a guideline for our decisions ,",
    "the following principles are used :    * avoid leaving the search process without enough information to make an informed decision ; for example , avoid losing too much ( unit ) propagation or introducing too many tseitin symbols .",
    "* prevent creating a grounding that is too large ; this may for example happen as the result of a very long propagate - ground sequence .",
    "recall , the goal is not to create a minimal grounding , but to solve model expansion problems while avoiding a too large grounding .",
    "below , we introduce a number of parameters that affect these heuristics .",
    "the exact values used in the experimental evaluation for the parameters introduced below are specified in appendix  [ app : furtherconsid ] .    in , when handling a disjunction or existential quantification , there is a choice on how many disjuncts to expand .",
    "if we expand one instantiation at a time for a rule @xmath453 , as done in algorithm  [ algo : improveground ] ( lines  [ algo : selectonea ] and [ algo : selectoneb ] ) , iterative application results in a ground theory @xmath454    a sat - solver such as minisat , which is used in the system , initially assigns @xmath455 to the @xmath144 atoms ; such a choice triggers an iteration of propagation and grounding .",
    "the resulting thrashing behavior can be reduced somewhat , and the grounding is more compact when the grounding introduces @xmath28 disjuncts at a time : @xmath456    to further remedy this , two search - related heuristics are changed .",
    "first , the initial truth value is randomized , but favoring false ( as in most models , many more atoms are false than true ) .",
    "second , search algorithms typically _ restart _ after an ( ever - increasing ) threshold on the number of conflicts , sometimes caching the truth value assigned to atoms ( _ polarity caching _ ) .",
    "this allows the solver to take learned information into account in the search heuristic while staying approximately in the same part of the search space . in case of lazy grounding",
    ", we might want to jump to another part of the search space when we come across long propagate - ground sequences . to this end",
    ", we introduce the concept of _ randomized restarts _ , which take place after an ( ever - increasing ) threshold on the number of times @xmath192is extended and randomly flipping some of the cached truth values .",
    "in addition , always returns @xmath303if it is estimated that the formula has a small grounding . indeed ,",
    "grounding such formulas can help the search .",
    "whether a formula is considered small is determined in terms of its ( estimated ) grounding size .",
    "the same strategy is used in : whenever the formula to which would be applied is small , is applied instead , to completely ground the formula .",
    "grounding is applied during the search process as soon as unit propagation has taken place .",
    "the result is a focus on the current location in the search space , but with the danger of grounding too much if there is no solution in that part of the space .",
    "alternatively , we could apply the opposite strategy , namely to ground as late as possible : only apply additional grounding when the search algorithm terminates without ever having found a model in an acceptable default state .",
    "such a strategy is well - known from the fields of incremental proving and planning , where the domain ( number of time steps ) is only increased after search over the previous , smaller bound has finished .",
    "this guarantees a minimal grounding .",
    "a prototype of this strategy has been implemented in with good results on planning problems .",
    "the bulk of the paper focuses on model expansion ( mx ) for theories",
    "@xmath121 , for which solutions are structures that are two - valued on @xmath127 .",
    "often , one is only interested in a small subset of the symbols in @xmath127 .",
    "this is for example the case for model generation for , the language which extends with existential quantification over relations .",
    "an problem @xmath457 with an initial structure @xmath34 , relation symbols @xmath458 ,  , @xmath459 , and @xmath121an theory , can be solved by model generation for the theory @xmath460 with initial structure @xmath34and by dropping the interpretation of the symbols @xmath458 ,  , @xmath459 in the models .",
    "another example is query evaluation for : given a theory @xmath121 , an initial structure @xmath34and a formula @xmath80 with free variables @xmath185(all in ) , the purpose of evaluating the query @xmath461 is to find assignments of domain elements @xmath462to @xmath185such that a model of @xmath121exists that expands @xmath34and in which @xmath463 $ ] is true . to solve it by model expansion in ,",
    "a new predicate symbol @xmath85 is introduced and answers to the query are tuples of domain elements @xmath464 such that @xmath465 is true in a model of the theory @xmath460 extended with the sentence @xmath466 and the definition @xmath467 .    in both cases , approaches using ( standard ) model expansion",
    "compute a total interpretation and afterwards drop all unnecessary information , which is quite inefficient .",
    "lazy model expansion can save a lot of work by only partially grounding the theory .",
    "however , once a model is found for the grounded part , the justifications and the remaining definitions are used to expand the structure to a model of the full theory .",
    "although this expansion is obtained in polynomial time , it is still inefficient when afterwards a large part of the model is dropped .    to remedy this",
    ", we define a variant of the model expansion task , denoted _ restricted _ mx .",
    "restricted mx takes as input a theory @xmath121 , a structure @xmath34and an additional list of symbols @xmath468 , called _",
    "output symbols_. solutions are then structures @xmath469 which are",
    "two - valued on all symbols in @xmath468 and for which an expansion exists that extends @xmath34and is a model of @xmath121 . adapting lazy grounding to solve restricted mx can be done through an analysis of which justifications need not be added ( completely ) to the structure , splitting @xmath195into multiple definitions and only evaluating those defining output symbols or symbols on which those depend ( using a stratification argument ) .",
    "the above - mentioned inference tasks can be cast trivially to restricted mx problems and lazy restricted mx then greatly improves the efficiency with respect to ground - and - solve , as shown in the experimental section .",
    "the extension of with _ procedurally interpreted _ symbols  @xcite provides another class of interesting problems .",
    "such predicate symbols have a fixed interpretation , but to know whether a tuple belongs to the predicate , a procedural function has to be executed .",
    "such an approach provides a clean way to combine declarative and procedural specifications .",
    "consider for example a symbol @xmath470 that is interpreted by a procedure which executes an efficient prime - verification algorithm and returns true iff the given argument is prime .",
    "we are generally not interested in the complete interpretation of @xmath471 , so it can be cast as a restricted mx problem with @xmath471 not in @xmath468 .",
    "solving such a problem using lazy grounding then has the benefit of only executing the associated function _ during _",
    "search for relevant atoms @xmath472 .",
    "also for this task , we show an experimental evaluation in the next section .",
    "the system has a state - of - the - art model expansion engine , as can be observed from previous answer - set programming competitions  .",
    "the lazy model expansion algorithms presented in this paper were implemented in the system , by extending the existing algorithms  @xcite .",
    "the current implementation is incomplete in the sense that the cycle check for justifications has not been implemented yet .",
    "this only affects inductive definitions as non - inductive ones can be replaced by the fo formulas of their completion . as a workaround for the lack of a cycle check , , the function that constructs a direct justification , returns false for rules defining inductive predicates . as a consequence , an instance of such a rule is immediately grounded , although lazily , when a domain atom defined by the rule is assigned a value .",
    "another consequence is that inductively defined predicates can not be used in justifications of other rules .",
    "this affects three benchmarks of the asp competition ( described below in section  [ ssec : aspcompexper ] ) , namely ` reachability ` , ` sokoban`and ` labyrinth ` . for these",
    ", the grounding might be delayed even more in a complete implementation .",
    "the section is organized as follows . in section  [ ssec :",
    "overhead ] , we evaluate the overhead of completely grounding a theory using the presented approach . in section  [ ssec :",
    "aspcompexper ] , we evaluate the effect of lazy grounding on a number of benchmarks of the asp competition . in section  [ ssec :",
    "additionalexper ] , a number of additional properties of the presented algorithms are demonstrated .",
    "we tested three different setups : with the standard ground - and - solve approach ( referred to as ` g&s ` ) , with lazy model expansion ( ` lazy ` ) and the award - winning asp system gringo - clasp ( ` asp ` ) .",
    "we used version 3.2.1-lazy , gringo 3.0.5 and clasp 2.1.2-st .",
    "the parameters of the lazy grounding algorithms are discussed in section  [ ssec : heur ] , the values used in the experiments are documented in appendix  [ app : furtherconsid ] .",
    "the experiments for sections  [ ssec : overhead ] and [ ssec : additionalexper ] were run on a 64-bit ubuntu 13.10 system with a quad - core 2.53 ghz processor and 8 gb of ram .",
    "experiments for section  [ ssec : aspcompexper ] were run on a 64-bit ubuntu 12.10 system with a 24-core 2.40-ghz processor and 128 gb of ram .",
    "a timeout of 1000 seconds and a memory limit of 3 gb was used ; out - of - time is indicated by ` t ` , out - of - memory by ` m ` .",
    "lazy grounding may reduce grounding size and time but also causes overhead .",
    "for instance , we expect the ( naive ) incremental querying of justifications to be costly as discussed previously .",
    "the aim of this section is to quantify the overhead caused by lazy grounding . in the experiments below we compare the grounding time of the standard idp system with that of a _ naive _ instance of the lazy grounding algorithm that is forced to generate the complete grounding before starting the search",
    "this instance was obtained from the standard algorithm using some small changes : the shortcut to ground small formulas at once is turned off , disjuncts and instances of existentially quantified formulas are grounded one by one , a defined literal is enqueued for lazy grounding as soon as it appears in @xmath192 . for comparison",
    ", we also measure the cost of the standard lazy grounding algorithm that computes partial groundings .",
    "we devised six benchmarks to test various aspects of the novel algorithm .",
    "each benchmark is a simple theory with at most two sentences that is simple to solve .",
    "the benchmarks are designed to measure the cost of different aspects of lazy grounding : delaying and resuming grounding , the querying needed to resume grounding , the splitting of formulas , etc .",
    "specifically , the tested aspects are the following :    1 .   overhead of delaying and resuming grounding in case of an existential quantifier with a large domain .",
    "the sentence is @xmath473 .",
    "standard grounding creates a single clause with @xmath28 disjuncts ; naive lazy grounding grounds the formula piece by piece and introduces @xmath474 tseitin symbols",
    "overhead in case of an inductive definition , here @xmath475 .",
    "both standard grounding and naive lazy grounding construct a ground rule for each @xmath476 atom .",
    "3 .   overhead in case of a universal quantification .",
    "the sentence is @xmath477 .",
    "while standard grounding creates @xmath28 atomic formulas , naive lazy grounding splits off one instance at a time and introduces @xmath474 tseitin symbols .",
    "4 .   lifted unit propagation ( lup )  @xcite is an important preprocessing step to reduce the grounding size . concretely , applying lup to the rules @xmath478 derives that the second formula follows from the first and hence does not need to be grounded at all .",
    "this theory is used to check whether lup remains equally important in a system with lazy grounding .",
    "overhead in case of nested universal quantification .",
    "the sentence is of the form @xmath479 .",
    "standard grounding creates a formula for each instance @xmath464 of @xmath82 with a tseitin for the grounding of @xmath480 .",
    "naive lazy grounding creates an extra tseitin for each instance @xmath464 of @xmath82 and an extra set of tseitins for the piece by piece grounding of the subformula @xmath480 .",
    "overhead of the incremental querying in case a symbolic justification has to be validated .",
    "the sentence is @xmath481 , with an identical justification formula .",
    "the formula is validated by checking the falsity of the query @xmath482 .",
    "this query is re - evaluated each time an @xmath19-atom or @xmath45-atom is falsified .",
    "experiments were done for predicates @xmath17 and @xmath18 with arity 3 and @xmath19 and @xmath45 with arity 2 , and domains of size 10 , 20 , 30 , 40 and 50 .",
    "none of the predicates symbols were interpreted in the structure .    in all experiments ,",
    "the overhead for the time required to solve the initial optimization problem ( for the global approach ) was always around 0.02 seconds , so in itself negligible .",
    "the results for the first three experiments are not shown as the differences between standard grounding and naive lazy grounding are negligible .",
    "while expected for experiment 2 , for experiments 1 and 3 , it shows that our actual implementation eliminates the overhead for tseitins when quantifiers are not nested . in each of these three experiments , standard lazy grounding",
    "is able to justify the formulas without grounding them and hence fast and almost insensitive to the domain size .",
    "as shown in figure  [ overhead ] , there is no difference between standard grounding and naive lazy grounding for experiment 4 . in both cases ,",
    "the use of lup has a big impact on the size of the grounding and hence on the time .",
    "while experiment 1 and 3 showed that a top level quantifier does not create overhead for lazy grounding , experiment 5 shows that this does not hold anymore for nested quantifiers and that naive lazy grounding has substantial overhead when compared with standard grounding .",
    "note that this overhead is worst case . when tseitins can be justified , their definitions are not grounded , which explains why normal lazy grounding is faster than standard grounding and insensitive to the domain size .",
    "experiment 6 shows that a more complex justification formula causes significant overhead for naive lazy grounding . also here",
    ", the overhead is worst case and not visible in normal lazy grounding .",
    "still , it is an important part of future research to reduce the overhead of the incremental querying of complex justification formulas .",
    "second , we selected benchmarks from previous asp competitions to evaluate the lazy grounding algorithm in a more realistic setting .",
    "many benchmarks solutions of that competition are carefully fine tuned for speed and minimal grounding .",
    "lazy grounding is usually unable to substantially reduce the grounding of such theories and , due to its overhead , is then slower than standard ground and solve .",
    "for this reason , we have sometimes selected modelings of the benchmarks that are more natural but less optimized in time and grounding size .",
    "we justify this on the ground that the aim of our work is to improve inference for declarative _ modeling _",
    "@xcite , where the emphasis is not on developing intricate encodings , but on modeling a problem close to its natural language specification .",
    "we selected the following problems ( see the competition websites for complete descriptions ) .",
    "they consist of problems that are known to be hard , in order to evaluate the effect of lazy model expansion on search , and problems that typically result in a large grounding .    * ` reachability ` : given a directed graph , determine whether a path exists between two given nodes . * ` labyrinth ` : a planning problem where an agent traverses a graph by moving between connected nodes to reach a given goal node .",
    "in addition , the graph can be manipulated to change its connectedness . * ` packing ` : given a rectangle and a number of squares , fit all squares into the grid without overlaps .",
    "* ` disjunctive scheduling ` : schedule a number of actions with a given earliest start and latest end time with additional constraints on precedence and disjointness . * ` sokoban ` : a planning problem where a robot has to push a number of blocks to goal positions , constrained by a 2-d maze . * ` graph colouring ` : given a graph , assign colour to nodes ( from a given set of colours ) , such that no connected nodes have the same colour . * ` stable marriage ` : given a set of men and women and a set of preferences , find a `` stable '' assignment : no swap results in a better match .    for each of these",
    ", we used all instances from the 2011 and 2013 competitions , except for the 2013 ` reachability`instances , because of the huge data files which none of the systems is designed to handle . for ` stable marriage ` , ` graph colouring`and ` reachability ` , we based our encodings on the available asp - core-2 encodings . for `",
    "packing`and ` disjunctive scheduling ` , we constructed a natural encoding and made a faithful translation to asp . for the more complex benchmarks of ` labyrinth`and ` sokoban ` , we used the original and gringo - clasp s specifications submitted to the 2011 competition .",
    "for the lazy model expansion , we replaced cardinality expressions by their encoding as for the former no justifications are derived yet ; this also increases the size of the full grounding .",
    ".the number of solved instances for the asp benchmarks and the average time taken on the solved instances .",
    "different solvers solve quite different sets of instances . [ cols=\"<,^,^,^,^,^,^,^ \" , ]      during the modeling phase of an application , different encodings are typically tested out , in an attempt to improve performance or to locate bugs .",
    "while modeling our experimental benchmarks , we noticed that simplifying a theory by dropping constraints often resulted in a dramatic reduction in the time lazy model expansion took to find a model .",
    "standard model expansion , on the other hand , was much less affected by such simplifications . in our opinion , this observation , while hardly definitive evidence , is another indication that the presented algorithms are able to derive justifications for parts of a theory that can be satisfied cheaply .",
    "in that way , the approach is able to distinguish better between problems which are inherently difficult and problems which would just have a large grounding .",
    "lazy model expansion offers a solution for the blow - up of the grounding that often occurs in the ground - and - solve model expansion methodology for theories . and",
    "techniques also process theories that can have a large grounding ; the constraint store of and mixed integer programming and the clauses of sat can be considered the equivalent of a grounded theory ( they are often derived from quantified descriptions such as `` @xmath483 * for all * @xmath484 and @xmath404 for which  '' ) and can also become very large . and have reported a blow - up problem in these paradigms and a multitude of techniques has been developed to address it .",
    "we distinguish four approaches .",
    "first , concerning grounding up - front , research has been done towards _ reducing the size of the grounding _ itself through ( * i * ) _ static analysis _ of the input to derive bounds on variable instantiations  @xcite , ( * ii * ) techniques to _ compile _ specific types of sentences into more compact ground sentences  , ( * iii * ) detect parts that can be evaluated polynomially   and ( * iv * ) detect parts that are not relevant to the task at hand ( e.g. , in the context of query problems ) as shown in the work of  .",
    "naturally , each of these approaches can be used in conjunction with lazy grounding to further reduce the size of the grounding . in ,",
    "e.g. , lazy grounding is already combined with ( * i * ) and ( * iii * ) .",
    "second , the size of the grounding can be reduced by _ enriching _ the language .",
    "for example , asp solvers typically support ground aggregates ( interpreted second - order functions such as cardinality or sum that take sets as arguments ) , and and solvers support ( uninterpreted ) functions .",
    "more recently , the constraint - asp paradigm was developed  @xcite , that integrates asp and cp by extending the asp language with _ constraint",
    "these are interpreted as constraints in a csp problem and can thus be handled using techniques .",
    "various casp solvers are already available , such as clingcon  ( @xcite ) , ezcsp   mycommoncitationezcsp @xcite , mingo  @xcite and inca   mycommoncitationinca @xcite .",
    "this technique is also integrated into  .",
    "inca and in fact implement lazy clause generation  @xcite , an optimized form of lazy grounding for specific types of constraints .",
    "the language hex - asp   also extends asp , this time with _ external _ atoms that represent ( higher - order ) external function calls .",
    "third , _ incremental approaches _ are well - known from model generation , theorem proving and planning . for these tasks ,",
    "the domain is typically not fixed in advance , but part of the structure being sought , such as the number of time steps in a planning problem ( recall the sokoban example from the introduction ) .",
    "such an approach typically works by grounding the problem for an initial guess of ( the number of elements in ) the domain .",
    "afterwards , search is applied ; if no model was found , the domain is extended and more grounding is done .",
    "this is iterated until a model is found or a bound on the maximum domain size is hit ( if one is known ) .",
    "this technique is applied , e.g. , in the prover paradox  @xcite and the asp solver iclingo  .",
    "fourth , and closest to lazy grounding itself , is a large body of research devoted to delaying the grounding of specific types of expressions until necessary ( for example until they result in propagation ) .",
    "propagation techniques on the first - order level that delay grounding until propagation ensues have been researched within   and within  @xcite .",
    "such techniques can be used in conjunction with lazy grounding as they derive more intelligent justifications for specific types of constraints than presented here .",
    "for example , dao - tran et al . also presented an efficient algorithm for bottom - up propagation in a definition . within smt ,",
    "various theory propagators work by lazily transforming their theory into sat , such as for the theory of bit vectors by  .",
    "investigated quantifier handling by combining heuristic instantiation methods with research into decidable fragments of fo theories , as these can be efficiently checked for models . within",
    ", work has been done on goal - directed reasoning . both   and   demonstrate approaches , in the style of sld resolution , that apply top - down instantiation to answer queries over infinite domains .",
    "extend an abduction framework to lazily generate part of the relevant sentences . in search algorithms , justifications ( or _",
    "watches _ ) are used to derive when a constraint will not result in propagation or is already satisfied , and hence need not be checked in the propagation phase .",
    "show how maintaining ( short ) justifications can significantly reduce the cost of the propagation phase .",
    "in fact , a well - known technique already exists that combines search with lazy instantiation of quantifiers , namely _ skolemization _ , where existentially quantified variables are replaced by newly introduced function symbols .",
    "universal quantifications are handled by instantiating them for those introduced function symbols .",
    "reasoning on consistency can , e.g. , be achieved by congruence closure algorithms , capable of deriving consistency without effectively assigning an interpretation to the function symbols .",
    "these techniques are used in tableau theorem proving  @xcite and smt solvers  @xcite .",
    "formula  @xcite interleaves creating a ground program and giving it to an smt solver , iterating when symbolic guesses proved to be wrong .",
    "skolemization - based techniques typically work well in case only a small number of constants needs to be introduced , but have difficulty in case the relevant domain is large .",
    "one can also see that lazy grounding ( with support for function symbols ) could incorporate skolemization by adapting the rules for grounding existential and universal quantification .",
    "we expect skolemization to be complementary to lazy grounding , but an in - depth investigation is part of future work .    in the field of probabilistic inference , several related techniques have been developed that also rely on lazy instantiation .",
    "first , the problog system uses a form of static dependency analysis to ground a ( probabilistic ) program in the context of a given query , by constructing all possible ways to derive the query in a top - down fashion  .",
    "second , so - called _ lazy inference _ , applied e.g. in _ lazysat _",
    "@xcite , exploits the fact that , for the considered inference , a ( fixed ) _ default _ assumption exists under which an expression certainly does not contribute to the probabilities .",
    "hence , expressions for which the assumption certainly holds do not have to be considered during search .",
    "third , _ cutting plane inference _",
    "@xcite applies lazy inference in an interleaved setting , only constructing the part of the program for which the assumptions are not satisfied .",
    "several aspects of the presented work need further investigation . one aspect is extending support to lazily ground more complex expressions , including aggregate expressions and ( nested ) function terms .",
    "consider for example the sentence @xmath485 , which expresses that the sum of terms @xmath486 for which the atom @xmath171 is true , with @xmath177 , @xmath17 a predicate and @xmath487 a function , should be larger than 3 .",
    "one can observe that it is not necessary to ground the whole sentence up - front .",
    "for example , if @xmath487 maps to the natural numbers ( hence positive ) , the set @xmath488 is a minimal justification .",
    "even if no easy justification can be found , we can suffice by grounding only part of the sentence and delay the remainder .",
    "for example , we can create the ground sentence @xmath489 , with @xmath85 a tseitin symbol defined as @xmath490 .",
    "indeed , in any model of the sentence in which @xmath85 is false , the original inequality is satisfied .",
    "a second aspect is whether there are advantages to grounding earlier , for example to guarantee no propagation is lost , or grounding later , possibly reducing the size of the grounding even more .",
    "for example , consider the sentences @xmath491 and @xmath492 , with @xmath493 and @xmath350 both large formulas for which no justification was found . instead of grounding at least one of the sentences , we might add @xmath17 to the list of atoms the search algorithm has to assign and only ground either of the sentences when @xmath17 has been assigned a value ( it might even be that unsatisfiability is detected before grounding either one ) .    given that lazy grounding is useful , what about lazy _ forgetting _ the grounded theory ? as the ground theory is extended when",
    "making the structure more precise , the ground theory could be reduced again during backtracking . by storing the justification violations that caused grounding , we can derive",
    "which grounding can be forgotten again if the violation is no longer problematic ( e.g. , after backtracking ) . for this , an algorithm needs to be developed which tracks grounding / splitting dependencies between rules given their justifications .",
    "this closely resembles techniques used in tableau theorem proving and smt , where the theory at hand can be compacted when moving to a different part of the search space .",
    "the approach described for lazy grounding can also be applied to answer set generation in the field of . in ,",
    "a logic program under stable semantics can be seen as one rule set , a single definition .",
    "however , such asp programs do not satisfy a major condition to apply lazy grounding .",
    "indeed such programs are typically non - total , due to the presence of constraints and rules of the form @xmath494 or other _ choice rules _ which result in multiple stable models . however , as described by  , most practical programs can be partitioned in a set of choice rules , a set of _ total _ definitions and a set of constraints ( the so - called generate - define - test partition ) . any program that can be gdt - partitioned , can be translated straightforwardly into an equivalent theory that only contains total definitions .",
    "this suggests a way to apply lazy grounding to such programs .",
    "solvers used in the domains of sat , smt and asp are often confronted with problems that are too large to ground .",
    "lazy model expansion , the technique described in this paper , interleaves grounding and search in order to avoid the grounding bottleneck .",
    "the technique builds upon the concept of a justification , a deterministic recipe to extend an interpretation such that it satisfies certain constraints .",
    "a theoretical framework has been developed for lazy model expansion for the language and algorithms have been presented to derive and maintain such justifications and to interleave grounding with state - of - the - art cdcl search algorithms .",
    "the framework aims at bounded model expansion , in which all domains are finite , but is also an initial step towards handling infinite domains efficiently .",
    "experimental evaluation has been provided , using an implementation in the system , in which lazy model expansion was compared with a state - of - the - art ground - and - solve approach .",
    "the experiments showed considerable improvement over ground - and - solve in existing benchmarks as well as in new applications .",
    "the main disadvantage is the less - informed search algorithm , caused by the delay in propagation and the introduction of additional symbols .",
    "a possible solution is to develop new heuristics or portfolio approaches that combine the strengths of both methods .",
    "finally , we have indicated a way how the proposed methods can be applied beyond , to solvers in general .",
    "during this research , broes de cat was funded by the agency for innovation by science and technology in flanders ( iwt ) .",
    "this research was also supported by fwo - vlaanderen and by the project goa 13/010 , research fund kuleuven .",
    "nicta is funded by the australian government through the department of communications and the australian research council through the ict centre of excellence program .",
    "in this appendix , we mention parameter values as well as some optimizations that further reduce the grounding overhead and/or improve the search . for each optimization , we indicate what is currently implemented ( and part of the experimental results ) and what is part of future work .",
    "in  [ ssec : heur ] , a number of parameters were introduced to control the behavior of lazy model expansion .",
    "here , we provide details on the values used in the experimental evaluation .",
    "these values were set manually , based on experience and a limited number of observations ( e.g. , the extension threshold works similar to the conflict threshold of the sat solver ) .",
    "it is part of future work to study the impact of different values .",
    "* for an existential quantification , 10 instantiations are grounded at a time ; for a disjunction , 3 disjuncts are grounded at a time .",
    "this turned out to give the best balance between introducing too many tseitin atoms and grounding too much . *",
    "the initial truth value is @xmath495 with probability @xmath496 and @xmath455 otherwise . *",
    "the initial threshold for randomized restarts is 100 extensions of the ground theory .",
    "it is doubled after each restart . * a formula",
    "is considered small if its estimated grounding size is below @xmath497 atoms .",
    "so far , we have described a lazy model expansion algorithm for function - free .",
    "however , , the knowledge - base language of the system , supports a much richer input language . besides types which we use to initialize the domains it also supports ( partial ) functions , aggregates and arithmetic .",
    "our current implementation ignores the latter extensions through a straightforward adaptation of ( algorithm  [ fig : buildconstr ] ) : the case for literals is extended to return @xmath303when the literal is not part of the function - free language .",
    "for example , given a rule @xmath498 , @xmath499 can be used in a justification but @xmath500 can not . for functions ,",
    "there is also the option to replace them by graph predicates during the preprocessing step . as for the experiments of section  [ ssec : aspcompexper ] , functions ,",
    "if any , are given in the input structure and hence play no role .",
    "it is part of future work to extend lazy grounding for these extensions , especially for functions .",
    "techniques developed in smt and in constraint programming to handle ( ground ) atoms containing function symbols are useful to reduce the size of the grounding and improve search . in previous work ,",
    "these techniques have been integrated in the system  @xcite and it is certainly worthwhile to fully integrate them with lazy grounding .      in , it is checked for each assigned literal whether it is defined in @xmath193and whether it violates any justifications . to implement this cheaply ,",
    "our implementation maintains a mapping for literals in @xmath192 .",
    "it states whether the literal is defined in @xmath193and also lists the justifications in which its negation occurs .",
    "this mapping is extended whenever a new literal is added to @xmath192and maintained whenever justifications change .",
    "the performance of the search loop is unaffected as long as literals are assigned for which the mapping is empty .      in algorithm",
    "[ fig : lazymx ] , we took the standard stopping criterion used in most search algorithms ( line  [ stop - early ] ) : to stop in a conflict - free state where @xmath34is two - valued on all symbols of @xmath501 . in principle , we may stop earlier , with a partial structure @xmath34that admits a total justification for @xmath129 .",
    "indeed , corollary  [ col : acceptable ] tells us that such an @xmath40 can be expanded to a model .",
    "this has a considerable impact on grounding size . indeed , assigning a truth value to an atom @xmath502 defined in",
    "@xmath193that is irrelevant ( in effect , does not appear in the justification ) will trigger grounding of @xmath502 s definition , which in turn might introduce new literals defined in @xmath193 , causing a cascade of unnecessary groundings and assignments . our solver algorithm does not maintain a justification of @xmath192 , so it can not know exactly when a justification exists .",
    "instead , the implemented algorithm only chooses literals that are watched by some formula / rule .",
    "it stops with a partial structure in which unwatched literals may not be assigned .",
    "it can be shown that this suffices to guarantee that @xmath34admits a justification .",
    "hence it is safe to stop search .      in some cases ,",
    "can not find a valid justification for a large formula because a few literals are already false in @xmath34 .",
    "for example for a formula @xmath503 , returns @xmath303if at least one atom of @xmath17 is false .",
    "instead , we have adapted with a heuristic check on the number of expected violations .",
    "if it is small enough , the justification is still returned . naturally , we are then required to check whether there are any real violations , by querying the justification formula over @xmath34 , and apply to them .",
    "alviano , m. , calimeri , f. , charwat , g. , dao - tran , m. , dodaro , c. , ianni , g. , krennwallner , t. , kronegger , m. , oetsch , j. , pfandler , a. , phrer , j. , redl , c. , ricca , f. , schneider , p. , schwengerer , m. , spendier , l.  k. , wallner , j.  p. ,  xiao , g. 2013 .",
    "the fourth answer set programming competition : preliminary reportin cabalar , p.   son , t.  c. , lpnmr ,  8148 of lncs ,  4253 .",
    "springer .",
    "bruttomesso , r. , cimatti , a. , franzn , a. , griggio , a. , hanna , z. , nadel , a. , palti , a. ,  sebastiani , r. 2007 . a lazy and layered smt(bv )",
    "solver for hard industrial verification problemsin damm , w.   hermanns , h. , cav ,  4590 of lncs ,  547560 .",
    "springer .",
    "dao - tran , m. , eiter , t. , fink , m. , weidinger , g. ,  weinzierl , a. 2012 .",
    "omiga : an open minded grounding on - the - fly answer set solverin del cerro , l.  f. , herzig , a. ,  mengin , j. , jelia ,  7519 of lncs ,  480483 .",
    "springer .          , b. , denecker , m. ,  stuckey , p.  j. 2012 .",
    "lazy model expansion by incremental groundingin dovier , a.   costa , v.  s. , iclp ( technical communications ) ,  17 of lipics , 201211 .",
    "schloss dagstuhl - leibniz - zentrum fuer informatik .",
    "denecker , m. 2000 .",
    "extending classical logic with inductive definitionsin lloyd , j.  w. , dahl , v. , furbach , u. , kerber , m. , lau , k .- k . , palamidessi , c. , pereira , l.  m. , sagiv , y. ,  stuckey , p.  j. , cl ,  1861 of lncs ,  703717 .",
    "springer .",
    "denecker , m. , lierler , y. , truszczynski , m. ,  vennekens , j. 2012 . a tarskian informal semantics for answer set programmingin dovier , a.   costa , v.  s. , iclp ( technical communications ) ,  17 of lipics , 277289 .",
    "schloss dagstuhl - leibniz - zentrum fuer informatik .",
    "drescher , c.   walsh , t. 2012 .",
    "answer set solving with lazy nogood generationin dovier , a.   costa , v.  s. , iclp ( technical communications ) ,  17 of lipics , 188200 .",
    "schloss dagstuhl - leibniz - zentrum fuer informatik .",
    "eiter , t. , ianni , g. , schindlauer , r. ,  tompits , h. 2005 . a uniform integration of higher - order reasoning and external evaluations in answer - set programmingin kaelbling , l.  p.   saffiotti , a. , ijcai ,  9096 . professional book center .",
    "gebser , m. , kaminski , r. , kaufmann , b. , ostrowski , m. , schaub , t. , thiele , s. 2008 .",
    "engineering an incremental asp solverin garca de la banda , m.   pontelli , e. , iclp ,  5366 of lncs ,  190205 .",
    "springer .",
    "marek , v.  w.   truszczyski , m. 1999 .",
    "stable models and an alternative logic programming paradigmin apt , k.  r. , marek , v.  w. , truszczyski , m. ,  warren , d.  s. , the logic programming paradigm : a 25-year perspective ,  375398 .",
    "springer - verlag .",
    "marin , m. , wittocx , j. , denecker , m. ,  bruynooghe , m. 2008 .",
    ": satisfiability of propositional logic extended with inductive definitionsin kleine bning , h.   zhao , x. , sat ,  4996 of lncs ,  211224 .",
    "springer .",
    ", j.  p. , lynce , i. ,  malik , s. 2009 .",
    "conflict - driven clause learning sat solversin biere , a. , heule , m. , van maaren , h. ,  walsh , t. , handbook of satisfiability ,  185 of frontiers in artificial intelligence and applications ,  131153 .",
    "ios press .",
    "son , t.  c. , pontelli , e. ,  le , t. 2014 .",
    "two applications of the asp - prolog system : decomposable programs and multi - context systemsin flatt , m.   guo , h .- f . ,",
    "padl ,  8324 of lecture notes in computer science , 87103 . springer ."
  ],
  "abstract_text": [
    "<S> finding satisfying assignments for the variables involved in a set of constraints can be cast as a ( bounded ) _ model generation _ problem : search for ( bounded ) models of a theory in some logic . </S>",
    "<S> the state - of - the - art approach for bounded model generation for rich knowledge representation languages like and and a csp modeling language such as zinc , is _ ground - and - solve _ : reduce the theory to a ground or propositional one and apply a search algorithm to the resulting theory .    </S>",
    "<S> an important bottleneck is the blow - up of the size of the theory caused by the grounding phase . </S>",
    "<S> _ lazily grounding _ the theory during search is a way to overcome this bottleneck . </S>",
    "<S> we present a theoretical framework and an implementation in the context of the knowledge representation language . instead of grounding all parts of a theory , _ justifications _ </S>",
    "<S> are derived for some parts of it . given a partial assignment for the grounded part of the theory and valid justifications for the formulas of the non - grounded part , the justifications provide a recipe to construct a complete assignment that satisfies the non - grounded part . </S>",
    "<S> when a justification for a particular formula becomes invalid during search , a new one is derived ; if that fails , the formula is split in a part to be grounded and a part that can be justified . </S>",
    "<S> experimental results illustrate the power and generality of this approach . </S>"
  ]
}