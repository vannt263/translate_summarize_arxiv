{
  "article_text": [
    "aperture synthesis in radio interferometry is a powerful technique that dates back more than sixty years  @xcite .",
    "it allows observation of the sky with otherwise inaccessible angular resolution and sensitivity ( i.e.  dynamic range ) , providing a wealth of information for astrophysics and cosmology .",
    "the measurement equation for aperture synthesis provides incomplete linear information about the signal , thus defining an ill - posed inverse problem in the perspective of signal reconstruction . under restrictive assumptions of narrow - band ( i.e.  monochromatic ) non - polarized imaging on small fields of view",
    ", the visibilities measured identify with fourier measurements . already powerful calibration and imaging techniques",
    "have been developed in the field .",
    "standard imaging algorithms , such as clean and its multi - scale variants  @xcite , regularize the inverse problem through an implicit sparsity assumption of the signal in the spatial dimensions .",
    "the new science envisaged in astronomy in the coming decades requires that next - generation radio telescopes , such as the new low frequency array ( lofar ) , or the future extended very large array ( evla ) and square kilometer array ( ska ) , achieve much higher dynamic range than current instruments , also at higher angular resolution .",
    "these telescopes will also have to consider wide - band ( i.e.  hyper - spectral ) polarized imaging on wide fields of view on the celestial sphere .",
    "direction - dependent effects further complicate the measurement equation , and will have to be calibrated and accounted for in this high - dimensional imaging process , and calibrated . in this context ,",
    "calibration and imaging techniques for radio interferometry literally need to be re - invented , thus triggering an intense research in the field .    the now famous theory of compressed sensing deals with the recovery of sparse signals from incomplete linear measurements  @xcite .",
    "it acknowledges the fact that natural signals often exhibit a sparse representation in multi - scale bases . compressed",
    "sensing proposes both optimization of the acquisition technique , and non - linear iterative algorithms for signal reconstruction regularizing the ill - posed inverse problem through a sparsity prior .",
    "these algorithms are defined either in the context of convex optimization , or greedy approaches .",
    "it is also important to note that , beyond the pure theory of compressed sensing , these frameworks are particularly versatile and can account for a large variety of priors .    the first application of compressed sensing to radio interferometry was performed by @xcite , where the problem of image reconstruction from incomplete visibility measurements was considered .",
    "@xcite demonstrated the versatility of the approach and its superiority relative to standard interferometric imaging techniques .",
    "the spread spectrum phenomenon , which arises by partially relaxing the small field - of - view ( fov ) assumption and including a first order @xmath0 term , was introduced by @xcite as a potential optimization of the acquisition , leading to enhanced image reconstruction quality for sparsity bases that are not maximally incoherent with the measurement basis .",
    "furthermore , a compressed sensing approach was developed and evaluated by @xcite to recover the signal induced by cosmic strings in the cosmic microwave background .",
    "@xcite generalise the compressed sensing imaging techniques developed by @xcite and @xcite to a wide fov , recovering interferometric images defined directly on the sphere , rather than a tangent plane .",
    "all of these works consider uniformly random and discrete visibility coverage in order to remain as close to the theory of compressed sensing as possible .",
    "first steps towards more realistic visibility coverages have been taken by @xcite and @xcite , who consider coverages due to specific interferometer configurations but which remain discrete .",
    "@xcite studied a compressed sensing imaging approach based on the isotropic undecimated wavelet transform , reporting results from discrete simulated coverages of askap .",
    "these preliminary works suggest that the performance of compressed sensing reconstructions is likely to hold for more realistic visibility coverages .",
    "convex optimization methods coupled with sparsity priors have proven to be a powerful framework for radio - interferometric imaging . beyond the versatility that enables one to impose a wide range of sparsity priors ,",
    "convex optimization provides significant improvements in the speed of the reconstruction process relative to state - of - the - art imaging methods in radio interferometry .",
    "this enhancement in speed is crucial for the scalability of the techniques to very high dimensions in the perspective of next - generation telescopes .    in the present work ,",
    "we propose a novel algorithm for radio interferometric imaging , defined in the framework of convex optimization , dubbed the sparsity averaging reweighted analysis ( sara ) algorithm .",
    "the algorithm relies on the conjecture that astrophysical signals are simultaneously sparse in various bases , in particular the dirac basis , wavelet bases , or in their gradient , so that promoting average signal sparsity over multiple wavelet bases represents an extremely powerful prior .",
    "for comparison , we also study a variety of fast image reconstruction algorithms designed in the frameworks of convex optimization and sparse signal modelling , some of which were identified as providing similar performance as clean and its multi - scale versions .",
    "we show , through realistic simulations , the superiority of sara compared to most radio - interferometric imaging techniques .    the organization of the remainder of the paper is the following . in section  [ sec : convex optimization for sparse reconstruction ] , we review convex optimization methods for sparse inverse problems in the compressed sensing framework and discuss their versatility . in section  [ sec :",
    "radio interferometric imaging ] , we recall the inverse problem for image reconstruction from radio - interferometric data and concisely describe the state - of - the - art image reconstruction techniques used in radio astronomy . section  [ sec : sara ] presents the sara algorithm .",
    "numerical results of the sara algorithm compared to state - of - the - art imaging techniques are presented in section  [ sec : simulations and results ] .",
    "finally we conclude in section  [ sec : conclusion ] with closing thoughts .",
    "convex optimization provides a powerful and versatile framework to solve sparse linear inverse problems such as those posed in radio interferometry . in this section",
    ", we concisely recall the inverse problem for sparse signals considered in the compressed sensing framework and proceed further with a discussion of the versatility offered by convex optimization approaches . finally , we review the key ideas behind the methods to solve these convex problems .      in the framework of compressed sensing @xcite the signals probed",
    "are firstly assumed to be sparse or compressible in some basis .",
    "consider a complex - valued signal denoted by the vector @xmath1 .",
    "an orthonormal basis @xmath2 is also considered , in which the decomposition @xmath3 of the signal is defined by @xmath4 . the signal is said to be sparse if it contains only @xmath5 non - zero coefficients in its decomposition , where @xmath6 , or compressible if its ordered set of coefficients decays rapidly and the signal can be well approximated by just the first @xmath5 coefficients .    secondly , the signal is assumed to be probed by @xmath7 linear measurements denoted by a vector @xmath8 in some sensing basis @xmath9 and possibly affected by independent and identically distributed noise @xmath10 .",
    "this defines an inverse problem @xmath11 where the matrix @xmath12 identifies the sensing basis as seen from the sparsity itself .",
    "typically @xmath13 so that the inverse problem is ill - posed .",
    "the ideal approach to recover @xmath14 from is to find the sparsest representation @xmath15 that is consistent with the measurements , posing the following problem : @xmath16 where the @xmath17 norm , @xmath18 , counts the number of non - zero elements in @xmath15 and @xmath19 is an upper bound on the @xmath20 norm @xmath21 of the residual noise , with @xmath22 .",
    "let us recall that the @xmath23 norm of a complex - valued vector @xmath24 is defined as @xmath25 , where @xmath26 represents the modulus of a complex number .",
    "the problem in ( [ cs3 ] ) is combinatorial and np - complete . the most common approach is to replace the @xmath17 norm by the @xmath27 norm and pose a convex problem to estimate a solution  @xcite . in the presence of noise ,",
    "the so - called basis pursuit denoise problem is the minimization of the @xmath27 norm @xmath28 of the coefficients of the signal in the sparsity basis under a constraint on the @xmath20 norm @xmath21 of the residual noise : @xmath29 the theory shows that the @xmath30 and basis pursuit denoise problems are equivalent under certain properties of the sensing matrix , @xmath12  @xcite .",
    "the theory also offers various ways to design suitable sensing matrices , showing in particular that a small number of measurements is required relative to a naive nyquist - shannon sampling : @xmath31 .",
    "note that , in theory , an explicit @xmath30 minimization would require fewer measurements , @xmath32  @xcite .",
    "a family of iterative greedy algorithms are also proposed in the literature  @xcite .",
    "these algorithms are shown to enjoy similar approximate reconstruction properties , however , requiring more measurements for exact reconstruction than convex optimization approaches .",
    "while the theory of compressed sensing provides reconstruction guarantees for the @xmath33 minimization problem , convex optimization is extremely versatile and can account for many variations , which in practice can prove more effective for signal reconstruction . in the following",
    "we briefly describe these variations .",
    "[ [ positivity ] ] positivity : + + + + + + + + + + +    one of the main advantages of convex approaches is the flexibility that they provide to include prior information about the signal as convex constraints . in the case of image processing problems , where most images of interest are intensity images , the signals are real - valued and positive , i.e. @xmath34 .",
    "this constraint is convex and can be easily added to the optimization problems without much computational load increase and without affecting their convergence .",
    "this constraint has proven to be very effective in improving reconstruction quality in radio - interferometric imaging  @xcite .",
    "[ [ constrained - vs - unconstrained - problems ] ] constrained vs unconstrained problems : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the least squares @xmath33 regularized problem is an alternative formulation of the basis pursuit denoising problem that recovers a sparse signal as the solution of an unconstrained problem formulated as : , where @xmath35 is a regularization parameter that balances the weight between the fidelity term and the regularization term .",
    "it follows that determining the proper value of @xmath35 is akin to determining the power limit of the noise  @xcite .",
    "however , there is no optimal strategy to fix the regularization parameter even if the noise level is known , therefore constrained problems , such as , offer a stronger fidelity term when the noise power is known , or can be estimated _ a priori_.    [ [ orthogonal - vs - overcomplete - representations ] ] orthogonal vs overcomplete representations : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the techniques mentioned above hold for signals which are sparse in the standard coordinate basis or sparse with respect to some other orthonormal basis .",
    "however , there are numerous practical examples in which a signal of interest is not sparse in a single orthonormal basis but over several orthonormal bases or over an overcomplete dictionary  @xcite . in the generalized",
    "setting the signal @xmath36 is now expressed in terms of a dictionary @xmath37 ( @xmath38 ) as @xmath39 , @xmath40 . note that the problem is now severely underdetermined since @xmath41 , therefore requiring greater sparsity or compressibility of @xmath14 .",
    "@xcite find conditions on the compound matrix @xmath42 such that @xmath14 can be recovered accurately , which leads to a good estimate of @xmath36 .",
    "@xcite extend the compressed sensing theory to redundant dictionaries , providing theoretical stability guarantees based on general conditions on the sensing matrix @xmath43 .",
    "[ [ analysis - vs - synthesis - problems ] ] analysis vs synthesis problems : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the basis pursuit denoising problem defines the optimization in the sparse representation domain finding the optimal representation vector @xmath15 and then recovering the true signal trough the synthesis relation @xmath44 .",
    "these methods are known as synthesis based methods in the literature .",
    "synthesis - based problems may also be substituted by analysis - based problems , where instead of estimating a sparse representation of the signal , the methods recover the signal itself  @xcite . in the case of orthonormal bases ,",
    "@xmath45 , the two approaches are equivalent . however , when @xmath45 is a frame or an overcomplete dictionary , the two problems are no longer equivalent .",
    "the geometry of the two problems are studied by @xcite , who show that because these geometrical structures exhibit substantially different properties , there is a large gap between the two formulations .",
    "one remark to make is that the analysis problem does not increase the dimensionality of the problem relative to solving for the signal itself , even in the case when overcomplete dictionaries are used .",
    "empirical studies have shown very promising results for the analysis approach  @xcite . @xcite",
    "provide a theoretical analysis of the @xmath33 analysis problem coupled with redundant dictionaries .",
    "[ [ reweighted - ell_1-vs - ell_1-minimization ] ] reweighted @xmath33 vs @xmath33 minimization : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    as discussed above , the @xmath33 minimization problem is equivalent to @xmath30 minimization when the measurement matrix satisfies certain conditions defined in the context of compressed sensing . in general",
    "though , the key difference between the two problems , of course , is that @xmath33 depends on the magnitudes of the coefficients of a signal , whereas @xmath30 minimization does not . to reconcile this imbalance ,",
    "a reweighted @xmath33 minimization algorithm was proposed by @xcite to mimic the @xmath30 minimization behaviour .",
    "the algorithm replaces the @xmath33 norm in by a weighted @xmath33 norm @xmath46 .",
    "the idea behind this formulation is that large weights will encourage small coordinates of the solution vector , and small weights will encourage larger coordinates . as a motivational example suppose that the sparse signal @xmath47 is known _ a priori _ and that we set the weights as @xmath48 . in this case",
    "the weights are infinite at all locations where the signal is zero , forcing the coordinates of the solution vector at these locations to be zero .",
    "this set of weights makes the weighted norm independent of the precise value of the non - zero components and guarantees to recover the correct solution assuming only @xmath49 .    in practice",
    ", the original signal is not known in advance but we can compute the appropriate weights by solving sequentially weighted @xmath33 problems , each using as weights essentially the inverse of the values of the solution of the previous problem . of course , it is not possible to have infinite weights where the estimated signal values are zero , so a stability parameter must also be added to the signal value in the selection of the weights . this procedure has been observed to be very effective in reducing the number of measurements needed for recovery , and to outperform standard @xmath33-minimization in many situations , see e.g. @xcite .",
    "unlike many generic optimization problems , convex optimization problems can be efficiently solved , both in theory ( i.e. , via algorithms with worst - case polynomial complexity ) and in practice @xcite .",
    "there exists a broad range of methods to efficiently solve convex problems , e.g. interior point methods , primal - dual methods and proximal splitting methods . among these",
    ", proximal splitting methods offer great flexibility and are shown to capture and extend several well - known algorithms in a unifying framework .",
    "douglas - rachford , iterative thresholding , projected landweber , projected gradient , alternating projections , alternating direction method of multipliers , alternating split bregman are special instances of proximal splitting algorithms @xcite .",
    "such methods offer a powerful framework for solving convex problems in terms of speed and scalability of the techniques to very high dimensions .",
    "proximal splitting methods solve optimization problems of the form @xmath50 where @xmath51 are convex functions from @xmath52 to @xmath53 .",
    "note that any convex constrained problem can be formulated as an unconstrained problem by using the indicator function of the convex constraint set as one of the functions in , i.e. @xmath54 where @xmath55 represents the constraint set . also note that complex - valued vectors are treated as real - valued vectors with twice the dimension ( accounting for real and imaginary parts ) . a major difficulty that arises in solving this problem stems from the fact that , typically , some of the functions are not differentiable , which rules out conventional smooth optimization techniques .",
    "the key concept in proximal splitting methods is the use of the proximity operator of a convex function , which is a natural extension of the notion of a projection operator onto a convex set .",
    "for example , the proximal operator of the @xmath33 norm is the soft - thresolding operator , and the proximal operator of the indicator function of a constraint is simply the projection operator onto the constraint set .",
    "proximal splitting methods proceed by splitting the contribution of the functions @xmath56 individually so as to yield an easily implementable algorithm .",
    "they are called proximal because each non - smooth function in is involved via its proximity operator .",
    "in essence , the solution to is reached iteratively by successive application of the proximity operator associated with each function .",
    "see @xcite for a review of proximal splitting methods and their applications in signal and image processing .",
    "one remark to make is that there also exist proximal splitting algorithms that offer a parallel implementation structure where all the proximity operators can be computed in parallel rather than sequentially .",
    "examples of these algorithms are the proximal parallel algorithm and the simultaneous - direction method of multipliers  @xcite .",
    "such a structure is useful when implementing the algorithms in multicore architectures , thus providing a significant gain in terms of speed .",
    "in this section we recall the general form of the visibility measurements and also pose the corresponding interferometric inverse problem for image reconstruction under small fov considerations .",
    "we also review the state - of - the - art imaging algorithms in radio interferometry .      in order to image a region of the sky , all radio telescopes of an interferometric array point in the same direction @xmath57 on the unit celestial sphere .",
    "we consider a cartesian coordinate system centred on the earth aligned with the pointing direction . at each instant of observation ,",
    "each telescope pair measures a complex visibility defined as the correlation between incoming electric fields at the positions of the two telescopes .",
    "this visibility only depends on the relative position between the two telescopes , defined as a baseline .",
    "we consider a monochromatic signal @xmath58 , and made up of incoherent sources .",
    "also , we consider non - polarized radiation and a small fov such that the signal on the celestial sphere is well approximated by its projection on to plane orthogonal to @xmath59 . in this context , each visibility corresponds to the measurement of the fourier transform of a planar signal at the spatial frequency @xmath60 where @xmath61 identifies the baseline components in the image plane , and in units of the observation wavelength .",
    "this result is known as the van cittert - zernike theorem  @xcite .",
    "the measured visibility reads as : @xmath62 where @xmath63 denotes the coordinates on the image plane and @xmath64 is the so - called primary beam , which limits the observed fov .",
    "the total number of points @xmath65 probed by all telescope pairs of the array during the observation provides some incomplete coverage in the fourier plane characterizing the interferometer .      in a practical",
    "setting we want to represent the map @xmath58 by a discretized image .",
    "the band - limited functions considered are completely identified by their nyquist - shannon sampling on a discrete uniform grid of @xmath66 points @xmath67 in real space with @xmath68 and by their corresponding discrete spatial frequencies @xmath69 .",
    "the sampled intensity signal and primary beam are denoted by the vectors @xmath70 respectively .    as in @xcite , we assume that the spatial frequencies @xmath65 probed by all telescope pairs during the observation belong to the discrete uniform grid of points @xmath69 , thus bypassing gridding considerations for the sake of simplicity . the fourier coverage provided by the @xmath7 spatial frequencies probed can simply be identified by a binary mask in the fourier plane equal to @xmath71 for each spatial frequency probed and @xmath72 otherwise .",
    "the visibilities measured may be denoted by a vector of @xmath7 complex fourier coefficients @xmath73 , possibly affected by complex noise of astrophysical or instrumental origin , identified by the vector @xmath10 .",
    "since the signal @xmath36 is real - valued , we could only take measurements in half of the plane and infer the measurements of the other half through conjugate relations .    in this discrete setting ,",
    "the fourier coverage is in general incomplete in the sense that the number of real constraints @xmath74 is smaller than the number of unknowns @xmath75 ; complete coverage of the fourier plane corresponds to @xmath76 .",
    "an ill - posed inverse problem is thus defined for the reconstruction of the signal @xmath36 from the measured visibilities @xmath77 : @xmath78 where the matrix @xmath9 identifies the complete linear relation between the signal and the visibilities .",
    "the matrix @xmath79 is the diagonal matrix implementing the primary beam .",
    "the unitary matrix @xmath80 implements the discrete fourier transform providing the fourier coefficients .",
    "the matrix @xmath81 is the rectangular binary matrix implementing the mask characterizing the interferometer .",
    "the inverse transform of the binary mask , i.e. @xmath82 with @xmath83 defining the vector of ones , identifies the dirty beam and the inverse transform of the fourier measurements with all non - observed visibilities set to zero , i.e. @xmath84 , is the dirty image .    for signal reconstruction , a regularization scheme that encompasses",
    "enough prior information on the original signal is needed in order to find a unique solution .",
    "all image reconstruction algorithms will differ through the kind of regularization considered .",
    "the most standard and otherwise already very effective image reconstruction algorithm from visibility measurements is called clean , which is a non - linear deconvolution method based on local iterative beam removal @xcite .",
    "a sparsity prior on the original signal in real space is implicitly introduced .",
    "multi - scale versions of clean ( ms - clean ) have also been developed @xcite , where the sparsity is improved by multi - scale decomposition , hence enabling better recovery of the signal .",
    "the ms - clean method was shown to perform better than the standard clean , but still suffers from an empirical choice of basis profiles and scales .",
    "an adaptive scale pixel decomposition method called asp - clean was also introduced to improve on multi - scale clean by relying on an adaptive choice of scales @xcite .",
    "note that these approaches are known to be slow , sometimes prohibitively .",
    "another approach to the reconstruction of images from visibility measurements is the maximum entropy method ( mem ) .",
    "in contrast to clean , mem solves a global optimization problem in which the inverse problem is regularized by the introduction of an entropic prior on the signal , but sparsity is not explicitly required @xcite . in practice ,",
    "clean is often preferred to mem .",
    "reconstruction techniques based on convex optimization and sparse models have also been proposed .",
    "approaches based on @xmath33 minimization coupled with the dirac basis have been previously studied in the field  @xcite .",
    "the equivalence between clean and @xmath33 minimization has been studied in @xcite .",
    "@xcite and @xcite report that @xmath33 minimization yields similar reconstruction quality to clean , while including a positivity constraint in a convex formulation significantly enhances the reconstruction quality relative to clean .",
    "extended structures do not have an optimal sparse representation in dirac basis .",
    "thus , wavelet bases have also been considered in order to provide a sparser representation .",
    "synthesis - based approaches with redundant representations have been proposed by @xcite and @xcite .",
    "@xcite use a reweighted @xmath33 approach coupled with a steerable wavelet frame as sparsity dictionary .",
    "@xcite use a least squares @xmath33 regularized problem with the isotropic undecimated wavelet transform ( iuwt ) as sparsity dictionary .",
    "the reconstruction quality of the iuwt method was reported to be superior than those of clean and ms - clean .",
    "many signals in nature are also sparse or compressible in the magnitude of their gradient space , in which case the tv minimization problem has been shown to yield superior reconstruction results  @xcite .",
    "the tv norm is defined by the @xmath33 norm of the magnitude of the gradient of the signal @xmath85 , where @xmath86 denotes the gradient magnitude @xcite . from this formulation",
    ", it can be seen that the tv problem might be modelled as an analysis @xmath33 minimization problem with the discrete gradient operator as the sparsity inducing transform .",
    "tv minimization was already proposed for radio - interferometric imaging by @xcite and @xcite showing promising results .",
    "moreover , @xcite used a reweighted tv minimization approach to recover the signal induced by cosmic strings in the cosmic microwave background .",
    "in this section we propose a novel algorithm for radio - interferometric imaging based on the prior of average signal sparsity over multiple wavelet bases .",
    "we start by discussing our conjecture of average signal sparsity .",
    "then , we propose the reweighted @xmath33 analysis method as a means to promote average sparsity . finally , we present the resulting algorithm .      as already discussed in the previous sections , while point and compact sources have a sparse representation in the dirac basis , piecewise smooth structures exhibit gradient sparsity , and continuous extended structures are better encapsulated in wavelet bases .",
    "astronomical images are often complex and all these types of structures can be present at once . therefore , we here conjecture that promoting average sparsity or compressibility over multiple bases rather single bases represents an extremely powerful prior . note on a theoretical level that a single signal can not be arbitrarily sparse simultaneously in any pair of bases , due to the incoherence between these bases ( see @xcite and references therein for a definition of incoherence ) . for illustration , a signal extremely sparse in the dirac basis is completely spread in the fourier basis .",
    "we hypothesize that , for any pair of bases , there might exist a lower bound on the average sparsity of a signal , which identifies a generalized `` uncertainty relation '' . in essence , our prior consists of assuming that the signals of interest are those that saturate this uncertainty relation between multiple pairs of bases .",
    "we propose using a dictionary composed of a concatenation of orthonormal bases , i.e. @xmath87,\\ ] ] thus @xmath88 with @xmath89 . given the previous considerations on astronomical images , the dictionary should be composed of the dirac basis and wavelet bases . in particular , the haar wavelet basis can be used as an alternative to gradient sparsity ( usually imposed by a tv prior ) to promote piecewise smooth signals . see section  [ ssec : saraimp ] for further details on a practical selection of these bases .      in the light of our previous discussions on the versatility of convex optimization",
    ", we promote this average sparsity through a reweighted @xmath33 analysis method .",
    "let us define the weighted @xmath33 problem @xmath90 where @xmath91 is a diagonal matrix with positive weights and the constraint @xmath92 represents the positivity prior on @xmath36 .",
    "assuming i.i.d .",
    "complex gaussian noise with variance @xmath93 , the @xmath20 norm term in is identical to a bound on the @xmath94 distribution with @xmath74 degrees of freedom governing the noise level estimator .",
    "therefore , we set this bound as @xmath95 , where @xmath96 is the variance of both the real and imaginary part of the noise .",
    "this choice provides a likely bound for @xmath97 , since the probability that @xmath98 exceeds @xmath99 is the probability that a @xmath94 with @xmath74 degrees of freedom exceeds its mean , @xmath74 , by at least two times the standard deviation @xmath100 , which is very small . the solution to is denoted as @xmath101 , which is a function of the data vector @xmath77 , the measurement and weight matrices @xmath43 and @xmath102 , and the bound @xmath19 on the noise level estimator .",
    "recall that in the reweighting approach a sequence of weighted @xmath33 problems is solved , each using as weights essentially the inverse of the values of the solution of the previous problem . in practice , we update the weights at each iteration , i.e. after solving a complete weighted @xmath33 problem , by the function @xmath103 where @xmath104 plays the role of a stabilization parameter ( ideally zero ) .",
    "note that as @xmath105 the weighted @xmath33 norm approaches the @xmath30 norm . to approximate the @xmath30 norm by the reweighted @xmath33 algorithm",
    ", we use a homotopy strategy  @xcite and solve a sequence of weighted @xmath33 problems using a decreasing sequence @xmath106 , with @xmath107 denoting the iteration time variable . under this scheme ,",
    "a weighted @xmath33 problem is first solved and its solution is used as the warm start initialization for the next problem that is geometrically closer to the @xmath30 problem .",
    "this process is then repeated until the solution becomes stationary  @xcite .",
    "the resulting algorithm , dubbed sparsity averaging reweighted analysis ( sara ) , is defined in algorithm  [ alg3 ] .",
    "a rate parameter @xmath108 , with @xmath109 , controls the decrease of the sequence @xmath110 such that @xmath111 as @xmath112 .",
    "ideally , @xmath113 should decrease to zero , but since we have noise , we set a lower bound as @xmath114 . the standard deviation of the noise in the representation domain is computed as @xmath115 , which gives a rough estimate for a baseline above which significant signal components could be identified . as a starting point",
    "we set @xmath116 as the solution of the @xmath33 problem and @xmath117 , where @xmath118 stands for the empirical standard deviation of the signal , fixing the signal scale .",
    "the reweighting process ideally stops when the relative variation between successive solutions @xmath119 is smaller than some bound @xmath120 , with @xmath121 , or after the maximum number of iterations allowed , @xmath122 , is reached . in our implementation ,",
    "which will be detailed in section  [ ssec : saraimp ] , we fix @xmath123 and @xmath124 .",
    "@xmath77 , @xmath43 , @xmath19 , @xmath125 , @xmath108 , @xmath120 and @xmath122 .",
    "reconstructed image @xmath126 .",
    "initialize @xmath127 , @xmath128 and @xmath129 .",
    "compute + @xmath130 , + @xmath117 . update the weight matrix + @xmath131 , for @xmath132 + with @xmath133 compute a solution + @xmath134 .",
    "+ update @xmath135 .",
    "in this section we evaluate the performance of the sara algorithm through numerical simulations .",
    "firstly , we describe the practical implementation of sara and state - of - the - art algorithms used as benchmarks .",
    "secondly , we describe the simulation set up in the context of the inverse problem associated with .",
    "thirdly , we report the results of the comparison of sara to the state - of - the - art . finally , we present an illustrative example of the performance of sara in the presence of the spread spectrum phenomenon .      for all the experiments we consider a concatenation of nine bases ( @xmath138 ) , thus @xmath88 with @xmath139 , as the dictionary for sara .",
    "the first basis is the dirac basis .",
    "the eight remaining bases are the first eight daubechies wavelets , db1-db8  @xcite .",
    "the first daubechies wavelet basis , db1 , is the haar wavelet basis .",
    "we use a fourth order decomposition depth for all wavelet bases .",
    "we compare sara to state - of - the - art algorithms for @xmath33 and tv minimization problems , as well as their reweighted versions , in terms of reconstruction quality and computation time .",
    "firstly , the reweighted @xmath33 problems considered are defined through the reweighting procedure described in section [ ssec : rwl1 ] based on , with specific choices of the sparsity dictionary @xmath45 .",
    "we consider three different options for @xmath45 : the dirac basis , the daubechies 8 wavelet basis and the isotropic undecimated wavelet redundant dictionary .",
    "the associated methods are respectively denoted r - bp , r - bpdb8 and r - bpiu . the ( non - reweighted ) @xmath33 problems are defined through with @xmath140 and again different choices of the sparsity dictionary @xmath45 .",
    "we here consider four different options for @xmath45 : the dirac basis , the daubechies 8 wavelet basis , the isotropic undecimated wavelet dictionary and the concatenation of 9 bases described above for sara .",
    "the associated methods are respectively denoted bp , bpdb8 , bpiu and bpsa .",
    "secondly , the tv minimization problem is formulated as : @xmath141 we have also implemented a reweighted version of tv ( still through the procedure defined in section [ ssec : rwl1 ] ) , denoted as r - tv .",
    "finally , we also use as benchmark the synthesis - based iuwt method of @xcite and we denote it as iuwt . in the light of the discussion in section [ ssec : state of the art imaging algorithms ]",
    "we assume that the reconstruction quality provided by bp is essentially equivalent to that of the standard clean algorithm , and that the reconstruction quality provided by iuwt is an upper bound on the reconstruction quality of any multi - scale implementation of clean .    to solve and",
    ", we use the douglas - rachford splitting algorithm , which is tailored to solve problems of the form for @xmath142 and with the additional property of not requiring differentiability of any of the functions  @xcite .      [ cols=\"^,^,^ \" , ]",
    "in this paper we have proposed a novel algorithm for image reconstruction in radio interferometry dubbed sparsity averaging reweighted analysis ( sara ) .",
    "the algorithm relies on the conjecture that astrophysical signals are simultaneously sparse in multiple bases , in particular the dirac basis , wavelet bases , or in their gradient , so that promoting average signal sparsity over multiple wavelet bases represents an extremely powerful prior .",
    "experimental results demonstrate that sara outperforms state - of - the - art imaging methods in the field , all based on the assumption of signal sparsity in a single basis or signal gradient sparsity .    in future work",
    "we plan to focus on extending the current algorithm to handle continuous visibilities . in this respect , a stable version of the algorithm",
    "must be implemented in a low level programming language . also , the final evolution should take advantage of proximal splitting algorithms with parallel and distributed structures allowing implementation in multicore architectures or in computer clusters .",
    "such approaches are crucial for the scalability of the proposed algorithm to very high dimensions when dealing with continuous visibilities .",
    "we thank pierre vandergheynst , jean - philippe thiran and dimitri van de ville for providing the infrastructure to support our research .",
    "rec is supported by the swiss national science foun- dation ( snsf ) under grant 200021 - 130359 .",
    "jdm is supported by a newton international fellowship from the royal society and the british academy and , during this work , was also supported by a leverhulme early career fellowship from the leverhulme trust .",
    "yw is supported in part by the center for biomedical imaging ( cibm ) of the geneva and lausanne universities , epfl and the leenaards and louis - jeantet foundations , and in part by the snsf under grant pp00p2 - 123438 .",
    "combettes p. l. , pesquet j .- c . , 2011 ,",
    "proximal splitting methods in signal processing , in bauschke h. h. , burachik r.s . ,",
    "combettes p.l . ,",
    "elser v. , luke d.r . , wolkowicz h. , eds , fixed - point algorithms for inverse problems in science and engineering"
  ],
  "abstract_text": [
    "<S> we propose a novel algorithm for image reconstruction in radio interferometry . </S>",
    "<S> the ill - posed inverse problem associated with the incomplete fourier sampling identified by the visibility measurements is regularized by the assumption of average signal sparsity over representations in multiple wavelet bases . </S>",
    "<S> the algorithm , defined in the versatile framework of convex optimization , is dubbed sparsity averaging reweighted analysis ( sara ) . </S>",
    "<S> we show through simulations that the proposed approach outperforms state - of - the - art imaging methods in the field , which are based on the assumption of signal sparsity in a single basis only .    </S>",
    "<S> [ firstpage ]    techniques : image processing  techniques : interferometric . </S>"
  ]
}