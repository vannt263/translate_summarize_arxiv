{
  "article_text": [
    "in this paper we study the two mode optimal switching problem ( osp ) under incomplete information .",
    "the manager can choose to be either in state @xmath1 or state @xmath2 . in state",
    "@xmath2 the production facility is open and one continuosly collects the stoachstic revenue @xmath3 . in state @xmath1 , the facility is closed and generates no revenue .",
    "the task of the manager is to choose when to open / close the facility in order to generate maximum profit . if the process @xmath3 is fully observed and there is no cost of switching between open and closed , it is intuitevly clear that the manager should let the facility be open when @xmath4 and closed when @xmath5 .",
    "however , when costs are associated to opening or closing , it may be more profitable to leave the plant open for a while even if @xmath6 ( or , simliarly , leave it closed even if @xmath4 ) .",
    "furthermore , if the process @xmath3 can not be fully observed , the manager has to base her decisions on incomplete information of the underlying process @xmath3 .",
    "the problem of optimal switching under full information has been widely studied during the last decades and mainly three different approaches have turned out to be useful , two based on stochastic techniques and one on deterministic ditto .",
    "firstly , snell envelopes was used by @xcite in combination with a verification theorem to prove the existence of a unique value function .",
    "secondly , the optimal switching problem can be tackled using reflected backward stochastic differential equations ( bsdes ) and we refer to @xcite , @xcite , @xcite , and the references therein for more on this reflected bsde approach . for the connection between snell envelopes and bsdes we refer to @xcite .",
    "thirdly , the optimal switching problem has been studied using deterministic methods based on systems of variational inequalities .",
    "more on this deterministic approach to the osp can be found in @xcite , @xcite , @xcite , @xcite and the references therein .",
    "when dealing with the incomplete information optimal switching problem ( iiosp ) considerably less work seems to be done and the author is only aware of the paper @xcite , in which the authors formulate and develop numerical methods for this type of problem . under incomplete information and",
    "when using the formalism of stochastic filtering as in @xcite , the iiosp is in general not analytically tractable and numerical methods seem inevitable .",
    "however , in this paper we derive some analytical results concerning a simplistic model of the iiosp introduced in @xcite . to be more specific",
    ", we study the iiosp in a setting similar to that of @xcite , in which the related problem of incomplete information optimal stopping is studied .",
    "we prove that the value function is convex , non - decreasing in the amount of available information and that it converges to the value function of the standard osp as the noise in the observation tends to @xmath1 .",
    "we emphasize that , in the current situation , the analytical approach of this paper is mainly conceptual while the numerical method developed in @xcite deal with more general iiosps and is readily available for applications .",
    "the rest of this paper is organized as follows . in section [ sec : assandnot ] we formulate the iiosp , state precise assumptions and present some preliminaries .",
    "section [ sec : mainresults ] contains the main results while section [ sec : proofs ] is devoted to proving these . in section [ sec : numerical ] we give a numerical example of the problem studied in this paper .",
    "finally , we end with section [ sec : conclusions ] containing conclusions and some future lines of research .",
    "we begin by briefly outlining the standard osp under full information .",
    "let @xmath7 be an @xmath8-dimensional stochastic process @xmath9 and denote the infinitesimal generator of @xmath10 by @xmath11 .",
    "let @xmath12 be the finite set of available states .",
    "a management strategy is a combination of a non - decreasing sequence of stopping times @xmath13 , where , at time @xmath14 , the manager decides to switch production from its current mode to another one , and a sequence of indicators @xmath15 , taking values in @xmath16 , indicating the mode to which the production is switched . at @xmath14",
    "the production is switched from mode @xmath17 to @xmath18 .",
    "the cost of switching from state @xmath19 to state @xmath20 at time @xmath21 is denoted @xmath22 . a strategy @xmath23",
    "can be represented by the simple function @xmath24}(s ) + \\gamma_0 \\chi_{[\\tau_0 , \\tau_1 ] } ( s)\\ ] ] indicating the current state of the facility .",
    "we will throughout the paper alternate between these two notations without further notice .",
    "if the facility is in state @xmath19 at time @xmath21 the genrated revenue per unit time is @xmath25 .",
    "hence , when the production is run under a strategy @xmath26 over a finite horizon @xmath27 $ ] , the expected total profit is @xmath28.\\end{aligned}\\ ] ] the task in the osp is to find the value function @xmath29 where @xmath30 denotes the set of strategies adapted to the filtration generated by @xmath10 which are in state @xmath19 at time @xmath31 . under sufficient regularity conditions on the payoff functions",
    "@xmath32 and switching costs @xmath33 and the so called `` no - loop condition '' the following theorems can be proven , see @xcite .",
    "[ thm : varineq ] the vector of value functions @xmath34 solves the system of variational inequalities @xmath35 in the viscosity sense .",
    "furthermore , @xmath34 is the unique solution satisfying the polynomial growth condition @xmath36 @xmath37 , for some @xmath38 .",
    "[ thm : finstrategy ] there exists a finite strategy @xmath39 such that @xmath40 for any @xmath41 .    for future reference",
    "we introduce the regions @xmath42 and @xmath43 , @xmath37 , defined as @xmath44 \\times \\r : v_i(t , x ) > v_j(t , x ) - c_{ij}(t , x ) \\big\\ } , & \\notag \\\\ s_i & = \\big \\ { ( t , x ) \\in [ 0,t ] \\times \\r : v_i(t , x ) = \\max _ { j \\in \\q \\setminus",
    "\\{i \\ } } { \\left}\\ { v_j(t , x ) - c_{ij}(t , x ) { \\right}\\ } \\big\\}. & \\end{aligned}\\ ] ] the sets @xmath43 and @xmath42 are usually refered to as `` switching regions '' and `` continuation regions '' , respectively .",
    "it is optimal to switch from region @xmath19 when the underlying process @xmath45 hits the switching region @xmath43 , see @xcite .",
    "in contrast to the osp outlined above , the manager in an iiosp only has access to incomplete information about the underlying process @xmath10 , information acquired through a fully observable @xmath10-dependent process @xmath46 . in particular , the manager can only observe the process @xmath46 , solution to the stochastic differential equation @xmath47 where @xmath48 is a brownian motion independent of @xmath49 , and she must base her decisions solely on the information contained in @xmath50 , the @xmath51-algebra generated by @xmath46 .",
    "this lack of information prevents us from directly applying results concerning standard osp .",
    "in the theory of stochastic filtering , and we refer to @xcite for details concerning this , the main goal is to compute conditional expectations @xmath52 $ ] for suitably chosen test functions @xmath53 .",
    "the solution to the stochastic filtering problem is the distribution of the random variable @xmath3 conditional on the @xmath51-algebra @xmath54 .",
    "we let @xmath55 denote this distribution and hence @xmath56 = \\int_{\\mathbb{r}^{m}}\\phi(x)\\pi_t(dx ) \\triangleq \\pi_t(\\phi).\\ ] ] based on the solution @xmath55 of the stochastic filtering problem we define , following @xcite , the expected total profit when the production is run under an @xmath57-adapted strategy @xmath58 , over a finite horizon @xmath59 $ ] , to be @xmath60ds-\\sum_{k\\geq 1}\\mathbb e\\bigl[c_{\\xi^y_{{k-1}},\\xi^y_{k } } ( \\tau^y_{k},x_{\\tau^y_k})|\\f^{y}_{\\tau^y_{k}}\\bigr]\\biggr ) \\biggr ] .\\ ] ] let for @xmath61 $ ] , @xmath37 , @xmath62 denote set of @xmath63-adapted strategies such that @xmath64 and @xmath65 a.s . and recall the notation introduced in .",
    "given @xmath66 $ ] and a probability measure @xmath67 , we define @xmath68 , the value function associated with the iiosp , to equal @xmath69.\\ ] ] the function @xmath68 stands for the optimal expected profit if , at time @xmath31 , the production is in mode @xmath19 and the probability distribution of the unknown @xmath3 is @xmath67 .",
    "we now turn to the specific setup studied in this paper .",
    "we let @xmath70 be a complete filtered probability space on which we define two independent brownian motions @xmath71 and @xmath72 . the notation @xmath73 is used to indicate that the brownian motion is started from the point @xmath74 at time @xmath75 .",
    "the assumption that the initial observation is made at time @xmath75 is made w.l.o.g .",
    ", see remark 3.1 of @xcite .",
    "we let @xmath76 be the underlying stochastic process and let , for an arbitrary but fixed @xmath77 , the process @xmath78 defined by , @xmath79 represents noisy observations of @xmath49 .",
    "we denote by @xmath80 the filtration generated by @xmath78 .",
    "we stress that @xmath81 and consequently the value of @xmath82 is not known based on the information in @xmath83 .",
    "the manager can choose between having the production facility open ( state @xmath2 ) or closed ( state @xmath1 ) , i.e. , @xmath84 , and the corresponding payoff functions are @xmath85 the manager can only observe the process @xmath78 and the decision to open / close the production at time @xmath31 must hence be made based solely on the information contained in @xmath83 .",
    "concerning the cost of switching we assume that @xmath86 the solution to the iiosp outlined above is the value function @xmath87 , @xmath88 , defined as @xmath89   ds - \\sum _ { n \\geq 1 } c_{\\mu_{\\tau_{n-1 } } \\mu_{\\tau_n } }   \\,\\vline \\ ,   w^{x}_t \\sim \\hat \\pi { \\right}],\\ ] ] where @xmath67 is a probability measure and @xmath90 denotes the set of strategies adapted to the filtratrion @xmath83 which are in state @xmath19 at time @xmath31 .",
    "we denote by @xmath91 $ ] and @xmath92 $ ] the conditional mean and conditional variance of @xmath82 . using this notation and the fact that @xmath26 is by definition",
    "an @xmath93-measurable strategy can be simplified to read @xmath94\\ ] ] as with , the function @xmath95 can be interpreted as the optimal expected profit if , at time @xmath31 , the facility is in state @xmath19 and , given the available observations , the probability distribution of @xmath82 is @xmath67 . for future reference",
    "we also introduce the value function @xmath96 defined as @xmath97,\\ ] ] i.e. , the value function of the standard osp corresponding to the assumptions above .",
    "to simplify the statements of the main results , we first state an immidiate consequence of theorem [ thm : filtering ] , further explained in the bulk of the paper . in particular , proposition [ prop : dimreduction ] reduces the apriori infinite dimensionality of the iiosp .",
    "[ prop : dimreduction ] the stochastic probability measure @xmath55 of @xmath82 conditional on @xmath98 is fully characterized by its conditional mean @xmath99 $ ] and a time - dependent deterministic function @xmath100 .    with this proposition in mind , it is clear that the value function @xmath101 can be expressed as a function @xmath102\\times \\r \\to \\r$ ] . with slight abuse of notation",
    "we will write @xmath103\\ ] ] for @xmath104 $ ] .",
    "we are now ready to state the results .",
    "[ prop : monotone ] for any @xmath105 such that @xmath106 we have @xmath107    in words , theorem [ prop : monotone ] states that the value of information is positive , i.e. , decreasing the noise in the observation process @xmath108 increases the optimal expected profit .",
    "the intuitive reason for this result is that more accurate observations simplify the managers task of optimally controlling the production facility .",
    "when the noise in @xmath108 tends to @xmath1 , more and more information becomes available and the task of the manager starts to resemble that under full information .",
    "consequently , the expected optimal profit under incomplete information should tend to the expected optimal profit under full information .",
    "this intuition is confirmed by the follwoing theorem .",
    "[ thm : convergence ] as @xmath109 the value function @xmath110 and @xmath111",
    "the outline of this section is as follows .",
    "firstly , we state some results from the theory of stochastic filtering which will constitute a base for the proofs of the results in section [ sec : mainresults ] .",
    "we then show that the iiosp stated above can be reduced to a full information osp and apply the standard theory , in particular the results presented in section [ sec : assandnot ] , to prove theorem [ prop : monotone ] and theorem [ thm : convergence ] .",
    "results concerning standard osp are in general not directly applicable to the iiosp due to the lack of information .",
    "the main idea of this paper is to reduce the iiosp to a standard osp to which the results of section [ sec : assandnot ] can be applied .",
    "this reduction is made possible by the following well - known results from the theory of linear stochastic filtering .",
    "proofs of the below statements can be found in @xcite ( theorem 10.3 and theorems 7.12 and 7.16 ) .",
    "[ thm : filtering ] the distribution of @xmath82 conditional on @xmath83 is gaussian .",
    "furthermore , the conditional mean @xmath91 $ ] and variance @xmath112 $ ] are the unique pair of processes satisfying @xmath113    [ thm : filtering2 ] the random process @xmath114 , @xmath115 , with @xmath116 is a wiener process and the filtration @xmath117 generated by @xmath118 conincides with that generated by @xmath78 , i.e. , @xmath119 for all @xmath66 $ ] .",
    "note that the starting point @xmath120 $ ] is given by the starting point of the underlying process @xmath76 .",
    "since the distribution of @xmath82 conditional on @xmath83 is gaussian it is fully characterized by its mean @xmath121 and variance @xmath100 .",
    "proposition  [ prop : dimreduction ] follows immediately since @xmath100 is given by the ordinary differential equation .      before proving the main results",
    ", we reduce the problem to a complete information setting and prove the convexity of the value function .",
    "[ prop : altrepres ] fix @xmath122 and assume and .",
    "let @xmath123 be the solution to @xmath124 and let @xmath125\\ ] ] be the value function of the full information osp .",
    "then , @xmath126 .",
    "recall that @xmath127\\ ] ] where @xmath128 $ ] . by theorem [ thm : filtering ]",
    "the dynamics of @xmath129 is given by which , after solving and inserting the solution @xmath130 , reads @xmath131 since the value function is an expected value we can replace the underlying process ( and corresponding set of strategies ) in our optimal switching problem with any other process having the same distributional properties without changing its value .",
    "with this in mind , we introduce the innovations process @xmath132 and put @xmath133 .",
    "then , by the process @xmath78 admits a represenation of the form @xmath134 and by theorem [ thm : filtering2 ] the process @xmath135 is a brownian motion .",
    "furthermore , the @xmath51-algebra @xmath136 generated by @xmath137 coincides with @xmath83 for all @xmath138 . the above together with and the initial condition",
    "@xmath139 gives that @xmath140 recall the underlying brownian motion @xmath141 and the dynamics of @xmath142 , @xmath143 the distributional properties of the brownian motions @xmath144 and @xmath141 conincide and hence , since @xmath145 for all @xmath146 , it follows that @xmath147 \\notag \\\\ & = & \\sup_{\\mu \\in \\a^r_i } \\e { \\left}[\\int",
    "_ t^t m^{x,\\e}_s \\i_{\\{\\mu_s = 1\\ } } ds - \\sum_{n\\geq 1 }   c_{\\mu_{\\tau_{n-1 } } \\mu_{\\tau_{n } } } \\ , \\vline \\ , m^{x,\\e}_t = m { \\right } ] \\notag \\\\ & = & \\sup_{\\mu \\in \\a_i } \\e { \\left}[\\int _",
    "t ^t x^{m , t,\\e}_s\\i_{\\{\\mu_s = 1\\ } } ds -   \\sum_{n\\geq 1 }    c_{\\mu_{\\tau_{n-1 } } \\mu_{\\tau_{n } } } { \\right } ] = v_i(t , m)\\end{aligned}\\ ] ] and the proof is complete .",
    "note that although the process @xmath148 is not explicitly observable , its path is completely determined by the deterministic function @xmath100 and the observed process @xmath78 .",
    "hence , we can w.l.o.g .",
    "consider @xmath149 as being the observed process rather than @xmath78 .",
    "[ lemma : convexity ] for any @xmath77 , the value function @xmath150 , @xmath88 , is convex in @xmath8 .    recall the characterization of @xmath150 given in proposition  [ prop : altrepres ] . since the dynamics of @xmath142 is independent of its current value ,",
    "the resulting process is linear w.r.t .",
    "its starting point , i.e. , @xmath151 .",
    "let @xmath152 be an optimal strategy for @xmath150 so that @xmath153.\\ ] ] we now perturb the initial condition @xmath8 by @xmath154 and consider @xmath155 .",
    "the strategy @xmath156 is sub - optimal for @xmath157 and hence @xmath158 \\notag \\\\ = &    \\e { \\left } [ \\int _ t ^t x^{m , t,\\e}_s \\i_{\\{\\mu^\\ast_s = 1\\}}ds - \\sum _ { n \\geq 1 } c _ { \\mu^\\ast_{\\tau_{n-1 } }   \\mu^\\ast_{\\tau_n } }   + \\eta \\int",
    "\\i_{\\ { \\mu^\\ast_s = 1\\}}ds { \\right } ] \\notag \\\\= & v^\\e_i(t , m ) + \\eta f(t , m , i),\\end{aligned}\\ ] ] where @xmath159 is the expected time spent in state @xmath2 , using the optimal strategy for the starting point @xmath160 . repeating the above for the optimal strategy associated to the initial value @xmath161 yields @xmath162 since @xmath163",
    "it follows from that @xmath150 is non - decreasing in @xmath8 .",
    "furthermore , combining the inequalities above we find @xmath164 i.e. , the time spent online increases with the initial starting point . dividing by @xmath154 and letting @xmath165 gives @xmath166 since @xmath167 is non - decreasing in @xmath8 , we can conclude that for any @xmath168 @xmath169 where @xmath170 denotes the right spatial derivative of @xmath171 at @xmath172 .",
    "we conclude that the right derivative of @xmath171 is increasing at @xmath8 .",
    "convexity of @xmath150 now follows since @xmath8 was arbitrary .      by combining propostition",
    "[ prop : altrepres ] and theorem [ thm : varineq ] we conclude that the vectors @xmath173 , @xmath174 , solve , respectively , the systems of variational inequalities @xmath175 where @xmath176 is the generator of the process @xmath177 . we now intend to prove that @xmath178 is a subsolution to the system above with @xmath179 , i.e. , that @xmath180 and then apply the comparison principle for .",
    "we focus on @xmath181 , the inequality in @xmath182 being treated similarly .",
    "firstly , on the region @xmath183 @xmath181 is trivially satisfied since @xmath184 by definition .",
    "hence , we only need to show that on the region @xmath185 , where @xmath186 is above its obstacle by construction , we have @xmath187 in the viscosity sense .",
    "assume that @xmath188 has a local minimum at @xmath189 .",
    "since @xmath190 is a viscosity solution to with @xmath191 we have @xmath192 in particular , we see that @xmath193 .",
    "hence , at @xmath194 we have @xmath195 the monotonicity of @xmath196 for @xmath197 and the assumption @xmath198 gives @xmath199 a function @xmath200 is convex if and only if it is convex in the viscosity sense , see @xcite , and hence it follows from lemma [ lemma : convexity ] that @xmath201",
    ". we can thus conclude from that holds .",
    "this proves @xmath181 since @xmath202 . repeating the above arguments for @xmath203 proves @xmath182 and",
    "thus the subsolution property is proven . since @xmath204 , @xmath88",
    ", the theorem now follows from the comparison principle for .      that @xmath205 for any @xmath122 is proven as proposition [ prop : monotone ] using @xmath206 for any @xmath197 .",
    "we omit the details . by theorem [ thm : finstrategy ]",
    "there exists a finite optimal strategy @xmath152 for the full information problem .",
    "this strategy is sub - optimal in and hence @xmath207-   \\e { \\left}[\\sum_{n\\geq 1 }    c_{\\mu^\\ast_{\\tau_{n-1 } } \\mu^\\ast_{\\tau_{n } } } { \\right}]\\notag \\\\ & - \\sup _ { \\mu \\in \\a^\\xi_{i , t } } \\e { \\left}[\\int _ t ^t x^{m , t,\\e}_s\\i_{\\{\\mu_s = 1\\ } } ds -\\sum_{n\\geq 1 }    c_{\\mu_{\\tau_{n-1 } } \\mu_{\\tau_{n } } } { \\right } ]   \\notag \\\\ \\leq & \\e{\\left}[\\int _",
    "t ^t   { \\left } ( w^{m , t}_s - x^{m , t,\\e}_s { \\right})\\i_{\\{\\mu^\\ast_s=1\\ } }   ds { \\right } ] , \\end{aligned}\\ ] ] where @xmath208 , @xmath209 is the brownian motion @xmath76 conditional on @xmath210 .",
    "following @xcite we introduce the notation @xmath211 } q^\\e_{t , s } , \\notag \\\\",
    "n_{t,\\infty}^\\e = & \\sup_{s \\geq t } q^\\e_{t , s } \\notag .\\end{aligned}\\ ] ] by definition @xmath212 and hence yields @xmath213 \\notag \\\\   & \\leq \\e { \\left } [ \\sup _ { s \\in [ t , t ] } q^\\e_{t , s }    \\int _",
    "t ^t \\i_{\\{\\mu^\\ast_s=1\\ } } ds { \\right}]\\leq   \\e { \\left } [ \\sup _ { s \\geq t } q^\\e_{t , s }    \\int _ t ^t \\i_{\\ { \\mu^\\ast_s=1\\ } } ds { \\right } ] \\notag \\\\ & \\leq \\e{\\left } [   n^\\e_{t,\\infty}{\\right } ] ( t - t).\\notag\\end{aligned}\\ ] ] since @xmath214=   \\e { \\left } [ \\lim_{r \\to \\infty } n^\\e_{t , r } { \\right}]$ ] and @xmath215 is monotone in @xmath216 we may apply the monotone convergence theorem to find @xmath217 =   \\e { \\left}[\\lim_{r \\to \\infty } n^\\e_{t , r } { \\right } ] = \\lim_{r \\to \\infty } \\e { \\left } [ n^\\e_{t , r } { \\right}].\\ ] ] by the reflection principle it follows that @xmath218 = { \\left } ( \\frac{2}{\\pi }   \\int _",
    "t ^s { \\left}(1- \\tanh(\\dfrac{r}{\\e } ) { \\right})^2 dr { \\right})^{1/2}.\\ ] ] to be more explicit , applying the reflection principle to the stochastic process @xmath219 yields @xmath220 , i.e. , the distribution of @xmath221 coincides with that of @xmath222 .",
    "furthermore , since @xmath223 it is normally distributed , @xmath224 and @xmath225 follows the corresponding half - normal distribution . hence @xmath226",
    "= \\e[|q^\\e_{t , r}| ] = { \\left } ( \\frac{2}{\\pi } \\int _ t^r   ( 1 - \\tanh(\\dfrac{u}{\\e } ) ) ^2 du{\\right})^{1/2}\\ ] ] and @xmath227 = & \\lim _",
    "{ r\\to \\infty } \\e [ n_{t , r } ^\\e ] = \\lim _ { r\\to \\infty } { \\left } ( \\frac{2}{\\pi } \\int _ t   ^r { \\left}(1- \\tanh(\\dfrac{u}{\\e } ) { \\right})^2 du { \\right})^{1/2 } \\notag \\\\ \\leq & \\lim _ { r\\to \\infty }   { \\left } ( \\frac{2}{\\pi } \\int _ 0   ^r { \\left}(1- \\tanh(\\dfrac{u}{\\e } ) { \\right})^2 du { \\right})^{1/2 } = \\sqrt { \\e}{\\left } ( \\frac{4}{\\pi } \\log ( 2 ) -\\frac{2}{\\pi } { \\right } ) ^{1/2}.\\end{aligned}\\ ] ] the result now follows by combining and .",
    "we conclude with a numerical calculation showing some features stemming from the lack of information . in particular , we solve using the crank - nicolson finite difference scheme with linear interpolation at the boundaries .",
    "the value function @xmath228 is found using the parameters in table [ table : parameters ] is chosen as @xmath229 to get a convenient order of magnitude of the value function . ] .",
    "recall that the value function @xmath230 is given w.r.t .",
    "@xmath231 . for ease of exposition",
    "we only present numerical results for @xmath232 subject to the initial condition @xmath233 .",
    "the monotonicity proved in proposition  [ prop : monotone ] is clearly seen in figure  [ fig : results ] and table  [ tab : results ] .",
    "when the noise in the observation grows bigger it becomes less and less valuable and the value function tends towards the case of no information , i.e. , @xmath234 where @xmath235 for @xmath236 and @xmath237 for @xmath238 .",
    ".parameter values [ cols=\"<,<,>\",options=\"header \" , ]      for @xmath239 . ]",
    "@xmath240     for @xmath239 . ]    @xmath241",
    "in this paper we studied a brownian optimal switching problem under incomplete information .",
    "we showed that the value of information is positive and that the value function converges to the corresponding full information value function when the noise in the observation tends to @xmath1 .",
    "although the problem studied here is simplistic , the results indicate that the method of reducing to a full information problem , a technique successfully used in the study of incomplete information optimal stopping , provides a feasible way of tackling iiosps .",
    "an interesting and natural continuation of this paper is to study the iiosp for more general stochastic processes and payoff functions / switching costs , firstly in the general setting of linear kalman - bucy filters and ultimately for fully non - linear stochastic filters .",
    "k. li , k. nystrm , m. olofsson , _ optimal switching problems under incomplete information _ , to appear in monte carlo methods and applications .",
    "lundstrm , k. nystrm , m. olofsson , _ systems of variational inequalities in the context of optimal switching problems and operators of kolmogorov type _ ,",
    "annali di mathematica pura ed applicata , * 193 * ( 2014 ) , 1213 - 1247 ."
  ],
  "abstract_text": [
    "<S> in this paper we study an incomplete information optimal switching problem in which the manager only has access to noisy observations of the underlying brownian motion @xmath0 . </S>",
    "<S> the manager can , at a fixed cost , switch between having the production facility open or closed and must find the optimal management strategy using only the noisy observations . </S>",
    "<S> using the theory of linear stochastic filtering , we reduce the incomplete information problem to a full information problem , show that the value function is non - decreasing with the amount of information available , and that the value function of the incomplete information problem converges to the value function of the corresponding full information problem as the noise in the observed process tends to @xmath1 . </S>"
  ]
}