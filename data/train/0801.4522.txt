{
  "article_text": [
    "anyone contemplating a statistical analysis is warned , at an early stage of the game , `` but do nt combine the statistics of monkey wrenches and watermelons '' , or the equivalent .",
    "failure to heed this instruction  at a more sophisticated level , to be sure  gives rise frequently to simpson s paradox ( here , in its 2-trial sequence version ) : if choice @xmath0 is `` statistically better '' than choice @xmath1 in each of two sets of trials under differing circumstances , then it may happen that merging the two sets of data produces the opposite conclusion .",
    "consider the following specially constructed example for the sake of illustration :    l c c c & trial # 1 & trial # 2 & total + @xmath2 @xmath0 successes & 60 & 60 & 120 + @xmath3 @xmath0 failures & 20 & 140 & 160 + @xmath4 @xmath1 successes & 140 & 20 & 160 + @xmath5 @xmath1 failures & 60 & 60 & 120 +   +   +    in fig . 1",
    ", we pictorially represent trial sequence # 1 by a solid line , trial sequence # 2 by a dashed line ; trial # 1 tests drug @xmath0 , @xmath6 times , drug @xmath1 , @xmath7 times , while trial # 2 reverses the number of tests . the successes @xmath8 , and failures @xmath9 are shown for each drug in each trial sequence .",
    "if @xmath10 , so @xmath11 , then clearly the @xmath12 ratio of drug @xmath0 is larger than that of @xmath1 in both trial sequences , so drug @xmath0 certainly seems better .",
    "but in the combined trials @xmath13 is lower than @xmath14 if @xmath15 , or @xmath16 a quite feasible circumstance , so that drug @xmath0 has now become inferior to @xmath1 !",
    "this phenomenon is well - known and well - documented [ 5 ] [ 6 ] [ 7 ] [ 8 ] [ 9 ] [ 10 ]  but hope springs eternal . only recently [ 1 ] , a drug manufacturer , whose current potential blockbuster drug ( xinlay ) failed to better a placebo in two clinical trials with uncorrelated protocols , proposed to a regulatory agency to pool the two sequences .",
    "if accepted , their drug would then outperform the placebo , allowing them to move forward .",
    "the regulatory agency panel was not unaware of the forced paradox , and denied the reinterpretation of the data .",
    "the simpson paradox is data - driven . as in ( 1.1 ) , it may , or may not , hold in a given situation .",
    "however , what we may term inverse simpson paradox is a different story : can we take a long pair of data streams  say successes and failures with drug @xmath0 , and similarly with drug @xmath1  and decompose them into two pairs of subsequences , each of which reverses the conclusion of the original pair ?",
    "this can be carried out in different ways and for different purposes ,    1 .",
    "most directly and legitimately , it may be realized that data from two sources were combined for simplicity , and so there is a unique decomposition called for , which may indeed reverse the conclusion .",
    "this appears to be the case in the oft - quoted berkeley sex discrimination controversy [ 5 ] .",
    "2 .   least directly and least legitimately  but perhaps an effective strategy in litigation",
    " one can ask for that decomposition that maximally reverses the conclusion , and then use ingenuity to characterize the subsets thus obtained .",
    "3 .   putting a different spin on b )",
    ", one can ask for that decomposition that maximally comes jointly to either conclusion , and use this as an investigative tool to recognize a hidden characterization of significant subsets of related entities .    at first blush , inverse simpson , in contexts b ) and c ) ,",
    "is trivially accomplished .",
    "2 illustrates the principle .",
    "the dotted lines refer to the assertedly pooled data , clearly indicating that @xmath0 loses to @xmath1 .",
    "the hypothetical trial 1 data is represented by solid lines , and since @xmath0 has only successes , it is surely superior . and the dashed lines refer to trial 2 , in which @xmath1 has only failures , and so surely loses .    but fig .",
    "2 is a suspiciously extreme version of a strategy that can be made to look more reasonable . to put it in context ,",
    "let us consider the well - known berkeley sex discrimination case [ 5 ] , which we will paraphrase for numerical simplicity .",
    "the original data is that in one division , @xmath17 out of @xmath18 male applicants were admitted , a success rate of @xmath19 . on the other hand , @xmath20 of @xmath21 female applicants",
    "were admitted , a success rate of only @xmath22 .",
    "clearly , it would seem that the admission process discriminated against females .",
    "this was not the case .",
    "in fact ,    l c c & dept .",
    "1 & dept . 2 + male applicants & 30 & 70 + males admitted & 6 & 35 + female applicants & 70 & 30 + females admitted & 14 & 15 +   +   +    table 2 , simplified berkeley admission data , was arrived at by combining that of two departments , say 1 and 2 . referring to table 2 ,",
    "we see that the success rates of males in the two departments were @xmath23 , @xmath24 , with the corresponding female success rates of @xmath25 , @xmath26 .",
    "there was no demonstrable discrimination in either department , but `` mixing watermelons and monkey wrenches '' created very much of a statistical artifact .",
    "let us proceed to a general situation .",
    "we are given @xmath27 and @xmath28 , and @xmath29 for which , without loss of generality , @xmath30 .",
    "we then imagine compartmentalizing the @xmath0-pool as @xmath31 , @xmath32 , and the @xmath1-pool as @xmath33 , @xmath34 ; the success rates are to be given via @xmath35 , @xmath36 , @xmath37 , @xmath38 .",
    "the question then is whether @xmath39 and @xmath40 can be chosen so that @xmath41 indicating no advantage to @xmath0 or @xmath1 in either case .",
    "this is trivial . since @xmath42 , @xmath43 , @xmath44 , @xmath45",
    ", we must have @xmath46    thus , @xmath47 and @xmath48 are both averages of @xmath49 and @xmath50 , which therefore must lie outside the interval @xmath51 as in fig .",
    "explicitly , of course , we have @xmath52 in situations not as clear cut as the berkeley case , we would want to invent a hypothetical decomposition in which e.g. @xmath49 is roughly in the middle of the @xmath53 interval , @xmath50 roughly in the middle of @xmath54 , in order to allay suspicion . in the berkeley case , we see that @xmath55 , @xmath56 do satisfy this criterion .    with ( 2.3 ) , we find that a suitable decomposition removes the apparent bias against females : no assertion can then be made .",
    "2 illustrates a proactive strategy , in which a suitable decomposition reverses the original assertion and appears to establish the superiority of @xmath0 . what is wrong with the construction of fig .",
    "2 , aside from its suspicious extreme nature ? nothing , but the conclusion is questionable because we have not attended to the statistical significance of the new assertions , a point that was emphasized by the fda panel cited above . doing so forms the substance of our ensuing discussion .",
    "a prototypical situation calling for statistical assessment is this . a sequence of @xmath57 independent bernoulli trials  successes or failures ",
    "is carried out on the same object , resulting in @xmath8 successes .",
    "given @xmath58 , with what probability , or , can we claim that @xmath59 , the intrinsic success probability parameter , satisfies @xmath60 the standard approach is to start with the elementary result that , regarding @xmath8 as a random variable and defining @xmath61 , @xmath62}^{[np+n^{1/2}\\epsilon ] } \\left(\\begin{smallmatrix}{n}\\\\ { j}\\end{smallmatrix}\\right)p^jq^{n - j } , \\end{aligned}\\ ] ] where [ ] denotes integer part .",
    "the device then is to identify ( 3.2 ) , which is a probability on @xmath8-space , with a probability on @xmath59-space : @xmath63 signifying our confidence that ( 3.1 ) holds .",
    "the sort of information that will interest us will , however , in the context of this prototype , be more like : with what confidence , based upon the observed value of @xmath8 , can we claim that @xmath64 now , the above recipe is not readily applicable , since we are no longer questioning a between @xmath59 and @xmath8 that makes possible the sub rosa journey from @xmath8-space to @xmath59-space .",
    "but this is indeed the province of the bayes approach [ 4 ] which  ignoring the controversy that continues to swirl around it  is what we will use .",
    "first of all , let up recall what ( 3.1 ) would become in a bayesian context : we imagine joint @xmath65-space and quote the obvious @xmath66 @xmath67 here referring to probability density . if @xmath68 is the prior density on @xmath59-space , then @xmath69 but suppose we choose a uniform prior , @xmath70 ; then ( 3.6 ) becomes @xmath71 eqs .",
    "( 3.2 , 3.3 ) and ( 3.7 ) are certainly not identical , but if we go to the large sample regime , i.e. the normal approximation to the binomial , then ( 3.2 , 3.3 ) aver that @xmath72 which , it is easy to show identical with the large @xmath57 , fixed @xmath12 , steepest descent expansion [ 3 ] of ( 3.7 ) around @xmath73 .    on the basis of the above equivalence , we now go immediately to the question indicated by ( 3.4 ) . using bayes with a uniform prior ,",
    "precisely as in ( 3.7 ) , we have @xmath74 where @xmath1 is the beta function , @xmath75 the corresponding incomplete beta function [ 2 ] . eq .",
    "( 3.9 ) can also be written in the neat form @xmath76 the important point however is that this construction leads quite directly to evaluation of quantities such as @xmath77 , that are appropriate to the simpson paradox .",
    "the effect we are studying is not very subtle , and so it is sufficient to take a large sample limit , which strategy we adopt .",
    "however , there are several sample parameters , leading to the meaningful use of additional limiting operations .",
    "consider first the prototype , eq . ( 3.10 ) ; here , @xmath78 expresses the level of significance of the assertion that @xmath79 , and it is not until such an assessment is made that one can declare meaningful comparisons .",
    "let us evaluate ( 4.1 ) in the large sample limit in a familiar fashion that extends at once to the question of @xmath77 relevant to the simpson paradox .",
    "although ( 4.1 ) is finite and explicit , its implementation for large @xmath57 and @xmath8  while trivial numerically  is a bit complex .",
    "for this purpose , the expression ( 3.9 ) is more useful ; it says that @xmath80 by the large sample limit , we will mean that in which @xmath81 is fixed ( to within @xmath82 ) as @xmath83 , and we then ask for @xmath84 this is obtained quite directly by a steepest descent evaluation [ 3 ] of ( 4.2 ) .",
    "the relevant integrand is now @xmath85 , \\end{aligned}\\ ] ] with a maximum at @xmath86 and a corresponding expansion starting as @xmath87.\\ ] ] hence @xmath88 immediately recognizable in a normal distribution context .",
    "we can then proceed to the desired evaluation of @xmath89dp_a\\,dp_b/\\\\ \\qquad \\sideset{}{}\\iint_{\\substack{1\\ge p_a\\ge 0\\\\1\\ge p_b\\ge 0 } } [ f(p_a , p_b)\\\\ pr(s_a , s_b|p_a , p_b , n_a , n_b)]dp_a\\,dp_b .",
    "\\end{split}\\ ] ]    this is carried out in appendix a , where we choose bayes with uniform prior on @xmath90 space and process ( 4.9 ) as we did ( 4.2 ) .",
    "the result is that for large @xmath91    @xmath92    unsurprisingly , we can obtain ( 4.10 ) as well by a version of the probability space equivalence assertion employed in ( 3.3 ) .",
    "it is only necessary to consider the random variable @xmath93 where @xmath94 and @xmath95 are binomially distributed with success probabilities @xmath96 and @xmath97 . since we find at once that",
    "@xmath98 it follows directly that @xmath99 and then from the central limit theorem that in the limit @xmath27 , @xmath100 , @xmath101 the same sleight of hand as in ( 3.3 ) then converts this to @xmath102 and so , setting @xmath103 , to ( 4.10 ) , as was to be shown .",
    "now let us make use of the result ( 4.10 ) .",
    "if our initial data is characterized by @xmath94 , @xmath95 , @xmath104 , and @xmath105 , then the confidence level with which we can assert that @xmath106 is given by @xmath107 our objective is to supply a decomposition into two hypothetical trials @xmath108 and @xmath109 such that @xmath110 in fact , to be definite , we suppose that the two pairs of trials reverse the initial assertion at a common level of confidence @xmath111 with @xmath112 .",
    "to start , we need to find the restrictions on @xmath113 under which the required @xmath114 satisfying ( 5.2 ) can be found .",
    "the solution is direct but algebraically cumbersome , and is presented in detail in appendices b and c. the conclusion of the former is that if @xmath115 , then @xmath116    since we require @xmath117 , this implies that @xmath118    in ( 5.4 ) and ( 5.5 ) , we uniformly adopt the notation : @xmath119    eq .",
    "( 5.4 ) is a bit involved and , even worse , contains the unknown parameters @xmath120 , @xmath121 implicitly .",
    "but it can be simplified by reducing its right hand side and thereby strengthening the requirement on @xmath113 a bit .",
    "this is carried out in appendix c , with the conclusion that , if @xmath115 , then @xmath122\\\\ p_a+p_b\\le1:c'\\le2(\\gamma\\bar{\\gamma})^{1/2}((p_a / p_b)^2 - 1)\\\\(p_a - p_b)(\\bar{p}_a/\\bar{p}_b)/ \\left[\\left(\\frac{p_a}{p_b}\\frac{\\bar{p}_b}{\\bar{p}_a}\\right)^2 - 1\\right]\\\\ \\text{where}\\,\\,\\gamma = n_a / n \\end{split}\\ ] ] are sufficient to carry out the apparent reversal of ranking of @xmath0 and @xmath1 .",
    "let us take a simple example that has been previously quoted [ 4 ] [ 8 ] .",
    "we will paraphrase it and use rounded off data .",
    "hospitals @xmath0 and @xmath1 specialize in treating a certain deadly disease .",
    "@xmath123 patients are treated at @xmath0 and @xmath124 at @xmath1 .",
    "of these , @xmath125 recover , while @xmath126 recover , so that @xmath127 , @xmath128 and hospital @xmath0 is apparently the place to go . in fact , one computes @xmath129 , so that this conclusion is supported at the @xmath130 standard deviation level .",
    "detailed investigation shows that matters are not so simple .",
    "some patients enter in otherwise good shape , others in poor shape . of the former ,",
    "@xmath131 enter hospital @xmath0 , and 870 recover ; of the latter , @xmath132 enter and 30 recover , so @xmath133 , @xmath134 .",
    "l c c & good shape & poor shape + admissions to hospital a&900 & 100 + recovered in hospital a&870 & 30 + admissions to hospital b&600 & 400 + recovered in hospital b & 590 & 210 +   +   +    on the other hand , @xmath135 enter hospital @xmath1 in good shape and @xmath136 recover , whereas @xmath137 , @xmath138 .",
    "thus , @xmath139 , @xmath140 .",
    "we see that by not mixing the two classes of patients , hospital @xmath1 is superior for each class  at levels @xmath141 ( 1.7 standard deviations ) and @xmath142 ( 7.9 standard deviations ) .",
    "simpson , or inverse simpson , depending upon one s point of view , is certainly exemplified .",
    "of course , the criteria as to which patients entered in good shape , which in poor shape , are a bit fuzzy . given the aggregate data , the decomposition into the two classes could , as we have seen , been planned with the intention of most convincingly asserting the opposite of the conclusion from the aggregate data .",
    "if this had been done according to the prescription of ( 5.7 ) , then with the same input data , we would have found @xmath143 , @xmath144 ( not far from the @xmath145 , @xmath146 corresponding to the additional data presented ) and concluded with the superiority of hospital @xmath1 at a confidence level corresponding to @xmath147 or 4.79 standard deviations for each class of patients .",
    "the simpson paradox , one of the simplest examples of the common misuse of statistics ( think meta - analysis ? ) has received increasing attention , since the consequences of its use  or misuse  can be quite severe ( as well as profitable ) . in the classical simpson paradox ,",
    "the only question is whether or not to combine data from different sources ( and trying to justify the decision to combine ) .",
    "what we have seen here is that the inverse simpson paradox , even in its most `` sophisticated '' version in which mean differences are weighted by appropriate standard deviations , is nearly universally applicable",
    ". this can be an effective analytical tool , but can equally well be an effective technique for distorting statistical data .",
    "choosing bayes with a uniform prior on @xmath90 space , ( 4.9 ) becomes @xmath148 applying the known expansion of the incomplete beta function [ 2 ] , this reduces after a little algebra to @xmath149 or introducing @xmath150 , @xmath151 for notational convenience , @xmath152    but we will go to the large sample limit defined by fixed @xmath153 as @xmath83 .",
    "we could proceed precisely as in ( 4.5  4.8 ) , but if we imagine a large sample limit from the outset , the derivation is brief and standard . consider drug @xmath0 . a uniform prior for @xmath96",
    "is given by the beta distribution @xmath154 which , after@xmath94 successes in @xmath27 trials creates the posterior distribution @xmath155 drug b works the same way .",
    "it follows that @xmath156 and so by the central limit theorem for large @xmath27 , @xmath157 , @xmath158",
    "eq . ( 5.3 ) itself imposes two conditions . aside from the crucial @xmath159 , there are just two more due to the composition conditions that @xmath160 .",
    "we reintroduce the notation of section 2 : @xmath161 and hereafter uniformly adopt the notation that @xmath162 thus @xmath163 implies @xmath164 , or @xmath165 and similarly @xmath166 we also append ( 5.3 ) in the form @xmath167 and solve ( b.3 ) , ( b.4 ) , ( b.5 ) to yield @xmath168 where @xmath169    eqs .",
    "( b.6 ) , ( b.7 ) are realizable if the requirements @xmath170 are satisfied . since we are asserting , without loss of generality , that @xmath106 , we of course have the condition @xmath171 there are then two cases to consider .",
    "if @xmath115 , it is easily seen that @xmath172 , @xmath173 , so that @xmath174 , @xmath175 are already satisfied .",
    "the remaining four conditions @xmath176 , @xmath177 can then be gathered together as @xmath178 or , inserting ( b.7 ) , @xmath179 similarly , @xmath180 since we require @xmath117 , immediate consequences are that @xmath181 must hold .",
    "the major step is the observation , from ( 5.2 ) that @xmath182 so that @xmath183 hence , @xmath184 yielding @xmath185 setting @xmath186 , condition ( 5.4 ) can therefore be strengthened to @xmath187 .",
    "\\end{aligned}\\ ] ] and in the same way , we obtain the strengthened @xmath188 . \\end{aligned}\\ ] ]    eqs .",
    "( c.5 ) and ( c.6 ) are valid for all @xmath189 , and we may indeed find the largest feasible range for @xmath113 by maximizing their right hand sides over @xmath39 and @xmath40 . again , to reduce complexity , let us take the special case in which : @xmath190 so that @xmath191/\\\\ [ ( p_a / p_b)^2(\\bar{p_b}/\\bar{p_a})^2 - 1]\\\\ \\beta=[(\\bar{p_b}/\\bar{p_a})^2 - 1]/[(p_a / p_b)^2(\\bar{p_b}/\\bar{p_a})^2 - 1 ] \\end{aligned}\\ ] ] converting ( c.5 ) and ( c.6 ) to @xmath192\\\\ \\min[(\\bar{p_b}/\\bar{p_a})^2 - 1,(p_a / p_b)^2 - 1]\\\\ \\cdot\\min(\\bar{p_a}-\\bar{p_a}^2/\\bar{p_b } , p_b - p_b^2/p_a ) . \\end{split}\\ ] ] but @xmath193 and @xmath194 , so it follows that in the @xmath115 case , @xmath195\\\\ p_a+p_b\\le1:c'\\le2(\\gamma\\bar{\\gamma})^{1/2}\\left(\\left(\\frac{p_a}{p_b}\\right)^2 - 1\\right)\\\\ ( p_a - p_b)\\frac{\\bar{p_a}}{\\bar{p_b}}/\\left[\\left(\\frac{p_a}{p_b}\\frac{\\bar{p_b}}{\\bar{p_a}}\\right)^2 - 1\\right ] \\end{aligned}\\ ] ] are sufficient to carry out the apparent reversal of ranking of @xmath0 and @xmath1 .",
    "the decomposition corresponding to the choice @xmath196 can of course be similarly specialized ."
  ],
  "abstract_text": [
    "<S> given two sets of data which lead to a similar statistical conclusion , the simpson paradox [ 10 ] describes the tactic of combining these two sets and achieving the opposite conclusion . depending upon the given data , this may or may not succeed . </S>",
    "<S> inverse simpson is a method of decomposing a given set of comparison data into two disjoint sets and achieving the opposite conclusion for each one . </S>",
    "<S> this is always possible ; however , the statistical significance of the conclusions does depend upon the details of the given data . </S>"
  ]
}