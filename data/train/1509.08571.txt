{
  "article_text": [
    "the standard game theory framework considers players who are von neumann - morgenstern ( vnm ) utility maximizers ; that is , they maximize the expected value of someutility function \" defined over potential outcomes .",
    "the key to finding equilibria in such framework , of course , is to know the exact functional form of the utility function in order to translate payoffs and probabilities to utilities .",
    "the complexity of the analysis under non - standard functional forms , on the one hand , and the complications of identifying _ the _ functional forms of the utilities of the real - world players , on the other hand , are two of the challenges of the standard framework .    in this paper",
    ", we undertake the above issues by introducing a non - equilibrium solution concept .",
    "we develop an analytical framework for ( zero - sum ) repeated games to study the following question : _ what is the highest payoff that players can `` guarantee with high probability ? '' _ more precisely , we are concerned with payoffs that can be guaranteed ( with some strategy ) with probability @xmath0 , where @xmath1 goes to @xmath2 as the games get played more and more .",
    "this  high probability game theory \" setting helps us to derive results analogous to the existing ones on repeated games with incomplete information by mertens and zamir in @xcite .",
    "22[*alice*][*bob * ] @xmath3 & @xmath4 & @xmath5 + @xmath6 & 1 & 2 + @xmath7 & -4 & -6    22[*alice*][*bob * ] @xmath8 & @xmath4 & @xmath5 + @xmath6 & 1 & 2 + @xmath7 & 8 & 8     +    22[*alice*][*bob * ] & @xmath4 & @xmath5 + @xmath6 & 1 & 2 + @xmath7 & 2 & 1    let us motivate our solution concept by a simple , concrete example .",
    "consider the zero - sum repeated game depicted in fig .",
    "[ figcap1 ] between alice and bob .",
    "there is a state variable @xmath9 with uniform distribution over @xmath10 .",
    "alice s payoff table for @xmath11 and @xmath12 are given ( bob s payoff is negative of alice s payoff ) .",
    "we assume that alice and bob have no knowledge of the value of @xmath9 .",
    "the game is played @xmath13 times between alice and bob , with the state variable being drawn at the beginning and kept fixed throughout the @xmath13 games .",
    "alice and bob only get to see their payoff values after playing all the @xmath13 games ; hence they can not gain any information about @xmath9 throughout the game .",
    "we make the assumption that if the total sum of the @xmath13 payoffs of the @xmath13 games of a player is positive , that player wins the entire game .",
    "there is a draw if the total sum of each player is zero .",
    "let us first assume that alice aims to maximize the expected value of her average payoffs in the @xmath13 games .",
    "since alice and bob do not know @xmath9 , we can compute the average table with weights @xmath14 as given in the bottom of fig .",
    "[ figcap1 ] .",
    "the average table is symmetric and a nash equilibrium strategy is for players to choose their actions uniformly at random .",
    "this gives alice an expected average payoff of @xmath15 .",
    "thus , alice can guarantee a positive total expected payoff in the nash equilibrium of the repeated game .",
    "however , with this strategy , alice s average payoff is negative with probability @xmath16 ; it is @xmath17 when @xmath11 .",
    "therefore , with probability @xmath16 when @xmath11 , she will lose the entire @xmath13 game as her total sum payoff becomes negative with high probability by the law of large numbers . on the other hand , assume that alice plays a different strategy of choosing action @xmath6 all the time ( which is not part of a nash equilibrium ) .",
    "then , bob will play @xmath4 and this leads to a payoff of @xmath18 for alice regardless of whether @xmath11 or @xmath12 .",
    "the payoff of @xmath18 is smaller than the average payoff of @xmath15 that an equilibrium strategy will give her , but is guaranteed with probability one ; thus ensuring that alice will win the entire game .",
    "more generally , given an arbitrary repeated game ( with complete or incomplete information ) , we ask that given an @xmath19 , whether alice has a strategy , for a sufficiently large enough @xmath13 , that guarantees her total sum payoff to be greater than a number @xmath20 with probability @xmath0 . in studying this natural problem",
    ", one may consider the whole @xmath13 games as a one stage strategic form game , and then consider the sequence of these games for different values of @xmath13 , as @xmath13 becomes larger and larger .",
    "however , we find it easier to analyze this game as an extensive form repeated game in a high probability framework .",
    "* motivation from information theory : * one motivation for a high probability framework comes from information theory , where repeated use of a channel and a vanishing probability of error as the number of channel uses , @xmath13 , tends to infinity is common . in the following we explain this via a simple example that requires little background in information theory .",
    "we need some definitions : a binary erasure channel ( bec ) is a communication medium with a binary input @xmath21 .",
    "the output of this channel , denoted by random variable @xmath22 , is a symbol from @xmath23 where @xmath24 indicates that the input symbol is erased .",
    "when the input symbol is not erased @xmath25 , we have @xmath26 . the transmitter will not know whether a transmission has been erased at the receiver or not .",
    "let us denote the erasure event by random variable @xmath27 , _",
    "@xmath28 indicates that the input bit is _ not _ erased .",
    "when we use the channel @xmath13 times , we will have erasure random variables @xmath29 for each transmission .",
    "we assume that each @xmath30 is a function of three variables : an internal channel state variable @xmath9 , an input @xmath31 by alice and an input @xmath32 by bob , according to @xmath33 , where @xmath34 is a given function for any @xmath35 .",
    "random variable @xmath9 is randomly chosen at the beginning and is fixed through the @xmath13 channel uses ( slow fading ) .",
    "alice and bob have initial partial knowledge about @xmath9 by having access to @xmath36 and @xmath37 that are correlated with @xmath9 .",
    "figure  [ fig : bec - repeated - game ] illustrates this configuration .",
    "alice aims to help the transmission ( trying to make @xmath38 variables one , as much as possible ) and bob aims to disrupt it .",
    "neither alice nor bob observe the variables @xmath38 .",
    "but we assume that both alice and bob observe each other actions ( inputs to the channel ) causally ; therefore , if they know each other s strategies , each party can infer some information about the other party s side information by observing their actions .",
    "hence , there is a tradeoff for both parties between using and hiding their side information : using it can be advantageous for the current transmission while actions can reveal information to the other party which could be turned against them in subsequent transmissions .",
    "= [ rounded corners , fill = blue!20,draw = blue!50,very thick ] = [ decoration = markings , mark = at position 0.999 with , postaction = decorate , shorten > = 0.4pt ] ( -1,-0.5 ) rectangle ( 1,0.5 ) ; at ( 0,0 ) bec ; ( -2,0 )  ( -1,0 ) ; ( -1,1.5 ) rectangle ( 1,2.5 ) ; at ( 0,2 ) @xmath39 ; ( 0,1.5 )  ( 0,0.5 ) ; at ( 0.25,1 ) @xmath38 ; at ( -1.5,2.2 ) @xmath31 ; ( -4,1.5 ) rectangle ( -2,2.5 ) ; at ( -3,2 ) alice ; ( -2,2 )  ( -1,2 ) ;    ( -3,3 )  ( -3,2.5 ) ; at ( -3,3.2 ) @xmath36 ; ( -4.5 , 2 )  ( -4,2 ) ; at ( -5.5,2 ) @xmath40 } , b_{[1:i-1]}$ ] ;    ( 1,0 )  ( 2,0 ) ; at ( 2.3 , 0 ) @xmath41 ; at ( -2.3 , 0 ) @xmath42 ; ( 4,1.5 ) rectangle ( 2,2.5 ) ; at ( 3,2 ) bob ; ( 4.5 , 2 )  ( 4,2 ) ; at ( 5.5,2 ) @xmath40 } , b_{[1:i-1]}$ ] ; ( 3,3 )  ( 3,2.5 ) ; at ( 3,3.2 ) @xmath37 ; at ( 1.5,2.2 ) @xmath32 ; ( 2,2 )  ( 1,2 ) ;    we can view the above as a game with incomplete information if we consider @xmath38 to be the payoff of the game for alice ( the payoff of bob will be the negative of the payoff of alice ) . now , suppose that alice can guarantee the expected total payoff of @xmath43",
    ". it may be the case that with probability @xmath16 , her total payoff is zero , and with probability @xmath16 her total payoff is @xmath13 .",
    "then , with probability @xmath16 all the transmitted bits will be erased and no communication will be possible . therefore , having a bound on the expected value of total payoff is not useful .",
    "on the other hand , given some small @xmath19 , assume that alice can guarantee her total payoff to be at least @xmath44 with probability @xmath0 , regardless of how bob plays .",
    "in other words , with probability @xmath0 , at least @xmath44 bits from the @xmath13 bits that the transmitter sends will become available at the receiver . then , with probability @xmath0 , the transmitter can send about @xmath44 data bits by employing standard coding techniques such as fountain codes . therefore , a high probability framework is of relevance to information transmission problem over this adversarial bec channel .",
    "it is possible to think of other information theory problems with a threshold phenomenon where the high probability framework is of relevance .",
    "for instance , in coding theory , the minimum distance of a code gives a guarantee that if the number of changes in a code sequence is sufficiently small , decoding will be successful .",
    "one can consider a problem where alice and bob are having actions that ( along with a channel state ) determines when a transmission will become erroneous .",
    "it would be desirable for alice to make sure that the number of errors are bounded to ensure successful decoding . or for instance , one can imagine a control system with two players , one who is trying to increase the error and the other who is trying to reduce the error",
    ". it may be that a bound on the total error of a system be of importance ( and not its expected value ) .",
    "in section [ compoundavc ] , we provide a technical application of the high probability framework for the problem of communication over a certain compound arbitrarily varying channel .    * our contribution : * in this paper , we focus on repeated games with incomplete information .",
    "incomplete information refers to the fact that there are some unknown parameters that affect the payoff of the players .",
    "each player has its own partial knowledge of the parameters , which may leak to the other player through actions during the repeated game .",
    "there is a tradeoff between hiding and using the information to each party .",
    "we refer the reader to @xcite for a comprehensive treatment .",
    "our main contribution in this paper is to find payoffs that can be guaranteed with high probability .",
    "we introduce a non - equilibrium approach  the high probability condition  and characterize payoffs that can satisfy that condition . just like the average case framework ,",
    "a complicating aspect of the problem is the tradeoff between hiding and using the information in the high probability framework . after proving our main result in the high probability framework , a non - trivial application of this framework to compound arbitrarily varying channel",
    "is also given .",
    "there have been few previous works on implicit flow of information through actions in information theory @xcite .",
    "however , none of existing works address implicit communication from the perspective of game theory to characterize the tradeoff between hiding and using the information .",
    "therefore , there are new conceptual features in our treatment",
    ".    * related work : * the literature of repeated game theory contains several ideas that are related to our paper . the standard approach to infinitely repeated games with no discount rate is the closest to ours , but it is concerned with the average payoff as a criteria of equilibrium @xcite . as we discussed before",
    ", our paper in some sense provides a high probability analogous of @xcite .",
    "fudenberg and levine @xcite study a repeated game of imperfect monitoring where they provide asymptotic bounds for the payoff of the player whose reputation ( against his opponent ) is crucial in identifying the equilibrium . the robust mechanism design literature is also related to ours , in that the goal is to `` guarantee '' a payoff ( in a maxmin sense ) , but with a focus on single period games  see , for instance , @xcite and @xcite .",
    "it should be pointed out that classical game theory has already found many applications in information theory in scenarios where we have channels with unknown parameters , or channels that can vary arbitrarily ( adversarial channels ) .",
    "the payoff function is generally either a mutual information ( _ e.g. , _",
    "@xcite ) or a coding error probability ( _ e.g. , _",
    "@xcite ) . other than the problem of channels with uncertainty",
    ", game theory is vastly being used in other problems of information theory such as adversarial sources , power allocation and spectrum sharing .",
    "* organization : * the rest of this paper is organized as follows : in section  [ notation ] we define our notation . in section  [ sec : game - definition - problem - statement ]",
    "we formally define the problem , in section  [ sec : expected - asymptotic ] we review a result in repeated games with incomplete information in the expected value regime and finally in section  [ sec : vs - vw ] we prove our main result which is finding the highest value a party can guarantee with high probability in repeated games with incomplete information .",
    "section [ compoundavc ] includes an application of the framework .",
    "we use capital letters for random variables and small letters for their realizations .",
    "we use @xmath45 $ ] to denote the set @xmath46 .",
    "then @xmath47}$ ] denotes @xmath48 .",
    "we use both subscript and superscripts to denote indicies ; _",
    "@xmath49 is rv @xmath50 indexed by @xmath51 , and @xmath52 is rv @xmath50 indexed by @xmath53 and @xmath51 .",
    "thus , @xmath54}_{[n]}=\\{(x_i^j : i\\in [ n ] , j\\in[k]\\}$ ] . for a function @xmath55 , @xmath56 and @xmath57 denote its lower concave envelope and upper convex envelope , respectively ; _",
    "@xmath56 is the smallest concave function that lies above @xmath55 .",
    "the support of a probability distribution @xmath58 over a finite set @xmath59 is defined as @xmath60 .",
    "we consider a two player zero  sum game with alice and bob as players .",
    "we are interested in alice s payoffs ; hence alice is the maximizer and bob is the minimizer .",
    "[ def : value - of - game ] we define the value of a strategic game @xmath61 , @xmath62 , as alice s payoff in a nash equilibrium ; this value is the same for all nash equilibriums since the game is zero  sum .",
    "we use @xmath63 and @xmath64 to denote alice s and bob s payoffs in any nash equilibrium respectively . hence , @xmath65 .    a standard zero  sum repeated game of incomplete information consists of the following components @xcite :    * a zero  sum two player game @xmath66 called the _ stage game _ which is repeated @xmath13 times .",
    "this game is between two players , say alice and bob , with finite sets of permissible actions @xmath67 and @xmath68 , respectively . for each state @xmath69",
    ", we have a payoff table @xmath70 where @xmath34 denotes alice s payoff when alice plays action @xmath71 and bob plays action @xmath72 in @xmath66 . * a probability distribution @xmath73 on a finite set of states , @xmath74 , from which the state of the game is chosen by nature at random at the beginning of the game . without loss of generality",
    ", we may assume that @xmath75 for all @xmath76 , _",
    "i.e. , _ @xmath77 .",
    "* this state is fixed throughout the @xmath13 repetitions of @xmath66 , but neither alice , nor bob know the exact value of the state . instead , alice and bob receive @xmath36 and @xmath37 as the side information about @xmath9 , respectively .",
    "we assume that @xmath36 and @xmath37 are functions of @xmath9 , _",
    "@xmath78 and @xmath79 .",
    "this assumption is made without loss of generality , as argued later .",
    "equivalently , one can think that the set of states , @xmath74 , is partitioned into some sets in two ways , one for alice and one for bob , and each player realizes the number of partition @xmath9 falls in for his own partition .",
    "hence , partitions for alice and bob are of the form @xmath80 and @xmath81 , respectively , where @xmath82 and @xmath83 are realizations of @xmath36 and @xmath37 , respectively .",
    "the alphabets of random variables @xmath36 and @xmath37 are denoted by @xmath84 and @xmath85 , respectively . *",
    "each party plays actions in the repeated game based on the information they have since the beginning of the game , _",
    "i.e. , _ their side informations @xmath36 and @xmath37 and the history of the game @xmath86}$ ] and @xmath87}$ ] which are alice s and bob s actions up to stage @xmath53 respectively . note that in stage @xmath88 , alice and bob play @xmath89 and @xmath90 simultaneously ; here we have shown actions with capital letters to emphasize that they are random variables since the two parties are allowed to employ random strategies , and the initial state @xmath9 is random .",
    "* we assume that alice and bob just observe their actions , not the payoffs they have received .",
    "when all @xmath13 stages are finished , alice receives the time average of the payoffs of stage games , _",
    "@xmath91 note that @xmath92 is a random variable .",
    "the repeated game with above components is shown by @xmath93 where @xmath58 is the prior distribution on state space @xmath94 . with an abuse of notation ,",
    "we alternatively write @xmath95 where @xmath9 the random variable with distribution @xmath58 .",
    "a few points should be made about the above definition .",
    "first , note that the assumption that @xmath36 and @xmath37 are deterministic functions of @xmath9 is not restrictive .",
    "in fact , in the general case where @xmath36 and @xmath37 are allowed to be random functions of @xmath9 , we can define a random variable @xmath96 where @xmath36 and @xmath37 are deterministic functions of @xmath9 and @xmath96 ( functional representation lemma ( * ? ? ?",
    "* appendix b ) ) . therefore ,",
    "for the new repeated game with state @xmath97 and payoff tables @xmath98 side informations are of our desired form and also the resulting payoffs do not change .",
    "we can consider the strategic form for the above extensive form game and call it @xmath99 . in this strategic form game , each action of a player is a pure strategy of him in the repeated game , _",
    "i.e. , _ a collection of deterministic functions determining what action should be played at each stage given the observations up to that time .",
    "the payoff of this game is the expected outcome of the repeated game defined as in when @xmath9 is generated from distribution @xmath73 .",
    "this strategic form game is indeed zero  sum , hence has a mixed strategy nash equilibrium with value @xmath100 .",
    "this could be defined rigorously as follows :    [ def : strategic - form ] the strategic form game @xmath99 is defined as a one stage zero  sum game with action sets @xmath101 for alice and @xmath102 for bob where @xmath103 } \\times { \\mathcal{b}}_{[i-1 ] }   \\times { \\mathcal{s}}_a \\rightarrow { \\mathcal{a } } ,",
    "1 \\leq i \\leq n \\ } \\\\ \\hat{{\\mathcal{b } } } & = \\{(g_1,\\dots , g_n ) \\ , | \\ , g_i : { \\mathcal{a}}_{[i-1 ] } \\times { \\mathcal{b}}_{[i-1 ] }   \\times   { \\mathcal{s}}_b \\rightarrow { \\mathcal{b } } , 1 \\leq i \\leq n \\ } \\\\   \\end{split}\\ ] ] where @xmath104 } , b_{[i-1 ] } , s_a)$ ] determines which action alice will play if the history of the game is @xmath105 } , b_{[i-1]}$ ] and she has the side information @xmath36 , and bob s strategies are similar . given a realization @xmath106 , a unique deterministic sequence of actions is played by alice and bob , denoted by @xmath107}(s ) , b_{[n]}(s)$ ] where @xmath108}(s ) , b_{[i-1]}(s ) , \\mathscr t_a(s ) )   \\\\",
    "b_i(s ) & = g_i(a_{[i-1]}(s ) , b_{[i-1]}(s ) , \\mathscr t_b(s ) ) .   \\\\",
    "\\end{split}\\ ] ] the payoff function of this game is defined as follows : @xmath109    as mentioned above , this is a finite zero  sum game , hence has a mixed strategy nash equilibrium . any strategy of this form is a mixture of pure strategies defined above , called a mixed strategy in the repeated game . however , since the repeated game @xmath110 is with perfect recall , _",
    "i.e. , _  each player remembers his own past actions , kuhn s theorem implies that without loss of generality we may only consider behavioral strategies ( see , @xcite , for instance ) .",
    "a behavioral strategy is a collection of random functions assigning probabilities to each action given the history of the game at each stage :    a behavioral strategy of alice in the game @xmath110 is a collection of random functions where @xmath111 } , b_{[i-1 ] } , s_a),\\ ] ] is the probability that alice chooses action @xmath112 when the history of the game is @xmath105 } , b_{[i-1]}$ ] and alice s side information is @xmath82 .",
    "behavioral strategies are defined similarly via @xmath113 } , b_{[i-1 ] } , s_b)$ ] .",
    "the choices of alice and bob in different stages are assumed to be conditionally independent given the past action history , _",
    "i.e. , _ the probability distribution on the outcome of the game is @xmath114},b_{[n ] } ) = p_s(s ) \\prod_{i=1}^n \\alpha(a_i | a_{[i-1 ] } , b_{[i-1 ] } ,   \\mathscr t_a(s ) ) \\beta(b_i | a_{[i-1 ] } , b_{[i-1 ] } ,   \\mathscr t_b(s)).\\ ] ]    the set of alice s behavioral strategies in @xmath110 is denoted by @xmath115 and bob s behavioral strategies is denoted by @xmath116 .",
    "the value of @xmath110 is defined as the value of its strategic form . as a result of kuhn s theorem",
    ", we have @xmath117 } = \\min_{\\beta   \\in \\tilde{{\\mathcal{b}}}_n } \\max_{\\alpha \\in \\tilde{{\\mathcal{a}}}_n } { \\mathbb{e } \\left [   \\frac{1}{n } \\sum_{i=1}^ng_s(a_i ,   b_i )   \\right ] } , \\ ] ] where @xmath31 and @xmath32 are random variables denoting the actions of alice and bob .",
    "let @xmath118 be the time average payoff of alice .",
    "then , equation implies that if alice plays her equilibrium strategy , independent of bob s strategy , we have @xmath119 } \\geq { \\mathbb{v}\\left ( \\gamma_n^{\\mathscr t_a , \\mathscr t_b}(s ) \\right)},\\ ] ] which shows that alice can guarantee @xmath120 in the average sense by playing an equilibrium ( behavioral ) strategy .",
    "conversely , from , if bob plays his equilibrium strategy , alice can not guarantee more than the value of the game , _",
    "i.e. , _ @xmath121 } \\leq { \\mathbb{v}\\left ( \\gamma_n^{\\mathscr t_a,\\mathscr t_b}(s ) \\right)}$ ] .",
    "hence @xmath120 is the maximum value alice can guarantee in the expected value sense .",
    "the asymptotic behavior of this value , _",
    "@xmath122 is analyzed by mertens and zamir in @xcite .",
    "we will review a special case of this result in section  [ sec : expected - asymptotic ] .    on the other hand",
    ", one might be interested in finding the value alice can guarantee with high probability instead of in average .",
    "there are two ways of defining this concept .",
    "[ def : strong - guaranteeing ] we say that alice can strongly guarantee a value @xmath20 if for all @xmath19 , there exists a natural number @xmath96 such that for all @xmath123 , alice has a strategy @xmath124 in @xmath125 so that for all strategies @xmath126 of bob in this game we have @xmath127    [ def : weak - guaranteeing ] we say that alice can weakly guarantee a value @xmath20 if for all @xmath19 , there exists @xmath96 such that for all @xmath123 and for all strategy @xmath126 for bob in @xmath125 , there exists a strategy @xmath124 for alice in this game such that @xmath127    note that the difference between the above two definitions is that if alice wants to guarantee a payoff strongly , then she needs to have a _ universal _",
    "strategy @xmath124 independent of bob s strategy . a universal strategy of alice should work for all possible strategy of bob . on the other hand , when alice wants to guarantee a value weakly",
    ", she can adapt her strategy based on bob s strategy .",
    "therefore , it is evident that if alice can guarantee a value in the strong sense , she can guarantee it in the weak sense too .",
    "[ def : vsup ] when the game state has distribution @xmath128 , alice s and bob s side information functions are @xmath129 and @xmath130 , respectively , we denote the supremum of all values alice can strongly guarantee as @xmath131 .",
    "similarly @xmath132 denotes the supremum over all values alice can guarantee weakly .",
    "when it is clear from the context , we use @xmath133 and @xmath134 instead as shorthands for @xmath132 and @xmath131 , respectively .",
    "we will find the values of @xmath133 and @xmath134 in section  [ sec : vs - vw ] .",
    "in this section , we review an existing result for guaranteeing payoffs in the expected value . in this approach , the nash equilibrium of the @xmath13 stage game , @xmath135 is asymptotically analyzed and its limit value as well as its convergence rate is obtained .",
    "we first need a definition :    [ def : u - average - game ] given a distribution @xmath128 on set @xmath136 and payoff tables @xmath34 for @xmath137 , define @xmath138 as the value of the one - stage zero - sum game with the average payoff table @xmath139 . we may also denote it by @xmath140 where @xmath9 is the random variable with distribution @xmath128 .",
    "consider the special case where one player is fully aware of the game state and the other has no side information . in order to do",
    "so we employ the notation @xmath141 as the function which gives no side information , _",
    "i.e. , _ it has a constant output @xmath142 for all @xmath69 . on the other hand ,",
    "let @xmath143 is the side information function which gives full information , _",
    "@xmath144 for all @xmath69 .",
    "we consider the case where @xmath145 .",
    "then ,    [ thm : zamir - side - information - on - one - side ] @xmath146 exists and is equal to @xmath147 where @xmath148 is the convex hull of @xmath149 as a function on the probability simplex .",
    "furthermore there exists a constant @xmath150 such that for all @xmath128 we have @xmath151    in @xcite , alice is assumed to have full information and bob knows nothing ; in fact their place is reversed . in order to change their place , we can negate the payoff table .",
    "that is why we have @xmath152 instead of @xmath153 here and also the inequality direction in   is reversed . to be more precise , statement of theorem  3.16 of @xcite in our notation translates to @xmath154 noting @xmath155 for any zero sum game @xmath61 and @xmath156 for any function @xmath55 transforms the above equation into . also note that on the right hand side of the analogue of in @xcite we have the term @xmath157 which is upper bounded by @xmath158 and is absorbed into the constant @xmath150 here .",
    "+ observe that the constant @xmath150 in is independent of @xmath128 , hence it implies uniform convergence of the sequence @xmath159 to its limit on @xmath128 .    in the following ,",
    "we provide an intuitive sketch of the key ideas used to prove theorem  [ thm : zamir - side - information - on - one - side ] ; see @xcite for a rigorous proof .",
    "alice initially does not know anything about @xmath9 .",
    "bob knows @xmath9 and his actions may increase alice s information about @xmath9 .",
    "let us denote alice s information about @xmath9 at time stage @xmath53 by the mutual information @xmath160}b_{[i-1]})$ ] for @xmath161 $ ] .",
    "the sequence @xmath162 satisfies the following properties : @xmath163 , @xmath164 and @xmath165 $ ] .",
    "take some @xmath166 .",
    "we say that an information jump occurs at stage @xmath53 if @xmath167 . since @xmath165 $ ] , the number of jumps is at most the constant @xmath168 .",
    "let @xmath169 : j_{i}-j_{i-1}\\leq \\delta\\}$ ] . since @xmath88 is a constant , @xmath170 .",
    "the payoff of alice is its average over time stages @xmath18 to @xmath13 and is dominated by the average of stages in @xmath171 , _",
    "i.e. , _ @xmath172 at time instances in @xmath173 , bob s strategy is essentially non - revealing in the sense that if from alice s view , @xmath9 has conditional pmf @xmath174}b_{[i-1]})$ ] at time stage @xmath53 , we have that @xmath175 .",
    "then , the payoff that alice can obtain at time stage @xmath53 is that of a non - revealing @xmath176 .",
    "the average payoff over various realizations of @xmath105}b_{[i-1]}$ ] is equal to @xmath177}b_{[i-1]}}p(a_{[i-1]}b_{[i-1]}){\\mathfrak{u } \\ !",
    "\\left ( p(s|a_{[i-1]}b_{[i-1 ] } ) \\right ) } \\geq   \\operatorname*{vex}{\\mathfrak{u } \\ !",
    "\\left ( p \\right ) } \\ ] ] as @xmath178}b_{[i-1]}}p(a_{[i-1]}b_{[i-1]})p(s|a_{[i-1]}b_{[i-1]})=p(s)$ ] .",
    "this demonstrates that alice s payoff is greater than or equal to @xmath179 , regardless of how bob plays .    on the other hand",
    ", bob has a strategy ensuring that alice s payoff does not exceed @xmath180 .",
    "assume that @xmath181 for some non - negative weights @xmath182 $ ] adding up to one , and pmfs @xmath183 satisfying @xmath184 let @xmath185 be a random variable on alphabet set @xmath186 satisfying @xmath187 .",
    "rv @xmath185 is joint distributed with @xmath9 as follows : @xmath188 bob can locally create @xmath185 by passing @xmath9 through a channel @xmath189 .",
    "bob s strategy is then as follows : he uses his actions in the first few instances of the game to communicate @xmath185 to alice .",
    "the payoff in these first few instances of the game do not affect the overall payoff over the @xmath13 games . by doing this ,",
    "bob is effectively announcing @xmath185 to alice , at no effective cost .",
    "bob then proceeds as follows : he completely forgets the exact state @xmath9 and only given the variable @xmath185 , he plays the optimal strategy of @xmath190 when @xmath191 . in this case , since the marginal distribution of @xmath9 is @xmath192 and alice knows whatever bob knows about the state , the posterior of the state does not change from stage to stage from alice s point of view,_i.e .",
    ", _ she does not learn further about the state from bob s actions than the initial announcement @xmath185 .",
    "hence , @xmath193 } = \\sum_{i=1}^k \\lambda_i \\frac{1}{n } \\sum_{j=1}^n { \\mathbb{e } \\left [ g_s(a_j , b_j ) | v= i \\right ] } \\leq \\sum_{i=1}^k \\lambda_i { \\mathfrak{u } \\",
    "! \\left ( p_i \\right ) } = \\operatorname*{vex}{\\mathfrak{u } \\ ! \\left ( p \\right ) } .\\ ] ] roughly speaking , this argument shows that the optimal strategy for the informed player is to announce whatever the uninformed player is eventually going to learn about the state at the beginning of the game and forget the extra information , so that both players end up having a balanced information about the state .",
    "this completes the sketch of the proof of @xcite .",
    "an interesting implication of theorem [ thm : zamir - side - information - on - one - side ] is as follows : considering the mixed nash strategies , alice s mixed strategy ensures learning and exploiting from bob s actions about state @xmath9 in an optimal way , for all possible strategies of bob . in other words",
    ", it implies existence of a  universal \" algorithm for alice that performs as if alice knew bob s strategy .",
    "in this section we find the values of @xmath133 and @xmath134 . without loss of generality , we assume that @xmath194 for all @xmath195 , where @xmath196 .",
    "therefore @xmath197 is non - empty for all @xmath82 .",
    "our main result is the following :    [ thm : main - two - sided ] we have @xmath198    consider the game tables given in figure  [ figcap2 ] where the numbers in the table are alice s payoff .",
    "22[*alice*][*bob * ] @xmath3 & @xmath4 & @xmath5 + @xmath6 & -1 & 0 + @xmath7 & 0 & 0    22[*alice*][*bob * ] @xmath8 & @xmath4 & @xmath5 + @xmath6 & 0 & 0 + @xmath7 & 0 & -1     +    22[*alice*][*bob * ] & @xmath4 & @xmath5 + @xmath6 & -p & 0 + @xmath7 & 0 & -(1-p )    assume that bob knows the exact value of @xmath9 , while alice has no side information about @xmath9 .",
    "the average table is also given in the figure .",
    "one can easily obtain @xmath199 ( ( * ? ? ?",
    "* sec .  3.2.5 . ) ) .",
    "since @xmath200 is convex , the maximum value that alice can guarantee in expected value is @xmath201 .",
    "however , since alice has no side information , we get @xmath202 which is strictly less than the expected value case unless @xmath203 .",
    "a naive approach suggests that perhaps it is more beneficial for bob to play @xmath4 if @xmath11 , and play @xmath5 if @xmath12 .",
    "however , note that in this case , alice after observing bob s actions realizes the true state and plays @xmath7 for @xmath11 , and @xmath6 for @xmath12 . while if bob chooses each column with probability @xmath16 independent of the state ( which is a completely non  revealing strategy ) , then alice does not gain any information about the true state and should choose one row with probability half ( since she does not know where the @xmath204 is located ) .",
    "this would guaruntee her a payoff of @xmath205 in high probability . on the other hand , for the expected payoff regime ,",
    "the optimal average payoff of alice is @xmath206 , and this is obtained by bob playing the equilibrium strategy of the average table without using his knowledge of the state .    before getting into the proof of this theorem in section [ sec - sub - l2 ] ,",
    "we prove a few lemmas .",
    "our first observation is that the values of @xmath134 and @xmath133 depend only on the support of @xmath207 .",
    "[ lem : support - invariant ] assume @xmath128 and @xmath208 are two distributions on @xmath74 such that @xmath209",
    ". then we have @xmath210    note that @xmath211 . therefore ,",
    "if @xmath212 , then we have @xmath213 where @xmath214 is the minimum value of @xmath207 on its support .",
    "then , we have @xmath215 } = \\sum_s \\tilde{p}(s ) { \\mathbb{p } \\left ( \\sigma_n",
    "< v|s \\right ) } \\leq   \\sum_s \\tilde{p}(s ) \\frac{\\epsilon}{p_\\text{min } } =   \\frac{\\epsilon}{p_\\text{min}},\\ ] ] which could be made small enough by setting @xmath1 sufficiently small .",
    "[ rem : vweak - vstrong - set - notation ] as a result of this lemma , for a subset @xmath216 we may use @xmath217 and @xmath218 as the value of @xmath219 and @xmath220 , respectively , for any distribution @xmath221 with @xmath222 .",
    "in fact , @xmath217 and @xmath218 could be interpreted as values that alice can guarantee `` for each possible state in @xmath223 '' in the worst case regime .    in the following lemma ,",
    "we reduce the problem of finding @xmath134 and @xmath224 to the case where alice has zero side information about the game state and bob exactly knows its value .",
    "we use the notations @xmath141 and @xmath143 from the previous section .",
    "[ lem : reduction - one - side - information ] we have @xmath225    we first show that @xmath226 and similarly for @xmath227 . in other words , @xmath134 does not depend on @xmath130 and from alice s perspective , it is always as if bob knows the state perfectly . to show this , consider the following strategy for bob : he guesses the state @xmath9 randomly and proceeds assuming that his guess is the correct value for @xmath9 .",
    "since the state space is finite , with a nonzero and constant probability his guess becomes true .",
    "but since alice should guarantee with high probability , she can not neglect the constant probability of bob s guess becoming true .",
    "therefore , her strategy should be for the worst case , guaranteeing her payoff conditioned on the event that bob s guess about the state is correct .",
    "this completes the proof for @xmath228 .",
    "it remains to show that @xmath229 and similarly for @xmath227 .",
    "when alice receives a side information @xmath82 , any of the states in the set @xmath80 may have happened .",
    "since alice has no further initial side information other than @xmath82 , we can assume that state space is reduced to @xmath80 with alice having zero side information .",
    "then , @xmath230 would be the payoff that can be guaranteed in this case .",
    "since alice should guarantee for any possible value of @xmath82 , the maximum payoff she can guarantee is @xmath231 .      by lemma [ lem : reduction - one - side - information ] , we only need to show that @xmath232 since @xmath233 , it suffices to show the following two propositions :    [ prop : lower - bound - final ] we have @xmath234    [ prop : uppernound ] we have @xmath235    to prove the above propositions , we first show a lemma :    [ prop : lower - bound - sasl ] we have @xmath236 where @xmath237 is an auxiliary zero  sum game in which bob chooses state @xmath76 ( the table @xmath70 ) from the set @xmath74 once and for all , and alice receives no side information , and then each player observes the history of the game ( expect that alice does not observe bob s action on choosing the table ) .",
    "the game is played for @xmath13 stages .",
    "the final payoff of alice is the average of her payoff in the @xmath13 subgames , according to the payoff table @xmath70 with @xmath76 chosen by bob in his first action .",
    "note that @xmath237 is a repeated zero  sum game with perfect recall , so using kuhn s theorem , we may consider behavioral strategies in a nash equilibrium of this game .",
    "assume @xmath238 is the value of @xmath237 and @xmath239 be an equilibrium strategy for alice .",
    "this means that for all strategy @xmath240 for bob , the expected value of alice by playing @xmath239 is at least @xmath20 .",
    "now , we repeat game @xmath237 , @xmath241 times . hence , we have a game of size @xmath242 with @xmath241 blocks of length @xmath13 . at the beginning of each block ,",
    "a new value for @xmath76 ( a new payoff table ) is chosen by bob and the game of length @xmath13 is played .",
    "we call the state of block @xmath53 as @xmath243 and actions of this block by @xmath244}$ ] and @xmath245}$ ] for alice and bob , respectively . here",
    "@xmath246 for @xmath247 , j\\in[n]$ ] is the @xmath51-th action of alice in the block @xmath53 .",
    "assume alice plays strategy @xmath239 in an i.i.d .",
    "fashion in each block , which means that she plays action @xmath246 at block @xmath53 with probability @xmath248}_{[n ] } a^i_{[j-1 ] }   b^{[i-1]}_{[n ] } b^i_{[j-1]}\\right ) = \\tilde{\\alpha } \\left ( a^i_j |    a^i_{[j-1 ] } b^i_{[j-1 ] } \\right).\\ ] ] now we claim that playing this strategy by alice results in guaranteeing @xmath249 with high probability for her when @xmath241 is large enough . for doing so , assume that bob plays an arbitrary strategy in the game with length @xmath242 .",
    "more precisely he chooses state @xmath250 for block @xmath53 with probability @xmath251 } a^{[i-1]}_{[n ] } b^{[i-1]}_{[n ] } \\right),\\ ] ] and action @xmath252 with probability @xmath253 } a^{[i-1]}_{[n ] } a^i_{[j-1 ] }   b^{[i-1]}_{[n ] } b^i_{[j-1 ] } \\right ) .\\ ] ] now define the random variable @xmath254 to be @xmath255 which is the sum of the payoffs of alice in the first @xmath88 blocks , centered by the expected payoff .",
    "now we claim that @xmath254 is submartingale with respect to @xmath256}_{[n ] } , b^{[k]}_{[n ] } ,   s_{[k]}$ ] .",
    "note that @xmath257}_{[n ] } , b^{[k]}_{[n ] } ,   s_{[k ] } \\right ] } = w_k + { \\mathbb{e } \\left [ \\sum_{j=1}^n g_{s_{k+1 } } ( a^{k+1}_j , b^{k+1}_j ) \\bigg |   a^{[k]}_{[n ] } , b^{[k]}_{[n ] } ,   s_{[k ] } \\right ] } - nv.\\ ] ] now we claim that @xmath258}_{[n ] } , b^{[k]}_{[n ] } ,   s_{[k ] } \\right ] } \\geq nv.\\ ] ] it suffices to show that for any realization of the history , @xmath259 } ,   a^{[k]}_{[n ] } b^{[k]}_{[n]}$ ] , the expected value is at least @xmath260 . to show this , note that for this specific realization of the history , the term inside the expectation is the sum of alice s payoff in a game @xmath261 where alice uses equilibrium strategy @xmath239 and bob uses strategy @xmath262 }   a^{[k]}_{[n ] } b^{[k]}_{[n ] } \\right ) , \\ ] ] and @xmath263 } b^{k+1}_{[j-1 ] } ) =   \\beta \\left ( b^{k+1}_j \\bigg | s_{[k+1 ] } a^{[k]}_{[n ] } a^{k+1}_{[j-1 ] }   b^{[k]}_{[n ] } b^{k+1}_{[j-1 ] }   \\right ) .\\ ] ] since @xmath239 is an equilibrium strategy , for all strategy of bob including the above @xmath240 in block @xmath264 the expected value of alice s payoff is at least the value of the game . hence @xmath265}_{[n ] } , b^{[k]}_{[n ] } ,   s_{[k ] } \\right ] } \\geq nv \\qquad \\forall a^{[k]}_{[n ] } , b^{[k]}_{[n ] } ,   s_{[k]}.\\ ] ] therefore @xmath258}_{[n ] } , b^{[k]}_{[n ] } , s_{[k ] } \\right ] } \\geq nv,\\ ] ] substituting this into shows that @xmath254 is a submartingale .",
    "note that @xmath266 where @xmath267 is an upper bound on payoffs .",
    "now using azuma s inequality with @xmath268 we have @xmath269 setting @xmath270 for a @xmath271 , the above bound goes to zero with @xmath241 going to infinity .",
    "therefore for @xmath241 large enough , with high probability we have @xmath272 or equivalently @xmath273 or @xmath274 where the last inequality holds with high probability for @xmath241 large enough . therefore , alice can guarantee payoff @xmath20 with high probability for the game with the game @xmath261 repeated @xmath241 times by playing @xmath239 i.i.d .    next ,",
    "observe that playing the same strategy by alice can guarantee her payoff @xmath275 for game @xmath276 for large enough @xmath241 .",
    "the reason is that bob s strategies in @xmath276 is a subset of bob s strategies in the @xmath241 repetition of @xmath261 , as in the former bob chooses @xmath76 once at the beginning while in the latter , he is allowed to choose it at the beginning of each of the @xmath241 blocks .",
    "finally , observe that alice can guarantee payoffs arbitrarily close to @xmath20 for game @xmath277 , as long as @xmath88 is large enough , even when @xmath88 is not of the product form @xmath278 for some @xmath241 .",
    "let @xmath279 for some @xmath280 .",
    "alice can play the above good strategy in stages @xmath18 through @xmath242 and plays arbitrarily in stage @xmath281 through @xmath282 . then",
    "alice s gain in @xmath283 would be with high probability at least @xmath284 where @xmath267 is an upper bound on the gains .",
    "the above value is greater than @xmath285 for @xmath241 large enough .    to sum this up",
    ", we have shown that there is a strategy for alice ( namely , i.i.d .",
    "@xmath239 ) that guarantees payoff @xmath20 for alice , regardless of bob s strategy .",
    "this implies that @xmath286 which is the first part of our claim in equation .    now using minimax expression for the nash equilibrium we have @xmath287}\\\\ & = \\min_{q(s ) } \\min_{\\beta(b_i | s , a_{[i-1 ] } , b_{[i-1 ] } ) }   \\max_{\\alpha(a_i |   a_{[i-1 ] } , b_{[i-1 ] } ) } \\frac{1}{n } \\sum_{i=1}^n { \\mathbb{e } \\left [ g_s(a_i , b_i ) \\right ] } \\\\ & = \\min_{q(s ) } { \\mathbb{v}\\left ( \\gamma^{\\emptyset , { \\mathds{1}}}_n(q(s ) ) \\right ) }     , \\end{split}\\ ] ] where in the second equality we have split bob s ( behavioral ) strategy @xmath240 into two parts : first choosing the state , and then playing actions based on the chosen state and history of the game .",
    "this completes the proof .",
    "we have , @xmath288 where @xmath289 uses proposition  [ prop : lower - bound - sasl ] ( which holds for all values of @xmath13 ) , @xmath290 uses theorem  [ thm : zamir - side - information - on - one - side ] , @xmath291 uses the fact that the constant @xmath150 is independent of @xmath58 and @xmath292 uses the fact that the minimum of the convex hull of the function is the same as the minimum of the function itself .",
    "since this holds for all values of @xmath13 , the result is proved simply by sending @xmath13 to infinity .    from equation",
    ", we have that @xmath293 for any distribution @xmath207 , using lemma  [ lem : support - invariant ] and remark  [ rem : vweak - vstrong - set - notation ] , we have @xmath294 , since @xmath295 .",
    "now we claim that @xmath296 . in order to do so ,",
    "assume @xmath20 is a value that alice can weakly guarantee when the state is generated from distribution @xmath58 , @xmath297 and @xmath298 .",
    "therefore , due to the definition , for any @xmath19 , with @xmath13 large enough , for any strategy @xmath299 for bob in @xmath300 , there exists an strategy @xmath301 for alice such that @xmath212 .",
    "assume bob plays the equilibrium strategy of @xmath302 , iid in @xmath13 games .",
    "then since initially neither alice nor bob have any side information about the state , they do not gain any extra information by observing each other s strategies .",
    "now , looking at the game at stage @xmath88 , since bob is playing his equilibrium strategy , @xmath303 } \\leq { \\mathfrak{u } \\ ! \\left ( p \\right ) } $ ] .",
    "hence , @xmath119 } = { \\mathbb{e } \\left [ \\frac{1}{n } \\sum_{i=1}^n g_s(a_i , b_i ) \\right ] } \\leq { \\mathfrak{u } \\",
    "! \\left ( p \\right ) } .\\ ] ] on the other hand , @xmath212 implies @xmath121 } \\geq v(1-\\epsilon)$ ] . this together with the above inequality we have @xmath304 . since @xmath1 was arbitrary , @xmath305 and thus @xmath306 .",
    "since @xmath58 was arbitrary , by taking minimum over @xmath58 we get @xmath307 substituting this into finishes the proof .",
    "in this section , we provide an application of the high probability framework .",
    "this section assumes a background in information theory .",
    "consider an avc channel with a legitimate sender / receiver and also an adversary .",
    "assume that the channel has a state @xmath9 which is partially known to the encoder / decoder and the adversary ( imperfect csi ) .",
    "communication channel is a conditional probability distribution @xmath308 where @xmath309 is the encoder s input on the channel , @xmath310 is adversary s input on the channel , @xmath76 is the channel state and @xmath311 is the output at the decoder .",
    "we assume that @xmath312 and @xmath9 take values in finite sets @xmath313 and @xmath74 , respectively .",
    "we assume that the state @xmath9 is chosen from a distribution @xmath128 .",
    "encoder and decoder both have the same side information @xmath314 about @xmath9 , while the adversary has a side information @xmath36 about it .",
    "we assume that the channel state is chosen once and for all and remains unchanged during the consecutive uses of the channel ( slow fading ) . however , we assume that the channel noise in @xmath308 is independent in different channel uses , _",
    "i.e. , _ @xmath315}|x_{[n ] } , a_{[n ] } , s)=\\prod_{i=1}^np(y_i|x_i , a_i , s)$ ] . furthermore , as before without loss of generality we assume that @xmath314 and @xmath36 are functions of @xmath9 , _",
    "i.e. , _  @xmath316 and @xmath78 .",
    "we assume that @xmath317 for all @xmath318 .",
    "adversary observes the history of the game at any stage @xmath53 , _",
    "i.e. , _ inputs put on the channel by the encoder @xmath319}$ ] .",
    "likewise , we assume that both the encoder and decoder observe adversary s input on the channel @xmath86}$ ] .",
    "therefore , this is a communication problem with feedback .",
    "we assume that encoder and decoder have access to unlimited private shared randomness , unknown to the adversary , allowing them to use randomized algorithms .",
    "a @xmath320 code consists of strategies for encoding as well as strategies for decoding .",
    "the encoder wants to reliably send a message @xmath267 in @xmath321 via @xmath13 uses of the channel , while the adversary wants to prevent this from happening .",
    "more specifically , at stage @xmath53 , the encoder creates input @xmath42 using the message @xmath267 , its side information @xmath314 , its shared randomness @xmath322 , as well as @xmath319 } , a_{[i-1]}$ ] previous transmissions by himself and the adversary .",
    "therefore the encoder s strategy is to assign a probability to each symbol in @xmath323 given the history of the game .",
    "hence , @xmath324 } , a_{[i-1 ] } , s_x , m , k)$ ] which is the encoding strategy , determines the probability of encoder generating .",
    "adversary has also a strategy , which we denote by the conditional pmf @xmath325 } , a_{[i-1 ] } ,   s_a , k_a)$ ] where @xmath326 denotes private randomness of adversary ; it determines the probability of choosing @xmath112 as the input of the adversary , the history of the game and adversary s side information .    at the decoder side",
    ", we find an @xmath327 given @xmath328 } , a_{[n ] } , k$ ] ; thus we are assuming that receiver observes @xmath329}$ ] as well as adversary s inputs to the channel .",
    "the side information at the decoder is assumed to be @xmath314 which is the same as the one at the encoder .",
    "a rate @xmath6 is called achievable if for @xmath330 , there is some @xmath331 such that for any @xmath332 , we can design encoding / decoding strategies such that independent of adversary s strategy , the probability of error , _ i.e. , _  @xmath333 is smaller than @xmath1 .",
    "the supremum over all the achievable rates is called the capacity of the channel and is denoted by @xmath150 .",
    "our goal is to find @xmath150 .",
    "figure  [ fig : avc - model ] depicts our channel model .",
    "following the common assumption in the game theory literature , we assume that both encoder / decoder and adversary know each other s strategies . as in a repeated game with incomplete information",
    ", there is a tradeoff for both encoder and adversary to use or hide their side information about the channel state .",
    "= [ rounded corners , fill = blue!20,draw = blue!50,very thick ] = [ decoration = markings , mark = at position 0.999 with , postaction = decorate , shorten > = 0.4pt ] ( -1,-0.5 ) rectangle ( 1,0.5 ) ; at ( 0,0 ) @xmath334 ; ( -2,0 )  ( -1,0 ) ; ( 1,0 )  ( 4,0 ) ;            at ( -1.5,0.3 ) @xmath42 ; at ( 1.5,0.3 ) @xmath41 ; ( -4,-0.5 ) rectangle ( -2,0.5 ) ; at ( -3,0 ) encoder ; ( 4,-0.5 ) rectangle ( 6,0.5 ) ; at ( 5,0 ) decoder ; ( -6,0 )  ( -4,0 ) ; at ( -5.5,0.3 ) @xmath267 ; ( 6,0 )  ( 7,0 ) ; at ( 6.5,0.3 ) @xmath327 ;                        for proving the converse , assume that the adversary puts its inputs i.i.d .",
    ", from an input distribution @xmath342 independent of all its observations and its side information about the state",
    ". then for a fixed value of state @xmath76 , we have a point to point channel with input @xmath50 and output @xmath343 .",
    "the encoder receives the side information @xmath344 ; no further information about @xmath9 is revealed to him during the transmission , since adversary s input is independent of the state .",
    "therefore , with the observation @xmath345 at the encoder and decoder , we have a classical memoryless compound channel with input @xmath50 , output @xmath343 and state @xmath9 with the conditional pmf @xmath346 .",
    "the capacity of this compound channel is ( * ? ? ?",
    "* theorem 7.1 ) @xmath347 therefore @xmath348 where @xmath289 results from the minimax theorem and the fact that @xmath349 is concave in @xmath350 and convex in @xmath207 . since the above holds for all @xmath318 and also for all @xmath207 , @xmath351 since @xmath352 for all @xmath318 .",
    "this completes the proof of the converse .        before specifying the encoder and decoder",
    ", we define an auxiliary repeated game with incomplete information as follows : take @xmath353 to be a finite subset of the probability simplex @xmath354 over the input alphabet @xmath323 .",
    "the game has two players : encoder / decoder ( which we call encoder for the sake of simplicity ) and adversary .",
    "the action set of encoder is @xmath353 and the action set of adversary is @xmath67 .",
    "the one stage game has @xmath355 tables for each state of the channel . in payoff table corresponding to @xmath69 , when encoder chooses action @xmath356 and adversary chooses action @xmath357 , payoff @xmath358 for @xmath359 is assigned to the encoder ( and its negative is assigned to the adversary ) . in the following , instead of",
    "writing @xmath360 , we use @xmath361 in order to emphasize the dependence on @xmath362 . then this game is repeated @xmath13 times , and the total payoff function of encoder would be the sum of its individual payoffs from the @xmath13 games .",
    "further , we assume that the encoder and adversary receive @xmath314 and @xmath36 as their side information at the beginning of the game .",
    "we call this game @xmath110 .",
    "assume that @xmath133 is the maximum value encoder can guarantee with high probability in the auxiliary game @xmath110 .",
    "we claim that any rate @xmath363 is achievable for the original compound - avc problem .",
    "take some @xmath364 such that @xmath365 .",
    "assume the strategy of encoder for strongly guaranteeing @xmath364 is @xmath366 .",
    "thus , @xmath367 } , \\pi_{[i-1]})$ ] denotes the probability the encoder chooses distribution @xmath368 at stage @xmath53 given his observations up to that time . adopting @xmath366 ,",
    "the gain of the encoder in @xmath110 is at least @xmath364 with high probability when @xmath13 is large enough .",
    "* codebook generation : * a codebook of @xmath369 codewords of length @xmath13 can be illustrated by a table of size @xmath370 where row index indicates the message and columns indicate time steps .",
    "encoder and decoder _ dynamically _ construct the @xmath370 table , column by column , during the transmission process by running the auxiliary game in parallel .",
    "in other words , the column @xmath53 of the codebook ( which is needed to make the @xmath53-th transmission ) is created after time step @xmath371 as follows : the symbols in the @xmath53-th column of the codebook table are generated independently from distribution @xmath368 of the auxiliary game ( _ i.e. , _",
    "@xmath369 i.i.d .",
    "samples from @xmath368 are generated and put in the @xmath53-th column of the table ) .",
    "note that since encoder and decoder have infinite shared randomness , they can use their shared randomness to simultaneously generate the codebook ( _ i.e. , _ the randomness needed to draw samples from @xmath13 i.i.d .",
    "samples from @xmath368 comes from the shared randomness between the encoder and decoder ) .",
    "the encoder and decoder are synchronized as the decoder observes @xmath105}$ ] and knows @xmath314 .    *",
    "encoding : * having message",
    "@xmath241 , the encoder sends the symbols from the @xmath241-th row of the codebook table that is being dynamically constructed during the transmission process . to write down the joint pmf that this encoding strategy implies ,",
    "let @xmath372 denote adversary s strategy in the compound - avc problem , _",
    "i.e. , _ let @xmath373 } ,   x_{[i-1 ] } , k_a)$ ] be the probability that adversary chooses @xmath112 at stage @xmath53 where @xmath374 is encoder s input on the channel at stage @xmath53 and @xmath326 is adversary s private randomness .",
    "then , the joint distribution of variables in the problem when the state of the channel is @xmath76 and the message @xmath241 is @xmath375 } , a_{[i-1 ] } )   p^a(a_i | s_a , a_{[i-1 ] } , x_{[i-1]}(m ) , k_a )   \\\\&\\times \\left ( \\prod_{j=1}^{2^{nr } }   \\pi_i(x_i(j ) ) \\right ) p(y_i | x_i(m ) , s , a_i)\\end{aligned}\\ ] ]    * decoding : * the decoder has access to @xmath107}$ ] , @xmath376}$ ] .",
    "also note that @xmath368 is generated from the strategy @xmath366 , @xmath314 , @xmath377}$ ] and @xmath105}$ ] which are all known to the decoder .",
    "also as was mentioned above , since we use random strategies in the repeated game , @xmath368 is a random function of the observations .",
    "however , since encoder and decoder have access to shared randomness , they can use it to come up with the same @xmath368 and apply the strategy simultaneously .",
    "also since encoder and decoder have shared randomness , the decoder knows the codebook . for @xmath362 and @xmath310 in finite sets @xmath378 and @xmath59 respectively , define @xmath379 to be the set of indexes @xmath380 where encoder s distribution is @xmath362 and adversary s input is @xmath310 , _",
    "@xmath381 then in the decoder , assume the sequence @xmath376}$ ] is received .",
    "the receiver declares that message @xmath382 has been sent if @xmath383 } ,   a_{[n]}),\\ ] ] where @xmath384 is the number of indexes @xmath53 where @xmath385 and @xmath386 ; the set @xmath387 includes jointly typical sequences from @xmath388 and @xmath389 of length @xmath390 according to @xmath391 ; and finally @xmath392 } , a_{[n ] } ) = \\left \\ { s \\in { \\mathcal{s } } : \\frac{1}{n } \\sum_{i=1}^n   i(\\pi_i;y|a_i , s ) \\geq \\tilde r \\right \\},\\ ] ]    * analysis of error : * because the codebook is constructed symmetrically , without loss of generality we assume that @xmath393 .",
    "we have two types of errors , the first one denoted by @xmath394 happens when @xmath395 does not satisfy and @xmath396 happens when for some @xmath397 , is satisfied .    for analyzing the first error ,",
    "assume that @xmath398 has happened .",
    "first note that since encoder s strategy guarantees @xmath364 , we have @xmath399 and hence @xmath400 } , a_{[n ] } )   \\right ) } \\geq 1 - \\epsilon .",
    "$ ] so we can assume that @xmath401 } , a_{[n ] } ) .",
    "$ ] hence , in order to show that @xmath395 satisfies , we shall show that with high probability @xmath402 in the above expression @xmath403 is the real state of the channel and @xmath404 and @xmath405 be the side informations .",
    "iin the remaining we condition everything on @xmath406 and at times , we do not state this explicitly in our expressions for the sake of simplicity .",
    "note that since adversary s input at stage @xmath53 , @xmath31 is dependent on @xmath319}$ ] , then we can not say that @xmath407 are i.i.d .  from distribution @xmath362 .",
    "for instance , if @xmath408 , then conditioned on our observations on adversary , the distribution on input is changed .",
    "hence , we can not employ standard lln type argument to show that the first error type vanishes .",
    "instead , define @xmath409 where @xmath410 is the number of times @xmath411 has happened up to stage @xmath53 . note that in the above definition , @xmath412 are fixed values and not random quantities .",
    "similarly @xmath413 also define @xmath414 .",
    "now we claim that @xmath415 is a martingale with respect to @xmath416 } : = a_{[i ] } \\pi_{[i ] } x_{[i ] }   y_{[i]}k_a$ ] which is the history of the events up to stage @xmath53 . to see that note , @xmath417 } \\right ] } & = w_i + { \\mathbb{e } \\left [ { \\mathds{1}\\left [ { a_{i+1 } = a , \\pi_{i+1 } = \\pi , x_{i+1 } =   x , y_{i+1 } = y } \\right ] } \\big| h_{[i ] } \\right ] } \\\\ &",
    "\\qquad - { \\mathbb{e } \\left [ { \\mathds{1}\\left [ { a_{i+1 } = a , \\pi_{i+1 } = \\pi } \\right ] } \\pi(x ) p(y|x , a , s^ * ) \\big| h_{[i ] } \\right ] } \\\\ & = w_i + p^a(a|s_a^ * , a_{[i ] } , x_{[i ] } , k_a ) p^e(\\pi |s^*_x , a_{[i ] } , \\pi_{[i ] } ) \\pi(x ) p(y|x , a , s^ * ) \\\\ & \\qquad - \\pi(x ) p(y|x , a , s^ * ) p^a(a|s^*_a , a_{[i ] } , x_{[i ] } , k_a ) p^e(\\pi |s^*_x , a_{[i ] } , \\pi_{[i ] } ) \\\\ & = w_i ,   \\end{split}\\ ] ] where in the second equality we have used the fact that the expected value of an indicator function is the probability of its corresponding event . hence , as was claimed , @xmath415 is a martingale . also note that @xmath418 } -   { \\mathds{1}\\left [ { a_i = a , \\pi_i = \\pi } \\right ] } \\pi(x ) p(y|a , x , s ) \\big",
    "| \\leq 1.\\ ] ] therefore using azuma s inequality for @xmath419 , we have @xmath420 which goes to zero as @xmath13 goes to infinity .",
    "hence , for @xmath13 large enough with high probability we have @xmath421 this statement is true for all @xmath422 which form a finite set .",
    "therefore , we can take @xmath13 large enough so that the above expression is true wit high probability for all values of @xmath412 . now , if @xmath423 we have @xmath424 which shows that is satisfied and the first type error vanishes as @xmath13 goes to infinity .",
    "now we analyze the second type of error .",
    "we condition the second error on @xmath425 } = \\pi_{[n]}$ ] and @xmath338 } = a_{[n]},y_{[n ] } = y_{[n]}$ ] .",
    "define @xmath426 for @xmath382 to be the event where @xmath382 satisfies .",
    "note that since the adversary does not observe @xmath427}(\\hat{m})$ ] for @xmath428 , unlike the first type of error , it can not establish correlation between them .",
    "thus , conditioned on @xmath429}$ ] , @xmath427}(\\hat{m})$ ] are independent and @xmath430 is generated from @xmath368",
    ". therefore for @xmath431 } ,   a_{[n]})$ ] , we can use packing lemma ( * ? ? ?",
    "* lemma 3.1 ) . using the independence among blocks @xmath379 , for some @xmath432 where @xmath433 we have @xmath434 for some @xmath435 that converges to zero as @xmath1 converges to zero . now using the independence of the above events , we have @xmath436",
    "now since the mutual information is bounded and the terms corresponding to those @xmath437 that do not appear in the above expression have length less than @xmath438 , and the set of possible @xmath432 is finite , there is a bounded constant @xmath439 such that @xmath440 where the last inequality uses the assumption @xmath431 } , a_{[n]})$ ] . therefore using union bound @xmath441 the above value goes to zero as @xmath13 goes to infinity by appropriate choice of @xmath1 since @xmath442 .        in the rest of the proof , we use theorem [ thm : main - two - sided ] to find the value of @xmath133 .",
    "we need to first find @xmath302 , which is the game value for the average payoff table @xmath443 .",
    "thus , @xmath444 writing @xmath50 instead of its distribution @xmath362 for convenience we have @xmath445 where the joint distribution of the variables is @xmath446 .",
    "since @xmath447 and @xmath9 are independent , we have @xmath448 using theorem [ thm : main - two - sided ] , we have @xmath449    in the above argument , the set @xmath353 is a finite and arbitrary subset of distributions on @xmath323 . now the only thing which remains to show is that by appropriate choice of finite set @xmath353 we can get arbitrarily close to the target value in . in order to do so ,",
    "define function @xmath55 as @xmath450 where the joint distribution is @xmath451 .",
    "this function is continuous on the product of compact spaces which is compact itself .",
    "therefore , @xmath55 is uniformly continuous .",
    "hence , since the set of distributions on @xmath323 is compact , for every given , @xmath330 , there is a finite covering @xmath353 of @xmath354 where for all @xmath452 , there exists @xmath453 such that for all @xmath454 @xmath455 therefore by appropriate choice of finite set @xmath353 we can get within any @xmath1 to the target value in .",
    "s.  zamir . .",
    "in robert aumann and sergiu hart , editors , _ _ , volume  1 of _ handbook of game theory with economic applications _ ,",
    "pages 109154 .",
    "elsevier , 1992 .",
    "url : http://www.sciencedirect.com/science/article/pii/s1574000505800086 , http://dx.doi.org/10.1016/s1574-0005(05)80008-6 [ ] ."
  ],
  "abstract_text": [
    "<S> we introduce a  high probability \" framework for repeated games with incomplete information . in our non - equilibrium setting , players aim to guarantee a certain payoff with high probability , rather than in expected value . </S>",
    "<S> we provide a high probability counterpart of the classical result of mertens and zamir for the zero - sum repeated games . </S>",
    "<S> any payoff that can be guaranteed with high probability can be guaranteed in expectation , but the reverse is not true . </S>",
    "<S> hence , unlike the average payoff case where the payoff guaranteed by each player is the negative of the payoff by the other player , the two guaranteed payoffs would differ in the high probability framework . </S>",
    "<S> one motivation for this framework comes from information transmission systems , where it is customary to formulate problems in terms of asymptotically vanishing probability of error . </S>",
    "<S> an application of our results to a class of compound arbitrarily varying channels is given . </S>"
  ]
}