{
  "article_text": [
    "in the process of developing experiments measuring new phenomena in physics the estimation of the sensitivity of certain configurations of experiments is of utmost importance . + a particularly active field",
    "is the estimate of sensitivities for future neutrino oscillation experiments , see for example @xcite .",
    "the goal of future experiments is often the measurement of a mixing angle ( denoted @xmath0 ) , the probability for a neutrino oscillation taking place being proportional to @xmath1 .",
    "+ in sensitivity studies for neutrino oscillation experiments , `` sensitivity '' is often not defined in the same way .",
    "furthermore uncertainties in nuisance parameters ( often sloppily called `` systematic uncertainties '' ) are often ignored ( see for example @xcite ) or included in calculations in an incomplete manner ( see discussion in @xcite ) .",
    "little attention seems to be given to the issue of how sensitivity is defined and uncertainties are treated , despite the fact that decisions on experimental set - ups might be based on small differences in sensitivity studies .",
    "+ in this note we try to firstly clarify the definition of `` sensitivity '' and discuss - using a toy model - potential problems which arise if instrumental uncertainties need to be considered . + the issue of sensitivity calculation has after being discussed on a recent conference on future neutrino experiments @xcite already inspired a more careful assessment of sensitivity calculation @xcite which indicates that a more formal discussion is worthwhile .",
    "probably the most common definition of sensitivity adopted in the study of future experiments aimed at the discovery of signals of as yet undetected physics phenomena is : + _ the experiment is said to be sensitive to a given value of the parameter @xmath2 at significance level @xmath3 if the mean p - value obtained given @xmath4 is smaller than @xmath3 . _",
    "+ here we choose ( in the spirit of neutrino oscillation experiments ) the parameter describing the new physics phenomenon to be denoted by @xmath0 .",
    "the p - value is ( per definition ) calculated under the condition that the null hypothesis holds : @xmath5 where @xmath6 denotes the null hypothesis and @xmath7 denotes the test statistics with its observed value @xmath8 , which is distributed as the distribution function @xmath9",
    ". we will give common definitions of @xmath7 in the next section .",
    "+ a variation , which is the most commonly used in the context of neutrino experiments is using confidence intervals for the definition of sensitivity : + _ the experiment is said to be sensitive to a given value of the parameter @xmath2 at significance level @xmath3 if the mean @xmath10 confidence interval obtained , given @xmath4 , does not contain @xmath11 _ + both definitions can be equivalent , but are not in general , depending on the choice of test statistics and the method of confidence interval calculation .",
    "for example , choosing to calculate upper limits would never yield detection .",
    "+ to our knowledge , all sensitivity curves presented for neutrino oscillation experiments follow above definitions and therefore correspond to the mean observation .",
    "this has two important implications : firstly , it should be emphasized that if the distribution of parameter estimates is gaussian , it is a well known fact ( but often ignored ) that even if @xmath12 ( i.e. the true value is at the estimated sensitivity ) , the probability for actually claiming discovery is only 50 % .",
    "secondly , if the parameter estimates are not gaussian ( see for example @xcite ) , then the presentation of the mean result yields very little information on the actual probability for discovery .",
    "thus , the choice to present mean experimental results is not particularly informative .",
    "a more general definition of sensitivity therefore has to specify two probabilities : + _ the experiment is sensitive to a given value of @xmath2 if the probability of obtaining an observation n which rejects @xmath13 with at least significance @xmath3 is at least @xmath14 . _",
    "+ where we have chosen to reformulate the definition as to be applicable to both definitions given above .",
    "another example where an attempt is made to define sensitivity in a manner involving the detection probability can be found in @xcite",
    "according to the neyman - pearson lemma , the uniformly most powerful test statistics that can be chosen is the likelihood ratio : @xmath15 where t denotes the test statistics and @xmath16 denotes the likelihood under the observation @xmath17 for the null hypothesis ( @xmath18 ) and the alternative hypothesis ( @xmath19 ) , respectively .",
    "one useful property of the likelihood ratio is the fact that asymptotically : @xmath20 i.e. the distribution of t under the null hypothesis is known and the significance of the observation can be calculated from the @xmath21 distribution .",
    "a particular common method in studies of neutrino oscillation experiments is to perform a @xmath21 fit and calculate a confidence interval from the function @xmath22 .",
    "for example , the interval @xmath23 $ ] can be found by finding the points for which : @xmath24 where @xmath25 denotes the @xmath21 at the best fit value of @xmath0 .",
    "this confidence interval is then often used to claim discovery by requiring @xmath26 .",
    "+ there are two quantities which are of crucial importance in the context of calculation of confidence intervals and in the testing of hypothesis ( claiming of discovery ) .",
    "methods to calculate confidence intervals should have _ coverage _ , defined as : + _ an algorithm is said to have the correct _ coverage _ if given a confidence level @xmath10 and a large number of repeated identical experiments , the resulting confidence intervals include the true value of the parameters to be estimated in a fraction @xmath10 of all experiments . _",
    "+ if confidence intervals are used to claim discovery ( meaning for testing hypotheses ) , then @xmath3 is the probability for making a type i error , i.e. the probability for rejecting the null hypothesis though it is true ( often called _ significance _ ) . + the other quantity we will be interested in is the _",
    "power_. power is the probability that the null hypothesis is rejected given that the alternative hypothesis is true .",
    "this quantity is exactly the probability we denoted @xmath14 in the previous section .",
    "the probability 1 - @xmath14 is the probability to make a type ii error ( accepting the null hypothesis though it is false ) .",
    "_ nuisance parameters _ are parameters which enter the data model , but which are not of prime interest .",
    "the probably most common example is the expected background in a poisson process .",
    "sensitivities ( as confidence intervals ) are usually only calculated for the parameter of primary interest and it is not desired to calculate them depending on parameters which are of no physical interest and specific to the experiment .",
    "thus , ways have to be found to marginalize the nuisance parameter .",
    "there are two particularly common approaches : + in the first method , the probability density function ( pdf ) without uncertainty in nuisance parameters is replaced by one where there is an integration over all possible true values of the nuisance parameter _",
    "( integration method ) _ :",
    "@xmath27 here @xmath28 is the true value of the nuisance parameter and @xmath29 is its estimate .",
    "since the integrated pdf is describing the probability of the true value given its estimate ( and not vice versa ) this method is bayesian .",
    "some prior probability distribution of the true value of the nuisance parameter has to be assumed .",
    "+ in the other common method , the pdf is replaced by one where for each @xmath30 the pdf is maximized with respect to the nuisance parameters _ ( profiling method ) _ @xmath31 with notation as above .",
    "this method is completely frequentist , since it never treats @xmath28 as a random variable .",
    "therefore the argument of the maximization is a likelihood function and not a pdf .",
    "both these methods are frequently applied in high energy physics in confidence interval calculations @xcite,@xcite and references therein and to them .",
    "+ in assessment of sensitivities of neutrino oscillation experiments , uncertainties are often included by performing a least square fit using a modified @xmath21 and use the resulting confidence interval ( see previous section ) to claim discovery .",
    "two modifications are particularly common .",
    "one method is to add the uncertainty in the background estimate in quadrature ( for simplicity we will restrict ourselves to background estimate uncertainties ) : @xmath32 where @xmath33 denotes the experimental result , @xmath29 the background estimate and @xmath34 the uncertainty on that estimate . under assumption of a gaussian process and",
    "applying bayesian reasoning , @xmath35 can be viewed as equivalent to using the method illustrated in equation [ eq : integration ] .",
    "+ the other ( probably more common ) method of inclusion is based on adding a normalization parameter to the @xmath21 and minimize the @xmath21 with respect to it , see for example @xcite @xmath36 where in addition to the parameters described above , we introduce the normalization parameter @xmath37 .",
    "this modification is equivalent to the method represented by equation [ eq : profile ] under assumption of gaussian processes . +",
    "a priori it can not be assumed that the modified quantities @xmath38 and @xmath35 still follow a @xmath21 distribution .",
    "however , in general , this is the assumption employed in sensitivity calculations is obviously not modified , in our simple example : @xmath39 .",
    "however , its distribution under the null hypothesis is not @xmath21 since @xmath29 is not constant at the true value , but a random variable . ] . in the following section we will apply above definitions to a toy model and",
    "check the validity of the assumption using monte carlo simulations .",
    "for simplicity , we will consider a one bin measurement , where we measure a number of events from a poisson process with background contribution and we obtain an estimate of the background from a separate measurement , which is assumed to be gaussian . in equations : @xmath40 where @xmath41 denotes a poisson process with experimental outcome @xmath17 ( number of events ) , signal parameter @xmath30 and background parameter @xmath42 and @xmath43 denotes a gaussian process with experimental outcome @xmath29 and width @xmath44 . since in the common neutrino oscillation experiment @xmath45",
    "this toy model captures the main feature of many experiments ( though being a simplification , obviously ) .",
    "+ using monte carlo simulations of replica of the actual experiment , we can calculate the true distribution of the test statistics defined in equation [ eq : chi11 ] and [ eq : chi21 ] under the condition that the null hypothesis is true ( @xmath46 , thus the coverage .",
    "we can also assume @xmath47 and calculate the probability that the null distribution will be rejected given the alternative hypothesis is true , i.e. the power .",
    "+ figures [ fig : cov ] , [ fig : cov2 ] and [ fig : pow ] exemplify the results .",
    "figure [ fig : cov ] shows the value of the modified @xmath21s as a function of corresponding coverage .",
    "results are shown for a true background of @xmath48 and an uncertainty in the background estimate of 20 % .",
    "for this very simple example , it can clearly be seen that ignoring uncertainties ( in this case in the background estimate ) leads to a increased rate of false detections with respect to the one the experimenter intents .",
    "the real false detection rate for 99 % nominal threshold for example is larger by a factor @xmath493 . the effect becomes smaller if one decides to include the additional uncertainties in one of the two ways described in equation [ eq : chi11 ] and [ eq : chi21 ] . using the latter for example the false detection rate increases by 50 % with respect to that nominally required .",
    "+ though we are assuming a background of @xmath48 , part of the found difference could be due to the fact that we use @xmath21 statistics for a poisson process .",
    "we therefore include the case where we assume a strictly gaussian measurement process ( see fig .",
    "[ fig : cov ] , right panel ) .",
    "the difference between the methods becomes less pronounced , but is still large .",
    "+ in figure [ fig : cov2 ] we show results for smaller uncertainties in the background estimate ( 10 % ) . as intuitively expected , the impact of the method chosen to calculate the significance becomes less important .",
    "if we consider a truely gaussian process ( right panel ) for smaller uncertainties both the method using quadratic addition and profiling give results compatible with a nominal @xmath21 distribution .",
    "the complete measurement process consists of a measurement of background and a measurement of signal events .",
    "a complete @xmath21 is therefore : @xmath50 and @xmath51 .",
    "this quantity is included in the figures .",
    "the left panel shows the results for the poisson measurement process .",
    "the right panel assumes a gaussian process .",
    "the uncertainties in the background estimate are assumed to be 20 % .",
    "[ fig : cov ]    in figure [ fig : pow ] we show the relative difference in power between the quadratic addition and the profile method . for large signals the power non unexpectedly approaches one , i.e. the method used to calculate the test statistics does not matter .",
    "for low signals however one sees that the power of the profile method is up to 35 % larger than for the method of adding the uncertainty in quadrature .      in our simple toy model",
    "the set of measurements is @xmath52 and since we know the distribution of these measurements the ensemble of experiment replica is easily constructed . under more realistic experimental conditions many different both correlated and uncorrelated nuisance parameter might need to be considered .",
    "this might become computationally very cumbersome , for example if full detector simulations need to be employed .",
    "sometimes even uncertainties in theoretical estimates have to be considered .",
    "it seems doubtful , though possibly the only feasible way , to treat these as random variables .",
    "two subjects have been discussed in this note :    * _ the interpretation of `` sensitivity '' _ + usually estimates of sensitivity are based on an average experimental result . for a gaussian distribution of estimates , this implies that if @xmath2 the probability for claiming discovery will be only 50 % .",
    "this is a well known , but often ignored fact . in our experience , many physicists have the notion that if the value of the true value of the parameter is indeed equal to the sensitivity , then it should be very likely that a discovery will be made . + if the distribution of estimates is not gaussian , in general no statement about the probability of detection is made if only the average experimental result is presented .",
    "consequently , statements about the probability for detection should be included in presentation of sensitivity estimates .",
    "they can be calculated if the distribution of estimates is known or can be simulated .",
    "+ * _ effect of uncertainties _",
    "+ the results of the toy model calculation show that if uncertainties in nuisance parameters are included into the calculation of sensitivities ( and measurement results ) extra care has to be taken to make sure statistical statements ( like the significance of a discovery , or confidence level of an interval ) are still valid .",
    "the largest mistake is not surprisingly made if the uncertainties are ignored .",
    "the choice of method to include the systematics furthermore affects the probability of making a discovery . in addition , in presence of sizable instrumental uncertainties , the ensemble of experiments for calculating significance and power needs to be carefully defined .",
    "+    when comparing sensitivity estimates for different experiments and experimental configurations , differences therefore certainly could arise from the way the uncertainties are included ( if at all ) in the calculations .",
    "it seems obvious , that sensitivity curves need to be compared at the same `` real '' significance level and at the same `` real '' probability for discovery , whereas they are usually compared for the same nominal significance level and under the assumption that the probability for discovery will be always 50 % .",
    "+ the toy model presented here is a crude simplification of the actual experimental situation where many measurement bins and different types of correlated and uncorrelated uncertainties have to be considered .",
    "for example , a generalization of the profiling method to a more realistic experimental situation , including many bins and correlated systematic uncertainties , is given in @xcite .",
    "the results presented in figures [ fig : cov ] , [ fig : cov2 ] and figure [ fig : pow ] should therefore rather serve as an inspiration for detailed studies of realistic experimental conditions ( see for example @xcite ) .",
    "if possible , the statistical quantities should be studied using monte carlo simulations of many replica of the experiment under study .",
    "application of monte carlo simulations does not only yield information on the correct false detection rates but also on the probability of detection , which is of obvious importance for assessment of sensitivities of future experiments .",
    "this research was supported by the swedish research council under grant 621 - 2004 - 2196 .",
    "we thank an anonymous referee for useful suggestions .    00",
    "international scoping study , http://www.hep.ph.ic.ac.uk/iss/ p.  sinervo , _ in the proceedings of phystat2003 : statistical problems in particle physics , astrophysics , and cosmology , menlo park , california , 8 - 11 sep 2003 , pp tuat004_. m.  komatsu , p.  migliozzi and f.  terranova , j.  phys .",
    "g * 29 * , 443 ( 2003 ) [ arxiv : hep - ph/0210043 ] .",
    "d.  indumathi , m.  v.  n.  murthy , g.  rajasekaran and n.  sinha , phys .",
    "d * 74 * , 053004 ( 2006 ) [ arxiv : hep - ph/0603264 ] .",
    "j.  conrad , invited contribution to 8th international workshop on neutrino factories and superbeams ( nufact 06 ) , irvine , usa , august 2006 , http://nufact06.physics.uci.edu/workshop/program/plenary.aspx t.  schwetz , phys .",
    "b * 648 * ( 2007 ) 54 [ arxiv : hep - ph/0612223 ] .",
    "g.  punzi , _ in the proceedings of phystat2003 : statistical problems in particle physics , astrophysics , and cosmology , menlo park , california , 8 - 11 sep 2003 , pp modt002 _ [ arxiv : physics/0308063 ] .",
    "j.  conrad , _ et .",
    "d * 67 * ( 2003 ) 012002 [ arxiv : hep - ex/0202013 ] .",
    "w.  a.  rolke , a.  m.  lopez and j.  conrad , nucl .",
    "instrum .",
    "a * 551 * ( 2005 ) 493 [ arxiv : physics/0403059 ] .",
    "j.  burguet - castell , d.  casper , e.  couce , j.  j.  gomez - cadenas and p.  hernandez , nucl .",
    "b * 725 * ( 2005 ) 306 [ arxiv : hep - ph/0503021 ] .",
    "p.  huber , m.  lindner and w.  winter , nucl .",
    "b * 645 * ( 2002 ) 3 [ arxiv : hep - ph/0204352 ] .",
    "v.  barger , m.  dierckxsens , m.  diwan , p.  huber , c.  lewis , d.  marfatia and b.  viren , phys .",
    "d * 74 * , 073004 ( 2006 ) [ arxiv : hep - ph/0607177 ]",
    ". g.  l.  fogli , e.  lisi , a.  marrone , d.  montanino and a.  palazzo , phys .",
    "d * 66 * ( 2002 ) 053010 [ arxiv : hep - ph/0206162 ] ."
  ],
  "abstract_text": [
    "<S> calculations of sensitivities of future experiments are a necessary ingredient in experimental high energy physics . especially in the context of measurements of the neutrino oscillation parameters extensive studies </S>",
    "<S> are performed to arrive at the optimal configuration . in this note </S>",
    "<S> we clarify the definition of sensitivity as often applied in these studies . </S>",
    "<S> in addition we examine two of the most common methods to calculate sensitivity from a statistical perspective using a toy model . </S>",
    "<S> the importance of inclusion of uncertainties in nuisance parameters for the interpretation of sensitivity calculations is pointed out .    </S>",
    "<S> sensitivity , statistical methods , neutrino oscillation experiments </S>"
  ]
}