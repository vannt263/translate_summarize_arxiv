{
  "article_text": [
    "recent progress in next - generation sequencing ( ngs ) technologies allow to access large amounts of genomic data within a few hours at a reasonable cost  @xcite . in metagenomics , ngs is used to analyse the genomic content of microbial communities by sequencing all dna present in an environmental sample  @xcite .",
    "it gives access to all organisms present in the sample even if they do not grow on culture media @xcite , and allows us to characterize with an unprecedented level of resolution the diversity of the microbial realm @xcite .",
    "the raw output of a metagenomics experiment is a large set of short dna sequences ( reads ) obtained by high - throughput sequencing of the dna present in the sample .",
    "there exist two main approaches to analyze these data , corresponding to slightly different goals . on the one hand , _ taxonomic profiling _ aims to estimate the relative abundance of the members of the microbial community , without necessarily affecting each read to a taxonomic class .",
    "recent works like wgsquikr @xcite or gasic @xcite proved to be very efficient for this purpose .",
    "_ taxonomic binning _ methods , on the other hand , explicitly affect each read to a taxonomic clade .",
    "this process can be unsupervised , relying on clustering methods to affect reads to operational taxonomic units ( otu ) , or supervised , in which case reads are individually affected to nodes of the taxonomy  @xcite . while binning is arguably more challenging that profiling , it is a necessary step for downstream applications which require draft - genome reconstruction",
    ". this may notably be the case in a diagnostics context , where further analyses could aim to detect pathogen micro - organisms  @xcite or antibiotic resistance mechanisms  @xcite .",
    "in this paper we focus on the problem of supervised taxonomic binning , where we wish to assign each read in a metagenomics sample to a node of a pre - defined taxonomy .",
    "two main computational strategies have been proposed for that purpose : ( i ) alignment - based approaches , where the read is searched against a reference sequence database with sequence alignment tools like blast @xcite or short read mapping tools ( e.g. , bwa , * ? ? ?",
    "* ) , and ( ii ) compositional approaches , where a machine learning model such as a naive bayes ( nb ) classifier @xcite or a support vector machine ( svm , * ? ? ?",
    "* ; * ? ? ?",
    "* ) is trained to label the read based on the set of @xmath0-mers it contains . since the taxonomic classification of a sequence by compositional approaches",
    "is only based on the set of @xmath0-mers it contains , they can offer significant gain in terms of classification time over similarity - based approaches . training a machine learning model for taxonomic binning can however be computationally challenging .",
    "indeed , compositional approaches must be trained on a set of sequences with known taxonomic labels , typically obtained by sampling error - free fragments from reference genomes . in the case of nb classifiers , explicit sampling of fragments from reference genomes",
    "is not needed to train the model : instead , a global profile of @xmath0-mer abundance from each reference genome is sufficient to estimate the parameters of the nb model , leading to simple and fast implementations @xcite .",
    "on the other hand , in the case of svm and related discriminative methods , an explicit sampling of fragments from reference genomes to train the model based on the @xmath0-mer content of each fragment is needed , which can be a limitation for standard svm implementations .",
    "for example , @xcite sampled approximately 10,000 fragments from 1768 genomes to train a structured svm ( based on a @xmath0-mer representation with @xmath3 ) , and reported an accuracy competitive with similarity - based approaches .",
    "increasing the number of fragments sampled to train a svm may improve its accuracy , and allow us to investigate larger values of @xmath0 .",
    "however it also raises computational challenges , as it involves machine learning problems where a model must be trained from potentially millions or billions of training examples , each represented by a vector in @xmath2 dimensions for , e.g. , @xmath4 .    in this work",
    ", we investigate the potential of compositional approaches for taxonomic label assignment using modern , large - scale machine learning algorithms .",
    "in most of compositional metagenomics applications , a sequence is represented by its @xmath0-mer profile , namely , a vector counting the number of occurrences of any possible word of @xmath0 letters in the sequence . only the @xmath5 nucleotides are usually considered to define @xmath0-mer profiles , that are therefore @xmath6-dimensional vectors .",
    "although the size of the @xmath0-mer profile of a sequence of length @xmath7 increases exponentially with @xmath0 , it contains at most @xmath8 non - zero elements since a sequence of length @xmath0 contains @xmath8 different @xmath0-mers",
    ".    given a sequence represented by its @xmath0-mer profile @xmath9 , we consider linear models to assign it to one of @xmath10 chosen taxonomic classes .",
    "a linear model is a set of weight vectors @xmath11 that assign @xmath12 to the class @xmath13 where @xmath14 is the standard inner product between vectors . to train the linear model , we start from a training set of sequences @xmath15 with known taxonomic labels @xmath16 .",
    "a nb classifier , for example , is a linear model where the weights are estimated from the @xmath0-mer count distributions on each class .",
    "another class of linear models popular in machine learning , which include svm , are the discriminative approaches that learn the weights by solving an optimization problem which aims to separate the training data of each class from each other .",
    "more precisely , to optimize the weight @xmath17 of the @xmath18-th class , one typically assigns a binary label @xmath19 to each training example ( @xmath20 if @xmath21 , or @xmath22 otherwise ) and solves an optimization problem of the form @xmath23 where @xmath24 is a loss function quantifying how `` good '' the prediction @xmath25 is if the true label is @xmath26 , and @xmath27 is a regularization parameter to tune , helpful to prevent overfitting in high dimension .",
    "a svm solves ( [ eq : learning ] ) with the hinge loss @xmath28 , but other losses such as the logistic loss @xmath29 or the squared loss @xmath30 are also possible and often lead to models with similar accuracies .",
    "these models have met significant success in numerous real - world learning tasks , including compositional metagenomics @xcite . in this work ,",
    "we use the squared loss function and choose @xmath31 , leading to no regularization .",
    "although learning linear models by solving ( [ eq : learning ] ) is now a mature technology implemented in numerous softwares , metagenomics applications raise computational challenges for most standard implementations , due to the large values that @xmath32 ( number of reads in the training set ) , @xmath33 ( dimension of the models ) and @xmath10 ( number of taxonomic classes ) can take .",
    "the training set is typically obtained by sampling fragments from reference genomes with known taxonomic class .",
    "for example , @xcite sampled approximately @xmath34 fragments from @xmath35 genomes to train svm models based on @xmath0-mer profiles of size @xmath3 .",
    "however , the number of distinct fragments that may be drawn from a genome sequence is approximately equal to its length ( by sampling a fragment starting at each position in the genome ) , hence can reach several millions for each microbial genome , leading to potentially billions of training sequences when thousands of reference genomes are used . while considering every possible fragment from every possible genome may not be the best choice because of the possible redundancy between the reads , it may still be useful to consider a significant number of fragments to properly account for the intra and inter species genomic variability .",
    "similarly , exploring models with @xmath0 larger than @xmath36 , say @xmath37 or @xmath38 , may be interesting but requires ( i ) the capacity to manipulate the corresponding @xmath6-dimensional vectors ( @xmath39 ) , and ( ii ) large training sets since many examples are needed to learn a model in high dimension .",
    "finally , real - life applications involving actual environmental samples may contain several hundreds microbial species , casting the problem into a relatively massive multiclass scenario out of reach of most standard implementations of svm .    to solve ( [ eq : learning ] ) efficiently",
    "when @xmath32 , @xmath0 and @xmath10 take large values , we use a dedicated implementation of stochastic gradient descent  ( sgd * ? ? ?",
    "* ) available in the vowpal wabbit software  ( vw * ? ? ?",
    "* ; * ? ? ?",
    "* ) . in short , sgd exploits the fact that the objective function in ( [ eq : learning ] ) is an average of @xmath32 terms , one for each training example , to approximate the gradient at each step using a single , randomly chosen term .",
    "although sgd requires more steps to converge to the solution than standard gradient descent , each step is @xmath32 times faster and the method is overall faster and more scalable . in addition , although the dimension @xmath33 of the data is large , vw exploits the fact that each training example is sparse , leading to efficient memory storage and fast updates at each sgd step .",
    "we refer the interested reader to @xcite for more discussion about the relevance of sgd in large - scale learning . in practice",
    ", vw can train a model with virtually no limit on @xmath32 as long as the data can be stored on a disk ( they are not loaded in memory ) . as for @xmath0",
    ", vw can handle up to @xmath40 distinct features , and the count of each @xmath0-mer is randomly mapped to one feature by a hash table .",
    "this means that we have virtually no limit on @xmath0 , except that when @xmath0 approaches or exceeds the limit ( such that @xmath41 , i.e. , @xmath42 ) , collisions will appear in the hash table and different @xmath0-mers will be counted together , which may impact the performance of the model .",
    "we simulate metagenomics samples by generating reads from three different reference databases , which we refer to below as the _ mini _ , the _ small _ and the _ large _ databases .    the _ mini _ reference database contains 356 complete genome sequences covering 51 bacterial species , listed in table [ tab : poc ] .",
    "we use this database to train and extensively vary the parameters of the different models . to measure the performance of the different models , we generate new fragments from 52 genomes not present in the reference database , but originating from one of the 51 species .",
    ".list of the 51 microbial species in the _ mini _ reference database.[tab : poc ] [ cols= \" < , < \" , ]      the evaluation performed in the previous sections is based on taxonomic classification of dna fragments drawn from reference genomes without errors . in real life",
    ", sequencing errors may alter the read sequences and make the classification problem more challenging . to evaluate the robustness of the classifiers to sequencing errors ,",
    "we generate new reads simulating sequencing errors using the grinder read simulation software @xcite .",
    "we consider two types of sequencing errors models : homopolymeric stretches , which are commonly encountered in pyrosequencing technologies ( e.g. , roche 454 ) , and general mutations ( substitutions and insertions / deletions ) . in order to be able to compare the results of the fragment- and read - based evaluations , we systematically simulate reads of length 200 ( exactly ) , and simulate around @xmath43 sequences as well .      to evaluate the impact of homopolymeric errors , we consider the three error models implemented in grinder : ` balzer ` @xcite , ` richter ` @xcite and ` margulies ` @xcite .",
    "results are shown in figure [ fig : fcp - homo ] .",
    "we first note that this kind of errors has a very limited impact on bwa - mem : only the ` margulies ` model turns out to be detrimental , with a drop of less than 1% for both the small and large reference databases .",
    "the ` balzer ` and ` richter ` models have a limited impact on the compositional approach as well : a drop of less than @xmath44 is observed as well in most cases ( except with the nb classifier , where a drop of almost @xmath45 is observed using the large reference database and the ` richter ` model ) .",
    "the ` margulies ` model , on the other hand , has a much more severe impact on the performance of @xmath0-mer based approaches .",
    "while a relatively limited performance drop of around @xmath46 is observed with vw using the small reference database , the nb shows a drop of more than @xmath47 . considering the large reference database ,",
    "both approaches show a drop of almost @xmath48 , which therefore leads to a gap of more than @xmath49 and up to @xmath50 , for vw and nb respectively , compared to the performance of the alignment - based approach .",
    "this discrepancy is therefore significantly higher than the one observed from fragments , where vw and nb have performance lower than that of bwa - mem by around @xmath51 and @xmath52 , respectively , on the large reference database . analyzing the error profile of the reads obtained by grinder reveals that both the ` balzer ` and ` richter ` models lead to a median mutation rate of @xmath53 ( meaning that half of the 200 bp simulated reads show more than one modified base ) , while this rate raises to @xmath54 with the ` margulies ` model .",
    "while this can readily explain why this latter model had a stronger impact , it suggests that what may be seen as a relatively moderate modification of the sequences ( 6 bases out of 200 ) can have a severe impact on compositional approaches .",
    "to study the impact of general mutation errors , we consider the 4th degree polynomial proposed by @xcite and implemented in grinder . using the default values proposed by grinder , we empirically observe a median mutation rate of @xmath55 .",
    "this value is much more important than what is expected by current ngs technologies , and is probably due to the fact that this model was calibrated from shorter reads .",
    "indeed , the median mutation rate decreases to around @xmath46 when we reduce the length of the reads to 30 , in agreement with the results of the original publication @xcite . to investigate in details the impact of mutations within reads of length 200 , we modify the parameters of the error model in order to gradually increase the median mutation rate from @xmath44 to @xmath49 , by @xmath44 .",
    "this therefore leads to simulating 11 datasets , since we consider in addition the default grinder configuration .",
    "results are shown in figure [ fig : fcp - mutation ] .",
    "we first note that this type of errors has a very limited impact on alignment - based approach : even at the higher rate of mutation considered ( median mutation rate of @xmath55 ) , the performance drops by around @xmath44 with respect to the performance obtained with fragments , for both the small and large reference databases . on the other hand ,",
    "the performance obtained with compositional approaches steadily decreases when the mutation rate increases .",
    "using the small reference database , the impact is more severe for nb than for vw : a drop of up to @xmath49 is observed in the former case ( from @xmath56 for fragments down to @xmath57 for a mutation rate of @xmath55 ) and almost @xmath58 in the latter ( from @xmath59 down to @xmath60 ) .",
    "the drop is even more severe using the larger database in both cases . interestingly",
    "while it remains relatively constant around @xmath49 for mutation rate greater than @xmath51 with nb ( hence twice the gap observed between the small and large datasets using fragments ) , it keeps increasing with vw and reaches @xmath61 at the highest mutation rate considered . as a result ,",
    "vw is outperformed by nb using the large reference database for mutation rates greater than @xmath48 .",
    "although these extreme configurations are not realistic regarding the current state of the ngs technologies , we emphasize , in agreement with the previous experiment on homopolymeric errors , that significant drops are observed with compositional approaches for moderate mutation rates , especially for large number of candidate species .",
    "for instance , with a mutation rate of @xmath45 , the performances of vw and nb drop respectively by @xmath62 and @xmath47 with the large reference database , while this has no impact on the alignment approach . in this more realistic setting",
    ", the alignment - based approach shows markedly higher performances : it provides a median species - level accuracy of @xmath63 , while vw and the nb classifier reach @xmath64 @xmath65 , respectively .        ) with the error model proposed in @xcite .",
    ", scaledwidth=60.0% ]      last but not least , we now turn to the comparison of the comparative and compositional approaches in terms of prediction time",
    ". this aspect is indeed of critical importance for the analysis of the large volumes of sequence data provided by next - generation sequencing technologies , and constitutes the main motivation of resorting to @xmath0-mer based approaches . to perform this evaluation",
    "we measure the time taken by bwa - mem and the @xmath0-mer based approaches to process the 30 test datasets involved in the previous experiments ( 1 fragments dataset , 3 reads datasets with homopolymeric errors and 11 reads datasets with mutation errors , for the two reference databases considered ) .",
    "this allows us to investigate the impact of the number of species involved in the reference database , as well as the amount of sequencing noise in the reads .",
    "we do not make a distinction between the two compositional approaches : both involve computing a score for each candidate species , defined as a dot product between the @xmath0-mer profile of the sequence to classify and a vector of weights obtained by training the model . to compute this dot - product efficiently",
    ", we implemented a procedure described in @xcite . with this procedure ,",
    "each a , t , g , c nucleotide is encoded by two bits , which allows to directly convert a @xmath0-mer as in integer between 0 and @xmath66 .",
    "provided that the weight vector is loaded into memory , the score can be computed  on the fly \" while evaluating the @xmath0-mer profile of the sequence to be classified , by adding the contribution of the current @xmath0-mer to the score .",
    "the drawback of this procedure lies in the fact that the vectors of weights defining the classification models need to be loaded into memory , which can be cumbersome in a multiclass setting . for 193 and 774 species and @xmath0-mers of size 12 ,",
    "this amounted to @xmath67 and @xmath68 gigabytes , respectively .",
    "computation times are measured on a single cpu ( intel xeon - 2.8 ghz ) equipped with 250 gb of memory , and summarized in figure  [ fig : pred - time ] .",
    "the time needed to classify each read or fragment dataset by the @xmath0-mer approach shows little variation , for a given reference database .",
    "the median value obtained across test datasets reaches 5.4 and 9.1 minutes , using the small and large reference database , respectively , hence about a two - fold difference .",
    "this therefore amounts to classifying around @xmath69 and @xmath70 reads per minute , respectively .",
    "bwa - mem shows a different behavior .",
    "we observe that the time varies more across reads and fragment datasets , and tends to increase with the amount of sequencing noise .",
    "on the other hand , the size of the reference database has a lesser impact , with at most an increase of @xmath50 between the time needed to process a test dataset with the small or large reference databases .",
    "the compositional approach systematically offers shorter prediction times , with an improvement of 3 to almost 15 times , depending on the configuration .",
    "in this work , we investigate the potential of modern , large - scale machine learning approaches for taxonomic binning of metagenomics data .",
    "we extensively evaluate their performance when the scale of the problem increases regarding ( i ) the length of the @xmath0-mers considered to represent a sequence , ( ii ) the number of fragments used to learn the model , and ( iii ) the number of candidate species involved in the reference database .",
    "we also investigate in details their robustness to sequencing errors using simulated reads .",
    "we consider two baselines for this evaluation : a comparative approach based on the bwa - mem sequence aligner and a compositional approach based on the generative nb classifier .",
    "we demonstrate in particular that increasing the number of fragments used to train the model has a significant impact on the accuracy of the model , and allows to estimate models based on longer @xmath0-mers .",
    "while this could be expected and was already highlighted by previous studies , the resulting configurations are out of reach of standard svm implementations .",
    "we also show that discriminatively trained compositional models usually offer significantly higher performances than generative nb classifiers .",
    "the resulting models are competitive with well - established alignment tools for problems involving a small to moderate number of candidate species , and for reasonable amounts of sequencing errors .",
    "our results suggest , however , that compositional approaches , both discriminative and generative , are still limited in their ability to deal with problems involving more than a few hundreds species . in this case , indeed , compositional approaches exhibit lower performance than alignment - based approaches and are much more negatively impacted by sequencing errors .",
    "finally , we confirm that compositional approach achieve faster prediction times .",
    "this is indeed systematically the case in the various configurations listed above , with predictions obtained 3 to 15 times faster by compositional approaches , and , interestingly , depends on the number of candidate species and the level of sequencing noise .",
    "we emphasize , however , that fast predictions can only be obtained provided that the classification models are loaded in memory , hence for a memory footprint that scales linearly with the number of candidate species and exponentially with the size of the @xmath0-mers , which can become important for large reference databases and long @xmath0-mers .",
    "at least three simple extensions could be envisioned to make compositional approaches more competitive in accuracy with the alignment - based approach , faster , and to limit their memory footprint .",
    "first , the robustness to sequencing errors may be improved by learning models from simulated reads instead of fragments .",
    "this could indeed allow to tune the model to the sequencing technology producing the reads to be analyzed , provided its error model is properly known and characterized .",
    "second , introducing a sparsity - inducing penalty while learning the model would have the effect of reducing the number of features entering the model , hence to reduce the memory footprint required to load the model into memory .",
    "finally , alternative strategies , known as error correcting tournaments @xcite , could be straightforwardly considered to reduce the number of models to learn , hence to store into memory during prediction , to address a multiclass problem .",
    "our results indeed suggest that addressing these issues is critical to build state - of - the - art compositional classifiers to analyze metagenomics samples that may involve a broad spectrum of species .",
    "we emphasize however that such large scale models can remain competitive for realistic amounts of sequencing errors and a moderate number of species ( around 200 in our study ) , hence can already be useful in cases where the number of species that can be encountered is limited , which may in particular be the case for diagnostic applications involving specific types of specimens .",
    "korbel , j .",
    "( 2010 ) pemer : a computational framework with simulation - based error models for inferring genomic structural variants from massive paired - end sequencing data , _ genome biol _ ,",
    "* 10 * , 2323 ."
  ],
  "abstract_text": [
    "<S> metagenomics characterizes the taxonomic diversity of microbial communities by sequencing dna directly from an environmental sample . </S>",
    "<S> one of the main challenges in metagenomics data analysis is the binning step , where each sequenced read is assigned to a taxonomic clade . due to the large volume of metagenomics datasets , </S>",
    "<S> binning methods need fast and accurate algorithms that can operate with reasonable computing requirements . </S>",
    "<S> while standard alignment - based methods provide state - of - the - art performance , compositional approaches that assign a taxonomic class to a dna read based on the @xmath0-mers it contains have the potential to provide faster solutions .    in this work , </S>",
    "<S> we investigate the potential of modern , large - scale machine learning implementations for taxonomic affectation of next - generation sequencing reads based on their @xmath0-mers profile . </S>",
    "<S> we show that machine learning - based compositional approaches benefit from increasing the number of fragments sampled from reference genome to tune their parameters , up to a coverage of about 10 , and from increasing the @xmath0-mer size to about 12 . </S>",
    "<S> tuning these models involves training a machine learning model on about @xmath1 samples in @xmath2 dimensions , which is out of reach of standard softwares but can be done efficiently with modern implementations for large - scale machine learning . </S>",
    "<S> the resulting models are competitive in terms of accuracy with well - established alignment tools for problems involving a small to moderate number of candidate species , and for reasonable amounts of sequencing errors . </S>",
    "<S> we show , however , that compositional approaches are still limited in their ability to deal with problems involving a greater number of species , and more sensitive to sequencing errors . </S>",
    "<S> we finally confirm that compositional approach achieve faster prediction times , with a gain of 3 to 15 times with respect to the bwa - mem short read mapper , depending on the number of candidate species and the level of sequencing noise . </S>"
  ]
}