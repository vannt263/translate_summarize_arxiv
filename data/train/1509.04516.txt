{
  "article_text": [
    "search problems appear in diverse contexts  @xcite and there have been a recent surge of interests in the physics community in these problems  @xcite .",
    "search strategies may be either systematic or random . in the systematic strategies ,",
    "the searcher uses deterministic rules ( e.g. , ` lawnmower ' ) to find a target . on the other hand ,",
    "the random search mechanism typically involves two kinds of moves : local steps when the searcher looks for a target , and long - range moves during which the searcher does not look for the target but relocates itself to a different territory . the slow search phase is typically modelled by a diffusion or a random walk .",
    "the long - range moves may be modelled depending on the specific application  @xcite .    a particularly simple long - range strategy consists of ` resetting ' the searcher to a fixed location ( say to the initial starting point ) with a finite probability / rate .",
    "the rational behind this strategy is that if one does not succeed in finding the target via short - range diffusion , it is better to ` restart ' the process , rather than continuing on the short - range moves .",
    "the effect of such stochastic resetting was first studied by manrubia and zanette  @xcite in the context of multiplicative processes and a slightly different version was studied later by gelenbe  @xcite in the context of network theory .",
    "such ` restart ' strategy also plays an important role in randomized search algorithms for combinatorial optimization problems  @xcite .",
    "recently , a very simple model of a brownian searcher in presence of stochastic resetting to its initial position with rate @xmath0 was introduced by evans and majumdar  @xcite . in presence of a nonzero @xmath0",
    ", it was shown that at long times , the probability distribution of the position of the walker reaches a non - equilibrium steady state  @xcite .",
    "the temporal relaxation to this steady state was also studied recently  @xcite and an interesting dynamical phase transition was found : as time progresses , an inner core region around the resetting point reaches the steady state , while the region outside the core is still transient .",
    "the boundaries of the core region grow linearly with time at late times  @xcite .    in presence of resetting with rate @xmath0 , the mean first - passage time to find a target located at the origin , by a searcher starting and resetting to @xmath13 , was computed exactly  @xcite and was found to have a minimum at an optimal resetting rate @xmath14 , thus making the search process efficient in presence of resetting .",
    "this conclusion holds in all dimensions  @xcite .",
    "also , it was proved that this non - equilibrium reset dynamics is more efficient in target search compared to an equilibrium langevin dynamics in presence of an external potential leading to the same steady state  @xcite .",
    "this simple model of diffusion with stochastic resetting , in the single searcher setting , has been generalized in various ways .",
    "for example , when the target as well as the resetting positions are not fixed but drawn from specified probability distributions  @xcite , in presence of partial detection ( or absorption ) of the target by a searcher  @xcite , when the searcher performs a continuous - time random walk  @xcite or a lvy flight instead of a brownian motion / random walk  @xcite , when the searcher moves in a bounded domain  @xcite or in the presence of a confining potential  @xcite , when the resetting occurs to any of the previously visited sites with a rate proportional to the number of visits to the site  @xcite etc .",
    "recently the model of random walks with resetting has also been used to understand the behavior in models of enzymatic reactions in biology  @xcite .",
    "going beyond the one particle setting , the effect of the resetting mechanism in searching an immobile target has also been studied in presence of multiple , but non - interacting searchers  @xcite .",
    "more recently , the resetting has been studied in spatially extended many - body interacting systems , such as for fluctuating interfaces  @xcite as well as a class of reaction - diffusion models  @xcite  in both cases , the natural dynamics of the system is stochastically interrupted by resetting it to the initial configuration at a nonzero rate @xmath0 .",
    "a nonzero @xmath0 leads to new non - equilibrium stationary states in such extended systems  @xcite .    in this paper",
    ", we consider a model where the searcher remembers the maximum location visited so far and the long - range move consists in resetting to this current maximum .",
    "this strategy may be thought as the mixture of the systematic search and the random search . in the systematic search strategy since each location is visited only once , if a target in an already visited place is missed ( by an _ imperfect searcher _ ) , it is never going to be detected . in the new strategy discussed in this paper ,",
    "the searcher revisits already searched locations ( with certain probability ) , but also feels a dynamical bias towards exploring new locations ( by resetting to the maximum ) .",
    "this model may actually be useful in the context of animals searching for food . during the foraging period",
    ", it is well known that an animal typically performs a random walk in search of food  @xcite .",
    "it is however quite natural for an intelligent animal ( with memory ) to remember the already visited ( explored ) sites and thus to have a natural tendency to relocate once in a while to the frontier between already explored and yet unexplored territories , where the probability of finding food may be higher due to the proximity of the unexplored territory . in a one dimensional",
    "setting , the animal , besides short - range diffusion , may relocate with a nonzero probability to the current maximum or to the current minimum , which together constitute the frontier between explored and unexplored territories . in this paper , we consider an even more simplified _ directed _ version that has the advantage of being exactly solvable . in our model",
    "the animal starting at the origin , besides performing short - range standard random walk , relocates stochastically with a nonzero probability to only the positive side of the frontier , i.e. , the farthest visited site so far to the right of the origin ( i.e. , to the maximum ) .",
    "we will see that despite the fact that the position of the walker evolves via a non - markovian dynamics ( as it remembers the maximum position so far in order to relocate ) , the model allows for an exact solution and thus provides interesting insights into this long - range search strategy .",
    "the rest of the paper is organized as follows . in section  [ summary ]",
    "we introduce the model precisely and summarize our main exact results . in section",
    "[ generating function ] we derive the generating functions for the probabilities of the position and the maximum after @xmath5 time steps .",
    "we then examine in detail the asymptotic large @xmath5 statistics in the two opposite limits respectively in the next two sections : ( i ) the case without resetting but only with diffusion in section  [ r=0 case ] and ( ii ) the case where only resetting occurs without any diffusion in section  [ r->1 limit ] . in section  [ general resetting ]",
    "we analyze the situation for arbitrary resetting rate . in section",
    "[ scaling - limit ] , we analyze the statistics of the maximum and the position in the scaling limit @xmath10 , @xmath9 while keeping the product @xmath15 fixed .",
    "the crossover scaling functions are computed exactly in this section and compared to numerical simulation results .",
    "finally we conclude with a summary and some open questions in section  [ conclusion ] .",
    "we consider a walker moving on a one - dimensional lattice , initially starting from the origin . here",
    "each lattice site should be thought of as a ` region ' which is much larger than the ` size of the searcher ' , but much smaller than the whole region .",
    "the searcher spends some characteristic time @xmath16 in each region ( lattice site ) , and we consider time steps in units of @xmath16 and take it to be discrete .",
    "let @xmath17 denote the position of the walker at step @xmath5 and @xmath18 denote the current position of the maximum at step @xmath5 , i.e. @xmath19 .",
    "\\label{max_def}\\ ] ]    the position @xmath17 evolves with time via the following stochastic dynamics . at any given time step @xmath5 , if the position @xmath17 of the walker is less than the maximum position @xmath18 reached up to that time ( i.e , @xmath20 strictly ) , then in the next time step , the position is reset to the maximum position with probability @xmath0 . with the remaining probability @xmath1 ,",
    "the walker moves either to the right or to the left lattice site , with equal probability @xmath2 . on the other hand ,",
    "if @xmath21 , then in the next time step , the walker moves either to the right or to the left lattice site with equal probability @xmath22 .",
    "the dynamics is precisely defined by the following evolution rules  [ see fig .  [ lattice ]  ( a ) ] : + if @xmath20 @xmath23 and if @xmath21 , @xmath24 evidently , the evolution of @xmath17 is non - markovian by itself , since the walker has to remember the maximum position reached so far in order to reset .",
    "however , the dynamics of the pair of stochastic variables @xmath25 is markovian in the two dimensional @xmath26 plane , and this is the key point behind the solvability of the model .",
    "figure  [ lattice ] depicts the motion in the @xmath26 plane .",
    "it is useful to summarize our main results .",
    "our main objective is to compute the statistics of the two random variables @xmath17 and @xmath18 .",
    "let us first recall that in the absence of resetting ( @xmath3 ) , the walker performs a standard one dimensional random walk , for which @xmath17 , converges to a gaussian random variable with zero mean and variance @xmath5 , for large @xmath5 .",
    "hence , the probability distribution of the position converges , for large @xmath5 , to @xmath27 $ ] .",
    "similarly , for @xmath3 , the distribution of the maximum @xmath28 , for large @xmath5 , converges to a half - gaussian : @xmath29 $ ] with support only over @xmath30 .",
    "thus , for @xmath3 , both the position and the maximum typically grow diffusively as @xmath4 for large @xmath5 .    when the resetting to the maximum is switched on ( @xmath31 ) , the walker feels a dynamical bias towards the maximum .",
    "hence , one expects that both @xmath17 and @xmath18 will grow faster than pure diffusion for large @xmath5 .",
    "the question is how much faster ?",
    "we will see that for @xmath31 ( strictly ) , both @xmath18 and @xmath17 grow linearly with @xmath5 for large @xmath5 with the _ same _ speed .",
    "in addition , the variance of both @xmath18 and @xmath17 grow diffusively for large @xmath5 with the _ same _ diffusion coefficient .",
    "this suggests that for all @xmath31 , the position latches on to the maximum and indeed , we show that the difference variable @xmath32 approaches a stationary distribution as @xmath9 for all @xmath31 .",
    "our exact results are summarized below .",
    "+ * statistics of the maximum @xmath18 : * the average maximum , for large @xmath5 , behaves as @xmath33 where the speed @xmath7 is given by @xmath34 the speed vanishes as @xmath35 as @xmath10 .",
    "the variance of @xmath18 grows diffusively for large @xmath5 , @xmath36 where the diffusion coefficient ( the subscript @xmath37 in @xmath38 denotes the random variable @xmath37 ) is given by @xmath39 where @xmath8 , for @xmath31 , is given by @xmath40 ^ 3 } \\label{d(r ) } \\\\ & & \\times \\left[(2 - 2 r-5 r^2 + 3 r^3)+ ( 2-r - r^2 + 2    r^3 ) \\sqrt{r(2-r ) } \\right ] \\;.",
    "\\nonumber\\end{aligned}\\ ] ]    the behavior of @xmath7 and @xmath8 , vs. @xmath0 , are shown in fig .",
    "note that as @xmath10 , @xmath41 .",
    "thus , there is a discontinuity in the variance as @xmath10 .",
    "these results clearly indicate that @xmath3 is a _ singular / critical _ point .",
    "indeed , we find that near the critical point @xmath3 , there is a scaling regime .",
    "taking @xmath10 , @xmath9 , but keeping the product @xmath42 fixed , we find that the mean and the variance exhibit the following scaling behavior @xmath43 where the two scaling functions @xmath44 and @xmath45 have nontrivial expressions @xmath46\\ , , \\\\ \\label{fm } f_m(y)&= 1+\\frac{y}{2}-f_m^2(y)\\ , ,   \\end{aligned}\\ ] ] where @xmath47 , is the error function . the scaling function",
    "@xmath44 have the asymptotic behaviors : @xmath48 as @xmath49 , and @xmath50 as @xmath51 .",
    "consequently , @xmath52 as @xmath49 , and @xmath53 as @xmath54 .",
    "these two limiting behaviors of the scaling functions ( for the mean and the variance ) then smoothly interpolate between @xmath3 ( strictly ) and @xmath31 ( and @xmath9 ) .",
    "for any small but fixed @xmath0 , there is a crossover time @xmath55 , such that for @xmath56 , the mean and the variance grow with @xmath5 simply as a random walk ( @xmath3 ) : @xmath57 and @xmath58 .",
    "however , for @xmath59 , the walker starts sensing the presence of a finite resetting rate @xmath0 and crosses over to a new behavior where the mean maximum grows linearly with @xmath5 , @xmath60 and the variance grows diffusively , @xmath61 with the diffusion constant @xmath8 given in eq .",
    "( [ d(r ) ] ) .",
    "+     ( color online ) @xmath7 and @xmath8 as a function of @xmath0 ( in blue and red respectively ) .",
    "the dashed lines show their limiting values , @xmath62 and @xmath63 respectively , for @xmath64 . ]    * statistics of the position @xmath17 : * we find that the mean position behaves as @xmath65 where the speed @xmath7 , for @xmath31 , is the same as that of the maximum given in eq .",
    "( [ v(r ) ] ) .",
    "the variance of @xmath17 grows diffusively for large @xmath5 , @xmath66 with the diffusion coefficient ( the subscript @xmath67 denotes the random variable @xmath67 ) @xmath68 where the diffusion coefficient @xmath8 is the same as that of the maximum and is given in eq .",
    "( [ d(r ) ] ) . as in the case of the maximum ,",
    "the diffusion coefficient @xmath69 undergoes a discontinuous jump at the critical point @xmath3 .",
    "similar to @xmath18 , the behavior of the mean and the variance of @xmath17 exhibit a scaling behavior in the scaling regime @xmath10 , @xmath9 with the product @xmath42 fixed @xmath70 the scaling functions have the exact expressions @xmath71\\ , , \\\\",
    "\\label{fx } f_x(y)&= \\frac{y}{2}+\\frac{1-e^{-y}}{y}-f_x^2(y)\\ , .",
    "\\end{aligned}\\ ] ] the scaling function @xmath72 has the asymptotic behavior : @xmath73 as @xmath49 and @xmath74 as @xmath54 . as a result , @xmath75 as @xmath49 and @xmath76 as @xmath54 .",
    "these scaling functions then smoothly interpolate between the critical ( @xmath3 ) and off - critical ( @xmath31 ) growth of the mean and the variance . + * statistics of the difference @xmath77 : * we show that the probability @xmath78 that the position at the @xmath5-th step is at a distance @xmath79 away from the global maximum , has the large deviation form @xmath80 , \\label{q_y large}\\ ] ] where the large deviation function is given by @xmath81 & \\text{for~ $ w",
    "< w^*$},\\\\[5 mm ] \\displaystyle \\frac{w}{2}\\ln\\frac{1+w}{1-w } + \\ln    \\frac{\\sqrt{1-w^2}}{1-r }    & \\text{for~ $ w > w^*$ } , \\end{cases } \\label{h(w)}\\ ] ] with @xmath82 .",
    "this result shows that for a given @xmath5 , the probability @xmath83 becomes independent of @xmath5 for @xmath84 : @xmath85 , \\label{qyless}\\ ] ] while for @xmath86 , the distribution @xmath83 is still time - dependent . in other words ,",
    "the distribution of @xmath79 becomes stationary on a larger and larger length scale @xmath87 that grows linearly with time @xmath5 .",
    "moreover , the rate function @xmath88 is weakly non - analytic at @xmath89 : the second derivative @xmath90 is discontinuous at @xmath89 .",
    "this signals a _",
    "dynamical _ phase transition , similar to the one observed in the temporal evolution of the distribution of position of a brownian motion with resetting to its initial position  @xcite .",
    "in this section we outline the derivation of our results . we start with the dynamics of the two basic observables @xmath17 and @xmath18 given in eqs .",
    "( [ evolution.1 ] ) and ( [ evolution.2 ] ) . since , we have @xmath91 and @xmath92 , it is convenient to define the difference variable @xmath93 , where @xmath94 . in terms of @xmath79 , the dynamics in eqs .",
    "( [ evolution.1 ] ) and ( [ evolution.2 ] ) get translated into the equivalent forms [ see fig .  [ lattice ]  ( b ) ] : + if @xmath95 @xmath96 and if @xmath97 @xmath98    let @xmath99 and @xmath100 denote the joint probability distribution of @xmath101 and @xmath102 respectively , at the @xmath5-th time step . evidently , @xmath103 . using the dynamics in eqs .",
    "( [ yevol.1 ] ) and ( [ yevol.2 ] ) , it is easy to write down the master equation for @xmath100 as @xmath104 q(y-1,m , n-1 ) \\notag\\\\+ \\frac{1-r}{2 } q(y+1,m , n-1 ) , \\label{masteryp}\\end{aligned}\\ ] ] for @xmath105 , and @xmath106 with the initial condition @xmath107 , and the boundary conditions @xmath108 and @xmath109 .    to solve the set of linear equations ( [ masteryp ] ) and ( [ mastery0 ] ) , it is natural to define the generating function @xmath110 evidently , @xmath111 is the generating function for the probability distribution of the global maximum position and @xmath112 is the generating function for the probability distribution of the position .",
    "moreover , @xmath113 must be equal to @xmath114 as demanded by the normalization of the probability .",
    "after straightforward algebra , it follows that @xmath115 satisfies @xmath116 = \\notag\\\\ & 1 + \\left(rs-\\frac{1-r}{s}+z-2r\\right)\\frac{\\lambda}{2 } f(z,\\lambda ) + r \\lambda g(1,z,\\lambda ) , \\label{gsz}\\end{aligned}\\ ] ] where @xmath117 and @xmath118 the expression for @xmath111 can be obtained by setting @xmath119 in eq .",
    "( [ gsz ] ) as @xmath120 . \\label{g1z}\\ ] ] the normalization condition @xmath121 is immediately checked from above . substituting @xmath111 in eq .",
    "( [ gsz ] ) , after some algebra , we get @xmath122\\frac{\\lambda}{2}f(z,\\lambda ) \\right ) ,   \\label{gsz-2}\\end{aligned}\\ ] ] where @xmath123 and @xmath124.\\ ] ]    in eq .",
    "( [ gsz-2 ] ) , the function @xmath125 is still undetermined and has to be determined self - consistently . to proceed",
    ", we note from eq .",
    "( [ gsz-2 ] ) that @xmath115 has two poles at @xmath126 respectively .",
    "therefore , inverting with respect to @xmath127 , gives the form @xmath128 where @xmath129 and @xmath130 are the residues at the two poles .",
    "however , from eq .",
    "( [ s_pm ] ) , we notice that @xmath131 and @xmath132 .",
    "hence , the @xmath133 term in the above expression diverges when @xmath134 , which is inconsistent with the boundary condition @xmath108 .",
    "the only way to prevent this blow up is that @xmath130 must necessarily vanish , which implies that the right hand side of eq .",
    "( [ gsz-2 ] ) vanishes for @xmath135 .",
    "we note that this method of determining the self - consistency condition via the ` pole - cancelling ' mechanism was used before in other contexts  @xcite .",
    "this condition then determines @xmath125 as @xmath136 substituting @xmath125 in eq .",
    "( [ g1z ] ) , gives the generating function of the maximum as @xmath137 the normalization condition @xmath121 is immediately checked .",
    "it is easy to invert @xmath111 with respect to @xmath138 exactly , which gives @xmath139 where @xmath140 is the probability of having the maximum at @xmath37 in @xmath5 steps .    on the other hand , substituting @xmath125 in eq .",
    "( [ gsz-2 ] ) yields the full generating function as @xmath141 where we have used @xmath142 and @xmath143 ( 1-\\lambda ) ( 1-a)^{-1}.\\ ] ] using @xmath144 , it can be shown that @xmath145 .",
    "\\label{useful - relation}\\ ] ] therefore , the normalization condition @xmath121 is checked from the above expression . finally , it is useful to rewrite the above expression as @xmath146\\,\\frac{1}{z_0-z } ,   \\label{mainresult}\\ ] ] where we recall that eqs .  , and @xmath147,\\ ] ] using eq .",
    "( [ z1 ] ) in @xmath148 .",
    "the explicit expression of the generating function @xmath115 in eq .",
    "( [ mainresult ] ) is the central result of this paper and is valid for arbitrary @xmath149 .",
    "let us first check a few immediate consequences of this result in eq .",
    "( [ mainresult ] ) .",
    "one can easily invert eq .",
    "( [ mainresult ] ) with respect to @xmath127 and @xmath138 to give @xmath150 \\ , z_0^{-(m+1)}. \\label{q(y , m , n)}\\ ] ] now , using @xmath103 we get @xmath151 .",
    "\\label{pxm}\\ ] ]    from eq .",
    "( [ pxm ] ) , one can derive the marginal distribution of the position by summing over @xmath37 .",
    "note that for positive @xmath67 , the sum over @xmath37 goes from @xmath67 to @xmath152 .",
    "in contrast , for negative @xmath67 , the sum goes from zero to @xmath152 .",
    "this yields @xmath153 z_0^{-(x+1 ) } & \\text{for $ x \\ge 0$},\\\\[2 mm ] s_+^{(x+1 ) }   & \\text{for $ x < 0$}. \\end{cases } \\end{aligned}\\ ] ]    for completeness , we also compute the generating function with respect to both @xmath67 and @xmath5 , which gives @xmath154 setting @xmath119 above and using eq .",
    "( [ useful - relation ] ) , it is easy to verify the normalization condition @xmath155    as mentioned above , the expression eq .",
    "( [ mainresult ] ) for the full generating function @xmath115 , valid for arbitrary reset probability @xmath149 , is the main central result of our paper .",
    "several asymptotic results for the statistics of the two random variables @xmath37 and @xmath67 can then be derived by analyzing this expression in eq .",
    "( [ mainresult ] ) in different limits , which we present in the next few sections .",
    "let us first check the case without resetting , i.e. , we set @xmath3 .",
    "this is the standard one dimensional random walk and the results for the maximum and the position of the walker are well known .",
    "however , we reproduce it here as a check as well as for the sake of completeness .    for @xmath3 , @xmath156 , and @xmath157 putting @xmath158 , and taking @xmath159 limit , we have @xmath160 , @xmath161 and @xmath162 as @xmath163 keeping @xmath164 fixed .",
    "therefore , in this limit , from  eq .  ( [ p_m ] ) @xmath165 inverting the laplace transform gives , @xmath166 from this distribution , it is easy to compute all the moments for large @xmath5 .",
    "for instance , the mean and the variance of the maximum grow asymptotically as @xmath167 as stated respectively in eqs .",
    "( [ r0meanm ] ) and ( [ r0mdiff ] ) .    similarly , from eq .",
    "( [ p_x ] ) , we get , @xmath168 which , after laplace inversion , gives the expected gaussian distribution ( since a random walk , for large @xmath5 , converges to a brownian motion ) @xmath169 thus the mean and the variance of the position behave as @xmath170 as stated respectively in eqs .",
    "( [ r0meanx ] ) and ( [ r0diffcx ] ) .    for the joint distribution of the maximum and the position",
    ", we get from eq .",
    "( [ pxm ] ) @xmath171,\\ ] ] which , after laplace inversion , gives @xmath172 , \\label{p(x , m , n)}\\ ] ] where @xmath173 and @xmath30 .",
    "let us also verify eq .",
    "( [ pxn - gf ] ) using the exact result of the random walk @xmath174 and zero otherwise .",
    "therefore , @xmath175^n.\\notag\\ ] ] consequently , @xmath176^{-1}\\notag \\\\ & = \\frac{2s}{\\lambda } \\ , \\frac{1}{(s_+-s ) ( s - s_-)}\\ , , \\end{aligned}\\ ] ] which is same as eq .",
    "( [ pxn - gf ] ) for @xmath3 .",
    "thus , for the case @xmath3 , when there is no resetting to the maximum , we have recovered the results for the usual random walk .",
    "in the other extreme limit of @xmath64 , we have @xmath177 therefore , from eq .",
    "( [ p_m ] ) @xmath178^{m}. \\label{pmr1}\\ ] ] from the series expansion of the above expression with respect to @xmath179 , it is easily verified that @xmath180 .",
    "moreover , @xmath181,\\ ] ] is the probability that the walker has not crossed the origin up to the step @xmath5 .",
    "this is the case where the walker goes to the site @xmath182 ( with probability @xmath22 ) and comes back to the origin ( with probability one ) at alternate time steps . in general ( for @xmath64 ) , @xmath183^{m}.\\ ] ] for large @xmath37 and @xmath5 , with @xmath184 , the integral can be evaluated using saddle - point approximation , which to the leading order gives @xmath185,\\ ] ] where @xmath186 with @xmath187 .\\ ] ] the saddle point @xmath188 is obtained by solving the equation @xmath189 , as @xmath190 ^ 2= 2(1-w)/(1+w).$ ] substituting this in the above equation we obtain the large deviation function as @xmath191 this large deviation function has a maximum at @xmath192 , and near this , one gets @xmath193 , which implies the gaussian form @xmath194 in fact , eq .",
    "( [ pmr1 ] ) can be inverted exactly , which gives @xmath195",
    "\\displaystyle 2^{-\\frac{(n+m+1)}{2 } }   { \\frac{n+m-1}{2}\\choose m } & \\text{if $ ( n - m)$ is odd}. \\end{cases } \\label{p(m , n ) for r->1}\\ ] ] for large @xmath5 and @xmath37 , using the stirling s approximation in eq .",
    "( [ p(m , n ) for r->1 ] ) , one can recover the large deviation function given by eq .",
    "( [ s - ldfr1 ] ) .",
    "let us now look at the probability distribution of the position using eq .",
    "( [ p_x ] ) .",
    "for @xmath64 we have @xmath196 and @xmath197 with @xmath198 .",
    "therefore , from eq .",
    "( [ p_x ] ) , it is clear that for negative @xmath67 , we get nonzero probability only for @xmath182 , which reads @xmath199 inverting this with respect to @xmath179 gives @xmath200 this result can be understood , as this is the case where the walker goes to the site @xmath182 ( with probability @xmath22 ) at odd time steps and comes back to the origin ( with probability one ) at even time steps .",
    "the also implies that @xmath201 is nonzero only when the maximum remains zero . indeed from eq .",
    "( [ pxm ] ) , for @xmath64 we get @xmath202 . for @xmath203 , eq .",
    "( [ p_x ] ) we get @xmath204^{x}.\\ ] ] although the exact form differs from eq .",
    "( [ pmr1 ] ) , it is evident that @xmath205 and @xmath140 have the same large deviation function , i.e. , @xmath206,\\ ] ] with @xmath207 given by eq .",
    "( [ s - ldfr1 ] ) .",
    "for general resetting probability @xmath209 , it is a bit cumbersome to find the exact large deviation functions associated with the probabilities @xmath140 and @xmath205",
    ". however , one expects ( as in the cases of @xmath210 ) the typical fluctuations near the mean to be governed by gaussian distributions .",
    "the generating functions for the mean and the variance for the maximum and the current position are obtained from the generating functions of their distributions , given by eq .",
    "( [ gen - max ] ) and eq .",
    "( [ pxn - gf ] ) respectively , simply by taking derivatives . from their respective generating functions , we then derive , for arbitrary but fixed @xmath209 , the asymptotic behavior of the mean and variance for large @xmath5 for both the maximum and the position . finally , the asymptotic behavior of the the full probability distribution of the difference variable @xmath77 is derived .",
    "these derivations are outlined in the next three subsections .      from eq .",
    "( [ gen - max ] ) , we get the generating functions of the first two moments of the maximum as @xmath211 and @xmath212 ,   \\label{moment-2}\\end{aligned}\\ ] ] respectively . using the expression of @xmath148 from eq .",
    "( [ z1 ] ) , it is easy to check that @xmath213 where @xmath214 with @xmath215 .",
    "inverting eqs .",
    "( [ moment-1 ] ) and ( [ moment-2 ] ) with respect to @xmath179 using cauchy s formula , we get @xmath216 and @xmath217 \\label{m2_cauchy}\\ ] ] respectively , where the integral is along a counterclockwise closed contour around the origin in the complex @xmath179 plane .    a hint that @xmath3 is a special case and is different from the @xmath31 case",
    "can be already seen at this level . for @xmath3 , @xmath156 and from eq .",
    "( [ c(r , lambda ) ] ) one gets @xmath218^{-1}$ ] .",
    "therefore , for the @xmath3 case , the powers of @xmath219 in the denominators of the above expressions , reduce by one , and hence this case must be treated separately from the @xmath31 case . in the following",
    "we will only consider the case @xmath31 .",
    "evaluating the contour integrals in eqs .",
    "( [ m1_cauchy ] ) and ( [ m2_cauchy ] ) explicitly for all @xmath5 looks cumbersome .",
    "however , the asymptotic behavior for large @xmath5 can be derived by separating out the contributions to the contour integrals arising from the pole at @xmath220 .",
    "note that @xmath221 also has two branch points at @xmath222 .",
    "therefore , @xmath223 [ contributions from the integrals around the branch cuts from @xmath224 to @xmath225 and from @xmath226 to @xmath152 ] . using the residue theorem and computing the residue at @xmath220",
    "we get @xmath228 , \\intertext{and } \\label{<m^2 > } & \\frac{1}{2\\pi i}\\oint_0 \\frac{d\\lambda}{\\lambda^{n+1 } } \\frac{2      c^2(r,\\lambda)}{(1-\\lambda)^3 } =   ( n+1 ) ( n+2 ) c_0 ^ 2(r ) \\notag \\\\ & \\qquad\\qquad + 4 ( n+1 ) c_0(r ) c_1(r )   + 2 c_1 ^ 2(r ) + 2 c_0(r ) c_2(r ) \\notag\\\\ & \\qquad\\qquad\\qquad\\qquad + [ \\text{branch cuts contributions}],\\end{aligned}\\ ] ] where @xmath229 these coefficients can be calculated explicitly using eq .",
    "( [ c(r , lambda ) ] ) .",
    "for example , the first two coefficients are given explicitly as @xmath230}{\\sqrt{2r - r^2 } \\left(r-2r^2+\\sqrt{2r - r^2}\\right)^2}. \\label{c1r}\\end{aligned}\\ ] ] one can also show that the branch cuts contributions in eqs .",
    "( [ < m > ] ) and ( [ < m^2 > ] ) go to zero exponentially fast as @xmath231 .    using the results from eqs .",
    "( [ < m > ] ) and ( [ < m^2 > ] ) in eqs .",
    "( [ m1_cauchy ] ) and ( [ m2_cauchy ] ) , we then obtain , for large @xmath5 , the mean @xmath232 the speed @xmath7 , as a function of @xmath0 , is plotted in fig .",
    "[ v&d ] . similarly , the variance grows linearly for large @xmath5 @xmath233 using @xmath234 and @xmath235 from eqs .",
    "( [ c0r ] ) and ( [ c1r ] ) gives the explicit expression for the diffusion coefficient @xmath8 , for @xmath31 , as given by eq .",
    "( [ d(r ) ] ) . a plot of @xmath8 vs. @xmath0",
    "is provided in fig .",
    "[ v&d ] .      similarly , to compute the mean and variance of the position @xmath17 , we take derivatives with respect to @xmath127 in eq .",
    "( [ pxn - gf ] ) at @xmath119 to get @xmath236   \\label{m1x}\\ ] ] and @xmath237}{\\left(1-s_-\\right )    \\left(z_0 - 1\\right)^3 } \\notag\\\\ & \\qquad   + \\frac{1-r \\left(1-s_-\\right)^2 - 3 s_-}{\\left(1-s_-\\right)^2    \\left(z_0 - 1\\right)^2 } + \\frac{s_- \\left(1+s_-\\right)}{\\left(1-s_-\\right)^3 \\left(z_0 - 1\\right ) } \\biggr ] ,    \\label{m2x}\\end{aligned}\\ ] ] where we recall eqs .  , and .",
    "it is useful to define the following quantities @xmath238}{a(1-s_-)},\\\\ a_2(r,\\lambda)&= \\frac{2s_-}{a(1-s_-)^2},\\\\",
    "a_3(r,\\lambda)&=\\frac{2[1-r \\left(1-s_-\\right)^2 - 3      s_-]}{a\\left(1-s_-\\right)^2},\\\\ a_4(r,\\lambda)&=\\frac{2 s_- \\left(1+s_-\\right)}{a \\left(1-s_-\\right)^3}.\\end{aligned}\\ ] ] we note that @xmath239 and @xmath240 c(r,\\lambda)=1 $ ] . using these definitions and eq .",
    "( [ 1/(z0 - 1 ) ] ) , we invert the above generating function with respect to @xmath179 and get @xmath241 , \\\\    \\langle x^2(n )",
    "\\rangle & = \\frac{1}{2\\pi i}\\oint_0 \\frac{d\\lambda}{\\lambda^{n+1 } } \\biggl[\\frac{2 c^2(r,\\lambda)}{(1-\\lambda)^3 } + \\frac{a_3(r,\\lambda )      c^2(r,\\lambda)}{(1-\\lambda)^2 } \\notag\\\\ & \\qquad\\qquad\\qquad\\qquad\\qquad + \\frac{a_4(r,\\lambda )      c(r,\\lambda)}{(1-\\lambda ) } \\biggr].\\end{aligned}\\ ] ] finally , evaluating these integrals using residue theorem , we get @xmath242\\nonumber \\\\ & + 2 c_1 ^ 2(r ) + 2 c_0(r ) c_2(r )   + a_{3,1}(r ) c_0 ^ 2(r ) \\notag\\\\ & + 2 a_{3,0 } ( r ) c_0(r ) c_1(r )   + a_{4,0}(r ) c_0(r ) + \\dots , \\end{aligned}\\ ] ] where @xmath243 is defined by eq .  ( [ cn ] ) and @xmath244    finally , collecting the leading term for large @xmath5 , we obtain the following asymptotic results for the mean and the variance . for large @xmath5 , and for @xmath31 , the mean @xmath245 where the speed @xmath246 turns out to be exactly the same as in case of maximum , with explicit expression given in eq .",
    "( [ meanm1 ] ) .",
    "similarly , the variance behaves , asymptotically for large @xmath5 and for all @xmath31 , as @xmath247 hence , the first and the second moments of the two variables @xmath18 and @xmath17 grow identically for large @xmath5 .",
    "it is then natural to ask how the difference variable @xmath77 is distributed and we address this in the next subsection      let @xmath78 be the probability that the location at the @xmath5-th step is at a distance @xmath79 away from the global maximum . clearly , @xmath248 .",
    "therefore , from eq .",
    "( [ q(y , m , n ) ] ) we get @xmath249 \\ , \\frac{1}{z_0 - 1}. \\label{q_y - gen}\\ ] ]    let us first look at the value @xmath97 , for which eq .",
    "( [ q_y - gen ] ) reads @xmath250 where we have used eq .",
    "( [ 1/(z0 - 1 ) ] ) . to extract the large @xmath5 behavior of @xmath251",
    ", we need to investigate the right hand side of eq .",
    "( [ q_0-gen ] ) in the limit @xmath252 . as @xmath252 ,",
    "@xmath253 given in eq .",
    "( [ c0r ] ) .",
    "hence , the right hand side of eq .",
    "( [ q_0-gen ] ) behaves as @xmath254 as @xmath252 .",
    "this clearly indicates that @xmath251 becomes independent of @xmath5 in the limit @xmath255 , given by @xmath256    for @xmath105 , inverting the generating function eq .",
    "( [ q_y - gen ] ) we get @xmath257 now , using explicit expressions , and changing the integral over @xmath179 to that over @xmath258 , we get @xmath259\\notag\\\\ & \\times\\left(\\frac{a_0}{a}\\right)^{n+1 } \\left[\\frac{a}{1+\\sqrt{1-a^2}}\\right]^y,\\end{aligned}\\ ] ] where @xmath260 .",
    "the integrand has a simple pole at @xmath261 and branch points at @xmath262 .",
    "the contour of integration around zero can be split into two vertical contours : one that goes from @xmath263 to @xmath264 through the left of the origin and another that goes from @xmath264 to @xmath263 through the right of the origin .",
    "the left contour subsequently can be wrapped around the branch cut from @xmath265 to @xmath224 . the contribution from this contour is subdominant and",
    "the main contribution comes from the contour on the right for large @xmath5 .",
    "it is useful to express the integral as @xmath266 , \\label{q_y large.1}\\ ] ] so that for large @xmath5 we can use the saddle point approximation method .",
    "here @xmath267 , \\label{h(w , a)}\\ ] ] and @xmath268 the saddle point @xmath269 is obtained by solving the condition @xmath270 , which gives @xmath271 .",
    "note that the integrand of eq .",
    "( [ q_y large.1 ] ) has a simple pole at @xmath272 . for @xmath273",
    ", we have @xmath274 , and therefore , the contribution to the above integral comes from both the pole and the saddle point . however , the contribution from the pole is larger than that from the saddle point . therefore , for large @xmath5 , @xmath275,$ ] where the large deviation function is given by @xmath276 .",
    "\\label{pole form}\\ ] ] on the other hand , for @xmath277 , we have @xmath278 .",
    "therefore , evaluating the above integral using saddle - point approximation gives @xmath279 $ ] where the large deviation function is given by @xmath280 finally , combining these two regimes we obtain the large deviation behavior @xmath80 , \\label{q_y large.2}\\ ] ] with the rate function given by @xmath281 & \\text{for $ w < w^*$},\\\\[5 mm ] \\displaystyle h_2(w)=\\frac{w}{2}\\ln\\frac{1+w}{1-w } + \\ln    \\frac{\\sqrt{1-w^2}}{1-r }    & \\text{for $ w > w^*$ } , \\end{cases } \\label{h(w).1}\\ ] ] with @xmath82",
    ".    as discussed in section 2 , this result indicates that for a given large @xmath5 , @xmath83 becomes independent of @xmath5 for @xmath84 and is still @xmath5-dependent for @xmath282 , signalling a _ dynamical phase transition_. the rate function @xmath88 , plotted in fig .",
    "[ pdf ] , is weakly singular at the critical point @xmath89 where both @xmath88 and @xmath283 are continuous , but the second derivative @xmath90 is discontinuous : @xmath284 , while @xmath285 .",
    "such a second order dynamical phase transition was also observed recently in the time evolution of the distribution of position of a brownian motion in one dimension with resetting to its initial position  @xcite .",
    "we finish this subsection by making a couple of interesting observations . in the limit @xmath10 we have @xmath286 .",
    "therefore , the large deviation form is given by @xmath287 with @xmath3 .",
    "expanding in taylor series , for small @xmath288 we get @xmath289 , which gives the gaussian form @xmath290 $ ] .",
    "this is consistent with the result obtained by substituting @xmath291 in eq .",
    "( [ p(x , m , n ) ] ) and integrating over @xmath37 from @xmath292 to @xmath152 . on the other hand , in the limit @xmath64",
    ", we have @xmath293 .",
    "therefore , the large deviation form is given by @xmath294 with @xmath295 .",
    "we note that for @xmath295 , the large deviation function is @xmath224 , except for the case @xmath296 .",
    "this is because , @xmath79 can take only two values , namely , @xmath292 and @xmath297 , for the case @xmath295 . using the result of eq .",
    "( [ q_y(0 ) ] ) , we get @xmath298 . for @xmath299 ,",
    "( [ q_y - gen ] ) gives @xmath300 now , in the limit @xmath64 , we get @xmath301 and @xmath302 . using these , and inverting the above equation we get @xmath303 \\to \\frac{1}{3}\\quad\\mbox{as}~ n\\to\\infty.\\ ] ]    finally , following the method used in ref .",
    "@xcite in a different context , we can also write down a more complete asymptotic form of @xmath304 for large @xmath5 as    @xmath305 +   e^{-n h_1(w)}g_{-1 } \\left [   \\frac{{\\mathrm{sgn}({w^*-w})}}{2}\\ , { \\mathrm{erfc}}\\bigl(\\sqrt{n[h_2(w)-h_1(w)]}\\,\\bigr )   -\\theta(w^*-w ) \\right ] , \\label{pdf - asymptotic}\\end{aligned}\\ ] ]    where @xmath306 and @xmath307 this pre - asymptotic form is particularly useful to compare to the results of simulation . indeed , figure  [ pdf ] compares this form with the numerical simulation results .",
    "the agreement is excellent .",
    "( color online ) @xmath304 against the scaled variable @xmath308 for @xmath309 and @xmath310 . the ( blue ) points are obtained from numerical simulation .",
    "the solid ( red ) line represents the asymptotic form given by eq .",
    "( [ pdf - asymptotic ] ) . the dashed lines ( magenta and black ) plot the large deviation forms @xmath311 $ ] with the large deviation functions @xmath294 and @xmath287 given by eq .",
    "( [ pole form ] ) and eq .",
    "( [ saddle form ] ) respectively .",
    "the vertical dotted line marks the position of @xmath312 . ]",
    "from the results presented in section  [ r=0 case ] for @xmath3 and in section  [ general resetting ] for @xmath31 , we see that the limit @xmath10 ( after taking the large @xmath5 limit ) is not the same as @xmath3 , for the statistics of both the maximum and the position . in other words ,",
    "the two limits @xmath313 and @xmath314 do not commute .",
    "this indicates that @xmath3 is a singular or a ` critical ' point . for finite but large @xmath5",
    ", there should then be a smooth crossover function interpolating between these two limits . in this section ,",
    "these crossover scalings functions are derived analytically and compared to numerical simulations .",
    "we first consider the crossover scaling functions ( near @xmath10 ) associated with the mean and the variance of the maximum @xmath18 .",
    "let us first focus on the mean .",
    "our starting point is the exact generating function for the mean in eq .",
    "( [ moment-1 ] ) , where we recall that @xmath148 is given in eq .",
    "( [ z1 ] ) .",
    "we also remind the reader that @xmath315 since , we want to analyze the behavior of @xmath316 for large @xmath5 , and simultaneously @xmath10 , we need to set @xmath179 close to @xmath297 in eq .",
    "( [ moment-1 ] ) .",
    "we set , @xmath317 where @xmath318 is small . upon inspecting @xmath319 in eq .",
    "( [ defas _ ] ) , it follows that the right scaling limit is when @xmath159 , @xmath10 , keeping the ratio @xmath320 fixed . in the real space",
    ", this limit corresponds to @xmath10 , @xmath9 but keeping the product @xmath321 fixed . in this limit",
    ", the leading behavior of @xmath319 can be easily worked out to give @xmath322 substituting this leading behavior of @xmath319 in eq .",
    "( [ z1 ] ) , it follows that in the scaling limit @xmath323 we substitute this leading behavior of @xmath324 on the right hand side ( rhs ) of eq .",
    "( [ moment-1 ] ) and use @xmath317 . in the limit @xmath159 , the sum on the left hand side ( lhs ) of eq .",
    "( [ moment-1 ] ) can be approximated by an integral , yielding in the scaling limit @xmath325 by power counting on both sides of eq .",
    "( [ meanm_laplace ] ) , it follows that @xmath316 must have the following scaling behavior @xmath326 in the appropriate scaling limit @xmath10 , @xmath9 with the product @xmath321 fixed .    substituting this scaling behavior on the lhs of eq .",
    "( [ meanm_laplace ] ) , setting @xmath327 and making a change of variable @xmath328 , yields the following equation for the scaling function @xmath44 @xmath329 to invert the laplace transform on the rhs of eq .",
    "( [ fmy_laplace ] ) , we reexpress @xmath330 each term on the rhs of eq .",
    "( [ rational_break ] ) is an elementary function that can be easily inverted using convolution theorem .",
    "inverting , we then get an exact expression for the scaling function @xmath331\\ , , \\label{fmy.1}\\ ] ] where @xmath47 . the function @xmath44 has the following asymptotic behaviors @xmath332 \\displaystyle \\sqrt{\\frac{y}{2}}+ o\\left(\\frac{1}{\\sqrt{y}}\\right )   & \\text{as $ y\\to \\infty$. } \\end{cases } \\label{fmy_asymp}\\ ] ]    thus , when @xmath3 , using @xmath333 in eq .",
    "( [ meanm_scaling.2 ] ) yields the asymptotic behavior of the mean , @xmath334 .",
    "in contrast , when @xmath31 , as @xmath9 , the scaling argument @xmath335 . hence , using the other asymptotic behavior in eq .",
    "( [ fmy_asymp ] ) as @xmath51 , yields the linear growth @xmath336 .",
    "note that the speed @xmath7 in eq .",
    "( [ v(r ) ] ) indeed tends to @xmath337 as @xmath10 .",
    "the exact scaling function @xmath44 thus interpolates smoothly between these two limits . for any small but nonzero @xmath0",
    ", we thus expect that @xmath316 , as a function of @xmath5 , will initially grow as @xmath338 ( the critical behaviour at @xmath3 ) , before crossing over at a characteristic time @xmath339 to the off - critical linear growth , @xmath340 . in figure",
    "[ mean - max ] , we compare the numerical simulation results for small values of @xmath0 and show how they approach the analytical scaling function @xmath44 as @xmath10 .",
    "+     ( color online ) @xmath341 plotted vs. @xmath342 for different small values of @xmath0 .",
    "as @xmath10 , the curves approach the analytical scaling function @xmath44 in eq .",
    "( [ fmy.1 ] ) plotted as a solid line . ]",
    "next we consider the variance of the maximum , @xmath343 in the scaling limit @xmath10 , @xmath9 but keeping the product @xmath321 fixed .",
    "for this , we now need to analyze the second moment in eq .",
    "( [ moment-2 ] ) in the scaling limit .",
    "the analysis proceeds more or less as in the case of the mean .",
    "we do not repeat this computation here and just mention the final result . in the scaling limit @xmath10 , @xmath9 with the product @xmath42 fixed , we find that the variance behaves as @xmath344 with the scaling function @xmath45 given by @xmath345 where @xmath44 is given in eq .",
    "( [ fmy.1 ] ) .",
    "the scaling function has the following asymptotic behaviors @xmath346 \\displaystyle \\frac{1}{2 } & \\text{as $ y\\to \\infty$}. \\end{cases } \\label{fmy_asymp}\\ ] ]    hence , for @xmath3 , using @xmath347 in eq .",
    "( [ varm_scaling.2 ] ) gives the asymptotic behavior of the variance , @xmath348 , i.e. , the result for normal diffusion without resetting .",
    "in contrast , for @xmath31 , as @xmath9 , the scaling argument @xmath54 . hence , using @xmath53 as @xmath54 in eq .",
    "( [ varm_scaling.2 ] ) gives , @xmath349 .",
    "this agrees perfectly with the finite @xmath0 result , @xmath350 with @xmath8 given in eq .",
    "( [ d(r ) ] ) , since @xmath351 . the exact scaling function @xmath45",
    "thus interpolates smoothly between these two limits . in figure",
    "[ var - max ] , we compare the numerical simulation results with the analytical scaling function @xmath45 in eq .",
    "( [ fmy.1 ] ) .",
    "+     ( color online ) @xmath352 plotted vs. @xmath342 for different small values of @xmath0 .",
    "as @xmath10 , the curves approach the analytical scaling function @xmath45 in eq .",
    "( [ fmy.1 ] ) plotted as a solid line . ]",
    "we now turn to the scaling behavior of the mean and the variance of the position @xmath17 .",
    "we start with the mean whose exact generating function is given in eq .",
    "( [ m1x ] ) . to analyze the scaling limit @xmath10 , @xmath9 while keeping the product @xmath342 fixed",
    ", we follow the same procedure as in the case of the maximum . setting @xmath317 with @xmath159 , and using eq .",
    "( [ z0scaling ] ) , we find that eq .",
    "( [ m1x ] ) reduces , in the scaling limit , to the following integral @xmath353 it then indicates the following scaling behavior for the mean position @xmath354 where @xmath72 , using eq .",
    "( [ meanx_laplace ] ) , satisfies @xmath355 one can again easily invert the laplace transform in eq .",
    "( [ fxy_laplace ] ) to get @xmath356\\ , .",
    "\\label{fxy.1}\\ ] ] it has the asymptotics @xmath357 \\displaystyle \\sqrt{\\frac{y}{2}}+o\\left(\\frac{1}{\\sqrt{y}}\\right ) & \\text{as $ y\\to    \\infty$}. \\end{cases } \\label{fxy_asymp}\\ ] ]    when @xmath3 , using @xmath358 , one recovers the standard random walk ( without resetting ) result , @xmath359 .",
    "in contrast , for @xmath31 , when @xmath9 , i.e. , the product @xmath360 , using the large @xmath79 asymptotic behavior in eq .",
    "( [ fxy_asymp ] ) , one gets , @xmath361 , compatible with the linear growth with speed @xmath7 in eq .",
    "( [ rpmeanx ] ) upon noting that @xmath362 .",
    "the scaling function @xmath72 interpolates between these two limits .",
    "figure  [ mean - pos ] demonstrates how simulation results converge to the analytical scaling function @xmath72 in eq .",
    "( [ fxy.1 ] ) as @xmath10 . +     ( color online ) @xmath363 plotted vs. @xmath342 for different small values of @xmath0 . as @xmath10 ,",
    "the curves approach the analytical scaling function @xmath72 in eq .",
    "( [ fxy.1 ] ) plotted as a solid line . ]",
    "we next consider the scaling behavior of the variance of the position , @xmath364 , in the scaling limit @xmath10 , @xmath9 with the product @xmath342 fixed . here",
    "we analyze the generating function for the second moment in eq .",
    "( [ m2x ] ) in the scaling limit . since the procedure is identical as in the case of the maximum , we skip the details and present only the result .",
    "we find that in the scaling limit , the variance of the position behaves as @xmath365 with the scaling function @xmath366 given by @xmath367 where @xmath72 is given in eq .",
    "( [ fxy.1 ] ) . the scaling function @xmath366 has the following asymptotic behaviors @xmath368 using these asymptotic behaviors , it is again easy to check that @xmath366 smoothly interpolates between the critical @xmath11 and the off - critical @xmath369 behavior of the variance of the position , for finite but large @xmath5 . in figure  [ var - pos ] , we compare the numerical simulation results with the analytical scaling function @xmath366 in eq .",
    "( [ fxy.1 ] ) .",
    "+     ( color online ) @xmath370 plotted vs. @xmath342 for different small values of @xmath0 .",
    "as @xmath10 , the curves approach the analytical scaling function @xmath366 in eq .",
    "( [ fxy.1 ] ) plotted as a solid line . ]",
    "in conclusion , we have considered a model of random walk in one dimension where the walker , at each time step , resets to the maximum of the already visited positions with a certain probability @xmath0 . for @xmath3 , it reduces to the standard random walk in one dimension .",
    "the presence of a nonzero resetting probability @xmath0 changes drastically the asymptotic behavior of the walker .",
    "we find that on average , both the position and the maximum move with the same speed , and we have obtained an exact expression for this speed @xmath7 .",
    "the fluctuations about the mean is again described by the same diffusion coefficient @xmath8 for both .",
    "we also obtain the large deviation form of the probabilities of finding the walker at a distance @xmath79 away from the maximum .",
    "the associated large deviation function shows a second order phase transition",
    ".    an interesting extension would be to study the walk which resets either to the maximum or the minimum with an equal probability @xmath371 .",
    "in general , one could ask the question in higher dimension , where the walker resets to one of the boundary sites of the already visited sites . yet another extension , beyond the study of the fluctuations of the position and the maximum studied here , concerns the study of the search process with resetting to the maximum . for instance",
    ", it would be interesting to compute the mean first - passage time to an immobile or a moving target for a such a random walker submitted to random resetting to the maximum .",
    "the authors acknowledge the support of the indo - french centre for the promotion of advanced research ( ifcpar / cefipra ) under project 4604 - 3 .",
    "s.  n.  m acknowledges useful discussions with p. sen and her hospitality at the physics department of calcutta university , where part of this work was done during a visit in july , 2015 .",
    "m. g. e. d. luz , a. grosberg , e. p. raposo , and g. m. viswanathan ( _ editors _ ) , _ special issue _ : the random search problem : trends and perspectives , j. phys . a : math . and theor .",
    "42 , 430301 - 434017 ( 2009 ) ."
  ],
  "abstract_text": [
    "<S> we study analytically a simple random walk model on a one - dimensional lattice , where at each time step the walker resets to the maximum of the already visited positions ( to the rightmost visited site ) with a probability @xmath0 , and with probability @xmath1 , it undergoes symmetric random walk , i.e. , it hops to one of its neighboring sites , with equal probability @xmath2 . for @xmath3 , it reduces to a standard random walk whose typical distance grows as @xmath4 for large @xmath5 . in presence of a nonzero resetting rate @xmath6 </S>",
    "<S> , we find that both the average maximum and the average position grow ballistically for large @xmath5 , with a common speed @xmath7 . </S>",
    "<S> moreover , the fluctuations around their respective averages grow diffusively , again with the same diffusion coefficient @xmath8 . </S>",
    "<S> we compute @xmath7 and @xmath8 explicitly . </S>",
    "<S> we also show that the probability distribution of the difference between the maximum and the location of the walker , becomes stationary as @xmath9 . however , the approach to this stationary distribution is accompanied by a dynamical phase transition , characterized by a weakly singular large deviation function . </S>",
    "<S> we also show that @xmath3 is a special ` critical ' point , for which the growth laws are different from the @xmath10 case and we calculate the exact crossover functions that interpolate between the critical @xmath11 and the off - critical @xmath12 behavior for finite but large @xmath5 .    </S>",
    "<S> = 1 </S>"
  ]
}