{
  "article_text": [
    "we consider the two - sample problem for general poisson processes .",
    "let @xmath4 and @xmath5 be two independent poisson processes observed on a measurable space @xmath6 , whose intensities with respect to some non - atomic positive @xmath7-finite measure @xmath8 on @xmath6 are denoted by @xmath9 and @xmath10 .",
    "given the observation of @xmath4 and @xmath5 , we address the question of testing the null hypothesis",
    "@xmath11 `` @xmath12 '' versus the alternative @xmath13 `` @xmath14 '' .",
    "many papers deal with the two - sample problem for homogeneous poisson processes such as , among others , the historical ones of @xcite , @xcite , @xcite , or @xcite , whose applications were mainly turned to biology and medicine , and less frequently to reliability .",
    "more recent papers like @xcite , @xcite , @xcite , and @xcite give interesting numerical comparisons of various testing procedures . as for non - homogeneous poisson processes , though a lot of references on the problem of testing proportionality of the hazard rates of the processes exist ( see @xcite for instance and the references therein ) , very few papers are devoted to a comparison of the intensities themselves .",
    "bovett and saw @xcite and deshpande et al .",
    "@xcite respectively proposed conditional and unconditional procedures to test the null hypothesis `` @xmath15 is constant '' versus `` it is increasing '' .",
    "deshpande et al .",
    "@xcite considered their test from a usual asymptotic point of view , proving that it is consistent against several large classes of alternatives .",
    "we propose in this paper to construct testing procedures of @xmath11 versus @xmath13 without any parametric or monotony assumption on @xmath9 or @xmath10 and which satisfy specific non - asymptotic performance properties .    in particular",
    ", for every @xmath2 in @xmath16 $ ] , these tests are of level @xmath2 , that is they have a probability of first kind error at most equal to @xmath2 .",
    "for special values of @xmath2 , they are even of size @xmath2 , that is their probability of first kind error is exactly equal to @xmath2 , since they involve very sharp critical values obtained via a non - asymptotic wild bootstrap approach . in the classical two - sample problem for i.i.d .",
    "samples , the choice of the critical values in testing procedures is a well - known crucial question .",
    "indeed , the asymptotic distributions of many test statistics are not free from the common unknown density under the null hypothesis . in such cases ,",
    "some bootstrap methods are often used to build data - driven critical values . by bootstrap methods ,",
    "we mean the original ones introduced by efron @xcite of course , but also more general weighted bootstrap approaches such as the precursor fisher s @xcite permutation , the @xmath17 out of @xmath18 bootstrap introduced by bretagnolle @xcite , the general exchangeably weighted bootstrap studied in @xcite and including the bayesian bootstrap of rubin @xcite for instance , as well as the wild bootstrap detailed in @xcite . except in the cases where the permutation approach is used",
    ", authors generally prove that the obtained tests are ( only ) asymptotically of level @xmath2 ( see among many other papers @xcite , @xcite , @xcite , and more recently @xcite for a complete and very interesting discussion ) . in this work",
    ", we adopt one of these general weighted bootstrap approaches , but from a non - asymptotic point of view .",
    "the critical values of our tests are constructed from wild bootstrapped @xmath1-statistics , which are based on rademacher variables .",
    "the use of rademacher variables is well - known in the bootstrap community since the work of mammen @xcite , but also particularly in the statistical learning community since the works of koltchinskii @xcite and bartlett et al .",
    "@xcite , followed by @xcite .",
    "it was notably proposed for the construction of general confidence bands in a recent paper by lounici and nickl @xcite .",
    "the main particularity of our study , as compared with previous ones , is that we prove here that , under @xmath11 , given the data , the considered wild bootstrapped @xmath1-statistics exactly have the same distributions as our test statistics .",
    "the corresponding tests are consequently of level @xmath2 for every @xmath2 in @xmath16 $ ] , and even of size @xmath2 for particular values of @xmath2 .",
    "note that as in @xcite or in @xcite , it is also possible to randomize these tests in order to turn them into size @xmath2 tests for every @xmath2 . in this sense , our bootstrap method can be viewed as an adapted version of the permutation bootstrap method in a poisson framework . as usual",
    "even when permutation methods are considered , the wild bootstrapped critical values of our tests are not computed exactly in practice , but just approximated through a monte carlo method .",
    "we also address this question from a non - asymptotic point of view , since we also focus on controlling the loss due to the monte carlo approximation .",
    "our test statistics are based on a single kernel function which can be chosen either as a projection kernel , or as an approximation kernel , or as a reproducing kernel .",
    "a non - asymptotic study of the second kind error of our tests is also performed .",
    "given any @xmath19 in @xmath16 $ ] , depending on the chosen kernel , we obtain non - asymptotic conditions which guarantee that the probability of second kind error is at most equal to @xmath19 .",
    "this can be done via a sharp control of the wild bootstrapped critical values under the alternative , which results from concentration inequalities for rademacher chaoses @xcite .    in order to deduce from these conditions recognizable asymptotic rates of testing",
    ", we assume that the measure @xmath8 on @xmath6 satisfies @xmath20 , where @xmath18 can be seen as a growing number whereas the measure @xmath21 is held fixed . typically , @xmath18 may be an integer and the above assumption amounts to considering the poisson processes @xmath4 and @xmath5 as @xmath18 pooled i.i.d .",
    "poisson processes with respective intensities @xmath9 and @xmath10 w.r.t .",
    "@xmath22 . the reader may also assume for sake of simplicity that @xmath6 is a measurable subset of @xmath23 and that @xmath22 is the lebesgue measure , but it is not required : @xmath22 may be any non - atomic positive @xmath7-finite measure on any measurable set @xmath6 . with this normalization ,",
    "when a reproducing kernel is considered , we obtain a parametric rate of testing for a weak metric defined in the associated rkhs , in the spirit of @xcite or @xcite for more classical weak metrics in i.i.d .",
    "samples frameworks .",
    "our results complete those of gretton et al .",
    "@xcite , who introduced reproducing kernels in the two - sample problem for i.i.d . samples .",
    "when a projection or an approximation kernel is considered , we obtain the following condition : the probability of second kind error of the test is at most equal to @xmath19 as soon as the @xmath3-distance w.r.t .",
    "@xmath22 between @xmath9 and @xmath10 is larger than a bound , which reproduces a bias - variance decomposition .",
    "this bound can be proved to be optimal with an appropriate choice of the vectorial space defining the projection kernel , or of the bandwidth defining the approximation kernel , choice which highly depends on the alternative .    in order to provide an adaptive test with respect to this choice",
    ", we propose to aggregate several of the previous single kernel - based tests , making sure that the resulting multiple test is still of level @xmath2 .",
    "we establish oracle type conditions , which guarantee that the probability of second kind error is at most equal to @xmath19 .",
    "this aggregation approach , inspired by adaptive estimation methods such as model selection , thresholding or approximation kernels methods , was used in many papers devoted to adaptive testing in various classical one - sample frameworks ( see @xcite or @xcite for adaptive tests related to thresholding methods , @xcite for adaptive tests related to model selection methods , @xcite for adaptive tests related to approximation kernels methods , or @xcite for adaptive tests related to both model selection and thresholding methods for instance ) . in a poisson process framework , we proposed in @xcite an aggregated test of homogeneity also based on both model selection and thresholding approaches . in the two - sample problem for i.i.d .",
    "samples , which is closely related to the present problem , butucea and tribouley @xcite propose an adaptive test based on a thresholding approach .",
    "we complete the study by proving that our aggregated tests are also adaptive in a non - asymptotic minimax sense over various classes @xmath24 of alternatives @xmath25 for which @xmath26 is smooth with parameter @xmath27 . for clarity s sake , let us here recall a few definitions .",
    "for any level @xmath2 test @xmath28 , with values in @xmath29 ( rejecting @xmath11 when @xmath30 ) , one defines its uniform separation rate @xmath31 over @xmath32 as @xmath33 where @xmath34 , and @xmath35 denotes the joint distribution of @xmath36 . a level @xmath2 test @xmath28 is said to be minimax over a particular class @xmath32 if its uniform separation rate achieves its best possible value over @xmath32 , which is called the minimax separation rate over @xmath32 ( see @xcite ) up to a multiplicative factor .",
    "it is said to be minimax adaptive if its uniform separation rates achieve ( up to a possible unavoidable small loss ) the minimax separation rates over several classes @xmath32 simultaneously .",
    "a great number of papers deal with the computation of the minimax separation rates over various classes of alternatives , or more precisely with the computation of their asymptotic equivalents , that are the minimax rates of testing defined in the key series of papers due to ingster @xcite .",
    "the question of the minimax adaptivity has also been widely studied since the work of spokoiny @xcite , who first brought out a context where minimax adaptive testing without a small loss of efficiency is impossible . for the problem of testing the goodness - of - fit of a poisson process , ingster and kutoyants",
    "@xcite derived the minimax rate of testing over a sobolev or a besov ball . for the problem of testing the homogeneity of a poisson process , we derived in @xcite similar minimax results considering classical besov bodies , and we moreover obtained new minimax adaptivity results considering weak besov bodies .    in the present two - sample problem for poisson processes ,",
    "no previous minimax result is available to our knowledge . as in @xcite , we here prove that the aggregation of single projection kernel - based tests lead to minimax adaptive tests over some classes of alternatives for which @xmath26 belongs to a besov or a weak besov body .",
    "such a result can be linked to the minimax results obtained by butucea and tribouley @xcite , noting however that the classes of alternatives they consider impose both @xmath9 and @xmath10 to belong to a besov space , which is more restrictive than only imposing some regularity assumptions on @xmath26 .",
    "then , when considering the aggregation of single approximation kernel - based tests , we obtain upper bounds for the uniform separation rates over some classes of alternatives based on multivariate sobolev or anisotropic nikolskii - besov balls .",
    "these upper bounds , which are conjectured to be optimal from results of horowitz and spokoiny @xcite or ingster and stepanova @xcite in other frameworks , are completely new in our poisson setting , and even in a general setting for anisotropic nikolskii - besov balls .",
    "the paper is organized as follows . in section [ single ] , we introduce our single kernel - based tests . as explained above , the corresponding critical values are constructed from a wild bootstrap approach , leading to level @xmath2 single tests .",
    "we then give conditions ensuring that these single tests also have a probability of second kind error at most equal to @xmath19 , and we study the cost due to the monte carlo approximation of the wild bootstrapped critical values . in section [ multiple ] , we construct level @xmath2 multiple tests by aggregating several of the single tests introduced in section [ single ] .",
    "oracle type conditions are obtained , ensuring that these multiple tests have a probability of second kind error at most equal to @xmath19 . from these conditions , some of our tests",
    "are also proved to be minimax adaptive over various classes of alternatives based on classical and weak besov bodies in the univariate case , or sobolev and anistropic nikolskii - besov balls in the multivariate case . the major proofs",
    "are given in section [ preuves ] , whereas a simulation study and the other proofs can be found in supplementary materials .",
    "let us now introduce some notations that will be used all along the paper .",
    "for any measurable function @xmath37 , let when they exist : @xmath38 , and @xmath39 .",
    "recalling that @xmath40 , we introduce the scalar product @xmath41 associated with @xmath42 .",
    "we denote by @xmath43 and @xmath44 the point measures associated with @xmath4 and @xmath5 respectively , and to suit for the notation @xmath35 of the joint distribution of @xmath36 , @xmath45 stands for the corresponding expectation .",
    "we set for any event @xmath46 based on @xmath36 , @xmath47 .",
    "furthermore , we will introduce some constants , that we do not intend to evaluate here , and that are denoted by @xmath48 meaning that they may depend on @xmath2 , @xmath19 , @xmath49 . though they are denoted in the same way , they may vary from one line to another .    finally , let us make the two following assumptions , which together imply that @xmath9 and @xmath10 belong to @xmath50 , and which will be satisfied all along the paper , except when specified .",
    "[ hypo1 ] @xmath51 and @xmath52 .",
    "[ hypo2 ] @xmath53 and @xmath54 .",
    "since @xmath9 and @xmath10 are assumed to satisfy assumptions [ hypo1 ] and [ hypo2 ] , they are also assumed to belong to @xmath50 .",
    "hence , testing @xmath11 `` @xmath12 '' versus @xmath13 `` @xmath14 '' here amounts to testing that `` @xmath55 '' versus `` @xmath56 '' . considering a well - chosen finite dimensional subspace @xmath57 of @xmath50 ,",
    "if @xmath58 denotes the orthogonal projection onto @xmath57 for @xmath41 , any estimator of an increasing function of @xmath59 may thus be a relevant candidate to be a test statistic .",
    "let @xmath60 be an orthonormal basis of @xmath57 for @xmath41 , and let @xmath61 where @xmath62 is the pooled poisson process whose point measure is given by @xmath63 . since @xmath64=\\left(\\int { \\ensuremath{\\varphi}}_{\\ensuremath{\\lambda}}(x ) f(x ) d\\mu_x\\right)^2+\\int { \\ensuremath{\\varphi}}_{\\ensuremath{\\lambda}}^2(x )",
    "f(x ) d\\mu_x$ ] , and similarly for @xmath65 $ ] , recalling that @xmath66 , it is easy to see that @xmath67 is an unbiased estimator of @xmath68 , and thus also a possible test statistic , whose large values lead to reject @xmath11 .",
    "let @xmath69 be the marks of the points from the pooled process @xmath62 , defined by @xmath70 if the point @xmath71 of @xmath62 belongs to @xmath4 and @xmath72 if the point @xmath71 of @xmath62 belongs to @xmath5 .",
    "then @xmath73 can also be expressed as @xmath74 starting from this remark , we can thus generalize the test statistic @xmath67 by replacing in its expression the function : @xmath75 by a general kernel function .",
    "so , let @xmath76 be any symmetric kernel function : @xmath77 satisfying :    [ hypo3 ] @xmath78    denoting by @xmath79}$ ] the set @xmath80 , we introduce the statistic @xmath81 } } k(x , x'){\\ensuremath{\\varepsilon}}_x^0{\\ensuremath{\\varepsilon}}_{x'}^0dn_xdn_{x'}.\\ ] ]    since for every @xmath71 in @xmath62 , @xmath82=(f(x)-g(x))/(f(x)+g(x))$ ] ( see proposition [ marques ] below for instance ) , @xmath83&=&{\\ensuremath{\\mathbb{e}}}_{f , g}\\left[{\\ensuremath{\\mathbb{e}}}\\left[\\int_{{\\ensuremath{\\mathbb{x}}}^{[2 ] } } k(x , x'){\\ensuremath{\\varepsilon}}_x^0{\\ensuremath{\\varepsilon}}_{x'}^0dn_xdn_{x'}\\big|n\\right]\\right]\\\\ & = & { \\ensuremath{\\mathbb{e}}}_{f , g}\\left[\\int_{{\\ensuremath{\\mathbb{x}}}^{[2]}}k(x , x')\\frac{f(x)-g(x)}{f(x)+g(x)}\\frac{f(x')-g(x')}{f(x')+g(x')}dn_xdn_{x'}\\right]\\\\ & = & \\int_{{\\ensuremath{\\mathbb{x}}}^{2}}k(x , x')(f - g)(x)(f - g)(x')d\\mu_xd\\mu_{x'}\\\\ & = & n^2 \\int_{{\\ensuremath{\\mathbb{x}}}^{2}}k(x , x')(f - g)(x)(f - g)(x')d\\nu_xd\\nu_{x'}.\\end{aligned}\\ ] ] in the following , we use the notation : @xmath84}(x')=\\int_{{\\ensuremath{\\mathbb{x}}}}k(x , x')p(x)d\\nu_x.\\ ] ] with this notation , @xmath85 is then an unbiased estimator of @xmath86},f - g\\rangle,\\ ] ] whose existence is ensured thanks to assumptions [ hypo1 ] and [ hypo3 ] .    we have chosen to consider and study in this paper three possible examples of kernel functions . for each example",
    ", we give a simpler expression of @xmath87 , which allows to justify the choice of @xmath85 as test statistic .",
    "_ [ projection kernel case ] _ our first choice for @xmath76 is a symmetric kernel function based on an orthonormal family @xmath88 for @xmath41 : @xmath89 when the cardinality of @xmath90 is finite , @xmath91 corresponds to the above natural test statistic @xmath92 . when the cardinality of @xmath90 is infinite , we assume that @xmath93 which ensures that @xmath94 is defined for all @xmath95 in @xmath6 and that assumption  [ hypo3 ] holds . typically , if @xmath96 and if the functions @xmath88 correspond to indicator functions with disjoint supports , this condition will be satisfied .",
    "we check in these cases that for every @xmath97 in @xmath98 , @xmath99}=\\pi_s(s),$ ] where @xmath57 is the subspace of @xmath98 generated by @xmath88 , and @xmath58 denotes as above the orthogonal projection onto @xmath57 for @xmath41 .",
    "this justifies that such a kernel function @xmath76 is called a projection kernel and that @xmath100    _ [ approximation kernel case ] _",
    "when @xmath96 and @xmath22 is the lebesgue measure , our second choice for @xmath76 is a kernel function based on an approximation kernel @xmath101 in @xmath102 , and such that @xmath103 : for @xmath104 , @xmath105 in @xmath6 , @xmath106 where @xmath107 is a vector of @xmath108 positive bandwidths .",
    "note that the assumption that @xmath109 together with assumption [ hypo2 ] ensure that assumption [ hypo3 ] holds .",
    "then , in this case , @xmath110 where @xmath111 and @xmath112 is the usual convolution operator with respect to the measure @xmath22 .    _",
    "[ reproducing kernel case ] _ our third choice for @xmath76 is a general reproducing kernel ( see @xcite for instance ) such that @xmath113 where @xmath114 and @xmath115 are a representation function and a rkhs associated with @xmath76 .",
    "here , @xmath116 denotes the scalar product of @xmath115 .",
    "we also choose @xmath76 such that it satisfies assumption [ hypo3 ] .",
    "this choice leads to a test statistic close to the one of gretton et al .",
    "@xcite for the classical two - sample problem for i.i.d .",
    "samples of equal sizes .",
    "we will however see that the corresponding critical value is not constructed here in the same way as in @xcite . while gretton et al .",
    "derive their critical value from either concentration inequalities , or asymptotic arguments , or an asymptotic efron s bootstrap approach , we construct our critical value from a non - asymptotic wild bootstrap approach .    in this case",
    ", it is easy to see that @xmath117 where @xmath118 and @xmath119 .",
    "note that in a `` density '' context where @xmath120 , @xmath87 is @xmath121 times the so - called squared maximum mean discrepancy on the unit ball in the rkhs @xmath115 ( see @xcite ) between the distributions @xmath122 and @xmath123 , and that the functions @xmath124 and @xmath125 are known ( see @xcite for instance ) as the mean embeddings in @xmath115 of the distributions @xmath122 and @xmath123 respectively .",
    "moreover , in this context , assuming that the kernel @xmath76 is characteristic ( see also @xcite ) , the map which assigns its mean embedding in @xmath115 to any probability distribution is injective by definition , so",
    "@xmath126 if and only if @xmath12 .    we want to mention here that the introduction of reproducing kernels is particularly pertinent if the space @xmath6 is unusual or pretty large with respect to the ( mean ) number of observations and/or if the measure @xmath22 is not well specified or not easy to deal with . in such situations , the use of reproducing kernels may be the only possible way to compute a meaningful test ( see @xcite where such kernels are used for microarrays data and graphs ) .",
    "thus , for each of the three above choices for @xmath76 , considering a test which rejects @xmath11 when @xmath85 is `` large enough '' seems to be reasonable . it remains to explain what we mean by `` large enough '' , that is to define the critical values used in our tests .",
    "the critical values we use here are based on a non - asymptotic wild bootstrap approach , that we present and justify in this section . to do this , we start from the remark that under @xmath11 , the test statistic @xmath85 is a degenerate @xmath1-statistic of order @xmath127 , for which adequate bootstrap methods were developed in particular in @xcite and @xcite .",
    "bretagnolle @xcite first noticed that a naive application of efron s original bootstrap fails for degenerate @xmath1-statistics , since it leads the bootstrapped statistic to lose the degeneracy property .",
    "he therefore introduced the more appropriate @xmath17 of @xmath18 bootstrap , while arcones and gin  @xcite preferred to keep on using efron s original bootstrap , but by forcing the bootstrapped statistic to satisfy the degeneracy property through a centering trick .",
    "the results of arcones and gin were then generalized to other kinds of bootstrap methods , and in particular bayesian and wild bootstrapped @xmath1-statistics were introduced in @xcite , @xcite and @xcite .",
    "following @xcite , we introduce a sequence @xmath128 of i.i.d .",
    "rademacher variables independent of @xmath62 . denoting by @xmath129 the size of the pooled process @xmath62 , and by @xmath130 the points of @xmath62 ,",
    "a wild bootstrapped version of @xmath85 may be expressed as @xmath131 we consider in fact the simpler version @xmath132 that can be proved to have , under @xmath11 , conditionally on @xmath62 , the same distribution as the above wild bootstrapped version of @xmath85 .",
    "we now choose the quantile of the conditional distribution of @xmath133 given @xmath62 as critical value for our test .",
    "more precisely , for @xmath2 in @xmath134 , if @xmath135 denotes the @xmath136 quantile of the distribution of @xmath133 conditionally on @xmath62 , we consider the test that rejects @xmath11 when @xmath137 .",
    "the corresponding test function is defined by @xmath138 note that in practice , the true conditional quantile @xmath135 is not exactly computed , but in fact just approximated by a classical monte carlo method .",
    "of course , such bootstrap tests are not completely new in the statistical scene . however , the main particularities of our work is that we justify our test from a non - asymptotic point of view .",
    "we actually prove that under @xmath11 , conditionally on @xmath62 , @xmath91 and @xmath139 exactly have the same distribution . as a consequence",
    "the test defined by @xmath140 is of level @xmath2 , that is it has a probability of first kind error at most equal to @xmath2 .",
    "we will briefly see in the next section that it may even be randomized to be of size @xmath2 , that is to have a probability of first kind error exactly equal to @xmath2 .    in the same way , instead of focusing as many previous authors on the consistence against some alternatives , we give precise conditions on the alternatives which guarantee that @xmath140 has a probability of second kind error controlled by a prescribed value @xmath19 in @xmath134 .",
    "these results are detailed in the next section .",
    "furthermore , we do not forget that studying our tests from a non - asymptotic point of view poses the additional question of the exact loss in probabilities of first and second kind errors due to the monte carlo approximation of @xmath135 .",
    "we also address this question in section [ montecarlo ] .",
    "such a non - asymptotic approach is actually conceivable thanks to the following proposition , which can be deduced from a general result of @xcite , but whose quite easy and complete proof is given in section [ preuves ] for sake of understanding .",
    "[ marques ] let @xmath4 and @xmath5 be two independent poisson processes on a metric space @xmath6 with intensities @xmath9 and @xmath10 with respect to some measure @xmath8 on @xmath6 and such that assumption [ hypo1 ] is satisfied .",
    "then the pooled process @xmath62 whose point measure is given by @xmath63 is a poisson process on @xmath6 with intensity @xmath141 with respect to @xmath8 .",
    "moreover , let @xmath142 be defined by @xmath70 if @xmath71 belongs to @xmath4 and @xmath72 if @xmath71 belongs to @xmath5 .",
    "then , conditionally on @xmath62 , the variables @xmath142 are i.i.d . and for every @xmath71 in @xmath62 , @xmath143 .",
    "we here study the probabilities of first and second kind errors of the test @xmath140 defined by ( [ fonctiontest ] ) .    from proposition [ marques",
    "] , we deduce that under @xmath11 , @xmath85 and @xmath133 exactly have the same distribution conditionally on @xmath62 . as a result , given @xmath2 in @xmath134 , under  @xmath11 , @xmath144 by taking the expectation over @xmath62",
    ", we obtain that @xmath145 in fact , the inequality ( [ inequationnivcond ] ) can be turned in an equality only for some particular values of @xmath2 , due to the discreteness of the conditional distribution of @xmath91 given @xmath62 . to go a little further , from proposition [ marques ] , we deduce that the randomization hypothesis as defined by romano and wolf @xcite and introduced by hoeffding @xcite is satisfied . from the construction of hoeffding @xcite",
    ", one can therefore randomize @xmath140 to obtain a test @xmath146 such that @xmath147 a.s . and such that under @xmath11 , @xmath148 for every @xmath2 . thus , by using the classical tool of randomization , one can circumvent the trouble due to the atoms of the discrete conditional distribution of @xmath91 given @xmath62 , and obtain a test with a probability of first kind error exactly equal to @xmath2 for every @xmath2 . note that the randomized test @xmath146 necessarily has a probability of second kind error smaller than @xmath140 s one , since @xmath147 a.s .",
    "however , in practice , since the conditional quantile @xmath135 is approximated by a monte carlo method as we have explained above , we do not have access to the true randomized version of @xmath140 .",
    "this explains why we have decided to focus in the following on the non - randomized test @xmath140 .",
    "given @xmath19 in @xmath134 , we now aim at bringing out a non - asymptotic condition on the alternative @xmath25 which will guarantee that @xmath149 denoting by @xmath150 the @xmath151 quantile of the conditional quantile @xmath135 , @xmath152 thus , a condition which guarantees that @xmath153 will be enough to ensure that @xmath149 the following proposition gives such a condition .",
    "[ propsinglerror ] let @xmath154 be fixed levels in @xmath134 , and let us recall that for any symmetric kernel function @xmath76 satisfying assumption [ hypo3 ] , @xmath155=\\mathcal{e}_k$ ] , with @xmath87 given in ( [ defek ] ) . if @xmath156 with @xmath157}(x)\\right)^2(f+g)(x)d\\nu_x,$ ] and @xmath158 then @xmath159 so that @xmath160 moreover , there exists some constant @xmath161 such that , for every @xmath76 , @xmath162    to prove the first part of this result , we simply use markov s inequality since obtaining precise constants and dependency in @xmath19 is not crucial here ( see section [ preuves ] ) .",
    "the control of @xmath150 derives from a property of rademacher chaoses combined with an exponential inequality ( see @xcite and @xcite ) .",
    "the following theorem allows to better understand proposition [ propsinglerror ] , and to deduce from it more recognizable properties in terms of uniform separation rates .",
    "[ singlerror ] let @xmath154 be fixed levels in @xmath134 .",
    "let @xmath76 be a symmetric kernel function satisfying assumption [ hypo3 ] , and @xmath140 be the test defined by  ( [ fonctiontest ] ) .",
    "let @xmath163 be an upper bound for @xmath164 .",
    "then , we have @xmath165 , as soon as @xmath166}\\right\\|^2\\\\ + \\frac{4 + 2\\sqrt{2}\\kappa \\ln(2/\\alpha)}{nr\\sqrt{\\beta}}\\sqrt{c_k}\\big]+\\frac{8{\\ensuremath{\\vert\\!\\vert f+g \\vert\\!\\vert}}_\\infty}{\\beta n}.\\end{gathered}\\ ] ] for instance , @xmath163 can be taken as follows .",
    "* @xmath167 when @xmath76 is chosen as in the [ projection kernel case ] , considering an orthonormal basis @xmath88 of a @xmath168-dimensional subspace @xmath57 of @xmath50 , * @xmath169 when @xmath76 is chosen as in the [ projection kernel case ] , considering an orthonormal basis @xmath88 of a possibly infinite dimensional subspace @xmath57 of @xmath50 , which satisfies : @xmath170 * @xmath171 when @xmath76 is chosen as in the [ approximation kernel case ] .",
    "_ comments .",
    "_    \\1 . when @xmath76 is chosen as in the _ [ projection kernel case ] _",
    ", then @xmath172}=\\pi_s(f - g)$ ] .",
    "hence by taking @xmath173 in ( [ rhs ] ) , the right hand side of the inequality reproduces a bias - variance decomposition close to the bias - variance decomposition for projection estimators , with a variance term of order @xmath174 instead of @xmath175 .",
    "this is quite usual for this kind of test ( see @xcite for instance ) , and we know that this leads to sharp upper bounds for the uniform separation rates over particular classes of alternatives",
    ".    \\2 . when @xmath76 is chosen as in the _ [ approximation kernel case ] _ with @xmath101 in @xmath176 , @xmath177 , and @xmath178 , then @xmath172}=k_h*(f - g)$ ] , and @xmath179 } \\vert\\!\\vert}}$ ] is a bias term .",
    "hence by taking @xmath173 in the inequality ( [ rhs ] ) , we still reproduce a bias - variance decomposition , but with a variance term of order @xmath180 , which coincides with the above variance term in the _ [ projection kernel case ] _ through the equivalence @xmath181 .",
    "this equivalence is usual in the approximation estimation theory ( see @xcite for instance for more details ) .",
    "\\3 . when @xmath76 is chosen as in the _ [ reproducing kernel case ] _",
    ", if @xmath76 is proportional to a kernel from the two above cases , then one can appropriately choose the constant @xmath182 such that @xmath183 } \\vert\\!\\vert}}$ ] is still a bias term .",
    "we thus recover for such kernel functions , such as the gaussian and laplacian kernels , which are commonly used in statistical learning theory , the same bias - variance decomposition as above .",
    "however , in some cases , one can not find any normalization constant @xmath182 for which @xmath183 } \\vert\\!\\vert}}$ ] can be viewed as a bias term , and the result can not be interpreted from a statistical point of view . in these cases in particular ,",
    "the @xmath184-norm which is considered in theorem [ singlerror ] is not the appropriate one to obtain relevant uniform separation rates , since it does not necessarily have any link with the norm of the rkhs @xmath115 .",
    "we give in the following theorem a more adequate result for the specific _ [ reproducing kernel case]_.    [ vitesseparametrique ] let @xmath154 be fixed levels in @xmath134 , and @xmath161 be the constant of proposition [ propsinglerror ] .",
    "let @xmath96 and @xmath76 be a kernel function on @xmath185 chosen as in the [ reproducing kernel case ] .",
    "let @xmath140 be the test function defined by ( [ fonctiontest ] ) .",
    "we assume furthermore that @xmath186 , that @xmath76 is a bounded measurable characteristic kernel , and that @xmath187 is constant equal to @xmath188 .",
    "let @xmath124 and @xmath125 be the mean embeddings of the distributions @xmath122 and @xmath123 respectively in @xmath115 .",
    "we have @xmath165 if @xmath189    _ comments .",
    "the assumption that @xmath187 is constant is usual , since it is satisfied by any normalized or translation - invariant kernel ( see @xcite p 46 - 47 , 57 , or @xcite for instance ) . moreover , as specified in @xcite for instance , bounded continuous characteristic and translation - invariant reproducing kernels exist , at least in @xmath23 , where bochner s theorem enables to characterize them .",
    "the result that we have here is in fact comparable to the one obtained by wellner @xcite for two - sample tests in an i.i.d . samples framework .",
    "while wellner s test is based on the estimation of a weak distance between @xmath122 and @xmath123 , associated with the sobolev norm with negative index , our test statistic is an unbiased estimator of @xmath190 , where @xmath191 defines a weak distance between the distributions @xmath122 and @xmath123 . as in @xcite ( or @xcite",
    "beforehand for the problem of testing uniformity ) , we obtain a uniform separation rate for this weak distance of the same order as the usual parametric separation rate , that is of order @xmath192 .        in practice ,",
    "a monte carlo method is used to approximate the conditional quantiles @xmath135 .",
    "it is therefore necessary to address the following question : what can we say about the probabilities of first and second kind errors of the test built with these monte carlo approximations ? recall that we consider the test @xmath140 rejecting @xmath11 when @xmath193 , where @xmath91 is defined by ( [ deftchapeauk ] ) , and @xmath135 is the @xmath136 quantile of @xmath139 defined by ( [ deftchapeaubootk ] ) conditionally on @xmath62 .",
    "the conditional quantile @xmath135 is estimated by @xmath194 via the monte carlo method as follows .",
    "conditionally on @xmath62 , we consider a set of @xmath195 independent sequences @xmath196 , where @xmath197 is a sequence of i.i.d .",
    "rademacher random variables .",
    "we define , for @xmath198 , @xmath199 under @xmath11 , conditionally on @xmath62 , the variables @xmath200 have the same distribution function as @xmath91 , which is denoted by @xmath201 .",
    "we denote by @xmath202 the empirical distribution function ( conditionally on @xmath62 ) of the sample @xmath203 : @xmath204 then , @xmath205 is defined by @xmath206 we finally consider the test given by @xmath207    [ mc1 ] let @xmath2 be some fixed level in @xmath134 , and @xmath208 be the test defined by ( [ testmc ] ) . under @xmath11 , @xmath209    _ comment .",
    "_ for example , if @xmath210 and @xmath211 , @xmath208 is of level @xmath212 .",
    "[ puismc ] let @xmath2 and @xmath19 be fixed levels in @xmath134 such that @xmath213 and @xmath214 .",
    "let @xmath208 be the test given in ( [ testmc ] ) .",
    "let @xmath87 , @xmath215 , @xmath216 and @xmath217 as in proposition [ propsinglerror ] , and let @xmath218 be the @xmath219 quantile of @xmath220 . if @xmath221 then @xmath222 moreover , @xmath223    _ comments .",
    "_ when comparing ( [ condekmc1 ] ) and ( [ condekmc2 ] ) with ( [ condek ] ) and ( [ controlq ] ) in proposition  [ propsinglerror ] , we notice that they asymptotically coincide when @xmath224 . moreover ,",
    "if @xmath225 and @xmath226 , the multiplicative factor of @xmath227 is multiplied by a factor of order @xmath228 in ( [ condekmc2 ] ) compared with ( [ controlq ] ) .",
    "if even @xmath229 , this factor passes from @xmath230 in ( [ controlq ] ) to @xmath231 in ( [ condekmc2 ] ) .",
    "in the above section , we consider testing procedures based on a single kernel function @xmath76 .",
    "using such single tests however leads to the natural question of the choice of the kernel , and/or its parameters : the orthonormal family when @xmath76 is a projection kernel , the vector of bandwidths @xmath37 when @xmath76 is based on an approximation kernel , the parameters of @xmath76 when it is a reproducing kernel .",
    "authors often choose particular parameters regarding the performance properties that they target for their tests , or use a data - driven method to choose these parameters which is not always justified .",
    "for instance , in @xcite , the parameter of the kernel is chosen from a heuristic method .    in order to avoid choosing particular kernels or parameters ,",
    "we propose in this section to consider some collections of kernel functions instead of a single one , and to define multiple testing procedures by aggregating the corresponding single tests .",
    "we propose an adapted choice for the critical value .",
    "then , we prove that these multiple tests satisfy strong statistical properties , such as oracle type properties and minimax adaptivity properties over many classes of alternatives .",
    "let us introduce a finite collection @xmath232 of symmetric kernel functions : @xmath77 satisfying assumption [ hypo3 ] .",
    "for every @xmath17 in @xmath233 , let @xmath234 and @xmath235 be defined by ( [ deftchapeauk ] ) and ( [ deftchapeaubootk ] ) respectively , with @xmath236 , and let @xmath237 be a collection of positive numbers such that @xmath238 .",
    "for @xmath239 in @xmath134 , we denote by @xmath240 the @xmath241 quantile of @xmath242 conditionally on the pooled process @xmath62 .",
    "given @xmath2 in @xmath134 , we consider the test which rejects @xmath11 when there exists at least one @xmath17 in @xmath233 such that @xmath243 where @xmath244 is defined by @xmath245 let @xmath28 be the corresponding test function defined by @xmath246 note that given the pooled process @xmath62 , @xmath247 and the quantile @xmath248 can be estimated by a monte carlo method .",
    "it is quite straightforward to see that this test is of level @xmath2 and that one can guarantee a probability of second kind error at most equal to @xmath19 in @xmath134 if one can guarantee it for one of the single tests rejecting @xmath11 when @xmath249 .",
    "we can thus combine the results of theorem  [ singlerror ] .",
    "[ testmulti ] let @xmath154 be fixed levels in @xmath134 .",
    "let @xmath250 be a finite collection of linear subspaces of @xmath251 and for all @xmath17 in @xmath233 , let @xmath252 be an orthonormal basis of @xmath253 for @xmath41 .",
    "we assume either that @xmath253 has finite dimension @xmath254 or that the conditions ( [ aa1 ] ) and ( [ aa2 ] ) hold with @xmath255 and @xmath256 .",
    "we set , for all @xmath17 in @xmath233 , @xmath257 .",
    "let @xmath258 be the test defined by ( [ testmult ] ) with the collection of kernels @xmath259 and a collection @xmath237 of positive numbers such that @xmath238 .",
    "then @xmath258 is a level @xmath2 test .",
    "moreover , @xmath260 if @xmath261 where @xmath161 and @xmath262 .",
    "_ comments .",
    "_ comparing this result with the one obtained in theorem [ singlerror ] for the single test based on a projection kernel , one can see that considering the multiple testing procedure allows to obtain the infimum over all @xmath263 in @xmath233 in the right hand side of ( [ oraclemulti ] ) at the price of the additional term @xmath264 .",
    "this result can be viewed as an oracle type property : indeed , without knowing @xmath26 , we know that the uniform separation rate of the aggregated test is of the same order as the smallest uniform separation rate in the collection of single tests , up to the factor @xmath264 .",
    "it will be used to prove that our multiple testing procedures are adaptive over various classes of alternatives .",
    "we focus here on two particular examples .",
    "the first example involves a nested collection of linear subspaces of @xmath265)$ ] , as in model selection estimation approaches . in the second example",
    ", we consider a collection of one dimensional linear subspaces of @xmath266)$ ] , and our testing procedure is hence related to a thresholding estimation approach .",
    "_ [ multiple kernels case - example 1 ] _ let @xmath267 $ ] and @xmath22 be the lebesgue measure on @xmath16 $ ] .",
    "let @xmath268 be the haar basis of @xmath269)$ ] with @xmath270}(x ) \\quad \\textrm{and } \\quad { \\ensuremath{\\varphi}}_{(j , k)}(x)=2^{j/2}\\psi(2^jx - k),\\ ] ] where @xmath271 . the collection of linear subspaces @xmath272 is chosen as a collection of nested subspaces generated by subsets of the haar basis",
    ". more precisely , we denote by @xmath273 the subspace of @xmath269)$ ] generated by @xmath274 , and we define @xmath275 .",
    "we also consider for @xmath276 the subspaces @xmath277 generated by @xmath278 with @xmath279 , and @xmath280 .",
    "let for some @xmath281 , @xmath282 and for every @xmath283 in @xmath284 , @xmath285    let @xmath286 be the test defined by ( [ testmult ] ) with the collection of kernels @xmath287 and with @xmath288 .",
    "we obtain from theorem [ testmulti ] that there exists @xmath289 such that @xmath290 if @xmath291    _ [ multiple kernels case - example 2 ] _ let @xmath267 $ ] and @xmath22 be the lebesgue measure on @xmath16 $ ] . let @xmath292 still be the haar basis of @xmath269)$ ] defined by ( [ haar ] ) .",
    "let for some @xmath293 , @xmath294 for any @xmath295 in @xmath296 , we consider the subspace @xmath297 of @xmath269)$ ] generated by @xmath298 , and @xmath299 .",
    "let @xmath300 be the test defined by ( [ testmult ] ) with the collection of kernels @xmath301 , with @xmath302 , and @xmath303 for @xmath304 we obtain from theorem [ testmulti ] and pythagoras theorem that there is some constant @xmath289 such that if there exists @xmath295 in @xmath305 for which @xmath306 then @xmath307 . if @xmath308 the above condition is equivalent to saying that there exists @xmath17 in @xmath309 such that @xmath310 where @xmath253 is generated by @xmath311 .",
    "hence , there exists some constant @xmath312 such that @xmath313 if @xmath314      [ testmultapproxkern ] let @xmath154 be fixed levels in @xmath134 , @xmath96 and let @xmath22 be the lebesgue measure on @xmath23 .",
    "let @xmath315 be a collection of approximation kernels such that @xmath316 , @xmath317 , and a collection @xmath318 , where each @xmath319 is a vector of @xmath108 positive bandwidths @xmath320 .",
    "we set @xmath321 , and for all @xmath322 in @xmath233 , @xmath104 , @xmath105 in @xmath323 , @xmath324 let @xmath258 be the test defined by ( [ testmult ] ) with @xmath259 and a collection @xmath237 of positive numbers such that @xmath325 .",
    "then @xmath258 is a level @xmath2 test .",
    "moreover , there exists @xmath161 such that if @xmath326 then @xmath327    we focus here on two particular examples .",
    "the first example involves a collection of non necessarily integrable approximation kernels with a collection of bandwidths vectors whose components are the same in every direction .",
    "the second example involves a single integrable approximation kernel , but with a collection of bandwidths vectors whose components may differ according to every direction .    _",
    "[ multiple kernels case - example 3 ] _ let @xmath328 and @xmath22 be the lebesgue measure on @xmath23 .",
    "we set @xmath329 and @xmath330 . for @xmath331 in @xmath332 , let @xmath333 be a kernel such that @xmath334 and @xmath317 , non necessarily integrable , whose fourier transform is defined when @xmath335 by @xmath336 and is extended to @xmath337 in the plancherel sense .",
    "we assume that for every @xmath331 in @xmath332 , @xmath338 , and @xmath339 for some @xmath340 , where @xmath341 denotes the euclidean norm of @xmath239 .",
    "note that the sinc kernel , the spline type kernel and pinsker s kernel given in @xcite for instance satisfy this condition which can be viewed as an extension of the integrability condition ( see @xcite p. 26 - 27 for more details ) .",
    "for @xmath342 in @xmath343 , let @xmath344 and for @xmath322 in @xmath321 , let @xmath345 we take @xmath346 , so @xmath347 .",
    "let @xmath348 be the test defined by ( [ testmult ] ) with the collection of kernels @xmath259 and @xmath349 .",
    "we obtain from theorem [ testmultapproxkern ] that there exists @xmath350 such that @xmath351 if @xmath352    _ [ multiple kernels case - example 4 ] _ let @xmath328 and @xmath22 be the lebesgue measure on @xmath23 .",
    "let @xmath353 and @xmath354 .",
    "for @xmath104 in @xmath23 , let @xmath355 where the @xmath356 s are real valued kernels such that @xmath357 , @xmath358 , and @xmath359 . for @xmath360 in @xmath343 , @xmath361 and for @xmath322 in @xmath321 , @xmath362 we also set @xmath363 , so that + @xmath364 .",
    "let @xmath365 be the test defined by ( [ testmult ] ) with the collections @xmath259 and @xmath349 .",
    "we deduce from theorem  [ testmultapproxkern ] that there exists @xmath350 such that @xmath366 if @xmath367      we here evaluate the uniform separation rates , defined by ( [ defrate ] ) , of the multiple testing procedures introduced above over several classes of alternatives based on besov and weak besov bodies when @xmath267 $ ] , or sobolev and anisotropic besov - nikolskii balls when @xmath96 .      in this section , we adapt to the present setting the results that we obtained in @xcite .    given @xmath2 in @xmath134 , let @xmath368 and @xmath369 be the tests defined in _ [ multiple kernels case - example 1 ] _ and _ [ multiple kernels case - example 2 ] _ ( with @xmath2 replaced by @xmath370 ) , and let @xmath371 + recall that these tests are constructed from the haar basis @xmath292 of @xmath269)$ ] defined by ( [ haar ] ) .",
    "we define for @xmath372 , @xmath373 the besov body @xmath374 as follows : @xmath375 we also consider the weak besov body given for @xmath376 , @xmath377 by @xmath378    [ vitesses ] assume that @xmath379 , @xmath380 , and @xmath381",
    ". then , for any @xmath372 , @xmath376 , @xmath382 , if @xmath383 @xmath384 , defined by ( [ defrate ] ) , is upper bounded by + @xmath385 @xmath386 if @xmath387 , + @xmath388 @xmath389 if @xmath390 .",
    "_ comments .",
    "lower bounds for the minimax separation rates over @xmath391 are also available , proving that the test @xmath392 is adaptive in the minimax sense over @xmath391 , up to a @xmath393 factor if @xmath394 and exactly if @xmath395 and @xmath396 . in the other cases",
    ", the exact rate is unknown .",
    "let us mention here that our classes of alternatives are not defined in the same way as in @xcite in the classical two - sample problem for i.i.d .",
    "samples , since the classes of alternatives @xmath25 of @xcite are such that @xmath9 and @xmath10 both belong to a besov ball . here",
    "the smoothness condition is only required on the difference @xmath26 . in particular , the functions",
    "@xmath9 and @xmath10 might be very irregular but as long as their difference is smooth , the probability of second kind error of the test will be controlled .",
    "let @xmath348 be defined as in _ [ multiple kernels case - example 3 ] _ , and let us introduce for @xmath372 the sobolev ball @xmath397 defined by @xmath398 where @xmath341 denotes the euclidean norm of @xmath239 and @xmath399 denotes the fourier transform of @xmath97 : @xmath400    [ vitessessobolev ] assume that @xmath401 .",
    "for any @xmath402 , if @xmath403 then @xmath404    _ comments .",
    "_ from @xcite , we know that , in the density model , the minimax adaptive estimation rate over @xmath405 is of order @xmath406 when @xmath407 .",
    "rigollet and tsybakov construct some aggregated density estimators , based on pinsker s kernel , that achieve this rate with exact constants . in the same way ,",
    "the test @xmath348 consists in an aggregation of some tests based on a collection of kernels , that may be for instance a collection of pinsker s kernels .",
    "it achieves over @xmath408 a uniform separation rate of order @xmath409 up to a @xmath393 factor .",
    "this rate is now known to be the optimal adaptive minimax rate of testing when @xmath410 in several models ( see @xcite in a gaussian model or @xcite in the density model for instance ) . from the results of @xcite",
    ", we can conjecture that our rates are also optimal when @xmath411 .",
    "let @xmath365 be the test defined in _ [ multiple kernels case - example 4]_. let @xmath412 , where for every @xmath413 , @xmath414 is a positive integer .",
    "assume furthermore that @xmath415 for every @xmath413 and @xmath416 .    for @xmath417 $ ] and @xmath373 , we consider the anisotropic nikolskii - besov ball @xmath418 defined by : @xmath419    [ vitessesanisotrop ] assume that @xmath401 .",
    "for any @xmath420 in @xmath421 $ ] and @xmath422 , if @xmath423 then , for @xmath424 , @xmath425    _ comments .",
    "_ when @xmath410 , from @xcite , we know that in the density model , the adaptive minimax rate of testing over a nikolskii class with smoothness parameter @xmath27 is of order @xmath426 .",
    "we find here an upper bound similar to this univariate rate , but where @xmath27 is replaced by @xmath427 .",
    "such results were obtained in a multivariate density estimation context in @xcite where the adaptive minimax estimation rates over the anisotropic nikolskii classes are proved to be of order @xmath428 , and where adaptive kernel density estimators are proposed . moreover , the minimax rates of testing obtained recently in @xcite over anisotropic periodic sobolev balls , but in the gaussian white noise model , are of the same order as the upper bounds obtained here .",
    "all along the proof , @xmath429 denotes @xmath430 . recalling that the marked point processes are characterized by their laplace functional ( see @xcite for instance ) , we first aim at computing @xmath431 $ ] for any bounded measurable function @xmath37 on @xmath6 . since @xmath4 and @xmath5 are independent , @xmath432={\\ensuremath{\\mathbb{e}}}\\left[\\exp\\left(\\int h dn^1\\right)\\right]{\\ensuremath{\\mathbb{e}}}\\left[\\exp\\left(\\int h dn^{-1}\\right)\\right].\\ ] ] the laplace functional of @xmath4 is given by @xmath433=\\exp\\left(\\int \\left(e^h-1\\right ) f d\\mu\\right),\\ ] ] and the laplace functional of @xmath5 has the same form , replacing @xmath9 by @xmath10 , so @xmath432=\\exp\\left(\\int \\left(e^h-1\\right ) \\left(f+g\\right ) d\\mu\\right),\\ ] ] which is the laplace functional of a poisson process with intensity @xmath434 w.r.t .",
    "therefore , @xmath62 is a poisson process with intensity @xmath434 w.r.t . @xmath8 .    in order to prove ( [ loieps0 ] )",
    ", we then give an explicit expression of the function : @xmath435,\\ ] ] which characterizes the distribution of @xmath436 conditionally on @xmath62 .",
    "+ let @xmath295 be a bounded measurable function defined on @xmath6 , and let @xmath437}.\\ ] ] by definition of @xmath436 and by independency of @xmath4 and @xmath5 , we have that @xmath438}\\\\ & = & { \\ensuremath{\\mathbb{e}}}{\\left[{\\exp{\\left({\\int ( \\lambda(x)+t_x ) dn^1_x}\\right ) } } \\right ] } { \\ensuremath{\\mathbb{e}}}{\\left[{\\exp{\\left({\\int ( \\lambda(x)-t_x ) dn^{-1}_x}\\right ) } } \\right]}\\\\ & = & \\exp \\int { \\left [ { ( e^{\\lambda(x)+t_x}-1 ) f(x)+   ( e^{\\lambda(x)-t_x}-1 ) g(x)}\\right ] } d\\mu_x .",
    "\\end{aligned}\\ ] ] then , for @xmath439 , @xmath440}.\\ ] ] hence , for every bounded measurable function @xmath295 defined on @xmath6 , @xmath441}=\\\\   { \\ensuremath{\\mathbb{e}}}\\bigg[\\exp\\left(\\int \\lambda dn\\right ) \\prod_{x\\in n } \\bigg(e^{t_x } \\frac{f(x)}{(f+g)(x ) } + e^{-t_x } \\frac{g(x)}{(f+g)(x)}\\bigg)\\bigg].\\end{gathered}\\ ] ] since the marked point processes are characterized by their laplace functional , this implies that @xmath442 }   = \\prod_{x\\in n } { \\left({e^{t_x } \\frac{f(x)}{(f+g)(x ) } + e^{-t_x } \\frac{g(x)}{(f+g)(x)}}\\right)},\\ ] ] which concludes the proof .",
    "let us prove the first part of proposition  [ propsinglerror ] . recall that @xmath150 denotes the @xmath443 quantile of @xmath135 , which is the @xmath136 quantile of @xmath444 conditionally on @xmath62 .",
    "we here want to find a condition on @xmath85 , or more precisely on @xmath445 $ ] , ensuring that @xmath446 from markov s inequality , we have that for any @xmath447 , @xmath448 let us compute @xmath449-\\mathcal{e}_k^2 $ ] .",
    "let @xmath450}$ ] and @xmath451}$ ] be the sets @xmath452 and @xmath453 respectively .",
    "since @xmath454={\\ensuremath{\\mathbb{e}}}_{f , g}\\left[{\\ensuremath{\\mathbb{e}}}\\left[\\left(\\int_{{\\ensuremath{\\mathbb{x}}}^{[2 ] } } k(x , x'){\\ensuremath{\\varepsilon}}_x^0{\\ensuremath{\\varepsilon}}_{x'}^0 dn_xdn_{x'}\\right)^2\\bigg|n\\right]\\right],\\ ] ] by using ( [ loieps0 ] ) , @xmath455&=&{\\ensuremath{\\mathbb{e}}}_{f , g}\\bigg[\\int_{{\\ensuremath{\\mathbb{x}}}^{[4]}}\\ !",
    "k(x , y)k(u , v ) \\frac{f - g}{f+g}(x ) \\frac{f - g}{f+g}(y)\\\\ & & \\frac{f - g}{f+g}(u)\\frac{f - g}{f+g}(v)dn_xdn_ydn_udn_v\\bigg]\\\\ & & + 4{\\ensuremath{\\mathbb{e}}}_{f , g}\\left[\\int_{{\\ensuremath{\\mathbb{x}}}^{[3 ] } }   k(x , y)k(x , u ) \\frac{f - g}{f+g}(y ) \\frac{f - g}{f+g}(u)dn_xdn_ydn_u\\right]\\\\ & & + 2{\\ensuremath{\\mathbb{e}}}_{f , g}\\left[\\int_{{\\ensuremath{\\mathbb{x}}}^{[2 ] } } k^2(x , y)dn_xdn_y\\right].\\end{aligned}\\ ] ] now , from lemma 5.4 iii in @xcite on factorial moments measures applied to poisson processes , we deduce that @xmath455&=&\\int_{{\\ensuremath{\\mathbb{x}}}^{4}}\\bigg ( k(x , y)k(u , v)(f - g)(x)(f - g)(y)\\\\ & & ( f - g)(u)(f - g)(v)\\bigg )   d\\mu_xd\\mu_yd\\mu_ud\\mu_v\\\\ & & + 4\\int_{{\\ensuremath{\\mathbb{x}}}^{3 } }   k(x , y)k(x , u)(f+g)(x)(f - g)(y)(f - g)(u ) d\\mu_xd\\mu_yd\\mu_u\\\\ & & + 2\\int_{{\\ensuremath{\\mathbb{x}}}^{2 } } k^2(x , y)(f+g)(x)(f+g)(y ) d\\mu_xd\\mu_y\\\\\\end{aligned}\\ ] ] note that the three above integrals are finite , thanks to assumptions [ hypo1 ] , [ hypo2 ] et [ hypo3 ] .",
    "we finally obtain that @xmath456=\\mathcal{e}_k^2 + 4 n^3 a_k+2 n^2 b_k,$ ] and for @xmath447 , @xmath457 taking @xmath458 in the above inequality leads to @xmath459 therefore , if @xmath460 , then @xmath159 so @xmath149    let us now give a sharp upper bound for @xmath150 .",
    "reasoning conditionally on @xmath62 , we recognize in @xmath444 a homogeneous rademacher chaos , as defined by de la pe@xmath461a and gin @xcite , of the form @xmath462 where the @xmath463 s are some real deterministic numbers and @xmath128 is a sequence of i.i.d .",
    "rademacher variables .",
    "corollary 3.2.6 of @xcite states that there exists some absolute constant @xmath161 such that if @xmath464=\\sum_{i\\neq i ' } x_{i , i'}^2,$ ] then @xmath465 \\leq 2.\\ ] ] hence by markov s inequality , @xmath466 note that one could find more precise constants with the results of @xcite .",
    "+ applying this result to @xmath444 with @xmath467 leads to @xmath468 } } k^2(x , y)dn_x dn_{y}}.\\ ] ] hence @xmath150 is upper bounded by the @xmath151 quantile of + @xmath469 } } k^2(x , y)dn_x dn_{y}}$ ] .",
    "+ using markov s inequality again and lemma  5.4  iii in @xcite , we obtain that @xmath470 } } k^2(x , y)dn_x dn_{y}\\geq \\frac{2 n^2 b_k}{\\beta}\\right)\\leq \\frac{\\beta}{2},\\ ] ] and @xmath471      first notice that for every @xmath472 , and every kernel function @xmath76 satisfying assumption [ hypo3 ] , @xmath473 } \\vert\\!\\vert}}^2-{\\ensuremath{\\vert\\!\\vert ( f - g)-r^{-1 } k{\\left[{f - g}\\right ] } \\vert\\!\\vert}}^2\\right).\\ ] ] with the notations of proposition [ propsinglerror ] , let @xmath163 be any upper bound for @xmath216 . since @xmath474 } \\vert\\!\\vert}}^2 { \\ensuremath{\\vert\\!\\vert f+g \\vert\\!\\vert}}_\\infty$ ] , from proposition [ propsinglerror ] , we deduce that @xmath475 if @xmath476 } \\vert\\!\\vert}}^2-{\\ensuremath{\\vert\\!\\vert ( f - g)-r^{-1 } k{\\left[{f - g}\\right ] } \\vert\\!\\vert}}^2\\\\ \\geq 4\\sqrt{\\frac{2{\\ensuremath{\\vert\\!\\vert f+g \\vert\\!\\vert}}_\\infty}{n\\beta}}\\frac{{\\ensuremath{\\vert\\!\\vert k{\\left[{f - g}\\right ] } \\vert\\!\\vert}}}{r}+\\frac{2}{nr\\sqrt{\\beta}}\\left(2+\\kappa\\sqrt{2}\\ln\\left(\\frac{2}{\\alpha}\\right)\\right ) \\sqrt{c_k},\\end{gathered}\\ ] ] by using the elementary inequality @xmath477 with @xmath478 } \\vert\\!\\vert}}/r$ ] and @xmath479 in the right hand side of the above condition , this condition can be replaced by : @xmath480 } \\vert\\!\\vert}}^2+\\frac{8{\\ensuremath{\\vert\\!\\vert f+g \\vert\\!\\vert}}_\\infty}{n\\beta}\\\\ + \\frac{2}{nr\\sqrt{\\beta}}\\left(2+\\kappa\\sqrt{2}\\ln\\left(\\frac{2}{\\alpha}\\right)\\right ) \\sqrt{c_k}. \\end{gathered}\\ ] ] we can even add an infimum over @xmath182 in the right hand side of the condition , since @xmath182 can be arbitrarily chosen . let us now justify our choices for @xmath163 .",
    "_ [ projection kernel case ] _ we consider an orthonormal basis @xmath481 of a subspace @xmath57 of @xmath50 and @xmath482 when the dimension of @xmath57 is finite , equal to @xmath168 , @xmath483 when the dimension of @xmath57 is infinite , @xmath484 where we have used the assumption ( [ aa2 ] ) to invert the sum and the integral .",
    "hence we have , by orthogonality , and since by assumption ( [ aa1 ] ) , @xmath485 , @xmath486    _ [ approximation kernel case ] _ assume now that @xmath96 and introduce an approximation kernel such that @xmath487 and @xmath103 , @xmath488 , with @xmath489 for every @xmath490 , and @xmath491 , with @xmath492 . in this case , @xmath493 this ends the proof of theorem [ singlerror ] .",
    "we first recall that when @xmath76 is chosen as in the _ [ reproducing kernel case ] _ , under the assumptions of theorem [ vitesseparametrique ] , @xmath494 ( see section [ introker ] ) .    since @xmath495 , by the cauchy - schwarz inequality for the norm @xmath496 in the rkhs",
    ", we obtain : @xmath497 now , since for every @xmath498 in @xmath6 , @xmath499 , @xmath500 this leads to @xmath501 finally , noting that @xmath502 and that by assumption @xmath503 , we obtain the desired result from proposition [ propsinglerror ] and obvious calculations .",
    "first let us rewrite here a result due to romano and wolf @xcite .",
    "[ lemmerw ] [ romw ] let @xmath504 be @xmath505 exchangeable variables then for all @xmath506 $ ] , @xmath507    assume that @xmath11 is satisfied .",
    "conditionally on @xmath62 , the observed statistic @xmath508 has the same distribution and is independent of the @xmath509 s for @xmath510",
    ". therefore the variables @xmath509 s for @xmath511 are exchangeable variables given @xmath62 . hence applying lemma [ lemmerw ] ,",
    "we obtain : @xmath512      let @xmath513 . by definition of @xmath194 ,",
    "@xmath514 we have @xmath515 so we can decompose as follows : @xmath516 by hoeffding s inequality applied to the second probability given @xmath62 , we obtain : @xmath517 but by definition of @xmath518 , this becomes @xmath519 let us now control the probability of second kind error of the test @xmath520 .",
    "@xmath521 we deduce from ( [ inemarkov ] ) that if @xmath522 then @xmath523 and @xmath524 . an upper bound for @xmath518",
    "is finally derived from ( [ controlq ] ) , which concludes the proof . + * acknowledgments .",
    "* we are grateful to the referee , whose discussion and comments allowed us to improve some of our results and to clarify some important points .",
    "we also acknowledge the support of the french agence nationale de la recherche ( anr ) , under grant atlas ( jcjc06 - 137446 )  from applications to theory in learning and adaptive statistics  and under grant calibration ( anr-2011-bs01 - 010 - 02 ) .",
    "9    arcones , m. a. and gin , e. ( 1992 ) . _ on the bootstrap of @xmath1 and @xmath525 statistics _ , _ ann",
    ". statist . _ * 20 * , 2 , 655674 .",
    "baraud , y. ( 2002 ) .",
    "_ non - asymptotic minimax rates of testing in signal detection _ , _ bernoulli _ * 8 * , 5 , 577606 .",
    "baraud , y. and huet , s. and laurent , b. ( 2003 ) .",
    "_ adaptive tests of linear hypotheses by model selection _ , _ ann .",
    "statist . _",
    "* 31 * , 1 , 225251 .",
    "bartlett , p. l. , boucheron , s. and lugosi , g. ( 2002 ) . _ model selection and error estimation _",
    ", _ machine learning _ * 48 * , 1 , 85113 .",
    "bovett , j. m. and saw , j. g. ( 1980 ) .",
    "_ on comparing two poisson intensity functions _ , _ comm",
    "a  theory methods _ * 9 * , 9 , 943948 .",
    "bretagnolle , j. ( 1983 ) .",
    "_ lois limites du bootstrap de certaines fonctionnelles _ , _ ann .",
    "h. poincar sect .",
    "b _ * 19 * , 3 , 281296 .",
    "butucea , c. and tribouley , k. ( 2006 ) . _ nonparametric homogeneity tests _ , _ j. statist .",
    "plann . inference _ * 136 * , 3 , 597639 .",
    "chiu , s. n. ( 2010 ) .",
    "_ parametric bootstrap and approximate tests for two poisson variates _ ,",
    "_ j. stat .",
    "simul . _ * 80 * , 3 - 4 , 263271 .",
    "chiu , s. n. and wang , l. ( 2009 ) .",
    "_ homogeneity tests for several poisson populations _ , _ comput",
    "statist . data anal . _ * 53 * , 12 , 42664278 .",
    "cox , d. r. ( 1953 ) .",
    "_ some simple approximate tests for poisson variates _ , _ biometrika _ * 40 * , 354360 .    daley , d. j. and vere - jones , d. ( 2008 ) . _ an introduction to the theory of point processes . vol .",
    "ii _ , second edition , springer , new york .",
    "de la pea , v. h. and gin , e. ( 1999 ) . _ from dependence to independence , randomly stopped processes .",
    "@xmath1-statistics and processes .",
    "martingales and beyond _ , springer , new york .",
    "dehling , h. and mikosch , t. ( 1994 ) . _ random quadratic forms and the bootstrap for @xmath1-statistics _ , _ j. multivariate anal . _",
    "* 51 * , 2 , 392413 .",
    "deshpande , j. v. and sengupta , d. ( 1995 ) .",
    "_ testing the hypothesis of proportional hazards in two populations _ , _ biometrika _ * 82 * , 252261 .",
    "deshpande , j. v. and mukhopadhyay , m. and naik - nimbalkar , u. v. ( 1999 ) .",
    "_ testing of two sample proportional intensity assumption for non - homogeneous poisson processes _ , _ j. statist .",
    "plann . inference _ * 81 * , 2 , 237251 .",
    "efron , b. ( 1979 ) .",
    "_ bootstrap methods : another look at the jackknife _ , _ ann",
    "statist . _",
    "* 7 * , 1 , 126 .",
    "fisher , r. a. ( 1935 ) . _",
    "the design of experiments _ , edinburgh : oliver and boyd .",
    "fromont , m. and laurent , b. and reynaud - bouret , p. ( 2011",
    "_ adaptive tests of homogeneity for a poisson process _ , _ ann .",
    "henri poincar probab .",
    "stat . _ * 47 * , 1 , 176213 .",
    "gail , m. ( 1974 ) .",
    "_ computations for designing comparative poisson trials _ , _ biometrics",
    "_ * 30 * , 2 , 231237 .",
    "gin , e. ( 1975 ) .",
    "_ invariant tests for uniformity on compact riemannian manifolds based on sobolev norms _ , _ ann .",
    "statist . _",
    "* 3 * , 6 , 12431266 .",
    "goldenshluger , a. and lepski , o. ( 2011 ) . _ bandwith selection in kernel density estimation : oracle inequalities and adaptive minimax optimality _ , _ ann .",
    "_ * 29 * , 3 , 16081632 .",
    "gretton , a. and borgwardt , k. m. and rasch , m. j. and schlkopf , b. and smola , a. ( 2008 ) . _ a kernel method for the two - sample problem _ , _ j. mach .",
    "_ * 1 * , 110",
    ". hoeffding , w. ( 1952 ) . _ the large - sample power of tests based on permutations of observations _ , _ ann .",
    "math . statistics .",
    "_ * 23 * , 169192 .",
    "horowitz , j. l. and spokoiny , v. g. ( 2001 ) .",
    "_ an adaptive , rate - optimal test of a parametric mean - regression model against a nonparametric alternative _ , _ econometrica _ * 69 * , 3 , 599631 .",
    "hukov , m. and janssen , p. ( 1993 ) .",
    "_ consistency of the generalized bootstrap for degenerate @xmath1-statistics _ , _ ann .",
    "statist . _ * 21 * , 4 , 18111823 .",
    "ingster , y. i. ( 1993 ) .",
    "_ asymptotically minimax testing for nonparametric alternatives i - ii - iii _ , _ math .",
    "methods statist .",
    "_ * 2 * , 85114 , 171189 , 249268 .",
    "ingster , y. i. ( 2000 ) .",
    "_ adaptive chi - square tests _ , _ j. math .",
    "sci . _ * 99 * , 2 , 1110-1119 .",
    "ingster , y. i. and kutoyants , y. a. ( 2007 ) .",
    "_ nonparametric hypothesis testing for intensity of the poisson process _ , _ math .",
    "methods statist . _ * 16 * , 3 , 217245 .",
    "ingster , y. i. and stepanova , n. ( 2011 ) . _",
    "estimation and detection of functions from anisotropic sobolev classes _ , _ electron . j. statist . _ * 5 * , 484506 .",
    "janssen , p. ( 1994 ) .",
    "_ weighted bootstrapping of @xmath1-statistics _ , _ j. statist .",
    "plann . inference _ * 38 * , 1 , 3141 .",
    "janssen , a. and pauls , t. ( 2003 ) .",
    "_ how do bootstrap and permutation tests work ?",
    "_ , _ ann .",
    "_ * 31 * , 3 , 768806 .",
    "koltchinskii , v. ( 2001 ) _ rademacher penalties and structural risk minimization _ , _ ieee trans .",
    "inform . theory _ * 47 * , 19021914 .",
    "koltchinskii , v. ( 2006 ) _ local rademacher complexities and oracle inequalities in risk minimization _ , _ ann .",
    "_ * 34 * , 6 , 2593 - 2656 .",
    "krishnamoorthy , k. and thomson , j. ( 2004 ) .",
    "_ a more powerful test for comparing two poisson means _ , _ j. statist .",
    "plann . inference _ * 119 * , 2335 .",
    "lataa , r. ( 1999 ) . _",
    "tail and moment estimates for some types of chaos _ , _ studia math . _ * 135 * , 1 , 3953 .",
    "lounici , k. and nickl , r. ( 2011 ) .",
    "_ global uniform risk bounds for wavelet deconvolution estimators _ , _ ann . statist .",
    "_ * 39 * , 1 , 201231",
    ".    mammen , e. ( 1992 ) . _ bootstrap , wild bootstrap , and asymptotic normality _ , _ probab . theory related fields _ * 93 * , 4 , 439455 .",
    "ng , h. k. t. and gu , k. and tang , m. l. ( 2007 ) . _ a comparative study of tests for the difference of two poisson means _ , _ comput .",
    "statist . data anal . _",
    "* 51 * , 6 , 30853099 .",
    "praestgaard , j. t. ( 1995 ) . _ permutation and bootstrap kolmogorov - smirnov tests for the equality of two distributions _ ,",
    "_ scand . j. statist . _ * 22 * , 3 , 305322 .",
    "praestgaard , j. t. and wellner , j. a. ( 1993 ) .",
    "_ exchangeably weighted bootstraps of the general empirical process _ , _ ann .",
    "probab . _ * 21 * , 4 , 20532086 .",
    "przyborowski , j. and wilenski , h. ( 1940 ) . _ homogeneity of results in testing samples from poisson series with an application to testing clover seed for dodder _ , _ biometrika _ * 31 * , 313323 .",
    "rigollet , p. and tsybakov , a. b. ( 2007 ) . _",
    "linear and convex aggregation of density estimators _ , _ math .",
    "methods statist . _",
    "* 16 * , 3 , 260280 .",
    "romano , j. p. ( 1988 ) . _ a bootstrap revival of some nonparametric distance tests _ , _",
    "assoc . _ * 83 * , 403 , 698708 .",
    "romano , j. p. ( 1988 ) . _",
    "bootstrap and randomization tests of some nonparametric hypotheses _ , _ ann .",
    "statist . _",
    "* 17 * , 1 , 141159 .",
    "romano , j. p. and wolf , m. ( 2005 ) . _ exact and approximate stepdown methods for multiple hypothesis testing _ , _",
    "assoc . _ * 100 * , 469 , 94108 .",
    "rubin , d. b. ( 1981 ) . _ the bayesian bootstrap _ , _ ann .",
    "statist . _",
    "* 9 * , 1 , 130134 .",
    "schlkopf , b. , and smola , a. j. ( 2002 ) .",
    "_ learning with kernels _ , cambridge ( mass . ) , mit press .",
    "shiue , w. and bain , l. j. ( 1982 ) .",
    "_ experiment size and power comparisons for two - sample poisson tests _ , _ j. roy .",
    "c _ * 31 * , 2 , 130134 .",
    "spokoiny , v. g. ( 1996 ) .",
    "_ adaptive hypothesis testing using wavelets _ , _ ann .",
    "_ * 24 * , 6 , 24772498 .",
    "spokoiny , v. g. ( 1998 ) .",
    "_ adaptive and spatially adaptive testing of a nonparametric hypothesis _ , _ math .",
    "methods statist .",
    "_ * 7 * , 3 , 245273 .",
    "sriperumbudur , b. k. , fukumizu , k. , and lanckriet , g. r. g. ( 2011 ) .",
    "_ universality , characteristic kernels and rkhs embeddings of measures _ , _ j. mach .",
    "* 12 * , 23892410 .",
    "tsybakov , a. b. ( 2009 ) .",
    "_ introduction to nonparametric estimation _ , _ springer series in statistics _",
    "springer , new york .",
    "wellner , j. a. ( 1979 ) .",
    "_ permutation tests for directional data _ , _ ann",
    "statist . _",
    "* 7 * , 5 , 929943 .",
    "in this section , we study our testing procedures from a practical point of view .",
    "we consider @xmath267 $ ] or @xmath526 , @xmath527 and @xmath22 the lebesgue measure on @xmath6 .",
    "@xmath4 and @xmath5 denote two independent poisson processes with intensities @xmath9 and @xmath10 on @xmath6 with respect to @xmath8 with @xmath528 .",
    "we focus on several couples of intensities @xmath25 defined on @xmath6 and such that @xmath529 .",
    "we choose @xmath530 .",
    "+ conditionally on the number of points of both processes @xmath4 and @xmath5 , the points of @xmath4 and @xmath5 form two independent samples of i.i.d .",
    "variables with densities @xmath9 and @xmath10 with respect to @xmath22 . hence , conditionally on the number of points of @xmath4 and @xmath5 , any test for the classical two - sample problem for i.i.d .",
    "samples can be used here .",
    "we compare our tests to the conditional kolmogorov - smirnov test .",
    "thus we consider five testing procedures , that we respectively denote by ks , ne , th , g , e. the testing procedure ks corresponds to the conditional kolmogorov - smirnov test .",
    "the testing procedures ne and th respectively correspond to @xmath531 and @xmath532 defined in _ [ multiple kernels case - example 1 ] _ and _ [ multiple kernels case - example 2 ] _ with @xmath533 and @xmath534 .",
    "the testing procedures g and e are similar to the test @xmath535 defined in _ [ multiple kernels case - example 4]_. for g , we consider the standard gaussian approximation kernel defined by @xmath536 for all @xmath537 and for e , we consider the epanechnikov approximation kernel defined by @xmath538 .",
    "for both tests , we take @xmath539 and the corresponding collection of kernels @xmath232 given for all @xmath17 in @xmath233 by @xmath540 .",
    "we also take for both tests @xmath541 .",
    "let us recall that our tests reject @xmath11 when there exists @xmath17 in @xmath233 such that @xmath542 where @xmath62 is the pooled process obtained from @xmath4 and @xmath5 , and @xmath244 is defined by ( [ ualpha ] ) .",
    "hence , for each observation of the process @xmath62 whose number of points is denoted by @xmath129 , we have to estimate @xmath543 and the quantiles @xmath544 .",
    "these estimations are done by classical monte carlo methods based on the simulation of @xmath545 independent samples of size @xmath129 of i.i.d .",
    "rademacher variables ( see section [ montecarlo ] for the theoretical study of these monte carlo methods when single tests are considered ) . half of the samples is used to estimate the distribution of each @xmath242 .",
    "the other half is used to approximate the conditional probabilities occurring in ( [ ualpha ] ) .",
    "the approximation of @xmath247 is obtained by dichotomy , such that the estimated conditional probability occurring in ( [ ualpha ] ) is less than @xmath2 , but as close as possible to @xmath2 . by monotony arguments ,",
    "this is equivalent to make @xmath239 varying on a regular grid of @xmath16 $ ] with bandwidth @xmath546 , and to choose the approximation of @xmath247 as the largest value of the @xmath239 s on the grid such that the estimated conditional probabilities in ( [ ualpha ] ) are less than @xmath2 .",
    "we first study the probability of first kind error of each test for three common intensities .",
    "the first one is the uniform density on @xmath16 $ ] , the second one is the beta density with parameters @xmath547 , and the third one is a laplace density with parameter @xmath548 .",
    "let @xmath549}(x ) , \\\\   f_{2,2,5}(x)&= &   \\frac{x(1-x)^4}{\\int_0 ^ 1 x(1-x)^4 dx}{{\\bf 1}}_{[0,1]}(x),\\\\   f_{3,7}(x)&= &   \\frac{7}{2 } e^{-7|x-1/2|}.\\end{aligned}\\ ] ] taking @xmath9 as one of these three functions , we realize @xmath550 simulations of two independent poisson processes @xmath4 and @xmath5 both with intensity @xmath9 w.r.t . to @xmath8 . for each simulation , we determine the conclusions of the tests ks , ne , th , g and e , where the critical values of our four last tests are approximated by the monte carlo methods described above .",
    "the probabilities of first kind error of the tests are estimated by the number of rejections for these tests divided by @xmath550 .",
    "the results are given in the following table :       in all cases , the tests g and e based on approximation kernels are more powerful ( sometimes even about 4 times more powerful ) than the ks test .",
    "this is also the case for the test ne , except for the last example .",
    "the test th is more powerful than the ks test for the alternatives @xmath551 , but it fails to improve the ks test for the other alternatives .",
    "we conjecture that the test th consists in the aggregation of too many single tests .",
    "we can finally notice that the test e strongly performs for every considered alternative , except in a sparse case , where the test e is less powerful than the test th ( see figure 1 ) .",
    "our conclusion is that the test e is a good practical choice , except maybe when sparse processes are involved .",
    "aggregating the tests e and th in such cases would probably be a good compromise .",
    "it is clear from the definition of @xmath247 that the test defined by @xmath552 is of level @xmath2 . obviously , by bonferonni s inequality ,",
    "@xmath553 , hence , setting @xmath554 , we have @xmath555 as soon as there exists @xmath17 in @xmath233 such that @xmath556",
    ". we can now apply theorem [ singlerror ] , replacing @xmath557 by @xmath558 , to conclude the proof .",
    "let us first find an upper bound for + @xmath559 .",
    "considering , we in fact only need to find a sharp upper bound for the right hand side of the inequality when @xmath25 belongs to @xmath391 .",
    "so let us assume here that @xmath560 .",
    "then @xmath561 , and it is well known ( see @xcite for instance ) that in this case , @xmath562 since the constant @xmath563 in can be upper bounded by a constant @xmath564 , the right hand side of can be upper bounded by @xmath565 now , taking @xmath566 @xmath567 this leads to @xmath568 of course a similar upper bound applies to @xmath392 .",
    "let us now find an upper bound for @xmath569 . considering , we only need to find an upper bound for the right hand side of the inequality when @xmath25 belongs to @xmath391 .",
    "let @xmath283 be an integer that will be chosen later .",
    "as in @xcite , for any @xmath570 , one can write @xmath571 let us define the coefficients : @xmath572 for every @xmath295 in @xmath573 , and let us consider @xmath17 such that @xmath574 is the set of the @xmath168 largest coefficients among @xmath575 . from @xcite p.36 for instance , we deduce that @xmath576 as above , we also have that @xmath577 since the constant @xmath563 in can be upper bounded by a constant @xmath564 , taking @xmath578 for some @xmath579 , the right hand side of is upper bounded by @xmath580 now , taking @xmath581 , and @xmath582 , one obtains that when @xmath395 , then @xmath583 , and @xmath584 since this upper bound also applies to @xmath392 , one has @xmath585      we give here the arguments to derive from the results given in @xcite lower bounds for the minimax separation rates over @xmath391 . as usual , we introduce a finite subset @xmath586 of @xmath391 , composed of couples of intensities which are particularly difficult to distinguish .",
    "here one can use the finite subset of possible intensities @xmath587 that has been defined in @xcite equation ( 6.4 ) , and define @xmath588 } \\mbox { and } g \\in \\mathcal{s}_{m , d , r}\\},\\ ] ] for some fixed positive @xmath589 .",
    "next the computations of the lower bounds of @xcite can be completely reproduced once we remark that the likelihood ratio @xmath590}},g}}{d{\\ensuremath{\\mathbb{p}}}_{\\rho{{\\bf 1}}_{[0,1]},\\rho{{\\bf 1}}_{[0,1]}}}(n^1,n^{-1 } ) = \\frac{d{\\ensuremath{\\mathbb{p}}}_{\\rho{{\\bf 1}}_{[0,1]}}}{d{\\ensuremath{\\mathbb{p}}}_{\\rho{{\\bf 1}}_{[0,1]}}}(n^1)\\times\\frac{d{\\ensuremath{\\mathbb{p}}}_{g}}{d{\\ensuremath{\\mathbb{p}}}_{\\rho{{\\bf 1}}_{[0,1]}}}(n^{-1}),\\ ] ] where on the left hand side @xmath35 represents the joint distribution of two independent poisson processes @xmath4 and @xmath5 , with respective intensities @xmath9 and @xmath10 , and on the right hand side @xmath591 represents the distribution of one poisson process with intensity @xmath9 .",
    "this means that the likelihood ratios that have been considered in @xcite are exactly the ones we need here to compute the expected lower bounds .",
    "the results are consequently identical",
    ".      considering , we mainly have to find a sharp upper bound for @xmath592 when @xmath25 belongs to @xmath408 .",
    "+ let us first control the bias term @xmath593 .",
    "plancherel s theorem gives that when @xmath594 , @xmath595 assume now that @xmath596 and take @xmath597 .",
    "note that since @xmath598 and @xmath599 satisfies the condition ( [ nonintkernel ] ) , there also exists some constant @xmath600 such that @xmath601 then @xmath602 and since @xmath603 , @xmath604 furthermore , @xmath605 so @xmath606 choosing @xmath607 leads to @xmath608 and since @xmath609 , @xmath610 noting that @xmath611 when @xmath612 , @xmath613 this concludes the proof of corollary [ vitessessobolev ] .",
    "as in the previous section , considering , we here have to find a sharp upper bound for @xmath614 let us first evaluate @xmath615 when @xmath616 , and @xmath488 . + for @xmath617 , let @xmath618",
    ". then @xmath619 and since @xmath620 ,                @xmath628du\\bigg)^2dx\\\\ & \\leq & \\bigg[\\int_{{\\ensuremath{\\mathbb{r}}}^d } |k_1(u)|\\frac{|u_ih_i|^{\\lfloor \\delta_i\\rfloor}}{(\\lfloor \\delta_i\\rfloor\\!-\\!1 ) ! } \\bigg ( \\int_{{\\ensuremath{\\mathbb{r}}}^d}\\big[\\int_0 ^ 1(1-\\tau)^{\\lfloor \\delta_i\\rfloor-1}\\\\ & & \\big|d_i^{\\lfloor",
    "\\delta_i\\rfloor}(f - g)(x_1+u_1h_1,\\ldots , x_i+\\tau u_ih_i , x_{i+1},\\ldots , x_d)\\\\ & & -d_i^{\\lfloor \\delta_i\\rfloor}(f - g)(x_1+u_1h_1,\\ldots , x_i\\ldots , x_d)\\big|d\\tau\\big]^2dx\\bigg)^{1/2}du\\bigg]^2\\end{aligned}\\ ] ]    and @xmath629 ^ 2.\\end{aligned}\\ ] ] when @xmath616 , @xmath630 so , @xmath631 let us now find some @xmath342 in @xmath343 giving a sharp upper bound for @xmath632 let @xmath633 and choose @xmath634 in @xmath343 , with @xmath635 for every @xmath413 . since @xmath636 , @xmath637 so @xmath638 moreover , it is easy to see that @xmath639 and hence @xmath640 since @xmath641 when @xmath401 , this ends the proof of corollary [ vitessesanisotrop ] ."
  ],
  "abstract_text": [
    "<S> @xmath0considering two independent poisson processes , we address the question of testing equality of their respective intensities . </S>",
    "<S> we first propose single tests whose test statistics are @xmath1-statistics based on general kernel functions . </S>",
    "<S> the corresponding critical values are constructed from a non - asymptotic wild bootstrap approach , leading to level @xmath2 tests . </S>",
    "<S> various choices for the kernel functions are possible , including projection , approximation or reproducing kernels . in this last case </S>",
    "<S> , we obtain a parametric rate of testing for a weak metric defined in the rkhs associated with the considered reproducing kernel </S>",
    "<S> . then we introduce , in the other cases , an aggregation procedure , which allows us to import ideas coming from model selection , thresholding and/or approximation kernels adaptive estimation . </S>",
    "<S> the resulting multiple tests are proved to be of level @xmath2 , and to satisfy non - asymptotic oracle type conditions for the classical @xmath3-norm . from these conditions </S>",
    "<S> , we deduce that they are adaptive in the minimax sense over a large variety of classes of alternatives based on classical and weak besov bodies in the univariate case , but also sobolev and anisotropic nikolskii - besov balls in the multivariate case .    , </S>"
  ]
}