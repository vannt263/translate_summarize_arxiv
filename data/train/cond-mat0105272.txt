{
  "article_text": [
    "realistic simulations of molecular dynamics and other dynamic many - particle systems demand increasingly larger models .",
    "calculations on these large models can be distributed over several processors of a parallel computer to improve performance .",
    "an excellent review of the state - of - the - art of parallel atomistic simulations has recently been published by heffelfinger  @xcite . according to this work , and to the best of our knowledge , spatial decomposition of the simulation cell",
    "is done almost exclusively by partitioning into cubic domains of equal size , each of which is assigned to a processor .",
    "exceptions to this rule are earlier work by esselink and hilbers  @xcite and chynoweth et al .",
    "@xcite , who use a 2d decomposition motivated by the square mesh topology of their parallel machine . in case of density fluctuations ,",
    "load imbalance between the processors might occur ; here , we limit ourselves to homogeneous systems with a uniform density , such as bulk materials or liquids . other methods",
    "are necessary for heterogeneous systems such as proteins in vacuum or stellar systems . in homogeneous many - particle systems , the major source of inefficiency inherent to",
    "the domain decomposition approach lies in the fact that particles interact over some distance , so that in particular particles near the surface of these domains interact with particles in neighbouring domains .",
    "these particles near the surface thus cause communication with neighbouring processors , redundant calculations , or both . for brevity",
    ", we call this entire extra work the communication overhead . in the case",
    "that the interaction range is much smaller than the lateral size of the domains , the communication overhead will roughly scale with the surface area of the domain .",
    "hence , the optimal domain shape for many - particle systems with a uniform density and a short - range potential is a space - filling shape with minimal surface - to - volume ratio .",
    "this paper is organized as follows .",
    "first , we explore domain shapes that are derived from simple - cubic ( sc ) , body - centered - cubic ( bcc ) and face - centered - cubic ( fcc ) lattices .",
    "we determine their properties with respect to their use in parallel processing and discuss several implementation details .",
    "we then apply these domain shapes in a representative many - particle simulation : the _ sillium _ model of amorphous silicon , as proposed by wooten , winer and weaire",
    ". finally , we present our conclusions .",
    "in this section , several domain shapes are discussed , regarding their properties relevant for parallel processing . all lengths and distances",
    "are measured in fractions of the system to be simulated , which thus by definition has unit length edges .",
    "the domains assigned to each processor are equal in shape and size , and consequently have a volume of @xmath0 where @xmath1 is the number of processors .",
    "the following discussion assumes a cubic simulation cell , but extension to other regular - shaped simulation cells is straightforward .",
    "the interaction range ( distance over which particles exert forces ) equals @xmath2 , where @xmath3 .",
    "relevant for our purpose is the volume of the _ halo _ : the region outside the domain but within a distance @xmath2 .",
    "particles in this halo interact with those inside the domain , causing communication overhead .",
    "the most straightforward three - dimensional division of a cube into identical domains is a division into @xmath4 smaller cubes , with @xmath5 a positive integer .",
    "the resulting cubic domains have an edge length of @xmath6 .",
    "the volume @xmath7  of the halo with radius @xmath2 around each domain equals @xmath8    the first term is dominant and equal to @xmath2 times the surface area of the domain .",
    "the second and third terms correspond to the extra volume of the halo located near the edges and corners of the domain , respectively . in simulations with short - range interactions as discussed here , usually @xmath9 , so that these terms are small compared to the first .    in the limit of very short - range interaction",
    "our problem reduces to the well known kelvin problem , which is to find a partitioning of space with minimal surface area .",
    "kelvin  @xcite conjectured that the optimal solution is the voronoi cell of the bcc lattice , slightly curved to satisfy plateau s",
    "rules  @xcite , but weaire and phelan  @xcite produced an even better partitioning , based on two different cells , and related to the @xmath10-tungsten structure .",
    "we limit ourselves to proposing partitionings that can be shown to be better than sc and that can be implemented in a relatively simple way .    in the case of sc , the surface area is equal to @xmath11      given that we strive for a small surface - to - volume ratio , it is natural to investigate sphere packings . in one of the better sphere packings ,",
    "the spheres are located on the sites of a body - centred - cubic ( bcc ) lattice , with spheres at the corners and the centres of cubic cells .",
    "the bcc unit cell is displayed in figure  [ fig : bcc](a ) .",
    "each unit cell adds two sphere centres to the lattice , as only one corner point is part of the unit cell ; the other seven corner points are considered part of neighbouring cells . by repeating this unit cell the bcc lattice",
    "is generated .",
    "the lattice is then rescaled , such that the length of the edges of a unit cell becomes @xmath12 .",
    "the domain of a processor is formed by the voronoi cell of a lattice point , i.e. , the space closest to that point .",
    "the model cube can now be divided into @xmath13 voronoi cells , as generated by the bcc lattice .",
    "it turns out that each voronoi cell is a truncated octahedron , as shown in figure  [ fig : bcc](b ) .",
    "this is also the shape that kelvin proposed as a solution to the kelvin problem .",
    "each truncated octahedron generated by the bcc lattice fits into a cube with edge length @xmath12 .",
    "each of the six square faces has a surface area of @xmath14 and each of the eight hexagonal faces has a surface area of @xmath15 .",
    "this results in a total surface area of @xmath16 which , after substitution of @xmath17 , gives @xmath18 this is over eleven percent better than for sc .    [",
    "cols=\"^,^ \" , ]",
    "we have proposed two space partitionings , based on voronoi cells of the bcc and fcc lattices , that can be used in parallel particle simulations with uniform density and short - ranged interactions .",
    "the advantage of these new partitionings is two - fold : ( i ) they reduce the communication volume by about eleven percent compared to the commonly used sc partitioning ; ( ii ) they extend the range of possible processor numbers , so that now we can use , among others , all powers of two as a number of processors .",
    "these two partitionings are of practical use , because they are almost as easy to implement as sc ."
  ],
  "abstract_text": [
    "<S> in a common approach for parallel processing applied to simulations of many - particle systems with short - ranged interactions and uniform density , the simulation cell is partitioned into domains of equal shape and size , each of which is assigned to one processor . </S>",
    "<S> we compare the commonly used simple - cubic ( sc ) domain shape to domain shapes chosen as the voronoi cells of bcc and fcc lattices . </S>",
    "<S> the latter two are found to result in superior partitionings with respect to communication overhead . </S>",
    "<S> other domain shapes , relevant for a small number of processors , are also discussed . </S>",
    "<S> the higher efficiency with bcc and fcc partitionings is demonstrated in simulations of the sillium model for amorphous silicon .    </S>",
    "<S> parallel computing , particle simulations , space partitioning </S>"
  ]
}