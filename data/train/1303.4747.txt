{
  "article_text": [
    "[ intro ]    observations of cosmic microwave background ( cmb ) temperature anisotropies as well as polarization @xcite can be used to uncover the physics of the early universe e.g. of cosmic inflation @xcite .",
    "however , calculations of power spectra of cmb anisotropies and polarization @xcite involve making a number of assumptions e.g. about the reionization history of the universe , the equation of state of dark energy etc .",
    "it is also usually assumed that the primordial power spectrum of scalar metric perturbations ( denoted by spps in this work ) is a power law ( with a small running ) .",
    "one can then use the cmb observational data to put constraints on the values of various cosmological parameters @xcite including the ones specifying spps ( usually denoted by @xmath0 , @xmath1 etc ) . since this procedure leads to reasonable   values of these parameters",
    ", it is often said that a power law spps is consistent with the observed data .",
    "but it is worth noticing that this is just an assumption .",
    "cosmic inflation is the most actively investigated paradigm for explaining the origin of anisotropies in cmb sky as well as the large scale structure of the universe .",
    "the simplest versions @xcite of inflationary models give a smooth , nearly scale - invariant ( tilted red ) spps .",
    "but there are other models which are capable of giving more complicated forms of spps ( abnormal initial conditions , multifield models , interruptions to slow roll evolution , phase transition during inflation , see e.g. @xcite ) . are these models ruled out by the present data ?",
    "thus , even though power law spps is consistent with the data , the assumption of a power law pps ( with small running ) is just that : a well motivated assumption .",
    "it is worth checking , how the models in which spps is not just a simple power law with a small running fare against the present available data .",
    "this can be done in various ways : e.g. one could try to redo cosmological parameter estimation with the actual form of spps left free ( see e.g. @xcite ) .",
    "another option is to work with inflationary models which lead to features in spps and redoing parameter estimation for those models ( see e.g. @xcite ) .",
    "this exercise illustrates that ( i ) models in which spps is not this simple also do fit the data , ( ii ) very often , with these models , one can get a better fit to data than power law with small running .",
    "given this situation , a reasonable possibility is to try to directly deconvolve spps from observed cmb anisotropies ( i.e. @xmath2s ) .",
    "previous attempts  @xcite at doing so seem to suggest the existence of features in spps ( the statistical significance of which is still being assessed  @xcite ) , e.g. , a sharp infrared cutoff on the horizon scale , a bump ( i.e. a localized excess just above the cut off ) and a ringing ( i.e. a damped oscillatory feature after the infrared break ) .",
    "this is consistent with many existing models of inflation and this has also motivated theorists to build models of inflation that can give large and peculiar features in primordial power spectrum ( see @xcite ) .",
    "given the fact that primordial power spectrum of scalar metric perturbations is the only cosmological correlation whose effect is , at this stage , observable in the universe ( primordial non gaussianity is yet to be detected in cmb data , so are b modes of polarization of cmb due to inflationary gravitational waves ) , it becomes important to settle this issue of possible existence of features .    in the present work ,",
    "we try a new method of probing the shape of primordial power spectrum : the maximum entropy method ( mem ) .",
    "we begin in [ decov ] by broadly describing the problem and its various attempted solutions .",
    "then , in [ algo ] , we describe in detail the algorithm that we have used .",
    "this is followed by [ cmbkernel ] in which we apply the algorithm to binned cmb temperature anisotropies data .",
    "we conclude in [ discussion ] with a discussion of salient features , limitations and future prospects for the work . in the appendix [ test ]",
    ", we present the results of applying the method on a toy problem and in the process illustrate the use of the algorithm .",
    "we address the issue of reconstructing the shape of the spps by attempting to directly solve the ( noisy ) integral equations giving the cmb angular power spectrum using mem .",
    "the observed cmb @xmath3 angular power spectrum is given by ( see e.g. @xcite ) : @xmath4 p_{\\phi } ( k )   ~~+~~ { c_{\\ell}^{tt}}_{\\mathrm{noise}}\\ ] ]    here , @xmath5 is the multipole moment , @xmath6 is the wave number and the quantity in the square brackets is the radiation transfer function ( @xmath7 denotes the value of conformal time today ) and @xmath8 is the power spectrum of the scalar metric perturbation in newtonian gauge ( often called bardeen potential , @xmath9 ) . assuming a given set of values of background cosmological parameters , the radiative transport kernel can be found ( see [ cmbkernel ] ) , we can then formulate the problem we are dealing with as the solution of a set of integral equations i.e. as an inverse problem .",
    "the scalar primordial power spectrum is the power spectrum of comoving curvature perturbation : @xmath10    here @xmath11 is the mode function   rendering @xmath12 dimensionless .",
    "] of the comoving curvature perturbation on super - hubble scale ( when it has become frozen ) . for a power law spps , @xmath13    in matter dominated universe ( at the time of recombination ) , at linear order in perturbation theory , @xmath14 , so , for a power law pps , @xmath15 should be ( in @xmath16 ) @xmath17 \\left ( \\frac{k}{k_0}\\right)^{n_s - 1 } ~.\\ ] ]    we shall now replace @xmath18 by a general function @xmath19 and try to find this function @xmath19 .",
    "we thus have    @xmath20 f(k)\\ ] ]    with @xmath21    and so the function @xmath19 shall have values of the order of magnitude of @xmath22",
    ".    given the temperature radiation transfer function ( @xmath23 ) , the theoretical @xmath24 can be found from eq [ [ fundaeqcont ] ] provided , we know the spps . the @xmath5 range for which we wish to evaluate the transfer function and the corresponding @xmath2s goes from @xmath25 to @xmath26 .",
    "the typical behaviour of the function    @xmath27    [ htbp ]    is shown in the fig ( [ glk ] ) ( with @xmath28 chosen such that the integral in the definition of @xmath2 can be evaluated to a high enough accuracy ) .",
    "for every given @xmath5 , the radiation transport kernel is a highly oscillatory function of the wavenumber @xmath6 .",
    "but for any @xmath5 , it has significant ( i.e. non - negligible ) values only within a small range of @xmath6 values .",
    "the brightness fluctuations roughly go as @xmath29 $ ] ( where @xmath30 is spherical bessel function while @xmath31 is the conformal time at the epoch of recombination ) , thus the minimum value of @xmath5 sets a minimum value of @xmath6 at which the kernel takes up non - negligible values .",
    "this procedure tells us that since the radiation transfer function is negligible for @xmath32 , no matter how much power is there in spps at very small @xmath33values , the cmb anisotropies can not be used to probe the spps at these ( very large scales ) .",
    "this sets the @xmath34 below which we can not probe the spps .",
    "similarly , given the fact that we have observations only till a maximum value of @xmath5 , this sets the maximum value of @xmath6 up to which we need to sample the kernel : thus , the smallest possible angular resolution of a cmb experiment shall set the lmax that we can probe which shall set a @xmath35 , i.e. spps at scales smaller than this scale can not be probed by cmb experiments .",
    "thus , @xmath25 determines @xmath34 while @xmath36 determines @xmath35 . within this range ,",
    "one discretizes the @xmath33space in such a way that the transfer function can be sampled sufficiently well and the above integral can be performed to the desired accuracy .",
    ", this number is 6200 , thus our @xmath37 matrix shall have dimensions @xmath38 . ]",
    "apart from this consideration , the actual observed @xmath2s are also noisy ( due to cosmic variance , instrumental noise and the effect of masking the sky ) .",
    "thus eq ( [ fundaeqcont ] ) can be written as a set of linear equations @xmath39    where @xmath40 is the number of bins in @xmath33space and @xmath41 is the noise term .",
    "thus the problem we wish to solve is : given the matrix @xmath42 , the few observations ( @xmath2s ) , the moments of the random variables @xmath41 , how can we find the set of numbers @xmath43 ? in this paper , we shall use the binned cmb data to find spps .",
    "the number of ( binned and hence uncorrelated ) data points ( wmap ) is @xmath44 ( call it @xmath45 ) . to sample the kernel satisfactorily",
    ", we divide the @xmath6 space into @xmath46 points ( @xmath40 ) .",
    "thus , we have a problem with a set of @xmath44 noisy linear equations and @xmath46 unknowns to be determined .",
    "recovering the primordial power spectrum @xmath43 from the observed @xmath47 can be casted as a bayesian inversion problem in the following way .",
    "the posterior probability @xmath48 of obtaining the primordial power spectrum @xmath43 given a kernel @xmath49 and observed @xmath47 is given by :    @xmath50    where @xmath51 is the likelihood and @xmath52 is the prior probability . for our case",
    "the denominator ( evidence ) works just a normalization and we can ignore it .    for the case of gaussian noise s is not gaussian , we proceed pretending the noise to be gaussian .",
    "this is justified because by the central limit theorem : since the chi - squared distribution is the sum of @xmath45 independent random variables with finite mean and variance , it converges to a normal distribution for large @xmath45 . ]",
    "the likelihood function can be written as @xmath53\\ ] ] where @xmath54 for the case when the noise covariance matrix is diagonal .    since for our problem",
    "the number of unknowns i.e. , @xmath43 are far more than the number of known i.e. , @xmath55 therefore ordinary chi square minimization is of no use since it can make the chi square too low   parameters , the presence of noise shall ensure that @xmath56 shall be a sum of @xmath45 normalized gaussians . ] . in order to avoid chi square taking unphysical values",
    "we need some form of regularization in the form of prior . in place of maximizing the likelihood function",
    "we maximize the posterior probability .",
    "it has been a common practice to consider the following form of prior for any regularization problem @xmath57\\ ] ] where @xmath58 is the regularization parameter and @xmath59 is the regularization function .",
    "there have been many form of regularization function like quadratic form etc .    in the present work we use an entropy function @xmath60 as a regularization function which is defined in the following way    @xmath61\\ ] ]    where @xmath62 is a parameter which parametrizes the entropy functional we use .    with the regularization function",
    "the posterior probability distribution can be written as    @xmath63 * \\exp[-\\lambda s/2 ] = \\exp[-(\\chi^2+\\lambda s ) ] = \\exp[-m(f_k)]\\ ] ]    where @xmath64    maximum entropy method is a particular ( nonlinear ) inversion method . here",
    "the regularization function @xmath65 is non - quadratic so that the equations to be dealt with to solve the optimization problem shall turn out to be non - linear .",
    "without such a maximum entropy ( me ) constraint , the inversion problem is ill - posed ( since the data can be satisfied by an infinity of primordial power spectra ) .",
    "the condition that the entropy be a maximum selects one among these .",
    "there exist , in the literature , various arguments justifying the use of mem over other ways of inversion ( often using arguments from information theory   ) , at this stage , we just treat it as just another nonlinear version of the general regularization scheme .",
    "[ algo ]    so , the problem that we wish to solve involves a highly under - determined system of linear equations . as was mentioned in the last section , one way in which we can attempt to solve",
    "this problem is to formulate it as a problem involving the optimization of a non - quadratic function ( which will require solving a set of non - linear equations ) subject to a constraint .",
    "since the number of unknowns is so large , we have to solve the corresponding constrained non - linear optimization problem in a very large dimensional space .",
    "also , we have other constraints that we need to take care of e.g. the components of @xmath66 are positive quantities ( since @xmath66 is a power spectrum ) , so the optimization algorithm that we use must not cause the components of @xmath66 to become negative ( this requirement rules out methods such as the steepest ascent ) .",
    "similarly , since the the objective function is quite different from a pure quadratic form , methods such as conjugate gradient method are not very useful .    experience has shown that one of the strategies which work ( despite being complicated ) is the following : instead of searching for a minimum in a single search direction ( e.g. in steepest ascent method ) , one searches in a small- ( typically three- ) dimensional subspace .",
    "this subspace is spanned by vectors that are calculated at each point in such a way as to avoid directions leading to negative values .",
    "the algorithm that we use is based on the one developed by skilling and bryan @xcite and is sometimes referred to as the cambridge maximum entropy algorithm .",
    "it has been extensively used in not only radio astronomy but also in other fields . here",
    "we quickly review this algorithm for the sake of completeness .",
    "the problem to be solved involves finding a set of @xmath67 ( with maximum entropy ) from a data set @xmath68 . for any @xmath43 ,",
    "let    @xmath69    we shall use the following definition of entropy ( the non - linear regularization function ) @xmath70 = - \\sum_k f_k \\ln(f_k / ea)\\ ] ] here , @xmath62 is a fixed number ( sometimes called the default ) that sets the normalization of @xmath66 .",
    "notice that @xmath71 .",
    "this gives , ( since @xmath62 is fixed ) , @xmath72    telling us that @xmath73 and @xmath74 .",
    "it is easy to see that entropy surfaces are strictly convex .",
    "also , the expression for the various derivatives of the entropy tell us that the solution @xmath75 is the global maximum of entropy , this fact shall be important later .",
    "the measure of misfit that we shall use ( in order to use the data ) is the chi - squared function    @xmath76    from which we get , the gradient of @xmath77    @xmath78    and the hessian @xmath79    for a linear experiment , the surfaces of constant chi - squared are convex ellipsoids in n - dimensional space .",
    "the largest acceptable value for @xmath56 at 99 percent confidence is about @xmath80 ( with @xmath45 being the number of observations ) , see @xcite .",
    "as the above equations show , quantities such as gradient of @xmath77 and hessian of @xmath77 can be easily evaluated ( though finding the hessian of @xmath77 is the one of the most computationally expensive tasks since the matrix @xmath81 is @xmath82 and hessian of @xmath77 shall be @xmath83 matrix ) .    at every iteration , instead of searching for the maximum of @xmath59 and minimum of @xmath77 along a line , we search in an @xmath84 dimensional subspace of the parameter space .",
    "so , instead of @xmath85    we shall have ( with @xmath86 being @xmath84 search directions ) @xmath87    sufficiently near any point , every function can be approximated by a quadratic function ( provided the higher order terms in the taylor expansion can be ignored ) .",
    "so , within the subspace we shall model the entropy and chi - squared by @xmath88 where @xmath89 and @xmath90 are quadratic @xmath91    which correspond to the first three terms in the taylor series expansion of @xmath92 and @xmath93 .",
    "the first order term in the taylor expansion of @xmath59 is @xmath94    which tells us what @xmath95 should be .",
    "similarly , @xmath96 , @xmath97 and @xmath98 can be found : @xmath99    thus , if we know the basis vectors , we can find the quadratic functions @xmath89 and @xmath90 .",
    "obviously , the above definitions shall not be valid to arbitrary distances from the point in question .",
    "the quadratic models are reliable only in the vicinity of the current @xmath66 where cubic and higher powers can be neglected .",
    "thus , the step size at each iteration must be such that @xmath100    for some @xmath101 .",
    "we thus need to define the concept of distance in this abstract space . recall that this means we need to define a metric @xmath102    note that the metric @xmath103 is different from the function @xmath97 defined by eq .",
    "( [ defs ] ) . experience",
    "( see @xcite ) has shown that the following definition of distance works well @xmath104    this needs to be compared with the expression for the hessian matrix of entropy ( notice that @xmath105 ) .",
    "it is straightforward to show that @xmath106    while choosing @xmath107 to be @xmath108 of @xmath109 works well ( see @xcite ) .",
    "the algorithm works in the following way : at every iteration , when we are at a point in the @xmath66 space , one considers a distance region s.t .",
    "the quadratic model is a good approximation in that region .",
    "we now find a subspace and within this subspace , we try to find the place where    1 .",
    "@xmath89 is maximum , 2 .",
    "@xmath90 equals some @xmath110 , and , 3 .",
    "the distance of this new point from the old point is smaller than @xmath101 .",
    "so , how do we decide the basis vectors which span the subspace ? one of our aims is to find the maximum of entropy on the surface of ellipsoid corresponding to @xmath111 .",
    "so , naturally , the direction of gradient of entropy must be one of the basis vectors .",
    "since the metric in the space of interest is not cartesian , there shall be a distinction between contravariant and covariant components of vectors in the space . since the `` position vector '' of any point is @xmath112 , a contravariant vector , gradient such as @xmath113 is going to be a covariant vector .",
    "so the first ( contravariant ) basis vector is @xmath114    the meaning of this direction is easy to understand by recalling its equivalent in usual cartesian space . in the usual situation , @xmath115 ( i.e. if we are at any point , and we go in the direction @xmath116 by a distance of @xmath117 , the change in the value of the function is @xmath118 ) .",
    "it is obvious from this expression that when @xmath119 is parallel to the direction of gradient , the change @xmath120 is maximum .",
    "thus , to maximize the change in @xmath66 , we shall move in the direction parallel to @xmath121 so that @xmath122    this equation should be compared with the definition of the first basis vector , eq [ [ vec_1 ] ] ( and since the kronecker delta is the metric in a cartesian space , the two equations are equivalent ) .",
    "thus , the first basis vector tells us the direction in which the entropy change per unit distance is maximum .",
    "similarly , another basis vector could be @xmath123    since we wish to change the @xmath56 at every iteration so that we eventually reach the @xmath111 surface .",
    "if we find what the two search directions ( defined above ) become after incrementing by @xmath124 , the direction @xmath125 shall stay within the subspace spanned by @xmath125 and @xmath126 but the direction @xmath126 shall go out of the subspace ( see @xcite ) .",
    "this suggests that we choose more basis vectors such as @xmath127    experience has shown that a family of three or four such search directions gives quite a robust algorithm for solving the problem . in our problem , we chose the third search direction to be @xmath128    where , the following eqs define the lengths @xmath129 and @xmath130 which are the gradient vectors @xmath131    our experience has shown that putting the factors of @xmath129 and @xmath130 in the definition of the third basis vector improves the speed of convergence of the answer .",
    "once we have found the subspace ( by finding the basis vectors in the space of all @xmath66s ) , we proceed as follows : we now wish to find the step , the coefficients @xmath132 in eq ( [ step ] ) . to do this ,",
    "we shall solve a corresponding constrained optimization problem in the @xmath84 dimensional subspace ( as was stated in the previous subsection , we worked with @xmath133 , but we shall continue to explain the details for a general @xmath84 ) .",
    "since the functions @xmath89 and @xmath90 are quadratic , the problem in the subspace is much simpler : it is a simple problem of quadratic programming ( quadratic objective function with quadratic constraint ) .",
    "the only additional complication is that the quadratic model is not valid to arbitrary distances from the original point , so we need to satisfy an additional distance constraint .",
    "let us begin by recalling that both the matrices @xmath134 and @xmath135 are real - symmetric . also , the matrix @xmath134 is positive definite .",
    "the reason is as follows : the way we have defined the metric on the space ( see eq ( [ metric ] ) ) , @xmath136    where in the last step we used eq ( [ equality ] ) .",
    "so , it is clear that @xmath97 is a positive definite matrix ( which implies that all its eigenvalues are positive ) .",
    "thus if one of the eigenvalues of @xmath97 is a small positive number , numerical errors can cause it to become negative . in our implementation of the algorithm",
    ", we choose to ignore any directions which are defined by eigenvalues which are too small .",
    "additional simplification occurs if we simultaneously diagonalize the two matrices @xmath134 and @xmath135 .   and",
    "@xmath137 are real symmetric matrices and @xmath137 is positive definite , then there exists an invertible matrix @xmath138 s.t . @xmath139 and @xmath140 is diagonal .",
    "the diagonal entries of @xmath62 are the roots of the polynomial @xmath141 .",
    "notice that this is different from finding a basis in which both are diagonal . here ,",
    "if @xmath137 is chosen to be identity matrix , then @xmath138 is orthogonal and @xmath140 is the same as @xmath142 .",
    "this leads to the unique diagonal representation of the matrix ( with the eigenvalues as the diagonal values ) .",
    "recall that the eigenvalues of a matrix @xmath143 are the solutions of the equation @xmath144 . there exist stable numerical algorithms to achieve this ( see e.g. page 463 of @xcite ) which take in the two real symmetric matrices @xmath62 and @xmath137 and returns the ( non - singular ) matrix @xmath138 and the diagonal matrix @xmath140 . ]    after simultaneous diagonalization , within the subspace , the quadratic model functions @xmath145 and @xmath146 are given by @xmath147    the quantities @xmath95 etc are now defined in terms of the new basis vectors ( but the same old definitions ) .",
    "since this causes the function @xmath97 to become a kronecker delta , the distance constraint eq .",
    "looks like @xmath148    we chose the coefficient on the rhs to be @xmath149 and we verified that the actual value of this number is unimportant .",
    "typically , the function @xmath146 is such that all its eigenvalues are ( also ) positive , then , the minimum value of the function @xmath146 in the subspace ( where the above definitions work ) is @xmath150    thus , no matter what the global aim @xmath151 is , at a given iteration , within the subspace , we can not get to any values below @xmath152 .",
    "in fact , even trying to achieve @xmath152 is not a great idea since in that case we shall not use any information about @xmath145 .",
    "the real challenge in the subspace is to satisfy the distance constraint .",
    "many different elaborate tricks have been mentioned in the literature to do this .",
    "we choose to not worry about getting a quick answer , hence we do the following : in order to ensure that the distance constraint always gets satisfied ( i.e. we do not go too far from the present location in just one step ) , we shall choose to have a @xmath153 which is not too different from @xmath154 ( the present value of @xmath56 ) .",
    "we thus choose @xmath155    with @xmath156 chosen to be a small number ( e.g. @xmath157 ) .",
    "this causes the algorithm to take very small `` baby steps '' towards the answer .",
    "numerical experience has shown that as far as our problem is concerned , this is good enough .",
    "of course , the actual value of @xmath156 or @xmath151 chosen is not important as long as the distance constraint gets satisfied .    the problem in the sub space is thus simplified to finding the point @xmath158 such that the function @xmath145 is maximum subject to the constraint that @xmath159 ( and an additional constraint that the distance constraint must get satisfied ) .",
    "the technique of lagrange s undetermined multiplier is useful here : we wish to find the point on the curve @xmath160 where @xmath145 is maximum , to find the desired point , we consider the set of points at which all the partial derivatives of the function    @xmath161    ( for an undetermined @xmath162 ) vanish .",
    "for any @xmath162 , such points are given by @xmath163    so , for every value of @xmath162 , find the value of @xmath158 and then the function @xmath146 : we are after that value of @xmath162 which leads to @xmath159 so we look for a solution of the equation @xmath164 .",
    "the function @xmath165 is a monotonically increasing function of @xmath162 , see fig .",
    "( [ c_alpha ] ) . since the function @xmath166 often happens to be a quickly changing function of @xmath162 ( especially while it is changing its sign )",
    ", the solution for @xmath162 needs to be found to a high tolerance level .      in solving the constrained optimization problem ,",
    "one fact which becomes important is the following : at the point at which the constrained optimization problem gets solved , the gradient vectors of the two functions become parallel .",
    "thus , if we find the unit vector in the direction of gradient of entropy and in the direction of gradient of chi squared function , the dot product of these two unit vectors ( defined using the entropy metric ) must become negligible as we head towards the point at which the constrained optimization problem gets solved .",
    "the unit vectors in the directions of gradients are ( with @xmath129 and @xmath130 defined previously ) @xmath167    we thus expect the angle @xmath168    to become too small ( compared to a unit radian ) as the algorithm proceeds ( fig([evol ] ) ) .",
    "@xmath169{evol.eps }   \\includegraphics[width=2.3 in , angle = -90]{theta.eps } \\end{array}$ ]",
    "in this section , we shall ( i ) test the formalism presented in the previous section by trying to recover a featureless as well as feature - full spps from simulated noisy cmb data and ( ii ) apply the algorithm to actual wmap 7 year binned tt angular power spectrum @xcite to recover the primordial power spectrum .",
    "thus , to begin with , we shall find out the radiation transfer function for the simplest set of assumptions , inject a featureless spps and get noise - free @xmath170 ( which we shall refer to as theoretical @xmath2s ) .",
    "next we shall add noise to these pure @xmath2s .",
    "first , we need to set the values of the various cosmological parameters and get the corresponding radiation transfer function .",
    "this can be done by making use of the codes such as cmbfast @xcite , camb @xcite or gtfast @xcite .",
    "the results in this section are got from transfer function found using the code gtfast which itself is based on cmbfast ( version 4.0 ) .",
    "it is important to notice that since in this work we shall only use the @xmath3 data , so , we only calculate the temperature radiation transfer function . to find out the transport kernel",
    ", we assume that the universe is spatially flat and dark energy is a cosmological constant ( i.e. we have a spatially flat @xmath171cdm universe ) and set the values of the cosmological parameters to their wmap nine year values @xcite ( wmap9 + bao + h0 ) : the values of various parameters to be fed into the code gtfast are given in table [ cosmo_para_1 ] .",
    "we also assume that there are no tensor perturbations to the metric .",
    "we use peebles recombination ( rather than using recfast ) and assume that the primordial fluctuations are completely adiabatic . finally , we shall not correct the transfer function for lensing of cmb , sz effect or other effects that cause secondary anisotropies of cmb .",
    "this shall give us the radiation transfer function from which we can easily evaluate the matrix @xmath81 .",
    "for the case we are dealing with , the matrix @xmath81 shall have dimensions @xmath172 .",
    "finally , we would like to state that the results one obtains and conclusions that one draws should better not depend on the exact values of these parameters .",
    "[ htbp ]    .the values of various parameters for the run .",
    "[ cols=\"<,<\",options=\"header \" , ]      we can now inject a test spps which is a power law with @xmath173 ( with @xmath174 and @xmath175k ) and get the corresponding theoretical @xmath2s , and add noise",
    ". the noise we add is dominated by cosmic variance at low @xmath5 ( less than 600 ) values while for high @xmath5 values , the noise is dominated by instrumental errors . fig ( [ unbinned ] ) shows the result of using the algorithm described in the previous section to recover the spps in the present case .",
    "the following points are worth noting :",
    "1 .   to get the result shown in fig ( [ unbinned ] )",
    ", we set the parameter @xmath62 in eq ( [ entropy_def ] ) to be @xmath176 .",
    "as was stated , the solution @xmath75 is the location of global maximum of entropy in the @xmath66 space . from @xmath177 it is clear that @xmath178 corresponds to @xmath12 being @xmath179 .",
    "thus , this value of @xmath62 corresponds to the situation in which @xmath180 is the solution with the maximum value of entropy .",
    "2 .   in an actual cmb experiment ( such as wmap )",
    "the amount of noise ( instrumental as well as that due to cosmic variance ) is not the same for all scales , which means that our data is not equally good for all values of @xmath6 .",
    "fig ( [ unbinned ] ) shows that at scales at which the noise is large ( very low and very high @xmath5 values which will correspond to very low and very high @xmath6 values ) , the recovered @xmath19 tends to approach the value @xmath62 , the recovery ( at these scales ) tends to be poor .",
    "thus , _ at scales at which the noise is too large ( or the kernel takes up negligible values ) , the recovery depends on what is the prior information we have about the solution_. thus the range of @xmath6 values in which we can recover the pps is too restricted .",
    "3 .   even at scales at which the noise is smaller ( and",
    "at which we hope to recover well ) , we can have wiggly artificial features in the recovered pps ( in the form of peaks and dips ) . in the recovered power spectrum there",
    "could exist three kinds of features : ( i ) those which are actually there in the injected pps ( which are not there in the present case ) , ( ii ) those which are not there in the pps but got introduced by the algorithm itself ( these shall change as we change @xmath62 ) and finally , ( iii ) those which are artifacts of the added noise ( a particular realization of the noise shall have outliers , if we consider different realizations of the noise , we shall get different recoveries ) .",
    "4 .   the scales at which we typically introduce features in the spps are roughly @xmath181 mpc@xmath182 to @xmath183 mpc@xmath182 . we would like the recovery to be good at these scales .",
    "if we have data till very large value of @xmath5 , and the noise at these large @xmath5 values is very low compared to the noise at @xmath5s corresponding to the above scales , the algorithm shall ignore the few data points with larger noise and try to only take the data at the other scales seriously .",
    "thus , if we wish to recover better at these scales we must focus on recovering the pps using only the data from the @xmath5 values corresponding to these scales . thus , _ having data till larger values of multipole moment with lesser noise may not help_.    [ htbp ]    [ htbp ]    [ htbp ]    [ htbp ]    in practise , the process of masking the sky causes the various @xmath2s to get correlated .",
    "the simplest situation in which we can hope to recover the spps is the one in which the the data points corresponding to different @xmath5 values are uncorrelated .",
    "this happens for the binned cmb data set ( which has data only for 45 @xmath5 values ) . to make use of the binned data",
    ", we also work with a binned kernel which is defined @xmath184    where @xmath185 is the number of @xmath5 values in the bin . by using this averaged kernel and applying the algorithm to simulated binned data ( with the added noise equal to the noise for wmap 7 year binned data ) ,",
    "we get the results shown in fig ( [ binned_diff_a ] ) ( this time we show the results for many @xmath62 values ) .",
    "we again get an answer which at scales at which the noise is large , tends to the value of the default ( i.e. @xmath62 ) while at scales at which the noise is relatively low , the recovery tends to fluctuate around the featureless injected signal . for a fixed value of @xmath62",
    ", the recovery at scales at which the noise is relatively lower shall be different if we consider different realizations of the noise .",
    "this is illustrated in fig ( [ binned_diff_realization ] ) : here the recovery shall be the same at scales with no data and shall be different at scales with data .",
    "the key question is whether we can recover features in the spps by this method .",
    "the fact that this can be done is illustrated in fig ( [ binned_bumpy ] ) : we just introduce a bumpy feature between the scales @xmath181 mpc@xmath182 to @xmath183 mpc@xmath182 and vary its height and see that unless the height of the bump is too small , the algorithm can recover it .",
    "of course if we introduce a feature at a scale at which the data is not good or at which the kernel takes up negligible values , the feature shall not be recovered .",
    "moreover , it is not surprising that the recovery is much better if the feature is more prominent .      in this sub - section",
    "we apply the algorithm to actual cmb data .",
    "we use wmap 7 year binned @xmath3 data set and use it to recover the spps . the result",
    "is shown in fig [ rec_binned_7 ] .",
    "the details of the recovery of course depend on the chosen value of the parameter @xmath62 . in the present context",
    ", the value of @xmath62 represents our a priori knowledge ( without using any data ) of how much we think should be the scalar fluctuation in the metric in the early universe .",
    "[ htbp ]    it may appear that if the conclusion depends on such an a priori knowledge , we may not get anything worthwhile .",
    "but the following fact is worth noting : it is seen that at scales at which the noise is lesser , even though the recovered @xmath12 depends on the value of @xmath62 chosen , this dependence is quite weak and quite predictable ( as we increase @xmath62 a lot or decrease it a lot , the recovery just `` stretches '' in the @xmath12 direction in the @xmath186 plane ) .",
    "an interesting exercise is this : if , without using the cmb data , we still knew that the amplitude of the scalar metric perturbations is ( roughly ) @xmath187 , then what can this method of deconvolution tell us about the spps ?",
    "fig ( [ a_as ] ) illustrates how the red tilt of the pps can be _ detected _ in such a case .",
    "one can keep on decreasing the value of @xmath62 and see what happens . in this context , the case of @xmath188 is very interesting since this corresponds to using another familiar definition of entropy , the recovery for this case is illustrated in fig ( [ rec_1 ] ) .",
    "what is interesting is that if we choose @xmath62 to be too small , we begin to get an ir cut - off not very different from the one reported in the literature previously ( see @xcite ) , but , we also get an apparent uv cut - off .",
    "moreover , such a small value of @xmath62 causes the artificial features to get stretched so much that we may not consider the reconstruction to be trustworthy in this case .",
    "in this work , we attempted to probe the amplitude and shape of scalar primordial power spectrum ( spps ) using the cmb data .",
    "we fixed the values of various cosmological parameters ( apart from the ones specifying the spps itself ) and formulated the problem as an inverse problem . to solve the inverse problem , we use the maximum entropy method which is a non linear regularization method . there",
    "exist many possible ways to employ the maximum entropy regularization , we use a particular definition of entropy and a particular algorithm to solve the corresponding constrained non - linear optimization problem in a very large dimensional parameter space .",
    "the way we have formulated the problem , there exists a parameter ( which we called @xmath62 ) whose value decides the location of global maximum of entropy in the space of all @xmath12s . in the absence of any data",
    ", the algorithm shall just send every initial guess to the global maximum of entropy . even in the presence of data ,",
    "the following is worth noting    1 .   at scales",
    "where 1 .",
    "we have noisy data ( so , little or no information ) , or , 2 .",
    "the kernel ( to be inverted ) takes up negligible values ( again too large or too small @xmath6 values ) , + the @xmath12 recovered by mem depends on the value of @xmath62 chosen ( as @xmath189 is the me solution ) , while at the scales where the data is good , we recover something which has comparatively lesser dependence on what @xmath62 we choose . 2 .   at scales at which the data is good ,",
    "the @xmath12 recovered by mem is consistent with a power law primordial power spectrum ( with any possibly small deviations which we can not say anything about at this stage ) .",
    "this can be seen by comparing fig ( [ rec_binned_7 ] ) with figs ( [ binned_diff_a ] ) and ( [ binned_bumpy ] ) .",
    "while the existence of any small deviations from power law behaviour can not be completely ruled out , this analysis reinforces our belief that any such possible deviations must be small .",
    "this is by no means the last word on the existence of features in spps , this is not even the last word on the use of mem for this purpose.the implementation of our algorithm to this problem till now does not seem to give any reason to believe that there are any serious deviations from the power law .",
    "we would like to mention that this is not completely unexpected , even in the light of existing papers such as @xcite because the error bars at scales at which the features were recovered in those works are very large : the maximum entropy method can not claim any features at scales where the error bars are so large .",
    "this analysis shows that _ at scales at which the cmb data is trustworthy , the primordial power spectrum of scalar metric perturbations is , to a very good approximation , a power law_.    in future , one can look at the following prospects",
    ". we should be able to solve this problem of possible existence of features in spps without assuming the values of other cosmological parameters ( i.e. without formulating this problem as a simple inversion problem ) .",
    "even in the present formulation , there may be ways of combining results from different values of @xmath62 to get a better recovery .",
    "one may wish to use the actual wmap likelihood ( or rather , the corresponding @xmath190 ) as a measure of misfit , but this is not easy in the way we have attempted to solve the problem ( we need to know the @xmath56 and its first two derivatives ) .",
    "also , we have lost a lot of information in the process of binning the kernel and working with the binned , uncorrelated data .",
    "we would like to use all that lost information .",
    "similarly , we have only used the @xmath3 angular power spectrum of cmb , we would also like to use the polarization spectra to probe the spps .",
    "we may also need to post - process the recovered spps to get more useful information .",
    "another interesting possibility worth exploring is the connection of maximum entropy deconvolution with other ways of deconvolution ( e.g. richard lucy deconvolution ) .",
    "[ test ]    the main text described the material necessary to employ the maximum entropy inversion in any circumstance .",
    "the following points need to be noted ( these are just tried and tested facts about the algorithm , many of which are illustrated here for the case of a toy problem shown in fig([toy_prob ] ) , whose solution is given in fig ( [ ini_guess ] ) ) :          * if we did not have any data available , the optimization problem would have involved maximizing entropy subject to no constraints . in such a scenario ,",
    "the solution we should get must be @xmath75 as that is where the global maximum of entropy is . *",
    "if the value of @xmath62 is such that the @xmath56 of the global maximum of entropy is smaller than @xmath151 , then @xmath75 is itself the desired solution since `` the data are too noisy for any information to be extracted '' ( see the last paragraph of page 113 of @xcite ) . *",
    "it is not a surprise at all that choosing too small value of @xmath62 should lead to negative value for entropy ( the fact that depending upon the choice of @xmath62 , sometimes we could be at locations in the parameter space with negative value of @xmath59 has no impact on the solution of the problem ) , see fig ( [ effec_a ] ) . * in eq ( [ qeq ] )",
    ", @xmath191 corresponds to the unconstrained maximization of @xmath145 irrespective of @xmath146 .",
    "if we are too close to the global maximum of entropy ( @xmath75 ) , the value of @xmath162 required to solve the constrained optimization problem in the subspace ( for @xmath192 defined by eq ( [ qeq ] ) ) shall become too large .",
    "in this situation , it may be difficult to numerically find any solution for @xmath162 .",
    "* as long as we do not stay too close to the global maximum of entropy ( so that numerical problems such as those stated in the previous point above do not turn up ) , the choice of the initial guess for running the algorithm is immaterial .",
    "that is , all the initial guesses shall lead to the same answer ( see fig ( [ ini_guess ] ) ) .",
    "* all the above problems can be easily avoided if we just choose a value of @xmath62 s.t .",
    "the @xmath56 of @xmath75 configuration is much higher than the @xmath56 of initial guess ( which better be more than @xmath151 ) .",
    "notice that this is not a requirement , just a trick .",
    "also , this does not help us in finding any unique preferable value of @xmath62 .",
    "* for many kernels the exact value of @xmath151 chosen does not matter as far as the recovered @xmath66 is concerned , as long as the final value of @xmath193 becomes sufficiently small compared to a unit radian , all recoveries with different final @xmath56 are almost the same .",
    "the @xmath56 of signal ( for a given realization ) shall just fluctuate around ( roughly ) @xmath45 , we have tested that if @xmath151 is set equal to @xmath194 , the recovery does not change .",
    "this happens to be true e.g. for the case of cmb kernel , the case of our interest .",
    "* the exact details of the shape of the final recovered solution does depend upon the actual value of @xmath62 chosen : the @xmath195 surface can be thought of as a closed ellipsoidal surface in the @xmath40 dimensional @xmath66-space while as we change @xmath62 , we define the line @xmath75 as being the location of global maximum of entropy for these different values of @xmath62 .",
    "this will of course mean that as we change @xmath62 , the place where the entropy is maximum on the @xmath195 surface shall also change .",
    "thus , as we continuously change @xmath62 , we shall get a family of recoveries ( see fig ( [ effec_a ] ) ) .",
    "so , the details of the recovered answer depends on the chosen value of this free ( or adjustable ) parameter .",
    "but since the global maximum of entropy is at @xmath75 , the value of @xmath62 represents the `` background '' ( i.e.a priori ) knowledge of how much the power in various bins is , without using any knowledge of data at all .",
    "* whether the recovery is good or bad , depends on the details of the kernel .",
    "for the case of cmb kernel , we have tested that the recovery is often quite good .",
    "* acknowledgment : * the authors acknowledge the use of wmap data and the use of codes such as cmbfast , gtfast and camb .",
    "the authors would also like to thank tarun souradeep ( iucaa , pune ) for reading through the manuscript and giving useful comments .",
    "gg thanks rajaram nityananda ( ncra , pune ) , mihir arjunwadkar ( cms , pune university , pune ) , abhilash mishra ( caltech , pasadena ) and ranjeev misra ( iucaa , pune ) for discussions at various stages of the work .",
    "gg thanks council of scientific and industrial research ( csir ) , india , for the research grant award no .",
    "10 - 2(5)/2006(ii)-eu ii .",
    "jp acknowledge support from the swarnajayanti fellowship , dst , india ( awarded to prof .",
    "tarun souradeep , iucaa , pune , india ) .",
    "starobinsky , phys .",
    "b * 91 * , 99 ( 1980 ) ; d. kazanas , ap .",
    "j. * 241 * , l59 ( 1980 ) ; a. h. guth , phys .",
    "d * 23 * , 347 ( 1981 ) ; a. d. linde , phys .",
    "b108 * , 389 ( 1982 ) ; a. albrecht and p. j. steinhardt , phys .",
    "48 * , 1220 ( 1982 ) .",
    "starobinsky , jetp lett .",
    "30 , 682 ( 1979 ) ; mukhanov v. f. , chibisov g. v. , 1981 , zhetf pis ma redaktsiiu , 33 , 549 ; hawking s. w. , 1982 , physics letters b , 115 , 295 ; a.a .",
    "starobinsky , phys .",
    "b 117 , 175 ( 1982 ) ; guth a. h. , pi   s.y . , 1982 , physical review letters , 49 , 1110 .",
    "a. linde , arxiv : hep - th/ 0503203 ; d. h. lyth and a. r. liddle , _ the primordial density perturbation _ , cambridge university press , 2009 ; d. baumann , arxiv : astro - ph/0907.5424v1 ; d. langlois , arxiv : astro - ph/1001.5259v1 ; l. sriramkumar , arxiv : astro - ph/0904.4584v1 .",
    "jayanti prasad and tarun souradeep phys .",
    "d * 85 * , 123008 ( 2012 ) ; kiyotomo ichiki1 and ryo nagata phys .",
    "d 80 , 083002 ( 2009 ) ; kiyotomo ichiki1 , ryo nagata1 , and junichi yokoyama1 phys . rev .",
    "d 81 , 083010 ( 2010 ) ;          ryo saito , junichi yokoyama , ryo nagata jcap06(2008)024 ; rajeev kumar jain , pravabati chingangbam , l. sriramkumar jcap 07 10 : 003 , 2007 .",
    "[ arxiv : astro - ph/0703762 ] ; sirichai chongchitnan , george efstathiou jcap 07 01 : 011 , 2007 .          a. shafieloo and t. souradeep phy .",
    "d * 70 * , 043523 ( 2004 ) ; r. sinha and t. souradeep phy .",
    "d * 74 * , 043518 ( 2006 ) ; a. shafieloo , t. souradeep , p. manimaran , p.k .",
    "panigrahi and r. rangarajan phy .",
    "d * 75 * , 123502 ( 2007 ) ; a. shafieloo and t. souradeep phy",
    "d * 78 * , 023511 ( 2008 ) ; gavin nicholson and carlo r. contaldi jcap07 ( 2009 ) 011 ; tocchini - valentini , d. , hoffman , y. and silk , j. mnras , 367 : 1095 - 1102 , 2006 .",
    "skilling , j. , and gull , s.f .",
    "1985 , inmaximum - entropy and bayesian methods in inverse problems , c.r .",
    "smith and w.t .",
    "grandy , jr .",
    "( dordrecht : reidel ) .",
    "skilling , j. 1986 , in maximum entropy and bayesian methods in applied statistics , j.h .",
    "justice , ed .",
    "( cambridge : cambridge university press ) .",
    "gull , s.f .",
    "1989 , in maximum entropy and bayesian methods , j. skilling , ed .",
    "( boston : kluwer ) ."
  ],
  "abstract_text": [
    "<S> it is well known that cmb temperature anisotropies and polarization can be used to probe the metric perturbations in the early universe . presently , there exist neither any observational detection of tensor modes of primordial metric perturbations nor of primordial non - gaussianity . in such a scenario , primordial power spectrum of scalar metric perturbations </S>",
    "<S> is the only correlation function of metric perturbations ( presumably generated during inflation ) whose effects can be directly probed through various observations . to explore the possibility of any deviations from the simplest picture of the era of cosmic inflation in the early universe </S>",
    "<S> , it thus becomes extremely important to uncover the amplitude and shape of this ( only available ) correlation sufficiently well . in the present work , </S>",
    "<S> we attempt to reconstruct the primordial power spectrum of scalar metric perturbations using the binned ( uncorrelated ) cmb temperature anisotropies data using the maximum entropy method ( mem ) to solve the corresponding inverse problem . </S>",
    "<S> our analysis shows that , given the current cmb data , there are no convincing reasons to believe that the primordial power spectrum of scalar metric perturbations has any significant features .    1.5 cm * maximum entropy deconvolution of primordial power spectrum + * 1 cm gaurav goswami and jayanti prasad +   0.75 cm iucaa , post bag 4 , ganeshkhind , pune-411007 , india    .25 cm </S>"
  ]
}