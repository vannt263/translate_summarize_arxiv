{
  "article_text": [
    "this paper discusses some problems possibly arising when approximating  via monte - carlo simulations ",
    "the distributions and critical values of the most commonly employed goodness - of - fit ( gof ) tests based on empirical distribution function ( edf ) statistics @xcite .",
    "this situation arises very frequently  in many areas of statistical physics or econophysics  when the researcher aims at fitting some experimental or empirical ( univariate ) sample with a parametric ( univariate ) probability distribution whose parameters are unknown . in such cases ,",
    "the goodness of fit may be ex - post evaluated by employing standard statistical tests based on the edf .",
    "if , as typically happens , critical - value tables are not available , one has to resort to monte - carlo methods to derive the approximated distribution of the test statistics under analysis .",
    "we show that , when testing with unknown parameters , critical values ( and consequently testing outcomes ) may be dramatically sensible to the details of the monte - carlo procedure actually employed to approximate them .",
    "more specifically , we argue that the researcher may sometimes build inaccurate critical - value tables because he / she fails to perform a crucial step in his / her monte - carlo simulation exercises , namely maximum - likelihood ( ml ) re - estimation of unknown parameters on each simulated sample . in our opinion , this is a lesson worth learning because critical - value tables are only available for particular distributions ( e.g. , normal , exponential , etc . ) . in all other cases , our study indicates that failing to correctly specify the monte - carlo approximation procedure may lead to overly - conservative hypothesis tests .",
    "the rest of this paper is organized as follows .",
    "section 2 formalizes the general gof test under study and discusses the main problems associated to the approximation of edf - based gof test - statistic distributions from a theoretical perspective .",
    "section 3 presents an application to the case of normality with unknown parameters .",
    "finally , section 4 concludes with a few remarks .",
    "in many applied contexts , the researcher faces the problem of assessing whether an empirical univariate sample @xmath0 comes from a ( continuous ) distribution @xmath1 , where @xmath2 is a vector of _ unknown _ parameters .",
    "edf - based gof tests @xcite employ statistics that are non- decreasing functions of some distance between the theoretical distribution under the null hypothesis @xmath3 and the empirical distribution function constructed from @xmath4 , provided that some estimate of the unknown parameters is given .    in",
    "what follows , we will begin by focusing on the simplest case where @xmath1 has only location and scale unknown parameters ( we will discuss below what happens if this is not the case ) .",
    "furthermore , we will limit the analysis to four out of the most used edf test statistics , namely kolmogorov - smirnov @xcite , kuiper @xcite , cramr - von mises @xcite and quadratic anderson- darling @xcite , with small - sample modifications usually considered in the literature .",
    "it is well - known that if one replaces @xmath2 with its maximum likelihood ( ml ) empirical - sample estimate @xmath5 , the distributions of the edf test statistic under study can be shown to be independent on the unknown true parameter values @xcite .",
    "however , test - statistic distributions are hard to derive analytically",
    ". they must be therefore simulated via monte - carlo and critical values must be accordingly computed .",
    "to do so , let us consider a first possible procedure :    * procedure a *    * step a1 * : :    _ generate , by means of standard simulation techniques @xcite , a    sufficiently large number ( say , @xmath6 ) of    independently - drawn n - sized samples    @xmath7 ,    @xmath8 , where each @xmath9 is an i.i.d .",
    "observation from a @xmath10 ,    i.e. from the distribution under @xmath11 where unknown    parameters are replaced by their empirical - sample estimates ; _ * step a2 * : :    _ for each n - sized sample @xmath12 , compute an    observation of the edf test statistic under study by comparing the edf    constructed from @xmath12 with the theoretical    distribution +    @xmath13 , i.e.    when @xmath14 is computed at the empirical sample observations    and _ unknown parameters are always replaced with estimates    @xmath5 obtained once and for all    from the empirical sample _ ; _ * step a3 * : :    _ once step a2 has been carried out for all @xmath15 samples ,    compute the empirical distribution function @xmath16 of the    test statistic ; _ * step a4 * : :    _ compute ( upper - tailed ) critical values , for any given significance    level @xmath17 , by employing the empirical distribution    function @xmath16 of the edf test statistic as obtained in step    a3 .",
    "_    at a first scrutiny , the above procedure seems to be correct .",
    "indeed , the procedure tells us to approximate the distribution of the test statistic under study by repeatedly compute it on a sufficiently large number of i.i.d .",
    "samples , all distributed as if they came from the null distribution @xmath18 , when the unknown parameters are replaced with their empirical sample estimate @xmath5 .    despite its appeal , however , procedure a can be shown to be wrong , in the sense that it generates a completely wrong approximation to the `` true '' distribution of the test statistic under the null hypothesis .",
    "the reason why procedure a is not correct lies in step a2 .",
    "more precisely , when we compare the edf constructed from @xmath12 with the theoretical distribution @xmath13 , we are assuming that our estimate for @xmath2 does not depend on the actual sample @xmath12 under analysis .",
    "this is the same as presuming that the hypothesis test is performed for _ known parameters_. on the contrary , sticking to the null hypothesis implies that the theoretical distribution which should be compared to the edf of @xmath12 must have parameter estimates that depend on the actual monte - carlo sample @xmath12 .",
    "in other words , scale and location parameters @xmath2 must be re - estimated ( via , e.g. , ml ) _ each time we draw the monte - carlo sample_. let @xmath19 be such estimate for sample @xmath20 .",
    "this means that the theoretical distribution to be used to compute the test statistic would be @xmath21 and not @xmath13 .",
    "the correct procedure therefore reads :    * procedure b *    * step b1 * : :    _ same as a1 ; _ * step b2 * : :    _ for each n - sized sample @xmath12 , compute an    observation of the edf test statistic under study by comparing the edf    constructed from @xmath12 with the theoretical    distribution    @xmath21 ,    i.e. when @xmath14 is computed at the empirical sample    observations and _ unknown parameters are replaced with estimates    @xmath19 obtained from the j - th    monte - carlo sample _ ; _ * step b3 * : :    _ same as a3 _ ; * step b4 * : :    _ same as a4_.    how dramatic is the error we make in applying procedure a instead of procedure b ?",
    "do we get a more conservative or less conservative test by using the wrong procedure ?",
    "in other words , can we detect significant shifts in the monte - carlo approximation to the distribution of the test statistics under study when we compare procedures a and b ?",
    "in the next section , we will answer these questions by providing a simple example .",
    "let us consider the null hypothesis that the empirical sample comes from a normal distribution @xmath22 with unknown mean ( @xmath23 ) and standard deviation ( @xmath24 ) .",
    "in such a case , parameters may be replaced by their ml estimates @xmath25 , i.e. sample mean and standard deviation . in this case",
    "critical values for the four test statistics under study are already available .",
    "our goal , for the sake of exposition , is therefore to compare monte - carlo approximations to the distributions of the four test statistics obtained under procedures a and b.    we thus have two setups . in the first one ( procedure a )",
    ", one does not re - estimate the parameters and always employs @xmath25 to build the theoretical distribution . in the second one ( procedure b ) , one re - estimates via ml mean and standard deviation on each simulated sample by computing @xmath26 and then uses them to approximate the theoretical distribution of the test statistic .",
    "our simulation strategy is very simple .",
    "since the argument put forth above does not depend on the observed sample s mean and standard deviation , we can suppose that @xmath27 without loss of generality .",
    "for each of the four test statistics considered , we run monte - carlo simulations , version 7.4.0.287 ( r2007a ) . ] to proxy its distribution under the two setups above . in both setups ,",
    "we end up with an approximation to the distribution of the four tests , from which one can compute critical values associated to any significance level ( or p - value ) .    to begin with , table",
    "[ bigtable ] shows critical values for all 4 tests at @xmath28 significance level , and for different combinations of @xmath29 ( sample size ) and @xmath15 ( monte - carlo replications ) .",
    "it is easy to see that if we employ procedure b , we obtain the same critical values published in the relevant literature for the case of normality with _ unknown _ parameters ( compare , e.g. , our table [ bigtable ] with table 1a-1.3 at page 732 in stephens , 1974 ) . on the contrary , if we employ procedure a , critical values dramatically increase .",
    "the effect is of course more evident in the case of so - called `` quadratic statistics '' ( cramr - von mises and quadratic anderson - darling ) , but is equally relevant also in the case of `` supremum statistics '' ( kolmogorov - smirnov and kuiper ) .",
    "what is more , procedure a allows us to obtain critical - value figures which are very similar to those found in the literature for the case of normality with _ completely specified , known , parameters_.    table [ bigtable ] also indicates that if we wrongly employ procedure a , we end up with test statistics that are dramatically more conservative ( at @xmath28 ) than if we correctly employ procedure b. this is true irrespective of the significance level .",
    "as figure [ pvalues ] shows , the a vs. b gap between critical values remains relevant for all ( reasonable ) p - value levels .",
    "in other words , the wrong choice of employing procedure a induces a rightward shift of ( and reshapes ) the entire test - statistic distribution . to see this , in figure [ edistrf ] we plot the estimated cumulative distribution of all 4 test statistics under the two setups . choosing procedure a makes all tests much more conservative .",
    "finally , it is worth noting that the above results do not depend on the empirical sample size .",
    "in fact , one might argue that the mismatch between the two procedures may be relevant only for small @xmath29 s but should vanish as @xmath29 gets large .",
    "this is not true : the gap remains there as @xmath29 increases within an empirically - reasonable range and for any sufficiently large number of monte - carlo replications ( @xmath15 )  see figure [ changingsample ] for the case @xmath30 .",
    "in this paper , we have argued that failing to re - estimate unknown parameters on each simulated monte - carlo sample ( and not employing this information to compute the theoretical distribution to be compared with the sample edf ) may lead to wrong , overly - conservative approximations to the distributions of gof test statistics based on the edf .",
    "furthermore , as our simple application shows , the impact of this possible mistake may turn out to be dramatic and does not vanish as the sample size increases .",
    "notice that similar issues have already been discussed in the relevant literature @xcite .",
    "more specifically , @xcite shows that the mean of the anderson - darling statistic shifts leftwards when the parameters of the population distribution are unknown .",
    "furthermore , @xcite discuss the problem of approximating edf test statistics from a rather theoretical perspective . yet , despite the success of edf - based gof tests , no clear indications were given  to the best of our knowledge  about the practical correct monte - carlo procedure to be followed in order to approximate test - statistic distributions in the case of unknown parameters .",
    "this paper aims at shedding more light on the risks ensuing a wrong specification of the monte - carlo simulation strategy , in all cases where critical - value tables are not already available .",
    "given the lack of contributions addressing this topic , and the subtle nature of the choice between procedure a and b , our feeling is that mistakes may be more likely than it may seem .",
    "a final remark is in order . in our discussion",
    "we deliberately focused only on the case where parameters to be estimated are location and scale .",
    "in such an `` ideal '' situation , as we noted , the distributions of the four edf - based test - statistics that we have considered do not depend on the true unknown parameters .",
    "therefore , in principle , to approximate their distributions one may generate , in step b1 , a sufficiently large number of independently - drawn n - sized samples from a @xmath31 , where @xmath32 is any given value of the unknown parameters , and not necessarily their empirical - sample estimates @xmath5 .",
    "since the distribution of the test is location- and scale - invariant , we just need to make sure to apply step b2 ( i.e. re - estimation of @xmath2 using @xmath12 ) in order to avoid the implicit assumption that parameters are known .    what happens if instead parameters are not location and scale but are still unknown ?",
    "in such a case , very common indeed ( e.g. , when @xmath14 is a beta or a gamma distribution ) , test - statistic distributions do depend on the true unknown parameter values @xcite .",
    "therefore , step b1 may be considered as a first ( good ) guess towards the approximation of test - statistic distributions .",
    "in fact , when parameters are not location and scale , one can not employ any given @xmath32 to generate monte carlo samples .",
    "since the `` true '' test - statistic distribution depends on the `` true '' unknown parameter values , one would like to approximate it with a sufficiently similar ( although not exactly equal ) distribution , which can be easily obtained  provided that procedure b is carried out  by employing the empirical sample estimates @xmath5 .",
    "in such a situation , critical value tables are not typically available , because they would depend on the empirical sample to be tested .",
    "monte - carlo simulations are therefore required and choosing the correct procedure ( b ) instead of the wrong one ( a ) becomes even more crucial than in the location - scale case .",
    "this article enormously benefitted from comments and suggestions made by richard lockhart , who patiently went through the main points with his illuminating explanations .",
    "thanks also to michael stephens and fabio clementi for their very useful remarks and suggestions .",
    "any remaining errors are the sole responsibility of the authors ."
  ],
  "abstract_text": [
    "<S> this paper discusses some problems possibly arising when approximating via monte - carlo simulations the distributions of goodness - of - fit test statistics based on the empirical distribution function . </S>",
    "<S> we argue that failing to re - estimate unknown parameters on each simulated monte - carlo sample  and thus avoiding to employ this information to build the test statistic  may lead to wrong , overly - conservative testing . </S>",
    "<S> furthermore , we present a simple example suggesting that the impact of this possible mistake may turn out to be dramatic and does not vanish as the sample size increases . </S>"
  ]
}