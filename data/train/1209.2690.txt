{
  "article_text": [
    "in 1830 , charles babbage , professor of mathematics at cambride university , wrote an now - famous essay describing the ways that scientific data can be consciously or unconsciously manipulated to achieve a desired conclusion@xcite . in it , he describes one of the manipulation methods as _ `` retaining only those results that fit the theory , and discarding others''_. many would likely assume that this kind of manipulation only involves exclusion of data , but in this paper we discuss a perhaps much more subtle example ; excluding none of the data , but rejecting data analysis methods that do not result in the desired conclusion .",
    "as an example of how this can occur in practice , let us consider a hypothetical empirical data set that we wish to compare to a model .",
    "the data are stochastic ( ie ; have some random variation ) , and thus vary somewhat about the true mean .",
    "let us refer to data that stochastically fluctuate higher than the true mean as @xmath0 , and data that stochastically fluctuate lower as @xmath1 . fairly often , just due to stochasticity , several events in succession may fluctuate high ( or low ) .",
    "thus , for example , if we wish the data in a particular bin to appear to be consistent with a predicted mean hypothesis that is larger than the true mean , we can simply adjust the bin width and optimize the bin boundaries to increase the ratio of @xmath0 to @xmath1 events in the bin .",
    "if we are attempting to compare a longer time series of data to the predictions of a desired ( but incorrect ) model , the optimization process becomes somewhat more complicated because several bin boundaries must be simultaneously optimized to take advantage of stochastic fluctuations such that as many bins as possible agree with the incorrect model hypothesis .",
    "however , straightforward monte carlo methods can be employed to achieve this , where many different random combinations of bin boundaries are tested , choosing the boundaries that achieve the best fit of the binned data to the incorrect model .    in figure",
    "[ fig : trend ] we give a simple example of this kind of manipulation . a time series of data recorded over 100 days is monte carlo generated with a normal distribution of zero mean and no trend ( red points ) .",
    "however , we ( wrongly ) believe that the underlying model has trend with slope @xmath2 days@xmath3 . using varying bin widths from 5 to 20 days",
    ", we thus use monte carlo methods to determine the bin boundaries that yield a binned likelihood fitted trend that is most consistent with this mistaken hypothesis .",
    "the results are shown in figure  [ fig : trend ] ; the fitted slope with the optimized binning is @xmath4 , which is nicely consistent with the desired slope of @xmath2 , and is three standard deviations away from the true slope of zero . however ,",
    "if equal sized bins are employed , the likelihood fit returns a slope of @xmath5 , which is consistent with zero , and over two standard deviations away from the desired incorrect slope .",
    "thus , when given the freedom to chose variable bin widths and the placement of the bin boundaries , we see from just this one simple example that it is possible for researchers to accept a desired ( but wrong ) hypothesis , and reject the true hypothesis . in the following sections we will discuss a much more complicated example that involves fitting the phase of periodic data with carefully chosen variable bin widths . we will show that if empirical data exhibit annual modulation due to a true underlying phase , @xmath6 , implementing variable width binning when fitting for the phase can unfortunately often result in an incorrect conclusion that the the data are instead consistent with a different phase , @xmath7 .    before moving on",
    ", we would like to stress that the manipulation of the data in this way , when it occasionally occurs , should not be assumed to be motivated by deliberate researcher prevarication ; rather , such manipulations can happen when the researchers sincerely believe an incorrect model to be the true underlying description of their data , and thus wish to present the data in a way that highlights what they believe to be evidence of that relationship .",
    "here we consider an illustrative example with basis in the real world , simulating periodic data similar to that of a typical dark matter experiment@xcite . daily data with annual periodicity are simulated over a five year time span , with an annual variation of amplitude @xmath8 , and true phase @xmath6 , which for _ illustrative purposes only _ we assume to be due to background or some other systematic effect . to simulate the observed data , @xmath9 ,",
    "at day @xmath10 , we thus use the model @xmath11 where @xmath12 is random number drawn from the normal distribution . for this example",
    "we assume the daily variation in the data is @xmath13 .",
    "we examine various binnings of the data , with bins between 30 days to 90 days in width .",
    "one thousand randomly selected binning schemes are examined , and the binning scheme is chosen that provides the best agreement of the fitted phase to the model @xmath14 and worst agreement to the model with the true phase , @xmath6 .    using this unequal width binning scheme ,",
    "we then perform a binned maximum likelihood fit to the data to obtain the estimated phase , @xmath15 , and its uncertainty , @xmath16 .",
    "we compare this to the phase estimate of an unbinned likelihood fit , and we also examine the phase estimate of a binned likelihood fit with bins of equal width .    here",
    "we arbitrarily assume that the phase of physics interest , @xmath7 , is 90 days past january 1@xmath17 .",
    "we examine values of @xmath6 from 45 to 85 days past january 1@xmath17 , in steps of 5 days .",
    "note that it does nt matter for this analysis what we assume for @xmath7 , because the results only depend on the absolute difference between @xmath7 and @xmath6 .",
    "for each true phase value , @xmath6 , we repeat the simulation and fitting procedure 250 times .",
    "an example of the significant bias that can be achieved with variable width bins when fitting to the simulated harmonic data is shown in figure  [ fig : example ] .",
    "the true phase of the data is @xmath18 days and the variable width binning is tuned to best match a desired phase of @xmath19 days .",
    "the fit to the variably binned data yields an estimated phase , @xmath20 , which is consistent with the untrue hypothesis , and statistically inconsistent with the true hypothesis .",
    "conversely , fitting with the same number of equal sized bins ( bottom plot in figure  [ fig : example ] ) yields an estimate of the phase , @xmath21 , which is statistically consistent with the true hypothesis and statistically inconsistent with the untrue hypothesis .",
    "the results of using variable binning with 250 data simulations for various values of @xmath6 reveal that on average the variably binned fit yields a phase estimate that is around one standard deviation closer to the untrue hypothesis than the phase estimate from the unbinned and/or equal bin width fit .",
    "this results in the untrue phase hypothesis being accepted much more often than it would be if the fit is unbiased .",
    "for instance , as seen in figure  [ fig : results ] , when the true and untrue phase hypotheses are a month apart , using variable binning instead of unbinned or equal width binning more than triples the chances of accepting the untrue hypothesis as being correct ( from 8% to 28% ) . for a three week phase difference ,",
    "the fit with variable binning doubles the probability of accepting the untrue hypothesis from 37% to 73% . indeed , as seen in the figure , for all differences between the phase hypotheses , variable binning yields a significantly improved probability of accepting the untrue hypothesis .",
    "we have shown that fitting to data grouped into bins of variable widths can yield significantly biased results . using a simple example of linear data , and a much more complicated example of periodic data , we have shown that fitting with variable binning can too often produce biased estimates that result in an incorrect model hypothesis being accepted as true . in the cases examined , we have shown that unbinned likelihood fits and/or binned fits with bins of equal width produce unbiased results .",
    "the examples given in this paper are illustrative only , and certainly not an exhaustive examination of the degree of bias that can be obtained in any particular physics analysis when variable width binning is employed .",
    "researchers must thus be careful to employ variable bin widths only when absolutely necessary , and reviewers must be careful to inquire about the underlying motivation when reviewing a fitting analysis wherein the bin widths are variable .",
    "the only truly reliable cross - check of sensitivity to binning effects is to fit with equal width bins or , ideally , perform an unbinned likelihood fit .",
    "it is not enough for researchers to merely state that `` alternate '' binning schemes were examined , since the alternate binning schemes may have been chosen to be different , but still nevertheless quite optimal in affirming the desired ( but wrong ) hypothesis ."
  ],
  "abstract_text": [
    "<S> when reading peer - reviewed scientific literature describing any analysis of empirical data , it is natural and correct to proceed with the underlying assumption that experiments have made good faith efforts to ensure that their analyses yield unbiased results . </S>",
    "<S> however , particle physics experiments are expensive and time consuming to carry out , thus if an analysis has inherent bias ( even if unintentional ) , much money and effort can be wasted trying to replicate or understand the results , particularly if the analysis is fundamental to our understanding of the universe .    in this note </S>",
    "<S> we discuss the significant biases that can result from data binning schemes . </S>",
    "<S> as we will show , if data are binned such that they provide the best comparison to a particular ( but incorrect ) model , the resulting model parameter estimates when fitting to the binned data can be significantly biased , leading us to too often accept the model hypothesis when it is not in fact true . when using binned likelihood or least squares methods there is of course no _ a priori _ requirement that data bin sizes need to be constant , but we show that fitting to data grouped into variable width bins is particularly prone to produce biased results if the bin boundaries are chosen to optimize the comparison of the binned data to a wrong model . </S>",
    "<S> the degree of bias that can be achieved simply with variable binning can be surprisingly large .    </S>",
    "<S> fitting the data with an unbinned likelihood method , when possible to do so , is the best way for researchers to show their analyses are not biased by binning effects . failing that , equal bin widths should be employed as a cross - check of the fitting analysis whenever possible . </S>"
  ]
}