{
  "article_text": [
    "the min - sum ( ms ) decoder is perhaps the second most fundamental message passing decoder after belief propagation ( bp ) decoder for two main reasons .",
    "firstly , the ms decoder is optimal with respect to block error probability on a tree code @xcite .",
    "secondly , it is widely believed that the ms decoder is closely related to the linear programming ( lp ) based decoder proposed in @xcite . in @xcite ,",
    "a complete characterization of the decoding region of the lp decoder has been provided with respect to the pseudocodewords of the underlying bipartite graph .",
    "the results in @xcite suggest that the decoding region of the lp decoder is identical to that of the ms decoder ( indeed , this is the case for tree codes ) .",
    "in addition , the ms decoder is of practical interest because of its low implementation complexity .    in @xcite , the asymptotic performance of the ms decoder using density evolution was evaluated .",
    "not much is known , however , analytically about the density evolution behavior of the ms decoder as compared to bp .",
    "we first address the issue of _ stability _ of the ms decoder .",
    "in particular , we derive a condition which guarantees that the densities corresponding to the ms decoder which one observes in density evolution converge to an `` error - free '' density .",
    "this condition turns out to be essentially the same as the stability condition for bp .",
    "recall that for the bp decoder the space of densities which arise in the context of density evolution is the space of _ symmetric _ densities . under ms decoding , on the contrary , no equivalent condition is known .",
    "empirically , one observes that for @xmath6 the densities fulfill the inequality @xmath7 we show that such a bound indeed stays preserved under ms processing at the check nodes .",
    "the equivalent question at the variable nodes is an open question .",
    "what are the fundamental performance limits under ms decoding ? under bp decoding an explicit optimization of the degree distribution shows that we can seemingly get arbitrarily close to capacity by a proper choice of the degree distribution .",
    "is the same behavior true under ms decoding or are the fundamental limits which can not be surpassed ? in order to address this question we implemented an optimization tool based on exit charts .",
    "we found that the gap between the best code and shannon limit is rather large .    in @xcite",
    "some simple improvements are proposed to the ms decoder .",
    "for some examples , it is demonstrated that by a simple scaling of the output at the check nodes , the performance of the ms decoder can be brought closer to that of the bp decoder . using the ldpc code design procedure ,",
    "we also study how close we can get to the shannon capacity limit by using this modified ms algorithm .",
    "the paper is organized as follows . in section [ sec : prelim ] , we give relevant definitions and briefly review the ms decoding algorithm and its density evolution analysis . in section",
    "[ sec : stabc ] , we derive a sufficient condition for stability and also discuss some properties of density which arise in density evolution . in section [ sec : optim ] , we discuss the optimization procedure .",
    "we then present the optimization results in section [ sec : res ] and finally conclude in section [ sec : conclusion ] .",
    "the ldpc ensemble is specified by specifying @xmath8 and @xmath9 which represent the degree distribution ( dd ) of the bit nodes and check nodes in the edge perspective , i.e. , @xmath10 @xmath11 is the fraction of edges connected to a degree @xmath12 bit ( check ) node .",
    "the design rate of an ldpc ensemble is given by @xmath13 .",
    "we consider transmission over a binary - input , memoryless , and symmetric ( bms ) channel .",
    "let @xmath14 be the log - likelihood ratio ( llr ) of bit @xmath15 obtained from the channel observation corresponding to bit @xmath15 .",
    "let @xmath16 and @xmath17 be the check to bit and bit to check message at iteration @xmath18 corresponding to edge @xmath19 .",
    "we will sometimes specifically refer to the binary input awgn ( biawgn ) channel , @xmath20 , where @xmath21 is the input bit and @xmath22 has a gaussian distribution with @xmath23 mean and variance @xmath24 . in this case",
    "@xmath25 is given by @xmath26 and its distribution under the all zero code word assumption is gaussian with mean @xmath27 and variance @xmath28 .",
    "finally , we denote the bhattacharyya constant associated to density @xmath29 by @xmath30 and error probability by @xmath31 .",
    "we now discuss the message passing rules for the ms decoder . in ms decoder the bit to check message update is given by @xmath32 where @xmath33 is the set of edges .",
    "the check to bit message update equation is    rcl l_cb , u , v^(t ) & = & 1 _ u:(u,v ) , u u ( l_bc , u,v^(t ) ) _",
    "u:(u,v ) , u u |l_bc , u,v^(t)| . [ eqn : checkminsum ]    for the ms decoder @xmath34 , but we will also consider modified ms decoders with @xmath35 .    the asymptotic performance of ldpc codes under ms decoding can be characterized by studying the evolution of the density of the messages with iterations ( see @xcite ) .",
    "let @xmath36 , @xmath37 , and @xmath38 be the probability density function ( pdf ) of channel log - likelihood ratio , the message from check to bit and bit to check node respectively in @xmath39 iteration under the all zero codeword assumption .",
    "the density evolution equation for the bit node ( corresponding to ( [ eqn : bitupdate ] ) ) is given by @xmath40 where @xmath41 denotes convolution of @xmath29 with itself @xmath12 times .",
    "similarly the check node side operation on densities is denoted by @xmath42 .",
    "the pdf of the message at the output of check nodes employing ms ( corresponding to ( [ eqn : checkminsum ] ) ) has been derived in @xcite , @xcite .",
    "it is given by    rcl _ t ( ) & & ( _ t(l ) )    rcl & & = _ i .",
    "the density evolution process is started with @xmath43 and iterative decoding is successful if the densities eventually tend to @xmath44 .",
    "in this section we derive the stability condition under ms decoding .",
    "the stability condition guarantees that if the density in density evolution reaches `` close '' to error free density ( @xmath44 ) then it converges to it .",
    "we derive the stability condition by upper bounding the evolution of the bhattacharyya parameter in density evolution .",
    "note that the bhattacharyya parameter appears naturally in the context of bp where densities are symmetric . in this case",
    "the bhattacharyya parameter has a very concrete meaning : it is equal to @xmath45 , where @xmath29 is a symmetric density . for general densities",
    "which are not symmetric this is no longer true but we can always compute @xmath30 .",
    "the reason we use bhattacharyya parameter is to have a one dimensional representation of densities and because of its property of being multiplicative on the variable node side .    in the following lemma",
    "we give a sufficient condition for stability of @xmath44 .",
    "this condition turns out to be same as the stability condition for bp ( ) .",
    "[ lemma : stab ] assume we are given a degree distribution pair @xmath46 and that transmission takes place over a bms channel characterized by its @xmath47-density @xmath48 .",
    "define @xmath49 , and for @xmath50 , define @xmath51 .",
    "if @xmath52 then there exists a strictly positive constant @xmath53 such that if , for some @xmath54 , @xmath55 , then @xmath56 as well as @xmath57 converge to zero as @xmath58 tends to infinity .",
    "conversely , if @xmath59 then @xmath60 with @xmath61 .    by lemma [ lemma : upbound ] in appendix",
    "we know that @xmath62 .",
    "thus    rcl b(_t+1 ) & = & b(_ch ) ( b(_k _ k ( ) ^(k-1 ) ) ) , + & & b(_ch ) ( (1 ) b(_t ) ) .    expanding the last equation around zero , we get    rcl & = & b(_ch ) (0 ) (1 ) b(_t ) + o(b(_t)^2 ) .",
    "since @xmath63 is assumed to be a constant less than 1 , we can choose a sufficiently small @xmath64 such that if @xmath55 , then @xmath65 . therefore if for some @xmath54 , @xmath55 , then @xmath66 , which converges to zero as @xmath58 tends to infinity .",
    "as @xmath67 so @xmath57 also converges to zero .    for the converse statement , the stability condition in eqn([eqn : stabcond ] ) is a necessary condition for bp decoding to be successful .",
    "hence by the optimality of bp decoding on a tree it is also a necessary condition for ms decoding to be successful .    in proving the sufficiency of the stability condition we used the bhattacharyya parameter as the functional to project densities to one dimension .",
    "however we could have used any other functional of the form @xmath68 , \\alpha > 0 $ ] which is multiplicative on the variable node side .",
    "lemma [ lemma : upbound ] stays valid for any such functional .",
    "therefore , we get a general stability condition that reads @xmath69",
    ". however , as @xmath70 is a symmetric density , @xmath71 .",
    "this implies that the sufficient condition for @xmath72 is weaker than the condition corresponding to bhattacharyya parameter .",
    "note that the converse in lemma [ lemma : stab ] is partial .",
    "it does not say that the condition in eqn([eqn : stabcond ] ) is necessary for the density to converge to @xmath44 if for some @xmath18 the density @xmath73 is `` close '' to @xmath44 .",
    "however the following observation suggests that this indeed should be the necessary condition .",
    "suppose we evolve the density @xmath74 under the ms decoder .",
    "then it again follows by the arguments of theorem 5 in @xcite ) that for the density to converge to @xmath44 the necessary condition is @xmath75 .",
    "for the bp decoder we know that @xmath74 is the `` best '' density ( in the sense of degradation ) with error probability @xmath76 .",
    "however for the ms decoder this is not the case .",
    "hence we can not conclude that eqn([eqn : stabcond ] ) is a necessary condition .",
    "the bp densities satisfy the symmetry condition @xmath77 .",
    "the densities which arise in ms decoder do not satisfy the symmetry property .",
    "however , we have observed empirically that the densities satisfy the property that @xmath78 and @xmath79 , @xmath80 . in the following lemma",
    "we prove that these properties remain preserved on the check node side .",
    "[ lemma : denschar ] let @xmath81 and @xmath82 be two densities which satisfy the property that @xmath83 and @xmath84 for @xmath85 .",
    ". then @xmath87 and @xmath88 .",
    "let @xmath89 and @xmath90 be random variables having density @xmath29 and @xmath91 respectively",
    ". then    rcl ( x ) & = & ( x ) ( b > |x| ) + ( x ) ( a > |x| ) + + & & ( -x ) ( b < -|x| ) + ( -x ) ( a < -|x| ) .",
    "thus    rcl ( x)-(-x ) & = & ( ( x)-(-x ) ) ( - ) + + & & ( ( x)-(-x ) ) ( - ) , + & & 0 .    similarly , @xmath92",
    "@xmath93 @xmath94 which is greater than or equal to zero by the assumption .",
    "proving lemma [ lemma : denschar ] for the variable node side is still an open question .",
    "exit charts @xcite were proposed as a low complexity alternative to design and analyze ldpc codes . typically by assuming that the density of the messages exchanged during iterative decoding is gaussian , the problem of code design can be reduced to a curve fitting problem which can be done using linear programming .",
    "if the gaussian assumption is exact , this technique is shown to be optimal in @xcite . in @xcite , a fast procedure",
    "is proposed that uses a combination of exit charts and density evolution to design ldpc codes .",
    "the basic idea is to perform the design in steps , where , in each step , the ldpc code ensemble is optimized using exit charts using the densities of the messages obtained from density evolution of the ensemble obtained in the previous step . in this paper",
    ", we use a similar idea to design ldpc codes for ms decoding .",
    "an exit curve of a component decoder is a plot of the mutual information corresponding to the extrinsic output expressed as a function of the mutual information corresponding to the a priori input ( message coming from the other component decoder ) .",
    "usually , it is assumed that the a priori information is from an awgn channel of signal - to - noise ratio @xmath95 and the exit curve is obtained by calculating the input and output mutual information for @xmath24 varying from @xmath23 to @xmath96 . in an exit chart ,",
    "the exit curves of one component code and the flipped exit curve of the other component code are plotted . using this chart",
    ", we can predict the path taken by the iterative decoder as shown in fig .",
    "[ fig : exit_chart_example ] .",
    "it has been observed that the actual path taken and the path predicted from exit charts are quite close . based on this observation ,",
    "ldpc codes can be designed as follows .",
    "let @xmath97 ( @xmath98 ) be mutual information corresponding to the extrinsic output of bit ( check ) node of degree @xmath12 when the a priori mutual information is @xmath99 .",
    "the mutual information @xmath100 can be calculated from the conditional distribution @xmath101 using @xmath102    the exit curve of the bit nodes and the check nodes is given by @xmath103 and @xmath104 respectively .",
    "usually both @xmath105 and @xmath106 are increasing function of @xmath99 .",
    "the convergence condition , based on the assumption on the message density , states that the exit curve of the bit nodes should lie above that of the check nodes for the iterative decoder to converge to the correct codeword , i.e. , @xmath107 or equivalently @xmath108 for all @xmath99 where @xmath109 . for a fixed @xmath110 , the problem of code design",
    "can then be stated as the following linear program @xmath111 note that maximizing the objective function corresponds to maximizing the rate .",
    "a similar linear program can be written for optimizing @xmath110 for a given @xmath112 .",
    "we consider the problem of finding ldpc codes for a given bms channel such that reliable communication is possible with the ms decoding algorithm .",
    "we are interested here in the performance when the block length goes to infinity .",
    "our goal is to maximize the rate of transmission . towards achieving this goal",
    "we first pick an ldpc code such that it converges to error free density for the specified channel . starting from the initial ensemble ,",
    "the ldpc code ensemble is optimized in several steps . in each step , the basic idea is to design the codes using exit charts .",
    "however , instead of using the gaussian assumption on the input densities , the input density in a particular step of the optimization process is assumed to be the same as the density obtained by using the density evolution procedure for the ensemble obtained in the previous step .",
    "the inherent assumption is that the input densities do not change much in one step of the optimization procedure and therefore the approximate exit curves obtained using the previous densities are close to the actual exit curves .",
    "note that this assumption is different from the assumption that the density at iteration @xmath12 for a particular optimization step is same as the density at iteration @xmath12 in the next optimization step .",
    "if we denote the densities at iteration @xmath12 by @xmath113 and consider a family of densities that includes @xmath114\\}$ ] then the assumption made is that the family of densities does not change much in one step of the optimization .",
    "we could sample many points in this family to enforce the condition in the linear program that the exit curves do not intersect .",
    "however , we sample only at points @xmath113 .",
    "this is usually sufficient since if the old exit curves are close to each other , then we get many samples there and at other points we have more leeway so we can sample fewer times .    in each step of the optimization procedure",
    ", we generate a new dd pair from the previous dd pair in two sub - steps . in the first sub - step we change @xmath112 keeping @xmath110 constant and in the next sub - step we change @xmath110 while keeping @xmath112 the same .",
    "the first sub - step is as follows .",
    "we choose @xmath115 and optimize @xmath112 as follows .",
    "we perform density evolution with the dd pair @xmath116 and at the end of each iteration store @xmath117 which is the mutual information corresponding to the extrinsic output of a bit node of degree @xmath118 at the end of iteration @xmath119 .",
    "the optimization then reduces to the following linear program .",
    "rcl & & _ i / i + & & _ i = 1 , _",
    "i 0 , + & & , + & & _ i i_b^l(i ) > _ old , i i_b^l-1(i ) + & &  + _ old , i ( i_b^l(i)-i_b^l-1(i ) )   [ 0,1 )  l ,   [ eqn : exitmatching ] + & & -_i - _ old , i  i , [ eqn : maxchange ] + & & _ 2    .",
    "[ eqn : stabcond2 ]    before we explain the constraints , we note that the cost function corresponds to maximizing the rate and that the old dd pair satisfies the constraints and therefore the resulting rate is always larger than the old rate .    the constraint ( [ eqn : exitmatching ] ) basically represents the condition that the exit curve corresponding to the bit nodes should lie above that of the check nodes .",
    "the quantity @xmath120 is the gap between the two exit curves corresponding to the old dd pair .",
    "the constant @xmath121 determines how much change in the gap is allowed . if @xmath121 is chosen to be 0 the gap between the curves can become zero while if @xmath121 is chosen to be one the gap is kept the same .    by choosing a smaller @xmath121",
    "we weaken the constraints and therefore get a larger rate .",
    "however , since the dd pair changes , the input densities also change and therefore the actual exit curves change . since the gap between the approximate exit curves ( one obtained using the previous densities ) is smaller with smaller @xmath121 , the chances of the actual exit curves intersecting increases .",
    "we choose some value of @xmath121 , perform the density evolution with the new dd pair and check if it converges . if it does , we accept the new ensemble and go to the second sub - step . if it does not converge , we increase @xmath121 and repeat this sub - step .",
    "the constraint ( [ eqn : maxchange ] ) is introduced so that the degree distributions do not change much in an iteration which in turn will ensure that the input densities and the resulting exit curves do not change significantly .    the constraint ( [ eqn : stabcond2 ] )",
    "is the stability condition . for the modified ms algorithm with @xmath35 ,",
    "we replace the stability condition by the condition @xmath122 .    in the second sub - step",
    "we perform the density evolution with the dd pair obtained in the previous sub - step and store @xmath123 which is the mutual information corresponding to the extrinsic output of a degree @xmath118 check node at the end of iteration @xmath119 . a linear program , similar to that discussed before ,",
    "can then be used to optimize the rate . as mentioned before , the rate keeps increasing with each step of the optimization process .",
    "we stop the optimization when the increase in rate becomes insignificant .",
    "the linear program discussed above can be easily modified for the case when we have a fixed rate and we want to find a code with better threshold .",
    "this optimization procedure is available on - line at @xcite .",
    "we used the optimization procedure discussed in this paper to design ldpc codes for ms . for fixed rate optimization scheme the gap to capacity varied significantly depending on the average right degree chosen . for the fixed channel optimization procedure ,",
    "the final gap to capacity depended on the initial profile with which the optimization procedure was started however the variations were observed to be lesser than that in fixed rate optimization .    in fig .",
    "[ fig : gaptocap ] we show the gap to capacity and the average right degree corresponding to ldpc codes optimized for ms decoding and modified ms decoding with @xmath5 .",
    "the fixed channel optimization procedure was used to obtain these points .",
    "we observe that the gap decreases as the rate increases but it is still quite far from the shannon capacity limit .",
    "comparison of the threshold of ldpc codes designed for bp but used with ms and the threshold of codes designed for ms shows that significant gains are obtained by using codes specifically designed for ms .",
    "for example , the best rate 0.5 code designed for bp from @xcite has a threshold of 1.91 db with ms which is 0.97 db worse than the best threshold we obtained for ldpc codes that were optimized for ms @xcite .",
    "we derived a sufficient condition for the stability of the fixed point @xmath44 which is also a necessary condition for the density evolution to converge to @xmath44 when initiated with channel log - likelihood ratio density .",
    "it remains an open question whether this condition is also necessary for the stability of fixed point @xmath44 subjected to local perturbation .",
    "we have discussed some properties of densities which are observed to be empirically true .",
    "we proved that these properties remain preserved on the check node side .",
    "it remains to be seen if the same thing can be proved for the variable node side .",
    "we presented a simple procedure to optimize ldpc codes for ms decoding . to the best of our knowledge ,",
    "the obtained codes are the best codes reported so far for ms decoding and they perform significantly better than codes that were designed for bp but are decoded using ms",
    ". however , their performance is quite far from the capacity limit and it remains to be seen if the gap is due to the sub - optimality of the design procedure . on the other hand if the gap is due to the inherent sub - optimality of ms , it will be an interesting research direction to explain the gap by information theoretic reasoning .      for the sake of simplicity , in the proof",
    "we assume that densities @xmath29 and @xmath91 are absolutely continuous .",
    "however the proof also works in the general case .",
    "let @xmath126 and @xmath127 be two random variables with densities @xmath29 and @xmath91 respectively and @xmath128 . then @xmath129}$ ] ,    rcl b ( ) & = & _ -^_-^e^- ( x ) ( y ) dy dx , + & = & _ 0^_0^((x ) ( y ) + ( -x ) ( -y))e^- dy dx + + & & _",
    "0^_0^((x ) ( -y ) + ( -x ) ( y))e^ dy dx , + & & _ 0^_0^x \\ { ( ( x ) ( y ) + ( -x ) ( -y))e^- .",
    "+ ( ( x ) ( -y ) + ( -x ) ( y ) ) e^ } dy dx +      in @xmath130 we multiply and divide by @xmath131 .",
    "note that all the densities which arise in density evolution satisfy the property that @xmath132 if and only if @xmath133 is zero",
    ". thus if @xmath81 or @xmath134 are equal to zero then the integrand itself is zero and those values of @xmath135 and @xmath136 do not contribute to the integral . hence without lose of generality",
    "we can assume that @xmath137 and @xmath138 are not zero .",
    "now ,    rcl b ( ) & = & _ 0^((x ) e^- + ( -x ) e^ ) dx , + & & _",
    "0^_0^((y ) + ( -y ) ) ( ( x ) e^- + ( -x )",
    "e^ ) dy dx , + & & _ 0^_0^x ( ( y ) + ( -y ) ) + & & ( ( x ) e^- + ( -x ) e^ ) dy dx + + & & _ 0^_x^ ( ( y ) + ( -y ) ) + & & ( ( x ) e^- + ( -x ) e^ ) dy dx . + & = & i_1 + i_2 .",
    "[ eqn : bha ]        note that by eqn([eqn : bhc ] , [ eqn : bha ] , [ eqn : bhb ] ) , @xmath142 .",
    "we first consider @xmath143 .",
    "we prove that the integrand of @xmath143 is pointwise non positive .",
    "as @xmath144 is a common non negative factor in the integrands of @xmath145 and @xmath146 , we will not consider it .",
    "then the remaining integrand of @xmath147 is : @xmath148 define @xmath149 , @xmath150 .",
    "now we can write eqn ( [ eqn : integrand ] ) as @xmath151 @xmath152 the eqn([eqn : integrandpq ] ) is exactly the eqn([eqn : bhgbsc ] ) in lemma [ lemma : gbsc ] which is proved to be non positive .",
    "also note that as required by lemma [ lemma : gbsc ] , @xmath153 and @xmath136 is associated with @xmath154 .",
    "the integrand of @xmath155 can also be reduced to eqn([eqn : bhgbsc ] ) in lemma [ lemma : gbsc ] .",
    "hence we prove that @xmath156 .",
    "j. feldman , d. r. karger , and m. j. wainwright , `` using linear programming to decode linear codes , '' in _ proc .",
    "37th annual conference on information sciences and systems ( ciss 03 ) _ , baltimore , md , mar .",
    "12 - 14 2003 ."
  ],
  "abstract_text": [
    "<S> the min - sum ( ms ) algorithm is arguably the second most fundamental algorithm in the realm of message passing due to its optimality ( for a tree code ) with respect to the _ block error _ probability @xcite . </S>",
    "<S> there also seems to be a fundamental relationship of ms decoding with the linear programming decoder @xcite . despite its importance </S>",
    "<S> , its fundamental properties have not nearly been studied as well as those of the sum - product ( also known as bp ) algorithm .    </S>",
    "<S> we address two questions related to the ms rule . </S>",
    "<S> first , we characterize the stability condition under ms decoding . </S>",
    "<S> it turns out to be essentially the same condition as under bp decoding . </S>",
    "<S> second , we perform a degree distribution optimization . </S>",
    "<S> contrary to the case of bp decoding , under ms decoding the thresholds of the best degree distributions for standard irregular ldpc ensembles are significantly bounded away from the shannon threshold . </S>",
    "<S> more precisely , on the awgn channel , for the best codes that we find , the gap to capacity is @xmath0db for a rate @xmath1 code and it is @xmath2db when the rate is @xmath3 ( the gap decreases monotonically as we increase the rate ) .    </S>",
    "<S> we also used the optimization procedure to design codes for modified ms algorithm where the output of the check node is scaled by a constant @xmath4 . for @xmath5 </S>",
    "<S> , we observed that the gap to capacity was lesser for the modified ms algorithm when compared with the ms algorithm . </S>",
    "<S> however , it was still quite large , varying from 0.75 db to 0.2 db for rates between 0.3 and 0.9 .    </S>",
    "<S> we conclude by posing what we consider to be the most important open questions related to the ms algorithm . </S>"
  ]
}