{
  "article_text": [
    "we propose to use a specific family of point processes to select samples for the purpose of estimating the mean or the integral of a function of a real variable .",
    "we draw a parallel with sampling designs which are themselves point processes on finite spaces .",
    "systematic sampling is widely used in finite population .",
    "it has been introduced by @xcite and @xcite . it is easily implemented and , by spreading the sample over the population",
    ", it results in precise mean and total estimators when the variable of interest is similar for neighboring units .",
    "the main drawback of systematic sampling is that most of the unit joint inclusion probabilities are null , making it impossible to estimate the variance of the horvitz - thompson estimator without bias ( see * ? ? ?",
    "the aim of this paper is to develop a method that is a compromise between a base point process such as the poisson process or the binomial process and the systematic process for sample selections in a continuous population .",
    "a similar objective is pursued in @xcite in a finite population setting supported by a superpopulation model .",
    "@xcite considers one - per - stratum sampling designs from a population that is split into strata of @xmath3 successive units where @xmath3 divides the population size .",
    "he introduces a class of sampling procedures that encompasses systematic sampling with constant rate @xmath4 and simple random sampling of one unit per stratum .",
    "point processes , that we refer to as _ sampling processes _ in the context of sampling , are the subject of a vast literature ( see for example * ? ? ?",
    "* ; * ? ? ?",
    "* and references therein ) .",
    "@xcite and @xcite introduced independently the continuous analogue to the horvitz - thompson estimator for infinite population sampling .",
    "different communities have studied point processes : mathematical physicists , probabilists and statisticians .",
    "a detailed state of the art in the study and simulation of some complex point processes can be found in @xcite .",
    "many simulation methods for point processes are implemented in the @xmath5 package ` spatstat ` @xcite .",
    "we introduce a new family of sampling methods that enable to continuously tune the distance between units in the sample .",
    "these processes allow to obtain small probabilities of jointly selecting neighboring units .",
    "these sampling methods are particularly efficient when the function of interest is smooth . moreover , joint inclusion densities are positive and it is possible to estimate the sampling variance without bias .    the paper is organized as follows : in section  [ s3 ] , we give a definition of sampling processes in continuous populations and we define the poisson process , the binomial process and the systematic process .",
    "important results of renewal process theory are recalled in section  [ s4 ] . in section  [ s5 ] , we define the systematic - poisson and the systematic - binomial processes with tuning parameter @xmath1 , and compute the joint densities .",
    "section  [ s6 ] contains proofs for the asymptotic processes when @xmath1 tends to infinity .",
    "simulations are presented in section  [ s7 ] and our ideas on the choice of the tuning parameter in section  [ st ] .",
    "finally , we give a brief discussion of the method and its advantages in section  [ s8 ] .",
    "following @xcite ( see also * ? ? ?",
    "* ) , a finite sample of size @xmath6 from a bounded and open subset @xmath7 of @xmath8 is a collection of units @xmath9 without consideration for the order of the @xmath10 s .",
    "this definition matches those commonly used in finite population sampling ( see for example * ? ? ?",
    "* for an introduction to finite population sampling theory ) .",
    "a sampling process is a probability distribution on the space @xmath11 of all such collections , for all @xmath12 .",
    "note that it is not directly a distribution on @xmath13 equipped with the tensor product of borel sigma algebras @xmath14 as the sample units are not ordered .",
    "an extensive discussion on the definition of a sampling point process on @xmath7 and the corresponding symmetric measure on @xmath15 is given in @xcite .",
    "it is sufficient for our purpose to know that a sampling point process is a probability distribution on @xmath16 where @xmath17 , with @xmath18 and @xmath19 in @xmath20 being in the same class for the equivalence relation @xmath21 if @xmath18 is a permutation of elements of @xmath19 , and @xmath22 is the sigma algebra generated by the family of counting events : @xmath23 and @xmath24 is the number of elements of @xmath25 that are in @xmath26 .",
    "the first and second factorial moment measures of a sampling point process @xmath27 @xcite are defined respectively as @xmath28 \\end{array } \\right),\\ ] ] where @xmath29 is the random number of elements of @xmath27 that are in @xmath26 , and the second factorial moment measure is the extension to @xmath30 of @xmath31 \\end{array } \\right),\\ ] ] where @xmath32 is the random number of pairs @xmath33 , @xmath34 of elements of @xmath27 such that @xmath35 and @xmath36 .",
    "we call first and joint ( second ) order inclusion densities the respective densities of @xmath37 and @xmath38 with respect to the lebesgue measure on @xmath7 and @xmath39 when they exist . in that case , the first order inclusion density @xmath40 is such that @xmath41 , for all @xmath42 , and the second - order inclusion density @xmath43 satisfies @xmath44 for all @xmath45 .",
    "heuristically , the term @xmath46 can be viewed as the probability that one unit of the sample lies between @xmath18 and @xmath47 , and @xmath48 as the probability that one unit of the sample lies between @xmath18 and @xmath47 and another between @xmath19 and @xmath49 , disregarding what happens outside of these sets .",
    "likewise , one can define @xmath50th order factorial moments and , when they exist , inclusion densities for @xmath51 .",
    "we now turn to the problem of estimating the mean of a lebesgue integrable function @xmath52 defined on @xmath7 : @xmath53 where @xmath54 denotes the lebesgue measure of @xmath7 , using a finite random sample @xmath55 of points in @xmath7 . assuming that @xmath7 is bounded , @xmath54 is known and @xmath27 is a sampling process with inclusion density @xmath40",
    ", @xcite defines the continuous analogue of the horvitz - thompson estimator as : @xmath56 and gives its properties . under the assumption that @xmath57 on @xmath7 and that @xmath52 is bounded or non - negative",
    ", this estimator is unbiased ( * ? ? ?",
    "* theorem  1 ) .",
    "if , moreover , @xmath58 , the variance of this estimator is given by : @xmath59^{2}}{\\pi(x ) } dx + \\int_\\omega \\int_\\omega z(x)z(y ) \\left [ \\frac{\\pi^{(2)}(x , y)-\\pi(x)\\pi(y)}{\\pi(x)\\pi(y)}\\right ] dx dy,\\ ] ]    and if the joint inclusion density exists with @xmath60 for all @xmath18 , @xmath19 in @xmath7 then : @xmath61^{2 } + \\sum_{x_{i}\\in x } \\sum_{\\substack{x_{j}\\in x\\\\ i \\neq j}}z(x_{i})z(x_{j } ) \\left [ \\frac{\\pi^{(2)}(x_{i},x_{j})-\\pi(x_{i})\\pi(x_{j})}{\\pi(x_{i})\\pi(x_{j } ) \\pi^{(2)}(x_{i},x_{j})}\\right],\\ ] ] is an unbiased estimator of the variance of @xmath62 ( * ? ? ?",
    "* theorem  2 ) .",
    "as pointed out in @xcite the horvitz - thompson variance and variance estimator for a continuous population are slightly different from the finite population case . conditions to ensure that these estimators are unbiased are , however , similar .    in the case of fixed size sampling process ,",
    "the continuous analogue of the @xcite and @xcite variance formula and estimator are : @xmath63^{2 } [ \\pi(x)\\pi(y)-\\pi^{(2)}(x , y ) ] dx dy,\\ ] ] and @xmath64 ^{2 } \\left[\\frac { \\pi(x_{i})\\pi(x_{j})-\\pi^{(2)}(x_{i},x_{j})}{\\pi^{(2)}(x_{i},x_{j})}\\right],\\ ] ] ( see * ? ? ?",
    "* ) .    throughout this paper , we assume that @xmath65 but the construction we used up to here also allows to work with other spaces",
    ". indeed , @xcite and @xcite consider finite dimensional real vector spaces , and @xcite work on complete separable metric spaces ( polish spaces ) .",
    "our purpose is to define sampling processes that have good properties regarding the estimation of @xmath66 .    in the following , we assume that @xmath67 .",
    "for an ordered set @xmath68 , we define the corresponding _ inter - arrival times _ @xmath69 as the differences between two successive units , namely @xmath70 , for @xmath71 .",
    "if @xmath27 is a point process , the corresponding inter - arrivals ( also called waiting times ) are random variables .",
    "a special class of point processes , called renewal processes , are obtained when the inter - arrival times are independent and identically distributed ( see for example * ? ? ?",
    "* ) . in this paper ,",
    "except when explicitly stated , the random inter - arrival times of our sampling processes are neither assumed to be identically distributed nor independent .    the binomial process ( see * ? ? ?",
    "* ) is one of the most basic point processes and has a fixed sample size .",
    "let @xmath72 be a pdf on @xmath73 and let @xmath12 be a natural number .",
    "the _ binomial point process _ of @xmath6 points in @xmath7 with pdf @xmath72 is the point process whose realizations consist of @xmath6 points generated from i.i.d distributions with common pdf @xmath72 .",
    "when the sample space @xmath7 is bounded , inter - arrival times of the binomial process are not independent .",
    "indeed , the sum of these inter - arrival times is necessarily no larger than the diameter of @xmath7 . in the following , we only use binomial processes in @xmath74 with i.i.d .",
    "points selected according to a uniform distribution on @xmath74 .",
    "the @xmath50th order joint inclusion density of a binomial process of size @xmath6 at @xmath75 is given by : @xmath76 in particular , @xmath77 if @xmath78 , and @xmath79 if @xmath80 .",
    "the @xmath81th order joint inclusion density is equal to @xmath82 on samples @xmath83 with @xmath84 .    with @xmath85 and a fixed size @xmath6",
    ", we can define the circular inter - arrival times as @xmath86 , @xmath87 and @xmath88 .",
    "as we see in proposition  [ prop1 ] , the binomial process can be obtained by generating the circular inter - arrival times according a dirichlet distribution . the dirichlet distribution with parameter @xmath89 , denoted",
    "@xmath90 is a multivariate distribution with pdf given by @xmath91 where @xmath92 for @xmath93 @xmath94 @xmath95 , @xmath96 and @xmath97 is the multinomial beta function .",
    "properties of the dirichlet distribution are given in @xcite .",
    "[ prop1 ] let @xmath98 , where @xmath99 is a vector of @xmath6 ones and @xmath100 , uniformely distributed on @xmath74 , is independent from @xmath101 .",
    "the sorted values in @xmath102 follow a binomial process on @xmath74 with uniform density .    with parameter @xmath99 , the pdf in  ( [ dirichlet ] )",
    "simplifies to @xmath103 with @xmath104 .",
    "let @xmath105 be the sorted values  ( [ cccc ] ) .",
    "since the sum of all @xmath106 s is equal to @xmath107 , we see that a given set of numbers @xmath108 in @xmath74 is obtained exactly when @xmath109 for some @xmath110 and the inter - arrival times allow to obtain @xmath111 .",
    "these events are almost surely non overlapping and @xmath112 is independent from @xmath101 .",
    "it follows , if @xmath113 is the density of @xmath112 and @xmath114 the density of @xmath101 , that @xmath115    the poisson process ( see for example * ? ? ?",
    "* ; * ? ? ?",
    "* ) is one of the basic and most studied point processes .",
    "it is particularly useful for the construction of more complex processes .",
    "a point process @xmath27 on @xmath7 is a poisson process with intensity @xmath116 if the following properties are satisfied :    1 .   for any @xmath117 , @xmath29 follows a poisson distribution with parameter @xmath118 , where @xmath119 denotes the lebesgue measure of @xmath26 . if @xmath120 , then @xmath121 almost surely .",
    "2 .   for any @xmath12 , conditional on @xmath122 ,",
    "the distribution of @xmath123 ( the trace of the random set @xmath27 on @xmath26 ) is that of a binomial process on @xmath26 with size @xmath6 and constant pdf on @xmath26 .",
    "there exist several equivalent definitions of the poisson process , but this one highlights the link with the binomial process .",
    "there is a similar link in finite population sampling , where conditioning a bernoulli sampling design on its size yields a simple random sampling design ( see * ? ? ?",
    "bernoulli sampling can thus be considered as the discrete analogue to the poisson sampling process .",
    "inter - arrival times of the poisson process with intensity @xmath124 are i.i.d . and follow an exponential distribution with parameter @xmath124 @xcite .",
    "it follows from the definition that the first order inclusion density of the poisson sampling process on @xmath73 is equal to @xmath124 , and using the independence property , that the @xmath50th order joint inclusion density is equal to @xmath125 if @xmath126 .",
    "the systematic process , or deterministic renewal process in the interval @xmath74 is defined as follows :    [ def::sys_design ] let @xmath127 and @xmath128 .",
    "a systematic sampling process with sampling interval @xmath127 is defined as the distribution of @xmath129 where @xmath130 and @xmath6 is such that @xmath131 .",
    "a renewal process , or renewal sequence , is a stochastic process defined on the positive real line .",
    "it is completely characterized by the distribution of its independent and identically distributed inter - arrival times .",
    "for example , the poisson process is a renewal process with exponentially distributed inter - arrival times when its intensity @xmath124 is constant . the following definition can be found in @xcite .",
    "a renewal process is any process @xmath132 with @xmath133 where @xmath134 is a given non - negative random variable and @xmath135 is a sequence of i.i.d non - negative random variables with common cumulative distribution function ( cdf ) @xmath136 . if @xmath137 a.s .",
    ", the process is called a pure renewal process ( or simply a renewal process ) . if @xmath138 then the process is called a delayed renewal process ( see * ? ? ? * ) .",
    "the counting measure @xmath139 ( or renewal counting process ) of a pure renewal process @xmath27 is defined in @xcite as : @xmath140 where @xmath141 denotes the indicator function .",
    "@xcite then define the _ forward recurrence time _ of a renewal process as : @xmath142 it is the random time between an arbitrarily chosen instant @xmath143 and the following occurrence of the process ( see figure  [ graph : lifetime_dist ] ) .",
    "( -4,0)(5,0 ) ; plot ( -2,0 ) node[above]@xmath144 ; ( -2,0.05)(-2,-0.05 ) ; plot ( -.4,0 ) node[above]@xmath143 ; ( -.4,0.05)(-.4,-0.05 ) ; plot ( 3,0 ) node[above]@xmath145 ; ( 3,0.05)(3,-0.05 ) ; ( -.4,-0.45)(-.4,-0.55 ) ; ( -.4,-0.5)(3,-0.5 ) node[midway , below]@xmath146 ; ( 3,-0.45)(3,-0.55 ) ;    an important result of renewal theory concerns the limiting distribution of the forward recurrence time @xmath146 when @xmath147 . under some mild conditions",
    "( see * ? ? ?",
    "* theorem 1.18 ) , if the inter - arrival times have cdf @xmath136 and finite expectation @xmath148 , @xmath146 converges in distribution when @xmath147 to a random variable with cdf @xmath149 defined as : @xmath150 dt,\\ x\\geq 0 .",
    "\\label{f0}\\ ] ] the pdf of this limiting distribution is equal to : @xmath151,\\ x\\geq 0.\\ ] ] for example , if the inter - arrival times follow a gamma distribution with shape parameter @xmath1 and rate parameter @xmath124 , denoted @xmath152 , their distribution function is given by @xmath153 , where @xmath154 and @xmath155 .",
    "the corresponding limiting forward recurrence time distribution follows a forward gamma distribution @xmath156 with pdf : @xmath157 with @xmath158 .",
    "another property of renewal processes that will be essential in the following is given in proposition  [ fondamental ] .",
    "[ fondamental ] let @xmath159 be a sequence of i.i.d non - negative continuous random variables , with expectation @xmath160 , cdf @xmath161 , and pdf @xmath162 .",
    "let also @xmath163 be the function defined by : @xmath164 \\mbox { if } x\\geq 0\\mbox { and } 0\\mbox { if } x<0.\\ ] ] then , equation  [ eqfond ] holds @xmath165 where @xmath166 denotes the @xmath50fold convolution of the function @xmath162 with itself , i.e. the pdf of @xmath167 .",
    "proposition  [ fondamental ] is a classical result of renewal process theory .",
    "we give a simple proof of it in appendix .",
    "different proofs can be found for instance in @xcite or in @xcite .",
    "proposition  [ fondamental ] implies that the delayed renewal process , obtained by generating @xmath134 with cdf @xmath149 and the @xmath168 s independently with cdf @xmath136 , has , among other properties , a constant first - order inclusion density equal to @xmath169 on @xmath170 .",
    "such a delayed renewal process has stationary increments and is called a stationary renewal process @xcite .",
    "a special case is that of the poisson process with intensity @xmath124 .",
    "it is a renewal process whose inter - arrival times follow an exponential distribution @xmath171 .",
    "it turns out that its limiting forward recurrence time distribution is also an exponential distribution with parameter @xmath124 , so that @xmath172 .",
    "this is a consequence of the memory - less property of the exponential distribution .",
    "our aim is to propose new sampling processes that allow to control the selection probability of neighboring units by adjusting the joint inclusion density . spreading the sample units over @xmath7",
    "has some advantages when units close together are similar ( e.g. when the function @xmath52 has small variations ) .",
    "the systematic sampling process allows to select samples that are very well spread . however",
    ", it does not possess a positive second - order inclusion density so that @xcite s horvitz - thompson variance estimator may not be used .",
    "we are thus interested in sampling processes with inter - arrival times that have a positive variance smaller than that of poisson or binomial processes . without auxiliary information that would encourage us to do otherwise",
    ", we focus on sampling processes with constant first - order inclusion density on @xmath7 .",
    "the family of sampling processes that we consider can be seen as a compromise between basic sampling processes ( poisson and binomial processes ) and systematic sampling .",
    "the rough idea is the following : in a first phase sampling procedure , a sample of expected size @xmath173 , with @xmath174 , is selected using an elementary sampling process . in the second selection phase ,",
    "we use a systematic sampling to draw one unit every @xmath1 units of the first phase sample .",
    "we call these processes quasi - systematic sampling processes .",
    "we consider the `` systematic - poisson '' and `` systematic - binomial '' processes obtained when the first phase processes are respectively the poisson and the binomial process .",
    "the first and second - order inclusion densities of these sampling processes have a closed form .",
    "consider the following two - phases sampling process : a first phase sample is generated from a poisson sampling process with constant intensity @xmath124 .",
    "then , a systematic sample is drawn inside this first phase sample with rate @xmath175 ( i.e. a starting unit is randomly chosen among the @xmath1 first units of the first phase sample and is kept in the second phase sample along with every other @xmath1 unit ) . in an interval of length @xmath107 , the expected number of units selected by the poisson process is @xmath124 .",
    "thus , by setting @xmath176 , where @xmath6 is the targeted final average sample size and @xmath1 is freely chosen , we ensure that the expected final sample size is @xmath6 .",
    "the inter - arrival times of the first sample are , by definition , realizations of an exponential random variable with parameter @xmath124 . after the systematic sampling phase ,",
    "inter - arrival times are realizations of sums of @xmath1 independent exponential random variables i.e. of non - negative random variables @xmath152 with pdf @xmath177 .",
    "thus , except for the first inter - arrival , this process is a renewal process with @xmath152 renewal distribution .    as we are set on having a constant first - order inclusion density , and thanks to proposition  [ fondamental ] ,",
    "we choose to generate the first inter - arrival with a @xmath156 distribution and the following ones with independent @xmath152 distributions .",
    "the first and second - order densities of the obtained systematic - poisson sampling process are given in proposition  [ denssp ] .",
    "note that parameters @xmath6 and @xmath1 do not in fact need to be integer numbers .",
    "algorithm  [ alg : poiss_qs ] can be used to select a systematic - poisson sample in @xmath74 .",
    "@xmath178 , @xmath0 ; generate @xmath179 ; i=2 ; generate @xmath180 @xmath181 @xmath182 @xmath183 ordered systematic - poisson sample with parameters @xmath1 and @xmath124 .",
    "[ denssp ] let us consider a systematic - poisson process on @xmath74 with positive parameters @xmath1 and @xmath124",
    ". then    1 .",
    "the first - order inclusion density is given by : @xmath184 for any @xmath185 , 2 .",
    "the second - order inclusion density is given by @xmath186 for any @xmath187 .    1 .",
    "is a direct application of proposition  [ fondamental ] , considering that the expectation of a @xmath152 distribution is equal to @xmath188 .",
    "2 .   from ( * ? ? ?",
    "* , example 5.4(b ) ) , we have that , for @xmath189 , @xmath190 where @xmath112 is the first - order density of the renewal process @xmath191 , @xmath192 .",
    "@xmath193 is equal to @xmath194 , where @xmath195 and @xmath72 is the pdf of @xmath196 . as the sum of @xmath197 independent @xmath152 variables is a @xmath198 and has pdf : @xmath199 we can infer that the counting measure of the renewal process @xmath27 has renewal density @xmath200 and the result follows .",
    "the joint inclusion density equation simplifies for some values of @xmath1 .",
    "set @xmath201 with @xmath6 the expected the sample size . with @xmath202 we get the usual poisson process and thus @xmath203 .    the plot of @xmath204 as a function of @xmath205 is given in figure  [ g1 ] for different values of @xmath1 .",
    "except for @xmath202 , @xmath206 if @xmath207 .",
    "the larger @xmath1 is , the flatter the plot is near the origin : the sampling design avoids selecting neighboring units . we see that , when @xmath1 is very large , the function concentrates on the inverse of the sampling rate and its multiples .",
    "it illustrates that the systematic - poisson sampling design is close to a systematic sampling when @xmath1 is large .",
    "joint inclusion density @xmath204 as a function of @xmath205 for systematic - poisson sampling , for @xmath208 , @xmath209 and @xmath210 .",
    "the range of oscillations increases with @xmath1 . when @xmath202 , @xmath204 is constant . ]",
    "the systematic - binomial process is a fixed size sampling process with constant inclusion density on @xmath74 .",
    "it is obtained , for example , by taking a realization of a binomial process of size @xmath173 , selecting a systematic sub - sample with rate @xmath175 inside the first phase units and finally adding , modulo  1 , a random number @xmath112 generated from a @xmath211 distribution .",
    "this last step ensures that the circular inter - arrival time @xmath212 has the same distribution as the other inter - arrival times .",
    "an illustration of the sampling procedure is given in figure  [ graph : sample_circle ] .",
    "( 0,0 ) circle ( 1 ) ; ( 95.583118731156:1 - 0.03) ( 95.583118731156:1 + 0.03 ) node[above]_u _ ; ( -pi,-1.5)(pi , -1.5 ) ; ( -pi,-1.55)(-pi , -1.45 ) node[above]_u _ ; ( pi,-1.55)(pi , -1.45 ) node[above]_u _ ;    table pts_sample_comp_circle.csv ; table pts_sample_comp.csv ; table pts_sample.csv ; table pts_sample_circle.csv ;    an implementation is proposed in algorithm  [ alg : binom_qs ] .",
    "generate @xmath214 the sequence of order statistics of @xmath173 i.i.d .",
    "variables @xmath211 .",
    "@xmath215 generate @xmath216 @xmath217 @xmath183 ordered systematic - binomial sample with parameter @xmath1 and size @xmath6 .",
    "another way to obtain a realization of a systematic - binomial process is to work with circular inter - arrival times .",
    "the first phase binomial sample is selected by generating @xmath218 , realization of a @xmath219 distribution , then these inter - arrival times are aggregated in packets of @xmath1 to form the circular inter - arrival times of the final sample , @xmath220 and finally a random uniform shift @xmath112 is used to set the origin . the selected units are @xmath221 however , the aggregation properties of the dirichlet distribution ensure that the vector @xmath222 of equation  [ dirn ] follows a @xmath223 distribution",
    ". we also get that @xmath224 and @xmath225 where @xmath226 denotes the beta distribution . taking advantage of this consideration , we can use algorithm  [ alg : binom_qs2 ] to select samples from a systematic - binomial process .",
    "this method is not restricted to integer values of @xmath1 .",
    "generate @xmath228 generate @xmath216 @xmath229 @xmath183 ordered systematic - binomial sample with parameter @xmath1 and size @xmath6 .",
    "inclusion densities of the systematic - binomial process are given in proposition  [ densbin ] .",
    "[ densbin ] consider a systematic - binomial process of size @xmath6 with parameter @xmath1 .",
    "its inclusion densities are given below .    1 .",
    "the first - order inclusion density is given by : @xmath230 2 .",
    "the second - order inclusion density is given by @xmath231 } |x - y|^{mr-1}(1-|x - y|)^{(n - m)r-1 } , \\label{pik2systbin}\\ ] ] for @xmath232 .",
    "the @xmath81th order inclusion density is given by : @xmath233^{n } } ( 1+x_{1}-x_{n})^{r-1}(x_{2}-x_{1})^{r-1 } \\cdots \\ ; ( x_{n}-x_{n-1})^{r-1},\\ ] ] for @xmath234 .    1 .   due to",
    "the random uniform shift used to set the origin , the point process canonically induced on the unit circle is clearly stationary ( i.e. rotation invariant ) .",
    "its first moment measure is thus a haar measure and proportional to the lebesgue measure .",
    "it follows that the first moment measure of the considered systematic - binomial process is proportional to the lebesgue measure on @xmath74 , and the proportionality coefficient is the total mass @xmath6 .",
    "the point process being stationary , its second - order inclusion density reduces to @xmath235 where @xmath112 is the first - order density of the point process @xmath236 on @xmath237 $ ] .",
    "however we have that the corresponding counting function @xmath238 is given by : @xmath239 where @xmath240 is the cdf of @xmath241 and is thus the cdf of a @xmath242 distribution . hence @xmath243 }",
    "h^{mr-1}(1-h)^{(n - m)r-1},\\mbox { } 0<h<1,\\ ] ] and the result follows .",
    "3 .   as with ordinary binomial sampling",
    ", a given sample is obtained exactly when @xmath112 is equal to one of the units and the inter - arrival times agree with the sample .",
    "moreover the dirichlet distribution with parameter @xmath244 is symmetric and @xmath112 is independent from @xmath245 . we get that : @xmath246^{n } } ( 1+x_{1}-x_{n})^{r-1}(x_2-x_{1})^{r-1 } \\cdots \\;(x_{n}-x_{n-1})^{r-1 } .\\end{aligned}\\ ] ]    some straightforward computations lead to equation  [ intpi2 ] @xmath247 a plot of @xmath204 as a function of @xmath19 is given in figure  [ g2 ] , for @xmath248 and different values of @xmath1 . except for @xmath202 , @xmath206 if @xmath207 .",
    "the larger @xmath1 is , the flatter the joint inclusion density is around @xmath207 .",
    "the selection of neighboring units is thus very unlikely with such a sampling design and a large @xmath1 .",
    "when @xmath1 is very large the function concentrates on regularly spaces pikes as in the systematic - poisson case .",
    "joint inclusion density @xmath204 as a function of @xmath19 for @xmath248 in systematic - binomial sampling with @xmath208 and @xmath249 .",
    "the range of oscillations increases with @xmath1 . when @xmath202 , @xmath204 is constant . ]",
    "the sampling processes introduced in section  [ s5 ] depend on a parameter @xmath1 .",
    "when @xmath1 gets large , they look more and more like systematic sampling processes . indeed",
    ", we will see that these processes converge in distribution to the systematic sampling process when @xmath6 is fixed and @xmath1 goes to infinity .",
    "we first need lemma  [ convergenceb ] .",
    "[ convergenceb ] a forward gamma random variable @xmath250 converges in distribution to a continuous uniform variable @xmath251 when @xmath1 tends to infinity and @xmath6 is fixed .",
    "it is easy to prove that , if @xmath252 is the characteristic function of a positive probability distribution with expectation @xmath253 , pdf @xmath72 and cdf @xmath136 , then the characteristic function @xmath254 of the probability distribution with density @xmath255 is such that : @xmath256,\\ t\\in \\r,\\ ] ] where @xmath257 .",
    "however , the characteristic function of a @xmath152 is given by @xmath258 .",
    "it follows that the characteristic function of a @xmath156 is given by @xmath259 replacing @xmath124 by @xmath260 and letting @xmath1 tend to infinity , we obtain that the characteristic function has a limit : @xmath261 which is the characteristic function of a continuous uniform random variable @xmath262 .",
    "lvy s continuity theorem applies and gives the result .",
    "we can now prove the announced result .",
    "we start with the systematic - poisson process in proposition  [ prop::convergence_syst_poiss ] .",
    "[ prop::convergence_syst_poiss ] let us consider a systematic - poisson process on @xmath74 with parameters @xmath263 and @xmath264 .",
    "then , the process weakly converges to a systematic process of size @xmath6 when @xmath1 tends to infinity .    in systematic - poisson process with parameter @xmath1 and @xmath264",
    ", the first inter - arrival time follows a forward gamma distribution @xmath250 and the next ones follow a gamma distribution @xmath265 .",
    "we have seen in proposition  [ convergenceb ] that @xmath250 converges to a @xmath251 when @xmath1 tends to infinity .",
    "we also have that the @xmath265 distribution converges to a @xmath266 . indeed , the expectation of a @xmath265 is equal to @xmath267 and its variance to @xmath268 . as the inter - arrival times are independent , we get that any finite family of them jointly converges to the matching distributions of inter - arrival times of a systematic process , as defined in section  [ s3 ]",
    ". however , in the case of point processes the weak convergence of finite distributions is equivalent to the weak convergence of the process ( see , e.g. , theorem 11.1.vii of * ? ? ?",
    "the case of the systematic - binomial process is dealt with in proposition  [ propbin ] .",
    "[ propbin ] consider a systematic - binomial process of size @xmath6 on @xmath74 and with parameter @xmath0 .",
    "then the process converges in distribution to a systematic sampling process when @xmath1 tends to infinity .",
    "it is sufficient to show that the circular inter - arrival times converge in distribution to a @xmath266 .",
    "indeed , the random start is already accounted for in the procedure .",
    "however , the inter - arrival times follow a beta distribution with mean @xmath267 and variance @xmath269 $ ] , and indeed , their variance tends to @xmath270 when @xmath1 tends to infinity . as in the proof of proposition  [ prop::convergence_syst_poiss ] , theorem 11.1.vii in @xcite allows to finish the proof .",
    "some simulations are useful to illustrate the properties of the systematic - binomial sampling process .",
    "we also ran simulations with the systematic - poisson process and found that it behaves similarly but gives results that are less accurate than the systematic - binomial process with our test function .",
    "we considered the following test function : @xmath271\\right\\},\\ ] ] plotted in figure  [ fig : est_binom ] ( left ) .",
    "we aim at estimating its mean using the horvitz - thompson estimator on a sample selected with a systematic - binomial process .",
    "a set of @xmath272 samples was generated using a systematic - binomial process with fixed size @xmath273 and for each value of the parameter @xmath274 .",
    "figure  [ fig : est_binom ] ( right ) shows that the accuracy of the horvitz - thompson estimator increases with @xmath1 .",
    "as expected , the systematic process performs better than any quasi - systematic process .",
    "corresponding simulation root mean square errors ( rmse ) are given in table  [ tab : rmse ] .",
    "we see in this table that the rmse decreases rapidly with moderate values of @xmath1 .",
    ".rmse of simulation results with a systematic - binomial process of size @xmath273 and different values of @xmath1 .",
    "[ cols=\"^,^,^,^,^,^,^,^,^\",options=\"header \" , ]",
    "by choosing the tuning parameter @xmath1 one can make a compromise between an accurate estimation of the target parameter with a poor estimation of the precision and a less accurate estimation of the target parameter but with a reliable estimation of the estimator variance .",
    "ideally one would have at its disposal a proxy interest function and could run simulations to select a suitable @xmath1 , that is to say a @xmath1 that corresponds to one s preferred compromise .",
    "when no useful proxy function is available , some general remarks apply . judging from our simulations",
    ", it seems that a small value of @xmath1 already helps reducing variance considerably compared to plain binomial process sampling .",
    "it is to be noted that , with values of @xmath1 between 1 and 2 , the joint inclusion probability function @xmath204 takes small values only when @xmath18 and @xmath19 are extremely close , as can be seen on figures  [ g1 ] and  [ g2 ] .",
    "this is not the case anymore when @xmath1 is larger than @xmath275 . in our simulations of section  [ s7 ] , using the transformed function , we observed large values of the variance estimator only with @xmath1 larger than 2 .",
    "a second point that could be inferred from our simulations is that larger sample sizes can accommodate for larger values of @xmath1 .",
    "however , we do not have solid arguments to support that and we may just be lacking more simulation results here .",
    "it is to be noted though that , for fixed size processes such as the systematic - binomial process , one can check in advance which values of @xmath1 and sample size @xmath6 , allow to satisfy the @xcite , @xcite conditions : @xmath276 for all @xmath277 . when these conditions hold , the variance estimator  ( [ equ : varhhsyg ] ) is non - negative .",
    "based on a numerical exploration , our conjecture is that this condition holds for @xmath278 and any sample size , but not for @xmath279 .",
    "we also conjecture that , for fixed @xmath280 , increasing the sample size does not help reducing the maximal value of @xmath281 .",
    "however , for a large enough @xmath6 , and a given @xmath18 , values of @xmath19 such that @xmath281 is greater than 1 are concentrated around @xmath18 , and thus these couples do not contribute much to the variance estimator  ( [ equ : varhhsyg ] ) .",
    "based on these considerations , it seems that @xmath278 could be a good compromise between stability of the variance estimator and stability of the target parameter estimator when no other information is available .",
    "the associated estimator true variance is however clearly greater than that obtained with larger values of @xmath1 .",
    "finally , the regularity of the interest function has its importance .",
    "we can observe that having a function that satisfies a hlder condition with exponent @xmath282 implies that the variance estimator  ( [ equ : varhhsyg ] ) is bounded for all @xmath283 ( n.b . : we need to take the restriction of the function to @xmath284 and transport its source to the unit circle first in order to account for what happens near 0 and 1 ) .",
    "in this paper , we only worked on sampling processes with constant first - order inclusion density .",
    "it is however common in finite population survey sampling to choose different inclusion probabilities for different population units using auxiliary information available ( e.g. the size of businesses or the approximate dispersion of the interest variable in a sub - population ) .",
    "suppose we want to have a sampling process with first - order inclusion density proportional to a non - negative continuous function @xmath285 , and note @xmath286 .",
    "assume that the set of zeroes of @xmath285 have no interior , so that @xmath287 is increasing .",
    "we just need to select a sample @xmath83 with a constant inclusion density process , and retain @xmath288 as our sample .",
    "indeed , if @xmath289)\\}$ ] is the counting function of the new process and @xmath290)\\}$ ] is the counting function of the constant density process , we have that @xmath291=\\lambda \\phi(x)\\mbox { for some } \\lambda > 0.\\ ] ] it follows that @xmath292 and that the first - order inclusion density of the new process is given by @xmath293 .",
    "the second inclusion density @xmath294 of this new process can also be derived from that , denoted by @xmath43 , of the process used to select @xmath83 .",
    "we find that @xmath295\\phi(x)\\phi(y)$ ] .",
    "both algorithms proposed in section  [ s5 ] work with any positive value of @xmath1 .",
    "the use of a parameter @xmath296 results in an attractive or clustering process where units tend to be selected in grouped clusters .",
    "this can be useful in some modelization problems .",
    "however , the interest of sampling with such clustering processes is probably limited to very specific objectives .    in future work",
    ", we intend to explore the possibility of developing similar sampling tools in spaces with more than one dimension .",
    "the generalization is far from being obvious as we only worked here on @xmath8 equipped with its field ordering and some notions strongly depend on it .",
    "quasi - systematic sampling processes are useful to the practitioner who wants to make his own compromise between a more accurate estimation of a functions mean and a good estimation of the uncertainty of his estimator .",
    "our simulations illustrate this trade - off between precision in the estimation of the mean and accuracy of the variance estimator .",
    "the former is better with a systematic sampling process while the latter is better with small values of @xmath1 .",
    "we argue that quasi - systematic sampling processes could be used in place of plain binomial or poisson processes for the purpose of estimating a mean in a continuous universe .",
    "a possible application is the estimation of the total or the mean of a variable of interest over time .",
    "the authors are grateful to one associate editor and three reviewers for their insightful comments that helped considerably improve the quality of this paper .",
    "this work was supported in part by the swiss federal statistical office .",
    "the views expressed in this paper are solely those of the authors .",
    "m. w. was partially supported by a doc.mobility fellowship of the swiss national science foundation .",
    "20 natexlab#1#1[1]`#1 ` [ 2]#2 [ 1]#1 [ 1]http://dx.doi.org/#1 [ ] [ 1]pmid:#1 [ ] [ 2]#2 , & ( ) . . , _ _ , .",
    "( ) . . , _",
    "( ) . . : .",
    "( ) . . , _",
    "http://www.sciencedirect.com/science/article/pii/016771529390028h . . ,",
    "probability and its applications ( ed . ) . : .",
    ", & ( ) . .",
    "probability and its applications ( ed . ) . : .",
    "( ) . . in _ _ ( pp . ) . : . , & ( ) . . , _",
    ", , & ( ) . .",
    "( ed . ) . : .",
    "( ) . . , _",
    "_ , . , & ( ) .",
    "( ) . . , _",
    "_ , . , & ( ) .",
    "springer . : .",
    ", & ( ) . .",
    ": . , & ( ) . . ,",
    "( ) . . , _",
    "( ) . . : .",
    "( ) . . , _",
    "( ) . . : . , & ( ) . . , _"
  ],
  "abstract_text": [
    "<S> a specific family of point processes are introduced that allow to select samples for the purpose of estimating the mean or the integral of a function of a real variable . </S>",
    "<S> these processes , called quasi - systematic processes , depend on a tuning parameter @xmath0 that permits to control the likeliness of jointly selecting neighbor units in a same sample . </S>",
    "<S> when @xmath1 is large , units that are close tend to not be selected together and samples are well spread . </S>",
    "<S> when @xmath1 tends to infinity , the sampling design is close to systematic sampling . for all @xmath2 , the first and second - order unit inclusion densities are positive , allowing for unbiased estimators of variance .    </S>",
    "<S> algorithms to generate these sampling processes for any positive real value of @xmath1 are presented . </S>",
    "<S> when @xmath1 is large , the estimator of variance is unstable . </S>",
    "<S> it follows that @xmath1 must be chosen by the practitioner as a trade - off between an accurate estimation of the target parameter and an accurate estimation of the variance of the parameter estimator . </S>",
    "<S> the method s advantages are illustrated with a set of simulations . </S>"
  ]
}