{
  "article_text": [
    "the first stars in the universe ( so called population iii or pop iii stars ) emerge several hundred million years after the big bang and dramatically change the physical conditions of their environment .",
    "the properties of pop iii stars have a fundamental influence on many subsequent physical processes , such as the synthesis of heavy elements , subsequent star and galaxy formation , or reionisation of the intergalactic gas , and it is therefore crucial to understand primordial star formation .",
    "although a consistent and widely accepted formation scenario developed over the last few years @xcite , there are still a number of open questions , whose answers might modify this picture .",
    "a review of some of these these open questions is given by @xcite .",
    "in this paper , we focus on the determination of the optically thick h@xmath0 cooling rate , because only little progress has been made on this topic since the late 80s in the context of star formation .",
    "furthermore , h@xmath0 emission is the dominant cooling process in this regime and hence a detailed understanding of its efficiency under different physical conditions is key to model pop iii star formation and gas dynamics in primordial halos . + following the standard formation scenario , the first stars form at redshifts @xmath5 in dark matter halos that have total masses of @xmath6 and virial temperatures of around @xmath7k @xcite .",
    "gas in the centre of these dark matter halos decouples and undergoes self  gravitating collapse @xcite .",
    "the decoupled gas clouds have jeans masses between @xmath8 and @xmath9 @xcite and a critical number density of @xmath10 when they decouple from their host halos @xcite . during the collapse",
    ", gas cools mainly via h@xmath0 rotational and vibrational line emission , with the h@xmath0 fractional abundance being a few times @xmath11 at the beginning of the collapse and becoming close to unity due to three  body h@xmath0 formation above @xmath12 .",
    "because these cooling processes can cool the gas very efficiently , the overall collapse proceeds almost isothermally until the gas becomes very optically thick at high densities and an adiabatic core forms .",
    "the exact determination of the optically thick cooling rate requires information about the velocity profile of the cloud , because relative velocities doppler  shift the spectral lines and therefore increase the photon escape probability .",
    "the shortcomings of commonly used methods for optically thick cooling lie mainly in the assumption of isotropy and in the dependence on local quantities .    due to tidal forces and an initial angular momentum",
    ", the collapse does not proceed in a spherically symmetric manner , but rather leads to the formation of a rotationally supported disc around the first protostar .",
    "the disc generally extends out to @xmath13au , has a characteristic temperature of @xmath14k , becomes gravitationally unstable , and fragments into multiple parts @xcite .",
    "the disc  like structure is a typical feature due to the inability of the halo to transfer angular momentum outwards quickly enough @xcite .",
    "one of the main goals of simulations of primordial star formation is to establish the form of the pop iii initial mass function ( imf ) .",
    "the mass of a pop iii star is the crucial parameter which defines its luminosity , temperature , spectrum , lifetime , final fate , and its metal yields .",
    "however , the significant variations and uncertainties in the expected mass ranges @xcite reveal the lack of understanding of the primordial gas fragmentation behaviour .",
    "since cooling is the key ingredient for disc instabilities and fragmentation , an accurate determination of optically thick h@xmath0 cooling is of general interest for the determination of the primordial imf .    here , we analyse the dependence of fragmentation on two different cooling implementations : the commonly used sobolev approximation and a more sophisticated , yet computationally expensive approach based on the treecol algorithm of @xcite .",
    "we also present a new approximate method , which yields photon escape fractions with mean relative errors smaller than 10% .",
    "this paper is ordered as follows : in section [ sec : methods ] , we review the different approaches that are commonly used to model optically thick h@xmath0 cooling . in section [ sec : simulations ] , we describe our numerical methodology . in section [ sec : results ] , we test the methods and present our results .",
    "we discuss these results in section [ sec : discussion ] , and conclude in section [ sec : conclusion ] .",
    "in this section , we present the commonly used photon escape probability approach for the determination of optically thick h@xmath0 cooling rates and several methods of calculating this probability .",
    "moreover , we derive a correction factor for the sobolev approximation to account for the overlap of spectral lines .      since h@xmath0 is a symmetric , diatomic molecule , it has no permanent dipole moment and can therefore only radiate via ro  vibrational transitions @xcite . in the optically thin regime @xmath15",
    "we expect all radiation to escape the cloud freely and the cooling rate can be calculated fairly accurately as a function of the local density , temperature and chemical composition of the gas .",
    "a number of different parametrisations of the h@xmath0 cooling rate in terms of these quantities are available in the literature . in this work",
    ", we use the rates given in @xcite . in the optically thin case",
    "we assume that photons , which are emitted in the ro  vibrational transitions , can escape the cloud without being scattered or absorbed and therefore transport thermal energy outwards efficiently . in the optically thick case , however , scattering and absorption events might capture the photons and hence decrease the overall cooling efficiency .",
    "one generally assumes complete redistribution of the frequency between these scattering events and uses the `` escape probability method '' in order to solve this problem .",
    "most important for our further discussion are the applications of the escape probability method by @xcite and @xcite to the case of optically thick cooling in primordial gas .",
    "the cooling rate in an optically thick medium is given by @xmath16 where @xmath17 is the energy separation between the lower level @xmath18 and upper level @xmath19 , @xmath20 is the spontaneous radiative transition rate for transitions between @xmath19 and @xmath18 , @xmath21 is the probability for an emitted line photon to escape without absorption , and @xmath22 is the population density of hydrogen molecules in the upper level . following @xcite , we assume all energy levels to be populated according to local thermodynamic equilibrium and we consider rotational levels from @xmath23 to @xmath24 and vibrational levels @xmath25 . at the temperatures of interest , the contribution of other levels will be negligibly small ( @xmath26 ) .",
    "we take values for the level energies from the compilation made available by p. g. martin on his website and the radiative transitions rates from @xcite .",
    "since all other quantities are known for typical conditions in primordial gas , the remaining task is the determination of the photon escape probability .",
    "based on the work by @xcite , @xcite derived the escape probability for constant velocity gradients in his study of expanding envelopes ( for an english translation see @xcite ) .",
    "this approximation has been reviewed during the last few decades @xcite and is widely used in simulations of primordial star formation @xcite . following the derivation by @xcite , the photon escape probability is given by @xmath27 where @xmath28 is the opacity at the line centre .",
    "the absorption coefficient for a transition from the lower to the upper level is given by @xmath29 \\phi ( \\nu ) , \\label{eq_alpha}\\ ] ] where @xmath30 is the einstein coefficient for absorption and @xmath31 is the line profile function .",
    "the opacity can be written as @xmath32 where @xmath33 is a characteristic length scale @xcite . according to equation ( [ eq_alpha ] ) ,",
    "@xmath34 is only a function of temperature and , following @xcite , we can express the optical depth by @xmath35 where @xmath36 defines an effective column density .",
    "hence , the last task for the determination of optically thick cooling is the calculation of the characteristic length and the associated effective column density . knowing these quantities ,",
    "one can generally determine the angle  dependent escape probability and afterwards average it over all lines of sight and all relevant ro ",
    "vibrational lines .",
    "since h@xmath0 cooling is due to a number of lines without a single dominant line @xcite , we can directly average the escape probability over these lines .",
    "furthermore , one often assumes spherical symmetry , whereas @xcite proposed an average over three orthogonal directions @xmath37 the averaged escape probability finally relates the optically thin and optically thick cooling rate by @xmath38 and is therefore also known as the `` opacity correction '' . in order to determine this escape probability , we have to understand the dynamics of the cloud .",
    "if the photon is emitted in the centre of the cloud and an envelope of gas is moving towards it with a constant radial velocity gradient @xmath39 , then the photon observes the spectral lines of the envelope to be doppler  shifted with respect to its rest frame . according to @xcite , a photon is not absorbed and can escape freely , if the spectral lines of a possibly absorbing h@xmath0 molecule are shifted by more than one thermal line width .",
    "the line width of thermal line broadening is given by @xmath40 where @xmath41 is the central frequency of the line , @xmath42 is the thermal velocity of molecular hydrogen , @xmath43 is the temperature , and @xmath44 is the mass of a hydrogen atom . using this , we can determine the characteristic distance @xmath33 beyond which the sobolev criterion is fulfilled .",
    "this length scale is typically known as the sobolev length @xmath45 phrased differently , all relevant matter that might reabsorb a photon is within its sobolev length . assuming a constant density within this sobolev length , the effective column density can be determined by @xmath46 in order to capture the three  dimensional dynamics of the collapse",
    ", one normally uses @xmath47 for the determination of the sobolev length @xcite .",
    "however , a fundamental problem of the sobolev approximation was already mentioned by several authors : both the velocity gradient and the number density have to be constant within one sobolev length @xcite . as we will see below ,",
    "this assumption is generally not valid .      for simplicity",
    ", @xcite assumed the absorption coefficient @xmath48 to be zero outside the interval @xmath49 $ ] and @xcite used the same simplification . following this approach , a photon can escape freely from the optically thick gas after one sobolev length @xmath50 , because it will not be reabsorbed thereafter .",
    "the actual absorption probability however , is related to the true overlap of spectral lines . in the present context",
    ", the shape of the h@xmath0 lines is dominated by thermal broadening and can therefore be described by a normalised gaussian profile . if one line with central frequency @xmath41 is doppler  shifted to the frequency @xmath51 , the relative line displacement in units of the thermal gas velocity between these two cases is given by @xmath52 accordingly , the relative overlap of these two line profiles can be calculated by @xmath53 the overlap of spectral lines for the special case @xmath54 is illustrated in figure [ fig : overlap ] .",
    "normalised thermal line profiles as a function of frequency in units of the thermal line width .",
    "the right profile is shifted by one thermal line width with respect to the left profile .",
    "the overlapping area shows a relative overlap of 62% , which should be negligible according to @xcite . ]",
    "this displacement represents the case after one sobolev length , though the relative overlap is still @xmath55 .",
    "while the original sobolev approximation ignores all possible absorption events beyond this point , there is a non  negligible absorption possibility beyond one sobolev length and we therefore need to introduce a correction term in order to account for the additional matter . even after three sobolev lengths the relative overlap , for example , is still 13% and reabsorption might be possible .    in order to find a proper correction for this overlap , we start from the basic definition of the column density . however , we are not interested in the total column density but rather in the effective column density which includes only the gas that could be relevant for the reabsorption of escaping h@xmath0 line photons .",
    "the sobolev approximation gives a very simple answer to the question of which gas we have to include in the effective column density , namely all gas within one sobolev length",
    ". expressed in terms of line overlap we write this as @xmath56 where a constant number density of molecular hydrogen is assumed in the last step .",
    "thus , @xcite overestimated the overlap and the matter contribution within one sobolev length but neglected all matter contributions beyond this point .",
    "since we want to account for the true overlap of spectral lines , we introduce the relative line overlap @xmath57 as a weighting function into the determination of the effective column density , @xmath58 the remaining problem is to relate the line displacement @xmath59 to the distance @xmath60 along the line of sight .",
    "assuming a constant velocity gradient @xmath61 , we can rewrite equation ( [ eq_sob_length ] ) into @xmath62 and transform the radial integration into an integration over the relative line displacement @xmath63 which finally yields @xmath64 in other words , the relevant column density for the determination of the escape probability of line photons is about 1.7 times higher than originally assumed by sobolev .",
    "although we correct for the line overlap , we should still keep in mind that this derivation implies several assumptions like constant velocity gradient and constant density within the sobolev length .",
    "also some gas further away may be absorbing , because of similar velocities .",
    "in particular in turbulent clouds this may become relevant .",
    "this is related to the question of how `` real '' clumps identified in position  position ",
    "velocity space are in position  position  position space ( see e.g. @xcite and @xcite ) .",
    "molecular hydrogen has more than two hundred spectral lines in the range @xmath65 which could be relevant for cooling primordial gas @xcite .",
    "although these lines appear to be very close to each other , the possibility that a photon is emitted in one line with a certain frequency and absorbed by another line which is doppler  shifted into the emitting frequency is negligibly small ( @xmath66 ) .",
    "consequently , this effect can be ignored .",
    "besides the commonly used sobolev approximation there are several other approaches , which we present in the following subsections .",
    "@xcite model molecular hydrogen and star formation in cosmological simulations .",
    "they determine h@xmath0 column densities for the self  shielding of h@xmath0 against lyman ",
    "werner photons by using a `` sobolev  like '' approximation .",
    "they define a characteristic length scale @xmath67 based on the number density and its gradient .",
    "the column density is then simply given by @xmath68 this approach accounts for the density gradient in the gas distribution . in the following",
    ", we will label this method as `` gnedin '' .",
    "they claim that this approximation provides a very good estimate for the column density in the range @xmath69 .",
    "although we are dealing with star formation on much smaller scales than they do , their method seems to be a reasonable , scale  invariant approach for the determination of effective column densities .",
    "furthermore , this method depends only on local quantities and is easy to implement in different codes .",
    "nevertheless , this method includes no information about the velocity profile of the cloud and therefore neglects the enhanced photon escape probability due to the doppler  shifting of lines .",
    "we are interested in the column densities in order to determine the photon escape probabilities for h@xmath0 line cooling ( equation [ eq_thickcooling ] ) . besides the previously presented methods , there are two analytical fitting functions that directly relate a given number density of the gas to the photon escape probability . the first fitting function @xmath70 \\label{ra_fit_formula}\\ ] ] with @xmath71 and @xmath72",
    "was proposed by @xcite and has been applied in several ( mainly grid  based ) simulations @xcite .",
    "this formula was obtained from the detailed one  dimensional calculation by @xcite .",
    "a second method was proposed by @xcite who study the chemo  thermal instability in primordial star  forming clouds .",
    "the idea follows the approach by @xcite but with a smooth transition and therefore a continuous derivative towards the optically thin regime .",
    "the formula is given by @xmath73 where @xmath74 , @xmath75 , and @xmath76 .",
    "these fits are the easiest and most direct way to determine the photon escape probability , but their use does not account for any information about the temperature , velocity or density profiles .",
    "recently , @xcite investigated the collapse of primordial gas using a multi  line , multi  frequency raytracing scheme in order to accurately model the transfer of h@xmath0 line emission .",
    "although he provides a new fit formula , we will not include this in our analysis , since it is very similar to the original fit function by @xcite .      in order to find a method for the determination of optically thick cooling that only depends on local quantities of the collapse and that is easy to implement , but nevertheless captures the dynamics of the cloud",
    ", we propose a combination of the sobolev and gnedin approximation .",
    "the corrected sobolev approximation takes the line overlap into account but neglects the decreasing density . on the other hand",
    ", the gnedin approximation takes the decreasing number density into account but neglects the doppler  shifting of lines . since each method on its own generally overestimates column densities , the general idea behind this new approach is to combine these two methods in order to overcome their individual shortcomings .",
    "the reciprocal sum @xmath77 of the two characteristic lengths provides the right behaviour .",
    "if both lengths are of the same order ( @xmath78 ) , the result should be smaller than both lengths ( @xmath79 ) , since each length individually overestimates the column density .",
    "whereas if one length is significantly smaller than the other length @xmath80 , the result should be equal to the smaller one ( @xmath81 ) , because beyond this smaller distance the photons can escape freely anyway . following this method ,",
    "the number density is simply given by @xmath82",
    "here , we describe the implementation of treecol and three criteria to define the effective column density . furthermore , we present our simulations and the initial conditions .      the main problem of the sobolev approximation is the dependence on local quantities and therefore the neglect of all information about density gradients , velocity profile and the actual shape of the cloud .",
    "generally , the most exact way to determine effective column densities is to sum up all relevant mass along all possible lines of sight . in order to avoid this extremely high computational effort",
    ", @xcite designed the treecol algorithm which determines column densities based on a tree structure , used by many gravitational @xmath83body solvers .",
    "treecol uses a spherical pixelation with diamond  shaped pixels based on healpix @xcite . during the walk of the tree , all relevant data for the column density map are collected and projected onto a spherical grid . since the data are already stored in a tree , treecol can use this information and therefore scales as @xmath84 with the number of cells or particles @xmath83 .",
    "however , in our simulations , the usage of treecol slows down the simulation by a factor of about five with respect to a run without treecol .",
    "this slowdown is mainly related to the evaluation of several inverse trigonometric functions .",
    "although we use this method in an sph  based simulation , the only requirement for its implementation is the clustering of matter in a tree  like structure , as indeed , the treecol method has already been implemented in the arepo moving mesh code @xcite and the flash amr code ( wnsch et al .",
    ", in prep . ) .",
    "+ treecol overcomes several shortcomings of the sobolev approximation .",
    "first of all , we can use it for any density distribution because we directly sum up the individual mass contributions .",
    "furthermore , we can use the velocity information of the tree nodes and do not have to assume a constant velocity gradient .",
    "additionally , we account for the actual spatial matter distribution and do not have to stick to a rough one dimensional approximation .",
    "while the original treecol algorithm computes the h@xmath0 column densities of the entire cloud , in what follows , we will present three improved versions that account for the doppler  shifting of the line by only including mass that lies within the appropriate velocity range .     of the target particle .",
    "in the lookup implementation , the matter contributions to the column density are weighted by the relative overlap of spectral lines , which in turn depends on the relative velocities .",
    "this weighting is illustrated by the partial filling.,scaledwidth=45.0% ]      the sobolev approximation assumes that all relevant mass for the column density is located within one sobolev length .",
    "translated into velocities , we should only include particles or tree nodes whose relative velocity is smaller than the thermal velocity .",
    "thus , we modify treecol in order to include only the mass contributions of nodes that fulfil this criterion . a schematic illustration of this approach is given in figure [ fig : scheme ] .",
    "from there we already see that the relevant volume around a particle does not necessarily have to be spherical , but usually follows the dynamic shape of the cloud .",
    "following equation ( [ eq : correction_factor ] ) , the next possible approach is to include all tree nodes whose relative velocities fulfil the criterion @xmath85 . using this criterion",
    ", we take into account the non ",
    "negligible overlap beyond one sobolev length .",
    "however , the individual velocity contributions are still not taken into account correctly , and we will focus on the following , more sophisticated approach for further studies .",
    "the above methods only distinguish whether matter contributes to the effective column density or not .",
    "however , the doppler  shifting of spectral lines is a smooth process and so is the matter contribution , which should be included in a proper treatment of line cooling .",
    "the overlap of spectral lines and therefore the relevance for the effective column density depends only on the relative velocity . since we know this information for the individual tree nodes , we weight their contributions to the column density map with their relative spectral line overlap ( equation [ eq_overlap ] ) .",
    "a schematic illustration of this approach is given in figure [ fig : scheme ] .",
    "this method does not rely on any assumptions ( like a constant velocity gradient or number density ) , but captures the complete three dimensional collapse of the cloud and takes care of the true line overlaps .",
    "this is the most exact method and it will serve as a reference for our analysis . for simplicity , we will refer to this method simply as `` treecol '' , but actually mean the lookup method implemented in treecol  if not explicitly stated otherwise .      in this section",
    ", we describe the general properties of our code , discuss the implementation of the treecol method , comment on its computational effort , and present our initial conditions .",
    "we use a modified version of the cosmological simulation code gadget2 .",
    "the original code was written by @xcite in order to simulate structure formation by means of smoothed particle hydrodynamics ( sph ) .",
    "for the nonlinear collapse , we follow the chemical and thermal evolution of the gas cloud , solve the rate equations and couple the relevant heating and cooling terms to the hydrodynamic equations . for this purpose",
    ", we use a chemical network and cooling functions developed by glover and collaborators ( see @xcite and @xcite for full details ) .",
    "the primordial chemistry network includes h , d , he , h@xmath0 , h@xmath86 , h@xmath87 , d@xmath86 , h@xmath88 , hd , he@xmath86 , he@xmath89 and e@xmath87 . the rate equations between these species",
    "are solved self ",
    "consistently for every time step .",
    "for the three - body h@xmath0 formation reaction @xmath90 we adopt the rate coefficient of @xcite , derived by applying the principle of thermal balance to the collisional dissociation rate of @xcite .",
    "the time scales associated with chemical heating and cooling can become extremely short when species come close to chemical equilibrium .",
    "since the particle time step depends on the thermal timescale , this can result in some particles having very short timescales once the gas density exceeds @xmath91 . at this point",
    "it can become computationally prohibitive to run the simulation further .",
    "besides h@xmath0 line cooling , which is the most relevant process for this analysis , we also track the contribution by several other heating and cooling processes , such as electronic excitation of h and he , recombination , photodissociation , hd line cooling , compton cooling , and bremsstrahlung ( see * ? ? ?",
    "? * ; * ? ? ?",
    "* for a more detailed description ) .",
    "for the collisional induced emission ( cie ) cooling , we follow the implementation by @xcite , which is based on studies by @xcite , and @xcite . above densities of @xmath92 ,",
    "cie cooling from h@xmath0 becomes more efficient than h@xmath0 line cooling , but the gas is most susceptible to fragmentation at densities below @xmath93 ( see section [ sec : frag2 ] ) .",
    "consequently , the implementation of cie cooling is unlikely to significantly affect the conclusions of our study .",
    "furthermore , we implement a simple feedback model for the accretion heating by assuming that the accreting protostars produce an accretion luminosity of @xmath94 , where @xmath95 is the mass accretion rate and @xmath96 and @xmath97 are the mass and radius of the protostars , respectively .",
    "we use the models by @xcite for the protostellar radius and assume a constant accretion rate of @xmath98 , which is consistent with @xcite , @xcite , and with the actual accretion rates in our model . the heating rate",
    "is then given by @xmath99 where @xmath100 is the gas density , @xmath101 is the planck mean opacity and @xmath60 is the distance from the source .    in order to minimise computational effort in the high  density regime ,",
    "we use sink particles , based on the implementation by @xcite , which was already used before ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "above a certain density threshold @xmath102 all sph particles are merged into one single sink particle , which now contains all mass and momenta of the merged particles .",
    "this approach conserves mass and momentum , avoids small dynamical and chemical time steps , and we can identify the protostars by the newly formed sink particles . the critical density threshold is chosen so that the local jeans mass is resolved by at least 100 sph particles , following the resolution criterion by @xcite . + nevertheless , one should keep in mind that sink particles are not physical entities in their own right , but rather computationally motivated and consequently may cause problems by introducing a discontinuity in the mass and number of particles as well as a lack of pressure forces at the accretion radius . strictly speaking , they also violate the hydrodynamic equations because the accretion onto the sink particle happens instantaneously @xcite . in order to guarantee that the formation of a sink particle actually represents the local collapse to a protostar , we introduce several formation criteria .",
    "the gas clump converted into a sink particle must exceed a certain density threshold , it must be gravitationally unstable , at the centre of a locally convergent flow , and it must have a certain distance to preexisting sink particles ( see e.g.  @xcite ) .",
    "another crucial value is the accretion radius @xmath103 , because a too large accretion radius might artificially influence the fragmentation behaviour @xcite . on the other hand , @xcite and @xcite state that fragmentation does not occur for densities above @xmath104 , because there are no more efficient chemical or radiative cooling mechanisms .",
    "@xcite , who additionally include the effect of heating by accretion feedback , find this value to be @xmath105 . phrased differently , the choice of the accretion radius might have an influence on the fragmentation behaviour but as long as the critical density is @xmath106 , we should capture all fragmentation of the cloud .",
    "we set the critical density to @xmath107 in order to resolve the jeans mass throughout the simulation .",
    "the jeans length is @xmath108au under these conditions .",
    "such a small accretion radius might lead to tiny dynamical time steps in the vicinity of sink particles and hence increase the computational effort .",
    "therefore , we set the accretion radius to @xmath109au , which clearly fulfils the resolution criterion , but may suppress small  scale fragmentation .",
    "the general idea of the different cooling approaches has already been discussed in section [ sec : coolingmethods ] . here",
    ", we address the actual implementation of these approaches into the code .",
    "+ the optically thick cooling rate @xmath110 is given by equation ( [ eq_thickcooling ] ) , where the photon escape probability @xmath111 can be expressed as a function of the column density divided by the thermal velocity of the h@xmath0 molecules ( @xmath112 ) and the temperature @xmath43 .",
    "these values are stored in a lookup table for @xmath113 and @xmath114 .    for the treecol  based determination of the effective column densities we create another lookup table , which relates the relative velocities in units of the thermal velocities ( @xmath115 ) to an overlap of spectral lines .",
    "since the relative velocities are distributed roughly equally throughout the simulation , we create this lookup table with linear steps in velocity space . for each node that might contribute to the effective column density we first check if @xmath116 because otherwise the line overlap is smaller than @xmath11 and",
    "can be neglected anyway .",
    "the computational effort for the lookup of relative overlaps is negligibly small compared to the computational cost of treecol itself .",
    "+      the initial conditions of our simulations presented here are generated in the following way : first , we ran collisionless @xmath83body simulations with 1 mpc/@xmath117 comoving in length with uniform mass resolution to capture collapsing dark matter halos starting at a redshift @xmath118=100 .",
    "these collisionless simulations were executed with gadget3 @xcite and we employ cosmological parameters consistent with the wmap7 measurements ( @xmath119 , @xmath120 , @xmath121 , @xmath122 , @xcite ) .",
    "we would not expect our results to differ significantly if we were to use the cosmological parameters measured by planck @xcite .",
    "this choice of parameters is for consistency with our previous works @xcite . since we ensure that the parameters for the tree force calculation are set to the same value in the gadget3 and arepo simulations , described later in this section , this is practically equivalent to using arepo for the n  body simulation .",
    "the reason we used gadget3 to evolve dark matter only initial conditions is that , in principle , it allows us to make use of more physical merger histories of dark matter halos when picking a specific dark matter halo to resimulate .",
    "currently , this is only analysed with ease from gadget3 snapshots but not from arepo snapshots . from this parent simulation ,",
    "we select four dark matter halos , which are individually shifted to the centre of the simulation box .",
    "the regions further away from each specific halo are represented by dark matter particles of proceedingly larger mass and lower resolution .",
    "the parent simulation contains @xmath123 ( halo 1 ) and @xmath124 ( halo 2 - 4 ) particles . at the regions of interest the mass resolution of the dark matter particles is improved by @xmath125 .",
    "the dark matter mass is 7.3 @xmath126 for the @xmath124 runs .    from this newly generated initial condition with improved dark matter resolution",
    ", we start a hydrodynamical simulation with the moving  mesh code arepo @xcite . at the start",
    " up of our hydrodynamic simulations , the code generates gas cells from dark matter only initial conditions . in order to numerically follow the dynamics of pristine gas in a cosmological context",
    ", we adopt an on  the  fly mass refinement scheme , which ensures that the jeans length is resolved by at least 64 cells at all times . in order to deal with memory consumption and small time steps ,",
    "we stop our simulation when the highest density in the simulation is @xmath127 @xmath128 .",
    "we cut out spheres with a radius of @xmath129 pc , store only gas cells , and continue the simulation forcing further mass refinement in a non  cosmological setup ( 256 cells per jeans length ) .",
    "this is to ensure that the jeans mass at @xmath130 is resolved with @xmath127 100 cells without further refinement in the gadget2 simulation .",
    "the resulting gas clouds serve as initial conditions for the high  resolution runs , which are performed with gadget .",
    "these clouds have average masses of @xmath131 , temperatures of @xmath132k , and a mean h@xmath0 abundance of @xmath133 .",
    "the average particle number is @xmath134 per simulation , which yields a mass resolution of @xmath135 in the central region .",
    "these final runs are performed in gadget2 , to make use of the already implemented primordial chemistry .",
    "an additional external pressure term is added in order to compensate for the missing gas contribution from the surrounding halo @xcite . in order not to artificially squeeze the cloud",
    ", we set the external pressure to the smallest occurring pressure in the outer 10% of the cloud .",
    "in this section , we first test the validity of our new method in a simple , spherically symmetric test scenario .",
    "then , we compare the treecol  based cooling approach to the local , isotropic cooling implementations for the cosmological halos .      before we apply our new method to cosmological halos , we test its accuracy in a simple test scenario . we start from a spherical , primordial cloud with a mass of @xmath136 , an initial density of @xmath137 and a temperature of @xmath138k",
    ". the gas is represented by @xmath139 sph particles and we follow the simulation to densities above @xmath140 , where we insert sink particles . for each different method",
    ", we run the simulation independently and compare the effective h@xmath0 column densities in figure [ plots_rho_col_syn ] .",
    "the lookup approach explicitly accounts for the true line overlaps and therefore is the most exact method .",
    "while `` treecol corrected sobolev '' accounts for the correction factor and reproduces `` treecol lookup '' remarkably well , `` treecol sobolev '' corresponds to the uncorrected sobolev method and generally underestimates the effective column density .",
    "consequently , this correction factor is mandatory to account for the exact line overlaps .",
    "furthermore , the commonly used sobolev method and the gnedin approach , which are only based on local gas quantities , overestimate the column density in the optically thick regime above @xmath141 .",
    "these two local methods yield almost the same results for the effective column density , which means that the relation @xmath142 holds for the spherical collapse scenario .",
    "this illustrates that the density is generally not constant within the sobolev length , but rather varies on the same length scale as the velocity field .",
    "hence , even in this simple test case , the local methods are not able to determine the column density properly .      in this section ,",
    "we test our approaches in more realistic cosmological halos .",
    "we first use the treecol  based simulations and determine all relevant information by post  processing these output files . by doing so , we can focus on the intrinsic differences of the methods ( determined under the same physical conditions ) rather than comparing different simulations with presumably different dynamics .",
    "the plots in this section represent averages over all four cosmological halos .",
    "we want to find an accurate cooling approach that reproduces the treecol method best and hence , we compare the commonly used sobolev approximation with the corrected sobolev approximation , the gnedin approach and our new reciprocal method , which combines the corrected sobolev and gnedin approach .",
    "the column density for these different approaches can be seen in figure [ plots_rho_col ] .    generally , the local methods overestimate the effective column density in the optically thick regime ( @xmath143 ) . especially at later stages of the collapse these differences increase , because the slope of the photon escape fraction as a function of density flattens with time in the optically thick regime for the treecol method .",
    "the ( corrected ) sobolev method overestimates the column density all the time , whereas the gnedin and reciprocal approaches overestimate the column density only for high densities .",
    "the latter yield accurate fits for the density regime @xmath144 , whereby one should keep in mind that the relative importance of h@xmath0 line cooling decreases above @xmath145 .",
    "realising that the sobolev approximation already overestimates column densities , one might ask why we need this additional correction factor , which makes the approximation even worse . a detailed answer to this question",
    "is given in section [ sec : sobfails ] , but we already want to emphasise the total neglect of any density gradient .",
    "the sobolev approximation assumes a constant density , although the density of molecular hydrogen generally decreases when moving radially outwards .",
    "hence , this approximation is not valid , but leads to an overestimation of the column density ( already for the uncorrected sobolev method ) .",
    "the photon escape probability as a function of density can be seen in figure [ plots_rho_opac_methods ] for different methods .",
    "although there are slight differences between the individual approaches , all methods seem to agree well with the treecol approach prior to the formation of the first sink particles .",
    "however , at later times , the treecol approach yields higher values for the photon escape probability , corresponding to a smaller effective opacity of the cloud .",
    "the other methods , which depend only on local quantities , can not reproduce this behaviour and therefore underestimate the photon escape probability .",
    "we compare the analytical fitting formulae to the treecol method by using the parametrised formulae ( equation [ ra_fit_formula ] and [ greif_fit_formula ] ) with the fit parameters @xmath146 , @xmath147 , @xmath148 , and @xmath149 . in figure [ plots_rho_opac_analyt ]",
    "we see the original functions and the best fits to the treecol data .",
    "the newly adjusted fits minimise the weighted scatter sum @xmath150 where @xmath151 is the number of particles , @xmath152 is the analytic fit , @xmath153 is the photon escape probability based on the treecol approach , @xmath154 is the h@xmath0 cooling rate , and @xmath155 is the cie cooling rate for the @xmath156th particle , respectively .",
    "the weighting by the relative cooling rate accounts for the decreasing relevance of h@xmath0 cooling at higher densities .",
    "+ for each single snapshot , the exact data can be fitted remarkable well by an analytic formula , but we note that both fit parameters vary strongly during the collapse .",
    "although the original fits are a satisfying approximation at the beginning of the collapse , their accuracy decreases during the collapse and they totally miss the true photon escape probabilities at later stages .",
    "+ the time evolution of the fit parameter @xmath157 ( equation [ ra_fit_formula ] and [ greif_fit_formula ] ) reveals an interesting insight into the structure of the collapse . in figure [ opacity_fit ]",
    "we compare the evolution of @xmath157 for both fit formulae with time .",
    "it quantifies the slope and therefore represents the dependence of the opacity on density .",
    "the parameters @xmath157 and @xmath158 are fitted simultaneously , but the plot only contains the slope because it reveals more information about the underlying physics . for large @xmath157 , the cloud becomes opaque with increasing density very promptly , whereas for a shallow slope the opacity remains low although the density increases .",
    "the blue dash  dotted line illustrates the original slope for both fits of @xmath159 , but the newly fitted formulae to the treecol data reveal that the actual slope is shallower and most notably varies with time .",
    "the small value of @xmath157 for @xmath160yr is a numerical artefact , because at these times there are almost no particles in the optically thick regime , which might define a distinct slope . on the other hand , the shallow slope of @xmath161 during the later stages of the collapse",
    "can be related to the flattening of the cloud .",
    "consequently , it is impossible to find one single analytic fit , which describes the dynamics of the collapse completely .",
    "however , the mean parameters that fit the treecol data best from @xmath162yr before formation of the first protostar until the end of our simulations are @xmath163 and @xmath164 .",
    "+ in order to analyse the accuracy of the different cooling approaches quantitatively , we determine the relative error of the photon escape probability for each method .",
    "therefore , we compare the photon escape probabilities of all particles above a certain density threshold to the ones determined with the treecol method . the density threshold is necessary , because below @xmath165 , the escape probability is very close to one anyway and consequently there are no significant deviations between the methods .",
    "the relative error @xmath166 is weighted by the relative h@xmath0 cooling rate , so that the mean relative error of the photon escape probability can be expressed as @xmath167 where @xmath168 is the number of particles above a certain density threshold .",
    "we chose the density threshold @xmath169 to analyse how accurate the methods are in this density regime .",
    "the time evolution of the mean relative photon escape probability error for this threshold can be seen in figure [ opacity_error_1e9 ] .",
    "the relative error is small at early times in the collapse because all photon escape probabilities are close to one , whereas at later times , more particles enter the optically thick regime and the relative errors rise to values between @xmath170 .",
    "the reciprocal approach is slightly better than the gnedin approximation , although both yield errors between @xmath171 throughout the simulations .",
    "interestingly , the corrected sobolev approximation yields higher errors ( @xmath172 ) , whereas the uncorrected one yields errors between @xmath173 .",
    "this behaviour is caused by the fact that the sobolev approximation already overestimates column densities because it neglects the density gradient .",
    "since the reciprocal method is mostly dominated by the gnedin approximation , we can conclude that the effective column density is more strongly influenced by the density gradient than by the relative velocities .",
    "however , the velocity information still improves the fit and is therefore important for a proper treatment .",
    "the original analytic fits are comparatively inaccurate with errors between @xmath174 and are therefore not displayed in this figure .",
    "however , the analytical fitting function proposed by @xcite yields slightly better results than the one proposed by @xcite . the same analysis for higher density thresholds ( @xmath175 ) shows qualitatively similar results , but with a trend to higher mean relative errors .",
    "here , we analyse the fragmentation behaviour of the gas with the different cooling implementations .",
    "we first compare the number of protostars that form in each simulation , analyse the dynamics of the collapse and then determine the susceptibility to fragmentation for the sobolev method and the treecol approach .",
    "we are interested in how the treatment of the cooling affects the characteristic mass range for pop iii stars . based on our simulations ,",
    "we compare the number of sink particles in each halo at the end of the simulations .",
    "however , due to a prohibitively small chemical time step and a too simplified treatment of feedback , we end the simulations before accretion has terminated . in order to compare the number of sink particles , we choose for each halo the snapshots with the same amount of accreted mass onto the sink particles .",
    "this condition enables us to compare the clouds for the sobolev  based and the treecol  based runs at the same stage of the accretion process .",
    "the resulting numbers of sink particles are given in table [ table : sinks ] .",
    "cccc    1 & 11.0 & 1 & 2 + 2 & 5.1 & 2 & 3 + 3 & 3.3 & 1 & 3 + 4 & 10.3 & 5 & 4    [ table : sinks ]    the treecol approach yields more sink particles in all but one halo .",
    "however , the time evolution of the number of sink particles ( see figure [ plot : timen ] ) suggests that this effect might be caused by a delay of the fragmentation in the sobolev  based runs .",
    "while the sobolev approximation causes the disc to fragment into 1 - 6 protostars , the treecol approach causes slightly earlier fragmentation with at least two protostars in each halo .",
    "since we had to end the simulations at this point , the final number of protostars can not be fully constrained in this case .",
    "however , the treecol method accelerates the collapse and the gas fragments earlier compared to the sobolev approximation .",
    "the accretion rates onto individuals protostars are in the range @xmath176 for the sobolev approximation and @xmath177 for the treecol approach in all four halos .      in order to study the fragmentation behaviour independently of the number of sinks",
    ", we first analyse the dynamics of the collapse .",
    "this analysis is mainly based on the fact that the temperature profile of a gas cloud directly influence the collapse to protostars by affecting the local jeans mass , which is the absolute minimum requirement for collapse and is a strong function of temperature @xcite .",
    "hence , we compare the basic quantities between the four runs using the treecol approach and the four runs using the sobolev approximation . the first quantity to compare",
    "is naturally the photon escape probability .",
    "figure [ plot_compare_opac ] illustrates the time evolution of the photon escape probability for both methods .        while the spatial distribution of the photon escape probability seems to be smoother for the treecol",
    " based run , the distribution is comparatively structured for the sobolev approximation .",
    "additionally , we see another important difference . using the treecol method yields values for the photon escape probability close to one at the end of the simulations , whereas the sobolev approximation yields smaller photon escape probabilities .",
    "obviously , the sobolev approximation is not able to capture the flattening of the cloud ( see section [ sec : sobfails ] ) .",
    "furthermore , the sobolev  based simulation develops only one central core , while an elongated core with two peaks is formed in the treecol  based run .",
    "since the photon escape probability has a direct influence on the cooling rates , we are consequently interested in the h@xmath0 cooling rate . this cooling rate is not significantly higher for the treecol  based run , although the photon escape probabilities are higher .",
    "this can be explained by the cooling implementation : due to the presumably higher cooling rate in the treecol  based run , thermal equilibrium is reached for lower temperatures .",
    "thus , the cloud simply remains cooler instead of increasing its cooling rate significantly .",
    "consequently , the gas in the sobolev  based runs is generally hotter , which can also be seen in figure [ plot_compare_temps ] .",
    "the difference of temperatures in this inner regime can be up to @xmath178k , which influences the fragmentation behaviour significantly .",
    "finally , we compare different fragmentation criteria of the clouds .",
    "the possibility of fragmentation in primordial clouds has been considered by many authors ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "fragmentation is a very chaotic , non  deterministic process and",
    "the actual outcome depends sensitively on the initial conditions @xcite .",
    "nevertheless , there are three analytic expressions that help to quantify the possibility of a gas cloud fragmenting :    * in order to locally contract instead of globally collapse , a necessary criterion for fragmentation of a gas cloud is @xcite @xmath179 where @xmath180)$ ] is the cooling time with the net cooling rate @xmath181 and @xmath182 is the free  fall time . *",
    "@xcite analysed the stability of rotating gas discs and derives the instability criteria @xmath183 where @xmath184 is the epicyclic frequency and @xmath185 is the surface density of the disc .",
    "formally , this criterion is only valid for thin discs whereas @xcite extended the criterion by requiring @xmath186 for a finite  thickness isothermal disc to fragment .",
    "* @xcite investigated the nonlinear outcome of a stability analysis of a keplerian accretion disc .",
    "based on numerical experiments , he derived the instability criterion @xmath187 where @xmath188 is the orbital frequency .",
    "the gammie criterion expresses the possibility that pieces of the disc cool and collapse before they have the opportunity to collide with one another in order to reheat the disc .    in their study on the formation and evolution of primordial protostellar systems ,",
    "@xcite find the toomre criterion insufficient for the quantification of gravitational instability and additionally use the gammie criterion .",
    "non of these criteria guarantees fragmentation @xcite , but a combination of them yields a reliable quantification of instabilities in the gas disc .",
    "+ we compare the radial and density profile of these fragmentation criteria for the sobolev  based and the treecol  based runs .",
    "we do this directly after formation of the first protostar to ensure comparability between the different runs and methods ( fig .",
    "[ fig : fragmentation ] ) .",
    "the requirement that all three fragmentation criteria have to be fulfilled simultaneously is very strict , because each criterion alone already quantifies stability .",
    "applying this conservative criterion shows that all simulations are susceptible to fragmentations in the density regime @xmath189 at a radius of @xmath190au from the densest region .",
    "however , the gammie criterion seems to be a less restrictive version of the rees  ostriker  criterion and consequently yields no additional constraint to this regime , because it is fulfilled anyway .",
    "the regime of fragmentation and the instability of the gas cloud is slightly higher for the treecol approach .",
    "especially the cooling time criterion remains significantly longer under the stability threshold for the treecol  based run , which is mainly a consequence of the lower temperatures , as discussed before .",
    "consequently , the high  density gas is more susceptible to fragmentation in the treecol  based runs . since these are averaged profiles over four halos , we expect these results to be representative for primordial star formation .",
    "in this section , we discuss the previous results , point out shortcomings of commonly used methods , and comment on the expected different fragmentation behaviour .",
    "the local and isotropic approximations fail in determining the proper effective column densities for h@xmath0 cooling .",
    "although they yield acceptable results up to the formation of the first protostars , most approaches break down during later phases of the collapse , because they can not capture the evolving dynamical structure , particularly once a flattened accretion disc has formed .",
    "the appropriate consideration of the overlap of spectral lines is very important , although even the uncorrected sobolev approximation generally overestimates column densities .",
    "further shortcomings are mostly related to the assumption that all relevant quantities are constant within the characteristic length scale .",
    "this simplification avoids the evaluation of integrals along the line of sight but is formally only valid for large velocity gradients .",
    "the analysis of the relevant quantities shows that the h@xmath0 number density , thermal velocity and the gradient of the velocity vary by up to two orders of magnitude within one sobolev length .",
    "while the thermal velocity seems to be rather constant , the h@xmath0 number density varies most strongly .",
    "since the distribution around the central value is not symmetric , these effects do not cancel out and generally lead to an overestimation of column densities .",
    "+ due to angular momentum conservation in the infalling material , a disc forms around the first protostar and the photon escape probability is enhanced perpendicular to the disc .",
    "an isotropic column density estimation that depends only on local quantities , can not capture this feature and therefore generally underestimates the photon escape probability ( see figure [ plot_xyzopac ] ) .",
    "+        the sobolev approximation is not able to capture this angular dependence and consequently underpredicts the angle  averaged photon escape probability .",
    "comparing the escape probabilities in different directions for one and the same particle quantitatively yields high angle  dependent variations . shortly before formation of the first sink particle , the photon escape probabilities in the inner @xmath191au vary by factors of up to@xmath192 in different healpix pixels . during the further collapse ,",
    "this value decreases but is still between @xmath193 on average in the centre of the cloud .",
    "this clearly demonstrates the failure of the local approximation in modelling inhomogeneous , non  spherical density distributions .",
    "@xcite also mention the problem of direction  dependent escape probabilities during their comparison of different cooling implementations in simulations of primordial star formation .",
    "moreover , the sobolev approximation is highly sensitive to small - scale details of the velocity field , and hence improving the resolution and accuracy with which one models the sub - sonic turbulence in the gas actually makes the method worse , because locally you start to see more of the turbulent velocity gradients , but these persist only over short length scales , not globally @xcite .    although the treecol  based method is computationally expensive , it is able to capture the non  uniformity of the h@xmath0 distribution in a way that local approximations can not manage",
    ". it is also significantly cheaper than the more robust method employed by @xcite , although a comparison between the accuracy of the method proposed here and that by @xcite still needs to be done .",
    "regarding the local methods , there is no general recommendation .",
    "most of these methods assume spherical symmetry and hence their validity breaks down when a disc forms around the first protostar .",
    "since the accretion process through the disc lasts for several thousand years or more , one should use an approach which yields a suitable long  time accuracy .",
    "the reciprocal method is the only approach that considers both gradients in density and the doppler  shifting of spectral lines .",
    "therefore , this method is the most accurate approach for the determination of the effective column density even after subsequent sink particle formation . the difference between whether one uses the corrected or uncorrected sobolev length for the determination of the reciprocal sum is small , but the corrected sobolev length provides a more accurate method for the long  time evolution of the disc .",
    "analytic fits might be useful during the initial collapse of the primordial cloud , but also fail when the disc  like structure starts to form .",
    "nevertheless , at any stage of the collapse , the escape probability as a function of mass can generally be fitted very accurately by an analytic formula , which could also be done on the fly during the simulation .",
    "consequently , a hybrid version between the proper treecol  based determination of escape probabilities every several time steps and an analytic fit to these data for the steps in between should yield reliable results with less computational effort .",
    "this new method for the determination of effective column densities can also be applied in other astrophysical scenarios .",
    "for example the photodissociation of h@xmath0 in protogalaxies is a crucial process for the formation of supermassive black hole seeds @xcite . to model these processes properly ,",
    "the effective column densities are needed to account for the effect of h@xmath0 self - shielding against lyman werner photons @xcite .",
    "it can generally be applied in most scenarios of line transfer , where the radially infalling velocities of gas are higher than the turbulent gas velocities .",
    "fragmentation is a highly chaotic process and slight changes in the initial conditions or in the implementation of the governing physics can completely change the outcome . therefore , looking just at the number of sink particles is not a valid quantification , especially since we do not capture the entire duration of the accretion and fragmentation process .",
    "nevertheless , it is instructive to determine and compare different fragmentation criteria for the individual cooling approaches .",
    "we find that the treecol method seems to promote fragmentation .",
    "in other words , commonly used cooling approximations generally underestimate the number of pop iii stars .",
    "moreover , the disc has just formed , when we end our simulations .",
    "therefore , the differences between the individual cooling approaches and their effect on fragmentation might even be more pronounced for later stages of the collapse .",
    "since the overall mass accretion rates are roughly equal , regardless of the cooling implementation , we expect the pop iii stars in our treecol  based runs generally to have smaller masses than previous sobolev  based studies have yielded .",
    "there are several open questions , shortcomings and approximations , which one should keep in mind , when interpreting the previously presented results .",
    "since we follow the fragmentation of the cloud only for the first few hundred years after formation of the first protostar , we have no information about the physical conditions during the late stages of disc accretion .",
    "it is , however , likely that the disc  like structure will proceed to grow and most of our statements remain valid .",
    "+ furthermore , we do not account for mergers , which influence the final number of pop iii stars @xcite , nor do we include the effects of ionizing radiation .",
    "we determine radiative feedback under the assumption of a constant mass accretion rate and although the value of @xmath194 seems to be justified by similar accretion rates in the simulations , a proper treatment is necessary .",
    "besides , we should also keep in mind that the escape probability , as the theoretical basis for our cooling implementation , is an approximation by itself , e.g. we use one average escape probability for all photons , instead of determining the individual escape probabilities for each line separately . in this context",
    ", @xcite find that a multi  line , multi  frequency raytracing scheme does not alter these results significantly .",
    "magnetic fields might influence the collapse and act as a stabilising force .",
    "we have not included these effects in our simulation , but for a detailed discussion of the effects of magnetic fields in primordial star formation , see @xcite and references therein .",
    "we compared different implementations for the approximate treatment of optically  thick h@xmath0 line cooling and analysed the fragmentation behaviour of primordial gas under these different methods . since h@xmath0 is the dominant coolant in primordial gas clouds , line cooling by molecular hydrogen is a crucial process to consider for the formation of pop iii stars . while the cooling rates in the optically thin regime can be calculated accurately , optically thick cooling is only poorly understood , although it has a strong influence on the temperature profile and fragmentation of the cloud .",
    "the commonly used sobolev approximation has to be corrected for the effect of line overlap .",
    "however , since the sobolev and other approximations for the effective column density assume isotropy and certain quantities to be constant on the relevant scales , they all fail if the system deviates strongly from spherical symmetry or if it has strong density gradients .",
    "while the cloud flattens and develops a disc during the collapse , the local approaches generally yield too small values for the photon escape probability ( mean relative errors of @xmath195 ) .",
    "existing analytical fitting formulae yield acceptable results up to the formation of the first protostar .",
    "thereafter , the detailed functional form needs to be modified , because an analytical fitting formula derived at one time in the evolution will generally fail at other times , as the system is strongly out of dynamical equilibrium and therefore rapidly evolving . only the treecol  based methods are adaptively adjusting to the kinematic and morphological changes of the system . capturing these dynamical features ,",
    "the treecol  based methods yield lower temperatures in the centre of the cloud .",
    "+ we find primordial gas is most susceptible to fragmentation in the density regime from @xmath196 to @xmath197 .",
    "whereas local methods lead to the formation of fewer and higher - mass pop iii stars , the treecol  based approach promotes a higher degree of fragmentation and therefore tend to result in the formation of more and lower  mass stars .",
    "regardless of the cooling implementation , the protostars have very high mass accretion rates and the mass function will be dominated by high  mass stars .",
    "however , only high  resolution simulations with a proper treatment of h@xmath0 cooling , magnetic fields , and feedback that run long enough to capture the entire accretion and fragmentation process can give a complete picture of pop iii star formation and the corresponding primordial imf .",
    "the authors acknowledge financial support from the deutsche forschungsgemeinschaft ( dfg ) via sfb 881 `` the milky way system '' ( sub - projects b1 , b2 , and b8 ) , and from the baden - wrttemberg - stiftung by contract research via the programme internationale spitzenforschung ii ( grant p - ls - spii/18 ) .",
    "the simulations described in this paper were performed on the _ kolob _ cluster at the university of heidelberg , which is funded in part by the dfg via emmy - noether grant ba 3706 , and via a frontier grant of heidelberg university , sponsored by the german excellence initiative as well as the baden - wrttemberg foundation .",
    "th appreciates fruitful discussions with clio bertelli motta and volker bromm . th and rsk",
    "are supported from the european research council under the european communitys seventh framework programme ( fp7/2007 - 2013 ) via the erc advanced grant `` starlight : formation of the first stars '' ( project number 339177 ) .",
    "ms and th acknowledges computing time from judge super computing centre .",
    "pcc is supported by grant cl 463/2 - 1 , part of the dfg priority program 1573 `` physics of the interstellar medium '' .",
    "ms , as part of imprs - hd , thanks financial support from heidelberg graduate school of fundamental physics ( hgsfp ) and wishes to thank thomas greif for help with performing numerical simulations ."
  ],
  "abstract_text": [
    "<S> we present a new method for estimating the h@xmath0 cooling rate in the optically thick regime in simulations of primordial star formation . </S>",
    "<S> our new approach is based on the treecol algorithm , which projects matter distributions onto a spherical grid to create maps of column densities for each fluid element in the computational domain . </S>",
    "<S> we have improved this algorithm by using the relative gas velocities , to weight the individual matter contributions with the relative spectral line overlaps , in order to properly account for the doppler effect . </S>",
    "<S> we compare our new method to the widely used sobolev approximation , which yields an estimate for the column density based on the local velocity gradient and the thermal velocity . </S>",
    "<S> this approach generally underestimates the photon escape probability , because it neglects the density gradient and the actual shape of the cloud . </S>",
    "<S> we present a correction factor for the true line overlap in the sobolev approximation and a new method based on local quantities , which fits the exact results reasonably well during the collapse of the cloud , with the error in the cooling rates always being less than @xmath1 . </S>",
    "<S> analytical fitting formulae fail at determining the photon escape probability after formation of the first protostar ( error of @xmath2 ) because they are based on the assumption of spherical symmetry and therefore break down once a protostellar accretion disc has formed . </S>",
    "<S> our method yields lower temperatures and hence promotes fragmentation for densities above @xmath3 at a distance of @xmath4au from the first protostar . </S>",
    "<S> since the overall accretion rates are hardly affected by the cooling implementation , we expect pop iii stars to have lower masses in our simulations , compared to the results of previous simulations that used the sobolev approximation . </S>"
  ]
}