{
  "article_text": [
    "the visual cortex of humans features a columnar organization .",
    "each column contains cells whose receptive fields monitor almost identical retinal positions and orientations . such nearby _ orientation columns _",
    "encode different orientations .",
    "a set of orientation columns encoding all possible orientations is a hypercolumn of orientation .",
    "the visual input to a hypercolumn is from the retina through the thalamus .",
    "the hypercolumn is a relay that sharpens the output of the thalamus to make the local retinal visual orientation more `` conspicuous '' .",
    "this happens because the neurons of the hypercolumn inhibit and excite each other according to simple rules .",
    "these rules are used to build a mathematical model of a hypercolumn whose predictions can be compared with experimental evidence .",
    "we study the properties of such a model whose rich symmetries can be traced to the fact that two orientations differing by the value @xmath0 are the same visually .",
    "important consequences of our analysis are the clarification of the model parameters role in shaping the `` perception '' of the hypercolumn and the prediction of a neuronal illusion , the fact that a hypercolumn can be in the same state as if the retinal stimulus were at an orientation rotated by 90 degrees with respect to the actual one .",
    "since the discovery by hubel and wiesel @xcite of the selective response of a single neuron to some orientations , a long standing debate has been the degree of cortical computation involved in this selectivity compared to the feedforward selectivity implied by the lgn projections .",
    "cortical models @xcite have been used to show how this selectivity can be produced in a cortex with center - surround interactions in the orientation domain .    the ring model of orientation tuning",
    "was introduced by hansel and sompolinski @xcite and studied by several other scientists @xcite , after the seminal work of ben - yishai and colleagues @xcite , as a model of a hypercolumn in primary visual cortex .",
    "this rate model is a simplification of complex spiking networks @xcite designed to make it easier to understand the role of different mesoscopic parameters .",
    "it assumes that the local orientation @xmath1 in the receptor fields of the neurons in the column is encoded in their activity , or firing rate , noted @xmath2 .",
    "the interaction between the neurons is modeled by a function @xmath3 of the orientation that represents how the activities corresponding to two different orientations reinforce or inhibit each other .",
    "this function is called the connectivity function of the model . with this in mind , the dynamics of the firing rate can be represented by the following integro - differential equation in the line of the model of wilson - cowan @xcite : @xmath4 \\quad t>0\\\\ a(x,0)&=&a_0(x ) \\end{array } \\right.\\ ] ] @xmath5 defines the intrinsic dynamics of the population and @xmath6 is the input from the lateral geniculate nucleus ( lgn ) to the hypercolumn whose contrast is defined by the parameter @xmath7 , see figure [ fig : visual path ] .",
    "@xmath8 is the sigmoid @xmath9 which takes values between 0 and 1 , @xmath10 is a parameter that determines the nonlinear gain of the sigmoid , @xmath11 is a threshold that controls for which value the sigmoid takes the value @xmath12 , the function @xmath6 represents the input from the lgn .    .",
    "this grating excites mostly the lgn cells that share this receptive field and are aligned in the direction @xmath13 ; the tuning is broad , see the curve in the middle part of the figure .",
    "these lgn cells project onto the network of cells in the hypercolumn of orientation of v1 whose interactions , represented by the ring model , result in a sharpening of the tuning around the grating direction , see the curve in the righthand side of the figure.,scaledwidth=75.0% ]    regarding the connectivity function , in all cases it is an even @xmath0-periodic function , positive for orientation values close to 0 ( corresponding to an excitation ) and negative for orientation values larger in magnitude ( corresponding to an inhibition ) .",
    "the rich symmetries of @xmath3 play a prominent role in our upcoming analysis of the ring model .",
    "the reason for this is that , when the contrast @xmath7 is equal to 0 , equation , is equivariant , i.e. it has some nice properties with respect to the action of a certain group that we proceed to describe .",
    "let us consider the group , noted @xmath14 , of translations of @xmath15 .",
    "an element @xmath16 , @xmath17 of this group acts on the orientation @xmath1 by @xmath18 and on the activity function @xmath2 by @xmath19 .",
    "similarly , we consider the reflection , noted @xmath20 , such that @xmath21 and therefore @xmath22 .",
    "we note @xmath23 the group generated by @xmath14 and @xmath20 .",
    "we can abstractly rewrite equation as @xmath24 , where @xmath25 $ ] . using the symmetry properties of the function",
    "@xmath3 it is easy to verify that @xmath26 satisfies the condition @xmath27 for all elements @xmath28 in the group @xmath23 when @xmath29 .",
    "since moreover we clearly have @xmath30 the group g is in effect isomorphic to @xmath31 , the group of two - dimensional othogonal transformations ( * ? ? ?",
    "* chapter 1 ) .",
    "several variants of this model have been studied in the literature , e.g. , in @xcite @xmath3 is a difference of gaussians while in @xcite the authors start with a network of excitatory / inhibitory spiking neurons and derive a meanfield approximation of this network yielding an interaction function @xmath3 described by the following equation : @xmath32    the input @xmath6 from the lgn has a similar shape @xmath33 as mentioned above , and as shown in figure [ fig : visual path ] , it is weakly tuned , i.e. , maximal , at @xmath34 and it is the network , modeled by , that sharpens this tuning .",
    "these authors vary the anisotropy parameter @xmath35 between 0 and 1 .",
    "the sigmoid @xmath8 is often chosen to be a heaviside function , or , as in @xcite , a piecewise linear approximation of the sigmoid .",
    "in @xcite it is a true sigmoidal function .",
    "the parameter @xmath36 is positive , an important property of the network that is necessary to produce the tuning curves .. @xmath37 is most of the time negative @xcite but can be positive as well @xcite .",
    "note that the @xmath38s , @xmath39 are the first fourier coefficients of the function @xmath3 .",
    "@xmath37 is its mean value and can be positive even if the surround is inhibitory .",
    "for example , in @xcite , we find @xmath40 which are the values in @xcite except for @xmath41 and @xmath42 . the slope , or nonlinear gain , @xmath10 is assumed to be equal to 1 .",
    "using the previous rescaling , it becomes @xmath43 and @xmath44 in the case of @xcite and @xmath45 in the case of @xcite .",
    "the model is called an activity model in the terminology of @xcite . for technical reasons",
    "we turn it into a voltage model as follows .",
    "we first rewrite equation in a more compact and convenient , functional , form : @xmath46 .\\ ] ] @xmath3 is now thought of as a linear ( integral ) operator acting on the function @xmath47 as the periodic convolution @xmath48 , see , e.g. , @xcite .",
    "we then perform the change of variable @xmath49 . assuming that the input current is not a function of time , this leads to the following equation @xmath50 note that this equation , as , is @xmath23-equivariant .",
    "the stationary solutions ( some of them called tuning curves , see the paragraph _ discussion _ ) of ( respectively of ) satisfy @xmath51 ( respectively @xmath52 )",
    ". characterizing and computing them for different values of the parameters is the first step toward understanding the dynamics of the solutions to these equations .",
    "indeed , it is known that this type of equations is such that there are only heteroclinic ( linking two stationary solutions , or equilibria ) or unbounded orbits .",
    "since we showed in @xcite that all trajectories were bounded , this implies that they are made of heteroclinic orbits .",
    "this motivates further the study of the stationary solutions of .",
    "one of our goals is to show how the stationary solutions are organized and to give indications about the dynamics in a given range of parameters , corresponding to biologically plausible values .",
    "this is relevant because many large scale models of v1 including many hypercolumns represent them with the ring model .",
    "therefore a good understanding of one hypercolumn paves the way to an understanding of a population thereof .",
    "we show that , depending on the nonlinear gain @xmath10 , there may exist many stationary solutions , which are all acceptable responses of the network to a given input from the lgn ( at least for the model at hand ) .",
    "thus this local orientation tuning device may behave less trivially than what it was initially designed for . in effect",
    ", the existence of these stationary solutions , sometimes called persistent cortical states , can make the local dynamics quite intricate when @xmath10 is large enough to support the existence of these extra solutions .",
    "it is worth noticing that the stationary solutions of and are in one to one correspondence . as a consequence we will work on because it is mathematically more convenient .",
    "we will follow a method similar to the one developed in @xcite to compute the stationary states of .",
    "the method has been modified to take into account the symmetries of the ring model .",
    "the general idea is that the lgn input is weak and only modulates the network activity .",
    "hence the cortical network ( represented by the ring model ) encodes the possible tuning curves within its connectivity function and when presented with a weak external input , produces small deviations of its tuning curves . our goal is to compute these tuning curves .",
    "however , because of the symmetries of the connectivity function @xmath3 , the model in effect encodes an infinite number of tuning curves , and this is an endless cause of numerical problems .",
    "indeed we pointed out above that if the input current was null , equation ( respectively ) was @xmath23-equivariant .",
    "this implies that if @xmath53 is a stationary solution of , so are @xmath54 , @xmath17 and @xmath55 .",
    "we show that by performing an appropriate change of variables , we can get rid of this redundancy and recover numerical accuracy .",
    "problem ( respectively ) is infinite dimensional since the solutions live in some ( unspecified , but a priori infinite dimensional ) functional space . by truncating the fourier series of the even @xmath0-periodic connectivity function @xmath3 we reduce the problem to a finite number of dimensions . we write @xmath56 where @xmath57 is the number of fourier modes that are sufficient to represent @xmath3 .",
    "we will show how the choice of @xmath57 affects the biological functional properties of the ring model .",
    "notice that by varying @xmath57 , we generate a family of models that contains all previously published ones .    for convenience",
    ", we shall write @xmath58 for the function @xmath59 . the same holds for @xmath60 .",
    "it was shown in @xcite that this form of the connectivity function implies that the solutions to can be written @xmath61 , where @xmath62 is a linear combination of the functions @xmath63 and @xmath64 , @xmath65 and the function @xmath66 tends to 0 exponentially fast when @xmath67 .",
    "this implies that the stationary solutions satisfy @xmath68 .",
    "the spectrum of the integral operator @xmath3 associated with the eponymic connectivity function is readily seen to be equal to @xmath69 .",
    "we can , up to a rescaling of @xmath10 in , assume that @xmath37 takes the values @xmath70 : @xmath71 similarly we define @xmath72 by @xmath73 with all this in hands , the tuning curves satisfy the equation : @xmath74 s\\left [ \\lambda v(y , t))\\right]dy/\\pi+\\varepsilon i(x)-\\theta\\ ] ] it follows that any stationary solution to can be written @xmath75,\\ ] ] where @xmath76 , @xmath77 are @xmath78 reals .",
    "solving is therefore equivalent to finding these reals . in the case of a general solution , @xmath79",
    "is given by the same formula where the coefficients are now real functions of time .",
    "under the assumption that @xmath66 is neglected , it is easy to obtain the system of ordinary differential equations that are satisfied by the functions @xmath76 .",
    "using the complex values @xmath80 , @xmath81 we obtain the following equations    @xmath82 dy -\\theta + \\varepsilon i_0\\\\ & & \\quad \\overset{\\rm def}{= } b_0(v_0,\\left\\lbrace z_p\\right\\rbrace ) -\\theta+\\varepsilon i_0 \\\\",
    "z_k+z_k&= & \\varepsilon_k\\frac{\\sqrt{|j_k|}}{\\pi}\\int\\limits_{-\\frac{\\pi}{2}}^\\frac{\\pi}{2}s\\left [ \\lambda v_0+\\lambda{\\sum\\limits}_{p=1}^n\\sqrt{|j_p|}\\re\\left (   z_pe^{-2piy }   \\right ) \\right ] e^{2kiy}dy+\\varepsilon i_k\\\\ & & \\quad \\overset{\\rm def}{= } b_k(v_0,\\left\\lbrace z_p\\right\\rbrace ) + \\varepsilon i_k \\quad k=1,\\cdots , n \\end{array}\\right.\\ ] ]    where @xmath83 and @xmath84 .",
    "the coefficients defining the tuning curves satisfy the following equations : @xmath85 the @xmath86 dimensional vector @xmath87 is a representation of @xmath62 .",
    "the group @xmath23 also acts on this representation as follows @xmath88 as shown in the introduction , the use of the group @xmath31 is motivated by the fact that when @xmath29 , then are @xmath31-equivariant as @xmath89 , this means that @xmath90 , @xmath91 . since if @xmath92 is a stationary solution of for @xmath29 , so is @xmath93 there is an infinity of tuning curves that are encoded by the network .",
    "however , when @xmath94 , all the symmetries are broken , are not @xmath31-equivariant anymore and the number of tuning curves becomes finite .    in the next two sections we study the cases @xmath95 and @xmath96 .",
    "the second case shows that adding more modes does not change the main results of the analysis .",
    "we consider the following connectivity function @xmath97 from our previous analysis of the symmetries of the ring model , we know that the equations are redundant when @xmath29 . in order to eliminate this redundancy",
    "they should be rewritten using their equivariant structure with respect to the action of the group @xmath31 . in this case , this turns out to be equivalent to writing an equation for @xmath98 and the magnitude @xmath99 of @xmath100 .",
    "it is convenient to write @xmath101 , which yields to the following equations , assuming @xmath102 : @xmath103 for the dynamics , and @xmath104 for the tuning curves .",
    "the functions @xmath105 and @xmath106 are given by ( using an integration by parts to factor out @xmath99 in @xmath107 ) @xmath108 equations do not produce the same dynamics as because the change from cartesian to polar cordinates is not a diffeomorphism .",
    "nevertheless equations are most useful for computing the tuning curves .",
    "we now write : @xmath109 in order to agree with known experimental facts , the tuning curves should be mainly unimodal .",
    "compared to the previous case , the fact that the second mode is nonzero could induce an `` interaction '' between the two modes leading to multimodal tuning curves .    following the analysis of section [ section : finite ] we have to solve five coupled equations which are redundant because of the action of the group @xmath23 which in this case reads @xmath110 in order to eliminate the redundancy arising from this symmetry we used polar coordinates as in the case @xmath95 .",
    "it is tempting to do the same with the two complex variables @xmath100 and @xmath111 but it turns out to be a dead end .",
    "+ the main reason is numerical : we compute ( see _ supporting information _ , second paragraph )",
    "the solutions of the nonlinear equations using numerical continuation .",
    "this scheme works well if the jacobian of the nonlinear equation has at worst a one - dimensional kernel at some isolated points .",
    "if we write @xmath112 , then , using the invariance by @xmath16 , the equations for @xmath113 , @xmath114 simplify to @xmath115 which are functions of the phase difference @xmath116 .",
    "it turns out that the other equations ( for @xmath117 ) also involve only @xmath116 .",
    "we were unable to find a simple relation between @xmath118 and @xmath119 .",
    "as a consequnce we end up with 5 equations in the 4 unknows @xmath120 : this is unappropriate for numerical continuation and we need to find a way to obtain 4 equations in 4 unknowns .    to reach this goal we turn to a general technique ,",
    "the orbit space reduction @xcite , which provides the right change of coordinates through the use of what is called a hilbert basis of @xmath31-invariant polynomials is finitely generated as an @xmath121-algebra , this goes back to hilbert .",
    "a family @xmath122 of generators of @xmath123 is called a hilbert basis . ] .",
    "a fundamental property is that any smooth equivariant function can be expressed using the elements of a hilbert basis and their gradients .",
    "a hilbert basis associated to the action of the group @xmath31 ( @xcite ) is given by the @xmath31-invariant polynomials : @xmath124 which must satisfy the constraints @xmath125 our analysis is now focused on the so - called orbit space , i.e. the subset of @xmath126 of the four - tuples @xmath127 , @xmath128 , that satisfy the previous inequalities .",
    "as the fonction @xmath129 is @xmath31-invariant ( i.e. @xmath130 for all @xmath28 in @xmath23 ) , it is a function , noted @xmath131 , of the variables @xmath127 , i.e. @xmath132 .",
    "furthermore since the pair @xmath133 is @xmath31-equivariant ( i.e. @xmath134 for all @xmath28 in @xmath23 ) , it can be written : @xmath135 where @xmath136 are @xmath31-invariant functions .",
    "notice that this implies that @xmath137 .    using the definition of the polynomials @xmath138 , it is possible to rewrite ( [ eq : discrete ] ) only in terms of @xmath127 ( as we did in the previous section with the polar coordinates ) : @xmath139 \\pi_3 + 2c(v_0,\\vec\\pi)\\pi_1\\pi_2+d(v_0,\\vec\\pi)\\pi_1 ^ 2         \\end{array}\\right.\\ ] ] these equations are solved to find the tuning curves .",
    "we used the equations of the previous paragraph to find the tuning curves in the cases @xmath95 and @xmath96 .",
    "some of these tuning curves corresponded to a neuronal illusion .",
    "we then showed that adding more modes to the connectivity function did not change the results .",
    "finally we designed two different types of external stimuli for bringing the network to the illusory states .",
    "the ring model is based on one main ingredient : at null contrast and for small values of the nonlinear gain @xmath10 , there is a unique stationary solution , which is not tuned ! indeed , this stationary solution has to satisfy @xmath140 otherwise it would not be unique because of the group @xmath31 equivariance .",
    "thus , in order to produce tuning curves ( that are tuned by definition ) , we need a solution to satisfying @xmath141 .",
    "this means that we must investigate for which values of @xmath10 , if any , the @xmath99 solution of bifurcates . for no external input",
    "they read : @xmath142 a bifurcated solution arises when @xmath143 it follows that the equations for the existence of a tuned stationary solution , satisfying @xmath141 are : @xmath144 using the relation @xmath145 it is straightforward to show that @xmath10 and @xmath36 must satisfy the condition @xmath146 . in ( see _ supporting information _ ,",
    "third section ) , we find other equivalent conditions that are used to produce the graphs shown in figure [ fig : condtc ] .",
    "these graphs show that the threshold @xmath11 and the ratio excitation / inhibition are constrained in order to produce the tuning curves .",
    "plane for the existence of the tuning curves for @xmath147 ( green , it is very close to @xmath148 ) , and @xmath149 ( red ) .",
    "the domain of existence lies above these boundaries.,width=302,height=264 ]    when these conditions are satisfied we obtain a continuum of tuning curves parametrized by the phase angle @xmath150 , noted @xmath151 , which are given by @xmath152\\ ] ]    note that these tuning curves are dynamically stable because they are produced by a pitchfork bifurcation , as can be seen by examing equation .",
    "the bifurcated branch of interest is the one corresponding to @xmath153 .",
    "the next step is to investigate what happens when we switch on the lgn drive , _",
    "i.e. _ when @xmath154 .",
    "first , when the anisotropy @xmath35 of the lgn input is not zero , the equations are not @xmath31-equivariant anymore .",
    "this is a symmetry breaking and , as mentioned above , there are a finite number of tuning curves .",
    "two important questions are 1 ) how many of the ( continuum of ) tuning curves remain solutions and 2 ) what is their stability ?",
    "for very small @xmath154 , switching on the lgn can be viewed as a perturbation of the nonlinear equations when @xmath29 , as a consequence , we expect an opening of the pitchfork as we explained in @xcite .",
    "this is confirmed by figure [ fig : rho+- ] .",
    "we know from our previous analysis that these solutions satisfy :    @xmath155 considering the two cases @xmath156 even and @xmath156 odd we obtain : @xmath157 because @xmath158 is even and @xmath159 is odd , necessarily @xmath160 .",
    "we solve these equations for @xmath161 as functions of @xmath10 by using a continuation algorithm described in @xcite , the results are shown in figure [ fig : rho+- ] .     shown in red , green , blue , respectively , as functions of @xmath10 for @xmath162 .",
    "notice the turning points labelled with black dots.,scaledwidth=50.0% ]    from this bifurcation diagram , we observe that there are three stationary solutions for @xmath163 , one unstable corresponding to a small value of @xmath99 ( thus it is untuned and , by definition , does not represent a tuning curve ) and two others which are tuning curves .",
    "one , noted @xmath164 , is peaked at @xmath165 and the other , noted @xmath166 , is peaked at @xmath167 .",
    "note that the values @xmath163 are in agreement with the previously derived necessary condition @xmath168 .",
    "the two tuning curves are shown in figure [ fig : tc ] .     and",
    "@xmath166 for @xmath169 and @xmath170.,scaledwidth=50.0% ]    the interesting fact to notice is that the tuning curve @xmath166 is a somewhat bizarre stable state of the ring model .",
    "we may want to call it a neuronal illusion , the 90 degrees illusion , since it corresponds to the fact that , even if the thalamic input is peaked at the zero degree orientation , the ring model may be ( and stay ) in a stable state corresponding to a tuning curve peaking at 90 degrees ! in other words , even if the thalamic input `` says '' 0 degrees , the hypercolumn of orientation `` says '' 90 degrees .",
    "the previous results may seem to depend very much on the type of simple connectivity function that we have assumed .",
    "in fact this is not so . by adding one more mode to this function",
    "we show that they are generic if the resulting function preserves the structure of the local excitation and the lateral inhibition .    the tuning curves are now solution of the nonlinear equations : @xmath171 \\pi_3 + 2c(v_0,\\vec\\pi)\\pi_1\\pi_2+d(v_0,\\vec\\pi)\\pi_1 ^ 2         \\end{array}\\right.\\ ] ] we first look at the case where the sigmoid function @xmath8 is zero at the origin , i.e. @xmath172 .",
    "we see on the graph of solutions on the orbit space shown in figure [ fig : osmu0 ] that there are two bifurcations from the trivial solution @xmath173 , at the points , noted @xmath174 and @xmath175 in this figure , corresponding to the values @xmath176 of the nonlinear gain . considering again figure [ fig : osmu0 ] it motivates the following remarks :    1 .",
    "the first bifurcated branch from @xmath174 reaches high values well before @xmath175 .",
    "2 .   our orbit space reduction procedure allows us to compute numerically such secondary bifurcation points as @xmath177 which might produce linearly stable tuning curves .",
    "these are undesirable from a biological viewpoint because they produce stable multimodal tuning curves .",
    "the linear stability analysis shows that the branch bifurcating from @xmath174 is stable and corresponds to a continuum of tuning curves parametrized by the phase qngle @xmath150 and given by : @xmath178\\ ] ] the unstable tuning curves bifurcating from @xmath175 ( before @xmath177 ) are given by : @xmath179\\ ] ] this shows that in order to have unimodal tuning curves ( responses of the hypercolumn represented by the ring model ) , it is necessary that @xmath180 or equivalently @xmath181 because the nonlinear gains which produce the pitchforks are @xmath182 , @xmath114 .",
    "moreover , since @xmath183 quickly reaches high values , @xmath184 is close to @xmath185 : the response does not depend upon the contrast @xmath7 of the lgn .",
    "_ this implies that the working range of the nonlinear gain @xmath10 is close to the value @xmath186 .",
    "_    it is now possible to understand the diagram of solutions shown in figure [ fig : osmu1 ] obtained with the regular sigmoid @xmath8 as a deformation of the diagram shown in figure [ fig : osmu0 ] . as in the case",
    "@xmath95 , the bifurcated branches will persist if the coefficients @xmath38 , @xmath114 , and the threshold @xmath11 , satisfy the constraints shown in figure [ fig : condtc ] . indeed , if we reproduce the analysis in the paragraph _ materials and methods _ , the existence of a pitchfork for the @xmath187 , @xmath114 coordinate is given by @xmath188    we again notice that the first branch bifurcating from @xmath174 ( in green in figure [ fig : osmu1 ] ) is quickly reaching high values and that the tuning curve is now asymmetric ( this is much easier to see in the middle part of figure [ fig : tcmu1 ] ) .",
    "this is because the @xmath189 components ( in blue and magenta in figure [ fig : osmu1 ] ) are not zero as in the case @xmath95 .",
    "the tuning curve corresponding to the first bifurcated branch is given @xmath190\\ ] ] where @xmath191 , and @xmath192 .",
    "remember that there is an infinity of tuning curves that are obtained from the one given by equation by applying an element of the group g.    we have plotted in figure [ fig : tcmu1 ] examples of the tuning curves for three values of the nonlinear gain @xmath10 that are slightly larger than the values corresponding to the three bifurcation points @xmath174 , @xmath175 and @xmath177 in figure [ fig : osmu1 ] .",
    "these tuning curves are obtained by reading from figure [ fig : osmu1 ] the 4-tuple @xmath193 .",
    "this yields , through the relation @xmath192 , the value of @xmath194 that is needed in equation .",
    "notice the unstable multimodal tuning curves that appear once the stable tuning curve has saturated ( middle plot in figure [ fig : tcmu1 ] ) .",
    "this is an indication that the nonlinear gain should not be too high otherwise most responses of the network will be saturated .",
    "( left ) ,  @xmath195 ( middle ) , and @xmath196 ( right ) when the input is equal to 0 , see text . on the left and in the middle , stable tuning curves are shown in continuous line , unstable ones in dotted lines .",
    "stability is not shown in the plot on the right , except for the null solution .",
    "the other parameters are the same as in figure [ fig : osmu1].,title=\"fig:\",scaledwidth=30.0% ]   ( left ) ,  @xmath195 ( middle ) , and @xmath196 ( right ) when the input is equal to 0 , see text . on the left and in the middle , stable tuning curves are shown in continuous line , unstable ones in dotted lines .",
    "stability is not shown in the plot on the right , except for the null solution .",
    "the other parameters are the same as in figure [ fig : osmu1].,title=\"fig:\",scaledwidth=30.0% ]   ( left ) ,  @xmath195 ( middle ) , and @xmath196 ( right ) when the input is equal to 0 , see text . on the left and in the middle , stable tuning curves are shown in continuous line , unstable ones in dotted lines .",
    "stability is not shown in the plot on the right , except for the null solution .",
    "the other parameters are the same as in figure [ fig : osmu1].,title=\"fig:\",scaledwidth=30.0% ]    if we switch on the lgn , the contrast @xmath7 is nonzero .",
    "the external current is given by @xmath197 .",
    "if @xmath198 , the symmetries of the equation are broken and we expect a finite number of solutions .",
    "more precisely , the same argument as for @xmath95 shows that we can interpret as a perturbation of when @xmath7 is small , leading to an opening of the pitchforks .",
    "hence , when the nonlinear gain @xmath10 is close to that of @xmath174 we have @xmath199 for @xmath7 small .",
    "since the equations @xmath200 are the same as in the case @xmath95 when @xmath201 , they do not change much when @xmath202 and the 90 degrees illusion found in the previous section remains : there are two tuning curves , one peaking as the external input @xmath6 and one translated by 90 degrees .",
    "this analysis is confirmed by the results of the numerical computations shown in figure [ fig : tcn2 ] where we show the solutions of for @xmath96 , @xmath203 .     and",
    "@xmath166 for @xmath204 , @xmath205 and @xmath203 .",
    "@xmath6 is plotted in red .",
    "notice the unstable weakly tuned tuning curve shown in black.,scaledwidth=30.0% ]      we can perform the same computations using more modes , this will only bring in more tuning curves . because these tuning curves only appear once the stable unimodal tuning curve has saturated these high values for the nonlinear gain @xmath10 are biologically irrelevant or nonplausible .",
    "notice also that the neuronal illusions found in the case @xmath206 are still present for @xmath207 , as shown for example in figures [ fig : tcmu1 ] and [ fig : tcn2 ] .",
    "indeed , as seen in the previous section , they only depend upon the fact that the network features a pitchfork bifurcation at the point noted @xmath174 in figures [ fig : osmu0 ] and [ fig : osmu1 ] and this is always the case for any value of the number @xmath57 of modes if the coefficients @xmath38 satisfy the mild constraints we have described previously and we summarize in the next section .      in the last paragraphs , we found two cortical representations of the same external stimulus .",
    "an immediate question is how can we bring a hypercolumn of orientation into each of these two states ?",
    "can we drive the cortical state to the illusion using only the stimulus @xmath6 ?",
    "we answer this question positively in the next two paragraphs .      as",
    "the illusory tuning curve @xmath166 is very close to the cortical state corresponding to the response of the network to a stimulus peaked at @xmath208 , we first present a stimulus peaked at @xmath209 to put the system in the @xmath164 state corresponding to no illusion .",
    "we then slowly change the position of the peak of the external stimulus @xmath6 and bring it to the value @xmath208 .",
    "the network follows the stimulus and its response is peaked at @xmath208 .",
    "we then suddenly change the stimulus to a stimulus peaked at @xmath209 and since the responses of the network to stimulus oriented at @xmath209 or @xmath208 are very close , the cortical state will remain in the state peaked at @xmath208 , the one it is in just before the sudden change of the stimulus .",
    "this is reminiscent of the after - effect illusion and can be confirmed by numerical simulation .",
    "the resulting effect is shown in figure [ fig : illusion1 ] when the time variation of the peak @xmath13 of the stimulus in equation is given by @xmath210\\\\    \\frac{\\pi}{2}&\\text { if } t\\in[2000 , 2e4]\\\\    0&\\text { if } t>2e4",
    "\\end{array}\\right.\\ ] ]     ( shown in blue ) of the peak of the stimulus @xmath6 and the phase coordinate @xmath150 ( shown in black ) of the network , both as functions of time , on a logarithmic scale .",
    "note that the stimulus drives the network into a state that is very close to its expected state when presented with a stimulus oriented at 90 degrees and that it stays there even after the input is switched back to a 0 orientation stimulus .",
    "the parameters are the same as in figures [ fig : rho+- ] and [ fig : tc].,scaledwidth=60.0% ]      this second dynamical 90 degrees illusion is very close in principle to the one presented in the previous paragraph . instead of rotating the stimulus , we change its contrast as follows .",
    "let us note @xmath211 the stimulus peaked at @xmath209 and @xmath212 the one peaked at @xmath213 , the thalamic input to the hypercolumn of orientation takes the form @xmath214 where @xmath215 is the function shown in figure [ fig : contrast ] .     allowing to vary the contrast of the thalamic input , see text.,scaledwidth=50.0% ]    we check numerically , using the dynamics given by equations , that the hypercolumn stays in the cortical state @xmath164 ( see figure [ fig : ill2 ] ) , despite the fact that the final stimulus corresponds to an orientation of 90 degrees .",
    "to become a mixture of @xmath211 and @xmath212 and finishes as a pure @xmath212 .",
    "right : the response of the network shows that it stays in the cortical state @xmath164.,title=\"fig:\",height=188 ]   to become a mixture of @xmath211 and @xmath212 and finishes as a pure @xmath212 .",
    "right : the response of the network shows that it stays in the cortical state @xmath164.,title=\"fig:\",height=188 ]",
    "we now have a clear view of the functional impact of each parameter in the model .",
    "it turns out that the combination of mathematical and biological constrains basically fixes their values .",
    "we first notice that the requirement for unimodal responses is a very strong constraint .",
    "indeed , it implies that the first pitchfork bifurcation that occurs when @xmath10 varies has to be the one corresponding to the first mode and this requires @xmath216 next , in order to actually see these tuning curves , the threshold @xmath11 should not be too high : the condition shown in figure [ fig : condtc ] is approximately @xmath217 for @xmath147 .",
    "this in turn gives the range for the nonlinear gain @xmath10 : it should be high enough in order for the model to produce tuning curves but smaller than the value for which the tuning curves saturate , hence do not vary with the input contrast anymore , in contradiction with the biological measurements .",
    "this means that @xmath218 .",
    "the last relevant parameter is the width of the tuning curve . as shown in",
    "_ supporting information _ , last paragraph , it can easily be estimated when @xmath219 can be neglected which is often a reasonable assumption , see figure [ fig : osmu1 ] .",
    "it turns out to depend upon the ratio @xmath220 .",
    "this closes the loop : we have set all the three parameters @xmath221 and constrained the others ( @xmath222 ) .",
    "we now discuss the appearance of tuning curves ( _ i.e. _ stationary solutions such that @xmath223 , @xmath224 ) .",
    "what is the condition on the external input in order to produce such stationary solutions ?",
    "let us consider the case @xmath95 .",
    "we have seen ( see figure  [ fig : rho+- ] ) that if a tuning curve exists , then we have three stationary solutions and there is a value @xmath225 of the nonlinear gain @xmath10 ( roughly equal to @xmath226 in figure  [ fig : rho+- ] ) at which the two tuning curves disappear , we call it a turning point ( it results from an opening of the pitchfork when @xmath29 ) .",
    "when varying @xmath7 , we can look for the value of the nonlinear gain @xmath10 ( if there is one ) at which a turning point occurs : it is an indication that tuning curves do exist for higher nonlinear gains .",
    "the trilinos package features the numerical continuation of the locus of the turning point and , starting with the turning point of [ fig : rho+- ] , it can produce the locus of the turning points in the plane @xmath227 as shown in figure [ fig : tp ] .    .",
    "same parameters as in fig.[fig : rho+-].,scaledwidth=50.0% ]    above the blue curve , the stable response of the network is a tuning curve . hence , if @xmath228 , even for no external input , @xmath29 , the network will be in a stable stationary state @xmath229 which is a tuning curve whose tuning angle @xmath230 is randomly selected . however , if @xmath231 until the contrast @xmath7 has reached a certain value , the response will be untuned .",
    "it is more biologically relevant that the network operates in the regime @xmath231 , otherwise the neurons would have a high firing rate ( around @xmath232 of their maximum firing rate , see figure [ fig : rho+- ] ) even though no stimulus is present .",
    "notice that in figures  [ fig : rho+- ] , [ fig : tc ] , we are in the case @xmath228 .",
    "hence , for the parameters of figure  [ fig : rho+- ] , the working range of the nonlinear gain is @xmath233 $ ] .",
    "notice that the condition on the threshold ( see figure  [ fig : condtc ] ) gives the condition for @xmath225 to exist ( in the limit @xmath234 , the turning point converges to the pitchfork point ) .",
    "also , @xmath235 lowers the threshold @xmath11 and taking the differential of w.r.t .",
    "@xmath11 , it can be shown that @xmath236 when @xmath237 .",
    "hence we expect that the local behavior around @xmath238 in figure  [ fig : tp ] to be quite general in the case @xmath237 .",
    "this analysis hence provides a tighter constraint on the nonlinear gain @xmath10 , it should be just below @xmath225 : @xmath239 .",
    "the fact that the cortical network shows two states corresponding to perpendicular orientations in response to a single stimulus can also be put in resonance with some published models of the cortical primary visual area ( see @xcite for a spatial network of ring models ) .",
    "indeed , in this study of planforms in relation to visual hallucination , it may come as a surprise to the attentive reader that most of the planforms ( in the cortical space ) do not respect the good continuation principles of contours since adjacent hypercolumns show responses corresponding to orthogonal orientations . however once we agree that , for a hypercolumn , two orthogonal states are equivalent , this becomes perhaps less surprising .",
    "we relate our formalism to previous studies of recurrent models of orientation selectivity by first noting that the 90 degrees illusion was not reported in @xcite although they share the same assumptions as ours .    in @xcite , the authors used a ( voltage based ) ring model in order to explain some of the features of the complicated spiking network of @xcite .",
    "although they used the non - saturating nonlinearity @xmath240 , they observed that narrowing the spatial extension of inhibition leads to mulimodal responses which they interpreted as neuronal illusions .",
    "this can be understood within our formalism : decreasing the spatial extent of inhibition introduces more fourier terms ( possibly with high values ) in the connectivity @xmath3 and can produce multimodal responses to a unimodal stimulus ( see _ finding the tuning curves , case @xmath241 _ ) .",
    "this type of nonlinearity ( see also @xcite ) can not produce the 90 degrees illusion we have described , more generally , it is not possible to produce the 90 degrees illusions using non - saturating nonlinearities .",
    "remember that the saturation arises when one takes into account the refractory period of neurons ( see @xcite ) , or more simply the fact that the firing rate of neurons is bounded .    under",
    "what conditions do the 90 degrees illusions survive in a network of ring models ?",
    "can we find similar illusions in more sophisticated networks and which experiments could confirm / invalidate our predictions ?",
    "we just discussed the matter of a network of ring models with the study of @xcite . in @xcite ,",
    "the authors used a generalization of the ring model with a very similar connectivity to explain the spontaneous activity observed in optical imaging recordings .",
    "they could not report the 90 degrees illusion because of their use of a non - saturating nonlinearity .",
    "if a detailed mathematical analysis of a modified version of their model to include a saturating rate function were conducted , it is very likely that the 90 degrees illusion would be predicted by the modified model .    finally , despite its ability to reproduce several experimental facts",
    ", the ring model lacks some anatomical data support because it does not use realistic cortical circuitry .",
    "recently , m. shelley _",
    "( see @xcite ) introduced a reduced system of a computationally intensive spiking neuron network model of a hypercolumn with realistic cortical circuitry .",
    "although they do not use a refractory period in their spiking model ( hence , their reduced model has a nonsaturating nonlinearity ) , it could be interesting to look for neuronal illusions predicted by their model using the techniques developed in @xcite .",
    "we have pushed further the study , started in @xcite , of the mathematical properties of the ring model of orientation tuning and of some of their biological implications .",
    "this was achieved by taking into consideration the rich symmetries of the network .",
    "for the first time to our knowledge in the field of neural networks , we have introduced the orbit space reduction technique to deal with translation invariant connectivity kernels .",
    "this allowed us to find a suitable change of coordinates in order to remove the redundancy introduced by the symmetries .",
    "this is a generic technique that can be applied to many other problems in neuroscience . using this reduction ,",
    "we have shown that the exact shape of the connectivity function did not matter much as long as the first mode @xmath242 was the first to bifurcate .",
    "our numerical continuation scheme has allowed us to discover another tuning curve encoded in the network that represents an orientation that is orthogonal to that of the lgn input .",
    "this neural illusion can be thought of as a ghost of the first pitchfork bifurcation that occurs when the sigmoid is centered ( taking the value 0 at the origin ) and opens up when the bias on the sigmoid is removed .",
    "we have shown that it was possible to drive a hypercolumn to the illusory state by adding some dynamics to the lgn input : this gave rise to two dynamical illusions , one relying on rotating the stimulus , the other relying on changing its contrast .",
    "this is a strong prediction of the model that could possibly be tested experimentally even though this seems difficult given the fact that the ring model does not take into account the lateral spatial connectivity that is present in the visual cortex and allows different hypercolumns of orientation to interact with each other , but see the above discussion",
    ".    it would be interesting to see if and how the illusions are modified when adding lateral spatial connections in a spatially organized network of ring models .",
    "finally our approach leads to a near complete understanding of the role of each parameter in the ring model : the shape of the connectivity function through the weights @xmath38 , the threshold @xmath11 , and the nonlinear gain @xmath10 .",
    "let us say a few words about the practical computation of the invariant functions @xmath243 .",
    "as we are interested in the tuning curves , using the estimates of @xcite , we obtain that the @xmath244-norm @xmath245 of the tuning curve is upperbounded by @xmath246 for the connectivity function shown in figure [ fig : osmu0 ] .",
    "the relation @xmath247 yields the estimation : @xmath248 for the same values of the parameters .",
    "the next step is to approximate the sigmoid @xmath8 by a polynomial @xmath249 on some interval @xmath250 $ ] where the value of @xmath251 is chosen so that @xmath252 .",
    "as we need to observe the first two pitchfork bifurcations , reached for the values @xmath176 of @xmath10 , see remark [ rm : numerics ] , we need at least @xmath253 and , being a little bit conservative , we end up computing the solutions for @xmath254 $ ] .",
    "this in turn requires @xmath255 .",
    "note that the more accurate the approximation of @xmath8 , the higher the degree of @xmath249 with the consequence that some numerical instabilities may develop since this implies raising small numbers to high powers .",
    "@xmath249 is then expressed in the basis of the chebychev polynomials as @xmath256 .",
    "the reason for this is that the chebychev polynomials having rational coefficients , we can use , for example , the groebner basis package of the symbolic computation package maple to express the invariants @xmath257 as functions of @xmath127 . for example , we have :    @xmath258 dy\\\\ & \\approx & \\frac{\\varepsilon_0}{\\pi}\\int\\limits_{-\\frac{\\pi}{2}}^\\frac{\\pi}{2}p\\left [ \\lambda v_0+\\lambda \\re\\left ( \\sqrt{j_1 } z_1e^{-2piy } + \\sqrt{j_1 } z_2e^{-4piy}\\right ) \\right ] dy \\\\ & = & \\frac{\\varepsilon_0}{\\pi}\\sum_i\\alpha_i\\int\\limits_{-\\frac{\\pi}{2}}^\\frac{\\pi}{2}t_i\\left [ \\lambda v_0+\\lambda \\re\\left ( \\sqrt{j_1 } z_1e^{-2piy } + \\sqrt{j_1 } z_2e^{-4piy}\\right ) \\right ] dy\\\\ & \\overset{maple}{=}&\\frac{\\varepsilon_0}{\\pi}\\sum_i\\alpha_i\\tilde t_i(v_0,\\vec\\pi ) \\end{array}\\ ] ] the computation of @xmath259 dy$ ] is done automatically by the groebner basis package but requires that the coefficients of the polynomial @xmath260 be rational , not real . this justifies the chebychev approximation . for @xmath261 and an approximation error of @xmath262 ( @xmath263}<0.01 $ ] ) , it gives a polynomials @xmath249 of degree @xmath264 .",
    "one important advantage of this method is that it does not require the vector @xmath127 to be on the orbit space to do the computations , i.e. we can compute @xmath243 even for values of @xmath127 that make no sense , e.g. @xmath265 , and then project the result on the orbit space .",
    "note that the method is coherent since the results shown in figures  [ fig : osmu0 ] and [ fig : osmu1 ] obtained by numerical continuation do satisfy @xmath266 , that is , are consistent with the numerical approximation .      in order to solve the nonlinear equations for the tuning curves , we apply the strategy of @xcite .",
    "the idea is to use a homotopy to solve the problem : we introduce a new parameter @xmath267 which translates @xmath8 , i.e. @xmath268 where @xmath11 is the threshold .",
    "thus @xmath269 and @xmath270 .",
    "this way we change the nonlinearity in in order to find the tcs analytically ( notice that this translation only affects the first equation of ) . indeed , when the nonlinearity is the centered sigmoid @xmath271 we obtain the trivial solution @xmath272 and we can also compute the values of the nonlinear gain @xmath10 where the pitchfork bifurcations occur . we can then numerically continue this trivial solution with respect to the parameters @xmath273 to find the solutions of the equations with the `` correct '' nonlinearity , namely @xmath274 .",
    "we then simply take a slice of the output of the continuation program for @xmath275 and obtain the dependency of the solutions w.r.t .",
    "the nonlinear gain @xmath10 .",
    "this approach , though numerically intensive , is very convenient because it automatically gives the bifurcated branches .",
    "it also allows to compute some non - connected branches of solutions .",
    "this strategy relies on the library trilinos , see the acknowledgements below .",
    "remember that our goal is to find a region in the plane @xmath276 where there exists a pair @xmath277 such that : @xmath278 we work out the case @xmath149 , the other one being very similar .",
    "as @xmath145 , the second equation ( e.2 ) becomes : @xmath279 where @xmath280 .",
    "this quadratic equation in @xmath281 has real solutions if and only if @xmath168 , and they are given by @xmath282 we still have to verify that ( e.1 ) is satisfied for at least one of these solutions .",
    "this yields an equivalent condition to ( e ) but with 3 variables instead of 4 .",
    "for example , for @xmath283 , we obtain the equation in @xmath221 : @xmath284 . using brute force computation for @xmath285,\\,\\theta\\in[0,1],\\,j_1\\in[0,10]$ ]",
    ", we check when this is possible thereby obtaining the graphs shown in figure  [ fig : condtc ] .",
    "if @xmath286 , then the width at half height of the tuning curve is equal to @xmath287 $ ]    by definition , we look for the angle @xmath150 such that :    @xmath288 = 2s\\left[\\lambda \\left(v_0^f+\\sqrt{\\pi_1^fj_1}\\cos_2(\\varphi)-\\theta\\right)\\right ] $ ] . setting @xmath289 and @xmath290 , it follows that @xmath291 .",
    "hence the half - width is given by @xmath292 .",
    "the numerical continuation experiments were done using the library trilinos ( see @xcite and the website _ http://trilinos.sandia.gov_ ) using multiparameters continuation . we thank m.e .",
    "hendersen for his valuable help in using the library multifario ( part of trilinos ) .",
    "much of our work would have proved difficult - if not impossible - without his help .",
    "the authors wish to thank p.chossat for fruitfull discussions regarding equivariance problems . +",
    "this work was partially funded by the erc advanced grant nervi number 227747 .",
    "10 [ 1]`#1 ` urlstyle [ 1]doi:#1    [ 1 ] [ 2 ]    _ _ _ _ _ _ _ _ _ _ _ _ _ _ key : # 1 + annotation :  # 2 _ _ _ _ _ _ _ _ _ _ _ _ _ _    hubel d , wiesel t ( 1962 ) receptive fields , binocular interaction and functional architecture in the cat visual cortex .",
    "j physiol 160 : 106154 .",
    "somers d , nelson s , sur m ( 1995 ) an emergent model of orientation selectivity in cat visual cortical simple cells . journal of neuroscience 15 : 5448 .",
    "ben - yishai r , bar - or r , sompolinsky h ( 1995 ) theory of orientation tuning in visual cortex .",
    "proceedings of the national academy of sciences 92 : 38443848 .",
    "hansel d , sompolinsky h ( 1997 ) modeling feature selectivity in local cortical circuits .",
    "methods of neuronal modeling : 499567 .",
    "shriki o , hansel d , sompolinsky h ( 2003 ) rate models for conductance - based cortical neuronal networks .",
    "neural computation 15 : 18091841 .",
    "ermentrout b ( 1998 ) neural networks as spatio - temporal pattern - forming systems",
    ". reports on progress in physics 61 : 353430 .",
    "dayan p , abbott l ( 2001 ) theoretical neuroscience : computational and mathematical modeling of neural systems .",
    "mit press .",
    "bressloff p , bressloff n , cowan j ( 2000 ) dynamical mechanism for sharp orientation tuning in an integrate - and - fire model of a cortical hypercolumn .",
    "neural computation 12 : 24732511 .",
    "bressloff p , cowan j , golubitsky m , thomas p , wiener m ( 2001 ) geometric visual hallucinations , euclidean symmetry and the functional architecture of striate cortex .",
    "phil trans r soc lond b 306 : 299330 .",
    "douglas r , koch c , mahowald m , martin k , suarez h ( 1995 ) recurrent excitation in neocortical circuits .",
    "science 269 : 981",
    ".    wilson h , cowan j ( 1972 ) excitatory and inhibitory interactions in localized populations of model neurons .",
    "biophys j 12 : 124 .",
    "haragus m , iooss g ( 2009 ) local bifurcations , center manifolds , and normal forms in infinite dimensional systems .",
    "springer verlag utx series . to appear .",
    "veltz r , faugeras o ( 2009 ) local / global analysis of the stationary solutions of some neural field equations .",
    "technical report , arxiv .",
    "http://arxiv.org/pdf/0910.2247v1 .",
    "chossat p , lauterbach r ( 2000 ) methods in equivariant bifurcations and dynamical systems .",
    "world scientific publishing company .",
    "carandini m , ringach d ( 1997 ) predictions of a recurrent model of orientation selectivity .",
    "vision research 37 : 30613071 .",
    "gerstner w , kistler w ( 2002 ) spiking neuron models .",
    "cambridge university press .",
    "blumenfeld b , bibitchkov d , tsodyks m ( 2006 ) neural network model of the primary visual cortex : from functional architecture to lateral connectivity and back .",
    "journal of computational neuroscience 20 : 219241 .",
    "shelley m , mclaughlin d ( 2002 ) coarse - grained reduction and analysis of a network model of cortical response : i. drifting grating stimuli .",
    "journal of computational neuroscience 12 : 97122 .",
    "sala m , heroux ma , day dm ( 2004 ) trilinos tutorial .",
    "technical report sand2004 - 2189 , sandia national laboratories ."
  ],
  "abstract_text": [
    "<S> the ring model of orientation tuning is a dynamical model of a hypercolumn of visual area v1 in the human neocortex that has been designed to account for the experimentally observed orientation tuning curves by local , i.e. , cortico - cortical computations . </S>",
    "<S> the tuning curves are stationary , i.e. time independent , solutions of this dynamical model . </S>",
    "<S> one important assumption underlying the ring model is that the lgn input to v1 is weakly tuned to the retinal orientation and that it is the local computations in v1 that sharpen this tuning . </S>",
    "<S> because the equations that describe the ring model have built - in equivariance properties in the synaptic weight distribution with respect to a particular group acting on the retinal orientation of the stimulus , the model in effect encodes an infinite number of tuning curves that are arbitrarily translated with respect to each other . by using the orbit space reduction technique we rewrite the model equations in canonical form as functions of polynomials that are invariant with respect to the action of this group </S>",
    "<S> this allows us to combine equivariant bifurcation theory with an efficient numerical continuation method in order to compute the tuning curves predicted by the ring model . </S>",
    "<S> surprisingly some of these tuning curves are not tuned to the stimulus . </S>",
    "<S> we interpret them as neural illusions and show numerically how they can be induced by simple dynamical stimuli . </S>",
    "<S> these neural illusions are important biological predictions of the model . </S>",
    "<S> if they could be observed experimentally this would be a strong point in favor ot the ring model . </S>",
    "<S> we also show how our theoretical analysis allows to very simply specify the ranges of the model parameters by comparing the model predictions with published experimental observations . </S>"
  ]
}