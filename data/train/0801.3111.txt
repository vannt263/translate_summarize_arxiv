{
  "article_text": [
    "nk fitness landscapes  @xcite were introduced by kauffman as tunable models of rugged fitness landscape .",
    "an nk landscape is a function defined on binary strings of fixed length and is characterized by two parameters : ( 1 )  @xmath0 for the overall number of bits and ( 2 )  @xmath1 for the neighborhood size . for each bit ,",
    "@xmath1 neighbors are specified and a function is given that determines the fitness contribution of the bit and its neighbors .",
    "usually , the function for each bit is given as a lookup table of size @xmath2 ( one value for each combination of the bit and its neighbors ) , and both the neighbors as well as the subfunction lookup tables are initialized randomly in some way .",
    "nk landscapes are np - complete for @xmath3 , although some variants of nk landscapes are polynomially solvable and there exist approximation algorithms for other cases  @xcite .",
    "nonetheless , nk landscapes remain a challenge for any optimization algorithm and they are also interesting from the perspective of complexity theory and computational biology ; that is why since their inception nk landscapes have attracted researchers in all these areas  @xcite .",
    "this paper presents an in - depth empirical performance analysis of various genetic and evolutionary algorithms on nk landscapes with varying @xmath0 and @xmath1 . for each value of @xmath0 and @xmath1 ,",
    "a large number of problem instances are first generated .",
    "then , the branch - and - bound algorithm is applied to each of these instances to provide a guaranteed global optimum of this instance .",
    "although the application of branch and bound limits the size of problems that we can study , one of the primary goals was to ensure that we are able to verify the global optimum of each instance for every algorithm considered in this study .",
    "several genetic and evolutionary algorithms are then applied to all generated problem instances and their performance is analyzed and compared .",
    "more specifically , we consider the hierarchical bayesian optimization algorithm ( hboa ) , the univariate marginal distribution algorithm ( umda ) , and the simple genetic algorithm ( ga ) with bit - flip mutation , and uniform or two - point crossover operator . additionally , ga without any crossover is considered .",
    "the results provide insight into the difficulty of nk landscapes with respect to the parameters @xmath0 and @xmath1 and performance differences between all compared algorithms .",
    "several interesting avenues for future work are outlined .",
    "the paper starts by describing nk landscapes and the branch - and - bound algorithm used to verify the global optima of generated nk landscapes in section  [ section - landscapes ] .",
    "section  [ section - algorithms ] outlines compared algorithms .",
    "section  [ section - experiments ] presents experimental results . section  [ section - future - work ] discusses future work .",
    "finally , section  [ section - conclusions ] summarizes and concludes the paper .",
    "this section describes nk landscapes and a method to generate random problem instances of nk landscapes .",
    "additionally , the section describes the branch - and - bound algorithm , which was used to obtain global optima of all nk problem instances considered in this paper .",
    "branch and bound is a complete algorithm and it is thus guaranteed to find the true global optimum ; this was especially useful for scalability experiments and performance analyses of different evolutionary algorithms .",
    "nonetheless , branch and bound requires exponential time and thus the size of instances it can solve in practical time is severely limited .",
    "an nk fitness landscape  @xcite is fully defined by the following components :    * the number of bits , @xmath0 .",
    "* the number of neighbors per bit , @xmath1 . * a set of @xmath1 neighbors @xmath4 for the @xmath5-th bit , @xmath6 , for every @xmath7 . * a subfunction @xmath8 defining a real value for each combination of values of @xmath6 and @xmath4 for every @xmath7 .",
    "typically , each subfunction is defined as a lookup table with @xmath2 values .    the objective function @xmath9 to maximize",
    "is then defined as @xmath10    the difficulty of optimizing nk landscapes depends on all of the four components defining an nk problem instance .",
    "one useful approach to analyzing complexity of nk landscapes is to focus on the influence of @xmath1 on problem complexity . for @xmath11 ,",
    "nk landscapes are simple unimodal functions similar to onemax or binint , which can be solved in linear time and should be easy for practically any genetic and evolutionary algorithm .",
    "the global optimum of nk landscapes can be obtained in polynomial time  @xcite even for @xmath12 ; on the other hand , for @xmath3 , the problem of finding the global optimum of unrestricted nk landscapes is np - complete  @xcite .",
    "the problem becomes polynomially solvable with dynamic programming even for @xmath3 if the neighbors are restricted to only adjacent string positions ( using circular strings )  @xcite or if the subfunctions are generated according to some distributions  @xcite . for unrestricted nk landscapes with @xmath3 ,",
    "a polynomial - time approximation algorithm exists with the approximation threshold @xmath13  @xcite .",
    "typically , both the neighbors as well as the lookup tables defining the subfunctions are generated randomly . in this paper , for each string position @xmath6 , we first generate a random set of @xmath1 neighbors where each string position except for @xmath6 is selected with equal probability .",
    "then , the lookup table defining @xmath8 is generated using the uniform distribution over @xmath14 .",
    "consequently , the studied class of nk landscapes is np - complete for any @xmath3 . since the case for @xmath12 is extremely simple to solve , we only considered @xmath3 ; specifically , we considered @xmath15 to @xmath16 with step @xmath17 . to study scalability of various evolutionary algorithms , for each @xmath1 , we considered a range of values of @xmath0 with the minimum value of @xmath18 and the maximum value bounded mainly by the available computational resources and the scope of the empirical analysis .",
    "the basic idea of branch and bound is to recursively explore all possible binary strings of @xmath0 bits using a recursion tree where each level corresponds to one of the bits and the subtrees below each level correspond to the different values of the bit corresponding to this level . to make the algorithm more efficient ,",
    "some subtrees are cut if they can be proven to not lead to any solution that is better than the best - so - far solution found .",
    "while this can not eliminate the exponential complexity , which can be expected due to the np - completeness for nk landscapes with @xmath3 , it significantly improves the performance of the algorithm and allows it to solve much larger problem instances than if a complete recursion tree had to be explored .",
    "the branch - and - bound procedure is illustrated in figure  [ fig - bb - procedure ] .    before running the branch - and - bound algorithm",
    ", we first use a simple hill climber based on bit - flip mutation with several random restarts to locate high - quality local optima .",
    "the best of the discovered optima is then used as the best - so - far solution when the branch - and - bound algorithm is started . in the branch - and - bound approach",
    "used in this paper , the bits are assigned sequentially from @xmath19 to @xmath20 ( there are two subtrees of each node at level @xmath5 , each corresponding to one value of @xmath6 ) , although reordering the bits might improve performance under some conditions .    when processing a node at level @xmath5 , the best value we can obtain by setting the remaining @xmath21 bits is given by @xmath22 where bits @xmath23 to @xmath24 are assumed to be fixed to the values defined by the path from the root of the recursion tree to the current node .",
    "if a solution has been found already that has a higher fitness than this maximum possible value , the processing below the currently processed node does not have to continue and the remaining unexplored parts of the recursion tree can be explored with the exception of those parts that have already been cut .",
    "we also tried another variant of the branch - and - bound algorithm , in which the best value of the objective function is computed incrementally for subsets containing only the first @xmath5 bits with @xmath25 to @xmath0 .",
    "while this approach has been very efficient in solving instances of the sherrington - kirkpatrick spin glass model  @xcite , for nk landscapes , the algorithm described earlier performed more efficiently .",
    "the aforedescribed branch - and - bound algorithm is complete and it is thus guaranteed to find the global optimum of any problem instance .",
    "nonetheless , the complexity of branch and bound can be expected to grow exponentially fast and solving large nk instances becomes intractable with this algorithm .",
    "for example , for @xmath15 , the proposed branch - and - bound algorithm was fast enough to solve ten thousand unique instances of @xmath26 ; for @xmath27 , the algorithm was fast enough to deal with instances of size @xmath28 .",
    "while the evolutionary algorithms presented in the next section should be capable of reliably solving larger instances , their convergence to the global optimum can not be guaranteed ; nonetheless , section  [ section - future - work ] discusses how to extend this study to deal with larger nk problem instances , which are intractable with the branch - and - bound algorithm .",
    "this section outlines the optimization algorithms discussed in this paper : ( 1 ) the hierarchical bayesian optimization algorithm ( hboa )  @xcite , ( 2 )  the univariate marginal distribution algorithm ( umda )  @xcite , and ( 3 )  the genetic algorithm ( ga )  @xcite .",
    "additionally , the section describes the deterministic hill climber ( dhc )  @xcite , which is incorporated into all compared algorithms to improve their performance . in all compared algorithms , candidate solutions",
    "are represented by binary strings of @xmath0 bits and a niching technique called restricted tournament replacement ( rtr )  @xcite is used for effective diversity maintenance .",
    "the genetic algorithm ( ga )  @xcite evolves a population of candidate solutions typically represented by fixed - length binary strings .",
    "the first population is generated at random .",
    "each iteration starts by selecting promising solutions from the current population .",
    "we use binary tournament selection .",
    "new solutions are created by applying variation operators to the population of selected solutions .",
    "specifically , crossover is used to exchange bits and pieces between pairs of candidate solutions and mutation is used to perturb the resulting solutions .",
    "here we use uniform or two - point crossover , and bit - flip mutation  @xcite . to ensure effective diversity maintenance ,",
    "the new candidate solutions are incorporated into the original population using restricted tournament replacement ( rtr )  @xcite .",
    "the run is terminated when termination criteria are met .",
    "the univariate marginal distribution algorithm ( umda )  @xcite also evolves a population of candidate solutions represented by fixed - length binary strings with the initial population generated at random .",
    "each iteration starts by selecting a population of promising solutions using any common selection method of genetic and evolutionary algorithms ; we use binary tournament selection .",
    "then , the probability vector is learned that stores the proportion of @xmath17s in each position of the selected population . each bit of a new candidate solution",
    "is then set to @xmath17 with the probability equal to the proportion of @xmath17s in this position ; otherwise , the bit is set to @xmath29 .",
    "consequently , the variation operator of umda preserves the proportions of @xmath17s in each position while decorrelating different string positions .",
    "the new candidate solutions are incorporated into the original population using rtr .",
    "the run is terminated when termination criteria are met .",
    "umda is an estimation of distribution algorithm ( eda )  @xcite .",
    "edas  also called probabilistic model - building genetic algorithms ( pmbgas )  @xcite and iterated density estimation algorithms ( ideas )  @xcite  replace standard variation operators of genetic algorithms such as crossover and mutation by building a probabilistic model of promising solutions and sampling the built model to generate new candidate solutions .",
    "the only difference between the ga and umda is in the way the selected solutions are processed to generate new solutions .",
    "the hierarchical bayesian optimization algorithm ( hboa )  @xcite is also an eda and the basic procedure of hboa is similar to that of the umda variant described earlier .",
    "however , to model promising solutions and sample new solutions , bayesian networks with local structures  @xcite are used instead of the simple probability vector of umda .",
    "similarly as in the considered ga and umda variants , the new candidate solutions are incorporated into the original population using rtr and the run is terminated when termination criteria are met .",
    "the deterministic hill climber ( dhc ) is incorporated into ga , umda and hboa to improve their performance .",
    "dhc takes a candidate solution represented by an @xmath0-bit binary string on input .",
    "then , it performs one - bit changes on the solution that lead to the maximum improvement of solution quality .",
    "dhc is terminated when no single - bit flip improves solution quality and the solution is thus locally optimal . here",
    ", dhc is used to improve every solution in the population before the evaluation is performed .",
    "this section describes experiments and presents experimental results .",
    "first , problem instances and experimental setup are discussed .",
    "next , the analysis of hboa , umda and several ga variants is presented .",
    "finally , all algorithms are compared and the results of the comparisons are discussed .",
    "nk instances for @xmath15 to @xmath27 with step @xmath17 were studied .",
    "the only restriction on problem size was the efficiency of the branch - and - bound algorithm , the complexity of which grew very fast with @xmath0 . for @xmath15",
    ", we considered @xmath18 to @xmath30 with step @xmath31 ; for @xmath32 , we considered @xmath18 to @xmath33 with step @xmath31 ; for @xmath34 , we considered @xmath18 to @xmath35 with step @xmath31 ; for @xmath36 , we considered @xmath18 to @xmath37 with step @xmath31 ; finally , for @xmath27 , we considered @xmath18 to @xmath38 with step @xmath31 .    for each combination of @xmath0 and @xmath1 , we generated 10,000 random problem instances and for each instance we used the branch - and - bound algorithm to locate the global optimum .",
    "then , we applied hboa , umda and several ga variants to each of these instances and collected empirical results , which were subsequently analyzed .",
    "that means that overall 600,000 unique problem instances were generated and all of them were tested with every algorithm included in this study .",
    "the following list summarizes the algorithms included in this study :    a.   hierarchical boa ( hboa ) .",
    "b.   univariate marginal distribution algorithm ( umda ) . c.   genetic algorithm with uniform crossover and bit - flip mutation .",
    "d.   genetic algorithm with two - point crossover and bit - flip mutation .",
    "e.   genetic algorithm with bit - flip mutation and no crossover .",
    "f.   hill climbing ( results omitted due to inferior performance and infeasible computation ) .      to select promising solutions ,",
    "binary tournament selection is used .",
    "new solutions ( offspring ) are incorporated into the old population using rtr with window size @xmath39 as suggested in ref .",
    "@xcite . in hboa ,",
    "bayesian networks with decision trees  @xcite are used and the models are evaluated using the bayesian - dirichlet metric with likelihood equivalence  @xcite and a penalty for model complexity  @xcite .",
    "all ga variants use bit - flip mutation with the probability of flipping each bit @xmath40 .",
    "two common crossover operators are considered in a ga : two - point and uniform crossover . for both crossover operators , the probability of applying crossover",
    "is set to @xmath41 . to emphasize the importance of using crossover ,",
    "the results for ga without any crossover are also included , where only bit - flip mutation is used .",
    "a stochastic hill climber with bit - flip mutation has also been considered in the initial stage , but the performance of this algorithm was far inferior compared to any other algorithm included in the comparison and it was intractable to solve most problem instances included in the comparison ; that is why the results for this algorithm are omitted .    for each problem instance and each algorithm ,",
    "an adequate population size is approximated with the bisection method  @xcite , which estimates the minimum population size required for reliable convergence to the optimum .",
    "here , the bisection method finds an adequate population size for the algorithms to find the optimum in 10 out of 10 independent runs .",
    "each run is terminated when the global optimum has been found .",
    "the results for each problem instance comprise of the following statistics : ( 1 ) the population size , ( 2 ) the number of iterations ( generations ) , ( 3 ) the number of evaluations , and ( 4 ) the number of flips of dhc . for each value of @xmath0 and @xmath1 ,",
    "all observed statistics were averaged over the 10,000 random instances . since for each instance , 10 successful runs were performed , for each @xmath0 and @xmath1 and each algorithm the results are averaged over 100,000 successful runs .",
    "overall , for each algorithm , the results correspond to 6,000,000 successful runs on a total of 600,000 unique problem instances .",
    "figure  [ fig - hboa - results ] shows the average performance statistics for hboa on nk problem instances for @xmath15 to @xmath27 .",
    "as expected , performance of hboa gets worse with increasing @xmath1 .",
    "more specifically , the population size , the number of iterations , the number of evaluations , and the number of dhc flips appear all to grow exponentially with @xmath1 . for a fixed @xmath1 ,",
    "the time complexity appears to grow with @xmath0 slightly faster than polynomially regardless of whether it is measured by the number of evaluations or the number of flips .",
    "+    figure  [ fig - umda - results ] shows the average performance statistics for umda .",
    "similarly as with hboa , time complexity of umda grows exponentially fast with @xmath1 and its growth with @xmath0 for a fixed @xmath1 appears to be slightly faster than polynomial .",
    "+    figures  [ fig - ga2p - results ] , [ fig - gau - results ] and  [ fig - ganc - results ] show the average performance statistics for all three ga variants .",
    "similarly as with hboa and umda , time complexity of all ga variants grows exponentially fast with @xmath1 and its growth with @xmath0 for a fixed @xmath1 is slightly faster than polynomial .      to compare performance of algorithms @xmath42 and @xmath43 , for each problem instance , we can compute the ratio of the number of evaluations required by @xmath42 and the number of evaluations required by @xmath43 ; analogically , we can compute the ratio of the number of flips required by @xmath42 and the number of flips required by @xmath43 . then",
    ", the ratios can be averaged over all instances with specific @xmath0 and @xmath1 .",
    "if @xmath42 performs better than @xmath43 , the computed ratios should be smaller than @xmath17 ; if @xmath42 performs the same as @xmath43 , the ratios should be about @xmath17 ; finally , if the @xmath42 performs worse than @xmath43 , the ratios should be greater than @xmath17 .",
    "a comparison based on the aforementioned ratio was computed for each pair of algorithms studied in this work . to make the results easier to read ,",
    "the superior algorithm was typically used as the second algorithm in the comparison ( in the denominator of the ratios ) , so that the ratios should be expected to be greater than @xmath17 .",
    "figure  [ fig - compare - hboa - ga2p ] compares performance of ga with two - point crossover and that of hboa .",
    "figure  [ fig - compare - hboa - gau ] compares performance of ga with uniform crossover and that of hboa .",
    "figure  [ fig - compare - gau - ga2p ] compares performance of ga with two - point crossover and that of ga with uniform crossover .",
    "finally , figures  [ fig - compare - gau - ganc ] and  [ fig - compare - ga2p - ganc ] compare performance of gas with and without crossover .",
    "one of the important trends to observe in the results of the comparisons is the change in the two ratios with problem size . in most cases ,",
    "when one algorithm outperforms another one , the differences become more significant as the problem size increases . in some cases , although one algorithm outperforms another one on small problems , because of the observed dynamics with problem size , we can expect the situation to reverse for large problems .",
    "the comparisons based on the number of evaluations and the number of flips can be summarized as follows :    hboa . : :    while for small values of @xmath1 , hboa is outperformed by    other algorithms included in the comparison , as @xmath1    increases , the situation changes rapidly .",
    "more specifically , for    larger @xmath1 , hboa outperforms all other algorithms and its    relative performance with respect to other algorithms improves with    increasing problem size .",
    "the larger the @xmath1 , the more    favorably hboa compares to other algorithms .",
    "ga with uniform crossover .",
    ": :    ga with uniform crossover performs better than ga with two - point    crossover and umda regardless of @xmath1 and its relative    performance with respect to these algorithms improves with problem    size",
    ". however , as mentioned above , for larger values of    @xmath1 , ga with uniform crossover is outperformed by hboa and    the factor by which hboa outperforms ga with uniform crossover grows    with problem size .",
    "ga with two - point crossover .",
    ": :    ga with two - point crossover performs worse than hboa and ga with    uniform crossover for larger values of @xmath1 , but it still    outperforms umda with respect to the number of flips , which is the    most important performance measure .",
    ": :    umda performs worst of all recombination - based algorithms included in    the comparison except for a few cases with small values of    @xmath1 .",
    "crossover versus mutation .",
    ": :    crossover has proven to outperform pure mutation , which is clear from    all the results .",
    "first of all , for the most difficult instances ,    hboa  which is a pure selectorecombinative evolutionary algorithm with    no explicit mutation  outperforms other algorithms with increasing    @xmath0 .",
    "second , eliminating crossover from ga significantly    decreases its efficiency and the mutation - based approaches perform    worst of all compared algorithms .",
    "specifically , ga with no crossover    is outperformed by all other variants of ga , and the stochastic hill    climbing is not even capable of solving many problem instances in    practical time .",
    "there are several interesting ways of extending the work presented in this paper .",
    "first of all , the problem instances generated in this work can be used for analyzing performance of other optimization algorithms and comparing different optimization algorithms on a broad class of problems with tunable difficulty .",
    "second , the class of problems considered in this study can be extended substantially using genetic and evolutionary algorithms with adequate settings for solving instances unsolvable with branch and bound .",
    "although the global optimum would no longer be guaranteed , methods can be devised that still guarantee that the global optimum is found reliably .",
    "finally , other probability distributions for generating nk problem instances can be considered to provide further insights into the difficulty of various classes of nk landscapes and the benefits and costs of using alternative optimization strategies in each of these classes .",
    "this paper presented an in - depth empirical performance study of several genetic and evolutionary algorithms on nk landscapes with various values of @xmath0 and @xmath1 .",
    "specifically , the algorithms considered in this work included the hierarchical bayesian optimization algorithm ( hboa ) , the univariate marginal distribution algorithm ( umda ) , and the simple genetic algorithm ( ga ) with bit - flip mutation , and two - point or uniform crossover .",
    "additionally , ga with bit - flip mutation but no crossover was considered . for each value of @xmath0 and @xmath1 ,",
    "a large number of nk instances were generated and solved with the branch - and - bound algorithm , which is a complete algorithm that is guaranteed to find the global optimum .",
    "performance of all algorithms was analyzed and compared , and the results were discussed .",
    "the main contributions of this work are summarized in what follows .",
    "first of all , nk landscapes represent an important class of test problems and despite that there has been practically no work on using advanced estimation of distribution algorithms ( edas ) on nk landscapes .",
    "this work provides many experimental results on one advanced and one simple eda , and it shows that advanced edas can significantly outperform other genetic and evolutionary algorithms on nk landscapes for larger values of @xmath1 .",
    "second , most studies concerned with nk landscapes do not verify the global optimum of the considered problem instances and it is thus often difficult to interpret the results and evaluate their importance . in this study ,",
    "the global optimum of each instance is verified with the complete branch - and - bound algorithm .",
    "third , while the difficulty of nk landscapes can be expected to vary substantially from instance to instance , most studies presented in the past used only a limited sample of problem instances ; here we provide an in - depth study where about 600,000 unique problem instances are considered . finally ,",
    "the results in this paper are not based on only one evolutionary algorithm ; instead , we consider several qualitatively different evolutionary algorithms , providing insight into the comparison of genetic algorithms and edas , as well as into the comparison of the mutation - based and recombination - based evolutionary algorithms .",
    "this project was sponsored by the national science foundation under career grant ecs-0547013 , by the air force office of scientific research , air force materiel command , usaf , under grant fa9550 - 06 - 1 - 0096 , and by the university of missouri in st .",
    "louis through the high performance computing collaboratory sponsored by information technology services , and the research award and research board programs .",
    "government is authorized to reproduce and distribute reprints for government purposes notwithstanding any copyright notation thereon .",
    "any opinions , findings , and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the national science foundation , the air force office of scientific research , or the u.s .",
    "some experiments were done using the hboa software developed by martin pelikan and david e. goldberg at the university of illinois at urbana - champaign and most experiments were performed on the beowulf cluster maintained by its at the university of missouri in st .",
    "louis .",
    "h.  e. aguirre and k.  tanaka .",
    "genetic algorithms on nk - landscapes : effects of selection , drift , mutation , and recombination . in g.",
    "r. raidl et  al . ,",
    "editors , _ applications of evolutionary computing : evoworkshops 2003 _ , pages 131142 , 2003 .",
    "l.  altenberg . landscapes . in t.",
    "bck , d.  b. fogel , and z.  michalewicz , editors , _ handbook of evolutionary computation _ , pages b2.7:510 .",
    "institute of physics publishing and oxford university press , bristol , new york , 1997 .",
    "s.  baluja .",
    "population - based incremental learning : a method for integrating genetic search based function optimization and competitive learning .",
    "cmu - cs-94 - 163 , carnegie mellon university , pittsburgh , pa , 1994 .",
    "k.  sastry .",
    "evaluation - relaxation schemes for genetic and evolutionary algorithms .",
    "master s thesis , university of illinois at urbana - champaign , department of general engineering , urbana , il , 2001 .",
    "also illigal report no ."
  ],
  "abstract_text": [
    "<S> this study analyzes performance of several genetic and evolutionary algorithms on randomly generated nk fitness landscapes with various values of @xmath0 and @xmath1 . </S>",
    "<S> a large number of nk problem instances are first generated for each @xmath0 and @xmath1 , and the global optimum of each instance is obtained using the branch - and - bound algorithm . </S>",
    "<S> next , the hierarchical bayesian optimization algorithm ( hboa ) , the univariate marginal distribution algorithm ( umda ) , and the simple genetic algorithm ( ga ) with uniform and two - point crossover operators are applied to all generated instances . </S>",
    "<S> performance of all algorithms is then analyzed and compared , and the results are discussed .         * </S>",
    "<S> *    * *    * *    * keywords : * nk fitness landscape , hierarchical boa , genetic algorithm , branch and bound , performance analysis , scalability , local search , crossover . </S>"
  ]
}