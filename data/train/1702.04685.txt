{
  "article_text": [
    "the large hadron collider ( lhc ) at cern continues to advance the exploration of the energy frontier as it begins its new run , called run 2 , in 2015 by colliding protons at a center - of - mass energy of 13 tera - electronvolts ( tev ) , an energy never before achieved in the laboratory .",
    ", from 2010 - 2012 , provided the data that led to the discovery of the higgs boson .",
    "it was followed by a two - year period of upgrade work to prepare the collider and its associated detector experiments for the new higher energy and the much larger amount of collision data . during",
    ", the cms experiment [ 1 ] is expected to collect ten times more data than it did in .",
    "however , the disk storage resources for cms will be increasing only marginally . for",
    ", cms physics analysis was based upon the analysis object data ( aod ) format , but this format is too large for it to be used in the same way for run 2 . at the end of 2013 ,",
    "the total size of aod stored by cms for run 1 was about 20 petabytes . increasing this amount by ten times for run 2 would vastly exceed available storage resources . to tackle this challenge ,",
    "cms has developed a new , condensed data format called mini - aod .",
    "for run 1 , the cms data flow included several steps ( fig .",
    "[ dmrun1 ] ) .",
    "raw data were digitized , and collision events were reconstructed to form the reco dataset .",
    "about twice a year , the aod dataset was generated from reco .",
    "aod comprised about one to four billion events of roughly 400 kilobytes each in size . from multiple copies of aod spread across many cms computing sites , physics analysis groups generated intermediate datasets called ntuples that had more specialized formats intended for particular analysis needs .",
    "the last step was for individual analysis groups to generate simple , flat ntuples for their specific needs from the intermediate ntuples .",
    "data flow for cms run 1 .",
    "aod comprises about one to four billion events , with each event taking about 400 kilobytes . ]    unfortunately , the different sets of intermediate ntuples were largely overlapping , and many copies of them were made throughout the cms storage infrastructure . in run 2 , given the vast increase in the amount of data , this data flow would not be sustainable .",
    "the new cms data flow for run 2 replaces the many , duplicative intermediate ntuples with one standard , condensed dataset called mini - aod ( fig .",
    "[ dmrun2 ] ) . without the need for specialized intermediate ntuples , the multiple copies of aod used in run 1 to support ntuple generation",
    "have also been eliminated .",
    "mini - aod is produced centrally by the cms computing group and provides a common foundation for cms physics analyses .",
    "its compressed format is one tenth the size of aod , and it provides cms the solution for handling the large influx of data coming from run 2 . it is designed to meet the needs of most cms physics analyses while fitting within storage constraints .",
    "data flow for cms run 2 .",
    "the size of aod is about 480 kilobytes per event , while mini - aod is around 40 - 50 kilobytes per event .",
    "total aod size will grow substantially compared to run 1 , going as high as 12 billion events or even more , depending on how much data is ultimately collected . ]",
    "mini - aod was developed under the guidance of a basic design philosophy with the following principles :    * use the minimum amount of space . *",
    "extract only the minimum required data from existing data formats . * re - use existing data formats and algorithms where possible without including unnecessary data . *",
    "maintain flexibility for : * * supporting a wide variety of cms physics analyses .",
    "* * novel analysis techniques .",
    "* * re - tuning of algorithms and calibrations that may be necessary after the first new data at 13 tev are analyzed .",
    "* do nt over - optimize .",
    "the basic requirements are to be able to store about five billion events at a cms computing center and to be able to process them in one or two days . once those requirements are met , further optimization and compression of mini - aod is not necessary .",
    "efficient use of space is not the only objective mini - aod must meet .",
    "it must also support the full range of cms physics analyses , from standard model measurements to searches for exotic new physics . and it must provide the flexibility to respond to the challenges of collisions at the new , higher energy of 13 tev .",
    "in particular , the number of additional collision interactions , called pile - up , is much higher in run 2 than in run 1 and presents difficulties for accurately reconstructing collision events efficiently .",
    "based upon the design philosophy , the following components are included in mini - aod .",
    "first it contains high - level physics objects : leptons , photons , jets , and @xmath0 , which is defined as follows .",
    "@xmath1 , where @xmath2 is @xmath3 of reconstructed particle _",
    "i _ projected on the plane perpendicular to the lhc beams .",
    "these objects are stored in the cms physics analysis tools format that includes detailed information .",
    "second , mini - aod contains all particle candidates in a packed format that contains only basic kinematic information .",
    "the candidates are produced by the cms particle flow ( pf ) reconstruction algorithm [ 2 , 3 ] ( fig .",
    "[ pflow ] ) , and their presence allows analysts to re - reconstruct physics objects with new techniques directly from mini - aod .",
    "third , trigger information is also stored .",
    "triggers are used to decide which collisions events are recorded .",
    "the trigger data identify which triggers were tripped and enables calculation of trigger efficiencies .",
    "fourth , information about simulated particles is included .",
    "final state particles are stored , as well as generated jets and reference information .",
    "fifth , some miscellaneous information like the interaction vertices and @xmath0 filters is also included .",
    "cms particle flow ( pf ) algorithm [ 2 , 3 ] .",
    "the top half of the diagram shows how collisions lead to particle decays and final state particles , which leave tracks and deposits in the cms detector .",
    "the bottom half shows that pf candidates are derived from detector information and then become input for the pf algorithm that uses them to construct high - level physics objects like leptons and jets , which then are used by analysts to reconstruct the collision event . ]",
    "mini - aod contains leptons , photons , jets , and @xmath0 objects .",
    "high - quality electrons are saved with detailed information if their transverse momentum ( @xmath4 ) is greater than 5 giga - electronvolts ( gev ) , or , if not , with only their detector clusters . full muon information is saved for muon candidates that meet basic quality requirements .",
    "likewise , high - quality tau candidates with @xmath5 gev are saved .",
    "similar to electrons , photon candidates that pass quality requirements are stored in detail , while lower quality photons are stored with only basic detector cluster information .",
    "two collections of jets are saved : one for general use , and one intended for substructure studies .",
    "the general - use jets must have @xmath6 gev and include b - quark jet discriminators and secondary decay vertex information .",
    "jets in the second collection must have @xmath7 gev and include jet substructure information .",
    "pf candidates are the building blocks used by pf to reconstruct high - level physics objects .",
    "basic information for all pf candidates is included in mini - aod : four - momentum , charge , impact parameters , and particle type ( electron , photon , etc . ) .",
    "quality flags relating to association to the interaction vertex and tracking hits in the detector are also provided .",
    "lossy compression is applied to the variables , limiting precision to about 0.1% .",
    "compression is facilitated by sorting the pf candidates , converting ` double ` variables ( typically 8 bytes ) to ` float ` ( typically 4 bytes ) , and reducing precision of matrices from @xmath8 to @xmath9 .",
    "the presence of all pf candidates in mini - aod supports many important physics analysis tasks .",
    "varied algorithms for pile - up mitigation can be studied , and lepton and photon isolation algorithms can be re - computed with these different pile - up algorithms .",
    "reconstructed jets can be re - clustered in substructure studies , and b - jet discrimination can be re - computed with new criteria .",
    "the pf candidates allow analysts to use mini - aod to test and utilize a wide variety of candidate - based algorithms .",
    "the physics objects and pf candidates are fully cross referenced , so each object is linked to the pf candidates from which it was reconstructed . this linking facilitates event interpretation and more accurate calculation of isolation .",
    "for simulated events , only a selected set of particles is stored because the simulated particle format , called genparticle , takes a lot of space .",
    "first , a set called pruned genparticles that includes initial partons , heavy flavor particles , electroweak bosons , and leptons is stored in full .",
    "second , a set called packed genparticles that have only the four - momentum and particle type is saved for particles representing the final state particles in the event . generated jets and some reference information is also saved .    with the packed genparticles , an analyst can re - make the generated jets with various algorithms . the pruned genparticles enable event classification , flavor definition , and matching to reconstructed physics objects .",
    "links from each packed genparticle to its last surviving ancestor pruned genparticle allow the decay chain of the event to be reconstructed .",
    "figure [ macomp ] shows a breakdown of the composition of mini - aod .",
    "composition of mini - aod .",
    "the average size of an event contained in mini - aod for simulated events involving top and antitop quark decay is about 40 kilobytes . ]",
    "mini - aod was conceived in 2014 .",
    "february brainstorming sessions led to a prototype in march .",
    "further development and a series of integration test releases occurred in april and may , and mini - aod was ready for production use in june .",
    "the latter half of the year comprised two concentrated campaigns of testing and validation , the computing , software and analysis challenge 2014 and the physics challenge 2014 . during these campaigns ,",
    "many bugs and issues were discovered and fixed .",
    "now , as run 2 begins in 2015 , mini - aod has been validated and is ready for the flood of new data .",
    "the cms experiment faces the challenge of analyzing ten times more data in the new lhc starting this year compared to run 1 in 2010 - 2012 .",
    "however , cms data storage resources have increased only marginally .",
    "the run 1 method of using aod as the foundation of physics analysis and storing many overlapping versions of intermediate datasets is not sustainable for run 2 . for these reasons ,",
    "a new compressed data format called mini - aod has been developed .",
    "mini - aod is 10% of the size of aod , and it replaces the multiple intermediate datasets used in run 1 .",
    "it provides a standard foundation for cms physics analysis .",
    "its optimized collections store only the minimum required amount of information , but it maintains flexibility for a variety of new and customized analysis techniques and also for any re - tuning of the analysis process that might be necessary as cms performs the ground - breaking exploration of the energy frontier at .",
    "mini - aod has undergone a lengthy and thorough testing and validation process and is now ready to meet the challenge of lhc run 2 .",
    "chatrchyan s _ et al _ ( cms collaboration ) 2008 the cms experiment at the cern lhc_jinst _ vol 3 p s08004      cms collaboration 2010 commissioning of the particle - flow event reconstruction with the first lhc collisions recorded in the cms detector _",
    "cms physics analysis summary _ cms - pas - pft-10 - 001 ( http://cdsweb.cern.ch/record/1247373 )"
  ],
  "abstract_text": [
    "<S> the cms experiment has developed a new analysis object format ( `` mini - aod '' ) targeting approximately 10% of the size of the run 1 aod format . </S>",
    "<S> the motivation for the mini - aod format is to have a small and quickly derived data format from which the majority of cms analysis users can start their analysis work . </S>",
    "<S> this format is targeted at having sufficient information to serve about 80% of cms analysis , while dramatically simplifying the disk and i / o resources needed for analysis . </S>",
    "<S> such large reductions were achieved using a number of techniques , including defining light - weight physics - object candidate representations , increasing transverse momentum thresholds for storing physics - object candidates , and reduced numerical precision when it is not required at the analysis level . in this contribution </S>",
    "<S> we discuss the critical components of the mini - aod format , our experience with its deployment and the planned physics analysis flow for run 2 based on the mini - aod . </S>"
  ]
}