{
  "article_text": [
    "we begin by defining some notation .",
    "let @xmath0 be an integer , @xmath1 .",
    "all our vectors will have length @xmath0 , and will have entries in the real numbers @xmath2 . for a vector @xmath3 , we write @xmath4 for the @xmath5th entry of @xmath3 , we write @xmath6 for the mean of @xmath3 and we write @xmath7 for the ( unnormalised ) standard deviation of @xmath3 .",
    "we write @xmath8 for the all - one vector of length @xmath0 , and call any scalar multiple of @xmath8 a constant vector . for vectors @xmath9 and @xmath10 that are not constant vectors , the _ pearson correlation coefficient _",
    "@xmath11 is defined by @xmath12 finally , the _ pearson distance _ @xmath13 between vectors @xmath9 and @xmath10 is defined to be @xmath14 since @xmath11 lies between @xmath15 and @xmath16 , the pearson distance lies between @xmath17 and  @xmath18 .",
    "both pearson distance and pearson correlation are well - known concepts in the area of cluster analysis .",
    "the channel considered by kees a. schouhamer immink and jos h. weber  @xcite is defined as follows . if the vector @xmath3 is sent through the channel , the channel outputs the received vector @xmath19 where @xmath20 here @xmath21 ( the _ gain _ ) and @xmath22 ( the _ offset _ ) are unknown real numbers , with @xmath23 , and @xmath24 where the @xmath25 are independently normally distributed with mean @xmath17 and standard deviation @xmath26 .",
    "the channel is motivated by the properties of flash memory .",
    "we give some basic details of this setting here ; see  @xcite for more detailed introductions , and see ( for example )  @xcite for another approach to modelling the problem using rank modulation codes .",
    "flash memory is made up of an array of floating - gate transistors , known as flash cells .",
    "data is stored in each cell by varying the charge ( equivalently , the voltage ) on the cell . in single level cell ( slc )",
    "flash memory , each cell stores one bit of information depending on whether the voltage level is zero or non - zero . in more recent multi - level cell ( mlc )",
    "systems , more information is stored by allowing the cell to be charged at one of several discrete non - zero voltage levels .",
    "the vector @xmath3 corresponds to the voltages we wish to store in a block of @xmath0 cells , so @xmath4 is the voltage we wish to store in the @xmath5th cell . we can not hope to initialise a cell with the exact voltage we wish : the errors in this process give rise to the error term @xmath27 . over time , the voltage in each cell drops due to charge leakage .",
    "we assume that the function that gives this voltage change is unknown , but is affine and is independent of which cell in the block we are examining .",
    "the unknown coefficients @xmath21 and",
    "@xmath22 specify this function ; the coefficient @xmath21 is positive since charge leakage is monotonic increasing : the more charge we have initially , the more we have after leakage .",
    "the received vector @xmath19 thus models the set of voltages we retrieve from a block of cells we have initialised with voltages corresponding to @xmath3 .",
    "we note that the channel does not model some aspects of flash memory : intercell coupling ( where the charge on one cell influences the charge on neighbouring cells ) is not modelled in any way ; nor is the possibility that the magnitude of the error in the charging process depends on the charge in some way .",
    "nevertheless , the channel is very natural and captures key properties of the process of retrieving data from flash memory .",
    "immink and weber assume that the vectors @xmath3 lie in some finite subset @xmath28 of @xmath29 .",
    "( in fact , they assume that @xmath30 for some fixed integer @xmath31 . )",
    "this corresponds to the fact that we initialise each cell with one of a finite discrete set of voltages . to ensure unique decoding in the absence of noise",
    ", they assume that if @xmath32 then no other codeword @xmath33 has the form @xmath34 for real numbers @xmath21 and @xmath22 with @xmath21 positive .",
    "they also assume that no constant vector lies in @xmath28 .",
    "this makes the pearson distance between any pair of vectors in @xmath28 well - defined ; see section  [ sec : comments ] for additional motivation for this assumption . weber , immink and blackburn  @xcite",
    "have studied maximal codes @xmath35 with these properties .",
    "a decoder based on pearson distance is proposed in this setting in  @xcite .",
    "so we decode a received vector @xmath19 as @xmath36 , where @xmath37 minimises @xmath38 .",
    "one motivation for this choice is that pearson distance behaves well with respect to an affine charge - leakage function , since @xmath39 pearson distance has a natural geometric meaning : see section  [ sec : comments ] for a brief discussion .    in this paper , we derive a maximum likelihood decoding function for the channel in  @xcite , and compare a decoder based on this function with a decoder based on minimising pearson distance .",
    "we also propose and justify a notion of minimum distance for codes used with this channel .",
    "we should emphasise that the model makes no assumptions on the distribution of the unknown ( ` nuisance ' ) parameters @xmath21 and @xmath22 :",
    "if we know something about these distributions , other decoding methods might be appropriate .",
    "for example , if @xmath21 is known to be very close to @xmath16 , then decoding based on minimising euclidean distance is sensible ; immink and weber  @xcite have proposed a decoder based on minimising a weighted sum of euclidean and pearson distances in some situations .",
    "the remainder of the paper is structured as follows .",
    "section  [ sec : preliminaries ] sets up notation , and contains some preliminary lemmas . in section  [ sec : mld ] we show how to achieve maximum likelihood decoding for this channel .",
    "pearson distance is not the measure to use for maximum likelihood decoding , but is often a good approximation to it : simulations show comparable performance between both mld and pearson decoders .",
    "section  [ sec : distance ] defines and justifies a minimum distance measure for codes designed for the channel . in section  [ sec : comparison ] , we give some results of simulations that compare the approach in  @xcite with the one taken here . finally , section  [ sec : comments ] provides some comments on various aspects of the model in  @xcite .",
    "this section contains notation that will be used in the remainder of this paper .",
    "some simple facts , which will often be used without further comment , are also stated .",
    "we define @xmath40 to be the euclidean length of @xmath41 , and we define @xmath42 to be the euclidean distance between @xmath43 .",
    "define the subspace @xmath44 of @xmath45 by @xmath46 let @xmath47 be defined by @xmath48 we can think of @xmath49 as a ` normalisation ' , applying an offset to a vector so that it has mean zero .",
    "using @xmath49 allows the formulas given in the introduction to be expressed in a more geometric way .",
    "we now give more details .",
    "we see that @xmath50 we write @xmath51 for the standard inner product ( the dot product ) of @xmath3 and @xmath52 .",
    "so @xmath53 since @xmath54 where @xmath55 is the angle between @xmath3 and @xmath52 , we see that @xmath56 where @xmath55 is the angle between @xmath57 and @xmath58 .    finally , we note that @xmath59 , that @xmath60 and that @xmath61 .",
    "this section provides a proof of the following theorem :    [ thm : mld ] a maximum likelihood decoder decodes a received vector @xmath19 to the codeword @xmath36 which minimises @xmath62 , where @xmath63    before proving this theorem , we provide a geometrical interpretation for the formula  . for a non - zero vector @xmath64 ,",
    "define @xmath65 so @xmath66 is a subspace , and @xmath67 is a half - subspace , of @xmath45 . for a vector @xmath64 we write @xmath68 for the ray from the origin in the direction of @xmath19 , so @xmath69    [ lem : mld ] let @xmath19 and @xmath36 be vectors in @xmath45 .",
    "let @xmath70 be the euclidean distance between @xmath36 and @xmath71 .",
    "let @xmath72 be the euclidean distance between @xmath73 and @xmath74 .",
    "then @xmath75    we start by proving that @xmath76 .",
    "let @xmath77 .",
    "then @xmath78 and @xmath79 .",
    "so @xmath80 .",
    "let @xmath81 .",
    "then @xmath82 since @xmath83 and since @xmath8 is orthogonal to @xmath44 .",
    "since @xmath84 , we see that @xmath85 .",
    "hence @xmath76 .",
    "we now prove that @xmath86 .",
    "there are two cases , depending on whether or not the closest point @xmath87 to @xmath73 on the line generated by @xmath88 lies in the ray @xmath74 : see figure  [ fig : dist_to_ray ] .",
    "the first case , when @xmath87 lies on the ray , happens if and only if @xmath89 .",
    "this happens exactly when @xmath90 , by  . in this case , @xmath91 where @xmath55 is the angle between @xmath73 and @xmath88 , by   and  .",
    "in the second case , when @xmath92 , the distance between @xmath73 and the ray @xmath74 is given by the distance from @xmath73 to the origin .",
    "so @xmath93 by  .",
    "this establishes the lemma .",
    "since the components of @xmath27 are picked independently according to a normal distribution with mean @xmath17 and standard deviation @xmath26 , each value of @xmath27 is associated with the value of the corresponding normal probability density function @xmath94 , where @xmath95    for vectors @xmath19 and @xmath36 , define @xmath96 this is the likelihood of @xmath36 given @xmath19 when @xmath21 and @xmath22 are fixed , since @xmath97 in this case .    in maximum likelihood decoding",
    ", we decode a received vector @xmath98 as @xmath37 , where @xmath36 is the codeword that maximises @xmath99 where @xmath100 and @xmath101 .",
    "the logarithm function is strictly increasing on the positive real numbers , and @xmath102 is a positive function .",
    "so equivalently we want to find @xmath37 that maximises @xmath103 . but @xmath104 since @xmath105 is a constant ( in other words , independent of @xmath36 and @xmath19 ) , and since @xmath106 is a positive constant , we see that a maximum likelihood decoder finds a codeword @xmath36 that _ minimises _ @xmath107 which is the square of the euclidean distance between @xmath108 and @xmath36 .",
    "but , by lemma  [ lem : mld ] , this is exactly the same as minimising the function @xmath62 , as required .",
    "we describe techniques to reduce the amount of computation the maximum likelihood decoder needs .",
    "firstly , the value @xmath109 can be precomputed for all codewords @xmath37 . secondly , for codes such as @xmath18-constrained codes  @xcite",
    "that are preserved under permuting their cooordinates , we can significantly reduce the number of codewords we need to consider by making the following observations .",
    "the value of @xmath110 is not changed if we permute the coordinates of @xmath36 , and the value of @xmath111 is maximised when we permute the coordinates of @xmath36 to have the same order as the coordinates of @xmath19 .",
    "so we may use the ` composition code ' decomposition technique from  ( * ? ? ?",
    "* section  iv.b ) to decode more efficiently , only storing codewords that are in sorted order . finally , we observe that @xmath18-constrained codes @xmath28 have the property that whenever @xmath32 then its _ complement _ @xmath112 also lies in @xmath28 .",
    "we note that @xmath113 and so we find that @xmath114 and @xmath115 for any non - constant received word @xmath19 .",
    "so for codes which are closed under taking complements , we only need to store one codeword from each pair @xmath116 . if we do this , we search for a codeword @xmath36 that minimises @xmath117",
    "; we then decode to the complement of @xmath36 when @xmath118 and decode to @xmath36 otherwise .",
    "this technique can be combined with the composition code technique above .",
    "the technique can also be used with the decoder in  @xcite : here we find a codeword maximising @xmath119 , and decode to this codeword if @xmath120 or to its complement otherwise .",
    "for codewords @xmath121 , we define a ( squared ) distance measure @xmath122 by @xmath123 note that @xmath124 .",
    "also note that @xmath122 depends only on @xmath57 and @xmath58 , by   and .",
    "finally , we claim that @xmath125 to see this , we may verify by routine calculation that @xmath126 a similar calculation shows that the left hand side of   is at most @xmath127 , and so the claim follows .    in this section",
    ", we will give a geometric interpretation for @xmath122 , and we relate the minimum distance of a code ( using this notion of distance ) to the error rate of a maximum likelihood decoder .",
    "we note that  @xcite defines a different distance measure ( namely the distance @xmath128 , which is not symmetrical in @xmath9 and @xmath10 ) to be used to calculate the minimum distance of a code in this context .",
    "this distance measure is natural for the decoder in  @xcite ; in section  [ sec : comparison ] we briefly compare this measure with the measure above .",
    "[ lem : ray ] let @xmath129 .",
    "then @xmath130 is the largest real number @xmath131 with the following property .",
    "let @xmath132 be the ball in @xmath44 of radius @xmath133 and centre @xmath134 ( using euclidean distance ) .",
    "let @xmath135 be the ball in @xmath44 of radius @xmath133 and centre @xmath136 .",
    "then there is no ray @xmath74 that intersects the interior of both @xmath132 and @xmath135 .     at equal distance from @xmath134 and @xmath136,width=302 ]    firstly , suppose that @xmath137 .",
    "in particular this means that @xmath138 , and so @xmath139 is a non - zero vector .",
    "the typical situation in this case is drawn in figure  [ fig : generic_min_radius ] .",
    "let @xmath87 be the subplane of @xmath44 generated by @xmath134 and @xmath136 , and let @xmath140 be the subplane of vectors orthogonal to @xmath87 .",
    "let @xmath141 be the hyperplane in @xmath44 generated by @xmath139 and @xmath140 .",
    "we have that @xmath134 and @xmath136 lie on different sides of @xmath141 . the closest point in @xmath141 to @xmath134",
    "lies in @xmath87 , and so lies on the line generated by @xmath142 ; the same is true for the closest point to @xmath136 .",
    "setting @xmath55 to be the angle between @xmath134 and @xmath142 , we find that the squared distance between @xmath141 and @xmath134 is @xmath143 so the interior of @xmath132 does not intersect @xmath141 .",
    "similarly , @xmath136 is also at distance @xmath131 from @xmath141 and so the interior of @xmath135 does not intersect @xmath141 .",
    "so the interiors of @xmath132 and @xmath135 lie on different sides of a hyperplane , and therefore no ray from the origin intersects them both , as required .",
    "we now show that the value for @xmath131 is optimal , by proving that the ray @xmath144 touches the boundaries of both @xmath132 and @xmath135 .",
    "the nearest point to @xmath134 on the line generated by @xmath139 is given by @xmath145 so @xmath144 touches @xmath132 if and only if @xmath146 .",
    "but @xmath147 so @xmath144 touches @xmath132 . the argument that @xmath144 touches @xmath135 is similar , and uses the fact that @xmath148 .",
    "this shows that our value for @xmath131 is optimal in this case .",
    "we now turn to the case when @xmath149 .",
    "see figure  [ fig : bigger_min_radius ] for a typical situation . without loss of generality , assume that @xmath150 .",
    "so @xmath151 and @xmath152 .",
    ", width=302 ]    let @xmath153 , so @xmath154 is the hyperplane in @xmath44 of all vectors that are orthogonal to @xmath3 .",
    "clearly the nearest point on @xmath141 to @xmath134 is the origin , so @xmath134 is at distance @xmath155 from @xmath141 .",
    "moreover , all points @xmath9 in the interior of @xmath132 have @xmath156 .",
    "now let @xmath9 be a point in the interior of @xmath135",
    ". then @xmath157 , where @xmath158 and so @xmath159 thus all points in the interior of @xmath135 lie on the opposite side of the hyperplane @xmath141 to the points in the interior of @xmath132 .",
    "so no ray from the origin can pass through both @xmath132 and @xmath135 , as required . finally , it is easy to see that no larger value of @xmath131 can have this property , for when @xmath160 we find that the origin is in the interior of @xmath132 , and so all rays from the origin ( including , for example , @xmath161 ) pass through @xmath132 .",
    "[ thm : decoder_probability ] let @xmath162 be a finite set of non - constant codewords . define the minimum distance @xmath131 of @xmath28 by @xmath163 the word error probability of a maximum likelihood decoder is bounded above by the probability that @xmath164 , where @xmath165 is the chi - squared distribution with @xmath166 degrees of freedom .    when a codeword @xmath3 is transmitted , the decoder receives a vector @xmath167 where @xmath21 and @xmath22 are unknown , and the components of @xmath27 are normally distributed with mean @xmath17 and standard deviation @xmath26 .",
    "let @xmath168 be an orthonormal basis for @xmath45 , with @xmath169 spanning @xmath44 .",
    "we may write @xmath170 where @xmath171 and where the real numbers @xmath172 and @xmath173 are independent and normally distributed with mean @xmath17 and standard deviation @xmath26 . now @xmath174 is a chi - squared random variable with @xmath166 degrees of freedom , so @xmath175 with probability equal to the probability that @xmath164 .",
    "assume that @xmath175 .",
    "it suffices to show that our maximum likelihood decoder returns the codeword @xmath3 .",
    "note that @xmath176 , and so @xmath177 .",
    "the ray @xmath74 passes within a squared distance of @xmath178 from @xmath134 , since @xmath179 lies on this ray .",
    "so @xmath180 .",
    "let @xmath37 be such that @xmath181 .",
    "lemma  [ lem : ray ] and the definition of @xmath131 shows that @xmath74 can not intersect the interior of a ball in @xmath44 of radius @xmath131 centred at @xmath73 .",
    "hence @xmath182 .",
    "thus a maximum likelihood decoder will correctly decode to @xmath3 .",
    "simulations indicate that the decoder in  @xcite has a comparable performance with the maximum likelihood decoder when word error rate is considered .",
    "figure  [ fig : wer4 ] shows the results of a simulation for the maximum likelihood decoder when @xmath183 and @xmath184 for a range of noise levels when a @xmath16-constrained code  @xcite is used : the horizontal axis is the signal to noise ratio , defined as @xmath185 , and the vertical axis is the word error rate .",
    "each point was the result of 10,000 trials with @xmath186 and @xmath187 .",
    "figure  [ fig : wer12 ] gives a similar situation when @xmath188 . in each figure ,",
    "simulation results are plotted along with the error rate predicted by averaging the bound in theorem  [ thm : decoder_probability ] over all subcodes of size @xmath18 .",
    "these parameters are chosen for direct comparison with figure  5 in  @xcite .     and",
    "@xmath184,width=302 ]     and @xmath188,width=302 ]    figure  [ fig : distance_comparison ] is a scatter plot of two notions of distance for 10,000 random vectors when @xmath189 and @xmath190 : the distance @xmath122 defined in section  [ sec : distance ] and the distance @xmath191 defined in section  iv.b of  @xcite for the purposes of estimating word error rates .",
    "the figure shows a close to linear relationship between these two quantities for random vectors .",
    "figure  [ fig : likelihood_comparison ] is a scatter plot of two likelihood functions ( namely pearson distance and the likelihood function @xmath192 used by the maximum likelihood decoder ) for a similarly randomly generated collection of vectors .",
    "again , a close to linear relationship can be observed , which provides an explanation for the similar performance of the corresponding decoders .     against @xmath131,width=302 ]    , width=302 ]",
    "since the offset @xmath22 is arbitrary and unknown , and changes the mean of a vector by @xmath22 , it seems sensible to normalise codewords and received words to have mean @xmath17 . in other words , we consider the words @xmath193 and @xmath194 rather than @xmath36 and @xmath19 .",
    "scaling a vector of mean @xmath17 by @xmath21 does not change the mean , but scales the standard deviation by a factor of @xmath21 .",
    "so it seems sensible to scale our normalised vectors so that they have standard deviation @xmath16 : if our original vectors were non - constant , we can always find a scaling factor @xmath21 that does this .",
    "the resulting vectors , @xmath195 and @xmath196 , lie on an @xmath166-dimensional unit sphere , centred at the origin .",
    "a natural distance measure between two vectors @xmath9 and @xmath10 on this unit sphere is their squared euclidean distance , and it is not difficult to show that this is exactly @xmath197 .",
    "the ( unnormalised ) standard deviation of a constant codeword is @xmath17 , so the pearson correlation coefficient @xmath111 is not defined when @xmath36 is constant .",
    "but the forbidding of constant codewords is an artifact of the channel itself , not just the distance measure that is proposed for decoding . to see this ,",
    "suppose that @xmath198 is a codeword .",
    "let @xmath19 be a received word , and define @xmath199 .",
    "for any positive @xmath200 we have @xmath201 setting @xmath202 , @xmath203 and @xmath204 we have that @xmath205 . but @xmath206 may be taken to be arbitrarily small , and so we see @xmath19 could have been received when @xmath36 was transmitted , with an abitrarily small error vector @xmath204 . so any reasonable decoder for this channel would decode _ every _ received vector to @xmath36 , and a sensible distance measure would set the distance between @xmath36 and any other vector as @xmath17 .",
    "weber , immink and blackburn  @xcite have studied optimal pearson codes , which are the largest codes contained in @xmath207 that can be correctly decoded in the zero - error case ( when @xmath208 , and so @xmath209 ) .",
    "it would be very interesting to fully explore the interplay between the error correcting capacity of codes when @xmath210 and the rate of an optimal code .",
    "we hope that the distance between codewords that is defined in section  [ sec : distance ] will provide a tool to accomplish this .",
    "the author would like to thank alexey koloydenko for fruitful discussions on maximum likelihood estimation , and kees s. immink and jos weber for commenting on an earlier draft of the manuscript .",
    "the author would also like to acknowledge the help of two software packages that were used to conduct experiments and simulations : compass and ruler  @xcite , and mathematica  @xcite .",
    "99 roberto bez , emilio camerlenghi , alberto modelli and angelo visconti , ` introduction to flash memory ' , _ proc",
    "* 91 * ( 2003 ) , 489502 .",
    "ren grothmann , compass and ruler dynamic geometry programme , version 12.0 , http://car.rene - grothmann.de / doc_en/. kees a. schouhamer immink and jos h. weber , ` minimum pearson distance detection for multilevel channels with gain and/or offset mismatch ' , _ ieee trans .",
    "information theory _ * 60 * ( 2014 ) , 59665974 .",
    "kees a. schouhamer immink and jos h. weber , ` hybrid minimum pearson and euclidean distance detection ' , _ ieee trans . communications _ , to appear .",
    "jos h. weber , kees a. schouhamer immink and simon r. blackburn , ` pearson codes ' , preprint .",
    "anxiao ( andrew ) jiang , robert mateescu , moshe schwartz and jehoshua bruck , ` rank modulation for flash memories ' , _ ieee trans .",
    "information theory _ * 55 * ( 2009 ) , 26592673 .",
    "anxiao ( andrew ) jiang , moshe schwartz and jehoshua bruck , ` error - correcting codes for rank modulation ' , in _ proc .",
    "symposium on information theory ( isit ) _",
    "( ieee , 2008 ) , 17361740 .",
    "anxiao ( andrew ) jiang , moshe schwartz and jehoshua bruck , ` error - correcting codes for rank modulation ' , _ ieee trans .",
    "information theory _ * 56 * ( 2010 ) , 21122120 .",
    "frederic sala , kees a. schouhamer immink , and lara dolecek , ` error control schemes for modern flash memories ' , _ ieee consumer electronics magazine _ , january 2015 , 6673 .",
    "wolfram research , inc .",
    ", mathematica , version 9.0 , champaign , il ( 2012 ) ."
  ],
  "abstract_text": [
    "<S> k.a.s . immink and j.h . </S>",
    "<S> weber recently defined and studied a channel with both gain and offset mismatch , modelling the behaviour of charge - leakage in flash memory . </S>",
    "<S> they proposed a decoding measure for this channel based on minimising pearson distance ( a notion from cluster analysis ) . </S>",
    "<S> the paper derives a formula for maximum likelihood decoding for this channel , and also defines and justifies a notion of minimum distance of a code in this context . </S>"
  ]
}