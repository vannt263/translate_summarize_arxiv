{
  "article_text": [
    "shannon s source - channel separation theorem essentially states that asymptotically there is no loss from optimum by decoupling the source coding component and channel coding component in a point - to - point communication system @xcite .",
    "this separation result tremendously simplifies the concept and design of communication systems , and it is also the main reason for the division between research in source coding and channel coding .",
    "however , it is also well known that in many multi - user settings , such a separation indeed incurs certain performance loss ; see , _",
    "e.g. _ , @xcite . for this reason ,",
    "joint source - channel coding has attracted an increasing amount of attention as the communication systems become more and more complex .",
    "one of the most intriguing problems in this area is joint source - channel coding of a gaussian source on a gaussian broadcast channel with @xmath0 users under an average power constraint .",
    "it was observed by goblick @xcite that when the source bandwidth and the channel bandwidth are matched , _",
    "i.e. _ , one channel use per source sample , directly sending the source samples on the channel after a simple scaling is in fact optimal , but the separation - based scheme suffers a performance loss @xcite .",
    "however , when the source bandwidth and the channel bandwidth are not matched , such a simple scheme is no longer optimal .",
    "many researchers have considered this problem , and significant progress has been made toward finding better coding schemes based on hybrid digital and analog signaling ; see , _",
    "e.g. _ , @xcite and the references therein .    in spite of the progress on the achievability schemes , our overall understanding on this problem is still quite limited . as pointed out by caire @xcite , the key difficulty appears to be finding meaningful outer bounds .",
    "such outer bounds not only can provide a concrete basis to evaluate various achievability schemes , but also may provide insights into the structure of good or even optimal codes , and may further suggest simplification of the possibly quite complex optimal schemes in certain distortion regimes . in this regard , the result by reznic _",
    "@xcite is particularly important , where they derived a non - trivial outer bound for the achievable distortion region for the two - user system .",
    "this outer bound relies on a technique previously used in the multiple description problem by ozarow @xcite , where one additional random variable beyond those in the original problem is introduced .",
    "the bound given in @xcite is however rather complicated , and was only shown to be asymptotically tight for certain high signal to noise ratio regime .",
    "in this work , we derive an outer bound for the @xmath0-user problem using a similar technique as that used in @xcite , however , more than one additional random variable is introduced .",
    "the technique used here also bears some similarity to that used in @xcite .",
    "the outer bound has a more concise form than the one given in @xcite , but for the @xmath1 case , it can be shown that they are equivalent . this outer bound is in fact a set of outer bounds parametrized by @xmath2 non - negative variables .",
    "though one can optimize over these variables to find the tightest one , this optimization problem appears difficult .",
    "thus we take an approach similar to the one taken in @xcite , and choose some specific values for the @xmath2 variables which gives specific outer bounds . moreover , by combining these specific outer bounds with the simple achievability scheme based on source - channel separation , we provide approximate characterizations of the achievable distortion region within some universal constant multiplicative factors , independent of the signal to noise ratio and the bandwidth mismatch factor . in one of the approximations , the multiplicative factor is roughly of form @xmath3 for the distortion at the @xmath4-th user , while in the other , the factor is @xmath0 for all the distortions .",
    "thus although shannon s source - channel separation result does not hold strictly in this problem , it indeed holds in an approximate manner .",
    "in fact , this set of results is extremely flexible , and can be applied in the case with an infinite number of users but the minimum achievable distortion is bounded away from zero , for which we can conclude that the source - channel separation based approach is also within certain finite constant multiplicative factors of the optimum .",
    "in this case , these constants can be upper bounded by factors related to the disparity between the best and worse distortions , which is not influenced by the number of users being infinite .",
    "though the outer bound is derived using techniques that have some precedents in the information theory literature , the difficulty lies in determining which terms to bound . in contrast to pure source coding problems or pure channel coding problems , where we can usually meaningfully bound a linear combination of rates , in a joint source - channel coding problem the notion of rates does not exist . in @xcite ,",
    "the lower bound on one distortion is given in terms of a function of the other distortion in the two - user problem .",
    "it is clear that such a proof approach becomes unwieldy for the general @xmath0-user case . in this work ,",
    "we instead derive bounds for some quantity which at the first sight may seem even unrelated to the problem , but eventually serves as an interface between the source and channel coding components , thus replacing the role of `` rates '' in traditional shannon theory proofs .    inspired by a recent work of avestimehr , caire and tse @xcite , where source - channel separation in more general networks is considered ,",
    "we further show that our technique can be conveniently extended to general broadcast channels , and the source - channel separation based scheme is within the same multiplicative constants of the optimum as for the gaussian channel case .",
    "the rest of the paper is organized as follows .",
    "section [ sec : definition ] gives the necessary notation and reviews an important lemma useful in deriving the outer bound .",
    "the main results are presented in section [ sec : mainresult ] , and the proofs for these results are given in section [ sec : proof ] .",
    "the extension to general broadcast channels is given in section [ sec : general ] , and section [ sec : conclusion ] concludes the paper .",
    "in this section , we give a formal definition of the gaussian source broadcast problem in the context of gaussian broadcast channels ; the notation will be generalized in section [ sec : general ] when other broadcast channels are considered .",
    "let @xmath5 be a stationary and memoryless gaussian source with zero - mean and unit - variance .",
    "the vector @xmath6 will be denoted as @xmath7 .",
    "we use @xmath8 to denote the domain of reals , and @xmath9 to denote the domain of non - negative reals .",
    "the gaussian memoryless broadcast channel is given by the model @xmath10 where @xmath11 is the channel output observed by the @xmath4-th receiver , and @xmath12 is the zero - mean additive gaussian noise on the channel input @xmath13 .",
    "thus the channel is memoryless in the sense that @xmath14 is a stationary and memoryless process .",
    "the variance of @xmath12 is denoted as @xmath15 , and without loss of generality , we shall assume @xmath16 the mean squared error distortion measure is used , which is given by @xmath17",
    ". the encoder maps a source sample block of length @xmath18 into a channel input block of length @xmath19 , and each decoder maps the corresponding channel output block of length @xmath19 into a source reconstruction block of length @xmath18 .",
    "the bandwidth mismatch factor is thus defined as @xmath20 which is essentially the ( possibly fractional ) channel uses per source sample ; see fig . [",
    "fig : systemdiag ] .",
    "the channel input is subject to an average power constraint .",
    ", width=302 ]    we can make the codes in consideration more precise by introducing the following definition .    an @xmath21 gaussian source - channel broadcast code is given by an encoding function @xmath22 such that @xmath23 and @xmath0 decoding functions @xmath24 and their induced distortions @xmath25 where @xmath26 is the expectation operation .",
    "note that there are two kinds of independent randomness in the system , the first of which is by the source , and the second is by the channel noises ; the expectation operation in ( [ eqn : expectation ] ) is taken over both of them . in the definition , @xmath27 in the expression @xmath28 is understood as the length-@xmath19 vector addition .    from the above definition ,",
    "it is clear that the performance of any gaussian joint source - channel code depends only on the marginal distribution of @xmath29 , but not the joint distribution @xmath30 .",
    "this implies that physical degradedness does not differ from statistical degradedness in terms of the system performance .",
    "since the gaussian broadcast channel is always statistically degraded , we shall assume physical degradedness from here on without loss of generality .",
    "the channel noises can thus be written as @xmath31 where @xmath32 is a zero - mean gaussian random variable with variance @xmath33 , which is independent of everything else ; for convenience , we define @xmath34 , and it follows that @xmath35 and @xmath36 .",
    "[ def : distortionvector ] a distortion vector @xmath37 , where @xmath38 is achievable under power constraint @xmath39 and bandwidth mismatch factor @xmath40 , if for any @xmath41 and sufficiently large @xmath18 , there exist an integer @xmath42 and an @xmath21 gaussian source - channel broadcast code such that @xmath43    note that the constraint @xmath38 is without loss of generality , because otherwise the problem can be reduced to an alternative one with fewer users due to the assumed physical degradedness . the collection of all the achievable distortion vectors under power constraint @xmath39 and bandwidth mismatch factor @xmath40 is denoted by @xmath44 , and this is the region that we are interested in .",
    "one important result we need in this work is the following lemma , which is a slightly different version of the one given in @xcite .",
    "[ lemma : difference ] let @xmath45 be a random variable jointly distributed with the gaussian source vector @xmath7 in the alphabet @xmath46 , such that there exists a deterministic mapping @xmath47 satisfying @xmath48 let @xmath49 and @xmath50 , where @xmath51 and @xmath52 are mutually independent gaussian random variables independent of the gaussian source @xmath53 and the random variable @xmath45 , with variance @xmath54 and @xmath55 , respectively . then with @xmath56 and @xmath57 , we have    1 .   * mutual information bound * @xmath58 2 .   * bound on mutual information difference *",
    "@xmath59    the proof of this lemma is almost identical to the one given in @xcite .",
    "the only difference between the two versions is that in @xcite the random variable @xmath45 is in fact a deterministic function of @xmath7 , however it is rather straightforward to verify that this condition was never used in the proof given in @xcite ; we include the proof of this lemma in the appendix for completeness .",
    "our main results for gaussian source broadcast on gaussian broadcast channels are summarized in theorem [ theorem : maintheorem ] , corollary [ corollary : firstcorollary ] , proposition [ proposition : firstcorollary ] , corollary [ corollary : infiniteusers ] and corollary [ corollary : secondcorollary ] , the proofs of which are given in the next section ; extensions of these results to general broadcast channels are given in section [ sec : general ] .",
    "define the region in ( [ eqn : innerbound ] ) on the top of next page , which is in fact the inner bound via source - channel separation .",
    "next define the regions in ( [ eqn : firstoutbound ] ) and ( [ eqn : secondouterbound ] ) also on the top of next page , which are in fact outer bounds to the achievable distortion region .",
    "we have the the following theorem .",
    "@xmath60    [ theorem : maintheorem ] @xmath61    theorem [ theorem : maintheorem ] is stated as inner and outer bounds to the achievable distortion region , however it can be observed that the bounds have similar forms , and their difference , in terms of distortions , can be bounded by some multiplicative constants .",
    "the following corollary follows directly from theorem [ theorem : maintheorem ] , by comparing ( [ eqn : innerbound ] ) and ( [ eqn : firstoutbound ] ) .",
    "[ corollary : firstcorollary ] if @xmath62 , and if @xmath63 for @xmath64 , then @xmath65 .",
    "the condition @xmath63 in corollary [ corollary : firstcorollary ] is to ensure that the distortion vector @xmath66 satisfies the monotonicity requirement in definition [ def : distortionvector ] and ( [ eqn : innerbound ] ) .",
    "this result has the following intuitive interpretation if the condition indeed holds that @xmath67 for all @xmath64 : if a genie helps the separation - based scheme by giving each individual user half a bit information per source sample , and at the same time all the better users also receive this half a bit information for free , then the separation - based scheme is as good as the optimal scheme",
    ".    this approximation can in fact be refined , and for this purpose , the following additional definition is needed . for any @xmath68",
    ", we associate with it a _ relaxed distortion vector _ @xmath69 and a binary labeling vector @xmath70 in a recursive manner @xmath71 for @xmath72 , and we have defined @xmath73 for convenience . it is easily verified that @xmath74 for @xmath64 , and moreover @xmath75 .",
    "[ proposition : firstcorollary ] let @xmath69 be the relaxed distortion vector of @xmath76 . if @xmath62 , then @xmath77 .",
    "the notion of relaxed distortion vector essentially removes the rather artificial condition @xmath63 in corollary [ corollary : firstcorollary ] .",
    "when this condition does not hold for some @xmath4 , the relaxed distortion vector is introduced to replace @xmath66 , which in this case does not satisfy the monotonicity requirement in definition [ def : distortionvector ] and thus is not a valid choice of a distortion vector ; nevertheless , in this case , the difference between the original distortion vector and its relaxed version is in fact smaller , being @xmath78 , instead of @xmath3 for @xmath79 as in the case already considered in corollary [ corollary : firstcorollary ] .",
    "proposition [ proposition : firstcorollary ] can be used in the situation where there are an infinite number of users such as in a fading channel .",
    "let the set of users indexed by @xmath80 and their associated distortions be denoted as @xmath81 , since there may be an uncountably infinite many of them .",
    "if we apply the construction given in ( [ eqn : enhanceddistortion ] ) , with @xmath82 replaced by @xmath83 , @xmath84 taking the role of @xmath85 and @xmath86 taking the role of @xmath87 , then the following lemma is straightforward by observing that @xmath88 and @xmath89 .",
    "[ lemma : maximumgroups ] the sequence @xmath83 specified by ( [ eqn : enhanceddistortion ] ) satisfies @xmath90 .    it is clear that the maximum multiplicative constant is less than @xmath91 in the statement of proposition [ proposition : firstcorollary ] . if there exists a lower bound on the achievable distortion for the best user , denoted as @xmath92 , which is strictly positive , _",
    "i.e. _ , @xmath93 , then since @xmath94 , the multiplicative factor can be bounded as @xmath95 thus even when the number of users is infinite , as long as the lower bound @xmath92 is bounded away from zero , the multiplicative factors are in fact finite .",
    "more formally , we have the following corollary , however a more rigorous approach is to derive the outer bounds for this case and show the result holds .",
    "this can indeed be done either along the line of the proof given in section [ sec : proof ] with careful replacement of summation by integral , or more straightforwardly along the line of proof given in section [ sec : general ] . ] .",
    "[ corollary : infiniteusers ] for an infinite number of users indexed by @xmath80 with @xmath96 , let @xmath97 be the relaxed distortion vector of @xmath98 . if @xmath99 , then @xmath100 , and furthermore , @xmath101 .",
    "the next corollary gives another version of the approximation , essentially stating that for any achievable distortion vector , its @xmath0-fold multiple is achievable using the separation approach . in terms of the genie - aided interpretation",
    ", the genie only needs to provide @xmath102 bits common information to the users in the separation - based scheme , then it is as good as the optimal scheme .",
    "more formally , the following corollary follows directly from theorem [ theorem : maintheorem ] .",
    "[ corollary : secondcorollary ] if @xmath62 , then @xmath103 , where @xmath104 .",
    "theorem [ theorem : maintheorem ] , proposition [ proposition : firstcorollary ] and the corollaries provide approximate characterizations of the achievable distortion region , essentially stating that the loss of the source - channel separation approach is bounded by constants .",
    "the bound on the gap is chosen to be ( largely ) independent of a specific distortion tuple on the boundary of @xmath44 , but it will become clear in the next section that such a choice is not necessary .",
    "the proofs of theorem [ theorem : maintheorem ] and proposition [ proposition : firstcorollary ] rely heavily on the following outer bound , which is one of the main contributions of this work .    [",
    "theorem : outerbound ] let @xmath105 be any @xmath2 non - negative real values , and @xmath106 .",
    "if @xmath62 , then @xmath107^{\\frac{1}{b}}\\leq p+n_1.\\label{eqn : outerbound}\\end{aligned}\\ ] ]    with the above theorem in mind , let us denote the set of distortion vectors satisfying ( [ eqn : outerbound ] ) for a specific choice of @xmath105 as @xmath108 , _",
    "i.e. _ , ( [ eqn : defineoutbounds ] ) as given on the top of next page .",
    "@xmath109^{\\frac{1}{b}}\\leq p+n_1,\\right.\\nonumber\\\\ & \\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\left.\\phantom{\\sum_{k=1}^k \\delta n_k \\left[\\frac{(1+\\tau_k)\\prod_{j=2}^k(d_j+\\tau_{j-1})}{\\prod_{j=1}^k ( d_j+\\tau_j)}\\right]^{\\frac{1}{b } } } 1\\geq d_1\\geq d_2 \\geq\\ldots\\geq d_k\\geq 0\\right\\}.\\label{eqn : defineoutbounds}\\end{aligned}\\ ] ]    thus theorem [ theorem : outerbound ] essentially states that @xmath110 for any valid choice of @xmath111 .",
    "the following corollary is then immediate .",
    "[ corollary : outerbound ] @xmath112    to illustrate corollary [ corollary : outerbound ] , let us consider the case @xmath1 for which the bound involves only one parameter @xmath113 .",
    "for this case , it can be shown through some algebra that this outer bound is equivalent to the one given in @xcite . in fig .",
    "[ fig : outerbound ] , we illustrate the outer bounds for several specific choices of @xmath114 . for comparison , the achievable region using the proposed scheme in @xcite",
    "is also given .",
    "note that although the inner bound given by this scheme is extremely close to the outer bound , it appears they do not match exactly .",
    "it is worth emphasizing that we view this outer bound differently from the authors in @xcite : for each possible value of @xmath113 we view the condition ( [ eqn : outerbound ] ) as specifying an outer bound for the distortion region @xmath115 ; in contrast , the authors of @xcite viewed the distortion @xmath116 as being lower bounded by a function of @xmath85 , and the parameter @xmath113 was viewed as an additional variable that is subject to optimization , and consequently only the optimal choice of @xmath113 value was of interest .",
    "these two views are complementary , however the former view appears to be more natural for the @xmath0-user problem , which also readily leads to the approximate characterizations . in certain cases , the second view may be more convenient , such as when we are given a specific achievable distortion tuple , and wish to determine how much further improvement is possible or impossible .    for @xmath1 , the properties of the outer bound were thoroughly investigated in @xcite . in certain regimes ,",
    "this outer bound in fact degenerates for the case of bandwidth compression , and it is looser than the trivial outer bound with each user being optimal in the point - to - point setting .",
    "due to its non - linear form , the optimization of this bound is rather difficult , and it also appears difficult to determine whether it is always looser than the trivial outer bound in all distortion regimes with bandwidth compression .",
    "nevertheless , it is clear that this outer bound always holds whether the bandwidth is expanded or compressed , and the approximate characterizations are valid in either case .",
    "a different and simpler approximate characterization may in fact be more useful for the bandwidth compression case .",
    "consider a different genie who helps the separation - based scheme by giving each individual user half a bit information _ per channel use _ , and at the same time all the better users also receive this half a bit information for free , then the genie - aided separation - based scheme is as good as the optimal scheme , and moreover each user can in fact achieve the optimal point - to - point distortion . to see this approximation holds , first observe that the following broadcast channel rates are achievable by using the gaussian broadcast channel capacity region characterization @xcite ( it is particularly easy by using the alternative gaussian broadcast channel capacity characterization given in ( [ eqn : capacity ] ) ) @xmath117 the @xmath4-th user can thus utilize a total rate of @xmath118 per channel use on this broadcast channel ; together with the genie - provided rates , it will have at least a total rate of @xmath119 per channel use , _",
    "i.e. _ , the optimal point to point channel rate .",
    "since the gaussian source is successively refinable @xcite , it is now clear that each user can achieve the optimal point - to - point distortion with this genie - aided separation - based scheme .",
    "note that though this approximation is good for bandwidth compression , it can be rather loose when the bandwidth expansion factor is large .",
    "in contrast , the approximations given in theorem [ theorem : maintheorem ] and proposition [ proposition : firstcorollary ] are independent of the bandwidth mismatch factor ( the genie provides information in terms of _ per source sample _ ) ; another difference is that the approximations given in theorem [ theorem : maintheorem ] and proposition [ proposition : firstcorollary ] rely on the new outer bound , instead of the simple point - to - point distortion outer bound .",
    "it is clear from the above discussion that the outer bound in theorem [ theorem : maintheorem ] may be further improved by taking its intersection with the trivial point - to - point outer bound . in the remainder of this paper , we do not pursue such possible improvements , but instead focus on the proofs for the results stated in theorem [ theorem : maintheorem ] and proposition [ proposition : firstcorollary ] .",
    "the proofs of the main results for gaussian source broadcast on gaussian broadcast channels are given in this section .",
    "we start by establishing a simple inner bound for the distortion region @xmath44 based on source - channel separation , and then focus on deriving an outer bound , or more precisely a set of outer bounds .",
    "the approximate characterizations are then rather straightforward by combining these two bounds . from here on , we shall use natural logarithm for concreteness , though choosing logarithm of a different base does not make any essential difference .",
    "the source - channel separation based coding scheme we consider is extremely simple , which is the combination of a gaussian successive refinement source code and a gaussian broadcast channel code ; this scheme was thoroughly investigated in @xcite , and a solution for the optimal power allocation was given to minimize the expected end - user distortion . since gaussian broadcast channel is degraded , a better user can always decode completely the messages sent to the worse users , and thus a successive refinement source code is a perfect match for this channel .",
    "note that such a source - channel separation approach is not optimal in general for this joint source - channel coding problem ; see for example @xcite .",
    "the gaussian broadcast channel capacity region is well known @xcite , which is usually given in a parametric form in terms of the power allocation . in this work , we will use an alternative representation , which first appeared in @xcite and was instrumental for deriving the optimal power allocation solution in @xcite .",
    "the gaussian broadcast channel capacity region ( per channel use ) can be written in the form in ( [ eqn : capacity ] ) as given on the top of next page .",
    "@xmath120    the rate @xmath121 is the individual message rate intended only to the @xmath4-th user , however due to the degradedness , all the better users can also decode this message . since the gaussian source is successively refinable @xcite , by combining an optimal gaussian successive refinement source code with a gaussian broadcast code that ( asymptotically ) achieves ( [ eqn : capacity ] )",
    ", we have the following theorem .",
    "[ theorem : innerbound ]",
    "@xmath122    we wish to show that any @xmath123 is indeed achievable . using the separation scheme ,",
    "we only need to show the channel rates @xmath124 specified by @xmath125 are achievable on this gaussian broadcast channel .",
    "the non - negative vector @xmath124 is uniquely determined by @xmath76 , and it is straightforwardly seen that it indeed satisfies the inequality in ( [ eqn : capacity ] ) .",
    "the proof is thus complete .",
    "next we derive a set of conditions that any achievable distortion vector @xmath76 has to satisfy , _",
    "i.e. _ , theorem [ theorem : outerbound ] .",
    "let us first introduce a set of auxiliary random variables , defined as @xmath126 where @xmath127 s are zero gaussian random variables , with variance @xmath128 , and furthermore @xmath129 where @xmath130 is a zero - mean gaussian random variable , independent of everything else , with variance @xmath131 . for convenience ,",
    "we define @xmath132 , which implies @xmath133 ; furthermore , define @xmath134 , _",
    "i.e. _ , being a constant .",
    "this technique of introducing auxiliary random variables beyond those in the original problem was previously used in @xcite to derive outer bounds , and specifically in @xcite more than one random variable was introduced , whereas in @xcite only one was introduced .    for any encoding and decoding functions ,",
    "we consider a quantity which bears some similarity to the expression for the gaussian broadcast channel capacity ( [ eqn : capacity ] ) , and we denote this quantity as @xmath135 due to its sum exponential form @xmath136.\\end{aligned}\\ ] ] the subscript @xmath137 makes it clear that this quantity depends on the specific encoding and decoding functions .",
    "next we shall derive universal upper and lower bounds for this quantity regardless the specific choice of functions @xmath137 , which eventually yield an outer bound for @xmath44 .",
    "let @xmath137 be any encoding and decoding functions that ( asymptotically ) achieve the distortions @xmath76 .",
    "we first derive a lower bound for @xmath135 . observe that for @xmath138 , @xmath139 where the equality is due to the markov string @xmath140 , and the inequality is by lemma [ lemma : difference ] .",
    "moreover , also by lemma [ lemma : difference ] , we have @xmath141 it follows that @xmath142 summarizing the above bounds , we have @xmath143.\\end{aligned}\\ ] ]    next we turn to upper - bounding @xmath135 , and first write the following .",
    "@xmath144\\nonumber\\\\ & = \\frac{2}{n}\\sum_{j=1}^k \\left[h(y^n_j|u^m_{j-1})-h(y^n_j|u^m_j)\\right]\\nonumber\\\\ & = \\frac{2}{n}\\sum_{j=1}^k h(y^n_j|u^m_{j-1})-\\frac{2}{n}\\sum_{j=1}^k h(y^n_j|u^m_j).\\end{aligned}\\ ] ] applying the entropy power inequality @xcite for @xmath145 , we have @xmath146\\nonumber\\\\ & \\geq \\exp\\left[\\frac{2}{n}h(y^n_{j+1}|u^m_j)\\right]+\\exp\\left[\\log(2\\pi e\\delta n_j)\\right]\\nonumber\\\\ & = \\exp\\left[\\frac{2}{n}h(y^n_{j+1}|u^m_j)\\right]+2 \\pi e\\delta n_j .",
    "\\label{eqn : applyentropypower}\\end{aligned}\\ ] ] for @xmath147 ,",
    "it is clear that @xmath148=\\exp\\left[\\frac{2}{n}h(y^n_k|s^m)\\right]\\nonumber\\\\ & \\qquad\\qquad\\qquad\\qquad\\qquad= 2 \\pi en_k=2 \\pi e \\delta n_k.\\end{aligned}\\ ] ] by defining @xmath149\\triangleq 0 $ ] , it now follows that @xmath150\\nonumber\\\\ & \\leq \\sum_{k=1}^k \\delta n_k \\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^k h(y^n_j|u^m_{j-1})\\right]}{\\prod_{j=1}^k\\left[\\exp(\\frac{2}{n}h(y^n_{j+1}|u^m_j))+2 \\pi e\\delta n_j\\right]}.\\end{aligned}\\ ] ] we bound this summation , by considering the summands in the reversed order , _",
    "i.e. _ , @xmath151 . starting with the summands when @xmath152 and @xmath153 , we have ( [ eqn : firststep ] ) as given on the top of next page    @xmath154}{\\prod_{j=1}^{k-1}\\left[\\exp(\\frac{2}{n}h(y^n_{j+1}|u^m_j))+2 \\pi e\\delta n_j\\right]}+\\delta n_{k } \\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^{k } h(y^n_j|u^m_{j-1})\\right]}{\\prod_{j=1}^{k}\\left[\\exp(\\frac{2}{n}h(y^n_{j+1}|u^m_j))+2 \\pi e\\delta n_j\\right]}\\nonumber\\\\ & = \\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^{k-1 } h(y^n_j|u^m_{j-1})\\right]}{\\prod_{j=1}^{k-1}\\left[\\exp(\\frac{2}{n}h(y^n_{j+1}|u^m_j))+2 \\pi",
    "e\\delta n_j\\right]}\\left[\\delta n_{k-1}+\\delta n_{k } \\frac{\\exp\\left[\\frac{2}{n}h(y^n_k|u^m_{k-1})\\right]}{2 \\pi e\\delta n_k}\\right]\\nonumber\\\\ & = \\frac{1}{2 \\pi e}\\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^{k-1 } h(y^n_j|u^m_{j-1})\\right]}{\\pi_{j=1}^{k-2}\\left[\\exp(\\frac{2}{n}h(y^n_{j+1}|u^m_j))+2 \\pi e\\delta n_j\\right]}.\\label{eqn : firststep}\\end{aligned}\\ ] ]    continuing this line of reduction , we finally arrive at ( [ eqm : upperbounde ] ) when @xmath155    @xmath156}{\\exp\\left[\\frac{2}{n}h(y^n_{2}|u^m_1))\\right]+2 \\pi e\\delta",
    "n_1}+\\frac{1}{2 \\pi e}\\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^{2 } h(y^n_j|u^m_{j-1})\\right]}{\\left[\\exp(\\frac{2}{n}h(y^n_{2}|u^m_1))+2 \\pi",
    "e\\delta n_1\\right]}\\nonumber\\\\ & = \\frac{\\exp\\left[\\frac{2}{n } h(y^n_1)\\right]}{\\exp\\left[\\frac{2}{n}h(y^n_{2}|u^m_1))\\right]+2 \\pi e\\delta n_1}\\left[\\delta n_1+\\frac{\\exp \\left[\\frac{2}{n}h(y^n_2|u^m_1)\\right]}{2\\pi e}\\right]\\nonumber\\\\ & = \\frac{\\exp\\left[\\frac{2}{n } h(y^n_1)\\right]}{2\\pi e}\\leq p+n_1,\\label{eqm : upperbounde}\\end{aligned}\\ ] ]    where the last inequality is by the concavity of the @xmath157 function and the given power constraint .    combining ( [ eqn : lowerbounde ] ) and ( [ eqm : upperbounde ] ) , it is clear that for any encoding and decoding functions @xmath137 @xmath158,\\end{aligned}\\ ] ] which completes the proof .",
    "the meaning of the newly introduced random variable @xmath159 can be roughly understood as the message meant for the @xmath4-th user . under this interpretation",
    ", the term @xmath160 in the quantity @xmath135 essentially represents the individual rate intended for the @xmath4-th user in the gaussian broadcast channel ; this informal understanding provides the rationale for bounding @xmath135 .",
    "this interpretation is nevertheless not completely accurate , and thus the outer bound is likely to be not tight in general , but suffices to provide approximate characterizations .",
    "now we are ready to prove theorem [ theorem : maintheorem ] and proposition [ proposition : firstcorollary ] .",
    "the first inclusion @xmath161 in theorem [ theorem : maintheorem ] is simply theorem [ theorem : innerbound ] , and thus we focus on the other inclusion @xmath162 , for which we prove @xmath163 and @xmath164 separately . from theorem [ theorem :",
    "outerbound ] , it is clear that if @xmath62 , then ( [ eqn : outerbound ] ) holds with any @xmath165 , and thus ( [ eqn : outerbound ] ) holds when we choose @xmath166 for @xmath64 .",
    "it follows that the following condition has to be satisfied by any achievable distortion vector @xmath167^{\\frac{1}{b}}\\leq p+n_1.\\end{aligned}\\ ] ] however , notice that @xmath168^{\\frac{1}{b}}\\nonumber\\\\ & \\qquad\\geq \\sum_{k=1}^k \\delta n_k \\left[\\frac{\\prod_{j=2}^kd_{j-1}}{\\prod_{j=1}^k 2d_j}\\right]^{\\frac{1}{b}}=\\sum_{k=1}^k \\delta n_k ( 2^kd_k)^{-\\frac{1}{b}}.\\end{aligned}\\ ] ] it now follows straightforwardly that any achievable distortion vector has to satisfy @xmath169 and @xmath163 is proved .    to prove @xmath164 , note again that any achievable distortion vector has to satisfy theorem [ theorem : outerbound ] , and because of the similarity between the forms given in ( [ eqn : secondouterbound ] ) and ( [ eqn : outerbound ] ) , we only need to prove @xmath170 for some specific choice of @xmath171 .",
    "we first consider the case that @xmath172 ; the case that @xmath173 needs to be treated in a slightly different manner , as we shall discuss later .",
    "we take an induction approach , for which the following auxiliary quantities are needed @xmath174 we claim that there exist @xmath171 such that ( [ eqn : kfactor ] ) holds with equality for @xmath64 , and holds for @xmath153 with equality or inequality ; moreover with these @xmath128 s we have @xmath175 .",
    "first consider the case @xmath155 , since the function @xmath176 is monotonically decreasing and continuous in the range @xmath177 $ ] , as long as @xmath178 there exists a unique solution of @xmath113 such that ( [ eqn : kfactor ] ) holds with equality .",
    "this is indeed true for @xmath172 , which gives @xmath179 it follows that @xmath180 and thus our claim holds for @xmath155 .",
    "next suppose the claim is true for @xmath181 and we prove it is also true @xmath182 , for which we wish to find @xmath183 such that @xmath184 where the last equality is by the supposition that the claim holds true for @xmath185 .",
    "again by the monotonicity and continuity of @xmath186 , as long as the choice of @xmath187 satisfies @xmath188 there exists a valid solution @xmath183 in @xmath189 $ ] for ( [ eqn : kstarequal ] ) to hold .",
    "the second inequality in ( [ eqn : inductioninequality ] ) is clearly true , and thus we only need to consider the first inequality .",
    "however , notice that @xmath190 and we thus conclude that there indeed exists a valid solution of @xmath183 for ( [ eqn : kstarequal ] ) , or more precisely @xmath191 to bound @xmath192 , we write @xmath193 where the last inequality is by the monotonicity of @xmath194 in @xmath195 , and the fact @xmath196 .",
    "the induction is thus complete .",
    "it only remains to check that when @xmath153 the inequality ( [ eqn : kfactor ] ) still holds , for which we have @xmath197 where the last inequality is by the fact @xmath198 .",
    "we have thus proved that @xmath164 for the case @xmath172 .",
    "next we briefly discuss the case @xmath199 , and we shall prove that ( [ eqn : kfactor ] ) holds for some @xmath171 .",
    "notice that by choosing @xmath200 sufficiently large , we can make @xmath201 because of the strict inequality given in @xmath202 , and the fact that the left - hand - side of ( [ eqn : lhsrhs ] ) goes to @xmath203 when we send @xmath200 to infinity .",
    "we have also @xmath204 , and thus there exist @xmath205 such that @xmath206 holds with equality for @xmath207 and with either equality or inequality for @xmath153 , by applying the result for the previously discussed case in a system with @xmath208 users .",
    "since we can choose @xmath200 sufficiently large , it is clear that indeed this set of @xmath128 s makes ( [ eqn : kfactor ] ) hold for @xmath209 .",
    "this completes the proof for @xmath164 .    to prove proposition [ proposition : firstcorollary ]",
    ", we need to choose different values for @xmath210 .",
    "essentially , when the condition @xmath211 is not satisfied for certain @xmath4 , we will choose to ignore the contribution of @xmath212 in the outer bound of theorem [ theorem : outerbound ] by taking an appropriate value of @xmath213 .",
    "for convenience , define the set @xmath214 , where @xmath215 is the labeling function given before proposition [ proposition : firstcorollary ] ; denote the member of @xmath216 in an increasing order as @xmath217 , where @xmath218 is the cardinality of the set @xmath216 .",
    "the value of @xmath128 s are set by the following recursive formula @xmath219 where we have defined @xmath220 for convenience .",
    "note that @xmath221 for @xmath222 .",
    "it follows from theorem [ theorem : outerbound ] that this achievable distortion vector has to satisfy ( [ eqn : conditions ] ) on the top of next page ,    @xmath223^{\\frac{1}{b}}\\nonumber\\\\ & \\qquad\\qquad\\qquad = n_1-n_{k_1}+\\sum_{i=1}^{|\\mathcal{b}| } ( n_{k_i}-n_{k_{i+1 } } ) \\left[\\frac{(1+d_{k_i})\\prod_{j=2}^{i}(d_{k_j}+d_{k_{j-1}})}{\\prod_{j=1}^{i } ( d_{k_j}+d_{k_j})}\\right]^{\\frac{1}{b}}\\leq p+n_1,\\label{eqn : conditions}\\end{aligned}\\ ] ]    where for convenience we define @xmath224 ; to see the equality holds , note that the terms for @xmath225 are combined with the terms of @xmath226 , because this choice of @xmath210 cancels out some of terms in the numerator and the denominator .",
    "this implies that the distortion vector has to satisfy @xmath227 where the last two equalities are by the definition of @xmath228 .",
    "the proof can now be completed by applying theorem [ theorem : innerbound ] .",
    "in this section , we show that the results for sending gaussian sources on gaussian broadcast channels can be conveniently extended to general broadcast channels , which was inspired by a recent work by avestimehr , caire and tse @xcite .    the broadcast channel is now given by an arbitrary conditional distribution @xmath229 , in the alphabets @xmath230 .",
    "for brevity , we omit repeating the definition of the codes here . to distinguish from the gaussian channel case , we denote the achievable distortion region as @xmath231 , with a bandwidth mismatch factor @xmath40 . for the separation - based scheme",
    ", we shall consider combining successive refinement source codes with broadcast codes with degraded message set @xcite .",
    "particularly , for an arbitrary permutation @xmath232 , the degraded message set requirement implies that there are a total of @xmath0 independent messages @xmath233 , such that the user @xmath234 should decode the messages @xmath235 . for an arbitrary permutation @xmath236 ,",
    "let us denote the achievable distortion by the separation - based approach of combining successive refinement source code with the broadcast code with degraded message set as @xmath237 , and the overall achievable distortion region using this separation - based approach is given by @xmath238 clearly the convex closure of the above region is also achievable , however such generality is not required .",
    "it is worth noting that since the characterization of the broadcast channel capacity region with degraded message set is still an open problem for @xmath239 , we do not have a characterization for the region @xmath240 .",
    "however , if the broadcast channel is degraded , then only one permutation needs to be considered ; moreover , if the capacity region of the broadcast channel ( with degraded message set or it is a degraded broadcast channel ) is known , such as for the gaussian broadcast channel case , the region @xmath240 can then be completely characterized .",
    "now we present the counterpart of corollary [ corollary : firstcorollary ] , proposition [ proposition : firstcorollary ] , corollary [ corollary : infiniteusers ] and corollary [ corollary : secondcorollary ] for general broadcast channels .",
    "[ corollary : zerocorollaryprime ] if @xmath241 , and if @xmath63 for @xmath64 , then @xmath242 .",
    "[ proposition : firstcorollaryprime ] let @xmath69 be the relaxed distortion vector of @xmath76 as defined in ( [ eqn : enhanceddistortion ] ) . if @xmath243 , then @xmath244 .    for",
    "an infinite number of users indexed by @xmath80 with @xmath245 , let @xmath97 be the relaxed distortion vector of @xmath98 as defined in ( [ eqn : enhanceddistortion ] ) . if @xmath246 , then @xmath247 , and furthermore , @xmath101 .",
    "[ corollary : firstcorollaryprime ]    [ corollary : secondcorollaryprime ] if @xmath241 , then @xmath248 .",
    "we only prove corollary [ corollary : secondcorollaryprime ] here , since the proofs of corollary [ corollary : zerocorollaryprime ] , proposition [ proposition : firstcorollaryprime ] and corollary [ corollary : firstcorollaryprime ] are quite similar .",
    "assume a distortion vector @xmath76 is indeed achievable with certain joint source - channel coding scheme .",
    "let us view the induced random mapping from @xmath249 to @xmath250 , @xmath251 , by this joint source - channel code as a super - broadcast - channel ; without loss of generality , let us assume @xmath252 .",
    "we pick up the story from ( [ eqn : difference ] ) and ( [ eqn : firstone ] ) , and claim that there exists a degraded message set broadcast code on the super - broadcast - channel with asymptotic rate per each length-@xmath18 block as follows @xmath253    it is not difficult to see that the distribution @xmath254 can be used to construct a well - known super - position code with the above rates @xcite by ( [ eqn : difference ] ) and ( [ eqn : firstone ] ) .",
    "this code needs to span over @xmath255 blocks , and note that the induced super - broadcast - channel is block - wise memoryless .",
    "we only need to confirm that receiver @xmath4 can decode all the messages up to the @xmath4-th layer by successive decoding .",
    "observe that since @xmath256 indeed receiver @xmath4 can decoder the first layer code , and thus recover the codewords based on @xmath257 .",
    "the above inequality essentially shows that the channel to @xmath258 is more powerful than that to @xmath259 , with the given channel input distribution , although the broadcast channel itself is not necessarily degraded . for the @xmath260-th layer",
    "where @xmath261 , we have @xmath262 because of the monotonicity of the function @xmath263 when @xmath264 , and the fact @xmath265 .",
    "thus our claim is indeed true .    using this set of degraded message set broadcast channel codes , we can achieve ( or more precisely , approach arbitrarily close to ) the following distortion @xmath228 for any @xmath165 , and @xmath266 , @xmath267 however , in the proof of theorem [ theorem : maintheorem ] , we have already showed that there exist @xmath268 s such that ( [ eqn : kfactor ] ) holds , _",
    "i.e. _ , @xmath269 the proof is thus complete .",
    "we derived a new outer bound to the achievable distortion region for the joint source - channel coding problem of sending a gaussian source on gaussian broadcast channels with bandwidth mismatch .",
    "when combined with a simple separation - based achievability result , this new bound leads to approximate characterizations of the achievable distortion region within some universal constant multiplicative factors .",
    "these results are further extended to the case of gaussian source broadcast on general broadcast channels .",
    "the outer bound was not fully optimized , which seems to be a difficult problem by itself .",
    "it may be beneficial to investigate the outer bound more thoroughly when more powerful achievability schemes become available . in the current work ,",
    "we only considered the separation - based scheme that yields approximate characterizations .",
    "the technique used in this work can be applied to the problem of multi - source broadcast on more complex communication networks under certain conditions .",
    "we believe that similar results hold for many classes of suitably well - behaved networks . in a follow - up work to this paper , we have shown approximate separation for a class of such networks along with other results on source - channel separation @xcite .",
    "the outer bounding technique of introducing auxiliary random variables used in this work is inspired by those used in @xcite .",
    "we believe this technique is also promising for other multi - user information theoretic problems .",
    "the role of the auxiliary random variable introduced in @xcite was not quite well understood or interpreted previously , and may even appear mysterious to many researchers less familiar with the specific problems being treated .",
    "the current work ( see also @xcite ) has made the meaning of the introduced random variables explicit .",
    "more specifically , they are introduced to either substitute the messages in the channel coding problem , or to substitute the source reconstructions in the source coding problem . by this substitution ,",
    "the quantities representing rates are replaced by the corresponding information quantities . with the interpretation made clear in a general manner",
    ", it is our hope that this technique can inspire other meaningful results in the future .",
    "[ appendix : lemmadifference ]    define @xmath270 and @xmath271 , and thus @xmath272 and @xmath273 . to prove the first statement ,",
    "we consider the following chain of inequalities @xmath274\\\\ & \\stackrel{(c)}{\\geq } mh(u')\\\\ & \\qquad-\\sum_{i=1}^m\\frac{1}{2}\\log\\left\\{(2\\pi e){\\mbox{${\\mathbb e}$ } } [ ( s(i)+z'(i)-\\hat{s}(i))^2 ] \\right\\}\\\\ & = mh(u')-\\sum_{i=1}^m\\frac{1}{2}\\log\\left[(2\\pi e)({\\mbox{${\\mathbb e}$ } } d(s(i),\\hat{s}(i))+\\tau ' ) \\right],\\end{aligned}\\ ] ] where @xmath275 is the reconstruction with @xmath45 , and its @xmath276-th position is denoted as @xmath277 .",
    "the inequality ( a ) is because conditioning reduces entropy , ( b ) is because of the chain rule for differential entropy and the fact that conditioning reduces entropy , and ( c ) is because gaussian distribution maximizes the differential entropy for a given second moment .",
    "since @xmath157 is a concave function , we have @xmath278\\nonumber\\\\ & \\qquad\\leq \\frac{m}{2}\\log\\left[2\\pi e \\left({\\mbox{${\\mathbb e}$ } } d(s^n,\\hat{s}^n)+\\tau'\\right)\\right].\\end{aligned}\\ ] ] it follows @xmath279\\\\ & \\geq mh(u')-\\frac{m}{2}\\log\\left[2\\pi e(d+\\tau')\\right]\\\\ & = \\frac{m}{2}\\log\\frac{1+\\tau'}{d+\\tau'},\\end{aligned}\\ ] ] which is the first claim in the lemma .    to prove the second claim , we write the following @xmath280 for the latter two terms , we have @xmath281 where ( a ) is because @xmath282 is independent of @xmath283 and @xmath45 ; ( b ) is by the definition of @xmath284 .",
    "continuing the chain of inequalities , we have @xmath285}\\\\ & = \\sum_{i=1}^m i\\big{(}v'(i);s(i)-\\hat{s}(i)+v(i)+v'(i)\\big{)}\\\\ & \\stackrel{(d)}{\\geq}\\sum_{i=1}^m \\frac{1}{2}\\log \\frac{{\\mbox{${\\mathbb e}$ } } d(s(i),\\hat{s}(i))+\\tau'}{{\\mbox{${\\mathbb e}$ } } d(s(i),\\hat{s}(i))+\\tau}\\\\ & \\stackrel{(e)}{\\geq } \\frac{m}{2}\\log \\frac{d+\\tau'}{d+\\tau},\\end{aligned}\\ ] ] where ( a ) is because @xmath52 is independent of @xmath45 ; ( b ) is because conditioning reduces entropy ; ( c ) is by applying the chain rule , and the facts that @xmath282 is an i.i.d . sequence and conditioning reduces entropy ;",
    "( d ) is by applying the mutual information game result that gaussian noise is the worst additive noise under a variance constraint @xcite ( pg .",
    "1 ) , and taking @xmath286 as channel input ; finally ( e ) is due to the convexity and monotonicity of @xmath287 in @xmath288 when @xmath289 . this completes the proof for the second claim .",
    "the authors would like to thank david tse for the stimulating discussions at several occasions as well as his insightful comments .",
    "the authors are also grateful to the anonymous reviewers for their comments .",
    "u.  mittal and n.  phamdo , `` hybrid digital - analog ( hda ) joint source - channel codes for broadcasting and robust communications , '' _ ieee transactions on information theory _ , vol .",
    "48 , no .  5 , pp .",
    "10821102 , may 2002 .",
    "m.  skoglund , n.  phamdo , and f.  alajaji , `` hybrid digital - analog source - channel coding for bandwidth compression / expansion , '' _ ieee transactions on information theory _ , vol .",
    "52 , no .  8 , pp . 37573763 , aug .",
    "2006 .                    c. tian , a. steiner , s. shamai , and s. diggavi , `` successive refinement via broadcast : optimizing expected distortion of a gaussian source over a gaussian fading channel , '' , vol .",
    "54 , no . 7 , pp .",
    "29032918 , jul .",
    "2008 .",
    "d.  n.  c. tse , `` optimal power allocation over parallel gaussian broadcast channels , '' in ; available at http://www.eecs.berkeley.edu/pubs/techrpts/1999/3578.html.[http://www.eecs.berkeley.edu/pubs/techrpts/1999/3578.html ]        c. tian , j. chen , s. diggavi and s. shamai , `` optimality and approximate optimality of source - channel separation in networks , '' , austin , tx , usa , jun .",
    "2010 , pp . 495499 .",
    "see also http://arxiv.org/abs/1004.2648    chao tian(s00 , m05 ) received the b.e .",
    "degree in electronic engineering from tsinghua university , beijing , china , in 2000 and the m.s . and",
    "d. degrees in electrical and computer engineering from cornell university , ithaca , ny in 2003 and 2005 , respectively .",
    "tian was a postdoctoral researcher at ecole polytechnique federale de lausanne ( epfl ) from 2005 to 2007 .",
    "he joined at&t labs  research , florham park , new jersey in 2007 , where he is now a senior member of technical staff .",
    "his research interests include multi - user information theory , joint source - channel coding , quantization design and analysis , as well as image / video coding and processing .",
    "suhas n. diggavi ( s93 , m99 ) received the b. tech .",
    "degree in electrical engineering from the indian institute of technology , delhi , india , and the ph.d .",
    "degree in electrical engineering from stanford university , stanford , ca , in 1998 .    after completing his ph.d . , he was a principal member technical staff in the information sciences center , at&t shannon laboratories , florham park , nj .",
    "since then he had been in the faculty of the school of computer and communication sciences , epfl , where he directed the laboratory for information and communication systems ( licos ) .",
    "he is currently a professor , in the department of electrical engineering , at the university of california , los angeles .",
    "his research interests include wireless communications networks , information theory , network data compression and network algorithms .",
    "he is a recipient of the 2006 ieee donald fink prize paper award , 2005 ieee vehicular technology conference best paper award and the okawa foundation research award .",
    "he is currently an editor for acm / ieee transactions on networking and ieee transactions on information theory .",
    "he has 8 issued patents .",
    "shlomo shamai ( shitz)(s80 , m82 , sm89 , f94 ) received the b.sc .",
    ", m.sc . , and",
    "degrees in electrical engineering from the technion ",
    "israel institute of technology , in 1975 , 1981 and 1986 respectively .    during 1975 - 1985",
    "he was with the communications research labs in the capacity of a senior research engineer .",
    "since 1986 he is with the department of electrical engineering , technion ",
    "israel institute of technology , where he is now the william fondiller professor of telecommunications .",
    "his research interests encompasses a wide spectrum of topics in information theory and statistical communications .",
    "shamai ( shitz ) is an ieee fellow , and the recipient of the 2011 claude e. shannon award .",
    "he is the recipient of the 1999 van der pol gold medal of the union radio scientifique internationale ( ursi ) , and a co - recipient of the 2000 ieee donald g. fink prize paper award , the 2003 , and the 2004 joint it / com societies paper award , the 2007 ieee information theory society paper award , the 2009 european commission fp7 , network of excellence in wireless communications ( newcom++ ) best paper award , and the 2010 thomson reuters award for international excellence in scientific research .",
    "he is he is also the recipient of 1985 alon grant for distinguished young scientists and the 2000 technion henry taub prize for excellence in research .",
    "he has served as associate editor for the shannon theory of the ieee transactions on information theory , and has also served on the board of governors of the information theory society ."
  ],
  "abstract_text": [
    "<S> we consider the joint source - channel coding problem of sending a gaussian source on a @xmath0-user gaussian broadcast channel with bandwidth mismatch . a new outer bound to the achievable distortion region </S>",
    "<S> is derived using the technique of introducing more than one additional auxiliary random variable , which was previously used to derive sum - rate lower bound for the symmetric gaussian multiple description problem . by combining this outer bound with the achievability result based on source - channel separation , we provide approximate characterizations of the achievable distortion region within constant multiplicative factors . </S>",
    "<S> furthermore , we show that the results can be extended to general broadcast channels , and the performance of the source - channel separation based approach is also within the same constant multiplicative factors of the optimum .    </S>",
    "<S> gaussian source , joint source - channel coding , squared error distortion . </S>"
  ]
}