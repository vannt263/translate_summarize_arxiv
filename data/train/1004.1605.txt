{
  "article_text": [
    "as a subfield of signal detection or hypothesis testing , multihypothesis sequential detection has many important engineering applications such as target detection in multiple - resolution radar , serial acquisition of direct - sequence spread spectrum signals and fault detection , see baum and veeravalli @xcite . the centralized version has been studied in both statistical and engineering literature , see the award winning papers by dragalin , tartakovsky and veeravalli @xcite , @xcite and their references for the latest development .    in recent decades the decentralized version of signal detection or hypothesis testing has gained a great deal of attention , partly because geographically distributed sensors have been employed into a wide range of areas like military surveillance @xcite , target tracking and classification @xcite , and data filtering @xcite , etc . in the decentralized version , it is standard to assume that raw observations are observed at the local sensors , and quantized into sensor messages that are sent to a fusion center , which makes a final decision . unfortunately , most research on decentralized detection deals with the off - line setting and research for the online or _",
    "sequential _ setting is rather limited . to the best of our knowledge ,",
    "so far existing research on decentralized sequential detection is restricted to two - hypothesis , see veeravalli , basar , and poor @xcite , veeravalli @xcite and mei @xcite .",
    "the goal of this paper is to develop asymptotic optimality theory for decentralized sequential detection when there are @xmath0 possible hypotheses on the models of the sensor network system .",
    "a main challenge is how to find good quantizers at the local sensors so that the fusion center is able to utilize quantized sensor messages to make effective decisions .",
    "intuitively , the choice of good quantizers should depend on the true unknown distribution of raw sensor observations .",
    "since there are @xmath0 hypotheses , it is expected that stationary quantizers will not lead to ( asymptotically ) optimal tests no matter how clever one chooses it .",
    "it turns out that by combining three existing methodologies together :  tandem quantizers \" in mei @xcite ,  unambiguous likelihood quantizers \" ( ulq ) in tsitsiklis @xcite , and randomized quantizers , we are able to find good quantizers and use them to offer a family of asymptotically bayes tests for decentralized multihypothesis sequential detection .    the remainder of this article is organized as follows .",
    "section ii provides a formal mathematical formulation of decentralized sequential multihypothesis testing problem and introduce the notation of randomized quantizer .",
    "section iii discusses tandem quantizers and constructs a family of `` two - stage '' decentralized sequential tests .",
    "this leads to a natural definition of  maximin quantizers , \" in which the corresponding two - stage decentralized sequential tests are shown to be asymptotically bayes . in section iv , the maximin quantizers are characterized in more details as a randomized quantizer based on at most @xmath1 ( deterministic ) ulqs , and numerical algorithms are provided to solve them explicitly .",
    "section v provides specific examples to illustrate the method developed in previous sections .",
    "[ fig : snsrnet ] shows a widely used configuration of sensor networks , where a fusion center is associated with a set of remote local sensors @xmath2 to highlight our main ideas , we assume @xmath3 here , since the extension to systems with multiple sensors is relatively straightforward as long as the sensor observations are independent from sensor to sensor conditioned on each hypothesis .",
    "the local sensor takes a sequence of independent and identically distributed ( i.i.d . )",
    "raw observations @xmath4 over time @xmath5 . in the decentralized version",
    ", it is assumed that the fusion center has no direct access to the raw sensor data @xmath6 s due to communication constraints .",
    "rather , the local sensor compresses @xmath7 into quantized message @xmath8 and sends it to the fusion center , which will then use the @xmath9 s as inputs to make a final decision . for our purpose",
    ", we also assume that the fusion center can send feedbacks @xmath10 to local sensor so that the local sensor can adaptively adjust sensor policies to the optimal one . for simplicity , we further assume the quantized messages to be binary , i.e. , @xmath11 .",
    "mathematically , at time @xmath12 the sensor message @xmath9 and fusion center feedback @xmath10 can be defined as @xmath13}),\\ ] ] where @xmath14}=(u_1,\\dots , u_{n-1})$ ] .",
    "note that the feedback @xmath10 should only depend on the past sensor messages . here",
    "no restrictions are imposed on @xmath10 , but it turns out that @xmath15-bit feedbacks will be sufficient to construct asymptotically optimal tests under our setting .        in decentralized multihypothesis sequential detection , it is assumed that there are @xmath0 hypotheses regarding the true probability distribution @xmath16 of @xmath6 s : @xmath17 for @xmath18 where the @xmath6 s have a probability density ( or mass ) function @xmath19 under @xmath20 furthermore , the sensor network system will continue taking observations until the fusion center believes that there is sufficient evidence from the quantized messages @xmath9 s to make a final decision .",
    "that is , at a stopping time @xmath21 the fusion center makes a decision @xmath22 where @xmath23 means that one accepts the hypothesis @xmath24 here we emphasize that the decision @xmath25 only depends on the first @xmath5 sensor messages , i.e. , @xmath26 is a stopping time with respect to the filtration @xmath27}\\}\\}$ ] and @xmath28 is measurable to @xmath29 .",
    "in summary , a decentralized sequential test @xmath30 includes a sequence of quantizers @xmath31 at the local sensor , a sequence of feedback functions @xmath32 , a stopping time @xmath26 at the fusion center and the final decision @xmath28 .    as in wald @xcite and veeravalli et al .",
    "@xcite , we consider the bayes formulation of decentralized multihypothesis sequential detection .",
    "let @xmath33 be the cost of data sampling per time step , and @xmath34 be the loss of making decision @xmath35 when the true state of nature is @xmath36 .",
    "we assume that all @xmath34 s are non - negative and @xmath37 if and only if @xmath38 .",
    "let the total risk of a test @xmath30 when the true state is @xmath39 be @xmath40.\\ ] ] assigning prior probabilities @xmath41 to @xmath42 define the average risk of a decentralized sequential test @xmath30 as @xmath43 the bayesian formulation of decentralized sequential detection problems can be stated as follows :    _ problem ( p1 ) : _ minimize the @xmath44 in ( [ equ : ttlcstsapriorpi ] ) among all possible decentralized sequential hypothesis testing procedures @xmath30 .",
    "let @xmath45 denote a bayes solution to ( _ p1 _ ) , i.e. , @xmath46 .",
    "unfortunately , the exact form of @xmath47 is too complicated to be tractable for multihypothesis sequential detection even for the centralized version , see , for example , dragalin , tartakovsky and veeravalli @xcite .",
    "this leads us to consider the `` asymptotic optimality '' approach as follows :    _ problem ( p2 ) _ : find a family of decentralized sequential tests @xmath48 such that @xmath49 where @xmath50 is the unit cost in ( [ equ : ttlcstsapriorpi ] ) .",
    "problem ( p2 ) is meaningful in application because it is often the case that the cost of doing a round of sampling is much smaller than that of making an incorrect decision .    in the remainder of this section ,",
    "let us discuss the concepts of randomized quantizers and kullback - leibler ( k - l ) divergences .",
    "denote by @xmath51 the set of deterministic quantizers that consists of all measurable functions from @xmath52 to @xmath53 .",
    "for a quantizer @xmath54 , let @xmath55 denote the induced distribution of the quantized data @xmath56 under @xmath36 , i.e. , for @xmath57 , @xmath58 .",
    "recall that the k - l divergence of @xmath59 of any state @xmath39 against any other state @xmath60 is defined as @xmath61 now define a `` randomized quantizer '' @xmath62 as a probability measure that assigns certain masses @xmath63 on an at most countable subset @xmath64 .",
    "denote by @xmath65 the set of all quantizers , deterministic or random .",
    "note that a deterministic quantizer can be thought of as a randomized one that assigns probability one to itself .",
    "for a randomized quantizer @xmath62 , define its k - l divergences as the weighted average of those of the deterministic ones it randomizes : @xmath66 this divergence for randomized quantizer will be key to our theorems .",
    "the following assumption ensures basic regularities of the pdf s , it will be imposed throughout the rest of the paper .",
    "[ ass:1stmmts ] for any two states @xmath67 , @xmath68<\\infty.\\ ] ]",
    "in this section we will use tandem quantizers to define a class of `` two - stage '' tests @xmath70 , and show that asymptotic bayes tests can be found within it .",
    "the intuition is that the fusion center first makes a guess about the true state of nature and then tries to optimize the test based on the guess .    as discussed in mei @xcite ,",
    "tandem quantizer denotes the case when each sensor has the choice between two different sensor quantizers with at most one switch between them .",
    "obviously , a tandem quantizer is the simplest non - stationary quantizers from the viewpoint of the number of switches . for the purpose of defining the two - stage sequential test @xmath70 , a useful alternative way to think about tandem quantizers is to divide the decision making into two stages .    in the _ first stage _ of",
    "@xmath71 one can use whatever reasonable stationary quantizers to make a preliminary decision on which of the @xmath72 hypotheses is likely true , and the only requirement is that the sample size of this stage is large but is small relative to the overall sample sizes ( or that of the second stage ) . specifically , as @xmath73 consider a sequence of @xmath74 such that @xmath75 and @xmath76 , e.g. , @xmath77 and assume there is a quantizer @xmath78 such that for any @xmath79 , @xmath80 now in the first stage , the local sensor uses the stationary quantizer @xmath81 to send sensor messages to the fusion center , which will then face the classical multihypothesis sequential detection problem based on the i.i.d .",
    "quantized sensor messages @xmath82 hence , one can recursively update the posterior distribution @xmath83 at the fusion center as follows : @xmath84 where @xmath85 is the quantized message at time @xmath5 . as a reasonable test for the preliminary decision",
    ", the fusion center will stop the first stage at time @xmath86 : @xmath87 and decides that the preliminary decision @xmath88 of the most promising state of nature is @xmath89    in the _ second stage _ of our two - stage test @xmath71 the local sensor switches to another stationary ( though likely randomized ) quantizer , whose choices will likely depend on the preliminary decision @xmath90 of the first stage .",
    "denote the quantizer used in the second stage as @xmath91 when @xmath92 , where @xmath93 .    in the second stage , with the new quantizer applied at the local sensor ,",
    "the fusion center starts afresh to update the posterior distribution @xmath94 based on i.i.d .",
    "sensor messages in the second stage .",
    "an efficient stopping rule for the fusion center can then be found as in dragalin et al . @xcite as follows .",
    "let @xmath95 be the average loss by making a decision @xmath39 at time @xmath5 , and let @xmath96 be the least value of loss by making some decision @xmath60 at time @xmath5 while @xmath39 is the true state of nature .",
    "define a total of @xmath72 stopping times : @xmath97 the fusion center can stop the second stage ( hence the whole procedure ) at time @xmath98 , and makes a final decision @xmath99 if @xmath100 .    it is worth discussing the implementation of the likely randomized quantizer @xmath101 if @xmath92 is the preliminary decision .",
    "we also need to give a explicit formula for updating posterior when randomized quantizer is used to form reports .",
    "suppose @xmath102 .",
    "the key of any allowable randomization schemes is that the fusion center must know which deterministic quantizer is finally chosen , otherwise it may lose significant information and compromise the decision making efficiency .",
    "we propose two alternative ways to achieve this goal .",
    "the most straightforward way is to let the fusion center do the randomization directly .",
    "specifically , at a time step @xmath5 of the second stage , the fusion center selects a deterministic quantizer @xmath103 randomly according to the probability measure @xmath104 and informs the local sensor its choice through a feedback .",
    "meanwhile , the posteior distributions should be updated as follows : @xmath105 an alternative way of randomization is to implement a `` block design '' at local level .",
    "suppose that @xmath91 is randomized by a finite number , say @xmath106 of deterministic quantizers , and @xmath107 is a common denominators of the rational probabilities @xmath108 .",
    "then take  blocks \" of @xmath107 observations , and in each block @xmath109 ,  , @xmath110 are used following a fixed order such that each @xmath111 appears exactly @xmath112 times . in this way",
    "the fusion center also knows which quantizer is used at each time step and it will update the posterior just as in ( [ equ : postupdaterdmnqntzr ] ) .    for our proposed two - stage procedure @xmath71",
    "its asymptotic properties are summarized in the following theorem , whose proof is omitted since it can be derived along the same lines as those in section v of kiefer and sacks @xcite . to state the theorem , first we define the following information number for a quantizer @xmath113 and state @xmath93 : @xmath114    [ the : asymp2stageproc ] let @xmath115 be the randomized quantizers applied in the second stage of @xmath70 , and each @xmath91 randomizes finite number of deterministic quantizers .",
    "suppose @xmath116 , @xmath117 for any @xmath39 .",
    "then as @xmath118 , for the sample size @xmath26 : @xmath119=(1+o(1))|\\log c|/i(m ; \\bar{\\phi}_m ) , \\quad m=0,1,\\dots , m-1,\\ ] ] and for the probability of incorrect decisions : @xmath120=o(c ) , \\quad m=0,1,\\dots , m-1.\\ ] ] thus , the bayes risk of the proposed two - stage test @xmath70 is given by @xmath121    in light of theorem [ the : asymp2stageproc ] , from the asymptotic viewpoint , an optimal procedure within the class of two - stage tests should maximize the information numbers @xmath122 so as to minimize the bayes risk .",
    "this leads to a natural definition of the optimal quantizers that we should use in the second stage :    for @xmath123 the quantizer @xmath124 is defined as the maximin quantizers with respect to @xmath36 if @xmath125    let us focus on the two - stage procedure @xmath126 with the maximin quantizers being applied on the second stage . in next section , we will show that each @xmath124 can be attained by randomizing at most @xmath1 deterministic quantizers .",
    "hence by theorem [ the : asymp2stageproc ] , it has a bayes risk @xmath127 as @xmath118 , where @xmath128 .",
    "surprisingly , test @xmath126 is not only the best among the two - stage tests , but also an asymptotically bayes solution to problem ( p2 ) .",
    "this is a direct consequence of the following important theorem :    [ the : asympoptdeltaic ] relation ( [ equ : bayesoptimal ] ) is also satisfied by @xmath47 , the bayes procedure .",
    "the conclusion will be established once we prove the following : for any test with the probability of making incorrect decisions @xmath129 for @xmath93 , its expected values of the total time steps must satisfy @xmath130 for any state @xmath39 as @xmath118 .",
    "however this can be proved in the same way as theorem 1 of tsitovich @xcite .",
    "it is useful to point out that although the stopping rules of the asymptotic bayes test @xmath126 involve the prior distribution @xmath131 s , this is not essential and the key is for the local sensor to use the maximin quantizers @xmath124 s at the second stage .",
    "in fact , since the maximin quantizers does not depend on the prior distribution @xmath131 s , ( [ equ : samplesize2stageproc ] ) and ( [ equ : wrongdecision2stageproc ] ) show that the optimality of @xmath126 is robust w.r.t . a priori distribution @xmath131 as long as its support covers all @xmath72 possible states of nature .",
    "in this section , we provide a deeper understanding of the maximin quantizers @xmath132 and also illustrate how to compute them explicitly when the sensor messages are binary . for this purpose",
    ", we first introduce the concept of the unambiguous likelihood quantizer ( ulq ) , which was proposed in tsitsiklis @xcite as a generalization of monotone likelihood ratio quantizer ( mlrq ) .    for simplicity",
    ", we assume that for any set of real numbers @xmath133 which are not all zeros , @xmath134 note that ( [ equ : ulqisextcondition ] ) is easily satisfied by the common continuous pdf families like normal , exponential , etc .",
    "[ def : ulq ] under ( [ equ : ulqisextcondition ] ) , a deterministic quantizer @xmath54 is said to be an unambiguous likelihood quantizer if there exist real numbers @xmath135 which are not all zero , such that @xmath136    it is easy to see that in the case of binary simple hypothesis testing , i.e. , @xmath137 , the ulqs become mlrqs .    with the definition of ulqs ,",
    "now it is time to state the following useful theorem which characterizes the maximin quantizers @xmath138 .",
    "[ the : maximinqntzrapproxbyulq ] under ( [ equ : ulqisextcondition ] ) , each maximin quantizer @xmath124 can be attained as a randomization of at most @xmath1 ulqs .",
    "the detailed proof involves tedious technical details , and thus here we will only provide a high - level short explanation . for a fixed state @xmath39 , finding the maximin quantizers against the other @xmath1 states",
    "is equivalent to solving an optimization problem in an @xmath1 dimensional space , where each quantizer , deterministic or randomized , corresponds to a point in it . by tsitsiklis @xcite ,",
    "these points construct a convex region whose extremal points all correspond to ulqs under the condition of ( [ equ : ulqisextcondition ] ) . moreover , the maximin quantizers correspond to the points that must be on the surface of the convex region , and thus can be expressed as a convex combination of at most @xmath1 extremal points ( see hormander @xcite ) .",
    "combining these results together leads to the desired relation between the maximin quantizers and the ulqs .",
    "with theorem [ the : maximinqntzrapproxbyulq ] , we are ready to illustrate how to find the maximin quantizers numerically .    fix any state @xmath39 , define @xmath139 parameters as probability masses @xmath140 and ulq coefficients @xmath141 based on every combination of these parameters , define by @xmath142 the quantizer randomizing @xmath1 ulqs : @xmath143 where @xmath144 the maximin quantizer @xmath124",
    "can then be found as @xmath142 that maximizes @xmath145 among all possible combinations of @xmath146",
    "in this section we illustrate our procedure with a concrete example .",
    "suppose that the raw sensor observations @xmath6 s are distributed according to @xmath147 if there are only @xmath137 hypotheses on @xmath148 say testing @xmath149 against @xmath150 then there is no randomization involved in the second stage , and the maximin quantizer is just the ulqs which becomes the mlrqs when @xmath151 such a result is consistent with those in mei @xcite .",
    "now suppose there are @xmath152 hypotheses regarding the normal mean : @xmath153 @xmath154 and @xmath155 for this specific case , it is not too difficult to solve the optimization problem ( [ equ : objfunc ] ) by linear programming . up to the precision of four decimal places , numerical computations show that all three maximin quantizers turn out to be deterministic ones : @xmath156 @xmath157 and @xmath158 and their corresponding maximin information numbers are @xmath159 and @xmath160 . for the first stage , the quantizer @xmath161 can be applied because it satisfies the condition ( [ equ : prmlqntzrdecnt ] ) . by theorem [ the : asymp2stageproc ] , the risk of @xmath126 can be approximated by @xmath162    as a comparison , in the centralized version when the whole raw observations are allowed to be used at the fusion center , it can be shown that the bayes risk of the optimal centralized test is @xmath163 see , for example , dragalin et al .",
    "@xcite and kiefer and sacks @xcite .",
    "thus the asymptotic efficiency of @xmath126 with respect to the optimal centralized test is @xmath164 in particular , if we just merely introduce another identical sensor into the network system , then the efficiency of @xmath126 will be doubled and the corresponding decentralized test will have better properties than that of @xmath165 .",
    "in this article , the problem of decentralized testing multihypotheses in ( single ) sensor networks is studied .",
    "asymptotically bayes test @xmath166 is constructed by combining the ideas of `` tandem quantizers '' , `` unambiguous quantizers '' , and `` randomized quantizers . ''",
    "such a test involves a new concept of maximin quantizers which are discussed in details , both theoretically and numerically .",
    "it is natural to extend our results to the networks with multiple sensors , where different sensors may use different quantizers .",
    "a more interesting extension is to understand what happens when one or more hypotheses are not simple , i.e. , the composite multihypotheses case .",
    "these will be reported elsewhere .",
    "this work was supported in part by the afosr grant fa9550 - 08 - 1 - 0376 and the nsf grant ccf-0830472 .    1 c. w. baum , v. v. veeravalli , `` a sequential procedure for multihypothesis testing '' , _ ieee trans .",
    "inf . theory _ ,",
    "1994 - 2007 , 1994 .",
    "r. s. blum , s. a. kassam , and h. v. poor ,  distributed detection with muliple sensors : part ii- advanced topics , \" _ proceedings of the ieee _ , vol .",
    "64 - 79 , 1997 .",
    "h. chernoff , `` sequential design of experiment , '' _ ann .",
    "_ , vol . 30 , pp .",
    "755 - 770 , 1959 .",
    "v. p. dragalin , a. g. tartakovsky , v. v. veeravalli , `` sequential probability ratio tests - part i : asymptotic optimality '' , _ ieee trans . inf .",
    "2448 - 2461 , 1999 .",
    "j. kiefer and j. sacks , `` asymptotically optimal sequential inference and design , '' _ ann . math .",
    "705 - 750 , 1963 .",
    "d. li , k. d. wong , y. h. hu , a. m. sayeed , `` detection , classification and tracking of targets in distributed sensor networks '' , _ ieee signal processing magazine , _ vol .",
    "19 , pp 17 - 29 , 2002 .",
    "y. mei , `` information bounds and quickest change detection in decentralized decision systems , '' _ ieee trans .",
    "theory , _ vol .",
    "2669 - 2681 , jul . 2005 .",
    "y. mei , `` asymptotic optimality theory for decentralized sequential hypothesis testing in sensor networks '' _ ieee trans .",
    "inf . theory _ ,",
    "2072 - 2089 , may . 2008 .",
    "r. r. tenney , n. r. sandell jr .",
    ", `` detection with distributed sensors , '' _ ieee trans .",
    "aerospace elect .",
    "syst , _ vol .",
    "aes-17 , pp.501 - 510 , 1981 .",
    "i. i. tsitovich , `` sequential desigh of experiments for hypothesis testing , '' _ theory prob .",
    "814 - 817 , 1984 . j. n. tsitsiklis , `` extremal properties of likelihood ratio quantizers '' , _ ieee trans",
    "550 - 558 , 1993 .",
    "v. v. veeravalli , `` sequential decision fusion : theory and applications '' , _",
    "j. franklin inst .",
    "301 - 322 , feb . 1999 .",
    "v. v. veeravalli , t. basar , and h. v. poor , `` decentralized sequential detection with a fusion center performing the sequential test , '' _ ieee trans .",
    "inf . theory _ ,",
    "433 - 442 , mar . 1993 .",
    "r. viswannathan , p. k. varshney ,  distributed detection with muliple sensors : part i- fundamentals , \" _ proceedings of the ieee _ , vol .",
    "54 - 63 , 1997 .",
    "a. wald , _",
    "sequential analysis_. new york : wiley , 1947 . f. ye , h. luo , s. lu , l. zhang , `` statistical en - route filtering of injected false data in sensor networks '' , _ ieee journal on selected areas in communications _",
    ", vol 23 , pp 839 - 850 , 2005 ."
  ],
  "abstract_text": [
    "<S> this article is concerned with decentralized sequential testing of multiple hypotheses . in a sensor network system with limited local memory , raw observations </S>",
    "<S> are observed at the local sensors , and quantized into binary sensor messages that are sent to a fusion center , which makes a final decision . </S>",
    "<S> it is assumed that the raw sensor observations are distributed according to a set of @xmath0 specified distributions , and the fusion center has to utilize quantized sensor messages to decide which one is the true distribution . </S>",
    "<S> asymptotically bayes tests are offered for decentralized multihypothesis sequential detection by combining three existing methodologies together : tandem quantizers , unambiguous likelihood quantizers , and randomized quantizers . </S>"
  ]
}