{
  "article_text": [
    "compressive sensing ( cs ) ( cf .",
    "the pioneering work @xcite ) is a new technique in data acquisition realm that reconstructs the signal from fewer measurements than that required by the classical nyquist - shannon sampling theorem .",
    "this fact makes it very useful in reducing the sensing cost in a variety of applications such as geophysics , astronomy and medical imaging .",
    "the incomplete measurement @xmath0 of cs is usually linear projections of the underlying image of interest @xmath1 in the form of @xmath2 where @xmath3 is noise .",
    "it relies on sparsity / compressibility of @xmath4 itself or under certain transform @xmath5 to recover it from @xmath6 . when there is no noise ( @xmath7 ) , a straightforward approach to reconstructing @xmath4 is to solve the @xmath8 problem @xmath9 however , since the @xmath8 problem is np - hard , it is common in practice to consider a convex relaxed @xmath10 optimization problem @xmath11 which is more computationally efficient .",
    "when the sparsifying transform @xmath5 is orthonormal , the solution of turns out to be the same as that of , and approximate the underlying signal with an overwhelming probability if @xmath12 satisfies the restricted isometry property ( rip ) .",
    "a commonly used example of orthonormal @xmath5 is the haar wavelet transform .",
    "more recently , rip is generalized to d - rip @xcite , a property that guarantees accurate recovery of images that are nearly sparse in overcomplete / redundant dictionaries .",
    "the theoretical results make it more flexible to choose @xmath5 and reconstruct the signal using @xmath10 optimization . in the presence of noise , a relaxed model of interest",
    "is @xmath13 or equivalently @xmath14 where @xmath15 is related to the noise level @xmath16 in the data . to preserve the discontinuities of @xmath17 which correspond to the image features , e.g. , edges , total variation ( tv )",
    "is taken into consideration as an additional regularization term @xcite .",
    "then the model with two regularization terms reads as @xmath18 where @xmath5 is the wavelet transform and @xmath19 depends on the characteristics of the underlying image itself .",
    "wavelet transform and total variation have been used widely in various computer vision and/or imaging science problems .",
    "the advantage of wavelet transform is its optimality in approximating signals containing point - wise singularities , but it is widely known that traditional wavelets are not so effective in dealing with singularities in higher dimensions , such as edges in 2d images .",
    "tv is optimal in describing piecewise constant images and preserving image edges .",
    "however , it is well known that the tv regularization will cause staircase effects . recently",
    ", it has been shown that the tv regularization is closely connected to the wavelet one @xcite .",
    "therefore , the combination of wavelet and tv is not ideal for reconstructing natural images with abundant directional geometric information from few noisy cs measurements .    in this paper",
    ", we present a geometric information guided cs ( abbreviated as geocs ) reconstruction method to improve the performance for the situations when the sampling rate is low and/or the noise level is high .",
    "the goal is to preserve geometries and fine features with less data required than the state - of - the - art methods .",
    "there are three major contributions in our paper .",
    "* shearlet transform instead of the widely used wavelet transform is adopted as @xmath5 to promote the sparsity of signals and thereby reduce the number of measurements required for accurate recovery of them by the fundamental cs theory .",
    "shearlets @xcite provide an optimally sparse approximation of piecewise smooth function with @xmath20 singularity curves , e.g. , edges , cusps and corners .",
    "it combines the power of multiscale methods with the capability of extracting geometry of images . * a two - stage method rather than the conventional one - stage method",
    "is applied to obtain better recovered images from fewer measurements than the state of the arts .",
    "this reconstruction approach adaptively learns the gradient of increasing accuracy to some extent controlling the image geometry .",
    "the first stage is to get an initial image reconstruction from cs measurements based on shearlet transform and tv .",
    "the second stage starts with geometric information extracted from the result of stage i , and alternates image reconstruction and geometric information update until it converges .",
    "adaptive tv and shearlet transform are used in the second stage .",
    "massive numerical experiments show that the two - stage approach outperforms the classical one - stage methods .",
    "* apply the alternating direction method of multipliers ( admm ) @xcite or its equivalent split bregman method @xcite to efficiently solve the optimization problems in both stages .",
    "the algorithm achieves fast convergence and produces high - quality images .",
    "the convergence of the algorithm at each stage is guaranteed as well .    in @xcite , the binary reweighted @xmath10 regularization",
    "is exploited for recovering 1d sparse signals .",
    "while it can be applied to recover the sparse wavelet coefficients of an image and hence the image itself , it can hardly take advantages of image edges to improve the recovery .",
    "in our recent work @xcite , binary edge detection and image reconstruction are performed alternatively in a mutually beneficial way and thus the recovery quality has been improved .",
    "this work considers the more general edge detection whose range is continuous rather than binary .",
    "the spatially variant weights associated to the tv ranges between zero and one based on the extracted salient geometric information . in that case , the sharp edges are still able to be preserved while gradual intensity changes in smooth regions can be preserved as well to reduce the staircase effects resulted in tv regularization .",
    "the paper is organized as follows .",
    "we provide a brief review of the shearlet transform in section [ sec : review ] , and present the two - stage geometric information guided algorithm in section [ algorithm ] .",
    "the convergence analysis of the algorithm and practical parameter selection are presented in section [ convergence ] . to show the consistent excellence and robustness of the proposed algorithm , plenty of numerical results and comparisons to related work reconstruction from partial fourier data ( recpf ) @xcite and edge guided compressive sensing ( edgecs ) @xcite are provided in section [ experiments ] .",
    "finally , conclusion and remarks are made in section [ conclusion ] .",
    "the traditional wavelet transform is based on isotropic dilations and thus has limited ability to describe the geometry of multidimensional functions . directional representation systems such as ridgelets @xcite ,",
    "curvelets @xcite , contourlets @xcite , and shearlets @xcite have been designed to provide much more geometric information of multidimensional functions such as images .",
    "curvelets , a tight frame of elongated oscillatory functions at various scales , was first proposed by cands and donoho to generalize wavelet . for any @xmath21 function @xmath22 , the @xmath23 largest term approximation using the curvelet transform has error norm of order @xmath24 . since the curvelets are not generated by taking a family of actions on one function as wavelet , it is numerically difficult to implement . in an attempt to provide a better discrete implementation of the curvelets ,",
    "the contourlet representation is then proposed .",
    "it is a discrete time - domain construction , which is designed to achieve essentially the same frequency tiling as the curvelet representation . with the same rate of approximation error decay as curvelets ,",
    "shearlets have several advantages : efficient implementation , more directional sensitivity and theoretical relation to the multiresolution analysis .",
    "shearlet transform is an efficient multiscale directional representation of signals , theoretically proven to be optimal up to a log - factor in encoding images with anisotropic features such as edges , corners and other singularities @xcite . given any function @xmath25 , the shearlet system is generated by applying the operations of dilation , shear transformation and translation of @xmath26 : @xmath27 where @xmath28 with @xmath29 , @xmath30 a shear operator and @xmath31 an anisotropic dilation operator .",
    "note in the generation of wavelets , there are only isotropic scaling and translation involved without shearing or anisotropic scaling .",
    "the shearlet transform of function @xmath32 is defined as @xmath33 the shearlet transform is invertible if the function @xmath26 satisfies the admissibility property @xmath34 where @xmath35 is fourier transform of @xmath26 .",
    "given complete shearlet transform coefficients , the original function @xmath22 can be recovered by @xmath36 discrete shearlet transform can be implemented efficiently using the fast fourier transform .",
    "there are three shearlet toolboxes using matlab available online : local shearlet toolbox http://www.math.uh.edu/~dlabate/software.html , fast finite shearlet transform ( ffst)@xcite , and shearlab http://www.shearlet.org .",
    "more recently , the shearlet transform has been successfully applied in image processing , e.g. , the shearlet - based total variation denoising algorithm @xcite .",
    "because of its higher sparsity of signal representation and ability to capture directional features , the performance of the shearlet transform has also been explored in cs field @xcite .",
    "in this section , we present our reconstruction model and analyze how to apply split admm to solve the model at each stage .",
    "the idea is to use both the shearlet transform and the weighted tv . to enhance the accuracy of weights associated to the tv regularization , we propose a two - stage method .",
    "the first stage is to solve a standard @xmath37-@xmath10-@xmath38 model with the shearlet transform to get an initial guess for the underlying image of interest .",
    "note that the extraction of geometry does not work at stage i since the accuracy is relatively low . in the second stage",
    ", we generate the initial spatially variant weights based on the result from stage i , and then alternate image reconstruction and weights update until it converges at this stage .",
    "the entire algorithm alternates the two stages until the relative error between two consecutive results is within a tolerance value .    for the shearlet part @xmath39",
    ", we adopt the ffst algorithm which is completely done by the fourier transform and the inverse fourier transform .",
    "let @xmath40 where @xmath41 is the @xmath42th subband of shearlet transform of @xmath17 and @xmath23 depends on the number of scales in shearlet transform .",
    "the @xmath42th subband of the shearlet transform can be efficiently implemented as componentwise multiplication with a mask matrix denoted by @xmath43 in the frequency space .",
    "we have @xmath44 where @xmath45 , @xmath46 is the matrix representation of the vectorized image @xmath17 and @xmath47 is the fourier transform of @xmath46 .",
    "we demonstrate the idea of the proposed model using partial fourier sampling , but it can be extended easily to other linear projection measurements .",
    "let @xmath48 where @xmath49 is a selection matrix and @xmath50 is the fourier transform operator . for 2d fourier transform",
    ", @xmath51 is the kronecker product of two identical @xmath52 unitary fourier transform matrices @xmath53 with @xmath54 it can be shown that @xmath50 satisfies @xmath55 . by this notation , we get the explicit representation of @xmath56 as @xmath57 the selection matrix @xmath58 is generated simply by deleting the @xmath59th row of the @xmath60 identity matrix if the @xmath61th entry of data matrix is not sampled .      to simplify our discussion , we assume the image to be studied has a square domain .",
    "let @xmath63 be the vectorized ground truth image , and @xmath64 ( @xmath65 ) the given data .",
    "at the first stage , we consider the unconstrained minimization problem with anisotropic discretization of tv as follows : @xmath66 where @xmath67 ( @xmath68 ) is a horizontal ( vertical ) first order finite difference operator with periodic boundary conditions .    due to the non - differentiability of both tv and @xmath10 terms , we introduce auxiliary variables @xmath69 ( @xmath70 ) and @xmath71 ( @xmath72 ) such that @xmath73 ( @xmath70 ) and @xmath74 ( @xmath72 ) to split the variables .",
    "we wish to solve the problem @xmath75 after adding the quadratic penalty terms , we get the following unconstrained problem : @xmath76 the above optimization problem is equivalent to when @xmath77 go to infinity . solving using the continuation scheme",
    "@xcite is a straightforward method , but it is slow and leads to the ill conditioning of the problem when @xmath78 are sufficiently large .",
    "we hereby apply the split bregman , which provides fast convergence while values of @xmath78 can be fixed .",
    "the split bregman formulation is @xmath79 where @xmath80 s , @xmath81 s are updated by bregman iterations @xmath82 with @xmath83 a parameter to be discussed later .",
    "we finally decompose it into three sets of subproblems and apply alternating minimization scheme to get a minimizer iteratively .",
    "@xmath84    the first two subproblems are both in the form of @xmath10-@xmath38 optimization @xmath85 whose solution is given by using the shrinkage operator @xmath86 where @xmath87 is componentwise sign function and @xmath88 is componentwise multiplication . then by the similar derivations , the first two subproblems have closed - form solutions using shrinkage .    to solve the last least square subproblem , we consider the corresponding normal equation @xmath89 to circumvent the expensive computation of the inverse matrix , we multiply both sides by @xmath50 and simply the solution due to the fact that @xmath50 is unitary . by simplification ,",
    "the solution is explicitly represented as @xmath90 here @xmath91 is a @xmath60 diagonal matrix with diagonal value 0 , 1 corresponding to nonsampled and sampled entries , respectively . denoting @xmath92 ,",
    "the solution can be further written in terms of fourier transform @xmath93 here @xmath94 means the componentwise division .",
    "one more remark about this approach is that since @xmath95 s and @xmath56 s are circulant matrices which can be diagonalized under the fourier transform , both @xmath96 and @xmath97 are diagonal matrices .",
    "we follow the convention that @xmath98 .",
    "the above analysis yields the following algorithm .",
    "initialization : set @xmath99 as zero matrices , and choose proper parameters @xmath100 .    for @xmath101 ,",
    "run the following steps : @xmath102      the stage i model works well in mild cs scenario but not so efficient in challenging scenarios when sampling rate is extremely low and noise is excessive . to handle challenging situations ,",
    "we start with the result of stage i and then alternatively perform geometric information update and image reconstruction in a beneficial way .",
    "specifically , setting the result from stage i as initial guess , we define adaptive weights based on it , and use weighted tv along with shearlet to reconstruct an image .",
    "we then continue alternating weight update and image reconstruction until it converges . for a fixed weight ,",
    "the model reads as below @xmath104 where @xmath105 s are the weights based on the extracted geometric information , such as reliable gradients and high frequency subbands of shearlet transform coefficients . and @xmath88 is componentwise multiplication .",
    "algorithm [ alg2 ] is designed to address the above problem and the complete stage ii algorithm is shown in algorithm [ alg3 ] .    given the latest iterate @xmath106 for the reconstructed image , we define tv weight at each pixel as a function of the gradient of @xmath106 at the same pixel .",
    "suppose @xmath107 $ ] is a non - increasing function satisfying @xmath108 @xmath109 is called edge stopping function in image segmentation or diffusivity function in pde .",
    "the reason is that @xmath110 approaches to zero near edges where the gradient gets large while close to one in smooth areas where the gradient becomes small .",
    "in fact , besides separating edges from smooth areas , @xmath109 also identifies the small differences in intensity variations _ within _ the smooth areas .",
    "the pixel in regions of small intensity variations will get larger @xmath109 value than that in regions of large intensity variations .",
    "weighted tv with this type of weight will preserve the various intensity variation scales in the reconstruction process , and thus increase the robustness of tv and reduce the staircase effects of tv .",
    "there are many choices for @xmath109 .",
    "some commonly used ones are listed below , where @xmath111 is a parameter controlling the differentiation of smoothness levels .",
    "a.   lorentzian function @xmath112 b.   le clerc function @xmath113 c.   tukey bi - weight function @xmath114 d.   weickert function @xmath115    in fig .",
    "[ fig : edgestopfcn ] , we plot the above four @xmath109 functions when @xmath116 . from observation",
    ", it s clear that they have different decay behaviors . especially , weikert edge function decays slowly at the two ends but fast near the middle and tukey bi - weight function decays slowly all the way long .",
    "so for piecewise constant images whose intensity changes sharply from one region to another , weikert is optimal while tukey bi - weight function is more appropriate for generic complicated piecewise smooth images with ubiquitous unprecedented intensity variations .",
    "we use tukey bi - weight for all our numerical experiments as we focus on testing piecewise smooth images .",
    "s when @xmath117,scaledwidth=60.0% ]    since we adopt anisotropic tv discretization , our weights are different along @xmath118 directions and are defined respectively as @xmath119 notice that high frequency components of the shearlet transform of @xmath106 also provide some edge information .",
    "so another option to define weights is to gather all the high frequency subbands .",
    "but our massive numerical experiments show that @xmath109 function of gradients is more efficient .",
    "initialization : set @xmath99 as those generated from stage i.    for @xmath101 , run the steps : @xmath120    in hope of retrieving more trustworthy geometric prior information , we update the weights from each convergent intermediate result and reapply the algorithm [ alg2 ] .",
    "then we get the algorithm [ alg3 ] .",
    "initialization : set @xmath99 as those produced from stage i.    for @xmath121 , run the steps :    1 .",
    "build the weights @xmath122 based on @xmath123 by .",
    "2 .   set @xmath124 as initial values ,",
    "apply algorithm [ alg2 ] to solve and get @xmath125 .",
    "if @xmath126 , stop the iteration .",
    "there are close relationships between bregman iterative methods and its variants such as linearized bregman , bregman operator splitting , and the classical lagrangian based methods , such as method of multipliers , the alternating direction method of mutlipliers ( admm ) and alternating minimization algorithm ( ama ) .",
    "the connection between split bregman algorithm and admm , and its illustrative applications in tv-@xmath10 and tv-@xmath38 problems can be found in @xcite . in this section",
    ", we aim to bridge the gap between our proposed algorithms using split bregman method and admm by constructing one augmented lagrangian adapted to our problem .",
    "then the existing convergence theory for admm can be used to justify our proposed algorithm utilizing the split bregman and quadratic penalties .",
    "we first analyze the algorithm in stage i , and the discussions can be analogously extended to the algorithm [ alg2 ] in stage ii .",
    "based on the problem , we build the augmented lagrangian as below : @xmath127 since the variables @xmath128 s and @xmath129 s are separable in the lagrangian @xmath130 , minimizing @xmath130 over @xmath131 simultaneously can be replaced by minimizing @xmath130 over @xmath128 s and @xmath129 s individually .",
    "thus admm yields @xmath132 by absorbing the linear terms involving @xmath80 s and @xmath81 s into the quadratic terms , it can be simplified as @xmath133 one can see the algorithm derived by admm here is equivalent to algorithm [ alg1 ] by split bregman method with quadratic penalization . the detailed convergence analysis of the algorithm can be found in @xcite . to be complete ,",
    "we present the convergence theorem without the proof .",
    "[ thm1 ] for any @xmath77 and @xmath134 , the sequences @xmath135 generated by from any starting point @xmath136 converges to a solution of problem .",
    "therefore , by choosing appropriate parameter @xmath137 , the proposed algorithm [ alg1 ] provides a convergent solution to the problem .",
    "likewise for the fixed weights @xmath105 s , by replacing @xmath138 with @xmath139 the admm yields a similar algorithm equivalent to algorithm [ alg2 ] and thereby the convergence is guaranteed as well",
    ".    * parameter selection .",
    "* the above theorem only requires @xmath140 , and positive @xmath78 to guarantee convergence . in the perspective of convergence speed",
    ", our experience with a variety of tests shows that @xmath137 restricted in @xmath141 $ ] consistently yields good results . regarding @xmath142 and @xmath143 ,",
    "as they show up in the shrinkage representation of updates for @xmath128 and @xmath129 , an inappropriate selection of them leads to slow convergence .",
    "especially , if @xmath142 and @xmath143 are set too small , the updates for @xmath128 and @xmath129 will dwell in @xmath144 at the first several iterations .",
    "we scale image intensity to @xmath145 $ ] to make the effect of @xmath142 and @xmath143 on convergence speed moderate . @xmath19 and @xmath146",
    "depend on the gradient / shearlet transform sparsity of the underlying image and the noise / error level in the measurements .",
    "implementation details and specific parameter selections will be explained in section [ experiments ] .",
    "in this section , we illustrate the performance of geocs on various images with different sampling rates and noise levels .",
    "we also compare geocs with two recent related cs reconstruction approaches : recpf @xcite and edgecs @xcite .",
    "all experiments were performed under windows 7 professional operating system and matlab r2012a running on a dell desktop with intel core i5 cpu at 3.10 ghz and 8 gb of memory .",
    "recpf iteratively recovers an image from its incomplete fourier samples by solving @xmath147 where @xmath148 can be either isotropic or anisotropic and @xmath5 is wavelet transform .",
    "edgecs alternatively performs image reconstruction and edge detection in a mutually beneficial manner .",
    "it detects edges from the intermediate reconstruction and use edge information to guide the next stage of image reconstruction and so on .",
    "geocs is different from edgecs as analyzed in section [ sec : background ] .",
    "our test images are all piecewise smooth images with a lot of fine details : a human brain mr image , barbara image with textures and a human knee mr image .",
    "the intensity value of each test image is scaled to the range @xmath145 $ ] before simulating @xmath6 .",
    "partial fourier cs data are simulated through fast fourier transform ( fft ) on the test images followed by sampling on smooth radial trajectories that are empirically shown to be effective .",
    "all the quantitative comparisons are based on relative error and signal - to - noise ratio ( snr ) .",
    "relative error is to measure the recovery accuracy and defined as @xmath149 where @xmath17 and @xmath150 are the recovered image and the ground truth , respectively .",
    "considering the independence with the above measure , we adopt the snr defined in @xcite @xmath151 where ( @xmath152 ) represents the componentwise squaring .",
    "for all the experiments , we fix @xmath153 and vary @xmath154 slightly based on the noise level . when there is no noise we set @xmath155 for all of the three images while they are set a little larger in the presence of noise .",
    "the results are not sensitive to the selection of @xmath19 and @xmath146 . for discrete shearlet transform , we adopt ffst @xcite with 3 scales and 13 subbands ( 12 high frequency and one low frequency ) .",
    "the parameter @xmath111 used in tukey bi - weight @xmath109 function in stage ii is set among @xmath156 $ ] . and in each of the following experiment , the total number of iterations used in stage i is less than 1000 and stage ii takes less than 100 iterations to achieve a convergent solution .      in the first example",
    ", we look at the simulated noise - free spectral measurements of a @xmath157 brain mr image .",
    "the ground truth image has inhomogenous contrasts in different areas , especially in the gray matter and cerebrospinal fluid .",
    "we tested the proposed geocs algorithm , recpf and edgecs with 40 radial sampling lines , namely 8.79% sampling rate .",
    "we show the results in fig .",
    "[ fig : test1 ] and zoom in one small patch for better visual comparison .",
    "it s apparent that the image produced by geocs has better quality than the others .",
    "recpf sort of oversmooths the whole image , and edgecs is able to detect the edges while losing some gradual transition between smooth areas and boundaries . to further compare three results , we take the difference between the ground truth and the reconstructed image for each method and display the inverted residue images in fig .",
    "[ fig : test1dif ] .",
    "it s clear that our proposed algorithm suppresses the error more evenly inside the skull .",
    "the three approaches are also compared as the sampling rate changes .",
    "the quantitative comparison listed in table [ table : test1err ] and table [ table : test1snr ] shows that the proposed geocs consistently outperforms the other methods .    [ cols=\"^,^,^,^ \" , ]",
    "we proposed a two - stage compressive sensing image reconstruction algorithm based on shearlet transform and weighted tv .",
    "the first stage is to use standard @xmath37-@xmath10-@xmath38 model with shearlet transform to get an initial guess for the underlying image of interest .",
    "geometric information extracted from this guess serves as an initial a priori in weighted @xmath37-@xmath10-@xmath38 model to further enhance the reconstruction accuracy .",
    "this kind of geometric information extraction and image reconstruction are alternated in a mutually beneficial fashion until it converges .",
    "replacing the conventional wavelet transform with shearlet transform , the model is able to promote the signal sparsity , and preserve multiple directional features better during the recovery .",
    "the spatially variant weights associated to tv plays an important part in preserving sharp edges while reducing staircase effects of tv .",
    "the minimization problem is solved by split bregman which divides one complicated optimization problem with nondifferentiable terms into three sets of subproblem , each of which has closed - form solutions .",
    "convergence of the algorithm is guaranteed under mild conditions .",
    "the proposed approach is compared with two recent related work .",
    "numerical experiments show the consistent overwhelming advantages of our algorithm .    the proposed approach geocs is better than recpf and edgecs in reconstructing complicated piecewise smooth images . however , as for piecewise constant images , it s sufficient to apply one - stage methods . moreover , by adapting the weights to the spatially variant gradients along with two - stage reweighting scheme",
    ", geocs integrates more reliable geometric prior to the reconstruction than edgecs .",
    "our extensive experience shows that the more accurate geometric information is obtained during the algorithm , the better the overall scheme will perform .",
    "but , it is possible that the extracted geometric information is not reliable at all in case of extremely insufficient samples or excessive noise and thereby geocs might fail .",
    "there is still room to study how to extract much more reliable geometric information from noisy incomplete measurements and how to efficiently utilize them .",
    "furthermore , some recent acceleration techniques , e.g. , nesterov s accelerated gradient descent@xcite , can be applied to speed up the convergence .",
    "the authors would like to thank the partial support from the case western reserve university aces+ advance opportunity funds .",
    "glowinski , r. , marroco , a. : sur lapproximation , par elements finis dordre un , et la resolution , par penalisation - dualit , dune classe de problems de dirichlet non lineares .",
    "revue franaise dautomatique , informatique et recherche oprationelle 9(r-2 ) , 41 - 76 ( 1975 ) .",
    "yang , j. , zhang , y. , yin , w. : a fast alternating direction method for tvl1-l2 signal reconstruction from partial fourier data . selected topics in signal processing , ieee journal of , 4(2 ) , 288 - 297 ( 2010 )      cands , e. , donoho , d. : curvelets - a surprisingly effective nonadaptive representation for objects with edges .",
    "curves and surfaces , l. l. schumaker et al .",
    "( eds ) , vanderbilt university press , nashville , tn ."
  ],
  "abstract_text": [
    "<S> in compressive sensing , it is challenging to reconstruct image of high quality from very few noisy linear projections . </S>",
    "<S> existing methods mostly work well on piecewise constant images but not so well on piecewise smooth images such as natural images , medical images that contain a lot of details . </S>",
    "<S> we propose a two - stage method called geocs to recover images with rich geometric information from very limited amount of noisy measurements . </S>",
    "<S> the method adopts the shearlet transform that is mathematically proven to be optimal in sparsely representing images containing anisotropic features such as edges , corners , spikes etc . </S>",
    "<S> it also uses the weighted total variation ( tv ) sparsity with spatially variant weights to preserve sharp edges but to reduce the staircase effects of tv . geometric information extracted from the results of stage i serves as an initial prior for stage ii which alternates image reconstruction and geometric information update in a mutually beneficial way . </S>",
    "<S> geocs has been tested on incomplete spectral fourier samples . </S>",
    "<S> it is applicable to other types of measurements as well . </S>",
    "<S> experimental results on various complicated images show that geocs is efficient and generates high - quality images .    </S>",
    "<S> * keywords : * compressive sensing , shearlet transform , weighted tv , split bregman , admm </S>"
  ]
}