{
  "article_text": [
    "simulational science often involves the generation of configurations from high - dimensional probability distributions as well as the computation of ensemble averages and normalization constants . numerous applications in statistical physics , biomolecular",
    "simulation and bayesian inference illustrate the ubiquitous need for efficient sampling methods .",
    "challenges are posed by the complexity of the system , its shear size , slow convergence and non - ergodicity .    to address these challenges , algorithms that work with modified versions of the system have been proposed .",
    "one idea is to simulate the system at multiple temperatures and utilize the enhanced flexibility at higher temperatures to avoid local free - energy minima at lower temperatures .",
    "this idea is the basis of sampling algorithms such as replica - exchange monte carlo @xcite and simulated tempering @xcite but also used in popular optimization algorithms such as simulated annealing @xcite .",
    "parallel tempering ( pt ) @xcite , for example , considers a family of canonical ensembles at different temperatures .",
    "the ensembles are simulated independently and occasional swaps of configurations between ensembles at nearby temperatures allow the simulation to escape from metastable states . from a pt",
    "simulation thermodynamic quantities such as free energies and heat capacities can then be computed with high accuracy .",
    "but the success and convergence of a pt run depends critically on the choice of the temperature schedule . to choose a good temperature schedule",
    "can be highly non - trivial , especially for systems undergoing phase transitions .",
    "a well - balanced schedule entails overlap between ensembles at neighboring temperatures .",
    "this means that we have to use more and more replicas with increasing system size because energy is extensive @xcite .",
    "moreover , pt explores temperature space on a fixed ladder . if we want to use multiple temperatures or control parameters as in multi - dimensional pt @xcite we are suffering from the curse of dimensionality .",
    "another source of inefficiency is the fact that configurations at high temperatures are constantly being produced but no longer needed once the simulation has converged .",
    "multi - canonical sampling algorithms @xcite are a powerful alternative to annealing methods . rather than utilizing a temperature parameter to modify the system , multi - canonical algorithms draw configurations from an ensemble whose weight is inversely proportional to the density of states ( dos ) of the system , such that ideally the energy histogram will be constant .",
    "however , this requires that we know the dos before the actual simulation , which is rarely the case .",
    "the wang - landau ( wl ) algorithm @xcite is an ingenious variant of multi - canonical sampling that sidesteps this problem .",
    "the unknown density of states is estimated in the course of a wl run , configurational samples are generated as a by - product .",
    "the fact that the correct dos should produce a flat energy histogram can be used to monitor the convergence of the method . by gradually decreasing the learning rate ,",
    "the simulation is stabilized and converges .",
    "wl sampling has originally been developed for discrete systems @xcite .",
    "its direct extension to large or continuous systems requires choosing an energy range and binning .",
    "but there might be forbidden energy levels that can not be visited , in which case the corresponding bins remain empty and the energy histogram will never be flat .",
    "these problems are aggravated for multi - dimensional dos over more than one macrovariable because the number of bins grows exponentially in the number of macrovariables . in that case",
    "flatness of the energy histogram ceases to be a useful convergence criterion and must be replaced by other criteria @xcite . to apply these modifications in practice remains a challenge and involves parameter tweaking .",
    "this article proposes an algorithm , _ ensemble annealing _ , that solves these issues and produces samples and an estimate of the dos .",
    "ensemble annealing is inspired by the nested sampling method for bayesian computation @xcite and can be viewed as a generalization of nested sampling to the canonical or other ensembles .",
    "the algorithm applies both to discrete and continuous systems .",
    "in contrast to simulated annealing or parallel tempering , ensemble annealing constructs an optimal temperature protocol adaptively and has only few algorithmic parameters .",
    "ensemble annealing is a sequential algorithm that steps through iterations denoted by @xmath0 . @xmath1 non - interacting particles or walkers",
    "are employed to explore a series of ensembles typically starting in a high temperature ensemble , then cycling through ensembles at lower and lower temperatures , until the destination ensemble is reached . for each ensemble ,",
    "the walkers produce configurations @xmath2 where @xmath3 .",
    "in contrast to other annealing and tempering methods only the start and final ensemble have to be chosen .",
    "the intermediate ensembles are found during the simulation by placing them such that a constant overlap between successive ensembles is maintained . to implement this approach , we need to agree on various concepts , mainly what kind of ensembles will be considered , and how to measure distances between ensembles .",
    "let us denote the target ensemble from which we aim to generate configurations @xmath4 by @xmath5 .",
    "often @xmath6 with energy @xmath7 . in bayesian inference , for example",
    ", @xmath8 denotes the prior distribution and @xmath9 corresponds to negative log likelihood . in a physical simulation of particles in a box , @xmath8 will be uniform over the box and @xmath10 will be the interaction energy between all particles .",
    "note that in practice both @xmath8 and @xmath5 are often unnormalized .    to draw configurations from @xmath5 we consider a series of ensembles @xmath11\\ , \\pi(x)\\ ] ] where @xmath12\\ , \\pi(x)\\ , { \\mathrm{d}{x}}$ ] normalizes the @xmath0-th ensemble . here , we assume that ensemble @xmath13 depends on the configuration only through the macrovariable @xmath9 , but the method works also for more general ensembles . typically @xmath14 where @xmath15 is a parameterized family and @xmath16 a protocol parameter .",
    "the distributions @xmath17 are intermediate helper or bridging distributions . in case of the canonical ensemble ,",
    "configurations are weighted by the boltzmann factor @xmath18 where @xmath19 is the inverse temperature and @xmath20 is the partition function .",
    "obviously the canonical ensemble is a widespread choice in annealing methods , but it might also be worthwhile to consider other ensembles .",
    "for example , in parallel tempering the use of the tsallis ensemble @xmath21 with control parameter @xmath22 , . because we already use @xmath23 for the bridging ensemble",
    ", we denote the tsallis parameter by @xmath24 .",
    "] inverse temperature @xmath25 and minimum energy @xmath26 has been proposed @xcite .",
    "a multi - parameter combination of the boltzmann and tsallis ensemble is used in complex bayesian data analyses @xcite to independently control the prior density and the likelihood function .",
    "another ensemble that is of potential interest is the fermi distribution @xmath27 which has two control parameters : the inverse temperature @xmath19 and an energy cutoff @xmath28 .",
    "the zero - temperature fermi ensemble approaches a stepfunction , i.e. configurations with energies greater than @xmath28 are assigned zero probability : @xmath29 where @xmath30 is the heaviside step function .",
    "this ensemble is used in the nested sampling method for bayesian computation @xcite and also related to the microcanonical ensemble @xcite : @xmath31 where @xmath32 is the dimension of configuration space ( number of configurational degrees of freedom ) and @xmath28 the total energy of the system ( potential plus kinetic energy ) .",
    "note that the target ensemble @xmath5 does not necessarily need to be a member of the bridging family , i.e. there might be no @xmath33 such that @xmath34 , which is the case , for example , in nested sampling and the microcanonical ensemble .",
    "the density of states ( dos ) over the prior or reference distribution @xmath8 is defined as @xmath35 with @xmath36 denoting the delta function . with the help of the dos",
    "it is straightforward to compute how the energies are distributed in the intermediate ensembles : @xmath37 where @xmath38 is a one - dimensional distribution .      when choosing the intermediate distributions that bridge between the initial and final ensemble , it is essential to control the `` distance '' or overlap between successive ensembles @xmath33 and @xmath39 .",
    "we use the kullback - leibler ( kl ) divergence @xcite or relative entropy @xmath40\\ , { \\mathrm{d}{x}}\\ ] ] for this purpose .",
    "the relative entropy satisfies the gibbs inequality @xmath41 with equality only if @xmath42 and @xmath43 are identical .",
    "therefore the kullback - leibler divergence qualifies as an `` entropic distance '' between ensembles @xmath42 and @xmath43 .",
    "however in contrast to a true distance the kl divergence is not symmetric under interexchange of @xmath42 and @xmath43 .",
    "it is only well - defined if @xmath43 is `` broader '' than @xmath42 , i.e. if the support of @xmath42 is contained in the support of @xmath43 , and therefore a _ directed divergence_. in information theory , the kl divergence is used to quantify information _",
    "gain_.    let us now consider the relative entropy between two members @xmath13 and @xmath44 of the family of bridging distributions [ eq . ( [ eqn : family ] ) ] . with the help of the dos we can reduce the high - dimensional configurational integral [ eq .",
    "( [ eqn : relativeentropy ] ) ] to a one - dimensional integral over the energies : @xmath45 where @xmath46 denotes an average over the @xmath0-th ensemble @xmath13 . for the canonical ensemble [ eq . ( [ eqn : canonical ] ) ] the relative entropy reduces to @xmath47 where @xmath48 is the free energy at inverse temperature @xmath25 .    throughout this article",
    ", we will use the relative entropy to measure the distance between ensembles @xmath49 and @xmath50 .",
    "other measures that quantify the overlap between different ensembles might also be useful .",
    "for example , we could use the exchange rate of a parallel tempering simulation @xmath51 as a measure to compare ensembles . the jensen - shannon divergence @xcite ,",
    "a symmetrized version of the relative entropy , has been used in thermodynamic control @xcite .",
    "the hellinger distance @xcite is a widespread distance used mainly in statistics and may also provide a useful measure for comparing ensembles . in this article , however , we have not explored measures for comparing ensembles other than the relative entropy .    given a continuous bridging family ,",
    "the optimal annealing protocol would involve infinitely many steps ( adiabatic annealing ) .",
    "we want to reach the target ensemble in finitely many steps but produce intermediate ensembles that have a fixed and finite relative entropy @xmath52 .",
    "we will later see that for small @xmath52 this amounts to cooling with constant thermodynamic speed .",
    "as we move from ensemble @xmath13 to the next ensemble @xmath53 we need to evaluate their relative entropy @xmath54 .",
    "equation ( [ eqn : kl ] ) shows that this involves the computation of ensemble averages as well as the estimation of free energy differences .",
    "these are challenging computational problems , which can be solved by the methods outlined in the next subsection .      because the relative entropy [ eq .",
    "( [ eqn : kl ] ) ] both involves the normalization constants @xmath20 , @xmath55 as well as an ensemble average , it is computationally challenging to evaluate @xmath56 accurately .",
    "however , if we know the density of states @xmath57 , the configurational integrals can be reduced to low - dimensional integrals . therefore , ensemble annealing estimates @xmath57 during the course of the simulation , similar to the wang - landau method @xcite or nested sampling @xcite .",
    "the estimation of the dos relies on histogram methods @xcite .",
    "if we work with @xmath1 non - interacting walkers at the @xmath0-th iteration , the configurations are denoted by @xmath2 ( i.e. the first index indicates the ensemble , whereas the second index enumerates the walkers ) . at each ensemble annealing iteration @xmath0 ,",
    "a non - parametric estimate of the dos @xmath58 is updated where @xmath59 are the energies of the visited configurations .",
    "the discrete dos @xmath60 assigns a weight to every configuration @xmath61 that has been generated by the walkers during the entire simulation up to the current ensemble @xmath13 .",
    "that is , the vector of all weights expands in each iteration and is constantly updated ( which is indicated by the superscript ) .    with the help of the estimated dos it is straightforward to compute the relative entropy between two ensembles @xmath13 and @xmath44 : @xmath62 where @xmath63 these relations are used in histogram methods for estimating free energy differences @xcite .",
    "the weights are obtained using the histogram iterations @xmath64 in which each update of the weights @xmath65 is followed by their normalization and a re - evaluation of the partition functions @xmath66 according to eq .",
    "( [ eqn : zestimate ] ) .",
    "we start the iteration from the previous dos estimate ( setting the weights of the new states @xmath2 to zero ) , which speeds up the convergence of the histogram iterations .",
    "the estimated dos serves two purposes : first , to estimate the relative entropy between two ensembles reliably ; second , to initialize the walkers to sample the next ensemble by recycling configurations that have been generated previously , which are then equilibrated in the new ensemble . in the @xmath0-th ensemble annealing iteration ,",
    "ensemble @xmath33 is approximated by @xmath67 we use this approximation to generate @xmath1 initial states for the walkers by the following scheme : first , we draw an energy level according to the probability @xmath68 .",
    "second , we randomly pick one among all configurations that map to the energy drawn in the first step .",
    "in continuous systems , it is very unlikely that two configurations were generated that have exactly matching energies .",
    "however , in discrete systems such as the two - dimensional ising model there are only finitely many energy levels . in this case",
    ", we can speed up the dos estimation [ eqs .",
    "( [ eqn : zestimate ] ) and ( [ eqn : wham ] ) ] by working with histograms as explained in @xcite . due to the limitation of the approximation ( [ eqn : approxensemble ] ) , the @xmath1 recycled states need to be equilibrated in the correct ensemble [ eq . ( [ eqn : family ] ) ] @xmath69 using monte carlo or molecular dynamics simulations .",
    "we have now all tools at hand to formulate the ensemble annealing algorithm .",
    "ensemble annealing is an adaptive sequential monte carlo algorithm .",
    "the main parameters are the number of walkers @xmath1 and the relative entropy @xmath52 between successive ensembles @xmath13 and @xmath53 .",
    "choosing ensembles with a constant relative entropy ensures that the annealing process proceeds at a constant thermodynamic speed .",
    "iteration @xmath0 comprises the following steps :    a.   initialization : using the current estimate of the dos @xmath70 [ eq . ( [ eqn : dosestimate ] ) ] , the particles are initialized by drawing @xmath1 energies @xmath71 from @xmath72 [ eqs .",
    "( [ eqn : ensemble_energy ] ) and ( [ eqn : dosestimate ] ) ] and finding the corresponding configurations @xmath73 by a simple lookup in the energy table such that @xmath74 .",
    "because @xmath75 is only an approximation , the initial states will not be equilibrated .",
    "b.   equilibration : the states are equilibrated in the new ensemble @xmath76 by running monte carlo or molecular dynamics simulations starting from @xmath73 and producing new states @xmath2 . the new configurations and energies @xmath77 are added to the pool of all states visited so far . c.   dos estimation : a new estimate of the dos , @xmath78 , is computed from all energies and temperatures using non - parametric histogram reweighting @xcite . to speed up the convergence ,",
    "the previous dos estimate is used to initialize the iterations .",
    "d.   annealing :",
    "the next ensemble @xmath53 is adjusted such that it has a desired relative entropy @xmath52 with respect to the current ensemble @xmath13 , i.e. @xmath53 satisfies @xmath79 .",
    "the algorithm has only few parameters , namely the initial and final ensemble , the number of walkers @xmath1 and the target relative entropy @xmath52 between successive ensembles .",
    "evidently , @xmath52 determines the cooling or compression rate . for smaller @xmath52",
    "the overlap between successive ensembles is larger and the annealing progresses more slowly .",
    "if we allow @xmath52 to be large , we anneal faster but risk to fail to equilibrate .",
    "let us illustrate ensemble annealing for a simple system , the one - dimensional harmonic oscillator with energy @xmath80 and ground state @xmath81 in the canonical ensemble : @xmath82 the distance between two ensembles at inverse temperatures @xmath25 and @xmath83 , @xmath84 , is : @xmath85\\ ] ] in this case the kl divergence depends only on the ratio between two successive temperatures .",
    "the constant relative entropy criterion yields a constant cooling rate @xmath86 which is determined by @xmath87 this results in the geometric schedule @xmath88 .",
    "for @xmath89 we reach the adiabatic limit of infinitely slow cooling since @xmath90 .",
    "geometric schedules have been proposed for optimal simulated annealing @xcite .",
    "alternatively , we could consider the ground state a control parameter , @xmath91 , and let @xmath92 , @xmath93 with @xmath94 and @xmath95 .",
    "the relative entropy is now according to eq .",
    "( [ eqn : klcanonical ] ) : @xmath96 constant steps in the relative entropy lead to a schedule that is linear in the inverse temperature : @xmath97 . that is , the ground state is shifted either in the positive or the negative direction depending on the targeted ground state .",
    "these examples highlight that it is not sufficient to prescribe the relative entropy to choose the next ensemble",
    ". we must also impose some sense of directionality in order to shift the ensemble closer to the target ensemble .",
    "this will become particularly important in multi - dimensional annealing .",
    "we will now apply annealing of the canonical ensemble to various systems including discrete systems such as ising and potts models and a continuous protein model .      to illustrate ensemble annealing",
    ", we first apply it to a system with a one - dimensional configuration space and a rugged energy function @xmath98 , the one - dimensional schwefel function .",
    "we deliberately choose a large number of walkers for illustrative purposes ( @xmath99 ) ; a smaller number of walkers would be sufficient in this one - dimensional example . at every iteration",
    ", equilibration is achieved by using a random walk metropolis monte carlo scheme @xcite consisting of 10 random steps drawn from a uniform distribution .",
    "the relative entropy is set to @xmath100 .",
    "figure [ fig : schwefel ] shows the configurations at the various temperatures obtained by the constant relative entropy criterion .",
    "we start at @xmath101 and target a final inverse temperature @xmath102 .",
    "as ensemble annealing progresses the walkers become more and more localized in the dominant modes of the target ensemble .",
    "the relative proportions are reproduced accurately .",
    "this example also suggests that it should be possible to prune the number of the walkers during the annealing process . in the course of annealing ,",
    "the ensemble becomes more and more concentrated ( as monitored by a decrease in the entropy @xmath103 ) , and fewer walkers are needed to explore and represent it . using the boltzmann relation @xmath104 where @xmath105 is the number of accessible microstates , we could decrease the number of walkers in each iteration and thereby save computational resources .",
    "however , we have not explored this strategy further in this article .",
    "we now apply ensemble annealing to the two - dimensional ising and potts model .",
    "figure [ fig:1 ] shows simulation results for the @xmath106 lattice .",
    "@xmath107 particles were used and the relative entropy was set to @xmath108 .",
    "the equilibration step consisted of metropolis monte carlo runs that randomly select lattice sites and try to flip the spin ( ising model ) or draw a random color ( potts model ) .",
    "figure [ fig:1](a ) shows how the algorithm improves the initial dos estimate .",
    "the algorithm starts with @xmath1 random spin configurations from which the initial dos covering only a limited energy range is derived .",
    "as the algorithm proceeds , lower energy states are generated and the dos expands into the lower energy region .",
    "this process continues until the full energy range has been explored and a highly accurate estimate of the dos is produced .",
    "the accuracy of the estimated dos is illustrated in fig .",
    "[ fig:1](b )",
    ". the estimation error can be as small as with wl sampling @xcite .",
    "a similar accuracy is also obtained for the ten state potts model which undergoes a first order phase transition .",
    "the dos tends to be more accurate for the low energy states . in most situations",
    "this is desirable because one is primarily interested in the thermodynamic properties of the system at finite temperatures , at which the low energy states contribute most strongly .",
    "ensemble annealing readily applies to continuous systems such as g models that have been used extensively to study protein folding ( see e.g. @xcite ) . in our version of the g model ,",
    "the dihedral angles are the only conformational degrees of freedom ; bond lengths and angles are fixed to ideal values .",
    "the energy function is comprised of a generic non - bonded energy potential and the g term .",
    "the non - bonded energy penalizes atom clashes using the same quartic repulsion term as in ref .",
    "the g term enforces the native structure by imposing a lennard - jones potential on the c@xmath109 distances between residues in contact in the native state . the inverse temperature @xmath25 serves as the control parameter in ensemble annealing runs .",
    "as in ref .",
    "@xcite , we used hybrid monte carlo @xcite for equilibration .",
    "we seeded the simulation with 100 random structures and annealed an ensemble of @xmath110 structures ; the relative entropy was set to @xmath108 . for reference , we also ran a parallel tempering simulation of the g model using 37 temperatures . the dos obtained with ensemble annealing",
    "was used to optimize the temperatures to produce an exchange rate of 48% on average .",
    "10000 replica transitions were simulated and an estimate of the dos was obtained by running histogram reweighting .",
    "we studied the g model derived for a small protein domain , the 59 amino - acid fyn - sh3 domain ( pdb code 1shf ) .",
    "figure [ fig : go](a ) shows the density of states obtained with ensemble annealing and compares it to the reference computed with an exhaustive parallel tempering simulation .",
    "the agreement is very high over the entire energy range . in figure",
    "[ fig : go](b ) we study the characteristics of the g model as revealed by ensemble annealing .",
    "shown is the average number of native contacts @xmath111 as a function of the inverse temperature .",
    "the folding transition is marked by a sudden increase in the number of native contacts .",
    "the heat capacity peaks at @xmath112 indicating a folding temperature of roughly @xmath113 .",
    "we will now have a closer look at the schedules constructed by ensemble annealing and compare them to other schedules that have been proposed in the literature .",
    "moreover , we discuss the possibility to use ensemble annealing as a numerical method to construct near - optimal thermodynamic paths .",
    "figure [ fig:2 ] shows the energy histograms and temperature schedule found by ensemble annealing for the ten state potts model . by way of construction of the schedule ,",
    "the energy histograms of successive ensembles have a constant overlap ( fig . [ fig:2](a ) ) .",
    "the temperature schedule is non - trivial and deviates from the linear , geometric , and logarithmic schedules that have been proposed in the literature @xcite .",
    "initially , the inverse temperatures grow sublinearly . in this phase ,",
    "the schedule constructed by ensemble annealing is reminiscent of the logarithmic schedule proposed by geman and geman @xcite , i.e. @xmath114 . as ensemble annealing approaches the critical temperature , the cooling rate it slowed down automatically such that the system is not quenched and avoids being trapped in a metastable state . beyond the critical point ,",
    "the temperatures show a super - exponential increase ( fig . [ fig:2](b ) ) .",
    "salamon and co - workers have proposed an adaptive version of simulated annealing more than two decades ago @xcite .",
    "their algorithm finds the temperature schedule by minimizing the entropy production whereupon the temperature changes inversely proportional to the square root of the heat capacity .",
    "this rule follows directly from the constant relative entropy criterion . for small changes in inverse temperature",
    ", we have @xmath115 where @xmath116 is proportional to the heat capacity @xmath117 .",
    "if the desired relative entropy @xmath52 is small , the increment in inverse temperature is @xmath118 integration over the inverse temperature increments @xmath119 generates a schedule that is very close to the one found by ensemble annealing at finite @xmath52 ( fig . [ fig:2](b ) ) .",
    "comparison with the schedule derived by salamon _",
    "shows that @xmath120 is proportional to the thermodynamic speed of the annealing process . in the context of bayesian computation ,",
    "similar , but independent arguments have been put forward by skilling @xcite who uses @xmath52 to control the rate of compression as the system moves from the prior to the posterior probability .    from a practical point of view",
    ", an ensemble annealing run can be used to seed a parallel tempering simulation that has a well - balanced schedule and equilibrated initial states .",
    "the right panel in fig .",
    "[ fig:2](b ) illustrates that the exchange rates are indeed uniform for a pt simulation when using every fifth temperature of the ensemble annealing schedule . a drop in the swap rate",
    "is only observed close to the critical temperature where the heat capacity peaks .",
    "let us now see if the results of the previous section generalize to multiple temperatures . although ensemble annealing can be applied to any family of bridging distributions [ eq . ( [ eqn : family ] ) ] , let us focus on parametric families of the form @xmath121\\ , \\pi(x)\\ ] ] where @xmath16 denotes the vector of all control parameters .",
    "the second order expansion of the relative entropy is @xcite : @xmath122 where the zero and first order term vanish because @xmath123 and @xmath124 is the global minimum of @xmath125 viewed as a function of @xmath126 .",
    "because the fisher information matrix @xmath127[\\nabla_\\lambda \\ln p(x|\\lambda)]^t\\ , p(x|\\lambda)\\ , { \\mathrm{d}{x}}\\ ] ] is positive definite , it defines a metric on the space of distributions parameterized by @xmath16 .",
    "equation ( [ eqn : dkl ] ) is a special case of the general relation ( [ eqn : klexpansion ] ) for the boltzmann ensemble with a single temperature , where the fisher information is simply @xmath128 .    in statistics , the fisher metric has been studied since the beginnings of information geometry .",
    "the fisher information can also be used to define a thermodynamic length and action ( see @xcite and references therein ) .",
    "quasistatic processes that switch between two thermodynamic states follow minimal dissipation paths in @xmath16 space .",
    "these can be computed by minimizing the thermodynamic length ( see , for example , @xcite ) .",
    "therefore , the optimal path is a geodesic on the riemanian manifold equipped with the fisher information metric .",
    "very similar results have been presented by gelman and meng in their work on bridge and path sampling @xcite .    by taking constant but finite steps in relative entropy followed by an equilibration ,",
    "ensemble annealing approximates a quasistatic process .",
    "after @xmath129 successful equilibrations , the relative entropy accumulated during ensemble annealing is @xmath130 and approximates the thermodynamic action due to eq .",
    "( [ eqn : klexpansion ] ) .",
    "if we aim to optimize the use of computing resources , we have to minimize @xmath129 , the number of bridging distributions . for a single control parameter",
    "this is straightforward : we have to follow the geodesic towards the destination ensemble . in the canonical ensemble , for example ,",
    "if the destination temperature is lower than the initial temperature ( annealing ) , we have to increase @xmath25 such that @xmath131 also for all intermediate temperatures . for ensembles with multiple control parameters the situation is more complicated because minimizing the accumulated relative entropy [ eq .",
    "( [ eqn : length ] ) ] requires the computation of a discrete geodesic .",
    "however the dos is generally unknown , and we can compute @xmath132 only in the vicinity of the current state .",
    "it is not possible to evaluate reliably the length of an entire path connecting the initial and the destination ensemble .",
    "we can only search locally without any guarantee that the generated path is close to the geodesic .",
    "a major advantage of using the boltzmann distribution ( [ eqn : canonical ] ) as bridging family is that many powerful methods to simulate the canonical ensemble exist .",
    "we can use these algorithms in the equilibration step .",
    "but it can be beneficial to consider also other ensembles , because they might bridge more efficiently between the initial and final ensemble .",
    "the tsallis ensemble has been used previously in combination with parallel tempering @xcite . the motivation for",
    "this choice is that due to the heavier tails of the tsallis ensemble replicas have a larger overlap and can exchange states even if they show large energy differences . as a consequence , the number of intermediate replicas should be smaller than with the boltzmann ensemble .",
    "this is indeed confirmed by an analysis of the @xmath106 ising model .",
    "test calculations based on the correct dos show that the canonical ensemble requires 273 @xmath19 to reach the destination ensemble ( @xmath102 ) at a relative entropy of @xmath108 , whereas the tsallis ensemble needs only 85 @xmath24 values to bridge between @xmath133 ( corresponding to a very high canonical temperature ) and @xmath134 .",
    "however , in practice this apparent advantage does not hold up .",
    "the reason is that the tsallis ensemble typically yields multimodal energy distributions at intermediate @xmath24 . to see this",
    "let us first consider the more general case where a parametric bridging family @xmath15 is used . according to eq .",
    "( [ eqn : ensemble_energy ] ) the energy distribution at @xmath16 is proportional to @xmath135 and peaks at @xmath136 solving : @xmath137 where @xmath138 and @xmath139 are the microcanonical entropy and inverse temperature . in case of the canonical ensemble ,",
    "this equation is simply @xmath140 , that is the energy distribution peaks at the energy @xmath136 whose microcanonical temperature matches the canonical temperature . in case of the tsallis ensemble ( [ eqn : tsallis ] )",
    ", we have : @xmath141 this equation can have multiple solutions depending on @xmath109 and @xmath142 , which is why it is difficult to get annealing of the tsallis ensemble running in a stable fashion .",
    "not only the control parameter @xmath109 , but also the minimum energy @xmath142 plays a critical role ( see fig . [",
    "fig : tsallis ] ) .",
    "if @xmath142 is exactly set to the energy of the ground state @xmath143 , the energy distribution of the ising model becomes bimodal with a sharp peak around the ground state energy and a second peak corresponding to high temperatures .",
    "that is , in order to generate samples from this ensemble we have to simulate two phases simultaneously . as a consequence",
    "the dos estimate produced by ensemble annealing shows systematic errors ( fig .",
    "[ fig : tsallis](b ) ) , despite producing an efficient schedule with 103 bridging distributions .",
    "if we lower @xmath142 , the phase separation is less dramatic and consequently the dos estimate is as accurate as with the boltzmann ensemble .",
    "but we also lose the efficiency of the tsallis ensemble in bridging large energy differences , which is reflected in the larger number of @xmath24 : 230 @xmath24 for @xmath144 which is similar to the 270 temperatures produced by boltzmann annealing .",
    "this shows that @xmath142 is an additional algorithmic parameter which is delicate to choose .",
    "nested sampling has been invented by skilling @xcite to solve bayesian inference problems .",
    "bayesian inference demands that we draw from a posterior distribution @xmath5 and compute its normalization constant , which are essentially the tasks that ensemble annealing addresses . in bayesian inference",
    "@xmath8 is the prior , @xmath145 the likelihood function ; the destination ensemble that we aim to characterize is the posterior distribution over some inference parameter(s ) @xmath4 .",
    "nested sampling is based on the microcanonical ensemble @xmath146 [ eq .",
    "( [ eqn : nested ] ) ] ; the control parameter @xmath147 is the maximum energy that the system is allowed to reach @xcite .",
    "therefore nested sampling can be viewed as a special case of ensemble annealing based on a zero - temperature fermi or the microcanonical ensemble .",
    "the relative entropy between two ensembles [ eq . ( [ eqn : kl ] ) ] with energy levels @xmath148 simplifies to : @xmath149\\ ] ] where the normalization constant @xmath150 is the cumulative dos or configuration space volume . from a bayesian point of view",
    ", @xmath151 is the prior mass enclosed by the likelihood contour @xmath152 .",
    "the control parameter is reduced from infinity to the energy of the ground state @xmath142 .",
    "there are several differences between nested sampling and annealing of the ensemble ( [ eqn : nested ] ) using @xmath147 as control parameter .",
    "these differences result from the fact that all of the features that ensemble annealing aims to implement explicitly are built - in to nested sampling .",
    "in fact , nested sampling s design principles served as a guide to develop the ensemble annealing algorithm .",
    "ensemble annealing uses histogram methods to estimate the dos , whereas nested sampling utilizes _ order statistics _ due to the special form the of truncated ensemble ( [ eqn : nested ] ) . as a consequence of the truncation , @xmath153 will be uniformly distributed over @xmath38 ( defined for @xmath154 ) , which is clear from eq .",
    "( [ eqn : ensemble_energy ] ) . to @xmath153 where @xmath153 is the cumulative distribution function of @xmath155",
    "is called _",
    "probability transform_. it is a basic mathematical fact that if @xmath10 follows @xmath155 , @xmath153 will be uniformly distributed over @xmath156 $ ] .",
    "] therefore the configuration space volume associated with the maximum energy state follows the distribution @xmath157 where @xmath158 and @xmath159 is the maximum energy among all @xmath1 walkers .",
    "based on this result from order statistics , nested sampling estimates @xmath153 at well - dispersed energy cutoffs @xmath28 .",
    "another elegant feature of nested sampling is that if @xmath160 , the next ensemble achieving a compression of @xmath52 is the one in which the energy is bounded by @xmath161 .",
    "this results from the fact that @xmath162 where the average is over the beta distribution @xmath163 .",
    "therefore the search for the next control parameter will simply yield @xmath164 , and we only have to resample the state with the highest energy .",
    "although nested sampling is much more efficient at cooling the truncated ensemble ( [ eqn : nested ] ) , it is also possible to run the ensemble annealing algorithm .",
    "both methods produce comparable sequences of energy levels @xmath28 for the @xmath165 ising model with @xmath107 and @xmath166 ( see fig .",
    "[ fig : ns ] ) .",
    "also the estimated dos is of similar accuracy . for this example , nested sampling runs at a speed that is three orders of magnitude faster than ensemble annealing .",
    "this is due to the fact that dos estimation and annealing ( i.e. the choice of the next energy limit ) are instantaneous in nested sampling , because they are built - in to the method .",
    "ensemble annealing , on the contrary , needs to run the histogram iterations for every energy contour .",
    "the histogram iterations converge only very slowly .",
    "each iteration is dominated by dos estimation because equilibration of the ising model is very fast . for other systems such as proteins",
    "it will be the equilibration step rather than dos estimation that consumes most of the computation time .",
    "in this situation , the discrepancy between nested sampling and ensemble annealing will not be as dramatic as for the ising model .    for the @xmath32-dimensional harmonic oscillator we have @xmath167 and @xmath168 .",
    "as in the canonical ensemble , the relative entropy depends on the ratio of two successive control parameters : @xmath169 .",
    "therefore nested sampling and ensemble annealing progress geometrically according to @xmath170 where @xmath171 .",
    "let us compare this to the thermal approach using the inverse temperature as a control parameter .",
    "the compression rate of the canonical distribution is given by @xmath172 [ eq . ( [ eqn : canonicalrate ] ) ] .",
    "therefore @xmath173 where @xmath174 and @xmath175 are the compression rates of thermal and microcanonical annealing .",
    "rewritten we have @xmath176 , and therefore @xmath177 .",
    "this means that annealing the canonical ensemble compresses faster than annealing the microcanonical ensemble .",
    "we observe this for the application to the ising model ( fig .",
    "[ fig : ns ] ) .",
    "canonical annealing with @xmath107 walkers and a relative entropy of @xmath178 requires only 42 iterations to reach the destination ensemble .",
    "microcanonical annealing and nested sampling , on the contrary , need approximately 1800 iterations until convergence .",
    "the reason for this is that states accumulate at the maximum energy @xmath147 , and therefore nested sampling and microcanonical annealing will produce many intermediate ensembles in order to bridge between the initial and the destination ensemble .",
    "ensemble annealing is a monte carlo algorithm that steps through a sequence of ensembles and generates conformational samples .",
    "along with the samples , it also estimates the density of states using histogram methods . the ensembles are placed in an adaptive manner so as to maintain a constant , pre - chosen relative entropy between successive ensembles .",
    "ensemble annealing can be applied to a variety of bridging distributions , foremost the canonical ensemble but also to non - boltzmann families such as the tsallis or the microcanonical ensemble .",
    "there is a close connection to the nested sampling algorithm .",
    "in fact , ensemble annealing aims to implement the features that are built - in to nested sampling : control of the compression or thermodynamic speed , as well as reliable estimation of the compression based on the dos or the configuration space volume .",
    "nested sampling is intimately tied to the truncated ensemble ( [ eqn : nested ] ) , whereas ensemble annealing is more general in the choice of the ensemble itself , which can help to speed up the simulation and allows the use of samplers that work efficiently with a particular ensemble ( such as , for example , hybrid monte carlo in the canonical ensemble ) .",
    "ensemble annealing is also related to previous work by salamon and co - workers @xcite on simulated annealing .",
    "our approach is more general and gives richer results because it not only finds the system s ground state but reconstructs the entire dos . that way ensemble annealing can be used to both simulate thermodynamic systems and solve difficult optimization problems . by means of the dos ,",
    "all visited states contribute to the computation of ensemble averages making our approach more robust .",
    "moreover , it is possible to work with multiple control parameters , which will be studied in future extensions of ensemble annealing ."
  ],
  "abstract_text": [
    "<S> algorithms for simulating complex physical systems or solving difficult optimization problems often resort to an annealing process . rather than simulating the system at the temperature of interest , </S>",
    "<S> an annealing algorithm starts at a temperature that is high enough to ensure ergodicity and gradually decreases it until the destination temperature is reached . </S>",
    "<S> this idea is used in popular algorithms such as parallel tempering and simulated annealing . </S>",
    "<S> a general problem with annealing methods is that they require a temperature schedule . </S>",
    "<S> choosing well - balanced temperature schedules can be tedious and time - consuming . </S>",
    "<S> imbalanced schedules can have a negative impact on the convergence , runtime and success of annealing algorithms . </S>",
    "<S> this article outlines a unifying framework , ensemble annealing , that combines ideas from simulated annealing , histogram reweighting and nested sampling with concepts in thermodynamic control . </S>",
    "<S> ensemble annealing simultaneously simulates a physical system and estimates its density of states . </S>",
    "<S> the temperatures are lowered not according to a prefixed schedule but adaptively so as to maintain a constant relative entropy between successive ensembles . after each step on the temperature ladder an estimate of the density of states </S>",
    "<S> is updated and a new temperature is chosen . </S>",
    "<S> ensemble annealing is highly practical and broadly applicable . </S>",
    "<S> this is illustrated for various systems including ising , potts , and protein models . </S>"
  ]
}