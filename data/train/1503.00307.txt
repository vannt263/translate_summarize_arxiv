{
  "article_text": [
    "many engineering applications revolve around the task of identifying a configuration that in some sense best fits certain objective criteria under certain constraints . such design or optimization problems typically involve ( sometimes many ) _ parameters _ that need to be chosen so as to satisfy given optimality criteria .",
    "an optimization over such a parameter domain usually requires a frequent evaluation of the states under consideration which typically means to frequently solve a _",
    "parameter dependent _ family of operator equations @xmath1 in what follows the parameter set @xmath2 is always assumed to be a compact subset of @xmath3 for some fixed @xmath4 and @xmath5 should be thought of as a ( linear ) partial differential operator whose coefficients depend on the parameters @xmath6 .",
    "moreover , @xmath5 is viewed as an operator taking some hilbert space @xmath7 one - to - one and onto the _ normed dual _",
    "@xmath8 of some ( appropriate ) hilbert space @xmath9 where @xmath7 and @xmath9 are identified through a variational formulation of as detailed later , see for instance .",
    "recall also that the normed dual @xmath8 is endowed with the norm @xmath10 where @xmath11 denotes the dual pairing between @xmath9 and @xmath8 .    given a parametric model the above mentioned design or optimization problems concern now the _ states _",
    "@xmath12 which , as a function of the parameters @xmath6 , form what we refer to as the _ solution manifold _",
    "@xmath13 examples of arise , for instance , in geometry optimization when a transformation of a variable finitely parametrized domain to a reference domain introduces parameter dependent coefficients of the underyling partial differential equation ( pde ) over such domains , see e.g. @xcite .",
    "parameters could describe conductivity , viscosity or convection directions , see e.g. @xcite . as an extreme case ,",
    "parametrizing the random diffusion coefficients in a stochastic pde e.g. , by karhunen - loew or polynomial chaos expansions , leads to a deterministic parametric pde involving , in principle , even _ infinitely _ many parameters , @xmath14 , see e.g. @xcite and the literature cited there .",
    "we will , however , not treat this particular problem class here any further since , as will be explained later , it poses different conceptual obstructions than those in the focus of this paper , namely the absence of ellipticity which makes conventional strategies fail . in particular , we shall explain why for other relevant problem classes , e.g. those dominated by transport processes , @xmath15 is not `` as visible '' as for elliptic problems and how to restore `` full visibility '' .",
    "a conventional way of searching for a specific state in @xmath15 or optimize over @xmath15 is to compute approximate solutions of possibly for a large number of parameters @xmath16 .",
    "such approximations would then reside in a sufficiently large trial space @xmath17 of dimension @xmath18 , typically a finite element space .",
    "ideally one would try to assure that @xmath19 is large enough to warrant sufficient accuracy of whatever conclusions are to be drawn from such a discretization .",
    "a common terminology in reduced order modeling refers to @xmath19 as the _ truth space _ providing accurate computable information .",
    "of course , each such parameter query in @xmath19 is a computationally expensive task so that many such queries , especially in an online context , would be practically infeasible . on the other hand ,",
    "solving for each @xmath20 a problem in @xmath19 would just treat each solution @xmath21 as some `` point '' in the infinite dimensional space @xmath7 , viz . in the very large finite dimensional space @xmath19 .",
    "this disregards the fact that all these points actually belong to a possibly much thinner and more coherent set , namely the low dimensional manifold @xmath15 which , for compact @xmath2 and well posed problems , is compact .",
    "moreover , if the solutions @xmath21 , as functions of @xmath6 , depend smoothly on @xmath16 there is hope that one can approximate all elements of @xmath15 uniformly over @xmath2 with respect to the hilbert space norm @xmath22 by a relatively small but judiceously chosen linear space @xmath23 .",
    "here `` small '' means that @xmath24 is significantly smaller than @xmath25 , often by orders of magnitude . as detailed",
    "later the classical notion of _ kolmogorov @xmath0-widths _ quantifies how well a compact set in a banach space can be approximated in the corresponding banach norm by a linear space and therefore can be used as a _ benchmark _ for the effectiveness of a model reduction strategy .",
    "specifically , the core objective of the _ reduced basis method _ ( rbm ) is to find for a given _ target accuracy",
    "_ @xmath26 a possibly small number @xmath27 of basis functions @xmath28 whose linear combinations approximate each @xmath29 within accuracy at least @xmath26 .",
    "this means that ideally for each @xmath6 one can find coefficients @xmath30 such that the expansion @xmath31 satisfies @xmath32 thus , projecting into the small space @xmath33 reduces each parameter query to solving a small @xmath34 system of equations where typically @xmath35 .",
    "recall that the actual goal of reduced modeling is often not to recover the full fields @xmath36 but only some _ quantity of interest _",
    "@xmath37 typically given as a _ functional _ @xmath38 of @xmath21 where @xmath39 .",
    "asking just the value of such a functional is possibly a weaker request than approximating all of @xmath21 in the norm @xmath22 . in other words ,",
    "one may have @xmath40 without insisting on the validity of for a tolerance of roughly the same size .",
    "of course , one would like to exploit this in favor of online efficiency .",
    "duality methods as used in the context of _ goal - oriented _ finite element methods @xcite are indeed known to offer ways of economizing the approximate evaluation of functionals .",
    "such concepts apply in the rbm context as well , see e.g. @xcite . however , as we shall point out later , guaranteeing that @xmath40 holds for @xmath6 , ultimately reduces to tasks of the type as well .",
    "so , in summary , understanding how to ensure for possibly small @xmath41 remains the core issue and therefore guides the subsequent discussions .",
    "postponing for a moment the issue of how to actually compute the @xmath42 , it is clear that they should intrinsically depend on @xmath15 rendering the whole process highly nonlinear . to put the above approach first into perspective ,",
    "viewing @xmath43 as a function of the spatial variables @xmath44 and of the parameters @xmath16 , is just _ separation of variables _ where the factors @xmath30 , @xmath45 are a priori unknown .",
    "it is perhaps worth stressing though that , in contrast to other attempts to find good _ tensor approximation _ , in the rbm context explicit representations are only computed for the spatial factors @xmath42 while for each @xmath16 the weight @xmath30 has to be _ computed _ by solving a small system in the reduced space @xmath23 .",
    "thus , the computation of @xmath46 could be interpreted as _ dictionary learning _ and , loosely speaking , @xmath27 being relatively small for a given target accuracy , means that all elements in @xmath15 are _ approximately sparse _ with respect to the dictionary @xmath47 .",
    "the methodology just outlined has been pioneered by y. maday , t.a .",
    "patera and collaborators , see e.g. . as indicated before , rbm is one variant of a _ model oder reduction _ paradigm that is specially tailored to parameter dependent problems . among its distinguishing constituents one can name the following .",
    "there is usually a careful division of the overall computational work into an _",
    "offline phase _ , which could be computationally intense but should remain managable , and an _ online phase _ which should be executable with highest efficiency taking advantage of a precomputed basis and matrix assemblations during the offline phase .",
    "it is important to note that while the offline phase is accepted to be computationally expensive it should remain _ offline - feasible _ in the sense that a possibly extensive search over the parameter domain @xmath2 in the offline phase requires for each query solving only problems in the small reduced space .",
    "under which circumstances this is possible and how to realize such division concepts has been worked out in the literature , see e.g. @xcite .",
    "here we are content with stressing that an important role is played by the way how the operator @xmath5 depends on the parameter @xmath16 , namely in an _ affine _ way as stated in later below .",
    "second , and this is perhaps the most distinguishing constituent , along with each solution in the reduced model one strives to provide a _ certificate _ of accuracy , i.e. , computed bounds for incurred error tolerances @xcite .",
    "when trying to quantify the performance of such methods aside from the above mentioned structural and data organization aspects , among others , the following questions come to mind :    \\(i ) for which type of problems do such methods work very well in the sense that @xmath41 in grows only slowly when @xmath26 decreases ?",
    "this concerns quantifying the sparsity of solutions .",
    "\\(ii ) how can one compute reduced bases @xmath46 for which @xmath41 is _ nearly minimal _ in a sense to be made precise below ?",
    "of course , the better the sparsity quantified by ( i ) the better could be the pay - off of an rbm .",
    "however , as one my expect , an answer to ( i ) depends strongly on the problem under consideration .",
    "this is illustrated also by the example presented in  [",
    "ssec : numerical ] .",
    "question ( ii ) , instead , can be addressed independently of ( i ) in the sense that , no matter how many basis functions have to be computed in order to meet a given target accuracy , can one come up with methods that guarantee generating a _ nearly minimal number _ of such basis functions ?",
    "this has to do with _ how to sample _ the solution manifold and is the central theme in this paper .",
    "the most prominent way of generating the reduced bases is a certain _ greedy sampling _ of the manifold @xmath15 . contriving _",
    "greedy sampling strategies _ that give rise to reduced bases of nearly minimal length , in a sense to be made precise below , also for _ non - coercive or unsymmetric singularly perturbed problems _ is the central objective in this paper .",
    "we remark though that a greedy parameter search in its standard form is perhaps not suitable for very high dimensional parameter spaces without taking additional structural features of the problem into account .",
    "the subsequent discussions do therefore not target specifically the large amount of recent work on stochastic elliptic pdes , since while greedy concepts are in principle well understood for elliptic problems they are per se not necessarily adequate for infinitely many parameters without exploiting specific problem dependent structural information .",
    "first , we recall in  [ sec : greedy ] a _ greedy space growth _ paradigm commonly used in all established rbms . to measure its performance in the sense of ( ii )",
    "we follow @xcite and compare the corresponding distances @xmath48 to the smallest possible distances achievable by linear spaces of dimension @xmath0 , called _ kolmogorov @xmath0-widths_. the fact that for _ elliptic problems _ the convergence rates for the greedy errors are essentially those of the @xmath0-width , and hence _ rate - optimal _ , is shown in  [ sect : growth ] to be ultimately reduced to analyzing so called _ weak greedy algorithms _ in hilbert spaces , see also @xcite . however , for indefinite or strongly unsymmetric and singularly perturbed problems this method usually operates far from optimality .",
    "we explain why this is the case and describe in  [ sec : proj ] a remedy proposed in @xcite .",
    "a pivotal role is played by certain _",
    "well - conditioned variational formulations _ of which are then shown to lead again to an optimal _ outer greedy _ sampling strategy also for non - elliptic problems .",
    "an essential additional ingredient consists of certain stabilizing _ inner greedy loops _ , see  [ sec : d - greedy ] .",
    "the obtained rate - optimal scheme is illustrated by a numerical example addressing convection dominated convection - diffusion problems in  [ ssec : numerical ] .",
    "we conclude in  [ sec : duality ] with applying these concepts to the efficient evaluation of quantities of interest .",
    "the by far most prominent strategy for constructing reduced bases for a given parameter dependent problem is the following greedy procedure , see e.g. @xcite .",
    "the basic idea is that , having already constructed a reduced space @xmath23 of dimension @xmath0 , find an element @xmath49 in @xmath15 that is farthest away from the current space @xmath23 , i.e. , that maximizes the best approximation error from @xmath23 and then grow @xmath23 by setting @xmath50 .",
    "hence , denoting by @xmath51 the @xmath7-orthogonal projection onto @xmath23 , @xmath52 unfortunately , determining such an exact maximizer is computationally way too expensive even in an offline phase because one would have to compute for a sufficiently dense sampling of @xmath2 the exact solution @xmath21 of in @xmath7 ( in practice in @xmath19 ) .",
    "instead one tries to construct more efficiently computable _ surrogates _",
    "@xmath53 satisfying @xmath54 recall that `` efficiently computable '' in the sense of offline - feasibility means that for each @xmath55 , the surrogate @xmath53 can be evaluated by solving only a problem of size @xmath0 in the reduced space @xmath23 . deferring an explanation of the nature of such surrogates , algorithm",
    "[ alg : greedy ] described below is a typical offline - feasible _ surrogate based greedy algorithm _ ( sga ) . clearly , the maximizer in below is not necessarily unique . in case",
    "several maximizers exist it does not matter which one is selected .",
    "set @xmath56 , @xmath57 , @xmath58    strictly speaking , the scheme sga is still idealized since : + ( a ) computations can not be carried out in @xmath7 ; + ( b ) one can not parse through all of a continuum @xmath2 to maximize @xmath53 .",
    "+ concerning ( a ) , as mentioned earlier computations in @xmath7 are to be understood as synonymous to computations in a sufficiently large truth space @xmath19 satisfying all targeted accuracy tolerances for the underlying application . solving problems in @xmath19",
    "is strictly confined to the offline phase and the number of such solves should remain of the order of @xmath59 .",
    "we will not distinguish in what follows between @xmath7 and @xmath19 unless such a distinction matters .",
    "as for ( b ) , the maximization is usually performed with the aid of a complete search over a _",
    "discrete _ subset of @xmath2 .",
    "again , we will not distinguish between a possibly continuous parameter set and a suitable training subset .",
    "in fact , continuous optimization methods that would avoid a complete search have so far not proven to work well since each greedy step increases the number of local maxima of the objective functional .",
    "now , how fine such a discretization for a complete search should be depends on how smoothly the @xmath21 depend on @xmath16 .",
    "but even when such a dependence is very smooth a coarse discretization of a _ high - dimensional _ parameter set @xmath2 would render a complete search infeasible so that , depending on the problem at hand , one has to resort to alternate strategies such as , for instance , random sampling .",
    "however , since it seems that ( b ) can only be answered for a specific problem class we will not address this issue in this paper any further .    instead",
    ", we focus on general principles which guarantee the following . loosely speaking the reduced spaces based on sampling @xmath15 should perform _ optimally _ in the sense that the resulting spaces @xmath23 have the ( near ) `` smallest dimension '' needed to satisfy a given target tolerance while the involved offline and online cost remains feasible in the sense indicated above .",
    "to explain first what is meant by `` optimal '' let us denote the _ greedy error _ produced by sga as @xmath60 note that if we replaced in the space @xmath23 by _ any _ linear subspace @xmath61 and infimize the resulting distortion over _ all _ subspaces of @xmath7 of dimension at most @xmath0 , one obtains the classical _ kolmogorov @xmath0-widths _ @xmath62 quantifying the `` thickness '' of a compact set , see .",
    "one trivially has @xmath63 of course , it would be best if one could reverse the above inequality .",
    "we will discuss in the next section to what extent this is possible .    to prepare for such a discussion we need more information about how the surrogate @xmath53 relates to the actual error @xmath64",
    "because the surrogate drives the greedy search and one expects that the quality of the snapshots found in sga depends on how `` tight '' the upper bound in is .    to identify next the essential conditions on a `` good '' surrogate it is instructive to consider the case of _ elliptic _ problems . to this end ,",
    "suppose that @xmath65 is a uniformly @xmath7-coercive bounded bilinear form and @xmath66 , i.e. , there exist constants @xmath67 such that @xmath68 holds uniformly in @xmath6 .",
    "the operator equation is then equivalent to : given @xmath69 and a @xmath6 , find @xmath12 such that @xmath70 ellipticity has two important well - known consequences .",
    "first , since implies @xmath71 , @xmath72 the operator @xmath73 has a finite condition number @xmath74 which , in particular , means that residuals in @xmath75 are uniformly comparable to errors in @xmath7 @xmath76 second , by ca s lemma , the galerkin projection @xmath77 onto @xmath23 is up to a constant as good as the _ best approximation _ ,",
    "i.e. , under the assumption @xmath78 ( when @xmath79 is in addition symmetric @xmath80 can be replaced by @xmath81 . ) hence , by and , @xmath82 statisfies more than just , namely it provides also a uniform _ lower bound _",
    "@xmath83 finally , suppose that @xmath79 depends _ affinely _ on the parameters in the sense that @xmath84 where the @xmath85 are smooth functions of @xmath55 and the bilinear forms @xmath86 are independent of @xmath16 .",
    "then , based on suitable precomputations ( in @xmath19 ) in the offline phase , the computation of @xmath87 reduces for each @xmath55 to the solution of a rapidly assembled @xmath88-system , and @xmath53 can indeed be computed very efficiently , see @xcite .",
    "an essential consequence of and can be formulated as follows .",
    "[ prop : weakgreedy ] given @xmath89 , the function @xmath90 generated by for @xmath53 defined by , has the property that @xmath91    hence , maximizing the residual based surrogate @xmath53 ( over a suitable discretization of @xmath2 ) is a computationally feasible way of determining , up to a fixed factor @xmath92 , the maximal distance between @xmath15 and @xmath23 and performs in this sense almost as well as the `` ideal '' but computationally infeasible surrogate @xmath93 .",
    "+ * proof of proposition [ prop : weakgreedy ] : * suppose that @xmath94 , @xmath95 so that @xmath96",
    ". then , keeping and in mind , we have @xmath97 where we have used in the second but last step .",
    "this confirms the claim . @xmath98",
    "+ property turns out to play a key role in the analysis of the performance of the scheme sga .",
    "proposition [ prop : weakgreedy ] allows us to view the algorithm sga as a special instance of the following scenario .",
    "given a compact subset @xmath99 of a hilbert space @xmath100 with inner product @xmath101 inducing the norm @xmath102 , consider the _ weak greedy _ algorithm [ alg : wgreedy ] ( wga ) below .",
    "set @xmath103 , @xmath57 , @xmath104 , fix any @xmath105 , given @xmath106 , choose some @xmath107 for which @xmath108 and set @xmath109 .    note that again the choice of @xmath90 is not necessarily unique and what follows holds for _ any _ choice satisfying .",
    "greedy strategies have been used in numerous contexts and variants .",
    "the current version is not to be confused though with the _ weak orthogonal greedy algorithm _ introduced in @xcite for _ approximating _ a _ function _ by a linear combination of @xmath0 terms from a _ given _ dictionary .",
    "in contrast , the scheme wga  described in algorithm [ alg : wgreedy ] aims at _ constructing _ a ( problem dependent ) dictionary with the aid of a pde model . while greedy function approximation is naturally compared with the _",
    "best @xmath0-term approximation _ from the underlying dictionary ( see @xcite for related results ) , a natural question here is to compare the corresponding greedy errors @xmath110 incurred when approximating a compact set @xmath99 with the smallest possible deviation of @xmath99 from any @xmath0-dimensional linear space , given by the kolmogorov @xmath0-widths @xmath111 mentioned earlier in the preceding section .",
    "one trivially has @xmath112 for all @xmath113 and the question arises whether there actually exists a constant @xmath114 such that @xmath115 one may doubt such a relation to hold for several reasons .",
    "first , orthogonal greedy _ function approximation _ performs in a way comparable to best @xmath0-term approximation only under rather strong assumptions on the underlying given dictionary .",
    "intutitively , one expects that errors made early on in the iteration are generally hard to correct later although this intuition turns out to be misleading in the case of the present _ set approximation_. second , the spaces @xmath23 generated by the greedy growth are restricted by being generated only from snapshots in @xmath99 while the best spaces can be chosen freely , see the related discussion in @xcite .    the comparison was addressed first in @xcite for the ideal case @xmath116 . in this case",
    "a bound of the form @xmath117 could be established for some absolute constant @xmath114 .",
    "this is useful only for cases where the @xmath0-widths decay faster than @xmath118 which indeed turns out to be possible for elliptic problems with a sufficiently smooth affine parameter dependence .",
    "in fact , in such a case the @xmath21 can be even shown to be _",
    "analytic _ as a function of @xmath16 , see @xcite and the literature cited there .",
    "it was then shown in @xcite that the slightly better bound @xmath119 holds .",
    "more importantly , these bounds can not be improved in general .",
    "moreover , the possible exponential loss in accuracy is not due to the fact the greedy spaces are generated by snapshots from @xmath99 . in fact , denoting by @xmath120 the restricted `` inner '' widths , obtained by allowing only subspaces spanned by snapshots of @xmath99 in the competition , one can prove that @xmath121 , @xmath113 , which is also sharp in general @xcite .",
    "while these findings may be interpreted as limiting the use of reduced bases generated in a greedy fashion to problems where the @xmath0-widths decay exponentially fast the situation turns out to be far less dim if one does _ not _ insist on a _ direct comparison _ of the type with @xmath0 being _ the same _ on both sides of the inequality . in @xcite the question is addressed whether a certain _ convergence rate _ of the @xmath0-widths @xmath122 implies some convergence rate of the greedy errors @xmath123 .",
    "the following result from @xcite gave a first affirmative answer .",
    "[ thm : poldecay ] let @xmath124 be the parameter in and assume that @xmath125 for some @xmath126 .",
    "then @xmath127 for some @xmath128 , implies @xmath129 where @xmath130 and @xmath131 .",
    "this means that the weak greedy scheme may still be highly profitable even when the @xmath0-widths do not decay exponentially .",
    "moreover , as expected , the closer the weakness parameter @xmath132 is to one , the better , which will later guide the sampling strategies for constructing reduced bases .",
    "results of the above type are not confined to polynomial rates .",
    "a sub - exponential decay of the @xmath122 with a rate @xmath133 , @xmath134 is shown in @xcite to imply a rate @xmath135 the principle behind the estimates , is to exploit a `` flatness '' effect or what one may call `` conditional delayed comparison '' .",
    "more precisely , given any @xmath136 and defining @xmath137 , one can show that ( ( * ? ? ?",
    "* lemma 2.2 ) ) @xmath138 thus , a comparison between greedy errors and @xmath0-widths is possible when the greedy errors do not decay too quickly .",
    "this is behind the diminished exponent @xmath139 in .",
    "these results have been improved upon in @xcite in several ways employing different techniques yielding improved comparisons .",
    "abbreviating @xmath140 , a central result in the present general hilbert space context states that for any @xmath141 , @xmath142 one has @xmath143 as a first important consequence , one derives from these inequalities a nearly direct comparison between @xmath144 and @xmath145 without any constraint on the decay of @xmath144 or @xmath145 .",
    "in fact , taking @xmath146 , and any @xmath147 in , using the monotonicity of the @xmath144 , one shows that @xmath148 from which one deduces @xmath149 this , in particular , gives the direct unconditional comparison @xmath150 the estimate is then used in @xcite to improve on establishing the bounds @xmath151",
    "i.e. , the exponent @xmath152 is preserved by the rate for the greedy errors .",
    "moreover , one can recover from ( with different constants ) .",
    "although not needed in the present context the second group of results in @xcite should be mentioned that concerns the extension of the weak greedy algorithm wga to _ banach _ spaces @xmath153 in place of the hilbert space @xmath100 .",
    "remarkably , a direct comparison between @xmath154 and @xmath155 similar to is also established in @xcite .",
    "the counterpart to reads @xmath156 i.e. , one looses a factor @xmath157 which is shown , however , to be necessary in general .",
    "all the above results show that the smaller the weakness parameter @xmath132 the stronger the derogation of the rate of the greedy errors in comparison with the @xmath0-widths .",
    "as shown by and , the weak greedy algorithm wga  realizes optimal rates for essentially all ranges of interest .",
    "a natural question is under which circumstances a surrogate based greedy algorithm sga   is in this sense also _ rate - optimal _ , namely ensures the validity of and .",
    "obviously , this is precisely the case when new snapshots generated through maximzing the surrogate have the _ weak greedy property _ .",
    "note that proposition [ prop : weakgreedy ] says that the _ residual based surrogate _ in the case of _ coercive problems _ does ensure the weak - greedy property so that sga   is indeed rate - optimal for coercive problems .",
    "note also that the weakness parameter @xmath158 is in this case the larger the smaller the condition number of the operator @xmath5 is , see . obviously ,",
    "the key is that the surrogate not only yields an upper bound for the best approximation error but also , up to a constant , a lower bound , and the more tightly the best approximation eror is sandwiched by the surrogate the better the performance of sga .",
    "therefore , even if the problem is coercive for a very small @xmath158 , as is the case for convection dominated _ convection - diffusion problems _ , in view of the dependence of the bounds in and on @xmath159 , one expects that the performance of a greedy search based on degrades significantly .    in summary ,",
    "as long as algoritm sga employs a _ tight surrogate _ in the sense that @xmath160 holds for some constant @xmath161 , independent of @xmath55 , algorithm sga is _ rate - optimal _ in the sense of , , i.e. , it essentially realizes the @xmath0-width rates over all ranges of interest , see @xcite .",
    "we refer to @xmath162 as the _ condition _ of the surrogate @xmath163 . in the rbm community",
    "the constant @xmath164 is essentially the _ stability factor _ which is usually computed along with an approximate reduced solution .",
    "clearly , the bounds in  [ sect : growth ] also show that the quantitative performance of sga  is expected to be the better the smaller the condition of the surrogate , i.e. , the larger @xmath165 .",
    "as shown so far , coercive problems with a small condition number @xmath166 represent an ideal setting for rbm and standard galerkin projection combined with the _ symmetric surrogate _ , based on measuring the residual in the dual norm @xmath167 of the `` error - norm '' @xmath22 , identifies rate - optimal snapshots for a greedy space growth .",
    "of course , this marks a small segment of relevant problems .",
    "formally , one can still apply these projections and surrogates for any variational problem for which a residual can be computed .",
    "however , in general , for indefinite or unsymmetric singularly perturbed problems , the tightness relation may no longer hold for surrogates of the form or , if it holds the condition @xmath168 becomes prohibitively large .",
    "in this latter case , the upper bound of the best approximation error is too loose to direct the search for proper snapshots .",
    "a simple example is the _ convection - diffusion _ problem : for @xmath169 find @xmath170 , @xmath171 , such that @xmath172 where , for instance , @xmath173\\times s^{d-1}$ ] , @xmath174 the @xmath175-sphere .",
    "[ rem : cond ] it is well nown that when @xmath176 the problem has for any @xmath177 a unique solution .",
    "thus , for @xmath178 is still valid but with @xmath179 which becomes arbitrarily large for a correspondingly small diffusion lower bound @xmath180 .",
    "the standard scheme sga indeed no longer performs nearly as well as in the well conditioned case .",
    "the situation is even less clear when @xmath181 ( with modified boundary conditions ) where no `` natural '' variational formulation suggests itself ( we refer to @xcite for a detailed discussion of these examples ) .",
    "moreover , for _ indefinite problems _ the galerkin projection does generally perform like the best approximation which also adversily affects tightness of the standard symmetric residual based surrogate .",
    "hence , to retain rate - optimality of sga  also for the above mentioned extended range of problems one has to find a better surrogate than the one based on the symmetric residual bound in .",
    "we indicate in the next section that such better surrogates can indeed be obtained at affordable computational cost for a wide range of problems through combining _ petrov - galerkin projections _ with appropriate _ unsymmetric _",
    "residual bounds . the approach can be viewed as _ preconditioning _ the continuous problem already on the infinite dimensional level .",
    "we consider now a wider class of ( not necessarily coercive ) variational problems @xmath182 where we assume at this point only for each @xmath183 the existence of a unique solution @xmath184 , i.e. , the operator @xmath185 , induced by @xmath186 , is bijective .",
    "this is well known to be equivalent to the validity of @xmath187 \\mbox{for } \\ , v\\in v\\ , \\exists\\ , w\\in w,\\ , \\mbox{such that } b(w , v)\\neq 0 , \\end{array}\\right.\\ ] ] for some constants @xmath188 .",
    "however , one then faces two principal obstructions regarding an rbm based on the scheme sga :    \\(a ) first , as in the case of for small diffusion , @xmath189 could be very large so that the corresponding error - residual relation @xmath190 renders a corresponding residual based surrogate ill - conditioned .",
    "\\(b ) when @xmath186 is not coercive , the galerkin projection does , in general , not perform as well as the best approximation .",
    "the following approach has been used in @xcite to address both ( a ) and ( b ) .",
    "the underlying basic principle is not new , see @xcite , and variants of it have been used for different purposes in different contexts such as least squares finite element methods @xcite and , more recently , in connection with",
    "_ discontinuous petrov galerkin methods _ @xcite .",
    "in the context of rbms the concepts of _ natural norms _ goes sort of half way by sticking in the end to galerkin projections @xcite .",
    "this marks an essential distinction from the approach in @xcite discussed later below .",
    "the idea is to change the topology of one of the spaces so as to ( ideally ) make the corresponding induced operator an _ isometry _ , see also @xcite .",
    "following @xcite , fixing for instance , @xmath191 , one can define @xmath192 which means that one has for @xmath193 @xmath194 a perfect error - residual relation .",
    "it also means that , replacing @xmath195 in by @xmath196 , yields the inf - sup constant @xmath197 .",
    "alternatively , fixing @xmath22 , one may set @xmath198 to again arrive at an isometry @xmath199 , meaning @xmath200 whether the norm for @xmath7 or for @xmath9 is prescribed depends on the problem at hand and we refer to @xcite for examples of both type .    next note that for any subspace @xmath201 one has @xmath202 and analogously for the pair @xmath203 , i.e. , the best approximation in the @xmath204-norm is a _ minimum residual solution _ in the @xmath8-norm .    to use residuals in @xmath8 as surrogates requires fixing a suitable discrete projection for a given trial space . in general , in particular",
    "when @xmath205 , the galerkin projection is no longer appropriate since inf - sup stability of the _ infinite dimensional _ problem is no longer inherited by an arbitrary pair of _ finite dimensional _ trial and test spaces . to see which type of projection would be ideal , denote by @xmath206 the riesz map defined for any linear functional @xmath39 by @xmath207 then , by , for any @xmath208 , taking @xmath209 one has @xmath210 thus , in particular , @xmath211 i.e. , given @xmath201 , using @xmath212 as a test space in the _ petrov - galerkin _",
    "scheme @xmath213 is equivalent to computing the @xmath204-orthogonal projection of the exact solution @xmath214 of and hence the best @xmath204-approximation to @xmath214 .",
    "one readily sees that this also means @xmath215 i.e. , we have a petrov - galerkin scheme for the pair of spaces @xmath216 with perfect stability and the petrov - galerkin projection is the best @xmath204-projection .",
    "unfortunately , this is not of much help yet , because computing the _ ideal test space _",
    "@xmath217 is not numerically feasible .",
    "nevertheless , it provides a useful orientation for finding good and practically realisable pairs of trial and test spaces , as explained next .",
    "we briefly recall now from @xcite an approach to deriving from the preceding observations a practically feasible numerical scheme which , in particular , fits into the context of rbms .",
    "taking as point of departure we notice that the minimization of @xmath218 over @xmath219 is a least squares problem whose normal equations read : find @xmath220 such that ( with @xmath221 ) @xmath222 introducing the auxiliary variable @xmath223 which is equivalent to @xmath224 the two relations and can be rewritten in form of the _ saddle point problem _ @xmath225 the corresponding inf - sup constant is still one ( since the supremum is taken over all of @xmath9 ) and @xmath226 is a scalar product so that has a unique solution @xmath227 , see e.g. @xcite . taking for any @xmath228 the test function @xmath229 in the first line of , one obtains @xmath230 by the second line in",
    "so we see that @xmath231 holds for all @xmath228 which means that @xmath227 solves the ideal petrov - galerkin problem .",
    "thus is equivalent to the ideal petrov galerkin scheme .    of course , is still not realizable since the space @xmath9 is still the full infinite dimensional space .",
    "one more step to arrive at a realizable scheme is the following : given the finite dimensional space @xmath219 find a finite dimensional space @xmath232 so that when @xmath9 in is replaced by @xmath233 , one obtains a _",
    "stable _ finite dimensional saddle point problem which is the same as saying that its inf - sup constant is safely bounded away from zero .",
    "since @xmath234 would yield perfect stability the choice of @xmath232 can be viewed as a _",
    "stabilization_. to quantify this we follow @xcite and say that for some @xmath235 , @xmath232 is @xmath236-_proximal _ for @xmath201 if @xmath233 is suffciently close to the ideal test space @xmath237 in the sense that @xmath238 the related main findings from @xcite can be summarized as follows .",
    "[ thm : saddle ] ( i ) the pair @xmath239 solves the saddle point problem @xmath240 if and only if @xmath241 solves the petrov - galerkin problem @xmath242 ( ii ) if @xmath233 is @xmath236-proximal for @xmath219 , is solvable and one has @xmath243 \\|u - u_{w , z}\\|_{\\hat u } + \\|r_{w , z}\\|_v & \\le & \\frac{2}{1-\\delta}\\inf_{w\\in w}\\|u_{w , z}-w\\|_{\\hat u}. \\end{array}\\ ] ] ( iii ) @xmath233 is @xmath236-proximal for @xmath219 if and only if @xmath244    note that involves ordinary bilinear forms and finite dimensional spaces @xmath245 and ( iii ) says that the @xmath9-projection of the ideal test space @xmath246 onto @xmath233 is a good test space if and only if @xmath233 is @xmath236-proximal for @xmath219 . loosely speaking , @xmath233 is large enough to `` see '' a substantial part of the ideal test space @xmath246 under projection .",
    "the perhaps most important messages to be taken home regarding the rbm context read as follows .",
    "[ rem : takehome ] ( i ) the petrov - galerkin scheme is realized through the saddlepoint problem explicitly computing the test space @xmath247 .",
    "+ ( ii ) moreover , given @xmath219 , by compactness and , one can in principle enlarge @xmath233 so as to make @xmath236 as small as possible , a fact that will be explointed later .",
    "+ ( iii ) the solution component @xmath241 is a near - best approximation to the exact solution @xmath214 in the @xmath204-norm .",
    "+ ( iv ) @xmath248 can be viewed as a _ lifted residual _ which tends to zero in @xmath9 when @xmath219 grows and can be used for a - posteriori error estimation , see @xcite . in the reduced basis context",
    "this can be exploited for certifying the accuracy of the truth solutions and for constructing computationally feasible surrogates for the construction of the reduced bases .",
    "we point out next how to use the preceding results for sampling the solution manifold @xmath15 of a given _",
    "paramteric family of variational problems _ : given @xmath6 , @xmath249 , find @xmath250 such that @xmath251 in a way that the corresponding subspaces are rate - optimal .",
    "we will always assume that the dependence of the bilinear form @xmath79 on @xmath6 is affine in the sense of .    as indicated by the notation the spaces @xmath252 for which the variational problems are well - posed in the sense that the induced operator @xmath253 is bijective , could depend on @xmath16 through @xmath16-dependent norms .",
    "however , to be able to speak of a `` solution manifold '' @xmath15 as a compact subset of some `` reference hilbert space '' , the norms @xmath254 should be _ uniformly _ equivalent to some _ reference _ norm @xmath22 which has to be taken into account when formulating .",
    "in fact , under this condition , as shown in @xcite , for well - posed variational formulations of pure transport problems the dependence of the test spaces @xmath255 on @xmath55 is essential , in that @xmath256 is a strict subset of each individual @xmath255 .",
    "this complicates the construction of a tight surrogate .",
    "we refer to @xcite for ways of dealing with this obstruction and confine the subsequent discussion for simplicity to cases where the test norms @xmath257 are also uniformly equivalent to a single reference norm @xmath191 , see the example later below .    under the above assumptions ,",
    "the findings of the preceding section will be used next to contrive a well - conditioned tight surrogate even for non - coercice or severely ill - conditioned variational problems which is then in general unsymmetric , i.e. , @xmath258 .",
    "these surrogates will then be used in sga . to obtain such a residual based well - conditioned surrogate in the sense of ,",
    "_ renorm _ the pairs of spaces @xmath259 or @xmath255 according to or . in anticipation of the example below , for definiteness we concentrate on and refer to @xcite for a discussion of . as indicated above",
    ", we assume further that the norms @xmath260 are equivalent to reference norms @xmath261 , respectively .",
    "suppose that we have already constructed a pair of spaces @xmath262 , @xmath55 , such that for a given @xmath263 @xmath264 i.e. , @xmath265 is @xmath236-proximal for @xmath89 .",
    "thus , by theorem [ thm : saddle ] , the parametric saddle point problem @xmath266 has for each @xmath55 a unique solution @xmath267 . by the choice of norms we know that @xmath268 i.e. , @xmath269 suggests itself as a surrogate .",
    "there are some subtle issues about how to evaluate @xmath270 in the dual @xmath271 of a sufficiently large truth space @xmath272 , @xmath6 , so as to faithfully reflect errors in @xmath273 , not only in the truth space @xmath274 but in @xmath204 , and how these quantities are actually related to the auxiliary variable @xmath275 which is computed anyway . as indicated before , these issues are aggrivated when the norms @xmath257 are _ not _ all equivalent to a single reference norm .",
    "we refer to a corresponding detailed discussion in @xcite and continue working here for simplicity with the idealized version and assume its offline feasibility .",
    "thus , we can evaluate the errors @xmath276 and can determine a maximizing parameter @xmath277 for which @xmath278 now relation in theorem [ thm : saddle ] tells us that for each @xmath55 @xmath279 i.e. , @xmath280 is a near best approximation to @xmath214 from @xmath23 which is , in fact , the nearer to the best approximation the smaller @xmath236 . by and ,",
    "the surrogate is indeed well - conditioned with condition number close to one for small @xmath236 .",
    "a natural strategy is now to enlarge @xmath23 to @xmath281 .",
    "in fact , this complies with the _ weak gready _ step in ",
    "[ sect : growth ] with weakness parameter @xmath282 as close to one as one wishes , when @xmath236 is chosen accordingly small , provided that the pair of spaces @xmath283 satisfies .",
    "a repetition would therefore , in principle , be a realization of algorithm [ alg : greedy ] , sga , establishing rate - optimality of this rbm .",
    "obviously , the critical condition for such a procedure to work is to ensure at each stage the validity of the weak - greedy condition which in the present situation means that the companion space @xmath284 is at each stage @xmath236-proximal for @xmath23 .",
    "so far we have not explained yet how to grow @xmath284 along with @xmath23 so as to ensure @xmath236-proximality .",
    "this is explained in the subsequent section .",
    "[ rem : crucial ] one should note that , due to the possible parameter dependence of the norms @xmath260 on @xmath16 , obtaining tight surrogates with the aid of an explicit petrov - galerkin formulation , would be infeasible in an rbm context because one would have to recompute the corresponding ( parameter dependent ) test basis for each parameter query which is not online - feasible .",
    "it is therefore actually crucial to employ the saddle point formulation in the context of rbms since this allows us to determine a space @xmath284 of somewhat larger dimension than @xmath23 but stabilizes the saddle point problem for all @xmath16 simultaneously .",
    "a natural option is to enlarge @xmath284 by the second component @xmath285 of .",
    "note though that the lifted resilduals @xmath286 tend to zero as @xmath287 .",
    "hence , the solution manifold of the ( @xmath16-dependent version of the ) saddle point formulation has the form @xmath288 where @xmath15 is the solution manifold of ( since @xmath289 for @xmath6 ) .",
    "thus , the spaces @xmath284 are _ not _ needed to approximate the solution manifold . instead the sole purpose of the space @xmath284 is to guarantee stability . at any rate , the grown pair @xmath290 may fail to satisfy now .",
    "therefore , in general one has to further enrich @xmath291 by additional _ stabilizing _ elements again in a greedy fashion until holds for the desired @xmath236 . for problems that initially arise as natural saddle point problems such as the stokes system , enrichments by so called",
    "_ supremizers _ ( to be defined in a moment ) have been proposed already in @xcite . in these cases it is possible to enrich @xmath291 by a _ fixed _ a priori known number of such supremizers to guarantee inf - sup stability . as shown in @xcite ,",
    "this is generally possible when using fixed ( parameter independent ) reference norms @xmath196 , @xmath191 for @xmath7 and @xmath9 .",
    "for the above more general scope of problems a greedy strategy was proposed and analyzed in @xcite , a special case of which is also considered in @xcite without analysis .",
    "the strategy in @xcite adds only as many stabilizing elements as are actually needed to ensure stability and works for a much wider range of problems including singularly perturbed ones . in cases where not all parameter dependent norms @xmath257 are equivalent such a strategy is actually necessary and its convergence analysis is then",
    "more involved , see @xcite .",
    "to explain the procedure , suppose that after growing @xmath23 to @xmath292 we have already generated an enrichment @xmath293 of @xmath291 ( which could be , for instance , either @xmath294 or @xmath295 ) but the pair @xmath296 still fails to satisfy for the given @xmath297 . to describe the next enrichment from @xmath293 to @xmath298 we first search for a parameter @xmath299 and a function @xmath300 for which the inf - sup condition is worst",
    ", i.e. , @xmath301 if this worst case inf - sup constant does not exceed yet @xmath302 , the current space @xmath293 does not contain an effective supremizer for @xmath303 , yet .",
    "however , since the truth space satisfies the uniform inf - sup condition there _ must exist _ a good supremizer in the truth space which can be seen to be given by @xmath304 providing the next enrichment @xmath305 we defer some comments on the numerical realization of finding @xmath306 in , to the next section .",
    "this strategy can now be applied recursively until one reaches a satisfactory uniform inf - sup condition for the reduced spaces .",
    "again , the termination of this stabilization loop is easily ensured when holds and the norms @xmath307 , @xmath257 are uniformly equivalent to reference norms @xmath308 , @xmath309 , respectively , but is more involved in the general case @xcite .",
    "thus , in summary , to ensure that the greedy scheme sga   with the particular surrogate , based on the corresponding _ outer greedy _",
    "step for extending @xmath23 to @xmath292 , has the _ weak greedy property _ , one can employ an _ inner stabilizing greedy _ loop producing a space @xmath310 which is @xmath236-proximal for @xmath292 . here",
    "@xmath311 is the number of enrichment steps needed to guarantee the validity of for the given @xmath236 .",
    "a sketchy version of the corresponding `` enriched '' sga , developed in @xcite , looks as follows : +    initialize @xmath312 , @xmath235 , target accuracy @xmath313 , @xmath314 , compute @xmath315 with the aid of the inner stabilizing greedy loop , given @xmath316 , satisfying , compute @xmath317 with the aid of the outer greedy step 4 , in algorithm sga for the surrogate ,    as indicated above , both algorithm [ alg : greedy ] , sga   and algorithm [ alg : doublegreedy ] , sga - dou   are surrogate based greedy algorithms .",
    "the essential difference is that for non - coercive problems or problems with an originally large variational condition number in sga - dou   an additional interior greedy loop provides a tight well - conditioned ( unsymmetric ) surrogate which guarantees the desired weak greedy property ( with weakness constant @xmath132 as close to one as one wishes ) needed for rate - optimality .",
    "of course , the viability of algorithm sga - dou hinges mainly on two questions :    \\(a ) how to find the worst inf - sup constant in and how to compute the supremizer in ?",
    "\\(b ) does the inner greedy loop terminate ( early enough ) ?    as for ( a ) , it is well known that , fixing bases for @xmath318 , finding the worst inf - sup constant amounts to determine for @xmath55 the cross - gramian with respect to @xmath79 and compute its smallest singular value .",
    "since these matrices are of size @xmath319 and hence ( presumably ) of `` small '' size , a search over @xmath2 requires solving only problems in the reduced spaces and are under the assumption therefore offline - feasible .",
    "the determination of the corresponding supremizer @xmath320 in , in turn , is based on the well - known observation that @xmath321 which is equivalent to solving the galerkin problem @xmath322 thus , each enrichment step requires one offline - galerkin solve in the truth space .    a quantitative answer to question ( b )",
    "is more involved .",
    "we are content here with a few related remarks and we refer to a detailed discussion of this issue in @xcite . as mentioned before ,",
    "when all the norms @xmath260 , @xmath55 , are equivalent to reference norms @xmath261 , respectively , the inner loop terminates after at most the number of terms in .",
    "when the norms @xmath257 are no longer uniformly equivalent to a single reference norm termination is less clear .",
    "of course , since all computations are done in a truth space which is finite dimensional , compactness guarantees termination after finitely many steps . however , the issue is that the number of steps should not depend on the truth space dimension .",
    "the reasoning in @xcite used to show that ( under mild assumptions ) termination happens after a finite number of steps which is _ independent _ of the truth space dimension , is based on the following fact . defining @xmath323 , solving the problem",
    "@xmath324 when all the @xmath307-norms are equivalent to a single reference norm , can be shown to be equivalent to a greedy step of the type and can hence again be reduced to similar small eigenvalue problems in the reduced space .",
    "note , however , that is similar to a greedy space growth used in the outer greedy loop and for which some understanding of convergence is available . therefore , successive enrichments based on are studied in @xcite regarding their convergence .",
    "the connection with the inner stabilizing loop based on is that @xmath325 just means @xmath326 which is a statement on @xmath236-proximality known to be equivalent to inf - sup stability , see theorem [ thm : saddle ] , and .",
    "a central result from @xcite can be formulated as follows , see ( * ? ? ?",
    "* theorem 5.5 ) .",
    "[ thm : main ] if holds and the norms @xmath260 are all equivalent to a single reference norm @xmath327 , respectively , and the surrogates are used , then the scheme sga - dou is rate optimal , i.e. , the greedy errors @xmath328 decay at the same rate as the @xmath0-widths @xmath329 , @xmath287 .    recall that the quantitative behavior of the greedy error rates are directly related to those of the @xmath0-widths by @xmath330 , see theorem [ thm : poldecay ] .",
    "this suggests that a fast decay of @xmath329 is reflected by the corresponding greedy errors already for moderate values of @xmath0 which is in the very interest of reduced order modeling .",
    "this will be confirmed by the expamples below . in this context",
    "an important feature of sga - dou is that through the choice of the @xmath236-proximility parameter the weakness parameter @xmath132 can be driven towards one , of course , at the expense of somewhat larger spaces @xmath331 .",
    "hence , stability constants close to one are built into the method .",
    "this is to be contrasted by the conventional use of sga based on surrogates that are not ensured to be well conditioned and for which the computation of the certifying stability constants tends to be computationally expensive .",
    "the preceding theoretical results are illustrated next by a numerical example that brings out some of the main features of the scheme .",
    "while the double greedy scheme applies to non - coercive or indefinite problems ( e.g. see @xcite for pure transport ) we focus here on a classical _ singularly perturbed _ problem because it addresses also some principal issues for rbms regarding problems with _",
    "small scales_. specifically , we consider the _ convection - diffusion _ problem on @xmath332 for a simple _ parameter dependent convection _",
    "field @xmath333 keeping for simplicity the diffusion level @xmath26 fixed but allowing it to be arbitrarily small .",
    "all considerations apply as well to variable and parameter dependent diffusion with any arbitrarily small but strictly positive lower bound .",
    "the `` transition '' to a pure transport problem is discussed in detail in @xcite .",
    "parameter dependent convection directions mark actually the more difficult case and are , for instance , of interest with regard to kinetic models .",
    "let us first briefly recall the main challenges posed by for very small diffusion @xmath26 .",
    "the problem becomes obviously dominantly unsymmetric and singularly perturbed .",
    "recall that for each positive @xmath26 the problem possesses for each @xmath6 a unique solution @xmath21 in @xmath334 that has a zero trace on the boundary @xmath335 . however , as indicated earlier , the condition number @xmath166 of the underlying convection - diffusion operator @xmath5 , viewed as an operator from @xmath334 onto @xmath336 , behaves like @xmath337 , that is , it becomes increasingly _",
    "ill conditioned_. this has well known consequences for the performance of numerical solvers but above all for the stability of corresponding discretizations .",
    "we emphasize that the conventional mesh dependent stabilizations like supg ( cf .",
    "@xcite ) do _ not _ offer a definitive remedy because the corresponding condition , although improved , remains very large for very small @xmath26 . in @xcite supg - stabilization for the offline truth calculations as well as for the low - dimensional online galerkin projections",
    "are discussed for moderate pclet - numbers of the order of up to @xmath338 . in particular , comparisons are presented when only the offline phase uses stabilization while the un - stabilized bilinear form is used in the online phase , see also the references in @xcite for further related work .",
    "as indicated earlier , we also remark in passing that the singularly perturbed nature of the problem poses an additional difficulty concerning the choice of the truth space @xmath19 .",
    "in fact , when @xmath26 becomes very small one may not be able to afford resolving correspondingly thin layers in the truth space which increases the difficulty of capturing essential features of the solution by the reduced model .",
    "this problem is addressed in @xcite by resorting to a weak formulation that does not use @xmath339 ( or a renormed version of it ) as a trial space but builds on the results from @xcite .",
    "a central idea is to enforce the boundary conditions on the outflow boundary @xmath340 only weakly . here",
    "@xmath340 is that portion of @xmath335 for which the inner product of the outward normal and the convection direction is positive .",
    "thus , solutions are initially sought in the larger space @xmath341 enforcing homogeneous boundary conditions only on the _ inflow _ boundary @xmath342 . since the outflow boundary , and",
    "hence also the inflow boundary depend on the parameter @xmath16 , this requires subdividing the parameter set into smaller sectors , here four , for which the outflow boundary @xmath343 remains unchanged .",
    "we refer in what follows for simplicity to one such sector denoted again by @xmath2 .",
    "the following prescription of the _ test space _ falls into the category where the norm for @xmath7 is adapted .",
    "specifically , choosing @xmath344 in combination with a boundary penalization on @xmath345 , we follow @xcite and define @xmath346 where @xmath347 , @xmath348 and @xmath349 denotes the operator induced by this weak formulation over @xmath350 .",
    "the corresponding variational formulation is of minimum residual type ( cf . ) and reads @xmath351 one can show that its ( infinite dimensional ) solution , whenever being sufficiently regular , solves also the strong form of the convection diffusion problem .",
    "figure [ figs : condiff ] illustrates the effect of this formulation where we set @xmath352    ;   middle : @xmath353 ;   right : @xmath354.,title=\"fig:\",scaledwidth=28.0% ] ;   middle : @xmath353 ;   right : @xmath354.,title=\"fig:\",scaledwidth=28.0% ] ;   middle : @xmath353 ;   right : @xmath354.,title=\"fig:\",scaledwidth=28.0% ]    table[x = dim_trial , y = max_residual]all - cases-5 ;       the shaded planes shown in figure [ figs : condiff ] indicate the convection direction for which the snapshot is taken . for moderately large diffusion",
    "the boundary layer at @xmath345 is resolved by the truth space discretization and the boundary conditions at the outflow boundary are satisfied exactly . for smaller diffusion in the middle example the truth space discretization",
    "can no longer resolve the boundary layer and for very small diffusion ( right ) the solution is close to the one for pure transport .",
    "the rationale of is that all norms commonly used for convection diffusion equations resemble the one chosen here , for instance in the form of a mesh dependent `` broken norm '' , which means that most part of the incurred error of an approximation is concentrated in the layer region , see e.g. @xcite .",
    "hence , when the layers are not resolved by the discretization , enforcing the boundary conditions does not improve accuracy and , on the contrary , may degrade accuracy away from the layer by causing oscillations .",
    "the present formulation instead avoids any non - physical oscillations and enhances accuracy in those parts of the domain where this is possible for the afforded discretization , see @xcite for a detailed discussion .",
    "the following table quantifies the results for the case of small diffusion @xmath355 and a truth discretization whose a posteriori error bound is @xmath356 .",
    "+    .convection - diffusion equation , @xmath357 , maximal a - posteriori error @xmath358 [ cols=\"^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     [ tab : all - cases-5 ]    the columns @xmath359 and @xmath360 show the @xmath236 governing the condition of the saddle point problems ( and hence of the corresponding petrov - galerkin problems ) , see , the greedy space growth is based upon .",
    "hence the surrogates are very tight giving rise to weakness parameters very close to one .",
    "as indicated in remark [ rem : takehome ] one can use also an a posteriori bound for the truth solution based on the corresponding lifted residual",
    ". columns @xmath361 and @xmath362 show therefore the relative accuracy of the current reduced model and the truth model .",
    "this corresponds to the stability constants computed by conventional rbms . even for elliptic problems these latter ones",
    "are significantly larger than the ones for the present singularly perturbed problem which are guaranteed to be close to one by the method itself . based on the a posteriori bounds for the truth solution ( which are also obtained with the aid of tailored well - conditioned variational formulations ,",
    "see @xcite ) , the greedy space growth is stopped when the surrogates reach the order of the truth accuracy .",
    "as illustrated in figure [ fig : all - cases-5 ] , in the present example this is essentially already the case for @xmath363 trial reduced basis functions and almost three times as many test functions . to show this `` saturation effect '' we have continued the space growth formally up to @xmath364 showing no further significant improvement which is in agreement with the resolution provided by the truth space .",
    "these relations agree with the theoretical predictions in @xcite .",
    "figure [ fig : all - cases-5 ] illustrates also the rapid gain of accuracy by the first few reduced basis functions which supports the fact that the solution manifold is `` well seen '' by the petrov - galerkin surrogates .",
    "more extensive numerical tests shown in @xcite show that the achieved stability is independent of the diffusion but the larger the diffusion the smaller become the dimensions @xmath365 for the reduced spaces .",
    "this indicates the expected fact that the larger the diffusion the smoother is the dependence of @xmath21 on the parameter @xmath16 .",
    "in fact , when @xmath366 one approaches the regime of pure transport where the smoothness of the parameter dependence is merely hlder continuity requiring for a given target accuracy a larger number of reduced basis functions , see @xcite .",
    "the central focus of the preceding discussion has been to control the maximal deviation @xmath367 and to push this deviation below a given tolerance for @xmath0 as small as possible .",
    "however , in many applications one is not interested in the whole solution field but only in a _ quantity of interest _",
    "@xmath37 , typically of the form @xmath368 where @xmath369 is a bounded linear functional .",
    "looking then for some desired optimal state @xmath370 one is interested in a guarantee of the form latexmath:[\\[\\label{guarantee }    where the states @xmath280 belong to a possibly small reduced space @xmath23 in order to be then able to carry out the optimization over @xmath6 in the small space @xmath89 .",
    "asking only for the values of just a _ linear functional _ of the solution seems to be much less demanding than asking for the whole solution and one wonders whether this can be exploited in favor of even better online efficiency .    trying to reduce computational complexity by exploiting",
    "the fact that , retrieving only a linear functional of an unknown state - a scalar quantity - may require less information than recovering the whole state , is the central theme of _ goal oriented _ adaptation in finite element methods , see @xcite . often the desired accuracy is indeed observed to be reached by significantly coarser discretizations than needed to approximate the whole solution within a corresponding accuracy .",
    "the underlying effect , sometimes referred to as `` squared accuracy '' is well understood and exploited in the rbm context as well , see @xcite .",
    "we briefly sketch the main ideas for the current larger scope of problems and point out that , nevertheless , a guarantee of the form ultimately requires controlling the maximal deviation of a reduced space in the sense of .",
    "hence , an optimal sampling of a solution manifold remains crucial .",
    "first , a trivial estimate gives for @xmath369 @xmath372 would indeed yield a guarantee .",
    "however , the @xmath0 needed to drive @xmath373 below @xmath313 is usually larger than necessary .    to explain the principle of improving on we consider again a variational problem of the form ( suppressing any parameter dependence for a moment ) for a pair of spaces @xmath374 where we assume now that @xmath375 is already small , possibly after renorming an initial less favorable formulation through or .",
    "let @xmath184 again denote the exact solution of . given a @xmath369 we wish to approximate @xmath376 , using an _ approximate solution _",
    "@xmath377 defined by @xmath378 where @xmath379 is a suitable test space generated by the methods discussed in  [ ssec : stabvar ] .",
    "in addition we will use the solution @xmath380 of the _ dual problem _ : @xmath381 together with an approximation @xmath382 defined by @xmath383 again with a suitable test space @xmath384 . recall that we need not determine the test spaces",
    "@xmath385 explicitly but rather realize the corresponding petrov - galerkin projections through the equivalent saddle point formulations with suitable @xmath236-proximal auxiliary spaces generated by a greedy stabilization .",
    "then , defining the primal residual functional @xmath386 and adapting the ideas in @xcite for the symmetric case @xmath387 to the present slightly more general setting , we claim that @xmath388 is an approximation to the true value @xmath376 satisfying latexmath:[\\[\\label{quadratic }    where @xmath114 depends only on the inf - sup constant of the finite dimensional problems .",
    "in fact , since by , @xmath390 one has @xmath391 and hence @xmath392 which confirms the claim since @xmath393 , @xmath394 are near - best approximations due to the asserted inf - sup stability of finite dimensional problems .",
    "clearly , says that in order to approximate @xmath376 the primal approximation in @xmath7 need not resolve @xmath214 at all as long as the dual solution @xmath395 is approximated well enough .",
    "moreover , when @xmath396 is a local functional , e.g. a local average approximating a point evaluation , @xmath395 is close to the corresponding green s function with ( near ) singularity in the support of @xmath396 . in the elliptic case",
    "@xmath395 would be very smooth away from the support of @xmath396 and hence well approximable by a relatively small number of degrees of freedom concentrated around the support of @xmath396 .",
    "thus , it may very well be more profitable to spend less effort on approximating @xmath214 than on approximating @xmath395 .",
    "returning to parameter dependent problems , the methods in  [ sec : d - greedy ] can now be used as follows to construct possibly small reduced spaces for a frequent online evaluation of the quantities @xmath368 .",
    "we assume that we already have properly renormed families of norms @xmath397 , @xmath6 , with uniform inf - sup constants close to one .",
    "we also assume now that both families of norms are equivalent ( by compactness of @xmath2 uniformly equivalent ) to reference norms @xmath398 , respectively .",
    "hence we can consider two solution manifolds @xmath399 and use algorithm [ alg : doublegreedy ] , sga - dou   to generate ( essentially in parallel ) two sequences of pairs of reduced spaces @xmath400 here @xmath401 are suitable stabilizing spaces such that for @xmath402 and for the corresponding reduced solutions @xmath403 the quantity @xmath404 satisfies latexmath:[\\[\\label{quadratic2 }    with a constant @xmath114 independent of @xmath406 .",
    "the choice of @xmath407 determines how to distribute the computational effort for computing the two sequences of reduced bases and their stabilizing companion spaces . by theorem [ thm : main ]",
    ", one can see that whichever @xmath0-width rate @xmath408 or @xmath409 decays faster one can choose @xmath407 to achieve for a total of @xmath410 the smallest error bound .",
    "of course , the rates are not known and one can use the tight surrogates to bound and estimate the respective errors very accurately .",
    "for instance , when @xmath411 , @xmath412 , @xmath413 yields an optimal distribution with a bound @xmath414 the dimensions on the reduced bases for the dual problem should be somewhat larger but essentially using the same dimensions for the primal and dual reduced spaces yields the rate @xmath415 confirming the `` squaring '' when @xmath416 . in contrast , as soon as either one of the @xmath0-width rates decays exponentially it is best to grow only the reduced spaces for the faster decay while keeping a fixed space for the other side .",
    "we have reviewed recent developments concerning reduced basis methods with the following main focus . using kolmogorov @xmath0-width as a benchmark for the performance of reduced basis methods in terms of minimizing the dimensions of the reduced models for a given target accuracy",
    ", we have shown that this requires essentially to construct tight well - conditioned surrogates for the underlying variational problem .",
    "we have explained how _ renormation _ in combination with _ inner stabilization loops _ can be used to derive such residual based surrogates even for problem classes not covered by conventional schemes .",
    "this includes in a fully robust way indefinite as well as ill - conditioned ( singularly perturbed ) coercive problems .",
    "greedy strategies based on such surrogates are then shown to constitute an optimal sampling strategy , i.e. , the resulting snapshots span reduced spaces whose distances from the solution manifold decay essentially at the same rate as the kolmogorov @xmath0-widths .",
    "this means , in particular , that stability constants need not be determined by additional typically expensive computations but can be pushed by the stabilizing inner greedy loop as close to one as one wishes . finally",
    ", we have explained why the focus on uniform approximation of the entire solution manifold is equally relevant for applications where only functionals of the parameter dependent solutions have to be approximated .",
    "a. buffa , y. maday , a.t .",
    "patera , c. prudhomme , and g. turinici , a priori convergence of the greedy algorithm for the parameterized reduced basis , esaim : mathematical modelling and numerical analysis , 46 ( 03 ) ( 2012 ) , 595603 .",
    "w. dahmen , c. plesken , g. welper , double greedy algorithms : reduced basis methods for transport dominated problems , esaim : mathematical modelling and numerical analysis , 48(3 ) ( 2014 ) , 623663 .",
    "doi 10.1051/m2an/2013103          a .-",
    "gerner , k. veroy , reduced basis a posteriori error bounds for the stokes equations in parameterized domains : a penalty approach , to appear in mathematical models and methods in applied sciences ( m3as ) .",
    "grepl , a.t .",
    "patera . a posteriori error bounds for reduced - basis approximations of parametrized parabolic partial differential equations , m2an mathematical modelling and numerical analysis , 2005 , 39(1 ) , pp . 157181 .",
    "t. hughes , g. sangalli , variational multiscale analysis : the fine - scale green s function , projection , optimization , localization , and stabilized methods , siam journal of numerical analysis , vol .",
    "45 , ( no .",
    "2 ) ( 2007 ) , 539557 .",
    "t. manteuffel , s. mccormick , j. ruge , and j. g. schmidt , first - order system @xmath418 @xmath419 for general scalar elliptic problems in the plane , siam journal on numerical analysis , 43 ( 2005 ) , pp .",
    "20982120 .",
    "patera , g. rozza , reduced basis approximation and a posteriori error estimation for parametrized partial differential equations , version 1.0 , copyright mit 20062007 , to appear in ( tentative rubric ) mit pappalardo graduate monographs in mechanical engineering .    c. pruhhomme , d.v .",
    "rovas , k. veroy , l. machies , y. maday , a.t .",
    "patera , g. turinici , reliable real - time solution of parametrized partial differential equations : reduced basis output - bound methods , transactions of the asme , 124 ( 2002 ) , 7080 .",
    "g. rozza , d.b.p .",
    "huynh , a.t .",
    "patera , reduced basis approximation and a posteriori error estimation for affinely parametrized elliptic coercive partial differential equations , arch .",
    "methods eng . ,",
    "15 ( 2008 ) , 229275 .",
    "s. sen , k. veroy , d.b.p .",
    "huynh , s. deparis , n.c .",
    "nguyn , a.t .",
    "patera , `` natural norm '' a - posteriori error estimators for reduced basis approximations , journal of computational physics , 217 ( 2006 ) , 3762 ."
  ],
  "abstract_text": [
    "<S> model reduction attempts to guarantee a desired `` model quality '' , e.g. given in terms of accuracy requirements , with as small a model size as possible . </S>",
    "<S> this article highlights some recent developments concerning this issue for the so called reduced basis method ( rbm ) for models based on parameter dependent families of pdes . in this context </S>",
    "<S> the key task is to sample the _ solution manifold _ at judiciously chosen parameter values usually determined in a _ </S>",
    "<S> greedy fashion_. the corresponding _ space growth _ concepts are closely related to so called _ weak greedy _ algorithms in hilbert and banach spaces which can be shown to give rise to convergence rates comparable to the best possible rates , namely the _ kolmogorov @xmath0-widths _ rates . such algorithms can be interpreted as _ adaptive sampling _ strategies for approximating compact sets in hilbert spaces . </S>",
    "<S> we briefly discuss the results most relevant for the present rbm context . </S>",
    "<S> the applicability of the results for weak greedy algorithms has however been confined so far essentially to well - conditioned coercive problems . </S>",
    "<S> a critical issue is therefore an extension of these concepts to a wider range of problem classes for which the conventional methods do not work well . </S>",
    "<S> a second main topic of this article is therefore to outline recent developments of rbms that do realize @xmath0-width rates for a much wider class of variational problems covering indefinite or singularly perturbed unsymmetric problems . </S>",
    "<S> a key element in this context is the design of _ well - conditioned variational formulations _ and their numerical treatment via saddle point formulations . </S>",
    "<S> we conclude with some remarks concerning the relevance of uniformly approximating the whole solution manifold also when the _ quantity of interest _ is only of a _ functional _ of the parameter dependent solutions . </S>"
  ]
}