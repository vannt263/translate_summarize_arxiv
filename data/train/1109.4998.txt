{
  "article_text": [
    "in this paper we study the integration error using a lattice rule .",
    "a lattice rules is a quadrature rule of the form @xmath4 where @xmath5 and @xmath6 are natural numbers , @xmath7 , and where @xmath8 for @xmath9 and @xmath10 stands for the fractional part of a nonnegative real number @xmath11 .",
    "lattice rules are quasi - monte carlo algorithms which are useful to approximate integrals @xmath12^s } f(\\boldsymbol{x } ) \\,\\mathrm{d } \\boldsymbol{x}$ ] . in the following",
    "we present a survey of the literature and some background on lattice rules .",
    "it has been shown that lattice rules are efficient for approximating integrals of periodic functions ( see @xcite ) .",
    "the construction of lattice rules has seen many advances in recent years .",
    "an important framework in which to study lattice rules ( and other quadrature rules ) are reproducing kernel hilbert spaces , which have first been considered in @xcite and are now a standard tool in quasi - monte carlo integration . the component - by - component ( cbc ) construction ( where the generating vector @xmath13 is constructed one component at a time )",
    "was first discovered by korobov  @xcite and ( * ? ? ?",
    "* theorem  18 , p. 120 ) and independently rediscovered by sloan and reztsov @xcite . in @xcite this idea has been further developed to allow one to use lattice rules also for nonperiodic integrands .",
    "optimal convergence rates for lattice rules constructed this way have been shown in @xcite and independently in @xcite for a prime number of points @xmath14 and in @xcite for a nonprime number of points .",
    "a breakthrough in reducing the construction cost of the cbc construction has been achieved by nuyens and cools in @xcite , who showed how the fast fourier transform can be used to reduce the construction cost of the search algorithm .",
    "a further very important development has been the introduction of weighted function spaces by sloan and woniakowski  @xcite .",
    "therein , the authors make the important observation that integrands may have different dependence on different projections .",
    "to take this fact into account , the authors introduced so - called weighted function spaces which yields a weighted worst - case error criterion .",
    "a comprehensive introduction to weighted function spaces and tractability questions as well as further background can be found in the comprehensive monographs @xcite .      in the following",
    "we introduce a specific reproducing kernel which will be sufficient to illustrate our algorithm . in order to keep the notation as simple as possible , we do not consider the most general case possible .",
    "consider the reproducing kernel ( see @xcite ) @xmath15 ^ 2 \\to \\mathbb{c}$ ] defined by @xmath16 where @xmath17 is a nonnegative real number , the weight , and @xmath18 is the bernoulli polynomial of degree two ( cf .",
    "@xcite ) . the bernoulli polynomial @xmath19 has the fourier series @xmath20 the reproducing kernel @xmath21 defines a reproducing kernel hilbert space @xmath22 of absolutely continuous , periodic functions on @xmath0 $ ] which integrate to @xmath23 , with inner product @xmath24 for dimensions @xmath25 we consider the reproducing kernel @xmath26 where @xmath27 , @xmath28 is a set of nonnegative real numbers @xmath29 associated with the projection onto the coordinates in @xmath30 ( we refer to these numbers as the weights @xcite ) , @xmath9 and @xmath31 .",
    "the associated reproducing kernel hilbert space is denoted by @xmath32 which is a sum of tensor products of the reproducing kernel hilbert space with kernel @xmath21 and the space of constant functions , see @xcite for more information . the kernel @xmath33 can also be interpreted as the shift - invariant kernel of a reproducing kernel hilbert space of non - periodic functions @xcite .",
    "thus the results here can also be interpreted for randomly shifted lattice rules in the associated non - periodic reproducing kernel hilbert space ( as for instance in@xcite and many other papers ) .    the integration error using a lattice rule with generating vector @xmath7",
    "is defined as @xmath34^s } f(\\boldsymbol{x})\\,\\mathrm{d } \\boldsymbol{x } - \\frac{1}{n } \\sum_{n=0}^{n-1 } f\\left(\\left\\{\\frac{n \\boldsymbol{g}}{n } \\right\\}\\right)\\right|.\\ ] ] it was shown in @xcite that @xmath35^s } \\int_{[0,1]^s } k_{\\boldsymbol{\\gamma}}(\\boldsymbol{x } , \\boldsymbol{y } ) \\,\\mathrm{d } \\boldsymbol{x } \\,\\mathrm{d } \\boldsymbol{y } \\\\ & - \\frac{2}{n } \\sum_{n=0}^{n-1 } \\int_{[0,1]^s } k_{\\boldsymbol{\\gamma}}(\\boldsymbol{x } , \\{n \\boldsymbol{x}/n\\ } ) \\,\\mathrm{d } \\boldsymbol{x } + \\frac{1}{n^2 } \\sum_{n , n'=0}^{n-1 } k_{\\boldsymbol{\\gamma}}(\\{n \\boldsymbol{g}/n\\ } , \\{n ' \\boldsymbol{g}/n\\ } ) \\\\ & = \\sum_{\\emptyset \\neq u \\subseteq \\mathcal{s } } \\gamma_u \\frac{1}{n } \\sum_{n=0}^{n-1 } \\prod_{i\\in u } b_2(\\ { n g_i / n\\}),\\end{aligned}\\ ] ] where the last inequality follows from @xmath36 and the fact that ( see @xcite ) @xmath37    we use the last expression as error criterion in this paper , i.e. @xmath38 as indicated above , can be interpreted as the square worst - case error in a korobov space or the mean square worst - case error of a randomly shifted lattice rules in a sobolev space .",
    "the square worst - case error @xmath39 is commonly used as error - criterion in a cbc construction @xcite .",
    "the cbc algorithm is a greedy search algorithm to find a good generating vector @xmath40 .",
    "this algorithm works the following way .",
    "first one chooses a number of points @xmath14 , the dimension @xmath6 and some weights @xmath41 . the component - by - component construction then finds a generating vector @xmath42 in the following way :    * set @xmath43 . * for @xmath44 set @xmath45      in practice , it is usually not known how to choose the weights @xmath29 , @xmath46 in the worst - case error criterion . some suggestions on how to choose the weights in financial applications",
    "have been put forward for instance in @xcite .",
    "another method of choosing the weights is by choosing them such that the error bound is minimized @xcite .",
    "however , choosing good weights remains a particular challenge for the application of lattice rules .",
    "in this paper we assume that the weights are independent random variables with a given mean and variance for two reasons stemming from practical applications :    * it is usually not known in practice how to choose the weights precisely . by assuming randomness in the weights",
    "permits a measurement error or noise in choosing the weights .",
    "* it is convenient to use the same lattice rule for many different integrands .",
    "the best choice of weights for each integrand may vary to some degree , hence considering the weights random variables seems to be the right model in this case .",
    "indeed , it is desirable to have quadrature rules ( lattice rules ) which are robust with respect to the weights @xmath47 , that is , for which one obtains a good convergence behavior , not only for one given choice of weights , but for a whole range of weights . in order to construct lattice rules which have this property , we assume that the weights are not given ( or fixed ) , but rather , we assume they are chosen randomly with a given mean and variance . in this way , the square worst - case error @xmath48 is a random variable ( with respect to the weights @xmath41 ) . in the following",
    "we propose an algorithm to construct lattice rules which have a small expectation value and , at the same time , a small variance of @xmath48 with respect to the random choices @xmath41 . in a nutshell ,",
    "the existence of such a lattice rule is guaranteed by the fact that more than half of the generating vectors have small expectation value of the worst - case error and more than half of the generating vectors have small variance of the worst - case error .",
    "thus there exists at least one vector for which both , the expectation value and the variance , are small .",
    "this yields a component - by - component algorithm with @xmath1 constrains , which we call the cbc@xmath1c algorithm .",
    "we also study a general version which uses @xmath2 constraints which we call the cbc@xmath2c ( component - by - component ( with ) @xmath2 constraints ) algorithm .",
    "we show that lattice rules generated by the cbc@xmath2c algorithm simultaneously work well for all weights in a subspace spanned by the chosen weights @xmath3 .",
    "thus , in applications , instead of finding one set of weights , it is enough to find an @xmath2 dimensional convex polytope in which the optimal weights lie .",
    "the price for this method is a factor @xmath2 in the upper bound on the error and the construction cost of the lattice rule .",
    "thus the burden of finding one set of weights can be shifted to the construction of good lattice rules .",
    "theoretically one could make an exhaustive search to obtain a lattice rule which simultaneously works well for all choices of weights .",
    "this may eventually shift the question of how to choose the weights for a particular problem to the problem of finding a universal lattice rule which simultaneously works well for all choices of weights , thereby removing the need to choose weights in the first place .",
    "the computational challenge though is , that for higher dimensions finding such a lattice rule is currently intractable ( since the cost depends exponentially on the dimension ) .",
    "further , also the upper bound from this paper depends exponentially on the dimension when @xmath49 .",
    "this method may be useful though for integrands with low truncation dimension @xmath50 by choosing @xmath51 in this case .",
    "we note that a similar theory can be applied to polynomial lattice rules and related point sets @xcite .    in the next section",
    "we study the implications of the assumption that the weights are random on the square worst - case error . in section  [ sec3 ]",
    "we first repeat some important insights from @xcite .",
    "we introduce the cbc@xmath1 algorithm and show that the constructed lattice rules work well for weights taken from a set of large measure .",
    "we then consider the cbc@xmath2 algorithm and consider the geometrical interpretation of the algorithm .",
    "it is shown that the square worst case error satisfies a certain bound for all weights in an @xmath2-dimensional convex polytope which is defined by the weights used in the cbc@xmath2c algorithm .",
    "in particular we explain how the weights in the cbc@xmath2c algorithm determine the shape of the search space of the generating vectors . in section  [ sec_num ]",
    "we provide some numerical examples to illustrate that in certain instances the cbc@xmath1c algorithm is beneficial .",
    "we assume that the weights @xmath29 , @xmath46 , are nonnegative , independent random variables with a given mean and variance .",
    "let @xmath52 denote the expectation value and @xmath53 the variance .",
    "for any @xmath46 there are numbers @xmath54 such that for all @xmath55 the following properties hold :    * @xmath56 , * @xmath57 , * @xmath58 for @xmath59 , * @xmath60 ;    note that we have @xmath61 .",
    "let @xmath62 and @xmath63 .",
    "we point out that the conditions for product weights need to be dealt with carefully .",
    "assume that @xmath64 for some nonnegative real numbers @xmath65 .",
    "further assume that @xmath66 .",
    "then @xmath67 and hence @xmath68 .",
    "assume that @xmath69 .",
    "then for @xmath55 with @xmath70 we have @xmath71 thus , using these assumption , we do not have @xmath58 in general , i.e. , the weights are not independent ( as is obvious from the definition @xmath64 ) .",
    "the analysis for such weights is slightly different and is not considered here . instead",
    ", if the weights are of product form @xmath64 , we assume that @xmath68 and that @xmath72 for all @xmath46 for some numbers @xmath73 .    if the weights @xmath29 are uniformly distributed in the interval @xmath74 $ ] , where @xmath75 , then the expectation value is @xmath76 and @xmath77 , thus the variance is @xmath78 .",
    "note that @xmath79 , which ensures that the weights are always non - negative . in the following",
    "we do not assume that the weights are uniformly distributed , in fact , it is more interesting to assume a different distribution which also allows weights much larger than @xmath80 .    in the following the expectation @xmath52 , the variance @xmath53 and the standard deviation @xmath81 are always taken with respect to the random variables @xmath29 .",
    "the expectation value is now @xmath82 thus , current construction algorithms @xcite can be viewed as finding quadrature rules for which the expected value is small . here",
    "we aim at finding quadrature rules for which , additionally , the variance is small .",
    "we point out that there is a difference between @xmath83 very small and @xmath84 .",
    "the restriction @xmath56 implies that if @xmath84 then @xmath85 .",
    "thus if one constructs a lattice rule with error criterion @xmath86 where @xmath87 for some @xmath46 , then this means that the random variable @xmath88 with probability @xmath89 . thus setting @xmath90",
    "means that one knows that @xmath88 and the associated anova term @xmath91 .",
    "lattice rules constructed using such weights do not have any guarantee that positive weights @xmath92 will yield a good result . to illustrate , consider the two - dimensional example where @xmath93 , @xmath94 and @xmath95 and the lattice rule has generating vector @xmath96 .",
    "this lattice rule works well in this case but not if the weight @xmath97 changes to @xmath89 , say ; see also @xcite .    using some elementary properties of the variance",
    "we obtain @xmath98 and the standard deviation is given by @xmath99 lattice rules for which the variance @xmath100 is small are less sensitive to changes of the weights @xmath29 .",
    "notice that the variance is difficult to compute in general in high dimensions since it involves a sum over all subsets of @xmath101 for which @xmath102 and which , in general , can not easily be simplified to a formula which can be computed quickly , even in the case where the weights are of product form .",
    "notice that is the one - norm of the vector consisting of the error of the projections weighted by the expectation values of the weights , whereas the standard deviation is the two - norm of the vector consisting of the error of the projections weighted by the variance of the weights .",
    "let @xmath103 be a probability measure on the weights @xmath104 .",
    "we now use the one - sided chebyshev inequality which states that for a random variable @xmath105 with probability measure @xmath106 , expectation @xmath107 and standard deviation @xmath108 , we have for any @xmath109 that @xmath110 thus we obtain the following result .",
    "[ lem_cheb ] for any @xmath109 we have @xmath111    as noted above , the standard deviation is in general difficult to compute , however , using jensen s inequality we have @xmath112 thus the square worst - case error with the variances as weights is an upper bound on the standard deviation .",
    "this upper bound can easily be computed ( for instance for variances of product form ) .",
    "assume now that if for some @xmath46 we have @xmath113 , then also @xmath88 and therefore @xmath84 .",
    "using hlder s inequality we have @xmath114 thus a small standard deviation implies a small expected error . combining the last two inequalities we obtain the following result .",
    "assume that if for some @xmath46 we have @xmath113 , then also @xmath88 and therefore @xmath84 .",
    "then we have @xmath115    if the weights",
    "@xmath116 are decaying such that the upper bound is independent of the dimension , i.e. strong tractability ( see @xcite ) holds , then for any weights @xmath41 such that the expression @xmath117 one also obtains a bound which is independent of the dimension , i.e. one has strong tractability .",
    "further , if @xmath118 satisfies strong tractability , then also the standard deviation is bounded .    combining the last two lemmas we obtain the following corollary .",
    "assume that if for some @xmath46 we have @xmath113 , then also @xmath88 and therefore @xmath84 .",
    "then for any @xmath109 we have @xmath119    this result can be viewed as a robustness result with respect to weights .",
    "if one constructs a lattice rule using @xmath120 as weights , then for a set of weights taken from a set with measure at least @xmath121 , the error is bounded by @xmath122    there is one notable exception , namely , if @xmath123 for some @xmath46 , then no robustness with respect to the projection on @xmath30 can be obtained ( as was also illustrated above ) .    in the following",
    "we show that one can do better by taking the robustness into account in the construction of the lattice rule itself .",
    "in this section we generalize the component - by - component algorithm from @xcite .",
    "we repeat some facts from the fast cbc algorithm of nuyens and cools  @xcite .",
    "nuyens and cools @xcite have shown how to use the fast fourier transform to reduce the computation time of the component - by - component algorithm . because of the importance of these ideas we repeat them here ( as is well understood",
    ", we see below that the algorithm of nuyens and cools actually calculates slightly more , which is important for the cbc@xmath2c algorithm below ) .",
    "for simplicity of exposition we assume product weights @xmath124 and that @xmath14 is a prime number .",
    "for more general cases see @xcite .",
    "assume that the coordinates @xmath125 are already fixed .",
    "then we write the error criterion for @xmath126 in the form @xmath127 since the components @xmath128 are fixed , the value @xmath129 and @xmath130 does not depend on @xmath131 and can therefore be ignored . thus it suffices to calculate @xmath132 we define the matrix @xmath133 and the vector @xmath134 then @xmath135 the matrix @xmath136 has some structure which allows one to use the fast fourier transform .",
    "let @xmath137 be a primitive element in the finite field @xmath138 of prime order @xmath14 .",
    "note that the multiplicative inverse @xmath139 is then also a primitive element .",
    "we define the permutation matrix @xmath140 by @xmath141 note that @xmath142 , the identity matrix .",
    "let @xmath143 be defined by @xmath144 hence @xmath145 the matrix @xmath146 is therefore circulant .",
    "let @xmath147 be the fourier matrix of order @xmath148 where @xmath149 .",
    "then @xmath150 is a diagonal matrix .",
    "thus we have @xmath151 consider now the matrix - vector multiplication @xmath152 . multiplying a vector with the permutation matrices @xmath153 takes @xmath154 operations , the matrix vector - multiplication with the matrices @xmath155",
    "can be carried out in @xmath156 operations using the fast fourier transform .",
    "multiplying the diagonal matrix @xmath157 with a vector takes @xmath154 operations .",
    "thus the matrix - vector multiplication @xmath152 can be carried out in @xmath158 operations . for more details",
    "see @xcite .",
    "notice that the fast matrix vector multiplication directly yields the whole vector @xmath159 .",
    "this vector can be ordered ( using a sorting algorithm ) to obtain @xmath160 .",
    "this can be done in @xmath158 operations .",
    "thus , by the above arguments , we can compute @xmath161 such that @xmath162 in @xmath158 operations .      in the previous section we have shown some robustness of lattice rules which are constructed for a given set of weights . in this section",
    "we modify the fast cbc algorithm @xcite to construct lattice rules for which , simultaneously , @xmath163 and @xmath164 are small .",
    "since the standard deviation @xmath164 is in general difficult to compute , we use @xmath165 as criterion instead .",
    "this has the additional advantage that the roles of @xmath166 and @xmath116 are interchangeable .    throughout the paper",
    "let @xmath167 denote the number of distinct prime factors of the integer @xmath168 .",
    "we use ( * ? ? ?",
    "* theorem  3 ) , which states that for any @xmath169 , the proportion of generating vectors @xmath7 which satisfy @xmath170 where @xmath171 is the riemann zeta function , is bigger than @xmath172 , i.e. there are more than @xmath173 generating vectors @xmath7 which satisfy the above bound ( see also @xcite for other criteria and bounds when @xmath14 is not prime ) .",
    "further , ( * ? ? ?",
    "* theorem  10 ) states that a generating vector @xmath40 which satisfies can be found component - by - component .",
    "thus we obtain the following result which follows from the fact that the intersection of two sets with measure bigger than @xmath174 and @xmath175 , where @xmath176 are such that @xmath177 , is non - empty .",
    "[ alg1 ] given : natural numbers @xmath178 , nonnegative real numbers @xmath179 for all @xmath46 ; @xmath180 , @xmath181 such that @xmath182 .",
    "* set @xmath43 ; * for @xmath183 do the following : * * * hard constraint * + let @xmath184 .",
    "find the set of integers @xmath185 which satisfies : @xmath186 for all @xmath187 and @xmath188 ( using the fast fourier transform ) .",
    "* * * soft constraint * + let @xmath189 .",
    "find the set of integers @xmath190 which satisfies : @xmath191 for all @xmath192 and @xmath193 ( using the fast fourier transform ) .",
    "* * choose @xmath194 which minimizes @xmath195 as a function of @xmath196 .",
    "* return @xmath42 .",
    "some comments are in order :    * we have @xmath197 .",
    "thus the set @xmath198 is not empty .",
    "further note that the vector @xmath199 found by algorithm  [ alg1 ] satisfies the bounds in theorem  [ thm1 ] ( see also ( * ? ? ?",
    "* theorem  10 ) ) . *",
    "the algorithm is basically symmetric in the constraints , but , by choosing @xmath180 , the first constraint is at least as hard to satisfy as the second one , since the upper bound is lower .",
    "* we have biased the algorithm towards the hard constraint . instead of choosing the value @xmath200 which minimizes @xmath201 actually any value in the set",
    "@xmath198 could be chosen .",
    "the results still apply in this case . *",
    "the classical cbc algorithm corresponds to the special case where @xmath202 and @xmath203 .",
    "further , the classical cbc algorithm can also be obtained by choosing @xmath204 ( in which case the choice of @xmath205 is irrelevant ) . *",
    "the fast cbc algorithm can be used to calculate the values @xmath206 and @xmath207 for all @xmath208 very efficiently .",
    "the values need to be sorted and then one needs to choose a value in @xmath198 .",
    "the main complexity is calculating the worst - case errors , hence the number of operations needed for the algorithm is the same as that for the fast cbc construction @xcite ( but with a larger constant since we have two worst - case errors ) .",
    "thus one has a fast cbc2c algorithm .    from ( * ? ? ?",
    "* theorem  10 ) we obtain the following result concerning the cbc@xmath1c algorithm .    [ thm1 ] let @xmath14 be an integer and @xmath209 such that @xmath182 .",
    "then the generating vector @xmath210 constructed by the cbc@xmath1c algorithm satisfies @xmath211    for @xmath109 and @xmath212 let @xmath213    we obtain the following corollary from lemma  [ lem_cheb ] and theorem  [ thm1 ] .    [ cor3 ] the generating vector @xmath214 constructed by the cbc@xmath1c algorithm satisfies @xmath215    by choosing @xmath204 , algorithm  [ alg1 ] can be simplified to the classical cbc algorithm .",
    "thus corollary  [ cor3 ] , with @xmath204 , applies to the classical fast cbc algorithm .",
    "however , in this case , if @xmath83 is small then also @xmath216 is small and thus the lattice rule may be sensitive to changes in the projection @xmath30 .",
    "unfortunately corollary  [ cor3 ] does not give any information about the set of the weights which satisfy the condition .",
    "we study this topic in the following more general setting of the cbc algorithm with @xmath2 constraints .      in this subsection , instead of two constraints we study a cbc algorithm using @xmath217 constraints . in this case",
    "one needs @xmath2 sets of weights @xmath218 which are linearly independent in @xmath219 and @xmath220 such that @xmath221 . as we will see below , adding a vector of weights @xmath222 which is a linear combination of the weights @xmath3 does not add a new constraint , since any vector satisfying the first @xmath2 constraints automatically satisfies the constraint using the weight @xmath222 .",
    "[ alg2 ] given : natural numbers @xmath178 and @xmath217 , nonnegative real vectors @xmath223 which are linearly independent in @xmath219 ; positive numbers @xmath224 which satisfy @xmath225 and @xmath221 .    * set @xmath226 for @xmath227 .",
    "* set @xmath43 ; * for @xmath183 do the following : * * for @xmath228 do the following : + find the set of integers @xmath229 which satisfies : @xmath230 for all @xmath231 and @xmath232 using the fast algorithm described above . *",
    "* choose @xmath233 which minimizes @xmath234 as a function of @xmath131 .",
    "* return @xmath42 .",
    "the considerations above imply therefore that the construction cost of the fast cbc@xmath2c algorithm is @xmath235 operations using @xmath236 storage ( note that the intersection step can be done by sorting the elements in @xmath237 first , which takes @xmath158 operations ) .    from ( * ? ? ?",
    "* theorem  10 ) we also obtain a generalization of theorem  [ thm1 ] which applies to the cbc@xmath2c algorithm .    [ thm1b ] let @xmath168 and @xmath238 be integers and @xmath220 such that @xmath221",
    ". then the generating vector @xmath210 constructed by the cbc@xmath2c algorithm using the weights @xmath3 satisfies @xmath239 and all @xmath227 .      for a @xmath240",
    "we write @xmath241 if @xmath242 for all @xmath243 , where @xmath244 and @xmath245 .",
    "similarly we use the symbols @xmath246 .    for @xmath247 and @xmath248",
    "we define the simplex @xmath249 this simplex has vertices @xmath250 and @xmath251 , @xmath243 , which stands for the vector whose @xmath252th component is @xmath23 for @xmath253 and whose @xmath254th component is @xmath65 .",
    "if @xmath255 for some component @xmath254 , then the simplex is degenerate and we consider the projection of the set onto those components which are nonzero ( which is then a nondegenerate simplex ) .",
    "let @xmath256 , @xmath257 and @xmath258 notice that since @xmath259 is the worst - case error of integration in a reproducing kernel hilbert space , we have @xmath260 and therefore @xmath261 .",
    "theorem  [ thm1b ] implies that the cbc@xmath2c algorithm now chooses the generating vector @xmath7 such that @xmath262 thus @xmath263 lies in the intersection of the simplices @xmath264 for @xmath227 : @xmath265 geometrically this means that @xmath263 lies in a convex @xmath2-polytope given by the intersection of @xmath2 simplices .",
    "the weights @xmath266 change the shape of the simplices , whereas the values @xmath267 change the size of the simplices .",
    "compared to the cbc algorithm , the component - by - component @xmath2 criteria ( cbc@xmath2c ) algorithm first increases the original simplex ( by at most a factor of @xmath268 ) and then intersect it with other simplices , see figure  [ fig1 ] .",
    "this can be used to prevent @xmath263 to be chosen too close to a vertex of the original simplex ( this prevents @xmath259 from becoming too large for some @xmath46 ) .",
    "we now study the geometry of the weights for which the corresponding square worst - case error satisfies a certain bound .",
    "since @xmath263 is fixed once a generating vector @xmath199 is chosen , we consider now the set of weights @xmath269 where @xmath248 is a real number , @xmath270 and @xmath271^s } f(\\boldsymbol{x } ) \\,\\mathrm{d } \\boldsymbol{x } \\right|\\ ] ] is the initial error @xcite . for our space",
    "we have @xmath272 .    the square worst - case error @xmath273 is a linear function of @xmath29 .",
    "thus @xmath274 is a simplex in @xmath219 given by @xmath275 which has vertices @xmath276 and @xmath277    we consider now the set of weights for which the cbc@xmath2c algorithm yields bounds .",
    "we have the following result .    [ thm2 ]",
    "let @xmath199 be constructed by the cbc@xmath2c algorithm using the weights @xmath3 .",
    "let @xmath278 for some @xmath279 .",
    "then it follows that @xmath280    by the cbc@xmath2c algorithm we have @xmath281 for @xmath227 .",
    "thus we have @xmath282 which shows the result .",
    "the above theorem shows that the cbc@xmath2c algorithm yields lattice rules which simultaneously satisfy bounds for weights @xmath283 taken from a subspace of @xmath219 spanned by @xmath284 .    the theorem above can be understood geometrically in the following way .",
    "note that @xmath285 if and only if @xmath286 .",
    "we define the new weights @xmath287 , @xmath227 for some real number @xmath248 .",
    "then @xmath288 for all @xmath227 .",
    "note that criterion in the cbc@xmath2c algorithm does not change by this normalization since the cbc@xmath2c algorithm yields exactly the same generating vector @xmath199 using the weights @xmath3 as it does for using the weights @xmath289 .",
    "thus @xmath290 now is equivalent to @xmath291 therefore , the cbc@xmath2c algorithm ensures that @xmath199 is chosen such that @xmath292 all lie in the simplex @xmath293 , i.e. @xmath294 in fact , the cbc@xmath2c algorithm finds , component - by - component , the smallest simplex @xmath295 which contains @xmath292 .",
    "if one chooses @xmath296 in the cbc@xmath2c algorithm , then the weights @xmath297 themselves are the vertices of a @xmath298-dimensional convex polytope which is contained in the simplex @xmath299 of the same dimension . however ,",
    "if @xmath300 , then the convex polytope spanned by @xmath292 is degenerate since it lies in a @xmath2-dimensional subspace . thus using only @xmath301 weights",
    "@xmath218 does not fully control the shape of the simplex @xmath299 .",
    "for the classical cbc algorithm only one vector of weights @xmath41 is used .",
    "the cbc construction then only ensures that @xmath302 . in the numerical examples below we",
    "show that it is possible for the classical cbc construction to choose generating vectors which are not suitable for many other choices of weights . by adding additional constraints",
    ", the cbc@xmath2c algorithm can prevent such bad choices .",
    "the bound in theorem  [ thm2 ] applies for all weights which lie in the linear subspace of @xmath219 spanned by vectors @xmath3 .",
    "in particular , if one uses the cbc@xmath303c algorithm , then one can obtain a bound for any choice of weights .",
    "however , in higher dimensions @xmath6 this is currently problematic for two reasons : the computational cost is exponential in the dimension ; the second problem is that one would have to choose @xmath304 such that @xmath305 .",
    "for instance , the choice @xmath306 , @xmath307 , yields a factor in the upper bound which grows exponentially with the dimension . for lower dimensions",
    "this is feasible though and hence can be useful in applications with low truncation dimension .",
    "consider now @xmath308 , where @xmath279 and @xmath309 , i.e. , @xmath41 lies in the convex polytope with vertices @xmath310.then , by theorem  [ thm2 ] , we have @xmath311 we summarize the results in the following corollary .",
    "let @xmath217 .",
    "let @xmath312 be given such that @xmath313 .",
    "let @xmath248 be a real number .",
    "let @xmath292 be weights which are normalized such that @xmath314 for all @xmath227 .",
    "let @xmath308 where @xmath279 and @xmath309 .",
    "let @xmath199 be constructed by the cbc@xmath2c algorithm based on the weights @xmath292",
    ". then @xmath315 and @xmath311",
    "to illustrate the ideas in the paper we chose some instructive examples .",
    "we tested the algorithm with @xmath316 .",
    "the computation time for the cbc@xmath1c algorithm is between @xmath1 and @xmath317 times the computation time of the cbc@xmath89c algorithm .",
    "this was observed for a variety of choices for @xmath318 and @xmath319 and values @xmath320 .",
    "further we tested the component - by - component algorithm with fast decaying weights .",
    "we used @xmath321 , product weights @xmath322 with @xmath323 , @xmath324 and @xmath325 .",
    "further we chose @xmath326 .",
    "the cbc@xmath89c algorithm using the weights @xmath327 returns the same components @xmath328 for @xmath329 .",
    "this choice of generating vector would be bad for slow decaying weights .",
    "on the other hand , the cbc@xmath1c does not return any repeated components , which is prevented by the second constraint .",
    "the results are presented in table  [ table1 ] .",
    "it shows that the cbc@xmath1c algorithm yields approximately the same results as the cbc@xmath89c algorithm constructed for the right weight , but can do significantly better if the lattice rule constructed by the cbc@xmath89c algorithm is used for different weights , as can be seen in table  [ table1 ] .",
    "the results in table  [ table2 ] are for a different choice of weights and are similar .",
    "the choice of weights @xmath330 and @xmath331 in table  [ table1 ] and table  [ table2 ] are quite different from each other .",
    "numerical tests for examples where the weights are more similar than in the examples shown , for instance @xmath332 and @xmath333 ( or even @xmath334 ) , yield numerical results which are quite similar , indicating that there are not many ( bad ) outliers .",
    "table  [ table3 ] and [ table4 ] show numerical results with randomly chosen weights , again showing that the lattice rules constructed by the cbc and cbc@xmath1c algorithms perform well except in the case where the cbc construction is based on fast decaying weights .",
    ".this table shows the square worst - case errors using the cbc@xmath1c construction based on the weights @xmath327 and @xmath335 , the cbc construction based on the weights @xmath327 and the cbc construction based on the weights @xmath335 . here",
    ", @xmath336 stands for the worst - case error @xmath337 .",
    "we choose @xmath338 , product weights with @xmath339 , @xmath340 , @xmath325 , @xmath326 ; [ cols=\">,>,>,>,>,>\",options=\"header \" , ]                          f. y. kuo , component - by - component constructions achieve the optimal rate of convergence for multivariate integration in weighted korobov and sobolev spaces .",
    "numerical integration and its complexity ( oberwolfach , 2001 ) . j. complexity , 19 , 301320 , 2003 .",
    "h. niederreiter , _ random number generation and quasi - monte carlo methods_. cbms - nsf regional conference series in applied mathematics , 63 .",
    "society for industrial and applied mathematics ( siam ) , philadelphia , pa , 1992 .",
    "e. novak and h. woniakowski , _ tractability of multivariate problems .",
    "volume ii : standard information for functionals_. ems tracts in mathematics , 12 .",
    "european mathematical society ( ems ) , zrich , 2010 .",
    "d. nuyens and r. cools , fast component - by - component construction , a reprise for different kernels . in : monte carlo and quasi - monte carlo methods 2004 , h. niederreiter and d. talay ( eds . ) , 373387 , springer , berlin , 2006 .",
    "v. sinescu and p. lecuyer , existence and construction of shifted lattice rules with an arbitrary number of points and bounded weighted star discrepancy for general decreasing weights .",
    "j. complexity , 27 , 449465 , 2011 .",
    "i. h. sloan , f. y. kuo and s. joe , on the step - by - step construction of quasi - monte carlo integration rules that achieve strong tractability error bounds in weighted sobolev spaces .",
    "math . comp .",
    ", 71 , 16091640 , 2002 ."
  ],
  "abstract_text": [
    "<S> in this paper we study lattice rules which are cubature formulae to approximate integrands over the unit cube @xmath0^s$ ] from a weighted reproducing kernel hilbert space . </S>",
    "<S> we assume that the weights are independent random variables with a given mean and variance for two reasons stemming from practical applications : ( i ) it is usually not known in practice how to choose the weights . </S>",
    "<S> thus by assuming that the weights are random variables , we obtain robust constructions ( with respect to the weights ) of lattice rules . </S>",
    "<S> this , to some extend , removes the necessity to carefully choose the weights . </S>",
    "<S> ( ii ) in practice it is convenient to use the same lattice rule for many different integrands . the best choice of weights for each integrand may vary to some degree , hence considering the weights random variables does justice to how lattice rules are used in applications .    in this paper </S>",
    "<S> the worst - case error is therefore a random variable depending on random weights . </S>",
    "<S> we show how one can construct lattice rules which perform well for weights taken from a set with large measure . </S>",
    "<S> such lattice rules are therefore robust with respect to certain changes in the weights . </S>",
    "<S> the construction algorithm uses the component - by - component ( cbc ) idea based on two criteria , one using the mean of the worst case error and the second criterion using a bound on the variance of the worst - case error . </S>",
    "<S> we call the new algorithm the cbc@xmath1c ( component - by - component with 2 constraints ) algorithm </S>",
    "<S> .    we also study a generalized version which uses @xmath2 constraints which we call the cbc@xmath2c ( component - by - component with @xmath2 constraints ) algorithm . </S>",
    "<S> we show that lattice rules generated by the cbc@xmath2c algorithm simultaneously work well for all weights in a subspace spanned by the chosen weights @xmath3 . </S>",
    "<S> thus , in applications , instead of finding one set of weights , it is enough to find an @xmath2 dimensional convex polytope in which the optimal weights lie . </S>",
    "<S> the price for this method is a factor @xmath2 in the upper bound on the error and in the construction cost of the lattice rule . </S>",
    "<S> thus the burden of determining one set of weights very precisely can be shifted to the construction of good lattice rules .    </S>",
    "<S> numerical results indicate the benefit of using the cbc@xmath1c algorithm for certain choices of weights . </S>"
  ]
}