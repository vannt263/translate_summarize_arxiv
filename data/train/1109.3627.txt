{
  "article_text": [
    "finding low - energy configurations of crystals  @xcite , disordered magnets  @xcite or proteins  @xcite , reconstructing geological structure from seismic data @xcite , and analysing x - ray data @xcite are just a few examples of optimization problems in physical sciences @xcite .",
    "various techniques have been developed to approach these problems and one of the most frequently used is genetic algorithms @xcite .",
    "their basic idea is to mimic the way biological evolution creates apparrently better fitted species .",
    "to do so one needs to represent a pool of optimization methods ( routines , functions , strategies , etc . ) as a population of individuals , which , as in nature , is subjected to two , in a sense opposing , processes . on the one hand , due to mutations or crossing - over operations , the variability in the population increases . on the other hand , to guide the evolution in a desired direction , one has to trim the population with some selection mechanisms .",
    "it turns out that such a biology - inspired scheme allows us to find optimal or nearly optimal solutions of various problems in a very efficient way  @xcite .",
    "selection is an important part of genetic algorithms since it affects significantly their convergence .",
    "the basic strategy follows the rule : the better fitted an individual , the larger the probability of its survival and mating .",
    "the most straightforward implementation of this rule is the so - called roulette - wheel selection @xcite .",
    "this method assumes that the probability of selection is proportional to the fitness of an individual .",
    "it can be briefly described as follows .",
    "let us consider @xmath0 individuals , each characterized by its fitness @xmath4  @xmath5 .",
    "the selection probability of the @xmath6-th individual is thus given as @xmath7 let us imagine a roulette wheel with sectors of size proportional to @xmath8 .",
    "selection of an individual is then equivalent to choosing randomly a point on the wheel and locating the corresponding sector ( fig .",
    "[ ruletka ] ) .",
    "when a simple search is used , such a location requires @xmath1 operations while the binary search needs @xmath2 operations .     out of consecutive sectors of length @xmath9",
    ", generates a random number @xmath10 such that @xmath11 , and locates the corresponding sector ( @xmath12 in this case ) , thus selecting the respective individual .",
    "when a simple search of an @xmath0-element list is used for location , the procedure requires @xmath1 operations , which can be reduced to @xmath2 by means of the binary search .",
    "[ ruletka],width=340 ]    there are also other methods with the selection probability depending on the fitness , such as stochastic remainder or stochastic universal selection @xcite .",
    "they have slightly different statistical properties and in general lead to populations of larger variability . in yet another class of selection methods ,",
    "the ranking or ordering of individuals rather than their fitness plays a central role  @xcite .",
    "it is certainly difficult to indicate which of these methods is the best  @xcite .",
    "although some studies suggest that fitness - based selection methods suffer from certain scaling - related problems @xcite , there are some works that seem to alleviate this difficulty @xcite .",
    "let us notice that the roulette - wheel selection is also used in the generation of complex networks .",
    "for example , in some models of growing networks , a newly added site is linked to one of the already existing sites with probability proportional to the degree of this old site @xcite .",
    "this preferential - attachment algorithm is known to generate highly heterogeneous scale - free networks , which recently have been intensively studied  @xcite .",
    "the roulette - wheel selection is also used in certain adaptive network models  @xcite .    due to simplicity of implementation and straightforward interpretation ,",
    "the roulette - wheel selection is frequently used in genetic algorithms .",
    "although the binary search significantly reduces computational complexity , still faster implementations would be , in our opinion , desirable . in the present paper , we show that the roulette - wheel selection can be realized with a simple algorithm of typically @xmath3 complexity . the proposed algorithm does not use searching but is based on a stochastic acceptance of a randomly selected individual .",
    "our algorithm consists of the following steps :    1 .   select randomly one of the individuals ( say , @xmath6 ) .",
    "the selection is done with uniform probability ( @xmath13 ) , which does not depend on the individual s fitness @xmath14 ( fig .",
    "[ ruletka - new ] ) .",
    "2 .   with probability @xmath15 , where @xmath16 is the maximal fitness in the population , the selection is accepted .",
    "otherwise , the procedure is repeated from step  1 ( i.e. , in the case of rejection , another selection attempt is made ) .",
    "of course , the probability that the @xmath6-th individual will be selected in a single attempt equals @xmath17 .",
    "however , since several first attempts might fail , one has to calculate the probability that the individual selected in an unspecified number of attempts will be the @xmath6-th individual .",
    "straightforward calculations give @xmath18 where @xmath19 is the rejection probability and @xmath20 is the average fitness .",
    "the geometrical series ( [ series ] ) is convergent ( @xmath21 ) and summing it up , we easily find that @xmath22 where @xmath23 is defined in eq .",
    "( [ prob ] ) .",
    "this shows that the probability distribution of our procedure is indeed the same as in the roulette - wheel selection .",
    "similarly , we can calculate the average number of attempts @xmath24 needed for a single selection of any individual .",
    "one obtains @xmath25=\\frac{w_{\\rm max}}{\\langle w \\rangle } \\label{tau}\\ ] ]    although @xmath24 , which determines the computational complexity of our algoritmm , does not depend explicitly on @xmath0 , the ratio @xmath26 might change with @xmath0 , depending on the specificity of the problem .",
    "we expect , however , that in many applications , for example , those where fitness remains bounded ( @xmath27 ) and @xmath28 does not diminish to 0 for increasing @xmath0 , the ratio @xmath26 does not increase unboundedly with @xmath0 and thus a typical complexity of our algorithm should be  @xmath3 .",
    "one can examine a more general algorithm where acceptance is made with probability @xmath29 , where @xmath30 is a certain constant .",
    "for such an algorithm the selection probability @xmath31 also satisfies eq .",
    "( [ pp ] ) .",
    "however , a smaller acceptance probability results in a larger rejection probability and the efficiency of the algorithm is reduced ( as @xmath24 increases ) . for @xmath32 ,",
    "some of the fractions @xmath29 may turn out greater than unity and the equality  ( [ pp ] ) does not hold .",
    "thus , the choice @xmath33 ensures optimal performance .    )",
    "an individual ( say , @xmath6 ) and accepts such a selection with probability @xmath15 , where @xmath34 is the maximal fitness . in case of rejection , the procedure is repeated anew ( i.e. , a new individual is selected repeatedly until acceptance ) .",
    "although it requires extra call(s ) of a random - number generator , it remains typically @xmath3 algorithm .",
    "[ ruletka - new],width=340 ]    to examine its performance , we applied our algorithm to a population of @xmath0 individuals with fitness being a uniformly distributed random number @xmath35 .",
    "we implemented the roulette - wheel selection algorithms using linear or binary search as well as our stochastic acceptance method .",
    "we found that the distributions of selected individuals generated by these programs were within statistical errors the same .",
    "average execution time per single selection as a function of @xmath0 is shown in fig .",
    "[ avtime ] .",
    "as expected , the linear and binary search show @xmath1 and @xmath2 behaviour , respectively .",
    "our algorithm requires basically @xmath0-independent cpu time and a slight increase for large @xmath0 is due to excessive memory requirements that exceeded the size of cache memory .",
    "we also measured the average number of attempts @xmath24 . in our numerical example , @xmath36 for large  @xmath0 , and @xmath37 .",
    "thus , according to eq .",
    "( [ tau ] ) , @xmath38 , and our numerical data are in excellent agreement with this result ( fig .",
    "[ avtime ] ) .",
    "( in @xmath39s ) of roulette - wheel selection of a single individual as a function of the population size  @xmath0 ( log - log scale ) . as expected , the linear search has the complexity @xmath1 and the binary search @xmath40 .",
    "the stochastic acceptance algorithm behaves as @xmath3 and a slight increase for the largest  @xmath0 is due to excessive memory requirements that exceeded the size of cache memory .",
    "calculations were made on the intel xeon 2.8ghz processor .",
    "filled squares show the average number of attempts per selection .",
    "[ avtime],width=340 ]",
    "as we have already mentioned in introduction , the roulette - wheel selection is used in some models of complex networks that are based on preferential attachment .",
    "the networks generated in this way are strongly inhomogeneous with a small fraction of sites having a very large degree .",
    "the distribution of weights , which are proportional to degrees , is thus very broad and the ratio @xmath26 might be quite large .",
    "consequently , the efficiency of our algorithm might diminish .",
    "however , a simple modification of the algorithm might lead to a better performance .",
    "first , let us assume that there is one weight that is much larger than the others , say @xmath41 ( @xmath42 ) . in this case we might use the following hybrid algorithm , which combines search and stochastic acceptance : with probability @xmath43 one selects the first individual and with probability @xmath44 one of the remaining @xmath45 individuals ( using roulette - wheel applied to @xmath45 weights ) . in the latter step , the stochastic acceptance should be quite efficient since the largest weight @xmath41 was removed .",
    "the probability of selection of the individual @xmath46 equals @xmath47 , thus it is indeed equal to  ( [ prob ] ) .",
    "generalization to the case where there are several much larger weights is straightforward .    to ensure a sufficiently large variability of the population ,",
    "it is sometimes desirable in optimization problems to use sampling without replacement . in order to guarantee that a once selected individual is never selected again , one can simply set its fitness to 0 .",
    "however , when the individual happened to have the maximal fitness , a new maximum should be found .",
    "sacrifying slightly the efficiency , one can use the old maximum to calculate the acceptance probability @xmath15 .",
    "similarly , when fitness of individuals is known to be bounded ( @xmath27 ) , it is not needed to keep track of the current maximum , as one can use @xmath48 as the acceptance probability .",
    "although the efficiency of the algorithm is reduced , it still should remain of the @xmath3 type @xcite",
    ".    the replacement of @xmath34 with a certain constant @xmath32 in our algorithm might be yet another way of increasing variability in the population .",
    "indeed , in such a case individuals are selected according to eq .",
    "( [ prob ] ) but with their fitness cut - off at @xmath49 ( i.e. , @xmath50 ) .",
    "our algorithm might also be adapted to evolving systems , such as , for example , complex adaptive systems where fitness of some or all individuals changes in time .",
    "let us emphasize that the performance of a selection method depends on a number of factors and also on a particular type of the optimization problem @xcite .",
    "more detailed analysis of the efficiency of our algorithm in comparison with other selection methods will be presented elsewhere .    in conclusion , we have shown that holland s original idea of using fitness - proportionate selection , i.e. , the so - called roulette - wheel selection , can be formulated as an algorithm of typically @xmath3 complexity .",
    "the numerical example shows that for sizes of populations used in genetic - algorithm applications , ranging from @xmath51 to @xmath52 , our algorithm offers a significant cpu gain over exisiting routines based on a linear or binary search .",
    "the algorithm is very simple and we expect that it can be modified and used in even more sophisticated selection schemes",
    ".    d. m. deaven and k. m. ho , phys .",
    "lett . * 75 * , 288 ( 1995 ) .",
    "n. l. abraham and m. i. j. probert , phys .",
    "b * 77 * , 134117 ( 2008 )",
    ". k. f. pal , physica a * 223 * , 283 ( 1996 )",
    ". g. m. morris , d. s. goodsell , r. s. halliday , r. huey , w. e. hart , r. k. belew and a. j. olson , j. comput . chem . * 19 * , 1639 ( 1998 ) .",
    "t. shibutani , m. sambridge , b. kennett , geophys .",
    "* 22 * , 1829 ( 1996 ) .",
    "i. golovkin , r. mancini , s. louis , r. lee , and l. klein , j. quant .",
    "tr . * 75 * , 625 ( 2002 ) .",
    "a. k. hartmann and h. rieger , _",
    "optimization algorithms in physics _",
    "( wiley - vch , 2002 ) .",
    "adaptation in natural and artificial systems _ ( university of michigan press , ann arbor , michigan , 1975 ) ; re - issued by ( mit press , 1992 ) .",
    "d.e . goldberg _ genetic algorithms in search , optimization , and machine learning _",
    "( addison - wesley , reading , massachusetts , 1989 ) .",
    "d. e. goldberg and k. deb , a comparative analysis of selection schemes used in genetic algorithms p. 69",
    "- 93 , in `` foundations of genetic algorithms '' , ed .",
    "g.j.e rawlins , ( morgan kaufmann publishers , san mateo , california , 1991 ) .",
    "p. j. b. hancock , an empirical comparison of selection methods in evolutionary algorithms , in `` selected papers from aisb workshop on evolutionary computing '' p. 80",
    "- 94 , springer - verlag , london uk ( 1994 ) .",
    "s. gupta , relative fitness scaling for improving efficiency of proportionate selection in genetic algorithms , in `` proceedings of the 11th annual conference companion on genetic and evolutionary computation conference : late breaking papers '' , p. 27412744",
    ", acm new york , ny , usa ( 2009 ) ."
  ],
  "abstract_text": [
    "<S> roulette - wheel selection is a frequently used method in genetic and evolutionary algorithms or in modeling of complex networks . </S>",
    "<S> existing routines select one of @xmath0 individuals using search algorithms of @xmath1 or @xmath2 complexity . </S>",
    "<S> we present a simple roulette - wheel selection algorithm , which typically has @xmath3 complexity and is based on stochastic acceptance instead of searching . </S>",
    "<S> we also discuss a hybrid version , which might be suitable for highly heterogeneous weight distributions , found , for example , in some models of complex networks . with minor modifications , </S>",
    "<S> the algorithm might also be used for sampling with fitness cut - off at a certain value or for sampling without replacement . </S>"
  ]
}