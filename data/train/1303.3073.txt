{
  "article_text": [
    "many important processes in nature can be described as rare events ",
    "i.e. events that happen rapidly but unpredictably , with long waiting times between occurrences .",
    "examples of such processes range from large - scale problems such as electricity or computer network failures , to molecular level processes such as the formation of crystal nuclei or vapour bubbles in metastable liquids .",
    "rare events are difficult to study , either in experiments or in computer simulations , because most of the observation time is spent waiting for the fluctuation - driven event to happen . in simulations , this problem can be overcome using rare event simulation techniques such as umbrella sampling  @xcite , bennett - chandler methods  @xcite , transition path sampling  @xcite , transition interface sampling  @xcite , milestoning  @xcite , nudged elastic band  @xcite , string methods  @xcite , weighted - ensemble methods  @xcite , non - equilibrium umbrella sampling or forward flux sampling ( or splitting)-type methods  @xcite .",
    "all of these methods aim to enhance the sampling in the region of phase space ( or trajectory space ) that corresponds to the rare event , while reducing the amount of time the simulation spends in the uninteresting phase space ( or trajectory space ) regions corresponding to the waiting times .    in this paper , we focus on the forward flux sampling ( ffs ) approach @xcite . in ffs ,",
    "one uses an order parameter to measure the progress of the system from the initial state towards the final state .",
    "the region of phase space between the initial and final states is partitioned by a series of interfaces defined by specific values of the order parameter .",
    "these interfaces are used to ratchet the system from the initial to the final state .",
    "short trajectories are fired from the initial state ; if these reach the first interface , they are used as starting points for further trajectories , which , if they reach the second interface , are used as starting points for further trajectories , etc . during this procedure",
    ", the fraction of trajectories which reach the next interface is monitored .",
    "the product of these `` success probabilities '' over all interfaces , together with the flux of trajectories out of the initial state , gives the transition rate from initial to final state .",
    "unbiased transition trajectories can be reconstructed from the collection of trajectories between interfaces .",
    "ffs provides a convenient way to simulate rare events in stochastic dynamical systems , because it is rather simple to implement and allows direct calculation of the transition rate .",
    "importantly , ffs is suitable for both equilibrium and non - equilibrium systems ( since it does not require _ a priori _ knowledge of the phase space density ) @xcite .",
    "recent advances in ffs - type methods include the development of different algorithms for the trajectory - firing procedure  @xcite , computation of phase - space densities as well as transition rates  @xcite , analysis and optimization of the efficiency of the method @xcite , and the development of ffs - like methods for systems which are out of the stationary state @xcite .",
    "while ffs is of course not a panacea for all rare event problems @xcite , it is widely and successfully used for a range of systems , some of which would be difficult or impossible to tackle with other methods .",
    "the validity of ffs has been extensively tested against brute force simulations and other rare event simulation methods for a range of problems @xcite    in this paper , we focus on the placement of interfaces in ffs .",
    "the number of interfaces and their positions are important inputs in ffs , since poor interface placement can have strongly detrimental effects on the efficiency @xcite .",
    "if the interfaces are placed too far apart the probability of reaching the next interface will be very low , and much effort will be wasted firing trajectories that fail to progress . on the other hand ,",
    "if the interfaces are too close together , trajectories will be highly correlated between successive interfaces so that little new information is gained at each interface .",
    "borrero and escobedo @xcite have shown that , for a fixed number of interfaces , the efficiency of ffs simulations is optimized when the flux of trajectories between interfaces is equalized : i.e. , for a fixed number of trial trajectories per interface , the probability of reaching the next interface should be equal for all interfaces .",
    "this criterion allows optimal interface placement , if one has prior knowledge of how the success probabilities depend on the order parameter .",
    "such knowledge is , however , not usually available .",
    "borrero and escobedo suggest beginning with non - optimized interfaces and using the constant flux criterion to iteratively improve the interface placement in successive ffs runs @xcite . while this is a good strategy for some problems , it is problematic for computationally expensive systems with high barriers . for these systems , ffs simulations with poorly chosen interface sets simply will not finish in a reasonable computational time .",
    "this forces the user to spend much effort on finding a reasonable initial interface set , by manual trial - and - error .",
    "moreover , repeating the ffs simulations to obtain iteratively better interface sets is computationally expensive . to our knowledge , the only interface - based method that does not require _ a priori _ interface placement is adaptive multi - level splitting ( ams ) @xcite . in this method ,",
    "successive interfaces are placed adaptively , based on the furthest point in order parameter space reached by previous trajectories .",
    "practical implementation of ams is , however , more complex than for standard ffs , because one needs to keep track of the histories of previous trajectories in order to determine the start points of new trajectories .",
    "this is likely to involve coding and storage overheads , particularly for large systems .    in this paper , we present two methods which allow optimal placement of interfaces in standard ffs simulations , on - the - fly , _ without any prior knowledge_. we first use theoretical arguments to estimate the optimal range for the flux between interfaces , when the number of interfaces is not fixed ( section [ sec : bg ] ) . in section [ sec : ipm ] we present our algorithms and discuss the situations in which we expect each to be advantageous .",
    "we demonstrate the performance of both methods in section [ sec : simex ] , first for a one - particle test problem and then for a computationally expensive rare event problem : crystallization in a system of yukawa particles .",
    "finally we present our conclusions in section [ sec : dis ] .",
    "in this section , we first briefly describe the `` direct '' ffs algorithm .",
    "we then review the work of borrero and escobedo which shows that , for a fixed number of interfaces , optimal efficiency requires equal fluxes between interfaces @xcite .",
    "building on this work , we establish the optimal range for the transition probability between interfaces , in the case where the number of interfaces is not constrained .",
    "this optimal range will be used as input for the computational algorithms described in section [ sec : ipm ] .",
    "the aim of ffs is to compute the transition rate @xmath0 from an initial state @xmath1 to a final state @xmath2 , while at the same time sampling the associated transition trajectories .",
    "the transition rate @xmath0 is given by @xmath3 @xcite , where @xmath4 is the flux of trajectories leaving the initial state , and @xmath5 is the probability that a trajectory that leaves the initial state will subsequently make it to the final state ( rather than returning to the initial state ) . in ffs ,",
    "the initial and final states are defined in terms of an order parameter @xmath6 , such that if @xmath7 the system is in the initial state and if @xmath8 it is in the final state .",
    "intermediate values of @xmath6 ( @xmath9 ) correspond to the `` barrier '' region .",
    "this barrier region is partitioned by a series of @xmath10 interfaces , defined by specific values of @xmath6 , such that @xmath11 , @xmath12 and @xmath13 ( see figure [ fig : ffs_fig ] ) .",
    "the probability @xmath5 can be written as @xcite @xmath14 where @xmath15 is the conditional probability that the system , having reached interface @xmath16 , subsequently goes on to reach interface @xmath17 before returning to the initial state .",
    "ffs provides a practical and efficient way to compute @xmath4 , and @xmath15 for each interface , thus allowing the computation of @xmath0 .",
    "the algorithm also generates transition trajectories . while several variants of ffs exist @xcite , we focus here on the direct ffs algorithm ( dffs ) @xcite .",
    "the dffs algorithm has two stages . in the first stage ,",
    "the flux @xmath4 across the first interface @xmath18 is computed by simulating a system in the initial state and monitoring the frequency with which the trajectory crosses @xmath18 in the direction of increasing @xmath6 . when these crossings happen , the configuration of the system is stored ; this simulation thus generates not only a measurement of @xmath4 but also a collection of @xmath19 configurations corresponding to states of the system at the moments of crossing @xmath18 . depends on good sampling of the configurations at @xmath18 : to avoid correlation between configurations arising from rapid recrossings of @xmath18 it is often best to store configurations every @xmath20 crossings ( with @xmath21 ) rather than at every crossing ",
    "see ref @xcite for further practical details . ] in the second stage of the algorithm , the probabilities @xmath15 are computed in a step - wise fashion ( see figure [ fig : ffs_fig ] for illustration ) . to compute @xmath22",
    ", one chooses configurations at random from the collection stored at @xmath18 and uses them to initiate new `` trial '' trajectories , which are continued until they either reach @xmath23 ( `` success '' ) or return to @xmath18 ( `` failure '' ) .",
    "for successful trajectories , the final configuration at @xmath23 is stored in a new collection .",
    "after @xmath24 trial trajectories have been fired , @xmath22 is computed by dividing the number of successes by @xmath24 .",
    "one then repeats the same procedure , using the configurations at @xmath23 as starting points for @xmath25 trajectories that are continued until they reach @xmath26 or return to @xmath18 , and so on , until the final interface is reached and one has a complete set of estimated probabilities @xmath15 .",
    "transition trajectories from the initial to the final state can then be reconstructed from the set of successful trajectories between interfaces  @xcite .      under the assumption that trajectories decorrelate between adjacent interfaces , analytic results for the computational efficiency of the dffs method ( and related methods )",
    "can be derived @xcite .",
    "even though these assumptions may not always be satisfied for many real problems , these analytical predictions still give a useful general guide to the performance of the method .",
    "in particular , by modelling the number of successful trajectories from interface @xmath16 as a binomially distributed random variable with parameter @xmath15 , one can obtain predictions for the computational cost , and the statistical error , associated with the computation of the rate constant @xmath0 for given choices of the number @xmath10 of interfaces , the numbers @xmath27 of trial trajectories , the number @xmath19 of configurations at @xmath18 , and for given values of @xmath15 @xcite . for dffs ,",
    "the variance @xmath28 in the estimated rate constant is given approximately by @xcite @xmath29 borrero and escobedo @xcite have shown that , for fixed @xmath10 , @xmath30 and @xmath5 , eq .",
    "( [ eq : var ] ) can be minimized by placing the interfaces such that @xmath31 is the same for all interfaces  i.e. the statistical error is smallest when the net flux of trajectories between successive interfaces is constant .",
    "assuming , for simplicity , that one fires the same number of trajectories for each interface ( @xmath32 ) , one should place the interfaces such that @xmath15 is the same for all interfaces .",
    "thus , interfaces should be closer together in `` bottleneck '' regions of the phase space ( note that here borrero and escobedo assume that , since the number of interfaces is fixed , the computational cost does not depend strongly on the interface placement , and does not need to be considered in the optimization ) .",
    "an alternative formulation of the constant flux rule , put forward by borrero and escobedo , states that the quantity @xmath33 should be linear when plotted against the interface index @xmath16 . to see this we note that if all the transition probabilities are equal , @xmath34 , then @xmath35 on can therefore measure the `` quality '' of a particular set of interfaces , either by directly asking whether the success probability @xmath15 is the same across different interfaces , or by testing whether @xmath36 is linear when plotted against the interface number @xmath16 .",
    "borrero and escobedo s work shows that for @xmath10 interfaces , the optimal positioning is such that @xmath37 ( this follows from eq .",
    "( [ eq : ppi ] ) ) .",
    "however , if we are to place interfaces optimally , on - the - fly , we also wish to optimize the number @xmath10 of interfaces .",
    "this is equivalent to optimizing the crossing probability @xmath38 , under the constraint that @xmath39 .",
    "here we compute the optimal value of @xmath38 , and we find that the efficiency is rather insensitive to @xmath38 over a broad range of parameter values .    in optimizing the efficiency with respect to @xmath38 we need to consider both computational cost and statistical error , since we expect both to depend on @xmath38 . following ref .",
    "@xcite , we define the computational efficiency of a dffs calculation as @xmath40 where @xmath28 measures the statistical error , as in eq.([eq : var ] ) , and @xmath41 is the computational cost of the calculation .",
    "an approximate expression for @xmath41 in terms of @xmath38 is given in appendix [ sec : ofc ] , where we also rewrite eq.([eq : var ] ) for @xmath28 in terms of @xmath38 and @xmath5 .",
    "combining these expressions allows us to write an approximate analytical expression for the efficiency @xmath42 , as a function of @xmath38 .",
    "this expression is given in appendix [ sec : ofc ] : it depends only on @xmath38 , @xmath5 , @xmath43 and two constants @xmath44 and @xmath45 which measure the cost of generating a single configuration at @xmath18 , and the cost of a trajectory from @xmath46 to @xmath47 ( see appendix [ sec : ofc ] ) .",
    "figure [ fig : cvem ] shows the function @xmath48 , plotted for a hypothetical rare event problem in which @xmath49 and @xmath50 , for several values of @xmath5 , @xmath44 and @xmath45 .",
    "@xmath48 is non - monotonic , with a peak at the optimal value of @xmath38 .",
    "this non - monotonicity arises from contrasting trends in the computational cost and the statistical error ( see insets to figure [ fig : cvem ] ) : while the cost increases with @xmath38 ( because increasing @xmath38 implies more interfaces , and thus more trajectories ) , the statistical error decreases with @xmath38 ( since more interfaces implies more accurate measurement of @xmath0 ) .",
    "encouragingly , for all the parameter combinations tested , the peak in @xmath48 in figure [ fig : cvem ] is rather broad , suggesting that one may achieve high computational efficiency without needing to control the interface crossing probability too precisely . for low values of @xmath38 ( less than about 0.2 ) the efficiency does , however , decrease drastically .",
    "thus our calculations suggest that placing the interfaces such that the success probability is larger than about 0.3 should generally result in high computational efficiency . however , there is of course an upper limit on the value of @xmath38 that is sensible .",
    "for very high crossing probabilities , the interfaces become very close together and trajectories between successive interfaces become correlated  a factor that is not taken into account in our theoretical analysis .",
    "this is likely to compromise efficiency because correlated measurements at closely spaced interfaces incur computational overheads but provide little extra information .",
    "taking this into account , choosing a value of @xmath38 in the range @xmath51 appears to be a sensible rule of thumb for most rare event simulation problems .",
    "we now present two algorithms which automatically position the interfaces during a dffs simulation so as to achieve a desired value of the success probability @xmath38 . at the beginning of the simulation ,",
    "the positions of the interfaces are not defined : the user specifies only the boundaries of the initial and final states ( @xmath46 and @xmath47 ) and the desired value ( or range ) for @xmath38 , as well as a minimal distance between interfaces so as to avoid correlations . starting from @xmath52 , the algorithms place interfaces on - the - fly ",
    "i.e. first the optimal value of @xmath23 is determined , then trajectories are fired to @xmath23 , then @xmath26 is optimized , then trajectories are fired to @xmath26 , etc . in these algorithms ,",
    "the number @xmath10 of interfaces adapts automatically to the choice of @xmath38 .    in order to place @xmath53 optimally ,",
    "given that the simulation has arrived at @xmath54 , one needs to make an estimate of how the transition probability @xmath55 depends on @xmath53 .",
    "both algorithms achieve this by firing a small number of `` exploratory '' trajectories from @xmath54 ; the difference between the two algorithms lies in the way that the information from these exploratory trajectories is used .      in the `` trial interface '' method we position interfaces such that the transition probability @xmath38 lies within user - defined acceptable bounds @xmath56 $ ] . to achieve this",
    ", we choose a trial position @xmath57 for the next interface , obtain an estimated transition probability @xmath58 for this trial interface , and then , based on this information , shift the trial interface until @xmath58 lies within the range @xmath59 $ ] . assuming that the dffs simulation has reached interface @xmath54",
    ", the algorithm proceeds as follows ( see also figure [ fig : auto_virtual ] ) :    1 .   choose a trial position @xmath57 for the next interface @xmath53 , in the range @xmath60 .",
    "this should be done in a way appropriate to the problem being studied ; we typically set @xmath61 , where @xmath62 , but one could also use for example @xmath63 . .",
    "2 .   using as starting points the configurations stored at @xmath54 , fire @xmath64 trajectories , which are continued until they reach @xmath57 or @xmath46 .",
    "@xmath64 should be significantly smaller than the typical number of @xmath43 trajectories per interface in the complete ffs simulation .",
    "3 .   compute @xmath65 where @xmath66 is the number of trial trajectories that reached @xmath57 .",
    "4 .   if @xmath67 , accept the trial interface . otherwise , choose a new trial interface position according to @xmath68 where @xmath69 and fire trial trajectories to obtain a new @xmath58 for this trial interface .",
    "repeat this procedure until @xmath58 lies within the desired range .",
    "if the resulting value @xmath70 , set @xmath71 , where @xmath72 is the user - defined minimal acceptable distance between interfaces . if @xmath73 set @xmath74 .",
    "5 .   set @xmath75 .",
    "continue with the dffs simulation ",
    "i.e. fire @xmath43 trajectories to @xmath53 to compute @xmath55 and obtain a new collection of configurations at @xmath53 , as in the standard dffs procedure .",
    "any trajectories previously fired to this interface during step 5 can be included in the estimate of @xmath55 .    in this algorithm , in addition to @xmath76 and @xmath77 , the user - defined parameters are the stepwidth @xmath78 ( which determines how far the interface is shifted in each adjustment step ) , @xmath64 , the number of trial trajectories used to obtain @xmath58 ( typically @xmath79 ) , and @xmath72 , the minimal acceptable spacing between interfaces .",
    "this latter parameter is introduced to avoid excessive correlation between the sampling at successive interfaces , even if @xmath76 is chosen to be small .",
    "the choice of @xmath72 depends on the choice of order parameter and the dynamics of the system being studied .",
    "for example , if the order parameter is discrete , @xmath72 should be at least one .",
    "in continuous systems , it should prevent the system from being able to cross several interfaces in a single timestep , and should be larger for systems whose dynamics is slow to decorrelate .",
    "the choice of interface shifting rule ( point 4 in the algorithm described above ) is not unique .",
    "we expect this rule to work well for systems with steep energy barriers , where one needs the initial interfaces to be closely spaced .",
    "however , for systems with flatter barriers , one might prefer to use a bisectional scheme , in which the trial interface is initially placed midway between @xmath54 and @xmath47 , and is then shifted forwards or backwards by bisecting the space between itself and either @xmath54 or @xmath47 .",
    "the trial interface method is conceptually simple and can be implemented with only very minor modifications to an existing dffs simulation code .",
    "the method also has the advantages that estimated transition probabilities for several possible trial interface positions can be computed in parallel on separate processors , and that any trial trajectories fired to interfaces that are eventually accepted can be reused in the final calculation of @xmath55 .",
    "the method does , however , have the potential drawback that it relies on a reasonably good first estimate of @xmath57 : if this first estimate is very poor , the algorithm may take many iterations to find an acceptable interface position .",
    "this problem is avoided in our second approach , the `` exploring scouts '' method .      in the `` exploring scouts '' method",
    ", we again fire @xmath64 trial trajectories from interface @xmath54 , but this time without defining a trial interface position . in this method , illustrated in figure [ fig :",
    "auto_scout ] , the trial trajectories are continued until they reach either @xmath47 or @xmath46 , or until a user - defined maximum number of steps is exceeded .",
    "the maximum value of @xmath6 achieved by each trial trajectory is monitored , and the distribution of these values is used to position the next interface such that the success probability is close to a user - defined desired value @xmath80 .",
    "the exploring scouts algorithm proceeds as follows :    1 .   fire @xmath64 trial trajectories from interface @xmath54 , starting from the configurations generated by the dffs algorithm . continue each trajectory until it either reaches @xmath47 or @xmath46 , or exceeds @xmath81 steps .",
    "record the maximum value of @xmath6 achieved in each trial trajectory .",
    "2 .   generate a ranked list of maximum @xmath6 values for all trial trajectories ",
    "i.e. assign each trajectory an index @xmath82 in the range @xmath83 , such that @xmath84 .",
    "3 .   compute @xmath85 and set the position of the next interface @xmath86 . if the resulting value @xmath87 , set @xmath88 ( where @xmath72 is the minimal acceptable spacing between interfaces as in the trial interface method ) .",
    "4 .   continue with the dffs simulation ",
    "i.e. fire @xmath43 trajectories to @xmath53 to compute @xmath55 and obtain a new collection of configurations at @xmath53 , as in the standard dffs procedure .",
    "this algorithm works because the trial trajectories , or `` exploring scouts '' , supply information on the probability of reaching a particular value of @xmath6 , for all @xmath6 in the range @xmath89 . for entry @xmath82 in our ranked list ,",
    "@xmath82 exploring scouts failed to reach @xmath90 and @xmath91 scouts reached @xmath90 or beyond ( note @xmath82 runs from zero to @xmath92 ) .",
    "the transition probability for an interface placed at @xmath90 would therefore be approximately @xmath93 .",
    "we can obtain a next interface position @xmath53 corresponding approximately to our desired transition probability @xmath80 simply by picking the @xmath94-th entry in our list of maximal @xmath6 values .",
    "more precise versions of this algorithm are of course possible ( e.g. interpolating between @xmath90 values in our list ) . however , because the efficiency is in general not very sensitive to the precise value of @xmath38 , we do not find these to be necessary .",
    "the user - defined parameters for this method are the target probability @xmath80 , the number @xmath64 of exploring scouts , the minimal interface spacing @xmath72 and the limit @xmath81 on the number of simulation steps per trial trajectory .",
    "if @xmath81 is set too low , the algorithm will fail to explore regions of larger @xmath6 , and may tend to place the interfaces too close together ( i.e. the true @xmath38 will be smaller than @xmath80 ) . choosing a large value of @xmath81",
    "will , however make the algorithm more computationally expensive .",
    "the exploring scouts method has the advantage that one knows _ a priori _ how many trial trajectories will be required to set the next interface position  this may be important in parallelized ffs applications .",
    "furthermore , the number of user - defined parameters is fewer than in the trial interface method .",
    "the exploring scouts method requires slightly more modifications to an existing standard dffs code than the trial interface method , since one needs to track the maximal values of @xmath6 for the trial trajectories , but it is nevertheless rather simple to implement .",
    "we now demonstrate our interface placement methods for two test problems .",
    "first , we study the toy problem of a single particle undergoing langevin dynamics in a one - dimensional potential ; this also provides an opportunity to test the predictions for the computational efficiency made in section [ sec : bof ] .",
    "next , we demonstrate the utility of the methods for the much more computationally demanding example of crystal nucleation in a system of particles interacting _ via _ a yukawa potential .      we first consider a single particle moving in one dimension , in a potential with two minima , defined by @xmath95 $ ] for @xmath96 in the range @xmath97 $ ]",
    "the height of the potential barrier , at @xmath98 , is @xmath99 .",
    "the particle , which is initially placed in the region @xmath100 , undergoes underdamped langevin dynamics .",
    "we set @xmath101 , @xmath102 , @xmath103 and the friction coefficient @xmath104 ; with these parameters the crossover between ballistic and diffusive motion occurs on a timescale of about 1000 time steps or a dimensionless distance of 1 .",
    "our reaction coordinate @xmath6 is taken to be the position @xmath96 of the particle and the borders of the initial and final states are defined by @xmath105 and @xmath106 .",
    "we carry out dffs simulations for this problem , using both the trial interface method and the exploring scouts method . for both methods , we set @xmath107 , @xmath108 , @xmath109 and @xmath110 . in the trial interface method , we set @xmath111 , @xmath112 and the initial trial position for interface @xmath53 is chosen to be @xmath113 . in the exploring scouts method , we set @xmath114 and @xmath115 .    figure [ fig : splp ] shows the positions of the interfaces ( main plot ) , and the resulting success probabilities @xmath55 ( inset ) , for the trial interface and exploring scouts methods .",
    "both methods produce probabilities @xmath55 that are approximately uniform across the interfaces , as desired .",
    "this corresponds to a highly non - uniform interface spacing : in fact all the interfaces are located prior to the maximum of the potential barrier , with the final interface lying close to the maximum .",
    "figure [ fig : ftifes ] shows the quantity @xmath36 , defined in eq.([eq : finter ] ) , for both methods .",
    "this is indeed close to linear , confirming that the interface placement is close to optimal .",
    "these methods allow us to choose the success probability @xmath38 and place interfaces accordingly .",
    "we can therefore use them to test the theoretical predictions made in section [ sec : bof ] for the dependence of the computational efficiency on @xmath38 . to this end , we have used the exploring scouts method to carry out a series of dffs simulations for the single particle test problem , with the transition probability @xmath38 varying between @xmath116 and @xmath117 .",
    "the parameters of the method were as above , but with @xmath118 . in these simulations",
    ", we measured the computational cost ( in simulation steps ) and the statistical error in the computed rate constant , allowing us to compute the computational efficiency @xmath119 as defined by eq.([eq : eff1 ] ) .",
    "figure [ fig : effsp ] shows the measured computational efficiency , as a function of the transition probability @xmath38 , compared to the theoretical prediction .",
    "the latter was computed using eq.([eq : eff ] ) , with @xmath120 ( the result obtained from our simulations ) , @xmath121 and @xmath122 ( both in simulation steps , and obtained by fitting the cost function to our simulation data ) .",
    "the simulations are in remarkably good agreement with our theoretical predictions , showing that the estimated optimal values of @xmath38 obtained from the theory are indeed valid , at least for this problem . taking the error bars into account , the value of @xmath5 obtained in the our simulations is independent of @xmath38 , justifying the use of @xmath38 as a performance tuning parameter and showing that the ffs method remains valid regardless of the number of interfaces ( which varies between 3 and 671 as @xmath38 is varied between @xmath116 and @xmath117 ) .",
    "we now move on to a much more challenging test problem : crystal nucleation in a system of particles interacting _ via _ a combined yukawa and weeks - chandler - andersen ( wca ) potential @xcite , @xmath123 with @xmath124 and @xmath125 the repulsive wca potential is used to model the excluded volume of the particles ( note that the energy scale for the wca potential is set to @xmath101 in our simulation units ) .",
    "the yukawa potential is a screened coulomb potential , suitable for modeling charged particles whose electrostatic interactions are screened by surrounding ionic atmospheres . in this work , the parameters of the yukawa potential are the value of the repulsive potential at contact @xmath126 ( in units of @xmath127 ) and the inverse screening length @xmath128 ( in terms of the hard - sphere diameter @xmath129 ) . despite important previous advances @xcite , the mechanism by which crystal nucleation happens in screened coulomb systems",
    "remains an open question , to which ffs simulations can contribute by providing both nucleation rates and transition paths @xcite .",
    "however , because the yukawa interaction requires a larger cutoff radius than the more widely studied lennard - jones interaction , simulations of yukawa particles are computationally expensive ( especially for low salt conditions ) , which means that the number of trial trajectories which can be performed in an ffs simulation is limited .",
    "this makes setting up standard ffs simulations difficult , particularly under interesting conditions , e.g. close to coexistence where the transition rate is expected to be low  @xcite . under these conditions ,",
    "manual placing of the interfaces can easily lead to conditions where no ffs trial trajectories succeed in reaching the next interface . for such systems ,",
    "automatic , optimal interface placement has the potential greatly to improve the feasibility and computational efficiency of ffs simulations .",
    "we performed molecular dynamics ( md ) simulations of @xmath130 wca - yukawa particles in a cubic box with periodic boundary conditions in the npt ensemble at constant pressure @xmath131 ( lj units ) with a langevin thermostat using the software package espresso @xcite in combination with dffs , implemented in our rare event sampling framework freshs  @xcite .",
    "note that ffs requires stochastic dynamics : here this is provided by the langevin thermostat .",
    "the system is initially prepared in the liquid phase , which is undercooled ( and therefore metastable ) .",
    "we are interested in the transition to the stable fcc crystal phase .",
    "our order parameter @xmath6 is the size of the largest cluster of solid particles , where particles are classified as solid or liquid based on the local @xmath132 order parameter , as used in previous work @xcite .",
    "the boundaries of the initial and final states were fixed such that the system is in the initial state if less than @xmath133 of the particles are in the largest solid cluster and in the final state if more than 90% of the system s particles are in the largest solid cluster .",
    "this corresponds to @xmath134 and @xmath135 .    in our dffs simulations , we compared three methods for interface placement : ( i ) placing the interfaces manually _ via _ a logarithmic scheme , ( ii ) the trial interface method and ( iii ) the exploring scouts method .",
    "all our dffs simulations used @xmath136 configurations at the first interface and @xmath137 trial runs per interface . here , we discuss only the performance of the interface placement methods ; the nucleation rates and pathways generated in the simulations will be presented elsewhere  @xcite .",
    "we first discuss the manual interface placement . for nucleation problems , where simulations are computationally very expensive , manual interface placement in ffs",
    "is very challenging .",
    "our problem has a steep free energy barrier and so placing interfaces evenly between @xmath46 and @xmath47 results in very poor success rates for early interfaces .",
    "in fact , for our problem , we did not obtain any successes for early interfaces even with @xmath138 evenly spaced interfaces .",
    "therefore , as a `` best possible '' manual choice , based on this prior knowledge , we placed @xmath139 interfaces logarithmically between @xmath46 and @xmath47 , with closer spacing between the early interfaces .",
    "even with this rather well - informed choice of interfaces , figure [ fig : yuk_all](a ) shows that we obtain success probabilities that are far from equal across interfaces ( inset ) . indeed ,",
    "many of the @xmath55 values are very low : this is because the free energy landscape contains unforseen bottleneck regions , in which too few interfaces were placed .",
    "because the success probabilities are low in these bottleneck regions , much computational effort will be wasted on failed trajectories .",
    "another problem is also apparent : for later interfaces , the transition probabilities are extremely high ( close to 1 ) . in this region of the free energy landscape , the crystal grows spontaneously : the placement of unnecessary interfaces implies extra computational overhead in storing configurations , etc .",
    "the fact that the manual interface placement is far from optimal is also apparent in the highly non - linear form of the function @xmath36 when plotted against the interface index @xmath16 ( main plot in fig .",
    "[ fig : yuk_all](a ) ) .",
    "we note that a commonly used approach to manual interface placement in ffs is to start with some initial guess , then if one obtains no successes for a given interface , shift it to a lower @xmath6 value and continue the ffs simulation . if not done carefully , this can actually bias the resulting computation of the rate constant @xmath0 towards higher values , since for interfaces at which by chance one obtains a large number of successes , one makes no change , but for interfaces where by chance one obtains few successes one shifts the interface .",
    "if such a shifting approach is used , bias can only avoided by repeating the entire ffs simulation _ a posteriori _",
    "- i.e. after the interface positions have been fixed .",
    "figures [ fig : p_vgl ] and [ fig : yuk_all ] also show the results of the automatic interface placement methods . for both methods , we set @xmath140 and @xmath141 . the value of @xmath72 was chosen to prevent the system from crossing several interfaces in one md timestep ( simultaneous attachment of 3 particles in one step is unlikely ) and to avoid correlation between trajectories at successive interfaces . for the trial interface method , we used @xmath142 and @xmath112 and the initial trial position for @xmath53 was set at @xmath143 . for the exploring scouts method , we used @xmath144 and @xmath145 timesteps .",
    "figure [ fig : p_vgl ] shows that both these methods produce similar interface numbers and positions , which are very different from those of our manual interface placement .",
    "the automatic methods position the interfaces much closer to the a state : in fact there are no interfaces at all for @xmath6 values greater than @xmath146 .",
    "this suggests that the free energy barrier to nucleation is located closer to @xmath46 than to @xmath47  once the system has passed the barrier , the transition probability is always greater than the target value and thus no further interfaces are necessary .",
    "however , without _ a priori _ knowledge , there would be no way to guess this when placing the interfaces manually .",
    "figure [ fig : yuk_all ] ( b ) and ( c ) show that indeed both automatic interface placement methods perform well according to our optimization criteria : the success probabilities @xmath55 are much more uniform , with no very low @xmath55 values ( insets ) . the functions @xmath36 are also much more linear for the automatic interface placement methods than for the manual interface placement ( main plots ) .",
    ".yukawa test case : rate constant @xmath0 ( in @xmath147 with the simulation time unit @xmath148 ) for dffs simulations using the manual interface placement , trial interface method and exploring scouts method . for parameter values ,",
    "see main text .",
    "the error bars in @xmath0 were determined by repeated independent simulations .",
    "[ cols=\"^,^\",options=\"header \" , ]     an obvious advantage to using the automatic interface placement methods is that setting up a dffs simulation becomes very much easier and less time - consuming than using manual interface placement .",
    "in addition , the resulting dffs calculations are more efficient with the optimized interface sets .",
    "table [ tb : simdet ] shows that the rate constants computed using the three interface placement methods are equivalent , but the error bars ( computed by repeated ffs calculations ) are larger for the manual interface placement .",
    "moreover , as shown in table [ tb : simdet2 ] , the computational cost of the ffs calculation , measured in simulation steps , was about a factor of 2 lower for the automatically placed interfaces than for those that were placed manually",
    ". had we not used our prior knowledge to place the manual interface set logarithmically , this factor would have been even greater . for this problem , the exploring scouts method required about @xmath149 fewer simulation steps than the trial interface method .",
    "table [ tb : simdet2 ] also shows estimates for the statistical errror in the rate constant ( computed using eq .",
    "( [ eq : var ] ) ) , and the resulting computational efficiency .",
    "the estimated computational efficiency is two orders of magnitude higher using the automatic interface placement methods , compared to the manual interface set .",
    "the efficiency of interface - based rare event simulation methods such as ffs is strongly dependent on the locations of the interfaces . without _ a priori _ information ,",
    "manual interface placement is a `` hit and miss '' task , that , for computationally intensive systems , often involves a large amount of user effort and results in non - optimal interface sets , for which the ffs calculations may be inefficient . in this paper , we have presented two methods for automatically placing interfaces on - the - fly in dffs simulations , so that the user need only choose the order parameter , the definitions of the initial and final states , and the target transition probability ( or its range ) . building on previous work by borrero and escobedo , we have analysed",
    "theoretically how the computational efficiency depends on the interface transition probability @xmath38 , providing an analytical expression for the optimal value of @xmath38 for a given total transition probability @xmath5 .",
    "we have further shown that in fact this optimum is broad and not very sensitive to @xmath5 , so that for most problems target success probabilities in the range @xmath150 are likely to produce satisfactory results .",
    "the lower bound of this range is set by the fact that efficiency decreases strongly when the success probability becomes too low .",
    "the upper bound is determined by the fact that trajectories will be highly correlated at successive interfaces if they are too close , meaning that little extra information is gained .    our two methods for automatic interface placement both work by firing a small number of trial trajectories from an existing interface , to determine the position of the next interface .",
    "the methods differ in the way in which the information from these trial trajectories is used . in the trial interface method ,",
    "a `` trial '' interface is placed , the probability of reaching this interface is estimated , and the trial interface is shifted until the estimated probability lies within an acceptable range .",
    "this method is very simple to implement in an existing dffs code , because the information needed from the trial runs ( simply whether they succeeded or failed ) is the same as in a conventional ffs simulation .",
    "the interface shifting step can easily be parallelized and information from some of the trial runs can be re - used in the actual ffs step once the interface has been fixed .",
    "the exploring scouts method is in some ways more sophisticated : here , trial runs are fired from the existing interface and the distribution of the maximum @xmath6 values which they reach is used to determine a position for the next interface which corresponds to the target probability .",
    "this method has the advantage that one knows _ a priori _ how many trial runs will be needed to fix the interface position ( important in some parallel implementations of ffs ) and that the maximum length of these trial runs is fixed ( albeit with some loss of accuracy in the interface position if the runs are too short )",
    ". this may be important for problems where trial runs require many computational steps ( e.g. free energy barriers that are not sharply peaked , or where returning to the initial state happens slowly ) .",
    "however , implementation of the exploring scouts method requires slightly more modifications to existing dffs codes , since one needs to know the maximal value of @xmath6 reached by the trial runs , rather than their success or failure , as in standard dffs . while we did not test it here ,",
    "one could of course combine the trial interface and exploring scouts methods within a single dffs run , for example estimating the position of a trial interface using exploring scouts , then , in a second step , firing trial runs to the trial interface to check whether its probability is acceptable .",
    "we have demonstrated the use of both methods , for a simple example of a single particle in a one - dimensional potential ( where we showed that the computational efficiency indeed agrees well with our theoretical predictions ) , and for the more realistic example of the crystallization of yukawa particles , a computationally intensive system where the nucleation free energy barrier is _ a priori _ unknown . in the latter case ,",
    "automatic interface placement led to a large saving in both user and computational time , compared to manual interface placement , even when the manual placement uses some prior knowledge of the shape of the free energy landscape .",
    "the methods presented here should greatly improve the feasibility and computational efficiency of dffs simulations for computationally expensive systems .",
    "of course , our methods and the approach of borrero and escobedo @xcite are not incompatible : having placed a set of interfaces automatically using either the trial interface method or the exploring scouts method , one can further optimize their placement iteratively via the method of borrero and escobedo , if necessary .",
    "for the rare event problem tested here ( the crystallization of yukawa particles ) , we found that this did not result in any further improvement .",
    "our focus here has been on automatic interface placement for direct ffs ( dffs ) simulations , in which the entire ensemble of trajectories is propagated forward in order parameter space , one interface at a time .",
    "in other variants of the ffs method ( e.g. branched growth , rosenbluth - like sampling  @xcite , s - pres @xcite or ns - ffs @xcite ) , transition paths from initial to final state are instead generated in a one - at - a - time fashion . it should be possible to develop modifications of the automatic interface placement methods for these ffs variants : for example applying either the trial interface or exploring scouts method to fix the interfaces during the generation of the first transition path .",
    "the approaches presented here should also be compatible with other interface - based rare event simulation methods such as transition interface sampling  @xcite .",
    "finally we note that the methods described here could be extended to interfaces that depend on more than one order parameter .",
    "for example , in the exploring scouts method , one might track the trajectories of the scouts in two coordinates and set the interfaces to be optimal lines in the space of these coordinates .",
    "as well as optimising interface placement , this could also provide a way to adjust the choice of reaction coordinate , on - the - fly during an ffs simulation .",
    "the methods described in this paper have already been implemented in the parallel rare event simulation framework freshs  @xcite , which allows the generic use of both ffs and other rare event simulation methods .",
    "this framework will soon be publicly available as an open - source package .",
    "the authors thank kevin stratford , juho lintuvuori and chantal valeriani for helpful discussions .",
    "r.j.a . was funded by a royal society university research fellowship and by epsrc under grant epsrc / ep / i030298/1 .",
    "a.a . and k.k",
    ". were funded by the cluster of excellence `` simtech '' , university of stuttgart .",
    "here we describe in more detail our theoretical analysis of the computational efficiency of dffs , and present our analytical expression for the efficiency as a function of the transition probability .",
    "we assume that the transition probability @xmath151 is the same for all interfaces .",
    "in contrast to the work of borrero and escobedo @xcite , we do not fix the number @xmath10 of interfaces .",
    "instead , @xmath10 is determined by the relation @xmath152 where @xmath153 is the probability that a trajectory leaving @xmath1 reaches @xmath2 before returning to @xmath1 .",
    "following @xcite , we define the computational efficiency as @xmath154 where @xmath155 and @xmath156 represent the computational cost of an ffs calculation , and the statistical error ( variance ) in the resulting rate constant measurement .",
    "we use the expressions for @xmath155 and @xmath156 derived in @xcite to predict the dependence of @xmath42 on the transition probability @xmath38 .",
    "the computational cost of a dffs calculation , in simulation steps , is approximated in @xcite by @xmath157 where @xmath19 is the number of configurations stored at @xmath46 , @xmath44 is the cost of generating each of these configurations , @xmath43 is the number of trials per interface ( note we have assumed this to be constant ) and @xmath158 is the average cost of firing a trial run from interface @xmath16 . note that eq.([eq : cost ] ) describes the total cost of the ffs run rather than the cost per configuration at @xmath46 , as in ref .",
    "simplifying somewhat the calculation in @xcite , we assume that the cost of a trial run is linearly proportional to the number of interfaces that it crosses , with proportionality constant @xmath159 ( since the spacing between interfaces is inversely proportional to @xmath10 ; thus @xmath45 is the cost of a trajectory from @xmath1 to @xmath2 ) .",
    "thus a trial run from @xmath54 to @xmath53 has cost @xmath159 while a run from @xmath54 to @xmath46 has cost @xmath160 .",
    "taking into account the relative probabilities of these outcomes gives @xmath161   \\label{eq : ci}\\ ] ] resulting in the following expression for the cost : @xmath162 } \\\\",
    "= n_0\\left(r+\\frac{sk}{2n } \\left[2p(n-1 ) + n(n-1)(1-p ) \\right]\\right ) \\end{split }   \\label{eq : costnew}\\ ] ] where @xmath163 .",
    "the first result in eq.([eq : costnew ] ) is identical to eq.([eq : cost ] ) in the main text . substituting in the expression for @xmath10 in terms of @xmath5",
    "we obtain an expression for the cost in terms of @xmath38 and @xmath5 : @xmath164 . \\end{split }   \\label{eq : costpb}\\ ] ]          bringing together eqs . , and , we obtain the following expression for the computational efficiency in terms of @xmath38 and @xmath5 : @xmath168^{-1 }   \\end{split }   \\label{eq : eff}\\ ] ] expression ( [ eq : eff ] ) was used to generate the data shown in figure [ fig : cvem ] ."
  ],
  "abstract_text": [
    "<S> forward flux sampling ( ffs ) provides a convenient and efficient way to simulate rare events in equilibrium or non - equilibrium systems . </S>",
    "<S> ffs ratchets the system from an initial state to a final state via a series of interfaces in phase space . </S>",
    "<S> the efficiency of ffs depends sensitively on the positions of the interfaces . </S>",
    "<S> we present two alternative methods for placing interfaces automatically and adaptively in their optimal locations , on - the - fly as an ffs simulation progresses , without prior knowledge or user intervention . </S>",
    "<S> these methods allow the ffs simulation to advance efficiently through bottlenecks in phase space by placing more interfaces where the probability of advancement is lower . </S>",
    "<S> the methods are demonstrated both for a single - particle test problem and for the crystallization of yukawa particles . by removing the need for manual interface placement , our methods both </S>",
    "<S> facilitate the setting up of ffs simulations and improve their performance , especially for rare events which involve complex trajectories through phase space , with many bottlenecks . </S>"
  ]
}