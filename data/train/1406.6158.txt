{
  "article_text": [
    "gravitational n - body simulations deal with the motions of the many bodies ( particles ) interacting with other particles by gravitational force and are used for solving astronomical problems : formation of stars and galaxies .",
    "there are basically two types of n - body systems : collisional and collision - less systems . in a collisional system ,",
    "a number of particles is relatively small and the orbit of the particles is significantly deformed by force from the nearby particles . in a collision - less system ,",
    "a number of particles is large and the effect from near particles is relatively small .",
    "also it does not necessary require highly accurate force calculation .",
    "a most simple algorithm for calculating forces ( or acceleration ) between these bodies is a direct algorithm that calculates interactions of all @xmath0 pair of particles .",
    "however , we can reduce the calculation complexity by barnes - hut tree algorithm that approximates forces from many source particles as force from one source particle by tree structure for particles @xcite .",
    "the calculation complexity of the tree algorithm is @xmath1 , but accuracy of force is worse at the expense of the approximation .",
    "as the tree algorithm , many techniques for reducing calculation time of n - body simulation have been developed so far .",
    "however , it is necessary to further speed - up the calculation for large - scale simulations .",
    "we usually speed - up n - body simulations by parallel computing using message passing interface ( mpi ) along with acceleration techniques such as graphical processing units ( gpu ) . nowadays",
    ", gpu is used for not only graphic processing but also general purpose processing .",
    "gpu enables us to accelerate n - body simulations by running the tree algorithm on it @xcite .    as an approach for further reducing calculation cost of the tree algorithm",
    ", we can extend particle - particle particle - tree(pppt ) algorithm @xcite .",
    "pppt algorithm is a hybrid of direct and tree algorithms for collisional simulation . in the method",
    ", we split gravitational force into short - rage and long - range force .",
    "the accurate direct algorithm is used for calculating short - range force while we use the tree algorithm for calculating long - range force .",
    "we apply different time integration methods for the two parts of the force .",
    "accordingly , we only adopt high accuracy methods for short - range force and can reduce the cost of unimportant ( distant and weak ) force calculation . in this paper , we show a new algorithm based on pppt scheme for reducing calculation and communication cost of parallel n - body simulations .",
    "we evaluated the performance of our algorithm on gpu clusters where each node of the cluster is equipped with gpus .",
    "in this section , we describe basic concepts for our hybrid tree algorithm",
    ".      motions of gravitational bodies follow the following equation of motion , @xmath2 here , @xmath3 is softened gravity force expressed as @xmath4 where @xmath5 is a position of a `` sink '' particle that is forced from other particles , and @xmath6 is a position of a `` source '' particle that exerts the force to other particles , @xmath7 is a mass of the sink particle , @xmath8 is a gravitational constant , and @xmath9 is the softening length to reduce non - realistic acceleration when @xmath10 .",
    "simply , we calculate all pair interactions of particles for calculating right hand side of equation ( [ nbforce ] ) .",
    "we call the simple algorithm for calculating force to a particle brute - force algorithm or direct algorithm",
    ".    we solve the motion of particles by numerical integration of a position of each particle with the calculated force .",
    "actually , the integration is performed by updating velocities followed by updating positions of particles .",
    "this integration scheme is called the leap - frog method .",
    "the leap - frog scheme is a second - order symplectic integrator .",
    "a velocity and a position of a particle are updated as follow , @xmath11 where @xmath12 is velocity of a particles at time @xmath13 , @xmath14 is position of a particle at time @xmath13 , @xmath15 is a time - step for integration . in the following ,",
    "we call the velocity update as `` kick '' and the position update as `` drift '' .",
    "the tree algorithm is a technique for reducing the cost of force calculation for large - scale simulations @xcite .",
    "the concept of tree algorithm is that we approximate force from many distant source particles into force from one source particle as the center of mass of the particles .",
    "force calculation by tree algorithm is performed as follow : constructing tree ; calculating center of mass of tree nodes and criterion for depth of tree traversal ; and traversing tree and calculating force .    for constructing tree structure ,",
    "we divide three dimensional space into eight equal size cells recursively from root cell that contains all particle in the system .",
    "the division is recursively continued while the cell has many particles than a critical number of particles @xmath16 . as the result ,",
    "the particles are placed on leaves of the tree .",
    "next , to approximate distant particles , we calculate center of mass of cell for each cell .    then , we calculate multi - pole acceptance criterion ( mac ) of each tree node as the criterion for tree traversal .",
    "mac determines whether we further traverse leaf cells of the cell or calculate force from the cell .",
    "we use absolute mac @xcite , @xmath17 where @xmath18 is the maximum distance between the center of mass and particles in the cell , @xmath19 is a position of a center of mass of source cell , and @xmath20 is the number of particles in the cell .",
    "@xmath21 is a numerical parameter specified by user to control the accuracy of force calculation .",
    "finally , we traverse the tree for calculating force .",
    "we start from root cell .",
    "if @xmath22 , where @xmath23 is a distance between sink particle and center of mass of source cell , we further visit to leaf cells to traverse in more detail , else we add the force from the cell and go to next node .",
    "after tree traversal , we get the force of a sink particle by summing forces from source cells and particles .      here",
    ", we explain an algorithm we proposed based on pppt algorithm for collision - less systems .",
    "our algorithm is the similar to pppt algorithm : splitting force into hard - force from near particles and soft - force from distant particles but we adopt a different numerical method for the hard - force part . in the original pppt algorithm ,",
    "the direct algorithm is used for high accuracy calculation of hard - force .",
    "the high accuracy is not necessary for collision - less simulation , thus we can design our algorithm for hard - force having lower accuracy than original pppt algorithm .",
    "another difference of our algorithm is that we try to speed - up the calculation by reducing communication cost in parallel computing .",
    "the force is divided by using a kernel function @xmath24 as follow .",
    "@xmath25 where @xmath26 is the hard - force , and @xmath27 is the soft - force . for a kernel function ,",
    "we use the dll function ( adopted in @xcite ) written as follows , @xmath28 where @xmath29 , @xmath30 and @xmath31 are constants specified by user determining the size of transition zone between hard and soft forces .",
    "we use the tree algorithm and the leap - frog for both of soft and hard forces but the time - step for soft ( @xmath32 ) and hard ( @xmath33 ) are different .",
    "we make the relation between @xmath32 and @xmath33 as @xmath34 , where @xmath35 .",
    "illustration of our integration is shown in figure [ fig : ht ] .",
    "we call the step calculating both of soft and hard force `` soft - step '' and the step of calculating only hard - force `` hard - step '' ; we need one soft - step and @xmath36 hard - steps to calculate time evolution for @xmath37 .",
    "since the soft - step theoretically require the position of all particles but the hard - step only relies on the position of near particles , we expect that calculation and communication cost of the proposed hybrid tree algorithm is lower than the normal tree algorithm .",
    "the time integration error of our algorithm expected to be slightly larger than the normal tree algorithm with time - step @xmath38 due to reduction of long - range force calculation .",
    "however , we can control the error by choosing appropriate parameters for @xmath32 , @xmath33 , @xmath39 , @xmath30 , and @xmath31 .    .",
    "in this section , we present how we use make our parallel using openmp and mpi along with explanation for gpu computing .      in this section ,",
    "we show the procedure and data structure for our tree algorithm .",
    "our method is based on @xcite as constructing tree by cpu and traversing tree by gpus .      first , we construct tree structure of particles .",
    "we make cell - nodes above the particle - nodes and connect the nodes with pointers . in the method , each node has `` more '' pointer to the first leaf cell and `` next '' pointer to the next cell / particle to traverse skipping over leafs .    for tree construction ,",
    "we first calculate the region and size of the root cell that include all particles .",
    "then , we calculate keys of the particles .",
    "we use the morton key as the key that is following order of morton curve ( or z - curve ) , a space filling curve .",
    "the advantage of moron key is that it encodes hierarchical information of position of particles .",
    "the key calculation is able to be executed individually for particles , thus we use openmp for parallelizing the calculation .",
    "second , we sort the keys .",
    "we use the extension of c++ standard library std::sort for sorting in parallel with openmp .",
    "we also sort the data of the positions of the particles to preserve locality of the particles .",
    "third , we divide the array into eight sub - arrays by the three most significant bits of the keys , then we set a cell node with `` more '' pointer and `` next '' pointer and make child cells with next pointers .",
    "then we recursively repeat the procedure for every three bits of key while the array has @xmath16 or more particles .",
    "if the array has particles fewer than @xmath40 , we treat each particle as leaf node . finally , we need to calculate center of mass and mac of each cell .",
    "both of them are calculated from position and mass of particles contained in the cell .",
    "thus , we calculate center of mass and mac by traversal of the part of tree , and the calculation is individual for each cell , and we parallelize the calculations by openmp .",
    "we use gpus for tree traversal and force calculation .",
    "this part is implemented in opencl , the framework for parallel computing .",
    "first , cpu sends the data of tree to gpu .",
    "then , we run the kernel code for traversing tree .",
    "the kernel code traverse the tree by indexing `` more '' and `` next '' pointers .",
    "the tree traversal is individually executed for each sink particle .",
    "thus , all threads are run by gpus in parallel .",
    "in addition , for reducing a number of tree traversal , multiple sink particles traverse in same thread .",
    "the number of particles traversing in same thread is @xmath41 .",
    "we typically set @xmath42 as efficient number of particles for gpu .",
    "as a distance for determining whether traverse the children or not , we use minimum distance between a source cell @xmath43 and @xmath41 sink particles @xmath44 ; we traverse the leaf if @xmath45 for @xmath46 .",
    "if particles are unsorted , and @xmath41 particles are distant each other , we need to traverse unnecessary nodes because @xmath47 may be small for distant cell .",
    "thus , for reducing unnecessary traversal , we should sort the particle data so that we retain data locality of positions of particles .      our method of parallelization is that we assign each mpi process own region that contains subset of particles , and each mpi process calculates force by own particles and particles received from other processes .",
    "we have already presented the parallelization on each process attached gpu . here , we show the implementation of parallel computation and communication of our algorithm on gpu clusters .",
    "our procedure for parallel n - body simulations is as follow ,    1 .",
    "domain decomposition 2 .",
    "constructing local tree 3 .   calculating force from local tree 4 .",
    "communicating tree from remote processes 5 .   calculating force from remote tree 6 .",
    "updating positions and velocities of local particles      first , we need to distribute particle data to each process . to simplify communication for hard - force calculation , a shape of a region of a process should be a cuboid . as the method of cuboid domain decomposition , we use the method introduced in @xcite . with the method , we decompose whole region into @xmath48 regions , where @xmath49 and@xmath50 are the number of division in @xmath51 and @xmath52 direction .",
    "the decomposition is implemented as exchanging of particles between neighbor processes given pre - determined boundaries between regions .    to determine the boundaries",
    ", we use the sampling domain decomposition method used in @xcite . in the method , we gather sample particles to a main process , then the main process tries to balance the boundaries such that each process has approximately same number of sample particles .    . ]    illustration of sampling domain decomposition is shown in figure [ fig : dd ] . here , the number of sample particles @xmath53 is defined for balancing the sum of the number of local particles that are assigned to each process @xmath54 and the number of particles received from other processes for hard - force calculation @xmath55 .",
    "@xmath53 for process @xmath44 is determined as follow ; @xmath56 where @xmath57 is the total number of particles , @xmath58 is sampling rate constant , and @xmath59 is a correction factor for balancing .",
    "we typically set @xmath60 in the present work .",
    "@xmath61 is the measure for load balancing defined as @xmath62 our intention is that we make the calculation cost for hard - force equal on all processes because the calculation is the majority of running time in our case .",
    "after the main process determines the boundaries , it broadcasts the result to all other processes , and each process exchanges necessary particle data between other processes .",
    "to reduce the cost of domain decomposition , we execute it only for every soft - step ; at hard - steps , a process has the same particles as the previous soft - step .",
    "after construction of tree structure of local particles , we need to communicate the particles of other processes to calculate the force from the particles . in our method , we need different set of particles for hard and soft force , respectively .    for communicating the soft particles , we need data of all particles , but distant particles are able to be approximated as the center of mass of the cells . locally essential tree (",
    "let ) is the method for communicating only necessary part of tree for the processes @xcite . for determining the cells to send",
    ", we traverses the local tree with mac , @xmath63 where @xmath64 is the distance between center of mass of cell @xmath44 and boundary of process @xmath43 , and @xmath65 is the mac calculated by method in section [ sec : tree ] .",
    "we only send the position and the mass of center of mass for a cell .",
    "both the calculation cost for determining cells to send and the cost for communicating cells are @xmath66 . as the result of communication , a process get the cells that we need to calculate the force in the process as shown in figure [ fig : comm2 ] . here , we show the cells that upper - left process needs to receive from other processes .",
    "we use mpi asynchronous send and receive functions to exchange data . after the communication",
    ", the process concatenates the arrays of own particles and the cells received by neighbor processes and constructs a let .",
    "then , we traverse the tree and calculate force from the remote particles to local particles .        for hard - force",
    ", we also use let scheme , but a process only need cells around the boundary that is at the distance less than @xmath31 as showing in the red cells in figure [ fig : comm2 ] . to determine the cells to send , we traverse the local tree .",
    "in addition to mac in equation ( [ eqn : mac ] ) , the condition to determine whether traverse the leaf for searching the cells or not is applied as follow @xmath67 after the tree traversal , we obtain the cells in the process that the distance to boundary of process @xmath43 is smaller than @xmath31 .",
    "the communication cost for hard - force is smaller than for soft - force . especially , the cost is significantly reduced in large number of processes because of reduction of volume that a process needs to consider .",
    "we execute the force calculation on gpus and other calculations on host cpu .",
    "thus , we overlap both calculation with communications . while traversing the tree in gpus , cpu communicate particles and construct a let using received particles . while gpus run kernels , we need to retain a thread for management of the gpu .",
    "the thread is generated by using pthread api , an programming interface the interface for thread programming .",
    "as the result of the overlap , the total calculation time of the overlapped processes is constrained by the maximum calculation time of the cpu threads and the gpu .",
    "however , we need a cpu thread for organizing queuing jobs to opencl device such as gpu . thus , performance of calculations that use openmp may be decreased .",
    "in this section , we present the performance evaluation of n - body simulations with our hybrid tree method .      for the test of our algorithm , we use plummer model @xcite .",
    "the plummer model is a typical spherical model of n - body simulations .",
    "we set @xmath68 , and @xmath69 , where @xmath70 is mean velocity of the system in the case of our simulation @xmath71 , as being in range of optimal parameters for the model shown in @xcite .",
    "we have the following numerical parameters that control the balance between the execution time and accuracy of the simulations : @xmath72 , @xmath39 , @xmath30 , and @xmath31 . in the present work",
    ", we typically set @xmath73 .",
    "@xmath39 , @xmath30 , and @xmath31 should be adjusted for maintaining sufficient accuracy of error in total energy of the system that is the sum of kinetic and potential energy after simulation . by the result of test simulations for our model , we choose an optimal parameters as @xmath74 , @xmath75 , and we sent @xmath76 in the present work .",
    "development and computations for the present work have been carried out under the `` interdisciplinary computational science program '' in center for computational sciences , university of tsukuba .",
    "a node of ha - pacs has two intel e5 - 2670 ( 8 cores ) cpus with four nvidia tesla m2090 gpus .",
    "actually , we assign four mpi processes per node of ha - pacs such that one mpi process is exclusively assigned one gpu board .      here",
    ", we compare the calculation cost of kernel for calculating hard - force by our algorithm and communication cost with the normal tree algorithm with let .    in hard - force calculation , we can cut - off the tree traversal for distant cells .",
    "thus , the cost for hard calculation is reduced if we set small @xmath30 and @xmath31 . as the result of our test simulations , for @xmath57 between 256k and 4096k ,",
    "the time for calculating hard force at optimal @xmath77 is about 40% of the time for calculating force with normal tree algorithm .",
    "next , we analyze the cost for communicating of our algorithm with the normal tree algorithm . for the test , we set @xmath78 ( @xmath79 ) . in figure [ fig : nphs ] , the solid red line shows the ratio between the average number of hard particles @xmath80 and soft particles @xmath81 as a function of @xmath82 , the number of processes .",
    "this ratio is an indicator of the reduction of cost for gpu computing and is roughly constant at 40% .",
    "the dotted green line shows the ratio between the average number of local plus hard particles @xmath83 and local and soft particles @xmath84 .",
    "since the communication cost for our algorithm and the normal tree are proportional to @xmath83 and @xmath84 , respectively , we see that our algorithm works better in large @xmath82 due to the reduction of communication . for larger @xmath82",
    ", we have smaller the ratio as @xmath85 70 % at @xmath82 = 128 .     and @xmath86 as a function of @xmath82 . ]",
    "we evaluate the scalability of our simulation with gpu clusters .",
    "it is not easy to reduce the execution time by number of processes linearly , e.g. good strong scaling , even if our hybrid tree algorithm can reduce the communication cost by reducing the volume of interest for communication . for the test",
    ", we run a series of simulations with @xmath87 1 m ( m = @xmath88 ) to 64 m on up to @xmath89 using 32 nodes of ha - pacs .",
    "figure [ fig : scaltime ] shows the strong scaling result of our simulation ; capability of the speed - up with many processes for fixed total number of particles . here",
    ", we plot the average execution time for simulating @xmath37 time evolution as a function of @xmath82 .",
    "the time evolution of @xmath37 is completed with one soft - step and three hard - steps in the present work ( we set @xmath90 ) .",
    "we omit some cases of the simulations that were not able to run due to the limitation of gpu memory in the figure . the execution time",
    "is reduced in @xmath91 for small @xmath82 , but the time hardly reduces at large @xmath82 and small @xmath57 . for @xmath92 ,",
    "the reduction of the execution time stops at @xmath93 . for @xmath94 , the execution time",
    "is reduced approximately linearly , and the time at @xmath89 is 59% of the time at @xmath93 . as the result ,",
    "the execution time is sufficiently reduced when @xmath95 ; the calculation time with @xmath96 processes is typically less than 60% of that with @xmath82 processes .    in figure",
    "[ fig : dettimet ] , we present the detailed breakdown of the execution time for hard - step , soft - step , and domain decomposition for the simulation with @xmath97 . here , @xmath98 , @xmath99 , @xmath100 , and @xmath101 are the execution times of total for simulating @xmath37 , one hard - step , one soft - step , and domain decomposition , respectively .",
    "the relation between those timing is expressed as @xmath102 .",
    "@xmath99 is reduced to about 60% of @xmath100 for any @xmath82 . @xmath99 and @xmath100 are reduced as increasing of @xmath82 . in @xmath99 for @xmath89 , time for force calculation , tree construction , and communicating cells are 26% , 37% , and 54% , respectively . the sum of percentages of time is larger than 100% because kernel execution on gpu and other processes on cpu are overlapped .",
    "@xmath101 is not reduced and be around 0.1 seconds for this case .",
    "the reason is that communication and calculation cost for domain decomposition depends on not @xmath82 but @xmath57 as shown in section [ sec : dd ] .",
    "since the core of our tree code is written in opencl api , we can use not only gpus but cpu threads to compute the tree travarsal kernels for hard and soft force . for @xmath103 m runs , the total execution time with @xmath104 is 113 , 30.6 , and 5.51 seconds , respectively while the runs with gpus took 13.6 , 3.55 , and 0.688 seconds .",
    "the speed - up factor due using gpus with @xmath104 is 8.3 , 8.6 , and 8.0 , respectively where we compare the time for all computation and comunication . to be more specific only on computation",
    ", we found the speed - up factor of the execution of opencl kernels is 11 - 16 times faster than the runs with cpu threads .",
    "our hybrid tree algorithm can take huge advantage of the acclearation with the gpu technology .      here",
    ", we compare the result of the execution time of our algorithm to the normal tree algorithm with let that does not split force into two parts .",
    "to achieve approximately same total energy error between two algorithms , we set @xmath105 , where @xmath106 is the time - step of the normal tree .",
    "in addition , domain decomposition in the normal tree is executed every four steps to fairly compare the execution time .",
    "figure [ fig : ration ] shows the reduction of the execution time of the hybrid tree algorithm versus the normal tree algorithm @xmath107 , where @xmath108 and @xmath109 is the execution time of the hybrid tree and the normal tree for same simulation time @xmath110 .",
    "we can reduce the time to about 80% - 90% of that of the normal tree . especially , for @xmath111",
    ", @xmath112 is even smaller as @xmath82 is larger .",
    "this means that our hybrid tree algorithm has the advantage for large - scale simulations .",
    "the theoretical reduction of the hybrid tree @xmath113 is estimated as @xmath114 where @xmath115 is the execution time of the normal tree algorithm . according to the results in section [ sec : red ] and [ sec : scal ] , it is expected that the hybrid tree algorithm can reduce the cost for hard - force to about 60 % of soft - force for large @xmath82 .",
    "thus , assuming that @xmath116 , @xmath117 , and @xmath74 , then @xmath118 ; we can ultimately speed - up the calculation with hybrid tree to 70% of the normal tree for large @xmath82 except for time for the domain decomposition .",
    "ogiya et al . implemented parallel tree n - body code on ha - pacs @xcite .",
    "their gpu code use the same algorithm @xcite also used in the present work .",
    "however , the detailed implementation details of their tree traversal kernels and domain decomposition are different . in @xcite",
    ", they presented a model of cdm ( cold dark matter ) , and they claimed it was hard to keep load balance when @xmath111 . for @xmath97 and @xmath119 , the execution time for four time - steps in @xcite @xmath120 8.2 seconds and the execution time for three hard steps and one soft step in our work @xmath121 6.8 seconds and @xmath122=0.83 . for @xmath93 ,",
    "@xmath120 3.0 seconds and @xmath121 1.1 seconds and @xmath122=0.37 .",
    "although the implementation and a simulation model are different to @xcite , our algorithm can efficiently reduce execution time for scalable computation .",
    "in this work , we developed a new algorithm for n - body simulations named hybrid tree algorithm , the algorithm for accelerating collision - less n - body simulation by splitting the force from other particles into short - range and long - range forces .",
    "the proposed hybrid tree algorithm is effective to reduce the calculation cost and communication cost for simulations .",
    "we have implemented the algorithm on gpu clusters up to 128 processes , and we showed that the hybrid tree algorithm can reduce the execution time up to 80% of the normal tree algorithm .",
    "as future work , we should investigate the scalability and speed - up of our algorithm with more scalable computing systems .",
    "in addition , we will investigate whether our algorithm is efficient for other systems and other parameters because we have simulated the algorithm with only limited combinations of parameters and only on plummer model .",
    "shoichi oshino , yoko funato , junichiro makino , `` particle - particle particle - tree : a direct - tree hybrid scheme for collisional n - body simulations '' , publications of the astronomical society of japan , vol.63 , no.4 , 2011 , pp .",
    "881 - 892                  go ogiya , masao mori , yohei miki , taisuke boku , naohito nakasato , `` studying the core - cusp problem in cold dark matter halos using n - body simulations on gpu clusters '' , 2013 j. phys ."
  ],
  "abstract_text": [
    "<S> we propose a hybrid tree algorithm for reducing calculation and communication cost of collision - less n - body simulations . </S>",
    "<S> the concept of our algorithm is that we split interaction force into two parts : hard - force from neighbor particles and soft - force from distant particles , and applying different time integration for the forces . for hard - force calculation </S>",
    "<S> , we can efficiently reduce the calculation and communication cost of the parallel tree code because we only need data of neighbor particles for this part . </S>",
    "<S> we implement the algorithm on gpu clusters to accelerate force calculation for both hard and soft force . as the result of implementing the algorithm on gpu clusters </S>",
    "<S> , we were able to reduce the communication cost and the total execution time to 40% and 80% of that of a normal tree algorithm , respectively . </S>",
    "<S> in addition , the reduction factor relative the normal tree algorithm is smaller for large number of processes , and we expect that the execution time can be ultimately reduced down to about 70% of the normal tree algorithm . </S>"
  ]
}