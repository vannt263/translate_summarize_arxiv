{
  "article_text": [
    "machine learning techniques provide consumers , researchers and businesses with valuable insight .",
    "however , significant challenges arise when scaling the corresponding training algorithms to massive datasets that do not fit in the memory of a single machine , making the implementation as well as the design of distributed algorithms more demanding than that of single machine solvers .",
    "going distributed involves a lot of programming effort and system - level knowledge to correctly handle communication and synchronization between single workers , and , in addition , requires carefully designed algorithms that run efficiently in a distributed environment . in the past decades",
    "distributed programming frameworks such as open mpi have empowered rich primitives and abstractions to leverage flexibility in implementing algorithms across distributed computing resources , often delivering high - performance but coming with the cost of high implementation complexity .",
    "in contrast , more _ modern _ frameworks such as hadoop and sparkhave recently emerged which dictate well - defined distributed programming paradigms and offer a powerful set of apis specially built for distributed processing .",
    "these abstractions make the implementation of distributed algorithms more easily accessible to developers , but seem to come with poorly understood overheads associated with communication and data management which make the tight control of computation vs communication cost more difficult . in this work",
    "we will analyze these overheads and show that to minimize their effect  and thus to design and implement efficient real - world distributed learning algorithms using apache spark it is important to be aware of these overheads and adapt the algorithm to the conditions given .",
    "hence , understanding the underlying system and adapting the algorithm , remains the key to performance even when using apache sparkand we demonstrate that a careful tuning of the algorithm parameters can decide upon several orders of magnitude in performance .",
    "the three main contributions of this paper are the following :    * we provide a fair analysis and measurements of the overheads inherent in spark , relative to an equivalent mpi implementation of the same linear learning algorithm .",
    "in contrast to earlier work @xcite we clearly decouple framework - related overheads from the computational time .",
    "we achieve this by off - loading the critical computations of the spark - based learning algorithm into compiled c++modules .",
    "since the mpi implementation uses exactly the same code , any difference in performance can be solely attributed to the overheads related to the spark  framework .",
    "* we demonstrate that by using such c++modules we can accelerate spark - based learning by an order of magnitude and hence reduce its relative loss in performance over mpi from @xmath0 to an acceptable level of @xmath1 .",
    "we achieve this by , firstly , accelerating computationally heavy parts of the algorithm by calling optimized c++modules from within spark , and , secondly , utilizing such c++modules to extend the functionality of spark  to reduce overheads for machine learning tasks . *",
    "our clear separation of communication and computation related costs provides new insights into how the communication - computation trade - off on real world systems impacts the performance of distributed learning .",
    "we will illustrate that if the algorithm parameters are not chosen carefully  in order to trade - off computation versus communication  then this can lead to performance degradation of over an order of magnitude .",
    "furthermore , we will show that the optimal choice of parameters depends strongly on the programming framework the algorithm is executed on : the optimal choice of parameters differs significantly between the mpi and the spark  implementations respectively , even when running on the same hardware .    for this analysis we will focus on standard distributed learning algorithms using synchronous communication , such as distributed variants of single machine solvers based on the principle of mini - batches , e.g. , mini - batch stochastic gradient descent ( sgd ) @xcite and mini - batch stochastic coordinate descent ( scd ) @xcite , as well as the recent cocoamethod @xcite .",
    "in contrast to more complex asynchronous frameworks such as parameter servers @xcite , synchronous schemes have tighter theoretical convergence guarantees and are easier to accurately benchmark , allowing for a more isolated study of system performance measures , such as the communication bottleneck and framework overheads . it is well known that for such methods , the mini - batch size serves as a tuning parameter to efficiently control the trade - off between communication and computation  where we will see that the optimal mini - batch size shows a very sensitive dependence on the algorithm and the programming framework being used . for our experiments",
    "we have chosen the state of the art cocoaalgorithm and implemented the same algorithm on the different programming frameworks considered .",
    "cocoais applicable to a wide range of generalized linear machine learning problems . while having the same flexible communication patterns as mini - batch sgd and scd , cocoaimproves training speed by allowing immediate local updates per worker , leading to up to  @xmath2 faster training than standard distributed solvers such as those provided by mllib @xcite .",
    "our results can provide guidance to developers and data scientists regarding the best way to implement machine learning algorithms in spark , as well as provide valuable insight into how the optimal parameters of such algorithms depend on the underlying system and implementation .",
    "in distributed learning , we assume that the data is partitioned across multiple worker nodes in a cluster , and these machines are connected over a network to the master node as illustrated in figure [ fig : cluster ] .",
    "we wish to learn the best classification or regression model from the given training data , where every machine has access to only part of the data and some shared information that is periodically exchanged over the network .",
    "this periodic exchange of information is what makes machine learning problems challenging in a distributed setting because worker nodes operate only on a subset of the data , and unless local information from every worker is diffused to every other worker the accuracy of the final model can be compromised .",
    "this exchange of information however is usually very expensive relative to computation .",
    "this challenge has driven a significant effort in recent years to develop novel methods enabling communication - efficient distributed training of machine learning models .",
    "distributed variants of single machine algorithms such as mini - batch sgd and scd are well known work - horses in this context , where , in every round , each worker processes a small fixed number @xmath3 of local data samples , in order to compute an update to the parameter vector , see e.g. @xcite and @xcite .",
    "the update of each worker is then communicated to the master node , which aggregates them , computes the new parameter vector and broadcasts this information back to the workers .",
    "a useful property of the mentioned algorithms is that the size of the mini - batch , @xmath3 , can be chosen freely .",
    "hence , @xmath3 allows control of the amount of work that is done locally between two consecutive rounds of communication . on a real - world compute system ,",
    "the costs associated with communication and computation are typically very different and thus the parameter @xmath3 allows to optimally trade - off these costs to achieve the best overall performance .",
    "similar to mini - batch sgd and scd , the state of the art cocoaframework @xcite allows the user to freely trade - off communication versus computation . for our study",
    ", we chose the cocoaalgorithm for training of generalized linear machine learning models , because of its superior performance over mini - batch methods , and because it still offers a similar tuning parameter @xmath3 , for the number of points processed per communication round , which allows a fair investigation of the communication - computation trade - off and the associated overheads .",
    "the cocoaalgorithm is designed to efficiently solve regularized linear loss minimization problems of the form @xmath4    in a distributed setting . here",
    "@xmath5 parametrizes the model , @xmath6 and @xmath7 are convex functions and @xmath8 is the matrix where the number of rows equals the number of datapoints , @xmath9 , and the number of columns equals the number of features , @xmath10 . during training with cocoa ,",
    "every worker node repeatedly works on a local approximation of based on its locally available data , after which it communicates a single vector of updates back to the master .",
    "every message sent will be a vector of dimensionality @xmath9 . to solve the local subproblem , cocoaallows the user to employ an arbitrary local solver on each worker .",
    "the amount of time spent computing in the local solver between two consecutive rounds of communication can then be controlled by adapting the parameter , @xmath3 , which determines the number of local points processed in each round , and thus steering the accuracy to which each local subproblem is solved . for more detail about the algorithm framework and subproblem formulations",
    ", we refer to @xcite . in this paper",
    "we will choose scd as a local solver , where every node works on its dedicated coordinates of @xmath5 .",
    "in this case cocoadiffers from classical mini - batch scd ( a.k.a .",
    "sdca , see @xcite ) in that coordinate - updates are immediately applied locally .",
    "there exist many different programming frameworks that are designed to simplify the implementation of distributed algorithms . in this work",
    "we will focus on spark , due to its widespread use , and compare it against the well established mpi framework .",
    "apache spark  @xcite is an open source general - purpose cluster computing framework developed by the amp lab at the university of california , berkeley .",
    "the core concept underpinning spark   is the resilient distributed dataset ( rdd ) .",
    "an rdd represents a read - only collection of elements , spread across a cluster that can be operated on in parallel . through the concept of the lineage graph ,",
    "rdds provide fault tolerance by keeping transformation logs . with this abstraction ,",
    "spark  allows the developer to describe their distributed program as a sequence of high level operations on rdds without being concerned with scheduling , load - balancing and fault tolerance .",
    "these high - level operations are of two types : transformations and actions . whereas transformations create a new rdd from one or more existing rdds , actions launch a computation on an rdd and generate an output .",
    "transformations are evaluated _ lazily _ , this means that spark  waits to execute transformations until an action is called to generate an output .",
    "this allows the spark  engine to do simple optimization and pipelining within stages .",
    "[ [ pyspark . ] ] pyspark .",
    "+ + + + + + + +    the core of spark  is written in scala , runs on the java@xmath11 virtual machine ( jvm ) and offers a functional programming api to scala , python , java and r. the python api is called pyspark   and exposes the spark  programming model to python . specifically , the local driver consists of a python program in which a spark  context is created .",
    "the spark  context communicates with the java virtual machine ( over py4j ) which in turn is responsible for initiating and communicating with python processes .",
    "[ [ sparkmllib . ] ] spark  mllib .",
    "+ + + + + + + + + + + +    mllib is the machine learning library built on top of spark , designed to harness its scalability and performance properties .",
    "it implements commonly used algorithms for machine learning including regression , classification , clustering , dimensionality reduction and collaborative filtering .",
    "message passing interface ( mpi ) @xcite is a language - independent communications protocol for parallel computing that has been developed for high - performance computing ( hpc ) platforms .",
    "it offers a scalable and effective way of programming distributed systems consisting of tens of thousands of nodes .",
    "the collective communication functions of mpi ( e.g. , broadcast , gather , scatter , and reduce operations ) significantly simplify the design of distributed machine learning algorithms .",
    "mpi allows application programmers to take advantage of problem - specific load - balancing and communication optimization techniques .",
    "mpi is independent of the underlying network stack .",
    "it can operate on top of tcp / ip , rdma , or on top of high - performance network architectures supported by supercomputers .",
    "furthermore , mpi offers various different ways of enabling fault - tolerance for distributed applications .",
    "however , enabling fault - tolerance , customizing load - balancing , and minimizing the communication overhead typically requires a significant amount of manual work and necessitates advanced understanding of the algorithms , mpi s library functions , and the underlying network architecture .",
    "to compare and analyze the performance of the aforementioned programming frameworks , we have implemented the cocoaalgorithm @xcite from scratch on spark , pysparkand mpi . in our implementations",
    "these program frameworks are used to handle the communication of updates between workers during the training of cocoa .",
    "additionally , sparkhandles data partitioning and data management , which needs to be implemented by the user in the case of mpi .",
    "[ [ data - partitioning . ] ] data partitioning .",
    "+ + + + + + + + + + + + + + + + + +    in our implementations we distribute the data matrix @xmath12 column - wise according to the partition @xmath13 .",
    "hence , columns @xmath14 reside on worker @xmath15 , where @xmath16 denotes the size of the partition .",
    "thus , every worker samples uniformly at random from its @xmath17 local features ( also referred to as @xmath18 ) and updates the corresponding coordinates @xmath19}$ ] of the parameter vector .",
    "we use the notation @xmath19}$ ] to denote the vector @xmath5 with nonzero entries only at positions @xmath20 .    [",
    "[ communication - pattern . ] ] communication pattern .",
    "+ + + + + + + + + + + + + + + + + + + + + +    during the cocoaalgorithm execution , after every computation round consisting of @xmath3 local coordinate steps , the individual workers communicate a single @xmath9-dimensional vector @xmath21},\\ ] ] to the master node , where @xmath22}$ ] denotes the update computed by worker @xmath15 to its local coordinate vector during the previous @xmath3 coordinate steps .",
    "@xmath23 is a dense vector , encoding the information about the current state of @xmath24}$ ] , where @xmath19}$ ] itself can be kept local .",
    "the master node then aggregates these updates and determines @xmath25 which is then broadcast to all workers to synchronize their work .",
    "the definition of the shared vector @xmath26 is motivated by fenchel - rockafellar duality , where @xmath27 is related to the dual parameter vector which is defined through the linear map @xmath28 , see @xcite for more details .      in this section",
    "we present five selected implementations of cocoafor the widely used problem of ridge regression  that is @xmath6 being the linear least - squares cost function , and @xmath29  being the euclidean norm regularizer  under the assumptions described in the previous section .",
    "mathematically , all our algorithm implementations are equivalent , but small differences in the learned model can occur due to different random number generation , floating point precision and slight variations in the partitioning of the data across workers .",
    "the first four implementations are all based on spark  but make use of different language bindings and in some cases leverage apis to expose data stored within rdds to native code .",
    "the fifth implementation is built on mpi as a reference .",
    "[ [ mathrma - spark . ] ] @xmath30 ) spark .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we use the open source implementation of smith et al .",
    "@xcite as a reference implementation of cocoa . this implementation is based on spark  and entirely written in scala .",
    "the breeze library @xcite is used to accelerate sparse linear algebra computations . as sparkdoes not allow for persistent local variables on the workers , the parameter vector @xmath5 needs to be communicated to the master and back to the worker in every round , in addition to the shared vector @xmath27  the same applies to implementations ( @xmath31 ) , ( @xmath32 )   and ( @xmath33 ) .",
    "[ [ mathrmb - sparkc . ] ] @xmath31 ) spark+c .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we replace the local solver of implementation ( @xmath30 )  with a java native interface ( jni ) call to a compiled and optimized c++module .",
    "furthermore , the rdd data structure is modified so that each partition consists of a flattened representation of the local data .",
    "this modification allows one to execute the local solver using a _ map _ operation in spark instead of a _ mappartitions _ operation . in that manner",
    ", one can pass the local data into the native function call as pointers to contiguous memory regions rather than having to pass an iterator over a more complex data structure .",
    "the c++code is able to directly operate on the rdd data ( with no copy ) by making use of the _ getprimitivearraycritical _ functions provided by the jni .",
    "[ [ mathrmc - pyspark . ] ] @xmath32 ) pyspark .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this implementation is equivalent to that of ( @xmath30 )  except it is written entirely in python / pyspark .",
    "the local solver makes use of the _ numpy _ package @xcite for fast linear algebra .    [",
    "[ mathrmd - pysparkc . ] ] @xmath33 ) pyspark+c .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we replace the local solver of implementation ( @xmath32 )   with a function call to a compiled and optimized c++module , using the python - c api .",
    "unlike implementation ( @xmath31 )  we did not flatten the rdd data structure since this was found to lead to worse performance in this case .",
    "instead , the local solver is executed using a _ mappartitions _ operation . within the _ mappartitions _",
    "operation we iterate over the rdd in order to extract from each record a list of _ numpy _ arrays .",
    "each entry in the list contains the local data corresponding to a given feature . the list of _ numpy _ arrays is then passed into the c++module .",
    "the python - c api allows _ numpy _",
    "arrays to expose a pointer to their raw data and thus the need to copy data into any additional c++data structures is eliminated .    [ [ mathrme - mpi . ] ] @xmath34 ) mpi .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the mpi implementation is entirely written in c++ . to initially partition the data we have developed a custom load - balancing algorithm to distribute the computational load evenly across workers , such that @xmath35#nonzeros(@xmath36 ) is roughly equal for each partition .",
    "such a partitioning ensures that each worker performs roughly an equal amount of work and was found to perform comparable to the spark  partitioning .",
    "note that the c++code that implements the local solver in implementations ( @xmath31 ) , ( @xmath33 )  and ( @xmath34 )  is identical up to specific jni / python - c api functions .      for the experiments discussed in the next section we ran our algorithm implementations on a cluster of 4 physical nodes interconnected in a lan topology through a 10gbit - per - port switched inter - connection .",
    "each node is equipped with 64 gb ddr4 memory , an 8-core intel xeon@xmath11 e5 x86_64 2.4ghz cpu and solid - state disks using pcie nvme 3.0 x4 i / o technology .",
    "the software configuration of the cluster is based on linux@xmath11 kernel v3.19 , mpi v3.2 , and apache spark v1.5 .",
    "spark is configured not to use the hdfs filesystem ; instead smb sharing directly over ext4 filesystem i / o is employed . while this decision may occasionally give reduced performance in spark , on one hand it eliminates i / o measurement delay - variation artifacts due to the extensive buffering / delay - writing of streams in hdfs , and on the other hand it enables more _ fair _ comparison with mpi since all overheads measured are strictly related to spark . finally , all cluster nodes are configured without a graphical environment or any other related services that could possibly compete with spark or mpi over cpu , memory , network , or disk resources .",
    "we investigate the performance of the five different implementations of the cocoaalgorithm discussed in section  [ sec : implementations ] , by training a ridge regression model on the publicly available _ webspam _ dataset .",
    "all our experiments are run on our internal cluster described in section [ sec : infrastructure ] . if not specified otherwise , we use 8 spark  workers with 24 gb of memory each , 2 on each machine , which allows the data partitions to fit into memory .",
    "all our results are shown for optimized parameters , including @xmath3 , to suboptimality @xmath37 and the results are averaged over 10 runs .",
    "figure [ fig : performance ] gives an overview over the performance of implementation ( @xmath30)-(@xmath34 ) , showing how the suboptimality evolves over time during training for every implementation .",
    "we see that the reference spark  code , ( @xmath30 ) , written in scala performs significantly better than the equivalent python implementation , ( @xmath32 ) .",
    "this is to be expected , for two main reasons : 1 ) scala is a jvm compiled language in contrast to python , 2 ) spark  itself is written in scala and using pyspark , adds an additional layer which involves data copy and serialization operations .    )",
    "-(@xmath34 )  for training the ridge regression model on webspam . ]    in this paper we would like to study the overheads present in the spark framework in a language independent manner ( in as far as it is possible ) .",
    "as described in section  [ sec : infrastructure ] , this can be achieved by offloading the computationally intense local solvers into compiled c++ modules for both the scala as well as the python implementations . in figure",
    "[ fig : performance ] the performance of these new implementations is shown by the dashed lines . as expected ,",
    "the performance gain is larger for the python implementation .",
    "however , the scala implementation can also significantly benefit from these extensions : the performance gap between mpi and spark is reduced from @xmath38 to @xmath39 .      to accurately measure the framework overhead of spark  and pyspark , we leverage the fact that the accelerated spark , pyspark   as well as the mpi implementation  ( @xmath31 ) , ( @xmath33 )   resp .",
    "( @xmath34 )    execute exactly the same c++script on the workers , in each round .",
    "hence , the difference in performance of the red and blue dashed lines in figure [ fig : performance ] can  ignoring the minor computational work on the master  entirely be attributed to the overheads involved in using the python api .",
    "similarly , the difference in performance of the dashed lines to the mpi implementation can be traced to the overheads of the spark  and pyspark  frameworks , respectively , over mpi .    to get a better understanding of these overheads and separate them from the computation time , we ran every implementation for 100 rounds using @xmath40 and measured the execution time for the following three sections of the code :    [ cols=\"<,^ , < \" , ]      for the sparkimplementations ( @xmath30 )  and ( @xmath31 ) , the pyspark  implementations ( @xmath32 )  and ( @xmath33 )  and the mpi implementation  ( @xmath34).,width=216 ]    the results of this analysis are displayed in the bar plot in figure [ fig : barplot ] .",
    "the first observation we make is that the time spent computing on the master is very small ( @xmath41 ) for all implementations and the execution time splits into worker computation time and overheads related to communications and data serialization / de - serialization .",
    "firstly , focusing on the worker execution times , shown by the dotted areas , we note , that the performance of the sparkand pysparkimplementations , ( @xmath30 )   and ( @xmath32 ) , is vastly dominated by the time spent in the local solver .",
    "the benefit from replacing the local solver by c++  modules , i.e. @xmath42 , is significant and reduces the local execution time of the sparkimplementation by one order of magnitude and the execution time of the pysparkimplementation by more than @xmath43 orders of magnitude .",
    "the local execution time of the c++code is roughly the same for implementation ( @xmath31 ) , ( @xmath33 )   and ( @xmath34 ) .",
    "when going into more detail , however , we can see that despite executing identical code , we observe a slight increase in the worker execution time for implementation ( @xmath31 ) .",
    "while the source of this is not known we suspect it due to the internal workings of the jni .",
    "now focusing on the framework overheads , shown by the dashed areas in figure [ fig : barplot ] , we can see that the overheads of the pyspark  implementation are @xmath44 larger than those of the reference spark  implementation written in scala .",
    "this performance loss of pysparkwas also observed in earlier work , i.e. @xcite , and comes from the python api which adds additional serialization steps and overheads coming with initializing python processes and copying data from the jvm to the python interpreter .",
    "newer versions of spark  1.5.2 offer dataframes , which promise to alleviate some of overheads of pyspark  @xcite , but they are not yet ready to be used in machine learning applications , due to lack of fast iteration operators on top of dataframes .",
    "further , we see that calling the c++modules from python adds some additional overhead on top of the pyspark  overhead , coming from minimal data copy operations into c++memory as well as multiple calls to the python - c api .",
    "however , these overheads are negligible compared to the gain in execution time achieved by using these extensions . for scala , we do not have this direct comparison as we changed the data format of the reference implementation when adding the c++modules , in order to minimize the number of jni calls .",
    "we see that this flat data format is much more efficient for the scala implementation and reduces overheads by a factor of @xmath45 .",
    "we have also implemented this format in python but we could not achieve a similar improvement",
    ". for mpi the overheads are negligible and only account for @xmath46 of the total execution time .",
    "as we have seen , spark , especially pyspark , adds significant overhead to the execution of the learning algorithm as opposed to mpi . in this section",
    "we will propose two techniques for extending the functionality of spark  so that these overheads can be somewhat alleviated .",
    "[ [ addition - of - persistent - local - memory . ] ] addition of persistent local memory .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    spark  does not allow for local variables on the workers that can persist across stage boundaries , that is the algorithm rounds .",
    "thus , the cocoaalgorithm has to be implemented in sparkinvolving additional communication , since it is not possible for workers to store their dedicated coordinates of @xmath5 locally . as a consequence , in addition to the shared vector ,",
    "the @xmath5 vectors need to be communicated to the master and back in every stage of the algorithm , thus increasing the overhead associated with communication .",
    "however , one can additionally implement such functionality from within the c++extension modules .",
    "globally - scoped c++arrays can be allocated upon first execution of the local solver that store the local @xmath5 vectors .",
    "the state of these arrays persists into the next stage of execution in spark , and thus the additional communication is no longer necessary  this of course comes at a small expense of a violation of the spark  programming model in terms of consistency of external memory with the linage graph .",
    "[ [ meta - rdds ] ] meta - rdds + + + + + + + + +    for the python implementations in particular , there is a significant overhead related to the rdd data structure and its elements themselves .",
    "it is possible to overcome this overhead by following the approach of @xcite and working with rdds that consist purely of meta - data ( e.g. feature indices ) and handling all loading and storage of the training data from within underlying native functions .",
    "while this may now be considered a serious deviation from the spark  programming model ( data resiliency is most likely lost ) , spark  is still being used to schedule execution of the local workers , to collect and aggregate the local updates and broadcast the updated vectors back to the workers .    ) , the spark  implementation  ( @xmath31 ) , the pyspark  implementation  ( @xmath33 )  and our optimized implementations  ( @xmath31)@xmath11 and  ( @xmath33)@xmath11 . ]    )  and the mllib solver . ]",
    "we have implemented both of these features for both the scala and the python - based implementations . in figure",
    "[ fig : hack ] we compare the execution time and the overheads of these optimized implementations ( @xmath31)@xmath11 and ( @xmath33)@xmath11 with the corresponding implementations that make use of native functions but do not break with the spark  programming model .",
    "we observe that our two modifications reduce overheads of the scala implementation , ( @xmath31 ) , by @xmath47 and those of the python implementation , ( @xmath33 ) , by @xmath38 .",
    "for the scala implementation , the overall improvement due to using the meta - rdd is negligible and most of the gain comes from communication of less data .",
    "however , for the python implementation the effect of using meta - rdds is far more significant .",
    "this is most likely due to the vast reduction in intra - process communication that has been achieved . in figure",
    "[ fig : mllib ] we illustrate that with our optimizations we achieve a @xmath38 speedup over the reference implementation and the performance is less than a factor of 2 slower than mpi .",
    "we also see that by implementing such extensions the performance of spark  and pyspark  is more or less equivalent .",
    "note that the performance gain from reducing overheads in distributed algorithms not only comes from less time spent in every communication round but also from tuning @xmath3 to the reduced communication cost .",
    "this enables more frequent communication , i.e. decrease @xmath3 , and benefit from better convergence in the cocoaalgorithm .",
    "the effect of tuning @xmath3 will be studied in detail in section [ sec : comcomp ] .      in figure",
    "[ fig : mllib ] we compare the performance of our implementation against the performance of the mllib solver available in pyspark .",
    "we used the linear regression solver from the library which is based on sgd and we tuned its batch size to get the best performance .",
    "our findings are consistent with earlier results @xcite that show that the reference cocoaimplementation outperforms existing state - of - the - art distributed solvers by up to  @xmath2 . with our optimizations",
    ", we gain another order of magnitude over the mllib solver which enables training of the ridge regression model on our sample dataset in the order of minutes as opposed to hours .",
    "we have seen in figure [ fig : barplot ] that the different implementations ( @xmath30)-(@xmath34 )  suffer from different overheads associated with communication and data management . to _ fairly _",
    "compare the performance of the different implementations in figure [ fig : performance ] and figure [ fig : mllib ] we have optimized @xmath3 separately for each implementation to account for the different communication and computation costs . in this section",
    "we study in more detail how @xmath3  the number of points processed locally in every round  can be used to control the trade - off between communication and computation and how this impacts the performance of cocoa .     for implementations ( @xmath30)-(@xmath34 )  as a function of @xmath3 .",
    "]    figure [ fig : h ] shows the time needed to achieve a suboptimality of @xmath48 as a function of @xmath3 for the five different implementations ( @xmath30)-(@xmath34 ) .",
    "we see that for the different implementations the optimal value of @xmath3 is indeed different .",
    "hence , in order to get the best performance out of every implementation , @xmath3 needs to be tuned individually to the respective communication and computation costs , whereas not doing so may degrade performance dramatically .",
    "we can see that , in our setting , the best performance of the pysparkimplementation is achieved for @xmath49 , i.e. , every worker performs @xmath50 coordinate updates in every round . for the accelerated pysparkimplementation , ( @xmath33 ) , however , the optimal value of @xmath3 is more than @xmath51 larger .",
    "this is because in implementation ( @xmath33 )   the computational cost is significantly reduced as compared to the vanilla pysparkimplementation , see figure [ fig : barplot ] , and we can afford to do more updates between two consecutive rounds of communication to find a more accurate solution to the local subproblems .",
    "comparing now implementation ( @xmath33 )   to the mpi implementation , ( @xmath34 ) , where communication is much cheaper , see figure [ fig : barplot ] , we can conclude that communicating more frequently to benefit from improved convergence leads to better performance . for the scala implementation , shown by the red curves , the same reasoning applies , whereas overheads are less significant .",
    "these results show that trading - off communication and computation is crucial in designing and applying distributed algorithms . for example , as the optimized @xmath3 value for implementation  ( @xmath34)is not optimal for implementation  ( @xmath33 ) , it would more than double its training time .     for implementations ( @xmath31 ) ,  ( @xmath33 )  and",
    "( @xmath34 ) . ]",
    "figure [ fig : commcomp ] shows how @xmath3 impacts the trade - off between communication and computation for implementations ( @xmath31 ) , ( @xmath33 )  and ( @xmath34 )  by illustrating the fraction of time spent within the local solver as a function of @xmath3 .",
    "the open squares indicate the optimal @xmath3 found in figure [ fig : h ] for the corresponding implementations .",
    "we again see that for the spark  implementations , which suffer from higher communication overheads , larger @xmath3 are needed to strike a good balance between communication and computation . however , as @xmath3 increases the benefit of doing additional updates between communication rounds and further improve the accuracy to which the local subproblem is solved , vanishes .",
    "therefore , we can see that the optimal ratio between computation time and communication overhead is different for every implementation .",
    "whereas for mpi we ideally spend up to @xmath52 of the time computing , for the pyspark+cimplementation @xmath53 appears to be optimal .",
    "this optimal fraction decreases with increasing effective overheads  which makes the algorithm suffer increasingly from the communication bottleneck .      in this subsection",
    "we investigate how the overheads of the different implementations impact the scaling behavior of distributed learning algorithms . to that end , in figure [ fig : scaling ] , we plot the time the cocoaalgorithm takes to reach an accuracy of @xmath48 as a function of the number of workers , where for each data point the algorithm parameters were re - optimized . for the spark  implementations we start with one worker per machine and increase this number by one until we have used all available cores on our cluster . due to significant memory overheads spark  could not handle the data for less than 4 workers . for the mpi implementation we also scaled until we reached the maximum parallelism of our cluster .",
    "the dashed black line shows the theoretical performance of the mpi implementation where communication cost is assumed to be zero .",
    "we see that , when overheads are small , the cocoaalgorithm can achieve a flat scaling behavior",
    ". however , present overheads related to communication have an increasing impact on the performance of cocoaas the number of workers increases .",
    "hence , without minimizing overheads and carefully tuning the communication - computation trade - off , scaling of distributed optimization algorithms appears not to be feasible .     as a function on the number of worker nodes , @xmath54 . ]",
    "in this work we have studied the overheads of sparkin the context of training general linear machine learning models .",
    "we have proposed several practical solutions for acceleration , and demonstrated a reduction of the performance gap between sparkand mpi from @xmath0 to less than @xmath1 . while in this work we have chosen to focus on the cocoaalgorithmic framework ,",
    "our strategies for acceleration and overhead reduction can be applied to a variety of spark - based learning algorithms , including widely - use mini - batch methods .",
    "we have demonstrated that the performance of the machine learning algorithms strongly depends on the choice of a parameter that controls the ratio of communication to computation .",
    "furthermore , we have shown that the optimal choice of this parameter depends not only on the convergence properties of the underlying algorithm but also on the characteristics of the system on which it is executed .",
    "we conclude that in order to develop high - performance machine learning applications , one must carefully adapt the algorithm to account for the properties of the specific system on which such an application will be deployed . for this reason ,",
    "algorithms that are able to automatically adapt their parameters to changes in system - level conditions are of considerable interest from a research perspective .",
    "the authors would like to thank frederick r. reiss from the ibm spark technology center / ibm research - almaden for highly constructive advice regarding this work and martin jaggi from epfl for his help and inspiring discussions .",
    "@xmath11java is a registered trademark of oracle and/or its affiliates .",
    "intel and intel xeon are trademarks or registered trademarks of intel corporation or its subsidiaries in the united states and other countries .",
    "linux is a registered trademark of linus torvalds in the united states , other countries , or both .",
    "other product or service names may be trademarks or service marks of ibm or other companies .",
    "in this section we provide some background on the cocoaalgorithmic framework and its extensions cocoa@xmath55@xcite and proxcocoa@xmath55@xcite , which we refered to as cocoafor simplicity , see @xcite for a unified overview .",
    "this algorithm is designed to solve standard regularized loss minimization problems of the form @xmath56 in a distributed setting . here",
    "@xmath57 and @xmath58 are convex functions , @xmath57 is smooth , @xmath59 is the weight vector and @xmath12 is a given data matrix with column vectors @xmath60 $ ] .",
    "the cocoaalgorithm is fundamentally based on the concept of fenchel - rockafellar duality which makes it more efficient than standard distributed frameworks . by forming a quadratic approximation to the global objective cocoaachieves separability of the problem over the coordinates of @xmath5 and the partitions .",
    "the resulting local subproblem have similar structure to the original problem and exploit second order information within the local data partition .",
    "key to this framework is that the data local subproblems can be solved independently on each worker in parallel and only depend on the local data and the previously shared dual parameter vector @xmath61 . as the data stays local during the whole algorithm and only a single @xmath9-dimensional vector",
    "is exchanged , the amount of communicated data is reduced to a minimum . cocoaleaves it to the user to choose a local solver to find the solution of the local subproblems , which allows to reuse existing , fine - tuned solvers on the workers .",
    "furthermore , cocoa allows to solve the local subproblems to an arbitrary user - defined accuracy and hence allows to control the time spent in the local solver and trade - off communication and computation .",
    "we assume the dataset is distributed column - wise according to the partition @xmath62 .",
    "hence columns @xmath14 of @xmath8 reside on worker @xmath15 .",
    "we denote the size of each partition by @xmath16 , the number of columns on this worker .",
    "further , for @xmath63 $ ] we will use the notation @xmath64}$ ] to denote the vector with entries @xmath65})_i = { { \\bf v}}$ ] for @xmath66 and @xmath65})_i = 0 $ ] for @xmath67 .",
    "the data - local subproblem allocated to every machine @xmath63 $ ] have the following form : @xmath68 } } } { \\mathcal{g}_k^\\sigma\\hspace{-0.08em } } (   { \\delta { { \\boldsymbol \\alpha}}_{[k ] } } ; { { \\bf w } } , { { { \\boldsymbol \\alpha}}_{[k ] } } ) \\label{eq : subproblem}\\ ] ] where @xmath69 } } ; { { \\bf w } } , { { { \\boldsymbol \\alpha}}_{[k ] } } ) & { : = } &    \\sum_{i \\in \\mathcal{p}_k } \\lambda \\left[\\frac \\eta 2 ( { { \\boldsymbol \\alpha}}+ { \\delta { { \\boldsymbol",
    "\\alpha}}_{[k]}})_i ^2 +   ( 1-\\eta)| ( { { \\boldsymbol \\alpha}}+ { \\delta { { \\boldsymbol \\alpha}}_{[k]}})_i)|\\right]\\label{eq : elasticsub}\\\\ & & + \\frac{1}{k } \\| { { \\bf w}}\\|_2 ^ 2   + { { \\bf w}}^t a{\\delta { { \\boldsymbol \\alpha}}_{[k ] } } + \\frac \\sigma 2   \\big\\|a{\\delta { { \\boldsymbol \\alpha}}_{[k]}}\\big\\|_2 ^ 2.\\notag\\end{aligned}\\ ] ] each machine @xmath15 only works on its dedicated coordinates @xmath70}}$ ] of @xmath5 and only needs access to data columns within the local partition @xmath71 as well as the previously shared dual vector @xmath72 .",
    "the parameter @xmath73 of the subproblem characterizes the data partitioning and allows for more aggressive updates if correlations between partitions are small .",
    "ridge regression is a special case of the elastic net regularized problem @xmath74 \\label{eq : elastic}\\ ] ] with @xmath75 $ ] , @xmath76 are the labels and @xmath77 the regularization parameter , we have the following local local subproblems : @xmath69 } } ; { { \\bf w } } , { { { \\boldsymbol \\alpha}}_{[k ] } } ) & { : = } &    \\sum_{i \\in \\mathcal{p}_k } \\lambda \\left[\\frac \\eta 2 ( { { \\boldsymbol \\alpha}}+ { \\delta { { \\boldsymbol \\alpha}}_{[k]}})_i ^2 +   ( 1-\\eta)| ( { { \\boldsymbol \\alpha}}+ { \\delta { { \\boldsymbol \\alpha}}_{[k]}})_i)|\\right]\\label{eq : elasticsub}\\\\ & & + \\frac{1}{k } \\| { { \\bf w}}\\|_2 ^ 2   + { { \\bf w}}^t a{\\delta { { \\boldsymbol \\alpha}}_{[k ] } } + \\frac \\sigma 2   \\big\\|a{\\delta { { \\boldsymbol \\alpha}}_{[k]}}\\big\\|_2 ^ 2.\\notag\\end{aligned}\\ ] ] where @xmath78 . for a problem independent definition of the local subproblems we refer to @xcite      we have chosen stochastic coordinate descent ( scd ) as a local solver for our experiments . in every iteration updates",
    "are made by solving for a single coordinate exactly while keeping all others fixed .",
    "this algorithm is particularly nice in practice as the close - form updates are free of learning parameters .",
    "when solving the local subproblems in using stochastic coordinate descent then coordinate update @xmath79 can be computed as @xmath80_+ .",
    "\\label{eq : softthressholding}\\ ] ] with @xmath81 where @xmath82 is the local residual .",
    "it is initialized in every round by the shared vector as @xmath83 and updated as @xmath84 after every coordinate step .      given this partitioning the detailed procedure of cocoafor elastic net regularized regression using scd as a local solver",
    "is given in algorithm [ alg : cocoa ] .",
    "ridge regression is obtained when choosing @xmath85 .",
    "we refer to @xcite for a description of the framework when using a general local solver .",
    "the core procedure is the following : at the beginning @xmath5 and the shared vector @xmath86 are initialized and every worker gets a local copy of @xmath5 .",
    "then , in every round , @xmath86 is broadcast and the @xmath87 workers independently work on their local subproblem .",
    "they update the local coordinates of the parameter vector @xmath5 and adapt @xmath86 accordingly . at the end of every round",
    "the workers communicate their change @xmath88 to the shared vector @xmath86 to the master node .",
    "the master aggregates these updates and determines the new @xmath86 .",
    "data matrix @xmath8 distributed column - wise according to partition @xmath62 . +",
    "* input : * subproblem parameter @xmath73 and @xmath3 + * initialize : * @xmath89 , @xmath90 + run @xmath3 steps of scd on @xmath91}}$ ] update @xmath92 } } : = { { { { \\boldsymbol \\alpha}}^{(t)}}_{[k ] } } + { \\delta { { \\boldsymbol \\alpha}}_{[k]}}$ ] return @xmath93}}$ ] reduce @xmath94"
  ],
  "abstract_text": [
    "<S> in this paper we compare the performance of distributed learning using apache sparkand mpi by implementing a distributed linear learning algorithm from scratch on the two programming frameworks . </S>",
    "<S> we then explore the performance gap and show how spark - based learning can be accelerated , by reducing computational cost as well as communication - related overheads , to reduce the relative loss in performance versus mpi from @xmath0 to @xmath1 . with these different implementations at hand , we will illustrate how the optimal parameters of the algorithm depend strongly on the characteristics of the framework on which it is executed . </S>",
    "<S> we will show that carefully tuning a distributed algorithm to trade - off communication and computation can improve performance by orders of magnitude . </S>",
    "<S> hence , understanding system aspects of the framework and their implications , and then correctly adapting the algorithm proves to be the key to performance .    </S>",
    "<S> = 1 </S>"
  ]
}