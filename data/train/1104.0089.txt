{
  "article_text": [
    "let @xmath0 , @xmath1 be independent and identically distributed continuous variables and suppose that their common density has a support defined by @xmath2 the unknown function @xmath3 is called the _",
    "frontier_. we address the problem of estimating @xmath3 . in  @xcite",
    ", we introduced a new kind of estimator based upon kernel regression on high power - transformed data .",
    "more precisely the estimator of @xmath4 was defined by @xmath5 where @xmath6 and @xmath7 are non random sequences , @xmath8 is a symmetrical probability density with support included in @xmath9 $ ] , and @xmath10 .",
    "although the correcting term @xmath11 was specially designed to deal with the case of a uniform conditional distribution of @xmath12 , this estimate has been shown to converge in any case . in the special but interesting case of a uniform conditional distribution of @xmath12 for a @xmath13lipschitzian frontier the minimax rate of convergence",
    "is attained .",
    "we also proved that the estimator is asymptotically gaussian .",
    "it is also interesting to note that , compared to the extreme value based estimators  @xcite , projection estimators  @xcite or piecewise polynomial estimators  @xcite , this estimator does not require a partition of the support @xmath14 .",
    "a natural idea suggested by our referees was to investigate the possible gains obtained by substituting a local polynomial regression to the nadaraya - watson regression .",
    "the basic idea in this theory consists in approximating locally a @xmath15 regression function by a polynomial of degree @xmath16 and taking the zero - degree term as an estimate of the regression .",
    "the regularity of the function brings improvement on the bias term .",
    "accordingly , when dealing with high power - transformed data we establish in this paper that the bias of the local polynomial estimator of degree @xmath16 is @xmath17 and the variance is @xmath18 .",
    "let us introduce the notations @xmath19 and @xmath20 .",
    "the conditional distribution of @xmath12 is supposed to be uniform on @xmath21   $ ] , so that @xmath22 . for fixed @xmath23 the method for estimating @xmath24 first consists in solving the following minimization problem@xmath25 then , denoting by @xmath26 the solution of this least square minimization , one considers @xmath27 as an estimate of @xmath28 . the originality and",
    "the difficulty of our paper in contrast with these traditional lines is that here @xmath6 and that we consider @xmath29 as an estimate of @xmath30 so we write @xmath31 .",
    "we refer to  @xcite for other definitions of local polynomials estimators ( i.e. without high power transform ) and to  @xcite for the estimation of frontier functions under monotonicity assumptions .    in order",
    "to get simplified matricial expressions , let us denote by @xmath32 the @xmath33 matrix defined by the lines @xmath34 _ { i=1, ... n}$ ] .",
    "the diagonal matrix of weights @xmath35 is denoted by @xmath36 .",
    "we call _ design _ the vector@xmath37 and we denote by @xmath38 the vector @xmath39",
    ". then the local regression problem @xmath40 can be rewritten as    @xmath41 where @xmath42 .",
    "it is well known from the weighted least square theory that @xmath43 in particular , in the case @xmath44 we have @xmath45 so we exactly find back the estimator @xmath46 studied in  @xcite . in order to give a general expression of @xmath47 , we adopt the notations of fan and gijbels whose book  @xcite will also serve of reference for some preliminary results established in section  [ preli ] ( see also  @xcite for a general multidimensional analysis ) .",
    "basing on this , the asymptotic conditional bias and variance of the estimator are derived in section  [ condi ] when @xmath48 given @xmath49 is uniformly distributed .",
    "this result is extended in section  [ comple ] , where the almost complete convergence is proved without this uniformity assumption .",
    "we conclude this paper by an illustration of the behavior of our estimator on some finite sample situations in section  [ simul ] .",
    "technical lemmas are postponed to the appendix .",
    "let @xmath50 . from now on , it is assumed that the density function @xmath51 of @xmath52 is continuous at @xmath53 and that @xmath54 .",
    "besides , we suppose that there exists @xmath55 such that , for all @xmath56 , @xmath57 .",
    "let @xmath58 be the @xmath59 matrix @xmath60   $ ] @xmath61 defined by @xmath62 similarly , denoting by @xmath63 the @xmath64 diagonal matrix @xmath65 , @xmath66 is the @xmath67 matrix  @xmath68_{0\\leq j , l\\leq k}$ ] with @xmath69 finally , we introduce the matrices @xmath70   _ { 0\\leq j , l\\leq k}$ ] and @xmath71 @xmath72   _ { 0\\leq j , l\\leq k}$ ] with @xmath73 and @xmath74 .",
    "following roughly the same lines as fan and gijbels  @xcite , we obtain asymptotic expressions for @xmath75 and @xmath76 .",
    "the first equality  ( [ 1 - 3 ] ) is a standard result of the theory and the second one  ( [ 1.4 ] ) boils down to an easy adaptation .",
    "proofs are thus omitted .",
    "[ prop1 ] if @xmath77 and @xmath78 , then @xmath79   .",
    "\\label{1 - 3}\\ ] ] if , moreover , @xmath80 we have for any @xmath81 function @xmath3 @xmath82   \\text{. } \\label{1.4}\\ ] ]    let us now quote a general expression of the conditional bias of@xmath83 . from fan and gijbels  @xcite , and denoting by @xmath84 the first vector of the canonical basis of @xmath85 , we have @xmath86 so that @xmath87   .",
    "\\label{1 - 1}\\ ] ] in appendix i we give a detailed proof of the following    [ prop2 ] suppose @xmath3 is a @xmath15 function . if @xmath77 , @xmath78 and @xmath80 , then @xmath88    we now examine the conditional variance of @xmath89@xmath90 taking into account of the independence of the pairs @xmath91 is the diagonal matrix @xmath92 . from the uniformity of the conditional distribution of the @xmath93 , it is easily seen that @xmath94 , so that @xmath95 following the same lines as fan and gijbels  @xcite , we obtain the following asymptotic expression    [ prop3 ] suppose @xmath3 is a @xmath15 function . if @xmath77 , @xmath78 and @xmath80 , then @xmath96,\\ ] ] where @xmath97 .",
    "the proof of proposition  [ prop3 ] is much easier than the one of proposition  [ prop2 ] and it thus omitted .",
    "here we present the main results of this paper and an outline of their proofs .",
    "many details and ancillary results are postponed to appendix ii .",
    "proofs are made under the assumption that @xmath3 is a @xmath15 function and the system of conditions below @xmath99    [ th4 ] suppose @xmath100 holds and @xmath3 is a @xmath15 function .",
    "then , the asymptotic conditional bias of the estimate is given by @xmath101    let us write @xmath102 , so that @xmath103 and define@xmath104 let @xmath105 .",
    "for sufficiently large @xmath106 we have @xmath107 , and thus , lemma  [ lem16 ] entails @xmath108 which leads to the following bound@xmath109 now , from proposition  [ prop2 ] and proposition  [ prop3 ] , @xmath110   + o_{p}\\left (   \\left (   hp\\right ) ^{2k+2}\\right )   \\text{.}\\ ] ] then , taking into account of @xmath111 , it follows that @xmath112   ^{1/2}\\nonumber\\\\ &   = o_{p}\\left (   \\alpha_{n}/\\sqrt{nhp}\\right )   + o_{p}\\left (   \\alpha _ { n}h\\left (   hp\\right )   ^{k}\\right ) \\nonumber\\\\ & = o_{p}\\left (   \\alpha_{n}h\\left ( hp\\right )   ^{k}\\right ) .",
    "\\label{2 - 1}\\ ] ] besides ,",
    "making use of lemma  [ lem15 ] , we can write@xmath113 and , from the triangular inequality , @xmath114 recalling that @xmath115 and noticing that @xmath116 , we conclude that the sequence @xmath117 goes to @xmath118 .",
    "moreover , remark that @xmath119 is a @xmath120-valued random variable .",
    "this means that for a sufficient large @xmath106 depending on @xmath121 , we merely have @xmath122 now , from lemma  [ lem14 ] , @xmath123   \\right\\}\\\\ &   = 2\\exp\\left\\ {   -\\frac{{c_4}}{4}\\sqrt { nh / p\\log^{2}(nh)}\\left [   1+o_{p}\\left (   1\\right )   \\right ]   \\log(nh)\\right\\ }   \\\\ &   = \\left (   nh\\right )   ^{-\\infty_{p}\\left (   1\\right )   } , \\end{aligned}\\ ] ] where @xmath124 stands for a sequence going almost surely to the infinity .",
    "we thus have at least@xmath125 collecting @xmath126 and @xmath127 yields @xmath128 from@xmath129 and proposition  [ prop2 ] , we obtain @xmath130 finally , since @xmath131 , expansion  @xmath132 reduces to@xmath133 and the conclusion follows .",
    "suppose @xmath100 holds and @xmath3 is a @xmath15 function .",
    "then , the asymptotic conditional variance of the estimate is given by @xmath134    introducing@xmath135 we have@xmath136 the first term is bounded using proposition  [ prop3 ] : @xmath137 second , @xmath138 and ( [ 2 - 0 ] ) yields , for sufficiently large @xmath106 , @xmath139 which entails@xmath140   .\\end{aligned}\\ ] ] in a similar way as in the previous proof , one has @xmath141 it follows that @xmath142 and , taking account of @xmath105 and @xmath143 , we finally obtain @xmath144 and the result is proved .    under the assumptions of the above theorems , the conditional mean square error is given by @xmath145 & =   { \\mathbb{v}}\\left (   \\frac{\\widehat{g}_{n}\\left (   x\\right )   } { g\\left (   x\\right ) } -1/\\mathcal{x}\\right )   + { \\mathbb{e}}^{2}\\left (   \\frac{\\widehat{g}_{n}\\left (   x\\right ) } { g\\left (   x\\right )   } -1/\\mathcal{x}\\right ) \\\\ &   = o_{p}\\left (   \\frac{1}{nhp}\\right )   + o_{p}\\left (   h^{2}\\left (   hp\\right ) ^{2k}\\right ) \\\\ &   = o_{p}\\left (   h^{2}\\left (   hp\\right )   ^{2k}\\right )   = o_{p}\\left (   \\frac { 1}{nhp}\\log^{2}(nh)\\right).\\end{aligned}\\ ] ]    under condition h , the ratio between the bias and variance terms is asymptotically equivalent to @xmath146 .",
    "thus , bias and variance of @xmath147 are approximatively of same order , up to this logarithmic factor .",
    "in this section , the almost complete convergence of @xmath98 is established without any assumption on the conditional distribution of @xmath48 given @xmath148 .",
    "if @xmath77 , @xmath149 , and @xmath150 , then @xmath98 converges to @xmath151 almost completely .    introducing @xmath152 and@xmath153 , lemma  [ lem9 ] entails that @xmath154 can be rewritten as @xmath155 thus , with @xmath156 and since @xmath157^{1/p}= [   1+o_{p}(1 ) ]   $ ] , we have @xmath158 with @xmath159   ^{p}\\right ]   ^{1/p}.\\ ] ] since @xmath160 , let us focus on @xmath161   ^{p}\\right ]   ^{1/p}.\\ ] ] taking @xmath162 , @xmath163 implies @xmath164 and thus @xmath165   ^{p}\\mathbf{1}\\left\\ {   y_{i}<g\\left (   x\\right )   \\left (   1+\\delta\\right )   \\right\\ } \\right ]   ^{1/p}\\\\ &   \\leq\\left (   1+\\delta\\right )   \\left [   \\sum_{i=1}^{n}a\\left ( x_{i}\\right )   \\mathbf{1}\\left\\ {   y_{i}<g\\left (   x\\right )   \\left ( 1+\\delta\\right )   \\right\\ }   \\right ]   ^{1/p}.\\end{aligned}\\ ] ] moreover , since , for @xmath106 large enough , @xmath166 , it follows that @xmath167 now , the only difference with the proof of theorem  1 in  @xcite is that the positive kernel @xmath168 is replaced by the signed kernel of higher order @xmath169 . the case @xmath170 is easily treated in a similar way .",
    "here , the following model is simulated : @xmath148 is uniformly distributed on @xmath171 $ ] and @xmath48 given @xmath49 is distributed on @xmath172 $ ] such that @xmath173 with @xmath174 .",
    "this conditional survival distribution function belongs to the weibull domain of attraction , with extreme value index @xmath175 , see  @xcite for a review on this topic . in the following , three exponents are used @xmath176 .",
    "the case @xmath177 corresponds to the situation where @xmath48 given @xmath49 is uniformly distributed on @xmath172 $ ] . the larger @xmath178 is , the smaller the probability  ( [ proba ] ) is , when @xmath179 is close to the frontier @xmath4 .",
    "the frontier function is given by @xmath180 the following kernel is chosen @xmath181\\},\\ ] ] and we limit ourselves to first order local polynomials , i.e. @xmath182 . in this case , to fulfill assumption h , one can choose @xmath183 and @xmath184 where @xmath185 , @xmath186 and @xmath187 are positive constants . in practice , since the choice of @xmath186 and @xmath187 is more important than the logarithmic factors , we use @xmath188 and @xmath189 .",
    "the multiplicative constants are chosen heuristically .",
    "the dependence with respect to the standard - deviation of @xmath148 is inspired from the density estimation case .",
    "the scale factor 4 was chosen on the basis of intensive simulations , similarly to  @xcite .",
    "the experiment involves four steps :    * first , @xmath190 replications of a @xmath191 sample are simulated . * for each of the @xmath192 previous set of points , the frontier estimator @xmath193 is computed for @xmath182 . *",
    "the @xmath192 associated @xmath194 distances to @xmath3 are evaluated on a grid . * the smallest and largest @xmath194 errors are recorded .",
    "results are depicted on figure  [ fctludo1][fctludo3 ] , where the best situation ( i.e. the estimation corresponding to the smallest @xmath194 error ) and the worst situation ( i.e. the estimation corresponding to the largest @xmath194 error ) are represented .",
    "worst situations are obtained when no points were simulated at the upper boundary of the support . to overcome this problem , the normalizing constant @xmath195 in  ( [ 1 - 0 ] )",
    "could be modified as in  @xcite , section  6 to deal with some particular parametric models of @xmath48 given @xmath49 .",
    "in this appendix , we provide a proof of proposition  [ prop2 ] . from @xmath196 , we have @xmath197,\\ ] ] where the term @xmath198 can be rewritten as @xmath199 taylor - lagrange formula with @xmath200 and @xmath201 yields @xmath202 so that , we can derive , for @xmath203 depending on @xmath204 , the following expansion @xmath205 since @xmath8 has a bounded support , we have @xmath206 for @xmath207 . if @xmath208 and @xmath203 , under the conditions @xmath77 and @xmath209 , lemma  [ lem11 ] yields @xmath210.\\end{aligned}\\ ] ] thus , recalling that @xmath211 and @xmath212 , the @xmath213-dimensional vector @xmath214 can be rewritten as @xmath215   _ { j=1, ...",
    ",k+1}\\\\ &   = \\left [   \\beta_{k+1}s_{n , k+j}+\\frac{1}{k+1!}s_{n , k+j+1}\\sum_{j=1}^{k+1}p^{j}g^{p - j}\\left (   x\\right )   o\\left(1\\right )   \\right ] _ { j=1, ... ,k+1}.\\end{aligned}\\ ] ] introducing the vector @xmath216 , we obtain@xmath217 and , returning to the bias of @xmath47 , @xmath218 recalling that @xmath219   $ ] with @xmath220 , we have @xmath221.\\ ] ] besides , introducing the vector @xmath222 , the asymptotic expression of @xmath75 established in proposition  [ prop1 ] entails @xmath223   .\\ ] ] let us first focus on the first term of the bias expansion  ( [ bias ] ) : @xmath224 \\\\ &   = g^{-p}\\left (   x\\right )   h^{k+1}\\beta_{k+1}e_{1}^{t}\\mathbf{s}^{-1}c\\left [ 1+o_{p}\\left (   1\\right )   \\right],\\end{aligned}\\ ] ] and using the expression of @xmath225 in @xmath226 , we have @xmath227 leading to @xmath228 let us now consider the second term in  ( [ bias ] ) : @xmath229 expanding @xmath230 we have @xmath231   = nh^{k+1}f\\left (   x\\right ) c\\left [   1+o_{p}\\left (   1\\right )   \\right],\\ ] ] which entails @xmath232 collecting ( [ bias1 ] ) and ( [ bias2 ] ) , we obtain the announced result @xmath233",
    "we first quote a bernstein - frchet inequality adapted to our framework .",
    "[ lem8 ] let @xmath234 independent centered random variables such that for each positive integers @xmath235 and @xmath16 , and for some positive constant @xmath236 , we have @xmath237 then , for every @xmath238 , we have @xmath239    the proof is standard . note that condition  ( [ condbf ] ) is verified under the boundedness assumption @xmath240 , @xmath241 .",
    "in the next lemma , an asymptotic expansion of the estimated regression function @xmath242 is introduced .",
    "it is known from the local polynomial fitting theory that @xmath246**@xmath53**@xmath247 admits the following asymptotic expression@xmath248,\\ ] ] where@xmath249 is the so - called _ equivalent kernel _ , see  @xcite .",
    "the remaining of the proof consists in explicitly writing this equivalent kernel .",
    "it is worth noticing that @xmath250 depends exclusively of the design @xmath121 .        from @xmath257 and",
    "a recurrence argument it is easily checked that @xmath258 where the @xmath259 are continuous functions .",
    "the triangular inequality entails @xmath260 and , from lemma  [ lem10 ] , if @xmath80 and @xmath261 we get , for sufficiently large @xmath106 , @xmath262 where @xmath263   } | \\phi_{j}(s)|$ ] .",
    "thus , @xmath264 and replacing in  ( [ 4 - 1 ] ) yields @xmath265 and the result is proved .",
    "let us consider , for @xmath266 the random variables defined by @xmath267 the next two lemmas are preparing the application of the bernstein - frchet inequality given in lemma  [ lem8 ] .",
    "first , it is established that the @xmath268 are bounded random variables .",
    "second , a control of the conditional variance @xmath269 is provided .",
    "since the kernel @xmath8 is bounded and has bounded support , it is easily seen that @xmath272 if @xmath273 and that @xmath274 uniformly in @xmath235 . noticing that @xmath275 @xmath276 and using lemma  [ lem10 ] , we get@xmath277 and the result is proved .",
    "recalling that @xmath281 we can write @xmath282   ^{2}g^{2p}\\left (   x_{i}\\right )   \\\\ &   = \\frac{h^{2}}{g^{2p}\\left (   x\\right )   } \\frac{1}{2p+1}\\frac{1}{f^{2}\\left ( x\\right )   } \\sum_{j , l=0}^{k}u_{j}u_{l}\\sum_{i=1}^{n}k_{h}^{2}\\left ( x_{i}-x\\right )   \\left (   \\frac{x_{i}-x}{h}\\right )   ^{j+l}g^{2p}\\left ( x_{i}\\right )   \\\\ &   = \\frac{h^{2}}{g^{2p}\\left (   x\\right )   } \\frac{1}{2p+1}\\frac{1}{f^{2}\\left ( x\\right )   } \\sum_{j , l=0}^{k}u_{j}u_{l}\\frac{1}{h^{j+l}}s_{n , j+l}^{\\ast}.\\end{aligned}\\ ] ] now , substituting the asymptotic expression for @xmath76 into the above expression yields @xmath283,\\ ] ] and the parts @xmath284and @xmath285 of this lemma follow .",
    "the next two lemmas are the key tools to prove theorem  [ th4 ] .",
    "lemma  [ lem14 ] is mainly a consequence of the bernstein - frchet inequality given in lemma  [ lem8 ] .",
    "lemma  [ lem15 ] is dedicated to the control of the random variable @xmath286 introduced in  ( [ defdelta ] ) .      following the asymptotic expression of @xmath89 in lemma  [ lem9 ]",
    ", we can write@xmath290   \\geq\\varepsilon r_{n}\\left (   x\\right ) /\\mathcal{x}\\right ) \\\\ &   = { \\mathbb{p}}\\left (   \\left\\vert \\sum_{i=1}^{n}a\\left (   x_{i}\\right )   \\left ( \\left (   p+1\\right )   y_{i}^{p}-g^{p}\\left (   x_{i}\\right )   \\right )   \\right\\vert \\geq\\left [   1+o_{p}\\left (   1\\right )   \\right ]   \\varepsilon g^{p}\\left ( x\\right )   /\\mathcal{x}\\right).\\end{aligned}\\ ] ] it is worth noticing that , conditionally to @xmath121 , the sequence @xmath250 can be seen as a deterministic sequence converging to @xmath118 .",
    "we now introduce the bounded variables @xmath291 ( see lemma  [ lem12 ] ) . in accordance with the bernstein - frchet inequality given in lemma  [ lem8 ] , and with the expressions  ( [ 4 - 5 ] ) and  ( [ 4 - 6 ] ) in lemma  [ lem13 ] , we write@xmath292   \\varepsilon\\frac{nh}{p}/\\mathcal{x}\\right )   \\\\ &   = { \\mathbb{p}}\\left (   \\left\\vert \\sum_{i=1}^{n}\\xi_{i}\\right\\vert \\geq\\varepsilon\\left [   1+o_{p}\\left (   1\\right )   \\right ]   \\frac{nh}{p\\sqrt{{\\mathbb{v}}\\left (   \\sum_{i=1}^{n}\\xi_{i}/x\\right )   } } \\sqrt{{\\mathbb{v}}\\left ( \\sum\\nolimits_{i=1}^{n}\\xi_{i}/x\\right )   } /\\mathcal{x}\\right )   \\\\ &   \\leq2\\exp\\left\\ {   -\\frac{\\left (   \\varepsilon\\left [   1+o_{p}\\left ( 1\\right )   \\right ]   \\frac{nh}{p\\sqrt{{\\mathbb{v}}\\left (   \\sum_{i=1}^{n}\\xi _ { i}/\\mathcal{x}\\right )   } } \\right )   ^{2}}{4 + 2\\varepsilon\\left [   1+o_{p}\\left ( 1\\right )   \\right ]   \\frac{nh}{p\\sqrt{{\\mathbb{v}}\\left (   \\sum_{i=1}^{n}\\xi _ { i}/\\mathcal{x}\\right )   } } { c_2}/\\sqrt{{\\mathbb{v}}\\left (   \\sum_{i=1}^{n}\\xi_{i}/\\mathcal{x}\\right )   } } \\right\\ }   \\\\ &   = 2\\exp\\left\\ {   -\\frac{\\left (   \\varepsilon\\sqrt{\\frac{nh}{p}}\\sqrt{{c_3}}\\left [   1+o_{p}\\left (   1\\right )   \\right ]   \\right )   ^{2}}{4+{c_2}\\varepsilon\\left [   1+o_{p}\\left (   1\\right )   \\right ]   \\frac{nh}{p}/{\\mathbb{v}}\\left ( \\sum_{i=1}^{n}\\xi_{i}/\\mathcal{x}\\right )   } \\right\\ }   \\\\ &   = 2\\exp\\left\\ {   -\\frac{\\varepsilon^{2}\\frac{nh}{p}^{{}}{c_3}\\left [ 1+o_{p}\\left (   1\\right )   \\right ]   } { 4+{c_2}{c_3}\\varepsilon\\left [ 1+o_{p}\\left (   1\\right )   \\right ]   } \\right\\ } \\\\ & \\leq2\\exp\\left\\ {   -{c_4}\\frac { nh}{p}\\varepsilon^{2}\\left [   1+o_{p}\\left (   1\\right )   \\right ]   \\right\\},\\end{aligned}\\ ] ] and the conclusion follows .      from inequality ( [ 4 - 7 ] ) , we have @xmath295   \\\\ &   \\leq\\left (   \\sum_{i=1}^{n}\\left\\vert a\\left (   x_{i}\\right ) \\right\\vert \\left (   p+1\\right )   g^{p}\\left (   x_{i}\\right )   \\right )   \\left [ 1+o_{p}\\left (   1\\right )   \\right ]   \\\\ &   = { c_1}\\frac{p}{h}g^{p}\\left (   x\\right )   \\left [   1+o_{p}\\left (   1\\right ) \\right ]   \\frac{1}{n}card\\left\\ {   i:\\left\\vert x_{i}-x\\right\\vert < h\\right\\}.\\end{aligned}\\ ] ] then , the strong law of large numbers entails @xmath296   \\left [   1+o_{p}\\left (   1\\right )   \\right],\\ ] ] and from the continuity of the density @xmath51 , we have @xmath297.\\ ] ] consequently , @xmath298,\\ ] ] with @xmath299 depending on the design @xmath121 .",
    "we thus write@xmath300 where @xmath301  is a positive constant under the conditioning by @xmath121 . as an immediate consequence , we get@xmath302 from @xmath303 and @xmath304",
    "it is clear that @xmath286 is bounded conditionally to @xmath121 .",
    "d.  deprins , l.  simar , and h.  tulkens . measuring labor efficiency in post offices . in p.",
    "pestieau m.  marchand and h.  tulkens , editors , _ the performance of public enterprises : concepts and measurements_. north holland ed , amsterdam , 1984 ."
  ],
  "abstract_text": [
    "<S> we present a new method for estimating the frontier of a sample . </S>",
    "<S> the estimator is based on a local polynomial regression on the power - transformed data . </S>",
    "<S> we assume that the exponent of the transformation goes to infinity while the bandwidth goes to zero . </S>",
    "<S> we give conditions on these two parameters to obtain almost complete convergence . the asymptotic conditional bias and variance of the estimator </S>",
    "<S> are provided and its good performance is illustrated on some finite sample situations . </S>",
    "<S> + * keywords : * local polynomials estimator , power - transform , frontier estimation .    * </S>",
    "<S> ams 2000 subject classification : * 62g05 , 62g07 , 62g20 . </S>"
  ]
}