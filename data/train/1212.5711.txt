{
  "article_text": [
    "to define the information in a _",
    "finite object one commonly uses the kolmogorov complexity @xcite of that object ( finiteness is taken as understood in the sequel ) .",
    "information distance @xcite is the information required to transform one in the other , or vice versa , among a _",
    "pair _ of objects . for research in the theoretical direction",
    "see among others @xcite .",
    "here we are more concerned with normalizing it to obtain the so - called similarity metric and subsequently approximating the kolmogorov complexity through real - world compressors @xcite .",
    "this leads to the normalized compression distance ( ncd ) which is theoretically analyzed and applied to general hierarchical clustering in @xcite .",
    "the ncd is parameter - free , feature - free , and alignment - free , and has found many applications in pattern recognition , phylogeny , clustering , and classification , for example @xcite and the many references in google scholar to @xcite .",
    "another application is to objects that are only represented by name , or objects that are abstract like ` red , ' ` einstein , ' ` three . ' in this case the distance uses background information provided by google or any search engine that produces aggregate page counts .",
    "it discovers the ` meaning ' of words and phrases in the sense of producing a relative semantics @xcite .",
    "the question arises of the shared information between many objects instead of just a pair of objects .      in @xcite",
    "the notion is introduced of the information required to go from any object in a multiset of objects to any other object in the multiset .",
    "this is applied to extracting the essence from , for example , a finite nonempty multiset of internet news items , reviews of electronic cameras , tv s , and so on , in a way that works better than other methods .",
    "let @xmath0 denote a finite nonempty multiset of @xmath1 finite binary strings defined by ( abusing the set notation ) @xmath2 , the constituting elements ( not necessarily all different ) ordered length - increasing lexicographic .",
    "we use multisets and not sets , since if @xmath0 is a set then all of its members are different while we are interested in the situation were some or all of the objects are equal .",
    "let @xmath3 be the reference universal turing machine , for convenience the prefix one as in section  [ sect.prel ] .",
    "we define the _ information distance _ in @xmath0 by @xmath4 for all @xmath5}. it is shown in @xcite , theorem 2 , that @xmath6 up to an additive term @xmath7 .",
    "define @xmath8 .",
    "theorem 3 in @xcite states that @xmath9 up to a logarithmic additive term .",
    "the information distance in @xcite between strings @xmath10 and @xmath11 is denoted by @xmath12 .",
    "here we use the notation @xmath13 .",
    "the two coincide for @xmath14 since @xmath15 up to an additive constant term . in @xcite",
    "this notation was introduced and the following results were obtained for finite nonempty multisets .",
    "the maximal overlap of information , concerning the remarkable property that the information needed to go from any member @xmath16 to any other member @xmath17 in a multiset @xmath0 can be divided in two parts : a single string of length @xmath18 and a special string of length @xmath19 possibly depending on @xmath20 and some logarithmic additive terms possibly depending on @xmath21 .",
    "furthermore , the minimal overlap property , the metricity property , the universality property , and the not - subadditivity property . with respect to normalization of the information distance of multisets only abortive attempts were given .",
    "a review of some of the above is @xcite .      for many applications we require a normalized and computable version of the information distance for finite nonempty multisets of finite objects . for instance , classifying an object into one or another of disjoint classes we aim for the class of which the ncd for multisets grows the least .",
    "we give preliminaries in section  [ sect.prel ] .",
    "the normalization of the information distance for multisets which did not succeed in @xcite is analyzed and performed in section  [ sect.nid ] .",
    "in particular it is proved to be a metric .",
    "we sometimes require metricity since otherwise the results may be inconsistent and absurd .",
    "subsequently we proceed to the practically feasible compression distance for multisets and prove this to be a metric , section  [ sect.cd ] .",
    "next , this compression distance is normalized and proved to retain the metricity , section  [ sect.ncd ] .",
    "we go into the question of how to compute this in section  [ sect.comp ] , how to apply this to classification in section  [ sect.ancd ] , and then treat the applications section  [ sect.app ] .",
    "we applied the new ncd for multisets to retinal progenitor cell classification questions , section  [ sect.rpc ] , and to synthetically generated data , section  [ sect.synth ] , that were earlier treated with the pairwise ncd . here",
    "we get significantly better results .",
    "this was also the case for questions about axonal organelle transport , section  [ sect.aot ] .",
    "we also applied the ncd for multisets to classification of handwritten digits , section  [ sect.nist ] . although the ncd for multisets did not improve on the accuracy of the pairwise ncd for this application , classification accuracy was much improved over either method individually by combining the pairwise and multisets ncd .",
    "we treat the data , software , and machines used for the applications in section  [ sect.means ] .",
    "we finish with conclusions in section  [ sect.concl ] .",
    "we write _ string _ to mean a finite binary string , and @xmath22 denotes the empty string .",
    "the _ length _ of a string @xmath23 ( the number of bits in it ) is denoted by @xmath24 .",
    "@xmath25 . we identify strings with natural numbers by associating each string with its index in the length - increasing lexicographic ordering according to the scheme @xmath26 in this way the kolmogorov complexity in the next section can be about finite binary strings or natural numbers .",
    "the kolmogorov complexity is the information in a single finite object @xcite .",
    "informally , the kolmogorov complexity of a finite binary string is the length of the shortest string from which the original can be lossless reconstructed by an effective general - purpose computer such as a particular universal turing machine .",
    "hence it constitutes a lower bound on how far a lossless compression program can compress . for technical reasons we choose turing machines with a separate read - only input tape that is scanned from left to right without backing up , a separate work tape on which the computation takes place , and a separate output tape .",
    "all tapes are divided into squares and are semi - infinite .",
    "initially , the input tape contains a semi - infinite binary string with one bit per square starting at the leftmost square , and all heads scan the leftmost square on their tapes . upon halting ,",
    "the initial segment @xmath27 of the input that has been scanned is called the input `` program '' and the contents of the output tape is called the `` output . '' by construction , the set of halting programs is prefix free .",
    "an standard enumeration of such turing machines @xmath28 contains a universal machine @xmath3 such that @xmath29 for all indexes @xmath30 and programs @xmath27 .",
    "( such universal machines are called `` optimal '' in contrast with universal machines like @xmath31 with @xmath32 for all @xmath30 and @xmath27 , and @xmath33 for @xmath34 for some @xmath27 . )",
    "we call @xmath3 the _ reference universal prefix turing machine_. this leads to the definition of `` prefix kolmogorov complexity '' which we shall designate simply as `` kolmogorov complexity . ''",
    "the _ conditional kolmogorov complexity _",
    "@xmath35 is the length of the shortest input @xmath36 such that the reference universal prefix turing machine @xmath3 on input @xmath36 with auxiliary information @xmath37 outputs @xmath23 .",
    "the _ unconditional kolmogorov complexity _",
    "@xmath38 is defined by @xmath39 where @xmath22 is the empty string . in these definitions",
    "both @xmath23 and @xmath37 can consist of strings into which finite multisets of finite binary strings are encoded .",
    "theory and applications are given in the textbook @xcite .",
    "here we give some relations that are needed in the paper .",
    "the _ information about @xmath23 contained in @xmath37 _ is defined as @xmath40 .",
    "a deep , and very useful , result holding for both plain complexity and prefix complexity , due to l.a .",
    "levin and a.n .",
    "kolmogorov @xcite called _ symmetry of information _ states that @xmath41 with the equalities holding up to a @xmath42 additive term . here , @xmath43 . hence , up to an additive logarithmic term @xmath44 and we call this the _ mutual ( algorithmic ) information _ between @xmath23 and @xmath37 .",
    "a multiset is also known as _ bag _",
    ", _ list _ , or _ multiple_. a _ multiset _ is a generalization of the notion of set .",
    "the members are allowed to appear more than once .",
    "for example , if @xmath45 then @xmath46 is a set , but @xmath47 and @xmath48 are multisets , with abuse of the set notation .",
    "we also abuse the set - membership notation by using it for multisets by writing @xmath49 and @xmath50 for @xmath51 .",
    "further , @xmath52 . if @xmath53 are multisets and @xmath54 is nonempty and @xmath55 , then we write @xmath56 . for us , a multiset is finite and nonempty such as @xmath57 with @xmath58 and the members are finite binary strings in length - increasing lexicographic order . if @xmath0 is a multiset , then some or all of its elements may be equal .",
    "@xmath59 means that `` @xmath60 is an element of multiset @xmath0 . ''",
    "with @xmath61 we mean the multiset @xmath62 with one occurrence of @xmath23 removed .",
    "the finite binary strings , finiteness , and length - increasing lexicographic order allows us to assign a unique kolmogorov complexity to a multiset .",
    "the conditional prefix kolmogorov complexity @xmath63 of a multiset @xmath0 given an element @xmath23 is the length of a shortest program @xmath27 for the reference universal turing machine that with input @xmath23 outputs the multiset @xmath0 .",
    "the prefix kolmogorov complexity @xmath64 of a multiset @xmath0 is defined by @xmath65 .",
    "one can also put multisets in the conditional such as @xmath66 or @xmath67 .",
    "we will use the straightforward laws @xmath68 and @xmath69 up to an additive constant term , for @xmath70 and @xmath71 equals the multiset @xmath0 with one occurrence of the element @xmath23 deleted .",
    "the information distance in a multiset @xmath0 ( @xmath72 ) is given by . to obtain the _ pairwise information distance _ in @xcite we take @xmath73 in .",
    "the resulting formula is equivalent to @xmath74 up to a logarithmic additive term .",
    "let @xmath75 be the set of length - increasing lexicographic ordered nonempty finite multisets of finite binary strings .",
    "a _ distance function _",
    "@xmath76 on @xmath75 is defined by @xmath77 where @xmath78 is the set of nonnegative real numbers .",
    "define @xmath79 if @xmath54 is the multiset consisting of the elements of the multisets @xmath0 and @xmath80 and the elements of @xmath54 are ordered length - increasing lexicographic .",
    "a distance function @xmath76 is a _",
    "metric _ if    1 .",
    "_ positive definiteness _ : @xmath81 if all elements of @xmath0 are equal and @xmath82 otherwise .",
    "symmetry _ :",
    "@xmath83 is invariant under all permutations of @xmath0 .",
    "triangle inequality _ : @xmath84 .",
    "we recall theorem 4.1 and claim 4.2 from @xcite .",
    "[ theo.metric ] the information distance for multisets",
    "@xmath85 is a metric where the ( in)equalities hold up to a @xmath42 additive term . here",
    "@xmath86 is the largest quantity involved in each metric ( in)equality 1 ) to 3 ) , respectively .",
    "[ claim.metric ] let @xmath53 be three nonempty finite multisets of finite binary strings and @xmath87 .",
    "then , @xmath88 up to an @xmath42 additive term .",
    "the quantitative difference in a certain feature between many objects can be considered as an _ admissible _ distance , provided it is upper semicomputable and satisfies a density condition for every @xmath89 ( to exclude distances like @xmath90 for every multiset @xmath0 ) : @xmath91 thus , for the density condition on @xmath92 we consider only multisets @xmath0 with @xmath72 and not all elements of @xmath0 are equal .",
    "moreover , we consider only distances that are upper semicomputable , that is , they are computable in some broad sense ( they can be computably approximated from above ) .",
    "theorem 5.2 in @xcite shows that @xmath85 ( the proof shows this actually for @xmath93 ) is universal in that among all admissible multiset distances it is always least up to an additive constant .",
    "that is , it accounts for the dominant feature in which the elements of the given multiset are alike .",
    "admissible distances as defined above are absolute , but if we want to express similarity , then we are more interested in relative ones . for example , if a multiset @xmath0 of strings of each about @xmath94 bits have pairwise information distance @xmath95 bits to each other , then we are inclined to think that those strings are relatively similar .",
    "but if a multiset @xmath80 consists of strings of each about @xmath96 bits and each two strings in it have a pairwise information distance of @xmath95 bits , then we think the strings in @xmath80 are very different . in the first case @xmath97 , and in the second case @xmath98 .",
    "possibly @xmath99 .",
    "the information distances in the multisets are about the same .    to express similarity we need to normalize the universal information distance @xmath85",
    ". it should give a similarity with distance 0 when the objects in a multiset are maximally similar ( that is , they are equal ) and distance 1 when they are maximally dissimilar .",
    "naturally , we desire the normalized version of the universal multiset information distance metric to be also a metric .    for pairs of objects @xmath100 the normalized version @xmath101 of @xmath85 defined by @xmath102 takes values in @xmath103 $ ] up to an additive term of @xmath104 .",
    "it is a metric up to additive terms @xmath105 with @xmath86 denotes the maximum of the kolmogorov complexities involved in each of the metric ( in)equalities , respectively .",
    "a normalization formula for multisets of more than two elements ought to reduce to that of for the case of multisets of two elements .",
    "[ rem.ex ] for example set @xmath106 and by using we have @xmath107 .",
    "the most natural definition is a generalization of : @xmath108 but we find @xmath109 , and @xmath110 , @xmath111 , and the triangle inequality is violated .",
    "but with @xmath112 , @xmath113 , @xmath114 , and the kolmogorov complexities as before , the triangle inequality is not violated . in this case , @xmath115 even though @xmath116 .",
    "however it makes sense that if we add an element to a multiset of objects then a program to go from any object in the new multiset to any other object should be at least as long as a program to go from any object in the old multiset to any other object .",
    "the reasoning in the last sentence of the remark points the way to go : the definition of @xmath117 should be monotonic nondecreasing in @xmath118 if we want @xmath101 to be a metric .",
    "[ lem.triangle ] let @xmath119 be multisets and @xmath76 be a distance that satisfies the triangle inequality .",
    "if @xmath120 then @xmath121 .",
    "let @xmath122 be multisets with @xmath123 , and @xmath76 a distance that satisfies the triangle inequality .",
    "assume that the lemma is false and @xmath124 .",
    "let @xmath125 .",
    "it follows from the triangle inequality that @xmath126 since @xmath127 this implies @xmath128 , and therefore @xmath129 . but this contradicts the assumption .",
    "let @xmath0 be a multiset .",
    "define the _ normalized information distance _ ( nid ) for multisets by @xmath130 for @xmath131 , and for @xmath132 by @xmath133 here the left - hand term in the outer maximalization is denoted by @xmath134 as in .",
    "for @xmath14 the value of @xmath117 is equivalently given in . in this way , satisfies the property in lemma  [ lem.triangle ] : if @xmath135 are multisets and @xmath136 then @xmath137 .",
    "therefore we can hope to prove the triangle property for . instead of `` distance '' for multisets one can also use the term `` diameter . ''",
    "this does not change the acronym nid .",
    "moreover , the diameter of a pair of objects is the familiar distance .",
    "[ theo.01 ] for every nonempty finite multiset @xmath0 we have @xmath138 up to an additive term of @xmath139 where @xmath140 .    by induction on @xmath141 .",
    "_ base case : _",
    "the theorem is vacuously true for @xmath142 .",
    "_ induction : _ @xmath143 .",
    "assume that the lemma is true for the cases @xmath144 .",
    "let @xmath145 . if @xmath146 then the lemma holds by the inductive assumption since @xmath147 .",
    "hence assume that @xmath148 the numerator is at most the denominator up to an @xmath149 additive term and the denominator is at most @xmath64 .",
    "the lemma is proven .",
    "for @xmath150 the definition of @xmath117 is .",
    "the proof of the lemma for this case is also in @xcite .",
    "[ rem.ei ] the least value of @xmath117 is reached if all occurrences of elements of @xmath0 are equal . in that case @xmath151 .",
    "the greatest value @xmath152 is reached if @xmath153 .",
    "for example , if the selected conditional , say @xmath37 , has no consequence in the sense that @xmath154 .",
    "this happens if @xmath155 for all @xmath156 .",
    "another matter is the consequences of .",
    "use in the left - hand term in both the numerator and the denominator .",
    "then we obtain up to additive logarithmic terms in the numerator and denominator @xmath157 this expression goes to 1 if both @xmath158 this happens , for instance , if @xmath159 , @xmath160 , @xmath161 , and @xmath162 .",
    "also in the case that @xmath163 ( @xmath164 copies of a fixed @xmath23 ) and @xmath162",
    ". then @xmath165 and @xmath166 with @xmath167 . to consider another case",
    ", we have @xmath168 and @xmath166 if @xmath169 and @xmath170 , that is , if @xmath0 consists of at least two elements and gap between the minimum kolmogorov complexity and the maximum kolmogorov complexity of the elements grows to infinity when @xmath168 .",
    "[ rem.defp ] heuristically the partitioning algorithm described in section  [ sect.app ] approaches the question when to use the left - hand term of .",
    "but we can analyze directly under what conditions there is a @xmath56 such that @xmath171 . without loss of generality",
    "we can assume that in that case the left - hand term of for @xmath80 is greater than the left - hand term of for @xmath0 ( that is , @xmath172 with @xmath173 according to ) .",
    "this means that @xmath174 ignoring logarithmic additive terms .",
    "take the example of remark  [ rem.ex ] .",
    "let @xmath175 and @xmath176 . then @xmath56 .",
    "the left - hand side of equals 1 and the right - hand side equals @xmath177 . in this case",
    "@xmath178 with @xmath173 according to and as we have seen the triangle inequality does not hold for @xmath173 .",
    "[ theo.nmetric ] the function @xmath101 as in is a metric up to an additive @xmath105 term in the respective metric ( in)equalities , where @xmath86 is the largest kolmogorov complexity involved the ( in)equality .",
    "the quantity @xmath117 satisfies positive definiteness and symmetry up to an @xmath179 additive term , as follows directly from the definition of @xmath117 in .",
    "it remains to prove the triangle inequality :    let @xmath53 be multisets .",
    "then , @xmath180 within an additive term of @xmath105 where @xmath181 .",
    "the proof proceeds by induction on @xmath182 .",
    "_ base case :",
    "_ @xmath142 .",
    "these cases are vacuously true .    _",
    "induction @xmath143_. assume that the lemma is true for the cases @xmath144 .",
    "let @xmath183 . if @xmath184 then the lemma holds by the inductive assumption since @xmath185 .",
    "hence assume that @xmath186 where we let @xmath187 and @xmath188 denote the elements that reach the maximum in @xmath189 , and @xmath190 .",
    "[ claim.tr ] let @xmath53 be multisets ( finite , but possibly empty ) .",
    "@xmath191 up to an additive @xmath42 term , where @xmath87 .",
    "if one or more of @xmath53 equal @xmath192 the theorem holds trivially . therefore , assume neither of @xmath53 equals @xmath192 . by theorem  [ theo.metric ]",
    "we have that @xmath85 and hence @xmath193 is a metric up to an @xmath42 additive term . in particular , the triangle inequality is satisfied by claim  [ claim.metric ] : @xmath194 for multisets @xmath53 up to an additive term of @xmath42 .",
    "thus with @xmath195 and @xmath196 we have @xmath197 up to the logarithmic additive term . writing this out @xmath198 or @xmath199 up to an additive term of @xmath200 .",
    "now consider the following inequalities ( where possibly one or more of @xmath53 equal @xmath192 ) : @xmath201 up to a @xmath105 additive term .",
    "the first inequality is claim  [ claim.tr ] ( by this inequality the denominator is unchanged ) ; the second inequality follows from @xmath202 and @xmath203 using the principle that @xmath204 , reducing both denominators and increasing the sum of the quotients ( by this inequality the numerators are unchanged ) ; the third inequality follows by definition .    by definition",
    "a multiset @xmath205 has @xmath206 or it contains a proper submultiset @xmath3 such that @xmath207 .",
    "this @xmath208 is the multiset ( if it exists ) that achieves the maximum in the right - hand term of the outer maximalization of @xmath209 in .",
    "assume @xmath3 exists .",
    "denote @xmath210 , @xmath211 , and @xmath212 . then holds with @xmath71 substituted for @xmath0",
    ", @xmath213 substituted for @xmath80 , and @xmath214 substituted for @xmath54 .",
    "since @xmath215 and @xmath216 we have @xmath217 up to a @xmath105 additive term .",
    "assume @xmath3 does not exist",
    ". then @xmath218 .",
    "by we have @xmath219 up to a @xmath105 additive term .    by the monotonicity property of and since @xmath220 and @xmath221 we have @xmath222 and @xmath223 .",
    "therefore , @xmath180 up to an @xmath105 additive term .",
    "the definition of @xmath224 with @xmath225 is .",
    "the proof of the lemma for this case is in @xcite .",
    "the proof above is simpler and more elementary for a more general case than the one in @xcite .    by theorems  [ theo.01 ] and [ theo.nmetric ]",
    "the distance according to is a metric with values in @xmath103 $ ] up to some ignorable additive terms ..",
    "we develop the compression - based equivalence of the kolmogorov complexity based theory in the preceding sections .",
    "this is similar to what happened in @xcite for the case @xmath14 .",
    "we assume that the notion of the real - world compressor @xmath226 used in the sequel is `` normal '' in the sense of @xcite .",
    "[ def.gx ] by @xmath227 we mean the length of string @xmath23 when compressed by @xmath226 .",
    "consider a multiset @xmath0 as a string consisting of the concatenated strings of its members ordered length - increasing lexicographic with a means to tell the constituent elements apart .",
    "thus we can write @xmath228 .",
    "let @xmath229 .",
    "the information distance @xmath230 can be rewritten as @xmath231 within logarithmic additive precision , by .",
    "the term @xmath64 represents the length of the shortest program for @xmath0 .",
    "the order of the members of @xmath0 makes only a small difference ; block - coding based compressors are symmetric almost by definition , and experiments with various stream - based compressors ( gzip , ppmz ) show only small deviations from symmetry .",
    "approximation of @xmath230 by a compressor @xmath226 is straightforward : it is @xmath232 we need to show it is an admissible distance and a metric .",
    "[ lem.ad ] if @xmath226 is a normal compressor , then @xmath233 is an admissible distance .    for @xmath233 to be an admissible distance it must satisfy the density requirement and be upper semicomputable .",
    "since the length @xmath227 is computable it is a fortiori upper semicomputable .",
    "the density requirement is equivalent to the kraft inequality @xcite and states in fact that for every string @xmath23 the set of @xmath233 is a prefix - free code for the @xmath0 s containing @xmath23 . according to we have for every @xmath234 : @xmath235 .",
    "hence , @xmath236 and therefore @xmath237 a compressor @xmath226 compresses strings into a uniquely decodable code ( it must satisfy the unique decompression property ) and therefore the length set of the compressed strings must satisfy the kraft inequality @xcite .",
    "then , for every @xmath23 the compressed code for the multisets @xmath238 must satisfy this inequality .",
    "hence the right - hand side of above displayed inequality is at most 1 .",
    "[ lem.mg ] if @xmath226 is a normal compressor , then @xmath239 is a metric with the metric ( in)equalities satisfied up to logarithmic additive precision .",
    "let @xmath53 be multisets with at most @xmath1 members of length at most @xmath164 .",
    "the positive definiteness and the symmetry property hold clearly up to an @xmath240 additive term .",
    "only the triangular inequality is nonobvious . for every compressor @xmath226",
    "we have @xmath241 up to an additive @xmath242 term , otherwise we obtain a better compression by dividing the string to be compressed .",
    "( this also follows from the distributivity property of normal compressors . ) by the monotonicity property @xmath243 and @xmath244 up to an @xmath242 or @xmath245 additive term , respectively .",
    "therefore , @xmath246 up to an @xmath247 additive term .",
    "let @xmath0 be a multiset . the normalized version of @xmath117 using the compressor @xmath226 based approximation of the normalized information distance for multisets ,",
    "is called the _ normalized compression distance _ ( ncd ) for multisets : @xmath248 for @xmath249 ; if @xmath72 then @xmath250 this @xmath251 is the main concept of this work .",
    "it is the real - world version of the ideal notion of normalized information distance nid for multisets in .",
    "as mentioned before , instead of `` distance '' for multisets it one can use also the term `` diameter . ''",
    "this does not change the acronym ncd .    in practice ,",
    "the ncd is a non - negative number @xmath252 representing how different the two files are .",
    "smaller numbers represent more similar files .",
    "the @xmath22 in the upper bound is due to imperfections in our compression techniques , but for most standard compression algorithms one is unlikely to see an @xmath22 above 0.1 ( in our experiments ` gzip ` and ` bzip2 ` achieved ncd s above 1 , but ` ppmz ` always had ncd at most 1 ) .",
    "if the compressor is normal , then the ncd for multisets is a normalized admissible distance and satisfies the metric ( in)equalities up to an ignorable additive term , that is , it is a similarity metric .",
    "the ncd is a normalized admissible distance by lemma  [ lem.ad ] .",
    "it is normalized to @xmath103 $ ] up to an additive term of @xmath253 with @xmath254 as we can see from the formula and theorem  [ theo.01 ] with @xmath226 substituted for @xmath86 throughout .",
    "we next show it is a metric .",
    "we must have that @xmath255 up to negligible error for a normal compressor @xmath226 if @xmath0 consists of equal members .",
    "the idempotency property of a normal compressor is up to an additive term of @xmath256 .",
    "hence the positive definiteness of @xmath257 is satisfied up to an additive term of @xmath258 .",
    "the order of the members of @xmath0 is assumed to be length - increasing lexicographic .",
    "therefore it is symmetric up to an additive term of @xmath258 .",
    "it remains to show the triangle inequality @xmath259 up to an additive term of @xmath253 where @xmath260 .",
    "we do this by induction on @xmath182 where @xmath119 are multisets .",
    "_ base case : _",
    "the triangle property is vacuously satisfied .    _",
    "induction : _ @xmath261 .",
    "assume the triangle property is satisfied for the cases @xmath262 .",
    "we prove it for @xmath263 .",
    "if @xmath264 for some @xmath265 then the case follows from the inductive argument . therefore , @xmath266 is the first term in the outer maximization of .",
    "write @xmath267 and @xmath268 and similar for @xmath269 . following the induction case of the triangle inequality in the proof of theorem  [ theo.nmetric ] , using lemma  [ lem.mg ] for the metricity of @xmath270",
    "wherever theorem  [ theo.metric ] is used to assert the metricity of @xmath85 , and substitute @xmath226 for @xmath86 in the remainder .",
    "this completes the proof .",
    "that is , for every multiset @xmath54 we have @xmath271 up to an additive term of @xmath272 .",
    "for @xmath225 the triangle property is also proved in @xcite .",
    "the proof above is simpler and more elementary .",
    "define @xmath273 the first term of .",
    "assume we want to compute @xmath257 and @xmath274 . in practice",
    "it seems that one can do no better than the following ( initialized with @xmath275 for @xmath276 ) :    * for * @xmath277    * do * @xmath278 using    @xmath279    however , this process involves evaluating the @xmath251 s of the entire powerset of @xmath0 requiring at least order @xmath280 time .",
    "[ theo.fast ] let @xmath0 be a multiset and @xmath141 .",
    "there is a heuristic algorithm to approximate @xmath257 from below in @xmath281 computations of @xmath282 with @xmath120 .",
    "( assuming every @xmath283 to be a binary string , @xmath284 , and @xmath226 compresses in linear time then @xmath282 is computed in @xmath285 time . )",
    "we use the analysis in remark  [ rem.defp ] and in particular the inequality .",
    "we ignore logarithmic additive terms .",
    "we approximate @xmath257 from below by @xmath286 for a sequence of @xmath287 properly nested @xmath80 s of decreasing cardinality .",
    "that is , in the computation we set the value of @xmath257 to @xmath288 unless there is one of these @xmath80 s such that @xmath289 in which case we set the value of @xmath257 to @xmath290 .",
    "how do we choose this sequence of @xmath80 s ?",
    "[ claim.1 ] let @xmath56 and @xmath291 .",
    "then , @xmath289 .",
    "we first show that @xmath292 .",
    "let @xmath293 .",
    "since @xmath56 we have @xmath294 .",
    "we next show that if @xmath295 and @xmath296 then @xmath297 .",
    "namely , dividing the first inequality by @xmath298 we obtain @xmath299 .",
    "hence , @xmath297 .",
    "setting @xmath300 , @xmath301 , @xmath302 , and @xmath303 , the above shows that the claim holds .",
    "claim  [ claim.1 ] states that the only candidates @xmath80 ( @xmath56 ) for @xmath304 are the @xmath80 such that @xmath305 .",
    "for example , let @xmath306 , @xmath307 , @xmath308 ( for instance @xmath309 ) , and @xmath310 . clearly , @xmath311 .",
    "then , @xmath312 .    hence for @xmath56 ,",
    "if @xmath313 is smaller than @xmath314 then @xmath304 .",
    "note that if the @xmath23 that maximizes @xmath315 is not the @xmath23 that minimizes @xmath316 then @xmath317 , otherwise @xmath318 .    removing the element that minimizes @xmath313 may make the elements of @xmath80 more dissimilar and therefore increase @xmath319 .",
    "iterating this process may make the elements of the resulting sets ever more dissimilar , until the associated @xmath320 declines due to decreasing cardinality .",
    "therefore , we come to the following heuristic . let @xmath321 .",
    "compute @xmath322 let @xmath323 be the index @xmath30 for which the maximum in the second term is reached . set @xmath324 . repeat this process with @xmath325 instead of @xmath0 to obtain @xmath326 , and so on .",
    "the result is @xmath327 with @xmath328 and @xmath329 .",
    "set @xmath330 . the whole process to compute this heuristic",
    "to approximate @xmath257 from below takes @xmath281 steps where a step involves compressing a subset of @xmath0 in @xmath285 time .",
    "the inequality @xmath304 for @xmath56 in the form of @xmath178 with @xmath307 occurs in the example of remark  [ rem.defp ] . here",
    "@xmath173 is according to , that is , the left term in defining @xmath117 .",
    "the applications in section  [ sect.app ] concern classifications . for these purposes",
    ", it makes no sense to compute the @xmath251 , but instead we consider the change in @xmath320 for each multiset that we are classifying against with and without the element that is being classified . to compare these changes we require as much discriminatory power as possible .",
    "remark  [ rem.ei ] shows that @xmath331 for @xmath332 and @xmath333 ( in the form of @xmath134 ) . while possibly @xmath334 , for some @xmath335 we have @xmath336 .",
    "in general we believe that the nondecreasing of @xmath257 with larger @xmath0 according to lemma  [ lem.triangle ] is just required to make the @xmath251 metric .",
    "this smoothes the @xmath320 function according to to a nondecreasing function for increasing cardinality arguments .",
    "however , in the smoothing one obliterates differences that obviously enhance discriminatory power .      suppose we want to classify @xmath23 as belonging to one of the classes represented by multisets @xmath337 . our method is to consider @xmath338 , and similar for classes represented by @xmath339 , and then to select the least difference . however , this difference is always greater or equal to 0 by lemma  [ lem.triangle ] .",
    "if we look at @xmath340 then the difference may be negative , zero , or positive and possibly greater in absolute value .",
    "this gives larger discriminatory power in the classes selection .",
    "another reason is as follows .",
    "let @xmath341 be as in the proof of theorem  [ theo.fast ] .",
    "for the handwritten digit recognition application in section  [ sect.nist ] we computed @xmath341 for digits @xmath342 .",
    "the values were 0.9845 , 0.9681 , 0.9911 , 0.9863 , 0.9814 , 0.9939 , 0.9942 , 0.9951,0.992 , 0.9796 . but @xmath343 for the class of digit 1 where the maximum is reached for index @xmath344 .",
    "thus @xmath345 for this class with the @xmath251 computed according to theorem  [ theo.fast ] . we know",
    "that @xmath346 because @xmath347 .",
    "computing @xmath348 similarly as @xmath349 may yield @xmath350 because @xmath351 for @xmath352 may be the same multiset as @xmath353 for @xmath354 for some @xmath355 .",
    "this has nothing to do with the element @xmath23 we try to classify .",
    "the same may happen to @xmath356 , and so on .",
    "the kolmogorov complexity of a file is a lower bound on the length of the ultimate compressed version of that file . above",
    "we approximate the kolmogorov complexities involved by a real - world compressor @xmath226 .",
    "since the kolmogorov complexity is incomputable , in the approximation we never know how close we are to it . however , we assume that the natural data we are dealing with contain no complicated mathematical constructs like @xmath357 or universal turing machines .",
    "in fact , we assume that the natural data we are dealing with contains only effective regularities that a good compressor like @xmath226 finds . under those assumptions",
    "the kolmogorov complexity @xmath38 of object @xmath23 is not much smaller than the length of the compressed version @xmath227 of the object .",
    "section [ sect.nist ] describes an algorithm that we developed to partition data for classification in cases where the classes are not well separated so that there are no subsets of a class with separation larger than that of the smallest inter - class separation , a heuristic that we have found to work well in practice .",
    "we detail preliminary results using the new ncd for multisets .",
    "the ncd for pairs as originally defined @xcite has been applied in a wide range of application domains . in @xcite a close relative was compared to every time series distance measure published in the decade preceding 2004 from all of the major data analysis conferences and found to outperform all other distances aside from the euclidean distance with which it was competitive .",
    "the ncd for pairs has also been applied in biological applications to analyze the results of segmentation and tracking of proliferating cells and organelles @xcite .",
    "the ncd is unique in allowing multidimensional time sequence data to be compared directly , with no need for alignment or averaging .    here",
    ", we compare the performance of the proposed ncd for multisets to that of a previous application of the ncd for pairs for predicting retinal progenitor cell ( rpc ) fate outcomes from the segmentation and tracking results from live cell imaging @xcite .",
    "we also apply the proposed ncd to a synthetic data set previously analyzed with the pairwise ncd @xcite .",
    "finally , we apply the proposed ncd for multisets to the classification of handwritten digits , an application that was previously evaluated using the pairwise ncd in @xcite .      in @xcite , long - term time - lapse image sequences showing rat rpcs were analyzed using automated segmentation and tracking algorithms .",
    "images were captured every five minutes of the rpcs for a period of 913 days .",
    "up to 100 image sequences may be captured simultaneously in this manner using a microscope with a mechanized stage . for an example",
    "see figure  [ fig.rpc ] .        at the conclusion of the experiment ,",
    "the `` fate '' of the offspring produced by each rpc was determined using a combination of cell morphology and specific cell - type fluorescent markers for the four different retinal cell types produced from embryonic day 20 rat rpcs @xcite . at the conclusion of the imaging , automated segmentation and tracking algorithms @xcite",
    "were applied to extract the time course of features for each cell . these automated segmentation and tracking algorithms",
    "extract a time course of feature data for each stem cell at a five - minute temporal resolution , showing the patterns of cellular motion and morphology over the lifetime of the cell .",
    "specifically , the segmentation and tracking results consisted of a 6-dimensional time sequence feature vector incorporating two - dimensional motion @xmath358 , as well as the direction of motion , total distance travelled , cellular size or area ( in pixels ) and a measure of eccentricity on @xmath103 $ ] ( 0 being linear , 1 being circular shape ) .",
    "the time sequence feature vectors for each of the cells are of different length and are not aligned .",
    "the results from the segmentation and tracking algorithms were then analyzed as follows .",
    "the original analysis of the rpc segmentation and tracking results used a multiresolution semi - supervised spectral analysis based on the originally formulated pairwise ncd .",
    "an ensemble of distance matrices consisting of pairwise ncds between quantized time sequence feature vectors of individual cells is generated for different feature subsets @xmath359 and different numbers of quantization symbols @xmath164 for the numerical time sequence data .",
    "the fully automatic quantization of the numeric time sequence data is described in @xcite .",
    "all subsets of the 6-dimensional feature vector were included , although it is possible to use non - exhaustive feature subset selection methods such as forward floating search , as described in @xcite .",
    "each distance matrix is then normalized as described in @xcite , and the eigenvectors and eigenvalues of the normalized matrix are computed .",
    "these eigenvectors are stacked and ordered by the magnitude of the corresponding eigenvalues to form the columns of a new `` spectral '' matrix .",
    "the spectral matrix is a square matrix , of the same dimension @xmath360 as the number of stem cells being analyzed .",
    "the spectral matrix has the important property that the @xmath30th row of the matrix is a point in @xmath361 ( @xmath362 is the set of real numbers ) that corresponds to the quantized feature vectors for the @xmath30th stem cell . if we consider only the first @xmath363 columns , giving a spectral matrix of dimension @xmath364 , and run a k - means clustering algorithm , this yields the well - known spectral k - means algorithm @xcite .",
    "if we have known outcomes for any of the objects that were compared using the pairwise ncd , then we can formulate a semi - supervised spectral learning algorithm by running for example nearest neighbors or decision tree classifiers on the rows of the spectral matrix .",
    "this was the approach adopted in @xcite .",
    "in the original analysis , three different sets of known outcomes were considered .",
    "first , a group of 72 cells were analyzed to identify cells that would self - renew ( 19 cells ) , producing additional progenitors and cells that would terminally differentiate ( 53 cells ) , producing two retinal neurons .",
    "next , a group of 86 cells were considered on the question of whether they would produce two photoreceptor neurons after division ( 52 cells ) , or whether they would produce some other combination of retinal neurons ( 34 cells ) .",
    "finally , 78 cells were analyzed to determine the specific combination of retinal neurons they would produce , including 52 cells that produce two photoreceptor neurons , 10 cells that produce a photoreceptor and bipolar neuron , and 16 cells that produced a photoreceptor neuron and an amacrine cell .",
    "confidence intervals are computed for the classification results by treating the classification accuracy as a normally distributed random variable , and using the sample size of the classifier together with the normal cumulative distribution function ( cdf ) to estimate the region corresponding to a fixed percentage of the distribution @xcite . for the terminal versus self - renewing question ,",
    "99% accuracy was achieved in prediction using a spectral nearest neighbor classifier , with a 95% confidence interval of [ 0.93 , 1.0 ] . in the sequel",
    ", we will list the 95% confidence interval in square brackets following each reported classification accuracy .",
    "for the two photoreceptor versus other combination question , 87% accuracy [ 0.78 , 0.93 ] was achieved using a spectral decision tree classifier . finally , for the specific combination of retinal neurons 83% accuracy [ 0.73 , 0.9 ] was achieved also using a spectral decision tree classifier .",
    "classification using the newly proposed ncd is much more straightforward and leads to significantly better results . given multisets @xmath354 and @xmath365 , each consisting of cells having a given fate , and a cell @xmath23 with unknown fate , we proceed as follows .",
    "we assign @xmath23 to whichever multiset has its distance ( more picturesque `` diameter '' ) increased the least with the addition of @xmath23 . in other words , if @xmath366 we assign @xmath23 to multiset @xmath354 , else we assign @xmath23 to multiset @xmath365 .",
    "( the notation @xmath367 is shorthand for the multiset @xmath0 with one occurrence of @xmath23 added . )",
    "note that for classification purposes we consider the impact of element @xmath23 on the @xmath320 only and do not evaluate the full ncd for classification .",
    "we use the @xmath320 in rather than the @xmath251 because the @xmath320 has the ability to decrease when element @xmath23 contains redundant information with respect to multiset @xmath354 .",
    "see also the reasons in section  [ sect.ancd ] .",
    "the classification accuracy improved considerably using the newly proposed ncd for multisets . for the terminal versus self - renewing question",
    ", we achieved 100% accuracy in prediction [ 0.95,1.0 ] compared to 99% accuracy [ 0.93,1.0 ] for the multiresolution spectral pairwise ncd .",
    "for the two photoreceptor versus other combination question , we also achieved 100% accuracy [ 0.95,1.0 ] compared to 87% [ 0.78,0.93 ] .",
    "finally , for the specific combination of retinal neurons we achieved 92% accuracy [ 0.84,0.96 ] compared to 83% [ 0.73,0.9 ] with the previous method .      in @xcite ,",
    "an approach was developed that used the pairwise ncd to compute a concise and meaningful summarization of the results of automated segmentation and tracking algorithms applied to biological image sequence data obtained from live cell and tissue microscopy .",
    "a synthetic or simulated data set was analyzed using a method that incorporated the pairwise ncd . allowing precise control over differences between objects within and across image sequences .",
    "the features for the synthetic data set consisted of a 23-dimensional feature vector .",
    "the seven features relating to 3-d cell motion and growth were modeled as described below , the remaining 16 features were set to random values .",
    "cell motility was based on a ? ? ?",
    "run - and - tumble ? ? ?",
    "model similar to the motion of bacteria .",
    "this consists of periods of rapid directed movement followed by a period of random undirected motion .",
    "cell lifespan was modeled as a gamma distributed random variable with shape parameter 50 and scale parameter 10 .",
    "once a cell reaches its lifespan it undergoes cell division , producing two new cells , or , if a predetermined population limit has been reached , the cell undergoes apoptosis , or dies .",
    "the final aspect of the model was cell size .",
    "the initial cell radius , denoted @xmath368 , is a gamma - distributed random variable with shape parameter 200 and scale parameter 0.05 .",
    "the cells growth rate is labeled @xmath369 . at the end of its lifespan",
    ", the cell doubles its radius .",
    "the radius at time t is given by @xmath370 in the original analysis , two different populations were simulated , one population having an @xmath369 value of 3 , the second having an @xmath369 value of 0.9 .",
    "the data was originally analyzed using a multiresolution representation of the time sequence data along with feature subset selection .",
    "here we repeat the analysis for a population of 656 simulated cells , with between 228 and 280 time values for each 23 dimensional feature vector .",
    "this data was analyzed using a minimum distance supervised classifier with both the original pairwise and the proposed ncd for multisets . omitting the feature subset selection step and incorporating the entire 23 dimensional feature vector ,",
    "the pairwise ncd was 57% correct [ 0.53,0.61 ] the classifying the data , measured by leave - one - out cross validation .",
    "using ncd for multisets , we achieved 91% correct [ 0.89,.93 ] classification , a significant improvement .",
    "when a feature subset selection step was included , both approaches achieved 100% correct classification .",
    "deficiencies in the transport of organelles along the neuronal axon have been shown to play an early and possibly causative role in neurodegenerative diseases including huntington s disease @xcite . in @xcite , we analyzed time lapse image sequences showing the transport of fluorescently labeled brain derived neurotrophic factor ( bdnf ) organelles in a wild - type ( healthy ) population of mice as well as in a mutant huntingtin protein population .",
    "the goal of this study was to examine the relationship between bdnf transport and huntington s disease .",
    "the transport of the fluorescently labeled bdnf organelles was analyzed using a newly developed multi - target tracking approach we termed `` multitemporal association tracking '' ( mat ) . in each image sequence , organelles were segmented and then tracked using mat and instantaneous velocities were calculated for all tracks .",
    "image data was collected over eight time - lapse experiments , with each experiment containing two sets of simultaneously captured image sequences , one for the diseased population and one for the wild type population .",
    "there were a total of 88 movies from eight data sets .",
    "although the pairwise ncd was not able to accurately differentiate these populations for individual image sequences , by aggregating the image sequences so that all velocity data from a single experiment and population were considered together , we were able to correctly classify six of the eight experiments as wild type versus diseased for 75% correct classification accuracy . analyzing the velocity data from the individual image sequences using pairwise ncd with a minimum distance classifier",
    ", we were able to classify 57% [ 0.47,0.67 ] of the image sequences correctly into wild type versus diseased populations .",
    "using the ncd for multisets formulation described in with the same minimum distance approach , as described in the previous sections , we achieved a classification accuracy of 97% [ 0.91,0.99 ] .",
    "in addition to the previous applications , we applied the new ncd for multisets to analyzing handwritten digits from the mnist handwritten digits database @xcite , a free and publicly available version of the nist handwritten digits database 19 that was analyzed in @xcite .",
    "the nist data consists of 128x128 binary images while the mnist data has been normalized to a 28x28 grayscale ( 0, .. ,255 ) images .",
    "the mnist database contains a total of 70,000 handwritten digits . here",
    ", we consider only the first 1000 digits .",
    "the images are first scaled by a factor of four and then adaptive thresholded using an otsu transform to form a binary image .",
    "the images are next converted to one - dimensional streams of binary digits and used to form a pairwise distance matrix between each of the 1000 digits .",
    "originally the input looks as figure  [ fig.digits ] .",
    "following the same approach as described for the retinal progenitor cells above , we form a spectral matrix from this pairwise distance matrix . in @xcite ,",
    "a novel approach was developed for using the distances as input to a support vector machine .",
    "random data examples along with unlabelled images of the same size were selected and used as training data , achieving a classification accuracy of 87% on the unscaled nist database 19 digits .",
    "we follow the same approach of incorporating the distances into a supervised learning framework , using our spectral matrix as input to an ensemble of discriminant ( gaussian mixture model ) classifiers @xcite .",
    "using leave - one - out cross validation , this approach using the pairwise ncd achieved 82% correct classification [ 0.79,0.84 ] for the 1000 scaled and resized mnist digits .    in applying the multisets ncd to this data ,",
    "we measured the separation between classes or the _ margin_. given multisets @xmath354 and @xmath365 , each corresponding to a class in the testing data , we measure the separation between the two classes as @xmath371 this follows directly from the relevant venn diagram .",
    "our goal is to partition the input classes such that the separation between classes is larger than any separation between subsets of the same class , subject to a minimum class size .",
    "we have found that this approach works well in practice .",
    "we have developed an expectation maximization algorithm to partition the classes such that there exist no subsets of a class separated by a margin larger than the minimum separation between classes .",
    "our expectation maximization algorithm attempts to partition the classes into maximally separated subsets as measured by .",
    "this algorithm , that we have termed _ k - lists _",
    ", is modeled after the k - means algorithm .",
    "although it is suitable for general clustering , here we use it to partition the data into two maximally separated subsets .",
    "the algorithm is detailed in figure  [ tab.1 ] .",
    "there is one important difference between proposed k - lists algorithm and the k - means algorithm .",
    "because we are not using the centroid of a cluster as a representative value as in k - means , but rather the subset itself via the ncd for multisets , we only allow a single element to change subsets at every iteration .",
    "this prevents thrashing where groups of elements chase each other back and forth between the two subsets",
    ". the algorithm is run until it either can not find any partitions in the data that are separated by more than the maximal inter - class separation , or until it encounters a specified minimum cluster size .",
    "this step is computationally demanding , but it is an inherently parallel computation .    for the retinal progenitor cell data and synthetic data sets described in the previous sections , the k - lists partitioning algorithm was not able to find any subsets that had a larger separation as measured by compared to the separation between the classes . for the nist handwritten digits data , the partitioning algorithm was consistently able to find subsets with separation larger than the between class separation .",
    "the partitioning was run for a range of different minimum cluster sizes ( 10% , 20% and 30% of the original class size ) .",
    "this results in multiple distances to each original digit class .",
    "here we included the two minimum distances to each class as input to the ensemble of discriminant classifiers .",
    "this resulted in a classification accuracy of for the 30% partition size of 85% [ 0.83,0.87 ] .",
    "the other two partition sizes had marginally lower classification accuracy . finally , we combined the two minimal class distances from the partitioned multisets data along with the pairwise spectral distances described above as input to the classification algorithm , resulting in a combined leave - one - out cross validation accuracy of 99.6% correct [ 0.990,0.998 ] , a significant improvement over the accuracy achieved using either the pairwise or multisets ncd alone .",
    "the current state of the art classifier for the mnist data achieves an accuracy of 99.77% correct @xcite .",
    "all of the software and the time sequence data for the rpc fate outcome problem can be downloaded from http://bioimage.coe.drexel.edu/ncdm .",
    "the software is implemented in c and uses mpi for parallelization .",
    "all data compression was done with ` bzip2 ` using the default settings .",
    "data import is handled by a matlab script that is also provided .",
    "the software has been run on a small cluster , consisting of 100 ( hyperthreaded ) xeon and i7 cores running at 2.9 ghz .",
    "the rpc and synthetic classification runs in approximately 20 minutes for each question , while the partitioning and classification of the nist digit data takes multiple hours for each step .    1 .   ( initialize )",
    "pick two elements ( seeds ) of @xmath0 at random , assigning one element to each @xmath354 and @xmath365 . for each remaining element @xmath23 ,",
    "assign @xmath23 to the closer one of @xmath354 or @xmath365 using pairwise ncd to the random seeds 2 .   for each element @xmath23 ,",
    "compute the distance from @xmath23 to class @xmath354 and @xmath365 using and assign to whichever class achieves the smaller distance .",
    "3 .   choose the single element that wants to change subsets , e.g. from @xmath354 to @xmath365 or vice versa and whose change maximizes @xmath372 and swap that element from @xmath354 to @xmath365 or vice versa .",
    "repeat steps 2 and 3 until no more elements want to change subsets or until we exceed e.g. 100 iterations .",
    "repeat the whole process some fixed number of times ( here we use 5 ) for each @xmath0 and choose the subsets that achieve the maximum of @xmath372 .",
    "if that value exceeds the minimum inter - class separation and the subsets are not smaller than the specified minimum size then divide @xmath0 into @xmath354 and @xmath365 and repeat the process for @xmath354 and @xmath365 . if the value does not exceed the minimum inter - class separation of our training data or the subsets exceed the specified minimum size , then accept @xmath0 as approximately monotonic and go on to the next class .",
    "information distance @xcite uses the notion of kolmogorov complexity to identify the metric where the pairwise distance is a quantification of the dominant of all differences between the digital objects .",
    "normalized _ form of information distance , the similarity metric , was developed in @xcite allowing the differences to be relative rather than absolute . with a leap of faith",
    "the kolmogorov complexities involved were approximated with real - world compressors . in @xcite",
    "this led to the ncd , with the real compressors involved required to satisfy certain properties and under this requirement the ncd is shown to be a metric as well .",
    "moreover the evolutionary trees were liberated to hierarchical clustering of general objects .",
    "the ncd uses standard file compression algorithms ( _ e.g. _ ` gzip ` , ` bzip2 ` or ` ppmz ` ) . in @xcite , it was proposed to extend the idea of information distance to multiple objects , or multisets .",
    "the idea of information distance for multisets was studied in @xcite , where certain properties were shown , including the positive definiteness , symmetry and triangle inequality properties required of a metric . in order to compare the relative rather than absolute differences among objects , a normalized form of this information distance",
    "is required .",
    "previous efforts to find such a normalized form that obey the triangle inequality were not successful @xcite .",
    "here we present a normalized form of the information distance for multisets and show it to be a metric .",
    "this normalized form of information distance is based on the observation that in order to obey the triangle inequality , the distance can never decrease as elements are added to the multiset .",
    "the proposed normalized information distance for multisets reduces to the original ( pairwise ) formulation of normalized information distance as in @xcite when applied to multisets of cardinality two .",
    "similar to the original pairwise ncd developed as an approximation to the normalized information distance @xcite , we developed a practically effective approximation to the normalized information distance for multisets based on file compression algorithms .",
    "this ncd for multisets is more computationally demanding than the pairwise ncd but it is straightforward to implement the computations in parallel .    the ncd for multisets is applied to previous applications where the pairwise ncd was used so that comparison is possible . in all these applications it improved the results either alone or in combination with the pairwise version . in some applications ,",
    "including retinal progenitor cell fate prediction and the analysis of simulated populations of proliferating cells , the new ncd for multisets obtain significant improvement over the pairwise ncd .",
    "in other applications such as the nist handwritten digits , the ncd for multisets alone did not significantly improve upon the result from the pairwise ncd , but a significant overall improvement in accuracy resulted by combining both distance measures . in all cases , we applied the same parameter - free implementation of both the multiple version and the pairwise version of the ncd .",
    "that is , no features of the problems were used at all .",
    "a. r. cohen , c. bjornsson , s. temple , g. banker , and b. roysam , automatic summarization of changes in biological image sequences using algorithmic information theory , _ ieee trans",
    ". pattern anal .",
    "_ 31(2009 ) , 13861403 .",
    "a. kocsor , a. kertsz - farkas , l. kajn , and s. pongor , application of compression - based distance measures to protein sequence classification : a methodology study , _ bioinformatics _ , 22:4(2006 ) , 407412 .",
    "m. nykter , n.d . price , m. aldana , s.a .",
    "ramsey , s.a .",
    "kauffman , l.e .",
    "hood , o. yli - harja , and i. shmulevich , gene expression dynamics in the macrophage exhibit criticality , _ proc .",
    "usa _ , 105:6(2008 ) , 18971900 .",
    "m. nykter , n.d .",
    "price , a. larjo , t. aho , s.a .",
    "kauffman , o. yli - harja and i. shmulevich , critical networks exhibit maximal information diversity in structure - dynamics relationships , _ physical review lett .",
    "_ , 100(2008 ) , 058702(4 ) .        m. winter , e. wait , b. roysam , s. goderie , e. kokovay , s. temple , et al . , vertebrate neural stem cell segmentation , tracking and lineaging with validation and editing , _ nature protocols _ , 6(2011 ) ,",
    "19421952 .",
    "zvonkin and l.a .",
    "levin , the complexity of finite objects and the development of the concepts of information and randomness by means of the theory of algorithms , _ russian math . surveys _ 25:6 ( 1970 ) 83 - 124 ."
  ],
  "abstract_text": [
    "<S> normalized compression distance ( ncd ) is a parameter - free , feature - free , alignment - free , similarity measure between a pair of finite objects based on compression . </S>",
    "<S> however , it is not sufficient for all applications . </S>",
    "<S> we propose an ncd of finite nonempty multisets ( a.k.a . </S>",
    "<S> multiples ) of finite objects that is also a metric . </S>",
    "<S> previously , attempts to obtain such an ncd failed . </S>",
    "<S> we cover the entire trajectory from theoretical underpinning to feasible practice . </S>",
    "<S> the new ncd for multisets is applied to retinal progenitor cell classification questions and to related synthetically generated data that were earlier treated with the pairwise ncd . with the new method we achieved significantly better results . </S>",
    "<S> similarly for questions about axonal organelle transport . </S>",
    "<S> we also applied the new ncd to handwritten digit recognition and improved classification accuracy significantly over that of pairwise ncd by incorporating both the pairwise and ncd for multisets . in the analysis we use the incomputable kolmogorov complexity that for practical purposes is approximated from above by the length of the compressed version of the file involved , using a real - world compression program .    </S>",
    "<S> _ index terms_ normalized compression distance , multisets or multiples , pattern recognition , data mining , similarity , classification , kolmogorov complexity , retinal progenitor cells , synthetic data , organelle transport , handwritten character recognition </S>"
  ]
}