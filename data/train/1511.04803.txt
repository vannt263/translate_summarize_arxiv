{
  "article_text": [
    "due to the predictive nature of classification models , the predictive power is usually the most important factor for assessing a classifier / diagnosis procedure .",
    "this is especially the case in the scenarios of disease screening or survey research , where an efficient classification rule that can effectively distinguish the diseased from normal subjects is preferred .",
    "however , we are also aware that the performance should not be the solo measure for assessing a classifier when the model interpretation and the impacts of factors are of interest . for example , in some medical / pharmaceutical research , we want to learn the impacts of biomarkers in a classification rule .",
    "because this information might also imply their associations with the studied disease , it could be useful for drug and therapy developments .",
    "hence , in this kind of research , besides the diagnostic power , the ability of to identify useful biomarkers / variables or the ease of model interpretation is also an important criterion for evaluating a classification rule . in modern classification literature , we can easily find many powerful classification procedures , such as the support vector machine ( see * ? ? ?",
    "* ) , which can provide high classification accuracy .",
    "yet , we also know that when these types of powerful and complicated classification rules are used , extra effort is required to interpret their rules / models , and to dig out the impact information of individual variables / biomarkers from them is even more difficult .    on the other hand , simple conventional statistical models , such as linear logistic models , can usually be easily interpreted ; nevertheless , they might not have as good classification performance as those modern methods , especially when the association between diseases and variables is complicated .",
    "a nonlinear model can usually fit the observed data better than its linear model counterpart .",
    "however , can it also assure us good prediction performance in general classification problems ?",
    "as far as we know , there is still a lack of theoretical justification in the literature to guarantee this .",
    "in fact , the inconsistency between the fitted model and the prediction - based model building has been reported in @xcite .",
    "of course , if the model is true , then fitting observations may better insure this model against bad predictions .",
    "however , in practical situations , the true model is usually unknown .",
    "then , to overfit the observed data or training samples with a complicated model can not guarantee good classification / prediction performance . from practical perspectives , to balance the classification performance and the ease of model interpretation is important , especially in the studies that focus on providing detailed model information for further research and developments .",
    "this motivates us to find a way to boost the performance of the conventional model and retain its ease of model interpretation .",
    "the assessment measures play an important role in classification / diagnostic research ( see * ? ? ?",
    "* ) , and using a different assessment measure commonly results in selecting a different classifier . because the accuracy of a binary classifier can easily be affected by the selected cutting point , and because using training samples to decide a cutting point might easily cause overfitting , a cross - validation procedure is usually used to prevent this situation . however , the cross - validation method is computationally intensive .",
    "thus , threshold independent measures , such as the receiver operating characteristic ( roc ) curve , are usually preferred to accuracy @xcite .",
    "the area under roc curve ( auc ) is a popularly used summarization statistic of the roc curve , and in this study , we will use it as the performance measure . for a binary classification problem",
    ", it has been proved in @xcite that a logistic - type classification function will achieve the maximum auc under certain conditions . moreover , as stated in @xcite , the general additive model ( gam ) is a method of approximating the true model and is a flexible statistical method that can be used to characterize and identify nonlinear regression effects .",
    "many advantages of gam have been intensively discussed . among them , a commonly mentioned one is its ease of model interpretability @xcite . the general additive models ( gam )",
    "@xcite are flexible statistical methods that may be used to characterize and identify nonlinear regression effects .",
    "many advantages of gam have been intensively discussed @xcite , and a commonly mentioned one is its ease of model interpretability @xcite .",
    "moreover , the gam is a method of approximating the true model @xcite , and it has been proved that a logistic type classification will achieve the maximum auc @xcite under certain condition .",
    "the results mentioned above motivate us to study how to use a general additive logistic function as a classification model such that model interpretation ability is retained , and a better classification performance is achieved .",
    "hence , in this paper , a general additive logistic type of classification function is used to boost the classification performance of conventional models in terms of auc .",
    "theoretical justification is presented , and some suggestions for fitting a general additive logistic model are discussed .",
    "the rest of this paper is organized as follows .",
    "we start with a brief review of the roc curve , auc , and gam .",
    "then , we will show the relations between the roc curve and the logistic regression models , and how the auc of a logistic model can be improved with a general additive logistic model .",
    "it is followed by the numerical results using both synthesized data and two real data sets . fitting a gam model relies on some iterative algorithms , and the different approaches used in the algorithms",
    "may affect the fitting results .",
    "hence , the computational methods of gam are compared , and some suggestions based on the empirical results are given in the summary .",
    "the information on algorithms and the corresponding packages used here are described in the appendix .",
    "the roc curve and auc are important statistical tools for evaluating binary classifiers ( see * ? ? ?",
    "let @xmath0 be the score of a binary classification function ; then they can be briefly described as follows .",
    "assume that the greater the value of @xmath0 , the higher the probability of a subject being diagnosed as a diseased one .",
    "suppose @xmath1 is a threshold and the subject with @xmath2 will be classified as diseased .",
    "then , the sensitivity and specificity for such a cutting point @xmath3 are defined as @xmath4 and @xmath5 , respectively .",
    "it follows that the corresponding roc curve is defined as a plot of @xmath6 , and its auc is then equal to @xmath7 .",
    "that is , the plot of an roc curve takes all possible cutting points into consideration , and the auc of it can be viewed as a summarization of roc curve .",
    "the detailed properties of the roc curve and auc can be easily found in the literature and textbooks , such as @xcite .",
    "let @xmath8 , @xmath9 , @xmath10 be predictors and @xmath11 be a binary response variable .",
    "a gam has a form as @xmath12 where @xmath13 s are some smooth functions .",
    "thus , it can be viewed as an additive extension of the family of generalized linear models @xcite . each smooth function in can be fitted using a scatterplot smoother , such as a cubic smoothing spline or kernel smoother . as a special case of the generalized linear models , a general additive logistic model , under the gam framework , is formulated as @xmath14 where @xmath15 and @xmath13 s are some unknown smooth functions .",
    "the smooth functions of gams are estimated based on the observations with some iterative procedures . due to the additive assumption",
    ", these smooth functions can always provide the relations between the variables and the disease .",
    "the non - parametric form of @xmath13 gives us some flexibility for model fitting , and the additive form of gam retains much of the ability of model interpretation @xcite . besides these properties , there are more classification - related advantages of the additive logistic models discussed in @xcite .    in many medical diagnostic situations , to learn the relationship between the sensitivity and specificity of classifiers is important .",
    "an roc curve and its auc can provide more information before a threshold is determined .",
    "thus , despite the accuracy of a classification rule , they are commonly used measures in these kinds of research .",
    "below , we show how the classification power of a conventional logistic model can easily be improved by an additive logistic model counterpart with only a little extra computational effort .",
    "let @xmath16 be a binary response variable as before .",
    "suppose that @xmath17 or @xmath18 are labels of two classes in a binary classification problem .",
    "let @xmath19 be the vector of measurements of a subject and @xmath20 and @xmath21 be the conditional probability density functions of @xmath19 , given @xmath22 and @xmath23 , respectively .",
    "let @xmath24 and @xmath25 , with @xmath26 , denote the probabilities of @xmath22 and @xmath23 , accordingly .",
    "that is , @xmath24 and @xmath25 are the proportions of two classes in the whole population .",
    "it follows that for a given @xmath27 , the log - odd ratio of two classes , say @xmath28 , can be written as a function of @xmath27 : @xmath29    as stated before , an roc curve is a plot true positive rate ( sensitivity ) against the false positive rate ( 1-specificity ) .",
    "if we treat the false positive and false negative as type i and type ii errors , respectively , then an roc curve can also be viewed as a plot of type ii errors versus type i errors at different critical values . moreover , from the neyman - pearson lemma , we have that for a given type i error , the likelihood ratio test is the most powerful test for testing the null hypothesis @xmath22 versus the alternative hypothesis @xmath23 . hence , under this hypotheses testing framework , and using the neyman - pearson lemma , it is proved that @xmath28 defined in is a statistic that maximizes the height of the roc curve at all levels of specificity .",
    "that is , if @xmath28 is used as a classification function , then its corresponding roc curve will dominate the roc curves of all other binary classification functions and therefore has the maximum auc . based on this fact",
    ", @xcite showed that the maximum auc can only be achieved when the true model for the density ratio , @xmath30 , is known .",
    "however , both @xmath20 and @xmath21 are usually unknown in practice , and so is @xmath28 .",
    "thus , among all possible classification functions based on the observations , the one that can best approximate @xmath28 will have the largest maximum auc .",
    "it follows that when a conventional logistic model is a true model , then the classification function based on it will have the maximum auc .",
    "therefore , in this case there is no room for further improvement .",
    "otherwise , if the prediction power is the only concern , then one can always find a more complicated model for approximating the likelihood ratio in order to have better classification performance . on the other hand ,",
    "if the final model is too difficult to be interpreted , then it provides little information about the relation between responses and the variables of interest .",
    "thus , these types of models will not be useful for identifying the impacts of individual variables on the response .",
    "however , in many situations , to identify the key variables is also an important task .",
    "for example , in pharmaceutical and medical research , this information is highly valued for developing new drugs or therapies .",
    "it is well - known that a general additive model will usually fit data well . in addition , authors suggest that to use an additive logistic model to fit data is a good strategy in practice , as it will retain some ease of model interpretation @xcite .",
    "however , it is also pointed out in the literature that a better - fitting model can not guarantee a better prediction @xcite in a general sense , and as far as we know , there is still no theoretical proof that a better - fitting model will also have a larger auc . in below , we show that a general additive model will have a larger auc than its linear logistic model counterpart will .",
    "[ [ proof ] ] proof + + + + +    let @xmath28 be the true log - odds ratio as before . if a linear logistic model is used to approximate the log odds - ratio , then we assume that @xmath31=\\beta'x$ ] , where @xmath32 is the unknown regression parameters to be estimated .",
    "similarly , if an additive logistic model is used , then we set @xmath31=\\sigma_i f_i$ ] , where @xmath33 s are some smooth functions as in .",
    "let @xmath34 , @xmath35 and @xmath36 be three constants and define @xmath37 , @xmath38 , @xmath39 as the corresponding critical regions of the likelihood ratio tests based on @xmath28 , @xmath40 and @xmath41 , respectively , such that @xmath42 that is , all three test statistics , @xmath28 , @xmath40 and @xmath41 , have the same type i error .",
    "then , by the neyman - pearson lemma , we have @xmath43 and the equality in holds only when the linear logistic model is the true model for the log odds - ratio .",
    "if this linear logistic model is not the true model , then there is an @xmath44 such that @xmath45 if inequality @xmath46 holds , then it follows from and , we have proved that the auc of an additive logistic model defined by @xmath40 is greater than or equal to that of a linear logistic model defined by @xmath41 .",
    "it is clear that to prove is equivalent to show that @xmath47 .",
    "however , in general there is no guarantee that @xmath47 , when @xmath33 s are just some nonlinear or additive extensions of the original linear logistic model . in below",
    ", we show that if @xmath40 satisfy certain conditions , then the inequality in holds , and thus the proof is complete .",
    "suppose that @xmath48 s are bounded ; then the estimates of @xmath33 s , say @xmath49 s , are chosen to minimize @xmath50 $ ] subject to the constraint @xmath51 .",
    "then , under a common smoothness assumption on @xmath52 , stone @xcite showed that the rate of convergence for spline estimates of @xmath53 is @xmath54 , where @xmath55 is the sample size and @xmath56 is a measure of the smoothness of @xmath57 .",
    "thus , @xmath58 $ ] will converge to 0 as the sample size becomes large . because holds",
    ", it implies that for any given @xmath59 , there is a large enough @xmath55 such that @xmath60 because @xmath61 can be arbitrarily small as @xmath55 goes to infinity , equations and together imply that as the sample size @xmath55 is large enough , @xmath62 it implies that for a large enough @xmath55 , we have @xmath63 that is , when the sample size is large enough , there is a spline estimate , @xmath40 , of @xmath28 such that @xmath64 let @xmath65 be a function of @xmath34 , @xmath66 such that @xmath67 .",
    "therefore , @xmath68 as @xmath67 .",
    "let auc@xmath69 denote the auc of the general additive logistic model based on @xmath40 , and let auc@xmath70 denote the auc of the linear logistic regression model based on @xmath41 .",
    "then , the rest of the proof follows via similar arguments of that in @xcite .",
    "that is , it is shown that    _ = & _ u=+^-\\{_if_i > u|y=1}d(\\{_if_i > u|y=0 } ) + & = _",
    "u=+^-\\{_if_i > u|y=1}d(\\{x > u+(u)|y=0 } ) + & _",
    "u=+^-\\{x > u+(u)|y=1}d(\\{x > u+(u)|y=0})=_.",
    "this completes that proof that as @xmath55 is large , the general additive logistic model based on @xmath40 has a larger auc than the linear logistic model with @xmath41 .",
    "the above result says that unless the linear logistic model above is the true model , which leaves no room for improvement , there is always a general additive logistic model that has a larger auc than that of the original linear logistic model when the sample size is large .",
    "moreover , because holds for all classification thresholds , it implies that the general additive logistic model has larger sensitivity than its corresponding linear logistic model does at any specificity level .",
    "that is , the general additive logistic model actually also has a larger partial auc than the linear logistic model does at any given range of specificity .",
    "this is a very useful feature , especially in rare disease diagnosis or other similar situations where the high specificity of a classification model is a must .",
    "we report the numerical results using both synthesized and real data sets .",
    "there are several numerical algorithms available in the r platform that can be used to fit a general additive logistic model with different options .",
    "according to the computational approaches adopted in these algorithms , there are three categories :    * \\(a ) back - fitting method ( see also @xcite , chapter 4 ) , * \\(b ) simultaneous estimation method ( estimating all components with optimization in smoothing parameter space @xcite , and * \\(c ) likelihood - based boosting method @xcite .",
    "the computational efficiency depends on many factors such as the dimensionality of explanatory variables of the data set , sample size and so on .",
    "basically , we found that none of these three types of methods can dominate the other two in all situations .",
    "hence , in order to provide useful information for practitioners to choose a suitable one for their needs , the advantages and disadvantages of using these methods in different situations are discussed .",
    "the results of fitting a linear logistic regression with a conventional method are used as baseline models , and the results of the general additive logistic models using different fitting algorithms will be compared with these results .",
    "( the variable selection is not the focus in this paper ; the variable selection schemes will be used only when there is such an option available in the corresponding packages . ) the following abbreviations denote the algorithms and the options used in our numerical studies .    1 .",
    "_ glm _ : fitting a _ linear logistic regression model _ with all predictors 2 .   _",
    "glm_step _ : fitting a _ linear logistic regression model _ with a backward elimination method for variable selection 3 .",
    "_ backfitting _ : fitting a _ general additive logistic model _ using a back - fitting algorithm 4 .   _",
    "backfitting_step _ : fitting a _ general additive logistic model _ using a back - fitting algorithm with the aic option for stepwise selection of model components and degrees of freedom 5 .",
    "_ mgcv _ : simultaneously estimating all components with smoothing parameter optimization when fitting a _ general additive logistic model _ 6 .   _",
    "mgcv_step _ : similar to _ mgcv _ with automatic selection of smoothing parameter using the aic criterion 7 .",
    "_ gamboost _ : a boosting procedure with the number of boosting steps selected with the aic criterion    because fitting a gam relies on the iterated algorithms and some parameter - setting in the algorithms need to be set in advance , there are many suggestions for the parameter setting in the algorithms in @xcite . here , we follow the suggestions of @xcite by apply a scaling factor 1.4 to the effective degrees of freedom of _ mgcv _ , and we multiply the degrees of freedom of both _",
    "glm _ and _ backfitting _ methods by 1.4 . for the _ gamboost _ has a variable selection option during its boosting procedure , so we use the default variable selection scheme in _ gamboost_. all numerical studies",
    "are conducted using the r language on a 64-bit linux pc cluster with xeon octa - core and hyper - threading e5 - 2670 2.6 ghz cpu with 256 gb of ram .",
    "the technical details of the packages used here , please refer to their original manuals in r.    in addition to aucs , the computational times of using these methods in different model - fitting scenarios in our numerical studies are reported .",
    "the fitting methods are described in the appendix .",
    "we just use the variable selection option when it is available in a package ; however , we will not discuss much about it .",
    "for the details of the variable selection option , please refer to their original papers , which can be found in the documents of the corresponding packages .",
    "instead , we emphasize the improvement of aucs when a general additive logistic type classification function is used and its interpretation .",
    "we consider two different dimensions ( @xmath71 and @xmath72 ) of models . to simulate different kinds of model complexities , we use two sets of effective variables as described in equations and below :",
    "@xmath73 the others variables , @xmath74 of the model are generated from a uniform distribution @xmath75 $ ] .",
    "that is , in all cases , only variable set 1 and set 2 above have contributions to their corresponding responses , and the other variables @xmath74 will have no contributions at all . in our studies , the true log - odds function of models with set 1 and set 2 variables",
    "have the same form below : @xmath76 the true probability vector @xmath77 is calculated with @xmath78 for each @xmath79 , and the binary response vector @xmath80 is generated using a bernoulli distribution with success probability @xmath81 for each @xmath82 .",
    "there are 100 repetitions for each case . for each run",
    ", we separately generated 100 training samples and 1000 testing samples .     with equation , ( b ) @xmath71 with equation , ( c ) @xmath72 with equation and ( d ) @xmath72 with equation .,scaledwidth=90.0% ]    \\times[0,1]$ ] unit square for each method .",
    "the curve of each method is based on 100 repetitions , and data are generated from 4 different situations : ( a ) @xmath71 with equation , ( b ) @xmath71 with equation , ( c ) @xmath72 with equation and ( d ) @xmath72 with equation .",
    "the vertical bars in these plots indicate the 95% point - wise confidence intervals for each curve.,scaledwidth=90.0% ]    figure [ figure1 ] shows the box - plots of aucs based on 100 replications for different models using different fitting methods described before . for the model with set 1 as its effective variables ,",
    "all fitting methods for the general additive model have larger aucs than the conventional linear logistic models do ( with and without variable selection option ) . for the model with the effective variable set 2 ,",
    "the advantage of the general additive logistic model is not as significant as the previous case , which is due to the complexity of the true model such that both the linear and general additive models can not approximate the true model well .",
    "however , the additive logistic model using _ backfitting _ and _ gamboost _ still outperforms the linear logistic model .",
    "figure [ figure10 ] are plots of the average roc curves in the left - upper corner of the unit - square , @xmath83\\times[0,1]$ ] .",
    "we can clearly see that there are two groups of roc curves in each picture , and the roc curves of the general additive model , with different fitting methods , are always higher than that of logistic models ( glm and glm_step ) .",
    "the general additive model fitted with different algorithms is essentially the same model unless their default variable selection option is used , which may introduce some variation due to their variable selection schemes .",
    "( note that glm denotes the result of fitting a conventional linear logistic model , and glm_step denotes the result of a similar fitting procedure but with a stepwise variable selection option . )",
    "figure [ figure3 ] shows the box - plots of computational times of different methods .",
    "when @xmath71 , the _ backfitting _ method uses the shortest time among all methods in two models .",
    "when @xmath72 , the _ gamboost _ method becomes very competitive , especially when the model is complicated as in ( see figure [ figure3](d ) ) . among different fitting methods for the general additive logistic model , the _ backfitting _ and _ gamboost _ are more computationally efficient than are the _ mgcv _ methods with and without step - wise variable selection",
    "based on the simulation results , the _ gamboost _ _ backfitting _ methods are `` cost - effective '' in terms of their gains in aucs and the little cost of extra computational time used compared to that of fitting a conventional linear logistic model with _ glm_-based algorithms .",
    "there are more discussions and comparisons of the computational - related issues for algorithms for fitting a logistic model and gam that can be found in @xcite .     with equation , ( b ) @xmath71 with equation , ( c ) @xmath72 with equation and ( d ) @xmath72 with equation .,scaledwidth=90.0% ]",
    "we also apply the proposed method and algorithms discussed above to two real data sets , parkinson s disease @xcite and cardiotocography @xcite , for illustration purposes .",
    "we compared the performances of methods using a general additive logistic model to the results obtained via fitting a linear logistic model .",
    "the main purpose of using these two data sets is to assess the improvement in aucs when replacing a linear logistic with a general additive logistic model .",
    "hence , for the details of these two data sets , please refer to their original papers @xcite .",
    "brief information about these two data sets is summarized below .",
    "[ [ parkinsons - disease - data - set ] ] parkinson s disease data set + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the original purpose of this data set is to find a classification rule to discriminate healthy people from the parkinson s disease ( pd ) patients based on some biomedical voice measurements .",
    "there are 31 persons in this study , and among them , 23 are patients .",
    "the study includes 195 voice recordings from these 31 individuals with different numbers of replications of each individual .",
    "there are 23 variables for each recoding .",
    "the binary code indicates the voice recording is from a diseased or a normal subject .",
    "the other 22 predictive variables consist of the records of several voice measurements , such as average vocal fundamental frequency , variation in amplitude and so on . for illustration purposes ,",
    "we treat 195 voice recordings as 195 individual samples .",
    "thus , among these 195 voices , there are 147 voice recordings from pd subjects and 48 from healthy subjects .",
    "that is , we treat it as a data set with 195 samples ( 147 positive and 48 negative cases ) with 22 variables , and the target becomes to build a classification rule to distinguish these two types of recordings .",
    "we follow the common training - test framework in machine learning and classification literature . each time ,",
    "90% of samples are randomly selected from these two groups for the model fitting ( training ) , and the remaining 10% of each of them are used as testing samples .",
    "this procedure is then repeated 100 times . because of the number of predictive variables is relatively large comparing to the subject size we have , _ mgcv _ and _ mgcv_step _ methods can not converge in a reasonable computing time . hence , we do not include the results of these two algorithms in this example .",
    "figures [ figure5 ] ( a ) and ( b ) are the box - plots of aucs and the computational times of all other methods based on 100 runs , respectively . in this example , all methods , including _",
    "glm _ and _ glm_step _ , perform well in terms of their auc averages .",
    "_ g__amboost has the largest average auc with the smallest variation among these methods .",
    "the linear logistic models ( with and without a stepwise variable selection option ) have smaller means of aucs and larger variances than others do .",
    "most of the algorithms are computationally efficient in this case , except _",
    "backfitting_step_. this is due to the stepwise variable selection procedure in _",
    "backfitting_step_. without stepwise option , the _ backfitting _ is as efficient as others .",
    "the differences of the computational times of _ glm _ , _ glm_step _ and _ backfitting _ are not statistically significant .",
    "in fact , the cpu time used in _ backfitting _ is only slightly longer than that of _ glm _ and _ glm_step_. thus , from both the improvement of aucs and the corresponding computational time view points , _ backfitting _ and _ gamboost _ are very `` cost - effective '' in this case .    the advantage of the _ backfitting _ and _ gamboost _ can also be seen from the plot of the average roc curves in figure [ figure8 ] . in order to have a clearer picture , we only show the left - upper @xmath84\\times[0.5 , 1]$ ] corner of the unit square .",
    "each curve plotted here is based on 100 replications , and the vertical bars on each curve are the corresponding 95% point - wise confidence intervals at the given false positive rates .",
    "it is clearly shown that the roc curve of _ gamboost _ is significantly higher than other roc curves in this range of false positive rate , and all roc curves from fitting a general additive logistic model , with different fitting algorithms , are higher than those of glm methods .",
    "this result confirms that the recommended method is useful even when only a specific range of false positive rate is of interest .",
    "( note that the roc curves of _ glm _ and _ glm_step _ are very close and thus can not be distinguished in this figure . )",
    "-axis is the value of each predictor , the solid line is the estimated functions and the dot - lines represents @xmath85 2 standard - error curves obtained from the fitting algorithm . ]",
    "figure [ figure4 ] shows the plots of estimated smooth functions and their corresponding partial residual plots for the selected predictors obtained from the _ backfitting_step _ method . because of the additive model assumption",
    ", we can look at one variable at a time by keeping the others fixed .",
    "thus , the interpretation of the relations between predictors and response variable is similar to that in a linear logistic model ( see * ? ? ?",
    "from this figure , we can see the impacts of the individual variables on the odds - ratio .",
    "for example , the left - upper corner is a plot of the curve of the estimated association function for mdvp.fo.hz , and it shows the functional relation between the log odds - ratio ( response variable ) and this variable .",
    "when the values of all other variables are fixed , this plot shows that mdvp.fo.hz and the response is positively associated at the beginning and then turns to negatively associated as the value of the variable becomes large .",
    "compared to that in the association plot for mdvp.flo.hz at the first row and second column , it clearly shows that these two variables have different associations with the responses .",
    "because the curve of mdvp.flo.hz stays near 0 , it indicates that the association of mdvp.flo.hz with the responses is not as strong as mdvp.fo.hz .",
    "in addition , the picture at the second row and forth column shows that the estimated function of variable _",
    "mdvp.apq _ is almost flat , and the @xmath86 standard deviation curves of it cover @xmath87 at most values of _",
    "mdvp.apq _ in this picture , except for the values around 0.02 .",
    "this suggests that this variable might have just a little impact on the ( log ) odds - ratio ( see * ? ? ?",
    "* ; * ? ? ?",
    "( please note that we just use this as an example for illustration purposes and no disease - related inference is made here . )",
    "thus , we can clearly find the impacts of individual variables on the responses through these plots as well as the certain levels of the interpretation ability of variables .",
    "it is clear that we can not obtain this kind of nonlinear relation using a linear logistic model .",
    "the way of interpretation is similar to that of a linear logistic model except that they are in functional form instead of slopes .",
    "more discussions about the interpretation of gams can be easily found in the literature such as @xcite and textbooks about gam as @xcite .",
    "[ [ cardiotocography - data - set ] ] cardiotocography data set + + + + + + + + + + + + + + + + + + + + + + + + +    the cardiotocography data set used here consists of 2126 fetal cardiotocograms ( ctgs ) , where 19 diagnostic features were measured , including fetal heart rate and uterine contraction features . based on the judgements of some expert obstetricians ,",
    "these 2126 subjects are classified as three fetal states : normal , suspect , and pathologic . because we consider only two - class classification problems in this work , we combine two neighbored classes into one class .",
    "thus , they becomes two binary classification problems : ( 1 ) \\{*normal and suspect * } versus \\{*pathologic * } and ( 2 ) \\{*normal * } versus \\{*suspect and pathologic*}. for demonstration , they are treated separately as two different binary classification problems .",
    "besides the contents , a major difference between these two real data examples is that the cardiotocography data set has more observations and less predictors , which will affect the computational efficiency of some algorithms .",
    "the results reported here are based on a smilier re - sampling plan as before . both _",
    "mgcv _ and _ mgcv_step _ algorithms will now converge in a reasonable time , so their results are included . in this example , we omit the plots of the estimated functions and only focus on aucs and related model fitting issues that are useful for practitioners to choose suitable methods for their own studies .",
    "figures [ figure7 ] ( a ) and ( c ) are the box - plots of aucs for the cases of \\{normal and suspect } versus \\{pathologic } and \\{normal } versus \\{suspect and pathologic } , respectively .",
    "figures [ figure7 ] ( b ) and ( d ) show their corresponding computational times of all methods . although _ mgcv _ and _ mgcv_step _ converge in a reasonable time in this example , they are still not as stable as other gam - based counterparts are in terms of variation of aucs .",
    "the _ gamboost _ algorithm takes a much longer time than others in this case .",
    "( note that in our study , _ gamboost _ takes more than eight hours for one run , while the _ backfitting _ and _ backfitting_step _ take only less than five minutes . )",
    "this phenomenon is due to the large sample size of the cardiotocography data set .",
    "this result is consistent with our simulations and the comments reported in the literature . besides _",
    "mgcv _ and _ mgcv_step _ , all other gam - based fitting algorithms perform better than _ glm _ and _ glm_step _ do in terms of their means of aucs and variances . hence",
    ", when the sample size is large and the number of predictive variables is relatively small , the _ backfitting _ and _ backfitting_step _ algorithms are recommended .",
    "figure [ figure9 ] shows the roc curves at the left - upper corner of the unit square , and figure [ figure9 ] ( a ) is \\{normal and suspect } versus \\{pathologic } case , and [ figure9 ] ( b ) is for \\{normal } versus \\{suspect and pathologic } case . from figure [ figure9 ] ( a )",
    ", we can see that the roc curves of _ backfittting _ , _ backfitting_step _ and _ gamboost _ are three methods on the top ; meanwhile , then the two curves of _ glm_-based methods , and the curves of _ mvcv_-based methods are the worst two in this case . figure [ figure9 ] ( b )",
    "shows that roc curves of the \\{normal } versus \\{suspect and pathologic } case . here ,",
    "the performances of all methods are very close .",
    "however , we still find that all _ gam_-based fitting algorithms are significantly better than the two _ glm_-based methods in the low false positive rate range ( i.e. , less than 0.15 in this plot ) .",
    "in fact , in both binary classification cases of this data set , using a general additive logistic model increases the sensitivity in the range of the low false positive rate .",
    "this range is usually important when a high - specificity diagnostic rule is preferred .",
    "hence , this is also an advantage of using the recommended method .",
    "in this paper , the conventional logistic classification function can be further improved in terms of auc .",
    "we show that both numerically and asymptotically , the spline - based generalized additive logistic model will have a larger auc than a conventional linear logistic model does .",
    "we also demonstrate that the classification performance of a conventional linear logistic regression model can be easily improved with a general additive logistic model without sacrificing much of its ease of interpretation using numerical results using some synthesized data sets and two real data sets . several numerical algorithms",
    "are used to fit a gam , and their pros and cons are discussed based on the numerical results in our studies .",
    "we found that the _ gamboost _ method outperforms other methods when with a moderate sample size and variable length . when the sample size becomes large , the _ backfitting _ algorithms are more computationally efficient compared to the cpu times used for fitting a conventional linear logistic model .",
    "it is worth mentioning that the most of the algorithms used here are `` parallel - computing friendly . ''",
    "( please see their manual for further details ) .",
    "that is , these algorithms can be used in some parallel computing environment , such as a pc - cluster or just a multi - core cpu , which is now very popular in desktop or portable computers , with little programing effort .",
    "hence , the proposed method is useful for improving the diagnostic performance without diminishing the ability of the interpretation of the final prediction model , and it is `` cost - effective '' in terms of the computational time and the gain in auc .",
    "moreover , the roc curve of the additive logistic model is higher than that of its linear logistic model counterpart in the whole range of specificity .",
    "it implies that the partial area under roc curve in the high - specificity range is always improved , which is an important and useful feature in many medical diagnosis situations , and it is especially beneficial for applications where the high specificity is a must .",
    "[ [ backfitting - algorithm ] ] backfitting algorithm + + + + + + + + + + + + + + + + + + + + +    the backfitting algorithm employs a concept of conditional expectation ; that is , if gam is correct , then for any @xmath88 , @xmath89=f_k(x_k).$ ] following , the backfitting algorithm is stated below ;    1 .",
    "initial step : @xmath90 for @xmath91 .",
    "2 .   cycle : @xmath92 , + & _ js_j[\\{y_i--_kj_k(x_ik)}_1^n ] , + & -_i=1^n_j(x_ij ) , + where @xmath93 denotes a smoothing spline for a target against the predictor @xmath48 .",
    "3 .   continue step ( ii ) until individual functions do not change .    for a generalized additive logistic model as in ,",
    "hastie and tibshirani proposed a local - scoring algorithm ( see chapter 4 of their book ) , which is a maximum likelihood approach under a linear logistic regression model setup and a newton - raphson iterative type of method .",
    "the local - scoring algorithm has the following steps :    1 .",
    "initial step : @xmath94 for @xmath91 .",
    "cycle : 1 .",
    "construct a new response : @xmath95 where @xmath96.$ ] 2 .",
    "construct weights : @xmath97 .",
    "3 .   estimate new @xmath98 and @xmath99 for any @xmath100 by fitting a weighted additive model to @xmath101 with weights @xmath102 via a backfitting algorithm .",
    "3 .   continue step ( ii ) until the individual functions do not change .",
    "( note that the gam package in r can perform both the backfitting and local scoring algorithms . )    [ [ simultaneous - estimation - of - all - components - with - optimization - in - a - smoothing - parameter - space ] ] simultaneous estimation of all components with optimization in a smoothing parameter space + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    both and can be modeled using the @xmath103-spline method : @xmath104 where @xmath105 is the @xmath79th @xmath103-spline basis function of order @xmath106 for the @xmath107 evenly spaced knots , and @xmath108 is an unknown coefficient of @xmath105 for @xmath13 . to prevent overfitting and have a better prediction , marx and eilers replaced the basic @xmath103-splines with a penalized @xmath103-splines , called @xmath109-splines ( see * ? ? ?",
    "thus , when estimating the unknown @xmath108 by maximizing a likelihood function , the @xmath109-splines will attach a different penalty on the adjacent coefficients of the @xmath103-splines to guarantee their smoothness .",
    "therefore , to fit a gam becomes to maximize the penalized likelihood below : @xmath110 where @xmath111 , for all @xmath100 , are smoothing parameters , @xmath112 is the penalty matrix , and @xmath113 is the log - likelihood of gam . for a generalized additive logistic model as in",
    ", the log - likelihood with a penalized first order differences becomes @xmath114 where @xmath115 .",
    "@xcite provided a stable and efficient approach to estimate all functions , simultaneously .",
    "this feature is available in the _ mgcv _ package in r.    [ [ likelihood - based - boosting - method ] ] likelihood - based boosting method + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    its basic idea of the boosting algorithm is to combine some `` weaker classifiers '' to produce a more powerful classifier that can reduce misclassification error using an iterative adaptive weighting scheme on observations .",
    "@xcite use it as a way of fitting an additive expansion in a set of elementary basis functions by minimizing a loss function , such as a likelihood - based loss function .",
    "they proposed the gamboost procedure to fit gam with this boosting technology via maximizing the log - likelihood . in the statements below",
    ", we also use similar notations as that in the backfitting . the gamboost algorithm for fitting a generalized additive logistic model",
    "is stated as follows :    1 .",
    "definition : @xmath116 , @xmath117}$ ] .",
    "initialize : @xmath118 for @xmath91 , yielding @xmath119 , @xmath120 .",
    "3 .   cycle : @xmath121 , 1 .",
    "\\(a ) estimate all components : for @xmath91 compute @xmath122 where @xmath123 , @xmath124 , + @xmath125 , @xmath126 , and @xmath127 .",
    "\\(b ) selection : set @xmath128 yielding @xmath129 and + get @xmath130 , where @xmath131 denotes the deviance when @xmath132 is the fitted predictor .",
    "\\(c ) update : set @xmath133 .    the r package , gamboost is developed based on this algorithm .",
    "19 natexlab#1#1url # 1`#1`urlprefix                    little , m.  a. , mcsharry , p.  e. , roberts , s.  j. , costello , d.  a. , moroz , i.  m. , et  al . , 2007 .",
    "exploiting nonlinear recurrence and fractal scaling properties for voice disorder detection . biomedical engineering online 6  ( 1 ) , 23 ."
  ],
  "abstract_text": [
    "<S> classification is a common statistical task in many areas . in order to ameliorate the performance of the existing methods , </S>",
    "<S> there are always some new classification procedures proposed . </S>",
    "<S> these procedures , especially those raised in the machine learning and data - mining literature , are usually complicated , and therefore extra effort is required to understand them and the impacts of individual variables in these procedures . however , in some applications , for example , pharmaceutical and medical related research , future developments and/or research plans will rely on the interpretation of the classification rule , such as the role of individual variables in a diagnostic rule / model . hence , in these kinds of research , despite the optimal performance of the complicated models , the model with the balanced ease of interpretability and satisfactory performance is preferred . </S>",
    "<S> the complication of a classification rule might diminish its advantage in performance and become an obstacle to be used in those applications . in this paper , we study how to improve the classification performance , in terms of area under the receiver operating characteristic curve of a conventional logistic model , while retaining its ease of interpretation . </S>",
    "<S> the proposed method increases the sensitivity at the whole range of specificity and hence is especially useful when the performance in the high - specificity range of a receiver operating characteristic curve is of interest . </S>",
    "<S> theoretical justification is presented , and numerical results using both simulated data and two real data sets are reported .    </S>",
    "<S> area under curve ; generalized additive model ; logistic regression model ; roc curve </S>"
  ]
}