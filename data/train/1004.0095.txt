{
  "article_text": [
    "the main motivation for this work comes from two important and challenging problems in contemporary scientific computing :    * the uncertainty quantification for some nonlinear models in mechanics , and more precisely , for contact problems ; * the computation of some high - dimensional functions in molecular dynamics .",
    "concerning the first domain of application which is the main focus of this work , there is now a wide literature on the subject , ranging from specific questions related to the modeling of the noise sources ( in particular of their correlation ) , to dedicated methods for the evaluation of events with very small probabilities ( reliability ) .",
    "the focus of this paper is rather on the development of methods to compute efficiently a _",
    "reduced model _ which rapidly gives the output of interest as a function of the random variable which enters the input parameters , in the context of contact problems in continuum mechanics .",
    "such a model can then be used to evaluate the distribution of the outputs ( for a given distribution of the input parameters ) , or to reduce the variance in a monte carlo computation for example .",
    "many methods have been proposed in the literature to attack this problem@xcite : stochastic collocation methods , galerkin methods , perturbation methods , etc . to be more specific ,",
    "let us assume that the noise on the parameters of the model can be modeled by a possibly large number of random variables @xmath0 , so that the quantity of interest ( say the displacement field ) @xmath1 is a function of @xmath2 variables , where @xmath3 is the dimension of the physical space .",
    "the question is then how to approximate a function on such a high - dimensional space .",
    "the natural idea at the basis of many methods is to look for the solution to this problem as a linear combination of tensor products : @xmath4 where @xmath5 and @xmath6 are bases of vector spaces of dimension @xmath7 and @xmath8 respectively which are fixed a priori , and where @xmath9 are real numbers to be computed .",
    "this method leads to the resolution of a problem in a vector space of dimension @xmath10 which may be very large .",
    "this difficulty becomes all the more pregnant if @xmath11 is really large , so that the solution should be typically approximated as a sum : @xmath12 in this case , @xmath13 will be too large for a classical discretization method .",
    "the method we are studying is a way to circumvent this difficulty .",
    "the second application we have in mind is the computation of the solution to a high - dimensional poisson equation arising in molecular dynamics , called the committor function@xcite .",
    "mathematically , this function gives the probability for a stochastic process to reach a given region ( say @xmath14 ) before another one ( say @xmath15 ) .",
    "using feynman - kac formula , it can be shown that this function satisfies a poisson equation in a weighted sobolev space , with dirichlet boundary conditions ( namely @xmath16 on @xmath17 and @xmath18 on @xmath19 ) .",
    "typically , the stochastic process lives in a high - dimensional space ( @xmath3 is large ) , so that computing this function is a challenge .    in both cases ,",
    "the difficulty comes from the high - dimensionality of the function to approximate .",
    "the principle of the method we are interested in is : ( i ) to rewrite the original problem as a minimization problem : @xmath20 where @xmath21 is a functional defined on some hilbert space @xmath22 and ( ii ) to expand the solution in tensor products of lower - dimensional functions @xmath23 in practice , for each @xmath24 , the functions @xmath25 and @xmath26 are computed as linear combinations of the functions of the bases @xmath27 and @xmath28 so that @xmath29 and @xmath30 where for each @xmath31 , @xmath32 and @xmath33 . in the end , computing the approximation ( [ eq : approx ] ) leads to a problem of dimension @xmath34 which , provided that @xmath35 remains small enough , will hopefully be lower than the dimension of the problem obtained with the classical approach @xmath10 when the size of the bases @xmath7 and @xmath8 are large .",
    "the reduction of dimension is even more significant when we are in the case of equation ( [ devlpt ] ) .",
    "indeed , the approximation ( [ eq : approx ] ) can be adapted in this case in the following form : @xmath36 in this case , the overall dimension of the problem will be @xmath37 instead of @xmath38 in the classical approach .    such a representation of a function as a sum of tensor product of other functions to avoid the curse of dimensionality",
    "have already been introduced in the literature .",
    "one approach consists in using the so - called sparse tensor product representation@xcite .",
    "if the solution @xmath39 we wish to approximate is sufficiently regular , one does not need to use fine discretizations in each direction .",
    "this idea can be used for example in galerkin - like discretizations .",
    "however , this method loses its efficiency in the case when the solution @xmath39 is not regular enough or when the mesh considered is complicated .",
    "we adopt another approach in this article .",
    "the principle of our method is to determine _ sequentially _ the pairs of functions @xmath40 which intervene in the approximation ( [ eq : approx ] ) through the following minimization problem : @xmath41 where @xmath42 and @xmath43 in ( [ eq : min_pb ] ) denote respectively hilbert spaces of functions depending only on the variable @xmath44 or only on the variable @xmath45 .    to rewrite the two problems mentioned above as minimization problems on hilbert spaces",
    ", we penalize the constraints , namely the presence of the obstacle for the contact problem , or the dirichlet boundary conditions for the high - dimensional poisson problem .",
    "the method described above has been introduced by chinesta@xcite for solving high - dimensional fokker - planck equations , by nouy@xcite in the context of uncertainty quantification in mechanics , and is very much related to so - called greedy algorithms@xcite used in nonlinear approximation theory .",
    "the main contributions of this work are the following :    * the convergence of the greedy algorithm ( [ eq : approx])-([eq : min_pb ] ) to the unique solution of ( [ eq : minimisation ] ) is proved , under the key assumptions that @xmath21 is strongly convex and that the gradient of @xmath46 is lispchitz on bounded sets ; * an exponential rate of convergence is obtained in the finite dimensional case ; * an adequate procedure to solve the minimization subproblem   is proposed and tested on an academic test case .",
    "this paper can be seen as an extension of previous works on greedy algorithms @xcite which concentrate on the linear case , namely when @xmath47 , where @xmath48 is the norm of the hilbert space @xmath22 , and @xmath49 a continuous linear form on @xmath22 .",
    "we would like to stress that even if all the results and proofs are provided in the context of tensor products of two functions , our results can be easily generalized to the case of tensor products of more than two functions such as ( [ devlpt ] ) _ except for the results in section  5_. we have chosen not to present the results in this general setting for the sake of clarity .",
    "the paper is organized as follows . in section  2",
    ", we introduce the general setting for the problem we consider and state the main result of this paper , namely the convergence of the greedy algorithm .",
    "section  2 also presents more precisely the two specific examples of application we have in mind .",
    "section  3 is devoted to the proof of the convergence . in section  4 ,",
    "an exponential rate of convergence is proved , in the finite dimensional setting ( i.e. when @xmath42 and @xmath43 are finite dimensional spaces ) .",
    "section  5 shows that , under specific additional assumptions which are typically satisfied in the context of uncertainty quantification , the convergence results also hold if @xmath50 in   is only a local minimum .",
    "finally , section  6 is devoted to a discussion of the numerical implementation , as well as to the presentation of test cases on a toy model .",
    "in this paper , we are interested in the convergence of a greedy algorithm for the minimization of high - dimensional nonlinear convex problems .",
    "we first introduce the general theoretical setting in which we prove the convergence , then describe two prototypical examples to which our analysis can be applied .      throughout this article ,",
    "@xmath11 and @xmath3 denote some positive integers , and @xmath51 and @xmath52 some open sets of @xmath53 and @xmath54 respectively .",
    "let @xmath42 and @xmath43 be hilbert spaces of real - valued functions respectively defined over @xmath51 and @xmath52 ( typically @xmath55 or sobolev spaces ) .",
    "let @xmath56 and @xmath57 be the norms of @xmath42 and @xmath43 .",
    "we introduce the following tensor product for all @xmath58 , @xmath59 which defines a real - valued function on @xmath60 .",
    "we also denote by @xmath61 .",
    "let @xmath22 be a hilbert space of real - valued functions defined on @xmath62 .",
    "the scalar product of @xmath22 is denoted by @xmath63 and the associated norm by @xmath64 .",
    "let @xmath46 be a differentiable real - valued functional defined on @xmath22 . for all @xmath65 ,",
    "we denote by @xmath66 the gradient of @xmath46 at @xmath67 .",
    "we make the following assumptions :     @xmath68 @xmath69 is a dense subset of @xmath22 for @xmath64 ;     @xmath70 for all sequences of @xmath71 bounded in @xmath22 , there exists a subsequence which weakly converges in @xmath22 towards an element of @xmath71 ;     @xmath72 the functional @xmath46 is strongly convex for @xmath64 , i.e. there exists a constant @xmath73 for which @xmath74 the functional @xmath46 is also said to be @xmath75-convex ;     @xmath76 the gradient of @xmath46 is lipschitz on bounded sets : for each bounded subset @xmath77 of @xmath22 , there exists a nonnegative constant @xmath78 such that @xmath79    the unique global minimizer of @xmath46 on @xmath22 is denoted by @xmath39 .",
    "its existence and uniqueness are ensured by the @xmath75-convexity of the functional @xmath46 : @xmath80    we are going to study the following algorithm : the sequence @xmath81 is defined recursively by @xmath82    throughout this article , we will denote for all @xmath83 , @xmath84    our main result is the following theorem , whose proof is given in section  3 .    under the assumptions @xmath68 , @xmath70 , @xmath72 and @xmath76 , the iterations of the algorithm are well - defined , in the sense that ( [ algorithm ] ) has at least one minimizer @xmath85 .",
    "moreover , the sequence @xmath86 strongly converges in @xmath22 towards @xmath39 .    for each @xmath83 ,",
    "the minimizer of ( [ algorithm ] ) is not unique in general . in particular , notice that the function @xmath87 is not convex .",
    "theorem  2.1 could be generalized to the case of tensor products of more than two hilbert spaces .",
    "indeed , let @xmath88 with @xmath89 .",
    "let @xmath90 be @xmath91 positive integers .",
    "let @xmath92 be @xmath91 open subsets of @xmath93 respectively .",
    "we consider @xmath91 hilbert spaces , @xmath94 of real - valued functions defined respectively on @xmath92 .",
    "let @xmath22 be a hilbert space of real - valued functions defined on @xmath95 .",
    "let @xmath46 be a real - valued differentiable functional defined on @xmath22 .",
    "we denote by @xmath96 .",
    "our algorithm can then easily be adapted provided that assumptions @xmath68 , @xmath70 , @xmath72 and @xmath76 are satisfied : @xmath97 are defined recursively by @xmath98    our convergence result also holds in this case . but for the sake of simplicity , we will limit our analysis to the case of only two hilbert spaces .",
    "let @xmath99 be the scalar product defined on @xmath69 as : for all @xmath100 , @xmath101 where @xmath102 and @xmath103 denote the scalar products of @xmath42 and @xmath43 respectively .",
    "let @xmath104 be the cross - norm associated to the scalar product @xmath99 .",
    "the tensor space of @xmath42 and @xmath43 , denoted as @xmath105 is then defined as the closure of @xmath69 for the product norm @xmath104 , @xmath106",
    "let us point out that the hilbert space @xmath22 is not necessarily equal to @xmath105 , the tensor space of @xmath42 and @xmath43 associated to the tensor product ( [ tensor ] ) .",
    "indeed , an example where our analysis can be applied and where @xmath107 is given in section  2.2.2 ( see remark  2.5 . ) .",
    "however , the following inclusion relationship holds : @xmath108 .",
    "if @xmath42 and @xmath43 are discretized in finite - dimensional spaces of dimension @xmath7 and @xmath8 , our algorithm consists in solving several problems in dimension @xmath109 instead of solving one problem of dimension @xmath110 .",
    "thus , we can circumvent the curse of high - dimensionality .      to prove that the general theoretical setting we described in section  2.1 is satisfied on the prototypical problems we present in this section , we need the following lemma , which is well - known in distribution theory@xcite .",
    "let @xmath111 be a distribution such that for any functions @xmath112 , @xmath113    then @xmath114 in @xmath115 .",
    "moreover , for any two sequences of distributions @xmath116 and @xmath117 such that @xmath118 in @xmath119 and @xmath120 in @xmath121 , @xmath122 in @xmath115 .",
    "an example of application of our algorithm is the study of uncertainty propagation on obstacle problems .",
    "we assume that uncertainty can be modeled by a set of @xmath11 random variables @xmath123 , @xmath124 , ... ,",
    "@xmath125 , and that the random vector @xmath126 takes its values in @xmath51 .",
    "we consider also that the physical problem is defined over the domain @xmath52 , which is supposed to be a bounded subset of @xmath54 . if @xmath127 is a hilbert space of functions defined on @xmath52 , we denote by @xmath128 < + \\infty \\right\\},\\ ] ] where @xmath129 denotes the expectation with respect to the probability law of @xmath130 , and @xmath131 denotes the norm of @xmath127 . we endow @xmath132 with the scalar product defined by @xmath133 $ ] .",
    "a formulation of the obstacle problem with uncertainty is the following@xcite .",
    "let @xmath134 and @xmath135 .",
    "a membrane is stretched over the domain @xmath52 and is deflected by some random force having pointwise density @xmath136 for @xmath137 . at the boundary @xmath138 ,",
    "the membrane is fixed and in the interior of @xmath52 the deflection is assumed to be bounded from below by the function @xmath139 ( a random obstacle ) . then the deflection @xmath140 is solution of the following obstacle problem with uncertainty ( see figure  1 ) : @xmath141    an equivalent formulation of this problem is the following .",
    "let us denote @xmath142    solving the obstacle problem  ( [ form1 ] ) consists in solving the minimization problem @xmath143 where @xmath144 $ ] .",
    "one of the main difficulties of this kind of problems is their very high nonlinearity .",
    "many methods have been proposed to approximate the solution of these problems in the case without uncertainty@xcite . among them , penalization methods@xcite are among the most widely used .",
    "they consist in approximating the solution of a given obstacle problem by a sequence of solutions of penalized problems defined on the entire hilbert space .",
    "let @xmath145 be a parameter in @xmath146 .",
    "such a penalized problem associated with problem  ( [ obstacle ] ) may be defined as @xmath147 where @xmath148_+^2 dx\\right]$ ] .    here and below ,",
    "we denote by @xmath149_+$ ] the positive part of the real number @xmath150 , i.e. @xmath151_+ = 0 $ ] if @xmath152 and @xmath151_+ = a$ ] if @xmath153 .",
    "when @xmath145 goes to infinity , the solution @xmath154 of problem  ( [ penalized ] ) strongly converges to the solution @xmath155 of problem  ( [ obstacle ] ) .",
    "the goal of the algorithm we described in the previous section is to calculate the solution @xmath156 of this regularized problem for a given value of the parameter @xmath145 .",
    "let us check that the general theoretical setting we described in section  2.1 can be applied in this case .",
    "let us consider @xmath157 , @xmath158 , @xmath159 and @xmath160 for @xmath65 .",
    "we have @xmath161 .",
    "we endow @xmath162 with the scalar product defined by @xmath163 . in this case",
    ", we have @xmath164 and as a consequence assumption @xmath68 is obviously satisfied .    besides , assumption @xmath70 is satisfied as well .",
    "if @xmath165 is such that @xmath166 is bounded , it is possible to extract a subsequence which weakly converges in @xmath22 towards an element @xmath167 .",
    "besides , there exists a non - negative constant @xmath168 such that for all @xmath169 , @xmath170 \\\\ & = & \\mathbb{e}\\left[|r_n(t)|^2\\right ] \\int_{\\mathcal{x } } |\\nabla_x s_n(x)|^2 dx \\\\ & = & \\|r_n\\|_{v_t}^2 \\|s_n\\|_{v_x}^2 \\\\ & \\leq & c .\\\\\\end{aligned}\\ ] ]    we can then choose @xmath171 such that @xmath172 and @xmath173 .",
    "the sequences @xmath174 and @xmath175 are then bounded in @xmath176 and @xmath162 respectively and we can extract subsequences which weakly converge in @xmath176 and @xmath162 towards @xmath177 and @xmath178 respectively .",
    "as the weak convergences in @xmath176 and @xmath162 imply the convergences in the distributional sense , the sequence @xmath172 necessarily converges towards @xmath179 in @xmath180 by lemma 2.1 .",
    "as the weak convergence in @xmath22 also implies the convergence in the sense of the distributions , we obtain , by uniqueness of the limit , @xmath181 .",
    "hence assumption @xmath70 is satisfied .",
    "the functional @xmath46 is differentiable and @xmath16-convex . indeed , for all @xmath65 , @xmath182_+^2dx\\right]\\right),\\ ] ] is the sum of a @xmath16-convex function ( @xmath183 ) and of a convex function ( @xmath184_+^2dx\\right]$ ] ) .",
    "the functional @xmath46 therefore obeys property ( [ alpha ] ) with @xmath185 .",
    "hence , assumption @xmath72 is satisfied .",
    "let us finally check that the gradient of @xmath46 is lipschitz . for all @xmath186 , @xmath187\\right| \\\\   & &   + \\rho\\left|\\mathbb{e}\\left [ \\int_{\\mathcal{x } } ( [ g(t , x)-v(t , x)]_+ - [ g(t , x ) -w(t , x)]_+)y(t , x)dx \\right]\\right| \\\\ & \\leq & \\|v - w\\|_v\\|y\\|_v \\\\ & & + \\rho \\mathbb{e}\\left [ \\int_{\\mathcal{x } }   \\left|[g(t , x)-v(t , x)]_+ - [ g(t , x ) -w(t , x)]_+\\right| \\left|y(t , x)\\right|dx \\right].\\\\\\end{aligned}\\ ] ]    for @xmath188 , it can easily be seen that @xmath189_+-[b]_+|\\leq |a - b|$ ] .",
    "this implies @xmath190 \\\\ & \\leq & \\|v - w\\|_v\\|y\\|_v\\\\ & & + \\rho \\left(\\mathbb{e}\\left [ \\int_{\\mathcal{x } } |v(t , x)- w(t , x)]|^2 dx\\right]\\right)^{1/2}\\left(\\mathbb{e}\\left [ \\int_{\\mathcal{x } } |y(t , x)]|^2 dx\\right]\\right)^{1/2 } .\\\\\\end{aligned}\\ ] ]    the poincar inegality in @xmath191 implies that there exists a nonnegative constant @xmath192 such that for all @xmath193 , @xmath194|^2 dx\\right]\\right|^{1/2 } \\leq d\\|h\\|_v.\\ ] ]    this yields @xmath195 hence , @xmath196 the functional @xmath46 then obeys property ( [ lipschitz ] ) with a constant @xmath197 independent of the bounded set considered .",
    "thus , our obstacle problem ( [ penalized ] ) falls into the general theoretical setting introduced in section  2.1 .",
    "there exist several variants of the obstacle problem which could be tackled with our algorithm .",
    "we refer to ref .",
    "@xcite or ref .",
    "@xcite for such examples .",
    "our algorithm may also be used to calculate the solution of other problems than obstacle problems .",
    "other examples are high - dimensional nonlinear poisson equations .",
    "a specific application where such high dimensional poisson equations arise is the calculation of the so - called committor function in molecular dynamics@xcite , which is an important quantity to compute reaction rates or to derive some effective dynamics for example .",
    "let @xmath198 .",
    "the committor is the solution to the following problem : @xmath199 where @xmath91 is typically large , @xmath17 and @xmath19 are disjoint smooth open sets of @xmath200 , @xmath201 is a given potential function such that @xmath202 and @xmath203 for @xmath204 , @xmath205 can be interpreted as the probability that the stochastic process  @xmath206 solution to @xmath207 reaches @xmath208 before @xmath209 . here",
    ", @xmath210 denotes a @xmath91-dimensional brownian motion .",
    "let @xmath211 such that @xmath212 . in this example",
    ", we consider the case when @xmath213 is bounded .",
    "let @xmath51 and @xmath52 be open convex bounded subsets of @xmath53 and @xmath54 respectively such that @xmath214 and such that @xmath215 where @xmath216 denotes the lebesgue measure .",
    "we also assume that @xmath217 . in this case",
    ", the initial problem can be rewritten as a minimization problem set on @xmath218 instead of @xmath219 .",
    "indeed , as @xmath220 and @xmath221 is bounded , there exists constants @xmath222 such that for all @xmath223 , @xmath224 . and",
    "thus , we have @xmath225 if and only if @xmath226 , @xmath227 and @xmath228 .",
    "the penalized version of the committor problem then reads @xmath229 where @xmath230 for some @xmath231 .",
    "let us check that the general theoretical setting described in section  2.1 is relevant for this problem .    in this case , we consider @xmath232 , @xmath233 and @xmath234 .",
    "the inner products that are defined over these hilbert spaces are the following . for",
    "all @xmath235 , @xmath236 , @xmath237 , @xmath238 @xmath239 @xmath240    let us point out that in this case , @xmath107 .",
    "indeed , for all @xmath241 , the @xmath22-norm of the tensor product @xmath242 reads @xmath243 which is not a cross - norm , equivalent to the norm induced by @xmath244 and @xmath245 over @xmath105 , which is @xmath246 indeed , let us consider @xmath247 , @xmath248 and @xmath249 for @xmath250 and @xmath251 .",
    "the sequence @xmath252 is bounded , but the sequence @xmath253 is not .",
    "assumption @xmath68 holds true , since @xmath254 is such that @xmath255 and @xmath256 is dense in @xmath257 .",
    "hence , @xmath258 is also dense in @xmath22 .",
    "let us prove that assumption @xmath70 also holds true .",
    "if @xmath165 is such that @xmath166 is bounded , we can extract a subsequence of @xmath259 which weakly converges in @xmath22 towards an element @xmath167 . besides , there exists a nonnegative constant @xmath168 such that for all @xmath169 , @xmath260    we can then choose @xmath171 such that @xmath172 and such that @xmath261 .",
    "the sequences @xmath174 and @xmath175 are then bounded in @xmath262 and @xmath263 and we can extract subsequences which weakly converge in @xmath262 and @xmath263 respectively towards @xmath264 and @xmath265 . as the weak convergences in @xmath262 and @xmath263 imply the convergences in the distributional sense , @xmath172 necessarily converges towards @xmath179 in the distributional sense by lemma 2.1 . as the weak convergence in @xmath22 also implies the convergence in the sense of the distributions , by uniqueness of the limit , @xmath266 .",
    "let us suppose @xmath267 . in that case",
    ", we have @xmath268 and @xmath269 . besides",
    ", we have @xmath270 hence @xmath271 as a consequence @xmath272 is finite and @xmath273 .",
    "hence @xmath274 .",
    "if @xmath275 , then obviously @xmath276 .",
    "hence , assumption @xmath70 holds true .",
    "the functional @xmath46 is differentiable and strongly convex . to prove this",
    ", it is sufficient to prove that there exists a constant @xmath277 such that for all @xmath278 , @xmath279 .",
    "indeed , there exists @xmath280 such that for all @xmath281 , @xmath282 .",
    "thus , there exists a constant @xmath283 such that , for all @xmath278 , @xmath284 to prove that the functional @xmath46 is strongly convex , it is sufficient to have the following inequality : there exists a constant @xmath285 such that for all @xmath286 , @xmath287 as @xmath51 and @xmath52 are bounded open convex subsets of @xmath53 and @xmath54 respectively , @xmath221 is then a bounded open convex subset of @xmath200 such that @xmath288 and inequality ( [ poinc ] ) is a well - known poincare - like inequality .",
    "hence , assumption @xmath72 is satisfied .",
    "let us check that the gradient of @xmath46 is lipschitz . for all @xmath289 , @xmath290",
    "hence @xmath291 the functional @xmath46 therefore obeys property ( [ lipschitz ] ) with a constant @xmath292 independent of the bounded subset considered .",
    "thus , the committor problem falls into the general theoretical setting introduced in section  2.1 .",
    "we begin by proving that the iterations of the algorithm are well - defined . for this , we will need the following lemma .",
    "let @xmath293 be a function in @xmath22 .",
    "then there exists a pair @xmath241 such that @xmath294 if and only if @xmath295 .",
    "let @xmath167 and let us suppose that @xmath296 for all @xmath297 . for a given pair @xmath298 , for all @xmath299 , @xmath300    as a consequence , we have the following by letting @xmath301 go to @xmath18 : @xmath302 .",
    "this holds for all @xmath297 .",
    "hence , for all @xmath303 , we also have @xmath304 , and the density of @xmath69 in @xmath22 , which is ensured by assumption @xmath68 , yields @xmath305 .",
    "conversely , let us assume that @xmath306 . then",
    ", as @xmath46 is @xmath75-convex , @xmath293 is necessarily the global minimizer of @xmath46 and , in particular , we have for all @xmath307 , @xmath308    this concludes the proof .    using this lemma ,",
    "the following result can be proved :    for all @xmath309 , there exists a solution @xmath310 to the minimization problem ( [ algorithm ] ) .",
    "moreover , @xmath311 if and only if @xmath312 , where @xmath313 is defined by ( [ undef ] ) .",
    "firstly , let us prove the existence of a minimizer for problem ( [ algorithm ] ) .",
    "let @xmath314 . for all @xmath315 , @xmath316 .",
    "so @xmath317 exists in @xmath318 .",
    "we then consider a minimizing sequence @xmath319 such that @xmath320    using ( [ alpha ] ) and the fact that @xmath321 , we have @xmath322    then the sequence @xmath323 is bounded in @xmath22 because @xmath324 is convergent and consequently bounded .    as assumption @xmath70",
    "is satisfied , we can then extract a subsequence ( which we still denote @xmath323 ) which weakly converges in @xmath22 towards an element of @xmath71 .",
    "in other words , there exist @xmath325 and @xmath326 such that @xmath323 weakly converges in @xmath22 towards @xmath327 .",
    "furthermore , as the functional @xmath46 is convex and continuous on @xmath22 , @xmath328    hence @xmath329 so that @xmath330 is a minimizer of problem ( [ algorithm ] ) .",
    "let us prove now that @xmath331 if and only if @xmath332 .",
    "if @xmath333 , we have @xmath334 for all @xmath241 such that @xmath335 as @xmath46 is strictly convex .",
    "so a minimizer @xmath179 of problem ( [ algorithm ] ) must necessarily satisfy @xmath336 .",
    "conversely , if @xmath312 , we have @xmath337 and from lemma 3.1 , there exists a pair @xmath241 such that @xmath338 .",
    "hence , @xmath339 and @xmath179 can not be equal to @xmath18 .    for each @xmath83 ,",
    "a minimizer @xmath85 of problem ( [ algorithm ] ) obeys the following euler equation : @xmath340    this result is obtained by considering the first - order conditions of the minimization problem ( [ algorithm ] ) .",
    "this will be useful in the proof of convergence .      in this subsection",
    ", we present the different steps of the proof .",
    "the series @xmath341 and the sequence @xmath342 are convergent .",
    "let us set @xmath343    using ( [ algorithm ] ) , @xmath344 for all @xmath345 , and in particular , by taking @xmath346 , @xmath347 is a non - increasing sequence .",
    "moreover , it is bounded from below . indeed , for all @xmath309 , we have @xmath348 .",
    "thus , it is convergent .",
    "this implies that the sequence defined as @xmath349 is nonnegative , converges to @xmath18 , and satisfies @xmath350 .    besides , the @xmath75-convexity of @xmath46 yields the following inequality :    @xmath351    using the euler equations ( [ el ] ) , @xmath352 and thus , @xmath353 .",
    "hence the result .",
    "the sequence @xmath354 is bounded in @xmath22 .    by @xmath75-convexity of the functional @xmath46",
    ", we have @xmath355 thus @xmath356    therefore , the sequence @xmath357 is bounded in @xmath22 .",
    "the following estimate is essential for the proof of convergence .",
    "there exists a constant @xmath358 such that , for all @xmath83 and all @xmath345 , @xmath359    let @xmath360 be such that for all @xmath83 , @xmath361 .",
    "its existence is ensured by lemma  3.3 .",
    "let @xmath362 be such that for all @xmath83 , @xmath363 .",
    "let @xmath364 be the closed ball of  @xmath22 centered at @xmath18 of radius @xmath365 .",
    "let @xmath49 be the lipschitz constant associated with  @xmath77 in ( [ lipschitz ] ) .    for all @xmath345",
    ", we have @xmath366    then , by the convexity of @xmath46 , we have the following inequality @xmath367 which leads to @xmath368    let @xmath345 such that @xmath369 .",
    "we then have , by using ( [ lipschitz ] ) and ( [ ineg ] ) , @xmath370    the last line has been obtained by taking into account the fact that @xmath371 because of the euler equation ( [ el ] ) .",
    "thus , for all @xmath58 such that @xmath372 , @xmath373    as a consequence , @xmath374    let @xmath297 such that @xmath375 and @xmath376 such that @xmath377 . then , we have @xmath378    and , by setting @xmath379 , we obtain the following inequality for all @xmath241 such that @xmath380 , @xmath381    of course , this inequality also holds true for all @xmath345 such that @xmath382",
    ". therefore , ( [ estimate ] ) holds with @xmath383 .",
    "we now state an elementary result which will be useful in the sequel .",
    "let @xmath384 be a sommable sequence of @xmath146 .",
    "then , there exists a subsequence of @xmath385 which converges to @xmath18 .",
    "if such a subsequence could not be extracted , it would imply @xmath386    thus , the series @xmath387 would diverge . hence the contradiction .",
    "we are now in position to complete the proof of theorem 2.1 .    by lemma 3.2 , the sequence @xmath388 is convergent .",
    "let us denot its limit by @xmath389 .",
    "we want to prove that @xmath390 .",
    "firstly , for all @xmath309 , @xmath391 , since @xmath39 is the global minimizer of the functional @xmath46 . by letting @xmath35 go to infinity ,",
    "we obtain @xmath392    it remains to prove that @xmath393 .",
    "let us first prove that @xmath394 weakly converges to @xmath18 in @xmath22 .",
    "let @xmath360 such that for all @xmath83 , @xmath361 .",
    "its existence is ensured by lemma  3.3 .",
    "let @xmath395 be the closed ball of  @xmath22 centered at @xmath18 of radius @xmath396 .",
    "let @xmath49 be the lipschitz constant associated with  @xmath77 in ( [ lipschitz ] ) . using ( [ lipschitz ] ) and the fact that @xmath397 , we have @xmath398 and as @xmath357 is bounded in @xmath22 by lemma 3.3 , we deduce that @xmath399 is also bounded in @xmath22 .",
    "we can then extract a subsequence of @xmath399 which weakly converges in @xmath22 towards @xmath167 . by using proposition 3.3 and by letting @xmath35 go to infinity in ( [ estimate ] )",
    ", we deduce that @xmath400 for all @xmath345 .",
    "then , as @xmath69 is dense in @xmath22 with assumption @xmath68 , necessarily @xmath275 .",
    "thus the sequence @xmath399 weakly converges to @xmath18 in @xmath22 .",
    "as @xmath46 is convex , we have the following inequality for all @xmath83 , @xmath401    let us prove that we can extract a subsequence of @xmath402 which converges to @xmath18 .",
    "let @xmath309 . by using proposition 3.3 , @xmath403    as the sequence @xmath404 converges by lemma 3.2",
    ", we have @xmath405 .",
    "furthermore , we can also extract a subsequence from @xmath406 which converges to @xmath18 ( see lemma 3.4 ) .",
    "we can then extract a subsequence from @xmath407 which converges to @xmath18 .    by letting @xmath35 go to infinity in ( [ fin ] ) with this subsequence",
    ", we obtain that @xmath393 .",
    "we have thus proved that @xmath408 .",
    "besides , as the functional @xmath46 is @xmath75-convex , ( [ alpha ] ) yields the following inequality , @xmath409 which necessarily implies that @xmath410 converges to @xmath18 when @xmath35 goes to infinity , which proves that @xmath357 strongly converges towards @xmath39 in @xmath22 .",
    "in the case when @xmath42 and @xmath43 are finite - dimensional , we are able to prove that the algorithm converges exponentially fast .    we assume that @xmath42 and @xmath43 are finite - dimensional and that assumptions @xmath68 , @xmath70 , @xmath72 and @xmath76 are fulfilled .",
    "then there exist two constants @xmath411 and @xmath412 such that for all @xmath83 , @xmath413 and @xmath414[1 ]    let us denote by @xmath415 and @xmath416",
    ". then we can consider that @xmath417 , @xmath418 and @xmath419 ( which is implied by @xmath68 ) .    as the spaces are finite - dimensional , all the norms are equivalent , and we can consider without loss of generality that @xmath244 , @xmath245 and @xmath64 are equal to the frobenius norms of @xmath420 , @xmath421 and @xmath422 defined by : @xmath423 \\|s\\|_m^2 & = & s^t s,\\\\ [ 5pt ] \\|u\\|_{lm}^2 & = &   \\mbox{tr}(u^t u).\\\\   \\end{array}\\ ] ] notice that for all @xmath424 , @xmath425    let @xmath27 and @xmath28 be orthonormal bases of @xmath42 and @xmath43 respectively . then , @xmath426 forms an orthonormal basis of @xmath22 .",
    "our goal is to prove that there exists a constant @xmath412 such that for all @xmath83 , @xmath427    let @xmath83 .",
    "let us notice that @xmath428    as for all @xmath83 , @xmath429 , it is then sufficient with ( [ ratebeg ] ) to prove that there exists @xmath430 such that @xmath431 to have ( [ finalin ] ) with @xmath432",
    ".    let us notice that ( [ alpha ] ) and ( [ el ] ) yield @xmath433    besides , let @xmath434 such that for all @xmath83 , @xmath361 .",
    "its existence is ensured by lemma  3.3 .",
    "let @xmath435 be the closed ball of @xmath22 centered at @xmath18 of radius @xmath436 .",
    "let @xmath49 be the lipschitz constant of the gradient of @xmath46 associated to @xmath77 in ( [ lipschitz ] ) .    using ( [ lipschitz ] ) and the fact that @xmath397 , we also have , @xmath437    with ( [ init ] ) and ( [ un2 ] ) , it is sufficient to prove that there exists a constant @xmath438 such that for all @xmath83 , @xmath439 in order to have ( [ suite ] ) and hence ( [ finalin ] ) .    indeed ,",
    "if ( [ kappa ] ) holds , we then have , using ( [ init ] ) , ( [ kappa ] ) and ( [ un2 ] ) , @xmath440    as the @xmath75-convexity of @xmath46 and the fact that @xmath397 yields @xmath441 inequalities ( [ un1 ] ) and ( [ un2 ] ) then imply that @xmath442 and then ( [ suite ] ) holds with @xmath443 .    let us prove inequality ( [ kappa ] ) . from proposition  3.3 , estimate ( [ estimate ] ) holds true . as @xmath426 forms an orthonormal basis of @xmath22 , we obtain , using ( [ estimate ] ) , @xmath444    we then have the following estimate : @xmath445    the @xmath75-convexity of @xmath46 and estimate ( [ normeprime ] ) lead to @xmath446 besides , by using the fact that @xmath447 , we obtain @xmath448 which is ( [ kappa ] ) with @xmath449 for @xmath17 large enough .    hence the result .",
    "this result can be generalized to the case of tensor products of more than two hilbert spaces . indeed , with the notation of remark  2.2 , and if we denote @xmath450 , estimate ( [ normeprime ] ) becomes @xmath451 and the proof still holds .",
    "we are able to extend the results of theorem 2.1 and theorem 4.1 in the case when @xmath50 in ( [ algorithm ] ) is only defined as a * local minimum which ensures the decrease of the energy , more precisely , when @xmath85 is defined recursively as : @xmath452 such that @xmath453 where @xmath313 is defined as in ( [ undef ] ) . *    to extend these results",
    ", we will need an additional assumption ( which is naturally fulfilled in the finite dimensional case ) , see remark 5.2 below :     @xmath454 there exist @xmath455 such that @xmath456    let us suppose that the assumptions @xmath68 , @xmath70 , @xmath72 , @xmath76 and @xmath454 hold true .",
    "then , the iterations of the algorithm described above are well - defined in the sense that ( [ localalgo ] ) has at least one local minimizer @xmath85 which satisfies ( [ decrease ] ) .",
    "moreover , the sequence @xmath457 strongly converges in @xmath22 towards @xmath39 .",
    "the proof is similar to the proof of theorem  2.1 given in section  3 except for proposition  3.3 which gives estimate ( [ estimate ] ) : @xmath458    this estimate is no longer true , but we have a similar result which will be enough to complete the proof .",
    "indeed , let us prove that there exists a constant @xmath459 such that @xmath460    let @xmath360 such that for all @xmath83 , @xmath361 .",
    "its existence is ensured by lemma  3.3 .",
    "let @xmath461 be the closed ball of @xmath22 centered at @xmath18 and of radius @xmath462 .",
    "let @xmath49 be the lipschitz constant associated to @xmath77 in ( [ lipschitz ] ) .",
    "let @xmath345 and @xmath314 . as @xmath50 is a local minimum of @xmath463",
    ", there exists a constant @xmath464 such that for all @xmath465 , we have @xmath466    moreover , by convexity of the functional @xmath46 , we have the following inequality @xmath467    we deduce from ( [ locmin ] ) , ( [ convex ] ) and property ( [ lipschitz ] ) that , for all @xmath301 small enough",
    "so that @xmath468 , @xmath469    as @xmath50 is a local minimum of the functional @xmath470 , @xmath50 still obeys the euler equation ( [ el ] ) and thus @xmath471 .",
    "finally , we have @xmath472    dividing this expression by @xmath473 and letting @xmath301 go to zero , we obtain @xmath474    which leads to @xmath475    all this holds without the additional assumption ( [ svd ] ) for all @xmath241 . to derive estimate ( [ estimate2 ] ) , we use the additional assumption we made on @xmath64 : @xmath476    we can then choose @xmath477 and @xmath478 such that @xmath172 and @xmath479 and such that @xmath480 and @xmath481 .",
    "thus , @xmath482    and in the end , we obtain estimate ( [ estimate2 ] ) with @xmath483 . with this result , it is then possible to conclude as in the proof of theorem  2.1 .",
    "problem ( [ penalized ] ) falls into the scope of theorem  5.1 . on the other hand , this is not the case for problem ( [ poisson ] ) , for which property ( [ svd ] ) is not true ( see remark  2.5 ) .",
    "we were not able to prove a similar result in the case when @xmath64 does not satisfy property ( [ svd ] ) .    here",
    "are two typical examples for which assumption @xmath454 holds :    * in the case when @xmath164 , property ( [ svd ] ) holds with @xmath484 .",
    "this holds in uncertainty propagation problems where @xmath485 with @xmath127 an hilbert space of real - valued functions defined on @xmath52 . denoting by @xmath158 and @xmath486 , then @xmath487 . * in other cases , to find an approximation of the global minimum of the energy @xmath46 , the hilbert spaces @xmath42 and @xmath43 are usually discretized in finite - dimensional spaces . the problem can then be rewritten as a problem over @xmath417 , @xmath418 with @xmath488 , and then @xmath22 is naturally defined as the hilbert space @xmath419 .",
    "then , assumptions @xmath68 , @xmath70 , @xmath72 and @xmath76 are automatically satisfied on the discretized spaces .",
    "as all the norms are equivalent in finite dimension , the norms on @xmath420 , @xmath421 and @xmath422 induced by the norms defined over the original hilbert spaces @xmath42 , @xmath43 and @xmath22 are equivalent to the frobenius norms , defined by ( [ normkl ] ) .",
    "these norms satisfy property ( [ svd ] ) since for all @xmath424 , @xmath489 .",
    "hence , the norms induced by the norms defined on the original hilbert spaces automatically satisfy property ( [ svd ] ) even if the property is not satisfied in the continuous spaces .    as in section  4",
    ", we can prove that the algorithm defined by ( [ localalgo ] ) and ( [ decrease ] ) converges exponentially fast in finite dimension .",
    "let us consider the algorithm defined by ( [ localalgo ] ) and ( [ decrease ] ) .",
    "let @xmath488 .",
    "let @xmath490 , @xmath418 and @xmath419 . then there exist two constants @xmath411 and @xmath412 such that for all @xmath83 , @xmath413 and @xmath414    as the spaces are finite - dimensional , assumptions @xmath68 , @xmath70 , @xmath72 , @xmath76 and @xmath454 are automatically fulfilled ( see remark  5.2 ) and estimate ( [ estimate2 ] ) holds true .",
    "the proof is similar to the proof of theorem  4.1 . indeed , ( [ ratebeg ] ) , ( [ init ] ) , ( [ un2 ] ) and ( [ un1 ] ) still hold .",
    "then it is sufficient to prove an inequality similar to ( [ kappa ] ) to prove theorem  5.2 .",
    "however , as ( [ estimate2 ] ) holds instead of ( [ estimate ] ) , inequality ( [ normeprime ] ) is replaced by : @xmath491 and consequently , an inequality similar to ( [ kappa ] ) must be obtained in another way .",
    "let @xmath360 such that for all @xmath83 , @xmath361 .",
    "its existence is ensured by lemma  3.3 .",
    "let @xmath395 be the closed ball of  @xmath22 centered at @xmath18 of radius @xmath396 .",
    "let @xmath49 be the lipschitz constant associated with  @xmath77 in ( [ lipschitz ] ) .",
    "on the one hand , using the convexity of @xmath46 , ( [ lipschitz ] ) and the fact that @xmath397 , we have @xmath492    on the other hand , ( [ un1 ] ) , the convexity of @xmath46 , ( [ el ] ) and ( [ normeprime2 ] ) yield @xmath493    then , using ( [ sup ] ) , we have ( [ kappa ] ) with @xmath494 .",
    "we can conclude as in the proof of theorem  4.1 .",
    "the results given in this section may not stand when we consider more than two hilbert spaces .",
    "indeed , the scheme of the proof of theorem  5.1 can not be easily adapted and we do not necessarily have an estimate similar to ( [ estimate2 ] ) .",
    "in this section , we describe how we implemented the algorithm introduced in section  2 for the resolution of problem ( [ penalized ] ) in a very simple setting , namely a one - dimensional membrane problem with uncertainty .",
    "we present the numerical results we obtained .",
    "additional investigations to demonstrate the applicability and the efficiency of the procedure on high - dimensionnal problems are still required .",
    "we however refer to nouy@xcite for illustrations of the interest of the method for problems in high dimensions .",
    "let us recall problem ( [ penalized ] ) .",
    "let @xmath135 and @xmath134 .",
    "let us assume that the random variable @xmath130 has a probability density @xmath495 for @xmath496 .",
    "in other words , @xmath497 where @xmath498 is a measurable subset of @xmath51 .    for a given value of the penalization parameter @xmath499 , we wish to calculate an approximation of the minimizer of    @xmath500    where @xmath501_+^2 dx \\right].\\ ] ]    in other words , @xmath502_+^2 p(t ) \\,dx\\,dt.\\\\\\end{aligned}\\ ] ]    in this case , our algorithm can be rewritten in the following form . set @xmath503 and @xmath504 and define recursively @xmath505 as @xmath506 with @xmath507_+^2p(t)\\,dx\\,dt,\\\\\\end{aligned}\\ ] ] where @xmath508    indeed , @xmath509_+^2p(t)\\,dx\\,dt + \\mathcal{e}_n(r\\otimes s),\\ ] ] where @xmath313 is defined as in ( [ undef ] ) .",
    "in fact , from theorem 5.1 , it is sufficient for @xmath50 to be a _ local minimum of @xmath510 such that : @xmath511_+^2 p(t)\\,dx\\,dt,\\ ] ] which ensures ( [ decrease ] ) . _",
    "we write the algorithm in the discrete case , and , for clarity , we restrict ourselves to the case of two open intervals @xmath51 and @xmath52 of @xmath318 .",
    "more precisely , @xmath512\\underline{t } , \\overline{t}[$ ] and @xmath513\\underline{x } , \\overline{x}[$ ] , with @xmath514 , such that @xmath515 and @xmath516 .",
    "let @xmath488 , which will denote respectively the number of degrees of freedom in the discretized spaces of @xmath42 and @xmath43 .",
    "let us introduce a subdivision @xmath517 such that @xmath518 and a subdivision @xmath519 such that @xmath520 .",
    "let @xmath521 and @xmath522 be functions such that @xmath523 and @xmath524 and let us consider @xmath525 and @xmath526 .",
    "for example , @xmath527 or @xmath528 finite elements satisfy these properties for all @xmath198 .",
    "our goal is to find an approximation of the function @xmath39 under the following form @xmath529 where @xmath530 .",
    "let @xmath531 be the symmetric positive definite matrix which corresponds to the discretization of the one - dimensional operator @xmath532 in @xmath43 , in other words , for all @xmath533 , @xmath534    let also @xmath535 and @xmath536 be the symmetric positive definite matrices defined as @xmath537 and @xmath538    with discretization ( [ eq : discrete ] ) , the term @xmath539 is then equal to @xmath540    similarly , if we denote by @xmath541 the matrix defined as , for all @xmath542 and @xmath543 , @xmath544 the term @xmath545 is approximated by @xmath546    the approximation of the term @xmath547_+^2 p(t ) \\,dx\\,dt$ ] is more subtle . indeed , let us approximate the function @xmath548 in the discretized space @xmath549 by @xmath550 given relationships ( [ eq : phii ] ) and ( [ eq : psij ] ) , a natural way to define @xmath551 is the following @xmath552    it then holds @xmath553_+^2 p(t ) \\,dx\\,dt",
    "\\approx    \\frac{\\rho}{2 } \\int_{\\mathcal{x}\\times \\mathcal{t } } \\left [ \\sum_{i=1}^l \\sum_{j=1}^m ( g^{ij } - u^{ij } ) \\phi_i(t)\\psi_j(x ) \\right]_+^2p(t)\\,dx\\,dt.\\ ] ]    let @xmath293 be the function defined as @xmath554_+$ ] . from assumptions ( [ eq : phii ] ) and ( [ eq : psij ] ) ,",
    "it holds @xmath555_+ , \\ ; \\forall 1\\leq i \\leq l,\\ ; 1\\leq j \\leq m.\\ ] ] thus , we perform a supplementary approximation , that is to approximate the function @xmath293 itself as @xmath556_+ \\phi_i(t)\\psi_j(x).\\\\\\end{aligned}\\ ] ]    finally , it holds @xmath557_+^2 p(t ) \\,dx\\,dt & \\approx & \\frac{\\rho}{2 } \\int_{\\mathcal{x}\\times \\mathcal{t } } \\left(\\sum_{i=1}^l \\sum_{j=1}^m \\left[g^{ij } - u^{ij } \\right]_+\\phi_i(t)\\psi_j(x)\\right)^2 p(t)\\,dx\\,dt,\\\\ & = &   \\mbox{tr}(\\phi [ g - u]_+ \\psi [ g - u]_+^t).\\\\\\end{aligned}\\ ] ] we also made the following mass lumping approximation , that is to consider that @xmath558 and @xmath559 .",
    "then , the discretized problem ( [ penalized ] ) can be rewritten as @xmath560_+:[g - v]_+,\\\\ \\end{array}\\ ] ] where for @xmath561 , @xmath562    this problem is equivalent to : @xmath563_+.\\ ] ]    for each function @xmath564 and @xmath565 , we denote by @xmath566 and @xmath567 , their coordinates in the bases @xmath568 and @xmath28 , which are given by @xmath569 and @xmath570 our algorithm can then be rewritten as :    choose a threshold @xmath571 and set @xmath572 , @xmath573 . at iteration",
    "@xmath574 :    1 .",
    "find @xmath575 and @xmath576 two vectors respectively in @xmath420 and @xmath421 such that : @xmath577 with @xmath578_+ : [ g_{n-1 } - rs^t]_+ . \\\\\\end{aligned}\\ ] ] 2 .",
    "set @xmath579 and @xmath580 .",
    "3 .   if @xmath581_+\\| \\geq \\varepsilon$ ] , proceed to iteration @xmath582 .",
    "otherwise , stop .",
    "the remaining question is : how can we compute @xmath583 at step 1 ?",
    "this critical step is described in the following section .",
    "let us first describe a method which has been proposed by nouy@xcite and chinesta@xcite , that is the fixed - point procedure and which we use in our final numerical implementation ( see section  6.2.2 ) .",
    "we present this algorithm in a particular case .",
    "let us consider @xmath417 , @xmath418 and @xmath419 endowed with the frobenius norms defined by ( [ normkl ] ) .",
    "we fix a given matrix @xmath584 .",
    "let us define the energy functional as @xmath585 for @xmath586 .",
    "in this particuler case , applying the greedy algorithm described above consists in computing the singular value decomposition of the matrix @xmath587 .    in this particular case , the greedy algorithm can be rewritten in the following form .",
    "choose a threshold @xmath588 and set @xmath589 .",
    "at iteration @xmath574 ,    1 .",
    "find two vectors @xmath590 and @xmath591 respectively in @xmath420 and @xmath421 such that @xmath592 2 .",
    "set @xmath593 .",
    "3 .   if @xmath594 , proceed to iteration @xmath582 .",
    "otherwise , stop .    the euler equation associated to this problem",
    "can be rewritten as @xmath595 \\|r_n\\|_{v_t}^2 s_n & = & ( m_{n-1})^t r_n.\\\\ \\end{array } \\right .\\ ] ]    the method which is generally used@xcite to solve these euler equation is a fixed - point algorithm , which simply reads ( for a fixed @xmath35 ) : at iteration @xmath596 , compute two vectors @xmath597 such that @xmath598 \\|r_n^{(q+1)}\\|_{v_t}^2 s_n^{(q+1 ) } & = & ( m_{n-1})^t r_n^{(q+1)}.\\\\ \\end{array } \\right .\\ ] ]    one can check@xcite that this procedure is similar to the power method to compute the largest eigenvalue ( and associated eigenvector ) of the matrix @xmath599 .",
    "one could think of transposing this fixed - point procedure to the case of the obstacle problem we consider in this article . in our case ,",
    "the euler equation @xmath600_+^t r_n , \\\\[5pt ] ( ds_n : s_n ) r_n & = & f_{n-1 } s_n + \\rho [ g_{n-1 } - r_n s_n^t]_+ s_n .\\\\",
    "\\end{array } \\right .\\ ] ] could be solved _ a priori _ with a fixed point algorithm , which , at iteration @xmath91 , might be written as @xmath601_+^t r_n^{(q ) } , \\\\[5pt ] ( ds_n^{(q+1)}:s_n^{(q+1 ) } ) r_n^{(q+1 ) } & = & f_{n-1 } s_n^{(q+1 ) } + \\rho\\left[g_{n-1 } - r_n^{(q ) } \\left(s_n^{(q+1)}\\right)^t\\right]_+ s_n^{(q+1)}. \\\\ \\end{array } \\right .\\ ] ]    unfortunately , we have not been able to make this fully - explicit fixed point algorithm converge for large values of the parameter @xmath145 .",
    "we therefore have decided to resort to a minimization procedure .",
    "the approach we adopt then is the following .",
    "we choose an initial pair @xmath602 and then perform a quasi - newton algorithm to find a local minimum of the function @xmath603_+ : \\left[g_{n-1 } - rs^t\\right]_+.\\ ] ]    the main difficulty is to find a proper initial pair @xmath604 such that @xmath605_+ : \\left[g_{n-1 } - r_n^{(0)}s_n^{(0)t}\\right]_+\\ ] ] @xmath606_+ : [ g_{n-1}]_+,\\ ] ] to ensure that the energy decreases ( see ( [ decrease ] ) ) .",
    "let us describe our approach in the continuous setting with the notation used in section  4 .",
    "it consists in finding a pair @xmath607 such that @xmath608    we notice that for @xmath345 , and @xmath609 , we have @xmath610 for @xmath611 small enough .",
    "the idea is then to find a pair @xmath241 such that @xmath612 , so that there exists @xmath613 small enough for which @xmath614 .",
    "then , @xmath615 is a good initial guess .",
    "let us first consider the pair @xmath616 such that @xmath617    in other words , we consider @xmath618 the first term of the singular value decomposition of @xmath619 in @xmath22 .",
    "the euler equations then imply @xmath620    and therefore , @xmath621    by taking @xmath622 , there exists then @xmath609 small enough such that @xmath623    in the discrete case associated to problem ( [ penalized ] ) , @xmath624 is obtained by taking the first term of the singular value decomposition of the matrix @xmath625_+$ ] .",
    "this can be done with a fixed point procedure similar to ( [ fixedpoint ] ) .",
    "once we have this initial guess @xmath626 , we perform a quasi - newton algorithm to minimize the energy .",
    "the computations are done with the software scilab@xcite and the quasi - newton procedure is performed via the _ optim procedure of scilab .",
    "_    let us point out that this procedure is intrusive in general .      in this section",
    ", we present the results we obtained with this algorithm on the following membrane problem .",
    "we suppose @xmath627 .",
    "we consider a random variable @xmath130 following a uniform law of probability on the interval @xmath628 .",
    "we wish to study problem ( [ obstacle ] ) with the following values for @xmath629 and @xmath630 , @xmath631_+ + ( t-1)[\\sin(3\\pi x)]_-.\\ ] ]    the negative part of @xmath632 , i.e. @xmath151_- = 0 $ ] if @xmath153 , and @xmath151_- = -a$ ] if @xmath152 , is denoted by @xmath151_-$ ] .",
    "the above problem models a rope attached at @xmath633 and @xmath634 subjected to gravity and resting upon obstacles whose altitudes are given by @xmath635 .",
    "the quantity @xmath1 then represents the altitude of the rope at abscissa @xmath45 when @xmath636 .",
    "this problem is approximated by problem ( [ penalized ] ) with parameter @xmath637 .",
    "the problem is discretized with a regular mesh and @xmath638 finite elements in each direction .",
    "discretization parameters are chosen as @xmath639 .",
    "figure 2 represents the altitude of the obstacles given by @xmath635 for @xmath640 ^ 2 $ ] .",
    "the algorithm described in the previous sections is then applied with the following stopping criterion : @xmath641_+\\|_v <",
    "10^{-4}$ ] with @xmath642 for @xmath643 .",
    "figure 3 represents the evolution of @xmath644 and of @xmath645_+\\|_v)$ ]",
    ".    [ rate ] [ ] [ ] [ 0.6]number of iterations [ ] [ ] [ 0.7]@xmath646 [ ] [ ] [ 0.6]number of iterations [ ] [ ] [ 0.7]@xmath647_+\\|_v)$ ]    we can see that our algorithm captures very quickly the main modes of the solution and that both the energy and the @xmath22-norm of the residue @xmath641_+\\|_v$ ] converges exponentially fast , as predicted by theorem 5.1 .",
    "figure 4 represents the results obtained for the solution @xmath1 .",
    "figure 5 and 6 represents @xmath1 and @xmath635 for some special values of @xmath130 .",
    "[ fig3 ]    [ ] [ ] [ 0.4]@xmath648 [ ] [ ] [ 0.4]@xmath649    [ ] [ ] [ 0.4]@xmath648 [ ] [ ] [ 0.4]@xmath649    as we can observe , the solution does not exactly satisfies the constraint @xmath650 .",
    "this is due to the fact that we approximate a solution @xmath651 of the penalized problem ( [ penalized ] ) for @xmath637 .",
    "this is the main drawback of our method : we do not approximate directly the solution of the initial obstacle problem but the solution of a close regularized problem . indeed , if we try to further increase the parameter @xmath145 , we face the main drawback of penalization methods , that is the ill - conditioning of the resulting matrices .",
    "in this article , we presented a greedy algorithm based on variable decomposition aiming at computing the global minimum of a strongly convex energy functional .",
    "we proved that , provided that the gradient of the energy is lipschitz on bounded sets , and that the hilbert spaces considered satisfy assumptions @xmath68 and @xmath70 , then the approximation given by our algorithm strongly converges towards the desired result .",
    "one of the main advantage of the algorithm is that it can deal with highly nonlinear problems .",
    "we also proved that in finite dimension , this algorithm converges exponentially fast .",
    "we applied this algorithm in the context of uncertainty quantification on obstacle problems . in this frame",
    ", we considered regularizations of this kind of problems by penalization methods .",
    "indeed , the obstacle problem can be approximated by a global minimization problem defined on the entire hilbert space of some strongly convex energy functional where the constraints of the initial problem are replaced by penalization terms in the expression of the functional .",
    "our algorithm gives a good approximation of the solutions of the regularized problem .",
    "however , the problem of ill - conditioned matrices , which is inherent to penalization methods , limits the accuracy with which we can approach the solution of the initial obstacle problem .",
    "one way to circumvent this problem is to use augmented lagrangian methods ( see ref .",
    "@xcite ) instead of penalization methods . indeed ,",
    "the former algorithms converge towards the true solution of the initial obstacle problems .",
    "the adaptation of our algorithm to such methods is work in progress .",
    "another extension of our work would be to consider other problems than obstacle problems . in ref .",
    "@xcite , a similar algorithm based on proper generalized decomposition is used to study uncertainty quantification upon a burger type equation .",
    "we believe that it could be possible to extend our proof of convergence in the case of such hyperbolic systems .",
    "we would like to thank the michelin company for financial support .",
    "a. ammar , b. mokdad , f. chinesta and r. keunings , a new family of solvers for some classes of multidimensional partial differential equations encountered in kinetic theory modeling of complex fluids , _ journal of non - newtonian fluid mechanics _ * 139 * ( 2002 ) 153176 .",
    "c. le bris , t. lelivre and y. maday , results and questions on a nonlinear approximation approach for solving high - dimensional partial differential equations , _ constructive approximation _",
    "* 30 * ( 2009 ) 621651 .",
    "a. nouy , recent developments in spectral stochastic methods for the numerical solution of stochastic partial differential equations , _ archives of computational methods in engineering _ * 16 * ( 2009 ) 251285 ."
  ],
  "abstract_text": [
    "<S> in this article , we present a greedy algorithm based on a tensor product decomposition , whose aim is to compute the global minimum of a strongly convex energy functional . we prove the convergence of our method provided that the gradient of the energy is lipschitz on bounded sets . </S>",
    "<S> the main interest of this method is that it can be used for high - dimensional nonlinear convex problems . </S>",
    "<S> we illustrate this method on a prototypical example for uncertainty propagation on the obstacle problem .    </S>",
    "<S> universit paris est , cole des ponts - paristech , cermics , + 6 & 8 avenue blaise pascal + 77455 marne - la - valle cedex 2 + france + \\{cances , ehrlachv , lelievre}@cermics.enpc.fr +    keywords : greedy algorithm ; high dimension ; obstacle problem ; uncertainty quantification . </S>"
  ]
}