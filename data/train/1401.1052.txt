{
  "article_text": [
    "the method of science calls for the understanding of selected aspects of behaviour of a considered system , given available measurements and other relevant information .",
    "the measurements may be of the variable @xmath1 ( @xmath2 ) while the parameters that define the selected system behaviour may be @xmath3 , ( @xmath4 ) or the selected system behaviour can itself be an unknown and sought function @xmath5 of the known input variable vector @xmath6 ( @xmath7 ) , so that @xmath8 . in either case , we relate the measurements with the model of the system behaviour as in the equation @xmath9 or @xmath10 where the function @xmath11 is unknown .",
    "alternatively , in either case the scientist aims to solve an inverse problem in which the operator @xmath12 , when operated upon the data , yields the unknown(s ) .",
    "one problem that then immediately arises is the learning of the unknown function @xmath11 . indeed @xmath11 is often unknown though such is not the norm  for example in applications in which the data is generated by a known projection of the model function onto the space @xmath13 of the measurables , @xmath11",
    "is identified as this known projection .",
    "thus , image inversion is an example of an inverse problem in which the data is a known function of the unknown model function or model parameter vector [ among others]jugnon , qui2008,bereto , radon_xrays , bookblind . on the other hand ,",
    "there can arise a plethora of other situations in science in which a functional relationship between the measurable @xmath1 and unknown @xmath14 ( or @xmath3 ) is appreciated but the exact form of this functional relationship is not known [ to cite a few]parker , tarantola_siam , andrew , andrewreview , draper , tidal , gouveia .",
    "this situation allows for a ( personal ) classification of inverse problems such that    * in inverse problems of type  i , @xmath11 is known where @xmath9 or @xmath15 , * in inverse problems of type  ii , @xmath11 is unknown .",
    "while inverse problems of type  i can be rendered difficult owing to these being ill - posed and/or ill - conditioned as well as in the quantification of the uncertainties in the estimation of the unknown(s ) , inverse problems of type  ii appear to be entirely intractable in the current formulation of @xmath9 ( or @xmath15 ) , where the aim is the learning of the unknown @xmath3 ( or @xmath14 ) , given the data .",
    "in fact , conventionally , this very general scientific problem would not even be treated as an inverse problem but rather as a modelling exercise specific to the relevant scientific discipline . from the point of view of inverse problems ,",
    "these entail another layer of learning , namely , the learning of @xmath11 from the data  to be precise , from _ training data _",
    "training_geo , caers , astro . here by training data we mean data that comprises values of @xmath1 at chosen values of @xmath16 ( or at chosen @xmath3 ) .",
    "these chosen ( and therefore known ) values of @xmath16 ( or @xmath3 ) are referred to as the design points , so that values of @xmath1 generated for the whole design set comprise the training data.having trained the model for @xmath11 using such training data , we then implement this learnt model on the available measurements  or test data  to learn that value of @xmath3 ( or @xmath16 ) at which the measurements are realised .",
    "it is in principle possible to generate a training data set from surveys ( as in selected social science applications ) or generate synthetic training data sets using simulation models of the system simgeo , astrosim , atmos .",
    "however , often the physics of the situation is such that @xmath11 is rendered characteristic of the system at hand ( as in complex physical and biological systems ) .",
    "consequently , a simulation model of the considered system is only an approximation of the true underlying physics and therefore risky in general ; after all , the basic motivation behind the learning of the unknown @xmath16 ( or @xmath3 ) is to learn the underlying system physics , and pivoting such learning on a simulation model that is of unquantifiable crudeness , may not be useful .",
    "thus , in such cases , we need to develop an alternative way of learning @xmath11 or if possible , learn the unknown @xmath16 ( or @xmath3 ) given the available measurements without needing to know @xmath11 .",
    "it may appear that such is possible in the bayesian approach in which we only need to write the posterior probability density of the unknown @xmath16 ( or @xmath3 ) , given the data .",
    "an added advantage of using the bayesian framework is that extra information is brought into the model via the priors , thus reducing the quantity of data required to achieve inference of a given quality .",
    "importantly , in this approach one can readily achieve estimation of uncertainties in the relevant parameters , as distinguished from point estimates of the same . in this paper",
    "we present the bayesian learning of the unknown model parameters given the measurements but no training data , as no training data set is available .",
    "the presented methodology is inspired by state space modelling techniques and is elucidated using an application to astronomical data .",
    "the advantages of the bayesian framework notwithstanding , in systems in which training data is unavailable , fact remains that @xmath11 can not be learnt .",
    "this implies that if learning of the unknown @xmath16 ( or @xmath3 ) is attempted by modelling @xmath11 as a realisation from a stochastic process ( such as a gaussian process ( @xmath17 ) or ito process or t - process , etc . ) , then the correlation structure that underlies this process is not known .",
    "however , in this learning approach , the posterior probability of the unknowns given the data invokes such a correlation structure . only by using training data",
    "can we learn the covariance of the process that @xmath11 is sampled from , leading to our formulation of the posterior of the unknowns , given the measured data as well as the training data .",
    "to take the example of modelling @xmath11 using a high - dimensional @xmath17 , it might be possible of course to impose the form of the covariance by hand ; for example , when it is safe to assume that @xmath11 is continuous , we could choose a stationary covariance function rasmussen , such as the popular square exponential covariance or the matern class of covariance functions materngneiting , though parameters of such a covariance ( correlation length , smoothness parameter ) being unknown , @xmath18 values of these will then need to be imposed . in the presence of training data",
    ", the smoothness parameters can be learnt from the data .    for systems",
    "in which the continuous assumption is misplaced , choosing an appropriate covariance function and learning the relevant parameters from the measured data , in absence of training data , becomes even trickier .",
    "an example of this situation can arise in fact in an inverse problem of type  i  the unknown physical density of the system is projected onto the space of observables such that inversion of the available ( noisy ) image data will allow for the estimation of the unknown density , where the projection operator is known .",
    "such a density function in real systems can often have disjoint support in its domain and can also be typically characterised by sharp density contrasts as in material density function of real - life material samples crp . then",
    ", if we were to model this discontinuous and multimodal density function as a realisation from a @xmath17 , the covariance function of such a process will need to be non - stationary .",
    "it is possible to render a density function sampled from such a @xmath17 to be differently differentiable at different points , using for example prescriptions advanced in the literature paciorek , but in lieu of training data it is not possible to parametrise covariance kernels to ensure the representative discontinuity and multimodality of the sampled ( density ) functions .",
    "thus , the absence of training data leads to the inability to learn the correlation structure of the density function given the measured image data .    a way out this problem could be to make an attempt to construct a training data set by learning values of the unknown system behaviour function at those points in the domain of the density , at which measured data are available ;",
    "effectively , we then have a set of data points , each generated at a learnt value of the function , i.e. this set comprises a training data . in this data set",
    "there are measurement uncertainties as well as uncertainty of estimation on each of the learnt values of the system function .",
    "of course , learning the value of the function at identified points within the domain of the system function , is in itself a difficult task .",
    "thus , in this paradigm , the domain @xmath19 of the unknown system function @xmath16 is discretised according to the set of values of @xmath6 , @xmath20 , at which the @xmath21 measurements are available . in other words ,",
    "the discretisation of @xmath22 is dictated by the data distribution . over each @xmath6-bin , the function @xmath16",
    "is held a constant such that for @xmath6 in the @xmath23-th bin , the function takes the value @xmath24 , @xmath25 ; then we define @xmath26 and try to learn this vector , given the data .",
    "unless otherwise motivated , in general applications , the probability distribution of @xmath24 is not imposed by hand . in the bayesian framework",
    "this exercise translates to the computing of the joint posterior probability density of @xmath21 distribution - free parameters @xmath27 given the data , where the correlation between @xmath24 and @xmath28 is not invoked , @xmath29 . of course ,",
    "framed this way , we can only estimate the value of the sought function @xmath16 at identified values of @xmath6unless interpolation is used  but once the training data , thus constructed , is subsequently implemented in the modelling of @xmath11 with a @xmath17 of appropriate dimensionality , statistical prediction at any value of @xmath6 may be possible .",
    "above , we dealt schematically with the difficult case of lack of training data .",
    "however , even when a training data set is available , learning @xmath11 using such data can be hard . in principle , @xmath11 can be learnt using splines or wavelets . however , a fundamental shortcoming of this method is that splines and wavelets can fail to capture the correlation amongst the component functions of a high - dimensional @xmath11 .",
    "also , the numerical difficulty of the very task of learning @xmath11 using this technique , and particularly of inverting the learnt @xmath11 , only increases with dimensionality .",
    "thus it is an improvement to model such a @xmath11 with a high - dimensional @xmath17 .",
    "a high - dimensional @xmath11 can arise in a real - life inverse problem if the observed data is high - dimensional , eg . the data is matrix - variate cbb .    measurement uncertainties or measurement noise is almost unavoidable in practical applications and therefore , any attempt at an inference on the unknown model parameter vector @xmath3 ( or the unknown model function @xmath16 ) should be capable of folding in such noise in the data .",
    "in addition to this , there could be other worries stemming from inadequacies of the available measurements  the data could be  too small \" to allow for any meaningful inference on the unknown(s ) or  too big \" to allow for processing within practical time frames ; here the qualification of the size of the data is determined by the intended application as well as the constraints on the available computational resources . however , a general statement that is relevant here is the fact that in the bayesian paradigm , less data is usually required than in the frequentists approach , as motivated above .",
    "lastly , data could also be missing ; in particular , in this paper we discuss a case in which the measurable lives in a space @xmath30 where @xmath13 is the state space of the system at hand .",
    "the paper is constructed as follows . in section  [ sec : intro ] , we briefly discuss the outline of state space modelling . in the following section  [ sec : generic ]",
    ", our new state space modelling based methodology is delineated ; in particular , we explore alternatives to the suggested method in subsection  [ sec : alternative ] .",
    "the astrophysical background to the application using which our methodology is elucidated , is motivated in section  [ sec : casestudy ] while the details of the modelling are presented in section  [ sec : modelreal ] .",
    "we present details of our inference in section  [ sec : inference ] and applications to synthetic and real data are considered in section  [ sec : synthetic ] and section  [ sec : real ] respectively .",
    "we round up the paper with some discussions about the ramifications of our results in section  [ sec : discussions ] .",
    "understanding the evolution of the probability density function of the state space of a dynamical system , given the available data , is of broad interest to practitioners across disciplines .",
    "estimation of the parameters that affect such evolution can be performed within the framework of state space models or ssms west97,polewesthar , harveybook , carlin92 .",
    "basically , an ssm comprises an observation structure and an evolution structure . assuming the observations to be conditionally independent , the marginal distribution of any observation is dependent on a known or unknown stationary model parameter , at a given value of the state space parameter at the current time .",
    "modelling of errors of such observations within the ssm framework is of interest in different disciplines winshipecology , birdstate .",
    "the evolution of the state space parameter is on the other hand given by another set of equations , in which the uncertainty of the evolved value of the parameter is acknowledged . a state space representation of complex systems",
    "will in general have to be designed to capacitate high - dimensional inference in which both the evolutionary as well as observation equations are in general non - linear and parameters and uncertainties are non - gaussian .    in this paper",
    "we present a new methodology that offers a state space representation in a situation when data is collected at only one time point and the unknown state space parameter in this treatment is replaced by the discretised version of the multivariate probability density function ( @xmath0 ) of the state space variable .",
    "the focus is on the learning of the static unknown model parameter vector rather than on prediction of the state space parameter at a time point different to when the observations are made .",
    "in fact , the sought model parameter vector is treated as embedded within the definition of the @xmath0 of the state space variable . in particular , the method that we present here pertains to a partially observed state space , i.e. the observations comprise measurements on only some  but not all  of the components of the state space vector .",
    "thus in this paradigm , probability of the observations conditional on the state space parameters reduces to the probability that the observed state space data have been sampled from the @xmath0 of the full state space variable vector , marginalised over the unobserved components . here",
    "this @xmath0 includes the sought static model parameter vector in its definition .",
    "in addition to addressing missing data , the presented methodology is developed to acknowledge the measurement errors that may be non - gaussian .",
    "the presented method is applied to real and synthetic astronomical data with the aim of drawing inference on the distribution of the gravitational mass of all matter in a real and simulated galaxy , respectively .",
    "this gravitational mass density is projected to be useful in estimating the distribution of dark matter in the galactic system .",
    "here we aim to learn the unknown model parameter vector @xmath3 given the data , where data comprises @xmath31 measurements of some ( @xmath32 ) components of the @xmath33-dimensional state space parameter vector @xmath6 ; thus , @xmath34 . here @xmath35 .",
    "in fact , the data set is @xmath36 where the @xmath23-th observation is the vector @xmath37 .",
    "let the state space be @xmath13 so that @xmath38 .",
    "let the observable vector be @xmath39 .",
    "let @xmath40)=f_{{\\boldsymbol{x}}}({\\boldsymbol{x } } , { \\boldsymbol{\\alpha}})d{\\boldsymbol{x}}$ ] , i.e. the probability density function of the state parameter vector @xmath6 is @xmath41 , where the distribution is parametrised by the parameter @xmath42 .    in light of this , we suggest that @xmath43 .",
    "then had the observations lived in the state space @xmath13 , we could have advanced the likelihood function in terms of @xmath44 .",
    "however , here we deal with missing data that we know lives in the sub - space @xmath45 within @xmath46 .",
    "therefore , the data must be sampled from the density @xmath47 that is obtained by marginalising the @xmath0 @xmath48 over @xmath49 .",
    "in other words , the @xmath0 @xmath48 is projected onto the space of the observables , i.e. onto @xmath45 ; the result is the projected or marginalised density @xmath47 of the observables . then under the assumption of the observed vectors being conditionally @xmath50 ,",
    "the likelihood function is @xmath51 where + @xmath52    while the likelihood is thus defined , what this definition still does not include in it is the sought model parameter vector @xmath3 . in this treatment , we invoke a secondary equation that allows for the model parameter vector @xmath3 to be embedded into the definition of the likelihood .",
    "this can be accomplished by eliciting application specific details but in general , we suggest @xmath53 and construct the general model for the state space @xmath0 to be @xmath54 where @xmath55 is a @xmath56-dimensional vector function of a vector .    given this rephrasing of the state space @xmath0 , the projected density that the @xmath23-th measurement @xmath57 is sampled from , is re - written as + @xmath58 so that plugging this in the rhs of equation  [ eqn : likeli_prelim ] , the likelihood is @xmath59    however , it is appreciated that the @xmath0 of the state space vector @xmath6 may not be known , i.e. @xmath44 is unknown .",
    "this motivates us to attempt to learn the state space @xmath0 from the data , simultaneously with @xmath3 .",
    "we consider the situation that training data is unavailable where training data would comprise a set of values of @xmath60 generated at chosen values of @xmath14 .",
    "however , since the very functional relationship ( @xmath11 in the notation motivated above ) between @xmath60 and @xmath14 is not known , it is not possible to generate values of @xmath60 at a chosen value of @xmath14 , unless of course , an approximation of unquantifiable crudeness for this functional relationship is invoked . here",
    "we attempt to improve upon the prospect of imposing an @xmath61 model of @xmath11 .",
    "then in this paradigm , we discretise the function @xmath62 .",
    "this is done by placing the relevant ranges of the vectors @xmath63 and @xmath64 on a grid of chosen cell size .",
    "thus , for @xmath55 and @xmath11 being discretised into @xmath56 and @xmath65-dimensional vectors respectively , the discretised version of @xmath62 is then represented as the @xmath66-dimensional vector @xmath67 such that the @xmath68-th component of this vector is the value of @xmath62 in the @xmath68-th `` @xmath69-grid cell '' . here",
    ", such a grid - cell is the @xmath68-th of the ones that the domain of @xmath44 is discretised into , @xmath70 . given this discretisation of @xmath44 , the rhs of equation  [ eqn : nu_second ] is reduced to a sum of integrals over the unobserved variable in each of the grid - cells . in other words ,",
    "@xmath71 } \\label{eqn : nu_third}\\ ] ] where @xmath72 is the value that the vector of the unobserved variables takes up in the @xmath68-th @xmath69-grid - cell .",
    "the integral on the rhs of equation  [ eqn : nu_third ] represents the volume that the @xmath68-th @xmath69-grid - cell occupies in the space of the unobserved variable vector @xmath73 .",
    "the value of @xmath74 in the @xmath68-th @xmath69-grid - cell is dependent in general on @xmath3 for a given data vector @xmath57 ; hence the notation @xmath72 .    in other words , to compute the integral for each @xmath68 ( on the rhs of equation  [ eqn : nu_third ] ) we need to identify the bounds on the value of each component of @xmath74 imposed by the edges of the @xmath68-th @xmath69 grid - cell .",
    "this effectively calls for identification of the mapping between the space of @xmath63 and @xmath64 , and the space of the unobserved variables @xmath74 .",
    "now the observation @xmath75",
    ". then @xmath76 , where @xmath77 .",
    "indeed , this mapping will be understood using the physics of the system at hand .",
    "we will address this in detail in the context of the application that is considered in the paper .",
    "the likelihood function is then again rephrased as @xmath78}}\\end{aligned}\\ ] ] using equation  [ eqn : nu_third ] .",
    "however , the observed data is likely to be noisy too . to incorporate the errors of measurement ,",
    "the likelihood is refined by convolving @xmath79 with the density of the error @xmath80 in the value of the observed vector @xmath60 , where the error distribution is assumed known .",
    "let the density of the error distribution be @xmath81 where @xmath80 are the known parameters .",
    "then the likelihood is finally advanced as @xmath82    in a bayesian framework , inference is pursued thereafter by selecting priors for the unknowns @xmath3 and @xmath67 , and then using the selected priors in conjunction with the likelihood defined in equation  [ eqn : likeli_fin2 ] , in bayes rule to give the posterior of the unknowns given the data , i.e @xmath83 . in the context of the application at hand , we will discuss all this and in particular , advance the data - driven choice of the details of the discretisation of the @xmath62 function .",
    "posterior samples could be generated using a suitable version of metropolis - hastings and implemented to compute the 95@xmath84 hpd credible regions on the learnt parameter values .",
    "we ask ourselves the question about alternative treatment of the data that could result in the estimation of the unknown model parameter vector @xmath3 .",
    "let the sought model parameter be @xmath85-dimensional while the observable @xmath60 is an @xmath32-dimensional vector valued variable and there are @xmath31 number of measurements of this variable available .",
    "then the pursuit of @xmath86 can lead us to express the data as a function of the model parameter vector , i.e. write @xmath87 , where @xmath88 is an unknown , @xmath32-dimensional vector valued function of an @xmath85-dimensional vector . in order to learn @xmath3",
    ", we will need to first learn @xmath88 from the data , as was motivated in the introductory section .    as we saw in that section , the learning of this high - dimensional function from the data and its inversion",
    "are best tackled by modelling the unknown high - dimensional function with a gaussian process .",
    "cbb present a generic bayesian method that performs the learning and inversion of a high - dimensional function given matrix - variate data within a supervised learning paradigm ; the ( chosen ) stationary covariance function implemented in this work is learnt using training data and is subsequently used in the computation of the posterior probability of the unknown model parameter vector given the measured or test data , as well as the training data . in the absence of available training data , such an implementation is not possible , i.e. such a method is not viable in the unsupervised learning paradigm . in the application",
    "we discuss below , training data is not available and therefore , the modelling of the functional relation between data and @xmath3 , using gaussian processes appears to not be possible .",
    "this shortcoming can however be addressed if simulations of the system at hand can be undertaken to yield data at chosen values of @xmath3 ; however , the very physical mechanism that connects @xmath3 with the data may be unknown ( as in the considered application ) and therefore , such a simulation model is missing . alternatively ,",
    "if independently learnt @xmath3 , learnt with an independent data set , is available , the same can be used as training data to learn @xmath3 given another data set . on such instances , the gaussian process approach is possible but in lieu of such training data becoming available , the learning of @xmath3 given the matrix - valued data can be performed in the method presented above . on the other hand ,",
    "a distinct advantage of the method presented below is that it allows for the learning of the state space density in addition to the unknown model parameter vector .",
    "if the suggestion is to learn the unknown system function @xmath14 as itself a realisation of a @xmath17 , the question that then needs to be addressed is how to parametrise the covariance structure of @xmath17 in situations in which the data results from measurements of the variable @xmath60 that shares an unknown functional relation with @xmath14 . in other words , in such situations ,",
    "the unknown system function @xmath14 has to be linked with the available data via a functional relation , which however is unknown , as motivated above ; we are then back to the discussion in the previous paragraph .",
    "unravelling the nature of dark matter and dark energy is one of the major challenges of today s science .",
    "while such is pursued , the gathering of empirical evidence for / against dark matter ( dm ) in individual real - life observed astronomical systems is a related interesting exercise .",
    "the fundamental problem in the quantification of dark matter in these systems is that direct observational evidence of dm remains elusive . in light of this",
    ", the quantification is pursued using information obtained from measurable physical manifestations of the gravitational field of all matter in an astronomical system , i.e. dark as well as self - luminous matter .",
    "indeed , such measurements are difficult and physical properties that manifest the gravitational effect of the total gravitational field of the system would include the density of x - rays emitted by the hot gas in the system at a measured temperature 3379_xray , velocities of individual particles that live in the system and play in its gravitational field coccato09 , cote_m49 , romanowskyscience , m15,chakrabarty_somak and the deviation in the path of a ray of light brought about by the gravitational field of the system acting as a gravitational lens koopmans_06 .",
    "the extraction of the density of dm from the learnt total gravitational mass density of all matter in the system , is performed by subtracting from the latter , the gravitational mass density of the self - luminous matter .",
    "the density of such luminous matter is typically modelled astronomically using measurements of the light that is observed from the system . a reliable functional relationship between the total gravitational mass density and such photometric measurements is not motivated by any physical theories though the literature includes such a relationship as obtained from a pattern recognition study performed with a chosen class of galaxies brendan .    in this work ,",
    "we focus our attention to the learning of the total gravitational mass density in galaxies , the images of which resemble ellipses - as distinguished from disc - shaped galaxies for which the sought density is more easily learnt using measurement of rotational speed of resident particles . by a galactic `` particle '' we refer to resolved galactic objects such as stars .",
    "there could also be additional types of particles , such as planetary nebulae ( pne ) which are an end state of certain kinds of stars ; these bear signature marks in the emitted spectral data .",
    "other examples of galactic particles could include old clusters of stars , referred to as globular clusters ( gcs ) .",
    "as defined above , the space of all states that a dynamical system achieves is referred to as the system s state space @xmath13 .",
    "now , the state that a galaxy is in , is given by the location and velocity coordinates of all particles in the system . here",
    ", the location coordinate is @xmath89 as is the velocity coordinate vector @xmath90 .",
    "thus , in our treatment of the galaxy at hand , @xmath13 is the space of the particle location and velocity vector i.e. the space of the vector @xmath91 .",
    "we model the galactic particles to be playing in the average ( gravitational ) force field that is given rise to by all the particles in this system . under the influence of this mean field",
    ", we assume the system to have relaxed to a stationary state so that there is no time dependence in the distribution of the vector @xmath91 , where the 3-dimensional vector @xmath92 and @xmath93 .",
    "then the @xmath0 of the variable @xmath94 is @xmath95 , where @xmath96 is a parameter vector .",
    "our aim is to learn the density function of gravitational mass of all matter in the galaxy , given the data @xmath97 , where @xmath98 .",
    "the physical interpretation of these observables is that @xmath99 is the component of the velocity of a galactic particle that is aligned along the line - of - sight that joins the particle and the observer , i.e. we can measure how quickly the particle is coming towards the observer or receding away but can not measure any of the other components of @xmath90 .",
    "similarly , we know the components @xmath100 and @xmath101 of the location @xmath6 of a galactic particle in the galactic image but can not observe how far orthogonal to the image plane the particle is , i.e. @xmath102 is unobservable .",
    "thus @xmath103 but @xmath104 with @xmath105 .",
    "it merits mention that in the available data , values of @xmath100 and @xmath101 appear in the form of @xmath106 . then the data @xmath107 .    here",
    "@xmath31 is typically of the order of 10@xmath108 . while for more distant galaxies , @xmath31 is lower , recent advancements is astronomical instrumentation allows for measurement of @xmath99 of around 750 planetary nebulae or pne ( as in the galaxy cena , woodley , @xmath109 chakrabarty , under preparation ) .",
    "such high a sample size is however more of an exception than the rule - in fact , in the real application discussed below , the number of @xmath99 measurements of globular clusters ( or gcs ) available is only 29 . in addition , the measurements of @xmath99 are typically highly noisy , the data would typically sample the sub - space @xmath45 very sparsely and the data sets are typically one - time measurements .",
    "the proposed method will have to take this on board and incorporate the errors in the measurement of @xmath99 .",
    "given such data , we aim to learn the gravitational mass density of all matter - dark as well as self - luminous - at any location @xmath6 in the galaxy .",
    "in the bayesian framework , we are essentially attempting to compute the posterior of the unknown gravitational mass density function @xmath14 , given data @xmath110 . since gravitational mass density is non - negative , @xmath111 .",
    "that we model the mass density to depend only on location @xmath6 is a model assumption .    from bayes rule ,",
    "the posterior probability density of @xmath14 given data @xmath110 is given as proportional to the product of the prior and the likelihood function , i.e. the probability density of @xmath110 given the model for the unknown mass density .",
    "now , the probability density of the data vector @xmath60 given the model parameters @xmath96 is given by the probability density function @xmath112 of the observable @xmath60 , so that , assuming the @xmath31 data vectors to be conditionally independent , the likelihood function is the product of the @xmath0s of @xmath60 obtained at the @xmath31 values of @xmath60 : @xmath113 this is equation  [ eqn : likeli_fin ] written in the context of this application . given that @xmath75 , the @xmath0 of @xmath60 is related to the @xmath0 @xmath114 of the vector - valued variable @xmath115 as + @xmath116 however , this formulation still does not include the gravitational mass density function @xmath16 in the definition of @xmath117 , we explore the physics of the situation to find how to embed @xmath16 into the definition of the @xmath0 of the state space variable @xmath1 , and thereby into the likelihood .",
    "this is achieved by examining the time evolution of this @xmath0 of the state space variable ; we discuss this next .      here",
    "we invoke the secondary equation that tells of the evolution of @xmath117 .",
    "in general , the @xmath0 of the state space variable is a function of @xmath6 , @xmath90 and time @xmath119 .",
    "so the general state space @xmath0 is expected to be written as @xmath120 , with @xmath121 .",
    "it is interpreted as the following : at time @xmath56 ( @xmath122 ) , the probability for @xmath123 $ ] and @xmath124 $ ] for a galactic particle is @xmath125 .",
    "however , we assume that the particles in a galaxy do not collide since the galactic particles inside it , ( like stars ) , typically collide over time - scales that are @xmath126 the age of galaxies bt . given this assumption of collisionlessness",
    ", the @xmath0 of @xmath91 remains invariant .",
    "thus , the evolution of @xmath127 must is guided by the collisionless boltzmann equation ( cbe ) : @xmath128 this equation suggests that when the state space distribution has attained stationarity , so that @xmath129 , @xmath130 is a constant @xmath131 at a given time .",
    "this is referred to as jeans theorem bt .",
    "in fact , the equation more correctly suggests that as long as the system has reached stationarity , at any given time , @xmath130 is a constant @xmath131 inside a well - connected region@xmath132 . given this ,",
    "the state space @xmath0 can be written as a function of quantities that do not change with time .",
    "[ th : cbe ] any function @xmath133 is a steady - state or stationary solution of the collisionless boltzmann equation i.e. a solution to the equation @xmath134=0 if and only if @xmath133 is invariant with respect to time , for all @xmath135 and @xmath136 that lie inside a well - connected region@xmath132 .",
    "the proof is simple ; for the proof we assume @xmath6 and @xmath90 to take respective values of @xmath135 and @xmath136 inside a well - connected sub - space of @xmath13 .",
    "let a function of the vectors @xmath135 , @xmath136 be @xmath133 such that it remains a constant w.r.t .",
    "then @xmath137this function is a solution to the equation @xmath134=0 .",
    "let the equation @xmath134=0 have a solution @xmath138 .",
    "this implies @xmath139 , i.e. @xmath138 is a constant with respect to time . for this to be true , @xmath140 .",
    "therefore the solution to @xmath134=0 is a function of @xmath135 and @xmath136 that is a constant w.r.t .",
    "in fact , any function of a time - invariant function of vectors @xmath6 and @xmath90 is also a solution to the cbe .    now , in our work we assume the system to have attained stationarity so that the @xmath0 of the state space variable has no time dependence .",
    "then the above theorem suggests that we can write @xmath141 for any @xmath142 , where @xmath143 is any time - independent function of 2 vectors , for @xmath25 .    now , upon eliciting from the literature in galactic dynamics",
    "contop63 , binney82 we realise the following .",
    "* the number @xmath21 of constants of motion can be at most 5 , i.e. @xmath144 .",
    "* the @xmath145 of the state space variable has to include particle energy @xmath146 , ( which is one constant of motion ) , in its domain .",
    "thus , we can write @xmath147 .",
    "* energy @xmath146 is given as the sum of potential energy @xmath148 and kinetic energy @xmath149 , i.e. @xmath150 here @xmath151 is the euclidean norm . that the potential is maintained as dependent only of the location vector @xmath6 and not on @xmath90 stems from our assumption that there is no dissipation of energy in this system , i.e. we model the galaxy at hand to be a hamiltonian system . here ,",
    "a basic equation of physics relates the potential of the galaxy to the gravitational mass density of the system , namely poisson equation : @xmath152 @xmath153 is the laplace operator ( in the considered geometry of the galaxy ) and @xmath154 is a known constant ( the universal gravitational constant ) .    on the basis of the above , we can write @xmath155 at this point we recall the form of an isotropic function of 2 vectors shi , truesdell , wang .    [",
    "remark : isotropic ] a scalar function @xmath156 of two vectors @xmath157 and @xmath158 is defined as isotropic with respect to any orthogonal transformation @xmath159 if @xmath160 .",
    "here @xmath161 , the identity matrix and @xmath162 .",
    "under any such orthogonal transformation @xmath163 , only the magnitudes of the vectors @xmath164 and @xmath165 , and the angle between them remain invariant , where the angle between @xmath164 and @xmath165 is @xmath166 .",
    "therefore , it follows that + @xmath167 @xmath168 .",
    "we also recall that in this application , @xmath169 by construction .",
    "this leads us to identify any @xmath0 of the state space variable @xmath91 as isotropic if the @xmath0 is expressed as a function of energy @xmath146 alone .",
    "this follows from equation  [ eqn : fmanyforms ] since @xmath170 @xmath171 which is compatible with the form of isotropic functions as per remark  [ remark : isotropic ] .",
    "thus , if the @xmath0 of the state space variable is dependent on only 1 constant of motion  which by the literature in galactic dynamics has to be energy @xmath146then @xmath117 is an isotropic function of @xmath6 and @xmath90 .",
    "however , there is no prior reason to model a real galaxy as having an isotropic probability distribution of its state space .",
    "instead , we attempt to    * use as general a model for the state space distribution of the system as possible , * while ensuring that the degrees of freedom in the model are kept to a minimum to ease computational ease .",
    "this leads us to include another time - invariant function @xmath172 in the definition of the @xmath0 of the state space variable in addition to @xmath146 , such that the dependence on @xmath6 and @xmath90 in @xmath173 is not of the form that renders @xmath174 compatible with the definition of isotropic function , as per remark  [ remark : isotropic ] , unlike @xmath175 .",
    "this is so because @xmath176 where @xmath177 represents the `` cross - product '' of the two 3-dimensional vectors @xmath6 and @xmath90 , i.e. +",
    "@xmath178 so that + @xmath179 then , we set @xmath180 which is not compatible with the form of an isotropic function of the 2 vectors @xmath6 and @xmath90 .",
    "in other words , if the support of the @xmath0 of @xmath6 and @xmath90 includes @xmath146 and @xmath172 , then the state space distribution is no longer restricted to be isotropic .",
    "such a general state space is indeed what we aimed to achieve with our model . at the same time",
    ", adhering to no more than 1 constant of motion in addition to energy @xmath146 helps to keep the dimensionality of the domain of the @xmath0 of the state space function to the minimum that it can be , given our demand that no stringent model - driven constraint be placed on the state space geometry .",
    "thus , we use @xmath21=2 in our model .",
    "so now we are ready to express the unknown gravitational mass density function as embedded within the @xmath0 of @xmath6 and @xmath90 as : + @xmath181 @xmath182 using equation  [ eqn : den_l ] . to cast this in the form of equation  [ eqn : f_fin ] , we realise that the unknown gravitational mass density function will need to be discretised ; we would first discretise the range of values of @xmath183 over which the gravitational mass density function @xmath184 is sought .",
    "let @xmath185 such that @xmath186 $ ] and let the width of each @xmath183-bin be @xmath187 .",
    "then @xmath188 is discretised as the unknown model parameter vector @xmath189 where @xmath190\\quad b=1,2,\\ldots , n_x \\label{eqn : rho_discrete}\\ ] ] where @xmath191 .    then following on from equation  [ eqn : inter ] we write @xmath192 this is in line with equation  [ eqn : f_fin ] if we identify the function of the unknown model parameter vector @xmath193 in the rhs of equation  [ eqn : f_fin ] with the unknown gravitational mass density vector @xmath3 .",
    "then the @xmath0 of the state space variables @xmath6 and @xmath90 depends of @xmath3 and @xmath6 and @xmath90 .",
    "then the equivalent of equation  [ eqn : nu_second ] is @xmath194    @xmath195 . then plugging this in the rhs of equation  [ eqn : likeli_prelim ] , the likelihood is @xmath196 then to compute the likelihood and thereafter the posterior probability of @xmath3 given data @xmath110",
    ", we will need to compute the integral in equation  [ eqn : nu_galaxy ] . according to the general methodology discussed above in section  [ sec : generic ] , this is performed by discretising the domain of the @xmath0 of the state space variable , i.e. of @xmath174 . in order to achieve this discretisation we will need to invoke the functional relationship between @xmath146 and @xmath172 .",
    "next we discuss this .",
    "we recall the physical interpretation of @xmath172 as the norm of the `` angular momentum '' vector , i.e. @xmath197 is the square of the speed @xmath198 of circular motion of a particle with location @xmath6 and velocity @xmath90 ; here , `` circular motion '' is motion orthogonal to the location vector @xmath6 , distinguished from non - circular motion that is parallel to @xmath6 and the speed of which is @xmath199 .",
    "then as these two components of motion are mutually orthogonal , square of the particle s speed is @xmath200 where @xmath201 is the magnitude of the component of @xmath90 that is parallel to @xmath6 , i.e. @xmath202 but we recall that energy @xmath203 .",
    "this implies that @xmath204 where in the last equation , we invoked the definition of @xmath172 sing equation  [ eqn : ldefn ] .    at this stage , to simplify things , we consciously choose to work in the coordinate system in which the vector @xmath6 is rotated to vector @xmath205 by a rotation through angle @xmath206 , i.e. @xmath207 then by definition , @xmath208=0 , i.e. the projection of the @xmath209 vector on the @xmath210=0 plane lies entirely along the @xmath211-axis .",
    "this rotation does not affect the previous discussion since    * the previous discussion invokes the location variable either via @xmath212 , * or via @xmath213 as within the data structure : @xmath214 + @xmath215 .",
    "having undertaken the rotation , we refer to @xmath146 and @xmath172 as @xmath216 and @xmath217 respectively .",
    "this rotation renders the cross - product in the definition of @xmath173 simpler ; under this choice of the coordinate system , as @xmath218 @xmath219 ^ 2 & = & { \\parallel { \\boldsymbol{s}}{\\boldsymbol{\\times}}{\\boldsymbol{v}}\\parallel^2}\\nonumber\\\\ & = & { \\parallel(s_2 v_3 - s_3 v_2 , s_3 v_1 , -s_2 v_1)^t\\parallel^2}\\nonumber\\\\   & = & { \\parallel(r v_3 \\sin\\gamma - r v_2\\cos\\gamma , r v_1\\cos\\gamma , -r v_1\\sin\\gamma)^t\\parallel^2 } \\nonumber\\\\ & = & { r^2\\left[v_1 ^ 2 + ( v_2\\cos\\gamma - v_3\\sin\\gamma)^2\\right ] } \\label{eqn : lcoord}\\end{aligned}\\ ] ] where @xmath220 so that @xmath221 , so that in this rotated coordinate system , from equation  [ eqn : ljhamela ] @xmath222}{2 } } \\nonumber \\\\ { } & & + \\displaystyle{\\frac{v_{nc}^2}{2}}. \\label{eqn : elrevamp}\\end{aligned}\\ ] ] also , the component of @xmath90 along the location vector @xmath223 is @xmath224 .    from equation  [ eqn : ljhamela ] it is evident that for a given value @xmath225 of @xmath216 , the highest value @xmath226 of @xmath217 is attained if @xmath227 ( all motion is circular motion ) .",
    "this is realised only when the radius @xmath228 of the circular path of the particle takes a value @xmath229 such that @xmath230 } \\label{eqn : ellmax}\\ ] ] the way to compute @xmath229 given @xmath225 is defined in the literature bt as the positive definite solution for @xmath231 in the equation @xmath232 } = \\displaystyle{-r^3\\frac{d\\phi(r)}{dr } } \\label{eqn : ellsoln}\\ ] ]    we are now ready to discretise the domain of the @xmath0 of the state space variable , i.e. of @xmath174 in line with the general methodology discussed above in section  [ sec : generic ] with the aim of computing the integral in equation  [ eqn : nu_galaxy ] .",
    "we discretise the domain of @xmath233 where this 2-dimensional domain is defined by the range of values @xmath234 $ ] and @xmath235 $ ] , by placing a uniform 2-dimensional rectangular grid over @xmath236\\times[\\ell_{min},\\ell_{max}]$ ] such that the range @xmath236 $ ] is broken into @xmath237-bins each @xmath238 wide and the range @xmath239 $ ] is broken into @xmath240-bins each @xmath241 wide .",
    "then each 2-dimensional @xmath242-grid cell has size @xmath243 .",
    "then , @xmath244,\\nonumber \\\\ \\ell&\\in&[\\ell_{min}+(d-1)\\delta_\\ell , \\ell_{min}+d\\delta_\\ell],\\nonumber \\\\ c&=&1,2,\\ldots , n_\\epsilon,\\nonumber \\\\",
    "d&=&1,2,\\ldots , n_\\ell , \\label{eqn : prelim_cd}\\end{aligned}\\ ] ] where the number of @xmath237-bins is @xmath245 and the number of @xmath240-bins is @xmath246 .",
    "we then define the @xmath247-dimensional matrix @xmath248_{n_\\epsilon\\times n_\\ell}. \\label{eqn : matis_pdf}\\ ] ] in our model this is the discretised version of the @xmath0 @xmath174 of the state space variable @xmath249 .    in this application ,",
    "a particle with a positive value of energy is so energetic that it escapes from the galaxy .",
    "we are however concerned with particles that live inside the galaxy , i.e. are bound to the galaxy and therefore , the maximum energy that a galactic particle can attain is 0 , i.e. @xmath250 . given the definition of energy @xmath251 we realise that the value of @xmath216 is minimum , i.e. as negative as it can be , if @xmath252=0 , ( i.e. velocity is zero ) and @xmath253 is minimum , which occurs at @xmath254 . in other words ,",
    "the minimum value of @xmath237 is @xmath255 which is negative . in our work",
    "we normalise the value @xmath225 of @xmath237 by @xmath256 , so that @xmath257 $ ] .",
    "in other words , the aforementioned @xmath258 and @xmath250 .",
    "we normalise the value @xmath259 of @xmath217 with the maximal value @xmath226 that @xmath259 can attain for a given value @xmath225 of @xmath237 ( equation  [ eqn : ellmax ] ) .",
    "the maximum value that can be attained by @xmath240 is for @xmath260 ; having computed @xmath229 from equation  [ eqn : ellsoln ] , @xmath261 is computed .",
    "then , as normalised by @xmath261 , the maximal value of @xmath240 is 1 .",
    "also the lowest value of @xmath240 is 0 , i.e. @xmath262=0 . in light of this , we rewrite equation  [ eqn : prelim_cd ] as @xmath263,\\nonumber \\\\ \\ell&\\in&[(d-1)\\delta_\\ell , d\\delta_\\ell],\\nonumber \\\\ c&= & 1,2,\\ldots , n_\\epsilon,\\nonumber \\\\ d&= & 1,2,\\ldots , n_\\ell .",
    "\\label{eqn : prelim_cd2}\\end{aligned}\\ ] ] the @xmath237-binning and @xmath240-binning are kept uniform in the application we discuss below , i.e. @xmath238 and @xmath241 are constants .",
    "there are @xmath264 @xmath240-bins and @xmath265 @xmath237-bins .",
    "above we saw that as the range covered by normalised values of @xmath237 is @xmath266 $ ] , the relationship between @xmath265 and @xmath237-bin width @xmath238 is @xmath267 .",
    "we make inference on @xmath264 within our inference scheme while the physics of the situation drives us to a value of @xmath265 .",
    "it could have been possible to also learn @xmath265 from the data within our inference scheme but that would have been tantamount to wastage of information that is available from the domain of application .",
    "we attempt to learn @xmath264 from the data within our inference scheme ; for a given @xmath264 , @xmath265 is fixed by the data at hand . to understand this , we recall the aforementioned relation @xmath268 .",
    "let in the available data set ,    1 .",
    "the minimum value of @xmath269 be @xmath270 , 2 .",
    "the maximum value of @xmath269 be @xmath271 so that the value of @xmath272 is no less than @xmath273 , 3 .",
    "the maximum value of @xmath99 be @xmath274 so that the unnormalised value of @xmath237 is no less than @xmath275 ^ 2}{2 } + \\frac{[n_\\ell \\ell_{max}(0)]^2}{2 r_{min}^2}}\\ ] ] 4 .   and",
    "the unnormalised @xmath225 is no more than @xmath255 .",
    "thus , it is clear that the @xmath237-binning should cover the interval beginning at a normalised value of -1 and should at least extend to @xmath276 $ ] .",
    "then we set @xmath237-bin width @xmath267 and learn number of @xmath240-bins , @xmath264 , from the data within our inference scheme . then at any iteration , for the current value of @xmath264 and the current @xmath3 ( which leads to the current value of @xmath277 according to equation  [ eqn : poisson ] ) , placing @xmath276 $ ] at the centre of the @xmath265-th @xmath237-bin",
    "gives us @xmath278 i.e. @xmath279\\right)$ ] .",
    "experiments suggest that for typical galactic data sets , @xmath264 between 5 and 10 implies convergence in the learnt vectorised form of the gravitational mass density @xmath3 .",
    "this leads us to choose a discrete uniform prior over the set @xmath280 , for @xmath264 : @xmath281    again , the minimum and maximum values of @xmath269 in the data fix @xmath270 and @xmath271 respectively , so that @xmath282 . the radial bin width @xmath187 is entirely dictated by the data distribution such that there is at least 1 data vector in each radial bin .",
    "thus , @xmath283 and @xmath187 are not parameters to be learnt within the inference scheme but are directly determined by the data .",
    "following equation  [ eqn : likeli_fin ] , we express the likelihood in this application in terms of the @xmath0 of @xmath223 and @xmath90 , marginalised over all those variables that we do not have any observed information on .",
    "then for the data vector @xmath284 , the marginal @xmath0 is +   @xmath285 where + @xmath286}{2}}$ ] + @xmath287 + @xmath288}$ ] , + with @xmath289 ^ 2 $ ] recalled from equation  [ eqn : lcoord ] , and we have used @xmath290 and @xmath291 .    then given that the range of values of @xmath237 and @xmath240 is discretised , we write @xmath292 } , \\label{eqn : likeli_integ}\\ ] ] where @xmath293 refer to the values taken by @xmath210 for a given @xmath3 , inside the @xmath294-th @xmath242-grid - cell .",
    "similarly , @xmath295 and @xmath296 refer to the values of @xmath297 and @xmath298 inside the @xmath294-th @xmath242-grid - cell respectively , given @xmath3 .    indexing the values of any of the unobserved variables in this grid - cell as conditional on @xmath3 , is explained as follows .",
    "@xmath299 , @xmath300 and @xmath301 are determined by the mapping between the space of @xmath237 and @xmath240 and the space of the unobservables , namely @xmath302 .",
    "this mapping involves the definition of @xmath237 and @xmath240 in terms of the state space coordinates @xmath303 , which in turn depends upon the function @xmath188 or its discretised version , @xmath3 . hence the values taken by any of the 3 unobservables in the @xmath294-th @xmath242-grid - cell depend on @xmath3 . here",
    "@xmath304 and @xmath305 .",
    "we realise that the integral on the rhs of equation  [ eqn : likeli_integ ] represents the volume occupied by the @xmath242-grid - cell inside the space of the unobserved variables .",
    "the computation of this volume is now discussed .",
    "we begin by considering the volume of any @xmath242-grid - cell in the space of the 2 observables , @xmath297 and @xmath298 , at a given value of @xmath210 .",
    "thereafter , we will consider the values of the 3rd unobservable , @xmath210 , in this grid - cell .",
    "the definition @xmath306 ( equation  refeqn : ljhamela ) implies that for the @xmath307-th data vector @xmath284 , all particles with @xmath308 and energy @xmath309 will obey the equation @xmath310 - ( v_3^{(k)})^2 , \\label{eqn : engcirc}\\ ] ] i.e. for @xmath308 , all particles lying in the @xmath311-th e - bin will lie in the space of @xmath297 and @xmath298 , within a circular annulus that is centred at ( 0,0 ) and has radii lying in the interval @xmath312 $ ] where @xmath313    for @xmath308 , the definition @xmath314 provides a representation for all particles in the @xmath33-th @xmath240-bin with given observed values of @xmath208 , @xmath211 and @xmath99 .",
    "it then follows from @xmath315 ^ 2= ( r^{(k)})^2\\left[(v_1 ^ 2 + \\{v_2\\cos\\gamma -v^{(k)}_3\\sin\\gamma\\}^2\\right]$ ] , ( equation  [ eqn : lcoord ] ) that for the @xmath307-th data vector , all particles with @xmath308 , and in the @xmath33-th @xmath240-bin ( @xmath316 ) will obey the equation @xmath317 .",
    "\\label{eqn : ellell}\\ ] ] where we have recalled @xmath318 from equation  [ eqn : rk ] .",
    "this implies that for @xmath308 , all particles lying in the @xmath33-th l - bin , will lie in the space of @xmath297 and @xmath298 , along an ellipse centred at @xmath319 with semi - minor axis lying in the interval of @xmath320 $ ] and semi - major axis lying in the interval @xmath321}$ ] . here , @xmath322    collating the implications of equation  [ eqn : engcirc ] and equation  [ eqn : ellell ]",
    ", we get that at a given value of @xmath210 , particles with observed data @xmath323 , ( with energies ) in the @xmath311-th @xmath237-bin and ( momenta ) in the @xmath33-th @xmath240-bin will lie in the space of @xmath297 and @xmath298 , within an area bound by the overlap of    1 .",
    "the circular annular region centred at @xmath324 , extending in radii between @xmath325 and @xmath326 .",
    "the elliptical annular region centred at @xmath327 , extending in semi - minor between @xmath328 and @xmath329 and semi - major axis in @xmath330 $ ] , where @xmath331 .",
    "the area of these overlapping annular regions represents the volume of the @xmath294-th @xmath242-grid - cell in the space of @xmath297 and @xmath298 , at the value @xmath332 of @xmath210 .",
    "thus , the first step towards writing the volume of the @xmath294-th @xmath242-grid - cell in terms of the unobservables , is to compute the area of these overlapping annular regions in the space of @xmath297 and @xmath298 .",
    "such an area of overlap is a function of @xmath332 . at the next step ,",
    "we integrate such an area over all allowed @xmath332 , to recover the volume of the @xmath294-th @xmath242-grid - cell in the space of @xmath297 , @xmath298 and @xmath210 , i.e. the integral on the rhs of equation  [ eqn : likeli_integ ]",
    ".    there can be multiple ways these annular regions overlap ; three examples of these distinct overlapping geometries are displayed in figure  [ fig : overlap ] . in each such geometry , it is possible to compute the area of this region of overlap since we know the equations of the curves that bound the area .",
    "however , the number of possible geometries of overlap is in excess of 20 and identifying the particular geometry to then compute the area of overlap in each such case , is tedious to code . in place of this , we allow for a numerical computation of the area of overlap ; this method works irrespective of the particulars of the geometry of overlap .",
    "we identify the maximum and minimum values of @xmath298 allowed at a given value of @xmath297 , having known the equations to the bounding curves , and compute the area of overlap in the plane of @xmath297 and @xmath298 using numerical integration .",
    "this area of overlap in the plane defined by @xmath297 and @xmath298 is a function of @xmath210 since the equations of the bounding curves are expressed in terms of @xmath332 .",
    "the area of overlap is then integrated over all values that @xmath210 is permitted to take inside the @xmath294-th @xmath242-grid - cell .",
    "for any @xmath242-grid - cell , the lowest value @xmath210 can take is zero . for @xmath333 $ ] , and @xmath334 $ ] , the maximum value of @xmath210 is realised ( by recalling equation  [ eqn : elrevamp ] ) as the solution to the equation @xmath335      and @xmath298 , at neighbouring values of @xmath237 ( the circular contours in red ) and at neighbouring values of @xmath240 ( the elliptical contours in black).,title=\"fig:\",width=377 ]    where @xmath336 is the projection of @xmath136 along the @xmath337 vector ( discussed in section  [ sec : relation ] ) .",
    "thus , @xmath336 is given by the inner product of @xmath136 and the unit vector parallel to @xmath337 : @xmath338 where @xmath339 .",
    "under our choice of coordinate system , equation  [ eqn : vr ] gives @xmath340 using this in equation  [ eqn : zeqn ] we get @xmath341 this implies that given the observations represented by the @xmath307-th data vector @xmath342 , @xmath343\\left[\\epsilon_c - \\phi(r)\\right ] } = & & \\nonumber \\\\",
    "\\displaystyle{{\\ell_d^2 } + v_2 ^ 2 ( s_2^{(k)})^2 + ( v_3^{(k)})^2 s_3 ^ 2 + 2v_3^{(k ) } v_2 s_2^{(k ) } s_3}. & & \\label{eqn : zeqn3}\\end{aligned}\\ ] ] the highest positive root for @xmath332 from equation  [ eqn : zeqn3 ] as the highest value that @xmath210 can attain in the @xmath294-th @xmath242-grid - cell .",
    "thus , for the @xmath294-th cell , the limits on the integration over @xmath332 are 0 and the solution to equation  [ eqn : zeqn3 ] .",
    "so now we have the value of the integral over @xmath344 and @xmath345 and hereafter over @xmath332 , for the @xmath294-th @xmath242-grid - cell .",
    "this triple integral gives the volume of the @xmath294-th @xmath242-grid - cell in the space of the unobservables , i.e. of @xmath346 .",
    "this volume is multiplied by the value @xmath347 of the discretised @xmath0 of the state space variable in this @xmath242 cell and the resulting product is summed over all @xmath311 and @xmath33 , to give us the marginalised @xmath0 @xmath348 ( see equation  [ eqn : likeli_integ ] ) . once the marginalised @xmath0 is known for a given @xmath307 , the product over all @xmath307s contributes towards the likelihood .",
    "as we see from equation  [ eqn : likeli_integ ] , the marginal @xmath0 of @xmath223 and @xmath90 is dependent on @xmath3 , so this normalisation will not cancel within the implementation of metropolis - hastings to perform posterior sampling .",
    "in other words , to ensure that the value of @xmath349 - and therefore the likelihood - is not artificially enhanced by choosing a high @xmath3 , we normalise @xmath350 for each @xmath307 , by the @xmath0 integrated over all possible values of @xmath208 , @xmath211 and @xmath99 , i.e. by @xmath351 where the possible values of @xmath99 are in the interval @xmath352 $ ] , of @xmath211 in the interval @xmath353 $ ] and of @xmath208 in @xmath354 $ ] .",
    "hereafter , by @xmath349 we will imply the normalised marginal @xmath0 .      following equation  [ eqn : likeli_fin2 ] the likelihood is defined as the product over all data , of the convolution of the error distribution at the @xmath307-th datum and value of the marginalised @xmath0 for this @xmath307 ( assuming the data to be conditionally @xmath50 ) . in this application",
    "the measurement of the location of the galactic particle projected onto the image plane of the galaxy , i.e. @xmath355 , is constrained well enough to ignore measurement uncertainties in .",
    "however , the measurement errors in the line - of - sight component of the particle velocity , @xmath99 , can be large .",
    "this measurement error in @xmath99 is denoted as @xmath356 .",
    "the distribution of this error is determined by the astronomical instrumentation relevant to the observations of the galaxy at hand and are usually known to the astronomer . in the implementation of the methodology to real and simulated data ,",
    "as discussed below , we work with a gaussian error distribution with a known variance @xmath357 .",
    "thus , @xmath358 . for this particular error distribution ,",
    "the likelihood is defined as @xmath359}}.\\ ] ] for any other distribution of the uncertainties in the measurement of @xmath99 , the likelihood is to be rephrased as resulting from a convolution of @xmath349 and that chosen error distribution .      in the existing astronomical literature , there is nothing to suggest the @xmath0 of the state space variable in a real galaxy though there are theoretical models of the functional dependence between stellar energy ( @xmath237 ) and angular momentum ( @xmath240 ) and @xmath0 of @xmath223 and @xmath90 bt . given this , we opt for uniform priors on @xmath347 , @xmath304 , @xmath305 .",
    "however , in our inference , we will use the suggestion of monotonicity of the state space @xmath0 , as given in the theoretical galactic dynamics literature .",
    "we also use the physically motivated constraint that @xmath360 , @xmath361 .",
    "thus , we use @xmath362 , where @xmath363 denotes the uniform distribution over the interval @xmath364 $ ] .",
    "as far as priors on the gravitational mass density are concerned , astronomical models are available bt . all such models suggest that gravitational mass density is a monotonically decreasing function of @xmath183 . a numerically motivated form that has been used in the astrophysical community",
    "is referred to as the nfw density nfw , though criticism of predictions obtained with this form also exist [ among others]deblok2003 . for our purpose",
    "we suggest a uniform prior on @xmath365 such that @xmath366 i.e. @xmath367 is the gravitational mass density as given by the 2-parameter nfw form , for the particle radial location @xmath368 , @xmath369 .",
    "in fact , this location is summarised as @xmath370 , the mid - point of the @xmath371-th radial bin . @xmath372 and @xmath373 are the 2 parameters of the nfw density form . in our work",
    "these are hyperparameters and we place uniform priors on them : @xmath374 and @xmath375 , where these numbers are experimentally chosen .      given the data , we use bayes rule to write down the joint posterior probability density of + @xmath376 .",
    "this is @xmath377}\\times & & \\nonumber \\\\",
    "\\displaystyle{\\prod_{b=1}^{n_{x}}\\left[\\frac{1}{\\upsilon_{hi}^{(b)}(r_s,\\rho_0 ) -\\upsilon_{lo}^{(b)}(r_s,\\rho_0)}\\right ] } \\times & &   \\nonumber \\\\",
    "\\displaystyle{\\frac{1}{r_{max}-r_{min}}}\\times\\displaystyle{\\frac{1}{10^{14}-10^{9 } } } \\times \\displaystyle{\\frac{1}{5}}.&&\\end{aligned}\\ ] ] where we used @xmath378 , @xmath379 . here",
    ", the factor @xmath380 is a constant and therefore can be subsumed into the constant of proportionality that defines the above relation .",
    "we marginalise @xmath373 and @xmath372 out of + @xmath381 to achieve the joint posterior probability of @xmath3 , @xmath382 and @xmath264 given the data .",
    "the marginalisation involves only the term @xmath383}=$ ] + @xmath384}$ ] ( recalling equation  [ eqn : denprior ] ) . integrating this term over a fixed interval of values of @xmath372 and again over a fixed interval of @xmath373 , result in a constant that depends on @xmath31 , @xmath270 and @xmath187 .",
    "thus the marginalisation only results in a constant that can be subsumed within the unknown constant of proportionality that we do not require the exact computation of , given that posterior samples are generated using adaptive metropolis - hastings haario .",
    "thus we can write down the joint posterior probability of @xmath3 , @xmath382 and @xmath264 given the data as : @xmath385 }   \\label{eqn : posteriorfinal}\\ ] ] we discuss the implemented inference next .",
    "we intend to make inference on each component of the vector @xmath3 and the matrix @xmath382 , along with @xmath264 .",
    "we do this under the constraints of a gravitational mass density function @xmath184 that is non - increasing with @xmath183 and a @xmath0 @xmath174 of the state space variable that is non - increasing with @xmath237 .",
    "motivation for these constraints is presented in section  [ sec : priors ] . in other words , @xmath386 and @xmath387 for @xmath369 and @xmath388 .",
    "also , here @xmath389 and @xmath305 .",
    "first we discuss performing inference on @xmath3 using adaptive metropolis - hastings haario , while maintaining this constraint of monotonicity .",
    "we define @xmath390 it is on the parameters @xmath391 that we make inference .",
    "let within our inference scheme , at the @xmath21-th iteration , the current value of @xmath392 be @xmath393 .",
    "let in this iteration , a candidate value @xmath394 of @xmath392 be proposed from the folded normal density @xmath395 , i.e. @xmath396 where the choice of a folded normal folded or truncated normal proposal density is preferred over a density that achieves zero probability mass at the variable value of 0 .",
    "this is because there is a non - zero probability for the gravitational mass density to be zero in a given radial bin . here",
    "@xmath397 and @xmath398 are the mean and variance of the proposal density that @xmath392 is proposed from .",
    "we choose the current value of @xmath392 as @xmath397 and in this adaptive inference scheme , the variance is given by the empirical variance of the chain since the @xmath399-th iteration , i.e. @xmath400 ^ 2}{n - n_0 } } - \\displaystyle{\\left[\\frac{\\sum_{q = n_0}^{n-1 } \\delta_b^{(q)}}{n - n_0}\\right]^2}\\end{aligned}\\ ] ] we choose the folded normal proposal density given its ease of computation : @xmath401}\\ ] ] it is evident that this is a symmetric proposal density .",
    "we discuss the acceptance criterion in this standard metropolis - hastings scheme , after discussing the proposal density of the components of the matrix @xmath382 and the parameter @xmath264 .",
    "if @xmath394 is accepted , then the updated @xmath371-th component of @xmath3 in the @xmath21-th iteration is @xmath402 .",
    "if the proposed candidate is rejected then @xmath403 resorts back to @xmath404 .",
    "along similar lines , we make inference directly on @xmath405 let in the @xmath21-th iteration , the current value of @xmath406 be @xmath407 and the proposed value be @xmath408 where the proposed candidate is sampled from the folded normal density @xmath409 where the variance @xmath410 is again the empirical variance of the chain between the @xmath411-th and the @xmath412-th iteration",
    ". then the updated general element of the state space @xmath0 matrix in this iteration is @xmath413 , if the proposed value as accepted , otherwise , @xmath414 .",
    "thus , the proposal density that a component of the @xmath382 matrix is proposed from is also symmetric .",
    "we propose @xmath264 from the discrete uniform distribution , i.e. the proposed value of @xmath264 in the @xmath21-th iteration is @xmath415\\ ] ] where the bounds of the interval @xmath416 $ ] are found experimentally given the data at hand .",
    "given that we are making inference on the @xmath417 and @xmath418 , we rephrase the posterior probability of the unknowns as + @xmath419 .",
    "this posterior density is proportional to the rhs of equation  [ eqn : posteriorfinal ] .",
    "then given that the proposal densities that components of @xmath3 and of @xmath382 are sampled from and that the proposal density for @xmath264 is uniform , the metropolis - hastings acceptance ratio is reduced to the ratio of the posterior of the proposed state space vector value to that of the current state space vector , i.e. the proposed state space vector @xmath420 is accepted if @xmath421 where the uniform random variable @xmath422 $ ] .",
    "in this section we illustrate the methodology on synthetic data set simulated from a chosen models for the @xmath0 of @xmath249 .",
    "the chosen models for this @xmath0 are @xmath423 or @xmath424 and @xmath425 .",
    "these are given by : @xmath426 } , \\end{aligned}\\ ] ] where @xmath427 with @xmath428 chosen in both models for the state space @xmath0 to be @xmath429 . here",
    "the model parameters @xmath430 and @xmath431 are assigned realistic numerical values . from these",
    "2 chosen @xmath0s , @xmath31 values of @xmath60 were sampled ; these 2 samples constituted the 2 synthetic data sets @xmath432 and @xmath433 .",
    "the learnt gravitational mass density parameters and discretised version of the state space @xmath0 are displayed in figure  [ fig : syn1 ] .",
    "some of the convergence characteristics of the chains are explored in figure  [ fig : syn2 ] .",
    "the trace of the joint posterior probability of the unknown parameters given the data is shown along with histograms of @xmath434 learnt from 3 distinct parts of the chain that is run using data @xmath432 .",
    "in this section we present the gravitational mass density parameters and the state space @xmath0 parameters learnt for the real galaxy ngc3379 using 2 data sets @xmath435 and @xmath436 which respectively have sample size 164 pns and 29 bergond .",
    "an independent test of hypothesis exercise shows that there is relatively higher support in @xmath436 for an isotropic @xmath0 of the state space variable @xmath249 than in @xmath435 .",
    "given this , some runs were performed using an isotropic model of the state space @xmath0 ; this was achieved by fixing the number @xmath264 of @xmath240-bins to 1 .",
    "then @xmath240 identically takes the value @xmath437 and is rendered a constant .",
    "this effectively implies that the domain of @xmath174 is rendered uni - dimensional , i.e. the state space @xmath0 is then rendered @xmath175 .",
    "recalling the definition of an isotropic function from remark  [ remark : isotropic ] , we realise that the modelled state space @xmath0 is then an isotropic function of @xmath223 and @xmath90 .",
    "results from chains run with such an isotropic state space @xmath0 were overplotted on results from chains run with the more relaxed version of the @xmath0 that allows for incorporation of anisotropy ; in such chain , @xmath438 is in fact learnt from the data .     plotted as in red and blue against ( the value of @xmath216 ) @xmath225 , at two different @xmath259 , recovered from a chains that use data @xmath439 .",
    "the modal value of the learnt number of @xmath240-bins is 7 for this run .",
    "the state space @xmath0 parameters recovered using data @xmath436 are shown in black . _",
    "middle : _ gravitational mass density parameters @xmath24 estimated from a chain run with @xmath439 are shown in magenta , over - plotted on the same obtained using the same data , from a chain in which the number of @xmath240-bins , @xmath440 .",
    "when @xmath264 is fixed as 1 , it implies that @xmath217 is then no longer a variable and then @xmath174 is effectively univariate , depending on @xmath216 alone .",
    "such a state space @xmath0 is an isotropic function of @xmath223 and @xmath90 ( see remark  [ remark : isotropic ] ) .",
    "the @xmath24 estimated from such an isotropic @xmath0 of the state space variable is shown here in green .",
    "the mass density parameters learnt using the data @xmath436again learnt from an isotropic state space @xmath0are shown in black . _",
    "right : _ figure showing estimates of @xmath441 , against @xmath183 . here",
    "the parameters in magenta are obtained from the same chain that produce the @xmath24 parameters in the middle panel using @xmath443 while those in green and black are obtained using the @xmath24 that were represented in the middle panel in the corresponding colours.,width=415 ]",
    "in this work we focused on an inverse problem in which noisy and partially missing data on the measurable @xmath98 is used to make inference on the model parameter vector @xmath3 which is the discretisation of the unknown model function @xmath444 , where @xmath223 is an orthogonal transformation of @xmath6 and @xmath445 .",
    "the measurable and the sought function are related via an unknown function . given that the very physics that connects @xmath60 to @xmath184 is unknown  where @xmath446we can not construct training data , i.e. data comprising a set of computed @xmath447 for a known @xmath188 . in the absence of training data , we are unable to learn the unknown functional relationship between data and model function , either using splines / wavelets or by modelling this unknown function with a gaussian process .",
    "we then perform the estimation of @xmath184 at chosen values of @xmath183 , i.e. discretise the range of values of @xmath183 and estimate the vector @xmath3 instead , where @xmath24 is the value of @xmath188 for @xmath231 in the @xmath23-th @xmath183-bin .",
    "we aim to write the posterior of @xmath3 given the data .",
    "the likelihood could be written as the product of the values of the @xmath0 of the state space vector @xmath91 achieved at each data point , but the data being missing , the @xmath0 is projected onto the space of @xmath60 and the likelihood is written in terms of these projections of the @xmath0 .",
    "@xmath3 is embedded within the definition of the domain of the @xmath0 of @xmath1 .",
    "the projection calls for identification of the mapping between this domain and the unobserved variables @xmath448 ; this is an application specific task .",
    "the likelihood is convolved with the error distribution and vague but proper priors are invoked , leading to the posterior probability of the unknowns given the data .",
    "inference is performed using adaptive mcmc .",
    "the method is used to learn the gravitational mass density of a simulated galaxy using synthetic data , as well as that in the real galaxy ngc3379 , using data of 2 different kinds of galactic particles . the gravitational mass density vector estimated from the 2 independent data sets",
    "are found to be distinct .",
    "the distribution of the gravitational mass in the system is indicated by the function @xmath449 .",
    "the discretised form of this function defines the parameters @xmath450 , @xmath442 .",
    "these are computed using the learnt value of the @xmath24 parameters and plotted in figure  [ fig : anisotropy ] .",
    "we notice that the estimate of @xmath24 can depend on the model chosen for the state space @xmath0 ; thus , the same galaxy can be inferred to be characterised by a higher gravitational mass distribution depending on whether an isotropic state space is invoked or not . turning this result around",
    ", one can argue that in absence of priors on how isotropic the state space of a galaxy really is , the learnt gravitational mass density function might give an erroneous indication of how much gravitational mass there is in this galaxy and of corse how that mass is distributed . it may be remarked that in lieu of such prior knowledge about the topology of the system state space , it is best to consider the least constrained of models for the state space @xmath0 , i.e. to consider this @xmath0 to be dependent on both @xmath216 and @xmath217 .",
    "it is also to be noted that the estimate for the gravitational mass density in the real galaxy ngc3379 appears to depend crucially on which data set is being implemented in the estimation exercise .",
    "it is possible that the underlying @xmath0 of the variable @xmath249 is different for the sub - volume of state space that one set of data vectors are sampled from , compared to another .",
    "as these data vectors are components of @xmath223 and @xmath90 of different kinds of galactic particles , this implies that the state space @xmath0 that the different kinds of galactic particles relax into , are different ."
  ],
  "abstract_text": [
    "<S> in this paper we focus on a type of inverse problem in which the data is expressed as an unknown function of the sought and unknown model function ( or its discretised representation as a model parameter vector ) . </S>",
    "<S> in particular , we deal with situations in which training data is not available </S>",
    "<S> . then we can not model the unknown functional relationship between data and the unknown model function ( or parameter vector ) with a gaussian process of appropriate dimensionality . a bayesian method based on state space modelling </S>",
    "<S> is advanced instead . within this framework , </S>",
    "<S> the likelihood is expressed in terms of the probability density function ( @xmath0 ) of the state space variable and the sought model parameter vector is embedded within the domain of this @xmath0 . as the measurable vector lives only inside an identified sub - volume of the system state space , the @xmath0 of the state space variable is projected onto the space of the measurables , and it is in terms of the projected state space density that the likelihood is written ; the final form of the likelihood is achieved after convolution with the distribution of measurement errors . </S>",
    "<S> application motivated vague priors are invoked and the posterior probability density of the model parameter vectors , given the data is computed . inference is performed by taking posterior samples with adaptive mcmc . </S>",
    "<S> the method is illustrated on synthetic as well as real galactic data . </S>",
    "<S> + * keywords * : bayesian inverse problems ; state space modelling ; missing data ; dark matter in galaxies ; adaptive mcmc .    , </S>"
  ]
}