{
  "article_text": [
    "lossless compression of a discrete information source to its entropy rate @xmath0 is a well studied topic .",
    "a possibly lesser known approach to this problem is one based on symbolic dynamical systems , where the information generating mechanism is modeled by a randomly initialized iterative mapping of the unit interval to itself , and the emitted source sequence is a quantized observation of that process . for well behaved mappings",
    "the source sequence constitutes an _ expansion _ of the initial point , i.e. , corresponds to a unique such point .",
    "furthermore , the prefixes of this expansion describe the initial point with ( exponentially ) increasing resolution , and the unit interval can be uniformly partitioned into @xmath1 subintervals so that with high probability , the subinterval containing the initial point will have all its points admitting the same length-@xmath2 expansion .",
    "this leads to a conceptually simple and optimal compression scheme : a finite source sequence is mapped to a representing subinterval by computing the corresponding reverse trajectory of the dynamical system , and is reconstructed by following the trajectory of an arbitrary point in that subinterval . ] . a comprehensive study of the symbolic dynamics framework for information sources can be found in @xcite .",
    "some of the ideas can be traced back to rnyi , see @xcite and references therein .    in this paper",
    ", we extend the concept above to the lossy source coding regime , under the assumption that a noiseless feedforward link is available .",
    "this setting is described as follows : an encoder observes a stochastic source sequence @xmath3 over some product alphabet @xmath4 , and maps it to a rate @xmath5 index set @xmath6 using some encoding function @xmath7 .",
    "the index is sent to the decoder . at time @xmath8",
    ", the decoder knows the sequence @xmath9 via the feedforward link , and generates an approximation of @xmath10 using a decoding function @xmath11 , where @xmath12 is the reconstruction alphabet .",
    "the quality of the approximation is measured w.r.t . a distortion measure @xmath13 , by evaluating the time - averaged expected distortion : @xmath14 the _ rate - distortion function _ of the source is the infimum of all rates @xmath5 for which there exist encoding and decoding functions achieving a distortion at most @xmath15 , for any @xmath2 large enough .",
    "it is denoted @xmath16 under the feedforward assumption , and @xmath17 where feedforward is absent ( i.e. , when restricting @xmath18 ) .",
    "this model has been initially motivated and studied in the context of competitive prediction @xcite , where it was shown that feedforward does not decrease the rate - distortion function for a large family of sources ( in particular , memoryless ) .",
    "an in - depth analysis of the rate - distortion function with feedforward appears in @xcite . a simple scheme inspired by a successive error compression feedback coding technique and achieving the rate - distortion function for discrete memoryless sources ,",
    "was suggested in @xcite .",
    "another optimal protocol building on the schalkwijk - kailath scheme for channel coding with feedback over the awgn , was suggested for the white gaussian source @xcite . in this paper",
    ", we suggest an alternative approach based in symbolic dynamics and motivated by a recent optimal feedback transmission scheme , termed _ posterior matching _",
    "the suggested approach yields a conceptually simple compression protocol , which is shown to achieve the rate - distortion function for discrete memoryless sources with a bounded distortion measure .",
    "random variables ( r.vs ) are denoted by upper - case letters , their realizations by corresponding lower - case letters .",
    "@xmath19 ( either real or discrete ) is associated with a probability distribution @xmath20 ( over @xmath21 , or over a discrete alphabet @xmath22 ) and we write @xmath23 . the _ cumulative distribution function _",
    "( c.d.f . ) of @xmath19 is denoted by @xmath24 .",
    "we write @xmath25 for expectation and @xmath26 for the probability of an event within the parentheses .",
    "@xmath27 is the entropy of a discrete r.v .",
    "@xmath19 , @xmath28 is the differential entropy of a continuous r.v .",
    "@xmath19 , and @xmath29 is the mutual information between a pair of r.v .",
    "we use @xmath31 for the length of an interval @xmath32 , @xmath33 for @xmath34 , @xmath35 for function composition , @xmath36 for the closure of the set @xmath37 , @xmath38 for the indicator function over the set @xmath37 , @xmath39 for the open unit interval @xmath40 , and @xmath41 for the open unit square . an _",
    "open partition _ of a set @xmath37 ( in what follows , @xmath39 or @xmath42 ) is a family of disjoint open subsets @xmath43 of @xmath37 , such that @xmath44 .",
    "a sequence @xmath45 over a finite alphabet is said to be ( strongly ) @xmath46-typical w.r.t .",
    "@xmath47 , if the ( zero order ) empirical distribution of symbols in @xmath45 is @xmath46-close to the distribution @xmath47 in the supremum norm .",
    "the set of all such length @xmath2 sequences is denoted @xmath48 .",
    "we now turn to define a ( two - dimensional ) _ dynamical source _ , generalizing the definition in @xcite .",
    "note that in the sequel , we discuss in detail a significantly more restrictive family of dynamical sources .",
    "we provide the rather abstract definition below both for future reference , and as we believe it is more instructive .",
    "a dynamical source @xmath49 has the following components :    * a triplet of alphabets @xmath50 . * two open partitions of @xmath39 into open intervals @xmath51 and @xmath52 , and the corresponding product partition @xmath53 of @xmath42 . without loss of generality",
    "we assume that the intervals are arranged from left to right ( or vice versa ) according to the natural alphabet order . * two functions @xmath54 , @xmath55 that are equal to @xmath56 over @xmath57 respectively . * a function @xmath58 , and its corresponding extension to @xmath59 that is constant and equal to @xmath60 when restricted to @xmath61 . *",
    "a mapping @xmath62 of the form @xmath63 such that @xmath64 restricted to each @xmath61 is a continuous bijection , and @xmath65 is an open partition of @xmath42 for each @xmath66 .    setting @xmath67 as an _ initial state _",
    ", the source @xmath49 is associated with the following sequences , all of which are deterministic functions of the initial state :    * the _ state sequence _ @xmath68 over @xmath42 , recursively defined by @xmath69 . * the _ source sequence _ @xmath70 over the alphabet @xmath71 , defined by @xmath72 * the _ component sequences _ @xmath73 over the alphabets @xmath74 respectively , defined by @xmath75    furthermore , any finite source sequence @xmath76 corresponds to a _",
    "fundamental set _",
    "@xmath77 , defined to be the set of all initial states @xmath67 that result in the source sequence @xmath76 .",
    "following @xcite again , a _",
    "probabilistic dynamical source _ is a pair @xmath78 where @xmath49 is a dynamical source , and @xmath79 is a probability measure equivalent to the lebesgue measure over @xmath42 . setting @xmath80 as the initial state , the source @xmath78 is naturally associated with the _ stochastic _ sequences @xmath81 , all of which are deterministic functions of the initial state .",
    "let @xmath78 be a probabilistic dynamical source with @xmath82 , i.e. , one dimensional , and we can assume @xmath83 . in this case the fundamental sets are simply intervals in @xmath39 ( in this section we disregard the redundant dimension ) . under some further contraction conditions ,",
    "an asymptotic equipartition property was shown to hold @xcite , namely @xmath84 tends in probability to the entropy rate @xmath85 of the source sequence .",
    "this immediately leads to an optimal compression protocol : the unit interval is uniformly partitioned into @xmath86 representative intervals .",
    "the trajectory of the dynamical source is reversed using @xmath3 , namely recovering the fundamental interval @xmath87 .",
    "the index of a representative contained in the fundamental interval is used to describe the source sequence . to reconstruct @xmath3 ,",
    "the dynamical source is initialized with any point inside the representative interval .",
    "[ ex1 ] to generate a memoryless source over the alphabet @xmath71 , we set @xmath88 , @xmath89 , and @xmath90 to be affine and map @xmath91 to @xmath39 .",
    "this results in a source sequence that is i.i.d.-@xmath92 , where @xmath93 . if @xmath90 are all monotonically increasing , the fundamental intervals are precisely those generated by the simple arithmetic coding protocol for the source , and coding them ( the typical ones ) as described ( or alternatively , using a variable - rate code to obtain zero error ) results in lossless compression with a rate approaching @xmath94 .",
    "note that in particular for @xmath95 , the source sequence is simply the @xmath96-base expansion of the initial state point .",
    "the continued fraction expansion of a number in @xmath39 can be generated by a dynamical source @xcite . in this case",
    "we have @xmath97 , the open partition is @xmath98 , @xmath89 , and @xmath99 ( mod @xmath100 ) . endowing the source with any probability measure @xmath79 that is equivalent to the lebesgue measure over @xmath39 ,",
    "the state process converges to the invariant distribution that admits the density @xmath101 @xcite .",
    "coding the fundamental intervals as described results in lossless compression with a rate approaching the entropy rate of the continued fraction source , which is given by @xmath102 .",
    "it is interesting to note that in this case , a more efficient ( yet equivalent ) coding mechanism for the fundamental intervals is readily available : represent a finite source sequence @xmath76 by the unique rational number @xmath103 it is the continued fraction expansion of .",
    "it is well known that for almost all @xmath104 ( w.r.t . the lebesgue measure ) , the denominator of the convergents of the continued fraction expansion satisfies @xmath105 @xcite , and so @xmath106 can be represented at a rate of twice this number , which is precisely the entropy rate of the continued fraction source .",
    "in the lossless setting , a finite source sequence was described by efficiently enumerating ( typical ) fundamental sets , obtained via a representation of an initial state up to a suitable resolution . in the lossy setting , we wish to provide only partial information regarding the fundamental set . to that end ,",
    "a two - dimensional dynamical source model was introduced , where the high - level idea is to provide the decoder with a representation of the @xmath107-component of the initial state only . at time @xmath8",
    ", the decoder knows the sequence @xmath9 ( via feedforward ) , and can therefore compute the @xmath107-component @xmath108 that corresponds to the initial state @xmath109 it was given .",
    "this is made possible due to the restriction ( [ eq : t ] ) on the structure of @xmath110 , making its evolution dependent only on the @xmath107-component and the causal knowledge of the source sequence .",
    "had it known the @xmath111-component as well , the decoder could have reconstructed @xmath112 and hence @xmath10 . here , it can only reconstruct @xmath113 , which can serve as an estimate for @xmath10 .",
    "so , our first task is , for a fixed source sequence distribution , to design a probabilistic dynamical source @xmath78 that is consistent with this distribution , and also makes @xmath114 dependent in a prescribed way so that this reconstruction has low distortion .",
    "however , there is an even more difficult obstacle .",
    "the initial @xmath107-component has to be described with a finite rate , and ( loosely speaking ) this should be done while making sure that an initial @xmath111-component can be selected so that the statistical dependence above is roughly maintained . for memoryless sources ,",
    "both tasks can be accomplished .",
    "let @xmath92 be a probability distribution over the alphabet @xmath71 .",
    "there are many different probabilistic dynamical sources for which the source sequence is i.i.d.-@xmath92 .",
    "one simple example was given in the previous section , where @xmath82 and @xmath64 is affine on any @xmath91 , and corresponds to a lossless compression with rate @xmath94 .",
    "however , in two dimensions there is an abundance of distinct probabilistic dynamical sources that admit an i.i.d.-@xmath92 source sequence .",
    "consider any channel @xmath115 from @xmath116 to @xmath19 over the alphabets @xmath117 , let @xmath118 be the joint distribution and let @xmath119 be the corresponding test channel from @xmath19 to @xmath116 .",
    "the following lemma is easily observed @xcite .    [",
    "lem : func ] there exists an alphabet @xmath120 of size @xmath121 , a function @xmath122 , and a r.v . @xmath123",
    "independent of @xmath19 , such that @xmath124 .",
    "now , let us define the following dynamical source @xmath49 .",
    "the construction is motivated by the _ posterior matching scheme _ , a capacity achieving feedback transmission scheme for memoryless channels with feedback @xcite@xcite@xcite .    * @xmath125 for any @xmath126 . *",
    "@xmath127 for any @xmath128 . *",
    "the function @xmath129 is that of lemma [ lem : func ] , @xmath130 its natural extension . *",
    "the mapping @xmath131 is defined as follows : * * let @xmath132 be the conditional c.d.f . for @xmath115 . for any fixed @xmath66 , @xmath133 is a continuous non - decreasing function from @xmath39 onto @xmath39 , is affine on each @xmath91 , and is equal to @xmath134 on the right edge of @xmath135 . *",
    "* @xmath136 is one dimensional , affine on each @xmath137 and maps it onto @xmath39 .",
    "note that when @xmath115 is noiseless ( e.g. , @xmath138 ) then @xmath49 collapses to the one dimensional lossless construction of example [ ex1 ] .",
    "[ lem : fund_set ] for any @xmath139 , the fundamental set @xmath140 of the dynamical source @xmath49 is a finite disjoint union of product rectangles .",
    "the projections of these rectangles onto the @xmath107-axis form a set of at most @xmath141 distinct intervals .",
    "the first assertion follows easily from the affinity of @xmath64 . for @xmath142 ,",
    "the number of distinct intervals on the @xmath107-axis is exactly @xmath143 . for any fixed @xmath66",
    ", @xmath144 is quasi - affine over @xmath39 as a function of @xmath145 , with at most @xmath146 corner points .",
    "hence the number of distinct intervals can increase by at most @xmath146 at each step .",
    "the following lemma is adapted from @xcite .",
    "[ lem : pm ] let @xmath147 .",
    "the probabilistic dynamical source @xmath78 has the following properties :    a.   the sequence @xmath148 is i.i.d.-@xmath149 , @xmath150 is statistically independent of @xmath151 .",
    "b.   @xmath152 , @xmath153 is statistically independent of @xmath154 c.   the source sequence @xmath155 is i.i.d.-@xmath92 , and @xmath156 form a markov chain .",
    "d.   @xmath157    assertion ( a ) is immediate : @xmath158 is a deterministic function of @xmath159 and evolves according to the memoryless dynamical law described in example [ ex1 ] , hence is i.i.d-@xmath149 .",
    "furthermore , @xmath151 is a deterministic function of @xmath160 which are mutually independent of @xmath150 . for the other assertions ,",
    "see @xcite .",
    "define @xmath161 namely , the interval @xmath162 is obtained by reversing the trajectory of the ( edges of the ) interval @xmath163 .",
    "the following result , also adapted from @xcite , is central to our derivations .",
    "[ thrm : pm ] suppose that @xmath164 is strictly positive over @xmath165 , and that for any fixed @xmath104 , @xmath166 is not a constant function of @xmath167 .",
    "then for any @xmath168 ,    a.   @xmath169 for any @xmath170",
    ". b.   @xmath171 .",
    "loosely speaking , theorem [ thrm : pm ] implies that by observing the source sequence , the initial @xmath109 component of the state sequence can be found up to a resolution of @xmath172 . in a feedback communication setting ,",
    "this initial value represents a _ message _ to be sent over the channel @xmath119 , and this concentration result means that one can reliably transmit roughly @xmath173 such messages and decode them with high reliability , which corresponds to a communication rate of _ at most _",
    "@xmath29 bits per channel use . in order to be able to generate @xmath153 ( channel input )",
    "the encoder needs to know the @xmath154 on top of the message @xmath109 , hence the feedback . in the dual lossy source coding with feedforward",
    "setting we consider , @xmath109 plays the role of a lossy description of the source sequence , and we will need _ at least _",
    "@xmath29 bits per source symbol to represent it with high enough accuracy . in order to be able to generate @xmath153 ( lossy reconstruction of @xmath174 ) the decoder needs to know the @xmath154 on top of the ( quantized representation of the ) lossy description @xmath109 , hence the feedforward .",
    "fix the block size @xmath2 , and set @xmath175 for some @xmath176 .",
    "let @xmath177 be an open partition of @xmath39 into equi - sized intervals , and let @xmath178 be the midpoint of @xmath179 .",
    "denote the set of all midpoints by @xmath180 .",
    "[ lem : typical]@xmath181 .    for lack of space",
    "we only describe the main elements of the proof , skipping some details .",
    "let @xmath182 be the set of indices @xmath183 such that @xmath184 , and @xmath179 intersects with two or more intervals that are projections of a product rectangle in @xmath140 onto the @xmath107-axis .",
    "by lemma [ lem : fund_set ] , @xmath185 .",
    "define @xmath186 and consider theorem [ thrm : pm ] with a rate @xmath187 .",
    "now , assume to the contrary that @xmath188 for some fixed @xmath189 , i.e. , with probability at least @xmath190 the distribution of @xmath109 given @xmath3 has a mass at least @xmath191 inside that polynomial sized set of intervals .",
    "then we have ( some transitions assuming @xmath2 large enough ) @xmath192 \\\\",
    "\\nonumber   & \\hspace{0.5cm}+n^{-1}(1-{\\varepsilon}_3)(1 - 2{\\varepsilon})\\log((1 - 2{\\varepsilon})\\cdot 2^{n(i(x;y)-{\\varepsilon}_1 ) } ) \\\\ & = ( 1 - 2{\\varepsilon})\\cdot i(x;y ) + \\delta{\\varepsilon}_2{\\varepsilon}_3 - { \\varepsilon}_1(1 - 2{\\varepsilon}-{\\varepsilon}_2{\\varepsilon}_3 ) + o(\\log{n}\\slash n)\\end{aligned}\\ ] ] where we have used the concentration result of theorem [ thrm : pm ] for the inequality transition .",
    "since @xmath193 can be taken arbitrarily small for @xmath2 large enough , the right - hand - side of ( [ eq : conc ] ) can be made larger than @xmath29 , contradicting lemma [ lem : pm ] .",
    "note that this argument is similar in essence to the converse to the channel coding theorem @xcite .",
    "we conclude that @xmath194 in probability , which loosely speaking means that with high probability , @xmath195 is mostly concentrated on @xmath196 for large @xmath2 . using typicality arguments together with the properties in lemma [ lem : pm ] ,",
    "this can be shown to imply that with high probability we can find @xmath107 in that set together with some @xmath111 such that @xmath197 and @xmath198 . by definition ,",
    "@xmath199 where @xmath179 is a subset of some interval which is a projection of a product rectangle in @xmath200 .",
    "this is turn implies that @xmath201 and @xmath202 , concluding the proof .",
    "we are now ready to describe the compression protocol .",
    "a.   given the sequence @xmath76 , compute @xmath203 using the recursion ( [ eq : dec_set ] ) .",
    "b.   [ item : enc]out of the @xmath204 intervals @xmath205 , find the one with the least index @xmath183 , for which there exists @xmath206 such that @xmath207 .",
    "if no such index exists , arbitrarily set @xmath208 . c.   send the index @xmath183 to the decoder , which requires a rate of @xmath209 bits per source symbol .",
    "a.   initialization : set @xmath210 , compute @xmath211 .",
    "b.   for any @xmath8 , predict @xmath212[repstep1 ] .",
    "c.   receive the true @xmath213 via the feedforward link , compute @xmath214 and @xmath215[repstep2 ] .",
    "d.   repeat steps ( [ repstep1])([repstep2 ] ) up to @xmath216 .",
    "the compression rate attained by the scheme is @xmath217 .",
    "if encoding step ( [ item : enc ] ) is successful then the pair @xmath218 is jointly @xmath219-typical , which implies that @xmath220 is jointly @xmath164-typical . by lemma [ lem : typical ] , when encoding an i.i.d-@xmath92 sequence @xmath3 this occurs with probability approaching @xmath100 as @xmath221 .",
    "since the distortion measure is bounded , the expected distortion achieved by the scheme is given by @xmath222 .",
    "the development above holds for any @xmath92 and @xmath115 that satisfy the requirements of theorem [ thrm : pm ] .",
    "the strict positivity constraint for @xmath164 has a negligible effect , since such distributions can always be approximated arbitrarily via admissible distributions , and the distortion measure is bounded .",
    "the second constraint is redundant as it can always be averted by using a variant of the the probabilistic dynamical source , as in the channel coding case @xcite@xcite .",
    "hence , we have proved the following result .    for any discrete memoryless source and",
    "bounded distortion measure , the protocol described above can perform arbitrarily close to the rate distortion function of the source .",
    "let @xmath223 , @xmath224 , @xmath225 the hamming distortion measure .",
    "the rate distortion function @xmath226 is achieved by @xmath227 , @xmath228 independent of @xmath19 , and @xmath229 ( mod @xmath230 ) .",
    "the partitions and mappings are given by @xmath231 @xmath232 @xmath233 @xmath234 @xmath235 the mappings and the fundamental sets for @xmath236 are depicted in figures [ fig : t ] and [ fig : fund_sets ] .",
    "a symbolic dynamical system approach to lossy source coding with feedforward was introduced , yielding in particular a conceptually simple and optimal compression protocol for memoryless sources . in this latter case ,",
    "the construction is dual to the posterior matching feedback communication scheme for memoryless channels .",
    "future work should examine the suggested framework for sources with memory .",
    "a reasonable first goal could be the case where the @xmath111-component of the dynamical source evolves independently as in the memoryless case , yet generates e.g. a markovian @xmath237 ."
  ],
  "abstract_text": [
    "<S> it is known that modeling an information source via a symbolic dynamical system evolving over the unit interval , leads to a natural lossless compression scheme attaining the entropy rate of the source , under general conditions . </S>",
    "<S> we extend this notion to the lossy compression regime assuming a feedforward link is available , by modeling a source via a two - dimensional symbolic dynamical system where one component corresponds to the compressed signal , and the other essentially corresponds to the feedforward signal . for memoryless sources and an arbitrary bounded distortion measure , we show this approach leads to a family of simple deterministic compression schemes that attain the rate - distortion function of the source . </S>",
    "<S> the construction is dual to a recent optimal scheme for channel coding with feedback . </S>"
  ]
}