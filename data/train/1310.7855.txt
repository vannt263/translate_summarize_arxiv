{
  "article_text": [
    "the mean shift algorithm was introduced by fukunaga and hostetler in a seminal paper in 1975 @xcite , with the goal of estimating the gradient of a multivariate density .",
    "they also showed that their algorithm can be helpful for many applications in several pattern recognition problems , and particularly pointed out its usefulness for clustering and data filtering .",
    "even if this algorithm was highlighted in the popular book by silverman @xcite as an important application of kernel smoothing , it remained relatively neglected in the statistics literature , until it was  re - discovered \" by cheng @xcite , carreira - perpin @xcite and comaniciu and meer @xcite for its applications in engineering .",
    "some recent contributions that make use of the mean shift algorithm , either explicitly or implicitly , are @xcite , @xcite , @xcite or @xcite .",
    "being closely related to the problem of density gradient estimation , the mean shift algorithm inherits its dependence on the choice of a suitable bandwidth matrix .",
    "it was only recently ( see @xcite and @xcite ) that automatic methods for bandwidth selection for density gradient estimation were proposed .",
    "the goal of this paper is to provide a comparative study of the performance of these automatic bandwidth selectors , not with respect to the problem of density gradient estimation , but regarding the clustering of the space that they induce via the mean shift algorithm .",
    "the rest of the paper is organized as follows . in section 2 below the clustering procedure derived from the mean shift algorithm",
    "is introduced . a brief review of the existing bandwidth matrix selectors for density gradient estimation is contained in section 3 .",
    "the details of the simulation study comparing these methodologies are given in section 4 and some conclusions are discussed in section 5 .",
    "finally , we show in an appendix the ascending property of the mean shift algorithm with an unconstrained bandwidth matrix .",
    "let us consider a probability density @xmath0 , and denote by @xmath1 its gradient vector , so that with the usual column notation for vectors @xmath2 we have @xmath3 with @xmath4 standing for the transpose operator .",
    "the mean shift algorithm is a variant of the well - known gradient ascent algorithm which is usually employed to find the local maxima of a given function .",
    "explicitly , given any starting point @xmath5 , the mean shift algorithm iteratively constructs a sequence @xmath6 according to the following updating mechanism @xmath7 where @xmath8 is a @xmath9 positive definite matrix conveniently chosen to guarantee the convergence of the sequence .",
    "the only difference with the usual gradient ascent algorithm is that ( [ eq : meanshift ] ) uses the normalized gradient @xmath10 to accelerate the convergence when the starting point belongs to a low - density zone .",
    "since the shift at every step is done approximately along the gradient direction it follows that the limit point of the mean shift sequence should be a local maximum of @xmath11 ( i.e. , a mode of the density ) .",
    "this induces a clustering scheme in which any two points are said to belong to the same cluster whenever the sequences constructed from them as starting points converge to the same mode of @xmath11 . in that case , it is also common to say that the two points belong to the same domain of attraction of such local maximum , and this type of clustering is called _",
    "modal clustering_.    moreover , since the mean shift algorithm is applicable with any point in @xmath12 as starting point , eventually this clustering scheme induces a partition of the whole space @xmath12 into disjoint clusters .",
    "this partition , built up from the knowledge of the density @xmath11 , will be referred to as the ideal population clustering .",
    "a precise definition of this ideal population clustering can be found in @xcite .",
    "when the density @xmath11 is unknown , but a sample @xmath13 from @xmath11 is observed instead , the mean shift algorithm ( [ eq : meanshift ] ) , with the density and the density gradient estimated from the sample , yields a data - based clustering of the whole space @xmath12 .",
    "the goal of most clustering methodologies is not to partition @xmath12 , but only the data sample .",
    "nevertheless , it is clear that by partitioning the whole space the mean shift algorithm induces , in particular , a clustering of the data by assigning two data points to the same cluster if they belong to the same component of the aforementioned partition of @xmath12 .",
    "the density and density gradient estimators considered here are of kernel type .",
    "the kernel density estimator has the form @xmath14 where the kernel @xmath15 is a spherically symmetric @xmath16-variate density function , the bandwidth matrix @xmath17 is symmetric and positive definite , and we have used the re - scaling notation @xmath18 ( see @xcite , chapter 4 ) . then , following @xcite , the density gradient estimator is just the gradient of the kernel density estimator , given by @xmath19    being symmetric , the kernel @xmath15 can be expressed as @xmath20 , where the function @xmath21 is known as the profile of @xmath15 ( see @xcite ) .",
    "furthermore , the kernel @xmath15 is usually assumed to be smooth and unimodal , so that @xmath22 .",
    "thus , following the ideas of @xcite , @xcite showed that a sensible estimator of the normalized gradient @xmath23 is @xmath24 , where the term @xmath25 is known as the _",
    "mean shift_. it is the difference between a weighted mean of the data and @xmath26 , with the weights @xmath27 defined as @xmath28 where @xmath29 denotes the mahalanobis distance @xmath30 .",
    "hence , by plugging this estimate in ( [ eq : meanshift ] ) and taking @xmath31 , the updating mechanism of the data - based mean shift algorithm simply reads @xmath32    originally , @xcite developed the mean shift algorithm using a constrained bandwidth matrix consisting of a scalar @xmath33 times the identity matrix , @xmath34 , and @xcite showed that for this constrained form the choice of @xmath31 guarantees that the mean shift sequence is convergent , as long as the kernel @xmath15 has a convex and monotonically decreasing profile @xmath35 . in the appendix below we show that ( [ eq : ms2 ] ) , the unconstrained version of the mean shift algorithm , is also convergent .",
    "as it is common for all kernel smoothing methods , the performance of mean shift clustering is highly influenced by the choice of the bandwidth matrix .",
    "since the element having the biggest impact on the performance of the mean shift algorithm appears to be the density gradient , it seems reasonable that a bandwidth matrix chosen to obtain a good kernel density gradient estimate could lead to an appealing clustering via the mean shift algorithm .",
    "surprisingly , the literature tackling the problem of automatic , data - based bandwidth matrix selection for kernel density gradient estimation is quite scant and recent .",
    "we are aware only of two contributions dealing with this problem : @xcite and @xcite . in both papers the measure to evaluate the performance of the kernel density gradient estimator @xmath36 is the mean integrated squared error , defined as @xmath37 where @xmath38 denotes the usual euclidean norm in @xmath12 . with this goal in mind ,",
    "the optimal bandwidth for kernel density gradient estimation is taken to be @xmath39 , the minimizer of the mise function over the class of all symmetric positive definite matrices .    in @xcite ,",
    "three bandwidth matrix selectors were proposed for kernel estimation of the @xmath40-th derivative of a multivariate density @xmath11 , for arbitrary @xmath40 .",
    "they are defined as the minimizers of certain criteria which aim to estimate the mise .",
    "these criteria can be shown to generalize the well - known cross validation ( cv ) , plug - in ( pi ) and smooth cross validation ( scv ) methodologies proposed earlier for the base case of univariate density estimation ( i.e. , @xmath41 and @xmath42 ) . in the case of the density gradient ( arbitrary @xmath16 and @xmath43 ) , these criteria can be written as @xmath44^{-1}\\sum_{i\\neq j}\\nabla^2 k_\\mathbf h(\\mathbf x_i-\\mathbf x_j)\\\\ { \\rm pi}(\\mathbf h)&= n^{-1}|\\mathbf h|^{-1/2}{\\rm tr}\\big\\{\\mathbf h^{-1}\\mathbf r(\\mathsf dk)\\big\\}\\\\&\\quad- \\tfrac{1}{4 } \\{({\\rm vec}^\\top\\mathbf i_{d } ) \\otimes ( { \\rm vec}^\\top \\mathbf h ) \\otimes ( { \\rm vec}^\\top \\mathbf h)\\ } n^{-2 } \\sum_{i , j=1}^n \\mathsf d^{\\otimes 6 } k_\\mathbf g ( \\mathbf x_i - \\mathbf x_j)\\\\ { \\rm scv}(\\mathbf",
    "h)&=n^{-1}|\\mathbf h|^{-1/2}{\\rm tr}\\big\\{\\mathbf h^{-1}\\mathbf r(\\mathsf dk)\\big\\ } \\\\ & \\quad - n^{-2}\\sum_{i , j=1}^n\\nabla^2\\big\\{k_{2\\mathbf h+2\\mathbf g}-2k_{\\mathbf h+2\\mathbf g}+k_{2\\mathbf g}\\big\\}(\\mathbf x_i-\\mathbf x_j),\\end{aligned}\\ ] ] respectively . here",
    ", @xmath45 is the laplace operator , @xmath46 denotes the trace operator , @xmath47 is the vectorization operator that transforms a matrix into a vector by stacking the columns of the matrix one underneath the other , @xmath48 denotes the kronecker product , @xmath49 is a @xmath9 matrix , the vector @xmath50 includes all 6-th order partial derivatives of @xmath51 , arranged in a particular order ( see @xcite ) , and @xmath52 is a pilot bandwidth matrix .",
    "computation of these criteria is not simple , but efficient implementations were proposed in @xcite .    in @xcite an iterative method ( it )",
    "was proposed to treat the cases @xmath42 and @xmath43 for arbitrary @xmath16 .",
    "these authors noted that the asymptotic approximation of the optimal bandwidth @xmath39 , so - called @xmath53 , can be characterized as the solution of a particular equation involving the unknown density @xmath11 .",
    "so a sensible choice for the bandwidth is introduced as the solution of a data - based estimate of this equation , which for @xmath43 can be written as @xmath54 again , the computational details to obtain the solution of this equation are not simple , and an iterative method to solve it ( hence the name of this bandwidth selector ) is proposed in @xcite .",
    "all these methodologies focus on the most general form for the bandwidth matrix @xmath17 , which is only required to be symmetric and positive definite .",
    "other popular choices for the bandwidth matrix include constrained forms such as @xmath17 being diagonal , @xmath55 , or the parametrization using a single bandwidth @xmath34 so that @xmath56 , with @xmath57 denoting the @xmath9 identity matrix .",
    "the thorough study of @xcite reported that for density estimation , in general , the diagonal parametrization results in a small loss of efficiency , but the single - bandwidth estimator should not be blindly used for unscaled multivariate data ( see also @xcite ) . for density derivative estimation , @xcite showed that the loss of efficiency due to the use of simpler bandwidth matrix parametrizations can be even more severe .",
    "however , the goal of cluster analysis is quite different from that of density estimation , so that not very precise density estimates may equally lead to nearly optimal clusterings ( see @xcite , figure 6 , for an illustration of this phenomenon ) , so in principle the simpler parametrizations should not be completely discarded .",
    "in fact , the very simple diagonal bandwidth proposal of @xcite was shown to produce good results in @xcite .",
    "therefore , unconstrained but also diagonal bandwidth matrices will be considered in the simulation study below .",
    "the main goal of this paper is to provide an empirical comparison of the performance of several bandwidth selection methods for mean shift clustering .",
    "five true models are analyzed in the study , which cover a wide variety of cluster shapes .",
    "two of these densities are normal mixture densities ; hence a parametric cluster analysis of these two models , by fitting an estimated density through maximum likelihood , would probably yield quite good results ( see @xcite , and references therein ) . but to exploit the nonparametric nature of the mean shift approach we also include three densities with more intricate features which are not likely to be accurately recovered in a parametric setup .",
    "figure [ fig:1 ] shows the true densities and the ideal population clusterings associated to each of these models , along with the names which we will use to refer to them .",
    "a precise definition of these models can be found in @xcite .",
    "@cc@ trimodal iii & quadrimodal + & + 4-crescent & broken ring + & +    [ cols=\"^ \" , ]     in view of table [ tab:1 ] it is clear that no bandwidth selector is uniformly preferable over the others .",
    "however , it seems clear that nr and at nearly always induced a poor clustering ( an exception is nr for the broken ring model ) .",
    "the reason for this bad performance could be partially explained by table [ tab:2 ] .",
    "there it is shown the distribution of the number of clusters obtained by each method along the 100 simulation runs for each density model ( some unusually large number of clusters have been omitted for clarity ) . in table",
    "[ tab:2 ] it is possible to appreciate that both nr and at normally induce a number of clusters smaller than those appearing in the true model , which can be interpreted as a well - known oversmoothing effect , due to the fact that these two bandwidth selectors are based on a normal reference rule . as noted before , an exception is the broken ring model , where nr correctly identifies 5 clusters in all the cases .",
    "we acknowledge , however , that the density clustering approach of azzalini and torelli @xcite is not based on the mean shift algorithm ; the goal here was to test if their appealingly simple bandwidth proposal were also suitable for mean shift clustering .",
    "the performance of the it methods is somehow erratic .",
    "itu is the best method for the trimodal mixture density , and has moderately good results for the quadrimodal mixture density as well , but both itu and it d are unable to deal with more complicated features like those appearing in the last three density models .",
    "again , a partial explanation for this is provided in table [ tab:2 ] , where it is shown that itu , and especially it d , tend to partition the space in only one cluster , thus presenting a highly oversmoothed estimate . the fact that both methods found only one cluster in all the cases for the broken ring model is the reason why the iqr of the distribution of their distances in measure is exactly zero ( the distance in measure is a constant variable in this case ) .",
    "the pi bandwidth selectors induce the clusterings with lowest distance in measure for the broken ring and eye models , and are close to the best performance in the two normal mixture density models , ranking second to best in terms of median error .",
    "they fail , however , to capture the features of the 4-crescent density , with a tendency to find more clusters than present ( as seen in table [ tab:2 ] ) .",
    "the cv bandwidths perform disappointingly in the case of the trimodal mixture density , but cvu ranks first for the quadrimodal density model and both cvu and cvd obtain moderately good results for the densities with complicated features , frequently finding the right number of clusters .",
    "both scv proposals are probably the best ones concerning the right number of clusters for the densities with complicated features , and indeed they have the best marks for the 4-crescent model , but their behaviour is far from optimal for the normal mixture densities , with performances close to nr and at .    with respect to the unconstrained - diagonal bandwidth dilemma , our study seems to suggest that diagonal bandwidths perform worse than their unconstrained counterparts in most of the cases .",
    "however , perhaps the use of diagonal matrices should not be blindly discarded , since indeed in some cases their performance is comparable or even slightly better than that of the unconstrained ones , but with a clearly smaller computational cost .",
    "we explored here the influence of the bandwidth matrix in the mean shift algorithm from the point of view of modal clustering . due to the crucial influence of the density gradient estimate in the mean shift algorithm we analyzed the practical performance of ten bandwidth selectors originally designed for density gradient estimation .",
    "none of the ten automatic bandwidth matrix selectors showed a consistent superior performance over the rest of the methods in our simulation study , but surely neither nr nor at can be recommended for general use .",
    "all the cv , pi , scv and it proposals are best for one of the models , but utterly fail to identify the cluster structure for one , two or even three of the remaining ones .",
    "this suggests that the problem of bandwidth selection for mean shift clustering , though related , is different from that of bandwidth selection for density gradient estimation , and presents its own peculiarities , which undoubtedly deserve to be studied in further detail .    since cvu and piu are the only methods that failed solely for one of the density models , any of these two bandwidth matrix selectors would represent a cautious recommendation in practice , out of the ten methods studied here .",
    "* acknowledgements .",
    "* we would like to express our gratitude to prof .",
    "ivana horov for encouraging us to write this contribution , and to dr .",
    "kamila vopatov for sharing their code for the iterative bandwidth computation .",
    "the first author wishes to extend thanks to the whole research group leaded by prof .",
    "horov in brno ( czech republic ) for their hospitality during his visit to the masaryk university .",
    "this work has been supported by grant mtm2010 - 16660 from the spanish ministerio de ciencia e innovacin .",
    "here it is shown that when the profile of the kernel is a bounded , convex , non - increasing , differentiable function , then the mean shift is an ascending algorithm ; that is , the points of the sequence @xmath6 obtained through the mean shift algorithm attain sequentially increasing values of the estimated density @xmath58 , so that the sequence @xmath59 is convergent .    notice that since @xmath60 it follows that @xmath61 .",
    "therefore , @xmath62 then , following @xcite , the convexity of the profile @xmath35 implies that @xmath63 hence , expanding the difference between the two mahalanobis distances we obtain @xmath64 but definition ( [ eq : ms2 ] ) of the updating step entails that @xmath65 so that it is possible to replace @xmath66 for @xmath67 in the last term of the previous display , and simplify to get @xmath68 so the sequence @xmath59 is non - decreasing and bounded , hence convergent .",
    "comaniciu , d. and meer , p. ( 2002 ) mean shift : a robust approach toward feature space analysis .",
    "_ ieee trans .",
    "pattern anal .",
    "_ , * 24 * , 603619 .",
    "fukunaga , k. and hostetler , l.d .",
    "( 1975 ) the estimation of the gradient of a density function , with applications in pattern recognition .",
    "_ ieee trans .",
    "inform . theory _ ,",
    "* 21 * , 3240 ."
  ],
  "abstract_text": [
    "<S> we explore the performance of several automatic bandwidth selectors , originally designed for density gradient estimation , as data - based procedures for nonparametric , modal clustering . </S>",
    "<S> the key tool to obtain a clustering from density gradient estimators is the mean shift algorithm , which allows to obtain a partition not only of the data sample , but also of the whole space . </S>",
    "<S> the results of our simulation study suggest that most of the methods considered here , like cross validation and plug in bandwidth selectors , are useful for cluster analysis via the mean shift algorithm . </S>"
  ]
}