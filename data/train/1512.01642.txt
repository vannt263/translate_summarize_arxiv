{
  "article_text": [
    "in computer vision , it has received increasing attention in human activity understanding to determine what people are doing given an observed video in different application domains , e.g. intelligent surveillance , robotics , and human - computer interaction .",
    "recently developed 3d / depth sensors have opened up new opportunities with enormous commercial values , which provide more rich information ( e.g. extra depth data of scenes and objects ) compared with the traditional cameras . built upon the enriched information ,",
    "human poses can be estimated more easily . however , modeling complicated human activities still remains challenging , mainly due to the following difficulties .    *",
    "( * a * ) the complexity of representing high - level activities with the rich appearance and motion information from video .",
    "the actors may appear in diverse views or poses under different motions , and the surrounding objects and environments can also vary within the same activity category . moreover , the depth maps provided by the 3d sensors are often unavoidably contaminated @xcite due to the noise or the self - occlusion of the body parts . *",
    "( * b * ) the ambiguity in the temporal segmentation of the sub - activities which constitute an activity .",
    "an activity can be considered as a sequence of actions ( i.e. sub - activities ) occurred over time @xcite .",
    "for instance , the activity of `` microwaving food '' can be temporally decomposed into several parts such as picking up food , walking and operating microwave .",
    "however , the activity composition may vary for a category of activity instances .",
    "figure  [ fig : motivation ] shows two activities belonging to the same category , where the temporal lengths of decomposed actions are different for different subjects .",
    "it is therefore difficult to capture the temporal variation of activities during the category recognition .",
    "most of previous methods recognize 3d human activities by training discriminative / generative classifiers based on carefully designed features  @xcite .",
    "these approaches often require sufficient domain knowledge and heavy feature engineering because of the difficulty ( * a * ) , which could limit their applications . to improve the discriminative performance , some compositional methods  @xcite model complex activities by segmenting the videos into temporal segments of fixed length .",
    "but because of the difficulty ( * b * ) , they may have problems handling complex activities composed of actions of diverse temporal durations , e.g. the examples in figure  [ fig : motivation ] .    in this work ,",
    "we develop a deep structured human activity model to address the above mentioned challenges , and demonstrate superior performance over other state - of - the - art approaches on the task of recognizing human activities from grayscale - depth videos which are captured by a rgb - d camera ( i.e. microsoft kinect ) .",
    "our model adaptively represents the input activity instance as a sequence of temporally separated sub - activities , and each one is associated with a cubic - like video segment of a flexible length .",
    "our model is inspired by the effectiveness of two widely successful techniques : deep learning @xcite and the latent structured models @xcite .",
    "one example of the former is convolutional neural networks ( cnns ) , which was recently applied to generate powerful features for video classification @xcite . on the other hand , the latent structured models ( such as deformable part - based model @xcite )",
    "have been demonstrated as an effective class of models for handling large object variations for recognition and detection .",
    "one of the key components in these models is the reconfigurable flexibility of model structure , which often implemented by estimating latent variables during inference .",
    "we adopt the deep cnn architecture @xcite to layer - wisely extract features from the input video data , and the architecture are vertically decomposed into several sub - networks corresponding to the video segments , as figure [ fig : architecture ] illustrates .",
    "in particular , our model searches for the optimal composition for each activity instance during the recognition , which is the key to handle the temporal variation of human activities . moreover , we introduce relaxed radius - margin bound into our deep model , which effectively improves the generalization performance for classification . in the following ,",
    "we briefly overview the main components of our model and summarize the advantages .",
    "first , the configuration of our deep model can be flexibly adjusted to adapt to different input videos , and the significance of this property has been justified for human action recognition @xcite . in our approach , we make our model adaptively capture temporal structure by using the latent variables .",
    "this motivation finely accords with a batch of existing part - based structured models in visual recognition @xcite .",
    "more specifically , we utilize the latent variables to explicitly represent the temporal composition of the human activities , i.e. the input video is partitioned into several segments of alterable lengths ( each segment indicating a sub - activity ) .",
    "the different temporal compositions actually correspond to the different temporal durations of the separated sub - activities . and",
    "the frames of different video segments are extracted to feed to the corresponding sub - networks .     during the inference of activity recognition , we aggregate the responses from sub - networks while searching for the optimal temporal activity segmentation .",
    "this inference will inevitably cause extra computation cost just like traditional latent structured models  @xcite .",
    "it is worth mentioning that we can implement the inference in a parallel manner using gpu ( graphic processing unit ) programming , in order to counter - balance the extra computational demand .",
    "second , we integrate the radius - margin regularization with the deep feature learning , effectively conducting the classification with good generalization performance . collecting 3d data of human activities is relatively expensive in practice , while the large amount of training data plays a critical role in recent successful deep learning approaches @xcite . on the other hand ,",
    "the max - margin methods ( e.g. support vector machines ) have shown very impressive generalization power and thus been widely applied for small scale training data . according to @xcite , their performance ( i.e. the error rate ) for classification",
    "depends on not only the margin of positive / negative samples but also the radius of the enclosing ball of all samples , and this is more critical for joint learning of feature representation and classifier .",
    "inspired by these works , we incorporate a radius - margin bound as a regularizer into our deep model , and demonstrate better generalization performance compared to the softmax or svm classifier .",
    "more detailed discussion will be presented section 3.3 .",
    "training our deep structured model is nontrivial , as it needs to jointly optimize three components : ( i ) the activity decomposition , ( ii ) the classifier upon the generated features , and ( iii ) the neural networks . seeking the global optimum for such a model",
    "is extremely intractable due to the non - convexity , and we consider an approximate solution by iteratively optimizing these components for a local convergence . in each iteration",
    ", the learning algorithm performs the following three steps .    1 .",
    "we compute the optimal latent variables ( i.e. sub - activity decompositions ) for all training activities , and their feature vectors are then specified .",
    "2 .   based on the generated features , we optimize the classification margin of all training examples under the fixed radius bound .",
    "3 .   we learn the parameters of the cnns using the traditional backward propagation , which will lead to the decrease of the radius .",
    "the main contributions of this work are several folds .",
    "first , we present a novel deep neural network model to handle various challenges in 3d human activity recognition , and demonstrate superior performance over state - of - the - art approaches under several challenging scenarios .",
    "second , our deep model incorporates latent temporal structure to account for large temporal variations of diverse human activities . to the best of our knowledge ,",
    "this is a novel contribution to the literature of deep learning .",
    "third , we unify the radius - margin method with the feature learning in a principled way , providing a very general framework for many classification tasks .",
    "in addition , we construct a new database of rgb - d data , which includes 1180 instances of human activities in 20 categories .",
    "the remainder of the paper is organized as follows .",
    "section 2 presents a review of related work .",
    "then we present our deep model in section 3 and 4 , followed by a description of model learning algorithm in section 5 .",
    "section 6 discusses the procedure of activity recognition using our model .",
    "the experimental results , comparisons and component analysis are exhibited in section 6 .",
    "section 7 concludes this paper .",
    "many works on human action / activity recognition mainly focus on designing robust and descriptive features  @xcite .",
    "for example , xia and aggarwal  @xcite extracted spatio - temporal interest points from depth videos ( dstip ) and developed a depth cuboid similarity feature ( dcsf ) to model human activities .",
    "oreifej and liu  @xcite proposed to capture spatio - temporal changes of activities by using a histogram of oriented 4d surface normals ( hon4d ) . most of these methods , however , overlooked detailed spatio - temporal structure information , and limited in periodic activities .",
    "several compositional part - based approaches have been studied for complex scenarios and achieved substantial progresses @xcite , and they represent an activity with the deformable parts and contextual relations .",
    "for instance , wang et al .",
    "@xcite recognized human activities in common videos by training the hidden conditional random fields in a max - margin framework . for activity recognition in rgb - d data , packer et al .",
    "@xcite employed the latent structural svm to train the model with part - based pose trajectories and object manipulations .",
    "an ensemble model of actionlets were studied in @xcite to represent 3d human activities with a new feature called local occupancy pattern ( lop ) . to handle more complicated activities with large temporal variations , some improved models  @xcite discovered temporal structures of activities by localizing sequential actions .",
    "for example , wang and wu  @xcite proposed to solve the temporal alignment of actions by maximum margin temporal warping .",
    "tang et al .  @xcite captured the latent temporal structures of 2d activities based on the variable - duration hidden markov model .",
    "koppula and saxena  @xcite applied the conditional random fields to model the sub - activities and affordances of the objects for 3d activity recognition .",
    "recently , the and - or graph representations are introduced as extensions of the part - based models  @xcite , and produce very competitive performance to deal with large data variations .",
    "these models incorporate not only the hierarchical decompositions , but also the explicit structural alternatives ( e.g. the different ways of compositions ) .",
    "zhu and mumford  @xcite first explored the and - or graph models for image parsing .",
    "pei et al .",
    "@xcite then introduced the models for video event understanding , but their approach required elaborate annotations .",
    "liang et al .",
    "@xcite proposed to train the spatio - temporal and - or graph model using a non - convex formulation , which is discriminatively trained from weakly annotated training data .",
    "however , the above mentioned models rely on the hand - crafted features , and their discriminative capacities are not optimized for 3d human activity recognition .    in the mean time , the past few years have seen a resurgence of research in the design of deep neutral networks , and impressive progresses have been made on learning image features from raw data  @xcite . to address human action recognition from videos , ji et al .",
    "@xcite developed a novel deep architecture of convolutional networks , where they extracted features from both spatial and temporal dimensions .",
    "luo et al .",
    "@xcite proposed to incorporate a new switchable restricted boltzmann machine ( srbm ) to explicitly model the complex mixture of visual appearance for pedestrian detection , and train their model using an em - type interative algorithm .",
    "amer and todorovic  @xcite applied sum product networks ( spns ) to model human activities based on variable primitive actions .",
    "our deep model is partially motivated by these works , and we target on an more flexible and powerful solution by jointly considering the latent structure embedding , feature learning , and radius - margin classification .",
    "recently , recurrent neural networks ( rnn ) has been used for activity recognition due to its capability in modeling complex temporal dynamics .",
    "donahue et al .",
    "@xcite presented a long - term recurrent convolutional network ( lrcn ) architecture to integrates cnn and rnn into an unified model , and achieved promising results in a number of vision tasks .",
    "rohrbach et al .",
    "@xcite further improved lrcn by adding a pooling layer and had shown its potentials in video description .",
    "the main difference between rnn models and ours is that their models exploit several types of neural gates and memory cells to learn temporal dynamics implicitly , while our deep structured model explicitly accounts for temporal variations of human activities by inferring latent variables .",
    "speficially , compared with these rnn models , our model has the following advantages .",
    "first , the temporal composition is explicitly captured by our model , giving rise to a better interpretability , i.e. the semantic correspondence of video segments and sub - activities .",
    "second , as some recent works report  @xcite , the rnn models may have problems on using common dropout tricks and this limitation would influence the performances .",
    "moreover , the integration with explicit regularization approaches ( e.g. the radius - margin bound ) is also an important superiority of our model .",
    "in this section , we introduce the main components of our deep structured model , including the spatio - temporal cnns , the latent structure of activity decomposition , and the radius - margin bound for classification .",
    "we propose an architecture of spatio - temporal convolutional neural networks ( cnns ) , as figure  [ fig : architecture ] illustrates . in the input layer",
    ", the activity video is decomposed into @xmath0 video segments , where each segment associates to one separated sub - activity . accordingly , the proposed architecture consists of @xmath0 sub - networks to extract features from the corresponding decomposed video segments , respectively .",
    "our spatio - temporal cnns involve both 3d and 2d convolutional layers .",
    "the 3d convolutional layer extracts spatio - temporal features for jointly capturing appearance and motion information , and is followed by a max - pooling operator to improve the robustness against local deformations and noise .",
    "as shown in figure  [ fig : architecture ] , each sub - network ( highlighted by the dashed box ) is stacked up by two 3d convolutional layers and one 2d convolutional layer . for the input to each sub - network ,",
    "the number of frames is very small ( e.g. 9 ) .",
    "after two layers of 3d convolution followed with max - pooling , the temporal dimension for each set of feature maps is too small to perform 3d convolution .",
    "thus , we stack a 2d convolutional layer upon the two 3d convolutional layers .",
    "the outputs from different sub - networks are merged to be fed to one fully connected layer that generates the final feature vector of the input video .          unlike the traditional deep learning methods with the fixed architectures , we incorporate latent structure into the deep model to flexibly adapt to the input video during inference and learning .    to address the large temporal variation of human activities , we assume the input video is temporally divided into a number @xmath0 of segments , corresponding to the sub - activities .",
    "we associate the cnns with the video segmentation by feeding each segmented part into a sub - network as figure  [ fig : architecture ] illustrates .",
    "next , according to the way of video segmentation ( i.e. decomposition of sub - activities ) , we manipulate the cnns by inputting sampled video frames .",
    "specifically , we index each video segment by its starting anchor frame @xmath1 and its temporal length ( i.e. the number of frames ) @xmath2 for each sub - network , which must take @xmath3 video frames as the input .",
    "note that when @xmath4 , a uniform sampling is performed to extract @xmath3 key frames .",
    "thus , for all video segments , we denote the indexes of starting anchor frames as @xmath5 and their temporal lengths as @xmath6 , which are regarded as the latent variables in our model , @xmath7 .",
    "these latent variables specifying the segmentation will be adaptively estimated for different input videos .",
    "figure  [ fig : latent_structure ] shows an intuitive example of our structured deep model , where the input video are segmented into three sections corresponding to the three sub - networks in our deep architecture . in this way , the configuration of the cnns are dynamically adjusted together with searching for the appropriate latent variables of input videos .",
    "given the parameters of cnns @xmath8 and the input video @xmath9 with its latent variables @xmath10 , the generated feature of @xmath9 can be represented as @xmath11 .",
    "the large amount of training data is crucial for the success of many deep learning models .",
    "given sufficient training data , the effectiveness of applying the softmax classifier with cnns has been validated for image classification  @xcite . however , for 3d human activity recognition , the available training data are usually less what we expected . for example , the cad-120 dataset  @xcite consists of only 120 rgb - d sequences of 10 categories . under this scenario , though parameter pre - training and dropout are available , the model training often suffers from the over - fitting issue .",
    "hence , we consider introducing a more effective classifier together with regularizer to improve the generalization performance of the deep model .    in supervised learning , support vector machine ( svm ) , also known as the max - margin classifier , is theoretically sound and generally can achieve promising performance compared with the alternative linear classifiers . in the deep learning research",
    ", the combination of svm and cnns has been exploited  @xcite and obtained excellent results in object detection  @xcite .",
    "motivated by these approaches , we impose a max - margin classifier @xmath12 upon the feature generated by the spatio - temporal cnns for human activity recognition .     as a max - margin classifier , standard",
    "svm adopts @xmath13 , the reciprocal of the squared margin @xmath14 , as the regularizer .",
    "however , the generalization error bound of svm depends on the radius - margin ratio @xmath15 , where @xmath16 is the radius of the minimum enclosing ball ( meb ) of the training data  @xcite .",
    "when the feature space is fixed , the radius @xmath16 is constant and can thus be ignored .",
    "however , in our approach , the radius @xmath16 is determined by the meb of the training data in the feature space generate by the cnns . under this scenario ,",
    "the model has the risk that the margin can be increased by simply expanding the meb of the training data in the feature space .",
    "for example , simply multiplying a constant to the feature vector can enlarge the margin between the positive and negative samples , but obviously it will not really work for better classification . to overcome this problem",
    ", we incorporate the radius - margin bound together with the feature learning , as figure  [ fig : classifier ] illustrates .",
    "in particular , we impose a max - margin classifier with radius information upon the feature generated by the fully connected layer of the spatio - temporal cnns .",
    "the optimization tends to maximize the margin while shrinking the meb of the training data in the feature space , and we thus obtain a tighter error bound .",
    "suppose there are a set of @xmath17 training samples @xmath18 = \\{@xmath19 , ... , @xmath20 } , where @xmath9 is the video , @xmath21 represents the category labels and @xmath22 is the number of activity categories .",
    "we extract the feature for each @xmath9 by the spatio - temporal cnns , @xmath11 , where @xmath10 refers to the latent variables . by adopting the squared hinge loss and the radius - margin bound ,",
    "we define the following loss function @xmath23 of our model :    @xmath24    where @xmath25 is the trade - off parameter , @xmath26 denotes the margin of the separating hyperplane , @xmath27 denotes the bias , and @xmath28 denotes the radius of the meb of the training data @xmath29 = @xmath30 in the cnns feature space .",
    "formally , the radius @xmath28 is defined as  @xcite ,    @xmath31    the radius @xmath28 is implicitly defined by both the training data and the model parameters , making that : ( i ) the model in eq .",
    "( [ equ : svm ] ) is highly nonconvex , ( ii ) the derivative of @xmath28 with respect to @xmath8 is hard to compute , and ( iii ) the problem is difficult to solve using the stochastic gradient descent ( sgd ) method .",
    "motivated by the radius - margin based svm @xcite , we investigate the relaxed form to replace the original definition of @xmath28 in eq .",
    "( [ equ : defr ] ) .",
    "in particular , we introduce the maximum pairwise distance @xmath32 over all the training samples in the feature space , as    @xmath33    do and kalousis @xcite proved that @xmath28 could be well bounded by @xmath32 with the following lemma ,    [ lemma : radius_bound ] @xmath34    this above lemma guarantees that the true radius @xmath28 can be well approximated by @xmath32 . with the proper parameter @xmath35 , the optimal solution for minimizing the radius - margin ratio",
    "@xmath36 is the same with that for minimizing the radius - margin sum @xmath37  @xcite .",
    "thus , by approximating @xmath38 with @xmath39 and replacing the radius - margin ratio with the radius - margin sum , we suggest the following deep model with the relaxed radius - margin bound ,    @xmath40    however , the first max operator in eq .",
    "( [ equ : svm_l1 ] ) is non - smooth and defined over all pairs of training samples , and it is thus unsuitable for using the mini - batch - based sgd optimization method . in the following ,",
    "we first use the softmax function to avoid the non - smoothness of the max operator , and then further relax the radius to avoid the definition over all pairs of training samples . more specifically , we first transfer the max operator into a softmax form , resulting the following model ,    @xmath41    with @xmath42 where @xmath43 is a coefficient measuring the correlation of the two samples and @xmath44 is the parameter to control the approximation degree to the hard max operator . when @xmath45 is infinite , the approximation in eq .",
    "( [ equ : svm_l2 ] ) becomes the model in eq .",
    "( [ equ : svm_l1 ] ) .",
    "specifically , when @xmath46 , there is @xmath47 , and the relaxed loss function can be reformulated as :    @xmath48    with @xmath49    the optimization objectives in eq .",
    "( [ equ : svm_l2 ] ) and ( [ equ : svm_l3 ] ) are two relaxed losses of our deep model with the strict radius - margin bound in eq .",
    "( [ equ : svm ] ) . in this work ,",
    "we focus on the objective in eq .",
    "( [ equ : svm_l3 ] ) for the model training .",
    "the learning algorithm will be discussed in section [ sec : learning ] .",
    "in this section , we first explain the implementation that makes our model adaptive to alterable temporal structure , and then describe the detailed setting of our deep architecture .       during our learning and inference procedures , we search for the appropriate latent variables that determine the temporal decomposition of the input video ( i.e. the decomposition of activities ) .",
    "there are two parameters related to the latent variables in our model : the number @xmath0 of video segments and the temporal length @xmath3 of each segment .",
    "note that the sub - activities decomposed by our model have no precise definition given a complex activity , i.e. actions can be ambiguous depending on the considering temporal scale .    to incorporate the latent temporal structure , we associate the latent variables with the neurons ( i.e. convolutional responses ) in the bottom layer in the spatio - temporal cnns .",
    "the choice of the number of segments @xmath0 is important to the performance of 3d human activity recognition",
    ". the model with a small @xmath0 could be less expressive to handle temporal variations , while a large @xmath0 could lead to over - fitting due to high complexity .",
    "furthermore , when @xmath50 , the model latent structure would be disabled , and our architecture degenerates to the conventional 3d - cnns  @xcite . by referring to the setting of the number of parts for the deformable part - based model  @xcite in object detection , the value @xmath0 can be set by the cross validation on a small set . in all our experiments , we set @xmath0 = 4 .",
    "considering that the number of frames of the input videos are diverse , we develop a process to normalize the inputs by two - step sampling in the learning and inference procedure .",
    "first , we sample @xmath51 anchor frames uniformly from the input video . based on these anchor frames , we search for all of the possible non - overlapped temporal segmentations , and",
    "the anchor frame segmentation corresponds to the segmentation of the input video .",
    "then , from each video segment ( indicating a sub - activity ) we uniformly sample @xmath3 frames to feed the neural networks , and in our experiments we set @xmath52 .",
    "in addition , we reject the possible segmentations that can not offer @xmath3 frames for any video segment .    for an input video ,",
    "the possibility of temporal structure variations is @xmath53 in our experiments ( i.e. the possible enumeration numbers of anchor frame segmentation ) .",
    "the proposed spatio - temporal cnn architecture is constructed by stacking up two 3d convolution layers , one 2d convolution layer and one fully connected layer , and the max - pooling operator is deployed after each 3d convolutional layer . in the following ,",
    "we introduce the definitions and implementations of these components in our model",
    ".    * 3d convolutional layer . *",
    "the 3d convolution operation is adopted to perform convolutions spanning over both spatial and temporal dimensions for the characterization of both appearance and motion features  @xcite .",
    "suppose @xmath54 is the input video segment with the width @xmath55 , the height @xmath56 , and the number of frames @xmath3 , @xmath8 is the 3d convolutional kernel with the the width @xmath57 , height @xmath58 , and temporal length @xmath59 .",
    "as shown in figure  [ fig : conv3d ] , a feature map @xmath60 can be obtained by performing 3d convolutions from the @xmath61th to the @xmath62th frames , where the response for the position @xmath63 in the feature map is defined as ,    @xmath64    where @xmath65 denotes the pixel value of the input video @xmath54 at position @xmath66 in the @xmath67th frame , @xmath68 denotes the value of the convolutional kernel @xmath8 at the position @xmath69 , @xmath27 stands for the bias , and @xmath70 denotes the hyperbolic tangent function .",
    "thus , given @xmath54 and @xmath8 , @xmath71 feature maps can be obtained , each with size of @xmath72 .",
    "based on the 3d convolution operation , 3d convolution layer is designed for spatio - temporal feature extraction by considering three issues :    * _ number of convolutional kernels .",
    "_ the feature maps generated by one convolutional kernel are limited in capturing appearance and motion information . to generate more types of features ,",
    "several kernels are employed in each convolutional layer .",
    "we define the number of 3d convolutional kernels in the first layer as @xmath73 .",
    "after the first 3d convolutions , we obtain @xmath73 sets of @xmath71 feature maps .",
    "then we use 3d convolutional kernels on the @xmath73 sets of feature maps , and obtain @xmath74 sets of feature maps after the second 3d convolution layer .",
    "* _ decompositional convolutional networks .",
    "_ our deep model consists of @xmath0 sub - networks , and the input video segment to each sub - network involves @xmath3 frames ( the later frames might be unavailable ) . in the proposed architecture , all of the sub - networks use the same structure but each one has its own convolutional kernels , as we assume that each temporally decomposed sub - activity has its distinct features in terms of discriminative classification . for example , the kernels belonging to the first sub - network are only deployed to perform convolutions on the first temporal video segment . .",
    "* _ application to gray - depth video . _",
    "the rgb images are first converted to the gray - level images , and the gray - depth video is then adopted as the input to the neural networks .",
    "the 3d convolutional kernels in the first layer are respectively applied for both the gray channel and the depth channel in the video , and the convolution results from these two channels are further aggregated to produce the feature maps .",
    "note that the dimensions of the features remain the same as from only one channel .    in our implementation",
    ", the input frame is scaled with the height @xmath75 and width @xmath76 . in the first 3d convolution layer ,",
    "the number of 3d convolutional kernels is @xmath77 , and the size of the kernel is @xmath78 = @xmath79 . in the second layer ,",
    "the number of 3d convolutional kernels is @xmath80 , and the size of the kernel is @xmath78 = @xmath81 .",
    "thus , we have @xmath82 sets of feature maps after the first 3d convolution layer , and obtain @xmath83 sets of feature maps after the second 3d convolution layer .    * max - pooling operator .",
    "* after each 3d convolution , the max - pooling operation is introduced to enhance the deformation and shift invariance  @xcite .",
    "given a feature map with the size of @xmath84 , a @xmath85 max - pooling operator is performed by taking the maximum of every non - overlapping @xmath85 sub - regions of the feature map , resulting in an @xmath86 pooled feature map . in our implementation , @xmath87 max - pooling operator was applied after every 3d convolution layers . after two layers of 3d convolution and max - pooling , for each sub - network , we have @xmath83 sets of @xmath88 feature maps .",
    "* 2d convolutional layer .",
    "* after two layers of 3d convolution followed with max - pooling , 2d convolution is employed to further extract higher - level complex features .",
    "the 2d convolution can be viewed as a special case of 3d convolution with @xmath89 , which is defined as    @xmath90    where @xmath91 denotes the pixel value of the feature map @xmath54 at position @xmath66 , @xmath92 denotes the value of the convolutional kernel @xmath8 at the position @xmath93 , and @xmath27 denotes the bias . in the 2d convolution layer , suppose the number of 2d convolutional kernels is @xmath94 , @xmath95 sets of new feature maps are obtained by performing 2d convolutions on @xmath96 sets of feature maps generated by the the second 3d convolution layer .    in our implementation , the number of 2d convolutional kernels is set as @xmath97 with the kernel size @xmath98 . hence for each sub - network we can obtain @xmath99 feature maps with size @xmath100",
    ".    * fully connected layer .",
    "* there is only one fully connected layer with 64 neurons in our architecture .",
    "all these neurons connect to a vector of @xmath101 dimensions , which is generated by concatenating the feature maps from all of the sub - networks . the margin - based classifier is defined based on the output of the fully connected layer , where we adopt the squared hinge loss to predict the activity categories as @xmath102 where @xmath103 is the 64-dimensional vector from the fully connected layer , and",
    "@xmath104 denotes the weight and bias connected to the @xmath105-th activity category .     * dropout trick . *",
    "since our deep architecture contains a large number of parameters ( i.e. 179200 weighs at the fully - connected layer ) , we apply the standard dropout approach during the model training to alleviating the over - fitting problem .",
    "according to the recent reports  @xcite , the dropout method is capable of effectively improving the generalization power of neural network models by randomly turning off the neurons in the learning .",
    "specifically , we set turning - off probability rate is @xmath106 for each neuron at the fully - connected layer in each learning iteration , and this dropout approach is applied by default in every experiment .",
    "the proposed deep structured model involves three components to be optimized : ( i ) the latent variables @xmath107 that manipulate the activity decomposition , ( ii ) the margin - based classifier \\{@xmath108 } , and ( iii ) the cnns parameters @xmath8",
    ". the latent variables are not continuous and need to be estimated adaptively for different input videos , making the standard back propagation algorithm  @xcite unsuitable for our deep model . in this section ,",
    "we present a joint component learning algorithm that iteratively optimizes the three components . moreover , to overcome the problem of insufficient 3d data",
    ", we propose to borrow the large amount of 2d videos to pre - train the cnns parameters in advance .",
    "denote @xmath18 = \\{@xmath19 , ... , @xmath20 } as the training set with @xmath17 examples , where @xmath9 is the video , @xmath109 denotes the activity category .",
    "denote @xmath110 as the set of latent variables for all training examples .",
    "the model parameters to be optimized can be divided into three groups , i.e. @xmath111 , \\{@xmath108 } , and @xmath8 .",
    "fortunately , given any two groups of parameters , the other group of parameters can be efficiently learned using either the stochastic gradient descent ( sgd ) algorithm ( e.g. for \\{@xmath108 } and @xmath8 ) or enumeration ( e.g. for @xmath111 ) .",
    "therefore , we adopt a principled coordinate type algorithm to optimize the our deep structured model in eq .",
    "( [ equ : svm_l2 ] ) and ( [ equ : svm_l3 ] ) .",
    "this learning algorithm actually is a general expectation maximization ( gem ) method @xcite , which iteratively performs the e - step and the m - step : the former discovering the optimal latent variables by global searching and the latter optimizing the cnn and classifier parameters for a sub - optimal solution .",
    "as shown in @xcite , such a gem procedure can converge monotonically to a stationary point . more specifically ,",
    "our learning algorithm iterates with the three steps : ( i ) given the model parameters \\{@xmath108 } and @xmath8 , we estimate the latent variables @xmath10 for each video and update the corresponding feature @xmath11 ( figure  [ fig : learning ] ( a ) ) ; ( ii ) given the updated features @xmath112 , we update the max - margin classifier \\{@xmath108 } ( figure  [ fig : learning ] ( b ) ) ; ( iii ) given the model parameters \\{@xmath108 } and @xmath107 , we update the cnn parameters @xmath8 , which will lead to both the increase of the margin and the decrease of the radius ( figure  [ fig : learning ] ( c ) ) .",
    "it is worth mentioning that the two steps ( ii ) and ( iii ) can be performed in the same procedure of sgd , i.e. their parameters are jointly updated in an end - to - end way .    in the following ,",
    "we explain in detail the three steps for minimizing the loss in eq .",
    "( [ equ : svm_l3 ] ) , which are derived from our deep model .    * ( i ) * given the model parameters @xmath8 and \\{@xmath108 } , for each sample @xmath113 , the most appropriate latent variables @xmath10 can be determined by exhaustive searching over all the possible choices ,    @xmath114    gpu programming is employed to accelerate the searching process . with the updated latent variables ,",
    "we further obtain the feature set @xmath112 of all the training data .    *",
    "( ii ) * given @xmath112 and the cnns parameters @xmath8 , batch stochastic gradient descent ( sgd ) is adopted for updating model parameters in eq .",
    "( [ equ : svm_l3 ] ) . in iteration",
    "@xmath115 , a batch @xmath116 of @xmath117 samples is chosen .",
    "we can obtain the gradients of the max - margin classifier with respect to parameters \\{@xmath108 } ,    @xmath118    @xmath119    * ( iii ) * given the latent variables @xmath107 and the max - margin classifier \\{@xmath108 } , based on the gradients with respect to @xmath8 , the back propagation algorithm can be adopted to learn cnns parameters @xmath8 . more specifically , we first update the mean @xmath120 in eq .",
    "( [ equ : def_mean ] ) based on @xmath112 , and then compute the derivative of the relaxed loss in eq .",
    "( [ equ : svm_l3 ] ) as    @xmath121    by performing the proposed back propagation algorithm , we can further decrease the relaxed loss and optimize the model parameters . during the back propagation",
    ", batch sgd is adopted to simultaneously update the parameters of both step ( * ii * ) and ( * iii * ) .",
    "the optimization algorithm iterates between these three steps until convergence .     + the labeled 2d , 3d activity dataset and learning rate @xmath122 , @xmath123 .",
    "+ model parameters \\{@xmath124}.     + pre - train the spatio - temporal cnns using the 2d videos .",
    "+ learning on 3d video dataset :    * estimate the latent variables @xmath111 for all samples by fixing model parameters \\{@xmath124}. * optimize \\{@xmath108 } given the cnn model parameters @xmath8 and the input sample segments indicated by @xmath111 : * * calculate @xmath125 by forwarding the neural network with @xmath8 . * * optimize \\{@xmath108 } via : + @xmath126 : = @xmath127 by eq .",
    "( [ equ : g_wsvm ] ) ; + @xmath27 : = @xmath128 by eq .",
    "( [ equ : g_bsvm ] ) ; * optimize @xmath8 given \\{@xmath108 } and @xmath111 : * * calculate @xmath43 , @xmath129 and @xmath130 for @xmath131 , or calculate @xmath120 for @xmath132 . *",
    "* optimize the parameters @xmath8 of the spatio - temporal cnns : + @xmath8 : = @xmath133 by eq .",
    "( [ equ : g_cnn_3 ] ) .",
    "@xmath134 in ( [ equ : svm_l2 ] ) or ( [ equ : svm_l3 ] ) converges .",
    "parameter pre - training followed by fine - tuning is an effective method to boost the performance in deep learning , especially when the training data is scarce . in the literature , there are two popular solutions , i.e. unsupervised pre - training on unlabeled data  @xcite and supervised pre - training for an auxiliary task  @xcite .",
    "the latter usually requires the data formate ( e.g. image ) for parameter pre - training is exactly the same as that ( e.g. image ) for fine - tuning .    in our approach , we suggest an alternative solution for 3d human activity recognition .",
    "although collecting rgb - d videos of human activities is expensive , a large amount of 2d activity videos can be easily obtained .",
    "consequently , we first apply the supervised pre - training using a large number of 2d activity videos , and then fine - tune the cnns parameters for training the 3d human activity models .    in the step of pre - training ,",
    "the cnns parameters are randomly initialized at the beginning . for each input",
    "2d video , we equally segment it into @xmath0 parts without estimating its latent variables . here",
    "we simply employ the softmax classifier to pre - train the parameters of cnn , since the softmax loss unbiasedly treat all samples and it is suitable for learning a general feature representation @xcite .",
    "the 3d and 2d convolutional kernels obtained in pre - training are only for gray channel .",
    "thus , after pre - training , we duplicate the dimension of the 3d convolutional kernels in the first layer and initialize the parameters for the depth channel by the parameters for the gray channel , which allows us to borrow the features learned from the 2d video while directly learning the higher level information from the specific 3d activity dataset . for the fully connected layer , we set its parameters as random values .",
    "we summarize the overall learning procedure in algorithm [ alg : framwork ] .",
    "given an input video @xmath9 , the inference task aims to recognize its category of the activity , which can be formulated as the minimization of @xmath135 with respect to the activity label @xmath136 and the latent variables @xmath56 ,    @xmath137    where \\{@xmath138 } denotes the parameters of the max - margin classifier for the activity category @xmath136 .",
    "note the possible values for @xmath136 and @xmath56 are discrete .",
    "thus the problem above can be solved by searching across all of the labels @xmath139 and calculate the maximum @xmath135 by optimizing @xmath56 . to find the maximum of @xmath135 , we enumerate all the possible values of @xmath56 , and calculate the corresponding @xmath135 via forward propagations . since the forward propagations decided by different @xmath56 are independent , we can parallelize the computation via gpu to accelerate the inference process .",
    "[ fig : sbu][fig : oa1][fig : oa2 ]",
    "to validate the advantages of our model , experiments are conducted on several challenging public datasets , i.e. _ cad-120 dataset _",
    "@xcite , _ sbu kinect interaction dataset _  @xcite , and a larger dataset newly created by us , namely _ office activity ( oa ) dataset_. moreover , we introduce a more comprehensive dataset in our experiments by combining five existing datasets of rgb - d human activity .",
    "in addition to demonstrating the superior performance of the proposed model over other state - of - the - arts , we extensively evaluate the main components of our framework .",
    "the _ cad-120 _ dataset comprises of 120 rgb - d video sequences of humans performing long daily activities of @xmath140 categories , and has been widely used for testing 3d human activity recognition methods .",
    "these activities recorded via the microsoft kinect sensor were performed by four different subjects , and each activity was repeated three times by the same actor .",
    "these activities have a long sequence of sub - activities , which vary from subject to subject significantly in terms of length of the sub - activities , order of the sub - activities as well as in the way they executed the task .",
    "moreover , the challenges on this dataset also lie in the large variance in object appearance , human pose , and viewpoint .",
    "several sampled frames and depth maps from this databases of these @xmath140 categories are exhibited in figure  [ fig : cad120 ] ( a ) .",
    "the _ sbu _ dataset consists of @xmath141 categories of two - person interaction activities , including a total of about 300 rgb - d video sequences , i.e. about @xmath142 sequences for each interaction category .",
    "even though most interactions in this dataset are simple , it is still challenging for modeling two - person interactions by considering the following difficulties : i ) one person is acting and the other person is reacting in most cases , ii ) the average frame length of these interaction is short ( ranging from 20 to 40 ) , iii ) the depth maps have noises .",
    "figure  [ fig : sbu ] ( b ) shows several sampled frames and depth maps of these @xmath141 categories .",
    "the proposed _",
    "oa _ dataset is more comprehensive and challenging compared with the existing datasets , and it covers the regular daily activities taken place in an office . to the best of our knowledge , it is the largest activity dataset of rgb - d videos consisting of @xmath143 sequences .",
    "database is publicly accessible .",
    "three rgb - d sensors ( i.e. microsoft kinect cameras ) are utilized to capture data from different viewpoints , and more than 10 actors are involved .",
    "the activities are captured in two different offices to increase the variability , where each actor performs the same activity twice .",
    "the activities performed by two subjects with interactions are also included .",
    "specifically , it is divided into two subsets , each of which contains 10 categories of activities :",
    "( complex activities by a single subject ) and _ oa2 _ ( complex interactions by two subjects ) .",
    "several sampled frames and depth maps are exhibited in figure  [ fig : oa1 ] ( c ) and figure  [ fig : oa2 ] ( d ) from _ oa1 _ and _ oa2 _ , respectively .     to evaluate our model under a larger scale scenario",
    ", we collect an extra dataset by combining existing rgb - d human activity datasets : _ rgbd - hudaact _",
    "@xcite , _ cad120 _ , _ sbu _ , _ utkinect - action _",
    "@xcite and _",
    "oa_. this dataset contains @xmath144 video sequences with 5 , 500 , 000 frames ( approximately 50 hours long ) belonging to @xmath145 activity categories , and we name it as _",
    "merged_50 _ dataset .",
    "note that we merge very similar activity categories from the different datasets .",
    "in addition , we create a coarse - level variant of this dataset by merging the @xmath145 categories into only @xmath146 , that is , all of the @xmath144 activity instances are roughly divided into @xmath146 types : \\{a person interacting small objects ( e.g. answering - phones , having - meal ) , a person interacting large objects ( e.g. sleeping - in - bed , cleaning - objects ) , physical contacting of persons ( e.g. departing , asking - and - way ) , non - physical contacting of persons ( e.g. exchanging objects , hugging objects together)}. and we name this coarse - level dataset as _ merged_4_.    [ cols=\"^,^,^,^,^,^,^,^ \" , ]      _ cad-120 dataset .",
    "_ on this dataset , we adopt five state - of - the - art methods for comparison .",
    "note that for different methods we train the models using the same data annotation , which only includes the activity labels on videos .",
    "as shown in table  [ tab : cad120_avg ] , our method obtains the average accuracy of @xmath147 , which is significantly superior to the results generated by other five competing methods , i.e. @xmath148  @xcite , @xmath149  @xcite , @xmath150  @xcite , @xmath151  @xcite and @xmath152  @xcite .",
    "table  [ tab : cad120_all ] reports the accuracies per activity category of our method and the method based on hand - crafted feature engineering  @xcite , the deep architecture of convolutional neutral networks  @xcite , for 3d - cnn . ] and the rich spatio - temporal relations modeling  @xcite .",
    "our method achieves the highest accuracies on @xmath153 of the 10 activity categories .",
    "_ sbu dataset .",
    "_ as shown in table  [ tab : sbu ] , our method obtains the average accuracy of @xmath154 and performs better than the methods based on body - pose features  @xcite , which indicates that our method is effective in learning discriminative features directly from raw data for modeling person - to - person interaction .",
    "_ oa dataset .",
    "_ in this experiment , we apply our method on the two _ oa _ subsets . tables .",
    "[ tab : oa1 ] and  [ tab : oa2 ] list the accuracies per category and average accuracy of the competing methods , and our method outperforms the state - of - the - art methods in terms of the average accuracy . on the _",
    "oa1 _ set , our method achieves the best accuracies on all categories and obtains the highest average accuracy of @xmath155 , as shown in table .",
    "[ tab : oa1 ] . on the _",
    "oa2 _ set , our method achieves the best accuracies on 8 out of 10 activity categories and obtains the highest average accuracy of @xmath156 , as shown in table  [ tab : oa2 ] . by checking the results , we find that the failure cases are mainly caused by the lack of contextualized scene understanding .",
    "for example , understanding the activities of _ having - guest _ and _ eating - and - chatting _ actually requires extra higher level information , and we will consider this issue in the future work .     _ merged datasets .",
    "_ table  [ tab : merged ] reports the average accuracy of the competing methods , and our method outperforms the state - of - the - art methods  @xcite in terms of the average accuracy .    in summary , our method consistently achieves better results than the competing methods on the three 3d activity datasets .",
    "figure  [ fig : confusionmat ] shows the confusion matrices of our model for all datasets .",
    "one can see that , the confusion matrices are strongly diagonal with few errors , which indicates that our deep structured model is effective in handling various challenges in 3d human activity recognition .",
    "in this paper , we have introduced , first , a deep and latent - structured model using the convolutional neural networks .",
    "second , a unified formulation integrating the radius - margin regularization with the feature learning . third , an effective learning algorithm that iteratively optimizes the sub - activity decomposition , the margin - based classifier , and the neural networks . we have demonstrated the practical applicability of our model by effectively recognizing human activities using a depth camera .",
    "experiments on the public datasets suggest that our model convincingly outperforms other state - of - the - art methods under several very challenging scenarios .     one main drawback of our current solution is the scalability of model inference .",
    "the brute - force enumeration over all settings of the latent variables will cause extra computation cost and this issue may become much more serious when the number ( e.g. , 1000 ) of human activity categories is large . apart from the scalability issue , we intend to extend our work in the following directions .",
    "the first is to generalize our model with compositional grammar rules ( e.g. the and - or grammars ) , and thus deal with more complicated event understanding ( e.g. the causality inference ) .",
    "the second is to revise our neural network for recognizing human action / activity from 2d videos .",
    "note that there are distinct differences between 2d videos and 3d videos .",
    "for example , these mentioned 2d datasets basically include diverse environments ( e.g. , indoor / outdoor ) with the camera moving , and the 3d depth data are all captured indoor with a fixed sensor ( i.e. microsoft kinects ) . in addition , the 2d videos are usually in higher resolution than the data ( i.e. 320 @xmath157 240 ) captured by the depth sensor .",
    "this work was supported in part by the hong kong scholar program , and in part by the hk polyu s joint supervision scheme with the chinese mainland , taiwan and macao universities ( grant no .",
    "g - sb20 ) , in part by guangdong natural science foundation ( grant no .",
    "s2013010013432 ) , and in part by guangdong science and technology program ( grant no .",
    "2013b010406005 ) .",
    "bayer j , osendorfer c , korhammer d , chen n , urban s , van  der smagt p ( 2014 ) on fast dropout and its applicability to recurrent networks . in : _",
    "international conference on learning representations ( iclr ) _",
    "cheng z , qin l , huang q , jiang s , yan s , tian q ( 2011 ) human group activity analysis with fusion of motion and appearance information . in : _",
    "acm international conference on multimedia ( acm mm ) _ , pp 14011404        do h , kalousis a , hilario m ( 2009 ) feature weighting using margin and radius based error bound optimization in svms . in : _",
    "european conference on machine learning and knowledge discovery in databases : part i _ , pp 315329    donahue j , hendricks la , guadarrama s , rohrbach m , venugopalan s , saenko k , darrell t ( 2015 ) long - term recurrent convolutional networks for visual recognition and description . in : _",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _",
    "felzenszwalb pf , girshick rb , mcallester d , ramanan d ( 2010 ) object detection with discriminatively trained part based models .",
    "_ ieee transactions on pattern analysis and machine intelligence ( tpami ) _",
    "32(9):16271645    girshick r , donahue j , darrell t , malik j ( 2014 ) rich feature hierarchies for accurate object detection and semantic segmentation . in : _",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , pp 580587            karpathy a , toderici g , shetty s , leung t , sukthankar r , fei - fei l ( 2014 ) large - scale video classification with convolutional neural networks . in : _",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _",
    "lecun y , boser b , denker j , henderson d , howard r , hubbard w , jackel l , henderson d ( 1990 ) handwritten digit recognition with a back - propagation network . in : _ advances in neural information processing systems _",
    "ni b , y  pei zl , lin l , moulin p ( 2013 ) integrating multi - stage depth - induced contextual information for human action recognition and localization . in : _",
    "international conference and workshops on automatic face and gesture recognition _ , pp 18              sermanet p , kavukcuoglu k , chintala s , lecun y ( 2013 ) pedestrian detection with unsupervised multi- stage feature learning . in : _",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , pp 36263633              venugopalan s , xu h , donahue j , rohrbach m , mooney r , saenko k ( 2015 ) translating videos to natural language using deep recurrent neural networks . in : _ north american chapter of the association for computational linguistics _",
    "xia l , aggarwal j ( 2013 ) spatio - temporal depth cuboid similarity feature for activity recognition using depth camera . in : _",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , pp 28342841          yun k , honorio j , chattopadhyay d , berg tl , samaras d ( 2012 ) two - person interaction detection using body - pose features and multiple instance learning . in : _",
    "ieee conference on computer vision and pattern recognition workshops ( cvprw ) _"
  ],
  "abstract_text": [
    "<S> understanding human activity is very challenging even with the recently developed 3d / depth sensors . to solve this problem , this work investigates a novel deep structured model , which adaptively decomposes an activity instance into temporal parts using the convolutional neural networks ( cnns ) . </S>",
    "<S> our model advances the traditional deep learning approaches in two aspects . </S>",
    "<S> first , we incorporate latent temporal structure into the deep model , accounting for large temporal variations of diverse human activities . </S>",
    "<S> in particular , we utilize the latent variables to decompose the input activity into a number of temporally segmented sub - activities , and accordingly feed them into the parts ( i.e. sub - networks ) of the deep architecture . </S>",
    "<S> second , we incorporate a radius - margin bound as a regularization term into our deep model , which effectively improves the generalization performance for classification . for model training </S>",
    "<S> , we propose a principled learning algorithm that iteratively ( i ) discovers the optimal latent variables ( i.e. the ways of activity decomposition ) for all training instances , ( ii ) updates the classifiers based on the generated features , and ( iii ) updates the parameters of multi - layer neural networks . in the experiments , our approach is validated on several complex scenarios for human activity recognition and demonstrates superior performances over other state - of - the - art approaches . </S>"
  ]
}