{
  "article_text": [
    "functional data analysis has gained increased attention in the past years , in particular in high - throughput biology with the use of mass spectrometry . in this field ,",
    "the signal is a spectrum whose peaks provide information regarding the protein content of biological samples .",
    "a new challenge in functional data analysis is the availability of multisample data for which functional anova has become the appropriate framework .",
    "more specifically for spectrometry data , it is now well accepted that the noise corrupting the signal can be divided into a technical white noise added to an important inter - individual variability @xcite . in this case , the usual non - parametric regression framework ( a deterministic trend corrupted by a random noise ) is no longer appropriate since it does not account for heteroscedastic noise structure .",
    "functional mixed effects models @xcite appear to be a powerful framework to handle these data , as others , and we focus here on the estimation of the baseline signal .    in practice ,",
    "a trivial averaging procedure is often used to get an estimate of the baseline signal , but it has both a poor convergence rate and a finite sample performance .",
    "@xcite proposed an approach for baseline estimation based on empirical wavelet coefficients of the observed data .",
    "unfortunately the convergence of their estimator is not theoretically assessed , and more broadly , there is a general lack of theoretical results on functional estimators in functional mixed models , despite their increasing importance in practice @xcite .    in this work",
    "we propose a minimax estimator of the baseline signal , based on the empirical wavelet coefficients of the observed data .",
    "the functional fixed effect is assumed to belong to the besov class , which allows us to model curves that can exhibit strong irregularities , such as peaks in mass spectrometry data .",
    "we construct the lower bound for the @xmath0 minimax risk .",
    "this convergence rate is the same as in the classical non parametric setting but with an additional approximation error term .",
    "then , we propose a wavelet estimator that achieves near optimal rate of convergence ( within a logarithmic factor in sample size ) . through simulation studies , we show that our approach outperforms the approach proposed by @xcite .",
    "we also propose a new thresholding procedure based on the stein unbiased risk estimate ( sure ) @xcite , combined with the scad thresholding @xcite .",
    "this leads to improved performance for the baseline signal estimation .",
    "this article is organized as follows .",
    "section 2 presents the heteroscedastic model and the theoretical properties of our minimax estimator ( lower and upper bounds ) .",
    "in particular we show how classical rates are modified in the presence of replicates along with inter - individual variability .",
    "most of all , our work constitutes the first theoretical functional results in heteroscedastic multisample non - parametric regression .",
    "several thresholding strategies are considered in section 3 , where we provide a new sure - based procedure .",
    "section 4 is devoted to the numerical experiments , and the procedure is illustrated on an experimental dataset .",
    "technical proofs are provided in the appendix .",
    "we observe @xmath1 curves @xmath2 , for @xmath3 over @xmath4 equally spaced time points @xmath5 in @xmath6^m$ ] , with @xmath7 for some integer @xmath8 . in the general",
    "functional setting we consider a functional modeling ( as in @xcite ) for the observed signal of the @xmath9th individual : @xmath10 where @xmath11 , for @xmath12 are stochastically independent random functions that are modeled as realizations of zero - mean gaussian processes with parametrically structured covariances modeled in the wavelet domain ( see section [ sswe ] ) .",
    "we define @xmath13 to be the main functional fixed effect characterizing a population average profile . in the following",
    ", we will denote by @xmath14 , @xmath15 , the vector of observations on the time grid , and similarly by @xmath16 and @xmath17 , @xmath18 , respectively the vector of the fixed effect and the noise terms , observed on the discrete time grid .",
    "this modeling allows us to account for functional mixed effects models by decomposing @xmath19 in a sum of two independent processes @xmath20 , where @xmath21 are independent and identically distributed gaussian random variables with zero - mean and constant variance ; @xmath22 is a centered gaussian process standing for subject - specific functional deviations . in @xcite ,",
    "the authors introduce similar model although the variance of the process @xmath22 is constant with respect to positions @xmath23 .      in what follows",
    "we suppose that @xmath13 belongs to the besov class @xmath24 ( see section [ sswe ] for a proper definition ) , a set of compactly supported functions ( on @xmath6 $ ] ) with a bounded besov space norm ( by @xmath25 ) . such a set allows to model curves that can exhibit strong irregularities , such as peaks or jumps for instance .",
    "the notion of regularity is at the core of the functional setting which makes inhomogeneous besov spaces a privileged tool for irregular function analysis .",
    "these spaces allow the fine definition of the regularity @xmath26 of a function along with its derivatives lying in @xmath27)$ ] while bringing a correction @xmath28 to this regularity . for a detailed review of besov spaces and their properties , we refer the reader to the books of @xcite or @xcite .",
    "our goal is to recover the main functional effect @xmath13 from noisy observations .",
    "an originality of our approach is to consider multiple , say @xmath1 , individuals , which constitute available replicates to estimate the main fixed effect . to derive our estimator",
    ", we propose to use the so - called minimax approach . in this setup the risk of an estimator @xmath29 is defined by @xmath30 , with @xmath31 being a functional norm or a semi - norm .",
    "then the so - called _ minimax _ estimator , denoted by @xmath32 , is the minimizer of the maximal risk on class @xmath33 over the set of all estimators : @xmath34 thus the challenge is to propose an optimal minimax estimator @xmath32 , and to derive its associated risk @xmath35 , also referred to as the minimax risk .",
    "the construction of minimax estimators on the besov classes is well known when only one replicate is available ( see @xcite ) . when errors are measured with a @xmath36-norm `` sharper '' than the norm of the functional class @xmath37 , wavelet - based thresholding estimators",
    "can significantly outperform linear projection estimates .",
    "the rate of convergence depends on @xmath38 , @xmath37 and @xmath26 with two zones : the regular zone with usual rate @xmath39 and the sparse zone with a slower rate of convergence .",
    "however , this rate is not known when replicates are available ( @xmath40 ) . in this work",
    "we establish this risk for @xmath41 ( we will denote this norm by @xmath42 ) and for the besov class @xmath33 with usual constraints @xmath43 , @xmath44 and @xmath45 .",
    "that leads to consider the regular zone since , in this case , we have @xmath46 ( see @xcite ) . in order to establish the minimax risk , we first give its lower bound and",
    "secondly we propose an estimator that achieves a near optimal rate of convergence . in this context",
    ", the near - optimality means that the minimax rate is attained within a logarithmic factor in sample size @xmath4 .",
    "one of the main contributions of this paper is to derive the asymptotic lower and upper bounds for @xmath47 .",
    "the following theorem gives the lower bound for this minimax risk in the inhomogeneous besov class when dealing with multisample datasets ( @xmath48 @xmath40 ) .",
    "[ thmborneinf ] under the model ( [ functionalmodel ] ) with finite variances for the processes @xmath11 , for @xmath12 assume that @xmath13 belongs to a besov class @xmath49 with @xmath43 , @xmath44 , @xmath45 and @xmath50 , then @xmath51 } + { \\mathcal{o }   \\left[{m } ^{-s ' } \\right]}.\\ ] ] where @xmath52 if @xmath53 @xmath54 otherwise .",
    "let us mention that the term @xmath55 could be expected since it is the minimax rate ( when @xmath56 ) considering a noise of variance @xmath57 .",
    "however the approximation error term @xmath58 , present in the case with only one sample ( @xmath56 ) , is always negligible compared with the term @xmath55 .",
    "when @xmath40 , even a large @xmath1 does not provide more information on the function @xmath13 outside the grid @xmath59 . hence , @xmath58 becomes a limiting term .",
    "the upper bound of the minimax rate given in theorem [ thmborneinf ] is derived by constructing a wavelet estimator @xmath29 of @xmath13 .",
    "owing to their strong connection with the class of besov spaces , wavelets indeed represent a powerful tool to perform adaptive functional regression ( see @xcite ) .    as a brief recall and to set notations , wavelets can be used to construct orthonormal basis of the functional hilbert space @xmath60)$ ] by dilating and translating a compactly supported scaling function denoted by @xmath61 and a compactly supported mother wavelet denoted by @xmath62 .",
    "we assume that @xmath61 and @xmath62 belongs to @xmath63).$ ] then , letting @xmath64 be the first level of approximation , the family : @xmath65 with @xmath66 and @xmath67 is an orthonormal basis of @xmath60)$ ] .",
    "thus , any function @xmath13 in the space @xmath60)$ ] can be expressed in the wavelet basis as : @xmath68 where @xmath69 and @xmath70 are respectively the _ theorical _ approximation and wavelet coefficients , and with @xmath71 being the canonical hilbertian scalar product associated with the space @xmath60)$ ] . in the following , we set @xmath72 and omit the index @xmath73 for the unique remaining scaling coefficient denoted by @xmath74 .",
    "the besov class @xmath49 is defined via wavelet coefficients in the following way : @xmath75):\\ ; \\|\\mu \\|_{spq } \\leq l \\right\\},\\ ] ] where @xmath76 for @xmath77 @xmath78 and @xmath79 the norm @xmath80 is equivalent to the norm of the corresponding besov space ( cf .",
    "@xcite , @xcite ) .    in statistical settings , we are more concerned with discretely sampled curves .",
    "by applying the fast discrete wavelet transform proposed by @xcite to the functional model ( [ functionalmodel ] ) , we obtain a representation of the model in the coefficient domain given by : @xmath81 the @xmath82 vector @xmath83 contains @xmath84 scaling and wavelet coefficients associated with the signal , while @xmath85 stand for empirical coefficients related to the fixed effect @xmath13 and @xmath86 for the coefficients coming from the error term @xmath17 . following @xcite ,",
    "the modeling of such correlated noise is performed directly in the wavelet domain by assuming first that @xmath87 is a diagonal matrix thanks to the well known decorrelating property of wavelets ( see @xcite ) .",
    "then , to attain a wide range of processes , variances are assumed to vary with respect to the position and the resolution level such that @xmath88 and @xmath89 for all @xmath90 in @xmath91 with @xmath92 .",
    "conversely , existing works dealing with a correlated noise focused on the modeling of individual noise processes in the time domain by assuming a stationnary noise ( @xcite ) or a locally stationnary noise ( @xcite ) . in the wavelet domain",
    "these assumptions translate into variance terms for the matrix @xmath87 that are respectively depending on @xmath93 ( @xmath94 ) or depending on both @xmath93 and @xmath95 .",
    "based on the decorrelating property of wavelets , extra diagonal terms in the matrix @xmath87 are then neglected which restricts the class of reached processes in a way that is not effectively controlled . as a matter of fact",
    ", our model allows to consider non stationary processes whose covariance is diagonalizable by the dwt .",
    "however , we claim that such a modeling enables to catch a wide range of processes , even non stationary and hence allows a flexible enough modeling .    in the context of inhomogeneous spaces of functions such as besov classes",
    ", it is known that in some cases , no linear method can achieve the optimal rate ( see @xmath96 @xcite ) whereas nonlinear wavelet thresholding , pioneeringly introduced by @xcite in the white noise model , achieves this goal for a wide class of functional classes by taking advantage of the natural spatial adaptivity of wavelets . starting from model ( [ waveletmodel ] ) in the coefficient domain ,",
    "we extend the usual thresholding procedures to the heteroscedastic framework by including position - dependent variance parameters in the thresholding expressions . for @xmath97",
    "the wavelet coefficients @xmath98 are shrunk as from a certain level , through a defined shrinkage function @xmath99 , such that @xmath100 where @xmath101 and @xmath102 is a regularization parameter to be fixed .",
    "the shrunk coefficients are inversely transformed to yield the solution in the time domain , namely @xmath103^t,$ ] where @xmath104 is the transpose of the orthogonal matrix @xmath105 .",
    "when @xmath106 @xcite propose three strategies to estimate @xmath13 in model ( [ functionalmodel ] ) in the homoscedastic case .    1 .",
    "the most natural one , widely used in practice , is the direct pointwise averaging of observations @xmath107 however this simple procedure leads to poor convergence rate as pointed by @xcite , reflected by the completely pointwise procedure and poor finite sample performance .",
    "this approach is referred as a simple pointwise _ average _ approach by the authors .",
    "the second approach consists in averaging the nonparametric regression curves of the @xmath1 signals and is referred as a _",
    "shrink then average _ approach .",
    "this procedure improves the convergence rate due to the presence of a smoothing step .",
    "the former strategy can be further improved by first averaging the observations @xmath108 and then apply shrinkage to the average signal using then the whole sample .",
    "that is the third approach proposed in @xcite and referred as a _",
    "average then shrink _ approach .",
    "let us note that it has not been demonstrated that such an estimator achieves the optimal convergence rate .    in this work",
    "we consider this third approach in the heteroscedastic case and show that the associated estimator is near - minimax .",
    "precisely , we consider @xmath109 with , @xmath110 where @xmath111 denotes the average over the @xmath1 samples",
    ". the choice of the parameter @xmath112 will be detailed in the proof of theorem [ thmbornesup ] .",
    "the values of position - dependent thresholds @xmath113 are then given by : @xmath114 where @xmath115 are @xmath116-consistent estimates of variances .",
    "the following result gives an upper bound for the quadratic risk depending on the signal size @xmath4 and the number of samples @xmath1 .",
    "[ thmbornesup ] under the model ( [ functionalmodel ] ) , assume that @xmath13 belongs to a besov class @xmath49 with @xmath43 , @xmath44 , @xmath45 , @xmath117 and that the variances @xmath118 and @xmath119 are bounded by a constant denoted by @xmath120 . for any shrinkage function that satisfies , for any @xmath121 and @xmath122 latexmath:[\\[\\label{contdelta",
    "}    then the estimator @xmath29 defined by ( [ thfixedeffect],[coeff],[lambdajk ] ) with thresholds @xmath124 , satisfies @xmath125 + \\left[\\mathcal{o } \\left ( \\frac{\\log m}{m } \\right)^{s ' } \\right ] \\right\\ } , \\ ; \\text{if } \\ ; \\ ; \\frac{2}{2s+1 } < p < 2\\\\   & \\max \\left\\ { \\mathcal{o}\\left [ \\left(\\frac{1}{mn}\\right)^{\\frac{s}{2s+1 } } \\right ] + \\left[\\mathcal{o } \\left ( \\frac{\\log m}{m } \\right)^{s ' } \\right ] \\right\\ } ,   \\ ; \\text{if } \\ ; \\ ; p \\geq 2 \\end{aligned } \\right.\\ ] ] where @xmath126 is defined as in theorem [ thmborneinf ] .",
    "the next section describes the practical derivation of thresholding procedures that satisfy the conditions required by theorem [ thmbornesup ] .",
    "thus we propose estimators that enjoy a near - optimal convergence rate in a multisample heteroscedastic setting .",
    "among the usual thresholding procedures we first focus on the hard and soft thresholding procedures of @xcite , that provide estimators @xmath127 and @xmath128 .",
    "we also consider the scad ( @xmath129 ) thresholding of @xcite that establishes a trade - off between hard and soft thresholding , overcoming their respective non - continuity and bias drawbacks .",
    "the main conclusion of theorem [ thmbornesup ] is subject to the fulfilling of constraint ( [ contdelta ] ) .",
    "the lemma 2 of @xcite ensures that hard and soft thresholding meet this requirement .",
    "moreover , since we have @xmath130 the conclusion of this lemma still holds for the scad thresholding .      for theoritical purposes ,",
    "only the universal threshold ( [ lambdajk ] ) has been considered so far .",
    "its easy implementation and its good asymptotic properties makes the universal threshold very popular in major wavelet packages .",
    "our heteroscedastic thresholding approach is based on the definition of a threshold depending on the position @xmath90 through the variance parameters ( see ( [ lambdajk ] ) ) .",
    "theorem [ thmbornesup ] then applies in the context where the variances are unknown but for which @xmath116-consistent estimates are available .",
    "when @xmath56 , exhibiting @xmath116-consistent variance estimates is challenging .",
    "such an issue has been considered in the litterature and approaches based on a functional modeling of the variances in the time domain have been developed ( see @xmath131 @xcite , @xcite , @xcite ) . in their approaches , variances are then estimated using @xmath132-order differences ( @xmath133 ) , coupled with an appropriate smoothing nonparametric method .    in the mutlisample context ( @xmath40 ) , variance parameters can be easily estimated by simply considering empirical variances estimators such that : @xmath134 these variance parameter estimates straightforwardly satisfy the @xmath116-consistency requirement due to their asymptotic normality properties .",
    "however as pointed by @xcite and @xcite the universal threshold , originally designed for a `` noise - free '' reconstruction , is substantially larger than the minimax threshold . to handle this practical drawback ,",
    "@xcite proposed a strategy based on the stein unbiased risk estimate ( sure , @xcite ) whose purpose is to fix level dependent thresholds @xmath135 that leads to obtain an unbiased estimate of the @xmath136-risk .",
    "let @xmath137 be a vector in @xmath138 distributed as a standardized gaussian distribution of mean @xmath139 and covariance matrix equal to identity .",
    "the idea consists in writing the thresholding estimator @xmath140 as the sum : @xmath141 where @xmath142 is a weakly differentiable function from @xmath138 to @xmath138 .",
    "this leads to : @xmath143 the goal is then to select the parameter @xmath102 which minimizes the estimate of the @xmath136-risk , denoted by sure@xmath144 and given by @xmath145 by considering @xmath146 , where @xmath147 is given as in ( [ estsigma ] ) , the sure threshold is given by : @xmath148 where @xmath149 is the universal threshold given in ( [ lambdajk ] ) and @xmath150 the computation of the sure criterion depends on the chosen thresholding function .",
    "following the example of @xcite for soft thresholding , we propose an adaptation of the sure concept to scad thresholding .",
    "let us note that @xcite proposed an other derivation of the sure criterion leading to a sure - block - scad estimator in the context of wavelet - based functional regression .",
    "when replicates are available , the sure criterion to minimize according to @xmath102 is given by : @xmath151 \\mathbf{1 } _ { \\ { 2\\lambda < | \\widetilde{d}_{jk}| \\leq \\lambda \\ } } .\\end{gathered}\\ ] ] the computation details can be found in appendix [ appendix : sure.scad ] . as recommended by @xcite , @xmath152",
    "is set to @xmath153 based on a bayesian argument .",
    "moreover , we can point out that extremely sparse settings can lead to insufficient denoising due to the impact of zero coefficients in sure criterion . to avoid this drawback ,",
    "@xcite propose a compromising hybrid scheme ( hs ) between regular and sure thresholding defined by : @xmath154 for all @xmath155 .",
    "in this simulation study , we first investigate the benefits of using heteroscedastic thresholding estimators over homoscedastic ones when more than one sample are available .",
    "then , we investigate the effect of the choice of the threshold on realistic simulated datasets .",
    "[ [ simulation - settings . ] ] simulation settings .",
    "+ + + + + + + + + + + + + + + + + + + +    we consider the test functions ` blocks ` , ` bumps ` , ` heavisine ` and ` doppler ` @xcite that we use to model the principal mean functions @xmath13 . these functions are processed with the daubechies extremal phase wavelet basis with respectively 1,2,5 and 7 vanishing moments , based on the shannon entropy as described in @xcite , chap 2 .",
    "then we get the noise - free wavelet coefficients , to which we add heteroscedastic noise , following model ( [ waveletmodel ] ) : multisamples are simulated in the wavelet domain by corrupting the wavelet coefficients of the mean function by a normally additive heteroscedastic noise whose variance @xmath156 at a given position @xmath90 in @xmath91 is given by : @xmath157 the set @xmath158 contains index associated with the zero coefficients of the mean function whereas @xmath159 contains the ones associated with nonzero coefficients .",
    "the first term @xmath160 is associated to a white noise added to all coefficients , whereas the second term is an extra variability that introduces heteroscedasticity at some positions . following @xcite , a scale - wise exponential decrease",
    "is imposed to the extra variability terms by the quantity @xmath161 .",
    "parameter @xmath162 relates to the fixed effect regularity allowing the extra variability associated to @xmath163 to remain interpretable . in the following we use @xmath164 .",
    "+    [ [ dealing - with - zero - and - non - zero - coefficients . ] ] dealing with zero and non - zero coefficients .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one expects heteroscedastic thresholding estimators to be favored by heteroscedasticity structure expressed on the zero coefficients of the mean function : true zero coefficients are indeed more susceptible to be thresholded in this setting since heteroscedastic thresholds are expected to be larger than the homoscedastic one . therefore we put emphasis on configurations where heteroscedasticity concerns the null wavelet coefficients of the mean function .",
    "the value of @xmath160 is controlled by a signal - to - noise ratio ( snr ) and takes values in ( 1,5 ) going from a high level ( snr=1 ) to a low level of noise ( snr=5 ) .",
    "parameters @xmath163 are then drawn from a gamma distribution with scale 2 and shape @xmath165 .",
    "the quantity @xmath166 associated to the heteroscedasticity intensity is controlled with respect to the baseline variance @xmath160 by a ratio parameter @xmath167 defined by @xmath168    [ [ parameters - values . ] ] parameters values .",
    "+ + + + + + + + + + + + + + + + + +    we set the signal size to @xmath169 and the sample size to @xmath170 . a wider simulation study ( not shown for the sake of clarity )",
    "reveals that the main conclusions do not differ with different signal and sample size . for each fixed effect function",
    ", the simulation design explores the following configurations : snr @xmath171 , @xmath172 .",
    "the variability and heteroscedasticity parameters @xmath160 and @xmath166 are deduced from the value of snr and @xmath167 respectively .",
    "each configuration is repeated 200 times .",
    "[ [ heteroscedastic - versus - homoscedatic - thresholding . ] ] heteroscedastic versus homoscedatic thresholding .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we start by considering the framework defined by the assumptions of theorem [ thmbornesup ] , @xmath48 we consider the scad thresholding function with the universal threshold in a heteroscedastic setting .",
    "since the threshold used in theorem [ thmbornesup ] is known to be large @xcite , it is set to half of its value in the following .",
    "then heteroscedatic thresholding ( denoted he ) refers to the procedure that uses empirical estimates of the variance at each position @xmath173 whereas homoscedastic thresholding ( denoted ho ) uses @xmath174 ( based on the median absolute deviation ( mad ) of the coefficients at the finest resolution level @xcite ) .",
    "@xcite introduced the idea of wavelet - based thresholding in the context of noisy repeated measurements and discussed how to integrate the replicates in the analysis .",
    "they use in ( [ lambdajk ] ) the usual robust variance estimate @xmath174 instead of position - dependent estimators @xmath175 however , they do not investigate the effect of the choice of the threshold , and they do not handle the potential heteroscedasticity in their synthetic data , despite the presence of inter - individual variability .",
    "a simulation study ( not shown ) revealed that the strategy of taking the mean of the individual mad leads to better performance .",
    "therefore we consider this strategy for the homoscedastic part .",
    "we aim at comparing homoscedastic and heteroscedastic procedures regarding to the mean function reconstruction performance .",
    "performance of competed procedures are evaluated with respect to the mean integrated squared error ( mise ) of the reconstructed mean function .",
    "average mises are presented on table [ table : exreshomovshetero ] .",
    "the results show that heteroscedatic estimates greatly outperform homoscedastic ones in terms of functional reconstruction for all considered configurations . as expected , this is especially true when the heteroscedasticity intensity is high ( @xmath176 for @xmath177 ) .",
    "table 1 here    another argument supporting the use of heteroscedastic thresholding procedures concerns their adaptative behaviour in an homoscedastic framework : indeed , a simulation study in the homoscedastic framework ( @xmath48 with @xmath178 for all @xmath173 ) reveals similar reconstruction properties of homoscedastic and heteroscedastic estimates for a scad thresholding using the universal threshold .",
    "corresponding results are displayed in table  [ table : exreshomo ] .",
    "table 2 here    [ [ comparing - heteroscedastic - procedures ] ] comparing heteroscedastic procedures + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    despite good asymptotic properties , using the universal threshold may not be optimal in finite dimensional setting as mentioned by @xcite in their original paper .",
    "therefore we now focus on comparing heteroscedastic procedures for different choices of thresholds on simulated datasets . in order to consider more realistic cases , we consider datasets where heteroscedasticity corrupts both null and non null coefficients of the mean function . hence , starting from the same mean functions , the heteroscedasticity is as from now defined such that for @xmath90 in @xmath91 : @xmath179 the quantities @xmath156 and @xmath163 are defined as previously whereas @xmath180 is assumed to be a realization of a bernoulli distribution with parameters 0.3 .",
    "note that the pairs fixed effects-@xmath13/heteroscedasticity structure-@xmath181 are kept fixed for all the synthetic datasets .    for each mean function associated to a given heteroscedastic structure @xmath182 , the simulation design explores the following configurations : snr varies in @xmath183 and @xmath167 in @xmath184 .",
    "similarly , the signal and sample size are respectively set to @xmath169 and @xmath170 whereas each configuration is repeated 200 times",
    ". examples of simulated data are represented on figure [ fig : exsimdata ] for all considered main patterns .",
    "figure 1 here    then heteroscedastic thresholding procedures are competed for both soft and scad thresholding functions , @xmath185 and @xmath186 , and for both universal and sure threshold , @xmath187 and @xmath188 .",
    "performance of the procedures are evaluated with respect to the mean integrated squared error ( mise ) of the reconstructed mean functions .",
    "simulation results are presented on figure  [ fig : resmises ] .",
    "examples of reconstruction associated to median performance are represented in figure [ fig : exreconst ]    figure 2 and figure 3 here    as a main conclusion we can observe that using the sure threshold leads to improved performance for the reconstruction of the main effect in a heteroscedastic setting . as mentionned by @xcite in the homoscedastic framework , the universal threshold turns out to be too large in practice when dealing with finite dimensional signals .",
    "another interesting point concerns the interaction between the choice of the threshold and the thresholding function .",
    "when using the universal threshold , the scad thresholding gives indeed at least similar or improved reconstruction performance .",
    "this is expected since the scad thresholding is designed to smoothly correct the bias on high coefficients introduced by the soft thresholding .",
    "conversely such a difference vanishes when using the sure threshold for which soft and scad thresholdings exhibit similar performance .",
    "this finding can be explained by the adaptative behaviour of the sure threshold that compensates the existing bias on high coefficients .    by way of conclusion ,",
    "the overall simulation study encourages the use of the heteroscedatic thresholding in the context of functional regression with multiple samples .",
    "heteroscedastic thresholding keeps indeed the simplicity and the computational efficiency of the usual homoscedastic thresholding while being able to handle potential inter - individual variations .",
    "moreover , in practice , using the adaptative sure threshold , paired with the scad thresholding which enjoys good theoritical properties leads to improved reconstruction of the mean function .    as a last remark , we shall mention that the wider simulation study abovementioned with various sample and signal sizes shows that the overall mises orders of magnitude are more improved by a higher number of samples @xmath1 than by a larger signal size @xmath4 .      as an application to the proposed methodology",
    ", we analysed a seldi - tof mass spectrometry dataset issued from a study on ovarian cancer @xcite .",
    "this dataset was produced by the ciphergen wcx2 protein chip and is publicly available through the clinical proteomics programs databank ( ] , ovarian dataset 8 - 7 - 02 ) .",
    "the sample set consists of 162 serums profiles from women affected by an ovarian cancer and 91 control subjects .",
    "each spectra contains the measure of 15154 intensities characterizing as many mass over charge ( @xmath189 ) ratios .",
    "prior to analysis , raw data are background corrected using a quantile regression procedure , and spectra are aligned using a procedure based on wavelets zero crossings @xcite .",
    "moreover , we restrict on 512 intensities for @xmath189 ratios within the range [ 5200,5915 ] centered around the main central peak .",
    "mass spectrometry data represented a meaningful application for our method since @xcite show evidence for the presence of inter - individual variations occuring at specific ranges of @xmath189 ratios resulting in a sharp heterosecdasticity structure .",
    "we separately analysed the control group and the group affected by a cancer using an heteroscedastic scad thresholding procedure , with a sure threshold .",
    "mean reconstructed functions superimposed on experimental data are represented in figure [ fig : meanspectro ] .",
    "figure 4 here    we can observe that individuals from the control and cancer groups exhibit similar mean functional profiles .",
    "such an observation indicates that a nonparametric testing procedure would be on purpose to ascertain the presence of a significant effect of the group .",
    "although it is out of the scope of the present paper , in this context , taking into account the presence of potential inter - individual variations appears as critical for the application of such testing procedure .",
    "part of this work was supported by the interuniversity attraction pole ( iap ) research network in statistics p5/24 .",
    "we are grateful to anatoli juditsky for constructive and fruitful discussions .",
    "amato , u. and t.  sapatinas ( 2005 ) .",
    "wavelet shrinkage approaches to baseline signal estimation from repeated noisy measurements .",
    "_ 51 _ , 2150 .",
    "antoniadis , a. , j.  bigot , s.  lambert - lacroix , and f.  letue ( 2007 ) .",
    "non parametric pre - processing methods and inference tools for analyzing time - of - flight mass spectrometry data .  _",
    "3_(2 ) , 127147 .",
    "antoniadis , a. and j.  fan ( 2001 ) .",
    "regularization of wavelet approximations .   _",
    "96_(455 ) , 939955 .",
    "antoniadis , a. and c.  lavergne ( 1995 ) .",
    "variance function estimation in regression by wavelet methods .",
    "_ 103 _ , 3142 .",
    "antoniadis , a. and t.  sapatinas ( 2007 ) . estimation and inference in functional mixed - effects models .  _",
    "51_(10 ) , 47934813 .",
    "cai , t. and l.  wang ( 2008 ) .",
    "adaptative variance function estimation in heteroscedastic nonparametric regression .  _",
    "36_(5 ) , 20252054 .",
    "coifman , r. and d.  donoho ( 1995 ) .",
    "translation invariant de - noising .",
    "_ 103 _ , 125150 .",
    "delyon , b. and a.  juditsky ( 1997 ) . on the computation of wavelet coefficients .  _",
    "88_(1 ) , 4779 .",
    "devore , r. and g.  lorentz ( 1993 ) . .",
    "springer verlag .",
    "donoho , d. ( 1994 ) .",
    "l. schumaker , ed . , `",
    "recent advances in wavelet analysis ' .",
    "donoho , d. and i.  johnstone ( 1994 ) .",
    "ideal spatial adaptation by wavelet shrinkage .  _",
    "81_(3 ) , 425455 .",
    "donoho , d. and i.  johnstone ( 1995 ) . adapting to unknown smoothness via wavelet shrinkage .",
    "_ 90 _ , 12001224 .",
    "donoho , d. , i.  johnstone , g.  kerkyacharian , and d.  picard ( 1995 ) .",
    "wavelet shrinkage : asymptopia .   _",
    "57_(2 ) , 371394 .",
    "eckel - passow , j.  e. , a.  l. oberg , t.  m. therneau , and h.  r. bergen ( 2009 , jul ) .",
    "n insight into high - resolution mass - spectrometry data .",
    "_ 10 _ , 481500",
    ".    fan , j. and r.  li ( 2001 ) .",
    "variable selection via nonconcave penalized likelihood and its oracle properties .   _",
    "96_(456 ) , 13481360 .",
    "frazier , m. , b.  jawerth , and g.  weiss ( 1991 ) . .",
    "number  79 .",
    "american mathematical society .",
    "gasser , t. , l.  stroka , and c.  jennen - steinmetz ( 1989 ) .",
    "residual variance and residual pattern in nonlinear regression .",
    "_ 73 _ , 625633 .",
    "giacofci , m. , s.  lambert - lacroix , g.  marot , and f.  picard ( 2013 ) .",
    "wavelet - based clustering for mixed - effects functional models in high dimension .  _",
    "69_(1 ) , 3140 .",
    "hrdle , w. , g.  kerkyacharian , d.  picard , and a.  tsybakov ( 1998 ) . .",
    "springer .",
    "johnstone , i. and b.  silverman ( 1997 ) .",
    "wavelet threshold estimators for data with correlated noise .   _",
    "59_(2 ) , 319351 .",
    "juditsky , a. and b.  delyon ( 1996 ) . on minimax wavelets estimators .",
    "_ 3 _ , 215228 .",
    "mallat , s. ( 1989 ) .",
    "multiresolution approximations and wavelet orthonormal bases of l2(r ) .   _",
    "315_(1 ) , 6987 .",
    "morris , j.  s. , p.",
    "j. brown , r.  c. herrick , k.  a. baggerly , and k.  r. coombes ( 2008 , jun ) .",
    "ayesian analysis of mass spectrometry proteomic data using wavelet - based functional mixed models .",
    "_ 64 _ , 479489 .",
    "morris , j.  s. and r.  j. carroll ( 2006 ) .",
    "avelet - based functional mixed models .",
    "_ 68 _ , 179199 .",
    "nason , g. ( 2008 ) . .",
    "springer , new york .",
    "park , c. ( 2010 ) .",
    "block thresholding wavelet regression using \\{scad } penalty .  _",
    "140_(9 ) , 2755  2770 .",
    "petricoin , e.  f. , a.  m. ardekani , b.  a. hitt , p.",
    "j. levine , v.  a. fusaro , s.  m. steinberg , g.  b. mills , c.  simone , d.  a. fishman , e.  c. kohn , and l.  a. liotta ( 2002 , feb ) . .",
    "_ 359 _ , 572577 .",
    "stein , c. ( 1981 ) .",
    "estimation of the mean of a multivariate normal distribution .  _",
    "9_(6 ) , 11351151 .",
    "von sachs , r. and b.  macgibbon ( 2000 ) .",
    "nonparametric curve estimation by wavelet thresholding with locally stationary errors .  _",
    "27_(3 ) , 475499 .",
    "first let us recall the aim of the proof concerning the lower bound in the minimax context . since @xmath190 for some @xmath191 we have to show that @xmath192 for some constant @xmath193 .",
    "next we reduce the class @xmath33 to a subclass @xmath194 of finite number @xmath195 of functions in @xmath33 because the @xmath196 is greater over a larger class .",
    "the family @xmath197 is constructed by small perturbation of @xmath198 , so that the distance between each pairs of functions is small and at least of order @xmath199 then the problem can be reduced to the one of testing by the following way @xmath200 with @xmath201 the power function associated to @xmath61 , where @xmath61 is any test that allows to distinguishing between the @xmath195 hypotheses , the @xmath95-th of them stating that the observations of model ( [ functionalmodel ] ) are drawn from the @xmath95-th element of the set @xmath194 . to bound @xmath202 by",
    "@xmath203 we need to major the maximum of the kullback distance @xmath204 between observations of model ( [ functionalmodel ] ) associated with @xmath205 and the ones associated with @xmath206 . for instance",
    "when @xmath207 we have @xmath208 without loss of generality , since variances are assumed to be bounded , we can consider model ( [ functionalmodel ] ) with @xmath209 , @xmath210 @xmath211 independent and identically distributed gaussian random variables with zero - mean and variance @xmath212 in this case , we have @xmath213 let us come back to the proof of the lower bound .",
    "this proof can be decomposed in two steps . for the usual term in @xmath214,$ ]",
    "we just have to use the usual proof for the besov classes by adding the factor @xmath1 because of the multiplicative term @xmath1 in ( [ kulb ] ) .",
    "we now give the proof corresponding to the term in @xmath215.$ ] we only need two functions in order to construct @xmath216 that is @xmath217 for @xmath218 we put @xmath219 for all @xmath220,$ ] and @xmath221 where @xmath222 with support equal to @xmath223 $ ] such that @xmath224 and @xmath225 .",
    "we have @xmath226 and @xmath227 so we also have @xmath228 and @xmath229 hence , the family @xmath230 is inclued in the besov class @xmath49 and the @xmath0-distance between the two functions are at at least @xmath231 since @xmath232 we have @xmath233 and @xmath234 for any estimator @xmath235        this proof is an adaptation of the proof of theorem 1 of @xcite .",
    "we denote by @xmath240 , the estimator @xmath241 with @xmath242 instead of @xmath243 in([lambdajk ] ) and @xmath244 the associated estimator .",
    "we introduce @xmath245 where @xmath246 is such that @xmath247 let us note that ( see proposition 1 of @xcite ) , there exists some constant @xmath248 such that this function belongs to @xmath249 the global quadratic risk can then be decomposed such that : @xmath250 \\notag \\\\   & \\quad \\ ; + { \\ensuremath{\\mathbb{e}}}(|\\widehat{\\alpha } - \\alpha |^2 ) + { \\ensuremath{\\mathbb{e}}}\\left [ \\sum_{j=0}^{j_0 } \\sum_k | \\widetilde{\\beta}_{jk } - \\beta_{jk}|^2 \\right ] \\label{riskl2 } \\\\     & \\qquad + { \\ensuremath{\\mathbb{e}}}\\left [ \\sum_{j = j_0 + 1}^{j_1 } \\sum_k | \\widetilde{\\beta}_{jk } - \\beta_{jk}|^2 \\right ]   + \\| \\mu -\\mu_{j_1}\\|_{2}^2 \\notag \\\\   & = t_1 + t_2 + t_3 + t_4 + t_5 . \\notag\\",
    "] ] we seek to bound from above each term of the decomposition . by using the delta method based on a taylor expansion of the thresholding function and",
    "since @xmath115 are @xmath116-consistent estimates of variances , we get : @xmath251 with @xmath252 being a positive constant .",
    "the model ( [ waveletmodel ] ) leads to @xmath253 \\quad \\text{and } \\quad    d_{\\bullet , jk}\\sim { \\mathcal{n}}\\left [ \\beta_{jk } , \\frac{\\sigma^2_{jk}}{mn } \\right].\\ ] ] approximation coefficients in @xmath254 are left unchanged , hence we have : @xmath255 in the same way , terms in @xmath256 are not thresholded , hence we get : @xmath257   =   \\sum_{j=0}^{j_0 } \\sum_k { \\ensuremath{\\mathbb{e}}}\\left ( |   d_{\\bullet jk } - \\beta_{jk}|^2 \\right )   \\leq c_3 \\ ; 2^{j_0 } \\frac{\\sigma^2_{\\text{max}}}{nm } , \\ ] ] with @xmath258 being a positive constant .",
    "the term @xmath259 is the approximation term that can be bounded such that ( see proposition 1 of @xcite ) : @xmath260^{2s'}.\\ ] ] finally , bounding term @xmath261 needs the use of constraint ( [ contdelta ] ) with @xmath262 , we have @xmath263}_{t_{4.1 } }",
    "\\\\ + \\underbrace{{\\ensuremath{\\mathbb{e}}}\\left [ \\sum_{j = j_0 + 1}^{j_1 } \\sum_k |\\varepsilon^d_{\\bullet jk}|^2 \\mathbf{1}_{|\\varepsilon^d_{\\bullet jk}| >",
    "\\frac{\\lambda ' \\sigma_{jk}}{2\\sqrt{mn } } } \\right]}_{t_{4.2}},\\notag\\end{gathered}\\ ] ] where @xmath264 for the term @xmath265 , since @xmath266 , we obtain : @xmath267 for @xmath268 , we have with cauchy - schwartz and exponential inequalities : @xmath269^{\\frac12 } \\notag \\\\   & c_{4.2 } \\leq \\sum_{j = j_0 + 1}^{j_1 } \\frac{\\sigma^2_{\\text{max}}}{mn } \\exp \\left [ \\frac{-\\left(\\lambda \\sigma_{jk}/\\sqrt{mn}\\right)^2}{{2\\sigma^2_{jk}}/{mn}}\\right]^\\frac12 \\notag \\\\   & \\leq c_{4.2 } \\ ; \\frac{\\sigma^2_{\\text{max}}}{n } m^{-2 }   2^{j_1 }   \\leq c_{4.2 } \\ ; \\frac{\\sigma^2_{\\text{max}}}{mn } ( \\log m)^{-1}.\\notag\\end{aligned}\\ ] ]    in order to fix the parameter @xmath112 , the terms @xmath256 and @xmath265 need to be balance according to @xmath4 , which leads to : @xmath270.\\ ] ] by replacing @xmath271 in terms @xmath256 and @xmath265 , the inequality ( [ riskl2 ] ) becomes : @xmath272^{\\frac{2s}{2s+1 } } \\left ( \\log m \\right)^{\\frac{-2s'}{2s+1 } }   \\notag \\\\      & \\qquad \\qquad + c_{4.1 } \\ ; \\sigma_{\\text{max}}^{2-p } \\ ;",
    "\\left [ \\frac{\\log m}{mn } \\right]^{\\frac{2s}{2s+1 } } \\left ( \\log m \\right)^{\\frac{-2s'}{2s+1}}\\notag \\\\    & \\qquad \\qquad \\qquad \\qquad + c_{4.2 } \\ ; \\sigma^2_{\\text{max } } \\frac{m^{-\\frac18}}{n \\log m } + c_5 \\left [ \\frac{\\log m}{m } \\right]^{2s ' } \\notag \\end{aligned}\\ ] ] the convergence of the overall expression is limited by the terms in @xmath273 $ ] and in @xmath274.\\ ] ] the latter leads to a limitation in @xmath275 & \\qquad \\text{if } \\ ; \\ ; \\frac{2}{2s+1 } < p < 2\\\\   \\mathcal{o } \\left [ \\left ( \\frac{1}{mn } \\right)^{\\frac{2s}{2s+1 } } \\right ] & \\qquad \\text{if } \\ ; \\ ; p \\geq 2 \\end{aligned}\\ ] ]        for recall , the scad thresholding function is given by : @xmath277 and we are looking for a function @xmath278 such that : @xmath279 to define the sure - scad criterion : @xmath280 with @xmath281 . by defining @xmath282 as the weakly differentiable function : @xmath283 with @xmath284 , the relation ( [ decompscadfn ] ) is satisfied .",
    "we can then compute : @xmath285 \\mathbf{1 } _ { \\ { 2\\lambda < |d_{jk}|",
    "\\leq a\\lambda \\ } } \\\\ &   \\sum_{k=0}^{2^j-1 } \\frac{\\partial g(d_{jk})}{\\partial d_{jk } } = \\sum_{k=0}^{2^j-1 } \\left [ -\\mathbf{1 } _ { \\ { |d_{jk}| \\leq \\lambda \\ } } + \\frac{1}{a-2 } \\mathbf{1 } _ { \\ { 2\\lambda < |d_{jk}| \\leq a\\lambda \\ } } \\right],\\end{aligned}\\ ] ] which leads finally to the criterion ( [ sure.scad ] ) in section [ thstrategies ] .",
    "= 0.1,0.25,1 from a high level to a low level ) are considered .",
    "soft and scad thresholding functions differ by plotting colors ( respectively in orange and blue ) whereas threshold choices universal and sure differ by the line types ( respectively in dashed and solid line ) .",
    "vertical bars are associated to the standard deviations of the resulting mises .",
    "[ fig : resmises ] ]    .average mise ( and associated standard deviations ) on 200 repetitions for the fixed effects ` blocks ` , ` bumps ` , ` heavisine ` and ` dopller ` in a heteroscedastic framework .",
    "the heteroscedastic structure is defined as in equation [ heterostruct ] with snr and @xmath167 varying respectively in ( 1,5 ) and ( 0.1,1 ) .",
    "the sample size is set to @xmath170 and the signal size to @xmath286 .",
    "final estimates are based on a scad thresholding using the universal threshold @xmath187 . [ cols=\"<,^,^,^,^,^,^,^,^ \" , ]"
  ],
  "abstract_text": [
    "<S> the problem of estimating the baseline signal from multisample noisy curves is investigated . </S>",
    "<S> we consider the functional mixed effects model , and we suppose that the functional fixed effect belongs to the besov class . </S>",
    "<S> this framework allows us to model curves that can exhibit strong irregularities , such as peaks or jumps for instance . </S>",
    "<S> the lower bound for the @xmath0 minimax risk is provided , as well as the upper bound of the minimax rate , that is derived by constructing a wavelet estimator for the functional fixed effect . </S>",
    "<S> our work constitutes the first theoretical functional results in multisample non parametric regression . </S>",
    "<S> our approach is illustrated on realistic simulated datasets as well as on experimental data .    * keywords.-*functional mixed effects models ; minimax risk ; besov class ; wavelet estimator ; </S>"
  ]
}