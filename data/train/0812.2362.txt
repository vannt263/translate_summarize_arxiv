{
  "article_text": [
    "in collider physics , as soon as the final state involves hadronic particles , jets become fundamental objects present in many studies .",
    "even if the idea of a jet as a bunch of collimated partons or hadrons is what one always keeps in mind , the concept of a parton itself is ambiguous and as a consequence different jet definitions exist , possibly leading to different sets of jets for the same hadronic event .    in practice , many jet definitions , which we shall review in section [ sec : jetdefs ] , have been used for recent analysis .",
    "it turns out however that , among them , some fail to satisfy the fundamental requirements agreed upon in 1990 ( section [ sec : snowmass ] ) .",
    "the first series of results presented in these proceedings addresses those failures and give solutions that have been proposed recently .",
    "this includes the fastjetimplementation of the @xmath2 algorithm , section [ sec : ktspeed ] , as well as the the siscone and anti-@xmath2 algorithms , sections [ sec : siscone ] and [ sec : antikt ] .",
    "finally , in section [ sec : filtering ] , we will briefly discuss a filtering technique using jet substructure that has been recently proposed to reduce sensitivity to the underlying event .    since one has the choice between different jet definitions to perform jet analysis ,",
    "a legitimate question is which of them is best suited for a given analysis one wants to perform . in section [ sec : quality ] of these proceedings , we answer that question in the case of simple kinematic reconstructions at the lhc . to quantify the efficiency of a jet definition ,",
    "we introduce a figure of merit that is directly related to an effective luminosity ratio .",
    "we will see that not being careful enough in the choice of the jet algorithms and its parameters ( basically the radius @xmath3 ) can lead to important consequences for potential discoveries at the lhc .",
    "to begin with , let us briefly review the algorithms that have been widely used over the past two decades for jet reconstruction in @xmath5 collisions",
    ". generally speaking , they fall in two categories that we discuss hereafter .",
    "* successive recombinations . * the first family of jet clustering algorithms works by defining a distance between any pair of objects and a beam distance for every object .",
    "one identifies the smallest distance ; if it is a beam distance , the object is called a jet and removed from the event , otherwise , the two objects are recombined in a single one .",
    "the procedure is repeated until no object are left in the event .",
    "two well - known examples of recombination algorithms are the @xmath2 @xcite and cambridge / aachen ( c / a ) @xcite algorithms , using the distance @xmath6         &    & \\\\[-2 mm ] d_{ib } & = & r^2\\,k_{t , i}^{2p},\\nonumber\\end{aligned}\\ ] ] where @xmath7 ( @xmath8 ) corresponds to the @xmath2 ( c / a ) case .    * cone . * the cone algorithms aim at defining jets as dominant directions of energy flow . to achieve that goal",
    ", one defines the concept of _ stable cone _ as a circle of fixed radius in the @xmath9 plane such that the sum of the 4-momenta of the particles inside it points in the direction of its centre .",
    "most of the cone algorithms used so far are _ seeded _ in the sense that the search for stable cones starts from a given set of seeds from which one iterates the cone contents until it is stable . since stable cones might overlap , one can not define them as jets directly .",
    "two different techniques are in use to overcome this overlapping problem .    the first option , that we shall refer to as _ cone algorithms with split  merge _",
    ", first identify the set of all stable cones , then run a split  merge procedure on them .",
    "the latter repeatedly identifies the two hardest ( originally , in @xmath10 ) overlapping cones ; if their overlap passes a threshold fraction ( the overlap parameter @xmath11 ) of the softer of the selected cones , they are merged .",
    "otherwise , they are split by associating every particle to the cone to whose centre it is closer .    for the seeded versions of the cone algorithms with split ",
    "merge , one usually starts with all the particles in the event ( usually with a @xmath12 threshold ) as seeds , as is the case for the cdf jetclu @xcite and atlas cone algorithms . a step forward is to add as new seeds the midpoints between all pairs of stable cones found after this first pass .",
    "this is the case for the majority of the recently - used cone algorithms @xcite , noticeably the cdf midpoint , d0 run ii cone and pxcone algorithms .",
    "the second solution to the problem of overlapping stable cones , _ iterative cone algorithms with progressive removal ( ic - pr ) _ , starts by iterating the stable cone search from the hardest seed in the event .",
    "the resulting stable cone is called a jet and its contents are removed from the event .",
    "one then proceeds by iterating from the hardest remaining seed , until all the particles are clustered .",
    "the characteristic feature of this type of cone algorithm is that it produces hard jets that are circular and soft - resilient . in other words ,",
    "the addition of soft particles does not modify the shape of the hard jets , which is sometimes seen as an advantage for calibrating the jets .",
    "the cms iterative cone algorithm @xcite falls in this sub - category .",
    "back in 1990 , a list of fundamental requirements that every jet definition has to fulfil was agreed upon @xcite .",
    "it is known as the _ snowmass accords _ and consists of the 5 following criteria :    simple to implement in an experimental analysis;[it : snow1 ]    simple to implement in the theoretical calculations;[it : snow2 ]    defined at any order of perturbation theory;[it : snow3 ]    yields finite cross section at any order of perturbation theory;[it : snow4 ]    yields a cross section that is relatively insensitive to hadronisation.[it : snow5 ]    as consequences , because of constraints [ it : snow1 ] and [ it : snow5 ] , we want the implementation of the algorithm to be fast enough and as insensitive as possible to the underlying event ( ue ) so that it can be used in experimental analysis .",
    "also , the requirement that the cross section remains finite at any order of perturbation theory implies that the algorithm has to be infrared and collinear ( irc ) safe .",
    "indeed , if it was not the case , cancellation between real emissions and virtual corrections would not happen properly , leading to divergences in perturbative cross - sections .          beside its rather large sensitivity to the ue ,",
    "one argument that was sometimes used against the @xmath2 algorithm was its relatively slow running time .",
    "the _ ktjet _ @xcite and _ ktclus _ @xcite implementations , of complexity @xmath13 where @xmath14 is the number of particles in the event , have a clustering time around 1 second for @xmath15 , compared to about 0.2 seconds for the midpoint cone with a 1 gev seed threshold .    remarkably , the complexity can be reduced to @xmath16 using computational - geometry techniques , there exists a @xmath17 implementation that turns out to be faster than the @xmath18 @xcite . ] @xcite .",
    "as seen on figure [ fig : speed ] ( @xmath2 ( fastjet ) curve ) , this leads to a considerable improvement .",
    "it had already been noticed that the jetclu algorithm had some ir unsafety problems _",
    "e.g. _ when two hard particles were distant by more that @xmath3 and less that @xmath19 , an additional infinitely soft gluon added between the particles could change the clustering from 2 jets to 1 jet , yielding unreliable cross - sections at nlo in the inclusive jet cross - section .",
    "the midpoint algorithm was then introduced to cure that problem .",
    "unfortunately , this is not the end of the story .",
    "even if situations with 2 hard particles in a common vicinity ( plus another one , hadronic or electroweak to balance @xmath12 ) are ir safe provided one uses the midpoint algorithm instead of jetclu , the problem has just been shifted to situations with 3 hard particles in a common vicinity .",
    "this is illustrated in figure [ fig : irfailure ] , where we have clustered a 3-hard - particle event twice  with , fig .",
    "[ fig : irfailure](b ) , and without , fig .",
    "[ fig : irfailure](a ) an additional infinitely soft gluon  and notice that one finds different stable cones in the two cases .",
    "this means that the midpoint algorithm is also ir unsafe , though one order further in the perturbative expansion in the strong coupling than the jetclu algorithm .    to solve that problem to all orders in the perturbative expansion",
    ", we first notice that the ir unsafety comes from the fact that , in the event without the soft gluon , the stable cone enclosing particles 2 and 3 has been missed . since the mathematically well - defined set of stable cones is irc safe , _",
    "i.e. _ it changes neither when splitting a particle collinearily nor when adding infinitely soft particles ( up to harmless stable cones made only of those soft particles ) , finding a method that provably identifies all stable cones , guarantees irc safety .",
    "we then observe that every circular enclosure of given radius @xmath3 in the @xmath9 plane can be translated in any direction until it touches one point , then rotated around that point until it touches a second one , without changing its contents .",
    "therefore , enumerating all pairs of points , and for every pair of points considering the two circles of radius @xmath3 they define and the four possible inclusion / exclusion states of the edge particles , we enumerate all possible enclosures . for each of them",
    "we can then test if it is stable or not , which solves our problem .",
    "the complexity of this algorithm is @xmath13 ( a factor @xmath20 coming from the enumeration of the pairs of parent points and an additional factor of @xmath14 to test the stability of every enclosure ) .",
    "it is actually possible , using extra geometric observations , to improve that complexity to @xmath21 .",
    "this has been implemented @xcite in a new algorithm named _",
    "siscone _ ( seedless infrared safe cone ) .",
    "[ fig : speed ] shows that siscone runs faster than the ir - unsafe midpoint algorithm ( of order @xmath22 ) , even when a seed threshold of 1 gev is applied .      in a similar way as for the case of the midpoint algorithm , we can show that the iterative cone algorithm with progressive removal ( ic - pr ) also suffers from divergences in the perturbative series , at the same order as midpoint , this time due to collinear unsafety . in order to see that , first consider the event of fig .",
    "[ fig : uvfailure](a )",
    ". iterating from the hardest seed gives one jet containing all particles .",
    "if one splits the hardest of these particles in two collinear ones , fig .",
    "[ fig : uvfailure](b ) , iteration starts with the leftmost particle and 2 jets are found .",
    "this means that the ic - pr is collinear unsafe at the level of 3 particles ( + 1 to balance @xmath12 ) .    to address this issue",
    ", we will go back to the recombination - type algorithms .",
    "we have already mentioned that setting @xmath8 or @xmath23 in eq .",
    "( [ eq : distance ] ) reproduces the c / a and @xmath2 algorithms respectively .",
    "we now introduce the _ anti-@xmath2 algorithm _ , corresponding to @xmath24 in eq .",
    "( [ eq : distance ] ) @xcite .    at first sight",
    ", it is not obvious what this new , irc - safe , algorithm has to do with the ic - pr .",
    "however , since hard particles will be associated a small anti-@xmath2 distance , they will grow in circles , clustering softer particles in their vicinity up to a distance @xmath3 .",
    "this thus leads to soft - resilient hard jets , _",
    "i.e. _ the boundary of the hard jets is not affected by soft radiation , the precise characteristic feature of the ic - pr .    finally , the anti-@xmath2 algorithm is also amenable to a fast implementation ( see fig . [",
    "fig : speed ] ) using the same techniques as for the @xmath2 algorithm ( see section [ sec : ktspeed ] ) .",
    "one of the promising potential improvement of jet clustering is to make use of the jet substructure .",
    "for example , we can use the following filtering technique to reduce the contamination due to the underlying event :    cluster the event using , _",
    "e.g. _ , the c / a algorithm with a radius @xmath3 ,    for each jet , recluster it using a smaller radius @xmath25 and keep only the @xmath26 hardest jets as part of the initial jet , throwing the other subjets .",
    "the aim of filtering is to remove contamination due to soft background like the underlying event while keeping as much as possible of the perturbative radiation .",
    "this has already proven @xcite to be efficient in higgs searches in the @xmath27 channel .    in",
    "what follows we shall use @xmath28 and @xmath29 , though a more extensive study of the effects of these parameters would be interesting .",
    "now that we dispose of 5 irc - safe jet algorithms  the @xmath2 , c / a , anti-@xmath2 , siscone and c / a+filtering algorithms , all available from fastjet@xcite  we may ask , given an analysis involving jets we want to perform , which jet definition , _",
    "i.e. _ the jet algorithm and its parameters , is best suited . in this section",
    "we address that question for the case of kinematic reconstructions at the lhc .",
    "we first introduce a series of benchmark processes we will investigate , then a figure of merit that allows one to quantify the performance of a jet definition and finally present our results , both with and without including pileup . for a more extensive discussion , see @xcite .",
    "we will study the following 3 processes :    @xmath30 as a source of quark jets .",
    "we reconstruct the @xmath31 from the 2 hardest jets in the event ( imposing a maximal rapidity difference @xmath32 between them ) .",
    "@xmath33 as a source of gluon jets .",
    "we reconstruct the @xmath34 from the 2 hardest jets in the event ( imposing again @xmath35 ) .    a @xmath36 pair with fully hadronic decay into 6 jets ( 4 jets from the 2 @xmath37 bosons and 2 jets from the @xmath38 and @xmath39 quarks ) . the two @xmath37 s and then the 2 tops are reconstructed from the 6 hardest jets in the event - jets",
    "are tagged assuming the @xmath38 mesons are stable ; then the two @xmath37 are reconstructed by pairing the 4 remaining jets so as to minimise @xmath40 ; finally , the two top jets are reconstructed by matching the @xmath38-jets with the @xmath37 so as to minimise the mass difference between the 2 top candidates . ] .    for the case of quark and gluon jets , we can study the scale dependence by varying the mass of the @xmath41 boson ( in practice , between 100 gev and 4 tev ) .",
    "the last case , fully hadronic @xmath36 decay , allows us to study the relevance of our results in more complex environments , where one risks tensions between resolving the jets and capturing the perturbative radiation . in each of these situations",
    "we have generated a sample of events using pythia 6.4 tune dwt .               in order to quantify",
    "which jet definition is performing better than another , we need a figure of merit . since jets are expected to represent an original parton , one might be tempted to quantify the efficiency by comparing the jets to the initial partons .",
    "but because partons are a ill - defined concept ( especially at nlo ) , this is not robust enough .",
    "another option would be to fit a given distribution , _",
    "e.g. _ a gaussian , to the peak in the mass spectrum .",
    "but since the shape of the peak can be asymmetric , this would not produce a reliable result either .    for these reasons",
    ", we will quantify the efficiency of a jet definition based on the observation that , if two peaks have similar number of events then the narrower is the better one .",
    "we therefore introduce the quality measure @xmath42 as the _ width of the smallest possible window that contains a fraction @xmath43 of the events_. the smallest values of @xmath42 should then correspond to the most efficient jet definitions .",
    "this intuitively does what we want in the sense that a `` better '' jet definition should contain a given fraction of the events in a smaller window and therefore have a smaller @xmath42 .",
    "this quality measure can be related to a variation of luminosity needed to maintain a constant significance for a signal relative to background . for a jet definition @xmath44 ,",
    "the latter is defined as @xmath45 . assuming a constant background",
    ", we thus have @xmath46^{1/2 }    = \\left[\\frac{q_{f = z}^{w}({\\mathrm{jd}\\xspace}_2 ) } { q_{f = z}^{w}({\\mathrm{jd}\\xspace}_1)}\\right]^{1/2}.\\ ] ] two jet definitions @xmath47 and @xmath48 .",
    "this relation comes from the fact that the number of signal events is fixed by the fraction @xmath43 in the quality measure , while the background is directly proportional to the width of the window _",
    "i.e. _ to @xmath42",
    ". a `` better '' definition , _",
    "i.e. _ a smaller @xmath42 , thus corresponds to a larger discriminating power .",
    "we can then define an effective luminosity ratio @xmath49 ^ 2          = \\frac{{\\ensuremath{q_{f = z}^{w}}\\xspace}({\\mathrm{jd}\\xspace}_2)}{{\\ensuremath{q_{f = z}^{w}}\\xspace}({\\mathrm{jd}\\xspace}_1)}.\\nonumber\\end{aligned}\\ ] ] this means that a jet definition @xmath47 with a quality measure twice as large as @xmath48 will need twice the integrated luminosity in order to achieve the same discriminating power as @xmath48 .",
    "for the processes presented in section [ sec : processes ] , we have clustered our event samples using the 5 irc safe jet algorithms and varying the parameter has been fixed to 0.75 , the preferred choice at the time being .",
    "] @xmath3 between 0.1 and 1.5 .",
    "we can then compute the quality measure in each of those cases ( see figure [ fig : qa ] ) , which allows us to ( i ) compare different algorithms , and ( ii ) , for a given algorithm , find the optimal value @xmath50 of the parameter @xmath3 .",
    "figure [ fig : rhol ] summarises our results in a more compact and physical way : we have plotted the effective luminosity ratios corresponding to a series of selected processes : quark and gluon jets at 100 gev and 2 tev , and top reconstruction in the @xmath36 sample . for every process , @xmath51has been normalised to the best jet definition for that process .",
    "we observe a few important features : first of all , in general , siscone and c / a with filtering tend to perform slightly better than the @xmath2 , c / a and anti-@xmath2 algorithms , especially at higher scales ( with the exception of the top reconstruction where all algorithms have similar performances ) .",
    "for example , for the 2 tev gluon case , choosing the @xmath2 algorithm instead of siscone or c / a with filtering which are the preferred choices , translates into a cost of nearly 50% in the effective luminosity ratio .",
    "furthermore , the efficiency of a jet definition strongly depends on @xmath3 and not choosing the preferred value @xmath50 can be very costly .",
    "on top of that , @xmath50 varies significantly from one process to another .",
    "it increases from @xmath52 at small scales up to @xmath53 at tev scales .",
    "@xmath50 is also bigger for gluon jets than for quark jets .",
    "practically , using siscone with @xmath54 , the preferred choice for quark jets at 100 gev , to cluster gluon jets at 2 tev costs a factor of 2 in @xmath51compared to the best definition for that process .",
    "conversely , using the preferred value for gluon jets at 2 tev  _ i.e. _ siscone with @xmath55 or c / a with filtering and @xmath56  to cluster quark jets at 100 gev also leads to @xmath51increasing by at least 50% .",
    "pileup corresponds to the fact that multiple @xmath5 interactions can happen at the same time . for the case of the lhc at the designed luminosity ,",
    "one typically has an average of about 25 collisions per bunch crossing .",
    "this produces a large number of additional soft particles that form a reasonably uniform background over the detector .    for our concerns",
    ", pileup has two consequences . because it adds",
    "a background to every jets , the @xmath12 of the jets will be overestimated and the position of the mass peak in our kinematic reconstructions will be shifted towards larger masses . also , because the amount of pileup varies from one event to another , the reconstructed peak will be smeared , an effect that directly affects our quality measure .",
    "we therefore want a ( simple and generic enough ) method to subtract the contamination from the pileup background on an event - by - event basis . in practice , we will follow the subtraction method suggested in @xcite : for each jet @xmath57 in an event , we first compute its ( 4-vector ) area @xcite @xmath58 .",
    "the subtracted jet is then obtained using @xmath59 where @xmath60 is the average density of pileup per unit area .",
    "since the density of background is reasonably uniform , we estimate @xmath60 for each event using @xcite @xmath61 , where all the jets ( up to a maximal rapidity ) are included in the computation of the median .    in practice",
    ", we have considered the same benchmark processes as in the study without pileup .",
    "pileup is added to each event under the form of a random ( poisonian ) number of minimum bias events , also generated with pythia 6.4 tune dwt .",
    "we apply the same reconstruction procedure as above and compute the quality measure @xmath42 with pileup effects subtracted or not .",
    "we illustrate our results by showing on figure [ fig : rholpu ] the effective luminosity ratio @xmath51as obtained for a few representative processes .",
    "we compare the results with pileup ( subtracted or not ) with the corresponding quality measures obtained without pileup ( solid curves ) .",
    "the first observation is that if the pileup is not subtracted ( dashed curves ) , it causes a large degradation of the quality measure .",
    "the preferred @xmath3 is also shifted to smaller values , which one can explain by the fact that the contamination due to pileup background is smaller at small @xmath3 .",
    "the second element of information comes from the case where we apply our subtraction method ( dotted curves ) .",
    "obviously , even if the subtraction is not perfect  the quality is still larger than before pileup addition  one sees a significant improvement compared to the situation without subtraction .",
    "this means that the subtraction method gives narrower peaks _ i.e. _ the smearing due to pileup fluctuations between events is strongly reduced by the subtraction . on top of that , after the subtraction has been performed , the preferred value for @xmath3 obtained in the situation without pileup is no longer strongly disfavoured to the profit of a smaller @xmath3 .",
    "this is important since it implies that our conclusions from section [ sec : resnopu ] are still valid in the presence of pileup provided one uses subtraction .",
    ".overview of some jet algorithms used recently in experimental or theoretical work .",
    "sr@xmath62 sequential recombination ( with @xmath63 , see ( [ eq : distance ] ) ) ; sc = seedless cone ( finds all cones ) ; ic = iterative cone ( with midpoints @xmath64 , ratcheting @xmath65 ) , using either split  merge ( sm ) or progressive removal ( pr ) in order to deal with overlapping stable cones .",
    "regarding irc status , given @xmath66 hard particles in a common neighbourhood , ir@xmath67 indicates that the addition of 1 extra soft particle can modify the number of final hard jets , while coll@xmath67 means that the collinear splitting of one of the particles can modify the number of final hard jets . [ cols=\"<,<,^,<\",options=\"header \" , ]     the first point we have addressed concerns the jet algorithms themselves .",
    "as summarised in table [ tab : algs ] , some of the commonly used algorithms fail to satisfy the fundamental requirements of infrared and collinear safety .",
    "we have introduced siscone and the anti-@xmath2 algorithm to cure infrared unsafeties of the midpoint algorithm and collinear unsafeties of the ic - pr .",
    "we have also mentioned a new implementation of the @xmath2 algorithm leading to a sizeable improvement in speed .",
    "we have then addressed the problem of quantifying the performances of the jet definitions in the case of kinematic reconstructions at the lhc . from that study",
    ", one learns important messages showing that optimisation of the jet definition can significantly improve the potential for an early discovery at the lhc .",
    "we have shown that the preferred jet definition varies significantly from one process to another .",
    "siscone and c / a with filtering tend to perform slightly better than the other algorithms and the preferred value for @xmath3 goes from @xmath0 for 100 gev jets to @xmath1 for tev jets with a slightly larger value for gluon jets compared to quark jets .",
    "this indicates that a single choice for @xmath3 is not sufficient to cover the whole kinematic range at the lhc .",
    "finally , if one includes the effects of pileup , we have seen that , provided we use an adequate subtraction procedure , the conclusions obtained in the analysis without pileup hold once pileup is added , noticeably , there is no need to take a smaller value of @xmath3 .    in the more complex case of top reconstruction where jet clustering involves tension between catching enough radiation to reconstruct the jet energy , and resolving the 3 jets coming from the top decay products , techniques like the subjet analyses might be of crucial importance and",
    "definitely deserve further studies .",
    "s.  catani , y.  l. dokshitzer , m.  olsson , g.  turnock , and b.  r. webber , _ phys .",
    "* b269 * ( 1991 ) 432 ; s.  d. ellis and d.  e. soper , _ phys .",
    "* d48 * ( 1993 ) 31603166 , [ http://xxx.lanl.gov/abs/hep-ph/9305266[hep-ph/9305266 ] ] .",
    "y.  l. dokshitzer , g.  d. leder , s.  moretti , and b.  r. webber , _ jhep _ * 08 * ( 1997 ) 001 , [ http://xxx.lanl.gov/abs/hep-ph/9707323 [ hep - ph/9707323 ] ] ; m.  wobisch and t.  wengler , http://xxx.lanl.gov/abs/hep-ph/9907280 [ hep - ph/9907280 ] .",
    "j.  e.  huth _ et al .",
    "_ , fermilab - conf-90 - 249-e ( 1990 )",
    ". j.  m.  butterworth , j.  p.  couchman , b.  e.  cox and b.  m.  waugh , _ comput .",
    "* 153 * ( 2003 ) 85 [ arxiv : hep - ph/0210022 ] .",
    "m.  cacciari and g.  p. salam , _ phys .",
    "_ * b641 * ( 2006 ) 57 , [ http://xxx.lanl.gov/abs/hep-ph/0512210[hep-ph/0512210 ] ] .",
    "m.  cacciari , g.  p.  salam and g.  soyez , jhep * 0804 * ( 2008 ) 063 http://xxx.lanl.gov/abs/arxiv:0802.1189      [ hep - ph][[arxiv:0802.1189 ] ] . j.  m. butterworth , a.  r. davison , m.  rubin , and g.  p. salam , _ phys . rev .",
    "* 100 * ( 2008 ) 242001 , [ http://arxiv.org/abs/0802.2470 [ arxiv:0802.2470 ] ] .      c.  buttar _",
    "_ , arxiv:0803.0678 [ hep - ph ] . m.  cacciari , j.  rojo , g.  p.  salam and g.  soyez , arxiv:0810.1304 [ hep - ph ] .",
    "see also http://quality.fastjet.fr .",
    "m.  cacciari and g.  p.  salam , _ phys .",
    "_ * b659 * ( 2008 ) 119 [ arxiv:0707.1378 ] .",
    "m.  cacciari , g.  p.  salam and g.  soyez , _ jhep _ * 0804 * ( 2008 ) 005 [ arxiv:0802.1188 ] ."
  ],
  "abstract_text": [
    "<S> from dedicated qcd studies to new physics background estimation , jets will be everywhere at the lhc . in these proceedings </S>",
    "<S> , we discuss two important recent series of improvements . in the first one , </S>",
    "<S> we introduce new algorithms and new implementations of previously existing algorithms , in order to cure limitations of their predecessors and to satisfy fundamental requirements . in the second part , </S>",
    "<S> we show that it is of prime importance to carefully choose the jet definition  algorithm and parameters  to optimise kinematic reconstructions at the lhc . </S>",
    "<S> noticeably , we show that while at scales around 100 gev , @xmath0 is an appropriate choice , clustering at the tev scale requires @xmath1 for optimal efficiency . </S>",
    "<S> we finally show that our results are valid in the presence of pileup , provided that a subtraction procedure is applied . </S>"
  ]
}