{
  "article_text": [
    "the use of finite mixture models in clustering is finding a large number of applications , mainly because it allows standard statistical modelling tools to be used in order to assess and evaluate the clustering .",
    "the density or probability mass function of a finite mixture model is defined as @xmath0 where @xmath1 , and @xmath2 with @xmath3 .",
    "appropriate choices of @xmath4 can result in flexible models of small complexity . @xcite and the book of @xcite provide a detailed treatment of the framework of finite mixture modelling for clustering . for continuous data , a common choice for the component densities",
    "@xmath4 @xmath5 is the density of the multivariate normal distribution .",
    "this is mainly because of the convenience it offers in estimation ( closed - form maximization steps in the em algorithm ) and interpretation ( easy marginalization for visualising fitted components and the mixture density ) . the resultant clusters , though , are limited to be elliptical in shape , and as is demonstrated in @xcite , one may need more than one multivariate normal components , in order to fit a single non - elliptical cluster .    such restrictions of multivariate normal finite mixtures have resulted in an expanding literature where other special component distributions are considered .",
    "prominent examples of alternative component densities include multivariate @xmath6 distributions ( see , * ? ? ?",
    "* ) , multivariate skew - normal and skew-@xmath6 distribution ( see , for example , * ? ? ?",
    "* ; * ? ? ?",
    "* ) , multivatiate skew student-@xmath6-normal distributions @xcite , multivariate normal inverse gaussian distributions @xcite .",
    "other attempts can be found in @xcite for finite mixtures of multivariate scaled normal distributions and @xcite for mixtures of shifted asymmetric laplace distributions .",
    "the results of such studies indicate that the introduction of heavy tails and/or skewness allows the construction of more parsimonious models than multivariate normal mixtures , which can also bridge the gap between the number of clusters present in the data and the number of components used in the mixture .    despite the added flexibility",
    "that such mixture models offer , all of them force the data to obey very specific marginal properties , and they are not appropriate , for example , in cases where the simultaneous treatment of real - valued observations , strictly positive and observations in @xmath7 is needed . in such cases one needs to either ignore the range of the variables and treat them as real - valued or apply appropriate transformations that map the original range of the observations on the real line . furthermore , even for real - valued variables , as example  [ motivatingexample ] illustrates , current methods can fail to capture certain dependence structures .",
    "[ motivatingexample ] consider the artificial data set shown in the top left plot of figure  [ motivatingfig ] .",
    "the data set is formed by four distinct clusters of observations each shown in a different colour on the plot .",
    "a clayton and a survival clayton copula with normal marginals has been used for generating groups 3 and 4 , and then an exact copy of the latter has been translated appropriately in order to form groups 1 and 2 .    in an attempt to reconstruct the true groups ,",
    "the data set was fitted using a bivariate normal mixture model , a bivariate skew - normal mixture model , and a bivariate skew - t mixture model .",
    "all fitting procedures were initialized by the best k - means clustering in four clusters after 1000 random starting points .",
    "the resulting classification plots are shown in figure  [ motivatingfig ] .",
    "each plot also provides the value of the bayesian information criterion ( bic ) for each model and the corresponding misclassification rate .",
    "as is apparent none of the three models performs well in detecting the true shape of the underlying clusters with the misclassification rates ranging between @xmath8 to @xmath9 and adjusted rand index ( ari ) between @xmath10 and @xmath11 .",
    "the challenge with the artificial data set in figure  [ motivatingfig ] is the tail behaviour that the true groups demonstrate . if we restrict the number of components to four , the demonstrated extreme tail dependence and the small distances between the true groups makes models based on elliptical components ( like normal mixtures ) incapable of capturing the true shape of the clusters .",
    "moreover , in this example , models that are based on non - elliptical components ( like skew - normal and skew - t distributions ) seem to be not flexible enough to capture the true characteristics of the data .      for non - continuous data , one needs to specify @xmath4 @xmath5 in ( [ mixture_model ] ) through probability mass functions .",
    "while there is a wealth of choices for univariate non - continuous distributions , the use of multivariate non - continuous distributions for the definition of mixture models is limited due to the difficulty in constructing easy to work with models that allow practical flexibility on the dependence structure .",
    "some successful , but limited in application examples , are finite mixtures of multivariate poisson distributions @xcite , finite mixtures of multinomial distributions @xcite and models based on conditionally independent poisson distributions ( see , for example * ? ? ?",
    "mixture models with latent structures have been considered in @xcite , but these can have limitations because of assumptions like conditional independence .",
    "subsections 1.1 and 1.2 highlight the need for a new framework for setting and fitting mixture models , which can i ) match the flexibility that current proposals offer , and ii ) can accommodate the modelling of data with either continuous or non - continuous domains .",
    "copulas offer the means for constructing such a framework ; their extensive use in the modelling of applications with multivariate data is due to the flexibility they offer in describing dependence and in that they allow the construction of multivariate models with prescribed marginals .",
    "@xcite provides an introduction to the concept of copulas .",
    "moreover , specifically for continuous data , common dependence measures like kendall s @xmath12 and spearman s @xmath13 are marginal - free and depend solely on the copula .",
    "this fact allows the easy construction of multivariate mixture models for continuous data by first selecting the marginal properties of the variables involved and then the dependence structure implied by the mixture components .",
    "a few attempts have already been made in the direction of facilitating the flexibility that copulas offer in model - based clustering ( see , for example * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "the current paper sets a thorough framework for constructing mixture models using copulas , highlighting the benefits but also the challenges of their use in practice .",
    "the ingredients for constructing copula - based mixture models are described in section  2 .",
    "section  3 provides the details for maximum likelihood estimation through expectation - maximization ( em ) algorithm and proposes relevant procedures for obtaining starting values from the combination of a partitioning algorithm ( like @xmath14-medoids ) and of component - wise applications of the inference functions from margins ( ifm ) method of ( * ? ? ?",
    "* chapter  10 ) .",
    "section  4 focuses on the case of modelling continuous multivariate data .",
    "the special structure of the complete - data log - likelihood is exploited for producing more efficient and stable variants of the maximization step of the em algorithm .",
    "topics like the modelling of mixed - domain continuous data are discussed and a novel extension of the standard copula - based mixture model is presented that applies parametric component - wise rotations in the sample space and has effortless implementation .",
    "section  5 examines the property of closure under marginalisation for copula - based mixture models and section  6 provides a description of the use of the framework for modelling multivariate discrete data .",
    "the challenges in estimation and model specification compared to the continuous case are discussed .",
    "the exposition of the methodology is accompanied and motivated by the analysis of real and artificial data .",
    "the paper concludes in section  7 with a discussion including descriptions of new research directions that the current work offers .",
    "a copula @xmath15 is a distribution function with uniform marginals .",
    "the importance of copulas in statistical modelling stems from sklar s theorem ( see , * ? ? ?",
    "* ) , which shows that every multivariate distribution can be represented via the choice of an appropriate copula and , more importantly , it provides a general mechanism to construct new multivariate models in a straightforward manner .",
    "the copula - based mixture model is defined as in ( [ mixture_model ] ) but now @xmath16 is partitioned as @xmath17 and @xmath4 is the density ( or probability mass function ) corresponding to a distribution function @xmath18 where @xmath19 are univariate marginal cumulative distribution functions .",
    "as far as the model parameters are concerned , @xmath20 contains the parameter vectors @xmath21 for all marginals for @xmath22th component @xmath23 and @xmath24 contains the parameters of the copula used for the @xmath22-th component .      the definition of the component density @xmath25 through the choice of a copula @xmath26 and the choice of marginal distributions @xmath27 leads to a flexible framework for model - based clustering that according to sklar s theorem necessarily encompasses all known mixture models and allows the convenient construction of new mixture models that can handle any of continuous , discrete data .",
    "temporarily omitting the component index and suppressing the dependence on the parameters , assume that the density of the copula @xmath15 exists and is @xmath28 .",
    "then the component density for continuous marginals is @xmath29 where @xmath30 is the density function for the @xmath6th marginal distribution . for discrete data",
    ", the probability mass function is given in ( * ? ? ?",
    "* expression  ( 1.2 ) ) , and results from finite differences of the distribution function as @xmath31 with @xmath32 vertices , where each @xmath33 is equal to either @xmath34 or @xmath35 @xmath23 , and @xmath36    the model defined from ( [ mixture_model ] ) and ( [ basic_model ] ) being a finite mixture allows for inferential procedures based on the standard theory of finite mixtures , like use of the em algorithm for maximum likelihood estimation and the use of model selection criteria .",
    "suppose that a sample of @xmath37 @xmath38-vectors @xmath39 is available , which are assumed to be realizations of independent random variables @xmath40 each with distribution with density or probability mass function as defined by ( [ mixture_model ] ) and ( [ basic_model ] ) .",
    "the maximization of the likelihood function based on that sample can be performed using the em algorithm . at the @xmath41th iteration of the algorithm :    * _ e - step : _ calculate @xmath42 * _ m - step 1 : _ set @xmath43 @xmath5 . * _ m - step 2 : _ maximize @xmath44 with respect to @xmath45 to obtain an updated value @xmath46 for the copula and marginal parameters .",
    "the algorithm iterates between the _ e - step _ and the _ m - step _ until some convergence criterion is satisfied . in all the examples in the current paper",
    "the termination criterion that is used is that the relative increase @xmath47 of the log - likelihood @xmath48 in two successive iterations is less than @xmath49 .        for the general model defined by ( [ mixture_model ] ) and ( [ basic_model ] ) ,",
    "_ m - step 2 _ of the em iteration is generally not available in closed - form and needs to be performed numerically . at the current level of generality",
    ", it is recommended to take advantage of the separable form of the complete - data log - likelihood for mixture models , which allows to break down the maximization task into @xmath14 independent maximizations of weighted likelihoods @xmath50 that can be performed in parallel .      for calculating the starting values for @xmath51 and @xmath45 the following procedure",
    "is proposed which takes into account both the copula and the marginal specification of each component in the mixture model .",
    "the procedure is an application of the inference functions from margins ( ifm ) method ( * ? ? ?",
    "* chapter  10 ) for each component , and relies on an initial classification vector that partitions the observation indices @xmath52 into exclusive subsets @xmath53 , with @xmath54 , of cardinality @xmath55 , respectively .",
    "more specifically , the procedure for obtaining starting values consists of the following steps :    1 .",
    "set the starting values for @xmath56 using @xmath57 @xmath5 .",
    "2 .   use maximum likelihood to fit the marginal @xmath58 on data @xmath59 for @xmath60 in order to obtain starting values @xmath61 for @xmath21 @xmath23 .",
    "3 .   use maximum likelihood to fit the copula @xmath62 on observations @xmath63 @xmath64 , in order to get starting values @xmath65 for the copula parameters @xmath24 .",
    "the initial classification vector can be obtained either using a hard - partitioning distance - based algorithm ( like @xmath14-means for continuous data or @xmath14-medoids more generally ) or by randomly sampling @xmath14 observations and using the minimum distance of each to all other observations in order to form @xmath53 .      the possibility of using different copulas for the components of the mixture model defined by ( [ mixture_model ] ) and ( [ basic_model ] ) , and the fact that the likelihood function for mixture models generally has local maxima , make the solution of the em algorithm to depend on the order that the copulas appear in the mixture .    a solution to",
    "this problem is to fit all models that result from all possible permutations of the component copulas .",
    "then , for each one of the unique permutations of the components , the procedure in subsection  [ starting ] is applied , taking care to use the same initial classification vector ( and labelling ) for @xmath66 across permutations .",
    "then the fitted model with the largest value for the maximized log - likelihood is chosen .",
    "example  [ motivatingexamplecont ] below , uses this procedure for the choice of component ordering .",
    "subsection  [ goodfits ] presents an alternative , less intensive solution , which can give rise to flexible mixture models without the need of considering many different candidate copulas for the components .",
    "that solution is based on extending the specification of the mixture model by allowing for component - wise parametric rotations .",
    "if the same copula is used across the components of the mixture model , then the sensitivity that the result of the em algorithm can have on the starting values can be alleviated by trying several of those .",
    "this can be done by choosing a number of sets of @xmath14 randomly sampled observations , and construct distinct classification vectors by minimum distance , as described in subsection  [ starting ] .",
    "then , for each vector , component - wise ifm is used to get the corresponding set of starting values and initialize the em iterations .",
    "the model fit with the largest maximized log - likelihood is the one that is kept .",
    "the above process is used to carry out the analyses in example  [ nba ] and example  [ cognitive ] .",
    "as is apparent from ( [ m2continuous ] ) the only necessary ingredients for implementing the em algorithm for mixtures of copulas for continuous data are the specification of the copula densities @xmath70 and the specification of the marginal density and distribution functions @xmath71 and @xmath19 , respectively .",
    "the particular form of the complete data log - likelihood for continuous data allows here the use of the expectation / conditional maximization ( ecm ) algorithm of @xcite , where the full maximization of the complete data log - likelihood is relaxed to maximization in blocks ; first with respect to the marginal parameters given the current value of the copula parameter and then with respect to the copula parameter given the updated values for the marginal parameters . in mathematical notation ,",
    "_ m - step 2 _ in subsection  [ emsection ] is replaced by the steps    * _ cm - step 1 : _ maximize @xmath72 \\ , , \\ ] ] with respect to @xmath73 , @xmath74 , @xmath75 , @xmath76 , @xmath74 , @xmath77 to obtain updated values @xmath78 , @xmath74 , @xmath79 , @xmath80 , @xmath74 , @xmath81 for the marginal parameters . * _ cm - step 2 : _ maximize @xmath82 \\ , , \\ ] ] with respect to @xmath83 to obtain updated values @xmath84 for the copula parameters .    according to the definitions and results in @xcite , the ecm algorithm that results by replacing _",
    "m - step 2 _ with the pair _ cm - step 1 _ and _ cm - step 2 _ shares all the convergence properties of the full em algorithm , and , in this particular case , is more computationally efficient and stable , because _ cm - step 2 _ consists of a simple maximization with respect to the copula parameters .",
    "furthermore , _ cm - step 1 _ and _ cm - step 2 _ can each be broken down into parallel optimizations across components , as in the case of the full em in subsection  [ compute ] , which significantly reduces computation time in multicore systems .",
    "the pair of _ cm - step 1 _ and _ cm - step 2 _ is similar to the ifm method for fitting the complete data likelihood .",
    "their difference lies in _ cm - step 1 _ where instead of maximizing the weighted sum of marginal log - likelihoods , a valid ecm algorithm requires the maximization of a penalized version of it where the penalty depends on the log copula density at the current value for the copula parameter .",
    "[ motivatingexamplecont ] consider the setting of example  [ motivatingexample ] .",
    "the normal mixture model failed to capture the dependence structure that is apparent in the true groups because of the strict elliptical shape of the component densities .",
    "furthermore , two of the fashionable methods that allow non - elliptical clusters ( mixtures of skew - normals and skew - t distributions ) were not able to recover the dependence structure of the groups in the artificial data .",
    "the gumbel copula and the clayton copula can capture varying degrees of upper and lower tail dependence respectively and for the purposes of this example we consider a mixture model of two gumbel copulas and two clayton copulas with normal marginals .",
    "the gumbel copula is defined as @xmath85\\ , , \\quad \\psi \\in [ 1 ,      \\infty)\\ , , \\ ] ] and the clayton copula is defined as @xmath86 the associated densities @xmath87 and @xmath88 can be obtained by direct differentiation of @xmath89 and @xmath90 , respectively . the closed form expressions of those copula densities are given in ( * ? ? ?",
    "* corollary 1 ) along with the corresponding expressions for other archimedean copulas of arbitrary dimension",
    ". then the density of the bivariate mixture model with two gumbel and two clayton components and normal marginal distributions can be written as @xmath91 where @xmath92 and @xmath93 with @xmath94 .",
    "the functions @xmath95 , @xmath96 are the distribution and density function of a standard normal random variable , respectively .",
    "then _ m - step 2 _ of the maximization step at the @xmath41th iteration of the em algorithm in subsection  [ emsection ] consists of the maximization of each one of @xmath97          \\label{maxfun}\\ ] ] for @xmath98 , where @xmath99 for @xmath100 and @xmath101 for @xmath102 . for deriving the ecm algorithm in subsection  [ maxcontinuous ] , each of those maximizations should be replaced by the maximization of the function given in ( [ maxfun ] ) , firstly on with respect to @xmath103 at the current value @xmath104 of the copula parameter , in order to obtain updated marginal parameters @xmath105 , and , then , the maximization of @xmath106 with respect to @xmath107 to obtain an updated value @xmath108 for the copula parameter .",
    "the latter is simply a maximization with respect to the scalar parameter @xmath107 and can be performed using line search in the domain of definition of the copula parameter .",
    "supplementary material extends example  [ nba ] to illustrate that distinct sensible , transformations can lead to different results .",
    "r scripts that reproduce the analyses undertaken in this paper are available upon request to the authors .",
    "fraley , c. , a.  e. raftery , t.  b. murphy , and l.  scrucca ( 2012 ) .",
    "mclust version 4 for r : normal mixture modeling for model - based clustering , classification , and density estimation .",
    "technical report 597 , department of statistics , university of washington .",
    "genz , a. , f.  bretz , t.  miwa , x.  mi , f.  leisch , f.  scheipl , and t.  hothorn ( 2013 ) .",
    "mvtnorm : multivariate normal and t distributions .",
    "r package version 0.9 - 9996 .",
    "http://cran.r-project.org/package=mvtnorm .",
    "jajuga , k. and d.  papla ( 2006 ) .",
    "copula functions in model based clustering . in _ from data and information analysis to knowledge engineering studies in classification , data analysis , and knowledge organization _ , volume  15 , pp .",
    "springer berlin heidelberg ."
  ],
  "abstract_text": [
    "<S> the majority of model - based clustering techniques is based on multivariate normal models and their variants . in this paper copulas </S>",
    "<S> are used for the construction of flexible families of models for clustering applications . </S>",
    "<S> the use of copulas in model - based clustering offers two direct advantages over current methods : i ) the appropriate choice of copulas provides the ability to obtain a range of exotic shapes for the clusters , and ii ) the explicit choice of marginal distributions for the clusters allows the modelling of multivariate data of various modes ( either discrete or continuous ) in a natural way . </S>",
    "<S> this paper introduces and studies the framework of copula - based finite mixture models for clustering applications . </S>",
    "<S> estimation in the general case can be performed using standard em , and , depending on the mode of the data , more efficient procedures are provided that can fully exploit the copula structure . </S>",
    "<S> the closure properties of the mixture models under marginalization are discussed , and for continuous , real - valued data parametric rotations in the sample space are introduced , with a parallel discussion on parameter identifiability depending on the choice of copulas for the components . </S>",
    "<S> the exposition of the methodology is accompanied and motivated by the analysis of real and artificial data . </S>",
    "<S> + _ keywords : _ mixture models ; dependence modelling ; parametric rotations ; multivariate discrete data ; mixed - domain data .    </S>",
    "<S> = 1 </S>"
  ]
}