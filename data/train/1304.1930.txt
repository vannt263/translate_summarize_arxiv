{
  "article_text": [
    "in document analysis and processing , table extraction from document images has been received an important attention since it contains key information . in the context of table extraction  @xcite ,",
    "document image analysis and processing basically describes table either in terms of lines and ( un)analysed text blocks , a set of cells resembling the two - dimensional grid or a set of strings that are integrated with each other via relations , for instance .    basically , table detection and its structure recognition are two major tasks .",
    "table detection can be taken as a primary issue , which is however does not provide a complete solution  @xcite since one needs to be able to extract key fields within it .",
    "existing methods such as table segmentation  @xcite do not extract key fields , nor do they explicitly perform the content understanding  @xcite . note that structural information by considering relations between the contents , for instance can be very useful in indexing and retrieving document information  @xcite .",
    "to analyse table - forms structure , rulings techniques are basically limited without a priori knowledge about table organisation  @xcite .",
    "such concepts are completely failed since not all tables possess graphical lines . besides , plain ascii texts , text blocks are used . detecting columns , lines and headers , and representing them in terms of graph , for instance is interesting since it contains structural information . in order to fully exploit table in the scanned documents rather than just outlining the overall boundary ,",
    "it is interesting to extract those fields that are important or meaningful for the clients . to handle this , in this paper , key fields are provided by the clients .",
    "these key fields are then used to build a graph so that it can be applied for table extraction in the absence of clients .",
    "the rest of the paper is organised as follows .",
    "we start with explaining the proposed method in section  [ sec : prop ] .",
    "full experiments are reported and analysed in section  [ sec : expe ] .",
    "the paper is concluded in section  [ sec : conc ] .",
    "generally speaking , table is composed of similar items ( sometimes just a single ) even when columns alignment and corresponding text flow ( either in a single or multiple lines ) are not guaranteed . given an input pattern ( i.e. , an item , for instance ) from a client , finding similar patterns from the document is the core part of the paper .",
    "it not only extracts important fields ( in accordance with the client ) but also configures table represented by a set of similar patterns . to handle this",
    ", we first represent an input pattern via an arg and perform graph mining so that similar graphs can be extracted that are structurally and semantically similar .",
    "[ block ] shows a screen - shot of the overall idea .",
    "[ scale = 0.5 , auto , every node/.style = node distance=0.2 cm , comment/.style = rectangle , inner sep= 5pt , text width=4 cm , node distance=0.25 cm , input0/.style = rectangle , rounded corners , auto , input/.style = rectangle , rounded corners , fill = yellow!40 , auto , font= * * * * , input1/.style = draw , rectangle , rounded corners , fill = gray!40 , auto , document/.style = draw , rectangle , rounded corners = 10pt , minimum height=4em , fill = gray!40,database/.style= draw , rectangle , rounded corners = -10pt , color = black , minimum height=2em , fill = gray!40 , output/.style = rectangle , rounded corners = 1pt , color = black , auto , fill = magenta!40 , force/.style = rectangle , rounded corners , draw , fill = black!10 ] ( doc )    [ cols= \" < \" , ]     & @xmath0    c    ( -0.1,0 ) rectangle ( 1.3 , 0.3 ) ; ( 0.1,0.2 )  ( 0.1,0.25 ) ; ( 0.2,0.2 )  ( 0.2,0.25 ) ; ( 0.3,0.2 )  ( 0.3,0.25 ) ; ( 0.5,0.2 )  ( 0.5,0.25 ) ; ( 0.6,0.2 )  ( 0.6,0.25 ) ; ( 0.7,0.2 )  ( 0.7,0.25 ) ; ( 0.9,0.2 )  ( 0.9,0.25 ) ; ( 1.0,0.2 )  ( 1.0,0.25 ) ; ( 1.1,0.2 )  ( 1.1,0.25 ) ;    \\(a ) at ( 0,0.2 ) ; ( b ) at ( 0.4,0.2 ) ; ( d ) at ( 1.2,0.2 ) ; ( c ) at ( 0.8,0.2 ) ; ( 0,0.2 ) circle(0.03 cm ) ; ( 0.4,0.2 ) circle(0.03 cm ) ; ( 0.8,0.2 ) circle(0.03 cm ) ; ( a ) edge ( b ) ( b ) edge ( c ) ( c ) edge ( d ) ; ( 1,0.2 ) ",
    "( 1.3 , 0.2 ) ; at ( a ) [ black , below = 1pt]@xmath1 ; at ( c ) [ black , below = 1pt]@xmath2 ; at ( b ) [ black , below = 1pt]@xmath3 ;     + ( c ) relation vector space + using @xmath4 as a pivotal node      given the pattern graph @xmath5 , to extract similar graphs from a document , it starts with pivotal nodes selection in a document and perform relation assignment to compute feature score between the pairs of nodes .",
    "relations assignment repeats until a similar graph @xmath6 is achieved , with respect to @xmath5 .    _",
    "* pivotal nodes selection . *",
    "_ in a predefined set @xmath7 of labels such as _ price _ , _ date _ , _ address _ and _ description _ in the domain , for every node @xmath8 in pattern graph @xmath5 , the corresponding label @xmath9 is defined i.e. , @xmath10 . having these labelled nodes @xmath11 in a pattern graph @xmath5 ,",
    "the target is to select nodes sharing identical labels @xmath12 from a document @xmath13 .",
    "we now , refer the selected nodes as pivotal nodes .    _",
    "* feature score computation .",
    "* _ each pivotal node is taken and started to validate relations with neighbouring nodes in a document , as in pattern graph . to compute feature score between the pair of nodes @xmath14 in a document with respect to @xmath15",
    ", their respective relations must be identical i.e. , @xmath16 validates with @xmath17 .",
    "more formally , we can compute feature score between two corresponding nodes @xmath18 and @xmath19 as @xmath20 @xmath21 where @xmath22 $ ] provides weight to each features used to compute feature matching score @xmath23 . for each particular feature",
    ", weight @xmath24 can be varied according to its robustness and so is application dependent . given two strings : @xmath25 reference and @xmath26 primary , we compute feature ( like string _ value _ , number of _ _ word__s and _ size _ ( _ cf . _",
    "eq .  ) ) matching scores as follows .",
    "+ @xmath27 string _ type _ : + @xmath28 , where we treat numerals @xmath29 , all alphabets @xmath30 and symbols equally .",
    "+ @xmath27 number of _ _ word__s in a string : + @xmath31 i.e. , an absolute difference in number words is normalised by the maximum number of words .",
    "+ @xmath27 string _ size _ : + @xmath32 i.e. , an absolute difference in size ( number of letters ) is normalised by its maximum size . + following fig .",
    "[ relationv ] , let us elaborate a concept of matching . to simplify the explanation ,",
    "let us first create a relation vector space from a pattern graph and then realise the assignment process for each pivotal node in a document .",
    "taking a single pivotal node @xmath4 from a data graph @xmath6 ( having identical label with respect to @xmath33 in @xmath5 i.e. , @xmath34 ) , the idea is to assign relations @xmath35 in data graph @xmath6 .",
    "we validate relations @xmath36 one - by - one and compute feature score in parallel .",
    "it provides @xmath37 .",
    "however , an addition of a node @xmath38 can help to make them exactly similar in configuration via an edit cost operation .",
    "* _ graph matching score computation . _ * an aggregation of both scores i.e. , @xmath39score from relation assignment and @xmath40score from feature computation between the nodes yields a matching score @xmath41 for data graph @xmath6 with respect to @xmath5 @xmath42 . \\end{aligned}\\ ] ] * _ confidence score computation . _ * from each input pattern , a set of mined graphs @xmath43 will represent a table i.e. , an output .",
    "for such an output , we compute corresponding confidence score ( cs ) .",
    "cs is computed from the aggregation of all matching scores @xmath44 , which is then normalised i.e. , @xmath45 in case of multiple input patterns , the outputs are ranked and provided on a one - to - one basis .",
    "ranking is based on the order of similarity .",
    "note that we aim to use set of mined graphs to iteratively update the pattern graph and transform into a graph model so that it can be used in the absence of the clients  which is beyond the scope of the paper .",
    "a proof of the concept is reported in  @xcite and the thorough extension ( aiming to apply document information content extraction , not necessarily be always found in structured documents like forms ) has been made in  @xcite .",
    "* _ dataset . _",
    "* we work on a real - world industrial problem in direct collaboration with the * * itesoft * * , france . currently , the dataset is composed of 15 classes with 100 samples per class . for each document , clients provide ground - truths i.e. , all similar patterns within the table , according to the pattern selected .    * _ evaluation metric . _ * an output i.e. , the detected table is represented by a collection of mined graphs @xmath46 in a test document , and there are @xmath47 list of ground - truthed patterns corresponding to the ground - truthed table @xmath48 .",
    "each graph @xmath6 has a number of fields that are simply represented by iconic boxes @xmath49 .    to evaluate",
    ", we extend the area - ratio - based measure proposed by shafait and smith  @xcite .",
    "it uses bounding boxes to describe detected tables and the ground - truths . in our framework , the overlapping ratio between the two boxes is defined as @xmath50 where @xmath51 is the intersected or common area of two bounding boxes from ground - truthed and detected table respectively and @xmath52 are the individual areas .",
    "note that @xmath53 $ ] .",
    "we sum up all @xmath54 and normalise to compute overall overlapping ratio between ground - truth pattern @xmath55 and detected pattern @xmath6 by @xmath56 .",
    "then for a whole table , we can express evaluation metric as @xmath57      we have validated the outputs over 15 different suppliers by taking the associated ground - truths and reported the average performance in table  [ table : result ] .",
    "more specifically , it provides the two different ways to evaluate :    1 .",
    "one is associated with the input pattern created in the laboratory and 2 .",
    "another one is directly related with client or real - world patterns .",
    "the first evaluation of course , aims to provide an overall concept that can be applied to content extraction associated with the table .",
    "the latter one provides how robust it is . in the reported results in table  [ table : results ] , we observe the following .    1 .   without a surprise ,",
    "cleaner the input pattern , better the performance .",
    "this happens to be in _ eval . 1 _ since input patterns are created in accordance with what ocr results",
    ". 2 .   in contrast , in case of the client input patterns ( _ eval . 2 _ ) , a single field selection may sometimes take word(s ) from another closer fields ( can be left or right ) , and multiple lines . in that selected box ( from clients ) , since ocr reads some dots ( due to noise ) as ` full - stop ' , ` colon ' and ` semi - colon ' , it does not allow possible cleaning . as a consequence , feature properties representing the graph nodes can possibly varied . fig .  .",
    "shows an example of it .",
    "[ table : result ]    lcccc table type@xmath58 & & & & + _ eval . 1 _ & 97 & 99 & 98 & 98 + _ eval . 2 _ & 96 & 98 & 95 & 97 +   +   +   +    cc    \\(b ) at ( 0,3.6 ) ; at ( 0.4 , 3.6 ) ; ( b ) at ( 0.2,-2.0 ) ; ( b ) at ( 0.2,-2.2 ) ; ( b ) at ( 0.4,-2.4 ) ; ( b ) at ( 0.6,-2.6 ) ; at ( 2 , -1.0 ) ; at ( -3.5 , -7.0 ) ( a ) ; at ( 0.5 , 1.0 ) ; at ( -3.3 , -3.0 ) @xmath59 ; at ( -1.8 , -1.48 ) ; at ( -1.8 , -1.88 ) ; at ( -1.8 , -2.25 ) ; at ( -1.8 , -2.6 ) ; at ( -1.8 , -3.75 ) ; at ( -1.8 , -4.15 ) ; at ( -1.8 , -4.75 ) ;    &    \\(b ) at ( 0,3.6 ) ; at ( 0.7 , 3.4 ) ; ( b ) at ( 0.2,-2.0 ) ; ( b ) at ( 0.2,-2.2 ) ; ( b ) at ( 0.4,-2.4 ) ; ( b ) at ( 0.6,-2.6 ) ; at ( 2 , -2.0 ) ; at ( -3.5 , -7.0 ) ( b ) ; at ( 0.5 , 1.5 ) ; at ( -3.3 , -3.0 ) @xmath59 ; at ( -2.5 , -3.0 ) ; at ( -2.2 , -3.2 ) ;    at ( -2.5 , -4.0 ) ; at ( -2.2 , -4.2 ) ;    at ( -2.5 , -5.2 ) ; at ( -2.2 , -5.3 ) ;     +   +    besides , another considerable issue is the complexity of the graph - based pattern representation . in case of input patterns with complex structural formats ( lets say zig - zag ) ,",
    "such non - selected fields integration makes pattern graph more complex .",
    "furthermore , as said before , our system performance has been affected due to ocr errors since the system does not provide the expected semantics label at nodes in the graph .",
    "an example of the ocr effect is ` false detection ' because of the structural similarity between the graphs .",
    "in this paper , we have presented client - driven pattern - based approach to table extraction via graph mining scheme , inspiring from a real - world applications .",
    "we have very much focused and validated that the table extraction does not always mean only to detect the presence and absence as well as to spot the area where table(s ) is(are ) located but also to select important key fields within it while rejecting others .    given an input pattern ( i.e. , a pattern graph ) , finding similar pattern graphs so that we can reinforce or update it iteratively each time we extract them , is one of the primary issues of the further work  @xcite , for instance . as a consequence , such models are used to exploit document information content in the absence of clients ."
  ],
  "abstract_text": [
    "<S> _ the goal of the project is to extract content within table in document images based on learnt patterns . </S>",
    "<S> real - world users i.e. , clients first provide a set of key fields within the table which they think are important . </S>",
    "<S> these are first used to represent the graph where nodes are labelled with semantics including other features and edges are attributed with relations . attributed relational graph ( arg ) is then employed to mine similar graphs from a document image . </S>",
    "<S> each mined graph will represent an item within the table , and hence a set of such graphs will compose a table . </S>",
    "<S> we have validated the concept by using a real - world industrial problem . _ </S>"
  ]
}