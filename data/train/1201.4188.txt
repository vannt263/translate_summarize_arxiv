{
  "article_text": [
    "reduced basis methods ( rbm ) @xcite were developed for scenarios that require a large number of numerical solutions to a parametrized partial differential equation in a fast / real - time fashion .",
    "examples of such situations include simulation - based design , parameter optimization , optimal control , multi - model / scale simulation etc . in these situations , we are willing to expend significant computational time to pre - compute data that can be later used to compute accurate solution in real - time .",
    "the rbm splits the solution procedure into two parts : an offline part where the parameter dependence is examined and a greedy algorithm is utilized to judiciously select @xmath0 parameter values for pre - computation ; and an online part when the solution for any new parameter is efficiently computed based on these @xmath0 _ basis _ functions .    the motivation behind the rbm is the recognition that parameter - induced solution manifolds can be well approximated by finite - dimensional spaces . for linear affine problems , rbm can improve efficiency by several orders of . for nonlinear or non - affine problems , there are remedies which allow the rbm methods to be used efficiently @xcite .",
    "the offline selection of the @xmath0 parameter values for the pre - computed bases is enabled by a rigorous a posteriori error estimate which guarantees the accuracy of the solution . exponential convergence with respect to @xmath0",
    "has been commonly observed , see @xcite and the reference therein .",
    "theoretically , a priori convergence is confirmed for a one dimensional parametric problem @xcite .",
    "more recently , exponential convergence of the greedy algorithm for continuous and coercive problems with parameters in any dimension has been established in @xcite , and improved in @xcite .",
    "the development and analysis of rbm has been carried out in the galerkin framework .",
    "that is , the truth approximations ( the numerical approximation from a presumably very accurate numerical scheme ) are obtained from a ( galerkin ) finite element method , and the reduced basis solution is sought as a galerkin projection onto a low dimensional space .",
    "however , to date rbm have not been developed , applied , or analyzed in the context of collocation methods .",
    "while galerkin methods are derived by requiring that the projection of the residual onto a prescribed space is zero , collocation methods require the residual to be zero at some pre - determined collocation points .",
    "collocation methods are particularly attractive for their ease of implementation , particularly for time - dependent nonlinear problems @xcite .    in this paper",
    ", we develop the rbm idea for collocation methods . given a highly accurate collocation method that is used as the truth solver for the parametric problem",
    ", we wish to study the performance of the system under variation of certain parameters using a collocation - based rbm .",
    "that is , the new method uses collocation for both the truth solver and the online reduced solver .",
    "the paper is organized as follows . in section [ sec : alg ] , we present two approaches to collocation rbm .",
    "the first one utilizes a least squares approach .",
    "the second one relies on a projection of the fine collocation grid problem onto a ( carefully - chosen ) coarse collocation grid .",
    "theoretical analysis and discussions on the offline - online decomposition are provided in section [ sec : analysis ] .",
    "numerical results are shown in section [ sec : numerical ] .",
    "finally , some concluding remarks and future directions are in section [ sec : conclude ] .",
    "we begin with a parametrized partial differential equation of the form @xmath1 with appropriate boundary conditions .",
    "we are interested in the solutions of the differential equation over a range of parameter values @xmath2 , where @xmath3 , a prescribed dimensional real parameter domain .",
    "the parameters can be , for example , heat conductivity , wave speed , angular frequency , or geometrical configurations etc .    in this work",
    ", we assume that the operator is _ linear _ and _ affine _ with respect to functions of @xmath2 .",
    "that is , @xmath4 can be written as a linear combination of parameter - dependent coefficients and parameter - independent operators : @xmath5 we make a similar assumption for @xmath6 : @xmath7 in the galerkin framework , these are common assumptions in the reduced basis literature @xcite .",
    "there are remedies available when the parameter - dependence is not affine @xcite .    for any value of the parameter @xmath2",
    ", we can approximate the solution to this equation using a collocation approach : we define a discrete differentiation operator @xmath8 so that the approximate solution @xmath9 satisfies the equation @xmath10 _ exactly _ on a given set of @xmath11 collocation points @xmath12 , we assume that the scheme produces highly accurate numerical solutions @xmath9 to the problem .",
    "we refer to the solution @xmath9 as the `` truth approximation '' .",
    "although solving gives highly accurate approximations , it is prohibitively expensive and time - consuming to repeat for a very large number of parameter values @xmath2 .",
    "the reduced basis method allows for highly accurate solutions to be computed quickly and efficiently when needed ( the `` online '' computation ) based on a set of possibly expensive offline computations .",
    "the idea of the reduced basis method is that we first _ pre - compute _ the truth approximations for a set of well - chosen parameter values @xmath13 by solving with the corresponding parameter value .",
    "then when the solution for any parameter value @xmath14 in the ( prescribed ) parameter domain @xmath15 is needed , instead of solving for the ( usually expensive ) truth approximation @xmath16 , we combine @xmath17 in some way to produce a surrogate solution @xmath18 : @xmath19    thus , the design of the reduced basis method requires two components :    1 .",
    "offline : how to select the pre - computed basis .",
    "online : how to combine the pre - computed basis functions to produce the surrogate solution .    in the following sections , we describe two variants of the reduced collocation algorithm .",
    "we first explain our approaches for the online computation of the surrogate solution from the pre - computed reduced basis in section [ sec : chooseprojection ] , and then the related question of the selection of the reduced basis in section [ sec : precomp ] .      for the surrogate solution @xmath18 to approximate the truth approximation @xmath16",
    "reasonably well , we require that @xmath18 provides , in some sense , a good approximation to the solution of the discretized differential equation @xmath20 by exploiting the linearity of the operator we observe that our task is to find coefficients @xmath21 so that the residual @xmath22 is small . in the galerkin framework @xcite , the coefficients found by requiring that the @xmath23-projection of this residual onto the reduced space is zero . for the collocation case , the system of equations we to solve is @xmath24 however , this system is over - determined : we have only @xmath0 unknowns , but @xmath25 equations . to approximate the solution to this system ,",
    "our task is to identify an appropriate @xmath26 such that the following holds @xmath27 by considering two different ways to choose the operator @xmath26 in equation , we propose two approaches for finding the coefficients of the reduced basis solutions .",
    "these two approaches are the least squares approach and the reduced collocation method",
    ".    * least - squares approach .",
    "* our first approach is a very standard approach to approximating the solution to an over - determined system .",
    "we determine the coefficients by satisfying the equation in a least squares sense .",
    "given @xmath28 , @xmath29 , @xmath30 , @xmath31 , we define , for any @xmath14 , an @xmath32 matrix @xmath33 and vector of length @xmath11 @xmath34 and solve @xmath35 to obtain @xmath36 .",
    "* reduced collocation approach . * a more natural approach from the collocation",
    "point - of - view is to determine the coefficients @xmath37 by enforcing at a reduced set of collocation points @xmath38 . in other words ,",
    "we solve @xmath39 where @xmath40 is the operator the @xmath11-dimensional space corresponding to the fine - domain collocation points @xmath41 the smaller reduced set of collocation points @xmath42 .",
    "in other words , we define the @xmath0 vectors of length @xmath0 by their elements @xmath43 and solve the @xmath44 system of equations @xmath45 the choice of reduced collocation points @xmath38 can be any set of @xmath0 points in the computational domain . later we will demonstrate how this set of points can be determined , together with the choice of basis functions , through the greedy algorithm ( algorithm [ alg : rcgreedy ] ) . although the coefficients are computed based on collocation on a coarser mesh , the quality of the reduced solution is not degraded since the differentiations are performed first , by the highly accurate operator @xmath46 whose accuracy is dependent on @xmath11 . this differentiation",
    "is then followed by the set of @xmath0 points .",
    "once the coefficients @xmath47 are determined , whether by the least squares approach or the reduced collocation approach , we define the reduced basis solution @xmath48 in both , the coefficients are determined by solving an @xmath49 system .",
    "furthermore , due to the affine assumption on the operator , the online cost of assembling the system is also independent of @xmath11 ( as will be seen in section [ sec : analysis ] ) .",
    "thus , the online component requires only modest computational cost because @xmath0 is not large .",
    "appropriate selection of the basis functions is a major determinant of how well the reduced basis method will work .",
    "the pre - computation and selection of basis solutions may be expensive and time - consuming , but this cost is acceptable because it is offline and done once - for - all .",
    "once the reduced basis solutions are computed and selected , the online component can proceed efficiently , as described above .    in this section",
    "we describe algorithms for choosing the reduced basis set @xmath50 .",
    "the selection of the reduced basis is performed in order to enable us to certify the accuracy of the reduced solution .",
    "the critical piece of information is that given a pre - computed reduced basis set @xmath51 we can compute an upper bound @xmath52 for the error of the reduced solution @xmath53 for any parameter @xmath2 .",
    "this upper bound is given by @xmath54 where @xmath55 is the lower bound for the smallest eigenvalue of @xmath56 .",
    "this upper bound is enabled by the _",
    "a posteriori _ error estimate which will be proved in section [ sec : apost_greedy ] . in the following ,",
    "we present the greedy algorithms used for the selection of the pre - computed basis for the least squares and the reduced collocation approaches .      the idea behind the greedy algorithm is to discretize the parameter space , and scan the discrete parameter space to select the best reduced solution space .",
    "to do this , we first randomly select one parameter and call it @xmath57 , and compute the associated highly accurate solution @xmath58 .",
    "next , we scan the entire discrete parameter space and for each parameter in this space compute its least squares reduced basis approximation @xmath59 .",
    "we now compute the error @xmath60 .",
    "the next parameter value we select , @xmath61 , is the one corresponding to the largest error estimator .",
    "@xmath62    randomly select @xmath57 and solve @xmath63 for @xmath64 . for @xmath65",
    "do    * form @xmath66 .",
    "* for all @xmath67 , solve @xmath68 to obtain @xmath69 .",
    "* for all @xmath67 , calculate @xmath70 . *",
    "set @xmath71 .",
    "* solve @xmath72 for @xmath64 .",
    "this process is repeated until the is sufficiently small . at every step we select the parameter which is approximated most badly by the current solution space , that in this way we select a solution space that will approximate any parameter reasonably well .",
    "the detailed algorithm is provided in algorithm [ alg : lsgreedy ] .",
    "the least squares approach above can not be immediately adapted to the collocation case because collocation requires the same number of collocation points as basis functions .",
    "thus we face problem of having to choose an appropriate set of collocation points @xmath38 at which to enforce the pde .",
    "in fact , the choice of the reduced set of collocation points is crucial for the accuracy of the algorithm .",
    "for example , as we will show in the numerical example in section [ sec : numerical ] , naively using the coarse chebyshev grid does not yield an accurate result . in the following ,",
    "we propose the _ empirical reduced collocation method _ for choosing the basis functions and reduced collocation points .",
    "randomly select @xmath57 and solve @xmath63 , and let @xmath73 .",
    "for @xmath65 do    * let @xmath74 .",
    "* for all @xmath67 , solve  @xmath75 to obtain @xmath76 .",
    "* for all @xmath67 , calculate @xmath70 . *",
    "set @xmath77 .",
    "* solve @xmath72 .",
    "* find @xmath78 such that , if we define @xmath79 , we have @xmath80 for @xmath81 . *",
    "set @xmath82 and @xmath83 . *",
    "set the reduced set of collocation points @xmath84 and use the set    the idea behind the empirical reduced collocation method is similar to the greedy algorithm used quite often by reduced basis method and it has the same structure as the empirical interpolation method @xcite .",
    "we build the set of collocation points hierarchically with the each point chosen from the set of candidate points @xmath85 .",
    "in this section , we provide some analysis of the proposed algorithms and some details for the offline - online decomposition that is crucial to the traditional tremendous speedup of reduced basis method .",
    "the essential ingredient of the accuracy of the reduced collocation method is the upper bound which is used for error estimation . in this section , we state and",
    "prove the theorem relating to this error estimator .",
    "before we state our theorem , we must assume that we have a lower bound @xmath55 for the smallest eigenvalue of @xmath56 , @xmath86    for any @xmath2 , suppose @xmath87 is the truth approximation solving and @xmath88 is the reduced basis solution solving or , we define @xmath89 then we have @xmath90 .",
    "we have the following error equation on the @xmath11-dependent fine domain collocation grid thanks to the equation satisfied by the truth approximation : @xmath91 taking the discrete @xmath92-norm and using basic properties of eigenvalues gives @xmath93    this a posteriori error estimate is used repeatedly in the greedy algorithm to determine the reduced basis set @xmath94 .",
    "in addition , the _ a posteriori _ error estimate also serves the role of certifying the accuracy of the reduced solution : given a tolerance @xmath95 , it is trivial to modify the algorithms so that they will find an appropriate number @xmath0 and a corresponding set @xmath96 such that the resulting reduced solver will have error below @xmath95 for @xmath67 .",
    "while this is not enough to guarantee accuracy for any @xmath97 , it suggests that if @xmath98 is a discretization that represents @xmath15 well , the reduced basis method will work well for any @xmath97 .",
    "as is well - known @xcite , the tremendous speedup of the reduced basis method comes from the decomposition of the computation into two - stages , called offline and online stages .",
    "the offline stage is done once for all and is @xmath11-dependent ( thus expensive ) .",
    "the online stage should be independent of @xmath11 thus economical and can be afforded for every new value of the parameter @xmath2 in the prescribed domain @xmath15 .",
    "thus the key to the efficiency of the reduced collocation method is the ability to decompose the computation into an offline component and an efficient online component . in this section ,",
    "we describe how a complete offline - online decomposition is achieved for the two algorithms .",
    "we begin with the least - squares equation , @xmath99 invoking the affine assumption for @xmath100 ( equation ) and @xmath6 ( equation ) gives @xmath101 hence , the decomposition can be summarized as follows    * calculate @xmath102 and @xmath103 for @xmath104 , * form the @xmath49 matrix @xmath105 and @xmath106 vector @xmath107 and solve the reduced @xmath49 system for @xmath108 .      here , we demonstrate the offline - online decomposition for the reduced collocation approach .",
    "the reduced equation in this case is @xmath109 which becomes @xmath110 with the affine assumptions and .",
    "this means that , given @xmath111 and the set of @xmath0 reduced collocation points @xmath42 , the splitting of the computation is done as follows :    * calculate @xmath112 , their @xmath113 projections , and @xmath114 . *",
    "form @xmath115 for any @xmath116 and @xmath117 , evaluate @xmath118 and form @xmath119 at the reduced set of collocation points @xmath38 , and finally solve the reduced @xmath49 system for @xmath108 s .",
    "although we are primarily interested in minimizing the online cost of computation , it is also advantageous to be able to efficiently compute the offline component of the reduced collocation method . in particular",
    ", the greedy algorithm requires repeated computations of the error estimator @xmath52 for @xmath120 and any @xmath67 . to make this practical",
    ", as we select more and more bases and @xmath121 goes from @xmath122 to @xmath0 , we can reuse previously computed components of the error estimator .",
    "this can be achieved in essentially the same fashion as in the galerkin framework .",
    "indeed , we have , @xmath123 the resulting three terms after expansion are @xmath124 they can be handled efficiently in the same fashion .",
    "to do that , we invoke the affine assumptions - and the expansion of the reduced solution @xmath125 to obtain @xmath126 the offline - online decomposition of these terms as follows .    *",
    "calculate @xmath127 for @xmath128 , @xmath129 and @xmath130 . *",
    "evaluate the coefficients @xmath131 and form @xmath124      in this section , we show a particular advantage of the proposed empirical reduced collocation method over the traditional reduced basis method in the galerkin framework . when the operator is non - affine , that is , we have instead of @xmath132 the galerkin approach has to use the empirical interpolation method @xcite to achieve the offline - online decomposition and the traditional speedup .",
    "in fact , @xmath133 has to be approximated by the affine expansion @xmath134 so that @xmath135 are computed offline for all @xmath136 . during the online stage for any given @xmath2 ,",
    "@xmath137 are obtained and @xmath138 are formed .",
    "obviously , the online performance is dependent on @xmath139 the proliferation from @xmath140 to @xmath141 adversely affects the online performance of the reduced basis method and limits its practical scope .",
    "this is particularly the case for geometrically complex problems with parameters describing the geometry @xcite : @xmath141 can be one to two magnitudes larger than @xmath140 .",
    "the online efficiency is thus significantly worse than the affine problems .",
    "however , this significant barrier _ does not exist _ for the proposed empirical reduced collocation method . since to form the online solver we only need to evaluate @xmath142 for @xmath143 .",
    "this can be done without the expansion .",
    "note that @xmath144 is readily available from the offline calculation .",
    "unfortunately , this advantage of the empirical reduced collocation method over the galerkin framework does not translate to the least squares reduced collocation method : when @xmath145 , we need to perform the expansion to have the online procedure of forming @xmath49 matrix @xmath105 independent of @xmath11 .",
    "the fundamental reason is that least squares is intrinsically a projection method and thus our least squares reduced collocation method is closely related to the galerkin rbm framework .",
    "in this section , we consider a couple of two - dimensional diffusion - type test problems similar to those used in @xcite to show the accuracy and efficiency of the proposed methods :    1 .",
    "diffusion @xmath146 on @xmath147 \\times [ -1,1]$ ] with zero dirichlet boundary condition .",
    "anisotropic wavespeed simulation @xmath148 on @xmath147 \\times [ -1,1]$ ] with zero dirichlet boundary condition .",
    "our truth approximations are generated by a spectral chebyshev collocation method @xcite . for @xmath41 and for @xmath85",
    ", we use the chebyshev grid based on points in each direction .",
    "we consider the parameter domain @xmath15 for @xmath149 to be @xmath150 ^ 2 $ ] and @xmath151 \\times [ 0,2]$ ] respectively for the two test problems . for @xmath98 , they are discretized uniformly by @xmath152 and @xmath153 cartesian grids .        for the empirical reduced collocation method , we need the fine - to - coarse projection @xmath113 . we begin with a set of chebyshev points in one dimension @xmath154 . given a vector of function values @xmath155",
    ", we define the function @xmath156 by the chebyshev expansion @xcite @xmath157 where @xmath158 here , @xmath159    this definition relies on the fact that the chebyshev polynomial is @xmath160 so that @xmath161    now , if we wish to evaluate the function value of @xmath156 at any set of points @xmath162 , we simply plug those points into the chebyshev expansion @xmath163 in particular , the calculation of @xmath164 is done by evaluation at the reduced set of @xmath0 points @xmath38 .",
    "and @xmath165 computed on a @xmath166 chebyshev grid . ]     and @xmath165 with reference solution being computed on a @xmath166 chebyshev grid.,title=\"fig:\",scaledwidth=49.0% ]   and @xmath165 with reference solution being computed on a @xmath166 chebyshev grid.,title=\"fig:\",scaledwidth=49.0% ]        before we begin with the reduced basis solver , we must quantify the accuracy of the fine - domain solver , which produces the truth approximations .",
    "reference solutions computed by chebyshev collocation method on a @xmath166 grid for @xmath167 and @xmath165 are plotted in figure [ fig : truthsample ] .",
    "we also compute the truth solutions on a @xmath168 grid for @xmath169 changing from @xmath170 to @xmath171 and evaluate the @xmath23 and @xmath172 errors . exponential convergence of the truth approximation with respect to @xmath11 is shown by figure [ fig : truthaccuracy ] as expected .    in the greedy algorithm",
    ", we required a lower bound on the eigenvalue of the operator .",
    "for the purposes of this work , we simply calculate the smallest eigenvalue for each @xmath67 and use it as the lower bound @xmath55 .",
    "there are more efficient ways @xcite . however , algorithm design and implementation of how to efficiently calculate @xmath55 is not an emphasis of this paper .",
    "instead , we are concentrating on the design of the overall reduced basis method in the collocation framework .",
    "the eigenvalues @xmath173 are plotted in figure [ fig : diffanisoeigs ] for the two test problems .",
    "the first problem becomes close to being degenerate at the four corners of the parameter domain .      in this section",
    ", we present the results of the two reduced collocation methods applied to the anisotropic wavespeed simulation .",
    "error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the anisotropic wavespeed simulation . on the left are for the least squares reduced collocation method , and the empirical reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ]   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the anisotropic wavespeed simulation . on the left",
    "are for the least squares reduced collocation method , and the empirical reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ] +   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the anisotropic wavespeed simulation . on the left are for the least squares reduced collocation method , and the empirical reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ]   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the anisotropic wavespeed simulation . on the left are for the least squares reduced collocation method , and the empirical reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ] +   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the anisotropic wavespeed simulation . on the left are for the least squares reduced collocation method , and the empirical reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ]   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the anisotropic wavespeed simulation",
    ". on the left are for the least squares reduced collocation method , and the empirical reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ]    we first perform the offline pre - computation of the reduced basis and collocation points .",
    "the @xmath174 parameter values are chosen from @xmath98 by algorithms [ alg : lsgreedy ] and [ alg : rcgreedy ] are shown in figure [ fig : pickedmu ] , with larger marker indicating the earlier that parameter picked . the reduced set of collocation points @xmath38 for ercm is shown in figure [ fig : diffecmaniso ] ( top left ) .",
    "@xmath175 contains the @xmath121 points in the computational domain @xmath147 ^ 2 $ ] corresponding to the @xmath121 largest markers .",
    "next , we solve for the reduced basis solution for a randomly selected set of @xmath176 parameter values in @xmath15 and compute the maximum , median , and minimum errors for each selected value between the reduced solution and the truth approximations .",
    "these , together with the maximum of the error estimate are plotted in figure [ fig : histconv ] .",
    "we clearly see exponential convergence in all cases by both methods .",
    "we compare figure [ fig : truthaccuracy ] and figure [ fig : histconv ] to draw the following remarkable conclusion : in the worst case scenario , using the empirical reduced collocation method on a @xmath177 grid can produce solution having comparable accuracy of the truth approximation on a grid @xmath178 .",
    "we also see that , on average , the two proposed algorithms have similar accuracy .",
    "but , over a wide range of parameter values , the least squares approach seems to be more stable ( the errors have smaller variance )",
    ". moreover , we show in figure [ fig : diffecmaniso ] how the choice of the reduced set of collocation points @xmath38 affects the accuracy of the reduced collocation method : our proposed method generates the reduced grid on the top left . the best case scenario for a randomly selected set of @xmath176 parameter values",
    "are shown on the top right .",
    "on the other hand , if we naively use a coarse chebyshev grid as the @xmath38 ( shown bottom left ) , the best case convergence plot is on the bottom right : the approximation is very bad with the system becoming numerically singular for @xmath179 .",
    "we set @xmath180 ^ 2 $ ] , apply the empirical and least squares reduced collocation methods to the diffusion problem and present the results in this section .",
    "error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the diffusion problem . on the left are for the least squares approach , and the reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ]   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the diffusion problem . on the left are for the least squares approach , and the reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ] +   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the diffusion problem . on the left",
    "are for the least squares approach , and the reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ]   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the diffusion problem . on the left",
    "are for the least squares approach , and the reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ] +   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the diffusion problem . on the left are for the least squares approach , and the reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ]   error ( middle ) and the @xmath172 error ( bottom)of the rbm solutions for the diffusion problem . on the left",
    "are for the least squares approach , and the reduced collocation results are on the right.,title=\"fig:\",scaledwidth=45.0% ]    we pick @xmath181 parameter values in @xmath15 according to the greedy algorithm .",
    "the result is in figure [ fig : diffpickedmu ] with larger marker indicating the earlier it is picked .",
    "correspondingly , the @xmath181 points in @xmath182 determined by the ercm for empirical reduced collocation are shown in figure [ fig : diffecmellip ] .",
    "next , we solve for the rb solutions for randomly selected set of @xmath183 parameter values and compute the maximum of the errors for all selected between the reduced solution and the truth approximations .",
    "these , together with the maximum of the error estimate are plotted in figure [ fig : diffhistconv ] .",
    "we clearly see exponential convergence in all cases for both methods .      in this section ,",
    "we present statistics of the computation time for the reduced collocation methods .",
    "we present in table [ tab : comptime ] the offline and online computational time .",
    "we normalize the time with respect to that for solving truth approximation once .",
    "we see that the algorithm achieves savings of three orders of magnitude . from these examples",
    ", it seems that the empirical collocation approach is a little more efficient than the least - squares approach .",
    ".computation times of the methods for the two test problems . [ cols=\"<,^,^,^\",options=\"header \" , ]",
    "in this paper , we propose _ the first _",
    "reduced basis method for the collocation framework .",
    "two rather different approaches have been proposed and tested .",
    "they are both galerkin - free but produce the same fast exponential convergence and speedup as for the traditional galerkin approach . in future work",
    ", we will examine the accuracy and efficiency of our proposed methods for non - affine and nonlinear problems .",
    "we also plan to study and tailor successive constraint method , currently used for computation of the lower bound for the eigenvalues in the galerkin setting @xcite , for the collocation setting .",
    "the authors would like to thank professor maday , yvon from paris vi university for helpful discussions that led to a deeper understanding of the strength of our proposed approach .",
    "they also wish to thank the anonymous referees for constructive criticism that led to an improved presentation of the material in this paper .",
    "m.  barrault , n.  c. nguyen , y.  maday , and a.  t. patera .",
    "an `` empirical interpolation '' method : application to efficient reduced - basis discretization of partial differential equations .",
    ", 339:667672 , 2004 .                                c.  prudhomme , d.  rovas , k.  veroy , y.  maday , a.  t. patera , and g.  turinici .",
    "reliable real - time solution of parametrized partial differential equations : reduced - basis output bound methods . , 124(1):7080 , march 2002 .",
    "g.  rozza , d.b.p .",
    "huynh , and a.t .",
    "reduced basis approximation and a posteriori error estimation for affinely parametrized elliptic coercive partial differential equations : application to transport and continuum mechanics . , 15(3):229275 , 2008 ."
  ],
  "abstract_text": [
    "<S> in this paper , we present _ the first _ </S>",
    "<S> reduced basis method well - suited for the collocation framework . </S>",
    "<S> two fundamentally different algorithms are presented : the so - called least squares reduced collocation method ( lsrcm ) and empirical reduced collocation method ( ercm ) . </S>",
    "<S> this work provides a reduced basis strategy to practitioners who a collocation , rather than galerkin , approach . </S>",
    "<S> furthermore , the empirical reduced collocation method _ eliminates _ a potentially costly online procedure that is needed for non - affine problems with galerkin approach . </S>",
    "<S> numerical results demonstrate the high efficiency and accuracy of the reduced collocation methods , which match or exceed that of the traditional reduced basis method in the galerkin framework .    </S>",
    "<S> collocation method , reduced basis method , reduced collocation method , least squares , greedy algorithms    65m60 , 65n30 </S>"
  ]
}