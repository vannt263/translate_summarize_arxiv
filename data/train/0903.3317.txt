{
  "article_text": [
    "recently , data quality has become a hot topic in database community due to huge amount of `` dirty '' data originated from different resources ( see  @xcite for a survey ) . these data are often `` dirty '' , including inconsistencies , conflicts , and errors , due to various erroneous introduced by human and machines . in addition to cost of dealing the huge volume of data , manually detecting and removing `` dirty '' data is definitely out of practice because human proposed cleaning methods may introduce inconsistencies again .",
    "therefore , data dependencies , which have been widely used in the relational database design to set up the integrity constraints , have been revisited and revised to capture wider inconsistencies in the data .",
    "for example , consider a @xmath0 relation with the schema : @xmath1 the following functional dependency @xmath2 specifies a constraint that for any two tuples in @xmath0 , if they have the same @xmath3 code , then these two tuples have the same @xmath4 as well .",
    "recently , _ functional dependencies _ ( fds ) have been extended to _ conditional functional dependencies _ ( cfds )",
    "@xcite , i.e. , fds  with conditions , which have more expressive power .",
    "the basic idea of these extensions is making the fds , originally hold for the whole table , valid only for a set of tuples .",
    "for example , the following @xmath5 specifies that only in the condition of country code @xmath6 , if two tuples have the same @xmath3 , then they must have same @xmath7 as well .",
    "@xmath8\\rightarrow[\\mathsf{city}]\\\\ \\mathsf{cfd } & : & [ \\mathsf{zip } , \\mathsf{cc=44}]\\rightarrow[\\mathsf{street}]\\end{aligned}\\ ] ] these dependency constraints can be used to detect data violations  @xcite .",
    "for instance , we can use the above @xmath2 to detect violations in an instance of @xmath0 in table  [ table_data_relation ] . for the tuples @xmath9 and @xmath10 with the same values of @xmath11 , they have different values of @xmath4 , which are then detected as violations of the above @xmath2 .",
    "although functional dependencies ( and their extension with conditions ) are very useful in determining data inconsistency and repairing the `` dirty '' data  @xcite , they check the specified attribute value agreement based on",
    "_ exact match_. for example , with the above @xmath5 , tuples that have @xmath6 and the same value on @xmath3 attribute will be checked to see whether they have exactly matched values on @xmath7 .",
    "obviously , this strict exact match constraint limits usage of fds  and cfds , since real - world information often have various representation formats .",
    "for example , the tuples @xmath12 and @xmath13 in @xmath0 table will be detected as `` violations '' of the @xmath5 , since they have `` different '' @xmath7 values but agree on @xmath3 and @xmath6 . however , `` no.2 , central rd . '' and `` # 2 , central rd . ''",
    "are exactly the `` same '' street in the real - world with different representation formats .",
    "to make dependencies adapt to this real - world scenario , i.e. , to be tolerant of various representation formats , fan  @xcite proposed a new concept of data dependencies , called _ matching dependencies _ ( mds ) .",
    "informally , a matching dependency targets on the fuzzy values like text attributes and defines the dependency between two set of attributes according to their matching quality measured by some matching operators ( see  @xcite for a survey ) , such as _ euclidean distance _ and _ cosine similarity_. again , in @xmath0 example , we may have a md  as @xmath14\\rightarrow[\\mathsf{city } ] , < 0.8 , 0.7>)\\end{aligned}\\ ] ] which states that for any two tuples from @xmath0 , if they agree on attribute @xmath7 ( the matching similarity , e.g. _ cosine similarity _",
    ", on the attribute @xmath7 is greater than a threshold @xmath15 ) , then the corresponding @xmath4 attribute should match as well ( i.e. similarity on @xmath4 is greater than the corresponding threshold @xmath16 ) .",
    "584 & claire green & 44 & 606 & chicago & no.2 , central rd . & @xmath17 + 584 & claire gree & 44 & 606 & chicago & no.2 , central rd . & @xmath12 + 584 & claire gree & 44 & 606 & chicago & # 2 , central rd . & @xmath13 + 265 & jason smith & 01 & 021 & boston & no.3 , central rd . & @xmath18 + 265 & j. smith & 01 & 021 & boston & # 3 , central rd . &",
    "@xmath9 + 939 & w. j. smith & 01 & 021 & chicago & # 3 , central rd . & @xmath10 +    similar to the fds  related techniques , mds  can be applied in many tasks as well  @xcite .",
    "for example , in data cleaning , we can also use mds  to detect the inconsistent data , that is , data do not follow the constraint ( rule ) specified by mds .",
    "for example , according to the above @xmath19 example , for any two tuples @xmath20 and @xmath21 having similarity greater than @xmath15 on @xmath7 , they should be matched on @xmath4 as well ( similarity @xmath22 ) .",
    "if their @xmath4 similarity is less than @xmath16 , then there must be something wrong in @xmath20 and @xmath21 , i.e. , inconsistency .",
    "such inconsistency on text attributes can not be detected by using fds  and extensions based on exact matching . in addition to locating the inconsistent data , object identification , another important work for data cleaning , can also employ mds  as matching rules  @xcite .",
    "for instance , according to @xmath23 \\rightarrow [ \\mathsf{sin}],<0.9 , 0.9 , 1.0>)\\ ] ] if two tuples have high similarities on @xmath24 and @xmath7 ( both similarities are greater than 0.9 ) , then these two tuples probably denote the same person in the real world , i.e. , having the same @xmath25 .",
    "though the concept of matching dependencies is given in  @xcite , the authors did not discuss how to discover useful mds .",
    "in fact , given a database instance , there are enormous mds  that can be discovered if we set different similarity thresholds on attributes .",
    "note that if all thresholds are set to @xmath26 , mds  have the same semantics as traditional fds , in other words , traditional fds  are special cases of mds .",
    "for instance , the above @xmath2 can be represented by a md  @xmath27\\rightarrow[\\mathsf{city } ] , < 1.0 , 1.0>)$ ] .",
    "clearly , not all the settings of thresholds for mds  are useful .",
    "the utility of mds  in the above applications is often evaluated by _ confidence _ and _ support_. specifically , we consider a md  of a relation @xmath28 , denoted by @xmath29 , where @xmath30 and @xmath31 are the attribute sets of @xmath28 , @xmath32 is a pattern specifying different similarity thresholds on each attribute in @xmath30 and @xmath31 .",
    "let @xmath33 and @xmath34 be the projections of thresholds in pattern @xmath32 on the attributes @xmath30 and @xmath31 respectively .",
    "the _ support _ of @xmath35 is the proportion of tuple pairs whose matching similarities are higher than the thresholds in @xmath35 on both attributes of @xmath30 and @xmath31 .",
    "the _ confidence _ is the ratio of tuple pairs whose matching similarities satisfy @xmath33 also satisfying @xmath34 . in real applications like inconsistency detection , in order to achieve high detection accuracy , we would like to use mds  with high confidence .",
    "on the other hand , if users need high recall of detection , then mds  with high support are preferred .",
    "intuitively , we would like to discover those mds  with high support , high confidence and high matching quality .",
    "therefore , in this work , we would like to discover proper settings of matching similarity thresholds for mds , which can satisfy users utility requirements of support and confidence .",
    "[ [ contributions ] ] contributions + + + + + + + + + + + + +    in this paper , given a relation instance and @xmath36 , we study the issues of discovering matching dependencies on the given @xmath36 .",
    "our main contributions are summarized as follows :    first , we propose the utility evaluation of _ matching dependencies_. specifically , the confidence and support evaluations of mds  are formally defined . to the best of our knowledge ,",
    "this is the first paper to study the utility evaluation and discovery of mds .",
    "second , we study the exact algorithms for discovering mds .",
    "the mds  discovery problem is to find settings of matching similarity thresholds on attributes @xmath30 and @xmath31 for mds  that can satisfy the required confidence and support .",
    "we first present an exact solution and then study pruning strategies by the minimum requirements of support and confidence .",
    "third , we study the approximation algorithms for discovering mds .",
    "since the exact algorithm has to traverse all the data during the computation , we propose an approximate solution which only use some of the data",
    ". a bound of relative errors introduced by the approximation is developed .",
    "moreover , we also develop a strategy of early termination in individual step .",
    "finally , we report an extensive experimental evaluation . the proposed algorithms on discovering mds  are studied .",
    "our pruning strategies can significantly improve the efficiency in discovering mds .",
    "the remainder of this paper is organized as follows .",
    "first , we introduce some related work in section  [ sect_related ] .",
    "then , section  [ sect_model ] presents the utility measures for mds , including support and confidence . in section  [ sect_optimal_md ]",
    ", we develop the exact algorithm for discovering mds  and study the corresponding pruning strategies . in section  [ sect_approximation ]",
    ", we present the approximation algorithm with bounded relative errors . in section  [ sect_experiment ]",
    ", we report our extensive experimental evaluation .",
    "finally , section  [ sect_conclusion ] concludes this paper .",
    "table  [ table_notations ] lists the frequently used notations in this paper .",
    "cl symbol & description + @xmath35 & matching dependency , md   + @xmath32 & threshold pattern , of matching similarity + @xmath37 & candidate set , of total @xmath38 threshold patterns + @xmath39 & minimum requirement , of support + @xmath40 & minimum requirement , of confidence + @xmath28 & original relation , of @xmath41 data tuples @xmath42 + @xmath43 & statistical distribution , of @xmath44 statistical tuples @xmath45 +",
    "traditional dependencies , such as functional dependencies ( fds ) and inclusion dependencies ( inds ) for the schema design  @xcite , are revisited for new applications like improving the quality of data .",
    "the conditional functional dependencies ( cfds ) are first proposed in  @xcite for data cleaning .",
    "cong et al .",
    "@xcite study the detecting and repairing methods of violation by cfds .",
    "fan et al .",
    "@xcite investigate the propagation of cfds  for data integration .",
    "bravo et al .",
    "@xcite propose an extension of cfdsby employing disjunction and negation .",
    "golab et al .",
    "@xcite define a range tableau for cfds , where each value is a range similar to the concept of matching similarity intervals in our study .",
    "in addition , bravo et al .",
    "@xcite propose conditional inclusion dependency ( cinds ) , which are useful not only in data cleaning , but are also in contextual schema matching .",
    "ilyas et al.@xcite study a novel soft fd , which is also a generalization of the classical notion of a hard fd  where the value of @xmath30 completely determines the value of @xmath31 . in a soft fd ,",
    "the value of @xmath30 determines the value of @xmath31 not with certainty , but merely with high probability .",
    "the confidence and support measures are widely used in discovering approximate functional dependencies  @xcite and evaluating cfds  @xcite .",
    "the confidence can be interpreted as an estimate of the probability that a randomly drawn pair of tuples agreeing on @xmath30 also agree on @xmath31  @xcite .",
    "scheffer  @xcite study the trade off between support and confidence for finding association rules  @xcite , by computing a expected prediction accuracy .",
    "in addition , chiang and miller  @xcite also study some other measures such as conviction and @xmath46-test for evaluating dependency rules . when a candidate @xmath36 is suggested together with minimum support and confidence , golab et al .",
    "@xcite study the discovery of optimal cfds  with the minimum pattern tableau size .",
    "a concise set of patterns are naturally desirable which may have lower cost during the applications such as violation detection by cfds . on the other hand ,",
    "chiang and miller  @xcite explore cfds  by considering all the possible dependency candidates when @xmath36 is not specified . in  @xcite , fan et al . also study the case when the embedded fds  are not given , and propose three algorithms for different scenarios .",
    "the concept of matching dependencies ( mds ) is first proposed in  @xcite for specifying matching rules for the object identification ( see  @xcite for a survey ) .",
    "the mds  can be regarded as a generalization of fds , which are based on identical values having matching similarity equal to @xmath26 exactly .",
    "thus , fds  can be represented by the syntax of mds  as well .",
    "for any two tuples , if their @xmath30 values are identical ( with similarity threshold @xmath26 ) , then a fd  @xmath47 requires that their @xmath31 values are identical too , i.e. , a md@xmath48 .",
    "koudas et al .",
    "@xcite also study the dependencies with matching similarities on attributes @xmath31 when given the _",
    "exactly _ matched values on @xmath30 , which can be treated as a special case of mds .",
    "the reasoning mechanism for deducing mds  from a set of given mds  is studied in  @xcite .",
    "the mds  and their reason techniques can improve both the quality and efficiency of various record matching methods .",
    "in this section , we formally introduce the definitions of mds . then",
    ", we develop utility measures for evaluating mds  over a given database instance .",
    "traditional functional dependencies fds  and their extensions rely on the exact matching operator @xmath49 to identify dependency relationships . however , in the real world application , it is not possible to use exact matching operator @xmath49 to identify matching over fuzzy data values such as text values .",
    "for instance , @xmath50 and @xmath51 of attribute @xmath24 may refer to the same real world entity .",
    "therefore , instead of fds  on identical values , the _ matching dependencies _",
    "mds  @xcite are proposed based on the matching quality . for text values",
    ", we can adopt the similarity matching operators , denoted by @xmath52 , such as _ edit distance _",
    "@xcite , _ cosine similarity _ with word tokens  @xcite or _ q - grams _  @xcite .    consider a relation @xmath53 with @xmath54 attributes .",
    "following similar syntax of fds , we define mds  as following : for object identification in  @xcite , which can also be represented in a single relation schema @xmath55 as the fds . ]    [ def_md_dependency ] a _ matching dependency ( md ) _ @xmath35 is a pair @xmath56 ,",
    "where @xmath57 , and @xmath32 is a _ threshold pattern _ of matching similarity thresholds on attributes in @xmath58 , e.g. ,",
    "@xmath59 $ ] denotes the matching similarity threshold on attribute @xmath60 .",
    "a md  @xmath35 specifies a constraint on the set of attributes @xmath30 to @xmath31 .",
    "specifically , the constraint states that , for any two tuples @xmath17 and @xmath12 in a relation instance @xmath61 of @xmath28 , if @xmath62\\approx_{\\lambda[a_i ] } t_2[a_i]$ ] , then @xmath63\\approx_{\\lambda[a_j ] } t_2[a_j]$ ] , where @xmath64 $ ] and @xmath65 $ ] are the _ matching similarity thresholds _ on the attributes of @xmath66 and @xmath67 respectively . in the above constraint , for each attribute @xmath68 , the similarity matching operator @xmath52 indicates @xmath69 , if the similarity between @xmath70 $ ] and @xmath71 $ ] satisfies the corresponding threshold @xmath64 $ ] .",
    "for example , a md  @xmath72\\rightarrow[\\mathsf{city } ] , < 0.8 , 0.7>)$ ] in the @xmath0 relation denotes that if two tuples has similar @xmath7 ( with matching similarity greater than @xmath15 ) then their @xmath4 values are probably similar as well ( with similarity at least @xmath16 ) .    like fds  and cfds  @xcite",
    ", we adopt _ support _ and _ confidence _ measures to evaluate the matching dependencies . according to the above constraint of mds",
    ", we need to consider the matching quality ( e.g. , cosine similarity or edit distance ) of any pair of tuples @xmath17 and @xmath12 for @xmath28 .",
    "therefore , we compute a statistical distribution ( denoted by @xmath43 ) of the quality of pair - wised tuple matching for @xmath28 .",
    "the statistical distribution has a schema @xmath73 , where each attribute @xmath66 in @xmath43 corresponds to the matching quality values on the attribute @xmath66 of @xmath28 , and @xmath74 is the statistical value .",
    "let @xmath45 be a statistical tuple in @xmath43 .",
    "the statistic @xmath75 $ ] denotes the probability that any two tuples @xmath17 and @xmath12 of @xmath28 have the matching quality values @xmath76 $ ] , @xmath77 . with a pair - wised evaluation of matching quality of all the @xmath41 tuples for @xmath28 , we can easily compute @xmath74 by @xmath78 , where @xmath79 records the pairs of tuples having matching quality @xmath45 .",
    "different matching operators have various spaces of matching values , such as cosine similarity in @xmath80 $ ] while edit distance having edit operations @xmath81 . in order to evaluate in a consistent environment",
    ", we map these matching quality values @xmath82 $ ] to a unified space , say @xmath83 $ ] , which is represented by @xmath84 with @xmath85 elements . table  [ table_model_general ] shows an example of the statistical distribution @xmath43 computed from @xmath0 in table [ table_data_relation ] by mapping times @xmath86 the cosine similarities in @xmath80 $ ] to elements in @xmath83 $ ] of @xmath84 with @xmath87 . according to @xmath84 in our example , the first tuple @xmath88 denotes that there are about @xmath89 matching pairs in all pair - wised tuple matching , whose similarities are @xmath90 on the attribute @xmath91 respectively .",
    "@xmath92 & @xmath93 & @xmath94 & @xmath74 & + 1 & 0 & 3 & 5 & 8 & 4 & 0.065 & @xmath95 + 7 & 4 & 0 & 0 & 4 & 1 & 0.043 & @xmath96 + 0 & 4 & 8 & 1 & 6 & 2 & 0.124 & @xmath97 + & & & & & & & +    then , we can measure the support and confidence of mds , with various attributes @xmath30 and @xmath31 , based on the statistical distribution @xmath43 .",
    "let @xmath33 and @xmath34 be the projections of matching similarity threshold pattern @xmath32 on the attributes of @xmath30 and @xmath31 respectively in a md  @xmath35 , which are also specified in terms of elements in @xmath84 of each @xmath98 .",
    "let @xmath99 be the set of attributes not specified by @xmath35 , i.e. , @xmath100 .",
    "the definitions of support and confidence for the md  @xmath101 are presented as follows : @xmath102 where @xmath103 denotes the _ satisfiability _ relationship , i.e. , @xmath104 denotes that the similarity values on all attributes in @xmath30 satisfy the corresponding thresholds listed in @xmath33 .",
    "for example , we say that a statistical tuple @xmath45 in @xmath43 satisfies @xmath33 , i.e. , @xmath105\\vdash\\lambda_x$ ] , if @xmath45 has similarity values higher than the corresponding minimum threshold , i.e. , @xmath82\\geq \\lambda[a]$ ] , for each attribute @xmath60 in @xmath30 .",
    "consider any two tuples @xmath17 and @xmath12 from the original data relation @xmath28 , the @xmath106 estimates the probability that the matching similarities of @xmath17 and @xmath12 on attributes @xmath30 and @xmath31 satisfy the thresholds specified by @xmath33 and @xmath34 , respectively .",
    "similarly , the @xmath107 computes the conditional probability that the matching similarities between @xmath17 and @xmath12 on @xmath31 satisfy the thresholds specified by @xmath34 ( i.e. , @xmath108 ) given the condition that @xmath17 and @xmath12 are similar on attributes @xmath30 ( i.e. , @xmath104 ) .",
    "thus , high @xmath107 means few instances of matching pairs that are similar on attributes @xmath30 ( i.e. , @xmath104 ) but not similar on attributes @xmath31 ( i.e. , @xmath109 ) , where @xmath110 denotes the unsatisfiability relationship .    in real applications like inconsistency detection , in order to achieve high detection accuracy , we would like to use mdswith high confidence . on the other hand ,",
    "if users need high recall of detection , then mds  with high support are preferred .",
    "intuitively , we would like to discover those mds  with high support and high confidence .",
    "therefore , in the following of this paper , we study the problem of discovering mds  that can satisfy users minimum utility requirement of support @xmath39 and confidence @xmath39 .",
    "we now study the determination of matching similarity threshold pattern for mds  based on the statistical distribution , which is a new problem different from fds .",
    "in fact , once the @xmath36 is given for a fd , it already implies the similarity threshold to be @xmath26 , that is , @xmath48 if it is represented by the md  syntax . unlike fds , we have various settings of matching similarity thresholds for mds .",
    "therefore , in this section , we discuss how to find the right similarity thresholds in order to discover the mds  satisfying the required support and confidence .      in order to discover a md  @xmath35 with the minimum requirements of support @xmath111 and confidence @xmath112 , the following preliminary",
    "should be given first : * ( i ) * what is @xmath31 ? and * ( ii ) * what is matching quality requirement @xmath34 .",
    "these two preliminary questions are usually addressed by specific applications .",
    "for example , if we would like to use discovered mds  to guide objet identification in the @xmath0 table , then @xmath113 .",
    "the @xmath34 is often set to high similarity thresholds by applications to ensure high matching quality on @xmath31 attributes .",
    "for example , @xmath34 is set to @xmath26 for @xmath113 in the object identification application .",
    "note that without the preliminary @xmath34 , the discovered mdswill be meaningless .",
    "for example , a md  with @xmath114 can always satisfy any requirement of @xmath115 .",
    "since all the statistical tuples can satisfy the thresholds @xmath114 , the corresponding support and confidence will always be equal to @xmath26 .",
    "the threshold determination problem of mds  is : given the minimum requirements of support and confidence @xmath116 and the matching similarity threshold pattern @xmath34 , find all the mds@xmath29 with threshold pattern @xmath33 on attributes @xmath30 having @xmath117 and @xmath118 , if exist ; otherwise return _ infeasible_.    the attributes @xmath30 can be initially assigned by @xmath119 if no suggestion is provided by specific applications , since our discovery process can automatically remove those attributes that are not required in @xmath30 for a md  @xmath35 .",
    "specifically , when a possible discovered threshold @xmath59 $ ] on attribute @xmath60 is @xmath120 , it means that any matching similarity value of the attribute @xmath121 can satisfy the threshold @xmath122 and will not affect the md  @xmath35 at all .",
    "in other words , the attribute @xmath60 can be removed from @xmath30 of the md  @xmath35 .",
    "now , we present an algorithm to compute the matching similarity thresholds on attributes @xmath30 for mds  having support and confidence greater than @xmath39 and @xmath40 , respectively .",
    "let @xmath123 be the @xmath124 attributes in @xmath30 . for simplicity",
    ", we use @xmath32 to denote the threshold pattern projection @xmath33 with @xmath125 , \\dots , \\lambda[a_{m_x}]$ ] on all the @xmath124 attributes of @xmath30 .",
    "since , each threshold @xmath59 $ ] on attribute @xmath60 is a value from @xmath84 , i.e. , @xmath59\\in\\mathsf{dom}(a)$ ] , we can investigate all the possible candidates of threshold pattern @xmath32 .",
    "let @xmath37 be the set of all the possible threshold pattern candidates , having @xmath126 the total number of candidates is @xmath127 , where @xmath85 is the size of @xmath84 .",
    "let @xmath44 be the number of statistical tuples in the input statistical distribution @xmath43 .",
    "we consider two statistical values @xmath128 and @xmath129 , which record @xmath130 and @xmath131 respectively for the candidate @xmath132 based on the information of the first @xmath133 tuples in @xmath43 , initially having @xmath134",
    ". the recursion is defined as follows , with @xmath133 increasing from @xmath135 to @xmath44 and @xmath136 increasing from @xmath135 to @xmath38 .",
    "@xmath137 , & \\mathrm{if~ } s_i[x]\\vdash\\lambda_j , s_i[y]\\vdash\\lambda_y \\\\     p_{i-1}^{j}(x ,",
    "y ) , & \\mathrm{otherwise }     \\end{cases}\\\\ p_{i}^{j}(x ) & = &   \\begin{cases }     p_{i-1}^{j}(x)+s_i[p ] , & \\mathrm{if~ } s_i[x]\\vdash\\lambda_j   \\\\",
    "p_{i-1}^{j}(x ) , & \\mathrm{otherwise }     \\end{cases}\\end{aligned}\\ ] ] finally , those @xmath138 can be returned if @xmath139 and @xmath140 .",
    "@xmath134 compute @xmath141 @xmath138 with confidence and support satisfying @xmath142    we can implement the exact algorithm ( namely ea ) by considering all the statistical tuples @xmath143 in @xmath43 with @xmath133 from @xmath135 to @xmath44 , whose time complexity is @xmath144 .      since the original exact algorithm needs to traverse all the @xmath44 statistical tuples in @xmath43 and @xmath38 candidate threshold patterns in @xmath37 , which is very costly .",
    "in fact , with the given @xmath39 and @xmath40 , we can investigate the relationship between similarity thresholds and avoid checking all candidate threshold patterns in @xmath37 and all statistical tuples in @xmath43 .",
    "therefore , in the following two subsections , we present pruning techniques based on the given support and confidence , respectively .    [",
    "[ pruning - by - support ] ] pruning by support + + + + + + + + + + + + + + + + + +    we first study the relationships among different threshold patterns , based on which we then propose rules to filter out candidates that have supports lower than @xmath39 .",
    "[ def_md_dominate ] given two similarity threshold patterns @xmath145 and @xmath146 , if @xmath147\\leq \\lambda_2[a]$ ] holds for all the attributes , @xmath148 , then @xmath145 _ dominates _",
    "@xmath146 , denoted as @xmath149 .",
    "based on the _ dominate _ definition , the following lemma describes the relationships of supports between similarity threshold patterns .",
    "[ lemma_md_support_increase ] given two mds , @xmath150 and @xmath151 over the same relation instance of @xmath28 , if @xmath145 dominates @xmath146 , @xmath149 , then we have @xmath152 .",
    "let @xmath153 and @xmath154 denote the set of statistical tuples that satisfy the threshold @xmath145 and @xmath146 respectively , e.g. , @xmath155\\vdash\\lambda_2 , s\\in \\mathcal{d}\\}$ ] . according to the minimum similarity thresholds , for each attribute @xmath60 , we have @xmath156\\leq s[a]$ ] .",
    "in addition , since @xmath157 , for any tuple @xmath158 , we also have @xmath147\\leq\\lambda_2[a]\\leq s[a]$ ] on all the attributes @xmath60 . in other words , the set of statistical tuples covered by @xmath146",
    "also satisfy the threshold of @xmath145 , i.e. , @xmath159 . referring to the definition of @xmath160",
    ", we have @xmath152 .    according to lemma [ lemma_md_support_increase ] ,",
    "given a candidate similarity threshold pattern @xmath138 having support lower than the user specified requirement @xmath39 , i.e. , @xmath161 , all the candidates that are dominated by @xmath138 should have support lower than @xmath39 and can be safely pruned without computing their associated support and confidence .",
    "we present the implementation of pruning by support ( namely eps ) in algorithm  [ alg_md_prune_support ] .",
    "@xmath162 compute @xmath163 remove all the remaining candidates @xmath164 dominated by @xmath138 from @xmath37 @xmath138 with confidence and support satisfying @xmath142    in order to maximize the pruning , we can heuristically select an ordering of candidates in @xmath37 that for any @xmath165 having @xmath166 .",
    "that is , we always first process the candidates that dominate others .",
    "in fact , we can use a dag ( directed acyclic graph ) , @xmath167 , to represent candidate similarity patterns as vertices and dominant relationships among the similarity patterns as edges .",
    "therefore , the dominant order of candidate patterns can be obtained by a bfs traversal upon @xmath167 .",
    "[ [ pruning - by - confidence ] ] pruning by confidence + + + + + + + + + + + + + + + + + + + + +    other than pruning by support , we can also utilize the given confidence requirement to avoid further examining tuples that have no improvement of confidence when the confidence is already lower than @xmath40 for a candidate @xmath138 .",
    "we first group the statistical tuples in @xmath43 into two parts based on the preliminary @xmath34 as follows .",
    "let @xmath168 be a pivot between @xmath135 and @xmath44 .",
    "for the first @xmath168 tuples , we have @xmath169\\vdash\\lambda_y , 1\\leq i\\leq k$ ] .",
    "all the remaining @xmath170 tuples have @xmath169\\nvdash\\lambda_y , k+1 \\leq i\\leq n$ ] .",
    "this grouping of statistical tuples in @xmath43 can be done in linear time .",
    "[ lemma_md_confidence_decrease ] consider a pre - grouped statistical distribution @xmath43 .",
    "for any @xmath171 , we always have @xmath172    since the first @xmath168 tuples have @xmath169\\vdash\\lambda_y$ ] , according to the computation of @xmath173 and @xmath174 , we have @xmath175 moreover , for the remaining @xmath170 tuples with @xmath169\\nvdash\\lambda_y$ ] , the @xmath173 value will not change any more , i.e. , @xmath176 .",
    "meanwhile , the corresponding @xmath174 is non - decreasing , that is , @xmath177 for any @xmath178 .",
    "consequently , we have @xmath179 combining above two statements , we proved the lemma .    therefore , according to the formula of confidence , with the increase of @xmath133 from @xmath135 to @xmath44 , the confidence of a specific candidate @xmath138 is non - increasing . for a candidate @xmath138 , when processing the statistical tuple @xmath143 , if the current confidence @xmath180 is lower than @xmath40 , then we can prune the candidate @xmath138 without considering the remaining statistical tuples from @xmath181 to @xmath44 in @xmath43 .",
    "@xmath134 compute @xmath182 remove @xmath138 from @xmath37 * break * remove all the remaining candidates @xmath164 dominated by @xmath138 from @xmath37 @xmath138 with confidence and support satisfying @xmath142    finally , both the pruning by support and the pruning by confidence are cooperated together into a single threshold determination algorithm as shown in algorithm  [ alg_md_prune_both](namely epsc ) .",
    "we also demonstrate the performance of the hybrid pruning epsc  in section  [ sect_experiment ] .",
    "though we have proposed pruning rules for exact method ( algorithm [ alg_md_prune_both ] ) , the whole evaluation space is still all the @xmath44 tuples in statistical distribution @xmath43 .",
    "therefore , in this section , we present an approximate algorithm which only traverses the first @xmath168 ( @xmath183 ) tuples in @xmath43 , with bounded relative errors on support and confidence of returned mds .",
    "let @xmath184 and @xmath185 be the confidence and support computed in the exact solution with all @xmath44 tuples .",
    "we study the approximate confidence and support , @xmath186 and @xmath187 , by ignoring the statistical tuples from @xmath188 to @xmath189 . for a candidate threshold pattern @xmath132 ,",
    "let @xmath190 where @xmath191 denotes @xmath131 for the candidate @xmath138 based on the first @xmath168 tuples in @xmath43 , and @xmath192 is @xmath131 based on the remaining @xmath170 tuples .",
    "the following lemma indicates the error bounds of @xmath186 and @xmath187 when @xmath192 for a specific @xmath168 is in a certain range .",
    "[ lemma_md_appx_bound ] if we have @xmath193 , then the error of approximate confidence @xmath186 compared to the exact confidence @xmath184 is bounded by @xmath194 , and the error of approximate support @xmath187 compared to the exact @xmath185 is bounded by @xmath195 .",
    "let @xmath196 according to the computation of confidence , we have @xmath197 and @xmath198 .",
    "let @xmath199 , that is , @xmath200    first , we have @xmath201\\geq\\alpha$ ] .",
    "note that @xmath202 is the approximate support of the md  @xmath35 with matching similarity threshold pattern @xmath138 on the attributes @xmath30 . according to the minimum support constraint , for a valid @xmath138",
    ", we have @xmath203 .",
    "thereby , @xmath204 moreover , according to the condition @xmath205 , that is @xmath206 , we have @xmath207    second , similar to @xmath208 , we also have @xmath209 for the tuples from @xmath210 to @xmath44 .",
    "therefore , @xmath211 according to the minimum confidence @xmath212 , @xmath213 recall that @xmath214 and the confidence should be lower than or equal to @xmath135 , i.e. , @xmath215 .",
    "thus , @xmath216 since we have the condition @xmath217 , @xmath218    finally , based on the above two conditions , we conclude that @xmath219 @xmath220    on the other hand , according to the computation of support , we have @xmath221 and @xmath222 .",
    "therefore , @xmath223 recall that we have @xmath224 and @xmath225 .",
    "@xmath226 that is , the worst - case relative error is bounded by @xmath227 for both the confidence and support .",
    "now , we consider the last @xmath170 tuples in @xmath43 .",
    "let @xmath228,\\ ] ] where @xmath229 $ ] is the probability associated to each statistical tuple in @xmath43 .",
    "referring to the definition of @xmath192 , for any @xmath138 , we always have @xmath230 .",
    "if there exists a @xmath168 having @xmath231 , then @xmath193 is satisfied for all the threshold candidates @xmath138 . since the @xmath232 decreases with the increase of @xmath168 , to determine a minimum @xmath168 is to find a corresponding maximum @xmath232 .",
    "therefore , according to lemma  [ lemma_md_appx_bound ] , given an error bound @xmath233 , we can compute a minimum position @xmath234 having @xmath231 .",
    "[ the_approx ] given an error bound @xmath233 , we can determine a minimum @xmath168 , having @xmath235 the approximation by considering first @xmath168 tuples in @xmath43 finds approximate mds  with the error bound @xmath227 on both the confidence and support compared with the exact one .",
    "the complexity is @xmath236 .    finally , we present the approximation implementation in algorithm  [ alg_md_approx ] .",
    "let @xmath237 denotes @xmath238 $ ] for the current @xmath168 . with @xmath168 decreasing from @xmath44 to @xmath135",
    ", we can determine a minimum @xmath168 where @xmath239 is still satisfied .",
    "after computing @xmath168 , we process the tuples @xmath143 starting from @xmath240 . when the bound condition is first satisfied , i.e. , @xmath241 with @xmath239 , the processing terminates .",
    "here , the error bound @xmath227 is specified by user requirement with @xmath242 .",
    "@xmath237 ` + = ` @xmath243 $ ] @xmath168`++ ` ; * break * @xmath244 compute @xmath245 @xmath138 with confidence and support satisfying @xmath142    given an error bound @xmath227 , the bound condition is then fixed . in order to minimize @xmath168 , we expect that the @xmath74 values of the tuples from @xmath210 to @xmath44 in @xmath246 $ ] are small .",
    "in other words , an instance of @xmath43 with higher @xmath74 in the tuples from @xmath135 to @xmath168 is preferred .",
    "therefore , we can reorganize the tuples in @xmath43 in the decreasing order of @xmath74 as the input of algorithm  [ alg_md_approx ] .",
    "the ordering of statistical tuples in @xmath43 by the @xmath74 values can be done in linear time by amortizing the @xmath74 values into a constant domain .",
    "[ [ approximation - individually ] ] approximation individually + + + + + + + + + + + + + + + + + + + + + + + + + +    we study the approximation by each individual candidate @xmath138 with a more efficient bound condition respectively . according to formula ( [ equ_md_error_bound ] ) in the proof of error bound , we find that for each specific candidate @xmath138 if @xmath247 , then the error bound is already satisfied and the processing can be terminated for this @xmath138 .",
    "therefore , rather than one fixed bound condition for all the candidates , the bound of @xmath192 can be determined dynamically for each candidate @xmath138 respectively during the processing .",
    "algorithm  [ alg_md_approx_prune ] shows the implementation of approximation with dynamic bound condition on each candidate @xmath138 individually .",
    "@xmath237 ` + = ` @xmath229 $ ] @xmath248 @xmath244 @xmath249 compute @xmath245 @xmath250 @xmath251 ` -= ` @xmath229 $ ] * break * @xmath138 with confidence and support satisfying @xmath142    the worst case complexity of the approximation individually is @xmath236    note that with the increasing of @xmath133 from @xmath135 to @xmath168 , for a specific @xmath138 , the value @xmath191 increases and @xmath251 decreases . for any @xmath252 , if @xmath253 , i.e. , @xmath138 is invalid currently , the bound condition can not be satisfied having @xmath254 when @xmath138 has @xmath214 as a valid threshold , the bound condition is relaxed from @xmath255 to @xmath256 .",
    "thereby , the bound condition may be satisfied by a smaller @xmath133 than @xmath168 , i.e. , @xmath257 the worst case is that all candidates do not achieve their bounds until processing the tuple @xmath258 , where @xmath259 must be satisfied .",
    "this is exact the algorithm  [ alg_md_approx ] without individual approximation .",
    "finally , we cooperate the pruning by support together with the approximation ( namely aps ) and the approximation individually ( namely apsi ) respectively . as we presented in the experimental evaluation",
    ", the approximation techniques can further improve the discovering efficiency with an approximate solution very close to the exact one ( bounded by @xmath227 ) .",
    "now , we report the experiment evaluation on proposed methods .",
    "all the algorithms are implemented by java .",
    "the experiment evaluates on a machine with intel core 2 cpu ( 2.13 ghz ) and 2  gb of memory .",
    "[ [ experiment - setting ] ] experiment setting + + + + + + + + + + + + + + + + + +    in the experimental evaluation , we use three real data sets .",
    "the _ _ cora _ _ data set , prepared by mccallum et al .",
    "@xcite , consists of 12 attributes including @xmath260 @xmath261 , etc .",
    "the _ _ restaurant _ _ data set consists of restaurant records including attributes @xmath262 and @xmath263 .",
    "the _ _ citeseer _ _ data set is selected with attributes including @xmath264 , etc .",
    "we use the _ cosine _ similarity to evaluate the matching quality of the tuples in the original data . by applying the @xmath84 mapping in section  [ sect_model ] ,",
    "we can obtain statistical distributions with at most @xmath265 statistical tuples in _ cora _ , @xmath266 statistical tuples in _ restaurant _ and @xmath267 statistical tuples in _",
    "citeseer_. our experimental evaluation is then conducted in several pre - processed statistical distributions with various sizes of statistical tuples @xmath44 from @xmath268 to @xmath269 respectively",
    ".    we mainly observes the efficiency of proposed algorithms . since our main task is to discover mds  under the required @xmath39 and @xmath40 , we study the runtime performance in various distributions with different @xmath39 and @xmath40 settings .",
    "the discovery algorithms determine the matching similarity settings of attributes for mds .",
    "suppose that users want to discover mds  on the following @xmath36 of three data sets respectively : * i ) * the dependencies on @xmath270 with the preliminary requirement of minimum similarity @xmath271 on @xmath261 ; * ii ) * the dependencies on @xmath272 with the preliminary requirement of minimum similarity @xmath273 on @xmath274 ; and * iii ) * the dependencies on @xmath275 with preliminary @xmath276 on @xmath277 , respectively .",
    "a returned result is either infeasible , or a md  with threshold pattern on the given @xmath36 , for example , one of the result returned by real experiment on _ cora _ is : @xmath278 with @xmath279 and @xmath280 both greater than the specified requirements of @xmath39 and @xmath40 respectively .",
    "[ [ exact - approach - evaluation ] ] exact approach evaluation + + + + + + + + + + + + + + + + + + + + + + + + +    first , we evaluate the performance of pruning by support ( eps ) compared with the original exact algorithm ( ea ) . as shown in ( a ) and ( b ) in figure  [ exp_eps_time_cite ] , [ exp_eps_time_cora ] and [ exp_eps_time_rest ] , the ea , which verifies all the possible candidates , should have the same cost no matter how @xmath39 and @xmath40 set .",
    "therefore , the time cost of ea  in ( a ) is exactly the same as that in ( b ) in all three data sets .",
    "moreover , the eps  achieves significantly lower time cost in all the statistical distributions , which is only about @xmath281 of that of the ea .",
    "these results demonstrate that our eps  approach can prune most of candidates without costly computation .",
    "note that the time costs of approaches increase linearly with data sizes , which shows the scalability of discovering mds  on large data .    to observe more accurately",
    ", we also plot the eps  time cost in figure  [ exp_advanced_time_cite ] , [ exp_advanced_time_cora ] and [ exp_advanced_time_rest ] with the same settings respectively . according to the pruning strategy ,",
    "the epsperformance is only affected by support requirement @xmath39 .",
    "in other words , different @xmath40 settings take no effect on eps .",
    "thus , eps  has similar time costs in figure  [ exp_advanced_time_cora ] ( a ) and ( b ) with the same @xmath39 but different @xmath40 .",
    "similar results can be observed in figure  [ exp_advanced_time_rest ] as well .    on the other hand ,",
    "the eps  approach conducts the pruning based on the given requirement of support @xmath39 .",
    "it is natural that a higher @xmath39 turns to the better pruning performance .",
    "therefore , eps  with @xmath282 in figure  [ exp_advanced_time_cite ] ( a ) shows lower time cost , e.g. , about @xmath283s for @xmath284k , than that of @xmath285 in ( b ) , e.g. , @xmath271s for the same @xmath284k . similar results with different @xmath39 are also observed on _ cora _ and _ restaurant _ , which are not presented due to the limit of space .    [",
    "[ advanced - approach - evaluation ] ] advanced approach evaluation + + + + + + + + + + + + + + + + + + + + + + + + + + + +    now , we report the performance of advanced pruning and approximation techniques in figure  [ exp_advanced_time_cite ] , [ exp_advanced_time_cora ] and [ exp_advanced_time_rest ] , including the pruning by both support and confidence ( epsc ) , the approximation together with pruning by support ( aps ) , and the approximation individually together with pruning by support ( apsi ) .",
    "first , we study the influence of @xmath40 in different approaches .",
    "when the confidence requirement @xmath40 is high , e.g. , in figure  [ exp_advanced_time_cora ] ( b ) and [ exp_advanced_time_rest ] ( b ) , the epsc  can remove those low confidence candidates and shows better time performance than other approaches . on the other hand , when @xmath40 is small , e.g. , @xmath286 , we can have larger choices of @xmath287 such as @xmath288 in figure  [ exp_advanced_time_cora ] ( a ) and [ exp_advanced_time_rest ] ( a ) .",
    "thus , the approximation approaches have lower time cost , especially the apsi . according to this analysis ,",
    "we can choose epsc  in practical cases if the requirement @xmath40 is high ; otherwise , the apsi  is preferred in order to achieve lower time costs .",
    "according to the bound condition of approximation approaches in theorem  [ the_approx ] , not only @xmath227 , but also the @xmath39 affects the performance .",
    "as presented in figure  [ exp_advanced_time_cite ] ( a ) , a higher @xmath39 contributes a larger bound condition , which means the early termination of the program .",
    "thus , approximation approaches show better performance in figure  [ exp_advanced_time_cite ] ( a ) , having @xmath289 , compared with figure  [ exp_advanced_time_cite ] ( b ) , whose @xmath290 .    note that the bound condition also depends on the distribution features",
    ". a preferred distribution with more tuples in @xmath192 can achieve the bound condition and terminate early , such as @xmath291k in figure  [ exp_advanced_time_cora ] ( a ) with low time cost .",
    "finally , we evaluate the approximate confidence and support of the returned mds  with @xmath288 on both two datasets in figure  [ exp_md_apprx_confidence ] and [ exp_md_apprx_support ] .",
    "as we proved in lemma  [ lemma_md_appx_bound ] , the error introduced in approximation approaches is bounded by @xmath227 on both confidence and support .",
    "therefore , in figure  [ exp_md_apprx_confidence ] and [ exp_md_apprx_support ] , the approximate confidence and support of aps  and apsi  are very close to those of exact algorithms .",
    "consequently , the approximate algorithm can achieve low time cost ( e.g. , in figure  [ exp_advanced_time_cora ] ( a ) , [ exp_advanced_time_rest ] ( a ) and [ exp_advanced_time_cite ] ( a ) with the same setting of @xmath227 ) without introducing large variation in the confidence and support measures compared with the exact ones .    [ [ summary ] ] summary + + + + + + +    the experiment results demonstrate that our pruning and approximation techniques can significantly improve the efficiency of discovering mds . * i ) * the time costs of approaches increase linearly with data sizes , which shows the scalability of discovering mds  on large data .",
    "* ii ) * the eps  approach can significantly reduce the time costs by pruning candidates , compared with the ea .",
    "* iii ) * if the minimum confidence requirement @xmath40 is high , the pruning by confidence works well . *",
    "iv ) * otherwise , we can employ the approximation approaches to achieve low time cost .",
    "in this paper , we study the discovery of matching dependencies .",
    "first , we formally define the utility evaluation of matching dependencies by using support and confidence .",
    "then , we introduce the problem of discovering the mds  with minimum confidence and support requirements .",
    "both pruning strategies and approximation of the exact algorithm are studied .",
    "the pruning by support can filter out the candidate patterns with low supports .",
    "in addition , if the minimum confidence requirement is high , the pruning by confidence works well ; otherwise , we can employ the approximation approaches to achieve low time cost .",
    "the experimental evaluation demonstrates the performance of proposed methods .    since this is the first work on discovering the matching dependencies , there are many aspects of work to develop in the future .",
    "for example , although the current approach can exclude the attributes that are not necessary to a md , another issue is to minimize the number of attributes in the md . however , the problem of determining attributes for fds  is already hard  @xcite , where the matching similarity thresholds are not necessary to be considered .",
    "moreover , two different mds  may cover different dependency semantics , which leads us to the problem of generating mds  set . rather than a single md ,",
    "the utility evaluation of a mds  set is also interesting",
    ". finally , and most importantly , more exiting applications of mds  are expected to be explored in the future work . finally , along the same line as evaluating fds  @xcite ,",
    "the mds  utility can also be measured by the smallest number of tuples that would have to be removed from the relation in order to eliminate all violations ."
  ],
  "abstract_text": [
    "<S> the concept of _ matching dependencies _ ( mds ) is recently proposed for specifying matching rules for object identification . </S>",
    "<S> similar to the functional dependencies ( with conditions ) , mds  can also be applied to various data quality applications such as violation detection . in this paper </S>",
    "<S> , we study the problem of discovering matching dependencies from a given database instance . </S>",
    "<S> first , we formally define the measures , support and confidence , for evaluating utility of mds  in the given database instance . </S>",
    "<S> then , we study the discovery of mds  with certain utility requirements of support and confidence . </S>",
    "<S> exact algorithms are developed , together with pruning strategies to improve the time performance . since the exact algorithm has to traverse all the data during the computation </S>",
    "<S> , we propose an approximate solution which only use some of the data </S>",
    "<S> . a bound of relative errors introduced by the approximation is also developed . </S>",
    "<S> finally , our experimental evaluation demonstrates the efficiency of the proposed methods . </S>"
  ]
}