{
  "article_text": [
    "over the last four decades , radial basis functions ( rbfs ) have been successfully applied to ( scattered ) data interpolation / approximation in @xmath1 ( see , e.g. , @xcite and the references therein for a literature review ) .",
    "the interest on kernel - based and , in particular , on rbf interpolants can be traced in their ability to produce global interpolants of user - defined smoothness without the shortcomings of multivariate polynomial interpolation .",
    "these interpolants admit generally good convergence properties and they can be implemented in ( essentially ) dimension - independent fashion , making them potentially attractive for a number of applications .    despite the above attractive properties",
    ", rbf interpolation can be cumbersome in practice . solving the resulting linear system is challenging due to both the density and the ill - conditioning of the resulting interpolation matrix ( see , e.g. , @xcite ) .",
    "a number of techniques have been proposed to deal with the ill - conditioning of the interpolation system .    for smooth basis functions such as the gaussian and the multiquadric ,",
    "the ill - conditioning depends crucially on a width parameter .",
    "novel qr - based algorithms which eliminate the ill - conditioning problem for thousands of points have been developed @xcite .",
    "an alternative family of methods , where small local problems are solved which generate approximate cardinal functions has also been proposed @xcite .",
    "the matrix associated with such an approach is much better conditioned , and allows for rapid solution using iterative methods .",
    "finally , in @xcite , a stable interpolation algorithm on carefully selected nodes for gaussian basis functions is given .",
    "the introduction of rbfs with compact support @xcite aims to address the density issue of the interpolation matrix .",
    "moreover , a number of techniques have been developed to reduce the complexity of calculating the interpolant , involving multipole type expansion for a variety of rbfs @xcite .",
    "using such methods is possible to compute an rbf interpolant with @xmath3-computations for quasi ",
    "uniform data , where @xmath4 is the number of data sites though , to the best of our knowledge , we are not aware of any methods which guarantee a bounded number of iterations independently of @xmath4 .    thus , the complexity of kernel - based interpolation remains a challenge when @xmath5 , as the number of data points is required to grow exponentially with respect to the dimension @xmath0 to ensure good convergence rates .",
    "it is not surprising , therefore , that the use of rbfs in practice has been largely limited to tens of thousands of data sites , which , in turn , has restricted their application to low @xmath0 , typically @xmath6 or @xmath7 .",
    "this work is concerned with the introduction of a kernel - based interpolation method on structured or mildly unstructured data sites , which aims to address the computational complexity issues of rbf interpolation for @xmath8 , while simultaneously reducing the ill - conditioning of the resulting interpolation problem .",
    "the new scheme , termed _ multilevel sparse kernel - based interpolation _ ( mlski ) , is based on a hierarchical decomposition of the data sites , whereby at each level the detail is added to the interpolant by interpolating the resulting residual of the previous level . on each level , anisotropic radial basis functions are used for solving a number of small interpolation problems , which are subsequently linearly combined to produce the interpolant ; the new method can be viewed as an extension of ( and , indeed , it has been inspired from ) the idea of @xmath0-boolean interpolation @xcite to kernel - based functions , which , in turn , is closely related to ideas in sparse grid @xcite and hyperbolic crosses @xcite literature .",
    "we note that in  @xcite hyperbolic cross products of one dimensional rbfs have been considered .",
    "the hierarchical multilevel framework used to achieve accelerated convergence is relatively standard in the rbf literature .",
    "in the simplest setting , the mlski algorithm assumes that the data sites are on a cartesian uniform grid of size @xmath9 in @xmath10 , with @xmath11 , for a final level @xmath12 . for each level @xmath13 of the mlski algorithm",
    ", we construct a _",
    "sparse kernel - based interpolant _ of the interpolation residual as follows .",
    "we consider @xmath14 carefully chosen subsets of the data points of level @xmath15 , each subset having size @xmath16 data points . on each of these subsets , which we shall refer to as _ partial grids _ , we solve the interpolation problem .",
    "as the partial grids are anisotropic in nature , we employ appropriate anisotropically scaled kernels ( anisotropic rbfs @xcite ) for each interpolation problem on each partial grid .",
    "once all the @xmath14 interpolants on the partial grids have been computed they are linearly combined to give the total interpolant ( of the residual ) for level @xmath15 .",
    "hence , the complexity of the resulting mlski algorithm is dominated by the complexity of the last step , i.e. , one needs to solve @xmath17 interpolation problems of size @xmath18 and linearly combine the resulting interpolants on the partial grids .",
    "this , in turn , implies that the mlski algorithm admits ( at least theoretically ) @xmath19-complexity , where @xmath18 is the number of grid points in _ each _ direction , and @xmath20 is the complexity of the univariate @xmath18-point algorithm .",
    "the computation of each interpolant on the partial grids is completely independent from the other interpolants on each level @xmath15 .",
    "therefore , the mlski algorithm is ideally suited for implementation on parallel computers .",
    "the mlski algorithm is tested in practice for a number of relevant test cases with @xmath21 .",
    "the numerical experiments suggest that mlski is numerically stable in practice and efficient for the reconstruction of large data in @xmath1 , for @xmath2 , with hundreds of thousands of data points .",
    "also , mlski appears to be generally superior over classical radial basis function methods in terms of complexity , run time and convergence , at least for large data sets .",
    "the remaining of this paper is organized as follows . in section [ sec2 ]",
    ", we discuss anisotropic versions of radial basis functions , suitable for interpolation on data sites with anisotropic characteristics . in section  [ sec3 ]",
    ", we introduce the sparse kernel - based interpolation method , which will be used in section  [ sec4 ] at each level of the multilevel algorithm .",
    "the stability and implementation of the mlski algorithm is discussed in section  [ sec5 ] .",
    "a series of numerical experiments is given in section  [ sec6 ] , for @xmath0 = 2 , 3 , 4 . in section  [ sec7 ] , we draw some conclusions on the new developments presented in this work and discuss possible extensions .",
    "[ sec : anisotropic radial basis functions interpolation ] radial basis functions are radially symmetric by construction having hyper - spheres as their level surfaces .",
    "however , interpolation of data with anisotropic distribution of data sites in the domain requires special consideration . to this end ,",
    "anisotropic radial basis functions ( arbfs ) have been introduced and used in practice  @xcite ; they are also known as elliptic basis functions as they have hyper - ellipsoidal level surfaces .",
    "[ def : anisotropic radial basis functions ] let @xmath22 be a given rbf centred at @xmath23 and let @xmath24 be an invertible matrix .",
    "the anisotropic radial basis function @xmath25[varphia ] is defined by @xmath26 .    evidently , @xmath27 when @xmath28 is the @xmath29-identity matrix . in figure",
    "[ fig : gaussiananisotropic ] , the gaussian rbf and the corresponding anisotropic gaussian rbf centred at @xmath30 for @xmath31 are drawn .",
    "( here , we use the notation @xmath32 for a diagonal matrix with diagonal entries are given by the components of the vector @xmath33 . )",
    ".,width=377,height=188 ]    we now discuss the the solution of an anisotropic interpolation problem .",
    "we restrict the discussion to positive definite kernels , which will be used later , though anisotropic versions of conditionally positive definite rebs is completely completely analogous .    for data sites",
    "@xmath34 contained in a computational domain @xmath35 , we consider the interpolation data @xmath36 .",
    "let @xmath37 be a positive definite radial function and @xmath38 be a chosen invertible matrix .",
    "then , the anisotropic rbf interpolant @xmath39 is defined by : @xmath40 for @xmath41 such that the interpolation conditions @xmath42 , @xmath43 , are satisfied .",
    "the well - posedness of the interpolation problem is guaranteed ( for positive definite kernels ) as a direct consequence of the invertibility of the scaling matrix @xmath28 .",
    "we refer to  @xcite for the error analysis of anisotropic rbf interpolation .",
    "we describe the basic _ sparse kernel - based interpolation _ ( ski ) method that will be used in each step of the multilevel algorithm . the ski method can be used also as a single step interpolation method .",
    "the starting point is the observation that , assuming sufficient smoothness of the interpolation data , the number of points required to provide a given accuracy can be dramatically reduced when basis functions with carefully constructed direction - wise anisotropic scaling are used . this way , notwithstanding the approximation strength coming from a few directions",
    "only , there is only negligible loss of accuracy , due to the additional smoothness assumed .",
    "hyperbolic cross products and sparse grids use this idea in the context of high dimensional numerical quadrature , approximation and in numerical solution of partial differential equations .    in  @xcite",
    ", hyperbolic crosses of tensor products of one - dimensional rbfs have been considered without numerical assessment of the resulting method .",
    "the use of non - tensor product @xmath0-dimensional rbfs in the hyperbolic - cross / sparse - grid setting is not straightforward , as such approximation spaces are characterised by basis functions with differently anistropic scalings in different directions . using such scalings",
    "would _ not _ guarantee the well - posedness of the resulting kernel - based interpolation problem .",
    "an alternative approach can be motivated by the , so - called , @xmath0-boolean interpolation @xcite or , the related combination technique @xcite , for piecewise polynomial interpolation on sparse grids . a key point in this approach",
    "is that the piecewise polynomial interpolant is equivalent to a linear combination of interpolants constructed on a carefully selected collection of subsets of the ( anisotropic ) basis functions .",
    "each such subset consists of translations of the _ same _ ( anisotropic ) basis function .    to construct the sparse kernel - based interpolant ,",
    "we solve a number of anisotropic radial basis function interpolation problems on appropriately selected sub - grids and we linearly combine the resulting partial interpolants to obtain the sparse kernel - based interpolant .    more specifically ,",
    "let @xmath44 @xmath45 @xmath46^{d}$ ] , and let @xmath47 .",
    "the extension to general axiparallel domains is straightforward ; we refrain from doing so here in the interest of simplicity of the presentation only .",
    "comments on possible extensions to more general domains will be given in section [ sec7 ] .",
    "for a multi - index @xmath48 , we define the family of directionally uniform grids @xmath49 , in @xmath50 , with meshsize @xmath51 .",
    "that is , @xmath52 consists of the points @xmath53 , with @xmath54 , for @xmath55 , @xmath56 .",
    "the number of nodes @xmath57 in @xmath52 is given by @xmath58 if @xmath59 = @xmath60 for",
    "all @xmath61 @xmath52 is the uniform _ full grid _ of level @xmath62 , having size @xmath18=@xmath63 ; this will be denoted by @xmath64 .",
    "we also consider the following subset of @xmath64 , @xmath65 with @xmath66 , which will be referred to as the _ sparse grid of level @xmath62 in @xmath0 dimensions_. we refer to figure [ fig : sparse grid def ] for a visual representation of for @xmath67 and @xmath68 .",
    "notice that there is some redundancy in this definition as some grid points are included in more than one sub - grid .",
    "m1.8cmm0.1cmm1.6cmm0.1cmm1.6cmm0.1cmm1.6cmm0.1cmm1.6 cm   via . ,",
    "title=\"fig:\",width=83 ] & = & via .",
    ", title=\"fig:\",width=75 ] & @xmath69 & via .",
    ", title=\"fig:\",width=75 ] & @xmath69 &   via .",
    ", title=\"fig:\",width=75 ] & @xmath69 &   via .",
    ", title=\"fig:\",width=75 ]    we want to evaluate the interpolant at the constituent sub - grids @xmath52 .",
    "as the constituent grids admit different density in each coordinate direction , we shall make use the anisotropic rbfs from section [ sec2 ] . to this end , for each multi - index @xmath70 , we define the transformation matrix @xmath71 by @xmath72    the anisotropic rbf interpolant @xmath73 of @xmath74 at the points of @xmath52 is then defined by @xmath75 for @xmath76 , where @xmath77 are chosen so that the interpolation conditions @xmath78 are satisfied .    to construct the _ sparse kernel - based interpolant _",
    "( ski , for short ) @xmath79 on the sparse grid @xmath80 , the sub - grid interpolants @xmath73 are linearly combined using the formula @xmath81 the combination formula   has been used in the context of @xmath0-boolean lagrange polynomial interpolation  @xcite , and in the combination technique for the numerical solution of elliptic partial differential equations using the finite element method on sparse grids  @xcite . for @xmath68 , becomes @xmath82 that is , the first term on the right - hand side of gives the sum of interpolants on the sub - grids of level @xmath83 , while the second term on the right - hand side of subtracts the redundant points visited more than once .",
    "we refer to figure [ fig : sparse grid def2 ] for an illustration when @xmath68 and @xmath67 .",
    "m1.8cmm0.1cmm1.6cmm0.1cmm1.6cmm0.1cmm1.6cmm0.1cmm1.6 cm   interpolant on @xmath84.,title=\"fig:\",width=83 ] & = & interpolant on @xmath84.,title=\"fig:\",width=75 ] & @xmath85 & interpolant on @xmath84.,title=\"fig:\",width=75 ] & @xmath85 &   interpolant on @xmath84.,title=\"fig:\",width=75 ] & @xmath85 &   interpolant on @xmath84.,title=\"fig:\",width=75 ] + & @xmath86 & interpolant on @xmath84.,title=\"fig:\",width=75 ] & @xmath86 &   interpolant on @xmath84.,title=\"fig:\",width=75 ] & @xmath86 &   interpolant on @xmath84.,title=\"fig:\",width=75 ] &    hence , ski uses a dimension - wise multilevel decomposition of interpolation data sites in conjunction with the application of kernel - based interpolants @xmath87 with different scaling in each direction .",
    "the sparse kernel - based interpolant @xmath88 can be implemented in a quite straightforward fashion by utilising existing , fast , rbf interpolation algorithms : the only modification needed is the introduction of a scaling for each sub - grid problem .",
    "we note that each interpolation problem can be solved completely independently , rendering the resulting ski method ideally suited for implementation in parallel computers .",
    "moreover , we observe the size of each sub - grid problem is @xmath89 , where @xmath62 is the number of levels , i.e. , it is _ independent _ of the dimension @xmath0 .",
    "one has to solve @xmath17 such sub - grid problems to obtain the sparse kernel - based interpolant .",
    "observe that @xmath89 is the number of points of the corresponding full grid @xmath90 in _ each _ space direction .",
    "hence , if the rate of convergence for the ski algorithm is comparable with the one of the standard rbf algorithm for a sufficiently large class of underlying functions @xmath74 , the benefits in complexity are potentially significant , especially for @xmath8 . indeed , when the underlying function @xmath74 is assumed to admit sufficient regularity ( e.g. , if the regularity of @xmath74 is characterised by anisotropic sobolev spaces ) @xcite and @xcite the rate of convergence on sparse grids for tensor - product of piece - wise polynomials and of one - dimensional rbfs , respectively , is shown to be optimal ( modulo a logarithmic factor ) .",
    "although , there is no general proof at this point that this is also the case for the ski method presented here , numerical experiments presented below show that for the multilevel version of the ski algorithm , described in the next section , good convergence results are also observed .",
    "we finally remark that for the case of gaussian interpolation , due its tensor - product nature , the theoretical results of @xcite on tensor - product one - dimensional sparse rbf interpolation should be applicable to the case of ski also .",
    "multilevel methods for rbfs   combine the advantages of stationary and non - stationary interpolation , aiming to accelerate convergence and to improve the numerical stability of the interpolation procedure .",
    "the basic idea of multilevel methods in this context is to interpolate the data at the coarsest level , and then update by interpolating the residuals on progressively finer data sets using appropriately scaled basis functions .",
    "the setting of ski is naturally suited to be used within a multilevel interpolation algorithm .",
    "indeed , the sparse grids from lower to higher level are nested , i.e. , @xmath91 for @xmath12 ; we refer to figure  [ fig : first six sparse grids in 2d ] for an illustration when @xmath68 .",
    "moreover , each sub - grid interpolant uses appropriately scaled anisotropic basis function with the scaling being proportional to density of the corresponding constituent sub - grid . finally , due to the geometrical progression in the problem size from one sparse grid to the next",
    ", a multilevel algorithm would not affect adversely the attractive complexity properties of ski .    the _ multilevel ski _",
    "( mlski , for short ) algorithm is initialised by computing the ski @xmath92 at the coarsest designated sparse grid @xmath93 and set @xmath94 . then ,",
    "for @xmath95 , we compute @xmath96 to be the sparse grid interpolant of the residual @xmath97 on @xmath98 . the resulting multilevel sparse kernel based interpolant is then given by @xmath99    , @xmath100.,width=321 ]",
    "the numerical stability of rbf interpolation is a challenging issue , due to the ill - conditioning of the respective interpolation matrices in standard bases ; we refer to  @xcite and the references therein for a discussion .",
    "it is , therefore , evident that the numerical stability of ski and mlski algorithms can be assessed by considering the maximum condition number of the constituent sub - grid interpolation problems .",
    "the main factors affecting the conditioning of an rbf interpolation problem are the problem size , the separation distance @xmath101 of the respective data set @xmath102 , given by @xmath103 and the shape parameters of the rbf ( which adjusts the `` strength '' or the support , depending on the type of rbf ) .",
    "the choice of shape parameter and the monitoring of the separation distance require more attention in practice than the problem size , which is of secondary importance  @xcite .",
    "recipes for choosing rbf shape parameters in various contexts have been presented , e.g. , in  @xcite , while the dependence of the stability on the shape has been addressed in  @xcite , where stable algorithms for rbf interpolation with small shape parameters have been proposed .",
    "ski and mlski naturally include scaling adjustment at each level .",
    "so , the condition number of each sub - grid interpolation matrix appears to be ( mildly ) affected by the sub - grid size , as we shall see in section [ sec6 ] .",
    "this is , indeed , a very attractive feature of the ski and mlski algorithms as the growth of degrees of freedom on each sub - grid grows _ independently _ of the problem dimension @xmath0 .    observing that , due to the anisotropy of the scaling matrices @xmath104 , the separation distance on each pulled - back ( multiplied by @xmath105 ) sub - grid is constant with respect to the level @xmath62 .",
    "this suggests that we can use standard heuristics for the choice of shape - parameters for multilevel rbf interpolation ( see , or @xcite for a review ) . in particular , we set @xmath106 for some constant @xmath107 .",
    "extensive numerical experiments presented in @xcite suggest that the choice @xmath108 , gives very small condition numbers at the cost of ( mildly ) lower accuracy of the interpolation problem .",
    "the choice @xmath109 , produces larger but mostly safe condition numbers ( in this work we shall refer to a condition number @xmath110 as being _ safe _ when @xmath111 ) , with the resulting computations admitting good convergence properties . for @xmath109",
    ", we have @xmath112 . for @xmath113 ,",
    "the ill - conditioning gradually increases with @xmath114 , resulting in unstable computations .",
    "we present a collection of numerical experiments for @xmath21 , where the implementation of ski and mlski algorithms is assessed and compared against both the standard rbf interpolation on _ uniform full grids _ and its standard multilevel version ( mlrbf ) ; see , e.g , @xcite for a review .",
    "the algorithm implementation has been performed in matlab@xmath115 on a quad - core 2.67ghz intel xeon x5550 cpu with 12 gb of ram , _ without _ taking advantage of the possibility of parallel implementation of ski or mlski .",
    "the ski / mlski algorithm is able to solve @xmath0-variate interpolation problems on sparse grids up to @xmath116 centers for @xmath117 , and up to @xmath118 centers for @xmath119 , respectively .",
    "the same basic interpolation solver for classical rbf on the same machine could only solve problems of size nearly @xmath120 regardless of the dimension @xmath0 , due to the size of the resulting linear system .",
    "we stress that no attempt has been made to use fast algorithms , e.g. , the fast gauss transform of greengard and strain @xcite for the rbf interpolation problems for either the standard rbf , mlrbf or the ski , mlski algorithms",
    ". the use of fast or stable algorithms for rbf interpolation could be also used within the sub - grid interpolation problems of ski / mlski .",
    "indeed , any modern fast evaluation or numerical stabilization technique in rbf interpolation of a single problem can be incorporated into the ski / mlski framework , possibly substantially improving the results presented here .",
    ".mlski for @xmath121 , @xmath68 , using gaussians with @xmath122 .",
    "error evaluated at @xmath123 halton points . [ cols=\"^,^,^,^,^\",options=\"header \" , ]      we continue by comparing the ski and mlski algorithms with standard rbf interpolation on full grids and with its ( standard ) multilevel version on full grids , henceforth denoted by mlrbf .    in figure",
    "[ f3d ] , the root mean - square error of rbf , mlrbf , ski and mlski , respectively , for @xmath124 , are plotted against the number of data sites @xmath18 and against the computation time ( in seconds ) . for rbf and mlrbf",
    ", @xmath18 denotes the number of data sites on the full grid @xmath90 , whereas for ski and mlski , @xmath18 refers to the number of sparse grid nodes ( i.e. , @xmath125 sgnode ) .",
    "( we note in passing that using standard `` isotropic '' rbf interpolation on sparse grids does not appear to result to a convergent algorithm . )",
    "the choice of the shape parameter is given by with @xmath109 for ski / mlski for all experiments ; the shape parameter for rbf / mlrbf is chosen so as to have comparable condition numbers in all cases .",
    "we observe that rbf / mlrbf interpolation appears to perform better than ski / mlski when the error is plotted against @xmath18 .",
    "the ski / mlski algorithms are , on the other hand , able to calculate larger problems and they do so efficiently in terms of complexity , at least for the case of larger problems .",
    "this is manifested in the rms - error versus computation time plot in figure [ f3d ] .    as discussed in section [ sec3 ] ,",
    "@xmath0-boolean lagrange interpolation using polynomials requires additional smoothness of mixed derivatives in order to ensure the essentially optimal convergence rate . to test the extend to which this is also the case for the mlski algorithm",
    ", we consider the function @xmath126 ^ 3\\to\\mathbb{r}$ ] , with @xmath127 this function does _ not _ posses smooth mixed derivatives of ( arbitrarily ) high order . in figure",
    "[ r3d ] , the root mean - square error of rbf , mlrbf , ski and mlski , respectively , for @xmath128 , are plotted against the number of data sites @xmath18 and against the computation time ( in seconds ) .",
    "somewhat surprisingly , we observe that the mlski algorithm outperforms rbf / mlrbf interpolation both in terms of degrees of freedom and in terms of computational time , at least for larger problems .",
    "next , we turn our attention to the problem of interpolating five - dimensional data , i.e. , @xmath129 .",
    "this is a challenge in practice with known methods : standard rbf interpolation is limited to few tens of thousands of data points .",
    "this , in turn , results to using @xmath130 data points in each coordinate direction , thereby , limiting the resulting approximation quality .",
    "we compare the four interpolation methods on a four - variate version of the franke s function @xmath131 ^ 4\\to\\mathbb{r}$ ] , with @xmath132 as well as the four - variate version @xmath133 of @xmath128 , which is defined completely analogously .",
    "the convergence history , given in figures [ f4d ] and [ r4d ] , respectively , indicates similar behaviour to the three - dimensional case .",
    "the choice in the shape parameter is as in with @xmath109 .",
    "we remark on the favourable complexity of the mlski algorithm compared to rbf / mlrbf as @xmath0 grows .",
    "indeed , the mlski algorithm is able to compute highly accurate interpolants , as large @xmath18 can be achieved using moderate computational time .",
    "it is easy to see that @xmath0-dimensional gaussian kernels are tensor - products of one - dimensional ones .",
    "hence , it is interesting to also consider ski and mlski with non - gaussian kernels .    to this end , we consider the problem of interpolation of @xmath124 using wendland s compactly the supported kernel @xmath134 . in figure [ f3d_we32 ]",
    "the convergence history of the various interpolation methods based on the compactly supported kernel @xmath135 are given .",
    "the choice in the shape parameter is as in with @xmath109 , resulting in safe conditions numbers for all methods .",
    "interestingly , the ski method seems to converge very slowly , while the mlski algorithm appears to perform well .",
    "finally , we consider the problem of interpolation of @xmath136 and @xmath137 using the inverse multiquadric kernel @xmath138 with the above choice of the shape parameter .",
    "the results are given in figures [ f4d_imq ] and [ quad_imq ] , respectively .",
    "again , for the case of @xmath137 the ski methods seems to be performing poorly , compared to the fast convergence of mlski .",
    "a multilevel kernel - based interpolation method , suitable for moderately high - dimensional interpolation problems on carefully structured grids has been proposed .",
    "the key idea is the use of hierarchical decomposition of the data sites with anisotropic radial basis functions used on each level , solving a number of smaller independent interpolation problems .",
    "mlski appears to be generally superior over classical radial basis function methods in terms of complexity , run time and convergence , at least for large data sets when @xmath139 .",
    "it is expected that good convergence can be obtained for @xmath140 also .",
    "currently , the choice of data sets ( sparse grids ) is highly structured .",
    "some preliminary numerical experiments for ski on mildly perturbed sparse grids , presented in @xcite , indicate that the ski method converges with the same rate , albeit with a somewhat larger constant .",
    "perhaps a more robust methodology for extending the applicability of ski / mlski methods to scattered data is the pre - computation of the values on the corresponding sparse grid data sites via local interpolation .",
    "the extension of the ski / mlski method to more general geometries could possibly be handled either by introducing fictitious gridded data sites with suitable data values , taking into account the nature of the data , or by conformally mapping the computational domain @xcite .",
    "the discussion in this work has been confined to strictly positive definite kernels .",
    "the implementation of mlski with conditionally positive definite kernels is subject to ongoing work ; some preliminary results can be found in @xcite .",
    "height 2pt depth -1.6pt width 23pt , _ interpolation of track data with radial basis methods _ , comput .",
    "appl . , 24 ( 1992 ) ,",
    "advances in the theory and applications of radial basis functions .",
    "height 2pt depth -1.6pt width 23pt , _ meshfree approximation methods with matlab _ , vol .",
    "6 of interdisciplinary mathematical sciences , world scientific publishing co. pte .",
    "hackensack , nj , 2007 . with 1 cd - rom ( windows , macintosh and unix ) .                      ,",
    "_ on the parallelization of the sparse grid approach for data mining _ , in large - scale scientific computations , third international conference , lssc 2001 , sozopol , bulgaria , s.  margenov , j.  wasniewski , and p.  yalamov , eds .",
    "2179 of lecture notes in computer science , springer , 2001 , pp .  2232 . also as sfb 256 preprint 721 , universitt bonn , 2001 .          , _ multiscale methods for simulation of turbulent flow _ , in herschel , e , editers , numerical flow simulation , vol .  82 of notes on numerical fluid mechanics and multidisciplinary design , springer - verlag , 2003 , pp .",
    "203214 .",
    ", _ hierarchical scattered data filtering for multilevel interpolation schemes _ , in mathematical methods for curves and surfaces ( oslo , 2000 ) , innov .",
    "math . , vanderbilt univ",
    ". press , nashville , tn , 2001 , pp .",
    "211221 .                  , _ an algorithm for selecting a good value for the parameter @xmath142 in radial basis function interpolation _ , adv .",
    ", 11 ( 1999 ) , pp .",
    "radial basis functions and their applications .",
    ", _ interpolation on sparse grids and tensor products of nikolskij - besov spaces _ , j. comput .",
    "appl . , 1 ( 1999 ) , pp .",
    "dedicated to professor paul l. butzer on the occasion of his 70th birthday .",
    "height 2pt depth -1.6pt width 23pt , _ numerical solution of variational problems by radial basis functions _ , in approximation theory ix , vol . 2 ( nashville , tn , 1998 ) , innov .",
    "appl . math .",
    ", vanderbilt univ . press ,",
    "nashville , tn , 1998 , pp ."
  ],
  "abstract_text": [
    "<S> a multilevel kernel - based interpolation method , suitable for moderately high - dimensional function interpolation problems , is proposed . </S>",
    "<S> the method , termed _ multilevel sparse kernel - based interpolation _ ( mlski , for short ) , uses both level - wise and direction - wise multilevel decomposition of structured ( or mildly unstructured ) interpolation data sites in conjunction with the application of kernel - based interpolants with different scaling in each direction . </S>",
    "<S> the multilevel interpolation algorithm is based on a hierarchical decomposition of the data sites , whereby at each level the detail is added to the interpolant by interpolating the resulting residual of the previous level . on each level , anisotropic radial basis functions are used for solving a number of small interpolation problems , which are subsequently linearly combined to produce the interpolant . </S>",
    "<S> mlski can be viewed as an extension of @xmath0-boolean interpolation ( which is closely related to ideas in sparse grid and hyperbolic crosses literature ) to kernel - based functions , within the hierarchical multilevel framework to achieve accelerated convergence . </S>",
    "<S> numerical experiments suggest that the new algorithm is numerically stable and efficient for the reconstruction of large data in @xmath1 , for @xmath2 , with tens or even hundreds of thousands data points . </S>",
    "<S> also , mlski appears to be generally superior over classical radial basis function methods in terms of complexity , run time and convergence at least for large data sets .    </S>",
    "<S> kernel - based interpolation , radial basis functions , multilevel , @xmath0-boolean interpolation , sparse grids , hyperbolic crosses .    65f10 , 65n30 , 65n22 </S>"
  ]
}