{
  "article_text": [
    "significance testing for a possible signal in counting experiments centers on the probability that an observed count in a signal region , or one more extreme , could have been produced solely by fluctuations of the background source(s ) in that region .",
    "statisticians refer to this probability as a p - value .",
    "the traditions for calculating signal significance differ between high energy physics ( hep ) and high energy gamma ray astrophysics ( gra ) .",
    "both fields often quote significances in terms of equivalent standard deviations of the normal distributions ( statisticians sometimes refer to this as a z - value ) .",
    "i will present several of the commonly used methods in hep and gra , apply them to examples from the literature , then discuss the results . here",
    "i will concentrate on observed significance , the significance of a particular observation , rather than predictions of significance for a given technique as a function of exposure .",
    "the prediction problem is slightly different , involving the power of the test , or the probability of making an observation at a given significance level .",
    "gra has emphasized simple , quickly - evaluated analytical formulae for calculating z directly ( choosing asymptotically normal variables ) , while hep has typically calculated probabilities ( p - values ) and then translated into a z - value by    @xmath0    @xmath1 + this relation can be written@xcite for large @xmath2 as    @xmath3 + giving a rough dependence of @xmath4 . while more general than the search for a simple formula for z - values , the hep approach loses track of the analytic structure of the problem .",
    "observations in gra typically consist of a count of gamma rays when pointing directly at a potential source , called an on - source count , @xmath5 .",
    "the analogous quantity in hep is the number of counts in a signal region .",
    "the background relevant to an observation of a source is typically estimated in gra by an off - source observation .",
    "the relative exposure of the two observations is denoted by @xmath6 , often less than unity .",
    "then the background count mean s estimate is @xmath7 , its ( poisson ) uncertainty @xmath8 , and thus one derives @xmath9 gra expressions are couched in terms of @xmath10 .",
    "i will also use @xmath11 for compactness .    in hep , sometimes",
    "a side - band method of background estimation is used , rather like in a gra measurement ; or @xmath12 may be estimated as a sum of contributions from monte carlo and data - based side - band estimates , so that often @xmath13 is quoted , where @xmath14 is derived from adding uncertainties in quadrature .",
    "one can use eq.[eq : alpha ] to _ define _ @xmath10 when comparing hep results with gra expressions .",
    "non - integer values for effective @xmath15 result , but usually cause no problems .",
    "many expressions for z are of the form of a ratio of estimates of signal to its variance , where the signal is estimated by @xmath16",
    ". then @xmath17 , where @xmath18 is a variance estimate for @xmath19 .",
    "a standard gra reference@xcite gives as an example ( their equation 5 ) @xmath20 . the authors note that this expression treats @xmath5 and @xmath15 as independent ; this does not consistently calculate @xmath18 under the null hypothesis , @xmath21 and in fact biases against signals for @xmath22 by overestimating @xmath18 .",
    "i have derived a related formula , @xmath23 , by using only the background to estimate the mean and variance : while not optimal , it at least is consistent with the null .",
    "they also provide @xmath24 , which better implements the null hypothesis . however , their widely - used recommendation is likelihood ratio @xmath25 ,    @xmath26 .",
    "+ @xmath27 derives from the standard likelihood ratio test for a composite hypothesis , and wilks theorem , giving its asymptotic normal behavior .",
    "the numerator and denominator likelihoods are each separately maximized : one for a signal + background model , the other for a background - only ( null ) model .",
    "one may instead seek an asymptotically normal variable with nearly constant variance@xcite ,    @xmath28 . + the @xmath29 speeds convergence to normality from the underlying discreteness .",
    "one widely used form is @xmath30 ( sometimes@xcite called the `` signal to noise ratio '' ) .",
    "this entirely ignores the uncertainty in the background estimate .",
    "it is often used for optimizing selection criteria , because of its simplicity .",
    "slightly better is a @xmath31 calculated from the poisson probability p - value :    @xmath32 .",
    "+ here written@xcite in terms of an incomplete @xmath33 function .",
    "@xmath31 still ignores uncertainty in @xmath12 . occasionally one sees substitutions of @xmath34 as a feeble attempt to incorporate the uncertainty in b.    finally",
    ", one may view a significance calculation directly as a p - value calculation which one could use as a test of the null hypothesis .",
    "@xmath27 use the standard ( non - optimal ) test of a composite hypothesis against a null .",
    "however , the relationship of the poisson means , whether @xmath35 , is a special case of a composite hypothesis test that admits a more optimal solution .",
    "there exists a uniformly most powerful test among the class of unbiased tests for this case , in the form of a binomial proportion test for the _ ratio _ of the two poisson means@xcite .",
    "the umpu properties are , strictly speaking , derived only with an assumption of randomization , that is , hiding the underlying discreteness by adding a random number to the data .",
    "this test yields a binomial probability p - value ( using @xmath36 ) :    @xmath37 , + where @xmath38 is the expected ratio of the poisson means for @xmath39 and @xmath40 .",
    "after some manipulation , this can be written in terms of incomplete and complete beta functions@xcite , which is convenient for numerical evaluation :    @xmath41 + this test is conditional on @xmath40 fixed because of the existence of a nuisance parameter : there are two poisson means , but the quantity of interest is their ratio . while this test is known to both the gra@xcite and hep@xcite communities , it is common practice in neither , and its optimality properties are not common knowledge .    given the ( restricted ) optimality of the test , and the lack of a ump test for this class of composite hypotheses , this test ought to be more frequently used to calculate significance , even though it is clearly a longer calculation than @xmath27 .",
    "for moderate @xmath42 , closed forms in terms of special functions are available , while some care is required for larger @xmath43 . for @xmath44 , the z - values reported",
    "may be somewhat too small@xcite , but for typical applications one is more interested in @xmath45 .",
    "it is interesting to note that taking a normal approximation to the binomial test ( that is , comparing the difference of binomial proportion from its expected value , to the square root of its normal - approximation variance ) yields @xmath46 , which can be shown to be identical to @xmath47 .",
    "a different approach attempts to move directly from likelihood to significance by using a 3rd - order expansion@xcite .",
    "the mathematics is interesting , combining two first order estimates ( which give significance to order @xmath48 ) to yield a @xmath49 result . typically , the first - order estimates are of the form of a normal deviation , @xmath50 ( like @xmath51 ) , and a likelihood ratio like @xmath27 ; of these , the likelihood ratio is usually a better first - order estimate .",
    "the two are then combined into the third order estimate by a formula such as + @xmath52 .",
    "+ generically , @xmath53 is a student t - like variable , where @xmath54 is the difference of the maximum likelihood value of @xmath55 ( the parameter of interest ) from its value under the null hypothesis , and @xmath18 is a variance estimate derived from the fisher information @xmath56 .",
    "the attraction of the method is to achieve simple formulae with accurate results .",
    "however , the mathematics becomes more complex@xcite when nuisance parameters are included , as is needed when the background is imperfectly known . here",
    "i will only compare the approximate calculation for a perfectly known background to the corresponding exact calculation , @xmath57 .",
    "hep common practice often involves bayesian methods of incorporating `` systematic '' uncertainties for quantities such as efficiencies@xcite .",
    "these methods are also used for calculating significances , particularly when the background @xmath12 is a sum of several contributions , since the method naturally extends to complex situations where components of @xmath14 are correlated .",
    "the typical calculation represents the lack of knowledge of @xmath12 by a posterior density function @xmath58 ; it is referred to as a posterior density because it is posterior to the off - source measurement @xmath59 .",
    "the usual way of proceeding is to calculate poisson p - values @xmath60 as was done above , but this time taking into account the uncertainty in @xmath12 by performing an average of p - values weighted by the bayesian posterior @xmath58 , that is    @xmath61 + this can be evaluated by monte carlo integration , or by a mixture of analytical and numerical methods .",
    "i will pursue the latter course here .",
    "the most common usage in hep is to represent @xmath58 as a truncated normal distribution    @xmath62 + if @xmath12 is a sum of many contributions , its distribution should asymptotically approach a normal .",
    "an alternative i have advocated in hep@xcite , and which is also known to the gra communitity@xcite , is to start from a flat prior for @xmath12 and derive the @xmath58 in the usual bayesian fashion , leading to a gamma posterior :    @xmath63 .",
    "+ this is most appropriate when a single contribution to @xmath12 dominates and its uncertainty is actually due to counting statistics .",
    "i will refer to the z - values which result from these two choices as @xmath64 for the normal posterior , and @xmath65 for the gamma function posterior . choosing to represent @xmath57 as a sum , and performing the @xmath12 integration first gives the p - value for the gamma posterior@xcite    @xmath66",
    "+ despite appearances , @xmath67 is identical to @xmath68 .",
    "the beta function representation of @xmath68 is much more suitable for large values of @xmath42 .",
    "the two expressions can be made somewhat closer by using @xmath38 .",
    "bayesian practice typically focuses on direct comparison of specific hypotheses through the odds ratio .",
    "however , predictive inference@xcite is commonly used in model checking ( significance testing is just checking the background - only model ) .",
    "predictive inference in our case is directly related to calculating @xmath69 , that is , averaging over the unknown parameter @xmath12 .    @xmath70 + interestingly , some bayesian practitioners go farther , and are willing to calculate a `` bayesian p - value''@xcite ,    @xmath71 + which is precisely the @xmath72 given above ( there we summed before integrating ) .",
    "i have taken several interesting test cases from the hep and gra literature .",
    "the input values and z - value calculation results are shown in table 1 . for the hep cases ,",
    "the values reported in the papers are @xmath5 , @xmath12 , and @xmath14 , while in the gra case , the reported values are @xmath5 , @xmath15 , and @xmath10 .",
    "i have also included a few artificial cases in order to sample the parameter space reasonably .",
    "it is worth remarking that there are numerical issues to be faced in evaluation of the more complex methods .",
    "these remarks apply  at a minimum  to a mathematica implementation .",
    "the binomial is straightforward in its beta function representation .",
    "the bayes p - value methods may involve an infinite sum , and are touchy and slow for large @xmath43 ; @xcite suggests approximating the summation by an integral .",
    "fraser - reid and the bayes p - value summation results may be sensitive to whether integers are floating point values are used .",
    "an alternative attack is to leave the @xmath57 as a @xmath33 function ratio and trade an integration for the infinite sum .",
    "doing so in the bayes gaussian case is less unstable than summing , but for large @xmath43 requires hints on the location of the peak of the integrand .    for the purposes of the present section",
    ", i will take the frequentist umpu binomial ratio test as a reference standard , because of its optimality properties .",
    "i will have more to say on this later .",
    "none of these examples from the recent literature was published with a seriously wrong significance level . to me ,",
    "the most striking result in the table is that the bayes gamma prior method produces results _ identical _ to the binomial result ( msu graduate student hyeongkwan kim has proven the identity ) .",
    "the method most used in hep , bayes with a normal posterior for b , produces z s always larger than those from bayes gamma . viewing the calculation as averaging the poisson p - value @xmath73 over the posterior for @xmath12 ,",
    "the shorter tails of the normal compared to the gamma place less weight on the larger probabilities ( smaller p - values ) obtained when the off - source measurement happens to underestimate the true value of b. the difference is most striking for large values of @xmath10 , that is , when the background estimate is performed with less sensitivity than the signal estimate ; in this case , results differing in significance by over .5 @xmath74 can occur .",
    "the most common method in gra , the simple log likelihood ratio formula , produces comparable or slightly higher estimates of significance , but seems less vulnerable to problems at large @xmath10 .",
    "it appears to claim the highest significance of these methods at small @xmath43 .",
    "the variance stabilization method @xmath75 presented in @xcite does not appear to be in general use in gra , but produces results of similar quality to the other two mainstay methods .",
    "all methods agree for @xmath76 , where the normal approximations are good , even out to 3 - 6 @xmath74 tails .",
    "the `` not recommended '' methods all produce results off by more than .5 @xmath74 for several low - statistics cases .",
    "@xmath51 , which approximates @xmath77 , does best ; @xmath78 is indeed biased against real signals compared to other measures , and its alleged improvement @xmath79 , while curing that problem , overestimates significance as the price for its less efficient use of information compared to @xmath51 .",
    "as expected , ignoring the uncertainty in the background estimate leads to overestimates of the significance .",
    "@xmath80 is much more over - optimistic than an exact poisson calculation , particularly for small @xmath43 , or @xmath81 , where the background uncertainty is most important .",
    "the best that can be said for @xmath80 is that it is mostly monotonic in the true significance , at least as it is typically used ( for comparing two selection criteria with n varying by an order of magnitude at most ) .",
    "the 3rd order fraser - reid approximation is fast and accurate up to moderate @xmath43 , suggesting it is worth pursuing the full nuisance parameter case .",
    "however , the approximation fails for one large @xmath82 , and is very slow for the largest @xmath43 . of the ad - hoc corrections for signal uncertainty ,",
    "none are reliable ; the `` corrected '' poisson calculation is less biased than the un - corrected , but still widely overestimates significance for @xmath81 , and ca nt be used for serious work .",
    "the @xmath83 is nt much better than its `` un - corrected '' version .    to summarize , most bad formulae overestimate significance ( the only exceptions are @xmath78 for @xmath22 and poisson with @xmath84 ) . thus , prudence demands using a formula with good properties .",
    "the binomial test seems best for simple poisson backgrounds . for backgrounds with several components ,",
    "compare bayes mc with @xmath33 or normal posteriors .",
    "& @xcite&@xcite&@xcite&@xcite&@xcite&@xcite & @xcite&@xcite&rms + non = x&4&6&9&17&50&67&200&523 & 167589 & 498426 & 2119449 & + noff = y&5&18.78&17.83&40.11&55&15&10&2327 & 1864910 & 493434 & 23671193 & + @xmath10&0.2&0.0692&0.2132&0.0947&0.5&2.0&10.0&0.167&0.0891&1.000&0.0891 & + @xmath85&1.0&1.3&3.8&3.8&27.5&30.0&100.0&388.6 & 166213 & 493434 & 2109732 & + s = non - b&3.0&4.7&5.2&13.2&22.5&37&100&134.4&1376&4992&9717 & + @xmath86&0.45&0.3&0.9&0.6&3.71&7.75&31.6&8.1 & 121.7 & 702.4 & 433.6 & + @xmath14/b&0.447&0.231&0.237&0.158&0.135&0.258&0.316&0.0207&0.000732&0.00142&0.000206 & + reported p&&.0030&.027&2.0e-06 & & & & & & & & + reported z&&2.7&1.9&4.6&3.0&3.0&&5.9&3.2&5.0&6.4 & +    recommended : & & & & & & & & & & & & + @xmath87binomial&*1.66&*2.63&*1.82&*4.46&*2.93&*2.89&*2.20&*5.93&*3.23&*5.01&*6.40&0 + @xmath88bayes gamma & * 1.66&*2.63&*1.82&*4.46&*2.93&*2.89&*2.20&*5.93&*&*&*&0 + * * * * * * * * * * * * * * * * * * *    reasonable : & & & & & & & & & & & & + @xmath89bayes gauss ( hep ) & 1.88&2.71&1.94&4.55&3.08&_3.44&_2.90&*5.93&*3.23&*5.02&*6.40&.28 + @xmath90 + 3/8&1.93&2.66&1.98&4.22&3.00&3.07&2.39&5.86&*3.23&*5.01&*6.40&.15 + @xmath91l ratio ( gra)&1.95&2.81&1.99&4.57&3.02&3.04&2.38&*5.93&*3.23&*5.01&*6.41&.14 + not recommended : & & & & & & & & & & & & + @xmath92&_2.24&_3.59&2.17&_5.67&3.11&*2.89&*2.18&6.16&*3.23&*5.01&*6.41&.52 + @xmath93&1.46&_1.90&1.66&_3.17&2.82&3.28&_2.89&_5.54&*3.22&*5.01&*6.40&.93 + @xmath94&_2.74&_3.99&_2.42&_6.47&_3.50&_3.90&_3.02&6.31&*3.23&*5.03&*6.41&.53 + ignore @xmath14 : & & & & & & & & & & & & + @xmath95poisson : ignore @xmath14&2.08&2.84&2.14&4.87&_3.80&_5.76&_7.72&_6.44&3.37&_7.09&6.69&1.9 + @xmath96fraser - reid @xmath97&2.07&2.84&2.14&4.87&_3.80&_5.76&_(8.95)&_6.44&3.37&6.09&6.69&2.2 + @xmath98&_3.00&_4.12&_2.67&_6.77&_4.29&_6.76&_10.00&_6.82&3.38&_7.11&6.69&2.9 + unsuccessful hacks : & & & & & & & & & & & & + poisson : nb @xmath99 b +",
    "@xmath14&1.56&2.46&1.64&*4.47&3.04&_4.24&_5.51&6.01&3.07&_6.09&*6.39&1.1 + s / @xmath100 & _ 2.49&_3.72&_2.40&_6.29&_4.03&_6.02&_8.72&_6.75&3.37&_7.10&6.69&2.4 + _ _ _ _ _ _ _ _ _ * _ _ _ * _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * * * _ _ _ _ _ _ _ * * * _ _ _ _ * * * * * _ _ _ * * * * * * * * * * * _ _    [ results ]",
    "in the previous section , results of significance calculations were compared to a reference calculation , the umpu binomial test .",
    "that method produces the lowest reported significance among the methods with a sound theoretical basis .",
    "this alone could justify its use ( on grounds of conservatism)@xcite , but would beg the question of whether the binomial test is actually `` correct . ''",
    "this has been studied by monte carlo simulation , identical to @xmath51 , but described as having different deviations from the true mc result .",
    "if the z s were , by coincidence , identical , this might be an instance of the measure - dependence described below .",
    "alas , the paper was published without the mc comparisons figures . ] in @xcite .",
    "a few observations on mc testing are useful .",
    "one might imagine simply generating instances of poisson variables @xmath101 with means @xmath102 , and calculating @xmath103 from @xmath104 the fraction of events `` more signal - like '' than @xmath105 . instead , @xcite a separate mc is done _ for each individual measure _ , because there is no unique `` correct '' z - value for a given observation .",
    "the best that can be done is to ask that a method produce a z value consistent with mc probabilities when the observation is analyzed by that method .",
    "the problem is that there is no unique definition of `` more signal - like '' .",
    "one is essentially trying to find a unique ordering of points on the @xmath106 plane to define those which are similarly far from the observed point @xmath107 .            for small @xmath43 ,",
    "the contours are markedly different , so that two _ different _ z - values could both be correct if each agreed with their respective @xmath103 .",
    "still , the situation is not catastrophic , as values of @xmath82 are not wildly different , and presumably the @xmath103 differ somewhat less than the reported values in table 1 . for larger @xmath43 ,",
    "the contours become straighter and more similar , and more importantly , the probability becomes more peaked , so that a smaller region contributes .",
    "thus , the central limit forces convergence to a unique @xmath82 value for large @xmath43 .    although monte carlo studies can never explore the entire parameter space , the general conclusion of @xcite is that @xmath77 is the best of the alternatives .",
    "@xmath77 is only slightly conservative for @xmath111 .",
    "there , @xmath68 is a bit larger than @xmath112 and thus @xmath113 by @xmath114 or less on the z scale when @xmath115 , and @xmath77 performs even better for larger @xmath43 .",
    "they found the deviations of other methods from @xmath103 are typically larger .",
    "they also cite work@xcite which finds larger fractional deviations causes the differences from monte carlo . ] for @xmath77 for smaller z. since @xmath111 is the lower edge of the region where claims are liable to be made , and the degree of conservatism is small , this would also justify accepting @xmath77 as the reference standard , and as the recommended method of evaluating significance when there is any concern about the validity of other methods  at least when a single counting uncertainty dominates the knowledge of the background .",
    "the author wish to thank lanl for hospitality and financial support during his sabbatical , milagro and d0 colleagues for information and references , and tom loredo for reference @xcite .",
    "this work was supported in part by nsf contract nsf0140106 .",
    "the calculations were performed with the assistance ( mostly ) of _ mathematica_.      abramowitz & segun , handbook of mathematical functions , dover ( 1968 ) li & ma , astroph .",
    "j. 272 ( 1983 ) 314 - 324 zhang & ramsden , exp .",
    "astro . 1 ( 1990 ) 145 - 163",
    "babu & feigelson , astrostatistics ( 1996 ) , chapman & hall lehman , testing statistical hypotheses , 2nd edition , wiley ( 1986 ) stuart & ord , kendall s advanced theory of statistics , vol 1 & 2 james & roos , nuc phys b172 ( 1980 ) 475 - 480 dagostino et .",
    "al , am . statistician ( 1988 ) 198 fraser , `` statistical inference : likelihood to significance '' , jasa 86 ( 1990 ) 258 - 65 fraser , reid , & wu , ftp://utstat.toronto.edu/ pub / reid / research / general/196rev3.ps.z cousins & highland , nim a320 ( 1992 ) 331 conferences.fnal.gov/cl2k/copies/linnemann1.pdf alexandreas et .",
    "al . , nim a328 ( 1993 ) 570 - 577 gelman , carlin , stern , & rubin , bayesian data analysis , chapman & hall ( 1998 ) artificial case suggested by an example in @xcite abe et .",
    ", prl 74 ( 1995 ) 2626 - 31 : top quark : ( hep cdf collab . ;",
    "i chose one of many results ) abachi et .",
    "al . , prl 74 ( 1995 ) 2422 - 6 : top quark : ( hep d0 collab . )",
    "abachi et .",
    "al . , prl 74 ( 1995 ) 2632 - 7 : top quark : ( hep d0 collab . )",
    "two artificial examples from @xcite an artificial example with large @xmath10 icrr.u-tokyo.ac.jp/can/symp2002/presentations/ s08-rowell.pdf : cyg .",
    "ob2 ( gra : hegra collab . ) atkins , et al .",
    "( 2003 ) , astroph .",
    "j. , 595 , 803 - 811 : crab pulsar ( gra : milagro collab ) reynolds et .",
    "al . , astroph .",
    "j. 404 ( 1993 ) 206 - 218 : crab pulsar ( gra : whipple collab )"
  ],
  "abstract_text": [
    "<S> i compare and discuss critically several measures of statistical significance in common use in astrophysics and in high energy physics . </S>",
    "<S> i also exhibit some relationships among them . </S>"
  ]
}