{
  "article_text": [
    "stochastic processes are intrinsic to complex physical phenomena that range from stellar dynamics @xcite to epidemiology @xcite .",
    "an important example is stochastic chemical kinetics which describes the time evolution of chemically reacting systems by taking into account the fact that molecules are discrete entities that exhibit randomness in their dynamical behavior .",
    "the transition probabilities of such processes obey the chapman - kolmogorov equation , which in turn is equivalent to the master equation @xcite .",
    "the number of variables in the master equation is large for all but the simplest systems , so analytical or direct numerical integration methods are usually impractical .",
    "alternatively , monte carlo samples of the stochastic process can be numerically generated , via stochastic simulation algorithms ( ssas ) @xcite , so that the only error introduced is the sampling error .",
    "there are a variety of simulation @xcite and approximation @xcite methods available , and the appropriate method will depend on the system and the specific question posed . at one end of the spectrum",
    "is the stochastic simulation algorithm @xcite , which is a method that produces exact random variates from the master equation such that the probability density function can be reconstructed with an error of @xmath0 due to only the sampling error , where @xmath1 is the number of random variates . additionally , there are leaping methods @xcite that accelerate the running time of the stochastic simulation algorithm while also accruing an additional error that is a function of the time - step @xcite or the number of discrete quantities in the system @xcite . at the other end of the spectrum",
    "is the chemical langevin equation , which is a random variate from the fokker - planck equation , and the continuum reaction rate equations that dispense with fluctuations altogether .    in the classical stochastic simulation algorithm @xcite ,",
    "two uniformly distributed random numbers are required per time - step : 1 ) to select which reaction occurs and 2 ) to select the time - step . here",
    "we present a method to reduce the number of random variates needed to compute the time - steps .",
    "the method entails simulating the reactions _ without time _ and computing the final time once a desired state has been reached .",
    "for example , in chemical kinetics , the desired state might be a high concentration of a product .",
    "the distribution of the final time is derived here , as well as an approximation that is useful for simulations .",
    "it is shown that the final time of the simulation can be computed using a much smaller number of random variates .    in section 2",
    "we first review the classical stochastic simulation algorithm , then derive the method . in section 3",
    "we provide results for a simple numerical example and in section 4 we provide concluding remarks on this work . an appendix section is provided that includes the details of the mathematics used in section 2 .",
    "chemical reactions can be written in the form    @xmath2    where @xmath3 is the reaction rate , @xmath4 represents the number of @xmath5 molecules that participate in the reaction , and @xmath6 the number of @xmath5 products .",
    "let @xmath7 be a realization of the stochastic process , where @xmath8 , where @xmath9 denotes an enumeration of every possible state .",
    "the _ stoichiometric vector _ for reaction is @xmath10 so that if the current state is @xmath11 and reaction @xmath12 occurred within @xmath13 , then @xmath14 .",
    "the sample space @xmath9 of this stochastic process can be visualized as an integer lattice @xmath15 , where the dimension @xmath16 is the number of species in the system .",
    "usually the sample space is smaller than the whole of @xmath15 , thus it is @xmath17^d$ ] , where @xmath18 is the total number of particles in the system .",
    "a propensity is defined for a reaction indexed by @xmath12 as @xmath19 where @xmath20 is the probability of a reaction .",
    "intuitively , the product appears in since the collisions of molecules is assumed to be independent , and the factor of @xmath21 is needed so that @xmath22 has units of @xmath23^{-1}$ ] .",
    "the stochastic simulation algorithm ( ssa ) is a monte carlo method for the simulation of chemical reactions .",
    "ssas deal with a realization of the time - dependent stochastic processes , namely a trajectory @xmath8 .",
    "the process is simulated over time by the following update scheme : @xmath24 in the classical formulation of the stochastic simulation algorithm ( ssa ) @xcite , the probability of a reaction @xmath3 with a time - step @xmath25 is chosen from the joint probability density function @xmath26 where the propensities are defined by equation and the total propensity is @xmath27 equation can be decomposed as @xmath28 @xmath29 @xmath30 , where @xmath31 which amount to calculating the time - step in which a reaction occurred and finding the index of the reaction that occurred within said time - step .",
    "the inverse transform sampling method @xcite is used to sample @xmath25 and @xmath3 from equations and .",
    "for instance , @xmath32 where @xmath33 is sampled from a uniform distribution in the range @xmath34 .",
    "solving for @xmath25 yields @xmath35 the value for @xmath36 is the integer for which @xmath37 where @xmath38 is another sample from a uniform distribution in the range @xmath34 .",
    "the algorithm is : @xmath39 .",
    "initialize the time @xmath40 and the system s state @xmath41",
    ".    1 .   with the system in state @xmath42 at time @xmath43 , evaluate all of the propensities @xmath44 ( equation ) and their sum @xmath45 ( equation ) .",
    "2 .   generate values for @xmath25 and @xmath36 where @xmath25 is an exponential random variable with parameter @xmath45 ( equation ) and @xmath36 is a discrete random variable with @xmath46 ( equation ) .",
    "3 .   execute the next reaction by replacing @xmath47 and @xmath48 where @xmath49 is the stoichiometric vector that denotes the change induced by reaction @xmath36 .",
    "record @xmath50 as desired .",
    "return to step 1 , or else end the simulation .",
    "consider the transition from an initial state @xmath51 to the boundary @xmath52 , where @xmath52 could denote a high concentration of a particular product .",
    "the joint probability is @xmath53 since @xmath54 depends on the total propensity of the states at each iteration , we will write this as @xmath55 , where @xmath56 . below we will derive an expression for @xmath55 , which is known as the _ exit time _ or _ hitting time _ of a stochastic simulation .    the derivation will follow the schematic shown in figure [ fig : schematic ]    at each iteration in the stochastic simulation algorithm , we will increment time by sampling from an exponential random variable with a density of @xmath57 . therefore , we are interested in finding the sum of @xmath58 exponential random variables that are sampled from @xmath57 for @xmath59 , where @xmath56 .",
    "we begin by defining the exponential distribution : @xmath60 where @xmath61 and @xmath62 .",
    "we will find the sum of the variables by using the convolution theorem .",
    "let @xmath63 be the sampled time after @xmath58 iterations .",
    "in the stochastic simulation algorithm we have @xmath64 where @xmath1 is the number of monte carlo samples and @xmath65 is a random variate sampled from @xmath66 .",
    "let @xmath67 denote a convolution , then the convolution theorem @xcite states that @xmath68 for the final distribution for the random variate @xmath63 , i.e. @xmath69 .",
    "we begin by transforming equation @xmath70 where we have used laplace s transform in lieu of fourier s since @xmath61 and we have used the convolution property of the transform .",
    "we find that @xmath71 where @xmath72 .",
    "therefore , we can write @xmath73 the analytical expression can be found in two cases : 1 ) if @xmath74 , then ( see appendix section [ subusb : derivationofhypoexponentialdistribution ] ) @xmath75 and 2 ) if @xmath76 , then ( see appendix section [ sec : gammafrequency ] ) @xmath77 which is the erlang ( a.k.a .",
    "gamma ) distribution . in general",
    "the residue theorem ( see appendix section [ sec : residuetheory ] ) could be used to find the inverse laplace transform , but symbolic differentiation would be necessary so this is avoided . since the total propensity will change over time , we are interested in drawing random variates from equation , and we therefore need to find the inverse function",
    ". however , equation has no inverse ( see appendix section [ sec : randomvariatesfrompdf ] ) and , moreover , it is numerically unstable rendering it impractical .      we therefore want to approximate @xmath78 so as to obtain the erlang distribution , i.e. equation .",
    "to illustrate the approximation , we let @xmath79 where @xmath80 is chosen such that @xmath81 and @xmath82 , then ( see appendix section [ sec : approx ] ) @xmath83 where @xmath84 denotes an error on the order of @xmath85 . by grouping together @xmath86s that differ by @xmath87 into disjoint sets ,",
    "we can write @xmath88 where @xmath89 , and each @xmath90 and @xmath91 are chosen according to @xmath87 ( see appendix section [ sec : epsilon ] ) .",
    "therefore , @xmath92      transforming back , we have @xmath93      we want to generate a sample @xmath94 for each trajectory , therefore we sample from the sum of the distributions : @xmath95 where @xmath96 is a random variate from a gamma distribution with a scale parameter of @xmath97 and a shape parameter of @xmath91 , and @xmath1 is the number of monte carlo samples .",
    "we can now simulate a chemical system without time until a desired state has been reached , and use equation to compute the final time of the simulation once we have grouped together the propensities as shown in the appendix section [ sec : epsilon ] .",
    "here we consider the most elementary of nonlinear systems which has been used to model many disparate physical processes ranging from nuclear reactions @xcite to epidemics @xcite : @xmath98 in epidemics , this is the canonical sir model @xcite , upon which more detailed models that include age- and spatially - dependent processes are built .",
    "the reproductive number is defined @xmath99 , and @xmath9 , @xmath100 , and @xmath101 denote the susceptible , infectious , and recovered persons , respectively .",
    "this process models the event in which a susceptible person comes into contact with a infectious person at a rate @xmath102 and results in two infectious persons .",
    "we use @xmath103 yielding @xmath104 , @xmath105 and set the exit condition as @xmath106 , i.e. the exit vector is @xmath107 where the @xmath9 and @xmath100 can take any values .",
    "the initial state is @xmath108 .",
    "we performed @xmath109 samples using an intel core i7 - 2620 m cpu at 2.7ghz and computed the running time in seconds for various values of @xmath87 , the results of which are shown in table 1 . as can be seen , the running time is reduced when @xmath87 takes higher values since this will effectively reduce the number of gamma distributed samples needed to compute the exit time . as @xmath110 ,",
    "the method reduces to the classical stochastic simulation algorithm .",
    ".total simulation running time shown in seconds , @xmath111 denotes the standard simulation algorithm .",
    "[ cols=\"^,^,^,^,^\",options=\"header \" , ]     since increasing @xmath87 will increase the error , we compared the density function of the exit times from the method presented here and the classical simulation algorithm in figure [ fig : pdferror ] .",
    "we have shown the two distributions in the left panel as well as the difference between them on the right .",
    "we note that the exit time method is able to capture the correct distribution .",
    "in addition , we reported the value for @xmath112 which is the number of gamma distributed random variables needed for the exit time method divided by the number of exponential random variables needed for the stochastic simulation algorithm . in figure",
    "[ fig : convergence ] we have plotted convergence with respect to @xmath87 , which is in accord with the error analysis included in the derivation in section 2 .",
    "we note that there is a tapering off in the error which is incident to the monte carlo error becoming larger . in figure",
    "[ fig : speedup ] we have shown the speedup where @xmath113 is the ratio of the number of gamma random variates to the number of exponential random variates .",
    "we note that this is not the speedup of the simulation , but merely for the computation of random numbers .",
    "a original method was presented to compute the exit time for the stochastic simulation algorithm .",
    "the method was based on the addition of a series of random variables and was derived using the convolution theorem .",
    "we derived the final distribution and showed one approximation method .",
    "the result led to a formulation of the stochastic simulation algorithm that requires fewer random variates .",
    "as shown in the results section above for a typical nonlinear model , the error control parameter @xmath87 can be suitably chosen such that the number of random variates needed to resolve the exit time is reduced .",
    "equation has better convergence properties than leaping algorithms since the error is second order whereas leaping algorithms are typically first order , therefore , the monte carlo error will still dominate the total error . while the method is similar to r - leaping @xcite in that the distribution for time is drawn from a gamma distribution ,",
    "it differs in that the propensities are grouped according to their magnitude and the trajectory for the state transitions is exact .",
    "although the number of random variates has been reduced , the bottleneck of the stochastic simulation algorithm is still the re - computation of the propensities at each time - step .",
    "while we report relatively modest speed - up compared to the classical stochastic simulation algorithm , the derivation and application of the method may be beneficial to other areas of algorithmic research .",
    "indeed the derivation is not limited to the stochastic simulation algorithm and in principle could be used in other monte carlo algorithms . if @xmath114 is a sequence of random variables for @xmath59 such that @xmath115 , where @xmath116 is independent of @xmath117 , then the derivation could be used to find an expression for @xmath118 .",
    "the author thanks bill and melinda gates for their active support of this work and their sponsorship through the global good fund .",
    "this appendix is provided for completeness and includes derivations of mathematical results used in the exit time method presented in section 2 .",
    "we begin by attempting to rewrite the product in terms of partial fractions : @xmath119 where @xmath120 must be determined and @xmath121 denotes ` shall be equal to ' .",
    "then , @xmath122 which holds @xmath123 .",
    "if @xmath124 and @xmath125 , then @xmath126 therefore @xmath127 @xmath128 then @xmath129 in order to find the analytical form of the original convolution , we apply the inverse laplace transform , viz . :",
    "@xmath130 the inverse can be found by noting that @xmath131 and therefore @xmath132 .",
    "we use the inversion theorem @xcite to obtain : [ sec : randomvariatesfrompdf ] @xmath134 define the cumulative distribution @xmath135 , then , find @xmath43 such that @xmath136 , where @xmath137 by a root finding method .",
    "the residue theorem @xcite can be used to compute the inverse laplace transform : [ sec : residuetheory ] @xmath144 where @xmath145 is a pole and the complex residue for a pole @xmath145 of order @xmath146 is @xmath147                  initially set @xmath164 @xmath165 and let @xmath166 be the set @xmath167 sorted in descending order .",
    "the procedure is as follows : for @xmath168 , set @xmath169 , where @xmath170 is the first element in the set @xmath166 , and then set @xmath171 and repeat until @xmath172 .",
    "note that @xmath160 need not be known a priori and that @xmath173 is valid ."
  ],
  "abstract_text": [
    "<S> a novel method is presented to compute the exit time for the stochastic simulation algorithm . </S>",
    "<S> the method is based on the addition of a series of random variables and is derived using the convolution theorem . </S>",
    "<S> the final distribution is derived and approximated in the frequency domain . </S>",
    "<S> the distribution for the final time is transformed back to the real domain and can be sampled from in a simulation . </S>",
    "<S> the result is an approximation of the classical stochastic simulation algorithm that requires fewer random variates . </S>",
    "<S> an analysis of the error and speedup compared to the stochastic simulation algorithm is presented . </S>"
  ]
}