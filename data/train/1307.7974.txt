{
  "article_text": [
    "the community - contributed multimedia content in the internet , such as flickr , picasa , youtube and so on , has been exploding . to facilitate the organization of the uploaded images or videos ,",
    "media repositories usually offer a tool to enable consumers to manually assign tags ( a.k.a .",
    "labels ) to describe the media content  @xcite .",
    "these assigned tags are adopted to index the images to help consumers access shared media content .",
    "reliable tagging results in making shared media more easily accessible to the public .",
    "however , the reliability of tagging is not guaranteed in that the tags may be noisy , orderless and incomplete  @xcite , possibly due to carelessness of the taggers .",
    "first , some tags are noises and may be irrelevant to media . according to the statistics in flickr , there are about only @xmath0 tags indeed relevant to photos  @xcite .",
    "second , different tags essentially have different relevance degrees to the media , but such information is not indicated in the current tag list , where the order is given according to the input sequence .",
    "we did an analysis on the msra - tag dataset  @xcite , which was crawled from flickr , about what percentage of images have the most important tags in different positions .",
    "a statistics figure is shown in  fig.[fig : tagexample ] to indicate the result .",
    "it can be observed from this statistics that less than @xmath1 images have the most relevant tags at the top position , which shows that the tags are almost in a random order in terms of the relevance .",
    "last , the tags of some photos are incomplete due to the interest limitation of taggers , and even not given .",
    "we address the problem of refining the tags , to facilitate the access of the shared media . to be specific ,",
    "we investigate the tagging problem in flickr , one of the most popular photo sharing web sites , and propose to reorder the tags .",
    "the available information to refine the tags consists of manual tags and image affinity .    1 .",
    "although they are not completely reliable , the manual tags still reflect the photo content in some degree and their relations can be explored for tag refinement .",
    "existing solutions only make use of the pairwise relation between tags , mined from wordnet  @xcite , or estimated from web photo tags  @xcite .",
    "2 .   visually similar images usually tend to have similar semantics and hence have similar tags , which means that the tag refinement of one image may benefit from those of other images .",
    "the typical exploration  @xcite is to utilize the visual popularity of one image among the images having the same tag as a cue to estimate the relevance of the tag with this image .    in this paper",
    ", we present a novel probabilistic formulation , to estimate the relevance of a tag by considering all the other images and their tags . to this goal",
    ", we propose a novel model called regularized latent dirichlet allocation ( rlda ) , which estimates the latent topics for each document , with making use of other documents .",
    "the model is applicable in tag refinement due to the observation that the content of an image essentially contains a few topics and the reasonable assumption that the tags assigned to the image accordingly form a few groups .",
    "the latent topics are estimated by viewing the tags of each image as a document , and the estimation also benefits from other visually similar images by the regularization term , instead of the estimation by lda only from the corresponding document .",
    "the main contribution of our approach lies in the following aspects .",
    "on the one hand , both lda and rlda explore the multiple - wise relation among tags through the latent topics , rather than pairwise relations in the random walk based methods . on the other hand ,",
    "the tag relevance estimation from rlda can be interpreted using the deep structure  @xcite .",
    "compared with random walk and lda , our approach is the deepest , and the illustration is presented in figure [ fig : illustrationbydeeplearning ] .",
    "the automatic image tagging or annotation problem is usually regarded as an image classification task .",
    "typical techniques  @xcite usually learn a generative / discriminative multi - class classifier from the training data , to construct a mapping function from low level features extracted from the images to tags , and then predict the annotations or tags for the test images .",
    "later , a more precise formulation is presented to regard it as a multi - label classification problem by exploring the relations between multiple labels  @xcite .",
    "the automatic annotation techniques have shown great successes with small scale tags and the well - labeled training data .",
    "but in the social tags , e.g. , image tags on flickr , there exist noisy or low - relevance tags , and the vocabulary of tags is very large , which limits the performance of conventional automatic tagging techniques in social tagging .",
    "the study in  @xcite has shown that classifiers trained with flickr images and associated tags got unsatisfactory performance and that tags provided by flickr users actually contain noise .",
    "moreover , the relevance degrees of the tags , i.e. , the order of the tags , are not investigated in automatic annotation .",
    "various approaches have been developed to refine tags using the available tags and visual information .",
    "the following reviews some closely - related methods , and more discussions can be found from a survey  @xcite .",
    "the straightforward approach directly exploits the tag relation , e.g. , co - occurrence relation mined from wordnet  @xcite , or the internet , and then refines tags  @xcite . for example , the tag ambiguities are resolved  @xcite by finding two tags that appear in different contexts but are both likely to co - occur with the original tag set and then presenting such ambiguous tags to users for further clarification .",
    "the random walk approach over the pairwise graph on the provided tags with edges weighted by the tag similarities is presented in  @xcite .",
    "the visual information is proved very useful to help tag refinement .",
    "for example , the neighborhood voting approach  @xcite is to recommend the tags by exploring the tags of the visually similar images .",
    "the likelihood that a tag is associated with an image is computed in  @xcite from probabilistic models learnt the images assigned with such a tag , and then put it into the random walk framework for further refinement .",
    "a hybrid probabilistic model  @xcite is introduced to combine both collaborative and content based algorithms for tagging , which is similar to  @xcite in using the visual contents .",
    "a rankboost based approach  @xcite is presented to learn a function to combine ranking features from multi - modalities , including tag and visual information .",
    "an optimization framework  @xcite is proposed to perform tag filter and enrichment by exploring visual similarity and additional knowledge from wordnet  @xcite .",
    "an approach  @xcite formulates the tag refinement problem as a decomposition of the user - provided tag matrix into a low - rank matrix and a sparse error matrix , targeting the optimality by low - rank , content consistency , tag correlation and error sparsity .",
    "rather than exploring the pairwise relation among tags , some techniques are proposed to adopt the multiple wise relations among tags , through latent models .",
    "latent topic models , alternatives of latent dirichlet allocation , is adopted  @xcite to learn a generative model from the tags , which then can estimate the posterior probability that a tag is associated with an image .",
    "those methods are limited in lack of capabilities of adopting visual information .",
    "therefore , this paper proposes a novel topic model , called regularized latent dirichlet allocation , to estimate the topic models with exploiting the visual information . the latent topic based models are also justified by the conclusion in  @xcite that these tags assigned to images span a broad spectrum of the semantic space .    from the perspective of the deep learning theory  @xcite ,",
    "the random walk based approaches essentially estimate the tag relevance with a shallow structure , which only consists of two levels , the provided tags as the input level and the tag being considered as the output level .",
    "the lda based approach is with a deep structure , introducing a latent topic level , which has potential to get better performance .",
    "the proposed regularized lda model is deeper , with four levels , the tags associated with other images as the first level , the latent topics of other images and the tags of the image being considered as the second level , the latent topic as the third level , and the tag being considered as the output level .",
    "the relational topic model  @xcite is closely related to the proposed regularized lda .",
    "but they are clearly different because our approach imposes the regularization over the topic distribution instead of the latent variables and moreover our approach deals multiple modalities and makes use of additional visual similarity to formulate the regularization term .",
    "our approach is also different from topic models for image annotation  @xcite : the image tagging problem in our paper is more challenging than image annotation as aforementioned .",
    "and moreover the proposed regularized lda aims to impose the consistency of tags within similar images while they are supervised algorithms  @xcite or aim to find common topics shared by tags and visual contents .",
    "this paper is different from the short version  @xcite because we present a formal derivation of our approach , introduce a new inference approach conduct more experiments , and particularly , we use the deep network structure to analyze the benefit of regularized lda .",
    "the input consists of an image corpus , @xmath2 images @xmath3 , and @xmath2 tag documents @xmath4 , with @xmath5 being the set of tags manually assigned to image @xmath6 . here",
    "@xmath5 is defined , similarly to  @xcite , as a sequence of @xmath7 words denoted by @xmath8 .",
    "@xmath9 represents a word , an item from a vocabulary indexed by @xmath10 , and is a @xmath11-dimensional vector , with only one entry equal to 1 and all the other entries equal to 0 , e.g. , @xmath12 and @xmath13 for @xmath14 if @xmath9 represents the @xmath15-th word .",
    "besides , we use @xmath16 to represent the visual feature of image @xmath6 .",
    "the goal is to reorder the tags in each document , finding reordered tags @xmath17 with @xmath18 being a permutation of @xmath19 , so that the tags on the top are semantically more relevant to the image .    given the image corpus and the associated tag documents , we introduce a term , tag relevance , which is then used to reorder the tags . the tag relevance is inferred based on the joint probability , @xmath20 .",
    "the manually - assigned tags , in some degree , describe the semantic content of an image , although it may contain noise , or not be complete . hence , as a candidate solution , the relevance of each tag can be inferred from these tags .",
    "the joint probability over the tags @xmath21 of image @xmath22 is formulated as a pairwise markov random field ( mrf ) , @xmath23 where @xmath24 is valuated from the tag relation .",
    "this model can be further interpreted by a random walk model .",
    "specifically , a transition probability is defined from the tag relation as @xmath25 here @xmath26 has been normalized such that @xmath27 .",
    "@xmath28 is the similarity between @xmath29 and @xmath30 , and may be computed from wordnet  @xcite or other methods  @xcite .",
    "given this model , the stable distribution of this model , @xmath31 $ ] is then used to evaluate the relevance of each tag .",
    "the visual description of a tag , @xmath32 , can be obtained from a set of images , @xmath33 , associated with that tag .",
    "given an image @xmath34 , the posteriori probability @xmath35 can be computed as follows , @xmath36 where @xmath37 can be estimated by @xmath38 that can be computed using the kernel density estimation  @xcite , e.g. , @xmath39 .",
    "the scheme estimating the density can also be interpreted as the stable distribution of a random walk over the images @xmath40 , where the transition probability is estimated from the kernel @xmath41 . without any bias for any tag",
    ", @xmath42 can be thought as a uniform distribution . to the end",
    ", @xmath43 can be used as the relevance of tag @xmath32 for image @xmath34 .      as a straightforward scheme exploring of both tag and visual cues ,",
    "the relevances from the visual cue can be viewed as observations to the probability model over tags .",
    "denote @xmath44 as the observations of tag @xmath29 , the model can be written as @xmath45 it can also be interpreted as a random walk with restarts .",
    "the transition model is the same to  eqn .",
    "( [ eqn : transitionprobability ] ) , and @xmath44 , first normalized so that @xmath46 , is viewed as the restarts . the resulted approach includes two steps : relevance from visual cue and a random walk with restart over tags .",
    "the solution is essentially the fixed point @xmath47 , where @xmath48 $ ] .",
    "the two - step approach , presented in  @xcite , can be cast into this formulation .",
    "the above formulations actually consider each image independently , and as a result , tag relevances for each image can be estimated separately . in the computation of @xmath38 ,",
    "each image in the set , @xmath33 , is equivalently considered .",
    "in fact , an image is associated with several tags , and accordingly the typicality degree of each image to represent the tag may be different . alternatively , the tag relevance can be jointly estimated by considering a joint probability , @xmath49 where the first term corresponds to the pairwise mrf , and the second term is from the visual constraint and can be viewed as the visual regularization .",
    "@xmath37 , can be furthermore written as @xmath50 , ( viewed as a weighted random walk model ) where @xmath51 is a set of weights , with each corresponding to the typicality degree of each image and estimated as @xmath52 . to the end",
    ", the solution of the approach can be equivalently obtained by solving a fixed point problem , @xmath53 where @xmath54 is a weighted transition matrix , with @xmath55 corresponding to the pairwise probability @xmath56 , @xmath57 and @xmath58 are the observation probability vectors , a column vector and a row vector of @xmath59_{m\\times v } $ ] normalized w.r.t .",
    "image set and tag set , respectively .",
    "the aforementioned approach builds the relationship among the tags , using the pairwise framework , which is lack of the ability to describe the multiple wise relations among tags .",
    "however , we observed that the relation among tags is beyond pairwise and that some tags may have closed relations and the tags associated with one image form several meaningful cliques . to make use of the multiple wise relations , we introduce a topic model to construct the tag relation , which uses latent topic variables to connect the tags for building the multiple wise relationships . moreover , rather than separately building the topic model independently for each image",
    ", we propose a novel approach to jointly model the images together based on the observation that visually similar images should have similar semantic contents , to this goal , we introduce smoothness terms over the latent topics of images .           latent dirichlet allocation ( lda ) is a generative probabilistic model of a corpus , e.g. , a set of documents .",
    "the basic idea is that documents are represented as random mixtures over latent topics , where each topic is characterized by a distribution over tags ( words ) , or intuitively is viewed as a group of soft ( partially weighted ) tags .",
    "lda is a special directed graphical model ( a.k.a .",
    "bayesian network ) , and its graphical representation is shown in  figure  [ fig : lda : lda ] . in this graphical model",
    ", @xmath60 is a topic vector of length @xmath61 , with @xmath61 being the number of latent topics , where it corresponds to the @xmath62 topic if @xmath63 and @xmath64 for @xmath65 .",
    "@xmath66 is a @xmath61-dimensional vector , the parameter of the multinomial distribution .",
    "@xmath67 is the dirichlet parameter , a vector of @xmath61 positive reals .",
    "matrix @xmath68 , of dimension @xmath69 , is used to parameterize the tag - topic probability , where @xmath70 .",
    "it can be interpreted as a generative process for each document @xmath21 as follows .    1",
    ".   choose @xmath71 .",
    "2 .   for each of the @xmath72 tags @xmath73 , 1 .   choose a topic @xmath74 .",
    "2 .   choose a tag @xmath73 from @xmath75 , a multinomial probability conditioned on the topic @xmath76 .    in the graphical representation ,",
    "there are three levels . the parameters @xmath67 and @xmath68 are corpus level parameters , assumed to be sampled once in the generative process for a single corpus .",
    "the variable @xmath66 is a document - level ( image - level ) variable sampled for each document ( image ) . finally , the variables @xmath76 and @xmath73 are word - level ( tag - level ) variables , sampled once for each word in each document .",
    "the goal to use lda here is to mine the latent topic distribution for a given document @xmath21 , @xmath77 .",
    "the topic distribution can be obtained by integrating out other latent variables @xmath78 over the posterior distribution , @xmath79 .",
    "this distribution is intractable to compute in general .",
    "the approximate inference algorithms , e.g. , markov chain monte carlo and variational inference , can be used to tackle this problem .",
    "the variational inference algorithm introduces a variational distribution , @xmath80 where the dirichlet parameter @xmath81 and the multinomial parameters @xmath82 are the free variational parameters .",
    "the variational parameters can be obtained from the following optimization problem : @xmath83 where @xmath84 is the kullback - leibler ( kl ) divergence between the variational distribution @xmath85 and the true posterior @xmath86 .",
    "figure  [ fig : lda : variational ] illustrates this variational distribution .",
    "this minimization can be achieved via an iterative fixed - point method .",
    "the update equations are as follows , @xmath87\\ } \\\\",
    "\\gamma_i & = \\alpha_i + \\sum_{n=1 } ^n \\phi_{ni},\\end{aligned}\\ ] ] where @xmath88 is a function that maps a vector representation of a word to an index in the vocabulary .    in the lda model ,",
    "two model parameters , @xmath67 and @xmath68 , can be estimated from the given corpus of documents , @xmath89 , by maximizing the following log likelihood , @xmath90 here , @xmath91 can be efficiently estimated by an expectation - maximization ( em ) algorithm  @xcite .      given this topic model ,",
    "the relevance of a tag @xmath92 for each image is formulated as the probability conditioned on the set of tags @xmath89 associated with this image .",
    "it is mathematically formulated as @xmath93 the computation of this conditional distribution can be illustrated by a graphical model shown in  figure  [ fig : illustrationbydeeplearning : lda ] . from the analysis",
    ", it can be observed that the relations between tags are built using the latent variables that is beyond the pairwise relation , illustrated in  figure  [ fig : illustrationbydeeplearning : pairwise ] , and can capture the group information .      in the lda model",
    "discussed above , the distribution of topics for each image is estimated separately",
    ". however , the tags associated with one image may be incomplete and noisy .",
    "consequently , the distribution of topics is not well estimated , which influences the relevance of tags .",
    "it is observed that visually similar images usually have the same semantic content . to utilize this property ,",
    "we introduce a regularization term over the semantic content . rather than imposing this over tags directly ,",
    "we impose it over the latent topics because tags are sometimes too ambiguous for specifying a concept , while topics usually have clearly conceptual meanings .",
    "the straightforward solution to impose the regularization over topics is a two - step sequential scheme : first estimate the distribution of topics for each image , and then to smooth the distribution by considering the distributions of visually similar images .",
    "instead , we propose a collective inference scheme to estimate the distribution of latent topics . to this goal",
    ", we build a joint distribution over all the images , called regularized latent dirichlet allocation ( rlda ) .",
    "this joint distribution is shown in figure  [ fig : rlda ] .",
    "different from the latent dirichlet allocation model , the topics over different images are connected by an extra regularization model , which is defined over the topics of a pair of images .",
    "it can be interpreted as a generative process over the documents as follows .    1 .   for each of the @xmath2 documents",
    "@xmath21 1 .",
    "choose @xmath71 .",
    "2 .   for each of the @xmath72 tags @xmath73 , 1 .   choose a topic @xmath74 .",
    "2 .   choose a tag @xmath73 from @xmath75 , a multinomial probability conditioned on the topic @xmath76 .",
    "2 .   for each of the set of document pairs @xmath94 1 .   choose @xmath95 2 .",
    "choose a visual similarity @xmath96 , a gaussian probability conditioned on the latent relation topic @xmath97 .",
    "given the parameters , @xmath67 , @xmath68 , @xmath98 and @xmath99 , the joint distribution is given by @xmath100 \\nonumber\\\\ & \\times \\prod_{d d ' } p(\\boldsymbol{\\tau } | \\boldsymbol{\\theta}_d , \\boldsymbol{\\theta}_{d ' } ) p ( s_{dd ' } | \\boldsymbol{\\tau}_{dd ' } , \\boldsymbol{\\mu } , \\boldsymbol{\\sigma})\\end{aligned}\\ ] ]      the basic idea of the regularization is to align visual similarities with topic similarities between two images . to be specific ,",
    "it is to classify the two images into two categories that show whether the two images have the same semantic content , and to align the classification result from the topic distribution with that from the visual content .",
    "the latent variable @xmath101^t$ ] , called relational indicator , is a @xmath102-dimensional binary - valued vector , @xmath103 .",
    "@xmath104 indicates that the two images are regarded to have the same topics , and otherwise , the two images do not have the same topics .",
    "it satisfies a multinomial distribution , @xmath105 , where @xmath106^t = [ r_{dd'1}~1-r_{dd'1}]^t$ ] .",
    "@xmath107 , the probability of @xmath104 , is defined to describe the similarity between two topics .",
    "in essence , @xmath108^t$ ] reflects the probabilities that the two images are recognized to have the save topics or not .",
    "for example , @xmath109 can be defined as @xmath110^t$ ] , where @xmath111 is a histogram intersection over two topic distributions , @xmath112 and @xmath113 .    in this model , @xmath114 , an observed variable ,",
    "is the visual similarity between two images @xmath115 and @xmath116 .",
    "@xmath117^t$ ] and @xmath118^t$ ] are 2-dimensional vectors , and are used to describe two gaussian distributions , @xmath119 and @xmath120 , which correspond to the conditional probabilities of the visual similarity , conditioned on whether the two images have same semantic content .",
    "it can be easily derived that @xmath121 since the larger the visual similarity , the larger the probability that the two images have the same semantic content .",
    "the probability of @xmath114 , conditioned on the topic distribution , is given as follows , @xmath122 we analyze the relation between visual similarity @xmath114 and topic similarity @xmath123 in a bidirectional way . given the topic distribution , @xmath112 and @xmath113 , we can obtain @xmath124 = & r_{dd'1 } \\mu_1 + ( 1 - r_{dd'1 } ) \\mu_2.\\end{aligned}\\ ] ] this indicates that the expectation of the visual similarity is larger when the topic similarity is larger .",
    "this is more reasonable and more robust to noise , compared with the direct requirement that the visual similarity is larger when the topic similarity is larger , because of the gap between visual contents and semantics .",
    "given the visual similarity , @xmath114 , the posterior that the two images have the same content is computed by @xmath125 suppose we expect that the two image have the same content when @xmath126 .",
    "this leads to that @xmath127 in the case @xmath126 .",
    "this further means that @xmath128 from the above analysis , it can be concluded that the topic similarity must be larger than some constant value in order to align it with the classification result from visual similarity .",
    "this is a relaxant requirement since it does not require that the topic similarity must be larger if the visual similarity is larger , and hence also more reasonable because there is some gap between visual and semantic contents .",
    "let s first look at a possible solution , the variational inference technique that is used in lda  @xcite to estimate the posterior distribution of the latent variables : @xmath129    we introduce the following variational distribution @xmath130 \\prod_{dd ' } q(\\boldsymbol{\\tau}_{dd ' } | \\boldsymbol{\\rho}_{dd'}),\\end{aligned}\\ ] ] where the dirichlet parameter @xmath131 , the multinomial parameters @xmath132 , and the dirichlet parameters @xmath133 are the free variational parameters .",
    "these variational parameters can be obtained by solving the following optimization problem @xmath134 this optimization problem can be solved via an iterative fixed - point method . for @xmath135 and @xmath136",
    ", we can have the following update equations , @xmath137 ) + \\frac{1}{\\sigma_i\\sqrt{2\\pi}}\\exp(-\\frac{(s_{dd } - \\mu_i)^2}{2\\sigma_i^2})).\\end{aligned}\\ ] ] for @xmath81 , there is no closed - form solution .",
    "the gradient decent based solution requires the computation of @xmath138}{\\partial \\gamma_{di}}$ ] , which is intractable .    in order to make the inference feasible ,",
    "instead , we propose a hybrid sampling based approach , which iteratively samples two latent variables @xmath76 and @xmath139 and computes the conditional expectation , @xmath140 :    1 .",
    "sample @xmath76 from the conditional distribution @xmath141 .",
    "this is depicted in figure  [ fig : illustrationrldainference : z ] .",
    "sample @xmath97 from the conditional distribution @xmath142 .",
    "this is depicted in figure  [ fig : illustrationrldainference : tau ] .",
    "3 .   compute the conditional expectation @xmath143 .",
    "this is depicted in figure  [ fig : illustrationrldainference : theta ] .    from the definition",
    ", @xmath76 is a discrete vector with only one entry being @xmath144 and all the others being @xmath145 , thus sampling @xmath76 is straightforward .",
    "similarly , sampling @xmath97 is also straightforward .",
    "we propose to adopt the importance sampling approach to compute the conditional expectation @xmath146 .",
    "the conditional probability can be calculated as below , @xmath147 we use @xmath148 , which can be easily sampled , as the proposal function .",
    "the conditional expectation is computed as follows , @xmath149      given the expectations @xmath150 of all the documents , @xmath67 can be estimated by maximizing the likelihood , @xmath151 the maximization problem can be solved by a fixed - point iteration  @xcite .",
    "given samples @xmath152",
    ", @xmath68 can also be estimated by maximizing the likelihood , @xmath153 here , @xmath68 can be regarded as a markov matrix from @xmath60 to @xmath92 that can be easily computed .",
    "given samples @xmath97 , the gaussian parameters , @xmath154 , @xmath155 , @xmath156 and @xmath157 , can be easily estimated from visual similarities @xmath114 . in a summary ,",
    "given the observations , tags @xmath89 associated with visual similarities @xmath158 , the whole algorithm is an iterative scheme in which each iteration consists of latent variable inference ( section  [ sec : inference ] ) and model parameter estimation ( this section ) .      in the rlda , we can estimate the tag relevance jointly using the information from the image and the information from other images .",
    "the relevance of a tag @xmath92 for one image is formulated as the probability conditioned on the set of tags @xmath21 associated with this image , and other sets of tags @xmath159 .",
    "it is mathematically formulated as @xmath160 the computation of tag relevance is similar to that in lda .",
    "differently , this approximation is obtained by jointly considering the information from the other images .",
    "the tag relevance model is illustrated using a graphical representation in  figure  [ fig : illustrationbydeeplearning : rlda ] .",
    "our experiments are conducted over two datasets : the msra - tag dataset  @xcite and the nus - wide - lite dataset  @xcite .",
    "the msra - tag dataset consists of @xmath161 images and their associated tags that are downloaded from flickr using ten popular tags , including cat , automobile , mountain , water , sea , bird , tree , sunset , flower and sky . @xmath162",
    "distinctive tags are obtained after filtering out the misspelling and meaningless tags .",
    "similar to  @xcite , for quantitative evaluation , @xmath163 images are randomly selected from the dataset and manually labeled to build the ground truth . for each image",
    ", we ask volunteers to mark the relevance of each tag with a score , ranging from @xmath144 ( the least relevant ) to @xmath164 ( the most relevant ) .",
    "we perform the tag reranking task over this dataset .",
    "the nus - wide - lite dataset  @xcite consists of @xmath165 images with tags provided by users .",
    "@xmath166 filtered tags that appeared the most frequently were used .",
    "we perform the image rettagging task over this dataset . in our experiments ,",
    "the top @xmath164 tags with the highest scores are chosen as the new tags of the image and the performance of algorithms is evaluated on @xmath167 tags where the ground truth for these tags are provided in  @xcite .",
    "the task of tag reranking is to rank the original tags of an image according to their relevances .",
    "the confidence scores for the tags are produced and are used to rerank the tags .",
    "the normalized discounted cumulative gain ( ndcg ) measurement is adopted as the evaluation measure , which is calculated as @xmath168 , where @xmath169 is the relevance score of the @xmath62-th tag and @xmath170 is a normalization constant that is chosen so that the ndcg score of the optimal ranking is 1 .",
    "we use the average of the ndcg scores of all the images to compare the performance .    in the task of image retagging , each image",
    "is assigned a number of tags .",
    "the assigned tags can be either original tags or new tags that are not among the originals .",
    "the top @xmath164 tags with the highest scores are chosen as the retagging results of the image .",
    "we have the ground truth of @xmath167 tags , where whether each image in the dataset is related to these tags is provided .",
    "similar to  @xcite , we perform a retrieval process based on retagging results and evaluate the average f - measure of @xmath167 tags to compare the performance .",
    "the f - measure is calculated as @xmath171 , where @xmath172 and @xmath173 are computed form the returned retrieval list .      to evaluate the performance of our approach , regularized lda ( rlda ) , for tag refinement",
    ", we also report the experimental results of existing state - of - the - art approaches .",
    "1 .   baseline .",
    "the score is computed based on the original tag ranking provided by users according to the uploading time .",
    "random walk with restart ( rwr )  @xcite .",
    "this method performs a random walk process on a graph that encodes the relationship between tags .",
    "it only uses the text information without using the visual information .",
    "3 .   tag ranking based on visual and semantic consistency ( trvsc )  @xcite .",
    "this work follows rwr  @xcite using a random walk based method .",
    "the difference is that when constructing the graph over tags trvsc considers the visual similarity between images .",
    "tag refinement based on low - rank , content - tag prior and error sparsity ( lrctpes )  @xcite .",
    "this approach formulates the tag refinement problem as a decomposition of the user - provided tag matrix into a low - rank matrix and a sparse error matrix , targeting the optimality by low - rank , content consistency , tag correlation and error sparsity .",
    "collaborative retagging ( crt )  @xcite .",
    "the crt process is formulated as a multiple graph - based multi - label learning problem .",
    "this work also proposes a tag - specific visual sub - vocabulary learning method . in our implementation",
    "we did not use the sub - vocabulary part because we focus mainly on the approach of rag refinement , not feature extraction .",
    "the parameters of crt are tuned using the grid search method in  @xcite . 6 .",
    "separate retagging ( srt ) .",
    "srt performs the same method as crt  @xcite , but without considering tag similarity .",
    "we also use the grid search method described in  @xcite to find the best parameters .",
    "latent dirichlet allocation ( lda )  @xcite .",
    "we perform lda by considering each image as a document and each tag as a word .    in our experiments ,",
    "all the approaches use the same visual features , a @xmath174-dimensional block - wise color moment .",
    "the visual similarity is calculated as @xmath175 , where @xmath176 is the visual feature of image @xmath177 and @xmath178 $ ] with @xmath179 being the expectation operator .",
    "two images are connected in the rlda model only when their similarity is higher than @xmath180 .",
    "the results of tag reranking are reported in figure  [ fig : tagranking ] .",
    "it can be observed that all approaches perform better results than the baseline result .",
    "it demonstrates that tag refinement is a useful process . among these methods , rwr and lda",
    "are based on the tag information and do not take into account of the visual information .",
    "srt only uses the visual information .",
    "trvsc , lrctpes , crt and rlda make use of both the textual and visual information .",
    "we can see that both the textual information and the visual information can make great contributions to tag refinement .",
    "though lda does not use the visual information , it outperforms most of other methods , showing the significant benefit of jointly estimating the tag similarity and the tag relevance and the powerfulness of exploring multi - wise relationships using the topic model .",
    "our approach , rlda , further improves lda by encouraging visually similar images having similar topic distributions .",
    "the superiority of rlda over lda justifies our analysis that rlda is deeper than lda illustrated in figure  [ fig : illustrationbydeeplearning ] .",
    "the superior performance of our approach can be justified from the deep learning theory  @xcite , which shows that a deeper network has large potentials to achieve better performance . by comparison ,",
    "the random walk based approaches essentially use shallow structures , which only consists of two levels , the provided tags as the input level and the tag being considered as the output level .",
    "the lda based approach is with a deep structure , introducing a latent topic level , which has potential to get better performance .",
    "the proposed regularized lda model is deeper , with four levels , the tags associated with other images as the first level , the latent topics of other images and the tags of the image being considered as the second level , the latent topic as the third level , and the tag being considered as the output level . the comparison has been illustrated in figure  [ fig : illustrationbydeeplearning ] .                  to illustrate the superiority of rlda over lda clearer , we compare their performances using different numbers of topics , @xmath181 , which are shown in figure  [ fig : rldavslda ] .",
    "we have at least two observations .",
    "the first one is that taking visual information into account can be effective for the tag refinement task from the fact that rlda consistently outperforms lda on different number of topics .",
    "the second one is that the performances of both methods begins to decrease when @xmath181 grows too large .",
    "this is reasonable . considering the extreme case that @xmath182 , it can be validated that it will overfit the data distribution if setting each word as a single topic , which indicates that the relations among tags tend to be useless when @xmath181 is too large .    to understand our approach more deeply , we report the percentage of the images in which the truly most relevant tag is ranked in different positions . in figure",
    "[ fig : rldaposition ] .",
    "we can see that over 60 percent of the images have their most relevant tag at the first position .",
    "this can be helpful for related works like image retrieval , group recommendation , etc .",
    "some examples of refined tags are depicted in figure  [ fig : tagrakingexamples ] .    [ cols= \" < , < , < ,",
    "< , < \" , ]          different from tag reranking , retagging  @xcite aims to suggest a set of tags that are assigned according to the original tags .",
    "these tags may not necessarily be contained in the original tags . in this task ,",
    "the results of five methods , srt , lrctpes , crt , lda and our approach , are reported .",
    "other methods based on random walks only produce scores for original tags and can not perform the retagging task figure  [ fig : retag ]  shows the experiment results .",
    "the retagging results of all methods outperformed the base line that is based on the original tag list .",
    "this demonstrates that image retagging can make significant contributions for image retrieval . in the image retagging task lda",
    "does not perform as good as in the tag reranking task .",
    "this is because lda is unable to deal with the images without tags provided by users , while methods using visual features can tag the images using the tags of similar images .",
    "improving lda with using visual content of images , our method , rlda , gets the best result . in both tag reranking and image retagging tasks , the proposed method performs the best , which is because our model is based on a deeper structure and can exploit the semantic information derived from the topic level .",
    "this paper presents a regularized latent dirichlet allocation approach for tag refinement .",
    "our approach succeeds from the factors : ( 1 ) our approach explores the multi - wise relationship among the tags that are mined from both textual and visual information ; ( 2 ) our approach explores a deep structure that has large capability to refine tags .",
    "experimental results also demonstrate the superiority of our approach over existing state - of - the - art approaches for tag refinement ."
  ],
  "abstract_text": [
    "<S> tagging is nowadays the most prevalent and practical way to make images searchable . </S>",
    "<S> however , in reality many manually - assigned tags are irrelevant to image content and hence are not reliable for applications . </S>",
    "<S> a lot of recent efforts have been conducted to refine image tags . in this paper </S>",
    "<S> , we propose to do tag refinement from the angle of topic modeling and present a novel graphical model , regularized latent dirichlet allocation ( rlda ) . in the proposed approach , tag similarity and tag relevance </S>",
    "<S> are jointly estimated in an iterative manner , so that they can benefit from each other , and the multi - wise relationships among tags are explored . moreover , </S>",
    "<S> both the statistics of tags and visual affinities of images in the corpus are explored to help topic modeling . </S>",
    "<S> we also analyze the superiority of our approach from the deep structure perspective . </S>",
    "<S> the experiments on tag ranking and image retrieval demonstrate the advantages of the proposed method .    </S>",
    "<S> image tag refinement , regularized latent dirichlet allocation </S>"
  ]
}