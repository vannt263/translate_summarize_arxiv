{
  "article_text": [
    "few results exist on the concentration properties of sampling without replacement from a finite population @xmath0 . however , potential applications are numerous , from historical applications such as opinion surveys ( kish @xcite ) and ecological counting procedures ( bailey @xcite ) , to more recent approximate monte carlo markov chain algorithms that use subsampled likelihoods ( bardenet , doucet and holmes @xcite ) . in a fundamental paper on sampling without replacement ,",
    "serfling @xcite introduced an efficient hoeffding bound , that is , one which is a function of the range of the population .",
    "bernstein bounds are typically tighter when the variance of the random variable under consideration is small , as their leading term is linear in the standard deviation of @xmath0 , while the range only influences higher - order terms .",
    "this paper is devoted to hoeffding and bernstein bounds for sampling without replacement .",
    "let @xmath1 be a finite population of @xmath2 real points .",
    "we use capital letters to denote random variables on @xmath0 , and lower - case letters for their possible values .",
    "sampling without replacement a list @xmath3 of size @xmath4 from @xmath0 can be described sequentially as follows : let first @xmath5 , sample an integer @xmath6 uniformly on @xmath7 , and set @xmath8 to be @xmath9 .",
    "then , for each @xmath10 , sample @xmath11 uniformly on the remaining indices @xmath12 .",
    "hereafter , we assume that @xmath13 .",
    "there have been a few papers on concentration properties of sampling without replacement ; see , for instance , hoeffding @xcite , serfling @xcite , horvitz and thompson @xcite , mcdiarmid @xcite .",
    "one notable contribution is the following reduction result in hoeffding s seminal paper ( hoeffding @xcite , theorem  4 ) :    [ lem : reduction ] let @xmath14 be a finite population of @xmath2 real points , @xmath15 denote a random sample without replacement from @xmath0 and @xmath16 denote a random sample with replacement from @xmath0 .",
    "if @xmath17 is continuous and convex , then @xmath18    lemma  [ lem : reduction ] implies that the concentration results known for sampling with replacement as chernoff bounds ( boucheron , lugosi and massart @xcite ) can be transferred to the case of sampling without replacement . in particular , proposition  [ prop : hoeffnaive ] , due to hoeffding @xcite , holds for the setting without replacement .",
    "[ prop : hoeffnaive ] let @xmath14 be a finite population of @xmath2 points and @xmath15 be a random sample drawn without replacement from @xmath0 .",
    "let @xmath19 then , for all @xmath20 , @xmath21 where @xmath22 is the mean of @xmath0 .",
    "the proof of proposition  [ prop : hoeffnaive ] ( see , e.g. , boucheron , lugosi and massart @xcite ) relies on a classical bound on the moment - generating function of a random variable , which we restate here as lemma  [ l : hoeffnaive ] for further reference .",
    "[ l : hoeffnaive ] let @xmath23 be a real random variable such that @xmath24 and @xmath25 for some @xmath26 .",
    "then , for all @xmath27 , @xmath28    when the variance of @xmath0 is small compared to the range @xmath29 , another chernoff bound , known as bernstein s bound ( boucheron , lugosi and massart @xcite ) , is usually tighter than proposition  [ prop : hoeffnaive ] .    [ prop : bernnaive ] with the notations of proposition  [ prop : hoeffnaive ] , let @xmath30 be the variance of @xmath0",
    ". then , for all @xmath20 , @xmath31    although these are interesting results , it appears that the bounds in propositions [ prop : hoeffnaive ] and [ prop : bernnaive ] are actually very conservative , especially when @xmath4 is large , say , @xmath32 . indeed , serfling @xcite proved that the term @xmath4 in the rhs of ( [ eqn : hoeffnaive ] ) can be replaced by @xmath33",
    "; see theorem  [ thm : hoeff ] below , where the result of serfling is restated in our notation and slightly improved . as @xmath4 approaches @xmath2 ,",
    "the bound of serfling @xcite improves dramatically , which corresponds to the intuition that when sampling without replacement , the sample mean becomes a very accurate estimate of @xmath34 as @xmath4 approaches @xmath2 .      in section  [ sec : hoeff ] ,",
    "we slightly modify serfling s result , yielding a hoeffding  serfling bound in theorem  [ thm : hoeff ] that dramatically improves on hoeffding s in proposition  [ prop : hoeffnaive ] . in section  [ sec : bern ] , we contribute in theorem  [ thm : bern2 ] a similar improvement on proposition  [ prop : bernnaive ] , which we call a bernstein  serfling bound . to allow practical applications of our bernstein  serfling bound , we finally provide an _ empirical _ bernstein  serfling bound in section  [ sec : empbern ] , in the spirit of maurer and pontil @xcite , which does not require the variance of @xmath0 to be known beforehand . in section  [ sec : discussion ] , we discuss direct applications and potential further improvements of our results .     with our hoeffding  serfling and bernstein  serfling bounds .",
    "@xmath0 is here a sample of size @xmath35 from each of the four distributions written below each plot .",
    "an estimate ( black plain line ) of @xmath36 is obtained by averaging over @xmath37 repeated subsamples of size @xmath4 , taken from @xmath0 uniformly without replacement .",
    "( a ) gaussian @xmath38 .",
    "( b ) log - normal @xmath39 .",
    "( c ) bernoulli @xmath40 .",
    "( d ) bernoulli @xmath41 . ]",
    "to give the reader a visual intuition of how the above mentioned bounds compare in practice and motivate their derivation , in figure  [ fig : plots ] , we plot the bounds given by proposition  [ prop : hoeffnaive ] and theorem  [ thm : hoeff ] for hoeffding bounds , and proposition  [ prop : bernnaive ] and theorem  [ thm : bern2 ] for bernstein bounds for @xmath42 , in some common situations .",
    "we set @xmath0 to be an independent sample of size @xmath35 from each of the following four distributions : unit centered gaussian , log - normal with parameters @xmath43 , and bernoulli with parameter 1@xmath4410 and 1@xmath442 .",
    "an estimate of the probability @xmath45 is obtained by averaging over @xmath37 repeated samples of size @xmath4 taken without replacement . in figures  [ fig : plots](a ) , [ fig : plots](b ) and [ fig : plots](c ) , hoeffding s bound and the hoeffding  serfling bound of theorem  [ thm : hoeff ] are close for @xmath46 , after which the hoeffding  serfling bound decreases to zero , outperforming hoeffding s bound .",
    "bernstein s and our bernstein  serfling bound behave similarly , both outperforming their counterparts that do not make use of the variance of @xmath0 .",
    "however , figure  [ fig : plots](d ) shows that one should not always prefer bernstein bounds . in this case",
    ", the standard deviation is as large as roughly half the range , making hoeffding s and bernstein s bounds identical , and hoeffding ",
    "serfling actually slightly better than bernstein  serfling .",
    "we emphasize here that bernstein bounds are typically useful when the variance is small compared to the range .",
    "in this section , we recall an initial result and proof by serfling @xcite , and slightly improve on his final bound .",
    "we start by identifying the following martingales structures .",
    "let us introduce , for @xmath47 , @xmath48 note that by definition @xmath49 , so that the @xmath50-algebra @xmath51 is equal to @xmath52 .",
    "[ lem : martingales ] the following _ forward martingale _",
    "structure holds for @xmath53 : @xmath54 = z_{k-1}^\\star.\\end{aligned}\\ ] ] similarly , the following _ reverse martingale _",
    "structure holds for @xmath55 : @xmath56 = z_{k+1 } .\\end{aligned}\\ ] ]    we first prove ( [ eqn : fwmart ] ) .",
    "let @xmath57 .",
    "we start by noting that @xmath58\\\\[-8pt ] & = & \\frac{n - k+1}{n - k}z_{k-1}^\\star+ \\frac{x_k - \\mu}{n - k } .\\nonumber\\end{aligned}\\ ] ] since @xmath59 is uniformly distributed on the remaining elements of @xmath0 after @xmath60 have been drawn , its conditional expectation given @xmath60 is the average of the @xmath61 remaining points in @xmath0 .",
    "since points in @xmath0 add up to @xmath62 , we obtain @xmath63 & = & { \\mathbb{e } } [ x_k    \\nonumber \\\\ & = & \\frac{n\\mu- \\sum_{i=1}^{k-1}x_i}{n - k+1 } \\\\ & = & \\mu- z_{k-1}^\\star.\\nonumber\\end{aligned}\\ ] ] combined with ( [ eqn : decz * ] ) , this yields ( [ eqn : fwmart ] ) .",
    "we now turn to proving ( [ eqn : rvmart ] ) .",
    "first , let @xmath64 . since @xmath65 @xmath66 is equal to @xmath67 .",
    "now , let us remark that the indices of @xmath68 are uniformly distributed on the permutations of @xmath69 , so that @xmath70 and @xmath71 have the same marginal distribution .",
    "consequently , @xmath72 = { \\mathbb{e}}[x_{k+1 } \\vert x_{k+2}\\ldots , x_{n } ] = \\frac{s_{k+1}}{k+1},\\ ] ] where we introduced the sum @xmath73 .",
    "finally , we prove ( [ eqn : rvmart ] ) along the same lines as ( [ eqn : fwmart ] ) : @xmath74 & = & { \\mathbb{e}}\\biggl[\\frac{s_k - k\\mu}{k } \\bigl\\vert z_{k+1},\\ldots , z_{n-1 } \\biggr ] \\\\ & = & { \\mathbb{e}}\\biggl[\\frac{s_{k+1}-x_{k+1}}{k } \\bigl\\vert z_{k+1},\\ldots , z_{n } \\biggr ] -\\mu \\nonumber \\\\ & = & \\frac{s_{k+1}}{k } - \\frac{s_{k+1}}{k(k+1 ) } -\\mu \\nonumber \\\\ & = & z_{k+1}. \\nonumber\\end{aligned}\\ ] ]      let us now state the main result of serfling @xcite .",
    "this is a key result to derive a concentration inequality , a maximal concentration inequality and a self - normalized concentration inequality , as explained in serfling @xcite .",
    "[ prop : hoeff ] let us denote @xmath75 , and @xmath76 . then",
    ", for any @xmath77 , it holds that @xmath78 moreover , for any @xmath77 , it also holds that @xmath79    first , ( [ eqn : decz * ] ) yields that for all @xmath80 , @xmath81 furthermore , we know from ( [ eqn : espxk ] ) that @xmath82 is the conditional expectation of @xmath83 given @xmath60 .",
    "thus , since @xmath84 $ ] , lemma  [ l : hoeffnaive ] applies and we get that , for all @xmath85 , @xmath86 \\leq\\frac{(b - a)^2}{8 } \\frac{{\\lambda'}^2 } { ( n - k ) ^2 } .\\end{aligned}\\ ] ] similarly , we can apply lemma  [ l : hoeffnaive ] to @xmath87 to obtain @xmath88 upon noting that @xmath89 , and combining ( [ eqn : th1hoef ] ) and ( [ eqn : th1hoef2 ] ) together with the decomposition ( [ eqn : th1dec ] ) , we eventually obtain the bound @xmath90 in particular , for @xmath91 such that @xmath92 , the rhs of this equation contains the quantity @xmath93 where we used in the second line the following approximation from ( serfling @xcite , lemma  2.1 ) : for @xmath94 , it holds @xmath95 this concludes the proof of the first result of proposition  [ prop : hoeff ] .",
    "the second result follows from applying doob s maximal inequality for martingales combined with the previous derivation .",
    "the result of proposition  [ prop : hoeff ] reveals a powerful feature of the no replacement setting : the factor @xmath96 in the exponent , as opposed to @xmath4 in the case of sampling with replacement .",
    "this leads to a dramatic improvement of the bound when @xmath4 is large , as can be seen on figure  [ fig : plots ] .",
    "serfling @xcite mentioned that a factor @xmath97 would be intuitively more natural , as indeed when @xmath98 the mean @xmath34 is known exactly , so that @xmath99 is deterministically zero .",
    "serfling did not publish any result with @xmath97 .",
    "however , it appears that a careful examination of the previous proof and of the use of equation ( [ eqn : rvmart ] ) , in lieu of ( [ eqn : fwmart ] ) , allows us to get such an improvement .",
    "we detail this in the following proposition .",
    "more than a simple cosmetic modification , it is actually a slight improvement on serfling s original result when @xmath100 .",
    "[ prop : hoeff2 ] let @xmath101 be defined by ( [ def : zzs ] ) . for any @xmath77",
    ", it holds that @xmath102 moreover , for any @xmath77 , it also holds that @xmath103    let us introduce the notation @xmath104 for @xmath105 . from ( [ eqn : rvmart ] ) , it comes @xmath106 = y_{n - k-1 } .\\end{aligned}\\ ] ] by a change of variables , this can be rewritten as @xmath107 = y_{k-1 } .\\end{aligned}\\ ] ]    now we remark that the following decomposition holds : @xmath108\\\\[-8pt ] & = & \\lambda y_{k-1 } - \\lambda\\frac{x_{n - k+1}-\\mu - y_{k-1}}{n - k } .\\nonumber\\end{aligned}\\ ] ] since @xmath109 is the conditional mean of @xmath110 $ ] , lemma  [ l : hoeffnaive ] yields that , for all @xmath85 , @xmath111 \\leq\\frac{(b - a)^2}{8 } \\frac{{\\lambda'}^2 } { ( n - k ) ^2 } .\\end{aligned}\\ ] ] on the other hand it holds by definition of @xmath112 that @xmath113 .\\end{aligned}\\ ] ] along the lines of the proof of proposition  [ prop : hoeff ] , we obtain @xmath114 combining equations ( [ eqn : th1hoefb ] ) and ( [ eqn : th1hoef2b ] ) with the decomposition ( [ eqn : ydec ] ) , it comes @xmath115 where in the last line we made use of ( [ eqn : sumkn ] ) . rewriting this inequality in terms of @xmath116 , we obtain that , for all @xmath117 , @xmath118 that is , by resorting to a new change of variable , @xmath119 the second part of the proposition follows from applying doob s maximal inequality for martingales to @xmath120 , similarly to proposition  [ prop : hoeff ] .",
    "[ thm : hoeff ] let @xmath14 be a finite population of @xmath121 real points , and @xmath122 be a list of size @xmath123 sampled without replacement from  @xmath0 .",
    "then for all @xmath20 , the following concentration bounds hold @xmath124 where @xmath75 and @xmath125 .",
    "applying proposition  [ prop : hoeff2 ] together with markov s inequality , we obtain that , for all @xmath77 , @xmath126 we now optimize the previous bound in @xmath91 .",
    "the optimal value is given by @xmath127 this gives the first inequality of theorem  [ thm : hoeff ] .",
    "the proof of the second inequality follows the very same lines .    inverting the result of theorem  [ thm : hoeff ] for @xmath123 and remarking that the resulting bound still holds for @xmath98",
    ", we straightforwardly obtain the following result .",
    "[ cor : hoeff ] for all @xmath128 , for all @xmath129 $ ] , with probability higher than @xmath130 , it holds @xmath131 where we define @xmath132",
    "in this section , we consider @xmath133 is known , and extend theorem  [ thm : hoeff ] to that situation .    similarly to lemma  [ lem : martingales ]",
    ", the following structural lemma will be useful :    [ lem : var ] it holds @xmath134 = \\sigma^2 - q_{k-1}^\\star , \\qquad \\mbox{where } q_{k-1}^\\star= \\frac{\\sum_{i=1}^{k-1 }   ( ( x_i-\\mu)^2- \\sigma^2 ) } { n - k+1 } , \\end{aligned}\\ ] ] where the @xmath135 s are defined in ( [ def : zzs ] ) .",
    "similarly , it holds @xmath136 = \\sigma^2 + q_{k+1},\\qquad   \\mbox{where } q_{k+1 } = \\frac{\\sum_{i=1}^{k+1 }   ( ( x_i-\\mu)^2- \\sigma^2 ) } { k+1 } .\\end{aligned}\\ ] ]    we simply remark again that , conditionally on @xmath60 , the variable @xmath59 is distributed uniformly over the remaining points in @xmath0 , so that @xmath137 & = & { \\mathbb{e}}\\bigl [ ( x_k-\\mu)^2 | x_1,\\ldots , x_{k-1 } \\bigr ] \\\\ & = & \\frac{1}{n - k+1 } \\biggl [ n\\sigma^2 - \\sum _ { i=1}^{k-1}(x_i-\\mu ) ^2 \\biggr ] \\\\ & = & \\sigma^2-q_{k-1}^\\star . \\ ] ] the second equality of lemma  [ lem : var ] follows from the same argument , as in the proof of lemma  [ lem : martingales ] .",
    "let us now introduce the following notations : @xmath138 , \\\\",
    "\\mu_{>,k } & = & { \\mathbb{e}}[x_{k } - \\mu | z_{1},\\ldots , z_{k-1 } ] , \\\\",
    "\\sigma_{<,k+1}^2 & = & { \\mathbb{e}}\\bigl [ ( x_{k+1 } - \\mu)^2 | z_{k+1},\\ldots , z_{n-1 } \\bigr ] - \\mu_{<,k+1}^2 , \\\\ \\sigma_{>,k}^2 & = & { \\mathbb{e}}\\bigl [ ( x_{k } - \\mu)^2 | z_{1},\\ldots , z_{k-1 } \\bigr ] - \\mu_{>,k}^2 .\\end{aligned}\\ ] ] we are now ready to state proposition  [ prop : bern ] , which is a bernstein version of proposition  [ prop : hoeff ] .",
    "[ prop : bern ] for any @xmath77 , it holds that @xmath139 where we introduced the function @xmath140 .",
    "moreover , for any @xmath77 , it also holds that @xmath141    the key point is to replace equations ( [ eqn : th1hoef ] ) and ( [ eqn : th1hoef2 ] ) in the proof of proposition  [ prop : hoeff ] , which make use of the range of @xmath0 , by equivalent ones that involve the variance .",
    "we only detail the proof of the first inequality , the proof of the three others follows the same steps .    a standard result from the proof of bennett s inequality ( see lugosi @xcite , page 11 , or boucheron , lugosi and massart @xcite , proof of theorem  2.9 ) applied to the random variable @xmath142 , with conditional mean @xmath143 and conditional variance @xmath144 , yields @xmath145\\\\[-8pt ] & & \\hphantom{{\\mathbb{e}}\\biggl [ \\exp \\biggl ( } { } - \\sigma_{<,n - k+1}^2 { \\varphi}\\biggl(\\frac{2(b - a)\\lambda'}{n - k } \\biggr ) \\frac{{\\lambda'}^2 } { ( n - k ) ^2 } \\biggr ) \\bigl| y_1,\\ldots , y_{k-1 } \\biggr ] \\leq1 , \\nonumber\\end{aligned}\\ ] ] where we used the notation @xmath146 of proposition  [ prop : hoeff2 ] , and the function @xmath147 defined in the statement of the proposition @xmath148 similarly",
    ", @xmath112 satisfies @xmath149 where @xmath150 is deterministic .",
    "thus , combining ( [ eqn : th2ben ] ) and ( [ eqn : th2ben2 ] ) together with the decomposition ( [ eqn : ydec ] ) , we eventually get the bound @xmath151    using the result of proposition  [ prop : bern ] , we could immediately derive a simple bernstein inequality for sampling without replacement via an application of theorem  [ thm : hoeff ] to the random variables @xmath152 .",
    "however , maurer and pontil @xcite and audibert , munos and szepesvri @xcite showed that , in the case of sampling with replacement , a careful use of self - bounded properties of the variance yields better bounds .",
    "we now explain how to get a similar improvement on the naive bernstein inequality in the case of sampling without replacement .",
    "we start with a technical lemma .",
    "[ lem : sigmaleft ] for all @xmath129 $ ] , with probability larger than @xmath130 , it holds @xmath153 similarly , with probability larger than @xmath130 , it holds @xmath154    when @xmath155 , the upper bound on @xmath156 reduces to @xmath157 .",
    "indeed , this limit case intuitively corresponds to sampling with replacement , for which the conditional variance equals @xmath157 .",
    "proof of lemma  [ lem : sigmaleft ] we first prove ( [ eqn : sigmaleft ] ) . by definition and lemma  [ lem : var ] , it holds that @xmath158\\\\[-8pt ] & \\leq & \\sigma^2 - \\frac{1}{n - k+1}\\sum _ { i=1}^{k-1 } \\bigl [ ( x_i-\\mu ) ^2 - \\sigma^2 \\bigr ] .\\nonumber\\end{aligned}\\ ] ] let @xmath159 .",
    "equation ( [ eqn : decompsig2 ] ) yields @xmath160 the rest of the proof proceeds by establishing a suitable maximal concentration bound for the quantity @xmath161 , the mean of which is @xmath157 .",
    "we remark that @xmath162 is a martingale .",
    "indeed , it satisfies @xmath163 \\\\ & & \\quad = \\frac{1}{n - k+1}{\\mathbb{e}}\\biggl [ \\sum_{i=1}^{k-1 } \\bigl(\\sigma^2 - ( x_i-\\mu)^2 \\bigr ) | q^\\star_{k-2},\\ldots , q^\\star_1 \\biggr ] \\\\ & & \\quad = \\frac{1}{n - k+1}\\sum_{i=1}^{k-2 } \\bigl ( \\sigma^2 - ( x_i-\\mu)^2 \\bigr ) + \\frac{1}{n - k+1}{\\mathbb{e}}\\bigl [ \\bigl(\\sigma^2 - ( x_{k-1}- \\mu)^2 \\bigr ) | q^\\star_{k-2},\\ldots , q^\\star_1 \\bigr ] \\\\ & & \\quad = -\\frac{n - k+2}{n - k+1}q^\\star_{k-2 } + \\frac{1}{n - k+1}q_{k-2}^\\star \\\\ & & \\quad = -q^\\star_{k-2 } , \\end{aligned}\\ ] ] where we applied lemma  [ lem : var ] in the third line .",
    "doob s maximal inequality thus yields that , for all @xmath77 , @xmath164 \\\\ & = & { \\mathbb{e}}\\biggl[\\exp \\biggl(\\lambda\\frac{n-1}{n - n+1 } \\biggl ( \\sigma^2 - v_{n-1}- \\frac{n - n+1}{n-1 } { \\varepsilon}\\biggr ) \\biggr ) \\biggr ] .\\end{aligned}\\ ] ]    at this point , we fix @xmath77 and apply lemma  [ lem : reduction ] to the random variables @xmath165 and function @xmath166 . we deduce that , for all @xmath167 and @xmath77 , @xmath168 \\nonumber \\\\[-8pt]\\\\[-8pt ] & \\leq & { \\mathbb{e}}\\bigl[\\exp \\bigl(-\\lambda\\bigl(\\tilde v_{n-1 } - \\sigma^2 + { \\varepsilon}'\\bigr ) \\bigr ) \\bigr ] , \\nonumber\\end{aligned}\\ ] ] where we introduced in the last line the notation @xmath169 , with the @xmath170 being sampled from @xmath0 _ with replacement_. note that @xmath171 has mean @xmath157 too .",
    "now , we check that the assumptions of theorem  13 of maurer @xcite hold .",
    "we first introduce the modification @xmath172 of @xmath173 , where @xmath174 is replaced by @xmath175 . writing @xmath176 to underline the dependency on the sample set @xmath173 , it straightforwardly comes , on the one hand , that for all @xmath175 @xmath177 and , on the other hand , that the following self - bounded property holds : @xmath178 we now apply of the proof of theorem  13 of maurer @xcite - z \\geq{\\varepsilon}]$ ] but , actually , @xmath179 + { \\varepsilon } ) ) ] $ ] is bounded in the proof . ] to @xmath180 , together with ( [ eqn : sigv1 ] ) , which yields @xmath181 \\biggr ) \\\\ & = & \\exp \\biggl(- \\frac{(b - a)^2{\\varepsilon}^2}{2(n-1)\\sigma^2 } \\biggr ) , \\end{aligned}\\ ] ] where we used the same value @xmath182 } = \\frac{(b - a)^2{\\varepsilon}}{(n-1)\\sigma^2}$ ] as in maurer @xcite , theorem  13 .",
    "finally , we have proven that for all @xmath129 $ ] , with probability higher than @xmath130 , @xmath183 which concludes the proof of ( [ eqn : sigmaleft ] ) .",
    "we now turn to proving ( [ eqn : sigmaleft2 ] ) .",
    "first , we remark that @xmath184 \\\\ & = & { \\mathbb{e}}\\bigl[(x_{k+1}-\\mu)^2\\vert x_{k+2 } , \\ldots , x_{n } \\bigr ] \\\\ & = & { \\mathbb{e}}\\bigl[(y_{n - k}-\\mu)^2\\vert y_1 , \\ldots , y_{n - k-1 } \\bigr ] , \\end{aligned}\\ ] ] where in the second line we used that @xmath185 , and in the third line we used the change of variables @xmath186 .",
    "it follows that @xmath187 \\\\ & = & \\max_{1\\leq k\\leq n - n}{\\mathbb{e}}\\bigl[(y_{k}-\\mu)^2 \\vert y_1,\\ldots , y_{k-1 } \\bigr ] .\\end{aligned}\\ ] ] now @xmath188 has the same marginal distribution as @xmath189 , so that the proof of ( [ eqn : sigmaleft ] ) applies and yields the result .",
    "we emphasize that we used hoeffding s reduction lemma  [ lem : reduction ] in the proof of lemma  [ lem : sigmaleft ] .",
    "this allowed us to apply the key result from maurer @xcite",
    ". we will discuss alternatives to this proof in section  [ sec : discussion ] .",
    "we can now state our bernstein  serfling bound .",
    "[ thm : bern2 ] let @xmath14 be a finite population of @xmath121 real points , and @xmath122 be a list of size @xmath123 sampled without replacement from @xmath0 .",
    "then , for all @xmath20 and @xmath129 $ ] , the following concentration inequality holds @xmath190 + \\delta,\\end{aligned}\\ ] ] where @xmath191 @xmath192 , and @xmath193 .",
    "similarly , it holds @xmath194 + \\delta,\\end{aligned}\\ ] ] where @xmath195    we first prove ( [ eqn : bernserf2 ] ) . applying proposition  [ prop : bern ] together with markov s inequality , we obtain that for all @xmath196 , @xmath197 thus , combining equations ( [ eqn : cor1 ] ) and ( [ eqn : sigmaleft2 ] ) with a union bound , we get that for all @xmath77 for all @xmath198 , with probability higher than @xmath199 , it holds that @xmath200 \\\\ & & \\quad \\leq \\frac{\\log(1/\\delta)}{\\lambda } + \\frac{\\lambda}{n^2 } { \\varphi}\\biggl(\\frac{2(b - a ) \\lambda}{n } \\biggr ) \\biggl[\\sigma^2 + \\frac { n - n-1}{n+1}c_{n - n-1}\\bigl ( \\delta'\\bigr ) \\biggr ] \\sum_{k=1}^{n - n } \\frac{n^2}{(n -k)^2 } \\\\ & & \\quad \\leq \\frac{\\log(1/\\delta)}{\\lambda } + \\frac{\\lambda}{n^2 } { \\varphi}\\biggl(\\frac{2(b - a ) \\lambda}{n } \\biggr ) \\biggl[\\sigma^2 + \\frac { n - n-1}{n+1}c_{n - n-1}\\bigl ( \\delta'\\bigr ) \\biggr ] ( n+1 ) \\biggl(1 - \\frac{n}{n } \\biggr ) , \\end{aligned}\\ ] ] where we introduced @xmath201 where we used in the second line the fact that @xmath147 is nondecreasing and where we applied ( [ eqn : sumkn ] ) in the last line . for convenience ,",
    "let us now introduce the quantities @xmath202 and @xmath203 .\\end{aligned}\\ ] ] the previous bound can be rewritten in terms of @xmath20 and @xmath204 only , in the form @xmath205    we now optimize the bound ( [ eqn : invertedbound ] ) in @xmath91 .",
    "let us introduce the function @xmath206 corresponding to the term in brackets in ( [ eqn : invertedbound ] ) .",
    "by definition of @xmath147 , it comes @xmath207 thus , the derivative of @xmath208 is given by @xmath209 and the value @xmath210 that optimizes @xmath208 is given by @xmath211 let us now introduce for convenience the quantity @xmath212 . the corresponding optimal value @xmath213 is given by @xmath214 \\\\",
    "& = & -\\frac{n}{2(b - a ) u}\\zeta(u{\\varepsilon } ) , \\end{aligned}\\ ] ] where we introduced in the last line the function @xmath215 .",
    "now , using the identify @xmath216 for @xmath217 , we obtain @xmath218 which concludes the proof of ( [ eqn : bernserf2 ] ) .",
    "the proof of ( [ eqn : bernserf1 ] ) follows the very same lines , simply using ( [ eqn : sigmaleft ] ) instead of ( [ eqn : sigmaleft2 ] ) .",
    "inverting the bounds of theorem  [ thm : bern2 ] , we obtain corollary  [ cor : bern ] .    [ cor : bern ] let @xmath128 and @xmath129 $ ] . with probability larger than @xmath219",
    ", it holds that @xmath220 where we remind the definition of @xmath221 ( [ eqn : rhon ] ) @xmath222 and where we introduced the quantity @xmath223 with @xmath224 and @xmath225 .",
    "let @xmath226 $ ] . from ( [ eqn : bernserf1 ] ) in theorem  [ thm : bern2 ]",
    ", it comes that , with probability higher than @xmath199 , @xmath227 where we introduced for convenience @xmath228 and @xmath229 solving this equation in @xmath230 leads to @xmath231    on the other hand , following the same lines but starting from ( [ eqn : bernserf2 ] ) in theorem  [ thm : bern2 ] , it holds that , with probability higher than @xmath199 , @xmath232 where we introduced this time @xmath233 finally , we note that @xmath234    thus , when @xmath46 , we deduce that for all @xmath117 , with probability higher than @xmath219 , it holds @xmath235 whereas when @xmath236 , it holds , with probability higher than @xmath219 , that @xmath237 finally we note that when @xmath98 , @xmath238 and @xmath239 .",
    "so the bound is stillsatisfied .",
    "in this section , we derive a practical version of theorem  [ thm : bern2 ] where the variance @xmath157 is replaced by an estimate .",
    "a natural ( biased ) estimator is given by @xmath240 we also define , for notational convenience , the quantity @xmath241 . before proving our empirical bernstein  serfling inequality ,",
    "we first need to control the error between @xmath242 and @xmath50 .",
    "for instance , in the standard case of sampling with replacement , it can be shown ( maurer and pontil @xcite ) that , for all @xmath243 $ ] , @xmath244 we now show an equivalent result in the case of sampling without replacement .",
    "[ lem : sigmaright ] when sampling without replacement from a finite population @xmath14 of size @xmath2 , with range @xmath245 $ ] and variance @xmath157 , the empirical variance @xmath246 defined in ( [ eqn : defempvar ] ) using @xmath123 samples satisfies the following concentration inequality ( using the notation of corollary  [ cor : hoeff ] ) @xmath247    we conjecture that it is possible , at the price of a more complicated analysis , to reduce the term @xmath248 to @xmath249 , which would then be consistent with the analogous result for sampling with replacement in maurer and pontil @xcite .",
    "we further discuss this technically involved improvement in section  [ sec : discussion ] .",
    "proof of lemma  [ lem : sigmaright ] in order to prove lemma  [ lem : sigmaright ] , we again use lemma  [ lem : reduction ] , which allows us to relate the concentration of the quantity @xmath250 to that of its equivalent @xmath251 where the @xmath252s are drawn from @xmath0 _ with replacement_. let us introduce the notation @xmath253 . we know from the proof of lemma  [ lem : sigmaleft ] that @xmath116 satisfies the conditions of application of maurer @xcite , theorem  13 .",
    "let us also introduce for convenience the constant @xmath254 } = -\\frac{(b - a)^2{\\varepsilon}}{n\\sigma^2}$ ] . using these notations",
    ", it comes @xmath255 \\\\[-1pt ] & \\leq & { \\mathbb{e}}\\bigl[\\exp \\bigl(-\\lambda \\bigl({\\mathbb{e}}[z ] - z -{\\varepsilon}\\bigr ) \\bigr ) \\bigr ] \\\\[-1pt ] & \\leq & \\exp \\biggl(\\lambda{\\varepsilon}+ \\frac{\\lambda^2}{2}{\\mathbb{e}}[z ] \\biggr ) \\\\[-1pt ] & = & \\exp \\biggl ( -\\frac{(b - a)^2{\\varepsilon}^2}{2n\\sigma^2 } \\biggr ) .\\end{aligned}\\ ] ] the first line results of the application of markov s inequality .",
    "the second line follows from the application of lemma  [ lem : reduction ] to @xmath165 and @xmath256 .",
    "the last steps are the same as in the proof of lemma  [ lem : sigmaleft ] .",
    "so far , we have shown that , with probability at least @xmath130 , @xmath257 let us remark that @xmath258 that is , @xmath259 . in order to complete the proof , we thus resort twice to theorem  [ thm : hoeff ] to obtain that , with probability higher than @xmath130 , it holds @xmath260 combining equations ( [ eqn : sigvn ] ) and ( [ eqn : hoefsqr ] ) with a union bound argument yields that , with probability at least @xmath130 , @xmath261 & = & \\biggl(\\sigma- \\sqrt{(b - a)^2\\frac{\\log(3/\\delta)}{2n } } \\biggr)^2 - ( b - a)^2 ( 1+\\rho_n ) \\frac{\\log(3/\\delta)}{2n } .\\end{aligned}\\ ] ] finally , we obtain @xmath262    eventually , combining theorem  [ thm : bern2 ] and lemma  [ lem : sigmaright ] with a union bound argument , we finally deduce the following result .",
    "[ thm : empbern ] let @xmath14 be a finite population of @xmath121 real points , and @xmath122 be a list of size @xmath128 sampled without replacement from @xmath0 .",
    "then for all @xmath129 $ ] , with probability larger than @xmath263 , it holds @xmath264 where we remind the definition of @xmath221 ( [ eqn : rhon ] ) @xmath265 and @xmath266 .",
    "first , theorem  [ thm : empbern ] has the familiar form of bernstein bounds .",
    "the alternative definition of @xmath221 guarantees that we get the best reduction out of the no replacement setting . in particular ,",
    "when @xmath4 is large , the factor @xmath267 replaces @xmath268 and the corresponding factor eventually equals @xmath269 when @xmath98 , a feature that was missing in proposition  [ prop : hoeff ] .",
    "second , the constant @xmath270 is to relate to the constant @xmath271 in maurer and pontil @xcite , theorem  11 , for sampling with replacement .",
    "proof of theorem  [ thm : empbern ] first , by application of corollary  [ cor : bern ] , it holds for all @xmath129 $ ] that , with probability higher than @xmath219 , @xmath272 where we remind the definition of @xmath221 ( [ eqn : rhon ] ) @xmath222 and the definition of @xmath273 ( [ eqn : kappan ] ) @xmath274 we then apply lemma  [ lem : sigmaright ] to get that , with probability higher than @xmath263 , if @xmath46 , then @xmath275 and if @xmath100 , then @xmath276\\\\[-8pt ] & & \\qquad { } + \\frac{(b - a)\\log(1/\\delta)}{n } \\biggl(\\frac{4}{3}+ \\sqrt { g_{n+1}(1-f_n)}\\nonumber \\\\ & & \\hphantom{\\qquad { } + \\frac{(b - a)\\log(1/\\delta)}{n } \\biggl(}{}+ \\sqrt{(1-f_{n } ) ( 1 + 1/n ) } \\bigl(1 + \\sqrt{1 + ( 1-f_{n } ) ( 1 + 1/n ) } \\bigr ) \\biggr ) .",
    "\\nonumber\\end{aligned}\\ ] ]    we now simplify this result .",
    "assume first that @xmath46 .",
    "we thus get @xmath277 so that we deduce @xmath278 assume now that @xmath279 . in this case , it holds @xmath280 so that we deduce , since @xmath281 , @xmath282 respectively combining ( [ eqn : empbernterm1 ] ) and ( [ eqn : empbernterm2 ] ) with equations ( [ eqn : empberntool1 ] ) and ( [ eqn : empberntool2 ] ) concludes the proof .",
    "in this section , we discuss the bounds of theorem  [ thm : bern2 ] and theorem  [ thm : empbern ] from the perspective of both theory and application .     and [ cor : bern ] , and theorem [ thm : empbern ] .",
    "@xmath0 is here a sample from each of the four distributions written below each plot , of size @xmath283 .",
    "unlike figure  [ fig : plots ] , as @xmath4 increases , we keep sampling here without replacement until exhaustion .",
    "( a ) gaussian @xmath38 .",
    "( b ) log - normal @xmath39 .",
    "( c ) bernoulli @xmath40 .",
    "( d ) bernoulli @xmath41 . ]",
    "first , both bounds involve either the factor @xmath284 or @xmath285 , thus leading to a dramatic improvement on the usual bernstein or empirical bernstein bounds , which do not make use of the no replacement setting .",
    "this is crucial , for instance , when the user needs to rapidly compute an empirical mean from a large number of samples up to some precision level . to better understand the improvement of serfling bounds , we plot in figure  [ fig : empbern ] the bounds of corollaries [ cor : hoeff ] and [ cor : bern ] , and theorem  [ thm : empbern ] for an example where @xmath0 is a sample of size @xmath283 from each of the following four distributions : unit centered gaussian , log - normal with parameters @xmath43 , and bernoulli with parameter 1@xmath4410 and 1@xmath442 .",
    "as @xmath4 increases , we keep sampling without replacement from @xmath0 until exhaustion , and report the corresponding bounds .",
    "note that all our bounds have their leading term exactly equal to zero when @xmath98 , though our hoeffding  serfling bound only is exactly zero . in all experiments ,",
    "the loss of tightness as a result of using the empirical variance is small .",
    "our empirical bernstein  serfling demonstrates here a dramatic improvement on the hoeffding  serfling bound of corollary  [ cor : hoeff ] in figures  [ fig : empbern](a ) and [ fig : empbern](b ) .",
    "a slight improvement is demonstrated in figure  [ fig : empbern](c ) where the standard deviation of @xmath0 is roughly a third of the range .",
    "finally , bernstein  serfling itself does not improve on hoeffding  serfling in figure  [ fig : empbern](d ) , where the standard deviation is roughly half of the range , again indicating that bernstein bounds are not uniformly better than hoeffding bounds .",
    "there is a number of nontrivial applications of our bounds . _ scratch games",
    "_ , for instance , were introduced in fraud and urvoy @xcite as a variant of the multi - armed bandit problem , to model two real world problems : selecting ads to display on web pages and optimizing e - mailing campaigns .",
    "in particular , fraud and urvoy @xcite discuss practical situations where an upper confidence bound algorithm based on a hoeffding  serfling inequality outperforms a standard algorithm based on hoeffding s inequality .",
    "similar improvements should appear in practice when using our empirical bernstein  serfling inequality . as another application",
    ", our results could be useful in optimization .",
    "the stochastic dual - coordinate ascent algorithm ( sdca ; shalev - shwartz and zhang @xcite ) is a state - of - the - art optimization algorithm used in machine learning .",
    "shalev - shwartz and zhang @xcite introduce a variant of sdca called sdca - perm , which  unlike sdca",
    " relies on sampling without replacement , and achieves better empirical performance than sdca .",
    "however , the analysis in shalev - shwartz and zhang @xcite does not cover sdca - perm .",
    "we believe that the use of serfling bounds is an appropriate tool for that purpose .    to conclude , we discuss potential improvements of our bounds",
    ". a careful look at lemmas [ lem : sigmaleft ] and [ lem : sigmaright ] indicates that our bounds may be further improved , though at the price of a more intricate analysis .",
    "indeed , these two lemmas both resort to hoeffding s reduction lemma  [ lem : reduction ] , in order to be able to apply concentration results known for self - bounded random variables to the setting of sampling without replacement . as a result , we lose here a potential factor @xmath221 for the confidence bound around the variance , and we conjecture that the term @xmath286 in lemma  [ lem : sigmaright ] could ultimately be replaced with @xmath287 . a natural tool for this would be a dedicated _ tensorization inequality _ for the entropy in the case of sampling without replacement ( boucheron , lugosi and massart @xcite , maurer @xcite , bousquet @xcite ) .",
    "indeed , it is not difficult to show that @xmath288 satisfies a self - bounded property similar to that of maurer and pontil @xcite , theorem  11 , involving the factor @xmath221",
    ". thus , in order to be able to get a version of maurer and pontil @xcite , theorem  11 , in our setting , a specific so - called tensorization inequality would be enough .",
    "unfortunately , we are unaware of the existence of such an inequality for sampling without replacement , where the samples are strongly dependent .",
    "we are also unaware of any tensorization inequality designed for @xmath289-statistics , which could be another possible way to get the desired result .",
    "although we believe this is possible , developing such tools goes beyond the scope of this paper , and the current results of theorem  [ thm : bern2 ] and theorem  [ thm : empbern ] are already appealing without resorting to further technicalities , which would only affect second - order terms in the end .",
    "this work was supported by both the _ 2020 science _ program , funded by epsrc grant number ep / i017909/1 , and the technion ."
  ],
  "abstract_text": [
    "<S> concentration inequalities quantify the deviation of a random variable from a fixed value . in spite of numerous applications , such as opinion surveys or ecological counting procedures , </S>",
    "<S> few concentration results are known for the setting of sampling without replacement from a finite population . until now </S>",
    "<S> , the best general concentration inequality has been a hoeffding inequality due to serfling [ _ ann . </S>",
    "<S> statist . _ </S>",
    "<S> * 2 * ( 1974 ) 3948 ] . in this paper , we first improve on the fundamental result of serfling [ _ ann . </S>",
    "<S> statist . </S>",
    "<S> _ * 2 * ( 1974 ) 3948 ] , and further extend it to obtain a bernstein concentration bound for sampling without replacement . </S>",
    "<S> we then derive an empirical version of our bound that does not require the variance to be known to the user </S>",
    "<S> .    ./style / arxiv - general.cfg </S>"
  ]
}