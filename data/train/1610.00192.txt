{
  "article_text": [
    "randomized controlled trials ( rcts ) are a key component of medical research and by far the best way of achieving results that can genuinely increase our knowledge about treatment effectiveness  @xcite . because of the huge explosion of rcts , it is very hard for individuals to glean evidence from all of them .",
    "systematic reviews synthesize the results of more than one rct , summarize the effects of their individual outcomes with a certain degree of confidence and provide answers about the effectiveness of a particular intervention  @xcite .",
    "thus , systematic reviews provide current best evidence for policy and clinical decision - making .",
    "systematic review involves formulating a research question , searching in multiple biomedical databases , identifying relevant studies based on abstracts and titles ( abstract screening ) and then based on full texts of a subset thereof , assessing their methodological qualities , data extraction and synthesis , and finally reporting the conclusions on the review question  @xcite .",
    "however , the search precision is quite low and it usually returns a large number of citations , from hundreds to thousands .",
    "systematic review authors have to go through the tedious and time - consuming task of screening these citations .",
    "therefore , a systematic review platform that can automate the abstract screening process is fundamental in expediting the process of processing systematic reviews .",
    "there are several challenges in building a systematic review platform for abstract screening including : ( 1 )  feature extraction should be fast , ( 2 )  the features should be readily available , ( 3 )  the learning and prediction algorithms should be very efficient , and ( 4 )  the algorithms should also be able to handle the problem of extreme data imbalance ( due to the low search precision ) .",
    "in addition , the presentation of the citations should be based on their relevance , i.e. all the relevant citations should be ranked higher than the irrelevant ones .",
    "this is an instance of the bipartite ranking problem .",
    "generating a clear bipartition is a quite difficult task  @xcite and a common measure of success in such scenario is the area under the roc curve ( auc ) .",
    "however , the optimization techniques based on the auc can be reduced to binary classification  @xcite methods under specific settings . in this paper",
    ", we evaluate several svm based methods that either use a loss function such as @xmath5 ( classification ) , @xmath6 , kld , or quadratic mean error .    to address the first two constraints , quick feature extraction and availability , we focus in this paper on two classes of features , namely uni - bigram and word2vec features .",
    "other features may be hard to obtain such as co - citations or are not always readily available such as mesh terms .",
    "uni - bigram features do not have such issues .",
    "another popular choice is lda based topic features .",
    "however , lda features need to be generated per review and with each addition of a new batch of citations , one needs to regenerate the topics .",
    "there are several practical concerns about how many topics should be generated and the efficiency of generating the lda model .",
    "therefore , we use word2vec based features as it captures the semantic similarity between words similarly to lda and once the model is built ( offline ) , the features are readily available . on the other hand , for the data - imbalance constraint ,",
    "i.e. , irrelevant citations are more common than the relevant ones , we evaluate algorithms that have the potentials to address this problem , namely @xmath7 ( cost - sensitive svm ) and @xmath8 ( svm with multivariate performance measure ) .",
    "this will allow us to get more insights on the applicability of these algorithmic approaches to tackle the data imbalance issue .",
    "we should also note that svm - based approaches have less parameters to tune compared to others such as random forests .",
    "it is worth mentioning that a recent systematic review of current approaches in abstract screening  @xcite reported that among the @xmath9 publications it surveyed , only @xmath10 report about @xmath11 , @xmath12 report about @xmath13 , and @xmath14 about @xmath6 .",
    "the non - overlapping usage of these metrics makes it difficult to draw a conclusion about the different methods .",
    "for example , if a particular work only reports @xmath11 but not @xmath13 , it is hard to understand its applicability .",
    "moreover , recent works  @xcite suggest studying the variability of the reported metrics and advocate using a large number of repetitions ( @xmath15 ) to make the conclusions more reproducible .",
    "table  [ tab : summary ] characterizes most of the existing approaches in terms of their most important aspects . in particular , we observe that most of the studies have been performed on a small number of reviews , the evaluation is reported with different metrics , the cross validation uses a very small number of repetitions , and most of the approaches did not perform proper statistical significant tests .    in this paper",
    ", using a large set of systematic reviews , we conduct an extensive evaluation of several classification methods , along with different feature representations , which have the potential to address the above constraints .",
    "this would give us insights on the best approach to adopt for abstract screening in a practical systematic review platform .",
    "we also present such an approach as a consequence of our evaluation . more specifically",
    ", we make the following contributions :    1 .",
    "we use a large sample of reviews ( @xmath0 , most of them were collected from an existing abstract screening platform : rayyan ) 2 .",
    "we evaluate @xmath12 different methods and report on @xmath1 different metrics 3 .",
    "we perform a @xmath2x@xmath3 cross validation 4 .",
    "we apply a 2-factor anova analysis with a paired t - test and group the equivalent methods .",
    "we present an ensemble method that present prediction results through a @xmath4-star rating method .",
    "the remainder of this paper is organized as follows . in section  [ sec : rel_work ] , we discuss related work . in section  [",
    "sec : method ] , we detail the svm based methods used in the evaluation .",
    "section  [ sec : exp_result ] presents the experimental results .",
    "section  [ sec:5-star ] details the proposed @xmath4-star rating method .",
    "we conclude in section  [ sec : conclusion ] .",
    "@lp5cm@ & * related studies * + feature space representation & uni , bigram , mesh  @xcite , lda  @xcite , uni + cite  @xcite + algorithm & svm based  @xcite , others  @xcite + cross validation & 5@xmath162  @xcite , 10-fold  @xcite + no . of reviews used & 15  @xcite , 6  @xcite , 18  @xcite , 3  @xcite , 1  @xcite + statistical testing & post - hoc paired wilcoxon test  @xcite , rank group  @xcite + reported metric & auc  @xcite , utility  @xcite , burden  @xcite , yield  @xcite , wss  @xcite , precision  @xcite , recall  @xcite , f1  @xcite +",
    "we divide the related work into four groups : 1 )  work on  abstract screening \" methods , 2 )  discussion of  data imbalance \" as it is one of the main issues in the abstract screening process , 3 )   active learning \" a a popular method to address data imbalance issue , and 4 )   linear review \" , from the legal domain , which bears some similarity with abstract screening in systematic reviews .",
    "a large body of past research has focused on automating the abstract screening process  @xcite . in terms of feature representation ,",
    "most of the existing approaches  @xcite use unigram , bigram , and mesh ( medical subject headings ) .",
    "an alternative to the mesh terms is extracting lda based latent topics from the titles along with the abstracts and using them as features  @xcite .",
    "other methods  @xcite utilize external information as features , such as citations and co - citations . in terms of methods ,",
    "svm - based learning algorithms are commonly used  @xcite . according to a recent study  @xcite ,",
    "@xmath17 different types of algorithms have been proposed in systematic reviews including svm , decision trees , naive bayes , @xmath18-nearest neighbor , and neural networks . to the best of our knowledge , for abstract screening",
    ", past works did not use the structured output version of svm ( @xmath8 ) with different loss functions . @xmath8",
    "@xcite can learn faster than svm .",
    "for prediction , it only keeps feature weights and thus the prediction module becomes very fast . on the other hand , as transductive learning  @xcite takes both the labeled and unlabeled citations into account , the corresponding learning algorithm is slower than @xmath8  @xcite .",
    "data imbalance in supervised classification is a well studied problem  @xcite .",
    "two different kinds of approaches have been proposed to solve it .",
    "the first focuses on designing loss functions : kld  @xcite , quadratic mean  @xcite , cost sensitive classification  @xcite , mean average precision  @xcite , random forest  @xcite with meta - cost , and auc  @xcite .",
    "the second kind generates synthetic data for artificially balancing the ratio of labeled relevant and irrelevant citations .",
    "the example of such methods are borderline - smote  @xcite , safe - level - smote  @xcite , and oversampling of the minority class along with undersampling the majority class .",
    "the authors in  @xcite use probability calibration techniques . in this paper",
    ", we evaluate the algorithmic approaches rather than the data centric approaches or methods based on probability calibration since synthetic data generation is computationally intensive  generating data in extreme imbalance becomes quite difficult .",
    "besides , for probability calibration we need a validation set that might not be always available in such kind of abstract screening process .      as systematic reviews are done in batches , the problem of abstract screening can be modeled as an instance of batch mode active learning . online learning trains the classifier after adding every citation whereas batch - mode active learning ( bal ) does the same after adding batches of citations .",
    "however , bal does not have any theoretical guarantee compared to online learning  @xcite .",
    "the task of bal is to select batches with informative samples ( citations ) that would help learn a better classification model .",
    "there are two popular methods to select samples : ( 1 )  certainty based and ( 2 )  uncertainty based . in certainty based methods , ",
    "most certain \" samples are selected to train the classifier , while in uncertainty based method ,  most uncertain \" ones are selected . in the uncertainty sampling - based methodologies , a large number of uncertainty metrics have been proposed ; examples include entropy  @xcite , smallest - margin  @xcite , least confidence  @xcite , committee disagreement  @xcite , and version space reduction  @xcite . using  most uncertain \" samples based on these metrics improve the quality of the classifier to find the best separating hyperplane , and thus to improve its accuracy in classifying new instances  @xcite . on the other hand , certainty based methods",
    "have also been shown to be effective to carry out active learning on imbalanced data sets , as demonstrated in  @xcite .      a very similar review system that is popular among law firms is technology assisted linear review ( tar )  @xcite .",
    "the main objectives of both review systems are very similar .",
    "tar is used to save time of the attorneys to screen relevant documents rather than on the irrelevant ones .",
    "generally the number of documents are huge ( millions ) compared to the same in systemtic review , and , so active learning becomes a popular method .",
    "however , unlike systematic reviews , tar researchers are interested in finding a good stabilization point  finding a point , where the training of the classifier should be stopped .",
    "moreover , in tar , achieving at least 75% recall is considered as acceptable , whereas in systematic reviews 95%-100% recall is desirable .",
    "for abstract screening , we have title ( @xmath19 ) and abstract ( @xmath20 ) for a set of @xmath21 citations , @xmath22 .",
    "we represent each citation , @xmath23 as a tuple @xmath24 : @xmath25 is a @xmath26-dimensional feature space representation of the citation and @xmath27 is a binary label denoting whether @xmath28 is relevant or not . additionally , we use the following notations throughout the paper .",
    "we use @xmath29 and @xmath30 for the labeled and unlabeled set of citations , respectively ; @xmath31 to represent features for a set of citations ; @xmath32 for the hypothesis or hyperplane learned by training on @xmath29 ; and @xmath33 for the latent space representation for a particular word , @xmath34 . in this section",
    ", we describe the feature space representation and the methods for evaluation of automated abstract screening system .    [",
    "cols=\"<,<\",options=\"header \" , ]",
    "automating the production of systematic reviews will be crucial in delivering the promise of evidence - based medicine .",
    "an key task in this process is sifting through hundreds to thousands of citations and identifying relevant studies for further analysis . in this paper",
    ", we studied the most popular classification methods employed in this task .",
    "we focus on the methods that better fit the constraints of a practical system for abstract screening . in all",
    ", we report on 18 methods on a very large number of reviews ( 61 ) using 11 metrics .",
    "there is no single  winner \" or best method  various methods perform well on different prevalence groups and for different metrics .",
    "for instance , word2vec row with @xmath8 ( auc ) seems to be a good choice , outperforming the other methods in five metrics but is not doing well for a few other metrics .",
    "we also observe that in an active learning setting , a very large portion of included citations can be easily found with few iteration",
    ". however , one or two citations have some outlying behavior and requires much more iterations to be found .",
    "we also presented an ensemble method that combines three of the methods we evaluated and convert their scores into a 5-star rating system through a voting mechanism and rank citations based on their graded relevance .",
    "the goal is to help reviewers better manage their time ; a @xmath4-star citation might be relevant with high probability and need more attention whereas a @xmath35-star citation might be irrelevant with high probability and thus need less attention .    as a future work",
    ", we plan to look at different approaches to combine methods as well look more carefully at the outlying citations and how they can be screened with less iterations .    10 t.  c. chalmers , h.  smith , b.  blackburn , b.  silverman , b.  schroeder , d.  reitman , and a.  ambroz , `` a method for assessing the quality of a randomized control trial , '' _ controlled clinical trials _ , vol .  2 , no .  1 ,",
    "pp . 3149 , 1981 .",
    "sense - about - science .",
    "( 2009 , november ) sense about systematic reviews .",
    "[ online ] .",
    "l.  s. uman , `` systematic reviews and meta - analyses , '' _ journal of the canadian academy of child and adolescent psychiatry _ , vol .",
    "20 , no .  1 , p.  57",
    ", 2011 .",
    "s.  agarwal and d.  roth , `` learnability of bipartite ranking functions , '' in _ learning theory_.1em plus 0.5em minus 0.4emspringer , 2005 , pp .",
    "balcan , n.  bansal , a.  beygelzimer , d.  coppersmith , j.  langford , and g.  b. sorkin , `` robust reductions from ranking to classification , '' _ machine learning _ , vol .",
    "72 , no . 1 - 2 , pp .",
    "139153 , 2008 .",
    "a.  omara - eves , j.  thomas , j.  mcnaught , m.  miwa , and s.  ananiadou , `` using text mining for study identification in systematic reviews : a systematic review of current approaches , '' _ systematic reviews _ ,",
    "vol .  4 , no .  1 , p.  1 , 2015 .",
    "t.  raeder , _ evaluating and maintaining classification algorithms_. 1em plus 0.5em minus 0.4emuniversity of notre dame , 2012 .",
    "t.  raeder , t.  r. hoens , and n.  v. chawla , `` consequences of variability in classifier performance estimates , '' in _ 2010 ieee 10th international conference on data mining ( icdm ) _ , 2010 , pp .",
    "421430 .",
    "k.  ambert , `` a prospective evaluation of an automated classification system to support evidence - based medicine and systematic review , '' vol .",
    "2010 , p. 121",
    ", 2010 .",
    "y.  mo , g.  kontonatsios , and s.  ananiadou , `` supporting systematic reviews using lda - based document representations , '' _ systematic reviews _ ,",
    "vol .  4 , no .  1 , p.  1 , 2015 .",
    "m.  khabsa , a.  elmagarmid , i.  ilyas , h.  hammady , and m.  ouzzani , `` learning to identify relevant studies for systematic reviews using random forest and external information , '' _ machine learning _ , pp . 118 , 2015 .",
    "m.  miwa , j.  thomas , a.  omara - eves , and s.  ananiadou , `` reducing systematic review workload through certainty - based screening , '' _ journal of biomedical informatics _",
    "51 , pp . 242253 , 2014 .",
    "a.  m. cohen , k.  ambert , and m.  mcdonagh , `` studying the potential impact of automated document classification on scheduling a systematic review update , '' _ bmc medical informatics and decision making _ , vol .",
    "12 , no .  1 ,",
    "p.  1 , 2012 .",
    "b.  k. olorisade , e.  de  quincey , o.  brereton , p.  andras _ et  al .",
    "_ , `` a critical analysis of studies that address the use of text mining for citation screening in systematic reviews , '' 2016 .    a.  m. cohen , `` optimizing feature representation for automated systematic review work prioritization , '' in _ amia annual symposium proceedings _ , vol .",
    "2008 , 2008 , p. 121 .",
    "a.  m. cohen , w.  r. hersh , k.  peterson , and p .- y .",
    "yen , `` reducing workload in systematic review preparation using automated citation classification , '' _ journal of the american medical informatics association _ , vol .  13 , no .  2 , pp .",
    "206219 , 2006 .",
    "s.  hempel , k.  d. shetty , p.  g. shekelle , l.  v. rubenstein , m.  s. danz , b.  johnsen , and s.  r. dalal , `` machine learning methods in systematic reviews : identifying quality improvement intervention evaluations , '' 2012 .",
    "b.  c. wallace , k.  small , c.  e. brodley , and t.  a. trikalinos , `` active learning for biomedical citation screening , '' in _ proceedings of the 16th acm sigkdd international conference on knowledge discovery and data mining _",
    ", 2010 , pp . 173182 .",
    "t.  joachims , `` a support vector method for multivariate performance measures , '' in _ proceedings of the 22nd international conference on machine learning _",
    ", 2005 , pp . 377384 .",
    " , `` transductive inference for text classification using support vector machines , '' in _ icml _ , vol .  99 , 1999 , pp . 200209",
    ".    s.  shalev - shwartz , y.  singer , n.  srebro , and a.  cotter , `` pegasos : primal estimated sub - gradient solver for svm , '' _ mathematical programming _",
    "127 , no .  1 ,",
    "pp . 330 , 2011 .",
    "c.  c. aggarwal , _ data classification : algorithms and applications_. 1em plus 0.5em minus 0.4emcrc press , 2014 .",
    "y.  sun , h.  deng , and j.  han , `` probabilistic models for text mining , '' in _ mining text data_.1em plus 0.5em minus 0.4emspringer , 2012 , pp .",
    "259295 .",
    "a.  esuli and f.  sebastiani , `` optimizing text quantifiers for multivariate loss functions , '' _ acm transactions on knowledge discovery from data ( tkdd ) _ , vol .  9 , no .  4 , p.  27",
    ", 2015 .",
    "w.  liu and s.  chawla , `` a quadratic mean based supervised learning model for managing data skewness . '' in _ sdm _ , 2011 , pp .",
    "188198 .    c.  elkan ,",
    "`` the foundations of cost - sensitive learning , '' in _ international joint conference on artificial intelligence _ , vol .  17 , no .  1 , 2001 , pp . 973978 .",
    "y.  yue , t.  finley , f.  radlinski , and t.  joachims , `` a support vector method for optimizing average precision , '' in _ proceedings of the 30th annual international acm sigir conference on research and development in information retrieval _ , 2007 , pp .",
    "271278 .",
    "c.  chen , a.  liaw , and l.  breiman , `` using random forest to learn imbalanced data , '' _ university of california , berkeley _ , 2004 .",
    "h.  han , w .- y .",
    "wang , and b .- h .",
    "mao , `` borderline - smote : a new over - sampling method in imbalanced data sets learning , '' in _ advances in intelligent computing _ , 2005 , pp .",
    "878887 .    c.  bunkhumpornpat , k.  sinapiromsaran , and c.  lursinsap ,",
    "`` safe - level - smote : safe - level - synthetic minority over - sampling technique for handling the class imbalanced problem , '' in _ advances in knowledge discovery and data mining _ , 2009 ,",
    "475482 .",
    "b.  c. wallace and i.  j. dahabreh , `` improving class probability estimates for imbalanced data , '' _ knowledge and information systems _ , vol .",
    "41 , no .  1 ,",
    "pp . 3352 , 2014 .",
    " , `` class probability estimates are unreliable for imbalanced data ( and how to fix them ) , '' in _ 12th international conference on data mining _ , 2012 , pp . 695704 .",
    "a.  niculescu - mizil and r.  caruana , `` predicting good probabilities with supervised learning , '' in _ proceedings of the 22nd international conference on machine learning _ , 2005 , pp .",
    "625632 .",
    "s.  tong and d.  koller , `` support vector machine active learning with application to text classification , '' vol .  2 , 2001 , pp .",
    "s.  hanneke , `` theory of active learning , '' 2014 .",
    "i.  dagan and s.  p. engelson , `` committee - based sampling for training probabilistic classifiers , '' in _ proceedings of the twelfth international conference on machine learning _ , 1995 , pp .",
    "150157 .",
    "t.  scheffer , c.  decomain , and s.  wrobel , `` active hidden markov models for information extraction , '' in _ advances in intelligent data analysis_.1em plus 0.5em minus 0.4emspringer , 2001 , pp .",
    "309318 .",
    "a.  culotta and a.  mccallum , `` reducing labeling effort for structured prediction tasks , '' in _ aaai _ , 2005 , pp .",
    "746751 .",
    "h.  s. seung , m.  opper , and h.  sompolinsky , `` query by committee , '' in _ proceedings of the fifth annual workshop on computational learning theory_.1em plus 0.5em minus 0.4emacm , 1992 , pp .",
    "287294 .",
    "r.  nowak , `` noisy generalized binary search , '' in _ advances in neural information processing systems _ , 2009 , pp .",
    "13661374 .",
    "j.  fu and s.  lee , `` certainty - enhanced active learning for improving imbalanced data classification , '' in _ data mining workshops ( icdmw ) , 2011 ieee 11th international conference on_.1em plus 0.5em minus 0.4emieee , 2011 , pp . 405412 .",
    "h.  l. roitblat , a.  kershaw , and p.  oot , `` document categorization in legal electronic discovery : computer classification vs. manual review , '' _ journal of the american society for information science and technology _ , vol .",
    "61 , no .  1 ,",
    "pp . 7080 , 2010 .",
    "m.  gabriel , c.  paskach , and d.  sharpe , `` the challenge and promise of predictive coding for privilege , '' in _",
    "icail 2013 desi v workshop _ , 2013 .",
    "d.  w. henry , `` predictive coding : explanation and analysis of judicial impact and acceptance compared to established e - commerce methodology , '' http://www.dwhenry.com/files/predictive%20coding.pdf , [ online;accessed 23-june-2015 ] .",
    "m.  r. grossman and g.  v. cormack , `` technology - assisted review in e - discovery can be more effective and more efficient than exhaustive manual review , '' _ rich .",
    "jl & tech .",
    "_ , vol .",
    "17 , p.  1 , 2010 .    c.  glossary , `` the grossman - cormack glossary of technology - assisted review , '' _ federal courts law review _ ,",
    "vol .  7 , no .  1 , 2013 .    t.  k. saha , m.  al  hasan , c.  burgess , m.  a. habib , and j.  johnson , `` batch - mode active learning for technology - assisted review , '' in _ big data ( big data ) , 2015 ieee international conference on_.1em plus 0.5em minus 0.4emieee , 2015 , pp . 11341143 .",
    "t.  mikolov , i.  sutskever , k.  chen , g.  s. corrado , and j.  dean , `` distributed representations of words and phrases and their compositionality , '' in _ advances in neural information processing systems _ , 2013 , pp .",
    "31113119 .",
    "r.  ehuek and p.  sojka , `` software framework for topic modelling with large corpora , '' in _ proceedings of the lrec 2010 workshop on new challenges for nlp frameworks_.1em plus 0.5em minus 0.4emelra , 2010 , pp .",
    "t.  joachims , `` training linear svms in linear time , '' in _ proceedings of the 12th acm sigkdd international conference on knowledge discovery and data mining_.1em plus 0.5em minus 0.4emacm , 2006 , pp .",
    "217226 .",
    "m.  s. cohen  am , `` rmeq : a tool for computing equivalence groups in repeated measures studies . in : linking literature , '' in _ information and knowledge for biology : proceedings of the biolink2008 workshop _",
    "@xmath36 + fvote = @xmath37 + norm = @xmath38 + @xmath39 = @xmath40 +    algorithm  [ alg : gc ] helps the already classified citations to preseent in a ranked manner based on the scores ( obtained by calculating distance from hyperplanes ) .",
    "algorithm  [ alg : gc ] takes separation threshold ( st ) and max range ( mr ) as a parameter .",
    "st is used to define separation between ratings .",
    "we use @xmath41 as st .",
    "mt is used for range normalization of a rank score between @xmath42 .",
    "step  1 gets the number of unlabeled citations .",
    "step  2 and step  3 define fvote and norm as a lambda function . both of them are used to transform ranks into a specified range .",
    "fvote smooths any value between @xmath43 .    in step  4 , we get ranks for each of the scores @xmath44 .",
    "the higher the distance is from the hyperplane for a particular citation , the higher the rank .",
    "steps @xmath4-@xmath45 are used for calculating the final combined score .",
    "we iterate through all the scores in order .",
    "the very first hypothesis has the supreme power .",
    "if it predicts a particular citation as relevant , then the citation is rated between @xmath46 to @xmath4 star , and if it predicts as irrelevant , then the same gets a @xmath35 or @xmath3 star . in step 6 ,",
    "we get the vote from the dominant classifier i.e. if the score is greater than the classifier threshold then the vote count increases by @xmath35 .",
    "the rank score and the fractional vote are obtained in steps @xmath47 and @xmath48 .",
    "the number of vote ( @xmath49 ) only increases if both the dominant classifier and the current hypothesis vote as relevant . on the other hand ,",
    "the number of vote decreases if the both of them agree on its irrelevancy .",
    "finally , in step 14 , we get a normalize rank between @xmath35 to @xmath50 .",
    "if the number of votes is greater than or equal to @xmath35 then fractional vote is considered as the final vote otherwise the negative votes are used unchanged .",
    "this ensures that even if a particular citation gets postive votes , it still needs to get top rank to maintain its position in the rating .",
    "we use @xmath41 , @xmath51 , @xmath52 , @xmath53 and @xmath54 as a value for the parameters : st , mr , threshold for * relrank *  ( @xmath46-star ) , * relrank *  ( @xmath55-star ) , and * relrank *  ( @xmath4-star ) .    *",
    "example : * for example , if we decide that a @xmath4 starred citation needs to reside in the top @xmath56 of the whole set then it has to get at least @xmath57 fractional vote from each hypothesis . it gets a score of @xmath58 = @xmath59 . if the separation threshold is @xmath41 then it recieves a score of @xmath60 . from the normalized score",
    ", it gets @xmath61 = @xmath62 .",
    "so , the final score becomes greater than @xmath54 .",
    "hence , we can set a threshold of @xmath54 for the @xmath4 star rating . to be more conservative",
    "we can set a high threshold .",
    "the maximum score a citation can get is @xmath63 = @xmath64 ."
  ],
  "abstract_text": [
    "<S> a major task in systematic reviews is abstract screening , i.e. , excluding , often hundreds or thousand of , irrelevant citations returned from a database search based on titles and abstracts . </S>",
    "<S> thus , a systematic review platform that can automate the abstract screening process is of huge importance . </S>",
    "<S> several methods have been proposed for this task . </S>",
    "<S> however , it is very hard to clearly understand the applicability of these methods in a systematic review platform because of the following challenges : ( 1 )  the use of non - overlapping metrics for the evaluation of the proposed methods , ( 2 )  usage of features that are very hard to collect , ( 3 )  using a small set of reviews for the evaluation , and ( 4 )  no solid statistical testing or equivalence grouping of the methods . in this paper </S>",
    "<S> , we use feature representation that can be extracted per citation . </S>",
    "<S> we evaluate svm based methods ( commonly used ) on a large set of reviews ( @xmath0 ) and metrics ( @xmath1 ) to provide equivalence grouping of methods based on a solid statistical test . </S>",
    "<S> our analysis also includes a strong variability of the metrics using @xmath2x@xmath3 cross validation . </S>",
    "<S> while some methods shine for different metrics and for different datasets , there is no single method that dominates the pack . </S>",
    "<S> furthermore , we observe that in some cases relevant ( included ) citations can be found after screening only 15 - 20% of them via a certainty based sampling . a few included citations present outlying characteristics and can only be found after a very large number of screening steps . finally , we present an ensemble algorithm for producing a @xmath4-star rating of citations based on their relevance . </S>",
    "<S> such algorithm combines the best methods from our evaluation and through its @xmath4-star rating outputs a more easy - to - consume prediction . </S>"
  ]
}