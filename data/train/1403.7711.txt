{
  "article_text": [
    "manifold mcmc methods were introduced in @xcite and were shown to be effective for challenging target distributions with complex local - correlation structures . furthermore , mcmc methods robust in high dimensions",
    "have been recently developed ( see e.g. @xcite ) for important statistical models giving rise to targets defined as change of measures from gaussian laws in infinite dimensions .",
    "this work aims to develop new mcmc algorithms with the objective of joining strengths from the two directions of recent methodological progress .",
    "the new methodology will be illustrated on a model structure involving a diffusion process observed with ( small ) error .",
    "this simple example has been selected to clearly showcase the effect of the new method , as the infinite - dimensional aspect of the mcmc algorithm will deal with the high - dimensionality of the diffusion path , while its manifold aspect will provide a principled mechanism for driving proposed diffusion paths close to the data .",
    "we will focus on the manifold metropolis - adjusted langevin algorithm ( mmala ) of @xcite . on the infinite - dimensional side , the methods in , e.g. , @xcite are relevant for targets @xmath0 defined as change of measures from gaussian laws , i.e. : @xmath1 where @xmath2 is a separable hilbert space equipped with the inner product @xmath3 , @xmath4 a gaussian distribution on @xmath2 of mean @xmath5 and covariance @xmath6 , and @xmath7 .",
    "see e.g. @xcite for a treatment of gaussian laws on general hilbert spaces .",
    "the approaches in @xcite are effective in the case when @xmath2 is infinite - dimensional since - upon finite - dimensional projection and selection of some relevant mesh size - they provide algorithms of _ mesh - free _ mixing time , separating themselves from standard mcmc algorithms for which mixing time deteriorates with increasing dimension ( see e.g. @xcite )",
    ". the contribution of this paper will be to combine the manifold and infinite - dimensional methods , thus deriving new algorithms that could unify the positive computational effects of these two approaches . the main algorithm developed in this paper",
    "will be assigned the label @xmath8-mmala ( the label @xmath8-mala will be used for the infinite - dimensional mala of @xcite ; recall that mmala refers to the manifold method ) .",
    "the structure of the paper is as folllows . in section [ sec : algorithm ] we develop @xmath8-mmala and state conditions under which it is well - defined in infinite dimensions . in section [ sec :",
    "example ] we show numerical results from applying @xmath8-mmala on a diffusion - driven model . in section [ sec : directions ] we discuss further directions .",
    "we focus mainly on the practicalities of the derivation of the algorithm and avoid technicalities .",
    "therefore , we will not discuss here the notion of differentiation ( denoted by @xmath9 ) in general hilbert spaces or the well - posedness of the langevin stochastic differential equation ( sde ) below or its manifold version on arbitrary hilbert spaces .",
    "the reader could simply assume that the development of the algorithm happens on some @xmath10-dimensional projection of the infinite - dimensional target @xmath0 , for some large @xmath11 , so that the state - space is the euclidean @xmath12 .",
    "mathematical rigor will be applied when defining the final algorithm ( involving the easier to handle time - discretised sde dynamics ) .",
    "so , @xmath0 is used interchangeably below to denote both the infinite - dimensional target and the @xmath10-dimensional projection ; a similar convention is applied for other related notions , e.g.  for @xmath13 . also , from the definition of @xmath0 in ( [ eq : pi ] ) we have ( in a formal sense , in the case of general hilbert spaces ) : @xmath14 where we have set @xmath15 .",
    "mmala utilizes the dynamics of the langevin sde on the manifold space generated by a chosen metric tensor @xmath16 .",
    "its expression is as follows : @xmath17 with @xmath18 corresponding to differentiation along the manifold and @xmath19 denoting infinitesimal increments of a brownian motion on the manifold space . in agreement with the comments above , for",
    "all practical purposes one can assume that the state - space is @xmath20 , so that @xmath21 is assumed to be a symmetric positive - definite matrix in @xmath22 . using the analytical expressions from @xcite we can equivalently re - express ( [ eq : msde ] ) in terms of the following more familiar sde on euclidean space : @xmath23 with @xmath24 now denoting increments of standard brownian motion and @xmath25 is the determinant of @xmath16 .",
    "the langevin sde ( [ eq : sde ] ) will now be time - discretised to provide a proposal in a metropolis - hastings framework .",
    "the two algorithms , mmala and @xmath8-mala are now specified as follows :    * mmala : it applies the standard euler finite - difference scheme to time - discretise the dynamics ( [ eq : sde ] ) . for current position",
    "@xmath26 , this will provide a proposed transition to , say , @xmath27 , accepted or rejected according to the related metropolis - hastings ratio .",
    "this algorithm will typically not be well - defined in infinite - dimensions .",
    "* @xmath8-mala : in this case @xmath28 , so the drift function in ( [ eq : sde ] ) becomes : @xmath29 @xmath8-mala employs a semi - implicit discretisation scheme , where the linear term @xmath26 in the drift is replaced by with @xmath30 when applying finite differences . solving w.r.t .",
    "@xmath27 delivers a proposal of positive acceptance probability even in infinite dimensions ( under conditions ) .",
    "this is because due to the semi - implicit scheme , and under weak conditions on @xmath31 , @xmath13 , the distributions of @xmath32 and @xmath33 are absolutely continuous w.r.t .",
    "each other , thus allowing for a non - zero metropolis - hastings ratio .",
    "we will discuss this also in the sequel , as @xmath8-mmala will require some of the tools used for the development @xmath8-mala",
    ".      we will in fact opt for a simplified version of the dynamics in ( [ eq : sde ] ) , with the objective of combining designated moves with computational efficiency . as already noted in @xcite most of the strength of the manifold method",
    "is captured by the dynamics that only involve the term @xmath34 in the drift function .",
    "calculation of the removed christofell symbols is typically expensive ( of the order of @xmath35 ) and could eradicate in the balance their effect on improved mixing .    guided by the semi - implicit idea behind @xmath8-mala",
    ", we introduce a time - discretisation scheme which possesses the critical property of giving rise to a well - posed algorithm in infinite - dimensions .",
    "the scheme is as follows ( we add / subtract @xmath36 in the drift and apply an implicit scheme in one term ) : @xmath37 for a step - size @xmath38 , which can equivalently be written as : @xmath39 where we have defined : @xmath40 notice that the choice @xmath41 will deliver @xmath8-mala .",
    "equation ( [ eq : proposal ] ) provides the proposal for @xmath8-mmala upon which we will apply the metropolis - hasting acceptance rule . in section [ sub : acc ] below we give the expression for the acceptance probability of proposal ( [ eq : proposal ] ) on the infinite - dimensional space @xmath2 .",
    "following @xcite , an often effective approach is to choose the metric tensor as the expected fisher information ( we write @xmath42 to emphasize dependence of @xmath31 on some data @xmath43 ) : @xmath44 +   l \\   .\\nonumber\\end{aligned}\\ ] ] used in the context of high - dimensional @xmath45 , this can sometimes lead to prohibitive computations as an order of @xmath10 .",
    "thus , for a given class of target distributions one could try to balance improved mixing due to a good choice of @xmath16 with computational considerations , and maybe opt for a convenient proxy of the expected fisher information ( or the observed fisher information , or other tensor understood to be appropriate in a given scenario ) .",
    "our objective is to show that the acceptance ratio is non - trivial when working on an infinite - dimensional hilbert space @xmath2 .",
    "we denote by @xmath46 the transition probability measure corresponding to @xmath8-mmala proposal ( [ eq : proposal ] ) . as shown in @xcite for @xmath8-mala , a deviation from standard proofs of invariance for metropolis - hastings kernels",
    "is that there is typically no common dominating measure for the probability measures @xmath46 over all @xmath47 .",
    "so , one has to resort to a generalised definition of the metropolis - hastings ratio in @xcite .",
    "following @xcite , one has to seek for conditions so that - for @xmath48 , in stationarity - the laws of @xmath32 and @xmath33 are absolutely continuous w.r.t .",
    "each other ( we use the symbol @xmath49 to denote such a relation between probability laws ) ; then , their radon - nikodym derivative provides the metropolis - hastings acceptance ratio .",
    "more analytically , we define the bivariate probability measure on @xmath50 : @xmath51 and the corresponding symmetric measure @xmath52 . following @xcite , if @xmath53 then the metropolis - hastings acceptance probability is non - trivial and equal to : @xmath54 thus , we will specify conditions under which @xmath53 and find @xmath55 .",
    "the derivation below has connections with the one in @xcite for @xmath8-mala . to demonstrate well - posedness of @xmath8-mmala in infinite dimensions we need some assumptions .",
    "[ ass:1 ] @xmath13-a.s . in @xmath26 , we have @xmath56 , with : @xmath57    [ ass:2 ] @xmath13-a.s . in @xmath26 ,",
    "quantity @xmath58 is an element of the cameron - martin space of @xmath59 , that is @xmath60 .",
    "@xmath61 denotes the image space of @xmath62 .",
    "the cameron - martin space of @xmath59 is comprised of all elements of @xmath2 that preserve absolute continuity of @xmath59 when translating it .",
    "in particular , we have the following result .",
    "[ eq : rd ] consider @xmath63 on @xmath2 . if @xmath64 for a constant @xmath65 , then @xmath66 with density : @xmath67    this is theorem 2.21 of @xcite .",
    "notice that we can rewrite the proposal ( [ eq : proposal ] ) as : @xmath68 let @xmath69 denote the transition probability law for the update : @xmath70 we define the reference bivariate gaussian measure : @xmath71 it is easy to check that @xmath72 is symmetric ( see @xcite for details ; this is because the sum of the squares of the scalars in front of @xmath26 and @xmath73 in ( [ eq : q ] ) is unit ) , so that @xmath74 .",
    "[ prop : n ] under assumptions [ ass:1 ] and [ ass:2 ] above , @xmath13-a.s .",
    "in @xmath26 we have that @xmath75 with density : @xmath76 & \\qquad \\quad \\exp\\big\\{\\ , \\tfrac{\\sqrt{h}}{2}\\,\\big\\langle g^{1/2}(x)s(x ) , g(x)^{1/2}\\,v \\big\\rangle -   \\tfrac{h}{8}\\,\\big|g(x)^{1/2}s(x)\\big|^2 \\,\\big\\}\\,\\times \\kappa(v;x)\\   .\\end{aligned}\\ ] ]    we use the chain rule : @xmath77 the last density is found via assumption [ ass:1 ] . for the other",
    ", we use the fact that assumption [ ass:1 ] implies that operators @xmath78 , @xmath79 have the same cameron - martin space ( see feldman - hajek theorem in @xcite ) , so that applying proposition [ eq : rd ] for @xmath80 , @xmath81 ( guaranteed to be a proper element of @xmath2 due to having @xmath82 ) will give that the first density on the rhs of ( [ eq : chain ] ) is equal to : @xmath83 the proof is now complete .    from proposition",
    "[ prop : n ] , eqs ( [ eq : ql ] ) , ( [ eq : q ] ) imply directly that @xmath13-a.s . in @xmath26",
    "we have @xmath84 , thus also @xmath85 .",
    "this essentially completes the well - posedness of @xmath8-mmala as - due to the symmetricity of @xmath72 - it implies that @xmath86 .",
    "indeed , we can find the density required in the acceptance probability ( [ eq : acc ] ) as follows .",
    "first , we find : @xmath87 where we denote by @xmath88 the inverse of the 1 - 1 mapping : @xmath89 from the definition of symmetric measures , we have that @xmath90 , thus we finally have that : @xmath91 thus , we have proven that @xmath92 with the above density .",
    "the complete @xmath8-mmala algorithm can now be summarized in table [ tab : mala ] .    ' '' ''    ' '' ''    we note that earlier works ( e.g. the recent @xcite ) have looked at @xmath8-mala for a _ constant _ metric tensor @xmath16 ; @xcite use @xmath8-mala corresponding to the choice @xmath41 for the algorithm described here .",
    "the extension to a non - constant metric tensor is non - trivial and involved : i ) the development of the discretisation scheme in ( [ eq : implicit ] ) which is not an apparent generalisation of the scheme for a constant metric tensor of the earlier works ; ii ) the analytical justification of the well - posedness in infinite - dimensions of the new algorithm .",
    "we consider an sde observed with small error .",
    "that is , we have : @xmath93 where @xmath94 denotes standard brownian motion on @xmath95 , with data points : @xmath96 for times @xmath97 , a drift @xmath98 and a mapping @xmath99 .",
    "the target here is the posterior law @xmath100 of the path @xmath101\\}$ ] given @xmath102 , which is of the general form in ( [ eq : pi ] ) with : @xmath103 @xmath13 here is the law of a brownian motion on @xmath104 $ ] started at @xmath105 .",
    "also , here @xmath106,{\\mathbb{r}})$ ] , i.e. the space of squared - integrable paths , equipped with the corresponding inner product .",
    "there are two main challenges for mcmc algorithms attempting to sample from @xmath0 .",
    "\\(a ) high - dimensionality of state space . in theory",
    ", the state space is infinite dimensional . in practice",
    ", one will typically select a large @xmath11 and apply finite - differences to obtain a vector @xmath107 corresponding to times @xmath108 for mesh - size @xmath109 .",
    "@xmath8-mala will be stable under mesh - refinement : the computational cost per step will increase as @xmath110 , but the mixing time will be @xmath111 .",
    "mmala of @xcite will deteriorate with decreasing mesh - size @xmath112 .",
    "the work e.g. in @xcite suggests that one has to choose @xmath113 to control the acceptance probability , thus giving a mixing time of @xmath114 .",
    "\\(b ) complex a - posteriori covariance structure .",
    "@xmath8-mala will deteriorate for decreasing @xmath115 as target @xmath0 gets distanced from @xmath13 , but the proposal generation mechanism still uses a covariance matrix @xmath116 that does not adjust to the complex covariance structure of the posterior characterised by small marginal variances at the times of the data and larger ones further from those .",
    "in contrast to mala , mmala accommodates for the complex a - posteriori covariance structure of the @xmath26-path .",
    "the newly developed @xmath8-mmala turns out to be robust both in increasing @xmath10 and decreasing @xmath117 .",
    "as we are interested mainly in the effect of @xmath117 at the properties of the algorithm , we will obtain the metric tensor @xmath16 by applying the expected information idea in ( [ eq : tensor ] ) only upon @xmath118 in ( [ eq : phi ] ) - this also guarantees positive - definiteness for the induced @xmath16 .",
    "thus , we have : @xmath119 for the @xmath120 tridiagonal covariance matrix of the brownian motion : @xmath121 critically for the computational properties of @xmath8-mmala , due to @xmath16 being tri - diagonal the cost per step is @xmath110 ( the same holds for mmala ) .    regarding assumptions [ ass:1 ] , [ ass:2 ] here ,",
    "note that @xmath122 corresponds to a brownian motion  @xmath73 given finite observations with error , thus clearly @xmath56 . then , @xmath61 consists of paths with @xmath123 whose @xmath124 derivative ( in a weak sense ) is in @xmath125,{\\mathbb{r}})$ ] , see e.g. @xcite .",
    "we do not present a proof here that @xmath60 , but we mention that in our runs the paths @xmath58 over the various @xmath26 s appear to be everywhere differentiable apart from the instances of the data where they are only continuous , thus everywhere differentiable in the weak sense .",
    "we applied @xmath8-mmala in the following scenario : @xmath126 we used the standard euler scheme to discretise @xmath26 with mesh - size @xmath127 , so that @xmath128 .",
    "the algorithm was initiated at a path with @xmath129 , for @xmath130 , with brownian bridges connecting these points ; this position is very far from the center of the target ( notice that the @xmath131 ` true ' @xmath132 s will be scattered around @xmath133 due to the choice of drift , and @xmath134 ) .",
    "we used step - size @xmath135 , giving average acceptance probability of @xmath136 ( this changed to @xmath137 when trying @xmath138 , in an empirical manifestation of the mesh - free mixing time of @xmath8-mmala ) .",
    "fig.[fig : traceplot ] shows two traceplots for @xmath8-mmala over @xmath139 iterations , corresponding to the position of the path @xmath26 at times @xmath140 , @xmath141 .",
    "notice that the y - axes are on the same scale , so the algorithm adjusts automatically to the different sizes of the marginal posteriors ( at @xmath140 there is an observation , thus a lot of information about @xmath142 ) .",
    "even if started far from stationarity , the algorithm converges almost instantaneously to the target distribution .",
    "-mmala steps .",
    "the left panel corresponds to @xmath142 for @xmath140 , the right panel to @xmath141 .",
    "the horizontal line on the left panel indicates the value of @xmath143 ; the black rectangle at position 2 of the y - axis highlights the initial position . ]    for comparison , we applied @xmath8-mala , mmala in the same setting .",
    "@xmath8-mala was extremely poor , as we had to use @xmath144 to get acceptance ratio of @xmath145 , as the algorithm does not adjust to the different ( a - posteriori ) scales in the target , and needed a very small @xmath146 to stay close to the data .",
    "for mmala , we had to use a step - size of @xmath147 to get average acceptance probability of @xmath148 ( reduced to @xmath149 when trying @xmath138 ) , thus it is much less efficient that @xmath8-mmala ( execution times for both mmala and @xmath8-mmala were about 40s using matlab on a standard pc ) .",
    "fig.[fig : qv ] highlights a consequence of the fundamental structural difference between @xmath8-mmala and mmala : we took an initial path pinned at the data , so @xmath150 for @xmath151 with brownian bridges in - between , and run 1,000 iterations of @xmath8-mmala and mmala with @xmath135 .",
    "the plots in fig.[fig : qv ] show the estimated quadratic variation ( qve ) of all 1,000 _ proposed _ paths for both algorithms .",
    "recall here that @xmath152 , and this quantity will converge to @xmath153 as @xmath154 . as @xmath8-mmala is well - defined in infinite - dimensions ,",
    "the estimated qv of the path is very close to the limiting one for @xmath155 ( the acceptance ratio was @xmath156 ) .",
    "in contrast , mmala gave qve s wide off the mark ; not surprisingly , all 1,000 proposed paths were rejected .",
    "s over 1,000 iterations of @xmath8-mmala ( left ) and mmala ( right ) both using step - size @xmath135 .",
    "the horizontal lines highlight the limiting qv ( equal to @xmath153 ) in infinite dimensions .",
    "mmala proposes @xmath26 s with very wrong qv - so all of them got rejected ; @xmath8-mmala is well - defined in infinite - dimensions , thus the estimated qv of the proposed @xmath26 s is very close to the limiting one ( acceptance rate @xmath156 ) . ]",
    "we presented a first attempt at merging in a principled manner recently developed manifold and infinite - dimensional mcmc algorithms .",
    "a simple sde - model served well as an example where the new method indeed combines the benefits of the two directions .",
    "we aim to further develop this line of research and clarify the potential of new algorithms in important classes of applications .",
    "some further investigations are summarised below .",
    "_ algorithmic development : _ we aim to develop a hybrid monte - carlo ( hmc ) version of @xmath8-mmala .",
    "also , other approaches for merging infinite - dimensional algorithms with manifold ones could be more appropriate in particular settings . in data assimilation ,",
    "recent works have set - up a bayesian framework in infinite - dimensions ( see e.g. @xcite and the references therein ) where information for important parameters of interest , such as the permeability field for sub - surface flow models , or the initial condition for fluid velocity dynamics , is expressed in the form of a posterior distribution defined as a change of measure from a gaussian prior .",
    "@xmath8-mala ( or a random - walk version of it ) has turned out to be overly costly in this context ( see e.g. @xcite ) as the posterior could be characterised by far more complex correlation structure than the prior .",
    "it seems very natural to develop an @xmath8-mmala in this context , by applying mmala at the low frequency components of the unknown parameters that are mostly informed by the data , and @xmath8-mala for the high - frequency ones that are mainly determined by the gaussian prior .",
    "a similar algorithmic construction could give critical computational advantages in the class of models of sdes driven by fractional brownian motion ( fbm ) , where recent attempts ( see e.g. @xcite and the references therein ) to apply mcmc have to deal with the existence of complex correlation structures among model parameters together with a high - dimensional latent driving fbm .",
    "such ideas can be relevant also for bayesian non - parametric density estimation , e.g. the logistic gaussian process prior ( see e.g.  @xcite ) .",
    "_ weakening assumptions : _ assumptions [ ass:1 ] , [ ass:2 ] seem stronger than needed for the well - posedness of @xmath8-mmala . in our example model for instance",
    "we indeed have @xmath56 for any @xmath115 , but not in the limit when @xmath157 , this maybe suggesting ( falsely , from our experiments ) that the algorithm may deteriorate as @xmath158 .",
    "the resolution is that our assumptions and proof of well - posedness could involve some more ` appropriate ' gaussian measure instead of @xmath73 , and in particular one for which its density w.r.t .",
    "@xmath122 will not be trivial as @xmath158 .",
    "such considerations are relevant beyond our example model .",
    "i thank the anonymous referee and the associate editor for useful suggestions that have improved the content of the paper .",
    "[ sec : directions ]",
    "10 natexlab#1#1url # 1`#1`urlprefix"
  ],
  "abstract_text": [
    "<S> we combine two important recent advancements of mcmc algorithms : first , methods utilizing the intrinsic manifold structure of the parameter space ; then , algorithms effective for targets in infinite - dimensions with the critical property that their mixing time is robust to mesh refinement .    manifold mcmc , metropolis - adjusted langevin algorithm , cameron - martin space , infinite dimensions . </S>"
  ]
}