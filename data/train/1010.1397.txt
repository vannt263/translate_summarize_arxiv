{
  "article_text": [
    "changes in station instrumentation , location , or observer can often induce artificial discontinuities into climatic time series .",
    "for example , united states temperature recording stations average about six station relocation and instrumentation changes over a century of operation [ mitchell ( @xcite ) ] .",
    "many of these changepoint times are documented in station histories ; however , other changepoint times are unknown for a variety of reasons .",
    "even when a changepoint time is known , one may still question whether the change instills a mean shift in series observations .",
    "this paper proposes an information based approach to the multiple changepoint identification ( segmentation ) problem .",
    "our methods are specifically tailored to climatic time series in that they allow for periodicities and autocorrelations .",
    "multiple changepoint detection procedures have been studied under the assumption that the series is driven by independent and identically distributed errors [ braun and mller ( @xcite ) , caussinus and mestre  ( @xcite ) , menne and williams ( @xcite ) ] .",
    "this is unrealistic in climate settings where observations display moderate to strong serial autocorrelation .",
    "ignoring autocorrelations can drastically alter changepoint inferences , as positive autocorrelation can be easily mistaken for mean shifts [ see berkes et al .",
    "( @xcite ) and lund et al .",
    "( @xcite ) ] .",
    "multiple changepoint methods for time series data represent a very active area of current research [ davis , lee , and rodriguez - yam ( @xcite ) , fearnhead  ( @xcite ) ] .",
    "series recorded daily or monthly also display periodic dynamics .",
    "our methods allow for seasonality by employing a time series regression model with periodic features . in short , this paper develops a multiple changepoint segmenter that applies to a variety of realistic climate series .",
    "the rest of this paper is organized as follows .",
    "section [ sec2 ] introduces the time series regression model that underlies our work .",
    "section [ sec3 ] develops an objective function for the model .",
    "the objective function is a penalized likelihood whose penalty is based on the minimum description length ( mdl ) principle .",
    "this modifies caussinus and mestre s ( @xcite ) model to allow for autocorrelation , seasonal effects , and also changes their likelihood penalty to an mdl - based penalty .",
    "each segment of our model is allowed to have a distinct mean , but the autocovariance structure of each segment is constrained to be the same .",
    "section [ sec4 ] presents a genetic - type algorithm capable of optimizing the objective function to obtain estimates of the changepoint numbers , locations , and the time series regression parameters .",
    "section [ sec5 ] presents a short simulation study for feel .",
    "section [ sec6 ] applies the methods to a century of monthly temperatures from tuscaloosa , alabama and section [ sec7 ] concludes with comments .",
    "the object under study is a time series @xmath0 governed by periodic errors and multiple level shifts .",
    "the period of the series is @xmath1 and is assumed known .",
    "the series observation during season @xmath2 , @xmath3 , of the @xmath4st cycle is denoted by @xmath5 . the time - homogeneous and periodic notation @xmath0 and @xmath6 are used interchangeably , the latter to emphasize seasonality .",
    "we index the first data cycle with @xmath7 so that the first observation is indexed by unity . for simplicity , we take @xmath8 complete cycles of observations ; specifically , the observed data are ordered as @xmath9 and @xmath10 is assumed a natural number .",
    "the model driving our work is a simple linear regression in a periodic environment : @xmath11 in ( [ regressioneq ] ) @xmath12 is a linear trend parameter that is assumed time homogeneous for simplicity ; @xmath13 is the season @xmath2 location parameter ( a detrended mean in the absence of changepoints ) .",
    "the errors @xmath14 have zero mean and are a periodically stationary series with period @xmath1 in that @xmath15 for all integers @xmath16 and @xmath17 .",
    "many climatic series have periodic second moments in the sense of ( [ defperiodic ] ) . for a sample of size",
    "@xmath18 with @xmath19 changepoints , the ordered times of the changepoints are denoted by @xmath20 .",
    "the number of changepoints and the changepoint times are considered unknown .",
    "there are @xmath21 different segments ( regimes ) during the observation record . at each changepoint time",
    ", our model allows for a mean shift in the observations .",
    "such a structure is described by @xmath22 for parameter identifiability , we take @xmath23 ; otherwise , the @xmath24 s and @xmath13 s would become confounded . for a fixed @xmath18 , the mean component @xmath25",
    "$ ] in ( [ regressioneq ] ) depends on the @xmath26 parameters @xmath27 , @xmath12 , and @xmath28 . generalizations of ( [ regressioneq ] ) are mentioned in section [ sec3 ] when we derive mdl codelengths .    to describe the time series component @xmath29",
    ", we use a causal periodic autoregression of order @xmath30 @xmath31 $ ] .",
    "such errors are the unique ( in mean square ) solution to the periodic linear difference equation @xmath32 here , @xmath33 is zero mean periodic white noise with variance @xmath34 during season @xmath2 .",
    "solutions to ( [ par ] ) are indeed periodic with period @xmath1 in the sense of ( [ defperiodic ] ) .",
    "par models are dense in the set of short memory periodic time series and parsimoniously describe many such series ; explicit expressions for many time series quantities are available for pars .    in many applications ,",
    "reference series are available .",
    "a reference series is a series of the same genre as the series to be studied ( the target series ) that serves to aid changepoint identification .",
    "for example , with the tuscaloosa temperatures examined later , series from nearby greensboro al , selma al , and aberdeen ms are available over the same period of record . by constructing a target minus reference difference series , mean",
    "shifts induced by changepoints are sometimes illuminated .",
    "when the reference series is highly positively correlated with the target series , the target minus reference series will have smaller autocorrelations than the target series at all lags ( this happens when the target and reference series have the same periodic autocovariance structure and the correlation between these two series exceeds @xmath35 at all times ) .",
    "also , the linear trend assumption is typically more plausible for target minus reference differences than the target series , as long - memory and other nonlinear features can be eliminated in the subtraction . moreover ,",
    "the seasonal mean cycle is frequently reduced or altogether eliminated in target minus reference series .",
    "drawbacks with reference series lie with additional undocumented changepoints that the reference series may introduce .",
    "algorithms aimed at resolving which series among target and multiple references is responsible for any found changepoints are now available [ see menne and williams ( @xcite ) ] , but these works do not consider seasonal features or autocorrelated errors .    note that the difference of two series governed by ( [ regressioneq ] ) again lies in ( [ regressioneq ] ) . hence , in the next three sections we simply consider a single series satisfying  ( [ regressioneq ] ) . reference series will return in section [ sec6 ] .",
    "the parameters in the model will become important later .",
    "the @xmath36 model , including the @xmath1 white noise variance parameters , has @xmath37 autocovariance parameters . for a fixed @xmath38 ,",
    "there are also the changepoint times @xmath39 and the mean shifts @xmath40 . finally , a trend component @xmath12 and the seasonal means @xmath27 are present .",
    "hence , given @xmath30 and @xmath38 , there are @xmath41 model parameters . given @xmath30 and @xmath38",
    ", we will need to estimate @xmath42 , @xmath40 , @xmath43 , @xmath12 , and all @xmath44 ) parameters .",
    "developing and optimizing an objective function for this purpose will be the subject of our next two sections .",
    "before leaving the model description , we make a comment .",
    "the model studied here allows for process changes at the changepoint times in the form of level shifts .",
    "this is reasonable in climate cases [ vincent ( @xcite ) , menne and williams ( @xcite ) , lund et al .",
    "( @xcite ) ] .",
    "in other applications such as speech recognition and finance , it may be more realistic to keep mean process levels fixed and allow the time series parameters to change at each changepoint time [ see inclan and tiao ( @xcite ) , chen and gupta ( @xcite ) , davis , lee , and rodriguez - yam ( @xcite ) ] .",
    "to fit the above model , estimates of the changepoint numbers and locations , as well as the model parameters , are needed .",
    "since different changepoint numbers refer to models with a different number of parameters , the model dimension will also need to be estimated .",
    "this is a  model selection problem .",
    "popular approaches to model selection problems include aic ( akaike information criterion ) , bic ( bayesian information criterion ) , cross - validation type methods , and mdl methods . for problems that involve the detection of regime changes ,",
    "mdl methods often provide superior empirical results [ e.g. , lee ( @xcite ) , davis , lee , and rodriguez - yam ( @xcite ) ] .",
    "this superiority is likely due to the fact that both aic and bic place the same penalty on all parameters , regardless of the nature of the parameter ( e.g. , mean shift magnitudes and changepoint times receive the same penalty ) . on the other hand , mdl methods can situationally tailor penalties for parameters of different natures , thereby accounting for whether the parameter is real or integer - valued .",
    "the mdl principle was developed by rissanen ( @xcite ) as a general method for solving model selection problems .",
    "it has roots in coding and information theories . in brief",
    ", mdl defines the best fitting model as the one that enables the best compression of the data ; for the current problem , the data are the observed  @xmath45 .",
    "there exist several versions of mdl ; the so - called two - part mdl is used here . for introductory mdl material , see hansen and yu ( @xcite ) and lee  ( @xcite ) .",
    "the rest of this section develops a two - part mdl objective function for fitting a good model . the main idea behind the two - part mdl",
    "is described as follows .",
    "first , the data @xmath45 is decomposed into two parts , the fitted candidate model and its corresponding residuals .",
    "mdl methods then calculate the total codelength ( i.e. , the amount of computer memory ) required for storing both parts as a sum of the codelength of the two parts .",
    "finally , mdl methods define the best fitting model as one that produces a minimal codelength .",
    "intuition behind mdl methods lies with why minimum codelength models are also good statistical models .",
    "essentially , it is that both good compression and good statistical models are capable of capturing regularities in the data .    to proceed , let @xmath46 denote the codelength of the object @xmath47 .",
    "also write a candidate fitted model as @xmath48 and its residuals as @xmath49 .",
    "the codelength is additive in that @xmath50 the term @xmath51 in ( [ decomp1 ] ) can be viewed as a model complexity term , while @xmath52 can be viewed as a data fidelity term .",
    "our next task is to obtain a computable expression for @xmath53 that can be minimized .",
    "we begin with the calculation of @xmath51 .",
    "an important result of rissanen ( @xcite ) is that the maximum likelihood estimate of a real - valued parameter computed from a series of @xmath18 observations ( @xmath18 is large ) can be effectively encoded with @xmath54 bits .",
    "the trend parameter @xmath12 hence requires @xmath54 bits to encode .",
    "the seasonal mean parameters @xmath13 are effectively estimated via seasonal sample means , each of which contributes @xmath55 bits to the codelength . given values of the changepoint times @xmath39 ,",
    "the mean shift parameter @xmath56 can be estimated with data from the @xmath57th segment only .",
    "hence , @xmath56 requires @xmath58 bits to encode for @xmath59 ( @xmath60 is taken as a convention ) .",
    "hence , the portion of the codelength from mean parameters in the time series regression ( i.e. , @xmath61 , and @xmath62 ) is @xmath63    the @xmath36 time series parameters [ @xmath64 for @xmath65 and @xmath34 for @xmath66 are also real valued . because @xmath14 is a zero mean process , we need only consider the zero mean version of this model . in this case , the par parameters can be estimated in an efficient manner via seasonal versions of the yule ",
    "walker equations [ see pagano ( @xcite ) ] .",
    "the necessary equations for this task are presented in shao and lund ( @xcite ) .",
    "walker par parameter estimators are asymptotically most efficient [ pagano ( @xcite ) ] ; in fact , these estimators are the likelihood estimators except for the edge - effects ( i.e. , the likelihood is conditional on the first @xmath30 observations ) . the yule ",
    "walker estimators can be computed from the sample autocovariances @xmath67 over the lags @xmath68 .",
    "the lag @xmath69 sample autocovariance at season @xmath2 is defined as @xmath70 , where @xmath71 is taken as zero should a @xmath72 be encountered in the summation .",
    "observe that @xmath73 is a  function of @xmath8 series observations for each fixed @xmath2 .",
    "moreover , @xmath74 is essentially computed from @xmath75 observations .",
    "hence , the total codelength from @xmath36 parameters is @xmath76    the parameters @xmath39 are integers and must be treated as such . arguing as in davis , lee , and rodriguez - yam ( @xcite ) , an integer parameter bounded by  @xmath77 takes @xmath78 bits to encode",
    ". since the @xmath79 s are ordered , we have @xmath80 .",
    "this differs from davis , lee , and rodriguez - yam ( @xcite ) in that we do not loosely bound @xmath81 by @xmath18 for each @xmath57 . in short ,",
    "the codelength induced by the changepoint times that we use is @xmath82    finally , the model orders @xmath30 and @xmath38 contribute @xmath83 bits to the codelength . while @xmath38 is bounded by @xmath18 , typical values of @xmath38 are significantly smaller than @xmath18 and a penalty of @xmath84 would be too much for @xmath38 changepoints .    adding ( [ piece1])([piece4 ] ) gives @xmath85 \\\\[-8pt ] \\nonumber   & & { } + \\frac{pt \\log_2(2d)}{2}+ \\sum_{j=2}^m \\log_2(\\tau_j ) + \\log_2(m ) + \\log_2(p).\\end{aligned}\\ ] ]    moving to @xmath86 , a fundamental result of rissanen ( @xcite ) is that this quantity equals the negative logarithm ( base 2 ) of the likelihood of the fitted model @xmath48 . for the present problem , this conditional likelihood can be calculated as follows .",
    "a gaussian joint density of observations from the model , denoted by @xmath87 , takes the classical innovations form modified to allow for series periodicities and level shifts at the changepoint times : @xmath88 .",
    "\\label{rawlkhd}\\ ] ] here , @xmath89 is the best one - step - ahead predictor of @xmath90 from linear combinations of a constant and @xmath91 .",
    "also , @xmath92 $ ] is the mean squared error ( unconditional ) of the one - step - ahead predictor .    the one - step - ahead prediction equations and mean squared errors for the @xmath36 setup are easily expressed : @xmath93 + \\sum_{k=1}^p \\phi_k(\\nu)(x_{nt+\\nu - k}- e [ x_{nt+\\nu - k } ] ) , \\qquad       nt+\\nu > p,\\ ] ] where @xmath94=\\mu_\\nu+ \\alpha(nt+\\nu ) + \\delta_{nt+\\nu}$ ] is the mean function .",
    "computing @xmath95 and @xmath96 for @xmath97 is done as in shao and lund ( @xcite ) .",
    "taking a negative logarithm in ( [ rawlkhd ] ) gives @xmath98    substituting ( [ comp1 ] ) and ( [ comp2 ] ) into ( [ decomp1 ] ) , we arrive at the following approximation : @xmath99.\\end{aligned}\\ ] ] because @xmath18 , @xmath8 , and @xmath1 are constant , our objective function for the model @xmath100 , denoted by @xmath101 , can be taken as @xmath102 \\\\[-8pt ] \\nonumber   & & { } + \\ln(m ) + \\ln(p)+ \\frac{1}{2 } \\sum_{t=1}^n \\ln(v_t ) + \\frac{1}{2 } \\sum_{t=1}^n \\frac { ( x_t -\\hat{x}_t)^2}{v_t}.\\nonumber\\end{aligned}\\ ] ]    mdls for variants of the model in ( [ regressioneq ] ) are worth mentioning .",
    "should one also allow the trend to change with each regime , the codelength becomes , after appropriate modification of ( [ piece1 ] ) , @xmath103 where @xmath104 is taken as a convention .",
    "if the seasonal location parameters @xmath13 are consolidated to a single @xmath105 , then an appropriate mdl ( this assumes a single trend parameter ) is @xmath106 \\\\[-8pt ] \\nonumber   & & { } + \\ln(m ) + \\ln(p ) + \\frac{1}{2 } \\sum_{t=1}^n \\ln(v_t ) + \\frac{1}{2 } \\sum_{t=1}^n \\frac { ( x_t-\\hat{x}_t)^2}{v_t},\\nonumber\\end{aligned}\\ ] ] which is ( [ mdl1 ] ) expect for the @xmath107 term added in the first summation .",
    "mdls for models where the structural form of the regression changes segment by segment are harder to quantify , but also have climate ramifications and are currently being investigated .    by an mdl model",
    ", we refer to a model @xmath108 that minimizes a mdl score over the class of models being considered .",
    "practical minimization of @xmath101 over all admissible models is not a trivial task , which brings us to our next section .",
    "first , suppose that we know @xmath30 and @xmath38 and the changepoint times @xmath39 .",
    "then computation of @xmath109 proceeds as follows .",
    "computation of the model codelength given the parameters is straightforward . for computation of the likelihood contribution to the codelength , write",
    "( [ regressioneq ] ) in the general linear models form @xmath110 in ( [ glm ] ) , @xmath111 , @xmath112 , @xmath113 , and @xmath114 is the @xmath115 design matrix @xmath116,\\ ] ] where @xmath117 is an @xmath118 dimensional seasonal indicator matrix ( all entries are zero except @xmath119 if @xmath120 for some @xmath121 ) , @xmath122 is an @xmath123 vector with @xmath124 , and @xmath125 is an @xmath126 dimensional matrix with all zero entries except @xmath127 when time @xmath16 , @xmath128 , is observed during regime @xmath57 for @xmath59 .",
    "we first estimate @xmath129 with ordinary least squares methods . from the estimated  @xmath129 , residuals of this model fit",
    "are next computed . from these residuals and a par order parameter @xmath30 , estimates of @xmath64 for @xmath3 and @xmath130 and @xmath34 for @xmath3",
    "are constructed via seasonal yule ",
    "walker moment estimation methods . with estimates of the @xmath64 s and @xmath34 s",
    ", one can return to ( [ glm ] ) and compute generalized weighted least squares estimators of @xmath129 .",
    "new residuals are computed and the process is iterated in a cochrane  orcutt fashion [ see cochrane and orcutt ( @xcite ) ] until convergence is achieved .",
    "the process gives jointly optimal estimators of @xmath129 and the @xmath64 s and @xmath34 s .",
    "typically , only several iterations are needed .",
    "the above enables us to quickly compute a codelength for fixed values of @xmath30 ,  @xmath38 , and @xmath39 .",
    "however , not counting different values of @xmath30 , there are @xmath131 different configurations of @xmath38 and @xmath39 that must be considered .",
    "in other words , the parameter space has a huge cardinality . to optimize the codelength over this parameter space",
    ", we now introduce a genetic algorithm .",
    "a genetic algorithm ( ga ) is a stochastic search that can be applied to a variety of combinatorial optimization problems [ goldberg ( @xcite ) , davis ( @xcite ) , reeves  ( @xcite ) ] .",
    "the basic principles of gas were first developed by holland  ( @xcite ) and are designed to mimic the genetic process of natural selection and evolution .",
    "gas start with an initial population of individuals , each representing a possible solution to the given problem .",
    "each individual or _ chromosome _ in the population is evaluated to determine how well it scores with respect to the objective function .",
    "highly fit individuals are more likely to be selected as parents for reproduction . in a _",
    "crossover _ procedure , the _ offspring _",
    "( _ children _ ) share some characteristics of the parents .",
    "_ mutation _ is often applied after crossover to introduce random changes to the current population with a small probability .",
    "mutation increases population diversity .",
    "the offspring are used to construct a new generation by either a generational approach ( replacing the whole population ) or a steady - state approach ( replacing a few of the less fit individuals ) .",
    "this process is repeated until an individual is found that roughly optimizes the objective function .",
    "the ga used in this study is described as follows .",
    "_ chromosome representation _ : the first step in designing a ga is to create a suitable chromosome representation for the problem . here , any individual ( model )",
    "can be described as a set of parameters : the number of changepoints @xmath38 , the order of the par model @xmath30 , and the changepoint locations @xmath39 .",
    "once these parameters are fixed , the regression parameters in the model ( [ regressioneq ] ) can be estimated using the methods described above .",
    "hence , the chromosome , denoted by @xmath132 , is an integer vector of length @xmath133 .",
    "the lengths of the chromosomes in the population depend on the number of changepoints .",
    "a minimum number of observations in each regime is set to @xmath134 to ensure that reasonable mean shift estimates are obtained in all segments . here , @xmath135 is the minimum number of cycles between adjacent changepoints",
    ". our work will take @xmath136 ( no changepoints within a year for monthly data ) .",
    "also , we impose the upper bound @xmath137 for the order of the @xmath36 model ; @xmath138 is used in the forthcoming simulation study and examples .    _ initial population generation _ : for each individual , the par order @xmath30 is first randomly selected with equal probabilities from the set @xmath139 .",
    "the changepoint numbers @xmath38 and locations are then independently simulated as follows .",
    "there is a probability @xmath140 , essentially representing the probability that any admissible time is selected as a changepoint . since there can be no changepoint before time @xmath141 , we first examine time @xmath141 , flipping a coin with heads probability @xmath140 .",
    "if the flip is heads , @xmath141 is declared to be the first changepoint ( @xmath142 ) and attention shifts to the next possible changepoint time , which is time @xmath143 .",
    "but if the flip is tails , @xmath141 is not chosen as a changepoint and we move to the next location at @xmath144 , independently flipping the coin again .",
    "the process is continued in a similar manner until the last admissible changepoint time at @xmath145 is exceeded .",
    "the population size @xmath146 is used in this study and @xmath140 is set to be @xmath147 ( six changepoints over a century ) .    _",
    "crossover _ : pairs of parent chromosomes , representing mother and father , are randomly selected from the initial population or current population by a linear ranking / selection method . that is , a selection probability is assigned to an individual that is proportional to the individual s rank in optimizing the objective function .",
    "the least fit individual is assigned the rank @xmath148 and the most fit individual is assigned the rank @xmath149 . a crossover procedure , as explained in the paragraph below ,",
    "is then applied to the parents to produce offspring for the next generation .",
    "the probability that any two parents have children , denoted by @xmath150 , is set to @xmath151 .    in our ga implementation ,",
    "only one pair of parent chromosomes is chosen from the current generation and one child is produced by `` mixing '' two parent chromosomes with a uniform crossover .",
    "this works as follows .",
    "the child s par order @xmath30 is either the mother s or the father s par order , with both being equally likely . the child s changepoint locations are randomly selected using all admissible changepoint locations from _ both _ mother and father .",
    "for example , for @xmath152 , @xmath153 , and @xmath136 , suppose the mother s chromosome has 3 changepoints at the times @xmath154 and the father s chromosome has 4 changepoints at the times @xmath155 .",
    "first , all changepoints from mother and father are mixed together and sorted from smallest to largest , yielding the string @xmath156 .",
    "we select the first changepoint of the child at @xmath157 with probability @xmath158 .",
    "if @xmath157 is selected as a changepoint , then we discard the changepoint @xmath159 ( it would violate segmentation spacing requirements ) and move to the next candidate changepoint at @xmath160 , again doing a fifty - fifty selection / inclusion randomization . if @xmath157 is not chosen as one of the child s changepoints , we move to the next changepoint at @xmath159 with the same fifty - fifty selection criterion .",
    "the child s @xmath38 is simply the number of retained changepoints .",
    "_ mutation _ : mutation is applied to the child after crossover with a constant probability @xmath161 . the probability @xmath161 is typically low ; we use @xmath162 in the following examples .",
    "the par order @xmath30 for the new chromosome produced by mutation is equal to the child s @xmath30 with a probability of @xmath158 .",
    "then changepoint locations can either take on the corresponding changepoints from the child s or be a new set randomly selected from the parameter space .",
    "mutation ensures that no solution in the admissible parameter space has a zero probability of being examined .",
    "_ new generation _ : the steady - state replacement method with a duplication check as suggested by davis ( @xcite ) is applied here to form a new generation .",
    "one advantage of the steady - state approach over the generational approach is that it typically finds better solutions faster . in our implementation of the steady - state approach , only one individual is replaced in the current generation by a child after crossover and/or mutation .",
    "this allows parents and offsprings to live concurrently , which is true for long - lived species [ beasley , bull , and martin ( @xcite ) ] .",
    "if the child is already present in the current generation , this child will be discarded and another child must be produced by the selection - crossover - mutation process .",
    "the duplication check is applied to all new children until a child is found that is not present in the current generation . in this way , duplicate solutions and premature convergence are significantly avoided .",
    "_ migration _ : migrations act to speed up convergence of the ga and can be implemented via a parallel scheme [ davis ( @xcite ) , alba and troya ( @xcite ) ] .",
    "migration also reduces the probability of premature convergence .",
    "the population is divided into several different sub - populations ( islands ) .",
    "highly fit individuals periodically migrate between the islands .",
    "the island model ga is controlled by several parameters , such as the number of islands @xmath163 , the frequency of migration @xmath164 , the number of migrants @xmath165 , and the method used to select which individuals migrate . the migration policy used here is as follow . after every @xmath164 generations , the least fit individual on island @xmath57 , @xmath166 , is replaced by the best individual on island  @xmath167 , which is randomly selected among all other islands ( @xmath168 ) .",
    "therefore , each island sends and receives individuals from different islands throughout the duration of the search process . here , we set @xmath169 , @xmath170 , and @xmath171 .    _ convergence and stopping criteria _",
    ": we follow the criterion of davis , lee , and rodriguez - yam ( @xcite ) to declare convergence and terminate the ga . if the overall best individual at the end of each migration does not change for @xmath172 consecutive migrations , then the ga is deemed to have converged to this best individual . additionally ,",
    "if the total number of migrations exceeds a predetermined maximum number @xmath173 , then the search process is terminated and the best individual in the  @xmath173th migration is taken as the optimal solution to the given problem .",
    "the parameters  @xmath172 and @xmath173 are taken as 10 and 25 in the study , respectively .",
    "this section investigates the accuracy of the above methods via simulation .",
    "this study is designed to correspond to the simulation study in caussinus and mestre ( @xcite ) .",
    "elaborating , we will simulate a thousand series and apply our methods to each series .",
    "each series contains a century ( @xmath174 ) of monthly data ( @xmath153 ) with six ( @xmath175 ) changepoints .",
    "this corresponds to the average number of changepoints over a century of operation reported in mitchell  ( @xcite ) .",
    "the changepoint mean shifts in every series occur at the times @xmath176 , @xmath177 , @xmath178 , @xmath179 , @xmath180 , and @xmath181 .",
    "the error terms  @xmath182 are simulated as a gaussian first order periodic autoregression ( @xmath183 ) with parameters @xmath184 and @xmath34 as specified in table [ tab1 ] ; the seasonal means @xmath13 are also listed in table [ tab1 ] and are in degrees celsius .",
    "these values are those that were estimated for 50 years of monthly temperatures from longmire , washington , which was studied in lund et al .",
    "( @xcite ) .",
    "the trend parameter @xmath12 was set to zero in all simulations .",
    "6cm@ld2.2d2.3c@ @xmath185 & & & @xmath186 + 1 & -0.61 & 0.272 & 2.713 + 2 & 0.99 & 0.284 & 2.748 + 3 & 2.35 & 0.478 & 1.871 + 4 & 4.91 & 0.286 & 1.717 + 5 & 8.74 & 0.335 & 2.474 + 6 & 12.15 & 0.279 & 2.403 + 7 & 15.51 & 0.245 & 2.569 + 8 & 15.47 & 0.137 & 1.910 + 9 & 12.79 & -0.127 & 2.826 + 10 & 7.82 & 0.082 & 2.488 + 11 & 2.32 & 0.196 & 2.394 + 12 & -0.25 & 0.214 & 2.256 +    the magnitude of the mean shifts @xmath187 are critical .",
    "big mean shifts make changepoints easier to detect .",
    "to facilitate interpretability , we use a common mean shift magnitude @xmath188 at all changepoint times .",
    "for instance , if the current regime has mean level @xmath189 ( trend and seasonal effects are assumed zero here ) , the next regime will have mean @xmath190 or @xmath191 , with a fifty - fifty chance of shifting up or down at each changepoint time .",
    "it follows that @xmath192 for @xmath193 .",
    "the ability of our model to detect mean shifts can be roughly quantified by the mean shift magnitude relative to the process standard deviation ( the latter averaged over a complete seasonal cycle ) .",
    "a parameter quantifying such aspects , denoted by  @xmath194 , is @xmath195 better quantifiers of changepoint detection power may well exist , but derivation of such quantities would be difficult and is tangential to our points .",
    "below , we consider three different @xmath194 values : 1.0 , 1.5 , and 2.0 .",
    "the larger @xmath194 is , the easier it is to detect changepoints .",
    "a realization of a temperature series with @xmath196 is plotted in figure [ fig1 ] for feel .",
    "6cm@ld3.3d2.3d2.3@ @xmath197 & & & + 0 & 0.1% & 0.0% & 0.0% + 1 & 12.2% & 2.6% & 0.0% + 2 & 30.1% & 10.9% & 3.7%",
    "+ 3 & 34.5% & 17.5% & 5.4% + 4 & 18.3% & 23.6% & 11.8% + 5 & 3.9% & 12.9% & 12.5% + 6 & 0.9% & 31.9% & 58.9% + 7 & 0.0% & 0.6% & 7.1% + @xmath198 & 0.0% & 0.0% & 0.6% + @xmath183 & 99.9% & & + @xmath199 & 0.1% & 0.0% & 0.0% +    table [ tab2 ] and figure [ fig2 ] summarize the results of the simulations . table [ tab2 ] reports empirical frequency distributions of the number of estimated changepoints . observe that the true value of six changepoints is obtained more frequently as @xmath194 increases . when @xmath200 , the percentage of simulations where the correct number of changepoints is estimated is 58.9% , which is better than the corresponding 43.4% reported in caussinus and mestre ( @xcite ) that applies to uncorrelated and time - homogeneous settings ( i.e. , 100 years of annual data )",
    ". in fairness , we note that the equivalent sample size of our simulated series ( the number of independent data points with the same periodic variances ) translates to more than the 100 independent data points of caussinus and mestre ( @xcite ) ( we will not quantify equivalent sample sizes further here ) .",
    "the correct number of changepoints is identified only  0.9% when @xmath201 [ this , however , is also slightly better than the corresponding result in caussinus and mestre ( @xcite ) ] .",
    "it is clear that changepoint numbers are underestimated in settings with relatively small @xmath194 .",
    "in fact , the empirical mean ( standard deviation in parentheses ) of the distributions in table [ tab2 ] are 2.74 ( 1.07 ) for @xmath201 , 4.34 ( 1.48 ) for @xmath196 , and 5.413 ( 1.20 ) for @xmath200 .",
    "overall , one sees that changepoint shift sizes are critical in changepoint detection , that the detection situation is difficult when @xmath194 is small , but that methods work reasonably well when  @xmath194 is relatively large . using monthly data ( as opposed to annual averages ) also seems to improve changepoint detection power .        as for where the changepoints are estimated to occur , figure [ fig2 ] shows histograms of the estimated changepoint locations , reporting the total number of times a changepoint",
    "is signaled at time @xmath16 for @xmath202 in the 1000 simulations .",
    "observe that the histograms have modes around the actual changepoint times .",
    "it is also evident that the changepoints at times 840 and 900 were the most difficult to detect , a feature attributed to the close proximity of the times of these two changepoints ( with the fifty - fifty up / down mean shift randomization employed , the sign of these two mean shifts differ with probability @xmath35 , in which case their detection is relatively more difficult ) .",
    "173pt@ld2.3d2.3d2.3@ @xmath197 & & & + 0 & 6.2% & 0.1% & 0.0% + 1 & 29.5% & 0.3% & 0.0% + 2 & 32.5% & 4.2% & 0.0% + 3 & 22.8% & 5.4% & 0.0% + 4 & 7.4% & 35.3% & 7.7% + 5 & 1.5% & 33.0% & 4.4% + 6 & 0.1% & 20.9% &",
    "81.7% + 7 & 0.0% & 0.8% & 6.1% + @xmath198 & 0.0% & 0.0% & 0.1% +    note that the correct autoregressive order @xmath183 was obtained virtually all of the time .",
    "hence , the time series model selection component seems to be working well . as changing",
    "the trend parameter did not appreciably affect results , we will not report separate tables with nonzero trends .",
    "we now compare the mdl penalty more closely with the caussinus  lyazrhi penalty used in caussinus and mestre ( @xcite ) .",
    "the caussinus  lyazrhi penalty is larger than aic or bic penalties , but does not penalize parameters in the mean function or consider autocorrelation aspects . to make this comparison ,",
    "1000 series of length 100 were simulated with six changepoints always occurring at the times 20 , 40 , 50 , 70 , 75 , and 85 .",
    "the mean shift size parameter @xmath194 was changed to the parameter @xmath203 in caussinus and mestre ( @xcite ) to mimic their simulations .",
    "the errors in the model were assumed to be gaussian and independent .",
    "note that the level of changepoint activity relative to the sample size has increased 12-fold from the previous simulations .",
    "table [ tab3 ] below lists estimates of the relative frequencies of changepoints found by the genetic algorithm with an mdl penalty when @xmath13 is held constant with @xmath2 .",
    "no trends were considered in this setup nor was tuning of the genetic algorithm ( varying its mutation probabilities , etc . ) considered in detail .",
    "the frequency distributions in table [ tab3 ] are approximately the same as those in caussinus and mestre ( @xcite ) , perhaps slightly worse , in all cases . for this sample size and level of changepoint activity",
    ", an mdl penalty seems to perform about the same as the caussinus ",
    "lyazrhi penalty .",
    "of course , we reiterate that some gains are made by considering monthly data in lieu of annual averages .",
    "figure [ fig3 ] plots a century of monthly data from tuscaloosa , alabama recorded from january , 1901december , 2000 .",
    "a seasonal mean cycle is visually evident in the data , but trends and mean shifts are not readily apparent . comparing the year - to - year jaggedness of the seasonal throughs ( the winter minimums ) against the year - to - year seasonal peaks ( july maximums ) , it is discerned that this series has a periodic variance with winter temperatures being much more variable than summer temperatures .",
    "in fact , as we will see , the entire autocorrelation structure of the series is periodic .",
    "the tuscaloosa series is one in which the station history is reasonably documented .",
    "in particular , a catalog ( called meta - data ) exists that notes the circumstances under which the data were recorded , including the times of station relocations and instrumentation changes .",
    "this said , meta - data files are notoriously incomplete [ menne and williams ( @xcite ) ] and `` undocumented '' changepoints may lurk .",
    "the tuscaloosa series also has a moderately clean changepoint record with only four major documented changes over a century of operation ; as noted before , the average united states temperature station experiences about six changepoints per century [ mitchell ( 1953 ) ] . in short ,",
    "the tuscaloosa is a good `` proving ground '' series for changepoint methods .",
    "level shifts in temperature series are arguably the most important factor in assessing temperature trends [ see lu and lund ( @xcite ) ] . it has been argued in climate settings that the manner in which changepoints are handled may be the most critical factor in the global warming debate . supporting this ,",
    "temperature insurance treaties on wall street are based solely on station location and gauge properties , while ignoring long - term trends altogether .",
    "our methods were applied to the tuscaloosa data .",
    "a reference series was constructed by averaging three neighboring series located at selma , al , greensboro , al , and aberdeen , ms over the century of record .",
    "we work with one reference series that averages three neighboring series to expedite the discourse ; methods that analyze all @xmath204 pairs of stations are discussed in menne and williams ( @xcite ) .",
    "first , we examine the tuscaloosa series without a reference .",
    "the fitted mdl model has two changepoints at times 460 ( april , 1939 ) and 679 ( july , 1957 ) . the mean function induced by these two changepoints , less the seasonal cycle but including the trend ,",
    "is plotted against the data in figure [ fig3 ] .",
    "the mean shift magnitudes of the 1939 and 1957 changepoints , in degrees celsius , are both negative : @xmath205 and @xmath206 .",
    "the estimated trend parameter is @xmath207 .",
    "the standard errors were estimated from the fitted time series regression model with generalized weighted least squares techniques .",
    "the estimated order of the par model is @xmath183 ; a consequence of this is that the autocovariance structure in the errors of the fitted models is indeed periodic .",
    "second , we examine the tuscaloosa minus the reference series . this seasonally adjusted difference series is plotted in figure [ fig4 ] . in this target minus reference ,",
    "four changepoints are flagged : march 1909 , december 1919 , july 1933 , and august  1990 .",
    "the estimates of the @xmath24 s are @xmath208 , @xmath209 , @xmath210 , and @xmath211 .",
    "note that a mean shift with the small magnitude of 0.26 has been flagged .",
    "the trend estimate is @xmath212 and the selected order of the autoregression is @xmath183 .",
    "observe that the fitted order of the autoregression did not reduce from that for the raw series ; that is , periodic autocorrelation still exists in the target minus reference series .",
    "also , the trend for the target minus reference series appears to be significantly negative .",
    "we comment that the two large negative values occurring in the 1940s and the 1950s appear to be decimal typos in the raw data ; that is , the monthly average temperature for tuscaloosa was entered as ten degrees too small .",
    "we make this claim after examining additional reference series from various cities close to tuscaloosa . whereas the series in this database have been quality checked to some degree",
    ", errors like this may still exist .",
    "we reran the analysis above after replacing these two values by ( 1 ) their estimated seasonal means @xmath213 and ( 2 ) what we believe are the correct values , that is , adding 10 degrees to both outliers . in both cases , four changepoints with similar magnitudes and times to the ones above",
    "are found .",
    "the 1957 changepoint flagged in the target series has not been flagged in any version of the target minus difference series .",
    "the 1909 changepoint is possibly attributed to a changepoint in the reference series : greensboro reports a time of observation change in 1906 and aberdeen reports a station relocation in 1915 .",
    "the meta - data show four changepoints in this series : the first was a station relocation in november of 1921 , the second was a station relocation in march of 1939 , the third was a station relocation during june of 1956 and an accompanying instrumentation change in november of 1956 ( we regard this as one changepoint ) , and the fourth is a station relocation and instrumentation change in may of 1987 . the reference series analysis seems to have correctly identified three of these four changepoints ( we are liberally including the 1933 flagged changepoint time as correctly identifying the 1939 changepoint ) , missing the 1956 changepoint and adding a 1909 changepoint .",
    "the raw target series analysis misses the 1921 and 1987 changepoints , but finds the 1956 changepoint ; also , the estimated time of the 1939 changepoint is much closer to its true value than that for the reference analysis .",
    "overall , it seems that the reference analysis is superior to simple target series analysis , but that one can learn something with both analyses .",
    "we caution the reader that trends in some monthly temperature series , especially when the series is aggregated over a large geographic region , may not be well described by a linear regression component .",
    "as noted by handcock and wallis  ( @xcite ) , trends at localized series are more likely to be adequately described with a simple linear structure . as a final diagnostic check ,",
    "residuals from the model fits were computed .",
    "figure [ fig5 ] shows the sample autocorrelation of the residuals for the target series over the first 60 lags .",
    "the dashed lines are 95% pointwise confidence bounds for white noise . as only three of the sample autocorrelations lie outside the bounds",
    "( and then only slightly so ) , the model appears to have fitted the data well .",
    "figure [ fig6 ] shows the periodogram of the residuals from the target minus reference series .",
    "a long memory structure is not readily evident in this plot .",
    "time series parsimony may be an issue with periodic data .",
    "specifically , the penalty in ( [ piece2 ] ) essentially assumes that the par(1 ) model requires @xmath37 distinct parameters . in practice ,",
    "changes in climate processes from season to season are slow / smooth .",
    "low order fourier series expansions , such as those in lund , shao , and basawa ( @xcite ) , can statistically simplify the model and serve to lessen the penalty for time series components .",
    "this issue is likely to be paramount should daily data be considered .",
    "comments from two referees and the editor substantially improved this paper ."
  ],
  "abstract_text": [
    "<S> this paper proposes an information theory approach to estimate the number of changepoints and their locations in a climatic time series . </S>",
    "<S> a model is introduced that has an unknown number of changepoints and allows for series autocorrelations , periodic dynamics , and a mean shift at each changepoint time . </S>",
    "<S> an objective function gauging the number of changepoints and their locations , based on a minimum description length ( mdl ) information criterion , is derived . </S>",
    "<S> a genetic algorithm is then developed to optimize the objective function . </S>",
    "<S> the methods are applied in the analysis of a century of monthly temperatures from tuscaloosa , alabama .    ,    . </S>"
  ]
}