{
  "article_text": [
    "random matrices proved their usefulness in describing the spectra of quantum systems , the classical analogues of which are chaotic @xcite .",
    "in particular , spectral properties of the evolution operator of a deterministic quantum chaotic system seem to coincide with predictions obtained for the circular ensembles of random unitary matrices .",
    "the symmetry properties of the system determine which ensemble of random matrices is applicable . specifically ,",
    "if the physical system does not possess any time - reversal symmetry , one uses random unitary matrices of the circular unitary ensemble ( cue ) .",
    "statistical predictions obtained for ensembles of random matrices are also useful in analyzing generic properties of entangled states @xcite . in the theory of quantum information",
    "one deals with composite quantum system described in a hilbert space with a tensor product structure .",
    "thus any local unitary dynamics can be represented as a tensor product of unitary matrices , each describing time evolution of an individual subsystem .",
    "consider a quantum system consisting of @xmath0 subsystems . for simplicity we shall assume that each of them is described in @xmath1 dimensional hilbert space , so that any local unitary dynamics can be written as @xmath8 , where @xmath9 for @xmath10 .",
    "if the unitary dynamics of each subsystem is generic , the matrices u@xmath11 can be represented by random matrices from the cue .",
    "the main aim of the present work is to analyze properties of the tensor product of random unitary matrices .",
    "we show that when either @xmath3 in the limit of a large number @xmath0 of subsystems , or when @xmath2 in the limit of large subsystem size @xmath1 , the point process obtained from the spectrum of @xmath12 , properly rescaled , becomes poissonian , in the sense that its correlation functions converge to that of a poisson process .",
    "this paper is organized as follows . in section",
    "[ sec : spectral_statistics ] we provide some definitions and introduce our main results , theorem [ thm.cuecue ] and [ thm.cue^ ] , and their corollaries ; we also provide numerical simulations that confirm the results .",
    "section [ sec : spectral_statistics : two_nxn ] provides the proof of theorem [ thm.cuecue ] and of corollary [ cor.cuecue ] , while section [ sec : spectral_statistics : m_2x2 ] is devoted to the proof of theorem [ thm.cue^ ] and of corollary [ cor.cue^n ] .",
    "the spectral statistics for two ensembles of unitary matrices will be the focal points of our investigation .",
    "the first case involves two unitary @xmath13 matrices , whereas in the second we consider the tensor product of @xmath0 two - dimensional unitary matrices . as usual , we are interested in spectral properties in the asymptotic limits of large matrices , i.e. , respectively , @xmath14 and @xmath15 .",
    "we recall some standard definitions and properties of some ensembles of random unitary matrices .",
    "the simplest situation is a diagonal unitary matrix with eigenvalues being independently drawn points on the unit circle .",
    "such matrices form the * circular poisson ensemble * , @xmath16 for short .",
    "the name reflects the fact that for large matrices the number @xmath17 of eigenvalues inside an interval of the length @xmath18 is approximately poisson - distributed @xmath19 with parameter @xmath20 .",
    "our main interest will be in unitary matrices of size @xmath21 drawn according to the haar measure on the unitary group @xmath22 ; such a matrix is called a matrix from the @xmath23 , where @xmath24 stands for * circular unitary ensemble*.    let @xmath25 be a @xmath26 matrix",
    ". denote by @xmath27 its eigenvalues , where we assume that the eigenphases @xmath28 belong to the interval @xmath29 .",
    "the random vector @xmath30 possesses a density @xmath31 with respect to the lebesgue measure , which was given by dyson in his seminal paper @xcite , @xmath32 this expression can be rewritten in the following form ( see paragraph 11.1 in @xcite ) @xmath33_{k , l=1}^n,\\ ] ] where @xmath34 in particular @xmath35    the set of eigenphases of a random unitary matrix can be seen as an example of * a point process * @xmath36 on the interval @xmath37 related to these eigenphases , by which we mean a random collection of points @xmath38 or , in other words , an integer - valued random measure @xmath39 where @xmath40 denotes the indicator function of @xmath41 .    a possible way to describe a point process is to give its so - called * joint intensities * or , as physicists usually say , * correlation functions * @xmath42 , @xmath43 . in our case",
    "they might be defined simply as @xmath44 it is known @xcite that the process @xmath36 is determinantal with joint intensities @xmath45_{s , t=1}^k.\\ ] ] ( recall that a point process is called * determinantal * with kernel @xmath46 if its joint intensities can be written as @xmath47_{i , j=1}^k$ ] . ) for @xmath26 matrices , due to the translation invariance of the measures we have that @xmath48 , hence a kernel is given by a function @xmath49 of a single variable .",
    "we refer to @xcite for more background on such determinantal processes .    by definition ,",
    "the joint intensity @xmath50 equals @xmath51 times the @xmath52 dimensional marginal distribution of the vector @xmath30 .",
    "thus @xmath53_{s , t=1}^k = 1.\\ ] ]    if we rescale properly the eigenphases of a @xmath26 matrix it turns out that they exhibit nice asymptotic behavior .",
    "namely , it is clear that the point process @xmath54 is determinantal with the kernel @xmath55 .",
    "thanks to the fact that this function converges when @xmath56 , we can give a precise analytic description of the limit of the probability @xmath57 , where @xmath58 is a compact set ( see theorem 3.1.1 in @xcite ) .",
    "in the case of @xmath59 matrices the situation is even simpler .",
    "the point process related to the rescaled ( by the factor @xmath60 ) eigenphases of a @xmath61 matrix behaves for large @xmath1 as a poisson point process with the parameter @xmath62 .    for point processes , related to the correlation functions",
    "is the notion of * level spacing distribution * , denoted by @xmath63 , which is defined for a point process @xmath64 of the properly rescaled eigenphases @xmath65 of a random @xmath1-dimensional unitary matrix by @xmath66 where @xmath67 and @xmath68 is the non - decreasing rearrangement of the sequence @xmath69 .",
    "the scaling factor @xmath70 is chosen so that the mean distance @xmath71 between two consecutive rescaled eigenphases is @xmath72 . in the cases of a @xmath26 or @xmath61 matrix , one has @xmath73 .",
    "we should bear in mind that the level spacing distribution of the poisson point process with the parameter @xmath74 is exponential with the density @xmath75 moreover , it is easy to check that @xmath76 { } e^{-s}.\\ ] ] of course , the limit for the @xmath26 is different .",
    "we now present our main results for the two cases under consideration .",
    "we begin by considering two independent @xmath24 matrices @xmath77 and @xmath78 of size @xmath1 .",
    "we are interested in the asymptotic behavior of the eigenphases of the tensor product @xmath79 .",
    "our first main result is the following .",
    "[ thm.cuecue ]",
    "let @xmath80 and @xmath81 be the eigenphases of two independent @xmath26 matrices @xmath77 and @xmath78 .",
    "define the point process @xmath82 of rescaled eigenphases of the matrix @xmath79 as @xmath83 let @xmath84 , @xmath85 be the intensities of the process @xmath82 . then @xmath86 { } 1,\\ ] ] uniformly on any compact subset of @xmath87 .",
    "thus , theorem [ thm.cuecue ] relates the statistical properties of a properly rescaled phase - spectrum of a large @xmath88 matrix to those of a poisson point process .",
    "a ( not immediate ) corollary of the convergence of intensities is the following .",
    "[ cor.cuecue ] for the point process @xmath82 defined in , @xmath89 $ } } \\right ) } \\\\",
    "= { \\mathbb{p}\\left ( \\sigma_n([0 , s ] ) = 0 \\right ) } \\xrightarrow[n\\to\\infty ] { } e^{-s } , \\qquad s > 0",
    ".     \\end{split}\\ ] ] in particular @xmath90 { } e^{-s},\\ ] ] where the level spacing distribution @xmath91 is defined by    our numerical results support , i.e. the level spacing distribution of the tensor product of two random unitary matrices of size n is described asymptotically by the poisson ensemble .",
    "the numerical data presented in figure [ fig.p(s)cuecue ] reveals that just for @xmath92 the difference between @xmath91 and @xmath93 is negligible .",
    "we next consider @xmath0 independent @xmath94 matrices @xmath95 and study the asymptotic properties of the phase - spectrum of a matrix @xmath96 .",
    "our main result is as follows .",
    "[ thm.cue^ ] let @xmath97 , @xmath98 be the eigenphases of independent @xmath94 matrices @xmath95 .",
    "define the point process @xmath99 of the rescaled eigenphases of a matrix @xmath96 as @xmath100 then , for each @xmath52 there exists a continuous function @xmath101 with @xmath102 so that for any mutually disjoint intervals @xmath103 @xmath104    note that the statement of theorem [ thm.cue^ ] is weaker than that of theorem [ thm.cuecue ] .",
    "this is due to the fact that stronger correlations exist in the point process @xmath99 , which prevent us from discussing the convergence of its intensities to those of a poisson process .",
    "the mode of convergence is however strong enough to deduce interesting information , including the weak convergence of the processes .",
    "we exhibit this by considering the behavior of the level spacings when @xmath0 tends to infinity .",
    "[ cor.cue^n ] for the point process @xmath99 defined in we have @xmath105 $ } } \\right ) } \\\\        = { \\mathbb{p}\\left ( \\tau_m([0 , s ] ) = 0 \\right ) }",
    "\\xrightarrow[m\\to\\infty ] { } e^{-s } , \\qquad s > 0 .     \\end{split}\\ ] ] in particular @xmath106 { } e^{-s},\\ ] ] where the level spacing distribution @xmath107 is defined by .",
    "the relevant numerical results which confirm are shown in figure [ fig.p(s)cue^ ] .",
    "again we may observe that it is enough to take relatively small @xmath0 in order to get a good approximation of the spectrum of a matrix @xmath108 by the poisson ensemble .      the convergence exhibited in theorems [ thm.cuecue ] and [ thm.cue^ ] , and in their corollaries , is arguably not surprising : taking the tensor product introduces so many eigenphases ( @xmath109 in the case of theorem [ thm.cuecue ] , @xmath110 in the case of theorem [ thm.cue^ ] ) that , after appropriate scaling , the local correlations between adjacent eigenphases are not influenced by the long range correlation that is present due to the tensorization .",
    "one should however be careful in carying this heuristic too far : well known superposition and interpolation relations , see",
    "@xcite and the discussion in ( * ? ? ?",
    "* section 2.5.5 ) , show that the point process obtained by the union of eigenvalues of , say , a @xmath111 and @xmath112 independent matrices , is closely related to that obtained from of a @xmath113 matrix , and thus definitely not poissonian .",
    "this phenomenon had been also discussed in the physics literature @xcite . compared to that , the tensorization operation appears to strongly decorrelate eigenphases on the local level .",
    "it is natural to try to generalize theorems [ thm.cuecue ] and [ thm.cue^ ] to other situations , where either @xmath1 or @xmath0 are finite but not necessarily equal to @xmath114 , or both @xmath1 and @xmath0 go to infinity .",
    "while we expect similar methods to apply and yield similar decorrelation results , there are several technical issues to control , and we do not discuss such extensions here .",
    "we prove in this section theorem [ thm.cuecue ] and corollary [ cor.cuecue ] , that correspond to the case @xmath2 and @xmath1 large . we start with an elementary observation .",
    "recall the kernel @xmath115 , see .",
    "[ lem - oldclaim ] for any @xmath116 @xmath117    we show inductively that @xmath118 hence @xmath119 for @xmath120 we have equality , which completes the proof .",
    "we begin with setting @xmath121 and recalling that by definition @xmath122 let us first of all get rid of the addition modulo @xmath123 noticing that the event , probability of which we want to compute , is the sum of @xmath124 mutually exclusive events occurring when @xmath125 is in the interval @xmath29 or @xmath126 .",
    "thus we can write the sought after probability as @xmath127 where we denote @xmath128 and @xmath129 .",
    "let us now concentrate solely on the first term corresponding to the index @xmath130 ( the other terms can be dealt with in the same manner ) . in order to take an advantage of the independence we observe that the considered quantity equals @xmath131",
    "where the constrains @xmath132 are the result of the fact that @xmath133 , for @xmath134 , so , in particular , that @xmath135 . exploiting the independence",
    "we obtain that the last expression equals @xmath136 now observe that for a determinantal point process @xmath137 with a kernel @xmath46 and fixed numbers @xmath138 we have @xmath139_{s , t=1}^p + o(\\delta^p)\\right ) , \\end{split}\\ ] ] where @xmath140 is the collection of all partitions into @xmath141 non - empty pairwise disjoint subsets of the set @xmath142 . by this",
    "we mean that if @xmath143 is such a partition then @xmath144 where @xmath145 is cardinality of the @xmath146-th block of the partition @xmath143 .",
    "moreover , to compactify the notation , we attach to a partition @xmath143 the function @xmath147 , defined as @xmath148 applying this to formula we obtain @xmath149_{s , t=1}^{p_1 } + o(1/k^{p_1 } ) \\right ) \\\\      &       \\!\\!\\!\\!\\!\\ !      \\!\\!\\!\\!\\!\\ !      \\!\\!\\!\\!\\!\\ !      \\!\\!\\!\\!\\!\\ !      \\!\\!\\!\\!\\!\\ !      \\!\\!\\!\\!\\!\\ !      \\!\\!\\!\\!\\!\\ !      \\!\\!\\!\\!\\!\\ !      \\!\\!\\!\\!\\!\\ !",
    "\\cdot\\left ( \\left ( 2{\\varepsilon}\\right)^{p_2 } \\det\\left [ s_n\\left(x_{\\pi_2(s,1 ) } - 2\\pi\\ell_{\\pi_2(s,1)}/k - x_{\\pi_2(t,1 ) } + 2\\pi\\ell_{\\pi_2(t,1)}/k\\right ) \\right]_{s , t=1}^k + o({\\varepsilon}^{p_2 } ) \\right)\\,.\\end{aligned}\\ ] ] performing the limit @xmath150 we notice that only the terms corresponding to @xmath151 do not vanish , for , otherwise , @xmath152 would give nontrivial relations for @xmath153 which altogether with @xmath154 make the sum over @xmath153 of at most @xmath155 terms .",
    "recall that @xmath156 .",
    "thus , taking the limit @xmath157 , the extra factor @xmath158 is produced , so we finally find that the considered term contributes @xmath159_{s , t=1}^p \\\\ & \\cdot \\det\\left [ \\frac{2\\pi}{n}s_n(x_s - y_s - x_t + y_t ) \\right]_{s , t=1}^k { \\mathrm{d}}\\mathcal{h}_p(y_1,\\ldots , y_k)\\end{aligned}\\ ] ] to @xmath160 , where @xmath161 denotes the @xmath141-dimensional hausdorff measure in @xmath162 .",
    "as already mentioned the other terms in ( [ eq : probtot ] ) can be calculated in a similar way , only the limits of the integration have to be changed . summing up , we get @xmath163_{s , t=1}^p \\\\ & \\cdot \\det\\left [ \\frac{2\\pi}{n}s_n(2\\pi\\eta_s + x_s - y_s - 2\\pi\\eta_t - x_t + y_t ) \\right]_{s , t=1}^k",
    "\\bigg ) { \\mathrm{d}}\\mathcal{h}_p(y_1,\\ldots , y_k ) , \\end{split}\\ ] ] where the subset @xmath164 of @xmath165 is the set of all @xmath166 such that either @xmath167 if @xmath168 , or @xmath169 if @xmath170 for @xmath171 .    to proceed we have to investigate the asymptotic behavior of the integrand in ( [ eq.intensityprefinal ] ) . we will do it again only for @xmath172 , observing that an adaptation to other terms is straightforward .",
    "we start with the term @xmath173 .",
    "then the integrand is a product of two determinants of matrices of size @xmath52 , so applying to each of them the permutation definition and extracting the term referring to the trivial permutations , we find it equals @xmath174 where the summation involves all permutations @xmath175 and @xmath176 of @xmath52 indices .",
    "the first term + @xmath177 , after substituting in , gives simply @xmath178 we will show that the second term in after being put into vanishes in the limit .",
    "we consider here only the case @xmath179 to explain the main idea .",
    "the terms involving more factors can be treated along the same lines .",
    "the sum over @xmath175 and @xmath176 reduces to @xmath180 let us for instance deal with the last term in equation .",
    "putting it into we arrive at @xmath181 taking a quick look at the integrand we see that the above expression goes to @xmath182 when @xmath56 by lebesgue s dominated convergence theorem , for @xmath183 , when @xmath184 , and the appropriate bound follows from lemma [ lem - oldclaim ] . for the terms corresponding to @xmath185",
    ", we easily notice that thanks to the factor @xmath186 they converge to @xmath182 .",
    "the proof is now complete .",
    "[ rem-1 ] by virtue of formula the joint intensities @xmath50 can be estimated as @xmath187_{s , t=1}^k   \\\\      & \\cdot \\sum_{p=1}^k \\sharp \\mathfrak{s}(k , p ) \\int_{[0,2\\pi)^p } \\det\\left [ s_n(y_s - y_t ) \\right]_{s , t=1}^p { \\mathrm{d}}y_1 \\ldots { \\mathrm{d}}y_p,\\end{aligned}\\ ] ] where @xmath188 denotes cardinality of a set @xmath41 .",
    "using hadamard s inequality ( see , e.g. ( 3.4.6 ) in @xcite ) for the first term , the observation for the second one , and finally we obtain @xmath189 due to the well - known combinatorial fact that @xmath190 ( @xmath191 is the stirling number of the second kind , consult e.g. @xcite ) we may conclude with an useful bound @xmath192    for the proof of we have to calculate the probability of the event that there is no rescaled eigenphase in a given interval .",
    "this is done in the following lemma .",
    "[ lm.norescaled ] let @xmath193 be a point process related to the eigenphases , possibly rescaled , of a @xmath194 matrix @xmath25 with the joint intensities @xmath195 , @xmath85 ( so @xmath196 , for @xmath197 ) .",
    "then for any compact set @xmath198 @xmath199    clearly , we have @xmath200 one way to compute the probability @xmath201 is to use the notion of jnossy densities @xmath202 ( see definition 4.2.7 in @xcite ) .",
    "they can be expressed in terms of the joint intensities as @xmath203 where @xmath204",
    "they exist whenever @xmath205 which is clearly fulfilled in our case , as @xmath196 for @xmath206 .",
    "moreover , the vanishing of @xmath207 for large enough @xmath208 makes every sum in the following finite so we will not have troubles with interchanging the order of summations .    in terms of the jnossy intensities , the probability @xmath201 reads as ( see equation ( 4.2.7 ) of @xcite ) @xmath209 and , consequently , @xmath210 \\frac{(-1)^\\ell}{\\ell ! } \\int_{d^\\ell}\\rho_\\ell = 1 + \\sum_{\\ell \\geq 1 } \\frac{(-1)^\\ell}{\\ell ! } \\int_{d^\\ell } \\rho_\\ell.\\end{aligned}\\ ] ]    lemma [ lm.norescaled ] applied to the process @xmath82 yields @xmath211)=0 \\right ) } = 1 + \\sum_{\\ell \\geq 1 } \\frac{(-1)^\\ell}{\\ell ! } \\int_{[0,s]^\\ell } \\rho_\\ell^n.\\ ] ] to pass to the limit @xmath56 we need an appropriate bound on the intensities @xmath212 . in remark [ rem-1 ]",
    "we showed that @xmath213 ( see ) .",
    "therefore , by lebesgue s dominated convergence theorem , we get @xmath214)=0 \\right ) } = 1 + \\sum_{\\ell \\geq 1 } \\frac{(-1)^\\ell}{\\ell ! } \\int_{[0,s]^\\ell } \\lim_{n\\to\\infty } \\rho_\\ell^n = 1 + \\sum_{\\ell \\geq 1 } \\frac{(-1)^\\ell}{\\ell ! } s^\\ell = e^{-s}.\\ ] ] this completes the proof of .",
    "the formula follows now from a relation connecting the probability @xmath215 that a randomly chosen interval of length @xmath216 is free from eigenphases with the level spacing distribution @xmath63 , ( see equation ( 6.1.16a ) in @xcite ) , @xmath217 we have just showed that @xmath218)=0 \\right ) } = e(0;s ) = e^{-s}$ ] .",
    "thus , indeed @xmath219",
    "now we will prove theorem [ thm.cue^ ] .",
    "in the course of the proof we will need three lemmas .",
    "let us start with them .",
    "[ lm.q.g.sum ] fix a positive integer @xmath216 and a number @xmath221 . for each positive integer @xmath17",
    "let us define the set @xmath222 then @xmath223 { } 0.\\ ] ]    here , we adopt the convention that @xmath224",
    ".    first observe that @xmath225 let @xmath226 be i.i.d .",
    "bernoulli random variables such that @xmath227 .",
    "denote @xmath228 .",
    "then the last expression equals @xmath229 and can be estimated from above as follows @xmath230 { } 0,\\ ] ] where the last inequality follows for instance from hoeffding s inequality ( see @xcite ) .",
    "[ lm.density ] let @xmath41 be a random vector in @xmath231 with a bounded density .",
    "let @xmath232 be a linear mapping of rank @xmath233 .",
    "then there exists a constant @xmath234 such that for any intervals @xmath235 of finite length we have @xmath236 where @xmath237 are indices of those rows of the matrix @xmath77 which are linearly independent .",
    "let @xmath238 be rows of the matrix @xmath77 .",
    "we know there are @xmath233 of them , say @xmath239 , which are linearly independent .",
    "thus there exists an invertible @xmath240 matrix @xmath12 such that @xmath241 where @xmath242 is the @xmath243-th vector of the standard basis of @xmath231 . notice that @xmath244 for the vector @xmath245 also has a bounded density on @xmath246 .",
    "this finishes the proof .",
    "[ lm.matrixrank ] let @xmath77 be a matrix of dimension @xmath247 , with entries in @xmath248 , and satisfying the following conditions    a.   no two columns are equal",
    ". b.   no two rows are equal . c.   one column consists of all @xmath72s .",
    "then , the rank of @xmath77 is at least @xmath249 .    _",
    "( due to dima gourevitch ) _",
    "denote @xmath250 .",
    "the assertion of the lemma is equivalent to the statement that @xmath251 and if @xmath252 then @xmath253 .",
    "we may assume without loss of generality that the first @xmath233 rows of @xmath77 are linearly independent and the others are their linear combinations . under this assumption ,",
    "if two columns are identical in the first @xmath233 coordinates then they are identical in all coordinates . by condition _",
    "( i ) _ , such columns do not exist . therefore the @xmath254 submatrix @xmath78 which consists of the first @xmath233 rows has distinct columns . as a result @xmath255 .",
    "now suppose @xmath256 .",
    "if @xmath257 , consider the @xmath258 row of @xmath77 .",
    "it is a linear combination of the first @xmath233 rows . since the columns of @xmath78 include the column @xmath259 for all @xmath260 , the coefficient of each row is either @xmath182 or @xmath72 .",
    "since @xmath77 includes a column of @xmath72s , the coefficient of exactly one row is @xmath72 , and all other coefficients vanish .",
    "thus , the @xmath258-th row is identical to one of the first @xmath233 rows - in contradiction to condition _",
    "( ii)_.    fix an integer @xmath261 and finite intervals @xmath103 which are mutually disjoint .",
    "we need to compute the probability of the event @xmath262 which means that in each interval @xmath263 there is a rescaled eigenphase .",
    "such eigenphase is of the form @xmath264 for some @xmath265 .",
    "therefore @xmath266 where @xmath267 and @xmath268 runs over the set @xmath269_{i = 1,\\ldots , m}^{j = 1 , \\ldots , k } \\",
    "\\epsilon_i^j \\in \\{1,2\\ } , \\",
    "\\epsilon^u \\neq \\epsilon^v , \\textrm{for $ u \\neq v , u , v = 1 , \\ldots , k$}\\right\\}\\ ] ] of all @xmath270 matrices with entries @xmath271 which have pairwise distinct rows @xmath272 , @xmath273 ( @xmath274-th row @xmath275 describes the @xmath274-th eigenphase and since intervals are disjoint we assume the rows are distinct ) .",
    "column vectors are denoted by @xmath276^t$ ] , @xmath277 .",
    "we say that @xmath268 is _ bad _ if the collection of its vector columns @xmath278 is less than @xmath124 . otherwise @xmath268 is called _",
    "good_.    obviously , @xmath279 the strategy is to show that the contribution of bad @xmath268 s vanishes for large @xmath0 while good @xmath268 s essentially provide the desired result @xmath280 when @xmath0 goes to infinity .",
    "so the proof will be divided into several parts .",
    "[ [ good - epsilons . ] ] good @xmath268 s .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the goal here is to prove @xmath281 with the required uniformity in the choice of the disjoint intervals @xmath263 . by virtue of @xmath282 it suffices to prove that @xmath283 uniformly , and that the correlations between two different good epsilons does not matter @xmath284    let us now prove .",
    "the proof of is deferred to the very end as we will need the ideas developed here as well as in the part devoted to bad @xmath268 s .",
    "given @xmath285 and a vector @xmath286^t \\in \\{1,2\\}^k$ ] we count how many column vectors of @xmath268 equals @xmath70 and call this number @xmath287 . then @xmath288 .",
    "note that @xmath268 is good iff all @xmath287s are nonzero .",
    "the crucial observation is that the probability of the event @xmath289 does depend only on the vector @xmath290 associated to @xmath268 as described before .",
    "indeed , the sum @xmath291^t { \\ \\textrm{mod } \\;}2\\pi$ ] is identically distributed as the random vector @xmath292 , where @xmath293 is a sum modulo @xmath123 of i.i.d .",
    "note that the distribution of @xmath294 does not depend on the choice of indices @xmath295 but only on @xmath70 and @xmath287 .",
    "consequently , denoting by @xmath296 the set of all @xmath268 s such that there are exactly @xmath287 indices @xmath297 for which @xmath298 , we have that the value of @xmath299 is the same for all @xmath300",
    ". clearly @xmath301 , whence @xmath302    the idea is to identify those terms which will sum up to @xmath303 and the rest which will be neglected in the limit of large @xmath0 . to do this , set a positive parameter @xmath304 and let us call a good @xmath208 _ very good _ ( _ v.g .",
    "_ for short ) if @xmath305 for every @xmath70 and _ quite good _ ( _ q.g . _ for short ) otherwise .",
    "we claim that @xmath306 and @xmath307 _ where @xmath234 is a constant _ ( from now on in this proof we adopt the convention that @xmath234 is a constant depending only on @xmath52 which may differ from line to line ) .",
    "let us postpone the proofs and see how to conclude .",
    "notice that @xmath308 . thus applying we",
    "obtain @xmath309 by lemma [ lm.q.g.sum ] it vanishes when @xmath15 .",
    "now we deal with very good @xmath208 s writing with the aid of that @xmath310 the first term in the bracket approaches @xmath72 in the limit @xmath15 due to lemma [ lm.q.g.sum ] , while the second one approaches @xmath182 as it is bounded above by @xmath311 .",
    "let us define the vectors @xmath312 since @xmath208 is good , in particular we have that @xmath313 , so denoting the random vector @xmath314 by @xmath315 we have @xmath316 . by independence",
    "it is enough to show that the random vector @xmath317 has a bounded density on @xmath318 .",
    "equation yields that @xmath319 where @xmath320 are independent random vectors on @xmath321 with the same distributions as the vectors @xmath322 respectively . clearly , the vector @xmath320 has a bounded density on @xmath323 because the vector @xmath324 has a bounded density .",
    "therefore the vector @xmath325 has a bounded density on @xmath326 . a certain linear transformation with determinant @xmath72 maps this vector to @xmath327 which consequently also has a bounded density .",
    "one projects it to the first @xmath52 coordinates and then takes care of addition modulo @xmath123 obtaining that @xmath328 has a bounded density , which finishes the proof .    given a vector @xmath329",
    "let @xmath330 denote the random vector in @xmath318 identically distributed as the vector @xmath331 .",
    "take its independent copies @xmath332 such that the family @xmath333 also consist of independent random vectors .",
    "then @xmath334^t$ ] , and @xmath335 to ease the notation we introduce new indices @xmath336 sets @xmath337 and the vector @xmath338    now we intend to use the local central limit theorem of @xcite . indeed , due to independence such a theorem should hopefully yield that @xmath339 has a normal distribution for large @xmath0 . to be more precise ,",
    "let us consider the matrix @xmath340 and its eigenvalues . since for any @xmath341 @xmath342 it is clear that the largest eigenvalues are uniformly ( i.e. with respect to @xmath0 ) bounded by @xmath234 , which depends only on @xmath52 . to provide an uniform bound for",
    "the smallest eigenvalues let us observe that ( recall that @xmath343 is the vector @xmath344 ) @xmath345 where the second inequality is because @xmath208 is very good .",
    "it is a matter of direct computation to see the last inequality as for @xmath346 we have @xmath347^t[1 \\ldots 1 ] + \\textrm{diag } ( 2 + 2\\pi^2/3 , \\ldots , 2 + 2\\pi^2/3)$ ] and for @xmath348 the sum equals @xmath349 .",
    "therefore , with the matrix @xmath350 given by @xmath351 it holds that @xmath352 therefore the assumptions of ( * ? ? ?",
    "* corollary 19.4 ) are satisfied ( for the family of independent random vectors @xmath333 ) , so the vector @xmath353 possesses a density @xmath354 and @xmath355 where @xmath356 is the density of the standard normal distribution in @xmath162 and @xmath357 is a polynomial of degree @xmath358 whose coefficients depends on the cumulants of the vectors @xmath359 .",
    "we may put it differently , i.e. @xmath360 for some functions @xmath361 uniformly bounded @xmath362 .",
    "therefore , denoting @xmath363 , @xmath364    let us firstly deal with the error term @xmath365 . denoting @xmath366 we are to show that @xmath367 to do this we estimate the integrated function @xmath368 then @xmath369 introduce _ full _ boxes @xmath370 and observe that @xmath371 since @xmath372 { } 0 $ ] , the sets @xmath373 are pairwise disjoint and sum up to @xmath374",
    ", we can infer that the sum @xmath375 converges to @xmath376 .",
    "hence , this sum is bounded by @xmath234 and we get .",
    "now we handle the main term @xmath377 .",
    "we prove it equals @xmath378 up to another error @xmath379 .",
    "let @xmath380 be the linear isomorphism mapping @xmath373 onto @xmath381 .",
    "it equals @xmath382 , where @xmath383 is the linear mapping transforming the box @xmath384 onto the box @xmath385 , whence @xmath386 .",
    "thus , changing the variable we obtain @xmath387 notice that @xmath388 is close to @xmath389 , whenever @xmath390 , for @xmath391 consequently , on @xmath373 , @xmath392 is close to @xmath393 .",
    "strictly , we use the mean value theorem and get @xmath394 for some mean points @xmath395 $ ] .",
    "this results in @xmath396 we are almost done . clearly @xmath397 converges to @xmath182 faster that @xmath398 , so @xmath399 .",
    "for @xmath400 we use the schwarz inequality and integrability of @xmath401 @xmath402 this completes the proof of .",
    "we have proved claims and , so the proof of the part concerning good @xmath268 s is now complete .",
    "let us proceed to tackle bad @xmath268 s .",
    "[ [ bad - epsilons . ] ] bad @xmath268 s .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the goal here is to show that @xmath403 again , with the required uniformity .",
    "obviously it suffices to show that @xmath404 { } 0 $ ] .",
    "let @xmath405 be the set of those bad @xmath268 s for which the cardinality of the set @xmath278 equals @xmath274 .",
    "observe that @xmath406 . with the aid of lemma [ lm.matrixrank ]",
    "we will show that @xmath407 this will finish the proof , for @xmath408 { } 0 .",
    "\\end{split}\\ ] ]    for the proof of fix @xmath409 .",
    "we have seen that @xmath410 and we know that there are exactly @xmath274 numbers @xmath287 which are nonzero , say those which correspond to vectors @xmath411 .",
    "denote @xmath412 , @xmath413 and consider the random vector @xmath414 in @xmath162 .",
    "as in the proof of claim we observe that @xmath415 is a linear image of the vector @xmath416 .",
    "this mapping is given by the matrix @xmath417 $ ] where @xmath418 by lemma [ lm.density ] we obtain @xmath419 where @xmath250 .",
    "the number @xmath233 does not change if we replace the @xmath420-th column of @xmath77 with the vector @xmath421 with @xmath72 at each its entry , as the sum of @xmath422-th and @xmath420-th columns is just @xmath421 . taking only the columns",
    "@xmath423 we get the matrix @xmath78 which has the same rank as @xmath77 .",
    "it has @xmath424 columns and fulfils the assumptions of lemma [ lm.matrixrank ] .",
    "thus @xmath425 and when @xmath426 this minimum equals @xmath427 .",
    "if @xmath428 in the matrix @xmath77 there must be two identical columns , one with even , say @xmath429 , and one with odd , say @xmath430 index , which means that the @xmath431-th and the @xmath432-th column of @xmath78 add up to @xmath421 , so the @xmath432-th column may be erased and the rank of @xmath78 does not change .",
    "therefore we apply the lemma to the matrix @xmath78 with erased the @xmath432-th column which is of size @xmath247 and get again @xmath433 .",
    "this completes the proof of .",
    "[ [ pairs - of - good - epsilons - i.e .- the - proof - of- . ] ] pairs of good @xmath268 s , i.e. the proof of .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we denote by @xmath434 the random vector @xmath435 . by the definition of @xmath289 we may write @xmath436 since the intervals @xmath437 and @xmath438 are disjoint for @xmath439 , we may restrict ourselves to those @xmath268 and @xmath440 for which @xmath441 whenever @xmath439 , @xmath442 as otherwise the event @xmath443 is impossible .",
    "however it might happen that @xmath444 .",
    "let us count for how many @xmath431 s it takes place , i.e. given @xmath445 let @xmath446 be the set of all considered unordered pairs @xmath447 for which there are exactly @xmath448 indices @xmath449 such that @xmath450 , @xmath451 .",
    "the value @xmath452 is excluded as @xmath453 .",
    "we have @xmath454 thus we fix @xmath216 and prove that @xmath455 .",
    "there are two cases .",
    "a pair @xmath456 can be _ good _ which means @xmath457 , \\",
    "i = 1 , \\ldots , m \\right\\ } \\geq 2^{k+s}$ ] , or , otherwise we call it _",
    "bad_. we obtain a decomposition @xmath458 .",
    "now for a good pair , applying the reasoning already used for bad @xmath268 s ,",
    "i.e. combining lemmas [ lm.density ] and [ lm.matrixrank ] , we get the estimate @xmath459 but @xmath460 , so @xmath461    for a bad pair @xmath447 we know that there are @xmath462 different rows and at most @xmath463 different columns in the matrix @xmath464 $ ] .",
    "hence we repeat the argument of the part concerning bad @xmath268 s .",
    "namely , first exactly in the same manner as in that part we use lemma [ lm.matrixrank ] in order to establish an appropriate inequality in the spirit of .",
    "then we follow the estimate of and conclude that @xmath465 this finishes the proof of theorem [ thm.cue^ ] .",
    "fix @xmath466 small so that @xmath467 is an integer and divide the interval @xmath468 $ ] into consecutive intervals of length @xmath466 , denoted @xmath469 .",
    "let @xmath470 and @xmath471 .",
    "of course , @xmath472)=\\sum_{i=1}^{s/\\delta } z_i$ ] .",
    "our goal is to show that @xmath472)$ ] becomes poissonian in the limit of large @xmath0 , from which the statement of the corollary follows immediately .",
    "the proof of theorem [ thm.cue^ ] yields the following facts .",
    "there exist a sequence @xmath473 with @xmath474 and a universal constant @xmath234 such that the following hold .",
    "@xmath475 where @xmath476 denotes an arbitrary subset of @xmath52 distinct integers in @xmath477 .    indeed , to justify notice that @xmath478 where @xmath479 and @xmath289 is the event that there is an eigenphase described by @xmath268 in the interval @xmath469 ( see ) .",
    "the probability of the event @xmath443 can be estimated by @xmath480 . to see this , recall and follow the same argument which led to estimate ( in this case the relevant matrix has the rank no less than @xmath114 ) .",
    "it suffices , as @xmath481 . for , observe that @xmath482 and apply theorem [ thm.cue^ ] ( with its uniformity statement ) .",
    "let @xmath483 be i.i.d .",
    "bernoulli random variables with @xmath484 .",
    "by we have that for any integer @xmath208 , @xmath485 since @xmath486 converges to a poisson random variable of parameter @xmath216 as @xmath487 , it follows that @xmath488 converges in distribution to a poisson variable of parameter @xmath216 , when first @xmath15 and then @xmath487 . on the other hand , using we have that @xmath489 and therefore , one concludes that also @xmath490 converges in distribution to a poisson variable of parameter @xmath216 , when first @xmath15 and then @xmath487 .",
    "this yields the corollary .",
    "tt was partially supported by ncn grant no .",
    "2011/01/n / st1/05960 .",
    "ms , mk and kz were supported by the sfb transregio-12 project der deutschen forschungsgemeinschaft and a grant financed by the polish national science centre under the contract number dec-2011/01/m / st2/00379 .",
    "oz was supported by nsf grant dms-0804133 and by a grant from the israel science foundation .",
    "part of the work was done while the first named author was participating in the kupcinet - getz international summer science school at the weizmann institute of science in rehovot , israel .",
    "we are grateful to the wis for financial support making this possible .",
    "p. j. forrester and e. m. rains _ interrelationships between orthogonal , unitary and symplectic matrix ensembles_. in _ random matrix models and their applications _ , math .",
    ". publ . * 40 * , 171207 .",
    "cambridge , cambridge university press ( 2001 )"
  ],
  "abstract_text": [
    "<S> tensor products of @xmath0 random unitary matrices of size @xmath1 from the circular unitary ensemble are investigated . </S>",
    "<S> we show that the spectral statistics of the tensor product of random matrices becomes poissonian if @xmath2 , @xmath1 become large or @xmath0 become large and @xmath3 .    </S>",
    "<S> @xmath4institute of mathematics , university of warsaw , banacha 2 , 02 - 097 warsaw , poland . </S>",
    "<S> + ` tkocz@mimuw.edu.pl ` +   + @xmath5the marian smoluchowski institute of physics , jagiellonian university , reymonta 4 , 30 - 059 cracow , poland . ` marek.smaczynski@uj.edu.pl ` +   + @xmath6center of theoretical physics , polish academy of sciences , al . </S>",
    "<S> lotnikow 32/46 , 02 - 668 warsaw , poland . ` marek.kus@cft.edu.pl ` , ` karol@cft.edu.pl ` +   + @xmath7school of mathematics , university of minnesota and faculty of mathematics , weizmann institute of science , pob 26 , rehovot 76100 , israel . ` </S>",
    "<S> zeitouni@math.umn.edu `    * 2010 mathematics subject classification . * </S>",
    "<S> 60b20 , 15b52 .    * key words and phrases . * random matrices , circular unitary ensemble , tensor product . </S>"
  ]
}