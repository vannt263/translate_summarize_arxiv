{
  "article_text": [
    "a variety of techniques have been developed to extract information from a single image .",
    "for example , the depth - from - focus method @xcite allows estimation of a 3d scene ( depth - dependent focus ) from a single 2d image . the mosaic and demosaic technique  @xcite allows recovery of color information from a gray - scale image .",
    "recently , inspired by compressive sensing ( cs ) @xcite , video has been extracted from a single image  @xcite . in this setting the measured data are acquired at a low frame rate , with coding at a faster rate , and high - frame - rate video is computationally recovered subsequently .    in this paper",
    "we develop a new method that borrows and extends ideas from this previous work . specifically , like @xcite we perform high - frequency coding of video collected at a low frame rate , with cs - based inversion .",
    "our coding strategy differs from previous work in that we use a _ single _ code that is inexpensively translated via a piezoelectric device .",
    "we recover color via a hardware mosaicing and computational demosaicing procedure like in conventional cameras .",
    "the newest aspect of the proposed approach is that we use a lens with voltage - dependent index of refraction ( a liquid lens ) , and by varying the voltage at high rate , the recovered high - rate video corresponds to capturing data at varying focus points ( depths ) . for each of the measured frames ,",
    "we recover multiple color frames , and these multiple frames capture variable focus depths .",
    "we here show example results that summarize the three key aspects of the approach : mosaicing for color , high - speed coding for video , and fast time - dependent focus for depth , with the data measured at a low frame rate .",
    "we first consider mosaicing and high - speed coding , with the focus held constant . in figure",
    "[ fig : real_ball ] two compressive measurements ( real data from our camera ) are shown at left .",
    "these are two consecutive frames collected at frame rate 30 frames / sec , using an off - the - shelf guppy pro camera @xcite , with a high - speed coding element , as summarized in figure  [ fig : dec ] . at",
    "right in figure [ fig : real_ball ] , are shown @xmath0 recovered frames from each of the compressive measurements : 22 color video frames recovered from a single _ monochromatic _ coded image .",
    "each measurement in figure [ fig : real_ball ] employs a high - speed code ( here a shifting mask ) to modulate the light during the integration time - period @xmath1 ; see figure  [ fig : dec](a ) .    in figure",
    "[ fig : results_dynamic ] we now consider results in which the focus ( observed depth ) is varied at a rate that is fast relative to the rate of the video camera collecting the data ( now the measurements employ mosaicing , high - speed coding , and variation of the focal depth ) .",
    "the variable focus is manifested by varying the voltage on a liquid lens ( see figure [ fig : setup ] ) .",
    "the coded data , with subsequent cs inversion , allows recovery of multiple frames for each measured frame .",
    "since the focus has been adjusted at a fast rate , these high - frequency recovered frames also capture multiple depths .    in figure",
    "[ fig : results_dynamic ] , the top figure depicts the camera and scene , composed of multiple objects at varying depths . at the bottom in this figure",
    ", we depict one of the measured gray - scale frames ( here measured at a frame rate of 30 frames / sec ) , and at bottom right is depicted the recovered color video from this single frame .",
    "note that because of the high - speed time - varying focus , we effectively recover multiple depths , defined by the focus for which a given region of the image is sharpest .    in this paper",
    ", we describe in detail how the camera that took these measurements was implemented , with a summary provided in figure [ fig : dec ] for the coding and mosaicing components , and in figure [ fig : setup ] for the camera setup .",
    "we also discuss a new cs inversion algorithm , that is endowed with a guarantee that upon every iteration the residual between the true video and the estimate is assured to be reduced ( with technical requirements , that are discussed ) .",
    "this is an `` anytime '' algorithm , in that the estimated underlying video may be approximated at any time based upon computations thus far , and the quality of the inversion is guaranteed to improve with additional computations .",
    "the contributions of this paper are : @xmath2 ) development of a new _ low - cost and low - power _ cs camera , that for each low - frame - rate measured image allows recovery of multiple color frames focused at different depths ( at high - frame - rate ) ; and @xmath3 ) application of an anytime cs inversion algorithm to data measured by the camera , providing fast recovery of _ high - speed motion , color and depth _ information from the scene .",
    "the proposed imaging system is built with an off - the - shelf camera , specifically a guppy pro camera @xcite , by adding a _ liquid _ lens to change the focal plane , and by moving a _ single mask _ to modulate the high speed frames during one integration time - period , both extremely low - power additions ( in contrast with common alternatives in the literature , as detailed in section [ sec : related ] ) .",
    "the main challenge is to synchronize temporal modulation ( coding ) with time variation of the focus location ( for capture of variable depth ) .",
    "figure [ fig : setup ] depicts the setup of our camera , and figure [ fig : mask](b ) shows the synchronized control of the mask and liquid lens .",
    "the focal plane of the liquid lens used in the camera is controlled by the voltage of the input signal , which also controls the pizeoelectronic translator to shift the mask .",
    "the control signal ( a triangular wave ) is generated by a function generator and then we use power divider to distribute the signal ( figure [ fig : mask ] ) to the liquid lens and the pizeoelectronic translator to achieve the synchronization .",
    "the shifting ( through the pizeoelectronic translator ) of the same mask ( figure  [ fig : dec](a ) ) is utilized to modulate the high - speed frames .",
    "this modulation enjoys advantages of low - power ( @xmath4 ) , low - cost and low - bandwidth implementation , compared for example with the modulation by liquid - crystal - on - silicon ( lcos ) in @xcite ( power @xmath5 , and high - bandwidth electronic switching / coding ) . in the experiments , we show that the proposed efficient coding mechanism yields similar results to that of the relatively expensive lcos - type coding . during the calibration , we approximate the continuous moving of the mask by discrete patterns ( figure  [ fig : mask](a ) ) .",
    "we record temporally ( and depth ) compressed measurements for rgb colors on a bayer - filter mosaic , where the three colors are arranged in the pattern shown in the right bottom of figure [ fig : dec ] .",
    "the single coded image is partitioned into four components , one for r and b and two for g ( each is @xmath6 the size of the original spatial image ) .",
    "the cs recovery ( video from a single measurement ) is performed separately on these four mosaiced components , and then the demosaicing process in figure [ fig : dec](b ) is employed to manifest the final color video .",
    "one may also jointly perform cs inversion on all 4 components , with the hope of sharing information on the importance of ( here wavelet and dct ) components ; this was also done , and the results were very similar to processing r , b , g1 and g2 separately .",
    "let @xmath7 denote the continuous / analog spatio - temporal volume of the video being measured , with @xmath8 symbolizing the 3d space coordinate and @xmath9 denoting time .",
    "note the depth of the scene is defined by @xmath10 .",
    "additionally , let object - space and image - space coordinates be respectively designated with unprimed and primed variables .",
    "given an @xmath11-pixel sensor with pixel size @xmath12 and integration time @xmath1 , space - time compressive measurements @xmath13 are formed on the detector , with @xmath14 .",
    "the digital data used to represent the scene consists of discrete samples of the continuous transformation @xmath15 where @xmath16 represents a random binary transmission pattern that translates with periodic transverse @xmath17 motion parameterized by @xmath18 .",
    "the spatial and temporal pixel sampling functions , @xmath19 and @xmath20 , bandlimit the incident optical datastream , which is equivalently represented as @xmath21 , with @xmath22 denoting the convolution operator .",
    "here , @xmath23 denotes an instantaneous all - in - focus representation of the spatiotemporal scene and @xmath24 is a time and depth varying ( blur ) kernel imparted by the liquid lens on the focal volume .",
    "the discrete formulation of the model can be simplified .",
    "the frame at each depth ( @xmath25 depths in figure  [ fig : mask](a ) ) is approximated as being modulated by a single unique code ( approximated by the shifting mask , figure  [ fig : mask](a ) ) ; in reality the code / mask is always moving continuously . at each depth ,",
    "the ( physical / continuous ) frame can be denoted by @xmath26 ( @xmath10 is now manifested by @xmath9 ) , and after digitization , we represent it as @xmath27 . denoting the coding pattern of the mask by @xmath28 ,",
    "the measurement @xmath29 is @xmath30 or @xmath31 where @xmath32 denotes the noise and @xmath33 symbolizes the hadamard ( element - wise ) product . by vectorizing each frame and then concatenating them ,",
    "we have @xmath34^t \\in { \\mathbb r}^{n_xn_yn_t}$ ] , and ( [ eq : ysum ] ) can be written as : @xmath35 { \\boldsymbol{x } } + \\boldsymbol{e } \\nonumber\\\\ & = & \\boldsymbol{\\psi x } + \\boldsymbol{e},\\vspace{-7 mm } \\label{eq : ypsix } \\end{aligned}\\ ] ] where @xmath36 $ ] .",
    "the imaging process may therefore be modeled as in the standard cs problem .",
    "the goal is to estimate @xmath37 , given @xmath38 and @xmath39 . before presenting how we address this , we further comment on related work , now in that we have introduced the proposed hardware .",
    "video compressive sensing has been investigated in @xcite , by capturing low frame - rate video to reconstruct high frame - rate video .",
    "the lcos used in @xcite can modulate as fast as @xmath40 fps by pre - storing the exposure codes , but , because the coding pattern is continuously changed at each pixel throughout the exposure , it requires considerable energy consumption ( @xmath5 ) and bandwidth compared with the proposed modulation , in which a single mask is translated using a pizeoelectronic translator ( requiring @xmath4 ) .",
    "similar coding was used in @xcite . however , we investigate color video here , and thus demosaicing is needed ; because of the r , g and b channels , we need to properly align ( in hardware of course ) the mask more accurately compared with the monochromatic video in @xcite . therefore , @xcite can be seen as a special case of the proposed camera .",
    "furthermore , we also extract the depth information from the defocus phenomenon of the reconstructed frames , which has not been considered in the above papers .",
    "coded apertures have been used often in computational imaging for depth estimation @xcite . however , these only consider still images . from the algorithms investigated therein , one can get the depth map from a still image . in @xcite",
    "an imaging system was presented that enables one to control the depth of field by varying the position and/or orientation of the image detector , during the integration time of a single photograph .",
    "however , moving the detector costs more energy than controlling the liquid lens in the proposed design ( almost no power consumption ) , and the camera developed in @xcite can only provide a single all - in - focus image without the depth information .",
    "furthermore , no motion information is considered in the above coded - aperture cameras , while here we consider video ( allowing depth estimation on moving scenes ) .",
    "we reconstruct high - frame - rate video from low - frame - rate measurements via an _ anytime _ algorithm , the generalized alternating projection ( or gap ) algorithm , first developed in @xcite for other applications .",
    "gap produces a sequence of partial solutions that _ monotonically _ converge to the _ true signal _ ( thus , anytime ) . in @xcite",
    ", the authors did not mention how to select group weights and no real data or application was considered .",
    "the manner in which the gap algorithm is employed here , as well as the application considered , is significantly different from @xcite . in the following ,",
    "we first review the underlying gap algorithm and then show how to improve it to get better results for the data considered here .",
    "gap is used to investigate the _ group - sparsity _ of wavelet / dct coefficients of the video to be reconstructed .",
    "let @xmath41 , @xmath42 , @xmath43 be orthonormal matrices defining bases such as wavelets or dct @xcite .",
    "define @xmath44 , and @xmath45 , where @xmath46 denotes kronecker product @xcite",
    ". then we can write ( [ eq : ypsix ] ) concisely as @xmath47 , where @xmath48 with @xmath49 . for simplification ,",
    "from now we ignore possible noise @xmath50 .",
    "note that @xmath51 reflects one @xmath11 compressively measured image , as denoted at left in figure [ fig : real_ball ] , and @xmath52 is the @xmath53 video we wish to recover ( figure [ fig : real_ball ] right , for @xmath0 ) .",
    "( a )    ( b )    ( c )      let @xmath54 , @xmath55 , and @xmath56 , with @xmath57 .",
    "assume @xmath58 has full row rank .",
    "let @xmath59 be a set of nonempty mutually - disjoint and collectively exhaustive subsets of @xmath60 .",
    "let @xmath61^{t}$ ] be a column of constant positive weights with @xmath62 associated with @xmath63 .",
    "we solve the weighted-@xmath64 minimization problem @xmath65 with @xmath66 , where @xmath67 is a sub - vector of @xmath68 containing components indexed by @xmath63 , and @xmath69 denotes @xmath70 norm ; @xmath71 is referred as a weighted-@xmath64 norm or @xmath72 norm .",
    "the groups and weights are below related to the anticipated importance of wavelet / dct coefficients ; the larger @xmath73 , the more importance is placed on the @xmath74th group of coefficients being sparse .    the problem in ( [ eq : w - l21-min - formulation ] ) can be equivalently rewritten as @xmath75 denote @xmath76 and @xmath77 , where @xmath78 is a given linear manifold and @xmath79 is a weighted-@xmath64 ball with radius @xmath80 .",
    "geometrically , the problem in ( [ eq : w - l21-min - formulation-2 ] ) is to find the smallest weighted-@xmath64 ball that has a nonempty intersection with the given linear manifold ; we refer to this ball as the _ critical ball _ and denote its radius as @xmath81 .",
    "when the smallest intersection is a singleton , the solution to ( [ eq : w - l21-min - formulation-2 ] ) is unique .",
    "we solve ( [ eq : w - l21-min - formulation-2 ] ) as a series of alternating projection problems , @xmath82 where a special rule is used to update @xmath83 to ensure that @xmath84 .",
    "for each @xmath83 , we solve an equivalent problem @xmath85 where @xmath86 is the lagrangian multiplier uniquely associated with @xmath83 .",
    "denote by @xmath87 the multiplier associated with @xmath81 .",
    "it suffices to find a sequence @xmath88 such that @xmath89 .",
    "we solve ( [ eq : w - l21-min - formulation - admm ] ) by alternately projection between @xmath68 and @xmath90 .",
    "given one , the other is solved analytically : @xmath68 is an euclidean projection of @xmath90 on the linear manifold , while @xmath90 is the result of applying group - wise shrinkage to @xmath68 .",
    "an attractive property of gap is that , by using a special rule of updating @xmath91 , we only need to run a single iteration of ( [ eq : w - l21-min - formulation - admm ] ) for each @xmath91 to make @xmath88 converge to @xmath87 . in particular , gap starts from @xmath92 and computes two sequences , @xmath93 and @xmath94 : @xmath95 @xmath96 with @xmath97 a permutation of @xmath98 such that @xmath99    the algorithm ( [ eq : proj - affine])-([eq : weighted - l21-proj - final - t ] ) is referred as _ generalized alternating projection _ ( or gap ) @xcite to emphasize its difference from alternating projection ( ap ) in the conventional sense : conventional ap produces a sequence of projections between two _ fixed _ convex sets , while gap produces a sequence of projections between two convex sets that undergo systematic changes over the iterations .",
    "in the gap algorithm as shown in ( [ eq : proj - affine])-([eq : weighted - l21-proj - final - t ] ) , the alternating projection is performed between a fixed linear manifold @xmath78 and a changing weighted-@xmath64 ball , i.e. , @xmath100 whose radius @xmath83 is a function of the iteration number @xmath9 . by interpreting @xmath101 as a penalty to enforce @xmath102 , one may view that iteration of ( [ eq : w - l21-min - formulation - admm ] ) with @xmath9 constituting a penalty method for solving the following constrained problem , @xmath103 which is an equivalent formulation of ( [ eq : w - l21-min - formulation ] ) .",
    "the gap algorithm in ( [ eq : proj - affine])-([eq : lambdat ] ) is a special penalty method for solving ( [ eq : w - l21-min - formulation - admm - overlap ] ) , using ( [ eq : lambdat ] ) to adjust the penalty strength @xmath104 .",
    "bregman iteration  @xcite can also solve ( [ eq : w - l21-min - formulation ] ) or ( [ eq : w - l21-min - formulation - admm - overlap ] ) .",
    "however , bregman penalizes @xmath105 , while gap keeps @xmath106 as a constraint and fulfills it via the orthogonal projection in ( [ eq : proj - affine ] ) . under a set of group - restricted isometry property ( group - rip ) conditions",
    ", the use of ( [ eq : proj - affine])-([eq : lambdat ] ) ensures monotonic decrease of the reconstruction error to zero and makes gap an anytime algorithm  @xcite .",
    "by contrast , bregman iteration and classic penalty method ( which adjusts @xmath91 differently ) do not have the anytime property , nor do other popular algorithms such as twist and admm  @xcite .",
    "the diagonalization of @xmath107 is the key to fast gap recovery of video .",
    "the inversion of @xmath107 in ( [ eq : proj - affine ] ) now just requires computation of the reciprocals of the diagonal elements , as a result of the _ hardware implementation _ of the proposed camera .",
    "best results were found when @xmath108 and @xmath109 correspond to a wavelet basis ( here the daubechies-8 @xcite ) , and @xmath110 corresponds to a dct .",
    "the basis - function weights ( @xmath111 ) are defined with respect to these bases , and the groups are manifested in the domain of these wavelet - dct coefficients ( see figure [ fig : weight](a ) for a depiction of the groups ) . for @xmath110",
    "the coefficients are arranged from low frequencies to high frequencies in figure [ fig : weight](b ) , and for @xmath108 and @xmath109 the 2d arrangement of coefficients is as is done typically with wavelets @xcite , and illustrated in figure [ fig : weight](c ) .",
    "let @xmath112 represent the edge lengths of each group of coefficients ( figure [ fig : weight](a ) ) . in all experiments , @xmath113 and",
    "@xmath114 $ ] , where @xmath115 $ ] denotes the closest integer of the number inside @xmath115 $ ] . the weight is constituted by the product of a time - weight associated with the dct ( figure [ fig : weight](b ) ) and a scale - weight associated with the wavelets ( figure [ fig : weight](c ) ) .",
    "we show the details of the weight design in the following .",
    "let @xmath116 index each group with @xmath117 .",
    "the time weights are defined by @xmath118 . for the scale weights , we exploit the wavelet - tree structure ( figure [ fig : weight](c ) ) , and enforce the groups in the @xmath119th level ( assuming @xmath120 levels in total , and @xmath121 ) of the wavelet coefficients sharing the same weight , determined by @xmath122 , with @xmath123 denoting the end points of wavelet coefficients at the @xmath119th level , and @xmath124 .",
    "the weight for each 3d group is @xmath125 .",
    "setting @xmath126 was found to yield good results .",
    "after constructing the groups and weights as above , the gap performance is improved significantly in the application here .      in section [ sec : gap ] , each coded cs measurement @xmath127 is employed to recover @xmath25 frames of video .",
    "this may lead to discontinuities in the video recovered from consecutive cs measurements . to mitigate this",
    ", we also consider the _ joint _ inversion of two consecutive cs measurements , @xmath127 and @xmath128 , from which @xmath129 consecutive frames are recovered at once . therefore the @xmath25 frames associated with @xmath127 are estimated jointly from @xmath130 and ( separately ) from @xmath131 .",
    "the final recovered video within a particular contiguous set of @xmath25 frames is taken as the average of the results inferred from @xmath130 and @xmath131 . as demonstrated below , this tends to improve the quality of the recovered video ( yields smoother results ) .",
    "to demonstrate the performance of the reconstruction algorithm , we start with simulated data ( see section  [ sec : real ] for real data from the proposed camera ) , and employ a color video sequence in which a basketball player performs a dunk @xcite ; this video is challenging due to the complicated motion of the basketball players and the varying lighting conditions and multiple depths scene ; see the example video frames in figure [ fig : dec](a ) .",
    "we consider a binary mask , with 1/0 coding drawn at random bernoulli(0.5 ) ; the code is shifted spatially via the coding mechanism in figure [ fig : dec](a ) ) , as in our physical camera .",
    "the video frames are @xmath132 spatially , and we choose @xmath133 .",
    "we first investigate the efficacy of weighted groups in the proposed gap algorithm .",
    "figure [ fig : weight ] demonstrates the improvement by the weighting and grouping of the wavelet / dct coefficients ; these parameters ( weights and groups ) were not optimized , and many related settings yield similar results  there is a future opportunity for optimization . in figure",
    "[ fig : weight ] we also demonstrate the performance improvement manifested by temporal overlapping and averaging results from two consecutive measurements .",
    "note that _ without _ temporal overlapping , the psnr degrades for frames at the beginning ( @xmath134 , 1 , 9 , 17 , ... ) and end ( 8 , 16 , 24 , ... ) of a given measurement , while the psnr curve with temporal overlapping ( red curve ) is much smoother .",
    "the experiments with ( real ) measured data consider temporal overlapping when performing inversion .",
    "( a )    ( b )    [ fig : convergence ]      the developed gap algorithm is compared with the following : @xmath2 ) two - step iterative shrinkage / thresholding ( twist ) @xcite ( with total variation norm ) , @xmath3 ) k - svd @xcite with orthogonal matching pursuit ( omp ) @xcite used for inversion , @xmath135 ) a gaussian mixture model ( gmm ) based inversion algorithm @xcite , and @xmath136 ) the linearized bregman algorithm @xcite .",
    "the @xmath137-norm of dct or wavelet coefficients is adopted in linearized bregman algorithm with the same transformation as gap .",
    "gmm and k - svd are patch - based algorithms and we used a separate dataset for training .",
    "a batch of training videos were used ( shown in the website @xcite ) to pre - train k - svd and gmm , and we selected the best reconstruction results for presentation here .",
    "the psnr curves of videos reconstructed by gap and the four alternative algorithms are shown in figure [ fig : weight_algorithm ] , demonstrating the gap algorithm outperforms the other algorithms by 0.7 - 2db higher in psnr . in this simulation ,",
    "the temporal overlap was not used .",
    "the readers can refer to the reconstructed videos on the website @xcite .",
    "we further investigate the convergence properties of gap , twist and linearized bregman , as they are each solved iteratively .",
    "we run each algorithm a total of @xmath138 iterations and compute the relative mean square error ( mse ) of the estimate compared with the ground truth for each iteration .",
    "relative mse versus iteration number are plotted in figure [ fig : convergence](a ) .",
    "it can be seen that gap and linearized bregman converge much faster than twist , while gap provides the smallest relative mse in every iteration .",
    "we also verify the _ anytime _ property of gap by computing the first - order difference of the mse for each iteration ( compared with twist and bregman ) ; see supplementary material @xcite .",
    "one advantage of the proposed coded aperture compressive camera ( manifested by spatially shifting a _",
    "single _ binary mask ) , compared with others @xcite , is its low - power , low - bandwidth characteristics .",
    "however , the use of a single shifted binary mask to yield temporal coding may appear limiting , and therefore it is of interest to compare to other strategies . in figure [",
    "fig : convergence](b ) we compare the proposed translated coding mechanism in our hardware system with even more general coding strategies than in @xcite .",
    "specifically , we compare to a unique random binary mask at each time point , for which _ each _ of the @xmath25 codes is a _ distinct",
    "_ i.i.d . draw bernoulli(0.5 ) .",
    "we also consider the case for which each code / mask element , for each of the @xmath25 codes , is drawn uniformly at random from [ 0,1 ] , reflecting the degree of code transmission ( each of the @xmath25 codes is distinct , and each is not restricted to be binary ) .",
    "summarizing figure [ fig : convergence](b ) , the simple shifted binary code in the proposed system yields similar results ( even a little higher psnr for some datasets ) compared to these alternative coding strategies , at an order of magnitude less power .",
    "we found similar results when comparing to the coding strategies in @xcite .",
    "the physical camera we have developed captures the measurements ( coded capture ) at @xmath139 fps , and the reconstructed video has 660 fps ( @xmath0 , although different @xmath25 may be considered in the inversion ) .",
    "one result from this camera was shown in figure [ fig : real_ball ] ( recovery of high - speed motion ) . from the reconstructed frames in figure [ fig : real_ball ] ,",
    "one can clearly identify the spin of the red apple and the rebound of the yellow orange ; the full video is at @xcite , along with many addition examples . at @xcite ,",
    "we show comparisons to a diverse set of alternative algorithms , for example via @xcite .",
    "all algorithms considered here were implemented in matlab 2012(a ) , and the experiments are conducted on a pc with a cpu@3.30 ghz and 16 gb ram . for the real data ( @xmath140 ) , gap , twist , and linearized bregman use 50 , 100 , and 500 iterations , respectively ( required to yield good results ) .",
    "each iteration in these three algorithms are similar ( around 0.8 seconds ) .",
    "hence , twist and linearized bregman cost much longer ( @xmath141 ) time than gap , but typically provide worse results , and do not have an anytime property .",
    "k - svd and gmm may be made fast if parallel computing is used ( processing the multiple patches in parallel with gpu or networks ) , but for serial computing on a pc like that considered here these methods are slower than gap .",
    "figure [ fig : results_dynamic ] shows the reconstruction frames ( 6 out of 14 frames are shown for demonstration ) recovered from one measurement .",
    "the three objects ,  newspaper , \"  smile - face \" and  chopper - wheel \" are in three different depths .",
    "the motion of the _ rotating _ chopper - wheel is also recovered from the reconstructed frames .",
    "the first column of the recovered frames ( bottom right of figure [ fig : results_dynamic ] ) shows the newspaper is in focus ; the second column shows the smile - face is in focus , and finally , the chopper - wheel is in focus at column three . we have built a depth - frames relationship table with calibration .",
    "the newspaper is best in focus in frame 3 , which corresponds to 14 cm away from the objective lens ( truth 15 cm ) .",
    "the smile - face is best in focus in frame 8 , corresponding to 40 cm ( truth 38 cm ) .",
    "the chopper - wheel is best in focus in frame 12 , which corresponds to 64 cm ( truth 65 cm ) .",
    "it can be seen the depths of these objects are estimated correctly .",
    "as one additional example of high - speed motion recovery ( assuming all the objects are in focus , @xmath142 , here without the liquid lens ) , figure [ fig : real_hammer ] shows the results of a purple hammer quickly hitting a red apple . in this dataset ,",
    "44 frames are reconstructed from 2 measurements ( left part ) showing the entire process of hitting ( full video is at @xcite ) , and 5 example frames out of 44 are plotted in the right part of figure [ fig : real_hammer ] . to demonstrate the _ anytime _ property of gap , we show the results after 2 , 10 , 20 and 50 iterations . note that good results are manifested with as few as 10 iterations , with convergence after about 20 .              when the scene is not moving , we can get space - depth - color information from the reconstructed data .",
    "an example is shown in figure  [ fig : real_smile ] .",
    "we can see that the smile - face is first out - of - focus , then in - focus and finally out - of - focus again .",
    "this paper proposes a means of recovering depth , time , and color information from a single coded image , via development of a new color cs camera for high - speed depth - video reconstruction . in the presented computational time comparisons ,",
    "gap was run in matlab , since that was the language in which all of the comparison algorithms had available code , and therefore provided a good comparison point for _ relative _ speed . in the context of _ absolute _ speed ,",
    "we have implemented gap in c++ on a gpu , and the _ total _ time for reconstructing a @xmath140 video from a single cs measurement is less than 0.5 seconds , opening the door for real - time fast ( 3d ) video capturing and reconstruction .",
    "this work was supported by darpa under the kecom program , and by the doe , nga , onr , nsf and aro ."
  ],
  "abstract_text": [
    "<S> a simple and inexpensive ( low - power and low - bandwidth ) modification is made to a conventional off - the - shelf color video camera , from which we recover multiple color frames for each of the original measured frames , and each of the recovered frames can be focused at a different depth . </S>",
    "<S> the recovery of multiple frames for each measured frame is made possible via high - speed coding , manifested via translation of a single coded aperture ; the inexpensive translation is constituted by mounting the binary code on a piezoelectric device . to simultaneously recover depth information , a liquid lens is modulated at high speed , via a variable voltage . </S>",
    "<S> consequently , during the aforementioned coding process , the liquid lens allows the camera to sweep the focus through multiple depths . </S>",
    "<S> in addition to designing and implementing the camera , fast recovery is achieved by an anytime algorithm exploiting the group - sparsity of wavelet / dct coefficients . </S>"
  ]
}