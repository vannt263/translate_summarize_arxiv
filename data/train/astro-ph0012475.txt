{
  "article_text": [
    "several groups ( e.g. gawiser & silk 1998 ; webster et al . 1998 ; lineweaver 1998 ; eisenstein , hu & tegmark 1999 ; efstathiou et al . 1999 ; bridle et al .",
    "1999 , 2000 ; bahcall et al .",
    "1999 ) have recently discussed the estimation of cosmological parameters by joint analysis of data sets , e.g. cosmic microwave background ( cmb ) , sne ia , redshift surveys , cluster abundance and peculiar velocities .    while joint likelihood analyses employing both cmb and lss data are allowing more accurate estimates of cosmological parameters , they involve various subtle statistical issues :    * the choice of the model parameter space is somewhat arbitrary .",
    "* one commonly solves for the probability for the data given a model ( e.g. using a likelihood function ) , while in the bayesian framework this should be modified by the prior for the model . *",
    "if one is interested in a small set of parameters , should one marginalise over all the remaining parameters , rather than fix them at certain ( somewhat ad - hoc ) values ? *",
    "the ` topology ' of the likelihood contours may not be simple .",
    "it is helpful when the likelihood contours of different probes ` cross ' each other to yield a global maximum ( e.g. in the case of cmb and sne ) , but in other cases they may yield distinct separate ` mountains ' , and the joint maximum likelihood may lie in a ` valley ' .",
    "* different probes might be spatially correlated , i.e. not necessarily independent .",
    "* what weight should one give to each data set ?",
    "the above points have been discussed in many papers in the cosmological literature and also at this conference . here",
    "we focus on the last point .",
    "a conventional approach does not take into account the fact that different systematics may affect each data set .",
    "the problem arises when data sets are inconsistent with one another .",
    "one approach is to combine inconsistent data sets in the hope that the various systematic effects will tend to cancel out .",
    "however , this may lead to problems if all of parameter space is ruled out by one data set or another .",
    "the orthogonal approach is to choose , somewhat ad - hoc , a mutually , consistent group of data sets to combine .",
    "lahav et al .",
    "( 2000 ; hereafter l2000 ) presented a more objective method for dealing with disagreement between data sets by utilising ` hyper parameters ' ( hereafter hps ) . some previous approaches to this problem of assigning the relative weights of different measurements",
    "have been suggested in the astronomical literature ( e.g. godwin & lynden - bell 1987 ; press 1996 ) .",
    "the derivation of hps is given in section 2 . in section 3",
    "we apply the method to the recent boomerang and maxima cmb experiments , and we estimate the best fit hubble constant ( @xmath4 km / sec / mpc ) .",
    "extensions of the methods are discussed in section 4 .",
    "assume that we have two independent data sets , @xmath5 and @xmath6 ( with @xmath7 and @xmath8 data points respectively ) and that we wish to determine a vector of free parameters @xmath9 ( such as the density parameter @xmath10 , the hubble constant @xmath11 etc . ) .",
    "this is commonly done by minimising @xmath12 ( or , more generally , maximizing the product of likelihood functions ) .",
    "such procedures assume that the quoted observational random errors can be trusted , and that the two ( or more ) @xmath13s have equal weights .",
    "however , when combining ` apples and oranges ' one may wish to allow freedom in the relative weights .",
    "one possible approach is to generalise eq . 1 to be @xmath14 where @xmath15 and @xmath16 are ` hyper - parameters ' , which are to be dealt with the following bayesian way .",
    "there are a number of ways to interpret the meaning of the hps .",
    "one way is to understand @xmath15 and @xmath16 as controlling the relative weight of the two data sets .",
    "it is not uncommon that astronomers accept and discard measurements ( e.g. by assigning @xmath17 and @xmath18 ) in an ad - hoc way .",
    "the procedure proposed by l2000 gives an objective diagnostic as to which measurements are problematic and deserve further understanding of systematic or random errors .",
    "a simple example of the hps is the case that @xmath19 ^ 2\\ ; , \\label{chi2_example}\\ ] ] where the sum is over @xmath7 measurements and corresponding predictions and errors @xmath20 . hence by multiplying @xmath13 by @xmath15 we may interpret each error as effectively becoming @xmath21 .",
    "how do we eliminate the unknown hps @xmath15 and @xmath16 ?",
    "l2000 followed the bayesian formalism given ( in other contexts ) in gull ( 1989 ) , mackay ( 1992 ) , bishop ( 1995 ) and sivia ( 1996 ) . by marginalisation over @xmath15 and @xmath16 we can write the probability for the parameters @xmath22 given the data : @xmath23 using bayes theorem we can write the following relations : @xmath24 and @xmath25 we now make the following assumptions : @xmath26    @xmath27    @xmath28    with the choice of ` non - informative ' uniform priors in the log , @xmath29 we get @xmath30 and @xmath31 ( jeffreys 1939 ) .",
    "note that the integral over priors of this kind diverges ( such a prior is called ` improper ' , see bishop 1995 ) .",
    "these are very conservative priors , essentially stating that we are ignorant about the scale of measurements and errors .",
    "the other extreme is obviously @xmath32 , i.e. when the measurements and errors are taken faithfully .",
    "one can try other forms ( see below ) , but it is likely that these two extreme forms reasonably bracket the probability space .",
    "hence : @xmath33 where @xmath34 and @xmath35    it is common to have a likelihood function of the form of a gaussian in @xmath7 dimensions : @xmath36\\ ; ,    \\label{mvgauss}\\ ] ] where we assume for simplicity that the normalization constant is independent of the parameters @xmath22 ( this is indeed the case in our application for the cmb measurements in the next section ) .",
    "we generalise this form to incorporate @xmath15 as follows : @xmath37 the integral of eq .",
    "11 then gives @xmath38 and similarly for eq .",
    "we note that it is the specific choice of prior for @xmath39 that has led to a change from a gaussian distribution ( eq .",
    "13 ) to a power - law ( eq .",
    "10 can then be written ( ignoring constants ) as @xmath40 to find the best fit parameters @xmath22 requires us to minimise the above probability in the @xmath22 space .",
    "note that in this case our method is equivalent to assuming that we are ignorant of the relative scale of the errors in each experiment .",
    "it is as easy to calculate this statistic as the standard @xmath13 .",
    "16 actually generalises a similar equation derived by cash ( 1979 ) using an entirely different set of assumptions .    since",
    "@xmath15 and @xmath16 have been eliminated from the analysis by marginalisation they do not have particular values that can be quoted .",
    "rather , each value of @xmath15 and @xmath16 has been considered and weighted according to the probability of the data given the model .",
    "however , it may be useful to know which values of @xmath15 and @xmath16 were given the most weight .",
    "this can be estimated by finding the values of @xmath15 and @xmath16 at which eq .",
    "14 peaks : @xmath41 and similarly @xmath42 both evaluated at the joint peak .",
    "we note that if we substitute these effective @xmath15 and @xmath16 in eq .",
    "2 we obtain @xmath43 .",
    "there is of course freedom in choosing the prior .",
    "for example , if we take @xmath44 ( instead of jeffreys prior @xmath30 ) we find that the function to be minimised is @xmath45 instead of eq . 16 .",
    "thus these two priors give very similar results for large @xmath46 .",
    "numerous other priors are possible ( e.g. a top - hat centred on a plausible value ) , but at the expense of more free hps ( e.g. the width of the top - hat ) .",
    "illustrations of the hps approach applied to toy - models are given in bridle ( 2000 ) , and another application of the above hps ( to galaxy cluster data ) is given in diego et al .",
    "the recent boomerang ( hereafter b ; de bernardis et al . 2000 ) and maxima ( hereafter m ; hanany et al .",
    "2000 ) cmb anisotropy measurements yielded high - quality angular power spectra @xmath47 over the spherical harmonics @xmath48 . an important factor in interpreting the data is the calibration error .",
    "the experimental papers quote calibration errors of 10% and 4% ( 1-sigma in @xmath49 ) for b and m , respectively .",
    "the measurements ( with b data corrected upward by 10% , and m data corrected downward by 4 % ) are shown in figure 1 , and they indicate a well defined first acoustic peak at @xmath50 , with less convincing second and third peaks at higher harmonics . these measurements favour ( under certain assumptions ) a flat universe , spectral index @xmath51 and baryon density @xmath52 ( e.g. jaffe et al . 2000 ; bond et al . 2000 ; bridle , this volume ) , which is about 2-sigma higher than the big - bang nucleosynthesis ( bbn ) value @xmath53 ( 95 % cl ; burles et al .",
    "note that the recent cbi result ( padin et al . 2000 ) gives a higher power ( at @xmath54 ) relative to b&m .",
    "jaffe et al . ( 2000 ) fitted models after combining the b & m data sets into one set . here",
    "we take a different approach for joint analysis of the two data sets by utilising the ` hyper - parameters ' .",
    "we illustrate the effect of using hps by application to measurements of the angular power spectrum of the cosmic microwave background ( cmb ) .",
    "numerous groups have now used cmb data to estimate cosmological parameters .",
    "the most common method is the flat bandpower method ( bond 1995 ) in which the difference between observed and predicted flat bandpowers are compared using the @xmath13 statistic ( eq .",
    "we note that non - zero correlations between the cmb data points can make the data points look more smooth which , since the theoretical model is smooth on this scale , will tend to improve the apparent goodness of fit to the model and thus inappropriately give more weight to correlated data points .",
    "we also note that the assumption that the likelihood function is a gaussian is only an approximation ( douspis et al .",
    "2000 ) .",
    "l2000 applied the hps approach to the pre - b&m cmb data sets , in different combinations . here",
    "we apply the method to the recent high - quality b&m data , first in their ` raw ' form and then in their calibrated form . for simplicity , we restrict ourselves to a very limited set of cosmological models .",
    "we obtain theoretical cmb power - spectra using the cmbfast and camb codes ( slejak & zaldarriaga 1996 ; lewis , challinor & lasenby 2000 ) .",
    "we assume that cmb fluctuations arise from adiabatic initial conditions with cold dark matter ( cdm ) and negligible tensor component , in a flat universe with @xmath55 , @xmath56 , @xmath51 , @xmath57k and @xmath58 .",
    "this choice is motivated by numerous other studies which combined cmb data with other cosmological probes ( e.g. jaffe et al .",
    "2000 , bridle et al .",
    "2000 ; hu et al . 2000 ) .",
    "we then investigate the constraints on the remaining parameter , the dimensionless hubble constant , @xmath59  @xmath60 . increasing @xmath61 decreases the height of the first acoustic peak , and makes few other significant changes to the angular power spectrum ( e.g. hu et al . 2000 ) .",
    "the range in @xmath61 investigated here is ( @xmath62 ) .",
    "the results using conventional @xmath13 ( eqs . 1 and 3 ) are shown in table 1 , and with the hps approach ( eq .",
    "16 ) in table 2 .",
    "the full likelihood functions are given in figures 2 and 3 .",
    "we see that the raw ( uncalibrated ) b&m data give two distinct values in the standard @xmath13 analysis .",
    "the hps approach on the raw data suggests that b carries 4.5 times more weight than m ( the ratio of the hps ) , for this particular choice of model and parameter space , yielding a best @xmath63 .",
    "however , the calibration of the data ( as described in the caption to table 1 ) brings the two data sets to much better agreement ( e.g. the ratio of the b / m hps is now 1.3 ) .",
    "in fact , in this case the standard joint @xmath13 and the hps ( for two different choices of priors ; eqs . 16 and 19 ) give the same result , @xmath64 , with slightly smaller error bars in the hps case ( @xmath65 cl ) .",
    "this best fit model is shown in figure 1 .",
    "we also tried the bbn value @xmath66 ( last entries in table 1 and 2 ) , which we can see gives much poorer @xmath13 than the value @xmath58 ( as also suggested by jaffe et al .",
    "2000 and others ) .",
    "[ tableeachalone ]    [ table ]",
    "we have presented a formalism for analysing a combination of measurements , when it is likely that different systematics ( or methods for calculating random errors ) may affect each data set differently . by using a bayesian analysis , and by using a specific ` non - informative ' prior for the ` hyper - parameters ' ( @xmath67 ) , we find that for @xmath68 data sets one should minimise @xmath69 where @xmath70 is the number of measurements in data set @xmath71 .",
    "it is as easy to calculate this statistic as the standard @xmath13 .",
    "the corresponding hps @xmath72 provide useful diagnostics on the reliability of different data sets .",
    "we emphasize that a low hp assigned to an experiment does not necessarily mean that the experiment is ` bad ' , but rather it calls attention to look for systematic effects or better modelling .    in l2000",
    "we analysed pre - b&m data and found that while the standard @xmath13 approach gave a wide range for @xmath11 , the hyper - parameter analysis suggested two distinct values of @xmath11 , @xmath73 and @xmath74 km / sec / mpc .",
    "here we applied the method to the b & m data , with and without calibration .",
    "the hps indeed ` detect ' inconsistencies between the two ` raw ' data sets , but the calibrated data sets show good agreement with each other , as seen in both the @xmath13 and the hps statistics .",
    "we have also seen in this example that the hps solution is insensitive to the exact choice of prior .",
    "the best fit hubble constant is @xmath75 km / sec / mpc ( 95% cl , random errors only ) for a fixed flat cdm @xmath76 model with @xmath51 , @xmath57k and @xmath58 .",
    "we note that if more cosmological parameters are left free and then marginalised over , the error in @xmath61 would typically be larger ( e.g. bond , bridle in this volume ) .",
    "this combination of @xmath77 and @xmath11 corresponds gives for the age of the universe 11.9 gyr .",
    "our derived @xmath11 is slightly higher but still consistent with the ` final result ' of @xmath11 from cepheids and other distance indicators ( freedman et al . 2000 ) @xmath78 km / sec / mpc ( 1-sigma random and systematic errors ) .",
    "the above analysis can be extended in a number of ways .",
    "current and future cmb data can be combined with other cosmological probes ( and their corresponding hps ) , and more cosmological parameters can be kept free .",
    "here we used a simple correction for the calibration error .",
    "a more general approach is to marginalise over both the hps and a calibration probability function ( bridle et al , in preparation ) .",
    "two other aspects which can be modified according to specific problems are the priors @xmath79 and the probability functions @xmath80 .",
    "we shall discuss these extensions elsewhere .",
    "bridle , s.l . ,",
    "eke , v.r . ,",
    "lahav , o. , lasenby , a.n . ,",
    "hobson , m.p . ,",
    "cole , s. , frenk , c.s . ,",
    "henry , j.p . , 1999 ,",
    "mnras , 310 , 565 bridle s.l . , zehavi i. , dekel a. , lahav o. , lasenby a.n . , hobson m.p . , 2000 ,",
    "mnras , in press ( astro - ph/0006170 )              efstathiou g. , bridle s.  l. , lasenby a.  n. , hobson m.  p. , ellis r.  s. 1999 , mnras , 303 , l47 eisenstein , d.j . ,",
    "hu , w. , tegmark , m. , 1999 , apj , 518 , 2 freedman , w.l .",
    ", et al . , 2000 ,",
    "apj , in press ( astro - ph/0012376 )"
  ],
  "abstract_text": [
    "<S> we generalise the procedure for joint estimation of cosmological parameters to allow freedom in the relative weights of various probes . </S>",
    "<S> this is done by including in the joint likelihood function a set of ` hyper - parameters ' , which are dealt with using bayesian considerations . </S>",
    "<S> the resulting algorithm is simple to implement . </S>",
    "<S> we illustrate the method by estimating the hubble constant @xmath0 from the recent cosmic microwave background experiments boomerang and maxima . for an assumed flat @xmath1-cdm model with fixed parameters </S>",
    "<S> @xmath2 we solve for a single parameter , @xmath3 km / sec / mpc ( 95 % cl , random errors only ) , slightly higher but still consistent with recent results from cepheids . </S>",
    "<S> we discuss how the ` hyper - parameters ' approach can be generalised for a combination of cosmic probes , and for other priors on the hyper - parameters .    # </S>",
    "<S> 1#1 8_8 2h^2 # </S>",
    "<S> 1_#1 _ # 1_#1 _ =    # 1 1.25 in .125 in .25 in </S>"
  ]
}