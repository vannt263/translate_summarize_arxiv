{
  "article_text": [
    "over the past few years , security practitioners and policy makers have called for sharing of data related to cyber threats and attacks .",
    "prior work has shown that organizations are exposed to similar vulnerabilities , targeted by the same malevolent actors , and that collaboration could enhance timeliness and accuracy of threat mitigation  @xcite .",
    "the us government recently initiated efforts to encourage the private sector to share cybersecurity information to improve us cyber defenses  @xcite . at the same time , the private sector launched community - based initiatives such as the redsky alliance  @xcite , threatexchange  @xcite , domino  @xcite , and wombat  @xcite .    however , collaborative security initiatives have had little success due to the related confidentiality , privacy , trust , and liability challenges .",
    "sharing security data may damage competitivity , reveal negligence , and expose sensitive and private information .",
    "in fact , data sharing initiatives are often opposed by the privacy community as potentially harmful to individuals  @xcite , while organizations have little choice other than establishing `` circles of trust , '' aiming to control potential loss of competitive advantage and data exposure . alas ,",
    "this creates the need for lengthy out - of - band processes to establish trust , which hinders speediness and economic viability of such initiatives , as highlighted by a recent federal communications commission ( fcc ) report  @xcite .",
    "we investigate whether collaborative threat mitigation can be realized via a _ controlled data sharing _",
    "approach , i.e. , seeking an effective middle ground between sharing everything and sharing nothing , and helping organizations make informed decisions about _ whether or not _ to share data , and _",
    "how much_.    this raises a few compelling research challenges :    1",
    ".   how can organizations _ estimate benefits _ of collaboration ?",
    "what metrics can two organizations use to guide the decision as to whether or not they should share data ? 2 .",
    "can we ensure that benefit estimation occurs in a _ privacy - preserving way _",
    ", so that organizations do not need to disclose their entire datasets , but only the minimum required amount of information ? 3 .",
    "once two organizations decide to collaborate , _ how much _ and _ what _ should they share ?",
    "we address these challenges in the context of _ collaborative predictive blacklisting _ , whereby different organizations aim to forecast attack sources , based on their firewall and intrusion detection systems ( ids ) logs , and also those generated by collaborating organizations .",
    "we model collaboration as a three - step process in which organizations first estimate the benefits of data sharing among each other , then establish partnerships with promising partners , and finally share data with them .",
    "we aim to investigate which collaboration strategies work best , in terms of the resulting improvement in the prediction accuracy and false positive rate .",
    "we experiment with different metrics for estimating the benefits of collaboration , using jaccard , pearson , and cosine similarity of the logs , as well as the size of their intersection .",
    "we also test different degrees of data sharing , e.g. , sharing everything or only information about attacks entities have in common .",
    "one crucial aspect of our work is to impose a fundamental constraint : benefit estimation and data sharing should occur in a privacy - preserving way , which we attain via cryptographic tools for secure two - party computation ( 2pc )  @xcite .",
    "as research in 2pc has produced increasingly efficient and practical implementations , both for general - purpose garbled circuits  @xcite and special - purpose protocols ( e.g. , private set intersection  @xcite ) , the overhead introduced by the privacy protection layer is appreciably low ( cf . section  [ subsec : perf ] ) .    aiming to compare different strategies ,",
    "we perform an empirical evaluation using a real - world dataset of 2 billion suspicious ip addresses collected from dshield.org  @xcite over two months .",
    "this dataset contains a large variety of contributors , which allows us to test the effectiveness of data sharing among diverse groups of victims .",
    "we perform a quantitative analysis of this dataset in order to identify victims and attackers profiles , among other features .",
    "this helps us clean the dataset and design a meaningful ( controlled ) data sharing experiment .",
    "we repeatedly select @xmath0 victims at random and measure the accuracy improvement of the blacklisting algorithm , performing the prediction by means of a standard algorithm based on exponentially weighted moving average ( ewma )  @xcite .",
    "our analysis yields several key findings .",
    "we observe that : ( 1 ) the more information is available about attackers , the better the prediction , as intuitively expected ; ( 2 ) different collaboration strategies yield a large spectrum of prediction accuracy , and in fact , with some strategies , sharing does not help much ; ( 3 ) collaborating with other organizations not only helps improve prediction , but also reduces the false positive rate ; and ( 4 ) sharing information only about common attackers is almost as useful as sharing everything . as a results , we conclude that controlled data sharing can help organizations find the right balance between indiscriminate sharing and non - collaboration , i.e. , sharing just enough data to improve prediction",
    ".    * paper organization . * the rest of the paper is organized as follows : next section overviews related work , then , section  [ sec : preliminaries ] introduces relevant background information .",
    "section  [ sec : framework ] presents our controlled data sharing model for collaborative predictive blacklisting , while section  [ sec : dshield ] discusses the dshield dataset used in our experiments . after presenting the results of our experimental analysis in section  [ sec : experiments ] ,",
    "the paper concludes with section  [ sec : conclusion ] , and appendix  [ app : dshield ] presents additional statistics about the dshield dataset .",
    "previous work on collaborative intrusion detection has usually employed a centralized system where organizations contribute data to trusted third parties ( ttps ) in return for blacklisting recommendations .",
    "zhang et al .",
    "@xcite introduce the notion of highly predictive blacklisting for predicting future attacks based on centralized logs , while follow - up work by soldo et al .",
    "@xcite improve by using an implicit recommendation system and further increase accuracy .",
    "although we re - use one of the prediction algorithms from  @xcite , previous work  @xcite does not take into account privacy and relies on ttps .",
    "prior research attempted to mitigate privacy challenges from security data sharing by relying on data anonymization and sanitization  @xcite .",
    "however , this makes data less useful  @xcite and prone to de - anonymization  @xcite .",
    "other proposals require entities to send encrypted data to a central repository that aggregates contributions  @xcite .",
    "locasto et al .",
    "@xcite propose privacy - preserving data aggregation using bloom filters , which , while constituting a one - way data structure , are vulnerable to simple guessing attacks .",
    "secure distributed data aggregation is also discussed in  @xcite .",
    "while aggregation can help compute statistics , it only identifies most prolific attack sources and yields global models .",
    "as shown in  @xcite , however , generic attack models miss a significant number of attacks , especially when sources choose targets strategically and focus on a few known vulnerable networks , thus yielding poor prediction performance .",
    "previous work has also looked at the possible value of building collaborative and distributed intrusion detection systems .",
    "katti et al .",
    "@xcite are among the first to study correlation among victims and demonstrated the prevalence of `` correlated '' attacks , i.e. , attacks mounted by same sources against different victims .",
    "they find that : ( 1 ) correlations among victims are persistent over time , and ( 2 ) collaboration among victims from correlated attacks improves malicious ip detection time .",
    "they also propose a collaboration mechanism in which victims learn from a centralized entity about other correlated victims , and can then query each other about ongoing attacks .",
    "our work differs from  @xcite as we introduce a controlled data sharing approach and study distributed collaborator selection strategies based on similarity measures , model different data sharing strategies , measure true and false positives of blacklisting recommendations , and address privacy concerns using efficient secure computation techniques .",
    "this section introduces notations and relevant background information .      in the rest of the paper , we assume a group of entities @xmath1 , where each @xmath2 holds a dataset @xmath3 logging suspicious events , such as , suspicious ip addresses observed by a firewall along with corresponding ( time , port ) . for each @xmath4",
    ", we denote with @xmath5 the set of _ unique _ ip addresses in @xmath3 .    each entity",
    "@xmath2 aims to predict and blacklist ip addresses that will generate future attacks .",
    "we consider a controlled data sharing model for collaborative predictive blacklisting , whereby entities estimate the benefits of collaborating in a privacy - preserving way , and then decide with whom , and what , to share .",
    "each entity performs predictions based not only on its own dataset but also on an augmented dataset that comprises information shared by others , aiming to improve prediction and , at the same time , avoiding the wholesale disclosure of datasets . to this end",
    ", we turn to efficient cryptographic protocols for privacy - preserving information sharing , presented below .      *",
    "secure two - party computation ( 2pc )  @xcite * allows two parties , on respective input @xmath6 and @xmath7 , to _ privately _ compute the output of any ( public ) function @xmath8 over @xmath9 . in other words , neither party learns anything about the counterpart s input beyond what can be inferred from @xmath10 .",
    "security of 2pc protocols is formalized by considering an ideal implementation where a trusted third party ( ttp ) receives the inputs and outputs the result of the function : then , in the real implementation of the protocol ( without a ttp ) , each party does not learn , provably , more information than in the ideal implementation .",
    "the first 2pc instantiation , based on garbled circuits , was presented by yao  @xcite  since then , optimizations and more efficient constructions have been presented , such as  @xcite .",
    "* private set intersection ( psi )  @xcite * is a 2pc primitive that lets two parties , a server on input a set @xmath11 , and a client on input a set @xmath12 , interact so that the latter only learns @xmath13 , and the former learns nothing ( besides @xmath14 ) .",
    "state - of - the - art instantiations include both garbled - circuit based techniques  @xcite and specialized protocols  @xcite .    * psi with data transfer ( psi - dt )  @xcite * extends psi as follows : it involves a server on input a set @xmath11 where each item is associated to a data record , and a client on input a set @xmath12 .",
    "psi - dt allows @xmath12 to learn the set intersection , along with the data records associated to the items in the intersection ( and nothing else ) , while @xmath11 learns nothing .",
    "* private set intersection cardinality ( psi - ca )  @xcite * is a more `` stringent '' variant than psi , as it only reveals the magnitude of the intersection , but not the actual contents .    *",
    "private jaccard similarity ( pjs )  @xcite * allows two parties , a server on input a set @xmath11 , and a client on input a set @xmath12 , to interact in such a way that the client only learns the jaccard similarity  @xcite between their respective sets , i.e. ,  @xmath15 .",
    "pjs can be instantiated using psi - ca only , since secure computation techniques ( including psi - ca ) always reveal the size of inputs ( i.e. , size of sets in psi - ca ) .    in the rest of the paper , security of protocols discussed above",
    "is assumed in the honest - but - curious model , i.e. , parties are assumed to follow protocol specifications and not to misrepresent their inputs , but , during or after protocol execution , they might attempt to infer additional information about other parties inputs .",
    "let @xmath16 denote the day an attack was reported and @xmath17 the current time , so @xmath18 .",
    "we define a training window , @xmath19 and a testing window , @xmath20 .",
    "prediction algorithms usually rely on information in the training data , @xmath21 , to tune their model and validate the predictions for the testing data , @xmath22 .",
    "the global worst offender list ( gwol ) is a basic prediction algorithm that selects top attack sources from @xmath19 , i.e. , highest number of globally reported attacks  @xcite .",
    "local worst offender list ( lwol ) is the local version of gwol and operates on a local network based entirely on its own history  @xcite .",
    "lwol fails to predict on attackers not previously seen , while gwol tends to be irrelevant to small victims .",
    "thus , machine learning algorithms were suggested to improve gwol and lwol  @xcite .",
    "we use the _ exponentially weighted moving average ( ewma ) _ algorithm , as proposed by soldo et al .",
    "@xcite , to perform blacklisting prediction .",
    "ewma uses time series aggregation : it aggregates attack events from @xmath19 to predict future attacks .",
    "note that it is out of the scope of this paper to improve on existing prediction algorithms .",
    "rather , we focus on evaluating the feasibility of controlled data sharing for collaborative threat mitigation and , specifically , on measuring how different collaboration strategies perform in comparison to each other",
    ".    * accuracy metrics .",
    "* as commonly done with prediction algorithms , we measure accuracy with * _ true positives _ ( tp ) * , which is the number of predictions that correctly match future events . in practice",
    ", potentially malicious sources might not be blacklisted at once as blacklisting algorithms rely on several observations over time , such as the rate at which the source is attacking or the payload of suspicious packets .",
    "therefore , it is important to distinguish between the _ prediction _ and the _ blacklisting _ algorithm : the former identifies potential malicious sources and/or creates a watch - list , which is fed to the latter in order to help decide whether or not to block sources .",
    "the prediction algorithm thus enables the identification of suspicious ip addresses that deserve further scrutiny and improve the effectiveness of blacklisting algorithms .",
    "therefore , prior work  @xcite focused almost exclusively on measuring tp and ignored other accuracy measures such as false positives .",
    "by contrast , we decide to also study * _ false positives ( fp ) _ * , i.e. , the number of predictions that are incorrect .",
    "this measurement helps us better understand the possible negative overhead introduced by data sharing .    * upper bounds . * as in previous work  @xcite , we use two upper bounds to evaluate the accuracy of the prediction , aiming to take into account the fact that a future attack can be predicted only if it already appeared in the logs of some victims . the global upper bound @xmath23 measures , for every target @xmath2 , the number of attackers that are both in the training window _ of any victim _ and in @xmath2 s testing window .",
    "for every @xmath2 , we also define the local upper bound @xmath24 , as the number of attackers that are both in @xmath2 s training and testing windows .",
    "we outline our controlled data sharing approach for collaborative predictive blacklisting .",
    "it involves three steps :    1 .   estimating the benefits of sharing security data between potential partners , in a privacy - preserving way ( i.e. , without disclosing the datasets ) ; 2 .   establishing partnerships ; 3 .",
    "sharing data in a privacy - respecting way and guaranteeing that collaborating entities only share what is agreed upon .",
    "we consider several similarity metrics to estimate the benefits of collaboration : we report them in table  [ tab : metric-1 ] , along with the corresponding protocols for their privacy - preserving computation .",
    "we look at similarity metrics since previous work  @xcite has shown that collaborating with _ correlated victims _ works well , i.e. , entities targeted by attacks mounted by the same source against different networks ( around the same time ) .",
    "intuitively , correlation arises from attack trends as correlated victim sites might be on a single hit list or natural targets of a particular exploit .",
    "we consider two set - based metrics , i.e. , _ intersection - size _ and _ jaccard _ , which measure set similarity and operate on unordered sets , as well as _",
    "pearson _ and _ cosine _ similarity , which provide a more refined measure of similarity as they also capture statistical relationships .",
    "the last two metrics operate on data structures representing attack events , such as a binary vector , e.g. , @xmath25 $ ] , of all possible ip addresses with 1-s if an ip attacked at least once and 0-s otherwise .",
    "this can make it difficult to privately compute correlation in practice , as both parties need to agree on the range of ip addresses under consideration to construct vector @xmath26 .",
    "considering the entire range of ip addresses is not reasonable ( i.e. , this would require a vector of size 3.7 billion , one entry for each routable ip address ) .",
    "instead , parties could either agree on a range via secure computation or fetch predefined ranges from a public repository .",
    "all the functions we consider are symmetric , i.e. , both parties obtain the same value , however , some of the protocols used for secure computation of the benefit estimate , such as psi - ca  @xcite and pjs  @xcite , reveal the output of the protocol to only one party . without loss of generality ,",
    "we assume that this party always reports the output to its counterpart , which is a common assumption in the honest - but - curious model .    in practice , one could use any combination of metrics .",
    "also , the list in table  [ tab : metric-1 ] is non - exhaustive and other metrics could be considered , as long as it is possible to efficiently support their privacy - preserving computation .      after estimating the benefits of collaboration , in order to establish partnerships",
    ", entities could follow different strategies , acting in a distributed way or relying on a coordinating entity .",
    "for instance , an organization could request the collaboration of all entities for which estimated benefits are above a threshold ( i.e. , based on a",
    "_ `` local threshold '' _ ) , or enlist the @xmath27 partners with maximum expected benefits ( _ `` local maximization '' _ ) .",
    "local approaches have the advantage of not involving any third parties , but may require complex negotiations in order to reach a partnership agreement , as collaboration incentives may be asymmetric , e.g. , party a might be willing to collaborate with b , but b might prefer to do so with c. with centralized approaches , a semi - trusted server collects estimated benefits ( but not datasets ) and clusters entities so that those in the same cluster collaborate ( _ `` clustering '' _ ) , or encourage sharing among the pairs with highest expected benefits seeking a global utility - vs - cost optimum ( _ `` global maximization '' _ ) .    naturally , an appropriate partner selection strategy heavily depends on the use - case scenario and the trade - offs that organizations are willing to pursue . hence , some strategies might work well in different settings depending on economic , strategic , and operational factors .",
    "the evaluation of the different partnership strategies is an interesting research problem , particularly amenable to a game - theoretic analysis . in this work ,",
    "we _ do not experiment with different strategies to establish partnerships _ and leave such an analysis for future work . as a result , in our experiments ( section  [ sec : experiments ] ) , we fix one partner selection strategy and focus on the evaluation of different benefit estimation and data sharing mechanisms .",
    "after two entities have established a partnership , they can proceed to share their data with each other .",
    "this process can occur in different ways , e.g. , they can disclose their whole datasets or only share which ip addresses they have in common , with or without all attack events associated to common addresses . following our controlled data sharing approach , nothing is to be disclosed beyond what is agreed upon ( and , ideally , what is beneficial ) .",
    "for instance , if partners agree to only share information about common attackers , they should not learn any other information .",
    "possible sharing strategies we consider , along with the corresponding privacy - preserving protocols , are reported in table  [ tab : metric-3 ] .",
    "again , we assume that the output of the sharing protocol is revealed to both parties .",
    "strategies denoted as _ intersection / union with associated data _",
    "mean that parties not only compute and share the intersection ( resp .",
    ", union ) , but also all events related to items in the resulting set .",
    "obviously , union with associated data does not yield any privacy , as all events are mutually shared , but we include it to compare its efficacy to intersection with associated data .",
    "as we aim to evaluate the viability of the controlled data sharing approach and compare how different sharing strategies impact prediction accuracy , we need to design an experiment involving real - world data pertaining to suspicious ip addresses and observed by different organizations . to this end , as done in prior work  @xcite , we turn to dshield.org  @xcite : this section introduces the data we collect from dshield , and the methodology we use to clean it and to design a meaningful data sharing experiment .",
    "+    [ fig : average ]      we obtained two months worth of anonymized logs from dshield.org  @xcite , a community based repository of intrusion detection system logs that publishes blacklists of most prolific attack sources reported in these logs .",
    "each entry in the logs includes an anonymized contributor i d ( the target ) , a source ip address ( the suspected attacker ) , a target port number , and a timestamp , as illustrated in table  [ tab : illustrationdshield ] . note that dshield anonymized the `` contributor i d '' field by replacing it with a random yet _ unique _ string that maps to a single victim .",
    ".example of an entry in the dshield logs . [ cols=\"^,^,^,^,^\",options=\"header \" , ]      first , we observe that metrics with a normalization factor ( i.e. , all but _ intersection - size _ ) tend to favor partnerships with small collaborators . _",
    "intersection - size _ leads to better performance because it promotes collaboration with larger victims . to confirm this hypothesis , we measure the set size of collaborators according to different metrics ( fig .  [ fig : boxplot ] ) and confirm that metrics with a normalization factor tend to suggest partnerships with collaborators that know less .",
    "second , _ pearson _ and _ cosine _ tend to select partners that are _ too _ similar : maximum correlation values are close to @xmath28 , whereas maximum _ jaccard _ values only reach @xmath29 .",
    "although this implies that targets learn to better defend against specific adversaries , it also leads to little acquired knowledge .",
    "third , depending on the metric , entities may partner with previous collaborators , or with new ones .",
    "we find that _ intersection - size _ , _ pearson _ , and _ cosine _ lead to stable groups of collaborators with about 90% reuse over time , whereas _",
    "_ has larger diversity of collaborators over time .",
    "this is because about 20% of victims have high _ jaccard _ similarity compared to 4% for _ pearson _ and _ cosine _ , providing a larger pool of potential collaborators .",
    "hence , if _ intersection - size _ helps a few learn a lot , _ jaccard _ helps many victims over time .    * statistical analysis . *",
    "a t - test analysis shows that the mean of the number of events known by collaborators differs significantly ( @xmath30 ) across all pairs of benefit estimation metrics but _ cosine _ and _ pearson_. if one categorizes collaborators as `` large '' if they have seen more than @xmath31 events , and `` small '' otherwise , and consider _ cosine _ and _ pearson _ as one ( given the t - test result ) , we obtain a @xmath32x@xmath33 table of benefit estimation metrics and size categories .",
    "a @xmath34-test shows that categorization differences are statistically significant : _ intersection - size _ tends to select larger collaborators , but also more collaborators than _ pearson / cosine _ ( see table  [ tab : improvements ] ) .",
    "other metrics tend to select small collaborators .",
    "we obtain @xmath35 , where @xmath33 is the degrees of freedom of the @xmath34 estimate , and @xmath36 is the total number of observations .    * coalitions . *",
    "recall that , at each time step , different benefit estimation strategies lead to different partnerships in our analysis .",
    "table  [ tab : improvements ] shows the mean , standard deviation ( sd ) , and median number of collaborators per party for different collaboration metrics .",
    "we observe that with _ jaccard _ , coalitions are smaller and thus entities tend to select less collaborators .",
    "other metrics tend to have similar behavior and lead entities to collaborate with about @xmath37 other entities out of @xmath0 .",
    "this is in line with previous work  @xcite , which showed the existence of small groups of correlated entities .",
    "we also observe that , after a few days ( usually @xmath33 ) , _ intersection - size _ , _ pearson _ , and _ cosine _ converge to a relatively stable group of collaborators .",
    "from one time - step to another , parties continue to collaborate with about 90% of entities they previously collaborated . in other words ,",
    "coalitions are relatively stable over time .",
    "comparatively , _ jaccard _ has a larger diversity of collaborators over time .",
    "the next step is to compare the average prediction improvement @xmath38 resulting from different data sharing strategies . as showed in fig .",
    "[ fig : union ] , _ intersection with associated data _ performs almost as good as _ union with associated data _ with all benefit estimation metrics .",
    "it performs even better when using _",
    "jaccard_.    sharing using the union entails sharing more information , thus , one would expect it to always perform better  however , organizations quickly converge to a stable set of collaborators , and obtain a potentially lower diversity of insights over time . with most metrics ,",
    "the set of collaborators is stable over time in any case , and so union does perform better than intersection . as previously discussed , _",
    "jaccard _ tends to yield a larger diversity of collaborators over time and thus benefits more from _ intersection with associated data _ as it re - enforces such diversity of insights .",
    "we estimate the operational cost of using cryptographic techniques for the secure computation of the benefit estimation and the data sharing routines .    excluding _ pearson _ and _ cosine _ ( due to lower accuracy improvement ) , the protocols for privately estimating benefits of collaborating ( _ intersection - size _ and _ jaccard _ ) can all be realized based on private set intersection cardinality ( psi - ca ) .",
    "we chose the instantiation proposed in @xcite , which incurs computation and communication overhead linear in sets size .",
    "privacy - preserving data sharing , i.e. , _ intersection with associated data _ , is instantiated using the psi - dt protocol from  @xcite .",
    "we implemented protocols in c , using gmp and openssl cryptographic libraries , and measured total running times using two intel xeon desktops with 3.10ghz cpu connected by a 100mbps ethernet link . using sets of size @xmath39",
    ", it takes approximately @xmath40 to execute psi from  @xcite and @xmath41 for the psi - ca from  @xcite . assuming that @xmath0 organizations are possible partners , there would be @xmath42 pairwise executions of psi - ca and psi - dt in the worst case , yielding a total running time close to @xmath43 for psi - ca and @xmath44 for psi - dt .",
    "that is , it would take less than one minute for one entity to estimate benefits , using psi - ca , with all other ( @xmath45 ) parties , and also less than one minute to share data with all possible @xmath45 partners . in summary",
    ", overhead is appreciably low and could accommodate real - world scenarios where interactions occur several times a day .",
    "our experiments confirm that targets that know more tend to successfully predict more attacks .",
    "however , as indiscriminate sharing poses serious confidentiality , privacy , trust , and liability challenges , we have considered a controlled data sharing approach aiming to identify partners that help most . in our experiments",
    ", _ intersection - size _ proves to be the best metric to estimate the benefits of collaborating .",
    "interestingly , we find that if victims datasets are very similar , data sharing yields little gain , since there is little to learn .",
    "this is reinforced by the fact that similarity metrics with a normalization factor favor victims with small datasets .",
    "we find that sharing data with partners using _ intersection with associated data _ performs almost as good as sharing everything ( _ union _ ) . not only does intersection provide convenient privacy properties , it also indicates that there is more value in learning about current attackers than other potential attack sources .",
    "intuitively , intersection reinforces knowledge about attackers known to a victim , whereas , union might help victims targeted by varying group of attackers .",
    "thus , victims benefit as much from improving their knowledge about current attackers , as learning about other sources ( that could possibly attack them next ) . in brief , good partners are related but not identical , and should share information about known past attackers .",
    "* limitations .",
    "* the dshield dataset used in our experiments might be biased toward small organizations that _ voluntarily _ report attack data .",
    "thus , it might not be directly evident how to generalize our results . however",
    ", our findings indicate that controlled data sharing can remarkably improve prediction , and show statistical evidence that different collaboration strategies affect performance in interesting ways .",
    "we also make a few simplifying assumptions in our experimental setup , e.g. , sampling @xmath0 random organizations from the dshield dataset , and establish partnerships by selecting the top 1% pairs in the benefit estimation matrix .",
    "although we leave the evaluation of the different partnership strategies as part of future work , our choices are conservative , thus yielding lower - bound estimates of the benefits of collaboration .",
    "we investigated the viability of a controlled data sharing approach to collaborative threat mitigation .",
    "we focused on collaborative predictive blacklisting and explored how organizations could quantify expected benefits in a privacy - preserving way ( i.e. , without disclosing their datasets ) before deciding whether or not to share data , and how much .",
    "we performed an empirical evaluation on a dataset of 2 billion suspicious ip address , contributed by @xmath46,@xmath47 organizations to dshield.org over a period of two months .",
    "we observed a significant improvement in prediction accuracy ( up to 105% , even when only 1% of all possible partners collaborate ) , along with a reduction in the false positive rate .",
    "our analysis showed that some collaboration strategies work better than others .",
    "the number of common attacks provides a good estimation of the benefits of sharing , as it drives entities to partner with more knowledgable collaborators .",
    "in fact , only sharing information about common attacks proves to be almost as useful as sharing everything .",
    "our work is the first to show that collaborative threat mitigation does not have to be an `` all - or - nothing '' process : by relying on efficient cryptographic protocols , organizations can share only relevant data , and only when beneficial .    as part of future work",
    ", we intend to study other metrics for benefit estimation ( e.g. , dissimilarity , data quality  @xcite ) and experiment with other prediction algorithms .",
    "we also plan to study and experiment with distributed partner selection strategies , possibly relying on the stable roommate matching problem  @xcite .",
    "finally , we will explore how to adapt our approach to other collaborative security problems , e.g. , spam filtering  @xcite , malware detection  @xcite , or ddos mitigation  @xcite .",
    "* acknowledgments . *",
    "we wish to thank dshield.org and johannes ullrich for providing the dataset used in our experiments , as well as ersin uzun , marshall bern , craig saunders , and anton chuvakin for their useful comments and feedback .",
    "work done in part while emiliano de cristofaro was with parc .",
    "[ app : dshield ]",
    "* general statistics . *",
    "we present in fig .  [",
    "fig : general : subfig1 ] the histogram of the number of attacks per day , indicating about @xmath48 m daily attacks .",
    "we observe a significant increase around day @xmath49 to @xmath0 m attacks .",
    "careful analysis reveals that a series of ip addresses starts to aggressively attack around day @xmath49 , indicating a possible dos attack initiation .",
    "[ fig : general : subfig3 ] shows the number of unique targets and sources over time .",
    "detailed analysis shows a stable number of sources and targets .",
    "this stability confirms that it should be possible to predict attackers tactics based on past observations .",
    "an analysis of attacked ports shows that top 10 attacked ports ( with more than 10 m hits ) are telnet , http , ssh , dns , ftp , bgp , active directory , and netbios ports .",
    "this shows a clear trend towards misuse of popular web services",
    ".      * predictability . * fig .  [ fig : entropy ] shows the cdf of the shannon entropy of the different log entry elements .",
    "it helps us visualize the uncertainty about a given ip address , port number or target appearing in the logs , and thus estimate our ability to predict those values . to obtain this figure , we estimate the probability of each victim , source or port being attacked each day .",
    "for example , for each port @xmath4 , we compute : @xmath50    we also compute the entropy for each day and aggregate it overall using the cdf .",
    "previous work  @xcite showed that , following fano s inequality , entropy correlates with predictability .",
    "we observe that ports numbers have the lower entropy distribution , indicating a small set of targeted ports : @xmath51 of attacks target a set of @xmath52 ports , indicating high predictability .",
    "we also observe that victims are more predictable than sources , as @xmath53 of victims lie within a set of @xmath54 victims as compared to @xmath53 of sources being in a list of @xmath55 sources .",
    "victims set is thus significantly smaller and more predictable than attackers set .    *",
    "intensity . * fig .",
    "[ fig : interarrival : subfig1 ] shows the inter - arrival time of attacks in hours , and fig .",
    "[ fig : interarrival : subfig2 ] shows the inter - arrival time of attacks in seconds .",
    "we observe that almost all attacks occur within 3-minute windows .",
    "ip addresses and @xmath56 subnetworks have similar behavior .",
    "in particular , fig .  [",
    "fig : interarrival : subfig2 ] shows that in short time intervals , @xmath57 of @xmath58 subnetworks have short attack inter - arrival time indicating the bursty attacks on such networks .",
    "attackers target subnetworks for a short time and then disappear ."
  ],
  "abstract_text": [
    "<S> although sharing data across organizations is often advocated as a promising way to enhance cybersecurity , collaborative initiatives are rarely put into practice owing to confidentiality , trust , and liability challenges . in this paper </S>",
    "<S> , we investigate whether collaborative threat mitigation can be realized via a _ controlled data sharing _ </S>",
    "<S> approach , whereby organizations make informed decisions as to whether or not , and how much , to share . </S>",
    "<S> using appropriate cryptographic tools , entities can estimate the benefits of collaboration and agree on what to share in a _ privacy - preserving _ way , without having to disclose their datasets .    </S>",
    "<S> we focus on collaborative predictive blacklisting , i.e. , forecasting attack sources based on one s logs and those contributed by other organizations . </S>",
    "<S> we study the impact of different sharing strategies by experimenting on a real - world dataset of two billion suspicious ip addresses collected from dshield over two months . </S>",
    "<S> we find that controlled data sharing yields up to 105% accuracy improvement on average , while also reducing the false positive rate . </S>"
  ]
}