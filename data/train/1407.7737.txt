{
  "article_text": [
    "proposed algorithms are usually tested on benchmark for comparing both performance and efficiency . however , as it can be a very tedious task to select and implement test functions rigorously .",
    "thanks to gpus massive parallelism , a gpu - based optimization function suit will be beneficial to test and compare optimization algorithms .",
    "based on the well known cpu - based benchmarks presented in @xcite , we proposed a cuda - based real parameter optimization test suit , called curob , targeting on gpus .",
    "we think curob can be helpful for assessing gpu - based optimization algorithms , and hopefully , conventional cpu - based algorithms can benefit from curob s fast execution .",
    "considering the fact that research on the single objective optimization algorithms is the basis of the research on the more complex optimization algorithms such as constrained optimization algorithms , multi - objective optimizations algorithms and so forth , in this first release of curob a suit of single objective real - parameter optimization function are defined and implemented .",
    "the test functions are selected according to the following criteria : 1 ) the functions should be scalable in dimension so that algorithms can be tested under various complexity ; 2 ) the expressions of the functions should be with good parallelism , thus efficient implementation is possible on gpus ; 3 ) the functions should be comprehensible such that algorithm behaviours can be analysed in the topological context ; 4 ) last but most important , the test suit should cover functions of various properties in order to get a systematic evaluation of the optimization algorithms .    the source code and a sample can be download from code.google.com / p / curob/.      symbols and definitions used in the report are described in the following . by default ,",
    "all vectors refer to column vectors , and are depicted by lowercase letter and typeset in bold .",
    "* @xmath0 $ ] indicates the nearest integer value * @xmath1 indicates the largest integer less than or equal to * @xmath2 denotes @xmath3-th element of vector @xmath4 * @xmath5 , @xmath6 and @xmath7 multi - variable functions * @xmath8 optimal ( minimal ) value of function @xmath9 * @xmath10 optimal solution vector , such that @xmath11 * @xmath12 normalized orthogonal matrix for rotation * @xmath13 dimension * @xmath14 all one vector      the general setup of the test suit is presented as follows .    *",
    "* dimensions * the test suit is scalable in terms of dimension . within the hardware limit , any dimension @xmath15 works",
    "however , to construct a real hybrid function , @xmath13 should be at least @xmath16 . * * search space * all functions are defined and can be evaluated over @xmath17 , while the actual search domain is given as @xmath18^d$ ] .",
    "* * @xmath8 * all functions , by definition , have a minimal value of 0 , a bias ( @xmath8 ) can be added to each function .",
    "the selection can be arbitrary , @xmath8 for each function in the test suit is listed in tab.[tab : summary ] .",
    "* * @xmath10 * the optimum point of each function is located at original .",
    "@xmath10 which is randomly distributed in @xmath19^d$ ] , is selected as the new optimum . * * rotation matrix * to derive non - separable functions from separable ones , the search space is rotated by a normalized orthogonal matrix @xmath12 . for a given function in one dimension ,",
    "a different @xmath12 is used .",
    "variables are divided into three ( almost ) equal - sized subcomponents randomly .",
    "the rotation matrix for each subcomponent is generated from standard normally distributed entries by gram - schmidt orthonormalization .",
    "then , these matrices consist of the @xmath12 actually used .",
    "a simple description of the interface and implementation is given in the following .",
    "for detail , see the source code and the accompanied readme file .      only benchmark.h need to be included to access the test functions , and the cuda file benchmark.cu need be compiled and linked . before the compiling start",
    ", two macro , dim and max_concurrency should be modified accordingly .",
    "dim defines the dimension of the test suit to used while max_concurrency controls the most function evaluations be invoked concurrently . as memory",
    "needed to be pre - allocated , limited by the hardware , do nt set max_concurrency greater than actually used .",
    "host interface function initialize ( ) accomplish all initialization tasks , so must be called before any test function can be evaluated .",
    "allocated resource is released by host interface function dispose ( ) .",
    "both double precision and single precision are supported through func_evaluate ( ) and func_evaluatef ( ) respectively .",
    "take note that device pointers should be passed to these two functions .",
    "for the convenience of cpu code , c interfaces are provided , with h_func_evaluate for double precision and h_func_evaluatef for single precision .",
    "( in fact , they are just wrappers of the gpu interfaces . )      when configuration of the suit , some should be taken care for the sake of efficiency .",
    "it is better to evaluation a batch of vectors than many smaller .",
    "dimension is a fold of 32 ( the warp size ) can more efficient .",
    "for example , dimension of 96 is much more efficient than 100 , even though 100 is little greater than 96 .",
    "the test functions fall into four categories : unimodal functions , basic multi - modal functions , hybrid functions and composition functions .",
    "the summary of the suit is listed in tab.[tab : summary ] .",
    "detailed information of each function will given in the following sections .",
    "under different hardware , various speedups can be achieved .",
    "30 functions are the same as cec14 benchmark .",
    "we test the curob s speedup with these 30 functions under the following settings : windows 7 sp1 x64 running on intel i5 - 2310 cpu with nvidia 560 ti , the cuda version is 5.5 .",
    "50 evaluations were performed concurrently and repeated 1000 runs .",
    "the evaluation data were generated randomly from uniform distribution .",
    "the speedups with respect to different dimension are listed by tab.[tab : speedup : float ] ( single precision ) and tab.[tab : speedup : double ] ( double precision ) .",
    "notice that the corresponding dimensions of curob are 10 , 32 , 64 and 96 respectively and the numbers are as in tab.[tab : summary ]    fig .",
    "[ fig : overall_speedup ] demonstrates the overall speedup for each dimension . on average , curob is never slower than its cpu - base cec14 benchmark , and speedup of one order of magnitude can be achieved when dimension is high .",
    "single precision is more efficient than double precision as far as execution time is concerned .",
    ".speedup ( single precision ) [ cols=\"^,>,>,>,>,>,>,>,>,>,>\",options=\"header \" , ]     [ tab : speedup : double ]     +",
    "@xmath20    where @xmath21 .",
    "* unimodal * non - separable * highly symmetric , in particular rotationally invariant      @xmath22    where @xmath21 .      * unimodal * non - separable      @xmath23    where @xmath21 .      * unimodal * non - separable * quadratic ill - conditioned * smooth local irregularities      @xmath24    where @xmath21 .      * unimodal * non - separable * smooth local irregularities * with one sensitive direction      @xmath25    where @xmath21 .      * unimodal * non - separable * optimum located in a smooth but very narrow valley      @xmath26    where @xmath27 .",
    "* unimodal * non - separable * sensitivities of the @xmath28-variables are different      @xmath29    where @xmath21 .",
    "* unimodal * non - separable * global optimum located in a sharp ( non - differentiable ) ridge",
    "@xmath30    where @xmath21      * many plateaus of different sizes * non - separable      @xmath31    where @xmath32 , @xmath33 , @xmath34 , @xmath35 .      * multi - modal * non - separable * continuous everywhere but only differentiable on a set of points      @xmath36    where @xmath37 .      * multi - modal * non - separable * with many regularly distributed local optima      @xmath38    where @xmath39 .",
    "* multi - modal * separable * with many regularly distributed local optima      @xmath40    where @xmath41 .      * multi - modal * non - separable * with many regularly distributed local optima      @xmath42    where @xmath43 , @xmath21 .      * multi - modal * non - separable      @xmath44    @xmath45    where @xmath46 .      * multi - modal * non - separable *       @xmath47    where @xmath48 .",
    "* multi - modal * non - separable * with a long , narrow , parabolic shaped flat valley from local optima to global optima      @xmath49    @xmath50    where @xmath51 .",
    "* multi - modal * separable * having many local optima with the second better local optima far from the global optima      @xmath52    where @xmath53 and @xmath54 is defined as eq.[eq : basic_schwefel ] .",
    "* multi - modal * non - separable * having many local optima with the second better local optima far from the global optima      @xmath55|}{2^j})^{\\frac{10}{d^{1.2 } } } - \\frac{10}{d^2 }   + f_{opt}\\ ] ]    where @xmath56 .",
    "* multi - modal * non - separable * continuous everywhere but differentiable nowhere      @xmath57    where @xmath58 , @xmath59 , @xmath60 , @xmath61 , @xmath62 .      * multi - modal * non - separable * with two funnel around @xmath63 and @xmath64      @xmath65    where @xmath21 .",
    "* multi - modal * non - separable * having many local optima with the global optima located in a very small basin      @xmath66    where @xmath67 .      * multi - modal * non - separable * global optima located in curved narrow valley      @xmath68    where @xmath67 .      * multi - modal * non - separable * global optima located in curved narrow valley      @xmath69 @xmath70 where @xmath21 .      * multi - modal * non - separable",
    "hybrid functions are constructed according to @xcite . for each hybrid function , the variables are randomly divided into subcomponents and different basic functions ( unimodal and multi - modal ) are used for different subcomponents , as depicted by eq.[eq : hybrid ] .",
    "@xmath71 where @xmath72 is the constructed hybrid function and @xmath73 is the @xmath3-th basic function used , @xmath74 is the number of basic functions .",
    "@xmath28 is constructed as follows .",
    "@xmath75\\\\ \\mathbf{z}^2\\quad =   & [ \\mathbf{y}_{s_{n_{1}+1}},\\mathbf{y}_{s_{n_{1}+2 } } \\cdots \\mathbf{y}_{s_{n_{1}+n2}}]\\\\   & \\hspace { 2 cm } \\vdots\\\\ \\mathbf{z}^n\\quad = & [ \\mathbf{y}_{s_{(\\sum_{i=1}^{n-1}n_i ) + 1}},\\mathbf{y}_{s_{(\\sum_{i=1}^{n-1}n_i)+2}},\\dots,\\mathbf{y}_{s_{n_d } } ] \\end{array}\\ ] ] where @xmath76 is a permutation of @xmath77 , such that @xmath78 $ ] forms the transformed vector and @xmath79 are the dimensions of the basic functions , which is derived as eq.[eq : numbers ] .",
    "@xmath80 @xmath81 is used to control the percentage of each basic functions .      *",
    "@xmath82 * @xmath83 $ ] * @xmath84 : modified schwefel s function * @xmath85 : rastrigin function * @xmath86 : high conditioned elliptic function      * @xmath87 * @xmath83 $ ] * @xmath84 : bent cigar function * @xmath85 : hgbat function * @xmath86 : rastrigin function      * @xmath88 * @xmath89 $ ] * @xmath84 : griewank function * @xmath85 : weierstrass function * @xmath86 : rosenbrock function * @xmath90 : expanded scaffer s f6 function      * @xmath88 * @xmath89 $ ] * @xmath84 : hgbat function * @xmath85 : discus function * @xmath86 : expanded griewank plus rosenbrock function * @xmath90 : rastrigin function      * @xmath87 * @xmath91 $ ] * @xmath84 : expanded scaffer s f6 function * @xmath85 : hgbat function * @xmath86 : rosenbrock function * @xmath90 : modified schwefel s function * @xmath92 : high conditioned elliptic function      * @xmath87 * @xmath91 $ ] * @xmath84 : katsuura function * @xmath85 : happycat function * @xmath86 : expanded griewank plus rosenbrock function * @xmath90 : modified schwefel s function * @xmath92 : ackley function",
    "composition functions are constructed in the same manner as in @xcite .",
    "@xmath93 + f^{opt}\\ ] ]    * @xmath94 : the constructed composition function * @xmath73 : @xmath3-th basic function * @xmath74 : number of basic functions used * @xmath95 : define which optimum is the global optimum * @xmath96 : control @xmath73 s coverage range , a small @xmath96 gives a narrow range for @xmath73 * @xmath97 : control @xmath73 s height * @xmath98 : weighted value for @xmath73 , calculated as follows : @xmath99 where @xmath100 represents the optimum position for @xmath73 .",
    "then normalized @xmath101 to get @xmath98 : @xmath102 .",
    "+ when @xmath103 , @xmath104 , such that @xmath105 .",
    "the constructed functions are multi - modal and non - separable and merge the properties of the sub - functions better and maintains continuity around the global / local optima .",
    "the local optimum which has the smallest bias value is the global optimum .",
    "the optimum of the third basic function is set to the origin as a trip in order to test the algorithms tendency to converge to the search center .",
    "note that , the landscape is not only changes along with the selection of basic function , but the optima and @xmath106 and @xmath107 can effect it greatly .      * @xmath87 * @xmath108 $ ] * @xmath109 $ ] * @xmath110 $ ] * @xmath84 : rotated rosenbrock function * @xmath85 : high conditioned elliptic function * @xmath86 : rotated bent cigar function * @xmath90 : rotated discus function * @xmath92 : high conditioned elliptic function      * @xmath82 * @xmath111 $ ] * @xmath112 $ ] * @xmath113 $ ] * @xmath84 : expanded schwefel function * @xmath85 : rotated rstrigin function * @xmath86 : rotated hgbat function      * @xmath82 * @xmath114 $ ] * @xmath115 $ ] * @xmath113 $ ] * @xmath84 : rotated schwefel function * @xmath85 : rotated rastrigin function * @xmath86 : rotated high conditioned elliptic function      * @xmath87 * @xmath116 $ ] * @xmath117 $ ] * @xmath110 $ ] * @xmath84 : rotated schwefel function * @xmath85 : rotated happycat function * @xmath86 : rotated high conditioned elliptic function * @xmath90 : rotated weierstrass function * @xmath92 : rotated griewank function      * @xmath87 * @xmath118 $ ] * @xmath119 $ ] * @xmath110 $ ] * @xmath84 : rotated hgbat function * @xmath85 : rotated rastrigin function * @xmath92 : rotated schwefel function * @xmath90 : rotated weierstrass function * @xmath86 : rotated high conditioned elliptic function      * @xmath87 * @xmath108 $ ] * @xmath120 $ ] * @xmath110 $ ] * @xmath84 : rotated expanded griewank plus rosenbrock function * @xmath85 : rotated happycat function * @xmath86 : rotated schwefel function * @xmath90 : rotated expanded scaffer s f6 function * @xmath92 : high conditioned elliptic function      * @xmath82 * @xmath121 $ ] * @xmath122 $ ] * @xmath113 $ ] * @xmath84 : hybrid function 1 * @xmath85 : hybrid function 2 * @xmath86 : hybrid function 3      * @xmath82 * @xmath121 $ ] * @xmath122 $ ] * @xmath113 $ ] * @xmath84 : hybrid function 4 * @xmath85 : hybrid function 5 * @xmath86 : hybrid function 6    1    finck , s. , hansen , n. , ros , r. , auger , a. : real - parameter black - box optimization benchmarking 2010 : noiseless functions definitions .",
    "technical report 2009/20 , research center ppe ( 2010 )    liang , j.j .",
    ", qu , b.y . , suganthan , p.n .",
    ", hernndez - daz , a.g . : problem definitions and evaluation criteria for the cec 2013 special session and competition on real - parameter optimization . technical report 201212 , computational intelligence laboratory , zhengzhou university and nanyang technological university , singapore ( 2013 )    liang , j.j .",
    ", qu , b.y . , suganthan , p.n . : problem definitions and evaluation criteria for the cec 2014 special session and competition on single objective real - parameter numerical optimization .",
    "technical report 201311 , computational intelligence laboratory , zhengzhou university and nanyang technological university , singapore ( 2013 )"
  ],
  "abstract_text": [
    "<S> benchmarking is key for developing and comparing optimization algorithms . in this paper , </S>",
    "<S> a cuda - based real parameter optimization benchmark ( curob ) is introduced . </S>",
    "<S> test functions of diverse properties are included within curob and implemented efficiently with cuda . </S>",
    "<S> speedup of one order of magnitude can be achieved in comparison with cpu - based benchmark of cec14 . </S>"
  ]
}