{
  "article_text": [
    "in cocaine dependence research , it has been shown that one s baseline cocaine - use pattern is related to the risk of posttreatment cocaine relapse [ @xcite ] , along with many other factors such as cocaine withdrawal severity , stress and negative mood [ @xcite , @xcite ( @xcite ) ] .",
    "the timeline follow - back ( tlfb ) [ @xcite ] substance use calendar is often used to retrospectively construct trajectories of daily cocaine use in a baseline period before treatment .",
    "the tlfb uses a calendar prompt and many other memory aids ( e.g. , the use of key dates such as holidays , birthdays , newsworthy events and other personal events as anchor points ) to enhance the accuracy of self - report substance - use estimates .",
    "@xcite showed that the tlfb could provide reliable daily cocaine - use data that had high retest reliability , high correlation with other cocaine - use measures and high agreement with collateral informants reports of patients cocaine use as well as results obtained from urine assays .",
    "based on the self - reported daily cocaine - use trajectories , certain summary statistics can be derived and are often used as predictors in a subsequent analysis to explain cocaine relapse outcomes .",
    "commonly used summary statistics include baseline cocaine - use frequency and average daily use amount , and commonly used relapse outcome measures are time to relapse ( i.e. , time to first cocaine use ) , frequency of use and quantity of use per occasion during the follow - up period [ @xcite ] . among the different relapse outcome measures , time to first relapse ( which we also refer as `` relapse time '' for ease of exposition ) is of particular clinical importance because it signals the transition of a cocaine - use pattern from abstinence to relapse .",
    "@xcite examined time to cocaine relapse using cox proportional hazards regression models .",
    "they concluded that the amount of cocaine used per occasion during the 90 days prior to inpatient admission was significantly associated with relapse time .",
    "@xcite argued that because the baseline cocaine - use trajectories were random , summary statistics derived from them were only estimates of one s long - term cocaine - use behavior and could be subject to large measurement error . in a regression",
    "setting , the use of error - prone variables as predictors may cause severe bias to the regression coefficients [ @xcite ] . to mitigate the bias",
    ", @xcite proposed a method - of - moments - based calibration method for linear regression models and a subsampling extrapolation method that is applicable to both linear and nonlinear regression models .",
    "however , their methods require a restrictive assumption that the baseline cocaine - use trajectories are stationary processes , and their subsampling extrapolation method is an approximation method which can not completely eliminate the estimation bias in survival analysis .    we propose a new modeling framework to link one s baseline cocaine - use pattern to relapse time without assuming stationarity for the baseline cocaine - use trajectories .",
    "we treat the baseline cocaine - use trajectories as functional data [ @xcite ] and perform functional principal component analysis ( fpca ) to these trajectories .",
    "the resulting fpca scores are then used as predictors to model relapse time .",
    "we develop a joint modeling approach to conduct fpca and functional regression analysis simultaneously .",
    "we consider two types of baseline cocaine - use trajectories : the first is the actual self - reported daily cocaine - use amount as provided by the tlfb , whereas the second is a dichotomized version of the first in the form of any cocaine use versus no use .",
    "the actual daily cocaine - use amount can be difficult to estimate depending on the length of the recalling period and also due to the lack of a common scale to assess the amount used for the different methods of consumption ( e.g. , intranasal use versus injection ) .",
    "the dichotomized cocaine - use trajectories , although maybe less informative , are subject to smaller errors and hence are more reliable .",
    "there is a large volume of recent work on fpca .",
    "see @xcite for kernel - based fpca approaches , and @xcite , zhou , huang and carroll ( @xcite ) for spline - based fpca methods .",
    "all these papers are concerned with the gaussian type of functional data and can not be used for generalized longitudinal trajectories .",
    "@xcite proposed to model non - gaussian longitudinal data by generalized linear mixed models , where the fpca can be performed with respect to some latent random processes .",
    "once the fpca scores are obtained , a common approach is to use them as predictors in a second - stage regression analysis [ e.g. , @xcite ] . as pointed out in @xcite , a potential problem with such an approach",
    "is that the estimation errors in fpca are not properly taken into account in the second stage regression analysis , hence , the estimated coefficients can be biased and variations in the estimators may be underestimated . by performing fpca and functional regression analysis simultaneously , we can avoid these complications .",
    "our work is also related to joint modeling of longitudinal data and survival time [ e.g. , @xcite , @xcite ( @xcite ) , @xcite ] . however , the vast majority of the existing literature focuses on the instantaneous effect of longitudinal data on survival time .",
    "in other words , the hazard rate of the event time is only related to the value of the longitudinal process at the moment of event . in our problem ,",
    "the longitudinal trajectories were collected prior to the relapse period and we want to use the entire baseline - use trajectory as a functional predictor in the survival analysis . survival analysis with functional predictors is not well studied in the literature compared with other functional regression models , and an extra complication in our data is that the relapse time is interval censored ( see section  [ sec2.1 ] for details ) . as noted in @xcite , one prominent difficulty in modeling interval censored survival data is that , unlike right censored data , we can not separate estimating the baseline hazard function from estimating the hazard regression coefficients using approaches such as the partial likelihood . therefore , we propose to model the log baseline hazard function as a spline function . some recent literature on spline models of the log baseline hazard function for interval censored data",
    "includes @xcite and @xcite .",
    "our data came from a recently completed clinical trial for cocaine dependence treatment . in the study ,",
    "seventy - nine cocaine - dependent subjects were admitted to the clinical neuroscience research unit ( cnru ) of the connecticut mental health center to receive an inpatient relapse prevention treatment for cocaine dependence lasting for two to four weeks .",
    "the cnru is a locked inpatient treatment and research facility that provides no access to alcohol or drugs and only limited access to visitors . upon treatment entry ,",
    "all subjects were interviewed by means of the structured clinical interview for dsm - iv [ @xcite ] .",
    "variables collected during the interview include age , gender , race , number of cocaine - use years and number of anxiety disorders present at interview , among others .",
    "the tlfb substance use calendar was used to retrospectively construct daily cocaine - use history in the 90 days prior to admission .    after completing the inpatient treatment ,",
    "all participants were invited back for follow - up interviews to assess cocaine - use outcomes .",
    "four interviews were conducted at days 14 , 30 , 90 and 180 after the treatment . during each interview ,",
    "daily cocaine - use records were collected using the tlfb procedure for the period prior to the interview date .",
    "a urine toxicology screen was also conducted to verify the accuracy of a reported relapse or abstinence .",
    "a positive urine sample test would suggest that the subject had used cocaine at least once in the reporting period before the positive urine test , but the test could not tell the exact cocaine - use date(s ) .",
    "if the self - reported relapse time had no conflict with the urine tests , we consider it as an observed event time .",
    "however , some subjects had reported no prior cocaine use before the first positive urine sample test , their relapse times were interval censored between their first positive urine test and the previous negative test ( if there was any ) .",
    "there were also subjects who reported no cocaine use nor yielded any positive urine samples for the entire study period .",
    "for these subjects , their relapse time data were right censored at the last interview date . in our data , about @xmath0 of the subjects had observed relapse time ; @xmath1 were interval censored and @xmath2 were right censored .",
    "in what follows , let @xmath3 denote the number of study subjects .",
    "for the @xmath4th subject , let @xmath5 be the baseline cocaine - use trajectory , @xmath6 be a posttreatment relapse time that may be right or interval censored , and @xmath7 be an @xmath8-dimensional covariate vector , where @xmath9 is the @xmath10th observation time for the @xmath4th subject within the baseline time interval @xmath11 , @xmath12 is the total number of such observation time , and @xmath7 includes baseline information on age , gender ( @xmath13 for female and 0 for male ) , race ( @xmath13 for african american and 0 for the rest ) , number of cocaine - use years ( cocyrs ) and number of anxiety disorders present at the baseline interview ( curanxs ) . as mentioned in the , we consider two cases that @xmath14 is either the self - reported use amount on day @xmath15 or the dichotomized version .",
    "we assume that the longitudinal observations @xmath16 are variables from the canonical exponential family [ @xcite ] with a probability density or mass function @xmath17 , \\ ] ] where @xmath18 is the canonical parameter and @xmath19 is a dispersion parameter .",
    "denote @xmath20 as the mean of @xmath21 .",
    "then @xmath20 is the first derivative of @xmath22 at @xmath18 , that is , @xmath23 .",
    "the inverse function of @xmath24 , denoted as @xmath25 , is called the canonical link function .",
    "we consider two different types of trajectories : gaussian trajectories where @xmath26}(t)= \\log(0.5 + { } $ ] reported cocaine use on day @xmath15 ) , and dichotomized trajectories where @xmath27}(t)=1 $ ] if the @xmath4th subject used cocaine on day @xmath15 , and @xmath28 otherwise . for gaussian longitudinal outcomes , @xmath29 and @xmath30 is the density of @xmath31 ; in the case of dichotomized outcomes , @xmath32 is the binary probability mass function with @xmath33 and @xmath34 .",
    "we assume that @xmath14 is driven by a latent gaussian process @xmath35 such that @xmath36 and that @xmath35 yields a standard karhunen ",
    "love expansion @xmath37 where @xmath38 is the mean function , @xmath39 is a vector of orthonormal functions also known as the eigenfunctions in fpca , @xmath40 are the principal component scores , @xmath41 and @xmath42 are the eigenvalues . in theory , the karhunen ",
    "love expansion contains an infinite number of terms , and truncating the expansion to a finite order is a finite sample approximation to the reality .",
    "the number of principal components @xmath43 becomes a model parameter and will be chosen by a data - driven method .",
    "we approximate the unknown functions @xmath44 and @xmath45 by b - splines [ @xcite ] .",
    "the b - spline representation achieves two goals simultaneously : smoothing and dimension reduction .",
    "smoothing is needed because the self - reported cocaine - use amount trajectories contain a substantial amount of measurement error . with our spline representation , each function",
    "is parameterized by a small amount of spline coefficients and the estimates are further regularized by a roughness penalty .",
    "let @xmath46 be a @xmath47-dimensional b - spline basis defined on equally spaced knots in @xmath11 , @xmath48 be a @xmath49 vector and @xmath50 be a @xmath51 matrix of spline coefficients , then the unknown functions are represented as @xmath52 and @xmath53 .",
    "the general recommendation for choosing @xmath47 in the penalized spline literature is to choose a relatively large number @xmath54 , and let the smoothness of the estimated functions be regularized by the roughness penalty [ @xcite ] .",
    "the original b - spline basis functions are not orthonormal , therefore , we employ the procedure prescribed by @xcite to orthogonalize them so that @xmath55 , where @xmath56 is a @xmath57 identity matrix . under this construction ,",
    "the orthonormal constraints on @xmath45 translate into constraints on the coefficients , that is , @xmath58 .",
    "then the reduced - rank model for the latent process takes the form @xmath59 for the gaussian trajectories , that is , the log - transformed cocaine - use amount , @xmath60 , where @xmath61 is the design matrix by interpolating the basis functions on the observation time points and @xmath62 .",
    "the conditional log - likelihood function for the baseline - use trajectories is @xmath63}\\bigl ( \\theta_{l}^{[1]}\\bigr)= \\sum _ { i=1}^{n } \\ell _ { \\mathrm{long } , i}^{[1 ] } , \\nonumber \\\\[-8pt ] \\\\[-8pt ] & & \\eqntext{\\mbox{where } \\displaystyle\\ell_{\\mathrm{long } , i}^{[1]}=- \\frac{n_i}{2 } \\operatorname{log}\\bigl(\\sigma _ { \\varepsilon}^2\\bigr)- \\frac{1}{2\\sigma_{\\varepsilon}^2 } \\|y_i - b_i\\theta_{\\mu}-b_i \\theta _ \\psi\\xi_{i}\\|^2 , } \\ ] ] and @xmath64}=(\\theta_\\mu^ { t } , \\theta_{\\psi 1}^ { t } , \\ldots , \\theta_{\\psi p}^ { t},\\sigma_\\varepsilon^2)^ { t}$ ] .    for the dichotomized trajectories , @xmath65 , where @xmath66 .",
    "the conditional log - likelihood function is @xmath67}\\bigl ( \\theta_{l}^{[2]}\\bigr)= \\sum _ { i=1}^{n } \\ell _ { \\mathrm{long } , i}^{[2 ] } , \\nonumber \\\\[-8pt ] \\\\[-8pt ] & & \\eqntext{\\mbox{where } \\displaystyle\\ell_{\\mathrm{long } , i}^{[2]}=\\sum _ { j=1}^{n_i }",
    "\\bigl\\ { y_{ij}\\operatorname{log } \\pi_{ij}+(1-y_{ij})\\operatorname{log}(1-\\pi_{ij } ) \\bigr\\ } , } \\ ] ] and @xmath68}=(\\theta_\\mu^ { t } , \\theta_{\\psi 1}^ { t } , \\ldots , \\theta_{\\psi p}^ { t})^ { t}$ ] . to regularize the nonparametric estimators , we impose penalties on the @xmath69 norms of their second derivatives [ @xcite ] .",
    "define @xmath70 , then @xmath71 the penalized log - likelihood for the baseline longitudinal data is @xmath72 where @xmath73 is either @xmath74}$ ] or @xmath75}$ ] for gaussian and dichotomized trajectories , respectively , and @xmath76 and @xmath77 are tuning parameters .",
    "we assume that the relapse time @xmath6 depends on the baseline cocaine - use history @xmath14 only through the latent process @xmath35 . moreover , the conditional hazard of @xmath6 given @xmath78 and the covariate vector @xmath7 follows the cox proportional hazards model . our way of including the functional covariate @xmath79 into survival analysis",
    "is closely related to the functional linear model ; see @xcite and many others .",
    "more specifically , the conditional hazard function of @xmath6 is @xmath80 where @xmath81 is an unknown baseline hazard function , @xmath82 is a coefficient vector and @xmath83 is an unknown coefficient function . when @xmath84 has the karhunen  love expansion in ( [ eq : kl_expansion ] )",
    ", the coefficient function can be written as a linear combination of the eigenfunctions @xmath85 and the integral in the model can be simplified as @xmath86 , which motivates the model @xmath87 one important feature of the cocaine dependence treatment data is that the relapse time is partially interval censored .",
    "that is , the data are a mixture of noncensored , right censored and interval censored data .",
    "for the subjects with interval censoring , we only know that the relapse time occurred within an interval @xmath88 $ ] , where @xmath89 .",
    "we adopt the idea of @xcite and model the log baseline hazard as a linear spline function @xmath90 where @xmath91 and @xmath92 s are the knots . the spline basis used in ( [ eq : spline ] )",
    "is also known as the truncated power basis [ @xcite ] .",
    "there are two immediate benefits for this model .",
    "first , @xmath93 is guaranteed to be nonnegative , so that we do not have to consider any constraints on the parameters when maximizing the likelihood .",
    "second , since @xmath94 is modeled as a piecewise linear polynomial , the cumulative hazard function @xmath95 can be written out in an explicit form . for higher order spline functions ,",
    "such explicit expressions are not available .",
    "to write out the likelihood for the relapse time , we use the following notation . for the @xmath4th",
    "subject we observe @xmath96 , where @xmath97 $ ] gives the censoring interval and @xmath98 is the indicator for right censoring . when @xmath99 and @xmath100 , the event time @xmath6 is right censored at @xmath101 ; when @xmath102 and @xmath103 , @xmath6 is interval censored within @xmath97 $ ] ; when @xmath102 and @xmath100 , @xmath6 is observed at @xmath101 .",
    "in addition , @xmath104 is the indicator for noncensored relapse time . denoting @xmath105 ,",
    "the conditional log - likelihood function for the relapse time is [ @xcite ] @xmath106 , \\nonumber \\ ] ] and @xmath107 is the collection of parameters .    with the log baseline hazard function",
    "expressed as a linear spline function , the log - likelihood function in ( [ eq : like_survive ] ) can be evaluated explicitly . to regularize the estimators ,",
    "one commonly used approach is to model the polynomial coefficients @xmath108 as fixed effects and the spline coefficients @xmath109 as random effects with @xmath110 .",
    "this mixed model setup leads to a penalized log - likelihood @xmath111 @xcite recommended to use a relatively large number of basis functions in a penalized spline estimator , so that the smoothness of @xmath94 is mainly controlled by @xmath112 .",
    "following @xcite , we set @xmath113 , where @xmath114 is the floor of @xmath115 , and choose the knots to be equally spaced with respect to the quantiles defined on the unique values of @xmath116 . the variance parameter @xmath117 is treated as a tuning parameter in our nonparametric estimation .",
    "when analyzing the survival data alone , @xcite proposed to select @xmath112 by maximizing the marginal likelihood using a laplace approximation [ @xcite ] .",
    "choosing @xmath112 in our joint model is more challenging and will be addressed in section  [ sec : model_select ] .",
    "the principal component scores @xmath118 of the longitudinal data are also latent frailties in the survival model for the relapse time . by imposing a normality assumption ,",
    "the log - likelihood for @xmath119 is @xmath120 where @xmath121 are the diagonal elements of @xmath122 .",
    "the complete data log - likelihood for the joint model is given by combining the parts in ( [ eq : like_long_pen ] ) , ( [ eq : like_survive ] ) and ( [ eq : like_frail ] ) as @xmath123 where @xmath124 , and the penalized version of ( [ eq : joint_like ] ) is @xmath125 \\\\[-8pt ] \\nonumber & & \\qquad=\\ell_{c}(\\theta)-\\frac{1}{2\\sigma_\\mathbbm{b}^2}{\\mathbbm { b}}^t { \\mathbbm { b}}-\\frac{1}{2 } \\biggl\\ { h_\\mu\\theta_\\mu^{t } { { \\cal j}}_{\\mathscr{b}}\\theta_\\mu + h_\\psi\\sum _ { l=1}^{p}\\theta_{\\psi l}^t { { \\cal",
    "j}}_{\\mathscr{b}}\\theta_{\\psi l } \\biggr\\}. \\ ] ] here @xmath119 , @xmath126 , @xmath127 , @xmath128 , @xmath129 and @xmath130 are the vectors or matrices pooling the corresponding variables from all subjects .",
    "we fit the joint model by an em algorithm treating the latent variables @xmath118 as missing values . in our algorithm",
    ", we fix the tuning parameters @xmath76 , @xmath77 and @xmath131 and focus on estimating the model parameters  @xmath132 .",
    "selection of the tuning parameters is deferred to section  [ sec : model_select ] .",
    "the loss function of the em algorithm is @xmath133 where @xmath134 is the penalized complete data log - likelihood in ( [ eq : joint_like_pen ] ) and @xmath135 is the current value of @xmath136 .",
    "the algorithm updates the parameters by iteratively maximizing ( [ eq : q_em ] ) over @xmath132 .",
    "given the complexity of the joint model , the conditional expectation in ( [ eq : q_em ] ) does not have a closed form , we therefore approximate @xmath137 by markov chain monte carlo ( mcmc ) .",
    "let @xmath138 be mcmc samples from the conditional distribution @xmath139 , and then @xmath140 can be approximated by @xmath141 .",
    "this algorithm is a variant of the monte carlo em ( mcem ) algorithm of @xcite , and the details are provided in sections a.1 and a.2 of supplementary material [ @xcite ] . to ensure convergence of the mcmc",
    ", we also monitor the monte carlo error in the e - step using the batch means method of @xcite .",
    "specifically , we divide the monte carlo sequence @xmath142 in to @xmath143 batches so that we have replicates of @xmath144 to evaluate the monte carlo error .      the most pressing model selection issue in our joint model is to select the number of principal components @xmath43 since it determines the structure of the baseline trajectories and their association with the relapse time .",
    "another important issue is to select the tuning parameters .",
    "as mentioned before , as long as we include enough of a number of spline bases and place the knots reasonably , the performance of the estimated functions is mainly controlled by the penalty parameters @xmath145 and @xmath131 .",
    "we propose to select @xmath43 , @xmath145 and @xmath131 simultaneously by minimizing an akaike information criterion ( aic ) , which is the negative log - likelihood plus a penalty on the model complexity .    in our setting , the log - likelihood on observed data requires integrating out the latent variables @xmath119 from the complete data likelihood ( [ eq : joint_like ] ) , which is intractable .",
    "a commonly used approach is to replace the log - likelihood with its conditional expectation given the observed data [ @xcite ] .",
    "hence , the aic is of the form @xmath146 where the conditional expectation is approximated by a monte carlo average using the monte carlo samples in the last mcem iteration and @xmath147 is the effective degrees of freedom in the model .    for the longitudinal data , both the mean function @xmath44 and the eigenfunctions @xmath45",
    "are estimated by penalized splines . following @xcite , the effective degrees of freedom for a p - spline estimator with a penalty parameter @xmath148 is @xmath149 where @xmath148 can be either @xmath76 or @xmath77 .",
    "since our model consists of one mean function and @xmath43 eigenvalues and eigenfunctions , the effective degrees of freedom for the longitudinal data is @xmath150 .",
    "similarly , the effective degrees of freedom for the estimated log baseline hazard function can be approximated by [ @xcite ] @xmath151 where @xmath152 is the design matrix from the truncated power basis used in ( [ eq : spline ] ) . for interval censored subjects",
    ", we approximate the event time by the midpoint @xmath153 of the interval @xmath88 $ ] and the design matrix for the @xmath4th subject is @xmath154 by taking into account the degrees of freedom in all model components , the aic for the joint model becomes @xmath155 .",
    "\\nonumber \\ ] ] searching for the minimum of aic in a four - dimensional space is extremely time consuming .",
    "one possible simplification is to assume that the baseline mean and eigenfunctions have about the same roughness and set @xmath156 .",
    "then for each value of @xmath43 , we search for the optimal value of @xmath148 and @xmath112 over five grid points in each dimension .",
    "we adopt this search scheme in all of our numerical studies and it proves to be computationally feasible .",
    "to make inference on parameters in the joint model , we need to estimate the variance  covariance matrix of the estimator @xmath157 .",
    "let @xmath158 be the observed data .",
    "@xcite showed that the covariance matrix of @xmath157 can be approximated by the inverse of the observed information matrix @xmath159 where @xmath134 is the penalized log - likelihood based on complete data ( [ eq : joint_like_pen ] ) .",
    "we can estimate this information matrix by evaluating the partial derivatives at the final estimator @xmath157 and replacing the conditional expectations by monte carlo averages using the monte carlo samples generated in the final em iteration .",
    "one important distinction between our model and the generalized linear mixed models or other joint models is that the eigenfunctions are not identifiable without the orthonormal constraints in ( [ eq : kl_expansion1 ] ) . because of",
    "the constraints , the real number of free parameters in @xmath160 is lower than the nominal dimension . as a result , the information matrix defined above might be singular .",
    "one solution is to reparameterize @xmath160 so as to remove the constraints .",
    "details are given in supplementary material [ @xcite ] .",
    "a referee pointed out the methods by @xcite and @xcite can also be used to estimate the asymptotic variance of @xmath157 .",
    "these methods are not only based on observed information , but also evaluate the derivatives numerically by running additional markov chains .",
    "it is worth pointing out that these methods are designed for the cases where there is no constraint on the parameter  @xmath132 . extending these methods to our problem",
    "calls for future research .",
    "we illustrate the performance of the proposed methods by a simulation study . to mimic the real data , we consider two simulation settings where the baseline longitudinal trajectories are gaussian and binary , respectively . in both settings ,",
    "we simulate @xmath161 independent subjects , with @xmath162 baseline longitudinal observations equally spaced on the time interval @xmath163 $ ] .",
    "gaussian baseline trajectories are generated as @xmath164 , where @xmath35 is the @xmath4th realization of a gaussian process with the karhunen ",
    "love expansion ( [ eq : kl_expansion ] ) .",
    "we let the mean function be @xmath165 , the eigenvalues be @xmath166 , @xmath167 and @xmath168 for @xmath169 , and the eigenfunctions be @xmath170 , @xmath171 .",
    "the principal component scores are simulated as @xmath172 with @xmath173 .",
    "the error @xmath174 is a gaussian white noise process with variance @xmath175 . in the case of the binary baseline , @xmath21",
    "are generated from a bernoulli distribution with the probability @xmath176 , where the latent process @xmath84 is simulated the same way as for the gaussian baseline trajectories and @xmath177 for @xmath178 .",
    ", @xmath179 , @xmath180 and the log baseline hazard function , respectively . in each panel ,",
    "the dotted curve is the true function , the solid curve is the median of the estimator , the dash - dot and dashed curves are the 5% and 95% pointwise percentiles .",
    "1st eigenfunction .",
    "2nd eigenfunction .",
    "baseline mean function .",
    "log baseline hazard function . ]    under both simulation settings , we simulate the failure time @xmath6 from the cox proportional hazards model ( [ eq : cox ] ) , which includes the effects of the principal component scores and a covariate @xmath7 .",
    "we let @xmath7 be a binary random variable with a success probability of 0.5 , the regression coefficients be @xmath181 , and the baseline hazard function be @xmath182 for @xmath183 .",
    "we assume that the failure time is interval censored at random and set the censoring time to be @xmath184 , @xmath185 and @xmath186 .",
    "let the censoring indicator @xmath98 be a binary variable independent of @xmath118 and @xmath7 with @xmath187 .",
    "when @xmath102 , the event time @xmath6 is censored in the interval between the two closest censoring time ; if @xmath6 is less than 4 , it is censored in @xmath188 $ ] ; if @xmath6 is over 20 , it is automatically right censored at 20 .",
    "overall , the data structure is similar to the cocaine dependence treatment data described in section  [ sec2 ] : about @xmath189 of the failure times are right censored , @xmath190 are interval censored , and the remaining @xmath191 are observed .    ,",
    "@xmath179 , @xmath180 and the log baseline hazard function , respectively . in each panel ,",
    "the dotted curve is the true function , the solid curve is the median of the estimator , the dash - dot and dashed curves are the 5% and 95% pointwise percentiles .",
    "1st eigenfunction .",
    "2nd eigenfunction .",
    "baseline mean function . log baseline hazard function . ]    for both baseline settings , we repeat the simulation 100 times and apply the proposed method to fit the joint model . for the results reported below , we use @xmath192 cubic b - splines to model the mean and eigenfunctions of the latent longitudinal process and @xmath193 spline basis functions to model the log baseline hazard function . our experience and those of many others [ e.g. , @xcite ] suggest that the performance of penalized spline estimators is mainly controlled by the penalty parameters and is not sensitive to the choice of spline basis .    to choose the number of principal components @xmath43 and",
    "the penalty parameters @xmath76 , @xmath77 and @xmath131 , we conduct a grid search using the proposed aic ( [ eq : aic ] ) .",
    "for all the simulations , the aic selects the correct number @xmath194 of principal components about 77% of the time and selects @xmath195 for the remaining 23% of the time .",
    "since aic has a well - known tendency to select an over - fitted model and over - fitting is in general considered less problematic than under - fitting , this performance is quite satisfactory . for",
    "the estimation results below , we use the penalty parameters selected by aic when @xmath43 is fixed at 2.=-1    we summarize in figures  [ fig : simu_gauss ] and [ fig : simu_binary ] the nonparametric estimators when the baseline longitudinal trajectories are gaussian and binary , respectively .",
    "each figure contains four panels that summarize @xmath196 , @xmath179 , @xmath180 and the log baseline hazard function .",
    "we show in each panel the true curve , the median , and the @xmath197th and 95th pointwise percentiles of the estimators .",
    "as we can see , the spline estimators perform very well in both simulation settings , and the median and the pointwise percentiles of the estimated curves are very close to the truth . between the two types of baseline longitudinal data , binary trajectories are less informative , and",
    "hence the estimated curves are more variable .",
    "for instance , the integrated mean squared error for the two eigenfunctions are 0.0072 and 0.0150 in the gaussian case and are 0.0462 and 0.1206 in the binary case .",
    "the true log hazard function is @xmath198 , which is @xmath199 at @xmath200 ; this explains the bigger bias of our spline estimator near 0 .",
    "the bias in the nonparametric part has little effect on estimation of the parametric components such as @xmath201 .    @lccccccc@",
    "* method * & * parameter * & @xmath202 & @xmath203 & @xmath204 & @xmath205 & @xmath206 & @xmath207 +   + two - stage&true & 1.0000 & 1.0000 & 1.0000 & 9.0000 & 2.2500 & 0.4900 +",
    "& mean & 0.8154 & 0.8092 & 0.7972 & 8.9248 & 2.0224 & 0.4443 + & stdev & 0.0911 & 0.1513 & 0.3302 & 1.1193 & 0.3183 & 0.0147 + joint & mean & 0.9824 & 1.0130 & 0.9782 & 9.1184 & 2.0861 & 0.4839 + & stdev & 0.1253 & 0.1926 & 0.3885 & 1.1558 & 0.3349 & 0.0157 + & stder & 0.1184 & 0.1593 & 0.3469 & 1.3661 & 0.3633 & 0.0154 +   + two - stage&true & 1.0000 & 1.0000 & 1.0000 & 9.0000 & 2.2500 & + & mean & 0.8187 & 0.6681 & 0.4642 & 6.4365 & 2.1158 & + & stdev & 0.1759 & 0.4840 & 0.2658 & 1.1685 & 0.5384 & + joint & mean & 0.9798 & 0.9890 & 0.9997 & 9.3307 & 2.2823 & + & stdev & 0.1380 & 0.1727 & 0.3724 & 1.9894 & 0.8342 & + & stder & 0.1192 & 0.1553 & 0.3412 & 2.0035 & 0.6059 & +    we summarize the estimation results of the parametric components for both settings in table  [ table : nonlin ] , where we show the means and monte carlo standard deviations of the estimators .",
    "as we can see , the estimators for the parametric components are approximately unbiased and the standard deviations are reasonably small .",
    "we also present the means of the estimated standard errors using the modified empirical information in section  [ sec : inference ] , and find that the standard errors slightly underestimate the true standard deviations .",
    "this underestimation of standard error is quite common in semiparametric models under small sample sizes , since the standard error is based on an estimate of the asymptotic variance , which only captures the leading term in the asymptotic distribution of the point estimator [ @xcite ] .    to demonstrate the advantage of the joint modeling approach",
    ", we also provide a comparison between our method and a two - stage functional survival analysis approach , where we perform fpca to the longitudinal trajectory first and then use the estimated principal component scores as predictors in the second - stage survival analysis . for gaussian longitudinal trajectories ,",
    "the fpc scores are estimated by the principal analysis by the conditional expectation ( pace ) method [ @xcite ] ; for the dichotomized trajectories , the fpc scores are estimated by the method of @xcite which is implemented in a pace - grm package in matlab .",
    "the estimation results of the two - stage estimator are also provided in table  [ table : nonlin ] .",
    "we can see that the two - stage estimators for @xmath208 and @xmath82 are severely biased .",
    "this bias is the result of the attenuation effect caused by the estimation errors in the fpc scores .",
    "we apply our proposed joint modeling approach to analyze the cocaine dependence treatment data described in section  [ sec2 ] . for the baseline cocaine - use trajectories ,",
    "we consider both the ( log - transformed ) cocaine - use amount trajectories and the dichotomized trajectories .",
    "relapse time is determined from the self - reported posttreatment cocaine - use trajectories as well as the urine sample tests . as we discussed in section  [ sec2 ]",
    ", the relapse time is partially interval / right censored .",
    "we use the five covariates described in section  [ sec2 ] in the cox model , that is , age , gender , race , cocyrs and curanxs . to capture potential weekly periodic patterns of the baseline trajectories",
    ", we aligned the baseline trajectories by weekdays such that all trajectories start from the first sunday of the baseline period and last for 80 days .",
    "we use 30 cubic b - spline basis functions to model the mean and eigenfunctions of the baseline trajectories so that there are about two knots within each weak and the basis functions are flexible enough to capture possible weekly patterns in the data .",
    "the smoothness of these nonparametric estimators are governed by the data - driven tuning parameters .",
    "we use 12 linear spline basis functions to model the baseline hazard function , similar to the choice in @xcite .",
    "we choose the number of principal components and the penalty parameters @xmath145 and @xmath131 by the proposed aic .",
    "the aic selects three principal components for both types of baseline trajectories .",
    "the estimated eigenvalues are 16.1960 , 2.2097 and 0.8673 for the cocaine - use amount trajectories and 61.3838 , 0.8986 and 0.1695 for the dichotomized trajectories .",
    "we show the estimated mean and eigenfunctions for the cocaine - useamount trajectories in figure  [ fig : pc_effect_data ] and for the dichotomized trajectories in figure  [ fig : pc_effect_data2 ] .",
    "the curves estimated from the two types of trajectories exhibit rather similar patterns , and they all show clear weekly periodic structures  the baseline trajectories contain 11 weeks of data and these curves have 11 peaks and troughs matching the weekdays rather closely .",
    "if we look beyond the local periodic structures and focus on the overall trend of these curves over the entire baseline period , we can see that the mean functions are reasonably flat except near the beginning and the end of the baseline period .",
    "the overall trend in the first eigenfunction is a negative constant function . increasing the loading on the first principal component leads to less cocaine use ( or lower",
    "use probability for dichotomized trajectories ) , and hence the score on the first principal component represents the overall use amount ( or probability ) of a patient .",
    "the second principal component represents an overall decreasing trend in use amount ( or probability ) over the recall period .",
    "the third principal component is a higher order nonlinear trend in the trajectories .    to confirm that the weekly structures in these curves are real",
    ", we also provide pointwise standard error bands in the plots . since our simulation study shows that the standard error based on the louis formula underestimates the true standard deviation under a small sample size , we estimate the standard error using a bootstrap procedure instead . in our bootstrap procedure ,",
    "we resample the subjects with replacement , fit the joint model to the bootstrap samples using the same tuning parameters as for the real data , and estimate the standard deviations of the estimators using their bootstrap replicates pointwisely .",
    "the confidence bands in figures  [ fig : pc_effect_data ] and [ fig : pc_effect_data2 ] are based on 100 bootstrap replicates .",
    "these confidence bands confirm that the weekly structures in the eigenfunctions are real .",
    "note that the confidence bands in figure  [ fig : pc_effect_data2 ] are wider than those in figure  [ fig : pc_effect_data ] because the dichotomized trajectories are less informative .",
    "the estimated regression coefficients for the cox model and the corresponding standard errors and @xmath43-values are reported in table  [ tab : data ] .",
    "the standard errors are obtained by bootstrap with 100 replicates . for both types of baseline trajectories , the second principal component has a significant positive effect on the hazard rate of relapse time .",
    "this suggests that patients with a decline in recent cocaine - use amount or probability relapsed faster .",
    "subjects who experienced such a decline might have established a longer period of abstinence before entering treatment than those who did not . as a result",
    ", it would not be surprising for the onset of their cocaine withdrawal symptoms to start sooner ; this could have in turn caused a faster relapse . among the covariates ,",
    "cocyrs is significant , suggesting subjects who had used cocaine for fewer years tended to relapse later .        for comparison purposes",
    ", we also report in table  [ tab : data ] the estimation result of the two - stage procedure described in section  [ sec : simulation ] . in this procedure ,",
    "fpca and survival analysis are done in successive steps , and the estimation errors in the estimated principal component scores are not properly taken into account in the survival analysis .",
    "it is not surprising that the estimation coefficients for the principal component scores by the two - stage procedure are attenuated and none of them are significant .",
    "@lcd1.5d2.4d2.4d2.4d2.4d1.5c@ * amnt . * & & & & & & & & + & + est & 0.0418 & 0.1616 & -0.2251 & -0.3818 & -0.4081 & -0.0467 & 0.1182 & 0.2664 + stder & 0.0316 & 0.0995 & 0.1590 & 0.2986 & 0.3305 & 0.0276 & 0.0347 & 0.2584 + @xmath43-value & 0.1870 & 0.1046 & 0.1570 & 0.2011 & 0.2169 & 0.0908 & 0.0007^ * & 0.3024 + & + est & 0.0420 & 0.1802 & -0.2021 & -0.3255 & -0.3343 & -0.0449 & 0.1098 & 0.2348 + stder & 0.0352 & 0.0867 & 0.2394 & 0.3462 & 0.2591 & 0.0342 & 0.0407 & 0.2109 + @xmath43-value & 0.2327 & 0.0377^ * & 0.3985 & 0.3471 & 0.1969 & 0.1895 & 0.0070^ * & 0.2655 + [ 0.5ex ] * dich .",
    "* & & & & & & & & + & + est & 0.0008 & 0.0131 & -0.1331 & -0.3538 & -0.2664 & -0.0437 & 0.1031 & 0.3582 + stder & 0.0137 & 0.0762 & 0.1158 & 0.2743 & 0.2919 & 0.0223 & 0.0306 & 0.2802 + @xmath43-value & 0.9552 & 0.8636 & 0.2501 & 0.8030 & 0.3613 & 0.0500 & 0.0007^ * & 0.2011 + & + est & 0.0064 & 0.1840 & -0.2344 & -0.3536 & -0.1567 & -0.0408 & 0.0947 & 0.2431 + stder & 0.0135 & 0.0936 & 0.2261 & 0.3128 & 0.2343 & 0.0315 & 0.0393 & 0.2544 + @xmath43-value & 0.6339 & 0.0493^ * & 0.3000 & 0.2583 & 0.5035 & 0.1951 & 0.0160^ * & 0.3392 +    following a referee s suggestion , we have also performed pca to the use amount trajectories without b - spline representation and roughness penalty regularization and use the pc scores in the survival analysis .",
    "the estimated cox regression coefficients for the first three principal components are @xmath209 with standard errors @xmath210 . in other words ,",
    "none of these pc scores is found to be significantly related to the first relapse time .",
    "this is because the cocaine - use amount trajectories contain a large amount of error ( due to self - reporting and converting different consumption methods to equivalent grams ) , and without regularization and joint modeling the estimation errors in the pc scores greatly attenuate the cox regression coefficients and reduce statistical power .",
    "such a direct pca approach is not applicable to the dichotomized trajectories .    in our joint modeling analysis",
    ", we also closely monitor the convergence of the markov chain .",
    "we estimate the monte carlo error in the final em iteration using the method described in section  [ sec : mcem ] , which is @xmath211 for the cocaine - use amount trajectories and @xmath212 for the dichotomized trajectories .    in a previous work",
    ", @xcite analyzed a similar data set and concluded that the baseline average cocaine - use amount had a significant negative effect on the hazard function of relapse ; this implies that those who used less during the baseline period tended to relapse sooner , which is counterintuitive . in @xcite",
    ", the authors argued that the counterintuitive results could be due to measurement error in the average use amount .",
    "after having accounted for the measurement error , they found that the baseline average cocaine - use amount was no longer significant .",
    "since the first principal component in our joint model is closely related to the baseline average cocaine - use amount , our result further confirms the analysis of @xcite .",
    "however , we have also found that the subject - specific decreasing trend in the cocaine - use trajectories ( i.e. , the second principal component ) is related to faster relapse , while such a finding was not made by either @xcite or @xcite .",
    "in studying the relationship between baseline cocaine - use patterns and posttreatment time to first cocaine relapse , most existing literature only makes use of some basic summary statistics derived from the cocaine - use trajectories , such as the average use amount and frequency of use .",
    "these summary statistics are subject to measurement error and can not fully describe the dynamic structure of the baseline trajectories .",
    "we propose an innovative joint modeling approach based on functional data analysis to jointly model the baseline generalized longitudinal trajectories and the interval censored failure time .",
    "specifically , we model the latent process that drives the longitudinal responses as functional data , approximate the mean and eigenfunctions of the latent process by flexible spline basis functions , and propose a data - driven method to determine the number of principal components and hence the covariance structure of the longitudinal data .",
    "we propose and implement a monte carlo em algorithm to fit the model and modified empirical information to estimate the standard error of the regression coefficients .",
    "our analysis of the cocaine dependence treatment data shows that the relapse time is related to a decreasing trend in the cocaine - use behaviors rather than the average use amount .",
    "our proposed model can also be used to predict the first relapse time of the new subject . for a future",
    "subject , suppose that we only observe his / her baseline cocaine - use amount trajectory @xmath213 , then we can predict his / her first relapse time @xmath214 using an empirical bayes method . using the proposed joint model ,",
    "we can write out the conditional distribution @xmath215 $ ] , where @xmath216 is the vector of latent principal component scores for the new subject .",
    "we can use the model parameters estimated from the training data set , and run an mcmc to draw samples from this conditional distribution .",
    "we use the mcmc samples to estimate the posterior distribution of @xmath214 , which provides both a point predictor and prediction intervals .    as all monte carlo",
    "based methods , our methods are computationally intense . for the cocaine dependence treatment data , it takes about 25 em iterations for the algorithm to converge and the running time is about 1.5 hours using the self - reported use amount trajectories and about 2.5 hours using the dichotomized use trajectories .",
    "it takes a lot longer to perform model selection and bootstrap , since we have to fit the model many times .",
    "however , we argue that the computation time is a worthy price to pay in exchange for unbiased estimates and correct statistical inference .",
    "one of our future research directions is to accelerate the em algorithm using graphics processing units ( gpu ) and parallel computing .",
    "we thank the editor , the associate editor and three anonymous referees of an earlier version of this paper who gave valuable advice on clarifying and explaining our ideas .",
    "carroll , k.  c. , power , m. , bryant , k. and rounsaville , b.  j. ( 1993 ) .",
    "one year follow - up status of treatment - seeking cocaine abusers : psychopathology and dependence severity as predictors of outcome .",
    "_ journal of nervous and mental disease _ , 181 , 71 - 79 .",
    "fals - stewart , w. , ofarrell , t .- j . ,",
    "freitas , t .-",
    "t . , mcfarlin , s .- k . and rutigliano , p. ( 2000 ) .",
    "the timeline follow - back reports of psychoactive substance use by drug - abusing patients : psychometric properties .",
    "_ journal of consulting and clinical psychology _ , 68 , 134 - 144 .",
    "fox , h .- c . ,",
    "garcia , m. , milivojevic , v. , kreek , m .- j . and",
    "sinha , r. ( 2006 ) .",
    "gender differences in cardiovascular and corticoadrenal response to stress and drug cues in cocaine dependent individuals .",
    "_ psychopharmacology _ , 185 , 348 - 57 .",
    "guan , y. , li , y. and sinha , r. ( 2011 ) .",
    "cocaine dependence treatment data : methods for measurement error problems with predictors derived from stationary stochastic processes . _",
    "journal of the american statistical association _",
    ", 106 , 480 - 493 .",
    "kampman , k .-",
    "m . , volpicelli , j .-",
    "r . , mulvaney , f. , alterman , a .-",
    "cornish , j. , gariti , p. , cnaan , a. , poole , s. , muller , e. , acosta , t. , luce , d. and obrien , c. ( 2001 ) . effectiveness of propranolol for cocaine dependence treatment may depend on cocaine withdrawal symptom severity . _ drug and alcohol dependence _ , 63 , 69 - 78 .",
    "sinha , r. , garcia , m. , paliwal , p. , kreek , m. j. , and rounsaville , b. j. ( 2006 ) .",
    "stress - induced cocaine craving and hypothalamic - pituitary - adrenal responses are predictive of cocaine relapse outcomes .",
    "_ archives of general psychiatry _ , 63 , 324 - 331 .",
    "sobell , l. , and sobell , m. ( 1993 ) .",
    "timeline follow back : a technique for assessing self - reported ethanol consumption , in _ techniques to assess alcohol consumption _ ,",
    "eds . j. allen and r. litten , totowa , nj : humana press , inc .",
    "zhang , y. , hua , l. and huang , j. ( 2010 ) . a spline - based semiparametric maximum likelihood estimation method for the cox model with interval - censored data .",
    "_ scandinavian journal of statistics _",
    ", 37 , 338 - 354 .",
    "zhou , l. , huang , j. , martinez , j. g. , maity , a. , baladandayuthapani , v. and carroll , r. j. ( 2010 ) .",
    "reduced rank mixed effects models for spatially correlated hierarchical functional data .",
    "_ journal of the american statistical association _",
    ", 105 , 390 - 400 ."
  ],
  "abstract_text": [
    "<S> an important endpoint variable in a cocaine rehabilitation study is the time to first relapse of a patient after the treatment . </S>",
    "<S> we propose a joint modeling approach based on functional data analysis to study the relationship between the baseline longitudinal cocaine - use pattern and the interval censored time to first relapse . </S>",
    "<S> for the baseline cocaine - use pattern , we consider both self - reported cocaine - use amount trajectories and dichotomized use trajectories . </S>",
    "<S> variations within the generalized longitudinal trajectories are modeled through a latent gaussian process , which is characterized by a few leading functional principal components . </S>",
    "<S> the association between the baseline longitudinal trajectories and the time to first relapse is built upon the latent principal component scores . </S>",
    "<S> the mean and the eigenfunctions of the latent gaussian process as well as the hazard function of time to first relapse are modeled nonparametrically using penalized splines , and the parameters in the joint model are estimated by a monte carlo em algorithm based on metropolis  hastings steps . </S>",
    "<S> an akaike information criterion ( aic ) based on effective degrees of freedom is proposed to choose the tuning parameters , and a modified empirical information is proposed to estimate the variance  covariance matrix of the estimators .    </S>",
    "<S> ./style / arxiv - general.cfg    , </S>"
  ]
}