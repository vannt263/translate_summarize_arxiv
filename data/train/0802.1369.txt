{
  "article_text": [
    "consider a binary linear code @xmath1 of length @xmath2 that is used for data transmission over a binary - input discrete memoryless channel . as was observed by feldman _",
    "et al . _",
    "@xcite , the ml decoder for this setup can be written as @xmath3 where @xmath4 is a length-@xmath2 vector that contains the log - likelihood ratios and where @xmath5 is the inner product ( in @xmath6 ) of the vector @xmath4 with the vector @xmath7 . because the cost function in this minimization problem is linear , this is essentially equivalent to the solution of @xmath8 where @xmath9 denotes the convex hull of @xmath1 when @xmath1 is embedded in @xmath10 .",
    "( we say `` essentially equivalent '' because in the case where there is a unique optimal codeword then the two minimization problems yield the same solution . however , when there are multiple optimal codewords then @xmath11 and @xmath12 are non - singlet sets and it holds that @xmath13 . )    because the above two optimization problems are usually practically intractable , feldman _",
    "et al . _",
    "@xcite proposed to solve a relaxation of the above problem .",
    "namely , for a code @xmath1 that can be written as the intersection of @xmath14 binary linear codes of length @xmath2 , i.e. , @xmath15 , they introduced the so - called linear programming ( lp ) decoder @xmath16 with the relaxed polytope @xmath17 for which it can easily be shown that all codewords in @xmath1 are vertices of @xmath18 .",
    "the same polytope",
    "@xmath18 appeared also in papers by koetter and vontobel  @xcite , where message - passing iterative ( mpi ) decoders were analyzed and where this polytope @xmath18 was called the fundamental polytope .",
    "the appearance of the same object in these two different contexts suggests that there is a tight connection between lp decoding and mpi decoding .",
    "the above codes @xmath19 can be any codes of length @xmath2 , however , in the following we will focus on the case where these codes are codes of dimension @xmath20 . for example , let @xmath21 be an @xmath22 parity - check matrix for the code @xmath1 and let @xmath23 be the @xmath24-th row of @xmath21 . then , defining @xmath25 for @xmath26 , we obtain @xmath27 .    of course , the reason why the decoder in   is called lp decoder is because the optimization problem in that equation is a linear program ( lp ) .",
    "there are two standard forms for lps , namely @xmath28 and @xmath29 any lp can be reformulated ( by introducing suitable auxiliary variables , by reformulating equalities as two inequalities , etc . ) so that it looks like the first standard form .",
    "any lp can also be reformulated so that it looks like the second standard form .",
    "moreover , the first and second standard form are tightly related in the sense that they are dual convex programs .",
    "usually , the lp in   is called the primal lp and the lp in   is called the dual lp .",
    "( as it is to be expected from the expression `` duality , '' the primal lp is the dual of the dual lp . )",
    "not unexpectedly , there are many ways to express the lp that appears in   in either the first or the second standard form , and each of these reformulations has its advantages ( and disadvantages ) .",
    "once it is expressed in one of the standard forms , any general - purpose lp solver can basically be used to obtain the lp decoder output . however , the lp at hand has a lot of structure and one should take advantage of it in order to obtain very fast algorithms that can compete complexity- and time - wise with mpi decoders .",
    "several ideas have been presented in the past in this direction , e.g. , by feldman _ et al . _",
    "@xcite who briefly mentioned the use of sub - gradient methods for solving the lp of an early version of the lp decoder ( namely for turbo - like codes ) , by yang et al .",
    "@xcite on efficiently solvable variations of the lp decoder , by taghavi and siegel  @xcite on cutting - hyperplane - type approaches , by vontobel and koetter  @xcite on coordinate - ascent - type approaches , by dimakis and wainwright  @xcite and by draper _",
    "et al . _",
    "@xcite on improvements upon the lp decoder solution , and by taghavi and siegel  @xcite and by wadayama  @xcite on using variations of lp decoding ( together with efficient implementations ) for intersymbol - interference channels .",
    "in this paper our focus will be on so - called interior - point algorithms , a type of lp solvers that has become popular with the seminal work of karmarkar  @xcite .",
    "( after the publication of  @xcite in 1984 , earlier work on interior - point - type algorithms by dikin  @xcite and others became more widely known ) .",
    "we present some initial thoughts on how to use this class of algorithms in the context of lp decoding .",
    "so far , with the notable exception of  @xcite , interior - point - type algorithms that are especially targeted to the lp in   do not seem to have been considered .",
    "one of our goals by pursuing these type of methods is that we can potentially obtain algorithms that are better analyzable than mpi decoders , especially when it comes to finite - length codes .",
    "( wadayama  @xcite discusses some efficient interior - point - type methods , however , he is trying to minimize a quadratic cost function , and the final solution is obtained through the use of the sum - product algorithm that is initialized by the result of the interior - point search .",
    "although  @xcite presents some very interesting approaches that are worthwhile pursuing , it is not quite clear if these algorithms are better analyzable than mpi decoders . )    there are some interesting facts about interior - point - type algorithms that make them worthwhile study objects .",
    "first of all , there are variants for which one can prove polynomial - time convergence ( even in the worst case , which is in contrast to the simplex algorithm ) .",
    "secondly , we can round an intermediate result to the next vector with only @xmath30 / @xmath31 / @xmath32 entries and check if it is a codeword .",
    "are mapped to @xmath30 , that coordinates above @xmath31 are mapped to @xmath32 , and that coordinates equal to @xmath31 are mapped to @xmath31 . ] ( this is very similar to the stopping criterion that is used for mpi algorithms . ) note that a similar approach will probably not work well for simplex - type algorithms that typically wander from vertex to vertex of the fundamental polytope .",
    "the reason is that rounding the coordinates of a vertex yields only a codeword if the vertex was a codeword .. therefore , there is no nonzero - vector vertex that is rounded to the all - zero codeword .",
    "the proof is finished by using the symmetry of the fundamental polytope , i.e. , the fact that the fundamental polytope `` looks '' the same from any codeword . ] thirdly , interior - point - type algorithms are also interesting because they are less sensitive than simplex - type algorithms to degenerate vertices of the feasible region ; this is important because the fundamental polytope has many degenerate vertices .",
    "the present paper is structured as follows . in secs .",
    "[ sec : affine : scaling : algorithm:1 ] and  [ sec : primal : dual : interior : point : algorithms:1 ] we discuss two classes of interior - point algorithms , namely affine - scaling algorithms and primal - dual interior - point algorithms , respectively .",
    "as we will see , the bottleneck step of the algorithms in these two sections is to repeatedly find the solution to a certain type of system of linear equations .",
    "therefore , we will address this issue , and efficient solutions to it , in sec .",
    "[ sec : solving : equation : system:1 ] . finally , we briefly mention some approaches for potential algorithm simplifications in sec .  [",
    "sec : other : simplifications:1 ] and we conclude the paper in sec .",
    "[ sec : conclusions:1 ] .",
    "an interesting class of interior - point - type algorithms",
    "are so - called affine scaling algorithms which were introduced by dikin  @xcite and re - invented many times afterwards . good introductions to this class of algorithms can be found in  @xcite .",
    "[ fig : affine : scaling : algorithm : iterations:1 ] gives an intuitive picture of the workings of one instance of an affine - scaling algorithm .",
    "consider the lp in   and assume that the set of all feasible points , i.e. , the set of all @xmath7 such that @xmath33 and @xmath34 , is a triangle .",
    "for the vector @xmath35 shown in fig .",
    "[ fig : affine : scaling : algorithm : iterations:1 ] , the optimal solution will be the vertex in the lower left part .",
    "the algorithm works as follows :    1 .",
    "select an initial point that is in the interior of the set of all feasible points , cf .",
    "[ fig : affine : scaling : algorithm : iterations:1](b ) , and let the current point be equal to this initial point .",
    "2 .   minimizing @xmath36 over the triangle is difficult ( in fact , it is the problem we are trying to solve ) ; therefore , we replace the triangle constraint by an ellipsoidal constraint that is centered around the current point . such an ellipsoid is shown in fig .",
    "[ fig : affine : scaling : algorithm : iterations:1](c ) .",
    "its skewness depends on the closeness to the different boundaries .",
    "we then minimize the function @xmath37 over this ellipsoid .",
    "the difference vector between this minimizing point and the center of the ellipsoid ( see the little vector in fig .  [",
    "fig : affine : scaling : algorithm : iterations:1](d ) ) points in the direction in which the next step will be taken .",
    "4 .   depending on what strategy is pursued , a shorter or a longer step in the above - found direction is taken .",
    "this results in a new current point .",
    "( whatever step size is taken , we always impose the constraint that the step size is such that the new current point lies in the interior of the set of feasible points . )",
    "if the current point is `` close enough '' to some vertex then stop , otherwise go to step 2 .",
    "( `` closeness '' is determined according to some criterion . )    not surprisingly , when short ( long ) steps are taken in step  4 , the resulting algorithm is called the short - step ( long - step ) affine - scaling algorithm .",
    "convergence proofs for different cases can be found in  @xcite .",
    "of course , an affine - scaling algorithm can also be formulated for the lp in  .",
    "moreover , instead of the above - described discrete - time version , one can easily come up with a continuous - time version , see e.g.  @xcite .",
    "the latter type of algorithms might actually be interesting for decoders that are implemented in analog vlsi .",
    "the bottleneck step in the affine - scaling algorithm is to find the new direction , which amounts to solving a system of linear equations of the form @xmath38 , where @xmath39 is a given ( iteration - dependent ) positive definite matrix , @xmath40 is a given vector , and @xmath41 is the direction vector that needs to be found .",
    "we will comment on efficient approaches for solving such systems of equations in sec .",
    "[ sec : solving : equation : system:1 ] .",
    "in contrast to affine - scaling algorithms , which either work only with the primal lp or only with the dual lp , primal - dual interior point algorithms  as the name suggests  work simultaneously on obtaining a primal _ and _ a dual optimal solution . a very readable and detailed introduction to this topic can be found in  @xcite . as in the case of the affine - scaling algorithm there are many different variations : short - step , long - step , predictor - corrector , path - following , etc .",
    "again , the bottleneck step is to find the solution to a system of linear equations @xmath38 , where @xmath39 is a given ( iteration - dependent ) positive definite matrix , @xmath40 is a given ( iteration - dependent ) vector , and @xmath41 is the sought quantity .",
    "we will comment in sec .",
    "[ sec : solving : equation : system:1 ] on how such systems of linear equations can be solved efficiently .",
    "a variant that is worthwhile to be mentioned is the class of so - called infeasible - interior - point algorithms .",
    "the reason is that very often it is easy to find an initial primal feasible point or it is easy to find an initial dual feasible point but not both at the same time .",
    "therefore , one starts the algorithm with a primal / dual point pair where the primal and/or the dual point are infeasible points ; the algorithm then tries to decrease the amount of `` infeasibility '' ( a quantity that we will not define here ) at every iteration , besides of course optimizing the cost function .",
    "one of the most intriguing aspects of primal - dual interior - point algorithms is the polynomial - time worst - case bounds that can be stated .",
    "of course , these bounds say mostly something about the behavior when the algorithm is already close to the solution vertex .",
    "it remains to be seen if these results are useful for implementations of the lp decoder where it is desirable that the initial iterations are as aggressive as possible and where the behavior close to a vertex is not that crucial .",
    "( we remind the reader of the rounding - procedure that was discussed at the end of sec .  [",
    "sec : introduction:1 ] , a procedure that took advantage of some special properties of the fundamental polytope . )",
    "in secs .  [ sec : affine : scaling : algorithm:1 ] and  [ sec : primal : dual : interior : point : algorithms:1 ] we saw that the crucial part in the discussed algorithms was to repeatedly and efficiently solve a system of linear equations that looks like @xmath42 where @xmath39 is an iteration - dependent positive definite matrix and where @xmath40 is an iteration - dependent vector .",
    "the fact that @xmath39 is positive definite helps because @xmath41 can also be seen to be the solution of the quadratic unconstrained optimization problem @xmath43 where we assumed that @xmath39 is an @xmath44-matrix .",
    "it is important to remark that for the algorithms in secs .",
    "[ sec : affine : scaling : algorithm:1 ] and  [ sec : primal : dual : interior : point : algorithms:1 ] the vector @xmath41 usually does not have to be found perfectly .",
    "it is good enough to find an approximation of @xmath41 that is close enough to the correct @xmath41 .",
    "( for more details , see e.g.  ( * ? ? ?",
    "* ch .  9 ) . )",
    "using a standard gradient - type algorithm to find @xmath41 might work .",
    "however , the matrix @xmath39 is often ill - conditioned , i.e. , the ratio of the largest to the smallest eigenvalue can be quite big ( especially towards the final iterations ) , and so the convergence speed of a gradient - type algorithm might suffer considerably .    therefore , more sophisticated approaches are desirable .",
    "such an approach is the conjugate - gradient algorithm which was introduced by hestenes and stiefel  @xcite .",
    "( see shewchuk s paper  @xcite for a very readable introduction to this topic and for some historical comments . )",
    "this method is especially attractive when @xmath39 is sparse or when @xmath39 can be written as a product of sparse matrices , the latter being the case for lp decoding of ldpc codes .    in the context of the affine - scaling algorithm ,",
    "e.g.  resende and veiga  @xcite used the conjugate - gradient algorithm to efficiently solve the relevant equation systems .",
    "they also studied the behavior of the conjugate - gradient algorithm with different pre - conditioners .",
    "a quite different , yet interesting variant to solve the minimization problem in   is by using graphical models .",
    "namely , one can represent the cost function in   by an _ additive _ factor graph  @xcite .",
    "of course , there are a variety of factor graph representations for the this cost function , however , probably the most reasonable choice in the context of lp decoding is to choose the factor graph that looks topologically like the factor graph that is usually used for sum - product or min - sum algorithm decoding of ldpc codes .",
    "one can then try to find the solution with the help of the min - sum algorithm .",
    "[ equivalently , one can look at the maximization problem @xmath45 here the function to be optimized is proportional to a gaussian density and can be represented with a gaussian factor graph  @xcite .",
    "( which in contrast to the above factor graph is a _ multiplicative _ factor graph . )",
    "one can then try to find the solution with the help of the max - product algorithm , which in the case of gaussian graphical models is equivalent ( up to proportionality constants ) to the sum - product algorithm . ]",
    "the reason for this being an interesting approach is that the behavior of the min - sum algorithm applied to a quadratic - cost - function factor graphs is much better understood than for other factor graphs .",
    "e.g. , it is known that if the algorithm converges then the solution vector is correct . moreover , by now there are also practically verifiable sufficient conditions for convergence  @xcite",
    ". however , the quadratic - cost - function factor graphs needed for the above problem are more general than the special class of quadratic - cost - function factor graphs considered in the cited papers . of course",
    ", one could represent the cost function in   by a factor graph within this special class ( so that the above - mentioned results are applicable ) , however , and quite interestingly , when this cost function is represented by a factor graph that is not in this special class , then the convergence conditions seem to be ( judging from some empirical evidence ) less stringent . in fact , we obtained some very interesting behavior in the context of the short - step affine - scaling algorithm where only one iteration of the min - sum algorithm was performed per iteration of the affine - scaling algorithm .",
    "( the min - sum algorithm was initialized with the messages obtained in the previous affine - scaling algorithm iteration . )",
    "depending on the used algorithm , there are many small ( but very useful ) variations that can lead  when properly applied  to considerable simplifications .",
    "e.g. , one can replace the partial factor graph in fig .",
    "[ fig : redrawing : check : function : node:1](a ) by the partial factor graph in fig .",
    "[ fig : redrawing : check : function : node:1](b ) that contains new auxiliary variable nodes but contains only check nodes of degree three  @xcite . or , one can adaptively modify the set of inequalities that are included in the lp formulation  @xcite .",
    "we have presented some initial considerations towards using interior - point algorithms for obtaining efficient lp decoders .",
    "encouraging preliminary results have been obtained but more research is needed to fully understand and exploit the potential of these algorithms .",
    "this research was partly supported by nsf grant ccf-0514801 .            p.",
    "o. vontobel and r.  koetter , `` graph - cover decoding and finite - length analysis of message - passing iterative decoding of ldpc codes , '' _ accepted for ieee trans .  inform .",
    "theory , available online under _ ` http://www.arxiv.org/abs/cs.it/0512078`_ _ , 2007 .",
    " , `` on the relationship between linear programming decoding and min - sum algorithm decoding , '' in _ proc .  intern .  symp .  on inform",
    "theory and its applications ( isita ) _ , parma , italy , oct .",
    "1013 2004 , pp . 991996 .",
    "j.  feldman , d.  r. karger , and m.  j. wainwright , `` linear programming - based decoding of turbo - like codes and its relation to iterative approaches , '' in _ proc .",
    "40th allerton conf .  on communications , control , and computing _ ,",
    "allerton house , monticello , illinois , usa , october 24 2002 .",
    "k.  yang , x.  wang , and j.  feldman , `` non - linear programming approaches to decoding low - density parity - check codes , '' in _ proc .",
    "43rd allerton conf .  on communications , control , and computing _ ,",
    "allerton house , monticello , illinois , usa , sep .",
    "2830 2005 .",
    "m.  g.  c. resende and g.  veiga , `` an implementation of the dual affine scaling algorithm for minimum - cost flow on bipartite uncapacitated networks , '' _ siam journal on optimization _ ,",
    "vol .  3 , no .  3 , pp .",
    "516537 , 1993 .",
    "k.  yang , x.  wang , and j.  feldman , `` cascaded formulation of the fundamental polytope of general linear block codes , '' in _ proc .",
    "ieee intern .",
    "symp .  on inform .",
    "theory _ , nice , france , june 2429 2007 , pp ."
  ],
  "abstract_text": [
    "<S> interior - point algorithms constitute a very interesting class of algorithms for solving linear - programming problems . in this paper </S>",
    "<S> we study efficient implementations of such algorithms for solving the linear program that appears in the linear - programming decoder formulation .    </S>",
    "<S> [ definition]example [ definition]assumption [ definition]comment [ definition]remark    [ definition]lemma [ definition]theorem [ definition]proposition [ definition]corollary [ definition]algorithm [ definition]conjecture    _ </S>"
  ]
}