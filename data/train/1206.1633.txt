{
  "article_text": [
    "many combinatorial problems have linear programming ( _ lp _ ) relaxations that are commonly used for their solution through branch - and - cut algorithms .",
    "some of them also have stronger relaxations involving positive semidefinite ( @xmath0 ) constraints .",
    "in general , stronger relaxations should be preferred when solving a problem , thus using these @xmath0 relaxations is tempting .",
    "however , they come with the drawback of requiring a semidefinite programming ( sdp ) solver , creating practical difficulties for an efficient implementation within a branch - and - cut algorithm .",
    "indeed , a major weakness of current sdp solvers compared to lp solvers is their lack of efficient warm starting mechanisms .",
    "another weakness is solving problems involving a mix of @xmath0 constraints and a large number of linear inequalities , as these linear inequalities put a heavy toll on the linear algebra steps required during the solution process .    in this paper , we investigate lp relaxations of @xmath0 constraints with the aim of capturing most of the strength of the @xmath0 relaxation , while still being able to use an lp solver .",
    "the lp relaxation we obtain is an outer - approximation of the @xmath0 cone , with the typical convergence difficulties when aiming to solve problems to optimality .",
    "we thus do not cast this work as an efficient way to solve @xmath0 problems , but we aim at finding practical ways to approximate @xmath0 constraints with linear ones .",
    "we restrict our experiments to quadratically constrained quadratic program ( _ qcqp _ ) . a qcqp problem with variables @xmath1 and",
    "@xmath2 is a problem of the form @xmath3    where , for @xmath4 , @xmath5 is a rational symmetric @xmath6-matrix , @xmath7 is a rational @xmath8-vector , @xmath9 is a rational @xmath10-vector , and @xmath11 .",
    "moreover , the lower and upper bounds @xmath12 for @xmath13 , and @xmath14 for @xmath15 are all finite . if @xmath16 is negative semidefinite and @xmath5 is positive semidefinite for each @xmath17 , problem * qcqp * is convex and thus easy to solve . otherwise , the problem is np - hard @xcite .",
    "an alternative _ lifted _ formulation for * qcqp * is obtained by replacing each quadratic term @xmath18 with a new variable @xmath19 .",
    "let @xmath20 be the matrix with entry @xmath19 corresponding to the quadratic term @xmath18 . for square matrices",
    "@xmath21 and @xmath22 of the same dimension , let @xmath23 denote the _ frobenius inner product _ of @xmath21 and @xmath22 , i.e. , the trace of @xmath24 . problem * qcqp * is then equivalent to    @xmath25    the difficulty in solving problem * lift * lies in the non - convex constraint @xmath26 .",
    "a relaxation , dubbed @xmath0 , that is possible to solve relatively efficiently is obtained by relaxing this constraint to the requirement that @xmath27 be positive semidefinite , i.e. , @xmath28 .",
    "an alternative relaxation of * qcqp * , dubbed @xmath29 , is obtained by the reformulation linearization technique @xcite , using products of pairs of original constraints and bounds and replacing nonlinear terms with new variables .",
    "anstreicher @xcite compares the @xmath0 and @xmath29 relaxations on a set of quadratic problems with box constraints , i.e. , * qcqp * problems with @xmath30 and with all the variables bounded between 0 and 1 .",
    "he shows that the @xmath0 relaxations of these instances are fairly good and that combining the @xmath0 and @xmath29 relaxations yields significantly tighter relaxations than either of the @xmath0 or @xmath29 relaxations .",
    "the drawback of combining the two relaxations is that current sdp solvers have difficulties to handle the large number of linear constraints of the @xmath29 .",
    "our aim is to solve relaxations of * qcqp * using exclusively linear programming tools .",
    "the @xmath29 is readily applicable for our purposes , while the @xmath0 technique requires a cutting plane approach as described in section  [ relaxations ] .    in section  [ framework ]",
    "we consider several families of valid cuts .",
    "the focus is essentially on capturing the strength of the positive semidefinite condition using standard cuts @xcite , and some sparse versions of these .",
    "we analyze empirically the strength of the considered cuts on instances taken from globallib @xcite and quadratic programs with box constraints described in more details in the next section . implementation and computational results are presented in section  [ computationalresults ] .",
    "finally , section  [ conclusions ] summarizes the results and gives possible directions for future research .",
    "a typical approach to get bounds on the optimal value of a * qcqp * is to solve a convex relaxation .",
    "since our aim is to work with linear relaxations , the first step is to linearize * lift * by relaxing the last constraint to @xmath31 .",
    "we thus get the extended formulation @xmath32 * ext * is a linear program with @xmath33 variables and the same number of constraints as * qcqp*. note that the optimal value of * ext * is usually a weak upper bound for * qcqp * , as no constraint links the values of the @xmath34 and @xmath35 variables . two main approaches for doing that have been proposed and are based on relaxations of the last constraint of * lift * , namely @xmath36    they are known as the positive semidefinite ( @xmath0 ) relaxation and the reformulation linearization technique ( @xmath29 ) relaxation .",
    "as @xmath37 implies @xmath38 , using this last constraint yields a convex relaxation of * qcqp*. this is the approach used in @xcite , among others .",
    "moreover , using schur s complement @xmath39 and defining @xmath40 we can write the @xmath0 relaxation of * qcqp * in the compact form @xmath41 this is a positive semidefinite problem with linear constraints .",
    "it can thus be solved in polynomial time using interior point algorithms .",
    "* psd * is tighter than usual linear relaxations for problems such as the maximum cut , stable set , and quadratic assignment problems @xcite .",
    "all these problems can be formulated as * qcqp*s .",
    "the reformulation linearization technique @xcite can be used to produce a relaxation of * qcqp*. it adds linear inequalities to * ext*. these inequalities are derived from the variable bounds and constraints of the original problem as follows : multiply together two original constraints or bounds and replace each product term @xmath18 with the variable @xmath19 .",
    "for instance , let @xmath42 be two variables from * qcqp*. by taking into account only the four original bounds @xmath43 , @xmath44 , @xmath45 ,",
    "@xmath46 , we get the @xmath29 inequalities @xmath47    anstreicher @xcite observes that , for quadratic programs with box constraints , the @xmath0 and @xmath29 constraints together yield much better bounds than those obtained from the * psd * or * rlt * relaxations . in this work ,",
    "we want to capture the strength of both techniques and generate a linear programming relaxation of * qcqp*.    notice that the four inequalities above , introduced by mccormick @xcite , constitute the convex envelope of the set @xmath48 as proven by al - khayyal and falk @xcite , i.e. , they are the tightest relaxation for the single term @xmath19 .",
    "while the @xmath29 constraints are linear in the variables in the * ext * formulation and therefore can be added directly to * ext * , this is not the case for the @xmath0 constraint .",
    "we use a linear outer - approximation of the * psd * relaxation and a cutting plane framework , adding a linear inequality separating the current solution from the @xmath0 cone .    the initial relaxation we use and",
    "the various cuts generated by our separation procedure are described in more details in the next sections .",
    "our initial relaxation is the * ext * formulation together with the @xmath49 @xmath29 constraints derived from the bounds on the variables @xmath50 .",
    "we did not include the @xmath29 constraints derived from the problem constraints due to their large number and the fact that we want to avoid the introduction of extra variables for the multivariate terms that occur when quadratic constraints are multiplied together .",
    "the bounds @xmath51 $ ] for the extended variables @xmath19 are computed as follows : @xmath52 in addition , equality ( [ x - xxteq0 ] ) implies @xmath53 .",
    "we therefore also make sure that @xmath54 . in the remainder of the paper",
    ", this initial relaxation is identified as * ext+rlt*.      we use the equivalence that a matrix is positive semidefinite if and only if @xmath55 we can reformulate * psd * as the semi - infinite linear program @xmath56    a practical way to use * psdlp * is to adopt a cutting plane approach to separate constraints ( [ sdplinearcons ] ) as done in @xcite .",
    "let @xmath57 be an arbitrary point in the space of the @xmath58 variables .",
    "the spectral decomposition of @xmath57 is used to decide if @xmath57 is in the @xmath0 cone or not .",
    "let the eigenvalues and corresponding orthonormal eigenvectors of @xmath57 be @xmath59 and @xmath60 for @xmath61 , and assume without loss of generality that @xmath62 and let @xmath63 such that @xmath64 .",
    "if @xmath65 , then all the eigenvalues are non negative and @xmath57 is positive semidefinite .",
    "otherwise , @xmath66 for @xmath67 .",
    "hence , the valid cut @xmath68 is violated by @xmath57 .",
    "cuts of the form ( [ cuts : sdpcuts ] ) are called psdcuts in the remainder of the paper .",
    "the above procedure has two major weaknesses : first , only one cut is obtained from eigenvector @xmath60 for @xmath67 , while computing the spectral decomposition requires a non trivial investment in cpu time , and second , the cuts are usually very dense , i.e. almost all entries in @xmath69 are nonzero .",
    "dense cuts are frowned upon when used in a cutting plane approach , as they might slow down considerably the reoptimization of the linear relaxation .",
    "to address these weaknesses , we describe in the next section a heuristic to generate several sparser cuts from each of the vectors @xmath60 for @xmath67 .",
    "a simple idea to get sparse cuts is to start with vector @xmath70 , for @xmath67 , and iteratively set to zero some component of @xmath71 , provided that @xmath72 remains sufficiently negative .",
    "if the entries are considered in random order , several cuts can be obtained from a single eigenvector @xmath60 .",
    "for example , consider the _",
    "procedure in figure [ fig : sparsify ] , taking as parameters an initial vector @xmath73 , a matrix @xmath58 , and two numbers between 0 and 1 , @xmath74 and @xmath75 , that control the maximum percentage of nonzero entries in the final vector and the minimum violation requested for the corresponding cut , respectively . in the procedure ,",
    "parameter @xmath76 $ ] identifies the size of vector @xmath73 .",
    "@xmath77 @xmath78 \\cdot pct_{nz } \\rfloor$ ] @xmath79 @xmath80 $ ] @xmath81 @xmath82 $ ] [ divers1 ] @xmath83 , @xmath84 \\gets 0 $ ] [ assignz ] @xmath85 [ violz ] @xmath86",
    "[ w_i=0 ] @xmath87 @xmath88    it is possible to implement this procedure to run in @xmath49 if @xmath76 = n+1 $ ] : compute and update a vector @xmath10 such that @xmath89 its initial computation takes @xmath49 and its update , after a single entry of @xmath71 is set to 0 , takes @xmath90 .",
    "the vector @xmath10 can be used to compute the left hand side of the test in step [ violz ] in constant time given the value of the violation @xmath91 for the inequality generated by the current vector @xmath71 : setting the entry @xmath92 $ ] of @xmath71 to zero reduces the violation by @xmath93 and thus the violation of the resulting vector is @xmath94 .",
    "a slight modification of the procedure is used to obtain several cuts from the same eigenvector : change the loop condition in step [ divers1 ] to consider the entries in @xmath95 in cyclical order , from all possible starting points @xmath96 in @xmath97\\}$ ] , with the additional condition that entry @xmath98 is not set to 0 when starting from @xmath96 to guarantee that we do not generate always the same cut . from our experiments",
    ", this simple idea produces collections of sparse and well - diversified cuts .",
    "this is referred to as sparse1 in the remainder of the paper .",
    "we also consider the following variant of the procedure given in figure  [ fig : sparsify ] . given a vector @xmath71 ,",
    "let @xmath99}$ ] be the principal minor of @xmath58 induced by the indices of the nonzero entries in @xmath71 .",
    "replace step [ assignz ] with    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ [ assignz ] .",
    "@xmath100 where @xmath101 is an eigenvector corresponding to the most negative eigenvalue of a spectral decomposition of @xmath99}$ ] , @xmath84 \\gets 0 $ ] .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    this is referred to as sparse2 in the remainder , and we call the cuts generated by sparse1 or sparse2 described above _ sparse @xmath0 cuts_.    once sparse @xmath0 cuts are generated , for each vector @xmath71 generated , we can also add all @xmath0 cuts given by the eigenvectors corresponding to negative eigenvalues of a spectral decomposition of @xmath99}$ ] .",
    "these cuts are valid and sparse .",
    "they are called _ minor _ @xmath0 _ cuts _ and denoted by minor in the following .    an experiment to determine good values for the parameters @xmath74 and @xmath75",
    "was performed on the 38 globallib instances and 51 boxqp instances described in section  [ instances ] .",
    "it is run by selecting two sets of three values in @xmath102 $ ] , @xmath103 for @xmath75 and @xmath104 for @xmath74 .",
    "the nine possible combinations of these parameter values are used and the best of the nine @xmath105 is selected . we then center and reduce the possible ranges around @xmath106 and @xmath107 , respectively , and repeat the operation .",
    "the procedure is stopped when the best candidate parameters are @xmath108 and the size of the ranges satisfy @xmath109 and @xmath110 .",
    "in order to select the best value of the parameters , we compare the bounds obtained by both algorithms after @xmath111 , and @xmath112 seconds of computation . at each of these times , we count the number of times each algorithm outperforms the other by at least @xmath113 and the winner is the algorithm with the largest number of wins over the 6 clocked times .",
    "it is worth noting that typically the majority of the comparisons end up as ties , implying that the results are not extremely sensitive to the selected values for the parameters .    for sparse1 ,",
    "the best parameter values are @xmath114 and @xmath115 . for sparse2 , they are @xmath114 and @xmath116 .",
    "these values are used in all experiments using either sparse1 or sparse2 in the remainder of the paper .",
    "in the implementation , we have used the open solver interface ( osi-0.97.1 ) from coin - or @xcite to create and modify the lps and to interface with the lp solvers ilog cplex-11.1 .",
    "to compute eigenvalues and eigenvectors , we use the dsyevx function provided by the lapack library version 3.1.1 .",
    "we also include a cut management procedure to reduce the number of constraints in the outer approximation lp .",
    "this procedure , applied at the end of each iteration , removes the cuts that are not satisfied with equality by the optimal solution .",
    "note however that the constraints from the * ext+rlt * formulation are never removed , only constraints from added cutting planes are possibly removed .",
    "the machine used for the tests is a 64 bit 2.66ghz amd processor , 64 gb of ram memory , and linux kernel 2.6.29 .",
    "tolerances on the accuracy of the primal and dual solutions of the lp solver and lapack calls are set to @xmath117 .",
    "the set of instances used for most experiments consists of 51 boxqp instances with at most 50 variables and the 38 globallib instances as described in section  [ instances ] .",
    "for an instance @xmath118 and a given relaxation of it , we define the _ gap closed _ by the relaxation as @xmath119 where @xmath120 and @xmath29 are the optimal value for the given relaxation and the * ext+rlt * relaxation respectively , and @xmath121 is either the optimal value of @xmath118 or the best known value for a feasible solution .",
    "the @xmath121 values are taken from @xcite .",
    "tests are performed on a subset of instances from globallib @xcite and on box constrained quadratic programs ( boxqps ) @xcite .",
    "globallib contains 413 continuous global optimization problems of various sizes and types , such as boxqps , problems with complementarity constraints , and general qcqps .",
    "following @xcite , we select 160 instances from globallib having at most 50 variables and that can easily be formulated as * qcqp*. the conversion of a non - linear expression into a quadratic expression , when possible , is performed by adding new variables and constraints to the problem . additionally , bounds on the variables are derived using linear programming techniques and these bound are included in the formulation . from these 160 instances in ampl format , we substitute each bilinear term @xmath18 by the new variable @xmath19 as described for the * lift * formulation .",
    "we build two collections of linearized instances in mps format , one with the original precision on the coefficients and right hand side , and the second with 8-digit precision . in our experiments",
    "we used the latter .",
    "as observed in @xcite , using together the * sdp * and * rlt * relaxations yields stronger bounds than those given by the * rlt * relaxation only for 38 out of 160 globallib instances .",
    "hence , we focus on these 38 instances to test the effectiveness of the @xmath0 cuts and their sparse versions .",
    "the boxqp collection contains 90 instances with a number of variables ranging from 20 to 100 .",
    "due to time limit constraints and the number of experiments to run , we consider only instances with a number of variables between 20 to 50 , for a total of 51 boxqp problems .",
    "the converted globallib and boxqp instances are available in mps format from @xcite .",
    "we first compare the effectiveness of the various classes of cuts when used in combination with the standard psdcuts . for these tests , at most 1,000 cutting iterations are performed , at most 600 seconds are used , and operations are stopped if tailing off is detected .",
    "more precisely , let @xmath122 be the optimal value of the linear relaxation at iteration @xmath123 .",
    "the operations are halted if @xmath124 and @xmath125 .",
    "a cut purging procedure is used to remove cuts that are not tight at iteration @xmath123 if the condition @xmath126 is satisfied . on average in each iteration the algorithm generates @xmath127 cuts , of which only @xmath128 are are kept by the cut purging procedure and the rest are discarded .    in order to compare two different cutting plane algorithms , we compare the closed gaps values first after a fixed number of iterations , and second at several given times , for all qcqp instances at avail . comparisons at fixed iterations indicate the quality of the cuts , irrespective of the time used to generate them .",
    "comparisons at given times are useful if only limited time is available for running the cutting plane algorithms and a good approximation of the @xmath0 cone is sought .",
    "the closed gaps obtained at a given point are deemed different only if their difference is at least @xmath129 of the initial gap .",
    "we report comparisons for @xmath130 and @xmath131 .",
    "comparisons at one point is possible only if both algorithms reach that point .",
    "the number of problems for which this does not happen  because , at a given time , either result was not available or one of the two algorithms had already stopped , or because either algorithm had terminated in fewer iterations  is listed in the `` inc . ''",
    "( incomparable ) columns in the tables . for the remaining problems",
    ", we report the percentage of problems for which one algorithm is better than the other and the percentage of problems were they are tied .",
    "finally , we also report the average improvement in gap closed for the second algorithm over the first algorithm in the column labeled `` impr . '' .",
    "tests are first performed to decide which combination of the sparse1 , sparse2 and minor cuts perform best on average .",
    "based on tables [ bound@iter_sdpcuts_sparsecuts1_minorsdpcutsvssdpcuts_sparsecuts2_minorsdpcuts ] and [ bound@time_sdpcuts_sparsecuts1_minorsdpcutsvssdpcuts_sparsecuts2_minorsdpcuts ] below , we conclude that using minor is useful both in terms of iteration and time , and that the algorithm using psdcut+sparse2+minor ( abbreviated _ s2 m _ in the remainder ) dominates the algorithm using psdcut+sparse1+minor ( abbreviated _ s1 m _ ) both in terms of iteration and time .",
    "table  [ bound@iter_sdpcuts_sparsecuts1_minorsdpcutsvssdpcuts_sparsecuts2_minorsdpcuts ] gives the comparison between s1 m and s2 m at different iterations .",
    "s2 m dominates clearly s1 m in the very first iteration and after 200 iterations , while after the first few iterations s1 m also manages to obtain good bounds .",
    "table  [ bound@time_sdpcuts_sparsecuts1_minorsdpcutsvssdpcuts_sparsecuts2_minorsdpcuts ] gives the comparison between these two algorithms at different times . for comparisons with @xmath132 ,",
    "s1 m is better than s2 m only in at most 2.25% of the problems , while the converse varies between roughly 50% ( at early times ) and 8% ( for late times ) . for @xmath133 , s2 m still dominates s1 m in most cases .",
    "sparse cuts yield better bounds than using solely the standard @xmath0 cuts .",
    "the observed improvement is around 3% and 5% respectively for sparse1 and sparse2 .",
    "when we are using the minor cuts , this value gets to 6% and 8% respectively for each type of sparsification algorithm used .",
    "table [ bound@iter_sdpcutsvssdpcuts_sparsecuts2_minorsdpcuts ] compares psdcut ( abbreviated by _ s _ ) with s2 m .",
    "the table shows that the sparse cuts generated by the sparsification procedures and minor @xmath0 cuts yield better bounds than the standard cutting plane algorithm at fixed iterations .",
    "comparisons performed at fixed times , on the other hand , show that considering the whole set of instances we do not get any improvement in the first 60 to 120 seconds of computation ( see table  [ bound@time_sdpcutsvssdpcuts_sparsecuts2_minorsdpcuts ] ) . indeed s2 m initially performs worse than the standard cutting plane algorithm , but after 60 to 120 seconds , it produces better bounds on average . in section  [ appendix ]",
    "detailed computational results are given in tables [ detailedbound@iter_sdpcutsvssdpcuts_sparsecuts2_minorsdpcuts ] and [ detailedbound@time_sdpcutsvssdpcuts_sparsecuts2_minorsdpcuts ] where for each instance we compare the duality gap closed by s and s2 m at several iterations and times .",
    "the initial duality gap is obtained as in ( [ eq : gapclosed ] ) as @xmath134 .",
    "we then let s2 m run with no time limit until the value @xmath96 obtained does not improve by at least 0.01% over ten consecutive iterations .",
    "this value @xmath96 is an upper bound on the value of the * psd+rlt * relaxation .",
    "the column `` bound '' in the tables gives the value of @xmath135 as a percentage of the gap @xmath134 , i.e. an approximation of the percentage of the gap closed by the * psd+rlt * relaxation .",
    "the columns labeled s and s2 m in the tables give the gap closed by the corresponding algorithms at different iterations .",
    "note that although s2 m relies on numerous spectral decomposition computations , most of its running time is spent in generating cuts and reoptimization of the lp . for example , on the boxqp instances with a time limit of 300 seconds , the average percentage of cpu time spent for obtaining spectral decompositions is below 21 for instances of size 30 , below 15 for instances of size 40 and below 7 for instances of size 50 .",
    "this paper studies linearizations of the @xmath0 cone based on spectral decompositions .",
    "sparsification of eigenvectors corresponding to negative eigenvalues is shown to produce useful cuts in practice , in particular when the minor cuts are used .",
    "the goal of capturing most of the strength of an @xmath0 relaxation through linear inequalities is achieved , although tailing off occurs relatively quickly . as an illustration of typical behavior of a @xmath0 solver and our linear outer - approximation scheme ,",
    "consider the two instances , spar020 - 100 - 1 and spar030 - 060 - 1 , with respectively 20 and 30 variables .",
    "we use the sdp solver sedumi and s2 m , keeping track at each iteration of the bound achieved and the time spent .",
    "figure [ sdp0201001 ] and figure [ sdp0300601 ] compare the bounds obtained by the two solvers at a given time . for the small size instance spar020 - 100 - 1",
    ", we note that s2 m converges to the bound value more than twenty times faster than sedumi . in the medium size",
    "instance spar030 - 060 - 1 we note that s2 m closes a large gap in the first ten to twenty iterations , and then tailing off occurs . to compute the exact bound",
    ", sedumi requires 408 seconds while s2 m requires 2,442 seconds to reach the same precision .",
    "nevertheless , for our purposes , most of the benefits of the @xmath0 constraints are captured in the early iterations .",
    "two additional improvements are possible .",
    "the first one is to use a cut separation procedure for the rlt inequalities , avoiding their inclusion in the initial lp and managing them as other cutting planes .",
    "this could potentially speed up the reoptimization of the lp .",
    "another possibility is to use a mix of the s and s2 m algorithms , using the former in the early iterations and then switching to the latter .",
    "the authors warmly thank anureet saxena for the useful discussions that led to the results obtained in this work .",
    "99    f. a. al - khayyal and j. e. falk , jointly constrained biconvex programming . _ math .",
    "_ 8 , pp .  273 - 286 , 1983 .",
    "k. m. anstreicher , semidefinite programming versus the reformulation linearization technique for nonconvex quadratically constrained quadratic programming .",
    "pre - print .",
    "_ optimization online _ , may 2007 .",
    "available at http://www.optimization-online.org/db_html/2007/05/1655..html [ ]    e. balas , disjunctive programming : properties of the convex hull of feasible points .",
    "_ 89 , 1998 .",
    "m. s. bazaraa , h. d. sherali and c. m. shetty , nonlinear programming : theory and algorithms .",
    "wiley , 2006 .",
    "s. boyd , l. vandenberghe , convex optimization .",
    "cambridge university press , 2004 .",
    "s. burer and a. letchford , on non - convex quadratic programming with box constraints .",
    "_ optimization online _",
    ", july 2008 .",
    "available at + http://www.optimization-online.org/db_html/2008/07/2030.html [ ]    b. borchers , csdp , a c library for semidefinite programming , _ optimization methods and software _",
    "11(1 ) , pp .  613 - 623 , 1999 .",
    "computational infrastructure for operations research ( coin - or ) .",
    "+ http://www.coin-or.org [ ]    s. j. benson and y. ye , : software for semidefinite programming .",
    "available at http://www-unix.mcs.anl.gov/dsdp [ ]    gamsworld global optimization library .",
    "+ http://www.gamsworld.org/global/globallib/globalstat.htm [ ]    l. lovsz and a. schrijver , cones of matrices and set - functions and 0 - 1 optimization .",
    "_ siam journal on optimization _ ,",
    "may 1991    g.p .",
    "mccormick , nonlinear programming : theory , algorithms and applications .",
    "john wiley & sons , 1983 .",
    "http://www.andrew.cmu.edu/user/aqualizz/research/miqcp [ ]    a. saxena , p. bonami and j. lee , convex relaxations of non - convex mixed integer quadratically constrained programs : extended formulations , 2009 .",
    "to appear in _",
    "mathematical programming_.    , convex relaxations of non - convex mixed integer quadratically constrained programs : projected formulations , optimization online ,",
    "november 2008 .",
    "available at + http://www.optimization-online.org/db_html/2008/11/2145.html [ ]    j. f. sturm , sedumi : an optimization package over symmetric cones .",
    "available at http://sedumi.mcmaster.ca [ ]    h. d. sherali and w. p. adams , a reformulation - linearization technique for solving discrete and continuous nonconvex problems .",
    "kluwer , dordrecht 1998 .",
    "h. d. sherali and b. m. p. fraticelli , enhancing rlt relaxations via a new class of semidefinite cuts .",
    "_ j. global optim .",
    "_ 22 , pp .  233 - 261 , 2002 .    n.z .",
    "shor , quadratic optimization problems .",
    "_ tekhnicheskaya kibernetika _ , 1 , 1987 .",
    "k. sivaramakrishnan and j. mitchell , semi - infinite linear programming approaches to semidefinite programming ( sdp ) problems .",
    "novel approaches to hard discrete optimization , edited by p.m. pardalos and h. wolkowicz , _ fields institute communications series , american math . society _ , 2003 .    ,",
    "properties of a cutting plane method for semidefinite programming , technical report , department of mathematics , north carolina state university , september 2007 .",
    "k. c. toh , m. j. todd and r. h. ttnc , sdpt3 : a matlab software for semidefinite - quadratic - linear programming .",
    "available at + http://www.math.nus.edu.sg/~mattohkc/sdpt3.html [ ]    l. vandenberghe and s. boyd , semidefinite programming .",
    "_ siam review _ 38 ( 1 ) , pp .",
    "49 - 95 , 1996 .",
    "d. vandenbussche and g. l. nemhauser , a branch - and - cut algorithm for nonconvex quadratic programs with box constraints .",
    "prog . _ 102(3 ) , pp .  559 - 575 , 2005 .",
    "h. wolkowicz , r. saigal and l. vandenberghe , handbook of semidefinite programming : theory , algorithms , and applications .",
    "springer , 2000 .",
    "[ sdp0201001 ]     [ sdp0300601 ]       .comparison of s1 m with s2 m at several iterations . [ cols=\"^,^,^,^,^,^,^,^,^ \" , ]",
    "r|rr|r|rr|rr|rr + & & & & & & + instance & @xmath136 & @xmath137 & bound & s & s2 m & s & s2 m & s & s2 m +   +          circle & 3 & 0 & 45.79 & 0.00 & 0.00 & 10.97 & 41.31 & 45.77 & 45.79 + dispatch & 3 & 1 & 100.00 & 25.59 & 27.92 & 37.25 & 35.76 & 95.90 & 92.17 + ex2_1_10 & 20 & 0 & 22.05 & 3.93 & 8.65 & 15.93 & 21.05 & 22.05 & 22.05 + ex3_1_2 & 5 & 0 & 49.75 & 49.75 & 49.75 & 49.75 & 49.75 & 49.75 & 49.75 + ex4_1_1 & 3 & 0 & 100.00 & 99.81 & 99.84 & 100.00 & 100.00 & 100.00 & 100.00 + ex4_1_3 & 3 & 0 & 56.40 & 0.00 & 0.00 & 51.19 & 51.19 & 56.40 & 56.40 + ex4_1_4 & 3 & 0 & 100.00 & 22.33 & 42.78 & 98.98 & 99.98 & 100.00 & 100.00 + ex4_1_6 & 3 & 0 & 100.00 & 69.44 & 69.87 & 92.62 & 99.94 & 100.00 & 100.00 + ex4_1_7 & 3 & 0 & 100.00 & 18.00 & 48.17 & 96.86 & 99.90 & 100.00 & 100.00 + ex4_1_8 & 3 & 0 & 100.00 & 56.90 & 81.93 & 99.76 & 99.93 & 100.00 & 100.00 + ex8_1_4 & 4 & 0 & 100.00 & 94.91 & 95.19 & 99.98 & 100.00 & 100.00 & 100.00 + ex8_1_5 & 5 & 0 & 68.26 & 32.32 & 39.17 & 59.01 & 66.76 & 68.00 & 68.25 + ex8_1_7 & 9 & 0 & 77.43 & 3.04 & 33.75 & 33.13 & 53.44 & 64.03 & 75.38 + ex8_4_1 & 21 & 1 & 91.81 & 4.45 & 21.80 & 18.60 & 45.08 & 38.07 & 69.83 + ex9_2_1 & 10 & 0 & 54.52 & 0.00 & 42.55 & 0.01 & 50.13 & 0.01 & 51.90 + ex9_2_2 & 10 & 0 & 70.37 & 0.00 & 14.08 & 2.34 & 51.97 & 7.12 & 69.41 + ex9_2_4 & 6 & 2 & 99.87 & 0.00 & 24.84 & 25.24 & 99.85 & 86.37 & 99.87 + ex9_2_6 & 16 & 0 & 99.88 & 3.50 & 99.42 & 23.09 & 99.86 & 62.32 & 99.88 + ex9_2_7 & 10 & 0 & 42.30 & 0.00 & 4.59 & 0.00 & 27.34 & 3.14 & 34.91 + himmel11 & 5 & 4 & 49.75 & 49.75 & 49.75 & 49.75 & 49.75 & 49.75 & 49.75 + hydro & 12 & 19 & 52.06 & 0.00 & 20.87 & 21.95 & 29.03 & 26.04 & 31.39 + mathopt1 & 4 & 0 & 100.00 & 95.76 & 100.00 & 99.96 & 100.00 & 100.00 & 100.00 + mathopt2 & 3 & 0 & 100.00 & 99.84 & 99.93 & 100.00 & 100.00 & 100.00 & 100.00 + meanvar & 7 & 1 & 100.00 & 0.00 & 0.00 & 78.35 & 95.84 & 100.00 & 100.00 + nemhaus & 5 & 0 & 53.97 & 26.00 & 26.41 & 48.49 & 50.16 & 53.87 & 53.96 + prob06 & 2 & 0 & 100.00 & 90.61 & 92.39 & 98.39 & 98.39 & 98.39 & 98.39 + prob09 & 3 & 1 & 100.00 & 0.00 & 99.00 & 61.14 & 99.96 & 99.64 & 100.00 + process & 9 & 3 & 8.00 & 0.00 & 4.25 & 0.00 & 4.98 & 0.00 & 5.73 + qp1 & 50 & 0 & 100.00 & 79.59 & 89.09 & 93.89 & 99.77 & 98.93 & 100.00 + qp2 & 50 & 0 & 100.00 & 55.94 & 70.99 & 82.42 & 93.92 & 93.04 & 99.35 + rbrock & 3 & 0 & 100.00 & 97.48 & 100.00 & 99.96 & 100.00 & 100.00 & 100.00 + st_e10 & 3 & 1 & 100.00 & 56.90 & 81.93 & 99.76 & 99.93 & 100.00 & 100.00 + st_e18 & 2 & 0 & 100.00 & 0.00 & 0.00 & 98.72 & 98.72 & 100.00 & 100.00 + st_e19 & 3 & 1 & 93.51 & 5.14 & 15.93 & 29.97 & 60.10 & 93.40 & 93.50 + st_e25 & 4 & 0 & 87.55 & 55.80 & 55.80 & 87.02 & 87.01 & 87.23 & 87.23 + st_e28 & 5 & 4 & 49.75 & 49.75 & 49.75 & 49.75 & 49.75 & 49.75 & 49.75 + st_iqpbk1 & 8 & 0 & 97.99 & 71.99 & 76.69 & 97.20 & 97.95 & 97.99 & 97.99 + st_iqpbk2 & 8 & 0 & 97.93 & 70.55 & 75.16 & 94.93 & 97.52 & 97.93 & 97.93 + spar020 - 100 - 1 & 20 & 0 & 100.00 & 91.15 & 94.64 & 99.77 & 99.99 & 100.00 & 100.00 + spar020 - 100 - 2 & 20 & 0 & 99.70 & 90.12 & 92.64 & 98.17 & 99.32 & 99.66 & 99.69 + spar020 - 100 - 3 & 20 & 0 & 100.00 & 96.96 & 98.51 & 100.00 & 100.00 & 100.00 & 100.00 + spar030 - 060 - 1 & 30 & 0 & 98.87 & 43.53 & 53.64 & 79.61 & 87.39 & 93.90 & 97.14 + spar030 - 060 - 2 & 30 & 0 & 100.00 & 80.74 & 89.73 & 99.89 & 100.00 & 100.00 & 100.00 + spar030 - 060 - 3 & 30 & 0 & 99.40 & 67.43 & 71.94 & 91.48 & 95.68 & 98.75 & 99.26 + spar030 - 070 - 1 & 30 & 0 & 97.99 & 49.05 & 54.94 & 76.54 & 86.51 & 91.15 & 95.68 + spar030 - 070 - 2 & 30 & 0 & 100.00 & 81.19 & 85.82 & 99.26 & 99.99 & 100.00 & 100.00 + spar030 - 070 - 3 & 30 & 0 & 99.98 & 85.97 & 87.43 & 98.44 & 99.52 & 99.92 & 99.97 + spar030 - 080 - 1 & 30 & 0 & 98.99 & 64.44 & 70.99 & 87.32 & 92.11 & 96.23 & 98.01 + spar030 - 080 - 2 & 30 & 0 & 100.00 & 92.78 & 95.45 & 100.00 & 100.00 & 100.00 & 100.00 + spar030 - 080 - 3 & 30 & 0 & 100.00 & 92.71 & 94.18 & 99.99 & 100.00 & 100.00 & 100.00 + spar030 - 090 - 1 & 30 & 0 & 100.00 & 80.37 & 86.35 & 97.27 & 99.30 & 100.00 & 100.00 + spar030 - 090 - 2 & 30 & 0 & 100.00 & 86.09 & 89.26 & 98.13 & 99.65 & 100.00 & 100.00 + spar030 - 090 - 3 & 30 & 0 & 100.00 & 90.65 & 91.56 & 99.97 & 100.00 & 100.00 & 100.00 + spar030 - 100 - 1 & 30 & 0 & 100.00 & 77.28 & 83.25 & 95.20 & 98.30 & 99.85 & 100.00 + spar030 - 100 - 2 & 30 & 0 & 99.96 & 76.78 & 81.65 & 93.44 & 96.84 & 98.70 & 99.72 + spar030 - 100 - 3 & 30 & 0 & 99.85 & 86.82 & 88.74 & 97.45 & 98.75 & 99.75 & 99.83 + spar040 - 030 - 1 & 40 & 0 & 100.00 & 25.60 & 41.96 & 73.59 & 84.72 & 99.13 & 100.00 + spar040 - 030 - 2 & 40 & 0 & 100.00 & 30.93 & 53.39 & 79.34 & 95.62 & 99.46 & 100.00 + spar040 - 030 - 3 & 40 & 0 & 100.00 & 9.21 & 31.38 & 66.46 & 86.62 & 98.53 & 100.00 + spar040 - 040 - 1 & 40 & 0 & 96.74 & 23.62 & 29.03 & 63.04 & 75.93 & 85.93 & 93.29 + spar040 - 040 - 2 & 40 & 0 & 100.00 & 33.17 & 48.87 & 89.08 & 97.94 & 100.00 & 100.00 + spar040 - 040 - 3 & 40 & 0 & 99.18 & 21.77 & 30.31 & 70.44 & 80.96 & 91.37 & 96.69 + spar040 - 050 - 1 & 40 & 0 & 99.42 & 35.62 & 44.87 & 73.11 & 84.05 & 92.81 & 97.21 + spar040 - 050 - 2 & 40 & 0 & 99.48 & 36.79 & 47.68 & 82.38 & 91.27 & 97.26 & 98.93 + spar040 - 050 - 3 & 40 & 0 & 100.00 & 41.91 & 51.72 & 84.04 & 90.70 & 96.88 & 99.34 + spar040 - 060 - 1 & 40 & 0 & 98.09 & 46.22 & 52.89 & 81.65 & 87.28 & 92.39 & 95.97 + spar040 - 060 - 2 & 40 & 0 & 100.00 & 63.02 & 72.87 & 94.09 & 97.66 & 99.78 & 100.00 + spar040 - 060 - 3 & 40 & 0 & 100.00 & 78.09 & 87.91 & 99.30 & 99.99 & 100.00 & 100.00 + spar040 - 070 - 1 & 40 & 0 & 100.00 & 64.02 & 71.33 & 93.92 & 97.35 & 99.77 & 100.00 + spar040 - 070 - 2 & 40 & 0 & 100.00 & 67.49 & 76.78 & 95.12 & 97.97 & 99.97 & 100.00 + spar040 - 070 - 3 & 40 & 0 & 100.00 & 70.13 & 79.43 & 95.65 & 97.99 & 99.75 & 100.00 + spar040 - 080 - 1 & 40 & 0 & 100.00 & 63.06 & 69.40 & 91.09 & 95.44 & 99.00 & 99.97 + spar040 - 080 - 2 & 40 & 0 & 100.00 & 71.42 & 79.77 & 94.98 & 97.62 & 99.92 & 100.00 + spar040 - 080 - 3 & 40 & 0 & 99.99 & 83.93 & 88.65 & 97.76 & 98.86 & 99.81 & 99.95 + spar040 - 090 - 1 & 40 & 0 & 100.00 & 75.73 & 79.96 & 95.34 & 97.43 & 99.46 & 99.91 + spar040 - 090 - 2 & 40 & 0 & 99.97 & 76.39 & 80.97 & 95.16 & 96.72 & 99.20 & 99.81 + spar040 - 090 - 3 & 40 & 0 & 100.00 & 84.90 & 87.04 & 98.33 & 99.52 & 100.00 & 100.00 + spar040 - 100 - 1 & 40 & 0 & 100.00 & 87.64 & 90.43 & 98.27 & 99.35 & 99.98 & 100.00 + spar040 - 100 - 2 & 40 & 0 & 99.87 & 79.78 & 83.02 & 94.58 & 96.76 & 98.74 & 99.50 + spar040 - 100 - 3 & 40 & 0 & 98.70 & 72.69 & 78.31 & 90.83 & 93.03 & 95.84 & 97.36 + spar050 - 030 - 1 & 50 & 0 & 100.00 & 3.11 & 17.60 & 58.23 & 79.98 & - & - + spar050 - 030 - 2 & 50 & 0 & 99.27 & 1.35 & 16.67 & 51.11 & 70.58 & - & - + spar050 - 030 - 3 & 50 & 0 & 99.29 & 0.08 & 13.63 & 50.19 & 67.46 & - & - + spar050 - 040 - 1 & 50 & 0 & 100.00 & 23.13 & 30.86 & 72.10 & 81.73 & - & - + spar050 - 040 - 2 & 50 & 0 & 99.39 & 21.89 & 34.45 & 71.24 & 81.63 & - & - + spar050 - 040 - 3 & 50 & 0 & 100.00 & 27.18 & 37.42 & 83.96 & 91.70 & - & - + spar050 - 050 - 1 & 50 & 0 & 93.02 & 25.24 & 33.77 & 61.42 & 68.75 & - & - + spar050 - 050 - 2 & 50 & 0 & 98.74 & 32.10 & 41.26 & 77.48 & 83.48 & - & - + spar050 - 050 - 3 & 50 & 0 & 98.84 & 38.57 & 44.67 & 80.97 & 85.36 & - & - + average & - & - & - & 48.75 & 59.00 & 75.53 & 84.39 & 85.85 & 89.60            ex4_1_4 & 100.00 & - & 100.00 & - & - & - & - & - & - & - & - + ex8_1_4 & 100.00 & - & 100.00 & - & - & - & - & - & - & - & - + ex8_1_7 & 77.43 & 77.43 & 77.37 & - & - & - & - & - & - & - & - + ex8_4_1 & 91.81 & 28.14 & 36.24 & 61.60 & 90.43 & - & - & - & - & - & - + ex9_2_2 & 70.37 & - & 70.35 & - & - & - & - & - & - & - & - + ex9_2_6 & 99.88 & 96.28 & - & - & - & - & - & - & - & - & - + hydro & 52.06 & 26.43 & 31.46 & - & - & - & - & - & - & - & - + mathopt2 & 100.00 & - & 100.00 & - & - & - & - & - & - & - & - + process & 8.00 & - & 7.66 & - & - & - & - & - & - & - & - + qp1 & 100.00 & 79.99 & 80.28 & 98.22 & 99.52 & 99.73 & 99.96 & 99.92 & 99.98 & 99.99 & 100.00 + qp2 & 100.00 & 55.82 & 55.27 & 91.74 & 95.56 & 95.86 & 98.69 & 97.41 & 99.66 & 98.80 & 100.00 + spar020 - 100 - 1 & 100.00 & 100.00 & 100.00 & - & - & - & - & - & - & - & - + spar020 - 100 - 2 & 99.70 & 99.67 & 99.61 & - & - & - & - & - & - & - & - + spar020 - 100 - 3 & 100.00 & - & 100.00 & - & - & - & - & - & - & - & - + spar030 - 060 - 1 & 98.87 & 69.98 & 58.72 & 96.53 & 97.61 & 98.45 & 98.70 & 98.68 & 98.82 & - & - + spar030 - 060 - 2 & 100.00 & 96.52 & 91.05 & - & - & - & - & - & - & - & - + spar030 - 060 - 3 & 99.40 & 82.99 & 76.15 & 99.27 & 99.32 & 99.38 & 99.39 & 99.39 & 99.40 & 99.40 & 99.40 + spar030 - 070 - 1 & 97.99 & 69.81 & 60.36 & 94.50 & 96.38 & 97.29 & 97.73 & 97.70 & 97.91 & - & 97.98 + spar030 - 070 - 2 & 100.00 & 96.05 & 87.93 & - & - & - & - & - & - & - & - + spar030 - 070 - 3 & 99.98 & 96.26 & 90.42 & 99.98 & 99.98 & 99.98 & 99.98 & - & 99.98 & - & - + spar030 - 080 - 1 & 98.99 & 83.36 & 74.42 & 97.80 & 98.11 & 98.74 & 98.88 & 98.89 & 98.96 & - & 98.99 + spar030 - 080 - 2 & 100.00 & 99.83 & 96.70 & - & - & - & - & - & - & - & - + spar030 - 080 - 3 & 100.00 & 99.88 & 95.87 & - & - & - & - & - & - & - & - + spar030 - 090 - 1 & 100.00 & 92.86 & 87.69 & - & - & - & - & - & - & - & - + spar030 - 090 - 2 & 100.00 & 93.80 & 88.46 & - & 100.00 & - & - & - & - & - & - + spar030 - 090 - 3 & 100.00 & 97.78 & 91.35 & - & - & - & - & - & - & - & - + spar030 - 100 - 1 & 100.00 & 91.04 & 84.34 & 100.00 & 100.00 & - & - & - & - & - & - + spar030 - 100 - 2 & 99.96 & 90.21 & 83.14 & 99.56 & 99.75 & 99.91 & 99.95 & 99.95 & 99.96 & - & 99.96 + spar030 - 100 - 3 & 99.85 & 94.26 & 89.55 & 99.84 & 99.84 & 99.85 & 99.85 & 99.85 & 99.85 & 99.85 & 99.85 + spar040 - 030 - 1 & 100.00 & 28.97 & 40.51 & 89.30 & 84.19 & 99.06 & 99.98 & 99.98 & 100.00 & - & 100.00 + spar040 - 030 - 2 & 100.00 & 31.97 & 48.01 & 94.01 & 96.39 & 99.58 & 99.98 & 99.99 & 100.00 & - & - + spar040 - 030 - 3 & 100.00 & 9.20 & 27.59 & 81.66 & 85.43 & 97.25 & 99.86 & 99.81 & 100.00 & 100.00 & - + spar040 - 040 - 1 & 96.74 & 19.38 & 22.90 & 70.35 & 75.45 & 80.73 & 88.63 & 85.34 & 92.29 & 90.79 & 94.74 + spar040 - 040 - 2 & 100.00 & 24.51 & 29.87 & 98.63 & 98.60 & 100.00 & 100.00 & - & - & - & - + spar040 - 040 - 3 & 99.18 & 20.88 & 21.31 & 78.28 & 79.31 & 86.02 & 91.22 & 89.52 & 95.04 & 94.07 & 97.71 + spar040 - 050 - 1 & 99.42 & 28.96 & 21.27 & 80.18 & 84.01 & 88.70 & 94.62 & 92.75 & 96.71 & 96.53 & 98.32 + spar040 - 050 - 2 & 99.48 & 29.52 & 16.91 & 91.33 & 91.42 & 97.01 & 97.97 & 98.26 & 98.87 & - & 99.31 + spar040 - 050 - 3 & 100.00 & 28.67 & 19.81 & 90.03 & 90.72 & 95.68 & 97.51 & 97.49 & 99.08 & 98.92 & 99.89 + spar040 - 060 - 1 & 98.09 & 37.16 & 17.10 & 86.26 & 87.13 & 90.18 & 93.50 & 92.25 & 95.32 & 95.05 & 96.84 + spar040 - 060 - 2 & 100.00 & 39.57 & 22.83 & 98.09 & 98.22 & 99.90 & 99.96 & 100.00 & 100.00 & 100.00 & - + spar040 - 060 - 3 & 100.00 & 52.41 & 30.57 & 100.00 & 99.99 & - & - & - & - & - & - + spar040 - 070 - 1 & 100.00 & 50.01 & 21.79 & 97.74 & 97.78 & 99.80 & 99.87 & 99.97 & 99.99 & 100.00 & 100.00 + spar040 - 070 - 2 & 100.00 & 47.57 & 25.19 & 98.81 & 98.46 & 99.99 & 99.99 & 100.00 & 100.00 & - & - + spar040 - 070 - 3 & 100.00 & 47.22 & 21.95 & 98.96 & 98.70 & 99.88 & 99.92 & 99.98 & 100.00 & 100.00 & 100.00 + spar040 - 080 - 1 & 100.00 & 51.66 & 28.00 & 95.13 & 95.38 & 98.29 & 99.05 & 99.09 & 99.74 & 99.77 & 99.99 + spar040 - 080 - 2 & 100.00 & 52.24 & 25.94 & 98.71 & 98.31 & 99.95 & 99.97 & 100.00 & 100.00 & - & - + spar040 - 080 - 3 & 99.99 & 56.05 & 26.98 & 99.54 & 99.25 & 99.89 & 99.88 & 99.94 & 99.95 & 99.97 & 99.98 + spar040 - 090 - 1 & 100.00 & 59.71 & 28.17 & 98.10 & 97.86 & 99.43 & 99.61 & 99.70 & 99.86 & 99.90 & 99.99 + spar040 - 090 - 2 & 99.97 & 59.14 & 29.82 & 97.83 & 97.70 & 99.34 & 99.58 & 99.68 & 99.81 & 99.86 & 99.93 + spar040 - 090 - 3 & 100.00 & 63.07 & 34.62 & 99.94 & 99.85 & 100.00 & 100.00 & - & - & - & - + spar040 - 100 - 1 & 100.00 & 69.47 & 28.24 & 99.66 & 99.47 & 99.99 & 99.99 & 100.00 & 100.00 & - & - + spar040 - 100 - 2 & 99.87 & 65.27 & 26.07 & 97.34 & 96.87 & 98.60 & 98.98 & 99.02 & 99.39 & 99.44 & 99.69 + spar040 - 100 - 3 & 98.70 & 61.40 & 29.61 & 93.01 & 93.17 & 94.91 & 96.02 & 95.81 & 97.00 & 96.84 & 97.77 + spar050 - 030 - 1 & 100.00 & 0.37 & 3.63 & 54.46 & 37.52 & 70.10 & 73.34 & 76.87 & 84.75 & 86.23 & 96.33 + spar050 - 030 - 2 & 99.27 & 0.08 & 2.79 & 44.68 & 38.62 & 59.58 & 64.94 & 67.79 & 74.98 & 77.02 & 86.58 + spar050 - 030 - 3 & 99.29 & 0.00 & 2.75 & 44.32 & 32.31 & 57.13 & 59.07 & 62.54 & 68.99 & 71.18 & 82.86 + spar050 - 040 - 1 & 100.00 & 3.76 & 1.77 & 69.97 & 56.87 & 77.15 & 78.30 & 80.31 & 84.30 & 84.90 & 91.79 + spar050 - 040 - 2 & 99.39 & 2.08 & 2.84 & 68.64 & 58.47 & 77.72 & 77.61 & 81.54 & 83.63 & 86.40 & 90.94 + spar050 - 040 - 3 & 100.00 & 1.76 & 2.31 & 79.44 & 65.71 & 89.73 & 87.74 & 92.67 & 93.00 & 95.99 & 97.69 + spar050 - 050 - 1 & 93.02 & 4.91 & 1.84 & 60.64 & 53.28 & 65.52 & 66.42 & 66.81 & 70.38 & 68.45 & 74.76 + spar050 - 050 - 2 & 98.74 & 6.18 & 3.39 & 76.56 & 68.33 & 82.34 & 82.21 & 84.94 & 86.52 & - & 91.34 + spar050 - 050 - 3 & 98.84 & 6.12 & 2.82 & 79.38 & 69.23 & 84.95 & 83.23 & 86.99 & 86.98 & 89.77 & 91.57 + average & - & 51.45 & 42.96 & 87.50 & 86.38 & 92.14 & 93.22 & 93.18 & 94.77 & 93.16 & 95.86 +"
  ],
  "abstract_text": [
    "<S> we investigate the use of linear programming tools for solving semidefinite programming relaxations of quadratically constrained quadratic problems . </S>",
    "<S> classes of valid linear inequalities are presented , including sparse @xmath0 cuts , and principal minors @xmath0 cuts . </S>",
    "<S> computational results based on instances from the literature are presented .    </S>",
    "<S> quadratic programming , semidefinite programming , relaxation , linear programming .     </S>"
  ]
}