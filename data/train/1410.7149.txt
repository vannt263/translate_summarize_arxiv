{
  "article_text": [
    "markov chain monte carlo ( mcmc ) algorithms  @xcite are often used to generate samples distributed according to non - trivial densities in high dimensional spaces .",
    "many algorithms have been developed that allow mcmcs to produce samples @xmath0 from an unnormalized target density @xmath1 : @xmath2    in many applications , it is desirable or even necessary to be able to normalize the target density",
    ". i.e. , to calculate    @xmath3    where @xmath4 is the support of @xmath5 . this integral can be computationally very costly or impossible to perform with standard techniques if the volume where the target @xmath5 is non - negligible occupies a very small part of the total volume of @xmath6 .",
    "an important area where such integration is necessary is for bayesian data analysis  @xcite .",
    "bayes formula reads , for a given model @xmath7 , @xmath8 where here @xmath9 are the parameters of the model and the data are used to extract probabilities for possible values of @xmath9 .",
    "the denominator is usually expanded using the law of total probability and written in the form @xmath10 and goes by the names ` evidence ' , or ` marginal likelihood ' , and is the type of integral that we want to be able to calculate ( here the data are fixed and @xmath11 ) .",
    "an example use of @xmath12 is for the calculation of bayes factors in the comparison of two models : @xmath13 another application where the calculation of a normalization can be very important is in the parallelization of the mcmc algorithm  @xcite . while the mcmc approach has very attractive features , it is often slow in its execution due to the nature of the algorithm .",
    "a goal is therefore to parallelize the computations needed to map out the target density .",
    "this looks at first sight difficult since the mcmc algorithms are by construction serial .",
    "a parallelization of the calculations can however be achieved via a partitioning of the support .",
    "i.e. , we partition @xmath6 into sub volumes @xmath14 with @xmath15 and we run a separate mcmc sampling for each sub volume @xmath14 . in order to have a final set of samples representing the target density over the full support",
    ", we need to know the relative probabilities for the different sub volumes .",
    "i.e , we need @xmath16 the samples in the different regions are then given weights @xmath17 with @xmath18 the number of samples from @xmath1 in @xmath14 and @xmath19 .",
    "a variety of techniques to calculate the evidence in bayesian calculations have been successfully developed .",
    "a summary can be found in  @xcite , where a number of mcmc related techniques are reviewed , including laplace s method  @xcite , harmonic mean estimation  @xcite , chib s method  @xcite , annealed importance sampling techniques  @xcite , nested sampling  @xcite and thermodynamic integration methods  @xcite .",
    "we are here specifically interested in testing techniques directly applicable in an mcmc setting , and which is independent of the specific mcmc algorithm .",
    "we assume that the mcmc algorithm has been successfully run to extract samples according to the target density , and the goal is to provide an algorithm for calculating the normalization ( or evidence ) .",
    "given our requirements , only arithmetic mean estimation ( ame ) , harmonic mean estimation ( hme ) and laplace methods are directly applicable . using ame and hme methods",
    "directly is known to fail in many situations , and the laplace method is only applicable if the target density is gaussian .",
    "we introduce the use of a reduced integration volume and normalization using the mcmc output to improve the ame and hme performance . after a description of the techniques",
    ", we report on numerical investigations of the different approaches using samples from the mcmc code bat  @xcite .      assuming the mcmc has been successfully run to extract samples according to @xmath20 , one of the quantities directly retrievable from the mcmc output",
    "is an estimate of the parameter values at the global mode : @xmath21 is in the neighborhood of @xmath22 .",
    "i.e. , we know approximately where the integrand in eq .",
    "[ eq : integral ] has its maximum .",
    "we note that @xmath23 with @xmath24 a sub support of @xmath6 is directly estimated from the mcmc output by counting the fraction of samples falling within @xmath25 , @xmath26 ( the reason for this notation will become clear below ) .",
    "i.e. , the task of evaluating @xmath27 reduces to integrating the function @xmath1 over a well - chosen region - presumably a small region around @xmath22 and dividing by @xmath28 .",
    "this integral can be much simpler to evaluate than the integral over the full support .      in the following , we use a simple hypercube for our integration region .",
    "from the mcmc samples , we can construct the marginalized distributions along each of the @xmath9 dimensions .",
    "we define an interval along each dimension centered at @xmath21 with width which is a multiple of the standard deviation ( we use the symbol @xmath29 to represent this factor ) .",
    "the optimum value of @xmath29 depends on the dimensionality of the problem as described below .",
    "another option would be to produce a covariance matrix of the @xmath0 for sampling using a multivariate normal distribution if desired , but this was not found necessary in the examples we have studied .",
    "the integral in the numerator in eq .",
    "[ eq : scheme ] can presumably be determined in a straightforward way since now we are focusing on a small volume with significant mass .",
    "the standard importance sampling approximation is given by    @xmath30    where our sampling probability density is given by @xmath31 .",
    "@xmath32 is the number of samples used in the calculation .",
    "if we choose for @xmath31 a uniform distribution in the hypercube , then we have the well - known sample mean result @xmath33 with @xmath34 the volume of the hypercube .",
    "our estimator for @xmath27 is then @xmath35    we will use this simplest version of the estimator for our examples below .      assuming unbiased gaussian distributions for @xmath36 and @xmath28 about their true values",
    ", we can estimate the uncertainty for @xmath27 with @xmath37 where @xmath38 the effective sample size  @xcite is defined here as @xmath39 with the autocorrelation function at @xmath40 defined for our mcmc sample as @xmath41 in these equations , the subscript @xmath42 labels the component of @xmath0 , while the index @xmath40 labels the iteration in the mcmc .",
    "the uncertainty from the sample mean integration is estimated by separating the sample mean calculation of @xmath36 into @xmath43 batches and looking at the variance of these calculations : @xmath44 with these definitions , we are able to report both an estimate for our integral and an uncertainty . these will be compared to accurately calculated values for the chosen examples in the following sections .      the hme  @xcite value for @xmath27 can be calculated as follows :",
    "@xmath45_{\\hat{f}(\\lambda ) } & = & \\int_{\\omega } \\frac{1}{f(\\lambda ) } \\cdot \\frac{f(\\lambda)}{i } d\\lambda \\\\ & = & \\frac{v}{i } \\end{aligned}\\ ] ] where @xmath46 is the normalised target density and @xmath47 is the total volume of the support .",
    "the hme estimator is then @xmath48    this calculation is performed directly from the mcmc output from which the samples @xmath0 as well as @xmath49 are available , and does not require an extra sample mean calculation as in the ame scheme . however , it can be unstable because of samples occurring ( or missing ) in regions where @xmath1 is small ( relative to other regions ) .",
    "we can improve the estimation , as originally noted in  @xcite , by limiting ourselves to a small volume around the mode . using the same notation as above ,",
    "we can write @xmath50 where now only the samples in the restricted support @xmath24 are used . the uncertainty in the estimate is calculated by separating the mcmc samples included in our integration region into batches and looking at the variation of these estimates .      in this approach",
    ", the target distribution is assumed to be represented by a ( multivariate ) gaussian distribution .",
    "the estimator for the normalization is then @xmath51 where the target density is evaluated at the mode returned from the mcmc and @xmath52 is the determinant of the covariance matrix evaluated numerically from the samples @xmath0 .",
    "this method is clearly only expected to work in cases where the assumption of normality is valid .",
    "we start with a simple example - the target density is the product of a number of gauss functions depending on only one parameter - to describe our testing procedures in detail .",
    "we then move on to more complicated examples in multivariate spaces , including functions with degenerate modes .",
    "all mcmc calculations were performed using the bat program , with samples from the target density taken after convergence of the mcmc algorithm .",
    "we start with the following target function : @xmath53 this type of function could , e.g. , be the likelihood function constructed for producing an estimate of a quantity , @xmath54 , given @xmath55 measurements , @xmath56 , with a sampling distribution modeled by a gaussian probability distribution of fixed width @xmath57 .",
    "the normalization integral for the target can be performed analytically assuming the volume of interest extends well beyond the extreme values of the @xmath58 . for the more general case of the product of @xmath55 @xmath59-dimensional uncorrelated gaussian functions with known variances @xmath60 , the integral",
    "is given by    @xmath61 d\\vec{\\mu } \\\\   & = & \\frac{1}{(2\\pi)^{d\\cdot ( m-1)/2}\\vert\\sigma\\vert^{(m-1)/2 } m^{d/2 } } \\exp\\left(-\\sum_{j=1}^d \\frac{{\\rm var}[x_j]}{2\\sigma_j^2 } \\right ) \\end{aligned}\\ ] ]    where @xmath62 is the ( diagonal ) covariance matrix .",
    "for our concrete example , we take @xmath63 and generate random values of @xmath64 from a gauss distribution of mean zero and unit standard deviation , and we find for the generated values @xmath65 . in evaluating the integral , we take for the support @xmath66 .",
    "we then use @xmath67 samples from the mcmc output to find an estimate for the mode of @xmath68 and to calculate the standard deviation for @xmath54 .",
    "the distribution of samples from @xmath68 from the mcmc are displayed in fig .",
    "[ fig : mcmc1d](left ) .",
    "the mode of the samples is found at @xmath69 and the standard deviation is found to be @xmath70 .",
    "the effective sample size for this set of samples is @xmath71 .    the dependence of @xmath28 on the chosen value of @xmath29 is also shown in fig .",
    "[ fig : mcmc1d](right ) for 500 values of @xmath29 ranging from @xmath72 to @xmath73 in steps of @xmath72 . for a one - dimensional gaussian target density , which is what we have here",
    ", the expectation is that 68  % of mcmc samples occur within @xmath74 and 95  % occur within @xmath75 , and this is indeed what is found .     as a function of the value of @xmath29 ( in units of the standard deviation of the distribution).,title=\"fig:\",width=264 ]   as a function of the value of @xmath29 ( in units of the standard deviation of the distribution).,title=\"fig:\",width=264 ]",
    "we then perform a sample mean calculation with @xmath76 samples for each of the different choices of @xmath29 . for each calculation",
    ", we extract a value of @xmath77 as described in section  [ sec : sm ] as well as an estimate of the uncertainty .",
    "the extracted values of @xmath77 ( divided by the true value ) are shown as a function of @xmath29 in fig .",
    "[ fig : evidence1d](left ) .",
    "the error bars are the estimated one standard deviation uncertainties .",
    "we observe small systematic deviations of the results for small values of @xmath29 resulting from the inaccurate determination of @xmath78 from the mcmc samples ( note that the mcmc was only run once , so that the @xmath28 values are correlated ) .     as a function of @xmath29 , scaled by the true value .",
    "the error bars correspond to the estimated uncertainty .",
    "right ) the actual error @xmath79 ( red ) , the estimated uncertainty @xmath80 ( black ) and the total estimated uncertainty @xmath81 ( blue ) as a function of @xmath29 .",
    ", title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "the error bars correspond to the estimated uncertainty .",
    "right ) the actual error @xmath79 ( red ) , the estimated uncertainty @xmath80 ( black ) and the total estimated uncertainty @xmath81 ( blue ) as a function of @xmath29 .",
    ", title=\"fig:\",width=264 ]    to study the uncertainty estimation , we compare @xmath81 to @xmath82 at each value of @xmath29 .",
    "the results are shown in fig .",
    "[ fig : evidence1d](right ) . in this figure ,",
    "the red points indicate the absolute value of @xmath82 , the black points the estimated uncertainty coming from the sample mean calculation , @xmath83 , and the blue points the total estimated uncertainty , @xmath81 .",
    "we observe that our estimated uncertainty is accurate , and that there is a minimum of the uncertainty around @xmath75 .",
    "the location of the minimum clearly depends on the number of samples chosen for the mcmc and sample mean calculations , but it is important that we can accurately estimate the uncertainty . in this case , the arithmetic mean calculation is quite accurate even at large values of @xmath29 since we are only working in one - dimension .",
    "we now evaluate the harmonic mean estimate for @xmath27 as described in section  [ sec : hme ] .",
    "the estimate @xmath84 as well as the absolute deviation from @xmath85 as a function of @xmath29 are shown in fig .",
    "[ fig : hme ] .",
    "we see for this example that the hme technique works well , and that accuracies of a fraction of 1  % are possible from the hme estimation at @xmath86 . as @xmath29",
    "is increased , the hme estimation worsens since , although more of the mcmc samples are included , reducing the binomial uncertainty on @xmath26 , imperfect sampling in the tails of the distribution plays a large role and we see the importance of limiting the range of the integration region for the hme calculation already with this simple one - dimensional example .",
    "the uncertainty is somewhat worse than what was found for the ame calculation , but probably adequate for the majority of applications .",
    "also , the calculation did not require the extra step of performing a sample mean calculation .",
    "scaled by the true value as a function of @xmath29 .",
    "the error bars correspond to the estimated uncertainty .",
    "right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    ", title=\"fig:\",width=264 ]   scaled by the true value as a function of @xmath29 .",
    "the error bars correspond to the estimated uncertainty .",
    "right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    ", title=\"fig:\",width=264 ]    as seen in fig .",
    "[ fig : mcmc1d ] , the target density is gaussian and therefore the laplace method is expected to work well .",
    "indeed , the laplace method yields an estimate within @xmath88  % of the true value in this example : @xmath89 .",
    "we now move to a target density composed of a product of ten dimensional gaussian distributions with non - diagonal covariance matrix .",
    "the target function in this case is : @xmath90 where @xmath62 is the covariance matrix , assumed to be known , and @xmath91 .",
    "the target function is ten - dimensional and has significant correlations among the ten parameters .",
    "the values of @xmath92 were chosen by generating random vectors using @xmath93 and the following covariance matrix    @xmath94 and again could represent a type of situation found in a data analysis setting .",
    "the integration region for @xmath27 was taken as a @xmath95d hypercube of side length @xmath96 centered on @xmath97 .",
    "the value for @xmath85 can again be evaluated analytically by finding the similarity transformation that diagonalizes the covariance matrix .",
    "the expression of the integral in this case is    @xmath98 \\right ) .\\ ] ]    where @xmath99 and @xmath100 with @xmath101 a diagonal matrix .",
    "the true value of the integral for randomly generated data was evaluated using this expression and yielded @xmath102 .",
    "the mcmc program bat was used to sample from the target density with @xmath103 samples stored post - convergence ( yielding @xmath104 ) .",
    "the value of @xmath28 is given as a function of @xmath29 in fig .",
    "[ fig:10destimator ] .     as a function of the value of @xmath29 ( in units of the standard deviation of the marginalized distribution ) for the product of ten - dimensional correlated gauss functions.,width=340 ]",
    "the arithmetic mean calculation was performed at each of @xmath105 values of @xmath29 as in the one - dimensional case , with @xmath106 samples in each ame run .",
    "the results are shown in fig .",
    "[ fig : evidence10d ] .",
    "as is seen , for values of @xmath29 around @xmath107 , the uncertainty is about 1  % .",
    "the method does not show any systematic biases for @xmath108 , and the estimated uncertainty is again a good estimator for the error . at small @xmath29 , where a small number of mcmc samples are used",
    ", the correlation between the mcmc samples produces some systematic errors in the evaluation of @xmath27 .     as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty .",
    ", title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty .",
    ", title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty .",
    ", title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty .",
    ", title=\"fig:\",width=264 ]    the results for the hme estimator are also shown in fig .  [",
    "fig : evidence10d ] .",
    "we see that accuracies of a few tens of % are achieved , but only in a narrow @xmath29 range . for @xmath109 ,",
    "the error is more than @xmath110  % and the hme estimate is no longer useful .",
    "also , the estimated uncertainty is too low and does not provide a reliable estimate of the true error .",
    "the hme method is clearly already running into trouble at this level of complexity .",
    "the target density is again a multivariate gaussian , and the laplace method works well , yielding @xmath111 .",
    "we now move beyond simple unimodal gaussian type target densities and consider a function in @xmath59 dimensions with degenerate modes lying on a @xmath112 dimensional surface of fixed radius , a gaussian shell : @xmath113 this function is centered at @xmath114 with degenerate modes along a surface of radius @xmath78 .",
    "the value of the function decreases away from the modal surface along a radius according to a gaussian shape with standard deviation @xmath57 .",
    "the integral of this function can be evaluated using spherical coordinates centered at @xmath114 , where @xmath115 is the radial coordinate in the space , so that    @xmath116    the volume element , integrated over the angular coordinates , is @xmath117 with @xmath118 , so that we have    @xmath119    we are left with a one - dimensional integral that can be easily calculated numerically to high precision .",
    "note that we have assumed that the integral in the region outside @xmath120 ( the corners in the hypercube ) is vanishingly small .",
    "this is the case for the examples considered in this article .",
    "for the three examples below , we use the following settings : radius @xmath121 , width @xmath122 and @xmath123 .",
    "the integration region extends from @xmath124 in each dimension .",
    "the parameter values result in @xmath125 .",
    "we use the bat code to produce @xmath106 mcmc samples from the target density , yielding an effective sample size @xmath126 . the sample distribution from the mcmc as well as the estimate of @xmath28 as a function of @xmath29",
    "are shown in fig .",
    "[ fig:2dshell ] .",
    "standard deviation ranges .",
    "right ) fraction of mcmc samples falling within the hypercube of side length @xmath127 as a function of the value of @xmath29 ( in units of the standard deviation of the distribution).,title=\"fig:\",width=264 ]   standard deviation ranges .",
    "right ) fraction of mcmc samples falling within the hypercube of side length @xmath127 as a function of the value of @xmath29 ( in units of the standard deviation of the distribution).,title=\"fig:\",width=264 ]    as can be seen in the figure , the mcmc has produced a reasonable sample distribution .",
    "the location of the mode from the posterior samples happens to be close to @xmath128 and is indicated in the figure ( note that @xmath129 in the figure ) .",
    "the lack of a single mode is not a problem for the ame and hme algorithms , but we no longer expect the laplace method to give sensible results .",
    "the mean values of @xmath130 are very close to @xmath131 and the standard deviation in each direction is about @xmath73 units .",
    "the hypercube centered at the mode found from the mcmc samples and with @xmath74 contains about @xmath132  % of the samples , and the hypercube with @xmath75 contains about @xmath133  % of the samples .",
    "we again use @xmath106 samples for our sample mean calculations at each of the values of @xmath29 .",
    "the results for @xmath77 are shown in the top plots in fig .",
    "[ fig : evidence2dshell ] , and we see that there is no difficulty in achieving a good result for the integral despite not having a simple mode for the target distribution .",
    "the accuracy of the calculation is good , and the uncertainty is better than 1  % for a wide range of @xmath29 , despite the rather small number of samples in the mcmc and ame calculations .",
    "we again find that our estimated uncertainty gives a good reproduction of the actual error .",
    "the hme evaluations are also given in figs .",
    "[ fig : evidence2dshell ] . here",
    "we find good performance ( few  % level accuracy ) up to @xmath75 , at which point the hme calculation starts to systematically deviate from the correct value . in this case , the estimated uncertainty does not give a reliable indication of the actual error for @xmath109 and in fact the uncertainty is grossly underestimated .",
    "this is a result of the missing mcmc samples at very small @xmath134 .",
    "the volume term in the numerator in eq .  [ eq : hme ] grows as @xmath29 is increased , but is not properly compensated by large terms that should appear in the denominator from small values of @xmath134 .",
    "the inability to diagnose this behavior implies that the hme is unreliable .     as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty.,title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty.,title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty.,title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty.,title=\"fig:\",width=264 ]    as expected , the laplace method does not work for the gaussian shell situation .",
    "for the two - dimensional example considered here , @xmath135 .      here",
    "in a first calculation , we use the bat code to produce @xmath106 mcmc samples from the target density , yielding an effective sample size @xmath137 and calculate the evidence .",
    "we again use @xmath106 samples for our sample mean calculations .",
    "the results for the ame and hme evaluations are given in fig .",
    "[ fig : evidence10dshell ] . for the arithmetic mean calculation",
    ", we see the same pattern as in the previous examples . for small values of @xmath29 , the uncertainty coming from the small number of mcmc samples dominates .",
    "however , sub  % errors are possible for @xmath138 , which corresponds to @xmath139 . as @xmath29 increases",
    ", the uncertainties from the sample mean calculation dominate since we move to regions of the space that do not contain significant probability mass .",
    "the estimated uncertainty is again accurate and can be used as a guide to choose the optimal value of @xmath29 as we discuss below .",
    "the hme estimate achieves few  % accuracy at a somewhat smaller value of @xmath29 than the optimal for the sample mean calculation .",
    "the estimated uncertainty is again tends too small at larger @xmath29 and is not reliable .",
    "as expected , the laplace method does not work well and yields @xmath140 .    as a check that these results are not due to small mcmc sample size",
    ", the calculations were redone for @xmath141 mcmc samples .",
    "the optimal value of @xmath29 changes somewhat for the sample mean calculation , but otherwise all results are basically as before .",
    "the systematic behavior of the @xmath87 is the same as for the smaller mcmc sample size ; no significant improvement in performance was found with the 10 times large mcmc sample size .     as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty.,title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty.,title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty.,title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty.,title=\"fig:\",width=264 ]      as an extreme example , we considered a 50-dimensional gaussian shell . here",
    "the modal surface is a 49-dimensional hypersphere and @xmath142 .",
    "the bat code was used to initially produce @xmath106 mcmc samples from the target density , yielding an effective sample size @xmath137 .",
    "the values of @xmath28 increase rapidly from @xmath143 at @xmath144 to @xmath145 at @xmath146 .",
    "the standard deviations in each dimension is about @xmath147 units , so that @xmath148 approximately covers the full support defined for the function .",
    "the results for the ame and hme evaluations are given in fig .",
    "[ fig : evidence50dshell ] . the best result for the sample",
    "mean calculation gives about @xmath95  % accuracy , whereas the hme calculation is within @xmath110  % of the correct result for a small range of @xmath29 where @xmath28 starts to increase .",
    "we used @xmath106 samples for our sample mean calculations , although this is clearly too small a number for such a large dimensional volume . the error from the sample mean calculation increases rapidly as we increase @xmath29 , and becomes completely unreliable for @xmath109 .",
    "for such a large volume , the vast majority of sample mean evaluations are in regions where the target density is vanishingly small and the uncertainty grossly underestimates the true error . in the next section ,",
    "we discuss a choice of settings for the sample mean calculation and redo the calculation shown here .",
    "as expected , the laplace method does not work well and yields @xmath149 .",
    "we again checked that these results are not due to small mcmc sample size , the calculations were redone for @xmath150 mcmc samples .",
    "the optimal location of @xmath29 changes to smaller values for the sample mean calculation and few  % level accuracy is reached . for the hme calculation , a small improvement is also observed , but otherwise all results are basically as before .     as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty .",
    ", title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty .",
    ", title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty .",
    ", title=\"fig:\",width=264 ]   as a function of @xmath29 , scaled by the true value .",
    "top right ) the actual error @xmath79 ( red ) , the estimated uncertainty from the sample mean calculation ( black ) and the total estimated uncertainty ( blue ) as a function of @xmath29 .",
    "bottom left ) @xmath84 scaled by the true value as a function of @xmath29 .",
    "bottom right ) the actual error @xmath87 and the estimated uncertainty as a function of @xmath29 .",
    "the error bars in the left plots correspond to the estimated uncertainty .",
    ", title=\"fig:\",width=264 ]",
    "based on the results in the previous sections , we discuss now a procedure for choosing the value of @xmath29 for both the sample mean and harmonic mean estimators .",
    "as was seen in our examples , the uncertainty in the calculation for the ame estimator comes from two sources - the approximately binomial fluctuations in the number of mcmc samples included in our region of interest specified by @xmath29 , and the uncertainty coming from the sample mean calculation .",
    "the first uncertainty can be estimated from the mcmc output , and can be used to define a value of @xmath28 by specifying that this source of uncertainty should contribute half of the final uncertainty .",
    "i.e. , we find the value of @xmath28 such that ( see eq .",
    "[ eq : uncertainty ] ) @xmath151 where @xmath152 is the target uncertainty .",
    "we will use @xmath153 for our discussion below except for the fifty - dimensional gaussian shell example , where we take @xmath154 .",
    "once we have fixed @xmath28 in this way , we then find the corresponding value of @xmath29 and use this to calculate sample mean integrals with for a batch of samples , requiring a minimum of @xmath95 batches .",
    "we use the variance of these @xmath95 calculations to determine how many batches will be needed to get the desired uncertainty ; i.e. , @xmath155 the results for the examples given in the previous sections using this procedure for fixing the parameters of the algorithm is given in table  [ tab : summary ] .",
    "as is seen , the range of values for @xmath29 is relatively narrow and only grows slowly with the complexity of the target function .",
    "the number of sample mean calculations however depends strongly on the complexity of the problem , and is also inversely dependent on the accuracy specified and on the size of the mcmc sample . for a given specified accuracy",
    ", @xmath29 is reduced as @xmath156 is increased , and this reduces the number of sample mean calculations necessary .",
    "we find that the ame algorithm gives a reliable estimate of the uncertainty for the examples chosen if the required number of sample mean calculations is not too large .",
    "we conclude that the ame calculation of the integral of the target density using a reduced volume around the mode of the target works well for the types of cases we have studied .",
    ".summary of the results on different target functions for the ame estimator of the normalizing integral .",
    "@xmath156 is the number of posterior samples from the mcmc , @xmath157 is the effective sample size , @xmath152 is the specified accuracy for the integral calculation , @xmath29 is the multiplier of the standard deviation along each dimension chosen by the algorithm , @xmath32 is the number of samplings of the function used in the sample mean calculation , @xmath85 is the true value of the integral , @xmath158 is the fractional error made in the calculation and @xmath159 is the estimated fractional uncertainty from the calculation . [",
    "cols=\"^,^,^,^,^,>,<,^,^\",options=\"header \" , ]     as can be seen from the table , and as discussed earlier , the hme calculation works well for the simple target functions considered , but does not produce good results for the more complicated target functions . in particular , the estimated uncertainty does not provide a good estimate of the actual error , so that it is not possible to diagnose that the calcuclation is not performing well .",
    "we therefore do not recommend the use of the hme estimator to calculate the normalization integral for anything but the simplest low - dimensional target densities ,    the laplace estimation works well in cases where the target density is well approximated by a ( multivariate ) gaussian distribution .",
    "if this is known to be the case , then this approximation is easily calculated and can be used .",
    "however , it should be avoided if the shape of the target distribution is not well known .",
    "we have investigated techniques for the integration of the target density in cases where a mcmc algorithm has successfully run . we do not attempt to modify the sampling of the target density , but only to provide a post - processor for an mcmc algorithm . from the mcmc",
    ", we have an estimate of the global mode and also the variance of the samples marginalized along each parameter dimension .",
    "we use this information to define a hypercube centered on the global model and having side lengths proportional to the standard deviation along these directions , and then calculate the integral of the target function in the reduced volume using either an arithmetic mean or harmonic mean approach .",
    "the fraction of mcmc samples within the reduced volume was used to estimate the integral of the target density over the full volume of interest .",
    "this technique was tried on a variety of examples and also compared to a laplace estimator .",
    "the key elements of the methods studied are :    * given the mcmc has been run successfully , the evaluation of the normalization of the target function can be performed using any sub support of the support of the target function ; * from the mcmc , we can find a point near the maximum of the target function , and we can perform the integration in a region which is in some ways optimal by centering the sub support on this point ; * it is possible to also calculate an estimated accuracy for the integral .",
    "our conclusions are that the arithmetic mean calculation performed in a hypercube centered on the observed mode works well and provides a technique for calculating the normalization of the target density with a reliable uncertainty estimate . on the other hand , the harmonic mean estimator only works well in situations where the range of values from the target density does not vary too widely , and",
    "the laplace estimator is restricted for use on gaussian shaped target distributions .",
    "the authors would like to thank frederik beaujean , daniel greenwald , stephan jahn and kevin krninger for many fruitful discussions .",
    "9 see e.g. , c. robert and g. casella , ` monte carlo statistical methods ' , 2@xmath160 edition , springer ( 2004 ) . h. jeffreys , ` theory of probability ' , 3@xmath161 ed .",
    ", claredon press , oxford , mr0187257 ( 1961 ) .",
    "e. t. jaynes , ` probability theory : the logic of science ' , cambridge university press , cambridge , mr1992316 ( 2003 ) .",
    "d. n. vanderwerken , s. c. schmidler , ` parallel markov chain monte carlo ' , arxiv:1312.7479v1 n. friel and j. wyse , ` estimating the evidence - a review ' , stat .",
    "* 66 * ( 2012 ) 2800 .",
    "l. tierney and j. b. kadane , ` accurate approximations for posterior moments and marginal densities ' , journal of the american statistical associations , * 81 * ( 1986 ) 82 .",
    "m. a. newton and a. e. raftery , ` approximate bayesian inference with the weighted likelihood bootstrap ' , journal of the royal statistical society , series b*56 * ( 1994 ) 3 .",
    "s. chib , i. jeliazkov , ` marginal likelihood from the metropolis - hastings output ' , journal of the american statistical association * 96 * ( 2001 ) 270 .",
    "c. p. robert and d. wraith , ` computational methods for bayesian model choice ' , bayesian inference and maximum entropy methods in science and engineering : the 29@xmath162 international workshop on bayesian inference and maximum entropy methods in science and engineering ( aip conference proceedings ) , vol . 1193 ( 2009 ) 251 .",
    "j. skilling , ` nested sampling for general bayesian computation ' , bayesian analysis * 1 * ( 2006 ) 833 .",
    "a. gelman and x. l. meng , ` simulating normalizing constants : from importance sampling to bridge sampling to path sampling ' , statistical science * 13 * ( 1998 ) 163 .",
    "n. friel and a. n. pettitt , ` marginal likelihood estimation via power posteriors ' , journal of the royal statistical society , series b*70 * ( 2008 ) 589 .",
    "a. caldwell , d. kollar , k. krninger , ` bat - the bayesian analysis toolkit ' , comput .",
    "commun . 180",
    "( 2009 ) 2197 - 2209 .",
    "r. e. kass , b. p. carlin , a. gelman , and r. neal , ` markov chain monte carlo in practice : a roundtable discussion ' , the american statistician , * 52 * ( 1998 ) 93 .",
    "a. e. gelfand and d. k. dey , ` bayesian model choice : asymptotics and exact calculations ' , journal of the royal statistical society , b * 56 * ( 1994 ) 501 - 514 ."
  ],
  "abstract_text": [
    "<S> techniques for evaluating the normalization integral of the target density for markov chain monte carlo algorithms are described and tested numerically . </S>",
    "<S> it is assumed that the markov chain algorithm has converged to the target distribution and produced a set of samples from the density . </S>",
    "<S> these are used to evaluate sample mean , harmonic mean and laplace algorithms for the calculation of the integral of the target density </S>",
    "<S> . a clear preference for the sample mean algorithm applied to a reduced support region is found , and guidelines are given for implementation . </S>"
  ]
}