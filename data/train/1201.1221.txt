{
  "article_text": [
    "the clustering we use is hierarchical clustering in dendrograms based on a new fast heuristic for the quartet method @xcite .",
    "if we consider @xmath1 objects , then we find @xmath2 pairwise distances .",
    "these distances are between natural data .",
    "we let the data decide for themselves , and construct a hierarchical clustering of the @xmath1 objects concerned . for details",
    "see the cited reference .",
    "the method takes the @xmath3 distance matrix as input , and yields a dendrogram with the @xmath1 objects as leaves ( so the dendrogram contains @xmath1 external nodes or leaves and @xmath4 internal nodes .",
    "we assume @xmath5 .",
    "the method is available as an open - source software tool , @xcite .",
    "our aim is to capture , in a single similarity metric , _ every effective distance _ : effective versions of hamming distance , euclidean distance , edit distances , alignment distance , lempel - ziv distance , and so on .",
    "this metric should be so general that it works in every domain : music , text , literature , programs , genomes , executables , natural language determination , equally and simultaneously",
    ". it would be able to simultaneously detect _ all _ similarities between pieces that other effective distances can detect seperately .",
    "such a `` universal '' metric was co - developed by us as a normalized version of the `` information metric '' of @xcite .",
    "there it was shown that the information metric minorizes up to a constant all effective distances satisfying a mild density requirement ( excluding for example distances that are 1 for every pair @xmath6 such that @xmath7 ) .",
    "this justifies the notion that the information distance is universal",
    ".    we may be interested what happens in terms of properties or features of the pair of objects analyzed , say @xmath8 and @xmath9 .",
    "it can be shown that the information distance captures every property of which the kolmogorov complexity is logarithmic in the length of @xmath10 .",
    "if those lengths go to infinity , then logarithm of those lengths go to infinity too . in this case",
    "the information distance captures every property .",
    "this information distance ( actually a metric up to minor additive terms ) is normalized so that the resulting distances are in @xmath11 $ ] and can be shown to retain the metric property , @xcite .",
    "the result is the `` normalized information distance '' ( actually a metric up to neglidgible terms ) .",
    "all this is in terms of kolmogorov complexity @xcite .",
    "it articulates the intuition that two objects are deemed close if we can significantly `` compress '' one given the information in the other , that is , two pieces are more similar if we can more succinctly describe one given the other .",
    "the normalized information distance discovers all effective similarities in the sense that if two objects are close according to some effective similarity , then they are also close according to the normalized information distance .",
    "put differently , the normalized information distance represents similarity according to the dominating shared feature between the two objects being compared . in comparisons of more than two objects , different pairs may have different dominating features .",
    "for every two objects , this normalized information metric distance zooms in on the dominant similarity between those two objects out of a wide class of admissible similarity features .",
    "since the normalized information distance also satisfies the metric ( in)equalities , and takes values in @xmath11 $ ] , it may be called _",
    "`` the '' similarity metric_.    unfortunately , the universality of the normalized information distance comes at the price of noncomputability .",
    "recently we have shown that the normalized information distance is not even semicomputable ( this is weaker than computable ) and there is no semicomputable function at a computable distance of it @xcite .",
    "since the kolmogorov complexity of a string or file is the length of the ultimate compressed version of that file , we can use real data compression programs to approximate the kolmogorov complexity .",
    "therefore , to apply this ideal precise mathematical theory in real life , we have to replace the use of the noncomputable kolmogorov complexity by an approximation using a standard real - world compressor .",
    "starting from the normalized information distance , if @xmath12 is a compressor and we use @xmath13 to denote the length of the compressed version of a string @xmath8 , then we arrive at the _ normalized compression distance _ : @xmath14 where for convenience we have replaced the pair @xmath15 in the formula by the concatenation @xmath16 , and we ignore logarithmic terms in the numerator and denominator , see @xcite . in @xcite",
    "we propose axioms to capture the real - world setting , and show that approximates optimality . actually , the ncd is a family of compression functions parameterized by the given data compressor @xmath12 .      to make computers more intelligent",
    "one would like to represent meaning in computer - digestable form .",
    "long - term and labor - intensive efforts like the _ cyc _ project @xcite and the _ wordnet _ project @xcite try to establish semantic relations between common objects , or , more precisely , _",
    "names _ for those objects .",
    "the idea is to create a semantic web of such vast proportions that rudimentary intelligence and knowledge about the real world spontaneously emerges .",
    "this comes at the great cost of designing structures capable of manipulating knowledge , and entering high quality contents in these structures by knowledgeable human experts . while the efforts are long - running and large scale ,",
    "the overall information entered is minute compared to what is available on the internet .",
    "the rise of the internet has enticed millions of users to type in trillions of characters to create billions of web pages of on average low quality contents .",
    "the sheer mass of the information available about almost every conceivable topic makes it likely that extremes will cancel and the majority or average is meaningful in a low - quality approximate sense .",
    "below , we give a general method to tap the amorphous low - grade knowledge available for free on the internet , typed in by local users aiming at personal gratification of diverse objectives , and yet globally achieving what is effectively the largest semantic electronic database in the world .",
    "moreover , this database is available for all by using any search engine that can return aggregate page - count estimates like google for a large range of search - queries .",
    "while the previous ncd method that compares the objects themselves using is particularly suited to obtain knowledge about the similarity of objects themselves , irrespective of common beliefs about such similarities , we now develop a method that uses only the name of an object and obtains knowledge about the similarity of objects by tapping available information generated by multitudes of web users .",
    "the new method is useful to extract knowledge from a given corpus of knowledge , in this case the pages on the internet accessed by a search engine returning aggregate page counts , but not to obtain true facts that are not common knowledge in that database .",
    "for example , common viewpoints on the creation myths in different religions may be extracted by the web - based method , but contentious questions of fact concerning the phylogeny of species can be better approached by using the genomes of these species , rather than by opinion .",
    "this approach was proposed by @xcite .",
    "we skip the theory .",
    "in contrast to strings @xmath8 where the complexity @xmath13 represents the length of the compressed version of @xmath8 using compressor @xmath12 , for a search term @xmath8 ( just the name for an object rather than the object itself ) , the code of length @xmath17 represents the shortest expected prefix - code word length of the event @xmath18 ( the number of pages of the internet returned by a given search engine ) . the associated _ normalized web distance _ ( nwd ) is defined just as with the search engine in the role of compressor yielding code lengths @xmath19 for the singleton search terms @xmath6 being compaired and a code length @xmath20 for the doubleton pair @xmath15 , by @xmath21 this @xmath22 uses the background knowledge on the web as viewed by the search engine as conditional information .",
    "the same formula as can be written in terms of frequencies of the number of pages returned on a search query as @xmath23 and if @xmath24 and @xmath25 then @xmath26 .",
    "it is easy to see that    1 .",
    "@xmath27 is undefined for @xmath28 ; 2 .",
    "@xmath29 for @xmath25 and either or both @xmath30 and @xmath31 ; and 3 .",
    "@xmath32 otherwise .",
    "the number @xmath33 is related to the number of pages @xmath34 indexed by the search engine we use .",
    "our experimental results suggest that every reasonable ( greater than any @xmath35 ) value can be used for the normalizing factor @xmath33 , and our results seem in general insensitive to this choice . in our software",
    ", this parameter @xmath33 can be adjusted as appropriate , and we often use @xmath34 for @xmath33 . in the @xcite",
    "we analyze the mathematical properties of nwd , and prove the universality of the search engine distribution .",
    "we show that the nwd is not a metric , in contrast to the ncd .",
    "the generic example showing the nonmetricity of semantics ( and therefore the nwd ) is that a man is close to a centaur , and a centaur is close to a horse , but a man is very different from a horse .",
    "a typical procedure for finding an answer on the internet consists in entering some terms regarding the question into a web search engine and then browsing the search results in search for the answer .",
    "this is particularly inconvenient when one uses a mobile device with a slow internet connection and small display .",
    "question - answer ( qa ) systems attempt to solve this problem .",
    "they allow the user to enter a question in natural language and generate an answer by searching the web autonomously .",
    "the qa system quanta @xcite that uses variants of the ncd and the nwd to identify the correct answer to a question out of several candidates for answers .",
    "quanta is remarkable in that it uses neither ncd nor nwd introduced so far , but a variation that is nevertheless based on the same theoretical principles .",
    "this variation is tuned to the particular needs of a qa system . without going in too much detail",
    "it uses the maximal overlap of program @xmath36 going from file @xmath8 to file @xmath9 , and program @xmath37 going from file @xmath9 to file @xmath8 .",
    "the system quanta is 1.5 times better ( according to generally used measures ) than its competition .",
    "in many applications we are interested in shared information between _ many _ objects instead of just a pair of objects . for example , in customer reviews of gadgets , in blogs about public happenings , in newspaper articles about the same occurrence , we are interested in the most comprehensive one or the most specialized one .",
    "thus , we want to extend the information distance measure from pairs to multiples .",
    "this approach was introduced in @xcite while most of the theory is developed in @xcite .",
    "let @xmath39 denote a finite list of @xmath40 finite binary strings defined by @xmath41 , the constituting strings ordered length - increasing lexicographic .",
    "we use lists and not sets , since if @xmath39 is a set we can not express simply the distance from a string to itself or between strings that are all equal .",
    "let @xmath42 be the reference universal turing machine .",
    "given the string @xmath43 we define the information distance to any string in @xmath39 by @xmath44 for all @xmath45}. it is shown in @xcite , theorem 2 , that @xmath46 up to a logarithmic additive term .",
    "define @xmath47 .",
    "theorem 3 in @xcite states that for every list @xmath48 we have @xmath49 up to a logarithmic additive term .",
    "this is not a corollary of as stated in @xcite , but both inequalities follow from the definitions .",
    "the lefthand side is interpreted as the program length of the `` most comprehensive object that contains the most information about all the others [ all elements of @xmath39 ] , '' and the righthand side is interpreted as the program length of the `` most specialized object that is similar to all the others . ''",
    "information distance for multiples , that is , finite lists , appears both practically and theoretically promising .",
    "the results below appear in @xcite . in all cases",
    "the results imply the corresponding ones for the pairwise information distance defined as follows .",
    "the information distance in @xcite between strings @xmath51 and @xmath52 is @xmath53 . in the @xcite @xmath54 .",
    "these two definitions coincide for @xmath55 since @xmath56 up to an additive constant term . the reference investigate the maximal overlap of information which for @xmath55 specializes to theorem 3.4 in @xcite .",
    "a corollary in @xcite shows and another corollary shows that the lefthand side of can indeed be taken to correspond to a single program embodying the `` most comprehensive object that contains the most information about all the others '' as stated but not argued or proved in @xcite .",
    "the reference proves metricity and universality which for @xmath57 ( for metricity ) and @xmath55 ( for universality ) specialize to theorem 4.2 in @xcite ; additivity ; minimum overlap of information which for @xmath55 specializes to theorem 8.3.7 in @xcite ; and the nonmetricity of normalized information distance for lists of more than two elements and the failure of certain proposals of a normalizing factor ( to achieve a normalized version ) . in contrast , for lists of two elements we can normalize the information distance as in lemma v.4 and theorem v.7 of @xcite .",
    "the definitions are of necessity new as are the proof ideas",
    ". remarkably , the new notation and proofs for the general case are simpler than the mentioned existing proofs for the particular case of pairwise information distance .",
    "by now applications abound . see the many references to the papers @xcite in google scholar .",
    "the methods turns out to be more - or - less robust under change of the underlying compressor - types : statistical ( ppmz ) , lempel - ziv based dictionary ( gzip ) , block based ( bzip2 ) , or special purpose ( gencompress ) .",
    "obviously the window size matters , as well as how good the compressor is .",
    "for example , ppmz gives for mtdna of the investigated species diagonal elements ( @xmath58 ) between 0.002 and 0.006 .",
    "the compressor bzip2 does considerably worse , and gzip gives something in between 0.5 and 1 on the diagonal elements .",
    "nonetheless , for texts like books gzip does fine in our experiments ; the window size is sufficient and we do not use the diagonal elements .",
    "but for genomics gzip is no good ."
  ],
  "abstract_text": [
    "<S> in pattern recognition , learning , and data mining one obtains information from information - carrying objects . </S>",
    "<S> this involves an objective definition of the information in a single object , the information to go from one object to another object in a pair of objects , the information to go from one object to any other object in a multiple of objects , and the shared information between objects . </S>",
    "<S> this is called `` information distance . '' </S>",
    "<S> we survey a selection of new developments in information distance . </S>"
  ]
}