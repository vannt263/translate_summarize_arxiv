{
  "article_text": [
    "algorithmic probability has first been studied in the 1960s by solomonoff , levin , chaitin and others ( cf .",
    "@xcite , @xcite , @xcite ) , it has revealed a variety of interesting properties , including applications in computer science , inductive inference and statistical mechanics ( cf .",
    "@xcite , @xcite , @xcite ) .",
    "the algorithmic probability of a binary string @xmath0 is defined as the probability that a universal prefix computer @xmath1 outputs @xmath0 on random input , i.e. @xmath2 where @xmath3 denotes the length of a binary string @xmath4 .",
    "it follows from the kraft inequality that @xmath5 where @xmath6 is chaitin s famous halting probability .",
    "so algorithmic probability is a subnormalized probability distribution or semimeasure on the binary strings .",
    "it is closely related to prefix kolmogorov complexity @xmath7 which is defined  @xcite as the length of the shortest computer program that outputs @xmath0 : @xmath8 the relation between the two can be written as @xmath9 where the @xmath10-term denotes equality up to an additive constant .",
    "both kolmogorov complexity and algorithmic probability depend on the choice of the universal reference computer @xmath1 . however",
    ", they do not depend on @xmath1 `` too much '' : if @xmath1 and @xmath11 are both universal prefix computers , then it follows from the fact that one can emulate the other that @xmath12 i.e. the complexities @xmath13 and @xmath14 differ from each other only up to an additive constant .",
    "then equation  ( [ eqrelkp ] ) shows that the corresponding algorithmic probabilities differ only up to a multiplicative constant .",
    "this kind of `` weak '' machine independence is good enough for many applications : if the strings are long enough , then a fixed additive constant does not matter too much . however , there are many occasions where it would be desirable to get rid of those additive constants , and to eliminate the arbitrariness which comes from the choice of the universal reference computer .",
    "examples are artificial intelligence  @xcite and physics  @xcite , where one often deals with finite and short binary strings .",
    "we start with a simple example , to show that the machine - dependence of algorithmic probability can be drastic , and also to illustrate the main idea of our approach .",
    "suppose that @xmath15 is a `` natural '' universal prefix computer , say , one which is given by a turing machine model that we might judge as `` simple '' .",
    "now choose an arbitrary strings @xmath0 consisting of a million random bits ; say , @xmath0 is attained by a million tosses of a fair coin . with high probability , there is no short program for @xmath15 which computes @xmath0 ( otherwise toss the coin again and use a different string @xmath0 ) .",
    "we thus expect that @xmath16 now we define another prefix computer @xmath17 as @xmath18 the computer @xmath17 is universal , since it emulates the universal computer @xmath19 if we just prepend a `` 1 '' to the input . since @xmath20 , we have @xmath21 hence the algorithmic probability @xmath22 depends drastically on the choice of the universal computer @xmath1 . clearly , the computer @xmath17 seems quite unnatural , but in algorithmic information theory , all the universal computers are created equal  there is no obvious way to distinguish between them and to say which one of them is a `` better choice '' than the other .",
    "so what _ is _ `` the '' algorithmic probability of the single string @xmath0 ?",
    "it seems clear that @xmath23 is a better answer than @xmath24 , but the question is how we can make mathematical sense of this statement .",
    "how can we give a sound formal meaning to the statement that @xmath19 is more `` natural '' than @xmath17 ?",
    "a possible answer is that in the process of randomly constructing a computer from scratch , one is very unlikely to end up with @xmath17 , while there is some larger probability to encounter @xmath19 .",
    "this suggests that we might hope to find some natural probability distribution @xmath25 on the universal computers , in such a way that @xmath26 .",
    "then we could define the `` machine - independent '' algorithmic probability @xmath27 of some string @xmath0 as the weighted average of all algorithmic probabilities @xmath22 , @xmath28 guided by equation  ( [ eqrelkp ] ) , we could then define `` machine - independent kolmogorov complexity '' via @xmath29 .    but",
    "how can we find such a probability distribution @xmath25 on the computers ?",
    "the key idea here is to compare the capabilities of the two computers to emulate each other .",
    "namely , by comparing @xmath19 and @xmath17 , one observes that    * it is very `` easy '' for the computer @xmath17 to emulate the computer @xmath19 : just prepend a `` 1 '' to the input . on the other hand ,",
    "* it is very `` difficult '' for the computer @xmath19 to emulate @xmath17 : to do the simulation , we have to supply @xmath19 with the long string @xmath0 as additional data .",
    "( 0,2.5)(12.3,9 ) ( 3,5.2)@xmath19 ( 3,5.2)2.2 ( 12,5.2)@xmath17 ( 12,5.2)2.2 ( 4.2,7)(7.5,8.5)(10.5,7 ) ( 0,0 ) ( 4.5,3.5)(7.5,2)(10.8,3.5 ) ( 8,9.3)difficult ( 7.5,2.8)easy    the idea is that this observation holds true more generally : _",
    "`` unnatural '' computers are harder to emulate .",
    "_ there are two obvious approaches to construct some computer probability @xmath25 from this observation  interestingly , both turn out to be equivalent :    * the situation in figure  [ figeasydiff ] looks like the graph of some markov process . if one starts with either one of the two computers depicted there and interprets the line widths as transition probabilities , then in the long run of more and more moves , one tends to have larger probability to end up at @xmath19 than at @xmath17 .",
    "so let s apply this idea more generally and define a markov process of all the universal computers , randomly emulating each other .",
    "if the process has a stationary distribution ( e.g. if it is positive recurrent ) , this is a good candidate for computer probability . * similarly as in equation  ( [ eqdefap ] ) , there should be a simple way to define probabilities @xmath30 for computers @xmath1 and @xmath11 , that is , the probability that @xmath1 emulates @xmath11 on random input .",
    "then , whatever the desired computer probability @xmath25 looks like , to make any sense , it should satisfy @xmath31 but if we enumerate all universal computers as @xmath32 , this equation can be written as @xmath33 thus , we should look for the unknown stationary probability eigenvector @xmath34 of the `` emulation matrix '' @xmath35",
    ".    clearly , both ideas are equivalent if the probabilities @xmath30 are the transition probabilities of the aforementioned markov process .",
    "now we give a synopsis of the paper and explain our main results:[synopsislabel ]    * section  [ secpreliminaries ] contains some notational preliminaries , and defines the _ output frequency _ of a string as the frequency that this string is output by a computer . for prefix computers",
    ", this notion equals algorithmic probability ( example  [ exprefix ] ) . * in section  [ secstationarycomputerprobability ]",
    ", we define the emulation markov process that we have motivated above , and analyze if it has a stationary distribution or not .",
    "here is the construction for the most important case ( the case of the full set of computers ) in a nutshell : we say that a computer @xmath36 _ emulates _",
    "computer @xmath37 via the string @xmath38 , and write @xmath39 and @xmath40 if @xmath41 for all strings @xmath42 .",
    "a computer is _ universal _ if it emulates every other computer .",
    "given a universal computer , at least one of the two computers @xmath43 and @xmath44 must be universal , too .",
    "+ thus , we can consider the universal computers as the vertices of a graph , with directed edges going from @xmath1 to @xmath11 if @xmath45 or @xmath46 .",
    "every vertex ( universal computer ) has either one or two outgoing edges ( corresponding to the two bits ) .",
    "the random walk on this connected graph defines a markov process : we start at some computer , follow the outgoing edges , and if there are two edges , we follow each of them with probability @xmath24 .",
    "this is schematically depicted in figure  [ figemulationmarkovprocess ] .",
    "+ ( -1,-1.5)(11,11 ) + ( 5,5)1 ( 5,5)@xmath47 ( 10,6)1 ( 10,6)@xmath48 ( 7,9)1 ( 7,9)@xmath49 ( 4,1)1 ( 4,1)@xmath50 ( 8.5,1.5)1 ( 8.5,1.5)@xmath51 ( 0.5,6)1 ( 0.5,6)@xmath52 ( 5.7,5.7)(12,10 ) ( 4.8,5.9)(4,10 ) ( 4.4,5.6)(1,10 ) ( 5.9,5.2)(9,6 ) ( 7.5,6)@xmath53 ( 5.6,4.4)(7.8,2.2 ) ( 7,3.5)@xmath54 + ( 10.8,6.5)(13.5,8 ) ( 11.6,7.5)@xmath54 ( 10.8,5.5)(13.5,4 ) ( 11.6,4.5)@xmath53 + ( 9.4,1.5)(13.5,1.5 ) ( 11,2)@xmath53 ( 7.6,1.5)(4.95,1.1 ) ( 6.5,0.8)@xmath54 ( 8.2,0.6)(7.1,-1.2 ) ( 8.5,0.5)(8.5,-1.2 ) ( 8.8,0.6)(9.9,-1.2 ) + ( 3.5,1.8)(2.5,5)(6.2,8.6 ) ( 3.3,3)@xmath53 ( 3.3,1.6)(1.1,5.2 ) ( 2.4,2.4)@xmath54 ( 4.7,0.4)(6,-1.2 ) ( 3.9,0.1)(3.6,-1.2 ) ( 3.2,0.6)(0,-1.2 ) + ( 1.4,5.8)(4.1,5.1 ) ( 2.2,6)@xmath54 ( -0.5,6)(-2.5,6 ) ( -1,6.5)@xmath53 ( 0,5.2)(-2.5,3 ) + ( 6.4,9.65)(5.5,11 ) ( 5.8,9.9)@xmath53 ( 7,10)(7,11 ) ( 7.6,9.65)(8.5,11 ) ( 8.2,9.9)@xmath54 + if this process had a stationary distribution , this would be a good candidate for a natural algorithmic probability measure on the universal computers .",
    "unfortunately , no stationary distribution exists : this markov process is transient .",
    "+ we prove this in theorem  [ themarkoffchaney ] .",
    "the idea is to construct a sequence of universal computers @xmath55 such that @xmath56 emulates @xmath57 with high probability  in fact , with probability turning to @xmath58 fast as @xmath59 gets large .",
    "the corresponding part of the emulation markov process is depicted in figure  [ figvirus ] .",
    "the outgoing edges in the upwards direction lead back to a fixed universal reference computer , which ensures that every computer @xmath56 is universal .",
    "+ ( 0,4)(15,8 ) ( 0,5)1 ( 0,5)@xmath60 ( 4,5)1 ( 4,5)@xmath61 ( 8,5)1 ( 8,5)@xmath62 ( 12,5)1 ( 12,5)@xmath63 ( 0.9,5)(3.1,5 ) ( 4.9,5)(7.1,5 ) ( 8.9,5)(11.1,5 ) ( 12.9,5)(15.1,5 ) ( 1.8,5.7)@xmath24 ( 5.8,5.7)@xmath64 ( 9.8,5.7)@xmath65 ( 13.8,5.7)@xmath66 ( 16,4.5)@xmath67 ( 0.4,5.9)(3,8 ) ( 4.4,5.9)(7,8 ) ( 8.4,5.9)(11,8 ) ( 12.4,5.9)(15,8 ) ( 1.4,7.6)@xmath24 ( 5.4,7.6)@xmath68 ( 9.4,7.6)@xmath69 ( 13.4,7.6)@xmath70 + as our markov process has only transition probabilities @xmath24 and @xmath58 , the edges going from @xmath56 to @xmath57 in fact consist of several transitions ( edges ) . as those transition probabilities are constructed to tend to @xmath58 very fast , the probability to stay on this @xmath56-path forever ( and not return to any other computer ) is positive , which forces the process to be transient . + yet , it is still possible to construct analogous markov processes for restricted sets of computers @xmath71 . some of those sets yield processes which have stationary distributions ;",
    "a non - trivial example is given in example  [ exposrecurrent ] .",
    "* for those computer sets @xmath71 with positive recurrent emulation process , the corresponding computer probability has nice properties that we study in section  [ secsymmetries ] .",
    "the computer probability induces in a natural way a probability distribution on the strings @xmath72 ( definition  [ defstringprobability ] ) as the probability that the random walk described above encounters some output which equals @xmath0 .",
    "this probability is computer - independent and can be written in several equivalent ways ( theorem  [ thestatalgsp ] ) . *",
    "a symmetry property of computer probability yields another simple and interesting proof why for the set of all computers  and for many other natural computer sets  the corresponding markov process can not be positive recurrent ( theorem  [ theposrecsym ] ) . in short , if @xmath73 is a computable permutation , then a computer @xmath36 and the output permuted computer @xmath74 must have the same probability as long as both are in the computer set @xmath71 ( theorem  [ theoutputsym ] ) .",
    "if there are infinitely many of them , they all must have probability zero which contradicts positive recurrence .",
    "* for the same reason , there can not be one particular `` natural '' choice of a computer set @xmath71 with positive recurrent markov process , because @xmath75 is always another good ( positive recurrent ) candidate , too ( theorem  [ thenonuniqueness ] ) .",
    "* this has a nice physical interpretation which we explain in section  [ secconclusions ] : algorithmic probability and kolmogorov complexity always contain at least the ambiguity which is given by permuting the output strings .",
    "this permutation can be interpreted as `` renaming '' the objects that the strings are describing .",
    "we argue that this kind of ambiguity will be present in any attempt to eliminate machine - dependence from algorithmic probability or complexity , even if it is different from the approach in this paper .",
    "this conclusion can be seen as the main result of this work .",
    "finally , we show in the appendix that the string probability that we have constructed equals , under certain conditions , the weighted average of output frequency  this is a particularly unexpected and beautiful result ( theorem  [ theeqdef ] ) which needs some technical steps to be proved .",
    "the main tool is the study of input transformations , i.e. , to permute the strings before the computation .",
    "the appendix is the technically most difficult part of this paper and can be skipped on first reading .",
    "we start by fixing some notation . in this paper",
    ", we only consider _ finite , binary strings _ , which we denote by @xmath76 the symbol @xmath77 denotes the _ empty string _ , and we write the _ length _ of a string @xmath72 as @xmath78 , while the cardinality of a set @xmath79 is denoted @xmath80 . to avoid confusion with the composition of mappings",
    ", we denote the _ concatenation _ of strings with the symbol @xmath81 , e.g. @xmath82 in particular , we have @xmath83 and @xmath84 . a _ computer _",
    "@xmath36 is a partial - recursive function @xmath85 , and we denote the set of all computers by @xmath86 .",
    "note that our computers do not necessarily have to have prefix - free domain ( unless otherwise stated ) .",
    "if @xmath87 does not halt on some input @xmath4 , then we write @xmath88 as an abbreviation for the fact that @xmath89 is undefined .",
    "thus , we can also interpret computers @xmath36 as mappings from @xmath90 to @xmath91 , where @xmath92 as usual , we denote by @xmath93 the _ kolmogorov complexity _ of the string @xmath94 with respect to the computer @xmath87 @xmath95 or as @xmath96 is this set is empty .    what would be a first , naive try to define algorithmic probability ?",
    "since we do not restrict our approach to prefix computers , we can not take equation  ( [ eqdefap ] ) as a definition .",
    "instead we may try to count how often a string is produced by the computer as output :    [ defalgfrequency ]    ' '' ''    for every @xmath87 , @xmath97 and @xmath98 , we set @xmath99 for later use in section  [ secstationarycomputerprobability ] , we also define for every @xmath100 and @xmath97 @xmath101 where the expression @xmath39 is given in definition  [ defemulation ] .",
    "our final definition of algorithmic probability will look very different , but it will surprisingly turn out to be closely related to this output frequency notion .",
    "the existence of the limit @xmath102 depends on the computer @xmath36 and may be hard to decide , but in the special case of prefix computers , the limit exists and agrees with the classical notion of algorithmic probability as given in equation  ( [ eqdefap ] ) :    [ exprefix ] a computer @xmath87 is called _ prefix _ if the following holds : @xmath103 this means that if @xmath36 halts on some input @xmath4 , it must not halt on any extension @xmath104 .",
    "such computers are traditionally studied in algorithmic information theory . to fit our approach",
    ", we need to modify the definition slightly . call a computer @xmath105 _ prefix - constant _",
    "if the following holds true : @xmath106 it is easy to see that for every prefix computer @xmath36 , one can find a prefix - constant computer @xmath107 with @xmath108 whenever @xmath109 .",
    "it is constructed in the following way : suppose @xmath4 is given as input into @xmath107 , then it    * computes the set of all prefixes @xmath110 of @xmath38 ( e.g. for @xmath111 we have @xmath112 , @xmath113 , @xmath114 and @xmath115 ) , * starts @xmath116 simulations of @xmath36 at the same time , which are supplied with @xmath117 up to @xmath118 as input , * waits until one of the simulations produces an output @xmath72 ( if this never happens , @xmath107 will loop forever ) , * finally outputs @xmath0 .",
    "fix an arbitrary string @xmath98 .",
    "consider the set @xmath119 every string @xmath120 can be extended ( by concatenation ) to a string @xmath121 of length @xmath122 . by construction",
    ", it follows that @xmath123 .",
    "there are @xmath124 possible extensions @xmath121 , thus @xmath125 it follows that the limit @xmath126 exists , and it holds @xmath127 so the output frequency as given in definition  [ defalgfrequency ] converges for @xmath128 to the classical algorithmic probability as given in equation  ( [ eqdefap ] ) .",
    "note that @xmath129 .    ' '' ''",
    "@xmath130    it is easy to construct examples of computers which are _ not _ prefix , but which have an output frequency which either converges , or at least does not tend to zero as @xmath128 .",
    "thus , the notion of output frequency generalizes the idea of algorithmic probability to a larger class of computers .",
    "as explained in the introduction , it will be an essential part of this work to analyze in detail how `` easily '' one computer @xmath36 emulates another computer @xmath37 .",
    "our first definition specializes what we mean by `` emulation '' :    [ defemulation ] a computer @xmath87 _ emulates _ the computer @xmath131 via @xmath4 , denoted @xmath132 if @xmath133 for every @xmath72 .",
    "we write @xmath134 if there is some @xmath4 such that @xmath39 .",
    "it follows easily from the definition that @xmath135 and @xmath136    now that we have defined emulation , it is easy to extend the notion of kolmogorov complexity to emulation complexity :    for every @xmath100 , the _ emulation complexity _ @xmath137 is defined as @xmath138 or as @xmath96 if the corresponding set is empty .",
    "note that similar definitions have already appeared in the literature , see for example def .",
    "4.4 and def .",
    "4.5 in  @xcite , or the definition of the constant `` @xmath139 '' in  @xcite .",
    "let @xmath140 be a set of computers .",
    "if there exists a computer @xmath141 such that @xmath142 for every @xmath143 , then @xmath71 is called _ connected _ , and @xmath1 is called a _",
    "@xmath71-universal computer_. we use the notation @xmath144 , and we write @xmath145 .    note that @xmath146 and @xmath147 .",
    "examples of connected sets of computers include the set @xmath86 of all computers and the set of prefix - constant computers , whereas the set of computers which always halt on every input can not be connected , as is easily seen by diagonalization . for convenience ,",
    "we give a short proof of the first statement :    the set of all computers @xmath86 is connected .",
    "* proof . *",
    "it is well - known that there is a computer @xmath1 that takes a description @xmath148 of any computer @xmath149 together with some input @xmath4 and simulates @xmath150 on input @xmath38 , i.e. @xmath151 where @xmath152 is a bijective and computable encoding of two strings into one .",
    "we can construct the encoding in such a way that @xmath153 , i.e. the description is encoded into some prefix code that is appended to the left - hand side of @xmath38 .",
    "it follows that @xmath154 , and since this works for every @xmath149 , @xmath1 is @xmath86-universal .    ' '' ''    @xmath130    here is a basic property of kolmogorov and emulation complexity :    let @xmath140 be connected , then for every @xmath155 and @xmath156 , it holds that @xmath157    * proof . * since @xmath155 , it holds @xmath158 .",
    "let @xmath38 be a shortest string such that @xmath159 for every @xmath160 , i.e. @xmath161 . if @xmath162 resp .",
    "@xmath163 are shortest strings such that @xmath164 resp .",
    "@xmath165 , then @xmath166 and @xmath167 , and additionally @xmath168 and @xmath169 .",
    "thus , @xmath170 and @xmath171 .    ' '' ''    @xmath130    suppose some computer @xmath87 emulates another computer @xmath172 via the string @xmath173 , i.e. @xmath174 .",
    "we can decompose this into two steps : let @xmath175 , then @xmath176 similarly , we can decompose every emulation @xmath39 into @xmath3 parts , just by parsing the string @xmath38 bit by bit , while getting a corresponding `` chain '' of emulated computers . a clear way to illustrate",
    "this situation is in the form of a tree , as shown in figure  [ figemulation ] .",
    "we start at the root @xmath77 .",
    "since @xmath177 , this string corresponds to the computer @xmath36 itself .",
    "then , we are free to choose @xmath178 or @xmath58 , yielding the computer @xmath179 or @xmath180 respectively . ending up with @xmath37 , we can choose the next bit ( taking a @xmath178 we will end up with @xmath181 ) and so on .    in general , some of the emulated computers will themselves be elements of @xmath71 and some not . as in figure",
    "[ figemulation ] , we can mark every path that leads to a computer that is itself an element of @xmath71 by a thick line .",
    "( in this case , for example @xmath182 , but @xmath183 . )",
    "if we want to restrict the process of parsing through the tree to the marked ( thick ) paths , then we need the following property :    ( 0,-2.5)(14.3,10.5 ) ( 0.5,4)@xmath184 ( 0,3.5)(1,4.5 ) ( 4.5,6)@xmath178 ( 4,5.5)(5,6.5 ) ( 4.5,2)@xmath58 ( 4,1.5)(5,2.5 ) ( 1,4)(4,6 ) ( 1,4)(4,2 ) ( 9,8)@xmath185 ( 8.25,7.5)(9.6,8.5 ) ( 5,6)(8.25,8 ) ( 9,2.667)@xmath173 ( 8.25,2.167)(9.6,3.167 ) ( 5,2)(8.25,2.667 ) ( 9,5.333)@xmath186 ( 8.25,4.667)(9.6,5.833 ) ( 5,6)(8.25,5.333 ) ( 9,0)@xmath187 ( 8.25,-0.5)(9.6,0.5 ) ( 5,2)(8.25,0 ) ( 13.5,10)@xmath188 ( 12.7,9.5)(14.3,10.5 ) ( 9.6,8)(12.7,10 ) ( 13.5,-2)@xmath189 ( 12.7,-2.5)(14.3,-1.5 ) ( 9.6,0)(12.7,-2 ) ( 13.5,-0.2857)@xmath190 ( 12.7,-0.7857)(14.3,0.2143 ) ( 9.6,0)(12.7,-0.2857 ) ( 13.5,1.4286)@xmath191 ( 12.7,0.9286)(14.3,1.9286 ) ( 9.6,2.667)(12.7,1.4286 ) ( 13.5,3.1429)@xmath192 ( 12.7,2.6429)(14.3,3.6429 ) ( 9.6,2.667)(12.7,3.1429 ) ( 13.5,4.857)@xmath193 ( 12.7,4.357)(14.3,5.357 ) ( 9.6,5.333)(12.7,4.857 ) ( 13.5,6.571)@xmath194 ( 12.7,6.071)(14.3,7.071 ) ( 9.6,5.333)(12.7,6.571 ) ( 13.5,8.2857)@xmath195 ( 9.6,8)(12.7,8.2857 ) ( 12.7,7.7857)(14.3,8.7857 ) ( 0.5,5.2)c ( 4.5,3.2)d ( 9,3.9)e    a set of computers @xmath140 is called _ branching _ , if for every @xmath196 , the following two conditions are satisfied :    * for every @xmath197 , it holds @xmath198 * there is some @xmath199 such that @xmath200 .    if @xmath71 is branching , we can parse through the corresponding marked subtree without encountering any dead end , with the possibility to reach every leaf of the subtree . in particular ,",
    "these requirements are fulfilled by sets of universal computers :    [ propbranching ] let @xmath140 be connected and @xmath201 , then @xmath202 is branching .",
    "* let @xmath203 and @xmath204 , then @xmath205 for every @xmath206 , and so @xmath207 for every @xmath206 .",
    "moreover , there is some @xmath143 such that @xmath208 , so in particular , @xmath209 .",
    "thus , @xmath210 .    on the other hand , since @xmath201",
    ", there are computers @xmath211 such that @xmath212 . by definition of @xmath202",
    ", there is some @xmath143 such that @xmath213 .",
    "since @xmath36 emulates every computer in @xmath71 , we have @xmath214 , so @xmath215 for some @xmath216 .    ' '' ''    @xmath130    as illustrated in the bold subtree in figure  [ figemulation ] , we can define the process of a _ random walk _ on this subtree if its corresponding computer subset @xmath71 is branching : we start at the root @xmath77 , follow the branches , and at every bifurcation , we turn `` left or right '' ( i.e. input an additional @xmath178 or @xmath58 ) with probability @xmath24 . this random walk generates a probability distribution on the subtree :    if @xmath140 is branching and let @xmath196 , we define the _ @xmath71-tree of @xmath36 _ as the set of all inputs @xmath4 that make @xmath36 emulate a computer in @xmath71 and denote it by @xmath217 , i.e. @xmath218 to every @xmath38 in the @xmath71-tree of @xmath36 , we can associate its _ path probability _ @xmath219 as the probability of arriving at @xmath38 on a random walk on this tree .",
    "formally , @xmath220 for every bit @xmath221 with @xmath222 , where @xmath223 denotes the inverse bit .",
    "the associated @xmath122-step computer probability of @xmath206 is defined as the probability of arriving at computer @xmath37 on a random walk of @xmath122 steps on this tree , i.e. @xmath224    it is clear that for @xmath225 , we get back the notion of output frequency as given in definition  [ defalgfrequency ] : for every @xmath100 , it holds @xmath226 the condition that @xmath71 shall be branching guarantees that @xmath227 for every @xmath97 , i.e. the conservation of probability .",
    "for example , the path probability in figure  [ figemulation ] has values @xmath228 , @xmath229 , @xmath230 , @xmath231 .",
    "it is almost obvious that the random walk on the subtree that generates the computer probabilities @xmath232 is a markov process , which is the statement of the next lemma . for later reference",
    ", we first introduce some notation for the corresponding transition matrix :    let @xmath140 be branching , and enumerate the computers in @xmath71 in arbitrary order : @xmath233 .",
    "then , we define the ( possibly infinite ) _ emulation matrix _ @xmath234 as @xmath235    [ lemchapmankolm ] if @xmath140 is branching , then the computer probabilities @xmath236 are @xmath122-step probabilities of some markov process ( which we also denote @xmath71 ) whose transition matrix is given by the emulation matrix @xmath234 . explicitly , with @xmath237 , @xmath238 for every @xmath97 , and we have the _ chapman - kolmogorov equation _",
    "@xmath239 for every @xmath240 .",
    "also , @xmath140 ( resp .",
    "@xmath234 ) is irreducible if and only if @xmath134 for every @xmath241 .    * proof . *",
    "equation  ( [ eqmarkov ] ) is trivially true for @xmath242 and is shown in full generality by induction ( the proof details are not important for the following argumentation and can be skipped ) : @xmath243 the chapman - kolmogorov equation follows directly from the theory of markov processes .",
    "the stochastic matrix @xmath234 is irreducible iff for every @xmath244 there is some @xmath245 such that @xmath246 , which is equivalent to the existence of some @xmath247 such that @xmath248 .    ' '' ''    @xmath130    the next proposition collects some relations between the emulation markov process and the corresponding set of computers .",
    "we assume that the reader is familiar with the basic vocabulary from the theory of markov chains .",
    "[ propia ] let @xmath140 be a set of computers .",
    "* @xmath71 is irreducible @xmath249 . *",
    "if @xmath71 is connected and @xmath250 , then @xmath202 is irreducible and branching . *",
    "if @xmath71 is branching , then we can define the _ period _ of @xmath196 as @xmath251 ( resp .",
    "@xmath96 if this set is empty ) .",
    "if @xmath140 is irreducible , then @xmath252 for every @xmath241 holds true . in this case , @xmath253 will be called the period of @xmath71 , and if @xmath254 , then @xmath71 is called _ aperiodic_.    * proof . * to prove the first equivalence , suppose that @xmath140 is irreducible , i.e. for every @xmath241 it holds @xmath134 .",
    "thus , @xmath71 is connected and @xmath255 , so @xmath256 , and since always @xmath257 , it follows that @xmath258 . on the other hand , if @xmath258 , then for every @xmath241 it holds @xmath134 , since @xmath255 .",
    "thus , @xmath71 is irreducible . for the second equivalence ,",
    "suppose that @xmath71 is irreducible , thus , @xmath259 .",
    "if on the other hand @xmath260 , it follows in particular for every @xmath196 that @xmath214 for every @xmath143 , so @xmath71 is irreducible .    for the second statement ,",
    "let @xmath261 be arbitrary .",
    "by definition of @xmath202 , it follows that there is some @xmath156 such that @xmath262 , and it holds @xmath263 , so @xmath214 , and @xmath202 is irreducible . by proposition  [ propbranching ] and @xmath264 , @xmath202 must be branching .",
    "the third statement is well - known from the theory of markov processes .    ' '' ''",
    "@xmath130    a basic general result about markov processes now gives us the desired absolute computer probability - almost , at least :    [ thestatalgprop ] let @xmath140 be branching , irreducible and aperiodic .",
    "then , for every @xmath241 , the limit ( `` computer probability '' ) @xmath265 exists and is independent of @xmath36 .",
    "there are two possible cases :    * the markov process which corresponds to @xmath71 is transient or null recurrent .",
    "then , @xmath266 * the markov process which corresponds to @xmath71 is positive recurrent .",
    "then , @xmath267 in this case , the vector @xmath268 is the unique stationary probability eigenvector of @xmath234 , i.e. the unique probability vector solution to @xmath269 .",
    "note that we have derived this result under quite weak conditions  e.g. in contrast to classical algorithmic probability , we do not assume that our computers have prefix - free domain .",
    "nevertheless , we are left with the problem to determine whether a given set @xmath71 of computers is positive recurrent ( case ( 2 ) given above ) or not ( case ( 1 ) ) .",
    "the most interesting case is @xmath270 , i.e. the set of computers that are universal in the sense that they can simulate every other computer without any restriction .",
    "this set is `` large ''  apart from universality , we do not assume any additional property like e.g. being prefix . by proposition  [ propia ] , @xmath271 is irreducible and branching .",
    "moreover , fix any universal computer @xmath272 and consider the computer @xmath273 , given by @xmath274 as @xmath275 , we know that @xmath276 , and since @xmath277 , it follows that @xmath278 , and so @xmath279 . hence @xmath271 is aperiodic .",
    "so is @xmath271 positive recurrent or not ?",
    "unfortunately , the answer turns out to be negative : @xmath271 is transient .",
    "the idea to prove this is to construct a sequence of universal computers @xmath55 such that each computer @xmath56 emulates the next computer @xmath57 with large probability , that is , the probability tends to one as @xmath59 gets large .",
    "thus , starting the random walk on , say , @xmath60 , it will with positive probability stay on this @xmath56-path forever and never return to any other computer .",
    "see also figure  [ figvirus ] in the introduction for illustration .",
    "[ themarkoffchaney ]    ' '' ''    @xmath271 is transient , i.e. there is no stationary algorithmic computer probability on the universal computers .",
    "* let @xmath272 be an arbitrary universal computer with @xmath280 .",
    "we define another computer @xmath281 as follows : if some string @xmath72 is supplied as input , then @xmath60    * splits the string @xmath0 into parts @xmath282 , such that @xmath283 and @xmath284 for every @xmath285 .",
    "we also demand that @xmath286 ( for example , if @xmath287 , then @xmath288 , @xmath289 , @xmath290 , @xmath291 and @xmath292 ) , * tests if there is any @xmath293 such that @xmath294 ( i.e. @xmath295 contains only zeros ) .",
    "if yes , then @xmath60 computes and outputs @xmath296 ( if there are several @xmath59 with @xmath294 , then it shall take the smallest one ) . if not , then @xmath60 outputs @xmath297 .",
    "let @xmath298 , @xmath299 , @xmath300 and so on , in general @xmath301 resp .",
    "we also have @xmath303 , so @xmath304 for every @xmath305 .",
    "thus , the computers @xmath56 are all universal . also , since @xmath306 , the computers @xmath56 are mutually different from each other , i.e. @xmath307 for @xmath308 .",
    "now consider the computers @xmath309 for @xmath310 , but @xmath311 .",
    "it holds @xmath312 .",
    "the only property of @xmath0 that affects the outcome of @xmath60 s computation is the property to be different from @xmath313 . but",
    "this property is shared by the string @xmath314 , i.e. @xmath315 , resp .",
    "@xmath316 for every @xmath4 .",
    "thus , @xmath317 for every @xmath318 , and so @xmath319 iterated application of the chapman - kolmogorov equation ( [ eqchapmankolmogorov ] ) yields for every @xmath245 @xmath320 with at least this probability , the markov process corresponding to @xmath71 will follow the sequence of computers @xmath321 forever , without ever returning to @xmath60 .",
    "( note that also the intermediately emulated computers like @xmath322 are different from @xmath60 , since @xmath323 , but @xmath324 . )",
    "thus , the eventual return probability to @xmath60 is strictly less than @xmath58 .    ' '' ''",
    "@xmath130    in this proof , every computer @xmath57 is a modified copy of its ancestor @xmath56 . in some sense ,",
    "@xmath60 can be seen as some kind of `` computer virus '' that undermines the existence of a stationary computer probability .",
    "the theorem s name `` markoff chaney virus '' was inspired by a fictitious character in robert anton wilson s `` illuminatus ! ''",
    "trilogy damn the science of mathematics itself , the line , the square , the average , the whole measurable world that pronounced him a bizarre random factor . once and for all , beyond fantasy , in the depth of his soul he declared war on the `` statutory ape '' , on law and order , on predictability , on negative entropy",
    "he would be a random factor in every equation ; from this day forward , unto death , it would be civil war : the midget versus the digits ... _ ' ' ] .",
    "the set @xmath271 is in some sense too large to allow the existence of stationary algorithmic probability distribution . yet , there exist computer sets @xmath71 that are actually positive recurrent and thus have such a probability distribution ; here is an explicit example :    [ exposrecurrent ] fix an arbitrary string @xmath325 with @xmath326 , and let @xmath1 be a universal computer , i.e. @xmath272 , with the property that it emulates every other computer via some string that does not contain @xmath327 as a substring , i.e. @xmath328 if @xmath87 is any computer , define a corresponding computer @xmath329 by @xmath330 if @xmath331 and @xmath42 does not contain @xmath327 as a substring , and as @xmath332 otherwise ( that is , if @xmath38 does not contain @xmath327 ) .",
    "the string @xmath327 is a `` synchronizing word '' for the computer @xmath329 , in the sense that any occurrence of @xmath327 in the input forces @xmath329 to `` reset '' and to emulate @xmath1 .",
    "we get a set of computers @xmath333 whenever @xmath38 does not contain @xmath327 as a substring , it holds @xmath334 it follows that @xmath335 is a universal computer for @xmath336 . thus @xmath336 is connected , and it is easy to see that @xmath337 and @xmath338 . according to to proposition  [ propia ] , @xmath339 is irreducible and branching .",
    "an argument similar to that before theorem  [ themarkoffchaney ] ( where it was proved that @xmath271 is aperiodic ) proves that @xmath339 is also aperiodic .",
    "moreover , by construction it holds for every computer @xmath340 and @xmath341 @xmath342 the chapman - kolmogorov equation  ( [ eqchapmankolmogorov ] ) then yields @xmath343 consequently , @xmath344 . according to theorem  [ thestatalgprop ]",
    ", it follows that @xmath339 is positive recurrent .",
    "in particular , @xmath345 .",
    "note also that @xmath346 , so we do not have the trivial situation of a finite computer set .    obviously ,",
    "the computer set @xmath336 in the previous example depends on the choice of the string @xmath327 and the computer @xmath1 ; different choices yield different computer sets and different probabilities . in the next section",
    ", we will see in theorem  [ thenonuniqueness ] that every positive recurrent computer set contains an unavoidable `` amount of arbitrariness '' , and this fact has an interesting physical interpretation .",
    "given any positive recurrent computer set @xmath71 ( as in the previous example ) , the actual numerical values of the corresponding stationary computer probability @xmath347 will in general be noncomputable .",
    "for this reason , the following lemma may be interesting , giving a rough bound on stationary computer probability in terms of emulation complexity :    let @xmath140 be positive recurrent is positive recurrent , we shall always assume that @xmath71 is also branching , irreducible and aperiodic . ] .",
    "then , for every @xmath241 , we have the inequality @xmath348    * proof .",
    "* we start with the limit @xmath349 in the chapman - kolmogorov equation ( [ eqchapmankolmogorov ] ) and obtain @xmath350 for every @xmath97 .",
    "next , we specialize @xmath351 , then @xmath352 .",
    "this proves the left hand side of the inequality .",
    "the right hand side can be obtained simply by interchanging @xmath36 and @xmath37 .    ' '' ''    @xmath130",
    "the aim of this section is twofold : on the one hand , we will derive an alternative proof of the non - existence of a stationary computer probability distribution on @xmath271 ( which we have already proved in theorem  [ themarkoffchaney ] ) .",
    "the benefit of this alternative proof will be to generalize our no - go result much further : it will supply us with an interesting physical interpretation why getting rid of machine - dependence must be impossible .",
    "we discuss this in more detail in section  [ secconclusions ] .    on the other hand",
    ", we would like to explore what happens for computer sets @xmath71 that actually _ are _ positive recurrent .",
    "in particular , we show that such sets generate a natural algorithmic probability on the _ strings _  after all , finding such a probability distribution was our aim from the beginning ( cf .",
    "the introduction ) . actually , this string probability turns out to be useful in proving our no - go generalization .",
    "moreover , it shows that the hard part is really to define computer probability  once this is achieved , string probability follows almost trivially .    here",
    "is how we define string probability .",
    "while computer probability @xmath353 was defined as the probability of encountering @xmath36 on a random walk on the @xmath71-tree , we analogously define the probability of a string @xmath0 as the probability of getting the output @xmath0 on this random walk :    [ defstringprobability ] let @xmath140 be branching and let @xmath196 .",
    "the @xmath122-step string probability of @xmath98 is defined as the probability of arriving at output @xmath0 on a random walk of @xmath122 steps on the @xmath71-tree of @xmath36 , i.e. @xmath354    [ thestatalgsp ] if @xmath140 is positive recurrent , then for every @xmath196 and @xmath98 the limit @xmath355 exists and is independent of @xmath36 .",
    "* it is easy to see from the definition of @xmath122-step string probability that @xmath356 taking the limit @xmath128 , theorem  [ thestatalgprop ] yields equality of left and right hand side , and thus existence of the limit and independence of @xmath36 .    ' '' ''    @xmath130    in general , @xmath347 is a probability distribution on @xmath91 rather than on @xmath90 , i.e. the undefined string can have positive probability , @xmath357 , so @xmath358 .",
    "we continue by showing a chapman - kolmogorov - like equation ( analogous to equation  ( [ eqchapmankolmogorov ] ) ) for the string probability .",
    "note that this equation differs from the much deeper result of theorem  [ theeqdef ] in the following sense : it describes a weighted average of probabilities @xmath359 , and those probabilities do not only depend on the computer @xmath1 ( as in theorem  [ theeqdef ] ) , but also on the choice of the subset @xmath71 .",
    "[ eqckstring ] if @xmath140 is positive recurrent , then @xmath360 for every @xmath196 , @xmath240 and @xmath98 .    * proof . * for @xmath361",
    ", we use the notation @xmath362 and calculate @xmath363 the second sum equals @xmath364 and the claim follows .    ' '' ''    @xmath130    for prefix computers @xmath36 , algorithmic probability @xmath365 of any string @xmath0 as defined in equation  ( [ eqdefap ] ) and the expression @xmath366 differ only by a multiplicative constant  @xcite .",
    "here is an analogous inequality for stationary string probability :    let @xmath140 be positive recurrent and @xmath196 some arbitrary computer , then @xmath367    * proof .",
    "* we start with the limit @xmath349 in the chapman - kolmogorov equation given in proposition  [ eqckstring ] and get @xmath368 for every @xmath97",
    ". then we specialize @xmath369 and use @xmath370 for this choice of @xmath122 .    ' '' ''    @xmath130    looking for further properties of stationary string probability , it seems reasonable to conjecture that , for many computer sets @xmath71 , a string @xmath72 ( like @xmath371 ) and its inverse @xmath372 ( in this case @xmath373 ) have the same probability @xmath374 , since both seem to be in some sense algorithmically equivalent .",
    "a general approach to prove such conjectures is to study _ output transformations _ :    ' '' ''",
    "let @xmath375 be a computable permutation .",
    "for every @xmath87 , the map @xmath74 is itself a computer , defined by @xmath376 .",
    "the map @xmath377 will be called an _ output transformation _ and will also be denoted @xmath73 . moreover , for computer sets @xmath140 , we use the notation @xmath378    under reasonable conditions , string and computer probability are invariant with respect to output transformations :    [ theoutputsym ] let @xmath140 be positive recurrent and closed is _ closed _ with respect to some transformation @xmath379 if @xmath380 . ] with respect to some output transformation @xmath73 and its inverse @xmath381 .",
    "then , we have for every @xmath196 @xmath382 and for every @xmath72 @xmath383    * proof . *",
    "note that @xmath384 .",
    "let @xmath241 .",
    "suppose that @xmath385 for some bit @xmath221 .",
    "then , @xmath386 thus , we have @xmath387 .",
    "it follows for the @xmath58-step transition probabilities that @xmath388 for every @xmath389 .",
    "thus , the emulation matrix @xmath234 does not change if every computer @xmath36 ( or rather its number in the list of all computers ) is exchanged with ( the number of ) its transformed computer @xmath74 yielding the transformed emulation matrix @xmath390 .",
    "but then , @xmath234 and @xmath390 must have the same unique stationary probability eigenvector @xmath391 this proves the first identity , while the second identity follows from the calculation @xmath392 thus , if some computer set @xmath140 contains e.g. for every computer @xmath36 also the computer @xmath393 which always outputs the bitwise inverse of @xmath36 , then @xmath374 holds . in some sense",
    ", this shows that the approach taken in this paper successfully eliminates properties of single computers ( e.g. to prefer the string @xmath394 over @xmath395 ) and leaves only general algorithmic properties related to the set of computers .",
    "moreover , theorem  [ theoutputsym ] allows for an alternative proof that @xmath271 and similar computer sets can not be positive recurrent .",
    "we call a set of computable permutations @xmath396 _ cyclic _ if every string @xmath72 is mapped to infinitely many other strings by application of finite compositions of those permutations , i.e. if for every @xmath72 @xmath397 and if @xmath79 contains with each permutation @xmath73 also its inverse @xmath381",
    ". then , many computer subset can not be positive recurrent :    [ theposrecsym ] let @xmath140 be closed with respect to a cyclic set of output transformations , then @xmath71 is not positive recurrent .",
    "* suppose @xmath71 is positive recurrent .",
    "let @xmath396 be the corresponding cyclic set of output transformations .",
    "let @xmath72 be an arbitrary string , then for every composition @xmath398 , we have by theorem  [ theoutputsym ] @xmath383 since @xmath79 is cyclic , there are infinitely many such transformations @xmath73 , producing infinitely many strings @xmath399 which all have the same probability .",
    "it follows that @xmath400 .",
    "since @xmath72 was arbitrary , this is a contradiction .    ' '' ''",
    "@xmath130    again , we conclude that @xmath271 is not positive recurrent , since this computer set is closed with respect to _ all _ output transformations .    although @xmath271 is not positive recurrent , there might be a unique , natural , `` maximal '' or `` most interesting '' subset @xmath140 which is positive recurrent .",
    "what can we say about this idea ?",
    "in fact , the following theorem says that this is also impossible .",
    "as this theorem is only a simple generalization of theorem  [ theoutputsym ] , we omit the proof .",
    "[ thenonuniqueness ] if @xmath140 is positive recurrent , then so is @xmath75 for every computable permutation ( = output transformation ) @xmath73 .",
    "moreover , @xmath401 for every @xmath196 , and @xmath402 for every @xmath98 .",
    "this means that there can not be a unique `` natural '' positive recurrent computer set @xmath71 : for every such set @xmath71 , there exist output transformations @xmath73 such that @xmath403 ( this follows from theorem  [ theposrecsym ] ) .",
    "but then , theorem  [ thenonuniqueness ] proves that @xmath75 is positive recurrent , too  and it is thus another candidate for the `` most natural '' computer set .",
    "we have studied a natural approach to get rid of machine - dependence in the definition of algorithmic probability .",
    "the idea was to look at a markov process of universal computers emulating each other , and to take the stationary distribution as a natural probability measure on the computers .",
    "this approach was only partially successful : as the corresponding markov process on the set of _ all _ computers is not positive recurrent and thus has no unique stationary distribution , one has to choose a subset @xmath71 of the computers , which introduces yet another source of ambiguity .",
    "however , we have shown ( cf .",
    "example  [ exposrecurrent ] ) that there exist non - trivial , infinite sets @xmath71 of computers that are actually positive recurrent and possess a stationary algorithmic probability distribution .",
    "this distribution has beautiful properties and eliminates at least some of the machine - dependence arising from choosing a single , arbitrary universal computer as a reference machine ( e.g. theorem  [ theoutputsym ] ) .",
    "it gives probabilities for computers as well as for strings ( theorem  [ thestatalgsp ] ) , agrees with the average output frequency ( theorem  [ theeqdef ] ) , and does not assume that the computers have any specific structural property like e.g. being prefix - free .",
    "the second main result can be stated as follows : _ there is no way to get completely rid of machine - dependence , _ neither in the approach of this paper nor in any other similar but different approach . to understand why this is true , recall that the main reason for our no - go result was the symmetry of computer probability with respect to _ output transformations _",
    "@xmath404 , where @xmath73 is a computable permutation on the strings .",
    "this can be seen in two places :    * in theorem  [ theposrecsym ] , this symmetry yields the result that any computer set which is `` too large '' ( like @xmath271 ) can not be positive recurrent . *",
    "theorem  [ thenonuniqueness ] states that if a set @xmath71 is positive recurrent , then @xmath75 must be positive recurrent , too . since in this case @xmath405 for many @xmath73 ,",
    "this means that there can not be a unique `` natural '' choice of the computer set @xmath71 .",
    "output transformations have a natural physical interpretation as `` renaming the objects that the strings are describing '' . to see this ,",
    "suppose we want to define the complexity of the microstate of a box of gas in thermodynamics ( this can sometimes be useful , see  @xcite ) .",
    "furthermore , suppose we are only interested in a coarse - grained description such that there are only countably many possibilities what the positions , velocities etc .",
    "of the gas particles might look like .",
    "then , we can encode every microstate into a binary string , and define the complexity of a microstate as the complexity of the corresponding string ( assuming that we have fixed an arbitrary complexity measure @xmath406 on the strings ) .",
    "but there are always many different possibilities how to encode the microstate into a string ( specifying the velocities in different data formats , specifying first the positions and then the velocities or the other way round etc . ) .",
    "if every encoding is supposed to be one - to - one and can be achieved by some machine , then two different encodings will always be related to each other by a computable permutation .    in more detail ,",
    "if one encoding @xmath407 maps microstates @xmath408 to encoded strings @xmath409 , then another encoding @xmath410 will map microstates @xmath408 to @xmath411 , where @xmath73 is a computable permutation on the strings ( that depends on @xmath407 and @xmath410 ) .",
    "choosing encoding @xmath407 , a microstate @xmath408 will be assigned the complexity @xmath412 , while for encoding @xmath410 , it will be assigned the complexity @xmath413 .",
    "that is , there is an unavoidable ambiguity which arises from the arbitrary choice of an encoding scheme .",
    "switching between the two encodings amounts to `` renaming '' the microstates , and this is exactly an output transformation in the sense of this paper .    even if we do not have the situation that the strings shall describe physical objects , we encounter a similar ambiguity already in the definition of a computer : a computer , i.e. a partial recursive function ,",
    "is described by a turing machine computing that function .",
    "whenever we look at the output of a turing machine , we have to `` read '' the output from the machine s tape which can potentially be done in several inequivalent ways , comparable to the different `` encodings '' described above .",
    "every kind of attempt to get rid of those additive constants in kolmogorov complexity will have to face this ambiguity of `` renaming '' .",
    "this is why we think that all those attempts must fail .",
    "this appendix is rather technical and can be skipped on first reading .",
    "its aim is to prove theorem  [ theeqdef ] .",
    "this theorem says that the string probability which has been introduced in definition  [ defstringprobability ] in section  [ secsymmetries ] is exactly what we really wanted to have from the beginning : in the introduction , our main motivation to find a probability measure on the computers was to define machine - independent algorithmic probability of strings as the weighted mean over all universal computers as stated in equation  ( [ eqprobidea ] ) .",
    "theorem  [ theeqdef ] says that string probability can be written exactly in this way , given some natural assumptions on the reference set of computers .",
    "note that theorem  [ theeqdef ] is a surprising result for the following reason : string probability , as defined in definition  [ defstringprobability ] , only depends on the outputs of the computers on the `` universal subtree '' , that is , on the leaves in figure  [ figemulation ] which correspond to bold lines . but output frequency , as given on the right - hand side in theorem  [ theeqdef ] and defined in definition  [ defalgfrequency ] , counts the outputs on _ all _ leaves  that is , output frequency is a property of a single computer , not of the computer subset that is underlying the emulation markov process .",
    "in section  [ secsymmetries ] , we have studied output transformations on computers  the key idea in this appendix will be to study _ input transformations _ instead .",
    "so what is an input transformation ?",
    "if @xmath375 is a computable permutation on the strings and @xmath87 is some computer , we might consider the transformed computer @xmath414 , given by @xmath415 . but",
    "this turns out not to be useful , since such transformations do not preserve the emulation structure .",
    "in fact , the most important and useful property of output transformations in section  [ secsymmetries ] was that they preserve the emulation structure : it holds @xmath416 but for transformations like @xmath417 , there is no such identity  hence we have to look for a different approach .",
    "it turns out that a successful approach is to look only at a restricted class of permutations , and also to introduce equivalence classes of computers :    ' '' ''    for every @xmath418 , two computers @xmath100 are called @xmath419-equivalent , denoted @xmath420 , if @xmath421 for every @xmath4 with @xmath422 .",
    "we denote the corresponding equivalence classes by @xmath423_k$ ] and set @xmath424_k:=\\{|c]_k\\,\\,|\\,\\,c\\in\\phi\\}.\\ ] ] a computer set @xmath140 is called _ complete _ if for every @xmath196 and @xmath418 it holds @xmath423_k\\subset\\phi$ ] .",
    "if @xmath140 is positive recurrent and complete , we set for every @xmath423_k\\in[\\phi]_k$ ] @xmath425_k|\\phi):=\\sum_{c\\in[c]_k}\\mu(c|\\phi).\\ ] ] it is easy to see that for every @xmath100 it holds @xmath426,\\ ] ] thus , the definition @xmath427_k}^{(n)}([d]_k|\\phi):=\\sum_{d\\in[d]_k}\\mu_c^{(n)}(d|\\phi)$ ] makes sense for @xmath245 and @xmath423_k,[d]_k\\in[\\phi]_k$ ] and is independent of the choice of the representative @xmath428_k$ ] . enumerating the equivalence classes @xmath429_k=\\left\\{[c_1]_k,[c_2]_k,[c_3]_k,\\ldots\\right\\}$ ] in arbitrary order , we can define an associated emulation matrix @xmath430 as @xmath431_k}^{(1)}([c_j]_k|\\phi).\\ ] ]    it is easily checked that if @xmath71 is positive recurrent , then the markov process described by the transition matrix @xmath430 must also be irreducible , aperiodic and positive recurrent , and @xmath432_k|\\phi),\\mu([c_2]_k|\\phi),\\mu([c_3]_k|\\phi),\\ldots\\right)$ ] is the unique probability vector solution to the equation @xmath433 .",
    "now we can define input transformations :    [ definputtrafo ]    ' '' ''    let @xmath434 be a permutation such that there is at least one string @xmath247 for which @xmath435 , where @xmath436 denotes the first bit of @xmath38 . for every @xmath72 ,",
    "let @xmath437 be the string that is generated by applying @xmath73 to the last @xmath122 bits of @xmath0 ( e.g. if @xmath438 , @xmath439 and @xmath440 , then @xmath441 ) . if @xmath442 , then @xmath443 .",
    "for every @xmath87 , the @xmath444-transformed computer @xmath445 is defined by @xmath446 we call @xmath447 the _ order _ of @xmath73 .",
    "moreover , we use the notation @xmath448    ( 0,-2)(14.3,10.5 ) ( 0.5,4)@xmath184 ( 0,3.5)(1,4.5 ) ( 4.5,6)@xmath178 ( 4,5.5)(5,6.5 ) ( 4.5,2)@xmath58 ( 4,1.5)(5,2.5 ) ( 1,4)(4,6 ) ( 1,4)(4,2 ) ( 0,0 ) ( 5,5.3)(6,4)(5,2.7 ) ( 9,8)@xmath185 ( 8.25,7.5)(9.6,8.5 ) ( 5,6)(8.25,8 ) ( 9,2.667)@xmath173 ( 8.25,2.167)(9.6,3.167 ) ( 5,2)(8.25,2.667 ) ( 9,5.333)@xmath186 ( 8.25,4.667)(9.6,5.833 ) ( 5,6)(8.25,5.333 ) ( 0,0 ) ( 9.7,7.6)(10.2,6.6667)(9.7,5.7333 ) ( 9,0)@xmath187 ( 8.25,-0.5)(9.6,0.5 ) ( 5,2)(8.25,0 ) ( 0,0 ) ( 9.7,2.2667)(10.2,1.3333)(9.7,0.4 ) ( 13.5,10)@xmath188 ( 12.7,9.5)(14.3,10.5 ) ( 9.6,8)(12.7,10 ) ( 13.5,-2)@xmath189 ( 12.7,-2.5)(14.3,-1.5 ) ( 9.6,0)(12.7,-2 ) ( 13.5,-0.2857)@xmath190 ( 12.7,-0.7857)(14.3,0.2143 ) ( 9.6,0)(12.7,-0.2857 ) ( 13.5,1.4286)@xmath191 ( 12.7,0.9286)(14.3,1.9286 ) ( 9.6,2.667)(12.7,1.4286 ) ( 13.5,3.1429)@xmath192 ( 12.7,2.6429)(14.3,3.6429 ) ( 9.6,2.667)(12.7,3.1429 ) ( 13.5,4.857)@xmath193 ( 12.7,4.357)(14.3,5.357 ) ( 9.6,5.333)(12.7,4.857 ) ( 13.5,6.571)@xmath194 ( 12.7,6.071)(14.3,7.071 ) ( 9.6,5.333)(12.7,6.571 ) ( 13.5,8.2857)@xmath195 ( 9.6,8)(12.7,8.2857 ) ( 12.7,7.7857)(14.3,8.7857 ) ( 14.5,10)(15.4,9.14285)(14.5,8.2857 ) ( 0,0 ) ( 14.5,6.5713)(15.4,5.71415)(14.5,4.857 ) ( 0,0 ) ( 14.5,3.1426)(15.4,2.28545)(14.5,1.4283 ) ( 0,0 ) ( 14.5,-0.2861)(15.4,-1.14325)(14.5,-2 ) ( 0,0 ) ( 0.5,5.2)c ( 4.5,3.2)d ( 9,3.9)e    the action of an input transformation is depicted in figure  [ figipermutation ] : changing e.g. the last bit of the input causes a permutation of the outputs corresponding to neighboring branches .",
    "as long as @xmath71 is complete and closed with respect to that input transformation , the emulation structure will not be changed .",
    "this is a byproduct of the proof of the following theorem :    [ theinputsymmetry ] let @xmath140 be positive recurrent , complete and closed with respect to an input transformation @xmath444 .",
    "then , for every @xmath449 @xmath425_k|\\phi)=\\mu([\\mathcal{i}_\\sigma(c)]_k|\\phi).\\ ] ]    * proof .",
    "* suppose that @xmath423_k{\\stackrel{0}{\\longrightarrow}}[c_0]_k$ ] , i.e. @xmath450 for every @xmath422 , @xmath451_k$ ] and @xmath452_k$ ] . as @xmath453 , @xmath454 so @xmath455_k{\\stackrel{0}{\\longrightarrow}}[\\mathcal{i}_\\sigma(c_0)]_k$ ] .",
    "analogously , from @xmath423_k{\\stackrel{1}{\\longrightarrow}}[c_1]_k$ ] it follows that @xmath455_k{\\stackrel{1}{\\longrightarrow}}[\\mathcal{i}_\\sigma(c_1)]_k$ ] and vice versa .",
    "thus , @xmath456_k}^{(1)}([c_j]_k|\\phi )     = \\mu_{[\\mathcal{i}_\\sigma(c_i)]_k}^{(1)}([\\mathcal{i}_\\sigma(c_j)]_k|\\phi).\\ ] ] so interchanging every equivalence class of computers with its transformed class leaves the emulation matrix invariant . a similar argument as in theorem  [ theoutputsym ] proves the claim .    ' '' ''    @xmath130    we are now heading towards an analogue of equation  ( [ eqprobidea ] ) , i.e. towards a proof that our algorithmic string probability equals the weighted average of output frequency .",
    "this needs some preparation :    let @xmath444 be an input transformation of order @xmath245 .",
    "a computer @xmath87 is called _",
    "@xmath444-symmetric _ if @xmath457 ( which is equivalent to @xmath455_n=[c]_n$ ] ) .",
    "the _ input symmetry group _ of @xmath36 is defined as @xmath458    every transformation of order @xmath245 can also be interpreted as a transformation on @xmath459 for @xmath460 , by setting @xmath461 whenever @xmath462 . with this identification , @xmath463 is a group .",
    "let @xmath140 be irreducible .",
    "then @xmath463 is the same for every @xmath196 and can be denoted @xmath464",
    ".    * proof .",
    "* let @xmath140 be irreducible , and let @xmath196 be @xmath444-symmetric , i.e. @xmath465 for every @xmath72 .",
    "let @xmath206 be an arbitrary computer .",
    "since @xmath71 is irreducible , it holds @xmath134 , i.e. there is a string @xmath4 with @xmath133 for every @xmath72 .",
    "let @xmath466 , then @xmath467 and @xmath37 is also @xmath444-symmetric .    ' '' ''    @xmath130    for most irreducible computer sets like @xmath270 , the input symmetry group will only consist of the identity , i.e. @xmath468 .",
    "now we are ready to state the most interesting result of this section :    [ theeqdef ] if @xmath140 is positive recurrent , complete and closed with respect to every input transformation @xmath444 with @xmath469 , then @xmath470 where @xmath471 is the output frequency as introduced in definition  [ defalgfrequency ] .    *",
    "* the case @xmath242 is trivial , so let @xmath472 .",
    "it is convenient to introduce another equivalence relation on the computer classes .",
    "we define the corresponding equivalence classes ( `` transformation classes '' ) as @xmath473_k\\in[\\phi]_k\\,\\,|\\,\\,\\exists \\mathcal{i}_\\sigma:|\\sigma|\\leq k ,     [ \\mathcal{i}_\\sigma(v)]_k=[x]_k\\right\\}.\\ ] ] thus , two computer classes @xmath474_k$ ] and @xmath475_k$ ] are elements of the same transformation class if one is an input transformation ( of order less than @xmath419 ) of the other . again , we set @xmath476 .    for every @xmath477_n$ ] , the probability @xmath478 is the same and can be denoted @xmath479_n}^{(n)}(s|\\phi)$ ] .",
    "according to proposition  [ eqckstring ] , we have @xmath480_n\\in\\{x\\}_n }     \\mu([y]_n|\\phi)\\mu_{[y]_n}^{(n)}(s|\\phi).\\end{aligned}\\ ] ] due to theorem  [ theinputsymmetry ] , the probability @xmath481_n|\\phi)$ ] is the same for every @xmath475_n\\in\\{x\\}_n$ ] . let @xmath474_n$ ] be an arbitrary representative of @xmath482 , then @xmath483_n\\in\\{x\\}_n } \\mu([y]_n|\\phi)=\\ #",
    "\\{x\\}_n \\cdot    \\mu([x]_n|\\phi).\\ ] ] the two equations yield @xmath484_n\\in\\{x\\}_n } \\mu_{[y]_n}^{(n)}(s|\\phi).\\ ] ] let @xmath485 be the set of all permutations on @xmath486 .",
    "two permutations @xmath487 are called @xmath71-equivalent if there exists a @xmath488 such that @xmath489 ( recall that @xmath71 is irreducible ) .",
    "this is the case if and only of @xmath490 for one and thus every computer @xmath196 .",
    "the set of all @xmath71-equivalence classes will be denoted @xmath491 .",
    "every computer class @xmath475_n\\in\\{x\\}_n$ ] is generated from @xmath474_n$ ] by some input transformation .",
    "if @xmath492 is an arbitrary representative of @xmath474_n$ ] , we thus have @xmath493\\in\\mathbf{s}_n(\\phi)}\\mu_{[\\mathcal{i}_\\sigma(x)]_n}^{(n)}(s|\\phi),\\ ] ] where @xmath494 $ ] is an arbitrary representative . for every equivalence class @xmath495 $ ] , it holds true @xmath496=\\#(\\mathbf{s}_{2^n } \\cap \\mathcal{i}-{\\rm sym}(\\phi))$ ] , thus @xmath497_n}^{(n)}(s|\\phi).\\end{aligned}\\ ] ] by definition of the set @xmath491 ,",
    "@xmath498 using that @xmath499 , we obtain @xmath500 as @xmath501 it holds @xmath502 .",
    "the substitution @xmath503 yields @xmath504 up to normalization , the rightmost sum is the average of all permutations of the probability vector @xmath505 , thus @xmath506 recall that @xmath492 was an arbitrary representative of an arbitrary representative of @xmath482 .",
    "the last two equations yield @xmath507_n\\in\\{x\\}_n }     \\mu([x]_n|\\phi)\\mu_x^{(n)}(s)\\\\     & = & \\sum_{\\{x\\}_n\\in\\{\\phi\\}_n}\\sum_{[x]_n\\in\\{x\\}_n}\\sum_{x\\in[x]_n }     \\mu(x|\\phi)\\mu_x^{(n)}(s)\\\\     & = & \\sum_{x\\in\\phi}\\mu(x|\\phi)\\mu_x^{(n)}(s).\\end{aligned}\\ ] ] note that if @xmath492 and @xmath508 are representatives of representatives of an arbitrary transformation class @xmath482 , then @xmath509 .    ' '' ''    @xmath130    this theorem is the promised analogue of equation  ( [ eqprobidea ] ) : it shows that the string probability that we have defined in definition  [ defstringprobability ] is the weighted average of output frequency as defined in definition  [ defalgfrequency ] . for a discussion",
    "why this is interesting and surprising , see the first few paragraphs of this appendix .",
    "the author would like to thank n. ay , d. gross , s. guttenberg , m. ioffe , t. krger , d. schleicher , f .- j .",
    "schmitt , r. siegmund - schultze , r. seiler , and a. szkoa for helpful discussions and kind support .",
    "a. k. zvonkin , l. a. levin , `` the complexity of finite objects and the development of the concepts of information and randomness by means of the theory of algorithms '' , russian math .",
    "surveys , 25/6 , pp.83 - 124 , 1970 ."
  ],
  "abstract_text": [
    "<S> kolmogorov complexity and algorithmic probability are defined only up to an additive resp . </S>",
    "<S> multiplicative constant , since their actual values depend on the choice of the universal reference computer . in this paper </S>",
    "<S> , we analyze a natural approach to eliminate this machine - dependence .    </S>",
    "<S> our method is to assign algorithmic probabilities to the different computers themselves , based on the idea that `` unnatural '' computers should be hard to emulate . </S>",
    "<S> therefore , we study the markov process of universal computers randomly emulating each other . the corresponding stationary distribution , if it existed , would give a natural and machine - independent probability measure on the computers , and also on the binary strings .    </S>",
    "<S> unfortunately , we show that no stationary distribution exists on the set of all computers ; thus , this method can not eliminate machine - dependence . </S>",
    "<S> moreover , we show that the reason for failure has a clear and interesting physical interpretation , suggesting that every other conceivable attempt to get rid of those additive constants must fail in principle , too .    </S>",
    "<S> however , we show that restricting to some subclass of computers might help to get rid of some amount of machine - dependence in some situations , and the resulting stationary computer and string probabilities have beautiful properties </S>",
    "<S> .    [ section ] [ theorem]lemma [ theorem]corollary [ theorem]example [ theorem]definition [ theorem]proposition [ theorem]conjecture    algorithmic probability , kolmogorov complexity , markov chain , emulation , emulation complexity </S>"
  ]
}