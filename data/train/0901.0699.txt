{
  "article_text": [
    "we study a directed polymer model introduced by huse and henley ( in dimension @xmath0 ) @xcite with the purpose of investigating impurity - induced domain - wall roughening in the 2d - ising model .",
    "the first mathematical study of directed polymers in random environment was made by imbrie and spencer @xcite , and was followed by numerous authors @xcite ( for a review on the subject see @xcite ) .",
    "directed polymers in random environment model , in particular , polymer chains in a solution with impurities .    in our set  up the polymer chain is the graph @xmath2 of a nearest ",
    "neighbor path in @xmath3 , @xmath4 starting from zero .",
    "the equilibrium behavior of this chain is described by a measure on the set of paths : the impurities enter the definition of the measure as _ disordered potentials _ , given by a typical realization of a field of i.i.d .",
    "random variables @xmath5 ( with associated law @xmath6 ) .",
    "the polymer chain will tend to be attracted by larger values of the environment and repelled by smaller ones .",
    "more precisely , we define the hamiltonian @xmath7 we denote by @xmath8 the law of the simple symmetric random walk on @xmath3 starting at @xmath9 ( in the sequel @xmath10 , respectively @xmath11 , will denote the expectation with respect to @xmath8 , respectively q ) .",
    "one defines the polymer measure of order @xmath12 at inverse temperature @xmath13 as @xmath14 where @xmath15 is the normalization factor which makes @xmath16 a probability measure @xmath17 we call @xmath15 the _ partition function _ of the system . in the sequel",
    ", we will consider the case of @xmath18 with zero mean and unit variance and such that there exists @xmath19 $ ] such that @xmath20 finite exponential moments are required to guarantee that @xmath21 .",
    "the model can be defined and it is of interest also with environments with heavier tails ( see e.g.  @xcite ) but we will not consider these cases here .      in order to understand the role of disorder in the behavior of @xmath16 , as @xmath12 becomes large , let us observe that , when @xmath22 , @xmath16 is the law of the simple random walk , so that we know that , properly rescaled , the polymer chain will look like the graph of a @xmath23-dimensional brownian motion .",
    "the main questions that arise for our model for @xmath24 are whether or not the presence of disorder breaks the diffusive behavior of the chain for large @xmath12 , and how the polymer measure looks like when diffusivity does not hold .",
    "many authors have studied diffusivity in polymer models : in @xcite , bolthausen remarked that the renormalized partition function @xmath25 has a martingale property and proved the following zero - one law : @xmath26 a series of paper @xcite lead to @xmath27 and a consensus in saying that this implication is an equivalence .",
    "for this reason , it is natural and it has become customary to say that _ weak disorder",
    "_ holds when @xmath28 converges to some non - degenerate limit and that _ strong disorder",
    "_ holds when @xmath28 tends to zero .",
    "carmona and hu @xcite and comets , shiga and yoshida @xcite  proved that strong disorder holds for all @xmath13 in dimension @xmath29 and @xmath30 .",
    "the result was completed by comets and yoshida @xcite : we summarize it here    [ strdis ] there exists a critical value @xmath31 $ ] ( depending of the law of the environment ) such that    * weak disorder holds when @xmath32 .",
    "* strong disorder holds when @xmath33 .",
    "moreover : @xmath34 \\text { for } d\\ge 3 .",
    "\\end{split}\\ ] ]    we mention also that the case @xmath35 can only occur when the random variable @xmath36 is bounded",
    ".    in @xcite and @xcite a characterization of strong disorder has been obtained in term of localization of the polymer chain : we cite the following result ( * ? ? ?",
    "* theorem 2.1 )    if @xmath37 and @xmath38 are two i.i.d .",
    "polymer chains , we have @xmath39 moreover if @xmath40 there exists a constant @xmath41 ( depending on @xmath13 and the law of the environment ) such that for @xmath42    one can notice that has a very strong meaning in term of trajectory localization when @xmath28 decays exponentially : it implies that two independent polymer chains tend to share the same endpoint with positive probability . for this reason we introduce now the notion of free energy , we refer to ( * ? ? ?",
    "* proposition 2.5 ) and ( * ? ? ? * theorem 3.2 ) for the following result :    the quantity @xmath43 exists @xmath6-a.s . , it is non - positive and non - random .",
    "we call it the _ free energy _ of the model , and we have @xmath44 moreover @xmath45 is non - increasing in @xmath13 .",
    "we stress that the inequality @xmath46 is the standard _ annealing",
    "_ bound . in view on , it is natural to say that _ very strong disorder _",
    "holds whenever @xmath47 .",
    "one can moreover define @xmath48 the critical value of @xmath13 for the free energy i.e.  : @xmath49 let us stress that , from the physicists viewpoint , @xmath48 is the natural critical point because it is a point of non - analyticity of the free energy ( at least if @xmath50 ) . in view of this definition , we obviously have @xmath51 .",
    "it is widely believed that @xmath52 , i.e.  that there exists no intermediate phase where we have _ strong disorder _ but not _ very strong disorder_. however , this is a challenging question : comets and vargas @xcite answered it in dimension @xmath0 by proving that @xmath53 . in this paper , we make their result more precise .",
    "moreover we prove that @xmath54 .",
    "the first aim of this paper is to sharpen the result of comets and vargas on the @xmath0-dimensional case .",
    "in fact , we are going to give a precise statement on the behavior of @xmath45 for small @xmath13 .",
    "our result is the following    [ pasgaussi ] when @xmath55 and the environment satisfies , there exist constants @xmath41 and @xmath56 ( depending on the distribution of the environment ) such that for all @xmath57 we have @xmath58 \\le p({\\beta})\\le -c { \\beta}^4.\\ ] ]    we believe that the logarithmic factor in the lower bound is an artifact of the method . in fact , by using replica - coupling , we have been able to get rid of it in the gaussian case .",
    "[ gaussi ] when @xmath55 and the environment is gaussian , there exists a constant @xmath41 such that for all @xmath59 .",
    "@xmath60    these estimates concerning the free energy give us some idea of the behavior of @xmath16 for small @xmath13 .",
    "indeed , carmona and hu in ( * ? ? ?",
    "* section 7 ) proved a relation between @xmath45 and the overlap ( although their notation differs from ours ) .",
    "this relation together with our estimates for @xmath45 suggests that , for low @xmath13 , the asymptotic contact fraction between independent polymers @xmath61 behaves like @xmath62 .",
    "the second result we present is that @xmath54 . as for the @xmath0-dimensional case , our approach yields an explicit bound on @xmath45 for @xmath13 close to zero .",
    "[ 1 + 2uplb ] when @xmath63 , there exist constants @xmath41 and @xmath64 such that for all @xmath65 , @xmath66 so that @xmath67 and @xmath9 is a point of non - analyticity for @xmath45 .    after the appearance of this paper as a preprint , the proof of the above result has been adapted by bertin @xcite to prove the exponential decay of the partition function for _ linear stochastic evolution _ in dimension @xmath30 , a model that is a slight generalisation of directed polymer in random environment .    unlike in the one dimensional case , the two bounds on the free energy provided by our methods do not match .",
    "we believe that the second moment method , that gives the lower bound is quite sharp and gives the right order of magnitude for @xmath68 . the method developped in @xcite to sharpen the estimate on the critical point shift for pinning models at marginality adapted to the context of directed polymer",
    "should be able to improve the result , getting @xmath69 for all @xmath59 for any @xmath70 .",
    "the various techniques we use have been inspired by ideas used successfully for another polymer model , namely the polymer pinning on a defect line ( see @xcite ) .",
    "however the ideas we use to establish lower bounds differ sensibly from the ones leading to the upper bounds . for this reason ,",
    "we present first the proofs of the upper bound results in section [ rough ] , [ onedim ] and [ twodim ] .",
    "the lower bound results are proven in section [ lb11 ] , [ dim11 ] and [ dim12 ] .    to prove the lower bound results",
    ", we use a technique that combines the so - called _ fractional moment method _ and change of measure .",
    "this approach has been first used for pinning model in @xcite and it has been refined since in @xcite . in section",
    "[ rough ] , we prove a non - optimal upper bound for the free energy in the case of gaussian environment in dimension @xmath0 to introduce the reader to this method . in section [ onedim ]",
    "we prove the optimal upper bound for arbitrary environment in dimension @xmath0 , and in section [ twodim ] we prove our upper bound for the free energy in dimension @xmath1 which implies that _ very strong disorder",
    "_ holds for all @xmath13 .",
    "these sections are placed in increasing order of technical complexity , and therefore , should be read in that order .    concerning the lower ",
    "bounds proofs : section [ lb11 ] presents a proof of the lower bound of theorem [ pasgaussi ] .",
    "the proof combines the second moment method and a directed percolation argument . in section [ dim11 ]",
    "the optimal bound is proven for gaussian environment , with a specific gaussian approach similar to what is done in @xcite . in section [ dim12 ]",
    "we prove the lower bound for arbitrary environment in dimension @xmath1 .",
    "these three parts are completely independent of each other .",
    "before going into the core of the proof , we want to present here the starting step that will be used repeatedly thourough sections [ rough ] , [ onedim ] and [ twodim ] .",
    "we want to find an upper  bound for the quantity @xmath71 however , it is not easy to handle the expectation of a @xmath72 , for this reason we will use the following trick . let @xmath73 , we have ( by jensen inequality )    @xmath74    hence    @xmath75    we are left with showing that the fractional moment @xmath76 decays exponentially which is a problem that is easier to handle .      to introduce the reader to the general method used in this paper , combining fractional moment and change of measure , we start by proving a non  optimal result for the free  energy , using a finite volume criterion . as",
    "a more complete result is to be proved in the next section , we restrict to the gaussian case here .",
    "the method used here is based on the one of @xcite , marorizing the free energy of the directed polymer by the one of multiplicative cascades .",
    "let us mention that is has bee shown recently by liu and watbled @xcite that this majoration is in a sense optimal , they obtained this result by improving the concentration inequality for the free energy .",
    "the idea of combining fractional moment with change of measure and finite volume criterion has been used with success for the pinning model in @xcite",
    ".    [ lb ] there exists a constant @xmath41 such that for all @xmath59    @xmath77    for @xmath78 sufficiently small , we choose @xmath79 to be equal to @xmath80 for a fixed constant @xmath81 ( here and thourough the paper for @xmath82 , @xmath83 , respectively @xmath84 will denote the upper , respectively the lower integer part of @xmath85 ) and define @xmath86 .",
    "for @xmath87 we define @xmath88\\right){\\mathbf{1}}_{\\{s_n = x\\}}.\\ ] ] note that @xmath89 .",
    "we use a statement which can be found in the proof of theorem 3.3 . in @xcite :    @xmath90^{\\theta } \\quad \\forall m\\in { \\mathbb{n}}.\\ ] ]    this combined with implies that    @xmath91^{\\theta}.\\ ] ]    hence , to prove the result , it is sufficient to show that    @xmath92^{\\theta}\\le e^{-1 } , \\label{eq : aprouver}\\ ] ]    for our choice of @xmath93 and @xmath79 .    in order to estimate @xmath94^{\\theta}$ ] we use an auxiliary measure @xmath95 .",
    "the region where the walk @xmath96 is likely to go is @xmath97\\times[-c_2\\sqrt{n},c_2\\sqrt{n}]\\right)\\cap { \\mathbb{n}}\\times { \\mathbb{z}}$ ] where @xmath98 is a big constant .",
    "we define @xmath95 as the measure under which the @xmath99 are still independent gaussian variables with variance @xmath29 , but such that @xmath100 where @xmath101 .",
    "this measure is absolutely continuous with respect to @xmath6 and    @xmath102\\right).\\ ] ]    then we have for any @xmath87 , using the hlder inequality we obtain ,    @xmath103={\\widetilde}q \\left[\\frac{{\\,\\text{\\rm d}}q}{{\\,\\text{\\rm d}}{\\widetilde}q}\\left(w_n(x)\\right)^\\theta\\right]\\le \\left({\\widetilde}q \\left[\\left(\\frac{{\\,\\text{\\rm d}}q}{{\\,\\text{\\rm d}}{\\widetilde}q}\\right)^{\\frac{1}{1-\\theta}}\\right]\\right)^{1-\\theta}\\left ( { \\widetilde}q w_n(x)\\right)^{\\theta}.\\ ] ]    the first term on the right - hand side can be computed explicitly and is equal to    @xmath104    where the last inequality is obtained by replacing @xmath105 and @xmath93 by their values ( recall @xmath106 ) . therefore combining and we get that    @xmath107    to bound the right  hand side , we first get rid of the exponent @xmath93 in the following way :    @xmath108    if @xmath79 is sufficiently large ( i.e. , @xmath13 sufficiently small ) the first term on the right - hand side is smaller than @xmath109 so that    @xmath110    we are left with showing that the expectation of @xmath111 with respect to the measure @xmath95 is small .",
    "it follows from the definition of @xmath95 that    @xmath112    and therefore    @xmath113    one can choose @xmath98 such that the first term is small , and the second term is equal to @xmath114 that can be arbitrarily small by choosing @xmath81 large compared to @xmath115 . in that case is satisfied and we have @xmath116 for small enough @xmath13 .",
    "the upper bound we found in the previous section is not optimal , and can be improved by replacing the finite volume criterion by a more sophisticated coarse graining method .",
    "the technical advantage of the coarse graining we use , is that we will not have to choose the @xmath93 of the fractional moment close to @xmath29 as we did in the previous section and this is the way we get rid of the extra @xmath72 factor we had .",
    "the idea of using this type of coarse graining for the copolymer model appeared in @xcite and this has been a substantial source of inspiration for this proof .",
    "we will prove the following result first in the case of gaussian environment , and then adapt the proof to general environment .",
    "let @xmath79 be the smallest squared integer bigger than @xmath117 ( if @xmath13 is small we are sure that @xmath118 ) . the number @xmath79 will be used in the sequel of the proof as a scaling factor .",
    "let @xmath119 be fixed ( say @xmath120 ) . we consider a system of size @xmath121 ( where @xmath122 is meant to tend to infinity ) .",
    "let @xmath123 denote the interval @xmath124 .",
    "in order to estimate @xmath76 we decompose @xmath28 according to the contribution of different families path :    @xmath125    where    @xmath126.\\ ] ]    = 6.5 cm [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ]    then , we apply the inequality @xmath127 ( which holds for any finite or countable collection of positive real numbers ) to this decomposition and average with respect to @xmath6 to get ,    @xmath128    in order to estimate @xmath129 , we use an auxiliary measure as in the previous section .",
    "the additional idea is to make the measure change depend on @xmath130 .    for every @xmath131",
    "we define the set @xmath132 as @xmath133 where @xmath134 is equal to zero .",
    "note that for big values of @xmath79 and @xmath122    @xmath135    we define the measure @xmath136 the measure under which the @xmath137 are independent gaussian variables with variance @xmath29 and mean @xmath138 where @xmath139 .",
    "= 6.5 cm [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ]    the law @xmath136 is absolutely continuous with respect to @xmath6 and its density is equal to    @xmath140\\right).\\ ] ]    using hlder inequality with this measure as we did in the previous section , we obtain    @xmath141={\\widetilde}q_{y } \\left[\\frac{{\\,\\text{\\rm d}}q}{{\\,\\text{\\rm d}}{\\widetilde}q_{y}}{\\widecheck}w_{(y_1,y_2,\\dots , y_m)}^{\\theta}\\right]\\\\   \\le { \\widetilde}q_{y}\\left ( \\left[\\left(\\frac{{\\,\\text{\\rm d}}q}{{\\,\\text{\\rm d}}{\\widetilde}q_{y}}\\right)^{\\frac{1}{1-\\theta}}\\right]\\right)^{1-\\theta}\\left ( { \\widetilde}q_{y } { \\widecheck}w_{(y_1,\\dots , y_m)}\\right)^{\\theta } \\label{eq : hhol}.\\end{gathered}\\ ] ]    the value of the first term can be computed explicitly    @xmath142\\right)^{1-\\theta}=\\exp\\left(\\frac{\\ # j_y\\theta{\\delta}_n^2}{2(1-\\theta)}\\right)\\le \\exp(3 m ) , \\label{eq : dens}\\ ] ]    where the upper bound is obtained by using the definition of @xmath105 , and the fact that @xmath120 .    now we compute the second term    @xmath143\\}}.\\ ] ]    we define @xmath144 equation implies that ( recall that @xmath145 is the law of the simple random walk starting from @xmath85 , and that we set @xmath146 @xmath147 combining this with , and we have    @xmath148.\\ ] ]    if the quantity in the square brackets is smaller than @xmath149 , by equation we have @xmath150 .",
    "therefore , to complete the proof it is sufficient to show that @xmath151 is small . to reduce the problem to the study of a finite sum , we observe ( using some well known result on the asymptotic behavior of random walk ) that given @xmath152 we can find @xmath153 such that    @xmath154    to estimate the remainder of the sum we use the following trivial bound    @xmath155    then we get rid of the @xmath156 in the sum by observing that if a walk starting from @xmath85 makes a step in @xmath157 , the walk with the same increments starting from @xmath9 will make the same step in @xmath158 ( recall ) .",
    "@xmath159 now we are left with something similar to what we encountered in the previous section    @xmath160    if @xmath161 is chosen large enough , the first term can be made arbitrarily small by choosing @xmath161 large , and the second is equal to @xmath162 and can be made also arbitrarily small if @xmath163 is chosen large enough once @xmath161 is fixed .",
    "an appropriate choice of constant and the use of and can leads then to    @xmath164    this combined with completes the proof .    in the case of a general environment",
    ", some modifications have to be made in the proof above , but the general idea remains the same . in the change of measure one",
    "has to change the shift of the environment in @xmath132 by an exponential tilt of the measure as follow    @xmath165\\right).\\ ] ]    the formula estimating the cost of the change of measure becomes    @xmath166\\right)\\le \\exp(2 m),\\ ] ]    where the last inequality is true if @xmath167 is small enough if we consider that @xmath120 and use the fact that @xmath168 ( @xmath169 has @xmath9 mean and unit variance ) .",
    "the next thing we have to do is to compute the effect of this change of measure in this general case , i.e.  find an equivalent for .",
    "when computing @xmath170 , the quantity @xmath171\\ ] ] appears instead of @xmath172 . using twice the mean value theorem , one gets that there exists @xmath173 and @xmath174 in @xmath175 such that    @xmath176=-{\\beta}{\\delta}_n{\\lambda}''(-h{\\delta}_n+h'{\\beta}).\\ ] ]    and as @xmath169 has unit variance @xmath177 .",
    "therefore if @xmath13 and @xmath105 are chosen small enough , the right - hand side of the above is less than @xmath178 .",
    "so that can be replaced by    @xmath179\\}}.\\ ] ]    the remaining steps follow closely the argument exposed for the gaussian case .",
    "in this section , we prove the main result of the paper : very strong disorder holds at all temperature in dimension @xmath30 .",
    "the proof is technically quite involved .",
    "it combines the tools of the two previous sections with a new idea for the change a measure : changing the covariance structure of the environment .",
    "we mention that this idea was introduced recently in @xcite to deal with the _ marginal disorder _ case in pinning model .",
    "we choose to present first a proof for the gaussian case , where the idea of the change a measure is easier to grasp .    before starting ,",
    "we sketch the proof and how it should be decomposed in different steps :    * we reduce the problem by showing that it is sufficient to show that for some real number @xmath119 , @xmath76 decays exponentially with @xmath12 .",
    "* we use a coarse graining decomposition of the partition function by splitting it into different contributions that corresponds to trajectories that stays in a large corridor .",
    "this decomposition is similar to the one used in section [ onedim ] . *",
    "to estimate the fractional moment terms appearing in the decomposition , we change the law of the environment around the corridors corresponding to each contribution .",
    "more precisely , we introduce negative correlations into the gaussian field of the environment .",
    "we do this change of measure in such a way that the new measure is not very different from the original one .",
    "* we use some basic properties of the random walk in @xmath180 to compute the expectation under the new measure .",
    "we fix @xmath79 to be the smallest squared integer bigger than @xmath181 for some large constant @xmath182 to be defined later , for small @xmath13 we have @xmath183 . the number @xmath79 will be used in the sequel of the proof as a scaling factor . for @xmath184 we define @xmath185\\times[b\\sqrt{n},(b+1)\\sqrt{n}-1]$ ] so that @xmath186 are disjoint and cover @xmath180 . for @xmath187",
    ", we decompose the normalized partition function @xmath28 into different contributions , very similarly to what is done in dimension one ( i.e.  decomposition ) , and we refer to the figure [ fig : wnn2 ] to illustrate how the decomposition looks like :    @xmath188    where @xmath189 \\right){\\mathbf{1}}_{\\left\\{s_{in}\\in i_{y_i},\\forall i= 1,\\dots , m \\right\\}}.\\ ] ] we fix @xmath119 and apply the inequality @xmath190 ( which holds for any finite or countable collection of positive real numbers ) to get    @xmath191    in order to estimate the different terms in the sum of the right  hand side in , we define some auxiliary measures @xmath136 on the the environment for every @xmath192 with @xmath193 .",
    "we will choose the measures @xmath194 absolutely continuous with respect to @xmath6 .",
    "we use hlder inequality to get the following upper bound :    @xmath195    now , we describe the change of measure we will use . recall that for the @xmath29-dimensional case we used a shift of the environment along the corridor corresponding to @xmath196 .",
    "the reader can check that this method would not give the exponential decay of @xmath28 in this case .",
    "instead we change the covariance function of the environment along the corridor on which the walk is likely to go by introducing some negative correlation .",
    "we introduce the change of measure that we use for this case . given @xmath197 we define @xmath122 blocks @xmath198}$ ] and @xmath132 their union ( here and in the sequel , @xmath199 denotes the @xmath200 norm on @xmath180 ) :    @xmath201    we fix the covariance the field @xmath169 under the law @xmath202 to be equal to    @xmath203 \\text { such that } ( i , z ) \\text { and } ( j , z')\\in b_k     \\\\      { \\mathbf{1}}_{\\{(i , z)=(j , z')\\ } } & \\text { otherwise , }    \\end{cases}\\end{split}\\ ] ]    where    @xmath204    we define",
    "@xmath205    one remarks that the so - defined covariance matrix @xmath206 is block diagonal with @xmath122 identical blocks which are copies of @xmath207 corresponding to the @xmath208 , @xmath209 $ ] , and just ones on the diagonal elsewhere .",
    "therefore , the change of measure we describe here exists if and only if @xmath207 is definite positive .",
    "the largest eigenvalue for @xmath210 is associated to a positive vector and therefore is smaller than @xmath211 for the sequel we choose @xmath79 such that the spectral radius of @xmath210 is less than @xmath212 so that @xmath207 is positive definite . with this setup",
    ", @xmath136 is well defined .",
    "the density of the modified measure @xmath202 with respect to @xmath6 is given by @xmath213 where @xmath214 for any matrix @xmath215 of @xmath216 with finite support .",
    "then we can compute explicitly the value of the second term in the right - hand side of @xmath217 note that the above computation is right if and only if @xmath218 is a definite positive matrix . since its eigenvalues are the same of those of @xmath219 , this holds for large @xmath79",
    "thanks to . using again the fact that @xmath206 is composed of @xmath122 blocks identical to @xmath207",
    ", we get from @xmath220 in order to estimate the determinant in the denominator , we compute the hilbert - schmidt norm of @xmath210 .",
    "one can check that for all @xmath79    @xmath221    we use the inequality @xmath222 for all @xmath223 and the fact that the spectral radius of @xmath224 is bounded by @xmath225 ( cf . ) to get that    @xmath226&=\\exp\\left({\\text{trace}}\\left(\\log\\left(i-\\frac{{\\widehat}v}{1-\\theta}\\right)\\right)\\right)\\ge \\exp\\left(-\\frac{\\| { \\widehat}v\\|^2}{(1-\\theta)^2}\\right)\\\\ & \\ge \\exp\\left(-\\frac{1}{(1-\\theta)^2}\\right ) .",
    "\\end{split}\\ ] ]    for the numerator , @xmath227 implies that that @xmath228 . combining this with and we get    @xmath229",
    "now that we have computed the term corresponding to the change of measure , we estimate @xmath230 under the modified measure ( just by computing the variance of the gaussian variables in the exponential , using )  :    @xmath231    replacing @xmath206 by its value we get that    @xmath232    now we do something similar to @xmath233 : for each `` slice '' of the trajectory @xmath234}$ ] , we bound the contribution of the above expectation by maximizing over the starting point ( recall that @xmath145 denotes the probability distribution of a random walk starting at @xmath85 ) . thanks to the conditioning , the starting point has to be in @xmath235 . using the translation invariance of the random walk ,",
    "this gives us the following ( @xmath236 stands for maximum ) :    @xmath237.\\end{gathered}\\ ] ]    for trajectories @xmath4 of a directed random - walk of @xmath79 steps , we define the quantity    @xmath238    combining with , and , we finally get    @xmath239^m.\\ ] ]    the exponential decay of @xmath76 ( with rate @xmath79 ) is guaranteed if we can prove that    @xmath240    is small .",
    "the rest of the proof is devoted to that aim .",
    "we fix some @xmath152 .",
    "asymptotic properties of the simple random walk , guarantees that we can find @xmath241 such that @xmath242 to estimate the rest of the sum , we use the following trivial and rough bound    @xmath243^{\\theta } \\le r^2 \\left[\\max_{x\\in i_0 } p_x \\exp\\left(-\\frac{{\\beta}^2}{2}g(s)\\right)\\right]^{\\theta}\\ ] ]    then we use the definition of @xmath244 to get rid of the @xmath156 by reducing the width of the zone where we have negative correlation :    @xmath245    we define @xmath246 .",
    "we get from the above that    @xmath247    one can make the first term of the right - hand side arbitrarily small by choosing @xmath248 large , in particular on can choose @xmath248 such that    @xmath249 } |s_n|\\ge ( c_6 - 1)\\sqrt{n}\\right\\}\\le ( { \\varepsilon}/r^2)^{\\frac{1}{\\theta}}.\\ ] ]    to bound the other term , we introduce the quantity    @xmath250    and the random variable @xmath251 ,    @xmath252    for any @xmath253 , we can find @xmath254 such that @xmath255 . we fix @xmath254 such that this holds for some good @xmath256 ( to be chosen soon ) , and by remarking that @xmath257 almost surely , we obtain ( using markov inequality )    @xmath258    moreover we can estimate @xmath259 getting that for @xmath79 large enough    @xmath260    using and we get    @xmath261    due to the choice of @xmath79 we have made ( recall @xmath262 ) , the second term is less than @xmath263 .",
    "we can choose @xmath256 , @xmath254 and @xmath182 such that , the right - hand side is less that @xmath264 .",
    "this combined with , , and allow us to conclude that    @xmath265    so that with a right choice for @xmath70 , implies    @xmath266    then allows us to conclude that @xmath150 .    the case of general environment does not differ very much from the gaussian case , but one has to a different approach for the change of measure in . in this proof , we will largely refer to what has been done in the gaussian case , whose proof should be read first .",
    "let @xmath267 be a large constant .",
    "one defines the function @xmath268 on @xmath269",
    "as to be @xmath270 recall the definitions and , and define @xmath271 function of the environment as    @xmath272    multiplying by @xmath271 penalizes by a factor @xmath273 the environment for which there is to much correlation in one block .",
    "this is a way of producing negative correlation in the environment . for the rest of the proof we use the notation @xmath274    we do a computation similar to to get    @xmath275\\le",
    "\\left(q\\left [ g_y({\\omega})^{-\\frac{\\theta}{1-\\theta}}\\right]\\right)^{1-\\theta}\\left ( q\\left [ g_y({\\omega}){\\widecheck}w_{(y_1,\\dots , y_n)}\\right]\\right)^{\\theta}.\\ ] ]    the block structure of @xmath271 allows to express the first term as a power of @xmath122 .",
    "@xmath276=\\left(q\\left[\\exp\\left(-\\frac{\\theta}{1-\\theta}f_k\\left(u_1\\right)\\right)\\right]\\right)^m.\\ ] ]    equation says that @xmath277 so that @xmath278 and hence @xmath279\\\\ \\le 1+\\exp\\left(-2k^2+\\frac{\\theta}{1-\\theta}k\\right)\\le 2,\\end{gathered}\\ ] ] if @xmath267 is large enough . we are left with estimating the second term @xmath280=p q g_y({\\omega})\\exp\\left(\\sum_{i=1}^{nm}[{\\beta}{\\omega}_{i , s_i}-{\\lambda}({\\beta } ) ] \\right){\\mathbf{1}}_{\\{s_{kn}\\in i_{y_k},\\forall k=1\\dots m\\}}.\\ ] ] for a fixed trajectory of the random walk @xmath4 , we consider @xmath281 the modified measure on the environment with density    @xmath282 \\right).\\ ] ]    under this measure    @xmath283    as @xmath284 has zero - mean and unit variance under @xmath6 , implies @xmath285 around zero and that @xmath286 for all @xmath287 if @xmath13 is small enough .",
    "moreover @xmath281 is a product measure , i.e.  the @xmath288 are independent variables under @xmath289 . with this notation",
    "becomes    @xmath290{\\mathbf{1}}_{\\{s_{kn}\\in i_{y_k},\\forall k=1,\\dots , m \\}}.\\ ] ]    as in the gaussian case , one wants to bound this by a product using the block structure . similarly to , we use translation invariance to get the following upper bound    @xmath291    using this in with the bound we get the inequality    @xmath292^{\\theta}\\right)^m\\!\\!\\!\\!.\\ ] ]    therefore to prove exponential decay of @xmath76 , it is sufficient to show that    @xmath293^{\\theta}\\ ] ]    is small . as seen in the gaussian case ( cf .",
    ", ) , the contribution of @xmath294 far from zero can be controlled and therefore it is sufficient for our purpose to check @xmath295 for some small @xmath256 . similarly to , we force the walk to stay in the zone where the environment is modified by writing @xmath296}|s_i|\\ge ( c_6 - 1)\\sqrt{n}\\}\\\\ + \\max_{x\\in i_0 } p_x { \\widebar}q_s \\exp\\left(f_k\\left(u_1\\right)\\right){\\mathbf{1}}_{\\{|s_n - s_0|\\le ( c_6 - 1)\\sqrt{n}\\}}.\\end{gathered}\\ ] ] the first term is smaller than @xmath297 if @xmath248 is large enough .",
    "to control the second term , we will find an upper bound for    @xmath298}|s_i - s_0|\\le ( c_6 - 1)\\sqrt{n}\\}},\\ ] ]    which is uniform in @xmath299 .",
    "what we do is the following : we show that for most trajectories @xmath4 the term in @xmath268 has a large mean and a small variance with respect to @xmath289 so that @xmath300 with large @xmath281 probability .",
    "the rest will be easy to control as the term in the expectation is at most one .",
    "the expectation of @xmath301 under @xmath281 is equal to @xmath302 when the walk stays in the block @xmath303 we have ( using definition ) @xmath304 the distribution of @xmath251 under @xmath145 is the same for all @xmath305 .",
    "it has been shown earlier ( cf .   and ) , that if @xmath254 is chosen large enough , @xmath306 as @xmath307 if @xmath13 is small , if @xmath182 is large enough ( recall @xmath262 ) , this together with gives .",
    "@xmath308}|s_i - s_0|\\le ( c_6 - 1)\\sqrt{n}\\bigg\\}\\le \\frac{{\\delta}}{6}.\\ ] ] to bound the variance of @xmath301 under @xmath281 , we decompose the sum    @xmath309    and hence ( using the fact that @xmath310 ) .",
    "@xmath311 where we used that @xmath312 ( which is true for @xmath13 small enough ) .",
    "the last term is less than @xmath313 thanks to , so that we just have to control the first one . independently of the choice of @xmath314",
    "we have the bound    @xmath315    moreover it is also easy to check that    @xmath316    ( these two bounds follow from the definition of @xmath317 :  ) .",
    "therefore @xmath318\\max_{(j , z)\\in b_1}\\sum_{1\\le i\\le n}v_{(i , s_i),(j , z')}\\le 1.\\ ] ] injecting this into guaranties that for @xmath13 small enough    @xmath319    with chebyshev inequality , if @xmath267 has been chosen large enough and @xmath320 we have    @xmath321    hence combining with gives @xmath322}|s_i - s_0|\\le ( c_6 - 1)\\sqrt{n}\\right\\}\\le { \\delta}/3.\\ ] ] we use this in to get    @xmath323    so that our result is proved provided that @xmath267 has been chosen large enough .",
    "in this section we prove the lower bound for the free - energy in dimension @xmath29 in arbitrary environment .",
    "to do so we apply the second moment method to some quantity related to the partition function , and combine it with a percolation argument .",
    "the idea of the proof was inspired by a study of a polymer model on hierarchical lattice @xcite where this type of coarse - graining appears naturally .",
    "[ th : prop ] there exists a constant @xmath324 such that for all @xmath59 we have @xmath325    we use two technical lemmas to prove the result .",
    "the first is just a statement about scaling of the random walk , the second is more specific to our problem .",
    "[ th : lem1 ] there exists an a constant @xmath326 such that for large even squared integers @xmath79 , @xmath327    [ th : lem2 ] for any @xmath152 we can find a constant @xmath328 and @xmath64 such that for all @xmath329 , for every even squared integer @xmath330 we have @xmath331<{\\varepsilon}.\\ ] ]    let @xmath79 be some fixed integer and define    @xmath332    which corresponds to the contribution to the partition function @xmath111 of paths with fixed end point @xmath333 staying within a cell of width @xmath333 , with the specification the environment on the last site is not taken in to account .",
    "@xmath334 depends only of the value of the environment @xmath169 in this cell ( see figure [ fig : restr ] ) .",
    "= 4.5 cm [ c]o [ c]@xmath79 [ c]@xmath333    one also defines the following quantities for @xmath335 :    @xmath336}{\\mathbf{1}}_{\\{s_n=\\sqrt{(y+1)n } , 0<s_i - y \\sqrt n<\\sqrt{n } \\text { for } 0<i < n\\}}\\right],\\\\   { \\widebar}w_i^{(y , y-1)}&:=p_{\\sqrt{n}y}\\left[\\ e^{\\sum_{k=1}^{n-1}\\left[{\\beta}{\\omega}_{in+k , s_k}-{\\lambda}({\\beta})\\right]}{\\mathbf{1}}_{\\{s_n=(y-1)\\sqrt{n } , -\\sqrt{n}<s_i - y\\sqrt{n}<0 \\text { for } 0<i < n\\}}\\right ]",
    ". \\end{split}\\ ] ]    which are random variables that have the same law as @xmath334 .",
    "moreover because of independence of the environment in different cells , one can see that @xmath337 is a family of independent variables .",
    "let @xmath187 be a large integer .",
    "we define @xmath338 as the set of path @xmath339,\\ |s_{in}-s_{(i-1)n}|=\\sqrt{n},\\ \\forall j\\in [ 1,n-1],\\   s_{(i-1)n+j}\\in \\left ( s_{(i-1)n},s_{in}\\right)\\},\\ ] ] where the interval @xmath340 is to be seen as @xmath341 if @xmath342 , and @xmath343 \\right\\ } .\\ ] ] we use the trivial bound    @xmath344,\\ ] ]    to get that    @xmath345    ( the exponential term is due to the fact the @xmath334 does not take into account to site in the top corner of each cell ) .",
    "the idea is of the proof is to find a value of @xmath79 ( depending on @xmath13 ) such that we are sure that for any value of @xmath122 we can find a path @xmath346 such that along the path the values of @xmath347 are not to low ( i.e. close to the expectation of @xmath334 ) and to do so , it seems natural to seek for a percolation argument .",
    "let @xmath348 be the critical exponent for directed percolation in dimension @xmath0 ( for an account on directed percolation see ( * ? ? ?",
    "* section 12.8 ) and references therein ) . from lemma",
    "[ th : lem2 ] and chebyshev inequality , one can find a constant @xmath349 and @xmath64 such that for all @xmath350 and @xmath65 . @xmath351",
    "we choose @xmath79 to be the biggest squared even integer that is less than @xmath352 .",
    "( in particular have @xmath353 if @xmath13 small enough ) .",
    "as shown in figure [ fig : wnnn ] , we associate to our system the following directed percolation picture . for all @xmath354",
    "is even :    * if @xmath355 , we say that the edge linking the opposite corners of the corresponding cell is open . *",
    "if @xmath356 , we say that the same edge is closed .    equation and the fact the considered random variables are independent assures that with positive probability there exists an infinite directed path starting from zero .",
    "= 6.5 cm [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ] [ c ]    when there exists an infinite open path is linking zero to infinity exists , we can define the highest open path in an obvious way .",
    "let @xmath357 denotes this highest path . if @xmath122 is large enough , by law of large numbers we have that with a probability close to one , @xmath358",
    "\\ge -2m{\\lambda}({\\beta}).\\ ] ]    using this and and the percolation argument with we finally get that with a positive probability which does not depend on @xmath122 we have    @xmath359^m.\\ ] ]    taking the @xmath72 and making @xmath122 tend to infinity this implies that    @xmath360\\ge -\\frac{c}{n}\\log n.\\ ] ]    for some constant @xmath41 , if @xmath79 is large enough ( we used lemma [ th : lem1 ] to get the last inequality .",
    "the result follows by replacing @xmath79 by its value .",
    "let @xmath79 be square and even .",
    "@xmath361 , @xmath362 denote the first hitting time of @xmath363 by the random walk @xmath4 ( when @xmath364 it denotes the return time to zero ) .",
    "we have @xmath365 where the second equality is obtained with the strong markov property used for @xmath366 , and the reflexion principle for the random walk .",
    "the last line is equal to @xmath367 } s_k\\in [ \\sqrt{n}/2,\\sqrt{n})|t_0=n\\}p\\{t_0=n\\}.\\ ] ] we use here a variant of donsker s theorem , for a proof see ( * ? ? ?",
    "* theorem 2.6 ) .",
    "the process @xmath368\\ ] ] converges in distribution to the normalized brownian excursion in the space @xmath369,{\\mathbb{r}})$ ] .",
    "we also know that ( see for example ( * ? ?",
    "? * proposition a.10 ) ) for @xmath79 even @xmath370 . therefore , from we have @xmath371 } { \\bf e}_t\\in ( 1/2,1)\\right]+o(n^{-3/2}).\\end{gathered}\\ ] ] where @xmath372 denotes the normalized brownian excursion , and @xmath373 its law .",
    "let @xmath13 be fixed and small enough , and @xmath79 be some squared even integer which is less than @xmath374 .",
    "we will fix the value @xmath328 independently of @xmath13 later in the proof , and always consider that @xmath13 is sufficiently small . by a direct computation the variance of    @xmath375\\right)\\bigg| \\",
    "s_n=\\sqrt{n } , 0<s_i<\\sqrt{n } \\text { for } 0<i < n \\right]\\ ] ]    is equal to    @xmath376 - 1.\\ ] ]    where    @xmath377    and @xmath378 ( recall that @xmath379 ) , and @xmath380 , @xmath381 denotes two independent random walk with law denoted by @xmath382 . from this",
    "it follows that if @xmath79 is small the result is quite straight  forward",
    ". we will therefore only be interested in the case of large @xmath79 ( i.e.  bounded away from zero by a large fixed constant ) .",
    "we define @xmath383 the set where the walks meet ( it can be written as an increasing sequence of integers ) . by the markov property , the random variables @xmath384 are i.i.d .",
    ", we say that @xmath385 is a _",
    "renewal sequence_.    we want to bound the probability that the renewal sequence @xmath385 has too many returns before times @xmath386 , in order to estimate .",
    "to do so , we make the usual computations with laplace transform .    from @xcite , we know that @xmath387 thanks to the the local central limit theorem for the simple random walk , we know that for large @xmath79 @xmath388 so that we can get from that when @xmath85 is close to zero @xmath389 we fix @xmath390 such that @xmath391 for all @xmath392 . for any @xmath393 we have    @xmath394|\\ge k\\}=p^{\\otimes 2}\\{\\tau_k\\le n-1\\}&\\le \\exp((n-1)x ) p^{\\otimes 2 } \\exp ( -\\tau_k x)\\\\ & \\le \\exp\\left[nx+k \\log p^{\\otimes 2}\\exp(-x\\tau_1)\\right ] .",
    "\\end{split}\\ ] ]    for any @xmath395 one can choose @xmath396 in the above and use the definition of @xmath390 to get that    @xmath397|\\ge k\\}\\le \\exp\\left(-k^2/(32   n)\\right).\\ ] ]    in the case where @xmath398 we simply bound the quantity by    @xmath397|\\ge k\\}\\le \\exp\\left(k_0 ^ 2/(32 n)\\right)\\le \\exp\\left(-n x_0/4\\right).\\ ] ]    by lemma , if @xmath79 is large enough @xmath399 a trivial bound on the conditioning gives us    @xmath400|\\ge k \\ \\big| \\",
    "a_n \\right)&\\le\\min\\left(1,2c_{rw}^{-2 } n^3\\exp\\left(-k^2/(32 n)\\right)\\right ) \\text { if } k\\le k_0,\\\\   p^{\\otimes 2}\\left(|\\tau\\cap [ 1,n-1]|\\ge k \\",
    "\\right)&\\le 2c_{rw}^{-2}n^{3 } \\exp\\left(-n x_0/4\\right ) \\text { otherwise}. \\end{split}\\ ] ]    we define @xmath401 .",
    "the above implies that for @xmath79 large enough we have    @xmath402|\\ge k \\ \\big| \\ a_n \\right)&\\le 1 \\text { if } k\\le k_1 ,",
    "\\\\ p^{\\otimes 2}\\left(|\\tau\\cap [ 1,n-1]|\\ge k",
    "\\ \\big| \\ a_n \\right)&\\le",
    "\\exp\\left(-k^2/(64 n)\\right )",
    "\\text { if } k_1\\le k\\le k_0,\\\\   p^{\\otimes 2}\\left(|\\tau\\cap [ 1,n-1]|\\ge k \\ \\big| \\ a_n \\right)&\\le\\exp\\left(-n x_0/8\\right ) \\text { otherwise}. \\end{split}\\ ] ]    now we are ready to bound .",
    "integration by part gives ,    @xmath403|\\right)\\ \\big| \\ a_n\\right]-1\\\\ & \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad={\\gamma}({\\beta})\\int_{0}^{\\infty}\\exp({\\gamma}({\\beta } ) x)p^{\\otimes 2}\\left(|\\tau\\cap [ 1,n-1]|\\ge x \\",
    "a_n\\right){\\,\\text{\\rm d}}x .",
    "\\end{split}\\ ] ]    we split the right - hand side in three part corresponding to the three different bounds we have in : @xmath404 $ ] , @xmath405 $ ] and @xmath406 $ ] .",
    "it suffices to show that each part is less than @xmath407 to finish the proof .",
    "the first part is    @xmath408|\\ge x\\ \\big| \\",
    "\\le { \\gamma}({\\beta})k_1\\exp({\\gamma}({\\beta})k_1).\\ ] ]    one uses that @xmath409 and @xmath410 to get that for @xmath13 small enough and @xmath79 large enough if @xmath411 is well chosen we have @xmath412 so that @xmath413 .",
    "+ we use our bound for the second part of the integral to get    @xmath414|\\ge x\\ \\big| \\",
    "d}}x\\\\ & \\quad\\le { \\gamma}({\\beta})\\int_{0}^{\\infty}\\exp\\left({\\gamma}({\\beta})x - x^2/(64 n)\\right){\\,\\text{\\rm d}}x = \\int_{0}^{\\infty}\\exp\\left(x-\\frac{x^2}{64 n { \\gamma}({\\beta})^2}\\right){\\,\\text{\\rm d}}x . \\end{split}\\ ] ]    replacing @xmath79 by its value , we see that the term that goes with @xmath415 in the exponential can be made arbitrarily large , provided that @xmath411 is small enough .",
    "in particular we can make the left - hand side less than @xmath407 .",
    "+ finally , we estimate the last part    @xmath416|\\ge x \\ \\big| \\",
    "a_n\\right){\\,\\text{\\rm d}}x\\\\ & \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad \\le { \\gamma}({\\beta})\\int_{0}^{n}\\exp({\\gamma}({\\beta})x - n x_0/8){\\,\\text{\\rm d}}x = n\\exp(-[{\\gamma}({\\beta})-x_0/8]n ) .",
    "\\end{split}\\ ] ]    this is clearly less than @xmath407 if @xmath79 is large and @xmath13 is small .",
    "in this section we use the method of replica - coupling that is used for the disordered pinning model in @xcite to derive a lower bound on the free energy .",
    "the proof here is an adaptation of the argument used there to prove disorder irrelevance .",
    "the main idea is the following : let @xmath417 denotes the renormalized partition function for inverse temperature @xmath13 .",
    "a simple gaussian computation gives    @xmath418    where @xmath37 and @xmath38 are two independent random walk under the law @xmath382 .",
    "this implies that for small values of @xmath13 ( by the equality of derivative at @xmath419 ) ,    @xmath420    this tends to make us believe that    @xmath421    however , things are not that simple because is only valid for fixed @xmath12 , and one needs some more work to get something valid when @xmath12 tends to infinity .",
    "the proofs aims to use convexity argument and simple inequalities to be able to get the inequality    @xmath422    the fact that convexity is used in a crucial way make it quite hopeless to get the other inequality using this method .",
    "let use define for @xmath13 fixed and @xmath423 $ ]    @xmath424\\right),\\ ] ]    and for @xmath425 @xmath426\\right).\\ ] ] one can notice that @xmath427 and @xmath428 ( recall the definition of @xmath429 ) , so that @xmath430 is an interpolation function . via the gaussian integration by par formula    @xmath431    valid ( if @xmath169 is a centered standard gaussian variable ) for every differentiable functions such that @xmath432 , one finds    @xmath433\\right){\\mathbf{1}}_{\\left\\{s_j = z\\right\\}}}{p\\exp\\left(\\sum_{i=1}^n \\left[\\sqrt{t}{\\beta}{\\omega}_{i , s_i}-\\frac{t{\\beta}^2}{2}\\right]\\right)}\\right)^2 \\\\ & = -\\frac{{\\beta}^2}{2n}q \\left(\\mu^{(\\sqrt{t}{\\beta})}_n\\right)^{\\otimes 2 } \\left[\\sum_{i=1}^n { \\mathbf{1}}_{\\{s_i^{(1)}=s_i^{(2)}\\}}\\right ] .",
    "\\end{split}\\ ] ]    this is ( up to the negative multiplicative constant @xmath434 ) the expected overlap fraction of two independent replicas of the random ",
    "walk under the polymer measure for the inverse temperature @xmath435 .",
    "this result has been using it formula in ( * ? ? ?",
    "* section 7 ) .",
    "+ for notational convenience , we define    @xmath436.\\ ] ]    we use gaussian integration by part again , for @xmath437 :    @xmath438    the above implies that for every @xmath423 $ ] and @xmath425    @xmath439    comparing and , and using convexity and monotonicity of @xmath440 with respect to @xmath441 , and the fact that @xmath442 one gets    @xmath443    where in the last inequality we used @xmath444 and . integrating this inequality between @xmath9 and @xmath29 and recalling @xmath428",
    "we get    @xmath445    on the right - hand side of the above we recognize something related to pinning models .",
    "more precisely    @xmath446    where @xmath447 is the partition function of a homogeneous pinning system of size @xmath12 and parameter @xmath448 with underlying renewal process the sets of zero of the random walk @xmath449 .",
    "this is a well known result in the study of pinning model ( we refer to ( * ? ?",
    "* section 1.2 ) for an overview and the results we cite here ) that    @xmath450    where @xmath451 denotes the free energy of the pinning model .",
    "moreover , it is also stated @xmath452 then passing to the limit in ends the proof of the result for any constant strictly bigger that @xmath453 .",
    "the technique used in the two previous sections could be adapted here to prove the results but in fact it is not necessary . because of the nature of the bound we want to prove in dimension @xmath30 ( we do not really track the best possible constant in the exponential ) , it will be sufficient here to control the variance of @xmath111 up to some value , and then the concentration properties of @xmath454 to get the result . the reader can check than using the same method in dimension @xmath29 does not give the right power of @xmath13 .              as the above quantity is increasing in @xmath79 , it will be enough to prove the result for @xmath79 large . for technical convenience",
    "we choose to prove the result for @xmath465 ( recall @xmath378 ) which does not change the result since @xmath410 .",
    "the result we want to prove seems natural since we know that @xmath466 converges to an exponential variable ( see e.g.  @xcite ) , and @xmath467 .",
    "however , convergence of the right  hand side of requires the use of the dominated convergence theorem , and the proof of the domination hypothesis is not straightforward .",
    "it could be extracted from the proof of the large deviation result in @xcite , however we include a full proof of convergence here for the sake of completeness .      to prove the result , we compute bounds on the probability of having too many point before @xmath79 in the renewal @xmath385 . as in the @xmath29 dimensional case , we use laplace transform to do so . from @xcite , we know that                  let @xmath390 be such that for any @xmath392 , @xmath472 . for @xmath363 such that @xmath473",
    ", we replace @xmath85 by @xmath474 in to get @xmath475|\\ge k\\}\\le \\exp \\left(\\frac{k}{\\log(n / k)}-\\frac{3 k}{\\log\\left[k/(n\\log n / k)\\right]}\\right)\\le \\exp\\left(-\\frac{k}{\\log(n / k)}\\right),\\ ] ] where the last inequality holds if @xmath476 is small enough .",
    "we fix @xmath477 for some small @xmath256 .",
    "we get that @xmath478|\\ge k\\}&\\le \\exp\\left(-\\frac{k}{\\log(n / k)}\\right ) \\quad \\text{if } k\\le k_0\\\\     p^{\\otimes 2}\\{|\\tau\\cap [ 1,n]|\\ge k\\}&\\le \\exp\\left(-\\frac{k_0}{\\log(n / k_0)}\\right)=\\exp\\left(-\\frac{{\\delta}n}{\\log ( 1/{\\delta})}\\right ) \\quad \\text{if } k\\ge k_0 . \\end{split}\\ ] ] we are ready to bound .",
    "we remark that using integration by part we obtain            @xmath481|\\ge x){\\,\\text{\\rm d}}x\\le",
    "\\int_{1}^{{\\delta}n}{\\gamma}({\\beta})\\exp\\left({\\gamma}({\\beta})x-\\frac{x}{\\log(n / x)}\\right){\\,\\text{\\rm d}}x\\\\ \\le \\int_{1}^{{\\delta}n}{\\gamma}({\\beta})\\exp\\left({\\gamma}({\\beta})x-\\frac{{\\gamma}({\\beta}){\\beta}x}{c_{{\\varepsilon}}}\\right)\\le \\frac{c_{{\\varepsilon}}}{1-c_{{\\varepsilon}}}.\\end{gathered}\\ ] ]    this is less that @xmath407 if @xmath328 is chosen appropriately .",
    "the last part to bound is @xmath482|\\ge x)\\le n{\\gamma}({\\beta})\\exp\\left({\\gamma}({\\beta})n-\\frac{{\\delta}n}{\\log 1/{\\delta}}\\right)\\le { \\varepsilon}/3,\\ ] ] where the last inequality holds if @xmath79 is large enough , and @xmath13 is small enough .    by a martingale method that one can find a constant @xmath483 such that @xmath484 ( see ( * ? ? ?",
    "* proposition 2.5 ) and its proof for more details ) .",
    "+ therefore chebyshev inequality gives @xmath485 using lemma [ th : lemmvar ] and chebyshev inequality again , we can find a constant @xmath486 such that for small @xmath13 and @xmath487 we have @xmath488 this combined with implies that          the author is very grateful to giambattista giacomin for numerous suggestions and precious help for the writing of this paper , to francesco caravenna for the proof of lemma [ th : lem1 ] and to fabio toninelli and francis comets for enlightening discussions .",
    "the author also acknowledges the support of anr , grant polintbio ."
  ],
  "abstract_text": [
    "<S> we study the free energy of the directed polymer in random environment model in dimension @xmath0 and @xmath1 . for dimension one </S>",
    "<S> , we improve the statement of comets and vargas in @xcite concerning very strong disorder by giving sharp estimates on the free energy at high temperature . in dimension two </S>",
    "<S> , we prove that very strong disorder holds at all temperatures , thus solving a long standing conjecture in the field . </S>",
    "<S> + 2000 _ mathematics subject classification : 82d60 , 60k37 , 82b44 _ </S>",
    "<S> +   + _ keywords : free energy , directed polymer , strong disorder , localization , fractional moment estimates , quenched disorder , coarse graining . _ </S>"
  ]
}