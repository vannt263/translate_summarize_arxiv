{
  "article_text": [
    "in this paper , we consider the task of monocular depth estimation_i.e .",
    "_ ,  recovering scene depth from a single color image .",
    "knowledge of a scene s three - dimensional ( 3d ) geometry can be useful in reasoning about its composition , and therefore measurements from depth sensors are often used to augment image data for inference in many vision , robotics , and graphics tasks .",
    "however , the human visual system can clearly form at least an approximate estimate of depth in the absence of stereo and parallax cues_e.g .",
    "_ ,  from two - dimensional photographs  and it is desirable to replicate this ability computationally .",
    "depth information inferred from monocular images can serve as a useful proxy when explicit depth measurements are unavailable , and be used to refine these measurements where they are noisy or ambiguous .",
    "the 3d co - ordinates of a surface imaged by a perspective camera are physically ambiguous along a ray passing through the camera center .",
    "however , a natural image often contains multiple cues that can indicate aspects of the scene s underlying geometry .",
    "for example , the projected scale of a familiar object of known size indicates how far it is ; foreshortening of regular textures provide information about surface orientation ; gradients due to shading indicate both orientation and curvature ; strong edges and corners can correspond to convex or concave depth boundaries ; and occluding contours or the relative position of key landmarks can be used to deduce the coarse geometry of an object or the whole scene . while a given image may be rich in such geometric cues , it is important to note that these cues are present in different image regions , and each indicates a different aspect of 3d structure .",
    "we propose a neural network - based approach to monocular depth estimation that explicitly leverages this intuition .",
    "prior neural methods have largely sought to directly regress to depth  @xcite  with some additionally making predictions about smoothness across adjacent regions  @xcite , or predicting relative depth ordering between pairs of image points  @xcite .",
    "in contrast , we train a neural network with a rich distributional output space .",
    "our network characterizes various aspects of the local geometric structure by predicting values of a number of derivatives of the depth map  at various scales , orientations , and of different orders ( including the @xmath0 derivative , _",
    "i.e. _ ,  the depth itself)at every image location .    however , as mentioned above , we expect different image regions to contain cues informative towards different aspects of surface depth .",
    "therefore , instead of over - committing to a single value , our network outputs parameterized distributions for each derivative , allowing it to effectively characterize the ambiguity in its predictions .",
    "the full output of our network is then this set of multiple distributions at each location , characterizing coefficients in effectively an overcomplete representation of the depth map . to recover the depth map itself",
    ", we employ an efficient globalization procedure to find the single consistent depth map that best agrees with this set of local distributions .",
    "we evaluate our approach on the nyuv2 depth data set  @xcite , and find that it achieves state - of - the - art performance . beyond the benefits to the monocular depth estimation task itself , the success of our approach suggests that our network can serve as a useful way to incorporate monocular cues in more general depth estimation settings_e.g .",
    "_ ,  when sparse or noisy depth measurements are available .",
    "since the output of our network is distributional , it can be easily combined with partial depth cues from other sources within a common globalization framework .",
    "moreover , we expect our general approach  of learning to predict distributions in an overcomplete respresentation followed by globalization  to be useful broadly in tasks that involve recovering other kinds of scene value maps that have rich structure , such as optical or scene flow , surface reflectances , illumination environments , etc .",
    "interest in monocular depth estimation dates back to the early days of computer vision , with methods that reasoned about geometry from cues such as diffuse shading  @xcite , or contours  @xcite .",
    "however , the last decade has seen accelerated progress on this task  @xcite , largely owing to the availability of cheap consumer depth sensors , and consequently , large amounts of depth data for training learning - based methods .",
    "most recent methods are based on training neural networks to map rgb images to geometry  @xcite .",
    "et al . _",
    "@xcite set up their network to regress directly to per - pixel depth values , although they provide deeper supervision to their network by requiring an intermediate layer to explicitly output a coarse depth map .",
    "other methods  @xcite use conditional random fields ( crfs ) to smooth their neural estimates",
    ". moreover , the network in @xcite also learns to predict one aspect of depth structure , in the form of the crf s pairwise potentials .",
    "some methods are trained to exploit other individual aspects of geometric structure .",
    "et al . _",
    "@xcite train a neural network to output surface normals instead of depth ( eigen _ et al . _",
    "@xcite do so as well , for a network separately trained for this task ) . in a novel approach ,",
    "zoran _ et al . _",
    "@xcite were able to train a network to predict the relative depth ordering between pairs of points in the image  whether one surface is behind , in front of , or at the same depth as the other .",
    "however , their globalization scheme to combine these outputs was able to achieve limited accuracy at estimating actual depth , due to the limited information carried by ordinal pair - wise predictions .",
    "in contrast , our network learns to reason about a more diverse set of structural relationships , by predicting a large number of coefficients at each location .",
    "note that some prior methods  @xcite also regress to coefficients in some basis instead of to depth values directly .",
    "however , their motivation for this is to _ reduce _ the complexity of the output space , and use basis sets that have much lower dimensionality than the depth map itself .",
    "our approach is different  our predictions are distributions over coefficients in an _ overcomplete _ representation , motivated by the expectation that our network will be able to precisely characterize only a small subset of the total coefficients in our representation .",
    "our overall approach is similar to , and indeed motivated by , the recent work of chakrabarti _ et al . _",
    "@xcite , who proposed estimating a scene map ( they considered disparity estimation from stereo images ) by first using local predictors to produce distributional outputs from many overlapping regions at multiple scales , followed by a globalization step to harmonize these outputs",
    ". however , in addition to the fact that we use a neural network to carry out local inference , our approach is different in that inference is not based on imposing a restrictive model ( such as planarity ) on our local outputs .",
    "instead , we produce independent local distributions for various derivatives of the depth map .",
    "consequently , our globalization method need not explicitly reason about which local predictions are `` outliers '' with respect to such a model .",
    "moreover , since our coefficients can be related to the global depth map through convolutions , we are able to use fourier - domain computations for efficient inference .",
    "we formulate our problem as that of estimating a scene map @xmath1 , which encodes point - wise scene depth , from a single rgb image @xmath2 , where @xmath3 indexes location on the image plane .",
    "we represent this scene map @xmath4 in terms of a set of coefficients @xmath5 at each location @xmath6 , corresponding to various spatial derivatives .",
    "specifically , these coefficients are related to the scene map @xmath4 through convolution with a bank of derivative filters @xmath7 , _",
    "i.e. _ ,  @xmath8    for our task , we define @xmath9 to be a set of 2d derivative - of - gaussian filters with standard deviations @xmath10 pixels , for scales @xmath11 .",
    "we use the zeroth order derivative ( _ i.e. _ ,  the gaussian itself ) , first order derivatives along eight orientations , as well as second order derivatives  along each of the orientations , and orthogonal orientations ( see fig .  [",
    "fig : teaser ] for examples ) .",
    "we also use the impulse filter which can be interpreted as the zeroth derivative at scale 0 , with the corresponding coefficients @xmath12this gives us a total of @xmath13 filters .",
    "we normalize the first and second order filters to be unit norm .",
    "the zeroth order filters coefficients typically have higher magnitudes , and in practice , we find it useful to normalize them as @xmath14 to obtain a more balanced representation .",
    "to estimate the scene map @xmath4 , we first use a convolutional neural network to output distributions for the coefficients @xmath15 , for every filter @xmath16 and location @xmath6 .",
    "we choose a parametric form for these distributions @xmath17 , with the network predicting the corresponding parameters for each coefficient .",
    "the network is trained to produce these distributions for each set of coefficients @xmath18 by using as input a local region centered around @xmath6 in the rgb image @xmath19 .",
    "we then form a single consistent estimate of @xmath4 by solving a global optimization problem that maximizes the likelihood of the different coefficients of @xmath4 under the distributions provided by our network .",
    "we now describe the different components of our approach ( which is summarized in fig .",
    "[ fig : teaser])the parametric form for our local coefficient distributions , the architecture of our neural network , and our globalization method .",
    "our neural network has to output a distribution , rather than a single estimate , for each coefficient @xmath20 .",
    "we choose gaussian mixtures as a convenient parametric form for these distributions : @xmath21 where @xmath22 is the number of mixture components ( 64 in our implementation ) , @xmath23 is a common variance for all components for derivative @xmath16 , and @xmath24 the individual component means . a distribution for a specific coefficient @xmath20",
    "can then characterized by our neural network by producing the mixture weights @xmath25 , @xmath26 , for each @xmath20 from the scene s rgb image .    prior to training the network",
    ", we fix the means @xmath24 and variances @xmath27 based on a training set of ground truth depth maps .",
    "we use one - dimensional k - means clustering on sets of training coefficient values @xmath28 for each derivative @xmath16 , and set the means @xmath29 in above to the cluster centers .",
    "we set @xmath23 to the average in - cluster variance  however , since these coefficients have heavy - tailed distributions , we compute this average only over clusters with more than a minimum number of assignments .",
    "depth derivatives @xmath18 at each location @xmath6 , using a color image as input .",
    "the distributions are parameterized as gaussian mixtures , and the network produces the @xmath22 mixture weights for each coefficient .",
    "our network includes a local path ( green ) with a cascade of convolution layers to extract features from a @xmath30 patch around each location @xmath6 ; and a scene path ( red ) with pre - trained vgg-19 layers to compute a single scene feature vector .",
    "we learn a linear map ( with x32 upsampling ) from this scene vector to per - location features .",
    "the local and scene features are concatenated and used to generate the final distributions ( blue ) . ]",
    "our method uses a neural network to predict the mixture weights @xmath31 of the parameterization in from an input color image .",
    "we train our network to output @xmath32 numbers at each pixel location @xmath6 , which we interpret as a set of @xmath22-dimensional vectors corresponding to the weights @xmath33 , for each of the @xmath34 distributions of the coefficients @xmath35 .",
    "this training is done with respect to a loss between the predicted @xmath31 , and the best fit of the parametric form in to the ground truth derivative value @xmath20 .",
    "specifically , we define @xmath36 in terms of the true @xmath20 as : @xmath37 and define the training loss @xmath38 in terms of the kl - divergence between these vectors @xmath36 and the network predictions @xmath31 , weighting the loss for each derivative by its variance @xmath23 : @xmath39 where @xmath40 is the total number of locations @xmath6 .",
    "our network has a fairly high - dimensional output space  corresponding to @xmath32 numbers , with @xmath41 degrees of freedom , at each location @xmath6 .",
    "its architecture , detailed in fig .",
    "[ fig : narch ] , uses a cascade of seven convolution layers ( each with relu activations ) to extract a @xmath42-dimensional _ local _ feature vector from each @xmath30 local patch in the input image . to further add scene - level semantic context",
    ", we include a separate path that extracts a single @xmath43-dimensional feature vector from the entire image  using pre - trained layers ( upto _ pool5 _ ) from the vgg-19  @xcite network , followed downsampling with averaging by a factor of two , and a fully connected layer with a relu activation that is trained with dropout .",
    "this global vector is used to derive a @xmath44-dimensional vector for each location @xmath6using a learned layer that generates a feature map at a coarser resolution , that is then bi - linearly upsampled by a factor of @xmath45 to yield an image - sized map .",
    "the concatenated local and scene - level features are passed through two more hidden layers ( with relu activations ) .",
    "the final layer produces the @xmath32-vector of mixture weights @xmath46 , applying a separate softmax to each of the @xmath22-dimensional vector @xmath47 .",
    "all layers in the network are learned end - to - end , with the vgg-19 layers finetuned with a reduced learning rate factor of @xmath48 compared to the rest of the network .",
    "the local path of the network is applied in a `` fully convolutional '' way  @xcite during training and inference , allowing efficient reuse of computations between overlapping patches .      applying our neural network to a given input image",
    "produces a dense set of distributions @xmath49 for all derivative coefficients at all locations .",
    "we combine these to form a single coherent estimate by finding the scene map @xmath4 whose coefficients @xmath18 have high likelihoods under the corresponding distributions @xmath50 .",
    "we do this by optimizing the following objective : @xmath51 where , like in , the log - likelihoods for different derivatives are weighted by their variance @xmath23 .",
    "the objective in is a summation over a large ( @xmath34 times image - size ) number of non - convex terms , each of which depends on scene values @xmath4 at multiple locations @xmath6 in a local neighborhood  based on the support of filter @xmath52 . despite the apparent complexity of this objective",
    ", we find that approximate inference using an alternating minimization algorithm , like in @xcite , works well in practice .",
    "specifically , we create explicit auxiliary variables @xmath20 for the coefficients , and solve the following modified optimization problem : @xmath53 + \\frac{\\beta}{2}\\sum_{i , n } \\left(w_i(n)-(k_i*y)(n ) \\right)^2 + \\frac{1}{2}\\mathcal{r}(y).\\ ] ] note that the second term above forces coefficients of @xmath4 to be equal to the corresponding auxiliary variables @xmath20 , as @xmath54 .",
    "we iteratively compute , by alternating between minimizing the objective with respect to @xmath4 and to @xmath18 , keeping the other fixed , while increasing the value of @xmath55 across iterations .",
    "note that there is also a third regularization term @xmath56 in , which we define as @xmath57 using @xmath58 laplacian filters , at four orientations , for @xmath59 .",
    "in practice , this term only affects the computation of @xmath4 in the initial iterations when the value of @xmath55 is small , and in later iterations is dominated by the values of @xmath20 .",
    "however , we find that adding this regularization allows us to increase the value of @xmath55 faster , and therefore converge in fewer iterations .    each step of our alternating minimization can be carried out efficiently . when @xmath4 fixed , the objective in can be minimized with respect to each coefficient",
    "@xmath20 independently as : @xmath60 where @xmath61 is the corresponding derivative of the current estimate of @xmath4 . since @xmath62 is a mixture of gaussians , the objective in",
    "can also be interpreted as the ( scaled ) negative log - likelihood of a gaussian - mixture , with `` posterior '' mixture means @xmath63 and weights @xmath64 : @xmath65 while there is no closed form solution to , we find that a reasonable approximation is to simply set @xmath20 to the posterior mean value @xmath63 for which weight @xmath64 is the highest .",
    "the second step at each iteration involves minimizing with respect to @xmath66 given the current estimates of @xmath20 .",
    "this is a simple least - squares minimization given by @xmath67 note that since all terms above are related to @xmath66 by convolutions with different filters , we can carry out this minimization very efficiently in the fourier domain .",
    "we initialize our iterations by setting @xmath20 simply to the component mean @xmath68 for which our predicted weight @xmath31 is highest .",
    "then , we apply the @xmath66 and @xmath18 minimization steps alternatingly , while increasing @xmath55 from @xmath69 to @xmath70 , by a factor of @xmath71 at each iteration .",
    "we train and evaluate our method on the nyu v2 depth dataset  @xcite . to construct our training and validation sets ,",
    "we adopt the standard practice of using the raw videos corresponding to the training images from the official train / test split .",
    "we randomly select 10% of these videos for validation , and use the rest for training our network .",
    "our training set is formed by sub - sampling video frames uniformly , and consists of roughly 56,000 color image - depth map pairs .",
    "monocular depth estimation algorithms are evaluated on their accuracy in the @xmath72 crop of the depth map that contains a valid depth projection ( including filled - in areas within this crop ) .",
    "we use the same crop of the color image as input to our algorithm , and train our network accordingly .",
    "we let the scene map @xmath4 in our formulation correspond to the reciprocal of metric depth , _",
    "i.e. _ ,  @xmath73 . while other methods use different compressive transform ( _ e.g. _ ,  @xcite regress to @xmath74 ) , our choice is motivated by the fact that points on the image plane are related to their world co - ordinates by a perspective transform .",
    "this implies , for example , that in planar regions the first derivatives of @xmath4 will depend only on surface orientation , and that second derivatives will be zero .",
    "we use data augmentation during training , applying random rotations of @xmath75 and horizontal flips simultaneously to images and depth maps , and random contrast changes to images .",
    "we use a fully convolutional version of our architecture during training with a stride of @xmath76 pixels , yielding nearly 4000 training patches per image .",
    "we train the network using sgd for a total of 14 epochs , using a batch size of only one image and a momentum value of @xmath77 .",
    "we begin with a learning rate of @xmath78 , and reduce it after the @xmath79 , @xmath80 , @xmath81 , @xmath82 , and @xmath83 epochs , each time by a factor of two .",
    "this schedule was set by tracking the post - globalization depth accuracy on a validation set .",
    "first , we analyze the informativeness of individual distributional outputs from our neural network .",
    "figure  [ fig : unc ] visualizes the accuracy and confidence of the local per - coefficient distributions produced by our network on a typical image . for various derivative filters ,",
    "we display maps of the absolute error between the true coefficient values @xmath20 and the mean of the corresponding predicted distributions @xmath50 . alongside these errors",
    ", we also visualize the network s `` confidence '' in terms of a map of the standard deviations of @xmath50 .",
    "we see that the network makes high confidence predictions for different derivatives in different regions , and that the number of such high confidence predictions is least for zeroth order derivatives .",
    "moreover , we find that all regions with high predicted confidence ( _ i.e. _ ,  low standard deviation ) also have low errors . figure  [ fig : unc ] also displays the corresponding global depth estimates , along with their accuracy relative to the ground truth .",
    "we find that despite having large low - confidence regions for individual coefficients , our final depth map is still quite accurate .",
    "this suggests that the information from different coefficients predicted distributions is complementary .",
    "[ tab : ablat ]        to quantitatively characterize the contribution of the various components of our overcomplete representation , we conduct an ablation study on 100 validation images . with the same trained network ,",
    "we include different subsets of filter coefficients for global estimation  leaving out either specific derivative orders , or scales  and report their accuracy in table  [ tab : ablat ] .",
    "we use the standard metrics from @xcite for accuracy between estimated and true depth values @xmath84 and @xmath85 across all pixels in all images : root mean square error ( rmse ) of both @xmath86 and @xmath87 , mean relative error ( @xmath88 ) and relative square error ( @xmath89 ) , as well as percentages of pixels with error @xmath90 below different thresholds .",
    "we find that removing each of these subsets degrades the performance of the global estimation method  with second order derivatives contributing least to final estimation accuracy .",
    "interestingly , combining multiple scales but with only zeroth order derivatives performs worse than using just the point - wise depth distributions .",
    "finally , we evaluate the performance of our method on the nyu v2 test set .",
    "table  [ tab : rtest ] reports the quantitative performance of our method , along with other state - of - the - art approaches over the entire test set , and we find that the proposed method yields superior performance on most metrics .",
    "figure  [ fig : qual ] shows example predictions from our approach and that of @xcite .",
    "we see that our approach is often able to better reproduce local geometric structure in its predictions ( desk & chair in column 1 , bookshelf in column 4 ) , although it occasionally mis - estimates the relative position of some objects ( _ e.g. _ ,  globe in column 5 ) . at the same time , it is also usually able to correctly estimate the depth of large and texture - less planar regions ( but , see column 6 for an example failure case ) .",
    "our overall inference method ( network predictions and globalization ) takes 24 seconds per - image when using an nvidia titan x gpu . the source code for implementation , along with a pre - trained network model , are available at http://www.ttic.edu/chakrabarti/mdepth .",
    "[ tab : rtest ]",
    "in this paper , we described an alternative approach to reasoning about scene geometry from a single image . instead of formulating the task as a regression to point - wise depth values , we trained a neural network to probabilistically characterize local coefficients of the scene depth map in an overcomplete representation .",
    "we showed that these local predictions could then be reconciled to form an estimate of the scene depth map using an efficient globalization procedure .",
    "we demonstrated the utility of our approach by evaluating it on the nyu v2 depth benchmark .",
    "its performance on the monocular depth estimation task suggests that our network s local predictions effectively summarize the depth cues present in a single image . in future work",
    ", we will explore how these predictions can be used in other settings_e.g .",
    "_ ,  to aid stereo reconstruction , or improve the quality of measurements from active and passive depth sensors .",
    "we are also interested in exploring whether our approach of training a network to make overcomplete probabilistic local predictions can be useful in other applications , such as motion estimation or intrinsic image decomposition .",
    "ac acknowledges support for this work from the national science foundation under award no .",
    "iis-1618021 , and from a gift by adobe systems . ac and",
    "gs thank nvidia corporation for donations of titan x gpus used in this research ."
  ],
  "abstract_text": [
    "<S> a single color image can contain many cues informative towards different aspects of local geometric structure . </S>",
    "<S> we approach the problem of monocular depth estimation by using a neural network to produce a mid - level representation that summarizes these cues . </S>",
    "<S> this network is trained to characterize local scene geometry by predicting , at every image location , depth derivatives of different orders , orientations and scales . </S>",
    "<S> however , instead of a single estimate for each derivative , the network outputs probability distributions that allow it to express confidence about some coefficients , and ambiguity about others . scene depth is then estimated by harmonizing this overcomplete set of network predictions , using a globalization procedure that finds a single consistent depth map that best matches all the local derivative distributions . </S>",
    "<S> we demonstrate the efficacy of this approach through evaluation on the nyu v2 depth data set .    </S>",
    "<S> = 1 </S>"
  ]
}