{
  "article_text": [
    "we consider the problem of constructing accurate approximations on bounded time intervals to solutions of the following family of stochastic differential equations ( sdes ) @xmath0 where @xmath1 , @xmath2 , @xmath3 , and @xmath4 are one - dimensional wiener processes .",
    "thus , randomness is entering the system in fixed directions @xmath5 , but at variable rates @xmath6 .",
    "precise regularity conditions on the coefficients will be presented with our main results in section [ sec : method ] .",
    "the algorithm developed in this paper is a trapezoidal - type method and consists of two steps ; in the first an explicit euler step is used to take a fractional step and in the second the resulting fractional point is used in combination with the initial point to obtain a higher order , trapezoidal like , approximation .",
    "we will prove that the method developed is second order accurate in the weak sense . because the method developed here produces single paths ,",
    "it is natural to allow variable step - sizes ; this is in contrast to richardson extrapolation techniques ( @xcite ) . finally , it is important to note that while the method presented in this paper is applicable to only a sub - class of sdes , that sub - class does include systems whose diffusion terms do not commute , which is a classical simplifying assumption to obtain higher order methods ( see @xcite ) .",
    "the method we propose is in some sense similar to the classical predictor - corrector .",
    "there have already been a number of such methods proposed in the stochastic context to produce higher - order methods ( see @xcite ) . in a general way ,",
    "all of these methods require the simulation of iterated it integrals and sometimes need derivatives of the diffusion terms .",
    "if one only cares about weak accuracy , it is possible to use random variables which make these calculations easier and computationally cheaper .",
    "that being said , the complexity and cost of such calculations is one of the main impediments to their wider use . by assuming a certain structure for , we are able to develop a numerical method which we hope is more easily applied and implemented .    though a specific structure of is assumed , it is a structure which arises naturally in a number of settings .",
    "for example , our method will be applicable whenever @xmath7 .",
    "also , we note that diffusion approximations to continuous time markov chain models of population processes , including ( bio)chemical processes , satisfy . as stochastic models of biochemical reaction systems , and , in particular , gene regulatory systems , are becoming more prevalent in the science literature , developing algorithms that utilize the specific structure of such models",
    "has increased importance ( @xcite ) .",
    "furthermore , in section  [ uniforme ] , we quote a result from the literature which states that any system with uniformly elliptic diffusion can be put in the form of without changing its distribution .",
    "the topic of this paper is a method that produces a weak approximation rather than a strong approximation in that the approximate trajectory is produced without reference to an underlining wiener process trajectory .",
    "we see this as an advantage . except for applications such as filtering or certain problems of collective motion for stochastic flows ,",
    "one is usually simply interested in generating an accurate draw from the distribution on @xmath8 , { \\mathbb{r}}^d)$ ] induced by .",
    "this is different than accurately reproducing the it map @xmath9 implied by .",
    "the second is referred to as strong approximation . in our opinion",
    "such approximations are usually unnecessary and lead to a concept of accuracy which is unnecessarily restrictive . in @xcite",
    ", it is discussed that without accurately estimating second order it integrals one can not produce a strong method of order greater then 1/2 . if the vector fields commute , then this restriction does not apply and higher order strong methods are possible . while the term `` strong approximation '' is quite specific , the term `` weak approximation '' is used for a number of concepts .",
    "here we mean that the joint distribution of the numerical method at a fixed number of time points converges to the true marginal distribution as the numerical grid converges to zero .",
    "if this error goes to zero as the numerical mesh size to the power @xmath10 in some norm on measure then we say the method is of order @xmath10 .",
    "this should be contrasted with talking about the rate at which a given function of the path converges .",
    "the outline of the paper is as follows . in section  [ sec : method ] we present our algorithm together with our main results concerning its weak error properties . in section  [ sec : why ] we give the intuition as to why the method should work . in section  [ sec :",
    "proof ] we give the delayed proof of the local error estimates for the method which were stated in section  [ sec : method ] . in section [ sec : examples ] we provide examples illustrating the performance of the proposed algorithm . in section  [ sec",
    ": theta ] we discuss the effect of varying the size of the first fractional step of the algorithm . in section",
    "[ sec : richardson ] we compare one step of the algorithm to one step in a richardson extrapolation type algorithm . in section  [ uniforme ] we show how , at least theoretically , the method can be applied to any uniformly elliptic sde .",
    "finally , an appendix contains a tedious calculation needed in section  [ sec : proof ] .",
    "throughout the paper , we let @xmath11 denote the solution to and @xmath12 denote the computed approximation at the time @xmath13 for the time discretization @xmath14 . we begin both from the same initial condition , namely @xmath15 .",
    "let @xmath16 be a collection of mutually independent gaussian random variables with mean zero and variance one .",
    "it is notationally convenient to define @xmath17^+= x \\vee 0 = \\max\\{x,0\\}$ ] .",
    "we propose the following algorithm to approximate the solutions of .    algorithm .",
    "( weak @xmath18-midpoint trapezoidal )    notice that on the @xmath19th - step @xmath20 is the standard euler approximation to @xmath21 starting from @xmath22 at time @xmath23 @xcite .    notice that for all @xmath24 one has @xmath25 and @xmath26 .",
    "it is reasonable to ask which @xmath18 is best .",
    "notice that when @xmath27 both @xmath28 and @xmath29 are minimized with values @xmath30 and @xmath31 .",
    "this likely has positive stability implications",
    ". from the point of view of accuracy @xmath32 also seems like a reasonable choice as it provides a central point for building a balanced trapezoidal approximation , as will be explained in section  [ sec : why ] .",
    "further , picking a @xmath18 close to 1 or 0 increases the likelihood that the term @xmath33^+$ ] will be zero , which will lower the accuracy of the method .",
    "if instability due to stiffness is a concern , one might consider a @xmath18 closer to one as that would likely give better stability properties being closer to an implicit method . in general , @xmath32 seems like a reasonable compromise , though this question requires further investigation and will be briefly revisited in section [ sec : theta ] .",
    "[ rem : theta ]    for simplicity , we will restrict ourselves to the case when @xmath34 and the @xmath35 are in @xmath36 , the space of bounded functions whose first through sixth derivatives are continuous and bounded . in general , we will denote by @xmath37 the space of bounded , continuous functions whose first @xmath38 derivatives are bounded and continuous . for @xmath39 , we define the standard norm @xmath40 it is notationally convenient to define the markov semigroup @xmath41 associated with by @xmath42 where @xmath43 and markov semigroup @xmath44 associated with a single full step of size @xmath45 of the numerical method by @xmath46 where @xmath47 . clearly @xmath48 and @xmath49 .",
    "it is also a standard fact , which we summarize in appendix  [ opbound ] , that in our setting for any @xmath50 and @xmath51 if @xmath52 then there exists a @xmath53 so that @xmath54 is true for all @xmath55 . all of these can be rewritten succinctly in the induced operator norm from @xmath56 as @xmath57 , @xmath58 and @xmath59 .",
    "analogously , for any linear operator @xmath60 we will denote the induced operator norm from @xmath61 by @xmath62 which is defined by @xmath63    the following two theorems are the principle results of this article .",
    "they give respectively the weak local and global error of the weak trapezoidal method .",
    "[ thm : local ] assume that @xmath64 and for all @xmath38 , @xmath65 with @xmath66",
    ". then there exists a constant @xmath67 so that @xmath68 for all @xmath45 sufficiently small .    from this one - step error bound ,",
    "it is relatively straight - forward to obtain a global error bound .",
    "the following result shows that our approximation scheme gives a weak approximation of second order .",
    "assume that @xmath64 and for all @xmath38 , @xmath65 with @xmath69 .",
    "then for any @xmath70 there exists a constant @xmath71 such that @xmath72    we begin by observing that @xmath73 and hence since @xmath74 and @xmath75 , using we have that for any @xmath76 with @xmath77 @xmath78    the restriction that @xmath69 can likely be relaxed if one has some control of the behavior of the solution around the degeneracies of @xmath79 .",
    "this assumption is made to keep the proof simple with easily stated assumptions .",
    "we now give two different , but related , explanations as to why the weak @xmath18-midpoint trapezoidal algorithm is second order accurate in the weak sense .",
    "inserting the expression for @xmath80 from step 1 of the weak @xmath18-midpoint trapezoidal algorithm into step 2 and disregarding the diffusion terms yields @xmath81 + \\dots .",
    "\\label{eq : thewhy1}\\\\    & = y_{i-1 } + b(y_{i-1})h + \\frac{b(y^ * ) - b(y_{i-1})}{\\theta      h}\\frac{h^2}{2 } + \\dots .",
    "\\label{eq : thewhy2}\\end{aligned}\\ ] ] considering , we see that when @xmath82 we recover the standard theta method ( not to be confused with our use of @xmath18 ) with theta @xmath83 , which is known to be a second order method for deterministic systems .",
    "when @xmath27 , we recover the standard trapezoidal or midpoint method . for @xmath84 , we simply have a trapezoidal rule where a fractional point of the interval is used in the construction of the trapezoid .",
    "we will argue heuristically that the weak trapezoidal algorithm handles the diffusion terms similarly .",
    "we also note that shows that our algorithm can be understood as an approximation to the two - step taylor series where @xmath18 is a parameter used to approximate the second derivative .",
    "this idea will be revisited in the proof of theorem  [ thm : local ] .",
    "equation is distributionally equivalent to @xmath85 where the @xmath86 are independent space - time white noise processes are random measures on @xmath87 such that if @xmath88 with @xmath89 then @xmath90 and @xmath91 are each independent , mean zero gaussian random variables with variances @xmath92 and @xmath93 , respectively .",
    "integration with respect to this field can be defined in the standard way beginning with adapted simple functions which are fixed random variables on fixed rectangular sets and then extending by linearity after the appropriate it isometry is established . ] and all other notation is as before , in that solutions to are markov processes that solve the same martingale problem as solutions to ; that is , they have the same generator ( @xcite ) . in order to approximate the diffusion term in over the interval @xmath94 , we must approximate @xmath95 where @xmath96 is the region under the curve @xmath97 for @xmath98 .",
    "we consider a natural way to approximate @xmath99 and focus on the double integral in for a single @xmath38 .",
    "we also take @xmath27 for simplicity and simply note that the case @xmath84 follows similarly .",
    "we begin by approximating the value @xmath100 by @xmath80 obtained via an euler approximation of the system on the interval @xmath101 .",
    "to do so , we hold @xmath11 fixed at @xmath102 and see that we need to calculate @xmath103 , where region 1 is the grey shaded region in figure [ fig : exp](a ) . because @xmath104 we see that this step is equivalent in distribution to step 1 of algorithm [ eq : main ] .",
    "( here and in the sequel , `` @xmath105 '' denotes `` equal in distribution . '' )    if we were trying to determine the area under the curve @xmath97 using an estimated midpoint @xmath80 for a deterministic @xmath11 , one natural ( and common ) way would be to use the area of region 2 , where region 2 is the grey shaded region in figure [ fig : exp](b ) .",
    "such a method would be equivalent to the trapezoidal rule given in .",
    "however , in our setting we would have to ignore , or subtract off , the area already accounted for in region 3 , which is depicted as the shaded green section of figure [ fig : exp](b ) . in doing so ,",
    "the random variable needed in order to perform this step would necessarily be dependent upon the past ( via region 3 ) , and our current analysis would break down .",
    "however , noting that region 3 has the same area as region 4 , as depicted by the blue shaded region in figure [ fig : exp](c ) , we see that it would be reasonable to expect that if one only uses region 5 , as depicted as the grey shaded region in figure [ fig : exp](c ) , then the accuracy of the method should be improved as we have performed a trapezoidal type approximation . because @xmath106 where @xmath107 , we see that this is precisely what is carried out by step 2 of the weak @xmath18-midpoint trapezoidal algorithm .      to obtain a higher order method",
    "one must both approximate well the expected drift term as well as the quadratic variation of the process .",
    "the basic idea of the weak trapezoidal algorithm is to make a preliminary step using an euler approximation and then use this step to make a higher order approximation to the drift integral and to the quadratic variation integral .",
    "similar to the desired one step approximation to the quadratic variation integrals are @xmath108,\\end{aligned}\\ ] ] where all notation is as before .",
    "considering just the variance terms of the quadratic variation , we let @xmath109 be an orthonormal basis and see that our method yields the approximation @xmath110^+ } ( \\nu_k\\cdot      e_i ) \\eta_{2k } \\sqrt{(1-\\theta)h}\\big)\\\\&=      \\sum_{k=1}^m\\e\\big(\\sigma_k^2 ( y_{0 } ) \\theta     + \\big[\\alpha_1\\sigma^2_k({y^ * } ) - \\alpha_2\\sigma^2_k(y_{0})\\big]^+ ( 1    - \\theta)\\big ) ( \\nu_k\\cdot e_i)^2h.\\end{aligned}\\ ] ] if the step - size is sufficiently small then , @xmath111^+$ ] is positive with high probability because of our uniform ellipticity assumption ; and hence , @xmath112 which is a locally third order approximation to the true quadratic variation integral of @xmath113 notice that it was important in this simple analysis that the direction of variation @xmath5 stayed constant over the interval so that the two terms could combine exactly .",
    "of course , one should really be computing the full quadratic variation , including terms such as @xmath114 , but they follow the same pattern as above because each is a linear combination of the integral terms @xmath115 .",
    "we now give the proof of the local error estimate given in theorem [ thm : local ] which is the central result of this paper .",
    "( of theorem  [ thm : local ] ) we need to show that there exists a constant @xmath67 so that for any @xmath116 one has @xmath117 hence for the reminder of the proof we fix an arbitrary @xmath118 .",
    "observe that step 1 of the weak trapezoidal algorithm produces a value , @xmath20 , that is distributionally equivalent to @xmath119 , where @xmath120 solves @xmath121 likewise , step 2 of the weak trapezoidal algorithm produces a value , @xmath122 , that is distributionally equivalent to @xmath123 , where @xmath120 solves @xmath124^+ }      \\;\\nu_k \\",
    "dw_k(t ) , \\quad y(\\theta h ) = { y^*}.      \\label{eq : part2 }    \\end{aligned}\\ ] ] let @xmath125 denote the filtration generated by the weiner processes @xmath4 in and .",
    "then , @xmath126\\ , ] { \\!\\overset{\\mbox{\\tiny def}}{=}\\!}\\e\\,[\\,\\e_{\\theta h } f(y(h ) ) ] ,        \\label{eq : condition}\\ ] ] where we have made the definition @xmath127{\\!\\overset{\\mbox{\\tiny def}}{=}\\!}\\e [ \\ \\cdot \\ | \\ \\ftt]$ ] .",
    "let @xmath128 denote the generator for the process , @xmath129 denote the generator for the process , and @xmath130 denote the generator for the process conditioned upon @xmath131",
    ". then @xmath132(x ) + \\frac{1}{2 } \\sum_k \\sigma_k^2 f''[\\nu_k ,      \\nu_k](x)\\\\      ( b_1f)(x ) & = f'[b(x_0)](x ) + \\frac{1}{2 } \\sum_k \\sigma_k(x_0)^2      f''[\\nu_k , \\nu_k](x)\\\\      ( b_2 f)(x ) & = f'[\\alpha_1 b({y^ * } ) - \\alpha_2 b(x_0)](x ) +      \\frac{1}{2 } \\sum_k [ \\alpha_1 \\sigma_k({y^*})^2 - \\alpha_2      \\sigma_k(x_0)^2]^+ f''[\\nu_k , \\nu_k](x ) ,    \\end{aligned}\\ ] ] where @xmath133(z)$ ] is the derivative of @xmath134 in the direction @xmath135 evaluated at the point @xmath136 .",
    "note that @xmath137 . for any integer @xmath138",
    "we define recursively @xmath139 and similarly for @xmath129 and @xmath130 . by repeated application of the it - dynkin formula , see @xcite , we have @xmath140 the term @xmath141 depends on the first six derivatives of @xmath134 . therefore , since @xmath116 @xmath142 for some constant @xmath143 .",
    "combining , , , and recalling that @xmath144 gives @xmath145 = \\e \\ f({y^ * } ) + \\e \\      ( b_2f)({y^*})(1 - \\theta)h + \\e \\ ( b_2 ^ 2 f)({y^*})\\frac{(1 - \\theta)^2        h^2}{2 } + o(h^3 ) .",
    "\\label{eq : partway }    \\end{aligned}\\ ] ] here and in the sequel , we will write @xmath146 to mean that there exist a constant @xmath67 depending on only @xmath147 and @xmath34 so that for all initial conditions @xmath148 @xmath149 for @xmath45 sufficiently small . in the spirit of the preceding calculation , repeated application of the it - dynkin formula to produces @xmath150 the proof of the theorem is then completed by lemma  [ lem : keyestimate ] given below .",
    "its proof , which is straightforward but tedious , is given in the appendix .",
    "[ lem : keyestimate ] under the assumptions of theorem  [ thm : local ] , for all @xmath151 sufficiently small and @xmath116 one has @xmath152 = & f(x_0 ) + ( af)(x_0)+      ( a^2f)(x_0)\\frac{h^2}2 + o(h^3)\\ , .",
    "\\end{aligned}\\ ] ]    comparing equation and lemma [ lem : keyestimate ] shows that our algorithm can be viewed as providing an approximation to the two step taylor series approximation .",
    "we present two examples that demonstrate the rate of convergence of the weak trapezoidal algorithm with @xmath27 . in each example",
    "we shall compare the accuracy of the proposed algorithm to that of euler s method and a `` midpoint drift '' algorithm defined via repetition of the following steps @xmath153 where the notation is as before .",
    "we compare the proposed algorithm to that given via to point out that the gain in efficiency being demonstrated is not solely due to the fact that we are getting better approximations to the drift terms , but also because of the superior approximation of the diffusion terms .",
    "consider the system @xmath154      = \\left [ \\begin{array}{c }          x_1(t )",
    "\\\\          0        \\end{array}\\right ] + x_1(t ) \\left [ \\begin{array}{c }          0 \\\\          1        \\end{array}\\right]dw_1(t ) + \\frac{1}{10}\\left [ \\begin{array}{c }          1 \\\\          1        \\end{array}\\right]dw_2(t ) ,      \\label{eq : ou}\\ ] ] where @xmath155 and @xmath156 are standard weiner processes . in our notation @xmath157 , @xmath158 , @xmath159 , @xmath160 , and @xmath161^t$ ] , @xmath162^t$ ] .",
    "note that the noise does not commute .",
    "it is an exercise to show that @xmath163 for both euler s method and the midpoint drift method we used step sizes @xmath164 , @xmath165 and initial condition @xmath166 to generate @xmath167 sample paths of the system .",
    "we then computed @xmath168 where @xmath169 is the sample path generated numerically and @xmath170 is given via .",
    "we also generated @xmath171 sample paths using the weak trapezoidal algorithm with the same initial condition and step sizes @xmath172 , @xmath173 .",
    "we then computed @xmath174 similarly to before .",
    "the outcome of the numerical experiment is summarized in figure [ fig : ou ] where we have plotted @xmath175 versus @xmath176 for the different algorithms . as expected , we see that the weak trapezoidal algorithm gives an error that decreases proportional to @xmath177 , whereas the other two algorithms give errors that decrease proportional to @xmath45",
    ".      now consider the following system that is similar to one considered in @xcite @xmath178      = \\left [ \\begin{array}{c }          -x_2(t ) \\\\",
    "x_1(t )        \\end{array}\\right ] & + \\sqrt{\\frac{\\sin^2(x_1(t ) + x_2(t ) ) +          6}{t + 1 } } \\left [ \\begin{array}{c }          1 \\\\          0        \\end{array}\\right]dw_1(t)\\\\      & + \\sqrt{\\frac{\\cos^2(x_1(t ) + x_2(t ) ) + 6}{t + 1}}\\left [        \\begin{array}{c }          0 \\\\          1        \\end{array}\\right]dw_2(t ) ,    \\end{split }    \\label{eq : talay }   \\end{aligned}\\ ] ] where @xmath155 and @xmath156 are independent weiner processes .",
    "it is simple to show that @xmath179 we used step sizes @xmath180 , @xmath181 , to generate five million approximate sample paths of the system using each of : ( a ) weak trapezoidal algorithm , ( b ) euler s method , and ( c ) the midpoint drift method .",
    "we then computed @xmath182 where @xmath169 is the sample path generated numerically and @xmath183 is given via .",
    "the outcome is summarized in figure [ fig : talay ] where we have plotted @xmath175 versus @xmath176 for the different algorithms .",
    "as before , we see that the weak trapezoidal algorithm gives an error that decreases proportional to @xmath177 , whereas the other two algorithms give errors that decrease proportional to @xmath45 .",
    "we note that in both examples we needed to average over an extremely large number of computed sample paths in order to estimate error@xmath184 for the weak trapezoidal algorithm .",
    "this is due to the fact that the increased accuracy of the method quickly makes sampling error the dominant error .",
    "the term @xmath185^+$ ] in step 2 of the weak trapezoidal algorithm will yield zero , and the given step will have a local error of only @xmath186 , if @xmath187 we will call such a step a `` degenerate '' step .",
    "the function @xmath188 is minimized at @xmath189 , and @xmath190 as @xmath191 or @xmath192 .",
    "therefore , as mentioned remark  [ rem : theta ] , one would expect that as @xmath193 or @xmath192 more steps will be degenerate , and a decrease in accuracy , together with a bias against @xmath35 decreasing , would follow . using a step - size of @xmath194",
    ", we tracked the percentage of degenerate steps for the simple system @xmath195 where @xmath196 is a standard weiner process .",
    "to do so , we computed @xmath197 sample paths over the time interval @xmath198 $ ] for each of @xmath199 , @xmath200 .",
    "the results are shown in figure [ fig : theta ] where the behavior predicted above is seen .",
    "curiously , the minimum number of rejections takes place at @xmath201 .",
    "it is also worth noting that one can check on computer software that in the general case the coefficient of @xmath202 for the one - step error grows like @xmath203 as @xmath191 .",
    "this does not happen in the deterministic case .",
    "while the above considerations give some interesting insight into the effect of various @xmath18 , the situation is more complex . a @xmath18",
    "closer to one should give the method more stability , albeit at an expense as the rejection fraction increases as @xmath18 approaches one .",
    "it would be interesting to perform a stability analysis in the spirit of @xcite to better understand the effect of @xmath18 . in lieu of this",
    ", figure  [ fig : loglogtheta ] gives the result of a convergence analysis of the weak trapezoidal algorithm applied to with different choices of @xmath18 .",
    "interestingly , larger @xmath18 seem to result in smaller ( and hence better ) convergence rate prefactors .",
    "this seems to indicate that in at least this example stability is an issue .",
    "the performance of the weak trapezoidal algorithm as a function of @xmath18 is a topic deserving further consideration , but combining the above shows that @xmath27 is a reasonable first choice , though stability considerations might lead one to consider a @xmath18 closer to 1 .",
    "it is illustrative to compare the weak trapezoidal algorithm to richardson extrapolation , which from a certain point of view is the method in the literature that is most similar to ours .",
    "see @xcite for complete details of richardson extrapolation in the sde setting .",
    "let @xmath204 and @xmath205 denote approximate sample paths of generated using euler s method with step sizes of @xmath206 and @xmath45 , respectively . for all @xmath134 satisfying mild assumptions , both @xmath207 and @xmath208 will approximate @xmath209 with an order of @xmath210 .",
    "however , richardson extrapolation may be used and the linear combination @xmath211 will approximate @xmath212 with an order of @xmath186 ( see @xcite ) . of course , taking @xmath134 to be the identity shows that the linear combination @xmath213 gives an @xmath186 approximate of the mean of the process . as richardson extrapolation",
    "does not compute a single path , but instead uses the statistics from two to achieve a higher order of approximation for a given statistic , we will compare one step of the weak trapezoidal algorithm with a step - size of @xmath45 , to one step of size @xmath45 of the process @xmath213 with the clear understanding that @xmath213 is only @xmath210 accurate for higher moments .",
    "recall that systems of the form are equivalent to those driven by space - time white noise processes . as in section [ sec:1stview ] ,",
    "we consider how each method uses the areas of @xmath87 associated to @xmath214 from during one step .",
    "we will proceed considering a single @xmath38 since it is sufficient to illustrate the point . for @xmath215 ,",
    "we denote by @xmath216 a normal random variable with mean @xmath217 and variance area@xmath218 .",
    "recall that @xmath216 and @xmath219 are independent as long as @xmath220 has lebesgue measure zero .",
    "consider ( a ) in which we are supposing that @xmath97 increases over a single time - step .",
    "the change in the process @xmath221 due to this @xmath38 would be @xmath5 times @xmath222 similarly , the change in @xmath223 would be @xmath5 times @xmath224 .",
    "therefore , the change in the process @xmath225 would be @xmath5 times @xmath226 on the other hand , the change in the process generated by the weak trapezoidal algorithm due to this @xmath38 is @xmath5 times @xmath227 therefore , and as expected , the means should be the same , but the variances should not as @xmath228 similarly , in the case in which @xmath97 decreases as depicted in ( b ) , the process @xmath213 would use @xmath229 , whereas the weak trapezoidal algorithm would use @xmath230 . again , the means will be the same , but the variances will not . in both cases , the weak trapezoidal algorithm makes better use of the areas to approximate the quadratic variation of the true process , and thus achieves a higher order of convergence .",
    "for a moment let us consider the setting of general uniformly elliptic sdes @xmath231 where @xmath34 and @xmath232 are as before and @xmath233 is such that if @xmath234 then there exist positive @xmath235 and @xmath236 such that @xmath237 for all @xmath238 .",
    "for such a family of uniformly elliptic matrices a lemma of motzkin and wasow @xcite , whose precise formulation we take form kurtz @xcite , states that if the entries of @xmath239 are @xmath240 then there exists an @xmath241 and @xmath242 , @xmath243 with @xmath244 and strictly positive so that @xmath245 hence has the same law on path space as with these @xmath35 and @xmath5 .",
    "of course @xmath241 might be arbitrarily large ( depending on the ratio of @xmath246 ) and hence it is more subtle to compare the total work for our method with a standard scheme based directly on .",
    "furthermore , depending on the dependence on @xmath247 , it is not transparent how to obtain the vectors @xmath248 and functions @xmath147 exactly .",
    "approximations could be obtained using the svn of the matrix @xmath249 for fixed @xmath247 but we do not explore this further here .",
    "we have presented a relatively simple method directly applicable to a wide class of systems which is weakly second order .",
    "we have also shown how , at least theoretically , it should be applicable to systems which do not satisfy our structural assumptions but are uniformly elliptic .",
    "we have picked a particularly simple setting to perform our analysis to make the central points clearer .",
    "the assumption that @xmath34 and @xmath35 are uniformly bounded can be relaxed to a local lipschitz condition . that is to say ,",
    "if @xmath34 and @xmath147 and their needed derivatives are not bounded uniformly , but rather are bounded by an appropriate lyapunov function , then it should be possible to extend the method directly to the setting of unbounded coefficients provided the method is stable for the given sde ( see for instance @xcite ) .",
    "if the sde is not globally lipschitz then using an implicit drift split - step method as in @xcite , an adaptive method as in @xcite , or a truncation method as in @xcite should extend to our current setting .",
    "more interesting is relaxing the non - degeneracy assumption on the @xmath35 , which was used to minimize the probability of the diffusion correction being negative .",
    "this tact is in some ways reminiscent of @xcite in that a modification of the method is made on a small set of paths , though the take here is quite different .",
    "it would be interesting to use the probability that the correction to the diffusion is negative to adapt the step - size much in the spirit of @xcite .",
    "lastly , there is some similarity of our method with predictor corrector methods . in the deterministic setting ,",
    "predictor corrector methods not only have a higher order of accuracy but also have better stability properties . there have been a number of papers exploring this in the stochastic context ( see @xcite ) .",
    "it would be interesting to do the same with the method presented here .",
    "dfa was supported through grant nsf - dms-0553687 and jcm through grants nsf - dms-0449910 and nsf - dms-06 - 16710 and a sloan foundation fellowship .",
    "we would like to thank andrew stuart for useful comments on an early draft and martin clark for stimulating questions about richardson extrapolation .",
    "we also thank thomas kurtz for pointing out that all uniformly elliptic sdes can be represented in the form considered in this paper .",
    "the proof of lemma  [ lem : keyestimate ] requires the replacement of the terms of the form @xmath250^+$ ] with @xmath250 $ ] .",
    "the following two lemmas show that this can be done at the cost of an error whose size is @xmath251 . here",
    "@xmath251 has the same meaning described earlier around .",
    "we begin with an abstract technical lemma where @xmath10 and @xmath252 satisfy @xmath253 .",
    "[ prop : keeppos ] let @xmath254 and @xmath255 be a real valued random variables on a probability space @xmath256 with @xmath257 for some @xmath258 $ ] . then @xmath259^+ -\\e yx| \\leq |yx|_{l^p(\\omega ) }    ( \\pp\\ { x < 0\\})^{1/q}$ ] . similarly if @xmath254,@xmath255 and @xmath260 are real valued random variables with @xmath261 and @xmath262 then @xmath259^+[z]^+ -\\e yxz| \\leq 2    |zyx|_{l^p(\\omega ) } ( \\pp\\{a\\})^{1/q}$ ] .",
    "let @xmath263 and @xmath264 . then @xmath265^+ - x)| \\leq    \\e |y||[x]^+ -x|{\\mathbf{1}}_a \\leq |yx|_{l^p(\\omega ) } ( \\pp(a))^{1/q}$ ] , showing the first claim . for the second notice that @xmath266^+[z]^+    - \\e yxz = ( \\e y[x]^+z - \\e yxz ) + ( \\e y[x]^+[z]^+ - \\e y[x]^+z)$ ] and that each of the terms in parentheses can be bounded by the first result .",
    "[ cor : absswitch ] let @xmath267 with @xmath69 for all @xmath38 and let @xmath255 be a random variable with @xmath268 a.s .",
    "for some @xmath143 . then for any @xmath269 there exists an @xmath270 so that @xmath271^+ = \\e",
    "y [ \\alpha_1 \\sigma_k^2(y^ * ) - \\alpha_2 \\sigma_k^2(x_0 ) ] + o(h^p)\\\\      \\e y [ \\alpha_1 \\sigma_k^2(y^ * ) - & \\alpha_2 \\sigma_k^2(x_0)]^+      [ \\alpha_1 \\sigma_\\ell^2(y^ * )",
    "- \\alpha_2 \\sigma_\\ell^2(x_0)]^+ = \\e      y [ \\alpha_1 \\sigma_k^2(y^ * ) - \\alpha_2 \\sigma_k^2(x_0 ) ] [ \\alpha_1      \\sigma_\\ell^2(y^ * ) - \\alpha_2 \\sigma_\\ell^2(x_0 ) ] + o(h^p )    \\end{aligned}\\ ] ] for all @xmath272 $ ] and @xmath273 , where @xmath80 is defined via step 1 of the weak trapezoidal algorithm .",
    "define the event @xmath274 . in light of proposition",
    "[ prop : keeppos ] , it is sufficient to show that for any @xmath275 there exists a @xmath276 such that @xmath277 . because @xmath35 is lipschitz there exists a positive @xmath143 such that @xmath278 for any @xmath279 .",
    "in particular , setting @xmath280 , and noting that @xmath281 and that the @xmath147 s are uniformly bounded from both above and below , the result follows from the gaussian tails of the @xmath282 s .",
    "( of lemma  [ lem : keyestimate ] ) from taylor s theorem and the definition of the operators involved one has @xmath283 in the last line , we have used the observation that @xmath284 .",
    "now we turn to @xmath285 .",
    "we begin by using lemma  [ cor : absswitch ] to remove the @xmath286^+$ ] .",
    "then we use the fact that @xmath287 and taylor s theorem to expand various terms to produce the following : @xmath288 +      \\frac{1}{2 } \\e\\sum_k [ \\alpha_1 \\sigma_k^2({y^ * } ) - \\alpha_2      \\sigma_k^2(x_0)]^+      f''[\\nu_k , \\nu_k]({y^*})\\\\      & = \\e f'({y^*})[\\alpha_1 b({y^ * } ) - \\alpha_2 b(x_0 ) ] + \\frac{1}{2 }      \\e\\sum_k [ \\alpha_1 \\sigma_k^2({y^ * } ) - \\alpha_2 \\sigma_k^2(x_0 ) ]      f''[\\nu_k , \\nu_k]({y^*})+o(h^2)\\\\      & = f'(x_0)[b(x_0 ) ] + \\frac{1}{2 }   \\sum_k \\sigma_k(x_0)^2      f''(x_0)[\\nu_k , \\nu_k ] \\\\      & \\hspace{.2 in } + \\e b_1 \\big ( f'[\\alpha_1 b - \\alpha_2 b(x_0 ) ] +        \\frac{1}{2 } \\sum_k ( \\alpha_1 \\sigma_k^2 - \\alpha_2        \\sigma_k^2(x_0 ) ) f''[\\nu_k , \\nu_k ] \\big )      ( x_0 ) \\theta h + o(h^2 ) \\notag \\\\      & = ( af)(x_0 ) + \\alpha_1 ( b_1(af))(x_0)\\theta h - \\alpha_2 ( b_1 ^ 2      f)(x_0)\\theta h + o(h^2)\\notag \\\\                   & = ( af)(x_0)+ \\alpha_1 ( a^2f)(x_0)\\theta h -      \\alpha_2(b_1 ^ 2f)(x_0)\\theta h + o(h^2 ) .        \\end{aligned}\\ ] ] similar reasoning produces @xmath289 + \\frac{1}{2 } \\sum_k [ \\alpha_1          \\sigma_k^2({y^ * } ) -",
    "\\alpha_2 \\sigma_k^2(x_0)]^+          f''[\\nu_k , \\nu_k ] \\big)({y^ * } )   \\big)\\\\      & = f''[b(x_0),b(x_0)](x_0 ) + \\e \\sum_k [ \\alpha_1 \\sigma_k^2({y^ * } ) -      \\alpha_2 \\sigma_k^2(x_0)]^+ f'''[\\nu_k , \\nu_k , b(x_0)](x_0 ) \\\\      & + \\frac{1}{4 } \\e \\sum_{k , j } [ \\alpha_1 \\sigma_k^2({y^ * } ) - \\alpha_2      \\sigma_k^2(x_0)]^+ [ \\alpha_1 \\sigma_j^2({y^ * } ) -      \\alpha_2 \\sigma_j^2(x_0)]^+f''''[\\nu_k,\\nu_k,\\nu_j,\\nu_j](x_0 ) + o(h)\\\\      & = f''[b(x_0),b(x_0)](x_0 ) + \\sum_k \\sigma_k^2(x_0 ) f'''[\\nu_k ,      \\nu_k , b(x_0)](x_0 ) \\\\",
    "& \\qquad+ \\frac{1}{4 }      \\sum_{k , j } \\sigma_k^2(x_0 )   \\sigma_j^2(x_0 )      f''''[\\nu_k,\\nu_k,\\nu_j,\\nu_j](x_0 ) + o(h)\\\\       & = ( b_1 ^ 2f)(x_0 ) + o(h)\\ , .",
    "\\end{aligned}\\ ] ] combining these estimate and the fact that @xmath290 and @xmath291 , produces the quoted result after some algebra .",
    "in this section , we show that if @xmath293 then @xmath294 is a bounded operator from @xmath295 to @xmath295 for @xmath296 .",
    "the @xmath297 case follows immediately from @xmath298 for all @xmath299 . to address the higher @xmath38",
    ", we introduce the first @xmath38 variations of equation .    for any @xmath300",
    "we denote the first variation of in the direction @xmath135 by @xmath301 $ ] which solves the linear equation @xmath302&= ( \\nabla b)(x(t))[j^{(1)}(t , x)[\\xi]]\\ , dt + \\sum_{k=1}^m\\nu_k(\\nabla \\sigma_k)(x(t))[j^{(1)}(t , x)[\\xi]]\\ , dw_k(t)\\,,\\\\ j^{(1)}(0,x)[\\xi]&=\\xi \\quad\\text{and}\\quad x(0)=x\\end{aligned}\\ ] ] similarly for @xmath303 the second variation of @xmath11 ( in the directions @xmath135 ) will be denoted by @xmath304 $ ] and defined by @xmath305&= ( \\nabla b)(x(t))[j^{(2)}(t , x)[\\xi]]\\ , dt + \\sum_{k=1}^m\\nu_k(\\nabla \\sigma_k)(x(t))[j^{(2)}(t , x)[\\xi]]\\ , dw_k(t ) \\\\   & +   ( \\nabla^2b)(x(t))[j^{(1)}(t , x)[\\xi_1],j^{(1)}(t , x)[\\xi_2 ] ] + \\sum_{k=1}^m(\\nabla^2\\sigma_k)(x(t))[j^{(1)}(t , x)[\\xi_1],j^{(1)}(t , x)[\\xi_2]]dw_k(t)\\\\ j^{(2)}(0,x)[\\xi]&=0 \\quad\\text{and}\\quad x(0)=x\\,.\\end{aligned}\\ ] ] these equations were obtained from successive formal differentiation of . by further formal differentiation we obtain analogous equations for the @xmath38-variation @xmath306 $ ] where @xmath307 is the vector of directions .",
    "it is a standard fact that if the coefficients @xmath308 are in @xmath309 then for any @xmath310 @xmath311 } |j^{(n)}(s , x)[\\xi_1,\\dots,\\xi_n]|^p : \\xi_i   \\in { \\mathbb{r}}^d \\text { with } |\\xi_i|=1\\big\\ } < \\infty \\,.\\end{aligned}\\ ] ] this can be found in lemma  2 in @xcite on p. 196 or in a slightly different context in proposition  1.3 in @xcite .",
    "however the bounds on @xmath312 only require @xmath309 coefficients . ] . with these definitions in hand",
    ", we have that for any @xmath313 that @xmath314&=\\e_x f'(x(t))[j^{(1)}(t , x)[\\xi]]\\,,\\\\ \\nabla^2 ( \\mathcal{p}_tf)(x)[\\xi]&=\\e_x f'(x(t))[j^{(2)}(t , x)[\\xi]]+\\e_x f^{(2)}(x(t))[j^{(1)}(t , x)[\\xi_1],j^{(1)}(t , x)[\\xi_2]]\\,.\\end{aligned}\\ ] ] using the moment bounds we have that for @xmath315 and an ever changing constant @xmath143 , @xmath316|^q \\leq & c\\|f\\|_{{c}^1}^q   \\sup_{|\\xi|=1}\\big|j^{(1)}_t[\\xi]\\big|^q \\leq c\\|f\\|_{{c}^1}^q < \\infty \\\\",
    "\\e \\sup_{|\\xi_i|=1}|\\nabla^2 ( \\mathcal{p}_tf)(x)[\\xi_1,\\xi_2]|^q \\leq & c\\|f\\|_{{c}^2}^q\\big(\\big(\\e \\sup_{|\\xi_1|=1 }     \\leq & c\\|f\\|_{{c}^2}^q < \\infty\\end{aligned}\\ ] ] continuing in this manner we see that for any positive integer @xmath317 if @xmath318 then for any @xmath319 one has @xmath320|^q \\leq c\\|f\\|_{{c}^m}^q < \\infty\\,\\end{aligned}\\ ] ] for some @xmath143",
    ". now observe that taking @xmath321 proves the desired claim on the operator norm of @xmath294 from @xmath309 to @xmath309 since @xmath322\\big| \\leq c \\sum_{j=0}^k \\|f\\|_{{c}^j } \\leq c\\|f\\|_{{c}^k}\\end{aligned}\\ ] ] ."
  ],
  "abstract_text": [
    "<S> we present a numerical method for the approximation of solutions for the class of stochastic differential equations driven by brownian motions which induce stochastic variation in fixed directions . </S>",
    "<S> this class of equations arises naturally in the study of population processes and chemical reaction kinetics . </S>",
    "<S> we show that the method constructs paths that are second order accurate in the weak sense . </S>",
    "<S> the method is simpler than many second order methods in that it neither requires the construction of iterated it integrals nor the evaluation of any derivatives . </S>",
    "<S> the method consists of two steps . in the first an explicit euler step </S>",
    "<S> is used to take a fractional step . the resulting fractional point </S>",
    "<S> is then combined with the initial point to obtain a higher order , trapezoidal like , approximation . </S>",
    "<S> the higher order of accuracy stems from the fact that both the drift and the quadratic variation of the underlying sde are approximated to second order . </S>"
  ]
}