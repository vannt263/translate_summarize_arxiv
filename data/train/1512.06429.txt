{
  "article_text": [
    "strong data - processing inequalities ( sdpis ) quantify the decrease of mutual information under the action of a noisy channel .",
    "such inequalities have apparently been first discovered by ahlswede and gcs in a landmark paper  @xcite . among the work predating  @xcite and extending it we mention  @xcite .",
    "notable connections include topics ranging from existence and uniqueness of gibbs measures and log - sobolev inequalities to performance limits of noisy circuits .",
    "we refer the reader to the introduction in  @xcite and the recent monographs  @xcite for more detailed discussions of applications and extensions .    for a fixed channel @xmath11 ,",
    "let @xmath12 be the distribution on @xmath13 induced by the push - forward of the distribution @xmath14 .",
    "one approach to strong data processing seeks to find the contraction coefficients @xmath15 where the @xmath16 $ ] is an @xmath17-divergence of csiszr  @xcite . when the divergence @xmath18 is the kl - divergence and total variation and @xmath19 is @xmath20-q[e]|$ ] . ]",
    ", we denote the coefficient @xmath21 as @xmath22 and @xmath23 , respectively .    for discrete channels ,",
    "@xcite showed equivalence of @xmath24 , @xmath25 and connectedness of the bipartite graph describing the channel .",
    "having @xmath24 implies reduction in the usual data - processing inequality for mutual information  ( * ? ? ?",
    "* exercise iii.2.12 ) ,  @xcite : @xmath26 we refer to inequalities of the form _ linear _ sdpis .",
    "when @xmath27 is an additive white gaussian noise channel , i.e. @xmath1 with @xmath28 , it has been shown  @xcite that restricting the maximization in   to distributions with a bounded second moment ( or any moment ) still leads to no - contraction , giving @xmath29 for awgn .",
    "nevertheless , the contraction does indeed take place , except not multiplicatively .",
    "the region @xmath30",
    "\\leq \\gamma \\right\\}\\,,\\ ] ] has been explicitly determined in  @xcite , where @xmath31 denotes convolution .",
    "the boundary of this region , deemed the _ dobrushin curve _ of the channel , turned out to be strictly bounded away from the diagonal ( identity ) . in other words , except for the trivial case where @xmath32 , total variation decreases by a non - trivial amount in gaussian channels .",
    "unfortunately , the similar region for kl - divergence turns out to be trivial , so that no improvement in the inequality @xmath33 is possible ( given the knowledge of the right - hand side and moment constraints on @xmath34 and @xmath35 ) . in  @xcite , in order to study how mutual information dissipates on a chain of gaussian links , this problem was resolved by a rather lengthy workaround which entails first reducing questions regarding the mutual information to those about the total variation and then converting back .    a more direct approach , in the spirit of the joint - range idea of harremos and vajda  @xcite , is to find ( or bound ) the _ best possible data - processing function _",
    "@xmath36 defined as follows .",
    "[ def : fi ] for a fixed channel @xmath27 and a convex set @xmath37 of distributions on @xmath38 we define @xmath39 where the supremum is over all joint distributions @xmath40 with @xmath41 . when the channel is clear from the context , we abbreviate @xmath42 as @xmath43 .    for brevity",
    "we denote @xmath44 the function corresponding to the special case of the awgn channel and quadratic constraint .",
    "namely , @xmath45 , where @xmath28 is independent of @xmath2 , we define @xmath46 } } \\le 1    \\right\\}.\\ ] ]    the significance of the function @xmath36 is that it gives the optimal input - independent strong data processing inequalities .",
    "it is instructive to compare definition of @xmath36 with two related quantities considered previously in the literature .",
    "witsenhausen and wyner  @xcite defined @xmath47 with the infimum taken over all joint distributions satisfying @xmath48 = p_{xy}(x , y)\\,.\\ ] ] clearly , by a simple reparametrization @xmath49 , this function would correspond to @xmath50 if @xmath43 were defined with restriction to a given input distribution @xmath34 .",
    "the @xmath34-independent version of has also been studied by witsenhausen  @xcite : @xmath51 with the infimum taken over all @xmath52 = p_{y|x}(y|x)\\,.\\ ] ] this quantity plays a role in a generalization of mrs .",
    "gerber s lemma and satisfies a convenient tensorization property : @xmath53 there is no one - to - one correspondence between @xmath54 and @xmath43 and in fact , alas , @xmath43 does not satisfy any ( known to us ) tensorization property .",
    "a priori , the only bounds we can state on @xmath36 are consequences of capacity and the data processing inequality : @xmath55 where @xmath56 .",
    "for the gaussian - quadratic case , capacity equals @xmath57 @xmath58 where @xmath59 is the gaussian channel capacity .    in this work",
    "we show that generally the trivial bound   is not tight at any point .",
    "namely , we prove that @xmath60 and both functions @xmath61 and @xmath62 are strictly positive for all @xmath7 .",
    "we call these two results _ diagonal _ and _ horizontal _ bounds respectively",
    ". see fig .",
    "[ fig : fireg ] for an illustration .",
    "[ cc]@xmath63 [ cc]@xmath64 [ cc][c]@xmath65 [ cc][c]@xmath66 [ bc]@xmath36   and gaps @xmath61 and @xmath62 to the trivial data processing bound .,title=\"fig:\",scaledwidth=60.0% ]    for the gaussian - quadratic case we show explicitly that our estimates are asymptotically sharp .",
    "for example , theorem [ thm : diagonal ] ( gaussian diagonal bound ) shows the lower - bound portion of @xmath67 an application of   allows , via a repeated application of  , to infer that the mutual information between the input @xmath68 and the output @xmath69 of a chain of @xmath70 energy - constrained gaussian relays converges to zero @xmath71 .",
    "in fact ,   recovers the optimal convergence rate of @xmath72 first reported in  ( * ? ? ? * theorem 1 ) .",
    "we then generalize the diagonal bound to non - gaussian noise and arbitrary moment constraint ( theorem [ thm : diaggeneral ] ) by an additional quantization argument .",
    "it is worth noting that mutual information does not always strictly contract . consider the following simple example : let @xmath3 be uniformly distributed over @xmath73 $ ] and @xmath74 is bernoulli , then @xmath75 since @xmath2 can be decoded perfectly from @xmath76 .",
    "surprisingly , this turns out to be the only situation for non - contraction of mutual information occur , as the following characterization ( ) shows : for strict contraction of mutual information it is _ necessary and sufficient _ that the noise @xmath3 can not be perfectly distinguished from a translate of itself ( i.e. @xmath77 ) .",
    "going to the horizontal bound , we show ( for the gaussian - quadratic case ) that @xmath44 approaches @xmath78 no faster than double - exponentially in @xmath79 as @xmath80 .",
    "namely , in theorem [ thm : capbound ] and remark [ remark : cap ] , we prove that @xmath81 satisfies @xmath82 where @xmath83 and @xmath84 are strictly positive functions of @xmath85 .    generalization of the horizontal bound to arbitrary noise distribution ( theorem  [ thm : generalhoriz ] ) proceeds along a similar route . in the process",
    ", we derive a deconvolution estimate that bounds the kolmogorov - smirnov distance ( @xmath86 norm between cdfs ) in terms of the total variation between convolutions with noise .",
    "namely , shows that for a noise @xmath3 with bounded density and non - vanishing characteristic function we have @xmath87 for some continuous increasing function @xmath88 with @xmath89 .    the final result ( ) addresses the question of bounding @xmath36-curve for non - scalar channel @xmath1 .",
    "somewhat surprisingly , we show that for the infinite - dimensional gaussian case the trivial bound on the @xmath36-curve is exact .",
    "the rest of the paper is organized as follows .",
    "section [ sec : fiproperties ] introduces properties of the @xmath36-curve , together with a few examples for discrete channels .",
    "sections [ sec : diagonal ] and  [ sec : generaldiagonal ] present a ( diagonal ) lower bound for @xmath90 in the gaussian and generall setting respectively .",
    "section [ sec : mmse ] shows that any @xmath2 for which close - to - optimal ( in mmse sense ) linear estimator of @xmath1 exists , must necessarily be close to gaussian in the sense of kolmogorov - smirnov distance .",
    "these results are then used in section [ sec : horizontal ] to prove a ( gaussian horizontal ) lower bound on @xmath81 .",
    "section [ sec : deconvtv ] introduces a deconvolution result that connects ks - distance with tv - divergence .",
    "this result is then applied in section [ sec : generalhorizontal ] to derive a general horizontal bound for @xmath36 curve for a wide range of additive noise channels .",
    "finally , in section [ sec : infinite ] we consider the infinite - dimensional discrete gaussian channel , and show that in this case there exists no non - trivial strong data processing inequality for mutual information . in the appendix",
    ", we present a shorter proof of the key step in the gaussian horizontal bound ( namely , lemma [ lem : capks ] ) employing talagrand s inequality @xcite .    [ [ notations ] ] notations + + + + + + + + +    for any distribution @xmath14 on @xmath91 , let @xmath92)$ ] denote its cumulative distribution function ( cdf ) . for any random variable @xmath2 , denote its distribution and cdf by @xmath34 and @xmath93 , respectively . for any sequences",
    "@xmath94 and @xmath95 of positive numbers , we write @xmath96 or @xmath97 when @xmath98 for some absolute constant @xmath99 .",
    "in this section we discuss properties of the @xmath36-curve , and present a few examples for discrete channels .       1 .   @xmath36 is an increasing function such that @xmath100 with @xmath101 .",
    "@xmath102 is decreasing .",
    "consequently , @xmath36 is subadditive and @xmath103 .",
    "3 .   value of @xmath43 is unchanged if @xmath104 is restricted to an alphabet of size @xmath105 .",
    "upper concave envelope of @xmath43 equals upper concave envelope of a set of pairs @xmath106 achieved by restricting @xmath104 to alphabet @xmath38 .",
    "[ prop : fiprop ]    the first part follows directly from the definition , the non - negativity and the data processing inequality of mutual information . for the second part ,",
    "fix @xmath27 and let @xmath107 achieve the pair @xmath108 . then by choosing @xmath109 , the pair @xmath110 is also achievable .",
    "it follows directly that @xmath111 is decreasing .",
    "claim 3 follows by noticing that for a fixed distribution @xmath34 , any pair @xmath112 can be attained by @xmath104 with a given restriction on the alphabet , see  ( * ? ? ?",
    "* theorem 2.3 ) .",
    "similarly , concave envelope of @xmath43 can be found by taking convex closure of extremal points @xmath113 , which can be attained by @xmath104 with alphabet @xmath114 , see paragraph after  ( * ? ? ?",
    "* theorem 2.3 ) .",
    "we present next a few examples of the @xmath43-curve for discrete channels :    1 .",
    "_ erasure channel _ is defined as @xmath115 with @xmath116 or @xmath117 with probabilities @xmath118 and @xmath119 , respectively . in this case",
    "we have for any @xmath120 a convenient identity , cf .",
    "@xcite : @xmath121 and consequently , the @xmath36-curve is @xmath122 and is achieved by taking @xmath74 .",
    "2 .   _ binary symmetric channel _",
    "bsc(@xmath123 ) is defined as @xmath124 with @xmath1 , @xmath125 . here",
    "the optimal coupling is @xmath126 with @xmath127 and varying bias of @xmath128 .",
    "this is formally proved in the next proposition .",
    "[ prop : fibsc ] the @xmath36-curve of the bsc(@xmath123 ) is given by @xmath129 where @xmath130 , @xmath131 is the binary entropy function and @xmath132 \\to [ 0,{1\\over2}]$ ] is its functional inverse .    [ sec : bsc_gerber ] first , it is clear that @xmath133 } f_i(t , p)\\,,\\ ] ] where @xmath134 that is @xmath135 is an @xmath36-curve for a fixed marginal @xmath34 .",
    "it is sufficient to prove that @xmath136 is a maximizer in   regardless of @xmath79 . to that end ,",
    "recall mrs .",
    "gerber s lemma @xcite states that @xmath137 is convex on @xmath138 $ ] .",
    "consequently for any @xmath139 , @xmath140 .",
    "we now study properties of the @xmath36-curve in the gaussian case , i.e. @xmath141 in this section , we show that @xmath44 is bounded away from @xmath79 for all @xmath7 ( theorem [ thm : diagonal ] ) and investigate the behavior of @xmath44 for small @xmath79 ( corollary [ cor : diagonalrate ] ) .",
    "the proofs of the non - linear sdpis presented in both the current and the next section hinge on the existence of a linear sdpi when the input @xmath2 is amplitude - constrained .",
    "we define @xmath142 }      \\frac{d(p*p_z\\|q*p_z)}{d(p\\|q)}.\\ ] ] similarly , define the dobrushin s coefficient @xmath143 with @xmath144 replaced by @xmath145 in , that is , @xmath146 } { d_{\\rm tv}}(p_{z+z},p_{z+z ' } ) = \\sup_{|\\delta|\\leq 2a } \\theta(\\delta ) ,      \\label{eq : etatva}\\ ] ] where @xmath147    observe that for any @xmath0 , where @xmath1 and @xmath148 $ ] almost surely , we have @xmath149 . in the gaussian case considered in this section , @xmath150 can be upper - bounded as @xcite @xmath151 where @xmath152 is the gaussian complimentary cdf .",
    "this leads to the following general lemma , which also holds for general @xmath153 .",
    "[ lem : diagonallem ] let @xmath0 , where @xmath1 .",
    "for any @xmath154 , let @xmath155 $ ] .",
    "then @xmath156 where @xmath157 and @xmath158 .",
    "let @xmath159 and @xmath160 .",
    "then @xmath161 where the last inequality follows from the definition of @xmath162 in . observing that @xmath163 and denoting @xmath158",
    ", we can further bound by @xmath164 where follows from @xmath165 .",
    "the result follows by noting that @xmath166 .",
    "we now present explicit bounds for the value of @xmath167 when @xmath168\\leq \\gamma$ ] and @xmath169 .    for the awgn channel with quadratic constraint ,",
    "see  , we have @xmath170 and [ thm : diagonal ]    @xmath171}2q\\left(\\sqrt{\\frac{\\gamma}{x}}\\right)\\left(t-    h\\left(x\\right)-\\frac{x}{2}\\ln\\left (    1+\\frac{\\gamma}{x }",
    "\\right ) \\right ) .",
    "\\label{eq : vertical}\\ ] ]    let @xmath172 and @xmath173}}=\\epsilon$ ] .",
    "observe that @xmath174}}\\leq \\gamma/\\epsilon \\mbox { ~and~ } \\epsilon\\leq \\gamma / a^2 .",
    "\\label{eq : xcond}\\end{aligned}\\ ] ] therefore , from lemma [ lem : diagonallem ] and ,    @xmath175    now observe that , for @xmath176 , @xmath177 in addition , @xmath178 here follows from the fact that mutual information is maximized when @xmath2 is gaussian under the power constraint , and follows by noticing that @xmath179 is monotonically increasing for any @xmath180 . combining and , and for @xmath181 , @xmath182 choosing @xmath183 , where @xmath184 , becomes @xmath185 substituting in yields the desired result .",
    "note that @xmath186 is 0 at @xmath187 ; furthermore , @xmath188 is continuous and strictly positive on @xmath189 . therefore @xmath167 is strictly positive for @xmath7 .",
    "the next corollary characterizes the behavior of @xmath167 for small @xmath79 .",
    "[ cor : diagonalrate ] for fixed @xmath85 , @xmath190 and @xmath191 sufficiently large , there is a constant @xmath192 dependent on @xmath85 such that @xmath193 in particular , @xmath194    let @xmath195 in the expression being maximized in . for sufficiently large @xmath79 , @xmath196 and @xmath197",
    "the result follows .",
    "[ remark : diag ] fix @xmath198 and define a binary random variable @xmath2 with @xmath199=1/a^2 $ ] and @xmath200=1 - 1/a^2 $ ] for @xmath180 .",
    "furthermore , let @xmath201 denote the minimum distance estimate of @xmath2 based on @xmath202 .",
    "then the probability of error satisfies @xmath203 \\leq    q(\\sqrt{\\gamma}a/2)$ ] .",
    "in addition , @xmath204 and @xmath205 as @xmath206 .",
    "therefore , @xmath207 using fano s inequality , @xmath208 can be bounded as @xmath209 setting @xmath74 , this result yields the sharp asymptotics .",
    "in this section , we extend the diagonal bound derived in theorem [ thm : diagonal ] to arbitrary noise density and generalizing the power constraint to an @xmath4-norm constraint @xmath210}}\\leq \\gamma.$ ]    [ thm : diaggeneral ] assume that @xmath0 , where @xmath1 , @xmath2 and @xmath3 are independent , @xmath210}}\\leq \\gamma$ ] , and @xmath3 has an absolute continuous distribution .",
    "then @xmath211 where @xmath212 and the amplitude - constrained contraction coefficient @xmath213 is defined in  .",
    "[ cor : strict ] for any @xmath214 and any @xmath198 , the following statements are equivalent :    a.   non - linear sdpi holds with @xmath215 whenever @xmath7",
    ". b.   @xmath216 has non - zero lebesgue measure for all @xmath217 , where @xmath218 is the support of the probability density function @xmath219 of @xmath3 .    in order to prove these results , we first study the case where @xmath2 is discrete and a deterministic function of @xmath104 .    [",
    "lem : discrete ] let @xmath220 , @xmath1 , and @xmath221 be a deterministic mapping .",
    "in addition , assume that @xmath2 takes values on some @xmath222-grid for @xmath223 ( i.e. @xmath224 almost surely ) and @xmath210}}\\leq \\gamma$ ] , @xmath214 .",
    "then @xmath225 where @xmath226    let @xmath159 and @xmath227 $ ] .",
    "then , from lemma [ lem : diagonallem ] , @xmath228 observe that for @xmath210}}\\leq \\gamma$ ] , @xmath229\\leq \\gamma / a^p,\\ ] ] and , for @xmath230 @xmath231}}\\leq { { \\mathbb{e}_{}\\left",
    "[ |x|^p|e=1 \\right]}}\\leq \\gamma/\\epsilon.\\ ] ] in addition , for any integer - valued random variable @xmath232 we have ( cf .",
    "* lemma 13.5.4 ) ) @xmath233}}+1 \\right)h_b\\left ( \\frac{1}{{{\\mathbb{e}_{}\\left [ |u| \\right]}}+1 } \\right)+\\ln 2 .",
    "\\label{eq : u}\\ ] ] consequently , for @xmath234 , @xmath235 where and follows from the fact that @xmath236 and @xmath237 for @xmath238 $ ] , respectively , and follows by observing that @xmath239 .",
    "assuming @xmath240 , @xmath241 since the right - hand side of the previous equation is strictly decreasing for @xmath242 , @xmath243 can be chosen sufficiently large such that @xmath244 . choosing @xmath245 , where @xmath246 is given in , and combining and ,",
    "we conclude that @xmath247 proving the lemma .",
    "we start by verifying that @xmath119 defined in is finite and so is @xmath248 in . since @xmath249 , it suffices to show that @xmath250 vanishes as @xmath251 .",
    "recall @xmath252 as defined in . by the denseness of compactly",
    "supported continuous functions in @xmath253 , @xmath254 as @xmath255 .",
    "furthermore , the translation invariance and the triangle inequality of total variation imply that @xmath256 and hence @xmath257 is uniformly continuous . therefore , @xmath258 is continuous in @xmath259 on @xmath260 , which ensures that @xmath261 is finite .    from lemma [ lem : diagonallem ] , and",
    "once more denoting @xmath159 , @xmath262 $ ] and @xmath263 , we have @xmath264 let @xmath265 .",
    "then @xmath266 thus , @xmath267 since @xmath268 combining  gives @xmath269    since @xmath270}}\\leq \\alpha\\gamma / a^p$ ] , from and it follows that for @xmath271 , @xmath272 thus , choosing @xmath119 such that @xmath273 , and @xmath243 sufficiently large such that @xmath274 , becomes @xmath275 proving the result upon choosing @xmath276 .    to show ( a ) @xmath277 ( b ) , suppose that @xmath278 has zero lebesgue measure for some @xmath279 .",
    "consider @xmath280 , where @xmath281 with @xmath282=\\epsilon |x_0|^p \\leq \\gamma$ ] .",
    "since @xmath283 , @xmath2 can be perferctly decoded from @xmath1 and hence @xmath284 , which shows that @xmath285 in a neighborhood of zero .",
    "to show ( b ) @xmath277 ( a ) ,    in view of , it suffices to show that @xmath286 for all finite @xmath243 .",
    "recall that for any channel , @xmath287 if and only if @xmath288 ( ( * ? ? ?",
    "* proposition ii.4.12 ) ) .",
    "therefore it is equivalent to show that @xmath289 for all finite @xmath243 .",
    "suppose otherwise , i.e. , @xmath290 for some @xmath154 . by",
    ", there exists some @xmath291 $ ] such that @xmath292 , which means that @xmath293 has zero lebesgue , contradicting the assumption ( b ) and completing the proof .",
    "we now take a step back from strong data - processing inequalities and present an ancillary result of independent interest .",
    "we prove that any random variable for which there exists an almost optimal ( in terms of the mean - squared error ) linear estimator operating on the gaussian - corrupted measurement must necessarily be almost gaussian ( in terms of the kolmogorov - smirnov distance ) .",
    "we will use this result in the next section to bound the horizontal gap @xmath294 for gaussian noise . throughout the rest of the paper we make use of fourier - analytic tools and , in particular , esseen s inequality , stated below for reference .",
    "[ lem : esseen ] let @xmath14 and @xmath19 be two distributions with characteristic functions @xmath295 and @xmath296 , respectively .",
    "in addition , assume that @xmath19 has a bounded density @xmath297 .",
    "then @xmath298 where @xmath299 is the kolmogorov - smirnov distance .",
    "let @xmath300 and assume that @xmath301}}\\leq \\gamma$ ] .",
    "we show next that if the linear least - square error of estimating @xmath2 from @xmath202 is small ( i.e. close to the minimum mean - squared error ) , then @xmath2 must be almost gaussian in terms of the ks - distance . with this result in hand",
    ", we use the i - mmse relationship @xcite to show that if @xmath208 is close to @xmath78 , then @xmath2 is also almost gaussian .",
    "this result , in turn , will be applied in the next section to bound @xmath44 aways from @xmath78 .",
    "denote the linear least - square error estimator of @xmath2 given @xmath202 by @xmath302 , whose mean - squared error is @xmath303}}=\\frac{1}{1+\\gamma}.\\ ] ]    assume that @xmath304 .",
    "it is well known that @xmath305 if and only if @xmath306 ( see e.g. @xcite ) . to develop a finitary version of this result , we ask the following question : if @xmath307 is small , how close is @xmath34 to gaussian ?",
    "the next lemma provides a quantitative answer .",
    "[ lem : ksmmse ] if @xmath308 , then there are absolute constants @xmath309 and @xmath310 such that @xmath311    note that the gap between the linear and nonlinear mmse can be expressed as the fisher distance between the convolutions , i.e. , @xmath312 , where @xmath313 ^ 2 { { \\rm d}}p$ ] is the fisher distance , which dominates the kl divergence according to the log - sobolev inequality .",
    "therefore lemma  [ lem : ksmmse ] can be interpreted as a deconvolution result , where bounds on a stronger ( fisher ) distance between the convolutions lead to bounds on the distance between the original distributions under a weaker ( ks ) metric .",
    "[ remark : deconv ]    denote @xmath314}}$ ] .",
    "then @xmath315}}-{{\\mathbb{e}_{}\\left [ ( x - f_{m}(y_\\gamma))^2 \\right]}}\\nonumber \\\\                                                       = & { { \\mathbb{e}_{}\\left [ ( f_m(y_\\gamma)-f_l(y_\\gamma))^2 \\right ] } } \\\\                    \\leq & \\epsilon.\\end{aligned}\\ ] ] denote @xmath316 .",
    "then @xmath317}}=0 $ ] and @xmath318}}\\leq \\epsilon$ ] . from the orthogonality principle : @xmath319}}=0.\\end{aligned}\\ ] ] let @xmath320 denote the characteristic function of @xmath2",
    ". then @xmath319 } } = &      { { \\mathbb{e}_{}\\left [ e^{ity_\\gamma}(x - f_l(y_\\gamma)-\\delta(y_\\gamma ) ) \\right ] } } \\nonumber \\\\   = & \\frac{1}{1+\\gamma}\\left(e^{-t^2/2}{{\\mathbb{e}_{}\\left [ e^{i\\sqrt{\\gamma}tx}x \\right]}}-\\sqrt{\\gamma}\\varphi_x(\\sqrt{\\gamma   } t){{\\mathbb{e}_{}\\left [ ze^{itz }   \\right]}}\\right)-{{\\mathbb{e}_{}\\left [ e^{ity_\\gamma}\\delta(y_\\gamma ) \\right ] } } \\nonumber\\\\       = & \\frac{-ie^{-u^2/2\\gamma}}{1+\\gamma}\\left(\\varphi_x'(u)+u\\varphi_x(u)\\right)-{{\\mathbb{e}_{}\\left [ e^{ity_\\gamma}\\delta(y_\\gamma ) \\right]}},\\end{aligned}\\ ] ] where the last equality follows by changing variables @xmath321 . consequently , @xmath322 } } \\right|\\\\      & \\leq { { \\mathbb{e}_{}\\left [ \\left|\\delta(y_\\gamma)\\right| \\right]}}\\nonumber\\\\      & \\leq \\sqrt{\\epsilon}. \\label{eq : boundode}\\end{aligned}\\ ] ] put @xmath323 . then @xmath324 and , from , @xmath325 since @xmath326 , @xmath327 observe that @xmath328 .",
    "then , from , @xmath329 thus , lemma [ lem : esseen ] yields @xmath330 choosing @xmath331 , we find @xmath332 where @xmath333 and @xmath334 .    through the i - mmse relationship @xcite",
    ", the previous lemma can be extended to bound the ks - distance between the distribution of @xmath2 and the gaussian distribution when @xmath208 is close to @xmath78 .",
    "[ lem : capks ] assume that @xmath335 .",
    "then , for @xmath336 , @xmath337    from the i - mmse relationship @xcite : @xmath338 since @xmath339 , for any @xmath340 @xmath341 the function @xmath342 is continuous in @xmath85 .",
    "then , from the mean - value theorem for integrals , there exists @xmath343 such that @xmath344 from lemma [ lem : ksmmse ] , we find @xmath345 the desired result is found by choosing @xmath346 .",
    "using the results from the previous section , we show that , for @xmath347 , @xmath44 is bounded away from the capacity @xmath78 for all @xmath79 .",
    "[ thm : capbound ] for the awgn channel with quadratic constraint , see  , we have @xmath348 and @xmath349 where @xmath83 is some positive constant depending on @xmath85 .",
    "we first give an auxiliary lemma .",
    "[ lem : concentration ] if @xmath350 , then there exists an absolute constant @xmath351 such that @xmath352\\leq a_2\\epsilon^{1/8}.\\ ] ]    let @xmath353 . for any @xmath354 , pinsker s inequality yields @xmath355-{\\mathbb{p}}[z+x\\in b(0,\\delta)]&\\leq         { d_{\\rm tv}}(p_z , p_{z+x})\\\\         & \\leq \\sqrt{\\frac{\\epsilon}{2 } } .     \\end{aligned}\\ ] ] observe that @xmath356= & { \\mathbb{p}}\\left[z\\in b(-x,\\delta)\\mid |x|\\leq          3\\delta\\right]{\\mathbb{p}}[|x|<3\\delta]+{\\mathbb{p}}\\left[z\\in b(-x,\\delta)\\mid          |x| > 3\\delta\\right]{\\mathbb{p}}[|x|>3\\delta]\\\\           \\leq & { \\mathbb{p}}\\left[z\\in          b(0,\\delta)\\right]{\\mathbb{p}}[|x|\\leq 3\\delta]+{\\mathbb{p}}\\left[z\\in          b(3\\delta,\\delta)\\right]{\\mathbb{p}}[|x|>3\\delta]\\\\          = & { \\mathbb{p}}\\left [ |x|>3\\delta          \\right]\\left ( { \\mathbb{p}}\\left [ z\\in b(3\\delta,\\delta)-{\\mathbb{p}}[z\\in b(0,\\delta ) ]          \\right ] \\right)+ { \\mathbb{p}}\\left [ z\\in b(0,\\delta ) \\right ] .      \\end{aligned}\\ ] ] consequently , @xmath357\\left ( { \\mathbb{p}}[z\\in b(0,\\delta)]-{\\mathbb{p}}\\left [ z\\in b(3\\delta,\\delta )          \\right ] \\right)\\leq \\sqrt{\\frac{\\epsilon}{2}}.   \\end{aligned}\\ ] ] since @xmath358-{\\mathbb{p}}\\left [ z\\in b(3\\delta,\\delta )          \\right ] & \\geq 2\\delta ( \\varphi(\\delta)-\\varphi(2\\delta))\\\\          & \\geq \\frac{1}{4}\\delta^3 ,    \\end{aligned}\\ ] ] then @xmath359\\leq \\frac{\\delta^{-3}}{4}\\sqrt{\\frac{\\epsilon}{2}}.   \\end{aligned}\\ ] ] the result follows by choosing @xmath360 with constant @xmath361 .",
    "we will show an equivalent statement : if @xmath7 is such that @xmath362 then @xmath363 since @xmath364 , by choosing @xmath365 , it suffices to consider @xmath366 .",
    "observe that @xmath367 therefore , if @xmath368 is close to @xmath78 , then ( a ) @xmath34 needs to be gaussian like , and ( b ) @xmath369 needs to be almost deterministic with high @xmath370-probability .",
    "consequently , @xmath369 and @xmath34 are close to being mutually singular and hence @xmath63 will be large , since @xmath371    let @xmath372 and then @xmath373 .",
    "define @xmath374 then @xmath375 is jointly measurable and @xmath376 are measurable for any measurable subset @xmath243 .",
    "let @xmath377_k \\triangleq { \\lfloor k y \\rfloor}/k$ ] denote the uniform quantizer . by the data processing inequality and the lower semicontinuity of divergence , we have @xmath378_k|{{\\widetilde}{x}}=x}\\|p_{[y_{\\gamma}]_k|w = w } ) \\to d(p_{y_{\\gamma}|{{\\widetilde}{x}}=x}\\|p_{y_{\\gamma}|w = w})$ ] as @xmath379 .",
    "therefore the joint measurability of @xmath380 follows from that of @xmath381_k|{{\\widetilde}{x}}=x}\\|p_{[y_{\\gamma}]_k|w = w})$ ] . ] and @xmath382 $ ] .",
    "similarly , @xmath383 is measurable and @xmath384 $ ] . since @xmath385 in view of",
    ", we have @xmath386 \\geq 2\\epsilon\\cdot{\\mathbb{p } } [ d({{\\widetilde}{x}},w)\\geq 2 \\epsilon ] .",
    "\\end{aligned}\\ ] ] therefore @xmath387 >",
    "\\frac{1}{2}. \\label{eq : probb}\\end{aligned}\\ ] ] denote @xmath388 $ ] . in view of lemma [",
    "lem : concentration ] , if @xmath389 , then @xmath390= { \\mathbb{p}}\\left [ x\\in    b\\left(\\frac{x}{\\sqrt{\\gamma}},\\frac{\\epsilon^{1/8}}{\\sqrt{\\gamma}}\\right)\\middle| w = w \\right ] \\geq 1-a_2\\epsilon^{1/8}.\\end{aligned}\\ ] ] therefore , with probability at least @xmath391 , @xmath392 and , consequently , @xmath2 is concentrated on a small ball .",
    "furthermore , lemma [ lem : capks ] implies that there exist absolute constants @xmath393 and @xmath394 such that @xmath395&\\leq    { \\mathbb{p}}\\left [ z\\in    b\\left(\\frac{x}{\\sqrt{\\gamma}},\\frac{\\epsilon^{1/8}}{\\sqrt{\\gamma}}\\right ) \\right]+2{d_{\\mathrm{ks}}}(f_x,{\\mathcal{n}}(0,1))\\\\ & \\leq   \\frac{\\sqrt{2}\\epsilon^{1/8}}{\\sqrt{\\pi\\gamma}}+ a_3\\sqrt{\\frac{1}{\\gamma    \\ln\\left(\\frac{\\gamma}{4\\epsilon}\\right)}}+a_4(1+\\gamma)(\\gamma\\epsilon)^{1/4}\\sqrt{\\ln\\left(\\frac{\\gamma}{4\\epsilon}\\right)}\\\\    & \\leq \\kappa(\\gamma)\\left ( \\ln\\frac{1}{\\epsilon } \\right)^{-1/2},\\end{aligned}\\ ] ] where @xmath396 is some positive constant depending only on @xmath85 . therefore ,",
    "for any @xmath397 and @xmath307 sufficiently small , denoting @xmath398 , we have by data processing inequality : @xmath399 where @xmath400 is an absolute positive constant . combining with and letting @xmath401",
    ", we obtain @xmath402 \\geq { \\mathbb{p}}[d({{\\widetilde}{x}},w ) < 2 \\epsilon ] \\geq \\frac{1}{2},\\ ] ] which implies that @xmath403 \\geq   \\frac{1}{4}\\ln\\ln\\frac{1}{\\epsilon } - \\ln c_1(\\gamma)$ ] , proving the desired .",
    "[ remark : cap ] the double - exponential convergence rate in theorem  [ thm : capbound ] is in fact sharp . to see this , note that ( * ? ? ?",
    "* theorem 8) showed that there exists a sequence of zero - mean and unit - variance random variables @xmath404 with @xmath405 atoms , such that @xmath406 consequently , @xmath407 proving the right - hand side of .",
    "the proof of the horizontal gap for the scalar awgn channel in consists of four steps :    a.   notice that if @xmath408 is small , then both @xmath2 is gaussian - like and @xmath34 and @xmath369 are close to being mutually singular ; b.   use lemma [ lem : capks ] to show that @xmath409 can not be concentrated on any ball of small radius if it is gaussian - like ; c.   apply lemma [ lem : concentration ] to show that @xmath369 , in turn , is concentrated on a small ball with high @xmath104-probability ; d.   use to show that @xmath63 must explode .    in , we will implement the above program to extend the results in theorem [ thm : capbound ] ( i.e. @xmath9 approaches capacity only as @xmath410 ) for a range of noise distributions . we also generalize the moment constraint on the input distribution , allowing @xmath34 to be restricted to an arbitrary convex set . however , the extension of the awgn result to a wider class of noise distributions requires new deconvolution results that are similar in spirit to lemmas [ lem : capks ] and [ lem : concentration ] .",
    "these results are the focus of the present section .",
    "if @xmath37 is convex and @xmath411 , then there exists a unique capacity - achieving output distribution @xmath412 @xcite .",
    "in addition , by the saddle - point characterization of capacity , @xmath413 consequently , for any @xmath414 , we can decompose @xmath415 if the capacity - achieving input distribution @xmath416 is unique , then the same intuition for the gaussian case should hold : ( i ) @xmath34 must be close to the capacity achieving input distribution @xmath416 and ( ii ) @xmath369 must be concentrated on a small ball with high probability .",
    "therefore , as long as @xmath416 is assumed to have no atoms , then @xmath369 and @xmath34 are close to being mutually singular , which , in view of the fact that @xmath417 implies that @xmath63 will explode .    in order to make this proof concrete",
    ", we require additional results to quantify the distance between @xmath34 and @xmath416 ( analogous to lemma [ lem : capks ] in the gaussian case ) , and to show that @xmath418 is concentrated in a small ball ( analogous to lemma [ lem : concentration ] ) for general @xmath153 .",
    "these are precisely the results we present in this section , once again making use of lemma [ lem : esseen ] and fourier - analytic tools .",
    "in particular , we prove a deconvolution result in terms of total variation for a wide range of additive noise distributions @xmath153",
    "( e.g. gaussian , uniform ) .",
    "the main result in this section ( and ) states that , under first moment constraints and certain conditions on the characteristic function of @xmath153 ( e.g. , no zeros , cf .",
    "lemma [ lem : deconvgen ] ) , if @xmath419 is small and @xmath19 has a bounded density , then @xmath420 is also small .",
    "let @xmath421 be the positive , symmetric function @xmath422 and @xmath423 its fourier transform @xmath424 where @xmath425 .",
    "we have the following deconvolution lemma .",
    "[ lem : deconvgen ] assume @xmath153 has density bounded by @xmath426 and that there exists a decreasing function @xmath427\\to { \\mathbb{r}}^+$ ] with @xmath428 such that @xmath429.\\ ] ] then for all distributions @xmath430 and all @xmath431 : @xmath432}-{\\mathbb{e}_{q}\\left [ v(tx - x_0 ) \\right ] } \\right|\\le { c\\over        \\sqrt{t}},\\qquad t = g_1\\left ( m_1{d_{\\rm tv}}(p*p_z , q*p_z ) \\right),\\ ] ] where @xmath433 is an absolute constant .",
    "[ rmk : g1 ]    1 .",
    "the implication of the previous lemma is that @xmath14 and @xmath19 are almost the same on all balls of size approximately @xmath434 .",
    "2 .   for gaussian @xmath153 , @xmath435 . for uniform @xmath153 , @xmath436 .",
    "3 .   without assumptions similar to those of",
    ", it is impossible to have any deconvolution inequality .",
    "for example , if @xmath437 outside of a neighborhood of 0 ( e.g. @xmath219 is proportional to ) , then one may have @xmath438 , but @xmath439 .    denote the density of @xmath3 by @xmath219 . from plancherel s theorem",
    ", we have @xmath440 where the first inequality follows from hlder s inequality , and the second inequality follows from @xmath441 .",
    "assume there exist positive functions @xmath442 and @xmath443 and @xmath444 such that @xmath445 put @xmath446 and @xmath447\\backslash { \\mathcal{d}}$ ] .",
    "then @xmath448 where the third inequality follows cauchy - schwartz inequality .",
    "note that it is sufficient to consider @xmath449 , since otherwise we can simply shift the distributions @xmath14 and @xmath19 without affecting the value of @xmath123 .",
    "in addition , plancherel s theorem and yield @xmath450}=\\frac{1}{t}\\int_{-t}^t { \\varphi}_p(\\omega)\\left(1-\\frac{|\\omega|}{t } \\right)d\\omega .",
    "\\label{eq : ev}\\ ] ] thus , we have @xmath451}-{\\mathbb{e}_{q}\\left [ v(tx ) \\right ] } \\right|&\\leq \\frac{1}{t}\\int_{-t}^t |{\\varphi}_p(\\omega)-{\\varphi}_q(\\omega ) |d\\omega\\\\      & \\leq \\frac{h(t)}{t}+\\frac{\\sqrt{8 \\pi \\delta}}{\\sqrt{t}g(t)}. \\end{aligned}\\ ] ] finally , choosing @xmath452 , @xmath453 and @xmath454 , the result follows .",
    "the methods used in the proof of the previous theorem and , in particular , eq .",
    ", can be used to bound the ks - distance between @xmath14 and @xmath19 , as demonstrated in the next theorem .",
    "[ thm : ks_tv ] assume @xmath153 has density bounded by @xmath426 and that there exists functions @xmath455 and @xmath456 that satisfy assumption .",
    "then for any pair of distributions @xmath14 , @xmath19 where @xmath19 has a density bounded by @xmath457 we get for all @xmath444 : @xmath458 } + { \\mathbb{e}_{q}\\left [ |x| \\right ] } ) } { \\pi t } + \\frac{(2t)^{3/2}}{\\sqrt{\\pi }   g(t)}\\sqrt{m_1{d_{\\rm tv}}(p*p_z , q*q_z)},\\ ] ]    @xmath459 } + { \\mathbb{e}_{q}\\left [ |x| \\right ] } \\right)}{t}\\\\    & \\leq t h(t)+\\frac{t^{3/2}\\sqrt{8\\pi\\delta}}{g(t)}+ \\frac{2\\left ( { \\mathbb{e}_{p}\\left [ |x| \\right ] } + { \\mathbb{e}_{q}\\left [ |x| \\right ] } \\right)}{t},\\end{aligned}\\ ] ]    where the second inequality follows from the triangle inequality and the fact that @xmath460 , we get  .    as a consequence we have the following general deconvolution result which applies to any bounded density",
    "whose characteristic function has no zeros , e.g. , gaussians .",
    "[ cor : deconv - phiz ] assume that @xmath153 has a density bounded by @xmath426 and the characteristic function @xmath461 of @xmath153 has no zero .",
    "let @xmath462 let @xmath430 have finite first moments and @xmath19 has a density @xmath297 bounded by @xmath457",
    ". for any @xmath463 , let @xmath464 be the ( unique ) positive solution to @xmath465 , which satisfies @xmath466 .",
    "then @xmath467 where @xmath468 is a constant depending only on @xmath426 and @xmath469 } + { \\mathbb{e}_{q}\\left [ |x| \\right]}$ ] .    in particular , for @xmath28 , @xmath470 where @xmath471 is a constant depending only on @xmath469 } + { \\mathbb{e}_{q}\\left [ |x| \\right]}$ ] .    by assumption",
    ", we can choose @xmath455 in as and @xmath472 to fulfill .",
    "then leads to @xmath473 where @xmath474 } + { \\mathbb{e}_{q}\\left [ |x| \\right ] } ) , \\sqrt{8 m_1\\pi}\\}/\\pi$ ] . since @xmath153 has a density , @xmath475 by riemann - lebesgue lemma .",
    "since @xmath455 is decreasing and @xmath476 , @xmath477 always has a unique solution @xmath478 .",
    "choosing @xmath479 yields @xmath480 , completing the proof . when @xmath481 , we have @xmath482 .",
    "choosing @xmath483 , the result follows .",
    "consider a gaussian @xmath3 .",
    "then @xmath484 , where the last part follows from pointwise convergence of densities ( scheff s lemma , see , e.g. , @xcite ) .",
    "furthermore , when one of the distributions has bounded density the levy - prokhorov distance ( that metrizes weak convergence ) is equivalent to the kolmogorov - smirnov distance , cf .  @xcite . in this perspective , can be viewed as a finitary version of the implication @xmath485 .",
    "a slightly better bound may be obtained if @xmath486 } < \\infty$ ] .",
    "namely , @xmath487 in the third term in   can be reduced to @xmath488 .",
    "indeed if @xmath489 then elementary truncation shows @xmath490 and then following   we get @xmath491 now the left - hand side of   can be bounded by @xmath492 for the choice of @xmath455 as in   and a straightforward modification for the general case of  .",
    "this improves the constant in  .",
    "with the results introduced in the previous section in hand , we are now ready to extend theorem [ thm : capbound ] to a broader class of additive noise and channel input distributions .",
    "[ thm : generalhoriz ] let @xmath1 and let @xmath37 be a convex set of distributions",
    ". assume that    a.   @xmath153 satisfies the assumption of ; b.   the capacity @xmath493 is finite and attained at some @xmath494 .",
    "then there exists a constant @xmath495 and a decreasing function @xmath496 ( depending on @xmath153 and @xmath37 ) , such that any @xmath107 with @xmath414 satisfies @xmath497 furthermore , if @xmath416 has no atoms , then @xmath498 satisfies @xmath499 .",
    "translates into the following bound on the gap between the @xmath36 curve and the capacity : @xmath500 the function @xmath498 can be chosen to be @xmath501 where @xmath502 , @xmath433 , @xmath503 are as in , and @xmath504      \\label{eq : levy}\\ ] ] is the lvy concentration function @xcite of @xmath505 . for the awgn channel with @xmath347 and @xmath506}}\\leq \\gamma\\}$ ] this gives@xmath507 for some constant @xmath508 .",
    "compared to the gaussian - specific bound  , the general proof loses a factor of two , which is due to the application of pinsker s inequality .    throughout the proof",
    "we assume that @xmath509 and , from , @xmath510 and @xmath511 , where @xmath416 is capacity - achieving .",
    "denote @xmath512 which is joint measurable in @xmath513 for the same reason that @xmath514 defined in is jointly measurable .",
    "pinsker s inequality yields @xmath515 } \\nonumber \\\\          & \\geq 2{\\mathbb{e}}[t(x , w)^2 ] \\nonumber \\\\          & \\geq 2\\epsilon { \\mathbb{p}}[t(x ,",
    "w)^2\\geq \\epsilon ] .",
    "\\label{eq : epsilon - t}\\end{aligned}\\ ] ] define @xmath516 then , from , @xmath517\\geq { \\mathbb{p}}[(x , w)\\in { \\mathcal{f}}]\\geq \\frac{1}{2}.\\ ] ] therefore , for any @xmath518 , there exists @xmath519 such that @xmath520 .",
    "applying lemma [ lem : deconvgen ] with @xmath521 , @xmath522 and @xmath523 , we conclude that @xmath524}}-1 \\right|\\leq \\frac{c}{\\sqrt{t } } , \\label{eq : vdiff1}\\ ] ] where @xmath525 is defined in , @xmath433 is the absolute constant in and @xmath502 .    on the other hand , implies that @xmath526 and hence @xmath527 by pinsker s inequality . applying lemma [ lem : deconvgen ] with @xmath528 , @xmath529 and @xmath523 , we have @xmath530}}-{{\\mathbb{e}_{}\\left [ v(t(x^*-{\\hat{x}_w } ) ) \\right ] } } \\right|\\leq \\frac{c}{\\sqrt{t}}.\\ ] ] for any @xmath531 , since @xmath532 , @xmath533}}=2{{\\mathbb{e}_{}\\left [ \\frac{1-\\cos(t(x^*-x))}{t^2(x^*-x)^2 } \\right]}}\\leq { \\mathbb{p}}[x^*\\in b(x , t^{-3/4})]+\\frac{4}{\\sqrt{t}}.\\ ] ] therefore , @xmath534}}\\leq   { \\mathcal{l}}(x^*;t^{-3/4})+\\frac{4}{\\sqrt{t}}.\\ ] ]    note that the function @xmath525 takes values in @xmath73 $ ] . using the fact that @xmath535 and assembling  , we have for any @xmath518 @xmath536}}-{{\\mathbb{e}_{}\\left [ v(t(x-{\\hat{x}_w } ) ) \\right ] } } \\nonumber\\\\                    & \\geq 1 - { \\mathcal{l}}(x^*;t^{-3/4})-\\frac{4 + 2c}{\\sqrt{t}}. \\label{eq : tv_lb}\\end{aligned}\\ ] ] using and the fact that @xmath537 we have @xmath538}}\\\\        & \\geq { { \\mathbb{e}_{}\\left",
    "[ \\ln \\frac{1}{1-{d_{\\rm tv}}(p_x , p_{x|w})}{\\mathbf{1}}_{w\\in{\\mathcal{g } } } \\right]}}\\\\        & \\geq \\frac{1}{2 } \\ln\\frac{1}{{\\mathcal{l}}(x^*;t^{-3/4})+\\frac{4 + 2c}{\\sqrt{t}}},\\end{aligned}\\ ] ] where the last inequality follows from and . in implies that @xmath539}<1 $ ] .",
    "denote by @xmath495 the supremum of @xmath307 such that @xmath540 and define @xmath541 as in .",
    "this completes the proof of  .",
    "finally , by we have that for diffuse @xmath416 it holds that @xmath499 .",
    "it is possible to extend the results and proof techniques to the case when the channel @xmath542 is a @xmath514-dimensional gaussian channel subject to a total - energy constraint @xmath543 } } \\le 1\\,.$ ] unfortunately , the resulting bound strongly depends on the dimension ; in particular , it does not improve the trivial estimate   as @xmath544 .",
    "it turns out that this dependence is unavoidable as we show next that holds with equality when @xmath545 .    to that end",
    "we consider an infinite - dimension discrete - time gaussian channel . here",
    "the input @xmath546 and @xmath547 are sequences , where @xmath548 and @xmath549 are i.i.d .",
    "similar to definition  [ def : fi ] , we define @xmath550 where the supremum is over all @xmath107 such that @xmath551 } } = { { \\mathbb{e}_{}\\left [ \\sum x_i^2 \\right ] } } \\leq      \\gamma$ ] .",
    "note that , in this case , @xmath552 the next theorem shows that unlike in the scalar case , there is no improvement over the trivial upper bound in the infinite - dimensional case .",
    "this is in stark contrast with the strong data processing behavior of total variation in gaussian noise which turns out to be dimension - free ( * ? ? ?",
    "* corollary 6 ) .",
    "[ thm : infinite ] @xmath553 .    for any @xmath554 and all sufficiently large @xmath555",
    ", there exists @xmath70 and a code of size of @xmath556 for the @xmath70-parallel gaussian channel , where each codeword has energy ( squared @xmath557-norm ) less than @xmath558 , the probability of error is at most @xmath307 , and @xmath559 as @xmath560 ( see , e.g. ( * ? ? ?",
    "7.5.2 ) ) .",
    "choosing @xmath2 uniformly at random over the codewords , we have from fano s inequality @xmath561 for any @xmath562 , define @xmath563 where @xmath279 is an arbitrary vector outside the codebook .",
    "then , @xmath564 \\leq \\gamma$ ] . furthermore , as @xmath565 , @xmath566 and , by the concavity of the mutual information in the input distribution , @xmath567 since @xmath568 , first sending @xmath565 then @xmath569 , we have @xmath570 .",
    "the result then follows by noting that @xmath571 is decreasing and @xmath572 is increasing ( ) .",
    "[ lem : kstalagrand ] assume that @xmath573",
    ". then @xmath574    abbreviate @xmath575 by @xmath576 . from talagrand s inequality (",
    "* thm 1.1 ) @xmath577 since @xmath578 for any measures @xmath579 , there exists a random variable @xmath580 such that @xmath581}}\\leq 2\\sqrt{(1+\\gamma)\\epsilon}.\\ ] ]    let @xmath582 and @xmath583 be the characteristic functions of @xmath576 and @xmath584 , respectively .",
    "then @xmath585 } }                                     \\leq 2|t|\\sqrt{(1+\\gamma)\\epsilon}\\label{eq : kantorovich }      \\end{aligned}\\ ] ] where the second inequality follows from ( * ? ? ?",
    "* lemma 4.1 ) , and the last inequality from . using esseen s inequality ( ) and the fact",
    "that the pdf of @xmath584 is upper bounded by @xmath586 , for all @xmath444 @xmath587 choosing @xmath588 yields @xmath589 the proof is complete upon observing that @xmath590 .",
    "we show that the lvy concentration function defined in is continuous at zero if and only if the distribution has no atoms .",
    "let @xmath593 , which exists since @xmath594 is increasing . since @xmath595}$ ] for any @xmath596 and any @xmath531 , it is sufficient to show that @xmath597}$ ] .",
    "assume that @xmath180 for otherwise there is nothing to prove . by definition , for any @xmath70",
    ", there exists @xmath598 so that @xmath599 } \\geq a - 1/n$ ] .",
    "let @xmath444 so that @xmath600 } \\leq a/2 $ ] .",
    "then @xmath601 for all sufficiently large @xmath70 . by restricting to a subsequence",
    ", we can assume that @xmath598 converges to some @xmath531 in @xmath602 $ ] . by triangle inequality ,",
    "@xmath603 } \\geq { \\mathbb{p}\\left[x \\in b(x_n , 1/n)\\right ] } \\geq a-1/n$ ] . by bounded convergence theorem ,",
    "@xmath604 } \\geq a$ ] , completing the proof .",
    "yihong wu and s.  verd .",
    "the impact of constellation cardinality on gaussian channel capacity . in _ proc .",
    "48th annual allerton conference on communication , control , and computing _ , pages 620628 , september 2010 ."
  ],
  "abstract_text": [
    "<S> this paper quantifies the intuitive observation that adding noise reduces available information by means of non - linear strong data processing inequalities . </S>",
    "<S> consider the random variables @xmath0 forming a markov chain , where @xmath1 with @xmath2 and @xmath3 real - valued , independent and @xmath2 bounded in @xmath4-norm . </S>",
    "<S> it is shown that @xmath5 with @xmath6 whenever @xmath7 , if and only if @xmath3 has a density whose support is not disjoint from any translate of itself .    </S>",
    "<S> a related question is to characterize for what couplings @xmath8 the mutual information @xmath9 is close to maximum possible . to that end </S>",
    "<S> we show that in order to saturate the channel , i.e. for @xmath9 to approach capacity , it is mandatory that @xmath10 ( under suitable conditions on the channel ) . </S>",
    "<S> a key ingredient for this result is a deconvolution lemma which shows that post - convolution total variation distance bounds the pre - convolution kolmogorov - smirnov distance .    </S>",
    "<S> explicit bounds are provided for the special case of the additive gaussian noise channel with quadratic cost constraint . </S>",
    "<S> these bounds are shown to be order - optimal . </S>",
    "<S> for this case simplified proofs are provided leveraging gaussian - specific tools such as the connection between information and estimation ( i - mmse ) and talagrand s information - transportation inequality . </S>"
  ]
}