{
  "article_text": [
    "cooperative relaying is an emerging technology , which provides reliable high data rate transmission for wireless networks without the need of multiple antennas at each node .",
    "these benefits can be further exploited by utilizing judicious cooperative design ( see @xcite and the references therein ) .",
    "most of the existing designs optimize the performance of relay networks with gaussian - input assumptions , for example , maximizing output signal - to - noise ( snr ) @xcite , minimizing mean square error ( mse ) @xcite and maximizing channel capacity @xcite .",
    "despite the information theoretic optimality of gaussian inputs , they can never be realized in practice .",
    "rather , the inputs must be drawn from a finite constellation set , such as pulse amplitude modulation ( pam ) , phase shift keying ( psk ) modulation and quadrature amplitude modulation ( qam ) , in a practical communication system .",
    "these kinds of discrete constellations depart significantly from the gaussian idealization @xcite .",
    "therefore , there exhibits a big performance gap between the scheme designed with the gaussian - input assumption and the scheme designed from the standing point of finite - alphabet constraint @xcite .    in this paper",
    ", we consider the two - hop relay networks with finite - input constraint and utilize linear precoder to improve the maximal possible transmission rate of networks .",
    "we exploit the optimal structure of the precoding matrix under finite - alphabet constraint and develop a unified framework to solve this nonconvex optimization problem .",
    "we prove that the left singular matrix of the precoder coincides with the right singular matrix of the effective channel matrix ; the mutual information is a concave function of the power allocation vector of the precoder ; the optimization of the right singular matrix with unitary constraint can be formulated as an unconstrained one on the complex stiefel manifold .",
    "once these important results are provided , the optimal precoder is solved with a complete two - step iterative algorithm utilizing the theory of convex optimization and optimization on the manifold .",
    "we show that this novel iterative algorithm achieves significant gains compared to its conventional counterpart .",
    "_ notation : _ boldface uppercase letters denote matrices , boldface lowercase letters denote column vectors , and italics denote scalars .",
    "the superscripts @xmath0 and @xmath1 stand for transpose and hermitian operations , respectively .",
    "the subscripts @xmath2 and @xmath3_{ij}$ ] denote the @xmath4-th element of vector @xmath5 and the ( @xmath6)-th element of matrix @xmath7 , respectively .",
    "the operator @xmath8 represents a diagonal matrix whose nonzero elements are given by the elements of vector @xmath9 .",
    "furthermore , @xmath10 represents the vector obtained by stacking the columns of @xmath11 ; @xmath12 and @xmath13 represents an identity matrix and a zero matrix of appropriate dimensions , respectively ; @xmath14 denotes the trace operation . besides , all logarithms are base 2 .",
    "@xmath15\\right\\}.\\ ] ]    @xmath16\\left[\\sum_{k=1}^{m^{2l}}\\mathbf{x}_{k}^{h}\\exp\\left(-\\vert\\mathbf{y}-\\mathbf{hp}\\mathbf{x}_{k}\\vert^{2}\\right)\\right]}{\\sum_{m=1}^{m^{2l}}\\exp\\left(-\\vert\\mathbf{y}-\\mathbf{hp}\\mathbf{x}_{m}\\vert^{2}\\right)}d\\mathbf{y}.    \\end{aligned}\\ ] ]    consider a relay network with one transmit - and - receive pair , where the source node attempts to communicate to the destination node with the assistance of @xmath17 relays ( @xmath18 ) .",
    "all nodes are equipped with a single antenna and operated in half - duplex mode .",
    "we consider a flat fading cooperative transmission system , in which the channel gain from the source to the destination is denoted by @xmath19 , whereas those from the source to the @xmath4-th relay and from the @xmath4-th relay to the destination are denoted as @xmath20 and @xmath21 , respectively .",
    "we focus on the amplify - and - forward protocols combined with single relay selection @xcite .",
    "the signal transmission is carried out by blocks with block length @xmath22 , @xmath23 .",
    "for the selected relay node , there is a data receiving period of length @xmath24 before a data transmitting period of length @xmath24 .",
    "the original data at the source node is denoted by @xmath25^t,\\ ] ] where @xmath26^{t}$ ] , @xmath27^{t}$ ] with @xmath28 being the data symbol at the @xmath29-th time slot , @xmath30 .",
    "we assume that the original information signals are equally probable from discrete signaling constellations such as psk , pam , or qam with unit covariance matrix , _",
    "i.e. _ , @xmath31= \\mathbf{i}$ ]",
    ".    the original data is processed by a precoding matrix before being transmitted from the source node .",
    "the precoded data @xmath32^t$ ] is given by @xmath33 , where @xmath34 is a _",
    "generalized _ complex precoding matrix .",
    "the source node sends the signal @xmath35 with power constraint @xmath36 during the first @xmath24-time slots .",
    "let @xmath37 and @xmath38 be received signals at the @xmath4-th relay node and the destination , respectively , which are given by @xmath39 where @xmath40 and @xmath41 denote , respectively , the independent and identically distributed ( i.i.d . )",
    "zero - mean circularly gaussian noise with unit variance at the @xmath4-th relay and the destination .",
    "assuming the @xmath42-th relay node is selected at the second @xmath43-time slots , it scales the received signal by a factor @xmath44 ( so that its average transmit power is @xmath45 ) and forwards it to the receiver .",
    "we assume only the second - order statistics of @xmath46 is known at the @xmath42-th relay node , then @xmath44 can be chosen as @xmath47\\right)}$ ] . at the second @xmath43-time slots",
    ", the source node sends the signal @xmath48 .",
    "therefore , the destination node receives a superposition of the relay transmission and the source transmission according to @xmath49 where @xmath50 denotes the noise vector of the destination at the second @xmath43-time slots , and @xmath51 denotes the effective noise @xmath52 with @xmath53 .    for convenience in the presentation",
    ", we normalize @xmath54 by @xmath55 and denote the received signal vector as @xmath56^{t}$ ] .",
    "thus , the effective input - output relation for the two - hop transmission with precoding is summarized as @xmath57 where @xmath58 is the original transmitted signal vector ; @xmath59^{t}$ ] is i.i.d .",
    "complex gaussian channel noise vector with zero mean and unit variance , _",
    "i.e. _ , @xmath60 ; @xmath61 is the effective channel matrix of the two - hop relay channel @xmath62.\\ ] ]    our precoding scheme is thus the design of matrix @xmath34 to maximize the mutual information with finite - alphabet constraints .",
    "note that for the proposed algorithm to be effectively implemented in practice , the destination estimates effective channel matrices of relay networks through pilot assisted channel estimation",
    ". then the destination node selects one relay for cooperation and provides the corresponding effective channel to the source node via a feedback channel . considering the special structure of the channel matrix",
    ", the amount of the feedback can be very small .",
    "after signal feedback , the source node utilizes the proposed precoding algorithm to optimize the network performance .",
    "we consider the conventional equiprobable discrete constellations such as @xmath63-ary psk , pam , or qam , where @xmath63 is the number of points in the signal constellation .",
    "the mutual information between @xmath58 and @xmath64 , with the equivalent channel matrix @xmath61 and the precoding matrix @xmath65 known at the receiver , is @xmath66 given by ( [ eq : mutualinfo ] ) , where @xmath67 denotes euclidean norm of a vector ; both @xmath68 and @xmath69 contain @xmath22 symbols , taken independently from the @xmath63-ary signal constellation @xcite .",
    "[ prop : mutual_info ] let @xmath70 be a unitary matrix , and the following relationships hold : @xmath71    see proof in @xcite .",
    "proposition [ prop : mutual_info ] implies that the property of mutual information for the discrete input vector is different from the case of gaussian inputs . for gaussian inputs ,",
    "the mutual information is unchanged when either transmitted signal @xmath72 or received signal @xmath73 is rotated by a unitary matrix .",
    "the case of finite inputs does not follow the same rule .",
    "therefore , it provides us a new opportunity to improve the system performance .",
    "the optimization of the linear precoding matrix @xmath74 is carried out over all @xmath75 complex precoding matrices under transmit power constraint , which can be cast as a constrained nonlinear optimization problem @xmath76\\right\\ }      = { \\text{tr}}\\left(\\mathbf{pp}^h\\right ) \\leq 2l .",
    "\\end{array}\\ ] ]    [ prop : optimalcondition ] the optimal precoding matrix @xmath77 for the optimization problem satisfies the following condition @xcite @xmath78 where @xmath79 is chosen to satisfy the power constraint , and @xmath80 is the minimum mean square error ( mmse ) matrix given by ( [ eq : mmse ] ) .",
    "see proof in @xcite .",
    "it is important to note that proposition [ prop : optimalcondition ] gives a necessary condition satisfied by any critical points , since the optimization problem ( [ eq : opt - prob - original ] ) is nonconvex .",
    "it is possible to develop an algorithm based on the gradient of the lagrangian as proposed in @xcite .",
    "however , this kind of algorithms can be stuck at a local maximum , which is influenced by the starting point and may be far away from the optimal solution .",
    "this fact will be shown via an example in the sequel .",
    "we start by characterizing the dependence of mutual information @xmath81 on precoder @xmath34 .",
    "consider the singular value decomposition ( svd ) of the @xmath82 channel matrix @xmath83 , where @xmath84 and @xmath85 are unitary matrices , and the vector @xmath86 contains nonnegative entries in decreasing order .",
    "note that the equivalent channel matrix @xmath87 defined in is full rank for any nonzero channel gain @xmath88 .",
    "we also consider the svd of the precoding matrix @xmath89 and define @xmath90 and @xmath91 , where @xmath70 and @xmath92 are named as the left and right singular vectors , respectively ; the vector @xmath93 is nonnegative constrained by transmit power .",
    "[ prop : leftsingularmatrix ] the mutual information depends on the precoding matrix @xmath74 only through @xmath94 . for a given @xmath94 , we can always choose the precoding matrix of the form @xmath95 in order to minimize the transmit power @xmath96 , _",
    "i.e. _ , the left singular vector of @xmath74 coincides with the right singular vector of @xmath87 .",
    "see proof in @xcite .    from the results in proposition [ prop : mutual_info ] and [ prop : leftsingularmatrix ] , it is possible to simplify the channel matrix to @xmath97 now our discussion will be based on this simplified channel model .",
    "the optimization variables are power allocation vector @xmath98 and right singular vector @xmath99 , which are the focuses of the next two subsections . in the sequel",
    ", we will use @xmath100 and @xmath101 to emphasize the dependence of mutual information on variables @xmath93 and @xmath99 , respectively .      given a right singular vector of the precoder , we consider the following optimization problem over the power allocation vector @xmath98 @xmath102 where @xmath103 denotes a column vector with all entries one .    [ prop : hessian - concavity ]",
    "the mutual information is a concave function of the squared singular values of the precoder , @xmath93 , _",
    "i.e. _ , the mutual information hessian with respect to the power allocation vector satisfies @xmath104 . moreover , the jacobian of the mutual information with respect to the power allocation vector @xmath93 is given by @xmath105 where @xmath106 is a reduction matrix given by @xmath107_{i,2l(j-1)+k}=\\delta_{ijk } , \\quad { i , j , k}\\in \\left[1,2l\\right].\\ ] ]    see proof in @xcite .",
    "the concavity result in proposition [ prop : hessian - concavity ] extends the hessian and concavity results in ( * ? ? ?",
    "* theorem 5 ) from real - valued signal model to a generalized complex - valued case .",
    "it ensures to find the global optimal power allocation vector given a right singular vector @xmath99 , and the gradient result in provides the possibility to develop a steepest descent type algorithm to achieve the global optimum @xcite .",
    "we first rewrite the problem using the _ barrier _ method : @xmath108 where @xmath109 is the _ logarithmic barrier _ function , which approximates an indicator illustrating whether constraints are violated @xmath110 with the parameter @xmath111 setting the accuracy of the approximation .",
    "the gradient of objective function is @xmath112 where @xmath113 is the @xmath114-th element of vector @xmath115 .",
    "therefore , the steepest descent direction is chosen as @xmath116 then it is necessary to decide a positive step size @xmath117 so that @xmath118 .",
    "the backtracking line search conditions @xcite states that @xmath119 should be chosen to satisfy the inequalities @xmath120 the above ideas can be summarized as the following algorithm , which ensures to converge to the optimal power allocation vector because of the concavity .    [ alg : power - allocation ] steepest descent to maximize the mutual information over power allocation vector    1 .   given a feasible @xmath93 , @xmath121 , @xmath122 , tolerance @xmath123 .",
    "[ item : gradient]compute the gradient of @xmath124 at @xmath93 , @xmath125 , as and the descent direction @xmath126 . set the step size @xmath127 .",
    "3 .   evaluate @xmath128 .",
    "if it is sufficiently small , then go to step [ item : update - t ] .",
    "[ item : line - search-2 ] if @xmath129 , then set @xmath130 , and repeat step [ item : line - search-2 ] .",
    "[ item : line - search-1 ] if @xmath131 , then set @xmath132 , and repeat step [ item : line - search-1 ] . 6 .",
    "set @xmath133 .",
    "go to step [ item : gradient ] .",
    "[ item : update - t ] stop if @xmath134 , else @xmath135 , and go to step [ item : gradient ] .",
    "this section considers an alternative optimization problem for maximizing the mutual information over the right singular vector @xmath99 for a given power allocation vector , @xmath136 this unitary matrix constrained problem can be formulated as an unconstrained one in a constrained search space @xmath137 where we define the function @xmath138 as @xmath139 , and with domain restricted to the feasible set : @xmath140 in which the set @xmath141 is _ complex stiefel manifold _ @xcite @xmath142    associated with each point @xmath143 is a vector space called _ tangent space _ , which is formed by all the tangent vectors at the point @xmath99 .",
    "[ prop : gradient - on - tangent ] the gradient of the mutual information on the tangent space is @xmath144    see proof in @xcite .    utilizing the gradient on the tangent space as the descent direction has been suggested in @xcite , _",
    "i.e. _ , @xmath145 ; however , moving towards the direction on the tangent space may lost the unitary property .",
    "therefore , it needs to be restored in each step via projection .",
    "the projection of an arbitrary matrix @xmath146 onto the stiefel manifold @xmath147 is defined to be the point on the stiefel manifold closest to @xmath148 in the euclidean norm @xmath149    [ prop : projection ] let @xmath146 be a full rank matrix . if the svd of @xmath148 is @xmath150 , the projection is unique , which is given by @xmath151 .",
    "see proof in @xcite",
    ".    combining the search direction and projection method with the line search conditions in and , we are able to develop the optimization algorithm to maximize the mutual information over the right singular vector @xmath152 .",
    "[ alg : right - singular - matrix ] steepest descent to maximize the mutual information on complex stiefel manifold    1 .",
    "given a feasible @xmath153 such that @xmath154 .",
    "[ item : gradient - v]compute the gradient of @xmath155 at @xmath152 , @xmath156 , as and the descent direction @xmath157 . set the step size @xmath127 .",
    "3 .   evaluate @xmath158 .",
    "if it is sufficiently small , then stop .",
    "[ item : line - search - v-2 ] if @xmath159 , then set @xmath130 , and repeat step [ item : line - search-2 ] .",
    "[ item : line - search - v-1 ] if @xmath160 , then set @xmath132 , and repeat step [ item : line - search - v-1 ] .",
    "6 .   set @xmath161",
    ". go to step [ item : gradient - v ] .",
    "now we are ready to develop a complete two - step approach to maximize the mutual information over a generalized precoding matrix @xmath34 via combining proposition [ prop : leftsingularmatrix ] and algorithm [ alg : power - allocation ] and [ alg : right - singular - matrix ] .",
    "[ alg : general - p ] two - step algorithm to maximize the mutual information over a generalized precoding matrix    1 .   set the left singular vector of the precoder @xmath162 , and give a feasible @xmath93 and @xmath152 .",
    "[ item : algfull - alg1 ] _ update power allocation vector _ : run algorithm [ alg : power - allocation ] given @xmath152 .",
    "3 .   _ update right singular vector _ : run algorithm [ alg : right - singular - matrix ] given @xmath93 .",
    "4 .   go to step [ item : algfull - alg1 ] until convergence .",
    "we consider a single - relay network with the block length @xmath163 and the channel coefficient @xmath164 , @xmath165 and @xmath166 .",
    "we assume the same transmit power at the source and relay node ( _ i.e. _ , @xmath167 ) , and the snr is 3 db .",
    "when the elements of the transmitted signal @xmath168 is drawn independently from bpsk constellations , the mutual information is bounded by 1 bit / s / hz as shown in .",
    "the convergence of the proposed approach is illustrated in fig .",
    "[ fig : twostepconvergence ] .",
    "we also show the convergence of algorithms proposed in @xcite . from fig . [",
    "fig : twostepconvergence ] , it is shown that the direct gradient method is stuck at a local maximum ( 0.53 bit / s / hz ) .",
    "the reason for such performance is that the optimization problem is not convex in general .",
    "in contrast , the proposed two - step algorithm exploits the characterization of the optimal solution , which leads to a solution with the optimal left singular vector , the optimal power allocation vector ( for a given right singular vector ) , and the local optimal right singular vector from an arbitrary start point .",
    "hence , the algorithm is able to converge to a much higher value ( 0.85 bit / s / hz ) with about 60 percent improvement .",
    "note that the progress of the proposed method has a staircase shape , with each stair associated with either the iteration for @xmath169 , named as outer iteration in @xcite , or the change between the optimizations of the power allocation vector and the right singular vector .",
    "the performance of the proposed algorithm is shown is fig .",
    "[ fig : twostepsnr ] , in which the information symbol @xmath58 is modulated as qpsk , and the channel is the same as the above case . for the sake of completeness , we also show the performance corresponding to the case of no precoding , maximum diversity design in @xcite , maximum coding gain design in @xcite , and maximum capacity design with gaussian inputs assumption in @xcite . from fig .",
    "[ fig : twostepsnr ] , we have following several observations .",
    "the method based on maximizing capacity with gaussian - input assumption may result in a significant _ loss _ for discrete inputs , especially when the snr is in medium - to - high regions .",
    "the reason comes from the difference in design power allocation vector and right singular vector . for gaussian inputs ,",
    "it is always helpful to allocation more power to the stronger subchannels and less power to the weaker subchannels to maximize the capacity .",
    "however , this does not work for the case of finite inputs .",
    "since the mutual information of the relay network is upper bounded by @xmath170 from , there is little incentive to allocate more power to subchannels when they are already close to saturation .",
    "moreover , the right singular vector for gaussian inputs is an arbitrary unitary matrix to maximize the capacity , because the mutual information is unchanged when the input signal is rotated by a unitary matrix .",
    "the maximum coding gain design has better performance than the method of maximum diversity order and no precoding .",
    "we should note that the maximum coding design in @xcite is only valid for the case of block length @xmath163 and qpsk inputs ; it is extended to the case of @xmath163 and 16-qam inputs in @xcite .    the proposed two - step precoder optimization results in significant gain on mutual information in a wide range of snr region .",
    "for example , it is about 2 db , 4 db and 10 db better than the method of maximum coding gain , no precoding and maximum capacity , respectively , when the channel coding rate is 2/3 .",
    "moreover , this algorithm is able to be utilized for an arbitrary block length @xmath43 and input type .",
    "in this paper , we have studied the precoding design for dual - hop af relay networks .",
    "in contrast with the previous work utilizing various design criteria with the idealistic gaussian - input assumptions , we have formulated the linear precoding design from the standpoint of discrete - constellation inputs . to develop an efficient precoding design algorithm ,",
    "we have chosen the mutual information as the utility function .",
    "unfortunately , the maximization of this utility function over all possible complex precoding matrix is nonconvex , _",
    "i.e. _ , the direct optimization on the precoder can be stuck at a local maxima , which is influenced by the starting point and may be far away from the optimal solution .",
    "we have exploited the structure of the precoding matrix under finite - alphabet constraint and developed a unified framework to solve this nonconvex optimization problem .",
    "we have proposed a two - step iterative algorithm to maximize the mutual information .",
    "numerical examples have shown substantial gains of our proposed approach on mutual information compared to its conventional counterparts .",
    "a.  b. gershman , n.  d. sidiropoulos , s.  shahbazpanahi , m.  bengtsson , and b.  ottersten , `` convex optimization - based beamforming : from receive to transmit and network designs , '' _ ieee signal process mag .",
    "_ , vol .  27 , no .  3 , pp .",
    "6275 , 2010 .",
    "y.  rong , x.  tang , and y.  hua , `` a unified framework for optimizing linear nonregenerative multicarrier mimo relay communication systems , '' _ ieee trans .",
    "signal process .",
    "_ , vol .",
    "57 , no .  12 , pp . 48374851 , 2009 .",
    "m.  payaro and d.  p. palomar , `` hessian and concavity of mutual information , differential entropy , and entropy power in linear vector gaussian channels , '' _ ieee trans .",
    "inform . theory _",
    "55 , no .  8 , pp . 36133628 , 2009 .",
    "y.  ding , j.  zhang , and k.  wong , `` the amplify - and - forward half - duplex cooperative system : pairwise error probability and precoder design , '' _ ieee trans .",
    "signal process .",
    "_ , vol .",
    "55 , no .  2 ,",
    "605617 , 2007 ."
  ],
  "abstract_text": [
    "<S> in this paper , we investigate the optimal precoding scheme for relay networks with finite - alphabet constraints . </S>",
    "<S> we show that the previous work utilizing various design criteria to maximize either the diversity order or the transmission rate with the gaussian - input assumption may lead to significant loss for a practical system with finite constellation set constraint . a linear precoding scheme is proposed to maximize the mutual information for relay networks . </S>",
    "<S> we exploit the structure of the optimal precoding matrix and develop a unified two - step iterative algorithm utilizing the theory of convex optimization and optimization on the complex stiefel manifold . </S>",
    "<S> numerical examples show that this novel iterative algorithm achieves significant gains compared to its conventional counterpart . </S>"
  ]
}