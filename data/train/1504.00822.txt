{
  "article_text": [
    "a quantum css code is a particular instance of a quantum stabilizer code , and can be defined by two classical binary linear codes @xmath2 and @xmath3 in the ambient space @xmath4 , with the property that @xmath5 and @xmath6 . in other words , the classical codes @xmath2 and @xmath3 come together with respective parity - check matrices @xmath7 and @xmath8 such that the linear space @xmath9 generated by the rows of @xmath7 is orthogonal to the row space @xmath10 of @xmath8 , where orthogonality is with respect to the standard inner product . an _ error pattern _ is defined as a couple @xmath11 , where @xmath12 and @xmath13 are both binary vectors .",
    "the decoder is given the pair of _ syndromes _ @xmath14 and @xmath15 and decoding succeeds if it outputs , not necessarily the initial error pattern @xmath11 , but a couple of the form @xmath16 where @xmath17 and @xmath18 .",
    "see @xcite for the equivalence with the stabilizer formalism and a detailed introduction to quantum coding .",
    "if efficient quantum computing is to be achieved , it will come with a strong error - correcting component , that will involve very fast decoders , probably in not much more than linear time in the blocklength @xmath1 .",
    "the likeliest candidates for this task are quantum ldpc codes : in the css case , an ldpc code is simply a code whose above parity - check matrices @xmath7 and @xmath8 have row and column weights bounded from above by a constant . among recent developments ,",
    "the recent paper @xcite has shown how fault tolerant quantum computation with constant multiple overhead can be obtained , and quantum ldpc codes are an essential component of the scheme , making them possibly even more appealing .",
    "it is natural to hope that the success of classical ldpc codes , both in terms of performance and of decoding efficiency , can eventually be matched in the quantum setting .",
    "this agenda involves two major difficulties , however .",
    "the first one is that coming up with intrinsically good constructions of quantum ldpc codes is in itself a challenge .",
    "in particular the random constructions that can be so effective in the classical case do not work at all in the quantum case .",
    "indeed if one chooses randomly a sparse parity - check matrix @xmath7 , then , precisely since this gives a good classical code , there are no low - weight codewords in the dual of the row - space of @xmath7 and therefore an appropriate matrix @xmath8 does not exist . a testament to this difficulty",
    "is given in the introduction of @xcite by way of a list of proposed constructions of quantum ldpc codes from within the classical coding community that all yield constant minimum distances .",
    "presently , the known constructions of families of quantum ldpc codes that come with constant rates and minimum distances that grow with the qubit length can be reduced to essentially three constructions .",
    "the first consists of quantum codes based on tilings of two - dimensional hyperbolic manifolds ( surfaces ) that generalize kitaev s toric code and originate in @xcite .",
    "the minimum distance of these codes grows as @xmath19 , where @xmath1 is the qubit length .",
    "a recent generalisation of this approach to @xmath20-dimensional hyperbolic geometry @xcite yields minimum distances that behave as @xmath21 where @xmath22 is larger than some unknown constant and not more than  @xmath23 .",
    "finally , the construction @xcite yields codes of constant rate with minimum distances that grow as @xmath24 .",
    "these codes are perhaps the closest to classical ldpc codes in spirit , since they are constructed by taking a properly defined product of a classical ldpc code with itself .",
    "we note that presently all known constructions of quantum codes , even if they are allowed to have vanishing rate , fail to significantly break the @xmath24 barrier for the minimum distance and it is an intriguing open question as to whether there exist asymptotically good quantum ldpc codes ( i.e. with constant rate and minimum distance linear in @xmath1 ) .",
    "we also make the side remark that gottesman @xcite requires , for the purpose of fault - tolerant quantum computation , constant rate ldpc codes with good minimum distance properties that should behave well under some sort of adversarial error setting .",
    "the second difficulty in attempting to match the achievements of classical ldpc coding , is to devise efficient decoding algorithms .",
    "the vast majority of decoding algorithms developed for classical ldpc codes rely on iterative techniques whose ultimate goal is to take decisions on individual bits . in the quantum setting , taking a decision on an individual qubit is mostly meaningless : this is because a decoder who would try to recover the error vector exactly is doomed to fail , since it would be fooled by any error that spans only half a stabilizer vector ( a row vector @xmath25 of @xmath7 or @xmath26 of @xmath8 ) @xcite .",
    "the eventual error vector that one must look to output is therefore only defined up to addition of stabilizer vectors , so that there is no `` correct value '' for a single qubit of @xmath12 or @xmath13 which can always be just as well @xmath27 or @xmath28 .",
    "decoding quantum ldpc codes requires therefore additional elements to the classical tool kit .",
    "surface codes mentioned above come with efficient decoding algorithms , however they are very particular to the surface code structure , which implies that the associated classical codes @xmath2 and @xmath3 are cycle codes of graphs : full decoding , which is np - hard in general for linear codes , can be achieved for cycle codes of graphs in polynomial time ( with the help of edmonds weighted matching algorithm @xcite ) , and this strategy ( which does not really qualify as a local technique ) yields a decoding scheme for the quantum code that achieves vanishing error - probability for random errors .",
    "unfortunately , this technique does not extend to other classes of ldpc codes , and in an adversarial setting is limited to correcting at most @xmath19 errors , since the minimum distance of surface codes of constant rate can never surpass a logarithm of the qubit length @xcite .",
    "very recently , an alternative decoding algorithm was proposed @xcite for the 4-dimensional hyperbolic codes of guth and lubotzky that is devised to work in a probabilistic setting and for which its adversarial performance is unclear . the third class of constant rate quantum codes with growing minimum distance , namely the codes @xcite , had no known decoding algorithm to go with it until the present paper whose prime objective is to tackle this very problem .    in this paper",
    "we devise a decoding algorithm for the product codes @xcite that runs in linear time and decodes an arbitrary pattern of errors of any weight up to a constant fraction of the minimum distance , i.e. @xmath29 for some constant @xmath30 .",
    "our inspiration is the decoding algorithm of sipser and spielman @xcite which applies to classical ldpc codes whose tanner graph is an expander graph : recall that `` the '' tanner graph ( there may actually be several for the same code ) is a bipartite graph defined on the set of rows and the set of columns of a parity - check matrix for the code and which puts an edge between row @xmath31 and column @xmath32 if the matrix contains a `` 1 '' in position @xmath33 .",
    "the quantum codes under consideration here are products ( in a sense to be given precisely below ) of a classical ldpc code @xmath34 with itself , and we take the original code @xmath34 to be an expander code .",
    "the resulting tanner graphs of the two classical codes @xmath2 and @xmath3 that make up the quantum code are not strictly speaking expander graphs , but they retain enough expanding structure from the original code for a decoding algorithm to work . arguably , this is the first time that an import from classical ldpc coding theory succeeds in decoding a quantum ldpc code from a non - constant number of errors in an adversarial setting .",
    "there are some twists to the original sipser - spielman decoding scheme however , since it guesses values of individual bits and we have pointed out that this strategy can not carry through to the quantum setting .",
    "the solution is to work with _",
    "generators _ rather than qubits : the generators are the row vectors of @xmath7 and @xmath8 ( thus called because they correspond to generators of the stabilizer group of the code ) . at each iteration",
    ", the decoding algorithm looks for a pattern of qubits inside the support of a single generator that will decrease the syndrome weight .",
    "our results also have some significance in the area of local testability .",
    "locally testable codes ( ltc ) play a fundamental role in complexity theory : they have the property that code membership can be verified by querying only a few bits of a word @xcite .",
    "more precisely , the number of constraints not satisfied by a word should be proportional to the distance of the word from the code . given their importance , it is natural to ask whether a quantum version of ltc exists , and to investigate their consequences for the burgeoning field of quantum hamiltonian complexity , which studies quantum satisfaction problems @xcite .",
    "quantum lt codes were recently defined in @xcite , and these hypothetical objects are mainly characterized by their _ soundness _ ( or _ robustness _ ) @xmath35 , i.e. the probability that a word at relative distance @xmath36 from the code violates a randomly chosen constraint .",
    "while we do not exhibit such quantum lt codes here , we construct codes which are robust for errors of reasonably low weight , up to a constant fraction of the minimum distance : see corollary [ robust ] below",
    ". reaching beyond the regime of low weight errors appears to be much harder since it is well - known that the random expander codes at the heart of our construction are not locally testable @xcite .",
    "interestingly , for our construction , better expansion translates into greater robustness .",
    "this should be seen in contrast to results in ref .",
    "@xcite , @xcite , where good expansion ( admittedly not of the same graph ) appears to hurt the local testability of the quantum codes .",
    "we also remark that in the very recent result of @xcite , quantum codes are constructed by applying @xcite to classical lt codes , which leads to an alternative form of robustness where errors with small syndrome weight correspond to highly entangled states .",
    "the remainder of this extended abstract is organized as follows : section  [ sec : mainresult ] describes the code construction with its expanding properties and states the main result .",
    "section  [ basic - algo ] describes the basic decoding algorithm .",
    "section  [ sec : analysis ] gives the main points of the analysis of the algorithm , and states the robustness result .",
    "section  [ sec : conclusion ] gives some concluding comments .",
    "the proofs of the more technical lemmas are relegated to appendices .",
    "let @xmath37 be a biregular bipartite graph with left ( resp .",
    "right ) degree equal to @xmath38 ( resp .",
    "@xmath39 ) . let @xmath40 , @xmath41 , and suppose @xmath42 , so that @xmath43 .",
    "we shall write @xmath44 ( or more concisely , @xmath45 when @xmath46 is clear from context ) to mean that the vertices @xmath47 and @xmath48 are adjacent in the graph @xmath46 .",
    "if @xmath49 is a subset of vertices , denote by @xmath50 the set of all neighbors of vertices of @xmath49 .",
    "let us say that @xmath46 is @xmath51-_left - expanding _",
    ", for some constants @xmath52 , if for any subset @xmath53 with @xmath54 we have @xmath55 .",
    "similarly , we shall say that @xmath46 is @xmath56-_right - expanding _ if for any subset @xmath57 with @xmath58 we have @xmath59 .",
    "finally we shall say that @xmath46 is @xmath60 left - right expanding ( or simply expanding ) is it is both @xmath51-left - expanding and @xmath56-right - expanding .    to any bipartite graph @xmath46",
    "we may associate the @xmath61 matrix @xmath62 , whose rows are indexed by the vertices of @xmath63 , whose columns are indexed by the vertices of @xmath64 , and such that @xmath65 if @xmath31 and @xmath32 are adjacent in @xmath46 and @xmath66 otherwise .",
    "a binary linear code @xmath67 can be thus defined as the set of vectors @xmath68 of @xmath69 such that @xmath70 , i.e. @xmath67 is the code with parity - check matrix @xmath62 .",
    "conversely , any code @xmath34 has a parity - check matrix @xmath62 and the binary matrix @xmath62 can in turn be viewed as an incidence relation between its rows and columns , i.e. a bipartite graph @xmath46 : such a graph is usually called `` the '' tanner graph or the factor graph of the code @xmath34 .",
    "a code has several factor graphs , because it has several parity - check matrices , but it is usually clear which one we are talking about .",
    "expansion and classical error - correction are connected through the following result of sipser and spielman  @xcite .",
    "[ thm : ss ] let @xmath71 be a @xmath72-biregular @xmath51-left - expanding graph . letting",
    "@xmath38 and @xmath39 be fixed and allowing @xmath73 to grow , there exists a decoding algorithm for the associated code @xmath67 that runs in time linear in the code length @xmath74 , and that , under the condition @xmath75 , corrects any pattern of at most @xmath76 errors .",
    "our objective is to derive a quantum analogue of theorem  [ thm : ss ] .",
    "the codes we shall work with are the codes of @xcite , whose construction we briefly recall . as mentioned in the introduction , a css code is defined by two classical codes @xmath2 and @xmath3 : in our case , both these classical codes are constructed from a fixed bipartite graph @xmath71 .",
    "let us describe @xmath2 and @xmath3 through their factor graphs @xmath77 and @xmath78 .",
    "the bipartite graph @xmath77 has left set of vertices @xmath79 , and its right set of vertices is @xmath80 .",
    "the bipartite graph @xmath78 has the same left vertices but its set of right vertices is @xmath81 .",
    "we will find it convenient to denote vertices of @xmath77 and @xmath78 by pairs of letters , omitting parentheses to lighten notation , and to use greek letters for right vertices of @xmath77 , latin letters for right vertices of @xmath78 , and denote elements of @xmath82 by a greek letter followed by a latin letter , and elements of @xmath83 by a latin letter followed by a greek letter .",
    "typical elements of @xmath84 and @xmath81 will therefore be written respectively , @xmath85 , @xmath86 , @xmath87 , and @xmath88 .",
    "the incidence structure of the two graphs is defined as follows :    * in @xmath77 : the set of neighbors of left vertex @xmath89 is defined as @xmath90 the set of neighbors of left vertex @xmath91 is defined as @xmath92 * in @xmath78 : the set of neighbors of left vertex @xmath89 is defined as @xmath93 the set of neighbors of left vertex @xmath91 is defined as @xmath94    the corresponding parity - check matrices @xmath7 and @xmath8 of @xmath2 and @xmath3 may therefore be written in concise form as : @xmath95    it is not difficult to check @xcite that the rows of @xmath7 are orthogonal to the rows of @xmath8 , so that @xmath96 makes up a valid css quantum code .",
    "we also see that the parity - check matrices @xmath7 and @xmath8 are low density , with constant row weight @xmath97 .",
    "it is proved furthermore in @xcite that the parameters of the quantum code @xmath98 are @xmath99\\ ] ] where @xmath100 denotes the _ minimum distance _ of the classical code @xmath67 , i.e. the minimum number of columns of the @xmath61 matrix @xmath62 that sum to zero , and @xmath101 stands for the associated _ transpose minimum distance _ , which is the minimum number of _ rows _ of @xmath62 that sum to zero .",
    "this is with the convention that each of these respective minima is set to equal @xmath102 if there are no subsets of columns , or rows respectively , that sum to zero .",
    "the transpose minimum distance associated to a parity - check matrix of a classical linear code is not a standard parameter because it is usually @xmath102 , but this is not necessarily the case for a matrix associated to a typical bipartite biregular graph , and it can not be totally overlooked .    crucially , if one fixes the degrees @xmath103 with @xmath104 and one takes an infinite family of graphs @xmath71 with increasing number of vertices @xmath105 , the rate of the quantum code @xmath106 is bounded from below by a non - zero constant and its typical minimum distance scales as the square - root of its length @xmath1 .",
    "we remark that the construction of @xcite is somewhat more general , using two base graphs @xmath107 and @xmath108 rather than a single graph @xmath46 .",
    "the above construction corresponds to the case when @xmath109 and we choose to restrict ourselves to this setting for ease of description and notation .",
    "we can now state our main result :    [ thm : main ] let @xmath71 be a @xmath72-biregular @xmath110-left - right - expanding graph .",
    "assume the conditions @xmath111 and @xmath112 .",
    "letting @xmath38 and @xmath39 be fixed and allowing @xmath105 to grow , there exists a decoding algorithm for the associated quantum code @xmath106 that runs in time linear in the code length @xmath113 , and that decodes any quantum error pattern of weight less than @xmath114    [ [ comments . ] ] * comments .",
    "* + + + + + + + + + + +    theorem  [ thm : main ] implies in particular that the quantum code @xmath106 must have a minimum distance proportional to @xmath115 , and that the decoding algorithm corrects a number of adversarial errors equal to a constant fraction of the minimum distance .",
    "we stress that we need both left and right expansion from the graph @xmath46 , and that for these values of @xmath116 and @xmath117 , there are no known constructions that achieve it .",
    "however , the graph @xmath46 with the required expanding properties may be obtained by random choice with classical probabilistic arguments , as developed in @xcite or @xcite .",
    "we first need to describe the decoding problem precisely .",
    "an error pattern is a set of coordinates @xmath118 on which there is an @xmath119 pauli error , together with a set of coordinates @xmath120 on which there is a @xmath121 pauli error .",
    "there may be coordinates in @xmath122 on which an @xmath119 error and a @xmath121 error occur simultaneously , which is equivalent to a @xmath123 pauli error .",
    "the error pattern can therefore be given in equivalent form as the couple of binary vectors @xmath124 where @xmath12 and @xmath13 have supports @xmath125 and @xmath120 respectively .",
    "the input to the decoder is the _ syndrome @xmath126 _ of the error @xmath127 .",
    "it is made up of the classical syndromes of the vectors @xmath12 and @xmath13 for the matrices @xmath7 and @xmath8 , i.e. @xmath128 , with @xmath129 and @xmath130 .",
    "we will say that _ the error pattern @xmath124 is correctly decoded _",
    "if on input @xmath126 the decoder outputs @xmath16 , with @xmath25 and @xmath26 in the row space of @xmath8 and the row space of @xmath7 respectively . our purpose is to exhibit a decoder that will always correctly decode every error @xmath127 of weight smaller than the quantity given in theorem  [ thm : main ] .",
    "the _ weight _",
    "@xmath131 of the error @xmath124 is the number of coordinates  @xmath31 in which at least one of the two vectors @xmath132 is non - zero .    before describing the decoder ,",
    "let us fix some additional notation .",
    "the rows of the matrix @xmath8 are called _ @xmath121-generators _ ( for the purpose of this paper s internal notational coherence : note that this terminology is not standard in the stabilizer formalism ) .",
    "recall that a row of @xmath8 is indexed by an element @xmath88 of @xmath81 .",
    "we choose to identify the corresponding generator with its support in @xmath79 , and denote it by @xmath133 , so that we have : @xmath134    similarly the @xmath119-generators are denoted by @xmath135 and we write @xmath136    the decoding algorithm treats @xmath119 and @xmath121 errors independently .",
    "this means that the decoder applies two separate decoding procedures , one consisting of outputting @xmath137 from @xmath138 , and the other outputting @xmath139 from @xmath140 .",
    "we remark that it is enough to prove theorem  [ thm : main ] for error patterns of the form @xmath141 and of the form @xmath142 .",
    "we will therefore describe the decoding algorithm for errors of type @xmath141 , the other case being symmetric .",
    "note that the weight of the error pattern @xmath143 is simply the hamming weight of the vector @xmath12 , and we denote it by @xmath144 .",
    "the decoding algorithm for @xmath12 works by going through the generators @xmath133 and for each one , by looking at whether flipping any pattern of bits strictly decreases the weight of the syndrome . more precisely : the algorithm takes as input a syndrome vector @xmath145 .",
    "it then looks for a vector @xmath146 such that :    * the support of @xmath147 is included in some generator @xmath133 , * @xmath148 , with @xmath149 , * @xmath150 is maximal , subject to the above two conditions .    if the algorithm can not find a vector @xmath147 satisfying the first two conditions , it outputs a decoding failure .",
    "after @xmath31 decoding iterations , the algorithm is in possession of a syndrome vector @xmath151 , together with a vector @xmath152 , such that    * the support of every @xmath153 , @xmath154 , is included in some generator , * @xmath155 and @xmath156 .",
    "the @xmath157-th decoding iteration consists in finding a vector @xmath158 such that    * the support of @xmath159 is included in some generator @xmath133 , * @xmath160 , with @xmath161 , * @xmath162 is maximal , subject to the above two conditions .",
    "the algorithm proceeds until it reaches some iteration @xmath31 after which it can not find any generator @xmath133 which enables it to decrease the weight of @xmath163 .",
    "if @xmath164 , then it outputs a decoding failure",
    ". otherwise we have @xmath165 , and the algorithm outputs the vector @xmath166 .",
    "we shall prove that if @xmath167 with @xmath144 sufficiently small , then the decoding algorithm never outputs a failure and its output @xmath168 satisfies @xmath169 , equivalently @xmath170 is a sum of @xmath121-generators , meaning the algorithm has correctly decoded the error pattern @xmath12 .    by carefully updating the list of generators",
    "to be re - examined after every iteration , we obtain in a classical way an algorithm that runs in time linear in the number @xmath1 of qubits , in the uniform cost model .",
    "we first recall some tools and results from @xcite .    consider the graph @xmath71 and a subset of vertices @xmath49 .",
    "let us define the set @xmath171 of _ unique neighbors _ of @xmath49 , that is , the set of vertices @xmath172 such that @xmath172 has degree 1 in the graph @xmath173 induced by @xmath49 .",
    "the complement of @xmath171 in @xmath50 will be called the set of _ multiple neighbors _ of @xmath49 and denoted @xmath174 .",
    "provided that the expansion in the graph @xmath46 is large enough , then the graph displays unique - neighbor expansion , in the following sense :    @xcite .",
    "[ unique - exp ] let @xmath37 be a @xmath51-left - expanding graph with @xmath175 .",
    "then , for any subset @xmath176 with @xmath177 , we have : @xmath178 and @xmath179 .",
    "the number of edges incident to @xmath180 should coincide with the number of edges incident to @xmath179 , that is @xmath181 where @xmath182 is the average right degree on @xmath183 .",
    "this implies that @xmath184 .",
    "moreover , the expansion in @xmath46 requires that @xmath185 .",
    "combining both inequalities gives the unique - neighbor expansion .",
    "we also recall from @xcite :    [ prop : d ] if @xmath46 is @xmath51-left - expanding for @xmath186 , then the minimum distance @xmath100 of the associated classical code @xmath67 is at least @xmath187 .    from proposition  [ prop : d ]",
    "we immediately obtain :    [ cor : dmin ] if the graph @xmath71 is @xmath110-left - right - expanding with @xmath188 , then the minimum distance of the associated quantum code @xmath106 is at least @xmath189 .",
    "proposition  [ prop : d ] implies that the minimum distance of the associated classical code is at least @xmath187 , and , by inverting the roles of @xmath64 and @xmath63 , that the transpose minimum distance is at least @xmath190 .",
    "the result follows from .",
    "the crucial part of the original decoding strategy of sipser and spielman consists in showing that , for errors of sufficiently small weight , there must exist ( at least ) one critical variable vertex of @xmath64 in error that has many unique neighbors . flipping the bit associated with this",
    "vertex decreases the syndrome value and this eventually leads to showing that one can always decode correctly by flipping bits that decrease the syndrome weight , provided the initial error is sufficiently small . in the present setting ,",
    "we need a corresponding notion of criticality for generators .",
    "it will build upon the unique neighbor idea with a number of twists .",
    "[ def : critical ] let @xmath191 be a subset of vertices that can be thought of as an error pattern .",
    "let us say that a generator @xmath192 is _ critical _ ( with respect to @xmath193 ) if it can be partitioned as follows : @xmath194 where    * @xmath195 is a partition of @xmath196 and @xmath197 is a partition of @xmath198 , * @xmath199 , @xmath200 and @xmath201 , * every vertex in @xmath202 has exactly two neighbors in @xmath193 , * every vertex in @xmath203 has no neighbor in @xmath193 , * every vertex in @xmath204 and every vertex in @xmath205 has exactly one neighbor in @xmath193 , * @xmath206 , @xmath207 .",
    "note that definition  [ def : critical ] implies in particular that the syndrome vector has value @xmath27 in the coordinates indexed by @xmath208 and @xmath203 , and has value @xmath28 in the coordinates indexed by @xmath209 and in @xmath205 .",
    "see fig .",
    "[ syndrome ] for details .",
    "lemma  [ goodgen ] below asserts that a critical generator with respect to an error pattern always exists , whenever the error pattern @xmath193 has sufficiently small weight ( cardinality ) , and lemma  [ errordecreases ] claims that its is always possible to modify the pattern of qubits inside a critical generator in a way as to simultaneously decrease the syndrome weight and not increase the error weight .",
    "recall that we are decoding an @xmath119-error @xmath12 that we simply denote @xmath127 from now on .",
    "[ goodgen ] if the weight of the error @xmath127 satisfies @xmath210 , then there exists a critical generator @xmath133 with respect to the support @xmath193 of @xmath127 .",
    "the proof of lemma  [ goodgen ] is given in appendix  [ sec : goodgen ] .",
    "if @xmath127 is a vector of @xmath4 , let us call its _ reduced weight _ , denoted @xmath211 , the smallest hamming weight of an element of the coset @xmath212 , i.e. the set of vectors of the form @xmath213 , where @xmath214 is a sum of @xmath121-generators .",
    "[ errordecreases ] if the reduced weight of the error @xmath127 satisfies @xmath215 , then there exists a critical generator together with a vector @xmath147 whose support is included in the generator , such that @xmath216 . in words , flipping the @xmath217 bits of the support of @xmath147 decreases the syndrome weight by at least @xmath218 .",
    "moreover , @xmath219 .",
    "the proof of lemma  [ errordecreases ] is given in appendix  [ sec : errordecreases ] .",
    "the decoding algorithm is analyzed in two steps .",
    "first we show that it never outputs a decoding failure , i.e. always decreases the syndrome weight to zero , and secondly we prove the output error vector @xmath168 is equivalent to the original vector @xmath127 modulo the space of @xmath121-generators .",
    "lemma [ errordecreases ] implies the _ robustness _ of the quantum code .",
    "[ robust ] any error @xmath127 with reduced weight @xmath220 has a syndrome with weight bounded from below as @xmath221 .    without loss of generality ,",
    "suppose @xmath127 is a representative of @xmath212 with minimum weight .",
    "as long as the weight of the syndrome is positive , lemma [ errordecreases ] guarantees the existence of a generator and a vector @xmath147 whose support is included in the generator such that @xmath216 .",
    "moreover , since @xmath222 , we can apply lemma [ errordecreases ] again to @xmath223 and iterate , say @xmath31 times , until the syndrome weight reaches 0 .",
    "after @xmath31 iterations , we obtain that the syndrome of @xmath224 is 0 , hence that @xmath225 and that @xmath226 .",
    "this last fact implies by corollary  [ cor : dmin ] that @xmath227 is in @xmath228 , i.e. that @xmath127 is equal to @xmath229 modulo a sum of @xmath121-generators .",
    "inequality proves therefore that @xmath230 .",
    "unfortunately , the decoding algorithm is not guaranteed to follow the good decoding path exhibited by lemma  [ errordecreases ] .",
    "indeed , the decoding algorithm simply tries to optimize the weight of the syndrome , but the error weight might increase in the process .",
    "nevertheless , we have :    [ terminates ] if the hamming weight of the initial error @xmath127 is less than @xmath231 , then the decoding algorithm never outputs a decoding failure and always correctly decodes @xmath127 .",
    "the decoding algorithm chooses a sequence of vectors @xmath232 such that @xmath233 is a decreasing sequence .",
    "set @xmath234 .",
    "now whenever @xmath235 lemma  [ errordecreases ] ensures that @xmath236 by hypothesis holds for @xmath237 .",
    "suppose it holds for @xmath238 , we then have @xmath239 .",
    "writing @xmath240 we get @xmath241 since the syndrome @xmath242 has weight at most @xmath243 . from the hypothesis on the hamming weight of @xmath127",
    "we get that holds for @xmath244 , and inductively until the eventual output of the algorithm @xmath245 , such that @xmath246 has zero syndrome .",
    "condition translates to @xmath247 which ensures by corollary  [ cor : dmin ] that @xmath248 , which means exactly that @xmath168 is a valid representative of the initial error  @xmath127 .",
    "we have exhibited a linear - time decoding algorithm that corrects up to @xmath249 _ adversarial _ quantum errors over @xmath1 qubits .",
    "while this is the largest such asymptotic quantity to date , one would hope to break this barrier and eventually achieve correction of @xmath250 errors .",
    "if one were to do this with quantum ldpc codes , this would imply obtaining the elusive proof of existence of low - density codes with a minimum distance scaling linearly in the number of qubits .",
    "kovalev and pryadko have shown @xcite that the codes of @xcite have the potential to correct number of _ random _ depolarizing errors that scales linearly in @xmath1 , with a vanishing probability of decoding error .",
    "this is without decoding complexity limitations however , and a natural question is whether the ideas of the present paper can extend to decoding @xmath250 random errors in linear or quasi - linear time .    we have worked to achieve the smallest possible value of @xmath251 in theorem  [ thm : main ] , i.e. the smallest possible expansion coefficient for the base graph @xmath46 .",
    "can the bound @xmath252 be decreased further  ?",
    "a somewhat related question is whether the left - right expanding base graph @xmath46 can be obtained constructively , rather than by random choice  ?    10    dorit aharonov and lior eldar . . , 2013",
    "dorit aharonov and lior eldar . . , 2013",
    "leonid  a bassalygo .",
    "asymptotically optimal switching circuits . , 17(3):8188 , 1981 .",
    "eli ben - sasson , prahladh harsha , and sofya raskhodnikova . .",
    ", 35(1):121 , 2005 .",
    "nicolas delfosse . .",
    "in _ information theory proceedings ( isit ) , 2013 ieee international symposium on _ , pages 917921 .",
    "ieee , 2013 .",
    "jack edmonds . .",
    ", 17(3):449467 , 1965 .",
    "lior eldar .",
    "quantum systems with approximation - robust entanglement . , 2015 .",
    "michael  h freedman , david  a meyer , and feng luo . .",
    ", pages 287320 , 2002 .",
    "sevag gharibian , yichen huang , zeph landau , and seung  woo shin . .",
    ", 2014 .",
    "oded goldreich . .",
    "property testing _ , pages 65104 .",
    "springer , 2010 .",
    "daniel gottesman . .",
    "phd thesis , california institute of technology , pasadena , ca , 1997 .",
    "daniel gottesman . .",
    ", 14(15 - 16):13381372 , 2014 .",
    "larry guth and alexander lubotzky . .",
    ", 55(8):082202 , 2014 .",
    "matthew  b hastings . .",
    ", 14(13 - 14):11871202 , 2014 .",
    "alexey  a kovalev and leonid  p pryadko .",
    "fault tolerance of quantum low - density parity check codes with sublinear distance scaling .",
    ", 87(2):020304 , 2013 .",
    "david poulin and yeojin chung . on the iterative decoding of sparse quantum codes .",
    "8:987 , 2008 .    michael sipser and daniel  a spielman . .",
    ", 42(6):17101722 , 1996 .",
    "jean - pierre tillich and gilles zmor . . ,",
    "60(2):11931202 , 2014 .",
    "short version in proceedings of the ieee symposium on information theory , isit 2009 , seoul , pp.799 - 804 .    * appendices *    .",
    "the generator @xmath133 is partitioned into 6 sets : @xmath253 and @xmath254 contain the errors we want to correct , @xmath255 and @xmath256 do not contain any error , and @xmath257 and @xmath258 have a small relative size .",
    "when flipping the qubits corresponding to @xmath253 and @xmath254 ( or the qubits in @xmath255 and @xmath259 ) , the syndromes in @xmath260 and @xmath261 see their weight decrease from 1 to 0 while the syndromes in the sets @xmath262 and @xmath263 remain unchanged ; finally either the syndrome weights in @xmath264 , or in @xmath265 can increase by 1 while the others stay unchanged . ]",
    "first , we need the following extra notation .",
    "let @xmath49 be a subset of @xmath64 in the graph @xmath71 : for a vertex @xmath266 , we denote as follows , respectively , the set of unique neighbors of @xmath47 in the subgraph of @xmath46 induced by @xmath173 , and the set of multiple neighbors of @xmath47 in the same induced graph : @xmath267      suppose first @xmath271 .",
    "consider the projection @xmath272 of @xmath273 on the second coordinate : @xmath274 clearly @xmath275 .",
    "lemma [ unique - exp ] then implies that @xmath276 .",
    "therefore , using the notation , there exists @xmath277 such that @xmath278 .",
    "pick some @xmath279 and @xmath280 .",
    "then the generator @xmath133 can be partitioned into four components @xmath281 which satisfy the requirements of the lemma . specifically , we define @xmath282 , @xmath255 as the complement of @xmath253 in @xmath196 , @xmath283 and @xmath259 as the complement of @xmath258 in @xmath198 . in words ,",
    "@xmath253 and @xmath255 partition the @xmath82 part of the generator @xmath133 into error and error - free components , and @xmath259 and @xmath258 partition the @xmath83 part into , respectively , the set whose second coordinate is a unique neighbor and the set whose second coordinate is a multiple neighbor with respect to @xmath272",
    ".      let us turn our attention to the remaining case where both @xmath285 and @xmath286 .",
    "we define @xmath272 as above and choose a coordinate @xmath277 such that @xmath287 .",
    "from now on , we use the shorthand @xmath288 for this set , leaving @xmath272 implicit .",
    "next , we define : @xmath289 if @xmath290 , we proceed as in the case where @xmath271 .",
    "otherwise , by assumption on the weight of the error , namely @xmath291 , lemma [ unique - exp ] applies again , this time to the set @xmath292 corresponding to the projection of @xmath293 on its first coordinate , @xmath294 this implies that there exists @xmath295 such that @xmath296 . using the shorthand @xmath297 ,",
    "we define : @xmath298 the construction ensures that every element @xmath87 that belongs both to the neighborhood of @xmath299 and of @xmath300 is such that @xmath301 is a unique neighbor of @xmath48 _ and _ @xmath302 is simultaneously a unique neighbor of @xmath47 , unique neighborhood being understood with respect to @xmath193 .",
    "moreover @xmath303 by construction of the set @xmath304 .",
    "we consider the generator @xmath133 promised by lemma [ goodgen ] . without loss of generality , we may suppose that the error vector @xmath127 is in reduced form , i.e. it is the vector of lowest hamming weight in the coset @xmath212 .",
    "the consequence is that the number of qubit vertices in error @xmath305 within the generator @xmath133 is not more than @xmath306 , otherwise replacing @xmath127 by @xmath307 , with @xmath308 the vector having @xmath133 for support , would yield a vector with strictly smaller hamming weight within the coset @xmath212 .",
    "in particular we have : @xmath309      the expansion condition @xmath312 implies that @xmath313 by the last condition of definition  [ def : critical ] .",
    "@xmath314 and @xmath315 are integers , this implies @xmath316 and @xmath317 , which in turn give : @xmath318      * the syndrome of @xmath223 has strictly smaller weight than the syndrome of @xmath127 , and the difference @xmath319 is at least @xmath320 , * the reduced weight @xmath321 is at most equal to the hamming weight @xmath322 of @xmath127 .      1 .",
    "if @xmath323 , then the vector @xmath147 is chosen to have support @xmath324 , 2 .   if @xmath325 and @xmath326 , then the vector @xmath147 is chosen to have support @xmath324 , 3 .   if the above two hypotheses do not hold and if @xmath327 and @xmath328 , then the vector @xmath147 is chosen to have support either @xmath329 , or its complement in @xmath133 , 4 .   in the remaining cases , we show that either @xmath324 or @xmath329 , or @xmath330 is an adequate choice for the support of @xmath147 .",
    "let us denote by @xmath334 the decrease of the syndrome weight when we flip @xmath324 ( i.e. choose @xmath147 to have support @xmath324 ) . similarly we denote by @xmath335 the decrease of the syndrome weight when we flip either @xmath329 or @xmath330 .",
    "these quantities satisfy : @xmath336 this is because when we flip the bit values on the set @xmath337 , then the value of the syndrome is changed from 1 to 0 on the support @xmath260 and @xmath261 , remains at 0 on the supports @xmath262 and @xmath263 , may possibly change from 0 to 1 on the supports @xmath264 , and remains unchanged in the other regions .",
    "similarly , when we flip the bit values on the set @xmath329 , the syndrome is flipped from 1 to 0 on the support @xmath260 and @xmath261 and possibly from 0 to 1 on @xmath265 while the other regions remain unchanged .      1 .",
    "suppose @xmath338 then can be rewritten as : @xmath339 by applying eq . to @xmath340 and @xmath341 .",
    "the first term is nonnegative for @xmath342 , so that we obtain : @xmath343 furthermore , when @xmath147 has support @xmath337 , the support of @xmath147 is included in the support of @xmath127 , hence @xmath344 and @xmath345 .",
    "if @xmath325 and @xmath326 , then @xmath346 gives @xmath347 , hence , applying , @xmath348 similarly we have @xmath349 and gives @xmath350\\\\ & \\geq \\frac 12 \\left [ x \\delta_b + y \\delta_a \\right]\\\\ & \\geq \\frac 12 \\left| x_a \\cup x_b \\right|.\\end{aligned}\\ ] ] the set @xmath337 is again an adequate choice for the support of @xmath147 , and @xmath345 as before .",
    "if @xmath327 and @xmath328 , then by an argument symmetrical to the preceding case , exchanging @xmath68 with @xmath351 and @xmath352 with @xmath353 , we get : @xmath354 we remark that we must have @xmath355 , otherwise @xmath356 imply that @xmath357 , which contradicts our assumption .",
    "therefore , choosing @xmath147 to have support @xmath329 gives a strict decrease in the syndrome weight that is at least @xmath320 .",
    "now in this case , the _ hamming weight _ @xmath358 is larger than @xmath322 .",
    "however we need to consider its _ reduced weight_. a vector equivalent modulo @xmath228 to @xmath223 is @xmath359 with the support of @xmath360 being @xmath330 .",
    "the hamming weight of @xmath359 is @xmath361 but since @xmath362 and @xmath363 , we have @xmath364 , so that @xmath345 .",
    "4 .   finally , in the remaining case we consider @xmath365 to show that one of the two quantities , @xmath334 or @xmath335 is sufficiently large . adding and yields @xmath366 we now observe that the negation of the condition @xmath367 implies @xmath368 ,",
    "from which we get : @xmath369 the formal equality @xmath370 yields therefore , when combined with , @xmath371 hence , after rearranging , @xmath372 * if @xmath373 , then we choose @xmath147 to have support @xmath337 , and we get @xmath374 from condition .",
    "we have @xmath222 as in cases 1 . and 2 .",
    "* if @xmath375 , then * * either @xmath376 , in which case we set @xmath147 to have support @xmath329 and have @xmath377 and @xmath222 by the same argument as in case 3 , * * or @xmath378 , in which case we set @xmath147 to have support @xmath379 so as to again have @xmath377 .",
    "the hamming weight @xmath358 is at most @xmath380 , which is less than @xmath322 as in case 3 , so that again @xmath345 ."
  ],
  "abstract_text": [
    "<S> we present an efficient decoding algorithm for constant rate quantum hypergraph - product ldpc codes which provably corrects adversarial errors of weight @xmath0 for codes of length @xmath1 . </S>",
    "<S> the algorithm runs in time linear in the number of qubits , which makes its performance the strongest to date for linear - time decoding of quantum codes . </S>",
    "<S> the algorithm relies on expanding properties , not of the quantum code s factor graph directly , but of the factor graph of the original classical code it is constructed from . </S>"
  ]
}