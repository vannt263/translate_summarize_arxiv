{
  "article_text": [
    "a natural language understanding system is a machine that produces an action as the result of an input sentence ( speech or text ) .",
    "there are examples  @xcite of systems that are able of modeling and learning the relationship between the input sentence and the action in a direct way . however ,",
    "when the task is rather complicated , i.e. the set of possible actions is extremely large , we believe that it is necessary to rely on a intermediate symbolic representation . fig .",
    "[ fig : transl ] depicts a natural language understanding as composed of two components .",
    "the first , called _ semantic translator _ analyzes the input sentence in natural language _",
    "( n - l ) _ and generates a representation of its meaning in a formal semantic language _ ( s - l)_. the _ action transducer _ converts the meaning representation into statements of a given computer language _ ( c - l ) _ for executing the required action .",
    "+ although there are several and well established ways  @xcite of performing the semantic translation with relatively good performance , we are interested in investigating the possibility of building a machine that can learn how to do it from the observation of examples",
    ". traditional _",
    "non - learning _ methods are based on grammars ( i.e. set of rules ) both at the syntactic and semantic level .",
    "those grammars are generally designed by hand .",
    "often the grammar designers rely on corpora of examples for devising the rules of a given application .",
    "but the variety of expressions that are present in a language , even though it is restricted to a very specific semantic domain , makes the task of refining a given set of rules an endless job .",
    "any additional set of examples may lead to the introduction of new rules , and while the rate of growth of the number of rules decreases with the number of examples , larger and larger amounts of data must be analyzed for increasing the coverage of a system . moreover , if a new different application has to be designed , very little of the work previously done can be generally exploited .",
    "the situation is even more critical for spoken rather than written language .",
    "written language generally follows _ standard _ grammatical rules more strictly than spoken language , that is often ungrammatical and idiomatic .",
    "besides , in spoken language , there are phenomena like false starts and broken sentences that do not appear in written language . the following is a real example from a corpus of dialogues  @xcite within the airline information domain , ( darpa atis project  @xcite , see section  [ sect : implement ] ) .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ from uh sss from the philadelphia airport um at ooh the airline is united airlines and it is flight number one ninety four once that one lands i need ground transportation to uh broad street in phileld philadelphia what can you arrange for that _   _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    it is clear from this example that rules for analyzing spontaneously spoken sentences can hardly be foreseen by a grammarian .",
    "we believe that a system that learns from examples will ease the work of a designer of text or speech understanding system giving the possibility of analyzing big corpora of sentences .",
    "the question remains on how to collect those corpora , which kind of annotation is needed , and what is the amount of manual work that has to be carried on .",
    "+ the basis of the work exposed in this paper is a semantic translator , called _ chronus . _",
    "chronus is based on a stochastic representation of conceptual entities resulting from the formalization of the speech / text understanding problem as a communication problem .",
    "the paper is structured as follows . in section  [",
    "sect : model ] we formalize the language understanding problem and we propose an algorithm based on the maximum a posteriori decoding . in section  [",
    "sect : implement ] we explain how the described algorithm for conceptual decoding can be part of a complete understanding system and we give a short description of all the modules that were implemented for an information retrieval application . in section  [",
    "sect : practice ] we discuss experimental performance of the system as well as issues related to the training of the conceptual decoder . finally in section  [ sect : conclusion ] we conclude the paper with a discussion on the open problems and the future developments of the proposed learning paradigm .",
    "in this section we propose a formalization of the language understanding problem in terms of the noisy channel paradigm .",
    "this paradigm has been introduced for formalizing the general speech recognition problem  @xcite and constitutes a basis for most of the current working speech recognizers .",
    "recently , a version of the paradigm was introduced for formalizing the problem of automatic translation between two languages  @xcite .",
    "the problem of translating between two languages has the same flavor of the problem of understanding a language  @xcite . in the former ,",
    "both the input and the output are natural languages , while in the latter the output language is a formal semantic language apt to represent meaning .",
    "the first assumption we make is that the meaning of a sentence can be expressed by a sequence of basic units @xmath0 and that there is a _ sequential correspondence _ between each @xmath1 and a subsequence of the acoustic observation @xmath2 , so that we could actually segment the acoustic signal into consecutive portions , each one of them corresponding to a phrase that express a particular @xmath3 .",
    "the second assumption consists in thinking of the acoustic representation of an utterance as a version of the original sequence of meaning units corrupted by a noisy channel whose characteristics are generally unknown .",
    "thus , the problem of understanding a sentence can be expressed in this terms : given that we observed a sequence of acoustic measurements @xmath4 we want to find which semantic message @xmath5 most likely produced it , namely the one for which the a posteriori probability @xmath6 is maximum .",
    "hence the problem of understanding a sentence is reduced to that of maximum a posteriori probability decoding ( map ) .    for the actual implementation of this idea",
    "we need to represent the meaning of a sentence as a sequence of basic units .",
    "a simple choice consists in defining a unit of meaning as a _ keyword / value _ pair @xmath7 , where @xmath8 , is a conceptual category ( i.e. a _",
    "concept _ like for instance _ origin of a flight , destination , meal _ ) and @xmath9 is the _ value _ with which @xmath10 is instantiated in the actual sentence ( e.g. _ boston , san francisco , breakfast _ ) .",
    "given a certain application domain we can define a concept dictionary @xmath11 and for each concept @xmath12 we can define a set of values @xmath13 .",
    "examples of meaning representation for phrases in the airline information domain are given in table  [ tab : mean - examples ] .",
    ".example of keyword / pair representations of simple phrases within the atis domain.[tab : mean - examples ] [ cols=\"<,<\",options=\"header \" , ]     from this analysis it results that most of the errors are due to the parts of the system that are not trained .",
    "the template generator errors reflect a lack of entries in the look - up tables .",
    "the dialog manager errors are due to the fact the the simple strategy for merging the context and the current template should be refined with more sophisticated rules .",
    "the sql translator should be an error - free module .",
    "its only function is that of translating between two different representation in a deterministic fashion .",
    "however , in this test , the sql module faced two kinds of problems .",
    "the first is that the interpretation rules used for generating the answers were not exactly the same ones used for the official test , and this accounts for roughly half of the errors .",
    "the other half of the error is due to the limited power of the template representation , and this will be discussed in section  [ sect : conclusion ] .        the conceptual model , as explained in section  [ sect : model ] ,",
    "is defined by two sets of probabilities , namely the _ concept conditional bigrams _ @xmath14 and the _ concept transition probabilities _ @xmath15 . in the first experiments",
    "these probabilities were estimated using a set of 532 sentences whose conceptual segmentation was provided by hand . the accuracy of the system in the experiments carried out using the model estimated with such a small training set , although surprisingly high  @xcite , shows a definite lack of training data .",
    "smoothing the estimated model probability provides an increase of the performance .",
    "the knowledge of the task can be introduced through a _ supervised smoothing _ of the concept conditional bigrams .",
    "the supervised smoothing is based on the observation that , given a concept , there are several words that carry the same meaning .",
    "for instance , for the concept * origin * , the words    depart(s ) leave(s ) arrive(s )    can be considered as synonyms , and can be interchanged in sentences such as :    _ the flight that depart(s ) from dallas _ + _ the flight that leave(s ) from dallas _ + _ the flight that arrive(s ) from dallas . _    a number of groups of synonyms were manually compiled for each concept .",
    "the occurrence frequencies inside a group were equally shared among the constituting words , giving the same bigram probability for synonymous words .",
    "+      if one wants to use a larger corpus than the initial handlabeled few hundred sentences and wants to avoid an intensive hand segmentation labor , one has to capitalize on all the possible information associated to the sentences in the corpus .",
    "unfortunately , when the corpus is not expressively designed for learning , like the atis corpus , the information needed may not be readily available . in the remaining of this section",
    "we analyze solutions that , although particularly devised for atis , could be generalized to other corpora and constitute a guideline for the design of new corpora .",
    "a training token consists of a sentence and its associated meaning .",
    "the meaning of sentences in the atis corpus is not available in a declarative form . instead",
    ", each sentence is associated with the _ action _ resulting from the _ interpretation _ of the meaning , namely the correct answer .",
    "one way of using this information for avoiding the handlabeling and segmentation of all the sentences in the corpus consists in creating a training loop in which the provided correct answer serves the purpose of a feedback signal . in the training loop",
    "all the available sentences are analyzed by the understanding system obtained with an initial estimate of the conceptual model parameters .",
    "the answers are then compared to the reference answers and the sentences are divided into two classes .",
    "the _ correct _ sentences , for which we assume that the conceptual segmentation obtained with the current model is correct , and the _ problem sentences_. then the segmentation of the correct sentences is used for reestimating the model parameters , and the procedure is repeated again .",
    "the procedure can be repeated until it converges to a stable number of correct answers .",
    "eventually , the remaining _ problem sentences _ are corrected by hand and included in the set of correct sentences for a final iteration of the training algorithm .",
    "this procedure proved effective for reducing the amount of handlabeling . in the experiment described in  @xcite we showed that the performance increase obtained with the described training loop , without any kind of supervision ( the remaining _ problem",
    "_ sentences were excluded from the training corpus ) is equivalent to that obtained with the supervised smoothing .",
    "this means that the training loop , although is not able to learn radically new expressions or new concepts , is able to reinforce the acquired knowledge and to _ infer _ the meaning of semantically equivalent words . in a set of 4500 sentences the training loop automatically classified almost 80% of the sentences , leaving the remaining 20% to the manual segmentation .",
    "+      in section  [ sect : model ] we based our formalization of the speech understanding problem on the assumption that there is a sequential correspondence between the representation of a sentence ( words or acoustic measurements ) and the corresponding representation of meaning .",
    "this assumption is not generally true for any translation ( semantic or not ) task .",
    "an interesting example ( reported in  @xcite ) of a task where there is no sequential correspondence between a message and its semantic representation , is that of roman numbers ( e.g. i , xxiv , xcix ) and their correspondent decimal representation ( e.g. 1 , 24 , 99 ) .",
    "fortunately , in a natural language understanding task , we may have the freedom of choosing the semantic representation , like we did in the implementation of chronus explained above .",
    "but in general , if we are dealing with a large corpus of sentences that have not been expressively designed for the purpose of learning a semantic translator , and we would like to take advantage of some kind of semantic annotation already available , we may have to face the problem of the not sequentiality of the representation .",
    "for instance , in the atis corpus , each sentences is associated with the intermediate representations used by the annotators for obtaining the reference correct answers .",
    "in fact the annotators rephrase each valid sentence in an artificial language that is a very restricted form of english .",
    "this _ pseudo - english _ rephrasing ( called _ win _ or _ wizard input _ ) constitute the input of a parser , called nlparse  @xcite , that unambiguously generates the sql query .",
    "for instance , for a sentence like :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ i d like to find the cheapest flight from washington d c to atlanta _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    "the _ win _ rephrasing is :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ list cheapest one direction flights from washington and to atlanta _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    and the corresponding associated sql statement is :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( select distinct flight.flight_id from flight where ( flight.flight_id in ( select flight_fare.flight_id from flight_fare where flight_fare.fare_id in ( select fare.fare_id from fare where fare.one_direction_cost = ( select min ( fare .",
    "one_direction_cost ) from fare where fare.fare_id in ( select flight_fare.fare_id from flight_fare where flight_fare.flight_id in ( select flight.flight_id from flight where ( flight.from_airport in ( select airport_service.airport_code from airport_service where airport_service.city_code in ( select city.city_code from city where city.city_name = washington ) ) and flight.to_airport in ( select airport_service.airport_code from airport_service where airport_service.city_code in ( select city.city_code from city where city.city_name = atlanta ) ) ) ) ) ) ) ) and ( flight.from_airport in ( select airport_service.airport_code from airport_service where airport_service.city_code in ( select city.city_code from city where city.city_name = washington ) ) and flight.to_airport in ( select airport_service.airport_code from airport_service where airport_service.city_code in ( select city.city_code from city where city.city_name = atlanta ) ) ) ) ) ; . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    both the sql query and the _ win _ sentence can be considered semantic representations of the original sentence . in fact the sql query is the final target of the understanding system and can be unequivocally obtained from the _ win _ sentence through an existing parser .",
    "obviously the sequential correspondence assumption is strongly violated for the sql representation .",
    "however a sequential correspondence can be easily found between the pseudo - english _ win _ sentence and the original message , at least for the shown examples . since all the valid sentences in the atis corpus have a _ win _ annotation , the pseudo - english language can be thought of as an alternate candidate for the meaning representation in our learning framework . using _",
    "win _ for representing the meaning may lead to two different solutions . in the first we can think of developing a system that learns how to translate natural language sentences into pseudo - english sentences and then use the existing parser for generating the sql query . in the second solution each _",
    "win _ sentence in the corpus can be translated in the corresponding conceptual representation used for chronus .",
    "this translation is unambiguous ( _ win _ is an unambiguous artificial language by definition ) .",
    "a parser can be easily designed for performing the translation or , simply use chronus itself for performing the translation .",
    "unfortunately also for the _ win _ representation , the sequential correspondence assumption is violated for a good percentage of the sentences in the corpus .",
    "a typical example is constituted by the following sentence :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ could you please give me information concerning american airlines a flight from washington d c to philadelphia the earliest one in the morning as possible _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    whose corresponding _ win _ annotation is :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ list earliest morning flights from washington and to philadelphia and american_. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the problem of reordering the words of _ win _ representation for aligning it with the original sentence is a complex problem that can not be solved optimally .",
    "suboptimal solutions with satisfactory perfomance can be developed based on effective heuristics .",
    "we will not discuss the details of how the reordering can be put into practice .",
    "rather we want to emphasize the fact that an iterative algorithm based on a model similar to that explained in section  [ sect : model ] led to almost 91% correct alignments between english sentences and corresponding _ win _ representations on a corpus of 2863 sentences . with additional refinements",
    "this technique can be used , integrated in the training loop , for automatically processing the training corpus of the conceptual model .",
    "in this paper we propose a new paradigm for language understanding based on a stochastic representation of semantic entities called concepts . an interesting way of looking at the language understanding paradigm is in term of a language translation system . the first block in fig .",
    "[ fig : transl ] translates a sentence in natural language ( _",
    "n - l _ ) into a sentence expressed in a particular semantic language ( _ s - l _ ) .",
    "the natural language characteristics are generally unknown , while the semantic language designed to cover the semantic of the application is completely known and described by a formal grammar .",
    "the second step consists in the translation of the sentence in _ s - l _ into computer language code _",
    "c - l _ for performing the requested action",
    ". this second module can be generally ( but not necessarily ) designed to cover all the possible sentences in _ s - l _ , since both _",
    "s - l _ and _ c - l _ are known .",
    "however , the boundary between the first and the second module is quite arbitrary . in  @xcite , for instance",
    ", an automatic system is designed for translating atis english sentences directly into the sql query , and in  @xcite there is an example of a system that goes from an english sentence to the requested action without any intermediate representation of the meaning .",
    "however , the closer we move the definition of _ s - l _ to _",
    "n - l _ , the more complicate becomes the design of the _ action transducer _ , reaching in the limit the complexity of a complete understanding system .",
    "conversely , when we move the definition of _",
    "s - l _ closer to _ c - l _ , we may find that learning the parameters of the _ semantic translator",
    "_ becomes quite a difficult problem when the application entails a rather complex semantics .",
    "the subject of this paper deal with the investigation of the possibility of automatizing the design of the first block ( i.e. the _ semantic translator _ ) starting from a set of examples .",
    "the semantic language chosen for the experiments reported in this paper is very simple and consists of sequences of keyword / value pairs ( or _ tokens _ ) .",
    "there is no syntactic structure in the semantic language we use .",
    "two sentences for which the difference in the semantic representation is only in the order of the tokens are considered equivalent . in this way we cover a good percentage of sentences in the domain , but still there are sentences that would require a structured semantic language .",
    "for instance the two following sentences are indistinguishable when represented by our semantic language , and obviously they have a different meaning .",
    "although the system we propose uses a very simple intermediate semantic representation , we showed that it can successfully handle most of the sentences in a database query application like the atis task . when this simple representation is used and when the problem of _ semantic translation _ is formalized as a communication problem , a map criterion can be established for decoding the _ units of meaning _ from text or speech .",
    "the resulting decoder can then be integrated with other modules for building a speech / text understanding system .",
    "an understanding system based on a learning paradigm , like the one proposed in this paper , can evolve according to different dimensions of the problem .",
    "one dimension goes with the increase in complexity of the semantic language _",
    "s - l_. rather than using a sequential representation on could think of a tree representation of the meaning .",
    "however , this poses additional problems both in the training and decoding stage , and requires the use of algorithms designed for context - free grammars , like for instance the _ inside - outside _",
    "algorithm  @xcite@xcite that have a higher complexity that those explained in this paper .",
    "another dimension of the problem goes toward a complete automatization of the system , also for those modules that , at the moment , require a manual compilation of some of the knowledge sources .",
    "one of these modules is the _ template generator_. both  @xcite and  @xcite report examples of systems where the decision about the actual values of the conceptual entities ( or an equivalent information ) is drawn on the basis of knowledge acquired automatically from the examples in the training corpus .",
    "the kind of annotation required for the training corpus is also another dimension along with the research on learning to understand language should move .",
    "a strategy for learning the understanding function of a natural language system becomes really effective and competitive to the current non - learning methods when the amount of labor required for annotating the sentences in a training corpus is comparable or inferior to the amount of work required for writing a grammar in a traditional system .",
    "this requires the development of a learning system the does not require any other information than the representation of the meaning associated to each sentence ( e.g. it does not require an initial segmentation into conceptual units , like in chronus , for bootstrapping the conceptual models ) .",
    "moreover , the representation of the meaning should be made using a _ pseudo - natural _ language , for making easier and less time consuming the work of the annotators .",
    "an example of this kind of annotation was introduced in section  [ sect : pseudoe ] with the pseudo - english _ win _ rephrasing .",
    "this suggests a possible evolution of the learning strategy for understanding systems toward a system starting with the limited amount of knowledge required for understanding a small subset of the whole language ( e.g. the _ win _ language ) .",
    "then the system can evolve to understanding larger subsets of the language using the language already acquired for rephrasing new and more complex examples .",
    "but , of course , the science of learning to understand is still in its infancy , and many more basic problems must be solved before it becomes an established solution to the design of a language interface .",
    "baker , j. , `` trainable grammars for speech recognition , '' in wolf , j. j. , klatt , d. h. , editors , _ speech communication papers presented at the 97th meeting of the acoustical society of america , _ mit , cambridge , ma , june 1979 .",
    "katz , s. m. , `` estimation of probabilities from sparse data for the language model component of a speech recognizer , '' _ ieee trans . on acoustic , speech and signal processing , _ vol .",
    "assp-35 , no .",
    "3 , march 1987 .",
    "fissore , l. , laface , p. , micca , g. , pieraccini , r. , `` lexical access to large vocabularies for speech recognition , '' _ ieee trans . on acoustics , speech and signal processing , _",
    "37 , no . 8 , august 1989 .",
    "brown , p. f , cocke , j. , della pietra , s. a. , della pietra , v. j. , jelinek , f. , lafferty , j. , mercer , r. l. , roosin , p. s. , `` a statistical approach to machine translation , '' _ computational linguistics _ ,",
    "volume 16 , number 2 , june 1990 .",
    "fissore , l. , kaltenmeier , a. , laface , p. , micca , g. , pieraccini , r. , `` the recognition algorithms , '' in _ advanced algorithms and architectures for speech understanding , _",
    "g. pirani editor , springer - verlag brussels -luxemboug , 1990 .",
    "hemphill , c. t. , godfrey , j. j. , doddington , g. r. , `` the atis spoken language systems , pilot corpus , '' _ proc . of 3rd darpa workshop on speech and natural language _",
    "102 - 108 , hidden valley ( pa ) , june 1990 .",
    "pieraccini , r. , lee , c. h. , giachin , e. , rabiner , l. r. , `` an efficient structure for continuous speech recognition , '' in _ speech recognition and understanding , recent advances , trends and applications , _ p. laface and r. de mori editors , springer - verlag berlin heidelberg , 1992 .",
    "ostendorf , m. , kannan , a. , austin , s. , kimball , o. , schwartz , r. , rohlicek , j. r. , `` integration of diverse recognition methodologies through reevaluation of n - best sentence hypotheses , '' _ proc . of 4th darpa workshop on speech and natural language _ , pacific grove , ( ca ) , february 1991 .",
    "pieraccini , r. , levin , e. , lee , c .- h . , `` stochastic representation of conceptual structure in the atis task , '' _ proc .",
    "of 4th darpa workshop on speech and natural language _ , pacific grove , ( ca ) , february 1991 .",
    "giachin , e. p , `` automatic training of stochastic finite - state language models for speech understanding '' , _ proc . of international conference on acoustics , speech and signal processing _ , icassp-92 , san francisco , ca , march 1992 .",
    "pallett , d. s. , dahlgren , n. l. , fiscus , j. g. , fisher , w. m. , garofolo , j. s. , tjaden , b. c. , `` darpa february 1992 atis benchmark test results , '' _ proc . of fifth darpa workshop on speech and natural language _ , harriman , ny , feb 1992 .",
    "pieraccini , r. , tzoukermann , e. , gorelov , z. , levin , e. , lee , c .-",
    "h , gauvain , j .-",
    "l , `` progress report on the chronus system : atis benchmark results , '' _ proc . of fifth darpa workshop on speech and natural language _ , harriman , ny , feb 1992 .",
    "pieraccini , r. , gorelov , z. , levin .",
    "e. , tzoukermann , e. , `` automatic learning in spoken language understanding , '' _ proc . of 1992 international conference on spoken language signal processing _ , icslp 92 , banff , alberta , canada , october 1992 .",
    "tzoukermann , e. , pieraccini , r. , gorelov , z. , `` natural language processing in the chronus system , '' _ proc . of 1992 international conference on spoken language signal processing _",
    ", icslp 92 , banff , alberta , canada , october 1992 .",
    "oncina , j. , garca , p. , vidal , e. , `` learning subsequential transducers for pattern recognition interpretation tasks , '' _ ieee trans . on pattern analysis and machine",
    "intelligence _ ,",
    "5 , pp . 448 - 458 , may 1993 .",
    "kuhn , r. , de mori , r. , `` learning speech semantics with keyword classification trees , '' _ proc . of ieee international conference on acoustics , speech and signal processing , _",
    "icassp-93 , minneapolis , minnesota , april 27 - 30 , 1993 ,"
  ],
  "abstract_text": [
    "<S> in this paper we propose a learning paradigm for the problem of understanding spoken language . </S>",
    "<S> the basis of the work is in a formalization of the understanding problem as a communication problem . </S>",
    "<S> this results in the definition of a stochastic model of the production of speech or text starting from the meaning of a sentence . </S>",
    "<S> the resulting understanding algorithm consists in a viterbi maximization procedure , analogous to that commonly used for recognizing speech . </S>",
    "<S> the algorithm was implemented for building a module , called _ conceptual decoder _ for the decoding of the conceptual content of sentences in an airline information domain . </S>",
    "<S> the decoding module is the basis on which a complete prototypical understanding system was implemented and whose performance are discussed in the paper . the problems , the possible solutions and the future directions of the learning approach to language understanding are also discussed in this paper </S>",
    "<S> .    0.5 cm 1.0 cm 6.25 in 8.20 in </S>"
  ]
}