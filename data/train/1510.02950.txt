{
  "article_text": [
    "in statistics , one of the main interests is to make inferences about unknown quantities by using probability measures .",
    "as all natural phenomena are contingent , the inferences about their state are uncertain inferences .",
    "a typical type of uncertain inference is to verify if a specific ( null ) hypothesis @xmath0 is consistent or inconsistent with the observed data . in the classical statistics ,",
    "@xmath1-values are often used as measures for guiding this type of uncertain inference ; the smaller is the @xmath1-value , the more inconsistent is the tested hypothesis @xmath0 with the observed data . for recent definitions of @xmath1-values",
    "see , for instance , @xcite , @xcite , @xcite and @xcite .",
    "@xcite proposed a fuzzy @xmath1-value under imprecise information about the observed quantities .",
    "@xmath2-values were firstly popularized by ronald fisher in a series of works @xcite . on the one hand , a small @xmath1-value indicates that `` either an exceptionally rare chance has occurred or the theory is not true '' @xcite . on the other hand ,",
    "a non - small @xmath1-value does not suggest acceptation of the null hypothesis , since `` there is no reason for believing that a hypothesis has been proved to be true merely because it is not contradicted by the available facts '' @xcite . in the development of a @xmath1-value",
    ", it is not mandatory to explicit all possible hypotheses . in his time , fisher computed a @xmath1-value by fixing only the null hypothesis @xmath0 to be tested by the observed facts ; the negation of @xmath0 was not defined and , therefore , it may contain much more statements than the probabilistic theory can hold .",
    "this is a very general type of uncertain inference , however , optimal procedures are difficult , if not impossible , to derive under this general scenario .",
    "@xcite showed that , under some regular conditions , there exists an optimal test in terms of error rates for testing two simple hypotheses .",
    "then , for a fixed level of significance ( probability of rejecting the null hypothesis when it is true ) , there exists a test which provides the highest probability to reject the null hypothesis when it is false .",
    "@xcite generalized the latter result to some types of composite hypotheses when the likelihood ratio is monotone .",
    "the fisherian and neyman - pearsonian approaches are competitive : the former is related with general uncertain inference and the latter is related with decision theory .",
    "a @xmath1-value is , in general , defined under a large scenario not being necessary to define an alternative hypothesis , while the neyman - pearson procedure requires an alternative hypothesis to close the universe of possible hypotheses .",
    "it is natural that some @xmath1-values defined under general scenarios present inadequate behaviors under closed universe of hypotheses  some examples of inadequate behavior of @xmath1-values are provided in @xcite and @xcite .    despite many differences of first principles , these two approaches ( discussed above ) share a common feature , namely , both metrics that regulate the @xmath1-value and the critical region strongly depend on each specific null hypothesis .",
    "that is , two different null hypotheses are not directly comparable , since each null hypothesis uses different criteria based on different metrics . more specifically , if @xmath3 and @xmath4 are two null hypotheses such that @xmath3 implies @xmath4 , then , by the logical consequence , we expect to observe more evidence against @xmath3 than @xmath4 .",
    "this logical feature does not occur for both approaches , since under each @xmath3 and @xmath4 we have different metrics @xcite .",
    "this issue is recurrently discussed in the statistical literature for advocating in favor of the bayesian inference , since the use of the posterior distribution guarantees the validity of the logical consequence over the universe of hypotheses .",
    "the limitation , however , of the bayesian procedure is that if the set of statements in the null hypothesis has smaller dimension than the set of statements in the alternative hypothesis , the best posterior probability for the null hypothesis is zero regardless the observed sample . this is a limitation , since",
    ", in such cases , the posterior distribution can not provide a positive number to represent the conflicting degree between the observed data and the claimed hypothesis ( i.e. , it was decided _ a priori _ ) .    in the statistical literature ,",
    "virtually all existent proposals to make uncertain inferences are based on probability measures .",
    "the classical approaches make uncertain inferences by considering randomness as a property only of the sample space , i.e. , no probability measures are defined over the parameter space ( in the parametric case ) .",
    "the bayesian approach makes uncertain inferences by considering that both sample and parameter spaces are subject to probabilistic uncertainties . in this paper",
    ", we adopt the classical paradigm , therefore , probability measures are defined only for the sample space , however , we show that the defined likelihood - ratio measure can play the role of a posterior measure to make uncertain inferences .",
    "this present paper revisits the likelihood - ratio measure , showing : 1 ) some of its properties not well explored in the statistical literature ; 2 ) that it satisfies the logical consequence and can be interpreted in terms of displacements from the maximum likelihood ; 3 ) that it can be used for testing very general null hypotheses ;",
    "4 ) that it is an upper bound for posterior probabilities .",
    "we discuss some of its peculiar rules and how to interpret it satisfactorily to make uncertain inferences .",
    "the likelihood ratio approach has a long history in the statistical literature .",
    "@xcite demonstrated that the test based on the likelihood ratio statistics is the most powerful one for a fixed level of significance under simple hypotheses .",
    "@xcite studied the relation between generalized likelihood ratio tests and uniformly most powerful tests .",
    "@xcite studied optimal features for some p - values based on the likelihood ratio statistics for very general null hypotheses .",
    "@xcite provided examples for confidence regions not based on the likelihood ratio statistics that produce absurd regions .",
    "@xcite discussed likelihood methods in statistics and provided also , on page 79 , a counter - example to the likelihood principle  we discuss this example in section [ criti ] .",
    "@xcite examined the likelihood ratio to quantify the weight of evidence for one hypothesis over another and provided many examples and limitations of the traditional statistical inference .",
    "@xcite investigated the probability of observing misleading evidence for the likelihood ratio approach .",
    "@xcite justified an axiomatic system of decision theory by using the likelihood ratio approach .",
    "@xcite provided a tutorial on likelihood methods for measuring statistical evidence .",
    "more recently , @xcite generalized the law of likelihood for composite hypotheses and derived several properties .",
    "these authors postulate the existence of a true probability the governs the data behavior , but this `` true '' probability can always be understood just as a shorthand to a more complex interpretation without adopting a realist perspective .",
    "@xcite built a measure of evidence based on likelihood - ratio confidence regions and compared this measure with a specific p - value approach . in the present paper , we discuss and provide some interpretations for the likelihood - ratio measure with the purpose of revitalizing and reinforcing the use of this ( new / old ) measure in the discipline of statistics .",
    "the rest of this paper is organized as follows .",
    "subsection [ notation ] presents some notations used in this paper , section [ like ] defines the likelihood - ratio measure and exposes some properties not well known in the statistical literature , subsection [ examples ] illustrates the methodology with the binomial , poisson and normal distributions , subsection [ bayes - a ] provides a comparison with the bayesian approach .",
    "relations with previous works are presented in subsection [ relation - p ] , some criticisms of the likelihood approach are addressed in subsection [ criti ] .",
    "section [ sharp - non - sharp ] discusses how to test sharp and non - sharp hypotheses with the likelihood - ratio measure , subsections [ sharp0 ] , [ sharp - non ] and [ sharp2 ] explore each scenario for two hypotheses .",
    "finally , section [ app ] presents an application to the hardy - weinberg equilibrium .      in this paper",
    "we adopt the set - measure representation , because it is simple , elegant , powerful and it avoids ambiguity .",
    "the statistical model is the triplet @xmath5 , where @xmath6 is the sample space , @xmath7 is a list of measurable subsets of @xmath8 ( a sigma - field ) and @xmath9 is a family of well - defined probability measures that possibly explain the observed data . here ,",
    "each measure in @xmath10 is dominated by a sigma - finite measure @xmath11 ( that is , @xmath12 for all @xmath10 and @xmath13 ) . the likelihood function is then formally defined to be one version of the radon - nikodym derivative @xmath14 where @xmath15 , @xmath13 , @xmath10 and @xmath16 is a set containing all versions that are equal except for a set of @xmath11-measure zero .",
    "naturally , @xmath17 must be a non - pathological version in @xmath18 , i.e. , it is assumed that @xmath19 holds .",
    "the condition ( [ cond-1 ] ) will guarantee valid many of the properties presented in this paper .",
    "if this supremum is zero for some @xmath15 , then the family @xmath9 in the statistical model was not well defined and should be replaced by an appropriated family .",
    "the majority of statistical models can be represented by the triplet @xmath5 , for instance , regression models , mixed models , structural models , multivariate models , non - parametric models and so forth .",
    "the parametric model emerges when there exists a finite dimensional space @xmath20 , with @xmath21 , such that @xmath22 . in the first part of the paper ,",
    "the vector @xmath23 is considered to be a fixed indexer of probabilities , i.e. , no prior probability over @xmath24 is specified . in the second part",
    ", the results derived in this paper are compared with the bayesian approach and , under this framework , a prior over @xmath24 is specified .",
    "some statisticians are habituated to start the modeling by defining the density functions or conditional density functions of the involved random variables .",
    "these modellings can always be rewritten in terms of the above triplet .",
    "for instance , in the former case : let @xmath25 be a random vector such that @xmath26 , where @xmath27 is a probability density function and @xmath28 .",
    "the statistical model is recovered by noting that @xmath29 is the borel @xmath30-field for @xmath8 and @xmath31 , where @xmath13 .",
    "thus , the triplet emerges @xmath5 , where @xmath32 . if @xmath33 is discrete , then @xmath34 and @xmath35 . in a more general case ,",
    "when @xmath33 is a mixture of discrete and continuous processes , the statistical model @xmath5 may be seen as an induced model by the random variable @xmath36 , where the family of probability measures @xmath37 must be dominated by a sigma - finite measure . for conditional specifications",
    ", we have , for instance , the following : let @xmath25 and @xmath38 be two continuous random vectors , defined on the same space , such that @xmath39 and @xmath40 . the variable @xmath41 is , in general , not observable .",
    "the statistical model is defined just for observable variables , therefore , in this case we must compute the marginal density of @xmath33 by integrating the joint distribution over @xmath42 , namely , @xmath43 and now we back to the former case ( the discrete case is analogous ) . in other words , we always use the marginal statistical model related with the observable random variables , because the likelihood function for the joint vectors @xmath44 depend on the non - observable random vector @xmath41 .",
    "all statistical hypotheses contain only statements about subsets of @xmath9 , i.e. , all hypotheses should be of the type : @xmath45 `` the family @xmath46 contains at least one probability measure that potentially generates the data behavior '' , where @xmath47 . a short notation to represent the same will be preferred , namely , `` @xmath48 '' . in this paper ,",
    "the universe of hypotheses restricted to the family @xmath9 is defined by @xmath49 .",
    "the two extreme cases are @xmath50 and @xmath51 , we shall see in this paper that the likelihood - ratio measure sets impossibility for the former and full possibility for the latter .",
    "moreover , we consider here that @xmath52 and @xmath53 . as for each @xmath47",
    "we have a hypothesis @xmath54 , the same measure defined over the subsets of @xmath9 can also be defined over @xmath55 .",
    "note that , if @xmath9 is uncountable , then , by using the choice axiom , it is not possible to define a probability measure over @xmath55 ( some elements are not measurable in the probabilistic sense ) , in contrast , we shall see that the likelihood - ratio measure is well defined for testing all elements of @xmath55 .",
    "why use the likelihood for measuring the consistence of a hypothesis ? first , the likelihood function is a non - negative function that relates each unobservable probability measure @xmath10 with an observable data @xmath15 .",
    "second , the larger is the value of @xmath17 , the better is the agreement between the probability @xmath2 and the observed data , see the law of likelihood discussed in @xcite . according to the measure theory ,",
    "@xmath56 is one version of the radon - nikodym derivative of @xmath2 with respect to @xmath11 at the point @xmath57 . in the discrete case , the likelihood function is @xmath58 , then @xmath59 ranks the probabilities in @xmath9 from those that make @xmath57 most probable to those that make @xmath57 less probable . in the continuous case",
    ", it can be interpreted as the instantaneous rate of change of @xmath2 at @xmath57 , then @xmath59 ranks the probabilities in @xmath9 from those with the high instantaneous rate of change at @xmath57 to those with small instantaneous rate of change at @xmath57 .",
    "the likelihood ratio statistic is defined by @xmath60 for @xmath10 and @xmath61 .",
    "the set @xmath62 is important to restrict the observed values to the cases where the likelihood ratio statistic ( [ lr ] ) is well - defined .",
    "if it is observed @xmath63 , then @xmath64 will be ill - defined and other definition should be used . in this paper , besides condition ( [ cond-1 ] ) , it is assumed also that @xmath65 throughout this paper .      for each fixed @xmath66 , let @xmath67 $ ]",
    "be a set function such that @xmath68 where @xmath69 is a non - empty set .",
    "we call @xmath70 by likelihood - ratio measure ( lr - measure ) .    by condition ( [ cond-1 ] ) ,",
    "the lr - measure @xmath70 is a well - defined function over @xmath71 .",
    "this measure @xmath70 is known in the statistical literature as the general likelihood ratio statistic and it is typically used for building hypothesis testings and confidence regions . although , it is known many ( asymptotic ) properties of @xmath72 when @xmath57 varies over @xmath8 , little is known about its properties for a fixed @xmath65 . by knowing the properties of @xmath70 , for a fixed sample @xmath57 , it is possible to derive rules to identify which probabilities in @xmath9 are more plausible to explain this observed data . the repeated sampling principle will not be considered as a criterion to specify the plausibility of the subsets of @xmath9 , since @xmath57 is fixed and observed .",
    "an axiomatic approach for decision theory based on @xmath70 was developed by @xcite considering a parametric model .",
    "it is also possible to extend their axiomatic theory to the general statistical model considered here ( not necessarily parametric ) , but it is not the main goal of the present paper .    in the following ,",
    "some properties of @xmath70 are attained straightforwardly from its definition , which explicit that @xmath70 is a non - additive measure  see @xcite , for details on non - additive measures .",
    "let @xmath73 , then    * @xmath74 and @xmath75 ; * @xmath76 ; * if @xmath77 is non - empty , then @xmath78 ; * if @xmath79 , then @xmath80 ( the entailment condition ) .",
    "the above properties @xmath81@xmath82 indicate that @xmath70 is a possibility measure over the subsets of @xmath9 ( see * ? ? ?",
    "* for details on possibility measures ) .",
    "property @xmath83 says that the lr - measure satisfies the entailment condition . by these properties , it is possible to prescribe how to infer by using the lr - measure for a fixed sample @xmath65 .",
    "first , notice that by @xmath81 and @xmath84 , @xmath85 or @xmath86 for any @xmath87 and , also , on the contrary to the probability rules , @xmath88 in words : if no evidence against @xmath77 is observed , then it does not imply that full evidence against @xmath89 is observed .",
    "this is in accordance with the coherent reasoning , since , by definition , @xmath85 means that there exists @xmath90 with ( almost ) maximum likelihood and @xmath91 means that all @xmath92 have zero likelihood .",
    "that is , @xmath70 indicates a type of consistency degrees rather than probability degrees .",
    "some statisticians might find the above properties undesirable , for one can not use all known theorems from the probability theory , moreover , the probability axioms have justifications in terms of _ desiderata _ @xcite and wages @xcite .",
    "nonetheless , these justifications are not provided only for the probability axioms , the possibility axioms also have such justifications ( see * ? ? ?",
    "* ; * ? ? ?",
    "* for instance ) .",
    "the first three evident interpretations of the lr - measure follows :    * @xmath85 occurs whenever the observed data do not bring information against @xmath77 , according to the likelihood function .",
    "that is , @xmath77 is consistent with the observed data .",
    "* @xmath93 occurs whenever the observed data do bring some information against @xmath77 , according to the likelihood function .",
    "that is , @xmath77 has some inconsistence degree with the observed data . *",
    "@xmath94 occurs whenever the observed data do bring more information against @xmath77 than against @xmath95 , according to the likelihood function .",
    "that is , @xmath77 is more inconsistence with the observed data than @xmath95 .    from @xmath81@xmath83 and ( a)(b ) , it is possible to devise more three interpretations that will be used on hypothesis testings .    1 .",
    "if @xmath96 for all @xmath10 , then all elements of @xmath9 are equally possible .",
    "this happens because all probability measures reach the maximum likelihood and , therefore , all measures are equally consistent with the observed data , given the family @xmath9 .",
    "2 .   if @xmath97 and @xmath98 for all @xmath99 , then the observed data indicate necessity of @xmath100 and impossibility , in terms of likelihoods , for all other @xmath99 .",
    "this happens because only @xmath100 reaches the maximum likelihood and all others @xmath2 have zero likelihood . in this context",
    ", @xmath100 is the only measure consistent with the observed data while all the others are totally inconsistent , given the family @xmath9 .",
    "if @xmath101 and @xmath102 ( near zero ) , then the observed data bring strong evidence against @xmath103 .",
    "this happens because only probability measures in @xmath46 reach the maximum likelihood while its complement yields very low likelihoods . here",
    ", @xmath77 is consistent with the observed data and its complement is strongly inconsistent , given the family @xmath9 .    in order to make interpretations in terms of percentages of the maximum likelihood ,",
    "let @xmath46 be a closed set and if for each fixed @xmath65 there exists at least one measure in @xmath9 that reaches the maximum likelihood , that is , @xmath104 then    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the quantity @xmath105 indicates that the highest likelihood produced by the elements of @xmath46 equals @xmath106 of the maximum likelihood .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    it is easy to verify this claim , since by condition ( [ cond - close ] ) and the closure of @xmath46 , we have @xmath107 that is , in this context , @xmath108 provides a number for the best possible choice in @xmath46 in terms of maximum likelihood proportions . in any case , the smaller is the value of @xmath108 , the farther is the set @xmath46 from the best possible choices in @xmath9 .",
    "if all elements of @xmath46 generate small likelihoods compared to the maximum likelihood , the set @xmath46 must be considered `` improvable '' or `` implausible '' in the sense that the observed data are not corroborating to any element of @xmath46 . for many regular statistical models ,",
    "the set @xmath109 contains just one element , which is known as the maximum likelihood estimative .",
    "however , in our general setting , the family @xmath9 may contain models that are not identifiable and therefore the set @xmath109 will contain more than one element . for instance , let @xmath110 and each @xmath111 is a normal probability with variance one and mean @xmath112 .",
    "the parameter vector in this example is @xmath113 and , for this case , for each @xmath15 , we have @xmath114 . notice that , any set @xmath47 such that @xmath115 will have full lr - measure ( full possibility ) for a fixed @xmath66 , that is , @xmath101 . in other words ,",
    "the lack of identifiability is not an impediment to make inferences under the lr - measure .",
    "the identifiability of parameters is required to guarantee asymptotic properties of the maximum likelihood estimators ( uniqueness , consistency , etc . ) , as we are dealing with a pure statistical model and families of probabilities rather than parameter spaces , this condition is not necessary .",
    "naturally , the identifiability can help to have more precise inference , but it is not strictly needed here .    in order to elaborate any conclusions about the amount of evidence against @xmath46 , by the relation exposed in equation ( [ not - impl ] ) , it is mandatory to compute either @xmath108 and @xmath116 and compare their values properly .",
    "as we see above , the lr - measure possesses properties that differ very much from the @xmath1-value , posterior distributions and bayes factors . however , its properties are sufficiently precise to make consistent inferences .",
    "see subsection [ examples ] for some illustrative examples , section [ bayes - a ] for a comparison with the bayesian procedure and section [ sharp - non - sharp ] for a discussion on conducting hypothesis testings .    in order to provide a geometrical interpretation of the lr - measure , lemma [ def2 ]",
    "offers an equivalent definition for @xmath70 .",
    "[ def2 ] for each @xmath10 and @xmath66 , @xmath117 : \\",
    "\\lambda_\\alpha(x ) \\cap\\{p\\ } \\neq \\varnothing\\},\\ ] ] where @xmath118    the proof is straightforward , since for each @xmath66 and @xmath10 @xmath119 : \\lambda_\\alpha(x ) \\cap \\{p\\}\\neq \\varnothing\\big\\ } \\equiv \\big\\{\\alpha \\in [ 0,1 ] : \\lambda(p , x)\\geq \\alpha\\ } \\equiv \\big[0 , \\lambda(p , x)\\big].\\ ] ] lemma [ def2 ] helps us to interpret graphically the distance between a specific probability measure @xmath2 and the set containing elements with the highest likelihood @xmath109 .",
    "assuming valid ( [ cond - close ] ) , the set @xmath120 contains all measures @xmath2 such that @xmath121 .",
    "moreover , the set @xmath109 can be seen as the center of @xmath120 in the following sense : @xmath122 for all @xmath123 $ ] .    from lemma",
    "[ def2 ] and properties @xmath81 and @xmath82 , the following general form is attained @xmath124 for any subfamily @xmath87 , where @xmath125 .",
    "it is noteworthy that equation ( [ s - value ] ) is similar to the one proposed by @xcite , see definition 2.3 of the latter paper .",
    "the main difference is that , in @xcite , @xmath126 was defined , under a parametric context , by the confidence region built on the likelihood ratio statistics .",
    "later on , @xcite and @xcite presented some discussions similar to those in @xcite .",
    "it is useful to specialize the above results to the parametric model @xmath127 , where @xmath128 . in this context",
    ", all quantities can be written in terms of the parametric subspaces @xmath129 in practice , it is possible to represent graphically the relation with @xmath46 and @xmath109 by the set @xmath130 , where @xmath131 .",
    "the set @xmath130 highlights the distance between @xmath46 and @xmath109 , i.e. , the more distant is the border of @xmath132 from its center , the more implausible is @xmath46 for the given observed data @xmath57 , see section [ app ] for an application .    to sum up ,",
    "this section presented and discussed some important properties @xmath81@xmath83 of the lr - measure and their interpretative implications ( a)(f ) that were not well - explored in the statistical literature . by using these properties ,",
    "it is possible to create a ranking of all subsets of @xmath9 ( or subsets of @xmath24 , in the parametric context ) describing the degree of adequacy according to their respective likelihood values .      in order to illustrate the simplicity of the methodology",
    ", we present three simple examples from binomial , poisson and normal distributions in figures [ bin - fig ] , [ pois - fig ] and [ norm - fig ] , respectively .",
    "as we shall see , this methodology can be easily applied by any undergraduate student .",
    "the genuine likelihood functions are employed for each example . in the normal case , we have two parameters , namely , the location @xmath11 and scale @xmath133 , but here we will be interested in verifying the plausibility of @xmath134 . in this context",
    ", @xmath11 can be considered as a nuisance parameter , as we shall see it is not necessary to resort to integrated or profiled likelihood functions .",
    "* binomial example : * let @xmath33 be a binomial random variable , i.e. , @xmath135 , @xmath136 for @xmath15 and @xmath137 .",
    "figure [ bin - fig ] shows the values of likelihood - ratio measure for all observable values from a binomial random variable with @xmath138 , the full horizontal segment represents the set @xmath139 $ ] . here",
    ", the likelihood - ratio measure is @xmath140 observe that , for either @xmath141 and @xmath142 , figures [ bin - fig](a ) and ( i ) show that @xmath143 and @xmath144 . that is , when @xmath141 ( or @xmath142 ) , on the one hand , @xmath145 contains the probability that generates the highest likelihood and , on the other hand , the likelihoods produced by the elements of @xmath146 reach at most 2% of the maximum likelihood . for @xmath147",
    ", we have @xmath148 and @xmath149 , that is , @xmath46 contains the probability that generates the highest likelihood and the likelihoods produced by the elements of @xmath103 equal at most 85% of the maximum likelihood .",
    "* poisson example : * let @xmath33 be a poisson random variable , i.e. , @xmath150 , @xmath151 for @xmath15 and @xmath152 .",
    "figure [ pois - fig ] depicts the values of the likelihood - ratio measure for the first eight observable values from a poisson random variable , the full horizontal segment represents the set @xmath153 $ ] . here , the likelihood measure is @xmath154 when @xmath141 , figure [ pois - fig](a ) shows that @xmath155 and @xmath156 .",
    "that is , when @xmath141 , on the one hand , @xmath146 contains the probability that generates maximum likelihood and , on the other hand , the likelihoods produced by the elements of @xmath145 equals at most 5% of the maximum likelihood .",
    "when @xmath142 , figure [ pois - fig](i ) shows that @xmath157 and @xmath158    * normal example : * let @xmath33 be a normal sample , i.e. , @xmath159 , @xmath160 , where @xmath161 is the sample mean and @xmath162 is the sample variance ( the denominator is @xmath163 ) and @xmath164",
    ". in this case , we have two parameters and a simple graphical visualization is through the set @xmath126 .",
    "figure [ norm - fig ] presents the smallest contour for which @xmath126 has at least one element in common with @xmath165 ( the full line ) for some observable sample mean @xmath161 and variance @xmath162 from a normal sample of size @xmath166 , the dashed area represents the set @xmath167 . here",
    ", the likelihood measure is @xmath168    observe that , the set @xmath167 represents our interest in @xmath133 .",
    "the distance between the maximum likelihood estimative and the border of @xmath167 does not depend on @xmath11 .",
    "when the sample variance is 1 , figures [ norm - fig](a)(c ) show that @xmath155 and @xmath169 .",
    "when the sample variance is 2 , figures [ norm - fig](d)(f ) show that @xmath170 and @xmath158 .",
    "finally , when the sample variance is 3 , figures [ norm - fig](g)(i ) show that @xmath171 and @xmath158 . in the normal case ,",
    "all of these lr - measures do not depend on the sample mean value .",
    "$ ] for all observable values from a binomial random variable with @xmath138 .",
    "the horizontal full segment represents the set @xmath167 .",
    "the full dot represents the value of @xmath172 in the normalized likelihood . ]",
    "$ ] for the eight first observable values from a poisson random variable .",
    "the horizontal full segment represents the set @xmath167 .",
    "the full dot represents the value of @xmath172 in the normalized likelihood .",
    "]     for some observable values of the sample mean and variance from a random sample of a normal distribution with @xmath166 .",
    "the cross mark is the maximum likelihood estimate .",
    "the set @xmath167 is represented by the dashed area .",
    "the full line is the smallest contour for which @xmath126 has at least one element in common with @xmath167 . ]      in the bayesian inference , all inferences are based on the posterior probability defined over the parameter space . in this paper , it was studied an inference procedure based on a possibility measure over the same parameter space rather than a probability one .",
    "this section provides a comparison of these two strictly different approaches under parametric models .",
    "as these two procedures use different rules , they must have different interpretation .    in the bayesian framework , a prior probability @xmath173 ( dominated by a sigma - finite measure @xmath174 )",
    "is defined over the parameter space @xmath24 and a posterior is attained through @xmath175 where @xmath176 this posterior distribution is a well - defined measure of support over the measurable subsets of @xmath24 , i.e. , the posterior probability of @xmath167 given the observed data @xmath57 is defined by @xmath177 where the integral is the lebesgue integral . if @xmath178 is very small , then the set @xmath167 must be regarded as improbable . the value @xmath179 is completely determined by knowing @xmath178 , since @xmath180 .",
    "then , @xmath181 this feature does not hold for the lr - measure @xmath70 , e.g. , for the same observed sample @xmath57 we may have @xmath182 and @xmath183 ( these implications are valid by properties @xmath81 and @xmath84 ) , that is , @xmath184 in words , although there is an increasing in the @xmath70-values from @xmath167 to @xmath185 , the @xmath70-values of @xmath186 and @xmath187 are the very same . secondly , as the sum rule governs the posterior probability measure , the probability of an uncountable set can not be recovered from the probabilities of each of its elements .",
    "it does not occur with @xmath188 , since , by definition , the @xmath70-value of an uncountable set is obtained from the @xmath70-value of each of its constituents through the supremum function .",
    "this feature poses the lr - measure @xmath70 in advantage when it comes to testing sharp hypothesis of the type : `` the probability @xmath189 potentially generates the observed data '' , since whenever @xmath24 is uncountable , the posterior probability will attach probability zero to the above quoted event even when @xmath189 fits adequately the observed data .",
    "the lr - measure can be viewed as a classical counterpart of the posterior distribution , nevertheless , as it has seen above , the rules that govern both measures are quite different and hence the interpretations must differ .",
    "the following result explicits a relation between @xmath70 and any posterior probability .",
    "[ dominate ] let @xmath5 be a statistical model where @xmath190 is a parametric probability family ( dominated by a sigma - finite measure ) and @xmath191 .",
    "also , let @xmath192 be a prior probability ( dominated by a sigma - finite measure ) defined over a measurable list of subsets of @xmath24 .",
    "assume valid condition ( [ cond-1 ] ) , then , for any @xmath192-measurable @xmath167 such that @xmath193 , @xmath194 for any @xmath65 , where @xmath195 .",
    "as @xmath66 and @xmath196 , the posterior probability can be written as @xmath197 therefore @xmath198    it is noteworthy that @xmath70 is defined over the power set of @xmath24 , while the posterior distribution is defined on the measurable subsets ( in the lebesgue sense ) of @xmath24 .",
    "thus , there exist subsets of @xmath24 that are not measurable for @xmath199 but are computable for @xmath70 .",
    "notice that , from equation ( [ zero ] ) of lemma [ dominate ] , @xmath200 but the converse is not true , for there exist prior probabilities that induce probability zero for @xmath167 even when @xmath201 .",
    "this shows that the @xmath70-value behavior is in agreement with the expected reasoning between possibility and probability :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ `` a high degree of possibility does not imply a high degree of probability , nor does a low degree of probability imply a low degree of possibility .",
    "however , if an event is impossible , it is bound to be improbable . ''",
    "@xcite _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    moreover , lemma [ dominate ] provides an upper bound for the posterior probability of @xmath167 .    [ consistency ]",
    "assume valid the lemma [ dominate ] s assumptions .",
    "then , for each @xmath192-measurable @xmath167 such that @xmath202 , @xmath203    notice that the extra condition of the corollary [ consistency ] is not vacuous , since @xmath204 by the following @xmath205 corollary [ consistency ] is valid for subsets of @xmath24 with low prior probabilities relative to @xmath206 .",
    "@xcite argued that a consistency principle between probability and possibility can be mathematically stated as @xmath207 for all measurable @xmath208 ( in a probability sense ) .",
    "the possibility of an event is interpreted by @xcite as `` the lack of surprise when it occurs '' .",
    "based on this interpretation , @xcite claim : `` an event that often occurs is not very surprising and then it seems very possible that it happens ; on the other hand , events which are not very possible do not often occur and are surprising .",
    "then by an inductive reasoning , we are conducted to suppose that if an event seldom occurs , it must be less possible than events which often occur . ''",
    "corollary [ consistency ] establishes when this consistency principle occurs for posterior probabilities and the lr - measure .",
    "it is worth saying that only optimization procedures are required in the computation of @xmath172 , no integrations are required .",
    "computing a posterior probability can be a harsh task in some high dimensional problems , therefore , an upper bound of the posterior probability can be attained by lemma [ dominate ] and corollary [ consistency ] in terms of @xmath70 .",
    "that is , if the @xmath70-value is small for an event , then the correlative posterior probability must be even smaller ( under the specified conditions ) .",
    "unfortunately , in the statistical literature there are few works addressing the likelihood approach in the context of the present paper .",
    "the law of likelihood to compare two hypotheses was studied by @xcite , @xcite and @xcite , this law of likelihood can be represented by using our notation as follows @xmath209 provided that , @xmath210 . in our paper",
    "the likelihood - ratio measure is relative to the maximum likelihood , that is , all possibly computed likelihoods for the family @xmath9 are compared with the highest likelihood .",
    "some features of @xmath211 can be derived by using the properties @xmath81@xmath83 and ( a)(f ) , but this is not the focus of the present paper .    in a paper published by the journal of the royal statistical society , @xcite proposed two methods based on likelihoods for statistical models with a finite parametric space @xmath212 .",
    "the methods are 1 ) the upper and lower probabilities defined , respectively , by @xmath213 and 2 ) the bayesian posterior probability derived from a uniform prior distribution @xmath214 the authors defined types of likelihood measures that satisfy some properties of a probability measure .",
    "some works in the fuzzy literature use measures based on likelihoods , but none of them address the point treated in this paper .",
    "for instance , @xcite studied the semantics for possibility theory based on likelihoods .",
    "their work considers a different type of likelihood measure , which in a sense is related with the lr - measure .",
    "the main interest in their paper lies in subsets of the observable set @xmath8 .",
    "they defined for @xmath215 @xmath216 see the bottom the page 363 of their paper .",
    "this measure is defined over the subsets of @xmath8 , while @xmath70 is defined over the subsets of @xmath9 .",
    "that is , @xmath217 $ ] , while @xmath67 $ ] , their domains are different .    in the artificial intelligence journal ,",
    "@xcite proposed an axiomatic decision theory based on @xmath70 under parametric models . therefore , justifications in terms of lost functions are also available for the likelihood - ratio measure .      in this paper",
    ", we consider only the information provided by the ` observed ' likelihood and external information sources are not used ( so far , it was not necessary to resort on the repeating sampling principle ) . despite that , in this paper we are not embracing the likelihood principle as the only principle to make good inferences .",
    "there are some examples , based on anomalous likelihood functions , illustrating that information beyond the likelihood function is necessary for proper statistical inference ( * ? ? ?",
    "* ; * ? ? ?",
    "* example 3.5 ) . in this section ,",
    "we discuss the first anomalous ( flat ) likelihood function presented in @xcite and the example 3.5 presented in @xcite .",
    "* fraser , monete and ng s example : * let @xmath5 such that @xmath218 , @xmath34 and @xmath219 , where @xmath220 is defined as follows @xmath221 where @xmath222 denotes the greatest integer smaller or equal to the argument . for a given @xmath57 ,",
    "the likelihood function is @xmath223 and the likelihood - ratio measure is @xmath224    that is , in this example , for a given @xmath57 , the lr - measure indicates possibility one for @xmath225 and impossibility for any other values .",
    "that is all the information we can extract from the likelihood - ratio measure .",
    "however , `` the smallest of the three possible @xmath23 values provides a confidence procedure with 2/3 confidence '' @xcite , i.e. , @xmath226    it means that there is an external information that is not regarded in the likelihood - ratio measure and can help to discriminate which values are more probable than others .",
    "however , the procedure ( [ ic - fraser ] ) uses the `` repeated sampling principle '' , that is , if the experiment is repeated , the quantity @xmath227 will be equal to @xmath23 , in average and under the law @xmath220 , 2/3 of times .",
    "notice that it does not mean at all that the statement `` @xmath228 '' is more plausible than the others , namely , `` @xmath229 '' and `` @xmath230 '' , for a fixed observation @xmath57 .",
    "for a fixed value @xmath57 , all statements `` @xmath228 '' , `` @xmath229 '' and `` @xmath230 '' are equally plausible with respect to the likelihood - ratio measure .",
    "since the underlying principles are different , the two interpretations must be different , therefore one should not be used as a counter - argument for the other .",
    "* severini s example : * let @xmath5 such that @xmath218 , @xmath34 and @xmath219 , where @xmath220 is defined as follows : if @xmath231 or @xmath23 is even , then @xmath232 where @xmath233 denotes the smallest integer greater or equal to the argument .",
    "if @xmath23 is an odd number greater than one , then @xmath234 for a given @xmath57 , the likelihood function is @xmath235 and the likelihood - ratio measure is given by @xmath236    clearly , the likelihood - ratio measure indicates that `` @xmath237 '' produces the highest likelihood , the other possible values ( with positive lr - measure ) attain at least 70% of the maximum likelihood . nonetheless , note that this point with the highest likelihood has probability @xmath238 define the statistic @xmath239 @xcite , on page 80 , shows that @xmath240 which proofs that `` the point with smaller likelihood is more likely to be equal to @xmath23 [ than the point with the highest likelihood ] '' @xcite . for this latter conclusion to be valid ,",
    "the repeated sampling principle must be evoked , because the word _",
    "likely _ is restricted to ensembles of the sample space .    in these two examples and in many others ,",
    "the repeated sampling principle is embraced only rhetorically and , in general , it is not effectively executed in the majority of actual problems .",
    "that is , one sample is observed and a conclusion should be drawn from this single observed sample .",
    "as this principle is not universally accepted , i strongly believe that these examples do not produce a valid contra - argument against the likelihood - ratio measure .",
    "personally , i did not reject the repeated sampling principle , but i strongly believe that it ( or any other principle ) should not be imposed to drive * all * types of uncertain inferences , mainly inasmuch as there are some examples where methods with good long run properties are inadmissible and incoherent in a specific sense .",
    "besides being applied as a support measure over the subsets of @xmath9 , the lr - measure @xmath70 may also be employed for testing a null hypothesis @xmath241 . here , two types of hypothesis testings can be conducted , one based on fisherian philosophy and another based on the neyman - pearson philosophy .",
    "the fisherian philosophy considers that the family @xmath9 can not exhaustively list all mechanisms that possibly generate the observed sample , therefore , the alternative hypothesis is always ill - defined and it is only reasonable to reject the null hypothesis .",
    "the neyman - pearson philosophy considers that the family may list exhaustively all possible mechanisms that generate the observed data and , given this family , the alternative hypothesis is well - defined and it is reasonable to accept or to reject the null hypothesis .",
    "the hypothesis @xmath242 is sharp when @xmath243 and it is non - sharp when @xmath244 , where @xmath245 is the lebesgue dimension . on the one hand , in a general setting , it is non - trivial to compute @xmath1-values for non - sharp hypotheses , since , depending on the geometry of @xmath46 , the limiting distribution of the usual likelihood ratio statistics may be other than the chi - square distribution ( see * ? ? ?",
    "* for specific details ) .",
    "as the wald and score statistics are connected with the likelihood ratio statistic , the same issue is expected to occur with these statistics . a study on optimal @xmath1-values under special cases of sharp and non - sharp null hypotheses",
    "is provided in @xcite . on the other hand , under sharp null hypotheses ,",
    "the posterior probability can not provide a positive measure and the alternative bayes factor is not a consistent measure ( see * ? ? ? * for details ) .",
    "in contrast , we shall see in this section that the lr - measure @xmath70 can consistently test sharp or non - sharp hypotheses .",
    "condition ( [ cond-1 ] ) is considered valid throughout this section .",
    "if the practitioner follows the fisherian philosophy , then the decision of rejection is taken if the lr - measure @xmath108 is small .",
    "if the practitioner adopts the neyman - pearson philosophy , then the acceptation / rejection of @xmath242 varies according to three different situations :    1 .",
    "@xmath242 and @xmath246 are both non - sharp hypotheses ( see section [ sharp0 ] ) , 2 .",
    "@xmath242 is sharp and @xmath246 is non - sharp ( see section [ sharp - non ] ) , 3 .",
    "@xmath242 is non - sharp and @xmath246 is sharp ( see section [ sharp2 ] ) .    for each of these situations",
    ", we have different types of decisions .",
    "it is very important to treat each case particularly , since for each case we have different degrees of restrictiveness . in the following ,",
    "we define conditions that indicate a rejection or acceptation of @xmath242 .",
    "[ rejection ] there are indications to reject @xmath242 ( or accept @xmath246 ) , given the family @xmath9 , when    1 .",
    "the observed data bring ( strong ) evidence against @xmath242 , i.e. , @xmath247 ( small enough ) ; 2 .",
    "the observed data bring no evidence against @xmath246 , i.e. , @xmath248 .",
    "when the observed data do not provide evidence against @xmath242 , i.e. , @xmath101 , by the properties of @xmath70 , it does not necessarily imply that the same data provide strong evidence against the alternative @xmath246 .",
    "if this occurs , we have indications to accept @xmath242 .",
    "then , we define conditions for accepting @xmath242 .",
    "[ acceptation ] there are indications to accept @xmath242 ( or reject @xmath246 ) , given the family @xmath9 , when    1 .",
    "the observed data bring no evidence against @xmath242 , i.e. , @xmath249 ; 2 .",
    "the observed data bring strong evidence against @xmath246 , i.e. , @xmath250 ( small enough ) .",
    "that is , it is not sufficient to observe `` no evidence '' against @xmath242 to accept @xmath242 , also it is necessary to observe ( strong ) evidence against @xmath246 .",
    "if @xmath251 is not small enough , then there are no indications to either reject or accept the null hypothesis . in this latter case",
    ", we should maintain both hypotheses and collect more data or more information to make further conclusions .",
    "it must be clear that we can only accept @xmath242 restricted to the options in @xmath9 , it is not an unconditional decision , it is a decision given the family of possible choices @xmath9 .",
    "furthermore , it is not conditional in the probabilistic sense , it is conditional in the possibilistic sense , for there is no probability measure over @xmath9",
    ".    it should be noticed that if the null hypothesis is @xmath252 , where @xmath109 is defined in ( [ cond - close ] ) , then , by definitions [ acceptation ] and [ rejection ] , we should only accept this hypothesis if @xmath253 ( small enough ) .",
    "for instance ,    * binomial example : * let @xmath254 , @xmath255 and @xmath256 , assume that @xmath257 and the observed data is @xmath258 .",
    "then , the lr - measure is @xmath259 and @xmath260 . if the null hypothesis is @xmath252 , we have @xmath261 and @xmath262 , therefore , given this family @xmath9 , we observe evidence to accept @xmath242 , since the set @xmath263 is almost impossible .",
    "define @xmath264\\times [ 0,1]$ ] such that @xmath265 for each @xmath47 .",
    "this function will be used for testing @xmath242 against @xmath246 .",
    "two extreme decisions follow : @xmath266 is the maximal value for @xmath242 , therefore @xmath267 should be readily accepted , for the possibility of @xmath103 is zero ; @xmath268 is the minimal value for @xmath242 , therefore @xmath267 should be readily rejected , the possibility of @xmath46 is zero .",
    "the above prescriptions are just representing the properties of @xmath70 for any subset @xmath47 . in practice",
    ", it is observed something between the maximal and minimal values and the types of decisions depend on the restrictiveness of the involved hypotheses .      in this section ,",
    "@xmath242 and @xmath246 are both non - sharp hypotheses , that is , @xmath269 .",
    "two arrangements are possible , namely    * @xmath270 , with @xmath271 $ ] , if @xmath272 . in this first case ,",
    "if @xmath273 is sufficiently small , @xmath242 should be accepted , given the family @xmath9 .",
    "* @xmath274 , with @xmath275 $ ] , if @xmath276 . in this second case ,",
    "if @xmath277 is sufficiently small , @xmath242 should be rejected , given the family @xmath9 .",
    "observe that , @xmath278 whenever @xmath279 , where @xmath280 is the closure of @xmath46 . based on these two arrangements ,",
    "it is allowed three types of decisions , namely : ( 1 ) acceptation of @xmath242 , given the family @xmath9 .",
    "that is , the observed sample @xmath57 does not bring evidence against @xmath46 , but it brings strong evidence against @xmath103 ( if @xmath281 ) ; ( 2 ) rejection of @xmath242 , given the family @xmath9 .",
    "that is , the observed sample @xmath57 brings strong evidence against @xmath46 ( if @xmath282 ) , but it does not bring evidence against @xmath103 ; and ( 3 ) without evidence to neither accept nor reject @xmath242 , given the family @xmath9 .",
    "that is , the observed sample @xmath57 does not bring evidence against either @xmath46 and @xmath103 ( if @xmath283 ) .      in this section , @xmath242 is a sharp hypothesis and @xmath246 is a non - sharp hypothesis .",
    "assume the following condition : for each proper non - empty subset @xmath284 , @xmath285 condition ( [ cond-2 ] ) is saying that there is no `` gap '' between @xmath46 and @xmath103 as in the binomial example presented in section [ sharp - non - sharp ] .",
    "as @xmath286 , the maximum likelihood set @xmath109 will have a non - empty intersection with the closure of @xmath103 , for this reason @xmath287 . in this case",
    ", the observed data will never produce evidence against @xmath246 , therefore , by definitions [ acceptation ] and [ rejection ] , we can only find evidence to reject @xmath242 . here , it is allowed only two types of decisions , namely : ( 2 ) rejection of @xmath242 , that is , the observed sample @xmath57 brings strong evidence against @xmath46 ( if @xmath282 ) ; and ( 3 ) without evidence to either accept or reject @xmath242 , that is , the observed sample @xmath57 does not bring evidence against @xmath46 ( if @xmath288 ) .      in this section , @xmath242 is a non - sharp hypothesis and @xmath246 is a sharp hypothesis .",
    "a similar analysis as was done in section [ sharp - non ] follows .",
    "assume also valid condition ( [ cond-2 ] ) , then as @xmath289 , the maximum likelihood set @xmath109 will always have a non - empty intersection with the closure of @xmath46 , this implies @xmath290 . in this case",
    ", the observed data will never produce evidence against @xmath242 , therefore , by definitions [ acceptation ] and [ rejection ] , we can only find evidence to accept @xmath242 . here , it is allowed only the following two types of decisions , namely :",
    "( 1 ) acceptation of @xmath242 , that is , the observed sample @xmath57 brings strong evidence against @xmath103 ( if @xmath281 ) ; and ( 3 ) without evidence to neither accept nor reject @xmath242 , that is , the observed sample @xmath57 does not bring evidence against @xmath103 ( if @xmath291 ) .",
    "if @xmath277 ( or @xmath273 ) is not sufficiently small , we can not reject ( accept ) @xmath242 . in this case",
    ", we maintain @xmath242 as a hypothesis to be verified by using further data . in practice",
    ", we can define a small threshold for @xmath277 and @xmath273 in terms of the maximum likelihood value .",
    "for instance , consider the case @xmath274 ( respectively , @xmath270 ) , if we set the threshold @xmath292 ( or @xmath293 ) , then we will reject ( or accept ) the null hypothesis whenever the highest likelihood produced by the elements in @xmath46 ( or in @xmath103 ) is lesser than @xmath294 of the maximum likelihood value .",
    "these thresholds values @xmath295 and @xmath296 can be derived from loss functions , error probabilities or any other procedure . moreover",
    ", these thresholds values may take into account the sample size , for the curvature of the likelihood function is affected by it .",
    "some authors @xcite advise computing the probability of misleading evidence for @xmath211 , given in equation ( [ ratio ] ) .",
    "the justification is that `` observations can truly constitute strong evidence supporting one distribution when the other is true '' @xcite .",
    "this perspective explicitly assumes a true measure that governs the data behavior . in this paper , we did not assume , in any moment , the existence of a true measure , here we are just comparing all likelihoods relative to the maximum likelihood for an observed sample . in this paper",
    ", we endorse a perspective based on the likelihood function and we do not apply a `` long - run of trials '' perspective in order to avoid the same controversies of the @xmath1-values .",
    "in this section we apply the above results to analyze genotype frequencies in a population .",
    "when the genotype frequencies of a given population remain constant from generation to generation , it is said that the population is under the hardy - weinberg equilibrium . in this section ,",
    "we investigate three situations , namely : 1 ) the population is under the hardy weinberg equilibrium ; 2 ) the population is undergoing a regular system of ` inbreeding ' ( when relatives produce offspring ) ; and 3 ) the population is undergoing a regular system of ` outbreeding ' ( when very genetically different individuals produce offspring ) .",
    "these situations will be formalized mathematically in the sequel .",
    "let @xmath297 , @xmath298 and @xmath299 be the possible genotypes and @xmath300 , @xmath301 and @xmath302 their respective population frequencies , where the parameter vector is @xmath303 with @xmath304 .",
    "let @xmath5 be a parametric statistical model , where @xmath305 with @xmath306 a fixed value , @xmath34 and each @xmath111 is defined by @xmath307 where @xmath13 is a measurable set .",
    "the parameter space is @xmath308 ^ 3 : \\ \\theta_1 + \\theta_2 + \\theta_3 = 1\\}.\\ ] ] for the observed sample @xmath309 , the likelihood function and the likelihood ratio statistics are , respectively , given by @xmath310 where @xmath311 .",
    "the population is under the hardy - weinberg equilibrium when @xmath312 , for this situation we define @xmath313 the population is under inbreeding pressure when @xmath314 , for this case we define @xmath315 finally , the population is under outbreeding pressure when @xmath316 , for this last case we define @xmath317 for more details and discussion on this topic the reader is referred to @xcite .",
    "the lr - measure is @xmath318 for @xmath319 .",
    "notice that @xmath320 where @xmath321 and @xmath322 , that is , @xmath323 restricted to @xmath185 depends only on @xmath300 , that is , @xmath324 } f(\\theta_1),\\ ] ] where @xmath325 . as @xmath326 is continuous , @xmath327)$ ]",
    "is closed and it has a maximum , i.e. , @xmath328 ) = \\max f([0,1])$ ] .",
    "it is possible to show that the maximum value of @xmath326 is attained at @xmath329    therefore , the @xmath70-value for @xmath185 is @xmath330 where @xmath331 , @xmath332 , @xmath333 , and @xmath334 .",
    "notice that , @xmath335 also note that for @xmath336 , @xmath337 is concave .",
    "therefore , @xmath338 and we have three situations    1 .   if @xmath339 , then @xmath340 and @xmath341 .",
    "2 .   if @xmath342 , then @xmath343 and @xmath344 .",
    "3 .   if @xmath345 , then @xmath346 , for @xmath319    where @xmath347 is the closure of set @xmath208 .",
    "figure [ fig:2 ] presents in each figure the three sets @xmath185 , @xmath348 and @xmath349 .",
    "the simplex formed by points ( 0,0 ) , ( 0,1 ) and ( 1,0 ) represents the parameter space @xmath24 .",
    "the dashed curve illustrates the hardy - weinberg equilibrium .",
    "the crosshatched area ( below the dashed curve ) stands for the inbreeding restriction and the white area ( above the dashed curve ) stands for the outbreeding restriction .",
    "each plot in figure [ fig:2 ] refers to a specific observe sample , for instance plot ( a1 ) refers to @xmath350 and @xmath351 , plot ( a2 ) refers to @xmath350 and @xmath352 and so forth . in each plot",
    ", the cross mark indicates the maximum likelihood estimate for @xmath353 and the full lines surrounding the ml estimates are the smallest contours for which @xmath126 has at least one element in common with @xmath185 .    on the one hand , in the plots ( a1)(a6 ) , ( b1)(b4 ) ,",
    "( c6 ) , ( d1)(d4 ) , ( e5)(e6 ) and ( f1 ) the maximum likelihood lies in @xmath348 , that is , it is favoring the inbreeding restriction .",
    "notice that only for some cases this favoring seems to be relevant ( e.g. , @xmath70-values less than @xmath354 ) :    * ( a1 ) : @xmath350 , @xmath355 , * ( a2 ) : @xmath350 , @xmath356 , * ( a3 ) : @xmath350 , @xmath357 , * ( c6 ) : @xmath358 , @xmath359 .",
    "on the other hand , in the plots ( b6 ) , ( c1)(c5 ) , ( d6 ) , ( e1)(e4 ) and ( f2)(f6 ) the maximum likelihood lies in @xmath349 , that is , is favoring the outbreeding restriction .",
    "notice that only for some cases this favoring seems to be relevant ( @xmath70-values less than @xmath354 ) :    * ( f5 ) : @xmath360 , @xmath361 , * ( f6 ) : @xmath360 , @xmath362 .",
    "it is also noteworthy that in two cases the maximum likelihood is in @xmath363 , namely : ( b5 ) and ( d5 ) .",
    "this paper discussed theoretical properties of the likelihood - ratio measure that go beyond the probabilistic framework .",
    "it was shown that the likelihood ratio approach can be employed by testing sharp ( the dimension of the null parameter space is smaller than the original parameter space ) and non - sharp hypotheses .",
    "three types of decision are possible : accept , reject or maintain a specific null hypothesis ( it depends on the type of the hypothesis and the adopted philosophy ) .",
    "moreover , it was established that the likelihood - ratio measure can be used as upper bounds for posterior probabilities for sets with relative small prior probabilities , this property is in agreement with the consistency principle of the possibility theory .",
    "these results can revitalize the potentiality and stimulate the use of the likelihood ratio approach in the statistical community .",
    "the author gratefully acknowledges grant from fapesp  brazil ( 2014/25595 - 0 ) ."
  ],
  "abstract_text": [
    "<S> the present paper considers an evidence measure built under the likelihood ratio approach . </S>",
    "<S> the resulting likelihood - ratio measure can be used for testing general hypotheses in a simple manner . </S>",
    "<S> moreover , it satisfies the entailment condition ( the logical consequence ) , which is required to maintain a special type of coherence over the space of hypotheses . in this paper </S>",
    "<S> , we study some important non - probabilistic properties of the likelihood - ratio measure for a given observed sample . </S>",
    "<S> its applicability in testing sharp and non - sharp statistical null hypotheses is discussed . some counter - examples to the likelihood principle are analyzed and a comparison with the bayesian approach is also established . </S>",
    "<S> it is presented an application to test if the genotype frequencies of a given population are under the hardy - weinberg equilibrium , under inbreeding restrictions or under outbreeding restrictions . </S>",
    "<S> + * key - words * : classical statistics ; evidence measure ; hypothesis testing ; likelihood ratio statistics ; possibility theory ; </S>"
  ]
}