{
  "article_text": [
    "a fundamental observation of shannon s channel coding theorem is that using a randomly generated codebook ( i.i.d .",
    "generated according to some @xmath0 ) at a rate below capacity will lead to a distribution pattern of the output sequences , by which , a decoding scheme with arbitrarily low probability of error can be devised .    in this paper , we are interested in the case when the rate is above capacity .",
    "we will show that such a pattern that can be used for decoding will disappear when there are too many input sequences , i.e. , when the rate is above capacity . instead",
    ", in this case , the output will have an asymptotic equipartition property on the set of typical output sequences ( typical with respect to @xmath1 ) .",
    "interestingly , this set is independent of the specific codebook used , as long as the codebook is typical according to the random codebook generation .",
    "the reason for this equipartition is that the input sequences are too dense , so that different input sequences can contribute to the same output sequence and get mixed up .",
    "investigating the optimal compress - and - forward relay scheme has motivated this study of output distribution when rate is above capacity .",
    "the optimality of the compress - and - forward schemes is arguably one of the most critical problems in the development of network information theory , where ambiguity always arises when decoding can not be done correctly . in the classical approach of @xcite , the compression scheme at the relay",
    "was only based on the distribution used for generating the codebook at the source , instead of the specific codebook generated .",
    "while many different codebooks can be generated according to the same distribution , can the knowledge of the specific codebook be helpful ?",
    "there have been some discussions on this issue ( e.g. , @xcite ) . here , in this paper , we show that the observations at the relay are somehow independent of the specific codebook used at the source , and only depend on the distribution by which the codebook is generated .    to further explore the optimality of the compress - and - forward schemes , we compare the rates needed to losslessly",
    "compress the relay s observation in two different scenarios : i ) the relay uses the knowledge of the source s codebook to do the compression ; ii ) the relay simply ignores this knowledge .",
    "it is shown that the minimum required rates in both scenarios are the same when the rate of the source s codebook is above the capacity of the source - to - relay link .",
    "the remainder of the paper is organized as the following . in section [ s :",
    "pre ] , we first introduce some standard definitions of strongly typical sequences , and then give a definition of typical codebooks . then , we summarize our main results in section [ s : results ] , followed by the proof of these results in section [ s : aep ] , [ s : whp ] and [ s : proofofrate ] . finally , as an application of the results ,",
    "the optimality of the compress - and - forward schemes is discussed in section [ s : relay ] .",
    "consider a discrete memoryless channel @xmath2 with capacity @xmath3 . under the random coding framework , a random codebook @xmath4 with respect to @xmath0 with rate @xmath5 and block length @xmath6",
    "is defined as @xmath7 where each codeword in @xmath4 is an i.i.d .",
    "random sequence generated according to a fixed input distribution @xmath0 .",
    "it is well known that information can be transmitted with arbitrarily small probability of error for sufficiently large @xmath6 if @xmath8 . in this paper , however , we are interested in the case where the rate is above capacity .",
    "we begin with some standard definitions on strong typicality [ 3 , ch.13 ] .",
    "the @xmath9-strongly typical set with respect to @xmath0 , denoted by @xmath10 , is the set of sequences @xmath11 satisfying :    \\1 . for all @xmath12 with @xmath13 , @xmath14    \\2 .",
    "for all @xmath12 with @xmath15 , @xmath16 .",
    "@xmath17 is the number of occurrences of @xmath18 in @xmath19 .",
    "similarly , we can define the @xmath9-strongly typical set with respect to @xmath20 and denote it by @xmath21 .",
    "the @xmath9-strongly typical set with respect to @xmath22 , denoted by @xmath23 , is the set of sequences @xmath24 satisfying :    \\1 . for all @xmath25 with @xmath26 , @xmath27    \\2 . for all @xmath25 with @xmath28 ,",
    "@xmath29    @xmath30 is the number of occurrences of the pair @xmath31 in the pair of sequences @xmath32 .",
    "the @xmath9-strongly conditionally typical set with the sequence @xmath19 with respect to the conditional distribution @xmath33 , denoted by @xmath34 , is the set of sequences @xmath35 satisfying :    \\1 . for all @xmath25 with @xmath36 , @xmath37    \\2 . for all @xmath25 with @xmath38 , @xmath39      for the discrete memoryless channel @xmath2",
    ", the channel noise is said to be @xmath9-typical if for any given input @xmath19 , the output @xmath40 is @xmath9-strongly conditionally typical with @xmath19 with respect to the channel transition function @xmath33 , i.e. , @xmath41 .    due to the law of large numbers , the channel noise is `` typical '' with high probability .",
    "index the sequences in @xmath21 as @xmath42 , where @xmath43 .",
    "consider the set @xmath44 , where each sequence in @xmath45 is strongly typical and can reach @xmath46 over a channel with typical noise , i.e. , @xmath47    the following notation is useful for defining the typical codebooks .",
    "@xmath48 where @xmath49 is drawn i.i.d .",
    "according to @xmath0 and @xmath50 is the indicator function : @xmath51    [ d : tcb ] a codebook @xmath52 is said to be @xmath9-typical with respect to @xmath0 if +    1 .",
    "@xmath53 , + 2 .   @xmath54 .",
    "the main results of this paper are summarized by the following three theorems .",
    "their proofs are presented in sections [ s : aep ] , [ s : whp ] and [ s : proofofrate ] respectively .",
    "the application of these results to the relay channel will be discussed in section [ s : relay ] .",
    "[ t : odmcu ] given that an @xmath9-typical codebook @xmath55 is used and the channel noise is also @xmath9-typical , then , if @xmath56 .",
    "`` @xmath57 '' and `` @xmath58 '' have similar interpretations . ]",
    "@xmath59 when @xmath60 , where both @xmath61 and @xmath62 are calculated according to @xmath63 .    throughout this paper ,",
    "we generate the codebook @xmath4 at random according to @xmath0 and reserve only the @xmath9-strongly typical codewords",
    ". then we have theorem [ t : dmcwhp ] and [ t : rate ] .",
    "[ t : dmcwhp ] for any @xmath64 , @xmath65    [ t : rate ] consider the conditional entropy of the channel output given the source s codebook information , namely @xmath66 .",
    "we have @xmath67 where @xmath61 , @xmath62 and @xmath68 are all calculated according to @xmath63 .",
    "in contrast , without the codebook information , we have @xmath69",
    "essentially , theorem [ t : odmcu ] states that there exists an asymptotic equipartition property of the typical output sequences , irrespective of the specific codebook used , as long as the codebook is a typical codebook . to prove this theorem , we first introduce two lemmas .    [",
    "l : transprob ] let @xmath70 denote the event that the output @xmath71 for any given input @xmath19 . for any @xmath72 , @xmath73 where @xmath68 is calculated",
    "according to @xmath63 and @xmath74 goes to 0 as @xmath75 and @xmath76 .    by the definition of @xmath77",
    ", we have for any @xmath19 in @xmath77 , @xmath78 and @xmath79 .",
    "then , it follows from the definition of strong typicality that @xmath80 , where @xmath81 as @xmath75 .",
    "since strong typicality implies weak typicality , for any @xmath19 in @xmath45 , we have @xmath82 where @xmath83 as @xmath75 .",
    "thus , @xmath84 and @xmath85    therefore , for any @xmath72 , we have @xmath86 where @xmath87 and @xmath88 as @xmath75 and @xmath76 .",
    "similarly , for any @xmath72 , we have @xmath89 which finishes the proof of lemma [ l : transprob ] .",
    "[ l : nint ] if @xmath55 is a typical codebook , then for any @xmath90 , @xmath91 where @xmath62 is calculated according to @xmath92 and @xmath93 goes to 0 as @xmath75 and @xmath76 .    to prove lemma [ l : nint ] , we need the following standard result on strong typicality ( see lemma 13.6.2 in @xcite ) :    let @xmath49 be drawn i.i.d . according to @xmath94 . for @xmath95 , @xmath96 where @xmath62 is calculated",
    "according to @xmath22 and @xmath97 goes to 0 as @xmath75 and @xmath76 .    according to the definition of @xmath98 , @xmath99 where @xmath49 is drawn i.i.d . according to @xmath0 .    since @xmath100 and @xmath101 imply that @xmath102 , where @xmath103 goes to 0 as @xmath75 , we have @xmath104 where @xmath105 and @xmath106 as @xmath75 and @xmath76 .",
    "furthermore , by the standard definitions of strong typicality , it follows that @xmath107 implies @xmath78 .",
    "now , we show @xmath107 also implies @xmath79 .",
    "suppose @xmath107 .",
    "then , we have    1 .   for all @xmath108 with @xmath38 , @xmath28 and @xmath109 .",
    "2 .   for all @xmath108 with @xmath36 and @xmath15 , @xmath28 and @xmath109 , as well as @xmath16 .",
    "3 .   for all @xmath108 with @xmath36 and @xmath13 , @xmath26 and @xmath14 @xmath110",
    "thus , @xmath111    therefore , @xmath107 implies that @xmath79 , as well as @xmath78 .",
    "then , we have @xmath112 where @xmath113 and @xmath114 as @xmath75 and @xmath76 .",
    "let @xmath115 . combining ( [ e : new1 ] ) and",
    "( [ e : new2 ] ) , we have @xmath116    therefore , if @xmath55 is a typical codebook , by the definition of the typical codebooks and ( [ e : combinebound ] ) , for any @xmath90 , @xmath91 where @xmath62 is calculated according to @xmath92 and @xmath93 goes to 0 as @xmath75 and @xmath76 .",
    "let @xmath70 denote the event @xmath71 for any given input @xmath19 .",
    "consider @xmath117 for any @xmath118 .",
    "we lower bound this probability as follows : @xmath119.\\end{aligned}\\ ] ]    ( [ ( a ) ] ) follows from the law of total probability and accumulates the contributions from all the codewords in the codebook to the probability for @xmath46 to be channel output .",
    "( [ ( b ) ] ) follows from the uniform distribution of message index @xmath120 .",
    "( [ e : ctn ] ) follows from the the condition @xmath70 and the fact that @xmath55 contains only strongly typical codewords .",
    "( [ ( d ) ] ) follows from lemma [ l : transprob ] .",
    "( [ ( e ) ] ) follows from lemma [ l : nint ] .",
    "let @xmath75 as @xmath76 .",
    "then for any @xmath90 , @xmath121 when @xmath60 .    similarly , following ( [ e : ctn ] ) , by lemmas [ l : transprob ] and [ l : nint ]",
    ", we have @xmath122.\\end{aligned}\\ ] ] therefore , for any @xmath90 , @xmath123 when @xmath60 . combining ( [ e : lower ] ) and ( [ e : upper ] ) , we establish theorem [ t : odmcu ] .",
    "in this section , we will show that with high probability , a typical codebook will be generated by the random codebook generation .",
    "we begin with some relevant definitions and the vapnik - chervonenkis theorem @xcite , @xcite :    a range space is a pair @xmath124 , where @xmath125 is a set and @xmath126 is a family of subsets of @xmath125 . for any @xmath127 , we define @xmath128 , the projection of @xmath126 on @xmath129 , as @xmath130 .",
    "we say that @xmath129 is _ shattered _ by @xmath126 if @xmath131 , i.e. , if the projection of @xmath126 on @xmath129 includes all possible subsets of @xmath129 .",
    "the vc - dimension of @xmath126 , denoted by vc - d(@xmath126 ) is the cardinality of the largest set @xmath129 that @xmath126 shatters .",
    "if arbitrarily large finite sets are shattered , the vc dimension of @xmath126 is infinite .    _ the vapnik - chervonenkis theorem : _",
    "if @xmath126 is a set of finite vc - dimension and @xmath132 is a sequence of @xmath6 i.i.d . random variables with common probability distribution @xmath133 , then for every @xmath9 , @xmath134 @xmath135 whenever @xmath136    let @xmath137 . to show theorem [ t : dmcwhp ] , a finite vc dimension of @xmath138 is desired in order to employ the vapnik - chervonenkis theorem . for this reason ,",
    "we introduce lemma [ l : dmcvcdimension ] .",
    "[ l : dmcvcdimension ] for a fixed block length @xmath6 , vc - d@xmath139 , where @xmath140 as @xmath75 .",
    "[ p : vcdimension ] by the asymptotic equipartition property , @xmath141 , where @xmath81 as @xmath75 .",
    "thus , for any @xmath142 , @xmath143 and hence vc - d@xmath139 .",
    "[ p : dmcwhp ] since we reserve only the @xmath9-strongly typical codewords when generating the codebook , for any random codebook , the first condition in definition [ d : tcb ] is obviously satisfied .",
    "below , we focus on showing that a random codebook satisfies the second condition in definition [ d : tcb ] with high probability .    for the given @xmath0 , consider all the codewords in a random codebook , @xmath144 , @xmath145 .",
    "they are generated with the common distribution @xmath146 , where @xmath49 is drawn i.i.d . according to @xmath0 . since vc - d@xmath147 is finite for a fixed @xmath6",
    ", we employ the vapnik - chervonenkis theorem under the range space @xmath148 . to satisfy ( [ e : vctheorem2 ] ) , let both @xmath9 and @xmath149 in ( [ e : vctheorem1 ] ) be @xmath150 , where",
    "@xmath151 then the vapnik - chervonenkis theorem states that @xmath152 where @xmath153 .",
    "since @xmath154 for sufficiently large @xmath6 , ( [ e : o11 ] ) concludes the proof of theorem [ t : dmcwhp ] .",
    "before proceeding to the proof of theorem [ t : rate ] , we first introduce lemma [ l : jaep ] , which will facilitate the later discussions . the proof of lemma [ l : jaep ]",
    "is given in appendix [ a : a ] .",
    "[ l : jaep ] for the channel @xmath2 , generate the codebook at random according to @xmath0 and reserve only the @xmath9-strongly typical codewords .",
    "the channel input and output @xmath155 and @xmath40 satisfy that    1 .",
    "@xmath156 , for any @xmath64 ; 2 .",
    "@xmath157 , @xmath158 , and @xmath159 .",
    "since we reserve only the @xmath9-typical codewords when generating the codebook , generally , the channel input @xmath155 is no longer an i.i.d . random process .",
    "however , lemma [ l : jaep ] essentially states that the random process @xmath160 still satisfies the joint asymptotic equipartition property and furthermore , the entropy rates of the random processes @xmath155 , @xmath40 and @xmath160 can still be simply expressed in the single letter form respectively .",
    "this observation will facilitate our later discussions .",
    "we prove theorem [ t : rate ] by characterizing @xmath161 in two different cases : when @xmath60 and when @xmath162 , respectively .",
    "define an indicator random variable @xmath163 as @xmath164 where @xmath70 denotes the event @xmath71 for any given input @xmath19 .",
    "when @xmath165 , we have @xmath166}\\right ) \\label{(h ) }   \\\\ \\nonumber = & n[h_0(y)-\\epsilon^*]\\cdot(1-o(1 ) ) \\cdot \\sum_{\\mathcal{c}\\text { is typical } } p(\\mathcal{c } ) \\cdot \\left(\\sum_{y^n \\in a_{\\epsilon,0}^{(n)}(y)}p(y^n|e_{\\epsilon},\\mathcal{c } )   \\right )    \\\\ \\nonumber = & n[h_0(y)-\\epsilon^*]\\cdot(1-o(1 ) ) \\cdot \\sum_{\\mathcal{c}\\text { is typical } } p(\\mathcal{c } ) \\cdot \\mbox{pr}(y^n\\in a_{\\epsilon,0}^{(n)}(y)| e_{\\epsilon},\\mathcal{c } ) \\\\ \\nonumber = & n[h_0(y)-\\epsilon^*]\\cdot(1-o(1 ) ) \\cdot \\sum_{\\mathcal{c}\\text { is typical } } p(\\mathcal{c}|e_{\\epsilon } ) \\cdot \\mbox{pr}(y^n\\in a_{\\epsilon,0}^{(n)}(y)| e_{\\epsilon},\\mathcal{c } ) \\\\",
    "\\nonumber \\stackrel { } { = } & n[h_0(y)-\\epsilon^*]\\cdot(1-o(1 ) ) \\cdot \\mbox{pr}(y^n\\in a_{\\epsilon,0}^{(n)}(y),\\mathbf{c}\\text { is typical}| e_{\\epsilon } ) \\\\ \\stackrel { } { = } & n[h_0(y)-\\epsilon^*]\\cdot(1-o(1 ) ) \\cdot   ( 1-o(1))\\label{(i ) }   \\\\ \\nonumber= & n[h_0(y)-\\epsilon^*]\\cdot(1-o(1))\\end{aligned}\\ ] ]    ( [ ( f ) ] ) follows from the fact that conditioning reduces entropy .",
    "( [ ( g ) ] ) follows from the fact that @xmath167 as @xmath76 , for any @xmath168 .",
    "( [ ( h ) ] ) follows from theorem [ t : odmcu ] , which upper bounds @xmath169 by @xmath170}$ ] for any @xmath171 and typical @xmath55 , where @xmath172 as @xmath76 .",
    "( [ ( i ) ] ) follows from the fact that @xmath173 this can be seen from the following .",
    "@xmath174 since @xmath175 , @xmath176 and @xmath177 all go to 1 , obviously both the numerator and denominator of ( [ l : ndgoto1 ] ) go to 1 as @xmath76 .",
    "thus , @xmath173    therefore , when @xmath60 , @xmath178\\cdot(1-o(1))\\right)\\\\ \\nonumber = & \\liminf _ { n \\to \\infty } [ h_0(y)-\\epsilon^*]\\cdot(1-o(1))\\\\ = & h_0(y).\\label{e : sandwich 1}\\end{aligned}\\ ] ]    furthermore , @xmath179 where the last equality follows from lemma [ l : jaep ] .    combining ( [ e : sandwich 1 ] ) and",
    "( [ e : sandwich 2 ] ) , we have that when @xmath60 , @xmath180      to find @xmath161 when @xmath162 , we first introduce two lemmas . the proofs of these two lemmas are given at the end of this section .",
    "[ l : rlessc1 ] when @xmath162 , @xmath181    [ l : rlessc2 ] @xmath182    now , expanding @xmath183 in two different ways , we have @xmath184 and thus @xmath185 therefore , when @xmath162 , @xmath186\\\\ = & r+h_0(x , y)-h_0(x)\\label{(l)}\\\\ \\nonumber = & r+h_0(y|x),\\end{aligned}\\ ] ] where ( [ ( j ) ] ) follows from lemma [ l : rlessc1 ] and [ l : rlessc2 ] , ( [ ( k ) ] ) follows from the fact that @xmath187 forms a markov chain , and ( [ ( l ) ] ) follows from lemma [ l : jaep ] .",
    "this completes the proof of theorem [ t : rate ] .",
    "to prove lemma [ l : rlessc1 ] , we begin with fano s inequality ( see theorem 2.11.1 in @xcite ) :    let @xmath188 , where @xmath189 is any function of @xmath190 .",
    "then @xmath191    for the channel @xmath2 with a codebook @xmath55 , we estimate the message index @xmath120 from @xmath40 .",
    "let the estimate be @xmath192 and @xmath193 .",
    "then , applying fano s inequality , we have @xmath194    since given @xmath55 , @xmath155 is a function of @xmath120 , say @xmath195 , we have @xmath196 then , @xmath197    recall the channel coding theorem , which states that if we randomly generate the codebook according to @xmath0 , then when @xmath162 , @xmath198    therefore , when @xmath162 , @xmath199\\\\ = & \\limsup_{n\\to \\infty}\\frac{1}{n } [ 1 + nr\\sum_{\\mathcal{c}}p(\\mathcal{c})p_e^{(n)}(\\mathcal{c } )      ]",
    "\\\\ = & \\limsup_{n\\to \\infty}\\frac{1}{n}+\\limsup_{n\\to \\infty}r\\sum_{\\mathcal{c}}p(\\mathcal{c})p_e^{(n)}(\\mathcal{c } ) \\\\ = & 0.\\end{aligned}\\ ] ] furthermore , it is obvious that @xmath200 and hence @xmath201 when @xmath162 .    given any @xmath55 , @xmath155 is a function of @xmath120 .",
    "thus , @xmath202 and @xmath203    therefore , to show lemma [ l : rlessc2 ] , it suffices to show that @xmath204 . for this purpose",
    ", we first define a class of codebooks as regular codebooks and focus on characterizing @xmath205 for a regular codebook @xmath55 .",
    "then , we show that a regular codebook appears with high probability when we randomly generate the codebook , and conclude that @xmath204 .",
    "we say a codebook @xmath55 is regular if @xmath206 where @xmath207 is the number of occurrences of @xmath19 in @xmath55 , defined by @xmath208 and @xmath146 where @xmath49 is drawn i.i.d . according to @xmath0 .",
    "given a regular @xmath55 , for any @xmath209 , we have @xmath210 where the @xmath103 in ( [ epsilon ] ) goes to 0 as @xmath75 and ( [ wlog ] ) follows from the general assumption that @xmath211 .",
    "note that the message index @xmath120 is uniformly distributed , we have for a given @xmath55 and any @xmath209 , @xmath212 where @xmath213 goes to 0 as @xmath76 .",
    "therefore , @xmath214\\sum_{x^n",
    "\\in a_{\\epsilon,0}^{(n)}(x ) } p(x^n|\\mathcal{c})\\\\ = & [ n(r-\\epsilon'')].\\end{aligned}\\ ] ]    below , we use the vapnik - chervonenkis theorem to show that a regular codebook appears with high probability .",
    "let @xmath215 .",
    "since @xmath216 , for any @xmath142 , @xmath217 and hence vc - d@xmath218 .",
    "since vc - d@xmath219 is finite for a fixed @xmath6 , we employ the vapnik - chervonenkis theorem under the range space @xmath220 . to satisfy ( [ e : vctheorem2 ] ) , let both @xmath9 and @xmath149 in ( [ e : vctheorem1 ] ) be @xmath150 , where",
    "@xmath221 then the vapnik - chervonenkis theorem states that @xmath222 since @xmath154 for sufficiently large @xmath6 , ( [ e : o1 ] ) concludes that @xmath223 as @xmath76 .",
    "therefore , @xmath224\\sum_{\\mathcal{c } \\text{~is regular } } p(\\mathcal{c})\\\\ = & [ n(r-\\epsilon'')](1-o(1)),\\end{aligned}\\ ] ] and @xmath225(1-o(1))\\\\ \\nonumber = & \\lim_{n\\to \\infty } ( r-\\epsilon'')(1-o(1))\\\\ = & r.\\label{e : cbound2}\\end{aligned}\\ ] ] combining ( [ e : cbound1 ] ) and ( [ e : cbound2 ] ) , we finish the proof of lemma [ l : rlessc2 ] .",
    "to study the optimality of the compress - and - forward strategy , in this section , we investigate the rate needed for the relay to losslessly compress its observation . in the classical approach of @xcite , the compression scheme at the relay",
    "was only based on the distribution used for generating the codebook at the source , without being specific on the codebook generated . however , since both the relay and destination have the knowledge of the exact codebook used at the source , it is natural to ask whether it is beneficial for the relay to compress its observation based on this codebook information .",
    "this question motivates us to compare the rates needed to compress the relay s observation in two different scenarios : when the relay uses the knowledge of the source s codebook and when the relay simply ignores this knowledge .    specifically , we consider the two compression problems shown in figure [ f : compression ] , where @xmath40 is generated from @xmath155 through the channel @xmath2 , and @xmath226 in ( b ) is the source s codebook information available to both the encoder and decoder .",
    "interestingly , we will show that to perfectly recover @xmath40 , the minimum required rates in both scenarios are the same when the rate @xmath5 associated with @xmath226 is greater than the channel capacity .",
    "formally , we have the following theorem :    [ t : compression ] for the discrete memoryless channel @xmath2 , generate the codebook at random according to @xmath0 and reserve only the @xmath9-strongly typical codewords .",
    "let @xmath226 be the source s codebook with rate @xmath5 , and @xmath155 and @xmath40 be the input and output of the channel respectively .",
    "when @xmath165 , to compress the channel output @xmath40 , we have    \\1 ) @xmath40 can be encoded at rate @xmath227 and recovered with arbitrarily low probability of error if @xmath228 .",
    "\\2 ) given that the source s codebook information @xmath226 is available to both the encoder and decoder and @xmath40 is encoded at rate @xmath229 , the decoding probability of error will be bounded away from zero if @xmath230 , which implies that we can not compress the channel output better even if the source s codebook information is employed .    to show theorem [ t : compression ] , we need the following lemma .",
    "[ l : converse ] for the compression problem in figure [ f : compression]-(b ) , we can encode @xmath40 at rate @xmath229 and recover it with the probability of error @xmath231 only if @xmath232    the source code for figure [ f : compression]-(b ) consists of an encoder mapping @xmath233 and a decoder mapping @xmath234 .",
    "let @xmath235 , then @xmath236 . by fano s inequality , for any source code with @xmath231",
    ", we have @xmath237 where @xmath238 as @xmath76 .    therefore ,",
    "for any source code with rate @xmath229 and @xmath231 , we have the following chain of inequalities @xmath239 where ( [ m ] ) follows from the fact that @xmath240 , ( [ o ] ) follows from the fact that @xmath241 is a function of @xmath40 and @xmath226 , and ( [ p ] ) follows from ( [ e : fano ] ) . dividing the inequality @xmath242 by @xmath6 and taking the limit as @xmath76",
    ", we establish lemma [ l : converse ] .",
    "proof of part 1 ) : to show part 1 ) , we only need to show that the sequence @xmath40 satisfies the asymptotic equipartition property , i.e. , @xmath243 , as @xmath76 . then , following the classical approach to show the source coding theorem , we can conclude that the rate @xmath244 is achievable . by lemma [ l : jaep ] , @xmath245 thus , the sequence @xmath40 satisfies the asymptotic equipartition property and the rate @xmath244 is achievable .",
    "proof of part 2 ) : by lemma [ l : converse ] , given that the codebook information @xmath226 is available to both the encoder and decoder and @xmath40 is encoded at rate @xmath229 , @xmath231 only if @xmath246 . by theorem [ t : rate ] ,",
    "@xmath247 when @xmath60 .",
    "therefore , when @xmath60 , @xmath231 only if @xmath248 , which establishes part 2 ) .",
    "proof of part 1 ) : let @xmath249 be drawn i.i.d . according to @xmath0 and @xmath250",
    "be generated from @xmath249 through the channel @xmath2 .",
    "then , we have @xmath251    proof of part 2 ) : denote the @xmath9-weakly typical sets with respect to @xmath0 , @xmath20 and @xmath22 by @xmath252 , @xmath253 and @xmath254 respectively .",
    "along the same line as in the proof of part 1 ) , we can prove that @xmath255 as @xmath76 , and hence @xmath256 and @xmath257 both go to 1 as @xmath76 .",
    "( [ e : logsum ] ) follows from the the log sum inequality ( see theorem 2.7.1 in @xcite ) , which states that for non - negative numbers , @xmath266 and @xmath267 , @xmath268 with equality if and only if @xmath269 are equal for all @xmath270 .                    v. n. vapnik and a. chervonenkis , `` on the uniform convergence of relative frequencies of events to their probabilities , '' _ theory of probability and its applications _ , vol .",
    "16 , no .  2 , pp .",
    "264280 , jan ."
  ],
  "abstract_text": [
    "<S> the output distribution , when rate is above capacity , is investigated . </S>",
    "<S> it is shown that there is an asymptotic equipartition property ( aep ) of the typical output sequences , independently of the specific codebook used , as long as the codebook is typical according to the standard random codebook generation . </S>",
    "<S> this equipartition of the typical output sequences is caused by the mixup of input sequences when there are too many of them , namely , when the rate is above capacity . </S>",
    "<S> this discovery sheds some light on the optimal design of the compress - and - forward relay schemes . </S>"
  ]
}