{
  "article_text": [
    "in a non - distributed context , solving a problem is believed to be , sometimes , much harder than verifying it ( e.g. , for np - hard problems ) . given a graph @xmath11 and",
    "a subgraph @xmath12 of @xmath11 , a task introduced by tarjan @xcite is to check whether @xmath12 is a minimum spanning tree ( mst ) of @xmath11 .",
    "this non - distributed verification seems to be just slightly easier than the non - distributed computation of an mst . in the distributed context",
    ", the given subgraph @xmath12 is assumed to be represented distributively , such that each node stores pointers to ( some of ) its incident edges in @xmath12 .",
    "the verification task consists of checking whether the collection of pointed edges indeed forms an mst , and if not , then it is required that at least one node _ raises an alarm_. it was shown recently that such an mst verification task requires the same amount of time as the mst computation  @xcite . on the other hand , assuming that each node can store some information , i.e. , _ a label _ , that can be used for the verification , the time complexity of an mst verification can be as small as 1 , when using labels of size @xmath13 bits per node @xcite , where @xmath14 denotes the number of nodes . to make such a proof labeling scheme a useful algorithmic tool , one needs to present a _ marker _",
    "algorithm for computing those labels .",
    "one of the contributions of the current paper is a time and memory efficient marker algorithm .    every decidable graph property ( not just an mst )",
    "can be verified in a short time given large enough labels  @xcite .",
    "a second contribution of this paper is a generalization of such schemes to allow a reduction in the memory requirements , by trading off the locality ( or the time ) . in the context of mst ,",
    "yet another ( third ) contribution is a reduced space proof labeling scheme for mst .",
    "it uses just @xmath0 bits of memory per node ( asymptotically the same as the amount of bits needed for merely representing distributively the mst ) .",
    "this is below the lower bound of @xmath15 of @xcite .",
    "the reason this is possible is that the verification time is increased to @xmath16 in synchronous networks and to @xmath17 in asynchronous ones , where @xmath3 is the maximum degree of nodes .",
    "another important property of the new scheme is that any fault is detected rather close to the node where it occurred .",
    "interestingly , it turns out that a logarithmic time penalty for verification is unavoidable .",
    "that is , we show that @xmath4 time for an mst verification scheme is necessary if the memory size is restricted to @xmath0 bits , even in synchronous networks .",
    "( this , by the way , means that a verification with @xmath0 bits , can not be silent , in the sense of @xcite ; this is why they could not be of the kind introduced in @xcite ) .    given a long enough time , one can verify @xmath18 by recomputing the mst .",
    "an open problem posed by awerbuch and varghese @xcite is to find a synchronous mst verification algorithm whose time complexity is smaller than the mst computation time , yet with a small memory .",
    "this problem was introduced in @xcite in the context of self - stabilization , where the verification algorithm is combined with a non - stabilizing _ construction _ protocol to produce a stabilizing protocol .",
    "essentially , for such purposes , the verification algorithm repeatedly checks the output of the non - stabilizing construction protocol , and runs the construction algorithm again if a fault at some node is detected .",
    "hence , the construction algorithm and the corresponding verification algorithm are assumed to be designed together .",
    "this , in turn , may significantly simplify the checking process , since the construction algorithm may produce output variables ( labels ) on which the verification algorithm can later rely . in this context",
    ", the above mentioned third contribution solves this open problem by showing an @xmath19 time penalty ( in synchronous networks ) when using optimal @xmath0 memory size for the mst verification algorithm .",
    "in contrast , if we study mst _ construction _ instead of mst verification , time lower bounds which are polynomial in @xmath14 for mst construction follow from @xcite ( even for constant diameter graphs ) .",
    "one known application of some methods of distributed verification is for general transformers that transform non - self - stabilizing algorithms to self - stabilizing ones .",
    "the fourth contribution of this paper is an adaptation of the transformer of @xcite such that it can transform algorithms in our context .",
    "that is , while the transformer of @xcite requires that the size of the network and its diameter are known , the adapted one allows networks of unknown size and diameter .",
    "also , here , the verification method is a proof labeling scheme whose verifier part is self - stabilizing .",
    "based on the strength of the original transformer of @xcite ( and that of the companion paper @xcite it uses ) , our adaptation yields a result that is rather useful even without plugging in the new verification scheme .",
    "this is demonstrated by plugging in the proof labeling schemes of @xcite , yielding an algorithm which already improves the time of previous @xmath19 memory self - stabilizing mst construction algorithm @xcite , and also detects faults using 1 time and at distance at most @xmath5 from each fault ( if @xmath5 faults occurred ) .",
    "finally , we obtain an optimal @xmath0 memory size , @xmath7 time asynchronous self - stabilizing mst construction algorithm .",
    "the state of the art time bound for such optimal memory algorithms was @xmath20 @xcite .",
    "in fact , our time bound improves significantly even the best time bound for algorithms using polylogarithmic memory , which was @xmath9 @xcite .",
    "moreover , our self - stabilizing mst algorithm inherits two important properties from our verification scheme , which are : ( 1 ) the time it takes to detect faults is small : @xmath19 time in a synchronous network , or @xmath17 in an asynchronous one ; and ( 2 ) if some @xmath5 faults occur , then each fault is detected within its @xmath6 neighbourhood .",
    "intuitively , a short detection distance and a small detection time may be helpful for the design of local correction , for fault confinement , and for fault containment algorithms @xcite .",
    "those notions were introduced to combat the phenomena of faults `` spreading '' and `` contaminating '' non - faulty nodes .",
    "for example , the infamous crash of the arpanet ( the predecessor of the internet ) was caused by a fault in a single node .",
    "this caused old updates to be adopted by other nodes , who then generated wrong updates affecting others @xcite .",
    "this is an example of those non - faulty nodes being contaminated .",
    "the requirement of _ containment _ @xcite is that such a contamination does not occur , or , at least , that it is contained in a small radius around the faults .",
    "the requirement of _ confinement _ @xcite allows the contamination of a state of a node , as long as this contamination is not reflected in the output ( or the externally visible actions ) of the non - faulty nodes . intuitively , if the detection distance is short , non - faulty nodes can detect the faults and avoid being contaminated .",
    "the distributed construction of an mst has yielded techniques and insights that were used in the study of many other problems of distributed network protocols .",
    "it has also become a standard to check a new paradigm in distributed algorithms theory .",
    "the first distributed algorithm was proposed by @xcite , its complexity was not analyzed .",
    "the seminal paper of gallager , humblet , and spira presented a message optimal algorithm that used @xmath21 time , improved by awerbuch to @xmath7 time @xcite , and later improved in @xcite to @xmath22 , where @xmath23 is the diameter of the network .",
    "this was coupled with an almost matching lower bound of @xmath24 @xcite .",
    "proof labeling schemes were introduced in @xcite .",
    "the model described therein assumes that the verification is restricted to 1 unit of time .",
    "in particular , a 1 time mst verification scheme was described there using @xmath19 bits per node .",
    "this was shown to be optimal in @xcite . in @xcite ,",
    "gs and suomela extend the notion of proof labeling schemes by allowing constant time verification , and exhibit some efficient proof labeling schemes for recognizing several natural graph families .",
    "in all these schemes , the criterion to decide failure of a proof ( that is , the detection of a fault ) is the case that at least one node does not manage to verify ( that is , detects a fault ) .",
    "the global state passes a proof successfully if all the nodes verify successfully .",
    "this criterion for detection ( or for a failure to prove ) was suggested by @xcite in the contexts of self stabilization , and used in self stabilization ( e.g. @xcite ) as well as in other other contexts @xcite .",
    "self - stabilization @xcite deals with algorithms that must cope with faults that are rather severe , though of a type that does occur in reality @xcite .",
    "the faults may cause the states of different nodes to be inconsistent with each other .",
    "for example , the collection of marked edges may not be an mst .",
    "table [ tab : alg - compare ] summarizes the known complexity results for self stabilizing mst construction algorithms .",
    "the first several entrees show the results of using ( to generate an mst algorithm automatically ) the known transformer of katz and perry @xcite , that extends automatically non self stabilizing algorithms to become self stabilizing .",
    "the transformer of katz and perry @xcite assumes a leader whose memory must hold a snapshot of the whole network .",
    "the time of the resulting self - stabilizing mst algorithm is @xmath7 and the memory size is @xmath25 .",
    "we have attributed a higher time to @xcite in the table , since we wanted to remove its assumption of a known leader , to make a fair comparison to the later papers who do not rely on this assumption .    to remove the assumption , in the first entry we assumed the usage of the only leader election known at the time of @xcite .",
    "that is , in @xcite , the first self - stabilizing leader election algorithm was proposed in order to remove the assumptions of  @xcite that a leader and a spanning tree are given .",
    "the combination of @xcite and @xcite implied a self - stabilizing mst in @xmath9 time .",
    "( independently , a leader election algorithm was also presented by @xcite ; however , we can not use it here since it needed an extra assumption that a bound on @xmath14 was known ; also , its higher time complexity would have driven the complexity of the transformed mst algorithm higher than the @xmath9 stated above . )    using unbounded space , the time of self - stabilizing leader election was later improved even to @xmath26 ( the actual diameter ) @xcite .",
    "the bounded memory algorithms of @xcite or @xcite , together with @xcite and @xcite , yield a self - stabilizing mst algorithm using @xmath27 bits per node and time @xmath28 or @xmath7 .    [",
    "tab : alg - compare ]    .`comparing self - stabilizing mst construction algorithms ` [ cols=\"<,^,^,^,<\",options=\"header \" , ]     antonoiu and srimani @xcite presented a self stabilizing algorithm whose complexities were not analyzed . as mentioned by @xcite , the model in that paper can be transformed to the models of the other papers surveyed here , at a high translation costs .",
    "hence , the complexities of the algorithm of @xcite may grow even further when stated in these models . gupta and srimani @xcite presented an @xmath29 bits algorithm .",
    "higham and liang @xcite improved the core memory requirement to @xmath0 , however , the time complexity went up again to @xmath30 .",
    "an algorithm with a similar time complexity and a similar memory per node was also presented by blin , potop - butucaru , rovedakis , and tixeuil @xcite .",
    "this latter algorithm exchanges less bits with neighbours than does the algorithm of @xcite .",
    "the algorithm of @xcite addressed also another goal- even during stabilization it is _",
    "loop free_. that is , it also maintains a tree at all times ( after reaching an initial tree ) .",
    "this algorithm assumes the existence of a unique leader in the network ( while the algorithm in the current paper does not ) .",
    "however , this does not seem to affect the order of magnitude of the time complexity .",
    "note that the memory size in the last two algorithms above is the same as in the current paper .",
    "however , their time complexity is @xmath25 versus @xmath7 in the current paper .",
    "the time complexity of the algorithm of blin , dolev , potop - butucaru , and rovedakis @xcite improved the time complexity of @xcite to @xmath9 but at the cost of growing the memory usage to @xmath19 .",
    "this may be the first paper using labeling schemes for the design of a self - stabilizing mst protocol , as well as the first paper implementing the algorithm by gallager , humblet , and spira in a self - stabilizing manner without using a general transformer .",
    "additional studies about mst verification in various models appeared in @xcite .",
    "in particular , kor et al .",
    "@xcite shows that the verification from scratch ( without labels ) of an mst requires @xmath31 time and @xmath32 messages , and that these bounds are tight up to poly - logarithmic factors .",
    "we note that the memory complexity was not considered in @xcite , and indeed the memory used therein is much higher than the one used in the current paper .",
    "the time lower bound proof in @xcite was later extended in @xcite to apply for a variety of verification and computation tasks .",
    "this paper has results concerning distributed verification .",
    "various additional papers dealing with verification have appeared recently , the models of some of them are rather different than the model here .",
    "verification in the @xmath33 model ( where congestion is abstracted away ) was studied in @xcite from a computational complexity perspective . that paper presents various complexity classes , shows separation between them , and provides complete problems for these classes . in particular , the class nld defined therein exhibits similarities to the notion of proof labeling schemes .",
    "perhaps the main result in @xcite is a sharp threshold for the impact of randomization on local decision of hereditary languages . following that paper",
    ", @xcite showed that the threshold in @xcite holds also for any non - hereditary language , assuming it is defined on path topologies .",
    "in addition , @xcite showed further limitations of randomness , by presenting a hierarchy of languages , ranging from deterministic , on the one side of the spectrum , to almost complete randomness , on the other side .",
    "still , in the @xmath33 model , @xcite studied the impact of assuming unique identifiers on local decision .",
    "we stress that the memory complexity was not considered in neither @xcite nor in its follow - up papers @xcite .",
    "this paper contains the following two main results .    [ [ solving - an - open - problem - posed - by - awerbuch - and - varghese ] ] ( 1 ) solving an open problem posed by awerbuch and varghese @xcite : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in the context of self - stabilization , an open problem posed in @xcite is to find a ( synchronous ) mst verification algorithm whose time complexity is smaller than the mst computation time , yet with a small memory .",
    "our first main result solves this question positively by constructing a time efficient self - stabilizing verification algorithm for an mst while using optimal memory size , that is @xmath0 bits of memory per node .",
    "more specifically , the verification scheme takes as input a distributed structure claimed to be an mst . if the distributed structure is indeed an mst , and if a marker algorithm properly marked the nodes to allow the verification , and if no faults occur , then our algorithm outputs _",
    "accept _ continuously in every node .",
    "however , if faults occur ( including the case that the structure is not , in fact , an mst , or that the marker did not perform correctly ) , then our algorithm outputs _ reject _ in at least one node .",
    "this _ reject _ is outputted in time @xmath19 after the faults cease , in a synchronous network .",
    "( recall , lower bounds which are polynomial in @xmath14 for mst _ construction _ are known even for synchronous networks @xcite . ) in asynchronous networks , the time complexity of our verification scheme grows to @xmath17 .",
    "we also show that @xmath4 time is necessary if the memory size is restricted to @xmath0 , even in synchronous networks .",
    "another property of our verification scheme is that if @xmath5 faults occurred , then , within the required detection time above , they are detected by some node in the @xmath6 locality of each of the faults .",
    "moreover , we present a distributed implementation of the marker algorithm whose time complexity for assigning the labels is @xmath7 , under the same memory size constraint of @xmath0 memory bits per node .    [ [ constructing - an - asynchronous - self - stabilizing - mst - construction - algorithm - which - uses - optimal - memory - olog - n - bits - and - runs - in - on - time ] ] ( 2 ) constructing an asynchronous self - stabilizing mst construction algorithm which uses optimal memory ( @xmath0 bits ) and runs in @xmath7 time : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in our second main result , we show how to enhance a known transformer that makes input / output algorithms self - stabilizing .",
    "it now takes as input an efficient construction algorithm and an efficient self - stabilizing proof labeling scheme , and produces an efficient self - stabilizing algorithm .",
    "when used with our verification scheme , the transformer produces a memory optimal self - stabilizing mst construction algorithm , whose time complexity , namely , @xmath7 , is significantly better even than that of previous algorithms .",
    "( recall , the time complexity of previous mst algorithms that used @xmath8 memory bits per node was @xmath9 , and the time for optimal space algorithms was @xmath10 . ) inherited from our verification scheme , our self - stabilising mst construction algorithm also has the following two properties . first ,",
    "if faults occur after the construction ended , then they are detected by some nodes within @xmath1 time in synchronous networks , or within @xmath2 time in asynchronous ones , and second , if @xmath5 faults occurred , then , within the required detection time above , they are detected within the @xmath6 locality of each of the faults .",
    "we also show how to improve these two properties , at the expense of some increase in the memory .",
    "preliminaries and some examples of simple , yet useful , proof labeling schemes are given in section [ sec : preliminaries ] .",
    "an intuition is given in section [ sec : intuition ] .",
    "a building block is then given in section [ sec : mst - construction ] .",
    "namely , that section describes a synchronous mst construction algorithm in @xmath0 bits memory size and @xmath7 time .",
    "section [ sec : section5 ] describes the construction of parts of the labeling scheme .",
    "those are the parts that use labeling schemes of the kind described in @xcite- namely , schemes that can be verified in one time unit .",
    "these parts use the mst construction ( of section [ sec : mst - construction ] ) to assign the labels .",
    "sections [ sec : proof ] , [ sec : viewing ] , and [ sub : utilizing ] describe the remaining part of the labeling scheme .",
    "this part is a labeling scheme by itself , but of a new kind .",
    "it saves on memory by distributing information .",
    "specifically , section  [ sec : proof ] describes how the labels should look if they are constructed correctly ( and if an mst is indeed represented in the graph ) .",
    "the verifications , in the special case that no further faults occur , is described in section [ sec : viewing ] .",
    "this module verifies ( alas , not in constant time ) by moving the distributed information around , for a `` distributed viewing '' . because the verification is not done in one time unit",
    ", it needs to be made self stabilizing .",
    "this is done in section  [ sub : utilizing ] .",
    "section [ sec : lower ] presents a lower bound for the time of a proof labeling scheme for mst that uses only logarithmic memory .",
    "( essentially , the proof behind this lower bound is based on a simple reduction , using the rather complex lower bound given in . )",
    "the efficient self - stabilizing mst algorithm is given in section  [ sec : full - mst - alg ] .",
    "using known transformers , we combine efficient mst verification schemes and ( non - self - stabilizing ) mst construction schemes to yield efficient self - stabilizing schemes .",
    "the mst construction algorithm described in section  [ sec : mst - construction ] is a variant of some known time efficient mst construction algorithms .",
    "we show there how those can also be made memory efficient ( at the time , this complexity measure was not considered ) , and hence can be used as modules for our optimal memory self - stabilizing mst algorithm .",
    "[ sec : def ]      we use rather standard definitions ; a reader unfamiliar with these notions may refer to the model descriptions in the rich literature on these subjects .",
    "in  particular , we use rather standard definitions of self - stabilization ( see , e.g. @xcite ) . note that the assumptions we make below on time and time complexity imply ( in self stabilization jargon ) a distributed daemon with a very strong fairness .",
    "when we speak of asynchronous networks , this implies a rather fine granularity of atomicity .",
    "note that the common self stabilization definitions include the definitions of faults .",
    "we also use standard definitions of graph theory ( including an edge weighted graph @xmath34 , with weights that are polynomial in @xmath35 ) to represent a network ( see , e.g. @xcite ) .",
    "each node @xmath36 has a unique identity @xmath37 encoded using @xmath0 bits .",
    "for convenience , we assume that each adjacent edge of each node @xmath36 has some label that is unique at @xmath36 ( edges at different nodes may have the same labels ) .",
    "this label , called a _ port - number _ , is known only to @xmath36 and is independent of the port - number of the same edge at the other endpoint of the edge .",
    "( clearly , each port - number can be assumed to be encoded using @xmath0 bits ) .",
    "moreover , the network can store an object such as an mst ( minimum spanning tree ) by having each node store its _ component _ of the representation .",
    "a component @xmath38 at a node @xmath36 includes a collection of pointers ( or port - numbers ) to neighbours of @xmath36 , and the collection of the components of all nodes induces a subgraph @xmath39 ( an edge is included in @xmath39 if and only if at least one of its end - nodes points at the other end - node ) . in the verification scheme considered in this current paper , @xmath39 is supposed to be an  mst and for simplicity , we assume that the component of each node contains a single pointer ( to the parent , if that node is not defined as the root ) .",
    "it is not difficult to extend our verification scheme to hold also for the case where each component can contain several pointers .",
    "note that the definitions in this paragraph imply a lower bound of @xmath4 bits on the memory required at each node to even represent an mst ( in graphs with nodes of high degree ) .    some additional standard ( @xcite )",
    "parts of the model include the assumption that the edge weights are distinct .",
    "as noted often , having distinct edge weights simplifies our arguments since it guarantees the uniqueness of the mst . yet , this assumption is not essential .",
    "alternatively , in case the graph is not guaranteed to have distinct edge weights , we may modify the weights locally as was done in @xcite .",
    "the resulted modified weight function @xmath40 not only assigns distinct edge weights , but also satisfies the property that the given subgraph @xmath39 is an mst of @xmath11 under @xmath41 if and only if @xmath39 is an mst of @xmath11 under @xmath42 . , and then , by the identifiers of the edge endpoints .",
    "this yields a modified graph with unique edge weights , and an mst of the modified graph is necessarily an mst of the original graph . for construction purposes",
    "it is therefore sufficient to consider only the modified graph . yet , this is not the case for verification purposes , as the given subgraph can be an mst of the original graph but not necessarily an mst of the modified graph .",
    "while the authors in @xcite could not guarantee that any mst of the original graph is an mst of the modified graph ( having unique edge weights ) , they instead make sure that the particular given subgraph @xmath18 is an mst of the original graph if and only if it is an mst of modified one .",
    "this condition is sufficient for verification purposes , and allows one to consider only the modified graph . for completeness",
    ", we describe the weight - modification in @xcite . to obtain the modified graph ,",
    "the authors in @xcite employ the technique , where edge weights are lexicographically ordered as follows .",
    "for an edge @xmath43 connecting @xmath36 to its neighbour  @xmath44 , consider first its original weight @xmath45 , next , the value @xmath46 where @xmath47 is the indicator variable of the edge @xmath48 ( indicating whether @xmath48 belongs to the candidate mst to be verified ) , and finally , the identifiers of the edge endpoints , @xmath49 and @xmath50 ( say , first comparing the smaller of the two identifiers of the endpoints , and then the larger one ) .",
    "formally , let @xmath51 where @xmath52 and @xmath53",
    ". under this weight function @xmath40 , edges with indicator variable set to 1 will have lighter weight than edges with the same weight under @xmath45 but with indicator variable set to 0 ( i.e. , for edges @xmath54 and @xmath55 such that @xmath56 , we have @xmath57 ) .",
    "it follows that the given subgraph @xmath18 is an mst of @xmath11 under @xmath58 if and only if @xmath18 is an mst of @xmath11 under @xmath42 .",
    "moreover , since @xmath42 takes into account the unique vertex identifiers , it assigns distinct edge weights . ]",
    "we use the ( rather common ) ideal time complexity which assumes that a node reads all of its neighbours in at most one time unit , see e.g.  @xcite .",
    "our results translate easily to an alternative , stricter , _ contention _ time complexity , where a node can access only one neighbour in one time unit .",
    "the time cost of such a translation is at most a multiplicative factor of @xmath3 , the maximum degree of a node ( it is not assumed that @xmath3 is known to nodes ) .",
    "as is commonly assumed in the case of self - stabilization , each node has only some bounded number of memory bits available to be used . here",
    ", this amount of memory is @xmath0 .",
    "we use a self stabilizing transformer of awerbuch and varghese as a building block @xcite .",
    "that protocol was designed for the message passing model . rather than modifying that transformer to work on the model used here ( which would be very easy , but would take space ) , we use emulation .",
    "that is , we claim that any self stabilizing protocol designed for the model of @xcite ( including the above transformer ) can be performed in the model used here , adapted from @xcite .",
    "this is easy to show : simply use the current model to implement the links of the model of @xcite . to send a message from node @xmath36 to its neighbour @xmath44 ,",
    "have @xmath36 write its shared variable that ( only @xmath36 and ) @xmath44 can read . this value can be read by @xmath44 after one time unit in a synchronous network as required from a message arrival in the model of @xcite .",
    "hence , this is enough for synchronous networks .    in an asynchronous network",
    ", we need to work harder to simulate the sending and the receiving of a message , but only slightly harder , given known art .",
    "specifically , in an asynchronous network , an event occurs at @xmath44 when this message arrives . without some additional precaution on our side",
    ", @xmath44 could have read this value many times ( per one writing ) resulting in duplications : multiple message `` arriving '' while we want to emulate just one message .",
    "this is solved by a self stabilizing data link protocol , such as the one used by @xcite , since this is also the case in a data link protocol in message passing systems where a link may loose a package . there , a message is sent repeatedly , possibly many times , until an acknowledgement from the receiver tells the sender that the message arrived .",
    "the data link protocol overcomes the danger of duplications by simply numbering the messages modulo some small number .",
    "that is , the first message is sent repeatedly with an attached `` sequence number '' zero , until the first acknowledgement arrives .",
    "all the repetitions of the second message have as attachments the sequence number  1 , etc .",
    "the receiver then takes just one of the copies of the first message , one of the copies of the second , etc .",
    "a self stabilized implementation of this idea in a shared memory model appears in @xcite using ( basically , to play the role of the sequence number ) an additional shared variable called the `` toggle '' , which can take one of three values .",
    "when @xmath44 reads that the toggle of @xmath36 changes , @xmath44 can emulate the arrival of a message . in terms of time complexity",
    ", this protocol takes a constant time , and hence sending ( an emulated ) message still takes a constant time ( in terms of complexity only ) as required to emulate the notion of ideal time complexity of @xcite .",
    "note that the memory is not increased .",
    "we use the well known wave&echo ( pif ) tool . for details , the readers are referred to @xcite . for completeness , we remind the reader of the overview of wave&echo when performed over a rooted tree . it is started by the tree root , and every node who receives the wave message forwards it to its children . the wave can carry a command for the nodes .",
    "a leaf receiving the wave , computes the command , and sends the output to its parent .",
    "this is called an _",
    "echo_. a parent , all of whose children echoed , computes the command itself ( possibly using the outputs sent by the children ) and then sends the echo ( with its own output ) to its parent .",
    "the wave&echo terminates at the root when all the children of the root echoed , and when the root executed the command too .    in this paper ,",
    "the wave&echo activations carry various commands .",
    "let us describe first two of these commands , so that they will also help clarify the notion of wave&echo and its application .",
    "the first example is the command to sum up values residing at the nodes .",
    "the echo of a leaf includes its value .",
    "the echo of a parent includes the sum of its own value and the sums sent by its children .",
    "another example is the counting of the nodes .",
    "this is the same as the sum operation above , except that the initial value at a node is @xmath59 . similarly to summing up",
    ", the operation performed by the wave can also be a logical @xmath60 .      in @xcite ,",
    "the authors consider a framework for maintaining a distributed proof that the network satisfies some given predicate @xmath61 , e.g. , that @xmath39 is an mst .",
    "we are given a predicate @xmath61 and a graph family @xmath62 ( in this paper , if @xmath61 and @xmath62 are omitted , then @xmath61 is mst and @xmath62 ( or @xmath63 ) is all connected undirected weighted graphs with @xmath14 nodes ) .",
    "proof labeling scheme _",
    "( also referred to as a _ verification _",
    "algorithm ) includes the following two components .    * a _ marker _",
    "algorithm @xmath64 that generates a label @xmath65 for every node @xmath36 in every graph @xmath66 .",
    "* a _ verifier _ , that is a distributed algorithm @xmath67 , initiated at each node of a _ labeled _ graph @xmath66 , i.e. , a graph whose nodes @xmath36 have labels @xmath68 ( not necessarily correct labels assigned by a marker ) .",
    "the verifier at each node is initiated separately , and at an arbitrary time , and runs forever .",
    "the verifier may _ raise an alarm _ at some node @xmath36 by outputting `` no '' at @xmath36 .",
    "intuitively , if the verifier at @xmath36 raises an alarm , then it detected a fault .",
    "that is , for any graph @xmath66 ,    * if @xmath11 satisfies the predicate @xmath61 and if the label at each node @xmath36 is @xmath65 ( i.e. , the label assigned to @xmath36 by the marker algorithm @xmath69 then no node raises an alarm . in this case",
    ", we say that the verifier _ accepts _ the labels . *",
    "if @xmath11 does not satisfy the predicate @xmath61 , then for _ any _ assignment of labels to the nodes of @xmath11 , after some finite time @xmath70 , there exists a node @xmath36 that raises an alarm . in this case , we say that the verifier _ rejects _ the labels .    note that the first property above concerns only the labels _ produced by the marker algorithm _",
    "@xmath64 , while the second must hold even if the labels are assigned by some adversary .",
    "we evaluate a proof labeling scheme @xmath71 by the following complexity measures .    * the _ memory size _ : the maximum number of bits stored in the memory of a single node @xmath36 , taken over all the nodes @xmath36 in all graphs @xmath72 that satisfy the predicate @xmath61 ( and over all the executions ) ; this includes : ( 1 ) the bits used for encoding the identity @xmath37 , ( 2 ) the marker memory : number of bits used for constructing and encoding the labels , and ( 3 ) the verifier memory : the number of bits used during the operation of the verifier at each node @xmath36 . recall that for simplicity , we assume here that each component contains a single pointer , and therefore , the size of each component is @xmath0 bits .",
    "hence , for our purposes , including the size of a component in the memory complexity would not increase the asymptotical size of the memory , anyways .",
    "however , in the general case , if multiple pointers can be included in a component , then the number of bits needed for encoding a component would potentially be as large as @xmath73 .",
    "since , in this case , the verification scheme has no control over the size of the component , we decided to exclude this part from the definition of the memory complexity . ] .",
    "* the ( ideal ) _ detection time _ : the maximum , taken over all the graphs @xmath72 that do _ not _ satisfy the predicate @xmath61 and over all the labels given to nodes of @xmath11 by adversaries ( and over all the executions ) , of the time @xmath70 required for some node to raise an alarm . ( the time is counted from the _ starting time _",
    ", when the verifier has been initiated at all the nodes . )",
    "* the _ detection distance _ : for a faulty node @xmath36 , this is the ( hop ) distance to the closest node @xmath44 raising an alarm within the detection time after the fault occurs .",
    "the detection distance of the scheme is the maximum , taken over all the graphs having at most @xmath5 faults , and over all the faulty nodes @xmath36 ( and over all the executions ) , of the detection distance of @xmath36 . *",
    "the ( ideal ) _ construction - time _ : the maximum , taken over all the graphs @xmath72 that satisfy the predicate @xmath61 ( and over all the executions ) , of the time required for the marker @xmath64 to assign labels to all nodes of @xmath11 . unless mentioned otherwise , we measure construction - time in synchronous networks only .    in our terms , the definitions of @xcite allowed only detection time complexity 1 . because of that , the verifier of @xcite at a node @xmath36 , could only consult the neighbours of  @xmath36 .",
    "whenever we use such a scheme , we refer to it as a _ @xmath59-proof labeling scheme _ , to emphasis its running time .",
    "note that a 1-proof labelling scheme is trivially self - stabilzying .",
    "( in some sense , this is because they `` silently stabilize '' @xcite , and `` snap stabilize '' @xcite . ) also , in @xcite , if @xmath5 faults occurred , then the detection distance was @xmath5 .      in section  [ sec : proof - labeling ] , we defined the memory size , detection time and the detection distance complexities of a _ verification _ algorithm .",
    "when considering a ( self - stabilizing ) computation algorithm , we extend the notion of the memory size to include also the bits needed for encoding the component @xmath38 at each node .",
    "recall , the definition of a component @xmath38 in general , and the special case of @xmath38 for mst , are given in section [ sec : preliminaries ] .",
    "( recall , from section  [ sec : proof - labeling ] , that the size of the component was excluded from the definition of memory size for verification because , there , the designer of the verification scheme has no control over the nodes components . )",
    "the notions of detection time and the detection distance can be carried to the very common class of self - stabilizing _ computation _ algorithms that use fault detection .",
    "( examples for such algorithms are algorithms that have silent stabilization @xcite . )",
    "informally , algorithms in this class first compute an output .",
    "after that , all the nodes are required to stay in some _ output state _ where they ( 1 ) output the computation result forever ( unless a fault occurs ) ; and ( 2 ) check repeatedly until they discover a fault . in such a case , they recompute and enter an output state again .",
    "let us term such algorithms _ detection based _ self - stabilizing algorithms .",
    "we define the _ detection time _ for such algorithms to be the time from a fault until the detection . however , we only define the detection time ( and the detection distance ) for faults that occur after all the nodes are in their output states .",
    "( intuitively , in the other cases , stabilization has not been reached yet anyhow . )",
    "the _ detection distance _ is the distance from a node where a fault occurred to the closest node that detected a fault .      as a warm - up exercise ,",
    "let us begin by describing several simple 1-proof labeling schemes , which will be useful later in this paper .",
    "the first two examples are taken from @xcite and are explained there in more details .",
    "the reader familiar with proof labeling schemes may skip this subsection .",
    "+ * @xmath74 example 1 : a spanning tree .",
    "( example @xmath75 ) * let @xmath76 denote the predicate such that for any input graph @xmath11 satisfies , @xmath77 if @xmath39 is a spanning tree of @xmath11 , and @xmath78 otherwise .",
    "we now describe an efficient @xmath59-proof labeling scheme @xmath71 for the predicate @xmath76 and the family of all graphs .",
    "let us first describe the marker @xmath64 operating on a `` correct instance '' , i.e. , a graph @xmath11 where @xmath79 is indeed a spanning tree of @xmath11 . if there exists a node @xmath44 whose component does not encode a pointer to any of its adjacent edges ( observe that there can be at most one such node ) ,",
    "we root @xmath18 at @xmath44 .",
    "otherwise , there must be two nodes @xmath36 and @xmath80 whose components point at each other . in this case , we root @xmath18 arbitrarily at either @xmath36 or @xmath80 .",
    "note that after rooting @xmath18 , the component at each non - root node @xmath36 points at @xmath36 s parent . the label given by @xmath64 to a node @xmath36",
    "is composed of two parts .",
    "the first part encodes the identity @xmath81 of the root @xmath82 of @xmath18 , and the second part of the label of @xmath36 encodes the distance ( assuming all weights of edges are 1 ) between @xmath36 and @xmath82 in @xmath18 .",
    "given a labeled graph , the verifier @xmath67 operates at a node @xmath36 as follows : first , it checks that the first part of the label of @xmath36 agrees with the first part of the labels of @xmath36 s neighbours , i.e. , that @xmath36 agrees with its neighbours on the identity of the root .",
    "second , let @xmath83 denote the number encoded in the second part of @xmath36 s label . if @xmath84 then @xmath67 verifies that @xmath85 ( recall that @xmath81 is encoded in the first part of @xmath36 s label ) .",
    "otherwise , if @xmath86 then the verifier checks that @xmath87 , where @xmath44 is the node pointed at by the component at @xmath36 .",
    "if at least one of these conditions fails , the verifier @xmath67 raises an alarm at @xmath36 .",
    "it is easy to get convinced that @xmath71 is indeed a 1-proof labeling scheme for the predicate @xmath76 with memory size @xmath0 and construction time @xmath7 .",
    "[ [ remark . ] ] remark .",
    "+ + + + + + +    observe that in case @xmath79 is indeed a ( rooted ) spanning tree of @xmath11 , we can easily let each node  @xmath36 know which of its neighbours in @xmath11 are its children in @xmath18 and which is its parent .",
    "moreover , this can be done using one unit of time and label size @xmath0 bits . to see this , for each node @xmath36 , we simply add to its label its identity @xmath37 and the identity @xmath88 of its parent @xmath44 .",
    "the verifier at @xmath36 first verifies that @xmath37 is indeed encoded in the right place of its label .",
    "it then looks at the label of its parent @xmath44 , and checks that @xmath36 s candidate for being the identity of @xmath44 is indeed @xmath88 .",
    "assume now that these two conditions are satisfied at each node .",
    "then , to identify a child @xmath80 in @xmath18 , node  @xmath36 should only look at the labels of its neighbours in @xmath11 and see which of them encoded @xmath37 in the designated place of its label . + * @xmath74 example 2 : knowing the number of nodes ( example @xmath89 ) * denote by @xmath90 the boolean predicate such that @xmath91 if and only if one designated part of the label @xmath68 at each node @xmath36 encodes the number of nodes in @xmath11 ( informally , when @xmath90 is satisfied , we say that each node ` knows ' the number of nodes in @xmath11 ) . let us denote the part of the label of @xmath36 that is supposed to hold this number by @xmath92 .    in @xcite , the authors give a 1-proof labeling scheme @xmath71 for @xmath90 with memory size @xmath0 .",
    "the idea behind their scheme is simple .",
    "first , the verifier checks that @xmath93 for every two adjacent nodes @xmath44 and @xmath36 ( if this holds at each node then all nodes must hold the same candidate for being the number of nodes ) .",
    "second , the marker constructs a spanning tree @xmath18 rooted at some node @xmath82 ( and verifies that this is indeed a spanning tree using the example @xmath75 above ) .",
    "third , the number of nodes in @xmath18 is aggregated upwards along @xmath18 towards its root @xmath82 , by keeping at the label @xmath65 of each node @xmath36 , the number of nodes @xmath94 in the subtree of @xmath18 hanging down from @xmath36 .",
    "this again is easily verified by checking at each node @xmath36 that @xmath95 , where @xmath96 is the set of children of @xmath36 . finally , the root verifies that @xmath97 .",
    "it is straightforward that @xmath71 is indeed a 1-proof labeling scheme for the predicate @xmath90 with memory size @xmath0 and construction time @xmath7 . +",
    "* @xmath74 example 3 : an upper bound on the diameter of a tree ( example @xmath98 ) * consider a tree @xmath18 rooted at @xmath82 , and let  @xmath99 denote the height of @xmath18 .",
    "denote by @xmath100 the boolean predicate such that @xmath101 if and only if one designated part of the label @xmath68 at each node encodes the same value @xmath102 , where @xmath103 ( informally , when @xmath100 is satisfied , we say that each node ` knows ' an upper bound of @xmath104 on the diameter @xmath23 of @xmath105 .",
    "let us denote the part of the label of @xmath36 that is supposed to hold this number by @xmath92 .",
    "we sketch a simple 1-proof labeling scheme @xmath71 for @xmath100 .",
    "first , the verifier checks that @xmath93 for every two adjacent nodes @xmath44 and @xmath36 ( if this holds at each node then all nodes must hold the same value @xmath106 .",
    "second , similarly to the proof labeling scheme for @xmath76 given in example @xmath75 above , the label in each node  @xmath36 contains the distance @xmath83 in the tree from @xmath36 to the root .",
    "each non - root node verifies that the distance written at its parent is one less than the distance written at itself , and the root verifies that the distance written at itself is 0 .",
    "finally , each node @xmath36 verifies also that @xmath107 .",
    "if no node raises an alarm then  @xmath102 is an upper bound on the height . on the other hand ,",
    "if the value @xmath102 is the same at all nodes and @xmath102 is an upper bound on the height then no node raises an alarm .",
    "hence the scheme is a 1-proof labeling scheme for the predicate  @xmath100 with memory size @xmath0 and construction time @xmath7 .",
    "the final mst construction algorithm makes use of several modules .",
    "the main technical contribution of this paper is the module that verifies that the collection of nodes components is indeed an mst .",
    "this module in itself is composed of multiple modules . some of those , we think may be useful by themselves . to help the reader avoid getting lost in the descriptions of all the various modules , we present , in this section , an overview of the mst verification part .",
    "given a graph @xmath11 and a subgraph that is represented distributively at the nodes of @xmath11 , we wish to produce a self - stabilizing proof labeling scheme that verifies whether the subgraph is an mst of @xmath11 . by first employing the ( self - stabilizing ) 1-proof labeling scheme mentioned in example @xmath75",
    ", we may assume that the subgraph is a rooted spanning tree of @xmath11 ( otherwise , at least one node would raise an alarm ) .",
    "hence , from now on , we focus on a spanning tree @xmath108 of a weighted graph @xmath109 , rooted at some node @xmath110 , and aim at verifying the minimality of @xmath18 .      from a high - level perspective",
    ", the proof labeling scheme proves that @xmath18 could have been computed by an algorithm that is similar to that of ghs , the algorithm of gallager , humblet , and spira s described in @xcite .",
    "this leads to a simple idea : when @xmath18 is a tree computed by such an algorithm , @xmath18 is an mst .",
    "let us first recall a few terms from @xcite .",
    "a _ fragment _",
    "@xmath111 denotes a connected subgraph of @xmath18 ( we simply refer it to a _ subtree _ ) .",
    "given a fragment @xmath111 , an edge @xmath112 whose one endpoint @xmath36 is in @xmath111 , while the other endpoint @xmath44 is not , is called _ outgoing _ from @xmath111 .",
    "such an edge of minimum weight is called a _ minimum outgoing _ edge from  @xmath111 .",
    "a fragment containing a single node is called a _ singleton_. recall that ghs starts when each node is a fragment by itself .",
    "essentially , fragments merge over their minimum outgoing edges to form larger fragments .",
    "that is , each node belongs to one fragment @xmath113 , then to a larger fragment @xmath114 that contains @xmath113 , etc .",
    "this is repeated until one fragment spans the network .",
    "a tree constructed in that way is an mst .",
    "note that in ghs , the collection of fragments is a laminar family , that is , for any two fragments @xmath111 and @xmath115 in the collection , if @xmath116 then either @xmath117 or @xmath118 ( see , e.g. @xcite ) .",
    "moreover , each fragment has a _ level _ ; in the case of @xmath36 above , @xmath114 s level is higher than that of @xmath113 .",
    "this organizes the fragments in a _",
    "@xmath119 , which is a tree whose nodes are fragments , where fragment @xmath113 is a descendant in @xmath119 of @xmath114 if @xmath114 contains @xmath113 .",
    "ghs manages to ensure that each node belongs to at most one fragment at each level , and that the total number of levels is @xmath0 .",
    "hence , the hierarchy @xmath119 has @xmath0 height .    the marker algorithm in our proof labeling scheme performs , in some sense , a reverse operation . if @xmath18 is an mst , the marker `` slices '' it back into fragments . then",
    ", the proof labeling scheme computes for each node @xmath36 :    the ( unique ) name of each of the fragments @xmath120 that @xmath36 belongs to ,    the level of @xmath120 , and    the weight of @xmath120 s minimum outgoing edge .    note that each node participates in @xmath0 fragments , and the above `` piece of information '' per fragment requires @xmath0 bits .",
    "hence , this is really too much information to store in one node . as we shall see later",
    ", the verification scheme distributes this information and then brings it to the node without violating the memory size bound @xmath0 . for",
    "now , it suffices to know that given these pieces of information and the corresponding pieces of information of their neighbours , the nodes can verify that @xmath18 could have been constructed by an algorithm similar to ghs .",
    "that way , they verify that @xmath18 is an mst .",
    "indeed , the 1-proof labeling schemes for mst verification given in @xcite follow this idea employing memory size of @xmath19 bits .",
    "( there , each node keeps @xmath0 pieces , each of @xmath0 bits . )",
    "the current paper allows each node to hold only @xmath0 memory bits .",
    "hence , a node has room for only a constant number of such pieces of information at a time .",
    "one immediate idea is to store some of @xmath36 s pieces in some other nodes .",
    "whenever @xmath36 needs a piece , some algorithm should move it towards @xmath36 .",
    "moving pieces would cost time , hence , realizing some time versus memory size trade - off .",
    "unfortunately , the total ( over all the nodes ) number of pieces in the schemes of @xcite is @xmath121 .",
    "any way one would assign these pieces to nodes would result in the memory of some single node needing to store @xmath4 pieces , and hence , @xmath8 bits .",
    "thus , one technical step we used here is to reduce the total number of pieces to @xmath7 , so that we could store at each node just a constant number of such pieces .",
    "however , each node still needs to use @xmath4 pieces .",
    "that is , some pieces may be required by many nodes .",
    "thus , we needed to solve also a combinatorial problem : locate each piece `` close '' to each of the nodes needing it , while storing only a constant number of pieces per node .",
    "the solution of this combinatorial problem would have sufficed to construct the desired scheme in the @xmath33 model  @xcite . there , node @xmath36 can `` see '' the storage of nearby nodes . however , in the congestion aware model , one actually needs to move pieces from node to node , while not violating the @xmath0 memory per node constraint .",
    "this is difficult , since , at the same time @xmath36 needs to see its own pieces , other nodes need to see their own ones .",
    "going back to ghs , one may notice that its correctness follows from the combination of two properties :    * p1 .",
    "( well - forming ) * the existence of a hierarchy tree @xmath119 of fragments , satisfying the following :    each fragment @xmath122 has a unique _ selected _ outgoing edge ( except when @xmath111 is the whole tree @xmath18 ) .",
    "a ( non - singleton ) fragment is obtained by merging its children fragments in @xmath119 through their selected outgoing edges .",
    "( minimality ) * the selected outgoing edge of each fragment is its minimal outgoing edge .    in our proof",
    "labeling scheme , we verify the aforementioned two properties separately . in section [ sec : section5 ] , we show how to verify the first property , namely , property well - forming .",
    "this turns out to be a much easier task than verifying the second property .",
    "indeed , the well - forming property can be verified using a 1-proof labeling scheme , while still obeying the @xmath0 bits per node memory constraint . moreover , the techniques we use for verifying the well - forming are rather similar to the ones described in @xcite .",
    "the more difficult verification task , namely , verifying the minimality property p2 , is described in section  [ sec : proof ] .",
    "this verification scheme requires us to come up with several new techniques which may be considered as contributions by themselves .",
    "we now describe the intuition behind these verifications .",
    "we want to show that @xmath18 could have been produced by an algorithm similar to ghs .",
    "crucially , since we care about the memory size , we had to come up with a new mst construction algorithm that is similar to ghs but uses only @xmath0 memory bits per node and runs in time @xmath7 .",
    "this mst construction algorithm , called @xmath123 , can be considered as a synchronous variant of ghs and is described in section [ sec : mst - construction ] .",
    "intuitively , for a correct instance ( the case @xmath18 is an mst ) , the marker algorithm @xmath64 produces a hierarchy of fragments @xmath119 by following the new mst construction algorithm described in section [ sec : mst - construction ] .",
    "let @xmath124 be the height of @xmath119 .",
    "for a fixed level @xmath125 $ ] , it is easy to represent the partition of the tree into fragments of level @xmath126 using just one bit per node .",
    "that is , the root @xmath127 of each fragment @xmath115 of level @xmath126 has 1 in this bit , while the nodes in @xmath128 have 0 in this bit .",
    "note , these nodes in @xmath128 are the nodes below @xmath127 ( further away from the root of @xmath18 ) , until ( and not including ) reaching additional nodes whose corresponding bit is  1 . hence , to represent the whole hierarchy ,",
    "it is enough to attach a string of length @xmath129-bits at each node @xmath36 .",
    "the string at a node @xmath36 indicates , for each level @xmath125 $ ] , whether @xmath36 is the root of the fragment of level @xmath126 containing @xmath36 ( if one exists ) .    next , still for correct instances",
    ", we would like to represent the selected outgoing edges distributively .",
    "that is , each node @xmath36 should be able to detect , for each fragment @xmath111 containing @xmath36 , whether @xmath36 is an endpoint of the selected edge of @xmath111 . if @xmath36 is , it should also know which of @xmath36 s edges is the selected edge .",
    "this representation is used later for verifying the two items of the well - forming property specified above . for this purpose , first , we add another string of @xmath129 entries at each node @xmath36 , one entry per level @xmath126 .",
    "this entry specifies , first , whether there exists a level @xmath126 fragment @xmath130 containing @xmath36 .",
    "if @xmath130 does exist , the entry specifies whether @xmath36 is incident to the corresponding selected edge .",
    "note , storing the information at @xmath36 specifying the pointers to all the selected edges of the fragments containing it , may require @xmath19 bits of memory at @xmath36 .",
    "this is because there may be @xmath0 fragments containing @xmath36 ; each of those may select an edge at @xmath36 leading to an arbitrary neighbour of @xmath36 in the tree @xmath18 ; if @xmath36 has many neighbours , each edge may cost @xmath0 bits to encode .",
    "the trick is to distribute the information regarding @xmath36 s selected edges among @xmath36 s children in @xmath18 .",
    "( recall that @xmath36 can look at the data structures of @xmath36 s children . )",
    "the strings mentioned in the previous paragraphs are supposed to define a hierarchy and selected outgoing edges from the fragments of the hierarchy .",
    "however , on incorrect instances , if corrupted , the strings may not represent the required . for example , the strings may represent more than one selected edge for some fragment .",
    "hence , we need also to attach proof labels for verifying the hierarchy and the corresponding selected edges represented by those strings . fortunately , for proving the well - forming property only , it is not required to verify that the represented hierarchy ( and the corresponding selected edges ) actually follow the mst construction algorithm ( which is the case for correct instances ) . in section [ sec : section5 ] , we present 1-proof labeling schemes to show that the above strings represent _ some _ hierarchy with corresponding selected edges , and that the well - forming property does hold for that hierarchy .",
    "a crucial point in the scheme is letting each node @xmath36 know , for each of its incident edges @xmath131 and for each level @xmath126 , whether @xmath44 and @xmath36 share the same level @xmath126 fragment .",
    "intuitively , this is needed in order to identify outgoing edges . for that purpose",
    ", we assign each fragment a unique identifier , and @xmath36 compares the identifier of its own level @xmath126 fragment to the identifier of @xmath44 s level @xmath126 fragment .",
    "consider the number of bits required to represent the identifiers of all the fragments that a node @xmath36 participates in .",
    "there exists a method to assign unique identifiers such that this total number is only @xmath0 @xcite .",
    "unfortunately , we did not manage to use that method here .",
    "indeed , there exists a marker algorithm that assigns identifiers according to that method .",
    "however , we could not find a low space and short time method for the verifier to verify that the given identifiers of the fragments were indeed assigned in that way .",
    "( in particular , we could not verify efficiently that the given identifiers are indeed unique ) .",
    "hence , we assign identifiers according to another method that appears more memory wasteful , where the identity @xmath132 of a fragment @xmath111 is composed of the ( unique ) identity of its root together with its level . we also need each node @xmath36 to know the weight @xmath133 of the minimum outgoing edge of each fragment @xmath111 containing  @xmath36 . to summarize , the _ piece of information _",
    "@xmath134 required in each node @xmath36 per fragment @xmath111 containing @xmath36 is @xmath135 .",
    "thus , @xmath134 can be encoded using @xmath0 bits .",
    "again , note that since a node may participate in @xmath136 fragments , the total number of bits used for storing all the @xmath134 for all fragments @xmath111 containing @xmath36 would thus be @xmath13 .",
    "had no additional steps been taken , this would have violated the @xmath0 memory constraint .    luckily , the total number of bits needed globally for representing the pieces @xmath134 of all the fragments @xmath111 is only @xmath21 , since there are at most @xmath137 fragments , and @xmath134 of a fragment @xmath111 is of size @xmath0 bits .",
    "the difficulty results from the fact that multiple nodes need replicas of the same information .",
    "( e.g. , all the nodes in a fragment need the @xmath138 of the fragment . )",
    "if a node does not store this information itself , it is not clear how to bring all the many pieces of information to each node who needs them , in a short time ( in spite of congestion ) and while having only a constant number of such pieces at a node at each given point in time .    to allow some node @xmath36 to check whether its neighbour @xmath44 belongs to @xmath36 s level @xmath126 fragment @xmath130 for some level  @xmath126 ,",
    "the verifier at @xmath36 needs first to reconstruct the piece of information @xmath139 . intuitively , we had to distribute the information , so that @xmath134 is placed `` not too far '' from every node in @xmath111 . to compare @xmath139 with a neighbour @xmath44 , node @xmath36 must also obtain @xmath140 from @xmath44 .",
    "this requires some mechanism to synchronize the reconstructions in neighbouring nodes .",
    "furthermore , the verifier must be able to overcome difficulties resulting from faults , which can corrupt the information stored , as well as the reconstruction and the synchronization mechanisms .",
    "the above distribution of the @xmath141 s is described in section [ sec : proof ] . the distributed algorithm for the `` fragment by fragment '' reconstruction ( and synchronization )",
    "is described in section [ sub:3.2 ] .",
    "the required verifications for validating the @xmath141 s and comparing the information of neighbouring nodes are described in section [ sub : utilizing ] .",
    "at a very high level description , each node @xmath36 stores permanently @xmath134 for a constant number of fragments  @xmath111 . using that , @xmath134 is `` rotated '' so that each node in @xmath111 `` sees '' @xmath134 in @xmath0 time .",
    "we term the mechanism that performs this rotation a _",
    "train_. a first idea would have been to have a separate train for each fragment @xmath111 that would `` carry '' the piece @xmath134 and would allow all nodes in @xmath111 to see it .",
    "however , we did not manage to do that efficiently in terms of time and of space .",
    "that is , one train passing a node could delay the other trains that `` wish '' to pass it .",
    "since neighbouring nodes may share only a subset of their fragments , it is not clear how to pipeline the trains .",
    "hence , those delays could accumulate .",
    "moreover , as detailed later , each train utilizes some ( often more than constant ) memory per node .",
    "hence , a train per fragment would have prevented us from obtaining an @xmath0 memory  solution .",
    "a more refined idea would have been to partition the tree into connected parts , such that each part @xmath142 intersects @xmath143 fragments .",
    "using such a partition , we could have allocated the @xmath143 pieces ( of these @xmath143 fragments ) , so that each node of @xmath142 would have been assigned only a constant number of such pieces , costing @xmath0 bits per node .",
    "moreover , just one train per part @xmath142 could have sufficed to rotate those pieces among the nodes of @xmath142 .",
    "each node in @xmath142 would have seen all the pieces @xmath134 for fragments @xmath111 containing it in @xmath143 time .",
    "hence , this would have been time efficient too , had @xmath142 been small .",
    "unfortunately , we did not manage to construct the above partition .",
    "however , we managed to obtain a similar construction : we construct _ two _ partitions of @xmath18 , called @xmath144 and @xmath145 .",
    "we also partitioned the fragments into two kinds : top and bottom fragments .",
    "now , each part @xmath142 of partition @xmath144 intersects with @xmath143 top fragments ( plus any number of bottom fragments ) .",
    "each part @xmath142 of partition @xmath145 intersects with @xmath143 bottom fragments ( plus top fragments that we do not count here ) .",
    "for each part in @xmath144 ( respectively @xmath145 ) , we shall distribute the information regarding the @xmath143 top ( respectively , bottom ) fragments it intersects with , so that each node would hold at most a constant number of such pieces of information .",
    "essentially , the pieces of information regarding the corresponding fragments are put in the nodes of the part ( permanently ) according to a dfs ( depth first search ) order starting at the root of the part . for any node @xmath36",
    ", the two parts containing it encode together the information regarding all fragments containing @xmath36 .",
    "thus , to deliver all relevant information , it suffices to utilize one train per part ( and hence , each node participates in two trains only ) .",
    "furthermore , the partitions are made so that the diameter of each part is @xmath0 , which allows each train to quickly pass in all nodes , and hence to deliver the relevant information in short time .",
    "the distributed implementation of this distribution of pieces of information , and , in particular , the distributed construction of the two partitions , required us to come up with a new _ multi - wave _ primitive , enabling an efficient ( in @xmath146 time ) parallel ( i.e. , pipelined ) executions of wave&echo operations on all fragments of hierarchy  @xmath147 .      consider a node @xmath36 and a fragment @xmath130 of level @xmath126 containing it . recall that the information @xmath139 should reside in some node of a part @xmath142 to which @xmath36 belongs . to allow @xmath36 to compare @xmath139 to @xmath140 for a neighbour @xmath44 , both these pieces",
    "must somehow be `` brought '' to @xmath36 .",
    "the process handling this task contains several components .",
    "the first component is called the _",
    "train _ which is responsible for moving the pieces of information through @xmath142 s nodes , such that each node does not hold more than @xmath0 bits at a time , and such that in short time , each node in @xmath142 `` sees '' all pieces , and in some prescribed order .",
    "essentially , a train is composed of two ingredients .",
    "the first ingredient called _ convergecast _ pipelines the pieces of information in a dfs order towards the root of the part ( recall , the pieces of information of the corresponding fragments are initially located according to a dfs order ) .",
    "the second ingredient _ broadcasts _ the pieces from the root of the part to all nodes in the part .",
    "since the number of pieces is @xmath0 and the diameter of the part is @xmath0 , the synchronous environment guarantees that each piece of information is delivered to all nodes of a part in @xmath0 time . on the other hand , in the asynchronous environment",
    "some delays may occur , and the delivery time becomes @xmath19 .",
    "these time bounds are also required to self - stabilize the trains , by known art , see , e.g.  @xcite .",
    "unfortunately , delivering the necessary pieces of information at each node is not enough , since @xmath139 may arrive at @xmath36 at a different time than @xmath140 arrives at @xmath44 .",
    "recall that @xmath44 and its neighbour @xmath36 need to have these pieces simultaneously in order to compare them ( to know whether the edge @xmath148 is outgoing from @xmath130 ) .",
    "further complications arise from the fact that the neighbours of a node  @xmath36 may belong to different parts , so different trains pass there . note that @xmath36 may have many neighbours , and we would not want to synchronize so many trains .",
    "moreover , had we delayed the train at @xmath36 for synchronization , the delays would have accumulated , or even would have caused deadlocks .",
    "hence , we do not delay these trains . instead ,",
    "@xmath36 repeatedly samples a piece from its train , and synchronizes the comparison of this piece with pieces sampled by its neighbours , while both trains advance without waiting .",
    "perhaps not surprisingly , this synchronization turns out to be easier in synchronous networks , than in asynchronous ones .",
    "our synchronization mechanism guarantees that each node can compare all pieces @xmath139 with @xmath140 for all neighbours @xmath44 and levels @xmath126 in a short time .",
    "specifically , @xmath19 time in synchronous environments and @xmath149 time in asynchronous ones .",
    "so far , with respect to verifying the minimality property , we have not discussed issues of faults that may complicate the verification .",
    "recall , the verification process must detect if the tree is not an mst .",
    "informally , this must hold despite the fact that the train processes , the partitions , and also , the pieces of information carried by the trains may be corrupted by an adversary . for example , the adversary may change or erase some ( or even all ) of such pieces corresponding to existing fragments . moreover ,",
    "even correct pieces that correspond to existing fragments may not arrive at a node in the case that the adversary corrupted the partitions or the train mechanism .    in section  [ sub : utilizing",
    "] , we explain how the verifier does overcome such undesirable phenomena , if they occur .",
    "intuitively , what is detected is not necessarily the fact that a train is corrupted ( for example ) .",
    "instead , what is detected is the state that _ some _ part is incorrect ( either the tree is not an mst , or the train is corrupted , or ... etc . ) .",
    "specifically , we show that if an mst is not represented in the network , this is detected in time @xmath19 for synchronous environments and time @xmath149 for asynchronous ones .",
    "note that for a verifier , the ability to detect while assuming any initial configuration means that the verifier is self - stabilizing , since the sole purpose of the verifier is to detect .",
    "verifying that _ some _ two partitions exist is easy .",
    "however , verifying that the given partitions are as described in section [ sec : partitions ] , rather than being two arbitrary partitions generated by an adversary seems difficult .",
    "fortunately , this verification turns out to be unnecessary .",
    "first , as mentioned , it is a known art to self - stabilize the train process .",
    "after trains stabilize , we verify that the set of pieces stored in a part ( and delivered by the train ) includes all the ( possibly corrupted ) pieces of the form @xmath139 , for every @xmath36 in the part and for every @xmath126 such that @xmath36 belongs to a level @xmath126 fragment .",
    "essentially , this is done by verifying at the root @xmath150 of a part @xmath142 , that ( 1 ) the information regarding fragments arrives at it in a cyclic order ( the order in which pieces of information are supposed to be stored in correct instances ) , ( 2 ) the levels of pieces arriving at @xmath150 comply with the levels of fragments to which @xmath150 belongs to , as indicated by @xmath150 s data - structure .",
    "next , we verify that the time in which each node obtains all the pieces it needs is short .",
    "this is guaranteed by the correct train operation , as long as the diameter of parts is @xmath0 , and the number of pieces stored permanently at the nodes of the part is @xmath0 .",
    "verifying these two properties is accomplished using a 1-proof labelling scheme of size @xmath0 , similarly to the schemes described in examples 2 and 3 ( @xmath75 and @xmath98 , mentioned in section [ sub : examples ] ) .    finally , if up to this point , no node raised an alarm , then for each node @xmath36 , the ( possibly corrupted ) pieces of information corresponding to @xmath36 s fragments reach @xmath36 in the prescribed time bounds .",
    "now , by the train synchronization process , each node can compare its pieces of information with the ones of its neighbours .",
    "hence , using similar arguments as was used in the @xmath19-memory bits verification scheme of @xcite , nodes can now detect the case that either one of the pieces of information is corrupted or that @xmath18 is not an mst .",
    "in this section , we describe an mst construction algorithm , called @xmath123 , that is both linear in its running time and memory optimal , that is , it runs in @xmath7 time and has @xmath0 memory size .",
    "we note that this algorithm is not self - stabilizing and its correct operation assumes a synchronous environment .",
    "the algorithm will be useful later for two purposes .",
    "the first is for distributively assigning the labels of the mst proof labelling scheme , as described in the next section .",
    "the second purpose , is to be used as a module in the self - stabilizing mst construction algorithm .    as mentioned , the algorithm of gallager , humblet , and spira ( ghs ) @xcite constructs an mst in @xmath29 time .",
    "this has been improved by awerbuch to linear time , using a somewhat involved algorithm .",
    "both algorithms are also efficient in terms of the number of messages they send .",
    "the mst construction algorithm described in this section is , basically , a simplification of the ghs algorithm .",
    "there are two reasons for why we can simplify that algorithm , and even get a better time complexity .",
    "the first reason is that our algorithm is synchronous , whereas ghs ( as well as the algorithm by awerbuch ) is designed for asynchronous environments .",
    "our second aid is the fact that we do not care about saving messages ( anyhow , we use a shared memory model ) , while the above mentioned algorithms strive to have an optimal message complexity . before describing our mst construction algorithm , we recall the main features of the ghs algorithm .      for full details of ghs",
    ", please refer to @xcite .",
    "ghs uses connected subgraphs of the final mst , called _",
    "fragments_. each node in a fragment , except for the fragment s root , has a pointer to its parent in the fragment .",
    "when the algorithm starts , every node is the root of the singleton fragment including only itself .",
    "each fragment is associated with its _ level _ ( zero for a singleton fragment ) and the identity of its root ( this is a slight difference from the description in @xcite , where a fragment is said to be rooted at an edge ) .",
    "each fragment @xmath111 searches for its _ minimum outgoing edge _ @xmath151 . using the selected edges ,",
    "fragments are merged to produce larger fragments of larger levels .",
    "that is , two or more fragments of some level @xmath126 , possibly together with some fragments of levels lower than @xmath126 , are merged to create a fragment of level @xmath152 .",
    "eventually , there remains only one fragment spanning the graph which is an mst .    in more details , each fragment sends an offer ( over @xmath153 to merge with the other fragment @xmath115 , to which the other endpoint @xmath44 belongs .",
    "if @xmath115 is of a higher level , then @xmath111 is connected to @xmath115 .",
    "that is , the edges in @xmath111 are reoriented so that @xmath111 is now rooted in the endpoint @xmath36 of @xmath154 , which becomes a child of the other endpoint  @xmath44 .",
    "if the level of @xmath115 is lower , then @xmath111 waits until the level of @xmath115 grows ( see below , the description of `` test '' messages ) .",
    "the interesting case is when @xmath111 and @xmath115 are of the same level @xmath155 . if @xmath156 , then @xmath111 and @xmath115 merge to become one fragment , rooted at , say , the highest @xmath138 node between @xmath44 and @xmath36 .",
    "the level of the merged fragment is set to @xmath157 .    the remaining case , that ( w.l.o.g . )",
    "@xmath158 does not need a special treatment .",
    "when @xmath111 sends @xmath115 an offer to merge , @xmath115 may have sent such an offer to some @xmath159 over @xmath160 .",
    "similarly , @xmath159 may have sent an offer to some @xmath161 ( over @xmath162 , etc .",
    "no cycle can be created in this chain of offers ( because of the chain of decreasing weights @xmath163 . hence , unless the chain ends with some fragment of a higher level ( recall that treating the case that a fragment s minimum edge leads to a higher level fragment was already discussed ) , some two fragments in the above chain merge , increasing their level by one .",
    "this case ( for the fragments of the chain , excluding the two merging fragments ) now reduces to the case ( discussed previously ) that a fragment @xmath111 makes an offer to a fragment of a higher level .",
    "the above describes the behavior of fragments . to implement it by nodes ,",
    "recall that every fragment always has a root .",
    "the root conducts wave&echo over the fragment to ask nodes to find their own _ candidate _",
    "edges for the minimum outgoing edge .",
    "on receiving the wave ( called `` find '' ) , each node @xmath36 selects its minimum edge @xmath164 that does not belong yet to the fragment , and has not been `` tested '' yet ( initially , no edge was `` tested '' ) .",
    "node  @xmath36 sends a `` test '' message to @xmath44 , to find out whether @xmath44 belongs to @xmath36 s fragment .",
    "the `` test '' includes the @xmath138 of @xmath36 s fragment s root @xmath82 and its level @xmath155 . if the level of @xmath44 s fragment is at least @xmath155 then @xmath44 answers . in particular ,",
    "if @xmath44 s level is @xmath155 and @xmath44 s fragment root is @xmath82 then @xmath44 sends a `` reject '' to @xmath36 , causing @xmath36 to conclude that @xmath164 is not outgoing and can not be a candidate .",
    "( node @xmath44 does not answer , until its level reaches @xmath155 , thus , possibly , causing @xmath36 s fragment to wait . ) in the converging wave ( called `` found '' ) of the above `` find '' broadcast , each node @xmath36 passes to its parent only the candidate edge with the minimum weight ( among its own candidate and the candidates it received from its children ) .",
    "node @xmath36 also remembers a pointer to whoever sent it the above candidate .",
    "these pointers form a route from @xmath165 root to the endpoint of @xmath154 .",
    "the root then sends a message `` change - root '' , instructing all the nodes on this route ( including itself ) to reverse their parent pointers .",
    "hence , @xmath111 becomes rooted at the endpoint of @xmath154 , who now can send an offer to `` connect '' over @xmath154 .",
    "the algorithm we now describe is synchronous and assumes that all the nodes wake up simultaneously at round  @xmath166 .",
    "however , to keep it easy for readers who are familiar with ghs , we tried to keep it as similar to ghs as possible .",
    "initially , each node is a root of a fragment of _ level _ @xmath166 that contains only itself . during the execution of @xmath123 ,",
    "a node who is not a root , keeps a pointer to its parent .",
    "the collection of these pointers ( together with all the nodes ) defines a forest at all times .",
    "each node also keeps an _ estimate _ of the @xmath138 and the level of the root of its fragment . as we shall see later ,",
    "the @xmath138 estimate is not always accurate .",
    "the level estimate is a lower bound on the actual level .",
    "we use the levels for convenience of comparing the algorithm to that of ghs ( and for the convenience of the proof ) .",
    "the levels actually can be computed from the round number , or from the counting procedure defined below .",
    "more specifically , the algorithm is performed in synchronous _",
    "phases_. phase @xmath167 starts at round @xmath168 .",
    "each root @xmath169 of a fragment @xmath111 ( that is , a node whose parent pointer is null ) starts the phase by setting its level to @xmath167 and then counting the number of nodes in its fragment .",
    "the counting process , called @xmath170 , is defined later , but for now it suffices to say that it consumes _ precisely _ @xmath171 rounds .",
    "if the diameter of the fragment is small , then some waiting time is added to keep the precise timing . on the other hand ,",
    "if the number of nodes in the fragment is too large , @xmath170 may terminate before all the nodes in the fragment are counted .",
    "specifically , we guarantee that if the counting process succeeds to count all nodes in the fragment @xmath111 then the precise number of these nodes is known to the root @xmath169 at the end of the counting procedure . on the other hand ,",
    "if the counting process does not count all nodes , then the number of nodes in the fragment is at least @xmath172 , and at the end of the @xmath170 process , the root @xmath169 learns this fact . moreover , in such a case , as a consequence , @xmath169 changes its level to @xmath173 .",
    "[ def : fragments ] a root @xmath169 is _ active _ in phase @xmath167 if and only if @xmath174 , where @xmath175 denotes the number of nodes in @xmath111 . note that if @xmath169 is active then its level is @xmath167 .",
    "in particular , all the roots are _ active _ in phase ( and level )  @xmath166 .",
    "a fragment is _ active _ when its root is active .",
    "[ com : fragments ] when constructing the marker algorithm in later sections , we use the fragments constructed by algorithm @xmath123 . more specifically",
    ", we refer only to the active fragments .",
    "as is easy to observe below in the current section , an active fragment is a specific set of nodes that does not change .",
    "this is because when the fragment merges with others ( or when others join it ) , it is no longer the same fragment . in particular , when the new set of nodes will be active , it will be in a higher phase .",
    "[ [ procedure - textttfind_min_out_edge ] ] procedure @xmath176 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    consider the root @xmath169 of fragment @xmath111 , who is active in phase  @xmath167 . at round @xmath177",
    ", each such root @xmath169 instructs the nodes in @xmath111 to search for the minimum outgoing edge of @xmath111 .",
    "this procedure , called @xmath176 , could have been combined with the counting , but we describe it as a separate stage for the sake of simplicity .",
    "the method is the same as that of ghs algorithm , except that we achieve an exact timing obtained by not saving in messages .",
    "the search is performed over exactly the same set of nodes which has just been counted .",
    "this is implemented by a wave operation initiated by @xmath169 , carrying @xmath169 s @xmath138 and level . at precisely round @xmath178 , each node @xmath36 who has received the wave , finds the minimum outgoing edge emanating from it .",
    "that is , @xmath36 looks at each of its neighbours @xmath44 to see whether @xmath44 belongs to a different fragment of some other root @xmath179 .",
    "we now describe how @xmath36 identifies this .",
    "let us note here two differences from ghs .",
    "first , node @xmath36 tests all of its emanating edges at the same time , rather than testing them one by one ( as is done in ghs ) . moreover",
    ", it does not reject any edge , and will test all its edges in the next searches too .",
    "intuitively , the above mentioned one by one process was used in ghs in order to save messages .",
    "we do not try to save messages , and the simultaneous testing allows us to keep an exact timing on which we rely heavily .",
    "second , in ghs , node @xmath44 s estimate of its level may be lower than that of node @xmath36 . in ghs , @xmath36 then needs to wait for @xmath44 to reach @xmath36 s level , before @xmath36 knows whether edge @xmath164 is outgoing .",
    "the main reason this action is useful in ghs is to save on message complexity . here",
    ", again , we do not intend to save messages .",
    "recall that the root of @xmath36 s fragment @xmath111 is active at phase @xmath167 , hence , @xmath180 .",
    "( we shall show that no additional nodes joined @xmath111 after the counting . ) hence , at round @xmath178 , _ all the nodes _ in @xmath111 have already received the wave , and set their @xmath138 estimates to @xmath181 .",
    "the big gain from that , is that at round @xmath178 , the @xmath138s of the roots of @xmath44 and @xmath36 are different if and only if the edge @xmath164 is outgoing at @xmath36 . the minimum outgoing edge in the fragment of @xmath169 is then computed during the convergecast , using the standard wave&echo technique .",
    "thus , procedure @xmath176 ( composed of the aforementioned wave&echo ) lasts at most @xmath182 round units , hence ( having been started at round @xmath183 ) , it is completed by round @xmath184 .",
    "[ [ merging - and - reorienting - edges ] ] merging and reorienting edges : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath185 be the chosen minimum outgoing edge from the fragment @xmath111 , such that @xmath186 .",
    "later , we refer to it as the _ candidate _ edge . at round",
    "@xmath187 , an active root @xmath169 of @xmath111 starts the process of re - orienting the edges in @xmath111 towards @xmath80 .",
    "( for a more thorough description of the root transfer refer to @xcite . )",
    "this takes at most @xmath188 rounds .",
    "node @xmath80 then conducts a handshake with @xmath102 , referred to as the _ pivot _ of @xmath111 .",
    "this takes a constant time , but , to keep the total numbers simple , we pad this time to @xmath189 .",
    "one case is that @xmath80 is , at that time exactly , a pivot of the fragment of @xmath102 , and also @xmath190 . in this case",
    ", node @xmath102 will become the child of @xmath80 . in every other case",
    ", @xmath80 hooks upon the other endpoint @xmath102 ( sets its parent pointer to point at @xmath102 ) .",
    "the hooking is performed exactly at round @xmath191 , ending phase @xmath167 .",
    "since the next phase starts at round @xmath192 there is no overlap between phases .",
    "[ [ procedure - textttcount_size ] ] procedure @xmath170 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    to complete the description of a phase , it is left to describe the counting process , namely , procedure @xmath170 .",
    "to count , a root starts a wave&echo , attaching a _ time - to - live _",
    "=  @xmath193 counter to its broadcast message .",
    "a child @xmath194 of a node @xmath195 accepts the wave only if the time - to - live is above zero .",
    "child @xmath194 then copies the wave broadcast message , decrementing the time - to - live ( by 1 ) . if , after decrementing , the value of time - to - live is zero , then @xmath194 is a leaf who needs to start the echo .",
    "the number of the nodes ( who copied the broadcast message ) is now counted during the echo in the standard way .",
    "finally , if the count covers the whole graph , this can be easily detected at the time of the echo .",
    "the algorithm then terminates .    to sum up , phase @xmath167 of the mst construction algorithm",
    "is composed of the following components .",
    "[ [ section ] ] +    starts at round @xmath168  ;    root @xmath169 of each fragment @xmath111 initiates procedure @xmath170 .    at the end of the procedure",
    ", we have : + @xmath174   iff   ( 1 ) @xmath169 is _ active _ and ( 2 ) all nodes in @xmath111 have their @xmath138 estimates set to @xmath181  ;    at round @xmath177 , each active root @xmath169 initiates procedure @xmath176  ;    at round @xmath187 , merge fragments and re - orient edges in the newly created fragments .",
    "the proof that the collection of parent pointers forms a forest ( or a tree ) at all times is the same as in ghs .",
    "let us now analyze the round complexity .",
    "observe that each phase @xmath167 takes @xmath196 time .",
    "hence , the linear time complexity of the algorithm follows from the lemma below .",
    "[ lem : disappear ] the size of a fragment @xmath111 in phase @xmath167 ( and in level @xmath167 ) is at least @xmath197 .",
    "moreover , @xmath198 if and only if @xmath169 is active by round @xmath177 .",
    "let us first prove the second part of the lemma . before deciding whether to be active , a root @xmath169 of level  @xmath167 counts the number of nodes in its fragment , by employing procedure @xmath170 . if the count amounts to @xmath172 or more , then the level of @xmath169 is set to @xmath173",
    "otherwise , we have @xmath174 and the root of @xmath111 becomes active . since procedure @xmath170 is terminated by round @xmath177 , the second part of the lemma follows . to prove the first part of the lemma , we need to show that the size of a level @xmath167 fragment is at least @xmath189 .",
    "we prove this by induction on @xmath167 .",
    "intuitively , the induction says that each fragment at the beginning of phase @xmath199 , is of size at least @xmath200 . during phase @xmath199 , by the second part of the lemma , at time @xmath201 , all the non - active fragments are already of size at least @xmath189 and are also of level @xmath167 ( as a result of the count ) . as for active fragments",
    ", each such fragment is combined to at least one other fragment , so the resulting size is at least @xmath202 .    in more details ,",
    "note that the claim holds for phase @xmath203 . for a larger phase @xmath167 ,",
    "assume that the lemma holds for phases up to @xmath199 including .",
    "consider a root @xmath169 of a fragment @xmath111 of level @xmath167 .",
    "it was a root also at level @xmath199 .",
    "first , assume that at phase @xmath199 , some other root @xmath204 hooked upon @xmath169 s tree .",
    "to do so , @xmath204 had to be active at phase @xmath199 . by the induction hypothesis ( the first part of the lemma ) , the size of fragment @xmath113 , as well as the size of fragment of @xmath111 at that point in time , was at least @xmath200 .",
    "the claim , in this case , follows .",
    "now , assume that no other fragment hooked upon fragment @xmath111 in phase @xmath199 .",
    "note that @xmath111 at level @xmath199 does not span the graph ( otherwise , no root would reach level @xmath167 , by the 2nd part of the inductive hypothesis , and since the counting process on trees is a known art and is known to be correct ) .",
    "hence , it has a minimum outgoing edge @xmath205 , where @xmath186 and @xmath102 belongs to some other fragment @xmath206 .",
    "we claim that the search process @xmath176 does find that edge @xmath48 .",
    "recall that in the fragment of an active root , the counting reaches all the nodes in the fragment .",
    "hence , each of them knows the @xmath138 of their root @xmath169 at the time the search in their fragment starts .",
    "moreover , since a hooking is performed only at times of the form @xmath207 , no new nodes ( or fragments ) join until the last time step of the phase ( which is after the search , because of what we established about the size of the fragment ) .",
    "we claim that either ( a ) edge @xmath205 was not the minimum outgoing edge of @xmath102 s fragment @xmath206 , or , alternatively , ( b ) the root @xmath208 of @xmath102 s fragment @xmath206 had level @xmath167 at that time , or ( c ) @xmath209 .",
    "assume the contrary . by the inductive hypothesis ,",
    "node @xmath208 is at least at level @xmath199 .",
    "since we assumed that ( b ) does not hold , @xmath208 is exactly at level @xmath199 .",
    "this means ( by the correctness of the counting ) that @xmath208 is active at phase @xmath199 .",
    "similarly , this also means that the size of @xmath206 is less than @xmath197 .",
    "hence , and by the induction hypothesis , the counting , the searching , the root transfer , and the handshake end in @xmath102 s fragment at the same time they end in @xmath80 s fragment .",
    "( these processes use known art , and we shall not prove them here . )",
    "then @xmath102 hooks upon @xmath80 , contrary to our assumption .",
    "we have just established that the conditions for @xmath80 to hook upon @xmath102 hold .",
    "hence , @xmath80 hooks upon @xmath102 .",
    "similarly to the previous case , the size of @xmath80 s fragment , as well as the size of @xmath102 s fragments at that point in time is at least @xmath200 .",
    "thus , the size of the combined fragment is at least @xmath197 .",
    "this concludes the proof of the first part of the lemma .",
    "[ cor : time - linear ] the synchronous mst construction algorithm computes an mst in time @xmath7 .",
    "[ [ implementing - the - algorithm - in - the - shared - memory - model - with - olog - n - memory ] ] implementing the algorithm in the shared memory model with @xmath0 memory : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    each node @xmath36 keeps its fragment level and root @xmath138 .",
    "node @xmath36 also remembers whether @xmath36 is in the stage of counting the number of nodes , or searching for the minimum outgoing edge .",
    "it also needs to remember whether it is in the wave stage , or has already sent the echo .",
    "node @xmath36 needs to remember the candidate ( for being @xmath153 edge that @xmath36 computed in the echo ( `` found '' ) stage of the convergecast .",
    "if this candidate was reported by a child , then @xmath36 also remembers a pointer to that child . clearly , all the above variables combined need @xmath0 bits of memory .    at a first glimpse",
    "it may look as if a node must also remember the list of pointers to its children .",
    "the list is used for ( 1 ) sending the wave ( e.g. , the `` find '' message of the search , using ghs terms ) to all the children , and ( 2 ) knowing when all the children answered the echo ( e.g. , the `` found '' of the search ) .",
    "note that a node does not need to store this list itself .",
    "node @xmath36 can look at each neighbour @xmath44 to see whether the neighbour is @xmath36 s child .",
    "( for that purpose , if @xmath44 is a child of @xmath36 , then @xmath44 stores @xmath36 s @xmath138 as @xmath44 s @xmath210 . )",
    "clearly , this can be implemented using @xmath0 bits per node .    to implement ( 1 ) , node @xmath36 posts its wave broadcast message ( e.g. , the `` find '' ) so that every neighbour can read it .",
    "however , only its children actually do . to allow the implementation of ( 2 ) , a precaution is taken before the above posting .",
    "node @xmath36 first posts a request for its children to reset their @xmath211 variables , and performs the posting of `` find '' only when it sees that @xmath211 has been reset for every neighbour @xmath80 whose parent pointer points at @xmath36 .",
    "to implement ( 2 ) , node @xmath36 further reads its neighbours repeatedly .",
    "it knows all its children echoed the wave in an iteration when it has just finished rereading all its neighbours , and every node @xmath44 pointing at @xmath36 ( as its parent ) , also sets its @xmath211 variable to some candidate edge ( or to some default value if it has no candidate edge ) .",
    "[ obs : spce - sync ] the space required by the linear time synchronous algorithm is @xmath0 bits per node .",
    "the theorem below follows from observation  [ obs : spce - sync ] and corollary [ cor : time - linear ] .",
    "[ thm : alg ] the synchronous algorithm @xmath123 computes an mst in time @xmath7 and memory size @xmath0 .",
    "we are now ready to describe our proof labeling scheme @xmath212 for mst .",
    "the goal of this section is to construct some part of the marker @xmath64 , and the corresponding part of the verifier @xmath213 , which are relatively easy to construct .",
    "the techniques used in this section bear similarity to the techniques presented in @xcite .",
    "hence , we only expose the main ideas behind this part of the proof labeling scheme , leaving out some of the technicalities .",
    "nevertheless , since the notion of proof labeling schemes can sometimes be confusing , this section may help the reader to get accustomed to the notion and the difficulties that may arise .    as a warm up",
    ", we first note that using the 1-proof labeling scheme described in example @xmath75 , we may assume that @xmath214 is a spanning tree of @xmath11 rooted at some node @xmath82 , and that each node knows which of its neighbours in @xmath11 are its children in @xmath18 and which is its parent .",
    "moreover , using the 1-proof labeling scheme described in example @xmath89 , we may also assume that each node knows @xmath14 .",
    "the 1-proof labeling schemes described in examples @xmath75 and @xmath89 use @xmath0 memory size and can be constructed using @xmath7 time .",
    "hence , using them does not violate the desired complexity constrains of our scheme .",
    "thus , from now on , let us fix a spanning tree @xmath108 of a graph @xmath109 , rooted at some node @xmath110 .",
    "the goal of the rest of the verification scheme is to verify that @xmath18 is in fact , minimal . before we continue",
    ", we need a few definitions .",
    "[ def : hierarchy ] a _ hierarchy _",
    "@xmath119 for @xmath18 is a collection of fragments of @xmath18 satisfying the following two properties .    1",
    ".   @xmath215 and , for every @xmath216 , there is an @xmath217 such such @xmath218 and @xmath219 .",
    "2 .   for any two fragments @xmath111 and @xmath115 in @xmath119 , if @xmath116 then either @xmath117 or @xmath118 .",
    "( that is , the collection of fragments is a laminar family . )",
    "please recall ( definition [ com : fragments ] and comment [ com : fragments ] ) that when we construct a hierarchy according to definition [ def : hierarchy ] , the fragments referred to are the active fragments constructed in @xmath123 .",
    "the _ root _ of a fragment @xmath111 is the node in @xmath111 closest to the root of @xmath18 . for a fragment @xmath220 , let @xmath221 denote the collection of fragments in @xmath119 which are _ strictly _ contained in @xmath111 .",
    "observe that a hierarchy @xmath119 can be viewed as a rooted tree , whose root is the fragment @xmath18 , and whose leaves are the singleton fragments in @xmath119 .",
    "a child of a non - singleton fragment @xmath122 is a fragment @xmath222 such that no other fragment @xmath223 satisfies @xmath224 .",
    "note that the rooted tree induced by a hierarchy is unique ( if the children are unordered ) . to avoid confusion with tree @xmath18",
    ", we use the name _ hierarchy - tree _ ( or , sometimes even just _ hierarchy _ ) for the above mentioned tree induced by a hierarchy .",
    "we associate a _ level _",
    ", denoted @xmath225 , with each fragment @xmath122 .",
    "it is defined as the height of the node corresponding to @xmath111 in the hierarchy - tree induced by @xmath119 , i.e. , the maximal number of fragments on a simple path in @xmath119 connecting @xmath111 to a singleton fragment .",
    "in particular , the level of a singleton fragment is 0 .",
    "the level of the fragment @xmath18 is called the _ height _ of the hierarchy , and is denoted by @xmath226 .",
    "figure [ fig : hierarchytree1 ] depicts a hierarchy @xmath119 of a tree @xmath18 .     of a tree @xmath18 .",
    "the root node of @xmath119 represents @xmath18 ( where non - tree edges are omitted ) .",
    "each fragment that is not a leaf fragment is a parent , in the hierarchy , of the fragments that were merged to form it .",
    "the broken arrow from each fragment is the outgoing edge of the fragment that is used to form a higher level ( parent ) fragment . ]    given a hierarchy @xmath119 for a spanning tree @xmath18 , a function @xmath227 is called a _ candidate function _ of @xmath228 if it satisfies @xmath229 for every @xmath220 .",
    "( less formally , @xmath111 is precisely the union of the candidate edges @xmath230 of all fragments @xmath115 of @xmath119 strictly contained in @xmath111 ) .",
    "the proof of the following lemma is similar , e.g. , to the proof of @xcite .",
    "[ lem : construction ] let @xmath18 be a spanning tree of a graph @xmath11 .",
    "if there exists a candidate function @xmath231 for a hierarchy @xmath119 for  @xmath18 , such that for every @xmath122 , the candidate edge @xmath232 is a minimum outgoing edge from @xmath111 , then @xmath18 is an mst of @xmath11 .",
    "we prove the claim that each fragment @xmath220 is a subtree of an mst of @xmath11 , by induction on the level @xmath225 of fragment @xmath111 .",
    "note that the claim obviously holds for any fragment @xmath111 with @xmath233 since @xmath111 is a singleton fragment .",
    "now consider a fragment @xmath111 with @xmath234 under the inductive assumption that the claim holds for every fragment @xmath115 with @xmath235 .",
    "let @xmath236 be the child fragments of @xmath111 in @xmath119 .",
    "since for each @xmath237 $ ] , fragment @xmath238 satisfies @xmath239 , the induction hypothesis implies that @xmath238 is a subtree of the mst .",
    "it also follows from the facts that @xmath229 and @xmath240 for each @xmath237 $ ] that the fragment @xmath111 is obtained by connecting @xmath236 with their minimum outgoing edges . in the case",
    "that a fragment @xmath115 is a fragment of an mst ( as is the case here for @xmath236 , by the induction hypothesis ) , it is known that the union of @xmath241 with the minimum outgoing edge of @xmath115 is a fragment of the mst ( the `` safe edge '' theorem ) .",
    "( see e.g. , @xcite . )",
    "thus , fragment @xmath111 , which is obtained by connecting fragments @xmath242 with their minimum outgoing edges , is a subgraph of an mst .",
    "informally , suppose that we are given distributed structures that are claimed to be a tree @xmath18 , a `` legal '' hierarchy  @xmath119 for the tree , and a `` legal '' candidate function for the hierarchy .",
    "the goal obtained in the current section is to verify the following properties of these structures .",
    "first , verify that this indeed is a hierarchy for @xmath18 of height @xmath243 and a candidate function @xmath231 for @xmath119 .",
    "moreover , verify that each node @xmath36 `` knows '' to which levels of fragments @xmath36 belongs and which of its neighbours in @xmath18 share the same given fragment .",
    "( note that this section does not guarantee that knowledge for neighbours in @xmath11 who are not neighbours in @xmath18 . ) in addition , each node is verified to `` know '' whether it is adjacent to a candidate edge of any of the fragments it belongs to .",
    "put more formally , this section establishes the following lemma .",
    "[ lem : simple - proof ] there exists a 1-proof labeling scheme with memory size @xmath0 and construction time @xmath7 that verifies the following :    @xmath214 is a spanning tree of @xmath11 rooted at some node @xmath82 , and each node knowns @xmath14 .",
    "the cartesian product of the data - structures indeed implies a hierarchy @xmath119 for @xmath18 of height @xmath244 and a candidate function @xmath231 for @xmath119 .",
    "furthermore , the data - structure at each node @xmath36 allows it to know ,    whether @xmath36 belongs to a fragment @xmath130 of level @xmath126 in @xmath119 for each @xmath245 , and if so :    whether @xmath36 is the root of @xmath130 .    whether @xmath36 is an endpoint of the ( unique ) candidate edge of @xmath130 , and if so , which of the edges adjacent to @xmath36 is the candidate edge .",
    "given the data - structure of a node @xmath44 which is a neighbour of @xmath36 in @xmath11 , i.e. , @xmath112 , node @xmath36 can find out whether they are neighbours in @xmath18 as well , i.e. , whether @xmath246 , and if so , for each @xmath247 , whether @xmath44 belongs to @xmath130 .",
    "on a correct instance , i.e. , when @xmath18 is indeed an mst , the marker @xmath64 first constructs a particular hierarchy @xmath147 over @xmath18 and a candidate function @xmath248 for that hierarchy .",
    "hierarchy @xmath147 and candidate function @xmath248 are designed so that indeed each candidate of a fragment is a minimum outgoing edge from that fragment .",
    "the marker then encodes hierarchy @xmath147 and candidate function @xmath248 in one designated part of the labels using @xmath0 bits per node .",
    "note , however , that these bits of information may be corrupted by the adversary . we will therefore need to employ another procedure that verifies that indeed a hierarchy @xmath119 and a candidate function @xmath231 are represented by the cartesian product of the encodings of all nodes . by lemma [ lem :",
    "construction ] , it is not necessary that the verifier checks that @xmath119 is , in fact , the particular hierarchy @xmath147 constructed by the marker , or that the candidate function @xmath231 is @xmath248 .",
    "however , as is clear from the same lemma , we do need to show that @xmath119 and candidate function @xmath231 satisfy that indeed each candidate of a fragment is a minimum outgoing edge from that fragment .",
    "this task is the main technical difficulty of the paper , and is left for the following sections .",
    "the hierarchy @xmath147 and candidate function @xmath248 built by the marker algorithm are based on @xmath123 , the new mst construction algorithm described in section  [ sec : mst - construction ] .",
    "since we assume that the mst is unique , algorithm @xmath123 will in fact construct the given mst .",
    "( recall that we describe here the labels assigned by the marker to a correct instance , where the given subgraph @xmath18 is indeed an mst . )",
    "the hierarchy and candidate function we define for @xmath18 follow the merging of _ active _ fragments in algorithm @xmath123 . more precisely , the nodes in @xmath147 are the active fragments defined during the execution of @xmath123 .",
    "recall from section [ sec : mst - construction ] , that an active fragment @xmath111 joins some fragment @xmath12 of @xmath18 , through its minimal outgoing edge @xmath48 .",
    "( it is possible that at the time @xmath111 joins @xmath12 , @xmath12 itself was an active fragment that joined @xmath111 through its own minimal outgoing edge that is also @xmath48 . )",
    "note that with time , some other fragments join the resulted connected component , until , at some point , the resulted connected component becomes an active fragment @xmath115 . in the hierarchy tree @xmath147 , fragment @xmath111",
    "is defined as the child of @xmath115 , and the candidate edge of @xmath111 is @xmath48 , i.e. , @xmath249 .",
    "as proved in lemma  [ lem : disappear ] , after performing the algorithm for level @xmath167 , the size of every fragment is at least @xmath189 .",
    "thus , in particular , the height of the hierarchy @xmath119 is at most @xmath250 .",
    "the candidate function @xmath248 chosen by the marker for @xmath147 is defined by the minimum outgoing edges selected by the algorithm , i.e. , for each @xmath251 , the candidate edge @xmath232 is the selected edge of @xmath111 .",
    "thus , under @xmath248 , each candidate of a fragment is , actually , a minimum outgoing edge .",
    "[ app : hierarchy ]    [ [ representing - a - hierarchy ] ] representing a hierarchy : + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath252 . given a hierarchy of fragments @xmath119 of height @xmath226 over the rooted tree @xmath79",
    ", we now describe how we represent it in a distributed manner .",
    "each node @xmath36 keeps a string named @xmath253 of length @xmath129 , where each entry in that string is either `` 1 '' , `` 0 '' , or `` * '' . to be consistent with the levels , we enumerate the entries of each string from left to right , starting at position 0 , and ending at position @xmath226 .",
    "fix @xmath254 $ ] .",
    "informally , the @xmath167th entry of @xmath253 , namely , @xmath255 , is interpreted as follows .",
    "@xmath256 indicates that @xmath36 is the root of the level @xmath167 fragment it belongs to .",
    "@xmath257 indicates that @xmath36 is not the root of the level @xmath167 fragment it belongs to .",
    "@xmath258 indicates that there is no level @xmath167 fragment that @xmath36 belongs to .",
    "see table [ tab : table1 ] for an example of @xmath259 strings of nodes corresponding to figure [ fig : hierarchytree1 ] .     2 & 3 & 4 + a & 1 & 0 & 0 & 0 & 0 & & a & up & none & none & none & none + b & 1 & 1 & 0 & 0 & 0 & & b & down & up & none & none & none + c & 1 & 0 & 0 & 0 & 0 & & c & up & none & none & none & none + d & 1 & * & 0 & 0 & 0 & & d & up & * & none & none & none + e & 1 & * & 0 & 0 & 0 & & e & up & * & none & none & none + f & 1 & 0 & 0 & 0 & 0 & & f & up & down & none & none & none + g & 1 & 1 & 1 & 1 & 0 & & g & down & none & down & up & none + h & 1 & * & 1 & 0 & 0 & & h & down & * & up & none & none + i & 1 & * & 0 & 0 & 0 & & i & up & * &",
    "none & none & none + j & 1 & 0 & 0 & 0 & 0 & & j & up & none & none & none & none + k & 1 & 1 & 1 & 0 & 0 & & k & down & down & up & none & none + l & 1 & 1 & 1 & 1 & 1 & & l & down & down & down & down & none + m & 1 & 1 & 0 & 0 & 0 & & m & down & up & none & none & none + n & 1 & 0 & 0 & 0 & 0 & & n & up & none & none & none & none + o & 1 & 0 & 0 & 0 & 0 & & o & up & none & none & none & none + p & 1 & 1 & 0 & 0 & 0 & & p & down & up & none & none & none + q & 1 & 0 & 0 & 0 & 0 & & q & up & none & none & none & none + r & 1 & 0 & 0 & 0 & 0 & & r & up & none & none & none & none +     1 & 2 & 3 & 4 + a & 1 & 0 & 0 & 0 & 0 & & a & 1 & 0 & 0 & 0 & 0 + b & 0 & 1 & 0 & 0 & 0 & & b & 1 & 1 & 0 & 0 & 0 + c & 0 & 0 & 0 & 0 & 0 & & c & 1 & 0 & 0 & 0 & 0 + d & 1 & 0 & 0 & 0 & 0 & & d & 1 & 0 & 0 & 0 & 0 + e & 0 & 0 & 0 & 0 & 0 & & e & 1 & 0 & 0 & 0 & 0 + f & 1 & 0 & 0 & 0 & 0 & & f & 1 & 1 & 0 & 0 & 0 + g & 0 & 0 & 0 & 1 & 0 & & g & 1 & 1 & 1 & 1 & 0 + h & 0 & 0 & 1 & 0 & 0 & & h & 1 & 0 & 1 & 0 & 0 + i & 0 & 0 & 0 & 0 & 0 & & i & 1 & 0 & 0 & 0 & 0 + j & 1 & 0 & 0 & 0 & 0 & & j & 1 & 0 & 0 & 0 & 0 + k & 0 & 0 & 1 & 0 & 0 & & k & 1 & 1 & 1 & 0 & 0 + l & 0 & 0 & 0 & 0 & 0 & & l & 1 & 1 & 1 & 1 & 0 + m & 0 & 1 & 0 & 0 & 0 & & m & 1 & 1 & 0 & 0 & 0 + n & 0 & 0 & 0 & 0 & 0 & & n & 1 & 0 & 0 & 0 & 0 + o & 1 & 0 & 0 & 0 & 0 & & o & 1 & 0 & 0 & 0 & 0 + p & 0 & 1 & 0 & 0 & 0 & & p & 1 & 1 & 0 & 0 & 0 + q & 1 & 0 & 0 & 0 & 0 & & q & 1 & 0 & 0 & 0 & 0 + r & 1 & 0 & 0 & 0 & 0 & & r & 1 & 0 & 0 & 0 & 0 +    [ [ verifying - a - hierarchy ] ] verifying a hierarchy : + + + + + + + + + + + + + + + + + + + + + +    observe , the @xmath259 strings assigned for a correct instance satisfy the following . + * the @xmath259 strings ( rs ) conditions : *    * ( rs0 ) * the prefix of the @xmath259 string at every node is in [ 1,*]@xmath260 and its suffix is in [ 0,*]@xmath260 , + ( * because each node is a root of a level 0 fragment and continues being a root in its fragment until some level when it stops ( if it does stop ) ; when the node stops being a root , it never becomes a root again * )    * ( rs1 ) * the length of each @xmath259 string is @xmath129 , + ( * because there can not be more than @xmath129 levels * )    * ( rs2 ) * the @xmath259 string of the root @xmath82 of @xmath18 contains only `` 1 ' 's and `` * ' 's , and its @xmath226th entry is `` 1 '' , + ( * because a zero in the @xmath167th position would have meant that @xmath82 is not the root of its fragment of level @xmath167 ; the second part follows from the fact that the whole tree is a fragment of level @xmath226 and @xmath82 is its root * )    * ( rs3 ) * the first entry ( at position 0 ) of every @xmath259 string is `` 1 '' , + ( * because every node @xmath36 is the root of a singleton fragment of level 0 containing only node @xmath36 * ) ,    * ( rs4 ) * the @xmath226th entry of every non - root node is `` 0 '' , + ( * because only @xmath82 is the root of a fragment of level @xmath226 , since that fragment is the whole tree * )    * ( rs5 ) * if the @xmath126th entry of @xmath253 is `` 0 '' for some node @xmath36 and @xmath254 $ ] , then the @xmath126th entry of the @xmath259 strings of @xmath36 s parent in @xmath18 is not `` * '' .",
    "+ ( * because node @xmath36 belongs to a fragment @xmath111 of level @xmath126 , but is not @xmath111 s root ; hence , @xmath36 s parent belongs to @xmath111 of level @xmath126 too * )    it is easy to see that for any assignment of @xmath259 strings @xmath261 obeying rules rs1rs5 there exists a unique hierarchy whose distributed representation is @xmath261 .",
    "hence , we say that an assignment of @xmath259 strings to the nodes of @xmath18 is _ legal _ if the strings obey the five @xmath259 strings conditions above , namely rs1rs5 . for a given legal assignment of @xmath259 strings @xmath261",
    ", we refer to its induced hierarchy as the _ @xmath259-hierarchy _ of @xmath261 .",
    "recall that at this point , we may assume that each node @xmath36 knows the value of @xmath14 , and that each node knows whether it is the root of @xmath18 .",
    "hence , verifying that a given assignment of @xmath259 strings is a legal one can be done locally , by letting each node look at its own string and the string of its parent only .",
    "[ [ identifying - tree - neighbours - in - the - same - fragment ] ] identifying tree - neighbours in the same fragment : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    obviously , for correct instances , the marker produces a legal assignment of @xmath259 strings . for a general instance , if the verifier at some node finds that the assignment of @xmath259 is not legal then it raises an alarm .",
    "thus , ( if no node raises an alarm ) , we may assume that hierarchy _",
    "@xmath259-hierarchy _ exists , and that each node knows ( by looking at its own label and the labels of its neighbours in the tree @xmath105 , for every level @xmath245 ,    1 .   whether it belongs to a fragment @xmath120 of level @xmath126 , and if so : 2 .   which of its neighbours in @xmath18 belongs to @xmath120 .",
    "having discussed the proof labeling for the hierarchy , we now describe the proof labeling scheme for the candidate function .",
    "consider now a correct instance @xmath11 and the hierarchy @xmath147 produced by the marker algorithm .",
    "recall , the candidate function @xmath248 is given by the selected outgoing edges , which are precisely the minimum outgoing edges of the corresponding fragments , as identified by the construction algorithm @xmath123 .",
    "we would like to represent this candidate function @xmath248 distributively , and to verify that this representation indeed forms a candidate function .",
    "moreover , we would make sure that each node @xmath36 be able to know , for each fragment @xmath111 containing it , whether it is an endpoint of the selected edge of @xmath111 , and if so , which of its edges is the selected edge .",
    "[ [ representing - a - candidate - function ] ] representing a candidate function : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    given a correct instance , and its corresponding legal assignment of @xmath259 strings , we augment it by adding , for each node @xmath36 , an additional string of @xmath129 entries named @xmath262 .",
    "intuitively , @xmath262 is used by the marker algorithm to mark the levels of the fragments for which @xmath36 is the endpoint of the minimum outgoing edge . moreover , in a sense , @xmath262 also is a part of the marking of the specific edge of @xmath36 that is the minimum outgoing edge in that level ( in the case that @xmath36 is indeed the endpoint ) .",
    "let us now give the specific definition of that marking .",
    "each entry in @xmath262 is one of four symbols , namely , `` up '' , `` down '' , `` none '' and `` * '' .",
    "the entries of @xmath262 are defined as follows .",
    "fix an integer @xmath125 $ ] and a node @xmath36 .",
    "if @xmath36 does not belong to a fragment of level @xmath126 in @xmath147 , then the @xmath126th entry in @xmath262 is `` * '' .",
    "consider now @xmath125 $ ] such that @xmath36 does belong to a fragment @xmath263 of level @xmath126 . if @xmath36 is not an endpoint of the candidate @xmath264 of @xmath111 , then the @xmath126th entry of @xmath262",
    "is `` none '' .",
    "otherwise , node @xmath36 is an endpoint of @xmath264 , i.e. , @xmath265 ( for some @xmath44 that is not in @xmath266 .",
    "consider two cases . if @xmath44 is @xmath36 s parent in @xmath18 then the @xmath126th entry of @xmath262",
    "is set to `` up '' . if , on the other hand , @xmath44 is a child of @xmath36 in @xmath18 , then the @xmath126th entry of @xmath262 is set to `` down '' .",
    "see table 1 for an example of @xmath267 strings of nodes corresponding to figure [ fig : hierarchytree1 ] .",
    "consider now a node @xmath36 that belongs to a level @xmath126 fragment @xmath263 . by inspecting its own label ,",
    "node @xmath36 can find out whether it is an endpoint of a candidate of @xmath111 ( recall , from the previous subsection , that it also knows whether or not it belongs to a level @xmath126 fragment ) .",
    "moreover , in this case , we would like @xmath36 to actually be able to identify in one time unit , which of its incident ( tree ) edges is the candidate .",
    "obviously , if the @xmath126th entry in @xmath262 is `` up '' , then the candidate @xmath48 is the edge leading from @xmath36 to its parent in @xmath18 .",
    "intuitively , in the case that the entry is `` down '' , we would like to store this information in @xmath36 s children to save space in @xmath36 ( since @xmath36 may be the endpoint of minimum outgoing edges for several fragments , of several levels , and may not have enough space to represent all of them ) .",
    "hence , we attach to each node  @xmath102 another string called @xmath268 , composed also of @xmath129 bits . for @xmath254 $ ]",
    ", the @xmath126th bit in @xmath268 is `` 1 '' if and only if @xmath269 is the candidate of the level @xmath126 fragment that contains @xmath195 ( if one exists ) , where @xmath195 is the parent of  @xmath102 .",
    "see table 1 for an example of @xmath270 strings of nodes corresponding to figure [ fig : hierarchytree1 ] .",
    "now , to identify  @xmath44 , node @xmath36 needs only to inspect the @xmath270 strings of its children . in either of the above cases for the @xmath262 entry ( `` up '' or `` down '' )",
    ", we call @xmath48 the _ induced candidate _ of @xmath111 .    [ [ verifying - a - candidate - function ] ] verifying a candidate function : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    given a legal assignment of @xmath259 strings , we say that assignments of @xmath267 and @xmath270 strings are _ legal _ if the following conditions hold :    * ( eps0 ) * if the @xmath126th entry of @xmath271 is `` 1 '' and @xmath44 is the parent of @xmath36 , then the @xmath126th entry of @xmath272 is `` down '' , + ( * because if @xmath36 indicates the minimum outgoing edge of @xmath44 s fragment ( of level @xmath126 ) leads from @xmath44 to @xmath36 , then @xmath36 s parent @xmath44 indicates this edge leads to one of @xmath44 s children * )    * ( eps1 ) * for each fragment @xmath111 of level @xmath273 in the @xmath259-hierarchy , there exists precisely one node @xmath274 whose @xmath126th entry in @xmath262 is either `` up '' or `` down '' , + ( * because only one node @xmath36 in each fragment @xmath111 of level @xmath126 is the endpoint of the outgoing edge of @xmath111 * )    * ( eps2 ) * for each node @xmath36 , if the @xmath126th entry in @xmath262 string is `` down '' then there exists precisely one child @xmath44 of @xmath36 such that the @xmath126th entry in @xmath275 is `` 1 '' , + ( * because the jth entry in @xmath262 being `` down '' indicates its minimum outgoing edge leads to _ one _ of @xmath36 s children ( only _ one _ , since there is only one minimum outgoing edge of the fragment @xmath111 of level @xmath126 containing  @xmath36 ) ; to remember which child , we mark this child @xmath44 by @xmath276 * )    * ( eps3 ) * for each node @xmath36 , and for each @xmath277 , if the @xmath126th entry in @xmath262 string is `` up '' then :    1 .",
    "the @xmath126th entry of @xmath36 s @xmath259-string is `` 1 '' , + ( * because node @xmath36 belongs to a different fragment @xmath278 of level @xmath126 than the level @xmath126 fragment of @xmath36 s parent ; hence , @xmath36 is the highest ( closest to the root of the whole tree ) in @xmath278 , that is , @xmath36 is @xmath278 s root * ) 2 .",
    "[ item - contain ] for every @xmath279 , the @xmath167th entry of @xmath36 s @xmath259-string is not `` 1 '' , + ( * because fragment @xmath278 of @xmath36 in level @xmath126 merges with the fragment ( of level @xmath126 ) of @xmath36 s parent ; hence , @xmath36 is not the highest in its fragments of levels @xmath279 * )    * ( eps4 ) * if the @xmath126th entry in @xmath271 is `` 1 '' then :    1 .",
    "the @xmath126th entry of @xmath36 s @xmath259-string is not `` 0 '' , + ( * because node @xmath36 is not in the fragments of level @xmath126 of @xmath36 s parent ( see eps2 ) ; hence , either @xmath36 is the root of its fragment of level @xmath126 ( see eps3 , part 1 ) , or @xmath36 does not belong to a fragment of level @xmath126 * ) 2 .   for every @xmath279 ,",
    "the @xmath167th entry of @xmath36 s @xmath259-string is not `` 1 '' , + ( * see eps3 part 2 * )    [ item - every ] * ( eps5 ) * for every non - root node @xmath36 , there exists an index integer @xmath254 $ ] , such that either the @xmath126th entry in @xmath271 is 1 or the @xmath126th entry in @xmath262 is `` up '' . + ( * because every node is the root of a fragment of level 0 ; at some level , @xmath36 s fragment merges with the fragment of @xmath36 s parent * )    [ lem : correct - candidate ] consider a @xmath259-hierarchy @xmath119 given by a legal assignment of @xmath259 strings .",
    "the conditions eps1eps5 above imply that legal assignments of @xmath267 and @xmath270 strings ( with respect to @xmath119 ) induce a candidate function @xmath227 .",
    "condition eps1 implies that for each fragment @xmath280 , there is precisely one node `` suspected '' as an endpoint of the induced candidate of @xmath111 .",
    "condition eps2 together with the previous one , implies that there is precisely one induced candidate edge @xmath232 for each fragment @xmath280 .",
    "that is , these two conditions induce a function @xmath227 .",
    "our goal now is to show that @xmath231 is , in fact , a candidate function .",
    "that is , we need to show that for every fragment @xmath220 , we have @xmath229 .",
    "( recall , @xmath221 denotes the set of fragments in @xmath119 which are strictly contained in @xmath111 . )",
    "it follows by the second items in conditions eps3 and eps4 , that for every fragment @xmath220 , we have @xmath281 in particular , we have @xmath282 .",
    "now , by condition eps5 , we get that each edge of @xmath18 is an induced candidate of some fragment .",
    "that is , we have : @xmath283 the first items in conditions eps3 and eps4 imply that for every fragment @xmath284 , the edge @xmath232 is outgoing from @xmath111 .",
    "this fact , together with part @xmath285 in the definition of a hierarchy , implies that for every fragment @xmath220 , @xmath286 equations ( 1 ) , ( 2 ) , and ( 3 ) imply that for every fragment @xmath220 , @xmath287 . in other words",
    ", @xmath231 is a candidate function for @xmath119 , as desired .",
    "condition eps0 is not required in order to prove the above lemma . if the labels were assigned by our mst construction algorithm , condition eps0 holds too . even though adding the condition seems redundant , we decided to add it because we believe it makes the reading more intuitive .",
    "now , to verify that assignments of @xmath267 and @xmath270 strings are legal with respect to a given legal assignment of @xmath259 strings , we need to verify the five conditions above",
    ". conditions eps2eps5 can be verified easily , in 1 unit of time , while the first condition eps1 needs additional information at each node to be verified in 1 unit of time . specifically , verifying the rule amounts to verifying that exactly one of the nodes in a fragment of level @xmath167 has its @xmath167th position in @xmath267 equal to 1 .",
    "this is easy to do in a scheme that is very similar to example @xmath89 in section [ sub : examples ] .",
    "hence , we omit this simple description ( nevertheless , it is demonstrated in table [ tab : table1 ] in the example of the @xmath288 strings of nodes corresponding to figure [ fig : hierarchytree1 ] ) .",
    "[ app : marker ] a natural method for assigning the labels of the 1-proof labeling scheme described above ( composed of the representation of @xmath147 and @xmath248 , and the strings @xmath259 , @xmath270 , @xmath267 , and @xmath288 ) , is to follow the construction algorithm of the mst , namely @xmath123 ( see section [ sec : mst - construction ] ) , which , in particular , constructs the hierarchy @xmath147 and the candidate function @xmath248 .",
    "recall that the complexity of @xmath123 is @xmath7 time and @xmath0 bits of memory per node .",
    "essentially , assigning the labels is performed by adding some set of actions to @xmath123 .",
    "these actions do not change the values of any of the variables of the original algorithm . also , we do not change the algorithm s flow of control , except for adding these actions .",
    "since each action is just a new assignment to a new variable ( of logarithmic size ) , the addition of these actions can not violate the correctness of @xmath123 , nor change its time and memory complexities ( except by a constant factor ) .",
    "we note that adding these actions on top of @xmath123 is not complicated , and can be realized using standard techniques .",
    "hence , we omit it here . hence , we obtain the following .    [",
    "lem : lineal - marker ] there exists a distributed marker algorithm assigning the labels of the 1-proof labeling scheme described in section  [ sec : section5 ] , running in @xmath7 time and using @xmath0 bits of memory per node .",
    "the lemma above together with lemma [ lem : correct - candidate ] establishes lemma [ lem : simple - proof ] .",
    "in the previous section , we described the verification that ( 1 ) a tree exists , ( 2 ) it is decomposed into a hierarchy of fragments , and ( 3 ) edges emanating from the fragments compose a candidate function ( so that the tree is the collection of these edges ) . that verified the well - forming property .",
    "it is left to verify the minimality property .",
    "that is , it is left to show that each edge of the candidate function is the minimum outgoing edge of some fragment in the hierarchy .",
    "the current section describes a part of the marker algorithm responsible for marking the nodes for this verification .",
    "informally , to perform the verification , each node must possess some information regarding each of the fragments @xmath111 containing it .",
    "the information regarding a fragment @xmath111 contains the weight of the selected edge of the fragment as well as the fragment identity , hence , it can be encoded using @xmath0 bits .",
    "( the fragment identity is needed to identify the set @xmath289 of outgoing edges from @xmath111 , and the weight of the selected edge is needed for comparing it to the weight of the other edges of @xmath289 ; this is how we detect that the selected edge is indeed the minimum ) .",
    "however , as mentioned , each node participates in @xmath0 fragments , and hence , can not hold at the same time all the information relevant for its fragments . instead , we distribute this information among the nodes of the fragments , in a way that will allow us later to deliver this information efficiently to all nodes of the fragment . in this section ,",
    "we show how to distribute the information regarding the fragments . in the next section ,",
    "we explain how to exploit this distribution of information so that during the verification phase , relevant information can be delivered to nodes relatively fast and without violating the @xmath0 memory size .",
    "[ [ the - piece - of - information - textttidf ] ] the piece of information @xmath132 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    as mentioned in section [ intuition : p2 ] , a crucial point in the scheme is letting each node @xmath36 know , for each of its incident edges @xmath131 and for each level @xmath126 , whether @xmath44 and @xmath36 share the same level @xmath126 fragment .",
    "( note , in the particular case where @xmath44 is also a neighbour of @xmath36 in @xmath18 , this information can be extracted by @xmath36 using @xmath44 s data - structure , see lemma [ lem : simple - proof ] . ) intuitively , this is needed in order to identify outgoing edges . for that purpose , we assign each fragment a unique identifier , and @xmath36 compares the identifier of its own level @xmath126 fragment with the identifier of @xmath44 s level @xmath126 fragment .",
    "the identifier of a fragment @xmath111 is @xmath290 , where @xmath181 is the unique identity of the root @xmath169 of @xmath111 , and @xmath225 is @xmath111 s level .",
    "we also need each node @xmath36 to know the weight @xmath133 of the minimum outgoing edge of each fragment @xmath111 containing  @xmath36 .",
    "to summarize , the _ piece of information _ @xmath134 required in each node @xmath36 per fragment @xmath111 containing @xmath36 is @xmath291 .",
    "thus , @xmath134 can be encoded using @xmath0 bits .    when describing the construction of hierarchy @xmath147 below , we view it as a tree ( and call it the _ fragment - tree _ ) whose nodes are fragments of @xmath18 , and in particular , the root of the fragment - tree is @xmath292 , the level @xmath226 fragment which is the whole tree @xmath18 .",
    "we shall make sure that @xmath124 .",
    "we refer to the nodes of the fragment - tree @xmath147 as _ fragment nodes_. consider a fragment node @xmath111 , corresponding to a fragment of @xmath18 .",
    "whenever no ambiguity arises , we refer to @xmath111 sometimes as a node of @xmath147 and sometimes as a fragment of @xmath18 . for example",
    ", we may refer either to @xmath292 or to @xmath18 , whichever simplifies the notations better .      .",
    "unfortunately , we did not manage to utilize one of the known decompositions of a tree , or an mst .",
    "one famous such decomposition is the set of fragments created in the algorithm of gallager , humblet , and spira @xcite as building blocks of the mst in constructed by their seminal algorithm .",
    "first , many of their fragments are very large .",
    "we could not spread the fragment s @xmath141 over such a large fragment , since this would take the information far beyond the desired locality radius .",
    "our construction below groups such fragments into an object we there term `` phase 1 '' and replicate @xmath141 over phase 1 as needed in order not to violate the locality radius constraint .",
    "the rest of the fragments are grouped into phases as well .",
    "this is motivated by our intention to show later ( in section [ sec : distributed - implementation ] ) a distributed implementation of the labeling schemes presented here .",
    "intuitively , the implementation needs to use some memory per an object , and let the marker algorithm distribute this memory over the nodes of the object ( we shall see the details in section [ sec : distributed - implementation ] ) .",
    "had there been too many objects , we would have violated the memory constraint .",
    "hence , we needed to group fragments together , leading the to `` phases '' structure described below .",
    "the marker constructs the fragment - tree @xmath147 in @xmath293 iterations .",
    "each iteration constructs a forest ( a collection of subtrees of @xmath147 ) termed _",
    "phase_. specifically , each iteration @xmath294 that constructs a phase @xmath142 , starts with a collection of fragment nodes , which then become the roots of the subtrees of phase @xmath142 .",
    "we term them the _ root fragments _ of phase @xmath142 .",
    "for an iteration @xmath295 , each such root fragment ( of phase @xmath142 ) is a child ( in @xmath147 ) of a fragment leaf of the phase @xmath296 constructed in the previous iteration .",
    "the first iteration starts with the root fragment of @xmath147 , namely , @xmath292 . for a fragment @xmath111 in some phase @xmath142 ,",
    "let @xmath297 denote the root fragment of @xmath142 that is an ancestor of @xmath111 in @xmath147 .",
    "we refer to @xmath297 as the _ root fragment _ of @xmath111 .",
    "let @xmath111 be a fragment of some phase constructed in iteration @xmath167 .",
    "we define parameter @xmath298 depending on the iteration @xmath167 as follows . for @xmath299 , @xmath300 and for @xmath301 , @xmath302 .",
    "two crucial properties of the hierarchy we construct are that for every leaf fragment @xmath111 , we have ( 1 ) @xmath303 , and ( 2 ) each child @xmath238 of @xmath111 ( a root fragment of the next phase ) satisfies @xmath304 .",
    "each iteration consists of steps , each starting with a fragment already in the hierarchy , and already in the current phase @xmath142 .",
    "in particular , the first step of the first phase starts with the whole @xmath305 and the first step of every other phase starts with a root fragment of that phase .",
    "let us now describe a step of an iteration .",
    "consider a fragment @xmath111 . if @xmath111 is a singleton fragment then @xmath111 in a leaf of the hierarchy @xmath147 .",
    "if @xmath306 then @xmath307 and we let the singleton fragments @xmath308 and @xmath309 be the two children of @xmath111 in the hierarchy @xmath147 ( each being a leaf of @xmath147 ) . consider now a fragment @xmath111 such that @xmath310 .",
    "fragment @xmath111 is first decomposed ( by the removal of one node- the _ separator _ ) into multiple subtrees @xmath311 . in traditional separator decompositions , the separator is chosen such that @xmath312 for every @xmath313 , and each such @xmath314 becomes a child fragment of @xmath111 in the hierarchy .",
    "( the `` removed '' node is added to one of the @xmath314 s arbitrarily besides belonging to @xmath111 ) .",
    "we start by partitioning @xmath111 the same way the traditional decomposition does . however , we change this decomposition ( for the construction of @xmath147 ) to satisfy the two crucial properties mentioned above .",
    "assume , without loss of generality , that after removing the chosen separator @xmath315 , the resulted subtrees @xmath316 are ordered by their size , i.e. , such that @xmath317 for @xmath318 .",
    "let @xmath319 be the subtree @xmath320 merged with the separator @xmath315 .",
    "first of all , if we either have @xmath321 or that each subtree @xmath316 is smaller than @xmath298 then @xmath111 becomes a leaf of the current phase @xmath142 and the subtrees @xmath322 become root fragments for the phase constructed in the next iteration .",
    "each such root fragment is nevertheless considered a child of @xmath111 in the hierarchy @xmath147 we build .",
    "consider now the case that @xmath323 .",
    "if @xmath324 holds for each @xmath167 , then each of the subtrees @xmath322 becomes a child fragment of @xmath111 , still in the current phase @xmath142 .",
    "we are left with the case that there exists some integer @xmath325 , such that @xmath326 , and @xmath327 .",
    "consider two subcases :    1 .",
    "merge @xmath329 adding the separator @xmath315 of @xmath111 .",
    "the result becomes one child fragment @xmath115 of @xmath111 in the same phase .",
    "each of the `` large '' subtrees , @xmath330 also becomes a child of @xmath111 in the same phase . in the next step ,",
    "when considering @xmath115 , choose @xmath315 as its separator , to guarantee that @xmath115 would be a leaf of the current phase ( note , after removing @xmath315 , fragment @xmath115 breaks into the `` small '' subtrees @xmath329 which are root fragments of the next phase ) .",
    "2 .   @xmath331 . merge them with @xmath332 and add the separator node .",
    "the resulting fragment becomes a child fragment of @xmath111 , in the same phase .",
    "each of the `` large '' subtrees , @xmath333 also becomes a child of @xmath111 in the same phase .",
    "[ lem : hierarchy - properties ] let @xmath111 be a leaf fragment of some phase constructed in iteration @xmath167 .",
    "+ the following * hierarchy properties * hold :    1 .   if @xmath334 then @xmath111 is not a leaf of the hierarchy @xmath147 , and each child @xmath238 of @xmath111 satisfies @xmath335 .",
    "2 .   @xmath303 .",
    "3 .   there are @xmath293 phases .",
    "the height of @xmath111 in the phase of @xmath111 is @xmath336 .",
    "the height of hierarchy @xmath147 is @xmath0 .",
    "consider a leaf fragment @xmath111 of some phase constructed in iteration @xmath167 .",
    "it follows trivially by the construction that if @xmath334 then @xmath111 is not a leaf of @xmath147 .",
    "let @xmath115 be a child of @xmath111 in @xmath147 .",
    "either @xmath111 satisfies @xmath321 , in which case we have @xmath337 , or that @xmath323 but @xmath338 .",
    "property ( 1 ) follows .",
    "property ( 3 ) follows from property ( 1 ) , since for iteration @xmath301 , we have @xmath302 .",
    "property ( 2 ) is satisfied since we guarantee that a fragment @xmath115 is a child of a fragment @xmath111 in the same phase only if @xmath339 .",
    "let us now show that properties ( 4 ) and ( 5 ) hold as well .    let @xmath142 be a phase and let @xmath111 be a fragment in @xmath142 .",
    "we first claim that if fragment @xmath115 , which is a child of fragment @xmath111 , satisfies @xmath340 then @xmath115 is a leaf fragment of phase @xmath142 .",
    "assume by contradiction that @xmath115 is not a leaf of @xmath142 and yet @xmath340 .",
    "consider first the case that @xmath115 was constructed in the first subcase above .",
    "the fact that @xmath115 is not a leaf means that @xmath115 was not constructed by merging @xmath341 .",
    "hence , the separator @xmath315 of @xmath111 is the one selected by the traditional separator decomposition .",
    "however , if @xmath115 is one of the subtrees @xmath314 obtained by removing @xmath315 from @xmath111 then @xmath342 .",
    "( if @xmath343 then @xmath344 ) . a contradiction .",
    "finally , consider the case that @xmath115 was constructed in the second subcase above , by merging @xmath341 together with @xmath332 .",
    "observe that @xmath345 and that @xmath331 .",
    "this means that @xmath346 . if @xmath347 then we have @xmath348 which implies that @xmath321 . however",
    ", in this case , @xmath111 is a leaf of @xmath142 , a contradicting .",
    "this establishes our claim .",
    "property ( 4 ) now follows immediately , and property ( 5 ) follows by property ( 3 ) .",
    "the candidate function @xmath248 for @xmath147 is defined as follows . for each @xmath349 , let @xmath115 be the parent of @xmath111 in @xmath119 . then @xmath264 is simply the edge in @xmath18 connecting @xmath111 with @xmath12 .    at a very high level description , each node @xmath36 stores",
    "_ permanently _",
    "@xmath134 for a constant number of fragments  @xmath111 . using that , @xmath134 is `` rotated '' so that each node in @xmath111 `` sees '' @xmath134 in @xmath0 time .",
    "we term the mechanism that performs this rotation a _ train_. a crucial point is having each node participate in only few trains .",
    "indeed , one train passing a node could delay the other trains that `` wish '' to pass it .",
    "furthermore , each train utilizes some ( often more than constant ) memory per node .",
    "hence , many trains passing at a node would have violated the @xmath0 memory constraint . in our solution",
    ", we let each node participate in two trains .",
    "let us recall briefly the motivation for _ two _ trains rather than one . as explained in section [ subsub : overview - proof ] , one way to involve only one train passing each node",
    "would have been to partition the nodes , such that each fragment would have intersected only one part of the partition .",
    "_ one _ train could have passed carrying the pieces of information for all the nodes in the part .",
    "unfortunately , we could not construct such a partition where the parts were _",
    "small_. a small size of each part is needed in order to ensure that a node sees all the pieces ( the whole train ) in a short time .    hence , we construct _ two _ partitions of the tree .",
    "each partition is composed of a collection of node - disjoint subtrees called _",
    "parts_. for each partition , the collection of parts covers all nodes .",
    "hence , each node belongs to precisely two parts , one part per partition . for each part , we distribute the information regarding some of the fragments it intersects , so that each node holds at most a constant number of such pieces of information .",
    "conversely , the information regarding a fragment is distributed to nodes of one of the two parts intersecting it .",
    "furthermore , for any node @xmath36 , the two parts corresponding to it encode together the information regarding all fragments containing @xmath36 .",
    "thus , to deliver all relevant information , it suffices to utilize one train per part ( and hence , each node participates in two trains only ) .",
    "furthermore , the partitions are made so that the diameter of each part is @xmath0 , which allows each train to pass in all nodes in short time , and hence to deliver the relevant information quickly .",
    "the mechanism of trains and their synchronization is described in the next section .",
    "the remaining of this current section is dedicated to the construction of the two partitions , and to explaining how the information regarding fragments is distributed over the parts of the two partitions .",
    "consider a correct instance , and fix the corresponding hierarchy tree @xmath350 .",
    "we now describe _ two _ partitions of the nodes in @xmath18 , called @xmath144 and @xmath145 .",
    "( the distributed algorithm that constructs the partitions is described later . )",
    "we also partition the fragments into two kinds , namely , _ top _ and _ bottom _ fragments .",
    "[ [ top - and - bottom - fragments ] ] top and bottom fragments : + + + + + + + + + + + + + + + + + + + + + + + + +    define the _ top _ fragments to be precisely those fragments whose number of nodes is at least @xmath351 .",
    "observe that the top fragments correspond to a subtree of the hierarchy tree  @xmath119 .",
    "name that subtree @xmath352 .",
    "all other fragments are called _",
    "bottom_. see the left side of figure [ fig : top ] for an illustration of the top fragments and the subtree @xmath353 .",
    "let us first describe partition @xmath144 .",
    "we first need to define three new types of fragments .",
    "[ [ red - blue - and - large - fragments ] ] red , blue , and large fragments : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    a leaf fragment in subtree @xmath352 is colored red . a fragment not in @xmath352 which is a sibling in @xmath119 of a fragment in @xmath352 is colored blue .",
    "( equivalently , a blue fragment is a fragment not in @xmath352 , whose parent fragment in @xmath119 is a non - red fragment in @xmath352 ) .",
    "the following observation is immediate .",
    "[ obs : red - blue - partition ] the collection of red and blue fragments forms a partition @xmath354 of the nodes of  @xmath18",
    ". see figure [ fig : top ] for an illustration of partition @xmath354 .    to emphasize the fact that each non - blue child fragment of an internal fragment in @xmath352 contains at least @xmath351 nodes , we call internal fragments in @xmath352 _",
    "large_. note , the large fragments are precisely the ( strict ) ancestors of the red fragments in @xmath119 . since the ancestry relation in @xmath119 corresponds to an inclusion relation between the corresponding ( active ) fragments in @xmath18 , we obtain the following observation .",
    "[ obs : large - red - blue ] each large fragment @xmath355 is composed of at least one red fragment @xmath356 as well as one or more blue ones , and does not contain any additional nodes ( of course , the part may contain also the _ edges _ connecting those fragments ) .",
    "[ [ par : red - blue - merge ] ] partition @xmath357 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our goal now is to partition the nodes to parts such that each part contains _ precisely _ one red fragment and possibly several blue ones , and no additional nodes .",
    "such a partition exists , since , it is just a coarsening of the partition @xmath358 of the nodes to red and blue fragments .",
    "moreover , the construction of _ some _ such a partition is trivial , following observation [ obs : large - red - blue ] and the fact that the tree is a connected graph .",
    "the following procedure produces such a partition @xmath357 that has an additional property defined below .",
    "( a less formal description of the procedure is as follows : let pink parts be either red fragments , or the results of a merge between a red fragment and any number of blue ones .",
    "now repeat the following as long as there are unmerged blue fragments : consider a blue fragment @xmath359 who has a sibling pink fragment and , moreover touches that sibling ; merge @xmath359 with one of its sibling pink fragments it touches ) .",
    "[ [ procedure - merge ] ] procedure merge + + + + + + + + + + + + + + +    1 .",
    "initialize the set @xmath360 of parts to include precisely the set of red parts .",
    "( * @xmath360 is not yet a partition * ) 2 .",
    "repeat while there are blue fragments not merged into parts of @xmath360 1 .",
    "let @xmath355 be a top fragment that contains a node @xmath44 that is _ not _ in any part of @xmath360 , where all the nodes of every child fragment of @xmath355 belong to parts of @xmath360 .",
    "2 .   let @xmath359 be the blue fragment containing @xmath44 .",
    "( note that we have @xmath361 . )",
    "let @xmath362 be some part that touches @xmath359 .",
    "3 .   merge @xmath359 with one such @xmath363 .",
    "( this also removes @xmath363 from @xmath360 and inserts , instead , the merged part @xmath364 3 .   when the procedure terminates , @xmath365 .",
    "see figure [ fig : top ] for an illustration of partition @xmath357 .",
    "it is easy to see ( e.g. , by induction on the order of merging in the above procedure ) that partition @xmath357 is constructed in the following way : let @xmath356 be the red fragment in a part @xmath363 .",
    "then all the nodes in @xmath363 belong to ancestor fragments of @xmath356 .",
    "this leads to the following observation .    ; on the right : partition @xmath354 ( above ) and partition @xmath357 ( below ) ]    [ cla : red - blue - intersect ] each part @xmath366 intersects at most one level  @xmath126 top fragment , for every  @xmath126 .    the property captured in",
    "the above claim is very useful .",
    "as can be seen later , this property means that the train in each part @xmath363 needs to carry only one piece of information for each level .",
    "[ [ partition - texttttop-1 ] ] partition @xmath144 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we would like to pass a train in each part @xmath142 of @xmath357 .",
    "unfortunately , the diameter of @xmath142 may be too large .",
    "in such a case , we partition @xmath142 further to _ neighbourhoods _ , such that each neighbourhood is a subtree of @xmath18 of size at least @xmath351 and of diameter @xmath0 . the resulted partition is called @xmath144 .",
    "the lemma below follows .",
    "[ lem : top ] for every part @xmath142 in partition @xmath144 , the following holds .",
    "@xmath367 ,    @xmath368 , where @xmath369 is the diameter of @xmath142 .",
    "@xmath142 intersects at most one level @xmath126 top fragment , for every @xmath126 ( in particular , it intersects at most @xmath370 top fragments ) .",
    "the bottom fragments are precisely those with less than @xmath351 nodes .",
    "the parts of the second partition @xmath145 are the following : ( 1 ) the blue fragments , and ( 2 ) the children fragments in @xmath147 of the red fragments . by observation [ obs : red - blue - partition ] , this collection of fragments is a indeed a partition .",
    "observe that each part of @xmath145 is a bottom fragment .",
    "thus , the size , and hence the diameter , of each part @xmath142 of @xmath145 , is less than @xmath351 .",
    "figure  [ fig : bottom ] illustrates the bottom fragments and partition @xmath145 .",
    "observe also that a part @xmath371 contains all of @xmath142 s descendant fragments in @xmath119 ( recall , @xmath142 is a fragment , and the collection of fragments are a laminar family ) , and does not intersect other bottom fragments .",
    "hence , we get the following .    .",
    "]    [ lem : bottom ] for every part @xmath142 of partition @xmath145 , the following holds :    @xmath372 , and    @xmath142 intersects at most @xmath373 bottom fragments .      in section  [ app : neighbourhoods ] , we show that the above partitions @xmath144 and @xmath145 can be constructed by a distributed algorithm that uses @xmath0 memory and linear time .",
    "each part @xmath142 of each of the two partitions is represented by encoding in a designated part of the label of each node in @xmath142 , the identity @xmath374 of the root of @xmath142 ( the highest node of part @xmath142 ) .",
    "recall that a node participates in only two parts ( one of each partition ) , so this consumes @xmath0 bits per node .",
    "obviously , given this representation , the root of a part can identify itself as such by simply comparing the corresponding part of its label with its identity .",
    "in addition , by consulting the data - structure of a tree neighbour  @xmath44 , each node @xmath36 can detect whether @xmath44 and  @xmath36 belong to the same part ( in each of the two partitions ) .",
    "a delicate and interesting point is that the verifier does not need to verify directly that the partitions @xmath144 or @xmath145 were constructed as explained here .",
    "this is explained in section [ sub:3.3 ] .",
    "fix a part @xmath142 of partition @xmath144 ( respectively , @xmath145 ) . recall that @xmath142 is a subtree of @xmath18 rooted at @xmath150 .",
    "let @xmath375 be the top ( resp .",
    ", bottom ) fragments intersecting  @xmath142 , for some integer @xmath376 . by lemma [ lem : top ]",
    ", lemma [ lem : bottom ] ) , we know that @xmath377 .",
    "assume w.l.o.g . , that the indices are such that the level of @xmath238 is , at least , the level of @xmath378 , for each @xmath379 .",
    "the information concerning part @xmath142 is defined as @xmath380 .",
    "we distribute this information over the nodes of @xmath142 as follows .",
    "we break @xmath381 into  @xmath382 pairs of pieces .",
    "specifically , for @xmath167 such that @xmath383 , the @xmath167th pair , termed @xmath384 , contains @xmath385 ( for odd @xmath376 , @xmath386 ) .",
    "the process of storing the pieces permanently at nodes of a part of the partition is referred to as the _ initialization of the trains_. the distributed algorithm that implements the initialization of the trains using @xmath0 memory size and linear time is described next . it is supposed to reach the same result of the following non - distributed algorithm ( given just in order to define the result of the distributed one ) .",
    "this non - distributed algorithm is simply the classical depth first search ( dfs ) plus the following operation in every node visited for the first time . consider a dfs traversal over @xmath142 that starts at @xmath150 and let @xmath387 denote the the @xmath167th node visited in this traversal .",
    "for each @xmath167 , @xmath388 , @xmath387 stores permanently the @xmath167th pair of @xmath381 , namely , @xmath384 .      before describing the distributed construction of the two partitions , namely @xmath144 and @xmath145 , we need to describe a tool we use for efficiently executing several waves&echoes operations in parallel .",
    "@xmath389 _ primitive ( described below ) performs a wave&echo in every fragment in @xmath119 of level @xmath155 , for @xmath390 .",
    "moreover , the @xmath173th wave&echo is supposed to start after the @xmath167th wave&echo terminates .",
    "furthermore , all this is obtained in time @xmath7 .",
    "we shall use this primitive only after the @xmath259 string is already set , so that every node knows for each level , whether it is the root of a fragment of that level .",
    "let us first present a slightly inefficient way to perform this .",
    "the root of the whole tree starts @xmath129 _ consecutive _ waves and echoes , each for the whole final tree .",
    "( by consecutive we mean that the @xmath157th wave starts when the @xmath155th wave terminates . )",
    "let the level @xmath155 wave be called @xmath391(t,@xmath392 since it carries some instruction @xmath393 , is sent over the whole tree @xmath18 , and carries the information that it is meant for level  @xmath155 .",
    "a root @xmath394 of a fragment @xmath395 of level @xmath155 , receiving @xmath391(t,@xmath392 , then starts its own wave&echo @xmath396(@xmath397 over its own fragment only .",
    "( here , @xmath398 is some instruction possibly different than @xmath393 . )",
    "a node who is not a root of a level @xmath155 fragment can echo @xmath391(t,@xmath392 as soon as all its children in the final tree ( if it has any ) echoed .",
    "a root  @xmath394 echoes @xmath391(t,@xmath392 only after its own wave @xmath396(@xmath397 terminated ( and , of course , after it also received the echoes of @xmath391(t,@xmath392 from all its children ) .",
    "the following observation follows immediately from the known semantics of wave&echo .",
    "[ obs : multi - wave - semantics ] consider a fragment @xmath395 of level @xmath155 rooted at some @xmath394 .",
    "the wave initiation by @xmath394 starts after all the waves involving its descendant fragments terminated ( at the roots of the corresponding fragments ) .",
    "the ideal time complexity of performing the above collection of @xmath226 waves is @xmath399 . in the case",
    "that the size of a level @xmath155 fragment @xmath395 is @xmath400 , we can achieve the semantics of observation [ obs : multi - wave - semantics ] somewhat more time efficiently .",
    "the primitive that achieves this is termed a @xmath389 .",
    "when invoking it , one needs to specify which instructions it carries .",
    "informally , the idea is that the roots @xmath401 of level @xmath166 fragments perform the wave ( for level 0 ) in parallel , each in its own fragment of level @xmath166 ( a single node ) .",
    "recall that a fragment @xmath113 of level 1 contains multiple fragments of level zero .",
    "the roots of these fragments of level zero report the termination of the level @xmath166 wave to the root of @xmath113 .",
    "next , the roots @xmath402 of level @xmath59 fragments perform the wave ( for level 1 ) in parallel , each in its own fragment of level @xmath59 .",
    "the terminations are reported to level @xmath403 fragment roots , etc .",
    ", until the @xmath389 terminates .",
    "the @xmath389 is started at the root of the final tree @xmath18 by a wave termed @xmath404 .",
    "each node @xmath36 who receives @xmath404 acts also as if @xmath36 has initiated a @xmath405 on a tree containing only itself . ensuring the termination and the semantics for level @xmath405 is trivial .",
    "we now define the actions of levels higher than zero in an inductive manner .",
    "every node @xmath36 who received ( and forwarded to its children if it has any ) @xmath404 , simulates the case that it received ( and forwarded to its children ) @xmath406 for every level @xmath155 .",
    "however , @xmath36 is not free yet to echo @xmath406 until an additional condition holds as follows : when some wave @xmath406 terminates at the root @xmath394 of @xmath120 , this root initiates an informing wave @xmath407 to notify the nodes in @xmath395 that the wave of level @xmath155 in their subtree terminated , and thus they are free to echo @xmath408 .",
    "that is , a leaf of a @xmath409 fragment can echo @xmath408 immediately when receiving @xmath407 , and a non - leaf of @xmath408 may echo @xmath408 when it receives echoes from all its children in @xmath409 .    specifically , the convergecast is performed to the containing @xmath157 fragment as follows : a leaf of a level @xmath157 fragment who receives @xmath407 sends a message @xmath410 to its parent .",
    "a parent node sends message @xmath411 if it is not a root of a level @xmath157 fragment , and only after receiving @xmath411 from all its children .",
    "when a root of a level @xmath157 fragment receives the @xmath411 message from all of its children , it starts @xmath412 .",
    "the @xmath389 terminates at the root of the final tree when the wave for level @xmath226 terminates at that root .",
    "the informing wave @xmath407 itself needs no echo .",
    "[ obs : multi - wave - semantics2 ] the efficient implementation of the multi - wave simulates the multiple waves analyzed in observation [ obs : multi - wave - semantics ] .",
    "that is , it obtains the same result for the instructions @xmath393 and @xmath398 in every node .",
    "consider an alternative algorithm ( for @xmath389 ) in which , when a root of fragment @xmath409 receives @xmath404 , it starts a wave @xmath413 .",
    "assume further , that the @xmath411 messages are sent as echoes of @xmath413 .",
    "moreover , assume that an echo @xmath411 is sent by a node only after it received @xmath407 .",
    "the claim for such an alternative algorithm would follow from observation [ obs : multi - wave - semantics ] and the known properties of wave&echo .",
    "now , it is easy to verify that the @xmath389 described simulates that alternative algorithm .",
    "that is , ( 1 ) @xmath404 is sent by a node @xmath414 who belongs to a fragment of level @xmath157 to its child @xmath415 in the same fragment exactly when it would have sent the imaginary @xmath413 .",
    "this is easy to show by induction on the order of events .",
    "moreover , at that time , the child @xmath415 knows the information carried by @xmath413 since it knows ( from its @xmath416 which fragments it shares with its parent ( and for each one of them we simulate the case @xmath44 now receives @xmath417 .    the ideal time complexity of performing a multi - wave on the hierarch @xmath147 is @xmath7 .",
    "the wave started by the root consumes @xmath7 time .",
    "recall that hierarchy @xmath147 corresponds to active fragments during the construction of the mst by algorithm @xmath123 .",
    "hence , lemma [ lem : disappear ] implies that in hierarchy @xmath147 , the size of a level @xmath155 fragment @xmath395 satisfies @xmath400 .",
    "thus , each wave started by a root of a fragment @xmath395 of level @xmath155 takes @xmath418 time , and starts at time @xmath418 after the initiation of the multi - wave .",
    "the construction of partition @xmath354 is performed in several stages .",
    "each of the tasks below is performed using the @xmath389 primitive .",
    "this is rather straightforward , given that the usage of wave&echo as a primitive is very well studied .",
    "below , we give some hints and overview .",
    "first , we need to identify red fragments .",
    "it is easy to count the nodes in a fragment using wave&echo to know which fragment has more than @xmath351 nodes .",
    "however , a large fragment that properly contains a red fragment is not red itself .",
    "hence , the count is performed first in fragments lower in the hierarchy , and only then in fragments that are higher .",
    "recall that the @xmath389 primitive indeed completes first waves in fragments that are lower in the hierarchy , before moving to fragments that are higher .",
    "hence , one execution of the @xmath389 primitive allows to identify red fragment . at the end of this execution ,",
    "the roots of fragments know whether they are the roots of red fragments or not .",
    "a similar technique can be applied to identify blue fragments .",
    "a second task is to identify a large fragment @xmath355 that is not red , but has a child fragment who is red .",
    "it is an easy exercise to perform the construction using the @xmath389 primitive .",
    "in such a case , if the level of @xmath355 is @xmath126 , we set the variable @xmath419 ( initialized to @xmath420 ) at a root of @xmath355 to @xmath421",
    ". this task can be performed by the same set of wave&echoes as above . recall that in the @xmath389 primitive , the wave&echo in @xmath355 is performed after the wave&echo in its red child fragment @xmath356 terminated in its root @xmath422 , and identified that @xmath356 was red .",
    "recall also , that @xmath355 contains @xmath356 , so the wave&echo in @xmath355 passes in @xmath422 .",
    "thus , by setting the proper flags , it is easy to set the value of @xmath419 in @xmath355 correctly .",
    "we also make use of an output @xmath423 ( initialized to @xmath420 ) , that is set to @xmath421 if @xmath424 is either red or contains a red descendant fragment .",
    "this output of the first two tasks is useful for performing a third task : identifying the blue fragments .",
    "[ obs:1st - partition ] consider a fragment @xmath355 of some level @xmath126 which has a red child .",
    "when the above two tasks are completed successfully , the following holds .    1 .",
    "the value of @xmath419 in the root @xmath425 of @xmath355 is @xmath421 .",
    "2 .   consider each child fragment @xmath426 of some level @xmath167 of @xmath355 .",
    "assume further that @xmath426 is either red itself , or it contains a red fragment .",
    "then the value of @xmath427 in the root @xmath428 of @xmath238 is @xmath421 .",
    "3 .   a child fragment @xmath426 of @xmath355 whose root @xmath428 does _ not _",
    "have @xmath421 in @xmath427 is a blue fragment .",
    "based on the last part of the above observation , it is easy to have a root detect it is the root of a blue fragment , using another wave&echo ( that starts by the root of the parent fragment @xmath355 ) . as before , the root of the final tree initiates a @xmath389 to facilitate that detection .",
    "third task : identifying the blue fragments .",
    "the third task is that of identifying the blue fragments . a fourth task is to let each node in a blue fragment , and each node in a red fragment ,",
    "know the color of their fragments .",
    "again , designing these tasks is an easy exercise given the example of the first task above , and the @xmath389 primitive .    is easy to do using a wave&echo from a root who already knows this color , as established above .",
    "this whole set of wave&echoes is started by the root of the final tree ( again , using a @xmath389 ) .",
    "it is rather straightforward to use waves&echos to implement procedure merge to generate partition @xmath357 .",
    "the red fragments use waves&echos to annex roots of sibling blue fragments .",
    "they become pink parts ( in the terminology of paragraph [ par : red - blue - merge ] .",
    "then this is repeated in the parent fragment , etc .",
    "since this process goes from a lower level fragment to higher and higher levels , the @xmath389 primitive handles this well .",
    "hence , we construct @xmath357 inductively , using @xmath129 wave&echoes , @xmath429 , for @xmath430 . to define the inductive property ,",
    "let us define the following . call a partition in which each part consists of one red fragment and zero or more blue fragments a _ red - centered partition_. notice that the process defined in the previous paragraph , establishes a red - centered partition of @xmath355 .",
    "this establishes the base for the following inductive property : + * invariant 1 : * consider the time @xmath429 is started . let @xmath426 of level @xmath431 be a fragment who contains a red fragment ( or is red itself ) .",
    "then , @xmath426 is already partitioned into a red - centered partition . moreover ,",
    "each part is rooted in its highest ( in the final tree ) node .",
    "+ it follows from observation [ obs:1st - partition ] , that any fragment child of @xmath432 that does not contain a red fragment ( and is not red itself ) is blue . by the induction assumption ,",
    "when @xmath429 is started in some @xmath432 of level @xmath126 , any fragment child of @xmath432 is either red - centered partitioned , or is blue .",
    "the process is very similar to the one described for @xmath355 in the first paragraph of this construction .",
    "that is , the root of each red - centered part starts yet another wave&echo ( in @xmath432 only ) carrying its own @xmath138 with invitations to blue fragments to join .",
    "consider the root @xmath433 of a blue fragment ( a child fragment of @xmath432 ) who has not yet joined a part of @xmath357 .",
    "root @xmath433 joins ( together with its whole blue fragment ) the part constructed by the root corresponding to the first such wave @xmath433 receives .      upon receiving the echoes for the @xmath389 primitive constructing partition @xmath357 , the root of the final tree instructs ( by yet another wave ) each @xmath434 of @xmath357 to start partitioning its part into parts of partition @xmath144",
    "that is , each part of @xmath357 is partitioned into subtrees , each of diameter @xmath0 and of size @xmath4 .",
    "this task is described in @xcite .",
    "when it is completed , each part of @xmath144 is rooted at its highest node . moreover ,",
    "every node in that part is marked by the name of its part leader , in its variable called @xmath435 .",
    "( since @xmath144 is a partition , each node belongs only to one part ; hence , this does not violate the @xmath0 bits constraint . )",
    "recall that the parts of the second partition @xmath145 are ( 1 ) the blue fragments and ( 2 ) the child fragments of red fragments .",
    "let us term the latter _",
    "green fragments_. we already established that members and roots of blue fragments know that they are members and roots of blue fragments .",
    "the green fragments are notified in a similar way the blue ones were .",
    "that is , the root of the final tree starts a wave&echo instructing the roots of the red fragments to notify child fragments that they are green .",
    "[ claim : top - bottom - assignment ] the two partitions @xmath144 and @xmath145 described in section [ sec : partitions ] can be assigned in time @xmath7 and memory size @xmath0 .",
    "first we describe a primitive that a root of a part @xmath142 uses for storing @xmath134 of one given fragment @xmath436 .",
    "this is a well known distributed algorithm , so we do not describe it in detail .",
    "we use a distributed depth first search ( dfs ) , see , e.g.  @xcite .",
    "initially , all the nodes in a part @xmath142 are marked @xmath437 .",
    "when the root of the part wants to store the @xmath134 of some fragment @xmath111 , it sends this @xmath134 ( with a token ) to perform a dfs traversal of part @xmath142 .",
    "the first time that token reaches a node marked @xmath437 , it sets @xmath437 to @xmath420 and stores @xmath134 in that node .",
    "it is left to describe how the root of a part gets @xmath134 for each @xmath111 whose @xmath134 should reside in that part .",
    "a part @xmath438 in partition @xmath439 contains precisely one red fragment @xmath356 .",
    "hence , we call such fragments _ red - centered_. consider a part @xmath142 in partition @xmath144 that was created from a red - centered part @xmath440",
    ". recall that such a part @xmath142 should store only the @xmath141 of top fragments it intersects . since each such top fragment is an ancestor fragment of @xmath356 , we let part @xmath142 store the @xmath141 of all ancestor fragments of @xmath356",
    "hence , the set of @xmath141 stored at @xmath142 includes the @xmath141 of all fragments @xmath142 intersects , but may include more @xmath141 s ( of fragments intersecting @xmath438 but not @xmath142 ) .",
    "nevertheless , note that , for every @xmath126 , these other @xmath141 s correspond to at most one fragment in level @xmath126 .",
    "this follows simply from the fact that @xmath356 intersects at most one level @xmath126 fragment ( see claim [ cla : red - blue - intersect ] ) .",
    "recall also that the root of the part knows it is a root of a part ( by comparing its @xmath435 variable with its identity ) , and every node knows which part it belongs to ( again , using its @xmath435 variable ) as well as who are its parent and children in the part .",
    "( the latter information a node can deduce by reading each tree neighbour . )    the root of the final tree @xmath18 starts a @xmath389 over @xmath18 .",
    "fix a level @xmath126 .",
    "the @xmath126th wave of the multi - wave , which we term @xmath441 ) , signals the roots of every top fragment @xmath424 of level @xmath126 to obtain the information @xmath442 and to send it to the roots of the parts of partition @xmath144 intersecting @xmath424 .",
    "consider a root @xmath443 of such a fragment @xmath424 who receives the signal of @xmath444 .",
    "first , to obtain @xmath442 , node @xmath443 must find the weight of @xmath48 , the minimum outgoing edge of @xmath424 . recall that the endpoint @xmath445 of @xmath148 can identify it is the endpoint using the @xmath126th position in @xmath446 , and",
    "can identify which of its incident edges is @xmath48 .",
    "so , node @xmath443 starts another wave&echo bringing the weight of @xmath48 to @xmath443 .",
    "( note that @xmath443 is the root of a single fragment in level @xmath126 , though it may be the root of other fragments in other levels ; hence , at the time of the wave of level @xmath126 , it handles the piece of only one fragment , namely , @xmath120 ; hence , not congestion arises ) . when this wave terminates , @xmath443 sets @xmath447 and starts another wave&echo , called @xmath448 , conveying @xmath442 to roots of the parts of partition @xmath144 intersecting @xmath424 .",
    "to implement this , @xmath443 , the root of @xmath120 , first broadcasts @xmath442 to the nodes of @xmath424 . at this point , each node in @xmath120 knows @xmath442 .",
    "next , our goal is to deliver @xmath442 to the roots of parts in partition @xmath144 intersecting @xmath424 .",
    "however , note that since @xmath120 is a subtree , and all parts are subtrees , the roots of the parts of partition @xmath144 intersecting @xmath424 are all contained in @xmath120 , except maybe the root @xmath449 of the part containing @xmath443 .",
    "so , by now , all roots of parts in partition @xmath144 intersecting @xmath424 , except maybe @xmath449 , already know @xmath442 . to inform @xmath449",
    "it suffices to deliver @xmath442 up the tree , from @xmath443 to @xmath449 . since",
    ", all roots of parts in @xmath144 , and @xmath449 in particular , know they are roots , this procedure is trivial . finally , to complete the wave at level @xmath126 , a root of a @xmath144 part receiving @xmath450 stores it in its part as described at top of this section ( that is , storing each piece at a node in the part , following a dfs order ) .    note , that since the diameter of a part in @xmath144 is of length @xmath0 , the wave of level @xmath126 can be implemented in @xmath451 time . altogether , the @xmath389 over @xmath18 is completed by time @xmath452      recall that a part in partition @xmath145 is a fragment of size @xmath0 .",
    "the root of such a part @xmath142 collects the @xmath141 of fragments in @xmath142 of each level @xmath167 by issuing a wave&echo for level @xmath167 .",
    "the weight of the minimum outgoing edge of each fragment @xmath426 of level @xmath167 is then collected by the root of @xmath426 .",
    "this ensures that the @xmath453 for each fragment @xmath426 of level @xmath167 in the fragment arrives at @xmath426 s root .",
    "finally , the wave&echo collects the @xmath141s from the roots of the fragments in the @xmath145 part to the root of the part .",
    "it is easy to see the following .",
    "[ claim : initial - trains ] the initialization of the trains information described in section [ app : neighbourhoods ] can be done in time @xmath7 and memory size @xmath0 .",
    "the next corollary that summarizes this section follows from lemma [ lem : lineal - marker ] and claims [ claim : top - bottom - assignment ] and [ claim : initial - trains ] .",
    "[ cor : marker - time ] the marker algorithm @xmath64 can be implemented using memory size @xmath0 and @xmath7 time .",
    "[ sub:3.2 ]    we now turn to the verifier algorithm of part of the proof labeling scheme that verifies the minimality property .",
    "consider a node @xmath36 and a fragment @xmath130 of level @xmath126 containing it . recall that @xmath139 should reside permanently in some node of a part @xmath142 to which @xmath36 belongs .",
    "this information should be compared at @xmath36 with the information @xmath140 regarding a neighbour  @xmath44 of @xmath36 , hence both these pieces must somehow be `` brought '' to @xmath36 .",
    "the process handling this task contains several components .",
    "the first is called a `` train '' and is responsible for moving the pieces pairs @xmath384 through @xmath142 s nodes , such that each node does not hold more than @xmath0 bits at a time , and such that in short time , each node in @xmath142 `` sees '' all pieces , and in their correct order .",
    "( by short time , we mean @xmath0 time in synchronous networks , and @xmath19 time asynchronous networks . )",
    "unfortunately , this is not enough , since @xmath139 may arrive at @xmath36 at a different time than @xmath140 arrives at @xmath44 , hence some synchronization must be applied .",
    "further difficulties arise from the fact that the neighbours of a node  @xmath36 may belong to different parts , so different trains pass there .",
    "note that  @xmath36 may have many neighbours , and we would not want to synchronize so many trains .",
    "a first idea to obtain synchronization would have been to utilize delays of trains .",
    "however , delaying trains at different nodes could accumulate , or could even cause deadlocks .",
    "hence , we avoid delaying trains almost completely .",
    "instead , each node @xmath36 repeatedly samples a piece from its train , and synchronizes the comparison of this piece with pieces sampled by its neighbours , while both trains advance without waiting .",
    "perhaps not surprisingly , this synchronization turns out to be easier in synchronous networks , than in asynchronous ones .",
    "this process presented below assumes that no fault occurs .",
    "the detection of faults is described later .      for simplicity",
    ", we split the task of a train into two subtasks , each performed repeatedly  the first , _ convergecast _ , moves ( copies of ) the pieces one at a time _ pipelined _ from their permanent locations to @xmath150 , the root of part @xmath142 , according to the dfs order .",
    "( recall , @xmath387 stores permanently the @xmath167th piece of @xmath381 . )",
    "a _ cycle _ is a consecutive delivery of the @xmath376 pairs of pieces @xmath454 to @xmath150 .",
    "since we are concerned with at most @xmath455 pairs of pieces , each cycle can be performed in @xmath0 time .",
    "the second subtask , _ broadcast _ , broadcasts each piece from @xmath150 to all other nodes in @xmath142 ( pipelined ) .",
    "this subtask can be performed in @xmath368 time , where @xmath369 is the diameter of @xmath142 .",
    "we now describe these two subtasks ( and their stabilization ) in detail .",
    "consider a part @xmath142 ( recall , a part is a subtree ) .",
    "the ( pipelined ) broadcast in @xmath142 is the simpler subtask .",
    "each node contains a broadcast buffer for the current broadcast piece , and the node s children ( in the part ) copy the piece to their own broadcast buffer .",
    "when all these children of a node acknowledge the reception of the piece , the node can copy the next piece into its broadcast buffer .",
    "obviously , this process guarantees that the broadcast of each piece is performed in @xmath368 time , where @xmath369 is the diameter of @xmath142 .",
    "we now describe the convergecast subtask .",
    "informally , this is a recursive process that is similar to a distributed dfs .",
    "the subtask starts at the root .",
    "each node @xmath36 which has woken - up , first wakes - up its first child ( that is , signals the first child to start ) .",
    "when the first child @xmath456 finishes ( delivering to @xmath36 all the pieces of information in @xmath456 s subtree ) , then @xmath36 wakes - up the next child , and so forth .",
    "each node holds two buffers of @xmath0 bits each for two pieces of the train , besides its own piece ( that it holds permanently ) .",
    "the node uses one of these buffers , called the _ incoming car _ , to read a piece from one of its children , while the other buffer , called the _ outgoing car _ is used to let its parent ( if it has one ) read the piece held by the node .",
    "a node @xmath457 participates in the following simple procedure whenever signaled by its parent to wake - up .",
    "let @xmath458 denote the children of @xmath36 in @xmath142 ( if any exists ) , ordered according to their corresponding port - numbers at @xmath36 ( i.e. , for @xmath431 , child @xmath459 is visited before @xmath449 in the dfs tour ) . + * train convergecast protocol * ( performed at each node @xmath457 ) + ( * using two buffers : incoming car and outgoing car * )    1 .",
    "copy @xmath36 s ( permanent ) piece into @xmath36 s outgoing car 2 .   for @xmath299 to @xmath460 (",
    "* @xmath460 is the number of @xmath36 s children * ) 1 .",
    "signal @xmath459 to start performing the train algorithm ; ( * wake - up @xmath459 * ) 2 .",
    "repeat until @xmath36 receives a signal `` finished '' from @xmath459 1 .",
    "copy the piece from the outgoing car of @xmath459 to @xmath36 s incoming car 2 .",
    "wait until @xmath36 s outgoing car is read by its parent ( * to accomplish that , @xmath36 reads the incoming car of its parent and compares it with its outgoing car * ) 3 .",
    "move the piece from the incoming car to outgoing car ( and , subsequently , empty the content of the incoming car ) ; 3 .",
    "report `` finished '' to parent ;    the train convergecast protocol of the root @xmath150 is slightly different . instead of waiting for its parent to read each piece",
    ", it waits for the train broadcast protocol ( at the root ) to read the piece to its own buffer .",
    "instead of reporting `` finished '' to its parent , it generates a new start to its first child .",
    "[ thm : train ] let @xmath461 be some time when the root @xmath462 of @xmath142 initiated the `` for '' loop of the train convergecast protocol .",
    "each node in @xmath142 sees the pieces in the cycle @xmath463 in @xmath0 time after  @xmath461 in synchronous networks and in @xmath19 time after  @xmath461 in asynchronous networks .",
    "first observe that the train broadcast in a leaf node of the part who received a piece from its parent , does not need to pass that piece to any further children .",
    "hence the train process does not incur a deadlock .    as mentioned before , once the root sees a piece , the broadcast protocol guarantees that this piece is delivered to all nodes in the part in @xmath368 time .",
    "let @xmath464 denote the maximal time period between two consecutive times that the broadcast protocol at the root reads the buffer of the convergecast protocol to take a new piece ( a piece is actually taken only if the convergecast has managed to bring there a new piece , after the broadcast process took the previous one ) .",
    "now , denote @xmath465 .    in synchronous networks",
    ", we have @xmath466 .",
    "in asynchronous networks , we have @xmath467 .",
    "the first part of the observation is immediate . to see why the second part of the observation holds ,",
    "note that by the definition of time , it takes @xmath468 for a chain of events that transfer a piece to a distance of @xmath369 , in the case that all the buffers on the way are free ; note that there is no deadlock and no congestion for information flowing down the tree , away from the root ; this can be seen easily by induction on the distance of a broadcast piece from the furthest leaf ; clearly , if the distance is zero , the piece is consumed , so there is already a room for a new piece ; the rest of the induction is also trivial . + we shall measure the time in _ phases _ , where each phase consists of @xmath469 time units .",
    "let us start counting the time after time @xmath461 , that is , we say that phase 0 starts at time @xmath461 .",
    "our goal now is to show that ( for either synchronous or asynchronous networks ) , for each @xmath470 , piece @xmath384 arrives at the root within @xmath0 phases .",
    "we say that a node @xmath36 is _ holding _ a piece at a given time if either ( 1 ) @xmath36 keeps the piece permanently , or ( 2 ) at the given time , the piece resides in either @xmath36 s incoming car or its outgoing car .",
    "consider now phase @xmath70 . for each  @xmath167 , where @xmath471 , if the root @xmath82 held @xmath384 at some time between @xmath461 and the beginning of the phase  @xmath70 , then we say that @xmath167 is _",
    "not @xmath70-relevant_. otherwise , @xmath167 is _",
    "@xmath70-relevant_. for any @xmath70-relevant @xmath167 , where @xmath471 , let @xmath472 denote the smallest dfs number of a node @xmath36 holding @xmath384 at the beginning of phase @xmath70 .",
    "that is , @xmath473 .",
    "for any @xmath167 that is not @xmath70-relevant , let @xmath474 .",
    "the following observation is immediate .",
    "[ obs : d ] at any time @xmath70 ,    * for any @xmath471 , we have @xmath475 ( in other words , @xmath472 can not increase with the phase ) . * for any @xmath470 , we have @xmath476 .    informally , the following lemma gives a bound for the delay of a piece as a result of processing previous pieces .",
    "[ lem : train ] let @xmath102 and @xmath167 be two integers such that @xmath477 .",
    "then , @xmath478  for   @xmath479 .",
    "to prove the lemma , first observe that the condition holds for the _ equality _ case , that is , the case where @xmath480 .",
    "indeed , for each @xmath481 , the node holding @xmath482 permanently is at distance at most @xmath483 from the root .",
    "hence , @xmath484 .",
    "now , the condition follows since , by observation  [ obs : d ] , @xmath485 can not increase with the phase .",
    "we now prove the lemma using a double induction .",
    "the first induction is on @xmath102 .",
    "the basis of the induction , i.e. , the case @xmath486 , is trivial , since it reduces to the equality case @xmath487 .",
    "assume by induction that the condition holds for @xmath483 and any @xmath167 , such that @xmath488 .",
    "we now prove that the condition holds for @xmath102 and any @xmath489 .",
    "this is done using a reverse induction on @xmath167 .",
    "the basis of this ( second ) induction , i.e. , the case @xmath480 , is an equality case and hence , it is already known to satisfy the desired condition .",
    "now assume by induction , that the condition holds for @xmath102 and @xmath167 , where @xmath490 , and let us show that it holds also for @xmath102 and @xmath199 .",
    "let us first consider the case @xmath491 . by the ( first ) induction hypothesis ( applied with values @xmath483 and @xmath299 ) , we know that    @xmath492 thus , at phase @xmath493 , piece @xmath494 is not @xmath495-relevant .",
    "that is , at that time , piece @xmath494 is either in the outgoing car of the root @xmath150 or in the root s incoming car . in the first case ,",
    "the incoming car of the root is already empty at @xmath495 .",
    "otherwise , recall that , by definition , the broadcast process at the root consumes a piece from @xmath150 s outgoing car every phase ( if there is a new piece there it has not taken yet ) .",
    "hence , the outgoing car at @xmath150 is consumed by phase @xmath496 . by that phase",
    ", the root notices the piece is consumed , deliverers the content of its incoming car ( namely , piece @xmath494 ) to its outgoing car , and empties its incoming car .    on the other hand , by the second induction hypothesis , @xmath497 at the beginning of phase @xmath498 .",
    "that is , @xmath482 is at some child @xmath36 of the root . by the second part of observation [ obs : d ] , node @xmath36 is the child the root reads next , and",
    ", moreover no piece other than @xmath482 is at the outgoing car of @xmath36 .",
    "if at the beginning of phase @xmath499 , piece @xmath482 is at the outgoing car of @xmath36 , then the piece reaches the incoming car of the root already at phase @xmath499 .",
    "otherwise , by at most phase @xmath500 , node @xmath150 has a copy of @xmath482 in its incoming car .",
    "this means that @xmath501 , where @xmath502 , as desired .    now consider the case that @xmath503 . by the second induction hypothesis",
    ", we have @xmath504 , where @xmath505 .",
    "if @xmath506 at the beginning of phase @xmath495 then we are done .",
    "otherwise , let @xmath36 be the node holding @xmath482 at the beginning of phase @xmath495 such that the distance ( on the tree ) of @xmath36 from @xmath82 is @xmath199 .",
    "let @xmath44 be @xmath36 s parent .",
    "our goal now is to show that @xmath44 holds @xmath482 by phase @xmath496 .",
    "the ( first ) induction hypothesis implies that the condition holds for the pair @xmath483 and @xmath507 .",
    "that is , @xmath508 thus , @xmath494 has already been copied to @xmath44 s parent @xmath80 .",
    "the only reason @xmath494 may be stuck at @xmath44 ( perhaps at both the incoming and outgoing cars of @xmath44 ) at phase @xmath509 , is that @xmath44 has not observed yet that its parent @xmath80 actually already copied @xmath494 .",
    "this is observed by @xmath44 by phase @xmath495 ( when @xmath44 observes this , it empties the content of its incoming car ) .",
    "thus , by phase @xmath496 , node @xmath44 has a copy of @xmath482 , as desired .",
    "this concludes the proof of the lemma .",
    "the theorem now follows from the lemma and from the fact that @xmath510 .    [",
    "[ recognizing - membership - to - arriving - fragments ] ] recognizing membership to arriving fragments : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    consider now the case that a piece containing @xmath134 carried by the broadcast wave arrives at some node @xmath36 . abusing notations , we refer to this event by saying that fragment @xmath111 _ arrives _ at @xmath36 .",
    "recall that @xmath36 does not  have  enough memory to remember the identifiers of all the fragments containing it .",
    "thus , a mechanism for letting  @xmath36 know  whether the arriving fragment @xmath111 contains @xmath36 must be employed .",
    "note that the level @xmath126 of @xmath111 can be extracted from  @xmath134 , and recall that it is already ensured that @xmath36 knows whether it is contained in some level @xmath126 fragment . obviously ,",
    "if @xmath36 is not contained in a level @xmath126 fragment then @xmath511 . if @xmath130 does exist , we now explain how to let @xmath36 know whether  @xmath512 .",
    "consider first a train in a part @xmath513 . here ,",
    "@xmath142 intersects at most one level @xmath126 top fragment , for each level  @xmath126 ( see lemma  [ lem : top ] ) .",
    "thus , this train carries at most one level @xmath126 fragment @xmath120 .",
    "hence , @xmath514 if and only if @xmath130 exists .    now consider a train in a part @xmath371 . in this case",
    ", part @xmath142 may intersect several bottom fragments of the same level . to allow a node @xmath36 to detect whether a fragment @xmath120 arriving at @xmath36 corresponds to fragment @xmath130 , we slightly refine the above mentioned train broadcast mechanism as follows . during the broadcast wave ,",
    "we attach a flag to each @xmath134 , which can be either `` on '' or `` off '' , where initially , the flag is `` off '' . recall that @xmath134 contains the identity @xmath181 of the root @xmath169 of @xmath111 .",
    "when the broadcast wave reaches this root @xmath169 ( or , when it starts in @xmath169 in the case that @xmath515 ) , node @xmath169 changes the flag to `` on '' .",
    "in contrast , before transmitting the broadcast wave from a leaf @xmath44 of @xmath111 to @xmath44 s children in @xmath18 ( that do not belong to @xmath111 ) , node @xmath44 sets the flag to  off  .",
    "that way , a fragment @xmath111 arriving at a node @xmath36 contains @xmath36 if and only if the corresponding flag is set to `` on '' .",
    "( recall that the data structure lets each node know whether it is a leaf of a level @xmath126 fragment . )",
    "this process allows each node @xmath36 to detect whether @xmath512 .",
    "to avoid delaying the train beyond a constant time , each node multiplexes the two trains passing via it .",
    "that is , it passes one piece of one train , then one piece of the other .",
    "fix a partition ( either @xmath144 or @xmath145 ) , and a part @xmath142 of the partition .",
    "node @xmath516 maintains two variables : @xmath517 and @xmath518 , each for holding one piece @xmath134 . in @xmath517",
    ", node @xmath44 keeps @xmath140 for some @xmath126 , until @xmath44 compares the piece @xmath140 with the piece @xmath139 , for each of its neighbours @xmath36 .",
    "let @xmath519 denote the event that node @xmath44 holds @xmath140 in @xmath517 and sees @xmath139 in @xmath520 .",
    "( for simplicity of presentation , we consider here the case that both @xmath44 and @xmath36 _ do _ belong to some fragments of level @xmath126 ; otherwise , storing and comparing the information for a non - existing fragments is trivial . ) for any point in time  @xmath70 , let @xmath521 denote the minimal time interval @xmath522 $ ] in which every event of the type @xmath519 occurred . for the scheme to function , it is crucial that @xmath521 exists for every time  @xmath70 .",
    "moreover , to have a fast scheme , we must ensure that @xmath523 is small .",
    "recall that the train ( that corresponds to @xmath142 ) brings the pieces @xmath134 in a cyclic order .",
    "when @xmath44 has done comparing @xmath140 with @xmath139 for each of its neighbours @xmath36 , node @xmath44 waits until it receives ( by the train ) the first piece @xmath134 following @xmath140 in the cyclic order , such that @xmath111 contains @xmath44 ( recall that @xmath44 can identify this  @xmath111 ) .",
    "let us denote the level of this next fragment @xmath111 by @xmath524 , i.e. , @xmath525 .",
    "node @xmath44 then removes @xmath526 from @xmath517 and stores @xmath527 there instead , and so  forth .",
    "each node @xmath44 also stores some piece @xmath528 at @xmath518 to be seen by its neighbours .",
    "( note that the value at @xmath518 may be different than the one at @xmath517 . )",
    "let us explain the comparing mechanism .",
    "assume that everything functions correctly .",
    "in particular , assume that the partitions and the distribution of the information are as described above , and the trains function correctly as well .",
    "let us first focus our attention on the simpler and seemingly more efficient synchronous case .",
    "fix a node @xmath36 . in a synchronous network ,",
    "node @xmath36 sees @xmath518 in every pulse , for each neighbour @xmath44 .",
    "let every node @xmath44 store in @xmath518 each piece that arrives in the train ( each time , replacing the previous content of @xmath518 ) .",
    "hence , by theorem [ thm : train ] , given a level @xmath126 , node @xmath36 sees @xmath526 ( if such exists ) within @xmath0 time . put differently , if @xmath36 waits some @xmath0 time ( while @xmath139 is in @xmath529 ) , node @xmath36 sees @xmath140 in @xmath518 for each neighbour @xmath44 .",
    "( we do not assume that @xmath44 keeps track of which neighbours @xmath36 has already seen @xmath140 ; node @xmath36 simply waits sufficient time  to allow one cycle of the train , while looking at its neighbours , looking for their @xmath141 for level @xmath126 . )",
    "subsequently , node @xmath36 waits another @xmath0 rounds until the train brings it @xmath530 and stores it in @xmath529 , and so forth . in other words , we have just established that event @xmath531 occurs within @xmath0 time after @xmath36 stores @xmath530 in @xmath529 , which happens @xmath0 time after event @xmath532 , and so forth .",
    "the time for at most @xmath533 such events to occur ( one per level @xmath126 ) is @xmath19 .",
    "[ lem : synchronous - time ] in a synchronous environment , for each node @xmath36 and its neighbour @xmath44 , all events of type @xmath532 ( for all levels @xmath126 ) occur within time @xmath534 .      in an asynchronous network , without some additional kind of a handshake , node @xmath44 can not be sure that the piece in @xmath518 was actually seen by its neighbours .",
    "( intuitively , this is needed , so that @xmath44 can replace the piece with the next one . )",
    "moreover , it is not easy to perform such handshakes with all of @xmath44 s neighbours , since @xmath44 does not have enough memory to keep track on which of its neighbours @xmath36 has seen the piece and which has not yet .",
    "first , let us describe a simple , but somewhat inefficient handshake solution .",
    "a more efficient one is presented later .",
    "each node @xmath36 , holding some piece @xmath139 in @xmath529 , selects a neighbour @xmath44 and acts as a `` client '' : that is , node @xmath36 writes in its register @xmath535 the pair @xmath536 .",
    "node @xmath36 then looks repeatedly at @xmath518 until it sees @xmath140 there . at the same time",
    ", each node @xmath44 also has a second role  that of a `` server '' .",
    "that is , each node rotates these two roles : it performs one atomic action as a server and one as a client .",
    "acting as a server , @xmath44 selects a client to serve ( in a round robin order ) .",
    "if the client has written some @xmath537 in the client s @xmath535 , for @xmath538 , then @xmath44 chooses another client .",
    "on the other hand , if the client wrote @xmath536 in the client s @xmath535 , then @xmath44 waits until it receives by the train @xmath140 and stores it in @xmath518 .",
    "a trivial handshake then suffices for @xmath44 to know that this value has been read by the client .",
    "node @xmath44 , in its role as a server , can then move to serve its next neighbour , and node @xmath36 , in its role as a client , can move on to the next server .",
    "in particular , if the client @xmath36 has already received service from all its neighbours for @xmath139 , then @xmath36 waits until the train brings it the next piece @xmath530 that @xmath36 needs to compare .",
    "consider now the time a client @xmath36 waits to see @xmath140 for one of its neighbours @xmath44 . before serving @xmath36 , the server",
    "@xmath44 may serve @xmath539 neighbours . by theorem [ thm : train ] ( applied for the asynchronous setting ) , each service takes @xmath19 time .",
    "in addition , the client needs services from @xmath3 servers , and for @xmath0 values of @xmath126 .",
    "the total time for all the required events to happen in this simple handshake mechanism is , thus , @xmath540 .",
    "let us now describe the more efficient asynchronous comparison mechanism that requires only @xmath2 time . before dwelling into the details of the comparison mechanism ,",
    "let us first describe a difference in the way we employ the train . recall that in the simple solution above ( as well as in the synchronous case ) , the movement of trains was independent from the actions of the comparison mechanism , and hence , by theorem [ thm : train ]",
    ", each train finishes a cycle in @xmath19 time .",
    "in contrast , a train here may be delayed by the nodes it passes , in a way to be described .",
    "crucially , as we show later , the delay at each node is at most some constant time @xmath194 , and hence , the time a train finishes a cycle remains asymptotically the same , namely , @xmath19 .",
    "as before , node @xmath36 , holding @xmath139 in @xmath529 chooses a server @xmath44 among @xmath36 s neighbours and reads @xmath518 . another small , but crucial addition to the actions taken in the simple procedure , is the following : if , when reading @xmath518 , node @xmath36 reads @xmath140 , then @xmath532 occurred , and @xmath36 moves on to read another neighbour .",
    "this is illustrated in figures [ fig : handshake1 ] and [ fig : handshake2 ] .    only in the case that @xmath140 is not at @xmath518 at that time ( see figure [ fig : handshake3 ] ) , node @xmath36 sets @xmath541 ( see figure [ fig : handshake4 ] ) . in this case",
    ", we say that @xmath36 _ files a request for _",
    "@xmath126 _ at _ @xmath44 .",
    "this request stays filed until the value of @xmath518 is the desired one and @xmath532 occurs .",
    "similarly to the synchronized setting , in the case that  @xmath36 has just finished seeing @xmath140 in every neighbour @xmath44 , node @xmath36 first waits until it gets by the train , the next piece @xmath530 in the cycle , and then puts @xmath530 as the new content of @xmath529 .",
    "now consider any node @xmath44 in its role as a server .",
    "it reads all the clients .",
    "( recall that the ideal time complexity assumes this can be performed in one time unit . )",
    "when node @xmath44 receives @xmath140 from the train , it puts this value in @xmath518 .",
    "it now delays the train as long as it sees any client @xmath36 whose @xmath542 .",
    "in particular , node @xmath44 keeps @xmath140 in @xmath518 during this delay time period . if @xmath44 has not read any neighbour @xmath36 such that @xmath542 , then @xmath44 stops delaying the train , waits for receiving the next piece @xmath527 from the train , and uses it to replace the content of @xmath518",
    ".     receives the next piece ( for @xmath543 ) to compare . ]",
    "occurred the first time @xmath36 reads @xmath544 .",
    "next , @xmath36 may look at its next node , @xmath80 . ]",
    "does not occur immediately . ]",
    "files a request at @xmath44 for @xmath543 . ]     and at @xmath44 do not stop . ]",
    "received the requested piece at last . ]",
    "we define the @xmath545 cycle of a node @xmath36 .",
    "this is the time interval starting at the time a client @xmath36 replaces the content of @xmath529 from @xmath546 to @xmath547 , and until ( and excluding ) the time @xmath36 does that again . here , @xmath548 is the highest level of a piece in that train , such that @xmath549 exists , and @xmath550 is the smallest level of a piece in that train , such that @xmath551 exists .",
    "[ lem : cycle - time ] the total length of a @xmath545 cycle of a node @xmath36 is @xmath17 .",
    "fix a node @xmath44 and let @xmath552 be some time that @xmath44 starts storing @xmath140 in @xmath518 , for some level @xmath126 ; moreover , @xmath140 is stored there until some time @xmath553 when @xmath44 replaces the content of @xmath518 again .",
    "recall , node @xmath44 delays the train and keeps @xmath140 in @xmath518 as long as it sees any client @xmath36 such that @xmath542 ; when it sees that no such neighbour @xmath36 exists , it stops delaying the train and waits for the train to deliver it the next piece @xmath527 to be used for replacing the content of @xmath518 .",
    "we now claim that the delay time period at node @xmath44 is at most some constant time . to prove that",
    ", we first show that there exists a constant @xmath194 such that no client @xmath36 has @xmath542 in the time interval @xmath554 $ ] . indeed ,",
    "for each neighbour @xmath36 of @xmath44 , let @xmath555 be the first time after @xmath552 that @xmath36 reads the value of @xmath518 .",
    "clearly , there exists a constant @xmath194 ( independent of @xmath44 and @xmath36 ) such that @xmath556 $ ] .",
    "right at time @xmath555 , the content of @xmath557 stops being @xmath558 ( if it were before ) , since @xmath140 is the value of @xmath518 during the whole time interval @xmath559 $ ] .",
    "moreover , during the time interval @xmath560 $ ] , node @xmath36 does not file a request for @xmath126 at @xmath44 , since again , whenever it reads @xmath518 during that time interval , it sees @xmath140 .",
    "hence , no client @xmath36 has @xmath542 in the time interval @xmath554 $ ] .",
    "now , from time @xmath561 , it takes at most some constant time to let @xmath44 observe that none of its neighbours @xmath36 has @xmath542 .",
    "this establishes the fact that the delay of the train at each node is at most some constant .",
    "hence , as mentioned before , the time the train finishes a cycle is @xmath19 .",
    "( it is also easy to get convinces that this delay does not prevent the train from being self - stabilizing . )    next , consider the time that some node @xmath36 starts holding @xmath139 in @xmath529 . consider a neighbour  @xmath44 of  @xmath36 .",
    "the time it takes for @xmath36 until it sees @xmath140 in @xmath518 is @xmath19 .",
    "hence , a client @xmath36 waits @xmath19 for each request @xmath36 files at a server @xmath44 for a value @xmath126 .",
    "the total time that @xmath36 waits for a service of @xmath126 at all the servers is then @xmath562 . from that time",
    ", @xmath36 needs to wait additional @xmath19 time to receive from the train the next piece @xmath530 ( to replace the content of @xmath529 ) . summing this over the @xmath0 pieces in the cycle ,",
    "we conclude that the total time of an @xmath545 cycle of @xmath36 is @xmath17 .",
    "[ lem : time - sync ] if ( 1 ) two partitions are indeed represented , such that each part of each partition is of diameter @xmath0 , and the number of pieces in a part is @xmath0 , and ( 2 ) the trains operate correctly , then the following holds .    * in a synchronous network , @xmath563 . * in an asynchronous network , @xmath564 .",
    "[ sec : verifying ] [ sub:3.3 ] in this section , we describe the measures taken in order to make the verifier self - stabilizing .",
    "that is , the train processes , the partitions , and also , the pieces of information carried by the train may be corrupted by an adversary . to stress this point and avoid confusion , a piece of information of the form @xmath565 , carried by a train , is termed the _ claimed _ information @xmath566 of a fragment @xmath111 whose root @xmath138 is @xmath567 , whose level is @xmath126 , and whose minimum outgoing edge is @xmath568 .",
    "note that such a fragment @xmath111 may not even exist , if the information is corrupted .",
    "conversely , the adversary may also erase some ( or even all ) of such pieces corresponding to existing fragments .",
    "finally , even correct pieces that correspond to existing fragments may not arrive at a node in the case that the adversary corrupted the partitions or the train mechanism .",
    "below we explain how the verifier does detect such undesirable phenomena , if they occur .",
    "note that for a verifier , the ability to detect with assuming any initial configuration means that the verifier is self - stabilizing , since the sole purpose of the verifier is to detect .",
    "we show , in this section , that if an mst is not represented in the network , this is detected .",
    "since the detection time ( the stabilization time of the verifier ) is sublinear , we still consider this detection as local , though some of the locality was traded for improving the memory size when compared with the results of @xcite .",
    "verifying that _ some _ two partitions exist is easy .",
    "it is sufficient to ( 1 ) let each node verify that its label contains the two bits corresponding to the two partitions ; and ( 2 ) to have the root @xmath110 of the tree verify that the value of each of its own two bits is 1 .",
    "( observe that if these two conditions hold then ( 1 ) @xmath110 is a root of one part in each of the two partitions ; and ( 2 ) for a node @xmath569 , if one of these two bits in @xmath36 is zero , then @xmath36 belongs to the same part in the corresponding partition as its parent . )",
    "note that this module of the algorithm self - stabilizes trivially in zero time .",
    "it seems difficult to verify that the given partitions are as described in section [ sec : partitions ] , rather than being two arbitrary partitions generated by an adversary .",
    "fortunately , this verification turns out to be unnecessary .",
    "( as we shall see , if the components at the nodes do not describe an mst , no adversarial partitioning can cause the verifier to accept this as representing an mst ; if partitions are represented , we just need to verify that a part is not too large for the time complexity ) .    first , for the given partitions , it is a known art to self - stabilize the train process .",
    "that is , the broadcast part of the train is a standard flooding , for which the self stabilization has been heavily studied , see , in particular , @xcite . for the convergecast , first , note that pieces are sent up the tree .",
    "hence , they can not cycle , and can not get `` stuck '' .",
    "moreover , it is easy to get convinced that only pieces that are already in some buffer ( either incomming , or outgoing , or permanent ) can be sent .",
    "finally , notice that the order of the starting of the nodes is exactly the dfs order .",
    "the stabilization of the dfs process is well understood @xcite .",
    "it is actually easier here , since this is performed on a tree ( recall that another part of the verifier verifies that there are no cycles in the tree ) .",
    "finally , composing such self - stabilizing primitives in a self - stabilizing manner is also a known art , see e.g.  @xcite . in our context , once the dfs part stabilizes , it is easy to see the pieces flow up the tree stabilizes too .",
    "this leads to the following observation .",
    "[ obs : train - sync ] starting at a time that is @xmath0 after the faults in synchronous networks , and @xmath19 time in asynchronous networks , the trains start delivering only pieces that are stored permanently at nodes in the part .    _",
    "after _ the trains stabilize ( in the sense described in observation [ obs : train - sync ] ) , what we want to ensure at this point is that the set of pieces stored in a part ( and delivered by the train ) includes all the ( possibly corrupted ) pieces of the form @xmath139 , for every @xmath36 in the part and for every @xmath126 such that @xmath36 belongs to a level @xmath126 fragment . addressing this",
    ", we shall show that the verifier at each node rejects if it does not obtain all the required pieces eventually , whether the partitions are correct or not .",
    "informally , this is done as follows . recall that each node @xmath36 knows the set @xmath570 of levels @xmath126 for which there exists a fragment of level @xmath126 containing it , namely , @xmath130 . using a delimiter ( stored at @xmath36 ) ,",
    "we partition @xmath570 to @xmath571 and @xmath572 ; where @xmath571 ( respectively , @xmath572 ) is the set of levels @xmath573 such that @xmath130 is top ( resp . ,",
    "bottom ) .",
    "node @xmath36 `` expects '' to receive the claimed information @xmath574 for @xmath575 ( respectively , @xmath576 ) from the train of the part in @xmath144 ( respectively , @xmath145 ) it belongs to .",
    "let us now consider the part @xmath577 containing @xmath36 .",
    "in correct instances , by the way the train operates , it follows that the levels of fragments arriving at @xmath36 should arrive in a strictly _ increasing order _ and in a _",
    "cyclical _ manner , that is , @xmath578 ( observe that @xmath579 ) .",
    "consider the case that the verifier at @xmath36 receives two consecutive pieces @xmath580 and @xmath581 such that @xmath582 .",
    "the verifier at @xmath36 then `` assumes '' that the event @xmath583 of the arrival of the second piece @xmath581 starts a new cycle of the train .",
    "let the set of pieces arriving at @xmath36 between two consecutive such @xmath583 events be named a _",
    "cycle set_. to be `` accepted '' by the verifier at @xmath36 , the set of levels of the fragments arriving at @xmath36 in each cycle set must contain @xmath584 .",
    "it is trivial to verify this in two cycles after the faults cease .",
    "( the discussion above is based implicitly on the assumption that each node receives pieces infinitely often ; this is guaranteed by the correctness of the train mechanism , assuming that at least one piece is indeed stored permanently in @xmath585 ; verifying this assumption is done easily by the root @xmath586 of @xmath585 , simply by verifying that @xmath586 itself does contain a piece . ) verifying the reception of all the pieces in a part in @xmath145 is handled very similarly , and is thus omitted .",
    "hence , we can sum up the above discussion as follows :    [ claim : received - info ] if the verifier accepts then each node @xmath36 receives @xmath574 , for every level @xmath573 ( in the time stated in lemma [ lem : time - sync ] ) , and conversely , if a node does not receive @xmath574 ( in the time stated in lemma [ lem : time - sync ] ) then the verifier has rejected .",
    "let @xmath587 denote the parent of @xmath36 in @xmath18 .",
    "recall , that by comparing the data structure of a neighbour @xmath44 in @xmath18 , node @xmath36 can know whether @xmath44 and @xmath36 belong to the same fragment of level @xmath126 , for each @xmath126 . in particular , this is true for @xmath44 being the parent of @xmath36 in @xmath18 .",
    "consider an event @xmath588 . in case",
    "@xmath587 belongs to the same level @xmath126 fragment as @xmath36 , node @xmath36 compares @xmath574 with @xmath589 , and verifies that these pieces are equal ( otherwise , it rejects ) . by transitivity ,",
    "if no node rejects , it follows that for every fragment @xmath220 , we have that @xmath566 is of the form @xmath565 , and all nodes in @xmath111 agree on this . by verifying at the root @xmath590 of @xmath111 that @xmath591 , we obtain the following .",
    "if the verifier accepts then :    * the claimed identifiers of the fragments are compatible with the given hierarchy @xmath119 .",
    "in particular , this guarantees that the identifiers of fragments are indeed unique .",
    "* for every @xmath122 , all the nodes in @xmath111 agree on the _ claimed _ weight of the minimum outgoing edge of fragment @xmath111 , denoted @xmath592 , and on the identifier of fragment @xmath111 , namely , @xmath132 .",
    "so far , we have shown that each node does receive the necessary information needed for the verifier .",
    "now , finally , we show how to use this information to detect whether this is an mst .",
    "basically , we verify that @xmath592 is indeed the minimum outgoing edge @xmath593 of @xmath111 and that this minimum is indeed the candidate edge of @xmath111 , for every @xmath220 .",
    "consider a time when @xmath532 occurs .",
    "node @xmath36 rejects if any of the checks below is not valid .    *",
    "* c1 : * if @xmath36 is the endpoint of the candidate edge @xmath43 of @xmath130 then @xmath36 checks that @xmath44 does not belong to @xmath130 , i.e. , that @xmath594 , and that @xmath595 ( recall , it is already ensured that @xmath36 knows whether it is an endpoint , and if so , which of its edges is the candidate ) ; * * c2 : * if @xmath594 then @xmath36 verifies that @xmath596 .",
    "the following lemma now follows from c1 , c2 and lemma  [ lem : construction ] .",
    "[ lem : self - stab - verifier ]    * if by some time @xmath70 , the events @xmath532 occurred for each node @xmath36 and each neighbour @xmath44 of @xmath36 in @xmath11 and for each level  @xmath126 , and the verifier did not reject , then @xmath18 is an mst of @xmath11 . *",
    "if @xmath597 is not an mst , then in the time stated in lemma  [ lem : time - sync ] after the faults cease , the verifier rejects .",
    "we are now ready for the following theorem , summarizing sections [ sec : mst - construction ] to [ sec : verifying ] .",
    "[ thm : verification - properties ] the scheme described in sections [ sec : mst - construction][sec : verifying ] is a correct proof labeling scheme for mst .",
    "its memory complexity is @xmath0 bits .",
    "its detection time complexity is @xmath19 in synchronous networks and @xmath149 in asynchronous ones .",
    "its detection distance is @xmath6 if @xmath5 faults occurred .",
    "its construction time is @xmath7 .",
    "the correctness and the specified detection time complexity follow from lemma  [ lem : self - stab - verifier ] and claim  [ claim : received - info ] .",
    "the space taken by pieces of @xmath141 stored permanently at nodes ( and rotated by the trains ) was already shown to be @xmath0 bits .",
    "in addition , a node needs some additional @xmath0 bits of memory for the actions described in section [ sub : utilizing ] .",
    "similarly , the data - structure at each node and the corresponding @xmath59-proof labeling schemes ( that are used to verify it ) consume additional @xmath0 bits .",
    "finally , for each train , a node needs a constant number of counters and variables , each of logarithmic size .",
    "this establishes the required memory size of the scheme .    to show the detection distance ,",
    "let network @xmath598 contain faults .",
    "consider a ( not necessarily connected ) subgraph @xmath599 containing every faulty node @xmath36 , every neighbour @xmath44 of @xmath36 , and the parts , both of @xmath145 and of @xmath144 of @xmath36 and @xmath44 .",
    "first , we claim that no node outside of @xmath599 will raise an alarm . to see that ,",
    "assume ( by way of contradiction ) that some node @xmath80 outside @xmath599 does raise an alarm .",
    "now , consider a different network @xmath600 with the same sets of nodes and of edges as @xmath598 .",
    "the state of every node in @xmath601 is exactly the ( correct ) state of the same node in @xmath598 .",
    "the states of the nodes in @xmath599 are chosen so that to complete the global configuration to be correct .",
    "( clearly , the configuration can be completed in such a way . ) hence , no node should raise an alarm ( since we have shown that our scheme is correct ) .",
    "however , node @xmath80 in @xmath600 receives exactly the same information it receives in @xmath598 , since it receives only information from nodes in the parts to which it or its neighbours belong .",
    "hence , @xmath80 will raise an alarm . a contradiction .",
    "the detection distance complexity now follows from the fact that the radius of @xmath599 is @xmath602 .",
    "( informally , this proof also says that non - faulty nodes outside of @xmath599 are not contaminated by the faulty nodes , since the verification algorithm sends information about the faulty nodes only within @xmath599 . )",
    "the construction time complexity required for the more complex part of the proof labeling scheme , that is , the proof scheme described in sections [ sec : proof][sec : verifying ] , is dominated by the construction time of the mst algorithm @xmath123 .",
    "this time is shown to be @xmath7 in theorem  [ thm : alg ] . the construction time required for the simpler 1-proof labeling scheme described in section  [ sec : section5 ]",
    "is shown to be linear in lemma [ lem : simple - proof ] .",
    "we now show that any proof labeling scheme for mst that uses optimal memory must use at least logarithmic time complexity , even when restricted to synchronous networks . the lower bound is derived below from the relatively complex lower bound for 1-proof labeling schemes for mst presented in @xcite , by a not- too- difficult reduction from that problem .",
    "we prove the lower bound on the specific kind of networks used in @xcite .",
    "these networks are a family of weighted graphs termed @xmath603_-hypertrees_. ( the name may be misleading ; a @xmath603-hypertrees is neither a tree nor a part of a hyper graph ; the name comes from them being a combination of @xmath603-trees ( see also @xcite ) and hypercubes . )",
    "we do no describe these hypertrees here , since we use them , basically , as black boxes .",
    "that is , all we need here is to know certain properties ( stated below ) of these graphs .",
    "( we also need to know the lower bound of @xcite ) .",
    "the following two properties of this family were observed in @xcite .",
    "first , all @xmath603-hypertrees are identical if one considers them as unweighted .",
    "in particular , two homologous nodes in any two @xmath603-hypertrees have the same identities .",
    "moreover , the components assigned to two homologous graphs in @xcite are the same .",
    "hence , the ( unweighted ) subgraphs @xmath39 induced by the components of any two @xmath603-hypertrees are the same .",
    "the second property that was observed is that this subgraph @xmath39 is in fact a ( rooted ) spanning tree of @xmath11 , the corresponding @xmath603-hypertree .",
    "another easy observation that can be obtained by following the recursive construction of an @xmath603-hypertree ( see section 4 of @xcite ) , is that each node in an @xmath603-hypertree @xmath11 is adjacent to at most one edge which is not in the tree @xmath39 , and that the root of @xmath39 is adjacent only to edges in @xmath39 .",
    "fix an integer @xmath469 . given a @xmath603-hypertree @xmath11",
    ", we transform @xmath11 into a new graph @xmath604 according to the following procedure ( see figures [ fig : lower1 ] and [ fig : lower2 ] ) .",
    "we replace every edge @xmath605 in @xmath11 where @xmath606 with a simple path @xmath607 containing @xmath608 consecutive nodes , i.e. , @xmath609 , where @xmath610 , and @xmath611 . for @xmath612 , the port number at @xmath613 of the port leading to @xmath614 ( respectively , @xmath615 is 1 ( resp . , 2 ) .",
    "the port - number at @xmath616 ( respectively , @xmath617 of the port leading to @xmath618 ( resp .",
    ", @xmath619 is the same as the port - number of the port leading from @xmath44 ( resp .",
    ", @xmath620 to @xmath36 ( resp .",
    ", @xmath621 in @xmath11 .",
    "the weight of the edge @xmath622 is the weight of @xmath605 , that is , @xmath623 , and the weight of all other edges in @xmath607 is 1 .",
    "the identities of the nodes in the resulted graph are given according to a dfs traversal on @xmath604 .",
    "we now describe the component of each node in @xmath604 .",
    "let @xmath605 be an edge in @xmath11 and let @xmath624 be the corresponding path in @xmath604 , where @xmath610 and @xmath611 ( here we do not assume necessarily that @xmath625 .",
    "consider first the case that in the graph @xmath11 , the edge @xmath605 belongs to the tree @xmath39 .",
    "assume without loss of generality that the component of @xmath44 in @xmath11 points at @xmath36 .",
    "for each @xmath626 , we let the component at @xmath613 point at @xmath627 ( the component at @xmath628 is the same as the component of @xmath36 in @xmath629 .",
    "consider now the case that @xmath605 does not belong to @xmath39 .",
    "in this case , for @xmath630 , we let the component at @xmath613 point at @xmath614 ( the component at @xmath610 in @xmath604 is the same as the component of @xmath44 in @xmath629 and for @xmath631 , we let the component at @xmath613 point at @xmath627 ( similarly , the component at @xmath628 is the same as the component of @xmath36 in  @xmath629 .     ( the upper part ) to a path of @xmath604 ( the lower part ) for @xmath466 and the case that the component of @xmath44 points at @xmath36 .",
    "the component of @xmath36 points at @xmath36 s port 1 . ]     points at @xmath44 s port 3 that does not lead to @xmath36 , and the component of @xmath36 points at @xmath36 s port 1 that does not lead to @xmath44 . ]    by this construction of @xmath604 , we get that the subgraph @xmath632 induced by the components of @xmath604 is a spanning tree of @xmath604 , and it is an mst of @xmath604 if and only if @xmath39 is an mst of @xmath11 .",
    "let @xmath633 be the family of all weighted graphs @xmath604 obtained by transforming every @xmath603-hypertree @xmath11 into @xmath604 using the method explained above .",
    "if there exists a proof labeling scheme for mst on the family @xmath633 with memory complexity @xmath226 and detection time @xmath469 then there exists a @xmath59-proof labeling scheme ( a proof labeling scheme in the sense of @xcite ) for the mst predicate on the family of @xmath603-hypertrees with label size @xmath634 .",
    "let @xmath635 be a proof labeling scheme for mst and the family @xmath633 with memory complexity @xmath226 and detection time @xmath469 .",
    "we describe now a 1-proof labeling scheme @xmath71 for the mst predicate on the family of @xmath603-hypertrees .",
    "let @xmath11 be an @xmath603-hypertree that satisfies the mst predicate .",
    "we first describe the labels assigned by the marker @xmath64 to the nodes on @xmath11 . in this lemma , we are not concerned with the time needed for actually assigning the labels using a distributed algorithm , hence , we describe the marker @xmath64 as a centralized algorithm and not as a distributed one .",
    "( we note that this is consistent with the model of @xcite that considers only centralized marker algorithms . )",
    "the marker @xmath64 transforms @xmath11 to @xmath604 .",
    "observe that @xmath604 must also satisfy the mst predicate .",
    "@xmath64 labels the nodes of @xmath604 using the marker @xmath636 .",
    "note that any label given by the marker @xmath636 uses at most @xmath226 bits . given a node @xmath637 ,",
    "let @xmath638 be the edge not in the tree @xmath39 that is adjacent to @xmath44 ( if one exists ) and let @xmath639 be the edge in @xmath39 leading from @xmath44 to its parent in @xmath39 ( if one exists ) .",
    "let @xmath640 be the path in @xmath604 corresponding to @xmath638 .",
    "if @xmath44 is not the root of @xmath39 then @xmath639 exists and let @xmath641 be the path in @xmath604 corresponding to @xmath639 , where @xmath642 and @xmath643 is the parent of @xmath44 . for the root @xmath82 of @xmath39 ,",
    "let @xmath644 be simply @xmath645 .",
    "if @xmath44 is not the root of @xmath39 then for each @xmath646 , the marker @xmath64 copies the labels @xmath647 and @xmath648 into the @xmath167th field in the label @xmath649 .",
    "( note that the labels @xmath648 are copied in the labels given by @xmath64 to both end - nodes of @xmath638 . )",
    "if @xmath82 is the root of @xmath39 then @xmath650 does not exist and actually , also @xmath651 does not exist , as @xmath82 is not adjacent to any edge not in @xmath39 .",
    "the marker @xmath64 simply copies the label @xmath652 into the label @xmath653 , where @xmath127 is the corresponding node of @xmath82 in @xmath604 .    in the model of proof labeling schemes in @xcite , the verifier @xmath67 at a node",
    "@xmath637 can look at the labels of all nodes @xmath36 such that @xmath605 is an edge of @xmath11 .",
    "in particular , it sees the labels assigned by @xmath636 to all nodes in @xmath604 at distance at most @xmath654 from its corresponding node @xmath655 in @xmath604 .",
    "let @xmath656 be the set of nodes at distance at most @xmath469 from @xmath655 in @xmath604 .",
    "we let the verifier @xmath67 at @xmath44 simulate the operations of the verifier @xmath657 at each node in @xmath656this can be achieved as the information in the @xmath59-neighbourhood of @xmath44 ( in @xmath629 contains the information in the @xmath469-neighbourhood of @xmath604 of any node in @xmath656 .",
    "finally , we let @xmath658 if and only if @xmath659 for all @xmath660 .",
    "it can be easily observed that @xmath71 is indeed a @xmath59-proof labeling scheme for the family of @xmath603-hypertrees .",
    "moreover , each label assigned by the marker @xmath64 uses @xmath634 bits .",
    "( note that the model in @xcite restricts only the sizes of the labels and not the memory size used by the verifier . )",
    "this completes the proof of the lemma .",
    "fix a positive integer @xmath661 .",
    "the memory complexity of any proof labeling scheme for @xmath63 with detection time @xmath469 is @xmath662 .",
    "( recall @xmath63 represents all connected undirected weighted graphs . )    in @xcite we showed that the label size of any proof labeling scheme for the mst predicate and the family of @xmath663-hypertrees is @xmath8 bits .",
    "the claim now follows by combining the previous lemma together with the fact that the number of nodes in a graph @xmath664 is polynomial in @xmath14 .",
    "[ scheme ]    we use a transformer that inputs a non - self - stabilizing algorithm and outputs a self - stabilizing one . for simplicity , we first explain how to use the transformer proposed in the seminal paper of awerbuch and varghese @xcite ( which utilizes the transformer of its companion paper @xcite as a black box ) .",
    "this already yields a self - stabilizing mst algorithm with @xmath7 time and @xmath0 memory per node .",
    "later , we refine that transformer somewhat to add the property that the verification time is of @xmath19 in a synchronous network , or @xmath665 in an asynchronous one .",
    "we then also establish the property that if @xmath5 faults occur , then each fault is detected within its @xmath602 neighbourhood .",
    "the resynchronizer of @xcite inputs a non - stabilizing synchronous input / output algorithm @xmath666 whose running time and memory size are some @xmath667 and @xmath668 , respectively .",
    "another input it gets is @xmath669 , which is an _ upper bound _ on the actual diameter @xmath23 of the network .",
    "it then yields a self - stabilizing version whose memory size is @xmath670 and whose time complexity is @xmath671 .",
    "for our purposes , to have the resynchronizer yield our desired result , we first need to come up with such a bound @xmath669 on the diameter .",
    "( recall that we do _ not _ assume that @xmath23 , or even @xmath14 , are known ) .",
    "second , the result of the resynchronizer of @xcite is a synchronous algorithm , while we want an algorithm that can be executed in an asynchronous network .",
    "let us describe how we bridge these two gaps .",
    "we use known self - stabilizing protocols @xcite to compute  @xmath23 , the diameter of the network , in time @xmath7 , using @xmath0 bits of memory per node .",
    "we use this computed @xmath23 as the desired @xmath669 . note that at the time that  @xcite was written , the only algorithm for computing a good bound ( of @xmath672 on the diameter with a bounded memory had time complexity @xmath673 @xcite .    to bridge the second gap , of converting the resulting self - stabilizing algorithm for an _ asynchronous _ network",
    ", we use a _ self - stabilizing synchronizer _ that transforms algorithms designed for synchronous networks to function correctly in asynchronous ones .",
    "such a synchronizer was not known at the time that  @xcite was written , but several are available now .",
    "the synchronizer of @xcite was first described as if it needs unbounded memory .",
    "however , as is stated in @xcite , this synchronizer is meant to be coupled with a reset protocol to bound the memory .",
    "that is , to have a memory size of @xmath0 and time @xmath7 , it is sufficient to use a reset protocol with these complexities .",
    "we use the reset protocol of @xcite .",
    "similarly , this reset protocol is meant to be coupled with a self - stabilizing spanning tree construction algorithm .",
    "the complexities of the resulting reset protocol are dominated by those of the spanning tree construction .",
    "we plug in some spanning tree algorithm with the desired properties ( such as @xcite ) whose memory size and time complexities are the desired @xmath0 and @xmath7 in asynchronous networks , respectively .",
    "( it is easy to improve the time to @xmath26 in synchronous networks . )",
    "this yields the desired reset protocol , and , hence , the desired synchronizer protocol . ] .",
    "[ eav ] * enhanced awerbuch - varghese theorem , ( eav ) : * assume we are given a distributed algorithm  @xmath666 to compute an input / output relation . whether @xmath666 is synchronous or asynchronous , let @xmath667 and @xmath668 denote @xmath666 s time complexity and memory size , respectively , when executed in synchronous networks .",
    "the enhanced resynchronizer compiler produces an asynchronous ( respectively , synchronous ) self - stabilizing algorithm whose memory size is @xmath674 and whose time complexity is @xmath675 ( resp .",
    ", @xmath676 .",
    "the eav theorem differs from the result in @xcite by ( 1 ) addressing also asynchronous algorithms , and ( 2 ) basing the time complexity on the actual values of @xmath14 and @xmath23 of the network rather than on an a - priori bound @xmath677 that may be arbitrarily larger than @xmath23 or @xmath14 .",
    "recall from theorem [ thm : alg ] that in synchronous networks , algorithm @xmath123 constructs an mst in @xmath7 time and using @xmath0 memory bits per node .",
    "hence , plugging in algorithm @xmath123 as @xmath666 yields the following theorem .",
    "the resynchronizer compiler performs iterations forever .",
    "essentially , the first iteration is used to compute the result of @xmath666 , by executing @xmath666 plus some additional components needed for the self - stabilization .",
    "each of the later iterations is used to check that the above result is correct . for that",
    ", the resynchronizer executes a _",
    "checker_. if the result is not correct , then the checker in at least one node `` raises an alarm '' .",
    "this , in effect , signals the resynchronizer to drop back to the first iteration .",
    "let us term such a node a _ detecting node_. our refinement just replaces the checker , interfacing with the original resynchronizer by supplying such a detecting node .",
    "we should mention that the original design in @xcite is already modular in allowing such a replacement of a checker .",
    "in fact , two alternative such checkers are studied in @xcite .",
    "the first kind of a checker is @xmath666 itself .",
    "that is , if @xmath666 is deterministic , then , if executed again , it must compute the same result again ( this is adjusted later in @xcite to accommodate randomized protocols ) .",
    "this checker functions by comparing the result computed by @xmath666 in each `` non - first '' iteration to the result it has computed before .",
    "if they differ , then a fault is detected .",
    "the second kind of a checker is a local checker of the kinds studied in @xcite or even one that can be derived from local proofs @xcite .",
    "that is , a checker whose time complexity is exactly  1 .",
    "when using this kind of a checker , the resynchronizer uses one iteration to execute  @xmath666 , then the resynchronizer executes the checker repeatedly until a fault is detected .",
    "it was argued in @xcite that the usage of such a checker ( of time complexity exactly @xmath59 ) is easy , since such a checker self - stabilizes trivially .",
    "we stress that it was later shown that such a checker ( whose time complexity is 1 ) must use @xmath8 bits  @xcite .",
    "hence , plugging such a checker into the resynchronizer compiler can not yield an optimal memory self - stabilizing algorithm .",
    "the door was left open in @xcite for additional checkers .",
    "it was in this context that they posed the open problem of whether mst has a checker which is faster than mst computation , and still uses small memory .",
    "( recall that theorem [ thm : verification - properties ] answers the open problem in the affirmative . )",
    "we use a self - stabilizing verifier ( of a proof labeling scheme ) as a checker .",
    "that is , if a fault occurs , then the checker detects it , at least in one node , regardless of the initial configuration .",
    "such nodes where the fault is detected serve as the detecting nodes used above by the resynchrnonizer .",
    "the following theorem differs from the eav theorem by stating that the final protocol ( resulting from the transformation ) also enjoys the good properties of the self - stabilizing verifier .",
    "i.e. , if the self - stabilizing verifier has a good detection time and good detection distance , then , the detection time and distance of the resulting protocols are good too .      * a distributed algorithm @xmath666 to compute an input / output relation  @xmath678 .",
    "whether @xmath666 is synchronous or asynchronous , let @xmath667 and @xmath668 denote @xmath666 s time complexity and memory size , when executed in _",
    "synchronous _ networks .",
    "* an asynchronous ( respectively , synchronous ) proof labeling scheme @xmath679 for verifying @xmath678 with memory size  @xmath680 , whose verifier self - stabilizes with verification time and detection distance @xmath681  and  @xmath682 , and whose construction time ( of the marker ) is @xmath683 .",
    "then , the enhanced resynchronizer produces an asynchronous ( resp . , synchronous ) self - stabilizing algorithm whose memory and time complexities are @xmath684 and @xmath685 ( resp .",
    ", @xmath686 , and whose verification time and detection distance are @xmath681 and @xmath682 .",
    "the proof relies heavily on the resynchronizer compiler given by the eav theorem ( theorem  [ eav ] ) .",
    "this resynchronizer receives as input the following algorithm @xmath687 , which is not assumed to be neither self - stabilizing nor asynchronous .",
    "specifically , algorithm @xmath687 first constructs the relation @xmath678 using algorithm @xmath666 and , subsequently , executes the marker algorithm of the proof labeling scheme @xmath679 .",
    "the resulted resynchronizer ( when executing together with the algorithm @xmath687 it transforms ) is a detection based self - stabilizing algorithm ( see the explanation of the detection time and distance in section [ sub : detection - time ] ) .",
    "it executes algorithm @xmath687 for a set amount of time ( here , counting the time using the self - stabilizing synchronizer ) and then puts all the nodes in an _ output _ state , where it uses the self - stabilizing verifier of the proof labeling scheme @xmath679 to check .",
    "( recall , in contrast to the marker algorithm , the verifier algorithm of @xmath679 is assumed to be self - stabilizing . )",
    "the detection time and the detection distance of the combined algorithm thus follow directly from the detection time and the detection distance of the proof labeling scheme @xmath679 .",
    "this concludes the proof of the theorem .",
    "now , as algorithm @xmath666 , we can plugged in theorem [ thm : self - stab ] the mst construction algorithm @xmath123 , that uses optimal memory size and runs in @xmath7 time .",
    "furthermore , two possible proof labeling schemes that can be plugged in theorem [ thm : self - stab ] as @xmath679 are the schemes of @xcite .",
    "both these schemes use @xmath19 memory size .",
    "since their detection time is 1 , they stabilize trivially .",
    "the corresponding distributed markers are simplified versions of the marker of the proof labeling scheme given of the current paper , and hence their construction time is @xmath7 .",
    "hence , plugging either one of these schemes as @xmath679 yields the following .      finally , by plugging to the resynchronizer given in theorem [ thm : self - stab ] , the construction algorithm @xmath123 as  @xmath666 and our optimal memory proof labeling scheme mentioned in theorem [ thm : verification - properties ] as @xmath679 , we obtain the following .",
    "[ cor : verification - properties ] there exists a self - stabilizing mst algorithm that uses optimal @xmath0 memory size and @xmath7 time . moreover , its detection time complexity is @xmath19 in synchronous networks and @xmath149 in asynchronous ones .",
    "furthermore , its detection distance is @xmath6 .",
    "the algorithm in this paper is composed of multiple modules ( figures [ fig : structure1 ] and [ fig : structure2 ] ) . some of them are self stabilizing , and some are not .",
    "when composing self stabilizing algorithms together , the result may not be self stabilizing , so one should take care @xcite .",
    "we have claimed the stabilization of composite programs throughout this paper . for the sake of completeness , let us go over all the components here once again , to recall that their composition self stabilizes in spite of the composition .",
    ", mainly consisting of algorithms @xmath170 and @xmath176 , induces the hierarchy of a mst . from the hierarchy the proof - labeling - scheme , mainly consisting of the trains and the construction of partitions @xmath145 and @xmath144 , produces a marker and a verifier . ]",
    "the main composition is that of the transformer algorithm of awerbuch and varghese @xcite together with a checking scheme .",
    "the way to perform this composition , as well as its correctness , have been established in @xcite ( as well as in @xcite ) .",
    "see theorem 6.1 in @xcite and theorem 9.3.2 in @xcite .",
    "a synchronizer uses , as an input , the number of nodes and the value of the diameter computed by other algorithms . here",
    "the correctness follows easily from the `` fair combination '' principle of @xcite .",
    "that is , the algorithms computing these values do not use inputs from the other algorithms in the composition .",
    "moreover , their outputs stabilize to the correct values at some points ( from their respective proofs , that do not depend on assumptions in other algorithms ) . from that time on",
    ", their values are correct .",
    "the tree construction itself is not supposed to be self stabilizing for the transformer scheme of @xcite .",
    "this is also the case with the marker algorithm , since the mst construction algorithm and the marker together constructs a data structure to be verified .",
    "( recall that verifying the mst alone is costly @xcite ; hence the idea is to construct a `` redundant '' representation of the mst , containing the mst plus the proof labels , such that verifying this redundant data structure is easier ) .",
    "it is left to argue that the verifier on its own self stabilizes , in spite of the fact that it is composed of several components .",
    "recall that the output of the verifier is a logical and of several verifiers .",
    "that is , if either the verifier for the scheme for the well - forming property ( sections [ sec : mst - construction ] and [ sec : section5 ] ) or the verifier for the scheme for the minimality property ( sections [ sec : proof ] , [ sub:3.2 ] , and [ sub : utilizing ] ) outputs `` no '' , then the combined ( composed together ) verifier outputs no .",
    "hence , the different schemes do not interfere with each other . if all of them are self stabilizing , then the composition is self stabilizing .",
    "in particular , the scheme for verifying the well - forming property runs in one time unit repeatedly . as observed by @xcite ,",
    "such a verifier is necessarily self stabilizing .",
    "it is then left to show that the verifier for the minimality property self stabilizes .",
    "note that section [ sec : proof ] describes a part of the marker , devoted to the scheme for verifying the minimality property .",
    "recall that the marker is not required to self stabilize .",
    "section [ sub:3.2 ] describes the trains process which is composed of two parts : the convergecast of the information to a part s root , and its broadcast from the root . the second process ( the broadcast ) inputs ( at the root ) the results of the first process , but not vice versa .",
    "hence , clearly , the composition self stabilizes as above ( that is , after the first process eventually stabilizes , the second process will eventually stabilize too ) .",
    "the pieces of information carried by the train are then used by each node to compare information with its neighbours ( in section [ sub : sampling and synchronizing ] ) and by the part root ( in section [ sec : section5 ] ) . again",
    ", the flow of information between modules is one way .",
    "that is , from the train process to the computations by each node and by the root .",
    "after the trains stabilizes , so does the rest , eventually .",
    "( the later computations also input the output of the module computing the number @xmath14 of nodes in the network ; again , the flow of information is only unidirectional , and hence the verifier does stabilize after the @xmath14 computation stabilizes ) .    *",
    "using later synchronizers : * as explained in section [ sec : full - mst - alg ] , for simplicity of the presentation we prefer using the synchronizer and the reset protocols built in the scheme of @xcite , since the proof of their composition is already covered in @xcite . for those who prefer using the later synchronizers and reset protocols we mentioned , e.g. , @xcite",
    ", the composition would remain self stabilizing even if we use those .",
    "the correction of this statement has essentially been established in those synchronizers papers .",
    "that is , they presented synchronizers such that they can take any algorithm intended to run over a synchronous network , compose with it , and have it run correctly ( and in a self - stabilizing manner ) in an asynchronous network .",
    "the same holds also for self stabilizing reset protocols .    for the sake of completeness ,",
    "let us recall , nevertheless , why this composition is correct . for the synchronizer to work , it needs a certain output from the algorithm .",
    "this output is trivial .",
    "that is , a synchronous algorithm at a node at a pulse acts as follows .",
    "it receives messages from all the neighbours ( or at least a statement that no message is going to arrive from a specific neighbour ) , and then processes a message from each neighbour .",
    "then it is ready for the next pulse .",
    "thus , the synchronizer needs to know ( 1 ) when did the algorithm receive messages from all the neighbours . for this purpose",
    ", the synchronizer receives the messages on the algorithm s behalf , and when it receives all of them ( or notifications that no messages will be sent ) , it passes all of them to the algorithm together , which , in turn , processes all of these messages together .",
    "the algorithm needs then to tell the synchronizer that it has finished processing the messages . if this processing generates messages to be sent to neighbours , the algorithm needs to give these new messages to the synchronizer to send them on the algorithm s behalf .",
    "( this is done so that if there is a neighbour @xmath44 to which the node does not send a message in the current pulse , the synchronizer will send a `` dummy '' message , saying that no message will arrive . )",
    "the analysis of the synchronizers ( in the papers that presented self stabilizing synchronizers , e.g. , @xcite ) were base on the rather obvious observation regarding the correctness of this trivial information for any `` reasonable '' algorithm , starting from the second round .",
    "that is , it is _ not _ assumed that the computation or the messages are correct .",
    "what is assumed by the synchronizers is just the fact that the algorithm computed already the messages from the previous round ( and is giving the synchronzer the resulting messages ) .",
    "obviously , this assumption holds for our algorithm too , so we can rely on the results of the papers where the synchronizers were designed .                                          c. boulinier , f. petit , and v. villain .",
    "when graph theory helps self - stabilization .",
    ", 150159 ( 2004 ) .",
    "a. bui , a. k. datta , f. petit , and v. villain .",
    "snap - stabilization and pif in tree networks . , 20(1 ) , 319 ( 2007 ) ."
  ],
  "abstract_text": [
    "<S> this paper demonstrates the usefulness of distributed local verification of proofs , as a tool for the design of self - stabilizing algorithms . in particular , it introduces a somewhat generalized notion of distributed local proofs , and utilizes it for improving the time complexity significantly , while maintaining space optimality . as a result </S>",
    "<S> , we show that optimizing the memory size carries at most a small cost in terms of time , in the context of minimum spanning tree ( mst ) . </S>",
    "<S> that is , we present algorithms that are both time and space efficient for both constructing an mst and for verifying it . </S>",
    "<S> this involves several parts that may be considered contributions in themselves .    </S>",
    "<S> first , we generalize the notion of local proofs , trading off the time complexity for memory efficiency . </S>",
    "<S> this adds a dimension to the study of distributed local proofs , which has been gaining attention recently . </S>",
    "<S> specifically , we design a ( self - stabilizing ) proof labeling scheme which is memory optimal ( i.e. , @xmath0 bits per node ) , and whose time complexity is @xmath1 in synchronous networks , or @xmath2 time in asynchronous ones , where @xmath3 is the maximum degree of nodes . </S>",
    "<S> this answers an open problem posed by awerbuch and varghese ( focs 1991 ) . </S>",
    "<S> we  also show that @xmath4 time is necessary , even in synchronous networks . </S>",
    "<S> another property is that if @xmath5 faults occurred , then , within the required detection time above , they are detected by some node in the @xmath6 locality of each of the faults .    </S>",
    "<S> second , we show how to enhance a known transformer that makes input / output algorithms self - stabilizing . </S>",
    "<S> it now takes as input an efficient construction algorithm and an efficient self - stabilizing proof labeling scheme , and produces an efficient self - stabilizing algorithm . when used for mst , the transformer produces a memory optimal self - stabilizing algorithm , whose time complexity , namely , @xmath7 , is significantly better even than that of previous algorithms . </S>",
    "<S> ( the time complexity of previous mst algorithms that used @xmath8 memory bits per node was @xmath9 , and the time for optimal space algorithms was @xmath10 . ) inherited from our proof labelling scheme , our self - stabilising mst construction algorithm also has the following two properties : ( 1 ) if faults occur after the construction ended , then they are detected by some nodes within @xmath1 time in synchronous networks , or within @xmath2 time in asynchronous ones , and ( 2 ) if @xmath5 faults occurred , then , within the required detection time above , they are detected within the @xmath6 locality of each of the faults . </S>",
    "<S> we also show how to improve the above two properties , at the expense of some increase in the memory .    </S>",
    "<S> * keywords : * distributed network algorithms , locality , proof labels , minimum spanning tree , distributed property verification , self - stabilization , fast fault detection , local fault detection . </S>"
  ]
}