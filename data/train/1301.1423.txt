{
  "article_text": [
    "_ compressed ( or compressive ) sensing _ ( cs ) is a technique for recovering a high - dimensional signal from lower - dimensional data , whose components represent partial information about the signal , by utilizing prior knowledge on the sparsity of the signal @xcite .",
    "the research field of cs is one of the main topics in information science nowadays and has been intensively investigated from the theoretical point of view @xcite .",
    "this technique has also been used in various engineering fields @xcite .    let us suppose a situation that an @xmath0-dimensional vector @xmath7 is linearly transformed into an @xmath8-dimensional vector @xmath4 by an @xmath9 measurement matrix @xmath10 , where @xmath11 .",
    "the signal is recovered from @xmath4 by determining the sparsest signal that is consistent with the measurements . when @xmath3 , the measurement usually loses some information and the inverse problem has an infinite number of solutions .",
    "however , when the @xmath0-dimensional signal is guaranteed to have only @xmath12 nonzero entries in some convenient basis and the measurement matrix is incoherent with that basis , there is a high probability that the inverse problem has a unique and exact solution .",
    "for example , smooth signals and piecewise - smooth signals , like natural images or communications signals , typically have a representation in a sparsity - inducing basis such as a fourier or wavelet basis @xcite .",
    "although most of the compressed sensing literature has not explicitly handled quantization of the measured data until recently , quantizing continuous data is unavoidable in most real - world applications , particularly those in which the measurement is accompanied by digital information transmission @xcite . addressing the practical relevance of cs in such operation , boufounos and baraniuk recently proposed and examined a cs scheme , often called _",
    "1-bit compressed sensing ( 1-bit cs ) _ , in which the signal is recovered from only the sign data of the linear measurements @xmath13 , where @xmath14 for @xmath15 operates for vectors in the component - wise manner @xcite .",
    "although in 1-bit cs the amplitude information is lost during the measurement stage , making perfect recovery of the original signal impossible , discarding the amplitude information can significantly reduce the amount of data that needs to be stored and/or transmitted .",
    "this is highly advantageous when perfect recovery is not required .",
    "in addition , quantization to the 1-bit ( sign ) information is appealing in hardware implementations because 1-bit quantizer takes the form of a comparator to zero and does not suffer from dynamic range issues .",
    "the scheme is considered practical relevant in situations where measurements are inexpensive and precise quantization is expensive , in which the cost of measurements should be quantified by the number of total bits needed to store the data instead of by the number of measurements .",
    "the purpose of this paper is to explore the abilities and limitations of a 1-bit cs scheme utilizing statistical mechanics methods . in @xcite an approximate signal recovery algorithm based on minimization of the @xmath6-norm @xmath16 under the constraint of @xmath17",
    "was proposed and its utility was shown by numerical experiments .",
    "quantization to the sign information , however , leads to the loss of the convexity of the resulting optimization problem , which makes it difficult to mathematically examine how well the obtained solution approximates the correct solution . comparing ( in terms of the mean square error ) the results of numerical experiments with the theoretical prediction evaluated by the replica method @xcite",
    ", we will show that the performance of the approximate algorithm is nearly as good as that potentially achievable by the @xmath6-based scheme .",
    "we will also develop another approximate algorithm inspired by the cavity method @xcite and will show that when the density of nonzero entries of the original signal is relatively high the new algorithm offers better recovery performance with much lower computational cost .",
    "this paper is organized as follows .",
    "the next section sets up the problem that we will focus on when explaining the 1-bit cs scheme .",
    "section 3 uses the replica method to examine the signal recovery performance achieved by the scheme . in section 4 an approximate signal recovery algorithm based on the cavity method",
    "is developed and evaluated , and the final section is devoted to a summary .",
    "let us suppose that entry @xmath18 @xmath19 of @xmath0-dimensional signal ( vector ) @xmath20 is independently generated from an identical sparse distribution : @xmath21 where @xmath22 $ ] represents the density of nonzero entries in the signal and @xmath23 is a distribution function of @xmath24 that does not have finite mass at @xmath25 . in 1-bit cs the measurement is performed as @xmath26 where for simplicity we assume that each entry of @xmath9 measurement matrix @xmath27 is provided as an independent sample from an identical gaussian distribution of zero mean and variance @xmath28 .",
    "given @xmath29 and @xmath27 , the signal reconstruction is carried out by searching for a sparse vector @xmath30 under the constraint of @xmath31 .",
    "for this task the authors of @xcite proposed a scheme of @xmath32 based on the @xmath6-recovery method widely used and studied for standard cs problems @xcite . here @xmath33 and @xmath34 denote the @xmath6- and @xmath35-norms of @xmath36 , respectively .",
    "the measurement process of ( [ measurement ] ) completely erases the information of length @xmath37 , which makes it impossible to recover the signal uniquely .",
    "we therefore introduce an extra normalization constraint @xmath38 for the recovered signal @xmath39 , and we consider the recovery successful when the direction cosine @xmath40 is sufficiently large .    unlike the standard cs problem , finding a solution of ( [ l1recovery ] ) is non - trivial because the norm constraint @xmath41 keeps it from being a convex optimization problem ( figures [ normal_vs_1bit ] ( a ) and ( b ) ) .",
    "the authors of @xcite also developed , as a practically feasible solution , a double - loop algorithm called renormalized fixed point iteration ( rfpi ) that combines a gradient descent method and enforcement to a sphere of a fixed radius .",
    "it is summarized in figure [ rfpi ] .",
    "the practical utility of rfpi was shown by numerical experiments , but how good solutions are actually obtained is unclear because in general the algorithm can be trapped at various local optima .",
    "one of our main concerns is therefore to theoretically evaluate the typical performance of the global minimum solution of ( [ l1recovery ] ) for examining the possibility of performance improvement .",
    "graphical representations of ( a ) standard and ( b ) 1-bit cs problems in the case of @xmath42 , @xmath43 , and @xmath44 .",
    "( a ) : a thick line and a square of thin lines represent a measurement result @xmath45 and a contour of @xmath6-norm @xmath46 , respectively . the optimal solution denoted by a circle is uniquely determined since both the set of feasible solutions @xmath47 and the cost function @xmath46 are convex .",
    "( b ) : the shaded area @xmath48 represents the region that is compatible with the sign information of the linear measurement @xmath47 ( dotted broken line ) .",
    "this and the @xmath35-norm constraint @xmath49 yield the set of feasible solutions as a semicircle ( thick curve ) , which is not a convex set . as a consequence ,",
    "the constraint optimization problem of ( [ l1recovery ] ) generally has multiple solutions ( two circles).,width=529 ]    renormalized fixed point iteration , 1 )  : + : _",
    "0  ||_0||_2= , + : + : k0 + 2 )  : + k k+1 + 3 )  : + _",
    "k(y)^t f^(y_k-1 ) + 4 )  : + _ k_k-_k , _ k-1_k-1/n + 5 )  : + _ k-1-_k + 6 )  : + ( ) _ i(()_i)\\{|()_i|-,0 }  i + 7 )  : + _ k + 8)  :",
    "the partition function @xmath50 where @xmath51 and @xmath52 for @xmath53 and @xmath54 , respectively , offers the basis for our analysis . as @xmath55 tends to infinity , the integral of ( [ eq : partition_func ] )",
    "is dominated by the correct solution of ( [ l1recovery ] ) .",
    "one therefore can evaluate the performance of the solution by examining the macroscopic behavior of equation ( [ eq : partition_func ] ) in the limit of @xmath56 .",
    "a characteristic feature of the current problem is that ( [ eq : partition_func ] ) depends on the predetermined random variables @xmath57 and @xmath58 , which requires us to assess the average of free energy density @xmath59_{{\\boldsymbol{\\phi}},{\\boldsymbol{x}}^0}$ ] when evaluating the performance for typical samples of @xmath27 and @xmath60 . here ,",
    "@xmath61_{{\\boldsymbol{\\phi}},{\\boldsymbol{x}}^0}$ ] denotes the configurational average concerning @xmath57 and @xmath7 .",
    "because directly averaging the logarithm of the partition function is technically difficult , we here resort to the replica method @xcite .    for this we first evaluate @xmath62-th moment of the partition function @xmath63_{{\\boldsymbol{\\phi}},{\\boldsymbol{x}}^0}$ ] for @xmath64 , using the formula @xmath65 which holds only for @xmath64 . here , @xmath66",
    "( @xmath67 ) denotes @xmath68-th replicated signal . averaging ( [ eq : expansion ] ) with respect to @xmath27 and @xmath60 results in the saddle point evaluation concerning macroscopic variables @xmath69 and @xmath70 ( @xmath71 ) .",
    "although ( [ eq : expansion ] ) holds only for @xmath72 , the expression of @xmath73_{{\\boldsymbol{\\phi}},{\\boldsymbol{x}}^0}$ ] obtained by the saddle point evaluation under a certain assumption concerning the permutation symmetry with respect to the replica indices @xmath74 is obtained as an analytic function of @xmath62 , which is likely to also hold for @xmath75 . therefore , we next utilize the analytic function for evaluating the average of the logarithm of the partition function as @xmath76_{{\\boldsymbol{\\phi}},{\\boldsymbol{x}}^0 } \\lim_{n \\to 0 } n^{-1 } \\ln \\left [ z^n \\left(\\beta ; { \\boldsymbol{\\phi } } , \\textrm{\\boldmath $ x$}^{0 } \\right ) \\right]_{{\\boldsymbol{\\phi}},{\\boldsymbol{x}}^0}$ ] .",
    "in particular , under the replica symmetric ( rs ) ansatz where the dominant saddle point is assumed to be of the form of @xmath77 when the distribution of nonzero entries in ( [ sparse ] ) is given as the standard gaussian @xmath78 , the above procedure offers an expression of the average free energy density as @xmath79_{\\textrm{\\boldmath $ x$}^{0},z } -\\frac{1}{2}\\hat{q}+\\frac{1}{2}\\hat{q}\\chi+\\hat{m}m \\nonumber\\\\   & & + \\frac{\\alpha}{2\\pi\\chi}\\left(\\arctan \\left ( \\frac{\\sqrt{\\rho - m^2}}{m } \\right ) -\\frac{m}{\\rho}\\sqrt{\\rho - m^2}\\right ) \\biggr\\ }   \\label{eq : free energy}\\end{aligned}\\ ] ] in the limit of @xmath80 . here",
    "@xmath81 , @xmath82 denotes extremization of a function @xmath83 with respect to @xmath84 , @xmath85 , @xmath86 is a gaussian measure , and @xmath87 the derivation of @xmath88 is provided in [ replicaderivation ] .",
    "the extremization problem of ( [ eq : free energy ] ) yields the following saddle point equations : @xmath89 \\right . \\nonumber\\\\            & & \\left .",
    "+ \\rho\\left[\\left(\\hat{q}+\\hat{m}^2 + 1\\right)h\\left(\\frac{1}{\\sqrt{\\hat{q}+\\hat{m}^2}}\\right )            -\\sqrt{\\frac{\\hat{q}+\\hat{m}^2}{2\\pi}}e^{-\\frac{1}{2\\left(\\hat{q}+\\hat{m}^2\\right)}}\\right]\\right\\ } , \\\\",
    "\\chi&=&\\frac{2}{\\hat{q}}\\left[\\left(1-\\rho\\right ) h\\left(\\frac{1}{\\sqrt{\\hat{q}}}\\right)+\\rho h\\left(\\frac{1}{\\sqrt{\\hat{q}+\\hat{m}^2}}\\right)\\right ] , \\\\",
    "m&=&\\frac{2\\rho\\hat{m}}{\\hat{q}}h\\left(\\frac{1}{\\sqrt{\\hat{q}+\\hat{m}^2}}\\right ) ,   \\label{results}\\end{aligned}\\ ] ] where @xmath90 .",
    "the value of @xmath91 determined by these equations physically means the typical overlap @xmath92_{{\\boldsymbol{\\phi } } , { \\boldsymbol{x}}^0 } $ ] between the original signal @xmath60 and the solution @xmath39 of ( [ l1recovery ] ) .",
    "therefore the typical value of the direction cosine between @xmath60 and @xmath39 , which serves as a performance measure of the current recovery problem , is evaluated as @xmath93_{{\\boldsymbol{\\phi,{\\boldsymbol{x}}^0 } } } = n m /(\\sqrt{n \\rho } \\times \\sqrt{n})=m/\\sqrt{\\rho}$ ] .",
    "alternatively , we may also use as a performance measure the mean square error ( mse ) between the normalized vectors : @xmath94_{{\\boldsymbol{\\phi,{\\boldsymbol{x}}^0 } } } = 2\\left ( 1-\\frac{m}{\\sqrt{\\rho } } \\right ) .",
    "\\label{mse}\\end{aligned}\\ ] ]    c    mse versus the measurement bit ratio @xmath95 for the signal recovery scheme using ( [ l1recovery ] ) .",
    "( a ) , ( b ) , ( c ) , and ( d ) correspond to the @xmath96 , and @xmath97 cases , respectively .",
    "curves represent the theoretical prediction evaluated by the rs solution , which is locally unstable for disturbances that break the replica symmetry for all regions of ( a)(d ) .",
    "each symbol ( @xmath98 ) stands for the experimental estimate obtained for rfpi in @xcite from @xmath99 experiments with @xmath100 systems.,width=321 ]    mse versus the measurement bit ratio @xmath95 for the signal recovery scheme using ( [ l1recovery ] ) .",
    "( a ) , ( b ) , ( c ) , and ( d ) correspond to the @xmath96 , and @xmath97 cases , respectively .",
    "curves represent the theoretical prediction evaluated by the rs solution , which is locally unstable for disturbances that break the replica symmetry for all regions of ( a)(d ) .",
    "each symbol ( @xmath98 ) stands for the experimental estimate obtained for rfpi in @xcite from @xmath99 experiments with @xmath100 systems.,width=321 ]     +    mse versus the measurement bit ratio @xmath95 for the signal recovery scheme using ( [ l1recovery ] ) .",
    "( a ) , ( b ) , ( c ) , and ( d ) correspond to the @xmath96 , and @xmath97 cases , respectively .",
    "curves represent the theoretical prediction evaluated by the rs solution , which is locally unstable for disturbances that break the replica symmetry for all regions of ( a)(d ) .",
    "each symbol ( @xmath98 ) stands for the experimental estimate obtained for rfpi in @xcite from @xmath99 experiments with @xmath100 systems.,width=321 ]    mse versus the measurement bit ratio @xmath95 for the signal recovery scheme using ( [ l1recovery ] ) .",
    "( a ) , ( b ) , ( c ) , and ( d ) correspond to the @xmath96 , and @xmath97 cases , respectively .",
    "curves represent the theoretical prediction evaluated by the rs solution , which is locally unstable for disturbances that break the replica symmetry for all regions of ( a)(d ) .",
    "each symbol ( @xmath98 ) stands for the experimental estimate obtained for rfpi in @xcite from @xmath99 experiments with @xmath100 systems.,width=321 ]    we solved the saddle point equations for various sets of @xmath95 and @xmath101 .",
    "the curves in figures [ fig2 ] ( a)(d ) show the theoretical prediction of mse evaluated by ( [ mse ] ) plotted against the measurement bit ratio @xmath81 for @xmath96 , and @xmath97 . to examine the validity of the rs ansatz",
    ", we also evaluated the local stability of the rs solutions against the disturbances that break the replica symmetry @xcite , which offers @xmath102 as the stability condition .",
    "a brief sketch of the derivation of this condition is shown in [ rsstability ] .",
    "unfortunately , ( [ at ] ) is not satisfied for any regions in figures [ fig2 ] ( a)(d ) .",
    "this is presumably because the optimization problem for ( [ l1recovery ] ) has many local optima reflecting the fact that the constraint of @xmath103 loses the convexity .",
    "this indicates that taking the replica symmetry breaking ( rsb ) into account is necessary for evaluating the exact performance of the signal recovery scheme defined by ( [ l1recovery ] ) .",
    "we nonetheless think that the rs analysis offers considerably accurate approximates of the exact performance in terms of mse .",
    "the ( @xmath98 ) symbols in figures [ fig2 ] ( a)(d ) stand for mse experimentally achieved by rfpi , which were assessed as the arithmetic averages over @xmath99 samples for each condition of @xmath100 systems .",
    "excellent consistency between the curves and symbols suggests that even if ( [ l1recovery ] ) has many local optima , they are close to one another in terms of the @xmath35-norm yielding similar values of mse .",
    "this also implies that rfpi , which is guaranteed to find one of the local optima , performs nearly saturates as well ( as measured by the mse ) as the signal recovery scheme based on ( [ l1recovery ] ) .",
    "of course , we have to keep in mind that the consistency between the theory and experiments depends highly on the performance measure used .",
    "figures [ fig : l1roc ] ( a)(d ) show the probabilities of wrongly predicting sites of nonzero and zero entries , which are sometimes referred to as false positive ( fp ) and false negative ( fn ) , respectively .",
    "these indicate that there are considerably large discrepancies between the theory and experiments in terms of these performance measures , which is probably due to the influence of rsb",
    ". nevertheless , the rs - based theoretical predictions are still qualitatively consistent with the experimental results in the way that the probability of a fp remains finite even when the measurement bit ratio @xmath81 tends to infinity for any values of @xmath101 .",
    "this implies that the @xmath6-based scheme is intrinsically unable to correctly identify sites of nonzero and zero entries .",
    "c     fp and fn probabilities versus the measurement bit ratio @xmath81 .",
    "( a ) , ( b ) , ( c ) , and ( d ) corresponds to the @xmath96 , and @xmath97 cases , respectively .",
    "solid and dashed curves represent theoretical predictions obtained by the rs solution for fp and fn , respectively . asterisks and squares denote experimental results for fp and fn , respectively .",
    "the experimental results were obtained by rfpi from 1000 samples for each condition of @xmath100 systems.,width=321 ]     fp and fn probabilities versus the measurement bit ratio @xmath81 .",
    "( a ) , ( b ) , ( c ) , and ( d ) corresponds to the @xmath96 , and @xmath97 cases , respectively .",
    "solid and dashed curves represent theoretical predictions obtained by the rs solution for fp and fn , respectively . asterisks and squares denote experimental results for fp and fn , respectively .",
    "the experimental results were obtained by rfpi from 1000 samples for each condition of @xmath100 systems.,width=321 ]     +     fp and fn probabilities versus the measurement bit ratio @xmath81 .",
    "( a ) , ( b ) , ( c ) , and ( d ) corresponds to the @xmath96 , and @xmath97 cases , respectively .",
    "solid and dashed curves represent theoretical predictions obtained by the rs solution for fp and fn , respectively .",
    "asterisks and squares denote experimental results for fp and fn , respectively .",
    "the experimental results were obtained by rfpi from 1000 samples for each condition of @xmath100 systems.,width=321 ]     fp and fn probabilities versus the measurement bit ratio @xmath81 .",
    "( a ) , ( b ) , ( c ) , and ( d ) corresponds to the @xmath96 , and @xmath97 cases , respectively .",
    "solid and dashed curves represent theoretical predictions obtained by the rs solution for fp and fn , respectively .",
    "asterisks and squares denote experimental results for fp and fn , respectively .",
    "the experimental results were obtained by rfpi from 1000 samples for each condition of @xmath100 systems.,width=321 ]",
    "the analysis so far indicates that the performance of rfpi is good enough in the sense that there is little room for improvement in achievable mse .",
    "rfpi requires tuning of two parameters @xmath104 and @xmath105 , however , which is rather laborious .",
    "in addition , the convergence of the inner loop of figure [ rfpi ] is relatively slow , which may limit its application range to systems of relatively small sizes .",
    "we therefore developed another recovery algorithm following the framework of the cavity method of statistical mechanics @xcite , or equivalently , the belief propagation of probabilistic inference @xcite .",
    "for simplicity of notations , let us first convert all the measurement results to @xmath106 by multiplying @xmath107 @xmath108 to each row of the measurement matrix @xmath109 as @xmath110 , and newly denote the resultant matrix as @xmath109 . in the new notation , introduction of lagrange multipliers @xmath111 and surplus variables @xmath112 converts ( [ l1recovery ] ) to an unconstrained optimization problem : @xmath113 where @xmath114 means that each entry of @xmath115 is restricted to be positive .",
    "coupling terms @xmath116 make the optimization of ( [ coupled_cost ] ) a nontrivial problem . in statistical mechanics , a standard approach to resolving",
    "such a difficulty is to approximate ( [ coupled_cost ] ) with a bunch of optimizations for single - body cost functions parameterized as @xmath117 and @xmath118 where @xmath119 , and @xmath120 are parameters to be determined in a self - consistent manner .    in the cavity method",
    "this is done by introducing virtual systems that are defined by removing a single variable @xmath121 or a single pair of variables @xmath122 from the original system @xcite .",
    "when @xmath0 is sufficiently large , the law of large numbers allows us to assume that the values of @xmath123 and @xmath124 are constant independently of their indices ; that is , that @xmath125 and @xmath126 are constants . under this simplification",
    ", this method yields a set of self - consistent equations : @xmath127 where @xmath128 , @xmath129 , @xmath130 , and @xmath131 .",
    "@xmath125 is determined so that @xmath132 holds , and @xmath126 is provided as @xmath133 .",
    "@xmath134 , and @xmath135 on the right - hand side of ( [ bpnaive3 ] ) is often referred to as the _ onsager reaction term _ @xcite .",
    "equation ( [ bpnaive4 ] ) offers the recovered signal .",
    "the derivations of these equations are provided in [ cavity_derivation ] .",
    "a distinctive feature of the above set of equations is that they are free from tuning parameters such as @xmath105 and @xmath104 in rfpi , which is highly beneficial in practical use .",
    "it is therefore unfortunate that in most cases the naive iterations of ( [ bpnaive1])([bpnaive4 ] ) hardly converge , which is considered a consequence of rsb @xcite .",
    "cavity - inspired signal recoveryb , ^ * , ^ *    1 )  : + : _ 0 ^ * + : _ 0 ^ * + : k0 + 2 )  : + k k+1 + 3 )  : + _ k_k-1-b^-1(y)^t",
    "f^(y_k-1 ) + 4 )  : + ( nb)^-1 ^t f^ ( y_k-1 ) + 5 )  : + _ k _ k+_k-1 + 6 )  : + ( ) _ i(()_i ) \\{|()_i|-1,0 }   i + 7 )  : + _ k + 8)  :    we found , however , that modifying ( [ bpnaive1 ] ) and ( [ bpnaive2 ] ) to @xmath136 in conjunction with handling @xmath126 as a parameter to be controlled in the outer loop , results in a fairly good approximate signal recovery algorithm .",
    "the resultant algorithm is somewhat similar to rfpi as the combination of ( [ bpnaive3 ] ) and ( [ bpnaive2rev ] ) roughly acts as the * one - sided quadratic gradient descent * step in figure [ rfpi ] .",
    "however , as the length of @xmath137 is not restricted to a fixed value , the current algorithm does not need a small step size @xmath104 for the convergence .",
    "another significant difference from rfpi is the existence of the onsager reaction term in ( [ bpnaive3 ] ) .",
    "this term effectively cancels the self - feedback effects included in @xmath138 of ( [ bpnaive3 ] ) , and this is expected to accelerate the convergence of the algorithm . a pseudocode for the inner loop",
    "is summarized in figure [ proposedalgorithm ] .",
    "the necessity of controlling @xmath126 in the outer loop , which is essential for having good convergence in the inner loop , means that our algorithm still requires one tuning parameter .",
    "nonetheless , the reduction in the number of the tuning parameters from two to one is considerably advantageous for practical use . in practice",
    ", the initial value of @xmath126 should be set so that only a single entry becomes nonzero .",
    "this is easily done by the binary iterative hard thresholding algorithm @xcite , which requires the number of nonzero entries as extra prior knowledge .",
    "after the initial value is set , @xmath126 is reduced as @xmath139 with an appropriate constant @xmath140 , where @xmath62 is the counter of the outer loop .",
    "the algorithm terminates when the difference between the convergent solutions of two successive outer loops is sufficiently small .",
    "c    mse versus measurement bit ratio @xmath95 for the cavity - inspired signal recovery ( cisr ) algorithm .",
    "experimental conditions are the same as in figures [ fig2 ] ( a)(d).,width=321 ]    mse versus measurement bit ratio @xmath95 for the cavity - inspired signal recovery ( cisr ) algorithm .",
    "experimental conditions are the same as in figures [ fig2 ] ( a)(d).,width=321 ]     +    mse versus measurement bit ratio @xmath95 for the cavity - inspired signal recovery ( cisr ) algorithm .",
    "experimental conditions are the same as in figures [ fig2 ] ( a)(d).,width=321 ]    mse versus measurement bit ratio @xmath95 for the cavity - inspired signal recovery ( cisr ) algorithm .",
    "experimental conditions are the same as in figures [ fig2 ] ( a)(d).,width=321 ]    c     fp and fn probabilities of versus measurement bit ratio @xmath95 for the cisr .",
    "experimental conditions are the same as in figures [ fig : l1roc ] ( a)(d).,width=321 ]     fp and fn probabilities of versus measurement bit ratio @xmath95 for the cisr .",
    "experimental conditions are the same as in figures [ fig : l1roc ] ( a)(d).,width=321 ]     +     fp and fn probabilities of versus measurement bit ratio @xmath95 for the cisr .",
    "experimental conditions are the same as in figures [ fig : l1roc ] ( a)(d).,width=321 ]     fp and fn probabilities of versus measurement bit ratio @xmath95 for the cisr .",
    "experimental conditions are the same as in figures [ fig : l1roc ] ( a)(d).,width=321 ]    the mse results obtained in numerical experiments with the cavity - inspired signal recovery ( cisr ) algorithm are shown in figures [ fig : bpmse ] ( a)(d ) .",
    "they indicate that except in the case in which the nonzero density @xmath101 of the original signals is significantly low , cisr provides mse values almost equal to or lower than those of rfpi .",
    "figures [ fig : bproc ] ( a)(d ) show the fp and fn probabilities for cisr .",
    "the discrepancies from the theoretical prediction are not unexpected because the modification of ( [ bpnaive2 ] ) to ( [ bpnaive2rev ] ) means that cisr is no longer based on ( [ l1recovery ] ) or ( [ coupled_cost ] ) .",
    "the fn probabilities for cisr are higher than those for rfpi , while the fp probabilities are lower .",
    "this implies that cisr has a capability of yielding sparser signals than rfpi , which is presumably because parameter @xmath126 of cisr is initially set so that only a single entry of @xmath39 is nonzero while such a tuning is not taken into account in rfpi .",
    "the run times actually required for performing the experiments in a matlab^^ environment for the cases of @xmath100 and @xmath141 are listed in table [ table1 ] . although the run times of rfpi may be reduced by optimally tuning the descent step size @xmath104 ,",
    "cisr is several hundreds of times faster than rfpi .",
    "this shows the significant computational efficiency of cisr .",
    "the nort values in table [ table1 ] are the run times when the onsager reaction term in ( [ bpnaive3 ] ) was removed from cisr .",
    "their being 1.132.37 times longer than those for cisr indicates that the cancellation of the self - feedback effects by adding the onsager reaction term speeds the convergence of cisr significantly .",
    ".[table1 ] comparison of computational costs for the @xmath100 and @xmath141 cases .",
    "the values listed here are the average run times ( in seconds ) evaluated in 1000 experiments , and the numbers in parentheses are the standard deviations . in rfpi ,",
    "@xmath104 was roughly tuned as @xmath142 , and @xmath105 was enlarged as @xmath143 with the initial value @xmath144 in the outer loop . on the other hand , @xmath126 of cisr",
    "was reduced as @xmath145 .",
    "the nort values are the run times required for performing the same experiments when the onsager reaction term was removed from cisr . in all cases the algorithms terminated when the difference per entry , in terms of @xmath6-norm , between the convergent solutions of two successive outer loops was less than @xmath146 . [",
    "cols=\"<,<,<,<,<\",options=\"header \" , ]",
    "in summary , we have examined typical properties of 1-bit compresses sensing ( cs ) proposed in @xcite utilizing methods of statistical mechanics .",
    "signal recovery based on the @xmath6-norm minimization is a standard approach in cs research . unlike the normal cs scheme ,",
    "however , the @xmath6-based signal recovery can not be formulated as a convex optimization problem , which makes practically performing it nontrivial .",
    "we have shown that the theoretical prediction of the performance of the @xmath6-based scheme , which is obtained by the replica method under the replica symmetric ( rs ) ansatz , exhibits a fairly good accordance ( in terms of mse ) with experimental results obtained using for an approximate signal recovery algorithm , rfpi , proposed in @xcite .",
    "the replica symmetry of the rs solution turned out to be broken , however , which implies that there are many local optima for the optimization problem of the signal recovery .",
    "our results suggest that the local optima , which can be searched by rfpi , yield similar values of mse representing the potential performance limit of @xmath6-based recovery scheme .",
    "we have also developed an approximate signal recovery algorithm utilizing the cavity method .",
    "naive iterations of self - consistent equations derived directly from the cavity method hardly converge in most cases , which can be regarded as a consequence of the replica symmetry breaking .",
    "however , we have shown that modification of one equation in an appropriate manner , in conjunction with controlling a macroscopic variable in the outer loop , results in a fairly good signal recovery algorithm .",
    "compared with rfpi , the resultant algorithm is beneficial in that the number of tuning parameters is reduced from two to one .",
    "numerical experiments have also shown that whenever the density of nonzero entries of the original signal is not considerably small the cavity - inspired algorithm performs as well as or better than rfpi ( in terms of mse ) and has a lower computational cost .",
    "we here focused on the @xmath6-based recovery scheme since it was proposed and examined in the seminal paper on 1-bit cs @xcite .",
    "however , the significance of the @xmath6-based scheme may be rather weak for 1-bit cs because the loss of convexity it entails keeps it from leading to the development of mathematically guaranteed and practically feasible algorithms .",
    "therefore , much effort should be devoted to developing recovery algorithms following various principles . for example , the idea based on the bayesian inference and matrix design that was proposed for standard cs @xcite may also be a promising approach for 1-bit cs .",
    "yx acknowledges a scholarship from rotary yoneyama memorial foundation , inc .",
    "this study was partially supported by jsps kakenhi nos .",
    "22300003 and 22300098 ( yk ) .",
    "averaging ( [ eq : expansion ] ) with respect to @xmath27 and @xmath60 offers the following expression of the @xmath62-th moment of the partition function : @xmath148_{\\phi,\\textrm{\\boldmath $ x$}^{0}}= \\int \\prod_{a=1}^n \\left ( d \\textrm{\\boldmath $ x$}^a\\delta\\left(\\vert \\textrm{\\boldmath $ x$}^a\\vert^{2}-n\\right ) \\times   e^{-\\beta||\\textrm{\\boldmath $ x^a$}||_{1 } } \\right ) \\cr & & \\hspace*{3 cm } \\times   \\left[\\prod_{a=1}^n \\prod_{\\mu=1}^m   \\theta\\left ( ( { \\boldsymbol{\\phi } } { \\boldsymbol{x}}^0)_\\mu   ( { \\boldsymbol{\\phi } } { \\boldsymbol{x}}^a)_\\mu   \\right ) \\right]_{{\\boldsymbol{\\phi}},{\\boldsymbol{x}}^{0}}.   \\label{zmoment}\\end{aligned}\\ ] ] we insert @xmath149 trivial identities @xmath150 where @xmath151 , into ( [ zmoment ] ) .",
    "furthermore , we define a joint distribution of @xmath152 vectors @xmath153 as @xmath154 where @xmath155 is an @xmath156 symmetric matrix whose @xmath157 and the other diagonal entries are fixed as @xmath101 and @xmath158 , respectively .",
    "@xmath159 denotes the distribution of the original signal @xmath60 , and @xmath160 is the normalization constant that makes @xmath161 hold .",
    "these indicate that ( [ zmoment ] ) can also be expressed as @xmath162_{\\phi,\\textrm{\\boldmath $ x$}^{0 } } = \\int d{\\boldsymbol{q } } \\left ( v\\left ( { \\boldsymbol{q}}\\right ) \\times \\xi\\left ( { \\boldsymbol{q}}\\right ) \\right ) ,   \\label{zn}\\end{aligned}\\ ] ] where @xmath163 and @xmath164_{{\\boldsymbol{\\phi}}}.   \\label{xi}\\end{aligned}\\ ] ]    equation ( [ xi ] ) can be regarded as the average of @xmath165 with respect to @xmath166 and @xmath27 over distributions of @xmath167 and @xmath168 . in computing this ,",
    "it is noteworthy that the central limit theorem guarantees that @xmath169 can be handled as zero - mean multivariate gaussian random numbers whose variance and covariance are provided by @xmath170_{{\\boldsymbol{\\phi}},\\{{\\boldsymbol{x}}^a\\ } } = \\delta_{\\mu \\nu } q_{ab } , \\end{aligned}\\ ] ] when @xmath27 and @xmath166 are generated independently from @xmath171 and @xmath167 , respectively .",
    "this means that ( [ xi ] ) can be evaluated as @xmath172    on the other hand , expressions @xmath173 and @xmath174 and use of the saddle point method offer @xmath175 here @xmath176 and @xmath177 is an @xmath178 symmetric matrix whose @xmath157 and other diagonal components are given as @xmath52 and @xmath179 , respectively , while off - diagonal entries are offered as @xmath180 . equations ( [ logxi ] ) and ( [ logv ] ) indicate that @xmath181_{{\\boldsymbol{\\phi } } , { \\boldsymbol{x}}^0}$ ] is correctly evaluated by using the saddle point method with respect to @xmath182 in the assessment of the right - hand side of ( [ zn ] ) when @xmath0 and @xmath8 tend to infinity keeping @xmath81 finite .",
    "let us assume that the relevant saddle point in assessing ( [ zn ] ) is of the form of ( [ rsanzats ] ) and , accordingly , @xmath183 @xmath152 dimensional gaussian random variables @xmath184 whose variance and covariance are provided as ( [ rsanzats ] ) can be expressed as @xmath185 utilizing @xmath186 independent standard gaussian random variables @xmath187 and @xmath188 .",
    "this indicates that ( [ logxi ] ) is evaluated as @xmath189 on the other hand , substituting ( [ rshatq ] ) into ( [ logv ] ) , in conjunction with the identity @xmath190 provides @xmath191_{x^0,z } \\right \\}.   \\label{newv}\\end{aligned}\\ ] ] although we have assumed that @xmath72 , the expressions of ( [ newxi ] ) and ( [ newv ] ) are likely to hold for @xmath75 as well . therefore the average free energy @xmath192 can be evaluated by substituting these expressions into the formula @xmath193_{{\\boldsymbol{\\phi}},{\\boldsymbol{x}}^0 } \\right ) $ ] .    in the limit of @xmath80 , a nontrivial saddle point",
    "is obtained only when @xmath194 is kept finite .",
    "accordingly , we change the notations of the auxiliary variables as @xmath195 , @xmath196 , and @xmath197 .",
    "furthermore , we use the asymptotic forms @xmath198 and @xmath199 using these in the resultant expression of @xmath192 offers ( [ eq : free energy ] ) .",
    "the 1-step replica symmetry breaking ( 1rsb ) ansatz means that , at the relevant saddle point , @xmath62 replica indices @xmath200 are classified into @xmath201 groups of an equal size @xmath202 , and @xmath203 holds if @xmath68 and @xmath204 belong to an identical group and @xmath205 , otherwise .",
    "this yields the following expression of the average free energy of finite temperature : @xmath206_{x^0,z } \\right   .",
    "\\cr & &   \\hspace*{0cm}-\\frac{1}{2\\beta}(\\hat{q}+\\hat{q}_1)+\\frac{\\hat{q}_1}{2\\beta } ( 1-q_1)+\\frac{p}{2\\beta } ( \\hat{q}_1q_1-\\hat{q}_0q_0 ) + \\frac{1}{\\beta}\\hat{m}m\\cr & & \\hspace*{0cm}\\left",
    ".   -\\frac{2\\alpha}{\\beta p}\\ ! \\int \\ ! { \\rm d}z h\\left ( \\!\\frac{m } { \\sqrt{\\rho q - m^2}}z\\ !",
    "\\right ) \\ln \\left ( \\int { \\rm d}t \\exp \\left ( -p { \\cal y}_1 \\right ) \\right ) \\right \\ } ,   \\label{1rsb}\\end{aligned}\\ ] ] where @xmath207 , @xmath208 , @xmath209 , and @xmath61_{x^0,z}=\\int dx^0 p(x^0)\\int { \\rm d}z \\left ( \\cdots \\right ) $ ] .",
    "the rs solution is regarded as a special case of the 1rsb solution for which @xmath210 holds .",
    "therefore one can check the thermodynamical validity of the rs solution by examining the stability of the solution of @xmath211 under the 1rsb ansatz .",
    "the extremization condition of ( [ 1rsb ] ) indicates that @xmath212_{x^0,z } \\cr & & \\phantom{q_1-q_0 } \\simeq \\left [ \\left ( \\frac{\\partial^2 { \\cal y}_0^{\\rm rs}}{\\partial ( \\sqrt{\\hat{q}_0}z ) ^2 } \\right ) ^2   \\left ( \\frac{\\int { \\rm d}t",
    "e^{-p { \\cal y}_0 } t^2}{\\int { \\rm d}t e^{-p { \\cal y}_0 } } -\\left ( \\frac{\\int { \\rm d}t e^{-p { \\cal y}_0 } t}{\\int { \\rm d}t e^{-p { \\cal y}_0 } } \\right ) ^2   \\right ) \\right ] _ { x^0,z } ( \\hat{q}_1-\\hat{q}_0 ) \\cr & & \\phantom{q_1-q_0 } \\simeq \\left [ \\left ( \\frac{\\partial^2 { \\cal y}_0^{\\rm rs}}{\\partial ( \\sqrt{\\hat{q}_0}z ) ^2 } \\right ) ^2   \\right ] _ { x^0,z } ( \\hat{q}_1-\\hat{q}_0 )   \\label{at1}\\end{aligned}\\ ] ] and @xmath213 hold for @xmath214 and @xmath215 irrespectively of the value of @xmath202 . here",
    "@xmath216 and @xmath217 represent assessments of @xmath218 and @xmath219 under the assumptions of @xmath220 and @xmath211 , respectively . in ( [ at1 ] ) and ( [ at2 ] ) we used the taylor expansion expressions @xmath221 and @xmath222 , and the fact that the variances of @xmath223 for the measures @xmath224 and @xmath225 become unity as @xmath226 and @xmath227 vanish , irrespectively of the value of @xmath202 .    to examine the stability of the rs solution in the limit of @xmath80 ,",
    "let us change the variable notations as @xmath228 , @xmath229 , @xmath230 , @xmath231 , and @xmath232 and set @xmath233 and @xmath234 .",
    "this yields expressions of @xmath235 and @xmath236 for @xmath237 .",
    "substituting these into ( [ at1 ] ) and ( [ at2 ] ) leads to @xmath238_{x^0,z } \\hat{\\delta }   \\label{at1new}\\end{aligned}\\ ] ] and @xmath239 where we set @xmath240 and @xmath241 , and used @xmath242 .",
    "the condition that ( [ at1new ] ) and ( [ at2new ] ) allow a solution of @xmath243 offers ( [ at ] ) .",
    "we refer to the system in which @xmath121 and @xmath122 are kept out as the @xmath244-cavity and @xmath245-cavity systems , respectively .",
    "in addition , we denote @xmath246 , @xmath247 and @xmath248 as the single - body cost function for the @xmath245-cavity system and its parameters , respectively , and similarly for @xmath249 , @xmath250 and @xmath251 .",
    "self - consistent equations are derived from the following arguments . +",
    "* vertical step : * + let us suppose that @xmath121 is put into the @xmath244-cavity system , which yields an approximation of the cost function of ( [ coupled_cost ] ) as @xmath252 . from this function",
    "we remove all terms that are related to @xmath253 of a certain index @xmath254 , which leads to an approximate cost function of the @xmath245-cavity system .",
    "@xmath246 must be obtained by partially optimizing the resulting @xmath245-cavity cost function with respect to @xmath255 of the remaining indices @xmath256 , where @xmath257 generally denotes the set provided by removing an element @xmath68 from a set @xmath258 .",
    "this offers the relation @xmath259 this relation and the fact that @xmath260 is a negligibly small independent sample from an identical gaussian distribution with zero mean and variance @xmath28 yield the following equations evaluating @xmath247 and @xmath248 from a set of @xmath261 and @xmath262 : @xmath263    * horizontal step : * + similarly , putting @xmath122 into the @xmath245-cavity system and removing @xmath121 yields another relation , @xmath264 which offers @xmath265 + * recovery step : * + @xmath123 and @xmath138 are evaluated from ( [ hstepb ] ) and ( [ hstepk ] ) as @xmath266 this means that the recovered signal is provided as @xmath267 where @xmath268 is determined in such a way that @xmath132 holds .",
    "similarly , @xmath269 are obtained from ( [ vstepa ] ) and ( [ vsteph ] ) .",
    "these offer the ( approximate ) optimal value of the lagrange multiplier @xmath270 as @xmath271 equations ( [ vsteph ] ) and ( [ rsteph ] ) indicate the difference between @xmath272 and @xmath273 is vanishingly small for @xmath274 as @xmath260 scales as @xmath275 , and similarly for @xmath251 and @xmath120 .",
    "this also allows us to handle @xmath123 and @xmath247 as a single site - independent parameter @xmath125 , and we similarly deal with @xmath276 and @xmath250 as @xmath126 .",
    "these considerations , in conjunction with ( [ rstepa ] ) and ( [ rstepb ] ) , offer @xmath277 where we replaced @xmath278 in ( [ rstepa ] ) and ( [ rstepb ] ) with its expectation @xmath28 by utilizing the law of large numbers . furthermore , inserting @xmath279 and @xmath280 into ( [ rsteph ] ) and ( [ rstepk ] ) , respectively , yields @xmath281 and @xmath282 where we set @xmath283 . equations",
    "( [ recoveredx ] ) , ( [ recovereda ] ) , and ( [ singlea])([singlek ] ) lead to ( [ bpnaive1])([bpnaive4 ] ) .",
    "99 cands e j and wakin m b , 2008 _ ieee signal processing magazine _ march 2008 , 21 donoho d l , 2006 _ ieee trans .",
    "inform . theory _ * 52 * 1289 cands e j , romberg j and tao t , 2006 _ ieee trans .",
    "inform . theory _ * 52 * 489 kabashima y , wadayama t and tanaka t , 2009 _ j. stat .",
    "( 2009 ) l09003 ; _ j. stat .",
    "( 2012 ) e07001 ganguli s and sompolinsky h , 2010 _ phys .",
    "lett . _ * 104 * 188701 krzakala f , mzard m , sausset f , sun y f and zdeborov l 2012 _ phys .",
    "x _ * 2 * 021005 ` https://sites.google.com/site/igorcarron2/compressedsensinghardware ` elad m , 2010 _ sparse and redundant representations : from theory to applications in signal and image processing _ ( new york : springer ) starck j - l , murtagh f and fadili j m , 2010 _ sparse image and signal processing : wavelets , curvelets , morphological diversity _ ( new york : cambridge university press ) lee d , sasaki t , yamada t , akabane k , yamaguchi y and uehara k , 2012 _ in proceedings of ieee vehicular technology conference ( vtc spring ) _ boufounos p t and baraniuk r g 2008 _ in proceedings of ciss2008 _ 16 dotsenko v s , 2001 _ introduction to the replica theory of disordered statistical systems _ , ( cambridge : cambridge university press ) mzard m , parisi g and virasoro m a , 1987 _ spin glass theory and beyond _ ( singapore : world scientific ) mzard m and montanari m , 2009 _ information , physics , and computation _ ( new york : oxford university press ) mackay d j c 1999 _ ieee trans .",
    "inform . theory _ * 45 * 399 ; mackay d j c and neal r m , 1997 _ elect . lett . _ 33 457 kabashima y and saad d , 1998 _ europhys lett _ * 44 * 668 de almeida j r l and thouless d j , 1978 _ j. phys .",
    "a _ * 11 * 983    thouless d j , anderson p w and palmer r g , 1977 _ phil . mag . _ * 35 * 593 shiino m and fukai t , 1992 _ j. phys .",
    "a _ * 25 * l375 kabashima y , 2003 _ j. phys . a _ * 36 * 11111 jacques l , laska j n and boufounos p t and baranuik r g , 2011 _ robust 1-bit compressive sensing via binary stable embeddings of sparse vectors _"
  ],
  "abstract_text": [
    "<S> compressed sensing is a framework that makes it possible to recover an @xmath0-dimensional sparse vector @xmath1 from its linear transformation @xmath2 of lower dimensionality @xmath3 . </S>",
    "<S> a scheme further reducing the data size of the compressed expression by using only the sign of each entry of @xmath4 to recover @xmath5 was recently proposed . </S>",
    "<S> this is often termed the _ </S>",
    "<S> 1-bit compressed sensing_. here we analyze the typical performance of an @xmath6-norm based signal recovery scheme for the 1-bit compressed sensing using statistical mechanics methods . </S>",
    "<S> we show that the signal recovery performance predicted by the replica method under the replica symmetric ansatz , which turns out to be locally unstable for modes breaking the replica symmetry , is in a good consistency with experimental results of an approximate recovery algorithm developed earlier . </S>",
    "<S> this suggests that the @xmath6-based recovery problem typically has many local optima of a similar recovery accuracy , which can be achieved by the approximate algorithm . </S>",
    "<S> we also develop another approximate recovery algorithm inspired by the cavity method . </S>",
    "<S> numerical experiments show that when the density of nonzero entries in the original signal is relatively large the new algorithm offers better performance than the abovementioned scheme and does so with a lower computational cost . </S>"
  ]
}