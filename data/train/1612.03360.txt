{
  "article_text": [
    "deployment of nanodevices has profound technological implications , and opens up unique opportunities in a wide range of applications , particularly in medicine , for disease detection , control and treatment .",
    "each nanodevice alone has a very limited operational capability . to increase their capability for complicated tasks , as required in many nano- and bio - technology applications ,",
    "it is essential to envision nanonetworks and study nanoscale communication .",
    "the size and power consumption of transceivers make the electromagnetic wave based communication rather unsuitable for interconnecting nanomachines .",
    "this motivates the use of molecular communication ( mc ) as a promising communication mechanism ( e.g. , see @xcite or @xcite ) .",
    "furthermore , being the prevalent communication mechanism in nature among living organisms , mc nanonetwork can use the existing micro - organisms , such as bacteria and cells , as part of network and is more compatible with the human body , a feature which is necessary for biomedical applications .",
    "we should note that even though mc was initially envisioned for nanoscale communications , there are also some potential macroscale applications for it , _",
    "e.g. _ , underwater communication where electromagnetic waves can not be efficiently employed over a long distance since they experience very high attenuations @xcite .",
    "mc is defined as a communication strategy that uses molecules as information carrier instead of electromagnetic waves .",
    "information can be coded in the type , concentration or release time of molecules that are spread in the medium . as with any other practical communication medium , uncertainty , imperfection and noise",
    "exist in mc , fundamentally limiting the system performance .",
    "the existing literature on mc provides various mathematical models of a molecular communication system , each of which is , in principle , amenable to capacity calculation .",
    "furthermore , just like classical communication , the optimal use of mc for the purposes of coordination , function computation , or control can be studied , using information theoretic tools .",
    "the idea of determining ultimate achievable limits is a helpful notion and provides an opportunity for information theorists to collaborate in the development of the theory of mc .",
    "furthermore , mc can inspire new interesting problems for information theorists of mathematical orientation to look at .",
    "nanocells and nanodevices can only perform operations due to their small physical scale and limitation of resources . in his 2002 shannon lecture on  living information theory \" , toby berger points to the fact that living systems employ simple structures in encoding and decoding information , and have  little if any need for the elegant block and convolutional coding theorems and techniques of information theory . \"",
    "berger argues ( mainly in the context of neural networks ) that this is because communication medium has adapted itself to the data sources in the evolutionary process .",
    "therefore , the optimality of encoder and decoders with simple structures is due to the fact that the channel and the data are matched .",
    "uncoded transmission , in particular , is an appealing strategy for biological applications , and is shown to be provably optimal in some settings @xcite . but simplicity may find other justifications besides adaptation in the evolutionary process . fixing the uncoded transmission , it is shown in @xcite that a certain memory - limited simple decoder is performing close to the optimal decoder .",
    "conversely , in @xcite , we fix a simple decoder and show that a certain memory - limited simple encoder is near optimal .",
    "these results seem to suggest that even though the optimal transmitter and maximum likelihood ( ml ) decoder may have complicated descriptions , the nature of the molecular channel is such that _ simplicity propagates _ : if some components of a mc system are forced to be structurally simple ( due to their physical limitation ) , then using complicated coding strategies at other components comes at a negligible benefit .",
    "differences between classical and molecular communication open up the possibility of defining new problems for information theorists .",
    "some of these differences are as follows :    * complexity : * mc may be used for both microscale and macroscale applications . in the case of microscale applications , complexity is a more serious issue compared to classical communication due to the small scale of nanodevices .",
    "nanodevices are simple and resource limited devices .",
    "an important question is how to find a proper theoretical framework for studying the limitation of computational resources in the context of mc .",
    "so far , the molecular communication literature has treated complexity in a loose manner .",
    "simplicity is generally invoked to justify certain restrictions of molecular encoders and decoders to a class of intuitive and easy - to - analyze functions . unfortunately",
    ", classical information theory does not accommodate for a quantitative restriction on the degree of simplicity ( limitations of computational capacity or memory ) of the encoder and decoder .",
    "coding theory aims to find practical capacity achieving codes with affordable encoder and decoder complexity .",
    "furthermore , finite blocklength and one shot results in information theory relate to complexity .",
    "nonetheless , proving fundamental lower bounds on the complexity can be a very difficult problem , and computational formulations such as the ones given in @xcite are too formal and abstract .",
    "the progress has been mainly within the context of specific circuit models , _",
    "e.g. _ , authors in @xcite consider the vlsi model to estimate the complexity of the implementation of an error correcting code ( see also @xcite for further computational results based on the vlsi circuit model ) . to sum this up , the development of a similar  molecular circuit model \" seems to be the most promising direction to address the computational aspects of mc .",
    "* nature of transmitter and receiver * : even when there is no channel noise , the capacity of a mc system is constrained by the physics of transmitter and receiver : the transmitter s _ actuation _ in response to excitement can be imperfect ; the receiver may have a fundamental _ sensing noise _ , which is independent of the channel noise .",
    "for instance , in ligand receptors where incoming molecules bind with receptors on the surface of the receiver , the sensing noise has a variance that is dependent on the amplitude of the signal @xcite , _",
    "i.e. _ , the higher the amplitude of the signal , the larger the variance of its observation noise .",
    "also , both the transmitter and receiver may be allowed to actively modify the communication medium itself by releasing chemicals in the environment .",
    "furthermore , similar to classical communication , the transmitter and receiver may be mobile , causing a change in the effective channel between the transmitter and the receiver .",
    "however , unlike the classical communication , the direction of mobility may itself be influenced by the concentration of molecules released in the environment by other nodes ( as in chemotaxis of many cells ) .",
    "* use of multiple molecule types : * in mc , we can employ multiple molecule types for signaling .",
    "a classical analogue of this degree of freedom is frequency : channels of different molecule types can correspond to channels over different frequencies .",
    "but there are some crucial limitations to this analogy : unlike waves moving on different frequencies , molecules of different types might undergo chemical reactions with each other as they travel from the transmitter to the receiver",
    ". these reactions among different molecule types can result in a nonlinear channel @xcite .",
    "furthermore , molecules of different types might compete with each other at the receiver in terms of binding with receptors on the surface of the receiver ; if a receptor bonds with one molecule type , it will be unable to bond with other molecule types for a period of time .",
    "* positivity of the input signal : * the linearity and time - invariance of wireless channel enables one to borrow tools from linear algebra or fourier analysis .",
    "macroscopic diffusion in a stable medium also results in a linear and time - invariant system .",
    "however , we can not readily use tools from fourier analysis : unlike electromagnetic waves whose amplitude can become negative , only a non - negative concentration of molecules can be released in the environment .",
    "the non - negativity constraint in the time domain does not have an easy equivalent in the fourier domain .",
    "to simulate negative signals , authors in @xcite suggest exploiting chemical reactions to reduce the concentration of a molecule type .",
    "unfortunately , diffusion with chemical reactions follows a _ non - linear _ differential equation , prohibiting the use of linear theories ( see @xcite for a partial solution based on the fact that even though the concentration of each molecule type follows a non - linear differential equation , the difference of the concentrations still follows a linear differential equation under some assumptions ) .",
    "* energy limitation : * in mc , in contrast to the classical communication , some energy is required to synthesize a molecule . while increasing the concentration of released molecules increases the channel capacity , the amount of energy consumed for their synthesis and transmission in an active transport mc channel increases as well .",
    "thus , for the energy limited mc system , by taking into account the energy required for synthesizing the molecules , there exists an optimum number of released molecules @xcite .",
    "the classical analogue of this ( for electronic circuits ) is given in @xcite where it is shown that approaching shannon s capacity may require very large energy consumption .",
    "* slow propagation : * when studying mc via diffusion in an aqueous or gaseous medium , we should note that the speed of transmission is slow .",
    "the slow propagation in conjunction with possible changes in the medium has implications in terms of mathematical modeling of the problem .",
    "for instance , this can make it difficult to obtain channel state information at the encoder via a feedback link from the decoder .",
    "next , because of the slow propagation of released molecules , self - interference among successive transmission is a challenge . as stated above , the concentration of molecules in an environment is a non - negative quantity .",
    "this prevents the employment of some classical techniques for capacity evaluation , such as fourier transform to convert an inter - symbol - interference ( isi ) channel to a parallel memoryless channel .",
    "* focus of this paper : * there are many existing works that address various aspects of mc , sometimes from an information theoretic perspective .",
    "we are selective in reviewing these works .",
    "our focus are on the works that are more theoretical and appealing to pure information theorists .",
    "for instance , there are many works that model a molecular communication system with a memoryless channel and then evaluate the capacity of the resulting channel . while valuable because of their modeling aspects , their analysis may not be exciting to information theorists .",
    "we are more interested in works that do not just borrow and apply tools from information theory , but can rather attract information theorists and help form a dialogue between molecular communication and information theory .",
    "there is one more caveat : we do not review a few number of works ( mostly published in biological journals ) that explain evolution of biological structures by arguing that a certain information theoretic criterion is optimized .",
    "genomics and molecular biology is listed as one of the future research directions in information theory by a number of information theorists @xcite , even though molecular communication is not specifically mentioned .",
    "nonetheless , molecular communication continues to attract the attention of more information theorists ( as evidenced by sessions dedicated to it in the isit conferences ) , and our hope is that this paper encourages more to join .",
    "this paper is organized as follows : we begin by reviewing transmitter , channel and receiver models for mc in section  [ sec : model ] . depending on the choice of the transmitter and receiver model , a number of end - to - end models",
    "are given in section  [ sec : end - to - end - rev ] .",
    "next , a section is devoted to each of the end - to - end models : in section  [ sec : concen ] and section  [ sec : rel_time ] we review capacity results for a transmitter that puts information on the concentration , and on the release time of molecules , respectively",
    ". we also review the results on the capacity of the ligand - receptor in section  [ sec : ligand ] .",
    "next , we turn to a multi - user setting in section  [ sec : cascade ] .",
    "molecular channels have memory , and capacity of network of channels with memory is of relevance to mc . in section  [ sec :",
    "cascade ] , we pose and discuss ( in detail ) the problem of finding the capacity of a cascade of channels with memory . finally , we present some concluding remarks in section  [ sec : concl ] . some of the proofs are moved to appendices .",
    "* notation : * throughout , we use capital letters to denote random variables and small letters to denote their values . the set @xmath0 is shown by @xmath1 $ ] . the sequence @xmath2 is shown by @xmath3 .",
    "the input to the channel is generally denoted by rv @xmath4 , and the output is denoted by either @xmath5 or @xmath6 .",
    "a point to point engineered communication system consists of a transmitter , a channel , and a receiver , as shown in fig .",
    "[ system_model ] .",
    "we employ this structure in our review of a molecular communication system .",
    "a molecular transmitter is a biological or engineered cell whose actions influence the density of molecules in the environment ( generally by emitting molecules in the environment ) . for a discussion . ]",
    "a molecular channel refers to a physical medium in which molecules propagate .",
    "a molecular receiver ( or sensor ) is a biological or engineered cell that is influenced by the density of molecules in the environment at its vicinity .    in the following three subsections ,",
    "we discuss the molecular transmitter , channel and the receiver , separately .",
    "besides this , observe that the physical structure of the transmitter or receiver imposes some limitations and imperfections on the transmission and reception processes .",
    "therefore , it is also possible to lump together the imperfections of the transmitter , channel , and receiver and define an end - to - end channel model .",
    "we discuss the end - to - end models in the final subsection . despite the fact that there are established models for the diffusion process ,",
    "modeling the uncertainty originated from the transmitter and the receiver is still an open area for research .",
    "a transmitter may be modeled as a point source of molecules , located at the origin .",
    "the transmitter can control the concentration , the type , and the release time of molecules at its location . as an example",
    ", information can be encoded in the concentration by releasing nothing for information bit @xmath7 , and releasing a given concentration of molecules for bit @xmath8 ( on - off keying ) ; information can be encoded in the type by releasing molecules of type @xmath9 for bit @xmath7 , and molecules of type @xmath10 for bit @xmath8 .",
    "finally , information can be encoded in time by adjusting the release time of consecutive molecules based on the input bit",
    ".    released molecules diffuse in the environment .",
    "the number of released molecules depends on the distance between the transmitter and receiver .",
    "if the distance between the transmitter and receiver is very small , individual molecules may be transmitted one by one .",
    "if the distance is large , molecules get diluted in the environment before reaching the receiver , and the transmitter may need to send considerably more molecules to ensure a viable communication line to the receiver .",
    "_ transmitter imperfection : _ in practice , the transmitter can not perfectly control the number or the release time of the molecules .",
    "furthermore , the molecule generation process of the transmitter can impose its own inherent constraints on the transmitter .",
    "to model these imperfections , one has to know the exact physical implementation of the transmitter .",
    "for instance , a physical description of a transmitter is detailed in ( * ? ? ? * section iii.a ) . in @xcite ,",
    "different chemical reactions are considered for the emission of different symbols . in @xcite ,",
    "the transmitter is assumed to have a reservoir of molecules , with an outlet whose size is controlled by the transmitter . in other words , the transmitter may not control the exact number of molecules that exit the reservoir , but only the size of its outlet . given the large number of molecules in the reservoir and a small probability of each exiting through the reservoir , the number of molecules exiting the outlet can be assumed to follow a poisson distribution .",
    "therefore , in this model , the number of released molecules from the transmitter is a poisson random variable , where its average or rate is determined by the transmitter @xcite .",
    "the poisson model also arises in the following contexts :    * poisson distribution models the number of escaped particles from a bounded domain when gates on the boundary of the domain open and close randomly , _",
    "e.g. _ as in the escape of diffusing proteins from a corral in the plasma membrane ( * ? ? ?",
    "similarly , it arises in @xcite , wherein molecule release based on ion channels across the cell membrane is considered ; the opening and closing of these channels are controlled by a gating parameter .",
    "* it also arises when transmitter uses a colony of bacteria for molecule release .",
    "each receptor on a bacterium releases a molecule with a probability that depends on the amount of provocation by the transmitter .",
    "if @xmath11 is the release probability and @xmath12 is the total number of colony receptors , the number of released molecules follows a binomial distribution with parameters @xmath12 and @xmath11 .",
    "this can be approximated by a poisson distribution if @xmath12 is large and @xmath11 is small .    _",
    "transmitter models : _ in this paper we focus on the following transmitter models :    * _ timing transmitter _ : transmitter releases individual molecules one by one , at specified time instances . *",
    "_ exact concentration transmitter : _ a time slotted transmission strategy is employed : time is divided into intervals of length @xmath13 , with transmission occurring at the beginning of each time slot .",
    "the transmitter releases exactly @xmath14 molecules ( or @xmath14 moles of molecule if the communication is very long range ) at the beginning of the @xmath15-th time slot , _",
    "i.e. , _ at time @xmath16 .",
    "* _ poisson concentration transmitter : _ again a time slotted transmission strategy is employed .",
    "the number of released molecules from the transmitter at the beginning of the @xmath15-th time slot is a poisson random variable with mean @xmath14 .      to obtain a statistical model for a molecular channel",
    ", one has to specify the physical mechanism of molecule transport between the transmitter and the receiver .",
    "the physical motion of molecules towards the receiver may be walk - based , flow - based , or diffusion - based @xcite . in * walk - based mechanisms * , information molecules are encapsulated into a cargo , which then by a motor protein , such as dynein and kinesin , are pushed toward the destination through a pre - defined path , like microtubule tracks .",
    "it is an active propagation and requires chemical energy ( atp ) . in * flow - based mechanisms * , molecule propagation is influenced by an external flow , like propagation of hormones in the blood stream .",
    "flow is a one - way phenomenon , which makes it unsuitable for a two - way communication .",
    "in contrast , in the * diffusion - based transport * , the molecules randomly propagate in all available directions via brownian motion and have the most spontaneous motion .",
    "this results in a higher degree of uncertainty at the receiver , compared to the other mechanisms .",
    "the diffusion - based mechanism is completely passive and always available without any energy cost or prior infrastructure , and is mostly suitable for highly dynamic and unpredictable environments .",
    "it is also possible to consider diffusion - based transport in the presence of a drift , resulting in a mixture of diffusion and flow based mechanisms .",
    "most of the literature ( as well as this paper ) is focused on the diffusion - based transport mechanism .",
    "molecular diffusion can be studied from either _ microscopic _ or _ macroscopic _ points of view . in a microscopic point of view , the focus is on the random movement of individual molecules , known as the _",
    "brownian motion_. in a macroscopic point of view , the focus is on the overall behavior of an enormous number of molecules . even though each molecule still has a random movement , but",
    "the total average behavior is characterized by a deterministic differential equation ( due to the law of large numbers phenomenon ) ; this deterministic differential equation is called the _",
    "fick s law of diffusion_. historically , fick proposed his macroscopic law of diffusion in 1855 , while the microscopic brownian motion was studied later by einstein in 1905 ; a full mathematical theory based on the theory of stochastic differential equations was developed only later in the 20th century .      according to fick",
    "s first law of diffusion , diffusion flux goes from the region of high concentration to the region of low concentration .",
    "furthermore , the diffusion rate , denoted by @xmath17 , is proportional to the concentration gradient .",
    "for simplicity of exposition , let us consider one - dimensional diffusion . then , fick s first law is : @xmath18 where @xmath19 and @xmath20 are respectively the diffusion flux , and molecule concentration ( in molar ) at location @xmath21 at time @xmath22 ; @xmath23 is the diffusion coefficient of the environment .",
    "now , assuming that there are no chemical reactions , drift velocity , or injection of external molecules to the environment , we can use the mass conservation principle to conclude that @xmath24 to intuitively understand the above equation , for a @xmath25 , @xmath26 shows the entry rate of molecules from position @xmath21 minus the exit rate of molecules from position @xmath27 ; if there is a mismatch between the entry and exit rates , the total number of molecules in the interval @xmath28 $ ] changes at a rate equal to the difference of the entry and exit rates , _",
    "i.e. , _ at rate @xmath26 .    equations and give us fick s second law of diffusion : @xmath29 if in addition to the diffusion process , we also have a molecule production rate , the changes in molecule concentration will be both as a result of molecule production as well as diffusion , @xmath30 here , for a given time @xmath22 , @xmath31 denotes the density of molecule production rate at point @xmath21 , _",
    "i.e. , _ the number of molecules added to the environment in @xmath32 $ ] between time @xmath33 $ ] is equal to @xmath34 .",
    "then , we can write fick s second law as @xmath35 to solve this differential equation in an interval @xmath36 $ ] , it suffices to know the initial and boundary conditions : the initial density @xmath37 at time zero for @xmath38 .",
    "the boundary condition imposes some constraints on @xmath39 and @xmath40 as follows :    * known values of @xmath20 at @xmath41 for all @xmath42 : this corresponds to known concentration on the boundaries .",
    "a special case of this is the zero boundary condition : @xmath43 ; this corresponds to an absorbing boundary , _",
    "i.e. , _ molecules are absorbed and removed from the environment upon hitting the boundary of @xmath44 .",
    "* known values of @xmath45 at @xmath41 for all @xmath42 : this corresponds to known diffusion flux @xmath19 on the boundaries .",
    "a special case of this is the zero boundary condition : @xmath46 ; this corresponds to a reflecting boundary , _",
    "i.e. , _ molecules that hit the boundary walls are reflected back into @xmath44 .",
    "when @xmath47 is the entire real line , the boundary can be placed as we take the limits to infinity ; for instance , one can solve the differential equation assuming that @xmath20 vanishes at infinity ( as @xmath21 becomes large ) .",
    "as an example , consider a transmitter that is located at the origin ( @xmath48 ) , and at time @xmath49 suddenly releases one unit of molecules in the environment . in this case , the molecule production rate will be equal to @xmath50 . in response to this input , the output @xmath20 from equation ( assuming vanishing @xmath20 at infinity ) is equal to the green s function : @xmath51}{(4\\pi dt)^{0.5 } }   e^{-\\frac{x^2}{4dt}}.\\label{eqn : impulse1d}\\end{aligned}\\ ] ] observe that for a fixed @xmath22 , @xmath52 as a function of @xmath21 is the pdf of a gaussian distribution with variance @xmath53 .",
    "this is no coincidence , and will become more transparent once we consider the microscopic interpretation of the diffusion process .    if there is a drift , in addition to pure diffusion , influencing the molecules motion , the modified fick s laws may be employed to analyze the molecular channel . solving the differential equations representing fick s laws can be very cumbersome when non - ideal assumptions are considered , _",
    "e.g. _ , non - homogeneous environment , bounded space , or turbulent diffusion .",
    "thereby , obtaining explicit channel models for molecular communication becomes complicated .",
    "a more difficult condition occurs when we consider multiple diffusing molecules subject to chemical reactions . while one can still find the differential equations that describe the process",
    ", a closed form analytical solution may not exist .      in his celebrated work in 1905",
    ", einstein showed that the density function of the movement of a single particle under brownian motion satisfies the differential equation given by fick s second law of diffusion .",
    "there are different equivalent ways to formally define the brownian motion , which is a continuous time , random - walk process ; _ e.g. , _",
    "compare @xcite and @xcite .",
    "the one - dimensional brownian motion @xmath54 can be defined as follows @xcite : ( i ) future displacements of the particle are independent of past movements . in other words , for @xmath55 , @xmath56 is independent of @xmath57\\}$ ] ; ( ii ) increments are normally distributed , _",
    "i.e. , _ for @xmath55 , @xmath56 is a gaussian variable @xmath58 .",
    "the definition of brownian motion is self - consistent , because sum of independent normal variables is also a normal variable .",
    "now , assume a single particle released at time zero , at the origin : @xmath59 .",
    "let us denote the distribution of the location of the particle at time @xmath22 by @xmath52 .",
    "then , the particle at time @xmath22 follows a normal distribution with variance @xmath53 , and @xmath20 has the same value as given in equation .",
    "both probability density function of a single particle ( microscopic ) , and the concentration profile of molecules ( macroscopic ) satisfy fick s diffusion law , even though these two are conceptually different .",
    "for instance unlike the integral of a density function , the integral of the concentration on the entire space ( _ i.e. _ , the total number of molecules ) can be greater than one .",
    "next , note that to solve fick s differential equation , boundary conditions are also needed .",
    "these can be imposed in the microscopic perspective in same manner as they are imposed in the macroscopic perspective .",
    "then , the distribution of the particle at time @xmath22 can be found by solving fick s law of diffusion with proper boundary conditions .",
    "we refer the reader to ( * ? ? ?",
    "* section 2.2 ) for an illustrative discussion of einstein s connection between the brownian motion random walk and diffusion . for a rigorous mathematical discussion , see @xcite .",
    "but to explain the connection at an intuitive level , assume that a very large number of molecules , @xmath12 molecules , are released at time zero at the origin .",
    "these molecules move randomly and independently of each other .",
    "assume that each molecule falls into the interval @xmath60 $ ] with probability @xmath61 .",
    "then , since there are @xmath12 molecules and each molecule falls in @xmath60 $ ] independently of other molecules , the number of molecules that fall in @xmath60 $ ] is distributed according to a binomial distribution with parameters @xmath62 .",
    "the expected value of this random variable is equal to @xmath63 . by the law of large numbers , for a fixed @xmath64 , if we let @xmath12 go to infinity , the binomial distribution has a sharp concentration around this expected value .",
    "for instance , if @xmath12 is one mole of molecules ( @xmath65 ) , then @xmath66 can be expressed as @xmath20 molar .",
    "then , the mapping @xmath67 also gives us the average macroscopic concentration profile of molecules as a function of @xmath22 and @xmath21 in terms of molar . on the other hand , we know that the macroscopic concentration satisfies the fick s laws of diffusion . as a result",
    ", @xmath20 satisfies the fick s laws of diffusion .",
    "the above argument also provides a bridge between the macroscopic and microscopic perspectives : the macroscopic concentration is @xmath68 , where the microscopic probability density is @xmath20 , and the number of molecules that fall into interval @xmath60 $ ] is distributed according to a binomial distribution with parameters @xmath62 .",
    "this binomial distribution may be approximated by gaussian or poisson distributions @xcite . in case of large @xmath69 ( even for small @xmath64 ) , the binomial distribution can be approximated with a normal distribution with mean @xmath63 and variance @xmath69 @xcite . with the assumption that @xmath61 is small , the variance @xmath69 can be approximated with @xmath63 .",
    "then , the density of molecules , _",
    "i.e. , _ the number of molecules divided by @xmath64 , follows a normal distribution with mean @xmath70 and variance @xmath71 . to sum this up , if the macroscopic perspective on diffusion predicts a concentration @xmath72 molecules per volume , the actual concentration of molecules per volume ( in an interval @xmath64 ) is a normal random variable whose mean is @xmath72 , and whose variance is @xmath73 .",
    "[ example : rev1 ] fick s law of diffusion in terms of probability demonstrates how the distribution of the particle s location at time @xmath22 , denoted by @xmath20 , changes over time . to show the use of this fact , consider a transmitter located at the origin @xmath48 , and an absorbing receiver located at @xmath74 , at distance @xmath75 from the transmitter .",
    "an absorbing receiver is particularly important in molecular communication and the result of the following derivation is used elsewhere in the paper",
    ".    assumed that a single molecule is released at time zero , therefore the initial distribution of the particle at @xmath49 is @xmath76 .",
    "the molecule disappears upon hitting the receiver . solving for fick s equation with the boundary conditions @xmath77 and @xmath78",
    ", we can obtain @xmath79 as the probability that the particle is located in @xmath32 $ ] at time @xmath22 .",
    "we refer the reader to ( * ? ? ?",
    "* section 2.5 ) for the technique for solving fick s differential with this boundary condition .",
    "then , the probability that the particle has not hit the receiver by time @xmath22 is equal to @xmath80 in other words , if @xmath81 denotes the hitting time of a released particle with the absorbing receiver , the distribution of @xmath81 can be obtained as follows : @xmath82=\\int_{x=-\\infty}^{d}\\rho(x , t)dx.\\ ] ] in case of the diffusion equation given in in a one - dimensional free homogeneous medium with diffusion coefficient @xmath23 , the first arrival time @xmath81 at the receiver can be explicitly calculated .",
    "first shown by schrodinger in 1915 , @xmath81 has a lvy distribution @xcite @xmath83 where @xmath84 on the other hand , if the medium also has a velocity @xmath85 towards the receiver , the modified fick s law can be used to show that @xmath81 follows an inverse gaussian distribution , @xmath86 @xcite : : @xmath87 where @xmath88 note that lvy is a heavy - tailed distribution ( has infinite mean and variance ) , while ig has an exponentially decreasing tail .",
    "[ sec : mic ]      to construct a statistical model for a molecular channel , the microscopic and macroscopic views of the diffusion should be appropriately utilized . on the transmitter side ,",
    "if only a few molecules are released , the microscopic perspective is relevant .",
    "however , if a large number of molecules are released by the transmitter , the macroscopic perspective becomes relevant . on the other hand , in case of a single tiny molecular receiver , the microscopic behavior of molecules around the receiver is of importance . as a result ,",
    "if a large number of molecules are released by the transmitter and the receiver is a single tiny nanomachine , we can employ the macroscopic view to compute the molecular concentration around the receiver , but then switch to the microscopic view as discussed in section [ sec : mic ] , and consider the actual number of molecules around the receiver .",
    "this is done explicitly later in section [ sec : end - to - end - rev ] .",
    "finally , we comment that while in the above we restricted to one - dimensional diffusion , similar formulas hold for diffusion in three dimensions . while fick s law have extensions for nonhomogeneous environment with general boundary conditions , most existing works study the simple case of an infinite medium in each direction , with no barrier or obstacle except the receiver surface",
    ".      there are different models of the receiver in the literature :    * _ sampling receiver : _ the simplest model for a receiver is a device that measures the macroscopic molecular concentration at a given point .",
    "the receiver s observation is assumed not to affect the diffusion of the molecules , hence it imposes no boundary conditions when solving fick s law of diffusion .",
    "the receiver may be assumed to sample the medium at certain given time instances . * _ transparent receiver : _ in this model , the receiver is a transparent sphere of volume @xmath89 rather than a point , but still not affecting the diffusion of the molecules .",
    "hence it imposes no boundary conditions when solving fick s law of diffusion .",
    "we may assume that the receiver can perfectly _ count _ the number of molecules that fall into its sphere .",
    "this is the model used in @xcite ( see also @xcite ) .",
    "the ( microscopic ) transparent receiver differs from the ( macroscopic ) sampling receiver as follows : as discussed in section [ micro - section ] , if a sampling receiver reads @xmath20 , a transparent receiver reads a normal random variable whose mean is @xmath90 , and whose variance is @xmath91 . * _ absorbing receiver : _ the receiver absorbs any molecule that hits its surface .",
    "it keeps a count of the number of molecules that have hit it so far . absorbing receivers imply the zero boundary condition when solving the fick s law of diffusion . * _ ligand or reactive receiver : _ this model is based on the receptors of natural cells that are used in biological signaling pathways .",
    "it considers chemical kinetics of receptors located on the surface of the receiver .",
    "more specifically , it assumes that molecules reaching the surface of the receiver may react and bind with the receptors on the surface of the receiver and thereby initiate a chemical process inside the cell .",
    "the literatures generally consider cyclic adenosine monophosphate ( camp ) receptors that have a simple state space for each receptor : each receptor may be in the bound ( b ) or unbound ( u ) state with incoming molecules .",
    "output at the receiver is the number of bound receptors .",
    "one important feature of a ligand receptor is its lingering effect , which is due to the fact that it takes some random time for each receptor to be detached , after binding .",
    "the state transition of each receptor depends on the concentration of molecules around the receptor , and is governed by chemical equations @xcite . + the most simplifying model is to take the statistical average of the number of bound receptors to approximate the output , but then add a signal - dependent memoryless gaussian noise to represent all the modeling imperfections , _",
    "i.e. , _ the output can be expressed as:@xmath92 for some constant @xmath93 and gaussian noise @xmath12 @xcite . in @xcite ,",
    "a memoryless binomial@xmath94 distribution is used for the number of bound receptors , where @xmath95 is the total number of receptors and the binding probability @xmath11 is a function of concentration around the receptors . in @xcite ,",
    "the number of bound receptors is modeled by a poisson distribution whose parameter depends on the concentration of molecules around the receiver . + more accurate models of the ligand receptor use markov chains to better represent chemical equations at the receptors and the memory of the system .",
    "the state transition probabilities of the markov chain depend on the concentration of molecules around the receiver @xcite . more specifically ,",
    "if there are @xmath95 receptors on the surface of the receiver , we can denote the state by a vector in @xmath96 .",
    "the state at time instance @xmath15 is also the output of the receiver , @xmath97 .",
    "the state transition probability @xmath98 specifies the behavior of the ligand receptor @xcite .",
    "the only assumption made about @xmath98 in @xcite is that when a receptor is in bound ( b ) state , the probability that it becomes unbound ( u ) does not depend on concentration @xmath14 .",
    "+ finally , authors in @xcite consider the boundary condition that a ligand receptor imposes ( the boundary condition needed for solving the fick s law of diffusion ) .",
    "the ligand receptor is modeled by a partially absorbing boundary condition , in conjunction with an active source of molecules .",
    "the partially absorbing boundary condition reflects the fact that molecules hitting a receptor might not bind with the receptor and get reflected back into the environment ( hence partially absorbing , partially reflecting ) , and furthermore , a bound receptor might unbind and release a molecule and hence an active source of molecule is included in the model .      in this section",
    ", we review a number of existing end - to - end models derived by jointly considering the transmitter , diffusion channel and receiver",
    ". it may be impossible to analyze and model the end - to - end molecular channel independent from the release and reception mechanisms at the transmitter and receiver , respectively .",
    "in other words , the release and the reception mechanisms may have mutual effects with the molecular channel .",
    "thereby , a joint analysis including the release , the transport , and the reception mechanisms is required .",
    "considering the three types of transmitter ( timing transmitter , exact concentration and poisson concentration transmitter ) and the four types of receiver ( sampling receiver , transparent receiver , absorbing receiver , and ligand receiver ) , one can potentially identify @xmath99 combinations .",
    "however , some of the combinations are not meaningful ( _ e.g. _ , the combination of a timing transmitter and a sampling receiver ) , and some are mathematically challenging ( _ e.g. _ the combination of the ligand receiver with any of the three transmitters ) . while transparent receiver @xcite , absorbing receiver @xcite , and ligand receptors @xcite are all considered in the literature , only few of the possible transmitter / receiver combinations are studied .",
    "we shall review these combinations in the sequel . in describing an end - to - end model",
    ", it is useful to keep in mind the five types of noise that may need to be accounted for @xcite .",
    "the first type is the _ diffusion noise _ due to the random propagation of individual molecules according to brownian motion .",
    "we also have an environmental noise due to the _ degradation and/or reaction _ of molecules .",
    "there is also a _",
    "multiple transmitters noise _ from molecules diffused by unintended transmitters . finally , there are two types of noise due to the physics of transceivers : the _ transmitter emission noise _ and _ receiver counting / reception noise_.    in all of the models presented here , for simplicity and for being tractable , the transmitter is considered as a point source of molecules , located at the origin , and molecules are assumed not to change while propagating in the medium and also not interact with the transmitter .",
    "motions of molecules do not influence each other and can be modeled by independent processes . also , when using a concentration transmitter , a time - slotted communications with symbol period of @xmath13 is assumed .",
    "the transmitter and receiver are assumed to be synchronized .",
    "fick s laws are employed in the models in different ways to determine the parameters of the model .",
    "the models that have an exact concentration transmitter with sampling or transparent receivers are also called the _ linear models _ ( also known as the _ deterministic models _ ) .",
    "they are described as follows :    _ transmitter : _ the transmitter is assumed to be completely controlling the intensity of molecules at its location .",
    "the transmitter releases a large number of molecules ( macroscopic diffusion regime ) .",
    "the intensity should be non - negative .    _ medium : _ extending the fick s second law of diffusion ( stated in ) to three - dimensional space @xcite for a medium without any reaction and drift velocity , the concentration of molecules in the environment , denoted by @xmath100 , at location @xmath101 and at time @xmath22 is governed by @xmath102 in which @xmath23 is the diffusion coefficient of the transmitted molecule , and @xmath103 is the density of molecule production rate at point @xmath101 at time @xmath22 . assuming that the transmitter is located at the origin , and at time @xmath49 suddenly releases one unit of molecules in the environment , the density of the molecule production rate will be equal to @xmath104 . in response to this input ,",
    "the output @xmath100 from equation is equal to the green s function : @xmath105}{(4\\pi dt)^{1.5 } }   e^{-\\frac{\\|r\\|_2 ^ 2}{4dt}}.\\label{eqn : impulse}\\end{aligned}\\ ] ] thus , describes a linear time - invariant system , whose impulse response is given in .",
    "the transmitter has a clock with frequency @xmath106 , and instantaneously releases @xmath107 molecules every @xmath13 seconds , _",
    "i.e. , _ the density of production rate is the impulse train @xmath108 then using the linearity of the diffusion system , the concentration of molecules at location @xmath101 at time @xmath22 will be equal to @xmath109    _ receiver : _ the receiver has a clock too , with the same frequency @xmath110 ( or possibly multiples of it ) , using it to uniformly sample the medium at times @xmath111 for @xmath112 .",
    "we then have    * ( sampling receiver ) : assume that the receiver is modeled by a point , located at @xmath113 , and is not affecting the diffusion medium .",
    "furthermore , we assume that the receiver can perfectly learn the macroscopic concentration of molecules at the time of sampling .",
    "then , we obtain @xmath114 . from , @xmath115 has a convolution form where @xmath116 . from",
    ", it is clear that @xmath117 for @xmath118 , and thus the convolution can be written as : @xmath119 * ( transparent receiver ) : assume that the receiver is modeled by a transparent sphere of volume @xmath89 rather than a point , but still not affecting the diffusion medium .",
    "let us further assume that the receiver can perfectly _ count _ the number of molecules that fall into its sphere .",
    "this is the model used in @xcite ( see also @xcite ) . by similar arguments as given in section [ sec : mic ] , the distribution of the number of molecules falling in the receiver s volume at time @xmath111 has a normal distribution whose mean is the macroscopic concentration @xmath120 , and whose variance is @xmath121 .",
    "thus , the total number of molecules in receiver s sphere at time @xmath111 satisfies @xmath122 where the noise , _",
    "@xmath123 , is distributed according to @xmath124 .",
    "observe that when the input sequence ( and thus @xmath14 ) is random , @xmath123 will be a doubly stochastic random variable since the variance of the @xmath123 is itself a random variable and depends on past inputs .",
    "this model is shown in fig .",
    "[ linear ] .",
    "+   and convolves it with samples of the impulse response of the diffusion channel .",
    "finally , a signal dependent noise is added to the convolution term .",
    ", scaledwidth=100.0% ] + [ remark2d ] equation only provides the pmf ( probability mass function ) of @xmath125 given the input sequence . to completely specify the channel",
    ", one has to specify the correlation of @xmath125 and @xmath126 ( for any given @xmath127 ) , conditioned on the input sequence . in other words ,",
    "the correlation of @xmath123 and @xmath128 conditioned on @xmath129 should be specified .",
    "observe that the number of molecules in @xmath89 is changing continuously over time , increasing or decreasing by one when a molecule enters / exits the receiver volume .",
    "therefore , for very small values of @xmath13 , @xmath125 and @xmath130 will be correlated , conditioned on the past inputs , and we can not impose independence on @xmath123 and @xmath131 .",
    "s with jointly gaussian colored noises , whose correlation coefficients and variances depend on the input sequence @xmath129 . briefly speaking ,",
    "the correlation of @xmath123 and @xmath131 can be computed as follows : let @xmath132 be the probability that a released molecule falls in the receiver s sphere at times @xmath111 and @xmath133 .",
    "let @xmath134 be the probability that the molecule falls in the sphere at time @xmath111 , but does not fall at time @xmath133 ; @xmath135 is defined reversely and @xmath136 is the probability that molecule does not fall in either of times @xmath111 or @xmath133 .",
    "if we release a deterministic number @xmath21 of molecules at time zero , we can define a multinomial distribution @xmath137 with parameters @xmath21 and probabilities @xmath138 .",
    "then @xmath139 and @xmath140 are the number of molecules received in times slots @xmath111 and @xmath133 respectively .",
    "if @xmath141 are small , we can approximate @xmath142 and @xmath143 by independent gaussian distributions .",
    "thus , @xmath125 and @xmath130 will be jointly ( colored ) gaussian random variables when we transmit @xmath21 molecules at time zero .",
    "] this analysis is missing in the literature @xcite .",
    "from the five types of noise mentioned in section  [ sec : end - to - end - rev ] , none of them was considered in the model given for the sampler receiver . and",
    "only diffusion noise was considered in the model given for the transparent receiver .",
    "it is possible to modify the model to consider other noises in the model . for instance",
    "consider the case in which the receiver has a small volume @xmath89 and counts the number of molecules that fall into that area .",
    "this incurs a _ particle counting noise _ in addition to the diffusion noise .",
    "poisson concentration transmitter with absorbing receiver is also called the _",
    "poisson model_.    _ transmitter : _ the transmitter chooses a rate @xmath144 at time slot @xmath15 .",
    "the number of released molecules in the beginning of the @xmath15-th time - slot is a poisson random variable , where its average or rate , is @xmath14 . as a result , the density of production rate is the impulse train @xmath145 where @xmath146 is the number of released molecules at time @xmath147 by a transmitter located at the origin .",
    "random variable @xmath148 is a doubly stochastic random variable ( a poisson distribution whose parameter is the random variable @xmath14 ) .    _",
    "medium and receiver : _ each released molecule is absorbed upon hitting the receiver .",
    "let @xmath149 , @xmath150 , denote the probability that a released molecule at the current slot hits the receiver in the next @xmath95-th time slot .",
    "the values of @xmath149 s depend on the communication medium and in general can be derived from fick s diffusion law . for a one - dimensional motion ,",
    "the distribution of the hitting time @xmath81 was found in example [ example : rev1 ] .",
    "then , the hitting probability can be computed as follows : @xmath151 distribution of the first hitting time ( and the values of @xmath149 ) for a non - uniform medium that is arbitrarily filled with barrier or obstacles may be found by numerically solving the fick s equations .",
    "generally , the signal is decoded at the receiver based on the total number of molecules received during the individual time slots . in a time slot ,",
    "three sources contribute to the received molecules : ( i ) molecules due to the transmission in the current time slot , ( ii ) the residue molecules due to the transmission in the earlier time slots known as the interference signal , and ( iii ) noise molecules , modeled within a slot of duration @xmath13 as a poisson random variable with parameter @xmath152 .",
    "based on the thinning property of poisson distribution , the number of received molecules in the time slot @xmath15 , denoted by @xmath153 , is as follows @xcite : @xmath154 where @xmath155 is the sum of interference and noise at time @xmath15 .",
    "the above equation states @xmath156})$ ] , which together with @xmath157}|x_{[0:n]})=\\prod_{i=1}^n p(y_i|x_{[0:i]})\\label{eqn : newadd1}\\end{aligned}\\ ] ] describes the poisson channel completely .",
    "equation is proved using the thinning property of poisson distribution in @xcite .    from the five types of noise mentioned in section  [ sec : end - to - end - rev ] , transmitter noise , diffusion noise and multiple transmitters noise are taken into account .",
    "transmitter noise is reflected in the fact that the number of molecules exiting the transmitter can not be exactly controlled ; diffusion noise is considered because the model is based on microscopic brownian motion , and finally multiple transmitters and background noise is considered by the @xmath158 term .      timing transmitter with absorbing receiver leads to what is known as the _ timing model _ for mc .",
    "_ transmitter : _ the transmitter is assumed to be completely controlling the release time of molecules one by one at its location .",
    "information is coded in the release time of individual molecules @xcite .",
    "_ medium and receiver : _ the released molecules randomly propagate according to the brownian motion .",
    "each molecule may arrive at the receiver after a ( random ) delay , or may never arrive at the receiver .",
    "molecules do not arrive if the brownian motion is transient , or the molecules fade away in the environment .",
    "since we consider an absorbing receiver , each molecule hits the receiver at most once .",
    "despite the uncertainty in the arrival times of the molecules , these arrival times are statistically correlated with their release time , and this correlation can be used for information transmission . in this context , information transmission capacity may be measured by bits per unit of time @xcite , bits per molecule @xcite , or bits per joule @xcite for a given production rate of molecules .",
    "timing channel models generally ignore the existence of noise molecules , _",
    "i.e. , _ molecules of the same type in the environment that are not diffused by the transmitter .",
    "noise molecules are likely to complicate the problem significantly . from the five types of noise mentioned in section",
    "[ sec : end - to - end - rev ] , only diffusion noise is taken into account .    assuming that a molecule is released at time @xmath4 , the arrival time is equal to @xmath159 , where @xmath81 is the transmission delay . because molecules are absorbed upon hitting the receiver , the distribution of @xmath81 is that of a first arrival time . for a one - dimensional motion with variance",
    "@xmath160 , a positive drift @xmath161 and travel distance @xmath75 , @xmath81 will follow an inverse gaussian distribution @xmath86 given in equation .",
    "when there is no drift @xmath162 , @xmath81 follows the lvy distribution given in equation .",
    "these models focus on the physical complexity of the receiver and simplify the channel noise , with the goal of understanding fundamental limits imposed by the receiver alone .",
    "_ transmitter and medium : _ it is assumed that the concentration of molecules around the receiver at time slot @xmath15 is a function of transmission in that time slot , _",
    "@xmath163 for some known function @xmath164 .",
    "_ receiver : _ a receiver with camp receptors that was described in section [ sec : rece : rev ] is assumed .",
    "one of the popular signaling methods in molecular communication uses the molecules concentration to encode the information . in this setup , the transmitter encodes information into the concentration of released molecules .",
    "the released molecules follow a diffusion process through the channel to reach the receiver . as discussed in section  [ sec : model ] , the temporal and spatial concentration of molecules can be derived by the fick s second law of diffusion which results in a distance - time dependent impulse response .",
    "there are several works in the literature on the concentration signaling , many of which claim complete characterizations of channel capacity , leaving the general impression to unfamiliar readers that the capacity of molecular channels is solved . however , once we go inside the papers we see that the capacity calculations are mostly done after simplifications in terms of the channel memory .",
    "simplification and approximation have the advantage of leading to explicit expressions .",
    "but one needs to also address how the derived bounds relate to the actual channel capacity without any simplifications , by specifying whether they are lower or upper bounds to the actual capacity .",
    "having said that , in principle , the capacity of concentration signaling , considering the transmitter - receiver limitations and the intersymbol interference ( isi ) effect of the channel is not an open problem , under some reasonable physical assumptions . as pointed out in @xcite , we may model the diffusion channel ( possibly with drift in a non - uniform medium ) as a state dependent channel . here",
    "the state models the number or density of molecules across the environment ; we can divide the space into very small cells and keep the number of molecules in the cells as the current state of the medium .",
    "part of the state can also model the bound / unbound state receptors on the surface of the receiver .",
    "then , observe that the resulting state - dependent channel is _ indecomposable _ @xcite as the initial state _",
    "diffuses away over time _ under reasonable physical constraints on the medium .",
    "thus , one can characterize the capacity in a computable form @xcite .",
    "however , the state space is very large and capacity characterization is in finite - letter form , making it prohibitively hard to compute and thus of little practical value . as its inputs and halts in and produces a curve within @xmath165 distance of the capacity region .",
    "there is no restriction on the time that takes for the algorithm to halt . ]    in the following , we describe some approaches that exist in the literature .",
    "the goal is to study the capacity of the channel @xmath166 where the noise , _",
    "@xmath123 , is distributed according to @xmath124 .",
    "the input constraint consists of non - negativity of input concentration @xmath144 , and possibly maximum and average concentration constraints : @xmath167 and @xmath168 . to study the capacity of this channel",
    ", one has to specify the joint distribution of @xmath169 conditioned on the entire input sequence as discussed in remark [ remark2d ] .",
    "even with the assumption of conditional independence of @xmath123 ( which is justified when @xmath13 is large ) , as far as we are aware , the capacity of the above channel has not been studied .",
    "if the variance of @xmath123 were some constant @xmath160 and channel inputs were allowed to become negative , the problem would have reduced to the classical gaussian isi channel that has been subject to many studies , starting from the work by hirt and massey in @xcite .",
    "nonetheless , much of the classical ideas clearly carry over from the classical isi channels .",
    "for instance , one can find bounds on capacity using the ideas of using i.i.d .",
    "input distribution @xcite . also , when the number of terms in the linear expansion is finite ( @xmath170 for large enough @xmath95 ) , we can find computable finite - letter expressions for the capacity using the ideas presented later in section [ sec : poissonmodel ] .",
    "the existing literature on the linear model simplify the problem by discarding the channel memory . in this approach ,",
    "the molecular channel is approximated by a memoryless channel ( in many cases , a channel with binary input alphabet ) whose capacity can be readily found by maximizing the input - output mutual information ( _ e.g. , _",
    "see @xcite ) .",
    "thus , while these papers might be valuable in the context of modeling , they are not exciting to information theorists .",
    "these approaches do not genuinely consider a channel with memory , as the interference from past inputs ( isi ) is either ignored , or averaged and put into the transition probabilities of a memoryless channel .",
    "the binary input restriction may be justified by the fact that nano nodes should be simple , and one of the simplest transmission strategies is the on - off keying modulation in which no molecule is transmitted for information bit 0 and @xmath171 concentration is released for information bit 1 . while on - off keying simplifies the transmitter s design , receiver s design can be simplified to a simple threshold decoder by adopting transmission modulation schemes that reduce or mitigate the isi .",
    "thus , channel simplifications and restriction to certain modulation schemes may not be unjustified as it may appear in first glance .",
    "finally , there are also some works based on the _ quorum sensing _ property of bacterial colonies @xcite that also consider a memoryless channel , but with an input - dependent noise . even though we obtained the linear model for an exact concentration transmitter , the same end - to - end model applies to the works based on quorum sensing . as the transmitter or the receiver noise in",
    ", the linear model reduces to the model of these works ( which was obtained by using a gaussian approximation for the binomial distribution ) if the dependency between the transmitter and receiver noises is ignored . ] in these works , the transmitter and receiver employ bacterial colonies .",
    "the collective behavior of the bacteria in response to stimuli is exploited for transmission and reception .",
    "the colony on the transmitter side , in the steady state , senses the concentration of a special molecule type and in response produces and releases another type of molecules .",
    "the released molecules propagate in the medium based on diffusion equations , which has been considered in the steady state .",
    "similar to the transmitter , the receiver senses the concentration based on the quorum sensing property .",
    "all limitations , _",
    "i.e. , _ noises , are modeled with an additive gaussian noise with input - dependent variance ( still a memoryless channel ) , and no isi terms are considered .",
    "in the same scenario of biological nodes consisting of bacteria , the relaying is studied in @xcite , where the relay exploits its quorum sensing property to apply the sense and forward scheme ( which is parallel to the amplify and forward scheme in the classic communication ) .",
    "the goal is to compute the capacity of the lti - poisson channel @xmath172 under average and maximum intensity cost constraints .",
    "more specifically , the following constraints on the input codewords of length @xmath173 are assumed : @xmath144 , average input constraint @xmath168 and a constraint on the maximum value of @xmath14 , @xmath174 .",
    "the summation @xmath175 is the convolution of the sequence @xmath176 with the sequence @xmath177 .",
    "this makes the @xmath153 as the output of a channel consisting of a cascade of an lti system ( with impulse response @xmath178 ) and a memoryless poisson channel , called an _ lti - poisson channel _ in @xcite .",
    "this model can be understood as a generalization of the classical memoryless poisson channel .",
    "therefore , the lti - poisson model relates to two bodies of literature in information theory : networks with memory and memoryless poisson channels . a common point in both literatures",
    "is an attempt to find easy - to - compute expressions for the capacity ( e.g. see @xcite ) .    the capacity for the channel given in equation is claimed to have been solved in ( * ? ? ?",
    "however , in the proof on page 10 of @xcite , after equation ( 50 ) , it is claimed that @xmath153 s are i.i.d .  and",
    "@xmath179 is expanded as @xmath180 . but",
    "@xmath153 s are correlated in general because they depend on the input sequence @xmath181 .",
    "the capacity for this channel has been characterized in @xcite under the assumption that molecules injected into the environment will disappear after @xmath95 time - slots , for some large enough @xmath95 .",
    "thus , @xmath182 for @xmath183 .",
    "this allows one to write that @xmath184 in particular , @xmath156})=p(y_i|x_{[i - k : i]})$ ] , and from equation @xmath185 the factorization given in equation allows for a multi - letter , albeit computable characterization of the capacity region .",
    "factorization of the type given by was first exploited by verdu for mac channels @xcite .",
    "verdu s motivation for defining this class of networks was to study linear isi channels .",
    "the intuitive reason that factorization of is useful is that one can set or reset the channel state using any @xmath95 consecutive inputs ( as the channel remembers only the last @xmath95 inputs)@xcite .    in @xcite , the capacity of the original channel ( with memory )",
    "is sandwiched between the capacities of two memoryless channels , _",
    "i.e. , _ two memoryless channels are given whose capacities bound the desired capacity from below and above .",
    "the upper and lower bounds can be made arbitrarily close to each other , resulting in a computable characterization of the capacity region .",
    "for the lower bound , a natural number @xmath186 is chosen . then time is partitioned into blocks of size @xmath187 , _",
    "i.e. _ one block for time instances 1 to @xmath187 , one block for time instances @xmath188 to @xmath189 , etc .",
    "then , the channel is depreciated by deleting output @xmath190 s for the first @xmath95 time instances of each block .",
    "in other words , the new channel after deletion has inputs @xmath191 and outputs @xmath192 and then @xmath193 , etc . because the outputs in each block depend only on inputs in the same block , the resulting channel is _ block memoryless _ and its capacity lies below the capacity of original channel .    for the upper bound ,",
    "a natural number @xmath186 is chosen .",
    "then time is partitioned into blocks of size @xmath186 ; in other words , first block covers time instances 1 to @xmath186 , second block covers time instances @xmath194 to @xmath195 , etc .",
    "the channel is enhanced by allowing the transmitter to arbitrarily  reset \" the memory of the channel ( @xmath95 last inputs ) at the _ beginning _ of each block ( without any regard to its actual last @xmath95 inputs ) .",
    "the new channel has a higher capacity than the original channel , since the memory content specified by the transmitter at the beginning of each block can simply be the actual state that the system would have been in , if transmitter did not have the option of changing the memory content of the channel .",
    "furthermore , the new channel is _ block memoryless _ and its capacity lies above the capacity of original channel .",
    "* the symmetrized kullback - leibler divergence upper bound : * capacity of a memoryless channel can be characterized as the maximum over input distributions of the mutual information between channel input and output of the channel .",
    "this characterization is not always sufficiently explicit .",
    "another contribution of @xcite is to propose an easy to compute and explicit upper bound on mutual information .",
    "the symmetrized kullback - leibler divergence ( kl divergence ) is defined as @xmath196 .",
    "then , @xmath197 one can prove directly by first simplifying the expression of @xmath198 and then applying the jensen s inequality @xcite , but the above chain of inequalities illustrate that the gap @xmath199 is @xmath200 , the _ lautum information _ (  mutual \" written in the reverse order ) that is an object of interest on its own terms @xcite .    given a channel @xmath201 , one",
    "can then define the following upper bound on capacity @xcite : @xmath202 it is shown in @xcite that @xmath203 can be explicitly computed .",
    "for instance , for a point to point poisson channel @xmath201 , where @xmath204 , it has the following compact formula : @xmath205 where @xmath206-\\mathbb{e}[x]\\mathbb{e}[y]$ ] .",
    "furthermore , it yields previously unknown bounds for channels with small capacity ( which can occur in mc systems ) .",
    "for instance , for a poisson channel with average intensity constraint @xmath207 and maximum intensity constraint @xmath208 , this bound is calculated as : @xmath209=\\mathcal{e}_{\\textnormal{s}},~~ 0 \\leq x \\leq \\mathsf{a}}}\\mathcal{u}(p(x , y))=\\\\ & \\quad \\begin{cases}\\frac{\\mathcal{e}_{\\textnormal{s}}}{\\mathsf{a}}(\\mathsf{a}-\\mathcal{e}_{\\textnormal{s}})\\log\\left(\\frac{\\mathsf{a}}{\\lambda_0}+1\\right ) , & \\mathcal{e}_{\\textnormal{s } } < \\mathsf{a}/2 \\\\ \\frac{\\mathsf{a}}{4}\\log\\left(\\frac{\\mathsf{a}}{\\lambda_0}+1\\right ) , & \\mathcal{e}_{\\textnormal{s}}\\geq \\mathsf{a}/2 .",
    "\\end{cases}\\end{aligned}\\ ] ] for previous works on poisson channel and other techniques for bounding mutual information , see @xcite .",
    "authors in @xcite consider a combination of an exact concentration transmitter and an absorber receiver .",
    "the exact concentration transmitter can send @xmath210 molecules at the beginning of each time slot .",
    "the receiver counts the number of absorbed molecules in each time slot .",
    "consider the hitting probabilities @xmath211 of the absorbing receiver in equation .",
    "then , each of the @xmath212 molecules released in the first time slot arrive in the @xmath95-th time slot with probability @xmath149 .",
    "thus , the total number of molecules that are released in time slot @xmath7 and arrive in the @xmath95-th time slot follows a binomial distribution with parameters @xmath213 .",
    "since we have a transmission at the beginning of each time slot , the total number of molecules received at the time slot @xmath95 is the sum of independent binomial random variables corresponding to transmissions from time slots @xmath95 , @xmath214 , @xmath215 , etc .",
    "the sum of independent binomial variables does not have a nice analytical form .",
    "the more serious difficulty is the correlation that arises between outputs at different time - slots .. ] there are only some approximation techniques for handling dependencies that arise in such balls and bins problems ; see for instance ( * ? ? ?",
    "* section 5.4 ) .",
    "authors in @xcite simplify the problem by assuming that @xmath216 for @xmath217 .",
    "furthermore , they handle the correlation by assuming an i.i.d .",
    "input distribution when evaluating the @xmath173-letter mutual information form of the channel capacity .",
    "we will review the idea of evaluating the @xmath173-letter mutual information by assuming an i.i.d .",
    "distribution in relation to a different problem in detail in section [ sec : rel_time ] .    a different model for the diffusion medium is considered in @xcite .",
    "the transmitter is still an exact concentration transmitter , but instead of using the linear model and fick s law to evaluate the concentration at the receiver , the authors assume that the concentration at the receiver can be at either of the two  low \" or  high \" concentration states . in other words ,",
    "the communication medium is modeled with a two - state markov chain , with low and high states , which indicate the  overall \" intensity of residual molecules in the environment due to the past transmissions ( high isi or low isi ) . by using the on - off keying scheme and assuming memory of depth one , an achievable rate is derived in @xcite .",
    "the capacity of molecular timing channels has been the subject of several studies .",
    "these works appeal to information theorists because they exploit serious information theoretic tools and are mathematically rigorous .",
    "while it is not possible to reproduce the entire literature here , we selectively provide a rough sketch of some of the tools and the ideas used .",
    "* signaling with identical tokens : * in an early work @xcite , the author assumes that @xmath173 molecules are released at times instances @xmath218 , and arriving at the receiver at times @xmath219 , where @xmath220 is the travel time of the @xmath15-th molecule .",
    "travel time @xmath221 are assumed to be independent and identically distributed according to some smooth continuous density function ( the inverse gaussian or lvy distribution for free diffusion in a one - dimensional medium ) .",
    "while the transmitter and receiver are perfectly synchronized , the order according to which the particles are received is not necessarily the same as the order they are released .",
    "the molecules are of the same type and indistinguishable at the receiver , which is the main source of difficulty in the problem .",
    "therefore , the receiver has only the sorted values @xmath222 , not the exact vector @xmath223 .",
    "this is a main difference of this model with ",
    "bits through queues \" of @xcite .",
    "here we are interested in the mutual information @xmath224 this mutual information is harder to analyze than @xmath225 as in @xcite .",
    "the reason is that @xcite @xmath226 where @xmath227 is the differential entropy . here",
    "only the first term @xmath228 depends on input pmf @xmath229 . on the other hand , @xmath230 but @xmath231 depends on @xmath229",
    ". however , we have that @xcite is the quantized version of @xmath232 ( a discrete random variable ) , we get that @xmath233 . letting @xmath234",
    "converge to zero , the difference @xmath235 converges to @xmath236 , and @xmath237 converges to @xmath238 . ]",
    "@xmath239 thus , @xmath240 .",
    "hence , @xmath241 since the third term on the right hand side @xmath242 does not depend on @xmath229 , one needs to consider the maximum of sum of the first two terms as a function of @xmath229 .",
    "authors in @xcite proceed by finding upper bounds on these two terms and maximize those bounds over input pmfs @xmath229 .",
    "it is also worth to mention another idea of this paper : observe that @xmath243 does not depend on the order of @xmath244 .",
    "therefore if @xmath245 is a permutation from @xmath246 to itself , then @xmath247 thus , if instead of transmitting the input sequence in the order of @xmath248 , we transmit them in the order of @xmath249 , the mutual information between @xmath250 and @xmath243 would not change .",
    "in other words , if @xmath229 is a capacity achieving distribution and we define @xmath251 , then @xmath252 would also be a capacity achieving distribution . observing that mutual information is concave in the input distribution",
    ", @xmath253 would also be capacity achieving .",
    "if we consider all the permutations @xmath245 , and take their average pmf , we get that it suffices to take maximum over input distributions that are symmetric with respect to permutation on the input indices ( called  hypersymmetric \" in @xcite ) .",
    "we continue this part by reviewing some of the ideas of @xcite : author in @xcite uses the following idea for numerically computing lower bounds on the mutual information @xmath254 .",
    "suppose we have an intractable channel @xmath201 and an input distribution @xmath255 .",
    "the idea is to find a tractable approximation @xmath256 of the channel @xmath257 .",
    "for any arbitrary channel @xmath258 we have that @xmath259 where @xmath256 is calculated from @xmath260 . the above inequality can be directly verified .",
    "note that similar upper bounds on mutual information can be found via topsoe s inequality @xcite : for any arbitrary output pmf @xmath261 we have @xmath262    * memoryless models : * as we saw , molecules arriving out of order are a challenge .",
    "this might be avoided if we release molecules of different types so that they can be distinguished at the receiver @xcite . alternatively",
    "if we assume a lifetime for molecules ( after which they fade away in the environment ) , we might restrict ourselves to a certain class of encoders that after releasing a molecule , delays the next transmission long enough to ensure that the previous transmission has either hit the receiver or died out in the environment @xcite . even though this restriction may not optimal , but by studying the maximum achievable rate for this class of encoders , we can find lower bounds on the capacity of the molecular timing channel .",
    "having resolved the out of order problem , the capacity of the molecular timing channel reduces to the capacity of an additive channel @xmath159 .",
    "distribution of the transmission delay @xmath81 depends on the physical properties of the communication medium . for a one - dimensional motion with variance @xmath160 and a positive drift velocity @xmath85 towards the receiver located at distance @xmath75 from the transmitter",
    ", @xmath81 will follow an inverse gaussian distribution @xmath86 given in equation .",
    "the additive channel @xmath159 is called an aign ( additive inverse gaussian noise ) channel .",
    "if there is no drift towards the receiver @xmath162 , the channel becomes an aln ( additive lvy noise ) channel @xcite .",
    "the goal is to compute the following expression : @xmath263\\leq \\lambda } i(x;x+t),\\ ] ] for some @xmath264 . even though capacity is concave in the input density and convex optimization techniques",
    "may be employed , the space of distributions over which the maximization occurs is difficult to handle analytically .",
    "there are several works that find explicit lower , upper or asymptotic expressions for the capacity of aign under an average input cost constraints @xcite , with some of the techniques are borrowed ( but carefully adapted ) from earlier works on the poisson channel . a simplifying fact is the additivity property of the ig distribution @xcite : let @xmath265 and @xmath266 be independent random variables .",
    "we further assume that @xmath267 for some @xmath268",
    ". then , @xmath269 .    in the following we mention some of the proof ideas .",
    "observe that @xmath270 .",
    "therefore , the problem is to maximize @xmath271 subject to @xmath272\\leq \\lambda$ ] for some @xmath273 .    *",
    "( lower bounds : ) the lower bound in @xcite is derived by evaluating @xmath271 when @xmath4 is distributed according to an ig distribution ( capacity is maximum over all distributions , so this yields an inner bound ) .",
    "the above additivity property of ig distribution is used to specify the distribution of @xmath274 . to derive a lower bound in @xcite",
    ", author chooses the input distribution of @xmath4 to an exponential distribution .",
    "the distribution of @xmath274 is the convolution of an exponential and an ig distribution .",
    "the author avoids this calculation .",
    "instead @xmath271 is bounded from below using the entropy power inequality in terms of @xmath275 and @xmath276 . in @xcite , the exact formula of the convolution of an exponential and an ig distribution",
    "is cited from @xcite and a new analytical lower bound is derived . *",
    "( upper bounds : ) the upper bound in @xcite is derived by noting that @xmath277=\\mathbb{e}[x]+\\mathbb{e}[t]\\leq \\lambda+\\mu$ ] .",
    "thus , the entropy of @xmath274 is bounded by the entropy of the exponential distribution with mean @xmath278 , as exponential distribution has maximal differential entropy amongst all non - negative random variables with the same mean .",
    "the idea of @xcite is to use topsoe s inequality in to bound mutual information from above , with the choice of inverse gaussian distribution for output pmf .",
    "in @xcite , authors consider a diffusion medium with no drift . a lifetime for molecules is considered ( after which they die out in the environment ) to make the channel memoryless , resulting in a variation of the aln channel : in case the molecule hits the receiver before its lifetime ends , we get @xmath159 , with @xmath81 following a truncated lvy distribution . by writing the expansion @xmath270 ,",
    "the particular form of the lvy distribution is used to find a closed form expression of the entropy of its truncated version @xmath276 .",
    "the term @xmath271 is bounded from below via the entropy power inequality ( epi ) , and from above by logarithm of the support of @xmath274 .    * the discrete delay - selector model : * let us consider the following discrete model of the timing channel .",
    "we divide the time horizon into time slots of duration @xmath13 . at the beginning of each time slot , up to @xmath279 indistinguishable molecules may be released .",
    "molecules are not lost during transmission , and each of these molecules will eventually arrive at the receiver in the current time - slot or in the subsequent time slots .",
    "furthermore , a channel delay of at most @xmath280 is assumed : a transmission in time slot @xmath281 arrives in any of the following @xmath234 time slots , _",
    "i.e. , _ in one of the time slots @xmath281 , @xmath282 , ... , @xmath283",
    ". the receiver can count the number of molecules received in each time slot , but does not otherwise know the exact arrival times of individual molecules within a time slot .",
    "overall , the input can be characterized a sequence @xmath2 where @xmath284 $ ] denotes the number of molecules released in time slot @xmath15 .",
    "the output is a sequence @xmath285 where @xmath286 indicates the number of molecules received in time slot @xmath15 . since @xmath153 depends not only on @xmath14 , but also on @xmath287 , this is a channel with memory .",
    "the above model was originally introduced in @xcite and called the _ delay - selector _ model .",
    "authors in @xcite studied the normal shannon capacity for the case of @xmath288 . the asymptotic behavior of capacity in terms of the number of molecules and time intervals for communication",
    "is studied in @xcite .",
    "its zero - error capacity was completely characterized in @xcite as @xmath289 where @xmath186 is the unique positive real root of the polynomial @xmath290 .",
    "the authors of @xcite were not apparently aware of @xcite , as @xcite is not cited and their zero - error capacity result is not compared with the vanishing error result of @xcite .",
    "one of the main ideas used in @xcite can be summarized as follows : consider a channel with memory . to compute the capacity , one would need to consider @xmath173-letter mutual information terms : @xcite @xmath291 but @xmath292 can not be expressed as @xmath293 . to derive a lower bound ,",
    "let us take an i.i.d .",
    "input pmf @xmath294 .",
    "then , one gets a single - letter expansion as follows : @xmath295    authors in @xcite find an exact zero - error result for the delay - selector channel .",
    "they also provide explicit capacity achieving codes and a linear - time decoding algorithm for their codes . to define a zero - error codebook ,",
    "we need a few definitions : we write that @xmath296 if there is a way to obtain @xmath285 from @xmath2 on the delay - selector channel with appropriate choice of delays for individual molecules .",
    "a zero - error code consists of a class of input sequences such that for any two codewords @xmath2 and @xmath297 , one can not find @xmath285 such that @xmath296 and @xmath298 at the same time .",
    "the paper follows by finding a recursive equation for the size of the optimal codebook of size @xmath173 .",
    "a key observation in @xcite is the following : if there are two codewords @xmath299 and @xmath300 such that @xmath301 for @xmath302 , and @xmath303 , then @xmath304 and @xmath305 may not both belong to a zero - error code at the same time .",
    "if this is the case and @xmath306 , then one can obtain the output sequence @xmath307 from both @xmath304 and @xmath305 .",
    "in this section , we review some results relating to the ligand - receptor models described in section  [ sec : ligand - model - part ]    * memoryless binomial channel model : * the ligand receptors are studied in @xcite , where a memoryless binomial distribution is proposed to model the number of bound receptors as the output while their binding probability is taken to be the input .",
    "thus , the input to the channel is @xmath308 $ ] and the output is a sample from @xmath309 for some given @xmath95 receptors on the surface of the receiver .",
    "the distribution which maximizes the mutual information among this input - output is jeffery s prior @xcite .",
    "assuming an environmental noise , authors in @xcite consider two bacterial point - to - point communication scenarios from the capacity viewpoint : ( i ) multi - type molecular communication with a single concentration level , and ( ii ) single - type molecular communication with multiple concentration levels .",
    "for both cases , upper and lower bounds are found on the capacity .",
    "for the upper bound , the symmetrized kullback - leibler divergence based upper bound of is employed .",
    "the lower bound is derived on the capacity under average and peak constraints by assuming a binary input .",
    "the approach of obtaining the lower bound is to covert the ligand - receptor model to a variation of z - channel with the binary input and the outputs in @xmath310 , where @xmath311 is the total number of the receptors .",
    "* markov model : * in the markov model with @xmath95 receptors on the surface of the receiver , the state of receiver is modeled by a vector in @xmath96 .",
    "furthermore , the state at time instance @xmath15 is also the output of the receiver , @xmath97 .",
    "as pointed out in @xcite such state dependent channels belong to the class of channels studied ( with and without feedback ) in @xcite .",
    "even though we have a channel with memory , the main result is that the capacity is achieved by i.i.d .",
    "input pmf @xmath312 @xcite by directly investigating the analytical expression for mutual information . for the case of one receptor ,",
    "output feedback is shown not to increase the capacity . here",
    ", the important assumption is that when a receptor is in state @xmath10 , its transition to state @xmath313 is independent of input .",
    "the intuition for this result is summarized in @xcite as follows :  when we have a coding scheme which uses feedback , the encoding function depends on the output of the channel in the previous epochs .",
    "since the channel has markov structure , if we go back more that one epoch , we do not get useful information .",
    "hence , one can modify the encoding function so that it would always assume that the previous output was @xmath313 ( i.e. , the receptor was at the unbound state ) .",
    "if the assumption was correct , it is similar to the feedback strategy .",
    "otherwise , the state of the channel is @xmath10 , and the next output is independent of the input .",
    "thus , in both cases , the feedback strategy and the modified strategy have the same result .",
    "therefore , every rate which is achievable via feedback can be achieved without feedback . \"",
    "this argument only shows that feedback does not help when there is one receptor on the surface of the receiver .",
    "authors in @xcite consider the case of multiple ligand receptors .",
    "the resulting state dependent channels again would belong to the class of channels studied in @xcite , and its feedback capacity can be computed via the formula given in @xcite .",
    "however , explicit calculation of the capacity still requires solving an optimization problem .",
    "authors in @xcite work out this optimization problem and show that if one can vary the input concentration of molecules around the receiver arbitrarily fast , the capacity for @xmath314 ligand receptors can be found by simply multiplying @xmath314 times the capacity of a single receptor .",
    "surprisingly , feedback does not help in this case either ( _ i.e. , _ revealing the current number of bound receptors to the transmitter can not increase the communication rate ) .",
    "our focus up to this point has been on a point to point setting .",
    "but many of the envisioned applications of mc employ a network of molecular nodes .",
    "molecular networks have received little attention in the literature .",
    "the problem is complicated by the fact that one needs to study the effect of _ memory _ in the context of _ networks _ ; any realistic model of molecular medium or transceivers should consider the effect of memory of past actions in their formulation .    among different network structures ,",
    "we focus on the cascade structure here in this section .",
    "we provide an open problem that was motivated by our study of molecular communication . as common with interdisciplinary topics , studying molecular communication",
    "may lead one to formulate new information theoretic problems .",
    "the channel cascade problem arises naturally when communicating over a medium consisting of identical objects placed one after another .",
    "for instance , this chain could consist of biological cells as in the bacteria cable of @xcite , where the output of each cell is directly connected to the input of the next cell .",
    "there is no intelligent processor after each cells to decode and then encode the message for the next cell .",
    "the diagram for the bacteria cable is depicted in fig .",
    "[ bacteriacablefig ] .",
    "each bacterium is modeled by a number of electron queues that describe its electron transport chain ( a process completed by a cell to produce energy ) .",
    "the size of these queues statistically affects transitions of electrons from its input terminal ( electron donor ) to its output terminal ( electron acceptor ) . here a vector of size four , consisting of the length of the queues associated to each cell , represents the state variable associated to each cell . by placing the cells one after another",
    ", we obtain the cascade architecture . in this section",
    ", we provide a conjecture about cascade of channels with memory .",
    "this conjecture implies that the capacity of the cascade link goes to zero as the length of the cable goes to infinity .",
    "bacteria , with the output of each directly connected as the input of the next bacterium .",
    "each bacterium has a state space determined by variables @xmath315.,scaledwidth=100.0% ]     general channels with memory , scaledwidth=95.0% ]    another motivation for the cascade problem is due to the short range of molecular communication and the need for multi - hop communication to send messages across longer distances .",
    "consider a state - dependent channel @xmath316 with identical input and output alphabets , _",
    "i.e. , _ @xmath317 .",
    "consider @xmath314 identical copies of this channel and let us denote the input , output and state of the @xmath281-th channel at time @xmath15 by @xmath318 , @xmath319 and @xmath320 ( see fig .  [ cascadeofchannelmemory ] ) .",
    "we say that these channels are connected in cascade if @xmath321 , _ i.e. , _ the output of the @xmath322-th channel is the input to the @xmath281-th channel ( no intelligent processing unit is placed between the output of one hop to the input of the next hop ) .",
    "the input of the cascade channel is @xmath323 and its output is @xmath324 .",
    "we allow for block codes .",
    "a communication rate is said to be achievable if the average error probably converges to zero as the blocklength goes to infinity , .",
    "the question is what is the behavior of the capacity of cascade of @xmath314 replicas of this channel as a function of @xmath314 ?    to best of our knowledge , cascade of channels with memory has not received much attention in the literature .",
    "the only result that we are aware of is that of @xcite wherein authors consider cascade of a certain nonlinear channel with memory that appears in the context of optical fibers , but the analysis is specialized to the particular optical channel that is governed by a certain stochastic differential equation .",
    "capacity of a finite - state discrete channel with input @xmath4 , output @xmath5 and state variable @xmath325 is given by @xcite @xmath326 since cascade of a channel with memory is itself a channel with memory , in principle it is possible to write a formula for channel capacity by considering ( multi - letter ) mutual information between the input of the first channel and the output of the @xmath314-th channel in cascade .",
    "the challenge is to study the limit as blocklength @xmath173 tends to infinity . in the expression of equation",
    ", the result of @xcite can be applied . when considering single - letter mutual information between the input of the first channel and output of the last channel , each of the @xmath314 finite - state channels has some initial state and thereby a channel transition matrix .",
    "thus , the end - to - end mutual information can be found using the result of @xcite for memoryless channel corresponding to these transition matrices . ]",
    "to state our main conjecture about the cascade problem , we need a definition :    we define the concept of zero - error capacity @xmath327 for a channel with memory of , as the maximum rate of information that can be communicated with _ exactly _ zero error , regardless of the initial state , @xmath328 , of the channel . as in @xcite . ]",
    "the zero - error capacity is defined when we allow for multiple - use of the channel with memory ( blockcoding is allowed ) , but only codes with exactly zero error ( and not a vanishing error probability as blocklength tends to infinity ) are allowed .",
    "given a channel with memory , observe that its @xmath314 cascade channel is itself a channel with memory ( with its state being the state vector of the @xmath314 channels ) , and hence its zero - error capacity can be defined in the same way .",
    "let @xmath329 denote the zero - error capacity of @xmath314 cascade channels .",
    "also , let @xmath330 .",
    "we can now formally state our conjecture :    take an arbitrary state dependent channel @xmath331 with finite input / output alphabet @xmath332 .",
    "then , the shannon capacity of the @xmath314 cascade channel converges to @xmath333 as @xmath314 goes to infinity if @xmath334 , _ i.e. , _ if it is a finite state channel . on the other hand , one can find channels with finite input / output alphabet but with infinite memory , @xmath335 , such that the shannon capacity of the cascade channel converges to a value that is strictly larger than @xmath333 as @xmath314 goes to infinity .    a partial proof of the above conjecture is given in appendix [ secprofconj ] .",
    "memoryless channels are special cases of channels with memory , and their study is the first step towards solving the general problem with memory . consider a _ memoryless _ channel @xmath336 with no state variable .",
    "we have the following markov chain : @xmath337 where @xmath338 is given .",
    "if we denote the transition matrix for channel @xmath336 by @xmath339 , the transition matrix for the @xmath314 cascade channel will be equal to @xmath340 .",
    "then , for a memoryless channel we have @xmath341 .",
    "it is insightful to construct a markov chain as follows : let the state space be @xmath342 and the transition probability from state @xmath21 to state @xmath343 be equal to @xmath344 .",
    "then , random variables @xmath345 can be understood as a random walk sequence on this markov chain with the initial state of @xmath346 .",
    "* memoryless channels with finite input / output alphabets : * as an example , cascade of @xmath314 binary symmetric channels ( bscs ) with parameter @xmath11 is a bsc channel with parameter @xmath347 , and capacity @xmath348 where @xmath227 is the binary entropy function . by writing the taylor expansion of entropy function around @xmath349 ,",
    "it is easy to verify that the capacity drops exponentially fast in @xmath314 .",
    "there are few previous works on the behavior of memoryless cascade channels in the literature , most of which consider cascade of simple channels ( _ e.g. _ see @xcite , @xcite , @xcite , @xcite , @xcite , @xcite ) . as a historical note , just like shannon who was motivated by the repeatered telephone lines common in his time , the motivation of simon for studying the cascade channel was the repeatered telephone line @xcite .",
    "it turns out that just like the bsc example , for any memoryless channel with finite alphabet and positive transition matrix , _",
    "@xmath350 for all @xmath351 , the shannon capacity of the cascade channel drops exponentially to zero .",
    "in fact , to compute the capacity , we seek the mutual information between the initial state @xmath346 and the final state @xmath352 .",
    "if the markov chain has a finite state space , and it is irreducible and aperiodic ( implied by @xmath350 for all @xmath351 ) , it will have a unique stationary distribution to which the chain converges ( exponentially fast ) , starting from any initial state .",
    "convergence of the markov chain to a stationary distribution implies that the correlation between initial state @xmath346 and the final state @xmath352 after @xmath314 walks fades away exponentially fast .",
    "this would imply that the capacity drops to zero exponentially fast . to see why the drop occurs exponentially fast in another way , note that by the data processing inequality , we have @xmath353",
    "however , the above data processing inequality can be strengthened by finding a constant @xmath354 such that for any @xmath355 we have @xmath356 , instead of the weaker @xmath357 @xcite .",
    "we can then write that @xmath358 showing that @xmath359 drops to zero exponentially fast in @xmath314 .",
    "let us consider a general discrete memoryless channel @xmath201 .",
    "let us first consider the zero - error capacity of the cascade channel , _",
    "i.e. , _ the rate at which it is possible to send information with _",
    "exactly _ zero error .",
    "first , we provide some definitions from finite - state markov chain theory .",
    "state @xmath281 is said to be accessible from state @xmath15 ( shown by @xmath360 ) , if it is possible to reach state @xmath281 from state @xmath15 in some number of steps , _",
    "i.e. , _ if there exists some @xmath361 such that @xmath362 , where @xmath363 $ ] is the probability transition matrix .",
    "two distinct states @xmath15 and @xmath281 are said to communicate ( shown by @xmath364 ) , if state @xmath281 is accessible from state @xmath15 and state @xmath15 is accessible from state @xmath281 .",
    "a state is always considered to communicate with itself .",
    "we can partition the states of a markov chain into disjoint communicating classes , where two states @xmath15 and @xmath281 are in the same class if and only if @xmath15 and @xmath281 communicate ( @xmath364 ) .",
    "a communicating class is closed if starting from a state in that class , we will remain in the class forever ( i.e. , states outside the class are not accessible from the states that belong to this class ) .",
    "a state is called _ recurrent _ if starting from the state , the probability of returning to it is one .",
    "otherwise , it is called _",
    "transient_. the states of a closed communicating class are all recurrent , and the states of a non - closed communicating class are all transient .    with the markov chain interpretation of the channel in mind , the zero - error capacity of the cascade of @xmath314-channels will be positive if the chain has more than one closed communicating class .",
    "the reason is that if initial state belongs to one of the closed communicating classes , it will remain in that class forever .",
    "therefore , it is possible to use the identity of the communicating class for signaling .",
    "furthermore , observe that zero - error communication at a positive rate is possible even when the chain is irreducible and has only one closed communicating class , if the states are periodic with period @xmath81 . in this case",
    ", we can partition the graph into @xmath81 components and index them by @xmath365 . then , starting from an initial state in component @xmath281 , after passing through @xmath314 cascade channels , we will end up in state @xmath366 .",
    "in fact , one can show the following :    [ proposition1 ] let @xmath367 and @xmath368 denote the zero - error and shannon capacities of the cascade of @xmath314 repetitions of a finite alphabet memoryless channel with transition matrix @xmath369 . then , @xmath370 where @xmath186 is the number of closed communicating classes of the markov chain corresponding to @xmath369 , and @xmath221 is the period of nodes in the @xmath15-th class ( thus , input alphabet @xmath371 can be partitioned into @xmath186 closed communicating classes , and set of transient nodes ) .    the proof is given in appendix [ appndixa ] .",
    "* memoryless channels with infinite input / output alphabets : * for memoryless channels with countably infinite or continuous alphabets , the behavior of the capacity of cascade channels can be very different than the finite discrete channels . to see why the behavior may be different , note that if we cascade @xmath314 memoryless gaussian channels with noise @xmath160 , the overall channel will be a gaussian channel with noise variance @xmath372 . with an input power constraint @xmath373",
    ", the capacity of the cascade channel will be @xmath374 which is equal to @xmath375 for large values of @xmath314 .",
    "thus , the capacity is proportional to @xmath376 , and not exponentially decreasing in @xmath314 .",
    "the difference between the infinite alphabet and finite alphabet cases is that while it is still possible to construct a markov chain on the state space @xmath342 , the chains on infinite alphabet spaces can be more involved and may not even have a stationary distribution .    as far as we are aware ,",
    "the possible behaviors of the capacity of cascade of identical memoryless channels with countably infinite or continuous alphabets have not received any attention .",
    "more specifically , one may ask that besides exponential and @xmath376 drop in capacity , what other behaviors are possible ?",
    "an example of a memoryless channel with countably infinite input / output alphabet is provided below to show that unlike the finite alphabet case , one can have @xmath377    \\(1 ) 0 ; ( 2 ) [ right of=1 ] 1 ; ( 3 ) [ right of=2 ] 2 ; ( 4 ) [ right of=3 ] 3 ; ( 1 ) edge [ loop above ] node 1 ( 1 ) ( 2 ) edge [ bend left ] node [ above ] @xmath378 ( 1 ) edge node [ above ] @xmath379(3 ) ( 3 ) edge [ bend left ] node [ above ] @xmath380 ( 1 ) edge node[above]@xmath381(4 ) ( 4 ) edge [ bend left ] node[below ] @xmath382(1 ) ; ( 12.5,0 ) circle [ radius=0.025 ] ; ( 12,0 ) circle [ radius=0.025 ] ; ( 12.25,0 ) circle [ radius=0.025 ] ; ( 10.3,0 ) to ( 11.5,0 ) ;    [ exmple1 ] let @xmath383 be the input / output alphabets of a memoryless channel with the following transition probabilities : @xmath384 and @xmath385 .",
    "this is depicted in fig .",
    "[ figmarkov ] .",
    "in other words , being at state @xmath15 , with probability @xmath386 we go to state @xmath387 and with probability @xmath388 we go to state @xmath7 .",
    "assume that @xmath389 , _",
    "i.e. , _ we always stay in state @xmath7 if we end up there .",
    "the probabilities @xmath386 are chosen such that @xmath390 for @xmath391 is a decreasing positive sequence that converges to @xmath349 as @xmath314 tends to infinity .",
    "observe that zero - error capacity @xmath392 for this channel because given any input , output symbol @xmath7 occurs with some positive probability .",
    "therefore , the zero - error capacity of the cascade channel is also zero .",
    "let us assume the uniform input distribution on @xmath393 ( input power is @xmath349 ) .",
    "then , if we use input @xmath394 on the cascade of @xmath314 identical channels as above , the output will be @xmath395 because input @xmath7 is always mapped to output @xmath7 . for input @xmath396 , with probability @xmath397",
    ", the output at the cascade of @xmath314 channels will be equal to @xmath314 ; with probability @xmath398 , it will be equal to @xmath7 .",
    "therefore , the cascade of @xmath314 channels is essentially a @xmath6-channel with input alphabet @xmath393 and output alphabet @xmath399 .",
    "the input / output mutual information as @xmath314 tends to infinity , converges to the input / output mutual information of a @xmath6-channel with parameter @xmath349 , which is non - zero .",
    "one implication of the above example is as follows : given an integer @xmath400 , let us consider the  @xmath400-truncated version \" of the above channel as follows : the input / output state space are @xmath401 , and @xmath384 and @xmath385 for @xmath402 . for @xmath403 , @xmath404 and @xmath405 for @xmath406",
    "is defined arbitrarily .",
    "the above example shows that the capacity of the  @xmath400-truncated version \" of the above channel converges to zero as @xmath314 tends to infinity _ for any arbitrarily large @xmath400 _ , but the capacity of the cascade of the channel itself is positive as @xmath314 tends to infinity , even in the presence of an input power constraint .    despite the above negative result ,",
    "cascade capacities of many continuous alphabet memoryless channels ( with @xmath392 ) converge to @xmath7 as the length of the cascade channel goes to infinity .",
    "this can happen if the strong data processing constant ( @xmath407 ) is less than one .",
    "even when @xmath408 , the idea of  non - linear \" data processing constant of polyanskiy and wu @xcite may be still used to show that mutual information drops to zero . the idea is to show an appropriate ( possibly non - linear ) increasing function @xmath164 satisfying @xmath409 , such that for any @xmath355 we have @xmath410 .",
    "this would then imply that @xmath411 therefore , one needs to look at the convergence of the sequence of @xmath412 for @xmath413 .",
    "* variation of the problem with relay nodes : * a natural variation of the cascade problem with relay processing nodes placed in between any two consecutive memoryless channels is studied in @xcite .",
    "if there is no restriction on the relays , they can decode and re - encode the information . in this case",
    ", the shannon capacity of the cascade channel will be equal to the min - cut capacity of the links .",
    "furthermore , the zero - error capacity of the cascade channel will be equal to @xmath414 , the zero - error capacity of each individual channel .",
    "therefore , there are potential improvements both in terms of the shannon capacity and the zero - error capacity .    to approach the min - cut capacity , one needs to use large blocklengths .",
    "an interesting result for the cascade problem with relays is provided in @xcite .",
    "it is shown in @xcite that if the relays are forced to process blocklength of fixed size , then for any discrete memoryless channel , the cascade capacity converges to the zero - error capacity @xmath414 exponentially fast as the length of the cascade channel @xmath314 goes to infinity . in other words ,",
    "relays of limited complexity are not helpful .",
    "another interesting result for additive gaussian channel is given in @xcite .",
    "it considers the simple strategy of each relay comparing the input signal with a threshold and choosing the input to the next channel accordingly . by a judicious choice of the thresholds",
    ", it is shown that the end to end mutual information drops like @xmath415 ( rather than @xmath376 ) , but the thresholds used depend on the location of the relay in the cascade network .",
    "the channel memory allows the channel statistic @xmath416 to adapt itself according to the channel state @xmath417 ( itself influenced by previous inputs to the channel ) .",
    "according to our conjecture , this freedom is limited and essentially useless for finite state channels .",
    "observe that even in a finite state channel ( @xmath418 ) , the output @xmath153 may still depend on all previous inputs @xmath419 .",
    "this is because @xmath153 depends on @xmath14 and @xmath420 , but @xmath420 may be affected by the _",
    "entire _ past inputs . since the input @xmath14 is not affected by only a finite number of past inputs",
    ", one can not try to model the memory effect with the actions of the relays in the model studied in @xcite , wherein relays are forced to process blocklength of fixed size .",
    "efficient communication among small devices is an area where communication and information theorists can contribute . in many applications , communication among nano - devices",
    "is not a goal in itself , but occurs with the goal of serving a task . in other words , there is not always a given explicit messages of a certain rate that needs to be communicated ; but the message itself is a parameter that needs to be created and transmitted .",
    "examples of such scenarios from classical information theory are studies of the relation of communication and control , communication for coordination or function computation .",
    "these may need rethinking to address the specific setting of applications in molecular communication .",
    "for instance , proper mathematical models of the restrictions imposed by the transmitter and receiver may be needed ; finite blocklength and one - shot results may be of importance ; and channel memory may require serious considerations .",
    "as discussed in the paper , study of networks with memory is challenging , even for the simple cascade architecture .",
    "next , results from arbitrarily varying channels in classical information theory might be of particular relevance because of stochastic effects such as sensitivity of the medium to temperature or jitters .",
    "finally , extremely long delay of the diffusion process complicates formation of feedback links , which are both useful for effective communication and providing stability in control .",
    "there are already many ongoing developments in the literature .",
    "many communication oriented papers focus on error probability and consider simple isi - mitigation techniques . to put these results in a firmer theoretical footing",
    ", it would be interesting if one can show near optimality of these techniques from an information theoretic perspective ( if one can restrict to energy efficient coding strategies of limited complexity ) .",
    "we introduced three models for the transmitter and four models for receiver . while ligand receiver is a realistic receiver model , it has not been studied in conjunction with any of the transmitter models .",
    "in particular , it would be interesting to characterize the capacity of the ligand receptor with the poisson concentration transmitter .",
    "also , further works on mathematical modeling of different components of a molecular communications system ( transmitter , receiver and channel ) and their intrinsic noises and temporal variations are needed for any thorough information theoretic analysis .",
    "for instance , a transmitter may not be able to _ instantaneously _ release molecules in the environment @xcite .    as mentioned in the introduction , development of a proper theoretical framework for studying limitation of resources in the context of mc",
    "is necessary , perhaps in the context of specific circuit models .",
    "for instance , for the vlsi model , in a series of works , @xcite consider how much information bits need to travel across the surface of a vlsi circuit in order to implement an encoder or decoder function .",
    "the concept of  frictional losses \" associated with moving information on a substrate is developed for thompsons vlsi - model and used to characterize fundamental energy requirements on encoding and decoding in communication circuitry .",
    "it may be possible to develop proper models for molecular circuits .",
    "molecular circuits , including logic gates or processing units , could be implemented using chemical reactions .",
    "it is not clear how the notion of complexity in the context of mc should be defined at this point",
    ". it could be the atp consumption at the encoder and decoder units @xcite , the number of reaction ( in chemical computation ) or the length of the dna sequences used ( in dna computation ) .",
    "see also @xcite .    finally , it is also worthwhile to look for new signalling mechanisms . to the best of our knowledge ,",
    "the common presumption in the existing literature is that the information should be coded by the transmitter via the action of in the environment .",
    "however , other options are possible too .",
    "for instance , we might have a node ( separate from the transmitter ) that emits molecules in the environment according to some predefined deterministic pattern .",
    "the transmitter may change the communication medium , by exploiting chemotaxis or changing the flow ( or in general physical properties ) of the medium between the emitter and receiver .",
    "we may call this  molecular media based modulation \" as it resembles media based modulation proposed in the classical communication @xcite . the closest existing work to molecular media based",
    "modulation appears to be @xcite .",
    "further understanding of molecular media based signaling can be of interest .",
    "the authors would like to thank prof .",
    "urbashi mitra for bringing our attention to bacteria cables , and thank hamidreza arjmandi , reza mosayebi , gholamali aminian , ladan khaloopour and mehdi soleimanifar for helping with figures and some data .",
    "we also like to thank the anonymous reviewers for their comments that improved the presentation of this paper .    100    m. pierobon , i. f. akyildiz ,  a physical end - to - end model for molecular communication in nanonetworks , \" _ ieee journal on selected areas in communications _ , 28 ( 4 ) : 602611 , 2010 .",
    "t. nakano , m. j. moore , f. wei , a. v. vasilakos , j. shuai ,  molecular communication and networking : opportunities and challenges , \" _ ieee transactions on nanobioscience _ , 11(2 ) : 135148 , 2012 .",
    "n. farsad , h. b. yilmaz , a. eckford , c. b. chae , and w. guo ,  a comprehensive survey of recent advancements in molecular communication , \" to appear in _ ieee communications surveys & tutorials _ , arxiv:1410.4258v3 , feb 2016 .",
    "m. gastpar , b. rimoldi , m. vetterli ,  to code , or not to code : lossy source - channel communication revisited , \" _ ieee transactions on information theory _ ,",
    "49(5 ) : 11471158 , 2003 .",
    "r. mosayebi , h. arjmandi , a. gohari , m. nasiri - kenari and u. mitra ,  receivers for diffusion - based molecular communication : exploiting memory and sampling rate , \" _ ieee journal on selected areas in communications _ , 32 ( 12 ) : 23682380 , 2014 .",
    "m. movahednasab , m. soleimanifar , a. gohari , m. nasiri - kenari and u. mitra ,  adaptive transmission rate with a fixed threshold decoder for diffusion - based molecular communication , \" _ ieee transactions on communications _ , 64 ( 1 ) : 236248 , 2015 .",
    "a. c. yao ,  theory and applications of trapdoor functions , \" _ 23rd annual ieee symposium on foundations of computer science _",
    ", 80-91 , 1982 .",
    "j. hastad , r. impagliazzo , l. a. levin and m. luby ,  a pseudorandom generator from any one - way function , \" _ siam journal on computing _ , 28 ( 4 ) : 13641396 , 1999 .",
    "a. el gamal , j. greene , and k. pang ,  vlsi complexity of coding , \" the _ mit conf . on adv .",
    "research in vlsi _ , cambridge , ma , jan .",
    "p. grover , a. goldsmith and a. sahai , ",
    "fundamental limits on the power consumption of encoding and decoding , \" _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 27162720 , 2012 .",
    "p. grover , ",
    "information friction and its implications on minimum energy required for communication , \" _ ieee transactions on information theory _ , 61(2 ) : 895907 , 2015 .",
    "a. einolghozati , m. sardari , and f. fekri ,  collective sensing - capacity of bacteria populations , \" _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 29592963 , 2012 .",
    "n. farsad and a. goldsmith ,  a molecular communication system using acids , bases and hydrogen ions , \" 2016 ieee 17th international workshop on in signal processing advances in wireless communications ( spawc ) , 16 , 2016 .",
    "r. mosayebi , a. gohari , m. mirmohseni , and m. nasiri - kenari ,  type based sign modulation for molecular communication , \" to appear in _ proc .",
    "iran workshop on communication and information theory ( iwcit ) _ , 2016 .",
    "andrews , a. dimakis , l. dolecek , m. effros , m. medard , o. milenkovic , a. montanari , s. vishwanath , e. yeh , r. berry , k. duffy ,  a perspective on future research directions in information theory , \" arxiv preprint arxiv:1507.05941 , 2015 .",
    "b. w. andrews and p. a. iglesias ,  an information - theoretic characterization of the optimal gradient sensing response of cells , \" _ plos computational biology _",
    ", 3(8):e153 , 2007 .",
    "m. pierobon , i. f. akyildiz ,  diffusion - based noise analysis for molecular communication in nanonetworks , \" ieee transactions on signal processing , 59 ( 6 ) , 2532 - 2547 , 2011 .",
    "chou ,  a markovian approach to the optimal demodulation of diffusion - based molecular communication networks , \" ieee transactions on communications , vol .",
    "63 , no,10 , pp .",
    "3728 - 3743 , oct . 2015",
    "p. c. bressloff , _",
    "stochastic processes in cell biology _",
    ", heidelberg : springer , switzerland , 2014 .",
    "h.  arjmandi , a.  ahmadzadeh , r.  schober , and m.  nasiri - kenari , `` ion channel based bio - synthetic modulator for diffusive molecular communication , '' to appear in _ ieee transactions on nanobioscience _ , 2016 .",
    "h. mahdavifar , a. beirami ,  diffusion channel with poisson reception process : capacity results and applications , \" _ proc",
    ". ieee int . symp . on inf .",
    "theory ( isit ) _",
    ", 19561960 , 2015 .    c. v. pao ,  nonlinear parabolic and elliptic equations , \" 1992 , plenum press , new york    b. oksendal , ",
    "stochastic differential equations : an introduction with applications , \" springer - verlag berlin heidelberg , 2003 .",
    "w. feller ,  an introduction to probability theory and its applications : volume ii , \" london - new york - sydney - toronto : john wiley & sons , 1971 .",
    "p. e. protter ,  stochastic differential equations . in stochastic integration and differential equations , \" springer berlin heidelberg , 2005 .",
    "b. cushman - roisin ,",
    " environmental transport and fate , \" thayer school of engineering dartmouth college , university lecture , 2012 .",
    "h.  arjmandi , a.  gohari , m.  nasiri - kenari , and f.  bateni , `` diffusion - based nanonetworking : a new modulation technique and performance analysis , '' _ communications letters , ieee _ , 17 ( 4 ) : 645648 , 2013 .",
    "m. pierobon and i. akyildiz , `` diffusion - based noise analysis for molecular communication in nanonetworks , '' _ ieee transactions on signal processing _ , 59 ( 6 ) : 25322547 , 2011 .",
    "m. mahfuz , d. makrakis , and h. mouftah , `` a comprehensive study of sampling - based optimum signal detection in concentration - encoded molecular communication , '' _ ieee transactions on nanobioscience , _ 13 ( 3 ) : 208222 , 2014 .",
    "a. noel , k. cheung , and r. schober , `` improving receiver performance of diffusive molecular communication with enzymes , '' _ ieee transactions on nanobioscience _ , 13 ( 1 ) : 3143 , 2014 .",
    "h. yilmaz , a. heren , t. tugcu , and c .- b .",
    "chae , `` three - dimensional channel characteristics for molecular communications with an absorbing receiver , '' _ ieee communication letters _ , 18 ( 6 ) : 929 - 932 , 2014 .",
    "s. ghavami , r. s. adve , and f. lahouti ,  information rates of ask - based molecular communication in fluid media , \" _ ieee transactions on molecular , biological and multi - scale communications _",
    ", 1 ( 3 ) : 277291 , 2015",
    ".    s. m. ross , _ introduction to pobability models ( tenth edition ) , _ academic press , 2010 .",
    "n. farsad , y. murin , a. eckford , a. goldsmith ,  capacity limits of diffusion - based molecular timing channels , \" arxiv preprint arxiv:1602.07757 , 2016 .",
    "k. v. srinivas , a. w. eckford , r. s. adve ,  molecular communication in fluid media : the additive inverse gaussian noise channel , \" _ ieee transactions on information theory _ , 58(7 ) , 46784692 , 2012 .",
    "h. b. yilmaz , a. c. heren , t. tugcu , and c .- b .",
    "chae ,  three- dimensional channel characteristics for molecular communications with an absorbing receiver , \" _ ieee commuminications letters _ , 18(6 ) : 929-932 , 2014 .",
    "d. kilinc , o. b. akan ,  receiver design for molecular communication , \" _ ieee journal on selected areas in communications _ , 31 ( 12 ) : 705 - 714 , 2013 .",
    "b. atakan , o. b. akan ,  an information theoretical approach for molecular communication , \" _ bio - inspired models of network , information and computing systems , bionetics _ 3340 , 2007 .",
    "b. atakan and o. b. akan ,  single and multiple - access channel capacity in molecular nanonetworks , \" _ nano - net _ , ser .",
    "springer lect .",
    "notes inst .",
    ", social inf . and telecommu .",
    "eng . , a. schmid , s. goel , w. wang , v. beiu , and s. carrara , eds . , 20",
    ": 1423 , 2009 .",
    "a. einolghozati , m. sardari , and f. fekri ,  capacity of diffusion - based molecular communication with ligand receptors , \" _ proc .",
    "theory workshop ( itw ) _ , 8589 , 2011 .",
    "a. w. eckford , p. j. thomas ,  capacity of a simple intercellular signal transduction channel \" , _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 18341838 , 2013 .",
    "m. tahmasbi , f. fekri ,  on the capacity achieving probability measures for molecular receivers \" , _ proc .",
    "theory workshop ( itw ) _",
    ", 109113 , 2015 .",
    "a. ahmadzadeh , h. arjmandi , a. burkovski , r. schober ,  comprehensive reactive receiver modeling for diffusive molecular communication systems : reversible binding , molecule degradation , and finite number of receptors , \" ieee transactions on nanobioscience , 2016 .",
    "m. pierobon and i. akyildiz , `` noise analysis in ligand - binding reception for molecular communication in nanonetworks , '' _ ieee transactions on signal processing _ , 59(9 ) : 41684182 , 2011 .",
    "c. t. chou , `` impact of receiver reaction mechanisms on the performance of molecular communication networks , '' _ ieee transactions on nanotechnology _ , 14 ( 2 ) : 304317 , 2015 .",
    "a. c. heren , h. b. yilmaz , c. b. chae , t. tugcu ,  effect of degradation in molecular communication : impairment or enhancement ? , \" _ ieee transactions on molecular , biological and multi - scale communications _ , 1(2 ) : 217229 , 2015 .",
    "a. w. eckford ,  nanoscale communication with brownian motion , \" in _ proc .",
    "conf . on inf .",
    "sci . and syst .",
    ", 160-165 , 2007 .",
    "c. rose , c. , i. s. mian ,  signaling with identical tokens : lower bounds with energy constraints , \" _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 18391843 , 2013 .",
    "c. rose and i. mian ,  a fundamental framework for molecular communication channels : timing & payload , \" _ proc .",
    "conf . on commun .",
    ", 10431048 , 2015 .",
    "d. arifler ,  capacity analysis of a diffusion - based short - range molecular nano - communication channel , \" _ computer networks _ , 55(6 ) , 1426 - 1434 , 2011 .",
    "g.  aminian , h.  arjmandi , a.  gohari , m.  nasiri - kenari , and u.  mitra , `` capacity of diffusion based molecular communication networks in the lti - poisson model,''_ieee transactions on molecular , biological and multi - scale communications , _",
    "1(2 ) : 188201 , 2015 .",
    "r. g. gallager , information theory and reliable communication .",
    "new york wiley , 1968 .",
    "w.  hirt and j.  l. massey , `` capacity of the discrete - time gaussian channel with intersymbol interference , '' _ ieee transactions on information theory _ , 34(3):3838 , 1988 .",
    "s. shamai , l. ozarow , and a. wyner ,  information rates for a discretetime gaussian channel with intersymbol interference and stationary inputs ,  _ ieee transactions on information theory _ , 37(6 ) : 15271539 , 1991 .",
    "b. atakan and o. b. akan ,  on channel capacity and error compensation in molecular communication , \" _ trans .",
    "x _ , ser .",
    "springer lect .",
    "notes comput .",
    ", c. priami , f. dressler , o. b. akan , and a. ngom , eds . , 5410 : 5980 , 2008 .",
    "q. liu , and k. yang ,  channel capacity analysis of a diffusion - based molecular communication system with ligand receptors , \" _ international journal of communication systems _",
    ", 28(8):15081520 , 2014 .",
    "a. einolghozati , m. sardari , and f. fekri ,  design and analysis of wireless communication systems using diffusion - based molecular communication among bacteria , \" _ ieee transactions on wireless communications _ , 12(12 ) : 60966105 , 2013 .",
    "a. einolghozati , m. sardari , and f. fekri ,  relaying in diffusion - based molecular communication , \" _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 18441848 , 2013 .",
    "a. einolghozati , m. sardari , and f. fekri ,  decode and forward relaying in diffusion - based molecular communication between two populations of biological agents , \" _ proc .",
    "conf . on commun .",
    ", 39753980 , 2014 .",
    "m. s. kuran , h. b. yilmaz , t. tugcu , and b. ozerman ,  energy model for communication via diffusion in nanonetworks , \" _ elsevier nano commun .",
    "_ , 1(2 ) : 8695 , 2010 .",
    "a.  lapidoth , j.  h. shapiro , v.  venkatesan , and l.  wang , `` the discrete - time poisson channel at low input powers , '' _ ieee transactions on information theory _ , 57(6 ) : 32603272 , 2011 .",
    "a.  lapidoth and s.  m. moser , `` on the capacity of the discrete - time poisson channel , '' _ ieee transactions on information theory _ , 55(1):303322 , 2009 .",
    "y. chahibi and i. f. akyildiz ,  molecular communication noise and capacity analysis for particulate drug delivery systems \" , _ ieee transactions on communications _",
    ", 62 ( 11 ) , 38913903 , 2014 .",
    "s.  verdu , `` multiple - access channels with memory with and without frame synchronism , '' _ ieee transactions on information theory _ , 35(3 ) : 605619 , 1989 .",
    "d. p. palomar , s. verdu ,  lautum information , \" _ ieee transactions on information theory _ , 54(3 ) : 964975 , 2008 .",
    "m. mitzenmacher and e. upfal , _ probability and computing : randomized algorithms and probabilistic analysis _ , cambridge university press , 2005 .",
    "a. einolghozati , m. sardari , a. beirami , and f. fekri , ",
    "capacity of discrete molecular diffusion channels , \" _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 723727 , 2011 .",
    "v. anantharam and s. verdu ,  bits through queues ,  _ ieee transactions on information theory _ , 42(1 ) : 4-18 , 1996 .",
    "c. rose , c. , i. s. mian ,  signaling with identical tokens : upper bounds with energy constraints , \" _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 18171821 , 2014 .",
    "l. cui , a. w. eckford ,  the delay selector channel : definition and capacity bounds , \" _",
    "ieee canadian workshop on information theory ( cwit ) _",
    ", 1518 , 2011 .",
    "f. topsoe ,  an information theoretical identity and a problem involving capacity , \" _ studia scientiarum math .",
    "hungarica _ , 2:291292 , 1967 .",
    "m. n. khormuji ,  on the capacity of molecular communication over the aign channel , \" _ proc .",
    "conf . on inf .",
    "sci . and syst .",
    "( ciss ) _ , 14 , 2011 .",
    "h. li , s. moser , and d. guo ,  capacity of the memoryless additive inverse gaussian noise channel , \" _ ieee journal on selected areas in communications _ , 32(12 ) : 23152329 , 2014 .",
    "w. schwarz ,  on the convolution of inverse gaussian and exponential random variables , \" _ communications in statistics  theory and methods _ , 31(12 ) : 21132121 , 2002 .",
    "eckford , c. b. chae  scaling laws for molecular communication \" , _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 12811285 , 2014 .",
    "m. kovacevic , p. popovski ,  zero - error capacity of a class of timing channels , \" _ ieee transactions on information theory _ , 60(11 ) , 67966800 , 2014 .",
    "s. verdu , t. s. han ,  a general formula for channel capacity , \" _ ieee transactions on information theory _ , 40 ( 4 ) , 1147 - 1157 , 1994 .",
    "q. xie and a. r. barron ,  minimax redundancy for the class of memoryless sources , \" _ ieee transactions on information theory _ , 43(2 ) : 646657 , 1997 .",
    "g.  aminian , m. farahnak - ghazani , m. mirmohseni , m.  nasiri - kenari , and f. fekri , `` on the capacity of point - to - point and multiple - access molecular communications with ligand - receptors , '' to appear in _ ieee transactions on molecular , biological and multi - scale communications , _ 2016 .",
    "p. j. thomas , a. w. eckford , a. w.  shannon capacity of signal transduction for multiple independent receptors , \" arxiv preprint arxiv:1604.03508 , 2016 .",
    "j. chen and t. berger , `` the capacity of finite - state markov channels with feedback , '' _ ieee transactions on information theory _ , 51(3 ) : 780798 , 2005 .",
    "h. h. permuter , h. asnani , and t. weissman ,  capacity of a post channel with and without feedback ,  _ ieee transactions on information theory _ , 60(10 ) : 60416057 , 2014 .",
    "p. j. thomas , a. eckford  shannon capacity of signal transduction for multiple independent receptors , \" ieee international symposium on information theory ( isit ) , 18041808 , 2016 .",
    "n. michelusi , s. pirbadian , m.y .",
    "el - naggar , u. mitra ,  a stochastic model for electron transfervin bacterial cables \" , _ ieee journal on selected areas in communication _ , 32(12 ) : 24022416 , 2014 .",
    "g. kramer , m. i. yousefi and f. r. kschischang ,  upper bound on the capacity of a cascade of nonlinear and noisy channels , \" _ ieee information theory workshop ( itw ) _ , 1 - 4 , 2015 .",
    "r. b. ash , _ information theory _ , new york wiley , 1965    t. m. cover and j. a. thomas , _ elements of information theory , _ new york wdey , 1991 .",
    "r. j. mceliece , _ the theory of information and coding , _ reading ,",
    "ma : addison - wesley , 1977    aaron b. kiely and john t. coffey ,  on the capacity of a cascade of channels \" , _ ieee transactions on information theory _ , 39 ( 4):13101321 , 1993 .",
    "e. majani ,  a model for the study of very noisy channels , and applications , \" _ ph.d .",
    "dissertation _ , california inst .",
    "of technol . , pasadena , ca , 1988 .",
    "simon ,  on the capacity of a cascade of identical discrete memoryless nonsingular channels , \" _ ieee transactions on information theory _ , 16(1 ) : 100 - 102 , 1970 .",
    "siveman ,  on binary channels and their cascades , \" _ ire transactions on information theory _ , 1(3 ) : 19 - 27 , 1955 .",
    "r. ahlswede and p. gacs ,  spreading of sets in product spaces and hypercontraction of the markov operator , \" _ annals of probability _ , 925-939 , 1976 .",
    "v. anantharam , a. gohari , s. kamath , and c. nair .",
    " on maximal correlation , hypercontractivity , and the data processing inequality studied by erkip and cover , \" arxiv preprint arxiv:1304.6133 , 2013 .",
    "y. polyanskiy and y. wu ,  dissipation of information in channels with input constraints , \" _ ieee transactions on information theory _ , 62 ( 1 ) , 3555 , 2016 .",
    "u. niesen , c. fragouli , d. tuninetti ,  on the capacity of line networks , \" _ ieee transactions on information theory _ , 53 ( 11 ) , 40394058 , 2007 .",
    "r. subramanian , b. n. vellambi , and i. land .",
    " an improved bound on information loss due to finite block length in a gaussian line network , \" _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 18641868 , 2013 .",
    "r. subramanian ,  the relation between block length and reliability for a cascade of awgn links , \" _ proc .",
    "zurich seminar on communications ( izs ) _",
    ", 71-74 , 2012 .",
    "y. lu , m. d. higgins , m. s. leeson ,  comparison of channel coding schemes for molecular communications systems , \" _ ieee transactions on communications _ , 63 ( 11 ) : 3991  4001 , 2015 .",
    "n. farsad , h. b. yilmaz , c. b. chae , a. goldsmith ,  energy model for vesicle - based active transport molecular communication , \" arxiv:1510.05075 ( 2015 ) .",
    "a. k. khandani ,  media - based modulation : a new approach to wireless transmission , \" _ proc .",
    "symp . on inf .",
    "theory ( isit ) _",
    ", 30503054 , 2013 .",
    "t. nakano , t. suda , m. j. moore ,  molecular communication through biological pattern formation , \" _ ieee global communications conference ( globecom ) _",
    ", 17 , 2015 .    c. a. charalambides , _ enumerative combinatorics , _ crc press , 2002 .",
    "we construct an example for the second part of the conjecture by carefully constructing a channel with memory .",
    "a channel with infinite memory can remember all of its past inputs and can adapt its input - output statistical description according to all past inputs .",
    "the general idea is to design the state dependent channel with memory , @xmath331 , that behaves intelligently as a memoryless channel followed by a relay node who can decode and re - encode the information .",
    "therefore the cascade of the @xmath314 channels with memory behaves as the cascade of @xmath314 memoryless channels with relay processers placed between them .",
    "these relays decode and re - encode information allowing for the capacity of the cascade channel to reach the min - cut capacity of the links , strictly above @xmath421 .",
    "we construct a @xmath331 structured as follows and depicted in fig .",
    "[ cascade2n2 ] : the input is @xmath422 and the output is @xmath423 , where @xmath424 , and @xmath425 .",
    "we assume that @xmath426 regardless of the state value , and input @xmath427 .",
    "the input @xmath427 first passes through a memoryless erasure channel @xmath428 , with erasure probability @xmath429 acting independent of the state , and then through a state - dependent channel @xmath430 .",
    "the value of @xmath431 is updated according to the input @xmath432 and its previous value .",
    "the idea is to have @xmath430 acting as a relay node that decodes information over the erasure channel and re - encodes it .",
    "are binary , while @xmath427 and @xmath433 are k - ary .",
    "the alphabet for @xmath434 is @xmath435 is created by passing @xmath427 through a memoryless erasure channel.,scaledwidth=80.0% ]     part passes through the chain without being disturbed.,scaledwidth=100.0% ]    note that @xmath436 for this channel .",
    "due to the @xmath346 part of the input that is directly connected to the output @xmath437 , it is possible to send one bit throughout the @xmath314 cascade channels ( see fig .  [ cascade2n ] ) .",
    "furthermore , because an erasure channel is acting on the @xmath427 part right after entering the first block , the input part @xmath427 can be erased with some positive probability .",
    "therefore , the @xmath427 part can not be used to transmit information with exactly zero error probability .",
    "observe that the @xmath346 component passes through all the cascade nodes without any error .",
    "it is used for the following actions :    * to reset the initial state of all of the state - dependent channels in the cascade structure to a known initial ",
    "reset \" state .",
    "we assume that this is done by sending three consecutive zeros ( @xmath438 ) on the @xmath346 part .",
    "* once in the initial  reset \" state , and given the error probability @xmath165 at the transmitter , the transmitter chooses a blocklength @xmath12 , finds the binary expansion of @xmath12 and send its bits to each of the state - dependent channels on the @xmath346 part .",
    "this incurs @xmath439 bits to communicate .",
    "the end of the @xmath439 bits is marked by the  end sequence \" string @xmath440 . in order to avoid confusion with ",
    "reset \" and  end sequence \" strings @xmath438 and @xmath440 , we assume that blocklength @xmath12 is chosen such that its binary expansion does not have either of @xmath438 and @xmath440 showing up as its consecutive digits . thus far , the channel has been used @xmath441 times .",
    "* once the blocklength @xmath12 is conveyed , the @xmath346 link is used to communicate information @xmath12 more times , while ensuring that the reset symbol @xmath438 is not used accidentally .",
    "one way to achieve this is to code the information bits into sequences of bits that do not have any two consecutive zeros .",
    "the number of such sequences of length @xmath12 is given by the fibonacci number @xcite , growing like @xmath442 .",
    "thus , with this set of sequences of length @xmath12 , we may convey @xmath443 bits of information .",
    "in other words , the communication rate is @xmath444 , which is less than @xmath8 bit per symbol that we could have achieved on the @xmath445 with simple transmission of bits ; we will compensate for this hit using the @xmath446 input part .",
    "the state - dependent channel can remember all the past inputs .",
    "once it goes to a reset state , it starts learning the blocklength @xmath12 .",
    "once that is over , each node knows exactly the blocklength @xmath12 ; then , all of the nodes can agree on an appropriate decoder / encoder of blocklength @xmath12 for communication over an erasure channel with paramter @xmath429 .",
    "each node begins looking at the @xmath427 part of their input for the next @xmath12 symbols . to produce @xmath433",
    ", each node simulates the appropriate decoder / encoder for the blocklength @xmath12 on the erasure channel . because the capacity of the erasure channel is @xmath447",
    ", this would allow for reliable transmission of @xmath448 bits of information with error probability @xmath165 on each hop .",
    "the total error probability will be at most @xmath449 where @xmath314 is the length of the cascade .",
    "this can be made arbitrarily close to zero for a given @xmath314 by sending blocklength @xmath12 to infinity and @xmath165 to zero .",
    "the total number of bits that are communicated is @xmath450 , and the channel is used @xmath451 times .",
    "this gives us the rate @xmath452 by letting @xmath12 converge to infinity and @xmath165 converge to zero .",
    "observe that @xmath453 can be made arbitrarily larger than @xmath436 by making @xmath95 large .",
    "observe that @xmath454 for any @xmath314 . to see this , note that by choosing an arbitrary vertex from communicating class @xmath15 and partition @xmath455 , we can perfectly predict that after going through @xmath314 channels , the final state is in communicating class @xmath15 and partition @xmath456 .",
    "therefore , we can use our choice of communicating class and one of its partitions for signaling with zero error probability .",
    "thus , @xmath457 because for each @xmath314 , @xmath458 , it only remains to show that @xmath459    let us assume that @xmath460 where @xmath461 is the set of transient nodes , and @xmath462 for @xmath463 $ ] is the @xmath15-th closed communicating class .",
    "furthermore , for @xmath464 $ ] , the induced graph on @xmath462 is @xmath221-partite and we can correspondingly partition @xmath462 into @xmath221 sets @xmath465 , having @xmath466 .",
    "_ case ( i ) : the support of @xmath467 is a subset of @xmath469 for some @xmath464 , j\\in[1:t_i]$]_. in other words , @xmath346 is in the @xmath281-th partition of the @xmath15-th communicating class . observe that @xmath470 is a decreasing sequence in @xmath314 , by the data processing inequality .",
    "therefore , it suffices to study the limit for the subsequence defined by @xmath471 for @xmath472 .",
    "but if @xmath346 is in the @xmath281-th partition of the @xmath15-th communicating class , after @xmath473 steps , it will return to the same partition of the same communicating class .",
    "therefore , we can define a reduced markov chain on nodes in the @xmath281-th partition of the @xmath15-th communicating class that specifies the transition probabilities after @xmath221 steps .",
    "this markov chain is irreducible and aperiodic .",
    "therefore , it has a unique stationary pmf @xmath245 to which the chain converges regardless of initial state @xmath346 .",
    "thus , @xmath474 and @xmath475 both tend to the entropy of @xmath245 as @xmath476 converges to infinity , for any arbitrary @xmath445 in @xmath469 .",
    "this implies that @xmath477 is zero in this case .",
    "_ case ( ii ) : @xmath478 for all @xmath479 .",
    "_ let random variable @xmath480 , j\\in[1:t_i]\\}$ ] denote the index of the communicating class and the corresponding partition that @xmath346 belongs to . from our earlier discussion",
    "@xmath481 is a deterministic function of both @xmath346 and @xmath352 .",
    "thus , @xmath482 by case ( i ) and the fact that @xmath483 is concentrated on one of the partitions of a communicating classes , we have that for any @xmath484 : @xmath485 therefore , @xmath468    _ case ( iii ) : arbitrary @xmath467 .",
    "_ since @xmath486 is the class of transient states , we have @xmath487=0.\\ ] ] thus , for any @xmath488 , one can find some @xmath489 such that @xmath490<\\delta$ ] .",
    "let @xmath313 be an indicator function that @xmath491 .",
    "then , @xmath492 now , conditioned on @xmath493 , the pmf of @xmath494 falls in the class of pmfs studied in case ( ii ) .",
    "therefore , @xmath495 .",
    "hence , @xmath496 we obtain the desired result by letting @xmath497 tend to zero ."
  ],
  "abstract_text": [
    "<S> molecular communication ( mc ) is a communication strategy that uses molecules as carriers of information , and is widely used by biological cells . as an interdisciplinary topic </S>",
    "<S> , it has been studied by biologists , communication theorists and a growing number of information theorists . </S>",
    "<S> this paper aims to specifically bring mc to the attention of information theorists . to do this </S>",
    "<S> , we first highlight the unique mathematical challenges of studying the capacity of molecular channels . addressing these problems require use of known , or development of new mathematical tools . toward this goal </S>",
    "<S> , we review a subjective selection of the existing literature on information theoretic aspect of molecular communication . </S>",
    "<S> the emphasis here is on the mathematical techniques used , rather than on the setup or modeling of a specific paper . finally , </S>",
    "<S> as an example , we propose a concrete information theoretic problem that was motivated by our study of molecular communication . </S>"
  ]
}