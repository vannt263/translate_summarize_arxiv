{
  "article_text": [
    "principal component analysis ( pca ) is a well studied , popular tool used for dimensionality reduction and low - dimensional representation of data with applications spanning many fields of science and engineering .",
    "principal components ( pc ) of a set of `` observations '' on some @xmath0 variables capture orthogonal directions of maximum variance and offer a euclidean - distance - optimal , low - dimensional visualization that -for many purposes- conveys sufficient amount of information . without additional constraints ,",
    "the pcs of a data set can be computed in polynomial time in @xmath0 , using the eigenvalue decomposition .",
    "one disadvantage of the classical pca is that , in general , the extracted eigenvectors are expected to have nonzero elements in all their entries .",
    "however , in many applications sparse vectors that maximize variance are more favorable .",
    "sparse pcs can be less complicated to interpret , easier to compress , and cheaper to store . thus ,",
    "if the application requires it , then some of the maximum variance property of a pc may be slightly traded for sparsity . to mitigate the fact that pca is oblivious to _ sparsity _ requirements , an additional cardinality constraint needs to be introduced to the initial variance maximization objective .",
    "the sparsity aware flavor of pca , termed _ sparse pca _ , inarguably comes at a higher cost : sparse pca is an np - hard problem @xcite .",
    "to approximate sparse pca various methods have been introduced in the literature .",
    "initially , factor rotation techniques that extract sparse pcs were used in @xcite , @xcite .",
    "straightforward thresholding of pcs was presented in @xcite as a computationally light means for obtaining sparsity .",
    "then , a modified pca technique based on the lasso was introduced in @xcite . in @xcite an elaborate nonconvex regression - type optimization approach combined with lasso penalty",
    "was used to approximately tackle the problem .",
    "a nonconvex technique , locally solving difference - of - convex - functions programs was presented in @xcite .",
    "semidefinite programming ( sdp ) was used in @xcite , @xcite , while @xcite augmented the sdp approach with an extra greedy step that offers favorable optimality guarantees under certain sufficient conditions .",
    "the authors of @xcite considered greedy and branch - and - bound approaches , further explored in @xcite .",
    "generalized power methods using convex programs were also used to approximately solve sparse pca @xcite .",
    "a sparse - adjusted deflation procedure was introduced in @xcite and in @xcite optimality guarantees were shown for specific types of covariance matrices under thresholding and sdp relaxations .    * our contribution : * in this work we prove that the sparse principal component of a matrix @xmath1 can be obtained in polynomial time under a new sufficient condition : when @xmath1 can be written as a sum of a scaled identity matrix plus an update , i.e. @xmath2 , and the rank of the update @xmath3 is not a function of the problem size . , then we simply have a low - rank matrix @xmath1 . ] under this condition , we show that sparse pca is polynomially solvable , with the exponent being only a linear function of the rank .",
    "this result is possible after introducing _ auxiliary spherical variables _ that `` unlock '' the low - rank structure of @xmath3 .",
    "the low - rank property along with the auxiliary variables enable us to scan a constant dimensional space and identify a polynomial number of _ candidate _ sparse vectors .",
    "interestingly , we can show that the optimal vector always lies among these candidates and a polynomial time search can always retrieve it .",
    "we are interested in the computation of the real , unit - length , and at most @xmath4-sparse principal component of the @xmath5 nonnegative definite matrix @xmath1 , i.e. @xmath6 where @xmath7 .",
    "interestingly , when @xmath1 can be decomposed as a low - rank update of a constant identity matrix , i.e. @xmath2 where @xmath8 , @xmath9 is the @xmath5 identity , and @xmath3 is a nonnegative definite matrix with rank @xmath10 , then @xmath11 .",
    "therefore , the optimization ( [ initial_problem ] ) can always be rewritten as @xmath12 where the new matrix @xmath3 has rank @xmath10 . since @xmath3 is a nonnegative definite matrix , it can be decomposed as @xmath13 where @xmath14 $ ] and problem can be written as @xmath15 in the following , we show that when @xmath10 is _ not _ a function of @xmath0 , ( [ initial_problem ] ) can be solved in time @xmath16 .",
    "prior to presenting the main result for the general rank @xmath10 case , in this section we provide insights as to why sparse pca of rank deficient matrices can be solved in polynomial time , along with the first nontrivial case of polynomial solvability for rank-@xmath18 matrices @xmath3 .      in this case",
    ", @xmath19 has rank @xmath17 , @xmath20 , and ( [ simpler_problem ] ) becomes     _ & = _ * x*_k^n |*v*^t*x*|= _ * x*_k^n|_i=1^nv_ix_i|.[rank1maxqf ]    it is trivial to observe that maximizing ( [ rank1maxqf ] ) can be done by distributing the @xmath4 nonzero _ loadings _ of @xmath21 to the @xmath4 absolutely largest values of @xmath22 , indexed by set @xmath23 .",
    "then , the optimal solution @xmath24 has the following @xmath4 nonzero loadings @xmath25 where @xmath26 denotes the set of elements of @xmath27 indexed by @xmath23 and @xmath28 for all @xmath29 .",
    "the leading complexity term of this solution is determined by the search for the @xmath4 largest element of @xmath22 , which can be done in time @xmath30 @xcite .",
    "therefore , the rank-@xmath17-optimal solution can be attained in time that is linear in @xmath0 .      in this case",
    ", @xmath31 is an @xmath32 matrix .",
    "a key tool used in our subsequent developments is a set of auxiliary spherical variables . for the rank-@xmath18 case",
    ", we introduce a single phase variable @xmath33 $ ] and define the polar vector @xmath34 which lies on the surface of a radius @xmath17 circle .",
    "then , from cauchy - schwartz inequality we obtain        with equality if and only if @xmath35 is parallel to @xmath36 .",
    "therefore , finding @xmath37 that maximizes @xmath38 in ( [ simpler_problem ] ) is equivalent to obtaining @xmath21 of the @xmath39 pair that maximizes @xmath40 .",
    "initially , this rewriting of the problem might seem unmotivated , however in the following we show that the use of @xmath35 unlocks the low - rank structure of @xmath41 and allows us to compute the sparse pc of @xmath3 by solving a polynomial number of rank-@xmath17 instances of the problem .",
    "we continue by restating the problem in ( [ simpler_problem ] ) as    _ * x*_k^n & = _ * x*_k^n _ ( - , ] | ^t ( ) ^t | + & = _ ( - , ] _ * x*_k^n | _ ^t ( ) | [ rank2intro : less_naive_equivalent ] .",
    "if we fix @xmath42 , then the internal maximization problem    _ * x*_k^n | ^t()*x*| [ rank2intro : observation_for_given_phi_is_rank_1 ]    is a rank-@xmath17 instance , for which we can determine in time @xmath30 the optimal index - set @xmath43 corresponding to the indices of the @xmath4 absolutely largest elements of @xmath44 .",
    "however , why should @xmath42 simplify the computation of a solution ?",
    "the intuition behind the polar vector concept is that every element of     ( ) =    v_1,1 + v_1 , 2 +   + v_n,1 + v_n , 2 +    [ rank2intro : vc ]    is actually a continuous function of @xmath42 , i.e. a curve in @xmath42 .",
    "hence , the @xmath4 absolutely largest elements of @xmath45 at a given point @xmath42 are functions of @xmath42 . due to the continuity of the curves , we expect that the index set @xmath43 will retain the same elements in an area `` around '' @xmath42 .",
    "therefore , we expect the formation of regions , or `` cells '' on the @xmath42 domain , within which the indices of the @xmath4 absolutely largest elements of @xmath46 remain unaltered . a sorting ( i.e. , an @xmath23-set ) might change when the sorting of the amplitudes of two element in @xmath46 changes .",
    "this occurs at points @xmath42 , where these two absolute values become equal , that is , points where two curves intersect . finding all these _ intersection points _ ,",
    "is sufficient to determine cells and construct all possible candidate @xmath23-sets . among all candidate @xmath23-sets ,",
    "lies the set of indices corresponding to the optimal @xmath4-sparse pc .",
    "exhaustively checking the @xmath23-sets of all cells , suffices to retrieve the optimal .",
    "surprisingly , the number of these cells is exactly equal to number of possible intersections among the amplitudes of @xmath46 , which is exactly equal to @xmath47 , counting all possible combinations of element pairs and sign changes .    , @xmath48 , rank-@xmath18 case : cells on the @xmath42 domain.,scaledwidth=50.0% ]    before we proceed , in fig .",
    "[ rank2intro : fig : v_rank2_cells_and_regions ] we illustrate the cell partitioning of the @xmath42 domain , where we set @xmath49 and @xmath48 and plot the magnitudes of the 4 curves that originate from the 4 rows of @xmath50",
    ". cells ( intervals ) are formed , within which the sorting of the curves does not change .",
    "the borders of cells are denoted by vertical dashed lines at points of curve intersections .",
    "our approach creates @xmath51 cells which exceeds the total number of possible index - sets , however this is not true for greater values of @xmath0 .",
    "moreover , we use @xmath52 regions to denote the sorting changes with respect to only the @xmath4-largest curves .",
    "these regions is an interesting feature that might yet decrease the number of cells we need to check .",
    "however , due to lack of space we are not exploiting this interesting feature here .",
    "our goal is the construction of all possible candidate @xmath4-sparse vectors , determined by the index - sets of each cell on the @xmath42 domain .",
    "this is a two step process .",
    "first we need to identify cell borders , and then we have to determine the index sets associated with these cells .    _ algorithmic steps : _ we first determine all possible intersections of curve pairs in @xmath46 . any pair @xmath53 of distinct elements in @xmath46",
    "is associated with two intersections : @xmath54 and @xmath55 .",
    "solving these two equations with respect to @xmath42 , determines a possible point where a new sorting of the @xmath4-largest values of @xmath46 might occur .",
    "observe that at an intersection point , the two values @xmath56 are absolutely the same .",
    "exactly on the point of intersection , all but @xmath18 ( the @xmath57th and @xmath58th ) coordinates of a candidate @xmath4 sparse vector can be determined by solving a rank @xmath17 instance of the problem .",
    "however , we are left with ambiguity with respect to @xmath18 coordinates @xmath57 and @xmath58 that needs to be resolved . to resolve this ambiguity",
    ", we can visit the `` outermost '' point of the @xmath42 domain , that is , @xmath59 .",
    "there , due to the continuity of @xmath60 and @xmath61 , the sortings within the two cells defined by the two intersections , will be the identical , or opposite sortings of @xmath62 and @xmath63 , depending on whether @xmath60 and @xmath61 are both positive , or negative at the intersection point , respectively .",
    "having described how to resolve ambiguities , we have fully described a way to calculate the @xmath23-set at any intersection point .",
    "apparently , all intersection points , that is , all @xmath64 pairwise combinations of elements in @xmath46 , have to be examined to yield a corresponding @xmath23-set .    _",
    "computational complexity : _ a single intersection point can be computed in time @xmath65 . at a point of intersection , we have to determine the @xmath4-th order element of the absolute values of @xmath46 and the @xmath66 elements larger than that , which can be done in time @xmath67 .",
    "resolving an ambiguity costs @xmath65 .",
    "so in total , finding a single @xmath23-set costs @xmath67 . constructing all candidate @xmath23-sets requires examining all @xmath68 points , implying a total construction cost of @xmath69 .",
    "in the general case , @xmath31 is a @xmath70 matrix . in this section",
    "we present our main result where we prove that the problem of identifying the @xmath4-sparse principal component of a rank-@xmath10 matrix is polynomially solvable if the rank @xmath10 is not a function of @xmath0 .",
    "the statement is true for any value of @xmath4 ( that is , even if @xmath4 is a function of @xmath0 ) .",
    "our result is presented in the form of the following proposition .",
    "the rest of the section contains a constructive proof of the proposition .    consider a @xmath5 matrix @xmath1 that can be written as a rank-@xmath10 update of the identity matrix , that is , @xmath71 where @xmath72 and @xmath3 is a rank-@xmath10 symmetric positive semidefinite matrix",
    "then , for any @xmath73 , the @xmath4-sparse principal component of @xmath3 that maximizes @xmath74 subject to the constraints @xmath75 and @xmath76 can be obtained with complexity @xmath77 .",
    "@xmath78    we begin our constructive proof by introducing the spherical coordinates @xmath79 $ ] and defining the spherical coordinate vector @xmath80}^t } , \\ ] ] the hyperpolar vector @xmath81 and set @xmath82 $ ] .",
    "then , similarly with and due to cauchy - schwartz inequality , our optimization problem in ( [ simpler_problem ] ) is restated as @xmath83 hence , to find @xmath37 that maximizes @xmath38 in ( [ simpler_problem ] ) , we can equivalently find the @xmath84 pair that maximizes @xmath85 .",
    "we interchange the maximizations in @xmath86 and obtain @xmath87 for a given point @xmath88 , @xmath89 is a fixed vector and the internal maximization problem @xmath90 is a rank-@xmath17 instance .",
    "that is , for any given point @xmath88 , we can determine the optimal set @xmath91 of the nonzero elements of @xmath37 as the set of the indices of the @xmath4 largest elements of vector @xmath92 .",
    "to gain some intuition into the purpose of inserting the second variable @xmath88 , notice that every element of @xmath93 is actually a continuous function of @xmath88 , a @xmath10-dimensional hypersurface and so are the elements of @xmath94 . when we sort the elements of @xmath94 at a given point @xmath88 , we actually sort the hypersurfaces at point @xmath88 according to their magnitude .",
    "the key observation in our algorithm , is that due to the continuity of the hypersurfaces in the @xmath95 hypercube , we expect that in an area `` around '' @xmath88 the hypersurfaces will retain their magnitude - sorting .",
    "so we expect the formation of cells in the @xmath95 hypercube , within which the magnitude - sorting of the hypersurfaces will remain unaltered , irrespectively of whether the magnitude of each hypersurface changes .",
    "moreover , even if the sorting of the hypersurfaces changes at some point around @xmath88 it is possible that the @xmath23 does not change .",
    "so we expect the formation of regions in the @xmath95 hypercube which expand over more than one cells and within which the @xmath23-set remains unaltered , even if the sorting of the hypersurfaces changes .",
    "if we can efficiently determine all these cells ( or even better regions ) and obtain the corresponding @xmath23-sets , then the set of all candidate index - sets may be significantly smaller than the set of all @xmath96 possible index - sets .",
    "once all the candidate @xmath23-sets have been collected , @xmath97 and @xmath24 will be determined through exhaustive search among the candidate sets .",
    "in we observed that at a given point @xmath88 the maximization problem resembles the and consequently , the @xmath23-set at @xmath88 consists of the indices of the @xmath4 largest elements of @xmath98 .",
    "motivated by this observation , we define a _ labeling function _ @xmath99 that maps a point @xmath88 to an index - set @xmath100 then , each point @xmath101 is mapped to a candidate index - set and the optimal index - set @xmath97 belongs to @xmath102 in the following , we _ ( i ) _ show that the total number of candidate index - sets is @xmath103 and _ ( ii ) _ develop an algorithm for the construction of @xmath104 with complexity @xmath77 .",
    "the labeling function is based on pair - wise comparisons of the elements of @xmath105 while each element of @xmath106 is a continuous function of @xmath88 , a @xmath10-dimensional hypersurface , and any point @xmath88 is mapped to an index - set @xmath23 which is determined by comparing the magnitudes of these hypersurfaces at @xmath88 . due to the continuity of hypersurfaces , the index - set @xmath23 does not change in the `` neighborhood '' of @xmath88 .",
    "a necessary condition for the @xmath23 set to change is two of the hypersurfaces to change their magnitude ordering .",
    "the switching occurs at the intersection of two hypersurfaces where we have @xmath107 which yields @xmath108 functions @xmath109 and @xmath110 determine @xmath111-dimensional hypersurfaces @xmath112 and @xmath113 , respectively .",
    "each hypersurface partitions @xmath95 into two regions .    for convenience , in the following we use a pair @xmath53 to denote the rows of matrix @xmath114 , that originate hypersurface @xmath115 .",
    "moreover , we allow @xmath57 and @xmath58 to be negative in order to encapsulate the information about the sign with which each row participates in the generation of hypersurface @xmath116 , i.e.    \\{i , j } s(*v*_|i| , : ; * v*_|j| , : ) ,    where @xmath117 .",
    "let @xmath118 where @xmath119 is one among the @xmath120 size-@xmath10 subsets of @xmath121 .",
    "then , by keeping @xmath122 fixed ( where @xmath122 is arbitrarily selected , say @xmath122 is the minimum among @xmath123 ) and assigning signs to @xmath124 we can generate @xmath125 sets of the form @xmath126 .",
    "hence , we can create totally @xmath127 such sets which we call @xmath128 .",
    "we can show ( the proof is omitted due to lack of space ) that , for any @xmath129 , the @xmath130 hypersurfaces @xmath115 that we obtain for @xmath131 have a single common intersection point @xmath132 which `` leads '' at most @xmath133 cells .",
    "each such cell is associated with an index - set in the sense that @xmath134 is maintained for all @xmath88 in the cell . in other words ,",
    "the @xmath23-set associated with all points @xmath88 in the interior of the cell is the same as the @xmath23-set at the leading vertex .",
    "in fact , the actual sorting of @xmath135 for all points in the interior of the cell is the same as the sorting at the leading vertex and the @xmath23-set may characterize a greater area that includes many cells .",
    "in addition , we can show that examination of all such cells is sufficient for the computation of all index - sets that appear in the partition of @xmath95 and have a leading vertex .",
    "we collect all index - sets into @xmath104 and observe that @xmath136 can only be a subset of the set of all possible @xmath137 index - sets .",
    "in addition , since the cells are defined by a leading vertex , we conclude that there are at most @xmath138 cells .",
    "we finally note that there exist cells that are not associated with an intersection - vertex .",
    "we can show that such cells can be ignored unless they are defined when @xmath139 . in the latter case",
    ", we just have to identify the cells that are determined by the reduced - size matrix @xmath140 over the hypercube @xmath141 .",
    "hence , @xmath142 and , by induction ,    _ ( _ n d ) = ( _ n d ) _ ( _ n ( d-2)),3dd ,    which implies that    & _ ( _ n d ) + & = ( _ n d ) ( _ n ( d-2 ) ) ( _ n ( d-2 ) ) + & = _ d=0^ ( _ n ( d-2d ) ) [ total_index_set_as_join ] .    as a result , the cardinality of @xmath143 is    & | _ ( _ n d ) | + & | ( _ n d)|+| ( _ n ( d-2))|++| ( _ n ( d-2 ) ) | + & 2^d-1 + 2^d-3 + + & + 2^d-1 - 2   + & = _",
    "d=0^ 2^d-1 - 2d=(n^d ) .",
    "it remains to show how @xmath104 is constructed .",
    "as already mentioned , there are in total @xmath127 intersection points which can all be blindly examined . for any @xmath129 ,",
    "the cell leading vertex @xmath132 is computed efficiently as the intersection of @xmath144 hypersurfaces , i.e. the unique solution of    l@l _ i_1 , 1:d & _ i_2 , 1:d + & +   _ i_1 , 1:d & _ i_d , 1:d     ( _ 1:d-1 ) = _",
    "( d-1)1 , [ find_phi_with_svd ]    which is obtained in time @xmath65 with respect to @xmath0 .",
    "after @xmath132 has been computed , we have to identify the index - sets associated with the cells that originate at @xmath132 by calling the labeling function @xmath145 which marks the @xmath4 elements of the @xmath23-set , i.e. the indices of the @xmath4 largest elements of @xmath146 , @xmath129 .",
    "since @xmath132 constitutes the intersection of @xmath10 hypersurfaces that correspond to the @xmath10 elements of @xmath132 , the corresponding values in @xmath146 equal each other . if the @xmath4 largest values in @xmath146 contain @xmath147 values that correspond to the @xmath10 elements of @xmath148 , then we can blindly examine all @xmath149 cases of index - sets to guarantee that all actual index - sets are included .",
    "the term @xmath149 is maximized for @xmath150 , hence at most @xmath133 index - sets correspond to intersection point @xmath132 .",
    "the complexity to build @xmath151 results from the parallel examination of @xmath127 intersection points while worst - case complexity @xmath152 is required at each point for the identification of the corresponding index - sets .",
    "the term @xmath67 corresponds to the cost required to determine the @xmath4th - order element of @xmath146 in an unsorted array .",
    "consequently , the worst - case complexity to build @xmath151 becomes @xmath153 .",
    "finally , we recall that the cardinality of @xmath143 is upper bounded by @xmath154 and conclude that the overall complexity of our algorithm for the evaluation of the sparse principal component of @xmath155 is upper bounded by @xmath77 .",
    "we considered the problem of identifying the sparse principal component of a rank - deficient matrix .",
    "we introduced auxiliary spherical variables and proved that there exists a set of candidate index - sets whose size is polynomially bounded , in terms of rank , and contains the optimal index - set , i.e. the index - set of the nonzero elements of the optimal solution .",
    "finally , we developed an algorithm that computes the optimal sparse principal component in polynomial time .",
    "our proposed algorithm stands as a constructive proof that the computation of the sparse principal component of a rank - deficient matrix is a polynomially solvable problem .",
    "y. zhang , a. d aspremont , and l. el ghaoui , `` sparse pca : convex relaxations , algorithms and applications , '' to appear in _",
    "handbook on semidefinite , cone and polynomial optimization_. preprint on arxiv : 1011.3781v2 [ math.oc]/"
  ],
  "abstract_text": [
    "<S> we consider the problem of identifying the sparse principal component of a rank - deficient matrix . </S>",
    "<S> we introduce auxiliary spherical variables and prove that there exists a set of candidate index - sets ( that is , sets of indices to the nonzero elements of the vector argument ) whose size is polynomially bounded , in terms of rank , and contains the optimal index - set , i.e. the index - set of the nonzero elements of the optimal solution . </S>",
    "<S> finally , we develop an algorithm that computes the optimal sparse principal component in polynomial time for any sparsity degree . </S>"
  ]
}