{
  "article_text": [
    "quantum computing offers the potential to solve computational problems intractable on classical computers .",
    "one of the great challenges facing the development of quantum computers is decoherence , a problem which affects all known quantum computing architectures .",
    "this has motivated much research into fault - tolerant quantum computing @xcite .",
    "the most fundamental building blocks in fault - tolerant quantum circuits are quantum error correcting codes ( qecc s ) @xcite , which encode logical qubits in a way that tolerates some number of physical errors .    in certain physical realizations of quantum computing",
    ", errors of two distinct types will be present : _ located _ and _ unlocated _ errors .",
    "a located error is one that leaves behind a classical signal indicating which qubit was affected .",
    "an unlocated error , on the other hand , corrupts the state of a qubit without leaving any such additional evidence .",
    "an important example of a located error is qubit loss ; for example the loss of a photon in optical quantum computing .",
    "( we use the terms _ located error _ and _ loss _ interchangeably in this paper .",
    "loss errors are also known as _ erasure _ errors in some contexts , e.g. @xcite . )",
    "traditionally qecc s have focused on correcting unlocated errors . specifically , most existing codes and protocols aim to protect against unlocated depolarizing noise ( where each qubit with some probability enters the maximally mixed state ) .",
    "recently , however , especially with the advent of photonic quantum computing architectures @xcite , several codes and protocols have been suggested for dealing specifically with located errors in the form of qubit loss @xcite .",
    "it has recently been shown @xcite that these loss - tolerant protocols have the negative side - effect of amplifying depolarizing noise .",
    "since scalable quantum computing requires tolerance against both error types , it is important to understand what type of fundamental constraints exist on the ability of quantum error - correcting codes to correct combinations of the two noise types .    in this paper",
    "we consider a generalization of the quantum hamming bound . for any nondegenerate quantum error - correcting code ,",
    "our generalized bound provides an upper limit on the values @xmath0 such that any error pattern consisting of @xmath1 located errors and @xmath2 unlocated errors can be corrected by the code .",
    "we study a number of aspects of the behaviour of this bound .",
    "we compare the bound to the performance of large concatenated codes , and show that the bound gives a very tight correspondence to the maximum values @xmath0 such that _ most _ patterns of @xmath1 located errors and @xmath2 unlocated errors can be corrected by the code .",
    "that is , the bound appears to predict which located and unlocated error weights are correctable with _ high probability _ by certain codes . despite this",
    ", we show that the bound is in fact quite loose in bounding those error weights that can be corrected with _",
    "certainty _ by a code .",
    "we also consider the behaviour of the bound in the limit of large code size , and show that it reduces to a simple condition relating to the coherent information of the error channel , a quantity that is known to be closely connected to the quantum capacity of a noisy channel .    in the remainder of this introductory section , we briefly review nondegenerate quantum error - correcting codes and the quantum hamming bound .",
    "then in the section that follows , the generalized bound is introduced .",
    "* nondegenerate quantum error - correcting codes and the quantum hamming bound : * a qecc that encodes @xmath3 qubits into @xmath4 qubits is a @xmath5-dimensional subspace of the @xmath6-dimensional state space on @xmath4 qubits . denote this subspace @xmath7 .",
    "a quantum code that corrects @xmath8 unlocated errors is said to be nondegenerate if each of the subspaces @xmath9 are orthogonal to one another , where @xmath10 takes the value of all possible @xmath4-qubit tensor products of pauli operators having weight is the number of non - identity terms in the tensor product . ] at most @xmath8 .",
    "that is , the code can distinguish any correctable pauli error from the others , since it is possible to perform a measurement to determine which of the orthogonal subspaces @xmath9 has been entered . hence , by the result known as the _ discretization of errors _ ( @xcite , sec .",
    "@xmath11 ) , all errors affecting @xmath8 or less qubits ( whether pauli or not ) will be correctable by the code .",
    "the quantum hamming bound @xcite expresses the fact that , since the subspaces @xmath9 are all orthogonal to one another , the sum of the dimensions of the @xmath9 can not exceed the number of dimensions of the entire state space of @xmath4 qubits .",
    "there are @xmath12 distinct @xmath4-qubit tensor products of pauli operators that have weight at most @xmath8 .",
    "the @xmath13 term arises from the fact that at every location there are three non - identity pauli errors that may occur ",
    "@xmath14 , @xmath15 and @xmath16 .",
    "each subspace @xmath9 has dimensionality @xmath5 , and the total state space has dimensionality @xmath6 , and hence the quantum hamming bound is : @xmath17 interestingly , this bound does not make any assumptions about the nature of the encoding or recovery operations .",
    "instead it is based purely on a counting argument .",
    "while the hamming bound does not cover degenerate quantum codes , of which there are many examples , it provides some insight into the behaviour of qecc s in general  to date no quantum codes are known to violate the hamming bound @xcite .",
    "we now modify the quantum hamming bound to accommodate for error patterns which are a combination of unlocated and located errors :    if a nondegenerate code encoding @xmath3 logical qubits into @xmath4 qubits corrects all error patterns consisting of at most @xmath2 unlocated and @xmath1 located errors , then the following generalized quantum hamming bound holds : @xmath18 [ thm : ghb ]    * proof : * assume that @xmath1 located errors have occurred ( and that the location and number of these errors are known to the decoder ) , and that in addition no more than @xmath2 unlocated errors have occurred on the remaining @xmath19 qubits .",
    "the code is nondegenerate , so for reliable decoding to occur the subspaces @xmath9 must be orthogonal to one another , where @xmath10 ranges over all @xmath4-qubit pauli tensor products that have weight at most @xmath2 on the @xmath19 qubits where located errors have not occurred ( and arbitrary weight on the @xmath1 qubits where located errors have occurred ) .",
    "there are @xmath20 such values of @xmath10 .",
    "each subspace @xmath9 has dimension @xmath5 , and the total state - space has dimension @xmath6 , hence eq .",
    "( [ eq : gen_hamm_bound ] ) follows.@xmath21    it is insightful to consider the limiting behavior of this modified bound . in the limit where no located errors have occurred ,",
    "the bound simply reduces to the original quantum hamming bound , as expected . in the opposing limit , where _ only _",
    "located errors occur , the inequality reduces to @xmath22 .",
    "this bound reaffirms the well - known no - cloning limit and represents an intuitive upper bound , it is impossible to perform the transformation @xmath23 , i.e. to make two identical copies of the state . to see how this relates to the number of located errors one can correct for , consider the following .",
    "suppose we encode a single logical qubit into an @xmath4 qubit codeword .",
    "if we divide the codeword in two and give each half to a different party , both parties would be able to reproduce the original codeword if they could correct @xmath24 or more located errors , since they are both missing half their qubits .",
    "thus , for @xmath25 , @xmath26 . for @xmath27 , consider the following .",
    "suppose our encoding operation maps the first @xmath28 logical qubits to the first @xmath28 codeword qubits directly , and the remaining logical qubit to the remaining @xmath29 codeword qubits .",
    "this strategy maximizes our ability to correct errors on the last logical qubit , assuming a unitary encoding operation .",
    "now if @xmath30 we could clone the last logical qubit .",
    "thus , @xmath22 . ] . the bound is shown graphically for some small values of @xmath4 in fig .",
    "[ fig : error_tradeoff ] .     which satisfy the generalized quantum hamming bound , for @xmath31 ( black ) , @xmath32 , @xmath33 , @xmath34 and @xmath35 ( light gray ) codes .",
    "in this section we derive the large-@xmath4 limiting form of the generalized hamming bound , expressed as a function of the error rates @xmath36 and @xmath37 .    from eq .",
    "( [ eq : gen_hamm_bound ] ) it follows that @xmath38 where all terms other than @xmath39 in the sum have been dropped . in the large-@xmath4",
    "limit the @xmath39 term dominates the left hand side of eq .",
    "( [ eq : gen_hamm_bound ] ) , so eq .  ( [ ghb2 ] ) and ( [ eq : gen_hamm_bound ] ) are essentially equivalent in this limit .    taking the logarithm ( base 2 ) of both sides of eq .",
    "( [ ghb2 ] ) , and substituting @xmath40 gives @xmath41    now , stirling s approximation states that for large @xmath42 , @xmath43 using this approximation , eq .",
    "( [ fac_prev ] ) becomes ( after some simplification , and after dividing both sides by @xmath4 ) @xmath44 where @xmath45 , @xmath46 , and @xmath47 .",
    "the variables @xmath48 and @xmath49 can be interpreted as the rate of unlocated errors and located errors respectively .",
    "( the appropriateness of the denominator @xmath19 in the definition of @xmath49 is explained by the fact that if both a located and unlocated error is by coincidence applied to the same qubit then the result is simply a located error ) .",
    "@xmath50 is the information rate of the code ( that is , the average number of encoded qubits transmitted per physical qubit sent through the channel ) .",
    "( [ eq2 ] ) has a particularly simple form when expressed in terms of _ coherent information _ @xcite .",
    "the coherent information is a measure of how well a channel @xmath51 preserves quantum correlations that exist between a system @xmath52 and other auxiliary systems when @xmath52 is sent through @xmath51 .",
    "[ def : ci ] let @xmath53 be the state of some system @xmath52 .",
    "let @xmath54 be an auxiliary system which purifies @xmath53 .",
    "that is , there is some pure joint state @xmath55 of @xmath52 and @xmath54 such that @xmath56 .",
    "say that the channel @xmath51 is applied to system @xmath52 only , resulting in the a joint state @xmath57 on @xmath58 and the reduced state @xmath59 on @xmath52 . by definition ,",
    "the coherent information equals @xmath60 - s[({\\mathcal{e}}\\otimes i ) ( |\\psi\\rangle\\langle \\psi|)],\\ ] ] where @xmath61 $ ] denotes the von neumann entropy .",
    "consider a channel @xmath62 , parameterized by @xmath49 and @xmath48 , that has the following effect on a qubit : with probability @xmath49 an unlocated depolarizing error is applied , and independently with probability @xmath48 a located depolarizing error is applied .",
    "that is , the channel modifies an arbitrary qubit state @xmath10 as follows : @xmath63 where the states @xmath64 and @xmath65 represent the classical signal indicating whether a located error has occurred , and where @xmath66 is the one - qubit identity matrix .",
    "suppose that @xmath10 is equal to one - half of a maximally - entangled qubit pair ( that is , @xmath10 is a maximally mixed state ) .",
    "then it is straightforward to evaluate the two required von neumann entropy values in definition  [ def : ci ] , giving @xmath67 $ ] @xmath68 @xmath69 $ ] and @xmath70 $ ] @xmath68 @xmath71 $ ] , where @xmath72 $ ] denotes the shannon entropy of a probability distribution . by utilizing the formula for shannon entropy ,",
    "one obtains the following expression for the coherent information of the maximally - mixed state sent through the depolarizing channel with unlocated / located error rates @xmath73 : @xmath74 comparing with eq .",
    "( [ eq2 ] ) , we see that the large-@xmath4 limit of the generalized hamming bound can be written succinctly as @xmath75 note that in @xcite a similar relation was found between the asymptotic form of the original quantum hamming bound and the coherent information of a unlocated depolarizing channel .",
    "this indicates that our generalization of the quantum hamming bound is in some sense a natural one .",
    "in this section we give numerical results which show that there exist codes whose performance against combinations of unlocated and located noise is closely governed by the generalized quantum hamming bound .",
    "the codes we consider are created by concatenating the 5 qubit code with itself several times .",
    "these codes are degenerate , and so _ a priori _ do not necessarily satisfy a hamming bound",
    ". however these codes have decoding algorithms that are optimal and efficient @xcite , making them amenable to numerical study .",
    "poulin s method @xcite for efficiently performing the maximum - likelihood decoding and correction of a @xmath76-qubit multiply - concatenated code can be described briefly as follows .",
    "input to the decoder are the _ a priori _ error distributions of each qubit .",
    "that is , for each @xmath77 we have a vector @xmath78 $ ] which represents the probability of each of the four pauli errors affecting qubit @xmath79 .",
    "for example , if the @xmath79-th qubit is known to have experienced a located depolarization error , the @xmath79-th input distribution will equal @xmath80 $ ] , otherwise it will equal @xmath81 $ ] , where @xmath49 is the rate of unlocated depolarization errors .",
    "the decoder consists of @xmath82 `` passes '' . in the first pass , the decoder corrects each of the @xmath83 5-qubit blocks separately . for each 5-qubit block , this step consists of measuring the syndrome @xmath84 of that block with respect to the 5-qubit code , applying a recovery operation @xmath54 which consists of some pattern of pauli operators whose syndrome matches @xmath84 , there are 64 such patterns ; it does nt matter which one is chosen . ] and outputting the posterior error probability distribution @xmath85 $ ] .",
    "the posterior error probability distribution describes the probability that the combined effect of the error pattern and recovery pattern on a given block corresponds to either an encoded @xmath66 , @xmath14 , @xmath15 , or @xmath16 operation on that block .",
    "( the values are straightforward to calculate , given knowledge of the prior distributions @xmath78 $ ] , the recovery @xmath54 , and the stabilizers and logical operators of the code . )",
    "thus , for each of the @xmath83 code blocks we have a distribution over encoded errors . in the second pass , these are reinterpreted as the _ a priori _ error distributions on a series of @xmath83 physical qubits , and the entire procedure above is repeated , giving the distribution of errors on a series of @xmath86 blocks at the next level of decoding . when the procedure has been carried out for @xmath82 passes in total ,",
    "we are left with a distribution over the four possible logical errors of the single @xmath76-qubit code block .",
    "the logical operation with the highest probability is selected , and applied to the state as a recovery operation .",
    "this completes the maximum - likelihood decoding and correction of the input state .",
    "-qubit code .",
    "also shown for comparison is the location of the generalized quantum hamming bound . ]",
    "[ fig : scatter ] shows the results of simulating the above procedure for a range of different located and unlocated error weights , for the @xmath87-qubit code .",
    "the simulation consisted of approximately 20000 trials .",
    "for each trial , the number of unlocated errors ( @xmath2 ) and the number of located errors ( @xmath1 ) were chosen randomly from the entire plot area .",
    "a random pauli error pattern was then chosen , consistent with the chosen values @xmath2 and @xmath1 .",
    "maximum - likelihood syndrome decoding was then performed , and a point was plotted on the figure whenever the decoding failed .",
    "the results show that the weights of the uncorrectable errors form a region that very closely resembles the generalized quantum hamming bound .",
    "similar results ( not shown ) were achieved with a multiply - concatenated @xmath88 qubit code .    however",
    ", the results do not imply that the bound is `` tight '' in the usual sense .",
    "this is because the results of fig .",
    "[ fig : scatter ] indicate a different property of the code to that which the quantum hamming bound indicates .",
    "the numerical results show which error weights have some reasonable probability of being uncorrectable . on the other hand , the quantum hamming bound places",
    "a limit on which error weights are correctable with certainty . to illustrate the point , note that there is a simple argument to show that there exists a pauli error pattern having @xmath89 that is uncorrectable by the @xmath90-qubit code .",
    "this point is far inside the hamming bound shown in fig .",
    "[ fig : scatter ] .",
    "however , a randomly chosen @xmath91 error pattern will have an extremely small probability of being uncorrectable , hence it will not be encountered in experiments such as fig .",
    "[ fig : scatter ] .",
    "in @xcite , the following simple general property of qeccs was observed : a qecc can correct all weight-@xmath8 located errors if and only if it can correct all weight-@xmath92 unlocated errors .",
    "this result can be generalized to the following theorem , which in turn provides a way to tighten the generalized quantum hamming bound .",
    "a quantum error - correcting code can correct all patterns of @xmath8 unlocated errors if and only if it can correct all patterns of errors that are a combination of @xmath93 located errors and @xmath94 unlocated errors .",
    "this statement holds for all integers @xmath95 .",
    "[ thmone ]    * proof : * let @xmath82 be a set of @xmath93 locations within the code .",
    "let @xmath96 be the set of all pauli operators that act as the non - identity on at most @xmath94 qubits outside the set @xmath82 ( but with no restriction on how they act on the qubits in the set @xmath82 ) . from the quantum error - correcting conditions ( @xcite , sec .",
    "@xmath97 ) it follows that the code @xmath98 can correct all combinations of @xmath93 located errors and @xmath94 unlocated errors if an only if @xmath99 for some complex numbers @xmath100 , and where @xmath101 projects onto the codespace .",
    "now , clearly the set of products @xmath102 just corresponds to the set @xmath103 , that is the set of pauli operators which act as the non - identity on at most @xmath104 qubits outside the set @xmath82 ( but with no restriction on how they act on the qubits in the set @xmath82 ) .",
    "so , the above condition can be written equivalently as @xmath105 for some complex @xmath106 .",
    "now , each @xmath107 acts as the non - identity on at most @xmath108 qubits .",
    "in fact , the set @xmath103 over all possible @xmath79 and @xmath82 is the entire set of pauli operators that act on at most @xmath92 qubits , which we denote @xmath109 .",
    "then eq .",
    "( [ eq : pep ] ) can be written equivalently as @xmath110 for some complex @xmath111 .",
    "thus , the statement `` a code can correct all patterns of errors that are a combination of @xmath93 located depolarization errors and @xmath94 unlocated depolarization errors '' holds if and only if the condition in eq .",
    "( [ eq : cond ] ) holds .",
    "but eq .  ( [ eq : cond ] )",
    "does not depend on @xmath112 .",
    "thus the different versions of the statement for the various values of @xmath112 are all equivalent to one other ( since they are each equivalent to eq .",
    "( [ eq : cond ] ) ) , including the one where @xmath112 is set to zero .",
    "this completes the proof .",
    "@xmath21    fig .",
    "[ fig : tight ] illustrates how theorem  [ thmone ] can be used to generate a bound which is significantly tighter than the generalized quantum hamming bound , in the case of large codes having an asymptotically zero rate ( that is , @xmath113 , such is the case for large multiply - concatenated codes ) .",
    "no nondegenerate qecc can exist which corrects all errors of a weight corresponding to a point above the dashed line .",
    "if such a code did exist , theorem  [ thmone ] would imply that the same code would break the original quantum hamming bound ( that is , be able to correct a number of unlocated errors corresponding to a point on the @xmath14-axis of fig .  [",
    "fig : tight ] to the right of where the solid line intersects ) , thus giving a contradiction .    , for large rateless codes . ]    the tighter bound can be stated formally as follows :    if a nondegenerate code encoding @xmath3 logical qubits into @xmath4 qubits corrects all error patterns consisting of at most @xmath2 unlocated and @xmath1 located errors , then the following bound holds : @xmath114 [ thm : tighter ]    * proof : * by theorem  [ thmone ] , the code can correct all patterns of @xmath115 unlocated errors .",
    "thus , the quantum hamming bound ( eq .  ( [ ohb ] ) ) applies , with @xmath116 , hence eq .",
    "( [ eq : tighter_bound ] ) .",
    "@xmath21    thus , although it would appear that dimension - counting arguments in the form of the generalized quantum hamming bound can give an accurate indication of the located and unlocated error weights which can be corrected with _ high probability _ by certain codes , in general it provides a poor indication of which error weights can be corrected exactly .",
    "we have derived two versions of a bound on the number of unlocated and located errors correctable by nondegenerate qeccs .",
    "the first was derived using dimension - counting arguments in a direct generalization of the quantum hamming bound .",
    "it was seen to be an accurate prediction of the performance of large concatenated codes against random combinations of located and unlocated errors .",
    "this is likely to extend to most typical large codes , due to the asymptotic connection between the bound and the `` coherent information '' , which in turn is closely related to the performance of `` random hashing '' error - correcting protocols .",
    "a significantly tighter version of the bound was derived by applying the quantum error - correction conditions .",
    "thus , it would appear to be a general feature of qeccs that the set of unlocated and located error weights correctable with certainty differs significantly to the set correctable with high probability .",
    "both forms of the bound show a general `` trade - off '' between a code s ability to simultaneously correct both unlocated and located errors .",
    "however , the trade - off is well - behaved : requiring a code to correct a small number of unlocated errors will only have a small impact of the code s ability to simultaneously correct located errors .",
    "thus , the high sensitivity of the various loss - tolerant protocols to unlocated noise is not likely to be attributable to general properties of qeccs , but rather to particular features of the protocols employed .",
    "rather , we speculate that as a consequence of theorem  [ thmone ] the loss - specific codes such as parity codes @xcite and horticultural codes @xcite will also have high tolerance to unlocated noise , when considered apart from the protocols in whose context they were defined .",
    "we thank tim ralph , bill munro , michael nielsen , alastair kay , and chris dawson for helpful discussions and feedback .",
    "ppr acknowledges support by the australian research council , queensland state government , and the dto - funded u.s .",
    "army research office contract no .",
    "w911nf-05 - 0397 ."
  ],
  "abstract_text": [
    "<S> in a recent study [ rohde et al . , quant - ph/0603130 ( 2006 ) ] of several quantum error correcting protocols designed for tolerance against qubit loss , it was shown that these protocols have the undesirable effect of magnifying the effects of depolarization noise . </S>",
    "<S> this raises the question of which general properties of quantum error - correcting codes might explain such an apparent trade - off between tolerance to located and unlocated error types . </S>",
    "<S> we extend the counting argument behind the well - known quantum hamming bound to derive a bound on the weights of combinations of located and unlocated errors which are correctable by nondegenerate quantum codes . </S>",
    "<S> numerical results show that the bound gives an excellent prediction to which combinations of unlocated and located errors can be corrected _ with high probability _ by certain large degenerate codes . </S>",
    "<S> the numerical results are explained partly by showing that the generalized bound , like the original , is closely connected to the information - theoretic quantity the _ quantum coherent information_. however , we also show that as a measure of the exact performance of quantum codes , our generalized hamming bound is provably far from tight . </S>"
  ]
}