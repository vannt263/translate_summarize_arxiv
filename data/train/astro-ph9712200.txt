{
  "article_text": [
    "many astrophysical projects hinge upon assigning importance to overdense regions in a set of points .",
    "examples include identifying collapsed halos in a cosmological simulation , determining whether two galaxies have merged , finding clusters of galaxies in a survey , or locating dwarf galaxies in star counts .",
    "because the objects represented by the groups of close points often have fuzzy edges that may overlap with other groups , there is no perfect algorithmic definition of a group ; consequently , the answers to questions posed about the objects may depend upon the way in which membership in the groups was decided .",
    "it is therefore useful to have several different methods available for dividing a set of points into groups of associated particles ; each will have its advantages and drawbacks .    in gravitational n - body simulations",
    ", one wishes to associate the clumps of particles with real - world objects , be they galaxies , dark matter halos , or clusters . while one has full 6-dimensional phase space information , in practice the particles cover phase space too sparsely to provide unambiguous differentiation of groups on the basis of velocity .",
    "hence , as a first cut , it is usual to consider only the spatial information , in which one looks for density enhancements .",
    "we focus here on methods that divide the set of particles into equivalence classes , i.e.  that each particle is a member of one and only one group ; one could imagine alternatives in which particles could belong to a series of nested or overlapping groups or even have their group membership expressed only in a probablistic way",
    ".    some of the more popular group - finding algorithms are friends - of - friends ( davis et al .",
    "1985 ; see barnes & efstathiou 1987 for a generalization ) , denmax ( bertschinger & gelb 1991 ; gelb & bertschinger 1994 ; frederic 1995 ) , and various methods based on the overdensity within spherical regions ( warren et al .  1992",
    "; lacey & cole 1994 ; bond & myers 1996 ) .",
    "because they raise issues related to our method , we will describe the first two of these in more detail .    in the friends - of - friends ( fof ) algorithm ( davis et al .",
    "1985 ) , two particles are part of the same group if their separation is less than some chosen value ; chains of such pairs then define the groups .",
    "the method is therefore coordinate - free and has only one parameter ; moreover , the outer boundary of the groups tend roughly to correspond to a density contour , related to the inverse cube of the linking distance .",
    "unfortunately , some groups found by the method may appear to the eye as two clumps , linked by a small thread of particles running between the subgroups .",
    "this can be harmless for some applications but may be inappropriate for others .",
    "denmax takes a quite different approach , first estimating the density at each point in space and then allowing each particle to determine its group membership by tracing a path along the gradient of this density surface until it reachs a local maximum .",
    "all particles which end up in the same maximum are assigned to the same group .",
    "unfortunately , the resolution with which one defines the density field results in a trade - off between one s ability to recognize smaller groups and one s propensity to split groups due to the discovery of multiple local maxima at finer resolution .",
    "these splittings may be undesirable , and it is difficult to assign physical importance to the way in which low - density particles are assigned into groups on the basis of the details of the locations of multiple local maxima in the high - density regions .",
    "some implementations of denmax ( gelb & bertschinger 1994 ) calculate the densities using a grid , although a more recent version known as skid ( stadel et al .",
    "1997 ; weinberg et al .",
    "1997 ) employs a coordinate - free method .    in this letter",
    ", we describe a new method , dubbed hop , similar in spirit to denmax but rather different in its implementation .",
    "instead of constructing the density gradient field , we confine ourselves to the point set , associate a density to every particle , and replace the concept of the gradient with a simple search for the highest density among a particle s nearest neighbors .",
    "we link each particle to its densest neighbor and then on to that particle s densest neighbor and so on , until we reach a particle which is its own densest neighbor .",
    "all particles that are traced to the same such particle , hereafter called a maximum , constitute a single group . because each  hop \" moves to a higher density particle , this process is guaranteed to converge .",
    "we thus avoid any numerical integration of the density gradient field , with its associated subtlety of a stopping condition ; moreover , the method is coordinate - free and can be spatially adaptive if the scales used to determine the density and the hopping process are tuned to reflect the local density , for example by using a constant number of nearest neighbors .    at this point ,",
    "every particle is assigned to a group ; since we are interested in the high - density regions , we simply remove particles below a given density threshold .",
    "however , one now finds that the method will have split the particles within that particular density contour into several pieces , one for each maximum within .",
    "as this may be undesirable , we reconnect those groups that share a sufficiently dense boundary , using two density thresholds to guard against small fluctuations in a contour splitting a group in two .",
    "finally , we demonstrate that , while the method thus has three integral parameters for near - neighbor searching and three density thresholds to be chosen , in fact the results are insensitive to one s choices for five of these : only the outer density contrast is important for determining group properties .",
    "we wish to divide the particles into distinct sets such that particles in individual high - density regions are grouped together and left separate from those in other regions . to do this , we attempt to distinguish between nearby groups by assigning each particle to the group nucleus that it reaches by following in the direction of increasing density . rather than construct an estimate of the density gradient at any point in space ,",
    "we instead calculate an estimate of the density at every particle position and then determine , of the particle and its nearest @xmath1 neighbors , which of the particles has the highest density .",
    "we next associate each particle with its highest density neighbor and continue hopping to higher and higher densities until we reach a particle that is its own highest density neighbor ( a  maximum \" ) . because one always hops to increasing density , it is impossible to enter a non - convergent loop .",
    "all particles that hop to the same maximum are placed into a group .",
    "every particle is assigned to one and only one group ; hence , we are establishing a set of equivalence classes among the particles .    we assign a density estimate to each particle by using the radial positions of the @xmath2 nearest neighbors of the given particle .",
    "generally , we use the smooth algorithm ( stadel 1995 ) , which calculates the densities from the @xmath2 by a spherically symmetric cubic spline kernel ( monaghan & lattanzio 1985 ) , giving unit weight to particles at zero distance from the given particle and zero weight to those at distances equal to or greater than the radial distance to the @xmath2 nearest neighbor .",
    "we also ran some tests with the simpler prescription that the density is proportional to @xmath3 ( casertano & hut 1985 ) . in either case , the smoothing length for calculating the density automatically adapts to the density itself , becoming smaller in high - density regions .    as such ,",
    "the above algorithm for assigning particles to groups is spatially adaptive , coordinate - free , and involves two parameters , @xmath0 and @xmath2 .",
    "once the densities are found , the group - finding proceeds without the numerical subtleties that denmax must face ; there are no differential equations to solve and the stopping condition is trivial . in general",
    ", quantities other than the density , e.g.  the gravitational potential or the magnitude of the acceleration ( lacey & cole 1994 ) , could be substituted .",
    "the hop algorithm could be useful for other applications besides group finding in large - scale cosmological simulations .",
    "for example , to study the process of galaxy merging , one might set up a series of automated scattering experiments in which each experiment starts off with two galaxies approaching each other with different relative velocities and orientations . during such experiments ,",
    "the hop algorithm could be used to flag the occurrence of a merger , from the fact that the total number of groups has been reduced from two to one .",
    "of course , additional care would have to be taken to check that the merger is permanent , rather than a temporary stage during which the two galaxies pass through each other only to separate again later .",
    "in many cases , we are interested simply in distinguishing dense clumps from less - dense regions and wish to ignore the substructure within highly dense regions . in this case",
    ", the algorithm as it stands has two problems .",
    "first , all particles are assigned to groups , so no distinction between the dense halo and its surroundings has yet been made .",
    "second , because the density is determined adaptively , even highly dense regions may have multiple maxima , causing the group to split into many pieces with unphysical shapes , e.g.  a spherical halo might be cut into sectors . here",
    "we offer solutions to these two problems .    as the density around each particle has already been computed , the obvious solution to the first problem is to only include particles that exceed some density threshold @xmath4 .",
    "as this places us in a position to select groups based on density contours , we address the second problem in the following way .",
    "we adopt two additional density thresholds , @xmath5 and @xmath6 , usually picked so that @xmath7 .",
    "we next define a boundary pair between two groups when a particle and one of its @xmath8 nearest neighbors are in different groups ; the density of the boundary pair is defined to be the average of the densities of the two particles .",
    "we then merge two groups if their densest boundary pair ( which is our equivalent of a saddle point ) exceeds the density @xmath5 .",
    "furthermore , groups whose maximum densities ( i.e. the density of the group maximum ) are less than @xmath6 are disbanded unless they share a boundary pair denser than @xmath4 with a group whose density does exceed @xmath6 ; such groups are attached to the group with which they share the largest boundary pair .",
    "we depict these rules visually in figure 1 .",
    "the intention of the algorithm is that groups consist of central regions whose maximum densities exceed @xmath6 but whose boundaries are defined by contours of a lower density @xmath5 ; the connectivity of the @xmath5 contours near `` pinch points '' is adjudicated via the @xmath8 nearest neighbors .",
    "however , from these centers , the groups extend out to a yet smaller density contour of @xmath4 , with affiliation between rival disjoint interior contours of density @xmath5 being determined by the process of hopping towards increasing density . in the rarer case where that hopping takes one to a density maximum with @xmath9 , the entire subgroup is attached to the viable ( @xmath10 ) group with which it shares the highest density contour .",
    "dealing with these two problems has introduced four new parameters@xmath4 , @xmath5 , @xmath6 , and @xmath8more than one might have wished for .",
    "clearly , the definition of the outer boundary of a group must involve a parameter such as @xmath4 .",
    "we shall demonstrate below that the results of merging are insensitive to the value of @xmath8 .",
    "finally , the possibility of choosing @xmath11 offers the following advantages . simply selecting groups on the basis of a single density contour ( i.e.  @xmath12 ) can produce groups that appear by eye to be multiple groups linked by thin bridges . by allowing @xmath13",
    "one suppresses such groups by splitting them according to the topology of a second , more interior , contour . by using @xmath14 one",
    "effectively blurs out this boundary so that a group can not split in two due to minor fluctuations exactly at the @xmath5 contour .",
    "for example , in figure 1 , if @xmath15 , the group efg would have been split due to a small fluctuation in the contour ; by using @xmath16 , this split is avoided .",
    "the hop method relies heavily on being able to efficiently extract lists of the @xmath17 nearest neighbors for each particle . for this",
    ", we use the tree - based near - neighbor search algorithm made publically available as part of the smooth program ( stadel 1995 ) . to implement hop , we modified their program so as to alter how these lists of neighbors were used .",
    "we make three passes through the data set .",
    "first , we calculate the density around each particle using @xmath2 nearest neighbors .",
    "second , we search for the densest of each particle s @xmath0 nearest neighbors . after tracing each particle to its maximum in order to label the groups ,",
    "we make a third pass with @xmath8 neighbors , compiling the densest boundary pairs between each pair of groups .",
    "we then write as output the densities and group memberships of each particle as well as all the densest boundary pairs",
    ". we can then quickly and repeatedly apply different choices for the density cut ( @xmath4 ) and group merging parameters ( @xmath5 , @xmath6 ) , allowing us to vary these thresholds without rerunning the main code .    for our tests",
    ", we use a single time output of a cold dark matter simulation , kindly provided by guohong xu , renyue cen , and jeremiah ostriker .",
    "the simulation , run with the tree particle mesh ( tpm ) method ( xu 1995 ) , has 16.8 million particles and the non - linear mass scale ( where the top - hat _",
    "rms _ mass fluctuations equal 1.69 ) contains about 12,000 particles .",
    "the hop code runs on this simulation in somewhat under 2 cpu hours on a ultrasparc 170e ( for @xmath18 , @xmath19 ) .",
    "more than half of this time is spent calculating the densities , as this requires the largest number of neighbors to be found .      with six free parameters , it is important to test the sensitivity of the results to changes in these parameters .",
    "as stated above , it is clear that at least one of these parameters , the density threshold used to clip the outer extent of the groups , will make a significant difference .",
    "we will argue , however , that varying the remaining five parameters produces little change in the results .",
    "we adopt as our canonical parameter set @xmath18 , @xmath19 , @xmath20 , @xmath21 , @xmath22 , and @xmath23 , with densities normalized relative to the mean density .",
    "we adopt the notation ( @xmath2@xmath0@xmath8)[@xmath6@xmath5@xmath4 ] to label sets . in figure 2",
    ", we present the fraction of the total mass held in groups per logarithmic interval of group mass ( i.e.  membership number ) .",
    "the effects of varying @xmath0 from 8 to 64 are shown ; the differences are small , but as expected , smaller @xmath0 produce slightly more small groups , while larger @xmath0 cause some of the small groups to be swallowed by larger groups .    in figure 3",
    ", we show the same statistic , but we vary @xmath8 . there is practically no difference between @xmath20 and @xmath25 .",
    "@xmath26 allows slightly more small groups to survive unmerged .    in figure 4",
    ", we show the same statistic while comparing @xmath2 of 64 and 128 .",
    "the most important result here is that groups below the scale @xmath2 tend not to be identified .",
    "presumably clumps of only a few particles either do not achieve sufficient density after smoothing to be included or , if they do get included , get absorbed into larger groups .",
    "also , for @xmath27 , about 4% fewer particles have sufficiently high density @xmath4 ( 80 in this case ) to be in any group ; most of this discrepancy is on the small mass end .",
    "we also show results when estimating the density as the inverse cube of the distance to the 24th nearest neighbor ( i.e.  using a top - hat kernel rather than a cubic spline ) .",
    "this slightly reduces the size of large groups while identifying more small ones .    in figure 5",
    ", we show the same statistic while varying @xmath6 and @xmath5 at fixed @xmath23 .",
    "we set @xmath5 to be @xmath28 . as @xmath6 increases",
    ", group sizes decrease as fringe groups are left unattached to large groups .",
    "also , the total number of particles in groups decreases because more and more groups are disqualified for failing to have a maximum density in excess of @xmath6 .",
    "this is particularly important for the smallest groups , in that it is nearly impossible for a group to have one particle with a density of , say , 800 , while having only 100 particles above a density of 80 .",
    "we prefer @xmath6 to be a small multiple of @xmath4 , perhaps 2 or 3 .    in figure 6",
    ", we show the same statistic , fixing @xmath29 and @xmath23 and letting @xmath5 vary between the two . for @xmath30 ,",
    "the method selects groups as any closed contour of density @xmath4 that achieves a density @xmath6 somewhere within it .",
    "as @xmath5 increases , a group may be subdivided as the region interior to contours of density @xmath5 goes from one connected volume ( at @xmath4 ) to multiple disjoint volumes . at @xmath15",
    "each closed contour of density @xmath6 defines a group center , with the group membership extending out to @xmath4 by hopping .",
    "hence , as @xmath5 increases , groups are broken into pieces , producing fewer large groups and more small groups , as seen in the figure .    in figure 7",
    ", we show the same statistic , varying @xmath6 , @xmath5 , and @xmath4 but keeping the ratio fixed .",
    "we also show the results for two fof groupings , with link lengths of 0.1 and 0.2 in units of the mean particle separation ( denoted fof(0.1 ) , etc . ) . at certain choices of @xmath4 ,",
    "the results of our method produce a rather similar plot to those of fof , suggesting that both algorithms are approximating criteria based on density contours .",
    "as discussed above , the existence of a second density parameter @xmath6 in hop produces slight differences from fof in the case of groups with multiple centers .",
    "also note that the two methods produce very different behavior for groups with fewer than 50 to 100 particles .",
    "in particular , fof finds a very large number of small groups , mostly in the fringes of larger groups ( bond et al .",
    "the shapes of the fof curves in the plot show that this behavior is simply a numerical artifact ",
    "there is no physical effect to provide the upturn at @xmath31 .",
    "this reinforces the lesson that the identification of small groups , even up to dozens of particles , may not be trustworthy when the groups are well below the non - linear mass scale and selected only with the particle position data .",
    "in contrast , hop produces almost no small groups .",
    "of course , this is also a numerical artifact ; since the density is found using the nearest @xmath2 particles , it is difficult for a group to have a maximum density exceeding @xmath6 ( as required to be viable ) and yet have many fewer than @xmath2 particles with density above @xmath4 .",
    "at heart , our method relies on the idea that searching among the nearest @xmath17 particles is an efficient way to collect particles into density maxima . in this sense",
    ", the hop algorithm is an attractive alternative to the usual numerical treatments of integrating the gradient of an interpolated density field . by choosing different means of estimating the density , or even choosing other scalar fields to maximize",
    ", one can imagine a variety of different group - finders .",
    "for example , by estimating the density with a fixed smoothing scale , one would stay more faithful to the original denmax scheme .    in our particular implementation",
    ", we use an adaptive smoothing scale for the density estimates . by avoiding a fixed smoothing length",
    ", we retain sensitivity to smaller groups . however , the resultant small smoothing lengths in high density regions can cause groups to be split into multiple pieces due to the presence of several local maxima in their centers . these pieces generally do not represent true substructure , so we wish to recombine them .",
    "we do this by merging groups that share high - density boundaries .",
    "the two density scales used for this may be chosen to be different from the density contour that defines the outer boundary of the group(s ) , so as to guard against the merging of groups connected only by thin necks . to quantify this",
    ", we consider the ratio of the two largest eigenvalues of the moment of inertia tensor of groups with more than 1000 particles and counted the fraction of such groups with a ratio greater than 2.5 .",
    "we found that 4.6% of fof(0.2 ) groups were this prolate , while for hop with ( @xmath2@xmath0@xmath8 ) = ( 64164 ) and [ @xmath6@xmath5@xmath4 ] = [ 808080 ] , [ 16014080 ] , [ 24020080 ] , and [ 80062080 ] the fractions were 6.6% , 3.1% , 1.8% , and 0.9% respectively .",
    "hence , a ratio of @xmath6 to @xmath4 of 23 substantially reduces the number of extremely prolate objects .",
    "perhaps extensions of fof using the generalization of barnes & efstathiou ( 1987 ) or techniques of minimal spanning trees ( barrow et al .  1985",
    "; bhavsar & splinter 1996 ) could provide other ways to suppress these thin - neck groups .",
    "the hop algorithm has six free parameters ; however , we have demonstrated that the results are quite insensitive to all but one : the choice of outer density contour @xmath4 .",
    "we recommend a default choice of ( 64164)[3@xmath42.5@xmath4@xmath4 ] .",
    "the resulting behavior is rather similar to the friends - of - friends algorithm , but with the advantages that group membership is explicitly based on the smoothed density field rather than pair percolation and that groups prematurely merged by thin necks may be separated by use of a second density threshold .",
    "we thank renyue cen , jeremiah ostriker , and guohong xu for supplying the output of their numerical simulation and joachim stadel and the university of washington s nasa hpcc ess group for making public their very efficient smooth and fof algorithms ( http://www-hpcc.astro.washington.edu/tools ) .",
    "dje was supported by nsf grant phy-9513835 .",
    "the source code for hop is available at http://www.sns.ias.edu/@xmath32eisenste/hop/hop.html .",
    "* figure 1 : * an illustration of the algorithm to merge maxima .",
    "the shaded regions represent areas with density exceeding @xmath6 . the solid heavy contours represent @xmath4 , the dashed heavy contours represent @xmath5 , and light contours represent other values .",
    "maxima a and b are merged into a single group because they lie within a single @xmath5 contour ; c and e are separate groups because they do not share this contour .",
    "the maxima d , f , g , and h can not be group centers because they do not achieve @xmath33 ; they are attached to other groups because they share @xmath4 contours with them .",
    "f , g , and h are attached to e , while d is attached to the a ",
    "b group rather than c because it shares a higher boundary with the former .",
    "the situation with f and g demonstrates the benefit of having @xmath34 ; had they been equal , this small fluctuation in the contour would have split the group .",
    "all groups would be truncated at density @xmath4 , resulting in the three groups enclosed by the solid and dashed - dot heavy contours .",
    "* figure 2 : * plot of the fraction of mass in groups per logarithmic interval of group mass versus the logarithm of the group mass .",
    "our canonical case is @xmath18 , @xmath19 , @xmath20 , @xmath35 , and @xmath23 .",
    "here we show three curves , varying @xmath0 from 8 to 64 .",
    "* figure 7 : * same as figure 2 , but we vary the density cutoffs while holding @xmath38 and @xmath39 . also shown are the results for two choices of friends - of - friends linking parameter @xmath40 , in units of the mean interparticle spacing .",
    "the top pair of curves are @xmath41 and @xmath42 and the bottom pair are @xmath23 and @xmath43 ."
  ],
  "abstract_text": [
    "<S> we describe a new method ( hop ) for identifying groups of particles in n - body simulations . having assigned to every particle an estimate of its local density , we associate each particle with the densest of the @xmath0 particles nearest to it . </S>",
    "<S> repeating this process allows us to trace a path , within the particle set itself , from each particle in the direction of increasing density . </S>",
    "<S> the path ends when it reaches a particle that is its own densest neighbor ; all particles reaching the same such particle are identified as a group . </S>",
    "<S> combined with an adaptive smoothing kernel for finding the densities , this method is spatially adaptive , coordinate - free , and numerically straight - forward . </S>",
    "<S> one can proceed to process the output by truncating groups at a particular density contour and combining groups that share a ( possibly different ) density contour . while the resulting algorithm has several user - chosen parameters , </S>",
    "<S> we show that the results are insensitive to most of these , the exception being the outer density cutoff of the groups . </S>"
  ]
}