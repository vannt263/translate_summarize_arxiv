{
  "article_text": [
    "the fundamental basis of our re - weighting approach is the recognition that a simulation s output ( the configurations generated ) _ contains valuable information that is not conventionally used _ to estimate ensemble averages .",
    "this information is the observed configuration - space density .",
    "it is critical to note that the observed density never matches the targeted distribution ( e.g. , proportional to a boltzmann factor ) because of ( i ) the omnipresent statistical error , and also possibly , ( ii ) errors in the algorithm or software .",
    "our approach can treat both statistical and systematic error because it is blind to the source of error .",
    "standard re - weighting theory assumes that configurations in a simulated ensemble are already distributed according to a known distribution , typically proportional to a boltzmann factor @xcite .",
    "the novelty of our re - weighting method is that _ we treat configurations as if they were generated by an unknown process _ , a `` black box . ''",
    "thus , any ensemble can be treated since the results of the re - weighting do not depend on the specific process that was used to generate the ensemble .",
    "our goal is to estimate ensemble averages and relative weights for configurations @xmath3denoted by @xmath4in the target distribution @xmath5 , regardless of how the configurations were generated . while our approach will be general",
    ", we will assume for concreteness that the target ensemble is a classical system with potential energy @xmath6 .",
    "in this case , the targeted probability density is @xmath7 , where @xmath8 is the configurational partition function at temperature @xmath9 .",
    "because @xmath10 is typically not known , it will prove useful to define the un - normalized distribution @xmath11 the overall partition function @xmath10 will not affect our quest to assign _ relative _ configurational weights .",
    "the sample to be analyzed consists of a set of @xmath12 configurations @xmath13 which may have been generated by an arbitrary simulation protocol .",
    "this set of configurations is distributed according to the _ observed _ probability density @xmath14 , by definition . in general the observed and targeted distributions will differ , @xmath15 , due to statistical and/or systematic error as explained earlier .",
    "it will again prove useful to consider an un - normalized density denoted by @xmath16 .    with the targeted and observed distributions defined , the straightforward logic of standard re - weighting @xcite may be applied .",
    "in an ideal sample , an infinitesimal configuration - space volume @xmath17 about @xmath4 would contain a quantity of configurations proportional to the targeted distribution @xmath18 .",
    "however , in actuality , @xmath19 is obtained .",
    "the erroneous sampling can be corrected to cancel the error , by applying a _ relative _",
    "weight @xmath20 to each configuration . for the physical systems considered here the target distribution",
    "is given exactly by the standard boltzmann factor of eq .  .",
    "we therefore assume @xmath21 is `` known '' in the sense that it can be evaluated for an arbitrary configuration .",
    "then , because eq .   is exact , the key to practical application of this equation is accurate estimation of @xmath22 .",
    "note that the relative weights of eq .   will only be applied to the @xmath12 configurations already generated  and therefore do not report on regions of configuration space not sampled .",
    "ensemble averages of any function @xmath23 , in our approach , are given by a weighted sum over sampled configurations @xmath3 : @xmath24 the average differs from what we term a `` canonical average '' of the same configurations , where one assumes @xmath25 ; then @xmath26 is a constant , and averages reduce to the usual un - weighted estimate @xmath27 @xcite .",
    "note that the proportionality constants for @xmath28 and @xmath29 cancel in and thus do not affect the average .    to see why it is better to re - weight samples when @xmath22 can be estimated well , consider the extreme case of a discrete system with six equi - probable states @xmath30 ( e.g. , a cubic die ) .",
    "of course , all ensemble properties can be calculated by hand , but what if statistical sampling were relied upon ?",
    "assume @xmath31 samples were generated ( either by a biased or unbiased procedure ) , yielding the frequencies @xmath32 , proportional to @xmath33 for @xmath34 , respectively .",
    "clearly , the canonical assumption @xmath35 will lead to substantial errors in ensemble averages .",
    "however , the frequencies of observation will _ exactly cancel _",
    "@xmath22 when the relative weights @xmath36 are used in summing over all 30 `` configurations''to yield exact ensemble averages .",
    "the extension of this simple idea to continuum systems is the subject of this report .",
    "several additional points should be made regarding the strategy embodied in and : ( i ) it is an _",
    "scheme , treating the same set of configurations as might be analyzed canonically ; the approach is not capable of predicting populations for regions of configuration space that are not in the observed ensemble .",
    "( ii ) the observed relative probabilities @xmath37 will _ always _ differ from those intended ( e.g. , canonical boltzmann factors ) due to statistical error  and perhaps significantly .",
    "( iii ) the relative weights are valid regardless of the specific process used to generate configurations .",
    "( iv ) the approach is particularly suited to estimating conformational free energy differences , as described below . ( v ) as in the single histogram approach @xcite , the bbrw method retains the ability to re - weight configurations into an arbitrary target ensemble @xmath21 . ( vi )",
    "the principal practical challenge in implementing our strategy is the estimation of @xmath22 .      to provide a proof of principle for our re - weighting approach we will determine free energy differences ( @xmath38 ) , between states for various test systems @xcite .",
    "a well established canonical technique for determining @xmath38 is to use ordinary simulation methods ( e.g. , molecular dynamics ) to generate an ensemble which is distributed according to the desired distribution @xmath21 .",
    "then , the free energy difference is defined as @xmath39 where @xmath40 is the configurational partition function for state @xmath30 with coordinates given by @xmath41 , and @xmath42 is the number of configurations observed in state @xmath30 .    for our re - weighting approach",
    ", we do not assume that configurations are distributed according to @xmath21 .",
    "instead , each configuration must first be assigned a relative weight using eq .  ; then @xmath38 is estimated based on summing these weights in the respective states : @xmath43 where @xmath44 represents a sum over all relative weights @xmath26 in the state @xmath30 .      the central idea behind",
    "our re - weighting approach is that one can utilize the _ observed _ configuration - space density to re - weight an arbitrary set of configurations into any desired ensemble . because this idea is so fundamental to the present discussion , and apparently novel , it is useful to illustrate the idea using a one - dimensional potential .",
    ", width=188 ]    consider the equal - energy double - square - well system depicted in fig .",
    "[ fig - square ] , for which we would like to estimate the relative populations of the two states .",
    "assume that the barrier is so high that it can not be crossed in a conventional simulation of affordable length , but that we can run independent simulations in each state ( a common situation for biomolecular systems when multiple structures are known ) .",
    "the states widths are in the ratio 1:10 .",
    "after generating , say , equi - sized trajectories in each state , a conventional view would hold that no analysis of the relative populations is possible since the barrier has not been crossed .",
    "however , since the right well is ten times wider than the left , the observed configuration - space density in the right well will be , on average , one - tenth that in the left . combined with knowledge of the two ensemble sizes , this is sufficient information for calculating the state populations .",
    "more explicitly , one can estimate the observed density by counting configurations in equi - sized histogram bins , leading to @xmath45 , where @xmath46 is the count in the bin containing configuration @xmath4 . in this example , @xmath47 for all @xmath4 because the energy is constant over both states .",
    "now , by using eq .   in eq .",
    ", the sum over relative weights leads to _ exact _ cancellation of @xmath48 for each bin .",
    "thus , this purely entropic case is correctly handled , ultimately yielding simply the ratio of the numbers of ( equi - sized ) bins in each state  i.e . , the ratio of state widths",
    "below , we will see that the `` easier '' energetic effects are also treated correctly in less trivial examples .",
    "the key point is that _ the observed density @xmath22 , combined with knowledge of the desired ensemble @xmath21 , provides sufficient information to deduce the state populations , regardless of the sampling bias_. perhaps equally importantly , we note that the density can be estimated in different ways besides binning , e.g. , using configuration - space distances between nearby configurations .",
    "the reasoning used to correct systematic bias can be applied equally to statistical error . assume now that we possess a single continuous trajectory which has crossed the barrier in fig .",
    "[ fig - square ] at least once .",
    "the population estimates will be statistically flawed due to finite sampling . yet",
    ", our re - weighting analysis will still yield correct results since the approach does not depend on the source of the bias in the data .",
    "below we will show that such density information is both present and often accessible in high - dimensional systems .",
    "we emphasize that the information is always present in principle and does not depend on prior knowledge .",
    "how can the observed density be computed in a way that will be useful , even for high - dimensional systems ?",
    "we will explore two distinct strategies : binning and also the use of configuration - space distances ( `` nearest - neighbors strategy '' ) . for high - dimensional systems",
    ", we will demonstrate that not all coordinates need be considered in the analysis .",
    "we emphasize that other strategies for estimating density are possible @xcite .",
    "the test systems chosen for this study are a one - dimensional double - well potential and a 50-atom dileucine peptide ( ace-(leu)@xmath49-nme ) .",
    "our reasoning for choosing these systems are : ( i ) the system sizes are small enough that it is possible to compute an independent @xmath38 estimate via counting , i.e. , using eq .  .",
    "( ii ) both are non - trivial : the one - dimensional potential has high barrier , and dileucine has large side chains and thus 144 degrees of freedom .      in the simplest use of bins ,",
    "the observed density is estimated based on simple counting : omitting normalization , @xmath50 , where @xmath46 is the number of configurations in the bin which includes configuration @xmath4 .",
    "indeed we have tried this scheme and it works , but not optimally .",
    "a more effective procedure for weighting individual configurations combines simple counting with the assumption of local equilibration : within bins , configurations are assumed distributed according to @xmath21 itself .",
    "this assumption could correspond to the case where separate canonical simulations have been performed in different regions of configuration space , or to a canonical simulation which was not equilibrated on long time scales but well - sampled locally .",
    "the local - equilibration estimate for the observed distribution is @xmath51 which implies @xmath52 .",
    "the bin - specific normalization is the average relative target probability in the bin , namely , @xmath53 .",
    "this normalization serves to keep the total observed probability of a bin proportional to the number of counts , and independent of the local boltzmann factors .",
    "as explained in the supplementary material , a consequence of adopting the approximation , is that @xmath54 is implicitly assumed proportional to the _ local _ partition function for the bin containing configuration @xmath4 .",
    "( each bin has a different local partition function estimate . ) nevertheless , we emphasize that the use of local partition functions is not intrinsic to the black - box approach , but only to binning methods for estimating @xmath22 : see , for instance , the nearest - neighbor strategy described below .",
    "independent computations . the canonical estimates ( squares ) are given by eq .  , the black - box estimates ( circles ) by eq .  .",
    "an independent estimate , obtained via integration , is shown by the solid horizontal line .",
    "( c ) the standard deviation from the same data as that for figure ( b ) is plotted showing the rapid decrease in the standard deviation for our method ( circles ) as compared to canonical ( squares ) .",
    "( d ) estimate of the ratio of partition functions using our re - weighting approach via eq .  , based on a heavily biased ensemble of configurations .",
    "note that canonical estimation using eq .",
    "is not possible .",
    "[ fig-1d ] , title=\"fig:\",height=113 ]   independent computations",
    ". the canonical estimates ( squares ) are given by eq .",
    ", the black - box estimates ( circles ) by eq .  . an independent estimate , obtained via integration , is shown by the solid horizontal line . ( c )",
    "the standard deviation from the same data as that for figure ( b ) is plotted showing the rapid decrease in the standard deviation for our method ( circles ) as compared to canonical ( squares ) .",
    "( d ) estimate of the ratio of partition functions using our re - weighting approach via eq .",
    ", based on a heavily biased ensemble of configurations . note that canonical estimation using eq .",
    "is not possible .",
    "[ fig-1d ] , title=\"fig:\",height=113 ]    independent computations",
    ". the canonical estimates ( squares ) are given by eq .",
    ", the black - box estimates ( circles ) by eq .  . an independent estimate , obtained via integration , is shown by the solid horizontal line .",
    "( c ) the standard deviation from the same data as that for figure ( b ) is plotted showing the rapid decrease in the standard deviation for our method ( circles ) as compared to canonical ( squares ) .",
    "( d ) estimate of the ratio of partition functions using our re - weighting approach via eq .",
    ", based on a heavily biased ensemble of configurations . note that canonical estimation using eq .",
    "is not possible .",
    "[ fig-1d ] , title=\"fig:\",height=113 ]   independent computations",
    ". the canonical estimates ( squares ) are given by eq .",
    ", the black - box estimates ( circles ) by eq .  . an independent estimate , obtained via integration , is shown by the solid horizontal line . ( c )",
    "the standard deviation from the same data as that for figure ( b ) is plotted showing the rapid decrease in the standard deviation for our method ( circles ) as compared to canonical ( squares ) .",
    "( d ) estimate of the ratio of partition functions using our re - weighting approach via eq .",
    ", based on a heavily biased ensemble of configurations . note that canonical estimation using eq .",
    "is not possible .",
    "[ fig-1d ] , title=\"fig:\",height=113 ]    _ one - dimensional double - well potential . _ here we consider the smooth potential of fig .",
    "[ fig-1d]a .",
    "the relative target probability is defined by @xmath55 , where @xmath56 is the potential energy sketched for the approximately 6 @xmath57 barrier height used here .",
    "the barrier heights for this potential , as well as basin curvatures and separations , are fully adjustable , using , @xmath58 $ ] , where we have used @xmath59 , @xmath60 , @xmath61 , and @xmath62 .",
    "we estimated the ratio of partition functions for the two wells ( right over left ) using data obtained from ordinary canonical simulation , i.e. , metropolis monte carlo ( mc ) @xcite .    fig .  [ fig-1d ] shows the differences between re - weighting , using a binning strategy , and canonical estimates of the ratio of partition functions between two wells ( right over left ) in ( a ) .",
    "results shown are the averages ( b ) and standard deviations ( c ) from @xmath63 independent computations .",
    "the canonical estimates ( squares ) were computed via , and the black - box estimates ( circles ) via eqs .   and with a bin size of 0.005 .",
    "_ all data were generated using the same mc trajectories , _ each initiated from the left basin of the potential in ( a ) .",
    "specifically , all mc trajectories were generated by starting the system at @xmath64 .",
    "each trajectory consisted of @xmath65 trial moves generated by adding a uniform random deviate between -1.0 and 1.0 to the current position .",
    "an independent estimate , obtained via numerical integration , is shown by the solid horizontal line in ( b ) .",
    "note that in ( b ) the apparent accuracy of canonical estimation at short times represents only the average behavior ; the statistical uncertainty is so large that any individual estimate would be completely unreliable .",
    "figure [ fig-1d]c demonstrates that the error in our re - weighting analysis decreases at a rate greater than the typical square - root behavior , as seen for the canonical error . since the same ensembles were used for both the re - weighting and canonical estimates , this improvement may lead one to believe we are getting something for nothing . in fact , there are costs , but in essence , they have already been paid : ( i ) the re - weighting approach requires knowledge of the desired distribution ; in our case ( and most other cases of interest ) this is given by the boltzmann factor .",
    "( ii ) the observed density is available information that is not generally used for analysis of simulation data , and requires only a small additional computational cost .    in fig .",
    "[ fig-1d]d we show that our re - weighting approach can be used to estimate the correct populations between the left and right wells , with _",
    "an example that simply can not be treated canonically .",
    "_ we generated a biased ensemble , with configurations that were _ not _ distributed according to @xmath21 ( boltzmann factor for @xmath66 shown in ( a ) ) .",
    ".   and were used with a bin size of 0.005 to estimate the ratio of partition functions .",
    "the data show the averages ( circles ) and standard deviations ( error bars ) for @xmath63 independent computations .",
    "since our re - weighting approach is independent of the method used to generate the ensemble , we are able to obtain the correct ratio , even though the ensemble used in the analysis was heavily biased . for completeness , we note that the biased ensemble configurations were generated using the same mc protocol as above , but with a square well potential defined as @xmath67 between @xmath68 and @xmath69 and infinite elsewhere .    _ dileucine peptide . _ in this high - dimensional molecular example , we again apply our approach to a biased ensemble , where canonical estimation would be meaningless .",
    "we use the method to estimate the free energy difference @xmath38 between conformational states of the 50-atom dileucine peptide based on independent simulations of each state .",
    "the two states considered were defined by backbone dihedrals angles``alpha '' : @xmath70 ; and , `` beta '' : @xmath71 .     and @xmath72 .",
    "the independent estimate is shown by the solid horizontal line with an approximate error determined by block averaging @xcite .",
    "( b ) box - counting analysis of dileucine configurations used to determine the range of bin sizes for figure ( a ) .",
    "[ fig - bin ] , title=\"fig:\",height=132 ]   and @xmath72 .",
    "the independent estimate is shown by the solid horizontal line with an approximate error determined by block averaging @xcite .",
    "( b ) box - counting analysis of dileucine configurations used to determine the range of bin sizes for figure ( a ) .",
    "[ fig - bin ] , title=\"fig:\",height=132 ]    to test the accuracy of the results from our re - weighting approach , we also generated an independent estimate of @xmath38 .",
    "an ordinary , unrestrained , 1.0 @xmath73s simulation was performed and analyzed via eq .  , yielding @xmath74 kcal / mol , with statistical error estimated via block averaging @xcite .",
    "the simulation data were generated using tinker 4.2 with the opls - aa forcefield @xcite .",
    "a 1.0 fs timestep was utilized , and the simulation was coupled to a 300.0 k bath using the andersen thermostat @xcite .",
    "solvation was provided by the generalized born surface area ( gbsa ) implicit model @xcite .    to generate a bbrw estimate based on the locally equilibrated scheme of eq .",
    ", simulations of dileucine were performed constrained to either the alpha or beta state .",
    "we generated 500,000 configurations in each state based on a total of @xmath75104 ns . bins used in were constructed uniformly using only the four backbone dihedrals  out of 144 degrees of freedom  leading to a four - dimensional histogram .",
    "note that empty bins , which are expected for physical and statistical reasons , simply do not contribute to averages computed via eq .",
    ", since only sampled configurations are summed over .",
    "figure [ fig - bin]a shows that our re - weighting approach can be used to correctly predict the free energy difference between the alpha and beta states of dileucine .",
    "the solid horizontal line is the independent estimate @xmath76 computed via eq .   with an approximate error determined by block averaging @xcite .",
    "the circles are results from our re - weighting method using the backbone dihedral angles @xmath77 and @xmath72 .",
    "these data were computed using eqs .  , , and , and plotted as a function of the number of bins used per dihedral angle in the histograms . even though an equal number of alpha and beta configurations were utilized in our analysis , the ratio of @xmath78 is recovered .",
    "note that our strategy , as shown here , is an example of an end - point free energy difference method , since no path connecting alpha and beta is needed ( e.g. , refs .",
    "@xcite ) .",
    "[ fig - bin]a also demonstrates a certain robustness in the approach : there is a broad range of bin sizes that can be used generate the correct free energy difference .",
    "two criteria were used to determine the range of bin sizes used for the re - weighting results in fig .",
    "[ fig - bin]a : ( i ) the range of bin sizes for accurate @xmath38 estimation apparently corresponds to the power - law regime of a plot for estimating the box counting dimension @xcite .",
    "this plot is shown in fig .",
    "[ fig - bin]b where the linear regions denote the power - law behavior .",
    "( ii ) the extreme bin size results are known exactly .",
    "if one bin per dihedral angle is chosen , then the estimate will always be poor and @xmath79 ( for equi - sized ensembles ) . at the other extreme ,",
    "if a very large number of bins per dihedral angle is used , then each bin will have a count of 1 , and @xmath80 for every structure . since no true density information is obtained near either extreme , we excluded such estimates .",
    "in addition to the binning implementation above , we now estimate @xmath22 of eq .   by computing distances between conformations .",
    "the motivation behind pursuing such non - binning approaches is the realization that for biomolecular systems , it may prove difficult to populate the necessary high - dimensional histogram bins . the number of bins will increase exponentially with the number of coordinates , but the density of sampling in configuration space can always be estimated based on `` distances '' in configuration space .    in general , to implement the nearest - neighbors strategy @xcite , the distances between all configurations in the ensemble are computed , using any metric which preserves the cartesian volumes intrinsic to partition functions . by definition , the dimensionality of the metric can be as large as the number of degrees of freedom needed to describe a conformation .",
    "the observed configuration - space ( relative ) density for structure @xmath4 is then given by @xmath81 which implies @xmath82 . here , @xmath83 is the radius of the hypersphere centered on structure @xmath4 enclosing @xmath84 structures , and @xmath85 is the dimensionality of the distance metric used .",
    "typically , as we will demonstrate below , @xmath85 can be chosen to be much smaller than the dimensionality of the system .",
    "see supplementary material for further discussion of the approximations entailed when @xmath85 is less than the full dimensionality of the system .",
    "we used eq .   to estimate @xmath22 for",
    "a particular structure @xmath4 using the following implementation : ( i ) compute the distance ( using any appropriate metric ) between structure @xmath4 and all other structures in the ensemble .",
    "( ii ) choose a value of @xmath86 .",
    "the radius of the hypersphere @xmath87 is given by the distance to the @xmath86 nearest neighbor .",
    "for example , if @xmath88 is chosen , then @xmath87 is given by the distance to the tenth nearest neighbor .",
    "_ dileucine peptide .",
    "_ we tested the approach embodied in eq .   by estimating the free energy difference ( @xmath38 ) between the alpha and beta conformations of dileucine , using the same restrained ( thus biased ) ensemble that was used above . following the previous success of using only the torsion angles of dileucine , we chose to use a dihedral angle distance between structures @xmath4 and @xmath89 defined by @xmath90 where @xmath91 could be any dihedral angle ( e.g. , @xmath92 ) , and",
    "@xmath85 is the number of angles used in the computation , i.e. , the metric dimension .",
    "figure [ fig - nobin ] shows that our re - weighting approach , using the nearest - neighbors strategy , can be used to predict the free energy difference between the alpha and beta states of dileucine .",
    "the solid horizontal line is the independent estimate @xmath76 computed via eq .   with an approximate error determined by block",
    "averaging @xcite .",
    "the circles are results from our re - weighting method using the backbone dihedral angles @xmath77 and @xmath72 .",
    "these data were computed using eqs .  , , and , with distances given by eq .  .",
    "the results are plotted as a function of the number of neighbors used in the analysis procedure , @xmath86 . even though an equal number of alpha and beta configurations were utilized in our analysis ,",
    "the ratio of @xmath78 is again recovered .    ) between the alpha and beta states of dileucine from a nearest - neighbors strategy .",
    "results from our re - weighting approach using a heavily biased ensembles are shown .",
    "data were generated using eqs .",
    ", and , with distances computed via eq .  .",
    "the analysis used only the backbone dihedrals @xmath77 and @xmath72 .",
    "data are given as a function of the number of distances ( neighbors ) used in the analysis .",
    "the independent estimate is shown by the solid horizontal line with an approximate error determined by block averaging @xcite .",
    "[ fig - nobin ] , height=132 ]    the accuracy of the nearest - neighbors strategy ( or at least the way we implemented the idea ) is lower than that of the binning approach ; see fig .",
    "[ fig - bin]a .",
    "however , the results in fig .  [ fig - nobin ] are encouraging , and demonstrate that it is possible to estimate @xmath22 using a non - binning procedure .",
    "it is worthwhile to briefly discuss the efficiency of the re - weighting approach using eq .",
    "compared with that of using eq .  .",
    "there are , in general , two extreme cases to consider : ( i ) the barrier between the states of interest is very low .",
    "this implies that barrier crossing events occur frequently , and thus counting via eq",
    ".   will likely be the most efficient approach .",
    "( ii ) the barrier between the states is too high to cross during ordinary simulation . in this case , counting via eq .",
    "is not possible .",
    "importantly however , the re - weighting approach of eq .   can still be utilized since all that is required are independent simulations in each state .",
    "the fairly lengthy simulations required for the bbrw method in the case of dileucine reflects the choice of state definitions : _ within each state _ ,",
    "i.e. , alpha or beta , the rotameric ( side - chain ) timescales are substantially longer than those of the backbone torsions .      with dileucine we were able to obtain accurate results for @xmath22 , and thus @xmath38 , using only 4 degrees of freedom  out of a possible 144 .",
    "the underlying assumption is that the the degrees of freedom not included in the analysis will provide the same contribution to each relative weight ( see supplementary material for details ) .",
    "thus , at a minimum , the coordinates used to define the states of interest must be included in the re - weighting analysis ( here , the backbone dihedrals @xmath77 and @xmath72 ) .    a particularly promising strategy for the future is to use principal components analysis , or related methods , to suggest an optimal reduced set of coordinates @xcite .",
    "these collective coordinates can then be used for binning or to determine configuration - space distances for the nearest - neighbor approach .",
    "the black - box re - weighting ( bbrw ) strategy computes ensemble averages for any target distribution based on estimating the observed configuration - space density actually sampled in a simulation  without employing typical assumptions about sampling quality . in principle",
    ", the approach can be used to re - weight any ensemble , regardless of the process used to generate the configurations .",
    "our data show that using bbrw can dramatically reduce both systematic and statistical error for some systems .    as a proof of principle",
    ", we used the approach to estimate free energy differences ( @xmath38 ) for non - overlapping states of one - dimensional and molecular systems , based on completely independent ensembles generated in each state .",
    "further , when ordinary one - dimensional trajectories exhibiting transitions between states were re - analyzed with bbrw , statistical error was substantially reduced .",
    "practical application of bbrw hinges on estimation of the observed configuration - space density , @xmath22 , but the theoretical basis does not .",
    "we have obtained reasonable results using two different methods for estimating @xmath22 , emphasizing that _ the central idea behind our re - weighting approach is independent of the specific strategy used to estimate @xmath22_. strategies beyond those examined in this report are available @xcite and will be explored in future work .",
    "there are two primary limitations of the overall approach .",
    "first , improved density estimation schemes will be needed for higher dimensional systems .",
    "second , bbrw is an _ analysis _",
    "method that re - weights configurations in _ existing _ ensembles ; thus , it can not predict populations for regions of configuration space not represented in the original data .",
    "our motivation for the black - box approach stems from the still - outstanding challenge of producing statistical ensembles for full - sized proteins .",
    "the black - box approach seems promising in this context because : ( i ) non - boltzmann - distributed sets of diverse structures can be generated using a variety of methods , including nmr structure prediction software @xcite , and by the addition of atomic detail to coarse models @xcite .",
    "( ii ) local canonical sampling based on _ ad hoc _ starting structures is readily possible with existing software .",
    "( iii ) our own box - counting studies of proteins ( unpublished ) suggest that folded proteins act as systems with dramatically reduced dimensionality ; see also @xcite .",
    "we also hope that bbrw will prove useful in re - weighting implicitly solvated biomolecules into explicit solvent ensembles .",
    "finally , the idea could prove of value in the analysis of data from insufficiently converged canonical simulation of any type .",
    "we thank edward lyman , robert swendsen , and david zuckerman for very helpful discussions .",
    "funding was provided by the idaho epscor , by nih grants gm076569 , ca078039 , and fellowship gm073517 , as well as by nsf grant mcb-0643456 ."
  ],
  "abstract_text": [
    "<S> there is a great need for improved statistical sampling in a range of physical , chemical and biological systems . </S>",
    "<S> even simulations based on correct algorithms suffer from statistical error , which can be substantial or even dominant when slow processes are involved . </S>",
    "<S> further , in key biomolecular applications , such as the determination of protein structures from nmr data , non - boltzmann - distributed ensembles are generated . we therefore have developed the `` black - box '' strategy for re - weighting a set of configurations _ generated by arbitrary means _ to produce an ensemble distributed according to any target distribution . </S>",
    "<S> in contrast to previous algorithmic efforts , the black - box approach exploits the configuration - space density _ observed _ in a simulation , rather than assuming a desired distribution has been generated . </S>",
    "<S> successful implementations of the strategy , which reduce both statistical error and bias , are developed for a one - dimensional system , and a 50-atom peptide , for which the correct 250-to-1 population ratio is recovered from a heavily biased ensemble .    </S>",
    "<S> ensemble averages over configurations are fundamental to the analysis of finite - temperature systems of physical , chemical , and biological interest , as well as to any statistically defined system . </S>",
    "<S> yet it is well appreciated that estimates of such averages based on computer simulations can suffer from both systematic and statistical error @xcite . </S>",
    "<S> we therefore ask : _ given a set of previously generated configurations of uncertain quality , what is the best way to estimate ensemble averages ? _ our proposed answer , the `` black - box re - weighting '' ( bbrw ) strategy described below , appears promising in its ability to overcome both types of error in some systems .    </S>",
    "<S> statistical error is a ubiquitous problem of under - appreciated practical importance . </S>",
    "<S> every algorithm known to the authors , including sophisticated methods @xcite , relies on repeated visits to a state ( a subset of configuration space ) in order to generate statistical reliability or precision in the population estimate for that state . </S>",
    "<S> if we define the simulation - and - system - specific correlation time @xmath0 as the time required to visit all important states at least once , then statistical precision requires a long total simulation time , @xmath1 . </S>",
    "<S> standard square - root - of - duration arguments @xcite suggest that a simulation retains a fractional imprecision of @xmath2 ( on a unit scale ) . </S>",
    "<S> below , we show that bbrw dramatically cuts statistical error , avoiding the slow square - root behavior .    </S>",
    "<S> systematic bias is typical in some systems of great practical importance  such as full - sized proteins  where , to date , it is not clear that any atomically detailed simulation has come close to reaching @xmath0 . indeed , </S>",
    "<S> surprisingly lengthy simulations are required to obtain statistical ensembles for small peptides @xcite . </S>",
    "<S> nevertheless , biased non - boltzmann distributed sets of atomically detailed protein structures _ are _ regularly generated , e.g. , for nmr structure determination @xcite and in the study of protein folding @xcite . </S>",
    "<S> these sets can be useful for docking @xcite , which is employed in drug design . </S>",
    "<S> the proposed bbrw strategy , in principle , can convert such sets into statistically distributed ensembles . </S>"
  ]
}