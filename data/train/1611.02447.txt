{
  "article_text": [
    "recognition of human actions from rgb - d ( red , green , blue and depth ) data has attracted increasing attention in multimedia signal processing in recent years due to the advantages of depth information over conventional rgb video , e.g. being insensitive to illumination changes . since the first work of such a type  @xcite reported in 2010 , many methods",
    "@xcite have been proposed based on specific hand - crafted feature descriptors extracted from depth . with the recent development of deep learning ,",
    "a few methods  @xcite have been developed based on convolutional neural networks ( convnets ) . a common and intuitive method to represent human motion",
    "is to use a sequence of skeletons . with the development of the cost - effective depth cameras and algorithms for real - time pose estimation  @xcite ,",
    "skeleton extraction has become more robust and many hand - designed skeleton features  @xcite for action recognition have been proposed .",
    "recently , recurrent neural networks ( rnns )  @xcite have also been adopted for action recognition from skeleton data .",
    "the hand - crafted features are always shallow and dataset - dependent .",
    "rnns tend to overemphasize the temporal information especially when the training data is not sufficient , leading to overfitting . in this paper , we present a compact , effective yet simple method that encodes the joint trajectories into texture images , referred to as joint trajectory maps ( jtm ) , as the input of convnets for action recognition . in this way , the capability of the convnets in learning discriminative features can be fully exploited  @xcite .",
    "one of the challenges in action recognition is how to properly model and use the spatio - temporal information .",
    "the commonly used bag - of - words model tends to overemphasize the spatial information . on the other hand , hidden markov model ( hmm ) or rnn",
    "based methods are likely to overstress the temporal information .",
    "the proposed method addresses this challenge in a different way by encoding as much the spatio - temporal information as possible ( without a need to decide which one is important and how important it is ) into images and letting the cnns to learn the discriminative one .",
    "this is the key reason that the proposed method outperformed previous ones .",
    "in addition , the proposed encoding method can be extended to online recognition due to the accumulative nature of the encoding process .",
    "furthermore , such encoding of spatio - temporal information into images allows us to leverage the advanced methods developed for image recognition .",
    "the proposed method consists of two major components , as illustrated in fig .",
    "[ fig : framework ] , three convnets and the construction of three jtms as the input of the convnets in three orthogonal planes from the skeleton sequences .",
    "final classification of a given test skeleton sequence is obtained through a late fusion of the three convnets .",
    "the main contribution of this paper is on the construction of suitable jtms for the convnets to learn discriminative features .",
    "we argue that an effective jtm should have the following properties to keep sufficient spatial - temporal information of an action :    * the joints or group of joints should be distinct in the jtm such that the spatial information of the joints is well reserved .",
    "* the jtm should encode effectively the temporal evolution , i.e. trajectories of the joints , including the direction and speed of joint motions .",
    "* the jtm should be able to encode the difference in motion among the different joints or parts of the body to reflect how the joints are synchronized during the action .",
    "specifically , jtm can be recursively defined as follows @xmath2 where @xmath3 is a function encoding the spatial - temporal information at frame or time - stamp @xmath4 . since jtm is accumulated over the period of an action",
    ", @xmath3 has to be carefully defined such that the jtm for an action sample has the required properties and the accumulation over time has little adverse impact on the spatial - temporal information encoded in the jtm .",
    "we propose in this paper to use hue , saturation and brightness to encode the spatial - temporal motion patterns .",
    "assume an action @xmath5 has @xmath6 frames of skeletons and each skeleton consists of @xmath7 joints .",
    "the skeleton sequence is denoted as @xmath8 , where @xmath9 is a vector of the joint coordinates at frame @xmath4 , and @xmath10 is the @xmath0 coordinates of the @xmath11th joint in frame @xmath4 .",
    "the skeleton trajectory @xmath12 for an action of @xmath6 frames consists of the trajectories of all joints and is defined as : @xmath13 where @xmath14 and the @xmath15th joint trajectory is @xmath16 . at this stage ,",
    "the function @xmath3 is the same as @xmath17 , that is , @xmath18    the skeleton trajectory is projected to the three orthogonal planes , i.e. three cartesian planes , to form three jtms .",
    "[ fig1 ] shows the three projected trajectories of the right hand joint for action ",
    "right hand draw circle ( clockwise ) \" in the utd - mhad dataset . from these jtms",
    ", it can be seen that the spatial information of this joint is preserved but the direction of the motion is lost .      to capture the motion information in the jtm",
    ", it is proposed to use hue to represent the motion direction .",
    "different kinds of colormaps can be chosen . in this paper , the jet colormap , ranging from blue to red , and passing through the colors cyan , yellow , and orange , was adopted .",
    "assume the color of a joint trajectory is @xmath19 and the length of the trajectory @xmath20 , and let @xmath21 be the color at position @xmath22 .",
    "for the @xmath23 trajectory @xmath24 from @xmath25 to @xmath26 , a color @xmath27 , where @xmath28 is specified to the joint trajectory , making different trajectories have their own color corresponding to their temporal positions in the sequence as illustrated in fig .",
    "herein , the trajectory with color is denoted as @xmath29 and the function @xmath3 is updated to : @xmath30 this ensures that different actions are encoded to a same length colormap .",
    "the effects can be seen in fig .",
    "[ fig3 ] , sub - figures ( 1 ) to ( 2 ) . even though the same actions with different number of cycles will be encoded into different color shapes",
    ", the direction can still be reflected in color variation and the differences between actions can still be captured due to the different spatial information .      to distinguish different body parts ,",
    "multiple colormaps are employed .",
    "there are many ways to achieve this .",
    "for example , each joint is assigned to one colormap , or several groups of joints are assigned to different colormaps randomly .",
    "considering arms and legs often have more motion than other body parts , we empirically generate three colormaps ( @xmath31 ) to encode three body parts .",
    "@xmath32 is used for the left body part ( consisting of left shoulder , left elbow , left wrist , left hand , left hip , left knee , left ankle and left foot ) , @xmath33 for the right body part ( consisting of right shoulder , right elbow , right wrist , right hand , right hip , right knee , right ankle and right foot ) , and @xmath34 for the middle body part ( consisting of head , neck , torso and hip center ) .",
    "@xmath32 is the same as @xmath19 , i.e. the jet colormap , @xmath33 is a reversed colormap of @xmath32 , and @xmath34 is a colormap ranging from light gray to black . here , the trajectory encoded by multiple colormaps is denoted as @xmath35 , and the function @xmath3 is formulated as : @xmath36 the effects can be seen in fig .",
    "[ fig3 ] , sub - figures ( 2 ) to ( 3 ) .",
    "motion magnitude is one of the most important factors in human motion . for one action ,",
    "large magnitude of motion usually indicates more motion information . in this paper , it is proposed to encode the motion magnitude of joints into the saturation and brightness components , so that such encoding not only encodes the motion but also enriches the texture of trajectories which are expected to be beneficial for convnets to learn discriminative features . for joints with high motion magnitude or speed",
    ", high saturation will be assigned as high motion usually carries more discriminative information .",
    "specifically , the saturation is set to range from @xmath37 to @xmath38 .",
    "given a trajectory , its saturation @xmath39 in @xmath40 color space could be calculated as @xmath41 where @xmath42 is the @xmath11th joint speed at the @xmath4th frame . @xmath43",
    "the trajectory adjusted by saturation is denoted as @xmath44 and the function @xmath3 is refined as : @xmath45 the encoding effect can be seen in figure  [ fig3 ] , sub - figures ( 3 ) to ( 4 ) , where the slow motion becomes diluted ( e.g. trajectory of knees and ankles ) while the fast motion becomes saturated ( e.g. the green part of the circle ) .    to further enhance the motion patterns in the jtm",
    ", the brightness is modulated by the speed of joints so that motion information is enhance in the jtm by rapidly changing the brightness according to the joint speed . in particular , the brightness is set to range from @xmath46 to @xmath47 . given a trajectory @xmath48 whose speed is @xmath42 , its brightness @xmath49 in the @xmath40 color space is calculated as @xmath50 the trajectory adjusted by brightness is denoted as @xmath51 and the function @xmath3 is updated to : @xmath52 the effect can be seen in fig  [ fig3 ] , sub - figures ( 3 ) to ( 5 ) , where texture becomes apparent ( e.g. the yellow parts of the circle ) . finally , motion magnitude is encoded with saturation and brightness together .",
    "the trajectory is denoted as @xmath53 and the function @xmath3 is refined as : @xmath54 as illustrated in fig .",
    "[ fig3 ] , sub - figures(3 ) to ( 6 ) , it not only enriches the texture information but also highlights the faster motion .      in the experiments , the layer configuration of the three convnets was same as the one in  @xcite .",
    "the implementation was derived from the publicly available caffe toolbox @xcite based on one nvidia geforce gtx titan x card and the pre - trained models over imagenet  @xcite were used for initialization in training .",
    "the network weights are learned using the mini - batch stochastic gradient descent with the momentum being set to 0.9 and weight decay being set to 0.0005 . at each iteration",
    ", a mini - batch of 256 samples is constructed by sampling 256 shuffled training jtms .",
    "all jtms are resized to 256 @xmath55 256 .",
    "the learning rate is to @xmath56 for fine - tuning and then it is decreased according to a fixed schedule , which is kept the same for all training sets . for each convnet",
    "the training undergoes 100 cycles and the learning rate decreases every 20 cycles . for all experiments ,",
    "the dropout regularisation ratio was set to 0.5 in order to reduce complex co - adaptations of neurons in nets .",
    "three convnets are trained on the jtms in the three cartesian planes and the final score for a test sample are the averages of the outputs from the three convnets .",
    "the testing process can easily achieved real - time speed ( average 0.36 seconds / sample ) .",
    "the proposed method was evaluated on three public benchmark datasets : msrc-12 kinect gesture dataset  @xcite , g3d  @xcite and utd - mhad  @xcite .",
    "experiments were conducted to evaluate the effectiveness of each encoding scheme in the proposed method and the final results were compared with the state - of - the - art reported on the same datasets . in all experiments , the saturation and brightness covers the full range ( from 0% @xmath57 100% mapped to 0 @xmath57 255 ) in hsv color space .",
    "the effectiveness of different encoding schemes ( corresponding to the sub - figures in [ fig3 ] ) was evaluated on the g3d dataset using the front jtm and the recognition accuracies are listed in table  [ steps ] .",
    ".comparisons of the different encoding schemes on the g3d dataset using the jtm projected to the front plane alone.[steps ] [ cols=\"^,^\",options=\"header \" , ]     please notice that the method used in  @xcite is based on depth and inertial sensor data , not skeleton data alone .",
    "the confusion matrix is shown in figure  [ fig : confusion3 ] .",
    "this dataset is much more challenging compared to previous two datasets . from the confusion matrix",
    "we can see that the proposed method can not distinguish some actions well , for example ,  jog \" and  walk \" .",
    "a probable reason is that the proposed encoding process is also a normalization process along temporal axis ( section 3.2 ) .",
    "the actions  jog \" and  walk \" will be normalized to have a very similar jtm after the encoding .",
    "this paper addressed the problem of human action recognition by applying convnets to skeleton sequences .",
    "we proposed an effective method to encode the joints trajectories to jtm where the motion information can be encoded into texture patterns .",
    "convnets learn discriminative features from these maps for real - time human action recognition .",
    "the experimental results showed that the techniques for encoding worked effectively .",
    "the proposed method can benefit from effective data augmentation process which would be our future work .",
    "this work was supported by the national natural science foundation of china ( grant 61571325 ) and key projects in the tianjin science & technology pillar program ( grant 15zczd gx001900 ) .",
    "v.  bloom , d.  makris , and v.  argyriou . : a gaming action dataset and real time action recognition evaluation framework . in _ proc .",
    "ieee computer society conference on computer vision and pattern recognition workshops ( cvprw ) _ ,",
    "pages 712 , 2012 .    c.  chen , r.  jafari , and n.  kehtarnavaz .",
    "utd - mhad : a multimodal dataset for human action recognition utilizing a depth camera and a wearable inertial sensor . in _",
    "image processing ( icip ) , 2015 ieee international conference on _ , pages 168172 , 2015 .",
    "y.  du , w.  wang , and l.  wang .",
    "hierarchical recurrent neural network for skeleton based action recognition . in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ , pages 11101118 , 2015 .",
    "m.  a. gowayyed , m.  torki , m.  e. hussein , and m.  el - saban .",
    "histogram of oriented displacements ( hod ) : describing trajectories of human joints for action recognition . in _ proc . international joint conference on artificial intelligence ( ijcai ) _ , pages 13511357 , 2013 .",
    "m.  e. hussein , m.  torki , m.  a. gowayyed , and m.  el - saban .",
    "human action recognition using a temporal hierarchy of covariance descriptors on 3d joint locations . in _ proc .",
    "international joint conference on artificial intelligence ( ijcai ) _ , pages 24662472 , 2013 .",
    "y.  jia , e.  shelhamer , j.  donahue , s.  karayev , j.  long , r.  b. girshick , s.  guadarrama , and t.  darrell .",
    "caffe : convolutional architecture for fast feature embedding . in _ proc .",
    "acm international conference on multimedia ( acm mm ) _ , pages 675678 , 2014 .",
    "a.  krizhevsky , i.  sutskever , and g.  e. hinton .",
    "imagenet classification with deep convolutional neural networks . in _ proc .",
    "annual conference on neural information processing systems ( nips ) _ , pages 11061114 , 2012 .",
    "o.  oreifej and z.  liu .",
    ": histogram of oriented 4d normals for activity recognition from depth sequences . in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ ,",
    "pages 716723 , 2013 .",
    "j.  shotton , a.  fitzgibbon , m.  cook , t.  sharp , m.  finocchio , r.  moore , a.  kipman , and a.  blake .",
    "real - time human pose recognition in parts from single depth images . in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ ,",
    "pages 12971304 , 2011 .",
    "r.  vemulapalli , f.  arrate , and r.  chellappa . human action recognition by representing 3d skeletons as points in a lie group . in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ ,",
    "pages 588595 , 2014 .",
    "j.  wang , z.  liu , y.  wu , and j.  yuan . mining actionlet ensemble for action recognition with depth cameras . in _ proc .",
    "ieee conference on computer vision and pattern recognition ( cvpr ) _ ,",
    "pages 12901297 , 2012 .",
    "p.  wang , w.  li , z.  gao , c.  tang , j.  zhang , and p.  o. ogunbona .",
    "convnets - based action recognition from depth maps through virtual cameras and pseudocoloring . in _ proc .",
    "acm international conference on multimedia ( acm mm ) _",
    ", pages 11191122 , 2015 .",
    "p.  wang , w.  li , p.  ogunbona , z.  gao , and h.  zhang .",
    "mining mid - level features for action recognition based on effective skeleton representation . in _ proc .",
    "international conference on digital image computing : techniques and applications ( dicta ) _ , pages 18 , 2014 .",
    "s.  yang , c.  yuan , w.  hu , and x.  ding . a hierarchical model based on latent dirichlet allocation for action recognition . in _ pattern recognition ( icpr ) , 2014 22nd international conference on _ , pages 26132618 .",
    "ieee , 2014 .",
    "x.  yang and y.  tian .",
    "eigenjoints - based action recognition using naive - bayes - nearest - neighbor .",
    "in _ proc .",
    "international workshop on human activity understanding from 3d data ( hau3d ) ( cvprw ) _ , pages 1419 , 2012 .",
    "x.  yang and y.  tian .",
    "super normal vector for activity recognition using depth sequences . in _ proc .",
    "ieee international conference on computer vision and pattern recognition ( cvpr ) _ , pages 804811 , 2014 .",
    "m.  zanfir , m.  leordeanu , and c.  sminchisescu .",
    "the moving pose : an efficient 3d kinematics descriptor for low - latency action recognition and detection . in _ proc .",
    "ieee international conference on computer vision ( iccv ) _ ,",
    "pages 27522759 , 2013 .        l.  zhou , w.  li , y.  zhang , p.  ogunbona , d.  t. nguyen , and h.  zhang .",
    "discriminative key pose extraction using extended lc - ksvd for action recognition . in _ proc . international conference on digital image computing : techniques and applications ( dicta ) _ , pages 18 .",
    "ieee , 2014 .    w.  zhu , c.  lan , j.  xing , w.  zeng , y.  li , l.  shen , and x.  xie . co -",
    "occurrence feature learning for skeleton based action recognition using regularized deep lstm networks . in _ the 30th aaai conference on artificial intelligence ( aaai ) _"
  ],
  "abstract_text": [
    "<S> recently , convolutional neural networks ( convnets ) have shown promising performances in many computer vision tasks , especially image - based recognition . </S>",
    "<S> how to effectively use convnets for video - based recognition is still an open problem . in this paper </S>",
    "<S> , we propose a compact , effective yet simple method to encode spatio - temporal information carried in @xmath0 skeleton sequences into multiple @xmath1 images , referred to as joint trajectory maps ( jtm ) , and convnets are adopted to exploit the discriminative features for real - time human action recognition . the proposed method has been evaluated on three public benchmarks , i.e. , msrc-12 kinect gesture dataset ( msrc-12 ) , g3d dataset and utd multimodal human action dataset ( utd - mhad ) and achieved the state - of - the - art results . </S>"
  ]
}