{
  "article_text": [
    "the nature of directed information flow between entities in distributed complex systems is of wide interest across neuroscience , economics , systems biology , multi - agent systems , etc . to quantify the directed information flow between two variables based on samples of time - series of their activity , the _ transfer entropy _",
    "@xcite has become the standard approach @xcite .",
    "transfer entropy @xcite from @xmath0 to @xmath1 for a pair of coincident time ordered sequences @xmath2 where @xmath3 such that the subscript @xmath4 is a ( discrete ) time index , is given by @xmath5 measured here and throughout in nats , where @xmath6 , and we use @xmath7 to indicate a probability distribution for an implied discrete random variable @xmath8 .",
    "note that @xmath9 , the local transfer entropy @xcite , represents the log ratio for a given sample @xmath10 at time @xmath4 .",
    "transfer entropy may be suitably extended for continuous random variables @xmath8 and @xmath11 ( in discrete time ) by replacing discrete probabilities @xmath7 with probability density functions @xmath12 , with appropriate weighted integrals over @xmath13 for the expectation value @xcite , based on underlying differential entropies @xcite .",
    "the transfer entropy is a measure of predictive information transfer , not of causal effect @xcite .",
    "it is particularly useful in describing distributed information processing ( where raw causality is not ) , such as identifying emergent dynamic structures ( i.e. gliders ) in cellular automata @xcite , cascading information waves in swarms @xcite , and information carrying signal properties in biochemical pathways @xcite .",
    "indeed , transfer entropy has proven particularly popular in computational neuroscience for characterising neural information flows , with applications such as inferring effective neural information networks underpinning cognitive tasks and their variation @xcite , across data modalities including meg @xcite , eeg @xcite and fmri @xcite . applications to spike train data",
    "have been less abundant however .",
    "this is because in considering neural spiking data  and many other processes ubiquitous in fields ranging from physics to economics and beyond  we do not have a discretised time basis , but instead have events which occur at an arbitrary resolution in continuous time .",
    "how should one rigorously compute the transfer entropy for such data sets ?",
    "previous approaches have attempted to apply the discrete time formalism to such systems in a number of ways , for example in examining the information between most recent events in an economic setting @xcite , or in discretising time ( i.e. time binning ) for spiking neural processes @xcite .",
    "such approaches necessarily recast the dynamics in order to make empirical approximations , which may ignore key mechanisms relevant to the source - target relationship .",
    "in particular , discretisations in time can not detect interactions ( including feedback ) below the resolution of the discretisation . choosing a fine discretisation",
    "( e.g. to ensure only one spike in any bin , with bin sizes of ms order or less ) to counter this however leads to the temporal history either being seriously undersampled or simply ignored . in @xmath14",
    "becoming impractically large since , for example , the temporal structure in spike trains is often tens or even several hundred ms long @xcite , or indeed scale - free for critical dynamics @xcite . ] while it may be possible to optimise such trade - offs for a time discretisation , one can not simultaneously avoid all of these issues in general .",
    "instead we argue that optimal treatment of information flow in these processes ( such as neural spike trains ) first requires a distinct theoretical understanding of the nature of transfer entropy in continuous time .",
    "we begin by presenting how the transfer entropy should be reconsidered in continuous time ( sect .",
    "[ sec : conttime ] ) wherein we present our central quantities , the transfer entropy rate and pathwise transfer entropy , which , in order to be expressed generally require a measure - theoretic formulation .",
    "we then apply this formalism , offering analytic forms for our central quantities , for jump processes ( those which exhibit jumps between states at continuous time points ) in sect .",
    "[ sec : jump ] , and specialise this solution for neural spike trains , or more broadly point processes , in sect .",
    "[ sec : spikes ] .",
    "next , we apply our solution for transfer entropy for spike trains to a number of scenarios in sect .",
    "[ sec : examples ] , in order to highlight the properties of the approach and how results should be interpreted .",
    "our results imply a simple empirical form for the transfer entropy rate for spike trains , summing  at each target spike only  the log ratio of history - dependent spike rates , with and without knowledge of the source .",
    "we expect these results to have significant influence on the measurement of information transfer in data sets from point processes , for example , broadening the already wide application of transfer entropy in computational neuroscience to spike train data sets .",
    "in this section we establish a generalised form for the transfer entropy in terms of relationships between probability measures on arbitrary stochastic processes . to do so we utilise measure - theoretic approaches , an oft - quoted rationale for which is to unify the ad - hoc methods which exist for discrete and continuous random variables and , under one framework , allow for the discussion of random variables for which probability mass functions or densities can not be readily formulated .",
    "for instance these could be combinations of discrete and continuous random variables or more sophisticated quantities such as random fields . whilst only a generalisation in discrete time , this will be essential when we come to consider continuous time , where the complete behaviour of some process evolving in time is described by an uncountably infinite number of points and so any formalism must be able to manage quantities which capture the whole process such as random functions .",
    "our first observation is that we can generalise eq .",
    "( [ eq : def ] ) by recognising it as the expectation of the logarithm of the radon - nikodym derivative of a given conditional probability measure with respect to a distinct , but equivalent , conditional probability measure ( as observed in @xcite ) . in discrete time , this leads us to the following definition :    ' '' ''    given two stochastic processes @xmath15 and @xmath16 adapted to the underlying filtered probability space @xmath17 , indexed by the set of consecutive integers @xmath18 , the transfer entropy is the expectation of the logarithm of the radon - nikodym derivative between two equivalent measures on the random variable @xmath19 taking values in a measurable state space @xmath20 , which are regular conditional probabilities given two related conditions : @xmath21\\nonumber\\\\ & = \\int_{\\omega}\\ln{\\frac{d\\mathbb{p}_n(x_n|x^{n-1}_{n - k},y^{n-1}_{n - l})}{d\\mathbb{p}_n(x_n|x^{n-1}_{n - k})}(\\omega)}dp(\\omega ) .",
    "\\label{measure}\\end{aligned}\\ ] ]    the extended notion of a local transfer entropy is analogously defined as @xmath22 [ radondef ]    ' '' ''    with this notation for the transfer entropy , in contrast to eq .",
    "( [ eq : deflocal ] ) , we introduce and emphasise the concept that this is the transfer entropy associated with , or accumulated over , the interval @xmath23 to @xmath4 ( see further discussion in sect .  [",
    "sec : implicationsforempirical ] ) .",
    "we may generalise this over longer intervals , in this instance @xmath23 to @xmath24 , by writing : @xmath25    explicitly , for eq .",
    "( [ measure ] ) , in the special case that @xmath19 is a single discrete variable the integral w.r.t .",
    "the measure reduces to @xmath26 summations and the @xmath27 can be directly considered as probabilities ( c.f .",
    "( [ eq : def ] ) ) .",
    "similarly , in the case that @xmath19 is continuous the integral w.r.t .",
    "the measure reduces to @xmath26 integrals over a probability density w.r.t .",
    "@xmath28 & @xmath29 and the contents of the logarithm can , in entirety , be considered as the ratio between two probability densities .    in formalising definition",
    "[ radondef ] and other quantities , we shall make use of the following .",
    "we consider @xmath8 and @xmath11 , taking values in the measurable state spaces @xmath20 and @xmath30 to be stochastic processes @xmath15 and @xmath16 adapted to the filtered probability space @xmath17 with samples @xmath31 such that @xmath32 .",
    "we assert the existence of the suitable measurable space @xmath33 , where @xmath34 such that samples are random functions , or _ paths _",
    ", @xmath35 , i.e. @xmath36 . similarly @xmath37 is the suitable measurable space for samples @xmath38 .",
    "we equip these path spaces with a family of probability measures , denoted @xmath39 , @xmath40 ( which we call natural measures ) , including the canonical ( pushforward ) measures , or laws , @xmath41 and @xmath42 induced on @xmath43 and @xmath44 .",
    "these measures are the marginal measures of the probability space @xmath45 induced on @xmath46 . to recover and generalise the original definition of the transfer entropy in discrete time where @xmath47 we consider the probability space @xmath48 induced on the single random variable @xmath49 ( such that we also recognise @xmath50 ) .",
    "by insisting @xmath51 we create the measures in eq .",
    "( [ measure ] ) in the manner of regular conditional probabilities @xcite.$ ] where @xmath52 is the indicator function on @xmath53 such that it satisfies @xmath54=\\mathbb{p}(x_n\\in \\mathcal{a}\\cap x^{n-1}_{n - k}\\in \\mathcal{b}),\\quad\\forall \\;\\mathcal{b}\\in\\sigma(x^{n-1}_{n - k})$ ] where @xmath55 denotes the sub-@xmath56-algebra of @xmath57 generated by @xmath58 . ] given these measures we define the transfer entropy ( in discrete time ) as the expectation in eq .",
    "( [ measure ] ) .      to define such a quantity in continuous time",
    "we recognise that eq .",
    "( [ eq : def ] ) represents a rate of a transfer of information per discretised time step @xcite .",
    "consequently , without such a fundamental temporal discretisation we must initially define a _ transfer entropy rate _ in proposition [ propcont ] ( see also @xcite ) .",
    "we emphasise that this naturally leads to integrated quantities , in the form of functionals of realised paths , which we introduce subsequently ( proposition [ pathdef ] ) .    ' '' ''    in continuous time such that we have stochastic processes @xmath15 and @xmath16 , indexed by the connected subset @xmath59 , we must consider the _ transfer entropy rate _ which , analogously to eq  ( [ measure ] ) , is given by @xmath60}{d\\mathbb{p}_{t+dt}[{x}_{t+dt}|{{x}}^{t}_{t - s}]}}\\right]\\nonumber\\\\ & = \\lim_{dt\\to 0}\\frac{1}{dt}\\int_{\\omega}\\ln{\\frac{d\\mathbb{p}_{t+dt}[{x}_{t+dt}|{{x}}^{t}_{t - s},{{y}}^{t}_{t - r}]}{d\\mathbb{p}_{t+dt}[{x}_{t+dt}|{{x}}^{t}_{t - s}]}}(\\omega)dp(\\omega ) .",
    "\\label{eq : eq2}\\end{aligned}\\ ] ] [ propcont ]    ' '' ''    the above uses notation convention @xmath61 $ ] to indicate that arguments include path functions which we write using the notation @xmath62 and @xmath63 , where @xmath64 .",
    "the conditional measures are constructed in the manner of regular conditional probabilities analogously to the discrete time case , but now conditional on previous path functions .",
    "expanding on eq .",
    "( [ eq : eq2 ] ) in proposition [ propcont ] , we require @xmath65 $ ] and introduce the variables @xmath66 which play the role of @xmath67 and @xmath68 in discrete time tuning how much previous history to use in the calculation .",
    "when they are omitted it is to be understood that it indicates the limit @xmath69 and @xmath70 .",
    "we point out that markovian dynamics are captured by the _ limit _",
    "@xmath71 ( i.e. not @xmath72 , @xmath73 ) .",
    "we emphasise , in these forms , eqs .",
    "( [ measure ] ) & ( [ eq : eq2 ] ) allow for a very general application of transfer entropy since @xmath8 can represent any quantity which can be assigned a probability measure that evolves in time with the distinction simply being whether that evolution occurs in discrete or continuous time .",
    "+   + we next introduce integrated versions of the transfer entropy which characterise the information transfer over finite time intervals through the use of probability measures on realisation of the stochastic processes .",
    "the identification of such integrated , or pathwise , quantities @xcite is generalised in our current formalism to read :    ' '' ''    by assuming the existence of unique measures , @xmath74 and @xmath75 , on a suitable path space for realisations of the stochastic process , @xmath76 , we introduce the _ pathwise transfer entropy _ @xmath77=\\ln{\\frac{d\\mathbb{p}_{x|\\{y\\}}^{(s , r)}[x_{t_0}^{t}|x^{t_0}_{t_0-s},\\{y^{t}_{t_0-r}\\}]}{d\\mathbb{p}_{x}^{(s)}[x_{t_0}^{t}|x^{t_0}_{t_0-s}]}}. \\label{local0}\\ ] ] eq .",
    "( [ local0 ] ) is a functional , mapping path functions of @xmath8 and @xmath11 into @xmath78 ( @xmath79 ) , designed to capture the information dynamics of individual realisations ( path functions ) of the stochastic processes where the measures are defined as those which satisfy the following property @xmath80\\right ] .",
    "\\label{avint}\\ ] ] [ pathdef ]    ' '' ''    this should be interpreted as the continuous time generalisation of eqs .",
    "( [ measure])-([localpathdiscrete ] ) .",
    "the contents of eq .",
    "( [ avint ] ) should be considered to be the total transfer entropy accumulated , or transferred , on the interval @xmath81 .",
    "we emphasise that this quantity is the expectation of the pathwise transfer entropy on the same time interval .",
    "this idea very closely resembles the concepts involved in modern treatments of entropy production , heat , work , etc .",
    ", within formalisms such as stochastic thermodynamics @xcite .",
    "this leads to a dual definition of the transfer entropy rate , valid for stationary processes .    ' '' ''    for stationary processes eq .",
    "( [ avint ] ) implies @xmath82}{d\\mathbb{p}_{x}^{(s)}[x_{t_0}^{t}|x^{t_0}_{t_0-s}]}}\\right ] .",
    "\\label{eq : rateintegralrelationshipstationary}\\end{aligned}\\ ] ] [ pathwise ]    ' '' ''    the natural measures @xmath75 and @xmath74 are those which jointly satisfy eqs .",
    "( [ eq : eq2 ] ) , ( [ local0 ] ) and ( [ avint ] ) and also , along with an appropriate choice of path space , lead to the correct path properties in @xmath8 .",
    "identification of such measures will be implementation specific , but to satisfy the above we may state the following conditions on the finite dimensional distributions of the measures .",
    "given @xmath83 the ( family of ) finite dimensional distributions for times @xmath84 is a measure on the space @xmath85 and satisfies    @xmath86,j\\geq 0}\\left(x_{t^j}\\in\\mathcal{a}_{j}\\right)\\right ) \\label{px}\\end{aligned}\\ ] ]    along with requisite consistency conditions thus corresponding to and implying the existence of the measure @xmath87 $ ] on a suitably defined path space , @xmath88 , dictating the regularity of the paths if appropriate @xcite . has absolutely continuous sampling paths ( driven perhaps by some coloured gaussian noise ) with @xmath89 , @xmath90 would be the space of continuous functions , @xmath91 , with @xmath92 being the borel sigma algebra associated with the uniform topology on @xmath91 such that @xmath93 , given the appropriate gaussian forms for @xmath94 , would be the continuous version of the extension of eq .",
    "( [ px ] ) . ]",
    "( [ px ] ) should be understood as a generalisation of the usual decomposition of a joint measure or density into conditional measures or densities utilised , for example , in markov chains , but with the ( not necessarily true ) _ assumption _ , @xmath95 $ ] , i.e. that given knowledge of @xmath96 seconds of the processes history , further knowledge of previous history does not help in making future predictions .",
    "this amounts to a generalisation of the usual markov property @xmath97 used in the construction of more familiar entities such as the chapman kolmogorov equation .",
    "we then define @xmath98\\equiv \\mathbb{p}_{x}^{(s)}[x_{t_0}^{t}\\in\\mathcal{a}|x_{t_0-s}^{t_0}]$ ] as a measure on the sub - space of functions on @xmath81 , @xmath99 , by appealing to regular conditional probabilities of @xmath87 $ ] . similarly @xmath100,j\\geq",
    "0}\\left(x_{t^j}\\in\\mathcal{a}_{j}\\right)\\right)\\cap \\left(y^{t^{i}}_{t^{i}-\\min(t^{i}-\\inf{\\mathbb{t}},r)}\\right)\\right ] \\label{meas}\\end{aligned}\\ ] ]    defines the measure @xmath101 $ ] , using the analogous assumption @xmath102 $ ] .",
    "again we define @xmath103\\equiv \\mathbb{p}_{x|\\{y\\}}^{(s , r)}[x_{t_0}^{t}|x_{t_0-s}^{t_0},\\{y_{t_0-r}^{t}\\}]$ ] on @xmath99 using regular conditional probabilities of @xmath101 $ ] .",
    "we note that in the limit @xmath69 we recover the canonical pushforward measure @xmath104=\\lim_{s\\to\\infty}\\mathbb{p}_{x}^\\mathbb{t}[x_{t_0-s}^t\\in\\mathcal{a}].\\ ] ] however , we emphasise @xmath105\\neq\\nonumber\\\\ & \\qquad \\lim_{\\substack{s\\to\\infty\\\\r\\to\\infty}}\\mathbb{p}_{x|y}^{\\mathbb{t}}[x_{t_0-s}^{t}\\in \\mathcal{a}|y^{t}_{t_0-r}]\\end{aligned}\\ ] ] where the latter quantity is a conditional probability measure in the usual sense . i.e. the structure of eq .",
    "( [ meas ] ) does _ not _ result in the standard definition of conditioning upon @xmath106 because no details of the distributions of @xmath11 are included in its construction .",
    "we denote this distinction with the use of braces , @xmath107 .",
    "this may be simultaneously thought of as the assumption that @xmath11 does not depend on @xmath8 or a recasting of the conditional dynamics into time inhomogeneous ( non - stationary ) dynamics parameterised by @xmath11 .",
    "it can not be overstated that @xmath108 and @xmath109 are distinct probability measures on @xmath33 .",
    "we also note that the approach for transfer entropy as a log - likelihood ratio for discrete time real - valued processes in @xcite is a special case of the general formalism for the pathwise transfer entropy in continuous time in eq .",
    "( [ local0 ] ) . +   +",
    "recent developments have discussed the importance of _ local _ transfer entropy that is associated with individual transitions @xcite",
    "( [ eq : deflocal ] ) ) .",
    "we emphasise that the information dynamics of individual realisations here is captured by the pathwise transfer entropy and that any attempt to define a local transfer entropy rate may not be well defined .",
    "this is because the logarithm of the relevant radon - nikodym derivative may be non - differentiable and indeed may even be nowhere differentiable leading us to assert that a local transfer entropy rate does not exist :    ' '' ''    a local or pointwise transfer entropy rate defined as @xmath110}{d\\mathbb{p}_{t+dt}[{x}_{t+dt}|{{x}}^{t}_{t - s}]}}\\ ] ] can not be guaranteed to exist .",
    "[ nolocal ]    ' '' ''    we finish by noting that all of the measure - theoretic and continuous time formalisms presented here are trivially extendible to conditioning on another source , or set of sources , to provide forms for the conditional transfer entropy @xcite .      the overwhelming majority of the applications of transfer entropy in the literature concern empirical data from some real world process",
    ". such underlying processes , despite being in continuous time , are often , in practice , sampled at a finite rate .",
    "our main observation is the following :    ' '' ''    [ rem : discretisationlimit ] we recover an approximation to the quantities in this formalism given a discretisation of a continuous time process by recognising , due to the linearity of the expectation operator , @xmath111\\nonumber\\\\ & = \\lim_{\\delta t\\to 0}\\sum_{i = t_0/\\delta t+1}^{t/\\delta t}t^{(k , l)}_{y\\to x}\\big|_{(i-1)\\delta t}^{i\\delta t},\\quad k=\\left\\lfloor\\frac{s}{\\delta t}\\right\\rfloor+1 , l=\\left\\lfloor\\frac{r}{\\delta t}\\right\\rfloor+1 \\label{eq : emp1},\\end{aligned}\\ ] ] where this limit exists , such that the relevant path measures are convergent in such a procedure , and where @xmath112 defines the discretisation scheme .",
    "consequently the transfer entropy rate , given discretisation of a continuous time process , would be approximated by @xmath113 in line with eq .",
    "( [ eq : eq2 ] ) .    ' '' ''    typical empirical assumptions and their implications are captured by the following :    ' '' ''    when the process is both stationary and self averaging ( ergodic ) , the transfer entropy rate would be approximated , in practice , by the following limit : @xmath114 again with @xmath115 , @xmath116 , and where @xmath117 is accumulated over @xmath118 time steps as per eq .",
    "( [ localpathdiscrete ] ) .    ' '' ''    eq .",
    "( [ eq : emp1 ] ) is consistent with the idea that one could , in principle , treat transfer entropy in continuous time as the limit of a discrete time transfer entropy and thus eq .  ( [ eq : eq2 ] ) as a discrete time transfer entropy rate as per eq .",
    "( [ emp2 ] ) .",
    "we note , however , that the leading @xmath119 term in eq .",
    "( [ emp2 ] ) has generally been overlooked ( e.g. in @xcite , where @xmath120 is computed for small @xmath112 , but without the limit and the @xmath119 term ) .",
    "this suggests that , where the limiting rate exists , a necessary condition for the appropriateness of the time - scale @xmath112 for a discrete time transfer entropy ( in terms of capturing the time - scale of interactions , and not being undersampled ) is that it must scale with @xmath112 in this vicinity .",
    "we know for example that a limiting rate exists for linearly coupled gaussian processes ( with wiener noise ) in continuous time , where the granger causality ( proportional to transfer entropy for such processes @xcite ) is linearly proportional to @xmath112 as @xmath121 @xcite .",
    "furthermore , this question of convergence from a discrete time approximation to continuous systems and the ambiguous inclusion of time interval parameters highlights a subtle distinction between transfer entropy as presented in the literature as a statistic associated with a single time , and our interpretation which insists , even in discrete time , that transfer entropy can only ever be associated with a finite time interval in contrast with the transfer entropy rate , even if that interval is simply one time step . in other words , in discrete time , if each time step is considered to take to a value of one , but is otherwise _ dimensionless _ , we have @xmath122 ( where @xmath123 indicates a discrete time derivative on @xmath124 analogous to the usual time derivative on @xmath78 ) .",
    "we note that for stationary processes this generalises to @xmath125 . however , as soon as one associates some unit or dimension with time one is obliged to distinguish between those quantities in nats ( or bits ) and those in nats per unit time . if each time step is deemed , still , to take value one , the quantities , whilst distinct , have the same value , leading to the previously discussed ambiguity .",
    "but application to continuous time shows that in general these notions are distinct and we argue that one should always , in continuous or discrete time , whether time is physical or otherwise , distinguish between accumulated transfer entropies ( in nats ) , which can only exist on a finite time interval , and transfer entropy rates ( in nats per unit time ) .",
    "finally , we note that the approach in remark [ rem : discretisationlimit ] unavoidably leads to a divergence in the number of bins required to capture path histories which we expect to be seriously limiting in practice .",
    "whilst this may seem unpromising for real world applications outside of theoretical models where path measures can either be asserted or derived , there do exist classes of stochastic processes , in continuous time , where alternative representations exist such that no binning is required . where real world phenomena can be meaningfully approximated by such stochastic processes we can then dramatically improve this picture .",
    "such processes are the subject of the next section .",
    "for the remainder of this paper we now focus specifically on jump processes . these are stochastic processes characterised by intermittent transitions between states in @xmath126 and where the states are constant in between these transitions .",
    "they can be thought of as a non - markov , inhomogeneous and possibly non - stationary generalisation of compound - poisson or renewal - reward processes . as such we consider @xmath127 to be the space of _ cdlg _ ( right continuous with left limits ) step functions on @xmath126 ( therefore @xmath128 is taken to be the borel sigma algebra associated with the @xmath129 , or skorokhod , topology on @xmath127 @xcite ) .",
    "we note that we present a formalism for discrete state spaces , @xmath126 , with the powerset @xmath130 , which necessarily deal with summations over states , but this is trivially modified for use with continuous state spaces by replacing all sums by the appropriate integrals ( or indeed more complicated spaces by an integral w.r.t an appropriate measure ) .",
    "examples of such systems are ubiquitous , but include financial times series such as equity prices , population dynamics and spiking neural processes .    ' '' ''    for stochastic processes @xmath15 , @xmath131 , whose sample paths are _ cdlg _ step functions which permit description by transition rates @xmath132 and escape rates @xmath133 , with path @xmath134 captured by the starting configuration @xmath135 at time @xmath136 , @xmath137 transitions into states @xmath138 at times @xmath139 up until final time @xmath140 , the _ pathwise transfer entropy _ is given by @xcite : @xmath141=\\sum_{i=1}^{n_x}\\ln{\\frac{w[x_{i}|x^{t_i}_{{t_{i}}-s},y^{t_i}_{{t_{i}}-r}]}{w[x_{i}|x^{t_i}_{{t_{i}}-s}]}}\\nonumber\\\\ & \\quad+\\int_{t_0}^{t}\\left(\\lambda_{x}[{{x}}_{t'-s}^{t'}]-\\lambda_{x|y}[{{x}}_{t'-s}^{t'},{{y}}_{t'-r}^{t'}]\\right)dt ' .",
    "\\label{eq : local}\\end{aligned}\\ ] ] [ pathjump ]    ' '' ''    to present the above , we begin by formally defining our notation . in such systems",
    "the quantities which characterise the behaviour are transition rates , for which we require those with and without knowledge of the source @xmath11 .",
    "we may construct them , using the probability of the @xmath128-measurable event of having a transition in a given interval @xmath142 $ ] denoted here by @xmath143}$ ] , by writing @xmath144&=\\lim_{dt\\to 0 } \\frac{1}{dt}\\mathbb{p}_{[t , t+dt]}[{x}'\\in[t , t+dt]|{{x}}_{t - s}^{t},{{y}}_{t - r}^{t}]\\nonumber\\\\ w[{x}'|{{x}}_{t - s}^{t}]&=\\lim_{dt\\to 0 } \\frac{1}{dt}\\mathbb{p}_{[t , t+dt]}[{x}'\\in[t , t+dt]|{{x}}_{t - s}^{t } ] , \\label{wrates}\\end{aligned}\\ ] ] where the notation @xmath145 $ ] indicates the transition into state @xmath146 in the interval @xmath147 $ ] .",
    "this naturally leads to the mean escape rates @xmath148=\\sum_{{x}'\\neq { x}^{-}_t}w[{x}'|{{x}}_{t - s}^{t}]\\\\ & \\lambda_{x|y}[{{x}}_{t - s}^{t},{{y}}_{t - r}^{t}]=\\sum_{{x}'\\neq { x}^{-}_t}w[{x}'|{{x}}_{t - s}^{t},{{y}}_{t - r}^{t}]\\end{aligned}\\ ] ] which are the rates of transitioning out of state @xmath149 , given knowledge of the history of @xmath8 or both @xmath8 and @xmath11 and where @xmath150 .",
    "we have made no assumption about the nature of @xmath11 , however if @xmath11 is also a jump process we have @xmath151=\\sum_{y'}w[{x}',{y}'|{{x}}_{t - s}^{t},{{y}}_{t - r}^{t}]$ ] .",
    "we note that such processes do not possess an embedded discrete time process such as an embedded markov chain since we consider non - markovian potentially non - stationary processes .",
    "again we point out we recover markovian transition and escape rates in the limit @xmath152 , @xmath153 .",
    "+   + in appendix [ appa ] we use the above quantities to construct the relevant probability measures of a jump process , @xmath76 , running from time @xmath154 to time @xmath155 that satisfy eqs .",
    "( [ px ] ) and ( [ meas ] ) .",
    "we introduce notation such that for a path that consists of @xmath137 transitions in @xmath8 , transitions may be labelled by the index @xmath156 so that @xmath157 being the state into which the system transitions at time @xmath139 .",
    "we maintain the notation for the inital time , @xmath136 , and introduce notation for the inital state @xmath158 to exploit the indexing system as a deliberate abuse of notation to characterise the path up to the first transition .",
    "key results include the identification of the following probability densities ( which may be thought of as generalised janossy densities @xcite ) w.r.t . the lebesgue measure on @xmath159 , or likelihoods , for a specific path realisation arising from measures @xmath160 and @xmath74 respectively @xmath161=\\nonumber\\\\ & \\quad\\left(\\prod_{i=1}^{n_x}w[x_{i}|x^{t_i}_{{t_{i}}-s}]\\right)\\exp{\\left[-\\int_{t_0}^{t}\\lambda_x[x^{t'}_{t'-s}]dt'\\right ] } \\label{eq : probden0-maintext}\\end{aligned}\\ ] ] @xmath162=\\nonumber\\\\ & \\quad\\left(\\prod_{i=1}^{n_x}w[x_{i}|x^{t_i}_{{t_{i}}-s},y^{t_i}_{{t_{i}}-r}]\\right)\\exp{\\left[-\\int_{t_0}^{t}\\lambda_{x|y}[x^{t'}_{t'-s},y^{t'}_{t'-r}]dt'\\right]}. \\label{probden - maintext}\\end{aligned}\\ ] ]",
    "we note @xmath163 such that we can represent any path @xmath164 .",
    "we point out that expectations are taken w.r.t . these measures by implementing variants of the following infinite series for @xmath75 @xmath165\\right]=\\int_{\\omega_x}f[x_{t_0}^t]d\\mathbb{p}_{x}^{(s)}[x_{t_0}^t]=\\sum_{i=0}^{\\infty}j^f_i[t , x^{t_0}_{t_0-s } ] \\label{jsum}\\ ] ] where @xmath166=\\sum_{\\substack{x_{i}\\in\\sigma_{x } \\\\",
    "x_{i}\\neq x_{i-1}}}\\ldots\\sum_{\\substack{x_1\\in\\sigma_{x } \\\\",
    "x_1\\neq x_{0}}}\\int_{t_0}^{t}dt_1\\ldots\\int_{t_{i-1}}^{t}dt_{i}\\nonumber\\\\ & \\quad f_{i}(x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0^{i}\\ } ) p_{i}^{(s)}[x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0^{i}\\}|x^{t_0}_{t_0-s}]\\end{aligned}\\ ] ] and where @xmath167=\\nonumber\\\\ & f_{0}(x^t_{t_0}\\equiv\\{t,\\{t_0,x_0\\}\\})p_0^{(s)}[x^t_{t_0}\\equiv\\{t,\\{t_0,x_0\\}\\}|x^{t_0}_{t_0-s}].\\end{aligned}\\ ] ] here @xmath168 are the functional forms of @xmath169 given @xmath170 transitions in @xmath8 .",
    "when @xmath171=1 $ ] we have @xmath172 $ ] equal to the probabilities of having @xmath170 transitions on @xmath81 , given @xmath173 , such that @xmath174=1 $ ] .",
    "explicitly , @xmath175 is the probability density for a path on @xmath176 that contains @xmath170 transitions , conditional upon the previous path function @xmath177 , where transition rates utilise @xmath96 seconds of history dependence .",
    "we note that @xmath175 would also be a density with respect to @xmath178 should @xmath8 be continuous .",
    "given such quantities , identified in appendix [ appa ] , the radon nikodym derivative may be identified as the ratio of such probability densities , or log likelihood ratio @xcite , and thus the pathwise transfer entropy in eq .",
    "( [ local0 ] ) as the sum and integral contribution in eq .",
    "( [ eq : local ] ) appearing in proposition [ pathjump ] .    explicitly eq .  ( [ eq : local ] ) , the pathwise transfer entropy , consists of :    1 .   a continuously varying contribution ( relating to waiting times between transitions ) , that is interrupted by 2 .",
    "discontinuous jump contributions when a transition in @xmath8 occurs .",
    "the implication is that not only can a transition be predicted by the previous behaviour in @xmath8 and @xmath11 , but the absence of a transition can as well . +   + examining the pathwise transfer entropy in eq .",
    "( [ eq : local ] ) we can consider analogues to the local or pointwise contributions associated with the usual formalism of transfer entropy @xcite by considering the contributions associated with transitions and periods between them .",
    "doing so allows us to consider a _",
    "local _ contribution to the transfer entropy associated with a transition @xmath179 and a _ local _ rate of transfer entropy associated with periods inbetween transitions @xmath180 such that @xmath141=\\nonumber\\\\ & \\qquad\\sum_{i=1}^{n_x}\\delta \\mathcal{t}^{(s , r)}_{t}(t_i)+\\int_{t_0}^{t}\\dot{\\mathcal{t}}_{nt}^{(s , r)}(t')dt ' , \\label{eq : localcontributions}\\end{aligned}\\ ] ] with @xmath179 and @xmath180 defined by identification with eq .",
    "( [ eq : local ] ) .",
    "however , we point out that these two contributions are distinct and any attempt to produce a single _ local _ ( pointwise ) _ rate _ will be rendered divergent because of the discontinuous contributions at the transitions , thus confirming proposition [ nolocal ] .",
    "next we consider the ( average ) transfer entropy rate for jump processes :    ' '' ''    the _ transfer entropy rate _ for jump processes , as described , is given by the expectation @xmath181}{w[x_{t}|x^{t}_{{t}-s}]}}\\right ] \\label{av}\\end{aligned}\\ ] ] where @xmath182 is the kronecker delta function .",
    "[ ratejump ]    ' '' ''    we point out that such an expectation is computed in a similar manner to eq .",
    "( [ jsum ] ) where , in this instance , we have @xmath183 , but with all permutations of transitions in @xmath8 and @xmath11 as opposed to just in @xmath8 .",
    "for instance if @xmath184 we would have @xmath185 where @xmath170 and @xmath186 are the number of transitions in @xmath8 and @xmath11 respectively .",
    "the expression in eq .",
    "( [ av ] ) arises directly from the crucial property @xmath187=\\mathbb{e}_{p}[\\lambda_{x}[{{x}}_{t - s}^{t}]]\\ ] ] which holds since each is a linear average over sums of transition rates .",
    "consequently , at any time , @xmath188=\\mathbb{e}_{p}[\\lambda_{x|y}[{{x}}_{t - s}^{t},{{y}}_{t - r}^{t}]]=\\mathbb{e}_{p}[\\lambda_{x\\cdot}[\\cdot]]$ ] ( the mean escape rate , identical given any natural measure on @xmath8 ) meaning @xmath189-\\lambda_{x|y}[{{x}}_{t'-s}^{t'},{{y}}_{t'-r}^{t'}]\\right)dt'\\right]=0 \\label{nonspike}\\ ] ] and thus @xmath190=0 $ ] .",
    "as such , there is no net contribution to the expected rate arising from the pathwise transfer entropy associated with waiting times between target transitions .",
    "consequently , the transfer entropy rate is expressible by eq .",
    "( [ av ] ) in proposition [ ratejump ] .",
    "again we compare this to the implied empirical formulation for a self averaging stationary process which can be expressed through :    ' '' ''    for stationary self averaging processes the _ transfer entropy rate _ is equivalent to the implied empirical measurement strategy @xmath191}{w[x_{t_i}|x^{t_i}_{{t_{i}}-s } ] } } \\label{empjump}\\ ] ] where @xmath137 is the number of transitions in @xmath8 in the interval @xmath81 .",
    "[ empjumprem ]    ' '' ''    crucially we can see that in comparison to eq .",
    "( [ eq : emp1 ] ) , no limit in a time discretisation parameter is required ; eq .",
    "( [ empjump ] ) is asymptotically exact as @xmath192 which may be achieved empirically by simply considering more data . finally , as per sect .",
    "[ sec : conttime ] , all of the formalisms for jump processes are trivially extendible to conditional transfer entropies @xcite .",
    "next we turn our attention to point processes , the most prominent example of which being spike train processes common to neuroscience .",
    "these processes are not characterised by transitions between distinct states , but rather consist of path spaces which permit , in model , several non - overlapping and individually indistinguishable events or spikes of zero width which occur in continuous time .",
    "as such the paths are completely described by the times of such spikes . to apply the preceding formalism we must consider them as a _ cdlg _",
    "process with the most natural way being to recast them as a non - markov extension of a poisson counting process or a generalised modulated renewal process , which in turn may be multidimensional .",
    "in such a set up the spike rate is equivalent to the rate of increasing the counting process by one or the transition rate between ` state ' @xmath193 and @xmath194 where @xmath193 is the total number of spikes that have occurred . here",
    "@xmath193 is arbitrary and so we insist that any transition rate be independent of @xmath193 such that the _ path dependent spike rate _ ( or conditional intensity function ) is @xmath195&=w[n^{-}_{t}+1|n^{t}_{t - s}]\\nonumber\\\\ & = w[n^{-}_{t}+1+m|n^{t}_{t - s}+m]\\quad\\forall \\:m\\in\\mathbb{n}\\end{aligned}\\ ] ] where @xmath196 indicates that @xmath197 spikes have been uniformly added to the counting process and @xmath198 indicates a spike in @xmath8 at time @xmath140 .",
    "such a process , in state @xmath199 may only escape into state @xmath200 ( i.e. not state @xmath201 etc . ) meaning that we also recognise that @xmath202=\\lambda_x[n^{t}_{t - s}+m]=\\lambda_x[x^{t}_{t - s}]\\ ] ] such that the path dependent spike rates act as both the path dependent transition and escape rates .",
    "in the first instance , this simplifies eqs .",
    "( [ eq : probden0-maintext ] ) and ( [ probden - maintext ] ) ( see also @xcite ) . returning , for continuity , to an expression of paths , @xmath8 , we can represent any path containing @xmath137 spikes starting at time @xmath136 as @xmath203 with spike times @xmath204 .    by comparison with eqs .",
    "( [ eq : local ] ) and ( [ av ] ) we then have    ' '' ''    for spike train or point processes , the _ pathwise transfer entropy _ is given by @xmath205=\\sum_{i=1}^{n_x}\\ln{\\frac{\\lambda_{x|y}[x^{t_i}_{{t_{i}}-s},y^{t_i}_{{t_{i}}-r}]}{\\lambda_x[x^{t_i}_{{t_{i}}-s}]}}\\nonumber\\\\ & \\quad+\\int_{t_0}^{t}\\left(\\lambda_{x}[{{x}}_{t'-s}^{t'}]-\\lambda_{x|y}[{{x}}_{t'-s}^{t'},{{y}}_{t'-r}^{t'}]\\right)dt ' .",
    "\\label{spikepath}\\end{aligned}\\ ] ] [ spikepathprop ]    ' '' ''    for spike train or point processes , the _ transfer entropy rate _ is given by the expectation @xmath206}{\\lambda_{x}[x^{t}_{{t}-s}]}}\\right ] .",
    "\\label{spikeav}\\end{aligned}\\ ] ] [ spikeavprop ]    ' '' ''    these quantities have the same properties as the more general jump processes case .",
    "that is , eq .",
    "( [ spikepath ] ) , the pathwise transfer entropy , consists of :    1 .   a continuously varying contribution ( relating to waiting times between spikes ) , with rate @xmath180 ; that is interrupted by 2 .   discontinuous jump contributions , @xmath179 , when a spike in @xmath8 occurs .",
    "again , this implies that not only can a spike in the target @xmath8 be predicted by the previous behaviour in @xmath8 and @xmath11 , but the absence of a spike can as well .",
    "however , there is no net contribution to the expected rate arising from the pathwise transfer entropy associated with waiting times between target spikes .    the implied empirical formalism in this case ,",
    "again for stationary self averaging processes , is of the form in eq .",
    "( [ empspike ] ) in remark [ empspikerem ] and thus reads    ' '' ''    for stationary self averaging processes the transfer entropy rate is equivalent to the implied empirical measurement strategy @xmath207}{\\lambda_x[x^{t_i}_{{t_{i}}-s } ] } } \\label{empspike}\\ ] ] where @xmath137 is the number of spikes in @xmath8 in the interval @xmath81 .",
    "[ empspikerem ]    ' '' ''    at this point we wish to point out that for such continuous time processes the ability to losslessly represent paths @xmath208 points to a strategy for efficient empirical computation , as an alternative to brute force time discretisation approaches , to be presented in a companion paper .",
    "the idea that information in spike times relates to an underlying directed relationship has been observed , e.g. , regarding `` causal entropy '' in @xcite , which indeed computed entropies of ( cross ) inter - spike intervals . however to our knowledge , this is the first formulation that computes transfer entropy based on lossless representation of entire spike trains ( and is thus a dynamic quantity which captures state - updates rather than static correlations of single spike - time relationships ) .",
    "we also note that our formulation would capture information transmission facilitated via either rate or temporal coding @xcite .",
    "we take a moment to point out that in order to provide a genuinely non - parametric statistic such as the transfer entropy , such a formalism must be completely general and so can easily capture the dynamics of frequently used processes for neural modelling .",
    "for instance such a formalism can represent a non - stationary poisson process , @xmath209=\\lambda_x(t)$ ] , a modulated renewal process , @xmath209=\\lambda_x(t , t - t_{n_x})$ ] or higher order stochastic processes such as cox processes through @xmath210=\\lambda_{x|y}(y_t)$ ] @xcite .",
    "indeed we assume some dependence on another variable in order for the concept of transfer entropy to be relevant .",
    "we emphasise , however , that the hidden variables used in the construction of such processes need not be the source used in the calculation of the transfer entropy ( i.e. the doubly stochastic variable in a cox process could be some hidden variable @xmath211 , for instance ) . and",
    "indeed , such hidden variables ( or others ) could be trivially conditioned on in all of these formalisms for spiking processes to make the extension to conditional transfer entropies as discussed in sect .",
    "[ sec : jump ] @xcite .",
    "to highlight the properties of our results we present two examples of spike train processes where , analytically and numerically respectively , the transfer entropy can be calculated . in these examples",
    "both the target and source are considered to be point processes .",
    "we point out that for such spike train processes the transition rate in @xmath8 where @xmath11 is known must have some finite non - markov character dependent on the history of @xmath11 since otherwise the process maps to the same markovian poisson process independently of the knowledge of @xmath11 giving a transfer entropy of zero .",
    "the main challenge for analytical computation is the tractability of computing the coarse grained spike rate @xmath212 since , as mentioned above , the joint process must be non - markov .      in our first example",
    "we alleviate such difficulties by defining a process and considering it in the regime where it is feasible to calculate the coarse grained spike rate analytically .",
    "to do so we consider a simple model of neuron spiking . in this model",
    "a source neuron spikes randomly with a refractory period preventing rapid sequential spiking .",
    "source spikes can cause a target neuron , also with a refractory period , to spike with a defined probability within in a subsequent time window .",
    "we can summarize the process with the following statements :    * both the source @xmath11 and target @xmath8 each have independent refractory periods of duration @xmath213 following a spike , during which they can not spike .",
    "* outside of its refractory period the source @xmath11 is a regular , stationary and markovian , poisson process with rate @xmath214 and is independent of @xmath8 .",
    "* the target @xmath8 may spike only within a window of @xmath215 seconds duration following a spike in the source @xmath11 .",
    "the probability of @xmath8 spiking in the interval is @xmath216 .",
    "this leads to an elevated spike rate in the @xmath215 long interval of @xmath217}$ ] since the probability of @xmath8 not spiking in this window is @xmath218 . * the refractory period @xmath213 is longer or equal to the the elevated rate period @xmath215 , a by - product of which being that that the target @xmath8 may only spike once in the elevated rate period @xmath215 .",
    "* the target and source can not spike simultaneously .",
    "such a property is sometimes called bipartite .",
    "this means @xmath219=w[x^t_{\\text{spike}},y^{-}_t|x_{t - s}^{t},y_{t - r}^{t}]$ ] .",
    "* by convention , any discontinuities in spike rates are considered to be _",
    "we can summarize the above using the following transition rates where @xmath220 and @xmath221 are the times of the most recent spikes in the source and target respectively @xmath222 } , & t^y \\leq t < t^y+\\tau\\\\ & 1_{[t^y , t)}(t^x)=0\\\\ & t\\geq t^x+\\tau^r\\\\ 0 &   \\text{otherwise}. \\end{cases } \\label{spikerates}\\end{aligned}\\ ] ] where @xmath223 is the indicator function of whether @xmath8 has spiked on the interval @xmath224 .",
    "we then consider this process up to first order in @xmath214 .",
    "the critical step in computing relevant quantities ( the transfer entropy rate and pathwise transfer entropy ) is in approximating the coarse grained @xmath212 . in this regime",
    "it can be shown ( see appendix [ appb ] for a complete treatment in the @xmath225 regime ) that the coarse grained rate ( @xmath96 and @xmath226 are implicitly taken to infinity ) is given by    @xmath227    where the approximation utilises a single spike ( i.e. the most recent ) in the path history of @xmath8 .",
    "we understand that , in this regime , from a perspective without knowledge of @xmath11 , after any given spike the @xmath8 process appears to be described by a refractory period of duration @xmath213 as before , a subsequent period in which the spike rate grows then a regime from @xmath228 seconds after a spike when it is readily approximated as a markovian poisson process with rate @xmath229 .",
    "such a form could then be readily used to calculate the pathwise transfer entropy using eq .",
    "( [ spikepath ] ) .    the same spike rate can then be utilised to calculate the transfer entropy rate ( a full treatment is found in appendix [ appb ] ) .",
    "crucially , when performing the requisite path integral average , the relevant path probability density introduces an additional term in @xmath214 .",
    "consequently , for this particular calculation in this regime , this has the effect of permitting us to exclude higher order terms associated with mutiple spikes allowing for an even simpler approximation for @xmath212 , equivalent to considering it to be a markov poisson process with rate @xmath229 throughout .",
    "this yields , again with @xmath69 , @xmath70 , @xmath230}}{a\\lambda_y\\tau}\\right]}+\\mathcal{o}(\\lambda_y^2 ) .",
    "\\label{terateexa}\\ ] ] the variation of the transfer entropy rate is shown in fig .",
    "( [ fig1 ] ) .",
    "the transfer entropy rate ( normalised by the limiting mean target spike rate ) for the process obeying rates as described in eq .",
    "( [ spikerates ] ) , with @xmath231 correct to @xmath225 , @xmath232 . ]    the form of eq .",
    "( [ terateexa ] ) reflects the fact that the appropriate approximation is equivalent to considering the spike process in @xmath8 to be a markov poisson process with rate @xmath229 when there is no knowledge of @xmath11 and a markov poisson with rate @xmath233}$ ] when @xmath11 is known .",
    "small increases in @xmath214 lead to increases in the transfer entropy rate , but only because of the subsequent increase in the likelihood of a spike in @xmath8 reflected in the leading @xmath229 term . on the other hand",
    ", we observe a decrease with the same small increase in @xmath214 in the transfer entropy rate normalised by this limiting mean target spike rate , since the increased likelihood renders each spike less surprising and thus less informative .",
    "further , as @xmath216 increases the transfer entropy also increases because the predictability of @xmath8 with knowledge of @xmath11 increases since one can be increasingly confident that a spike in @xmath8 will occur . when @xmath234 or @xmath235 the transfer entropy diverges since in these limits either the uncertainty in the existence of a spike in @xmath8 or in its timing vanishes .      in our final example",
    "we consider a slightly more complicated process for which we compute @xmath212 numerically rather than finding a limit where it can be described analytically .",
    "this allows for an illuminating graphical illustration of the pathwise tranfer entropy along paths in continuous time .",
    "once again the process is assumed to be bipartite and is defined by @xmath236 and @xmath237 .",
    "@xmath212 is then calculated numerically along spike trains ( path functions ) generated by the process allowing a discussion of the transfer entropy .",
    "this numerical procedure is described in appendix [ appc ] .",
    "the process we consider is given by the spike rates @xmath238=\\lambda_{y}\\qquad\\qquad\\qquad\\qquad\\qquad\\forall\\;s , r\\nonumber\\\\ & \\lambda_{x|y}[x^t_{t - s},y^t_{t - r}]=\\lambda_{x|y}[y^{t}_{t - t_{\\text{cut}}}]=\\lambda_{x|y}(t_y^1)\\quad\\forall\\;s\\geq t_{\\text{cut}},r\\nonumber\\\\ & \\quad=\\begin{cases } \\lambda_x^{\\text{base}}&t_y^1\\notin[0,t_{\\text{cut}})\\\\ \\lambda_x^{\\text{base}}+m\\exp{[-\\frac{1}{2\\sigma^2}(t_y^1-\\frac{t_{\\text{cut}}}{2})^2]}&t_y^1\\in[0,t_{\\text{cut}})\\\\ \\qquad - m\\exp{[-\\frac{1}{2\\sigma^2}(\\frac{t_{\\text{cut}}}{2})^2]}. \\label{rate2 } \\end{cases}\\end{aligned}\\ ] ] where @xmath239 is the time _ since _ the last spike in @xmath11 ( in contrast to @xmath240 which represents the time of the first spike in the relevant path history ) and where , again , the system is bipartite such that both @xmath8 and @xmath11 can not spike simultaneously .",
    "this process consists of a background rate on the target @xmath241 which becomes elevated following a source spike in the regime @xmath242 .",
    "specifically we choose this elevation to follow a gaussian form centred on @xmath243 with variance @xmath244 .",
    "the gaussian is then truncated and shifted to ensure continuity in the rate function .",
    "one can think of this system as a hybrid cox - renewal process .",
    "the reason being , once we consider @xmath11 to also be a spiking neuron ( in this cases a poisson process ) , @xmath8 can be thought of as an inhomogeneous poisson process with rate dependent , exclusively , on the process @xmath11 , and specifically the time since the last spike in @xmath11 in the manner of a renewal process . in this example",
    "we utilise parameter @xmath245 .",
    "two simulated spike trains along with the calculated joint & coarse transition rates and annotated resultant pathwise transfer entropy are shown in fig .",
    "( [ fig2 ] ) .",
    "we note that spike rates are chosen , by convention , to be _ cdlg _ , whilst the pathwise transfer entropy , being defined on the right open interval @xmath246 , must be interpreted as _ cgld _ ( left continuous with right limits ) .",
    "we emphasise that @xmath247 , the latter being undefined at target spikes and the former being the time derivative of the component which permits description in terms of local rates .",
    "consequently @xmath248 is defined everywhere and is _ cdlg _ following the convention of right continuity in the spike rates .",
    "we note that discontinuities in all quantities occur at spikes in either @xmath8 or @xmath11 depending on the quantity in question , but that discontinuities originating from spikes in @xmath11 only exist when the previous spike in @xmath11 is within @xmath249 seconds of the spike in question because of the form of the rates in eq .",
    "( [ rate2 ] ) .",
    "we point out that in order to produce values for @xmath250 , a prior history of an absence of spikes in @xmath11 and @xmath8 is assumed on the time interval @xmath251 .",
    "a spike in @xmath8 during the elevated rate period where knowledge of the source process @xmath11 is informative in the predictability of @xmath8 is illustrated at point @xmath252 and is associated with a discontinuous increase in the pathwise transfer entropy .",
    "in contrast including knowledge of @xmath11 at point @xmath253 ( outside of the elevated rate period ) is misinformative and is therefore associated with a discontinuous decrease in the pathwise transfer entropy .",
    "the cluster of target spikes at annotated region @xmath254 is more nuanced . at first",
    "@xmath11 is informative and so there is a large increase in pathwise transfer entropy with the first spike .",
    "however , the contributions associated with subsequent spikes are less significant as the rate function @xmath212 begins to more accurately reflect the elevation in @xmath236 due to the predicative capability it can derive the from the recent spikes in its history .",
    "however , these spikes leave @xmath212 elevated even once knowledge of @xmath11 has predicted the exit from the elevated rate period , and so @xmath11 is misinformative about the arrival of the final target spike in this region .",
    "considering instead the continuously varying non - spiking component , there are broadly two distinct situations .",
    "decreases are associated with knowledge of the source suggesting an increase in likelihood of spikes over knowledge of just the target , but with no anticipated spike arriving .",
    "this occurs in annotated region @xmath255 , an elevated rate period where no spikes occur .",
    "in contrast when knowledge of the source suggests a lower likelihood of spikes over that arising from knowledge of the target alone , and no spikes occur , the inclusion of @xmath11 provides a better estimate leading to a positive contribution .",
    "this can occur , for this process , when there are no recent spikes in either the source or target , for example , in annotated zone e. we expect , for this finite sample , both contributions to approximately cancel because , on average over the ensemble , the non - spiking contribution must be zero as indicated by eq .",
    "( [ nonspike ] ) .",
    "finally we point out that because the discontinuous and continuous contributions are based on the prediction of opposite behaviour ( spiking vs. not spiking ) whenever @xmath256 then @xmath257 and vice versa .",
    "in this paper we have introduced a generalisation of the transfer entropy in terms of radon - nikodym derivatives between probability measures and an extension to continuous time systems . for a consistent notion of transfer entropy to exist",
    "we have emphasised that we must deal with transfer entropy rates .",
    "we have also shown , however , that the notion of a _ local _ transfer entropy rate is not generally well defined .",
    "the natural solution , therefore , is to deal with integrated quantities which do exist .",
    "the implication is clear : transfer entropy should be understood as a _ dynamical _ quantity accumulated along evolution of some process .",
    "consequently the statement ` the transfer entropy at time @xmath140 ' is not strictly complete , but should be formally associated with a time interval over which it has been accumulated .",
    "this interpretation holds in both continuous and discrete time , where in the latter the time interval is usually `` one time step '' ( for which the units are often implicit , ignored or arbitrary ) .",
    "this places transfer entropy within the same family of physical quantities such as work and heat , for which there are rich accounts of their description as functionals constructed from probability measures of paths @xcite .",
    "this underlines some of the more modern advances revealing parallels between information - theoretic and thermodynamic quantities , e.g. @xcite .    in general , there is no obvious way to proceed with an empirical estimate of these transfer entropies for arbitrary continuous time processes aside from the brute force approach of time - binning",
    "however , by starting from an appropriate continuous time formulation , we have pointed out that there exist classes of stochastic processes in continuous time where the constituent measures may be directly written down with a finite number of variables , allowing us to sidestep time binning and its associated issues .",
    "a key example of these are counting processes which can be readily utilised to model spike train processes , for which we have presented the transfer entropy rates and contributions outlined above .",
    "such a result promises to be of great utility within computational neuroscience both theoretically and empirically . in future work",
    "we will outline an estimation algorithm which can exploit the formalism presented here for spiking or point processes such that it can be applied to empirical spike ( or event ) timing data .",
    "challenges for such an algorithm centre around accurately and efficiently estimating the history - dependent spike rates .",
    "we expect such an estimator to be able to sidestep the issues associated with time - binning ( undersampling , etc . ) specifically because our formulation permits a compressed representation of path histories in terms of spike times ( i.e. @xmath208 , as per eq .",
    "( [ spikepath ] ) ) .",
    "jl was supported through the australian research council decra grant de160100630 , and a faculty of engineering and it early career researcher and newly appointed staff development scheme 2016 grant .",
    "we thank lionel barnett and michael wibral for helpful comments on this manuscript .",
    "using the transition and escape rates defined in section [ sec : jump ] we can construct path probability measures of a jump process , @xmath76 , running from time @xmath154 to time @xmath155 that satisfy eq .  ( [ meas ] ) .",
    "we reiterate that for a path that consists of @xmath137 transitions in @xmath8 such that transitions may be labelled by the index @xmath156 we write the state labels @xmath157 as the state into which the system transitions at time @xmath139 , with @xmath136 indicating the initial time , and @xmath158 the initial state .    since we can characterise any path by an unbounded , but _",
    "countable _ , number of variables in this way we can directly write the probability measure for a given cylinder set .",
    "we do this by writing @xmath258 and understand it to mean that the path contains precisely @xmath137 tranitions with @xmath259 , @xmath260 , given initial state @xmath135 at starting time @xmath136 . for simplicity",
    "we assume @xmath261 , @xmath262 @xmath263 and @xmath264 . by recognising that we can rewrite the rates in eqs .",
    "( [ wrates ] ) as @xmath265}w[{x}'|{{x}}_{t'-s}^{t'}]dt ' = \\lim_{dt\\to 0}\\mathbb{p}_{[t , t+dt]}[{x}'\\in[t , t+dt]|{{x}}_{t - s}^{t}]$ ] we can generalise to an entire path which utilise integrals over finite time intervals by including finite probability measures of having no transition during the appropriate intervals such that @xmath266=\\int_{\\mathcal{a}_1^{n_x}}d\\mathbb{p}_{x}^{(s)}[x_{t_0}^{t}|x^{t_0}_{t_0-s}]\\nonumber\\\\ & = \\sum_{x_1\\in\\mathcal{a}^1}\\ldots \\sum_{x_{n_x}\\in\\mathcal{a}^{n_x}}\\int_{\\mathcal{a}_1}dt_1\\ldots\\int_{\\mathcal{a}_{n_x}}dt_n\\nonumber\\\\ & \\left(\\prod_{i=1}^{n_x}w[x_{i}|x^{t_i}_{t_i - s}]\\mathbb{p}^{(s)}[x_{t'}=x_i \\:\\forall\\ : t'\\in [ t_{i-1},t_i)]\\right)\\nonumber\\\\ & \\quad\\times \\mathbb{p}^{(s)}[x_{t'}=x_{n_x } \\:\\forall\\ : t'\\in [ t_{n_x},t)],\\end{aligned}\\ ] ] where the ( finite ) probability measures , @xmath267 , implicitly depend on @xmath96 seconds of prior history at all times .",
    "we may identify the form of @xmath267 by recognising that we must have @xmath268}{dt_j}=\\nonumber\\\\ & \\qquad-\\lambda_x[x^{t_j}_{t_j - s}]\\mathbb{p}^{(s)}[x_{t'}=x_j \\:\\forall\\ : t'\\in [ t_{j-1},t_j)]\\end{aligned}\\ ] ] which has solution @xmath269=\\exp{\\left[-\\int_{t_{j-1}}^{t_j}\\lambda_x[x^{t'}_{t'-s}]dt'\\right]}\\end{aligned}\\ ] ] given boundary condition @xmath270=1 $ ] for @xmath271 .",
    "we point out that for consistency we have @xmath270=p_0^{(s)}[x^{t_j}_{t_{j-1}}\\equiv\\{t_j,\\{t_{j-1},x_{t_{j-1}}\\}\\}|x^{t_{j-1}}_{t_{j-1}-s}]$ ] . alternatively , and",
    "perhaps more intuitively , we see that such a form agrees with the limit of a time discretisation where the probability of not transitioning is considered at every timestep viz .",
    "@xmath272\\nonumber\\\\ & \\quad = \\lim_{dt\\to 0}\\prod_{i={t_{j-1}/dt}}^{t_j / dt}(1-\\lambda_x[x^{idt}_{idt - s}]dt)\\nonumber\\\\ & \\quad=\\exp{\\left[-\\int_{t_{j-1}}^{t_j}\\lambda_x[x^{t'}_{t'-s}]dt'\\right]}+\\mathcal{o}(dt^2)\\end{aligned}\\ ] ] where we simplify by recognising the form of the taylor series of the exponential to first order in @xmath273",
    ". consequently we may write @xmath266=\\int_{\\mathcal{a}_1^{n_x}}d\\mathbb{p}_{x}^{(s)}[x_{t_0}^{t}|x^{t_0}_{t_0-s}]\\nonumber\\\\ & = \\sum_{x_1\\in\\mathcal{a}^1}\\ldots \\sum_{x_{n_x}\\in\\mathcal{a}^{n_x}}\\int_{\\mathcal{a}_1}dt_1\\ldots\\int_{\\mathcal{a}_{n_x}}dt_{n_x}\\nonumber\\\\ & \\quad\\left(\\prod_{i=1}^{n_x}w[x_{i}|x^{t_i}_{{t_{i}}-s}]\\right)\\exp{\\left[-\\int_{t_0}^{t}\\lambda_x[x^{t'}_{t'-s}]dt'\\right]}. \\label{jumpmeasure}\\end{aligned}\\ ] ] this then naturally forms a probability density for the path with units @xmath274 @xmath161=\\nonumber\\\\ & \\quad\\left(\\prod_{i=1}^{n_x}w[x_{i}|x^{t_i}_{{t_{i}}-s}]\\right)\\exp{\\left[-\\int_{t_0}^{t}\\lambda_x[x^{t'}_{t'-s}]dt'\\right ] } \\label{eq : probden0}\\end{aligned}\\ ] ] where again @xmath163 meaning we can represent any path @xmath164 . we note that the product term in eq .",
    "( [ eq : probden0 ] ) is over the @xmath137 transitions of @xmath8 , whilst the remaining exponentiated integral term relates to waiting times between transitions .",
    "expectations are taken w.r.t .",
    "this measure by performing an infinite series of integrals of the following form @xmath275\\right]=\\int_{\\omega_x}f[x_{t_0}^t]d\\mathbb{p}_{x}^{(s)}[x_{t_0}^t]\\nonumber\\\\ & = \\lim_{n_x\\to\\infty}f_0(x^t_{t_0}\\equiv\\{t,\\{t_0,x_0\\}\\})p_0^{(s)}[x^t_{t_0}\\equiv\\{t,\\{t_0,x_0\\}\\}|x^{t_0}_{t_0-s}]\\nonumber\\\\ & + \\sum_{\\substack{x_1\\in\\sigma_{x } \\\\",
    "x_1\\neq x_{0}}}\\int_{t_0}^{t}dt_1 f_1(x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0 ^ 1\\})\\nonumber\\\\ & \\qquad\\qquad\\quad\\times p_1^{(s)}[x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0 ^ 1\\}|x^{t_0}_{t_0-s}]\\nonumber\\\\ & \\quad+\\sum_{\\substack{x_2\\in\\sigma_{x } \\\\ x_2\\neq x_1}}\\sum_{\\substack{x_1\\in\\sigma_{x } \\\\",
    "x_1\\neq x_{0}}}\\int_{t_0}^{t}dt_1\\int_{t_1}^{t}dt_2 f_2(x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0 ^ 2\\})\\nonumber\\\\\\nonumber\\\\ & \\qquad\\qquad\\qquad\\times p_2^{(s)}[x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0 ^ 2\\}|x^{t_0}_{t_0-s}]\\nonumber\\\\ & \\quad+\\ldots\\nonumber\\\\ & \\quad+\\sum_{\\substack{x_{n_x}\\in\\sigma_{x } \\\\",
    "x_{n_x}\\neq x_{n_x-1}}}\\ldots\\sum_{\\substack{x_1\\in\\sigma_{x } \\\\",
    "x_1\\neq x_{0}}}\\int_{t_0}^{t}dt_1\\ldots\\int_{t_{n_x-1}}^{t}dt_{n_x}\\nonumber\\\\ & \\quad\\times f_{n_x}(x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0^{n_x}\\})p_{n_x}^{(s)}[x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0^{n_x}\\}|x^{t_0}_{t_0-s}]\\end{aligned}\\ ] ] where @xmath168 is the functional form that @xmath171 $ ] when there are @xmath137 transitions in @xmath8 on the interval @xmath81 and where @xmath175 is the probability density for a path on @xmath176 that contains @xmath170 transitions , conditional upon the previous path function @xmath177 , where transition rates utilise @xmath96 seconds of history dependence .",
    "such a form is then stated more concisely through eq .",
    "( [ jsum ] ) .",
    "we note that @xmath175 would also be a density with respect to @xmath178 should @xmath8 be continuous .",
    "whilst the above is formalised to include only knowledge of @xmath8 this can be trivially extended to include knowledge of @xmath11 such that we can describe the properties of @xmath74 with appropriate dependence in the transition and escape rates such that we use probability densities @xmath162=\\nonumber\\\\ & \\quad\\left(\\prod_{i=1}^{n_x}w[x_{i}|x^{t_i}_{{t_{i}}-s},y^{t_i}_{{t_{i}}-r}]\\right)\\exp{\\left[-\\int_{t_0}^{t}\\lambda_{x|y}[x^{t'}_{t'-s},y^{t'}_{t'-r}]dt'\\right]}. \\label{probden}\\end{aligned}\\ ] ] +   + we now have path measures which reduce to functions of the transition times which are continuous variables .",
    "the natural information theoretic interpretation leads to differential entropies , which have known issues surrounding positivity and scale invariance amongst others . however , transfer entropy , identified as a function of a radon - nikodym derivative avoids these issues in all ( e.g. discrete and/or continuous ) potential state spaces .",
    "we form the pathwise transfer entropy by first considering the radon - nikoym derivative between the two measures on samples @xmath134 which must satisfy @xmath276&=\\int_{\\mathcal{a}}\\exp{\\left[\\mathcal{t}^{(s , r)}_{y\\to x}[x^t_{t_0},y^t_{t_0}]\\right]}d\\mathbb{p}^{(s)}_x[x_{t_0}^t]\\nonumber\\\\ & = \\int_{\\mathcal{a}}\\frac{d\\mathbb{p}^{(s , r)}_{x|\\{y\\}}[x_{t_0}^t]}{d\\mathbb{p}^{(s)}_x[x_{t_0}^t]}d\\mathbb{p}^{(s)}_x[x_{t_0}^t ] .",
    "\\label{eq : radnik}\\end{aligned}\\ ] ] we can compute this , heuristically , but safely in this instance , by considering the limit @xmath277}{d\\mathbb{p}_{x}^{(s)}[x_{t_0}^t|x_{t_0-s}^{t_0}]}\\nonumber\\\\ & \\quad=\\lim_{\\mathcal{a}_{1}^{n_x}\\to\\{t,\\{t , x\\}_0^{n_x}\\}}\\frac{\\mathbb{p}_{x|\\{y\\}}^{(s , r)}[x_{t_0}^t\\in\\mathcal{a}_{1}^{n_x}|x_{t_0-s}^{t_0},\\{y^t_{t_0-r}\\}]}{\\mathbb{p}_{x}^{(s)}[x_{t_0}^t\\in\\mathcal{a}_{1}^{n_x}|x_{t_0-s}^{t_0}]}\\nonumber\\\\ & \\quad=\\frac{p_{n_x}^{(s , r)}[x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0^{n_x}\\}|x_{t_0-s}^{t_0},\\{y_{t_0-r}^{t}\\}]}{p_{n_x}^{(s)}[x^t_{t_0}\\equiv\\{t,\\{t , x\\}_0^{n_x}\\}|x_{t_0-s}^{t_0}]}\\nonumber\\\\ & \\quad=\\left(\\prod_{i=1}^{n_x}\\frac{w[x_{t_i}|x^{t_i}_{{t_{i}}-s},y^{t_i}_{{t_{i}}-r}]}{w[x_{t_i}|x^{t_i}_{{t_{i}}-s}]}\\right)\\nonumber\\\\ & \\quad\\quad\\times\\exp{\\left[-\\int_{t_0}^{t}(\\lambda_{x|y}[x^{t'}_{t'-s},y^{t'}_{t'-r}]-\\lambda_x[x^{t'}_{t'-s}])dt'\\right]},\\end{aligned}\\ ] ] which by comparison with eq .  ( [ jumpmeasure ] ) can be used , as expected , as a change of measure ( c.f .",
    "( [ eq : radnik ] ) ) . the pathwise transfer entropy appearing in eq .",
    "( [ eq : local ] ) then directly follows .",
    "in this appendix we wish to give an account of the spiking neuron model in the low source spike rate , leading order in @xmath214 , regime . to this end",
    "we present both the transfer entropy rate to leading order in @xmath214 and a scheme for approximating the pathwise transfer entropy , again to first order in @xmath214 .",
    "the model set up specifies a constant @xmath278 outside of the refractory period of length @xmath213 in @xmath11 , and specifies that @xmath279 $ ] up until the first spike in @xmath8 up to @xmath215 seconds after a spike in @xmath11 and zero at all other times or when @xmath8 is within its refractory period also of length @xmath213 .",
    "whilst these are aspects are immediately defined by the model , @xmath212 is not and so we must calculate its value , up to @xmath225 for our purposes . +   + to do",
    "so we formulate the spike rate in @xmath8 , informally , but safely , by the expression @xmath280=\\nonumber\\\\ & \\lim_{\\mathcal{a}_1^{n_x}\\to\\{q , t,\\{t\\}_1^{n_x}\\}}\\frac{\\lim_{dt\\to 0 } ( dt)^{-1}\\mathbb{p}_{x}[x_{\\text{spike}}\\in[t , t+dt]\\cap x_{t - q}^t\\in \\mathcal{a}_1^{n_x } ] } { \\mathbb{p}_{x}[x_{t - q}^t\\in\\mathcal{a}_1^{n_x } ] } \\label{main}\\end{aligned}\\ ] ] where @xmath281 .",
    "we may represent the whole joint path by @xmath282 and thus represent the denominator , dropping the explicit equivalence in earlier notation , as @xmath283=\\int_{\\mathcal{a}_1^{n_x}\\times{\\omega_y^{[t - q , t]}}}d\\mathbb{p}_{xy}[x_{t - q}^t , y_{t - q}^t]\\nonumber\\\\ & = \\lim_{n_y\\to\\infty } \\int_{\\mathcal{a}_1}dt^{x}_1\\ldots \\int_{\\mathcal{a}_{n_x}}dt^{x}_{n_x}p_{n_x,0}(q , t,\\{t^x\\}_1^{n_x})\\nonumber\\\\ & + \\int_{t - q}^{t}dt^y_1\\int_{\\mathcal{a}_1}dt^{x}_1\\ldots \\int_{\\mathcal{a}_{n_x}}dt^{x}_{n_x}p_{n_x,1}(q , t,\\{t^x\\}_1^{n_x},t^y_1)\\nonumber\\\\ & + \\ldots\\nonumber\\\\ & + \\int_{t - q}^{t}dt^y_1\\ldots \\int_{t^y_{n_y-1}}^{t}dt^y_{n_y}\\int_{\\mathcal{a}_1}dt^{x}_1\\ldots \\int_{\\mathcal{a}_{n_x}}dt^{x}_{n_x}\\nonumber\\\\ & \\qquad\\times p_{n_x , n_y}(q , t,\\{t^x\\}_1^{n_x},\\{t^y\\}_1^{n_y } ) \\label{int}\\end{aligned}\\ ] ] where @xmath284 is the probability density function for a path with @xmath170 spikes in @xmath8 and @xmath186 spikes in @xmath11 and @xmath285}$ ] is the entire relevant path space for trajectories in @xmath11 on @xmath286 $ ] .",
    "the numerator is then given by @xmath287\\cap x_{t - q}^t\\in\\mathcal{a}_1^{n_x}]\\nonumber\\\\ & = \\lim_{dt\\to 0}\\frac{1}{dt}\\int_{\\mathcal{a}_1^{n_x}\\times{\\omega_y^{[t - q , t+dt]}}}d\\mathbb{p}_{xy}[x_{t - q}^{t+dt},y^{t+dt}_{t - q}|t^x_{n_x+1}\\in [ t+dt]]\\nonumber\\\\ & = \\lim_{n_y\\to\\infty } \\int_{\\mathcal{a}_1}dt^{x}_1\\ldots \\int_{\\mathcal{a}_{n_x}}dt^{x}_{n_x}\\nonumber\\\\ & \\qquad\\times\\lambda_{x|y}^{n_x,0}(q , t,\\{t^x\\}_1^{n_x})p_{n_x,0}(q , t,\\{t^x\\}_1^{n_x})\\nonumber\\\\ & + \\int_{t - q}^{t}dt^y_1\\int_{\\mathcal{a}_1}dt^{x}_1\\ldots \\int_{\\mathcal{a}_{n_x}}dt^{x}_{n_x}\\nonumber\\\\ & \\qquad\\times\\lambda_{x|y}^{n_x,1}(q , t,\\{t^x\\}_1^{n_x},t^y_1)p_{n_x,1}(q , t,\\{t^x\\}_1^{n_x},t^y_1)\\nonumber\\\\ & + \\ldots\\nonumber\\\\ & + \\int_{t - q}^{t}dt^y_1\\ldots \\int_{t^y_{n_y-1}}^{t}dt^y_{n_y}\\int_{\\mathcal{a}_1}dt^{x}_1\\ldots \\int_{\\mathcal{a}_{n_x}}dt^{x}_{n_x}\\nonumber\\\\ & \\quad\\times \\lambda_{x|y}^{n_x , n_y}(q , t,\\{t^x\\}_1^{n_x},\\{t^y\\}_1^{n_y})p_{n_x , n_y}(q , t,\\{t^x\\}_1^{n_x},\\{t^y\\}_1^{n_y})\\end{aligned}\\ ] ] where @xmath288 is the spike rate in @xmath8 given @xmath170 spikes in the history of @xmath8 and @xmath186 spikes in the history of @xmath11 and @xmath289}$ ] is the entire relevant path space for trajectories in @xmath11 on @xmath290 $ ] .",
    "since , in our example , @xmath291 we can truncate these infinite series . to know where we are permitted to truncate the series depends upon the dependence on the history dependence of @xmath292 $ ] . in our example each spike in @xmath8 must be preceded by a spike in @xmath11 .",
    "consequently , since we are considering only @xmath293 ) contributions , we consider only ( up to ) one spike in the history of @xmath8 , @xmath294 , such that we may consider @xmath295=\\lambda_x^1(q , t , t^x_1)$ ] or @xmath296=\\lambda_x^0(q , t)$ ] ( where @xmath297 is the spike rate given @xmath170 spikes in the history of @xmath8 ) .",
    "proceeding , for now , with the @xmath298 case , we must include the spike in @xmath11 that preceded the spike in the history of @xmath8 , but also the spike that precedes the ( potential ) spike in question at time @xmath140 meaning all terms below @xmath299 in the numerator and the @xmath300 term in the denominator must vanish .",
    "expanding the remaining series about @xmath301 we then have , to first order in @xmath214 , @xmath302 we point out that because , in our example process , @xmath11 is independent of @xmath8 and is independent of its past behaviour outside of a refractory period , we can directly write the above probability densities despite only knowing the conditional spike rates . further , in our example , we recognise that a spike in @xmath8 must occur within @xmath215 seconds of a spike in @xmath11 so we can fix the timing of the ( previous ) single spike in @xmath8 , @xmath303 and set @xmath304 such that we have a result valid for all @xmath305 , leaving @xmath140 as the only free variable",
    ". consequently we drop the dependence on @xmath304 and write @xmath306 to proceed we need to establish the probability densities which for the specified process are given by @xmath307\\\\   \\quad\\times e^{-\\lambda_y(t-\\text{min}[t , t^y_1+\\tau^r])}e^{\\lambda_{x|y}^et^y_1},&\\\\   0,&t^y_1\\notin[-\\tau,0 ] .",
    "\\end{cases }   \\end{aligned}\\ ] ] @xmath308 \\\\",
    "\\times e^{-\\lambda_y(t^y_2-(t^y_1+\\tau^r))}&t^y_2\\in[\\text{max}[\\tau^r , t-\\tau],t]\\\\ \\times e^{-\\lambda_y(t-\\text{min}[t , t^y_2+\\tau^r])}&\\\\   \\times e^{\\lambda_{x|y}^e t^y_1}e^{-\\lambda_{x|y}^e\\text{max}[\\tau , t - t^y_2]},&\\\\   0,&t^y_1\\notin[-\\tau,0]\\\\   & \\text{or}\\\\   & t^y_2\\notin[\\text{max}[\\tau^r , t-\\tau],t ]   \\end{cases}.   \\end{aligned}\\ ] ] we can implement such forms via the integrals @xmath309)}e^{\\lambda_{x|y}^et^y_1}\\\\   & \\int_{-\\tau}^t dt^y_1\\int_{t^y_1}^t dt^y_2 \\lambda_{x|y}^{1,2}(t , t^x_1=0,\\{t^y\\}_1 ^ 2)p(t , t^x_1=0,\\{t^y\\}_1 ^ 2)\\nonumber\\\\   & = \\int_{-\\tau}^{0}dt^y_1\\int_{\\text{min}[t,\\text{max}[\\tau^r , t-\\tau]]}^{t}dt^y_2 ( \\lambda_y \\lambda_{x|y}^e)^2 dte^{-\\lambda_y(t^y_1+\\tau)}\\nonumber\\\\   & \\qquad\\qquad\\times e^{-\\lambda_y(t^y_2-(t^y_1+\\tau^r))}e^{-\\lambda_y(t-\\text{min}[t , t^y_2+\\tau^r])}\\nonumber\\\\   & \\qquad\\qquad\\times e^{\\lambda_{x|y}^et^y_1}e^{-\\lambda_{x|y}^e\\text{max}[\\tau , t - t^y_2]}\\nonumber\\\\   & = \\int_{\\text{min}[t,\\text{max}[\\tau^r , t-\\tau]]}^{t}dt^y_2 \\int_{-\\tau}^{0}dt^y_1(\\lambda_y \\lambda_{x|y}^e)^2 dte^{-\\lambda_y(t^y_2+(\\tau-\\tau^r))}\\nonumber\\\\   & \\qquad\\qquad\\qquad\\qquad\\times e^{-\\lambda_y(t-\\text{min}[t , t^y_2+\\tau^r])}e^{\\lambda_{x|y}^et^y_1}e^{-\\lambda_{x|y}^e(t - t^y_2)}\\nonumber\\\\   & = \\lambda_y^2 \\lambda_{x|y}^e dt\\left(e^{\\lambda_{x|y}^e\\tau}-1\\right)e^{-\\lambda_{x|y}^e(t+\\tau)-\\lambda_y(t+\\tau-\\tau^r ) } \\nonumber\\\\   & \\qquad\\qquad\\times \\int_{\\text{min}[t,\\text{max}[\\tau^r , t-\\tau]]}^{t}dt^y_2e^{\\lambda_{x|y}^et^y_2-\\lambda_y(t^y_2-\\text{min}[t , t^y_2+\\tau^r])}.   \\end{aligned}\\ ] ] we note the assumption of @xmath310 allows us to swap the order of the integrals as the second spike in @xmath11 is rendered independent of @xmath311 .",
    "now , from the refractory period constraint we know that @xmath312 for @xmath313 so we can ignore the computation for such a regime .",
    "consequently , for the denominator , we can write @xmath314)}e^{\\lambda_{x|y}^et^y_1}=\\nonumber\\\\   & \\int_{-\\tau}^{0}dt^y_1 \\lambda_y \\lambda_{x|y}^e e^{-\\lambda_y(t^y_1+\\tau)}e^{-\\lambda_y(t - t^y_1+\\tau^r)}e^{\\lambda_{x|y}^et^y_1},\\quad t\\geq \\tau^r\\nonumber\\\\ & = \\lambda_ye^{-\\lambda_{x|y}^e\\tau-\\lambda_y(t+\\tau-\\tau^r)}(e^{\\lambda_{x|y}^e\\tau}-1),\\quad t\\geq \\tau^r   \\label{eq : appadenominator }   \\end{aligned}\\ ] ] the numerator , however , is more complicated and can be written @xmath315}^{t}dt^y_2e^{\\lambda_{x|y}^et^y_2-\\lambda_y(t^y_2-\\text{min}[t , t^y_2+\\tau^r])}\\nonumber\\\\   & = \\lambda_y^2 \\lambda_{x|y}^e dt(e^{\\lambda_{x|y}^e\\tau}-1)e^{-\\lambda_{x|y}^e(t+\\tau)-\\lambda_y(t+\\tau-\\tau^r)}\\nonumber\\\\   & \\times    \\begin{cases }   0,&t<\\tau^r\\\\\\\\   \\int_{\\tau^r}^te^{\\lambda_{x|y}^et^y_2-\\lambda_y(t^y_2-t ) } , & \\tau^r\\leq t<\\tau^r+\\tau\\\\\\\\   \\int_{t-\\tau}^te^{\\lambda_{x|y}^et^y_2-\\lambda_y(t^y_2-t ) } , & t\\geq\\tau^r+\\tau   \\end{cases}\\nonumber\\\\    & = \\begin{cases }   0,&t<\\tau^r\\\\\\\\   \\lambda_y^2\\lambda_{x|y}^edt(\\lambda_{x|y}^e-\\lambda_y)^{-1 } , & \\tau^r\\leq t<\\tau^r+\\tau\\\\   \\times ( e^{\\lambda_{x|y}^e\\tau}-1)e^{-(\\lambda_{x|y}^e+\\lambda_y)(t+\\tau)}\\\\   \\times ( e^{\\lambda_{x|y}^et+\\lambda_y\\tau^r}-e^{\\lambda_{x|y}^e\\tau^r+\\lambda_yt})\\\\\\\\   \\lambda_y^2\\lambda_{x|y}^edt(\\lambda_{x|y}^e-\\lambda_y)^{-1 } , & t\\geq\\tau^r+\\tau\\\\   \\times ( e^{\\lambda_{x|y}^e\\tau}-1)(e^{\\lambda_{x|y}^e\\tau}-e^{\\lambda_y\\tau})\\\\   \\times e^{-2\\lambda_{x|y}^e\\tau-\\lambda_y(t+\\tau-\\tau^r ) }   \\end{cases}.   \\label{eq : appanumerator }   \\end{aligned}\\ ] ] considering the ratio of the results eq .  ( [ eq : appanumerator ] ) and eq .  ( [ eq : appadenominator ] ) , inserting @xmath316 $ ] and discarding all @xmath317 terms and higher we find @xmath318 allowing one to calculate the pathwise transfer entropy contributions set out in eq .",
    "( [ eq : local ] ) up to @xmath225 . returning to the @xmath319 case we must then have , by continuity arguments , @xmath320 .",
    "+   + to compute the transfer entropy rate we have , equivalently , @xmath321\\right]\\nonumber\\\\   & = \\frac{1}{(t - t_0)}\\mathbb{e}_{p}\\left[\\sum_{i=1}^{n_x}\\delta \\mathcal{t}_{t}(t_i)\\right]\\nonumber\\\\   & = \\frac{1}{(t - t_0)}\\mathbb{e}_{p}\\left[\\sum_{i=1}^{n_x}\\ln{\\frac{\\lambda_{x|y}^e}{\\lambda_{x}[x_{t_i-(\\tau+\\tau^r)}^{t_i}]}}\\right]\\nonumber\\\\   \\dot{t}_{y\\to x}&=\\mathbb{e}_{p}\\left [ \\delta\\mathcal{t}_{t}(t)\\right]\\nonumber\\\\    & = \\mathbb{e}_{p}\\left[(1-\\delta_{x_t^-x_t})\\ln{\\frac{\\lambda_{x|y}^e}{\\lambda_{x}[x_{t-(\\tau+\\tau^r)}^{t}]}}\\right ] .",
    "\\end{aligned}\\ ] ] considering only @xmath225 contributions allows for up to one transition in @xmath11 in the path measure such that the only contributing component of the integral of the form in eq .",
    "( [ int ] ) is @xmath322 . taking the latter transfer entropy rate definition we may consequently write @xmath323}}{\\lambda_x^0(t)\\tau}\\right]}\\nonumber\\\\   & = \\int_{t-\\tau}^{t}\\lambda_{x|y}^e\\lambda_ye^{-\\lambda_y(t^y_1-(t-\\tau))-\\lambda_{x|y}^e(t - t^y_1)}\\ln{\\left[-\\frac{\\ln{[1-a]}}{\\lambda_x^0(t)\\tau}\\right]}\\nonumber\\\\    & = ( 1-e^{-\\lambda_{x|y}^e\\tau})\\lambda_y\\ln{\\left[-\\frac{\\ln{[1-a]}}{\\lambda_x^0(t)\\tau}\\right]}+\\mathcal{o}(\\lambda_y^2)\\nonumber\\\\      & = a\\lambda_y\\ln{\\left[-\\frac{\\ln{[1-a]}}{a\\lambda_y\\tau}\\right]}+\\mathcal{o}(\\lambda_y^2).\\end{aligned}\\ ] ] for completeness",
    "we may equivalently write the former definition , acknowledging that in the @xmath225 regime we have @xmath294 , @xmath324}}{\\lambda_x^0(t^x_1)\\tau}\\right]}\\nonumber\\\\   & \\qquad\\qquad+\\mathcal{o}(\\lambda_y^2)\\nonumber\\\\   & = \\frac{1}{(t - t_0)}\\int_{t_0}^{t}dt^x_1p_1(t , t^x_1)\\ln{\\left[-\\frac{\\ln{[1-a]}}{\\lambda_x^0(t^x_1)\\tau}\\right]}+\\mathcal{o}(\\lambda_y^2 ) .   \\end{aligned}\\ ] ] we can write the probability density @xmath325 once again the continuity requirements dictate that @xmath326 so that @xmath327}}{\\lambda^0_x(t^x_1)\\tau}\\right]}+\\mathcal{o}(\\lambda_y^2)\\nonumber\\\\      = & a\\lambda_y\\ln{\\left[-\\frac{\\ln{[1-a]}}{a\\lambda_y\\tau}\\right]}+ \\mathcal{o}(\\lambda_y^2 ) .   \\end{aligned}\\ ] ]",
    "here we present a numerical scheme for computing the coarse grained spike rate given a bipartite co - spiking system .",
    "we imagine that in such systems the behaviour , of the joint system , at time @xmath140 , is completely described by the conditional spike rates @xmath328 $ ] and @xmath329 $ ] such that the parameters @xmath330 , @xmath331 , @xmath332 and @xmath333 represent a finite reliance on the past in a manner analogous to a markov order in discrete time systems .",
    "a true markov system is achieved in the limit of these quantities going to zero . however , when calculating the spike rate @xmath212 without knowledge of @xmath11 the spike rates may have an , in principle , infinite dependence on its past owing to the correlations that arise from the bi - directional influence between the two . taking our previously established definiton of the coarse grained spike rate in the form of eq .",
    "( [ main ] ) in @xmath8 , @xmath334 $ ] , we introduce , for brevity , the notation @xmath335 such that @xmath336=\\nonumber\\\\ & \\frac{\\int dy^t_{t - s } \\lambda_{x|y}^{n_x,\\cdot}(\\{t^x\\}_1^{n_x},y^t_{t - s})p_{n_x,\\cdot}(\\{t^x\\}_1^{n_x},y^t_{t - s})}{\\int dy^t_{t - s}p_{n_x,\\cdot}(\\{t^x\\}_1^{n_x},y^t_{t - s})}\\end{aligned}\\ ] ] such that @xmath337 represents the probability densities ( and analogously @xmath338 for spike rates ) used in the impicit sum over @xmath339 for paths that contain @xmath137 spikes in @xmath8 and @xmath186 spikes in @xmath11 over a process of @xmath96 seconds duration . however , given that we can only construct probability densities from conditional spike rates we must , in general , always specify the relevant conditioning , i.e. we can not write @xmath340 but instead must write , by virtue of the process being bipartite , @xmath341 where @xmath342 . using such densities , and integrating over all @xmath343 would unavoidably lead to dependence in the calculated spike rate on @xmath344 which can not , generally , be guaranteed not to change its value .",
    "instead , we must recognise that we can not remove conditioning on some previous spike history , since to integrate over it introduces more conditional spike history , and instead must render it irrelevant to our calculation . to do so",
    "we recognise that because we have specifed strict markov orders in @xmath236 and @xmath237 any additional dependence in the coarse grained spike rate arises from correlation with the past and thus must decay with that correlation .",
    "consequently we write @xmath345=\\lim_{s'\\to\\infty}\\lambda_{x|y}[x^t_{t - s},x^{t - s'}_{t-(s'+a)},y^{t - s'}_{t-(s'+b)}]\\ ] ] which can be achieved , approximately with finite @xmath346 , by integrating over all sequences for @xmath347 and @xmath348 using the probability densities @xmath349 $ ] indicating the set of probability densities of the form @xmath350 $ ] . as such we may utilise the following representation for @xmath351 $ ]    @xmath352p_{n_x,\\cdot,\\cdot}[\\{t^x\\}_1^{n_x},x^{t - s}_{t - s'},y^{t}_{t - s'}|x^{t - s'}_{t-(s'+a)},y^{t - s'}_{t-(s'+b)}]}{\\int dy^t_{t - s'}\\int dx^{t - s}_{t - s'}p_{n_x,\\cdot,\\cdot}[\\{t^x\\}_1^{n_x},x^{t - s}_{t - s'},y^{t}_{t - s'}|x^{t - s'}_{t-(s'+a)},y^{t - s'}_{t-(s'+b)}]}\\end{aligned}\\ ] ]    where @xmath353\\nonumber\\\\ & = p_{n_x+n'_x , n_y}[x^t_{t - s'}\\equiv\\{s',t,\\{t^x\\}_{1}^{n'_x+n_x},\\{t^y\\}_1^{n_y}\\}\\}|x^{t - s'}_{t-(s'+a)},y^{t - s'}_{t-(s'+b)}]\\nonumber\\\\ & = p_{n_x+n'_x}^{(\\tau^{xx},\\tau^{xy})}[x^t_{t - s'}\\equiv\\{s',t,\\{t^x\\}_{1}^{n'_x+n_x}\\}|x^{t - s'}_{t-(s'+\\tau^{xx})},\\{y^t_{t - s'}\\equiv\\{s',t,\\{t^y\\}_1^{n_y}\\},y^{t - s'}_{t-(s'+\\tau^{xy})}\\}]\\nonumber\\\\ & \\quad\\times p_{n_y}^{(\\tau^{yx},\\tau^{yy})}[y^t_{t - s'}\\equiv\\{s',t,\\{t^y\\}_{1}^{n_y}\\}|y^{t - s'}_{t-(s'+\\tau^{yy})},\\{x^t_{t - s'}\\equiv\\{s',t,\\{t^x\\}_1^{n_x+n'_x}\\},x^{t - s'}_{t-(s'+\\tau^{yx})}\\}]\\end{aligned}\\ ] ]    from the bipartite property of the process with the last line expressible by two probability densities of the form in eq .",
    "( [ probden ] ) .",
    "this is then a series of ( nested ) summations and integrals which can be readily approximated using a discrete time scheme .",
    "naturally , if capturing all possible path dependence in @xmath8 , such that @xmath354 , the path integral over @xmath8 is omitted . +   + discussing the practicalities of implementing such a process become cumbersome in the general case so we reduce the problem to the special case used in the numerical spiking example , but note that the technique would be analogous . in the example",
    "the target @xmath8 depends only on the history of the source @xmath11 , the source process @xmath11 is independent of the target process @xmath8 , the source is markov and because the process can only ever spike from the unspiked state the markovian property is equivalent to complete independence of its history .",
    "this has the consequence that we may consider @xmath355 , @xmath356 and @xmath357 hereafter denoted @xmath358 ( we also note that in our specific example we have @xmath359 ) .",
    "this also lets us fully specifiy all quantities involved in the construction of @xmath360 without conditioning such that we can write      notably , the independence of @xmath11 from @xmath8 provides conditions where the conditional probability density defined in the manner of eq .",
    "( [ meas ] ) aligns with the conditional probability density in the usual sense .",
    "next we recognise that the independence of @xmath8 from its history and @xmath11 from @xmath8 means there is no mechanism for feedback from @xmath8 to itself meaning that we have the property @xmath362=\\lambda_x[x^t_{t-\\tau^{xy}}]\\qquad \\forall\\ ; s\\geq\\tau^{xy}\\nonumber\\\\ & = \\frac{\\int dy^t_{t-2\\tau^{xy } } \\lambda_{x|y}^{n_x,\\cdot}(y^t_{t-\\tau^{xy}})p_{n_x,\\cdot}[\\{t^x\\}_1^{n_x},y^t_{t-2\\tau^{xy}}]}{\\int dy^t_{t-2\\tau^{xy}}p_{n_x,\\cdot}[\\{t^x\\}_1^{n_x},y^t_{t-2\\tau^{xy}}]}. \\label{coarserate}\\end{aligned}\\ ] ] to calculate @xmath212 thus requires approximation of the component integrals and probability densities .",
    "given specific sequences of spikes in @xmath8 and @xmath11 , the densities may be represented directly by eqs .",
    "( [ eq : probden0 ] ) and ( [ probden ] ) with exponentiated integrals performed numerically with convergence in a discrete time parameter @xmath112 .",
    "the complete infinite series of integrals in eq .",
    "( [ coarserate ] ) of the form in eq .",
    "( [ infint ] ) quickly become infeasible so instead of directly computing the infinite nested integrals we choose a cutoff , @xmath67 , for the number of spikes to include in the source path @xmath363 and then replace each of the @xmath67 sets of @xmath67 nested integrals with a separate monte carlo integration scheme .",
    "this is achieved , for a given @xmath364\\}\\in\\mathbb{n}$ ] , by placing @xmath193 spikes randomly , with floating point accuracy , on the interval @xmath365 and then taking the appropriate average of the associated path probability densities . as with all monte carlo integration",
    "this average does not take into account the phase space volume of the original integrals which represent the ` size ' associated with the number of ways to arrange @xmath67 spikes on the interval in continuous time ( such that @xmath366 and so on ) .",
    "this volume is given by the integral @xmath367 where @xmath368 which we can solve by induction , since @xmath369 such that @xmath370 we point out that one could approach the problem by constructing the limit of a discretised time space ( using discretisation @xmath371 , for example ) , thus considering probabilities , differing from the probability densities by @xmath372 and where the phase space volume would be given by a binomial coefficient such that @xmath373 proceeding , we may approximate the integrals    @xmath374=\\nonumber\\\\ & \\lim_{\\substack{\\delta t\\to 0\\\\k\\to\\infty\\\\n\\to\\infty}}\\sum_{n_y=0}^{k}\\frac{(2\\tau^{xy})^{n_y}}{n_y!n}\\sum_{i=1}^{n}p_{n_x,(\\delta t)}^{(0^{+},\\tau^{xy})}(x^t_{t-\\tau^{xy}}\\equiv\\{\\tau^{xy},t,\\{t^x\\}_1^{n_x}\\}|\\{y^t_{t-2\\tau^{xy}}\\equiv\\{\\tau^{xy},t,[\\{t^y\\}_1^{n_y}]_i\\}\\})\\nonumber\\\\ & \\qquad\\qquad\\qquad\\qquad\\qquad\\times p_{n_y,(\\delta t)}^{(0^+,0^+)}(y^t_{t-2\\tau^{xy}}\\equiv\\{\\tau^{xy},t,[\\{t^y\\}_1^{n_y}]_i\\ } ) \\label{bigint1}\\end{aligned}\\ ] ]    and @xmath375=\\nonumber\\\\ & \\lim_{\\substack{\\delta t\\to 0\\\\k\\to\\infty\\\\n\\to\\infty}}\\sum_{n_y=0}^{k}\\frac{(2\\tau^{xy})^{n_y}}{n_y!n}\\sum_{i=1}^{n}\\lambda_{x|y}^{n_x , n_y}(y^t_{t-2\\tau^{xy}}\\equiv\\{\\tau^{xy},t,[\\{t^y\\}_1^{n_y}]_i\\}\\})\\nonumber\\\\ & \\qquad\\qquad\\qquad\\qquad\\times p_{n_x,(\\delta t)}^{(0^{+},\\tau^{xy})}(x^t_{t-\\tau^{xy}}\\equiv\\{\\tau^{xy},t,\\{t^x\\}_1^{n_x}\\}|\\{y^t_{t-2\\tau^{xy}}\\equiv\\{\\tau^{xy},t,[\\{t^y\\}_1^{n_y}]_i\\}\\})\\nonumber\\\\ & \\qquad\\qquad\\qquad\\qquad\\qquad\\times p_{n_y,(\\delta t)}^{(0^+,0^+)}(y^t_{t-2\\tau^{xy}}\\equiv\\{\\tau^{xy},t,[\\{t^y\\}_1^{n_y}]_i\\ } ) \\label{bigint2}\\end{aligned}\\ ] ]    were @xmath376_i$ ] indicates the @xmath170th instance of @xmath377 randomly generated spikes in the source on the interval @xmath365 and the probability densities labelled with @xmath112 indicate they have used @xmath112 as a discretisation parameter in their numerical integrals .",
    "in our example model , where @xmath11 is a simple poisson process , we have @xmath378_i\\})=\\nonumber\\\\ & \\qquad\\qquad(\\lambda_y)^{n_y}\\exp{\\left[-\\lambda_y(2\\tau^{xy})\\right]}\\nonumber\\\\ & \\quad=\\lim_{\\delta t\\to 0}p_{n_y,(\\delta t)}^{(0^+,0^+)}(y^t_{t-2\\tau^{xy}}\\equiv\\{\\tau^{xy},t,[\\{t^y\\}_1^{n_y}]_i\\})\\nonumber\\\\ & \\quad=\\lim_{\\delta t\\to 0}(\\lambda_y\\delta",
    "t)^{n_y}(1-\\lambda_y\\delta t)^{\\frac{2\\tau^{xy}}{\\delta t}-n_y}.\\end{aligned}\\ ] ] the ratio of these two integrals , eqs .",
    "( [ bigint1 ] ) and ( [ bigint2 ] ) , then gives an estimate for @xmath212 given a path history @xmath379 containing @xmath137 spikes .",
    "we note that in practise @xmath67 is chosen at runtime by comparing convergence in @xmath212 to a tolerance parameter whilst @xmath112 and @xmath193 are chosen at compile time .",
    "+   + all of the above specifies how to construct @xmath212 for a given path history in @xmath8 , however when modelling a continuous time process we wish to obtain a value at arbitrary points in time in order to meet some practical time discretisation procedure .",
    "this can become infeasible and so various strategies are implemented to approximate and speed up this process .",
    "first we assume the property in the rate functions that for any @xmath380 , functions @xmath381 and @xmath382 ( in the general case ) are smooth in @xmath383 .",
    "this allows us to assume smoothness in @xmath384 for @xmath67 spikes in @xmath8 on some interval @xmath385 .",
    "this combined with the observation that as time progresses @xmath212 as a function of a cluster of @xmath4 spikes in @xmath385 is smooth in a single variable describing the relative position of the cluster in the interval until either a spike in the cluster leaves the interval or a new spike enters by virtue of @xmath8 spiking points towards a general interpolation scheme described below , where we focus on the special case of the utilised example where @xmath386 :    1 .   for phase spaces containing a manageable number , @xmath387 , of spikes in @xmath8 on @xmath388 ( e.g. 2 ) precompute @xmath389 ( alongside @xmath390 being a constant value for when there are no spikes on the interval ) at values @xmath391 where @xmath392 is a tuneable interpolation parameter .",
    "here @xmath112 is included in the final value since @xmath140 is the ` current ' time such that a spike at @xmath140 is not in the processes history reflecting the right - open interval @xmath393 .",
    "2 .   numerically generate a coevolving sequence of spikes using @xmath394 and @xmath395 utilising temporal discretisation @xmath396 , @xmath397 .",
    "partition the resultant spike train in @xmath8 into intervals , @xmath398 , where for any @xmath399 there are a constant number of spikes on the interval @xmath400 .",
    "given the discretisation scheme there is a finite probability of a spike leaving the window to the left at the same time as a spike enter from the right after it is generated .",
    "in such cases the regimes before and after this event are partitioned .",
    "first we consider intervals @xmath398 where the number of spikes in that interval , @xmath137 , is less than or equal to the established manageable number of spikes , @xmath387 . for such values of @xmath387",
    "we can take any such spike history and estimate @xmath212 by interpolating between the precomputed @xmath212 values in step one for the closest matching spike histories ( based on the @xmath392 scheme ) .",
    "this is performed for each required @xmath399 according to the numerically generated spike trains with time discretisation @xmath112 .",
    "next we consider the remaining intervals @xmath398 such that the number of spikes in that interval , @xmath137 , is greater than @xmath387 .",
    "a crucial observation is that in these intervals , where the number of spikes is constant , the interspike times ( i.e. @xmath401 ) are also constant for all times @xmath399 .",
    "this means we can parameterize the entire spike sequence by the relative position of a single spike , e.g. the time of the @xmath137th spike relative to the time in question @xmath402 , @xmath403 .",
    "this can be captured by the single variable @xmath404 . since the duration of the partitioned interval is @xmath405 we can compute values of @xmath212 for sequences characterised by @xmath404 for values in @xmath406 with intervals @xmath407 .",
    "we can then use these values to interpolate values of @xmath212 as measured for any time @xmath408 which are separated by the smaller discretisation parameter @xmath112 .",
    "the appropriateness of the interpolation is assured by the inital assumptions of continuity .",
    "this leaves us with intervals @xmath398 with @xmath409 where we utilise a precomputed interpolation scheme of dimension up to @xmath387 and a series of independent one dimensional interpolation schemes for each remaining @xmath398 .",
    "this allows us to estimate @xmath212 for any @xmath408 for all values of @xmath170 and thus for the entire spike train .",
    "we note that in practise @xmath407 is chosen through a desired interpolation density which is rounded up when necessary to fit the variable interpolation interval lengths .",
    "58ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ] ",
    "+ 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty link:\\doibase 10.1103/physrevlett.85.461 [ * * ,   ( ) ] link:\\doibase",
    "10.1140/epjb / e2010 - 00034 - 5 [ * * ,   ( ) ] link:\\doibase 10.3389/frobt.2014.00011 [ * * ,   ( ) ] ,   link:\\doibase 10.1103/physreve.63.046211 [ * * ,   ( ) ] link:\\doibase 10.1103/physreve.77.026110 [ * * ,   ( ) ] link:\\doibase 10.1016/s0167 - 2789(02)00432 - 3 [ * * ,   ( ) ] http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&#38;path=asin/0471062596[__ ]  ( ,  ,  ) link:\\doibase    10.1371/journal.pone.0040084 [ * * ,   ( ) ] @noop * * ,   ( ) link:\\doibase 10.1073/pnas.0701519104 [ * * ,   ( ) ] link:\\doibase 10.1186/1471 - 2202 - 12 - 119 [ * * ,   ( ) ] link:\\doibase 10.1371/journal.pone.0102833 [ * * ,   ( ) ] link:\\doibase 10.1371/journal.pcbi.1002653 [ * * , ( ) ] link:\\doibase 10.3390/e17010277 [ * * ,   ( ) ] link:\\doibase    10.1007/s10827 - 010 - 0262 - 3 [ * * , ( ) ] link:\\doibase    10.1016/j.pbiomolbio.2010.11.006 [ * * ,   ( ) ] link:\\doibase 10.1103/physreve.86.066211 [ * * ,   ( ) ] link:\\doibase 10.1155/2012/303601 [ * * ,   ( ) ] link:\\doibase 10.1088/1367 - 2630/16/10/105003 [ * * ,   ( ) ] , link:\\doibase    10.1007/s10827 - 010 - 0271 - 2 [ * * , ( ) ] http://view.ncbi.nlm.nih.gov/pubmed/26177254 [ * * , ( ) ] in  link:\\doibase 10.1007/978 - 3 - 319 - 20591 - 5_2 [ _ _ ] ,  ,  ( ,  )  pp .   link:\\doibase 10.1152/jn.01106.2006 [ * * ,   ( )",
    "] link:\\doibase    10.1371/journal.pone.0027431 [ * * ,   ( ) ] link:\\doibase    10.1371/journal.pone.0115764 [ * * ,   ( ) ] link:\\doibase 10.1371/journal.pcbi.1004858 [ * * ,   ( ) ] link:\\doibase 10.1103/physreve.90.022721 [ * * ,   ( ) ] http://view.ncbi.nlm.nih.gov/pubmed/2054667 [ * * ,   ( ) ] link:\\doibase 10.1016/s0165 - 0270(00)00335 - 6 [ * * ,   ( ) ] http://www.jneurosci.org/content/23/35/11167.abstract [ * * ,   ( ) ] link:\\doibase 10.1038/nphys758 [ * * , ( ) ] ,   @noop * * ,   ( ) @noop * * ,   ( ) link:\\doibase 10.1371/journal.pcbi.1002038 [ * * ,   ( ) ] link:\\doibase 10.3390/e17064173 [ * * ,   ( ) ] @noop _ _ ,  ed .",
    ",  wiley series in probability and mathematical statistics  ( ,  ,  ) http://arxiv.org/abs/0911.2873 [ `` , ''  ] ( ) ,   link:\\doibase 10.1088/1367 - 2630/16/12/125007 [ * * ,   ( ) ] @noop _ _  ( , )   http://arxiv.org/abs/1606.08644 [ `` , ''  ] ( ) ,   link:\\doibase 10.1103/physreve.94.022135 [ * * ,   ( ) ] link:\\doibase 10.1140/epjb / e2008 - 00001 - 9 [ * * ,   ( ) ] link:\\doibase 10.1088/0034 - 4885/75/12/126001 [ * * ,   ( ) ] in  @noop _ _ ,  ( ,  )  pp .",
    "@noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * , ( ) link:\\doibase 10.1103/physrevlett.103.238701 [ * * ,   ( ) ] link:\\doibase    10.3389/fncom.2014.00075 [ * * , ( ) ] @noop _ _ ,  wiley series in probability and mathematical statistics  ( ,  ,  ) @noop _ _ ,  probability and its applications  ( ,  ,  ) in  link:\\doibase 10.1109/cdc.2007.4434050 [ _ _ ]  ( ,  )  pp .",
    "link:\\doibase 10.1162/0899766054322973 [ * * ,   ( ) ] link:\\doibase    10.1371/journal.pcbi.1001110 [ * * ,   ( ) ] link:\\doibase 10.1088/0305 - 4470/37/12/007 [ * * ,   ( ) ] link:\\doibase    10.1016/j.jneumeth.2006.12.008 [ * * , ( ) ] link:\\doibase 10.1038/nature06105 [ * * , ( ) ]"
  ],
  "abstract_text": [
    "<S> transfer entropy has been used to quantify the directed flow of information between source and target variables in many complex systems . </S>",
    "<S> originally formulated in discrete time , we provide a framework for considering transfer entropy in continuous time systems . by appealing to a measure theoretic formulation we generalise transfer entropy , describing it in terms of radon - nikodym derivatives between measures of complete path realisations . </S>",
    "<S> the resulting formalism introduces and emphasises the idea that transfer entropy is an expectation of an individually fluctuating quantity along a path , in the same way we consider the expectation of physical quantities such as work and heat . </S>",
    "<S> we recognise that transfer entropy is a quantity accumulated over a finite time interval , whilst permitting an associated instantaneous transfer entropy rate . </S>",
    "<S> we use this approach to produce an explicit form for the transfer entropy for pure jump processes , and highlight the simplified form in the specific case of point processes ( frequently used in neuroscience to model neural spike trains ) . </S>",
    "<S> we contrast our approach with previous attempts to formulate information flow between continuous time point processes within a discrete time framework , which incur issues that our continuous time approach naturally avoids . finally , we present two synthetic spiking neuron model examples to exhibit the pertinent features of our formalism , namely that the information flow for point processes consists of discontinuous jump contributions ( at spikes in the target ) interrupting a continuously varying contribution ( relating to waiting times between target spikes ) . </S>"
  ]
}