{
  "article_text": [
    "throughout the brain , information is represented by discrete electrical pulses termed action potentials or ` spikes ' @xcite . for decades there has been controversy about the extent to which the precise timing of these spikes is significant : should we think of each spike arrival time as having meaning down to millisecond precision @xcite , or does the brain only keep track of the number of spikes occurring in much larger windows of time ? is precise timing relevant only in response to rapidly varying sensory stimuli , as in the auditory system @xcite , or can the brain construct specific patterns of spikes with a time resolution much smaller than the time scales of the sensory and motor signals that these patterns represent @xcite ? here we address these issues using the motion  sensitive neurons of the fly visual system as a model @xcite .",
    "we bring together new experimental methods for delivering truly naturalistic visual inputs @xcite and new mathematical methods that allow us to draw more reliable inferences about the information content of spike trains @xcite .",
    "we find that as we improve our time resolution for the analysis of spike trains from @xmath1 down to @xmath2 we reveal nearly one  third more information about the trajectory of visual motion .",
    "the natural stimuli used in our experiments have essentially no power above @xmath3 , so that the precision of spike timing is not a necessary correlate of the stimulus bandwidth ; instead the different patterns of precise spike timing represent subtly different trajectories chosen out of the stimulus ensemble .",
    "further , despite the long correlation times of the sensory stimulus , segments of the neural response separated by @xmath4 provide essentially independent information , suggesting that the neural code in this system achieves decorrelation @xcite in the time domain .",
    "this decorrelation is not evident in the time dependent spike rate alone , but the time scale for the independence of information does match the time scale on which visual motion signals are used to guide behavior @xcite .",
    "-0.25 in    flies exhibit a wide variety of visually guided behaviors , of which perhaps the best known is the optomotor response , in which visual motion drives a compensating torque , stabilizing straight flight @xcite .",
    "this system offers many advantages for the exploration of neural coding and computation : there is a small groups of identified , wide  field motion  sensitive neurons @xcite that provide an obligatory link in the process @xcite , and it is possible to make very long , stable recordings from these neurons as well as to characterize in detail the signal and noise properties of the photoreceptors that provide the input data for the computation . in free flight , the trajectory of visual motion is determined largely by the fly s own motion through the world , and there is a large body of data on flight behavior under natural conditions @xcite , offering us the opportunity to generate stimuli that approximate those experienced in nature .",
    "but the natural visual world of flies involves not only the enormous angular velocities associated with acrobatic flight ; natural light intensities and the dynamic range of their variations also are very large , and the fly s compound eyes are stimulated over more than @xmath5 steradians ; all of these features are difficult to replicate in the laboratory @xcite . as an alternative , we have moved our experiments outside @xcite , so that flies experience the scenes from the region in which they were caught .",
    "we record from a single motion  sensitive cell , h1 , while we rotate the fly along trajectories that are modeled on the natural flight trajectories ( see methods for details ) . for other approaches to the delivery of naturalistic stimuli in this system",
    "see @xcite .",
    "a schematic of our experiment , and an example of the data we obtain , are shown in fig [ big_expt ] .",
    "we see qualitatively that the responses to natural stimuli are very reproducible , and we can point to specific features of the stimulus  such as reversals of motion direction  that generate individual spikes and interspike intervals with better than millisecond precision .",
    "the challenge is to quantify these observations : do precise and reproducible patterns of spikes occur just at some isolated moments , or does looking at the spike train with higher time resolution generally provide more information about the visual input ?    precise spike timing endows each neuron with a huge `` vocabulary '' of responses @xcite , but this potential advantage in coding capacity creates challenges for experimental investigation . if we look with a time resolution of @xmath6 , then in each bin of size @xmath7 we can see either zero or one spike ; across the behaviorally relevant time scale of @xmath8 the neural response thus can be described as a 30bit binary word , and there are @xmath9 , or roughly one billion such words .",
    "although some of these responses never occur ( because of refractoriness ) and others are expected to occur only with low probability , it is clear that if precise timing is important then neurons can generate many more meaningfully distinguishable responses than the number that we can sample in realistic experiments .",
    "can we make progress on assessing the content and meaning of neural responses even when we ca nt sample all of them ?",
    "some hope is provided by the classical problem of how many people need to be present in a room before there is a reasonable chance that they share a birthday .",
    "this number , @xmath10 , is vastly less than the number of possible birthdays , @xmath11 . turning this argument around ,",
    "if we did nt know the number of possible birthdays we could estimate it by polling @xmath12 people and checking the frequency of coincidences .",
    "once @xmath12 is large enough to generate several coincidences we can get a pretty good estimate of @xmath13 , and this happens when @xmath14 .",
    "some years ago ma proposed that this coincidence counting method be used to estimate the entropy of physical systems from molecular dynamics or monte carlo simulations @xcite ( see also ref @xcite ) .",
    "if these arguments could be generalized , it would become feasible to estimate the entropy and information content of neural responses even when experiments provide only a sparse sampling of these responses .",
    "the results of ref @xcite provide such a generalization .    to understand how the methods of ref @xcite generate more accurate entropy estimates from small samples , it is useful to think about the simpler problem of flipping a coin under conditions where we do nt know the probability @xmath15 that it will come up heads .",
    "one strategy is to count the number of heads @xmath16 that we see after @xmath12 flips , and identify @xmath17 ;",
    "if we then use this `` frequentist '' or maximum likelihood estimate to compute the entropy of the underlying distribution , it is well known that we will underestimate the entropy systematically @xcite .",
    "alternatively , we could take a bayesian approach and say that a priori all values of @xmath18 are equally likely ; the standard methods of bayesian estimation then will generate a mean and an error bar for our estimate of the entropy given @xmath12 observations . as shown in fig [ errors",
    "] , this procedure actually leads to a systematic _ overestimate _ of the entropy in cases where the real entropy is not near its maximal value .",
    "more seriously , this systematic error is larger than the error bars that emerge from the bayesian analysis , so we would be falsely confident in the wrong answer .",
    "figure [ errors ] also shows us that if we use a bayesian approach with the a priori hypothesis that all values of the entropy are equally likely , then ( and as far as we know , only then ) we find estimates such that the systematic errors are comparable to or smaller than the error bars , even when we have seen only one sample .",
    "thus the problem of systematic errors in entropy estimation is not , as one might have thought , the problem of not having seen all the possibilities ; the problem rather is that seemingly natural and unbiased prior hypotheses about the nature of the underlying probabilities correspond to highly biased hypotheses about the entropy itself , and this problem gets much worse when we consider distributions over many alternatives .",
    "the strategy of ref @xcite thus is to construct , at least approximately , a ` flat prior ' on the entropy ( see methods for details ) .",
    "the results of ref @xcite demonstrate that this procedure actually works for both simulated and real spike trains , where ` works ' means that we generate estimates that agree with the true entropy within error bars even when the number of samples is much smaller than the number of possible responses .",
    "as expected from the discussion of the birthday problem , what is required for reliable estimation is that the number of coincidences be significantly larger than one @xcite .",
    "armed with tools that allow us to estimate the entropy of neural responses , we first analyze a long experiment in which the fly experiences a continuous trajectory of motion with statistics modeled on those of natural flight trajectories ( fig [ stim ] ; see methods for details ) .",
    "as shown in fig [ ent+inf_results]a , we examine segments of the response of duration @xmath19 , and we break these segments into discrete bins with time resolution @xmath7 . for sufficiently small @xmath7 each bin either has one or zero spikes , and hence the response becomes a binary word with @xmath20 bits , while in the opposite limit we can let @xmath21 and then the response is the total number of spikes in a window of size @xmath19 ; for intermediate values of @xmath7 the responses are multi  letter words , but with larger than binary alphabet when more than one spike can occur within a single bin . an interesting feature of these words is that they occur with a probability distribution similar to the distribution of words in english ( zipf s law ; fig [ ent+inf_results]b ) .",
    "this zipf  like behavior emerges only for @xmath22 , and was not observed in experiments with less natural , noisy stimuli @xcite .    with a fixed value of @xmath19 , improving",
    "our time resolution ( smaller @xmath7 ) means that we distinguish more alternatives , increasing the `` vocabulary '' of the neuron .",
    "mathematically this means that the entropy @xmath23 of the neural responses is larger , corresponding to a larger capacity for carrying information .",
    "this is shown quantitatively in fig [ ent+inf_results]c , where we plot the entropy rate , @xmath24",
    ". the question of whether precise spike timing is important in the neural code is precisely the question of whether this capacity is used by the system to carry information @xcite .    to estimate the information content of the neural responses , we follow the strategy of refs @xcite . roughly speaking",
    ", the information content of the ` words ' generated by the neuron is less than the total size of the neural vocabulary because there is some randomness or noise in the association of words with sensory stimuli . to quantify this noise we choose a five second segment of the stimulus , and then repeat this stimulus 100 times . at each moment @xmath25 in the cycle of the repeated stimulus , we can look across the one hundred trials to sample the different possible responses to the same input , and with the same mathematical methods as before we use these samples to estimate the ` noise entropy ' @xmath26 in this ` slice ' of responses . the information which the responses carry about the stimulus then is given by @xmath27 , where @xmath28 denotes an average over time @xmath29 , which implicitly is an average over stimuli .",
    "it is convenient to express this as an information rate @xmath30 , and this is what we show in fig [ ent+inf_results]d , with @xmath31 chosen to reflect the time scale of behavioral decisions @xcite .        the striking feature of fig [ ent+inf_results]d is the growth of information rate with time resolution .",
    "we emphasize that this measurement is made under conditions comparable to those which the fly encounters in nature  outdoors , in natural light , moving along trajectories with statistics similar to those observed in free flight .",
    "thus , under these conditions , we can conclude that the fly s visual system carries information about motion in the timing of spikes down to sub  millisecond resolution .",
    "quantitatively , information rates double as we increase our time resolution from @xmath32 to @xmath33 , and the final @xmath34 of this increase occurs between @xmath35 and @xmath33 . in the behaviorally relevant time windows",
    "@xcite , this @xmath36 extra information corresponds to a almost a full bit from this one cell , which would provide the fly with the ability to distinguish reliably among twice as many different motion trajectories .",
    "0.25 in    the information rate tells us _ how much _ we can learn about the sensory inputs by examining the neural response , but it does nt tell us _ what _ we learn . in particular , we would like to make explicit the nature of the extra information that emerges as we increase our time resolution from @xmath35 to @xmath33 . to do this",
    ", we look at particular `` words '' in a segment of the neural response , as shown in fig .",
    "[ features ] , and then examine the motion trajectories that correspond to these words @xcite . for simplicity , we consider all responses that have two spikes in successive @xmath1 bins , that is the pattern 11 when seen at @xmath35 resolution .",
    "when we improve our time resolution to @xmath33 , some of these responses turn out to be of the form 10000000000000000001 , while at the other extreme some of the responses have the two spikes essentially as close as is possible given the refractory period , 00000100000000100000 .",
    "remarkably , as we sweep through these subtly different patterns  which all have the same average spike arrival time but different interspike intervals  the average velocity trajectory changes form qualitatively , from a smooth `` on '' ( negative to positive velocity ) transition , to a prolonged period of positive velocity , to a more complex waveform with off and on transitions in succession . examining more closely the distribution of waveforms conditional on the different responses",
    ", we see that these differences among mean waveforms are in fact discriminable .",
    "thus , variations in interspike interval on the millisecond or sub  millisecond scale represent significantly different stimulus trajectories .    a second axis along which we can ask about the nature of the extra information at high time resolution concerns the absolute timing of spikes . as an example , responses which at @xmath35 resolution are of the form 11 can be unpacked at @xmath37 resolution to give patterns ranging from 01000000001000000000 to 00000000010000000010 , all with the same interspike interval but with different absolute arrival times . as shown in fig",
    "[ features ] , all of these responses code for motion trajectories with two zero crossings , but the times of these zero crossings shift as the spike arrival times shift .",
    "thus , whereas the times between spikes represent the shape of the waveform , the absolute arrival time of the spikes mark , with some latency , the time at which a specific feature of the waveform occurs , in this case a zero crossing .",
    "again we find that millisecond and sub  millisecond scale shifts generate discriminable differences .    the idea that sub ",
    "millisecond timing of action potentials could carry significant information is not new , but the clearest evidence comes from systems in which the dynamics of the stimulus itself has significant sub  millisecond structure , as in hearing and electroreception @xcite . even for h1 , experiments demonstrating the importance of spike timing at the @xmath38 level @xcite could be criticized on the grounds that the stimuli had unnaturally rapid variations .",
    "it thus is important to emphasize that , in these experiments , h1 does not achieve millisecond precision simply because the input has a bandwidth of kilohertz ; in fact , the stimulus has a correlation time of @xmath39 ( fig [ redundancy ] ) , and @xmath40 of the stimulus power is contained below @xmath3 ( fig [ stim]f ) .",
    "the long correlation time of these naturalistic stimuli also raises questions about redundancy  while each spike and interspike interval can be highly informative , does the long correlation time of the stimulus inevitably mean that successive spikes carry redundant information about essentially the same value of the instantaneous velocity ? certainly on very short time scales this is true : although @xmath41 actually increases at small @xmath19 , since larger segments of the response reveal more informative patterns of several spikes @xcite , it does decrease at larger @xmath19 , a sign of redundancy . on the other hand , the approach to a constant information rate happens very rapidly : we can measure the redundancy on time scale @xmath19 by computing @xmath42 , where @xmath43 means that successive windows of size @xmath19 provide completely independent information , and @xmath44 means that they are completely redundant . as shown in fig [ redundancy ] , @xmath45 decays rapidly , on a time scale of less than @xmath46 .",
    "in contrast , correlations in the stimulus decay much more slowly , on the @xmath47 time scale .",
    "further , we can compute at each moment of time the spike rate @xmath48 , and this has a correlation time comparable to the stimulus itself , suggesting that the decorrelation of information is more subtle than a simple filtering of the stimulus .",
    "the ability of the fly s visual system to mark features of the stimulus with millisecond precision , even when the stimulus correlation time is @xmath49 , depends on having access to a representation of visual motion with very high signal  to  noise ratio .",
    "previous work has suggested that this system can estimate motion with a precision close to the limits set by noise in the photoreceptors @xcite , which is dominated by photon shot noise @xcite .",
    "the present experiments , however , are done under very different conditions : velocities of motion are much larger , the fly s eye is stimulated over a much larger area , and light intensities outdoors are much larger than generated by laboratory displays .",
    "during the course of our experiments we monitor the light intensity at zenith , using a detector matched to the properties of the fly photoreceptors ( see methods ) ; from these measurements we estimate that the mean light intensity corresponds to @xmath50 per photoreceptor , which is near the limit of the photoreceptor s dynamic range for photon counting .",
    "is it possible that photon counting statistics still are relevant even at these high rates ?",
    "because the experiments are done outdoors , there are small fluctuations in light intensity from trial to trial as clouds drift by and obscure the sun .",
    "although the dynamic range of these fluctuations is less than a factor two , the arrival times of individual spikes ( e.g. , the `` first spike '' after @xmath51 in fig [ big_expt ] ) have correlation coefficients of up to @xmath52 with the light intensity , with the negative sign indicating that higher light intensities lead to earlier spikes .",
    "one might see this effect as a failure of the system to adapt to the overall light intensity , but it also suggests that some of what we have called noise really represents a response to trial  by  trial variations in stimulus conditions .",
    "indeed , a correlation between light intensity and spike time means that the noise entropy @xmath53 in windows which contain these spikes is smaller than we have estimated because some of the variability can be ascribed to stimulus variation .",
    "more subtly , if photon shot noise is relevant , we expect that on trials with higher light intensity the neuron will actually convey more information about the trajectory of motion .",
    "we emphasize that this is a delicate question .",
    "to begin , the differences in light intensity are small , and we expect ( at most ) proportionately small effects .",
    "further , as the light intensity increases , the total spike rate increases , and this increases both the total entropy and the noise entropy . to ask if the system uses the more reliable signal at higher light intensities to convey more information we have to determine which of these increases is larger .    to test the effects of light intensity on information transmission",
    "( see methods for details ) , we divide the trials into halves based on the average light intensity over the trial , and we try to estimate the information rates in both halves ; the two groups of trials differ by just @xmath54 in their median light intensities .",
    "since cutting the number of trials in half makes our sampling problems much worse , we focus on short segments of the response ( @xmath55 ) at high time resolution ( @xmath33 ) ; note that these are still `` words '' with 30 letters . for this case",
    "we find that for the trials with higher light intensities the information about the motion stimulus is larger by @xmath56 , which is small but significant at the @xmath57 confidence level .",
    "we find differences with the same sign for all accessible combinations of @xmath19 and @xmath7 , and the overall significance of the difference thus is much larger .",
    "note that since we are analyzing @xmath55 windows , this difference corresponds to @xmath58 , @xmath59 of the total ( cf fig [ ent+inf_results ] ) .",
    "thus even at rates of more than one million photons per second per receptor cell , small increases in photon flux produce significant changes in the transmission of information about the visual input .",
    "to summarize , we have found that under natural stimulus conditions the fly visual system generates spikes and interspike intervals with extraordinary temporal precision . as a consequence ,",
    "the neural response carries a substantial amount of information that is available only at sub  millisecond time resolution . at this high resolution ,",
    "absolute spike timing is informative about the time at which particular stimulus features occur , while different interspike intervals provide a rich representation of distinguishable stimulus features .",
    "these results provide a clear demonstration that the visual system uses sub ",
    "millisecond timing to provide a richer representation of the natural sensory world , at least in this corner of the fly s brain .",
    "in addition , the data provide support for the idea that the system performs efficiently both in the tasks of estimation and coding , making use of the extra signal  to  noise provided by increased photon flux and reducing the redundancy of the stimulus as it is transformed into spikes .",
    "finally , we note that our ability to reach these conclusions depends not just on new experimental methods that allow us to generate truly naturalistic stimuli @xcite , but critically on new mathematical methods that allow us to analyze neural responses quantitatively even when it is impossible for us to sample the distribution of responses exhaustively @xcite .",
    "we expect that these sorts of mathematical tools will become even more critical for neuroscience in the future .",
    "* neural recording and stimulus generation . * h1 was recorded extracellularly by a short ( @xmath60 shank length ) tungsten electrode ( fhc ) .",
    "the signal was preamplified by a differential bandpass amplifier based on the ina111 .",
    "after amplification by a second stage samples were digitized at @xmath61 by an ad converter ( national instruments daqcard ",
    "ai16e4 , mounted in a fieldworks fw5066p ruggedized laptop ) . in off line analysis ,",
    "the analog signal was digitally filtered by a template derived from the average spike waveform .",
    "spikes were then time stamped by interpolating threshold crossing times .",
    "the ultimate precision of this procedure is limited by the signal to noise ratio in the recording ; for typical conditions this error is estimated to be @xmath62 .",
    "note that we analyze spike trains down to a precision of @xmath63 , so that some saturation of information at this high time resolution may actually result from instrumental limitations .",
    "the experiments were performed outside in a wooded environment , with the fly mounted on a stepper motor with vertical axis .",
    "the speed of the stepper motor was under computer control , and could be set at @xmath1 intervals .",
    "the daq card generates a clock signal at @xmath64 in synchrony with the master clock which calibrates the neural recording . as explained in the legend to fig [ big_expt ] , each tick of the clock drives the stepper motor through an amount determined by reading the stimulus file stored on a dedicated computer .",
    "the motor ( sig  positec rdm566/50 stepper motor , 104 pulses per revolution ) is driven by a controller ( sig  positec divistep d331.1 ) , which in turn receives pulses at a frequency divided down from a free running @xmath65 clock ; the stimulus velocity is represented by the divisor for the pulse frequency . in this way , the stepper motor is driven in each @xmath1 period , in strict synchrony with the data acquisition clock , by steps that are evenly spaced .",
    "this design was chosen to minimize the effects of discrete steps and to maximize the reliability of all timing measurements . to stabilize temperature",
    "the setup was enclosed by a transparent plexiglass cylinder ( radius @xmath66 , height @xmath67 ) , with a transparent plexiglass lid .",
    "* monitoring light intensity and controlling temperature . * the air temperature in the experimental enclosure was regulated by a peltier element fitted with heat vanes and fans on both sides for efficient heat dispersal , driven by a custom built feedback controller .",
    "the temperature could be set over a range from approximately five degrees below to fifteen degrees above ambient temperature , and the controller stabilized temperature over this range to within about a degree . in the experiments described here ,",
    "temperature was @xmath68 .",
    "an overall measure of light intensity was obtained by monitoring the current of a photodiode ( hamamatsu ) enclosed in a diffusing ping pong ball .",
    "the photodiode signal was amplified by a logarithmic amplifier operating over five decades .",
    "the photodiode was located @xmath69 from the fly , and in the experiments the setup was always placed in the shade .",
    "the photodiode measurement was intended primarily to get a rough impression of relative light intensity fluctuations . however , to relate these measurements to outside light levels , before the start of each experiment a separate calibration measurement of zenith radiance was taken using a calibrated light intensity meter . to relate this measurement to fly physiology , the radiance reading was converted to an estimated effective fly photoreceptor photon rate .",
    "the reading of the photodiode was roughly proportional to the zenith intensity reading , with a proportionality factor determined by the placement of the setup and the time of day . to obtain a practical rule of thumb ,",
    "the photodiode readings were converted to equivalent zenith photon flux values , using the current to zenith intensity conversion factor established at the beginning of the experiment . during the experiments",
    "the photodiode current was sampled at @xmath70 intervals .",
    "* repeated stimuli . * in their now classical experiments , land and collett measured the trajectories of flies in free flight @xcite ; in particular they reported the angular position ( orientation ) of the fly vs time , from which we can compute the angular velocity @xmath71 .",
    "the short segments of individual trajectories shown in the published data have a net drift in angle , so we include both the measured @xmath71 and @xmath72 as parts of the stimulus .",
    "we use the trajectories for the two different flies in fig 4 of ref @xcite , and graft all four segments together , with some zero padding to avoid dramatic jumps in velocity , generating a stimulus that is 5 seconds in duration and has zero drift so that repetition of the angular velocity vs time also repeats the angular position vs time . since land and collett report data every @xmath73 , we interpolate to generate a signal that drives the stepper motor at @xmath1 resolution ; interpolation is done using the matlab routine interp , which preserves the bandlimited nature of the original signal and hence does not distort the power spectrum .",
    "* nonrepeated stimulus .",
    "* to analyze the full entropy of neural responses , it is useful to have a stimulus that is not repeated .",
    "we would like such a stimulus to match the statistical properties of natural stimulus segments described above . to do this",
    ", we estimate the probability distribution @xmath74 $ ] from the published trajectories , where @xmath75 is the time resolution , and then use this as the transition matrix of a markov process from which we can generate arbitrarily long samples ; our nonrepeated experiment is based on a @xmath76 trajectory drawn in this way .",
    "the resulting velocity trajectories will , in particular , have exactly the same distributions of velocity and acceleration as in the observed free flight trajectories .",
    "although the real trajectories are not exactly markovian , our markovian approximation also captures other features of the natural signals , for example generating a similar number of velocity reversals per second .",
    "again we interpolate these trajectories to obtain a stimulus at @xmath1 resolution .    * entropy estimation in a model problem .",
    "* the problem in fig [ errors ] is that of a potentially biased coin .",
    "heads appear with probability @xmath15 , and the probability of observing @xmath77 heads out of @xmath12 flips is @xmath78 if we observe @xmath77 and try to infer @xmath15 , we use bayes rule to construct @xmath79 where @xmath80 is our prior and @xmath81 . given this posterior distribution of @xmath15 we can calculate the distribution of the entropy , @xmath82 we proceed as usual to define a function @xmath83 that is the inverse of @xmath84 , that is @xmath85 ; since @xmath15 and @xmath86 give the same value of @xmath87 , we choose @xmath88 and let @xmath89 .",
    "then we have @xmath90 { \\bigg | } { { dg(s)}\\over{ds}}{\\bigg | } .\\ ] ] from this distribution , we can estimate a mean @xmath91 and a variance @xmath92 in the usual way .",
    "what interests us is the difference between @xmath91 and the true entropy @xmath84 associated with the actual value of @xmath15 characterizing the coin ; it makes sense to measure this difference in units of the standard deviation @xmath93 .",
    "thus we compute @xmath94 , \\ ] ] and this is what is shown in fig [ errors ] .",
    "we consider two cases .",
    "first , a flat prior on @xmath15 itself , so that @xmath95 .",
    "second , a flat prior on the entropy , which corresponds to @xmath96 note that this prior is ( gently ) diverging near the limits @xmath97 and @xmath98 , but all the expectation values that we are interested in are finite .",
    "* entropy estimation : general features .",
    "* our discussion here follows refs @xcite very closely .",
    "consider a set of possible neural responses labeled by @xmath99 .",
    "the probability distribution of these responses , which we do nt know , is given by @xmath100 .",
    "a well studied family of priors on this distribution is the dirichlet prior , parameterized by @xmath101 , @xmath102 \\delta\\left(\\sum_{{\\rm i } = 1}^k p_{\\rm i } -1\\right ) .\\ ] ] maximum likelihood estimation , which identifies probabilities with frequencies of occurrence , is obtained in the limit @xmath103 , while @xmath104 is the natural `` uniform '' prior .",
    "when @xmath13 becomes large , almost any @xmath105 chosen out of this distribution has an entropy @xmath106 very close to the mean value , @xmath107 where @xmath108 , and @xmath109 is the gamma function . we therefore construct a prior which is approximately flat on the entropy itself by a continuous superposition of dirichlet priors , @xmath110 and we then use this prior to perform standard bayesian inference .",
    "in particular , if we observe each alternative @xmath111 to occur @xmath112 times in our experiment , then @xmath113 and hence by bayes rule @xmath114 { \\cal p}({\\bf p } ) .\\ ] ] once we normalize this distribution we can integrate over all @xmath105 to give the mean and the variance of the entropy given our data @xmath115 .",
    "in fact , all the integrals can be done analytically except for the integral over @xmath101 .",
    "software implementation of this approach is available from http://nsb - entropy.sourceforge.net/. this basic strategy can be supplemented in cases where we have prior knowledge about the entropies . in particular , when we are trying to estimate entropy in `` words '' of increasing duration @xmath19 , we know that @xmath116 for any @xmath117 , and thus it makes sense to constrain the priors at @xmath19 using the results from smaller windows , although this is not critical to our results .",
    "we obtain results at all integer values of @xmath20 for which our estimation procedure is stable ( see below ) and use cubic splines to interpolate to non  integer values as needed .",
    "* entropy estimation : details for total entropy .",
    "* there are two critical challenges to estimating the entropy of neural responses to natural signals .",
    "first , the overall distribution of ( long ) words has a zipf  like structure ( fig [ ent+inf_results]b ) , which is troublesome for most estimation strategies and leads to biases dependent on sample size .",
    "second , the long correlation times in the stimulus mean that , successive words ` spoken ' by the neuron are strongly correlated , and hence it is impossible to guarantee that we have independent samples , as assumed implicitly in eq ( [ pngivenp ] ) .",
    "we can tame the long tails in the probability distribution by partitioning the space of responses , estimating entropies within each partition , and then using the additivity of the entropy to estimate the total .",
    "we investigate a variety of different partitions , including ( a ) no spikes vs.  all other words , ( b ) no spikes , all words with one spike , all words with two spikes , etc .",
    ", ( c ) no spikes , all words with frequencies of over 1000 , and all other words .",
    "further , for each partitioning , we follow @xcite and evaluate @xmath23 for data sets of different sizes @xmath118 , @xmath119 .",
    "note that by choosing fractions of the data in different ways we can separate the problems of correlation and sample size .",
    "thus , to check that our estimates are stable as a function of sample size , we choose contiguous segments of experiment , while to check for the impact of correlations we can ` dilute ' our sampling so that there are longer and longer intervals between words .",
    "obviously there are limits to this exploration ( one can not access large , very dilute samples ) , but as far as we could explore the impact of correlations on our estimates is negligible once the samples sizes are sufficiently large . for the effects of sample size we look for behavior of the form @xmath120 and take @xmath121 as our estimate of @xmath23 , as in ref @xcite . for all partitions",
    "in which the the most common word ( silence ) is separated from the rest , these extrapolated estimates agree and indicate negligible biases at all combinations of @xmath7 and @xmath19 for which the @xmath122 term is negligible compared to the @xmath123 ( that is , @xmath124 ms at @xmath125 ms ) . for smaller @xmath7",
    ", estimation fails at progressively smaller @xmath19 , and to obtain an entropy rate for large @xmath19 we extrapolate to @xmath126 using @xmath127 where @xmath128 is our best estimate of the entropy rate at resolution @xmath7 .",
    "all fits were of high quality , and the resulting error bars on the total entropy are negligible compared to those for the noise entropy . in principle , we could be missing features of the code which appear _ only _ when we use high resolution for very long words , but this unlikely scenario is almost impossible to exclude by any means .",
    "* entropy estimation : details for noise entropy .",
    "* putting error bars on the noise entropy averaged over time is more difficult because these should include a contribution from the fact that our finite sample over time is only an approximation to the true average over the underlying distribution of stimuli .",
    "most seriously , the entropies are very different in epochs that have net positive or negative velocities . because of the way that we constructed the repeated stimulus , @xmath129 , with @xmath130 ; thus if we compute @xmath131 with @xmath132 , this fluctuates much less as a function of @xmath29 than the entropy in an individual slice . because our stimulus has zero mean , every slice has a partner under this shift , and the small difference between @xmath133 and @xmath134 takes account of the difference in latency between responses to positive and negative inputs .",
    "a plot of @xmath135 vs time @xmath29 has clear dips at times corresponding to zero crossings of the stimulus , and we partition the data at these points .",
    "we derive error bars on the mean noise entropy @xmath136 by a bootstrap  like method , in which we construct samples by randomly sampling with replacements from among these blocks , jittering the individual entropies @xmath53 by the errors that emerge from the bayesian analysis of individual slices . as with the total entropy we extrapolate to otherwise inaccessible combinations of @xmath19 and @xmath7 , now writing @xmath137 and fitting by weighted regression . note that results at different @xmath19 but the same value of @xmath7 are strongly correlated , and so the computation of @xmath138 is done using the full ( non  diagonal ) covariance matrix .",
    "the periodic term is important at small @xmath7 , where we can see structure as the window size @xmath19 crosses integer multiples of the average interspike interval , @xmath139 .",
    "error estimates emerge from the regression in the standard way , and all fits had @xmath140 per degree of freedom .",
    "* impact of photon flux on information rates . *",
    "since there are no responses to repeated and unrepeated stimuli recorded at exactly the same illuminations , we use the data from the repeated experiment to evaluate both the noise entropy and the total entropy .",
    "we expect that we are looking for small differences , so we tighten our analysis by discarding the first two trials , which are significantly different from all the rest ( presumably because adaptation is not complete ) , as well as excluding the epochs in which the stimulus was padded with zeroes .",
    "the remaining 98 trials are split into two groups of 49 trials each with the highest and the lowest ambient light levels .",
    "we can then estimate the total entropy @xmath141 for the high @xmath142 and low @xmath143 intensity groups of trials , and similarly for the noise entropy in each slice at time @xmath29 , @xmath144 . as noted above ,",
    "assigning error bars is clearer once we form quantities that are balanced across positive and negative velocities , and we do this directly for the difference in noise entropies , @xmath145\\nonumber\\\\ & & \\,\\,\\,\\,\\,\\,\\,\\,\\,\\ , - [ s_n^{(l)}(t,\\tau |t ) + s_n^{(l)}(t,\\tau |t+t_1')],\\nonumber\\\\ & & \\end{aligned}\\ ] ] where we allow for a small difference in latencies ( @xmath146 ) between the groups of trials at different intensities .",
    "we find that @xmath147 has a unimodal distribution and a correlation time of @xmath148 ms , which allows for an easy evaluation of the estimation error .",
    "99 f rieke , d warland , r de ruyter van steveninck & w bialek _ spikes : exploring the neural code _",
    "( mit press , cambridge , 1997 ) .",
    "d mackay & ws mcculloch , the limiting information capacity of a neuronal link .",
    "_ bull math biophys _ * 14 , * 127135 ( 1952 ) .",
    "m abeles , _ local cortical circuits : an electrophysiological study _ ( springer  verlag , berlin , 1982 ) .",
    "sp strong , r koberle , rr de ruyter van steveninck & w bialek , entropy and information in neural spike trains .",
    "_ phys rev lett _ * 80 , * 197200 ( 1998 ) .",
    "ce carr , processing of temporal information in the brain .",
    "_ ann rev neurosci _ * 16 , * 223243 ( 1993 ) .",
    "jj hopfield , pattern recognition computation using action potential timing for stimulus representation .",
    "_ nature _ * 376 , * 3336 ( 1995 ) .",
    "k hausen , the lobular complex of the fly : structure , function and significance in behavior . in _",
    "photoreception and vision in invertebrates _ , m ali , ed , pp 523559 ( plenum , new york , 1984 ) .",
    "gd lewen , w bialek & rr de ruyter van steveninck , neural coding of naturalistic motion stimuli .",
    "_ network _ * 12 , * 317329 ( 2001 ) ; physics/0103088 .",
    "i nemenman , f shafee & w bialek , entropy and inference , revisited . in _ advances in neural information processing systems 14 _ , tg dietterich , s becker & z gharamani , eds , pp 471478 ( mit press , cambridge , 2002 ) ; physics/0108025 .",
    "i nemenman , inference of entropies of discrete random variables with unknown cardinalities ; physics/0207009 ( 2002 ) .",
    "i nemenman , w bialek & r de ruyter van steveninck , entropy and information in neural spike trains : progress on the sampling problem .",
    "_ phys rev e _ * 69 , * 056111 ( 2004 ) ; physics/0306063 .",
    "hb barlow , sensory mechanisms , the reduction of redundancy and intelligence .",
    "in _ proceedings of the symposium on the mechanization of thought processes , vol 2 _ , dv blake & am uttley , eds , pp 537574 ( hm stationery office , london , 1959 ) .",
    "hb barlow , possible principles underlying the transformation of sensory messages . in _ sensory communication _ , w rosenblith , ed , pp 217234 ( mit press , cambridge , 1961 ) .",
    "w reichardt & t poggio , visual control of orientation behavior in the fly .",
    "part i : a quantitative analysis .",
    "_ q rev biophys _ * 9 , * 311375 ( 1976 ) .",
    "k hausen & c wehrhahn , microsurgical lesions of horizontal cells changes optomotor yaw responses in the blowfly _",
    "calliphora erythrocephela_. _ proc r soc lond ser b _ * 219 , * 211216 ( 1983 ) .",
    "mf land & ts collett , chasing behavior of houseflies ( _ fannia canicularis _ ) . a description and analysis .",
    "_ j comp physiol _ * 89 , * 331357 ( 1974 ) .",
    "h wagner , flight performance and visual control of flight in the free  flying house fly ( _ musca domestica l. _ ) .",
    "_ phil trans r soc ser b _ * 312 , * 527595 ( 1986 ) .",
    "c schilstra & jh van hateren , blowfly flight and optic flow . i. thorax kinematics and flight dynamics . _ j exp biol _ * 202 , * 14811490 ( 1999 ) .",
    "jh van hateren & c schilstra , blowfly flight and optic flow .",
    "ii . head movements during flight . _ j exp biol _ * 202 , * 14911500 ( 1999 ) .",
    "r de ruyter van steveninck , a borst & w bialek , real time encoding of motion : answerable questions and questionable answers from the fly s visual system . in _ processing visual motion in the real world : a survey of computational , neural and ecological constraints , _ jm zanker & j zeil , eds , pp 279306 ( springer  verlag , berlin , 2001 ) ; physics/0004060 .",
    "jh van hateren , r kern , g schwerdtfeger & m egelhaaf , function and coding in the blowfly h1 neuron during naturalistic optic flow .",
    "_ j neurosci _ * 25 , * 43434352 ( 2005 ) .",
    "s ma , calculation of entropy from data of motion .",
    "_ j stat phys _ * 26 , * 221240 ( 1981 ) .",
    "gaf seber , _ estimation of animal abundance and related parameters_. ( griffin , london , 1973 ) .",
    "ga miller , note on the bias of information estimates . in _ information theory in psychology : problems and methods ii ",
    "b _ , h quastler , ed , pp 95100 ( free press , glencoe il , 1955 ) . a treves & s panzeri , the upward bias in measures of information derived from limited data samples .",
    "_ neural comp _ * 7 , * 399407 ( 1995 ) .",
    "l paninski , estimation of entropy and mutual information .",
    "_ neural comp _ * 15 , * 11911253 ( 2003 ) .",
    "rr de ruyter van steveninck , gd lewen , sp strong , r koberle & w bialek , reproducibility and variability in neural spike trains .",
    "_ science _ * 275 , * 18051808 ( 1997 ) .",
    "gk zipf , _ human behavior and the principle of least effort _",
    "( addison  wesley , cambridge , 1949 ) .",
    "r de ruyter van steveninck & w bialek , real  time performance of a movement sensitive neuron in the blowfly visual system : coding and information transfer in short spike sequences . _ proc r soc london ser b _ * 234 , * 379414 ( 1988 ) .",
    "i nemenman & w bialek , occam factors and model  independent bayesian learning of continuous distributions . _ phys rev e _ * 65 , * 026137 ( 2002 ) ; cond - mat/0009165 . dm green & ja swets , _ signal detection theory and psychophysics _ ( wiley , new york , 1966 ) . ce carr , w heiligenberg & gj rose , a time  comparison circuit in the electric fish midbrain . i. behavior and physiology .",
    "_ j neurosci _ * 10 , * 32273246 ( 1986 ) .",
    "n brenner , sp strong , r koberle , w bialek & rr de ruyter van steveninck , synergy in a neural code .",
    "_ neural comp _ * 12 , * 15311552 ( 2000 ) ; physics/9902067 .",
    "p reinagel & rc reid , temporal coding of visual information in the thalamus .",
    "_ j neurosci _ * 20 , * 53925400 ( 2000 ) .",
    "w bialek , f rieke , rr de ruyter van steveninck & d warland , reading a neural code .",
    "_ science _ * 252 , * 18541857 ( 1991 ) .",
    "r de ruyter van steveninck & w bialek , reliability and statistical efficiency of a blowfly movement  sensitive neuron . _ phil trans r soc lond ser b _ * 348 , * 321340 ( 1995 ) . rr de ruyter van steveninck & sb laughlin , the rate of information transfer at graded  potential synapses",
    ". _ nature _ * 379 , * 642645 ( 1996 ) .",
    "r de ruyter van steveninck & sb laughlin , light adaptation and reliability in blowfly photoreceptors .",
    "_ int j neural syst _ * 7 , * 437444 ( 1996 ) ."
  ],
  "abstract_text": [
    "<S> our knowledge of the sensory world is encoded by neurons in sequences of discrete , identical pulses termed action potentials or spikes . </S>",
    "<S> there is persistent controversy about the extent to which the precise timing of these spikes is relevant to the function of the brain . </S>",
    "<S> we revisit this issue , using the motion  sensitive neurons of the fly visual system as a test case . </S>",
    "<S> new experimental methods allow us to deliver more nearly natural visual stimuli , comparable to those which flies encounter in free , acrobatic flight , and new mathematical methods allow us to draw more reliable conclusions about the information content of neural responses even when the set of possible responses is very large . </S>",
    "<S> we find that significant amounts of visual information are represented by details of the spike train at millisecond and sub  millisecond precision , even though the sensory input has a correlation time of @xmath0 ; different patterns of spike timing represent distinct motion trajectories , and the absolute timing of spikes points to particular features of these trajectories with high precision . under these naturalistic conditions , </S>",
    "<S> the system continues to transmit more information at higher photon flux , even though individual photoreceptors are counting more than one million photons per second , and removes redundancy in the stimulus to generate a more efficient neural code . </S>"
  ]
}