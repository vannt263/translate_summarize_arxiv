{
  "article_text": [
    "the progress in three - dimensional ( 3d ) modeling research has been rapid and hectic , fueled by recent breakthroughs in keypoint detection and matching , the advances in computational power of desktop and mobile devices , the advent of digital photography and the subsequent availability of large datasets of public images .",
    "today , the goal of definitively bridging the gap between physical reality and the digital world seems within reach given the magnitude , breadth and scope of current 3d modeling systems .",
    "three dimensional modeling is the process of recovering the properties of the environment and optionally of the sensing instrument from a series of measures .",
    "this generic definition is wide enough to accommodate very diverse methodologies , such as time - of - flight laser scanning , photometric stereo or satellite triangulation .",
    "the structure - and - motion(a.k.a .",
    "structure - from - motion ) field of research is concerned with the recovery of the three dimensional geometry of the scene ( the structure ) when observed through a moving camera ( the motion ) .",
    "sensor data is either a video or a set of exposures ; additional informations , such as the calibration parameters , can be used if available .",
    "this paper describes our contributions to the problem of structure - and - motionrecovery from unordered , uncalibrated images i.e , the problem of building a three dimensional model of a scene given a set of exposures .",
    "the sought result ( the `` model '' ) is generally a 3d point - cloud consisting of the points whose projection was identified and matched in the images and a set of camera matrices , identifying position and attitude of each image with respect to an arbitrary reference frame .",
    "the main challenges to be solved are computational efficiency ( in order to be able to deal with more and more images ) and generality , i.e. , the amount of ancillary information that is required .    to address the efficiency issue we propose to describe the entire structure - and - motionprocess as a binary tree ( called _ dendrogram _ ) constructed by agglomerative clustering over the set of images .",
    "each leaf corresponds to a single image , while internal nodes represent partial models obtained by merging the left and right sub - nodes .",
    "computation proceeds from bottom to top , starting from several seed couples and eventually reaching the root node , corresponding to the complete model .",
    "this scheme provably cuts the computational complexity by one order of magnitude ( provided that the dendrogram is well balanced ) , and it is less sensitive to typical problems of sequential approaches , namely sensitivity to initialization @xcite and drift @xcite .",
    "it is also scalable and efficient , since it partitions the problem into smaller instances and combines them hierarchically , making it inherently parallelizable .    on the side of generality ,",
    "our aim is to push the `` pure '' structure - and - motiontechnique as far as possible , to investigate what can be achieved without including any auxiliary information .",
    "current structure - and - motionresearch has partly sidestepped this issue using ancillary data such as exif tags embedded in conventional image formats .",
    "their presence or consistency , however , is not guaranteed .",
    "we describe our approach to autocalibration , which is the process of automatic estimation from images of the internal parameters of the cameras that captured them , and we therefore demonstrate the first structure - and - motionpipeline capable of using unordered , uncalibrated images .      the main issue to address in structure - and - motionis the computational complexity , which is dominated by the bundle adjustment phase , followed by feature extraction and matching .",
    "a class of solutions that have been proposed are the so - called partitioning methods @xcite .",
    "they reduce the structure - and - motionproblem into smaller and better conditioned subproblems which can be effectively optimized . within this approach",
    ", two main strategies can be distinguished .",
    "the first one is to tackle directly the bundle adjustment algorithm , exploiting its properties and regularities .",
    "the idea is to split the optimization problem into smaller , more tractable components .",
    "the subproblems can be selected analytically as in @xcite , where spectral partitioning has been applied to structure - and - motion , or they can emerge from the underlying 3d structure of the problem , as described in @xcite . the computational gain of such methods is obtained by limiting the combinatorial explosion of the algorithm complexity as the number of images and points increases .    the second strategy is to select a subset of the input images and points that subsumes the entire solution .",
    "hierarchical sub - sampling was pioneered by @xcite , using a balanced tree of trifocal tensors over a video sequence . the approach was subsequently refined by @xcite , adding heuristics for redundant frames suppression and tensor triplet selection . in @xcite",
    "the sequence is divided into segments , which are resolved locally .",
    "they are subsequently merged hierarchically , eventually using a representative subset of the segment frames .",
    "a similar approach is followed in @xcite , focusing on obtaining a well behaved segment subdivision and on the robustness of the following merging step .",
    "the advantage of these methods over their sequential counterparts lies in the fact that they improve error distribution on the entire dataset and bridge over degenerate configurations . in any case",
    ", they work for video sequences , so they can not be applied to unordered , sparse images . the approach of @xcite works with sparse datasets and is based on selecting a subset of images whose model provably approximates the one obtained using the entire set .",
    "this considerably lowers the computational requirements by controllably removing redundancy from the dataset . even in this case , however , the images selected are processed incrementally . moreover",
    ", this method does not avoid computing the epipolar geometry between all pairs of images .    within the solutions aimed at reducing the impact of the bundle adjustment phase ,",
    "hierarchical approaches include @xcite and this paper .",
    "the first can be considered as the first paper where the idea has been set forth : a spanning tree is built to establish in which order the images must be processed .",
    "after that , however , the images are processed in a standard incremental way .",
    "the approach described in @xcite is based on recursive partitioning of the problem into fully - constrained sub - problems , exploiting the bipartite structure of the visibility graph .",
    "the partitioning operates on the problem variables , whereas our approach works on the input images .",
    "orthogonally to the aforementioned approaches , a solution to the the computational complexity of structure - and - motionis to throw additional computational power at the problem @xcite .",
    "within such a framework , the former algorithmic challenges are substituted by load balancing and subdivision of tasks .",
    "such a direction of research strongly suggest that the current monolithic pipelines should be modified to accommodate ways to parallelize and optimally split the workflow of structure - and - motiontasks . in @xcite image selection ( via clustering ) is combined with a highly parallel implementation that exploits graphic processors and multi - core architectures .",
    "the impact of the bundle adjustment phase can also be reduced by adopting a different paradigm in which _ first _ the motion is recovered and _ then _ the structure is computed .",
    "all these methods start from the relative orientation of a subset of camera pairs ( or triplets ) , computed from point correspondences , then solve for the absolute orientation of all the cameras ( _ globally _ ) , reconstruct 3d points by intersection , and finally run a single bundle adjustment to refine the reconstruction .",
    "camera internal parameters are required .",
    "the method described in @xcite solves a homogeneous linear system based on a novel decomposition of the essential matrix that involves the absolute parameters only . in @xcite",
    "nonlinear optimization is performed to recover camera translations given a network of both noisy relative translation directions and 3d point observations .",
    "this step is preceded by outlier removal among relative translations by solving simpler low - dimensional subproblems .",
    "the authors of @xcite propose a discrete markov random field formulation in combination with levenberg - marquardt minimization .",
    "this technique requires additional information as input , such as geotag locations and vanishing points .",
    "other approaches ( e.g. @xcite ) compute translations together with the structure , involving a significant number of unknowns .",
    "the method presented in @xcite proposes a fast spectral solution by casting translation recovery in a graph embedding problem .",
    "govindu in @xcite derives a homogeneous linear system of equations in which the unknown epipolar scaling factors are eliminated by using cross products , and this solution is refined through iterative reweighted least squares .",
    "the authors of @xcite propose a linear algorithm based on an approximate geometric error in camera triplets .",
    "moulon et al .",
    "@xcite extract accurate relative translations by using an a - contrario trifocal tensor estimation method , and then recover simultaneously camera positions and scaling factors by using an @xmath0-norm approach .",
    "similarly to @xcite , this method requires a graph covered by contiguous camera triplets .",
    "the authors of @xcite propose a two - stage method in which relative translation directions are extracted from point correspondences by using robust subspace optimization , and then absolute translations are recovered through semidefinite programming .",
    "another relevant issue in structure - and - motionis the level of generality , i.e. , the number of assumption that are made concerning the input images , or , equivalently the amount of extra information that is required in addition to pixel values .",
    "existing pipelines either assume known internal parameters @xcite , or constant internal parameters @xcite , or rely on exif data plus external information ( camera ccd dimensions ) @xcite .",
    "methods working in large scale environments usually rely on a lot of additional information , such as camera calibration and gps / ins navigation systems @xcite or geotags @xcite .",
    "autocalibration ( a.k.a .",
    "self - calibration ) has generated a lot of theoretical interest since its introduction in the seminal paper by maybank and faugeras @xcite .",
    "the attention created by the problem however is inherently practical , since it eliminates the need for off - line calibration and enables the use of content acquired in an uncontrolled setting .",
    "modern computer vision has partly sidestepped the issue by using ancillary information , such as exif tags embedded in some image formats .",
    "unfortunately it is not always guaranteed that such data will be present or consistent with its medium , and do not eliminate the need for reliable autocalibration procedures",
    ".    a great deal of published methods rely on equations involving the dual image of the absolute quadric ( diaq ) , introduced by triggs in @xcite .",
    "earlier approaches for variable focal lengths were based on linear , weighted systems @xcite , solved directly or iteratively @xcite .",
    "their reliability has been improved by more recent algorithms , such as @xcite , solving super - linear systems while directly forcing the positive definiteness of the diaq .",
    "such enhancements were necessary because of the structural non - linearity of the task : for this reason the problem has also been approached using branch and bound schemes , based either on the kruppa equations @xcite , dual linear autocalibration @xcite or the modulus constraint @xcite .",
    "the algorithm described in @xcite shares , with the branch and bound approaches , the guarantee of convergence ; the non - linear part , corresponding to the localization of the plane at infinity , is solved exhaustively after having used the cheiral inequalities to compute explicit bounds on its location .",
    "this paper describes a hierarchical and parallelizable scheme for structure - and - motion ; please refer to fig .",
    "[ fig : schema ] for a graphical overview .",
    "the front end of the pipeline is keypoint extraction and matching ( sec .",
    "[ sec : match ] ) , where the latter is subdivided into two stages : the first ( `` broad phase '' ) is devoted to discovering the tentative topology of the epipolar graph , while the second ( `` narrow phase '' ) performs the fine matching and computes the epipolar geometry .",
    "images are then organized into a dendrogram by clustering them according to their overlap ( sec .",
    "[ sec : dendro ] ) .",
    "a new clustering strategy , derived from the simple linkage , is introduced ( sec .",
    "[ sec : balance ] ) that makes the dendrogram more balanced , thereby approaching the best - case complexity of the method .",
    "the structure - and - motioncomputation proceeds hierarchically along this tree , from the leaves to the root ( sec .",
    "[ sec : hierarchical ] ) .",
    "images are stored in the leaves , whereas partial models correspond to internal nodes . according to the type of node , three operations are possible : stereo modeling ( image - image ) , resection - intersection ( image - model ) or merging ( model - model ) .",
    "bundle adjustment is run at every node , possibly in its `` local '' form ( sec .",
    "[ sec : localba ] ) .",
    "we demonstrate that this paradigm has several advantages over the sequential one , both in terms of computational performance ( which improves by one order of magnitude on average ) and overall error containment .",
    "autocalibration ( sec .",
    "[ sec : urec ] ) is performed on partial models during the dendrogram traversal .",
    "first , the location of the plane at infinity is derived given two perspective projection matrices and a guess on their internal parameters , and subsequently this procedure is used to iterate through the space of internal parameters looking for the best collineation that makes the remaining cameras euclidean .",
    "this approach has several advantages : it is fast , easy to implement and reliable , since a reasonable solution can always be found in non - degenerate configurations , even in extreme cases such as when autocalibrating just two cameras .",
    "being conscious that `` the devil is in the detail '' , section [ sec : devil ] reports implementation details and heuristics for setting the parameters of the pipeline .",
    "the experimental results reported in sec .  [ sec : exp ] are exhaustive and analyze the output of the pipeline in terms of accuracy , convergence and speed .",
    "we report here on the latest version of our pipeline , called samantha .",
    "previous variants have been described in @xcite and @xcite respectively .",
    "the main improvements are in the matching phase and in the autocalibration that now integrates the method described in @xcite .",
    "the geometric stage has been carefully revised to make it more robust , to the point where  in some cases  bundle adjustment is not needed any more except at the end of the process .",
    "most efforts have been made in the direction of a robust and automatic approach , avoiding unnecessary parameter tuning and user intervention .",
    "in this section we describe the stage of samanthathat is devoted to the automatic extraction and matching of keypoints among all the @xmath1 available images .",
    "its output is to be fed into the geometric stage , that will perform the actual structure - and - motionrecovery .",
    "good and reliable matches are the key for any geometric computation .",
    "although most of the building blocks of this stage are fairly standard techniques , we carefully assembled a procedure that is fully automatic , robust ( matches are pruned to discard as many outliers as possible ) and computationally efficient .",
    "the procedure for recovering the epipolar graph is indeed new .",
    "first of all , keypoints are extracted in all @xmath1 images .",
    "we implemented the keypoint detector proposed by @xcite , where blobs with associated scale levels are detected from scale - space extrema of the scale - normalized laplacian : @xmath2 we used a 12-level scale - space and in each level the laplacian is computed by convolution ( in cuda ) with a @xmath3 kernel .",
    "as for the descriptor , we implemented a 128-dimensional radial descriptor ( similar to the log - polar grid of gloh @xcite ) , based on the accumulated response of steerable derivative filters .",
    "this combination of detector / descriptor performs in a comparable way to sift and avoids patent issues .",
    "only a given number of keypoints with the strongest response overall are retained .",
    "this number is a multiple of @xmath1 , so as to fix the average quota of keypoints per image ( details in sec .",
    "[ sec : devil ] ) .      as the images are unordered , the first objective is to recover the _ epipolar graph _ ,",
    "i.e. , the graph that tells which images overlap ( or can be matched ) with each other .",
    "this must be done in a computationally efficient way , without trying to match keypoints between every image pair . as a matter of fact ,",
    "keypoint matching is one of the most expensive stages , so one would like to reduce the number of images to be matched from @xmath4 to @xmath5 .    in this broad phase",
    "we consider only a small constant number of descriptors for each image .",
    "in particular , we consider the keypoints with the highest scales , since their descriptors are more representative of the whole image content .",
    "then , each keypoint descriptor is matched to its approximate nearest neighbors in feature space , using the ann library @xcite ( with @xmath6 ) .",
    "a 2d histogram is then built that registers in each bin the number of matches between the corresponding images .",
    "consider the complete weighted graph @xmath7 where @xmath8 are images and the weighted adjacency matrix is the 2d histogram .",
    "this graph is  in general ",
    "dense , having @xmath9 .",
    "the objective is to extract a subgraph @xmath10 with a number of edges that is linear in @xmath1 .    in the approach of @xcite , also followed in @xcite , every image is connected ( in the epipolar graph ) to the @xmath11 images that have the greatest number of keypoint matches with it .",
    "this creates a graph with @xmath12 edges , where the average degree is @xmath13 ( by the handshaking lemma ) .",
    "when the number of images is large , however , it tends to create cliques of very similar images with weak ( or no ) inter - clique connections . on the other hand",
    ", one would like to get an epipolar graph that is strongly connected , to avoid over - fragmentation in the subsequent clustering phase .",
    "this idea is captured by the notion of _ @xmath14-edge - connectedness _ : in graph theory , a graph is @xmath14-edge - connected if it remains connected whenever fewer than @xmath14 edges are removed .",
    "so , the graph produced by the original approach has a low @xmath14 , while one would like to have @xmath14 as high as possible ( ideally @xmath15 ) , with same edge budget .",
    "we devised a strategy that builds a subgraph @xmath10 of @xmath16 which is `` almost '' @xmath11-edge - connected by construction .    1 .",
    "build the maximum spanning tree of @xmath16 : the tree is composed of @xmath17 edges ; 2 .   remove them from @xmath16 and add them to @xmath10 ; 3 .",
    "repeat @xmath11 times .    in the hypothesis that @xmath11 spanning trees can be extracted from @xmath16 ,",
    "the algorithm produces a subgraph @xmath10 that is @xmath11-edge - connected ( a simple proof of this is given in [ sec : app2 ] ) .",
    "please note that by taking the _ maximum _ spanning tree we favor edges with high weight .",
    "so this strategy can be seen as a compromise between picking pairs with the highest score in the histogram , as in the original approach , and creating a strongly connected epipolar graph .",
    "if the hypothesis about @xmath16 is not verified , a spanning forest will be obtained at a certain iteration , and @xmath10 will not be @xmath11-edge - connected . however , when @xmath18 one could expect that `` almost ''",
    "@xmath11 spanning trees can be extracted from @xmath16 without disconnecting it .",
    "keypoint matching follows a nearest neighbor approach @xcite , with rejection of those keypoints for which the ratio of the nearest neighbor distance to the second nearest neighbor distance is greater than a threshold ( see sec .  [",
    "sec : devil ] ) .",
    "matches that are not injective are discarded .    in order to speed up the matching phase",
    "we employ a keypoint clustering technique similar to @xcite .",
    "every keypoint is associated with a different cluster according to its dominant angle , as recorded in the descriptor .",
    "only keypoints belonging to the same cluster are matched together ( in our implementation we used eight equidistant angular clusters ) : this breaks down the quadratic complexity of the matching phase at the expense of loosing some matches at the border of the clusters .",
    "homographies and fundamental matrices between pairs of matching images are then computed using m - estimator sample consensus ( msac ) @xcite , a variation of ransac that gives outliers a fixed penalty but scores inliers on how well they fit the data .",
    "this makes the output less sensitive to a higher inlier threshold , thereby rendering less critical the choice of the threshold , at no extra computational cost with respect to ransac .",
    "the random sampling is done with a _ bucketing _ technique @xcite , which forces keypoints in the sample to be spatially separated .",
    "this helps to reduce the number of iterations and provide more stable estimates . since ransac and its variants ( like msac ) have a low statistical efficiency ,",
    "the model must finally be re - estimated on a refined set of inliers .",
    "let @xmath19 be the residuals of _ all _ the @xmath20 keypoints after msac , and let @xmath21 be the sample that attained the best score ; following @xcite , a robust estimator of the scale is : @xmath22 the resulting set of inliers are those points such that @xmath23 where @xmath24 is a constant ( we used 2.5 ) .",
    "the model parameters are re - estimated on this set of inliers via least - squares minimization of the ( first - order approximation of the ) geometric error @xcite .    the more likely model ( homography or fundamental matrix )",
    "is selected according to the geometric robust information criterion ( gric ) @xcite : @xmath25 where @xmath26 is the standard deviation of the measurement error , @xmath14 is the number of parameters of the model , @xmath27 is the dimension of the fitted manifold , and @xmath28 is the dimension of the measurements . in our case ,",
    "@xmath29 for fundamental matrices and @xmath30 for homographies",
    ". the model with the lower gric is the more likely .        in the end , if the number of remaining matches @xmath31 between two images is less than 20% of the total number of matches before msac , then they are discarded .",
    "the rationale is that if an excessive fraction of oultliers have been detected , the original matches are altogether unreliable .",
    "a similar formula is derived in @xcite on the basis of a probabilistic model . as a safeguard ,",
    "a threshold on the minimum number of matches is also set ( details in sec .",
    "[ sec : devil ] ) .",
    "after that , keypoint matching in multiple images are connected into _ tracks _ ( see figure [ fig : tracce ] ) : consider the undirected graph @xmath32 where @xmath8 are the keypoints and @xmath33 represents matches ; a track is a connected component of @xmath16 .",
    "vertices are labeled with the image the keypoints belong to : an inconsistency arises when in a track a label occurs more than once .",
    "inconsistent tracks and those shorter than three frames are discarded .",
    "a track represents the projection of a single 3d point imaged to multiple exposures ; such a 3d point is called a _ tie - point_.",
    "the images are organized into a tree with agglomerative clustering , using a measure of overlap as the distance .",
    "the structure - and - motioncomputation then follows this tree from the leaves to the root . as a result",
    ", the problem is broken into smaller instances , which are then separately solved and combined .",
    "algorithms for image clustering have been proposed in the literature in the context of structure - and - motion@xcite , panoramas @xcite , image mining @xcite and scene summarization @xcite .",
    "the distance being used and the clustering algorithm are application - specific .    in this paper",
    "we deploy an image affinity measure that befits the structure - and - motiontask .",
    "it is computed by taking into account the number of tie - points visible in both images and how well their projections ( the keypoints ) spread over the images . in formulae , let @xmath34 and @xmath35 be the set of visible tie - points in image @xmath36 and @xmath37 respectively : @xmath38 where @xmath39 is the area of the convex hull of a set of image points and @xmath40 ( @xmath41 ) is the total area of image @xmath36 ( @xmath37 ) .",
    "the first term is an affinity index between sets , also known as the jaccard index .",
    "the distance is @xmath42 , as @xmath43 ranges in @xmath44 $ ] .",
    "the general agglomerative clustering algorithm proceeds in a bottom - up manner : starting from all singletons , each sweep of the algorithm merges the two clusters with the smallest distance between them .",
    "the way the distance between clusters is computed produces different flavors of the algorithm , namely the simple linkage , complete linkage and average linkage @xcite .",
    "we selected the _",
    "simple linkage _ rule : the distance between two clusters is determined by the distance of the two closest objects ( nearest neighbors ) in the different clusters .    simple linkage clustering is appropriate to our case because : i ) the clustering problem _ per se _ is fairly easy , ii ) nearest neighbors information is readily available with ann and iii ) it produces `` elongated '' or `` stringy '' clusters which fits very well with the typical spatial arrangement of images sweeping a certain area or building .",
    "before describing our hierarchical approach , let us set the notation and review the geometry tools that are needed .",
    "a _ model _ is a set of cameras and 3d points expressed in a local reference frame ( _ stereo - model _ with two cameras ) .",
    "the procedure of computing 3d point coordinates from corresponding points in multiple images is called _ intersection _ ( a.k.a .",
    "triangulation ) . recovering the camera matrix ( fully or limited to the external parameters ) from known 3d-2d correspondences",
    "is called _",
    "resection_. the task of retrieving the relative position and attitude of two cameras from corresponding points in the two images is called _ relative orientation_. the task of computing the rigid ( or similarity ) transform that brings two models that share some tie - points into a common reference frame is called _",
    "absolute orientation_.    let us assume _ pro tempore _ that the internal parameters are known ; this constraint is removed in sec .",
    "[ sec : urec ] .",
    "images are grouped together by agglomerative clustering , which produces a hierarchical , binary cluster tree , called a _",
    "dendrogram_. every node in the tree represents a partial , independent model . from the processing point of view , at every node in the dendrogram an action is taken that augments the model , as shown in figure [ fig:2.1 ] .",
    "three operations are possible : when two images are merged a stereo - model is built ( relative orientation + intersection ) .",
    "when an image is added to a cluster a resection - intersection step is taken ( as in the standard sequential pipeline ) .",
    "when two non - trivial clusters are merged , the respective models must be conflated by solving an absolute orientation problem ( followed by intersection ) .",
    "each of these steps is detailed in the following",
    ".     corresponds to the creation of a stereo - model , the triangle   corresponds to a resection - intersection , the diamond   corresponds to a fusion of two partial independent models . ]    while it is useful to conceptually separate the clustering from the modeling , the two phases actually occur simultaneously : during the simple linkage iteration , every time a merge is attempted the corresponding modeling action is taken .",
    "if it fails , the merge is discarded and the next possible merge is considered .",
    "the parameters of the relative orientation of two given cameras are obtained by factorization of the essential matrix @xcite .",
    "this is equivalent to knowing the external parameters of the two cameras in a local reference frame , and since the internal parameters are already known , the two camera matrices are readily set up",
    ". then tie - points are obtained by _ intersection _ ( see sec .  [",
    "sec : inter ] ahead ) from the tracks involving the two images , and the model is refined with bundle adjustment @xcite .",
    "it is worth noting that in order for this stereo - modeling to be successful the two images must satisfy two conflicting requirements : to have both a large number of tie - points in common and a baseline sufficiently large so as to allow a well - conditioned solution .",
    "the first requirement is implemented by the affinity defined in , but the second is not considered ; as a result , the pairing determined by image clustering is not always the best choice as far as the relative orientation problem is concerned . since in our pipeline",
    "the clustering and the structure - and - motionprocessing occurs simultaneously , these pairs will be discarded by simple sanity - checks before and after attempting to perform the stereo - modeling .",
    "the a - priori check requires that the relationship between the two images is described by a fundamental matrix ( instead of a homography ) , according to the gric score .",
    "the a - posteriori check considers the residual error and the cheirality check of the points before and after the bundle adjustment .",
    "intersection ( a.k.a .",
    "triangulation ) is performed by the iterated linear ls method @xcite .",
    "points are pruned by analyzing the condition number of the linear system and the reprojection error .",
    "the first test discards ill - conditioned intersections , using a threshold on the condition number of the linear system ( @xmath45 , in our experiments ) .",
    "the second test applies the so - called x84 rule @xcite , that establishes that , if @xmath19 are the residuals , the inliers are those points such that @xmath46    a safeguard threshold on the reprojection error is also set ( details in sec .",
    "[ sec : devil ] ) .    in general , the intersection module obeys the following strategy .",
    "as soon as one track reaches length two in a given model ( i.e. at least two images of the track belongs to the model ) , the coordinates of the corresponding tie - point are computed by intersection . if the operation fails ( because of one of the sanity checks described above ) the 3d point is provisionally discarded but the track is kept .",
    "an attempt to compute the tie - point coordinates is undertaken every time the length of the track increases within the model .",
    "the tie - points belonging to the model that are also visible in the image to be added provides a set of 3d-2d correspondences , that are exploited to glue the image to the partial model .",
    "this is done by resection , where only the external parameters of the camera are to be computed ( a.k.a .",
    "external orientation problem ) .",
    "we used the ppnp algorithm described in @xcite inside msac , followed by non - linear minimization of the reprojection error at the end .",
    "after resection , which adds one image to the model , tie - points are updated by intersection , and bundle adjustment is run on the resulting model .",
    "when two partial independent ( i.e. , with different reference systems ) models are are to be conflated into one , the first step is to register one onto the other with a similarity transformation .",
    "the common tie - points are used to solve an absolute orientation ( with scale ) problem with msac .    given the scale ambiguity , the inlier threshold for msac is hard to set . in @xcite a complex technique for the automatic estimation of the inlier threshold in 3d is proposed .",
    "we take a simpler but effective approach : instead of considering the length of the 3d segments that connect corresponding points as the residuals , we look at the average length of their 2d projections in the images ; in this way a meaningful inlier threshold in pixels can be set easily . the final transformation , computed with the orthogonal procrustean ( op ) method @xcite ,",
    "minimizes the proper geometric residual , i.e. the sum of squared distances of 3d points .",
    "once the models are registered , tie - points are updated by intersection , and the new model is refined with bundle adjustment .",
    "this hierarchical algorithm can be summarized as follows :    1 .",
    "solve many independent relative orientation problems at the leaves of the tree , producing many independent stereo - models .",
    "2 .   traverse the tree ; in each node one of these operations takes place : 1 .",
    "update one model by adding one image with resection followed by intersection ; 2 .   merge two independent models with absolute orientation .",
    "steps 1 .",
    "and 2.(a ) are the resection - intersection steps of classical sequential pipelines , as bundler .",
    "step 2.(b ) summons up the photogrammetric independent models block adjustment ( imba ) @xcite , where for each pair of overlapping photographs a stereo - model is built and then all these independent models are simultaneously transformed into a common reference frame with absolute orientation .",
    "if the tree reduces to a chain , the algorithm is the sequential one , whereas if the tree is perfectly balanced , only steps 2.(b ) are taken , and the resulting procedure resembles the imba , besides the fact that our models are disjoint and that models are recursively merged in pairs .",
    "compared to the standard sequential approach , this framework has a lower computational complexity , is independent of the initial pair of images , and copes better with drift problems , typical of sequential schemes .",
    "the hierarchical approach that has been outlined above allows us to decrease the computational complexity with respect to the sequential structure - and - motionpipeline .",
    "indeed , if the number of images is @xmath1 and every image adds a constant number of tie - points @xmath47 to the model , the computational complexity in time of sequential structure - and - motionis @xmath48 , whereas the complexity of samantha(in the best case ) is @xmath49 .",
    "the cost of bundle adjustment with @xmath11 tie - points and @xmath1 images is @xmath50 @xcite , hence it is @xmath49 if @xmath51 .    in sequential structure - and - motion ,",
    "adding image @xmath52 requires a constant number of bundle adjustments ( typically one or two ) with @xmath52 images , hence the complexity is @xmath53 in the case of the hierarchical approach , consider a node of the dendrogram where two models are merged into a model with @xmath1 images .",
    "the cost @xmath54 of adjusting that model is given by @xmath49 plus the cost of doing the same onto the left and right subtrees .",
    "in the hypothesis that the dendrogram is well balanced , i.e. , the two models have the same number of images , this cost is given by @xmath55 .",
    "hence the asymptotic time complexity @xmath56 in the best case is given by the solution of the following recurrence : @xmath57 that is @xmath58 by the third branch of the master s theorem @xcite .",
    "the worst case is when a single model is built up by adding one image at a time . in this case , which corresponds to the sequential case , the dendrogram is extremely unbalanced and the complexity drops to @xmath48 .",
    "as demonstrated in precedence , the hierarchical framework can provide a provable computational gain , provided that the resulting tree is well - balanced .",
    "the worst case complexity , corresponding to a sequence of single image additions , is no better than the standard sequential approach .",
    "it is therefore crucial to ensure a good balance during the clustering phase .",
    "our solution is to employ a novel clustering procedure , which promotes the creation of better balanced dendrograms .",
    "the image clustering procedure proposed in the previous section allows us to organize the available images into a hierarchical cluster structure ( a tree ) that will guide the structure - and - motionprocess .",
    "this approach decreases the computational complexity with respect to sequential structure - and - motionpipelines , from @xmath48 to @xmath49 in the best case , i.e. when the tree is well balanced ( @xmath1 is the number of images ) . if the tree is unbalanced this computational gains vanishes .",
    "it is therefore crucial to enforce the balancing of the tree .    the preceding solution , which used the simple rule , specified that the distance between two clusters is to be determined by the distance of the two closest objects ( nearest neighbors ) in the different clusters .",
    "in order to produce better balanced trees , we modified the agglomerative clustering strategy as follows : starting from all singletons , each sweep of the algorithm merges the pair with the smallest cardinality among the @xmath47 closest pair of clusters .",
    "the distance is computed according to the simple linkage rule .",
    "the cardinality of a pair is the sum of the cardinality of the two clusters . in this way we are softening the `` closest first '' agglomerative criterion by introducing a competing `` smallest first '' principle that tends to produce better balanced dendrograms .",
    "the amount of balancing is regulated by the parameter @xmath47 : when @xmath59 this is the standard agglomerative clustering with no balancing ; when @xmath60 ( @xmath1 is the number of images ) a perfect balanced tree is obtained , but the clustering is poor , since distance is largely disregarded .",
    "figure [ fig:2.9 ] shows an example of balancing achieved by our technique .",
    "the height of the tree is reduced from 14 to 9 and more initial pairs are present in the dendrogram on the right .",
    "in the pursuit of further complexity reduction , we adopted a strategy that consists in reducing the number of images to be used in the bundle adjustment in place of the whole model .",
    "this strategy is an instance of local bundle adjustment @xcite , which is often used for video sequences , where the active images are the most recent ones .",
    "let us concentrate on the model merging step , as the resection is a special case of the latter .",
    "consider two models @xmath61 and @xmath62 , where @xmath61 has fewer images than @xmath62 .",
    "we always transform the smallest onto the largest ( if one is projective it is always the smallest ) .",
    "the bundle adjustment involves all the images of @xmath61 and the subset of images of @xmath62 that share some tracks with @xmath61 ( tie - points that are visible in images in both models ) .",
    "let us call this subset @xmath63 .",
    "all the tie - points linking @xmath63 and @xmath61 are considered in the bundle adjustment .",
    "images in @xmath64 are not moved by bundle adjustment but their tie - points are still considered in the minimization in order to anchor @xmath63 through their common tie - points .",
    "the tie - points linking only cameras in @xmath64 are not considered .",
    "this strategy is sub - optimal because in a proper bundle adjustment all the images in @xmath62 should be involved , even those that do not share any tie - point with @xmath61 .",
    "however , a bundle adjustment with all the images and all the tie - points can be run at the end to obtain the optimal solution .",
    "a model that differs from the true one by a projectivity is called _ projective_. a model that differs from the true one by a similarity is called euclidean .",
    "the latter can be achieved when calibration parameters are known , the former can be obtained if images are uncalibrated .    in this section",
    "we relax the hypothesis that images are calibrated and integrate the autocalibration algorithm in our pipeline , so that the resulting model is still euclidean .    the main difference from the procedure described in sec .",
    "[ sec : hierarchical ] is that now leaf nodes do not have proper calibration right from the start of the structure - and - motionprocess .",
    "the models is projective at the beginning , and as soon as one reaches a sufficient number of images , the euclidean upgrade procedure ( described in section [ sec : autocal ] ) is triggered .",
    "moreover , each step of hierarchical structure - and - motionmust be modified to accommodate for projective models , as described in sections [ sec:2vu ] , [ sec : res - int ] , and [ sec : merge ] .",
    "autocalibration starts from a projective model and seeks the collineation of space @xmath65 so as to transforms the model into a euclidean one .    without loss of generality ,",
    "the first camera of the euclidean model can be assumed to be @xmath66 $ ] , so that the euclidean upgrade @xmath65 has the following structure , since @xmath67 : @xmath68 \\label{eq : heuc}\\ ] ] where @xmath69 is the calibration matrix of the first camera , @xmath70 is a vector which determines the location of the plane at infinity and @xmath71 is a scale factor .",
    "our autocalibration technique is based on two stages :    1 .   given a guess on the internal parameters of two cameras compute a consistent upgrading collineation .",
    "this yields an estimate of all cameras but the first . 2 .",
    "score the internal parameters of these @xmath17 cameras based on the likelihood of skew , aspect ratio and principal point .",
    "the space of the internal parameters of the two cameras is enumerated and the best solution is refined via non - linear least squares .",
    "this approach has been introduced in @xcite , where it is compared with several other algorithms obtaining favorable results .",
    "this section describes a closed - form solution for the plane at infinity ( i.e. , the vector @xmath70 ) given two perspective projection matrices and their internal parameters .",
    "while the first camera is @xmath72 $ ] , the second projective camera can be written as @xmath73 $ ] , and its euclidean upgrade is : @xmath74 \\simeq p_2   h = \\left [ a_2   k_1 + \\mathbf{e}_2   \\mathbf{r}^{\\top }    \\vert   \\lambda \\mathbf{e}_2 \\right ] .\\end{aligned}\\ ] ] the rotation @xmath75 can therefore be equated to : @xmath76    using the constraints on orthogonality between rows or columns of a rotation matrix , one can solve for @xmath70 finding the value that makes the right hand side of equal to a rotation , up to a scale .",
    "the solution can be obtained in closed form by noting that there always exists a rotation matrix @xmath77 such as : @xmath78^{\\top},$ ] where @xmath79 .",
    "left multiplying it to yields : @xmath80^{\\top }      \\mathbf{r}^{\\top}\\ ] ]    calling @xmath81 and its rows @xmath82 , we arrive at the following : @xmath83 /   \\arrowvert \\mathbf{w}_3 \\arrowvert \\label{eq:8}\\ ] ] in which the last two rows are independent of the value of @xmath70 and the correct scale has been recovered normalizing each side of the equation to unit norm .",
    "since the rows of @xmath84 are orthonormal , we can recover the first one taking the cross product of the other two .",
    "vector @xmath70 is therefore equal to : @xmath85 the upgrading collineation @xmath65 can be computed using ; the term @xmath71 can be arbitrarily chosen , as it will just influence the overall scale .    when the calibration parameters are known only approximately , the right hand side of is no more a rotation matrix .",
    "however , will still yield the value of @xmath70 that will produce an _ approximate _",
    "euclidean model .",
    "in the preceding section we showed how to compute the euclidean upgrade @xmath65 given the calibration parameters of two cameras of the projective model .",
    "the autocalibration algorithm loops through all possible internal parameter matrices of two cameras @xmath86 and @xmath87 , checking whether the entire upgraded model has the desired properties in terms of @xmath88 .",
    "the process is well - defined , since the search space is naturally bounded by the finiteness of the acquisition devices .    in order to sample the space of calibration parameters we can safely assume , as customary , null skew and unit aspect ratio :",
    "this leaves the focal length and the principal point location as free parameters .",
    "however , as expected , the value of the plane at infinity is in general far more sensitive to errors in the estimation of focal length values rather than the image center .",
    "thus , we can iterate just over focal lengths @xmath89 and @xmath90 assuming the principal point to be centered on the image ; the error introduced with this approximation is normally well within the radius of convergence of the subsequent non - linear optimization .",
    "the search space is therefore reduced to a bounded region of @xmath91 .    to score each sample @xmath92",
    ", we consider the aspect ratio , skew and principal point location of the upgraded ( i.e. , transformed with @xmath65 ) camera matrices and aggregate their respective value into a single cost function : @xmath93 where @xmath94 is the internal parameters matrix of the @xmath47-th camera after the euclidean upgrade determined by @xmath92 , and @xmath95 reflects the degree to which @xmath96 meets a - priori expectations .",
    "let us consider the _ viewport matrices _ of the cameras , defined as : @xmath97   \\label{eq : viewport}\\ ] ] where @xmath98 and @xmath99 are respectively the width and height of each image .",
    "camera matrices are normalized with @xmath100 . in this way , the principal point expected value is @xmath101 and the focal range is @xmath102 $ ] .",
    "therefore , the term of the cost function writes : @xmath103 where @xmath104 denotes the entry @xmath105 of @xmath96 and @xmath98 are suitable weights , computed as in @xcite .",
    "the first term takes into account the skew , which is expected to be 0 , the second one penalizes cameras with aspect ratio different from 1 and the last two weigh down cameras where the principal point is away from @xmath101 .    finally , the solution selected is refined by non - linear minimization of eq .  .",
    "since it is usually very close to a minimum , just a few iterations of a levenberg - marquardt solver are necessary for convergence .",
    "( ) @xmath106 _ compute @xmath107 _ _ build @xmath65 from _ ( ) @xmath108 @xmath109 @xmath110 _ internal of @xmath111 _ _ compute @xmath112 from _ _ aggregate cost and select minimum _ _ refine non - linearly _",
    "the entire procedure is presented as pseudo - code in algorithm [ alg : selfcal ] .",
    "the algorithm shows remarkable convergence properties ; it has been observed to fail only when the sampling of the focal space was not sufficiently dense ( in practice , less than twenty focal values in each direction ) , and therefore all the tested infinity planes were not close enough to the correct one .",
    "such problems are easy to detect , since they usually take the final , refined solution outside the legal search space .    in principle",
    ", autocalibration requires a minimum number of images to work , according to the autocalibration `` counting argument '' @xcite ( e.g.  @xmath113 images with known skew and aspect ratio ) .",
    "however , as we strive to maintain an `` almost '' euclidean reference frame from the beginning , to better condition subsequent processing , autocalibration is triggered for models starting from two images .",
    "the result is an approximate euclidean upgrade ; in fact these models are still regarded as projective , until they reach a sufficient cardinality .",
    "after that point autocalibration is not performed any more and the internal parameters of each camera are refined further only with bundle adjustment , as the computation proceeds . in order not to hamper the process too much ,",
    "the internal parameters of a camera becomes fixed after they have been bundle - adjusted together with a given number of cameras .",
    "the model that can be obtained from two uncalibrated images is always projective .",
    "the following two camera matrices are used : @xmath114 \\quad \\text{and } \\quad p_2 =   [ [ \\mathbf{e}_2]_{\\times}f   \\",
    "\\vert   \\   \\mathbf{e}_2],\\ ] ] this canonical pair yields a projective model with the plane at infinity passing through the centre of the second camera , which is very unnatural .",
    "therefore , the method of section [ sec : autocal1 ] is applied for guessing a better location for the plane at infinity compatible with rough focal estimates , obtained from the magnitude of the image diagonal .",
    "even when the true focal lengths are far from the estimates , this procedure will provide a useful , well conditioned starting point for the subsequent steps .",
    "cheirality is then tested and enforced on the model .",
    "in practice only a reflection ( switches all points from in front to behind the cameras ) may be necessary , as the twisted pair case never occurs .",
    "in fact , the twisting corresponds to the infinity plane crossing the baseline , which would imply that our guess for the infinity plane is indeed very poor .",
    "the 3d coordinates of the tie - points are then obtained by intersection as before .",
    "finally bundle adjustment is run to improve the model .",
    "the procedure is the same as in the calibrated case , taking care of using the direct linear transform ( dlt ) algorithm @xcite for resection , as the the single image is always uncalibrated .",
    "while ppnp computes only the external parameters of the camera , the dlt computes the full camera matrix .",
    "partial models live in two different reference frames , that are related by a similarity  if both are euclidean  or by a projectivity  if one is projective . in this case",
    "the projectivity that brings the projective model onto the euclidean one is sought , thereby recovering its correct euclidean reference frame .",
    "the procedure is the same as in the calibrated case , with the only difference that when computing the projectivity the dlt algorithm should be used instead of op .",
    "the new model is refined with bundle adjustment ( either euclidean or projective ) and upgraded to a euclidean frame when the conditions stated beforehand are met .",
    "samanthais a complex pipeline with many internal parameters . with respect to this issue",
    "our endeavor was : i ) to avoid free parameters at all ; ii ) to make them data - dependent ; iii ) to make user - specified parameters intelligible and subject to an educated guess . in the last case",
    "a default should be provided that works with most scenarios .",
    "this guarantees the processing to be completely automatic in the majority of cases .",
    "all the heuristic parameter settings used in the experiments have been reported and summarized in table [ tab : parameters ] .",
    "+ number of log pyramid levels & 12 + average number of keypoints per image & 7500 +   + number of keypoints per image & 300 + degree of edge - connectedness & 8 +   + matching discriminative ratio & 1.5 + maximum number of msac iterations & 1000 + bucket size ( msac ) in pixels & @xmath115 + minimum number of matches & 10 + homography - to - fundamental gric ratio & 1.2 + minimum track length & 3 +   + maximum bundle adjustment iterations & 100 + reprojection error & @xmath116 +   + number of cameras for autocalibration & 4 + number of cameras to fix internal param.s & 25 +   + final minimum track length & 2 + final maximum reprojection error & @xmath117 +    [ [ keypoint - detection ] ] keypoint detection + + + + + + + + + + + + + + + + + +    the keypoints extracted from all images are ordered by their response value and the ones with the highest response are retained , while the others are discarded .",
    "the total number of keypoints to be kept is a multiple of the number of images , so as to keep the average quota of keypoints for each image fixed .",
    "during the broad matching phase the goal is to compute the 2d histogram mentioned in sec .",
    "[ sec : broad ] .",
    "to this end , the keypoints in each image are ordered by scale and the 300 keypoints with the highest scale are considered .",
    "the number of neighbors in feature space is set to six , as in @xcite .",
    "given the nature of the broad phase , this value is not critical , to the point where only the number of keypoints is exposed as a parameter .    the number @xmath11 in sec .",
    "[ sec : broad ] ( `` degree of edge - connectedness '' , in table [ tab : parameters ] ) , has been set to eight following @xcite . in our case , the role of the parameter is more `` global '' , as it does not set the exact number of images to be matched but the degree of edge - connectedness of the graph .",
    "however our experiments confirmed that that @xmath118 is a good default .",
    "the number of max iterations of msac is set to @xmath119 during the matching phase .",
    "this is only an upper bound , for the actual value is dynamically updated every time a new set of inliers is found .",
    "the `` matching discriminative ratio '' refers to the ratio of first to second closest keypoint descriptors , used to prune weak matches at the beginning of this phase .",
    "the `` minimum number of matches '' parameter refers to the last stage of the narrow phase , when poor matches between images are discarded based on the number of surviving inliers after msac .",
    "[ [ clustering ] ] clustering + + + + + + + + + +    the parameter @xmath47 of sec .",
    "[ sec : balance ] has been set to @xmath120 based on the graph reported in fig .",
    "[ fig : bilancia ] , where the number of reconstructed tie - points / images and the computing time are plotted as the value of @xmath47 is increased .",
    "after @xmath120 , the computing time stabilizes at around 30% of the baseline case , without any significant difference in terms of number of reconstructed images and tie - points .     in the balancing heuristics .",
    "the values on the ordinate are in percentage, where the baseline case @xmath121 . ]",
    "[ [ reconstruction ] ] reconstruction + + + + + + + + + + + + + +    the safeguard threshold on the reprojection error ( sec .",
    "[ sec : inter ] ) is set to 2 pixels with reference to a 6 mpixel image , and scaled according to the actual image diagonal ( assuming an aspect ratio of 4:3 , the reference diagonal is @xmath122 pixels ) .",
    "[ [ autocalibration ] ] autocalibration + + + + + + + + + + + + + + +    the euclidean upgrade is stopped as soon as a cluster reaches a sufficient cardinality @xmath14 ( `` number of cameras for autocalibration '' ) that satisfies the following inequality @xcite , giving the condition under which autocalibration is feasible : @xmath123 where @xmath124 internal parameters are known and @xmath125 internal parameters are constant . with known ( or guessed ) skew and aspect ratio (",
    "@xmath126 and @xmath127 ) four cameras are sufficient .",
    "the reason for keeping this value to the minimum is because we observed experimentally that projective alignment is fairly unstable and it is beneficial to start using a similarity transformation as soon as possible .",
    "the cluster cardinality after which the internal parameters are kept fixed in the bundle adjustment is set to 25 , a fairly high value , that guarantees all the internals parameters , especially the radial distortion ones , are steady .",
    "[ [ local - bundle - adjustment ] ] local bundle adjustment + + + + + + + + + + + + + + + + + + + + + + +    as discussed previously , the local bundle adjustment is generally to be preferred over the full one .",
    "however , since the autocalibration phase is crucial , our strategy is to run the full bundle adjustment until the clusters become euclidean .",
    "it should also be noted that the computational benefits of the local bundle adjustment are more evident with large clusters of cameras .",
    "[ [ prologue ] ] prologue + + + + + + + +    the last bundle adjustment is always full ( not local ) and is run with a lower safeguard threshold on the reprojection error ( 1.5 pixel in the reference 6 mpixel image ) .",
    "a final intersection step is carried out using also the tracks of length two , in order to increase the density of the model .",
    "please note however that these weak points do not interfere with the bundle adjustment , as they are added only _",
    "after _ it .",
    "we run samanthaon several real , challenging datasets , summarized in tab .  [",
    "tab : summary ] .",
    "all of them have some ground truth available , being either a point cloud ( from laser scanning ) , the camera internal parameters or measured `` ground '' control points ( gcp ) .    the qualitative comparison against visualsfmfocuses on differences in terms of number of reconstructed cameras and manifest errors in the model .",
    "the quantitative evaluation examines the accuracy of the model against gcps and laser scans , and/or the internal orientation accuracy .",
    "[ cols=\"<,>,^ , < , < , < \" , ]     [ tab : runningtimes ]",
    "in this paper we have described several improvements to the current state of the art in the context of uncalibrated structure - and - motionfrom images .",
    "our proposal was a hierarchical framework for structure - and - motion(samantha ) , which was demonstrated to be an improvement over the sequential approach both in computational complexity and with respect to the overall error containment .",
    "samanthaconstitutes the first truly scalable approach to the problem of modeling from images , showing an almost linear complexity in the number of tie - points and images .",
    "moreover , we described a novel self - calibration approach , which coupled with our hierarchical pipeline ( samantha ) constitutes the first published example of uncalibrated structure - and - motionfor generic datasets not using external , ancillary information .",
    "the robustness of our approach has been demonstrated on 3d model datasets both qualitatively and quantitatively .",
    "this technology has now been transferred to a company ( 3dflow srl ) which produced an industry grade implementation of samanthathat can be freely downloaded .",
    "thesis : the subgraph @xmath10 produced by the method reported in sec .",
    "[ sec : broad ] is @xmath11-edge - connected , provided that @xmath11 independent spanning tree can be extracted from @xmath16 .    to prove the thesis we rely upon the following observation .",
    "consider an undirected graph @xmath16 with the capacity of all edges set to one ; @xmath16 is @xmath14-edge - connected if and only if the maximum flow from @xmath128 to @xmath129 is at least @xmath14 for any node pair @xmath130 .",
    "since our @xmath10 is the union of @xmath11 independent ( disjoint ) 1-edge - connected graphs , each of them adds an independent path with unit capacity from every node pair @xmath130 , so the maximum flow from every pair @xmath130 in @xmath10 is @xmath11 .",
    "the `` ventimiglia '' images ( courtesy of fabio remondino ) were acquired by fbk trento ( 3dom.fbk.eu ) within a project funded by arcus spa and supported by direzione regionale per i beni culurali e paesaggistici della ligura ( mibac ) and soprintendenza per i beni archeologici della liguria .",
    "the laser scanning of `` br '' was conducted by gexcel s.r.l . with the eu jrc - ispra and the permission of the municipality of verona .",
    "the laser data of the `` duomo di pisa '' comes from the `` cattedrale digitale '' project , while the photo set is courtesy of the visual computing lab ( isti - cnr , pisa ) .",
    "domenico visintini ( universit di udine ) took the laser survey of `` s. giacomo '' .",
    "the images of the `` termica '' dataset have been captured by airmap ( curtesy of davide zorzetto ) .",
    "alberto beinat and marco fassetta ( universit di udine ) surveyed the gcps .",
    "the navona dataset was acquired by l. barazzetti ( politecnico di milano , italy ) and used for the evaluation of automated image orientation methods during the isprs 3d - arch workshop in 2011 .",
    "the `` herz - jesu - p25 '' images come from epfl dense multi - view stereo evaluation dataset .",
    "t.  thormhlen , h.  broszio , a.  weissenfeld , keyframe selection for camera motion and structure estimation from multiple views , in : proceedings of the european conference on computer vision , 2004 , pp .",
    "523535 .",
    "shum , q.  ke , z.  zhang , efficient bundle adjustment with virtual key frames : a hierarchical approach to multi - frame structure from motion , in : proceedings of the ieee conference on computer vision and pattern recognition , 1999 , pp . 25382543 .",
    "f.  schaffalitzky , a.  zisserman , multi - view matching for unordered image sets , or `` how do i organize my holiday snaps ? '' , in : proceedings of the 7th european conference on computer vision , 2002 , pp .",
    "414431 .",
    "r.  gherardi , m.  farenzena , a.  fusiello , improving the efficiency of hierarchical structure - and - motion , in : proceedings of the ieee conference on computer vision and pattern recognition , san francisco , ca , 2010 , pp .",
    "1594  1600 .",
    "s.  agarwal , y.  furukawa , n.  snavely , i.  simon , b.  curless , s.  m. seitz , r.  szeliski , building rome in a day , communications of the acm 54  ( 10 ) ( 2011 ) 105112 .",
    "frahm , p.",
    "fite - georgel , d.  gallup , t.  johnson , r.  raguram , c.  wu , y .- h .",
    "jen , e.  dunn , b.  clipp , s.  lazebnik , m.  pollefeys , building rome on a cloudless day , in : proceedings of the 11th european conference on computer vision : part iv , 2010 , pp .",
    "368381 .    m.  arie - nachimson , s.  z. kovalsky , i.  kemelmacher - shlizerman , a.  singer , r.  basri , global motion estimation from point matches , in : international conference on 3d imaging , modeling , processing , visualization and transmission , 2012 , pp .",
    "8188 .",
    "d.  crandall , a.  owens , n.  snavely , d.  p. huttenlocher , discrete - continuous optimization for large - scale structure from motion , in : proceedings of the ieee conf . on computer vision and pattern recognition , 2011 , pp .",
    "30013008 .          m.  brand , m.  antone , s.  teller , spectral solution of large - scale extrinsic camera calibration as a graph embedding problem , in : proceedings of the ieee conference on computer vision and pattern recognition , 2004 , pp . 262273 .",
    "p.  moulon , p.  monasse , r.  marlet , global fusion of relative motions for robust , accurate and scalable structure from motion , in : proceedings of the international conference on computer vision , 2013 , pp .",
    "32483255 .",
    "o.  ozyesil , a.  singer , r.  basri , http://arxiv.org/abs/1312.5047[camera motion estimation by convex programming ] , arxiv e - prints 1312.5047 , to appear in the siam journal on imaging sciences .",
    "g.  kamberov , g.  kamberova , o.  chum , s.  obdrzalek , d.  martinec , j.  kostkova , t.  pajdla , j.  matas , r.  sara , 3d geometry from uncalibrated images , in : proceedings of the 2nd international symposium on visual computing , 2006 , pp .",
    "802813 .",
    "m.  pollefeys , d.  nistr , j.  m. frahm , a.  akbarzadeh , p.  mordohai , b.  clipp , c.  engels , d.  gallup , s.  j. kim , p.  merrell , c.  salmi , s.  sinha , s.  sinha , b.  talton , l.  wang , q.  yang , h.  stewnius , r.  yang , g.  welch , h.  towles , detailed real - time urban 3d reconstruction from video , international journal of computer vision 78  ( 2 - 3 ) ( 2008 ) 143167 .",
    "m.  pollefeys , r.  koch , l.  van gool , self - calibration and metric reconstruction in spite of varying and unknown internal camera parameters , in : proceedings of the international conference on computer vision , bombay , 1998 , pp . 9095 .",
    "y.  seo , a.  heyden , r.  cipolla , a linear iterative method for auto - calibration using the dac equation , in : proceedings of the ieee conference on computer vision and pattern recognition , vol .  1 , 2001 ,",
    "p. 880 .",
    "m.  chandraker , s.  agarwal , f.  kahl , d.  nister , d.  kriegman , autocalibration via rank - constrained estimation of the absolute quadric , in : proceedings of the ieee conference on computer vision and pattern recognition , 2007 , pp .",
    "b.  bocquillon , a.  bartoli , p.  gurdjos , a.  crouzil , on constant focal length self - calibration from multiple views , in : proceedings of the ieee conference on computer vision and pattern recognition , 2007 .",
    "m.  chandraker , s.  agarwal , d.  kriegman , s.  belongie , globally optimal affine and metric upgrades in stratified autocalibration , in : proceedings of the international conference on computer vision , 2007 , pp .",
    "m.  farenzena , a.  fusiello , r.  gherardi , structure - and - motion pipeline on a hierarchical cluster tree , in : ieee international workshop on 3-d digital imaging and modeling , kyoto , japan , 2009 , pp .",
    "14891496 .",
    "z.  zhang , r.  deriche , o.  faugeras , q .- t .",
    "luong , a robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry , artificial intelligence 78  ( 1 - 2 ) ( 1995 ) 87  119 .",
    "t.  quack , b.  leibe , l.  van  gool , world - scale mining of objects and events from community photo collections , in : proceedings of the international conference on content - based image and video retrieval , 2008 , pp .",
    "4756 .",
    "v.  garro , f.  crosilla , a.  fusiello , solving the pnp problem with anisotropic orthogonal procrustes analysis , in : proceedings of the second joint 3dim/3dpvt conference : 3d imaging , modeling , processing , visualization and transmission , 2012 , pp .",
    "262269 .",
    "e.  mouragnon , m.  lhuillier , m.  dhome , f.  dekeyser , p.  sayd , real time localization and 3d reconstruction , in : proceedings of the international conference on computer vision and pattern recognition , 2006 , pp .",
    "363370 .",
    "f.  remondino , s.  del  pizzo , t.  p. kersten , s.  troisi , low - cost and open - source solutions for automated image orientation  a critical overview , in : progress in cultural heritage preservation , springer , 2012 , pp .",
    "4054 .    c.  strecha , w.  von  hansen , l.  van  gool , p.  fua , u.  thoennessen , on benchmarking camera calibration and multi - view stereo for high resolution imagery , in : ieee conference on computer vision and pattern recognition , 2008 , pp ."
  ],
  "abstract_text": [
    "<S> this paper addresses the structure - and - motionproblem , that requires to find camera motion and 3d structure from point matches . </S>",
    "<S> a new pipeline , dubbed samantha , is presented , that departs from the prevailing sequential paradigm and embraces instead a hierarchical approach . </S>",
    "<S> this method has several advantages , like a provably lower computational complexity , which is necessary to achieve true scalability , and better error containment , leading to more stability and less drift . </S>",
    "<S> moreover , a practical autocalibration procedure allows to process images without ancillary information . </S>",
    "<S> experiments with real data assess the accuracy and the computational efficiency of the method .    </S>",
    "<S> structure and motion ; image orientation ; bundle adjustment ; autocalibration ; 3d </S>"
  ]
}