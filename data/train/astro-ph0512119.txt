{
  "article_text": [
    "one of the main goals of modern photometric and spectroscopic surveys is to understand and isolate the different types of measured objects .",
    "this is best done automatically , both due to the overwhelming number of objects in the surveys and because of the relative objectivity gained by using automated methods .",
    "there are a number of approaches to classification of objects , traditionally falling into two major groups : supervised and unsupervised . supervised",
    "classifiers make use of labeled training data in order to train the software to recognize certain patterns in the data features that are characteristic of the different object classes known to be present .",
    "unsupervised classifiers , or clustering algorithms , try to find natural groupings of objects in feature space .",
    "@xcite were the first to use neural networks , a form of supervised classification , to automatically classify galaxies according to their morphology .",
    "@xcite have developed successful neural network based methods for star / galaxy separation . since the mid-1990s there has been a lot of work using neural networks for stellar object classification .",
    "@xcite used backpropagation neural networks to classify galaxies based on their morphology and showed the results compared favorably to classification by humans . @xcite and @xcite used neural networks to successfully predict effective temperatures , mk classifications , and luminosity classes of stars based on stellar spectra .",
    "@xcite used a neural network and a variety of morphological and photometric parameters to predict the eclass of sdss galaxy spectra .",
    "the eclass is a continuous parameterization of the galaxy type derived from principal component analysis applied to a collection of sdss galaxy spectra @xcite .",
    "@xcite determined the metallicities of stars from two different globular clusters using neural networks .",
    "another supervised classification method that has been used with astronomical data is the decision tree inducer .",
    "@xcite used a decision tree to classify stars and galaxies from the palomar sky survey ( dposs ) based on a set of eight features .",
    "@xcite used an oblique decision tree classifier ( oc1 ) to study the same data as @xcite used with a neural network , achieving comparable results . @xcite",
    "describe the use of oc1 for classifying 2mass extended sources .",
    "@xcite compared ensembles of decision trees with ensembles of other types of classifiers .",
    "they found the largest reduction in classification error was for ensembles of decision trees .",
    "more recently , @xcite used an ensemble of decision tree classifiers to determine types and redshifts of objects in the sdss photometric catalog .    the kohonen self - organizing map ( som ) @xcite has been used as an unsupervised method of exploring associations within astronomical data sets @xcite .",
    "this approach , an unsupervised neural network , clusters similar objects together in a way that conserves the topology of the input data .",
    "in other words , input vectors that are similar to each other are mapped to neighboring regions of what is usually a two - dimensional output lattice . in this way soms",
    "have been found useful as a way to visualize high dimensional data .",
    "a common approach to unsupervised clustering is the use of mixture models @xcite .",
    "mixture models produce probabilistic , or soft , assignments of data points to each of the mixture components , or clusters .",
    "the number of clusters to be learned must be specified as part of the algorithm .",
    "there is no single standard approach for choosing this parameter .",
    "furthermore , without supervising examples , there is no guarantee that the learned clusters will acceptably characterize the known classes within the data set .    to overcome some of these shortcomings _ semisupervised learning _",
    "algorithms were proposed , including the work of @xcite , @xcite , and @xcite . in these approaches ,",
    "the input data consists of both labeled and unlabeled samples .",
    "this affects the clustering process in two ways .",
    "first the labeled data helps guide the cluster definitions to properly reflect the known ground - truth classes @xcite .",
    "second , the unlabeled data may help to more accurately learn parameters of the model , so as to better define the shapes of the learned classes in feature space @xcite .    until recently , most semisupervised methods focused on building models and classifiers for the set of known classes , i.e. those for which labeled training examples are available .",
    "however , given a data set with many unlabeled examples , it is quite possible that , latent in the unlabeled data , some _ unknown _ classes are present .",
    "these unknown classes are compact clusters of unlabeled objects that have not , as yet , been recognized by domain experts as distinct classes or categories of interest",
    ". such clusters , once identified , could be the focus of further scientific inquiry , to either validate them as new classes of interest or to reject them as uninteresting outlier groups .",
    "recent work in @xcite developed semisupervised mixture modeling methods with a built - in capability to discover these unknown classes in mixed labeled and unlabeled data .",
    "standard supervised learning algorithms do not have good means to identify unknown classes because they can only be trained using examples from the known classes .",
    "standard unsupervised clustering algorithms make no distinction between clusters of purely unlabeled data and clusters containing some labeled samples .",
    "purely unlabeled clusters are of particular scientific interest because they represent groups of objects that are well separated from objects belonging to known classes .",
    "thus , they may represent new object types or groups of unusual objects , i.e , outliers from existing known classes .    in a previous study",
    ", @xcite applied the semisupervised class discovery approach to investigate astronomical data . in this paper , we analyze a portion of the sdss photometric catalog consisting of approximately 10,000 objects .",
    "the sdss data in our sample have been classified via the spectral pipeline into several different types of objects . here",
    "we particularly focus on the spectroscopically unclassified objects , suos , which consist of objects that were not readily classified as stars , galaxies , qsos , or late type stars ( red stars of type m or later ) .",
    "the papers describing the sdss data releases , in particular , @xcite , as well as the sdss website describe the procedure that leads to objects being labeled as spectroscopically unclassified ( the sdss class called `` unknown '' ) .",
    "suos are objects that passed through the various filters in the spectroscopic pipeline and were then examined by a person who could not reliably classify them because they were too noisy , too featureless , or for some other reason .",
    "we are interested in applying our semisupervised class discovery technique to the sdss data for two main reasons : 1 ) to see whether this approach determines significant substructure within the class of suos , i.e. , subclasses of suos ; 2 ) to determine whether some suos are clustered into groups that mainly consist of known class objects .",
    "an alternative approach would be to apply a simple clustering algorithm , such as k - means , to identify substructure solely using as data the set of suo samples .",
    "however , both the validity of the learned suo clusters and the nature of these clusters are best assessed relative to the known class clusters , by learning a clustering solution using the data from all the classes , both known and spectroscopically unclassified .",
    "our method clusters on the basis of _ all _ available information  feature vectors , available class labels , and the _ fact _ of label presence / absence for each sample @xcite .",
    "absence of labels in a compact cluster is suggestive that a meaningful subclass of the unknown class may have been found .",
    "@xcite demonstrated that use of label presence / absence information may help to achieve more accurate clusters and to better discern unknown subclasses than methods which do not use this information .",
    "our semisupervised mixture modeling approach has several benefits not seen by using standard unsupervised clustering . in particular , some objects labeled suos may have measured features that are similar to those of objects from known classes . in performing clustering using all the data , both from the known classes as well as the suo class , we can learn clustering solutions that reveal these similarities .",
    "that is , if an suo is assigned to a cluster of predominantly `` known '' objects of a given type , the clustering is indicating the possibility that the suo may be related to ( e.g. may be a variant of ) the known object class .",
    "this may also suggest the suo was mislabeled .",
    "likewise , consider a cluster that primarily contains suos , but which also owns some known class objects .",
    "the known class composition of the cluster may hint at the underlying physical nature of the suo subclass represented by this cluster . on the other hand",
    ", the ownership of some known class objects by the cluster may indicate that these known class objects were mislabeled . finally , consider the problem of choosing the _ number _ of clusters to represent each class .",
    "model order selection methods `` match '' the model complexity ( number of clusters in each class ) to the amount of data these clusters own .",
    "if a significant number of suo class objects can be explained by , i.e. belong to , clusters of known class objects , then fewer suo clusters will be needed in the model .",
    "this means that learning and model selection using only the suo class objects could lead to an overestimate of the number of suo clusters ( subclasses ) .",
    "there has been limited work using mixture models to classify astronomical data .",
    "@xcite used a mixture model to verify the bimodal galaxy distribution they found by other means .",
    "@xcite discuss the use of mixture models for finding clusters of galaxies .",
    "@xcite used a simple mixture model to identify classes of objects following principal component analysis ( pca ) of spectra .",
    "they applied a mixture model to the histogram of their parameter @xmath4 , the angle between the first two eigencoefficients of the pca decomposition of the galaxy spectra .",
    "they performed model selection using the akaike information criterion @xcite and found three components best fit their data .",
    "@xcite used a similar approach following pca of the shapelet decomposition of galaxy images and used the bayesian information criterion ( bic , @xcite ) .",
    "they also found that a three class representation of their data was optimal , although their data set was completely different from that of @xcite .",
    "the sloan digital sky survey , data release 4 contains spectra of about 850,000 objects , categorized into several different classes .",
    "we selected data with high signal to noise ( @xmath5 ) and redshifts below 2.3 . because we were especially interested in the class of suos , as determined by the sdss spectroscopic pipeline , we first selected objects that met these criteria from the suo class ( sdss unknown class ) .",
    "this resulted in 1763 suos .",
    "we then selected 2000 objects each from four other sdss spectroscopic classes : star , galaxy , qso , and late - type star .",
    "for each of these objects we extracted from the sdss database the following features : dereddened photometry in each of the five sdss bands , @xmath6 , @xmath7 , @xmath8 , @xmath9 , and @xmath10 ; four colors , @xmath0 , @xmath1 , @xmath2 , @xmath3 ; the spectroscopic redshift , @xmath11 , and the spectroscopic class .",
    "this produced our working dataset of 9763 objects .",
    "the purpose in limiting the study to 10,000 objects , with about 2000 objects from each class , was twofold .",
    "first we wanted to maintain an approximately equal number of objects from each class so that the statistics would not be dominated by one class . in our previous work",
    "@xcite we had one class containing approximately 78% of the data and several classes with less than 1% .",
    "second , we wanted to have a data set that would not take too long to process .",
    "computational scaling properties of the algorithm are discussed in the appendix .",
    "when running our algorithm we used the four colors as features , producing a modest 4-dimensional feature space .",
    "while we could also use the photometric values directly we wanted to be able to compare our results with those of other groups , for example @xcite who identified the bimodal galaxy distribution based on color alone .",
    "each of the objects in our dataset was also associated with the unique sdss object identifier which allows us to examine any specific object in more detail .",
    "the query we used to retrieve these data was :    .... select top 2000 p.objid , p.dered_u , p.dered_g , p.dered_r , p.dered_i , p.dered_z , p.dered_u - p.dered_g , p.dered_g - p.dered_r , p.dered_r - p.dered_i , p.dered_i - p.dered_z , s.z , s.specclass > from bestdr4 .. photoobj p , bestdr4 .. specobj s where s.bestobjid = p.objid and s.specclass = 0              -- suo and s.sn_1 > 3.0 and s.z < 2.3 ....    this sql command was repeated , changing specclass from 0 ( suo ) to 1 ( star ) , 2 ( galaxy ) , 3 ( qso ) , and 6 ( late - type star ) .",
    "the separate files containing the object ids and their features were concatenated and randomized to produce the input file for our algorithm .",
    "to apply the mixture modeling algorithm we start with a data set where each object is described by a feature vector .",
    "the elements , or dimensions , of the feature vector represent some measured or derived quantities from each object . in the present study the feature vectors consist of the photometric colors @xmath0 , @xmath1 , @xmath2 , @xmath3 , resulting in a 4-dimensional feature space .",
    "the feature vectors are not the only quantities treated as data by our model .",
    "the other data modeled by our mixture represents the _ labeling _ information for each object in the data set .",
    "we now discuss data labeling in more detail .",
    "there are five class types represented in our data set , the known class categories ( star , galaxy , qso , late - type star ) and the suo class category .",
    "each of the 9763 objects in our set does in fact come with a class label and all these object labels will be used to evaluate the mixture models that we learn . however , in order to capture the realistic scenario in which the data are only _ sparsely _ labeled , we treat only a 10% random sample of the data from the known classes as labeled for purposes of model learning / clustering , with all the other known class objects treated as unlabeled .",
    "while we used a single 10% random sampling of the data , we performed several runs using this data sample with different random initial conditions for the algorithm .",
    "we discuss this in more detail in the results section .",
    "the suo class is one of the class types .",
    "thus , all the suos are in fact labeled . however , there is uncertainty about the nature of each of the objects in this class .",
    "some suos may represent noisy measurements or objects of little interest , resulting from bad columns on the ccd or part of the spectrum falling off the edge of the ccd . some may be objects from known categories that were not properly labeled as such .",
    "some may represent new object types of scientific interest . to reflect our genuine uncertainty about the nature of these spectroscopically unclassified objects ,",
    "we treat them all as _ unlabeled_. the goal of our mixture modeling is to try to discern the underlying structure in and nature(s ) of these objects .",
    "consistent with this discussion , for purposes of data modeling , each labeled object is described by its feature vector , its class label , and a symbolic value indicating that the label is _ present _ for the object .",
    "each unlabeled object is described by its feature vector and a symbolic value indicating that the label is _",
    "absent_. the model is required to explain all the data describing each object , including the presence or absence of the class label . necessitating the explanation of this labeling information",
    "encourages the model to learn mixture solutions with some clusters that represent _ purely unlabeled _ ( or nearly so ) object subsets , with other clusters containing a mix of labeled and unlabeled objects  while the latter clusters represent known class data , the former may represent unknown subclasses .    to facilitate the learning of these mixture solutions , we define two different types of mixture components we dub `` predefined '' and `` nonpredefined '' .",
    "predefined components generate data points that can be either labeled or unlabeled , but where the labels are assumed to be _ missing at random_. these components represent the known classes ( for which class labels should , in fact , be missing at random , consistent with a random sample of the data being labeled ) .",
    "nonpredefined components generate only unlabeled data points , i.e. , the labels are always missing from the data .",
    "one way to picture this is to imagine a cluster of data points in some feature space .",
    "if that cluster of points contains a random mixture of labeled and unlabeled points it will be described by a predefined component .",
    "if the cluster contains essentially all unlabeled points it will be described by a nonpredefined component .",
    "the nonpredefined components contain data points that are almost purely unlabeled , and may represent novel classes or subclasses of objects .    the mixture model is learned based on local maximization of a statistical likelihood function .",
    "the `` best fit '' parameters that describe the mixture model , including gaussian parameters ( means and variances ) , the coefficients of the mixture components ( which are prior probabilities ) and the distribution used to model label generation given a particular mixture component , are determined by locally maximizing this function .",
    "this produces a set of probabilities that each mixture component describes a given class , with `` unlabeled '' treated as an additional class value .",
    "if the probability is high ( close to one ) that a specific mixture component describes unlabeled data , then that component is declared nonpredefined and , putatively , this component may be describing a new class .",
    "we provide further details of the algorithm in the appendix and in @xcite .",
    "as mentioned , one of the parameters learned by the mixture model is the variance of each gaussian component .",
    "if the variance is small then the component is compact and spans only a small part of parameter space .",
    "this tends to increase the number of components needed to describe the data , increasing the model complexity .",
    "although we use bic to determine the optimal model order , our previous work @xcite showed that bic sometimes had trouble converging on a finite model order . to avoid this we applied a variance threshold , essentially a minimum allowed width of the gaussian component",
    "this alleviated the convergence problem and resulted in simpler models .",
    "we use the same variance thresholding technique in this work .    for each run of the algorithm we must specify the number of mixture components to be used  the model order .",
    "determining the correct model order can be difficult and there are several proposed criteria in the literature @xcite .",
    "however , there is no agreed upon method appropriate to a given situation .",
    "model order selection is especially important in the case of class discovery because we view the nonpredefined components in the model as potential new classes .",
    "furthermore , the distribution of objects among the predefined components clearly changes with the model order .",
    "accurate model order selection is thus important for classification and successful new class discovery . here , as in our previous work @xcite we run the algorithm for a range of model orders and use a procedure called the bayesian information criterion ( bic ) @xcite to choose the best one .",
    "see the appendix for more details on bic .",
    "we ran the semisupervised discovery code using from 5 to 70 components and allowed bic to choose the best model order .",
    "after our initial run we found that the minimum bic cost was for a model with 16 components given the four features we used , although the minimum was quite broad .",
    "we then ran the code five more times , with different random initializations of the parameters , bracketing the initial minimum between 10 and 30 components .",
    "the minimum bic cost remained at a 16 component model .",
    "we used this model for subsequent investigations .",
    "we also compared the semisupervised model with a completely unsupervised mixture model .",
    "this allowed a useful comparison of the techniques and a fuller understanding of the benefits of the semisupervised approach .",
    "it is worth pointing out that changing the number of features and data points will in general change the optimal number of components that are found .",
    "for example , in our previous work @xcite we used six features ( and 50,000 objects ) and found optimal model orders in the range of 60 - 70 components .",
    "figure 1 shows the bic cost for our data as a function of the number of components for all the runs performed . the minimum is broad and",
    "the bic cost varies significantly over the repeated trials between 10 and 30 components .",
    "the global minimum at 16 components is evident , although the 14 and 24 component models do almost as well .",
    "these runs were for a single 10% random sampling of the data .",
    "ideally we would have several independent random samples and run multiple trials and a range of model orders .",
    "however , this becomes computationally expensive so we chose a single random sample of the data with a modest number of trials over a modest range of model orders .",
    "[ fig : bic ]    of the 16 components in the best model , 14 were predefined and 2 were nonpredefined . while the mixture model assigns probabilities of class membership to each point in the data set ( `` soft '' assignments ) we chose the class with the highest probability and assigned each point to that class ( `` hard '' assignments ) .",
    "thus , some points may have significant probabilities of membership in more than one class .",
    "conversely , each component will own data points from several different classes",
    ". some components will be more pure than others .",
    "table [ tab : comp - membership ] shows the number of data points from each class that are owned by each component in the model ( hard assignment ) .",
    "components 10 and 11 are nonpredefined components , meaning that the clusters of points owned by these components are almost purely unlabeled .",
    "as we can see from table [ tab : comp - membership ] both of these components have a majority of their points from the suo class ( 0 ) , but component 10 contains a significant numbers of points from the star class .",
    "rrrrrrr 0 & 0 & 0 & 0 & 0 & 0 & 494 + 1 & 0 & 66 & 17 & 147 & 1 & 114 + 2 & 0 & 16 & 5 & 39 & 0 & 650 + 3 & 0 & 99 & 31 & 1 & 8 & 3 + 4 & 0 & 9 & 2 & 2 & 0 & 132 + 5 & 0 & 60 & 40 & 3 & 3 & 125 + 6 & 0 & 10 & 769 & 9 & 2 & 0 + 7 & 0 & 17 & 11 & 0 & 0 & 58 + 8 & 0 & 70 & 469 & 167 & 25 & 1 + 9 & 0 & 152 & 17 & 2 & 221 & 10 + 10 & 1 & 360 & 250 & 2 & 5 & 1 + 11 & 1 & 296 & 9 & 2 & 0 & 19 + 12 & 0 & 325 & 48 & 12 & 1599 & 0 + 13 & 0 & 12 & 47 & 2 & 0 & 0 + 14 & 0 & 109 & 179 & 960 & 15 & 345 + 15 & 0 & 162 & 106 & 652 & 121 & 48 +    component 0 contains only late type stars while components 2 and 4 contain 92% and 91% late type stars , respectively .",
    "component 12 , with 81% quasars , has the largest number of quasars , and the largest total number of objects of any component .",
    "it also owns 325 suos .",
    "this component is significantly contaminated with suos and , to a lesser extent , stars .",
    "component 9 also has a relatively large number of quasars ( 221 or 55% ) and a significant number of suos also ( 152 or 38% ) .",
    "component 15 has 121 quasars but is dominated by galaxies .",
    "we will discuss components 14 and 15 in more detail later .",
    "the components with large numbers of galaxies are often contaminated with stars or late type stars ( components 1 , 8 , 14 , and 15 ) and objects of type suo are also often present .",
    "components 14 and 15 together own 81% of the galaxies in the sample while component 12 alone owns 80% of the quasars .    of the 1763 objects of type suo , the nonpredefined components 10 and 11 together own 656 or 37% .",
    "it is clear from table [ tab : comp - membership ] that the suos are spread across the components .",
    "component 11 consists of 91% suos with the remaining 9% objects almost entirely stars and late - type stars .",
    "only one quasar made it into this nonpredefined component .",
    "the suos are spread widely among the remaining components , with 6 components ( 9,10,11,12,14 , and 15 ) needed to account for more than 75% of these objects .",
    "table [ tab : phot - stats ] shows some additional statistics for each component , displaying the mean , median , and rms for each component in each of the four colors we used as features .",
    "note that component 10 , which has 58% of its points from the suo class , has a relatively small rms deviation from the mean for each of the colors even though it contains a mixture of different object types .",
    "conversely , component 11 , which is 91% suo class 0 , has a much larger standard deviation for @xmath0 in particular .",
    "note also that component 12 , which is mainly quasars but also has a significant number of suos , has quite a small rms in all colors .",
    "rrrrrrrrrrrrrrrr 0 & 2.43 & 2.38 & 1.01 & & 1.56 & 1.55 & 0.12 & & 1.98 & 1.95 & 0.17 & & 1.08 & 1.06 & 0.10 + 1 & 2.02 & 2.11 & 0.75 & & 1.73 & 1.72 & 0.26 & & 0.68 & 0.67 & 0.14 & & 0.38 & 0.39 & 0.10 + 2 & 2.82 & 2.69 & 0.90 & & 1.49 & 1.45 & 0.17 & & 1.00 & 1.00 & 0.25 & & 0.56 & 0.56 & 0.13 + 3 & 1.75 & 1.90 & 0.68 & & 0.81 & 0.77 & 0.26 & & 0.29 & 0.29 & 0.14 & & 0.07 & 0.00 & 0.30 + 4 & 1.55 & 1.57 & 0.93 & & 1.60 & 1.63 & 0.56 & & 1.09 & 1.16 & 0.40 & & 0.72 & 0.73 & 0.18 + 5 & 1.77 & 1.83 & 1.17 & & 0.79 & 0.84 & 0.81 & & 0.81 & 0.76 & 1.03 & & 0.40 & 0.45 & 0.95 + 6 & 1.04 & 1.04 & 0.15 & & 0.07 & 0.09 & 0.15 & & -0.01 & -0.00 & 0.10 & & -0.05 & -0.04 & 0.08 + 7 & 0.85 & 0.80 & 2.96 & & 2.47 & 1.94 & 2.79 & & -0.88 & -0.53 & 2.96 & & 1.44 & 0.82 & 2.91 + 8 & 1.06 & 1.06 & 0.20 & & 0.39 & 0.38 & 0.10 & & 0.18 & 0.16 & 0.11 & & 0.06 & 0.05 & 0.07 + 9 & 0.38 & 0.36 & 2.96 & & 0.33 & 0.33 & 0.16 & & 0.24 & 0.26 & 0.16 & & 0.30 & 0.28 & 0.14 + 10 & 0.07 & 0.10 & 0.22 & & -0.23 & -0.19 & 0.15 & & -0.21 & -0.20 & -0.10 & & -0.26 & -0.25 & -0.16 + 11 & 3.43 & 3.40 & 0.70 & & 0.87 & 0.83 & 0.23 & & 0.31 & 0.29 & 0.13 & & 0.09 & 0.13 & 0.21 + 12 & 0.19 & 0.18 & 0.16 & & 0.10 & 0.09 & 0.13 & & 0.09 & 0.08 & 0.14 & & 0.02 & 0.01 & 0.12 + 13 & 1.86 & 1.84 & 0.24 & & 0.66 & 0.69 & 0.15 & & 0.24 & 0.24 & 0.11 & & 0.16 & 0.14 & 0.09 + 14 & 2.04 & 1.96 & 0.35 & & 1.07 & 1.03 & 0.19 & & 0.46 & 0.45 & 0.12 & & 0.32 & 0.33 & 0.09 + 15 & 1.24 & 1.30 & 0.36 & & 0.67 & 0.67 & 0.13 & & 0.36 & 0.37 & 0.12 & & 0.26 & 0.25 & 0.11 +    in figure 2 we show three color - color diagrams for our entire data set .",
    "points plotted as green are from nonpredefined components 10 and 11 , while the blue points are from the other components .",
    "the contour levels are at 0.8 , 0.6 , 0.4 , 0.2 , 0.1 and 0.05 of the maximum and are plotted on a linear scale .",
    "it is evident from the color - color diagrams that the points from these two components are well separated and do not overlap with each other .",
    "we emphasize that these two components define regions in the feature space containing almost entirely unlabeled data points .",
    "this figure shows projections of the 4-dimensional feature space onto three 2-dimensional planes .",
    "while points from these components appear to be overlapping the blue points in projection , they are actually well separated in the 4-dimensional feature space .",
    "each of these components is shown in more detail in figure 3 which shows only the points from components 10 and 11 .",
    "the points are color and numerically coded for the spectroscopic class they were assigned : green 0suo ; blue 1star ; orange 2galaxy ; red 3quasar ; cyan 4late - type star .",
    "the @xmath0 vs @xmath1 diagram shows that component 10 has the suos clustering strongly between @xmath12 and @xmath13 although there is a faint tail of bluer objects .",
    "similar clustering is evident in the @xmath1 vs. @xmath2 diagram .",
    "however , the @xmath2 vs. @xmath3 diagram appears to show the suo class objects to be more spread out and intermixed with the other classes .",
    "[ fig : color - color ]    [ fig : color - color10 - 11 ]    we also ran an unsupervised mixture model on the same data set in order to compare the results of the semisupervised approach with the unsupervised approach .",
    "again , we ran five trials of the unsupervised mixture model and found the best solution using the bayesian information criterion .",
    "these tests resulted in an optimal mixture model consisting of 15 components .",
    "table [ tab : comp - membership2 ] summarizes the number of objects from each class that were assigned to each of the 15 components .",
    "comparison of the data in this table with the data from table [ tab : comp - membership ] for the semisupervised case provides a qualitative understanding of the differences between the two methods .",
    "rrrrrr 0 & 66 & 17 & 139 & 1 & 184 + 1 & 0 & 0 & 0 & 0 & 487 + 2 & 208 & 29 & 19 & 1488 & 3 + 3 & 94 & 44 & 7 & 4 & 190 + 4 & 320 & 17 & 2 & 0 & 7 + 5 & 170 & 210 & 1261 & 31 & 87 + 6 & 234 & 46 & 1 & 262 & 0 + 7 & 17 & 13 & 0 & 0 & 64 + 8 & 110 & 11 & 6 & 139 & 32 + 9 & 3 & 2 & 1 & 0 & 446 + 10 & 52 & 61 & 148 & 4 & 492 + 11 & 89 & 95 & 291 & 53 & 6 + 12 & 315 & 235 & 1 & 4 & 1 + 13 & 80 & 587 & 121 & 14 & 1 + 14 & 5 & 633 & 3 & 0 & 1 +",
    "the plot of the bic cost vs. number of components , figure 1 , shows a distinct global minimum , but there is also a lot of scatter evident .",
    "we performed additional runs using models with between 10 and 30 components in an attempt to quantify the reproducibility of the number of nonpredefined components in each model .",
    "table [ tab : multirun ] displays some results that illustrate this issue .",
    "rrrrr 10 & 1 2 2 3 2 & 2.0 & 0.63 + 11 & 2 2 1 2 2 & 1.8 & 0.40 + 12 & 2 2 2 2 3 & 2.0 & 0.40 + 13 & 2 1 2 2 3 & 2.0 & 0.63 + 14 & 2 3 1 2 2 & 2.0 & 0.63 + 15 & 2 3 2 1 5 & 2.8 & 1.47 + 16 & 3 3 3 4 2 & 3.0 & 0.63 + 17 & 3 4 3 2 3 & 3.0 & 1.26 + 18 & 4 1 2 4 4 & 3.0 & 1.26 + 19 & 5 2 4 5 6 & 4.4 & 1.46 + 20 & 3 2 6 6 3 & 4.0 & 1.67 + 21 & 5 3 4 3 3 & 3.6 & 0.80 + 22 & 3 3 5 4 3 & 3.6 & 0.80 + 23 & 3 6 5 2 4 & 4.0 & 1.41 + 24 & 8 7 4 6 4 & 3.4 & 1.60 + 25 & 3 4 5 2 3 & 3.4 & 1.02 + 26 & 5 3 4 4 2 & 3.6 & 1.02 + 27 & 7 4 3 3 6 & 4.6 & 1.62 + 28 & 5 5 5 5 4 & 4.8 & 0.40 + 29 & 6 6 5 2 4 & 4.6 & 1.50 + 30 & 6 4 5 5 7 & 5.4 & 1.02 +    column 1 gives the number of components in the model .",
    "column 2 gives the number of nonpredefined components for each of the five additional runs performed .",
    "column 3 gives the average number of nonpredefined components and column 4 gives the standard deviation .",
    "we see that there is a trend toward increasing number of nonpredefined components as the model complexity ( total number of components ) increases .",
    "this is expected since _ all _ classes , including the suo class , should be represented by more components as the total number of components is increased .",
    "note that for @xmath14 the additional model runs produced an average of 3 nonpredefined components .",
    "however , these models all had higher bic cost than the one we chose for analysis , which was based on the model with the lowest bic cost ; this model had only two nonpredefined components .",
    "for @xmath15 , which also had a low bic cost , the average number of nonpredefined components is 2 , with little scatter . for @xmath16 , the other model with especially low bic cost ,",
    "the average number of nonpredefined components is 3.4 , with three models producing six or more nonpredefined components .",
    "this is significantly different from the model we analyzed in detail and deserves further study .",
    "we hope to examine this in more detail in a future paper .",
    "the comparison of table [ tab : comp - membership ] with table [ tab : comp - membership2 ] provides some insight into the different results that are achieved with the semisupervised vs. unsupervised algorithms .",
    "the best unsupervised model had 15 components compared with the best semisupervised model , which contained 16 components .",
    "note that the numbers identifying each component are arbitrary so we can not perform a direct component to component comparison between the two models .",
    "however , we do note the following . component 0 of the semisupervised model ( ss0 for short ) is very similar to component 1 of the unsupervised model ( us1 for short ) ; they captured only late - type stars , with 494 and 487 stars respectively .",
    "also , ss12 corresponds closely to us2 since both captured the bulk of the qsos in the sample ( 80% and 74% respectively ) .",
    "still , the semisupervised algorithm did a better job at isolating the qsos .",
    "ss10 and ss11 , the nonpredefined components , appear to have unsupervised analogs in us12 and us4 . ss10 and",
    "ss11 together capture 37% of the suos while us12 and us4 capture 36% .    according to the sdss spectroscopic classification procedure ,",
    "the objects that comprise component 10 are a mixture of mainly suos and stars .",
    "it is notable in figure 3 that many of the suo class points are strongly clustered together between @xmath12 and @xmath13 .",
    "this component overlaps the white dwarf exclusion region of @xcite in all three color - color projections they defined .",
    "it also overlaps a region of low redshift , ugri selected quasars in @xmath0 vs. @xmath1 space ( see figure 13 of @xcite ; also @xcite ) .",
    "it also overlaps the high density region of confirmed quasars from @xcite in all three projections .",
    "all the works just cited base their quasar identifications on photometric properties , while our identification of the objects as suos is based on their spectral properties being unusual in some way .",
    "indeed , a visual inspection of the spectra labeled as suos in component 10 shows that they are almost all blue , relatively featureless spectra .",
    "most of these are likely to be stars , sdo or da white dwarfs @xcite , with a small number of bl lac objects .",
    "figure 5 shows spectra from several representative objects in component 10 .",
    "[ fig : spec10 ]    component 11 in our mixture model has very different characteristics from component 10 .",
    "it consists of almost purely suo type objects ( 80% ) , and it has a much broader distribution of all four colors . furthermore , all the points in component 11 are much redder than those in component 10 .",
    "component 11 has captured a region of color space that is largely in the hiz qso region of the @xmath0 vs. @xmath1 color - color diagram of @xcite .",
    "however , it also corresponds to a region of relatively high density of objects initially classified as quasars but then rejected following a cut on stellar density ( see figure 2 of @xcite ) . a visual inspection of component 11 objects labeled as suos indicates that a majority of these objects are low signal to noise g - k stars .",
    "see figure 6 for sample spectra from objects in component 11 .",
    "sdss target selection is fainter for qsos than stars and galaxies since their prominent broad features make qsos easier to identify at low signal to noise .",
    "stars incorrectly targeted as qsos are thus more likely to be classified as suos .",
    "[ fig : spec11 ]    the small rms values for several of the components suggest , on the surface , a homogeneity of object types within the components . for example , component 10 has a relatively small rms in all colors ( see table [ tab : phot - stats ] ) .",
    "this is consistent with all the objects being owned by a single mixture component but it does not necessarily mean all the objects are the same . that determination would have to be made with more detailed examination and comparison of the spectra of the objects .",
    "moreover , there are several possible reasons why the nonpredefined components contain significant numbers of points from other classes . first , for some objects",
    ", the fact that the object is assigned to the suo class is indicative that there is significant uncertainty about its class of origin .",
    "all objects that are identified as suos by the sdss spectral pipeline are also visually inspected .",
    "some objects in the suo class may really belong to one of the known classes , but were not classified as such in the sdss spectral pipeline because the specificity of the pipeline ( its ability to identify positive instances of an object class ) is limited .",
    "the procedure for labeling an object as spectroscopically unclassified involves cross - correlation with several standard templates and the determination of the confidence level of the cross - correlation . when this confidence level is below 0.25",
    "then the object is labeled as an suo .",
    "subsequent visual inspection was unable to provide a confident classification of these objects .",
    "if there are a significant number of such objects and if they have similar feature vectors , a nonpredefined cluster may be learned which contains many of these objects ( and whose model parameters well - describe these objects ) .",
    "however , such a cluster may also well - describe ( unlabeled ) known class objects , and thus may contain a significant number of such objects .",
    "another possibility is that some objects in the known classes are mislabeled and should really be members of the suo class or classes .",
    "while the mixed composition of nonpredefined components is partially explained by uncertainty and/or errors associated with the spectral pipeline object labelings , another possible explanation is that the features we chose were not powerful enough to fully distinguish between objects from the different classes . in particular , since each photometric band is essentially a weighted average of the spectrum of the object , it is clear that significantly different spectra may produce similar photometric responses .",
    "this suggests that one should be cautious when using only photometric features for classification purposes .",
    "using additional features , such as the photometry in @xmath6 , @xmath7 , @xmath8 , @xmath9 , and @xmath10 , might help differentiate between classes .",
    "certainly , including uv or ir data in a multispectral analysis would lead to more powerful discriminators .",
    "working directly with the high - dimensional object spectra would also substantially enhance the potential for class discrimination .",
    "however , there are also many spectral features that are _ not _ class - discriminating .",
    "this indicates the need for effective feature selection , to determine the ( perhaps small ) subset of features that are most important for distinguishing the different object classes .",
    "some recent approaches have been proposed for feature selection in high - dimensional mixture modeling , e.g. @xcite , which we hope to exploit in the near future .",
    "[ fig : color - color14 - 15 ]    as mentioned above , a number of predefined components also have significant admixtures of various types of objects .",
    "in particular we note components 14 and 15 , which together have 81% of all the galaxies in our sample .",
    "these two components split the galaxies into two clusters , as shown in figure 6 .",
    "this is very similar to the bimodal distributions found by @xcite in the sdss data and more recently seen also in combined galex and sdss observations @xcite .",
    "the two components contain essentially equal fractions of galaxies ( 60% ) , though some fraction of the suo class objects could also be galaxies .",
    "they also have a low fraction of quasars .",
    "our modeling procedure allows for the possibility that several mixture components may be needed to describe a single class .",
    "however , in this case no other components appear to overlap this region of color - color space .",
    "it is hard to find components for the unsupervised model which correspond well to components ss14 and ss15 that capture some of the bimodal galaxy distribution .",
    "us5 alone captures 63% of the galaxies , but the remaining galaxies are fairly evenly spread among four other components .",
    "notably , the separation into two clusters by the semisupervised mixture model is a byproduct of our main objective of looking for subclasses in the suos .",
    "however , even with a sample containing only 2000 galaxies , we find that our mixture model does a very good job of separating the galaxy distribution into two separate clusters .",
    "it also appears to result in a better separation than that due to the unsupervised approach .",
    "we hope to perform a similar analysis using a much larger sample of galaxies and look for a more detailed decomposition of the main galaxy class .",
    "we would like to thank the nasa applied information systems research program for supporting us in this effort under contract nas5 - 02098 .",
    "we also extend our thanks to the anonymous referee for a number of suggestions that greatly improved this paper .",
    "funding for the creation and distribution of the sdss archive has been provided by the alfred p. sloan foundation , the participating institutions , the national aeronautics and space administration , the national science foundation , the u.s .",
    "department of energy , the japanese monbukagakusho , and the max planck society .",
    "the sdss web site is http://www.sdss.org/.    the sdss is managed by the astrophysical research consortium ( arc ) for the participating institutions .",
    "the participating institutions are the university of chicago , fermilab , the institute for advanced study , the japan participation group , the johns hopkins university , the korean scientist group , los alamos national laboratory , the max - planck - institute for astronomy ( mpia ) , the max - planck - institute for astrophysics ( mpa ) , new mexico state university , university of pittsburgh , university of portsmouth , princeton university , the united states naval observatory , and the university of washington .",
    "in this appendix we provide a more detailed description of the semisupervised mixture model we used in this study .",
    "we describe what needs to be included in the input data and how this differs from a standard mixture model .",
    "we explain the various parameters used in the mixture model and how they make up the likelihood function that is maximized to find the best model parameters .",
    "we then describe how the model is used to infer class membership for each of the objects in the data set .",
    "we explain how the bayesian information criterion is used to find the best overall model among available models .",
    "finally , we discuss how the model scales with the number of parameters , components and objects in the data set .",
    "we first consider a data set that contains two types of samples : those that contain a class label and those that are missing a class label , called labeled and unlabeled respectively .",
    "each data point is described by a feature vector @xmath17 .",
    "the class labels are drawn from a finite set of known classes @xmath18 .",
    "this description follows that of @xcite .",
    "in particular , we note that if a sample is labeled then it must originate from one of the known classes .",
    "however , if the sample is unlabeled it may come from a new class ( one that is not in the set of known classes ) or it may be an unlabeled sample from a known class .",
    "moreover , in the unlabeled case , if it did come from a known class , it is uncertain which known class .",
    "mixture modeling is based on the premise that similar types of objects tend to cluster together in feature space .",
    "thus , if a cluster contains a mixture of labeled and unlabeled objects where the labels are randomly missing , these unlabeled objects probably belong to the class associated with the labeled data .",
    "furthermore , if a cluster contains mainly unlabeled objects then it is possible that this cluster describes a new class , one not contained in @xmath18 .",
    "clearly , the presence or absence of a class label on a sample may be helpful in distinguishing known classes from unknown . using this insight",
    ", @xcite suggested using the presence or absence of a class label as additional data which the mixture model must explain .",
    "thus , the data set can be completely described as @xmath19 , where now @xmath20 is the labeled data set and @xmath21 is the unlabeled data set .",
    "here we use the new random observation @xmath22 that takes on values indicating a sample is either labeled or missing the label .      using the entire data set @xmath23 , @xcite proposed a special mixture model to explain all the data , including the presence or absence of a label for each sample .",
    "this mixture model included two types of mixture components which differed in the way they generated the data values @xmath24 or @xmath25 indicating the presence or absence of a label for each sample .",
    "predefined components generate both labeled and unlabeled data from known classes , with the class labels missing at random .",
    "nonpredefined components generate only unlabeled data and may represent unknown or new classes : they capture isolated clusters of unlabeled data .",
    "we note that these two types of components correspond directly to the data scenario described above .",
    "the data from known classes have labels missing at random and are described by predefined components .",
    "the data from unknown classes are purely unlabeled and are described by nonpredefined components .",
    "next we provide a more detailed description of the mixture model we used , again following @xcite .",
    "we begin with the definitions of the relevant parameters in the model .",
    "our mixture model consists of @xmath26 mixture components , denoted by @xmath27 , @xmath28 . in this set of components",
    "there is a subset that are predefined , @xmath29 and a subset that are nonpredefined , denoted @xmath30 .",
    "we define @xmath31 to be a random variable over the @xmath32 known classes , with @xmath33 the class label for sample @xmath34 .",
    "the prior probability for component @xmath26 is denoted @xmath35 .",
    "we denote by @xmath36 the parameter set specifying component @xmath26 s component - conditional joint feature density , and let @xmath37 .",
    "@xmath38 augments the original class set @xmath18 by adding the value @xmath6 which is used to indicate that a sample is unlabeled . with respect to the augmented set @xmath39 every sample",
    "is now `` labeled '' , with the unlabeled samples taking on the class label `` u '' .",
    "we assume each model component has a different random label generator which we write as @xmath40 \\equiv \\beta_{c|k}$ ] . here",
    "the class @xmath41 is selected from the augmented class set : @xmath42 .",
    "note that @xmath43 .",
    "the function @xmath44 measures the fraction of samples from component @xmath26 that belong to class @xmath41 .",
    "in particular , @xmath45 is the fraction of unlabeled samples from component @xmath26 . strictly speaking , for a nonpredefined component @xmath46 , i.e.",
    ", all samples from the nonpredefined component , @xmath26 , are unlabeled . in practice , we take @xmath47 ; see discussion below . in summary , the mixture model is based on the parameter set @xmath48 .",
    "_ hypothesis for random generation of the data_the model of @xcite hypothesizes that each sample from @xmath23 is generated independently , based on the parameter set @xmath49 , according to the following stochastic generation process :      _ joint data likelihood_the log of the joint data likelihood associated with this model is @xmath54 where @xmath55 .",
    "the model parameters @xmath49 can be chosen to maximize the log - likelihood , equation [ newlik ] , via the expectation - maximization ( em ) algorithm ( e.g. @xcite )",
    ".    this model does not explicitly discover new class components , i.e. , mixture components that are purely unlabeled .",
    "however , suppose that for a given component @xmath50 two situations pertain .",
    "first suppose that @xmath56 .",
    "this means that almost all of the samples owned by this component are unlabeled . furthermore , suppose that @xmath57 is also significantly greater than the average value @xmath58 , meaning that the number of unlabeled samples owned by this component is larger than for most other components .",
    "then , for component @xmath50 the fraction of unlabeled data that it owns is unusually high and we categorize this component as `` nonpredefined '' , i.e. @xmath59 .",
    "such components describe a class of objects that are putatively unknown , novel , or new .",
    "all other components are categorized as `` predefined '' , and represent known class data .",
    "in other words we use the following strategy for new class discovery in a mixed labeled and unlabeled data scenario : ( 1 ) learn a mixture model to maximize the log likelihood , equation [ newlik ] ; ( 2 ) for each component , declare it `` nonpredefined '' if @xmath60 ; otherwise , declare it `` predefined '' . here , @xmath61 is a suitably chosen threshold . in practice",
    ", we declare a component `` nonpredefined '' when its value @xmath57 is closer to @xmath62 than to the average value , i.e. , we choose @xmath63 .",
    "we have found this choice for @xmath61 to give reasonable results for a variety of experimental conditions ( for different data sets and for different fractions of labeled data ) .      using the procedure just described we produce the maximum likelihood model based on the optimal parameter set defined by @xmath49 .",
    "this model can be used for the two inference tasks that are of interest to us : 1 ) classification of a given sample to one of the known classes and 2 ) discrimination between known and unknown classes . for a given sample @xmath34 ,",
    "we can perform classification using the _ a posteriori _",
    "probabilities    @xmath64 = \\frac{\\sum\\limits_{k \\in { \\cal c}_{\\rm pre } } \\alpha_k f(\\underline{x } | \\theta_k ) ( \\frac{\\beta_{c|k}}{1 - \\beta_{u|k}})}{\\sum\\limits_{k \\in { \\cal c } _ { \\rm pre } } \\alpha_k f(\\underline{x } | \\theta_k ) } , c \\in { \\cal p}_c.\\end{aligned}\\ ] ]      to handle the second inference task , discrimination between the hypotheses that an unlabeled sample originates from a known versus an unknown class , we need the _ a posteriori _ probability that the given feature vector is generated by a nonpredefined component .",
    "this is given by @xmath66 =   \\frac{\\sum\\limits_{k \\in { \\bar{\\cal c}}_{\\rm pre } } \\alpha_k   f(\\underline { x } | \\theta_k ) \\beta_{u|k}}{\\sum\\limits_k",
    "\\alpha_k   f(\\underline{x } | \\theta_k ) \\beta_{u|k}}.\\end{aligned}\\ ] ]        the expectation - maximization learning approach we used to find the maximum likelihood model parameters assumes that the number of mixture components @xmath68 ( the model order ) is fixed and known",
    ". however , in practice this size must be estimated .",
    "model order selection is a difficult and pervasive problem , with several criteria proposed @xcite and no consensus on the right one . when attempting class discovery , as we are doing here , accurate model order selection is critical .",
    "specifically , the nonpredefined components in the validated solution will be taken as candidates for new classes .",
    "these new classes will be examined by a domain expert to determine their validity as new classes , prompting additional study as needed .",
    "accurate model order selection is thus paramount for successful new class discovery .",
    "as discussed in the main text , and in @xcite , and @xcite we use the bayesian information criterion ( bic ) @xcite to decide between models with different numbers of components .",
    "the bic model selection criterion is written in the form @xmath69 with @xmath70 the number of free parameters in the @xmath68-component mixture model and @xmath71 the data length .",
    "the first term is the penalty on model complexity , with the second term the negative log - likelihood .",
    "we applied bic in a `` wrapper - based '' model selection approach ; i.e. , we built models for increasing @xmath68 , evaluated bic for each model , and then selected the model with minimum bic cost ( see figure 1 in the main text ) .",
    "the computational complexity of our ( em - based ) learning is @xmath72 , with @xmath73 the number of components , @xmath74 the data dimensionality , @xmath71 the number of data points , and @xmath75 the number of learning iterations before the em algorithm satisfies the convergence criterion ( based on diminishing relative gain in log - likelihood from one iteration to the next ) .",
    "while the number of learning iterations required to converge may in general depend upon the number of components and data dimensions , we have found experimentally that the total learning time does grow approximately linearly in these variables ."
  ],
  "abstract_text": [
    "<S> we analyze a portion of the sdss photometric catalog , consisting of approximately 10,000 objects that have been spectroscopically classified into stars , galaxies , qsos , late - type stars and unknown objects ( spectroscopically unclassified objects , suos ) , in order to investigate the existence and nature of subclasses of the unclassified objects . </S>",
    "<S> we use a modified mixture modeling approach that makes use of both labeled and unlabeled data and performs class discovery on the data set . </S>",
    "<S> the modeling was done using four colors derived from the sdss photometry : @xmath0 , @xmath1 , @xmath2 , and @xmath3 . </S>",
    "<S> this technique discovers putative novel classes by identifying compact clusters that largely contain objects from the spectroscopically unclassified class of objects . </S>",
    "<S> these clusters are of possible scientific interest because they represent structured groups of outliers , relative to the known object classes . </S>",
    "<S> we identify two such well defined subclasses of the suos . </S>",
    "<S> one subclass contains 58% suos , 40% stars , and 2% galaxies , qsos , and late - type stars . </S>",
    "<S> the other contains 91% suos , 6% late - type stars , and 3% stars , galaxies , and qsos . </S>",
    "<S> we discuss possible interpretations of these subclasses while also noting some caution must be applied to purely color - based object classifications . as a side benefit of this limited study </S>",
    "<S> we also find two distinct classes , consisting largely of galaxies , that coincide with the recently discussed bimodal galaxy color distribution . </S>"
  ]
}