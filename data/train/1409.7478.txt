{
  "article_text": [
    "in multi - objective optimization the aim of the optimizer is to find a good approximation of the pareto optimal set ( pos ) in terms of convergence and diversity of solutions .",
    "convergence dictates that solutions in the approximation must be either members of the pos or close to it in objective space .",
    "diversity usually implies that solutions in the approximation should be evenly spaced in objective space , following the distribution of the pos .    in many - objective optimization , in addition to convergence and diversity , a third criterion also becomes a relevant aim of the optimizer .",
    "we call it the _ resolution _ of the approximation",
    ". the _ resolution _ is related to the number of points in the generated approximation of the pos . in many - objective problems",
    "the number of solutions in the pos increases exponentially @xcite with the dimensionality of the objective space . in general , many more points are required to cover uniformly with the same density a higher dimensional space . however , the required resolution of the approximation could vary depending on the application domain and the task of the optimization within the problem solving approach .",
    "a low resolution of the approximation may suffice in some domain applications .",
    "for example , domains where the formulation of the problem is already well understood and a solution has to be found and implemented regularly , such as the daily operational schedule of machines and the jobs assigned to them in a manufacturing plant . in these domains , the optimizer is often required to provide alternative exact solutions and too many of them could overwhelm a decision maker ( operations manager ) that must suggest a prompt course of action . in other application domains a high resolution of the approximation",
    "is required .",
    "for example in design optimization , where the problem - solving cycle often starts with multiple , sometimes ill defined , problem formulations and uses optimization as a tool to validate the understanding of the problem and to discover new features about it . in these application domains it is not unusual to require that the optimizer provides approximations of the pos with tens of thousands or even hundreds of thousands of solutions .",
    "these approximations are subjected to data mining and analysis to verify and improve the problem formulation itself , understand the tradeoffs between variables and objectives , and extract valuable design knowledge @xcite .",
    "thus , a many - objective optimizer should also aim to find an approximation with a _ resolution _ that properly captures the pos , with enough points to provide a useful description of it , depending on the dimensionality of the objective space and the optimization task at hand .",
    "many - objective optimization was initially attempted using evolutionary algorithms that proved effective for two and three objectives only to discover their lack of scalability .",
    "a significant part of the research effort has been understanding the reasons for their failure and improving them , particularly in terms of convergence .",
    "recently , some many - objective optimizers are being proposed @xcite .",
    "however , the performance of the improved and newly proposed algorithms is commonly assessed using a relatively very small number of points focusing mostly on convergence and/or diversity .",
    "the resolution of the approximation in many - objective optimization has not been deeply studied and it is not clear the capabilities and behavior of the algorithms under this additional important criterion .    in this work",
    "we analyze the behavior of three elitist multi- and many - objective evolutionary algorithms generating a high - resolution approximation of the pos .",
    "we define a basic indicator for resolution , the accumulated gain of the population , and several generational search - assessment indices respect to the pos .",
    "we trace the dynamics of survival selection and study the ability to simultaneously keep pareto optimal ( po ) solutions in the population and find new ones to improve the resolution of the approximation , setting population size as a fraction of the size of the pos .",
    "we use mnk - landscapes with @xmath0 objectives and @xmath1 bits , for which it is possible to know by enumeration all po solutions .",
    "an important objective of this work is to analyze the ability of the algorithms to generate a high - resolution approximation of the pos .",
    "a simple and basic indicator for resolution is to count the number of po solutions found by the algorithms . in many - objective problems",
    "is likely that the population size is considerable smaller than the size of the pos .",
    "thus , to achieve a good resolution the algorithms should first be able to hit the pos with some members of the population and then continue discovering other po solutions .",
    "the ability to converge towards the pos is a very important feature of the algorithm . in this study , we focus our attention mostly on the ability of the algorithm to continue discovering new po solutions assuming that the algorithms can converge to the pos .    to evaluate this ability we use four mnk - landscapes @xcite randomly generated with @xmath2 , @xmath3 , @xmath4 , @xmath5 objectives , @xmath6 bits , and @xmath7 epistatic bit . in small landscapes with low non - linearity",
    "it is relatively simple for the algorithm to hit the optimal set .",
    "it is also possible to enumerate them and know the pos in order to analyze the dynamic of the algorithms respect to the optimum set .",
    "the exact number of po solutions found by enumeration and the number of non - dominated fronts are shown in table  [ post ] under columns @xmath8 and @xmath9 , respectively .",
    "the same table also shows the corresponding fraction ( @xmath10 ) of the population sizes @xmath11 to the @xmath8 for various population sizes investigated here .",
    ".number of pareto optimal solutions @xmath8 and number of non - dominated _ fronts _ in the landscapes with @xmath2 , @xmath3 , @xmath4 , and @xmath5 objectives . also , fraction of @xmath11 / @xmath8 ( in @xmath10 ) for various population sizes @xmath11 investigated in this study .",
    "[ cols=\"^,^,^ , > , > , > , > , > , > , > , > , > \" , ]     [ indexes ]    in this work we analyze nsga - ii @xcite , ibea @xcite , and the adaptive @xmath12-sampling and @xmath12-hood algorithm @xcite . in the following we briefly describe these algorithms , particularly fitness assignment , survival selection , and parent selection .",
    "nsga - ii is an elitist algorithm that uses pareto dominance and crowding estimation of solutions for survival and parent selections . to compute fitness of the individuals ,",
    "the algorithm joins the current population @xmath13 with its offspring @xmath14 and divide it in non - dominated fronts @xmath15 using the non - dominated sorting procedure .",
    "it also calculate the crowding distance @xmath16 of solutions within the fronts @xmath17 .",
    "the fitness of @xmath18-th solution in the @xmath19-th front is @xmath20 , where the front number is the primary rank and crowding distance the secondary rank .",
    "survival selection is performed by copying iteratively the sets of solutions @xmath17 to the new population @xmath21 until it is filled .",
    "if the set @xmath17 , @xmath22 , overfills the new population @xmath21 , the required number of solutions are chosen based on their secondary rank @xmath16 .",
    "parent selection for reproduction consists of binary tournaments between randomly chosen individuals from @xmath21 using their primary rank @xmath19 to decide the winners , breaking ties with their secondary rank @xmath16 .      the main idea of ibea @xcite is to introduce a total order between solutions by means of an arbitrary binary quality indicator @xmath23 .",
    "the fitness assignment scheme of ibea is based on a pairwise comparison of solutions in a population with respect to indicator  @xmath23 .",
    "each individual @xmath24 is assigned a fitness value measuring the `` loss in quality '' if @xmath24 was removed from the population @xmath25 , i.e. , @xmath26 , where @xmath27 is a user - defined scaling factor .",
    "survival selection is based on an elitist strategy that combines the current population @xmath13 with its offspring @xmath14 , iteratively deletes worst solutions until the required population size is reached , and assigns the resulting population to @xmath28 . here ,",
    "each time a solution is deleted the fitness values of the remaining individuals are updated .",
    "parent selection for reproduction consists of binary tournaments between randomly chosen individuals using their fitness to decide the winners .",
    "different indicators can be used within ibea .",
    "we here choose to use the binary additive @xmath29-indicator  ( @xmath30 ) , as defined by the original authors @xcite .",
    "@xmath31 @xmath32 gives the minimum value by which a solution  @xmath33 has to , or can be translated in the objective space in order to weakly  dominate another solution  @xmath34 .",
    "more information about ibea can be found in @xcite .",
    "adaptive @xmath12-sampling and @xmath12-hood ( a@xmath12s@xmath12h ) @xcite is an elitist evolutionary many - objective algorithm that applies @xmath12-dominance principles for survival selection and parent selection .",
    "there is not an explicit fitness assignment method in this algorithm .",
    "survival selection joins the current population @xmath13 and its offspring @xmath14 and divide it in non - dominated fronts @xmath15 using the non - dominated sorting procedure . in the rare case where the number of non - dominated solutions is smaller than the population size @xmath35",
    ", the sets of solutions @xmath17 are copied iteratively to @xmath21 until it is filled ; if set @xmath17 , @xmath22 , overfills @xmath21 , the required number of solutions are chosen randomly from it .",
    "on the other hand , in the common case where @xmath36 , it calls _ @xmath12-sampling _ with parameter @xmath37 .",
    "this procedure iteratively samples randomly a solution from the set @xmath38 , inserting the sample in @xmath21 and eliminating from @xmath38 solutions @xmath12-dominated by the sample .",
    "after sampling , if @xmath21 is overfilled solutions are randomly eliminated from it . otherwise , if there is still room in @xmath21 , the required number of solutions are randomly chosen from the initially @xmath12-dominated solutions and added to @xmath21 .",
    "after survival selection there is not an explicit ranking that could be used to bias mating .",
    "rather , for parent selection the algorithm first uses a procedure called _",
    "@xmath12-hood creation _ to cluster solutions in objective space .",
    "this procedure randomly selects an individual from the surviving population and applies @xmath12-dominance with parameter @xmath39 .",
    "a neighborhood is formed by the selected solution and its @xmath39-dominated solutions . neighborhood creation is repeated until all solutions in the surviving population have been assigned to a neighborhood .",
    "parent selection is implemented by the procedure _",
    "@xmath12-hood mating _ , which sees neighborhoods as elements of a list than can be visited one at the time in a round - robin schedule .",
    "the first two parents are selected randomly from the first neighborhood in the list .",
    "the next two parents will be selected randomly from the second neighborhood in the list , and so on .",
    "when the end of the list is reached , parent selection continues with the first neighborhood in the list .",
    "thus , all individuals have the same probability of being selected within a specified neighborhood , but due to the round - robin schedule individuals belonging to neighborhoods with fewer members have more reproduction opportunities that those belonging to neighborhoods with more members .    both epsilon parameters @xmath37 and @xmath39 used in survival selection and parent selection , respectively , are dynamically adapted during the run of the algorithm .",
    "further details about a@xmath12s@xmath12h can be found in @xcite .",
    "in all algorithms we use two point crossover with rate @xmath40 , and bit flip mutation with rate @xmath41 . in a@xmath12s@xmath12h",
    "we set the reference neighborhood size @xmath42 to 20 individuals . the mapping function @xmath43 used for @xmath12-dominance in @xmath12-sampling truncation and @xmath12-hood creation is additive , @xmath44 . for ibea ,",
    "the scaling factor is set to @xmath45 .",
    "the algorithms run for @xmath46 generations .",
    "results analyzed here were obtained from 30 independent runs of the algorithms .",
    "fig.[fig : r_aftpos_tpos_p50100200 ] shows the the basic resolution index @xmath47 of the approximation at the end of the run , i.e. the ratio of accumulated number of po solutions found to the size of the pos .",
    "results are shown for @xmath48 , @xmath3 , @xmath4 , and @xmath5 objectives using population sizes of @xmath49 .",
    "similarly , fig.[fig : r_aftpos_tpos_p1323 ] shows results for @xmath4 , and @xmath5 objectives using larger populations sizes , between @xmath50 and @xmath51 individuals .",
    "note that a@xmath12s@xmath12h finds many more pareto optimal solutions than nsga - ii and ibea for all population sizes and number of objectives tried here , whereas nsga - ii finds more solutions than ibea when population sizes are relatively a large fraction of the size of the pos .",
    "see fig.[fig : r_aftpos_tpos_p50100200 ] ( a ) and fig.[fig : r_aftpos_tpos_p1323 ] ( a)-(b ) where population sizes correspond roughly to @xmath52 , @xmath53 , and @xmath54 of the pos for 3 objectives and @xmath52 and @xmath53 for 5 and 6 objectives , as shown in @xmath55 . on the contrary",
    ", ibea finds more solutions than nsga - ii when population sizes are relatively a small fraction of the pos .",
    "see fig.[fig : r_aftpos_tpos_p50100200 ] ( c)-(d ) where population sizes @xmath56 are used in @xmath4 and @xmath5 objectives , which correspond to fractions in the range @xmath57 of the pos . in @xmath3 objectives ,",
    "fig.[fig : r_aftpos_tpos_p50100200 ] ( b ) , an interesting transition can be observed .",
    "when the smallest population is used , i.e. 50 individuals @xmath58 of pos , ibea finds more solutions than nsga - ii . for a population size of 100 @xmath59 of pos",
    "nsga - ii finds a slightly larger number of solutions than ibea . for a population size of 200 @xmath60 of pos",
    ", nsga - ii finds a significant larger number of solutions than ibea .",
    "the gap between a@xmath12s@xmath12h and the other two algorithms augments when the population size increases within a range in which it still is a small fraction of the pos , as shown in fig.[fig : r_aftpos_tpos_p50100200 ] ( b)-(d ) where the ranges in which population size increase are @xmath61 , @xmath62 , and @xmath63 of pos for @xmath3 , @xmath4 , and @xmath5 objectives , respectively . on the other hand ,",
    "the gap reduces when population size increases within a range in which it is a large fraction of the pos , as shown in fig.[fig : r_aftpos_tpos_p50100200 ] ( a ) and fig.[fig : r_aftpos_tpos_p1323 ] ( a)-(b ) where the ranges in which population size increase are roughly @xmath64 of pos for @xmath48 objectives and @xmath65 for @xmath4 and @xmath5 objectives .    , i.e. ratio of accumulated number of pareto optimal solutions found to the size of the pos .",
    "population sizes 50 , 100 , and 200 for 3 , 4 , 5 , and 6 objectives .",
    "algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]    \\(a ) @xmath66=3 objectives    , i.e. ratio of accumulated number of pareto optimal solutions found to the size of the pos .",
    "population sizes 50 , 100 , and 200 for 3 , 4 , 5 , and 6 objectives .",
    "algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]    \\(b ) @xmath66=4 objectives    , i.e. ratio of accumulated number of pareto optimal solutions found to the size of the pos .",
    "population sizes 50 , 100 , and 200 for 3 , 4 , 5 , and 6 objectives .",
    "algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]",
    "\\(c ) @xmath66=5 objectives    , i.e. ratio of accumulated number of pareto optimal solutions found to the size of the pos .",
    "population sizes 50 , 100 , and 200 for 3 , 4 , 5 , and 6 objectives .",
    "algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]",
    "\\(d ) @xmath66=6 objectives    , @xmath67 , and @xmath68 for 4 , 5 , and 6 objectives , respectively .",
    "algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]",
    "\\(a ) @xmath66=5 objectives    , @xmath67 , and @xmath68 for 4 , 5 , and 6 objectives , respectively .",
    "algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]    \\(b ) @xmath66=6 objectives    , 6 objectives , @xmath46 generations .",
    "algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]",
    "\\(a ) @xmath69 : pareto optimal    , 6 objectives , @xmath46 generations .",
    "algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]    \\(b ) @xmath70 : old pareto optimal    , 6 objectives , @xmath46 generations .",
    "algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]",
    "\\(c ) @xmath71 : absolutely new pareto optimal    , 6 objectives , @xmath46 generations . algorithms a@xmath12s@xmath12h ( a ) , nsga - ii ( n ) and ibea ( i ) . ]",
    "\\(d ) @xmath72 : dropped pareto optimal      fig.[fig : sip50100200m6g100 ] ( a)-(d ) show boxplots of some @xmath73 indexes computed from data obtained in 30 independent runs of the algorithms iterating @xmath46 generations .",
    "results are shown for 6 objectives landscapes using population sizes \\{50 , 100 , 200 } , which are relatively small compared to the pos .",
    "from these figures important observations are as follow .    in average , at each generation",
    ", ibea contains in its population a very large number of po solutions compared to a@xmath12s@xmath12h and nsga - ii as shown in fig.[fig : sip50100200m6g100 ] ( a ) .",
    "note that the median of index @xmath74 for ibea is in the range 0.88 - 0.95 , whereas the ranges for a@xmath12s@xmath12h and nsga - ii are between 0.6 - 0.85 and 03 - 0.4 , respectively .",
    "however , the number of old po solutions ( po solutions present in the current population and also in the population of the previous generation ) for ibea is much larger than for a@xmath12s@xmath12h and nsga - ii , as shown in fig.[fig : sip50100200m6g100 ] ( b ) .",
    "note that the median of @xmath75 is in the range 0.75 - 0.85 for ibea , whereas @xmath75 is in the range 0.48 - 0.68 for a@xmath12s@xmath12h and 0.25 - 0.35 for nsga - ii .",
    "in fact , the generational average number of absolutely new po solutions ( po solutions in the current population that have not been discovered in previous generations ) is larger for a@xmath12s@xmath12h than for ibea and nsga - ii , as shown in fig.[fig : sip50100200m6g100 ] ( c ) .",
    "note that the median of index @xmath76 for a@xmath12s@xmath12h is around 0.12 , whereas for ibea it reduces with population size from 0.10 to 0.06 and slightly increases for nsga - ii from @xmath77 to @xmath78 .",
    "the similar @xmath76 values by aeseh are a good sign of robustness to population size variations , i.e. a similar discovery rate could be expected with various population sizes . on the contrary ,",
    "ibea s discovery rate could reduce significantly with population size .",
    "if the evaluation of the algorithms is done based only on the points included in the population at a given generation , as it is often the case , ibea is likely to contain more po solutions than a@xmath12s@xmath12h , as shown in fig.[fig : sip50100200m6g100 ] ( a ) , and therefore be considered a better algorithm .",
    "however , a@xmath12s@xmath12h finds twice as many po solutions than ibea , as shown in fig.[fig : r_aftpos_tpos_p50100200 ] ( d ) .",
    "these results show that ibea could be a good algorithm for finding a low resolution approximation of the pos , but for high resolutions is not efficient . in general",
    ", these results show the importance of properly evaluating the algorithms according to the aim of the optimization task at hand .",
    "the index of dropped po solutions @xmath79 ( po solutions present in the population of the previous generation that are not included in the current population after truncation selection ) shows a trend vey similar to the one observed for the index @xmath76 , as shown in fig.[fig : sip50100200m6g100 ] ( d ) .",
    "dropping superior solutions in favor of solutions that appear non - dominated in the population but are inferior in the landscape could be seen as a selection weakness .",
    "however , this could also be a source of exploration .",
    "this deserves further research .",
    "the accumulated population gains @xmath80 for a@xmath12s@xmath12h and ibea are illustrated in fig.[fig : r_intpos_p_p200m6 ] for population size 200 and 6 objectives .",
    "note that just after 20 generation the gain by a@xmath12s@xmath12h is already larger than by ibea . at the end of the run ,",
    "a@xmath12s@xmath12h is able to generate an approximation twelve times the size of its population , whereas ibea is able to generate an approximation 6 times the size of its population .     over the generations .",
    "population size 200 , 6 objectives .",
    "algorithms a@xmath12s@xmath12h and ibea . ]",
    "\\(a ) aeseh     over the generations .",
    "population size 200 , 6 objectives .",
    "algorithms a@xmath12s@xmath12h and ibea . ]",
    "this work has studies the behavior of nsga - ii , ibea and a@xmath12s@xmath12h generating a high - resolution approximation of the pos .",
    "the study has clarified the ability and efficiency of the algorithms assuming scenarios where it is relatively easy to hit the pos , showing the importance to properly assess algorithm s performance according to the task of the optimizer in many objective optimization . in the future",
    ", we would like to extend our study to larger landscapes in order to understand the behavior of selection in scenarios where the convergence ability towards the pos is determinant to achieve a good resolution .",
    "also , we would like to study other indicators for ibea and other many - objective algorithms .",
    "y. nishio , a. oyama , y. akimoto , h. aguirre and k. tanaka .",
    " many - objective optimization of trajectory design for destiny mission \" , learning and intelligent optimization conference , lecture notes in computer science , springer , 2014 .",
    "h. aguirre , a. oyama , and k. tanaka ,  adaptive @xmath12-sampling and @xmath12-hood for evolutionary many - objective optimization \" , proc .",
    "7th intl conf . on evolutionary multi - criterion optimization ( emo 2013 ) , lecture notes in computer science , springer , vol.7811 , pp .",
    "322 - 336 , 2013 .",
    "k. deb , s. agrawal , a. pratap and t. meyarivan ,  a fast elitist non - dominated sorting genetic algorithm for multi - objective optimization : nsga - ii \" , _ kangal report 200001 _ , 2000 .",
    "e. zitzler , s. kunzli ,  indicator - based selection in multiobjective search \" , proc .",
    "8th intl conference on parallel problem solving from nature - ppsn viii , lecture notes in computer science , springer , vol .",
    "3242 , pp . 832 - 842 , 2004 ."
  ],
  "abstract_text": [
    "<S> this work studies the behavior of three elitist multi- and many - objective evolutionary algorithms generating a high - resolution approximation of the pareto optimal set . </S>",
    "<S> several search - assessment indicators are defined to trace the dynamics of survival selection and measure the ability to simultaneously keep optimal solutions and discover new ones under different population sizes , set as a fraction of the size of the pareto optimal set . </S>"
  ]
}