{
  "article_text": [
    "this work initiates the study of the _ risk profile _ problem for stock portfolio optimization .",
    "the problem has several variants depending on a given investor s preference toward the trade - off between risk and return @xcite .    in the problem",
    ", the investor has a capital , which is normalized to one dollar .",
    "she considers @xmath3 different stocks @xmath4 and wishes to invest some @xmath5 dollars in each stock @xmath6 for a certain period of time , where @xmath7 and @xmath8 for all @xmath9 .",
    "the vector @xmath10 is called a _",
    "portfolio_. let @xmath11 be the set of all portfolios for @xmath3 stocks .",
    "the _ return _ of @xmath12 is the ratio , expressed as a percentage , of the worth of this portfolio at the end of the investment period to the initial investment of one dollar .",
    "return _ of stock @xmath13 is the ratio of its price at the end of the investment period to its initial price , which is the same as the return of the portfolio @xmath14 with @xmath15 and all the other @xmath16 .    in mathematical finance , stock prices",
    "are often assumed to follow geometric brownian motions or its variants ( e.g. , see @xcite ) . to complement this conventional approach with computer science methodologies @xcite",
    ", we assume that stock prices can move arbitrarily .",
    "let @xmath17 be a positive real number .",
    "let @xmath18 and @xmath19 be integers with @xmath20 , and let @xmath21 .",
    "let @xmath22 .",
    "each stock @xmath6 is associated with a discrete probability distribution @xmath23 over @xmath24 , where @xmath25 is the probability that the stock s return is @xmath26 .",
    "for the sake of technical convenience , we allow @xmath18 and @xmath19 to be negative",
    ". the probability distributions @xmath27 are part of the input in our problem and are obtainable , e.g. , by observing historical market data .",
    "we assume that non - zero values satisfy @xmath28 for some constant @xmath29 , and when representation is important we assume that these values can be represented as fixed - point numbers with @xmath30 bits .",
    "the parameters @xmath17 , @xmath18 , and @xmath19 control the precision and range of such observations .",
    "for instance , for @xmath31 , @xmath32 , and @xmath33 , the set of possible returns are @xmath34 .",
    "the joint distribution of the @xmath3 probability distributions @xmath23 is usually unavailable for a variety of practical reasons . in particular",
    ", a joint distribution consists of @xmath35 entries and thus would require observing an exponential number of data points in @xmath3 .    the investor s goal is to find a portfolio @xmath12 , which is optimal according to her risk preference in six basic cases as follows . for a _ risk - averse _ investor ,",
    "minimizing loss is more important than maximizing win , while an _ aggressive _ investor has the opposite priority .",
    "each of these two investor types can be further classified into three subtypes , namely , _",
    "best - case , worst - case , and average - case _ , referring to whether the probability of loss or win is estimated in the best , worst , or average case over the feasible joint distributions .",
    "more precisely , for each of these six types , the investor first chooses a _",
    "return @xmath36 and then looks for such a portfolio @xmath12 that optimizes one of the following six probabilities :    * @xmath37 ( respectively , @xmath38 or @xmath39 ) is the smallest ( respectively , largest or average ) probability that the return of @xmath12 is at most @xmath40 over all joint distributions for @xmath27 . * @xmath41 ( respectively , @xmath42 or @xmath43 ) is the largest ( respectively , smallest or average ) probability that the return of @xmath12 is at least @xmath40 over all joint distributions for @xmath27 .    if the investor is best - case ( respectively , worst - case or average - case ) risk - averse , she would choose @xmath12 to minimize @xmath37 ( respectively , @xmath38 or @xmath39 ) .",
    "in contrast , if the investor is best - case ( respectively , worst - case or average - case ) aggressive , she would choose @xmath12 to maximize @xmath41 ( respectively , @xmath42 or @xmath43 ) .    while the risk profile problem originates from a very applied field ,",
    "the corresponding mathematical model has a substantial combinatorial structure . in the cases where the investor is highly risk - averse or highly aggressive",
    ", we can model the problem as a network flow problem . quite surprisingly , in the two - stock case , this flow problem is solvable by a simple greedy algorithm in @xmath44 time .",
    "in contrast , for the three - stock case , the applicability of a greedy flow - based algorithm would imply @xmath45 .",
    "if the number @xmath3 of stocks is part of the input , we give an exact algorithm based on linear programming which takes time polynomial in the number of entries of a corresponding contingency table but exponential in the input size . to supplement this algorithm",
    ", we also give a polynomial - time approximation algorithm based on linear programming .",
    "we further present an exact polynomial - time algorithm in the practical case where the capital can only be broken up into a fixed number of units ( e.g. , cents ) .",
    "it remains open whether this problem is @xmath46-complete if the number of stocks is part of the input .",
    "we strongly suspect that this is indeed the case .",
    "in the case of an average - case investor we show @xmath0-hardness of the problem of computing the distribution function over various probability bounds , a natural first - step in solving the average - case investor problem .",
    "this hardness result holds even in two dimensions , and we describe an approximation algorithm for this case .",
    "this algorithm uses a random walk approach to sample from the feasible joint distributions , and is closely related to volume computation and sampling from log - concave distributions .",
    "section [ sec_not ] defines some notation .",
    "section [ sec_two ] discusses the case where there are only two stocks under consideration .",
    "section [ sec_k ] discusses the case of general @xmath3 .",
    "due to page limitations , all figures are placed in the appendix ( these figures are helpful in understanding the material , but are not strictly necessary ) .",
    "let @xmath47 denote a vector @xmath48 , where @xmath49 .",
    "let @xmath50_{\\vec{\\delta}\\in\\delta^k}\\ ] ] denote a @xmath3-dimensional matrix indexed by @xmath51 .",
    "let @xmath52 denote the set of @xmath3-dimensional matrices for all possible joint distributions of @xmath27 ; i.e. , @xmath52 consists of all matrices @xmath50_{\\vec{\\delta}\\in\\delta^k},\\ ] ] where ( 1 ) @xmath53 is the probability that the return of stock @xmath6 is @xmath54 for @xmath55 , and ( 2 ) thus for all @xmath56 and for all @xmath57 and @xmath58 , @xmath59 for instance , @xmath52 contains the matrix @xmath60 defined by @xmath61 also , in the two - stock case , each @xmath62 is just a two - dimensional @xmath63 matrix , where for all @xmath64 , the entries of @xmath60 in column @xmath65 sum up to @xmath66 and those in row @xmath67 sum up to @xmath68",
    ".    given a portfolio @xmath69 and a target return @xmath36 , let @xmath70 which are the sets of the indices of all entries in the matrices in @xmath71 such that the return of @xmath12 is at most , less than , at least , and more than @xmath36% , respectively .",
    "we further define the following functions on @xmath72 : @xmath73 which are the probabilities in the joint distribution @xmath60 that the return of @xmath12 is at most , less than , at least , and more than @xmath40 , respectively .",
    "formally , if @xmath74 is a uniform density over @xmath71 , @xmath75 for example , in the two - stock case , @xmath76 is the set of all indices in a two - dimensional table @xmath60 in @xmath77 on or below the line @xmath78 , and @xmath79 maximizes the sum of the entries in this region under the condition that @xmath60 has the given column and row sums of @xmath80 .    for technical convenience",
    ", we also define the following terms : @xmath81    [ lem_simpl ] the following statements hold .",
    "@xmath82    straightforward .",
    "in light of lemma  [ lem_simpl ] , to solve the risk profile problem , it suffices to show how to compute @xmath83 the techniques for computing the latter three expressions are essentially the same as those for computing the former three .",
    "furthermore , the techniques for computing the first expression are almost identical to those for computing the second . for these reasons ,",
    "the remainder of our discussion focuses on how to compute @xmath84 and @xmath85 .",
    "this section assumes that @xmath86 , i.e. , there are only two stocks under consideration . in the case of two stocks , we can visualize the problems under consideration as in figure  [ fig : visual ] .",
    "the discrete and finite set of possible return pairs for the two stocks in the portfolio are shown as the dots in this picture  each pair has a probability ( from the joint distribution ) associated with it , with the given restrictions on column and row sums .",
    "a given portfolio and target return @xmath36 defines a half - space on the set of return pairs , with the shaded area in figure  [ fig : visual ] giving the area in which the total return is @xmath87 .",
    "the problem of computing @xmath38 then is the problem of determining which feasible assignment of joint probabilities places the highest total probability in the shaded region .",
    "given a target return @xmath36 , this section focuses on how to compute an optimal portfolio for a worst - case risk - averse investor .",
    "the cases of a best - case risk - averse investor , a worst - case aggressive investor , and a best - case aggressive investor can be solved similarly .",
    "we first present a basic algorithm to compute @xmath38 by computing a worst - case joint distribution matrix @xmath60 for @xmath88 and @xmath89 . for convenience ,",
    "we index the entries of @xmath60 with @xmath90 , where row @xmath9 ( respectively , column @xmath9 ) corresponds to return @xmath91 of @xmath92 ( respectively , @xmath93 of @xmath94 ) .",
    "we model the problem of computing @xmath60 as a network flow problem on the graph @xmath95 defined below :    * @xmath95 has @xmath96 vertices , namely , a source @xmath97 , a sink @xmath98 , and @xmath99 , @xmath100 , where @xmath101 ( respectively , @xmath102 ) corresponds to return @xmath91 of stock @xmath92 ( respectively , stock @xmath94 ) .",
    "* for all @xmath103 , @xmath95 has ( 1 ) edge @xmath104 , which has capacity @xmath105 if @xmath106 or @xmath107 otherwise ; ( 2 ) the edge @xmath108 with capacity @xmath109 ; and ( 3 ) the edge @xmath110 with capacity @xmath111 .",
    "geometrically , we wish to push as much probability as possible into the region of @xmath60 defined by @xmath112 . in other words ,",
    "the value of a maximum @xmath113 flow of @xmath95 equals @xmath38 .",
    "thus , it is tempting to use a maximum flow algorithm to solve this maximum flow problem .",
    "the fastest known algorithm for this problem is due to goldberg and rao @xcite and runs in @xmath114 time for the `` soft - o '' notation , which ignores polylogarithmic factors . in bounds for the approximation algorithms",
    ", this notation also ignores factors that depend only on the approximation bound @xmath115 . ] for our application ( note that @xmath116 in this bound is as defined in this work , not as the number of edges which is typical in general flow discussion ) .",
    "instead of using this algorithm , we exploit some structural properties of @xmath95 to solve the flow problem using a simple greedy algorithm in @xmath44 arithmetic operations .",
    "note that since @xmath95 may have @xmath117 edges with positive capacity , we can not afford to construct the whole @xmath95 explicitly .",
    "the idea of our @xmath44-time algorithm can be described as follows .    starting with @xmath118",
    ", we try to push a flow of @xmath119 through @xmath95 .",
    "assume @xmath120 for simplicity .",
    "we consider the path formed by edges @xmath121 first .",
    "we can push flow @xmath122 through this path , saturating either @xmath123 or @xmath124 .",
    "if we saturated @xmath123 then we next consider the path @xmath125 , @xmath126 , @xmath124 for pushing additional flow ; however , if we had saturated @xmath124 we will next consider the path @xmath127 . we continue in this fashion until we can push no more flow .",
    "the only complication is that if at some point we are considering the path @xmath128 , and @xmath129 , then obviously we ca nt saturate _ either _ @xmath108 or @xmath130 , and we simply decrease @xmath9 to next consider the path @xmath131 . the details of this @xmath44 time algorithm are given in figure  [ greedy ] .",
    "* procedure * greedy - flow @xmath132 @xmath133 @xmath134 @xmath135 @xmath136 @xmath137 @xmath138 @xmath139 * if * @xmath140 * then return * @xmath141 @xmath136 @xmath142 @xmath143 @xmath144 * if * @xmath145 * then return * @xmath141 @xmath134    given @xmath146 , a valid portfolio vector @xmath12 , and @xmath36 as input , greedy - flow  computes the value of a maximum flow of @xmath95 in @xmath44 arithmetic operations .    as a first step we prove that the algorithm computes the maximal flow .",
    "let @xmath147 be the minimal index such that @xmath148 is not saturated after termination of the algorithm and @xmath3 be the minimal index such that @xmath149 .",
    "we define a partition @xmath150 of the nodes by @xmath151 it is trivial from the definition of @xmath152 that the edges @xmath153 are saturated .",
    "since @xmath154 , and @xmath3 is the minimal value such that @xmath149 , we have @xmath155 for @xmath156 .",
    "since @xmath148 is not saturated , all edges @xmath157 must be saturated .    from the definition of @xmath3 and the non - negativity of the portfolio vector",
    "it is easy to see that edges @xmath158 for @xmath159 , @xmath160 and positive capacity can not exist .",
    "thus , every edge @xmath161 with @xmath162 and @xmath163 is saturated .",
    "the max - flow - min - cut theorem then implies that the algorithm indeed computes a maximal flow .    observing the fact that in each loop iteration either index @xmath9 is decremented or index @xmath152 is incremented , and that there are only @xmath116 different values that either @xmath9 or @xmath152 can take on before the algorithm terminates , there are at most @xmath164 loop iterations , and the linear running time bound follows .    to compute @xmath165 we have to compute @xmath38 for all possible portfolios @xmath166 .",
    "however , each feasible portfolio corresponds to a half - space ( as in figure  [ fig : visual ] ) defined by a line that goes through the point @xmath167 ( @xmath168 , since @xmath169 ) , so we only need to consider the @xmath170 distinct subsets of return pairs that can be defined by a line going through @xmath167 .",
    "we can identify each such portfolio with a different ( non - positive ) slope @xmath171 , which we assume to be sorted in descending order . by using a suitable data structure it is possible to compute the best portfolio much faster than the obvious @xmath172 algorithm that starts the greedy algorithm for each slope .",
    "given @xmath146 , and @xmath36 , we can compute in @xmath173 arithmetic operations a portfolio @xmath166 for a worst - case risk - averse investor which minimizes equation  @xmath174[p_raw]@xmath175 .    starting with the first slope",
    "@xmath176 we build up a binary tree .",
    "each is labeled with a pair of two real entries @xmath177 .",
    "the leaves of the tree correspond to the rows and the columns in the following way .",
    "starting from column @xmath19 we add leaves from left to right .",
    "we add leaves with labels @xmath178 , @xmath179 , @xmath180 , until we reach a row index @xmath181 such that @xmath182 , i.e. , this index is the last under the crucial line . to be precise",
    "we let @xmath183 ; note that it may be the case that @xmath184 , so this sequence of leaves may be empty . then we add the leaf @xmath185 .",
    "next , we consider column @xmath186 and add leaves @xmath187 , until we reach an index @xmath188 , such that @xmath189",
    ". then we add the leaf @xmath190 and proceed similarly with column @xmath191 .",
    "note that the order of adding leaves is crucial to this data structure and the correctness of the algorithm is based on that .",
    "starting from left to right we group the leaves in pairs of 2 and build a parent node for each pair according to the following rule @xmath192= ( e_1+\\min\\{e_2+f_1,0\\},\\max\\{e_2+f_1,0\\}+f_2).\\ ] ] we build @xmath193 layers iteratively , until we reach a single root node @xmath194 .",
    "it is easy to see that this tree based algorithm imitates the greedy algorithm described before and that @xmath195 is exactly the flow value .",
    "building this tree structure takes constant time per tree node , and since there are @xmath44 nodes we have a total time of @xmath44 , which is no better than the time bound of the greedy algorithm .",
    "the advantage is that we can dynamically update this data structure efficiently .",
    "we will first sort all of the @xmath196 possible return pairs by their slope with the point @xmath167 , so that as the slope determined by our portfolio increases we can quickly ( in constant time per pair ) determine which pairs are added and which are removed from our half - space of interest . this takes @xmath173 time . to update our data structure for each point insertion / removal ,",
    "all that is required is swapping the position of two neighboring leaves .",
    "with obvious techniques , the positions of these two leaves can be found in @xmath197 time , and we can update the tree by looking at the path from the two leaves to the root and update each node on that path .",
    "each update step requires @xmath197 operations and the length of the path is bounded by @xmath193 .",
    "since there are at most @xmath196 point additions and removals , each taking @xmath193 time , it takes at most @xmath198 time to consider all possible portfolios .      for the average - case investor ( @xmath199 or @xmath200 ) , we are not interested in the extremes of the joint distributions , but rather the distribution of the feasible tables . in this section",
    "we consider @xmath201 a random variable where @xmath60 is drawn from a uniform distribution over the feasible tables @xmath52 .",
    "the definition of @xmath39 , from  ( [ p_raa ] ) , is then @xmath202 $ ] .",
    "we will see that computing the distribution function of @xmath203 is a computationally difficult problem to solve exactly , but can be approximated within a reasonable ( polynomial ) amount of time .",
    "let @xmath204 $ ] be an @xmath205-bit rational .",
    "it is @xmath0-hard to compute the fraction of feasible tables @xmath206 with @xmath207 @xmath174the integration of the corresponding indicator function , or the distribution function for @xmath208 .",
    "given positive integers @xmath209 , it is shown in @xcite that computing the @xmath205-dimensional volume of the polyhedron @xmath210 @xmath211 is @xmath0-hard .",
    "let @xmath212 and consider the polyhedron @xmath213 where @xmath214 .",
    "note that for any valid assignment of values to @xmath215 we have @xmath216 , so there is a @xmath217 $ ] that will satisfy  ( [ eq : np1sum ] ) .",
    "now let @xmath218 and define a @xmath219 contingency table by @xmath220 , with row sums @xmath221 and column sums @xmath222 .    to completely define our stock problem",
    ", we must also give values for @xmath17 , @xmath36 , the portfolio @xmath223 , and the threshold @xmath224 , which we do as follows : @xmath225 it is straightforward to verify from these values that the return pairs in the critical region ( the shaded region in figure  [ fig : visual ] ) are exactly the entries @xmath226 for @xmath227 .",
    "therefore , the tables that satisfy our criteria , that @xmath228 , are precisely those with @xmath229 therefore the feasible tables that meet our criteria are exactly those that correspond to points in polyhedron @xmath210 , and so the fraction of tables that meet the criteria is exactly the volume of @xmath210 .    following the notation of dyer , kannan and mount @xcite , who describe a sampling procedure for contingency tables with integer entries and large row and column sums ( @xmath230 ) , we define @xmath231 and @xmath232 as the contingency polytope .",
    "thus , @xmath233 is the set of matrices with row and column sums specified by @xmath234 and @xmath29 respectively . in our case @xmath235 ,",
    "@xmath236 and @xmath237 is the set of joint distributions @xmath71 .",
    "let @xmath238 be the lattice @xmath239 for @xmath240 and @xmath241 , let @xmath242 be the vector in @xmath243 given by @xmath244 and @xmath245 for all other indices @xmath246 .",
    "any vector @xmath247 in @xmath248 can be expressed as linear combination of the @xmath242 s as follows @xmath249 it is easy to see that the @xmath242 are all linearly independent and the the dimension of @xmath233 and @xmath237 for positive row and column sum vectors @xmath234 and @xmath29 is @xmath250 @xcite .",
    "we will apply the sampling algorithm pioneered by dyer , frieze and kannan @xcite and later refined in a sequence of papers ( see @xcite for an overview ) to sample uniformly at random in @xmath237 .",
    "we sample in the space @xmath233 . as mentioned in the introduction , we know a starting point @xmath251 in @xmath237 ( multiplication of rows and column sums ) .",
    "it is easy to see that a ball of radius @xmath252 is inside @xmath237 , if every component of @xmath234 and @xmath29 is at least @xmath253 .",
    "since in our case @xmath234 and @xmath29 sum up to one , @xmath254 .",
    "the following theorem is a corollary of the analysis of the fastest sampling algorithm in convex bodies known so far by kannan , lovsz and simonovits @xcite .",
    "[ sampling ] we can generate a point in @xmath255 , which is almost uniform in the sense that its distribution is at most @xmath115 away from the uniform in total variation distance .",
    "the algorithm uses @xmath256 membership queries of @xmath255 ( each requires @xmath170 arithmetic operations ) .",
    "* procedure * estimate@xmath257 @xmath258 @xmath259 @xmath260 result from sample procedure started at @xmath247 @xmath261 @xmath262 * return * @xmath263    procedure estimate @xmath174 in figure  [ approx]@xmath175 computes a number @xmath263 in @xmath264 arithmetic operations , which approximates @xmath39 @xmath174i.e .",
    ", @xmath265 with probability @xmath266 .",
    "let @xmath267 .",
    "thus , @xmath268 , where @xmath269 is the density produced by the random walk . since @xmath270 for all @xmath271 , it is easy to see that @xmath272 and so @xmath273 . by chebychev s inequality , @xmath274",
    "since the samples are not entirely uniform , we must consider the error introduced by the approximately uniform sampling distribution as well .",
    "let @xmath74 denote a uniform density over the set @xmath52 , and then approximating a uniform distribution within bound @xmath275 , theorem  [ sampling ] implies @xmath276 setting @xmath277 the theorem follows .",
    "in this chapter we consider the general case of more than two stocks .",
    "since the problem of estimating the probability distribution for the average - case investor is already @xmath278-p complete in the two stock case , we do not consider it any more and concentrate on a worst - case investor .",
    "we start with a complexity result for three stocks , which implies that a greedy or flow based portfolio is quite unlikely to exist .    the existence of a greedy or flow based portfolio for the problem with 3 or more stocks implies @xmath2 .",
    "we prove this result by reduction from numerical-3-dim - matching .",
    "consider an instance of numerical-3-dim - matching , i.e. , disjoint sets @xmath279 , each containing @xmath116 elements , a size @xmath280 for each element @xmath281 and bound @xmath282 .",
    "we would like to know if @xmath283 can be partitioned into @xmath116 disjoint sets such that each of these sets contains exactly one element from each of @xmath284 , @xmath285 , and @xmath286 , and the sum of the elements is exactly @xmath287 ( we can change this requirement to @xmath288 without difficulty ) .",
    "this problem is np - complete in the strong sense , so we restrict the sizes to be bounded by a polynomial , @xmath289 for some constant @xmath29 .",
    "we construct an instance of the problem of computing @xmath290 by making a contingency table in which @xmath291 , where @xmath292 is the number of items in set @xmath293 with value @xmath9 .",
    "the existence of a greedy or flow based algorithm implies the existence of a solution in which all entries in the solution table are multiples of @xmath294 , and such a solution exists with @xmath295 if and only if there is a valid partition of @xmath283 .",
    "if such a partition exists , we can find it by simply taking all of the triples `` selected '' ( with multiplicity determined by the integer multiple of @xmath294 ) , and use elements from @xmath284 , @xmath285 , and @xmath286 as determined by the three coordinates of each selected point .    while this proof shows that it is unlikely that a fast and simple greedy or flow - based algorithm exists , as it does for 2 stocks , we can indeed solve the problem for a fixed number of stocks in polynomial time using a more time - consuming procedure based on linear programming .",
    "this is stated in a general setting in the following theorem .",
    "if the number of stocks @xmath3 is part of the input , the problem of determining the best portfolio for a worst - case investor can be solved in time polynomial in the number of entries of the contingency table ( but exponential in @xmath3 ) .",
    "the problem can be modeled as linear program with a number of variables , that corresponds to the number of entries of the contingency table , and @xmath296 inequalities .      in this section",
    "we describe an approximation algorithm , that solves the problem of determining the worst case probability for a given portfolio within a given error @xmath297 in polynomial time .",
    "additionally , we describe an important , non - trivial special case , where the problem can be solved exactly in polynomial time .",
    "suppose that a portfolio @xmath14 and a target return @xmath36 are given .",
    "the worst - case probability can be approximated @xmath174i.e . , we compute a value @xmath298 with @xmath299 in time polynomial in @xmath3 and @xmath205 . the number of steps is dominated by solving a linear program in @xmath300 variables and @xmath301 constraints .",
    "we consider the first pair of stocks @xmath92 and @xmath94 as in the two dimensional case and define a new portfolio as @xmath302 and @xmath303 .",
    "we divide the two dimensional plane in @xmath304 regions by @xmath147 parallel lines @xmath305 of constant distance .",
    "thus , we divide the entries of the joint distribution matrix into @xmath147 different sets ( see figure [ lp ] ) .",
    "each entry in the matrix corresponds to a variable and the variables satisfy the row sum and column sum condition of the joint distribution .",
    "next , we sum up the entries in the @xmath147 different sets and assign the sums to @xmath147 new variables . by combining these sum variables from two different pairs of stocks ,",
    "we get a new table with new row and column sum conditions , resulting again in @xmath147 new sum variables .    repeating combinations in this manner , we stop after @xmath306 iterations and the creation of @xmath307 variables and @xmath308 constraints , leaving just one table with 2 border distributions ( expressed as variables ) .",
    "assuming , that the variables of the border distributions correspond to the distribution of the stocks @xmath309 and @xmath310 , we do the following .",
    "we define a portfolio @xmath311 and @xmath312 for our last table and consider the line @xmath313 , dividing our last table in two sets .",
    "the variables below that line are summed up and we solve a linear program by maximizing this sum subject to the constraints created before . since we reduced the number of entries in each table from @xmath117 to only @xmath147 , that are considered in the next table , we lost some precision during the combination .",
    "but , after the first pairing in the lowest level of the binary tree , each sum variable represents a loss probability of the combination of the two stocks within an error of @xmath314% . furthermore , it is easy to see that during the repeated combination of the stocks the error accumulates linearly in each iteration . thus , the theorem follows .",
    "suppose that a portfolio @xmath14 and a target return probability @xmath315 is given . under the assumption , that the dollar , that has to be invested , can only be broken into a fixed number @xmath29 of equal units ( cents ) , the worst - case probability can be computed exactly in time polynomial in @xmath3 and @xmath116 .    the proof is based on a similar construction as the approximation algorithm and is omitted for brevity .",
    "the authors wish to thank the anonymous referees for very helpful comments ."
  ],
  "abstract_text": [
    "<S> this work initiates research into the problem of determining an optimal investment strategy for investors with different attitudes towards the trade - offs of risk and profit . </S>",
    "<S> the probability distribution of the return values of the stocks that are considered by the investor are assumed to be known , while the joint distribution is unknown . </S>",
    "<S> the problem is to find the best investment strategy in order to minimize the probability of losing a certain percentage of the invested capital based on different attitudes of the investors towards future outcomes of the stock market .    for portfolios made up of two stocks , </S>",
    "<S> this work shows how to exactly and quickly solve the problem of finding an optimal portfolio for aggressive or risk - averse investors , using an algorithm based on a fast greedy solution to a maximum flow problem . </S>",
    "<S> however , an investor looking for an average - case guarantee ( so is neither aggressive or risk - averse ) must deal with a more difficult problem . </S>",
    "<S> in particular , it is @xmath0-complete to compute the distribution function associated with the average - case bound . on the positive side , </S>",
    "<S> approximate answers can be computed by using random sampling techniques similar to those for high - dimensional volume estimation . </S>",
    "<S> when @xmath1 stocks are considered , it is proved that a simple solution based on the same flow concepts as the 2-stock algorithm would imply that @xmath2 , so is highly unlikely . </S>",
    "<S> this work gives approximation algorithms for this case as well as exact algorithms for some important special cases .    </S>",
    "<S> [ theorem]lemma [ theorem]corollary    risk management , portfolio optimization , computational hardness , approximation algorithms , greedy strategies , network flows , volume estimation , random walks . </S>"
  ]
}