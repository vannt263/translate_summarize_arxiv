{
  "article_text": [
    "by a cloud , we mean an infrastructure that provides resources and/or services over the internet . a",
    "_ storage cloud _ provides storage services ( block or file based services ) ; a _ data cloud _ provides data management services ( record - based , column - based or object - based services ) ; and a _ compute cloud _ provides computational services",
    ". often these are layered ( compute services over data services over storage service ) to create a stack of cloud services that serves as a computing platform for developing cloud - based applications .",
    "examples include google s google file system ( gfs ) , bigtable and mapreduce infrastructure @xcite , @xcite ; amazon s s3 storage cloud , simpledb data cloud , and ec2 compute cloud @xcite ; and the open source hadoop system @xcite , @xcite .",
    "data clouds provide some important advantages for managing and analyzing data compared to competing technologies .",
    "first , for the majority of applications , databases are the preferred infrastructure for managing and archiving data sets , but as the size of the data set begins to grow larger than a few hundred terabytes , current databases become less competitive with more specialized solutions , such as the storage services ( e.g. , @xcite , @xcite ) that are parts of data clouds . for example , google s gfs manages petabytes of data @xcite    second , data in a data cloud can easily be replicated .",
    "temporary replicas can be used to improve performance by exploiting locality and caches , permanent replicas can be used for backing up data , and long - term replicas can be used for archiving data .",
    "replicas are typically placed within a rack , across racks , and across data centers to handle various types of failures .",
    "automatic services ensure that after a failure drops a replica , an additional replica is created .",
    "in addition , once replicated , the replicated data provides a natural way to parallelize embarrassingly parallel computations in the cloud .",
    "third , once data is stored in a cloud , the data can wait for computing tasks .",
    "in contrast , in a standard grid computing environment , the data is scattered to nodes in clusters when a sufficiently large pool of nodes are available ; and , in this sense , the nodes wait for the data . for large data sets , transporting the data to the nodes can be a significant percentage of the total processing time .     @xmath0 +   +   +   +    in this paper , we describe a cloud based infrastructure that is optimized for high performance , wide area networks and designed to support the ingestion , data management , analysis , and distribution of large terabyte size data sets .",
    "we assume an `` optiputer '' style design in the sense that we assume that geographically distributed nodes running storage services are connected by a 10 + gbps network that functions more or less as a wide area `` back - plane or bus '' .",
    "this paper is organized as follows : section 2 describes related work .",
    "section 3 describes a storage cloud called sector .",
    "section 4 describes a compute cloud that we have developed called sphere .",
    "section 5 describes two sector and sphere applications .",
    "section 6 is the summary and conclusion .",
    "the most common platform for data mining is a single workstation .",
    "there are also several data mining systems that have been developed for local clusters of workstations , distributed clusters of workstations and grids @xcite .",
    "more recently , data mining systems have been developed that use web services and , more generally , a service oriented architecture .",
    "for a recent survey of data mining systems , see @xcite .    by and large ,",
    "data mining systems that have been developed to date for clusters , distributed clusters and grids have assumed that the processors are the scarce resource , and hence shared .",
    "when processors become available , the data is moved to the processors , the computation is started , and results are computed and returned @xcite . to simplify , this is the supercomputing model , and , in the distributed version , the teragrid model @xcite . in practice with this approach , for many computations , a good portion of the time",
    "is spent transporting the data .",
    "an alternative approach has become more common during the last few years . in this approach ,",
    "the data is persistently stored and computations take place over the data when required . in this model ,",
    "the data waits for the task or query . to simplify ,",
    "this is the data center model ( and in distributed data version , the distributed data center model ) .",
    "the storage clouds provided by amazon s",
    "s3 @xcite , the google file system @xcite , and the open source hadoop distributed file system ( hdfs ) @xcite support this model .    to date , work on data clouds @xcite has assumed relatively small bandwidth between the distributed clusters containing the data .",
    "in contrast , the sector storage cloud described in section  [ section : sector ] is designed for wide area , high performance 10 gbps networks and employs specialized protocols such as udt @xcite to utilize the available bandwidth on these networks .",
    "the most common way to compute over gfs and hdfs storage clouds is to use mapreduce @xcite .",
    "with mapreduce : i ) relevant data is extracted in parallel over multiple nodes using a common `` map '' operation ; ii ) the data is then transported to other nodes as required ( this is referred to as a shuffle ) ; and , iii ) the data is then processed over multiple nodes using a common `` reduce '' operation to produce a result set .",
    "in contrast , the sphere compute cloud described in section  [ section : sphere ] allows arbitrary user defined operations to replace both the map and reduce operations .",
    "in addition , sphere uses specialized network transport protocols @xcite so that data can be transferred efficiently over wide area high performance networks during the shuffle operation .",
    "[ cols=\"^\",options=\"header \" , ]",
    "until recently , most high performance computing relied on a model in which cycles were scarce resources that were managed and data was moved to them when required . as data sets grow large , the time required to move data begins to dominate the computation .",
    "in contrast , with a cloud - based architecture , a storage cloud provides long - term archival storage for large data sets .",
    "a compute cloud is layered over the storage to provide computing cycles when required and the distribution and replication used by the storage cloud provide a natural framework for parallelism .    in this paper",
    ", we have described a high performance storage cloud called sector and a compute cloud called sphere that are designed to store large distributed data sets and to support the parallel analysis of these data sets . sector and",
    "sphere rely on specialized high performance data transport protocols such as udt that use bandwidth efficiently over wide area high bandwidth networks .",
    "we have also described two applications that use this infrastructure and shown that with wide area high performance networks and a cloud - based architecture that computing with distributed data can be done with approximately the same efficiency as computing with local data .",
    "this work was supported in part by the national science foundation through grants sci-0430781 , cns-0420847 , and aci-0325013 .",
    "robert  l. grossman . a review of some analytic architectures for high volume transaction systems . in",
    "the 5th international workshop on data mining standards , services and platforms ( dm - ssp 07 ) _ , pages 2328 .",
    "acm , 2007 .",
    "robert  l grossman , michael sabala , yunhong gu , anushka anand , matt handley , rajmonda sulo , and lee wilkinson .",
    "distributed discovery in e - science : lessons from the angle project . in _",
    "next generation data mining ( ngdm 07 ) _ , page to appear , 2008 .",
    "i.  stoica , r.  morris , d.  karger , m.  f. kaashoek , and h  balakrishnana .",
    "chord : a scalable peer to peer lookup service for internet applications . in _ proceedings of the acm sigcomm 01 _ , pages 149160 , 2001 .",
    "giancarlo fortino , wilma russo using p2p , grid and agent technologies for the development of content distribution networks future generation computer systems , volume 24 , issue 3 ( march 2008 ) , pages 180 - 190 .",
    "mustafa mat deris , jemal h. abawajy , ali mamat an efficient replicated data access approach for large - scale distributed systems future generation computer systems , volume 24 , issue 1 ( january 2008 ) , pages 1 - 9    p. trunfio , d. talia , h. papadakis , p. fragopoulou , m. mordacchini , m. pennanen , k. popov , v. vlassov , s. haridi peer - to - peer resource discovery in grids : models and systems future generation computer systems , volume 23 , issue 7 ( august 2007 ) , pages 864 - 878"
  ],
  "abstract_text": [
    "<S> we describe a cloud based infrastructure that we have developed that is optimized for wide area , high performance networks and designed to support data mining applications . </S>",
    "<S> the infrastructure consists of a storage cloud called sector and a compute cloud called sphere . </S>",
    "<S> we describe two applications that we have built using the cloud and some experimental studies . </S>"
  ]
}