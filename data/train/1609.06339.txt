{
  "article_text": [
    "categorical data analysis attracts many fields of research and applications .",
    "when applying strategies to real - world data , it seems to be the rule rather than the exception that datasets are lacking to some degree .",
    "this is usually due to under - reportings of subgroups of the population , to non - representative study participants , or miscoded observations ( see e.g. , , or , and the applications therein ) .",
    "all these scenarios have in common that they result in a somehow skewed observation distribution . a major task in applied studies",
    "is to address the data s skewness at first before proceeding with any other investigation .    the most common way to correct for such",
    "a skewness is the application of weighting factors .",
    "however , a weighted or cloned sample does not give any additional information on the underlying random mechanisms , a fact that is often ignored by practitioners .",
    "statistical methods have to incorporate the weighting step instead of treating the data clones as new and independent observations .",
    "this cloning of dependencies makes the use of weighted samples rather challenging .",
    "it can be easily seen that weighting or cloning of data can only increase the ( asymptotic ) variance of distribution estimator compared to an unweighted approach in the univariate case which is briefly discussed in section  [ 1dim ] . in the multi - dimensional case",
    "the situation is more interesting .",
    "considering a two - dimensional discrete distribution , let us assume that one marginal distribution is known .",
    "this additional information in one category is reasonable in many applications where some properties of the underlying population are detailed reported in large databases and statistical surveys , while data on other categories are collected only in specific ( and smaller ) studies . given this additional amount of information , the intriguing question is whether the standard unweighted empirical probability estimators can be improved .    in section  [ 2dim ]",
    "we will settle this question to the positive .",
    "adjusting the observed relative frequencies to the known marginal distribution , we construct an asymptotically unbiased estimator for the unknown marginal .",
    "these estimators satisfy a central limit theorem with an asymptotic covariance matrix that is smaller than the asymptotic covariance of the classical estimators ( in the sense of positive semi - definite matrices ) .",
    "the weighting is related to the iterative proportional fitting procedure by .",
    "the information theoretic gain is linked to dependence between the two marginals .",
    "it is intuitive that the weighted approach can not improve the estimator in the case of independent marginals , but whenever there is some dependence structure the proposed method profits in the asymptotic variance .",
    "a simulation study in section  [ numericals ] illustrates the finite sample performance of the proposed method .",
    "already for small sample sizes there are substantial improvements for dependent marginals . as a little price to pay , we observe a small finite sample bias .",
    "an exemplary application in accident research is investigated in section  [ applications ] .",
    "the official national statistics , as e.g. the national highway traffic safety administration for the united states or the statistisches bundesamt for germany , provide highly accurate information about the accident situation .",
    "however , the administrations usually provide only very low dimensional data . to evaluate new driver assistance systems ,",
    "the automobile producers require further information on more than one accident characteristic .",
    "therefore , they retrieve accident studies of more depth , e.g. the national automotive sampling system or the german in - depth accident study ( gidas ) . based on gidas data , we estimate the ( discretized ) distribution of the speed reduction due to collision where the estimators are adjusted for the injury severity distribution from the national statistic .",
    "section [ conclusions ] concludes our paper .",
    "all technical proofs are deferred to section  [ proofs ] .",
    "before we come to our main results in the next section , we will recall some basic facts for the simple univariate case .",
    "we observe an independent and identically distributed ( i.i.d . )",
    "sample @xmath0 stemming from a discrete probability distribution @xmath1 with @xmath2 and @xmath3 here and throughout the @xmath4 possible values , or categories , are labeled by @xmath5 without loss of generality .",
    "the aim is to estimate the probability distribution @xmath6 .",
    "the usual estimates are computed by the observed relative frequencies @xmath7 these estimators satisfy , as @xmath8 , the well - known central limit theorem @xmath9 where @xmath10 denotes weak convergence and where the asymptotic covariance matrix @xmath11 is given by @xmath12    the estimators @xmath13 , @xmath14 , can be interpreted as uniformly weighted ( or unweighted ) means of the observations . changing the weights from @xmath15 to some general weights @xmath16 , @xmath17 , with @xmath18 ,",
    "yields the more general estimators @xmath19 for which we observe a slightly different limiting result :    [ lemmaweighted ] let @xmath0 be an i.i.d .",
    "sample stemming from a discrete probability distribution @xmath1 , @xmath20 .",
    "then the estimators @xmath21 from satisfy , as @xmath8 , @xmath22 where @xmath23 is given by .",
    "the proof of the lemma is straightforward and therefore omitted .    by the cauchy - schwartz inequality we have @xmath24 and thus @xmath25 .",
    "equality holds true if and only if the weights are chosen as @xmath26 for all @xmath17 .",
    "consequently , in a univariate i.i.d . framework non - uniformly weighting of observations always leads to an increased variance and slower convergence rates resulting in wider confidence interval approximations for finite sample sizes",
    ". we should emphasize at this point that this property might change when leaving the i.i.d .",
    "framework and allow for dependencies between the observations .",
    "[ clone ] in some situations appliers prefer to use data clones instead of ( relatively ) weighted observations . this may be due to easier implementations when working with databases since it is relatively simple to copy cases .",
    "lemma [ lemmaweighted ] applies immediately to cloned data which can be seen as follows : let @xmath27 for all @xmath17 , be a deterministic sequence with @xmath28 .",
    "any observation @xmath29 may be cloned @xmath30 times such that the sample size artificially increases .",
    "the new ( cloned ) sample then reads @xmath31 , where @xmath32 for all @xmath17 .",
    "the corresponding estimator for @xmath33 is defined by @xmath34 we recover the estimators from with weights @xmath35 .",
    "since the minimum variance is obtained for non - cloned observations , i.e. @xmath36 for all @xmath17 , we conclude that cloning increases variability .",
    "the findings of the previous section directly transfer to the multivariate case .",
    "however , we will now investigate whether the situation changes if we have some extra information .",
    "considering a two - dimensional contingency table , we study the estimation of one marginal distribution , say the first , under the assumption that the the other marginal distribution , the second , is fully known .",
    "let @xmath37 be a two - dimensional sample taking values in @xmath38 for some @xmath39 and being distributed according to the law @xmath40 .",
    "the first and second marginals are denoted by @xmath41 and @xmath42 , respectively . without loss of generality",
    ", we can assume @xmath43 for all @xmath44 .",
    "the commonly used estimators for the two - dimensional probabilities @xmath45 are given by @xmath46 the resulting estimator for the first marginal distribution is then defined via @xmath47 in view of , these estimators satisfy , as @xmath8 , @xmath48 where @xmath11 is given by @xmath49    the estimators @xmath50 ignore any information on the second components of the sample . in other words ,",
    "the estimators treat the two - dimensional sample as a one - dimensional sample . in order to incorporate the additional information to our estimates , we weight the estimators @xmath51 such that the known column - wise marginal distribution of the estimators coincide with the true and known marginal distribution @xmath52 .",
    "more precisely , we introduce the weighted estimators as @xmath53 owing to the assumption @xmath43 , @xmath44 , we have @xmath54 with probability one for a sufficiently large sample size . hence , due to the above definition we indeed obtain @xmath55 for all @xmath44 .",
    "the adjusted estimators are fairly simple to implement , but they are not anymore linear in the data owing to the data dependent weights . since @xmath56 is a @xmath57-consistent estimator of @xmath58 , all @xmath59 are asymptotically unbiased .",
    "the modified contingency table reads @xmath60 where the estimates of interest are given by @xmath61    it is worth to mention that the adjusted estimators @xmath59 do not change the cross - product ratios @xmath62 by construction .",
    "these ratios describe the degree of association of a contingency table .",
    "if , for instance , all cross - product ratios in a contingency table are equal to 1 , the table yields independence of the marginals , while values close to zero or infinity describe total dependence . since the weighted estimators maintain the two - dimensional inner dependence structure for raw data , cross - product ratio - based tests , e.g. for independence ( , ) , can be applied to the modified contingency table without any restrictions and changes in interpretation .",
    "the choice of the weights is in line with a single iteration of the so - called iterative proportional fitting ( ipf ) procedure by . by taking marginal distributions of lower dimension",
    ", the ipf algorithm computes a higher dimensional distribution fulfilling the given marginal restrictions ( cf . ) .",
    "the algorithm works conditional on a specific initialization table .",
    "this situation can be interpreted as a two - dimensional sample from which both marginals are known .",
    "the procedure aims at adapting the sample characteristics to the given marginals . in the present setup",
    ", the weighted sample can be regarded as the result of a single ipf iteration such that the following considerations also hold for any iteration step of the ipf algorithm . for further details on the ipf",
    "we refer to and .",
    "intuitively , the inclusion of further information should at least not worsen the estimators features . to rigorously evaluate whether there is an improvement from the original estimators @xmath63 to the modified estimators @xmath64",
    ", we will compare their limiting variances .",
    "[ thtilde ] let @xmath65 be an i.i.d .",
    "sample of a two - dimensional distribution @xmath66 , with some @xmath39 .",
    "then the estimators @xmath67 with @xmath59 from satisfy , as @xmath8 , the limiting result @xmath68 where @xmath69 is given by @xmath70    the quite simple and explicit structure of the asymptotic variance @xmath71 is charming .",
    "it can be rigorously understood in terms of the conditional ( co-)variance .",
    "the latter is defined by @xmath72)(w-\\e[w|z])\\big|z\\big]\\ ] ] for arbitrary random variables @xmath73 and @xmath74 on the same probability space . in the following",
    ", the notation @xmath75 also is used . as verified by the following lemma",
    ", the asymptotic covariance matrix @xmath71 of the weighted estimators for the first marginal is given by the covariance of the unweighted estimators conditional on the second component .",
    "hence , we recover in the asymptotic scale that the second margin is known .",
    "[ condcov ] grant the assumption of theorem  [ thtilde ] .",
    "we then have for any @xmath76 and @xmath77 from that @xmath78.\\ ] ]    this lemma implies together with the law of total variance that for any @xmath79 @xmath80+\\operatorname{var}\\big(\\e[\\hat p_{i\\cdot}|y_1,\\dots , y_n]\\big)\\ge\\frac{\\gamma_{i , i}}{n}.\\ ] ] therefore , the asymptotic variance of the adjusted estimators @xmath81 is indeed less or equal to the asymptotic variance of the classical estimators @xmath82 .",
    "the ( asymptotic ) information theoretic gain is given by @xmath83\\big)$ ] .",
    "this fact can be generalized to the joint limit law of @xmath84 .",
    "[ thcomparison ] grant the assumptions of theorem [ thtilde ] . then the asymptotic covariance matrices @xmath23 and @xmath71 given in and , respectively , satisfy @xmath85 in the sense of positive semi - definite matrices : for any vector @xmath86 , we have @xmath87\\big)\\ge 0.\\ ] ] in particular , @xmath88 holds if and only if @xmath89 and @xmath90 are independent .",
    "corollary [ thcomparison ] shows that the modification of the estimators by the additional information on the known marginal asymptotically improves the estimation of the target marginal .",
    "it should be noted that the theory guarantees improvements for the expected loss , but for a specific sample at hand the weighting approach might be misleading .",
    "the degree of improvement depends on the degree of association of the two marginals . to be more precise ,",
    "the following bound for the overall relative variance reduction can be easily deduced from : @xmath91 on the right - hand side we recover a natural measure for dependence being the population counterpart of the well known @xmath92-test statistic .",
    "theorem [ thtilde ] and corollary [ thcomparison ] state that using the modified estimators is asymptotically advantageous over using estimators which ignore the additional information .",
    "we have seen that the degree of improvement is related to the degree of association . to study the finite sample effects",
    ", we investigate the gain of the modification by simulations in 2x2 contingency tables with fixed marginals by varying the degree of association in terms of the cross - product ratio @xmath93 and several sample sizes @xmath94 .",
    "we consider three combinations of marginals , namely @xmath95    we focus on the estimation of @xmath96 in our simulations . to compare the performance of the estimators @xmath97 and @xmath98 , we simulated for any sample size @xmath94 and any given cross - product ratio 100,000 samples from which the estimators were computed and noted . since theory has shown that the variance of @xmath97 should be larger than the variance of @xmath98",
    ", we denote the average relative proportion of the variance which is removed by the modified estimator @xmath98 .",
    "the simulation results are given in figures [ 0505]-[0208 ] .",
    "positive values in the figures indicate whenever the modification of the estimator is -on average- advantageous while negative values indicate that the modification was misleading .",
    "recall that @xmath99 corresponds to independence of the marginals , while the degree of association increases with the distance from the origin in the horizontal axis .",
    "and the cross - product ratio @xmath100 for the fixed marginals @xmath101 and @xmath102 . ]     and the cross - product ratio @xmath100 for the fixed marginals @xmath103 and @xmath104 . ]     and the cross - product ratio @xmath100 for the fixed marginals @xmath105 and @xmath104 . ]",
    "the simulation results show that for already small and moderate sample sizes the modified estimators lead to performance improvements .",
    "it seems that an exception is given in case of independent marginals . in these cases",
    "there is a very slight disadvantage for the modified estimator .",
    "this effect vanishes when the sample size increases as expected from the theory .",
    "even more important the modified estimators lead to substantial improvements when there is some degree of dependence .",
    "the assessment of the effectiveness of advanced driver assistance systems plays a crucial role in traffic accident research . for reliable analysis detailed information on the pre - crash phase of an accident",
    "has to be known to predict possible benefits of future driver assistant systems .",
    "the german in - depth accident study ( gidas ) data contains hundreds of categories which carefully have to be reported for every single accident .",
    "accidents are reported to gidas teams by police , if and only if injured participants are to be expected .",
    "this consequently leads to a substantial bias in the injury severity ( e.g , ) .",
    "collision speed or the speed reduction due to the collision , say @xmath106 , is found to be a major correlate to injury severity in traffic accidents .    in this case study",
    "we estimate the ( discretized ) distribution of @xmath106 in passenger car to passenger car collisions with two accident participants .",
    "the corresponding gidas subsample contains 8,753 cases . to address the skewness in the injury severity of the gidas sample",
    ", we queried the german national statistic of the year 2014 ( ) from which we found the true injury severity distribution for germany for these accidents ( cf .",
    "table  [ global ] ) .",
    "@xmath107 &    [ 10.0\\%]&[0.4\\%]\\\\ \\end{array}\\end{aligned}\\ ] ]    table  [ global ] can be interpreted as a known marginal distribution for the gidas sample .",
    "hence , having the two - dimensional distribution ( about the injury severity and @xmath106 ) from gidas at hand , see table  [ gidas ] , we can apply the estimation strategy as developed in section [ 2dim ] .",
    "the estimates for the distribution of @xmath106 for the purely gidas - based approach , i.e. @xmath82 , are contained in the column _ total _ of table  [ gidas ] .",
    "the national statistic - aided weighted estimators @xmath81 are given in the column _ adjusted _ besides its relative difference to the purely gidas - based estimates .",
    "@xmath108&12.0\\%&+5.06\\%\\\\ 11\\leq \\delta v \\leq 20&935&118&1&1054   & [ 32.4\\%]&33.6\\%&+3.67\\%\\\\ 21\\leq \\delta v \\leq 30&739&192&4&935        & [ 28.7\\%]&28.9\\%&+0.43\\%\\\\ 31\\leq \\delta v \\leq 40&335&154&7&496        & [ 15.2\\%]&14.7\\%&-3.49\\%\\\\ 41\\leq \\delta v \\leq 50&124&92&7&223         & [ 6.9\\%]&6.3\\%&-7.63\\%\\\\ 51\\leq \\delta v \\leq 60&41&50&6&97           & [ 3.0\\%]&2.6\\%&-12.36\\%\\\\ 61\\leq \\delta v \\leq 70&16&25&6&47           & [ 1.4\\%]&1.2\\%&-15.75\\%\\\\ 71\\leq \\delta v               & 2&21&7&30              & [ 0.9\\%]&0.7\\%&-25.89\\%\\\\",
    "\\hline \\text{total }                      & 2,538&676&40&3,254&&&\\\\                                              & [ 78.0\\%]&[20.8\\%]&[1.2\\%]&&[100\\%]&&\\\\ \\end{array}\\end{aligned}\\ ] ]    from table  [ gidas ] we see that the adapted estimates -compared to the ordinary estimates- are increased for lower collision speeds and decreased for higher collision speeds . on a relative scale ,",
    "the estimate for the highest @xmath106 interval is reduced to around three - quarters of the original estimate .",
    "this is not too surprising .",
    "it was already stated that gidas is biased towards the more severely injured traffic participants , cf . , or compare table  [ global ] to the marginal distribution in table  [ gidas ] .",
    "hence , it is to be expected that accidents with higher collision speeds which are clearly associated with more severe injuries will be down - weighted .",
    "our proposed method gives precise weights to adjust the more severely injured cases leading to the final outcome in table  [ gidas ] .",
    "the paper investigated how weighting affects the estimation of a discrete probability distribution . while for one - dimensional data relative weighting will always increase estimation variances , it has been shown that additional information on a marginal distribution in a contingency table",
    "allows for improving the estimation of another marginal if there is some degree of association between the two categories .",
    "the gain in terms of the asymptotic ( co)variance increases with the degree of dependence . for independent marginals",
    "the weighted estimators have the same asymptotic behavior as their classical unweighted counterparts .",
    "the simulations indicate a small finite sample bias , but a clear gain when the marginals are substantially associated .",
    "therefore , from theory and from the simulations perspective we suggest to use the adjusted estimators in applications whenever it can not be assumed that the marginals are independent .",
    "we are indebted to dr .",
    "mirko junge and the volkswagen ag for providing the traffic accident data and for fruitful discussions on the case study .",
    "we first note that the matrix @xmath109 can be understood as a function of all @xmath51 .",
    "since a limiting result for the joint distribution of all @xmath51 is given in , the asymptotic features of the joint distribution of the weighted estimators @xmath59 can be determined using the delta method .",
    "we define the matrices @xmath110 and calculate @xmath111 where @xmath112 represents a vector of @xmath4 repetitions of the value 1 .",
    "now interpret @xmath113 as a function in @xmath114 or equivalently @xmath115 .",
    "hence , @xmath116 can be defined by @xmath117 , @xmath118 .",
    "the entries of the associated jacobi matrix @xmath119 are computed in the sequel .    to this end , we denote by @xmath120 the matrix of zeros with a single 1 at the @xmath121-th row and @xmath122-th column .",
    "we set @xmath123 for any @xmath14 and @xmath44 and calculate the @xmath124-th column of @xmath125 at the point @xmath126 ( for brevity we write @xmath127 instead of @xmath128 ) : @xmath129 for the delta method to apply , we do not need @xmath125 at @xmath126 , but at its non - estimated target value , i.e. we require @xmath125 at @xmath130 . by the above computation",
    ", the @xmath131-th row and @xmath132-th column value is @xmath133 hence , having all derivatives at hand , the limiting covariance matrix reads @xmath134 which we can be calculated component - wise to @xmath135 +      since @xmath136 is an i.i.d .",
    "sample , it suffices to consider @xmath137 .",
    "we have for any @xmath138 @xmath139-\\e\\big[\\hat p_{k\\cdot}\\big|y_1\\big]\\e\\big[\\hat p_{l\\cdot}\\big|y_1\\big]\\\\   & = \\sum_{s=1}^j\\sum_{r=1}^j\\big(\\e\\big[\\hat p_{ks}\\hat p_{lr}\\big|y_1\\big]-\\e\\big[\\hat p_{ks}\\big|y_1\\big]\\e\\big[\\hat p_{lr}\\big|y_1\\big]\\big).\\end{aligned}\\ ] ] owing to @xmath140 , we obtain @xmath141-\\e\\big[\\mathds 1_{\\{x_1=k\\}}\\big|y_1\\big]\\e\\big[\\mathds 1_{\\{x_1=l\\}}\\big|y_1\\big]\\big)\\\\   & = \\sum_{s=1}^j\\mathds 1_{\\{y_1=s\\}}\\big(\\frac{p_{k , s}}{p_{\\cdot , s}}\\mathds 1_{k = l}-\\frac{p_{k , s}p_{l , s}}{p_{\\cdot , s}^2}\\big).\\end{aligned}\\ ] ] therefore , @xmath142   & = p_{k,\\cdot}\\mathds 1_{k = l}-\\sum_{s=1}^j\\frac{p_{k , s}p_{l , s}}{p_{\\cdot , s}}.\\end{aligned}\\ ] ] +      in view of and we have @xmath143 we thus obtain for any @xmath86 that @xmath144 in terms of the function @xmath145 the last line can be written as @xmath146 ^ 2\\big]-\\e\\big[f_c(x_1)\\big]^2\\notag\\\\   & = \\e\\big[\\e[f_c(x_1)|y_1]^2\\big]-\\e\\big[\\e[f_c(x_1)|y_1]\\big]^2\\notag\\\\   & = \\operatorname{var}(\\e[f_c(x_1)|y_1])\\label{gam - sig}\\\\   & \\ge0,\\notag\\end{aligned}\\ ] ] where equality holds if and only if the conditional expectation @xmath147 $ ] is constant for any function such function @xmath148 .",
    "it remains to verify the equivalence of @xmath88 and the independence of @xmath149 and @xmath150 .",
    "let @xmath149 and @xmath150 be independent . then @xmath151=\\e[f(x_1)]$ ] almost surely for any finite function @xmath152 .",
    "therefore , @xmath153 for any @xmath86 , due to , and thus @xmath154 .",
    "for the other direction suppose is zero for any @xmath86 and let @xmath155 and @xmath156 be arbitrary .",
    "choosing @xmath86 as the vector with 1 in the @xmath121th row and all other entries zero , we obtain @xmath157=p(x_1=i)$ ] almost surely .",
    "we conclude @xmath158\\big]=p(x_1=i)p(y_1=j)\\ ] ] for all @xmath79 and @xmath159 , i.e. , @xmath149 and @xmath150 are independent .",
    "+      deming , w.e . and stephan , f.f .",
    "( 1940 ) . on a least squares adjustment of a sampled frequency table",
    "when the expected marginal totals are known .",
    "_ the annals of mathematical statistics _ , vol . 11 , no .",
    "427 - 444 .",
    "lu , t .- h . , lee , m .- c . and",
    "chou , m .- c .",
    "( 2000 ) : accuracy of cause - of - death coding in taiwan : types of miscoding and effects on mortality statistics _ international journal of epidemiology _ ,",
    "336 - 343 .",
    "otte , d. , krettek , c. , brunner , h. and zwipp , h. ( 2003 ) : scientific approach and methodology of a new in - depth - investigation study in germany so called gidas .",
    "_ proceedings of the 18th international technical conference on the enhanced safety of vehicles _ , paper",
    "0204 , nagoya ( japan ) .",
    "pfeiffer , m. and schmidt , j. ( 2006 ) : statistical and methodological foundations of the gidas accident survey system .",
    "_ proceedings of the 2nd international conference on expert symposium on accident research _",
    ", hanover , germany , pp . 8187 .",
    "yamamoto , t. , hashiji , j. and shankar , v.n .",
    "( 2008 ) : underreporting in traffic accident data , bias in parameters and the structure of injury severity models .",
    "_ accident analysis and prevention _ , vol .",
    "1320 - 1329 ."
  ],
  "abstract_text": [
    "<S> to take sample biases and skewness in the observations in account , practitioners frequently weight their observations . considering discrete distributions </S>",
    "<S> , the present paper explores the effect of weighted data from an asymptotic point of view . </S>",
    "<S> if one marginal is known , weighted estimators for any other marginal distribution are proposed . </S>",
    "<S> these have a strictly smaller asymptotic variance whenever there there is some dependence between the two marginals . </S>",
    "<S> the finite sample performance is illustrated in a simulation study . </S>",
    "<S> an application to traffic accident data concludes the paper .    </S>",
    "<S> = cmr8 at 8 . </S>",
    "<S> truept 2u^n+12 2n+12 </S>",
    "<S> _ ht_h    </S>",
    "<S> p + r_*^+ ii ||||    [ section ] [ theorem]lemma [ theorem]corollary [ theorem]proposition    [ theorem]remark [ theorem]example [ theorem]definition    22.25 cm 17.5 cm    plus 1pt plus 2pt minus 2pt    = cmss12 = cmr7 </S>"
  ]
}