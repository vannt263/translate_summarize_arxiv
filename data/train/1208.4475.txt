{
  "article_text": [
    "while the emergence of various online social networking platforms provides a steady source of data for researchers , it also provides a source of constantly evolving complexity .",
    "most prior research has focused on analyzing various static topological properties of networks induced by social communication , while discarding the content of communication . at the same time",
    ", there is a growing recognition that a more nuanced understanding of social interactions requires analyzing the semantic content of communications .",
    "for instance , it has been suggested that linguistic cues in communicative patterns , as well as the ways individuals echo and accommodate each other s linguistic styles , can be indicative of relative social status of participants  @xcite . despite recent progress , however , content - based analysis of social interactions is still a challenging problem due to the lack of adequate quantitative methods for extracting useful signals from unstructured text .",
    "another significant hurdle is that the design and usage of social networks , and thus the interpretation of various signals , are changing over time .    here",
    "we suggest a novel , information - theoretic approach for leveraging user - generated content to characterize interactions among social media participants . specifically , given all the content generated by a set of users ( e.g. , a sequence of tweets ) , our goal is to find meaningful edges that indicate social interactions among this set of users .",
    "our approach is model - free in the sense that it does not presuppose a particular behavioral model of users and their interactions .",
    "instead , we view users as producers of some arbitrarily encoded information stream .",
    "if @xmath0 s stream has an effect on @xmath1 s , then access to @xmath0 s signal can , in principle , improve our prediction of @xmath1 s future activity .",
    "this is what we mean by a _",
    "predictive link_. we show that this general notion of predictability can be used to identify social influence .",
    "the technical approach proposed here consists of two main ingredients ( see fig .",
    "[ fig : schematic ] ) .",
    "first , we represent user - generated content in a high - dimensional space so that a sequence of user - generated posts is mapped to a time - series in this space .",
    "second , we apply information - theoretic measures to those time series to discover and quantify directed influence among the users . because our method is based on information - theoretic principles , it is easy to interpret , applicable to arbitrary signals and/or platforms , and flexible with respect to the representation of content .    , predictable from past tweets , @xmath2 ?",
    "we answer this question by first transforming the text of tweets into vectors .",
    "joint samples of these variables can be used to estimate information transfer , or transfer entropy , quantifying how predictive @xmath0 s tweets are for @xmath1 s future tweets . ]",
    "our approach ultimately reduces to calculating an information - theoretic measure called _ transfer entropy _ between pairs of stochastic processes  @xcite .",
    "intuitively , transfer entropy between processes @xmath1 and @xmath0 quantifies how much better we are able to predict the target process @xmath1 if we use the history of the process @xmath0 and @xmath1 rather than the history of @xmath1 alone . by using transfer entropy as a statistical measure of the relationship between the content of y s tweets and the content of x s subsequent tweets ,",
    "we construct a graph of _ predictive links _",
    ", based only on the content of users tweets .",
    "our results demonstrate that transfer entropy indeed reveals a variety of predictive , causal behaviors .",
    "surprisingly , we also discover that many of the most predictive links _ are not present in the social network _ , through mentions nor friend links . nevertheless , in sec .",
    "[ sec : mention ] , we verify the meaningfulness of our measure by showing that predictive links are a statistically significant predictor of mentions on twitter .",
    "to summarize , our main contribution is a novel application of an information - theoretic framework to content - based social network analysis , providing a general , flexible measure of meaningful relationships in the network .",
    "this construction is made possible by two apparently novel technical insights .",
    "( 1 ) current state - of - the - art methods for estimating entropic measures such as mutual information continue to perform well in high - dimensional spaces as long as they are effectively low - dimensional in some sense . ( 2 ) while content representations of user activity are high - dimensional , they are effectively low dimensional in the required sense . taken together , these two points allow us to successfully apply entropic estimators in a previously inaccessible regime .    after motivating our technical approach and defining the relevant information - theoretic quantities in section  [ sec : theory ] , we describe how to estimate those quantities in sec .",
    "[ sec : teestimation ] , and demonstrate their use on real - world data from twitter in sec .",
    "[ sec : results ] . finally , we give an overview of related work in sec .",
    "[ sec : related ] , followed by a discussion of results in sec .",
    "[ sec : conclusion ] .",
    "let us consider a set of users that generate a time - stamped sequence of text documents , e.g. , tweets .",
    "let x and y be two such users . with a slight misuse of notation ,",
    "let @xmath3 and @xmath4 denote the content of tweets generated by those users up to some time , in some representation .",
    "while our approach is not limited to a particular representation , below we will use @xmath3 and @xmath4 to describe topical representation of the content ( e.g. , obtained via latent dirichlet allocation , or lda ) .",
    "consider now the problem of predicting the content of the next tweet generated by x , denoted by @xmath5 ; see fig .",
    "[ fig : schematic ]",
    ". generally speaking , @xmath5 is a random variable that can depend on a large number of factors that might not be directly observable : topical interests of user x ( and her friends ) , exogenous events , and so on . here , however , we are interested in the extent to which @xmath5 is influenced by the past tweets @xmath3 and @xmath4 .",
    "namely , we would like to see how much knowing the past content generated by user y , @xmath4 , helps us to better predict @xmath5 .",
    "if knowing y s past tweets helps us to predict @xmath5 more accurately , then we can say that y exerts certain influence on x.    the notion of _ influence _ ( or _ causality _ ) described above is taken in the sense of granger causality  @xcite which demands that ( 1 ) the cause occurs before the effect ; ( 2 ) the cause contains information about the effect that is unique , and is in no other variable  @xcite . in practice , determining that information is `` in no other variable '' is difficult . for determining a causal effect on a user in a social network , we only attempt to rule out the user s recent past as an explanation .",
    "exogenous and long - term effects are difficult to account for but will be discussed in some interesting cases .",
    "the principle behind granger causality was originally applied in the context of regression models , but applying these ideas in the context of information theory leads to effective tests of causality  @xcite .",
    "we denote by @xmath6 the entropy of a random variable , @xmath1 , with some associated probability distribution , @xmath7 for @xmath8 . in this case (",
    "differential ) entropy is defined in the standard way , using the natural log , @xmath9 we sometimes speak of entropy as quantifying our `` uncertainty '' about @xmath1 .",
    "standard higher order entropies such as mutual information and conditional entropy can be defined in terms of differential entropy as @xmath10 and @xmath11 , respectively .",
    "conditional information can be interpreted as the reduction of uncertainty in @xmath1 from knowing @xmath0 .",
    "transfer entropy , or information transfer  @xcite , can be defined as , @xmath12 where @xmath13 is interpreted as information about user @xmath1 s future behavior , and @xmath14 as user @xmath1 and @xmath0 s past behavior , respectively .",
    "the temporal indices dictate that cause should come before effect , and conditioning on @xmath1 s past insures that any explanatory value from @xmath0 is not already present in @xmath1 s past behavior .",
    "the first line writes this quantity succinctly as a _",
    "conditional mutual information _ while the second line has the nice interpretation that we are interested in how much knowing @xmath15 reduces our uncertainty about @xmath13 .",
    "this quantity is asymmetric , so in principle @xmath16 .",
    "we will see examples where this is the case .    in this paper ,",
    "we take @xmath17 to be random processes representing the content of tweets for users @xmath1 and @xmath0 , and so we refer to this measure as _",
    "content transfer_. in particular , referring to fig .",
    "[ fig : schematic ] , given some concrete procedure to turn an individual tweet into a vector , @xmath18 , we consider samples , @xmath19 , of triples of tweets @xmath20 representing @xmath1 s tweet , @xmath0 s most recent previous tweet , and @xmath1 s most recent previous tweet . note that we demand that @xmath0 s tweet should occur after @xmath1 s previous tweet , otherwise the causal effect of @xmath0 s tweet is already being taken into account as affecting @xmath1 s previous tweet . also , @xmath0 could tweet many times in between @xmath1 s tweets , but we only consider the most recent tweet for simplicity .",
    "many possibilities exist to represent a tweet as a vector and in sec .",
    "[ sec : topic ] we describe some of them along with the topic model approach used in this paper .    note that we could drop the conditioning on @xmath3 to get the mutual information between @xmath1 s future and @xmath0 s past , sometimes called time - delayed or time - shifted mutual information .",
    "we will compare this simpler quantity to transfer entropy below .",
    "on the other hand , in principle , we could add even more conditioning on other variables like news stories , other users activity , @xmath21 , or more history for users @xmath1 and @xmath0 .",
    "the difficulty is in estimating these entropies from sparse data , and adding more conditions also increases the dimensionality of the problem .",
    "generally speaking , calculating entropic measures for high - dimensional random variables is problematic due to data sparsity  @xcite .",
    "rather than binning data and estimating probability distributions as a prerequisite for calculating entropy , kozachenko and leonenko  @xcite introduced an entropy estimator that was asymptotically unbiased and did not require binning of data .",
    "binless estimators were extended to higher order quantities like mutual information  @xcite , and divergence between two distributions  @xcite . below we make use of a generalization of the approach that allows binless estimation of the more nuanced transfer entropy  @xcite .",
    "the basic idea behind non - parametric binless entropy estimators is to average local contributions to the entropy in the neighborhood of each point , where the neighborhood size is chosen adaptively according to the point s @xmath22 nearest neighbors .",
    "the neighborhood shrinks as we add more data , improving the estimate .",
    "the fundamental strength of this approach comes from the fact that it is easier to locally estimate entropy than to locally estimate a probability density ; mathematically , the equivalent local density estimators are not consistent while the entropy estimators are consistent  @xcite . for fixed @xmath22 , various entropy estimators",
    "have been shown to be asymptotically unbiased and consistent under only mild assumptions  @xcite .",
    "generally , suppose we have samples @xmath23 of points",
    "@xmath24 drawn from some unknown joint distribution .",
    "for each point , @xmath25 , we construct the random variable @xmath26 , representing the distance to the @xmath22-th nearest neighbor in the joint @xmath27-@xmath28 space according to some metric .",
    "we will use the maximum norm in all dimensions following previous work  @xcite .",
    "for instance , the distance between points @xmath25 and @xmath29 in the joint space would be @xmath30 where @xmath31 and @xmath32 are the dimensions of the @xmath27 and @xmath28 spaces , respectively .",
    "if we project only onto the @xmath27 ( or @xmath28 ) subspace , the number of points strictly within a distance @xmath26 is defined as @xmath33 ( or @xmath34 )",
    ". we can now proceed to write down the kraskov mutual information estimator  @xcite .",
    "@xmath35 here , @xmath36 is the digamma function . note that this simple expression depends only on distances between samples , and does not depend on the dimension of the space .",
    "the kraskov estimator has been extended to conditional mutual information(cmi )  @xcite .",
    "now we add a third covarying vector , @xmath37 , and define @xmath26 as the distance to the @xmath22-th nearest neighbor in the full joint @xmath27-@xmath28-@xmath38 space , while @xmath39 , for instance , represents the number of points strictly within a distance @xmath26 projecting onto the @xmath28-@xmath38 subspace . @xmath40",
    "these two estimators can interpreted as estimators of time - delayed mutual information and transfer entropy , respectively , through appropriate choice of @xmath41 . note that because transfer entropy ( and mutual information ) estimators are an average over all samples , we can easily determine the contribution of one sample to the estimated entropy .",
    "@xmath42 we refer to this quantity as _ local transfer entropy _ and note its similarity to a previously introduced measure  @xcite . in principle , not only can we identify a pair of users , @xmath43 , so that @xmath0 has high content transfer towards @xmath1 , we can also order their tweet exchanges to see which ones contribute most to that assessment .",
    "an example is shown in table [ tab : lcmi ] in sec .",
    "[ sec : full ] .",
    "although entropy estimators have many nice theoretical properties in the asymptotic limit , for finite sample sizes we must ultimately rely on empirical results .",
    "many papers have reported impressive empirical results from these entropy estimators already  @xcite , so we will explore only one unusual feature of our problem , with surprising results .",
    "note that the estimators in eq .",
    "[ eq : mi ] and [ eq : cmi ] , do not explicitly rely on the dimension .",
    "in fact , they only rely on the vectors themselves through a distance function . therefore",
    ", adding extra dimensions to a vector that are constant will have no effect on the distance function or the estimator .",
    "i.e. , we would be transforming the vectors @xmath44 , @xmath45 where the @xmath46 are arbitrary constants ( that is , they are the same for each point @xmath25 ) . clearly , the distances are unchanged , @xmath47 ( similarly in the joint @xmath18-@xmath48-@xmath37 space ) , and this is all that is relevant for the estimators in eq .",
    "[ eq : mi ] and [ eq : cmi ] . the question we explore in fig .",
    "[ fig : test ] is the effect of adding extra dimensions which are only nearly constant .",
    "the intuition for exploring this scenario is that vectors that represent content should be high dimensional , but we expect most individual users to participate in only a small subset of the full content space ( we make this intuition concrete in fig .  [",
    "fig : ntopics ] in sec .",
    "[ sec : topic ] ) .",
    "can we expect entropy estimators to work in this case ?",
    "we start by considering a situation in which we can calculate conditional mutual information(cmi ) analytically . as an example",
    ", we consider a gaussian where @xmath49 , and we take @xmath1 and @xmath0 to be strongly correlated , while @xmath50 and @xmath51 are weakly correlated . for illustration purposes , we consider the following covariance matrix .",
    "@xmath52 in this case , @xmath53 , while @xmath54 .",
    "because @xmath55 is correlated with @xmath0 , conditioning on it reduces some of @xmath0 s usefulness for predicting @xmath1 . in fig .",
    "[ converge ] , we attempt to estimate this entropy from random samples .",
    "we show the mean of the estimator over many trials(circles ) , along with the @xmath56 confidence intervals . for comparison",
    ", we apply the estimator to samples where the sample indices of the @xmath28 and @xmath38 components are randomly permuted and it converges quickly to zero(squares ) .    what happens if we now take @xmath57 ?",
    "we will let @xmath58 be drawn from the same low - dimensional distribution above , but all the other components of the vector will be uncorrelated gaussian noise with standard deviation @xmath59 .",
    "the mi and cmi should be unchanged .",
    "now we are estimating cmi in a 450 dimensional space with fewer than 400 samples .",
    "surprisingly , the estimator still works well , only slightly underestimating the true cmi .",
    "if we had increased the standard deviation of the noise , eventually the signal would have been lost and the estimator would converge to 0 .    in fig .",
    "[ converge2 ] , we look at the convergence of the estimator for examples from pairs of users on twitter ( details in the sec .  [",
    "sec : results ] ) .",
    "first , we consider a very strong signal corresponding to the edge @xmath60 discussed later ( circles ) .",
    "the estimate increases relatively quickly so that it must be continued in the inset .",
    "we consider two null hypotheses as comparisons .",
    "first , we permute the order of tweets for @xmath61 and calculate content transfer(squares ) .",
    "second , we construct two twitter streams from random tweets in our dataset , and we estimate the content transfer ( diamonds ) . finally , we calculate content transfer for the user pair @xmath62 from sec .  [",
    "sec : mention ] , which represents more social behavior ( triangles ) .",
    "note that the estimator in this case is quite noisy , and we do not expect perfect discrimination of the signal with so little data .",
    "there are several details to be considered before implementing the estimators above .",
    "first of all , we are required to find the @xmath22-nearest neighbors to each point , but how should we choose @xmath22 ?",
    "smaller @xmath22 reduces the bias , but larger @xmath22 reduces the variance  @xcite .",
    "we find the results are not very sensitive to @xmath22 .",
    "we use @xmath63 as suggested by kraskov et al .",
    "@xcite and this choice is confirmed by numerical results shown in the inset of fig .",
    "[ fig : mentions ] . to avoid situations where two points are exactly the same distance away",
    ", we also add low intensity ( @xmath64 ) noise to the data  @xcite .",
    "the most intensive part of the calculation is the search for nearest neighbors . in high dimensions , as is the case in this paper , this can not be sped up much beyond @xmath65 for @xmath66 samples .",
    "however , we can fix some constant @xmath67 , and only make estimates using samples of this fixed size .",
    "besides bounding the computational complexity , if we average over multiple samples we can also reduce the variance . for @xmath66 samples of tweet exchanges , we take @xmath68 random subsets of size @xmath67 .",
    "we set @xmath69 ( which will be the minimum sample size we keep in our data , discussed in sec .",
    "[ sec : results ] ) .",
    "this also insures that any bias from finite sample size will affect all edges equally .",
    "because we attempt to evaluate transfer entropy between all of the millions of user pairs ( only some of which have the minimum number of samples ) , we had to split our calculation over many processors .",
    "we will apply the entropy estimators to real world data from twitter . after describing the dataset",
    ", we will discuss options for representing tweet text as vectors . in sec .",
    "[ sec : full ] , we will examine the directional links with the highest content transfer on the entire dataset .",
    "although we lack a ground truth to validate our results , in sec .",
    "[ sec : mention ] we consider activity of a subset of users for whom mentions can be used to test the significance of content transfer .",
    "we make use of data originally collected and described in @xcite .",
    "all tweets are collected for a set of 2400 users over a one month period from 9/20/201010/20/2010 .",
    "the set of users was picked by starting with a small , random initial set and constructing a snowball sample using mentions and re - tweets .",
    "the dataset was constrained to users who self - reported in their profile a location in the middle east .",
    "the dataset also contained sampled tweets from tens of thousands of other users who mentioned users in the original set .",
    "we used those tweets to help train the topic model ( giving a total of over half a million tweets after preprocessing described in the next section ) , but we did not consider those users when calculating content transfer for pairs of users . after eliminating users with less than 100 tweets , we considered all possible directed edges among the remaining 770 users . note that not all ordered pairs of users had at least 100 tweet triples as defined in sec .",
    "[ sec : preliminaries ] in which case content transfer was not calculated .",
    "a crucial ingredient in our attempt to apply information - theoretic measures to social media is a way to represent content as vectors .",
    "luckily , a great deal of work has been done on mathematical representations of content , a few examples are discussed in sec .",
    "[ sec : related ] .",
    "the richness of our results are ultimately limited by the quality of content representation .",
    "on the other hand , higher dimensional representations make entropy estimation more difficult .",
    "compounding this difficulty , social media presents some unique challenges .",
    "for instance , on twitter , messages are very short ( 140 characters ) , providing little context to determine what a tweet is about . the use of `` netspeak '' , emoticons , and abbreviations challenge traditional models of communication .",
    "many languages are represented , sometimes mixed within a single tweet .",
    "spelling mistakes and urls multiply the number of unique tokens . on the other hand",
    ", the sheer volume of data provides an advantage that outweighs these difficulties .    ultimately , we chose to use topic models to represent tweets because of convenient off - the - shelf implementations@xcite , and a growing body of work exploring their applicability to twitter@xcite .",
    "our purpose in using a topic model differs from standard aims .",
    "in particular , our ultimate goal is not to find distinct topics with clear interpretations , but to find the minimal representation that preserves relevant detail . for our experiments , we trained an lda topic model implemented in _ gensim_@xcite . for pre - processing the text , we followed most of the prescriptions in @xcite .",
    "( 1 ) we replace all urls with the word `` [ url ] '' .",
    "( 2 ) we replace all words starting with `` @ '' with the word `` [ mention ] '' ( 3 ) we remove all non - latin alphabet characters and convert to lower - case . ( 4 ) we removed a standard list of english stop - words . because we will use mentions later in our validation , step ( 2 ) is particularly important to insure that our topic model has not learned name associations .",
    "we also removed all tweets that begin `` rt @ '' ( re - tweets ) , since this type of information diffusion has been well - studied , as discussed in sec .",
    "[ sec : related ] .     tweets . for each component of the @xmath70 dimensional topic vector",
    ", we calculate the standard deviation over all tweets from one user .",
    "if the standard deviation is greater than @xmath59 , we say that topic dimension is `` active '' for that user . ]",
    "next , we constructed a bag - of - words vector representation with the remaining words in the dataset that appeared more than once .",
    "each component of the vector represents the frequency with which one of these words occurred in a given tweet .",
    "these vectors were transformed using the tf - idf score .",
    "times it is transformed to @xmath71 , where @xmath72 represents the number of documents and @xmath73 represents the number of documents containing the term . ]",
    "finally , we used the tf - idf vectors to learn an lda topic model .",
    "we tried topic models with 10 , 50 , 100 , 125 , 150 , 175 , and 200 topics .",
    "at first , we assumed that the lower dimensional topic models , while being worse representations of the text , would be more amenable to entropy estimators .",
    "however , larger topic models actually fared much better , despite the high dimensionality of the vectors .",
    "one reason for this surprising result is that the effective dimensionality of most twitter users is far smaller than the dimensionality of the topic vector . to verify this , we considered all the users in our dataset with at least 100 tweets . for each component of the topic vector , we calculated the standard deviation over all tweets for one user .",
    "we define the number of `` active topics '' as those for which the standard deviation was over 0.05 .",
    "although this notion does not conform to a standard intuition about what should be considered an `` active topic '' , it does describe what is relevant for entropy estimation , as discussed in sec .",
    "[ sec : convergence ] . the result",
    "is shown in fig .",
    "[ fig : ntopics ] for a topic model with 150 topics .",
    "the dynamics of most users are constrained to a handful of dimensions .",
    "the fact that the active topics may differ for different users is irrelevant for the purpose of entropy estimation .",
    "we begin by calculating content transfer for all ordered pairs of users with sufficient samples . unless otherwise specified , we use @xmath74 in the following examples , although the high content transfer edges were insensitive to this choice .",
    "looking at the histogram of content transfer for all edges in fig .",
    "[ fig : tehistogram ] , we note that there are a few obvious outliers .",
    "we also show the network consisting of only these high content transfer edges , with account names abbreviated .",
    "inspection of the tweets reveal that these links are all strongly predictive , we proceed to give several examples .",
    "we start with the edge @xmath75 with sample tweets shown in table [ tab : lcmi ] and point out some things notably lacking .",
    "for these two users there are no friend links , no mentions , no retweets , no matching urls ( though the shortened urls point to the same stories ) , and no matching hash tags .",
    "nevertheless , even though the text is altered , content transfer recognizes that @xmath76 s tweets are identical in content to @xmath77 s tweets .",
    "we use the local transfer entropy from eq .",
    "[ eq : lcmi ] to order the 288 tweet exchanges .",
    "we also read through all the tweet exchanges and hand labeled 228 instances in which the two users tweets clearly referred to the same story .",
    "the probability that the local transfer entropy was higher for a tweet exchange which was a duplicate than for a non - duplicate one was 0.68 .",
    "we also note the asymmetry of this edge : the content transfer from @xmath75 is @xmath78 while in the other direction it is only @xmath79 . this asymmetry is often taken to suggest a causal connection@xcite .",
    "nevertheless , there remains the possibility of an external , mutual cause .",
    "the impossibility of ruling out such alternatives is one reason we emphasize the interpretation of content transfer as a measure of predictability .",
    "of course , this is a well - known caveat regarding granger causality .",
    "a simple explanation in this case is that both accounts simply read and post from the same news site .",
    "however , in that case we would expect the order of tweets to sometimes be reversed , causing the transfer entropy to be more symmetric .",
    "in fact , the order of tweets is always preserved .",
    "a more nuanced alternative is that one of the users is temporally `` closer '' to the news source .",
    "e.g. , a service like `` twitterfeed.com '' can automatically post news stories to your twitter account the instant they are published .    as opposed to the previous example",
    ", the @xmath80 cluster contains some bi - directed edges .",
    "in this case , the users are all following each other , however , once again , no retweets or mentions are used .",
    "the tweets revolve around sports and some samples are shown in table [ tab : sports ] .",
    "the tweets are clearly all copies of each other . confirming the previous intuition about temporal ordering , the bi - directed edges are duplicates that occur in arbitrary order , while the directed edge away from @xmath80 is reflected by the fact that all posts appear first on that account .",
    "the account @xmath81 appears to be a personal account that occasionally included unrelated tweets .",
    "the profile of that account describes the author as a `` sports analyst . ''",
    "the remaining clusters in fig .  [ fig : tehistogram ] have similar easy qualitative interpretations .",
    "the @xmath82 cluster users post identical israeli news stories .",
    "the remaining edges of the largest cluster also revolve around news , mostly of stories in the middle east .",
    "the profile of @xmath83 lists itself as the twitter stream of a tech news site , while the profile of @xmath84 lists itself as the founder of the same website .",
    "tweets are copied in arbitrary order , leading to symmetric content transfer .",
    "the edge @xmath85 has a similar interpretation , with @xmath86 s profile declaring himself a radio presenter for the internet radio station represented by account @xmath87 .",
    "again , no mention or follower edges are declared .",
    "we also calculated the time - delayed mutual information for all pairs of users .",
    "in general , this quantity was correlated with the content transfer ( see fig .",
    "[ fig : mentions ] ) .",
    "however , there were several examples where mutual information was high while content transfer was low .",
    "the intuition behind this phenomena is expressed in fig .",
    "[ fig : cmi_v_mi ] . to use a concrete example from the dataset",
    ", we have user y repeatedly tweeting the same message ` # shoutout for floods in # pakistan # pkfloods [ url ] ` , which we can imagine as a red line in the picture .",
    "at some point , user y switches to repeatedly tweeting a new message ` # teamfollow 100 free more twitter followers !",
    "[ url ] ` ( blue lines ) .",
    "coincidentally , at nearly the same time user x switches from repeatedly tweeting ` in my view : how to explode resources to earn foreign exchange [ url ] ` ( green lines ) to ` in my view : pakistan on the shoulders of n.r.o beneficiaries [ url ] ` , and this user was an example that had a high score for this measure .",
    "basically , the user tweets many different story titles , but repeats each one dozens of times . ]",
    "( grey lines ) . from looking at the figure",
    ", you can see that a red line for user y is quite predictive of a subsequent green line for user x , and this is reflected in the high mutual information . on the other hand ,",
    "if you condition on user x s past , you can easily predict that a green line is most likely followed by another green line , and seeing a red line from user y does not improve that prediction .",
    "therefore , transfer entropy is low in this scenario .",
    ".tweet exchanges between two users with high content transfer from @xmath75 .",
    "examples were picked which have high and low local transfer entropy .",
    "[ cols= \" < , < , < \" , ]",
    "much research has focused on characterizing and identifying influential users that can facilitate information diffusion along social links .",
    "researchers have suggested different characterizations of influentials based on various network centrality measures  @xcite . for twitter data , various influence measures include number of followers , mentions , retweets  @xcite , pagerank of follower network  @xcite , size of the information cascades  @xcite .",
    "more recent work has attempted to utilize temporal information through the influence ",
    "passivity score  @xcite , and transfer entropy  @xcite .",
    "none of those measures , however , take content into account .",
    "more recently , several authors have suggested topic - sensitive influence measures such as twitterrank  @xcite , which takes into account topical similarity among the users .",
    "topic - specific re - tweeting behavior was examined in  @xcite .",
    "more generally , there is an increasing trend to use communication content for inferring the nature of relationships between users  @xcite .",
    "an interesting line of research grounded in psycholinguistic theory of communication have studied the convergence of communicative behavior among twitter users  @xcite . in particular",
    ", it has been suggested that conversational behavior can be indicative of relative social status of participants , and subtle language - based signals can be used to infer power relationships among the users  @xcite .",
    "similar to our work , those approaches too work by projecting unstructured user - generated text onto a multivariate time series , in their case using liwc categories  @xcite rather than lda - induced topics . however , the influence measures suggested in  @xcite are defined in a rather _ ad hoc _ manner , as opposed to a more fundamental entropic measure used here .",
    "we believe that our approach based on transfer entropy provides a more principled measure of directed influence .",
    "a crucial component of our approach is based on the ability to estimate entropic quantities for very - high - dimensional random variables . due to data sparsity ,",
    "naive methods based on _ binning _ are not feasible .",
    "the binless approach for entropy estimation introduced in  @xcite has been used for quantifying information in neural spike trains  @xcite .",
    "the binless approach has been extended for estimating higher order entropic quantities such as mutual information  @xcite , divergences between two distributions  @xcite , and transfer entropy  @xcite .",
    "we also note that a linear version of the transfer entropy known as granger causality  @xcite has been used recently for uncovering predictive causal relationships in neuroscience  @xcite , genetics  @xcite , climate modeling  @xcite and various other applications .",
    "we have seen that using content transfer as a general , statistical measure of predictivity captures a wide variety of nontrivial behavior on twitter .",
    "information - theoretic techniques provide powerful , flexible tools for discovering patterns in data , but typically are impractical to implement .",
    "surprisingly , non - parametric entropy estimation was quite effective on a dataset that would be considered small by recent research standards .",
    "this is despite the fine - grain application of these entropic measures to individual user pairs .",
    "extraordinarily , table  [ tab : lcmi ] suggests the measure may even provide a meaningful signal at the level of individual tweets .",
    "the strongest , most predictive signals discovered in sec .  [ sec : full ] were all characterized by some type of news dissemination .",
    "most interesting about these results were how many of the links appeared to be purposely hidden in the explicit follower graph .",
    "if news dissemination is for the purpose of promoting your internet radio station , as in the @xmath88 example , it may be advantageous for the accounts promoting your web site to appear as independent as possible .",
    "indeed , twitter terms of usage prohibit automatic re - tweets , so if you are copying content on multiple accounts , it would be a mistake to call attention to the practice by using re - tweets .",
    "ironically , for these purposes it may be advantageous to hide the truly influential edges , while at the same time it is advantageous to accrue as many followers as possible to appear influential , even if most of these followers are dummy accounts that are not influenced at all .",
    "we also found a statistically significant result in sec .",
    "[ sec : mention ] for distinguishing `` social influence '' , i.e. , one user eliciting a response in another .",
    "the evaluation task we performed is akin to hearing hundreds of people talking at once and inferring who is talking to whom , just by the content of their statements and without reference to any explicitly declared relationships . while the data were not sufficient to distinguish an arbitrary social tie , on average edges identified with mentions had a higher content transfer and this effect was over four standard deviations from the null hypothesis .",
    "one of the top examples corresponded to an intuitive notion of social influence , revolving around political discussion , but the strongest signals were for multi - lingual users . responding in - kind to a certain language is a relatively easy signal to identify , at least within a topic model representation .",
    "we can see from fig .",
    "[ fig : test ] that to distinguish independent signals from correlated ones with transfer entropy requires either a strong signal or more data .",
    "it would be interesting to see what types of social influence are detected with even an order of magnitude more data , which is still many orders of magnitude away from the amount of data regularly processed by companies like twitter and facebook .",
    "a subtle point about our measure of content transfer is that at no point are @xmath0 s tweets directly compared to @xmath1 s tweets .",
    "rather , the measure checks if @xmath1 s future content varies in a predictable way based on @xmath0 s past content .",
    "while this distinction may be overly general for the purpose of discovering connections from what topics are being discussed , it may be relevant for more subtle social cues .",
    "for instance , whenever @xmath0 makes an aggressive statement , if @xmath1 always responds submissively , this is a predictable , but not matching , response . to capture this type of scenario",
    "would require content representation that includes things like stance , attitude , or sentiment , as discussed in sec .",
    "[ sec : related ] .",
    "social media is in a state of constant growth and change .",
    "subtle changes in the mechanisms that underly social media platforms can have dramatic effects on the user behavior  @xcite .",
    "results based on detailed modeling of hash tags , mentions , or re - tweets may not be relevant for the next generation of social media .",
    "on the other hand , a measure based on information - theoretic principles will remain relevant for any communication medium . on a more practical note , by providing a model - free way to discover unexpected relationships in data ,",
    "information - theoretic analysis is an effective tool for data exploration .",
    "we would like to thank sofus macskassy for providing data and valuable comments .",
    "we also thank kristina lerman and jaebong yoo for useful discussions .",
    "gv would like to thank larc , smu for their hospitality while finishing this work .",
    "this research was supported by darpa grant no .",
    "w911nf1210034 , afosr muri grant no .",
    "fa9550 - 10 - 1 - 0569 , and afosr award fa9550 - 11 - 1 - 0417 .",
    "e.  bakshy , j.  m. hofman , w.  a. mason , and d.  j. watts .",
    "everyone s an influencer : quantifying influence on twitter . in _ proc .",
    "fourth acm international conference on web search and data mining _ , wsdm 11 , pages 6574 , new york , ny , usa , 2011 .",
    "p.  bramsen , m.  escobar - molano , a.  patel , and r.  alonso . extracting social power relationships from natural language . in _ proceedings of the 49th annual meeting of the association for computational linguistics :",
    "human language technologies - volume 1 _ , pages 773782 , stroudsburg , pa , usa , 2011 .",
    "m.  cha , h.  haddadi , f.  benevenuto , and k.  p. gummadi . measuring user influence in twitter : the million follower fallacy . in _",
    "icwsm-10 : proceedings of international aaai conference on weblogs and social _ , 2010 .",
    "c.  danescu - niculescu - mizil , m.  gamon , and s.  dumais .",
    "mark my words !",
    ": linguistic style accommodation in social media . in _ proceedings of the 20th international conference on world wide web _ , www 11 , pages 745754 , new york , ny , usa , 2011 .",
    "acm .    c.  danescu - niculescu - mizil , l.  lee , b.  pang , and j.  kleinberg .",
    "echoes of power : language effects and power differences in social interaction . in _ proceedings of the 21st international conference on world wide web _ , www 12 , pages 699708 , new york , ny , usa , 2012 .",
    "c.  p. diehl , g.  namata , and l.  getoor .",
    "relationship identification for social network discovery . in _ proceedings of the 22nd national conference on artificial intelligence - volume 1 _ , aaai07 , pages 546552 .",
    "aaai press , 2007 .",
    "e.  gilbert and k.  karahalios . predicting tie strength with social media . in _ proceedings of the 27th international conference on human factors in computing systems",
    "_ , chi 09 , pages 211220 , new york , ny , usa , 2009 .",
    "acm .",
    "m.  kamiski , m.  ding , w.  a. truccolo , and s.  l. bressler .",
    "evaluating causal relations in neural systems : granger causality , directed transfer function and statistical assessment of significance .",
    ", 85(2):145157 , aug .",
    "2001 .",
    "h.  kwak , c.  lee , h.  park , and s.  moon .",
    "what is twitter , a social network or a news media ? in _ proceedings of the 19th international conference on world wide web _ , www 10 , pages 591600 , new york , ny , usa , 2010 .",
    "acm .",
    "a.  c. lozano , h.  li , a.  niculescu - mizil , y.  liu , c.  perlich , j.  hosking , and n.  abe .",
    "spatial - temporal causal modeling for climate change attribution . in _ proceedings of the 15th acm sigkdd _ , kdd 09 , new york , ny , usa , 2009 .",
    "acm .",
    "j.  weng , e .-",
    "lim , j.  jiang , and q.  he .",
    "twitterrank : finding topic - sensitive influential twitterers . in _",
    "proceedings of the third acm international conference on web search and data mining _ , wsdm 10 , pages 261270 , new york , ny , usa , 2010 ."
  ],
  "abstract_text": [
    "<S> the fundamental building block of social influence is for one person to elicit a response in another . </S>",
    "<S> researchers measuring a `` response '' in social media typically depend either on detailed models of human behavior or on platform - specific cues such as re - tweets , hash tags , urls , or mentions . </S>",
    "<S> most content on social networks is difficult to model because the modes and motivation of human expression are diverse and incompletely understood . </S>",
    "<S> we introduce _ content transfer _ , an information - theoretic measure with a predictive interpretation that directly quantifies the strength of the effect of one user s content on another s in a model - free way . estimating this measure is made possible by combining recent advances in non - parametric entropy estimation with increasingly sophisticated tools for content representation . </S>",
    "<S> we demonstrate on twitter data collected for thousands of users that content transfer is able to capture non - trivial , predictive relationships even for pairs of users not linked in the follower or mention graph . </S>",
    "<S> we suggest that this measure makes large quantities of previously under - utilized social media content accessible to rigorous statistical causal analysis . </S>"
  ]
}