{
  "article_text": [
    "the extraction of information from cosmic microwave background ( cmb ) anisotropies is a classic problem of model testing and parameter estimation , the goals being to constrain the parameters of an assumed model and to decide if the _ best  fit model _ ( parameter values ) is indeed a good description of the data .",
    "maximum likelihood is often used as the method of parameter estimation . within the context of the class of models to be examined ,",
    "the probability distribution of the data is maximized as a function of the model parameters , given the actual , observed data set .",
    "this is the same as a baysian analysis with uniform priors .",
    "once found , the best model must then be judged on its ability to account for the data , which requires the construction of a _ statistic _ quantifying the _ goodness  of  fit _ ( gof ) .",
    "finally , if the model is retained as a good fit , one defines _ confidence _",
    "intervals on the parameter estimation .",
    "the exact meaning of these confidence intervals depends heavily on the method used to construct them , but the desire is always the same  one wishes to quantify the ` ability ' of other parameters to explain the data ( or not ) as well as the best fit values .",
    "data on the cmb consists of sky brightness measurements , usually given in terms of equivalent temperature .",
    "an experiment may produce a true map , for example , the cobe maps , or a set of temperature differences , such as published by the saskatoon experiment .",
    "the likelihood function is to be constructed using these pixel values .",
    "standard inflationary scenarios predict _ gaussian _ sky fluctuations , which implies that the pixels should be modeled as random variables following a multivariate normal distribution , with covariance matrix given as a function of the model parameters ( in addition to a noise term ) .",
    "it is important to note that , since the parameters enter through the covariance matrix , and not as some linear combination of pixel values , _ the likelihood function is * not * gaussian_.    although it would seem straightforward to estimate model parameters directly with the likelihood function , in practice the procedure is considerably complicated by the complexity of the model calculations and by the size of the data sets ( bond et al .",
    "1998 , 2000 ; borrill 1999ab ; kogut 1999 ) .",
    "maps consisting of several tens of thousands of pixels ( the present situation ) are extremely cumbersome to manipulate , and the million  pixel maps expected from map and planck can not be analyzed by this method in any practical way .",
    "an alternative is to first estimate the angular power spectrum from the pixel data and then work with this reduced set of numbers . for gaussian fluctuations ,",
    "there is in principle no loss of information .",
    "because of the large reduction of the data ensemble to be manipulated , the tactic has been referred to as `` radical compression '' ( bond et al .",
    "the power spectrum has in fact become the standard way of reporting cmb results ; it is the best visual way to understand the data , and in any case it is what is actually calculated in the models .",
    "the critical issues are then how to best go from the pixel representation to the power spectrum , and how to correctly use the power spectrum for parameter estimation and model evaluation .",
    "consider the former issue . because any given experiment has only limited spatial frequency resolution , due to incomplete sky coverage",
    ", one may only obtain the signal power over a finite range ( or band ) of multipoles .",
    "extraction of this power is itself a question of parameter estimation , where the parameter is simply the _ band ",
    "power_. band ",
    "powers are thus themselves commonly found by using the likelihood . for first generation experiments , band  powers and their uncertainties",
    "can be found by completely mapping  out the band  power likelihood function .",
    "the large data sets from , for example , boomerang ( de bernardis et al . 2000 ) and maxima ( hanany et al .",
    "2000 ) , preclude this possibility and require approximate likelihood methods : for instance , one first determines the best ",
    "powers by just finding the maximum of the likelihood function ; the shape of the likelihood around the maximum is then modeled with a well  motivated but approximate expression ( bond et al .",
    "2000 ) .",
    "consider now the second issue .",
    "almost without exception , present efforts to constrain cosmological parameters use these band  power estimates as their starting point .",
    "in addition , many employ a simple @xmath0 minimization over the power points with the supplied ` error bars ' .",
    "there are two relevant remarks to make : firstly , the @xmath0 method is not appropriate for the task because band  power estimates do not represent gaussian distributed data .",
    "secondly , the ` error bars ' are most often defined in a baysian fashion by treating the band  power likelihood function as a probability distribution ; these do not necessarily represent the error distribution of the power estimator ( defined as the expression maximizing the likelihood ) that is required by the @xmath0 method , and which a frequentist would argue must be found by simulation .",
    "these comments motivate a more in depth consideration of the general problem of parameter estimation using band  powers .",
    "some authors have attempted to construct simple approximations to the band  power likelihood function that only require limited information , such as the best power estimate and associated baysian confidence limits ( bartlett et al .",
    "2000 , bond et al .",
    "2000 , wandelt et al . 2000 ) .",
    "a likelihood analysis over physical parameters ( e.g. , @xmath2 ) then follows by inserting the model dependence of the band ",
    "power into the approximate function .",
    "this kind of approach has a two  fold use : firstly , it permits one to analyze the ensemble of first generation data ( e.g. , le dour et al . 2000 ) , and secondly , it permits one to analyze larger data sets by just finding the best fit band  powers ( e.g. , jaffe et al .",
    "2000 ) . beyond the question of the accuracy of the approximation",
    ", one may worry that perhaps the whole approach is insufficient  that , even with the exact band ",
    "power likelihood function , the parameter constraints would not correspond to the more complete likelihood analysis using the entire pixel set .",
    "the fact that in principle the power spectrum contains the same information as the sky temperatures ( at least for gaussian fluctuations ) does not guarantee that band ",
    "powers do as well ; this depends on their definition , which usually adopts a certain spectral form . the common _ flat band ",
    "powers _ are defined by the assumption of a flat spectrum over the band .",
    "this may lead to a concern that important information on the slope of the spectrum is lost , a perhaps extremely relevant issue around the doppler peaks .",
    "the goal of this _ paper _ is to examine some of these questions by performing a complete likelihood analysis ( in pixel space ) of a subset of present cmb data ; in particular , we study the information content of flat band  power compression and the validity of likelihood approximations .",
    "the data subset consists of the cobe , saskatoon ( cap ) and max experimental results .",
    "taken together , they cover a wide range of angular scales , including the region of the first ( so  called ) doppler peak predicted by inflation models , and thereby allow non  trivial parameter constraints to be established .",
    "our complete analysis permits us to evaluate the performance of power  plane methods , such as @xmath0 minimization and the recently proposed band  power likelihood approximations ( bartlett et al . 2000 , bond et al .",
    "2000 , wandelt et al .",
    "we find that the @xmath0 approach is overly sensitive to outliers because of its incorrect assumption of normal distributions ; we shall see an example where this leads to a bias in the deduced best ",
    "fit model parameters .",
    "the approximate methods perform better , but even here we find some significant differences with the full analysis .",
    "these differences remain even if we simply interpolate the band  power likelihood functions , something that leads us to discover that the data set is not fully described by just its set of band  powers .",
    "the experiments are in fact individually somewhat sensitive to the shape of the spectrum , and the power estimates therefore depend on more than just the total in  band power . in most cases the experimental power is adequately modeled as a function of the normalization and local slope of the spectrum .    finally , we address the commonly neglected issue of the goodness of fit  ( gof)of the best model .",
    "we demonstrate that the best ",
    "fit model to this data set is indeed a _ good _ fit .",
    "this may also be interpreted as saying that our goodness of fit   statistic is consistent with gaussian temperature fluctuations .",
    "the common approach to cmb data analysis is through the likelihood function , @xmath3 . given a set of pixels , this function relates the prediction of a particular model to observations , taking into account , for example , the effects of beam smearing and the observing strategy .",
    "we will analyze in this section three experiments within the likelihood framework : max ( clapp et al .",
    "1994 , tanaka et al .",
    "1996 , ganga et al .",
    "1998 ) , saskatoon ( netterfield et al . 1997 ) and the cobe 4year maps ( bennett et al 1996 ) .",
    "each presents a different type of observing strategy .",
    "these three experiments are sensitive to different angular scales - schematically cobe provides information on the amplitude of the power spectrum , while max and saskatoon tell us about the position and height of the first acoustic peak .",
    "they hence prove quite complimentary in a likelihood analysis on cosmological parameters .",
    "the results of such an analysis for open inflationary models are given at the end of this section .",
    "they will subsequently be used as a benchmark against which we will be able to test various approximate methods .",
    "temperature fluctuations of the cmb are described by a random field in two dimensions : @xmath4 , where @xmath5 refers to the temperature of the background and @xmath6 is a unit vector on the sphere .",
    "it is usual to expand this field using spherical harmonics : @xmath7 the @xmath8 s are randomly selected from the probability distribution characterizing the process generating the perturbations . in the inflation framework , which we consider in this paper , the @xmath8 s are _ gaussian random variables _ with zero mean and covariance @xmath9 the @xmath1 s",
    "then represent the _",
    "power spectrum_. we may express the correlation between two points separated on the sky by an angle @xmath10 as @xmath11 where @xmath12 is the legendre polynomial of order @xmath13 and @xmath14 .",
    "the statistical isotropy of the perturbations demands that the correlation function depend only on separation , @xmath10 , which is in fact what permits such an expansion .",
    "when observed , the temperature fluctuations are convolved by the experimental beam , @xmath15 , positioned on the sky at @xmath16 : @xmath17 if the beam can be described by harmonic coefficients , @xmath18 , defined by @xmath19 where @xmath20 , then the observed ( or beam - smeared ) correlation function may simply be calculated as a convolution on the sphere : @xmath21 note that expansion ( @xmath22 ) pre  supposes axial symmetry for the beam .",
    "only these second statistical moments are needed to construct the likelihood function for gaussian theories .",
    "let @xmath23 be the set of parameters we wish to constrain .",
    "we represent a set of @xmath24 observed sky temperatures ( e.g. , a map ) by a _",
    "data vector _ , @xmath25 , with elements @xmath26 .",
    "if the noise is also gaussian , then the data has a multivariate gaussian distribution , and the likelihood function is @xmath27 the first equality reminds us that the likelihood function is the probability ( density ) of obtaining the data vector given a set of parameters . in this expression",
    ", @xmath28 is the pixel ",
    "pixel covariance matrix : @xmath29 where the expectation value is understood to be over the theoretical ensemble of all possible universes realizable with the same parameter vector .",
    "the second equality separates the theory covariance matrix ( @xmath30 ) from the noise covariance matrix ( @xmath31 ) .",
    "one obtains the third equality from eq .",
    "( [ eq : cbeam ] ) .",
    "we see that the model ( or the cosmological parameters , @xmath23 ) enters the likelihood through the dependence of @xmath30 on @xmath1 ( or @xmath32 $ ] ) .",
    "depending on the observational strategy , one may have either a true temperature map ( e.g. , cobe ) , or a set temperature differences ( e.g. , max ) .",
    "one could also imagine working with more complicated linear combinations of sky temperatures ; this is useful , for example , to customize bands in fourier space for reporting power estimates .",
    "let @xmath33 be the transformation matrix defining such a linear combination of sky temperatures .",
    "( [ eq : cbeam ] ) is accordingly transformed as @xmath34 where @xmath35 is the _ window matrix_. the diagonal element , @xmath36 , is normally given as the window function defining the band in fourier space over which the measured power is reported . in order to estimate this power ,",
    "one inserts a spectral form into ( 9 ) and finds its normalization as the maximum of the likelihood function .",
    "for example , the commonly used _",
    "flat _ band  power , @xmath37 , actually represents the equivalent logarithmic power integrated over the band : @xmath38\\ ] ] these are the numbers used to construct the familiar plot shown in figure 1 .",
    "the analysis of the max experiments is a good example that helps to clarify the use of the window matrix .",
    "this experiment re - groups several years of observations towards different directions on the sky ( see clapp et al .",
    "1994 , tanaka et al .",
    "1996 , ganga et al .",
    "1998 for details ) .",
    "we will analyze the hr , i d and sh campaigns and work in pixel  pixel space .",
    "for example , the 21 pixels of the max i d observations are described by a @xmath39 correlation matrix .",
    "these pixels are actually differences on the sky , defined by the observing strategy , so we must compute the window matrix given in eq . ( [ eq : defw ] ) .",
    "consider first the general strategy of a simple two  point difference : @xmath40 , whose variance is given by @xmath41 \\\\   & = & \\frac{1}{4\\pi } \\sum_l ( 2l+1 ) c_l          \\left\\ { 2 |b_l|^2 \\left[1 - p_l(\\mu)\\right ] \\right\\}\\end{aligned}\\ ] ] where the second equality uses eq .",
    "( [ eq : cbeam ] ) . the window function would be identified as the expression in the curly brackets .",
    "the _ off  diagonal _ terms of @xmath42 will depend not only on the distance between pixels , but also on their relative orientation , the angular symmetry now being broken by the nature of the difference .",
    "this means that these terms are not necessarily expressible as legendre series .    in reality , the max observational strategy is a sine  wave difference , which means that the sky temperature along a scan are weighted by a sine function , and not just the difference between two points on the sky .",
    "the window matrix element @xmath43 for two such sine  differenced pixels , separated along their common scan axis by an angle @xmath44 on the sky , may be written as @xmath45 ^ 2 }           l^2_{l-2r}(\\alpha_o ) \\\\",
    "\\times \\cos((l-2r)\\phi_{ij})\\end{aligned}\\ ] ] where @xmath46 , @xmath47 is a bessel function of the first kind , n is a normalization factor and @xmath48 is half the peak  to  peak chop angle ( see white & srednicki 1995 ) .",
    "note that this is in fact not a legendre series .",
    "once all the @xmath49 are calculated , we can construct the theory correlation matrix for a given model ( defined by either an inflation  generated spectrum , or a set of band  powers ) and compute the likelihood as given in eq .",
    "( [ eq : like1 ] ) .",
    "this also requires specification of the noise covariance matrix , @xmath31 , which for max we take to be diagonal with elements equal to the published noise variances .",
    "the max observations correspond to 4 well  separated fields on the sky ; there are therefore no correlations between each set ( i d , hr , sh , ph ) , and the overall likelihood is just the product of each individual field likelihood .",
    "results of such an analysis are presented at the end of this section and are shown as flat band  powers in figure 1 as the filled diamonds .",
    "the saskatoon experiment is described in netterfield et al .",
    "( 1997 ) . like max",
    ", the saskatoon pixels are in reality sky temperature differences , although saskatoon consists of a single field observed with different differencing strategies to probe a variety of angular scales .",
    "the data consist of 39 sets of pixels , each related to a particular frequency ( ka31ghz , q41ghz ) , for a particular year ( 1993,1994,1995 ) and for a particular strategy ; for example , there are 48 pixels for the 1994 , q - band , 6point difference . as was the case for max , these differences are actually the weighted sum of sky temperatures taken along a scan . once the exact weighting is known , it is straightforward to calculate the window matrix , @xmath42 , for each pixel set .",
    "this time , however , there are correlations between the different pixel sets , because they look at the same part of the sky and some sets probe similar scales .",
    "netterfield et al . proposed the construction of 5 separate bins of pixels , grouped according to scale such that the correlations between bins fall below 20% .",
    "clearly , correlations are larger between the 3point and 4point differences than between the 3point and 18point differences .",
    "we have not considered the data subset corresponding to the ring observations in the present analysis , but instead grouped the cap pixel sets into 5 bins in the same manner as netterfield et al . finding the power in one such bin requires calculation of the correlation matrix for all the constituent pixels . as an example",
    ", the fourth bin takes into account the 13 , 14 , 15point differences of q - band 1995 , with 96 pixels for each difference . the likelihood for the power over this bin , ignoring correlations",
    ", would be the product of three individual likelihoods , each involving a @xmath50 correlation matrix ; but properly taking the correlations into account in fact requires a @xmath51 correlation matrix .",
    "the five bins we considered contain , respectively , @xmath52 , @xmath53 , @xmath51 , @xmath51 and @xmath54 matrices .",
    "we neglect the residual correlations between bins , and use the noise correlation matrix as given by netterfield et al .",
    "this leaves us with 5 likelihoods for each model , one for each bin concentrated on 5 different scales in the power spectrum .",
    "the results are presented at the end of this section , and shown in figure 1 as the filled circles .",
    "our results are in agreement with those given by netterfield et al .",
    "for the same data ensemble .",
    "four years of observations by cobe have resulted in several full ",
    "sky maps ( different wavelength maps and combined maps to reduce galactic emission ) .",
    "one might expect that eq .",
    "( [ eq : like1 ] ) and the definition of @xmath30 given in ( [ eq : cbeam ] ) could be directly used to compute the likelihood function , since we are dealing with sky temperatures instead of differences ( all referenced to the map mean , which is set to zero ) .",
    "note , however , that the likelihood computation requires the inversion of @xmath30 and a calculation of its determinant , scaling as @xmath55 . full ",
    "sky cobe maps contain 6144 pixels .",
    "the first obstacle to direct application of eq .",
    "( [ eq : like1 ] ) is the time consuming nature of the matrix calculations .",
    "a second is due to the fact that one must use _ cut _ sky maps which remove the galactic plane . for the cobe `` custom cut '' , this reduces the number of usable pixels to 3881 , and a corresponding @xmath56 correlation matrix to invert . now , from eq .",
    "( [ eq : alm ] ) we see that the spherical harmonic coefficients ( @xmath8 ) are independent random variables for which the correlation matrix @xmath30 is diagonal , and thus easy to invert .",
    "this tempts one to try a fourier analysis of the cobe maps , but the sky cut compromises such analysis ",
    "one does not have access to the actual @xmath8 .",
    "one could all the same work with coefficients calculated only over the cut sky , @xmath57 , where the integral covers only the cut sky , but these _ do not _ have the same convenient properties as the real @xmath8  most notably a diagonal correlation matrix .",
    "it is obvious that the sky mask , seen as a convolution in fourier space , mixes different @xmath13 and correlates the @xmath58 .",
    "these @xmath58 , and in fact any coefficients defined on the cut sky , are just another example of power bands imposed by restricted sky coverage , as discussed above , but complicated here by the fact that they may not be compact over a contiguous band of multipoles .",
    "if one nevertheless wishes to perform a kind of fourier analysis on a cut map , then it would be better ( at the very least for numerical stability ) to work with orthogonal functions .",
    "this will not , as just emphasized , yield uncorrelated quantities ( orthogonality of the basis functions is not equivalent to independence over the theoretical ensemble defining the correlation matrix ) .",
    "gorsky ( 1994 ) proposed an elegant method for constructing orthonormal basis functions over an incomplete sky map , and we have used his approach for a likelihood analysis of the `` dcmb '' cobe dmr sky map . details of the technique can be found in gorski ( 1994 ) ; here we just briefly review the approach .",
    "consider an harmonic decomposition as given in ( [ eq : alm ] ) , up to order @xmath59 .",
    "we arrange our spherical harmonics @xmath60 ( we choose to use real harmonics ) in a @xmath24 by @xmath61 matrix @xmath62 with general element @xmath63 equal to @xmath64 , where the index @xmath65 ; in the following latin indices will refer to pixel number , while greek indices identify the harmonic function , i.e. , @xmath66 . any function on the sphere",
    "may be viewed as a pixel",
    " space column vector @xmath67 ( listing the function values for each pixel , e.g. , the data vector @xmath25 ) , and its harmonic decomposition is expressible as @xmath68 , where @xmath69 is a frequency  space column vector containing the harmonic coefficients ( the @xmath8 ) . the matrix @xmath62 lives in both spaces and transforms an object from one representation to the other .",
    "orthogonality of the @xmath70 over the full sky and its loss over the cut sky are represented by the following relations : @xmath71 where @xmath72 represents the solid angle subtended by the pixel elements and @xmath73 is a kind of coupling matrix for the spherical harmonics restricted to the cut sky ; it approaches unity as the size of the cut region goes to zero .",
    "since this matrix is positive definite , it may be cholesky ",
    "decomposed into the product of an upper triangular matrix @xmath74 and its transpose : @xmath75 the matrix @xmath74 permits a gram - schmidt orthogonalization and the construction of a new basis over the cut sky . setting @xmath76",
    ", we obtain the new basis functions @xmath77 from @xmath78 .",
    "their orthonormality is easily verified : @xmath79 ( notice that the @xmath80 are defined only on the cut sky , so we do not need to specify this explicitly in the matrix product ) .",
    "each new basis function @xmath77 is _ a linear combination of spherical harmonics @xmath81 of * lower or equal order , @xmath82*_. a basis function @xmath83 thus does not correspond to a pure , single spherical frequency ",
    "power is aliased in , _ but only from lower frequencies_. the fact that this power leak is only `` red  ward '' is important , because it preserves a progression towards higher frequencies with increasing @xmath84 .",
    "we have implemented this method with @xmath85 and a total of 961 @xmath80 functions .",
    "there is very little power in the cobe maps beyond @xmath86 due to the beam cutoff .",
    "we first decompose the _ pixel vector _",
    "@xmath25 on the new basis defined over the cut sky : @xmath87 the relation between these coefficients @xmath88 and the @xmath8 s is given by @xmath89 . written in the spherical harmonic basis , the theoretical correlation matrix @xmath30 of eq . ( [ eq : covmat ] ) would be diagonal : @xmath90}~ { > } ~ )   = diag\\{c_{l[\\alpha]}b_l^2\\}$ ] , where @xmath18 accounts for beam smoothing .",
    "transposed to the the cut sky , this becomes : @xmath91 this matrix has no a priori reason to be diagonal .",
    "the noise correlation matrix must also be projected from the original pixel space into the observational space defined by the new basis : @xmath92 since the noise is essentially uncorrelated in the cobe maps , the pixel ",
    "pixel noise correlation matrix is diagonal ( but not proportional to the identity matrix ! ) and the projected noise correlation matrix reduces to @xmath93 , where @xmath94 is the noise variance at pixel @xmath95 .",
    "we may now rewrite the likelihood function of eq .",
    "( [ eq : like1 ] ) in the new basis : @xmath96 we computed the likelihood of a suite of cosmological models with this function , and our results are summarized in the figures at the end of this section .",
    "note , however , that the points plotted in figure 1 do not issue from our analysis , but come rather from tegmark & hamilton ( 1997 ) and are based on the fisher matrix , as described in detail by these authors .",
    "we now detail some constraints obtained from our full likelihood analysis of the cobe , max and saskatoon data sets , following the methods outlined above .",
    "these results are interesting in their own right , and they will also serve as a benchmark against which other methods will be subsequently evaluated . _",
    "it is only this complete analysis which permits us to perform an in  depth evaluation of alternate methods attempting to approximate the full likelihood approach_. it being computationally impossible to explore a large parameter space , we shall illustrate with a series of open inflationary models , varying @xmath97 , @xmath98 and @xmath99 in the respective ranges @xmath100 ,   [ 15 , 100 , \\mbox{\\rm step}=5$]km / s / mpc@xmath101 , [ 11,23 , \\mbox{\\rm step}=1 \\mu$]k@xmath101 $ ] ; the spectral index @xmath102 is fixed to @xmath103 , @xmath104 ( olive , steigman & walker 2000 ; tytler et al .",
    "2000 ) and @xmath105 .",
    "we consider neither reionization , nor the presence of gravitational waves .",
    "this leaves us with 2340 models whose likelihood were computed .",
    "as mentioned , the independence of the selected experiments implies that the total likelihood function is simply the product of each individual likelihood .",
    "the best  fit model among this set corresponds to the parameter values @xmath106",
    ", @xmath107  km / s / mpc , @xmath108k .",
    "we note that this is in many ways a toy model , being based on a restricted data and parameter set .",
    "the zero curvature does agree with recent cmb results , such as boomerang and maxima1 ( jaffe et al .",
    "since we do not include a cosmological constant in our analysis , this implies a critical universe , which does not satisfy other cosmological constraints , for instance those arising from snia distance measurements ( riess et al .",
    "1998 ; perlmutter et al . 1999 ) and cluster evolution ( bahcall et al . 1999 ) ; although it remains consistent with some analyzes of cluster evolution ( blanchard et al . 2000 ) . nevertheless , this toy model is sufficient for our primary aim of testing analysis methods .",
    "we first discuss the gof of this model , finding that it is acceptable ( or that the fluctuations are consistent with a gaussian origin ) , and then present the parameter constraints .      the ability to compute a gof",
    "is an essential part of parameter estimation . given a set of data points and models , one can always find a `` best model '' and construct many different ways of giving confidence intervals on the parameters .",
    "the essential question we must answer is double : does the best model actually reproduce the data well ? and if so , what are the confidence intervals defined around the best ",
    "fit model .",
    "the gof attempts to quantify the first part of the question , while contours of our likelihood surfaces respond to the second .",
    "if the best model does not pass the gof , then there is no point in defining confidence intervals  the suite of chosen models is ruled out .",
    "maximization of the likelihood gives us our best estimate for the parameters , @xmath109 .",
    "to test the gof , we use the following statistic @xmath110 where the sum is over all experiments ( cobe , max , saskatoon ) and relevant bins , as discussed above .",
    "the quantity @xmath111 is the correlation matrix evaluated for the best ",
    "fit model .",
    "as might be wished , the quantity @xmath112 is distributed like a @xmath0 with a number of degrees  of  freedom equal to the total number of pixels summed over all experiments and bins : @xmath113 .",
    "this means that if our `` best model '' is a good fit , then the value of @xmath114 should be near 1 . for our best model ( @xmath106 , @xmath107 km / s / mpc@xmath115 , @xmath108k ) , we find @xmath116 , @xmath117 km / s / mpc@xmath115 and @xmath108k gives @xmath118 with @xmath113 . ] .",
    "thus , according to this test the model does indeed provide an adequate fit to the data , and so we may now move on to consider parameter constraints .",
    "this also implies that the data are consistent with a gaussian origin for the temperature fluctuations , at least according to this particular statistic .",
    "[ fig_powplot ]    for each experiment or bin , our results take the form of a three  dimensional matrix providing the likelihood over the parameter space .",
    "constraints are presented by projecting this matrix onto 2d parameter planes as follows : we construct the surface @xmath119 over the 2d plane of interest @xmath120 by either fixing the third parameter , or by letting it take on the value that minimizes @xmath121 ( `` marginalizing '' ) .",
    "contours of equal confidence are then defined by adding specific values @xmath122 to the minimum of the surface @xmath121 , e.g. , @xmath123 . if the likelihood were gaussian ( which it is not ) ,",
    "then these particular values would identify , respectively , the @xmath124 and @xmath125 confidence limits of @xmath126 or @xmath127 when projected onto these axes .",
    "figure 2 shows the constraints over the @xmath128plane with @xmath99 marginalized .",
    "inflationary power spectra are characterized by a succession of oscillating peaks ( `` doppler peaks '' ) with the first around @xmath129 .",
    "these are exactly the scales to which saskatoon is sensitive . the position of this first peak is strongly related to the curvature of the universe ( @xmath130 ) , and therefore to @xmath131 , given that we have set @xmath132 .",
    "it is then not surprising that we have a good constraint on the position of the peak , and so on @xmath2 .",
    "combined with cobe , we are able further to fix the height of the first peak relative to the large  scale plateau of the sachs  wolfe effect .",
    "this height is controlled by the quantity @xmath133 , providing an additional constraint of these parameters .",
    "it is noteworthy that with just these three experiments , albeit well selected , we obtain nontrivial constraints on the two free parameters @xmath97 and @xmath98 , at least within the chosen open inflationary context .",
    "the robust conclusion , clearly applicable beyond the present restricted context , is that large curvature is disfavored by the observed position of the peak , a conclusion reached by many authors previously ( lineweaver et al .",
    "1997 , bartlett et al . 1998ab , bond & jaffe 1998 , efstathiou et al .",
    "1999 , hancock et al .",
    "1998 , lahav & bridle 1998 , lineweaver & barbosa 1998ab , lineweaver 1998 , webster et al .",
    "1998 , lasenby et al .",
    "1998 , dodelson & knox 1999 ; tegmark & zaldarriaga 2000 ; knox & page 2000 ) , and confirmed by the recent boomerang and maxima1 results ( de bernardis et al .",
    "2000 ; hanany et al .",
    "2000 ; jaffe et al .",
    "2000 ) .",
    "these results obtained from a full likelihood analysis now permit us to test other , less time  consuming methods that have been proposed as an approximation to such a complete treatment .",
    "[ fig_saskmaxcob ]",
    "the time  costly nature of a full likelihood analysis over pixel space prevents its general application to actual cmb data sets ( bond et al .",
    "1998 , 2000 ; borrill 1999ab ; kogut 1999 ) .",
    "this has motivated the development of faster , but approximate , methods .",
    "these are _ approximate _ in the sense that they do not necessarily retain all relevant experimental information , as does the full likelihood treatment .",
    "it is therefore important to compare the results of these approximate methods to those of a complete likelihood treatment . because we have performed a complete likelihood analysis , we are now in a position to do just this .",
    "all currently proposed approximate approaches use power estimates as their starting point .",
    "as discussed in the introduction , the power spectrum may be considered as a compressed form of the data , because there are many fewer independent power points than original pixels .",
    "gaussian fluctuations observed in the absence of noise over the full sky are completely described by their set of multipole power estimates @xmath1 .",
    "real observations , however , contain noise and cover only limited amounts of sky .",
    "it is then no longer possible to uniquely decompose the sky signal ; the noise and limited sky coverage ( equivalent to a window function ) reduce the spectral resolution and correlate power estimates .",
    "flat band  power estimates , as shown in figure 1 , represent a particular attempt to express an experimental result in the power plane under such circumstances .",
    "there is no guarantee that the reduction to a set of flat  band powers does not involve the loss of pertinent information , i.e. , that it is a kind of _ lossy _ data compression .",
    "this raises an important question concerning the adequacy of any method based on flat  band estimates to reproduce the complete likelihood results ( which we take to be the defining goal of any proposed analysis scheme ) . once given a power estimate , one must then decide how to use it in a correct statistical analysis ; different choices lead to alternative approximate methods .",
    "we begin this section by first examining the accuracy ( always compared to our complete likelihood results ) of different ways of using flat  band estimates . in the second part of the section",
    ", we return to the fundamental question raised in the previous paragraph and study in greater detail the whole premise of the flat band ",
    "power approach  namely , whether any of these methods are able to recover all the relevant information contained in the likelihood analysis .",
    "we will discover shortcomings of the flat  band approach that will lead us to propose better approximate methods .",
    "the most obvious way of finding `` the best model '' given a set of points and errors is the traditional @xmath0minimization .",
    "this would appear to apply to our situation : we are given the points plotted in figure 1 , @xmath134 , with errors , and we have a large set of models depending on diverse parameters that we can express in terms of temperature fluctuations , @xmath135 .",
    "we would therefore just minimize @xmath136^{2}\\ ] ] this is the most basic and obvious way of estimating the parameters , @xmath23 .",
    "improvements may be added to take into account the asymmetry of the error bars and the effects of the window function .",
    "for the former , one would take a different @xmath137 in eq .",
    "( [ eq : chi21 ] ) if the model prediction is greater ( @xmath138 ) or lower ( @xmath139 ) than the observed value , and the model predictions may simply be convolved with the window function .",
    "the main problem with this approach is that it treats the flat band  power estimates as gaussian distributed data .",
    "as we saw at the beginning of the first section , gaussian temperature fluctuations , such as occur in inflationary models , lead to pixels that are gaussian random distributed , and so also the @xmath140 . since band powers",
    "measure the variance of these random sky fluctuations , the distribution of a power estimate * can not * be gaussian .",
    "it is something more akin to a @xmath0 distribution .",
    "while it is of course true that this tends to a gaussian as the number of independent values ( pixels ) entering the power estimate increases , this does not always apply in practice to cmb data : consider max as an extreme example with only 21 pixels ( and not effectively independent due to correlations ) .",
    "it is not true that the relevant number of degrees  of  freedom corresponds to the multipole order to which the experiment is sensitive ; it is rather the number of effectively independent pixels , and any experiment will always be limited by a small number of pixels over the largest scales probed .",
    "there is a perhaps less well  appreciated aspect of this issue .",
    "if one wishes to reproduce as closely as possible the complete likelihood analysis outlined in the previous sections , then what one really needs to know is @xmath141 $ ] , which is not the same thing as the distribution of the power estimator . to be precise ,",
    "the power estimator is given by the maximum of the band  power likelihood function .",
    "its distribution can be determined by a monte carlo for an adopted underlying model ( set of parameters ) .",
    "this remark is particularly relevant considering the nature of the error bars given in plots such as figure 1 : these are confidence intervals based on the likelihood function , and not the second moment of the power estimator distribution . due to its simplicity , the @xmath0 approach lies at the basis of most current efforts to constrain cosmological parameters with cmb data , despite these shortcomings .",
    "it is thus of some importance to test its ( a priori dubious ) adequacy .",
    "[ f : lsm18 ]    results from @xmath0minimization will be compared to our complete likelihood analyzes . for clarity , and to emphasize pertinent aspects of the problem , we continue to work in a restricted framework by fixing the normalization @xmath142k and combining only the max and saskatoon experiments ( 7 flat band  powers ) .",
    "[ f : csm18 ]    figures 3 and 4 show constraints in this restricted context for , respectively , the likelihood analysis and the @xmath0 method .",
    "we clearly see a difference in the inner contours between the two approaches ; and the `` best model '' also changes radically depending on the method . to see if the prefered models agree with our intuitive `` @xmath143by  eye '' , we plot them in the power plane of figure 1 .",
    "they appear both to agree perfectly with saskatoon , while trying to pass between the max points .",
    "the largest contribution to the @xmath0 comes from max hr ( lowest max point in figure 1 ) .",
    "it is natural to ask if this outlier alone can account for the difference between the two methods . a simple way to test",
    "this is by substituting just this experiment s true likelihood by its @xmath0 in an otherwise full likelihood analysis .",
    "this results in the contours of figure 5 , which are to be compared to those of figure 4 .",
    "[ f : lcsm18 ]    the fact that the contours begin to close around @xmath144 and @xmath145 km / s / mpc , as in figure 4 , indicates that indeed this one _ outlying _ point is capable of radically changing the confidence contours and the deduced `` best model '' .",
    "recall the supposition of a gaussian distribution implicitly adopted by the @xmath0 approach . here",
    ", we have precisely a case where the `` best models '' are typically far into the wing of the distribution function for this outlier , and so it is perhaps not too surprising that the @xmath0 method is at some odds with the complete likelihood analysis .    to further explore the issue , consider the difference in terms of the one  dimensional flat band",
    " power likelihood function .",
    "figure 6 shows the distributions used by the two methods .",
    "the solid ( black ) curve is the true likelihood function while the dashed3dotted ( red ) curve shows a two  tailed gaussian , as employed with eq .",
    "( [ eq : chi21 ] ) .",
    "the two distributions clearly diverge for @xmath146 ( @xmath147 greater than 6 ) , exactly where the two models of figure 1 pass . from this figure",
    "we see that a model with a temperature fluctuation of @xmath148k falls on the 99% confidence boundary ( @xmath149 ) in the likelihood analysis , but at 99.99% confidence ( @xmath150 ) in the @xmath0minimization .",
    "this makes a significant difference to the final contours .",
    "all the same , we note that the final 95% confidence contours are essentially the same for the two methods .    [",
    "f : func ]    in summary , the presence of outliers can significantly change the constraints of a @xmath0minimization relative to the true likelihood analysis , because a gaussian is a particularly bad approximation of the latter in the wings .",
    "in the above example , the overly rapid fall  off of the gaussian relative to the true likelihood ` pulls ' the contours towards lower @xmath97 and favors an entirely different best fit model than that selected by the likelihood analysis . on the other hand ,",
    "the constraints at the 95% confidence level are nearly the same .",
    "thus , it is rather difficult to arrive at a firm conclusion concerning the accuracy of the @xmath0 method , but this example would seem to indicate that some caution is required when applying the method .      how can we improve on a @xmath0 minimization while still using only flat band  powers ? some authors ( bartlett et al . 2000 , hereafter paper 1 ; bond et al .",
    "2000 , wandelt et al .",
    "2000 ) have proposed functional forms ( differing from a gaussian ) to approximate the band  power likelihood . in the present section",
    ", we study in detail the performance of the approximation we developed in paper 1 .",
    "there it was shown that the proposed approximation works quite well in fitting the _",
    "one  dimensional _ flat  band likelihood function ( see figures 2 , 3 , 4 in paper 1 and http://webast.ast.obs-mip.fr/cosmo/cmb ) .",
    "we may still wonder , however , if the approximation is good enough to reproduce the full likelihood constraints over the entire ( @xmath151)plane . this is our present concern .",
    "consider first that the approximation does indeed improve on the @xmath0 minimization , as we demonstrate in figure 7 by substituting the approximation for the true likelihood of max hr , in an otherwise full likelihood analysis .",
    "[ f : lsm18 ]    with the approximation , we able to recover almost the same contours as in figure 3 , thereby eliminating the over  importance given previously to this outlier by the @xmath0 method .",
    "further , when we substitute the approximation for all the power points , we reproduce the full likelihood constraints better than the @xmath0 minimization . there remain , nevertheless , some slight differences between the approximation and the full likelhood , acting in the same sense of rejecting the models at high @xmath97 prefered by the likelihood analysis . we may wonder whether these remaining differences are due to the fact that the approximation does not exactly reproduce the one  dimensional flat ",
    "band distribution , or to something more profound ?",
    "in other words , supposing that we had the _ exact",
    "_ 1d flat band ",
    "power likelihood function , could we then recover the full likelihood contours ?    to examine the issue in depth , we compute the exact band",
    " power likelihood function for each experiment / bin over a range of @xmath37 .",
    "the likelihood of any given model is then found by simple interpolation .",
    "we would like to point out at this point that in fact this technique would be more accurate and almost as fast as a @xmath0minimization , if it proves accurate .",
    "therefore , we invite people to published the one dimensional likelihood functions and to make them available for each new ( and old if possible ) experimental result .",
    "figure 8 shows the results , which are to be compared to the true likelihood constraints of figure 3 .",
    "we see that differences persist , including the shifted best ",
    "fit model , even though the band  power likelihood has been as well approximated as possible .",
    "thus , the remaining difference in contours is not due to the use of an approximation to @xmath152 , but apparently to _ information lost in the reduction to flat band ",
    "power estimates_. in the following discussion on this point , we will refer to all techniques using flat ",
    "band estimates , and not pixel values , as _ generalized _ @xmath0 techniques .",
    "[ f : cbsm18 ]      the residual differences just noted bring us back to the comments made at the beginning of this section concerning the reduction of an observation to a flat band  power estimate .",
    "any given experiment is sensitive to a number of different angular separations , and the totality of its information content is thus contained in as many numbers .",
    "for example , the set of parameters consisting of the _ distinct _ elements of the theory covariance matrix @xmath30 provides a complete description . the likelihood",
    "should then be viewed as a function of these parameters , each with its own frequency  space distribution given by the elements of the window matrix @xmath42 . in this context , we see that the reduction to a single flat band  power estimate is but the most crude ( order zero ) representation of an experimental result , and we should not be surprised if it is not always sufficient to the task .    we may attempt to quantify the information missing in the flat  band representation as follows : instead of the flat spectrum of eq .",
    "( [ eq : dtfb ] ) , we employ a spectral form with _ two _ free parameters  a normalization @xmath153 and an effective slope , @xmath154 , @xmath155 and treat the likelihood as a function of both ; the quantity @xmath156 is the usual effective multipole defined over the experimental window function .",
    "if both parameters are constrained by the data , then at least these two parameters are required to model the likelihood .",
    "generalized @xmath0 techniques fix the slope to zero ( @xmath157 ) and therefore neglect this information .",
    "we proceed by first restricting ourselves to the third bin of saskatoon ( chosen at random ) in order to gain some insight .",
    "we return to the complete data set at the end of the section , where we propose a new technique that accounts for the effects we now describe .",
    "figure 9 shows the constraints imposed by the third saskatoon bin ( see figure 1 ) in the @xmath158plane for @xmath159 .",
    "the black ( solid ) curves follow from a complete likelihood analysis , and the green ( dot  dashed ) ones from an interpolation of @xmath160 , as described previously .",
    "[ f : touts4 ]    as an illustration , notice that models with very low @xmath161 and intermediate @xmath2 are more acceptable to the generalized @xmath0 , but fall outside the inner contour of the likelihood analysis  constraints .",
    "typically , these models all rise through the third bin of saskatoon , i.e. , their effective slope is positive and far from zero ; an example is shown as the dotted line in figure 1 . that the data in fact prefer a _ negative _ slope",
    "is demonstrated in figure 10 .",
    "here we show the likelihood _ surface _ constructed over @xmath162 using eq .",
    "( [ eq : modfbm ] ) ; we immediately observe that falling spectra are favored ( @xmath163 ) on this scale .",
    "this was also noted by netterfield et al .",
    "( 1997 ) , and the same analysis applied to the other saskatoon bins finds the same trends as noted by these authors ( even though we do not include the ring data here ) . the fact that @xmath154 is at all constrained implies that the likelihood is sensitive to the local effective spectral slope .",
    "neglect of this information by all generalized @xmath0 methods lies at the origin of the differences noted between the flat  band results and the full likelihood in figure 9 .",
    "we will clearly do better by locally approximating any given spectrum by eq .",
    "( [ eq : modfbm ] ) and using the resulting @xmath153 and @xmath154 to find the corresponding approximate likelihood for the model . in practice",
    "this may be done by interpolating over a pre  calculated grid in the @xmath162plane , shown for the third saskatoon bin in figure 10 . when applied to this bin , we find the red ( dashed ) contours in figure 9 , a more faithful reconstruction of the full likelihood analysis .",
    "we thus propose a new approximate method taking into account not only in  band power , but also information on the local shape of the power spectrum .",
    "it is important to remark that _ it is little more complicated or time consuming than approximations based on simple flat  band likelihood curves _ ; the likelihood surface in 2d may be calculated once , and then interpolated for any model .",
    "more generally , one may imagine that additional parameters would useful when dealing with higher signal  to  noise data sets , such as expected with next generation observations .",
    "in reality , the exact choice of parameters is debatable and should depend on the number and definition of spectral bands .    [",
    "f : dtfb ]      the goal of these power  plane methods is to approximate as closely as possible the full likelihood analysis , and two central issues are the nature of the power estimates and their use in a statistical analysis .",
    "many current cmb constraints follow from standard @xmath0 techniques using flat  band power estimates and associated errors .",
    "the obvious objection is that neither the distribution of this power estimator , nor its likelihood function is gaussian ( e.g. , figure 6 ) . as we have seen from the comparison of figures 3 , 4 and 5 , the false assumption of gaussianity on the part of the @xmath0",
    "causes it to be overly sensitive to `` outliers '' , leading to a possible bias in the best ",
    "fit model ( as in our examples ) and a distortion of the confidence intervals .",
    "other methods overcome this deficiency by adopting simple , non  gaussian analytic functions to approximate the likelihood of @xmath164 ( paper 1 ; bond et al .",
    "2000 ; wandelt et al .",
    "although performing quite admirably , and better than the @xmath0 , the approximate approach is unable to fully reproduce the exact likelihood constraints .",
    "the fact that this remains true even if the _ exact",
    "band likelihood curve is used , say by interpolating over a pre  calculated table of values ( figures 3 and 8) , indicates that the reduction to flat band ",
    "powers losses pertinent information .    in general terms ,",
    "a set of temperature measurements requires as many parameters as unique pixel separations to be fully described , and this may be as large as or smaller than the original number of pixels , depending on the exact geometry of the observations .",
    "one implication is simply that , in principle , an experiment is sensitive to details of the power spectrum other than just the amplitude averaged over the range of probed scales ; e.g. , an additional sensitivity to the local slope . whether this information is in practice useful depends principally on the signal  to  noise ratio .",
    "the critical test is to see if these additional spectral characteristics are constrained by the likelihood function .",
    "we studied this for the saskatoon and max data sets and found that in some cases the local power spectrum slope is in fact constrained , thereby implying that useful information is lost in the reduction to a single band  power .",
    "this is illustrated in figure 9 for the third saskatoon bin .",
    "this bin actually prefers a slightly falling spectrum , and it is interesting to point out that the first bin , in contrast , prefers a slightly positive slope .",
    "the saskatoon data thus provide additional discrimination on the first doppler peak s position than one would deduce from the band ",
    "powers alone .",
    "returning to parameter constraints with this new insight , we were able to fully reproduce the likelihood constraints in the @xmath158plane by modeling each bin likelihood ( when needed ) as a function of two spectral parameters  a local amplitude and slope , eq .",
    "( [ eq : modfbm ] ) .",
    "this is demonstrated in figure 9 for the third saskatoon bin alone , and in figure 11 for the ensemble of cobe , max and saskatoon bins .",
    "this procedure is essentially as practical as any approximation to the 1d flat  band likelihood function : one only needs to calculate the likelihood _ surface _ over @xmath153 and @xmath154 once and use the tabulated values as a basis for interpolation to any other parameter values .    [",
    "f : touttout ]",
    "among the various reasons for believing that cmb temperature fluctuations are the cosmologist s most useful tool for determining the fundamental big bang model parameters are their simple , _ linear _ physics ( at least within the framework of standard passive perturbations ) and straightforward interpretation . by the latter",
    "we mean that there exists a very clear connection between measured and theoretical quantities  an easily constructible likelihood function , eq .",
    "( [ eq : like1 ] ) .",
    "unfortunately , the computational complexity of inverting the large covariance matrix @xmath28 and finding its determinant many times makes direct application of the likelihood approach practically impossible .",
    "it is really only possible to perform full likelihood treatments in pixel space for rather small data sets .",
    "one way of improving the situation is to work in the power plane of figure 1 , where sky temperatures are reduced to a much smaller number of power estimates .",
    "gaussian fluctuations are completely described by their multipole power spectrum , so the data compression is lossless .",
    "real experiments are however incapable , due to limited sky coverage and the presence of noise , of recovering the individual multipoles .",
    "this fact significantly complicates all cmb analysis efforts .",
    "the estimation of band  powers , their best definition and their use in statistical analyzes all become important , related and nontrivial issues .",
    "more specifically , one should address the question of the adequacy of any method based on band  powers to reproduce a full likelihood analysis .    in this",
    "_ paper _ we have examined in detail some of the current techniques applied to power estimates to constrain cosmological parameters . to test the various methods ,",
    "we have performed a full likelihood analysis on the cobe , max and saskatoon experiments ; this is a _ prerequisite _ for making any solid statement concerning the fidelity of an approximate method based on power estimates .",
    "we outlined our likelihood analysis in section 2 .",
    "although necessarily restricted to a limited set of models ( open scenarios with zero cosmological constant ) , we nevertheless note that interesting constraints are obtained with this small data subset .",
    "we found , perhaps not too surprisingly , that @xmath0 methods do not completely reproduce the likelihood contours and are susceptible to bias , all essentially due to their incorrect application of gaussian distributions to power estimates .",
    "other methods adopting more appropriate distributions fare better ( paper 1 ; bond et al .",
    "2000 ; wandelt et al .",
    "more fundamentally , we found that in certain situations flat band ",
    "powers do not always retain all the useful information of an experimental result .",
    "this is the case , for example , for some of the max and saskatoon power bins . in these cases we found that the data are more appropriately parameterized by two spectral parameters , a local in  band power ( @xmath153 ) and a local in  band slope ( @xmath154 ) .",
    "we were able to recover the lost information by using these two parameters rather than a single flat  band power estimate .    in the present work ,",
    "we have focused on first generation data , for which the observational strategy often suggests the form of the adopted power band ( e.g. , via the differencing scheme used ) .",
    "the issue concerning the fidelity of power estimates is nevertheless of general importance .",
    "the number of power bands , or parameters of any kind , used to summarize an observational campaign must correspond to the quantity of pertinent information .",
    "this may be addressed in practical terms by testing to see how many independent parameters ( power bands or spectral parameters ) are significantly constrained by the pixel data .",
    "these issues , the faithfulness of both the reduction to power estimates and the application of approximate power  based analysis methods , will become more important as the signal  to - noise of the observations increases , and as one tries to extract ever more precise constraints from the data .",
    "it will thus be of all the more interest to find fast analysis techniques able to reproduce as faithfully as possible complete ( but impossible to realize ) likelihood results .",
    "bahcall n.a .",
    ", ostriker j.p . , perlmutter s. & steinhardt p.j . , 1999 , science 284 , 1481 balbi a. et al .",
    "2000 , apj 545 , l1 [ astro - ph/0005124 ] bartlett j.g . , blanchard a. , le dour m. , douspis m. & barbosa d. 1998a , in : fundamental parameters in cosmology ( moriond proceedings ) , eds",
    ". j. trn thanh vn et al .",
    "( editions frontires : paris , france ) , astro  ph/9804158 bartlett j.g .",
    ", blanchard a. , douspis m. & le dour m. 1998b , in evolution of large  scale structure : from recombination to garching , ed .",
    "banday et al .",
    "( printpartners ipskamp , the netherlands ) , p202 [ astro  ph/9810318 ] bartlett j.g .",
    ", blanchard a. , douspis m. & le dour m. 1998c , to be published in : the cmb and the planck mission ( santander , spain ) , astro  ph/9810316 bartlett j.g . , douspis m. , blanchard a. & le dour m. 2000 , a&as 146 , 507 bennett c.l .",
    ", banday a.j .",
    ", gorski k.m .",
    "1996 , apj 464 , l1 blanchard a. , sadat r. , bartlett j.g . &",
    "le  dour m. 2000 , a&a 362 , 809 [ astro - ph/9908037 ] bond j.r . , jaffe a.h . &",
    "knox l. 1998 , ph.rev d57 , 2117 bond j.r .",
    ", jaffe a.h . &",
    "knox l. 2000 , apj 533 , 19 bond j.r .",
    "& jaffe a.h .",
    "1998 , to appear in philosophical transactions of the royal society of london a , 1998 .",
    "`` discussion meeting on large scale structure in the universe , '' royal society , london , march 1998 , astro ",
    "ph/9809043 bond j.r . ,",
    "chrittenden r.g .",
    ", jaffe a.h . & knox l. 1999 comp . in sci .",
    "& eng . , 1 , 21 ( astro  ph/9903166 ) borrill j. 1999a , in : 3k cosmology ( ec - tmr conference held in rome proceeding ) , eds .",
    "luciano maiani , et al .",
    "( american institute of physics ) , p277 [ astro  ph/9903204 ] borrill j. 1999b , in : proceedings of the 5th european sgi / cray mpp workshop , astro ",
    "ph/9911389 clapp a. c. , devlin m. , gundersen j. o. & al .",
    "1994 , apj 433 , 57l de bernardis p.",
    "2000 , nature 404 , pp .",
    "955 dodelson s. & knox l. 1999 , astro ",
    "ph/9909454 efstathiou g. , bridle s.l .",
    ", lasenby a.n . , hobson m.p . &",
    "ellis r.s . 1999 ,",
    "mnras , 303 , l47 [ astro  ph/9812226 ] ganga k. , ratra b. , lim m. a. & al .",
    "1998 , apjs 114 , 165 grski k.m .",
    "1994 , apj 430 , l85 hanany s. et al .",
    "2000 , apj 545 , l5 [ astro - ph/0005123 ] hancock s. , rocha g. , lasenby a.n . &",
    "gutierrez c.m .",
    "1998 , mnras 294 , l1 jaffe a. et al .",
    "2000 , astro - ph/0007333 knox l. & page l. 2000 , astro - ph/0002162 kogut a. 1999 , apj 520 , l83 lahav o. & bridle s.l .",
    "1998 , in evolution of large  scale structure : from recombination to garching , ed .",
    "banday et al .",
    "( printpartners ipskamp , the netherlands ) , p190 [ astro  ph/9810169 ] lange a.e .",
    "2000 , astro - ph/0005004 lasenby a.n .",
    ", bridle s.l . & hobson m.p .",
    "1999 , to be published in : the cmb and the planck mission ( santander , spain ) , astro  ph/9901303 le  dour m. , douspis m. , bartlett j.g . &",
    "blanchard a. 2000 , a&a in press [ astro  ph/0004282 ] lineweaver c. , barbosa d. , blanchard a. & bartlett j.g .",
    "1997 , a&a 322 , 365 lineweaver c.h .",
    "& barbosa d. 1998a , a&a 329 , 799 lineweaver c.h .",
    "& barbosa d. 1998b , apj 496 , 624 lineweaver c.h .",
    "1998 , apj 505 , 69 netterfield c.b . ,",
    "devlin m.j . , jarolik n. , page l. & wollack e.j .",
    "1997 , apj 474 , 47 olive k.a .",
    ", steigman g. & walker t.p .",
    "2000 , phys .",
    "333 , 389 [ astro  ph/9905320 ] perlmutter s. , aldering g. , goldhaber g. et al 1999 , apj 517 , 565 .",
    "riess a.g .",
    ", filippenko a.v .",
    ", challis p. et al .",
    "1998 , aj 116 , 1009 tanaka s.t . ,",
    "clapp a.c .",
    ", devlin m.j .",
    "1996 , apj 468 , l81 tegmark m. & hamilton a. 1997 , astro ",
    "ph/9702019 tegmark m. & zaldarriaga m. 2000 , apj 544 , 30 [ astro - ph/0002091 ] tytler d. , omeara j.m . , suzuki n. , lubin , d. 2000 , physica scripta t85 , 12 wandelt b.d . , hivon e. & grski k.m .",
    "1998 , astro ",
    "ph/9808292 wandelt b.d .",
    ", hivon e. & grski k.m .",
    "2000 , astro - ph/0008111 webster m. , bridle s.l . ,",
    "hobson m.p .",
    ", lasenby a.n .",
    ", lahav o. & rocha g. 1998 , apj 509 , l65 [ astro  ph/9802109 ] white m. & srednicki m. 1995 , apj 443 , 6"
  ],
  "abstract_text": [
    "<S> most parameter constraints obtained from cosmic microwave background ( cmb ) anisotropy data are based on power estimates and rely on approximate likelihood functions ; computational difficulties generally preclude an exact analysis based on pixel values . with the specific goal of testing this kind of approach </S>",
    "<S> , we have performed a complete ( un - approximated ) likelihood analysis combining the cobe , saskatoon and max data sets . </S>",
    "<S> we examine in detail the ability of certain approximate techniques based on band  power estimates to recover the full likelihood constraints . </S>",
    "<S> the traditional @xmath0method does not always find the same best  fit model as the likelihood analysis ( a bias ) , due mainly to the false assumption of gaussian likelihoods that makes the method overly sensitive to data outliers . </S>",
    "<S> although an improvement , other approaches employing non  gaussian flat  </S>",
    "<S> band likelihoods do not always faithfully reproduce the complete likelihood constraints either ; not even when using the exact flat  band likelihood curves . </S>",
    "<S> we trace this to the neglect of spectral information by simple flat band  power estimates . </S>",
    "<S> a straightforward extension incorporating a local effective slope ( of the power spectrum , @xmath1 ) provides a faithful representation of the likelihood surfaces without significantly increasing computing cost . </S>",
    "<S> finally , we also demonstrate that the best  </S>",
    "<S> fit model to this particular data set is a _ good fit _ , or that the observations are consistent with gaussian sky fluctuations , according to our statistic . </S>"
  ]
}