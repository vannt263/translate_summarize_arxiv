{
  "article_text": [
    "with the explosion of web information in the last decade , it becomes more and more difficult for individuals to discover interesting information from massive web resources . to solve the information overload problem that has attracted lots of attention from both academic and industrial communities",
    ", various personalized recommender systems have been developed to help a user automatically find their interested information .",
    "mainstream approaches include knn collaborative filtering @xcite , latent factor models @xcite , resource projection @xcite , restricted boltzmann machine , etc .",
    "although in recent years recommender systems play a more and more important role in online commerce and sharing services such as amazon , netflix and youtube , there still exists much room for a recommender system to improve its accuracy .",
    "a bunch of problems including sparsity , cold start and diversity remain as grand challenges in the open literature @xcite .",
    "the two major schools , neighborhood - based methods and latent factor models , are facing their own difficulties respectively .",
    "the family of latent factor models , originating from matrix factorization and making great progress by incorporating with probabilistic graphical models @xcite and compressed sensing @xcite recently , gains success in accurately completing missing ratings .",
    "however , its lack of interpretability may limit its application in practice , since interpretability plays a critical role in practice to affect users experience @xcite .",
    "the conventional neighborhood - based approaches like knn collaborative filtering techniques produce estimations in a way much easier to explain clearly , but meanwhile suffer from the _ rating bound problem_. take the item - based collaborative filtering as example .",
    "a neighborhood - based approach estimates an unobserved rating with the weighted average of ratings on similar items called neighbors , and therefore the estimation is bounded by observed neighbor s ratings .",
    "however , an item a user loves or hates _",
    "the most _ is usually rated higher or lower than all the neighbor items , and therefore has no chance to be correctly predicted by a neighborhood - based approach .",
    "similarly , the rating bound problem is also a big challenge to the user - based collaborative filtering technique",
    ". the rating bound problem will not be problematic if the actual bounds are fully observed , i.e. , the items rated higher / lower than all other items at least in a local range .",
    "unfortunately , in many practical scenarios , those ratings are not always fully observed , since , for example , a movie fan is lazy to label all her favorite movies on each of a dozen movie websites she registers on , or a reader is reluctant to post a rating to an extremely boring book . lacking observations of actual rating bounds , a neighborhood - based approach like knn collaborative filtering technique seriously suffers from the rating bound problem because of its results being bounded by incorrect bounds . by empirical analysis , up to @xmath2 estimation tasks suffer from the rating bound problem .",
    "nearly a half of estimation errors of knn collaborative filtering owe to incorrect estimations on those items .",
    "this implies that it is a much more difficult job to accurately recover an unobserved rating with the rating bound problem than recovering an unobserved rating without the problem .    besides the help to accurately recover missing ratings , the items which are rated higher or lower than all other items have their own values",
    "such items are called a user s _ interest centers_. a positive interest center of a user , i.e. , an item she rater higher than all neighbor items , is an item she loves the most , such as five favorite restaurants in the city or most beloved movies in a library . to correctly discover and recommend those items ( if unseen yet ) makes the user enjoyable and trust the system .",
    "symmetrically , a user might have several negative interest centers that she dislikes or hates , e.g. , a soft music fan might be unhappy to find a heavy metal rock album in a recommendation list .",
    "a recommender system should try its best to avoid recommending those disliked items .    in a word ,",
    "it is critical for a recommender system to solve the rating bound problem , not only for more accurately predicting the unobserved ratings , but also for better sketching a user s interest map and improving user experience .",
    "latent factor models might be helpful to reduce the pain caused by the rating bound problem . nevertheless , due to the practical importance to explain to users why the recommendation list is produces , as well as the difficulty in explaining matrix factorization results , we attempt to solve the problem in the line of neighborhood - based methods , which provides more explainable results than a latent factor model .",
    "to address the rating bound problem , we view the task to estimate unobserved ratings in a recommender system as a job of function recovery . given an item - item network built in the same way as in a standard neighborhood - based method , for each user @xmath3 , a scalar function @xmath4 is defined on the network to map any item to a rating .",
    "a recommender system is required to recover the whole function @xmath5 as accurate as possible , based on the partial observation of the function value on a few items . with a practically verified prior knowledge",
    "that such a scalar function is linear on most items , i.e. its second derivative vanishes on most items , we develop an effective method to recover the function by minimizing the number of items with non - zero second derivatives ( for simplicity , we denote _ sources _ for items with non - zero values of the second derivative of a scalar function in the rest of the paper ) .",
    "empirical practice supports that our approach effectively improves the performance when predicting items with the rating bound problem .",
    "the major contributions in this paper are listed below ,    * we study the rating bound problem that the conventional neighborhood - based approaches suffer from . * to solve the problem , we introduce a scalar function view to consider a recommender system algorithm as a scalar function recovery task based on partial observations . *",
    "we propose an approach that minimizes the @xmath0-norm of the second derivative of a scalar function to recover it .",
    "the approach is validated effective with empirical experiments .",
    "the rest of the paper is organized as follows .",
    "section [ section : model ] introduces our view to the recommender systems and section [ section : inference ] describes our approach to solve the rating bound problem , which is validated in section [ section : experiments ] .",
    "section [ section : backgrounds ] reviews the recent progress in recommender system research .",
    "section [ section : conclusion ] concludes the paper .",
    "in this section we introduce our view of recommender systems as a task of scalar functions recovery , and how different approaches leverage a property of the functions for inference .    from a function perspective",
    ", the process to complete missing ratings in a recommender system can be considered as a job of function recovery . for each user @xmath3 , a scalar function @xmath5",
    "is defined to map any item @xmath6 ( e.g , book , music , movie , product , celebrity , etc . ) to a real or integer rating @xmath7 .",
    "a recommender system is expected to recover the whole function @xmath5 for each user based on partial observation of the function value . obviously this is impossible unless prior knowledge or additional evidence is provided .    different prior knowledge or assumptions result in different approaches . for example ,",
    "latent factor models assume that the explicit form of a scalar function is a linear combination .",
    "each item is represented with a vector where each element corresponds to its `` quality score '' in a certain feature , and a set of `` interest '' weights is defined for each user to add up those scores to make a rating .",
    "differently , neighborhood - based approaches do not assume the explicit for the a scalar function , but instead assume that the shape of the concerned function is `` smooth '' on an item - item network , and therefore can be fulfilled with interpolation . in the scope of this paper we extend the line of neighborhood - based approaches because of its ease in explanation .",
    "a widely believed assumption , usually called the similarity assumption , tells that if two items were rated similarly in the past , they will be rated similarly in the future .",
    "the assumption provides the basis to build the collaborative filtering technique , which estimates an unobserved rating with the weighted average of ratings on similar items . an equivalent description to the assumption tells the linearity of a scalar function defined on an item - item network where nodes are items and edges describe the similarity among items .",
    "we introduce a _ linearity assumption _ of a scalar function that its second derivative vanishes on most items , i.e. , the following equation holds for most items @xmath6 ,    @xmath8    where @xmath9 denotes a discrete second derivative operator .",
    "the linearity assumption helps us recover the whole function after observing part of function values .",
    "we first explain why the similarity assumption and the linearity assumption are equivalent .",
    "let us recall the well - known resnick equation applied in knn collaborative filtering to predict an unknown rating @xmath7 as follows ) to describe knn collaborative filtering .",
    "there are several forms of knn collaborative filtering , for example @xmath10 , where @xmath11 denotes the global average rating of item @xmath6 .",
    "the discussion in this paper can be easily extended to the above form , with a simple preprocess to replace all @xmath12 with @xmath13 .",
    "extensions to other forms are similar .",
    "] ,    @xmath14    where @xmath15 is the weight on the edge between item @xmath6 and item @xmath16 , i.e. , the similarity between them .",
    "the weighted average is calculated among items in @xmath17 , the neighbor set of item @xmath6 .",
    "we move the rhs to the left and have    @xmath18    labeling all items with integers @xmath19 , we can rewrite the above equation in a matrix form ,    @xmath20 where @xmath21 is a vector consisting of @xmath5 values , @xmath22 is an identity matrix , @xmath23 is the weight matrix with element @xmath24 , and the diagonal matrix @xmath25 is defined as    @xmath26    notice that the laplacian matrix @xmath27 is the negative of @xmath9 , which is the discrete second derivative operator .",
    "the above equation is exactly an second - order ordinary differential equation @xmath28 as we mentioned in equation ( [ equ:2nd - derivative - vanish ] ) .",
    "the connection was firstly introduced in @xcite .",
    "to support the linearity assumption , we empirically examine whether the second derivative of any user s rating function vanishes on most items . in three real datasets ( dataset details described in section [ subection : dataset ] ) , we collect such examples where the second derivative @xmath29 can be directly calculated , i.e. , the ratings a user @xmath3 posts to an item @xmath6 and all its neighbor items in @xmath17 are completely observed . such that the user @xmath3 rates the item @xmath6 and no less than @xmath30 neighbor items ] we further require that no less than @xmath31 ratings are observed on neighbor items , otherwise the calculation of @xmath29 might be unreliable .    in each dataset ,",
    "there exist hundreds of user - item pairs where the second derivative can be calculated according to observed ratings .",
    "the statistics of the obtained second derivatives are report in fig .",
    "[ fig : exam.assumption ] . as shown in the figure , on most examples the calculated values of second derivative",
    "are almost zero , and few examples have a second derivative far away from zero .",
    "the number of those examples decreases exponentially with the distance from zero ( note that the vertical axis is labeled in logarithm ) .",
    "the results confirm the linearity assumption on the shape of a user s rating function , which later helps us accurately recover the whole rating function based on an observed part of ratings .",
    "as discussed earlier , the knn collaborative filtering technique ( denoted as knn in the rest of the paper ) leverages the linearity assumption to estimate an unobserved rating .",
    "however , it actually calculates the second derivative with observed ratings of neighbors only , instead of the observed ratings and estimated rating of all the neighbors , as    @xmath32    where @xmath33 denotes the set of items that user @xmath3 has rated .",
    "the above calculation is an approximation , and could be unreliable when the observations are sparse , which is quite common in a typical recommender system .",
    "an example is shown in figure [ fig : edge.usage ] to demonstrate . in the example network consisting of @xmath34 items , the left two items in grey",
    "are observed to be rated @xmath31-star and @xmath35-star respectively , while the right two ones in white wait predicting .",
    "as shown in figure [ fig : edge.usage.knn ] , knn collaborative filtering considers equation ( [ equ:2nd - derivative - vanish ] ) holding on unrated items as drawn in circles . each unobserved rating is estimated with observed neighbors .",
    "the upper right item has only one neighbor observed , the upper left item , and therefore its estimation simply equals @xmath31-star rating .",
    "the estimation is bounded by the @xmath31-star rating on its observed neighbor .",
    "the heat conduction process @xcite ( denoted as hcp in the rest of the paper ) points out the shortcoming of knn approach and improves the knn approach by calculating the second derivative with all neighbor ratings , no matter observed or unobserved . in order to break the dilemma that a pair of unobserved neighboring items wait for each other to complete the calculation first",
    ", the approach simultaneously estimate all unobserved ratings by solving a linear system consisting of equation ( [ equ:2nd - derivative - vanish ] ) on all unobserved items .",
    "however , the requirement that equation ( [ equ:2nd - derivative - vanish ] ) holds on all unobserved items is a strong assumption and therefore limits its performance .",
    "as shown in figure [ fig : edge.usage.hcp ] , hcp also considers equation ( [ equ:2nd - derivative - vanish ] ) holding on unrated items as drawn in circles .",
    "different from knn , an unobserved rating is estimated with observed and unobserved neighbors .",
    "the predicted rating of upper right item is calculated with its two neighbors , the observed upper left item and the unobserved lower right item .",
    "solving equation ( [ equ:2nd - derivative - vanish ] ) on the right two items simultaneously results in @xmath36-star and @xmath37-star ratings on them respectively .",
    "both estimators are bounded in the range of @xmath38 $ ] .    in our view of scalar function recovery , in order to estimate the second derivative as accurately as possible , the second derivative is also calculated using all neighbor ratings , no matter observed or unobserved .",
    "similarly , the recovery process also solves a bunch of instances of equation ( [ equ:2nd - derivative - vanish ] ) simultaneously to avoid the dilemma of mutually waiting .",
    "different from hcp , we expect equation ( [ equ:2nd - derivative - vanish ] ) hold on most items , no matter observed or unobserved , instead of all unobserved items . the distinct benefit of our method is explained as follows .    since an item with non - zero value of second derivative is probably rated higher than neighbor items ( local maxima of a rating function ) or lower than neighbor items ( local minima ) , it might represent the point a user loves or hates the most in a local range of dozens of items .",
    "the rating on such an item could be unobserved due to many reasons .",
    "for example , the user is lazy to label her favorite movie on a website since she registers for a dozen movie websites , or a user is reluctant to post a rating to an extremely boring book , etc . allowing equation ( [ equ:2nd - derivative - vanish ] ) not to hold on an unobserved item , we keep the possibility to view the unobserved item as a local favorite or dislike .",
    "symmetrically , since an unobserved item might be a local maximum or minimum , it is also possible that an observed item is not a local maximum or minimum , and furthermore it has a chance to have a zero valued second derivative .",
    "yet we do not exclude the possibility that equation ( [ equ:2nd - derivative - vanish ] ) holds on an observed item .    as shown in figure [",
    "fig : edge.usage.ihcp ] , sfr considers equation ( [ equ:2nd - derivative - vanish ] ) holding on some items .",
    "for example we take the upper left and lower right items as sources , drawn in boxes .",
    "the remaining two items , drawn in circles , are not considered as sources and are expected to satisfy equation ( [ equ:2nd - derivative - vanish ] ) .",
    "the missing ratings are predicted by simultaneously solving equation ( [ equ:2nd - derivative - vanish ] ) on the two non - source items , whose second derivatives are calculated with both observed and unobserved neighbors , as the arrows indicate .",
    "the results are @xmath35-star and @xmath39-star respectively , not bounded in the range of observed ratings .    in the demo",
    "all approaches predict with two instances of equation ( [ equ:2nd - derivative - vanish ] ) . in actual , since our approach seeks for a solution minimizing the number of sources ( discussed later ) , it is expected that the number of sources might be even smaller than the number of observed ones , and therefore the equations our approach uses might be more than the equations knn and hcp make use of . more equations could provide more evidence to accurately recover a scalar function .",
    ".different leverage of the linearity assumption by three approaches .",
    "[ cols=\"^,^,^\",options=\"header \" , ]      we test our approach on real datasets to examine its ability to solve the rating bound problem , compared with knn and hcp as baselines . based on ratings in the training set and an item - item network ,",
    "all approaches are tested to predict the ratings in the testing set which encounter the rating bound problem , i.e. , a ground truth rating in the testing set is higher or lower than all neighbor ratings in the training set .",
    "the prediction results are evaluated with rmse ( root - mean - square error ) and reported in table [ table : result.rating.bound ] , where `` higher '' and `` lower '' means the examples whose ratings are higher or lower than all observed neighbors respectively , and `` all '' means their combination .",
    "our approach shows consistently better ability to solve the rating bound problem on different datasets , with a reduction on prediction error by up to @xmath1 compared with knn .",
    "the improvement is even more significant on items whose ratings are higher than observed neighbors .",
    "since an item rated higher than neighbors is probably a user s positive interest center , our approach is expected to achieve much better user experience by accurately discover a user s favorites .     &",
    "knn & hcp & sfr + all & 1.532 & 1.287 & * 1.269 * + higher & 1.458 & * 1.086 * & * 1.086 * + lower & 1.594 & 1.437 & * 1.408 * +   + & knn & hcp & sfr + all & 1.566 & 1.404 & * 1.355 * + higher & 1.524 & 1.225 & * 1.211 * + lower & 1.597 & 1.521 & * 1.450 * +   + & knn & hcp & sfr + all & 1.849 & 1.303 & * 1.263 * + higher & 1.895 & 1.204 & * 1.185 * + lower & 1.760 & 1.472 & * 1.397 * +    furthermore , to analyze the approach performance on heterogeneous items , we classify the examples with the rating bound problem into subsets according to their real ratings , and report the prediction error on each subset respectively in figure [ fig : result.rating.bound ] .",
    "in the `` higher '' samples , both hcp and our approach largely reduce the prediction error compared with knn , and our approach outperforms hcp slightly .",
    "the reduction is almost the same in different subsets , supporting that the advantage is consistent .",
    "the only exception is that our approach fails to outperform knn in the subset of @xmath40-star rated items ( higher than observed neighbors ) in goodreads dataset , where the subset contains only @xmath41 examples and is not statistically significant . in the `` lower '' samples ,",
    "the improvement is not so large but our approach still outperforms two baselines in most cases .",
    "the improvement is more significant in high rated examples .",
    "the worst performance of knn attributes to the way it estimates the second derivative with partially observed neighbor ratings , while the significant improvement by hcp and our approach reveals the necessity to estimate the second derivative with all neighbors .",
    "besides , allowing an unobserved rating not necessarily satisfying equation ( [ equ:2nd - derivative - vanish ] ) makes it possible for our approach to discover uncovered interest centers for each user , which results in the reduction of prediction error our approach achieves compared with hcp predictions . to summarize , the empirical results support our claim that our approach has the ability to gain better prediction when encountering the rating bound problem , and",
    "therefore might be more applicable to discover a user s interest centers .",
    "personalized recommender systems have been a hot topic in the research literature for a decade @xcite .",
    "one of the earliest personalized approaches is named content - based method , which builds a profile for each user and each book with a vector of weights on different words .",
    "the approach estimates an unobserved rating with the dot product of a user vector and a book vector @xcite .",
    "although the approach is seldom used and soon replaced by collaborative filtering methods because its usage is limited in scenarios where an item can be explicitly parsed like a book , the form of dot product of a user vector and an item vector leaves the possibility that latent factor models arise .    due to",
    "the advantage that a content - based method solves half of the cold start problem by building a profile for each incoming book , recently researchers are seeking for an variation of it to reduce the pain of cold start .",
    "tag - based recommender systems are then developed to leverage user - generated tags to represent an item like videos or music which was difficult to explicitly parse @xcite .",
    "knn collaborative filtering techniques are developed to solve the problem left by content - based methods that items are not explicitly parsable .",
    "the series of approaches are built on the so - called similarity assumption that if two users behave similarly in the past they will behave similarly in the future @xcite .",
    "a user - based collaborative filtering technique calculates the similarity between two users with pearson s correlation coefficients and estimates a user s unobserved rating on a certain item with the weighted average rating that similar users post on that item .",
    "an item - based version calculates item similarity and predict in a symmetric way @xcite .",
    "recently researchers attempt to combine the two versions by simultaneously consider user - user and item - item similarities , and claim to gain better accuracy @xcite .",
    "pointing out the shortcoming that a knn collaborative filtering technique calculates the weighted average among observed neighbor ratings which may lead to inconsistency , zhang et al .",
    "propose the heat conduction process to estimate an unobserved rating with the weighted average rating of all neighbor ratings , no matter observed or unobserved . by simultaneously solving all unobserved ratings with a green function ,",
    "the method outperforms conventional knn collaborative filtering methods in prediction accuracy @xcite .",
    "a recent research work seeks for a unique set of global neighbors to be shared with all users and attempts to minimize the set size to achieve better accuracy and coverage @xcite .",
    "latent factor models represent a user and an item with a vector in a latent feature space , and estimate a rating with the dot product of a user vector and an item vector @xcite .",
    "different from standard matrix factorization tasks that the whole target matrix is observed , in a recommender system only partial entries in the rating matrix are observed , and therefore controlling the risk of over - fitting becomes a key point in the inference of a latent factor model .",
    "srebro et al .",
    "proposes a maximum margin constrain to control the structural risk represented by matrix rank @xcite , which is later incorporating with compressed sensing to find an accurate completion @xcite .",
    "salakhutdinov et .",
    "al introduces the probabilistic graphical model and controls the user vectors and item vectors with a gaussian prior @xcite .",
    "koren controls the @xmath42-norm of user and item vectors as a regularization term in the loss function when fitting the observations @xcite .    due to the different advantages and disadvantages of the two major schools of knn collaborative filtering and latent factor models , many researchers attempt to combine them to train a hybrid or ensemble model .",
    "a typical solution is incorporating one as a regularization into the other s framework @xcite .",
    "resource projection passes user interests back and forth in a bipartite consisting of users and items , resulting in adaptive balance between accuracy and diversity and showing good scalability when calculating on huge data @xcite .",
    "restricted boltzmann machine introduces a graphical model with a hidden layer to train user and movie profiles in an efficient and scalable way @xcite .",
    "with the recent explosion of social networking services , researchers attempt to incorporate recommender systems with social relations to reduce the pain of sparsity and cold start problem , such as running the pagerank algorithm on a social network @xcite , analyzing social influence in recommender systems @xcite , or training a latent factor model to fit observed ratings and social networks simultaneously @xcite .",
    "in recommender systems , it is crucial to accurately discover a user s interest centers , i.e. , the most favorite items .",
    "unfortunately , the commonly used neighborhood - based collaborative filtering methods fail to do so , as they suffer from the so - called rating bound problem .",
    "that is to say , the rating predicted with these methods on an item is fully bounded by those of observed ratings on neighboring items . as an interest center usually has a rating higher than the ratings of its observed neighbors , the aforementioned methods can not accurately predict its rating at all . to overcome this significant problem , we formulated information recommendation as a problem of recovering a scalar rating function , which was further solved by optimizing the @xmath0-norm of its second derivative . through carefully designed experiments on three real - world datasets , namely , douban , goodreads and movielens",
    ", we validated the effectiveness of the proposed approach .",
    "specially , we found that our approach can significantly reduce the prediction error by @xmath1 when discovering interest centers , as compared to the well - known knn collaborative filtering technique .",
    "in the view of this paper a scalar function is defined for each user independently .",
    "encouraged by some recent research works focusing on combining the traditional user - based and item - based collaborative filtering techniques , it is interesting to explore in our framework how to relate the scalar functions of similar users so that they could mutually borrow support on unobserved items . besides , it is an open question to introduce a background distribution as a prior to a scalar function , e.g. , the global opinion or topological property on an item might indicate its prior probability to be a source node .",
    "a.  boumaza and a.  brun . from neighbors",
    "to global neighbors in collaborative filtering : an evolutionary optimization approach . in _ proceedings of the fourteenth international conference on genetic and evolutionary computation conference _ , gecco 12 , pages 345352 , new york , ny , usa , 2012 .",
    "acm .",
    "j.  huang , x .- q .",
    "cheng , j.  guo , h .- w .",
    "shen , and k.  yang . social recommendation with interpersonal influence . in _ proceedings of the 19th european conference on artificial intelligence ( ecai 2010 ) _ , pages 601606 , amsterdam , the netherlands , 2010 .",
    "ios press .",
    "j.  huang , x .- q . cheng , h .- w .",
    "shen , t.  zhou , and x.  jin . exploring social influence via posterior effect of word - of - mouth recommendations . in _ proceedings of the fifth acm international conference on web search and data mining _ , wsdm 12 , pages 573582 , new york , ny , usa , 2012 .",
    "m.  jamali and m.  ester .",
    "trustwalker : a random walk model for combining trust - based and item - based recommendation . in _ proceedings of the 15th acm",
    "sigkdd international conference on knowledge discovery and data mining _ , kdd 09 , pages 397406 , new york , ny , usa , 2009 .",
    "m.  jamali and m.  ester . a matrix factorization technique with trust propagation for recommendation in social networks . in _ proceedings of the fourth acm conference on recommender systems",
    "_ , recsys 10 , pages 135142 , new york , ny , usa , 2010 .",
    "i.  konstas , v.  stathopoulos , and j.  m. jose .",
    "on social networks and collaborative recommendation . in _ proceedings of the 32nd international acm sigir conference on research and development in information retrieval _ , sigir 09 , pages 195202 , new york , ny , usa , 2009 .",
    "y.  koren .",
    "factorization meets the neighborhood : a multifaceted collaborative filtering model . in _ proceedings of the 14th acm sigkdd international conference on knowledge discovery and data mining _ , kdd 08 , pages 426434 , new york , ny , usa , 2008 .",
    "acm .",
    "h.  ma , i.  king , and m.  r. lyu .",
    "learning to recommend with social trust ensemble . in _ proceedings of the 32nd international acm sigir conference on research and development in information retrieval _ , sigir 09 , pages 203210 , new york , ny , usa , 2009 .",
    "h.  ma , h.  yang , m.  r. lyu , and i.  king .",
    "sorec : social recommendation using probabilistic matrix factorization . in _ proceedings of the 17th acm conference on information and knowledge management _ , cikm 08 , pages 931940 , new york , ny , usa , 2008 .",
    "p.  resnick , n.  iacovou , m.  suchak , p.  bergstrom , and j.  riedl .",
    "grouplens : an open architecture for collaborative filtering of netnews . in _ proceedings of the 1994 acm conference on computer supported cooperative work _",
    ", cscw 94 , pages 175186 , new york , ny , usa , 1994 .",
    "acm .",
    "r.  salakhutdinov and a.  mnih .",
    "bayesian probabilistic matrix factorization using markov chain monte carlo . in _ proceedings of the 25th international conference on machine learning _ , icml 08 , pages 880887 , new york , ny , usa , 2008 .",
    "r.  salakhutdinov , a.  mnih , and g.  hinton .",
    "restricted boltzmann machines for collaborative filtering . in _ proceedings of the 24th international conference on machine learning _ , icml 07 , pages 791798 , new york , ny , usa , 2007 .",
    "b.  sarwar , g.  karypis , j.  konstan , and j.  riedl .",
    "item - based collaborative filtering recommendation algorithms . in _ proceedings of the 10th international conference on world wide web _ , www 01 , pages 285295 , new york , ny , usa , 2001 . acm .",
    "s.  sen , j.  vig , and j.  riedl .",
    "tagommenders : connecting users to items through tags . in _ proceedings of the 18th international conference on world wide web _ , www 09 , pages 671680 , new york , ny , usa , 2009 .",
    "r.  sinha and k.  swearingen .",
    "the role of transparency in recommender systems . in _",
    "chi 02 extended abstracts on human factors in computing systems _ , chi ea 02 , pages 830831 , new york , ny , usa , 2002 .",
    "g.  takcs , i.  pilszy , b.  nmeth , and d.  tikk .",
    "matrix factorization and neighbor based algorithms for the netflix prize problem . in _ proceedings of the 2008 acm conference on recommender systems _ , recsys 08 , pages 267274 , new york , ny , usa , 2008 .",
    "b.  xu , j.  bu , c.  chen , and d.  cai .",
    "an exploration of improving collaborative recommender systems via user - item subgroups . in _ proceedings of the 21st international conference on world wide web _ , www 12 , pages 2130 , new york , ny , usa , 2012 ."
  ],
  "abstract_text": [
    "<S> as an important tool for information filtering in the era of socialized web , recommender systems have witnessed rapid development in the last decade . as benefited from the better interpretability , </S>",
    "<S> neighborhood - based collaborative filtering techniques , such as item - based collaborative filtering adopted by amazon , have gained a great success in many practical recommender systems . </S>",
    "<S> however , the neighborhood - based collaborative filtering method suffers from the rating bound problem , i.e. , the rating on a target item that this method estimates is bounded by the observed ratings of its all neighboring items . </S>",
    "<S> therefore , it can not accurately estimate the unobserved rating on a target item , if its ground truth rating is actually higher ( lower ) than the highest ( lowest ) rating over all items in its neighborhood . in this paper , we address this problem by formalizing rating estimation as a task of recovering a scalar rating function . with a linearity assumption , we infer all the ratings by optimizing the low - order norm , e.g. , the @xmath0-norm , of the second derivative of the target scalar function , while remaining its observed ratings unchanged . </S>",
    "<S> experimental results on three real datasets , namely douban , goodreads and movielens , demonstrate that the proposed approach can well overcome the rating bound problem . </S>",
    "<S> particularly , it can significantly improve the accuracy of rating estimation by @xmath1 than the conventional neighborhood - based methods . </S>"
  ]
}