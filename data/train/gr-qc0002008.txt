{
  "article_text": [
    "in table i there is a list of the five cryogenic resonant antennas now in operation .",
    "these detectors are aluminum ( niobium in the case of the australian one ) cylindrical bars , all equipped with resonant transducers , that give them two narrow bands of detection of a few hertz around the two near coupled modes of the bar - transducer system , at frequencies of about 900 hz ( about 700 hz for niobe ) .",
    "these are called the detection bands of the antenna ; in some detectors they can constitute a single wider band .",
    "the orientation of the bars was chosen in order to achieve the maximum parallelism of the bars .    in order to coordinate and correlate the data produced by these detectors , in july 1997",
    ", all the groups that operate them have undersigned a data exchange protocol named  international gravitational event center  (  igec  ) .",
    "it is based on some technical and policy rules .",
    "the main points are :    - the data consist of  candidate events  and service information .",
    "- the minimum information about each event consist of the time of the event maximum , the amplitude in units of standard burst strain , the duration and the mean detector noise at the time of the event",
    ".    - additional fields , giving further information on the candidate events ( e.g. the shape and/or parameters relating the shape ) may be provided .    - time accuracy will be at least 0.1 s.    - each group will set up a site ( ftp , www , ... ) on which the data will be continuously available in agreed formats , with an updating rate not exceeding one day .",
    "the full text of the agreement , together with other data exchange documents , is posted at _ http://grwav1.roma1.infn.it/gwda/de/de.htm _ .",
    "in this paper i will show how the candidate events are produced by the rome group ( that is operating the two cryogenic resonant antennas explorer and nautilus ) and how the igec data can be analyzed .",
    "the simplified modelisation of the detector as a linear system is normally very good and the gravitational signal is simply added to the noise ; nevertheless the detection of short gravitational pulses ( with unknown shape ) in the data of gravitational wave antennas is not an easy task .",
    "the main reasons are :    - the low signal - to - noise ratio ( snr ) and the rarity of the expected pulses    - the ignorance of their shape    - the non - stationarity of the noise of the detectors and the presence of many spurious events .    as regards the shape of the pulses , resonant antenna people normally consider as a standard pulse a delta function ( or the part of that signal in the detector band ) that , in the data at the output of the antenna , becomes a known waveform .",
    "the noise is considered gaussian and stationary ( also if some consider it slowly non - stationary ) , completely described by the noise power spectrum .    with these assumptions ,",
    "the problem becomes the classical problem of detecting a known waveform in gaussian noise , that is optimally solved by the ",
    "matched filter  .",
    "this filter is a non - causal linear system that has the property that at its output the signal - to - noise ratio ( i.e. the ratio between the square of the maximum of the signal and the variance of the noise ) is maximized .",
    "this means that , if we normalize the filter in order to have the same amplitude of the maximum of the input and output signal , the output noise ( that is also gaussian because of the linearity of the filter ) , has the minimum variance , so the probability that the noise samples exceed the threshold is minimized .",
    "there are many ways to express the equation of the matched filter . in the frequency domain",
    "it is    @xmath1    where @xmath2 is the complex conjugate of the fourier transform of the response of the antenna to the standard pulse and @xmath3 is the noise power spectrum .    as a matter of fact ,",
    "each group implement practically the filter in one or more different ways .",
    "this because :    - there are different ways of taking data ( high frequency sampling , aliased sampling , two lock - ins acquisition , single central lock - in , ... )    - the use of frequency domain procedures or time domain procedures    - the use of adaptive or non - adaptive procedures    - the threshold mechanism    - particular procedures of event features estimation and/or spurious event detection .    in our case ( ref @xcite ) , the most advanced procedure that we use is based on a high frequency sampling ( 5000 hz ) , from which we extract a band of 40 hz centered at 816 hz , containing the detection bands .",
    "other bands are also analyzed in order to monitor the behavior of the antenna and the presence of local disturbances , but this will not be discussed here .    on these data we implement three adaptive matched filters ( and also filters of other types ) , followed by a two state adaptive threshold mechanism .",
    "the noise power spectrum of our antennas is not stationary : both the electric noise , that normally gives a wide - band and a narrow band contributions , and the seismic noise , that gives normally a narrow band contribution , change with time .",
    "moreover often extra noise peaks appear in the spectrum , due to local disturbances .",
    "these bands change slowly in amplitude and in frequency .",
    "almost all these non - stationarities have time constants of at least a few hours .",
    "the presence of the non - stationarities can be seen as the fact that the detector has a time - varying sensitivity .",
    "also the resonance frequencies of the antennas can slowly change , mainly because of the change in the transducer polarization voltage . in order to have a good filter in presence of these varying features of the detectors , we use an adaptive approach : we apply the filter in the frequency domain , using the expression of eq.[mf ] and use , for the power spectrum , a first - order auto - regressive sum of the periodograms , with a time constant of one hour and with an updating rate of about one minute .",
    "the filter is so recomputed about every minute ; this is our  basic  adaptive filter .    in presence of a big disturbance ,",
    "the basic filter estimated spectrum is  dirtied  and can remain dirty for a long time ( also many time constants ) after the end of the disturbance , producing filters that are not optimal for the ",
    "clean  data . to solve this problem ,",
    "we have implemented a matched filter that uses only ",
    "periodograms for the estimation of the power spectrum .",
    "we studied also another policy that gets good results in the case that the disturbed period can be seen as a low sensitivity period .",
    "it is based on the reduction of the auto - regressive time constant in the case of highly disturbed spectra .    in order to evaluate the performances of the different filters , we add to the acquired data fictitious",
    " theoretical ",
    "pulses and analyze the resulting snr ; this is done every half an hour , disturbing the real data for less than the @xmath4 of the time .",
    "we chose as  official filter  the filter that gives the better results at that time .",
    "this procedure provides also a sort of monte carlo check procedure for the whole system and can be used also to analyze the behavior in case of non - delta - pulse events .",
    "because of the non - stationarity of the antenna noise , also at the output of one matched filter ( or of any linear filter ) the noise is not stationary , i.e. the variance of the noise changes ( slowly ) with the time ; this means that the sensitivity of the detector changes with the time . if we put a fixed threshold on these data , we have more ( spurious ) candidate events when higher is the noise ( and lower is the sensitivities ) and this can highly worsen the statistics .",
    "so we must change the threshold with the time .",
    "this can be done in various ways , for example choosing a fixed number n and taking the n highest events of each hour .",
    "we use a different procedure , based on an  adaptive threshold  defined in the following way .",
    "let @xmath5 be the filtered data samples .",
    "we estimate the background statistics by computing the auto - regressive mean of the absolute value and of the square of @xmath5    @xmath6    @xmath7    with @xmath8 where @xmath9 is the sampling time and @xmath10 is the  memory  of the auto - regressive mean ( we normally chose @xmath11 ) .",
    "then we define the standard deviation @xmath12 and the threshold @xmath13 is not set on @xmath14 , but on the critical ratio of @xmath14 given by @xmath15    this procedure was developed for the general case of @xmath5 ; if @xmath5 is simply zero mean , as is in the case of the matched filter , the algorithm for estimating the adaptive threshold can be simplified , using just the estimation @xmath16 and computing the critical ratio as @xmath17 .    in case of very large value of @xmath18 ,",
    "we can reduce the memory @xmath19 in order to reduce the  blinding  effect at the end of large disturbances .      in order to define candidate events ,",
    "let us suppose that we have chosen an adaptive threshold @xmath20 and a dead time ( that is the minimum time between two different events ; it depends on the apparatus , the noise and the expected signal : we normally use 3 s ) .",
    "then we use an easy two - state ( 0 and 1 ) mechanism that we call the  event machine  .",
    "the algorithm performed is the following .",
    "- the machine is normally set in the state @xmath21 .",
    "- when the signal goes over the threshold , it changes to state @xmath22 and an event begins .    -",
    "the state changes to @xmath21 after the signal has remained below the threshold for a time longer than the dead time .",
    "- the  duration  of the event is the duration of the state @xmath22 , subtracted the dead time .",
    "a simplified model of this algorithm ( ref @xcite ) is a two - state markov chain ( in the discrete time ) .",
    "its transition matrix is @xmath23 where @xmath24 and @xmath25 are the transition probability for the two states .",
    "we can easily compute the probabilities of the two states as @xmath26 @xmath27 and the mean length ( in unit of sampling time ) @xmath28      we can define the event density @xmath29 as the number of the events per unit time and then the candidate events production can be modeled by a poisson process with parameter @xmath29 .    obviously the value of @xmath29 depends on the value of the adaptive threshold @xmath13 .",
    "the functional dependence of @xmath29 on @xmath13 depends on the distribution of the filtered data ( or , more precisely , on its tail ) , that only theoretically is gaussian ; in practice it depends strongly on the local disturbances .",
    "this is what finally limits the sensitivity of a single antenna .",
    "however , because the disturbances give heavy tails in the distributions , reducing the threshold ( and so enhancing the sensitivity ) in this region gives a not big increment on @xmath29 .",
    "it is not so for the gaussian distribution ( that has light tails ) .",
    "if we consider the case of @xmath30 antennas , each defined with a @xmath31 , and if we choose a coincidence window of duration @xmath32 , in the hypothesis of uncorrelated data , that is that of the background noise event , we have an expected density of  casual  coincidences given by @xmath33 @xmath32 is chosen depending on the apparatuses , the time precision and the light time delay between the antennas ; good values ranges between @xmath34 and @xmath35 . in table 2",
    "there are some values for the coincidence densities ( expressed in number of coincidences per day ) for the case that all @xmath36 s are equal to the value @xmath29 and @xmath37 .",
    "@xmath38    in order to evaluate the statistical significance of the found coincidences , one should consider the appropriate poisson statistics .",
    "anyway , the poisson model is normally not a good approximation , because of all the non - stationarities in the detection process . in practice",
    "the @xmath39 s are functions of the time . in particular ,",
    "there are    - periodicities ( e.g. the solar day )    - aggregation ( the disturbances often are clustered in time )    - holes in the data .    also the signals ( the  true  events ) are not expected to be uniformly distributed in time , because of the radiation pattern of the antennas and the non - uniformity of the space distribution of the biggest sources , that causes a sidereal day modulation of the detection probability .",
    "to have an efficient evaluation method in presence of this problems , in the case of two antennas , weber introduced a non - parametric procedure , that we call `` pulse correlation '' .",
    "the pulse correlation method is based on the evaluation of the casual (  background  )",
    "coincidence rate for two antennas obtained by adding a bias time @xmath10 to the eventts of one antenna .",
    "@xmath10 is normally set equal to @xmath40 , with @xmath41 integer and @xmath42 ( e.g. , @xmath43 can be set equal to 1000 ) .    taken a period of time @xmath44 ( e.g. one day , one month , ... ) the number of coincidences @xmath45",
    "are computed .",
    "if we take the mean value @xmath46 of @xmath45 excluding @xmath47 , the estimated number of  true  coincidences is given by @xmath48 if @xmath49 .",
    "we can define @xmath50 as the estimated chance coincident event density ( analogous to @xmath51 for the equation [ lam ] ) .    because of the non - stationarities , the expected shape of @xmath45 for @xmath52 is not uniform and the evaluation of @xmath46 deserves some cares .",
    "i would note the analogy between the pulse correlation function and the classical cross - correlation function .    to evaluate the chance probability of having @xmath47",
    ", one can use one of the two following methods :    \\a ) use the poisson statistics with parameter @xmath46    \\b ) compute the histogram of @xmath45 and evaluate the ",
    "probability of having @xmath47 .",
    "both methods must be used with care , the first because of the uncertainty in the evaluation of @xmath46 and the second because it assumes that the event production is stationary on times of the order of @xmath53 .",
    "a particular use of the pulse correlation is in correlating the events of an antenna with themselves (  pulse auto - correlation  ) .",
    "this method of analysis can be used to identify the non - stationarities of the events : in particular aggregation and periodicities .    the pulse correlation can be applied on data selected by some  single event  rules ( e.g.",
    "the amplitude or the time of occurrence , that can be a particular solar or sidereal hour ) or  coincidence  rules ( e.g. consider a coincidence only if the amplitude and/or the duration of the two events is about the same ) .    in the evaluation of the probabilities",
    ", particular care must be taken on any choice made  a posteriori  .",
    "how can we generalize the pulse correlation in the case of @xmath54 antennas ? consider the following two methods :    \\a ) the * couple pulse correlation , * obtained summing the pulse correlation of all the @xmath55 couples of antennas .",
    "we obtain a function @xmath56 . with these method",
    "there is a ",
    "natural  weighting of multiple coincidences .",
    "in fact a coincidence between only two antennas is considered just once , a coincidence between 3 antennas is considered 3 times , a 4 antennas coincidence it is considered 6 times and a 5 antennas coincidence is considered 10 times .",
    "the background is the sum of all the backgrounds .",
    "\\b ) the * multiple pulse correlation * @xmath57 * , * obtained by adding to the events of each of the first @xmath58 antennas a different bias time .",
    "the delay variables @xmath59 can be chosen equal to @xmath40 , with @xmath42 ( e.g. , @xmath43 can be set equal to 10 ; in this case , with five antennas , we have 194481 delays ) .",
    "in searching for coincidences for more then two antennas , it must be taken into account that , in case of not too much big gravitational events , the probability that an event is overlooked by a detector is not negligible .",
    "this because of the presence of the additive noise ( see , for example , ref @xcite ) , the difference in the frequencies , the not perfect parallelism and the difference in sensitivities , that , also if are basically similar , change in time depending on the local noises .",
    "so methods like the multiple pulse correlation are good only in case of huge events and , for small events , would produce a false dismissal probability near to 1 .",
    "more complex procedures were presented in ref @xcite . with these procedures , with five detectors",
    "it is possible to estimate also the position of the source in the sky and the polarization of the gravitational pulse , together with a better estimate of its energy .",
    "also the rejection of spurious events is enhanced .",
    "unfortunately these methods get poor results with parallel antennas .",
    "because of the rarity of the gravitational events , it is important to not overlook the presence of real events in the data . so any method used to reduce the false detection probability , should not enhance too much the false dismissal probability .",
    "this means that we should reject a candidate event only after a careful analysis .    on the other hand ,",
    "also very low probability coincidence events must be carefully checked for consistency , e.g. to compare the amplitudes and the lengths in the different antennas or to check in the other antennas , that did not detect events at that time , if there is  something ",
    "( i.e. an event under the threshold ) .    as it is shown in table 2 , the multiple coincidence operation ( 2 or 3 antennas on 5 )",
    "reduces strongly the number of candidate events ; this can be done automatically .",
    "for the surviving candidates we should analyze carefully ( i.e. not automatically ) the outputs of all the antennas in operation , the signal shapes and the auxiliary channels .      a very important information to take into account are other impulsive astrophysical events , e.g. the gamma ray bursts and the neutrinos bursts detected in underground experiments .",
    "these must constitute a complementary data base to be analyzed routinely together with the candidate events .",
    "also supernova surveys can be useful , in order to correctly interpret the other detector results , also if they do nt give precise events time .",
    "99 frasca s. , papa m.a .",
    "jour . of mod phys .",
    "d , vol . 4 , ( 1995 ) 1 - 50 frasca s. , mazzitelli g. , papa m.a .",
    ", in _ general relativity and gravitational physics _ , 1997 , p. 475",
    "astone p. , pallottino g.v .",
    ", pizzella g. , in press on gen .",
    "rel . and grav ."
  ],
  "abstract_text": [
    "<S> five cryogenic resonant gravitational antennas are now in operation .    </S>",
    "<S> this is the first time that such a large number of high sensitive antennas are taking data and an agreement on data exchange has been signed by the responsible groups .    the data exchanged will consist essentially in lists of  candidate events  .    </S>",
    "<S> in this paper the procedure used by the rome group in order to obtain  candidate events  is presented .    </S>",
    "<S> some methods of analyzing the data of the `` network '' of the five antennas are shown . </S>"
  ]
}