{
  "article_text": [
    "it is well understood that fractional - order derivatives provide a good tool for the description of memory and hereditary properties of various processes , fractional - order systems being characterized by infinite memory .",
    "generalizations of dynamical systems using fractional - order derivatives instead of classical integer - order derivatives have proved to be useful and more accurate in the mathematical modeling of real world phenomena arising from several interdisciplinary areas such as : diffusion and wave propagation , viscoelastic liquids , fractional kinetics , boundary layer effects in ducts , electromagnetic waves , electrode - electrolyte polarization",
    ".    theoretical characterization of chaos in fractional - order dynamical systems is yet to be investigated .",
    "however , chaotic behavior has been observed by numerical simulations in many systems such as : a fractional - order van der pol system @xcite , fractional - order chua and chen s systems @xcite , a fractional - order rossler system @xcite and a fractional - order financial system @xcite .",
    "nevertheless , it is worth noting that numerical simulations are limited by the fact that they only reveal the chaotic behavior of discrete - time dynamical systems that are obtained by discretizing the fractional - order systems .    in order to assess chaotic behavior of fractional - order dynamical systems ,",
    "it is extremely important to be able to accurately estimate the solutions over a large time interval .",
    "several numerical methods are used for fractional - order systems , such as a generalization of the adams - bashforth - moulton @xcite predictor - corrector method or a class @xcite of p - fractional linear multistep methods .    for the numerical assessment of chaotic behavior of fractional - order systems",
    ", it is extremely important to accurately estimate the solutions over a large time interval . in numerical schemes such as the adams - bashforth - moulton predictor - corrector method , due to the hereditary nature of the problem and the non - locality of fractional - order derivatives , at every iteration step all previous iterations have to be taken into account",
    ". it may be feasible to overcome these difficulties with the aid of parallel computing algorithms ( e.g. @xcite ) implemented in a conventional way or using available high performance computing systems .    in this paper we present the case of adams - bashforth - moulton predictor - corrector method and measure the speedup of two parallel approaches by using gpu and hpc implementations . in the following",
    ", we will present the theoretical problem , we will describe the parallel dynamic scheme and then we will present our simulation results and our conclusions .",
    "were trying to solve an ordinary fractional differential equation of the form : @xmath0\\\\ y^{(k)}(0 ) = y_0^{k } , & k \\in \\{0 , \\dots , { \\left\\lceil \\alpha \\right\\rceil } - 1\\ } , \\end{cases}\\ ] ] where @xmath1 $ ] and @xmath2 denotes the ceiling function that rounds up to the nearest integer .",
    "the fractional derivative is defined as : @xmath3    the numerical method used to solve   is a fractional version of the adams - bashforth - moulton method ( a classic predictor - collector method ) presented also in figure [ alg : abm ] .",
    "the domain @xmath4 $ ] is discretized into @xmath5 intervals with a step size @xmath6 and the grid points @xmath7 , for @xmath8 .",
    "we will also denote @xmath9 and @xmath10 with @xmath11 as the initial condition .",
    "since we restrict @xmath12 to the @xmath13 $ ] interval , we do not require any of the higher derivatives of the initial condition .",
    "the first step of the scheme is the * predictor * , which will give a first approximation @xmath14 of our solution : @xmath15 where the weights @xmath16 are given by : @xmath17    the second and final approximation of our solution , called the * corrector * , is given by : @xmath18    where the weights @xmath19 and @xmath20 are defined as : @xmath21 and @xmath22    the most difficult part of numerically solving such equations consists in the fact that at each step , we require the complete history of the variable . that is to say , to compute @xmath23 , we need to know all the previous values @xmath24 that are used to compute @xmath25 , for @xmath26 .",
    "this makes fractional differential equations notoriously hard to parallelize .",
    "some attempts have been made , see  @xcite for a new method created specifically for fractional differential equations or  @xcite for an adaptation of the _ parareal _  @xcite method to this kind of equations .",
    "the first algorithm we are going to look at proposes to break up all the @xmath5 time steps between the @xmath27 processes we have , giving : @xmath28 steps per process ( see figure  [ fig : partition ] )    ( 0 , 0 ) ",
    "( 3 , 0 ) ; in 0 , 0.5, ...",
    ",1 ( , -0.05 ) ",
    "( , 0.05 ) ; at ( , -0.05 ) [ below ] @xmath29 ; in 2 , 2.5, ... ,3 ; ( , -0.05 ) ",
    "( , 0.05 ) ; at ( , -0.05 ) [ below ] @xmath30 ;    ( 0,-0.4 )  ( 1,-0.4 ) ; ( 2,-0.4 )  ( 3,-0.4 ) ;    at ( 0.5 , -0.6 ) [ below ] process @xmath31 ; at ( 2.5 , -0.6 ) [ below ] process @xmath32 ; at ( 1.5 , -0.2 ) @xmath33 ;    during an iteration @xmath34 , a process @xmath35 that represents the block in which we can find @xmath34 , that is to say if @xmath36\\ ] ] will compute the value of @xmath37 .",
    "this is done by computing a partial sum in each process @xmath38 and gathering the results to finally form the complete sum as defined in  .",
    "one major downside of the algorithm we are going to describe is that given a fix number @xmath27 of processes , most of them will be idle for a big part of the computations . to be exact , they will be idle as long as : @xmath39 that is to say , as long as the current iteration has not reached the block corresponding to process @xmath35 .",
    "=    = = by 2 by -2 bywidthheight 0pt depth 0pt",
    "on our tests we used uvt s bluegene / p cluster that consists of an fully loaded single bluegene / p rack that has move than 1000 cpus and 4 tb of ram memory . it can offer a 11.7 tflops sustained performance .",
    "one important issue of the algorithm described previously ( algorithm [ alg : abm ] ) is that for a fix number @xmath27 of processes , most of them will be idle for the time when the sum is computed from the partial results that are gathered .",
    "below are several simulation to find a balance for this drawback .",
    "we made several simulation of computing a number of elements , with different number of processes , and we observe the average running time for different time computation per process :    .bluegene simulation [ cols= \" > , > , > , > , > \" , ]     [ table : avgruntime ]      the parallel algorithm for the adams - bashforth - moulton scheme using mpi ( algorithm 1 ) was been also adapted for cuda .",
    "the parabm algorithm in this case suffered few changes : the partial sums are computed using parallel sum reduction ; the weights @xmath19 , @xmath40 , @xmath20 not being dependent on terms being computed in advance via previous steps , they can be preprocessed in parallel , taking into consideration that each thread n computes the weight at time n.    in table [ table : avgruntime ] we compare all together the absolute average time of multiple gpu cores versus multiple cpus .",
    "we can observe in figure [ fig : hpcvsgpu ] that in both cases the absolute processing time is increasing with number of steps .",
    "it is surprising that we obtained on hpc cpu a lower rate versus gpu , that tell us we should look carefully to the hpc processing time and idle time on the future .",
    "[ h ]        in both approaches we simulate the three - dimensional hindmarsh - rose model @xcite and we observed ( figure [ fig : numerical ] ) that is important to have a big number of steps in numerical simulation because the solution stability can not be seen even after a huge number of iterations , which could take very long time to simulate without parallel processing .",
    "we observed that fixing the number of processes that we need for a run is a huge problem which can be solved by adding new processes as the iteration progress or with iterative algorithms that does not start all the treads / processes at the very early beginning .    using cuda to simulate such an algorithm was not a bad idea , however computing at each step of evolution the convolution for the entire history needs complicated reductions algorithms , which should be investigated closely in the future .",
    "we present here few results from our work in progress , as a future work we should continue to investigate in both hpc and gpu approaches , what is the best way to find the numerical solution for such fractional - order systems .",
    "further simulations would possible give us a way for the best compromise in both cases hpc od gpu .",
    "this research has been supported by cncs idei grant pn - ii - ru - te-2014 - 4 - fradys : `` theoretical and numerical analysis of fractional - order dynamical systems and applications '' ."
  ],
  "abstract_text": [
    "<S> in this paper , we explore how numerical calculations can be accelerated by implementing several numerical methods of fractional - order systems using parallel computing techniques . </S>",
    "<S> we investigate the feasibility of parallel computing algorithms and their efficiency in reducing the computational costs over a large time interval . particularly , we present the case of adams - bashforth - mouhlton predictor - corrector method and measure the speedup of two parallel approaches by using gpu and hpc cluster implementations .    </S>",
    "<S> * keywords : * fractional - order systems , parallel numerical algorithms , gpu processing , hpc processing </S>"
  ]
}