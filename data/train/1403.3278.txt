{
  "article_text": [
    "a growing number of publications is devoted to the problem of statistical inference on heavy - tailed distributions .",
    "such distributions naturally appear in finance , meteorology , hydrology , teletraffic engineering , etc . @xcite .",
    "in particular , it is widely accepted that frequent financial data ( e.g. , daily and hourly log - returns of share prices , stock indexes and currency exchange rates ) often exhibits heavy tails @xcite , while less frequent financial data is typically light - tailed .",
    "the heaviness of a tail of the distribution appears to be responsible for extreme movements of stock indexes and share prices .",
    "the tail index indicates how heavy the tail is ; extreme quantiles are used as measures of financial risk @xcite . the need to evaluate the tail index and extreme quantiles stimulated research on methods of statistical inference on heavy - tailed data .",
    "the distribution of a random variable ( r.v . )",
    "@xmath7 is said to have a _ heavy right tail _ if @xmath8 where the ( unknown ) function @xmath9 is slowly varying at infinity : @xmath10 we denote by @xmath11 the non - parametric class of distributions obeying ( [ t1 ] ) .",
    "the tail index @xmath12 is the main characteristic describing the tail of a distribution . if @xmath13 then @xmath14 is called the tail constant .",
    "let @xmath15 denote the distribution function ( d.f . ) . obviously , the tail index is a functional of the distribution function : @xmath16 if @xmath17 tends to a constant ( say , @xmath18 ) as @xmath19 then the tail constant is also a functional of @xmath20 : @xmath21    the statistical inference on a heavy - tailed distribution is straightforward if the class of unknown distributions is assumed to be a regular parametric family .",
    "the drawback of the parametric approach is that one usually can not reliably check whether the unknown distribution belongs to a chosen parametric family .",
    "a lot of attention during the past three decades has been given to the problem of reliable inference on heavy tails without parametric assumptions .",
    "the advantage of the non - parametric approach is that a class of unknown distributions , @xmath22 is so large that the problem of testing the hypothesis that the unknown distribution belongs to @xmath23 does not arise .",
    "the disadvantage of the non - parametric approach is that virtually no question concerning inference on heavy tails can be given a simple answer . in particular , the problem of establishing a lower bound to the accuracy of tail index estimation remained open for decades .    a lower bound to the accuracy of statistical inference sets a benchmark against which the accuracy of any particular estimator can be compared .",
    "when looking for an estimator @xmath24 of a quantity of interest , @xmath25 where @xmath26 is the unknown distribution , @xmath27 is the class of distributions and @xmath28 is a functional of @xmath29 one often would like to choose an estimator that minimises a loss function uniformly in @xmath30 ( e.g. , @xmath31 where @xmath32 is a particular loss function ) .",
    "a  lower bound to @xmath33 follows if one can establish a lower bound to @xmath34    the first step towards establishing a lower bound to the accuracy of tail index estimation was made by hall and welsh @xcite , who proved the following result .",
    "note that the class @xmath11 of heavy - tailed distributions is too `` rich '' for meaningful inference , and one usually deals with a subclass of @xmath35 imposing certain restrictions on the asymptotics of @xmath36 .",
    "hall and welsh dealt with the class @xmath37 of distributions on @xmath38 with densities @xmath39 where @xmath40 @xmath41 @xmath42 .",
    "note that the range of possible values of the tail index is restricted to interval @xmath43 $ ] .",
    "let @xmath44 be an arbitrary tail index estimator , where @xmath45 are independent and identically distributed ( i.i.d . )",
    "random variables , and let @xmath2 be a sequence of positive numbers . if @xmath46 then @xmath47 ( to be precise , hall and welsh @xcite dealt with the random variables @xmath48 where @xmath49 are distributed according to ( [ tdens ] ) ) .",
    "beirlant et al .",
    "@xcite have a similar result for a larger class @xmath50 of distributions but require the estimators are uniformly consistent in @xmath51 .",
    "pfanzagl @xcite has established a lower bound in terms of a modulus of continuity related to the total variation distance @xmath52 .",
    "let @xmath53 be the class of distributions with densities ( [ tdens ] ) such that @xmath54 , and set @xmath55 where @xmath1 is the tail index of distribution @xmath56 and @xmath57 is a neighborhood of @xmath58 pfanzagl has showed that neither estimator can converge to @xmath12 uniformly in @xmath59 with the rate better than @xmath60 and @xmath61 donoho and liu @xcite present a lower bound to the accuracy of tail index estimation in terms of a modulus of continuity @xmath62 .",
    "however , they do not calculate @xmath63 .",
    "the claim that a particular heavy - tailed distribution is stochastically dominant over all heavy - tailed distributions with the same tail index appears without proof .",
    "assuming that the range of possible values of the tail index is restricted to an interval of fixed length , drees @xcite derives the asymptotic minimax risk for affine estimators of the tail index and indicates an approach to numerical computation of the asymptotic minimax risk for non - affine ones .",
    "the paper presents a simple method of deriving minimax lower bounds to the accuracy of non - parametric inference on heavy - tailed distributions .",
    "the results are non - asymptotic , the constants in the bounds are shown explicitly , the range of possible values of the tail index is not restricted to an interval of fixed length .",
    "the information functional seems to be found for the first time , as well as the lower bound to the accuracy of extreme quantiles estimation .",
    "the results indicate that the traditional minimax approach may require revising .",
    "the classical approach suggests looking for an estimator @xmath64 that minimises , say , @xmath65 ( cf .",
    "@xcite ) , while our results suggest looking for an estimator @xmath66 that minimises @xmath67 where @xmath68 is the `` information functional '' ( an analogue of fisher s information ) . theorems [ lp-1][lp-3 ] reveal the information functionals and indicate that the normalising sequence of a robust estimator should depend in a specific way on the characteristics of the unknown distribution .",
    "in the sequel , we deal with the non - parametric class @xmath69 of distributions on @xmath70 , where @xmath71 and @xmath72 is the left end - point of the distribution . if @xmath73 then @xmath74 the class @xmath75 is larger than @xmath76 ; the range of possible values of the tail index is not restricted to an interval of fixed length . below , given a distribution function ( d.f . ) @xmath77 , we put=-1 @xmath78=0 @xmath79 means the mathematical expectation with respect to @xmath80 and @xmath81 is the corresponding distribution .",
    "we set @xmath82 .",
    "[ lp-1 ] for any @xmath83 @xmath84 any tail index estimator @xmath85 and any estimator @xmath24 of index @xmath86 there exist d.f.s @xmath87 such that @xmath88 and @xmath89 as @xmath90 and @xmath91 $ ] .",
    "note that if @xmath92 as @xmath93 then for any @xmath94 we have @xmath95 for all large enough @xmath96 , yielding @xmath97 .",
    "thus , the hall ",
    "welsh result follows from  ( [ lp1 ] ) .",
    "theorem [ lp-1 ] shows that the natural normalising sequence for @xmath98 is @xmath99 the information functional @xmath100 plays here the same role as fisher s information function in the fr ' echet  rao  cramr inequality .",
    "theorem [ lp-1 ] yields also minimax lower bounds to the moments of @xmath101 in particular , there holds    [ lp - c ] for any @xmath83 @xmath102 there exist distribution functions @xmath103 such that @xmath104 and for any tail index estimator @xmath85 @xmath105 the result holds if @xmath106 in ( [ lpc ] ) is replaced with @xmath107    let @xmath108 be a class of d.f.s such that @xmath109 as @xmath110 .",
    "then for any estimator @xmath85    @xmath111    a lower bound to @xmath112 seems to be established for the first time .",
    "the presence of the information functional makes the bound non - uniform .",
    "note that a uniform lower bound would be meaningless : as the range of possible values of @xmath113 is not restricted to an interval of fixed length , it follows from ( [ lpcast ] ) that @xmath114 more generally , @xmath115 may tend to @xmath116 as @xmath117 if @xmath118 .",
    "let @xmath119 be an arbitrary tail constant estimator .",
    "the next theorem presents a lower bound to the probabilities @xmath120 .",
    "[ lp-2 ] let @xmath119 be an arbitrary tail constant estimator .",
    "for any @xmath121 and @xmath102 there exist distribution functions @xmath122 such that @xmath123 and for all large enough @xmath96 , as @xmath124 $ ] , @xmath125 where @xmath126    similarly to ( [ lpc ] ) theorem [ lp-2 ] yields lower bounds to the moments of @xmath127 in particular , ( [ lp4 ] ) entails    @xmath128    according to hall and welsh @xcite , @xmath129",
    "if @xmath130 . this fact can be obtained as a consequence to theorem [ lp-2 ] : if @xmath131 as @xmath93 then for any @xmath94 we have @xmath132 for all large enough @xmath96 , hence @xmath133 .",
    "we now present a lower bound to the accuracy of estimating extreme upper quantiles .",
    "we call an upper quantile of level @xmath134 `` extreme '' if @xmath135 tends to 0 as @xmath136 grows . in financial applications ( see , e.g. , @xcite ) , an upper quantile of the level as high as 0.05 can be considered extreme as the empirical quantile estimator appears unreliable .",
    "of course , there is an infinite variety of possible rates of decay of @xmath137 theorem [ lp-3 ] presents lower bounds in the case @xmath138 where @xmath139 is bounded away from @xmath140 and @xmath116 .",
    "set @xmath141 we denote the upper quantile of level @xmath142 by @xmath143 let @xmath144 be an arbitrary estimator of @xmath145",
    ". denote @xmath146 .",
    "[ lp-3 ] for any @xmath83 @xmath102 there exist distribution functions @xmath147 such that @xmath148 and for all large enough @xmath136 and @xmath149 @xmath150 where @xmath151 as @xmath117 .",
    "our approach to establishing lower bounds requires constructing two distribution functions @xmath152 and @xmath153 where @xmath152 is a pareto d.f .",
    "and @xmath154 is a `` disturbed '' version of @xmath152 .",
    "we then apply lemma [ lbh ] that provides a non - asymptotic lower bound to the accuracy of estimation when choosing between two close alternatives .    the problem of estimating the tail index , the tail constant and @xmath155 from @xmath45 is equivalent to the problem of estimating @xmath156 @xmath157 and quantiles from a sample @xmath158 of i.i.d .",
    "positive r.v.s with the distribution @xmath159 where function @xmath160 slowly varies at the origin .",
    "we denote by @xmath161 the class of distributions obeying ( [ t2 ] ) .",
    "note that @xmath162 if and only if @xmath163 obviously , a tail index estimator @xmath164 can be considered an estimator @xmath165 of index @xmath12 from the sample @xmath166 , and vice versa .",
    "the tradition of dealing with this equivalent problem stems from @xcite .",
    "we proceed with this equivalent formulation .",
    "a counterpart to @xmath75 is the following non - parametric class of d.f.s on @xmath70 : @xmath167 where @xmath71 and @xmath168 is the right end - point of @xmath20 . a d.f .",
    "@xmath169 obeys @xmath170 where @xmath171 and @xmath172    proof of theorem [ lp-1 ] let @xmath173 , and denote @xmath174 we will employ the distribution functions @xmath152 and @xmath175 where @xmath176 the counterparts to these distributions are @xmath177 it is easy to see that @xmath178 and @xmath179 obviously , @xmath180 we now check that @xmath181    since @xmath182 we have @xmath183 the right - hand side of ( [ lp3 ] ) takes on its maximum at @xmath184 ; the supremum is bounded by @xmath185 .",
    "note that @xmath186    let @xmath187 denote the hellinger distance .",
    "it is easy to check that @xmath188 according to lemma [ lbh ] below , @xmath189 let @xmath190 where @xmath191 note that @xmath192 as @xmath193 from ( [ lp10 ] ) , @xmath194 where @xmath195 and @xmath196 @xmath197 note that @xmath198 as @xmath199 .",
    "hence , @xmath200 as @xmath91 $ ] and ( [ lp1 ] ) follows .",
    "let @xmath24 be an arbitrary estimator of index @xmath86 .",
    "denote @xmath201 .",
    "since @xmath202 lemma [ lbh ] yields @xmath203 with @xmath204 the left - hand side of this inequality is @xmath205 where @xmath206 and @xmath207 , leading to ( [ lp ] ) .",
    "proof of corollary [ lp - c ] note that @xmath208 for any non - negative r.v .",
    "@xmath209 since @xmath210 as @xmath211 @xmath212 ( [ lp1 ] ) and ( [ lp9 ] ) entail ( [ lpc ] ) .    proof of theorem [ lp-2 ] with @xmath152 and @xmath213 defined as above , we have @xmath214 using this inequality , ( [ lp10 ] ) and lemma [ lbh ] , we derive @xmath215 let @xmath216",
    ". then @xmath217 note that @xmath218 as @xmath219 $ ] .",
    "the result follows .",
    "proof of theorem [ lp-3 ] denote @xmath220 obviously , @xmath221 is the quantile of @xmath222 .",
    "we find convenient dealing with the equivalent problem of estimating quantiles of the distribution of a random variable @xmath223 .    with functions",
    "@xmath224 defined as above , it is easy to see that @xmath225 where we put @xmath226 note that @xmath227 hence @xmath228 if @xmath229 ( @xmath230 ) .    denote @xmath231 then @xmath232 and @xmath233 by the assumption .    using the facts that @xmath234 and @xmath235 as @xmath236",
    ", we derive @xmath237 hence , @xmath238 and @xmath239 . by lemma [ lbh ] , @xmath240 for any estimator @xmath241 .",
    "thus , @xmath242 where @xmath243 and @xmath244 taking into account ( [ gama ] ) and ( [ lp13 ] ) , we derive @xmath245 this leads to ( [ lp7 ] ) .",
    "recall that @xmath246 . from ( [ lp8 ] ) , @xmath247 by lemma [ lbh ] , @xmath248 hence , @xmath249 where @xmath250 and @xmath251 .",
    "the proof is complete .",
    "the next lemma presents a lower bound to the accuracy of choosing between two `` close '' alternatives .",
    "let @xmath30 be an arbitrary class of distributions , and assume that the quantity of interest , @xmath25 is an element of a metric space @xmath252 .",
    "an estimator @xmath253 of @xmath28 is a measurable function of @xmath254 taking values in a subspace @xmath255 of the metric space @xmath252 .",
    "examples of functionals @xmath28 include ( a ) @xmath256 where @xmath257 is a parametric family of distributions ( @xmath258 ) ; ( b ) @xmath259 where @xmath260 is the density of @xmath56 with respect to a particular measure ; ( c ) @xmath261 .",
    "a minimax lower bound over @xmath30 follows from a lower bound to @xmath262 where @xmath263    [ lbh ] denote @xmath264 .",
    "then @xmath265 where @xmath266 is the hellinger distance .",
    "there is considerable literature on techniques of deriving minimax lower bounds of this kind ( cf .",
    "classical results include fano s and assuad s lemmas . inequality ( [ lp12 ] ) is sharper than lemma 1 in @xcite .",
    "another related result is theorem 2.2 in @xcite .",
    "proof of lemma [ lbh ] recall that @xmath267 where @xmath268 is a density of @xmath269 with respect to a certain measure ( e.g. , @xmath270 ) .",
    "let @xmath271 denote the density of @xmath272 and put @xmath273 by the triangle inequality , @xmath274 therefore , @xmath275 where @xmath276 using the definition of @xmath277 and the bunyakovskiy  cauchy  schwarz inequality",
    ", we derive @xmath278 & \\le & \\int\\sqrt{f_{0,n}f_{1,n } } \\1_0 + \\int \\sqrt{f_{0,n}f_{1,n } } \\1_1 \\\\[-2pt ] & \\le & \\p_0^{1/2}\\bigl(d(\\hat a;a_0 ) \\ge\\delta \\bigr ) + \\p_1^{1/2}\\bigl(d(\\hat a;a_1 ) \\ge \\delta\\bigr ) .\\end{aligned}\\ ] ] hence @xmath279 , leading to ( [ lp12 ] ) .",
    "the author is grateful to the editor , the associate editor and two referees for many helpful remarks . supported by a grant from the london mathematical society ."
  ],
  "abstract_text": [
    "<S> the paper suggests a simple method of deriving minimax lower bounds to the accuracy of statistical inference on heavy tails . a well - known result by hall and welsh ( _ ann . </S>",
    "<S> statist . _ </S>",
    "<S> * 12 * ( 1984 ) 10791084 ) states that if @xmath0 is an estimator of the tail index @xmath1 and @xmath2 is a sequence of positive numbers such that @xmath3 , where @xmath4 is a certain class of heavy - tailed distributions , then @xmath5 . </S>",
    "<S> the paper presents a non - asymptotic lower bound to the probabilities @xmath6 . </S>",
    "<S> we also establish non - uniform lower bounds to the accuracy of tail constant and extreme quantiles estimation . </S>",
    "<S> the results reveal that normalising sequences of robust estimators should depend in a specific way on the tail index and the tail constant . </S>"
  ]
}