{
  "article_text": [
    "crowdsourcing is a term often adopted to identify networked systems that can be used for the solution of a wide range of complex problems by integrating a large number of human and/or computer efforts @xcite .",
    "alternative terms , each one carrying its own specific nuance , to identify similar types of systems are : collective intelligence , human computation , master - worker computing , volunteer computing , serious games , voting problems , peer production , citizen science ( and others ) .",
    "the key characteristic of these systems is that a _ requester _ structures his problem in a set of _ tasks _ , and then assigns tasks to _ workers _ that provide _",
    "answers _ , which are then used to determine the correct task _ solution _ through a _ decision _ rule .",
    "well - known examples of such systems are seti@home , which exploits unused computer resources to search for extra - terrestrial intelligence , and the amazon mechanical turk , which allows the employment of large numbers of micro - paid workers for tasks requiring human intelligence ( hit  human intelligence tasks ) . examples of hit are image classification , annotation , rating and recommendation , speech labeling , proofreading , etc . in the amazon",
    "mechanical turk , the workload submitted by the requester is partitioned into several small atomic tasks , with a simple and strictly specified structure .",
    "tasks , which require small amount of work , are then assigned to ( human ) workers . since on the one hand answers may be subjective , and on the other task execution is typically tedious , and the economic reward for workers is pretty small , workers are not 100 % reliable ( earnest ) , in the sense that they may provide incorrect answers .",
    "hence , the same task is normally assigned in parallel ( replicated ) to several workers , and then a majority decision rule is applied to their answers . a natural trade - off between the reliability of the decision and cost arises ; indeed , increasing the replication factor of every task , we can increase the reliability degree of the final decision about the task solution , but we necessarily incur higher costs ( or , for a given fixed cost , we obtain a lower task throughput ) .",
    "although the pool of workers in crowdsourcing systems is normally large , it can be abstracted as a finite set of shared resources , so that the allocation of tasks to workers ( or , equivalently , of workers to tasks ) is of key relevance to the system performance .",
    "some believe that crowdsourcing systems will provide a significant new type of work organization paradigm , and will employ large numbers of workers in the future , provided that the main challenges in this new type of organizations are correctly solved . in @xcite",
    "the authors identify a dozen such challenges , including i ) workflow definition and hierarchy , ii ) task assignment , iii ) real - time response , iv ) quality control and reputation .",
    "task assignment and reputation are central to this paper , where we discuss optimal task assignment with approximate information about the quality of answers generated by workers ( with the term worker reputation we generally mean the worker earnestness , i.e. , the credibility of a worker s answer for a given task , which we will quantify with an error probability ) .",
    "our optimization aims at minimizing the probability of an incorrect task solution for a maximum number of tasks assigned to workers , thus providing an upper bound to delay and a lower bound on throughput . a dual version of our optimization is possible , by maximizing throughput ( or minimizing delay ) under an error probability constraint .",
    "like in most analyses of crowdsourcing systems , we assume no interdependence among tasks , but the definition of workflows and hierarchies is an obvious next step .",
    "both these issues ( the dual problem and the interdependence among tasks ) are left for further work .",
    "the performance of crowdsourcing systems is not yet explored in detail , and the only cases which have been extensively studied in the literature assume that the quality of the answers provided by each worker ( the worker reputation ) are not known at the time of task assignment .",
    "this assumption is motivated by the fact that the implementation of reputation - tracing mechanisms for workers is challenging , because the workers pool is typically large and highly dynamical .",
    "furthermore , in some cases the anonymity of workers must be preserved .",
    "nevertheless , we believe that a clear understanding of the potential impact on the system performance of even approximate information about the workers reputation in the task assignment phase is extremely important , and can properly assess the relevance of algorithms that trace the reputation of workers .",
    "examples of algorithms that incorporate auditing processes in a sequence of task assignments for the worker reputation assessment can be found in @xcite .",
    "several algorithms were recently proposed in the technical literature to improve the performance of crowdsourcing systems without a - priori information about worker reputation @xcite . in particular",
    ", @xcite proposed an adaptive simple on - line algorithm to assign an appropriate number of workers to every task , so as to meet a prefixed constraint on problem solution reliability . in  @xcite , instead , it was shown that the reliability degree of the final problem solution can be significantly improved by replacing the simple majority decision rule with smarter decision rules that differently weigh answers provided by different workers .",
    "essentially the same decision strategy was independently proposed in  @xcite and  @xcite for the case in which every task admits a binary answer , and then recently extended in  @xcite to the more general case .",
    "the proposed approach exploits existing redundancy and correlation in the pattern of answers returned from workers to infer an a - posteriori reliability estimate for every worker .",
    "the derived estimates are then used to properly weigh workers answers .",
    "the goal of this paper is to provide the first systematic analysis of the potential benefits deriving from some form of a - priori knowledge about the reputation of workers . with this goal in mind , first we define and analyze the task assignment problem when workers reputation estimates are available .",
    "we show that in some cases , the task assignment problem can be formalized as the maximization of a monotone submodular function subject to matroid constraints . a greedy algorithm with performance guarantees",
    "is then devised .",
    "in addition , we propose a simple  maximum a - posteriori ",
    "( map ) decision rule , which is well known to be optimal when perfect estimates of workers reputation are available .",
    "finally , our proposed approach is tested in several scenarios , and compared to previous proposals .",
    "our main findings are :    * even largely inaccurate estimates of workers reputation can be effectively exploited in the task assignment to greatly improve system performance ; * the performance of the maximum a - posteriori decision rule quickly degrades as worker reputation estimates become inaccurate ; * when workers reputation estimates are significantly inaccurate , the best performance can be obtained by combining our proposed task assignment algorithm with the decision rule introduced in @xcite .",
    "the rest of this paper is organized as follows .",
    "section [ sec : sa ] presents and formalizes the system assumptions used in this paper .",
    "section [ sec : pf ] contains the formulation of the problem of the optimal allocation of tasks to workers , with different possible performance objectives .",
    "section [ sec : allocation ] proposes a greedy allocation algorithm , to be coupled with the map decision rule described in section [ sec : decision ] .",
    "section [ sec : results ] presents and discusses the performance of our proposed approach in several scenarios , and compares it to those of previous proposals .",
    "finally , section [ sec : conclusions ] concludes the paper and discusses possible extensions .",
    "we consider @xmath0 binary tasks @xmath1 , whose outcomes can be represented by i.i.d .",
    "uniform random variables ( rv s ) @xmath2 over @xmath3 , i.e. , @xmath4 , @xmath5 . in order to obtain a reliable estimate of task outcomes",
    ", a requester assigns tasks to workers selected from a given population of size @xmath6 , by querying each worker @xmath7 , @xmath8 a subset of tasks .",
    "each worker is modeled as a binary symmetric channel ( bsc ) @xcite .",
    "this means that worker @xmath7 , if queried about task @xmath9 , provides a wrong answer with probability @xmath10 and a correct answer with probability @xmath11 .",
    "note that we assume that the error probabilities @xmath12 depend on both the worker and the task , but they are taken to be time - invariant , and generally unknown to the requester .",
    "the fact that the error probability may depend , in general , both on the worker and the task reflects the realistic consideration that tasks may have different levels of difficulty , that workers may have different levels of accuracy , and may be more skilled in some tasks than in others .",
    "unlike the model in @xcite , we assume in this paper that , thanks to a - priori information , the requester can group workers into classes , each one composed of workers with similar accuracy and skills . in practical crowdsourcing systems , where workers are identified through authentication ,",
    "such a - priori information can be obtained by observing the results of previous task assignments .",
    "more precisely , we suppose that each worker belongs to one of @xmath13 classes , @xmath14 , and that each class is characterized , for each task , by a different _ average _ error probability , known to the requester .",
    "let @xmath15 be the average error probability for class @xmath16 and task @xmath9 , @xmath17 , @xmath5 .",
    "we emphasize that @xmath15 does not necessarily precisely characterize the reliability degree of individual workers within class @xmath18 while accomplishing task @xmath9 ; this for the effect of possible errors / inaccuracies in the reconstruction of user profiles .",
    "workers with significantly different degree of reliability can , indeed , coexist within class @xmath18 .",
    "in particular our class characterization encompasses two extreme scenarios :    * full knowledge about the reliability of workers , i.e. , each worker belonging to class @xmath16 has error probability for task @xmath9 deterministically equal to @xmath15 , and * a hammer - spammer ( hs ) model  @xcite , in which perfectly reliable and completely unreliable users coexists within the same class .",
    "a fraction @xmath19 of workers in class @xmath16 , when queried about task @xmath9 , has error probability equal to @xmath20 ( the spammers ) , while the remaining workers have error probability equal to zero ( the hammers ) .",
    "suppose that class @xmath16 contains a total of @xmath21 workers , with @xmath22 .",
    "the first duty the requester has to carry out is the assignment of tasks to workers .",
    "we impose the following two constraints on possible assignments :    * a given task @xmath9 can be assigned at most once to a given worker @xmath7 , and * no more than @xmath23 tasks can be assigned to worker @xmath7 .",
    "notice that the second constraint arises from practical considerations on the amount of load a single worker can tolerate .",
    "we also suppose that each single assignment of a task to a worker has a _ cost _ , which is independent of the worker s class . in practical systems",
    ", such cost represents the ( small ) wages per task the requester pays the worker , in order to obtain answers to his queries .",
    "alternatively , in voluntary computing systems , the cost can describe the time necessary to perform the computation .",
    "the reader may be surprised by the fact that we assume worker cost to be independent from the worker class , while it would appear more natural to differentiate wages among workers , favoring the most reliable , so as to incentivize workers to properly behave  @xcite .",
    "our choice , however , is mainly driven by the following two considerations : i ) while it would be natural to differentiate wages according to the individual reputation of workers , when the latter information is sufficiently accurate , it is much more questionable to differentiate them according to only an average collective reputation index , such as @xmath15 , especially when workers with significantly different reputation coexist within the same class ; ii ) since in this paper our main goal is to analyze the impact on system performance of a - priori available information about the reputation of workers , we need to compare the performance of such systems against those of systems where the requester is completely unaware of the worker reputation , under the same cost model .",
    "finally , we wish to remark that both our problem formulation and proposed algorithms naturally extend to the case in which costs are class - dependent .",
    "let an _ allocation _ be a set of assignments of tasks to workers .",
    "more formally , we can represents a generic allocation with a set @xmath24 of pairs @xmath25 with @xmath26 and @xmath27 , where every element @xmath28 corresponds to an individual task - worker assignment .",
    "let @xmath29 be the complete allocation set , comprising every possible individual task - worker assignment ( in other words @xmath29 is the set composed of all the possible @xmath30 pairs @xmath25 ) .",
    "of course , by construction , for any possible allocation @xmath24 , we have that @xmath31 .",
    "hence , the set of all possible allocations corresponds to the power set of @xmath29 , denoted as @xmath32 .",
    "the set @xmath24 can also be seen as the edge set of a bipartite graph where the two node subsets represent tasks and workers , and there is an edge connecting task node @xmath33 and worker node @xmath34 if and only if @xmath35 .",
    "it will be sometimes useful in the following to identify the allocation with the biadjacency matrix of such graph .",
    "such binary matrix of size @xmath36 will be denoted @xmath37 and referred to as the _ allocation matrix_. in the following we will interchangeably use the different representations , according to convenience .    in this work ,",
    "we suppose that the allocation is non - adaptive , in the sense that all assignments are made before any decision is attempted . with this hypothesis",
    ", the requester must decide the allocation only on the basis of the a - priori knowledge on worker classes .",
    "adaptive allocation strategies can be devised as well , in which , after a partial allocation , a decision stage is performed , and gives , as a subproduct , refined a - posteriori information both on tasks and on workers accuracy .",
    "this information can then be used to optimize further assignments . however , in @xcite it was shown that non - adaptive allocations are order optimal in a single - class scenario .    when all the workers answers are collected , the requester starts deciding , using the received information .",
    "let @xmath38 be a @xmath36 random matrix containing the workers answers and having the same sparsity pattern as @xmath39 .",
    "precisely , @xmath40 is nonzero if and only if @xmath41 is nonzero , in which case @xmath42 with probability @xmath43 and @xmath44 with probability @xmath45 . for every instance of the matrix @xmath46 the output of the decision phase is an estimate @xmath47 for task values .",
    "in this section , we formulate the problem of the optimal allocation of tasks to workers , with different possible performance objectives . we formalize such problem under the assumption that each worker in class @xmath16 has error probability for task @xmath9 deterministically equal to @xmath48 .",
    "if the individual error probability of the workers within one class is not known to the scheduler , it becomes irrelevant which worker in a given class is assigned the task .",
    "what only matters is actually how many workers of each class is assigned each task . by sorting the columns ( workers ) of the allocation matrix @xmath39",
    ", we can partition it as * g*= where @xmath49 is a binary matrix of size @xmath50 representing the allocation of tasks to class-@xmath18 workers .",
    "define @xmath51 and @xmath52 .",
    "define also @xmath53 as the weight ( number of ones ) in the @xmath33-th row of matrix @xmath49 , which also represents the degree of the @xmath33-th task node in the subgraph containing only worker nodes from the @xmath18-th class .",
    "we formulate the problem of optimal allocation of tasks to workers as a combinatorial optimization problem for a maximum overall cost .",
    "namely , we fix the maximum number of assignments ( or , equivalently , the maximum number of ones in matrix @xmath39 ) to a value @xmath54 , and we seek the best allocation in terms of degree set @xmath55 .",
    "let @xmath56 be a given performance parameter to be maximized .",
    "then , the problem can be formalized as follows .",
    "@xmath57 where the first constraint expresses the fact that @xmath53 is the number of ones in the @xmath33-th row of @xmath49 , the second constraint derives from the maximum number of tasks a given worker can be assigned , and the third constraint fixes the maximum overall cost .    note that it could also be possible to define a dual optimization problem , in which the optimization aims at the minimum cost , subject to a maximum admissible error probability ; this alternative problem is left for future work .    by adopting the set notation for allocations",
    ", we can denote with @xmath58 the family of all feasible allocations ( i.e. the collection of all the allocations respecting the constraints on the total cost and the worker loads ) .",
    "observe that by construction @xmath59 is composed of all the allocations @xmath24 satisfying : i ) @xmath60 , and ii ) @xmath61 @xmath62 , where @xmath63 represents the set of individual assignments in @xmath24 associated to @xmath34 .",
    "the advantage of the set notation is that we can characterize the structure of the family @xmath58 on which the performance optimization must be carried out ; in particular , we can prove that :    [ prop - matroid ] the family @xmath58 forms a matroid  @xcite .",
    "furthermore , @xmath58 satisfies the following property .",
    "let @xmath64 be the family of maximal sets in @xmath58 , then @xmath65    the proof is reported in appendix [ app : matroid ] along with the definition of a matroid .",
    "the complexity of the above optimal allocation problem heavily depends on the structure of the objective function @xmath56 ( which is rewritten as @xmath66 when we adopt the set notation ) . as a general property ,",
    "observe that necessarily @xmath66 is monotonic , in the sense that @xmath67 whenever @xmath68 .",
    "however , in general , we can not assume that @xmath66 satisfies any other specific property ( some possible definitions for @xmath66 are given next ) .",
    "for a general monotonic objective function , the optimal allocation of tasks to workers can be shown to be np - hard , since it includes as a special case the well - known problem of the maximization of a monotonic submodular function , subject to a uniform matroid constraint ( see  @xcite ) is said to be submodular if : @xmath69 we have @xmath70 .",
    "the problem of the maximization of a monotonic submodular function subject to a uniform matroid constraint corresponds to : \\{@xmath71 for @xmath72 with @xmath73 submodular . } ] .",
    "when @xmath66 is submodular , the optimal allocation problem falls in the well - known class of problems related to the maximization of a monotonic submodular function subject to matroid constraints . for such problems",
    ", it has been proved that a greedy algorithm yields a 1/(1+@xmath74)-approximation  @xcite ( where @xmath74 is defined as in proposition [ prop - matroid ] ) .    in the next subsections , we consider different choices for the performance parameter @xmath56 .",
    "a possible objective of the optimization , which is most closely related to typical performance measures in practical crowdsourcing systems , is the average task error probability , which is defined as : p_1(d )",
    "= -1 t _ t=1^t p_e , t with @xmath75 where the second equality follows from symmetry .",
    "of course , @xmath76 can be exactly computed only when the true workers error probabilities @xmath45 are available ; furthermore it heavily depends on the adopted decoding scheme . as a consequence , in general , @xmath76 can only be approximately estimated by the requester by confusing the actual worker error probability @xmath45 ( which is unknown ) with the corresponding average class error probability @xmath48 .",
    "assuming a maximum - a - posteriori ( map ) decoding scheme , namely , @xmath77 , where @xmath78 is the @xmath33-th row of @xmath46 and @xmath79 is its observed value , we have [ eq : error_probability_task_i ] p_e , t = _ : \\{_t = 1|*a*_t= } < 1/2 \\{*a*_t = |_t=1 } .",
    "it is easy to verify that the exact computation of the previous average task error probability estimate requires a number of operations growing exponentially with the number of classes @xmath13 .",
    "thus , when the number of classes @xmath13 is large , the evaluation of ( [ eq : error_probability_task_i ] ) can become critical .    to overcome this problem , we can compare the performance of different allocations on the basis of a simple pessimistic estimate of the error probability , obtained by applying the chernoff bound to the random variable that is driving the maximum - a - posteriori ( map ) decoding ( details on a map decoding scheme are provided in the next section ) .",
    "we have : @xmath80 where @xmath81 .",
    "thus , the performance metric associated with an allocation becomes : @xmath82 the computation of @xmath83 requires a number of operations that scales linearly with the product @xmath84 .",
    "at last , we would like to remark that in practical cases we expect the number of classes to be sufficiently small ( order of few units ) , in such cases the evaluation of ( [ eq : error_probability_task_i ] ) is not really an issue .",
    "an alternative information - theoretic choice for @xmath56 is the mutual information between the vector of rvs associated with tasks @xmath85 and the answer matrix @xmath46 , i.e. , [ eq : mutual_info ] p_3(d ) = i(*a * ; ) = _ t=1^t i(*a*_t ; _ t ) .",
    "it is well known that a tight relation exists between the mutual information and the achievable error probability , so that a maximization of the former corresponds to a minimization of the latter .",
    "we remark , however , that , contrary to error probability , mutual information is independent from the adopted decoding scheme , because it refers to an optimal decoding scheme .",
    "this property makes the adoption of the mutual information as the objective function for the task assignment quite attractive , since it permits to abstract from the decoding scheme .",
    "the second equality in ( [ eq : mutual_info ] ) comes from the fact that tasks are independent and workers are modeled as bscs with known error probabilities , so that answers to a given task do not give any information about other tasks . by definition [ eq : mutual_info_definition ]",
    "i(*a*_t ; _ t ) = h(*a*_t ) - h(*a*_t | _ t ) = h(_t ) - h(_t |*a*_t ) where @xmath86 denotes the entropy of the rv @xmath87 , given by @xmath88\\ ] ] and for any two random variables @xmath89 , @xmath90 is the conditional entropy defined as @xmath91.\\ ] ] in what follows , we assume perfect knowledge of worker reliabilities , i.e. , we assume that each class-@xmath18 worker has error probability with respect to task @xmath92 exactly equal to @xmath48 , remarking than in the more general case , the quantities we obtain by substituting @xmath45 with the corresponding class average @xmath48 , can be regarded as computable approximations for the true uncomputable mutual information .",
    "since we have modeled all workers as bscs , each single answer is independent of everything else given the task value , so that [ eq : conditional_entropy_a_given_t ] h(*a*_t | _ t ) = _ a_tw 0 h(a_tw | _ t ) = _ k=1^k",
    "d_tk h_b(_tk ) . where @xmath93 for the second equality in , @xmath94 because @xmath92 is a uniform binary rv , and @xmath95 where @xmath79 runs over all possible values of @xmath96 .    by symmetry , for every @xmath79 such that",
    "@xmath97 , there is @xmath98 such that @xmath99 and @xmath100 . as a consequence",
    ", we can write @xmath101 notice the relationship of the above expression with .",
    "if in we substitute @xmath102 with @xmath103 , thanks to bayes rule , we obtain .",
    "an explicit computation of @xmath104 can be found in appendix [ app : mutual ] .",
    "as for the task error probability , the number of elementary operations required to compute @xmath104 grows exponentially with the number of classes @xmath13 .    an important property that mutual information satisfies is submodularity .",
    "this property provides some guarantees about the performance of the greedy allocation algorithm described in section  [ sec : greedy ] .",
    "[ prop - submodularity ] let @xmath24 be a generic allocation for task @xmath105 .",
    "then , the mutual information @xmath106 is a submodular function .",
    "the proof is given in appendix  [ app : submodularity ]      the previous optimization objectives represent a sensible choice whenever the target is to optimize the _ average _ task performance .",
    "however , in a number of cases it can be more appropriate to optimize the worst performance among all tasks , thus adopting a max - min optimization approach .    along the same lines used in the definition of the previous optimization objectives , we can obtain three other possible choices of performance parameters to be used in the optimization problem defined in , namely , the maximum task error probability , p_4(d ) = - _ t=1, ",
    ",t p_e , t the chernoff bound on the maximum task error probability , p_5(d ) = - _ t=1,  ,t _ e , t and the minimum mutual information , p_6(d ) = _ t=1 , 2 ,  , t i(*a*_t ; _ t ) .",
    "as we observed in section [ sec : pf ] , the optimization problem stated in is np - hard , but the submodularity of the mutual information objective function over a matroid , coupled with a greedy algorithm yields a 1/2-approximation  @xcite ( see proposition [ prop - matroid ] ) .",
    "we thus define in this section a greedy task assignment algorithm , to be coupled with the map decision rule which is discussed in the next section .",
    "the task assignment we propose to approximate the optimal performance is a simple greedy algorithm that starts from an empty assignment ( @xmath107 ) , and at every iteration @xmath108 adds to @xmath109 the individual assignment @xmath110 , so as to maximize the objective function .",
    "in other words ; @xmath111 the algorithm stops when no assignment can be further added to @xmath24 without violating some constraint .    to execute this greedy algorithm , at step @xmath108 , for every task @xmath33",
    ", we need to i ) find , if any , the best performing worker to which task @xmath33 can be assigned without violating constraints , and mark the assignment @xmath25 as a candidate assignment ; ii ) evaluate for every candidate assignment the performance index @xmath112 @xmath113 ; iii ) choose among all the candidate assignments the one that greedily optimizes performance .",
    "observe that , as a result , the computational complexity of our algorithm is @xmath114 where @xmath115 represents the number of operations needed to evaluate @xmath66 .",
    "note that in light of both propositions  [ prop - matroid ] and  [ prop - submodularity ] , the above greedy task assignment algorithm provides a @xmath116-approximation when the objective function @xmath117 is chosen .",
    "furthermore , we wish to mention that a better @xmath118-approximation can be obtained by cascading the above greedy algorithm with the special local search optimization algorithm proposed in  @xcite ; unfortunately , the corresponding cost in terms of computational complexity is rather severe , because the number of operations requested to run the local search procedure is @xmath119 .",
    "is @xmath120 if @xmath121 for any positive constant @xmath122 . ]      here we briefly recall that @xcite proposed a simple task allocation strategy ( under the assumption that workers are indistinguishable ) according to which a random regular bipartite graph is established between tasks and selected workers .",
    "every selected worker is assigned the same maximal number of tasks , i.e. @xmath123 @xmath62 , except for rounding effects induced by the constraint on the maximum total number of possible assignments @xmath54 .",
    "majority voting is the simplest possible task - decision rule which is currently implemented in all real - world crowdsourcing systems . for every task @xmath9 , it simply consists in counting the @xmath124 and the @xmath125 in @xmath78 and then taking @xmath126 in accordance to the answer majority .",
    "more formally : [ eq : majority_decision_rule ] _",
    "t(*a*_t ) = ( _ w a_tw ) .      we investigate the performance of the greedy task assignment algorithm , when coupled with the map decision rule for known workers reputation",
    ".    given an observed value of @xmath78 , the posterior log - likelihood ratio ( llr ) for task @xmath92 is @xmath127 where the second equality comes from bayes rule and the fact that tasks are uniformly distributed over @xmath128 , and the third equality comes from modelling workers as bscs .",
    "let @xmath129 be the number of `` @xmath130 '' answers to task @xmath33 from class-@xmath18 workers .",
    "then [ eq : llraposteriori ] _",
    "t(*a*_t ) = _ k=1^k ( d_tk - 2 m_tk ) .",
    "the map decision rule outputs the task solution estimate @xmath131 if @xmath132 and @xmath133 if @xmath134 , that is , [ eq : map_decision_rule ] _",
    "t(*a*_t ) = ( _ t(*a*_t ) ) .    observe that the computation of has a complexity growing only linearly with @xmath13 , and that , according to , each task solution is estimated separately .",
    "note also that , whenever worker reputation is _ not _ known a - priori , the above decision rule is no more optimal , since it neglects the information that answers to other tasks can provide about worker reputation .",
    "finally , for the sake of comparison , we briefly recall here the low - rank approximation decision rule proposed in  @xcite for the case when : i ) no a - priori information about the reputation of workers is available , ii ) the error probability of every individual worker @xmath34 is the same for every task , i.e. , @xmath135 @xmath136 .",
    "the lra decision rule was shown to provide asymptotically optimal performance under assumptions i ) and ii )  @xcite",
    ".    denote with @xmath137 the leading right singular vector of @xmath46 , the lra decision is taken according to : @xmath138 where @xmath139 the idea underlying the lra decision rule is that each component of the leading singular vector of @xmath46 , measuring the degree of coherence among the answers provided by the correspondent worker , represents a good estimate of the worker reputation .",
    "in this section , we study the performance of a system where @xmath140 tasks are assigned to a set of workers which are organized in @xmath141 classes . each worker can handle up to 20 tasks , i.e. , @xmath142 , @xmath143 .",
    "we compare the performance of the allocation algorithms and decision rules described in sections  [ sec : allocation ] and  [ sec : decision ] , in terms of achieved average error probability , @xmath144 .",
    "more specifically , we study the performance of :    * the `` majority voting '' decision rule applied to the `` uniform allocation '' strategy , hereinafter referred to as `` majority '' ; * the `` low rank approximation '' decision rule applied to the `` uniform allocation '' strategy , in the figures referred to as `` lra uniform '' ; * the `` low rank approximation '' decision rule applied to the `` greedy allocation '' strategy , in the figures referred to as `` lra greedy '' ; * the `` map '' decision rule applied to the `` greedy allocation '' strategy , in the following referred to as `` map greedy '' .",
    "specifically , for the greedy allocation algorithm , described in section  [ sec : greedy ] , we employed the overall mutual information @xmath145 as objective function .",
    "the first set of results is reported in figure  [ fig : figure1 ] .",
    "there we considered the most classical scenario where tasks are identical .",
    "the results depicted in figure  [ fig : figure1](a ) assume that all workers belonging to the same class have the same error probability i.e. , @xmath146 .",
    "in particular , we set @xmath147 for all @xmath33 .",
    "this means that workers in class 1 are the most reliable , while workers in class 3 are spammers .",
    "moreover , the number of available workers per class is set to @xmath148 .",
    "the figure shows the average error probability achieved on the tasks , plotted versus the average number of workers per task , @xmath149 . as expected , greedy allocation strategies perform better due to the fact that they exploit the knowledge about the workers reliability ( @xmath45 ) , and thus they assign to tasks the best possible performing workers .",
    "these strategies provide quite a significant reduction of the error probability , for a given number of workers per task , or a reduction in the number of assignments required to achieve a fixed target error probability .",
    "for example , @xmath150 can be achieved by greedy algorithms by assigning only 4 workers per task ( on average ) , while algorithms unaware of workers reliability require more than 20 workers per task ( on average ) .",
    "we also observe that the lra algorithm proposed in  @xcite performs similarly to the optimal map algorithm .",
    "next , we take into account the case where in each class workers do not behave exactly the same .",
    "as already observed , this may reflect both possible inaccuracies / errors in the reconstruction of user profiles , and the fact that the behavior of workers is not fully predictable , since it may vary over time .",
    "specifically , we assume that , in each class , two types of workers coexist , each characterized by a different error probability @xmath45 .",
    "more precisely , workers of type 1 have error probability @xmath151 , while workers of type 2 have error probability probability @xmath152 , where @xmath153 is a parameter .",
    "moreover workers are of type 1 and type 2 with probability @xmath154 and @xmath155 , respectively , so that the average error probability over the workers in class @xmath18 is @xmath48 .",
    "we wish to emphasize that this bimodal worker model , even if it may appear somehow artificial , is attractive for the following two reasons : i ) it is simple ( it depends on only one scalar parameter @xmath156 ) , and ii ) it encompasses as particular cases the two extreme cases of full knowledge and hammer - spammer .",
    "indeed , for @xmath157 all workers in each class behave exactly the same ( they all have error probability @xmath158 ) ; this is the case depicted in figure  [ fig : figure1](a ) , while for @xmath159 we recover the hammer - spammer scenario .",
    "this case is represented in figure  [ fig : figure1](b ) , where workers are spammers with probability @xmath155 and hammers with probability @xmath154 . here",
    ", the greedy allocation algorithms still outperform the others",
    ". however , the map decision rule provides performance lower than the `` lra greedy '' due to the following two facts : i ) map adopts a mismatched value of the error probability of individual workers , when @xmath160 , ii ) map does not exploit the extra information on individual worker reliability that is possible to gather by jointly decoding different tasks . in figure  [ fig : figure1](c ) , for @xmath161 , we show the error probability plotted versus the parameter @xmath156 .",
    "we observe that the performance of the `` map greedy '' strategy is independent on the parameter @xmath156 while the performance of `` lra greedy '' improve as @xmath156 increases .",
    "this effect can be explained by observing that the lra ability of distinguishing good performing workers from bad performing workers within the same class increases as @xmath156 increases .",
    "next , we assume that the @xmath140 tasks are divided into 2 groups of 50 each .",
    "workers processing tasks of group 1 and 2 are characterized by average error probabilities @xmath162 and @xmath163 , respectively .",
    "this scenario reflects the case where tasks of group 2 are more difficult to solve than tasks of group 1 ( error probabilities are higher ) .",
    "workers of class @xmath164 are spammers for both kinds of tasks .",
    "the error probabilities provided by the algorithms under study are depicted in figure  [ fig : figure2 ] , as a function of @xmath156 and for @xmath161 .",
    ", for @xmath161 and task organized in two groups of different difficulties . for the first group of tasks @xmath165 , while for the second group @xmath163 , moreover @xmath166 .",
    "]    we observe that all strategies perform similarly , like in the scenario represented by figure  [ fig : figure1](c ) , meaning that the algorithms are robust enough to deal with changes in the behavior of workers with respect to tasks .",
    "we wish to remark that the lra decoding scheme is fairly well performing also in this scenario , even if it was conceived and proposed only for the simpler scenario of indistinguishable tasks",
    ". this should not be too surprising , in light of the fact that , even if the error probability of each user depends on the specific task , the relative ranking among workers remains the same for all tasks .",
    "finally , in figure  [ fig : figure3 ] we consider the same scenario as in figure  [ fig : figure2 ] . here , however , the number of available workers per class is set to @xmath167 , and the workers error probabilities for the tasks in group 1 and 2 are given by @xmath168 , and @xmath169 , respectively .",
    "this situation reflects the case where workers are more specialized or interested in solving some kinds of tasks .",
    "more specifically , here workers of class 1 ( class 3 ) are reliable when processing tasks of group 1 ( group 2 ) , and behave as spammers when processing tasks of group 2 ( group 1 )",
    ". workers of class 2 behave the same for all tasks . in terms of performance ,",
    "the main difference with respect to previous cases is that the `` lra greedy '' algorithm shows severely degraded error probabilities for @xmath170 .",
    "this behavior should not surprise the reader , since our third scenario may be considered as adversarial for the lra scheme , in light of the fact that the relative ranking among workers heavily depends on the specific task .",
    "nevertheless , it may still appear amazing that `` lra greedy '' behaves even worse than the simple majority scheme in several cases .",
    "the technical reason for this behavior is related to the fact that , in our example , for @xmath170 , tasks of group 1 ( group 2 ) are allocated to workers of class 1 ( class 3 ) only , whilst workers of class 2 are not assigned any task . for this reason ,",
    "the matrix @xmath46 turns out to have a block diagonal structure , which conflicts with the basic assumption made by lra that matrix @xmath171 $ ] can be well approximated by a unitary rank matrix . for @xmath172 , tasks are also allocated to workers of class 2 ; in this situation , the matrix @xmath46 is not diagonal anymore , and the `` lra greedy '' performs quite well . observe , however , that also in this case even a fairly imprecise characterization of the worker behavior can be effectively exploited by the requester to significantly improve system performance .    finally , we want to remark that we have tested several versions of greedy algorithms under different objective functions , such as @xmath173 , @xmath83 , and @xmath145 , finding that they provide , in general , comparable performance . the version employing mutual information was often providing slightly better results , especially in the case of lra greedy .",
    "this can be attributed to the following two facts : i ) the mutual information was proved to be submodular ; ii ) being mutual information independent from the adopted decoding scheme , it provides a more reliable metric for comparing the performance of different task allocations under the lra decoding scheme with respect to the error probability @xmath173 ( which , we recall , is computed under the assumption that the decoding scheme is map ) .",
    "unfortunately , due to the lack of space , we can not include these results in the paper .",
    "in this paper we have presented the first systematic investigation of the impact of information about workers reputation in the assignment of tasks to workers in crowdsourcing systems , quantifying the potential performance gains in several cases .",
    "we have formalized the optimal task assignment problem when workers reputation estimates are available , as the maximization of a monotone ( submodular ) function subject to matroid constraints .",
    "then , being the optimal problem np - hard , we have proposed a simple but efficient greedy heuristic task allocation algorithm , combined with a simple  maximum a - posteriori  decision rule .",
    "we have tested our proposed algorithms , and compared them to different solutions , which can be obtained by extrapolating the proposals for the cases when reputation information is not available , showing that the crowdsourcing system performance can greatly benefit from even largely inaccurate estimates of workers reputation .",
    "our numerical results have shown that :    * even a significantly imperfect characterization of the workers earnestness can be extremely useful to improve the system performance ; * the application of advanced joint tasks decoding schemes such as lra can further improve the overall system performance , especially in the realistic case in which the a - priori information about worker reputation is largely affected by errors ; * the performance of advanced joint tasks decoding schemes such as lra may become extremely poor in adversarial scenarios .",
    "the workers answers about the tasks @xmath174 are collected in the random @xmath175 matrix @xmath46 , defined in section  [ sec : sa ] .",
    "the information that the answers @xmath46 provide about the tasks @xmath174 is denoted by @xmath176 where the entropy @xmath86 and the conditional entropy @xmath90 have been defined in section  [ sec : mutual_info ] .",
    "we first compute @xmath177 and we observe that , given the tasks @xmath174 , the answer @xmath46 are independent , i.e. , @xmath178 , where @xmath179 is the vector of answers to task @xmath9 from users of class @xmath16 . since @xmath180 has a product form , we obtain @xmath181 .",
    "thanks to the fact that workers of the same class are independent and all have error probability @xmath48 , we can write @xmath182 where @xmath183 and @xmath53 is the number of allocations of task @xmath33 in class @xmath16 . in conclusion ,",
    "we get : @xmath184    as for the entropy @xmath185 , we have : @xmath186 where @xmath78 is the vector of answers to task @xmath9 ( corresponding to the @xmath33-th row of @xmath46 ) .",
    "note that @xmath187 , hence @xmath188 and we immediately obtain @xmath189 . the probabilities @xmath190 and @xmath191 are easy to compute .",
    "indeed for @xmath192 we have @xmath193 where @xmath129 is the number of `` @xmath130 '' answers to task @xmath9 from class-@xmath18 workers .",
    "the above formula derives from the fact that workers of the same class are independent and have the same error probability @xmath48 .",
    "similarly @xmath194 the expressions   and   can compactly written as @xmath195 where @xmath196 . since , given @xmath92 , workers are independent , we obtain @xmath197 \\non & = &   \\frac{\\gamma_{tk}}{2 } \\left[\\prod_{k=1}^k b_{tk}^{-m_{tk } } + \\prod_{k=1}^k b_{tk}^{d_{tk}+m_{tk } } \\right ] =   \\frac{\\gamma_{tk}}{2 } f({{\\bf m}}_{t } ) \\nonumber\\end{aligned}\\ ] ] with @xmath198 $ ] and @xmath199 .",
    "finally , by using the definition of entropy , @xmath200 \\non & = & -\\log\\frac{\\gamma_{tk}}{2 } -{\\mathbb{e}}_{{{\\bf a}}_t}f({{\\bf m}}_{t } ) \\non & = & -\\log\\frac{\\gamma_{tk}}{2 } -\\frac{\\gamma_{tk}}{2 }   \\sum_{{{\\bf n } } } f({{\\bf n}})\\log f({{\\bf n}})\\prod_{k=1}^k\\binom{m_{tk}}{n_k } \\nonumber\\end{aligned}\\ ] ] where @xmath201 $ ] and @xmath202 , @xmath203 .",
    "first we recall the definition of a matroid . given a family @xmath58 of subsets of a finite ground set @xmath29 ( i.e. , @xmath204 @xmath58 is a matroid iff : i ) if @xmath205 then @xmath206 whenever @xmath207 + ii ) if @xmath205 and @xmath206 with @xmath208 then an @xmath209    now we can prove proposition  [ prop - matroid ] . first observe that in our case property i ) trivially holds .",
    "now we show that property ii ) holds too . given that @xmath208 and since by construction @xmath210 and @xmath211 , necessarily there exists an @xmath212 such that @xmath213 , this implies that @xmath214 .",
    "let @xmath215 be an individual assignment in @xmath216 .",
    "since by assumption @xmath217 , denoted with @xmath218 , we have that @xmath219 , therefore @xmath220 .    the fact that in our case @xmath221 descends immediately by the fact that necessarily @xmath222 iff either i ) @xmath223 when @xmath224 or ii ) @xmath225 when @xmath226 .",
    "let @xmath227 and @xmath228 be two generic allocations for the task @xmath229 , such that @xmath230 and @xmath231 . also let the pair @xmath232 . with a little abuse of notation hereinafter",
    "we denote by @xmath233 the mutual information between the task @xmath229 and the vector of answers @xmath234",
    ". then the mutual information @xmath235 is submodular if @xmath236 we first observe that @xmath237 where in @xmath238 we applied the mutual information chain rule .",
    "similarly we can write @xmath239 by consequence   reduces to @xmath240 by using the definition of the mutual information given in we obtain @xmath241            e. christoforou , a. fernandez anta , c. georgiou , m. a. mosteiro , a. sanchez , \" applying the dynamics of evolution to achieve reliability in master - worker computing ,  _ concurrency and computation : practice and experience _ vol .",
    "25 , n. 17 , pp . 23632380 , 2013 .",
    "d. r. karger , s. oh , d. shah , \" budget- optimal crowdsourcing using low - rank matrix approximations ,  2011 49th annual allerton conference on communication , control , and computing ( allerton ) , pp.284,291 , 28 - 30 sept ."
  ],
  "abstract_text": [
    "<S> this paper presents the first systematic investigation of the potential performance gains for crowdsourcing systems , deriving from available information at the requester about individual worker earnestness ( reputation ) . </S>",
    "<S> in particular , we first formalize the optimal task assignment problem when workers reputation estimates are available , as the maximization of a monotone ( submodular ) function subject to matroid constraints . </S>",
    "<S> then , being the optimal problem np - hard , we propose a simple but efficient greedy heuristic task allocation algorithm . </S>",
    "<S> we also propose a simple  maximum a - posteriori  decision rule . finally , we test and compare different solutions , showing that system performance can greatly benefit from information about workers reputation . </S>",
    "<S> our main findings are that : i ) even largely inaccurate estimates of workers reputation can be effectively exploited in the task assignment to greatly improve system performance ; ii ) the performance of the maximum a - posteriori decision rule quickly degrades as worker reputation estimates become inaccurate ; iii ) when workers reputation estimates are significantly inaccurate , the best performance can be obtained by combining our proposed task assignment algorithm with the lra decision rule introduced in the literature . </S>"
  ]
}