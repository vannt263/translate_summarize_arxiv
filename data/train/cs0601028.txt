{
  "article_text": [
    "the minimal distortion with which a memoryless source can be communicated over a memoryless noisy channel is given by the evaluation at channel capacity of the distortion vs.  rate function corresponding to the source law and the fidelity criterion ( * ? ? ?",
    "for a memoryless gaussian source and an average - power limited additive white gaussian noise ( awgn ) channel two classical schemes are known to achieve this minimum distortion : the source - channel separation approach @xcite and goblick s `` uncoded '' scheme @xcite .",
    "( see also @xcite , @xcite , and @xcite . ) here we shall show that these two schemes can be viewed as the endpoints of a continuum of optimal transmission schemes . in the proposed transmission schemes the transmitted waveform is a linear combination of the source sequence and of the result of its quantization using a gaussian vector quantizer .",
    "the source - channel separation approach corresponds to having the rate of the vector quantizer be arbitrarily close to channel capacity , and goblick s uncoded scheme corresponds to having the rate of the vector quantizer be zero .",
    "we point out that in contrast to other work on hybrid digital - analog joint source - channel coding , e.g.  @xcite , @xcite and @xcite , we do not aim for issues like `` robust '' communication , but merely mean to point out a generalization of two well - known optimal schemes .",
    "also , it should be emphasized that our transmission schemes do not increase bandwidth .",
    "this should be contrasted with the problem addressed by shamai , verd and zamir @xcite where a memoryless source is to be transmitted to a receiver via _ two independent channels _ where the transmission over one of the independent channels is required to be uncoded .",
    "to state our contribution more precisely we need some definitions .",
    "the additive white gaussian noise channel is a channel whose time-@xmath0 output @xmath1 takes value in the set of reals @xmath2 and is given by @xmath3 where @xmath4 denotes the time-@xmath0 channel input and where the random variables @xmath5 are iid , zero - mean , variance-@xmath6 , gaussian random variables .",
    "we say that the length-@xmath7 sequence of inputs @xmath8 satisfies the average power constraint if @xmath9 the capacity of the additive white gaussian noise channel under the above average power constraint is given by @xmath10 ( we assume throughout that @xmath6 is strictly larger than zero . )",
    "the memoryless zero - mean variance-@xmath11 source is a source that emits the sequence @xmath12 of iid zero - mean variance-@xmath11 gaussian random variables . the variance @xmath11 is assumed to be strictly larger than zero . the distortion vs.  rate function @xmath13 corresponding to this source and to the single - letter squared - error fidelity measure @xmath14",
    "is given by @xmath15    the evaluation of the above distortion vs.  rate function at the capacity of the additive gaussian noise channel is given by @xmath16    a blocklength-@xmath7 transmission scheme is a pair of mappings @xmath17 with the understanding that when the source emits the sequence @xmath18 the sequence @xmath19 is fed to the channel .",
    "we require that the transmitted sequence satisfy the average power constraint @xmath20 i.e. , @xmath21 the channel then produces the output sequence @xmath22 whose @xmath23-th component @xmath24 is given by @xmath25 .",
    "this output sequence is then mapped by @xmath26 to the reconstruction sequence @xmath27 : @xmath28 the distortion associated with @xmath29 is given by @xmath30 where @xmath31 and @xmath32 denote the @xmath23-th component of @xmath33 and @xmath27 respectively .    a sequence of schemes @xmath34 indexed by the blocklength @xmath7 is said to be asymptotically optimal for the transmission of a gaussian source over the additive white gaussian noise channel under the mean squared - error fidelity criterion if it results in the transmitted sequence satisfying the average power constraint i.e. , @xmath35 and",
    "if @xmath36    in this submission we propose a sequence of asymptotically optimal transmission schemes parameterized by the free parameter @xmath37 which corresponds to the rate of the gaussian vector quantizer that we employ .",
    "thus , to each fixed @xmath38 as above , we present a sequence @xmath39 of coding schemes ( parameterized by the blocklength-@xmath7 ) that is asymptotically optimal .",
    "the proposed scheme is conceptually simple , but this simplicity is masked by some of the epsilons and deltas involved .",
    "for the sake of clarity and brevity we shall therefore omit these epsilons and deltas here .    at the heart of the scheme",
    "is a rate-@xmath38 gaussian vector quantizer .",
    "we denote the quantizer s codebook by @xmath40 and assume that its @xmath41 codewords are chosen independent of each other , each being drawn uniformly over a centered sphere in @xmath42 .",
    "the normalized squared - radius of the sphere is roughly @xmath43 so that the normalized squared - norm of each of the codewords in @xmath40 is given roughly by @xmath44 where @xmath7 denotes the blocklength , @xmath45 denotes the sum of the squares of the components of @xmath46 , and where @xmath11 is the source s variance .    notice",
    "that this would be a rate-@xmath38 optimal vector quantizer for this source and that it would yield a quantization error @xmath47 , where @xmath48 also , if we slightly increase @xmath38 or slightly decrease the radius of the sphere on which the codewords of the quantizer lie , we could ( with very high probability ) find a codeword @xmath49 such that @xmath50 would be nearly orthogonal to @xmath51 .",
    "such a codeword @xmath51 would then satisfy @xmath52 where the first approximation follows because @xmath53 is nearly orthogonal to @xmath51 and where the second approximation follows by the law of large numbers for @xmath54 and from our choice of the radius of the quantizer s sphere .",
    "we can now describe the encoding schemes . observing the source sequence @xmath55",
    ", we choose the codeword @xmath51 in the vector quantizer s codebook @xmath40 equiprobably among all codewords that have a `` typical '' angle to @xmath55 , i.e.  equiprobably among all @xmath56 satisfying @xmath57 where @xmath58 is the standard inner product in @xmath42 .",
    "if no such @xmath56 exists , the codeword @xmath51 is choosen to be the all zero sequence @xmath59 .",
    "by slightly shrinking the quantizer s sphere we can guarantee that with very high probability there exists at least one @xmath56 satisfying , and consequently , with help of the weak law of large numbers for @xmath60 , that with very high probability @xmath61 the transmitted sequence @xmath62 is now given by a linear combination of @xmath51 and the source sequence @xmath55 : @xmath63 where the coefficients @xmath64 and @xmath65 are judiciously chosen as @xmath66 \\alpha(\\rho ) & = \\sqrt{\\frac{2^{-2\\rho}(n+p)-n}{\\sigma^2 2^{-2\\rho}}}.\\end{aligned}\\ ] ] this choice of @xmath67 and @xmath68 is dictated by two requirements .",
    "the first is that @xmath69 roughly satisfy the power constraint . indeed , writing @xmath70 we note that by we shall have @xmath71 if @xmath72 or , in view of and , if @xmath73    the second requirement dictating the choice of @xmath67 and @xmath68 has to do with the decoding and will be described as soon as we describe how the source sequence is reconstructed from the channel output .",
    "this reconstruction takes place in two phases . in the first phase the decoder makes a guess @xmath74 of the transmitted codeword @xmath49 . in the second phase",
    "the decoder then makes an estimate @xmath75 of the source sequence based on @xmath76 and @xmath77 .",
    "the guess of @xmath51 in the first phase is based on the observation @xmath78 the decoder treats the scaled quantization noise @xmath79 as gaussian noise , and thus `` sees '' a signal ( @xmath80 ) of average power @xmath81 contaminated in additive noise ( @xmath82 ) of variance @xmath83 . using minimum angle decoding , i.e.  @xmath84",
    ", it can be shown after some analysis that the decoder will succeed with high probability if @xcite @xmath85 replacing this inequality with an ( approximate ) equality gives us the second condition on @xmath86 .    in the second phase",
    "the reconstructor assumes that the first phase was successful in identifying the codeword @xmath51 .",
    "rearranging terms in we have @xmath87 and , since @xmath51 and @xmath88 are nearly orthogonal , a reasonable estimator of @xmath33 is now the linear estimator @xmath89 and this is , indeed , the reconstructor we propose .",
    "thus , the reconstruction function @xmath26 can be formally defined as @xmath90 where @xmath91 and @xmath92 .",
    "the expected squared error associated to the proposed sequence of schemes @xmath93 @xmath94 where the expectation is taken over all @xmath33 , @xmath95 and @xmath96 , can now be analyzed by using @xmath97 in .",
    "writing the expectation as a sum of the individual cross - terms ( most of which are straightforwardly bounded ) and showing that @xmath98 then results in @xmath99    of course , the rigorous analysis also requires analyzing the effect that the non - existence of a codeword @xmath56 satisfying the encoder condition and the effect that an error in identifying @xmath51 entail , as well as justifying the approximations that we have presented .",
    "we have shown that for the transmission of an iid gaussian source over an awgn channel with average input power constraint , the minimal expected squared error distortion can be achieved by the superposition of coded and uncoded transmission , for arbitrary power repartition among the schemes .",
    "the preserved correlation between the source sequence and the transmitted codeword makes the coded and uncoded schemes perfectly compatible .",
    "m.  skoglund , n.  phamdo , f.  alajaji , `` designa and performance of vq - based hybrid digital - analog joint source - channel codes '' , _ ieee transactions on information theory _ ,",
    "it-48(3 ) : pp .  708 - 720 ,",
    "march 2002 .",
    "u.  mittal , n.  phamdo , `` hybrid digital - analog ( hda ) joint source - channel codes for broadcasting in robust communications '' , _ ieee transactions on information theory _ , it-48(5 ) : pp .",
    "1082 - 1102 , may 2002 ."
  ],
  "abstract_text": [
    "<S> we propose to send a gaussian source over an average - power limited additive white gaussian noise channel by transmitting a linear combination of the source sequence and the result of its quantization using a high dimensional gaussian vector quantizer . </S>",
    "<S> we show that , irrespective of the rate of the vector quantizer ( assumed to be fixed and smaller than the channel s capacity ) , this transmission scheme is asymptotically optimal ( as the quantizer s dimension tends to infinity ) under the mean squared - error fidelity criterion . </S>",
    "<S> this generalizes the classical result of goblick about the optimality of scaled uncoded transmission , which corresponds to choosing the rate of the vector quantizer as zero , and the classical source - channel separation approach , which corresponds to choosing the rate of the vector quantizer arbitrarily close to the capacity of the channel . </S>"
  ]
}