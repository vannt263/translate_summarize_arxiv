{
  "article_text": [
    "proactive systems  @xcite anticipate the needs of the user and predict possible next steps based on the user s preferences and current context .",
    "the central component of proactive systems is the inference engine , which analyzes the current context to provide the highest - ranking suggestions .",
    "proactive systems have recently gained popularity , and many of the contemporary major operating systems include proactive components , e.g. , google now , apple siri , and microsoft cortana .",
    "the rationale for using search engines is to find information that helps us in our daily tasks , be they leisure or professional .",
    "an ideal search engine would support searching and identifying useful information that can then be used in solving these tasks @xcite . in proactive information retrieval  @xcite the estimation of the current task and context",
    "are utilized to proactively retrieve and recommend relevant items . in particular",
    ", this can include associative forms of recall , e.g. ,  in a situation where the user does not realize having forgotten about a specific resource  @xcite .",
    "a proactive retrieval system can be viewed as a digital personal assistant that knows the user s preferences and aims to provide useful and relevant information in the current task context .",
    "long short - term memory ( lstm ) networks @xcite have recently shown remarkable performance in a variety of natural language processing tasks , including speech recognition @xcite , automatic translation @xcite , image captioning @xcite and information retrieval @xcite .",
    "lstm networks have also been used to generate various kinds of sequences , including text  @xcite . in sequence generation ,",
    "the network is used to process input sequences one at a time and to sample the next item from the output distribution of the network .",
    "the sampled item is then fed to the network as the next input .",
    "this capability to predict future continuations of a sequence ( viz .",
    "text in this case ) makes lstms particularly attractive for proactive information retrieval .    a typical example of a task is writing about a given topic @xcite .",
    "in this paper , we propose a method for supporting the user by proactive information retrieval during a writing task .",
    "an lstm network is used to expand the proactive queries by predicting the most likely continuations of the current written text .",
    "an overview of the proposed method is shown in figure  [ fig : system_diagram ] .",
    "we present simulated experiments to validate the utility of the lstm predictions in providing relevant documents , and compare the method to a baseline and to another method based on user intent modeling .",
    "the rest of the paper is organized as follows . in the following section a discussion of related work",
    "is provided . in section  [",
    "sec : methods ] we describe the components of our proactive retrieval system : the query expansion methods ( based on an lstm and on user intent modeling ) , and the proactive query generation . in section  [ sec : experiment ] we describe our simulation experiments . in section  [ sec : ui ] we present our experimental user interface for providing proactive recommendations based on the current task context .",
    "the user interface is used in forthcoming user studies .",
    "we conclude and discuss future work in section  [ sec : discussion ] .",
    "recurrent neural networks ( rnns ) , and lstms in particular , have recently been used to generate sequences in various domains , such as music  @xcite , text  @xcite , and handwriting  @xcite . in information retrieval ,",
    "rnns have been used , e.g. , for extracting sentence - level semantic vectors  @xcite and context - aware query suggestion  @xcite .",
    "other kinds of deep neural networks have been used to project queries and documents to low - dimensional semantic spaces @xcite and to learn fixed - length vectors for variable - length pieces of texts , such as sentences , paragraphs , and documents @xcite .",
    "various types of task activities have been studied in the literature as a basis for query suggestion or query support .",
    "motivated by the observation that a notable proportion of the user s information needs were triggered by previous web browsing activity , several authors have studied the correlation between web browsing behavior and consecutive searches  @xcite .",
    "another popular approach is to use previous search queries  @xcite .",
    "our work is related to query auto - completion @xcite , in which possible completions of search engine queries are predicted .",
    "query auto - completion for web and mobile queries has recently been studied in  @xcite .",
    "a much studied task scenario for intelligent assistants is writing .",
    "the existing work has largely focused on bibliographic tasks involved in writing scientific or professional texts  @xcite .",
    "these mostly target either the planning or review phases of writing , as translation , i.e. , transforming the writer s mental ideas into sentences , is the most challenging process in terms of tolerance to undesired disruptions . in @xcite , the impact of proactive recommendations to different phases of the writing process",
    "is analyzed .",
    "the _ reactive keyboard _",
    "@xcite is an early prototype for predicting the succeeding words from a user - written text fragment . completing written sentences",
    "has also been studied in @xcite .",
    "the setup of our work is closely related to what was envisioned already by rhodes and starner in their _ remembrance agent _",
    "( ra )  @xcite .",
    "the user first indexes her personal data , e.g. , emails and written notes .",
    "ra is then set to run continuously in the background and display a list of summaries of documents that are related to the current document being read or written .",
    "other similar tools include _ watson _ @xcite and _ implicit query _",
    "the main difference of our method compared to these systems is the of use an lstm - based predictive model to perform query expansion .",
    "we also compare our method to a baseline and a method based on user intent modeling . in this paper , we evaluate our method using a simulated writing task , but our method can be applied to other sources of context , such as what is read on the screen .",
    "the proactive recommendations produced by our method are based on user input observed during the current task . to improve the recommendations , we propose to use an lstm - based method for query expansion described in section  [ ssec : lstm ] . for comparison ,",
    "we use a method based on estimating user intent using a multi - armed bandit model ( section  [ ssec : linrel ] and appendix  [ sec : linrelappendix ] ) .",
    "proactive information retrieval using the expanded query is described in section  [ ssec : queryconstr ] .",
    "an overview of the proposed method ( and the comparison and baseline methods ) is shown in figure  [ fig : system_diagram ] .      in lstm - based query expansion ,",
    "the most probable continuations are estimated for the current written text and the expansion words are selected from these estimated continuations . for computing the continuations , we use a beam search algorithm  @xcite described below .    the lstm network @xmath0 is first trained using a text corpus , like abstracts of scientific articles .",
    "the trained network can then serve as a model for text generation .    .",
    "on each level of the tree , nodes other than @xmath1 highest scoring ones are pruned out . as the branching coefficient is @xmath2 , there are at most 12 candidates on each level before the pruning . ]",
    "let us assume the user has written @xmath3 input words and denote by @xmath4 the latest word in the input sequence .",
    "when given an input word @xmath5 , the network @xmath0 will return a probability distribution for the next word , of which we will consider the @xmath6 most probable candidates .",
    "for example , with the branching coefficient @xmath2 and @xmath7 , the top candidates from @xmath0 could be @xmath8 , where @xmath9 denotes the @xmath10th candidate for the @xmath11th word following the input word @xmath4 .",
    "the output probability of the word is denoted as @xmath12 .",
    "further continuations are computed by using previous candidate words as input to @xmath0 .",
    "note that the output of @xmath0 depends not only on the latest input word , but on all input words so far .",
    "the different continuations form a tree structure , where the root node is the input word @xmath4 from which the continuations or paths evolve ( see figure  [ fig : path_formation ] ) .",
    "we denote by @xmath13 the depth of the tree , i.e. , the number of words in the estimated continuations of the sentence .",
    "as the size of the tree grows rather quickly , the number of generated paths is controlled by the beam width @xmath14 , pruning nodes on each level based on word probabilities on their corresponding paths .",
    "the path from @xmath4 to @xmath9 is denoted by @xmath15 , e.g. , in figure  [ fig : path_formation ] , @xmath16 .",
    "the pruning score @xmath17 is defined as the product of the word probabilities on @xmath15 : @xmath18 on each level of the tree , nodes other than the @xmath14 highest scoring ones are pruned out .",
    "after the pruning on level @xmath11 , the level @xmath19 candidates are obtained using the @xmath14 remaining words .",
    "figures [ fig : path_formation ] and [ fig : continuations ] show examples of the pruned tree and the corresponding continuations .    continuing our previous example , the second set of estimated words following the input word @xmath4",
    "are computed using the estimated words from the level @xmath20 , e.g.  when feeding to network @xmath0 the word @xmath21 , the top candidates returned could be @xmath22 .",
    "the third level of generated words are computed using the words from the second level and so forth : @xmath23 .",
    "the query expansion is formed from the words remaining in the pruned tree .",
    "first , the words are filtered using a standard list of english stop words .",
    "the query expansion score of @xmath24 is defined as the product of its _ idf _ value and its probability defined by the model @xmath0 : @xmath25 the _ idf _ values were computed from the same training data that was used to train the network using the form @xmath26 , where @xmath27 is the number of documents where the word @xmath5 appears in , and @xmath28 is the total number of documents .",
    "finally , the @xmath29 words having the highest scores are added to the expanded query .      as a comparison method",
    ", we use an upper confidence bound algorithm , which is based on estimating the user intent using a multi - armed bandit model @xcite .",
    "the model balances exploration with exploitation and selects words that have the highest upper confidence bound @xcite .",
    "this allows the user to interact with words that are relevant , but that are also uncertain to the model .",
    "further details of the method are described in appendix  [ sec : linrelappendix ] .      whenever resources are retrieved proactively , our system works as follows",
    "; for simplicity we refer to this as a _ proactive query _",
    ", despite that there is no explicit query from the user .",
    "based on the @xmath3 input words , our query expansion modules retrieve @xmath29 suggested words and add them to the query .    the actual information retrieval is performed using the lucene search engine with the standard cosine - similarity ranking .",
    "in order to test whether our method provides relevant documents , we performed two kinds of simulation experiments . in the simulations ,",
    "the input corresponding to text the user types comes from a given document .",
    "we perform query expansion with the lstm - based text prediction method and with the user intent model . in the baseline experiments , we use only the written input as the queries .",
    "the simulations were performed using the abstracts of the computer science branch of the _ _ arxiv _ _ preprint database , downloaded on october 28 , 2015 .",
    "the branch contains a total of 40 subcategories , which are used as topics in our experiments .",
    "a document in the arxiv database can belong to several subcategories , i.e. , several topics in our case .",
    "we used the _ medium _ lstm architecture of zaremba et al .",
    "@xcite with an tensorflow implementation .",
    "the network has two layers , 650 units per layer , and is unrolled for 35 words .",
    "all the abstracts in the data set were used to train the lstm network .",
    "the training data consisted of 15 m words with a vocabulary of 10k words . training the network took about 36 hours using two geforce gtx titan gpus . due to memory requirements , a random 10% of the abstracts was used to form the document term matrix for the user intent model .    in the lstm - based word prediction ,",
    "the beam width was set to @xmath30 and the depth to @xmath31 .",
    "the branching coefficient was set to @xmath32 and @xmath33 .",
    "we simulate a setting where a user is writing a text about a given topic .",
    "we choose at random a document and simulate inputting sequences of @xmath3 consecutive words from the text .",
    "the variable @xmath3 serves as the size of the context expressed as the number of words from the written text . for instance , if @xmath34 , and the test text is ",
    "machine learning is a subfield \" , the input sequences for the proactive search engine would be  machine learning is \" ,  learning is a \" , and  is a subfield \" .",
    "we envision a situation where the user has to find some relevant background resources about the given topic .",
    "the aim is thus to find other documents about the same topic @xmath35 as the input document . for the proactive queries ( section  [ ssec : queryconstr ] ) , we use @xmath3 input words and @xmath36 .",
    "the lucene search engine was set to return 10 documents .",
    "we use all the documents in the database belonging to the same topic as the test document as the target set @xmath37 . as a measure of performance , we use the _ precision _ of relevant documents with regard to the topic @xmath35 of the input document .",
    "we also run simulations of known - item search , in which the purpose is to study a setting where the user needs to re - find a certain previously seen document .",
    "the setting is the same as for the exploratory search task , except that now we have only one target document in @xmath37 .",
    "we take a random document as the query and perform a lucene search over the rest of the data set to retrieve the highest - scoring document .",
    "this is now our target document .",
    "note that the target document is thus a different document than our input document , and in the simulation we either find the target document or not .",
    "figure  [ fig : exp - clicks ] shows the results of the simulations . on the left - hand side , the retrieval precision in the exploratory search task is shown .",
    "the right - hand figure shows the fractions of known items found in the known - item search task .",
    "first of all , as expected , in both tasks the results improve as the size of the context increases .",
    "this was especially anticipated for known - item search , due to how the target document was selected .",
    "second , the results show that the query expansion methods can improve the precision of the proactively retrieved documents on the exploratory search task .",
    "the lstm - based query expansion improves the results when the context is long enough , i.e. , when @xmath38 . the intent model based query expansion , on the other hand , is suited for small context sizes ( @xmath39 ) . for known - item search ,",
    "the query expansion methods are not equally beneficial .",
    "the intent model again improves the results for small context sizes , but the lstm - based predictions degrade the results .",
    "the simulation results agree rather well with intuition of the query expansion methods .",
    "the user intent model based method expands the query with terms that have high _ tf - idf _ values in the same documents as the input words .",
    "it is conceivable that this is primarily useful when the input context is small , as the expansion can then bring useful additional information to the query . the lstm - based query expansion , on the other hand , dynamically models the written context and can predict upcoming words .",
    "it is unsurprising that this works better when there is enough input context . for exploratory search ,",
    "the predictions made by the lstm network are accurate enough to increase the retrieval precision ; in known - item search the target is smaller , i.e. , a single document , and the predictions are not equally useful .",
    "our research calls for a user study in order to assess the usefulness of the proactive search results in real - world tasks . for this reason",
    "we have implemented an experimental user interface intended to be shown in a corner of the screen , displaying the proactive recommendations ; see figure  [ fig : ui ] .",
    "the interface is designed to allow the user to maintain her focus on the current task at hand , while offering peripherally - shown contextual recommendations .",
    "any data source , e.g. , the user s own emails , a database of documents , or any web pages , can be used as information to be proactively retrieved . in figure",
    "[ fig : ui ] , the resources displayed are _",
    "_ preprints .    for obtaining the current writing context ,",
    "we have implemented a specific text editor , which transmits the current word surrounding the text cursor at each keypress to the proactive search application ; this way the input of @xmath3 words gradually builds up .",
    "similarly , the context could be deduced from , e.g. , the text read in a web browser .    by clicking on any of the resources , its contents ( i.e. , the corresponding arxiv page in the setting of figure  [ fig : ui ] ) are shown in a regular web browser .",
    "we have described a method for query expansion to enhance proactive information retrieval .",
    "the method is based on predicting the most likely continuations of the current input using an lstm network .",
    "the performed experiments provide evidence that our method is able to proactively produce relevant resources .",
    "the query expansion computed using an lstm network improved retrieval precision in an exploratory search task , when enough context data is available .",
    "the results with the method used as comparison , based on user intent modeling using an upper confidence bound algorithm , were partially complementary , improving the results when only limited context is available .",
    "this naturally suggests a further study on combining the two query expansion methods .",
    "further experiments with different kinds of datasets and tasks are in any case needed to validate the results .    in this work , we concentrated on the writing task .",
    "we introduced a simple user interface for showing the proactive search results based on the written context received from a dedicated text editor .",
    "the text predictions produced by the lstm network could also be used to to automatically suggest different continuations for the currently written text , as in the _ reactive keyboard _",
    "@xcite , @xcite , or @xcite .",
    "furthermore , user studies where the users are performing real - world tasks need to be carried out .",
    "finally , in contrast to many of the existing methods for producing proactive recommendations , the proposed method generalizes the context gathering in the sense that the context data can be extracted from several sources , such as a word processing software , pdf reader , or web browser .",
    "the only requirement for the context data is that it has to be in textual form .",
    "this work has been partly supported by the finnish funding agency for innovation ( project re : know ) and the academy of finland ( finnish centre of excellence in computational inference research coin , 251170 ) .",
    "10    k.  athukorala , a.  medlar , k.  ilves , and d.  glowacka .",
    "balancing exploration and exploitation : empirical parameterization of exploratory search systems . in _ proc .",
    "cikm _ , pages 17031706 , 2015 .",
    "p.  auer .",
    "using confidence bounds for exploitation - exploration trade - offs .",
    ", 3:397422 , mar .",
    "t.  babaian , b.  j. grosz , and s.  m. shieber .",
    "a writer s collaborative assistant . in _ proc .",
    "pages 714 , 2002 .",
    "h.  bast and i.  weber .",
    "type less , find more : fast autocompletion search with a succinct index . in _ proc .",
    "sigir _ , pages 364371 , 2006 .",
    "s.  bhatia , d.  majumdar , and n.  aggarwal .",
    "proactive information retrieval : anticipating users information need . in _ proc .",
    "ecir _ , pages 874877 .",
    "s.  bickel , p.  haider , and t.  scheffer . learning to complete sentences . in _ proc .",
    "ecml _ , pages 497504 .",
    "2005 .    n.  boulanger - lewandowski , y.  bengio , and p.  vincent .",
    "modeling temporal dependencies in high - dimensional sequences : application to polyphonic music generation and transcription . in _ proc .",
    "icml _ , pages 11591166 , 2012 .",
    "j.  budzik , k.  hammond , and l.  birnbaum .",
    "information access in context .",
    ", 14(12):3753 , 2001 .",
    "h.  cao , d.  h. hu , d.  shen , d.  jiang , j .-",
    "sun , e.  chen , and q.  yang .",
    "context - aware query classification . in _ proc .",
    "sigir _ , pages 310 , 2009 .",
    "z.  cheng , b.  gao , and t .- y .",
    "actively predicting diverse search intent from user browsing behaviors . in _ proc .",
    "www _ , pages 221230 , 2010 .",
    "j.  j. darragh , i.  h. witten , and m.  l. james .",
    "predictive typing aid .",
    ", 23(11):4149 , 1990 .",
    "s.  dumais , e.  cutrell , r.  sarin , and e.  horvitz .",
    "implicit queries ( iq ) for contextualized search . in _ proc .",
    "sigir _ , pages 594594 , 2004 .",
    "d.  glowacka , t.  ruotsalo , k.  konuyshkova , s.  kaski , g.  jacucci , et  al . directing exploratory search : reinforcement learning from user interactions with keywords . in _ proc .",
    "iui _ , pages 117128 , 2013 .",
    "k.  grabski and t.  scheffer .",
    "sentence completion . in _ proc .",
    "sigir _ , pages 433439 , 2004 .",
    "a.  graves . generating sequences with recurrent neural networks . ,",
    "a.  graves , a.  r.  mohamed , and g.  hinton .",
    "speech recognition with deep recurrent neural networks . in _",
    "proc icassp _ ,",
    "pages 66456649 , 2013 .",
    "s.  hochreiter and j.  schmidhuber .",
    "long short - term memory . , 9(8):17351780 , 1997 .",
    "huang , x.  he , j.  gao , l.  deng , a.  acero , and l.  heck .",
    "learning deep structured semantic models for web search using clickthrough data . in _ proc .",
    "cikm _ , pages 23332338 , 2013 .",
    "p.  koehn . .",
    "cambridge university press , 2009 .",
    "w.  kong , r.  li , j.  luo , a.  zhang , y.  chang , and j.  allan .",
    "predicting search intent based on pre - search context .",
    "in _ proc .  sigir _ ,",
    "pages 503512 , 2015 .",
    "q.  v. le and t.  mikolov . distributed representations of sentences and documents . ,",
    "2014 .    d.  j. liebling , p.  n. bennett , and r.  w. white .",
    "anticipatory search : using context to initiate search . in _ proc .",
    "pages 10351036 , 2012 .",
    "a.  livne , v.  gokuladas , j.  teevan , s.  t. dumais , and e.  adar .",
    "citesight : supporting contextual citation recommendation using differential search . in _ proc .",
    "sigir _ , pages 807816 , 2014 .",
    "m.  c.  p. melguizo , l.  boves , and o.  m. ramos . a proactive recommendation system for writing : helping without disrupting .",
    ", 39(3):516523 , 2009 .",
    "b.  mitra and n.  craswell .",
    "query auto - completion for rare prefixes . in _ proc .",
    "pages 17551758 , 2015 .",
    "h.  palangi , l.  deng , y.  shen , j.  gao , x.  he , j.  chen , x.  song , and r.  ward .",
    "deep sentence embedding using long short - term memory networks . , 2015 .",
    "b.  rhodes and t.  starner .",
    "emembrance agent : a continuously running automated information retrieval system . in _ proc .",
    "paam96 _ , pages 487495 , 1996 .",
    "a.  sordoni , y.  bengio , h.  vahabi , c.  lioma , j.  grue  simonsen , and j .- y .",
    "nie . a hierarchical recurrent encoder - decoder for generative context - aware query suggestion . in _ proc .",
    "cikm _ , pages 553562 , 2015 .",
    "i.  sutskever , j.  martens , and g.  e. hinton .",
    "generating text with recurrent neural networks . in _ proc .",
    "icml _ , pages 10171024 , 2011 .",
    "i.  sutskever , o.  vinyals , and q.  v. le .",
    "sequence to sequence learning with neural networks . , 2014 .",
    "d.  tennenhouse .",
    "proactive computing .",
    ", 43(5):4350 , may 2000 .",
    "m.  b. twidale , a.  a. gruzd , and d.  m. nichols .",
    "writing in the library : exploring tighter integration of digital library use with the writing process .",
    ", 44(2):558580 , 2008 .",
    "p.  vakkari .",
    "a theory of the task - based information retrieval process : a summary and generalization of a longitudinal study .",
    ", 57(1):4460 , 2001 .",
    "s.  vargas , r.  blanco , and p.  mika .",
    "term - by - term query auto - completion for mobile search . in _ proc .",
    "wsdm _ , pages 143152 , 2016 .",
    "o.  vinyals , a.  toshev , s.  bengio , and d.  erhan .",
    "show and tell : a neural image caption generator . in _ proc .",
    "cvpr _ , pages 31563164 , 2015 .",
    "b.  xiang , d.  jiang , j.  pei , x.  sun , e.  chen , and h.  li .",
    "context - aware ranking in web search . in _ proc .",
    "sigir _ , pages 451458 , 2010 .",
    "w.  zaremba , i.  sutskever , and o.  vinyals . recurrent neural network regularization . , 2014 .",
    "for computing the user intent model , we use a training database consisting of @xmath40 documents , from which @xmath28 unique words are extracted by excluding stop words . the @xmath11th document in the database",
    "is represented by a feature vector @xmath41 where @xmath42 is the _ tf - idf _ value of the @xmath10th word .",
    "we denote by @xmath43 the _ tf - idf _ matrix of the @xmath40 documents , where each column of @xmath44 corresponds to one document feature vector and each row corresponds to a distribution of the words over the documents .",
    "the user intent model is estimated using the context formed using @xmath3 previously written words . based on this input , a set of word weights",
    "are computed by using the linrel algorithm proposed in  @xcite .",
    "we denote the relevance vector of observed words by @xmath45^{n}$ ] , where @xmath46 corresponds to having observed the @xmath10th word in the input .",
    "if the @xmath10th word does not occur in the subsequent input words , its relevance value starts decreasing such that @xmath47 , where @xmath48 is the number of sets of input words since the last occurrence of the @xmath10th word . for omitting words having very low relevance values",
    ", we use a threshold @xmath49 : when @xmath50 the value of @xmath51 is set to zero .",
    "the observed values in @xmath52 , corresponding to the input words so far , are assumed to be formed from the model @xmath53 where @xmath54 is the estimated _ user intent model _ describing what documents from the training set are currently estimated to be relevant for the user .    given @xmath52 and @xmath44 , the user model @xmath55 can be obtained as @xmath56 where @xmath57 is an identity matrix of size @xmath58 and @xmath59 is a regularization parameter , set to @xmath60 in our experiments .",
    "the @xmath29 words to be included in the expanded query correspond to the @xmath29 maximum components of the vector @xmath65 with words appearing in the input excluded . here",
    "@xmath66 is the exploration / exploitation parameter controlling the trade - off between exploring the search space ( large @xmath67 ) and focusing on the currently most promising region ( small @xmath67 ) .",
    "we use here @xmath68 as recommended in the literature  @xcite ."
  ],
  "abstract_text": [
    "<S> we describe a method for proactive information retrieval targeted at retrieving relevant information during a writing task . in our method , the current task and the needs of the user are estimated , and the potential next steps are unobtrusively predicted based on the user s past actions . </S>",
    "<S> we focus on the task of writing , in which the user is coalescing previously collected information into a text . </S>",
    "<S> our proactive system automatically recommends the user relevant background information . </S>",
    "<S> the proposed system incorporates text input prediction using a long short - term memory ( lstm ) network . </S>",
    "<S> we present simulations , which show that the system is able to reach higher precision values in an exploratory search setting compared to both a baseline and a comparison system .    </S>",
    "<S> < ccs2012 > < concept > < concept_id>10002951.10003317.10003325.10003327</concept_id > </S>",
    "<S> < concept_desc > information systems  query intent</concept_desc > < concept_significance>300</concept_significance > </S>",
    "<S> < /concept > < concept > < concept_id>10002951.10003317.10003331</concept_id > < concept_desc > information systems  users and interactive retrieval</concept_desc > < concept_significance>300</concept_significance > </S>",
    "<S> < /concept > < concept > < concept_id>10003120.10003121.10003128.10011753</concept_id > < concept_desc > human - centered computing  text input</concept_desc > < concept_significance>300</concept_significance > < /concept > < </S>",
    "<S> concept > < concept_id>10010147.10010257.10010293.10010294</concept_id > < concept_desc > computing methodologies  neural networks</concept_desc > < concept_significance>300</concept_significance > < /concept > </S>",
    "<S> < /ccs2012 > </S>"
  ]
}