{
  "article_text": [
    "efficient methods for the characterization of quantum systems to extremely high precision are important both to reach new regimes of physics and to build robust quantum technologies  @xcite .",
    "one of the most fundamental characterisation tasks is the estimation of the parameters of a hamiltonian in a two - level system .",
    "several previous studies  @xcite used a method of repeatedly initializing the two - level system and then performing measurements in a fixed basis after consecutively longer intervals ( during which the system evolves under its hamiltonian ) and then averaging many runs . by calculating the fourier transform of the resulting signal and identifying its peak ,",
    "it is possible to obtain an estimate for the rate of evolution , and thus the desired hamiltonian parameter .",
    "this approach is noticeably more efficient ( faster ) in practice than quantum process tomography  @xcite , requiring only measurements in one particular basis ( as state initialization can be done via measurement ) .",
    "however , it still demands a large number of measurements for moderate accuracy .",
    "for example , in ref .",
    "@xcite , the two parameter estimation procedure required at least @xmath3 measurements in order to reach a joint variance of @xmath4 in the parameters being estimated .",
    "such large numbers of measurements can pose a problem , especially in solid - state systems where the measurement time is typically the slowest timescale , often many orders of magnitude longer than the period for coherent evolution . to specifically address such situations , we quantify resources in our estimation schemes as @xmath1 , the number of measurements used , rather than the total evolution time as is commonly used in phase estimation schemes using optics and assuming instantaneous measurements  @xcite ( however cf .",
    "we note however that our techniques could easily be modified to take into account both the waiting time and the measurement time .",
    "we emphasise that , unlike schemes based on the quantum phase estimation algorithm  @xcite such as that proposed in refs .",
    "@xcite , we restrict our measurement to a fixed basis and do not allow any controlling unitary dynamics",
    ". that is , our schemes are limited to preparing a pure state in this fixed basis , evolving for some time under the hamiltonian , and measuring in this same basis .",
    "the motivation for this restriction is simple : in most situations , the unitary required to change bases would be generated by the very hamiltonian parameter that we are attempting to estimate .",
    "a motivating example is provided by recent experimental progress in the development of spin qubits in semiconductor quantum dots , specifically , gaas double dot systems where a qubit is defined using two electron spins in a singlet / triplet configuration  @xcite . with one electron in each dot ,",
    "the states @xmath5 and @xmath6 experience an energy splitting proportional to the difference in the @xmath7-component of the magnetic field , @xmath8 , resulting from the hyperfine interaction with nearby lattice nuclear spins .",
    "because variations in @xmath8 are the primary source of decoherence in these spin qubits , there has been considerable recent interest in the measurement and control of this nuclear magnetic field by using the spin qubit as both a probe and feedback mechanism  @xcite .",
    "in addition , a well - known and stable value of this field can serve as a source of coherent quantum operations ( i.e. , logic gates ) on the spin qubit  @xcite .",
    "( however , one can not use this effect to change the measurement basis and implement a quantum phase estimation algorithm as in  @xcite without first estimating the field ; thus , our requirement for fixed basis measurements . ) with the recent demonstration of single - shot projective measurements of the spin qubit  @xcite , parameter estimation of @xmath8 in such systems is possible  @xcite .",
    "the system coherently evolves on a nanosecond timescale , whereas the measurement time is @xmath9s  @xcite .",
    "( in these systems the coherent evolution is switched off during the measurement process . ) for this estimation problem , then , we seek schemes that minimize the number of measurements required for a given accuracy .    in this paper , we consider the performance of a range of schemes for such a parameter estimation , using numerical simulations .",
    "first , we demonstrate that a bayesian approach outperforms the fourier estimation techniques .",
    "we show that , while schemes using a predetermined sequence of measurements yield a mean square error ( mse ) decreasing polynomially in the number of measurements , a drastic improvement can be found by using _ adaptive _",
    "measurement approach  @xcite .",
    "the adaption is done by _",
    "local optimization _",
    "@xcite : the time intervals between preparation and measurement is chosen to minimize the expected mse , conditioned on the result of that future measurement .",
    "numerical simulations for the adaptive scheme are consistent with exponential scaling in @xmath1 for the mse in the estimate of the parameter , while the best nonadaptive algorithm found has a power law scaling in @xmath1 .",
    "our result demonstrates that exponential scaling of the estimate precision can be achieved with a single , fixed basis of measurement , rather than requiring measurements in arbitrary bases as in the quantum phase estimation algorithm  @xcite .",
    "finally , we show that quite good performance is achievable by a _ locally optimal non - adaptive _ scheme .",
    "we consider the problem of estimating a single unknown parameter of a qubit hamiltonian , of the form @xmath10 . to simplify later calculations we assume that @xmath11 is a random parameter uniformly distributed over the interval @xmath12 $ ] , where @xmath13 is the largest possible value of @xmath11 . in order to estimate @xmath11 ,",
    "we probe that system with projective measurements of the @xmath14 component of spin at different times .",
    "( note that this measurement basis is _ not _ the energy eigenbasis of the hamiltonian ; otherwise , parameter estimation would not be possible . )",
    "we initialize the state as an eigenstate @xmath15 of @xmath16 at @xmath17 ; we note that this initialization is naturally performed at each step by the previous measurement .",
    "the nyquist ",
    "shannon theorem suggests that we want to choose the time between preparation and measurement to be as small as @xmath18 .",
    "this minimum time interval @xmath19 ( and hence maximum parameter range @xmath20 $ ] ) will be determined by experimental considerations , and it is therefore reasonable to assume that the _ waiting time _ between the @xmath21th preparation and the @xmath21th measurement , is an integer multiple of @xmath19 .",
    "that is , @xmath22 .",
    "the hamiltonian in this case generates the time evolution @xmath23 and the probabilities for the outcomes of the @xmath21th measurement are @xmath24 the relevant resource in our estimation procedure is the number of measurements .",
    "the problem then becomes : given a fixed number of measurements @xmath1 , how should one proceed in determining the waiting times @xmath25 , and how does one infer @xmath11 from the results of the measurements ?",
    "this problem falls within the domain of _ quantum parameter estimation _ , wherein one seeks to identify an unknown parameter influencing the preparation or dynamics of a quantum system .",
    "the canonical example is estimating the phase of a unitary operator , which is closely related to characterizing a hamiltonian with an unknown magnitude , as in this paper .",
    "quantum parameter estimation techniques can allow for high - precision phase estimation below the classical ( shot noise limit ) as well as power algorithms for quantum computation  @xcite .",
    "in quantum parameter estimation problems , such as the one we consider , it is necessary to carefully tailor measurements and process their outcomes in order to make inferences on the ( unaccessible ) parameter of interest . while many techniques for quantum parameter estimation make use of entanglement  @xcite , it is in some situations possible to replace entangled states with repeated application of the unknown unitary on a single system prior to measurement  @xcite .",
    "adaptive measurements which have been proposed and used for quantum parameter estimation  @xcite , quantum tracking  @xcite , state discrimination  @xcite , state estimation  @xcite , and quantum computing  @xcite  can play a key role in this context because of the phase ambiguity inherent in estimating a parameter that appears in the problem only as the scale of an anti - hermitian operator ( i.e. @xmath26 ) which is exponentiated  @xcite .",
    "one question of interest in quantum parameter estimation is how close the measurement comes to the so - called heisenberg limit @xcite .",
    "this is the limit on the variance , or fisher information , of the unknown parameter , imposed by heisenberg s uncertainty principle .",
    "for example , in the case of phase estimation , this limit scales as @xmath27 , where @xmath28 is the total number of times the unitary is applied , whether it is applied @xmath28 times to a single system , or once each across @xmath28 systems , or anything in between @xcite .",
    "restricting to a single system ( as in our paper ) , in the asymptotic limit @xmath29 , the run - time of any experiment that can attain the heisenberg limit will scale as @xmath30 .",
    "however , as noted above , in the practical regime of interest to us , the run - time of the experiment will be determined by @xmath1 , the number of preparation and measurement steps , not the evolution time @xmath31 between preparation and measurement .",
    "since there is no fixed relation between @xmath30 and @xmath1 ( except that @xmath32 ) , the heisenberg limit does not automatically translate into any limit on the variance as a function of @xmath1 .",
    "rather , we must determine how well various schemes scale with @xmath1 ( in the regime of interest ) , and thereby determine the best of them .",
    "in the following sections , we present techniques for hamiltonian parameter estimation based on fourier methods ( a ) , and then those based on bayesian methods ( b  d ) . the latter include simple non - adaptive bayesian schemes ( b ) , a locally optimal adaptive bayesian scheme ( c ) , and a locally - optimal non - adaptive bayesian scheme ( d ) .",
    "a simple strategy for this problem is to measure at uniformly distributed times @xmath33 , i.e. , to choose @xmath34 .",
    "the set of measurement results constitutes a measurement record , and can be loosely thought of as one realization of a random process @xcite .",
    "one method to estimate the parameter is to fourier transform the measurement record and identify the peak of the spectrum as the best estimate for @xmath11  @xcite .",
    "however , this is not the only strategy .",
    "for example , for each @xmath35 we could prepare , evolve and measure twice , with the range @xmath36 .",
    "the resulting measurement record can be viewed as two realizations of the random process , and averaging these two realizations will reduce the effect of projection noise ( i.e. , the noise due to the indeterminacy of the measurement outcomes ) .",
    "we can define a family of schemes , wherein @xmath37 different choices of waiting times are each repeated @xmath38 times , with a total of @xmath39 measurements .    using this technique",
    "we have considered partitions of @xmath1 where @xmath40 .",
    "we find that @xmath41 give the best mse scaling depending on the value of @xmath1 ; see fig .",
    "[ standard ] . in what follows ,",
    "we use the partitioning that minimizes the mse for a given @xmath1 , and call this method the _ best fourier method_. the mse in the estimate of @xmath11 as a function of @xmath1 for this method sets the benchmark to which our more sophisticated schemes will be compared . for a large number of measurements @xmath1 , the scaling of the mse is found to have power - law scaling in @xmath1 with a power close to @xmath42 .",
    "specifically , for a fit of @xmath1 from @xmath43 to @xmath44 with each point sampled @xmath45 times , the @xmath46 confidence interval in the power is @xmath47 , @xmath48 .    .",
    "the `` best fourier method '' ( solid line ) for a particular @xmath1 is given by the best performing scheme for that @xmath1 .",
    "to generate the data for this plot each scheme was sampled @xmath49 times , consequently the error bars ( not shown ) are slightly smaller than the markers for the data points . ]",
    "we now consider performing a bayesian analysis of the same schemes described above . here",
    ", one s knowledge about the unknown parameter @xmath11 is represented as a probability distribution @xmath50 . using the mean of this distribution as",
    "one s estimate gives a mse which is equal to the variance of this probability distribution , averaged over all realizations .",
    "thus we can use the variance of the posterior ( i.e. post - measurement ) @xmath50 as the measure of precision for bayesian schemes .",
    "we take the uniform prior probability distribution @xmath51 . at each measurement ,",
    "the outcomes @xmath52 and @xmath53 are expected with probabilities given by eq .",
    "( [ prob ] ) and so the total probability distribution can be updated each measurement step using bayes rule . the general expression for conditioned probability distribution of @xmath11 given @xmath21 measurements , is @xmath54,\\ ] ] where @xmath55 ( @xmath56 ) corresponds to learning that the @xmath57th result is @xmath52 ( @xmath53 ) , @xmath58 denotes the waiting time for the @xmath21th measurement , and @xmath59 is a normalization constant .",
    "these conditional probabilities allow for any bayesian parameter estimation task to be performed on a given measurement record .",
    "we can avoid the computationally costly practice of discretizing the distribution in @xmath11 by using the following technique .",
    "( [ product ] ) is an even function of @xmath11 , it can be represented as a fourier cosine series : @xmath60 where @xmath61 .",
    "the distribution is normalized by dividing by @xmath62 . because the number of terms in eq .",
    "( [ sumo ] ) is finite , the representation of the distribution is exact .",
    "it is then possible to derive an analytic expression for @xmath63 ( and @xmath64 ) using the parseval theorem , which relates the convolution of two functions , @xmath65 and @xmath11 ( or @xmath66 ) , to the summation of the product of their corresponding fourier coefficients .",
    "performing this calculation gives an explicit formula for the variance , @xmath67 , given by @xmath68 \\\\",
    "-\\left [ \\frac{\\omega_{0}}{2}+\\sum_{q=1}^k\\frac{c_q\\omega_{0}[(-1)^q-1]}{c_0(q\\pi)^2}\\right ] ^2.\\end{gathered}\\ ] ] with this technique , we can perform a bayesian analysis of the measurement outcomes of the predefined parameter estimation schemes discussed above .",
    "we simulated over @xmath49 runs for @xmath69 and @xmath1 up to @xmath43 measurements to obtain the variance as a function of @xmath1 shown on fig .",
    "[ nonadplot ] . the simplest algorithm with @xmath70 ,",
    "@xmath71 yields an asymptotic scaling of the variance @xmath72 .",
    "this is obtained by fitting the first @xmath73 steps ( @xmath46 confidence interval of power law scaling @xmath74 , with @xmath75 ) . by contrast ,",
    "algorithms with @xmath69 that uniformly distribute measurement times exhibit an improved error scaling of the variance @xmath76 ( for @xmath77 , the first @xmath78 steps yield the @xmath46 confidence interval for the power to be @xmath79 , with @xmath75 ) .",
    "this latter result demonstrated a significant improvement over the fourier analysis using the same sequences , an improvement due solely to the superior data processing of bayesian analysis .",
    "we find that @xmath80 is the most effective for smaller @xmath1 ( likely due to a reduction in projection noise ) , whereas @xmath77 has a better scaling for large @xmath1 .",
    "samples are taken at at @xmath71 .",
    "the downward triangles are for the bayesian @xmath77 method where the @xmath1 samples are sequentially taken at times @xmath81 ( here @xmath82 ) .",
    "the squares are for the bayesian @xmath80 method where each point is sampled three times , i.e. , @xmath83 .",
    "the circles are for the locally optimal non - adaptive ( lona ) method . ]",
    "we next consider an adaptive method in which the waiting times @xmath84 are chosen based on previous results .",
    "specifically , we adaptively chose @xmath85 so that the conditional expectation of the variance @xmath86 $ ] after the measurement is minimized .",
    "the conditional expectation of the variance after the @xmath21th result for the waiting time @xmath85 is @xmath87=\\frac {   { c_{k}(0|{+ } ) } v_{k|{+ } }   + { c_{k}(0|{- } ) } v_{k|{- } }    } { c_{k}(0|{+})+c_{k}(0|{-})}\\ ] ] where @xmath88 denotes the fourier coefficient @xmath89 of eq .",
    "( [ sumo ] ) given the measurement outcome @xmath90 from the @xmath21th measurement and @xmath91 is the variance conditional on this outcome .",
    "the factors multiplying each @xmath92 are the probabilities of the outcomes .",
    "our strategy is to , at each step , choose the waiting time @xmath93 in order to minimize the expected variance of posterior distribution @xmath94 $ ] .    )",
    "the bayesian method where the @xmath1 samples are taken at at @xmath71 ; ( @xmath95 ) the bayesian method where the @xmath1 samples are sequentially taken at times @xmath96 ; ( @xmath97 ) the locally optimal adaptive strategy .",
    "the average mse was computed from @xmath98 simulations and the largest possible allowed waiting time was @xmath99 .",
    "the shaded region on the adaptive strategy plot represents the standard deviation of the mse . ]",
    "[ adplot ] shows the scaling of the variance as a function of @xmath1 for this adaptive strategy , compared with the above non - adaptive bayesian schemes . unlike the previous schemes where we could fit numerics beyond @xmath100 , here we are limited up to @xmath101 .",
    "fitting to the first @xmath102 measurements , the mse of this adaptive strategy scales as @xmath103 with @xmath104 ( with @xmath46 confidence interval for exponent @xmath105 of @xmath106 ) and @xmath107 .",
    "we compare this exponential fit with the best power fit , which gives @xmath108 with @xmath109 of only @xmath110 .",
    "that is , we have obtained an exponentially decreasing mse similar to that of ref .",
    "@xcite without the need to alter measurement bases throughout the protocol .",
    "while scaling in the number of steps can be exponential in @xmath1 , this does not mean breaking the heisenberg limit on the variance , scaling as @xmath27 .",
    "the reason is that the adaptive algorithm ( as well as other previously discussed schemes ) require exponentially longer waiting times for large number of steps , so that @xmath30 varies exponentially with @xmath1 .",
    "as noted above , in the truly asymptotic regime , the evolution time will become much longer than the measurement time . in",
    "that limit our algorithm will scale worse than the heisenberg limit in terms of total run - time , since it is optimized for a different problem .      due to the computation required in optimally choosing the waiting time at each measurement step , the complexity of the adaptive scheme could present problems for practical use .",
    "we therefore seek to identify non - adaptive schemes with the best possible performance .",
    "several heuristics enable one to design such schemes ; we will describe one .    in the initial step , we begin with a flat prior and determine what waiting time will minimize @xmath111 $ ] . for the second measurement ,",
    "we determine the optimal waiting time to minimize @xmath112 $ ] given that a measurement was performed at @xmath113 but the result is not known .",
    "this process is then repeated .",
    "we can find the first 20 steps analytically  i.e. , @xmath114 .",
    "after that , we use a numerical search . because these waiting times are determined from expected rather than actual statistics , it is non - adaptive ; this string of waiting times is determined offline .",
    "we denote this scheme the locally optimal non - adaptive ( lona ) scheme . because of computational complexity",
    ", it becomes intractable to determine the error scaling of lona for large number of steps .",
    "however this algorithm performs well for small @xmath1 ( see fig",
    ".  2 ) , and so is appealing in situations where relatively few measurements are necessary and adaptive methods are not feasible .",
    ".comparison of schemes .",
    "number of measurements required to meet a desired variance of @xmath4 and @xmath115 . [ cols=\"<,^,^\",options=\"header \" , ]",
    "we have shown that bayesian methods can be used for efficient hamiltonian parameter estimation schemes .",
    "our adaptive bayesian algorithm , which is locally optimal , provides an exponential improvement in the scaling of the variance with the number of measurements performed , and unlike methods based on the quantum phase estimation algorithm does not require adaptive measurement bases  the measurements are in a fixed basis and only the waiting times between them are adapted .",
    "see table  [ tab : table ] for a comparison of schemes .",
    "we note that decoherence will in general affect the performance of these schemes . recently",
    ", considerable progress has been made in the understanding of how to determine asymptotic limits in parameter estimation in the presence of decoherence  @xcite . while a detailed analysis of the effects of decoherence is beyond the scope of this work",
    ", we note that simulations based on realistic parameters for gaas double dot spin qubits possessing coherent evolution on the nanosecond timescale and dephasing times of microseconds demonstrate only a small effect on the performance of the lona scheme up to @xmath116 measurements .",
    "we emphasise that , in our analysis , we have used the number of measurements @xmath1 to represent the resource cost of the scheme ; this differs from typical phase estimation scenarios , where @xmath1 represents the total number of applications or probes ( e.g. , number of photons ) of the hamiltonian  @xcite . as such , the scalings of our various schemes can not be directly compared with other results , nor the terminology based around the standard quantum limit or the heisenberg limit . for a simple comparison , it should be noted that the waiting time in our schemes typically becomes exponetially long for large @xmath1 , and so even the adaptive bayesian scheme with its exponential scaling in terms of number of measurements @xmath1 will appear heisenberg - limited when total time is used instead .",
    "the authors would like to acknowledge fruitful conversations with jared h. cole , jason f. ralph , and david reilly .",
    "this research was supported by the australian research council centre of excellence scheme ( project numbers ce110001027 and ce110001013 ) .",
    "sdb acknowledges support from aro / iarpa project w911nf-10 - 1 - 0330 .",
    "jc acknowledges support from national science foundation grant no .",
    "phy-0903953 and office of naval research grant no .",
    "n00014 - 11 - 1 - 008 ."
  ],
  "abstract_text": [
    "<S> we investigate schemes for hamiltonian parameter estimation of a two - level system using repeated measurements in a fixed basis . </S>",
    "<S> the simplest ( fourier based ) schemes yield an estimate with a mean square error ( mse ) that decreases at best as a power law @xmath0 in the number of measurements @xmath1 . by contrast </S>",
    "<S> , we present numerical simulations indicating that an adaptive bayesian algorithm , where the time between measurements can be adjusted based on prior measurement results , yields a mse which appears to scale close to @xmath2 . </S>",
    "<S> that is , measurements in a single fixed basis are sufficient to achieve exponential scaling in @xmath1 . </S>"
  ]
}