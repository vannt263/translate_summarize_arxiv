{
  "article_text": [
    "rapidly rotating neutron stars are among the most promising sources of continuous gravitational waves .",
    "they can emit gravitational waves through a variety of mechanisms , including unstable oscillation modes  @xcite and deformations of the crust  @xcite .",
    "neutron stars can radiate powerful beams of radio waves from their magnetic poles . if a neutron star s magnetic poles are not aligned with its rotational axis , the beams sweep through space , and if the earth lies within the sweep of the beams , the star is observed as a point source in space emitting bursts of radio waves .",
    "such a neutron star is called a pulsar  @xcite . since the first discovery  @xcite , around 2000 pulsars",
    "have been detected  @xcite .",
    "due to magnetic dipole radiation and gravitational radiation , the rotational frequencies of neutron stars slowly decrease in time .",
    "other than this effect , gravitational waves from isolated rotating neutron stars are essentially monochromatic in the rest frame of the star .",
    "the waves are continuous and their frequency is determined by the rotational frequency of the star .",
    "the motion of the detector as the earth rotates about its axis and around the sun , however , modulates the phase as well as the amplitude of the received signal . in order to recover the signal from interferometric data optimally ,",
    "both of these effects must be taken into account .",
    "detecting gravitational waves from neutron stars could reveal information about the strength of neutron star crusts and the equation of state of the nuclear matter that makes up the star  @xcite .",
    "continuous gravitational waves may also be produced by other sources , such as cosmic strings  @xcite .",
    "there are a number of techniques available for continuous wave searches .",
    "these techniques can be loosely divided into two categories : ( 1 ) coherent methods  @xcite , which keep track of the phase of the gravitational wave signals over long periods of time , and ( 2 ) semi - coherent methods  @xcite , which combine shorter periods of data without tracking the phase ( for example , taking fourier transforms of short segments of data and then summing the power ) .",
    "when the sky location and phase evolution of a neutron star are known , a coherent search for continuous gravitational waves is relatively straightforward  @xcite . assuming that the noise in a gravitational wave detector follows gaussian statistics , in the presence of a signal",
    ", the signal to noise recovered in a search increases with the square root of the amount of data used in the search .",
    "this is because the signal amplitude grows linearly while the noise follows a random walk .",
    "thus , with enough data , it is possible to recover any continuous signal out of noisy data .",
    "if certain parameters of the signal ( sky location , frequency , spindowns and binary parameters ) are not known the search becomes much more involved .",
    "the reason is that the number of points needed to cover the search parameter space ( and ensure no signals are lost ) grows like a large power of the amount of data used  @xcite .",
    "this makes the sensitivity of gravitational wave searches computationally bound : one can not simply integrate arbitrary amounts of data to gain sensitivity because there is not enough computational power available to perform the search .",
    "thus , more efficient code and greater computing power are highly desirable , since they translate into more data being analyzed and therefore an increase in the sensitivity of gravitational wave searches .",
    "a promising method for blind searches involves exploiting large - scale correlations in the coherent detection statistic  @xcite .",
    "another method that has been successful in these kinds of searches is the hierarchical scheme of incoherently combining coherent sets of data .",
    "some of the methods currently under use include the hough transform and stack - slide  @xcite .",
    "in this paper we focus on an efficient implementation of coherent techniques .",
    "the method we present here is similar to several previous implementations  @xcite , in that it uses fast fourier transforms ( ffts ) to calculate the so - called @xmath0-statistic  @xcite , the logarithm of the likelihood function maximized over the intrinsic ( and unknown ) parameters of the gravitational wave produced by a neutron star , but with one very important difference .",
    "we resample the time domain data to the solar system barycenter before taking a fft .",
    "this allows us to use a single fft to calculate the detection statistic for arbitrarily many frequencies and an arbitrary amount of observation time , while previous implementations have a maximum frequency band and observation time that can be calculated with a single fft , which are determined by losses due to phase mismatch .",
    "another set of techniques , described in  @xcite , implement stroboscopic resampling methods described in  @xcite .",
    "the stroboscopic method requires data at full bandwidth , and is therefore not suitable for distributed computing applications such as einstein@home .",
    "in section  [ sec : signal ] we review the signal properties and the nearly - optimal coherent statistic that can be used to extract continuous signals from interferometric gravitational wave data . in section  [ sec : implement_bary_resamp ]",
    "we discuss how to implement the calculation of the nearly - optimal coherent statistic in a computationally efficient way in both the time and frequency domains . in section  [ sec : results ] we describe the results of a computer code using this algorithm on software injections of gravitational waves into gaussian noise .",
    "lastly , in section  [ sec : practical ] we address important technical issues to do with practical implementations of barycentric resampling .",
    "in this section we closely follow the method of jaranowski , krolak , and schutz @xcite to provide the background on the signal and the detection statistic . power - recycled fabri - perot michelson interferometers such as those used by the laser interferometer gravitational wave observatory ( ligo ) are sensitive to the strain caused by gravitational waves passing through it . the strain measured at a detector",
    "can be written as  @xcite @xmath1 where @xmath2 is the time in the detector frame , and @xmath3 and @xmath4 are the `` plus '' and `` cross '' polarizations of gravitational wave . @xmath5 and @xmath6 are the beam - pattern functions of the interferometer and are given by @xmath7 , \\label{eq2}\\ ] ] and @xmath8 , \\label{eq3}\\ ] ] where @xmath9 is the polarization angle of the wave and @xmath10 is the angle between detector arms ( which in the case of ligo is 90@xmath11 ) .",
    "the functions @xmath12 and @xmath13 both depend on time and location of source and detector , but are independent of the polarization angle @xmath9 .    in the detector frame",
    "the phase of a gravitational wave produced by an isolated neutron star can be written as  @xcite @xmath14 where @xmath15 is the phase at the start time of the observation , @xmath16 is the @xmath17 derivative of the frequency , @xmath18 is the speed of light , @xmath19 and @xmath20 are the right ascension and declination of the source , @xmath21 is the unit vector of the source in the solar system barycenter ( ssb ) reference frame , @xmath22 is the position vector of the detector in the same frame , and @xmath23 is the order of the expansion . neglecting changes in the proper motion of the star , the third term in eq .",
    "( [ eq4 ] ) is a correction to the phase due to the detector motion relative to the neutron star .",
    "we can define @xmath24 , as well as defining @xmath25 and @xmath26 equations  ( [ eq4pt1 ] ) and ( [ eq4pt2 ] ) let us write    @xmath27+\\phi_{s}(t;f^{(k)},\\alpha,\\delta ) , \\label{eq5}\\ ] ]    which has the modulation due to the detector s motion around the ssb clearly separated from the modulation due to the gravitational wave s intrinsic frequency , although not the derivatives of the frequency .",
    "an almost optimal statistic for the detection of continuous gravitational wave signals is called the @xmath28-statistic  @xcite .",
    "it is the logarithm of the likelihood function maximized over the intrinsic and unknown signal parameters .",
    "the @xmath28-statistic is given by @xmath29 where @xmath30 is the one - sided spectral density of the detector s noise at frequency @xmath31 and @xmath32 is the observation time .",
    "@xmath33 , @xmath34 , @xmath35 , and @xmath36 are given by @xmath37 with @xmath38 @xmath39 and @xmath40 are integrals defined as @xmath41 and @xmath42    we define a new time variable called @xmath43 as follows : @xmath44    taking a derivative with respect to @xmath2 on both sides of eq .",
    "( [ eq11 ] ) , we get    @xmath45    from eqs .",
    "( [ eq4pt2 ] ) and ( [ eq11b ] ) , we get    @xmath46    where @xmath47 is the velocity of the detector in the ssb frame and thus @xmath48 is the doppler shift of the source with respect to the detector . for a detector located on earth ,",
    "the maximum doppler shift experienced is of the order of @xmath49 .",
    "using this fact and equation  [ eq11b ] we get @xmath50",
    ".    we can thus rewrite the eqs . for @xmath39 and @xmath40 as @xmath51 and @xmath52 which are",
    "just the fourier transforms of the resampled data and the detector response , multiplied by a phase @xmath53  @xcite . eqs .",
    "( [ eq12 ] ) and ( [ eq13 ] ) can be efficiently evaluated using ffts .",
    "details of the resampling procedure can be found in sec .",
    "[ resamp ] .",
    "gravitational wave detectors collect data at the rate of about 16 - 20 khz for spans of time on the order of a year .",
    "this means that typical searches for gravitational waves will involve on the order of a terabyte ( tb ) of data",
    ". computers currently have memories of a few gigabytes ( gb ) , making it necessary to break up the data into pieces that can fit in the memory of a single computer . to analyze the full data set hundreds to thousands of these computers",
    "can then be used together in the form of a beowulf cluster , or tens to hundreds of thousands with distributed computing systems such as einstein@home  @xcite .",
    "the @xmath28-statistic can be calculated from a time series directly by following the steps outlined in section  [ sec : signal ] . however , due to the large amounts of data involved , it is impractical to do this for the entire data set . one way to address",
    "this problem is to divide the data into band - limited time series , making it possible to analyze one small sub - band at a time .",
    "time series spanning different frequency bands are then analyzed in parallel on a beowulf cluster or a distributed computing system . in this section",
    "we provide details on how this is accomplished in the time domain , and address some of the difficulties that arise .",
    "let the output of the instrument be the time series @xmath54 , and its fourier transform be @xmath55 if we consider the fourier transform of the complex time series @xmath56 , @xmath57 it is obvious that multiplying the time series @xmath54 by @xmath58 has shifted all the frequencies in the time series @xmath54 by @xmath59 .",
    "this procedure is referred to as complex heterodyning .",
    "if just a small frequency band @xmath34 of data around @xmath59 is of interest , low - pass filtering followed by downsampling can be used to reduce the bandwidth of the data appropriately .",
    "specifically , if we wish to downsample by a factor @xmath36 , the new nyquist frequency of our time series will be given by @xmath60 a simple but effective downsampling technique involves picking every @xmath61 point in the time series . to avoid aliasing effects however , prior to downsampling a low pass filter",
    "must be applied to the data with a sharp fall - off around the new nyquist frequency .",
    "the heterodyned , band - limited , downsampled complex time series will have a sampling time @xmath62 .",
    "for example , suppose we are only interested in analyzing data between 990 hz and 1 khz . by multiplying the data with the phase factor @xmath63 , data at 995 hz",
    "moves to 0 hz ( dc ) , 990 hz moves to -5 hz , and 1 khz to + 5 hz ( we have taken @xmath2 to be measured in seconds ) . to avoid aliasing problems when we downsample",
    ", we low - pass filter the data at 5hz , the new nyquist frequency . we can then downsample by picking one point out of every 100 .",
    "the resulting complex time series will be sampled at 10 hz and contain all the information in the original time series between 990 hz and 1 khz .      in this section",
    "we explain how to use the low bandwidth heterodyned complex time series to compute the @xmath28-statistic given by eq .",
    "( [ eq6 ] ) .    in the following we will work only with @xmath39 .",
    "the procedure for @xmath40 is completely analogous .",
    "it is easiest to begin with the integral definition for @xmath39 in eq .",
    "( [ eq7 ] ) with the phase explicitly written out , namely , @xmath64 and a similar expression holds for @xmath40 .",
    "the heterodyned version of @xmath39 is @xmath65 if we already have a complex heterodyned time series @xmath66 ( heterodyned in the detector frame ) , we can use it to absorb some ( but not all ) of the heterodyne exponent in eq .",
    "( [ fa2 ] ) as follows : @xmath67 this means that rather than eq .",
    "( [ fa2 ] ) , we should evaluate @xmath68 where @xmath69 at this point we have an expression which looks like eqs .",
    "( [ eq7 ] ) and ( [ eq8 ] ) , and we can write the integral over @xmath2 instead as an integral over @xmath70 : @xmath71 with a similar expression for @xmath40 .    the discrete version of eq .",
    "( [ fa4 ] ) for a time series with @xmath72 points reads @xmath73 and a similar expression holds for @xmath40 : @xmath74 where @xmath75 is the @xmath17 datum in the time series as measured in the barycentric frame and @xmath76 .",
    "the relationship between @xmath43 and @xmath2 can be written as @xmath77 this relationship between @xmath78 and @xmath75 can be used to calculate @xmath79 from the time series @xmath80 . in practice ,",
    "one starts out with @xmath80 , i.e. data sampled regularly in the detector frame",
    ". then we calculate @xmath81 , which are detector times corresponding to regularly spaced samples in the barycentric frame .",
    "these @xmath82 are irregularly sampled in the detector frame , but since we have @xmath80 , we can calculate @xmath83 by using interpolation .",
    "the interpolated time series @xmath83 is the @xmath79 of eqs .",
    "( [ eq19 ] ) and ( [ eq20 ] ) .",
    "a similar procedure may be used to calculate the @xmath84 from @xmath85 , and the @xmath86 from @xmath87 .",
    "the factor of @xmath88 in eqs .",
    "( [ eq19 ] ) and ( [ eq20 ] ) is calculated using equation  ( [ eq4pt1 ] ) .",
    "in this case , instead of calculating @xmath89 , we calculate @xmath90 , which is equivalent to calculating @xmath91 .",
    "while in theory one has to calculate the quantity @xmath92 in equation  ( [ eq4pt1 ] ) , in practice this information is already encoded in @xmath82 as @xmath93 with all the parts of eqs .",
    "( [ eq19 ] ) and ( [ eq20 ] ) in hand , we can compute @xmath94 and @xmath95 .        in summary , the procedure is the following :    1 .",
    "start with a heterodyned , band - limited , downsampled @xmath96 with @xmath78 regularly spaced in time , in the frame of reference of the detector .",
    "2 .   correct the @xmath96 for the heterodyning done in the detector frame by multiplying with @xmath97 to produce the @xmath80 .",
    "the @xmath80 correspond to data irregularly spaced in the barycentric frame .",
    "calculate @xmath82 , which are times in the detector frame corresponding to regularly sampled solar system barycenter times .",
    "4 .   using interpolation ,",
    "calculate @xmath83 from @xmath80 , which is the @xmath79 used in eqs .",
    "( [ eq19 ] ) and ( [ eq20 ] ) .",
    "5 .   similarly , from @xmath85 and @xmath87 calculate @xmath84 and @xmath86 respectively .",
    "using ffts , evaluate eqs .",
    "( [ eq19 ] ) and ( [ eq20 ] ) to calculate @xmath94 and @xmath95",
    "( [ eq6 ] ) to calculate the @xmath28-statistic .      in the previous section",
    "we describe a practical way of calculating the @xmath28-statistic from time series data .",
    "however , in practice the calculation is done in the frequency domain for a couple of reasons .",
    "one is that much of the code written in the ligo scientific collaboration s ( lsc ) continuous waves working group is tailored to an analysis performed in the frequency domain and hence there exist many data processing and validation tools to process the data that are useful to this code .",
    "another reason is that gravitational wave detectors are subject to many sources of noise , some of which change daily or even hourly , such as wind , microseism , earthquakes , anthropogenic noise , etc .",
    "these change the noise floor of any analysis as a function of time .",
    "working in the frequency domain is a natural way to deal with this problem .",
    "we begin a frequency domain analysis by taking short time - baseline fourier transforms of the time domain data , called short fourier transforms ( sfts ) .",
    "when we calculate the @xmath28-statistic , we divide by the noise in the instrument at that frequency , as shown in eq .",
    "( [ eq6 ] ) .",
    "however , eq .  ( [ eq6 ] ) assumes the noise is stationary . to account for the non - stationarity of the noise we need to weight by the noise over time , which is done on a per sft basis .",
    "this normalization process is described in the next section .",
    "the computational cost of estimating the noise per sft scales with the number of sfts and thus for a fixed observation time scales inversely with the time - baseline .",
    "a compromise is needed between the demands of computational time and relative stationarity of the detector for a given time - baseline . in ligo , sfts are usually 1800 seconds long , since the detector is reasonably stationary for that time .      to deal with non - stationarities , variations in the noise floor from sft to sft , and colored data , we can normalize our sft data to absorb the @xmath98 term in the definition of the @xmath28-statistic in eq .",
    "( [ eq6 ] ) .",
    "if @xmath99 is the @xmath17 frequency bin of the @xmath100 sft , then we can redefine a normalized data point @xmath101 as @xmath102 where @xmath103 is an estimate of the one - sided power spectral density for the @xmath17 frequency bin of the @xmath100 sft .",
    "estimators used for this purpose should be robust in the presence of spectral features in the data , such as a running median .",
    "there are many practical difficulties that arise when dealing with sfts .",
    "often contiguous chunks of data have to be divided up into multiple sfts and it is necessary to coherently combine them into one long time - baseline sft .",
    "this is done using the dirichlet kernel , which is the equivalent of a sinc interpolation ( ideal interpolation ) done in the time domain .",
    "in order to keep the computational cost down , the dirichlet kernel is truncated at a finite number of points ( usually around 16 ) .",
    "this introduces a slight interpolation error , which can not be avoided without sacrificing a large amount of computational power .",
    "suppose we divide the data @xmath54 of length @xmath104 into @xmath105 short chunks of length @xmath106 each with @xmath72 points , so that @xmath107 .",
    "the discrete fourier transform ( dft ) of the data is @xmath108 where @xmath109 , @xmath110 is the sampling time , and @xmath111 is a long time - baseline frequency index .",
    "we can write the fourier transform in terms of two sums : @xmath112 where @xmath113 .",
    "we can express the @xmath114 in terms of an inverse dft of a short chunk of data , @xmath115 where the @xmath116 are the starting sft data , @xmath117 replacing @xmath114 with eq .",
    "( [ e3 ] ) in eq .",
    "( [ dft1 ] ) gives @xmath118 the last sum in this expression can be evaluated analytically . in particular , @xmath119 we take @xmath120 , @xmath121 , with @xmath122 , so that the sum is given by @xmath123 in the large @xmath72 limit the exponent of the denominator will be small so that @xmath124 this means we can write eq .",
    "( [ dft2 ] ) as @xmath125 with the dirichlet kernel @xmath126 and @xmath122 .",
    "the function @xmath127 is very strongly peaked around @xmath128 , which is near a value of the frequency index @xmath129 .",
    "this means one only needs to evaluate the sum over @xmath130 for a few terms @xmath131 around @xmath132 . with this in mind",
    "we write @xmath133 to produce a heterodyned time series a sub - band of the @xmath134 may be selected and inverse fourier transformed .      with the normalized sft data @xmath101 from eq .",
    "( [ dimlesssfts1 ] ) we can construct a normalized version of the long time - baseline fourier transform @xmath135 and take a sub - band of @xmath136 , inverse fourier transform it , and produce the heterodyned time series , and correct it to produce @xmath137 . in terms of this time series , we can write @xmath138 and @xmath139 and thus @xmath140      as shown before in eqs .",
    "( [ eq14 ] ) and ( [ eq15 ] ) , heterodyning is a procedure by which the frequency of interest can be shifted arbitrarily .",
    "when one applies the kind of correction in eq .",
    "( [ eq14 ] ) , we effectively move all the frequencies by a set amount . by doing so ,",
    "we convert the time series from a real time series to a complex time series , with the same amount of information content .",
    "heterodyning in the frequency domain can be done in two ways , one in which the time series produced after inverse fourier transforming is real and another in which it is complex .",
    "a cosine transform used to heterodyne would produce a real time series , but this method is not used in an implementation of the technique ( see section  [ sec : results ] ) .",
    "a complex heterodyned time series is produced by inverse fourier transforming a relabelled band of the frequencies . since in eq .",
    "( [ eq14 ] ) , all frequencies are shifted by a fixed amount , the equivalent procedure in the frequency domain is just relabelling the heterodyne frequency @xmath141 as dc and subsequently all the other frequencies relative to this new dc .    taking the example from section  [ timehetlowdown ] , we can just internally change the labels of the 995 hz frequency bin to dc and 1000 hz to 5 hz .",
    "once this relabelling is done , the original data will have all shifted by 995 hz , with the 10 hz from -5 hz to + 5 hz containing all the relevant information .",
    "if one were using the whole band without downsampling or filtering , then this relabelling would have to wrap around the nyquist frequency edge , but since the whole purpose of heterodyning is to downsample , it is never necessary to do so .",
    "following the time domain algorithm , after heterodyning the data , it needs to be downsampled and low - pass filtered .",
    "the downsampling and low - pass filtering is achieved by simply throwing out the data that is not in the band of interest .",
    "the heterodyning is done in such a way as to keep the center of the band of interest at dc .",
    "a tukey window applied to the band of interest , keeping a little bit of data on both edges to facilitate the rise of the window from 0 to 1 , is a good choice of a low - pass filter .",
    "once an inverse fourier transform is performed on this smaller subset in the frequency domain , it generates the same heterodyned , downsampled , and low - pass filtered time series as the time domain algorithm .",
    "data collected by an interferometer will have gaps due to periods of downtime .",
    "these gaps need to be dealt with in a manner that preserves the phase coherence of the segments around the gaps .",
    "the gaps increase the analysis time without contributing any power to the @xmath28-statistic , and thus act like a zero padding .",
    "the data is divided up into a series of contiguous chunks and gaps . for each contiguous chunk",
    "the sfts in that chunk are normalized , patched up and then a heterodyned , downsampled and low - pass - filtered time series is calculated from it .",
    "heterodyning done by relabelling is equivalent to multiplying with @xmath142 , where @xmath143 is the start time of the data chunk being heterodyned and @xmath59 is the heterodyne frequency . if we have multiple chunks that are separately being heterodyned , then @xmath143 is different for each chunk . in the time domain analysis",
    ", we assumed that the heterodyne reference time is the same as the start time of the analysis . in order to achieve the same kind of heterodyning",
    ", one needs to multiply each newly created time series with a correcting phase factor , namely @xmath144 where @xmath145 is the start time of the overall analysis .    a tukey window",
    "can then be applied to each of these time series to smoothly bring the data to zero at the edges , which correspond to the gaps .",
    "the gaps are then filled with zeros , as no data was collected during those times .",
    "this procedure is repeated for all the gaps and contiguous chunks . at the end",
    ", a time series is produced , which is contiguous and spans the time of the analysis . by ensuring that the timestamps of the first datum of each contiguous chunk correspond with the start time of that chunk , we ensure that the phase coherence is maintained throughtout .      to summarize , a simple algorithm to produce a time series equivalent to the one used for the time domain analysis is as follows :    1 .",
    "divide the data into time chunks and fourier transform them to create sfts .",
    "2 .   normalize these sfts and assign them weights .",
    "identify contiguous sets of sfts .",
    "4 .   combine each contiguous chunk of sfts into one long time - baseline fourier transform ( ft ) .",
    "create a downsampled , heterodyned , and low - pass - filtered time series by inverse fourier transforming the desired frequencies from the ft .",
    "stitch all these time domain chunks together , filling gaps with zeros .",
    "the scheme previously used to compute the @xmath28-statistic , involved the use of the dirichlet kernel to combine a series of sfts  @xcite  @xcite , which were calculated for 30 minutes of data taken at 16 khz .",
    "the 30 minute window was set by the maximum doppler shift due to the motion of the earth .",
    "a c code called computefstatistic@xmath146v2  @xcite was written in the ligo analysis library ( lal ) to calculate the @xmath28-statistic using this algorithm .",
    "the code which implements our method is also written in c and is called computefstatistic@xmath146resamp  @xcite .",
    "henceforth we will refer to the previous implementation as the lal implementation and our implementation as resampling .",
    "the @xmath28-statistic is calculated for a series of templates looping over various parameters such as sky location , @xmath19 and @xmath20 , spin - downs @xmath147 , and various frequencies @xmath31 .",
    "we can ignore the way the two implementations deal with loops over @xmath19 , @xmath20 , and @xmath147 , since they both loop over them in the same manner .",
    "the speed of computation for a loop over frequencies @xmath31 is worth comparing , however .",
    "assume that we have n data points ( take for example @xmath148 seconds of data at 100 hz , i.e. @xmath149 data points ) .",
    "now assume that the number of operations per sky location and per spin - down is @xmath150 .",
    "if the number of dirichlet kernel points used is @xmath151 , then the total number of operations used by the lal implementation is :    @xmath152    where @xmath150 is defined as the number of operations conducted in the innermost loop and is approximately of order 10 , @xmath153 is the number of times the dirichlet kernel loop is repeated , @xmath154 is the number of sfts , and @xmath72 is the number of data points .",
    "compare this to the resampling method , which consists of 4 major steps :    1 .",
    "calculating @xmath155 , given a sky location and time . 2 .",
    "calculating the integrands of @xmath39 and @xmath40 .",
    "3 .   interpolating and calculating the beam patterns .",
    "4 .   taking the fourier transform .",
    "each of these steps involves order 10 operations , but all of these steps are sequential , therefore they only add , resulting in a total number of operations per data point,@xmath156 , of approximately 30 operations .",
    "the last step is the fourier transform , which is of order @xmath157 , therefore the total number of steps is : @xmath158 therefore the ratio of operations between the two methods is @xmath159 to first order , we have @xmath160    therefore for large observation times ,",
    "this method of calculating the @xmath28-statistic is faster and , in the case of a targeted search , it allows for a large parameter space in @xmath161 s .",
    "the speed - up in practice is reduced by a few practical issues as seen in section  [ sec : practical ] . however",
    ", resampling is still considerably more efficient than the lal implementation . for einstein@home , because of the relatively small coherent integration time , the speed - up is around @xmath162 .",
    "but for targeted searches that span multiple months or years , the improvement can be as high as a factor of @xmath163 .",
    "thus , while some targeted searches which integrate over a couple of years were impossible to do previously , they are now possible .      the probability density distribution of the @xmath28-statistic for gaussian noise of zero mean and unity standard deviation is a @xmath164 distribution with four degrees of freedom . in the presence of a signal ,",
    "the distribution is a @xmath164 of four degrees of freedom with a non - centrality parameter given by the @xmath28-statistic in the absence of noise for the particular signal .",
    "resampling uses various approximate methods in the calculation of the @xmath28-statistic , and this can lead to disagreements between the theoretical @xmath28-statistic probability density function and the output of the code .",
    "these changes are of the order of a few percent and are within acceptable limits .",
    "the validity of the code can be tested by using a monte carlo simulation of about a million different injections of the same signal in different instances of noise .",
    "the noise is generated as a gaussian noise of zero mean and unity standard deviation , and the signal is added into this noise . for each individual injection",
    "the signal is chosen with a given set of amplitude parameters and a fixed sky location and spindowns , and the search is conducted over these exact chosen parameters in order to avoid any mismatches .",
    "these monte carlos are then repeated with another set of parameters , which are themselves chosen randomly . while it is not an exhaustive test ,",
    "randomly chosen parameters ensure that we are not biased in the validation test .",
    "the plot in figure [ fig2 ] is produced by performing one such monte carlo simulation . in this case , both the lal implementation and resampling were run on the same set of data .",
    "the @xmath28-statistic was picked out at the appropriate frequency and this was repeated about a million times .",
    "a histogram of these @xmath28-statistic values was then plotted .",
    "as one can see , there is very good agreement in between the expected distribution of the @xmath28-statistic and the two implementations .",
    "in the implementation of the algorithm explained above , one major obstacle is the fact that the data collected by any physical instrument is discrete and thus must be handled appropriately .",
    "take , for example , the heterodyne frequency used in the calculation .",
    "this frequency can not be chosen arbitrarily , as only certain frequencies are sampled and thus there are only certain permitted choices .",
    "most major fft computation algorithms output the frequency series in a specific format , which split the data into two parts .",
    "the first bin output by these algorithms is the dc followed by the first positive frequency bin up to positive nyquist and then follows this up with the negative frequencies starting at the negative nyquist frequency .",
    "this order of placing frequency bins speeds up computation and is necessary for the internal workings of these algorithms .",
    "thus when an inverse fft is performed on the frequency domain data in the form of sfts , a simple reshuffling needs to be done . the frequency selected to be",
    "the first bin will become the new dc and thus the data will have been heterodyned by that said frequency . in order to ensure that the same frequency bin is chosen as dc",
    ", one needs an odd number of bins per sft . if the number of bins are even , then upon increasing the amount of data it can shift this number to an odd number as the increase is always done by changing the number of sfts .",
    "but if the number of bins per sft is odd , then it will remain odd for any number of sfts .",
    "this ensures that there is no mismatch in choosing the appropriate bin as the heterodyne frequency .",
    "when the resampling algorithm is used on discrete data , one needs to interpolate between data points to go from the detector frame to the ssb frame",
    ". this interpolation acts like a nonlinear low - pass filter and destroys the power at higher frequencies in the band of analysis .",
    "since the filter is nonlinear , the frequency response is not well - defined , and thus there is no way to compensate for the power loss at high frequencies",
    ". the power loss can be significant ( of order @xmath165 ) and is unacceptable in most analyses .",
    "the exact nature of the filter depends on the type of the interpolation routine used and the sky location that one resamples to .",
    "the only work around is to perform the computation over a larger band than the one desired . in practice",
    "it is sufficient to double the band and to discard the higher frequencies .",
    "in this paper , we describe an efficient implementation of the barycentric resampling technique , which deals with the non - stationarity of the detector and calculates the @xmath28-statistic .",
    "although the calculation of the @xmath28-statistic has been targeted , this technique can be used for many other kinds of searches .",
    "the major contribution of this technique is to remove the doppler shift of the earth s motion in a gravitational wave signal .",
    "thus , once this doppler shift is removed , both frequentist and bayesian techniques can be applied to the data . in the process of implementing this algorithm ,",
    "a series of practical issues are dealt with , including constraints of modern computer memory , discreteness of the data taken , losses due to interpolation , and gaps in real data .",
    "the computational savings due to this technique can be used in various ways .",
    "one such use is to increase the coherent integration time for all - sky searches like the einstein@home searches .",
    "currently einstein@home  @xcite uses @xmath166 hour long coherent integration time .",
    "the resampling code will be about @xmath162 times faster for such integration times , and for the same computational power and keeping the same scaling for the search , we can coherently integrate @xmath167 hours instead , which corresponds to a sensitivity increase of about @xmath168 .",
    "the resampling technique is most effective for long integration times , which are feasible for targeted searches like the search for gravitational waves from the crab pulsar  @xcite .",
    "the computational savings can be used to search over wider parameter spaces like more spindown parameters or to search over binary systems .",
    "we would like to thank the membership of the ligo virgo collaboration s continuous waves group , especially stefano braccini , vladimir dergachev , greg mendell , chris messenger , marialessandra papa and reinhard prix for helpful discussions .",
    "we are also grateful to patrick brady and alan weinstein for useful conversations .",
    "ligo was constructed by the california institute of technology and massachusetts institute of technology with funding from the national science foundation and operates under cooperative agreement phy-0757058 .",
    "this paper has ligo document number ligo - p0900301-v1 .",
    "xavier siemens is supported in part by nsf grant no .",
    "phy-0758155 and the research growth initiative at the university of wisconsin - milwaukee ."
  ],
  "abstract_text": [
    "<S> we describe an efficient implementation of a coherent statistic for continuous gravitational wave searches from neutron stars . </S>",
    "<S> the algorithm works by transforming the data taken by a gravitational wave detector from a moving earth bound frame to one that sits at the solar system barycenter . </S>",
    "<S> many practical difficulties arise in the implementation of this algorithm , some of which have not been discussed previously . </S>",
    "<S> these difficulties include constraints of small computer memory , discreteness of the data , losses due to interpolation and gaps in real data . </S>",
    "<S> this implementation is considerably more efficient than previous implementations of these kinds of searches on laser interferometer gravitational wave ( ligo ) detector data . </S>"
  ]
}