{
  "article_text": [
    "in this paper , we study the numerical solution of the it sde @xmath0 by means of an adaptive time - stepping algorithm . here",
    "@xmath1 for each @xmath2 and @xmath3 is a @xmath4dimensional brownian motion .",
    "thus @xmath5 and @xmath6 for simplicity we assume that the initial condition is deterministic . throughout @xmath7 is used to denote either the euclidean vector norm or the frobenius ( trace ) matrix norm as appropriate .",
    "we assume throughout that @xmath8 are @xmath9 .",
    "further structural assumptions will be made where needed .",
    "the basic adaptive mechanism we study is detailed at the start of the next section .",
    "it is a simple adaptive algorithm , prototypical of a whole class of methods for the adaptive integration of sdes .",
    "our aim is twofold .",
    "first we show convergence , as the user - input tolerance @xmath10 tends to zero ; this is a non - trivial exercise because the adaptive strategy does not imply that the time - steps taken tend to zero with the tolerance everywhere in phase space .",
    "secondly we show that the methods have a variety of desirable properties for the long - time integration of ergodic sdes , including preservation of ergodicity and exponential moment bounds .",
    "the adaptive method controls the time - step of a forward euler drift step so that it deviates only slightly from a backward euler step .",
    "this not only controls an estimate of the contribution to the time - stepping error from the drift step , but also allows the analysis of stability ( large time ) properties for implicit backward euler methods to be employed in the explicit adaptive method .",
    "numerical experiments suggest that both the convergence and stability analyses extend to a number of more sophisticated methods which control different error measures ; some of these experiments are reported below .",
    "it is of interest to discuss our work in the context of a sequence of interesting papers which study the optimality of adaptive schemes for sdes , using various different error measures @xcite . for many of these error measures , which are quite natural in practice ,",
    "the asymptotically optimal adaptive schemes are based solely on the diffusion .",
    "this is essentially because it is the diffusion term which dominates the ( lack of ) regularity in paths and this regularity in turn dominates error measures .",
    "why then , have we concentrated on methods which adapt only on the drift ?",
    "the reason for this is that , as mentioned above , such methods are advantageous for long - time integration . in practice",
    ", we anticipate that error controls based on both drift and diffusion could combine the advantages of the asymptotically optimal schemes with the enhanced stability / ergodicity of schemes which control based on the drift .    in order to prove a strong mean - square convergence result for this algorithm",
    ", it is first necessary to obtain a suitable upper bound on the sequence of timesteps used .",
    "these bounds mimic those used in the convergence proofs for adaptive ode solvers @xcite and require that the numerical solution does not enter neighbourhoods of points where the local error estimate vanishes .",
    "( requiring that these neighbourhoods are small excludes some simple drift vector fields , such as constants . in practice , we would anticipate controlling on both the drift and the diffusion , minimizing this issue ) .",
    "an essential part of the analysis is a proof that the contribution to the mean - square error from paths that violate this condition is suitably small .",
    "adaptivity is widely used in the solution of ordinary differential equations ( odes ) in an attempt to optimize effort expended per unit of accuracy .",
    "the adaptation strategy can be viewed heuristically as a fixed time - step algorithm applied to a time re - scaled differential equation @xcite and it is of interest to study convergence of the algorithms as the tolerance employed to control adaptation is reduced to zero @xcite .",
    "however adaptation also confers stability on algorithms constructed from explicit time - integrators , resulting in better qualitative behavior than for fixed time - step counter - parts .",
    "this viewpoint was articulated explicitly in @xcite and subsequently pursued in @xcite , and @xcite for example .",
    "in particular the reference @xcite studies the effect of time - discretization on dissipative structures such as those highlighted in @xcite . it is shown that certain adaptive strategies have the desirable property of constraining time - steps of explicit integrators so that the resulting solution update differs in a controlled way from an implicit method .",
    "since many implicit methods have desirable stability properties ( see @xcite and @xcite , chapter 5 ) this viewpoint can be used to facilitate analysis of the stability of adaptive algorithms @xcite .    in @xcite ,",
    "stochastic differential equations ( sdes ) with additive noise and vector fields satisfying the dissipativity structures of @xcite are studied . there , and in @xcite , it is shown that explicit time - integrators such as euler - maruyama may fail to be ergodic even when the underlying sde is geometrically ergodic .",
    "the reason is that the ( mean ) dissipativity induced by the drift is lost under time - discretization .",
    "since this is exactly the issue arising for explicit integration of dissipative odes , and since this issue can be resolved in that context by means of adaptation , it is natural to study how such adaptive methods impact the ergodicity of explicit methods for sdes . in recent years",
    ", the numerical solution of sdes with gradient drift vector fields has been used as the proposal for an mcmc method for sampling from a prescribed density , known only up to a multiplicative constant  a technique referred to as metropolis - adjusted langevin algorithm @xcite . in this context , it is very desirable that the time discretization inherit ergodicity . the adaptive scheme proposed here is an approach to ensuring this . in this sense",
    "our work complements a number of recent papers concerned with constructing approximation schemes which are ergodic in situations where the standard fixed step euler - maruyama scheme fails to be : in @xcite a metropolis - hastings rejection criterion is used to enforce ergodicity ; in local linearization is used ; in @xcite implicit methods are used .",
    "although the adaptive method that we analyze here is proved to be convergent on finite time intervals , it would also be of interest to extend the work of talay @xcite , concerned with convergence proofs for invariant measure under time - discretization , to the adaptive time - step setting considered here .    in section [ sec : algorithm ] , we introduce the adaptive algorithm , together with some notation . in section  [ sec : res ] the finite time convergence result for the adaptive method is stated . the proof is given in section  [ sec : alg ] and proceeds by extending the fixed step proof given in @xcite ; the extension is non - trivial because the adaptivity does not force time - steps to zero with the tolerance in all parts of the phase space . in section [ sec : mainresults ] , we state the main results of the paper on the stability of the adaptive method . all results",
    "are proved under the dissipativity condition @xmath11 where @xmath12 is the inner - product inducing the euclidean norm , as well as a boundedness and invertibility condition on the diffusion matrix @xmath13 .",
    "the results proven include ergodicity and an exponential moment bound ; all mimic known results about the sde itself under .",
    "section [ sec : apriori ] starts with a number of _ a priori _ estimates for the adaptive scheme of section [ sec : algorithm ] , and proceeds to proofs of the stability stated in section [ sec : mainresults ] .",
    "numerical results studying both convergence and ergodicity are presented in sections [ sec : numerics][sec:9 ] . some concluding remarks and generalizations",
    "are given in section [ sec : conc ] .",
    "the adaptive algorithm for is as follows : @xmath14 where @xmath15 . here",
    "@xmath16 and @xmath17 the random variables @xmath18 form an i.i.d . sequence distributed as @xmath19 the parameter @xmath20 defines the initial time - step and @xmath21 the tolerance .",
    "note that the algorithm defines a markov chain for @xmath22 on @xmath23    we may write @xmath24 if @xmath25 then @xmath26 and the error control enforces the condition @xmath27 where @xmath28 is the fixed maximum time - step .",
    "furthermore we have @xmath29 in the absence of noise , this implies that the difference between an euler approximation at the next time - step , and an explicit second order approximation , is of size @xmath30 in the presence of noise , it imposes a similar restriction on the means .",
    "as mentioned in the introduction , in practice we would anticipate combining this drift error control with others tuned to the diffusion .",
    "the most important notation conceptually is concerned with making relationships between the numerical approximations at discrete steps , and the true solution at certain points in time . to do this",
    "we define @xmath31 to be the sigma - algebra generated by @xmath32 steps of the markov chain for @xmath33 let @xmath34 @xmath35 and define the stopping times @xmath36 by @xmath37 and , for @xmath38 , @xmath39 where the dependence on @xmath40 is important we will write @xmath41 it is natural to examine the approximate process at these stopping times since they are spaced approximately at fixed times in the time variable @xmath42 theorem [ t : stf ] in section [ sec : mainresults ] shows that these stopping times are almost surely finite , under the dissipativity condition .",
    "notice that @xmath43 when considering strong convergence results it is necessary to interpret @xmath44 in the adaptive algorithm as the brownian increment @xmath45    we let @xmath46 the markov chain for @xmath47 will be important in our study of long time behaviour and we will prove that it is ergodic .",
    "let @xmath48 , the filtration of events up to the @xmath49 stopping time .",
    "it is convenient to define two continuous time interpolants of the numerical solution .",
    "we set @xmath50 hence , for @xmath51 @xmath52\\\\ & = ( 1-\\alpha_n ( t))x_n+\\alpha_n ( t ) { x^{\\star}}_n+{g}(x_n)[w(t)-w(t_n ) ] \\label{eq : bx2}\\end{aligned}\\ ] ] for @xmath53    it is sometimes important to know the smallest step - size beneath which the error control is always satisfied , at a given point @xmath54 .",
    "hence we define @xmath55 noting that , by continuity of @xmath56 , @xmath57 is finite if @xmath58 is bounded .    because of the boundedness of @xmath59 we deduce that there are functions @xmath60 and constants @xmath61 such that , for @xmath62 distributed as @xmath63 and independent of @xmath54 , @xmath64 the following definitions will be useful : @xmath65 we will always assume that @xmath10 is chosen small enough so that @xmath66 .",
    "the constants @xmath67 is chosen so that @xmath68.\\ ] ]",
    "we start by discussing the error control mechanism . we define @xmath69 by @xmath70 the function @xmath71 by @xmath72 and @xmath73 by @xmath74 now , since @xmath75",
    ", taylor series expansion gives @xmath76 \\label{eq : form}\\ ] ] where @xmath77 are defined above .",
    "note that the error control forces a time - step so that the norm of @xmath78 is of order @xmath79 estimating the implications of this for the time - step @xmath80 forms the heart of the convergence proof below .    in order to state the assumptions required for the convergence result we define , for @xmath81 the sets @xmath82 and introduce the constant @xmath83}|f_2(u , h)|.$ ]",
    "now define the following : @xmath84    the first assumption is a local lipschitz condition on the drift and diffusion co - efficients , together with moment bounds on the true and numerical solutions .    for each @xmath85 there",
    "exists a constant @xmath86 depending only on @xmath87 , such that @xmath88 for some @xmath89 there is a constant @xmath90 , uniform in @xmath91 , such that @xmath92 \\vee { \\mathbb{e}}\\left [ \\sup_{0 \\le t \\le t } |x(t)|^p \\right ]   \\le a. \\label{mbd}\\ ] ] [ ass1 ]    note that inequality ( [ locall ] ) is a local lipschitz assumption which will be satisfied for any @xmath56 and @xmath13 in @xmath93 .",
    "the inequality ( [ mbd ] ) states that the @xmath94 moments of the exact and numerical solution are bounded for some @xmath95 .",
    "theorem [ t : moment ] proves for the numerical interpolant , under natural assumption on @xmath56 and @xmath13 ( see assumption [ ass : coerce ] ) . under the same assumptions ,",
    "such a bound is known to hold for @xmath96 see @xcite .",
    "we clearly also need an assumption on the local error estimate since if , for example , the drift term @xmath97 were constant then @xmath98 and the stepsize would , through doubling , reach @xmath99 , no matter how small @xmath10 is , and convergence can not occur as @xmath100 because the function @xmath69 maps @xmath101 into itself , the following assumption on the zeros of @xmath69 will hold for generic drift functions @xmath56 which are non - constant on any open sets ; it does exclude , however , the case of constant drift .",
    "furthermore the assumption on the hitting time rules out dimension @xmath102    [ ass3 ] define @xmath103 for any given @xmath85 we assume that @xmath104 for all sufficiently small @xmath105 , and that @xmath106 as @xmath107 furthermore , the hitting time @xmath108 satisfies , for any @xmath109 , @xmath110    here @xmath111 denotes hausdorff distance .",
    "the preceding assumption requires that the contours defining the boundary of @xmath112 are strictly nested as @xmath113 increases , and bounded .",
    "this enables us to show that the probability of @xmath114 is small , a key ingredient in the proof .",
    "we now state the strong convergence of the adaptive numerical method , using the continuous - time interpolant @xmath115 note that we do not assume @xmath116 for this theorem .",
    "hence the non - standard part of the proof comes from estimating the contribution to the error from regions of phase space where the time - step is not necessarily small as @xmath100    assume that @xmath117 let assumptions  [ ass1 ] and [ ass3 ] hold .",
    "then , there is @xmath118 such that , for all @xmath119 and any @xmath120 the numerical solution with continuous - time extension @xmath121 satisfies @xmath122   \\to 0 \\quad{\\hbox { as}}\\quad \\tau \\to 0.\\ ] ] [ res1 ]",
    "the primary technical difficulty to address in convergence proofs for adaptive methods is to relate the time - step to the tolerance @xmath10 . roughly speaking the formula shows that , provided @xmath123 , the error control will imply @xmath124 we now make this precise .",
    "we provide an upper bound on the timestep sequence of numerical solutions that remain within @xmath125 , for sufficiently small @xmath10 . for given @xmath126",
    "we define the quantities @xmath127    [ lem : ub ] for any @xmath128 , if @xmath129 , @xmath130 and @xmath131 then @xmath132    the error control implies @xmath133 note that @xmath134 we first proceed by contradiction to prove @xmath135 .",
    "let @xmath136 be the first integer such that @xmath137 . then , since there is a maximum timestep ratio of 2 , we have @xmath138 &   \\rightarrow & \\delta_m | f_2(x_m,\\delta_m)| < \\frac{\\epsilon}{2}\\\\ & \\rightarrow & |{e}(x_m , \\delta_m)| > \\delta_m ( \\epsilon -   \\epsilon/2 ) \\geq \\frac{\\epsilon \\overline{h}_{r,\\epsilon}}{2 } =   \\frac{\\epsilon^2}{12k_r}=\\tau_{r,\\epsilon } > \\tau .",
    "\\end{aligned}\\ ] ] thus @xmath139 is not an acceptable timestep , contradicting our original assumption .",
    "the first result follows .",
    "the proof of the bound on the timestep in ( [ le1 ] ) now follows immediately since @xmath140    proof of theorem 1 we denote the error by @xmath141 recall the young inequality : for @xmath142 @xmath143 we thus have for any @xmath144 @xmath145 & = & { \\mathbb{e}}\\left [ \\sup_{0 \\le t \\le t } |e(t)|^2                \\mathbf{1}\\{\\theta_{r,\\epsilon } > t\\ }              \\right ] + { \\mathbb{e}}\\left [ \\sup_{0 \\le t \\le t } |e(t)|^2                \\mathbf{1}\\{\\theta_{r,\\epsilon } \\le t\\ } \\right ]                \\nonumber \\\\            & \\le & { \\mathbb{e}}\\left [ \\sup_{0 \\le t \\le t } |e(t \\wedge \\theta_{r,\\epsilon})|^2 \\mathbf{1}\\ { \\theta_{r,\\epsilon } > t\\ } \\right ]         +       \\frac{2 \\delta}{p }       { \\mathbb{e}}\\left [ \\sup_{0 \\le t \\le t } |e(t)|^p \\right ] \\nonumber \\\\     & & \\mbox { } + \\frac{1-{{\\textstyle \\frac{2}{p } } } } { \\delta^{2/(p-2 ) } }               { \\mathbb{p}}\\big ( \\theta_{r,\\epsilon } \\le t \\big ) . \\end{aligned}\\ ] ] now @xmath146 but @xmath147 whilst @xmath148",
    "thus we have @xmath149 to control the last term notice that whenever @xmath150 , @xmath151 and @xmath152 we know that @xmath153 .",
    "hence we have @xmath154 combining the two preceding inequalities gives @xmath155 by markov s inequality @xmath156 so that @xmath157 furthermore , @xmath158       \\le { 2}^{p-1 }     { \\mathbb{e}}\\left [ \\sup_{0 \\le t \\le t } \\left(|{{\\overline{x}}}(t)|^p + |x(t)|^p \\right ) \\right ]      \\le 2^p a.\\ ] ]    using , in ( [ eq : ft0 ] ) gives , for @xmath113 sufficiently small , @xmath159 & \\le & \\left(1+\\frac{p-2}{p\\delta^{2/(p-2)}\\ell(\\epsilon , r)^2}\\right ) { \\mathbb{e}}\\left [ \\sup_{0 \\le t \\le t } |e(t \\wedge \\theta_{r,\\epsilon})|^2 \\right ]     \\nonumber \\\\         & & \\mbox { }       + \\frac{2^{p+1 } \\delta a}{p }   +             \\frac{(p-2)}{p\\delta^{2/(p-2)}}\\left[\\frac{2a}{r^p}+ { \\mathbb{p}}\\{\\rho_\\epsilon \\le t\\}\\right ] .",
    "\\label{eq : bdd}\\end{aligned}\\ ] ]    take any @xmath160 . to complete the proof we choose @xmath40 sufficiently small so that the second term on the right hand side of ( [ eq : bdd ] ) is bounded by @xmath161 and then @xmath87 and @xmath113",
    "sufficiently large / small so that the third and fourth terms are bounded by @xmath162 now reduce @xmath10 so that lemma [ lem : ub ] applies .",
    "then , by further reduction of @xmath10 in lemma [ lem : basic ] , we upper - bound the first term by @xmath162 ( lemma [ lem : basic ] calculates the error conditioned on the true and numerical solutions staying within a ball of radius @xmath87 , and away from small sets where the error control mechanism breaks down . with this conditioning it follows from lemma [ lem : ub ] that we have @xmath163 , which is the essence of why lemma [ lem : basic ] holds . )",
    "consequently we have @xmath164 \\le \\kappa\\ ] ] and since @xmath165 is arbitrary the required result follows .",
    "@xmath166    in the following , @xmath167 is a universal constant independent of @xmath168 , @xmath169 and @xmath10 .",
    "likewise @xmath170 is a universal constant depending upon @xmath87 , but independent of @xmath171 and @xmath172 @xmath173 is a universal constant depending upon @xmath87 and @xmath174 , but independent of @xmath169 and @xmath10 and @xmath175 and so forth are defined similarly .",
    "the actual values of these constants may change from one occurrence to the next .",
    "[ lem : basic ] assume that @xmath109 and that @xmath10 is sufficiently small for the conditions of lemma [ lem : ub ] to hold",
    ". then the continuous interpolant of the numerical method , @xmath121 , satisfies the following error bound : @xmath176 \\le   c_{r,\\epsilon , t}\\tau.\\ ] ]    using @xmath177 equation ( [ eq : bx1 ] ) and cauchy  schwartz , we have that @xmath178 , satisfies @xmath179.\\end{aligned}\\ ] ] let @xmath180\\ ] ] then , from the local lipschitz condition ( [ locall ] ) and the doob - kolmogorov martingale inequality @xcite , we have for any @xmath181 @xmath182 ds \\nonumber \\\\ & \\le & 4 c_r(t + 4 ) \\left [ { \\mathbb{e}}\\int_{0}^{t^ * \\wedge \\theta_{r,\\epsilon } }   |x(s ) - { { \\overline{x}}}(s)|^2   ds + \\int_0^{t^ * } { \\mathbb{e}}e(s)ds \\right ] .         \\label{bdi}\\end{aligned}\\ ] ] given @xmath183 , let @xmath184 be the integer for which @xmath185 .",
    "notice that @xmath186 is a stopping time because @xmath187 is a deterministic function of @xmath188 .",
    "we now bound the right hand side in . from the local lipschitz condition ( [ locall ] )",
    ", a straightforward calculation shows that @xmath189 now , for @xmath190 , using lemma [ lem : ub ] , @xmath191dw(l)\\\\ & \\le ( s - t_{k_s})[1+i(s ) ] \\le \\frac{2\\tau}{\\epsilon}[1+i(s)].\\end{aligned}\\ ] ] here @xmath192dw(l)\\big|.\\ ] ] let @xmath193 denote the @xmath194algebra of brownian paths up to time @xmath186 .",
    "then , conditioned on @xmath193 , we have @xmath195 thus , using lemma [ lem : ub ] , ( [ mbd ] ) and the lyapunov inequality @xcite , @xmath196 to obtain the last line we condition on @xmath193 so that @xmath197 and @xmath198 are independent ; we then use and the assumed moment bound .    in ( [ bdi ] )",
    ", we then have by lemma [ lem : ub ] @xmath199 applying the gronwall inequality we obtain @xmath200 \\le   c(r,\\epsilon , t)\\tau.\\ ] ]",
    "for all of our stability results , in this and the following sections , we make the assumption that holds , together with some conditions on the diffusion matrix .",
    "to be explicit we make    [ ass : coerce ] there exists finite positive @xmath201 such that @xmath202 where @xmath12 is the inner - product inducing the euclidean norm @xmath7 .",
    "furthermore @xmath203 , @xmath59 is globally bounded and is globally invertible .",
    "the assumption is made , without explicit statement , for the remainder of the paper .",
    "we also assume , without explicit statement , that @xmath204 so that @xmath205 finally we assume , also without explicit statement , that there is at least one point @xmath206 such that @xmath207 this may implicitly force upper bounds on @xmath10 and @xmath28 , although neither is necessarily restricted by this assumption .",
    "the existence of such a @xmath208 is implied by assumption [ ass : coerce ] , which rules out @xmath56 being identically constant .",
    "then there exists @xmath208 for which the function @xmath209 is non - zero in a neighbourhood of @xmath210 and must hold , possibly after enforcing bounds on @xmath10 and @xmath211    under assumption [ ass : coerce ] the solution of exists for all @xmath212 @xcite and the equation is geometrically ergodic @xcite .",
    "the first stability result ensures that the method will not decrease its stepsize in such a way that it is unable to reach arbitrary finite times .",
    "[ t : stf ] the stopping times @xmath36 are almost surely finite .",
    "the next result is the main ergodic result of the paper .",
    "it ensures that the adaptive method has an attracting statistical steady state . letting @xmath213 denote the expectation under the markov chain started at @xmath214",
    ", we have the following result .",
    "( recall @xmath40 occurring in the definition of stopping times @xmath215 )    [ t : erg ] assume that @xmath216 the markov chain @xmath217 has a unique invariant measure @xmath218 .",
    "furthermore , if @xmath219 is measurable and @xmath220 then there exists @xmath221 , @xmath222 such that @xmath223.\\ ] ]    the final result gives a moment bound on the continuous time interpolants of the numerical solution , mimicking that for the sde itself .",
    "[ t : moment ] there exists a @xmath224 and a @xmath225 so that @xmath226 } \\|x(t)\\|^{2 } ) & \\le \\exp ( \\lambda    { { \\mathbb e}}\\exp ( \\lambda \\sup_{t \\in [ 0,t ] } \\|{\\overline{x}}(t)\\|^{2 } ) & \\le \\exp ( \\lambda",
    "we start with a number of estimates which will be needed to prove the main results .",
    "it is useful to define @xmath227,\\\\ m_n=\\sum_{j=0}^{n-1}\\xi_{j+1},&\\quad { \\tilde{m}}_n=\\sum_{j=0}^{n-1}{\\tilde{\\xi}}_{j+1}.\\end{aligned}\\ ] ] observe that @xmath228 is a gaussian random variable conditioned on the values of @xmath229 and @xmath230 . hence the last two expressions are martingales satisfying the assumptions of lemma [ l : expmartnew ] from the appendix .",
    "also notice that the quadratic variations satisfy @xmath231    we start with a straightforward lemma .    the sequences @xmath232 and @xmath233 satisfy [ l:4.1 ] @xmath234,\\\\      |x_{n+1}|^2 & \\le \\beta_n|x_n|^2+{\\delta}_{n}[2{{\\tilde { \\alpha}}}+\\sigma^2 ] + \\xi_{n+1}+{\\tilde{\\xi}}_{n+1}.    \\end{aligned}\\ ] ] hence @xmath235     proof : taking the inner product of the equation @xmath236 with @xmath230 and using the fact that the error control implies @xmath237 a straightforward calculation from @xcite , using , gives the first result . to get the second simply square the expression for @xmath238 and use the first , noting that @xmath239 for the third use the first in the bound for @xmath240 .",
    "@xmath166    [ l : growslow ] we have @xmath241 where @xmath242 $ ] .",
    "furthermore @xmath243 where @xmath58 is a positive constant depending only on @xmath244 and @xmath245 .",
    "proof : squaring the expression for @xmath238 in , bounding @xmath246 by the first inequality in lemma [ l:4.1 ] and summing gives @xmath247 where @xmath248 and @xmath249 , @xmath250 are as before . using , one obtains @xmath251 and @xmath252    combining all of this produces , @xmath253 the probabilistic estimate follows from the exponential martingale estimates from the appendix .",
    "[ c : growslow ] then there exists a universal @xmath224 and @xmath254 so that for any stopping time @xmath255 with @xmath256 almost surely , for some fixed number @xmath257 , one has @xmath258",
    "the result follows from lemma [ l : growslow ] and the observation that @xmath259    the markov chain @xmath260 satisfies the foster - lyapunov drift condition @xmath261{{\\delta^{+}}}.\\ ] ] that is @xmath262{{\\delta^{+}}}.\\ ] ] [ l:4.2 ]     proof : note that @xmath263 for all @xmath264 $ ] . from lemma [ l:4.1 ] , we have @xmath265 where @xmath266 $ ] . defining @xmath267",
    "we obtain @xmath268 now @xmath269 straightforward calculations show that @xmath270 and @xmath271 hence @xmath272 and for the required result we need to bound the last term . by",
    "we have @xmath273 and we obtain @xmath274\\delta^{+}.\\ ] ] this gives the desired bound .",
    "we now proceed to prove the ergodicity and moment bound .",
    "we prove geometric ergodicity of the markov chain @xmath275 by using the approach highlighted in @xcite .",
    "in particular we use a slight modification of theorem 2.5 in @xcite .",
    "inspection of the proof in the appendix of that paper shows that , provided an invariant probability measure exists , and this follows from lemma [ l:4.2 ] , the set @xmath167 in the minorization condition need not be compact : it simply needs to be a set to which return times have exponentially decaying tails .",
    "let @xmath276 where @xmath277 we write @xmath278 with @xmath279 and @xmath280    the minorization condition that we use , generalizing that in lemma 2.5 of @xcite , is now proved : is compact in the following , @xmath281 is not . ]",
    "[ l : minor ] let @xmath167 be compact . for @xmath282 there is @xmath283 , @xmath206 and @xmath284 such that @xmath285 where @xmath286     proof : let @xmath287 and @xmath288 recall the definition of @xmath289 since @xmath290 almost surely , setting @xmath291 corollary [ c : growslow ] implies we can choose positive @xmath58 and @xmath87 sufficiently large so that @xmath292 and @xmath293 , and @xmath294 .",
    "label this event , with probability in excess of @xmath295 , by @xmath296 if @xmath297 occurs then there exists @xmath298 such that @xmath299 .",
    "this follows by contradiction , since otherwise @xmath300 for @xmath301 and @xmath302 however @xmath303 , a contradiction .",
    "once @xmath304 it follows that @xmath305 for @xmath306 as a consequence of the step - size selection mechanism .",
    "assume that @xmath297 has occurred .",
    "by choice of @xmath113 sufficiently small , @xmath307 .",
    "we now choose the @xmath308 for @xmath309 to ensure the event @xmath310 namely that @xmath311 it is possible to ensure that the event has probability @xmath312 , uniformly for @xmath313 and @xmath314 the fact that @xmath315 gives uniformity in @xmath316 we prove an upper bound on the number of steps after @xmath317 to get probability independent of @xmath318 to do this notice that @xmath305 now for @xmath319 , again as a consequence of the step - size mechanism .",
    "in fact @xmath320 this follows because an argument analogous to that above proves that there is @xmath321 for which @xmath322 for @xmath323 now @xmath324 , by continuity of @xmath56 and possibly by further reduction of @xmath325 since @xmath326 is not possible , it follows that @xmath327    if @xmath297 and @xmath310 both occur then , for some @xmath328 , the probability that @xmath329 is bounded below by @xmath330 , for some @xmath328 , because @xmath331 @xmath332 is in a compact set and @xmath59 is invertible .",
    "the fact that @xmath308 are i.i.d gaussian gives the required lower bound in terms of lebesgue measure .",
    "the final result follows with @xmath333 @xmath166    with this minorization condition in hand , we turn to the proof of ergodicity .     proof of theorem [ t : erg ] : the existence of an invariant measure @xmath218 follows from the foster - lyapunov drift condition of lemma [ l:4.2 ] which gives tightness of the krylov  bogoljubov measures .",
    "lemma [ l:4.2 ] shows that the chain @xmath275 repeatedly returns to the set @xmath281 and that the return times have exponentially decaying tails .",
    "this generalizes assumption 2.2 in @xcite .",
    "lemma [ l : minor ] gives a minorization condition enabling a coupling .",
    "together these two results give theorem [ t : erg ] , by applying a straightforward modification of the arguments in appendix a of @xcite .",
    "@xmath166     proof theorem [ t : moment ] : we define the stopping time @xmath255 by @xmath334 noting that @xmath335 notice that implies that @xmath336 , s \\in [ 0,t ] }    [ l:4.1 ] , @xmath337 from this relationship between the supremum of moments of @xmath338 and @xmath339 , and from the properties of increments of brownian motion , it follows that , to prove theorem [ t : moment ] , it suffices to bound @xmath340 for some @xmath224 .",
    "however this follows from the fact that @xmath341 and corollary [ c : growslow ] .",
    "we now provide some numerical experiments to complement the analysis of the previous sections .",
    "we begin , in this section , by demonstrating the importance of assumption [ ass3 ] in ensuring pathwise convergence . in the next section",
    "we discuss an abstraction of the method presented and studied in detail in this paper .",
    "section [ sec:9 ] then shows how this abstraction leads to a variant of the method discussed here , tailored to the study of damped - driven hamiltonian systems .",
    "we provide numerical experiments showing the efficiency of the methods at capturing the system s invariant measure .    in the convergence analysis , we made assumption [ ass3 ] the second part of which was to assume that the hitting time of small neighbourhoods of the set @xmath342 is large with high probability .",
    "we now illustrate that this is not simply a technical assumption .",
    "we study the test problem @xmath343 where @xmath344 is a real valued scalar brownian motion .",
    "the set @xmath342 comprises the points where @xmath345 satisfies @xmath346 and @xmath347 , that is the points @xmath348 since the problem is one dimensional the hitting time to neighbourhoods of these points is not small .",
    "for contrast we apply the algorithm to the systems in two and three dimensions found by making identical copies of the equation ( [ eq : test2 ] ) in the extra dimensions with each dimension driven by an independent noise .",
    "thus the set @xmath342 comprises the tensor product of the set @xmath349 in the appropriate number of dimensions .",
    "small neighbourhoods of this set do have large hitting time , with high probability . to illustrate the effect of this difference between hitting times we show , in figure [ fig : grad - problem ] , the average time step taken at a given location in space for ( the first component of ) @xmath350 .",
    "notice that in one dimension the algorithm allows quite large average steps in the neighbourhood of the points @xmath348 this does not happen in dimensions two and three because the probability that the other components of @xmath350 is also near to the set @xmath351 at the same time is very small .",
    "the effect of this large choice of time steps in one dimension is apparent in the empirical densities for ( the first component of ) @xmath350 which are also shown in figure [ fig : grad - problem ] ; these are generated by binning two hundred paths of the sde ( [ eq : test2 ] ) over two hundred time units .",
    "it is important to realize that , although the algorithm in one dimension makes a very poor approximation of the empirical density , this occurs only because of a relatively small number of poorly chosen time - steps .",
    "figure [ fig : grad - steps ] shows a histogram of the timesteps ( @xmath352 values ) taken in one , two and three dimensions .",
    "the plots are nearly identical , except that in one dimension the algorithm allows the method to take a small number of larger steps with @xmath353    [ cols=\"^,^ \" , ]",
    "the method given in can be seen as a simple instance of a general class of methods based on comparing , with some error metric , one time step given by two methods of the form @xmath354 where @xmath355 are deterministic functions .",
    "the method in was based on comparing the pair of explicit methods given by @xmath356 where @xmath357 .",
    "\\end{aligned}\\ ] ] in , closeness was measured by the difference , divided by the step size , between the conditional expectations of one time step of the two different methods ; this gives @xmath358    from this point of view , it is clear that the method discussed thus far is one of a large family of methods .",
    "depending on the setting , one might want to compare methods other that the simple euler methods used thus far .",
    "also one can consider different error measures . in the next section ,",
    "we study a damped - driven hamiltonian problem and use ideas from symplectic integration to design an appropriate method . in the discussion at the end of the article , we return to the question of different error measures .",
    "in this section , we demonstrate that the ideas established for the rather specific adaptive scheme studied , and for the particular hypotheses on the drift and diffusion , extend to a wider class of sdes and adaptive methods .    as a test problem",
    "we consider the langevin equation @xmath359\\;dt+{g}(q)dw \\ . \\notag\\end{aligned}\\ ] ] where @xmath360 , @xmath361 the preceding theory does not apply to this system since it is not uniformly elliptic ; furthermore it fails to satisfy .",
    "however it does satisfy a foster - lyapunov drift condition and since it is hypoelliptic the equation itself can be proven geometrically ergodic @xcite . in @xcite",
    ", it was shown that the implicit euler scheme was ergodic when applied to , and a similar analysis would apply to a variety of implicit methods . since the adaptive schemes we study in this section enforce closeness to such implicit methods , we believe that analysis similar to that in the previous section will extend to this langevin equation and to the adaptive numerical methods studied here .",
    "we will compare two different methods based on different choices of the stepping method .",
    "the first is the euler based scheme given in .",
    "the second is the following scheme : @xmath362 where @xmath363 once again we will use comparisons between the two updates ( with and without bars ) to control the error .",
    "as before , we control on the difference in the expected step .",
    "the point of the particular form used here is that , in the absence of noise and damping , the adaptation constrains the scheme to take steps which are close to those of the symplectic midpoint scheme , known to be advantageous for hamiltonian problems ; if the noise and damping are small , we expect the hamiltonian structure to be important .    in both the euler and symplectic case ,",
    "the stepping methods take the form @xmath364 where @xmath365 and @xmath366 , @xmath367 , @xmath368 are adapted to @xmath369 . in this notation",
    "the metric becomes ,",
    "@xmath370^\\frac12 < \\tau\\end{aligned}\\ ] ]    in the remainder of this section , we present numerical experiments with the two methods just outlined .",
    "we study the qualitative approximation of the invariant measure , we quantify this approximation and measure its efficiency , and we study the behaviour of time - steps generated .",
    "[ fig : invmeasureeuler1 ]   with different @xmath10 for euler method the value of tolerance @xmath10 is on the left of each figure.,title=\"fig:\",width=288 ]    [ fig : pdfeuler1 ]    [ fig : invmeasureeuler2 ]   with different @xmath10 for the symplectic method .",
    "the value of tolerance @xmath10 is on the left of each figure.,title=\"fig:\",width=288 ]    [ fig : pdfeuler2 ]    figure [ fig : invmeasureeuler1 ] plots the numerically obtained time average of the position @xmath371 and momentum @xmath372 for various values of the tolerance @xmath10 .",
    "the doted lines are the true invariant measure of the underling sde which can be computed analytically in this particular case .",
    "notice that the method appears stable for all values of @xmath10 , in contrast to the forward euler method which blows up when applied to this equation .",
    "though apparently stable , the results are far from the true distribution for large @xmath10 .",
    "figure [ fig : invmeasureeuler2 ] gives the analogous plots for the adaptive symplectic method given in .",
    "notice that these methods seem to do a much better job of reproducing the invariant measure faithfully at large @xmath10 .",
    "it is also important to study accuracy per unit of computational effort .",
    "figure [ fig : compare ] gives plots of the error in the total variation norm ( the @xmath373 distance between the numerically computed time averages and the exact analytic answer verses the @xmath10 used and versus the steps per unit of time ; the latter provides a measure of unit cost .",
    "the top plots are for the momentum @xmath372 and the bottom for the position @xmath371 .",
    "the plots on the right also include two fixed step methods , one using simple the forward euler scheme and the second using the first of the symplectic schemes .",
    "the fixed - step euler schemes blows up for steps larger than those given .",
    "we make the following observations on the basis of this experiment :    * the fixed - step symplectic method is the most efficient at small time - steps ; * the adaptive symplectic method is considerably more efficient than the adaptive and fixed - step euler methods ; * the adaptive symplectic method is the most robust method , providing reasonable approximations to the invariant density for a wide range of @xmath374    note that the adaptive methods have not been optimized and with careful attention might well beat the fixed - step methods , both as measured by accuracy per unit cost , as well as by robustness . further study of this issue is required .",
    "[ fig : compare ]",
    "this paper proposes a simple adaptive strategy for sdes which is designed to enforce geometric ergodicity , when it is present in the equation to be approximated ; without adaptation methods such as explicit euler may destroy ergodicity .",
    "as well as proving ergodicity , we also prove some exponential moment bounds on the numerical solution , again mimicking those for the sde itself .",
    "furthermore , we prove finite - time convergence of the numerical method ; this is non - trivial because we do not assume ( and it is not true in general ) that the time - step sequence tends to zero with user input tolerance .",
    "it would be of interest to transfer this finite time convergence to a result concerning convergence of the invariant measures , something which is known for fixed time - step schemes @xcite .    as discussed in section [ sec : generalization ] , the scheme we study in detail here is prototypical of more advanced schemes comparing two more sophisticated methods and controlling both on drift and diffusion . here",
    "we have mainly used simple forward euler methods and controlled only on the drift : our error measure is based on the conditional means .",
    "the split - step approach we take allows for additional terms to be added to the error measure , to ensure that the diffusion step is also controlled .",
    "the general idea is to enforce the closeness of one step by two different methods .",
    "one has freedom in the choice of the methods and the measure of closeness .",
    "we now briefly mention to other error measure which make this idea specific .    for simplicity",
    "let us assume work in one dimension though the ideas generalize directly to higher dimensions .",
    "the simple error control given in controls only the difference in the expectation of one step of the two methods .",
    "however one can also use measure which ensure the closeness of the entire distribution of one time step of the two methods .",
    "given @xmath375 and @xmath376 , one step of a method of the form is gaussian .",
    "hence it is reasonable to require that the standard deviations are close to each other .",
    "the error criteria would then be @xmath377 in some ways , comparing the mean and standard deviations is rather arbitrary .",
    "a more rational choice might be to ensure the closeness of the total variation distance of the densities after one time step of the two methods . a simple way to do",
    "this is to compare the relative entropy of the two distributions .",
    "since the distributions are gaussian this can be done explicitly .",
    "one finds that the criteria based on controlling relative entropy per unit step is @xmath378 it is interesting to note that this measure correctly captures the fact that one should measure the error in the drift on the scale of the variance . in other words",
    "if the variance is large , one does not need to be as accurate in calculating the drift as it will be washed out by the noise anyway . since the above measure is expensive to calculate one can use that fact that @xmath379 is small to obtain the asymptotically equivalent criteria @xmath380",
    "the authors thank george papanicolaou for useful discussions concerning this work .",
    "jcm thanks the nsf for its support ( grants dms-9971087 and dms-9729992 ) ; he also thanks the institute for advanced study , princeton , for its support and hospitality during the academic year 2002 - 2003 .",
    "ams thanks the epsrc for financial support .",
    "we also wish to thank a careful and conscientious referee who noticed a substantive error in an earlier draft of this paper , and persisted until we understood his / her point",
    ".    99    m.a .",
    "aves , d.f .",
    "griffiths and d.j .",
    "higham , _ does error control suppress spuriosity ? _ to appear in siam j. num .",
    "g. cassella and c.p .",
    "robert , _ monte carlo statistical methods _ , springer texts in statistics , new york , 2002 .",
    "k. dekker and j.g verwer , _ stability of runge - kutta methods for stiff nonlinear differential equations .",
    "_ north - holland , amsterdam , 1984 .    r.m .",
    "dudley , _ real analysis and probability_. cambridge university press , cambridge , 2002 .",
    "gaines and t.j .",
    "lyons , _ variable stepsize control in the numerical solution of stochastic differential equations _ , siam j. appl",
    ", * 57*(1997),14551484 .",
    "griffiths , _ the dynamics of some linear multistep methods with step - size control .",
    "_ appears in `` numerical analysis 1987 '' eds : griffiths , d.f . and watson , g.a . , longman ( 1988 ) , 115134 .    j.k .",
    "asymptotic behaviour of dissipative systems .",
    "_ ams mathematical surveys and monographs 25 , rhode island , 1988 .",
    "hansen , _ geometric ergodicity of discrete time approximations to multivariante diffusions_. bernoulli , submitted , 2002 .",
    "r.  z. hasminskii . .",
    "sijthoff and noordhoff , 1980 .",
    "higham and a.m. stuart _ analysis of the dynamics of error control via a piecewise continuous residual .",
    "_ bit * 38*(1998 ) , 4457 .",
    "d.  j. higham , x.  mao , and a.  m. stuart .",
    "strong convergence of euler - type methods for nonlinear stochastic differential equations .",
    ", 40:10411063 , 2002 .",
    "n. hofmann , t. mller - gronbach and k. ritter",
    "_ optimal approximation of sdes by adaptive step - size control . _ math . comp . * 69*(2000 ) , 10171034 .",
    "n. hofmann , t. mller - gronbach and k. ritter _ the optimal discretization of sdes .",
    "_ j. of complexity .",
    "* 17*(2001 ) , 117153 .",
    "n. hofmann , t. mller - gronbach and k. ritter",
    "_ optimal uniform approximation of systems of sdes .",
    ". prob . * 12*(2002 ) , 664690 .",
    "kloeden and e. platen , _ numerical solution of stochastic differential equations_. springer - verlag , new york , 1991 .",
    "h.  lamba .",
    "dynamical systems and adaptive time - stepping in ode solvers . , 40:314335 , 2000 .    h. lamba and a.m. stuart _ convergence results for the matlab ode23 routine_. bit * 38*(1998 ) , 751780 .",
    "h. lamba , j.c .",
    "mattingly and a.m. stuart _ an adaptive euler - maruyama scheme for sdes : part i , convergence_.    x. mao , _ stochastic differential equations and applications_. horwood , chichester , 1997 .",
    "the mathworks , inc .",
    ", _ matlab user s guide_. natick , massachusetts , 1992 .    j.c .",
    "mattingly , a.m. stuart and d.j .",
    "ergodicity for sdes and approximations : locally lipschitz vector fields and degenerate noise_. stoch .",
    "proc . and applics .",
    "* 101*(2002 ) , 185232 .    j.c .",
    "mattingly , _ a numerical study of adaptive methods for sdes_. in preparation .",
    "s. meyn and r.l .",
    "tweedie , _ stochastic stability of markov chains_. springer - verlag , new york , 1992 .    t.  mller - gronbach . .",
    "roberts and r.l .",
    "tweedie _ exponential convergence of langevin diffusions and their discrete approximations _ ,",
    "bernoulli * 2*(1996 ) , 341363 .    l.c.g .",
    "rogers and d.williams _ diffusions , markov processes and martingales , volumes 1 and 2_. cambridge university press , reprinted second edition , 2000 .",
    "sanz - serna , _ numerical ordinary differential equations versus dynamical systems_. in d.s .",
    "broomhead and a. iserles , editors ,  the dynamics of numerics and the numerics of dynamics  , clarendon press , oxford , 1992 .",
    "o. stramer and r.l .",
    "tweedie , _ langevin - type models i : diffusions with given stationary distributions , and their discretizations _ ,",
    "methodology & computing in applied probability , * 1*(1999 ) , 283 - 306 .",
    "a.m. stuart .",
    "probabilistic and deterministic convergence proofs for software for initial value problems .",
    ", 14:227260 , 1997 .",
    "a.m. stuart and a.r .",
    "humphries , _ dynamical systems and numerical analysis_. cambridge university press , 1996 .",
    "a.m. stuart and a.r .",
    "humphries , _ the essential stability of local error control for dynamical systems .",
    "_ siam j. num",
    "32*(1995 ) , 19401971 .",
    "d. talay , _ second - order discretization schemes for stochastic differential systems for the computation of the invariant law . _ stochastics and stochastics reports * 29*(1990 ) , 1336 .",
    "d. talay , _ approximation of the invariant probability measure of stochastic hamiltonian dissipative systems with non globally lipschitz co - efficients_. appears in `` progress in stochastic structural dynamics '' , volume 152 , 1999 , editors r. bouc and c. soize .",
    "publication du l.m.a .- cnrs .",
    "d. talay , _ stochastic hamiltonian dissipative systems with non globally lipschitz co - efficients : exponential convergence to the invariant measure and discretization by the implicit euler scheme_. markov proc .",
    "rel . fields .",
    ", * 8*(2002 ) , 163198 .",
    "r. temam , _ infinite dimensional dynamical systems in mechanics and physics .",
    "springer , new york , 1989 .",
    "let @xmath381 , @xmath382 be a filtration .",
    "let @xmath383 be a sequence of random variables with @xmath383 adapted to @xmath384 and such that @xmath385 conditioned on @xmath386 is normal with mean zero and variance @xmath387 < \\infty$ ] .",
    "we define the following processes :          we begin with the first estimate .",
    "define @xmath397 and observe that @xmath398 .",
    "this in turn implies that @xmath399 . combining these facts",
    "we see that @xmath400 is a martingale .",
    "hence , the doob - kolmogorov martingale inequality @xcite implies @xmath401 since @xmath402 , the proof is complete .    the second estimate is obtained in the same way after some preliminary calculations .",
    "we define @xmath403 and @xmath404 .",
    "observe that @xmath405 and @xmath406 if @xmath407 $ ] and @xmath408 .",
    "now @xmath409 setting @xmath410 , we have that @xmath411 for all @xmath412 since @xmath413 and @xmath414 . defining @xmath415 we have @xmath416 now",
    "recall that if @xmath417 is a unit gaussian random variable then @xmath418 for @xmath419 . by construction @xmath420 , conditioned on @xmath421 , is a gaussian random variable with variance less then @xmath295 .",
    "hence @xmath422 using this one sees that @xmath423 and @xmath424 , hence @xmath425 is a martingale . by the same argument as before using the doob - kolmogorov martingale inequality",
    ", we obtain the quoted result ."
  ],
  "abstract_text": [
    "<S> the understanding of adaptive algorithms for sdes is an open area where many issues related to both convergence and stability ( long time behaviour ) of algorithms are unresolved . </S>",
    "<S> this paper considers a very simple adaptive algorithm , based on controlling only the drift component of a time - step . </S>",
    "<S> both convergence and stability are studied .    </S>",
    "<S> the primary issue in the convergence analysis is that the adaptive method does not necessarily drive the time - steps to zero with the user - input tolerance . </S>",
    "<S> this possibility must be quantified and shown to have low probability .    </S>",
    "<S> the primary issue in the stability analysis is ergodicity . </S>",
    "<S> it is assumed that the noise is non - degenerate , so that the diffusion process is elliptic , and the drift is assumed to satisfy a coercivity condition . </S>",
    "<S> the sde is then geometrically ergodic ( averages converge to statistical equilibrium exponentially quickly ) . </S>",
    "<S> if the drift is not linearly bounded then explicit fixed time - step approximations , such as the euler - maruyama scheme , may fail to be ergodic . in this work </S>",
    "<S> , it is shown that the simple adaptive time - stepping strategy cures this problem . </S>",
    "<S> in addition to proving ergodicity , an exponential moment bound is also proved , generalizing a result known to hold for the sde itself .    </S>",
    "<S> key words : stochastic differential equations , adaptive time - discretization , convergence , stability , ergodicity , exponential moment bounds . </S>"
  ]
}