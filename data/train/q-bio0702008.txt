{
  "article_text": [
    "a key step in the immune response to pathogen invasion is the activation of cytotoxic t - cells , which is triggered by the recognition of a short peptide , called epitope , bound to major histocompatibility complex ( mhc ) class i molecules and presented to the t - cells .",
    "this recognition is supposed to trigger cloning and activation of cytotoxic lymphocytes able to identify and destroy the pathogen or infected cells .",
    "mhc class i epitopes are therefore potential tools for the development of peptide vaccines , in particular for aids vaccines  @xcite .",
    "they are also potential tools for diagnosis and treatment of cancer  @xcite .    identifying mhc class i epitope in a pathogen genome is therefore crucial for vaccine design .",
    "however , not all peptides of a pathogen can bind to the mhc molecule to be presented to t - cells : it is estimated that only 1 in 100 or 200 peptides actually binds to a particular mhc  @xcite . in order to alleviate the cost and time required to identify epitopes experimentally , _ in silico _ computational methods for epitope prediction",
    "are therefore increasingly used .",
    "structural approaches , on the one hand , try to evaluate how well a candidate epitope fit in the binding groove of a mhc molecule , by various threading or docking approaches  @xcite .",
    "sequence - based approaches , on the other hand , estimate predictive models for epitopes by analyzing and learning from sets of known epitopes and non - epitopes .",
    "models can be based on motifs  @xcite , profiles @xcite , or machine learning methods like artificial neural networks  @xcite , hidden markov models  @xcite , support vector machines ( svm )  @xcite , boosted metric learning  @xcite or logistic regression  @xcite .",
    "finally , some authors have recently proposed to combine structural and sequence - based approaches  @xcite .",
    "although comparison is difficult , sequence - based approaches that learn a model from the analysis of known epitopes benefit from the accumulation of experimentally validated epitopes and will certainly continue to improve as more data become available .",
    "the binding affinity of a peptide depends on the mhc molecule s 3d structure and physicochemical properties , which in turns vary between mhc alleles .",
    "this compels any prediction method to be allele - specific : indeed , the fact that a peptide can bind to an allele is neither sufficient nor necessary for it to bind to another allele",
    ". since mhc genes are highly polymorphic , little training data if any is available for some alleles .",
    "thus , though achieving good precisions in general , classical statistical and machine learning - based mhc - peptide binding prediction methods fail to efficiently predict bindings for these alleles .    some alleles , however , can share binding properties .",
    "in particular , experimental work  @xcite shows that different alleles have overlapping peptide repertoires .",
    "this fact , together with the posterior observation of structural similarities among the alleles sharing their repertoires allowed the definition of hla allele supertypes , which are families of alleles exhibiting the same behavior in terms of peptide binding .",
    "this suggests that sharing information about known epitopes across different but similar alleles has the potential to improve predictive models by increasing the quantity of data used to establish the model .",
    "for example ,  @xcite show that simply pooling together known epitopes for different alleles of a given supertype to train a model can improve the accuracy of the model .",
    "@xcite pool together epitope data for all alleles simultaneously to learn a metric between peptides , which is then used to build predictive models for each allele .",
    "finally , @xcite show that leveraging the information across mhc alleles and supertypes considerably improves individual allele prediction accuracy .    in this paper",
    "we show how this strategy of leveraging information across different alleles when learning allele - specific epitope prediction models can be naturally performed in the context of svm , a state - of - the - art machine learning algorithm .",
    "this new formulation is based on the notion of _ multitask kernels _",
    "@xcite , a general framework for solving several related machine learning problems simultaneously . known",
    "epitopes for a given allele contribute to the model estimation for all other alleles , with a weight that depends on the similarity between alleles . here",
    "the notion of similarity between alleles can be very general ; we can for example follow  @xcite and define two alleles to be similar if they belong to the same supertype , but the flexibility of our mathematical formulation also allows for more subtle notions of similarity , based for example of sequence similarity between alleles . on a benchmark experiment",
    "we demonstrate the relevance of the multitask svm approach which outperforms state - of - the - art prediction methods .",
    "in this section , we explain how information can be shared between alleles when svm models are trained on different alleles . for the sake of clarity",
    "we first explain the approach in the case of linear classifiers , and then generalize it to more general models .",
    "let us first assume that epitopes are represented by @xmath0-dimensional vectors @xmath1 , and that for each allele @xmath2 we want to learn a linear function @xmath3 to discriminate between epitopes and non - epitopes , where @xmath4 .",
    "a natural way to share information between different alleles is to assume that each vector @xmath5 is the sum of a common vector @xmath6 which is common to all alleles , and of an allele - specific vector @xmath7 , resulting in a classifier : @xmath8 in this equation the first term @xmath6 accounts for general characteristics of epitopes valid for all alleles , while the second term @xmath7 accounts for allele - specific properties of epitopes . in order to estimate such a model from data",
    "it is convenient to rewrite it as a simple linear model in a larger space as follows . assuming that there are @xmath9 alleles @xmath10 we can indeed rewrite as : @xmath11 where @xmath12 is the @xmath13-dimensional vector @xmath14 and @xmath15 is the vector obtained by concatenating the vector @xmath1 with @xmath9 blocks of zeros , except for the @xmath2-th block which is a copy of @xmath1 .",
    "indeed it is then easy to check that @xmath16 , hence that and are equivalent .",
    "each ( peptide , allele ) pair is therefore mapped to a large vector @xmath17 with only two non - zero parts , one common to all alleles and one at an allele - specific position .",
    "the parameters of this model , namely the weights @xmath6 and @xmath7 for all alleles @xmath2 , can then be learned simultaneously by any linear model , such as logistic regression or svm , that estimates a vector @xmath12 in from a training set @xmath18 of ( peptide , allele ) pairs labeled as @xmath19 if peptide @xmath20 is an epitope of allele @xmath21 , @xmath22 otherwise .",
    "this approach was followed by  @xcite who included another level of granularity to describe how information is shared across alleles , by considering allele - specific , supertype - specific and common weight vectors .    in summary , it is possible to embed the allele information in the description of the data point to estimate linear models in the new @xmath23 space to share information across alleles .",
    "it is furthermore possible to adjust how information is shared by choosing adequate functions @xmath17 to represent ( peptide , allele ) pairs . in other words , it is possible to consider the problem of leveraging across the alleles as a simple choice of representation , or feature design for the ( peptide , allele ) pairs that are to be used to learn the classifier .",
    "this approach , however , is limited by at least two constraints :    * it can be uneasy to figure out how to represent the allele information in the mapping @xmath17 . in  @xcite , this is done _ via _ boolean conjunctions and leads to a convenient form for the prediction functions , like with a third term accounting for the supertype .",
    "including more prior knowledge regarding when two alleles should share more information , _",
    "e.g. _ , based on structural similarity between alleles , is however not an easy task .",
    "* practically , injecting new features in the vector @xmath17 increases the dimension of the space , making statistical estimation , storage , manipulation and optimization tasks much harder .    in the next subsection",
    "we show how both limitations can be overcome by reformulating this approach in the framework of kernel methods .",
    "svm , and more generally kernel methods , only access data through the computation of inner products between pairs of data points , called a _ kernel _",
    "function  @xcite . as a result , estimating the weights @xmath12 in ( [ eq : mtfbis ] ) with a svm does not require to explicitly compute or store the vectors @xmath17 for training and test pairs of alleles and peptides .",
    "instead , it only requires to be able to compute the kernel between any two pairs @xmath24 and @xmath25 given , in our linear example , by : @xmath26 let us now introduce the following two kernels , respectively between peptides only and between alleles only : @xmath27 it is easy to see that both kernels are valid positive definite kernels for peptides and alleles , respectively . with these notations",
    "we see that the kernel for pairs @xmath24 can be expressed as the _ product _ of the kernel for alleles and the kernel for peptides : @xmath28 which is also the kernel associated to the tensor product space of the hilbert spaces associated to @xmath29 and @xmath30  @xcite .",
    "such kernels are used in particular in the field of _ multitask learning _",
    "@xcite , where several related machine learning tasks must be solved simultaneously .",
    "the allele kernel @xmath30 quantifies how information is shared between alleles .",
    "for example , in the simple model ( @xmath31 ) the kernel is simply equal to 2 if an allele is compared to itself , 1 otherwise , meaning that information is uniformly shared across different alleles . alternatively , adding supertype - specific features like  @xcite would result in a kernel equal to @xmath32 between an allele and itself , @xmath33 between two different alleles that belong to a common supertype , and @xmath34 otherwise , resulting in increased sharing of information within supertypes .",
    "interestingly this formulation lends itself particularly well to further generalization . indeed , for any positive definite kernels @xmath30 and @xmath29 for alleles and peptides , respectively",
    ", their product ( [ eq : product ] ) is a valid positive definite kernel over the product space of pairs ( peptide , allele )  @xcite .",
    "this suggests a new strategy to design predictive models for epitopes across alleles , by designing specific kernels for alleles and peptides , respectively , and combining them to learn all allele - specific models simultaneously with the tensor product kernel ( [ eq : product ] ) .",
    "benefits of this strategy over the explicit design and computation of feature vectors @xmath17 are two - folds .",
    "first , it splits the problem of feature vector design into two subproblems ( designing two kernels ) , each of which can benefit from previous work on kernel design  ( _ e.g. _ , * ? ? ?",
    "for example , the fact that nonlinear kernels such as gaussian or polynomial kernels for peptides give good results for svm trained on individual alleles suggest that they are natural candidates for the peptide part of the product kernel .",
    "second , working with kernels alleviates the practical issues due to the potentially large size of the feature vector representation @xmath17 in terms of memory for storage or speed of convergence of algorithms .",
    "we now describe in more details the kernels @xmath29 and @xmath30 that can be used for peptides and alleles , respectively , to create the product kernel used in the application .",
    "we consider in this paper mainly peptides made of @xmath35 amino acids , although extensions to variable - length peptides poses no difficulty in principle  @xcite . the classical way to represent these @xmath35-mers as fixed length vectors is to encode the letter at each position by a @xmath36-dimensional binary vector indicating which amino acid is present , resulting in a @xmath37-dimensional vector representations . in terms of kernel ,",
    "the inner product between two peptides in this representation is simply the number of letters they have in common at the same positions , which we take as our baseline kernel : @xmath38x'[i]),\\ ] ] where @xmath39 is the length of the peptides ( @xmath35 in our case ) , @xmath40 $ ] is the @xmath41-th residue in x and @xmath42x'[i])$ ] is @xmath34 if @xmath40 = x'[i]$ ] , @xmath43 otherwise .",
    "alternatively , several authors have noted that nonlinear variants of the linear kernel can improve the performance of svm for epitope prediction  @xcite . in particular , using a polynomial kernel of degree @xmath9 over the baseline kernel is equivalent , in terms of feature space , to encoding @xmath9-order interactions between amino acids at different positions . in order to assess the relevance of such non - linear extensions we tested a polynomial kernel of degree 5 , _",
    "i.e. _ , @xmath44    in order to limit the risk of overfitting to the benchmark data we restrict ourselves to the evaluation of the baseline linear kernel and its nonlinear polynomial extension . designing a specific peptide kernel for epitope prediction ,",
    "_ e.g. _ , by weighting differently the positions known to be critical in the mhc - peptide complex , is however an interesting research topic that could bring further improvements in the future .",
    "although the question of kernel design for peptides has been raised in previous studies involving svm for epitope prediction  @xcite , the question of kernel design for alleles is new to our knowledge .",
    "we tested several choices that correspond to previously published approaches :    * the _ dirac _ kernel is : @xmath45 with the dirac kernel , no information is shared across alleles and the svm learns one model for each allele independently from the others .",
    "therefore this corresponds to the classical setting of learning epitope prediction models per allele with svm .",
    "* the _ uniform _ kernel is : @xmath46 with this kernel all alleles are considered the same , and a unique model is created by pooling together the data available for all alleles . *",
    "the _ multitask _ kernel is : @xmath47 as explained in the previous section and in  @xcite this is the simplest way to train different but related models .",
    "the svm learns one model for each allele , using known epitopes and non - epitopes for the allele , but using also known epitopes and non - epitope for all other alleles with a smaller contribution .",
    "the training peptides are shared uniformly across different alleles . *",
    "the _ supertype _ kernel is @xmath48 where @xmath49 is @xmath34 if @xmath2 and @xmath50 are in the same supertype , @xmath43 otherwise . as explained in the previous section this scheme trains a specific models for each allele using training peptides from different alleles , but here the training peptides are more shared across alleles withing a supertype than across alleles in different supertypes .",
    "this is used by  @xcite , without the kernel formulation , to train a logistic regression model .",
    "@xcite show that the supertype kernel generally improves the performance of logistic regression models compared to the uniform or dirac kernel .",
    "intuitively it seems to be an interesting way to include prior knowledge about alleles .",
    "however , one should be careful since the definition of supertypes is based on the comparison of epitopes of different alleles , which suggests that the supertype information might be based on some information used to assess the performance of the method in the benchmark experiment . in order to overcome this issue , and illustrate the possibilities",
    "offered by our formulation , we also tested a kernel between alleles which tries to quantify the similarity of alleles without using known epitope information .",
    "for that purpose we reasoned that alleles with similar residues at the positions involved in the peptide binding were more likely to have similar epitopes , and decided to make a kernel between alleles based on this information .",
    "for each locus we gathered from  @xcite the list of positions involved in the binding site of the peptide ( table [ tab : bsite ] ) . taking the union of these sets of positions we then represented each allele by the list of residues at these positions , and used a polynomial kernel of degree @xmath51 to compare two lists of residues associated to two alleles , _",
    "i.e _ , @xmath52a'[i])+1\\right)^7,\\ ] ] where bsite is the set of residues implied in the binding site for one of the three allele groups hla - a , b , c , @xmath53 $ ] is the @xmath41-th residue in a and @xmath54a'[i])$ ] is @xmath34 if @xmath53 = a'[i]$ ] , @xmath43 otherwise .",
    "we learn epitope models with svm , a state - of - the - art algorithm for pattern recognition  @xcite .",
    "we used the ` libsvm ` svm implementation , with a custom kernel to account for the various kernels we tested , in the pyml environment ( http://pyml.sourceforge.org ) .",
    "besides the kernel , svm depends on one parameter usually called @xmath55 . for each experiment",
    ", we selected the best @xmath55 among the values @xmath56 by selecting the value leading to the largest area under the roc curve estimated by cross - validation on the training set only .",
    "the performance of each method was then tested on each experiment by evaluating the auc over the test data .",
    "in order to evaluate both the performance of our method and the impact of using various kernels for the peptides or the alleles , we test our method on three different benchmark datasets that have been compiled recently to compare the performance of epitope prediction algorithms .",
    "we first use two datasets compiled by @xcite , where it is already shown that leveraging improves prediction accuracy with respect to the best published results.the first dataset , called syfpeithy+lanl , combines experimentally confirmed positive epitopes from the syfpeithy database  ( see * ? ? ?",
    "* available at http://www.syfpeithy.de ) and from the los alamos hiv database ( http://www.hiv.lanl.gov ) and negative example randomly drawn from the hla and amino acid distribution in the positive examples , for a total of @xmath57 data points . for more details , see  @xcite where this dataset is used to compare the leveraged logistic regression with _",
    "distboost_. since this dataset is quite small and was already used as a benchmark , we use it as a first performance evaluation , and to compare our kernels .",
    "the second dataset of @xcite contains @xmath58 peptides including those from sysfpeithy+lanl and others from the mhcbn data repository  ( see * ? ? ?",
    "* available at http://www.imtech.res.in/raghava/mhcbn/index.html ) .",
    "this corresponds to @xmath59 experimentally validated epitopes , and @xmath60 randomly generated non - binders ( @xmath61 for each positive ) .",
    "we only kept @xmath62 negative for each positive in the interest of time and assuming this would not deteriorate too much the performance of our algorithm . in the worst case ,",
    "it is only a handicap for our methods .",
    "finally , we assess the performance of our method on the mhc - peptide binding benchmark recently proposed by  @xcite who gathered quantitative peptide - binding affinity measurements for various species , mhc class i alleles and peptide lengths , which makes it an excellent tool to compare mhc - peptide binding learning methods .",
    "since our method was first designed for binary classification of hla epitopes , we focused on the 9-mer peptides for the @xmath63 human alleles and thresholded at @xmath64 .",
    "nevertheless , the application of our method to other species or peptide lengths would be straightforward , and generalization to quantitative prediction should not be too problematic either .",
    "the benchmark contained @xmath65 9-mer .",
    "the first dataset is 5-folded , the second 10-folded , so that the test be only performed on hiv ( lanl ) data .",
    "the third dataset is 5-folded .",
    "we used the same folds as  @xcite , available at ftp://ftp.research.microsoft.com/users/heckerma/recomb06 for the first two datasets and the same folds as  @xcite available at http://mhcbindingpredictions.immuneepitope.org/ for the third one .",
    "molecule - based allele kernels require the amino - acid sequences corresponding to each allele .",
    "these sequences are available in various databases , includinghttp://www.anthonynolan.org.uk/ and  @xcite .",
    "we used the peptide - sequence alignment for hla - a , hla - b and hla - c loci .",
    "each sequence was restricted to residues at positions involved in the binding site of one of the three loci , see table  [ tab : bsite ] .",
    "preliminary experiments showed that using this restriction instead of the whole sequences did nt change the performance significantly , but it speeds up the calculation of the kernel .",
    "we were not able to find the sequence of a few molecules of the two datasets of  @xcite , so in the experiments implying these datasets and a molecule - based allele kernel , we used @xmath66 instead of simply using @xmath67 , with a sentinel value of @xmath68 in these cases .",
    "this is the sum of two kernels , so still a positive definite kernel and actually exactly the same thing as @xmath69 with @xmath70 instead of @xmath71 .",
    ".residue positions involved in the binding site for the three loci , according to  @xcite [ cols=\"^,<\",options=\"header \" , ]     * 5callele & peptide number & @xmath72 & adt & ann + a_2301 & @xmath73 & @xmath74 & @xmath75 & @xmath76 + a_2402 & @xmath77 & @xmath78 & @xmath79 & @xmath80 + a_2902 & @xmath81 & @xmath82 & @xmath83 & @xmath84 + a_3002 & @xmath85 & @xmath86 & @xmath87 & @xmath88 + b_1801 & @xmath89 & @xmath90 & @xmath91 & @xmath92 + b_4002 & @xmath89 & @xmath93 & @xmath94 & @xmath95 + b_4402 & @xmath96 & @xmath97 & @xmath98 & @xmath99 + b_4403 & @xmath96 & @xmath100 & @xmath101 & @xmath87 + b_4501 & @xmath102 & @xmath103 & @xmath104 & @xmath105 + b_5701 & @xmath106 & @xmath107 & @xmath108 & @xmath109 +",
    "in this paper , we introduced a general framework to share efficiently the binding information available for various alleles by simply defining a kernel for the peptides , and another one for the alleles .",
    "the result is a simple model for mhc - peptide binding prediction that uses information from the whole dataset to make specific prediction for any of the alleles .",
    "our approach is simple , general and both easy to adapt to a specific problem by using more adequate kernels , and to implement , by running any svm implementation with these kernels .",
    "everything is performed in low dimension and with no need for feature selection .",
    "we presented performances on three benchmarks . on the first two benchmark ,",
    "our approach performed considerably better than the state - of - the - art , which illustrates the good general behavior in terms of prediction accuracy .",
    "besides , these experiments clearly confirmed the interest of leveraging the information across the alleles . on the last benchmark ,",
    "the results were globally comparable to the best state - of - the - art tested in  @xcite , with a strong improvement on the alleles for which few training points were available , probably , as it was already observed , because of the fact that our model uses all the points from all the alleles for each allele - specific prediction .",
    "another contribution is the use of allele sequences , which allows us to improve the prediction accuracy and to do as well as what was done with the supertype information .",
    "supertype is a crucial information and a key concept in the development of epitope - based vaccines , for example to find epitopes that bind several alleles instead of just one .",
    "however , one should be careful when using it to learn an automatic epitope predictor because even if the idea behind a supertype definition is to represent a general ligand trend , the intuition is always guided by the fact that some alleles have overlapping repertoires of known binders , and it is not easy to figure out to which extent the known epitopes used to assess the predictor performances were used to design the supertypes .    because of these overfitting issues and the fact that supertypes are difficult to define , the good performances of molecule - based allele kernel with respect to the supertype - based allele kernels are good news .",
    "this potentially allows us to leverage efficiently across alleles even when the supertype is unknown , which is often the case , and we do nt take the risk to use overfitted information when learning on large epitope databases .    although the kernels we used already gave good performances , there is still room for improvement .",
    "a first way to improve the performances would be to use more adequate kernels to compare the peptides and , probably more important , to compare the alleles .",
    "in other words answering the question , what does it mean in the context of mhc - peptide binding prediction for two alleles to be similar ?",
    "possible answers should probably involve better kernels for the allele sequences , and structural information which could be crucial to predict binding and , as we said in introduction , is already used in some models .",
    "another interesting possibility is , as it was suggested in  @xcite , the use of true non - binders , that could make the predictor more accurate than randomly generated peptides since these experimentally assessed peptides are in general close to the known binders .",
    "finally , it could be useful to incorporate the quantitative ic50 information when available , instead of simply thresholding as we did for the last benchmark .",
    "this leads us to the possible generalizations we hope to work on , besides these improvements . using the binding affinity information ,",
    "it is obviously possible to apply our general framework to predict quantitative values , using regression models with the same type of kernels .",
    "this framework could also be used for a lot of similar problems involving binding , like mhc - type - ii - peptide binding where sequences can have variable length and the alignment of epitopes usually performed as pre - processing can be ambiguous . @xcite",
    "already proposed a kernel for this case .",
    "another interesting application would be drug design , for example protein - kinase - inhibitor binding prediction , or prediction of a virus susceptibility to a panel of drugs for various mutations of the virus ."
  ],
  "abstract_text": [
    "<S> _ in silico _ methods for the prediction of antigenic peptides binding to mhc class i molecules play an increasingly important role in the identification of t - cell epitopes . </S>",
    "<S> statistical and machine learning methods , in particular , are widely used to score candidate epitopes based on their similarity with known epitopes and non epitopes . </S>",
    "<S> the genes coding for the mhc molecules , however , are highly polymorphic , and statistical methods have difficulties to build models for alleles with few known epitopes . in this case , recent works have demonstrated the utility of leveraging information across alleles to improve the performance of the prediction .    </S>",
    "<S> we design a support vector machine algorithm that is able to learn epitope models for all alleles simultaneously , by sharing information across similar alleles . </S>",
    "<S> the sharing of information across alleles is controlled by a user - defined measure of similarity between alleles . </S>",
    "<S> we show that this similarity can be defined in terms of supertypes , or more directly by comparing key residues known to play a role in the peptide - mhc binding . </S>",
    "<S> we illustrate the potential of this approach on various benchmark experiments where it outperforms other state - of - the - art methods . </S>"
  ]
}