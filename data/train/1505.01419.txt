{
  "article_text": [
    "privacy protection in recommender systems is a notoriously challenging problem .",
    "there are often two competing goals at stake : similar users are likely to prefer similar products , movies , or locations , hence sharing of preferences between users is desirable . yet , at the same time , this exacerbates the type of privacy sensitive queries , simply since we are now not looking for aggregate properties from a dataset ( such as a classifier ) but for properties and behavior of other users ` just like ' this specific user .",
    "such highly individualized behavioral patterns are shown to facilitate provably effective user de - anonymization @xcite .",
    "consider the case of a couple , both using the same location recommendation service .",
    "since both spouses share much of the same location history , it is likely that they will receive similar recommendations , based on other users preferences similar to theirs . in this context sharing of information is desirable , as it improves overall recommendation quality .",
    "moreover , since their location history is likely to be very similar , each of them will also receive recommendations to visit the place that their spouse visited ( e.g.  including places of ill repute ) , regardless of whether the latter would like to share this information or not .",
    "this creates considerable tension in trying to satisfy those two conflicting goals .",
    "differential privacy offers tools to overcome these problems . loosely speaking",
    ", it offers the participants _ plausible deniability _ in terms of the estimate .",
    "that is , it provides guarantees that the recommendation would also have been issued with sufficiently high probability if another specific participant had not taken this action before .",
    "this is precisely the type of guarantee suitable to allay the concerns in the above situation @xcite",
    ".    recent work , e.g.  by @xcite has focused on designing _ custom built _",
    "tools for differential private recommendation .",
    "many of the design decisions in this context are hand engineered , and it is nontrivial to separate the choices made to obtain a differentially private system from those made to obtain a system that works well .",
    "furthermore , none of these systems @xcite lead to very fast implementations .    in this paper",
    "we show that a large family of recommender systems , namely those using matrix factorization , are well suited to differential privacy .",
    "more specifically , we exploit the fact that sampling from the posterior distribution of a bayesian model , e.g.  via stochastic gradient langevin dynamics ( sgld ) @xcite , can lead to estimates that are sufficiently differentially private @xcite . at the same time",
    ", their stochastic nature makes them well amenable to efficient implementation .",
    "their generality means that we _ need not custom - design a statistical model for differential privacy _",
    "but rather that is possible to _ retrofit an existing model _ to satisfy these constraints .",
    "the practical importance of this fact can not be overstated  it means that no costly re - engineering of deployed statistical models is needed .",
    "instead , one can simply reuse the existing inference algorithm with a trivial modification to obtain a differentially private model .",
    "this leaves the issue to performance .",
    "some of the best reported results are those using graphchi @xcite , which show that state - of - the - art recommender systems can be built using just a single pc within a matter of hours , rather than requiring hundreds of computers . in this paper , we show that by efficiently exploiting the power law properties inherent in the data ( e.g.most movies are hardly ever reviewed on netflix ) , one can obtain models that achieve peak numerical performance for recommendation .",
    "more to the point , they are 3 times faster than graphchi on identical hardware .    in summary",
    ", this paper describes the by far the fastest matrix factorization based recommender system and it can be made differentially privately using sgld without losing performance .",
    "most competing approaches excel at no more than one of those aspects . specifically ,    1 .",
    "it is efficient at the state of the art relative to other matrix factorization systems . *",
    "we develop a cache efficient matrix factorization framework for general sgd updates . *",
    "we develop a fast sgld sampling algorithm with bookkeeping to avoid adding the gaussian noise to the whole parameter space at each updates while still maintaining the correctness of the algorithm .",
    "it is differentially private . *",
    "we show that sampling from a scaled posterior distribution for matrix factorization system can guarantee user - level differential privacy .",
    "* we present a personalized differentially private method for calibrating each user s privacy and accuracy .",
    "* we only privately release @xmath0 to public , and design a local recommender system for each user .",
    "experiments confirm that the algorithm can be implemented with high efficiency , while offering very favorable privacy - accuracy tradeoff that nearly matches systems without differential privacy at meaningful privacy level .",
    "we begin with an overview of the relevant ingredients , namely collaborative filtering using matrix factorization , differential privacy and a primer in computer architecture .",
    "all three are relevant to the understanding of our approach .",
    "in particular , some basic understanding of the cache hierarchy in microprocessors is useful for efficient implementations .      in collaborative filtering",
    "we assume that we have a set of @xmath1 users , rating @xmath2 items .",
    "we only observe a small number of entries @xmath3 in the rating matrix @xmath4 . here",
    "@xmath3 means that user @xmath5 rated item @xmath6 .",
    "a popular tool @xcite to deal with inferring entries in @xmath7 is to approximate @xmath4 by a low rank factorization , i.e.@xmath8 for some @xmath9 , which denotes the dimensionality of the feature space corresponding to each item and movie . in other words , ( user , item )",
    "interactions are modeled via @xmath10 here @xmath11 and @xmath12 denote row - vectors of @xmath13 and @xmath0 respectively , and @xmath14 and @xmath15 are scalar offsets responsible for a specific user or movie respectively . finally , @xmath16 is a common bias .",
    "a popular interpretation is that for a given item @xmath6 , the elements of @xmath12 measure the extent to which the item possesses those attributes . for a given user @xmath5 the elements of @xmath11 measure the extent of interest that the user has in items that score highly in the corresponding factors .",
    "due to the conditions proposed in the netflix contest , it is common to aim to minimize the mean squared error of deviations between true ratings and estimates . to address overfitting , a norm penalty",
    "is commonly imposed on @xmath13 and @xmath0 .",
    "this yields the following optimization problem @xmath17 a large number of extensions have been proposed for this model .",
    "for instance , incorporating co - rating information @xcite , neighborhoods , or temporal dynamics @xcite can lead to improved performance . since we are primarily interested in demonstrating the efficacy of differential privacy and the interaction with efficient systems design , we focus on the simple inner - product model with bias .",
    "* bayesian view . * note that the above optimization problem can be viewed as an instance of a maximum - a - posteriori estimation problem .",
    "that is , one minimizes @xmath18 where , up to a constant offset @xmath19 and @xmath20 and likewise for @xmath0 . in other words , we assume that the ratings are conditionally normal , given the inner product @xmath21 , and the factors @xmath11 and @xmath12 are drawn from a normal distribution . moreover , one can also introduce priors for @xmath22 with a gamma distribution @xmath23 .",
    "while this setting is typically just treated as an afterthought of penalized risk minimization , we will explicitly use this when designing differentially private algorithms .",
    "the rationale for this is the deep connection between samples from the posterior and differentially private estimates .",
    "we will return to this aspect after introducing stochastic gradient langevin dynamics .",
    "* stochastic gradient descent . *",
    "minimizing the regularized collaborative filtering objective is typically achieved by one of two strategies : alternating least squares ( als ) and stochastic gradient descent ( sgd ) .",
    "the advantage of the former is that the problem is biconvex in @xmath13 and @xmath0 respectively , hence minimizing @xmath24 or @xmath25 are convex . on the other hand ,",
    "sgd is typically faster to converge and it also affords much better cache locality properties . instead of accessing e.g.  all reviews for a given user ( or all reviews for a given movie ) at once , we only need to read the appropriate tuples . in sgd each time we update a randomly chosen rating record by : @xmath26 one problem of sgd is that trivially parallelizing the procedure requires memory locking and synchronization for each rating , which could significantly hamper the performance .",
    "@xcite shows that a lock - free scheme can achieve nearly optimal solution when the data access is sparse .",
    "we build on this _ statistical _ property to obtain a _ fast system _ which is suitable for differential privacy .",
    "differential privacy ( dp )  @xcite aims to provide means to cryptographically protect personal information in the database , while allowing aggregate - level information to be accurately extracted . in our context",
    "this means that we protect user - specific sensitive information while using aggregate information to benefit all users .",
    "assume the actions of a statistical database are modeled via a randomized algorithm @xmath27 .",
    "let the space of data be @xmath28 and data sets @xmath29 .",
    "define @xmath30 to be the edit distance or hamming distance between data set @xmath31 and @xmath32 , for instance if @xmath31 and @xmath32 are the same except one data point then we have @xmath33 .",
    "[ def : diffp ] we call a randomized algorithm @xmath27 @xmath34-differentially private if for all measurable sets @xmath35 and for all @xmath36 such that the hamming distance @xmath37 , @xmath38 if @xmath39 we say that @xmath27 is @xmath40-differential private .",
    "the definition states that if we arbitrarily replace any individual data point in a database , the output of the algorithm does nt change much .",
    "the parameter @xmath40 in the definition controls the maximum amount of information gain about an individual person in the database given the output of the algorithm .",
    "when @xmath40 is small , it prevents any forms of linkage attack to individual data record ( e.g. , linkage of netflix data to imdb data @xcite ) .",
    "we refer readers to  @xcite for detailed interpretations of the differential privacy in statistical testing , bayesian inference and information theory .",
    "an interesting side - effect of this definition in the context of collaborative filtering is that it also limits the influence of so - called whales , i.e.  of users who submit extremely large numbers of reviews .",
    "their influence is also curtailed , at least under the assumption of an equal level of differential privacy per user . in other words ,",
    "differential privacy confers robustness for collaborative filtering .",
    "@xcite show that posterior sampling with bounded log - likelihood is essentially exponential mechanism @xcite therefore protecting differential privacy for free ( similar observations were made independently in @xcite ) .",
    "@xcite also suggests a recent line of works  @xcite that use stochastic gradient descent for hybrid monte carlo sampling essentially preserve differential privacy with the same algorithmic procedure .",
    "the consequence for our application is very interesting : if we trust that the mcmc sampler has converged , i.e.  if we get a sample that is approximately drawn from the posterior distribution , then we can use one sample as the private release . if not , we can calibrate the mcmc procedure itself to provide differential privacy ( typically at the cost of getting a much poorer solution ) .      a key difference between generic numerical linear algebra ,",
    "as commonly used e.g.  for deep networks or generalized linear models , and the methods used for recommender systems is the fact that the access properties regarding users and items are highly nonuniform .",
    "this is a significant advantage , since it allows us to exploit the caching hierarchy of modern cpus to benefit from higher bandwidth than what disks or main memory access would permit .",
    ".[tb : benchmark ] performance ( single threaded ) on a macbook pro ( 2011 ) using an intel core i7 operating at 2.0 ghz and 160mt / s transfer rate and 2 memory banks .",
    "the spread in l1 and l3 bandwidth is due to different packet sizes . [",
    "cols=\"<,>,>,>\",options=\"header \" , ]     we show the cache efficiency of c - sgd and graphchi in this section .",
    "our data access pattern can accelerate the hardward cache prefetching . in the meanwhile we also use software prefetching strategies to prefetch movie factors in advance . but",
    "software prefetching is usually dangerous in practice while implementing in practice because we need to know the prefetching stride in advance .",
    "that is when to prefetch those movie factors . in our experiments we set prefetching stride to 2 empirically .",
    "we set the experiments as follows . in each gradient update",
    "step given @xmath3 , once the parameters e.g. @xmath11 and @xmath12 in ( [ eq : sgd ] ) been read they will stay in cache for a while until they be flushed away by new parameters .",
    "what we really care about in this section is if the first time each parameter be read by cpu is already staying in cache or not .",
    "if it is not in cache then there will be a cache miss and will push cpu to idle . after that the succeeding updates ( the specific updates depend on the algorithms e.g. sgd or sgld ) for @xmath11 and @xmath12 will run on cache level .",
    "we use cachegrind  @xcite as a cache profiler and analyze cache miss for this purpose . the result in table  [ tb : cache ]",
    "shows that our algorithm is quite cache friendly when compared with graphchi on all dimensions .",
    "this is likely due to the way graphchi ingests data : it traverses one data and item block at a time . as a result",
    "it has a less efficient portfolio of access frequency and it needs to fetch data from memory more frequently .",
    "we believe this to be both the root cause of decreased computational efficiency and slower convergence in the code .",
    "we now investigate the influence of privacy loss on accuracy .",
    "as discussed previously , a small rescaling factor @xmath41 can help us to get a nice bound on the loss function .",
    "for private collaborative filtering purposes , we first trim the training data by setting each user s maximum allowable number of ratings @xmath42 and @xmath43 for the netflix competition dataset and yahoo music data respectively . we set @xmath44 and weight of each user as @xmath45 where @xmath46 is set to 1 .",
    "according to different trimming strength we have @xmath47 and @xmath48 for netflix data and yahoo data respectively .",
    "note that a maximum allowable rating from @xmath49 to @xmath50 is quite reasonable , since in practice most users rate quite a bit fewer than @xmath50 movies ( due to the power law nature of the rating distribution ) .",
    "moreover , for users who have more than @xmath50 ratings , we actually can get a quite a good approximation of their profiles by only using a reasonable size of random samples of these ratings .",
    "as such we get a dataset with 33 m ratings for netflix and 100 m ratings for yahoo music data .",
    "we study the prediction accuracy , i.e. the utility of our private method by varying the differential privacy budget @xmath40 for fixed model dimensionality @xmath51 .",
    "the parameters of the experiment are set as follows . for netflix data , we set @xmath52 , @xmath53 , @xmath54 , @xmath55 . for yahoo data , we set @xmath56 , and @xmath57 , @xmath58 , @xmath59 .",
    "in addition , because we are sampling p@xmath60 we fix regularizer parameters @xmath61 which are estimated by a non - private sgld in this section .",
    "while we are sampling @xmath62 jointly , we essentially only need to release @xmath0 .",
    "users can then apply their own data to get the full model and have a local recommender system : @xmath63 the local predictions , i.e.  in our context the utility of differentially private matrix factorization method , along the different privacy loss @xmath40 are shown in figure  [ fig : rmse_vs_privacy ] .    more specifically , the model ( [ eq : semiprivate ] ) is a _ two - stage _ procedure which first takes the differentially private _ item vectors _ and then use the latter to obtain locally non - private user parameter estimates .",
    "this is perfectly admissible since users have no expectation of privacy with regard to their own ratings .",
    "on netflix ( top ) and yahoo ( bottom ) .",
    "a modest decrease in accuracy affords a useful gain in privacy .",
    "[ fig : rmse_vs_privacy],title=\"fig : \" ]   on netflix ( top ) and yahoo ( bottom ) .",
    "a modest decrease in accuracy affords a useful gain in privacy .",
    "[ fig : rmse_vs_privacy],title=\"fig : \" ]      interpreting the privacy guarantees can be subtle . a privacy loss of @xmath64 as in figure  [ fig : rmse_vs_privacy ] may seem completely meaningless by definition  [ def : diffp ] and the corresponding results in @xcite may appear much better .",
    "we first address the comparison to @xcite .",
    "it is important to point out that our privacy loss @xmath40 is stated in terms of user level privacy while the results in @xcite are stated in terms of rating level privacy , which offers exponentially weaker protection .",
    "@xmath40-user differential privacy translates into @xmath65-rating differential privacy .",
    "since @xmath43 in our case , our results suggest that we almost lose no accuracy at all while preserving rating differential privacy with @xmath66 .",
    "this matches ( and slightly improves ) @xcite s carefully engineered system .    on the other hand",
    ", we note that the plain privacy loss can be a very deceiving measure of its practical level of protection .",
    "definition  [ def : diffp ] protects privacy of an arbitrary user , who can be a malicious spammer that rates every movie in a completely opposite fashion as what the learned model would predict .",
    "this is a truly paranoid requirement , and arguably not the right one , since we probably should not protect these malicious users to begin with .",
    "for an average user , the personalized privacy ( definition  [ def : dppersonal ] ) guarantee can be much stronger , as the posterior distribution concentrates around models that predict reasonably well for such users . as a result ,",
    "the log - likelihood associated with these users will be bounded by a much smaller number with high probability . in the example shown in figure  [ fig : rmse_vs_privacy ] , a typical user s personal privacy loss is about @xmath67 , which helps to reduce the essential privacy loss to a meaningful range .",
    "in this paper we described an algorithm for efficient collaborative filtering that is compatible with differential privacy .",
    "in particular , we showed that it is possible to accomplish all three goals : accuracy , speed and privacy without any significant sacrifice on either end .",
    "moreover , we introduced the notion of _ personalized _ differential privacy .",
    "that is , we defined ( and proved ) the notion of obtaining estimates that respect different degrees of privacy , as required by individual users .",
    "we believe that this notion is highly relevant in today s information economy where the expectation of privacy may be tempered by , e.g.  the cost of the service , the quality of the hardware ( cheap netbooks deployed with windows 8.1 with bing ) , and the extent to which we want to incorporate the opinions of users .",
    "our implementation takes advantage of the caching properties of modern microprocessors . by careful latency hiding",
    "we are able to obtain near peak performance .",
    "in particular , our implementation is approximately 3 times as fast as graphchi , the next - fastest recommender system . in sum , this is a strong endorsement of stochastic gradient langevin dynamics to obtain differentially private estimates in recommender systems while still preserving good utility .",
    "* acknowledgments : * parts of this work were supported by a grant of adobe research .",
    "z.  liu was supported by creative program of ministry of education ( irt13035 ) ; foundation for innovative research groups of nnsf of china ( 61221063 ) ; nsf of china ( 91118005 , 91218301 ) ; pillar program of nst ( 2012bah16f02 ) .",
    "wang was supported by nsf award bcs-0941518 to cmu statistics and singapore national research foundation under its international research centre @ singapore funding initiative and administered by the idm programme office .",
    "the @xmath40-dp claim follows by choosing the utility function to be the @xmath68 and apply the exponential mechanism @xcite which protects @xmath40-dp by output @xmath62 with probability proportional to @xmath69 where he sensitivity of function @xmath70 be defined as @xmath71 all we need to do is to work out the sensitivity for @xmath72 here . by the constraint in @xmath73 and @xmath74 , we know @xmath75 .",
    "since one user contributes only one row to the data the trimming / reweighting procedure ensures that for any @xmath73 and any user , the sensitivity of @xmath72 obeys @xmath76 as specified in the algorithm .",
    "the @xmath77dp claim is simple ( given in proposition 3 of @xcite ) and we omit here .",
    "lastly , we note that the `` retry if fail '' procedure will always sample from the the correct distribution of @xmath78 conditioned on @xmath62 satisfying our constraint that @xmath79 is bounded , and it does not affect the relative probability ratio of any measurable event in the support of this conditional distribution .    for generality , we assume the parameter vector is @xmath80 and all regularizers is capture in prior @xmath81 . the posterior distribution @xmath82 .",
    "for any @xmath83 , if we add ( removing has the same proof ) a particular user @xmath84 whose log - likelihood is uniformly bounded by @xmath85 .",
    "the probability ratio can be factorized into @xmath86      in algorithm  [ alg : dpmf ] , denote @xmath89 .",
    "we are sampling from a distribution proportional to @xmath90 .",
    "this is equivalent to taking the above posterior @xmath91 to have the log - likelihood of user @xmath84 bounded by @xmath92 , therefore the algorithm obeys @xmath93 personalized differential privacy for user @xmath84 .",
    "take @xmath85 to be any customized subset of @xmath94 adjustied using @xmath95 we get the expression as claimed .",
    "s.  ahn , a.  korattikara , and m.  welling .",
    "bayesian posterior sampling via stochastic gradient fisher scoring . in",
    "_ proceedings of the 29th international conference on machine learning ( icml-12 ) _ , pages 15911598 , 2012 .",
    "b.  mobasher , r.  burke , r.  bhaumik , and c.  williams . toward trustworthy recommender systems : an analysis of attack models and algorithm robustness .",
    "_ acm transactions on internet technology ( toit ) _ , 70 ( 4):0 23 , 2007 .              i.  sato and h.  nakagawa . approximation analysis of stochastic gradient langevin dynamics by using fokker - planck equation and ito process . in _ proceedings of the 31st international conference on machine learning ( icml-14 ) _ , pages 982990 , 2014 ."
  ],
  "abstract_text": [
    "<S> differentially private collaborative filtering is a challenging task , both in terms of accuracy and speed . </S>",
    "<S> we present a simple algorithm that is provably differentially private , while offering good performance , using a novel connection of differential privacy to bayesian posterior sampling via stochastic gradient langevin dynamics . due to its simplicity </S>",
    "<S> the algorithm lends itself to efficient implementation . by careful systems design and by exploiting the power law behavior of the data </S>",
    "<S> to maximize cpu cache bandwidth we are able to generate 1024 dimensional models at a rate of 8.5 million recommendations per second on a single pc . </S>"
  ]
}