{
  "article_text": [
    "crowdsourcing is a term often adopted to identify distributed systems that can be used for the solution of a wide range of complex problems by integrating a large number of human and/or computer efforts @xcite .",
    "the key elements of a crowdsourcing system are : i ) the availability of a large pool of individuals or machines ( called _ workers _ in crowdsourcing jargon ) that can offer their ( small ) contribution to the problem solution by executing a _ task _ ; ii ) an algorithm for the partition of the problem at hand into tasks ; iii ) an algorithm for the selection of workers and the distribution of tasks to the selected workers ; iv ) an algorithm for the combination of workers _ answers _ into the final _ solution _ of the problem , v ) a _ requester _",
    "employer ) , who uses the three algorithms above to structure his problem into a set of tasks , assign tasks to selected workers , and combine workers answers to obtain the problem solution .",
    "since on the one hand answers may be subjective , and on the other task execution is typically tedious and the economic reward for workers is pretty small ( if any ) , workers are not 100% reliable , in the sense that they may provide incorrect answers . in addition",
    ", workers may be biased for different reasons .",
    "hence , the same task is normally assigned in parallel ( replicated ) to several workers , and then a decision rule is applied to their answers . a natural trade - off between the accuracy of the decision and cost arises",
    "; indeed , by increasing the replication factor of every task , we can increase the accuracy of the final decision about the task solution , but we necessarily incur higher costs ( or , for a given fixed cost , we obtain a lower task throughput ) .",
    "a number of sophisticated software platforms have been recently developed for the exploitation of the crowdsourcing paradigm on a scale that could not be possible without a networked infrastructure .",
    "some relevant application scenarios taken from the domains of recommendation and evaluation , are the development of hotel and restaurant rating systems , the implementation of recommendation systems for movies , the management of the review process of large conferences .    given the scale of the current applications of crowdsourcing systems , the relevance of high - performance and scalable algorithms is enormous ( in some cases , it can have huge economical impact ) .",
    "an abstract view of the examples above reveals that they are very similar in nature : their essence is determining the best , or the @xmath0 best , elements in a group of objects in which each object has an intrinsic ( unknown ) quality metric .",
    "this is a very fundamental algorithmic problem , which has already been investigated by several researchers in the context of crowdsourcing .",
    "most of the previous literature considers workers only able to directly compare items in groups comprising two or more objects , expressing a preference . the proposed algorithms consist of comparisons arranged in rounds , forming a _ tournament _ , and the investigation concentrates on the trade - offs that appear in this context ( e.g. , cost , accuracy , latency ) @xcite . in this paper , instead , we assume that workers are able to evaluate ( in absolute terms ) the quality of an object , providing a noisy score .",
    "a similar path was followed in the recent ( still unpublished ) work by khan and garcia molina @xcite , which studies algorithms to find the maximum element in a group of objects , and discusses approaches based on comparisons , on ratings , as well as on a mix of the two possibilities .",
    "the main difference between their work and this one is in the quantization of workers scores .",
    "indeed , @xcite assumes that workers answers are coarsely quantized over few levels ( typically three or five ) , and this makes objects with similar quality indistinguishable , so that direct comparisons and tournaments become necessary to break ties .    on the contrary , we first work with unquantized workers answers , so as to maximize the amount of information provided by the workers .",
    "we show that in this context the scoring approach is superior ( in some cases by far ) to the approach based on direct comparisons .",
    "this should not be surprising , since quantization and comparisons entail a partial loss of information .",
    "then , we show that by adopting smart quantization techniques with a sufficiently large number of quantization levels ( in the order of few tens ) we can closely approach the performance of systems operating on unquantized scores .",
    "another significant difference with respect to @xcite is in the scope of the works .",
    "we aim at the definition of smart multiround _ adaptive _ algorithms that effectively distribute the resources ( workers ) among the objects , at every round , making online decisions whether to distribute further resources , based on past collected answers .",
    "the paper @xcite , instead , focuses on non - adaptive algorithms distributing resources to objects according to a fixed , pre - established scheme .",
    "our main findings are :    * algorithms operating on unquantized scores are intrinsically more efficient than algorithms based on direct comparisons of objects ; * resources ( workers ) must be allocated in a careful manner , concentrating more resources on the top - quality objects ; this can be done only if algorithms are adaptive and , at every round , exploit currently available information about objects quality to decide how to distribute further resources ; * if unquantized scores are available , tournament - based approaches , that partition objects into subgroups and move winners in each sub - group to the next round , may become extremely inefficient ; * more practical quantized schemes perform very close to their ideal unquantized counterparts , provided that a reasonable number of quantization levels is properly assigned to workers answers .",
    "the rest of this paper is organized as follows .",
    "section [ sec : sa ] presents our system assumptions .",
    "section [ sec : ad ] describes the main characteristics of the class of algorithms that is investigated in this paper , and section [ sec : dp ] discusses the parameters for the algorithm design .",
    "section [ sec : sco - vs - t ] shows that , with our system assumptions , the approach based on quantitative evaluations of object qualities is superior to the one based on comparisons between objects .",
    "section [ sec : quanti ] faces the problem of effective answer quantization .",
    "section [ sec : results ] presents and discusses numerical results for the class of algorithms considered in this paper , comparing them to previous proposals .",
    "section [ sec : dc ] briefly comments on the computational complexity of the most promising algorithm according to the numerical results of section [ sec : results ] , and discusses parameter setting .",
    "finally , section [ sec : conclusions ] contains our concluding remarks and presents the next steps of our work .",
    "we consider a set of @xmath1 objects , each of which is endowed with an intrinsic quality , whose evaluation requires human capabilities .",
    "let @xmath2 $ ] be the vector of all quality values , which are supposed to be instances of the i.i.d .",
    "random variables @xmath3 $ ] having common pdf @xmath4 over @xmath5 .",
    "our goal is to use a crowdsourcing approach to identify the `` best '' object , that is , the object with the largest quality value , denoted by @xmath6 , where @xmath7    the crowd is composed of statistically identical workers , whose evaluation of the object quality is prone to errors .",
    "we assume , for the moment , that workers provide absolute unquantized estimates ( scores ) of the intrinsic quality of individual objects , and we model as additive gaussian noise the error made in such evaluation process .",
    "more precisely , if the @xmath8-th object is sent for evaluation , say , for the @xmath9-th time , to a worker in the crowd , the worker s answer will be given by : @xmath10 where @xmath11 , @xmath12 , @xmath13 , are i.i.d .",
    "gaussian random variables with zero mean and variance @xmath14 .",
    "errors may be caused either by subjective factors influencing the assessment of the intrinsic object quality , or by the fact that workers avoid devoting the effort that is needed for an accurate assessment .",
    "observe that our model encompasses the case in which different workers may suffer from possibly different biases .",
    "however we make the conservative assumption that workers bias can not be estimated .",
    "this assumption is justified by the fact that , since evaluations of objects are usually carried out by many workers , each one performing few evaluations , estimating the worker bias is very challenging in practical crowdsourcing systems .    observe that our model differs from @xcite because we assume that workers can provide absolute estimates ( scores ) of the intrinsic quality of objects , while @xcite assume workers to be only able to perform noisy comparisons between groups of objects .",
    "we will show that , whenever applicable , the scoring approach is significantly more favorable , in the sense that algorithms dealing with absolute estimates of object quality achieve significantly better cost / performance trade - offs .",
    "we also wish to remark that the gaussian model of worker error is in good agreement with thurstone s law of comparative judgment  @xcite , according to which comparisons are based on latent quality estimations , whose distribution is gaussian around the true quality value . in the context of crowdsourcing ,",
    "the same model has recently been employed also in  @xcite .",
    "we investigate a class of adaptive algorithms in which objects are sent out for evaluation through several _ rounds_. in each round , each object receives a given number of evaluations by crowd workers ( possibly zero , for some objects ) .",
    "then , on the basis of all collected workers answers , the algorithms take decisions about the opportunity of requesting extra evaluations for a subset of the objects in a further round .",
    "if no extra evaluations are carried out , the algorithms terminate and a winner is identified",
    ".    more formally , denote with @xmath15 the number of evaluations the @xmath8-th object has received in round @xmath16 and with @xmath17 the total number of evaluations received by object @xmath8 up to ( and including ) round @xmath16 .",
    "we define @xmath18 $ ] , @xmath19 as the vector$ ] , as @xmath20 $ ] , @xmath21 of random variables representing the answers about object @xmath8 collected up to round @xmath16 , and @xmath22 $ ] .    at the beginning of round @xmath16 , with @xmath23 , a fitness index",
    "@xmath24 quantifies the current chances for object @xmath8 to be the winner at the end of the algorithm , as a result of processing of previous evaluations .",
    "let the vector of all fitness indices be @xmath25\\,.\\ ] ] for @xmath26 , i.e. , when no evaluations are available yet , fitness indices are equal for all objects , since the object qualities are assumed to be instances of i.i.d random variables .    in round @xmath16 , some of the objects may have a fitness index equal to @xmath27 .",
    "these objects are not assigned any further evaluation and are out of the contest .",
    "define the contestant set @xmath28 at round @xmath16 as the set of objects for which the fitness index is currently larger than @xmath27 , i.e. , @xmath29 we remark that , according to our algorithms , the contestant set at round @xmath30 is always a ( possibly improper ) subset of the contestant set at round @xmath16 , i.e. , @xmath31 .    on the basis of @xmath32 and , possibly , of the total number of past assignments @xmath33 , the algorithm decides , according to a termination rule , whether to stop or to go on with the rounds . if rounds are stopped , the object with the largest fitness index is declared the winner .",
    "otherwise , a budget of new worker evaluations is assigned to objects .",
    "such budget is dimensioned as @xmath34 = { { \\cal a}}({\\boldsymbol{\\phi}}^{(\\ell-1 ) } , m^{(\\ell-1)})\\ ] ] where @xmath35 is the @xmath36 allocation function .",
    "we assume function @xmath35 to be increasing with respect to the object quality , i.e. , our algorithm tends to allocate more workers to objects with top estimated quality , as formally stated below .    if @xmath37 , then @xmath38 , with @xmath39 if @xmath40 .    after determining the number of suitable evaluations ,",
    "the objects are sent to crowd workers and answers are collected .",
    "then , such answers , together with the previous ones , are used to update the fitness vector for next round , @xmath41 ( and , consequently , @xmath42 ) .",
    "several algorithms can be devised in accordance to the previous scheme , depending on how we select the different metrics and parameters , such as @xmath35 , the fitness index , and the termination rule .",
    "at round @xmath16 of the algorithm , on the basis of the collected answers we can compute an a - posteriori distribution @xmath43 for the quality @xmath44 , where @xmath45 represents a realization of the random vector @xmath46 ( assumed unquantized for the moment ) .",
    "thanks to bayes rule , such distribution can be written as : @xmath47 where @xmath48 is such that @xmath49 . when the a - priori pdf @xmath4 is gaussian with mean @xmath50 and variance @xmath51 , by substituting such prior into the above expression , we easily obtain that @xmath52 is also gaussian , namely @xmath53 where @xmath54 and @xmath55 .",
    "this is a consequence of the fact that the gaussian distribution is self - conjugate with respect to the gaussian likelihood function .",
    "it is also worth noting that @xmath56 is the minimum - mean - square - error estimate of @xmath57 given that @xmath45 is the realization of @xmath46 .",
    "observe that   also holds for unknown prior distribution .",
    "in such a case we set @xmath58 , i.e. , @xmath59 . moreover we remark that   can also be employed to obtain a simplified approximate a - posteriori distribution in the case of non - gaussian priors with variance @xmath51 .      in order to properly choose the metrics of the crowdsourcing algorithm , it is important to identify the performance parameters we may want to optimize .",
    "several options can be devised . in the following",
    ", we will omit the round index @xmath16 for ease of notation .",
    "consider an answer realization @xmath60 $ ] and define the corresponding estimate @xmath61 of @xmath62 , in the following simply denoted by @xmath63 .    *",
    "a first possible performance parameter ( to be minimized ) is the _ distortion _",
    "@xmath64 , which is averaged with respect to the current a - posteriori distribution of @xmath65 given @xmath66 .",
    "unfortunately the computation of the distortion is in general too complex , even for moderate values of @xmath1 . *",
    "a generalization of the previous metric is the _",
    "order-@xmath0 distortion _",
    "@xmath67 , where @xmath68 .",
    "* a different performance parameter to be minimized can be the _ error probability _ @xmath69 .",
    "with such a choice , a maximum - a - posteriori ( map ) rule turns out to be optimal .",
    "precisely , let @xmath70 be the probability of @xmath8 to be the top - quality object , given the answers @xmath71 , for @xmath72 .",
    "we can compute the value of @xmath73 as follows .",
    "@xmath74 where @xmath75 is the a - posteriori cdf of @xmath44 given @xmath76 .",
    "it is easy to see that @xmath77 is minimized when @xmath78 . in the case of gaussian or unknown priors , holds with @xmath79\\ ] ] + since the evaluation of @xmath80 , for @xmath81 , entails a computational complexity growing linearly with @xmath1 , we propose the following approximation : @xmath82 where @xmath83 corresponds to the object with maximum current estimated quality except @xmath8 . in practice , restricts the comparison to only two objects , the running candidate @xmath8 and its strongest competitor @xmath84 , and uses the current probability @xmath85 that object @xmath8 is better than @xmath84 as an approximation for @xmath80 .    in this work , because of complexity considerations , we choose the _ error probability _ as the performance parameter .      as in the case of performance parameters , different choices for fitness indices",
    "are possible .    *",
    "* exact max probability : * with this choice , we identify the fitness index of objects with their estimated probability of being the top - quality object : @xmath86 * * approximate max probability : * in this case : @xmath87 * * exact max probability with elimination : * as stated in the previous section , the contestant set , @xmath88 , initially set to @xmath89 , may be shortened along rounds .",
    "we have considered a strategy where , at each round , those objects whose @xmath90 is lower than a threshold @xmath91 are eliminated . for this strategy ,",
    "the fitness index is given by : @xmath92 * * approximate max probability with elimination : * analogously , we can consider a strategy where objects are eliminated if @xmath93 falls below a threshold @xmath91 .",
    "the corresponding fitness index is given by   where @xmath90 is replaced by @xmath93 .",
    "all these choices of fitness index have been tested numerically .      as stated in previous sections ,",
    "given the current fitness index , the allocation function @xmath35 determines the number of further evaluations needed by each object in round @xmath16 .",
    "furthermore , @xmath35 is a non - decreasing function of the fitness index ( property 1 ) .    for simplicity , we are particularly interested in the case where @xmath35 returns values in @xmath94 , i.e. , where the number of workers assigned to every object within a round is either 0 or 1 . in such a case , in round @xmath16 , the @xmath95 top - quality objects will receive an extra worker , while all other objects will not receive any extra worker .",
    "two possible choices are considered in this paper , according to whether the total evaluation budget is either fixed or not .    *",
    "* unbounded budget : * if there is no maximum number of requested evaluations , @xmath96 only depends on the fitness index , in the following way : @xmath97 where @xmath98 is a suitable accuracy threshold , generally different from @xmath91 defined in the previous subsection . however , for consistency , we need to have @xmath99 . *",
    "* bounded budget : * if at most @xmath100 evaluations can be requested in all rounds , then , in round @xmath16 , @xmath35 must take into account also the number of evaluations already requested , given by @xmath101 .",
    "let again @xmath98 be the threshold against which the fitness index is compared , like in the unbounded - budget case , and let @xmath102 be the number of objects that currently pass the threshold . if @xmath103 , then the allocation of new evaluations is the same as for unbounded budget , otherwise only the @xmath104 objects with the largest fitness index are allocated a further evaluation .",
    "based on the choice of the fitness index and the allocation function @xmath96 , the algorithm termination rule may be different .",
    "* * maximum budget achieved : * when a maximum of @xmath100 evaluations is allowed , reaching this maximum budget will cause rounds to stop . *",
    "* singleton contestant set : * for algorithms that eliminate objects when their fitness is lower than @xmath91 , the natural termination condition is when the contestant set only contains a single object , i.e. , @xmath105 . *",
    "* accuracy : * if only a single object passes the accuracy threshold @xmath98 , while all other objects do not , meaning that there is already a strong candidate winner , the algorithm may terminate rounds .    when applicable , the termination rule can be the combination of all three rules above , i.e. , the algorithm may terminate whenever one of the three becomes true .",
    "in this section we want to show that , whenever workers are able to provide ( noisy ) quantitative estimates of the object quality , algorithms exploiting those estimates are in general more effective than algorithms just resorting to direct comparisons among subsets of objects .",
    "we start by considering a toy case in which only two objects are given , with qualities @xmath106 and @xmath107 , and we compare two algorithms requiring the same amount of human effort . the first algorithm resorts to outcomes of direct comparisons between the objects performed by the crowd workers , while the second exploits quantitative estimates of the object qualities provided by the same ( or other ) crowd workers .",
    "observe that an algorithm exploiting the outcomes of direct comparisons between objects , and employing a fixed budget of @xmath108 workers for each comparison , necessarily works as follows .",
    "each of the @xmath108 enrolled workers returns a binary variable , indicating which object she prefers .",
    "once all answers , collectively denoted @xmath109 , are obtained , a majority rule is applied by the algorithm to choose the `` best '' object .",
    "according to our model , each worker prefers object @xmath110 , if she estimates that the quality of object @xmath110 exceeds the quality of object @xmath111 and vice versa .",
    "thus , a worker chooses object 1 , i.e. , returns an incorrect answer , with probability @xmath112 , while she chooses object @xmath111 , thus returning a correct answer , with probability @xmath113 .",
    "processing the @xmath108 collected answers ( to simplify the analysis , we assume an odd value for @xmath108 ) , the algorithm based on comparisons erroneously selects object @xmath110 whenever the number of answers equal to 1 exceeds @xmath114 , i.e. : @xmath115 where @xmath116 denotes a binomial distribution of parameters @xmath108 and @xmath117 .",
    "instead , an algorithm that has access to the quantitative quality estimates @xmath71 provided by the @xmath108 crowd workers , naturally selects the object with the largest estimated quality @xmath118 . in this case",
    "the error probability is given by : @xmath119 not surprisingly , @xmath120 , as shown in fig .",
    "[ fig : figure_comp ] for @xmath121 . indeed , from an information - theoretic perspective , the answers @xmath71 provide much more information on the quality of the two objects than the comparisons @xmath109 .",
    "this implies that any algorithm resorting to direct comparisons does not fully exploit the information on object quality that crowd workers are able to provide and , as a consequence , turns out to be suboptimal .    .",
    "]    we now analytically compare @xmath122 and @xmath123 to better quantify the advantages of the approach exploiting quantitative estimates of object quality . to this end , we approximate the binomial distribution @xmath124 with a gaussian distribution @xmath125 . by the de  moivre - laplace theorem ,",
    "such approximation is asymptotically tight for large @xmath108 . following this approach ,",
    "@xmath122 can be approximated as : @xmath126 to further simplify the expression of @xmath122 , we consider the limit for @xmath127 , in which case @xmath128 , and thus @xmath129 the performance penalty entailed by the approach resorting to direct comparisons of objects is expressed by the factor @xmath130 appearing in the argument of the above erfc function .",
    "this factor has a strong impact on the algorithm performance , since , for @xmath131 sufficiently small , as @xmath108 increases , the ratio @xmath132 tends exponentially fast to zero .",
    "now , consider a case in which @xmath133 objects are to be evaluated .",
    "for example , let us focus on the case @xmath134 . to declare a winner through direct comparisons of objects , we need to compare at least three pairs of objects .",
    "a natural solution is to arrange a  _ tournament _ in which the four objects are first partitioned into two pairs , so that the objects in each pair can be compared in parallel ( first round ) .",
    "the two winners of the first round are then compared to identify the globally best object ( second round ) .",
    "observe that the outcomes @xmath109 returned by crowd workers within the first round can not be exploited in any way at the second round .",
    "in other words , at the end of the first round , no useful information is available to rank the two first - round winners . if , instead , the workers return their own quantitative evaluations @xmath71 of the object quality , the evaluations carried out within the first round provide useful information also for the second round .    in light of this discussion",
    ", it should not be surprising that the performance gain of algorithms exploiting workers quantitative quality evaluations increases as the number of objects increases .",
    "up to now , we have assumed that workers return unquantized ( i.e. , infinite - precision ) noisy evaluations of object qualities .",
    "this assumption is unpractical in many scenarios , where instead workers evaluations must belong to a finite alphabet , i.e. , they are quantized . in this section ,",
    "we discuss how quantization can be effectively implemented in order to approach the performance of the proposed unquantized algorithm .    from a system point - of - view ,",
    "the key parameter of a quantizer is the cardinality @xmath135 of the alphabet on which answers should be encoded , i.e. , the number of levels of the quantizer . given @xmath135 , a specific quantization rule is characterized by an @xmath136-dimensional vector of thresholds @xmath137 $ ] with @xmath138 and an @xmath135-dimensional vector @xmath139 $ ] of representative values , satisfying @xmath140 .",
    "if workers answers are quantized , then the @xmath9-th answer to the evaluation of object @xmath8 can be modelled as @xmath141 where @xmath142 whenever @xmath143 $ ] . ; every worker is just requested to express a satisfaction level in @xmath144 , which is obtained by comparing her own unquantized evaluation with thresholds @xmath145 . therefore , our model perfectly matches the assumptions of @xcite . ]",
    "notice that we consider here a _ fixed _ ,",
    "non - adaptive quantizer , that is defined once and for all at the beginning , before any evaluation takes place .    in our context , the problem of optimal quantization can be formulated in terms of the minimization of some distortion index between unquantized answers and their quantized version .",
    "the mean square error @xmath146 $ ] represents a natural candidate for such distortion index , also because the seminal work by lloyd  @xcite provides an efficient iterative algorithm for the design of a quantizer that minimizes the mean square error .",
    "now , the nontrivial question to be answered is : _ which are the answers whose distortion after quantization should be minimized ? _ we list in the following a few possible answers to such question .    * since we have @xmath1 objects whose quality values are i.i.d .",
    ", each with pdf @xmath4 , we may want to minimize the distortion on the answer relative to the generic object .",
    "with such a choice , the distribution with respect to which the mean square error is to be computed is @xmath147 , where @xmath148 is the convolution product and @xmath149 is the distribution of the workers evaluation error . * from a different perspective , since we are searching for the top - quality object , we should minimize the distortion on the answers associated to that object only , i.e. , averaging with respect to @xmath150 } } * f_n$ ] , @xmath151 } } $ ] being the a - priori distribution of the largest quality value . * taking an approach which is in between the previous two , and considering that our target is to discriminate the best object from the others , we could aim at minimizing a weighted combination of the distortions relative to the ordered quality values .",
    "this goal can be achieved by using as the answer distribution @xmath152 } } * f_n$ ] , where @xmath153}}$ ] is the a - priori distribution for the @xmath8-th best object , and @xmath154 is its associated weight , satisfying @xmath155 .",
    "we will see in the next section that the impact on algorithm performance of the different possible choices for @xmath156 is pretty significant .",
    "therefore , the quantizer must be carefully designed . at last , observe that @xmath157 and @xmath158 can be obtained as particular cases of @xmath159 by setting @xmath160 for all @xmath8 in the first case , and @xmath161 , @xmath162 for @xmath163 in the second case .",
    "in this section , we compare the performance of several algorithms that are obtained by making different choices for the _ fitness index _ , the _ allocation function _",
    ", the _ termination rule _ , and the _ quantizer_.      in particular , we first focus on algorithms with unquantized answers and unbounded budget , and define :    * the greedy - keep - exact ( gke ) algorithm , employing the _ exact max probability _ as fitness index , _ unbounded budget _ as allocation function , and the _ accuracy termination rule _ ; * the greedy - keep - approximate ( gka ) algorithm , employing the _ approximate max probability _ as fitness index , the _ unbounded budget _ as allocation function , and the _ accuracy termination rule _ ; * the greedy - remove - approximate ( gra ) algorithm , employing the _ approximate max probability with eliminations _ as fitness index , the _ unbounded budget _ as allocation function , and the _ singleton contestant set _ as termination rule .    to reduce the space of parameters ,",
    "we have always fixed @xmath164 .",
    "for the sake of comparison , the following algorithms have been also considered .",
    "* we have superimposed a classical tournament scheme to our previously described algorithms , obtaining a family of _ tournament_-@xmath165 ( t-@xmath165 ) algorithms .",
    "specifically , in t-@xmath165 algorithms , the @xmath1 objects to be evaluated are first randomly partitioned into subgroups of size @xmath165 ( for simplicity , we neglect rounding problems ) .",
    "the gka algorithm is then run to elect a winner for each of the object groups .",
    "only winners have access to the second stage , in which again objects are partitioned into subgroups of size @xmath165 and winners are elected for each subgroup .",
    "the process is iterated until only one winner is left .",
    "we remark that our tournament schemes effectively exploit , at every stage , full information about the evaluations of competing objects collected at earlier stages . * a non - adaptive algorithm , which assigns to every object a fixed number of workers , referred to as uniform algorithm ( ua ) . * as a reference , we have also considered an unfeasible genie - aided ( ga ) algorithm , which has access to the identity of the two best competing objects , after a first initial round of evaluations , where every object receives one score .",
    "therefore , in the following rounds , the ga algorithm equally distributes workers only to the top two objects until the _ accuracy termination rule _ is met .",
    "observe that , by construction , the performance of the ga algorithm constitutes an upper bound for every feasible algorithm , since , as discussed in section  [ sec : sco - vs - t ] , it implements the optimal policy to find the best between two objects .",
    "we start considering a simple scenario with @xmath166 objects whose qualities @xmath57 are equally spaced in the interval @xmath167 $ ] , so that the smallest difference between quality values is @xmath168 .",
    "the standard deviation of the worker evaluation error has been set to @xmath169 .     vs @xmath170 ) of different algorithms with unquantized answers and unbounded budget for @xmath166 equally spaced objects . ]",
    "[ fig1 ] shows the results obtained with the different proposed algorithms , plotted in terms of error probability @xmath171 versus the average number of performed evaluations per object @xmath170 .",
    "we highlight that the different trade - offs between @xmath171 and @xmath170 correspond to different values of the threshold @xmath172 , as explicitly shown in fig .",
    "[ fig1 ] . observe that the choice of @xmath172 has a direct impact on the expected error probability of the algorithm .",
    "in particular , for the gke algorithm a simple analysis yields the following relationship between @xmath172 and @xmath171 : p_e=_i^ * _ i(*y*)(n-1)_th more in general , for every algorithm , by decreasing @xmath172 we achieve a larger accuracy at the cost of employing more resources .    from the results",
    ", the following observations can be made .    *",
    "every adaptive algorithm performs much better than the uniform algorithm , employing on average the same amount of resources .",
    "* greedy algorithms without elimination perform better than greedy algorithms with elimination . observe , however that the latter are preferable in terms of computational complexity , since in such schemes , at round @xmath16 , the fitness index has to be computed only for objects in the contestant set @xmath28 , while in schemes without elimination it has to be computed for all objects . *",
    "the selection of the approximate max probability as fitness index , in place of the exact max probability , does not lead to any appreciable performance degradation , while having a significant beneficial impact on the computational complexity of the algorithm ( this has been checked also for algorithms with elimination ) .",
    "* tournament algorithms perform worse than our adaptive algorithms ; furthermore , their performance tends to worsen as @xmath165 is reduced . *",
    "the performance of greedy algorithms without elimination is only marginally worse than that of the ga algorithm .    to gather more insight on the algorithm behavior , a further performance comparison for the different schemes",
    "is reported in fig .",
    "[ fig2 ] for the case in which the number of objects is increased to @xmath173 ( object qualities @xmath57 are still equally spaced in the interval @xmath167 $ ] , with @xmath169 ) .",
    "observe that the relative ranking among the algorithms does not change , but the performance gap between algorithms tends to become more significant . in particular , tournament algorithms perform much worse than gka and gra .",
    "we remark that our results seem somehow in contrast with findings in  @xcite , where it has been shown that tournament algorithms provide the best performance , for cases in which users are only able to compare objects pairs . to intuitively grasp why they become inefficient in our context as @xmath1 increases , notice that tournament algorithms waste a significant amount of resources to discriminate among objects with similar quality ( accidentally placed in the same group ) , even when the quality of such objects is much worse than top - quality values .",
    "observe that , also in this case , gka ( whose performance is again practically indistinguishable from gke , not reported in fig .",
    "[ fig2 ] for the sake of readability ) performs similarly to the ga algorithm .",
    "this proves the effectiveness of gka in the considered scenarios .     vs @xmath170 ) of different algorithms with unquantized answers and unbounded budget for @xmath173 equally spaced objects . ]",
    "to evaluate the impact of human evaluation errors on the overall performance of algorithms , fig .",
    "[ fig3 ] reports a performance comparison between the gka and ga algorithms for different values of the parameter @xmath131 .",
    "observe that @xmath131 plays an important role : as the ratio @xmath131 decreases , more and more resources are needed to meet the same error probability .",
    "the performance gap between the two algorithms is rather limited in all cases .",
    "in particular , uniformly over all cases , the penalty cost in terms of evaluations required to obtain the same error probability does not exceed 10% . once again",
    ", this confirms the effectiveness of our approach for a broad range of scenarios where evaluation errors have different impact .",
    ", @xmath173 equally spaced objects . ]",
    "now , we move to scenarios in which the budget of allocations is bounded , and we restrict our analysis to :    * the bounded - greedy - keep - approximate ( bgka ) , employing the _ approximate max probability _ as fitness index , the _ bounded budget _ as allocation function , the _ maximum budget achieved _ or _ accuracy termination rule _ ;",
    "* the bounded - greedy - remove - approximate , ( bgra ) employing the _ approximate max probability with eliminations _ as fitness index , the _ bounded budget _ as allocation function , the _ maximum budget achieved or singleton contestant list _ as termination rule .    as a reference , we report also the performance of the bounded version of the ga algorithm ( bga ) , which again provides an obvious upper bound to performance . also in this case , to reduce the space of parameters , we fix @xmath174 .",
    "[ fig4 ] compares the performance of different algorithms for different values of the normalized budget @xmath175 . in the same figure",
    ", we also report the performance of the unbounded versions of the algorithms .",
    "we observe that :    * the error probability for bgka and bgra now is not monotonic with respect to @xmath170 . in particular ,",
    "if the average number of evaluations @xmath176 is sufficiently smaller than @xmath100 ( i.e. , for sufficiently large values of @xmath177 ) , the performance of the bounded algorithms does not significantly differ from the respective unbounded version : this happens because the probability that the algorithm terminates for achieving maximum budget is negligible . as we further reduce @xmath172 , increasing the required accuracy , the probability that the algorithm terminates because the maximum budget is achieved quickly increases , and the overall performance of the bounded algorithms degrades .",
    "these effects can be better understood from fig  [ fig5 ] , which reports the average number of evaluations per object , @xmath170 , and the error probability , as a function of the threshold @xmath172 , for the bgka algorithm ( similar considerations hold for bgra ) .",
    "now , observe that @xmath170 monotonically increases as @xmath172 decreases , since , by decreasing @xmath172 , the algorithm tends to be more conservative in excluding objects from receiving further evaluations . as a result , we distribute a larger number of allocations to objects with a quality quite distant from the maximum . while the error probability behaves monotonically with respect to @xmath172 ( decreasing as @xmath172",
    "is decreased ) in the case of an unbounded budget , in the case of bounded budget , choosing a value of @xmath172 too small will lead to an inefficient distribution of the limited resources .",
    "* as a consequence of i ) , only a limited range of @xmath171 values can be achieved in the bounded budget case . *",
    "also in this case , bgka outperforms bgra .",
    "vs @xmath170 for bgka and bgra , @xmath173 equally spaced objects . ]     and @xmath170 vs @xmath172 for bgka , @xmath173 equally spaced objects . ]    now , we consider a scenario in which object qualities @xmath57 are randomly drawn from a gaussian distribution with zero mean and standard deviation @xmath178 .",
    "vs @xmath170 for bgka and uniform , @xmath173 , object qualities are gaussian . ]",
    "[ fig6 ] presents the performance of bgka for the cases in which @xmath179 and @xmath180 . for the sake of comparison",
    ", the figure also reports the performance of the uniform algorithm .",
    "we observe that :    * also when qualities are drawn from a gaussian distribution , bgka improves performance with respect to the uniform allocation algorithm that employs the same average budget of resources ; * from a qualitative point of view , bgka exhibits a behavior which is pretty similar to the case where objects are equally spaced . by decreasing @xmath172 we",
    "initially increase accuracy at the cost of increasing also the amount of employed resources .",
    "however , beyond a given point , further decrements of @xmath172 cause a loss of efficiency , worsening the overall performance of the algorithm ; * the performance of the algorithms heavily depends on the parameter @xmath181 , which can be regarded as a difficulty index for the problem .    to complement the previous results for the bgka algorithm , fig .",
    "[ fig7 ] reports the first - order conditional distortion , i.e. , @xmath182 $ ] , which may be interpreted as the average quality gap between the best object and the object selected by the bgka algorithm , conditional over the fact that the bgka algorithm is not choosing the best object .",
    "observe that the values of the distortion are extremely small , proving that , whenever the bgka algorithm makes an error , it selects an object with a quality very close to the best .",
    "in other words , errors occur ( almost ) only in very difficult problem instances , where a cluster of two or more objects with quality very close to the top value exists . for completeness ,",
    "[ fig7 ] reports also the conditional distortion for the uniform allocation algorithm .",
    "observe that the distortion experienced with the uniform allocation algorithms is more than one order of magnitude larger than under bgka .",
    "this implies that the algorithms we propose in this paper not only offer the benefit of a drastic reduction in error probability , but they also bring a second crucial improvement : a drop in the gap between the quality of the selected object and the actual maximum quality , in the case of errors .     for bgka , @xmath173 , object qualities are gaussian . ]",
    "we finally consider the effect of quantization on the system performance .    in fig .",
    "[ fig : quantization_equallyspaced ] , we test the impact of different quantizers , in terms of @xmath183 versus @xmath170 , in the case where @xmath173 objects are equally spaced in the interval @xmath167 $ ] . in the figure ,",
    "the gka algorithm with unbounded budget is employed for all curves . moreover ,",
    "the standard deviation of the worker evaluation error has been set to @xmath184 .",
    "we recall that , for equally spaced objects , @xmath185 is the smallest distance between quality values .",
    "the solid line without markers represents the performance of the gka algorithm without quantization and is used as a benchmark .",
    "the line with triangle markers refers to the performance obtained employing a quantizer with @xmath186 representative values uniformly distributed in @xmath187 $ ] .",
    "we observe that , despite of the high number of levels , uniform quantization significantly worsen the error probability . instead",
    ", much better performance is achievable when the quantizer design is more accurate . as an example",
    ", the solid line with filled square markers refers to the case when @xmath186 , and the quantizer is designed according to the criteria in  @xcite , over the answer distribution @xmath152 } } * f_n$ ] , where @xmath188 , and @xmath189 .",
    "this quantizer , labeled `` lloyd '' in the legend , provides performance close to the unquantized case . in general",
    ", we observe that the performance is quite insensitive to the design parameter @xmath190 except if its value is close to the extreme point @xmath191 .",
    "[ fig : quantization_equallyspaced ] also shows the performance of lloyd s quantizers with @xmath189 and number of levels @xmath192 .",
    "we observe that an accurately designed quantizer with only @xmath193 levels is enough to provide performance close to the unquantized case .",
    "[ fig : quantization_gaussian ] refers to the case of @xmath173 objects with gaussian - distributed qualities , the budget is bounded to @xmath194 , and workers answers are quantized .",
    "the quantizer is designed according to the lloyd s algorithm over the weighted distribution @xmath195 } } * f_n$ ] , with @xmath188 , and @xmath189 . in the figure",
    ", the solid line refers to the unquantized case , while the lines with markers refer to the case where quantization is employed with @xmath196 levels .",
    "also in this scenario , we observe that @xmath193 quantization levels are enough to provide performance close to the unquantized case .     vs @xmath170 ) of the gka algorithm with unbounded budget and quantized workers answers , for @xmath173 objects with equally spaced quality values . ]",
    "objects with gaussian - distributed qualities . ]",
    "in this section we address two important issues : we evaluate the computational complexity of our algorithms , and we discuss how to set algorithm parameters ( and in particular @xmath172 ) . for the sake of brevity ,",
    "we restrict our investigation to bgka , which turns out to be the best - performing algorithm .    for what concerns computational complexity , at round @xmath16 , for every object @xmath8 in the contestant set , bgka : i ) must update @xmath197 ( this requires @xmath198 operations per object ) ; ii ) must compute a fitness index @xmath199 ( this again requires @xmath198 operations per objects , since the _ approximate max probability _ can be computed exploiting ) ; iii ) must compare @xmath199 with @xmath172 , in order to decide whether to allocate an extra worker to @xmath8 ( again @xmath198 operations are required ) . in the final round , if the number of objects that pass the threshold exceeds the residual budget , the execution of an extra task is necessary : objects must be sorted in order of their fitness index ( the cost of sorting is notoriously @xmath200 .",
    "observing that @xmath100 is an obvious upper bound to the number of rounds , it turns out that the overall complexity of bgka is @xmath201 in consideration of the fact that by construction @xmath202 .",
    "as regards the setting of the algorithm parameters , which in the case of bgka are @xmath172 and @xmath100 , we observe that the choice of the value for @xmath100 normally depends on economical or application - oriented considerations , whose discussion is beyond the scope of this paper . given the value of @xmath100 , it is possible to tune the algorithm by selecting the value for @xmath203 , which should be set in order to minimize the error probability . for a careful setting of @xmath172 , a preliminary parametric analysis of the algorithm performance is necessary to estimate the key system parameters ( such as the pdf @xmath4 of object qualities , and the variance @xmath204 of the workers quality estimation errors ) .",
    "in this paper , we have studied the problem of finding the top - quality element within a large collection of objects , resorting to human evaluations affected by noise . differently from previous works ,",
    "our study started assuming that unquantized scores are returned by the evaluators , and highlights the potential advantages of such approach .",
    "then we have shown how to properly design quantized schemes whose performance is very close to their ideal unquantized counterparts , provided that a reasonable number of quantization levels is assigned to workers answers .",
    "we plan to generalize the approach proposed in this paper to the case of workers with different skills , and to the problem of finding the @xmath0 top - quality elements within a large collection of objects through crowdsourcing algorithms .",
    "v. verroios , p. lofgren and h. garcia - molina , `` tdp : an optimal - latency budget allocation strategy for crowdsourced maximum operations , '' _ 2015 acm intern . conf . on management of data _ , new york ( usa ) , 10471062 , 2015 ."
  ],
  "abstract_text": [
    "<S> we investigate crowdsourcing algorithms for finding the top - quality item within a large collection of objects with unknown intrinsic quality values . </S>",
    "<S> this is an important problem with many relevant applications , for example in networked recommendation systems . </S>",
    "<S> the core of the algorithms is that objects are distributed to crowd workers , who return a noisy evaluation . </S>",
    "<S> all received evaluations are then combined , to identify the top - quality object . </S>",
    "<S> we first present a simple probabilistic model for the system under investigation . </S>",
    "<S> then , we devise and study a class of efficient adaptive algorithms to assign in an effective way objects to workers . </S>",
    "<S> we compare the performance of several algorithms , which correspond to different choices of the design parameters / metrics . </S>",
    "<S> we finally compare our approach based on scoring object qualities against traditional proposals based on comparisons and tournaments . </S>"
  ]
}