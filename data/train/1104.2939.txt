{
  "article_text": [
    "let @xmath4 be a ( possibly infinite ) network rooted at node @xmath5 .",
    "assume that independent and identically distributed noisy observations of an hidden random variable @xmath6 are available at a subset @xmath7 of the vertices .",
    "explicitly , each @xmath8 has access to a private signal @xmath9 where @xmath10 are independent and identically distributed , conditional on @xmath2 .",
    "the ` state of the world ' @xmath2 is drawn from a prior probability distribution @xmath11 .",
    "the objective is to aggregate information about @xmath2 at the root node under communication constraints encoded by the network structure , while minimizing the error probability at @xmath5 .",
    "we ask the following question :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ how much does the error probability at the root node @xmath5 increase due to these communication constraints ? _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in order to address this question , consider a sequence of information aggregation problems indexed by @xmath0 .",
    "information is revealed in a subset of the vertices @xmath12 .",
    "there are @xmath0 rounds in which information aggregation occurs . in each round , a subset of the nodes in @xmath13 make ` decisions ' that are broadcasted to their neighbors . in the initial round , nodes @xmath14 with distance @xmath15 ( with @xmath16 being the graph distance ) broadcast a decision @xmath17 to their neighbors , with @xmath3 a finite alphabet . in the next round ,",
    "nodes @xmath18 with distance @xmath19 broadcast a decision @xmath17 to their neighbors . and",
    "so on , until the neighbors of @xmath5 announce their decisions in round @xmath0 .",
    "finally , the root makes its decision .",
    "the decision of any node @xmath20 is a function of decisions of @xmath20 s neighbors in earlier rounds , and , if @xmath8 , on the private signal @xmath21 received by @xmath20 .",
    "clearly , the root can possibly access only the private information available at nodes @xmath22 with @xmath23 ( with @xmath16 the graph distance ) .",
    "we can therefore assume , without loss of generality , that @xmath24 .",
    "it is convenient to think of @xmath25 as the _ information horizon _ at time @xmath0 .",
    "consider first the case in which communication is unconstrained .",
    "this can be modeled by considering the graph with vertices @xmath26 and edges @xmath27 .",
    "in other words , this is a star network , with the root at the center . without loss of generality , we take @xmath28 , with @xmath29 as @xmath30 .    a simple procedure for information aggregation would work as follows .",
    "each node @xmath20 computes the log - likelihood ratio ( llr ) @xmath31 corresponding to the observed signal , and quantizes it to a value @xmath32 .",
    "the root adds up the quantized llrs and decides on the basis of this sum .",
    "it follows from basic large deviation theory @xcite that , under mild regularity assumptions , the error probability decreases exponentially in the number of observations @xmath33 this result is extremely robust :    * @xmath34 *  it holds for any non - trivial alphabet @xmath35 ;    * @xmath36 *  using concentration - of - measure arguments @xcite it is easy to generalize it to families of weakly dependent observations @xcite ;    * @xmath37 *  it can be generalized to network structures @xmath38 with weak communications constrains .",
    "for instance , @xcite proved that the error probability decays exponentially in the number of observations for trees of bounded depth .",
    "the crucial observation here is that such networks have large degree diverging with the number of vertices .",
    "in particular , for a tree of depth @xmath0 , the maximum degree is at least @xmath39 .    at the other extreme ,",
    "hellmann and cover @xcite considered the case of a line network . in our notations , we have @xmath40 , @xmath41 , and @xmath42 .",
    "in @xcite they proved that , as long as the llrs are bounded ( namely @xmath43 almost surely for some constant @xmath44 ) , and the decision rule is independent of the node , the error probability remains bounded away from @xmath45 as @xmath30 .    if the decision rule is allowed to depend on the node , the error probability can vanish as @xmath30 provided @xmath46 @xcite . despite this , even if the probability of error decays to @xmath45 , it does so much more slowly than for highly connected networks .",
    "namely , tay , tsitsiklis and win @xcite proved that @xmath47 for some @xmath48 .",
    "in other words , the communication constraint is so severe that , after @xmath0 steps , the amount of information effectively used by the root is equivalent to a vanishingly small fraction of the one within the ` information horizon ' .",
    "these limit cases naturally lead to the general question : given a rooted network @xmath49 , a sequence of information horizons @xmath50 and a finite alphabet @xmath3 , can information be aggregated at the root in such a way that the error probability decays exponentially in @xmath51",
    "? the question is wide open , in particular for networks of with average degree bounded or increasing slowly ( e.g. logarithmically ) with the system size .",
    "networks with moderate degree arise in a number of practical situations . within decentralized detection applications ,",
    "moderate degree is a natural assumption for interference - limited wireless networks . in particular , systems in which a single root node communicates with a significant fraction of the sensors",
    "are likely to scale poorly because of interference at the root .",
    "standard models for wireless ad hoc networks @xcite are indeed based on random geometric graphs whereby each node is connected to a logarithmic number of neighbors .",
    "a different domain of applications for models of decentralized decision making is social learning @xcite . in this case",
    ", each node corresponds to an agent , and the underlying graph is the social network across which information is exchanged .",
    "also in this case , it is reasonable to assume that each agent has a number of neighbors which is bounded , or diverges slowly as the total number of agents grows . in many graph - theoretic models of social networks",
    "@xcite , although a small number of nodes can have large degree , the average degree is bounded or grows logarithmically with the network size .",
    "given the slow progress with extreme network structures ( line networks and highly - connected networks ) , the study of general moderate degree networks appears extremely challenging . in this paper",
    "we focus on regular trees .",
    "more precisely , we let @xmath38 be the ( infinite ) regular tree with branching factor @xmath52 , rooted at @xmath5 ( each node has @xmath52 descendants and , with the exception of the root , one parent ) . the information horizon @xmath25 is formed by all the nodes at distance @xmath0 from the root , hence @xmath53 . under a broad set of assumptions , we prove that the probability of error decays subexponentially in the size of the information set , cf .",
    "( [ eq : subexp ] ) , where @xmath54 depends on the size of the alphabet @xmath55 .    more precisely , we establish subexponential convergence in the following cases :    1 .   for binary messages @xmath56 and any choice of the decision rule .",
    "in fact , we obtain a precise characterization of the smallest possible error probability in this case .",
    "2 .   for general message alphabet @xmath57",
    "provided the decision rule does not depend on the node , and satisfies a mild ` irreducibility ' condition ( see section [ subsec : subexp_decay_general ] for a definition ) .    in the latter case",
    ", one expects that exponential convergence is recovered as the message set gets large .",
    "indeed we prove that the optimal exponent in eq .",
    "( [ eq : subexp ] ) obeys @xmath58 the upper bound follows from our general proof for irreducible decision rules , while the lower bound is obtained by constructing an explicit decision rule that achieves it .",
    "our investigation leaves several interesting open problems .",
    "first , it would be interesting to compute the optimal exponent @xmath59 for given degree of the tree and size of the alphabet .",
    "even the behavior of the exponent for large alphabet sizes is unknown at the moment ( cf .",
    "second , the question of characterizing the performance limits of general , node - dependent decision rules remains open for @xmath60 .",
    "third , it would be interesting to understand the case where non - leaf nodes also get private signals , e.g. , @xmath61 .",
    "finally , this paper focuses on tree of bounded degree .",
    "it would be important to explore generalization to other graph structures , namely trees with slowly diverging degrees ( which could be natural models for the local structure of preferential attachment graphs @xcite ) , and loopy graphs .",
    "our current results can be extended to trees of diverging degree only in the case of binary signals . in this case",
    "we obtain that the probability of error is subexponential @xmath62 as soon as the degree is sub - polynomial , i.e. @xmath63 for all @xmath64 .",
    "the rest of the paper is organized as follows : section [ sec : model ] defines formally the model for information aggregation .",
    "section [ sec : binary ] presents our results for binary messages @xmath56 .",
    "section [ sec : nodeoblivious ] treats the case of decision rules that do not depend on the node , with general @xmath3 .",
    "as mentioned in the introduction , we assume the network @xmath65 to be an ( infinite ) rooted @xmath52-ary tree , i.e. a tree whereby each node has @xmath52 descendants and one parent ( with the exception of the root , that has no parent ) .",
    "independent noisy observations ( ` private signals ' ) of the state of the world @xmath2 are provided to the nodes at all the nodes at @xmath0-th generation @xmath66 .",
    "these will be also referred to as the ` leaves ' .",
    "define @xmath67 .",
    "formally , the state of the world @xmath68 is drawn according to the prior @xmath69 and for each @xmath70 an independent observation @xmath71 is drawn with probability distribution @xmath72 ( if @xmath73 ) or @xmath74 ( if @xmath75 ) . for notational simplicity",
    "we assume that @xmath76 is finite , and that @xmath77 , @xmath78 for all @xmath79 . also , we exclude degenerate cases by taking @xmath80 .",
    "we refer to the refer to the two events @xmath81 and @xmath82 as the hypotheses @xmath83 and @xmath84 .",
    "in round 0 , each leaf @xmath20 sends a message @xmath17 to its parent at level 1 . in round 1",
    ", the each node @xmath85 at level 1 sends a message @xmath86 to its parent at level 2 . similarly up to round @xmath0 .",
    "finally , the root node @xmath5 makes a decision @xmath87 based on the @xmath52 messages it receives .",
    "the objective is to minimize @xmath88 .",
    "we call a set of decision rules _ optimal _ if it minimizes @xmath89 .    we will denote by @xmath90 the set of children of node @xmath20 .",
    "we denote the probability of events under @xmath83 by @xmath91 , and the probability of events under @xmath84 by @xmath92 .",
    "finally , we denote by @xmath93 the decision rule at node @xmath20 in the tree . if @xmath20 is not a leaf node and @xmath94 , then @xmath95 .",
    "the root makes a binary decision @xmath96 .",
    "if @xmath20 is a leaf node , it maps its private signal to a message , @xmath97 . in general , @xmath93 s can be randomized .",
    "in this section , we consider the case @xmath98 , i.e. , the case of binary messages .",
    "consider the case @xmath99 , @xmath100 and @xmath101 for @xmath102 ; where @xmath103 .",
    "define the majority decision rule at non - leaf node @xmath20 as follows : @xmath32 takes the value of the majority of @xmath104 ( ties are broken uniformly at random ) .",
    "it is not hard to see that if we implement majority updates at all non - leaf nodes , we achieve @xmath105 note that this is an upper bound on error probability under majority updates .",
    "our main result shows that , in fact , this is essentially the best that can be achieved .",
    "[ thm : binary_lower_bound ] fix the private signal distribution , i.e. , fix @xmath106 and @xmath107 .",
    "there exists @xmath108 such that for all @xmath109 and @xmath110 , for any combination of decision rules at the nodes , we have @xmath111    in particular , the error probability decays subexponentially in the number of private signals @xmath112 , even with the optimal protocol .",
    "we prove the theorem for the case @xmath99 , @xmath100 and @xmath101 for @xmath102 ; where @xmath103 .",
    "the proof easily generalizes to arbitrary @xmath113 and @xmath114 .",
    "also , without loss of generality we can assume that , for every node @xmath20 , @xmath115 ( otherwise simply exchange the symbols and modify the decision rules accordingly ) .",
    "denote by @xmath116 the ( negative ) logarithm of the ` type i error ' in @xmath32 , i.e. @xmath117 . denote by @xmath118 the ( negative ) logarithm of the ` type ii error ' in @xmath32 , i.e. @xmath119 .    the following is the key lemma in our proof of theorem [ thm : binary_lower_bound ] .",
    "[ lemma : binary_key_lemma ] given @xmath120 , there exists @xmath121 such that for any @xmath52 we have the following : there exists an optimal set of decision rules such that for any node @xmath20 at level @xmath122 , @xmath123    applying lemma [ lemma : binary_key_lemma ] to the root @xmath5 , we see that @xmath124 .",
    "the result follows immediately .",
    "lemma [ lemma : binary_key_lemma ] is proved using the fact that there is an optimal set of decision rules that correspond to deterministic likelihood ratio tests ( lrts ) at the non - leaf nodes .",
    "choose a node @xmath20 .",
    "fix the decision functions of all descendants of @xmath20 .",
    "define @xmath125 . + a ) the decision function @xmath93 is a _ monotone deterministic likelihood ratio test _ if : + ( i ) it is deterministic . + ( ii ) there is a threshold @xmath126 such that @xmath127    \\b ) the decision function @xmath93 is a",
    "_ deterministic likelihood ratio test _ if either @xmath93 or @xmath128 is a monotone deterministic likelihood ratio test .",
    "here @xmath128 is the boolean complement of @xmath93 .",
    "the next lemma is an easy consequence of a beautiful result of tsitsiklis @xcite . though we state it here only for binary message alphabet , it easily generalizes to arbitrary finite @xmath3 .",
    "[ lemma : lrtoptimal ] there is a set of monotone deterministic likelihood ratio tests at the nodes that achieve the minimum possible @xmath129 .",
    "consider a set of decision rules that minimize @xmath129 .",
    "fix the rule at every node except node @xmath20 to the optimal one .",
    "now , the distributions @xmath130 and @xmath131 are fixed .",
    "moreover , @xmath129 is a linear function of @xmath132 , where @xmath133 denotes the distribution of @xmath32 under hypothesis @xmath134 .",
    "the set @xmath135 of achievable @xmath136 s is clearly convex , since randomized @xmath93 is allowed . from (",
    "* proposition 3.1 ) , we also know that @xmath135 is compact",
    ". thus , there exists an extreme point of @xmath135 that minimizes @xmath129 .",
    "now ( * ? ? ?",
    "* proposition 3.2 ) tells us that any extreme point of @xmath135 can be achieved by a deterministic lrt .",
    "thus , we can change @xmath93 to a deterministic lrt without increasing @xmath129 .",
    "if @xmath93 is not monotone ( we know that @xmath94 in this case ) , then we do @xmath137 and @xmath138 .",
    "clearly , @xmath129 is unaffected by this transformation , and @xmath93 is now a monotone rule .",
    "we do this at each of the nodes sequentially , starting at level @xmath45 , then covering level @xmath139 and so on until the root @xmath5 .",
    "thus , we change ( if required ) each decision rule to a monotone deterministic lrt without increasing @xmath129 .",
    "the result follows .    clearly , if @xmath93 is a monotone lrt , eq",
    ".   holds .",
    "in fact , we argue that there is a set of deterministic monotone lrts with strict inequality in eq .  , i.e. , such that @xmath140 holds for all @xmath20 , that are optimal .",
    "eq .   can only be written when @xmath141 and @xmath142 .",
    "consider a leaf node @xmath20 . without loss of generality we can take @xmath143 for each leaf node @xmath20 ( since any other rule can be ` simulated ' by the concerned level 1 node ) .",
    "so we have @xmath141 and @xmath142 , eq",
    ".   holds and @xmath93 is a deterministic lrt .",
    "we can ensure these properties inductively at all levels of the tree by moving from the leaves towards the root .",
    "consider any node @xmath20 .",
    "if @xmath144 , then @xmath94 ( else @xmath145 ) and the parent of @xmath20 is ignoring the constant message received from @xmath20 .",
    "we can do at least as well by using any non - trivial monotone deterministic lrt at @xmath20 .",
    "similarly , we can eliminate @xmath146 . if @xmath141 and @xmath142 , then eq .   must hold for any monotone deterministic lrt @xmath93 , using the inductive hypothesis .",
    "let @xmath147 and @xmath148 be binary vectors of the same length @xmath149 .",
    "we say @xmath150 if @xmath151 for all @xmath152 .",
    "we now prove lemma [ lemma : binary_key_lemma ] .    from lemma [ lemma : lrtoptimal ] and eq .",
    ", we can restrict attention to monotone deterministic lrts satisfying eq .  .",
    "we proceed via induction on level @xmath149 . for any leaf node @xmath20 ,",
    "we know that @xmath153 . choosing @xmath154 , eq",
    ".   clearly holds for all nodes at level @xmath45 .",
    ".   holds for all nodes at level @xmath149 .",
    "let @xmath20 be a node at level @xmath155 .",
    "let its children be @xmath156 .",
    "without loss of generality , assume @xmath157    * claim : * we can also assume @xmath158 proof of claim : suppose , instead , @xmath159 ( so @xmath160 is doing better than @xmath161 on both types of error ) . we can use the protocol on the subtree of @xmath160 also on the subtree of @xmath161 .",
    "call the message of @xmath161 under this modified protocol @xmath162 . since , @xmath163 and @xmath164 ( both types of error",
    "have only become less frequent ) , there exists a randomized function @xmath165 , such that @xmath166 for @xmath167 .",
    "thus , node @xmath20 can use @xmath168 to achieve the original values of @xmath169 and @xmath170 , where @xmath93 is decision rule being used at @xmath20 before . clearly , the error probabilities at @xmath20 , and hence at the root , stay unchanged with this .",
    "thus , we can safely assume @xmath171 .",
    "similarly , we can assume @xmath172 for @xmath173 .",
    "clearly , our transformations retained the property that nodes at levels @xmath155 and below use deterministic lrts satisfying eq .  .",
    "similar to our argument for eq .",
    "above , we can make appropriate changes in the decision rules at levels above @xmath155 so that they also use deterministic lrts satisfying eq .",
    ", without increasing error probability .",
    "this proves the claim .",
    "recall that @xmath174 is the decision rule at node @xmath20 .",
    "assume the first bit in the input corresponds to @xmath175 , the second corresponds to @xmath176 , and so on . using lemma [ lemma : lrtoptimal ] , we can assume that @xmath93 implements a deterministic likelihood ratio test .",
    "define the @xmath52-bit binary vectors @xmath177 , @xmath178 ,  , @xmath179 . from lemma [ lemma : lrtoptimal ] and",
    ", it follows that @xmath180 for some @xmath181 .",
    "* claim : * without loss of generality , we can assume that @xmath182 and @xmath183 .",
    "proof of claim : suppose @xmath184 .",
    "it follows from lemma [ lemma : lrtoptimal ] and eq .   that @xmath185 for every possible @xmath104 . if @xmath186 then we have @xmath187 .",
    "suppose @xmath188 .",
    "then @xmath32 is a constant and is ignored by the parent of @xmath20 .",
    "we can not do worse by using an arbitrary non - trivial decision rule at @xmath20 instead .",
    "( the parent can always continue to ignore @xmath189 . )",
    "the case @xmath190 can be similarly eliminated .",
    "this proves the claim .",
    "thus , we can assume @xmath191 without loss of generality .",
    "now @xmath192 contribute to type i error and @xmath193 contribute to type ii error .",
    "it follows that @xmath194 where we have used the ordering on the error exponents ( eqs .   and ) .",
    "eqs .   and lead immediately to @xmath195 now , for any @xmath196 , we have @xmath197 . plugging @xmath198 and @xmath199",
    ", we obtain from eq .",
    "@xmath200 by our induction hypothesis @xmath201 .",
    "thus , @xmath202 as required .",
    "induction completes the proof .",
    "in this section we allow a general finite message alphabet @xmath3 that need not be binary .",
    "however , we restrict attention to the case of _ node - oblivious _ rules : the decision rules @xmath93 at all nodes in the tree , except the leafs and the root , must be the same .",
    "we denote this ` internal node ' decision rule by @xmath203 .",
    "also , the decision rules used at each of the leaf nodes should be same .",
    "we denote the leaf decision rule by @xmath204 .",
    "the decision rule at the root is denoted by @xmath205 .",
    "we call such @xmath206 a node - oblivious decision rule vector .    define @xmath207 . in section [ subsec : node - oblivious_efficient_scheme ]",
    ", we present a scheme that achieves @xmath208 when the error probability in the private signals is sufficiently small . next , under appropriate assumptions , we show that the decay of error probability must be sub - exponential in the number of private signals @xmath209 .      for convenience ,",
    "we label the messages as @xmath210 the labels have been chosen so as to be suggestive ( in a quantitative sense , see below ) of the inferred log - likelihood ratio .",
    "further , we allow the messages to be treated as real numbers ( corresponding to their respective labels ) that can be operated on . in particular , the quantity @xmath211 is well defined for a non - leaf node @xmath20 .",
    "the node - oblivious decision rule we employ at a non - leaf node @xmath188 is @xmath212 \\left \\lfloor \\frac{s_i / k - ( m-1)/2}{1 - 1/m}\\right \\rfloor + \\frac{m-1}{2}\\ , , & \\textup{if } s_i > 0 \\end{array } \\right .",
    "\\label{eq : good_decision_rule}\\end{aligned}\\ ] ] note that the rule is symmetric with respect to a inversion of sign , except that @xmath213 is mapped to the message @xmath214 when @xmath215 is even .",
    "the rule @xmath216 used at the leafs is simply @xmath217 and @xmath218 .",
    "the decision rule at the root is @xmath219 if we associate @xmath83 with negative quantities , and @xmath84 with positive quantities , then again , the rule at the leafs is symmetric , and the rule at the root is essentially symmetric ( except for the case @xmath220 ) .",
    "assume @xmath83 .",
    "define @xmath229 and @xmath230 .",
    "we show that , in fact , for suitable choice of @xmath231 the following holds : if @xmath224 , then for any node @xmath20 at any level @xmath225 , @xmath226 \\geq   \\nonumber\\\\ ( l / m ) \\gamma^\\tau + c \\label{eq : letter_prob_decay}\\end{aligned}\\ ] ]    we proceed by induction on @xmath149 .",
    "consider @xmath20 at level @xmath232 .",
    "we have @xmath233 = 0 $ ] for @xmath234 and @xmath235 = \\delta$ ] . choosing @xmath236 , we can ensure that eq",
    ".   holds at level @xmath45 .",
    "note that for @xmath237 , we have @xmath238 .",
    "now suppose eq",
    ".   holds at level @xmath149 .",
    "consider node @xmath20 at level @xmath155 . from eq .",
    ", for @xmath239 we need @xmath240 \\label{eq : si_lb}\\end{aligned}\\ ] ] for every @xmath241 such that eq .   holds , we have @xmath242 .",
    "thus , @xmath243 obviously , there are at most @xmath244 such @xmath104 .",
    "thus , @xmath245   \\\\ \\leq \\ ; & m^k \\exp\\left(- kc - ( 1/m)l \\gamma^{\\tau+1 } \\right ) \\\\",
    "= \\ ; & \\exp\\left(- c - ( 1/m)l \\gamma^{\\tau+1 } \\right ) \\end{aligned}\\ ] ] thus , eq . holds at level @xmath155 .",
    "induction completes the proof .    for @xmath221 and @xmath222",
    ", there exists @xmath246 , and a node - oblivious decision rule vector , such that the following is true : for any @xmath224 , we have @xmath247 & \\leq   \\exp \\left \\ { - \\frac{m-1}{2 m } \\big \\{k   \\left ( 1 - 1/m\\right ) \\big \\}^t \\right \\ } \\nonumber\\\\ & =   \\exp \\left \\{- \\frac{m-1}{2m}\\ , n^\\rho \\right \\}\\end{aligned}\\ ] ] with @xmath248 .",
    "[ thm : good_decision_rule_exists ]      assume @xmath83 .",
    "for every @xmath249 such that @xmath250 , we have @xmath251 . from lemma [ lemma : good_decision_decay](i ) , @xmath252 where @xmath229 and @xmath230 .",
    "obviously , there are at most @xmath244 such @xmath253 .",
    "it follows that @xmath254          define @xmath258 , i.e. , @xmath259 is the number of private signals received , one at each leaf .",
    "the scheme presented in the previous section allows us to achieve error probability that decays like @xmath260 , where @xmath261 for @xmath262 . in this section",
    "we show that under appropriate assumptions , error probability that decays exponentially in @xmath259 , i.e. , @xmath263 , is not achievable with node - oblivious rules .",
    "in this section we call the letters of the message alphabet @xmath264 . for simplicity , we consider only deterministic node - oblivious rules , though our results and proofs extend easily to randomized rules .",
    "we define here a directed graph @xmath265 with vertex set @xmath3 and edge set @xmath266 that we define below .",
    "we emphasize that @xmath265 is distinct from the tree on which information aggregation is occurring .",
    "there is a directed edge from node @xmath267 to node @xmath268 in @xmath265 if there exists @xmath269 such that @xmath270 appears at least once in @xmath147 and @xmath271 .",
    "informally , @xmath272 if @xmath273 can be ` caused ' by a message vector received from children that includes @xmath270 .",
    "we call @xmath265 the _ dependence graph_.      [ ass : strongly_connected ] the dependence graph @xmath265 is strongly connected . in other words , for any @xmath267 and @xmath268 such that @xmath274 , there is a directed path from @xmath273 to @xmath270 in @xmath265",
    ".        there exists @xmath282 , @xmath283 , @xmath284 and @xmath285 such that , for all @xmath286 the following holds : for node @xmath20 at level @xmath149 , we have @xmath287 and @xmath288 .",
    "[ ass : one_letter_dominant ]      it is not hard to verify that for @xmath221 , @xmath222 and @xmath289 ( where @xmath231 is same as in lemma [ lemma : good_decision_decay ] and theorem [ thm : good_decision_rule_exists ] ) , the scheme presented in the previous section satisfies all four of our assumptions .",
    "in other words , the assumptions are all satisfied in the regime where our scheme has provably good performance .",
    "consider a directed graph @xmath290 that is strongly connected .",
    "for @xmath291 , let @xmath292 be the length of the shortest path from @xmath293 to @xmath294 .",
    "then the _ diameter _ of @xmath265 is defined as -15pt @xmath295    [ thm : subexp_decay ] fix @xmath215 and @xmath52 .",
    "consider any node - oblivious decision rule vector @xmath206 such that assumptions [ ass : strongly_connected ] , [ ass : all_letters_+ve_prob ] and [ ass : one_letter_dominant ] are satisfied .",
    "let @xmath296 be the diameter of the dependence graph @xmath265 .",
    "then , there exists @xmath297 such that we have @xmath298 \\geq \\exp \\left \\{-",
    "c n^{\\brho } \\right \\}\\ , , \\end{aligned}\\ ] ] where @xmath299 .",
    "[ coro : subexp_decay ] fix @xmath215 and @xmath52 .",
    "consider any node - oblivious decision rule vector @xmath206 such that assumptions [ ass : strongly_connected ] , [ ass : all_letters_+ve_prob ] and [ ass : one_letter_dominant ] are satisfied .",
    "then , there exists @xmath297 such that we have @xmath298 \\geq \\exp \\left \\{-",
    "c n^{\\rho } \\right \\}\\ , , \\end{aligned}\\ ] ] where @xmath301 .",
    "[ rem : mus_vec_maps_to_itself ] we have @xmath302 .",
    "it follows that we must have @xmath303 ( else the probability of error is bounded below by @xmath304 for any @xmath0 ) .",
    "similarly , we must have @xmath305 .",
    "in particular , @xmath306 .",
    "it follows from assumption [ ass : all_letters_+ve_prob ] that for any @xmath278 , there is some @xmath269 such that @xmath308 .",
    "we prove the lemma by induction on the level @xmath149 .",
    "let @xmath309 by assumption , @xmath310 holds .",
    "suppose @xmath311 holds .",
    "consider node @xmath20 at level @xmath155 .",
    "consider any @xmath278 . by inductive hypothesis",
    ", we have @xmath312 .",
    "it follows that @xmath277 .",
    "thus , @xmath313 holds .",
    "lemma [ lemma : subexp_decay ] can be thought of as a quantitative version of lemma [ lemma : all_letters_+ve_prob_after_tau0 ] , showing that the probability of the least frequent message decays subexponentially .",
    "suppose assumptions [ ass : strongly_connected ] , [ ass : all_letters_+ve_prob ] and [ ass : one_letter_dominant ] are satisfied .",
    "fix @xmath314 . consider a node @xmath20 at level @xmath149 .",
    "define @xmath315 .",
    "let @xmath316 ( cf .",
    "assumptions [ ass : all_letters_+ve_prob ] , [ ass : one_letter_dominant ] ) .",
    "let @xmath317 .",
    "there exists @xmath318 such that for any @xmath319 and @xmath320 , we have , @xmath321 [ lemma : subexp_decay ]        we proceed via induction on @xmath323 .",
    "first consider @xmath324 .",
    "consider a node @xmath20 at level @xmath325 for @xmath320 .",
    "consider the descendants of node @xmath20 at level @xmath326 .",
    "for any @xmath278 , we know from lemma [ lemma : all_letters_+ve_prob_after_tau0 ] that there must be _ some _ assignment of messages to the descendants , such that @xmath327 .",
    "it follows that @xmath328 thus , choosing @xmath329 , we can ensure that eq .",
    "holds for @xmath324 and all @xmath320 .",
    "now suppose eq",
    ".   holds for some @xmath330 .",
    "consider a node @xmath20 at level @xmath331 .",
    "let @xmath332 be the set of descendants of node @xmath20 at level @xmath333 .",
    "note that @xmath334 .",
    "consider any @xmath278 . by assumption [ ass : strongly_connected ] , there is a directed path in @xmath265 of length at most @xmath296 going from @xmath335 to @xmath336 . by remark [ rem : mus_vec_maps_to_itself ] , we know that @xmath337 .",
    "it follows that there is a directed path in @xmath265 of length _ exactly _ @xmath296 going from @xmath335 to @xmath336 .",
    "thus , there must be an assignment of messages @xmath338 to nodes in @xmath332 , including at least one occurrence of @xmath336 , such that @xmath327 .",
    "using assumption [ ass : one_letter_dominant ] , we deduce that @xmath339 rewriting as @xmath340 and combining with eq .",
    ", we obtain @xmath341 induction completes the proof .          for the scheme presented in section [ subsec : node - oblivious_efficient_scheme ] , we have @xmath346 , where @xmath347 . for any @xmath348 , theorem [ thm : subexp_decay ]",
    "provides a lower bound on error probability with @xmath349 for some @xmath350 .",
    "this closely matches the @xmath215 dependence of the upper bound on error probability we proved in theorem [ thm : good_decision_rule_exists ] .",
    "we already mentioned that the efficient node - oblivious rule presented in section [ subsec : node - oblivious_efficient_scheme ] satisfies all of assumptions [ ass : strongly_connected ] , [ ass : all_letters_+ve_prob ] and [ ass : one_letter_dominant ] .",
    "moreover , it is natural to expect that similar schemes based on propagation of quantized likelihood ratio estimates should also satisfy our assumptions . in this section",
    ", we further discuss our assumptions taking the cases of binary and ternary messages as examples .",
    "binary messages are not the focus of section [ subsec : subexp_decay_general ] .",
    "however , we present here a short discussion of assumptions 1 , 2 and 3 in the context of binary messages for illustrative purposes .",
    "proof of claim : call the messages @xmath98 .",
    "consider a node - oblivious decision rule vector @xmath206 such that error probability decays to @xmath45 with @xmath0 .",
    "then @xmath352 can not be a constant function ( e.g. , identically @xmath45 ) , since this leads to @xmath353 .",
    "suppose assumption [ ass : strongly_connected ] is violated .",
    "without loss of generality , suppose @xmath354 .",
    "then @xmath355 for all @xmath356 .",
    "it follows that for node @xmath20 at level @xmath149 , we have @xmath357 for both @xmath73 and @xmath75 .",
    "in particular , @xmath89 is bounded away from @xmath45 .",
    "this is a contradiction .",
    "suppose assumption [ ass : all_letters_+ve_prob ] is violated .",
    "then , wlog , all nodes at level @xmath139 transmit the message @xmath139 almost surely , under either hypothesis .",
    "thus , all useful information is lost and @xmath353 .",
    "this is a contradiction .",
    "finally , we show that assumption [ ass : one_letter_dominant ] must hold as well .",
    "define @xmath358 for node @xmath20 at level @xmath0 .",
    "wlog , suppose @xmath359 occurs infinitely often",
    ". then we have @xmath360 , else @xmath361 for infinitely many @xmath0 .",
    "define @xmath362 for node @xmath20 at level @xmath0 . if @xmath363 occurs infinitely often",
    ", then it follows that @xmath364 and hence @xmath365 occur for infinitely many @xmath0 .",
    "so we can have @xmath363 only finitely many times .",
    "also , @xmath366 must hold .",
    "it follows that @xmath367 occurs only finitely many times .",
    "thus , assumption [ ass : one_letter_dominant ] holds with @xmath368 .",
    "we first show that if assumption [ ass : all_letters_+ve_prob ] is violated , then @xmath370 . if assumption [ ass : all_letters_+ve_prob ] does not hold , then only at most two letters are used at each level .",
    "it follows that we can have a ( possibly node - dependent ) scheme with binary messages that is equivalent to the original scheme at levels @xmath139 and higher .",
    "our lower bound on @xmath89 then follows from theorem [ thm : binary_lower_bound ] .",
    "thus , even in the best case , performance is significantly worse than the scheme presented in section [ subsec : node - oblivious_efficient_scheme ] .",
    "so a good scheme for ternary messages must satisfy assumption [ ass : all_letters_+ve_prob ]",
    ".    now consider assumption [ ass : strongly_connected ] .",
    "let @xmath371 .",
    "suppose assumption [ ass : strongly_connected ] is violated .",
    "then wlog , there is no path from letter @xmath45 to one of the other letters .",
    "it follows that under either hypothesis , we have @xmath372 for node @xmath20 at level @xmath149 .",
    "thus , the letter @xmath45 occurs with exponentially small probability , irrespective of @xmath2 .",
    "this should essentially reduce , then , to the case of binary messages , and we expect performance to be constrained as above",
    ".    finally , consider assumption [ ass : one_letter_dominant ] .",
    "we can not have @xmath373 for all @xmath278 , since that will lead to @xmath374 for all @xmath0 .",
    "similarly , we can also exclude the possibility @xmath375 for all @xmath278 .",
    "wlog , suppose @xmath376 and @xmath377 . now consider the problem of designing a good aggregation protocol . by the above , we must have @xmath378 and @xmath379 , for node @xmath20 at level @xmath149 , to each converge to 0 with increasing @xmath149 .",
    "further , it appears natural to use the message @xmath380 with an interpretation of ` not sure ' in such a situation .",
    "we would then like the probability of this intermediate symbol to decay with @xmath149 , or at least be bounded in the limit , i.e. , @xmath381 for each possible @xmath2 .",
    "if this holds , we immediately have assumption [ ass : one_letter_dominant ] ( with @xmath382 and @xmath383 ) .",
    "we argued above that our irreducibility assumptions are quite reasonable in various circumstances .",
    "in fact , we expect the assumptions to be a proof artifact , and conjecture that a subexponential convergence bound holds for general node - oblivious rules .",
    "a possible approach to eliminate our assumptions would be to prune the message alphabet @xmath3 , discarding letters that never appear , or appear with probability bounded by @xmath384 ( because they require descendants from a strict subset of @xmath3 ) ."
  ],
  "abstract_text": [
    "<S> we consider the decentralized binary hypothesis testing problem on trees of bounded degree and increasing depth . for a regular tree of depth @xmath0 and branching factor @xmath1 , we assume that the leaves have access to independent and identically distributed noisy observations of the ` state of the world ' @xmath2 . starting with the leaves , each node makes a decision in a finite alphabet @xmath3 , that it sends to its parent in the tree . </S>",
    "<S> finally , the root decides between the two possible states of the world based on the information it receives .    </S>",
    "<S> we prove that the error probability vanishes only subexponentially in the number of available observations , under quite general hypotheses . </S>",
    "<S> more precisely the case of binary messages , decay is subexponential for any decision rule . for general ( finite ) message alphabet @xmath3 , </S>",
    "<S> decay is subexponential for ` node - oblivious ' decision rules , that satisfy a mild irreducibility condition . in the latter case </S>",
    "<S> , we propose a family of decision rules with close - to - optimal asymptotic behavior . </S>"
  ]
}