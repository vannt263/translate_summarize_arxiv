{
  "article_text": [
    "the basis for regression is a response variable @xmath0 and a covariate vector @xmath1 which are linked via the formula @xmath2 , where @xmath3 is a regression function and @xmath4 is an error variable .",
    "the analysis is then carried out based on independent copies @xmath5 of the pair @xmath6 .",
    "we refer to this as the _ full model_. in applications , however , responses may be missing .",
    "the base observation is then a triple @xmath7 , where @xmath8 is an indicator variable with @xmath9=p(\\delta=1)>0 $ ] .",
    "the interpretation is that for @xmath10 , one observes the pair @xmath6 , while for @xmath11 one only observes the covariate @xmath1 .",
    "the analysis is now based on independent copies @xmath12 of the observation @xmath7 .",
    "an accepted way of analyzing such data is by imputing the missing responses . here we take a closer look at _ complete case analysis_. this method ignores the incomplete observations and works with only the @xmath13 completely observed pairs @xmath14 .",
    "formally , to each statistic @xmath15 for the full model there corresponds the _ complete case statistic _ @xmath16 which mimics the statistic @xmath17 by treating @xmath18 as if it were a sample of size @xmath19 from the original setting without missing data .",
    "our main result gives a simple and useful method for obtaining the asymptotic distribution of @xmath20 .",
    "we show that the limiting distribution of @xmath20 coincides with that of @xmath21 where @xmath22 form a random sample drawn from the conditional distribution of @xmath6 , given @xmath10 ; see remark  [ rem4 ] .",
    "this can be used as follows .",
    "one typically knows the limiting distribution @xmath23 of @xmath17 under each joint distribution @xmath24 of @xmath1 and @xmath0 belonging to some model .",
    "if the distribution @xmath25 of @xmath26 belongs to this model , then the limiting distribution of the complete case statistic is @xmath27 .",
    "we refer to this as the _ transfer principle_. it provides a convenient tool for obtaining the asymptotic behavior of complete case versions of established full data methods without ( reproducing ) lengthy proofs .    of special interest",
    "are statistics @xmath17 that are _ asymptotically linear _ for a functional  @xmath28 from a class @xmath29 of distributions into @xmath30 in the sense that if @xmath1 and @xmath0 have joint distribution @xmath24 belonging to the model @xmath29 , then the expansion @xmath31 holds . here",
    "@xmath32 is a measurable function into @xmath30 such that @xmath33=0 $ ] and @xmath34 $ ] is finite when @xmath1 and @xmath0 have joint distribution @xmath24 . here and below",
    "@xmath35 denotes the euclidean norm .",
    "the function @xmath32 is commonly called an _ influence function_. from the above expansion we obtain that @xmath36 is asymptotically normal with the zero vector as mean and with dispersion matrix @xmath37 $ ] . if @xmath25 belongs to the model @xmath29 , then we have the expansion @xmath38 and obtain from our main result that @xmath39 see remark  [ rem5 ] . from this",
    "we immediately derive the expansion @xmath40 } \\sum _ { j=1}^n\\delta_j \\psi_{\\tilde q}(x_j , y_j ) + o_p\\bigl(n^{-1/2}\\bigr).\\ ] ] thus , if @xmath25 belongs to the model @xmath41 and @xmath42 equals @xmath43 , then @xmath20 is asymptotically linear in the model with missing data with influence function @xmath44 , where @xmath45 } \\psi_{\\tilde q}(x , y).\\ ] ] we refer to this as the _ transfer principle for asymptotically linear statistics_. it yields that @xmath46 is asymptotically normal with the zero vector as mean and with dispersion matrix @xmath47)\\sigma(\\tilde q)$ ] .",
    "the key to a successful application of the transfer principle is the condition @xmath48 . under this condition",
    ", @xmath49-consistency carries over to the complete case statistic .",
    "if this condition is not met , the complete case statistic will be biased for estimating @xmath43 . for our illustration of the transfer principle",
    "we consider the important case where the response @xmath0 is _ missing at random _ ( mar ) .",
    "this means that the indicator  @xmath8 is conditionally independent of @xmath0 , given @xmath1 , that is , @xmath50 this is a common assumption and reasonable in many applications [ see @xcite , chapter 1 ] .",
    "this model is referred to as the _ mar model_.    it is well known that the complete case analysis does not always perform well and that an approach which imputes missing values often has better statistical properties .",
    "see , for example , chapter 3 of @xcite for examples where using the complete case approach results in bias or a loss of precision , due to the loss of information . for a discussion of various imputing methods",
    "we again refer to @xcite , and also to mller , schick and wefelmeyer ( @xcite ) , who propose efficient estimators for various regression settings which impute missing and non - missing responses .",
    "although complete case analysis can lead to the above - mentioned problems , there are situations where it provides useful and optimal inference procedures .",
    "@xcite , for example , considers nonparametric regression with responses missing at random .",
    "he shows that his complete case estimator of the regression function is optimal in the sense that it satisfies an asymptotic sharp minimax property .",
    "mller ( @xcite ) demonstrates efficiency of a complete case estimator for the parameter vector in the nonlinear regression model .    for simplicity and clarity ,",
    "we illustrate the above transfer principle using the partially linear regression model . in this model",
    "the response @xmath0 is linked to covariates @xmath51 and @xmath52 via the relation @xmath53 with @xmath54 an unknown @xmath55-dimensional vector and @xmath56 an unknown twice continuously differentiable function .",
    "the error @xmath4 is assumed to have mean zero , finite variance  @xmath57 and a density @xmath58 , and is independent of the covariates @xmath59 , where the random vector @xmath51 has dimension @xmath55 and the random variable @xmath52 takes values in the compact interval @xmath60 $ ] . throughout this paper ,",
    "we impose the following conditions on the joint distribution @xmath61 of @xmath51 and @xmath52 :    the covariate @xmath52 has a density that is bounded and bounded away from zero on @xmath60 $ ] .",
    "the covariate vector @xmath51 satisfies @xmath62 < \\infty$ ] and the matrix @xmath63\\ ] ] is positive definite , where @xmath64 $ ] .",
    "the requirement involving @xmath65 is needed to identify the parameter @xmath54 .",
    "one important problem is the _ efficient _ estimation of the regression parameter  @xmath54 in ( [ rho ] ) .",
    "this is addressed in our first illustration of the transfer principle below .",
    "the crucial condition for a successful application of the transfer principle , @xmath66 , is satisfied in this case and , more generally , also for functionals of the triple @xmath67 .",
    "the mar assumption and the independence of @xmath4 and @xmath59 imply that @xmath4 and @xmath68 are independent .",
    "hence , the regression parameters @xmath54 and @xmath56 and the error density @xmath58 stay the same when conditioning on @xmath10 .",
    "only the covariate distribution @xmath61 changes to @xmath69 , the conditional distribution of @xmath59 given @xmath10 .",
    "this argument suggests that inference about the triple @xmath67 should be carried out using a complete case analysis , because the complete case observations are _ sufficient _ for @xmath70 since they carry all the information about these parameters .",
    "the covariate pair @xmath59 alone , on the other hand , has no information on @xmath67 , and hence has no bearing on the inference about these parameters when the response @xmath0 is missing at random .",
    "the same reasoning also applies to general semiparametric regression models : inference about the regression function and the error distribution should be based on the complete cases only .    in order to obtain an efficient estimator for @xmath54",
    "we must assume that the error density @xmath58 has finite fisher information for location .",
    "this means that @xmath58 is absolutely continuous with a.e .",
    "derivative @xmath71 such that @xmath72 is finite , where @xmath73 is the score function for location .",
    "efficient estimators of @xmath54 in the full model are characterized by the stochastic expansion @xmath74 see , for example , @xcite .",
    "because of the structure of the mar model introduced above , the transfer principle for asymptotically linear statistics yields that the complete case version @xmath75 of an efficient estimator satisfies the expansion @xmath76 } ( j_f w_{\\tilde g})^{-1 } \\bigl(u_j- \\mu_{\\tilde g}(v_j )",
    "\\bigr ) \\elf(\\ve_j ) + o_p\\bigl(n^{-1/2}\\bigr).\\ ] ] this of course requires that @xmath69 satisfies the properties ( g1 ) and ( g2 ) .",
    "this is the case when @xmath77 is bounded away from zero ; see remark  [ rem6a ] . here",
    "@xmath78 .",
    "although several estimators exist which are efficient in the full partially linear model , to our knowledge no efficient estimators have so far been constructed for the corresponding mar model .",
    "we show in section  [ sec3 ] that the expansion ( [ eff - mar ] ) of @xmath79 characterizes asymptotically _ efficient _ estimators of @xmath54 in the mar model .",
    "this means that complete case versions of efficient estimators in the full model remain efficient in the mar model ( under appropriate conditions ) .",
    "this result in turn solves the important problem of constructing efficient estimators for @xmath80 in the partially linear mar model . for constructions of efficient estimators in the full model  ( [ rho ] ) ,",
    "we refer the reader to @xcite , schick ( @xcite , @xcite ) , @xcite and forrester et al .",
    "( @xcite ) .",
    "some of these constructions require smoothness assumptions on @xmath81",
    ". then the validity of ( [ eff - mar ] ) requires the same smoothness assumptions on @xmath82 .",
    "the above method of constructing efficient estimators for the finite - dimensional parameter also yields efficient estimators in other semiparametric regression mar models .",
    "the influence function of the complete case version of an estimator efficient for the full model is given by the transfer principle for asymptotically linear estimators .",
    "one then only needs to show that this influence function is the efficient influence function for the mar model .",
    "the latter can be done by mimicking the results in section  [ sec3 ] . there",
    "we sketch this approach for the partially linear model with additive @xmath56 and for a single index model .",
    "mller ( @xcite ) has calculated the efficient influence function for the regression parameter in a nonlinear regression model .",
    "using the transfer principle , one sees that the efficient influence function equals the influence function of the complete case version of an efficient estimator for the full model .",
    "this provides a simple derivation of efficient estimators in her model .",
    "we believe that the above _ efficiency transfer _ is valid for the estimation of other characteristics in the mar model ( [ rho ] ) .",
    "we expect that the efficiency transfer generalizes to the estimation of ( smooth ) functionals of the triple @xmath67 .",
    "this includes as important special cases the estimation of the distribution function , the error variance and other characteristics of @xmath58 such as quantiles and moments of  @xmath58 .",
    "however , further research is needed to crystallize the issues involved .",
    "next we illustrate the transfer principle on goodness - of - fit and lack - of - fit tests .",
    "there is a vast literature on goodness - of - fit tests for fitting an error distribution and lack - of - fit tests for fitting a regression function in fully observable regression models .",
    "see , for example , @xcite and the review article by @xcite , and the references therein .",
    "here we shall discuss two important examples for the mar regression models .",
    "one pertains to fitting a parametric distribution to the error distribution in ( [ rho ] ) and the other to testing whether @xmath56 in the model ( [ rho ] ) is a constant or not . in both examples",
    "the proposed tests are complete case analogs of full model tests that are _ asymptotically distribution free _ , that is , the limiting distribution of the test statistic under the null hypothesis is the same for all members of the null model being fitted . due to the transfer principle , the same conclusion continues to hold for the proposed tests for the mar model ( [ rho ] ) .",
    "first , consider the goodness - of - fit testing problem in the model ( [ rho ] ) and the null hypothesis @xmath83 , for some unknown @xmath84 .",
    "for the full model a residual - based test of this hypothesis was introduced by mller , schick and wefelmeyer ( @xcite ) ( msw ) adapting a martingale transform test of @xcite for fitting a parametric family of error distributions in nonparametric regression . in ( [ rho ] ) ,",
    "the residuals are of the form @xmath85 , where @xmath86 is a @xmath87-consistent estimator of @xmath54 and @xmath88 is a nonparametric estimator of @xmath56 , such as a local smoother based on the covariates @xmath89 and the modified responses @xmath90 , or a series estimator .",
    "let @xmath91 denote the estimator of the standard deviation @xmath92 and @xmath93 , @xmath94 denote the standardized residuals .",
    "the test statistic of msw is then @xmath95 - h ( \\hat z_j\\wedge t)h(\\hat z_j ) \\bigr\\ } \\biggr|\\ ] ] for some known functions @xmath96 and @xmath97 related to the standard normal distribution function and its derivatives ; see section  [ sec4 ] , equation ( [ hh ] ) .",
    "here we work with a series estimator of @xmath56 , which is discussed in section 4 of msw .",
    "this requires no additional assumptions .",
    "the test based on @xmath17 is asymptotically distribution free , because under the null hypothesis , @xmath17 converges in distribution to @xmath98 where @xmath99 is a standard brownian motion . due to the transfer principle ,",
    "the complete case version @xmath20 of the above @xmath17 has the same limiting distribution under the null hypothesis .",
    "hence , the null hypothesis is rejected if @xmath100 exceeds the upper @xmath101 quantile of the distribution of @xmath102 .",
    "see section  [ sec4 ] , equation ( [ tc ] ) , and the discussion around it for a detailed description of the complete case variant @xmath20 of the above @xmath17 . from the discussion on optimality of this test in @xcite and the transfer principle",
    ", it follows that the test based on @xmath100 will generally be more powerful than the complete case test based on the kolmogorov ",
    "smirnov statistic .",
    "finally , we consider testing whether @xmath56 is constant within the partially linear model , that is , we suppose that the partially linear model ( [ rho ] ) holds true and test whether the regression function is in fact linear . here",
    "we adapt an approach by @xcite for testing a general parametric model in nonparametric regression , which is based on a weighted residual - based empirical process . for the full model this suggests a test statistic of the form @xmath103 \\biggr|,\\ ] ] where @xmath104 are the residuals under the null hypothesis obtained by regressing the responses @xmath105 on the covariates @xmath106 including an intercept , and where @xmath107 are normalized versions of the residuals obtained from regressing @xmath108 on the covariates @xmath106 including an intercept , for a suitably chosen function @xmath109 .",
    "the asymptotic null distribution of this test is that of @xmath110 where @xmath111 denotes a standard brownian bridge .",
    "this is the first test for this problem in the case of fully observed data .",
    "the transfer principle immediately shows that the complete case variant of this test described at ( [ tc2 ] ) has the same limiting distribution .",
    "the literature on lack - of - fit testing in the regression model when responses are missing at random is scant .",
    "@xcite establish asymptotic distributional properties of some tests based on marked residual empirical processes for fitting a parametric model to the regression function when data are imputed using the inverse probability method .",
    "@xcite derive tests to check the hypothesis that the partially linear model ( [ rho ] ) is appropriate , based on data which are `` completed '' by imputing estimators for the responses .",
    "these tests are compared with tests that ignore the missing data pairs .",
    "gonzlez - manteiga and prez - gonzlez ( @xcite ) use imputation to complete the data .",
    "they derive tests about linearity of the regression function in a general nonparametric regression model .",
    "their test is similar to the above test for the last example .",
    "the last two papers report simulation results that support the superiority of these methods over a selected complete case method .",
    "however , one can verify that the first test statistic in sun , wang and dai ( @xcite ) is asymptotically equivalent to a complete case statistic in their case 3 , and this complete case statistic should thus result in an equivalent test .",
    "finally , @xcite uses imputation together with the minimum distance methodology of @xcite to propose tests for fitting a class of parametric models to the regression function that includes polynomials .",
    "this article is organized as follows .",
    "section  [ sec2 ] provides the theory for the transfer principle .",
    "the key is lemma  [ lm1 ] , which calculates the explicit form of the distribution of a complete case statistic . in section  [ sec3 ] we show that the influence function of the complete case version of an efficient estimator of @xmath54 in the full data partially linear model is the efficient influence function for estimating @xmath54 in the mar model .",
    "similar results are sketched for a partially linear additive model ( see remark  [ rem6a ] ) and a single index model ( see remark  [ rem6b ] ) .",
    "section  [ sec4 ] discusses the test for normality of the errors for the mar model , and derives expansions for the complete case residual - based empirical distribution function . in section  [ sec5 ]",
    "we provide details for the complete case version of the second test about the nonparametric part @xmath56 in  ( [ rho ] ) being constant .",
    "in this section we derive the exact distribution of a complete case statistic in a general setting .",
    "let @xmath112 be a measurable space , and , for each integer @xmath113 , let @xmath114 be a measurable function from @xmath115 into @xmath30 .",
    "let @xmath116 be independent copies of @xmath117 , where @xmath118 is bernoulli with parameter @xmath119 and @xmath120 is a @xmath121-valued random variable .",
    "we denote the conditional distribution of @xmath120 , given @xmath122 by @xmath25 .",
    "let @xmath123 be independent @xmath121-valued random variables with common distribution @xmath25 .",
    "denote the distribution of @xmath124 by @xmath125 .",
    "then , for any borel set @xmath99 , @xmath126 by a _",
    "complete case statistic associated with the sequence @xmath127 _ we mean a statistic @xmath128 of the form @xmath129 where @xmath130 is a constant , @xmath131 denotes the cardinality of @xmath132 and @xmath133 is the vector @xmath134 with @xmath135 the elements of the non - empty subset @xmath136 .",
    "note that the product @xmath137[\\prod_{i \\notin a } ( 1-\\d_i)]$ ] is the indicator function of the event @xmath138 .",
    "thus , @xmath128 equals @xmath139 on this event .",
    "it is now clear that @xmath128 depends on the indicators @xmath140 and only those observations @xmath141 for which @xmath142 .",
    "[ rem1 ] for a measurable function @xmath143 defined on @xmath121 , we define the sequence @xmath144 by @xmath145 .",
    "the complete case statistic associated with @xmath144 is @xmath146 .",
    "[ rem2 ] if @xmath128 is a complete case statistic associated with @xmath127 and @xmath101 is a real number , then @xmath147 is a complete case statistic associated with the sequence @xmath148 .    for the remainder of this section",
    "@xmath128 denotes a complete case statistic associated with @xmath127 and @xmath149 its distribution .",
    "the next lemma calculates @xmath149 explicitly .",
    "[ lm1 ] for every borel subset @xmath99 of @xmath30 , we have @xmath150 with @xmath151 $ ] .",
    "conditioning on @xmath152 yields the identity @xmath153\\ ] ] and , thus , @xmath154 where @xmath155 for non - empty @xmath132 , while @xmath156 .",
    "the desired result is now immediate .",
    "[ rem3 ] lemma  [ lm1 ] has the following interpretation .",
    "the statistic @xmath128 has the same distribution as @xmath157 , where @xmath158 is a binomial random variable with parameters @xmath159 and @xmath160 , independent of @xmath161    from the lemma we immediately obtain the following results .",
    "the following statements hold :    if the sequence @xmath162 is tight , so is the sequence @xmath163",
    ".    if @xmath125 converges weakly to some limit @xmath164 , then @xmath149 converges weakly to the same limit @xmath164 .",
    "if @xmath125 converges weakly to point mass at @xmath165 , then @xmath128 converges in probability to zero .",
    "[ rem4 ] recall that @xmath125 is the distribution of @xmath124 .",
    "thus , by ( b ) , the limiting distribution of @xmath128 equals the limiting distribution of @xmath166 .",
    "this provides the basis for the transfer principle .",
    "[ rem5 ] let @xmath143 and @xmath167 be as in remark  [ rem1 ] .",
    "set @xmath168 .",
    "then @xmath169 is a complete case statistic associated with @xmath170 .",
    "suppose that @xmath171 then , by ( c ) , we have @xmath172 and , consequently , @xmath173 this is the basis for the transfer principle for asymptotically linear statistics .",
    "here we shall show that the expansion ( [ eff - mar ] ) characterizes efficient estimators in the partially linear mar model . for this",
    "we only need to show that the influence function appearing in ( [ eff - mar ] ) is the efficient influence function for estimating @xmath54 in this model .",
    "we formulate this as the main result of this section ; see lemma  [ lm2 ] . by the discussion in the",
    ", we must require that the conditional distribution @xmath69 of @xmath59 , given @xmath10 , satisfies the assumptions ( g1 ) and ( g2 ) .",
    "this is crucial for the transfer principle to apply , and holds if the function @xmath77 is bounded away from zero , as we shall show first .",
    "[ rem6a ] consider the conditional distribution @xmath69 of @xmath59 given @xmath10 .",
    "then @xmath69 satisfies the properties ( g1 ) and ( g2 ) if @xmath77 is bounded away from zero : it is easy to check that @xmath69 has density @xmath174 with respect to @xmath61 , where @xmath175 $ ] . if @xmath176 for some positive constant @xmath177 , then @xmath178\\ ] ] for all @xmath179 and , therefore , @xmath180 from these inequalities we conclude that @xmath69 inherits the properties ( g1 ) and ( g2 ) from @xmath61 if @xmath77 is bounded away from zero .",
    "[ lm2 ] suppose the model ( [ rho ] ) holds with @xmath56 being twice continuously differentiable and error density having finite fisher information for location .",
    "also assume @xmath77 is bounded away from zero .",
    "then an efficient estimator of the parameter  @xmath54 in the mar model is characterized by ( [ eff - mar ] ) . as a consequence ,",
    "the complete case version of an efficient estimator of the parameter  @xmath54 in the full model is efficient for the mar model .",
    "we rely heavily on the calculations in mller , schick and wefelmeyer ( @xcite ) .",
    "the authors considered the general missing data problem with base observation @xmath181 where @xmath1 and @xmath0 do not have to follow a regression model .",
    "they expressed the joint distribution @xmath182 of @xmath181 via @xmath183 in terms of the distribution @xmath61 of @xmath1 , the conditional probability @xmath184 of @xmath10 given @xmath185 , and the conditional distribution @xmath186 of @xmath0 given @xmath185 . here",
    "@xmath187 denotes the bernoulli distribution with parameter @xmath160 and @xmath188 the dirac measure at @xmath189 .",
    "they showed that the tangent space is the sum of the orthogonal spaces @xmath190 here , the set @xmath191 consists of all real - valued functions @xmath192 satisfying @xmath193 , @xmath194 and for which there is a sequence @xmath195 of distributions fulfilling the model assumptions on @xmath61 and @xmath196 the set @xmath197 consists of real - valued functions @xmath198 with the property @xmath199 for which there is a sequence @xmath200 satisfying the model assumptions on @xmath77 such that @xmath201 finally , the set @xmath202 consists of functions @xmath203 with the properties @xmath204 @xmath205 for all @xmath206 and @xmath207 , and for which there is a sequence @xmath208 satisfying the model assumptions on @xmath24 and @xmath209    in the partially linear regression model ( [ rho ] ) we have @xmath210 and @xmath211 where the density @xmath58 has finite fisher information for location , @xmath54 belongs to @xmath30 and @xmath56 is a smooth function .",
    "for this model @xmath202 consists of the functions @xmath212 with @xmath213 , @xmath214<\\infty$ ] and @xmath215 with @xmath216 and@xmath217 . since we are interested in estimating the finite - dimensional parameter @xmath54 , we introduce the functional @xmath218 now consider @xmath219 with @xmath220 .",
    "then the coordinates of @xmath221 belong to @xmath202 .",
    "thus , we have @xmath222=0 $ ] and @xmath223 $ ] @xmath205 .",
    "note that @xmath4 and @xmath224 are independent , and that we have @xmath225=0 $ ] and @xmath226=j_f$ ] . using this and the definition of @xmath227",
    ", we calculate @xmath228 \\\\ & & \\qquad= e\\bigl[\\delta\\bigl(u-\\mu_1(v)\\bigr ) \\bigl(u^{\\top}a + b(v)\\bigr)\\bigr ] j_f + e\\bigl[\\delta\\bigl(u-\\mu_1(v ) \\bigr)\\bigr ] e\\bigl[\\elf(\\ve)c(\\ve)\\bigr ] \\\\ & & \\qquad = e\\bigl[\\delta\\bigl(u-\\mu_1(v ) \\bigr ) \\bigl(u- \\mu_1(v)\\bigr)^\\top\\bigr ] a j_f.\\end{aligned}\\ ] ] from this we can conclude that the functional @xmath229 is differentiable with canonical gradient @xmath230 of the form @xmath231 \\bigr)^{-1 } \\bigl(u-\\mu_1(v ) \\bigr)\\elf(\\ve ) \\\\ & & \\qquad = \\frac{\\delta}{e[\\delta ] } \\bigl ( j_f e\\bigl[\\bigl(u- \\mu_1(v)\\bigr ) \\bigl(u-\\mu_1(v)\\bigr)^{\\top } | \\delta=1\\bigr ] \\bigr)^{-1 } \\bigl(u-\\mu_1(v)\\bigr)\\elf(\\ve).\\end{aligned}\\ ] ] this canonical gradient is the influence function of an efficient estimator of @xmath54 .",
    "now use the fact that @xmath232 equals @xmath233 and @xmath234 $ ] equals @xmath235 to see that this is indeed the characterization ( [ eff - mar ] ) .    [ remremextn ] the above efficiency result extends in a straightforward manner to the case when @xmath52 is higher dimensional .",
    "it also extends to the partially linear additive model @xmath236 where @xmath237 takes values in the unit square @xmath60 ^ 2 $ ] and has a density that is bounded and bounded away from zero on the unit square .",
    "let @xmath61 now denote the joint distribution of @xmath238 .",
    "assume that the matrix @xmath239^{\\top}$ ] , with @xmath240 is positive definite , and that @xmath77 is bounded away from zero .",
    "in the present model the space @xmath241 consists of functions of the form @xmath242 where @xmath243 $ ] is finite . the role of @xmath244 is now played by @xmath245 where @xmath246 minimizes @xmath247 $ ] with respect to functions @xmath248 and @xmath249 from @xmath60 $ ] into @xmath30 such that @xmath250 $ ] and @xmath251 $ ] are finite .",
    "the efficient influence function is @xmath252 } \\bigl(j_f e\\bigl [ \\bigl(u-\\tilde\\nu_1(v_1 ) -\\tilde\\nu_2(v_2 ) \\bigr ) \\bigl(u-\\tilde\\nu_1(v_1 ) -\\tilde \\nu_2(v_2)\\bigr)^{\\top}|\\delta=1\\bigr ] \\bigr)^{-1 } \\\\ & & \\qquad { } \\times\\bigl(u-\\tilde\\nu_1(v_1)-\\tilde \\nu_2(v_2)\\bigr)\\ell_f(\\ve).\\end{aligned}\\ ] ] by the transfer principle , this is the influence function of a complete case version of an estimator with influence function @xmath253 \\bigr)^{-1}\\\\ & & \\qquad{}\\times \\bigl(u-\\nu_1(v_1)- \\nu_2(v_2)\\bigr)\\ell_f(\\ve)\\end{aligned}\\ ] ] in the full model , where @xmath254 minimizes @xmath255 $ ] over functions @xmath248 and @xmath249 as above .",
    "@xcite constructed estimators in the full model that have the latter influence function . in particular , he established their efficiency by showing that the above influence function is indeed the efficient influence function in the full model .",
    "[ rem6b ] in the above we have shown that for the partially linear mar model ( with a possibly additive smooth function ) an efficient estimator of the parameter @xmath54 can be obtained as the complete case version of an efficient estimator in the full model .",
    "this is typically also true for other more general semiparametric regression models and can be verified along the above lines .",
    "we sketch this for the following single index model .",
    "in this model @xmath256 with one - dimensional @xmath52 , @xmath55-dimensional @xmath51 , @xmath257 and twice continuously differentiable @xmath56 .",
    "assume again that @xmath77 is bounded away from zero .",
    "the space @xmath202 for this model consists of functions @xmath258 with @xmath213 , @xmath259<\\infty$ ] and @xmath260 as before .",
    "for this we must require that @xmath261 $ ] is finite .",
    "now one works with @xmath262 and @xmath263 , and obtains the canonical gradient @xmath264 } ( j_f w_1)^{-1 } \\bigl(u-\\nu_1\\bigl(v+\\vt^{\\top}u\\bigr)\\bigr ) \\rho'\\bigl(v+\\vt^{\\top}u\\bigr ) \\elf ( \\ve)\\ ] ] if @xmath265 $ ] is invertible . by the transfer principle ,",
    "this is the influence function of a complete case version of an estimator with influence function @xmath266 , where @xmath267 $ ] and @xmath268(\\rho'(v+\\vt^{\\top}u))^2]$ ] .",
    "the latter influence function is the efficient gradient for the full model .",
    "indeed , it is the canonical gradient for the case when @xmath10 almost surely .",
    "in this section we shall introduce a test for normal errors which uses the khmaladze transform of the empirical distribution function @xmath269 $ ] , @xmath270 , based on residuals @xmath271 .",
    "goodness - of - fit tests for the full model based on that transform were discussed in khmaladze and koul ( @xcite , @xcite ) for parametric and nonparametric regression , and by msw for the partially linear regression model considered here . due to the transfer principle , it is now straightforward to adapt the approach by msw to the mar model , which is what we will do here for a simple illustration of the method . note that msw consider the more complex case where @xmath52 is a covariate _",
    "vector_.    first , we briefly sketch the approach for the full model . to avoid additional assumptions , we estimate @xmath54 and @xmath56 using a least squares approach with the trigonometric basis .",
    "this is discussed in msw , section 4 , for an additive regression function , that is , with @xmath272 .",
    "( here we have @xmath273 . ) for @xmath274 we set @xmath275 our estimator of the regression function @xmath276 is then @xmath277 where @xmath278 and @xmath279 minimizes @xmath280 with respect to @xmath281 . for @xmath282",
    "the error @xmath283 is estimated by the residual @xmath284 we also need the normalized residuals @xmath285 , where @xmath286 is the square root of @xmath287 .",
    "assume for the remainder of this section that @xmath58 has finite fisher information for location and finite fourth moment .",
    "this assumption is met by the normal density .",
    "it then follows from msw , theorem 4.1 and remark 4.2 , that with @xmath288 we have the uniform stochastic expansions @xmath289 - \\1 [ \\ve_j \\leq t ] - f(t ) \\ve_j \\bigr ) \\biggr| = o_p(1)\\ ] ] and @xmath290 - \\1[z_j\\le t ] - f_*(t ) \\biggl(z_j + t\\frac{z_j^2 - 1}{2 } \\biggr ) \\biggr ) \\biggr| = o_p(1),\\ ] ] where @xmath291 denotes the density of the normalized errors @xmath292 .",
    "write @xmath293 for the standard normal density . in terms of the density @xmath291 ,",
    "the null hypothesis is @xmath294 msw proposed the test statistic @xmath295 - h(t \\wedge\\hat z_j ) h(\\hat z_j ) \\bigr ) \\biggr|,\\ ] ] with @xmath296 \\\\[-8pt ] \\nonumber h(t ) & = & \\int_{-\\infty}^t h^{\\top}(x ) \\gamma^{-1}(x ) \\phi(x ) \\,dx.\\end{aligned}\\ ] ] this is a version of the martingale transform test of @xcite for fitting an error distribution in nonparametric regression .",
    "msw showed that under the null hypothesis the test statistic @xmath17 converges in distribution to @xmath102 , which is the supremum of a standard brownian motion given in ( [ z ] ) .",
    "this holds for every distribution function @xmath61 satisfying ( g1 ) and ( g2 ) .",
    "since @xmath4 and @xmath297 are independent under the mar assumption , the conditional distribution of @xmath298 , given @xmath10 , is given by @xmath299 , where @xmath69 is the conditional distribution of @xmath59 , given @xmath10 .",
    "thus , if @xmath69 satisfies ( g1 ) and ( g2 ) , then the transfer principle applies and yields the same limiting distribution for the complete case version @xmath20 of @xmath17 , where @xmath300 - h(t\\wedge\\hat z_{jc } ) h(\\hat z_{jc } ) \\bigr ) \\biggr|.\\end{aligned}\\ ] ] here @xmath301 are the complete case versions of the normalized residuals and are defined by @xmath302 with @xmath303 and @xmath304 the square root of @xmath305 , while @xmath306 are the least squares estimators minimizing @xmath307    the transfer principle for asymptotically linear statistics also provides complete case versions of the expansions ( [ uu1 ] ) and ( [ uu2 ] ) from above .",
    "the first expansion becomes @xmath308 - \\1 [ \\ve_j \\leq t ] - f(t ) \\ve_j \\bigr ) \\biggl| = o_p(1),\\ ] ] and the second expansion becomes @xmath309 - \\1[z_j\\le t ] - f_*(t ) \\biggl(z_j + t\\frac{z_j^2 - 1}{2 } \\biggr ) \\biggr)\\biggr | = o_p(1).\\vspace*{-2pt}\\ ] ]",
    "in this section we address testing whether the function @xmath56 in the partially linear mar model is constant . in the previous section we demonstrated how",
    "the transfer principle can be used to adapt a known test for the full model to the mar model .",
    "we now show how to develop a test procedure for the mar model when no counterpart to the full model exists .",
    "our approach is to first develop a procedure for the full model , and then to apply the transfer principle .",
    "our test statistic is inspired by that in stute , xu and zhu ( @xcite ) .    under the null hypothesis",
    "the partially linear model reduces to the linear regression model @xmath310 , where @xmath101 is an unknown constant , that is , we have @xmath311 to simplify notation , we introduce @xmath312 and @xmath313",
    ". then we can write the model under the null hypothesis as @xmath314 .",
    "it follows from ( g2 ) that the dispersion matrix @xmath315 of @xmath51 is positive definite . from this",
    "we immediately see that the matrix @xmath316 = \\left[\\matrix { 1 & e \\bigl[u^{\\top}\\bigr ] \\vspace*{2pt } \\cr e[u ] & e\\bigl[uu^{\\top } \\bigr ] } \\right]\\vspace*{-1pt}\\ ] ] is also positive definite .",
    "thus , the least squares estimator @xmath317 of @xmath312 is root-@xmath159 consistent under the null hypothesis , as it satisfies @xmath318    now let @xmath109 denote a continuous non - constant function on @xmath60 $ ] . introduce the least squares estimator @xmath319 for regressing the responses @xmath108 on the design vectors  @xmath320 , so that @xmath319 minimizes @xmath321 set @xmath322 , @xmath323 , and @xmath324 , @xmath282 .",
    "our test statistic in the full model is @xmath325 \\biggr|.\\vspace*{-1pt}\\ ] ] as in stute , xu and zhu ( @xcite ) , we have the following result .    [ lm3 ]",
    "suppose the null hypothesis holds and @xmath58 is uniformly continuous .",
    "then @xmath17 converges in distribution to @xmath326 , where @xmath111 denotes a standard brownian bridge .",
    "set @xmath327 where @xmath328 minimizes @xmath329 $ ] .",
    "let @xmath330)]$ ] .",
    "then it is easy to check that @xmath331- \\rho_g^{\\top}\\bigl(u - e[u]\\bigr ) \\\\ & = & \\h(v)-e\\bigl[\\h(v)\\bigr]-\\rho_g^{\\top } \\bigl ( \\mu_g(v)-e[u]\\bigr ) - \\rho_g^{\\top } \\bigl(u- \\mu_g(v)\\bigr).\\end{aligned}\\ ] ] note also that @xmath109 being non - constant on @xmath60 $ ] and @xmath52 having a positive density on @xmath60 $ ] implies @xmath332 has a positive variance . these facts together with @xmath65 being positive definite guarantee that @xmath333=\\var(\\h(v)-\\rho_g^{\\top } \\mu_g(v))+ \\rho_g^{\\top } w_g\\rho_g$ ] is positive .",
    "next , let @xmath244 be a measurable function such that @xmath334 $ ] is finite and assume @xmath58 is uniformly continuous . then theorem 2.2.4 of @xcite yields @xmath335 - \\1[\\ve_j \\le t]\\bigr ) -f(t ) e\\bigl[g(x)z^{\\top}\\bigr](\\hat\\beta-\\beta)\\biggr | = o_p\\bigl(n^{-1/2}\\bigr).\\ ] ] from this fact we obtain @xmath336-\\1[\\ve_j\\le t ] \\bigr ) -f(t ) \\hat d(\\hat\\beta-\\beta ) \\biggr|= o_p\\bigl(n^{-1/2 } \\bigr),\\ ] ] where @xmath337- \\hat\\gamma^{\\top } e \\bigl[zz^{\\top}\\bigr ] = e\\bigl[\\h_g(v)z^{\\top}\\bigr]+ o_p(1).\\ ] ] in view of the identities @xmath338=0 $ ] and @xmath339 , we can conclude @xmath340-\\frac1n \\sum _ { j=1}^n r_j\\bigl(\\1[\\ve_j \\le t]-f(t)\\bigr ) \\biggr|=o_p\\bigl(n^{-1/2}\\bigr).\\ ] ] writing @xmath341 , we derive the expansions @xmath342-f(t)\\bigr ) \\biggr| & = & o_p\\bigl(n^{-1/2 } \\bigr ) , \\\\",
    "\\frac1n \\sum_{j=1}^n \\bigl(r_j-\\h_g(v_j)\\bigr)^2 \\le \\|\\hat\\gamma-\\gamma_g\\|^2 \\frac1n \\sum _ { j=1}^n \\|z_j\\|^2 & = & o_p(1),\\end{aligned}\\ ] ] and therefore obtain @xmath343 + o_p(1)$ ] .",
    "the above derivations in turn yield @xmath344 - \\frac{1}{\\sqrt{n } } \\sum _ { j=1}^n \\h^*_g(v_j ) \\bigl(\\1[\\ve_j\\le t]-f(t)\\bigr ) \\biggr| = o_p(1),\\ ] ] with @xmath345^{1/2}$ ] . since , again by theorem 2.2.4 of @xcite , the process @xmath346-f(t ) \\bigr),\\qquad -\\infty\\le t\\le \\infty,\\ ] ] converges in @xmath347)$ ] to a time - changed brownian bridge @xmath348 , we conclude that @xmath17 has the desired limiting distribution .    the complete case version of @xmath17 is given by @xmath349 \\biggr| \\bigg/ \\biggl(\\frac1n \\sum _ { j=1}^n\\dj r_{jc}^2 \\biggr)^{1/2},\\ ] ] with @xmath350 , @xmath351 , @xmath352 by the transfer principle",
    ", the limiting distribution of @xmath20 under the null hypothesis will be that of @xmath353 from the above lemma , as long as @xmath58 is uniformly continuous and  @xmath69 satisfies ( g1 ) and ( g2 ) .",
    "[ remgen ] the above is easily extended to cover testing for other parametric forms for @xmath56 .",
    "for example , we can test whether @xmath56 is linear , @xmath354 . in this case",
    "we proceed as above , but with the role of @xmath355 now played by the vector @xmath356 and with @xmath357 chosen to be nonlinear .",
    "the authors would like to thank the two reviewers for their constructive comments , which have helped to improve the paper ."
  ],
  "abstract_text": [
    "<S> this paper gives a general method for deriving limiting distributions of complete case statistics for missing data models from corresponding results for the model where all data are observed . </S>",
    "<S> this provides a convenient tool for obtaining the asymptotic behavior of complete case versions of established full data methods without lengthy proofs .    </S>",
    "<S> the methodology is illustrated by analyzing three inference procedures for partially linear regression models with responses missing at random . </S>",
    "<S> we first show that complete case versions of asymptotically efficient estimators of the slope parameter for the full model are efficient , thereby solving the problem of constructing efficient estimators of the slope parameter for this model . </S>",
    "<S> second , we derive an asymptotically distribution free test for fitting a normal distribution to the errors . </S>",
    "<S> finally , we obtain an asymptotically distribution free test for linearity , that is , for testing that the nonparametric component of these models is a constant . </S>",
    "<S> this test is new both when data are fully observed and when data are missing at random .    , </S>"
  ]
}