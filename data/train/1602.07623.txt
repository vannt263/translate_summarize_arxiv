{
  "article_text": [
    "the design of today s and future networks is characterised by a paradigm shift , from a host - centric communication architecture , towards an information centric networking ( icn ) one .",
    "the focus is on information itself , and how this can be best accessed @xcite . within this setting , network nodes are equipped with storage capacity , where data objects can be temporarily cached . in this way , information can be made available close to the user , it can be retrieved with minimum delay , and possibly with a quality adaptable to the users preferences , as envisioned for example in cases of multimedia files .",
    "the principal benefit of the approach is the reduction of traffic flow at the core network , by serving demands from intermediate nodes @xcite .",
    "this further results in congestion avoidance and a better exploitation of the backbone resources .",
    "the edge - nodes constitute a very important part of the architecture , since it is where the users directly have access to .",
    "when these nodes are equipped with storage capability , so that users can retrieve their data objects directly from them , average download path length can be minimised @xcite .",
    "caching at the edge definitely offers a potential increase in performance of icns , it comes however at the cost of a distributed implementation and management over a very vast area , where edge nodes are placed .",
    "if these nodes are chosen to be the base stations and small cells of a heterogeneous network @xcite , it is fairly clear that thousands of nodes within each city are considered , a number which increases by a factor of hundred ( or more ) if user equipment and other devices are also included as having storage potential .",
    "the large number of nodes , together with the relatively small memory size installed on each one , creates big challenges related to their cache management .",
    "we consider the wireless edge of a content centric network , which consists of a set of transmitting nodes taking fixed positions on a planar area , and a set of users dynamically arriving at this area and asking for service .",
    "the set of transmitters can refer to base stations ( bss ) of a cellular network , small stations of heterogeneous networks , wifi hotspots , or any other type of wireless nodes that can provide access to an arriving user who demands for a specific data object .",
    "a user can be covered by multiple of these nodes , but he / she will _",
    "choose only one _ to be served from .",
    "all nodes are equipped with memory of size @xmath0 objects , which offers the possibility to cache a fraction of the existing data .",
    "when the user s request is found in the cache of some covering station , then the user is served directly by this one .",
    "otherwise , the request is retrieved from the core network .",
    "an important question is _ how to maximise the hit probability _ , by managing the available edge - memories .",
    "the _ hit probability _ , is defined as the probability that a user will find her / his demand cached in the memory of one of the cells she / he is covered from . by _ managing _ , we mean to decide on : which objects to install in each cache ?",
    "how to update the cache inventories over time ?",
    "given the possibility for multi - coverage , cache management should target two , not necessarily conflicting , goals : on the one hand make popular objects , requested by the large bulk of demands , generously available at many geographical locations . on the other , make good use of multi - coverage , by filling the memory caches in a way that a user has access to as many different objects as possible , so that also less popular contents are served directly by the caches .",
    "additionally , since - as explained above - wireless nodes ( bss ) are scattered over a very large area and are of considerable number , related operations should be distributed as in @xcite , and centralised solutions should be avoided .      there exists a variety of cache placement policies that apply to _ single caches _",
    ", when no coverage overlap is considered .",
    "these include the least frequently used ( lfu ) , the least recently used ( lru ) , and their variations .",
    "specifically lru has been extensively studied and approximations to the hit probability have been proposed , like the one from dan and towsley @xcite .",
    "che et al proposed in 2002 @xcite a decomposition and a simple approximation for the single - lru under the independent reference model ( irm ) @xcite , which results in an analytical formula for the hit probability with excellent fit to simulations .",
    "this fitness is theoretically explained by fricker et al in @xcite .",
    "application of the che approximation under more general traffic conditions , to variations of the lru for single caches as well as networks of caches , is provided by martina et al @xcite . in that work , and",
    "further in elayoubi and roberts @xcite , it is shown that for mobile networks , application of pre - filtering improves the performance of lru",
    ".    there can be strong dependencies between content demands , objects can have a finite lifespan , and new ones can appear anytime .",
    "these phenomena constitute the _ temporal locality _ , not captured from the irm model . such type of traffic was studied for lru initially by jelenkovi and radovanovi @xcite , and recently using also statistics from user measurements , by traverso et al @xcite and olmos et al @xcite .",
    "the problem of optimal content placement , when network areas are covered by more than one station has also been recently studied in the literature .",
    "a number of pro - active caching policies have been proposed , where the cache inventories are pre - filled by content , based on knowledge of the content popularity distribution and additional network - related information .",
    "golrezaei et al @xcite find the optimal content placement that maximises hit probability , when full network information ( popularity , node and user positions ) is available .",
    "they formulate a binary optimisation problem and propose approximation and greedy algorithms for its solution . using reduced information ( content popularity , coverage probability ) , baszczyszyn and giovanidis @xcite provide a randomised strategy that maximises the hit probability .",
    "poularakis et al .",
    "@xcite formulate and solve the joint content placement and user association problem that maximises the fraction of content served by the caches of the edge - nodes .",
    "araldo et al .",
    "@xcite propose joint cache sizing / object placement / path selection policies that consider also the cost of content retrieval .",
    "recently , naveen et al .",
    "@xcite have formulated the problem in a way to include the bandwidth costs , and have proposed an online algorithm for its solution .",
    "further distributed replication strategies that use different system information are proposed by borst et al @xcite , and also by leconte et al @xcite .",
    "the problem of optimal request routing and content caching for minimum average content access delay in heterogeneous networks is studied by dehghan et al in @xcite .    the cache management problem for cellular networks",
    "has also been approached using point process modelling of the network node positions .",
    "bastug et al .",
    "@xcite find the outage probability and content delivery rate for a given cache placement .",
    "furthermore , tamoor - il - hassan et al @xcite find the optimal station density to achieve a given hit probability , using uniform replication .",
    "this work has the following contributions to the subject of caching at the network edge .",
    "@xmath1 it takes geometry explicitly into consideration for the analysis of caching policies . specifically",
    ", it investigates a three - dimensional model ( two - dimensional space and time ) .",
    "in this , stations have a certain spatial distribution ( modelled by point processes ) and coverage areas may overlap , allowing for multi - coverage .",
    "furthermore , it is a dynamic model , where users with demands arrive over time at different geographic locations ( sec .",
    "[ sec:3_network ] ) .",
    "@xmath1 it introduces ( sec . [ sec:2_cache ] ) a family of decentralised caching policies , which exploit multi - coverage , called _ spatial multi - lru_. specifically , two variations of this family are studied , namely multi - lru - one and -all .",
    "these policies constitute an extension of the classical single - lru , to cases where objects can be retrieved by more than one cache .",
    "the work investigates how to best choose the actions of update , insertion and eviction of content in the multiple caches and how this can be made beneficial for the performance .",
    "@xmath1 the hit probability of the new policies , is analysed using the che approximation ( sec .",
    "[ sec:4_che ] ) .",
    "two additional approximations made here , namely the cache independence approximation ( cia ) for multi - lru - one , and the cache similarity approximation ( csa ) for multi - lru - all , allow to derive simple analytical formulas for the spatial dynamic model , under irm traffic .",
    "@xmath1 verification for the che - like approximations and further comparison of the multi - lru policies , with other ones from the literature are provided in sec .",
    "[ sec:5_simul ] by simulations .",
    "the comparison considers policies both with distributed and with centralised implementation , that use various amount of network information . for irm ,",
    "the multi - lru - one outperforms the -all variation . in sec [ sec:5_4_temploc ]",
    "the policies are evaluated for traffic with temporal locality , where it is shown that multi - lru - all can perform better than -one .",
    "caching policies can profit from the availability of system information .",
    "such information can be related to user traffic , node positions and coverage areas , as well as the possibility for a bs to have knowledge over the cache content of its neighbours . in general , _ the more the available information , the higher the hit - performance _ , if the management policy is adapted to it .    in general , we can group caching policies as follows .",
    "* ( i ) poq ( policies with per - request updates ) : * for these , updates of the cache content are done on a per - request basis and depend on whether the requested object is found or not .",
    "information on file popularity is _ not available_. neither is information over the network structure .",
    "the actions are taken _ locally _ at each node , and are triggered by the user , in other words these policies do not require centralised implementation .",
    "the lru policies belong to this category .",
    "- _ lru : _ it leaves in each cache the @xmath0 most recently demanded objects .",
    "the first position of the cache is called most recently used ( mru ) and the last one least recently used ( lru ) .",
    "when a new demand arrives , there are two options .",
    "( a. _ update _ ) the object demanded is already in the cache and the policy updates the object order by moving it to the mru position . or , ( b. _ insertion _ ) the object is not in the cache and it is inserted as new at the mru position , while the object in the lru position is _ evicted_. in this work we will call this policy , _ single - lru_.    - _ q - lru : _ it is a variation of the single - lru , with a difference in the insertion phase . when the object demanded is not in the cache , it is inserted with probability @xmath2 .",
    "the eviction and order updates are the same as before .    *",
    "( ii ) pop ( policies with popularity updates ) : * here , exact information over the content popularities is available .",
    "these are static policies , for which the content of caches is updated in an infrequent manner , depending on the popularity changes of the catalogue @xmath3 .",
    "the following three belong to this category .",
    "- _ lfu : _ the policy statically stores in each cache the @xmath0 most popular contents from the set of all existing ones @xmath3 .",
    "lfu is known to provide optimal performance for a single cache under the independent reference model ( irm ) .",
    "the next two pop policies are solutions of optimisation problems , that require a - priori knowledge of more system information additional to popularity .",
    "- _ greedy full information ( gfi ) : _ the policy is proposed in @xcite . it assumes a - priori central knowledge of all station and user positions , their connectivity graph , and the content popularities . using this",
    ", it greedily fills the cache memories of all stations , so that at each step of the iteration , insertion of an object at a cache is the most beneficial choice for the objective function ( hit probability ) .",
    "- _ probabilistic block placement ( pbp ) : _ this policy is found in @xcite and is similar to the gfi , with the difference that it requires less system information : the coverage number probability and the content popularities .",
    "the policy randomly assigns blocks of @xmath0 contents to each cache , in a way that the probability of finding a specific content somewhere in the network comes from the optimal solution of a hit maximisation problem .",
    "pbp has considerably lower computational complexity compared to gfi .",
    "[ [ section ] ]    we propose here a novel family of distributed cache management poq policies , that can profit from multi - coverage .",
    "we name these _ spatial multi - lru _ policies and are based on the single - lru policy presented previously .",
    "the idea is that , since a user can check all the caches of covering bss for the demanded object , and download it from any one that has it in its inventory , cache updates and object insertions can be done in a more efficient way than just applying single - lru independently to all caches .",
    "the multi - lru policies take into account , whether a user has found the object in _ any _ of the covering stations , and each cache adapts its action based on this information .",
    "most importantly , it is the user who triggers a cache s update / insertion action , and in this way she / he indirectly informs each cache about the inventory content of its neighbours .",
    "we propose here variations of the multi - lru family , that differ in the number of inserted contents in the network , after a missed content demand .",
    "differences appear also in the update phase . @xmath1",
    "* multi - lru - one : * action is taken only in _",
    "one _ cache out of @xmath4 .",
    "( a. update ) if the content is found in a non - empty subset of the @xmath4 caches , only one cache from the subset is updated .",
    "( b. insertion ) if the object is not found in _ any _ cache , it is inserted only in one .",
    "this one can be chosen as the cache closest to the user , or a random cache , or one from some other criterion .",
    "( in this work , we will use the choice of the _ closest _ node , to make use of the spatial independence of poisson traffic ) .",
    "@xmath1 * multi - lru - all : * insertion action is taken in _ all _ @xmath4 caches .",
    "( a. update ) if the content is found in a non - empty subset of the @xmath4 caches , all caches from this subset are updated .",
    "( b. insertion ) if the object is not found in _ any _ cache it is inserted in all @xmath4 .    we can also propose another variation based on q - lru .",
    "@xmath1 * q - multi - lru - all : * this variation differs from the multi - lru - all only in the insertion phase .",
    "the object is inserted in each cache with probability @xmath2 .",
    "the motivation behind the different variations of the multi - lru policies is the following .",
    "when a user has more than one opportunity to be served due to multi - coverage , she / he can benefit from a larger cache memory ( the sum of memory sizes from covering nodes . here",
    "we assume that the user is satisfied as long as she / he is covered , without preference over a specific station ) .",
    "in this setting , the optimal insertion of new content and update actions are not yet clear .",
    "if multi - lru - one is applied , a single replica of the missed content is left down in one of the @xmath5 caches , thus favouring diversity among neighbouring caches .",
    "if multi - lru - all is used , @xmath4 replicas are left down , one in each cache , thus spreading the new content over a larger geographic area ( the union of @xmath4 covering cells ) , at the cost of diversity .",
    "q - multi - lru - all is in - between the two , leaving down a smaller than @xmath4 number of replicas .",
    "a - priori , it is unclear which one will perform better with respect to hit probability .",
    "the performance largely depends on the type of incoming traffic . for",
    "fixed object catalogue and stationary traffic , diversity in the cache inventories can be beneficial , whereas for time - dependent traffic with varying catalogue , performance can be improved when many replicas of the same object are available , before its popularity perishes . in this work",
    "the main focus will be on spatial irm input traffic , but a short evaluation of the policies under traffic with temporal locality will also be provided .",
    "for the analysis , the positions of transmitters coincide with the atoms from the realisation of a 2-dimensional _ stationary _ point process ( pp ) , @xmath6 , indexed by @xmath7 , with intensity @xmath8 in @xmath9 $ ] . in this setting , the type of pp can be general , however we consider here :      - a _ square lattice _",
    "@xmath15 , @xmath16 , whose nodes constitute a square grid with edge length @xmath17 , randomly translated by a vector @xmath18 that is uniformly distributed in @xmath19 ^ 2 $ ] ( to make @xmath20 stationary ) .",
    "its intensity is equal to @xmath21 .",
    "there are two different planar areas ( _ cells _ ) associated with each atom ( bs ) @xmath22 .",
    "the first one is the _ voronoi cell _ @xmath23 .",
    "given a pp , the voronoi tessellation divides the plane into _ non - overlapping _ planar subsets , each one associated with a single atom .",
    "a planar point @xmath24 belongs to @xmath25 , if atom @xmath22 is the closest atom of the process to @xmath24 . in other words , @xmath26 .",
    "the second one is the _ coverage cell _ @xmath27 .",
    "each transmitter node @xmath28 has a possibly random area @xmath27 of wireless coverage associated with it .",
    "when users arrive inside the coverage cell of @xmath22 they can be served by it , by downlink transmission . in general @xmath27",
    "is different from @xmath25 .",
    "coverage cells can overlap , so that a user at a random location may be covered by multiple bss , or may not be covered at all .",
    "the total coverage area from all bss with their coverage cells is @xmath29 ( see ( * ? ? ?",
    "* ch.3 ) ) . due to stationarity of the pp @xmath30",
    ", any planar location @xmath31 can be chosen as reference for the performance evaluation of the wireless model .",
    "this is called the _ typical location _ @xmath32 , and for convenience we use the cartesian origin @xmath33 .",
    "because of the random realisation of the bs positions and the random choice of the reference location @xmath32 , the number of bs cells covering @xmath32 is also random .    the _ coverage number _ @xmath34 ( as in @xcite , @xcite ) is the number of cells that covers the typical location .",
    "it is a random variable ( r.v . ) that depends on the pp @xmath30 and the downlink transmission scheme .",
    "it has mass function @xmath35 , & & m=0,1,\\ldots , m,\\end{aligned}\\ ] ] where @xmath36 .",
    "it holds , @xmath37    the choice of the coverage model determines the shape of the coverage cells and consequently the values of the coverage probabilities @xmath38 . in this work",
    "the choice of @xmath27 is left to be general . for the evaluation ,",
    "specific models are considered .",
    "special cases include : ( 1 ) the _ @xmath39 model _ and ( 2 ) the _ @xmath40 or boolean model_. both models consider the coverage cell @xmath27 of @xmath22 , as the set of planar points for which the received signal quality from @xmath22 exceeds some threshold value @xmath41 .",
    "the motivation is that t is a predefined signal quality , above which the user gets satisfactory quality - of - service .",
    "the difference between these two is that the @xmath39 model refers to networks with interference ( e.g. when bss serve on the same ofdma frequency sub - slot ) , whereas the @xmath40 model , to networks that are noise - limited ( e.g. by use of frequency reuse , neighbouring stations do not operate on the same bandwidth ) . for the boolean model",
    "the @xmath27 is a ball @xmath42 of fixed radius @xmath43 centred at @xmath22 .",
    "it coincides with the @xmath40 model , when no randomness of signal fading over the wireless channel is considered ( or when an equivalence - type argument is used to transform the analysis of networks with random fading into equivalent ones without it , as in @xcite ) .",
    "a more detailed presentation of the different coverage models can be found in appendix [ app : a ] .",
    "each user served from the network is assumed to arrive independently at some planar location , stay there during service and then leave .",
    "we model the users by a _ homogeneous space - time _ ppp in @xmath44 , @xmath45 , where @xmath46 takes values on the euclidean plane , and the time @xmath47 of arrival occurs at some point on the infinite time axis .",
    "the ppp intensity is @xmath48 in @xmath49 $ ] .",
    "service time is considered fixed and equal to unity but it will not play any role in the analysis .",
    "given a planar area @xmath14 , the arrival rate of users in this area is equal to @xmath50 in @xmath51 $ ] .",
    "the time between two consecutive arrivals in @xmath14 is exponentially distributed with mean @xmath52 @xmath53 $ ] and all users within the area take their positions independently and uniformly .",
    "each user arrives with a request for a specific data object . in this work ,",
    "we follow the so - called independent reference model ( irm ) @xcite , according to which ( i ) the catalogue of available objects , denoted by @xmath3 , has finite size @xmath54 .",
    "( ii ) the probability @xmath55 that a user requests object @xmath56 ( i.e. the object _ popularity _ ) is constant ( does not vary over time ) , known , and independent of all past requests . in this way , the sequence of generated requests in space and time is i.i.d .. we additionally consider that all objects have the same size , normalised to 1 .",
    "cases of unequal size will not be treated in this work , but we can always assume that each file can be divided into chunks of equal size , so the same analysis can still be applied .",
    "objects in @xmath3 are ordered by popularity : @xmath57 is the most popular , @xmath58 the second most popular and so on .",
    "the popularity of @xmath59 is @xmath60 , and to be consistent with the ordering , we also have @xmath61 . for every popularity distribution it obviously holds , @xmath62    without loss of generality , we will consider ( especially in the simulations ) that the distribution has a zipf probability mass function , although the analysis holds for general @xmath63 .",
    "this is motivated by traffic measurements showing that data - object popularity in the www follows a power law @xcite , @xcite . in such case ,",
    "the probability that a user asks for @xmath59 is equal to @xmath64 , @xmath65 . here",
    ", @xmath66 is the zipf exponent , often chosen as @xmath67 , so that @xmath68 .",
    "the normalisation factor is equal to @xmath69 .    in order to incorporate the object request process in the analysis",
    ", we relate to each atom @xmath70 of the user process @xmath71 a _ mark _ @xmath72 .",
    "each mark @xmath72 is an independent realisation of the random variable @xmath73 ( and independent of location and time ) taking as values the indices of the objects @xmath56 , and has distribution @xmath63 . in this way",
    ", we define the _ iid marked ppp _",
    "@xmath74 on @xmath75 .",
    "a consequence of the independent marking , is that the users that request object @xmath56 form a homogeneous space - time ppp with intensity @xmath76 @xmath49 $ ] , which results from an independent thinning of @xmath71 .",
    "the way we have modelled user traffic ( using irm ) ignores temporal and/or spatial correlations in the sequence of user requests , since it assumes independence in all dimensions . in reality",
    "however , when an object is requested by a user , it is more likely to be requested again at some near future in a neighbouring location .",
    "this is called time - locality @xcite , @xcite and space - locality @xcite .",
    "the presented pp model has the flexibility to be adapted to such traffic behaviour",
    ". we will not give much details about this type of traffic in this paper ( the reader is referred to the related references ) .",
    "some first simulations for the policies under study are however provided in sec .",
    "[ sec:5_4_temploc ] . further research on this is the subject of our ongoing work .",
    "we consider the case where a cache memory of size @xmath77 is installed and available on each transmitter node @xmath22 of @xmath30 .",
    "the memory inventory of node @xmath22 at time @xmath78 is denoted by @xmath79 and is a ( possibly varying over time ) subset of @xmath3 , with number of elements not greater than @xmath77 .",
    "the accuracy of the approximations in the two - cache network is shown in fig.[che2cache ] . the che - cia approximation for multi - lru - one - although not accurate - performs",
    "reasonably well in the two - cache network .",
    "the che - csa approximation for the multi - lru - all , is exact ."
  ],
  "abstract_text": [
    "<S> this article introduces a novel family of decentralised caching policies , applicable to wireless networks with finite storage at the edge - nodes ( stations ) . </S>",
    "<S> these policies are based on the _ least - recently - used _ replacement principle , and are , here , referred to as spatial _ multi - lru_. based on these , cache inventories are updated in a way that provides content diversity to users who are covered by , and thus have access to , more than one station . </S>",
    "<S> two variations are proposed , namely the _ multi - lru - one _ and _ -all _ , which differ in the number of replicas inserted in the involved caches . by introducing spatial approximations </S>",
    "<S> , we propose a che - like method to predict the hit probability , which gives very accurate results under the independent reference model ( irm ) . </S>",
    "<S> it is shown that the performance of multi - lru increases the more the multi - coverage areas increase , and it approaches the performance of other proposed centralised policies , when multi - coverage is sufficient . for irm traffic </S>",
    "<S> multi - lru - one outperforms multi - lru - all , whereas when the traffic exhibits temporal locality the -all variation can perform better .    </S>",
    "<S> [ wireless communication , network topology , distributed networks ] </S>"
  ]
}