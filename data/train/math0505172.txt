{
  "article_text": [
    "in many real life situations one seeks information on the evolution of a ( real - valued ) continuous - time stochastic process @xmath1 in the future . given a trajectory of @xmath2 observed on the interval @xmath3 $ ] , one would like to predict the behavior of @xmath2 on the entire interval @xmath4 $ ] , where @xmath5 , rather than at specific time - points .",
    "an appropriate approach to this problem is to divide the interval @xmath3 $ ] into subintervals @xmath6 $ ] , @xmath7 with @xmath8 , and to consider the stochastic process @xmath9 , where @xmath10 , defined by @xmath11 this representation is especially fruitful if @xmath2 has a seasonal component with period @xmath12 and can be decomposed into locally stationary parts .",
    "it can be also employed if the data are collected as curves indexed by time - intervals of equal lengths ; these intervals may be _ adjacent _ , _ disjoint _ or even _ overlapping _ ( see , for example , ramsay & silverman , 1997 ) .    in the recent literature , practically all investigations to date for this prediction problem",
    "are for the case , where one assumes that an appropriately centered version of the stochastic process @xmath13 is a ( zero - mean ) hilbert - valued _ autoregressive ( of order 1 ) processes _ ( arh(1 ) ) ; the best prediction of @xmath14 given its past history @xmath15 is then given by @xmath16 where @xmath17 is a bounded linear operator associated with the arh(1 ) process .",
    "the adopted approaches mainly differ in the way of estimating the ` prediction ' operator @xmath17 , or its value @xmath18 given @xmath19 ( see , e.g. , bosq , 1991 ; besse & cardot , 1996 ; bosq , 2000 ; antoniadis & sapatinas , 2003 ) .    in many practical situations ,",
    "however , the stochastic process @xmath13 may not have smooth sample paths ( lying in @xmath20 ) or may not be modelled with such an autoregressive structure .",
    "this is the case that we consider in the following development . in particular",
    ", we also assume that the ( real - valued ) continuous - time stochastic process @xmath21 possesses a representation of the form ( [ eqn : zprocess ] ) with short duration ` blocks ' @xmath22 , for @xmath23 .",
    "we then develop a version of prediction via functional regression analysis , in which both the predictor and response variables are functions of time , using a conditioning idea . under mild assumptions on the observed time series , a one time - interval ahead prediction of the ` block ' @xmath14",
    "is obtained by kernel regression of the present ` block ' @xmath24 on the past ` blocks ' @xmath25 .",
    "the resulting predictor will be seen as a weighted average of the past ` blocks ' , placing more weight on ` blocks ' that are similar to the present one .",
    "hence , the analysis is rooted in the ability to find ` similar blocks ' .",
    "considering that ` blocks ' can be quite irregular curves , similarity matching is based on a distance metric on the wavelet coefficients of an appropriate wavelet decomposition of the ` blocks ' . a resampling scheme , involving resampling of the original ` blocks ' to form ` pseudo - blocks ' of the same duration , is then used to calculate pointwise prediction intervals for the predicted ` block ' .",
    "the paper is organized as follows . in section 2 ,",
    "we introduce basic notions for continuous - time prediction , relevant notions on wavelet - based orthogonal expansions of continuous - time stochastic processes , and describe the strictly stationarity and @xmath0-mixing assumptions that are going to be adopted for forecasting . in section 3 , we discuss the extension of the conditioning approach to the one time - interval ahead prediction .",
    "resampling - based pointwise prediction intervals are presented in section 4 . in section 5",
    ", we illustrate the usefulness of the proposed functional wavelet - kernel approach for continuous - time prediction by means of three real - life datasets that were collected from different arenas .",
    "we also compare the resulting predictions with those obtained by two other methods in the literature , in particular with a smoothing spline method and with the sarima model .",
    "some concluding remarks are made in section  6 .",
    "proofs and auxiliary results are compiled in the appendix .",
    "let @xmath26 be a probability space , rich enough so that all random variables considered in the following development can be defined on this space , and let @xmath21 be a ( real - valued ) continuous - time stochastic process defined on this space .",
    "motivated by applications to prediction and forecasting , it is supposed that the time - interval on which the continuous - time stochastic process is observed is divided into intervals of constant - width @xmath27 so that , from @xmath2 , a functional - valued random variable sequence @xmath28 is constructed according to the representation ( [ eqn : zprocess ] ) , i.e. , @xmath29 in the sequel , we regard the @xmath30 s as elements of a certain ( semi-)normed functional linear space @xmath20 equipped with ( semi-)norm @xmath31 and its borel @xmath32-field @xmath33 . recall that our aim is a one - ahead time interval prediction which , under the above notation , is reduced in studying a corresponding problem for the @xmath20-valued time series @xmath34 . in what follows ,",
    "we assume that the time series @xmath13 is strictly stationary with @xmath35 .",
    "if the time series @xmath13 is not stationary , it is assumed that it has been transformed to a stationary one by a preprocessing procedure , and the procedures that we are going to develop hold for the resulting stationary time series .    in practice ,",
    "the random curves @xmath30 are only known at discretized equidistant time values , say @xmath36 .",
    "thus , they must be approximated by some @xmath20-valued functions , which in our case will be realized by first expanding the @xmath30 s into a wavelet basis and then estimating consistently the coefficients from the observed discrete data .",
    "we may have used a fixed spline basis or a fourier basis instead but there are some good reasons to prefer wavelet bases .",
    "when @xmath37 is fixed , using spline interpolation could make sense if the sample paths exhibits a uniformly smooth temporal structure thus not requiring any smoothing to stabilize the variance .",
    "when @xmath37 is large , a necessary smoothing step in the spline approximation would be necessary and since the smoothing is global this would not be appropriate when the sample paths are composed of different temporal structures .",
    "the same remarks apply for a fourier basis . on the contrary ,",
    "when @xmath37 is fixed and the sample paths are continuous , one may choose an interpolation wavelet basis and the wavelets coefficients are computed directly from the sampled values instead of inner product integrals .",
    "when @xmath30 are observed either continuously or on a very fine discretization grid , then wavelets can be used successfully for compression of a continuous - time stochastic process , in the sense that the sample paths can be accurately reconstructed from a fraction of the full set of wavelet coefficients . whatever the setting is , the wavelet decomposition of the sample paths will be a local one , so that if the information relevant to our prediction problem is contained in a particular part or parts of the sample path , as it is typically the case in many practical applications , this information will be carried by a very small number of wavelet coefficients .",
    "below , we recall some background on interpolating wavelets and orthonormal wavelet expansions of continuous - time stochastic processes that we are going to use in the subsequent development .",
    "the discrete wavelet transform ( dwt ) , as formulated by mallat ( 1989 ) and daubechies ( 1992 ) , is an increasingly popular tool for the statistical analysis of time series ( see , e.g. , nason & von sachs , 1999 ; percival & walden , 2000 ; fryzlewicz , van bellegem & von sachs , 2003 ) .",
    "the dwt maps a time series into a set of wavelet coefficients , each one associated with a particular scale .",
    "two distinct wavelet coefficients can be either ` within - scale ' ( i.e. , both are associated with the same scale ) or ` between - scale ' ( i.e. , each has a distinct scale ) .",
    "one reason for the popularity of the dwt in times series analysis is that measured data from most processes are inherently multiscale in nature , owing to contributions from events occurring at different locations and with different localization in time and frequency .",
    "consequently , data analysis and modelling methods that represent the measured variables at multiple scales are better suited for extracting information from measured data than methods that represent the variables at a single scale .",
    "let @xmath38 be a mean - square continuous - time stochastic process defined on @xmath39 $ ] , i.e. @xmath40 ) = \\left\\ { x(t ) : \\omega \\rightarrow { { \\ensuremath{{\\mathbb r}}}},\\ ; t \\in [ 0,1 ] \\ ; \\left| \\ ; { \\ensuremath{{\\mathbb e}}}\\left ( \\int_0 ^ 1 x^2(t ) \\ ; dt \\right )",
    "< \\infty \\right\\}. \\right.\\ ] ] recall that ( see , e.g. , neveu , 1968 ) @xmath41)$ ] is a separable hilbert space equipped with inner product defined by @xmath42 to develop a wavelet - based orthonormal expansion , we mimic the construction of a ( regular ) multiresolution analysis of @xmath43)$ ] ( see , e.g. , mallat , 1989 ) . in other words , consider a ladder of closed subspaces @xmath44),\\ ] ] with any fixed @xmath45 , whose union is dense in @xmath43)$ ] , and where , for each @xmath46 , @xmath47 is spanned by @xmath48 orthonormal scaling functions @xmath49 , such that @xmath50 $ ] , with @xmath51 a constant not depending on @xmath46 . at each resolution level @xmath46 ,",
    "the orthonormal complement @xmath52 between @xmath47 and @xmath53 is generated by @xmath48 orthonormal wavelets @xmath54 , such that @xmath55 $ ] . as a consequence ,",
    "the family @xmath56 , completed with @xmath57 , constitutes an orthonormal basis of @xmath43)$ ] .",
    "similarly , we define a sequence of approximating spaces of @xmath58)$ ] by @xmath59 ) = \\left\\ { x \\in l^2(\\omega \\times [ 0,1 ] ) \\ ; \\left|   \\ ; x(t)=\\sum_{k=0}^{2^j-1 } \\xi_{j , k } \\phi_{j , k}(t),\\ \\sum_{k=0}^{2^j-1}{\\ensuremath{{\\mathbb e}}}(\\xi_{j , k})^2 < \\infty \\right\\ } , \\right.\\ ] ] where @xmath60 is a sequence of random variables and @xmath61 is the scaling basis of @xmath47 . note that since @xmath58)$ ] is isomorphic to the hilbert tensor product @xmath62)$ ] , the stochastic approximating spaces @xmath63)$ ] are closed subspaces of @xmath41)$ ] .",
    "note also that for every @xmath64)$ ] , one has @xmath65)$ ] since @xmath66 ^ 2 dt = \\int_0 ^ 1 \\left[{\\ensuremath{{\\mathbb e}}}\\left(\\sum_{k=0}^{2^j-1 } \\xi_{j , k}\\phi_{j , k}(t)\\right)\\right]^2 dt = \\sum_{k=0}^{2^j-1 } \\left[{\\ensuremath{{\\mathbb e}}}(\\xi_{j , k})\\right]^2 \\leq \\sum_{k=0}^{2^j-1 } { \\ensuremath{{\\mathbb e}}}(\\xi_{j , k})^2,\\ ] ] by orthonormality of the scaling functions .",
    "following cohen & dales ( 1997 ) , it is easy to see that @xmath67):~ j \\in { \\ensuremath{{\\mathbb n}}}_0\\}$ ] is a multiresolution analysis of @xmath41)$ ] . moreover if @xmath68)$ ] denotes the orthonormal complement of @xmath63)$ ] in @xmath69)$ ] , then one naturally has the following stochastic wavelet orthonormal expansion @xmath70 ) \\leftrightarrow x(t ) = \\sum_{k=0}^{2^{j_0}-1 } \\xi_{j_0,k } \\phi_{j_0,k}(t ) + \\sum_{j = j_0}^{\\infty } \\sum_{k=0}^{2^j-1 } \\eta_{j , k } \\psi_{j , k}(t),\\ ] ] where @xmath71 and @xmath72 . the above remarks clearly show that the wavelet - based orthonormal expansion is a fundamental tool for viewing the continuous - time stochastic process in both time and scale domains .    in order to allow for inhomogeneous sample paths , the notion of the besov space ( @xmath73 ) comes naturally into the picture . without getting into mathematical details ,",
    "we just point out that besov spaces are known to have exceptional expressive power : for particular choices of the parameters @xmath74 , @xmath75 and @xmath76 , they include , e.g. , the traditional hlder ( @xmath77 ) and sobolev ( @xmath78 ) classes of smooth functions , and the inhomogeneous functions of bounded variation sandwiched between @xmath79 and @xmath80 .",
    "the parameter @xmath75 can be viewed as a degree of function s inhomogeneity while @xmath74 is a measure of its smoothness .",
    "roughly speaking , the ( not necessarily integer ) parameter @xmath74 indicates the number of function s ( fractional ) derivatives , where their existence is required in an @xmath81-sense , while the additional parameter @xmath76 provides a further finer gradation ( see , e.g. , .",
    "meyer , 1992 ) .",
    "therefore , from an approximation perspective , if the sample paths of the continuous - time stochastic process @xmath2 belong to an inhomogeneous besov space of regularity @xmath82 , and if one uses regular enough scaling functions , one may approximate in @xmath83)$ ] any sample path of the process @xmath2 by its projection onto @xmath84 at a rate of the order @xmath85 ( see cohen & dales , 1997 , theorem 2.1 ) .",
    "this is , in fact , a simple rephrasing , in the stochastic framework , of the deterministic results on the multiresolution approximation of functions in besov spaces when the error is measured in the @xmath43)$]-norm .",
    "this result has the advantage that dimension reduction by basis truncation in the wavelet domain is controlled more precisely .",
    "consider now the case where the stochastic signal is sampled over a finite number @xmath37 of equidistant points and assume that @xmath86 .",
    "one then may use an interpolating wavelet basis , as the one constructed by donoho ( 1992 ) , to interpolate the observed values .",
    "the interpolating scaling function @xmath87 corresponds to the autocorrelation function of an orthogonal , regular enough , scaling function and the projection onto the scaling approximating space @xmath84 is then given by @xmath88 while this projector has no orthogonality property , it retains however the good approximations properties of projection operators derived from orthogonal multiresolution analyses ( see mallat , 1999 , theorem 7.21 ) .",
    "when @xmath37 is not anymore a power of two , one may still use the above scheme by adapting the interpolating wavelet basis to the sampling grid using an appropriate subdivision scheme for interpolation ( see cohen , dyn & matei , 2003 ) .",
    "we conclude this section by recalling the strictly stationarity and @xmath0-mixing concepts that we are going to adopt for developing the proposed functional wavelet - kernel prediction methodology .",
    "one of our main assumption in predicting the times series @xmath13 will be its strictly stationarity .",
    "we therefore recall some results on strictly stationarity from the above stochastic multiresolution analysis perspective .",
    "recall that , for all @xmath89)$ ] , we have @xmath90 therefore , @xmath91 > from the above , it is easy to see that if @xmath2 is a strictly stationary process then , at any resolution level @xmath46 , the vector of its scaling coefficients , is also strictly stationary . as shown in cheng & tong ( 1996 ) , the converse is also true .",
    "it follows that strictly stationarity of the discrete - time series @xmath13 implies strictly stationarity in the above sense of the sequence of the scaling coefficients vectors at any resolution .",
    "note , moreover , that if the strictly stationarity assumption is too strong , one could calibrate the non - stationarity by considering only @xmath92-stationarity ( see cheng & tong , 1998 ) , that is , strictly stationarity of the scaling coefficients up to ( finest ) resolution @xmath92 , with eventually a different distribution at each resolution level @xmath46 .",
    "our theoretical results will be derived under @xmath0-mixing assumptions on the time series @xmath93 .",
    "recall that for a strictly stationary series @xmath93 , the @xmath0-mixing coefficient ( see rosenblatt , 1956 ) is defined by @xmath94 where @xmath95 and @xmath96 are the @xmath32-fields generated by @xmath97 and @xmath98 respectively , for any @xmath99 .",
    "the stationary sequence @xmath93 is said to be @xmath0-mixing if @xmath100 as @xmath101 . among various mixing conditions used in the literature ,",
    "@xmath0-mixing is reasonably weak ( see , e.g. , doukhan , 1994 ) .    since in the subsequent development we are dealing with wavelet decompositions , for each @xmath23 ,",
    "denote by @xmath102 the set of scaling coefficients up to resolution level @xmath92 of the @xmath103-th segment @xmath22 .",
    "note that because @xmath93 is a strictly stationary stochastic process , the same is also true for the @xmath104-dimensional stochastic process @xmath105 . furthermore , denote by @xmath106 and @xmath107 the @xmath32-fields generated by @xmath108 and @xmath109 respectively . because @xmath110 for any @xmath111 , we get @xmath112 note that the above observation is also true when dealing with sample paths discretized over a fixed equidistant grid on @xmath113 $ ] of size @xmath37 , since then @xmath114 for all @xmath115 .",
    "consider the nonparametric prediction of a ( real - valued ) stationary discrete - time stochastic process .",
    "let @xmath116 be the vector of lagged variables , and let @xmath74 be the forecast horizon .",
    "it is well - known that the autoregression function plays a predominant forecasting role in the above time series context .",
    "recall that the autoregression function @xmath117 is defined by @xmath118 it is clear that the first task is to estimate @xmath117 .",
    "the classical approach to this problem is to find some parametric estimate of @xmath117 .",
    "more specifically , it is assumed that @xmath117 belongs to a class of functions , only depending on a finite number of parameters to be estimated .",
    "this is the case of the very well - known arima models , widely studied in the literature ( see , e.g. , box & jenkins , 1976 ; brockwell & davis , 1991 ) .",
    "the above prediction problem can also be undertaken with a nonparametric view , without any assumption on the functional form of @xmath117 .",
    "this is a much more flexible approach that only imposes regularity conditions on @xmath117 .",
    "nonparametric methods for forecasting in time series can be viewed , up to a certain extent , as a particular case of nonparametric regression estimation under dependence ( see , e.g. , bosq , 1991 ; hart , 1991 ; hrdle & vieu , 1992 ; hart , 1996 ) .",
    "a popular nonparametric method for such task is to use the kernel smoothing ideas because they have good properties in real - valued regression problems both from a theoretical and a computational point of view .",
    "the kernel estimator @xmath119 ( based on @xmath120 of @xmath117 is defined by @xmath121 or @xmath122 if the denominator is null . in our development , for simplicity , we consider a product kernel , i.e. , for each @xmath123 , @xmath124 ; also @xmath125 is a sequence of positive numbers ( the bandwidths ) .",
    "the @xmath74-ahead prediction is then simply given by @xmath126 .",
    "theoretical results show that the detailed choice of the kernel function does not influence strongly the asymptotic behavior of prediction but the choice of the bandwidth values are crucial for prediction accuracy ( see , e.g. , bosq , 1998 ) .",
    "as it is readily seen , the prediction is expressed as a locally weighted mean of past values , where the weights measure the similarity between @xmath127 and @xmath128 , taking into account the process history .",
    "let now @xmath31 be a generic notation for a euclidean norm .",
    "if the kernel values decrease to zero as @xmath129 increases , the smoothing weights have high values when the @xmath130 is close to @xmath128 , and is close to zero otherwise .",
    "in other words , the prediction @xmath131 is obtained as a locally weighted average of future blocks of horizon @xmath74 in all blocks of length @xmath132 in the past , weighted by similarity coefficients @xmath133 of these blocks with the current block , where @xmath134      recall that , in our setting , the strictly stationary time series @xmath93 is functional - valued rather than @xmath135-valued , i.e. , each @xmath30 is a random curve . in this functional setup , and to simplify notation , we address , without loss of generality , the prediction problem for a horizon @xmath136 .",
    "we could mimic the above kernel regression ideas , and use the following estimate @xmath137 where the triangular - array of local weights @xmath138 increases with the closeness or similarity of the last observed path @xmath139 and the paths @xmath140 in the past , in a ( semi-)norm sense ; this is made more precise in ( [ eq : xxseg ] ) below .",
    "the literature on this infinite - dimension kernel regression related topic is relatively limited , to our knowledge .",
    "bosq & delecroix ( 1985 ) dealt with general kernel predictors for hilbert - valued stationary markovian processes .",
    "a similar idea was applied by besse , cardot & stephenson ( 1999 ) for arh(1 ) processes in the special case of a sobolev space .",
    "extending and justifying these kernel regression techniques to infinite - dimensional stochastic processes with no specific structures ( e.g. , arh(1 ) or more general markovian processes ) , will require using measure - theoretic assumptions on infinite - dimensional spaces ( e.g. , a probability density function with respect to an invariant measure ) thus restricting the analysis and applicability to a small class of stochastic processes ( e.g. , diffusion processes ) . such kind of assumptions are more natural in finite - dimensional spaces such as those obtained through orthonormal wavelet decompositions , especially when the discretized sample paths of the observed process are quite coarse .",
    "taking advantage of these latter remarks , our forecasting methodology relies upon a wavelet decomposition of the observed curves , and uses the concepts of strictly stationarity and @xmath0-mixing within the stochastic multiresolution analysis framework discussed in section 2 .",
    "moreover , note that using distributional assumptions such as those given in the appendix on the wavelet coefficients is much less restrictive than using similar assumptions on the original process @xmath13 .",
    "to summarize , the proposed forecasting methodology is decomposed into two phases    * find within the past paths the ones that are ` similar ' to the last observed path ( this determines the weights ) ; * use the weights and the stochastic multiresoltion analysis to forecast by a locally weighted averaging process as the one described by ( [ eq : zseg ] ) .",
    "since we are dealing with a wavelet decomposition , it is worth to isolate the first phase ( ph1 ) by discussing possible ways to measure the similarity of two curves , by means of their wavelet approximation , and then to proceed to the second phase ( ph2 ) , using again this wavelet approximation .",
    "the analysis of the proposed kernel - based functional prediction method is based on finding similar paths .",
    "similarity is now defined in terms of a distance metric related to the functional space in which the sample paths lie . when the space is a besov space , it is well - known that its norm is characterized by a weighted @xmath141-norm of the wavelet coefficients of its elements ( see , e.g. , meyer , 1992 ) .",
    "it is therefore natural to address the similarity issue on the wavelet decomposition of the observed sample paths .",
    "the wavelet transform is applied to the observed sample paths , and due to the approximation properties of the wavelet transform , only a few coefficients of the transformed data will be used ; a kind of contractive property of the wavelet transform .    applying the dwt to each path , decomposes the temporal information of the time series into discrete wavelet coefficients associated with both time and scale . discarding scales in the dwt that are associated with high - frequency oscillations , provides a straightforward data reduction step and decreases the computational burden .",
    "we want to use the distributional properties of the wavelet coefficients of the observed series .",
    "imagine first that we are given 2 observed series , and let @xmath142 , @xmath143 , be the discrete wavelet coefficient of the dwt of each signal at scale @xmath46 ( @xmath144 ) and location @xmath145 ( @xmath146 ) . at each scale @xmath147 , define a measure of discrepancy in terms of a distance @xmath148 which measures how effectively the two signals match at scale @xmath46 . to combine all scales , we then use @xmath149 such a measure of discrepancy is natural and is often used to test the equality of two regression functions in the wavelet domain ( see , e.g. , spokoiny , 1996 ; abramovich , antoniadis , sapatinas & vidakovic , 2004 ) .    as for the second phase ( ph2 ) ,",
    "recall that , for each @xmath150 , @xmath151 denotes the set of scaling coefficients up to resolution level @xmath92 of the @xmath103-th segment @xmath22 .",
    "the kernel prediction of the scaling coefficients at time @xmath152 , @xmath153 , is given by @xmath154 where the @xmath155 factor in the denominator allows expression ( [ eq : xxseg ] ) to be properly defined and does not affect its convergence rate . here , for simplicity",
    ", we use the notation @xmath156 , and @xmath157 is the set of wavelet coefficients obtained by applying the `` pyramid algorithm '' ( see mallat , 1989 ) on the set of ( finest level ) scaling coefficients @xmath158 , for @xmath159 .",
    "this , leads to the time - domain prediction at time @xmath152 , @xmath160 of @xmath161 , where @xmath162 are the components of the predicted scaling coefficients @xmath153 .",
    "the following theorem shows its consistency property .",
    "suppose that the assumptions ( a1)-(a7 ) , given in the appendix , are true .    * if @xmath163 and if @xmath164 , then , @xmath165 , we have @xmath166 * if the sample paths are sampled on a grid of size @xmath167 and if @xmath164 , then , @xmath165 , we have @xmath168    [ th : cons ]    note that in both assertions of theorem  [ th : cons ] , the size of the sampling grid over each segment affects the convergence rate of our predictor . in the first case , which is the most usual in practice ,",
    "the rate becomes slower as the dimension @xmath37 increases but we still have consistency as the number of segments increases to infinity . in the second case , however , an extra term is given by the wavelet approximation of the sample paths at resolution @xmath92 and getting a larger @xmath92 affects considerably the rate of the estimator which is the well - known problem of the `` curse of dimensionality '' .",
    "one possible way to deal with this problem would be to look at the regressor in an infinite - dimensional space but , as already noted above , this is a difficult problem , since one would need some concentration assumption about the distribution of the functional - valued time series @xmath93 without referring to any particular probability density function .",
    "we conclude this section by pointing out that , as in any nonparametric smoothing approach , the choice of the smoothing parameter @xmath169 ( the bandwidth ) is of great importance . once @xmath169",
    "is specified , only time segments that lie within a similarity distance from the segment @xmath24 within @xmath169 will be used to estimate the prediction at time @xmath152 .",
    "intuitively , a large value of @xmath169 will lead to an estimator that incurs large bias , while a small value , might reduce the bias but the variability of the predicted curve could be large since only few segments are used in the estimation .",
    "a good choice of @xmath169 should balance the bias - variance trade off . in our implementation",
    ", we have used the leave - one out cross - validation for times - series data as suggested by hart ( 1996 ) .",
    "the principle of the cross - validation criterion is to select the bandwidth which , for our given prediction horizon @xmath136 , minimizes the mean squared prediction errors of the @xmath170-th segment using all segments in the past except the @xmath103-th , i.e. , the value of @xmath169 that minimizes @xmath171 where @xmath172 is the kernel regression estimate with bandwidth @xmath173 obtained using the series without its @xmath103-th segment .",
    "this is the method for choosing the bandwidth adopted in the numerical results presented in section  [ sec : num ] .",
    "apart from the prediction @xmath174 discussed in section  [ sec : fwkp ] , we also construct resampling - based pointwise prediction intervals for @xmath175 . in particular , suppose that @xmath176 is observed at the set @xmath177 of discrete points on the interval @xmath178 $ ] . a pointwise prediction interval for @xmath175 is defined to be a set of lower and upper points @xmath179 and @xmath180 respectively , such that for every @xmath181 , and every @xmath182 , @xmath183 note that since we are looking at the one step prediction of @xmath175 given @xmath184 , we are in fact interested in the conditional distribution of @xmath185 given @xmath184 , i.e. , @xmath186 and @xmath187 are the lower and upper @xmath0-percentage points of the conditional distribution of @xmath188 given @xmath184 .    to construct such a prediction interval the following simple resampling procedure is proposed . given @xmath184 ,",
    "i.e. , given @xmath189 , define the weights @xmath190 note that the weights have been selected appropriately so that @xmath191 now , given @xmath184 , generate pseudo - realizations @xmath192 such that for @xmath193 , @xmath194 i.e. , @xmath192 is generated by choosing randomly a segment from the whole set of observed segments @xmath195 , where the probability that the @xmath196-th segment is chosen depends on how ` similar ' is the preceding segment @xmath197 to @xmath184 .",
    "this ` similarity ' is measured by the resampling probability @xmath198 .    given pseudo - replicates @xmath192 , calculate @xmath199 , where @xmath200 is our time - domain conditional mean predictor .",
    "let @xmath201 and @xmath202 be the lower and upper @xmath0-percentage points of @xmath203 .",
    "note that these percentage points can be consistently estimated by the corresponding empirical percentage points over @xmath204 realizations @xmath205 , @xmath206 , of @xmath207 .",
    "a @xmath208 pointwise prediction interval for @xmath188 is then obtained by @xmath209 , \\ \\",
    "i=1,2 , \\ldots , p\\},\\ ] ] where @xmath210 and @xmath211 .",
    "the following theorem shows that the proposed method is asymptotically valid , i.e. , the so - constructed resampling - based prediction interval achieves the desired pointwise coverage probability .",
    "suppose that the assumptions ( a1)-(a7 ) , given in the appendix , are true .",
    "then , for every @xmath212 , and every @xmath182 [ th : boot ] @xmath213",
    "we now illustrate the usefulness of the proposed functional wavelet - kernel ( w - k ) approach for continuous - time prediction in finite sample situations by means of three real - life datasets that were collected from different arenas , in particular with @xmath214 the prediction of the entire annual cycle of climatological el nio - southern oscillation time series one - year ahead from monthly recordings , @xmath215 the one - week ahead prediction of paris electrical load consumption from half - hour daily recordings , and @xmath216 the one - year ahead prediction of the nottingham temperature data from monthly recordings .    for the w - k approach , the interpolating wavelet transform of donoho ( 1992 ) based on _ symmlet 6 _ ( see daubechies , 1992 , p. 195 )",
    "preliminary simulations show that the analysis is robust with respect to the wavelet filter , e.g. , using _ coiflet 3 _ ( see daubechies , 1992 , p. 258 ) . in the case where the number of time points ( @xmath37 ) in each segment is not a power of 2 ,",
    "each segment is extended by periodicity at the right to a length closest to the nearest power of 2 .",
    "the gaussian kernel @xmath217 was adopted in our analysis . again , preliminary simulations show that our analysis is robust with respect to kernels with unbounded support ( e.g. , laplace ) .",
    "the bandwidth ( @xmath169 ) was chosen by the leave - one out cross - validation for times - series data as suggested by hart ( 1996 ) .",
    "for the associated 95% resampling - based pointwise prediction intervals , the number of resampling samples ( @xmath204 ) was taken equal to 500 .",
    "we compare the resulting predictions with those obtained by some well - established methods in the literature , in particular with a smoothing spline ( ss ) method and with the classical sarima model .",
    "the ss method , introduced by besse & cardot ( 1996 ) , assumes an arh(1 ) structure for the time series @xmath93 and handles the discretization problem of the observed curves by simultaneously estimating the sample paths and projecting the data on a @xmath76-dimensional subspace ( that the predictable part of @xmath13 assumed to belong ) using smoothing splines ( by solving an appropriate variational problem ) .",
    "the corresponding smoothing parameter ( @xmath218 ) and dimensionality ( @xmath76 ) are chosen by a cross - validation criterion . following the box - jenkins methodology",
    "( see box & jenkins , 1976 , chapter 9 ) , a suitable sarima model is also adjusted to the times series @xmath93 .",
    "the quality of the prediction methods was measured by the _ relative mean - absolute error _",
    "( rmae ) defined by @xmath219 where @xmath220 is the @xmath221-th element of the time series @xmath13 and @xmath222 is the prediction of @xmath220 given the past .",
    "the computational algorithms related to wavelet analysis were performed using version 8.02 of the freeware wavelab software .",
    "the entire numerical study was carried out using the matlab programming environment .",
    "this application concerns with the prediction of a climatological times series describing el nio - southern oscillation ( enso ) during the 12-month period of 1986 , from monthly observations during the 19501985 period .",
    "enso is a natural phenomenon arising from coupled interactions between the atmosphere and the ocean in the tropical pacific ocean .",
    "el nio ( en ) is the ocean component of enso while southern oscillation ( so ) is the atmospheric counterpart of enso .",
    "most of the year - to - year variability in the tropics , as well as a part of the extra - tropical variability over both hemispheres , is related to enso . for a detailed review of enso",
    "the reader is referred , for example , to philander ( 1990 ) .",
    "an useful index of el nio variability is provided by the sea surface temperatures averaged over the nio-3 domain ( @xmath223 , @xmath224 ) .",
    "monthly mean values have been obtained from january 1950 to december 1996 from gridded analyses made at the u.s .",
    "national centers for environmental prediction ( see smith , reynolds , livezey & stokes , 1996 ) . the time series of this en index is depicted in figure  [ elninoseries ] , and shows marked inter - annual variations superimposed on a strong seasonal component .",
    "it has been analyzed by many authors ( see , for example , besse , cardot & stephenson , 2000 ; antoniadis & sapatinas , 2003 ) .",
    "the bandwidth ( @xmath169 ) for the w - k method was chosen by a cross - validation criterion and found equal to 0.11 .",
    "we have compared our results with those obtained by besse , cardot & stephenson ( 2000 ) , using the ss method , with smoothing parameter ( @xmath218 ) and dimensionality ( @xmath76 ) chosen optimally by a cross - validation criterion and found equal to @xmath225 and 4 , respectively . to complete the comparison , a suitable arima model , including 12 month seasonality ,",
    "has also been adjusted to the times series from january 1950 to december 1985 , and the most parsimonious sarima model , validated through a portmanteau test for serial correlation of the fitted residuals , was selected .    ) , and sarima ( -@xmath226- ) methods.,title=\"fig:\",width=480 ] ) , and sarima ( -@xmath226- ) methods.,title=\"fig:\",width=480 ]    ) for the nio-3 surface temperature during 1986 , based on the corresponding prediction obtained by the w - k (  ) method .",
    "the true points ( @xmath227 ) are also displayed.,title=\"fig:\",width=480 ] ) for the nio-3 surface temperature during 1986 , based on the corresponding prediction obtained by the w - k (  ) method .",
    "the true points ( @xmath227 ) are also displayed.,title=\"fig:\",width=480 ]    figure  [ elninopred ] displays the observed data of the 37th year ( 1986 ) and its predictions obtained by the w - k , ss and sarima methods . the rmae of each prediction method are displayed in table  1 ( we have taken @xmath228 and @xmath229 ) . as observed in both the figure and the table , the w - k and ss estimators give almost similar predictions , both visually and in terms of rmae .",
    "the prediction obtained by the sarima model is strongly and uniformly biased , failing thus to produce an adequate prediction ( see besse , cardot & stephenson , 2000 , for an explanation ) . note that , after may , all predictions are not very close to the true points and this difficulty in prediction is captured in figure  [ cielnino ] which displays the corresponding 95% resampling - based pointwise prediction interval for the nio-3 surface temperature during 1986 , based on the corresponding prediction obtained by the w - k method . as observed in the figure , it becomes clear that as one moves from may onwards , this interval gets larger .",
    "[ errors - elnino ]    .rmae for the prediction of nio-3 surface temperatures during 1986 based on the w - k , ss and sarima methods . [ cols=\"^,^\",options=\"header \" , ]",
    "the functional wavelet - kernel prediction methodology , of a continuous - time stochastic process on an entire time - interval in terms of its recent past , developed in this paper exhibits very good performance with respect to other well - known parametric and nonparametric techniques . as it is demonstrated in the real - life datasets analyzed",
    ", the proposed wavelet - based prediction methodology outperforms the smoothing spline - based prediction methodology for stochastic processes with inhomogeneous sample paths , and performs equally - well for stochastic processes with quite regular sample paths .",
    "moreover , it performs reasonably well in situations where the classical seasonal parametric model exhibits very good predictions .",
    "we have , however , noted than when the number of sampling points within each time - segment is large , the curse of dimensionality leads to inefficiency of the proposed nonparametric prediction method unless the number of segments is really large .",
    "anestis antoniadis was supported by the ` iap research network p5/24 ' and the ` cyprus - france cy - fr/0204/04 zenon program ' .",
    "efstathios paparoditis and theofanis sapatinas were supported by the ` cyprus - france cy - fr/0204/04 zenon program ' .",
    "we would like to thank jean - michel poggi ( universite paris - sud , france ) for providing us with the paris electrical load consumption data .",
    "our asymptotic results will be based on the following set of assumptions , which we detail below before proceeding to the proofs .",
    "* assumption ( a1 ) : *  the sample paths of the strictly stationary process @xmath93 are assumed to lie within a besov space @xmath230 , where @xmath231 , @xmath232 , and @xmath132 is the regularity of the scaling functions associated with the regular multiresolution analysis discussed in section  [ subsec : orthsp ] .",
    "* assumption ( a2 ) : *  when we only observe a fixed number @xmath37 of samples values from each sample path , we assume that the sampled paths of the strictly stationary process @xmath93 are continuous on @xmath233 , and that the interpolating scaling function @xmath87 of the wavelet interpolating basis has an exponential decay .",
    "* assumption ( a3 ) : *  the @xmath234-mixing coefficient of the strictly stationary process @xmath93 satisfies @xmath235 ( note that the scaling coefficients of @xmath13 inherit the above mixing property , according to the relevant discussion in section  [ subsec : orthsp ] . )          1 .",
    "@xmath242 is lipschitz continuous , i.e. , @xmath243 2 .",
    "the random vector of the scaling coefficients at scale @xmath92 admits a compactly supported probability density function @xmath117 ( with support @xmath244 ) which is strictly positive and twice continuously differentiable .",
    "3 .   the conditional probability density function of @xmath245 given @xmath236 is bounded , i.e. , @xmath246 .",
    "let us now explain the meaning of the above assumptions .",
    "assumptions ( a1 ) ( or ( a2 ) ) and ( a3 ) are quite common in times series prediction ( see bosq , 1998 )",
    ". assumptions ( a4)-(a5 ) are essentially made on the distributional behavior of the scaling coefficients and , therefore , are less restrictive .",
    "they are moreover natural in nonparametric regression .",
    "assumption ( a5)-(ii ) is natural as far as it concerns the scaling coefficients since the decay of the scaling coefficients is ensured by the approximation properties of the corresponding transform .",
    "moreover , it is needed for obtained uniform consistency results .",
    "the conditions ( a6)-(a7 ) are classical for kernel regression estimation .",
    "* proof of theorem  [ th : cons ] .",
    "*  the difference in the two assertions of the theorem is due to the nature of the observations . in case @xmath257 , each observed segment is a time series with fixed , finite length , and we use an interpolating wavelet transform at the appropriate resolution @xmath92 that makes interpolation error negligible , i.e. , @xmath258 in case @xmath259 , the observed segments are continuous - time stochastic processes and one can not neglect anymore the approximation error due to the projection of the observed segment onto the scaling space @xmath84 .",
    "however , under our assumptions , and according to the results recalled in section 2 , this error is uniformly bounded by a constant times @xmath260 , where @xmath74 denotes the besov smoothness index @xmath74 , i.e. , @xmath261 resulting in a different rate for the second case .",
    "hence , in both cases , we proceed by deriving the appropriate rates for @xmath262 we first show that , as @xmath256 , @xmath263 for this , it suffices to show that , for every @xmath264 , as @xmath256 , @xmath265 let @xmath266 , let @xmath267 be the value of @xmath268 in ( [ eq : xxseg ] ) for @xmath269 , and denote by @xmath270 the @xmath145-th component of @xmath271 .",
    "consider the @xmath272-dimensional random variable @xmath273 , and denote by @xmath274 and @xmath275 the joint and marginal densities of @xmath276 and @xmath277 , respectively .",
    "notice that because of ( a4 ) , and the fact that @xmath278 is a linear transformation of @xmath279 , @xmath280 and @xmath275 exist with respect to lebesgue measure for every @xmath281 .",
    "let @xmath282 and notice that @xmath283 is the kernel estimator of the @xmath104-dimensional density @xmath284 .",
    "for notational convenience , in what follows , let @xmath285 and @xmath286 .",
    "we then have @xmath287 using now the assumptions of the theorem , the above decomposition , lemma 2.1 and theorem 3.2 of bosq ( 1998 ) , it follows that , as @xmath288 , @xmath289 recalling now that our estimator is defined as @xmath290 using the rate given in expression  ( [ arate ] ) , and the fact that we have used a regular multiresolution analysis , we have , as @xmath288 , @xmath291 the above bound ( [ eq : bfb ] ) , together with inequality  ( [ aux1 ] ) , ensures the validity of both the assertions @xmath257 and @xmath259 .",
    "this completes the proof of theorem  [ th : cons ] . @xmath292",
    "* proof of theorem  [ th : boot ] . *  for every @xmath293 , note that @xmath294 . since @xmath295 and , as @xmath288 , @xmath296 _ in probability _",
    ", it suffices to show that the distribution of @xmath297 approximates correctly the conditional distribution of @xmath298 given @xmath184 .",
    "now , given @xmath299 , i.e. , given @xmath300 , we have @xmath301}(z_{m+1}(t_{i})-e(z_{n+1}(t_{i } ) \\,|\\ , z_{n}=x))w_{n , m } \\nonumber \\\\ & = & \\sum_{m=1}^{n-1}1_{(-\\infty,\\overline{y}]}(z_{m+1}(t_i ) ) w_{n , m } \\nonumber \\\\ & = & \\sum_{m=1}^{n-1}1_{(-\\infty,\\widetilde{y}]}(\\xi_{m+1}^{(j , i)})w_{n , m } \\nonumber \\\\ & = &   \\frac{\\sum_{m=1}^{n-1}{\\bf 1}_{(-\\infty,\\widetilde{y}]}(\\xi_{m+1}^{(j , i)})\\ , k ( d({\\cal c}(\\widetilde{x } ) , { \\cal c}(\\xi_{m}))/h_{n } ) } { n^{-1 } + \\sum_{m=1}^{n-1}k ( d({\\cal c}(\\widetilde{x } ) , { \\cal c}(\\xi_{m}))/h_{n } ) } \\\\ & & + o(n^{-1 } ) , \\nonumber\\end{aligned}\\ ] ] where @xmath302 .",
    "note that ( [ eq.kern1 ] ) is a kernel estimator of the conditional mean @xmath303}(\\xi_{n+1}^{(j , i)})\\,|\\,\\xi_{n}=\\widetilde{x } ) = { \\ensuremath{{\\mathbb p}}}(\\xi_{n+1}^{(j , i ) } \\leq \\widetilde{y}\\,|\\ , \\xi_{n}=\\widetilde{x})$ ] , i.e. , of the conditional distribution of @xmath304 given that @xmath305 .",
    "denote now the conditional distribution of @xmath306 given @xmath307 by @xmath308 and its kernel estimator given in ( [ eq.kern1 ] ) by @xmath309 .",
    "then by the same arguments as in theorem  [ th : cons ] we get that , for every @xmath310 , as @xmath288 , @xmath311    it remains to show that the above convergence is also uniformly over @xmath312 .",
    "fix now a @xmath313 in the support @xmath244 of @xmath307 , and let @xmath314 arbitrary .",
    "since @xmath315 is continuous we have that , for every @xmath316 , points @xmath317 exist such that @xmath318 . for @xmath319 , and using the monotonicity of @xmath320 and @xmath321 , we have @xmath322 > from this , we get @xmath323 and , therefore , @xmath324 now , chose @xmath325 large enough such that @xmath326 .",
    "for such a fixed @xmath145 , and because , for every @xmath327 , as @xmath288 , @xmath328 we can choose @xmath329 large enough such that @xmath330 for any desired @xmath331 . since @xmath331 is independent on @xmath332 and @xmath333 , the desired convergence follows .",
    "this completes the proof of theorem  [ th : boot ] .",
    "@xmath292    abramovich , f. , antoniadis , a. , sapatinas , t. & vidakovic , b. ( 2004 ) .",
    "optimal testing in a fixed - effects functional analysis of variance model .",
    "j.  wavelets  multiresolut .",
    "inf .  process .",
    "_ , * 2 * , 323349 .",
    "antoniadis , a. & sapatinas , t. ( 2003 ) .",
    "wavelet methods for continuous - time prediction using hilbert - valued autoregressive processes . _",
    "j.multivariate  anal .",
    "_ , * 87 * , 133158 .",
    "besse , p.c .",
    "& cardot , h. ( 1996 ) .",
    "approximation spline de la prvision dun processus fonctionnel autorgressif dordre 1 .",
    "_ canad .",
    "j.  statist .",
    "_ , * 24 * , 467487 .",
    "besse , p.c .",
    ", cardot , h. & stephenson , d.b .",
    "autoregressive forecasting of some functional climatic variations .",
    "_ scand .",
    "j.  statist .",
    "_ , * 27 * , 673687 .",
    "bosq , d. & delecroix , m. ( 1985 ) .",
    "nonparametric prediction of a hilbert - space valued random variable .",
    "_ stochastic  process.appl._ * 19 * , 271280 .",
    "bosq , d. ( 1991 ) .",
    "modelization , nonparametric estimation and prediction for continuous time processes . in _ nonparametric functional estimation and related topics _ ,",
    "g. roussas , pp .",
    "509529 , nato asi series c , vol .",
    "* 335 * , dortrecht : kluwer academic publishers .",
    "bosq , d. ( 1998 ) . _ nonparametric statistics for stochastic processes_. lecture notes in statistics , vol . *",
    "110 * , new york : springer - verlag .",
    "bosq , d. ( 2000 )",
    ". _ linear processes in function spaces_. lecture notes in statistics , vol . * 149 * , new york : springer - verlag .",
    "box , g.e . & jenkins , g.m .",
    "_ time series analysis_. san francisco : holden day .",
    "brockwell , p.j . &",
    "davis , r.a . (",
    "_ time series : theory and methods_. 2nd edition .",
    "new york : springer - verlag .",
    "cardot , h. , ferraty , f. & sarda , p. ( 1999 ) . functional linear model .",
    "_ statist .",
    "_ , * 45 * , 1122 .",
    "cheng , b. & tong , h. ( 1996 ) . a theory of wavelet representation and decomposition for a general stochastic process . in _",
    "lect.notes  statist .",
    "_ , * 115 * , pp .",
    "115129 , springer verlag : new york .",
    "cheng , b. & tong , h. ( 1998 ) .",
    "@xmath145-stationarity and wavelets .",
    "_ j.  statist .",
    "inference _ , * 68 * , 129144 .",
    "cohen , a. & dales , j.p .",
    "nonlinear approximation of random functions .",
    "_ siam  j.  appl .",
    "_ , * 57 * , 518540 .",
    "cohen , a. , dyn , n. & matei , b. ( 2003 ) .",
    "quasilinear subdivision schemes with applications to eno interpolation .",
    "_ appl .  comp .",
    "_ , * 15 * , 89116 .",
    "daubechies , i. ( 1992 ) . _",
    "ten lectures on wavelets_. philadelphia : siam .",
    "donoho , d.l .",
    "interpolating wavelet transforms .",
    "_ technical report _ , * 408 * , department of statistics , stanford university , usa .",
    "doukhan , p. ( 1994 ) .",
    "_ mixing : properties and examples_. new york : springer - verlag .",
    "ferraty , f. & vieu , p. ( 2002 ) . the functional nonparametric model and application to spectrometric data .",
    "_ computat .",
    "_ , * 17 * , 545564 .",
    "fryzlewicz , p. , van bellegem & von sachs , r. ( 2003 ) .",
    "forecasting non - stationary time series by wavelet process modelling .",
    "inst.statist .",
    "_ , * 55 * , 737764 .",
    "hrdle , w. & vieu , p. ( 1992 ) .",
    "kernel regression smoothing of time series .",
    "_ j.  time  ser",
    "_ , * 13 * , 209232 .",
    "hart , j.d .",
    ". some automated methods of smoothing time - dependent data .",
    "_ j.  nonparametr .",
    "statist . _ * 6 * , 115142 .",
    "latif , m. , barnett , t. , cane , m. , flugel , m. , graham , n. , xu , j. & zebiak , s. ( 1994 ) . a review of enso prediction studies .",
    "_ climate dynamics _ , * 9 * , 167179 .",
    "mallat , s.g .",
    "a theory for multiresolution signal decomposition : the wavelet representation .",
    "_ ieee trans .  pat.anal .",
    "_ , * 11 * , 674693 .",
    "mallat , s.g .",
    "( 1999 ) . _ a wavelet tour of signal processing_. 2nd edition , san diego : academic press .",
    "meyer , y. ( 1992 ) .",
    "_ wavelets and operators_. cambridge : cambridge university press .",
    "misiti , m. , misiti , y. , oppenheim , g. & poggi , j .-",
    "( 1994 ) , d@xmath334composition en ondelettes et m@xmath335thodes comparatives : @xmath334tude dune courbe de charge @xmath334lectrique . _",
    "statist .",
    "_ , * xlii * , 5777 .",
    "nason , g.p . &",
    "von sachs , r. ( 1999 ) .",
    "wavelets in time - series analysis .",
    "_ r.soc .",
    "_ , series a , * 357 * , 25112526 .",
    "neveu , j. ( 1968 ) .",
    "processus aleatoirs gaussiens .",
    "_ technical report _ , presses de luniversit de montral , canada .",
    "percival , d.b .",
    "& walden , a.t . (",
    "_ wavelet methods for time series analysis_. cambridge : cambridge university press .",
    "philander , s. ( 1990 ) . _ el nio , la nia and the southern oscillation_. san diego : academic press .",
    "ramsay , j.o . & silverman , b.w .",
    "_ functional data analysis_. new york : springer - verlag .",
    "rosenblatt , m. ( 1956 ) .",
    "a central limit theorem and a strong mixing condition .",
    "usa _ , * 42 * , 4347 .",
    "smith , t.m . , reynolds , r. , livezey , r. & stokes , d. ( 1996 ) .",
    "reconstruction of historical sea surface temperatures using empirical orthogonal functions .",
    "_ j.  climate _ , * 9 * , 14031420 .",
    "venables , w.n .",
    "& ripley , b.d .",
    "_ modern applied statistics with s - plus_. new york : springer - verlag ."
  ],
  "abstract_text": [
    "<S> we consider the prediction problem of a continuous - time stochastic process on an entire time - interval in terms of its recent past . </S>",
    "<S> the approach we adopt is based on functional kernel nonparametric regression estimation techniques where observations are segments of the observed process considered as curves . </S>",
    "<S> these curves are assumed to lie within a space of possibly inhomogeneous functions , and the discretized times series dataset consists of a relatively small , compared to the number of segments , number of measurements made at regular times . </S>",
    "<S> we thus consider only the case where an asymptotically non - increasing number of measurements is available for each portion of the times series . </S>",
    "<S> we estimate conditional expectations using appropriate wavelet decompositions of the segmented sample paths . a notion of similarity , based on wavelet decompositions , </S>",
    "<S> is used in order to calibrate the prediction . </S>",
    "<S> asymptotic properties when the number of segments grows to infinity are investigated under mild conditions , and a nonparametric resampling procedure is used to generate , in a flexible way , valid asymptotic pointwise confidence intervals for the predicted trajectories . </S>",
    "<S> we illustrate the usefulness of the proposed functional wavelet - kernel methodology in finite sample situations by means of three real - life datasets that were collected from different arenas .    _ some key words : _ @xmath0-mixing ; besov spaces ; continuous - time prediction ; functional kernel regression ; pointwise prediction intervals ; resampling ; sarima models ; smoothing splines ; wavelets </S>"
  ]
}