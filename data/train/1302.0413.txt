{
  "article_text": [
    "the automatic search for knowledgeable people in the scope of specific user communities , with basis on documents describing people s activities , is an information retrieval problem that has been receiving increasing attention  @xcite",
    ". usually referred to as _",
    "expert finding _ , the task involves taking a short user query as input , denoting a topic of expertise , and returning a list of people sorted by their level of expertise in what concerns the query topic .    several effective approaches for finding experts have been proposed , exploring different retrieval models and different sources of evidence for estimating expertise .",
    "however , the current state - of - the - art is still lacking in principled approaches for optimally combining the multiple sources of evidence that can be used to estimate expertise . in traditional information retrieval tasks such as ad - hoc retrieval , there has been an increasing interest on the usage of machine learning methods for building retrieval formulas capable of estimating relevance for query - document pairs  @xcite .",
    "the general idea is to use hand - labeled data ( e.g. , document collections containing relevance judgments for specific sets of queries , or information regarding user - clicks aggregated over query logs ) to train ranking models , this way leveraging on data to combine the different estimators of relevance in an optimal way .",
    "however , few previous works have specifically addressed the usage of learning to rank approaches in the task of expert finding .",
    "this paper explores the usage of learning to rank methods in the expert finding task , specifically combining a large pool of estimators for expertise .",
    "these include estimators derived from the textual similarity between documents and queries , from the graph - structure with the citation patterns for the community of experts , and from profile information about the experts .",
    "we have built a prototype expert finding system using learning to rank techniques , and evaluated it on an academic publication dataset from the computer science domain .",
    "the rest of this paper is organized as follows : section 2 presents the main concepts and related works .",
    "section 3 presents the learning to rank approaches used in our experiments .",
    "section 4 introduces the multiple features upon which we leverage for estimating expertise .",
    "section 5 presents the experimental evaluation of the proposed methods , detailing the dataset and the evaluation metrics , as well as the obtained results .",
    "finally , section 6 presents our conclusions and points directions for future work .",
    "serdyukov and macdonald have surveyed the most important concepts and representative previous works in the expert finding task  @xcite .",
    "two of the most popular and well - performing types of methods are the profile - centric and the document - centric approaches  @xcite .",
    "profile - centric approaches build an expert profile as a pseudo document , by aggregating text segments relevant to the expert  @xcite .",
    "these profiles of experts are latter indexed and used to support the search for experts on a topic .",
    "document - centric approaches are typically based on traditional document retrieval techniques , using the documents directly . in a probabilistic approach to the problem",
    ", the first step is to estimate the conditional probability @xmath0 of the query topic @xmath1 given a document @xmath2 . assuming that the terms co - occurring with an expert can be used to describe him , @xmath0 can be used to weight the co - occurrence evidence of experts with @xmath1 in documents .",
    "the conditional probability @xmath3 of an expert candidate @xmath4 given a query @xmath1 can then be estimated by aggregating all the evidences in all the documents where @xmath4 and @xmath1 co - occur .",
    "experimental results show that document - centric approaches usually outperform profile - centric approaches  @xcite .",
    "many different authors have proposed sophisticated probabilistic retrieval models , specific to the expert finding task , with basis on the document - centric approach  @xcite .",
    "for instance cao et al . proposed a two - stage language model combining document relevance and co - occurrence between experts and query terms  @xcite .",
    "fang and zhai derived a generative probabilistic model from the probabilistic ranking principle and extend it with query expansion and non - uniform candidate priors  @xcite .",
    "zhu et al . proposed a multiple window based approach for integrating multiple levels of associations between experts and query topics in expert finding  @xcite .",
    "more recently , zhu et al . proposed a unified language model integrating many document features for expert finding  @xcite .",
    "although the above models are capable of employing different types of associations among query terms , documents and experts , they mostly ignore other important sources of evidence , such as the importance of individual documents , or the co - citation patterns between experts available from citation graphs . in this paper",
    ", we offer a principled approach for combining a much larger set of expertise estimates .    in the scientometrics community ,",
    "the evaluation of the scientific output of a scientist has also attracted significant interest due to the importance of obtaining unbiased and fair criteria .",
    "most of the existing methods are based on metrics such as the total number of authored papers or the total number of citations .",
    "a comprehensive description of many of these metrics can be found in  @xcite .",
    "simple and elegant indexes , such as the hirsch index , calculate how broad the research work of a scientist is , accounting for both productivity and impact .",
    "graph centrality metrics inspired on pagerank , calculated over citation or co - authorship graphs , have also been extensively used  @xcite . in the context of academic expert search systems , these metrics can easily be used as query - independent estimators of expertise , in much the same way as pagerank is used in the case of web information retrieval systems .    for combining the multiple sources of expertise",
    ", we propose to leverage on previous works concerning the subject of learning to rank for information retrieval ( l2r4ir ) .",
    "tie - yan liu presented a good survey on the subject  @xcite , categorizing the previously proposed algorithms into three groups , according to their input representation and optimization objectives :    * * pointwise approach * - l2r4ir is seen as either a regression or a classification problem . given feature vectors of each single document from the data for the input space , the relevance degree of each of those individual documents",
    "is predicted with scoring functions which can sort all documents and produce the final ranked list . *",
    "* pairwise approach * - l2r4ir is seen as a binary classification problem for document pairs , since the relevance degree can be regarded as a binary value which tells which document ordering is better for a given pair of documents .",
    "given feature vectors of pairs of documents from the data for the input space , the relevance degree of each of those documents can be predicted with scoring functions which try to minimize the average number of misclassified document pairs .",
    "several different pairwise methods have been proposed , including svm@xmath5  @xcite . * * listwise approach * - l2r4ir is addressed in a way that takes into account an entire set of documents , associated with a query , as instances .",
    "these methods train a ranking function through the minimization of a listwise loss function defined on the predicted list and the ground truth list . given feature vectors of a list of documents of the data for the input space , the relevance degree of each of those documents",
    "can be predicted with scoring functions which try to directly optimize the value of a particular information retrieval evaluation metric , averaged over all queries in the training data  @xcite .",
    "several different listwise methods have also been proposed , including svm@xmath6  @xcite .    in this paper",
    ", we made experiments with the application of representative learning to rank algorithms from the pairwise and the listwise approaches , namely the svm_rank _ and the svm_map _ algorithms , in a task of expert finding within digital libraries of academic publications .",
    "in this paper , we follow a general approach which is common to most supervised learning to rank methods , consisting of two separate steps , namely training and testing .",
    "figure  [ f1 ] provides an illustration .",
    "given a set of queries @xmath7 and a collection of experts @xmath8 , each associated with specific documents describing the topics of expertise , a training corpus for learning to rank is created as a set of query - expert pairs , each @xmath9 , upon which a relevance judgment indicating the match between @xmath10 and @xmath11 is assigned by a labeler .",
    "this relevance judgment can be a binary label , e.g. , relevant or non - relevant , or an ordinal rating indicating relevance , e.g. , definitely relevant , possibly relevant , or non - relevant .",
    "for each instance @xmath12 , a feature extractor produces a vector of features that describe the match between @xmath10 and @xmath11 .",
    "features can range from classical ir estimators computed from the documents associated with the experts ( e.g. , term frequency , inverse document frequency , bm25 , etc . ) to link - based features computed from networks encoding relations between the experts in @xmath13 ( e.g. , pagerank ) .",
    "the inputs to the learning algorithm comprise training instances , their feature vectors , and the corresponding relevance judgments .",
    "the output is a ranking function , @xmath14 , where @xmath15 is supposed to either give the true relevance judgment for @xmath12 , or produce a ranking score for @xmath11 so that when sorting experts according to these scores the more relevant ones appear on the top of the ranked list .    during the training process , the learning algorithm attempts to learn a ranking function capable of sorting experts in a way that optimizes a particular bound on an information retrieval performance measure ( e.g. , mean average precision ) . in the test phase",
    ", the learned ranking function is applied to determine the relevance between each expert @xmath11 in @xmath13 and a new query @xmath1 . in this paper",
    ", we experimented with the following learning to rank algorithms :    * svm@xmath5  @xcite : this pairwise method builds a ranking model in the form of a linear scoring function , i.e. @xmath16 , through the formalism of support vector machines ( svms ) .",
    "the idea is to minimize the following objective function over a set of @xmath17 training queries @xmath18 , their associated pairs of experts @xmath19 and the corresponding relevance judgment @xmath20 over each pair of experts ( i.e. , pairwise preferences resulting from a conversion from the ordered relevance judgments over the query - expert pairs ) : @xmath21 + differently from standard svms , the loss function in svm@xmath5 is a hinge loss defined over document pairs .",
    "the margin term @xmath22 controls the complexity of the pairwise ranking model @xmath23 .",
    "the method introduces slack variables , @xmath24 , ( i.e. , a variable that is added to an optimization constraint to turn an inequality into an equality where a linear combination of variables is less than or equal to a given constant ) , which measure the degree of misclassification of the datum @xmath25 .",
    "the coefficient @xmath26 affects the trade - off between model complexity and the proportion of non - separable samples .",
    "if it is too large , we have a high penalty for non - separable points and we may store many support vectors and overfit . if it is too small , we may have underfitting .",
    "the objective function is increased by a function which penalizes non - zero @xmath24 , and the optimization becomes a trade off between a large margin , and a small error penalty .",
    "* svm@xmath6  @xcite : this listwise method builds a ranking model through the formalism of structured support vector machines  @xcite , attempting to optimize the metric of average precision ( ap ) .",
    "suppose @xmath27 is the set of all the experts associated with a training query @xmath1 , and @xmath20 represents the corresponding ground truth labels .",
    "any incorrect label for @xmath28 is represented as @xmath29 .",
    "the svm@xmath6 approach can be formalized as follows , where ap is used in the constraints of the structured svm optimization problem .",
    "+ @xmath30 + in the constraints , @xmath31 is called the joint feature map , whose definition is : @xmath32 since there are an exponential number of incorrect labels for the documents , it is a big challenge to directly solve the optimization problem involving an exponential number of constraints for each query .",
    "the formalism of structured svms efficiently tackles this issue by maintaining a working set with those constraints with the largest violation : @xmath33    the survey by tie - yan liu discusses the above methods in more detail  @xcite .",
    "the considered set of features for estimating the expertise of a researcher towards a given query can be divided into three groups , namely textual features , profile features and graph features .",
    "the textual features are similar to those used in standard text retrieval systems and also in previous learning to rank experiments ( e.g. , tf - idf and bm25 scores ) .",
    "the profile similarity features correspond to importance estimates for the authors , derived from their profile information ( e.g. , number of papers published ) .",
    "finally , the graph features correspond to importance and relevance estimates computed from the author co - authorship and co - citation graphs .      similarly to previous expert finding proposals based on document - centric approaches , we also use textual similarity between the query and the contents of the documents to build estimates of expertise . in the domain of academic digital libraries",
    ", the associations between documents and experts can easily be obtained from the authorship information associated to the publications . for each topic - expert pair , we used the okapi bm25 document - scoring function , to compute the textual similarity features .",
    "okapi bm25 is a state - of - the - art ir ranking mechanism composed of several simpler scoring functions with different parameters and components ( e.g. , term frequency and inverse document frequency ) .",
    "it can be computed through the formula shown in equation  [ eq : bm25 ] , where @xmath34 represents the set of terms from query _ q _ , @xmath35 is the number of occurrences of term _ i _ in document @xmath2 , @xmath36 is the number of terms in document @xmath2 , and @xmath37 is the average length of the documents in the collection .",
    "the values given to the parameters @xmath38 and @xmath39 were 1.2 and 0.75 respectively .",
    "most previous ir experiments use these default values for the @xmath38 and @xmath39 parameters .",
    "@xmath40    we also experimented with other textual features commonly used in ad - hoc ir systems , such as _ term frequency _ and _ inverse document frequency_.    term frequency ( tf ) corresponds to the number of times that each individual term in the query occurs in all the documents associated with the author .",
    "equation  [ eq : tf ] describes the tf formula , where @xmath34 represents the set of terms from query _ q _ , @xmath41 is the set of documents having _ a _ as author , @xmath42 is the number of occurrences of term _ i _ in document @xmath43 and @xmath44 represents the number of terms in document @xmath43 .",
    "@xmath45    the inverse document frequency ( idf ) is the sum of the values for the inverse document frequency of each query term and is given by equation  [ eq : idf ] . in this formula",
    ", @xmath46 is the size of the document collection and @xmath47 corresponds to the number of documents in the collection where the @xmath48 query term occurs .",
    "@xmath49    other features used were the number of unique authors associated with documents containing the query topics , the range of years since the first and last publications of the author containing the query terms , and the document length , in terms of the number of words , for all the publications associated to the author .    in the computation of these textual features , we considered two different textual streams from the documents , namely ( i ) a stream consisting of the titles , and ( ii ) a stream using the abstracts of the articles .",
    "we also considered a set of profile features related to the amount of published materials associated with authors , generally taking the assumption that highly prolific authors are more likely to be considered experts .",
    "most of the features based on profile information are query independent , meaning that they have the same value for different queries .",
    "the considered set of profile features are based on the temporal interval between the first and the last publications , the average number of papers and articles per year , and the number of publications in conferences and in journals with and without the query topics in their contents .",
    "scientific impact metrics computed over scholarly networks , encoding co - citation and co - authorship information , can offer effective approaches for estimating the importance of the contributions of particular publications , publication venues , or individual authors .",
    "thus , we considered a set of features that estimate expertise with basis on co - citation and co - authorship information .",
    "the features considered are divided in two sets , namely ( i ) citation counts and ( ii ) academic indexes . in what regards citation counts , we used the total , the average and the maximum number of citations of papers containing the query topics , the average number of citations per year of the papers associated with an author and the total number of unique collaborators which worked with an author . on what regards academic impact indexes",
    ", we used the following features :    * * hirsch index * of the author and of the author s institution , measuring both the scientific productivity and the apparent scientific impact  @xcite .",
    "an author / institution has an hirsch index of @xmath50 if @xmath50 of his @xmath51 papers have at least @xmath50 citations each , and the other @xmath52 papers have at most @xmath50 citations each .",
    "authors with a high hirsch index , or authors associated with institutions with a high hirsch index , are more likely to be considered experts . * the * @xmath50-@xmath39-index * , which extends the hirsch index for evaluating the impact of scientific topics in general  @xcite . in our case ,",
    "the scientific topic is given by the query terms and thus the query has an @xmath50-@xmath39-index of @xmath53 if @xmath53 of the @xmath51 papers containing the query terms in the title or abstract have at least @xmath53 citations each , and the other @xmath54 papers have at most @xmath53 citations each .",
    "* * contemporary hirsch index * of the author , which adds an age - related weighting to each cited article , giving less weight to older articles  @xcite .",
    "a researcher has a contemporary hirsch index @xmath55 if @xmath55 of his @xmath51 articles get a score of @xmath56 each , and the rest @xmath57 articles get a score of @xmath58 . for an article @xmath53 ,",
    "the score @xmath59 is defined as : @xmath60 the @xmath61 and @xmath62 parameters are set to @xmath63 and @xmath64 , respectively , meaning that the citations for an article published during the current year account four times , the citations for an article published 4 years ago account only one time , the citations for an article published 6 years ago account @xmath65 times , and so on . * * trend hirsch index *  @xcite for the author , which assigns to each citation an exponentially decaying weight according to the age of the citation , this way estimating the impact of a researcher s work in a particular time instance .",
    "a researcher has a trend hirsch index @xmath66 if @xmath66 of his @xmath51 articles get a score of @xmath67 each , and the rest @xmath68 articles get a score of @xmath69 . for an article @xmath53 ,",
    "the score @xmath70 is defined as : @xmath71 the @xmath61 and @xmath62 parameters are set to @xmath63 and @xmath64 , respectively . *",
    "* individual hirsch index * of the author , computed by dividing the value of the standard hirsch index by the average number of authors in the articles that contribute to the hirsch index of the author , in order to reduce the effects of frequent co - authorship with influential authors  @xcite . *",
    "the * @xmath72-index * of the author / institution , measuring the magnitude of the most influential articles . for an author or institution with an hirsch index of @xmath50 that has a total of @xmath73 citations toward his papers",
    ", we say that he has an @xmath72-index of @xmath74 . *",
    "the * @xmath75-index * of the author / institution , also quantifying scientific productivity with basis on the publication record  @xcite .",
    "given a set of articles associated with the author / institution , ranked in decreasing order of the number of citations that they received , the g - index is the unique largest number @xmath75 such that the top @xmath75 articles received on average at least @xmath75 citations . * the * @xmath76-index * of the author  @xcite which represents the excess amount of citations of an author .",
    "the motivation behind this index is that we can complement the @xmath50-index by taking into account these excess amounts of citations which are ignored by the @xmath50-index .",
    "the @xmath76-index is given by the equation  [ eq : e - index ] , where @xmath77 are the citations received by the @xmath78 paper and @xmath50 is the @xmath50-index . @xmath79    besides the above features , and following the ideas of chen et al .",
    "@xcite , we also considered a set of graph features that estimate the influence of individual authors using pagerank , a well - known graph linkage analysis algorithm that was introduced by the google search engine .    pagerank assigns a numerical weighting to each element of a linked set of objects ( e.g. , hyperlinked web documents or articles in a citation network ) with the purpose of measuring its relative importance within the set .",
    "the pagerank value of a node is defined recursively and depends on the number and pagerank scores of all other nodes that link to it ( i.e. , the incoming links ) .",
    "a node that is linked to by many nodes with high pagerank receives a high rank itself .",
    "formally , given a graph with @xmath80 nodes @xmath81 , with @xmath82 directed links that represent references from an initial node to a target node with weights @xmath83 , the pagerank @xmath84 for the @xmath53th node is defined by :    @xmath85    in the formula , the sum is over the neighboring nodes @xmath86 in which a link points to node @xmath53 .",
    "the first term represents the random jump in the graph , giving a uniform injection of probability into all nodes in the graph .",
    "the second term describes the propagation of probability corresponding to a random walk , in which a value at node @xmath86 propagates to node @xmath53 with probability @xmath87 .",
    "the features that we considered correspond to the sum and average of the pagerank values associated to the papers of the author that contain the query terms , computed over a directed graph representing citations between papers .",
    "each citation link in the graph is given a score of @xmath88 , where @xmath80 represents the number of authors in the paper .",
    "authors with high pagerank scores are more likely to be considered experts .",
    "the main hypothesis behind this work is that learning to rank approaches can be effectively used in the context of expert search tasks , in order to combine different estimators of relevance in a principled way , this way improving over the current state - of - the art . to validate this hypothesis ,",
    "we have built a prototype expert search system , reusing existing implementations of state - of - the - art learning to rank algorithms , namely the svm@xmath5 implementation by thorsten joachims  @xcite and the svm@xmath6 implementation by yue et al  @xcite .",
    "we implemented the methods responsible for computing the features listed in the previous section , using _",
    "microsoft sql server 2008 _",
    "( e.g. , the full - text search capabilities for computing the textual similarity features ) and several existing java software packages ( e.g. , the law package for computing pagerank ) .",
    "the validation of the prototype required a sufficiently large repository of textual contents describing the expertise of individuals within a specific area . in this work",
    ", we used a dataset for evaluating expert search in the computer science research domain , corresponding to an enriched version of the dblp database made available through the arnetminer project .",
    "dblp data has been used in several previous experiments regarding citation analysis  @xcite and expert search  @xcite .",
    "it is a large dataset covering both journal and conference publications for the computer science domain , and where substantial effort has been put into the problem of author identity resolution , i.e. , references to the same persons possibly with different names .",
    "table  [ t1 ] provides a statistical characterization of the dblp dataset .    to train and validate the different learning to rank methods",
    ", we also needed a set of queries with the corresponding author relevance judgments . for the computer science domain",
    ", we used the relevant judgments provided by arnetminer which have already been used in other expert finding experiments  @xcite .",
    "the arnetminer dataset comprises a set of 13 query topics from the computer science domain , each associated to a list of expert authors . in order to add negative relevance judgments ( i.e. , complement the dataset with unimportant authors for each of the query topics )",
    ", we searched the dataset with the keywords associated to each topic , retrieving the top @xmath89 authors according to the bm25 metric and retrieving @xmath89 authors randomly selected from the dataset , where @xmath17 corresponds to the number of expert authors associated to each particular topic .",
    "this way , we obtained twice the relevant judgments provided by arnetminer , ending up with 2794 records for all 13 queries .",
    "table  [ judgments ] shows the distribution for the number of experts associated to each topic , as provided by arnetminer .",
    "the test collection was used in a leave - one - out cross - validation methodology , in which different experiments used 9 different queries to train a ranking model , which was then evaluated over the remaining queries .",
    "the averaged results from the four different cross - validation experiments are finally used as the evaluation result . to measure the quality of the results produced by the different learning to rank algorithms , we used two different performance metrics , namely the precision@k ( p@k ) and the mean average precision ( map ) .",
    "precision at rank @xmath90 is used when a user wishes only to look at the first @xmath90 retrieved domain experts .",
    "the precision is calculated at that rank position through equation  [ eq : precisionrank ] .",
    "@xmath91 in the formula , @xmath92 is the number of relevant authors retrieved in the top _ k _ positions .",
    "@xmath93 only considers the top - ranking experts as relevant and computes the fraction of such experts in the top-@xmath90 elements of the ranked list .",
    "the mean of the average precision over test queries is defined as the mean over the precision scores for all retrieved relevant experts . for each query @xmath94 , the average precision ( ap )",
    "is given by :    @xmath95 = \\frac{\\sum_{k=1}^n p@k[r ] \\times i\\ { g_{r_k } = \\max(g ) \\}}{\\sum_{k=1}^n i\\ { g_{r_k } = \\max(g ) \\}}\\ ] ]    as before , @xmath17 is the number of experts associated with query @xmath1 and @xmath96 is the relevance grade for author @xmath90 in relation to the query @xmath94 . in the case of our datasets , @xmath97",
    "( i.e. , we have 2 different grades for relevance , 0 or 1 ) .",
    "table  [ t2 ] presents the obtained results over the dblp dataset .",
    "the obtained results attest for the adequacy of both learning to rank approaches , showing that svm@xmath5 and svm@xmath6 achieve a similar performance , with svm@xmath5 slightly outperforming svm@xmath6 in our experiments in terms of map .    in a separate experiment",
    ", we attempted to measure the impact of the different types of ranking features on the quality of the results . using the best performing learning to rank algorithm , svm@xmath5 , we separately measured the results obtained by ranking models that considered ( i ) only the textual similarity features , ( ii ) only the profile features , ( iii ) only the graph features , ( iv ) only a representative graph feature , namely the h-@xmath39-index , ( v ) textual similarity and profile features , ( vi ) textual similarity and graph features and ( vii ) profile and graph features .",
    "table  [ t3 ] shows the obtained results , also presenting the previous results reported by yang et al .",
    "@xcite over the same dataset , as well as the results obtained by the h-@xmath39-index bibliographic index .",
    "as we can see , the set with the combination of all features has the best results .",
    "the results also show that , individually , textual similarity features have the poorest results .",
    "this means that considering only textual evidence provided by query topics , together with article s titles and abstracts , may not be enough to determine if some authors are experts or not , and that indeed the information provided by citation and co - authorship patterns can help in expert retrieval .",
    "finally , the results show that the different combinations of all features proposed in this paper outperform the previously proposed learning to rank approach for expert finding made by yang et al .",
    "@xcite    figure  [ f2 ] plots the obtained average precision in each of the individual query topics for the best performing approach , namely svm@xmath5 with the combination of all features .",
    "the figure presents the query topics in the same order as they are given in table  [ judgments ] .",
    "the horizontal dashed line corresponds to the map obtained in the same experiment .",
    "the results show that there are only slightly variations in performance for the different queries .",
    "finally , table  [ tab : people ] shows the top five people which were returned by the system for four different queries , corresponding to the best and worst results in terms of the p@5 metric .",
    "the system performed well for the queries neural networks , machine learning and support vector machines ( svms ) .",
    "although these are very related topics , the system managed to distinguish between them and still identify the relevant experts in these areas correctly . however , worse results were returned for the query boosting .",
    "these poor results can be explained by the absence of the query topics in the titles and abstracts of the publications of authors working in the area .",
    "we realized that the authors which were judged as relevant , and therefore considered experts , did not have too many query topics present in their publication s titles or abstracts , leading to misclassifications .",
    "this paper explored the usage of learning to rank methods in the context of expert searching within digital libraries of academic publications . we argue that learning to rank provides a sound approach for combining multiple estimators of expertise , derived from the textual contents , from the graph - structure of the community of experts , and from expert profile information .",
    "experiments on datasets of academic publications show very good results in terms of p@5 and map , attesting for the adequacy of the proposed approaches .    despite the interesting results , there are also many ideas for future work .",
    "recent advancements in the area of learning to rank for information retrieval are , for instance , concerned with query - dependent ranking ( i.e. , using different ranking models according to the type of queries being issued ) and it would be interesting to test these techniques in expert searching tasks .    our approach to the expert finding problem can also be generalized to any type of entity search .",
    "the introduction of entity ranking track in inex 2007 , with basis on a _ wikipedia _ dataset , provides a good platform for general entity search evaluation  @xcite . for future work",
    ", it would be interesting to experiment with learning to rank methods , similar to the ones proposed in this paper , over the more general entity search problem .",
    "k.  balog , l.  azzopardi , and m.  de  rijke .",
    "formal models for expert finding in enterprise corpora . in _ proceedings of the 29th annual international acm sigir conference on research and development in information retrieval _ ,",
    "2006 .",
    "a.  p. de  vries , j.  a. thom , a - m .",
    "vercoustre , n.  craswell , and m.  lalmas",
    ". overview of the inex 2007 entity ranking track . in _ proceedings of the 7th international workshop of the initiative for the evaluation of xml retrieval _ , 2008 .",
    "y.  yue , t.  finley , f.  radlinski , and t.  joachims . a support vector method for optimizing average precision . in _ proceedings of the 30th acm",
    "sigir international conference on research and development in information retrieval _ , 2007 ."
  ],
  "abstract_text": [
    "<S> the task of expert finding has been getting increasing attention in information retrieval literature . however , the current state - of - the - art is still lacking in principled approaches for combining different sources of evidence in an optimal way . </S>",
    "<S> this paper explores the usage of learning to rank methods as a principled approach for combining multiple estimators of expertise , derived from the textual contents , from the graph - structure with the citation patterns for the community of experts , and from profile information about the experts . </S>",
    "<S> experiments made over a dataset of academic publications , for the area of computer science , attest for the adequacy of the proposed approaches . </S>"
  ]
}