{
  "article_text": [
    "according to many textbooks , a hallmark of turbulence is its unpredictability @xcite .",
    "here we address this issue using experimental data from a turbulent soap film .",
    "the starting point is shannon s information theory @xcite , where in neil gershenfeld s words ,  ... information is what you do nt already know \" @xcite .",
    "our experiment conveys information about the physical state of the system .",
    "the amount of previously unknowable information is our measure of unpredictability .",
    "our objective is to quantify the prediction of turbulent velocity fluctuations and in the process characterize turbulence .",
    "we will measure both the limits on making predictions and how much we need to know to do so @xcite .",
    "this approach parallels the use of lyapunov exponents to characterize the sensitivity to initial conditions ( unpredictability ) of chaotic systems @xcite .",
    "the main finding is a transition in our ability to predict , corresponding to the emergence of a cascade .",
    "the turbulent cascade envisioned by richardson and described mathematically by kolmogorov is the prevalent picture of turbulence @xcite . in this picture ,",
    "energy ( or enstrophy in two dimensions ) is transported across scales from some injection scale until it reaches a dissipative scale and the cascade ends .",
    "this cascade exists in both three dimensional ( 3d ) and two dimensional ( 2d ) turbulence , such as the one studied here .",
    "we argue that a cascade influences prediction , as discussed below .",
    "the central quantity in information theory is the entropy density @xmath1 @xcite .",
    "it is the information we receive per measurement ( which in this case means a single velocity value ) .",
    "think of this as the number of yes / no questions needed on average to determine the next measurement ( not necessarily an integer ) @xcite .",
    "this number can be reduced if the data is not random and structureless @xcite . by looking at all previous data ,",
    "we reduce the unpredictability to @xmath1 . of course , knowing the value of @xmath1 does not tell us how to make a prediction , only the limits on our ability to do so .    while @xmath1 is the amount of information that we do nt know , we could also ask how much we do know .",
    "this is the excess entropy @xmath2 , which is the information about correlations in the system @xcite .",
    "it is the reduction of unpredictability .",
    "accurate prediction requires an amount of information at least equal to @xmath2 @xcite .",
    "although @xmath2 further characterizes our ability to predict , we still must decide how to do so .",
    "now we must decide how to make a prediction .",
    "there are many options , but our choice is to make a statistical model with a set of states and the probabilities to transition between them . for a binary system with @xmath3 and @xmath4 , this will look like the schematic in fig .",
    "[ digraph2 ] . there is more than one way to define which states to use and potential benefits from choosing them cleverly .    starting with the states that are present in the data @xmath5 , that set",
    "is then reduced by combining those states which statistically lead to the same future @xcite .",
    "this makes the connection with prediction clear .",
    "the information contained in these optimally predictive  causal states \" @xmath6 is the statistical complexity @xmath7 of crutchfield @xcite .",
    "it is defined so that it is zero for laminar flows and zero also for completely random velocity fluctuations . in both limits the system",
    "s prior behavior tells one nothing about velocity fluctuations to follow .",
    "it is known that @xmath8 , but the reasons why are not always clear @xcite .",
    "more details on @xmath1 , @xmath2 and @xmath7 can be found in the appendices [ appendix : data]-[appendix : c ] .",
    "this study focuses on predicting the spatial variations of turbulence .",
    "a prediction in space means that given the velocity @xmath9 at a point @xmath10 , one anticipates the velocity at some other point @xmath11 away .",
    "prediction is normally associated with time @xcite , but there are several reasons for considering the spatial alternative .",
    "we know that the temporal and spatial features of turbulence are distinct .",
    "the fundamental work of kolmogorov dealt only with the spatial structure of turbulence @xcite .",
    "kraichnan and others have also shown that many of the essential features of turbulence are retained if one throws away temporal correlations but keeps spatial ones @xcite .",
    "thus , a treatment of spatial prediction is arguably of more fundamental interest than temporal prediction , at least for turbulence .    for a specific application ,",
    "consider airplane flight .",
    "the typical cruise speed of a boeing 747 is @xmath12 m / s @xcite .",
    "contrast this with the rms velocity fluctuations @xmath13 of  strong \" atmospheric turbulence @xmath14 m / s @xcite . since @xmath15 is small",
    ", one must use taylor s frozen turbulence hypothesis when discussing the turbulence the airplane encounters @xcite .",
    "in other words , an airplane flies fast enough to sample only the spatial variations of turbulence .",
    "there is not enough time for the turbulent velocity field to evolve temporally .",
    "we have previously used @xmath1 to characterize two - dimensional ( 2d ) turbulence in a flowing soap film as a function of reynolds number @xmath0 @xcite .",
    "here we use @xmath7 and @xmath2 to go beyond this and fully characterize the prediction of turbulent velocity fluctuations .",
    "this leads to the following conclusions .",
    "( 1 ) the presence of correlated velocity fluctuations @xmath16 the amount of information @xmath7 needed to predict .",
    "however , those same velocity correlations increase @xmath2 .",
    "thus , @xmath7 and @xmath2 may be used as an indicator of the presence of a turbulent cascade .",
    "( 2 ) 2d turbulence becomes increasingly easy to predict as @xmath0 increases .",
    "while this study is on an experimental 2d system , the arguments apply for 3d turbulence as well .",
    "moreover , no specific assumptions about the data are made .",
    "thus , this study serves as an experimental test bed for these tools , which can be used generally for other complex systems .",
    "as a simple illustration of these ideas , consider a coin flipping experiment where each subsequent flip will be the same as the previous one with probability @xmath17 $ ] @xcite .",
    "this is the statistical model for , @xmath18 , correlated random walks @xcite .",
    "the statistical evolution of this system will look like fig .",
    "[ digraph2 ] but with , @xmath18 , @xmath19 .",
    "if @xmath20 we have the usual fair coin toss experiment , with @xmath21 and @xmath22 , since this system is maximally uncertain but statistically simple to predict with no information being shared between the past and future . in this fully random case ( @xmath20 ) both 0 and 1 predict the same future , so they are combined into a single causal state . of course ,",
    "with only one causal state , @xmath23 automatically ( see eq .",
    "[ eq : c ] ) .",
    "consider now a slight deviation of @xmath24 from 0.5 . now",
    "@xmath25 since we will always need to know 1 bit of information ( the previous flip ) to predict the future .",
    "we can also calculate @xmath1 and @xmath2 ( see appendices [ appendix : h ] and [ appendix : e ] ) , which are plotted together with @xmath7 vs. @xmath24 in fig .",
    "[ simple_example ] .",
    "since @xmath26 means more predictable , it is clear that @xmath1 should decrease with increasing @xmath24 , while @xmath2 should increase .",
    "this example highlights the difference between @xmath2 and @xmath7 , the crypticity @xmath27 @xcite .",
    "here @xmath28 , which is a unique feature of this system being first - order markovian @xcite . the extra information needed to predict beyond @xmath2",
    "is due to the randomness still intrinsic in the causal states themselves .",
    "there are many examples for which @xmath29 @xcite , but this is not always so .",
    "an important lesson we learn from this example is that @xmath1 , @xmath2 and @xmath7 were all necessary to characterize this system s behavior . for @xmath24 only slightly different from 0.5",
    ", @xmath1 and @xmath2 will still suggest a nearly random system , much like a slightly biased coin .",
    "the fact that @xmath7 is large and not 0 ( its random value ) , shows that there are important correlations not present in a simple biased coin system .",
    "the system is both unpredictable ( large @xmath1 ) and difficult to predict ( large @xmath7 ) .",
    "a similar result will be found for the low reynolds number flow in sec .",
    "[ sec : results ] .",
    "now consider a turbulent soap film , which is a good approximation to 2d turbulence since the film is only several @xmath30 m thick @xcite . the soap solution is a mixture of dawn ( 2@xmath31 ) detergent soap and water with 4 @xmath30 m particles added for laser doppler velocimetry ( ldv ) measurements .",
    "figure [ setup ] contains a diagram of the experimental setup as well as thickness fluctuations visualized through thin film interference using a monochromatic light source .",
    "the thickness fluctuations act as a surrogate for velocity fluctuations @xcite .",
    "the soap film is suspended between two vertical blades .",
    "nylon fishing wire connects the blades to the nozzle above and the weight below .",
    "the nozzle is connected by tubes to a valve and a top reservoir which is constantly replenished by a pump that brings the spent soap solution back up to the top reservoir .",
    "the flow is gravity - driven .",
    "typical centerline speeds @xmath32 are several hundred cm / s with rms fluctuations @xmath33 ranging roughly from 1 to 30 cm / s .",
    "the channel width @xmath34 is usually several cm .",
    "the reynolds number @xmath35 , where @xmath36 is the kinematic viscosity , thus ranges from 10 to 10,000 .",
    "turbulence is generated using several different protocols .",
    "we can ( 1 ) insert a row of rods ( comb ) perpendicular to the film , ( 2 ) replace on or both smooth walls with rough walls ( saw blades ) with the comb removed and possibly a rod inserted near the top @xcite , or ( 3 ) use a comb with smooth walls as in ( 1 ) but now very near the top of the soap film where the flow is still quite slow .",
    "the comb teeth are @xmath37 mm in diameter and several mm apart .",
    "the saw blade teeth are @xmath38 mm tall and wide .",
    "when protocol ( 1 ) is used we almost always observe the direct enstrophy cascade @xcite .",
    "if procedure ( 2 ) is used , we can observe an inverse energy cascade @xcite , although this depends sensitively on the flux and @xmath34 .",
    "when protocol ( 3 ) is used , we see no cascade at all .    the type of cascade is identified by calculating the one - dimensional velocity energy spectrum @xmath39 , where @xmath40 for the enstrophy cascade , @xmath41 and for the energy cascade @xmath42 @xcite .",
    "a number of measurements were taken above the blades where the flow is slower .",
    "for protocol ( 3 ) , @xmath39 is flat and so apparently there is no cascade , although the flow is not laminar ( @xmath43 ) . see fig .",
    "[ spectra ] for some representative spectra . in fig .",
    "[ re_e&c ] the data for @xmath44 have a flat @xmath39 .    in all cases ,",
    "we measure the longitudinal ( streamwise ) velocity component at the horizontal center of the channel .",
    "the data rate is @xmath45 5000 hz and the time series typically had more than @xmath46 data points . for this system",
    "the time series is really a spatial series by virtue of taylor s frozen turbulence hypothesis @xcite .",
    "this means that the spatial variations are swept through the ldv s measuring point by the mean flow so quickly that it is as if the ldv were scanning a frozen - in - time velocity field .",
    "this distinction between spatial and temporal is essential , as discussed above and in ref .",
    "the quantities @xmath7 , @xmath2 and @xmath1 are plotted vs. @xmath0 in fig .",
    "[ re_e&c ] .",
    "the data are roughly divided in @xmath0 into no - cascade ( flat @xmath39 for @xmath44 ) and cascade ( power law @xmath39 for @xmath47 ) regimes . although @xmath7 and @xmath2 intersect at finite @xmath48 in fig .",
    "[ re_e&c ] , this meeting point depends on the data analysis . in order to calculate probabilities from continuous data",
    ", one must bin the measurements . for different binning protocols we find a different meeting point .",
    "however , the @xmath0-dependent behavior of @xmath1 , @xmath2 and @xmath7 discussed below is the same .",
    "see appendices [ appendix : data ] and [ appendix : c ] for more details on the treatment of the data",
    ".      now consider the behavior of @xmath1 , @xmath2 and @xmath7 in the  cascade regime \" of fig .",
    "[ re_e&c ] , @xmath47 . at these values of @xmath0",
    ", @xmath39 shows power law scaling as in fig .",
    "[ spectra ] .",
    "both energy and enstrophy cascade data are present .",
    "we see from fig .",
    "[ re_e&c ] that the unpredictability ( @xmath1 ) is decreasing , the amount of information needed to predict ( @xmath7 ) is also decreasing , while information about correlations ( @xmath2 ) is increasing ( all logarithmically ) .",
    "the opposite trend in @xmath0 for @xmath2 and @xmath7 is noteworthy .",
    "it is surprising that the behavior of @xmath1 , @xmath2 and @xmath7 for @xmath47 does not depend on which cascade is present , only on whether or not there is a cascade at all .",
    "the increase of @xmath2 with @xmath0 can be understood from the traditional view that as @xmath0 increases , the  inertial range \" of correlated scales broadens @xcite .",
    "the increase in correlations across spatial scales is reflected by an increase in @xmath2 .",
    "we can go further to suggest a connection between @xmath2 and the broadness of the inertial range .",
    "dimensional arguments suggest that the turbulent degrees of freedom go as @xmath49 for the enstrophy cascade and @xmath50 for the inverse energy cascade . in the 3d energy cascade , @xmath51 @xcite .",
    "thus the behavior @xmath52 in fig .",
    "[ re_e&c ] indicates that @xmath2 is a logarithmic measure of the extent of the inertial range .",
    "an interpretation of the behavior of @xmath7 is also suggested by the traditional picture of 2d turbulence @xcite .",
    "as @xmath0 grows , the inertial range broadens , and more of the velocity fluctuations come under the governance of the cascade .",
    "thus , the randomness @xmath1 will decrease , and because the cascade s structure is dominating , our prediction cost @xmath7 decreases .",
    "this is the result of the general principle that patterns help us to predict @xcite . here",
    "the pattern is the cascade s structure .",
    "although turbulence has traditionally been thought of as unpredictable @xcite , with @xmath1 , @xmath2 and @xmath7 we see that the spatial predictability of ( 2d ) turbulence is increasing with @xmath0 in its fullest sense : we can predict further and more easily .",
    "this is in stark contrast to turbulence s increasing temporal unpredictability with @xmath0 , at least as evidence by numerical work @xcite .",
    "this reiterates the important difference between time and space in turbulence , which is of fundamental interest and practical importance ( recall the airplane ) .",
    "next consider the region of fig .",
    "[ re_e&c ] labeled  no - cascade \" .",
    "the absence of a cascade is evidenced by a lack of power law scaling in @xmath39 as in fig .",
    "[ spectra ] .",
    "here @xmath1 , @xmath2 and @xmath7 are relatively constant with respect to @xmath0 . it is notable that @xmath1 is very near to the random ( white noise ) value of @xmath53 , which is nothing like laminar flow where @xmath54 .",
    "when a cascade emerges at @xmath55 , all three quantities begin to change noticeably .",
    "this change in behavior is decidedly different from the laminar to turbulent transition which only involves the onset of fluctuations @xcite .",
    "the fluctuations of pre - cascade turbulence are apparently difficult to predict ( @xmath7 is large in fig .",
    "[ re_e&c ] ) .",
    "moreover , the wide separation between @xmath2 and @xmath7 is surprising .",
    "we emphasize that @xmath7 , @xmath2 and @xmath1 have made a clear distinction between simply unsteady velocity fluctuations and cascade turbulence .",
    "it is natural that tools designed to quantify randomness and order should be able to detect this transition .",
    "simulations of 3d turbulence have shown that statistics of the velocity derivatives are gaussian ( or sub - gaussian ) up until a small value of the reynolds number @xcite .",
    "below this value of reynolds number , there is a ",
    "regime which is a complex time - dependent flow rather than a turbulent one . \"",
    "they observe a transition similar to the one described here .",
    "their transition is evidenced primarily by non - gaussian velocity derivative statistics .",
    "recall that nongaussian statistics are a general feature of fully developed turbulence @xcite .",
    "we also resort here to a more traditional tool from turbulence , the correlation function @xmath56 plotted in fig .",
    "[ correlation ] @xcite .",
    "@xmath57 has typically been thought of as a tool for determining the range of length scales over which @xmath9 is correlated .",
    "@xmath57 is telling us that for small @xmath58 , the range of scales over which @xmath9 is correlated is very small .",
    "figures [ spectra ] and [ correlation ] both indicate that for @xmath58 the data is like white noise .",
    "the values of @xmath59 and @xmath60 in fig .",
    "[ re_e&c ] reinforce this interpretation . on the other hand , if the fluctuations were truly like white noise , then @xmath7 should also be zero in this regime , which it is not .",
    "recall that in the simple example from sec .",
    "[ sec : example ] , @xmath7 is large when @xmath1 and @xmath2 are close to their random values .",
    "the data are nearly random but have an explicit albeit short dependence on the past which drives @xmath7 from zero to its maximum value . if we were to only look at @xmath1 ( or @xmath2 ) , we would miss that there is nontrivial ( non - random ) behavior for low @xmath0 .",
    "we have yet to understand why self - similar turbulence emerges from this ",
    "complex , time - dependent flow \" @xcite .",
    "one sees from another nonlinear system , rayleigh - benard convection , that there is a lot to be learned at modest levels of excitation @xcite .",
    "the traditional approaches to the laminar - turbulent transition deal with instabilities of the laminar flow @xcite .",
    "whether it is the quasi - periodicity of landau @xcite or the nonperiodicity of ruelle and takens @xcite , none of these approaches deal with the development of a cascade @xcite . and",
    "yet a cascade is always present in  fully - developed turbulence \" @xcite .",
    "how does this cascade emerge ?",
    "new approaches and models are necessary to understand how cascade behavior develops out of a  complex , time - dependent flow \" @xcite . since this development is clearly visible in fig .",
    "[ re_e&c ] , an information theory approach seems promising .",
    "we suggest an information - theoretic indicator of a cascade . based on the above arguments , large @xmath2 and @xmath61",
    "should both indicate a well - developed cascade . with that in mind",
    ", we can also consider the  predictive efficiency \" @xmath62 @xcite , which is an increasing function of @xmath0 , as shown in fig .",
    "[ pred_eff ] for two different binning protocols .",
    "the ratio @xmath62 tells us the fraction of the information needed to predict @xmath7 that is due to correlations @xmath2 .",
    "it is nearly zero when no cascade is present and grows smoothly after one has emerged .",
    "this shows that @xmath62 is a nice tool for studying the transition to cascade turbulence .    besides this cascade transition ,",
    "the laminar to fluctuation transition is also of interest .",
    "unfortunately , we are not able to access a truly laminar regime with our apparatus . for laminar flow and this geometry ,",
    "@xmath63 @xcite . looking at fig .",
    "[ re_e&c ] , and with the reasonable assumption that @xmath1 and @xmath7 are continuous functions of @xmath0 , one expects a local maximum in @xmath7 and @xmath1 at some low value of @xmath0 .",
    "this maximum would correspond to a special transition in the evolution of the flow between laminar and turbulent behavior .",
    "the observation of this maximum requires a different experimental setup .",
    "the approach here is not limited to incompressible navier - stoke s turbulence .",
    "in fact it is useful for any nonlinear system , even those for which one does not know the equations of motion .",
    "when we think of turbulence in terms of information and prediction , we can make new distinctions and draw new insights .",
    "we have been able to highlight a cascade transition and have seen that spatially , turbulence is becoming easier to predict statistically as @xmath0 increases . as for our airplane , figs .",
    "[ re_e&c ] and [ pred_eff ] bring bittersweet news .",
    "although its passengers will certainly experience a rougher flight as @xmath0 increases , at least they wo nt be as surprised .",
    "we would like to thank d. p. feldman for explaining several concepts to us and for making his excellent lecture notes available online . c. j. ellison was kind enough to explain some of the finer points of the formalism to us .",
    "we are also indebted to m. bandi for providing numerous suggestions and insights .",
    "the criticisms and suggestions from several referees have also been beneficial .",
    "this work is supported by nsf grant no .",
    "1044105 and by the okinawa institute of science and technology ( oist ) .",
    "is also supported by a mellon fellowship through the university of pittsburgh .",
    "the approach used here is data driven .",
    "we are given a data stream and use it to say something about the system that made it .",
    "the main assumption is that the system is stationary @xcite .",
    "we do nt appeal to the navier - stoke s equation or any of kolmogorov s universality assumptions @xcite .",
    "this method is generally applicable to many types of systems .",
    "the formalism is now introduced . in the discussion that follows",
    "an uppercase @xmath5 denotes the data ( the random variable , the message ) with possible velocity values @xmath64 and the lowercase @xmath9 denotes a particular member of that set",
    ". we can also consider groups of length @xmath65 denoted by the set @xmath66 and its particular members @xmath67 .",
    "we are interested in treating a group because of the correlations that may exist between its members .",
    "overhead arrows indicate a direction in the 1d data set relative to an arbitrary reference point @xmath10 .",
    "for example , @xmath68 refers to any block of data of size @xmath65 taken to the right of @xmath10 .",
    "for example , if @xmath69 , then a particular block @xmath70 is as below @xmath71 where @xmath72 is the spatial resolution . if no @xmath65 is mentioned , the block is ( semi-)infinite .",
    "let @xmath5 be a velocity component in the soap film , which is characterized by the experimental probability distribution @xmath73 .",
    "the focus is on the information shared between different directions @xmath74 and @xmath75 relative to the arbitrary point @xmath10 @xcite .",
    "if we had data with explicit time dependence , we would talk about the past , future and present @xcite .    in order to use this formalism with turbulence",
    ", the continuous experimental data must be converted to symbols @xcite .",
    "a partition is defined which assigns data values in specific ranges to unique symbols @xcite .",
    "this is usually referred to as binning the data .",
    "all experiments of continuous systems do this because of limited resolution @xmath76 .",
    "there are numerous previous studies where even binarizing a turbulent velocity signal has given more insight than traditional techniques @xcite .    in this work we primarily use a binary partition ( alphabet size @xmath77 ) with the single partition wall located at the mean velocity .",
    "this smaller alphabet allows us to use a larger @xmath65 with confidence and so cover a wider range of length scales in our analysis . just as with @xmath1 in ref .",
    "@xcite , we have found that the general behavior of @xmath7 and @xmath2 with respect to @xmath0 is independent of the partition size ; partitions of sizes @xmath78 , @xmath79 gave similar results . here",
    "the choice was made to use the same alphabet size @xmath80 for all @xmath0 .",
    "this was done so that all data , if random , would have the same maximum value of @xmath81",
    ". thus , all data are treated at the same level of description .",
    "of course , there are alternative choices for setting the partition size .",
    "we have already spoken of the entropy density @xmath1 as a measure of unpredictability .",
    "the definition of entropy we are most familiar with is @xcite @xmath82 with units of  bits \" .",
    "this is the unpredictability of single data points given no immediate knowledge of any previous data points .",
    "an example of this would be estimating the unpredictability of letters in the english language based solely on the frequency of the letters and not on words .",
    "consider two examples .",
    "first look at a random string of 1s and 0s where @xmath83 .",
    "here @xmath84 is the maximum possible value . next consider a periodic string such as  ... 0101 ... \" . here again @xmath83 , and so here also @xmath84 .",
    "however , something is wrong since a periodic string should be perfectly predictable .",
    "since this definition of unpredictability misses any structure or correlations extending across scales , it is generalized to the block entropies @xcite @xmath85 this is the unpredictability of blocks of data . of course",
    ", if we want to go back to looking at the unpredictability of a single data point , we can manipulate the @xmath86 .",
    "the unpredictability of a single data point knowing @xmath65 immediately previous data points is @xmath87 the @xmath65-dependence is inconvenient , but if we make @xmath65 large enough @xmath88 will become @xmath65-independent ( for most systems ) @xcite .",
    "we are now ready to introduce the entropy density @xmath89 with an equivalent definition in terms of the conditional entropy @xcite .",
    "this says explicitly how unpredictable a single data point is given all previous ones .    to further develop intuition for how @xmath1 is associated with unpredictability , recall the lyapunov exponents @xcite .",
    "if a system is chaotic , its largest lyapunov exponent @xmath90 is greater than 0 @xcite .",
    "if our measurement has a resolution of @xmath76 and we enforce a tolerance of @xmath91 , then our system is typically predictable up to a distance of @xmath92 .",
    "consider an information approach to the same problem .",
    "we choose to ( or are forced to ) have a particular partition size @xmath76 .",
    "this will correspond to @xmath93 .",
    "our maximum possible uncertainty in bits is @xmath94 .",
    "it will take @xmath95 steps into the future to add up to this uncertainty and beyond this our data stream is unpredictable .",
    "we estimate @xmath1 using the limit of @xmath88 from eq .",
    "[ eq : hl ] in eq .",
    "[ eq : h ] , as discussed in ref .",
    "@xcite and elsewhere @xcite .",
    "the undersampling bias in the @xmath96 is corrected using grassberger s method @xcite , although this did not affect the value of @xmath1 very much .",
    "the @xmath88 typically reached @xmath1 at @xmath97 .",
    "while @xmath1 tells us about the unpredictability of @xmath98 given @xmath74 , we may also want to know how much we actually learned about @xmath75 from @xmath74 .",
    "this is the excess entropy @xmath2 .",
    "it is in some sense the opposite of unpredictability .",
    "@xmath2 does nt ask how much information we get from @xmath75 upon measuring , but how much we do nt get .",
    "we already know it . stated mathematically @xcite :",
    "@xmath99 where @xmath100 is the mutual information shared between @xmath75 and @xmath74 @xcite .",
    "this @xmath2 is the information we got from @xmath74 that reduces unpredictability .",
    "however , just like @xmath1 , this is a statistical statement that does nt tell us how to use that information . @xmath2 does provide us with a lower bound on the amount of information needed to make predictions , since we need to account for all correlations .",
    "no matter how it s done , @xmath2 bits will be necessary @xcite , otherwise we ignore some structure in the system .    an alternative expression is used to estimate @xmath2 @xcite : @xmath101 this calculation uses essentially the same quantities involved in estimating @xmath1 .",
    "it turns out that for many chaotic systems , @xmath102 ( @xmath103 is some constant independent of @xmath65 ) @xcite .",
    "this empirical relationship has been shown to improve the estimation of @xmath2 @xcite .",
    "this expression will be used when possible .",
    "we now come to prediction using a statistical model . we must determine a set of special states called causal states @xmath6 @xcite .",
    "these will make up a minimal representation of our system for predictive purposes .",
    "in other words , we are trying to build the simplest possible statistical model of our data . for more details",
    "there shalizi @xmath104 @xmath105 show that within the information theory framework , the approach described below is maximally predictive with a minimal amount of information needed .",
    "a statistical model consists of a set of states and the transition probabilities between them . to determine @xmath6 consider all unique blocks of data @xmath106 .",
    "one would like to make @xmath65 large to capture as many correlations as possible , but the finite amount of data means only finite @xmath65 can be statistically reliable .",
    "for our data , @xmath97 is a good compromise .",
    "this @xmath65 is also chosen because it is the value of @xmath65 at which @xmath88 typically reached @xmath1 .",
    "we now calculate the conditional probability @xmath107 that any particular block @xmath108 will give rise to any other block of the same length . if the conditional probability distributions conditioned on two blocks are the same , they are indistinguishable from a statistically predictive point of view .",
    "thus block 1 and block 2 are equivalent , @xmath109 , if @xmath110 .",
    "this process incorporates pattern recognition by construction , which is why @xmath7 was originally introduced as a complexity quantifier @xcite .",
    "all equivalent blocks are then combined and organized into a set of predictive causal states @xmath6 .",
    "for example , suppose there are only three states @xmath111 , @xmath112 , and @xmath113 ( forget about @xmath65 here ) .",
    "if @xmath114 , then @xmath115 and we have two causal states @xmath116 and @xmath117 . refer back to the example in sec .",
    "[ sec : example ] .",
    "it is apparent that if @xmath20 ( or 1 ) there is only one causal state , but if @xmath118 ( or 1 ) , there are two causal states .",
    "the shannon information ( entropy ) contained in @xmath6 is the statistical complexity @xcite @xmath119 = - \\sum_{s } p(s ) \\log_2 p(s ) .",
    "\\label{eq : c}\\ ] ] this is the total amount of information needed to statistically reproduce the data , as we shall soon see .    here is how this prediction work in practice : we find the causal states @xmath6 as just described and so we also have the transition probabilities between the states @xmath6 .",
    "start out in some state @xmath9 belonging to a particular @xmath120 .",
    "determine the next @xmath121 statistically using the known transition probabilities @xmath122 ( the @xmath123 means the next step ) .",
    "then determine a particular @xmath33 belonging to this @xmath121 according to @xmath124 .",
    "this is symbolically represented by @xmath125 then repeat . in this way the data is reproduced in a statistical sense . in summary , we can write down the probability of any @xmath9 starting from any other @xmath9 . this is statistical prediction .",
    "we needed to know an amount of information @xmath126 $ ] to carry out the above prediction program .",
    "that is , we need to ask ( on average ) @xmath7  yes \" or  no \" questions in order to find the current state of the system , and then predict from there . by design ,",
    "this connects with the system s predictability , since organizing the message s parts into causal states will affect the value of @xmath7 .",
    "we can appreciate the distinction between @xmath7 and @xmath1 by considering an unbiased coin flip .",
    "the system is maximally unpredictable with @xmath21 , since one has no clue as to what will come next .",
    "in contrast , @xmath23 since no information is needed for statistical prediction .",
    "there is only one causal state .",
    "this may strike the readers as strange , since random data is supposedly impossible to predict .",
    "this is only true if we insist on a prediction that has absolute certainty .",
    "here we are predicting statistically .",
    "when actually handling real data to identify @xmath6 , one must deal with imperfections .",
    "these may be due to external noise or the finiteness of the amount of data .",
    "regardless of the origin , one must set some sensible threshold to determine if two conditional probability distributions are the same , since they will never be identical .",
    "an example of some conditional probability distributions is shown in fig .",
    "[ cond_pdf ] .",
    "two of the distributions are similar , indicating that the two states belong to the same causal state .",
    "the third distribution is entirely different .",
    "the task is to choose a sensible metric to make this distinction objectively .",
    "we wrote a matlab program that uses a @xmath127 test to compare conditional probability distributions @xcite .",
    "we use a 0.95 confidence level , but the results are not sensitive to this choice",
    ". results from our method are in good agreement with another frequently used algorithm @xcite . in the end , of course , the choice has an element of subjectivity to it .",
    "note that alternative expressions for @xmath1 and @xmath2 are @xcite @xmath128 \\label{eq : hs}\\ ] ] and @xmath129 =   h[\\overrightarrow{s } ] - h[\\overrightarrow{s } ; \\overleftarrow{s } ] = c - h[\\overrightarrow{s } ; \\overleftarrow{s } ] .",
    "\\label{eq : es}\\ ] ] equations [ eq : hs ] and [ eq : es ] say that the causal states serve as a sufficient representation .",
    "equation [ eq : hs ] also serves as a check on our determination of @xmath6 by comparing @xmath1 calculated with eq .",
    "[ eq : hs ] with our previous method from eqs .",
    "[ eq : hl ] and [ eq : h ] . from eq .",
    "[ eq : es ] we see that @xmath7 may be different from @xmath2 .",
    "actually , it can be shown that @xmath8 .",
    "the difference between these two has various interpretations .",
    "the interpretation of crutchfield and coworkers is that a system may have some  hidden \" information , or crypticity @xmath130 @xcite . despite looking at the infinite @xmath74 , we missed out on the need to have an extra amount of information @xmath131 for prediction .",
    "wiesner and coworkers have interpreted @xmath131 as the information erased at each step in the system s evolution @xcite .",
    "if we were to simulate this process on a computer , @xmath132 ( where @xmath133 = boltzmann s constant and @xmath134 is the computer s temperature ) would be the minimum thermodynamic cost .",
    "this is an extension of landauer s work on computation .",
    "he was the first to suggest that the erasure of information has a thermodynamic cost @xcite .",
    "a. n. kolmogorov ,  the local structure of turbulence in incompressible viscous fluids for very large reynolds numbers , \" dokl . akad",
    "sssr * 30 * , 299 ( 1941 ) ( proc .",
    "lond . a * 434 * ( reprinted ) )"
  ],
  "abstract_text": [
    "<S> prediction is a fundamental objective of science . </S>",
    "<S> it is more difficult for chaotic and complex systems like turbulence . here </S>",
    "<S> we use information theory to quantify spatial prediction using experimental data from a turbulent soap film . at high reynolds number @xmath0 where a cascade exists </S>",
    "<S> , turbulence is becoming easier to predict as the inertial range broadens . </S>",
    "<S> a transition corresponding to the emergence of a cascade at low @xmath0 is detected by looking at turbulence through prediction . </S>"
  ]
}