{
  "article_text": [
    "let @xmath9 be a poisson process with a constant intensity @xmath10 and let @xmath11 be a sequence of independent random variables independent of @xmath12 and having a common distribution function @xmath13 with density @xmath14 ( with respect to the lebesgue measure ) .",
    "a compound poisson process ( abbreviated cpp ) @xmath15 is defined as @xmath16 where the sum over an empty set is by definition equal to zero .",
    "cpps form a basic model in a variety of applied fields , most notably in e.g.  queueing and risk theory , see  @xcite and  @xcite and the references therein , but also in other fields of science , see e.g.   @xcite , @xcite for stochastic models for precipitation , @xcite on modelling of hurricane damage , or @xcite for applications in economics and finance .",
    "suppose that corresponding to the ` true ' parameter values @xmath17 and @xmath18 a discrete time sample @xmath19 is available from , where @xmath20 such a discrete time observation scheme is common in a number of applications of cpp , e.g.  in the precipitation models of the above references .",
    "based on the sample @xmath21 we are interested in ( non - parametric ) estimation of @xmath2 and @xmath22 before proceeding further , we notice that by the stationary independent increments property of a compound poisson process , the random variables @xmath23 , @xmath24 , are independent and identically distributed .",
    "each @xmath25 has the same distribution as the random variable @xmath26 where @xmath27 is independent of the sequence @xmath28 and has a poisson distribution with parameter @xmath29 .",
    "hence , our problem is equivalent to estimating ( non - parametrically ) @xmath2 and @xmath0 based on the sample @xmath30 .",
    "we will henceforth use this alternative formulation of the problem .",
    "our emphasis is on _ high frequency _ data , @xmath31 as @xmath32 but the obtained results are also valid for _ low frequency _ observations , i.e.  for fixed @xmath6 .",
    "our main result is on the contraction rate of the posterior distribution , which we show to be , up to a logarithmic factor , @xmath33 .",
    "a by now standard approach to obtain contraction rates in an iid setting is to verify the assumptions of the fundamental theorem  2.1 in @xcite .",
    "it should be noted that in the present high frequency setting , this theorem is not applicable .",
    "one of the model assumptions underlying this theorem , which is satisfied in @xcite , is that one deals with samples of a _ fixed _ distribution , whereas in our present high frequency observation regime the distribution of @xmath34 is _ varying _ , with the dirac distribution concentrated at zero as its limit for @xmath7 .",
    "therefore we propose an alternative approach , circumventing the use of the cited theorem  2.1 .",
    "the theoretical contribution of the present paper is therefore not only the statement of the main result itself , but also its proof .",
    "next to this we also discuss a practical implementation of our non - parametric bayesian approach , a markov chain monte carlo algorithm that samples from the joint distribution of the unknown parameters in the mixture density and certain introduced auxiliary variables .      because adding a poisson number of @xmath35 s amounts to compounding their distributions , the problem of recovering the intensity @xmath2 and the density @xmath0 from the observations @xmath36 s can be referred to as decompounding .",
    "decompounding already has some history : the early contributions  @xcite and  @xcite dealt with estimation of the distribution function @xmath37 paying particular attention to the case when @xmath38 is discrete , while the later contributions  @xcite ,  @xcite and  @xcite concentrated on estimation of the density @xmath0 instead .",
    "more ( frequentist ) theory on statistical inference on compound poisson processes ( and more generally on lvy processes ) can be found in the volume  @xcite , with the survey paper  @xcite devoted to statistical methods for high frequency discrete observations , with a special section on compound poisson processes .",
    "other references on statistics for lvy processes in the high frequency data setting are @xcite , @xcite , @xcite , @xcite , @xcite , and @xcite .",
    "all these approaches are frequentist in nature .",
    "on the other hand , theoretical and computational advances made over the recent years have shown that a non - parametric bayesian approach is feasible in various statistical settings ; see e.g.  @xcite for an overview .",
    "this is the approach we will take in this work to estimate @xmath2 and @xmath22    to the best of our knowledge , non - parametric bayesian approach to inference for ( a class of ) lvy processes was first considered in @xcite .",
    "that paper , contrary to the present context , dealt with observations at fixed equidistant times , and was strongly based on an application of theorem  2.1 of @xcite , as already alluded to in the problem formulation of section  [ section : pf ] .",
    "the present work complements the results from @xcite , in the sense that we now allow high frequency observations , which requires a substantially different route to prove our results , as we will explain in more detail in section  [ int_res ]",
    ".    we will study the non - parametric bayesian approach to decompounding from a frequentist point of view ( in the sense specified below ) , so that one may also think of it as a means for obtaining a frequentist estimator .",
    "advantages of the non - parametric bayesian approach include automatic quantification of uncertainty in parameter estimates through bayesian posterior credible sets and automatic selection of the degree of smoothing required in non - parametric inferential procedures .",
    "the non - parametric class @xmath39 of densities @xmath14 that we consider is that of location mixtures of normal densities .",
    "so we consider densities specified by @xmath40 where @xmath41 denotes the density of the normal distribution with mean zero and variance @xmath42 and @xmath43 is a mixing measure .",
    "these mixtures form a rich and flexible class of densities , see @xcite and @xcite , that are capable of closely approximating many densities that themselves are not representable in this way .",
    "the resulting mixture densities will be infinitely smooth , which is arguably the case in many , if not most , practical applications .",
    "bayesian estimation requires specification of prior distributions on @xmath44 and @xmath45 we propose independent priors on @xmath44 and @xmath14 that we denote by @xmath46 and @xmath47 respectively . for @xmath14 ,",
    "we take a dirichlet mixture of normal densities as a prior .",
    "this type of prior in the context of bayesian density estimation has been introduced in @xcite and @xcite ; for recent references see e.g.  @xcite .",
    "the prior for @xmath14 is defined as the law of the function @xmath48 as in , with @xmath43 assumed to follow a dirichlet process prior @xmath49 with base measure @xmath50 and @xmath51 a - priori independent with distribution @xmath52 .",
    "recall that a dirichlet process @xmath53 on @xmath54 with the base measure @xmath50 defined on the borel @xmath51-algebra @xmath55 ( we assume @xmath50 to be non - negative and @xmath51-additive ) is a random probability measure @xmath56 on @xmath57 such that for every finite and measurable partition @xmath58 of @xmath57 the probability vector @xmath59 possesses the dirichlet distribution on the @xmath60-dimensional simplex with parameters @xmath61 see e.g.  the original paper  @xcite , or the overview article  @xcite for more information on dirichlet process priors . a nonparametric bayesian approach to density estimation employing a dirichlet mixture of normal densities as a prior can in very rough sense",
    "be thought of as a bayesian counterpart of kernel density estimation ( with a gaussian kernel ) , cf .",
    "@xcite , p.  697 .    with the sample size @xmath5 tending to infinity",
    ", the bayesian approach should be able to discern the true parameter pair @xmath3 with increasing accuracy .",
    "we can formalise this by requiring , for instance , that for any fixed neighbourhood @xmath62 ( in an appropriate topology ) of @xmath63 @xmath64 in @xmath65-probability . here",
    "@xmath66 is used as a shorthand notation for the posterior distribution of @xmath67 and we use @xmath68 to denote the law of the random variable @xmath69 in and @xmath65 the law of @xmath70 .",
    "more generally , one may take a sequence of shrinking neighbourhoods @xmath71 of @xmath3 and try to determine the rate at which the neighbourhoods @xmath71 are allowed to shrink , while still capturing most of the posterior mass .",
    "this rate is referred to as a posterior convergence rate ( we will give the precise definition in section  [ results ] ) .",
    "two fundamental references dealing with establishing it in various statistical settings are  @xcite and  @xcite .",
    "this convergence rate can be thought of as an analogue of the convergence rate of a frequentist estimator",
    ". the analogy can be made precise : contraction of the posterior distribution at a certain rate implies existence of a bayes point estimate with the same convergence rate ( in the frequentist sense ) ; see theorem 2.5 in  @xcite and the discussion on pp .",
    "506507 there .",
    "obviously , for our programme to be successful , @xmath6 has to satisfy the assumption @xmath72 which is a necessary condition for consistent estimation of @xmath63 as it ensures that asymptotically we observe an infinite number of jumps in the process .",
    "we cover both the case of so called high frequency observation schemes ( @xmath73 ) as well as low frequency observations ( fixed @xmath6 ) . a sufficient condition , which covers both observation regimes and which relates @xmath6 to @xmath5 , is @xmath74 , where @xmath75 .",
    "we note that in  @xcite and  @xcite non - parametric bayesian inference for markov processes is studied , of which compound poisson processes form a particular class , but these papers deal with estimation of the transition density of a discretely observed markov process , which is different from the problem we consider here . a parametric bayesian approach to inference for compound poisson processes",
    "is studied in @xcite , sections 5.5 and 10.3 .",
    "the main result of our paper is theorem  [ mainthm ] , in which we state sufficient conditions on the prior that yield a posterior rate of contraction of the order @xmath76 for some constant @xmath77 we argue that this rate is a nearly ( up to a logarithmic factor ) optimal posterior contraction rate in our problem .",
    "our main result complements the one in @xcite , in that it treats both the low and high frequency observation schemes simultaneously , with emphasis on the latter .",
    "we note ( again ) a fundamental difference between the present paper and @xcite , when it comes down to the techniques to prove the main result . as theorem  2.1 of @xcite can not immediately be used , we take an alternative tour that avoids this theorem , but instead refines a number of technical results involving properties of statistical tests that form essential ingredients of the proof in @xcite .",
    "these refined results are then used as key technical steps in a direct proof of our theorem  [ mainthm ] .",
    "furthermore , it establishes the posterior contraction rate for infinitely smooth jump size densities @xmath78 which is not covered by @xcite . on the other hand , @xcite deals with multi - dimensional cpps , while in this paper we consider only the one - dimensional case .",
    "finally , in this work we also discuss a practical implementation of our non - parametric bayesian approach .",
    "the computational problem is dealt with by inclusion of auxiliary variables .",
    "more precisely , we show how a markov chain monte carlo algorithm can be devised that samples from the joint distribution of the unknown parameters in the mixture density and the introduced auxiliary variables .",
    "numerical examples illustrate the feasibility of this approach .",
    "the remainder of the paper is organised as follows .",
    "in the next section we state some preliminaries on the likelihood , prior and notation . in section  [ results ]",
    "we first motivate the use of the scaled hellinger metric to define neighbourhoods for which posterior contraction rate is derived in case the observations are sampled at high frequency .",
    "then we present the main result on the posterior contraction rate ( theorem  [ mainthm ] ) , whose proof is given in section  [ sec : proofmainthm ] .",
    "we discuss the numerical implementation of our results in section  [ section : algo ] . technical lemmas and their proofs used to prove the main theorem",
    "are gathered in the appendix .",
    "we are interested in bayesian inference with bayes formula .",
    "therefore we need to specify the likelihood in our model .",
    "we use the following notation :    [ cols= \" < , < \" , ]     the characteristic function of the poisson sum @xmath69 defined in is given by @xmath79 where @xmath80 is the characteristic function of @xmath45 this can be rewritten as @xmath81 which , using the fact that @xmath80 vanishes at infinity , shows that the distribution of @xmath69 is a mixture of a point mass at zero and an absolutely continuous distribution . letting @xmath82",
    "we get that @xmath83 hence @xmath44 is identifiable from the law of @xmath69 , and then so is @xmath14 .",
    "the density of the law @xmath84 of @xmath69 with respect to the measure @xmath85 , which is the sum of lebesgue measure and the dirac measure concentrated at zero , can in fact be written explicitely as ( cf .",
    "p.  681 in  @xcite and proposition 2.1 in",
    "@xcite ) @xmath86 where @xmath87 denotes the indicator of a set @xmath62 , @xmath88 and @xmath89 denotes the @xmath90-fold convolution of @xmath14 with itself .",
    "however , the expression is useless for bayesian computations . to work around this problem",
    ", we will employ a different dominating measure .",
    "consider the law @xmath91 of @xmath92)$ ] . by the theorem on p.  261 in  @xcite",
    ", @xmath91 is absolutely continuous with respect to @xmath93 if and only if @xmath94 is absolutely continuous with respect to @xmath95 ( we of course assume that @xmath96 ) . a simple condition to ensure",
    "the latter is to assume that @xmath97 is continuous and does not take the value zero on @xmath98 define the random measure @xmath85 by @xmath99)\\otimes\\mathcal{b}(\\mathbb{r}\\setminus\\{0\\}).\\ ] ] under @xmath100 the random measure @xmath85 is a poisson point process on @xmath101\\times(\\mathbb{r}\\setminus\\{0\\})$ ] with intensity measure @xmath102 which follows e.g.  from theorem 1 on p.  69 and corollary on p.  64 in  @xcite . by formula ( 46.1 ) on p.  262 in  @xcite , we have @xmath103 by theorem 2 on p.  245 in  @xcite and corollary 2 on p.  246 there , the density @xmath104 of @xmath105 with respect to @xmath106 is given by the conditional expectation @xmath107 where the subscript in the conditional expectation operator signifies the fact that it is evaluated under the probability @xmath108 hence the likelihood ( in the parameter pair @xmath67 ) associated with the sample @xmath70 is given by the product @xmath109 an advantage of specifying the likelihood in this manner is that it allows one to reduce some of the difficult computations for the laws @xmath105 to those for the laws @xmath110 which are simpler .",
    "observe that the priors on @xmath44 and @xmath14 indirectly induce the prior @xmath111 on the collection of densities @xmath112 we will indiscriminately use the symbol @xmath66 to signify both the prior on @xmath113 but also on the density @xmath112 the posterior in the first case will be understood as the posterior for the pair @xmath113 while in the second case as the posterior for the density @xmath112 we will often use the same symbol @xmath66 to denote the posterior distribution of @xmath67 and on the density @xmath104 .",
    "this simplifies notationally some of the formulations below .    by bayes theorem , the posterior measure of any measurable set @xmath114",
    "is given by @xmath115 upon setting @xmath116 and recalling our conventions above , this can also be written as @xmath117 once the posterior is available , one can next proceed with computation of other quantities of interest in bayesian statistics , such as bayes point estimates or credible sets .      throughout the paper we will use the following notation to compare two sequences @xmath118 and @xmath119 of positive real numbers",
    ": @xmath120 will mean that there exists a constant @xmath121 that is independent of @xmath5 and is such that @xmath122 while @xmath123 will signify the fact that @xmath124 next we introduce various notions of distances between probability measures .",
    "the hellinger distance @xmath125 between two probability laws @xmath126 and @xmath127 on a measurable space @xmath128 is defined as @xmath129 assume further @xmath130 .",
    "the kullback - leibler ( or informational ) divergence @xmath131 is defined as @xmath132 while the @xmath133-discrepancy is defined through @xmath134 here is some additional notation . for @xmath135 nonnegative integrable functions ,",
    "not necessarily densities , we write @xmath136 note that these ` distances ' are all nonnegative and only zero if @xmath137 a.e . if @xmath14 and @xmath138 are densities of probability measures @xmath139 and @xmath140 on @xmath141 respectively , then the above ` distances ' reduce to the previously introduced ones .",
    "we will also use @xmath142 for @xmath143 .",
    "note that also @xmath144 and @xmath145 if and only if @xmath146 .",
    "denote the true parameter values for the compound poisson process by @xmath147 . recall that the problem is to estimate @xmath0 and @xmath2 based on the observations @xmath148 and that @xmath7 in a high frequency regime . to say that a pair @xmath149 lies in a neighbourhood of @xmath150 ,",
    "one needs a notion of distance on the corresponding measures @xmath151 and @xmath152 , the two possible induced laws of @xmath153 .",
    "the hellinger distance is a popular and rather reasonable choice to that end in non - parametric bayesian statistics .",
    "however , for @xmath7 the hellinger metric @xmath154 between those laws automatically tends to 0 .",
    "the first assertion of lemma  [ lemma : delta ] below states that @xmath155 is of order @xmath156 when @xmath7 .",
    "this motivates to replace the ordinary hellinger metric @xmath154 with the scaled metric @xmath157 in our asymptotic analysis for high frequency data . of course , for fixed @xmath6 ( in which case one can take @xmath158 w.l.o.g . ) , nothing changes with this replacement .",
    "the lemma also shows that the kullback - leibler divergence and the v - discrepancy are of order @xmath6 for @xmath7 .",
    "therefore we will also use the scaled distances @xmath159 and @xmath160    [ lemma : delta ] the following expressions hold true : [ eq : kdelta ] @xmath161    the proof will be presented in appendix  [ app : proof ] .    the hellinger process ( here deterministic ) of order @xmath162 for _ continuous _ observations of @xmath163 on an interval @xmath164 $ ] is given by  ( * ? ? ?",
    "* sections iv.3 and iv.4a ) @xmath165 from which it follows that @xmath166 , whose derivative in @xmath167 is the same as in and thus equal to @xmath168 .",
    "for the kullback - leibler divergence and the discrepancy @xmath133 similar assertions hold .",
    "these observations have the following heuristic explanation . for @xmath7",
    ", there is no big difference between observing the path of @xmath163 over the interval @xmath101 $ ] and @xmath169 , as the probability of @xmath170 is small ( of order @xmath171 ) .    in order to determine the posterior contraction rate in our problem",
    ", we now specify suitable neighbourhoods @xmath71 of @xmath63 for which this will be done .",
    "let @xmath172 be a constant and let @xmath173 be a sequence of positive numbers , such that @xmath174 as @xmath175 let @xmath176 be a rescaled hellinger distance .",
    "lemma  [ lemma : delta ] suggests that this is the right scaling to use .",
    "introduce the complements of the hellinger - type neighbourhoods of @xmath63 @xmath177 we shall say that @xmath178 is a posterior contraction rate , if there exists a constant @xmath179 such that @xmath180 in @xmath65-probability as @xmath181 .",
    "our goal in this section is to determine the ` fastest ' rate at which @xmath178 is allowed to tend to zero , while not violating .",
    "we will assume that the observations are generated from a compound poisson process that satisfies the following assumption .",
    "[ ass : truth ]    a.   @xmath2 is in a compact set @xmath182\\subset(0,\\infty)$ ] ; b.   the true density @xmath0 is a location mixture of normal densities , i.e.@xmath183 for some fixed distribution @xmath184 and a constant @xmath185\\subset(0,\\infty)$ ] . furthermore , for some @xmath186 @xmath187=1,$ ]",
    "i.e.  @xmath184 has compact support .",
    "the more general location - scale mixtures of normal densities , @xmath188 possess even better approximation properties than the location mixtures of the normals ( here @xmath184 and @xmath189 are distributions ) and could also be considered in our setup .",
    "however , this would lead to additional technical complications , which could obscure essential contributions of our work .    for obtaining posterior contraction rates",
    "we need to make some assumptions on the prior .",
    "[ ass : prior ]    a.   the prior on @xmath44 , @xmath46 , has a density @xmath190 ( with respect to the lebesgue measure ) that is supported on the finite interval @xmath191\\subset ( 0,\\infty)$ ] and is such that @xmath192\\ ] ] for some constants @xmath193 and @xmath194 ; b.   the base measure @xmath50 of the dirichlet process prior @xmath53 has a continuous density on an interval @xmath195 $ ] , with @xmath196 as in assumption  [ ass : truth ]  ( ii ) , for some @xmath197 is bounded away from zero there , and for all @xmath198 satisfies the tail condition @xmath199 with some constants @xmath200 and @xmath201 ; c.   the prior on @xmath51 , @xmath52 , is supported on the interval @xmath202\\subset(0,\\infty)$ ] and is such that its density @xmath203 with respect to the lebesgue measure satisfies @xmath204\\ ] ] for some constants @xmath205 and @xmath206    assumptions  [ ass : truth ] and  [ ass : prior ] parallel those given in @xcite in the context of non - parametric bayesian density estimation using the dirichlet location mixture of normal densities as a prior .",
    "we refer to that paper for an additional discussion .",
    "the following is our main result .",
    "note that it covers both the case of high frequency observations ( @xmath7 ) and observations with fixed intersampling intervals .",
    "we use @xmath66 to denote the posterior on @xmath67 .",
    "[ mainthm ] under assumptions  [ ass : truth ] and  [ ass : prior ] , provided @xmath207 , there exists a constant @xmath179 such that for @xmath208 we have @xmath209 in @xmath65-probability as @xmath175    for fixed @xmath6 ( w.l.o.g .",
    "one may then assume @xmath158 ) the posterior contraction rate in theorem  [ mainthm ] reduces to @xmath210 .",
    "we also see that the posterior contraction rate is controlled by the parameter @xmath211 of the tail behaviour in .",
    "note that if is satisfied for some @xmath212 it is also automatically satisfied for all @xmath213 .",
    "the stronger the decay rate in , the better the contraction rate , but all @xmath214 give the same value @xmath215 .",
    "the best possible posterior contraction rate in theorem  [ mainthm ] for minimal @xmath211 is obtained for @xmath216 . in the proof in section  [ sec : proofmainthm ] we can therefore assume that @xmath217 .",
    "as on p.  1239 in @xcite and similar corollary 5.1 there , theorem  [ mainthm ] implies existence of a point estimate of @xmath3 with a frequentist convergence rate @xmath218 the ( frequentist ) minimax convergence rate for estimation of @xmath104 relative to the hellinger distance is unknown in our problem , but an analogy to  @xcite suggests that up to a logarithmic factor it should be of order @xmath4 ( cf .",
    "@xcite , p.  1236 ) .",
    "the logarithmic factor is insignificant for all practical purposes .",
    "the convergence rate of an estimator of the lvy density with loss measured in the @xmath219-metric in a more general lvy model than the cpp model is @xmath220 whenever the target density is sobolev smooth of order @xmath221 ( cf .",
    "our contraction rate is hence , roughly speaking , a limiting case of the convergence in @xcite for @xmath222",
    "in this section we discuss computational methods for drawing from the distribution of the pair @xmath223 , conditional on @xmath224 ( or equivalently : conditional on @xmath225 ) . in the following",
    "there is no specific need that the observational times are equidistant .",
    "we will assume observations at times @xmath226 and set @xmath227 ( @xmath24 ) .",
    "further , for consistency with notation following shortly , we set @xmath228 and @xmath229 .",
    "we will use `` bayesian notation '' throughout and write @xmath230 for a probability density of mass function and use @xmath231 similarly for a prior density or mass function .    in general",
    ", it is infeasible to generate independent realisations of the posterior distribution of @xmath232 . to see this : from one",
    "obtains that the conditional density of a nonzero increment @xmath233 on a time interval of length @xmath6 is given by @xmath234 which generally is rather intractable due to the infinite weighted sum of convolutions .",
    "we specialise to the case where the jump size distribution is a mixture of @xmath235 gaussians .",
    "the richness and versatility of the class of finite normal mixtures is convincingly demonstrated in @xcite .",
    "hence , we assume @xmath236 where @xmath237 denotes the density of a random variable with @xmath238 distribution . note that in we parametrise the density with the _ precision _ @xmath239 . in the `` simple '' case",
    "@xmath240 the convolution density of @xmath60 independent jumps is given by @xmath241 plugging this expression into equation confirms the intractable form of @xmath242 .",
    "we will introduce auxiliary variables to circumvent the intractable form of the likelihood . in case the cpp is observed _ continuously _ , the problem is much easier as now the continuous time likelihood on an interval @xmath243 $ ] is known to be ( @xcite , theorem 11.6.7 ) @xmath244 where the @xmath245 are the jump times of the cpp , @xmath246 the corresponding jump sizes and @xmath247 .",
    "the tractability of the continuous time likelihood naturally suggests the construction of a data augmentation scheme .",
    "denote the values of the cpp in between times @xmath248 and @xmath249 by @xmath250 .",
    "we will refer to @xmath250 as the missing values on the @xmath251-th segment . set @xmath252 a data augmentation scheme now consists of augmenting auxiliary variables @xmath253 to @xmath232 and constructing a markov chain that has @xmath254 as invariant distribution . more specifically , a standard implementation of this algorithm consists of the following steps :    1 .",
    "initialise @xmath253 .",
    "2 .   draw @xmath255 .",
    "3 .   draw @xmath256 .",
    "repeat steps 2 and 3 many times .    under weak conditions , the iterates for @xmath232",
    "are ( dependent ) draws from the posterior distribution .",
    "step 3 entails generating compound poisson bridges . by the markov property ,",
    "bridges on different segments can be drawn independently .",
    "data augmentation has been used in many bayesian computational problems , see e.g.  @xcite .",
    "the outlined scheme can be applied to the problem at hand , but we explain shortly that imputation of complete cpp - bridges ( which is nontrivial ) is unnecessary and we can do with less imputation , thereby effectively reducing the state space of the markov chain .    as we assume that the jumps are drawn from a non - atomic distribution ,",
    "imputation is only necessary on segments with nonzero increments .",
    "for this reason we let @xmath257 denote the set of observations with nonzero jump sizes and define the number of segments with nonzero jumps to be @xmath258 .",
    "note that if @xmath259 with @xmath14 as in , then @xmath260 can be simulated by first drawing its label @xmath261 , which equals @xmath262 with probability @xmath263 , and next drawing from the @xmath264 distribution .",
    "knowing the labels , sampling the jumps conditional on their sum being @xmath233 is much easier compared to the case with unknown labels . adding auxiliary variables as labels is a standard trick used for inference in mixture models ( see e.g.  @xcite , @xcite .",
    "for the problem at hand , we can do with even less imputation : all we need to know is the number of jumps of each type on every segment with nonzero jump size . for @xmath265 and @xmath266 , let @xmath267 denote the number of jumps of type @xmath262 on segment @xmath251 .",
    "denote the set of all auxiliary variables by @xmath268 , where @xmath269 in the following we will use the following additional notation : for @xmath270 , @xmath271 we set @xmath272 these are the number of jumps on the @xmath251-th segment , the total number of jumps of type @xmath262 ( summed over all segments ) and the total number of jumps of all types respectively .      instead of parametrising with @xmath273 ,",
    "we define @xmath274 then @xmath275 the background of this reparametrisation is the obervation that a compound poisson random variable @xmath276 whose jumps are of @xmath277 types can be decomposed as @xmath278 , where the @xmath279 are independent , compound poisson random variables whose jumps are of type @xmath262 only , and where the parameter of the poisson random variable is @xmath280 .",
    "in what follows we use @xmath281 with @xmath282 and @xmath283 .    denote the gamma distribution with shape parameter @xmath50 and rate @xmath221 by @xmath284 .",
    "we take priors @xmath285 ' , i_{j\\times j}(\\tau\\kappa)^{-1 } ) \\\\",
    "\\tau \\quad & \\sim \\quad \\mathcal{g}(\\alpha_1,\\beta_1)\\end{aligned}\\ ] ] with positive hyperparameters @xmath286 fixed .",
    "we construct a metropolis - hastings algorithm to draw from @xmath287 for an index @xmath288 we set @xmath289 .",
    "the two main steps of the algorithm are :    1 .",
    "_ update segments : _ for each segment @xmath265 , draw @xmath290 conditional on @xmath291 ; 2 .",
    "_ update parameters : _ draw @xmath292 conditional on @xmath293 .",
    "compared to the full data augmentation scheme discussed previously , the present approach is computationally much cheaper as the amount of imputation scales with the number of segments that need imputation . if the time in between observations is fixed and equal to @xmath6 , then the expected number of segments for imputation equals @xmath294 , which is for small @xmath6 approximately proportional to @xmath295 .",
    "denote the poisson distribution with mean @xmath296 by @xmath297 . including the auxiliary variables , we can write the observation model as a _ hierarchical model _ @xmath298 ( with @xmath299 and @xmath300 ) .",
    "this implies @xmath301      updating the @xmath251-th segment requires drawing from @xmath302 we do this with a metropolis - hastings step .",
    "first we draw a proposal @xmath303 ( for @xmath304 ) from a @xmath305 ) distribution , conditioned to have nonzero outcome .",
    "next , we draw @xmath306 where @xmath307 denotes the multinomial distribution .",
    "hence the proposal density equals @xmath308 the acceptance probability for the proposal @xmath309 equals @xmath310 , with @xmath311      the proof of the following lemma is given in appendix  [ proof2 ] .    [",
    "lem : postpars ] conditional on @xmath312 , @xmath313 are independent and @xmath314 furthermore , @xmath315 where @xmath316 is the symmetric @xmath317 matrix with elements @xmath318 @xmath319 is the @xmath277-dimensional vector with @xmath320 @xmath321 is given by @xmath322 and @xmath323 .",
    "if for some @xmath300 we have @xmath324 ( no jumps of type @xmath262 ) , then the matrix @xmath325 is singular .",
    "however , adding @xmath326 ensures invertibility of @xmath316 .      the first two examples concern mixtures of two normal distributions we simulated @xmath327 segments with @xmath158 , @xmath328 , @xmath329 and @xmath330 . for the prior - hyperparameters we took @xmath331 , @xmath332 and @xmath215 .",
    "the results for @xmath333 , @xmath334 , @xmath335 and hence @xmath336 and @xmath337 are shown in figure  [ fig : la=1 ] .",
    "the densities obtained from the posterior mean of the parameter estimates and the true density are shown in figure  [ fig : la=1_dens ] .",
    "the average acceptance probability for updating the segments was @xmath338 .",
    "the results for @xmath339 , @xmath334 , @xmath335 and hence @xmath340 and @xmath341 are shown in figure  [ fig : la=3 ] .",
    "the densities obtained from the posterior mean of the parameter estimates and the true density are shown in figure  [ fig : la=3_dens ] . the average acceptance probability for updating the segments was @xmath342 .",
    "observe that the autocorrelation functions of the iterations of the @xmath343 in the second case display a much slower decay .",
    "we also assessed the performance of our method on a more complicated example where we took a mixture of four normals . here",
    "@xmath158 , @xmath344 , @xmath345 ( hence @xmath346 ) and @xmath347 .",
    "the results obtained after simulating @xmath348 segments are shown in figures  [ fig : multimodal - trace ] and  [ fig : multimodal - density ] .",
    "mixtures of normals need not be multimodal and can also yield skew densities . as an example , we consider the case where @xmath349 , @xmath350 ( hence @xmath351 ) and @xmath330 .",
    "data were generated and discretely sampled with @xmath158 and @xmath327 segments .",
    "a plot of the posterior mean is shown in figure  [ fig : skew - density ] .     using 15.000 mcmc iterations .",
    "the trace plots show all iterations ; in the other plots the first 5.000 iterations are treated as burnin .",
    "the figures are obtained after subsampling the iterates , where only each 5th iterate was saved .",
    "the horizontal yellow lines are obtained from computing the posterior mean of @xmath292 based on the true auxiliary variables on all segments.,scaledwidth=95.0% ]    ; the first 5.000 iterations are treated as burnin . shown",
    "are the true jump size density and the density obtained from the posterior mean of the non - burnin iterates . ]     using 25.000 mcmc iterations .",
    "the trace plots show all iterations ; in the other plots the first 10.000 iterations are treated as burnin .",
    "the figures are obtained after subsampling the iterates , where only each 5th iterate was saved .",
    "the horizontal yellow lines are obtained from computing the posterior mean of @xmath292 based on the true auxiliary variables on all segments.,scaledwidth=95.0% ]    ; the first 10.000 iterations are treated as burnin . shown",
    "are the true jump size density and the density obtained from the posterior mean of the non - burnin iterates . ]                  as can be seen from the autocorrelation plots , mixing of the chain deteriorates when @xmath352 increases .",
    "as the focus in this article is on high frequency data , where there are on average only a few jumps in between observations , we do not go into details on improving the algorithm .",
    "we remark that a non - centred parametrisation ( see for instance @xcite ) may give more satisfactory results when @xmath352 is large .",
    "a non centred parametrisation can be obtained by changing the hierarchical model in .",
    "denote by @xmath353 the inverse cumulative distribution function of the @xmath297 distribution .",
    "let @xmath354 ( @xmath355 and @xmath356 ) be a sequence of independent @xmath357 random variables and set @xmath358 . by considering the hierarchical model @xmath359 ( @xmath299 and @xmath300 ) , @xmath360 can be updated using a metropolis - hastings step . in this way @xmath361 and",
    "@xmath360 are updated simultaneously .",
    "another option is to integrate out @xmath362 from @xmath363 . in this model",
    "it is even possible to integrate out @xmath360 as well . in that case only the auxiliary variables @xmath312 have to be updated .",
    "yet another method to improve the efficiency of the algorithm is to use ideas from parallel tempering ( cf .",
    "chapter 11 in @xcite ) .",
    "there are a number of general results in bayesian nonparametric statistics , such as the fundamental theorem 2.1 in @xcite and theorem 2.1 in @xcite , which allow determination of the posterior contraction rates through checking certain conditions , but none of these results is easily and directly applicable in our case .",
    "the principle bottleneck is that a main assumption underlying these theorems is sampling from a fixed distribution , whereas in our high frequency setting , the distributions vary with @xmath6 . therefore , for the clarity of exposition in the proof of our main theorem we will choose an alternative path , which consists in mimicking the main steps of the proof of theorem  2.1 , involving judiciously chosen statistical tests , as in @xcite , while also employing some results on the dirichlet location mixtures of normal densities from @xcite . however , a significant part of technicalities we will encounter are characteristic of the decompounding problem only .    throughout this section",
    "we assume that assumptions  [ ass : truth ] and  [ ass : prior ] hold .",
    "furthermore , in view of the discussion that followed theorem  [ mainthm ] we will without loss of generality assume that @xmath364 .",
    "all the technical lemmas used in this section are collected in the appendices .",
    "we start with the decomposition @xmath365 where @xmath366 is a sequence of tests based on observations @xmath70 and with properties to be specified below .",
    "the idea is to show that the terms on the right - hand side of the above display separately converge to zero in probability .",
    "the tests @xmath367 allow one to control the behaviour of the likelihood ratio @xmath368 on the set where it is not well - behaved due to the fact that @xmath67 is ` far away ' from @xmath369      the next lemma is an adaptation of theorem 7.1 from @xcite to decompounding . a proof is given in appendix  [ appb ] .",
    "we use the notation @xmath370 to denote the @xmath371-packing number of a set @xmath62 in a metric space with metric @xmath372 , applied in our case with @xmath372 the scaled hellinger metric @xmath373 .",
    "[ lemma3 ] let @xmath374 be an arbitrary set of probability measures @xmath375 .",
    "suppose for some non - increasing function @xmath376 some sequence @xmath377 of positive numbers and every @xmath378 @xmath379 then for every @xmath380 there exists a sequence of tests @xmath381 ( depending on @xmath382 ) , such that @xmath383&\\leq d({\\varepsilon})\\exp\\left ( -kn\\delta{\\varepsilon}^2\\right ) \\frac{1}{1-\\exp\\left(-kn\\delta{\\varepsilon}^2\\right)},\\\\ \\sup_{\\left\\{\\mathbb{q}^\\delta_{\\lambda , f}\\in\\mathcal{q}:h^\\delta(\\mathbb{q}^\\delta_{\\lambda_0,f_0},\\mathbb{q}^\\delta_{\\lambda , f})>{\\varepsilon}\\right\\}}{\\mathbb{e}}_{\\lambda , f}[1-\\phi_n]&\\leq \\exp\\left ( -kn\\delta{\\varepsilon}^2 \\right),\\end{split}\\ ] ] where @xmath384 is a universal constant .    in the proofs of propositions  [ prop : c1 ] and  [ prop : c3 ] we need the inequalities below .",
    "there exists a constant @xmath385 depending on @xmath386 and @xmath387 only , such that for all @xmath388 $ ] and @xmath389 it holds that @xmath390 these inequalities can be proven in the same way as lemma  1 in @xcite .",
    "let @xmath391 be as in theorem  [ mainthm ] . throughout",
    ", @xmath392 denotes the above constant . for a constant @xmath393 define the sequences",
    "@xmath118 and @xmath394 by @xmath395 we will show that inequality holds true for every @xmath396 with @xmath397 and the set of measures @xmath374 equal to @xmath398 , h[-a_n , a_n]\\geq 1-\\eta_n , \\sigma \\in [ \\underline{\\sigma},\\overline{\\sigma } ] \\},\\ ] ] as a first step , note that we have @xmath399 where @xmath400 is the covering number of the set @xmath401 with @xmath154-balls of size @xmath402 the first inequality in follows from assuming @xmath397 . for bounding the righthand side in",
    ", we have the following proposition .",
    "[ prop : c1 ] we have @xmath403    define @xmath404\\ge 1-\\eta_n , \\sigma \\in [ \\underline{\\sigma } , \\overline{\\sigma}]\\}.\\ ] ] let @xmath405 be centres of the balls from a minimal covering of @xmath182 $ ] with @xmath406-balls of size @xmath407 .",
    "let @xmath408 be centres of the balls from a minimal covering of @xmath409 with @xmath154-balls of size @xmath410 for any @xmath411 , by we have @xmath412 by appropriate choices of @xmath251 and @xmath262 .",
    "it follows that @xmath413,|\\cdot| ) + \\log n ( \\eta_n ,   { \\mathcal{f}}_n , { h } ) .\\ ] ] evidently , @xmath414,|\\cdot| ) \\lesssim \\log \\left ( \\frac{1}{{\\varepsilon}_n } \\right).\\ ] ] as we assume @xmath415 , we can apply the arguments on pp .",
    "12511252 in @xcite , see in particular formulae ( 5.8)(5.10 ) ( cf .  also theorem 3.1 and",
    "lemma a.3 there ) , which yield @xmath416 combination of the above three inequalities implies the statement of the proposition .",
    "an application of proposition  [ prop : c1 ] to gives @xmath417 for some positive constant @xmath418 .",
    "here , the final inequality follows from our choice for @xmath391 .",
    "hence , is satisfied for @xmath419 by lemma  [ lemma3 ] there exist tests @xmath367 such that for all @xmath5 large enough @xmath420 & \\leq 2 \\exp\\left ( -(km^2-c_1)n\\delta{\\varepsilon}_n^2 \\right),\\label{eq : tests0 } \\\\ \\sup_{\\left\\{\\mathbb{q}^\\delta_{\\lambda , f}\\in\\mathcal{q}_n : h^\\delta(\\mathbb{q}^\\delta_{\\lambda_0,f_0},\\mathbb{q}^\\delta_{\\lambda , f})>{\\varepsilon}\\right\\}}{\\mathbb{e}}_{\\lambda , f}[1-\\phi_n]&\\leq \\exp\\left ( -kn\\delta m^2{\\varepsilon}_n^2 \\right)\\label{eq : tests1}.\\end{aligned}\\ ] ]      first note that by equation @xmath422 \\leq { \\mathbb{e}}_{\\lambda_0,f_0 } [ \\phi_n ] \\le 2 \\exp\\left ( -(km^2-c_1)n\\delta{\\varepsilon}_n^2 \\right).\\ ] ] chebyshev s inequality implies that @xmath421 converges to zero in @xmath423-probability as @xmath32 as soon as @xmath424 is chosen so large that @xmath425      now we consider @xmath427 we have @xmath428 we will show that the numerator @xmath429 goes exponentially fast to zero , in @xmath423-probability , while the denominator @xmath430 is bounded from below by an exponential function , with @xmath423-probability tending to one , in such a way that the ratio of @xmath429 and @xmath430 still goes to zero in @xmath423-probability .",
    "+ _ bounding @xmath429 . _ as @xmath431 we have @xmath432 \\leq \\pi(\\mathcal{q}_n^c)+\\iint _ { \\mathcal{q}_n \\cap a(\\varepsilon_n , m ) } { \\mathbb{e}}_{\\lambda , f } [ 1-\\phi_n]{\\mathrm{d}}\\pi_1(\\lambda){\\mathrm{d}}\\pi_2(f).\\ ] ] here we applied fubini s theorem to obtain the second term on the right - hand - side , which by is bounded by @xmath433 furthermore , @xmath434<1-\\eta_n,\\sigma\\in[\\underline{\\sigma},\\overline{\\sigma}])\\lesssim \\frac{1}{\\eta_n}e^{-ba_n^{\\delta}},\\ ] ] where the last inequality is formula ( 5.11 ) in @xcite . hence @xmath435\\lesssim \\frac{1}{\\eta_n}e^{-ba_n^{\\delta } } + \\exp(-km^2n\\delta{\\varepsilon}_n^2).\\ ] ] + _ bounding @xmath430 . _",
    "recall @xmath436 and @xmath437 .",
    "let @xmath438 and @xmath439 note that @xmath440 when @xmath181 .",
    "we will use the following bound , an adaptation of lemma  8.1 in @xcite to our setting , valid for every @xmath382 and @xmath121 , @xmath441 where @xmath442 is a normalised restriction of @xmath443 to @xmath444 .    by virtue of , with @xmath423-probability tending to one , for any constant @xmath121",
    "we have @xmath445 we will now work out the product probability on the right - hand side of this inequality .",
    "[ prop : c3 ] it holds that @xmath446 for some constant @xmath447    let @xmath448 be a constant . here",
    "@xmath392 is the constant in and . by these inequalities",
    "it is readily seen that @xmath449 it then follows by the independence assumption on @xmath46 and @xmath450 that @xmath451 for the first factor on the right - hand side we have by that @xmath452 as far as the second factor is concerned , for some constants @xmath453 it is bounded from below by @xmath454 by the same arguments as in inequality ( 5.17 ) in @xcite .",
    "the result now follows by combining the two lower bounds .    combining with proposition  [ prop : c3 ] , with @xmath65-probability tending to one as @xmath32 for any constant @xmath121 we have @xmath455 we are now ready for showing the final steps of proving that @xmath426 tends to zero in @xmath65-probability .",
    "let @xmath456 denote the set on which inequality   is true .",
    "then by   we obtain @xmath457 & \\lesssim \\exp\\left((1+c)n\\delta \\widetilde{{\\varepsilon}}_n^2+\\bar{c } \\log^2 \\left(\\frac{1 } { \\widetilde{\\varepsilon}_n } \\right)\\right ) \\\\ & \\qquad\\times \\left [ \\frac{1}{\\eta_n}e^{-ba_n^{\\delta } } + \\exp(-km^2n\\delta{\\varepsilon}_n^2 ) \\right].\\end{aligned}\\ ] ] recall that @xmath458 . hence , the exponent in the first factor of this display is of order @xmath459 .",
    "furthermore @xmath460 , which is of order @xmath461 as well .",
    "it follows that , provided the constants @xmath261 and @xmath424 are chosen large enough , the right - hand side of the above display converges to zero as @xmath175 chebyshev s inequality then implies that @xmath426 converges to zero in probability as @xmath175 this completes the proof of theorem  [ mainthm ] .",
    "* acknowledgement * : we wish to thank wikash sewlal from delft university of technology for the simulation results of the example with a mixture of four normals and the skewed density .",
    "we give a detailed proof of equality  .",
    "as we are interested in small values of @xmath6 , we make some necessary approximations .",
    "starting point is the expansion for the ` density ' of @xmath375 with respect to the lebesgue measure , @xmath462 see , with coefficients @xmath463 defined in .",
    "it follows that we have the likelihood ratio @xmath464 where we collected terms of order @xmath465 for @xmath466 as @xmath467 .",
    "hence we get for the hellinger affinity @xmath468 the approximating expression @xmath469 it follows that for @xmath7 , @xmath470 hence , for @xmath7 , @xmath471 equality   follows .",
    "the proofs of the equalities and follow a similar line of reasoning .",
    "the proof is an adaptation of theorem 7.1 from @xcite to decompounding . in all what follows it",
    "is assumed that @xmath472 , but we suppress this assumption in the notation .",
    "observe that @xmath473 from this point on the arguments from the proof of theorem 7.1 in @xcite are applicable ( with @xmath371 replaced by @xmath474 ) and eventually lead to the desired result .",
    "the role of formulae ( 7.1)(7.2 ) in that proof are played in the present context by and below .    for a given @xmath475",
    "there exists a sequence of tests @xmath367 based on @xmath476 such that @xmath420 & \\leq \\exp\\left ( -\\frac{1}{2}n\\delta h^\\delta(\\mathbb{q}^\\delta_{\\lambda_0,f_0},\\mathbb{q}^\\delta_{\\lambda , f})^2 \\right),\\label{eq : t1}\\\\ \\sup _ { h^\\delta(\\mathbb{q}^\\delta_{\\lambda , f},\\mathbb{q}^\\delta_{\\lambda_1,f_1 } ) < h^\\delta(\\mathbb{q}^\\delta_{\\lambda_0,f_0},\\mathbb{q}^\\delta_{\\lambda_1,f_1 } ) } { \\mathbb{e}}_{\\lambda , f}[1-\\phi_n]&\\leq \\exp\\left ( -\\frac{1}{2}n\\delta h^\\delta(\\mathbb{q}_{\\lambda_0,f_0},\\mathbb{q}_{\\lambda , f})^2 \\right).\\label{eq : t2}\\end{aligned}\\ ] ]    these two inequalities simply follow by rewriting the inequalities @xmath420 & \\leq \\exp\\left ( -\\frac{1}{2}nh^2(\\mathbb{q}_{\\lambda_0,f_0}^{\\delta},\\mathbb{q}_{\\lambda , f}^{\\delta } ) \\right),\\\\ \\sup _ { h(\\mathbb{q}_{\\lambda , f}^{\\delta},\\mathbb{q}_{\\lambda_1,f_1}^{\\delta } ) < h(\\mathbb{q}_{\\lambda_0,f_0}^{\\delta},\\mathbb{q}_{\\lambda_1,f_1}^{\\delta } ) } { \\mathbb{e}}_{\\lambda , f}[1-\\phi_n]&\\leq \\exp\\left ( -\\frac{1}{2}n h^2(\\mathbb{q}_{\\lambda_0,f_0}^{\\delta},\\mathbb{q}_{\\lambda , f}^{\\delta } ) \\right).\\end{aligned}\\ ] ] which are proved on pp .",
    "520521 in @xcite and rely upon the results in @xcite and @xcite .        for @xmath479",
    "we get @xmath480 this is proportional to @xmath481 where @xmath482 from this expression it is easily seen that we can integrate out @xmath85 to obtain the distribution of @xmath239 , conditional on @xmath293 . to get this right ,",
    "write @xmath483 as a quadratic form of @xmath85 : @xmath484 by completing the square , we find that @xmath485 the integrand is ( up to a proportionality constant ) , the density of a bivariate normal random vector with mean vector @xmath486 and covariance matrix @xmath487 evaluated in @xmath85 .",
    "this implies that the preceding display equals @xmath488 we conclude that @xmath489 which proves the asserted gamma distribution of @xmath239 .",
    "this computation also immediately leads to the assertion on the distribution of @xmath85 .",
    "we finally show that the rate parameter appearing for @xmath239 is positive . by definition @xmath490 for all @xmath85 .",
    "this implies that @xmath491 .",
    "b.  buchmann and r.  grbel.decompounding : an estimation problem for poisson random sums .",
    "_ , 31:10541074 , 2003 . b.  buchmann and r.  grbel .",
    "decompounding poisson random sums : recursively truncated estimates in the discrete case .",
    "statist .",
    "_ , 56:743756 , 2004 .",
    "p.  burlando and r.  rosso , stochastic models of temporal rainfall : reproducibility , estimation and prediction of extreme events . in : _",
    "stochastic hydrology and its use in water resources systems , simulation and optimization _ , j.b .",
    "marco , r. harboe , j.d .",
    "salas ( eds . ) , nato asi series 237 : 137173 . springer , 1993 .",
    "f.  comte and v.  genon - catalot .",
    "adaptive estimation for lvy processes . in : d.  belomestny , f.  comte , v.  genon - catalot , h.  masuki , m.  rei ( eds . ) .  _ lvy matters iv , estimation for discretely observed lvy processes_.  lecture notes in mathematics 2128 : 77177 .",
    "springer , cham , 2015 .",
    "f.  comte , c. duval and v.  genon - catalot .",
    "nonparametric density estimation in compound poisson process using convolution power estimators .",
    "_ metrika _ , 77:163183 , 2014 . f.  comte and v.  genon - catalot .",
    "estimation for lvy processes from high frequency data within a long time interval .",
    "_ , 39:803837 , 2011 . j.  diebolt , and c. p.  robert .",
    "_ estimation of finite mixture distributions through bayesian sampling _ , j. roy .",
    "b 56 : 363375 , 1994 . c.  duval .",
    "density estimation for compound poisson processes from discrete data",
    ".  _ stoch .",
    "_ , 123:39633986 , 2013 .",
    "p.  embrechts , c.  klppelberg and t.  mikosch . modelling extremal events for insurance and finance .",
    "applications of mathematics ( new york ) , 33 .",
    "springer - verlag , berlin , 1997 .",
    "b.  van es , s.  gugushvili and p.  spreij .",
    "a kernel type nonparametric density estimator for decompounding .",
    "_ bernoulli _ , 13:672694 , 2007 .",
    "ferguson .  a bayesian analysis of some nonparametric problems .  _ ann .",
    "_ , 1:209230 , 1973 .",
    "ferguson .",
    "bayesian density estimation by mixtures of normal distributions .",
    "_ recent advances in statistics _ ,",
    "287302 , academic press , new york , 1983 .",
    "figueroa - lpez .",
    "nonparametric estimation of lvy models based on discrete- sampling . in : _",
    "ims lecture notes monograph series _ 57 : 117146 , beachwood , oh : institute of statistical mathematics , 2009 .    s.  ghosal .  the dirichlet process , related priors and posterior asymptotics .",
    "_ bayesian nonparametrics _",
    ", 3579 , camb .",
    ", cambridge univ .  press , cambridge , 2010 .",
    "s.  ghosal , j.k .",
    "ghosh and a.w .",
    "van der vaart .",
    "convergence rates of posterior distributions .",
    "_ , 28:500531 , 2000 . s.  ghosal and y.  tang .",
    "bayesian consistency for markov processes .",
    "_ sankhy _ , 68:227239 , 2006 . s.  ghosal and a.w .  van der vaart .",
    "entropies and rates of convergence for maximum likelihood and bayes estimation for mixtures of normal densities .",
    "_ , 29:12331263 , 2001 . s.  ghosal and a.w .",
    "van der vaart .",
    "posterior convergence rates of dirichlet mixtures at smooth densities .",
    "_ , 35:697723 , 2007 . s.  gugushvili , f.  van der meulen and p.  spreij .",
    "non - parametric bayesian inference for multi - dimensional compound poisson processes .  _",
    "modern stochastics : theory and applications _ , 2:115 , 2015 .",
    "hjort , c.  holmes , p.  mller and s.g .",
    "_ bayesian nonparametrics .",
    "_ cambridge series in statistical and probabilistic mathematics , 28 . cambridge university press , cambridge , 2010 .",
    "ibragimov and r.z .",
    "khasminski .",
    "an estimate of the density of a distribution belonging to a class of entire functions ( russian ) .",
    "veroyatnost .",
    "i primenen .",
    "_ , 27:514524 , 1982 .",
    "insua , f.  ruggeri and m.p .",
    "_ bayesian analysis of stochastic process models_. john wiley & sons , 2012 .",
    "j.  jacod and a.n .",
    "_ limit theorems for stochastic processes , second edition_. grundlehren der mathematischen wissenschaften , 288 .",
    "springer - verlag , berlin , 2003 .",
    "_ statistical inference for spatial poisson processes .",
    "_ lecture notes in statistics , 134 .",
    "springer - verlag , new york , 1998 .",
    "l.  m.  le cam .",
    "_ asymptotic methods in statistical decision theory_. springer , new york , 1986 .",
    "lo .  on a class of bayesian nonparametric estimates : i. density estimates .",
    "_ , 12:351357 , 1984 .",
    "n.u .  prabhu .",
    "_ stochastic storage processes .",
    "queues , insurance risk , dams , and data communication . _ second edition .",
    "applications of mathematics ( new york ) , 15 .",
    "springer - verlag , new york , 1998 .",
    "s.  richardsen and p.j .",
    "_ on bayesian analysis of mixtures with an unknown number of components ( with discussion ) _ journal of the royal statistical society : series b ( statistical methodology ) , 59 : 731792 , 1997 .",
    "e.  scalas .",
    "the application of continuous time random walks in finance and economics . _",
    "physica a _ ,",
    "362(2 ) : 225239 , 2006 .    s.e .",
    "shreve , ( 2008 ) _ stochastic calculus for finance ii _",
    ", 2nd edition , springer .",
    "skorohod .  .",
    "`` nauka '' , moscow , 1964 .",
    "y.  tang and s.  ghosal .",
    "posterior consistency of dirichlet mixtures for estimating a transition density .",
    "_ j.  statist .",
    "plann .  inference _",
    ", 137:17111726 , 2007 .",
    "tanner and w.h .",
    "the calculation of posterior distributions by data augmentation . _ journal of the american statistical association _ 82:528540 , 1987 .",
    "f. a. j.  ueltzhfer and c.  klppelberg .",
    "an oracle inequality for penalised projection estimation of lvy densities from high frequency observations . _ journal of nonparametric statistics _",
    "23(4 ) : 967989 , 2011 .    a.w .",
    "van der vaart and j.a .",
    "wellner .",
    "_ weak convergence and empirical processes . with applications to statistics_. corrected second printing .",
    "springer series in statistics .",
    "springer - verlag , new york , 2000 ."
  ],
  "abstract_text": [
    "<S> given a sample from a discretely observed compound poisson process , we consider non - parametric estimation of the density @xmath0 of its jump sizes , as well as of its intensity @xmath1 we take a bayesian approach to the problem and specify the prior on @xmath0 as the dirichlet location mixture of normal densities . </S>",
    "<S> an independent prior for @xmath2 is assumed to be compactly supported and to possess a positive density with respect to the lebesgue measure . </S>",
    "<S> we show that under suitable assumptions the posterior contracts around the pair @xmath3 at essentially ( up to a logarithmic factor ) the @xmath4-rate , where @xmath5 is the number of observations and @xmath6 is the mesh size at which the process is sampled . </S>",
    "<S> the emphasis is on high frequency data , @xmath7 , but the obtained results are also valid for fixed @xmath6 . in either case </S>",
    "<S> we assume that @xmath8 . </S>",
    "<S> our main result implies existence of bayesian point estimates converging ( in the frequentist sense , in probability ) to @xmath3 at the same rate .    </S>",
    "<S> we also discuss a practical implementation of our approach . </S>",
    "<S> the computational problem is dealt with by inclusion of auxiliary variables and we develop a markov chain monte carlo algorithm that samples from the joint distribution of the unknown parameters in the mixture density and the introduced auxiliary variables . </S>",
    "<S> numerical examples illustrate the feasibility of this approach . </S>"
  ]
}