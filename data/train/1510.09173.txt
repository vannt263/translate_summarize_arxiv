{
  "article_text": [
    "the use and manipulation of entanglement is central to the exploitation of quantum computation ( see , e.g. , [ 1 - 8 ] ) .",
    "the quantum system obviously `` knows '' what its own entanglement is , though extraction of that information is not obvious ; thus , we use dynamic learning methods@xcite to map this information onto a single experimental measurement which is our entanglement indicator@xcite . our method does not require prior state reconstruction or lengthy optimization@xcite , nor must the system be `` close '' to a given entangled state @xcite .",
    "an entanglement witness emerges from the learning process .",
    "we use knowledge of the smaller two - qubit system as a means of `` bootstrapping '' to larger systems @xcite . as the size of the system grows the amount of additional training necessary diminishes@xcite , unlike other methods ,",
    "e.g. , which require knowledge or reconstruction of the density matrix @xcite ; thus , our method potentially may be of general applicability even to large - scale quantum computers , once they are built .    in any experimental implementation ,",
    "though , we need also to consider that no setup is perfect : there will always be some uncertainty due to extraneous effects . in quantum systems",
    "there is also the problem of decoherence .",
    "classically learning systems such as neural networks have proven fault tolerant and robust to noise ; they are also famously used for noise reduction in signals@xcite .",
    "a machine learning approach would seem to be an excellent one for issues like noise , decoherence , or missing or damaged data . here",
    ", we show that this is in fact the case , using as a test bed our entanglement indicator on the simple two - qubit system .",
    "in previous work , we showed we could successfully train a quantum system to estimate its own degree of entanglement , by mapping a measureable output at the final time , to give an indicator of the entanglement of the prepared , initial state . briefly",
    "the method was as follows ; for full details the reader is referred to@xcite    we begin with the schrdinger equation for the time evolution of the density matrix @xmath0@xcite : @xmath1   \\label{schr}\\ ] ] where @xmath2 is the hamiltonian .",
    "we consider an n - qubit system whose hamiltonian is : @xmath3 where @xmath4 are the pauli operators corresponding to each of the qubits , @xmath5 are the tunneling amplitudes , @xmath6 are the biases , and @xmath7 , the qubit - qubit couplings .",
    "we choose the usual `` charge basis '' , in which each qubit s state is given as 0 or 1 ; for a system of n qubits there are @xmath8 states , each labelled by a bit string each of whose numbers corresponds to the state of each qubit , in order .",
    "the amplitude for each qubit to tunnel to its opposing state ( i.e. , switch between the 0 and 1 states ) is its @xmath9 value ; each qubit has an external bias represented by its @xmath10 value ; and each qubit is coupled to each of the other qubits , with a strength represented by the appropriate @xmath11 value .",
    "note that , for example , the operator @xmath12 , where there are ( n-1 ) outer products , acts nontrivially only on qubit 1 .",
    "the parameter functions @xmath13 direct the time evolution of the system in the sense that , if one or more of them is changed , the way a given initial state will evolve in time will also change , because of eqs .",
    "[ schr]-[ham ] .",
    "this is the basis for using our quantum system as a neural network .",
    "the role of the input vector is played by the initial density matrix @xmath14 , the role of the output by ( some function of ) the density matrix at the final time , @xmath15 , and the role of the `` weights '' of the network by the parameter functions of the hamiltonian , @xmath16 , all of which can be adjusted experimentally@xcite . by adjusting these parameters using a machine learning algorithm we can train the system to evolve in time from an input state to a set of particular final states at the final time @xmath17 .",
    "because the time evolution is quantum mechanical ( and , we assume , coherent ) , a quantum mechanical function , like an entanglement witness of the initial state , can be mapped to an observable of the system s final state , a measurement made at the final time @xmath17 .",
    "complete details , including a derivation of the quantum dynamic learning paradigm using quantum backpropagation@xcite in time@xcite , are given in @xcite .",
    "we call this quantum system a `` quantum neural network '' ( qnn ) .",
    "we found @xcite a set of parameter functions that successfully map the input ( initial ) state of a two - qubit system to a good approximation of the entanglement of formation of that initial state , using as the output the qubit - qubit correlation function at the final time , @xmath18 .",
    "this set of parameter functions was relatively easily generalized to three- four- and five - qubit systems@xcite .",
    "here , we will consider the effect of noise on only the simplest case , of two qubits ( @xmath19 ) , and for ease of notation we will call the two qubits @xmath20 and @xmath21 . with continuum@xcite rather than piecewise constant parameter functions@xcite training is more rapid and complete ; see figure  [ trzero ] .",
    "the parameter functions are found by training with a set of just four initial quantum states ( `` inputs '' ) , as shown in table  [ enttraining ] : a fully entangled state ( `` bell '' ) , a `` flat '' state ( equal amounts of all basis states ) , a product state``c '' whose initial @xmath22 correlation function @xmath23 is nonzero , and a partially entangled state `` p '' .",
    "the parameter functions are shown in figures  [ k0 ]  [ ep0 ]  [ z0 ] . because of the symmetry in the hamiltonian and in the training set , @xmath24 , and @xmath25 .",
    "each is a relatively simple function , well parametrized by only one frequency ( @xmath26 ) or two ( @xmath9 ) , as shown in table  [ entparamfit ] and plotted in figures  refk0,[ep0],[z0 ] .",
    "the @xmath27 pairs are :    @xmath28    with prepared input states at zero time , and corresponding targets , given in table [ enttraining ] .",
    "this table also shows the qnn indicated entanglement values after training has finished and , for comparison , the entanglement of formation , calculated using the analytic formula @xcite for comparison .",
    "entanglement of formation is not the only measure of entanglement , of course , but any one that we chose would have qualitatively similar behavior , which we would like our entanglement indicator to imitate .",
    "that is , we seek here not exact with @xmath29 ( in which case we would train the state @xmath30 to a target value of 0.55 ) , but a robust and internally self consistent measure , which we would hope would track well with an analytic measure like @xmath29 .",
    "the qnn indicator systematically underestimates @xmath29 for partially entangled pure states ; this is because we found through simulation that the net naturally trained to the target value of 0.44 .",
    "see @xcite for details .    .",
    "for comparison : with piecewise constant functions a similar level of error required 2000 epochs.,height=192 ]    .training data for qnn entanglement witness . [",
    "cols=\"<,<,<,<\",options=\"header \" , ]     once trained , the parameter functions that are found can be tested , by using the hamiltonian so defined to calculate the qnn indicator for other initial states .",
    "testing was therefore done on a large number of states not represented in the training set , including fully entangled states , partially entangled states , product ( unentangled ) states , and even states .",
    "( note that only states were present in the training sets . )",
    "the interested reader is referred to our previous work for the ( extensive ) testing results @xcite .",
    "note also that the testing was done using the fitted functions only .",
    "physical systems contain noise , meaning that there is some uncertainty in each of the elements of the density matrix ( though , of course , it must remain hermitian and positive semidefinite , with unit trace to conserve probability . )",
    "what if the system on which we train is somewhat noisy ?    let us first define our terms .",
    "because we are working with simulations , we can isolate the different effects of `` noise '' and `` decoherence '' : here , we will use `` noise '' to refer to random ( uncorrelated ) magnitudes , of a given size , added to the density matrix elements ; and `` decoherence '' to refer to random phases so added . in general , of course , both effects will be present ; we will call that `` complex '' noise . recall that our entanglement indicator is a mapping to a time correlation function , after evolution in time according to the hamiltonian of equation [ ham ] ; that is , the entanglement of the initial state is approximated by a measurement performed at the final time . to simulate white noise ( zero mean and specified amplitude ) ,",
    "random numbers were added at each timestep @xmath31 ns of that time evolution .",
    "these numbers have zero time correlation themselves .",
    "the level of noise we report is the amplitude , that is , the root - mean - square - average size of these random numbers , that are imposed at each time step .",
    "all the simulations were done for the same total time of 317 timesteps , or about 253 ns .",
    "because the system evolves in time , the noise itself propagates , so that by the time the correlation function is measured , at the final time , numbers that seem quite small can build up to destroy a significant amount of entanglement .",
    "for comparison with our testing results , we will always therefore include the entanglement of formation for the noisy density matrix , calculated using the bennett - wootters formula@xcite and marked `` bw '' on our testing graphs ( figures 12 - 17 , 25 - 30 , and 38 - 43 ) below .",
    "we consider first the case of magnitude noise only .",
    "figure  [ magtrn ] shows a typical rms error training curve for a fairly large level of noise . as expected , asymptotic error for the training set does increase with increasing noise .",
    "the parameter functions also become `` noisy '' : see figures  [ kmag],[epmag],[zmag ] .    , about double what it was with no noise.,height=192 ]     as a function of time , as trained at 0.0089 amplitude noise at each of the 317 timesteps , for the entanglement indicator ( data points ) , and plotted with the fourier fit ( solid line ) .",
    "note the change in scale from figure  [ k0 ] , because of the ( much larger ) spread of the noisy data : the fourier fit is actually almost the same on this graph.,height=192 ]     as a function of time , as trained at 0.0089 amplitude noise at each of the 317 timesteps , for the entanglement indicator ( data points ) , and plotted with the fourier fit ( solid line).,height=192 ]     as a function of time , as trained at 0.0089 noise at each of the 317 timesteps , for the entanglement indicator ( data points ) , and plotted with the fourier fit ( solid line).,height=192 ]    much of this variation is not meaningful , though .",
    "in fact , the numbers in table  [ entparamfit ] are slightly different from the ones we found in @xcite .",
    "is that difference significant ? to investigate this , we tried testing with all but a selected one of the parameter functions fourier coefficients set to the trained values , but assigning random numbers ( of the right order of magnitude ) to the fourier coefficients of the one chosen .",
    "the system was remarkably insensitive to this procedure when the random function was the tunneling function @xmath9 : as long as @xmath9 was the right order of magnitude , the indicator still tested extremely well - in fact for most of the testing the indicator results were identical .",
    "this was not true if @xmath32 or @xmath11 were randomized , however : errors were substantial , particularly when the fourier frequency @xmath33 is randomized . still , exact agreement with the trained functions is not , apparently , necessary .",
    "we can , as before , fit each function to a fourier series , and test using the fitted functions .",
    "figures  [ fkmag],[fepmag],[fzmag ] show the fourier coefficients for @xmath34 , @xmath35 , and @xmath11 , respectively , as functions of increasing noise level .",
    "the fourier components of the tunneling parameter function @xmath9 are clearly the least sensitive to noise level , while for @xmath32 they are a bit more so and for @xmath11 the most .",
    "this is in accordance with the observed insensitivity of the entanglement indicator to @xmath9 : that is , it is true both that the indicator is relatively insensitive to the @xmath9 function , and that the @xmath9 function s fourier fit is insensitive to environmental noise .",
    ", as functions of noise level.,height=192 ]    , as functions of noise level .",
    ", height=192 ]    , as functions of noise level.,height=192 ]    all of the parameters look fairly stable at these levels of noise , from this point of view . but",
    "a more important question is : how much does noise interfere with the net s ability to detect entanglement ?    consider a pure state , specifically , the state @xmath36 .",
    "for @xmath37 this is of course the ( fully entangled ) bell state ; as @xmath38 increases the entanglement decreases .",
    "@xmath39 is one of the states we tested on in the 2008 paper@xcite , and , as we found then , the entanglement as computed by the quantum neural network , without noise , tracks the entanglement of formation very well .",
    "how much noise or uncertainty can the network tolerate ?",
    "we answer this question in two ways .",
    "first , we suppose the qnn was trained on the perfect ( zero noise ) system of the four - pair training set , and we add increasing amounts of noise to test the system for various nonzero values of @xmath38 , and compare the results to the entanglement of formation both at zero noise and at 0.0069 noise .",
    "see figure  [ p0mag ] .",
    "then , we suppose the qnn was trained on a noisy system , and , again , test with increasing levels of noise . figures  [ p89mag ] and [ p13mag ] show , respectively , an intermediate level and a high level of noise present during training .",
    "recall that the noise should be understood as occurring over the total time evolution interval : that is , an independent ( uncorrelated ) noise at the given rms level was added at timestep .",
    "the two curves showing the entanglement of formation can therefore be thought of as a kind of `` error bars '' : the correct entanglement of the system should lie somewhere between the zero noise result and the result at maximum noise , insofar as the qnn tracks well with the entanglement of formation .",
    "presumably the presence of noise does destroy entanglement , but , since the measurement itself is noisy , it is not certain how much is destroyed and how much is simply a bad measurement .",
    "still , it is obvious from the results that , indeed , the qnn technique does an excellent job of remaining robust to pure noise .     as a function of @xmath38 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise ( orange ) . in each case",
    "the qnn was trained at zero noise , but tested at the given level.,height=192 ]     as a function of @xmath38 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise ( orange ) . in each case",
    "the qnn was trained at a noise level of 0.0089 , and then tested at the given level.,height=192 ]     as a function of @xmath38 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise ( orange ) . in each case",
    "the qnn was trained at 0.013 noise , and then tested at the given level.,height=192 ]    second , we consider testing on mixed states .",
    "we might expect the qnn to perform significantly less well with these kinds of states , because the training set ( table [ enttraining ] ) contained no mixed states .",
    "in fact with zero noise the qnn tested well on several classes of mixed states @xcite ; we need to see if that success is maintained with noisy conditions .",
    "figures  [ m0mag],[m89mag],[m13mag ] show results for the mixed states @xmath40 , where @xmath41 is the bell state , given in table [ enttraining ] , as functions of @xmath42 , for qnn trained at zero , 0.0089 , and 0.013 noise amplitude , respectively .",
    "again , the entanglement of formation results can serve as an approximate error bound , and we see that the qnn s entanglement indicator is robust to noise .",
    "indeed , comparison of these figures with the ones for pure states shows that performance on mixed states is even better . because of this we might expect the qnn indicator to show greater robustness to decoherence than to magnitude noise",
    "; we will see in the next section that this is , indeed , the case .     as a function of @xmath42 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise ( orange ) .",
    "in each case the qnn was trained at zero noise , but tested at the given level.,height=192 ]     as a function of @xmath42 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise ( orange ) . in each case",
    "the qnn was trained at a noise level of 0.0089 , and then tested at the given level.,height=192 ]     as a function of @xmath42 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise ( orange ) . in each case",
    "the qnn was trained at 0.013 noise , and then tested at the given level.,height=192 ]",
    "we now turn to the case of `` pure '' decoherence , that is , we introduce random phases to the elements of the density matrix , without changing their magnitudes . figure  [ phtrn ] shows a typical rms error training curve for a fairly large level of phase noise . again , asymptotic error for the training set does increase with increasing phase noise ( decoherence ) .",
    "the parameter functions also become `` noisy '' : see figures  [ kph],[epph],[zph ] .",
    ", approximately the same as with no noise.,height=192 ]     as a function of time , as trained at 0.0089 phase noise at each of the 317 timesteps , for the entanglement indicator ( data points ) , and plotted with the fourier fit ( solid line),height=192 ]     as a function of time , as trained at 0.0089 phase noise at each of the 317 timesteps , for the entanglement indicator ( data points ) , and plotted with the fourier fit ( solid line).,height=192 ]     as a function of time , as trained at 0.0089 phase noise at each of the 317 timesteps , for the entanglement indicator ( data points ) , and plotted with the fourier fit ( solid line).,height=192 ]    figures  [ fkph],[fepph],[fzph ] show the fourier coefficients for @xmath34 , @xmath35 , and @xmath11 , respectively , as functions of increasing decoherence level .",
    "it is clear that in the case of decoherence the parameter functions are even more stable than in the previous case of noise .",
    ", as functions of decoherence level.,height=192 ]    , as functions of decoherence level.,height=192 ]    , as functions of decoherence level.,height=192 ]    testing results for the pure state @xmath43 subject to decoherence are shown in figures  [ p0ph],[p89ph],[p13ph ] , as trained , respectively , at zero , 0.0089 , and 0.013 decoherence ( phase noise ) , and tested with various levels of phase noise , and compared with the entanglement of formation at zero and at 0.0069 phase noise .",
    "the results are extremely good , better even than the ones in figures  [ p0mag],[p89mag],[p13mag ] ; clearly , the qnn is even better at dealing with decoherence than with `` pure '' noise .",
    "possibly the various ( random ) phases tend to cancel each other ; but since for phase shifts the qnn underestimates the entanglement , sometimes drastically @xcite , this was an unexpectedly good result .     as a function of @xmath38 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero phase noise ( blue ) and at 0.0069 phase noise ( orange ) . in each case",
    "the qnn was trained at zero phase noise , but tested at the given level.,height=192 ]     as a function of @xmath38 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero phase noise ( blue ) and at 0.0069 phase noise ( orange ) . in each case",
    "the qnn was trained at a phase noise level of 0.0089 , and then tested at the given level.,height=192 ]     as a function of @xmath38 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero phase noise ( blue ) and at 0.0069 phase noise ( orange ) . in each case",
    "the qnn was trained at 0.013 phase noise , and then tested at the given level.,height=192 ]    figures  [ m0ph],[m89ph],[m13ph ] show the performance of the qnn on the mixed state @xmath44 , as trained , respectively , at zero , 0.0089 , and 0.013 decoherence ( phase noise ) , and tested with various levels of phase noise , and compared with the entanglement of formation at zero and at 0.0069 phase noise .",
    "again , we see that the qnn entanglement indicator is robust to decoherence .     as a function of @xmath42 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero phase noise ( blue ) and at 0.0069 phase noise ( orange ) . in each case",
    "the qnn was trained at zero noise , but tested at the given level.,height=192 ]     as a function of @xmath42 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero phase noise ( blue ) and at 0.0069 phase noise ( orange ) . in each case",
    "the qnn was trained at a phase noise level of 0.0089 , and then tested at the given level.,height=192 ]     as a function of @xmath42 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero phase noise ( blue ) and at 0.0069 phase noise ( orange ) . in each case",
    "the qnn was trained at 0.013 phase noise , and then tested at the given level.,height=192 ]",
    "finally , we consider the case of noise plus decoherence , that is , what we are calling random complex noise . for this case , we add both magnitude and phase noise .",
    "figure  [ cxtrn ] shows a typical rms error training curve for a the same level of complex noise as in figures  [ magtrn ] and [ phtrn ] . again ,",
    "asymptotic error for the training set does increase with increasing complex noise .",
    "the parameter functions again become `` noisy '' : see figures  [ kcx],[epcx],[zcx ] .    , approximately the same as with only magnitude noise.,height=192 ]     as a function of time , as trained at 0.0089 complex noise at each of the 317 timesteps , for the entanglement indicator ( data points ) , and plotted with the fourier fit ( solid line ) . note the change in scale from figure  [ k0 ] , because of the ( much larger ) spread of the noisy data : the fourier fit is actually almost the same on this graph.,height=192 ]     as a function of time , as trained at 0.0089 complex noise at each of the 317 timesteps , for the entanglement indicator ( data points ) , and plotted with the fourier fit ( solid line).,height=192 ]     as a function of time , as trained at 0.0089 complex noise at each of the 317 timesteps , for the entanglement indicator ( data points ) , and plotted with the fourier fit ( solid line).,height=192 ]    again , we test to see how much the fourier fit changes , this time with complex noise . figures  [ fkcx],[fepcx],[fzcx ] show the fourier coefficients as a function of complex noise level , for @xmath9 , @xmath32 , and @xmath11 , respectively .",
    "we can see that the indicator is , again , relatively stable .",
    ", as functions of complex noise level.,height=192 ]    , as functions of complex noise level.,height=192 ]    , as functions of complex noise level.,height=192 ]    again we use the fourier fitted functions to test on both pure and mixed states .",
    "figures  [ p0cx],[p89cx],[p13cx ] show performance of the qnn on the entanglement of the state @xmath43 , as trained , respectively , at zero , 0.0089 , and 0.013 amplitude complex noise , and tested with various levels of complex noise , and compared with the entanglement of formation at zero and at 0.0069 complex noise .",
    "figures  [ m0cx ]  [ m89cx ]  [ m13cx ] show the performance of the qnn on the mixed state @xmath44 , as trained , respectively , at zero , 0.0089 , and 0.013 complex noise , and tested with various levels of complex noise , and compared with the entanglement of formation at zero and at 0.0069 complex noise .",
    "results are excellent ; in fact , they are somewhat better than for the case of only `` magnitude '' noise . in some sense allowing for decoherence makes the indicator even more robust .     as a function of @xmath38 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.69% noise plus decoherence ( orange ) . in each case",
    "the qnn was trained at zero noise , but tested at the given level.,height=192 ]     as a function of @xmath38 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise plus decoherence ( orange ) . in each case",
    "the qnn was trained at a noise level of 0.0089 complex noise , and then tested at the given level.,height=192 ]     as a function of @xmath38 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero complex noise ( blue ) and at 0.0069 noise plus decoherence(orange ) . in each case",
    "the qnn was trained at 0.013 level complex noise , and then tested at the given level.,height=192 ]     as a function of @xmath42 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise plus decoherence(orange ) . in each case",
    "the qnn was trained at zero noise , but tested at the given level.,height=192 ]     as a function of @xmath42 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise plus decoherence ( orange ) . in each case",
    "the qnn was trained at a complex noise level of 0.0089 , and then tested at the given level.,height=192 ]     as a function of @xmath42 , as calculated by the qnn , and compared with the entanglement of formation ( marked `` bw '' ) at zero noise ( blue ) and at 0.0069 noise plus decoherence ( orange ) . in each case",
    "the qnn was trained at 0.013 complex noise , and then tested at the given level.,height=192 ]",
    "in previous work , we have proposed an entanglement indicator for a general qubit system .",
    "this indicator is a quantum system that processes the state whose entanglement is to be estimated .",
    "the parameters of the quantum system are adjusted via a supervised learning process using a sparse training set of states whose entanglement is well - defined .",
    "the learning is continued until sufficient training is achieved .",
    "the trained parameter functions are well represented by single frequency functions ( first order fourier curve fit . )    we have shown here that those functions are robust to fairly high levels of noise and decoherence .",
    "the quantum neural network tests well on `` unknown '' states , both pure and mixed .",
    "performance on decoherence in particular was excellent .",
    "we are reasonably confident that our results show that quantum neural networks are well suited for dealing with these types of problems in quantum computing .",
    "we are currently working to extend our results on noise and decoherence to multiple - qubit systems , using the well - known neural network technique of bootstrapping @xcite .",
    "we also wish to understand exactly why the qnn is so robust to noise and decoherence .",
    "classical neural networks are robust to noise and single neuron / synapse failure because of the multiple - redundance of parallel computing . here",
    ", we have only a very small number of qubits / neurons , but we have designed our quantum network as operating over propagation in time , which can be written as a superposition of a very large number of definite time paths , using the feynman path integral representation of quantum mechanics @xcite . in this picture , the instantaneous states of the quantum system at intermediate times , which are integrated over , play the role of `` virtual neurons''@xcite . in other words , it is possible that quantum superposition ensures redundance , even when the physical number of qubits is small , and thereby supplies fault - tolerance .",
    "this work was supported in part by the national science foundation under grant no .",
    "nsf phy05 - 51164 , through the kitp scholars program ( ecb ) , at the kavli institute for theoretical physics , university of california at santa barbara , santa barbara , ca .",
    "v. vedral , m.b .",
    "plenio , m.a .",
    "rippin , and p.l . knight ( 1997 ) , _ quantifying entanglement _ , phys .",
    "2275 - 2279 ; v vedral and m.b .",
    "plenio ( 1998 ) , _ entanglement measures and purification procedures _ , phys .",
    "a 57 , pp .",
    "1619 - 1633 ; l. henderson and v. vedral ( 2001 ) , _ classical , quantum and total correlations _",
    ", j. phys .",
    "a 34 , pp .",
    "6899 - 6905 .            yann le cun ( 1988 ) , _ a theoretical framework for back - propagation _ in _ proc .",
    "1998 connectionist models summer school , _ d. touretzky , g. hinton , and t. sejnowski , eds . , morgan kaufmann , ( san mateo ) , pp .",
    "21 - 28 .",
    "behrman and j.e .",
    "steck , _ dynamic learning of pairwise and three - way entanglement _",
    ", in _ proceedings of the third world congress on nature and biologically inspired computing ( nabic 2011 ) _",
    "( salamanca , spain , october 19 - 21 , 2011 . )",
    "( institute of electrical and electronics engineers ) .",
    "behrman and j.e .",
    "steck , _ a quantum neural network computes its own relative phase _ , in _ proceedings of the ieee symposium on computational intelligence 2013 _ ( singapore , april 15 - 19 , 2013 . )",
    "( institute of electrical and electronics engineers ) .",
    "behrman , r.e.f .",
    "bonde , j.e .",
    "steck , and j.f .",
    "behrman ( 2014 ) , _ on the correction of anomalous phase oscillation in entanglement witnesses using quantum neural networks _ , ieee transactions on neural networks and learning systems 25 ( 9 ) , pp.1696 - 1703 .",
    "feynman ( 1951 ) , _ an operator calculus having applications in quantum electrodynamics _ , phys .",
    "84 , 108 - 128 ; r.p .",
    "feynman and a.r .",
    "hibbs ( 1965 ) , _ quantum mechanics and path integrals _ , mcgraw - hill ( new york ) ."
  ],
  "abstract_text": [
    "<S> in previous work , we have proposed an entanglement indicator for a general multiqubit state , which can be `` learned '' by a quantum system , acting as a neural network . </S>",
    "<S> the indicator can be used for a pure or a mixed state , and the system need not be `` close '' to any particular state ; moreover , as the size of the system grows , the amount of additional training necessary diminishes . here </S>",
    "<S> , we show that the indicator is stable to noise and decoherence .    quantum algorithm , entanglement , dynamic learning , noise , decoherence </S>"
  ]
}