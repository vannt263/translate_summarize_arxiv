{
  "article_text": [
    "neural networks learn from examples . this concept has extensively been investigated using models and methods of statistical mechanics @xcite .",
    "a  teacher ",
    "network is presenting input / output pairs of high dimensional data , and a  student  network is being trained on these data .",
    "training means , that synaptic weights adopt by simple rules to the input / output pairs .",
    "when the networks  teacher as well as student  have @xmath0 weights , the training process needs of the order of @xmath0 examples to obtain generalization abilities .",
    "this means , that after the training phase the student has achieved some overlap to the teacher , their weight vectors are correlated . as a consequence",
    ", the student can classify an input pattern which does not belong to the training set .",
    "the average classification error decreases with the number of training examples .",
    "training can be performed in two different modes : batch and on - line training . in the first case",
    "all examples are stored and used to minimize the total training error . in the second case only one new example is used per time step and then destroyed . therefore on - line training may be considered as a dynamic process : at each time step the teacher creates a new example which the student uses to change its weights by a tiny amount .",
    "in fact , for random input vectors and in the limit @xmath1 , learning and generalization can be described by ordinary differential equations for a few order parameters @xcite .    on - line training",
    "is a dynamic process where the examples are generated by a static network - the teacher .",
    "the student tries to move towards the teacher .",
    "however , the student network itself can generate examples on which it is trained .",
    "when the output bit is moved to the shifted input sequence , the network generates a complex time series @xcite .",
    "such networks are called bit ( for binary ) or sequence ( for continuous numbers ) generators and have recently been studied in the context of time series prediction @xcite .",
    "this work on the dynamics of neural networks - learning from a static teacher or generating time series by self interaction - has motivated us to study the following problem : what happens if two neural networks learn from each other ? in the following section an analytic solution is presented @xcite , which shows a novel phenomenon : synchronization by mutual learning .",
    "the biological consequences of this phenomenon are not explored , yet , but we found an interesting application in cryptography : secure generation of a secret key over a public channel .    in the field of cryptography , one is interested in methods to transmit secret messages between two partners a and b. an opponent e who is able to listen to the communication should not be able to recover the secret message .    before 1976 , all cryptographic methods had to rely on secret keys for encryption which were transmitted between a and b over a secret channel not accessible to any opponent .",
    "such a common secret key can be used , for example , as a seed for a random bit generator by which the bit sequence of the message is added ( modulo 2 ) .    in 1976 , however , diffie and hellmann found that a common secret key could be created over a public channel accessible to any opponent .",
    "this method is based on number theory : given limited computer power , it is not possible to calculate the discrete logarithm of sufficiently large numbers @xcite .    here",
    "we show how neural networks can produce a common secret key by exchanging bits over a public channel and by learning from each other .",
    "here we study mutual learning of neural networks for a simple model system : two perceptrons receive a common random input vector @xmath2 and change their weights @xmath3 according to their mutual bit @xmath4 , as sketched in fig . [ per ] . the output bit @xmath4 of a single perceptron",
    "is given by the equation    @xmath5    @xmath2 is an @xmath0-dimensional input vector with components which are drawn from a gaussian with mean @xmath6 and variance @xmath7 .",
    "@xmath8 is a @xmath0-dimensional weight vector with continuous components which are normalized ,    @xmath9     and learn their mutual output bits @xmath4 . ]",
    "the initial state is a random choice of the components @xmath10 for the two weight vectors @xmath11 and @xmath12 . at each training",
    "step a common random input vector is presented to the two networks which generate two output bits @xmath13 and @xmath14 according to ( [ eins ] ) .",
    "now the weight vectors are updated by the perceptron learning rule @xcite :    @xmath15    @xmath16 is the step function .",
    "hence , only if the two perceptrons disagree a training step is performed with a learning rate @xmath17 .",
    "after each step ( [ drei ] ) , the two weight vectors have to be normalized .    in the limit @xmath18 ,",
    "the overlap    @xmath19    has been calculated analytically @xcite .",
    "the number of training steps @xmath20 is scaled as @xmath21 , and @xmath22 follows the equation    @xmath23    where @xmath24 is the angle between the two weight vectors @xmath11 and @xmath25 , i.e. @xmath26 .",
    "this equation has fixed points @xmath27 , and    @xmath28     between two perceptrons as a function of learning rate @xmath17 . above a critical rate",
    "@xmath29 the time dependent networks are synchronized . from ref .",
    "@xcite ]    fig .",
    "[ fig1 ] shows the attractive fixed point of [ fuenf ] as a function of the learning rate @xmath17 . for small values of @xmath17 the two networks relax to a state of a mutual agreement , @xmath30 for @xmath31 . with",
    "increasing learning rate @xmath17 the angle between the two weight vectors increases up to @xmath32 for    @xmath33    above the critical rate @xmath29 the networks relax to a state of complete disagreement , @xmath34 .",
    "the two weight vectors are antiparallel to each other , @xmath35 .    as a consequence , the analytic solution shows ,",
    "well supported by numerical simulations for @xmath36 , that two neural networks can synchronize to each other by mutual learning .",
    "both of the networks are trained to the examples generated by their partner and finally obtain an antiparallel alignment . even after synchronization",
    "the networks keep moving , the motion is a kind of random walk on an n - dimensional hypersphere producing a rather complex bit sequence of output bits @xmath37 @xcite .",
    "we want to apply synchronization of neural networks to cryptography . in the previous section",
    "we have seen that the weight vectors of two perceptrons learning from each other can synchronize .",
    "the new idea is to use the common weights @xmath38 as a key for encryption @xcite .",
    "but two problems have to be solved yet : ( i ) can an external observer , recording the exchange of bits , calculate the final @xmath39 , ( ii ) does this phenomenon exist for discrete weights ?",
    "point ( i ) is essential for cryptography , it will be discussed in the following section .",
    "point ( ii ) is important for practical solutions since communication is usually based on bit sequences .",
    "it will be investigated in the following .",
    "synchronization occurs for normalized weights , unnormalized ones do not synchronize @xcite . therefore ,",
    "for discrete weights , we introduce a restriction in the space of possible vectors and limit the components @xmath40 to @xmath41 different values ,    @xmath42    in order to obtain synchronization to a parallel  instead of an antiparallel ",
    "state @xmath43 , we modify the learning rule ( [ drei ] ) to :    @xmath44    now the components of the random input vector @xmath2 are binary @xmath45 .",
    "if the two networks produce an identical output bit @xmath46 , then their weights move one step in the direction of @xmath47 .",
    "but the weights should remain in the interval ( [ acht ] ) , therefore if any component moves out of this interval , @xmath48 , it is set back to the boundary @xmath49 .",
    "each component of the weight vectors performs a kind of random walk with reflecting boundary .",
    "two corresponding components @xmath50 and @xmath51 receive the same random number @xmath52 .",
    "after each hit at the boundary the distance @xmath53 is reduced until it has reached zero . for two perceptrons with a @xmath0-dimensional weight space",
    "we have two ensembles of @xmath0 random walks on the internal @xmath54 .",
    "if we neglect the global signal @xmath46 as well as the bias @xmath55 , we expect that after some characteristic time scale @xmath56 the probability of two random walks being in different states decreases as    @xmath57    hence the total synchronization time should be given by @xmath58 which gives    @xmath59    in fact , our simulations for @xmath36 show that two perceptrons with @xmath60 synchronize in about 100 time steps and the synchronization time increases logarithmically with @xmath0 .",
    "however , our simulations also showed that an opponent , recording the sequence of @xmath61 is able to synchronize , too .",
    "therefore , a single perceptron does not allow a generation of a secret key .",
    "obviously , a single perceptron transmits too much information .",
    "an opponent , who knows the set of input / output pairs , can derive the weights of the two partners after synchronization .",
    "therefore , one has to hide so much information , that the opponent can not calculate the weights , but on the other side one has to transmit enough information that the two partners can synchronize .",
    "in fact , we found that multilayer networks with hidden units may be candidates for such a task @xcite .",
    "more precisely , we consider parity machines with three hidden units as shown in fig . [ par ] .",
    "each hidden unit is a perceptron ( [ eins ] ) with discrete weights ( [ acht ] ) .",
    "the output bit @xmath62 of the total network is the product of the three bits of the hidden units    @xmath63    at each training step the two machines @xmath64 and @xmath65 receive identical input vectors @xmath66 .",
    "the training algorithm is the following : only if the two output bits are identical , @xmath67 , the weights can be changed . in this case , only the hidden unit @xmath68 which is identical to @xmath62 changes its weights using the hebbian rule    @xmath69    for example , if @xmath70 there are four possible configurations of the hidden units in each network :    @xmath71    in the first case , all three weight vectors @xmath72 are changed , in all other three cases only one weight vector is changed .",
    "the partner as well as any opponent does not know which one of the weight vectors is updated .",
    "the partners @xmath64 and @xmath65 react to their mutual stop and move signals @xmath73 and @xmath74 , whereas an opponent can only receive these signals but not influence the partners with its own output bit .",
    "this is the essential mechanism which allows synchronization but prohibits learning .",
    "numerical @xcite as well as analytical @xcite calculations of the dynamic process show that the partners can synchronize in a short time whereas an opponent needs a much longer time to lock into the partners .",
    "this observation holds for an observer who uses the same algorithm ( [ dreizehn ] ) as the two partners @xmath64 and @xmath65 .",
    "note that the observer knows 1 .",
    "the algorithm of @xmath64 and @xmath65 , 2 .",
    "the input vectors @xmath75 at each time step and 3 .",
    "the output bits @xmath73 and @xmath74 at each time step .",
    "nevertheless , he does not succeed in synchronizing with @xmath64 and @xmath65 within the communication period .    .",
    "]        since for each run the two partners draw random initial weights and since the input vectors are random , one obtains a distribution of synchronization times as shown in fig .",
    "[ tsync ] for @xmath76 and @xmath60 .",
    "the average value of this distribution is shown as a function of system size @xmath0 in fig .",
    "even an infinitely large network needs only a finite number of exchanged bits - about 400 in this case - to synchronize , in agreement with the analytical calculation for @xmath1 .",
    "if the communication continues after synchronization , an opponent has a chance to lock into the moving weights of @xmath64 and @xmath65 .",
    "[ rat ] shows the distribution of the ratio between the synchronization time of @xmath64 and @xmath65 and the learning time of the opponent . in our simulations , for @xmath36 , this ratio never exceeded the value @xmath77 , and the average learning time is about 50000 time steps , much larger than the synchronization time .",
    "hence , the two partners can take their weights @xmath78 at a time step @xmath20 where synchronization most probably occurred as a common secret key .",
    "synchronization of neural networks can be used as a key exchange protocol over a public channel .",
    "interacting neural networks have been calculated analytically . at each training step",
    "two networks receive a common random input vector and learn their mutual output bits .",
    "a new phenomenon has been observed : synchronization by mutual learning .",
    "if the learning rate @xmath17 is large enough , and if the weight vectors keep normalized , then the two networks relax to an antiparallel orientation .",
    "their weight vectors still move like a random walk on a hypersphere , but each network has complete knowledge about its partner .",
    "it has been shown how this phenomenon can be used for cryptography .",
    "the two partners can agree on a common secret key over a public channel .",
    "an opponent who is recording the public exchange of training examples can not obtain full information about the secrete key used for encryption .",
    "this works if the two partners use multilayer networks , parity machines .",
    "the opponent has all the informations ( except the initial weight vectors ) of the two partners and uses the same algorithms",
    ". nevertheless he does not synchronize .",
    "this phenomenon may be used as a key exchange protocol .",
    "the two partners select secret initial weight vectors , agree on a public sequence of input vectors and exchange public bits .",
    "after a few steps they have identical weight vectors which are used for a secret encryption key . for each communication",
    "they agree on a new secret key , without having stored any secret information before .",
    "in contrast to number theoretical methods the networks are very fast ; essentially they are linear filters , the complexity to generate a key of length @xmath0 scales with @xmath0 ( for sequential update of the weights ) .    of course",
    ", one can not rule out that algorithms for the opponent may be constructed which find the key in much shorter time .",
    "in fact , ensembles of opponents have a better chance to synchronize . in addition",
    ", one can show that , given the information of the opponent , the key is uniquely determined , and , given the sequence of inputs , the number of keys is huge but finite , even in the limit @xmath79 @xcite",
    ". these may be good news for a possible attacker .",
    "however , recently we have found advanced algorithms for synchronization , too .",
    "such variations are subjects of active research , and future will show whether the security of neural network cryptography can compete with number theoretical methods .",
    "* acknowledgments * : this work profitted from enjoyable collaborations with richard metzler and michal rosen - zvi .",
    "we thank the german israel science foundation ( gif ) and the minerva center of the bar - ilan university for support .",
    "a. engel , and c. van den broeck : _ statistical mechanics of learning _ , ( cambridge university press , 2001 ) m. biehl and n. caticha : statistical mechanics of on - line learning and generalization , _ the handbook of brain theory and neural networks _ , ed . by m.",
    "a. arbib ( mit press , berlin 2001 )      i. kanter , d.a .",
    "kessler , a. priel and e. eisenstein , phys .",
    "lett . * 75 * , 2614 - 2617 ( 1995 ) ; l. ein - dor and i. kanter , phys . rev . * e 57 * , 6564 ( 1998 ) ; m. schrder and w. kinzel , j. phys .",
    "* a 31 * , 9131 - 9147 ( 1998 ) ; a. priel and i. kanter , europhys . lett ."
  ],
  "abstract_text": [
    "<S> two neural networks which are trained on their mutual output bits are analysed using methods of statistical physics . </S>",
    "<S> the exact solution of the dynamics of the two weight vectors shows a novel phenomenon : the networks synchronize to a state with identical time dependent weights . extending the models to multilayer networks with discrete weights </S>",
    "<S> , it is shown how synchronization by mutual learning can be applied to secret key exchange over a public channel . </S>"
  ]
}