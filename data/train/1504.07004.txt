{
  "article_text": [
    "the ubiquity of multimedia content in our daily lives requires effective tools for multimedia annotation and retrieval .",
    "multimedia annotation tools automatically annotate image or video content ( samples ) with text labels specifying different objects , events , etc . called _",
    "concepts_. most of these systems treat the task of automatic annotation as a classification challenge , whereby a separate classifier is trained for each of these concepts  @xcite ,  @xcite ,  @xcite ,  @xcite .",
    "however , fewer approaches explore the correlation between these concepts  @xcite .    a typical multimedia retrieval system , on the other hand , ranks the multimedia samples based on their relevance to the user s text query .",
    "generally , the retrieval is done by comparing the query to the sample concept labels .",
    "thus an exhaustive annotation of the sample is often a pre - requisite for such retrieval systems .",
    "normalized continuous relevance model ( normcrm )  @xcite is an example of a technique that allows for a direct retrieval of samples without having to annotate them .",
    "however training this model ( like many others ) , requires fully annotated data .",
    "the human - effort costs of concept annotation is significant and this raises an interesting research question : is there a way to achieve a decent annotation / retrieval performance without requiring a fully annotated training dataset ?",
    "the community has taken to _ active learning _ to address this issue  @xcite .",
    "active learning , is a machine learning technique that interactively selects unlabeled samples and queries an oracle to provide labels for the samples .",
    "such a system outputs an order of labeling the samples such that a decent annotation / retrieval performance is achieved before all unlabeled data is queried .",
    "a typical active learning system consists of a learning engine , which does the annotation / retrieval and a sample selection engine , responsible for determining the labeling order of the unlabeled samples .",
    "in this work , we use normcrm as the learning engine and propose a novel sample selection algorithm .",
    "we call this integrated system crmactive and apply it for video annotation and video retrieval tasks .",
    "the algorithm uses a measure of _ informativeness _ for ranking unlabeled samples during active learning .",
    "this informativeness combines a new measure of sample uncertainty with a novel cluster - refinement based approach for determining sample density and diversity .",
    "our experiments show that crmactive outperforms a state - of - the - art approach and a random baseline .",
    "normalized continuous relevance model ( normcrm ) is a generative annotation / retrieval technique  @xcite .",
    "let s consider a video sample @xmath0 defined by a @xmath1-dimensional feature vector @xmath2 and @xmath3 be the vocabulary of all concept labels ( each concept 1 word long ) .",
    "normcrm defines conditional probability for using a label word @xmath4 to annotate the video @xmath0 , as @xmath5 .",
    "lavrenko et al .",
    "@xcite suggest that for annotation we pick the top-@xmath6 words with highest @xmath7 , @xmath8 .",
    "for the task of retrieval using a query word @xmath9 , we pick the top-@xmath10 videos with highest @xmath11 , @xmath12 . in both cases ,",
    "the joint - distribution of words and features @xmath13 is estimated from the training data by @xmath14 where @xmath15 is the set of training video samples and @xmath16 is the set of words in question .",
    "however , normcrm requires a fully annotated data for training . to circumvent this ,",
    "we integrate normcrm into an active learning framework by combining it with a sample selection engine , which selects samples for annotation based on their _",
    "informativeness_. we calculate the informativeness by combining measures of sample _ uncertainty _ , _ density _ and _",
    "diversity_.    _ sample uncertainty _ is a measure of how uncertain the learning engine is about the labels of a sample . using svm as a learning engine , entropy and distance of sample from decision boundary have been explored as sample uncertainty measures  @xcite . however , these techniques do nt capture a measure of the ambiguity between the relevant labels and the irrelevant ones for normcrm - based models . hence",
    ", we define a novel measure of uncertainty of an unlabeled sample ( defined by a m - dim .",
    "feature @xmath17 ) as : @xmath18 where @xmath19 ( in decreasing order of relevance ) are the top - k most relevant labels assigned to @xmath17 . the denominator in eq .",
    "[ eq : uncertainty ] gives a measure of the gap ( distance ) between the posterior probabilities of the most relevant label and the first irrelevant one and can thus be used to obtain uncertainty .",
    "_ sample density _ is a measure of how likely a certain sample is to occur given the underlying distribution that generated the data while a high _ sample diversity _ score ensures that the samples chosen for labeling are nt too similar to each other . to compute sample density and diversity , we start by clustering all samples in the training data @xmath20 , consisting of the initial labeled training data @xmath21 and the unlabeled training data @xmath22 ( @xmath23 ) .",
    "we first represent every sample in the visual feature space and perform x - means clustering .",
    "x - means is a variant of k - means , which automatically picks the parameter k by comparing the bayesian information criterion ( bic ) scores of the clustering system for a range of values of k and picking the one with an optimal score  @xcite .",
    "we then check if every labeled sample shares a concept with at least one other labeled sample in the same cluster . a sample that shares no labels ,",
    "is removed from the cluster and we use it to create a new cluster and redistribute unlabeled samples from the original cluster between the old and the new clusters using 2-means .    in order to measure the extent of agreement amongst the labeled samples in a cluster , both in terms of their visual features and their labels , we use _ empirical entropy _  @xcite . for a cluster @xmath24",
    ", it is defined as : @xmath25 where there are @xmath26 labeled samples in the cluster and @xmath27 is a kernel function .",
    "a kernel is a mapping : @xmath28 , where @xmath29 is the input space .",
    "a kernel may be considered as a measure of similarity . for continuous input spaces , such as video features , a gaussian kernel",
    "is often used  @xcite : @xmath30 where @xmath31 . for discrete input spaces , such as the space of labels ,",
    "a bernoulli product kernel may be used  @xcite : @xmath32,\\ ] ] where @xmath33 , @xmath34 , @xmath35 shows the presence ( 1 ) or absence ( 0 ) of the @xmath36 concept and @xmath37 is the probability of the @xmath36 concept occurring . in order to capture the notion of sample similarity both from the visual and label perspectives ,",
    "we define a new kernel as a combination of the two  @xcite : @xmath38    once we clustered the sample videos , we compute the sample density of an unlabeled sample @xmath17 in cluster @xmath24 as @xmath39 where @xmath40 is the kernel density estimate : @xmath41 and @xmath42 is the total number of samples in cluster @xmath24 .    our definition of the sample density , though similar to zha et al .",
    "@xcite , differs by using clusters , which are refined ( see later in this section ) , to determine the neighboring samples of @xmath17 rather than a static set of its k - nearest neighbors .    to compute the sample diversity",
    ", we use the angular distance between features similar to brinker s technique  @xcite .",
    "however we choose only the representative samples of every cluster ( i.e. the sample closest to the cluster centroid ) , @xmath43 , rather than all the samples in @xmath44 , to gain speed .",
    "diversity of the unlabeled samples is thus , defined as : @xmath45 where @xmath46 is the set of all @xmath15 cluster representatives @xmath47 .",
    "now , we combine these measures to determine the _ informativeness _ of an unlabeled sample @xmath17 as @xmath48    we rank the unlabeled samples in the order of decreasing @xmath49 score , to select a batch of top-@xmath50 samples for labeling . while zha et al . use a combination of sample local structure , density , diversity , and relevance to score the samples  @xcite , our approach differs , most notably , in the use of clustering and a novel uncertainty measure .",
    "equation  [ eq : entropy ] reveals that a cluster with low inter - sample disagreement has a low entropy . as more samples in a cluster @xmath24",
    "are labeled , the disagreement among its labeled samples increases .",
    "this changes the empirical entropy @xmath51 in a monotonically non - decreasing fashion .",
    "therefore we refine the clusters by doing the following : after each batch of labeling , the algorithm determines the cluster with the worst entropy and uses its @xmath51 as a threshold to decide whether to keep or split a cluster during the next batch and this is repeated for successive iterations .",
    "if a newly labeled sample increases the cluster entropy beyond the threshold for that batch , then a grid search is used to determine the first labeled sample without which the cluster meets the entropy threshold .",
    "we create a new cluster with this sample and rearrange the unlabeled samples via 2-means , like before ( see algo .  [ ca ] ) .",
    "we conduct two sets of experiments . in each set ,",
    "the experimental dataset is divided into training and test subsets .",
    "for the first set of experiments , the task of an algorithm is to annotate a test video with a subset of concepts from the vocabulary .",
    "the algorithm starts with the training data set divided into labeled ( @xmath21 ) and unlabeled ( @xmath22 ) parts .",
    "initially only a small subset of the training set is considered to be labeled .",
    "the algorithm uses this information to annotate the test set with concept labels . for the next step ,",
    "the algorithm selects a batch of @xmath50 unlabeled training samples , we reveal the labels for the selected samples , and the algorithm repeats the annotation task . for every iteration ,",
    "we compute precision scores of the algorithm on the test - set for each concept and report their average .",
    "we call this score : ap .    in the second set of experiments , an algorithm ranks the test samples by their similarity to a single word query without annotating the test samples . again",
    ", the algorithm starts with the training dataset divided into labeled and unlabeled parts . for each concept label in the vocabulary , the algorithm ranks the test samples by their similarity to the concept .",
    "it then selects a batch of @xmath50 unlabeled training samples , we reveal the labels for the selected samples , and the algorithm repeats the ranking task . for each round , we report the ap scores for the top 5 images / videos .",
    "* trecvid 2007 * : the trecvid 2007 video corpus has 110 short video clips  @xcite .",
    "each frame in every video is annotated with at most 16 concept labels selected from a set of 36 concepts such as `` crowd '' , `` building '' , `` airplane '' , etc .",
    "this corpus has been used extensively in video annotation experiments  @xcite . in recent multimedia recognition / annotation tasks histograms",
    "have been found to be effective as a feature summarization technique for text content (  @xcite ,  @xcite ,  @xcite ) , acoustic content (  @xcite ) and images / video (  @xcite ,  @xcite ,  @xcite ) .",
    "therefore , for every frame we compute a 225-dimensional feature vector ( color moment , edge orientation histogram , wavelet pwttwt texture ) as described in the work of zha et al .",
    "we test our model on the frames from 13 randomly selected videos and we use the rest of the data ( frames from 97 videos ) for training .",
    "we selected 4000 frames from the training data as the initial set of labeled samples @xmath21 , containing at least 1 positive example of every concept .",
    "we set , batch size , @xmath50 to 2400 .",
    "* usc smartbody * : smartbody is an open virtual character animation platform .",
    "it ships with a library of 274 animations such as walking , hand beat gesture , pointing , eye - brow raising , lip corner stretching , etc .",
    "the animations are defined on a 3d skeleton consisting of 119 individual joints and the 3d coordinates of these joints are available from the smartbody api .",
    "each animation is annotated using at most 6 concept labels from a set of 30 labels such as `` legs '' , `` arms '' , `` face '' , `` left '' , `` right '' , etc .",
    "the x - axis of figure  [ conceptap ] gives an exhaustive list of all the concepts .",
    "the animations are annotated at the video clip level ( i.e. the individual frames are not annotated ) .",
    "9 out of 119 joints have been handpicked for feature computation ( neck , left(l)/right(r ) shoulders , l / r elbows , l / r hip joints , and l / r knees ) .",
    "for each frame in an animation , the skeleton angles at these joints are computed  @xcite and the differences between the minimum and the maximum values for the angles during the whole animation sequence have been encoded as a 9-dimensional feature vector .",
    "this dataset called the usc smartbody annotation - retrieval dataset ( sard ) has recently been made available for research by the community  @xcite .",
    "we randomly selected 24 animations for testing and we use the rest of the data ( 250 animations ) for training . we selected 40 animations from the training data as the initial set of labeled samples @xmath21 , containing at least one positive example of each concept .",
    "we now set , batch size , @xmath50 to 23 .      for annotation task",
    ", we compare crmactive with two methods .",
    "the first one is an active learning system that uses normcrm as the learning engine while the samples are selected randomly .",
    "the results are averaged over 3 runs with different random seeds .",
    "the second baseline is the method proposed by zha et al .",
    "( state - of - the - art )  @xcite .",
    "we determine the two normcrm smoothing parameters @xmath52 and @xmath53  @xcite , and the validated parameters of the second baseline using 10-fold cross - validation on the first annotation batch .",
    "these values are then fixed for successive rounds .",
    "the values of the fixed parameters for the second baseline are reused from the paper  @xcite . for crmactive , probability @xmath37 ,",
    "is re - estimated from the labeled training data on each annotation batch and the weighting parameters @xmath54 .",
    "finally , both normcrm and crmactive work by ranking annotation concepts , so we assign the top-16 concepts for trecvid 2007 and the top-6 for smartbody as relevant . for direct retrieval , crmactive is compared only with the first baseline discussed above , since no prior work is known .",
    ".ap scores ( on y - axis ) for annotation on trecvid ( a ) , smartbody ( b ) and ap scores ( on y - axis ) for retrieval of top-5 videos on trecvid ( c ) , smartbody ( d ) .",
    "[ cols=\"^,^ \" , ]      the results in table  [ aps ] shows that both the normcrm - based models , i.e. the first baseline ( normcrm ) and crmactive , generally perform better than the zha et al .",
    "approach for annotation .",
    "we believe that this is due to the fact that normcrm captures the inter - label correlation while zha et al .",
    "trains individual classifiers for every concept . also the normcrm - based systems",
    "jointly model the labels and features , which allows them to capture the patterns from both these perspectives , this is again not the case for zha et al .",
    "furthermore crmactive by selecting the more informative samples first , trains a more robust model early on , which results in its monotonic non - decreasing ap score for annotation / retrieval .",
    "this is in contrast with the occasional dips in the ap scores of the random baseline , which might potentially select some of the relatively  bad \" ( noisy ) training samples early on .",
    "figure  [ sampres ] shows a sample annotation result on the smartbody dataset using crmactive .",
    "we see that the model gets all top 3 labels correct at round 7 , even before the training data is fully annotated .",
    "figure  [ conceptap ] shows the annotation performance of all the models for the individual concepts of the smartbody dataset over two rounds ( initial and towards the end ) .",
    "the concept scores for the normcrm random baseline are obtained by averaging over the results of the 3 runs .",
    "we notice a performance gain for all the models across most concepts over the two rounds , indicating that more training data helps .",
    "we also notice that crmactive is always at least as good , on all concepts . for concepts with a high number of positive examples , such as legs ,",
    "all models do well .",
    "further , we believe that the nature of the features used can explain a good performance by all models for complex concepts such as dance as compared to some others ones like mouth .",
    "in this work , we proposed a sample selection algorithm based on active learning by combining a novel measure of sample uncertainty and a novel cluster - refinement approach for determining sample density and diversity .",
    "this approach is shown to outperform multiple baselines at both annotation and retrieval tasks .",
    "our experiments also reveal the pros of using a generative approach of jointly modeling both the features and labels .",
    "crmactive is thus shown to be a promising active learning approach to explore .",
    "this material is based on work supported in part by the dreamworks animation skg .",
    "any opinions , findings , conclusions or recommendations expressed in this material are the authorsand do not necessarily reflect those of the sponsors .",
    "additionally , the first author would also like to sincerely thank every member of the nld group , dr .",
    "ari shapiro , alesia egan at usc ict and prof .",
    "louis - philippe morency at lti , cmu for their insightful suggestions / feedback / co - operation ."
  ],
  "abstract_text": [
    "<S> conventional multimedia annotation / retrieval systems such as normalized continuous relevance model ( normcrm )  @xcite require a fully labeled training data for a good performance . </S>",
    "<S> active learning , by determining an order for labeling the training data , allows for a good performance even before the training data is fully annotated . in this work </S>",
    "<S> we propose an active learning algorithm , which combines a novel measure of sample uncertainty with a novel clustering - based approach for determining sample density and diversity and integrate it with normcrm . </S>",
    "<S> the clusters are also iteratively refined to ensure both feature and label - level agreement among samples . </S>",
    "<S> we show that our approach outperforms multiple baselines both on a recent , open character animation dataset and on the popular trecvid corpus at both the tasks of annotation and text - based retrieval of videos . </S>"
  ]
}