{
  "article_text": [
    "in his seminal 1948 paper  @xcite , claude shannon gave a formula for the increase in differential entropy per degree of freedom that a continuous - time , band - limited random process @xmath5 experiences after passing through a linear time - invariant ( lti ) continuous - time filter .",
    "in this formula , if the input process is band - limited to a frequency range @xmath6 $ ] , has differential entropy rate ( per degree of freedom ) @xmath7 , and the lti filter has frequency response @xmath8 , then the resulting differential entropy rate of the output process @xmath9 is given by ( * ? ? ?",
    "* theorem  14 ) @xmath10 the last term on the right - hand side ( rhs ) of   can be understood as the _ entropy gain _",
    "( entropy amplification or entropy boost ) introduced by the filter  @xmath8 .",
    "shannon proved this result by arguing that an lti filter can be seen as a linear operator that selectively scales its input signal along infinitely many frequencies , each of them representing an orthogonal component of the source . the result",
    "is then obtained by writing down the determinant of the jacobian of this operator as the product of the frequency response of the filter over @xmath4 frequency bands , applying logarithm and then taking the limit as the number of frequency components tends to infinity .",
    "an analogous result can be obtained for discrete - time input @xmath11 and output @xmath12 processes , and an lti discrete - time filter @xmath13 by relating them to their continuous - time counterparts , which yields @xmath14 where @xmath15 is the differential entropy rate of the process @xmath11 .",
    "of course the same formula can also be obtained by applying the frequency - domain proof technique that shannon followed in his derivation of  .    the rightmost term in  , which corresponds to the entropy gain of @xmath13 ,",
    "can be related to the structure of this filter .",
    "it is well known that if @xmath0 is causal with a rational transfer function @xmath13 such that @xmath16 ( i.e. , such that the first sample of its impulse response has unit magnitude ) , then @xmath17 where @xmath18 are the zeros of @xmath13 and @xmath19 is the open unit disk on the complex plane .",
    "this provides a straightforward way to evaluate the entropy gain of a given lti filter with rational transfer function @xmath13 .",
    "in addition ,   shows that , if @xmath16 , then such gain is greater than one if and only if @xmath13 has zeros outside @xmath20 .",
    "a filter with the latter property is said to be _ non - minimum phase _ ( nmp ) ; conversely , a filter with all its zeros inside @xmath20 is said to be _ minimum phase _ ( mp )  @xcite .",
    "nmp filters appear naturally in various applications .",
    "for instance , any unstable lti system stabilized via linear feedback control will yield transfer functions which are nmp  @xcite .",
    "additionally , nmp - zeros also appear when a discrete - time with zoh ( _ zero order hold _ ) equivalent system is obtained from a plant whose number of poles exceeds its number of zeros by at least 2 , as the sampling rate increases  ( * ? ? ?",
    "* lemma 5.2 ) . on the other hand ,",
    "all linear - phase filters , which are specially suited for audio and image - processing applications , are nmp  @xcite .",
    "the same is true for any all - pass filter , which is an important building block in signal processing applications  @xcite .",
    "an alternative approach for obtaining the entropy gain of lti filters is to work in the time domain ; obtain @xmath21 as a function of @xmath22 , for every @xmath23 , and evaluate the limit @xmath24 .",
    "more precisely , for a filter @xmath0 with impulse response @xmath25 , we can write @xmath26 where @xmath27^{t}$ ] and the random vector @xmath28 is defined likewise . from this",
    ", it is clear that @xmath29 where @xmath30 ( or simply @xmath31 ) stands for the determinant of @xmath32 .",
    "thus , @xmath33 = 0,\\end{aligned}\\ ] ] regardless of whether @xmath13 ( i.e. , the polynomial @xmath34 ) has zeros with magnitude greater than one , * which clearly contradicts   and  * . perhaps surprisingly , the above contradiction not only has been overlooked in previous works ( such as  @xcite ) , but the time - domain formulation in the form of   has been utilized as a means to prove or disprove   ( see , for example , the reasoning in  @xcite ) .",
    "a reason for why the contradiction between  ,   and   arises can be obtained from the analysis developed in  @xcite for an lti system @xmath35 within a noisy feedback loop , as the one depicted in fig .",
    "[ fig : fbksystem ] . in this scheme , @xmath36 represents a causal feedback channel which combines the output of @xmath35 with an exogenous ( noise ) random process @xmath37 to generate its output .",
    "the process @xmath37 is assumed independent of the initial state of @xmath35 , represented by the random vector @xmath38 , which has finite differential entropy .    for this system , it is shown in  ( * ? ? ?",
    "* theorem 4.2 ) that    [ eq : martins_both ] @xmath39 with equality if @xmath40 is a deterministic function of @xmath41 .",
    "furthermore , it is shown in  ( * ? ? ?",
    "* lemma 3.2 ) that if @xmath42 and the steady state variance of system @xmath35 remains asymptotically bounded as @xmath43 , then @xmath44    where @xmath45 are the poles of @xmath35 .",
    "thus , for the ( simplest ) case in which @xmath46 , the output @xmath47 is the result of filtering @xmath48 by a filter @xmath49 ( as shown in fig .",
    "[ fig : fbksystem]-right ) , and the resulting entropy rate of @xmath12 will exceed that of @xmath11 only if there is a random initial state with bounded differential entropy ( see  ) . moreover , under the latter conditions ,  ( * ? ? ?",
    "* lemma 4.3 ) implies that if @xmath13 is stable and @xmath42 , then this entropy gain will be lower bounded by the _ right - hand side _",
    "( rhs ) of  , which is greater than zero if and only if @xmath0 is nmp .",
    "however , the result obtained in   does not provide conditions under which the equality in the latter equation holds .",
    "additional results and intuition related to this problem can be obtained from in  @xcite .",
    "there it is shown that if @xmath12 is a two - sided gaussian stationary random process generated by a state - space recursion of the form    [ subeq : state_space_yhkim ] @xmath50    for some @xmath51 , @xmath52 , @xmath53 , with unit - variance gaussian i.i.d .",
    "innovations @xmath54 , then its entropy rate will be exactly @xmath55 ( i.e. , the differential entropy rate of @xmath54 ) plus the rhs of   ( with @xmath18 now being the eigenvalues of @xmath56 outside the unit circle ) .",
    "however , as noted in  @xcite , if the same system with zero ( or deterministic ) initial state is excited by a one - sided infinite gaussian i.i.d .",
    "process @xmath48 with unit sample variance , then the ( asymptotic ) entropy rate of the output process @xmath47 is just  @xmath55 ( i.e. , there is no entropy gain ) .",
    "moreover , it is also shown that if @xmath57 is a gaussian random sequence with positive - definite covariance matrix and @xmath58 , then the entropy rate of @xmath59 also exceeds that of @xmath48 by the rhs of  .",
    "this suggests that for an lti system which admits a state - space representation of the form  , the entropy gain for a single - sided gaussian i.i.d .",
    "input is zero , and that the entropy gain from the input to the output - plus - disturbance is  , for any gaussian disturbance of length @xmath60 with positive definite covariance matrix ( no matter how small this covariance matrix may be ) .",
    "the previous analysis suggests that it is the absence of a random initial state or a random additive output disturbance that makes the time - domain formulation   yield a zero entropy gain .",
    "but , how would the addition of such finite - energy exogenous random variables to   actually produce an increase in the differential entropy rate which asymptotically equals the rhs of  ? in a broader sense , it is not clear from the results mentioned above what the necessary and sufficient conditions are under which an entropy gain equal to the rhs of   arises ( the analysis in  @xcite provides only a set of sufficient conditions and relies on second - order statistics and gaussian innovations to derive the results previously described ) .",
    "another important observation to be made is the following : it is well known that the entropy gain introduced by a linear mapping is independent of the input statistics  @xcite .",
    "however , there is no reason to assume such independence when this entropy gain arises as the result of adding a random signal to the input of the mapping , i.e. , when the mapping by itself does not produce the entropy gain .",
    "hence , it remains to characterize the largest set of input statistics which yield an entropy gain , and the magnitude of this gain .",
    "the first part of this paper provides answers to these questions .",
    "in particular , in section  [ sec : geometric_interpretation ] explain how and when the entropy gain arises ( in the situations described above ) , starting with input and output sequences of finite length , in a time - domain analysis similar to  , and then taking the limit as the length tends to infinity .",
    "in section  [ sec : entropy_gain_output_disturb ] it is shown that , in the output - plus - disturbance scenario , the entropy gain is _ at most _ the rhs of  .",
    "we show that , for a broad class of input processes ( not necessarily gaussian or stationary ) , this maximum entropy gain is reached only when the disturbance has bounded differential entropy and its length is at least equal to the number of non - minimum phase zeros of the filter .",
    "we provide upper and lower bounds on the entropy gain if the latter condition is not met .",
    "a similar result is shown to hold when there is a random initial state in the system ( with finite differential entropy ) .",
    "in addition , in section  [ sec : entropy_gain_output_disturb ] we study the entropy gain between the _ entire output sequence _ that a filter yields as response to a shorter input sequence ( in section  [ sec : effective_entropy ] ) . in this case , however , it is necessary to consider a new definition for differential entropy , named _ effective differential entropy_. here we show that an effective entropy gain equal to the rhs of   is obtained provided the input has finite differential entropy rate , even when there is no random initial state or output disturbance .",
    "in the second part of this paper ( section[sec : implications ] ) we apply the conclusions obtained in the first part to three problems , namely , networked control , the rate - distortion function for non - stationary gaussian sources , and the gaussian channel capacity with feedback .",
    "in particular , we show that equality holds in   for the feedback system in fig .",
    "[ fig : fbksystem]-left under very general conditions ( even when the channel @xmath36 is noisy ) . for the problem of finding the quadratic rate - distortion function for non - stationary auto - regressive gaussian sources , previously solved in  @xcite",
    ", we provide a simpler proof based upon the results we derive in the first part .",
    "this proof extends the result stated in  @xcite to a broader class of non - stationary sources . for the feedback gaussian capacity problem ,",
    "we show that capacity results based on using a short random sequence as channel input and relying on a feedback filter which boosts the entropy rate of the end - to - end channel noise ( such as the one proposed in  @xcite ) , crucially depend upon the complete absence of any additional disturbance anywhere in the system .",
    "specifically , we show that the information rate of such capacity - achieving schemes drops to zero in the presence of any such additional disturbance . as a consequence , the relevance of characterizing the robust ( i.e. , in the presence of disturbances ) feedback capacity of gaussian channels , which appears to be a fairly unexplored problem , becomes evident .",
    "finally , the main conclusions of this work are summarized in section  [ sec : conclusions ] .    except where present , all proofs are presented in the appendix .      for any lti system @xmath0",
    ", the transfer function @xmath13 corresponds to the @xmath61-transform of the impulse response @xmath62 , i.e. , @xmath63 . for a transfer function @xmath13 ,",
    "we denote by @xmath64 the lower triangular toeplitz matrix having @xmath65^{t}$ ] as its first column .",
    "we write @xmath66 as a shorthand for the sequence @xmath67 and , when convenient , we write @xmath66 in vector form as @xmath68^{t}$ ] , where @xmath69 denotes transposition . random scalars ( vectors ) are denoted using non - italic characters , such as @xmath70 ( non - italic and boldface characters , such as @xmath71 ) . for matrices",
    "we use upper - case boldface symbols , such as @xmath56 .",
    "we write @xmath72 to the note the @xmath73-th smallest - magnitude eigenvalue of @xmath56 . if @xmath74 , then @xmath75 denotes the entry in the intersection between the @xmath73-th row and the @xmath76-th column . we write @xmath77^{i_{1}}_{i_{2}}$ ] , with @xmath78 , to refer to the matrix formed by selecting the rows @xmath79 to @xmath80 of @xmath56 .",
    "the expression @xmath81_{m_{2}}$ ] corresponds to the square sub - matrix along the main diagonal of @xmath56 , with its top - left and bottom - right corners on @xmath82 and @xmath83 , respectively .",
    "a diagonal matrix whose entries are the elements in @xmath84 is denoted as @xmath85",
    "consider the discrete - time system depicted in fig .  [ fig : general ] . in this setup ,",
    "the input @xmath48 is a random process and the block @xmath0 is a causal , linear and time - invariant system with random initial state vector @xmath38 and random output disturbance @xmath86 .    in vector notation , @xmath87 where @xmath88 is the natural response of @xmath0 to the initial state @xmath38 .",
    "we make the following further assumptions about @xmath0 and the signals around it :    [ assu : g_factorized ] @xmath13 is a causal , stable and rational transfer function of finite order , whose impulse response @xmath89 satisfies @xmath90 .",
    "it is worth noting that there is no loss of generality in considering @xmath91 , since otherwise one can write @xmath13 as @xmath92 , and thus the entropy gain introduced by @xmath93 would be @xmath94 plus the entropy gain due to @xmath95 , which has an impulse response where the first sample equals @xmath96 .",
    "the random initial state @xmath97 is independent of @xmath48 .",
    "[ assu : z ] the disturbance @xmath86 is independent of @xmath48 and belongs to a @xmath98-dimensional linear subspace , for some finite @xmath99 .",
    "this subspace is spanned by the @xmath98 orthonormal columns of a matrix @xmath100 ( where @xmath101 stands for the countably infinite size of @xmath102 ) , such that @xmath103 .",
    "equivalently , @xmath104 , where the random vector @xmath105 has finite differential entropy and is independent of @xmath106 .    as anticipated in the introduction ,",
    "we are interested in characterizing the entropy gain @xmath107 of @xmath0 in the presence ( or absence ) of the random inputs @xmath108 , denoted by @xmath109 in the next section we provide geometrical insight into the behaviour of @xmath110 for the situation where there is a random output disturbance and no random initial state . a formal and precise treatment of this scenario is then presented in section  [ sec : entropy_gain_output_disturb ] .",
    "the other scenarios are considered in the subsequent sections .",
    "in this section we provide an intuitive geometric interpretation of how and when the entropy gain defined in   arises . this understanding will justify the introduction of the notion of an entropy - balanced random process ( in definition  [ def : entropy_balanced ] below ) , which will be shown to play a key role in this and in related problems .",
    "suppose for the moment that @xmath0 in fig .",
    "[ fig : general ] is an fir filter with impulse response @xmath111 .",
    "notice that this choice yields @xmath112 , and thus @xmath13 has one non - minimum phase zero , at @xmath113 .",
    "the associated matrix @xmath114 for @xmath115 is @xmath116 whose determinant is clearly one ( indeed , all its eigenvalues are @xmath96 ) .",
    "hence , as discussed in the introduction , @xmath117 , and thus @xmath118 ( and @xmath114 in general ) does not introduce an entropy gain by itself .",
    "however , an interesting phenomenon becomes evident by looking at the singular - value decomposition ( svd ) of @xmath118 , given by @xmath119 , where @xmath120 and @xmath121 are unitary matrices and @xmath122 . in this case ,",
    "@xmath123 , and thus one of the singular values of @xmath118 is much smaller than the others ( although the product of all singular values yields @xmath96 , as expected ) . as will be shown in section  [ sec : entropy_gain_output_disturb ] , for a stable @xmath13 such uneven distribution of singular values arises only when @xmath13 has non - minimum phase zeros .",
    "the effect of this can be visualized by looking at the image of the cube @xmath124^{3}$ ] through @xmath118 shown in fig .",
    "[ fig : cube ] .    if the input @xmath125 were uniformly distributed over this cube ( of unit volume ) , then @xmath126 would distribute uniformly over the unit - volume parallelepiped depicted in fig .",
    "[ fig : cube ] , and hence @xmath117 .",
    "now , if we add to @xmath126 a disturbance @xmath127 , with scalar @xmath128 uniformly distributed over @xmath129 $ ] independent of @xmath125 , and with @xmath130 , the effect would be to `` thicken '' the support over which the resulting random vector @xmath131 is distributed , along the direction pointed by @xmath132 .",
    "if @xmath132 is aligned with the direction along which the support of @xmath126 is thinnest ( given by @xmath133 , the first row of @xmath120 ) , then the resulting support would have its volume significantly increased , which can be associated with a large increase in the differential entropy of @xmath134 with respect to @xmath125 . indeed , a relatively small variance of @xmath128 and an approximately aligned @xmath132 would still produce a significant entropy gain .",
    "the above example suggests that the entropy gain from @xmath28 to @xmath135 appears as a combination of two factors .",
    "the first of these is the uneven way in which the random vector @xmath136 is distributed over @xmath137 .",
    "the second factor is the alignment of the disturbance vector @xmath138 with respect to the span of the subset @xmath139 of columns of @xmath140 , associated with smallest singular values of @xmath114 , indexed by the elements in the set @xmath141 .",
    "as we shall discuss in the next section , if @xmath0 has @xmath142 non - minimum phase zeros , then , as @xmath4 increases , there will be @xmath142 singular values of @xmath114 going to zero exponentially .",
    "since the product of the singular values of @xmath114 equals @xmath96 for all @xmath4 , it follows that @xmath143 must grow exponentially with @xmath4 , where @xmath144 is the @xmath73-th diagonal entry of @xmath145 .",
    "this implies that @xmath136 expands with @xmath4 along the span of @xmath146 , compensating its shrinkage along the span of @xmath147 , thus keeping @xmath148 for all @xmath4 . thus ,",
    "as @xmath4 grows , any small disturbance distributed over the span of @xmath147 , added to @xmath136 , will keep the support of the resulting distribution from shrinking along this subspace .",
    "consequently , the expansion of @xmath136 with @xmath4 along the span of @xmath146 is no longer compensated , yielding an entropy increase proportional to @xmath149 .",
    "the above analysis allows one to anticipate a situation in which no entropy gain would take place even when some singular values of @xmath114 tend to zero as @xmath150 . since the increase in entropy",
    "is made possible by the fact that , as @xmath4 grows , the support of the distribution of @xmath136 shrinks along the span of @xmath147 , no such entropy gain should arise if the support of the distribution of the input @xmath28 expands accordingly along the directions pointed by the rows @xmath151 of @xmath152 .",
    "an example of such situation can be easily constructed as follows : let @xmath13 in fig .",
    "[ fig : general ] have non - minimum phase zeros and suppose that @xmath48 is generated as @xmath153 , where @xmath154 is an i.i.d . random process with bounded entropy rate .",
    "since the determinant of @xmath155 equals @xmath96 for all @xmath4 , we have that @xmath156 , for all @xmath4 . on the other hand , @xmath157 . since @xmath158^{1}_{n}\\rves^{1}_{\\kappa}$ ] for some finite @xmath98 ( recall assumption  [ assu : z ] ) , it is easy to show that @xmath159 , and thus no entropy gain appears .",
    "the preceding discussion reveals that the entropy gain produced by @xmath0 in the situation shown in fig .",
    "[ fig : general ] * depends on the distribution of the input and on the support and distribution of the disturbance*. this stands in stark contrast with the well known fact that the increase in differential entropy produced by an invertible linear operator depends only on its jacobian , and not on the statistics of the input  @xcite .",
    "we have also seen that the distribution of a random process along the different directions within the euclidean space which contains it plays a key role as well .",
    "this motivates the need to specify a class of random processes which distribute more or less evenly over all directions .",
    "the following section introduces a rigorous definition of this class and characterizes a large family of processes belonging to it .",
    "we begin by formally introducing the notion of an `` entropy - balanced '' process @xmath48 , being one in which , for every finite @xmath160 , the differential entropy rate of the orthogonal projection of @xmath22 into any subspace of dimension @xmath161 equals the entropy rate of @xmath22 as @xmath150 .",
    "this idea is precisely in the following definition .",
    "[ def : entropy_balanced ] a random process @xmath162 is said to be entropy balanced if , for every @xmath160 ,    [ eq : the_painful_assumption ] @xmath163    for every sequence of matrices @xmath164 , @xmath165 , with orthonormal rows .",
    "equivalently , a random process @xmath166 is entropy balanced if every unitary transformation on @xmath167 yields a random sequence @xmath168 such that @xmath169 .",
    "this property of the resulting random sequence @xmath168 means that one can not predict its last @xmath170 samples with arbitrary accuracy by using its previous @xmath161 samples , even if @xmath4 goes to infinity .",
    "we now characterize a large family of entropy - balanced random processes and establish some of their properties .",
    "although intuition may suggest that most random processes ( such as i.i.d . or stationary processes ) should be entropy balanced , that statement seems rather difficult to prove . in the following ,",
    "we show that the entropy - balanced condition is met by i.i.d .",
    "processes with per - sample _ probability density function _ ( pdf ) being uniform , piece - wise constant or gaussian .",
    "it is also shown that adding to an entropy - balanced process an independent random processes independent of the former yields another entropy - balanced process , and that filtering an entropy - balanced process by a stable and minimum phase filter yields an entropy - balanced process as well .",
    "[ prop : gaussian_is_entropy_balanced ] let @xmath48 be a gaussian i.i.d .",
    "random process with positive and bounded per - sample variance .",
    "then @xmath48 is entropy balanced .",
    "[ lem : piecewiseconstant ] let @xmath48 be an i.i.d . process with finite differential entropy rate , in which each @xmath171 is distributed according to a piece - wise constant pdf in which each interval where this pdf is constant has measure greater than @xmath172 , for some bounded - away - from - zero constant @xmath172 . then @xmath48 is entropy balanced .",
    "[ lem : sum_yields_entropy_balanced ] let @xmath48 and @xmath173 be mutually independent random processes . if @xmath48 is entropy balanced , then @xmath174 is also entropy balanced .",
    "the working behind this lemma can be interpreted intuitively by noting that adding to a random process another independent random process can only increase the `` spread '' of the distribution of the former , which tends to balance the entropy of the resulting process along all dimensions in euclidean space .",
    "in addition , it follows from lemma  [ lem : sum_yields_entropy_balanced ] that all i.i.d .",
    "processes having a per - sample pdf which can be constructed by convolving uniform , piece - wise constant or gaussian pdfs as many times as required are entropy balanced .",
    "it also implies that one can have non - stationary processes which are entropy balanced , since lemma  [ lem : sum_yields_entropy_balanced ] imposes no requirements for the process @xmath173 .",
    "our last lemma related to the properties of entropy - balanced processes shows that filtering by a stable and minimum phase lti filter preserves the entropy balanced condition of its input .",
    "[ lem : filtering_preserves_entropy_balance ] let @xmath48 be an entropy - balanced process and @xmath0 an lti stable and minimum - phase filter .",
    "then the output @xmath175 is also an entropy - balanced process .",
    "this result implies that any stable moving - average auto - regressive process constructed from entropy - balanced innovations is also entropy balanced , provided the coefficients of the averaging and regression correspond to a stable mp filter .",
    "we finish this section by pointing out two examples of processes which are non - entropy - balanced , namely , the output of a nmp - filter to an entropy - balanced input and the output of an unstable filter to an entropy - balanced input .",
    "the first of these cases plays a central role in the next section .",
    "in this section we formalize the ideas which were qualitatively outlined in the previous section . specifically , for the system shown in fig .  [ fig : general ] we will characterize the entropy gain @xmath110 defined in   for the case in which the initial state @xmath38 is zero ( or deterministic ) and there exists an output random disturbance of ( possibly infinite length ) @xmath86 which satisfies assumption  [ assu : z ] .",
    "the following lemmas will be instrumental for that purpose .",
    "[ lem : singular_values_bounded ] let @xmath176 be a causal , finite - order , stable and minimum - phase rational transfer function with impulse response @xmath177 such that @xmath178 . then @xmath179 and @xmath180 .",
    "[ lem : gap_with_two_terms ] consider the system in fig .",
    "[ fig : general ] , and suppose @xmath86 satisfies assumption  [ assu : z ] , and that the input process @xmath48 is entropy balanced .",
    "let @xmath181 be the svd of @xmath114 , where @xmath182 are the singular values of @xmath114 , with @xmath183 , such that @xmath184 @xmath185 .",
    "let @xmath142 be the number of these singular values which tend to zero exponentially as @xmath150 .",
    "then @xmath186^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\rvez^{1}_{n } \\right ) \\right ) .",
    "\\end{aligned}\\ ] ]    ( the proof of this lemma can be found in the appendix , page  ) .",
    "the previous lemma precisely formulates the geometric idea outlined in section  [ sec : geometric_interpretation ] . to see this , notice that no entropy gain is obtained",
    "if the output disturbance vector @xmath138 is orthogonal to the space spanned by the first @xmath142 columns of @xmath140 . if this were the case , then the disturbance would not be able fill the subspace along which @xmath136 is shrinking exponentially .",
    "indeed , if @xmath187^{1}_{n}\\rvez^{1}_{n}=0 $ ] for all @xmath4 , then @xmath188^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\rvez^{1}_{n } ) = h({^{1}}\\![\\bd_{n}]_{m}[\\br_{n}]^{1}_{m}\\rveu^{1}_{n } ) = \\sum_{i=1}^{m } \\log d_{n , i}+h([\\br_{n}]^{1}_{m}\\rveu^{1}_{n } ) $ ] , and the latter sum cancels out the one on the rhs of  , while @xmath189^{1}_{n}\\rveu^{1}_{n})=0 $ ] since @xmath48 is entropy balanced . on the contrary ( and loosely speaking )",
    ", if the projection of the support of @xmath138 onto the subspace spanned by the first @xmath142 rows of @xmath140 is of dimension @xmath142 , then @xmath190^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\rvez^{1}_{n } ) $ ] remains bounded for all @xmath4 , and the entropy limit of the sum @xmath191 on the rhs of   yields the largest possible entropy gain .",
    "notice that @xmath192 ( because @xmath193 ) , and thus this entropy gain stems from the uncompensated expansion of @xmath136 along the space spanned by the rows of @xmath187^{m+1}_{n}$ ] .",
    "lemma  [ lem : gap_with_two_terms ] also yields the following corollary , which states that only a filter @xmath13 with zeros outside the unit circle ( i.e. , an nmp transfer function ) can introduce entropy gain .",
    "[ coro : mp_filters_no_eg ] consider the system shown in fig .",
    "[ fig : general ] and let @xmath48 be an entropy - balanced random process with bounded entropy rate . besides assumption  [ assu : g_factorized ] , suppose that @xmath13 is minimum phase .",
    "then @xmath194    since @xmath13 is minimum phase and stable , it follows from lemma  [ lem : singular_values_bounded ] that the number of singular values of @xmath114 which go to zero exponentially , as @xmath150 , is zero . indeed , all the singular values vary polynomially with @xmath4 .",
    "thus @xmath195 and lemma  [ lem : gap_with_two_terms ] yields directly that the entropy gain is zero ( since the rhs of   is zero ) .      in this section we show that random disturbances satisfying assumption  [ assu : z ] , when added to the _ input _ @xmath48 ( i.e. , before @xmath0 ) , do not introduce entropy gain .",
    "this result can be obtained from lemma  [ lem : gap_with_two_terms ] , as stated in the following theorem :    let @xmath0 satisfy assumption  [ assu : g_factorized ] .",
    "suppose that @xmath48 is entropy balanced and consider the output @xmath196 where @xmath197 with @xmath198 being a random vector satisfying @xmath199 , and where @xmath200 has orthonormal columns .",
    "then , @xmath201    in this case , the effect of the input disturbance in the output is the forced response of @xmath0 to it . this response can be regarded as an output disturbance @xmath202 .",
    "thus , the argument of the differential entropy on the rhs of   is @xmath203^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\rvez^{1}_{n }    &    =    [ \\bd_{n}]^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m } \\bq_{n}^{t}\\bd_{n}\\br_{n}\\rveb^{1}_{n } \\\\ & =    [ \\bd_{n}]^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bd_{n}]^{1}_{m}\\br_{n}\\rveb^{1}_{n } \\\\ & =    { { ^{1}\\![\\bd_{n}]_{m } } } { [ \\br_{n}]^{1}_{m}}\\left ( \\rveu^{1}_{n } + \\rveb^{1}_{n}\\right ) .",
    "\\end{aligned}\\ ] ] therefore , @xmath204^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\rvez^{1}_{n } )    &    =    h({{^{1}\\![\\bd_{n}]_{m } } } { [ \\br_{n}]^{1}_{m}}\\left ( \\rveu^{1}_{n } + \\rveb^{1}_{n}\\right ) )    \\\\ &    =    \\sumfromto{i=1}{m}\\log d_{n , i } + h({[\\br_{n}]^{1}_{m}}\\left ( \\rveu^{1}_{n } + [ { \\boldsymbol{\\psi}}]^{1}_{n}\\rvea^{1}_{\\nu}\\right ) ) .\\end{aligned}\\ ] ] the proof is completed by substituting this result into the rhs of   and noticing that @xmath205^{1}_{m}(\\rveu^{1}_{n } + [ { \\boldsymbol{\\psi}}]^{1}_{n}\\rvea^{1}_{\\nu})\\right)=0.\\ ] ]    an alternative proof for this result can be given based upon the properties of an entropy - balanced sequence , as follows . since @xmath206 , we have that @xmath207 .",
    "let @xmath208 and @xmath209 be a matrices with orthonormal rows which satisfy @xmath210^{1}_{n}=\\bzero$ ] and such that @xmath211^{t}$ ] is a unitary matrix .",
    "then @xmath212^{t}\\left(\\rveu^{1}_{n}+\\rveb^{1}_{n}\\right ) )   =   h({\\boldsymbol{\\theta}}_{n } \\rveu^{1}_{n}+ { \\boldsymbol{\\theta}}_{n}[{\\boldsymbol{\\psi}}]^{1}_{n}\\rvea^{1}_{\\nu } \\,|\\ , \\overline{{\\boldsymbol{\\theta}}}_{n}\\rveu^{1}_{n } )   +   h(\\overline{{\\boldsymbol{\\theta}}}_{n}\\rveu^{1}_{n}),\\end{aligned}\\ ] ] where we have applied the chain rule of differential entropy .",
    "but @xmath213^{1}_{n}\\rvea^{1}_{\\nu } | \\overline{{\\boldsymbol{\\theta}}}_{n}\\rveu^{1}_{n } )   \\leq     h({\\boldsymbol{\\theta}}_{n } \\rveu^{1}_{n}+ { \\boldsymbol{\\theta}}_{n}[{\\boldsymbol{\\psi}}]^{1}_{n}\\rvea^{1}_{\\nu } ) \\end{aligned}\\ ] ] which is upper bounded for all @xmath4 because @xmath214 and @xmath215 , the latter due to @xmath48 being entropy balanced . on the other hand ,",
    "since @xmath216 is independent of @xmath28 , it follows that @xmath217 , for all @xmath4 .",
    "thus @xmath218 , where the last equality stems from the fact that @xmath48 is entropy balanced .",
    "we show here that the entropy gain of a transfer function with zeros outside the unit circle is at most the sum of the logarithm of the magnitude of these zeros . to be more precise , the following assumption is required .",
    "[ assu : zeros_of_g ] the filter @xmath0 satisfies assumption  [ assu : g_factorized ] and its transfer function @xmath13 has @xmath219 poles and @xmath219 zeros , @xmath142 of which are nmp - zeros . let @xmath60 be the number of distinct nmp zeros , given by @xmath220 , i.e. , such that @xmath221 , with @xmath222 being the multiplicity of the @xmath73-th distinct zero .",
    "we denote by @xmath223 , where @xmath224 , the distinct zero of @xmath13 associated with the @xmath73-th non - distinct zero of @xmath13 , i.e. , @xmath225    as can be anticipated from the previous results in this section , we will need to characterize the asymptotic behaviour of the singular values of @xmath114 .",
    "this is accomplished in the following lemma , which relates these singular values to the zeros of @xmath13 .",
    "this result is a generalization of the unnumbered lemma in the proof of  ( * ? ? ?",
    "* theorem  1 ) ( restated in the appendix as lemma  [ lem : hashimoto ] ) , which holds for fir transfer functions , to the case of _ infinite - impulse response _ ( iir ) transfer functions ( i.e. , transfer functions having poles ) .",
    "[ lem : hashimoto_iir ] for a transfer function @xmath0 satisfying assumption  [ assu : zeros_of_g ] , it holds that @xmath226 where the elements in the sequence @xmath227 are positive and increase or decrease at most polynomially with @xmath4 .",
    "( the proof of this lemma can be found in the appendix , page  ) .",
    "we can now state the first main result of this section .",
    "[ thm : eg_n_instate_w_disturb_ineq ] in the system of fig .",
    "[ fig : general ] , suppose that @xmath48 is entropy balanced and that @xmath13 and @xmath86 satisfy assumptions  [ assu : zeros_of_g ] and  [ assu : z ] , respectively .",
    "then @xmath228 where @xmath229 and @xmath98 is as defined in assumption  [ assu : z ] .",
    "both bounds are tight .",
    "the upper bound is achieved if @xmath230^{1}_{\\bar{\\kappa } } } { [ { \\boldsymbol{\\phi}}]^{1}_{n}}({[\\bq_{n}]^{1}_{\\bar{\\kappa } } } { [ { \\boldsymbol{\\phi}}]^{1}_{n}})^{t})>0 $ ] , where the unitary matrices @xmath231 hold the left singular vectors of @xmath114",
    ".    see appendix , page  .",
    "the second main theorem of this section is the following :    [ thm : eg_n_instate_w_disturb ] in the system of fig .",
    "[ fig : general ] , suppose that @xmath48 is entropy balanced and that @xmath13 satisfies assumption  [ assu : zeros_of_g ] .",
    "let @xmath86 be a random output disturbance , such that @xmath232 , and that @xmath233 .",
    "then @xmath234    see appendix , page  .",
    "here we analyze the case in which there exists a random initial state @xmath38 independent of the input @xmath48 , and zero ( or deterministic ) output disturbance .",
    "the effect of a random initial state appears in the output as the natural response of @xmath0 to it , namely the sequence @xmath235 .",
    "thus , @xmath168 can be written in vector form as @xmath236 this reveals that the effect of a random initial state can be treated as a random output disturbance , which allows us to apply the results from the previous sections .    recall from assumption  [ assu : zeros_of_g ]",
    "that @xmath13 is a stable and biproper rational transfer function with @xmath142 nmp zeros . as such ,",
    "it can be factored as @xmath237 where @xmath238 is a biproper filter containing only all the poles of @xmath13 , and @xmath239 is a fir biproper filter , containing all the zeros of @xmath13 .",
    "we have already established ( recall theorem  [ coro : mp_filters_no_eg ] ) that the entropy gain introduced by the minimum phase system @xmath238 is zero .",
    "it then follows that the entropy gain can be introduced only by the nmp - zeros of @xmath239 and an appropriate output disturbance @xmath240 .",
    "notice that , in this case , the input process @xmath241 to @xmath242 ( i.e. , the output sequence of @xmath35 due to a random input @xmath243 ) is independent of @xmath240 ( since we have placed the natural response @xmath244 after the filters @xmath35 and @xmath242 , hose initial state is now zero ) .",
    "this condition allows us to directly use lemma  [ lem : gap_with_two_terms ] in order to analyze the entropy gain that @xmath243 experiences after being filtered by @xmath0 , which coincides with @xmath245 .",
    "this is achieved by the next theorem .",
    "[ thm : eg - due - to - random - xo ] consider a stable @xmath219-th order biproper filter @xmath13 having @xmath142 nmp - zeros , and with a random initial state @xmath246 , such that @xmath247 .",
    "then , the entropy gain due to the existence of a random initial state is @xmath248    [ proof : thm_eg - due - to - random - xo ] being a biproper and stable rational transfer function , @xmath13 can be factorized as @xmath249 where @xmath238 is a stable biproper transfer function containing only all the poles of @xmath13 and with all its zeros at the origin , while @xmath239 is stable and biproper fir filter , having all the zeros of @xmath13 .",
    "let @xmath250 and @xmath251 be the natural responses of the systems @xmath35 and @xmath242 to their common random initial state @xmath38 , respectively , where @xmath252",
    ". then we can write @xmath253 since @xmath238 is stable and mp , it follows from corollary  [ coro : mp_filters_no_eg ] that @xmath254 for all @xmath4 , and therefore @xmath255 therefore , we only need to consider the entropy gain introduced by the ( possibly ) non - minimum filter @xmath242 due to a random output disturbance @xmath256 , which is independent of the input @xmath257 .",
    "thus , the conditions of lemma  [ lem : gap_with_two_terms ] are met considering @xmath258 , where now @xmath259 is the svd for @xmath260 , and @xmath261 .",
    "consequently , it suffices to consider the differential entropy on the rhs of  , whose argument is @xmath262^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\bar{\\rvey}^{1}_{n }     &   =   [ \\bd_{n}]^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m }    \\left ( \\bn_{n}\\tilde{\\bc}_{n}\\rvex_{0 } + \\bc_{n}\\rvex_{0}\\right )   \\\\ &    = [ \\bd_{n}]^{1}_{m}\\br_{n } \\left(\\rveu^{1}_{n } + \\tilde{\\bc}_{n}\\rvex_{0}\\right ) + [ \\bq_{n}]^{1}_{m } \\bc_{n}\\rvex_{0 }   \\\\ &    = [ \\bd_{n}]^{1}_{m}\\br_{n } \\rvev^{1}_{n }   + [ \\bq_{n}]^{1}_{m } \\bc_{n}\\rvex_{0},\\label{eq : the_term_of_v_and_x0}\\end{aligned}\\ ] ] where @xmath263 has bounded entropy rate and is entropy balanced ( since @xmath264 is the natural response of a stable lti system and because of lemma  [ lem : sum_yields_entropy_balanced ] ) .",
    "we remark that , in  , @xmath265 is not independent of @xmath38 , which precludes one from using the proof of theorem  [ thm : eg_n_instate_w_disturb_ineq ] directly .",
    "on the other hand , since @xmath239 is fir of order ( at most ) @xmath219 , we have that @xmath266^t$ ] , where @xmath267 is a non - singular upper - triangular matrix independent of @xmath4 .",
    "hence , @xmath268 can be written as @xmath269^{1}_{n}\\rves^{1}_{p}$ ] , where @xmath270^{1}_{n } = [ \\bi_p^t \\,|\\,\\bzero^t]^t$ ] and @xmath271 .",
    "according to  , the entropy gain in   arises as long as @xmath272 ^ 1_m\\bc_n\\rvex_0)$ ] is lower bounded by a finite constant ( or if it decreases sub - linearly as @xmath4 grows ) .",
    "then , we need @xmath273 ^ 1_m[{\\boldsymbol{\\phi}}]^1_n$ ] to be a full row - ranked matrix in the limit as @xmath150 .",
    "however , @xmath274^{1}_{m}[{\\boldsymbol{\\phi}}_{n}]^{1}_{n } ( [ \\bq_{n}]^{1}_{m}[{\\boldsymbol{\\phi}}_{n}]^{1}_{n})^{t}\\right )   & =   \\det \\left([\\bq_{n}^{(p)}]^{1}_{m}([\\bq_{n}^{(p)}]^{1}_{m})^{t}\\right),\\end{aligned}\\ ] ] where @xmath275 ^ 1_m$ ] denotes the first @xmath219 columns of the first @xmath142 rows in @xmath276 . we will now show that these determinants do not go to zero as @xmath150 .",
    "define the matrix @xmath277 such that @xmath275 ^ 1_m = [ { } ^1[\\bq_n]_m \\,|\\,\\ , \\overline{\\bq}_n]$ ] . then",
    ", it holds that @xmath278 , @xmath279 ^ 1_m)^t \\bx}^2 & = \\norm{({}^1[\\bq_n]_m)^t\\bx}^2 + \\norm{(\\overline{\\bq}_n)^t \\bx}^2 \\\\   & \\geq \\norm{({}^1[\\bq_n]_m)^t\\bx}^2 \\\\   & \\geq \\left(\\lambda_{\\text{min}}({}^1[\\bq_n]_m({}^1[\\bq_n]_m)^t)\\right)^{2}.\\end{aligned}\\ ] ] hence , the minimum singular value of @xmath275 ^ 1_m$ ] is lower bounded by the smallest singular value of @xmath280_m$ ] , for all @xmath281 .",
    "but it was shown in the proof of theorem  [ thm : eg_n_instate_w_disturb ] ( see page  ) that @xmath282_m({}^1[\\bq_n]_m)^t)>0 $ ]",
    ". using this result in   and taking the limit , we arrive to @xmath283^{1}_{m}([\\bq_{n}^{(p)}]^{1}_{m})^{t}\\right )   >   0.\\end{aligned}\\ ] ] thus @xmath284^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\bar{\\rvey}^{1}_{n } \\right )    &   =   h\\left([\\bd_{n}]^{1}_{m}\\br_{n}\\rvev^{1}_{n } + [ \\bq_{n}]^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n}\\rves^{1}_{p}\\right )   \\end{aligned}\\ ] ] is upper and lower bounded by a constant independent of @xmath4 because @xmath173 is entropy balanced , @xmath285^{1}_{m}$ ] has decaying entries , and @xmath286 , which means that the entropy rate in the rhs of   decays to zero .",
    "the proof is finished by invoking lemma  [ lem : hashimoto_iir ] .",
    "theorem  [ thm : eg - due - to - random - xo ] allows us to formalize the effect that the presence or absence of a random initial state has on the entropy gain using arguments similar to those utilized in section  [ sec : entropy_gain_output_disturb ] . indeed ,",
    "if the random initial state @xmath287 has finite differential entropy , then the entropy gain achieves  , since the alignment between @xmath246 and the first @xmath142 rows of @xmath276 is guaranteed .",
    "this motivates us to characterize the behavior of the entropy gain ( due only to a random initial state ) , when the initial state @xmath246 can be written as @xmath269 ^ 1_p\\rves^1_\\tau$ ] , with @xmath288 , which means that @xmath246 has an undefined ( or @xmath289 ) differential entropy .",
    "[ coro : eg_due_to_xo_ineq ] consider an fir , @xmath219-order filter @xmath290 having @xmath142 nmp - zeros , such that its random initial state can be written as @xmath291 , where @xmath292 and @xmath293 contains orthonormal rows .",
    "then , @xmath294 where @xmath295 . the upper bound in",
    "is achieved when @xmath273 ^ 1_m\\bc_n{\\boldsymbol{\\phi}}([\\bq_n]^1_m\\bc_n{\\boldsymbol{\\phi}})^t$ ] is a non - singular matrix , with @xmath296 defined by @xmath297 ( as in theorem  [ thm : eg - due - to - random - xo ] ) .",
    "the effect of the random initial state to the output sequence @xmath298 can be written as @xmath299 , where @xmath300^t \\in \\rl^{n\\times p}$ ] . therefore",
    ", if @xmath301 is an svd for @xmath302 , it holds that @xmath303 ^ 1_n\\br_n\\rveu^1_n + [ \\bq_n]^1_m \\bc_n{\\boldsymbol{\\phi}}\\rves^1_\\tau ) \\label{eq : car}\\end{aligned}\\ ] ] remains bounded , for @xmath150 , if and only if @xmath304 ^ 1_m\\bc_n{\\boldsymbol{\\phi}}([\\bq_n]^1_m\\bc_n{\\boldsymbol{\\phi}})^t)>0 $ ] .",
    "define the rank of @xmath273 ^ 1_m\\bc_n{\\boldsymbol{\\phi}}$ ] as @xmath305 .",
    "if @xmath306 ^ 1_m\\bc_n{\\boldsymbol{\\phi}}([\\bq_n]^1_m\\bc_n{\\boldsymbol{\\phi}})^t)=0 $ ] , then the lower bound is reached by inserting   in  .",
    "otherwise , there exists @xmath307 large enough such that @xmath308 , @xmath309 .",
    "we then proceed as the proof of theorem  [ thm : eg_n_instate_w_disturb_ineq ] , by considering a unitary @xmath310-matrix @xmath311 , and a @xmath312-matrix @xmath313 such that @xmath314^{1}_{m } \\bc_n{\\boldsymbol{\\phi}}=   \\begin{pmatrix }    \\ba_{n}[\\bq_{n}]^{1}_{m } \\bc_n{\\boldsymbol{\\phi}}\\\\    \\bzero   \\end{pmatrix } , \\fspace n\\geq l.\\end{aligned}\\ ] ]    this procedure allows us to conclude that @xmath315 ^ 1_n\\br_n\\rveu^1_n + [ \\bq_n]^1_m \\bc_n{\\boldsymbol{\\phi}}\\rves^1_\\tau ) \\leq",
    "\\sumfromto{i=\\tau_n + 1}{m}\\log d_{n , i}$ ] , and that the lower limit in the latter sum equals @xmath316 when @xmath273 ^ 1_m \\bc_n{\\boldsymbol{\\phi}}\\rves^1_\\tau$ ] is a full row - rank matrix . replacing the latter into   finishes the proof .",
    "if the random initial state @xmath291 is generated with @xmath317 , then the entropy gain introduced by an fir minimum phase filter @xmath318 is at least @xmath319 .",
    "otherwise , the entropy gain could be identically zero , as long as the columns of @xmath320 fill only the orthogonal space to the span of the row vectors in @xmath275 ^ 1_m$ ] , where @xmath321 , @xmath132 and @xmath275 ^ 1_m$ ] are defined as in the proof of theorem  [ thm : eg - due - to - random - xo ] .",
    "both results , theorem  [ thm : eg - due - to - random - xo ] and corollary  [ coro : eg_due_to_xo_ineq ] , reveal that the entropy gain arises as long as the effect of the random initial state aligns with the first rows of @xmath276 , just as in the results of the previous section .",
    "if there are no disturbances and the initial state is zero , then the first @xmath4 output samples to an input @xmath22 is given by  . therefore , the entropy gain in this case , as defined in  , is zero , regardless of whether or not @xmath0 is nmp .    despite the above",
    ", there is an interesting question which , to the best of the authors knowledge , has not been addressed before : since in any lti filter the entire output is longer than the input , what would happen if one compared the differential entropies of the complete output sequence to that of the ( shorter ) input sequence ? as we show next , a proper definition of this question requires recasting the problem in terms of a new definition of differential entropy . after providing a geometrical interpretation of this problem",
    ", we prove that the ( new ) entropy gain in this case is exactly  .",
    "consider the random vectors @xmath322^{t}$ ] and @xmath323^{t}$ ] related via @xmath324 suppose @xmath325 is uniformly distributed over @xmath326\\times[0,1]$ ] .",
    "applying the conventional definition of differential entropy of a random sequence , we would have that @xmath327 because @xmath328 is a deterministic function of @xmath329 and @xmath330 : @xmath331[\\rvau_1 \\ ; \\rvau_2]^{t}= [ 0\\;\\ ; 2 ] \\begin{pmatrix }   1 & 0\\\\   2 & 1\\\\ \\end{pmatrix}^{-1 }    \\begin{bmatrix }    \\rvay_1\\\\    \\rvay_2   \\end{bmatrix}.\\ ] ] in other words , the problem lies in that although the output is a three dimensional vector , it only has two degrees of freedom , i.e. , it is restricted to a 2-dimensional subspace of @xmath332 .",
    "this is illustrated in fig .",
    "[ fig : square_shear ] , where the set @xmath124\\times[0,1]$ ] is shown ( coinciding with the ` u`-`v ` plane ) , together with its image through @xmath333 ( as defined in  ) .    as can be seen in this figure , the image of the square @xmath124^{2}$ ] through @xmath333 is a @xmath334-dimensional rhombus over which @xmath335 distributes uniformly . since the intuitive notion of differential entropy of an ensemble of random variables ( such as",
    "how difficult it is to compress it in a lossy fashion ) relates to the size of the region spanned by the associated random vector , one could argue that the differential entropy of @xmath335 , far from being @xmath289 , should be somewhat larger than that of @xmath336 ( since the rhombus @xmath337^{2}$ ] has a larger area than @xmath124^{2}$ ] ) .",
    "so , what does it mean that ( and why should ) @xmath338 ? simply put , the differential entropy relates to the volume spanned by the support of the probability density function .",
    "for @xmath339 in our example , the latter ( three - dimensional ) volume is clearly zero .    from the above discussion",
    ", the comparison between the differential entropies of @xmath340 and @xmath341 of our previous example should take into account that @xmath339 actually lives in a two - dimensional subspace of @xmath332 .",
    "indeed , since the multiplication by a unitary matrix does not alter differential entropies , we could consider the differential entropy of @xmath342 where @xmath343 is the @xmath344 matrix with orthonormal rows in the singular - value decomposition of @xmath333 @xmath345 and @xmath346 is a unit - norm vector orthogonal to the rows of @xmath347 ( and thus orthogonal to @xmath339 as well ) .",
    "we are now able to compute the differential entropy in @xmath348 for @xmath349 , corresponding to the rotated version of @xmath339 such that its support is now aligned with @xmath348 .",
    "the preceding discussion motivates the use of a modified version of the notion of differential entropy for a random vector @xmath350 which considers the number of dimensions actually spanned by @xmath339 instead of its length .",
    "[ def : bmd_entropy ] let @xmath351 be a random vector . if @xmath339 can be written as a linear transformation @xmath352 , for some @xmath353 ( @xmath354 ) , @xmath355 , then the effective differential entropy of @xmath339 is defined as @xmath356 where @xmath357 is an svd for @xmath358 , with @xmath359 .",
    "it is worth mentioning that shannon s differential entropy of a vector @xmath360 , whose support s @xmath361-volume is greater than zero , arises from considering it as the difference between its ( absolute ) entropy and that of a random variable uniformly distributed over an @xmath361-dimensional , unit - volume region of @xmath362 .",
    "more precisely , if in this case the _ probability density function _ ( pdf ) of @xmath363^{t}$ ] is riemann integrable , then  ( * ? ? ?",
    "9.3.1 ) , @xmath364 , \\end{aligned}\\ ] ] where @xmath365 is the discrete - valued random vector resulting when @xmath339 is quantized using an @xmath361-dimensional uniform quantizer with @xmath361-cubic quantization cells with volume @xmath366 .",
    "however , if we consider a variable @xmath339 whose support belongs to an @xmath4-dimensional subspace of @xmath367 , @xmath368 ( i.e. , @xmath369 , as in definition  [ def : bmd_entropy ] ) , then the entropy of its quantized version in @xmath367 , say @xmath370 , is distinct from @xmath371 , the entropy of @xmath372 in @xmath373",
    ". moreover , it turns out that , in general , @xmath374 despite the fact that @xmath56 has orthonormal rows .",
    "thus , the definition given by   does not yield consistent results for the case wherein a random vector has a support s dimension ( i.e. , its number of degrees of freedom ) smaller that its length changes if @xmath339 is rotated . ]",
    "( if this were not the case , then we could redefine   replacing @xmath361 by @xmath4 , in a spirit similar to the one behind renyi s @xmath375-dimensional entropy  @xcite . ) to see this , consider the case in which @xmath376 distributes uniformly over @xmath124 $ ] and @xmath377^{t}\\rveu/\\hsqrt{2}$ ] .",
    "clearly , @xmath339 distributes uniformly over the unit - length segment connecting the origin with the point @xmath378 .",
    "then @xmath379 on the other hand , since in this case @xmath380 , we have that @xmath381 thus @xmath382    the latter example further illustrates why the notion of effective entropy is appropriate in the setup considered in this section , where the effective dimension of the random sequences does not coincide with their length ( it is easy to verify that the effective entropy of @xmath339 does not change if one rotates @xmath339 in @xmath362 ) .",
    "indeed , we will need to consider only sequences which can be constructed by multiplying some random vector @xmath383 , with bounded differential entropy , by a tall matrix @xmath384 , with @xmath385 ( as in  ) , which are precisely the conditions required by definition  [ def : bmd_entropy ] .",
    "we can now state the main result of this section :    [ thm : bmd_entropy_gain ] let the entropy - balanced random sequence @xmath48 be the input of an lti filter @xmath0 , and let @xmath47 be its output .",
    "assume that @xmath13 is the @xmath61-transform of the @xmath386-length sequence @xmath387 .",
    "then @xmath388    theorem  [ thm : bmd_entropy_gain ] states that , when considering the full - length output of a filter , the effective entropy gain is introduced by the filter itself , without requiring the presence of external random disturbances or initial states . this may seem a surprising result , in view of the findings made in the previous sections , where the entropy gain appeared only when such random exogenous signals were present . in other words , when observing the full - length output and the input , the ( maximum ) entropy gain of a filter can be recasted in terms of the `` volume '' expansion yielded by the filter as a linear operator , provided we measure effective differential entropies instead of shannon s differential entropy .",
    "the total length of the output @xmath361 , will grow with the length @xmath4 of the input , if @xmath0 is fir , and will be infinite , if @xmath0 is iir .",
    "thus , we define the _ output - length function _ @xmath389 it is also convenient to define the sequence of matrices @xmath390 , where @xmath391 is toeplitz with @xmath392_{i , j}=0,\\forall i < j$ ] , @xmath392_{i , j}=g_{i - j},\\forall i\\geq j$ ] .",
    "this allows one to write the _ entire _ output @xmath393 of a causal lti filter @xmath0 with impulse response @xmath394 to an input @xmath243 as @xmath395 let the svd of @xmath396 be @xmath397 , where @xmath398 has orthonormal rows , @xmath399 is diagonal with positive elements , and @xmath400 is unitary .",
    "the effective differential entropy of @xmath401 exceeds the one of @xmath402 by @xmath403 where the first equality follows from the fact that @xmath404 can be written as @xmath405 , which means that @xmath406 . but",
    "@xmath407 since @xmath408 is unitary , it follows that @xmath409 , which means that @xmath410 . the product @xmath411 is a symmetric toeplitz matrix , with its first column , @xmath412^{t}$ ] , given by @xmath413 thus",
    ", the sequence @xmath414 corresponds to the samples @xmath415 to @xmath416 of those resulting from the complete convolution @xmath417 , even when the filter @xmath0 is iir , where @xmath418 denotes the time - reversed ( perhaps infinitely large ) response @xmath419 .",
    "consequently , using the grenander and szeg s theorem  @xcite , it holds that @xmath420 where @xmath421 is the discrete - time fourier transform of @xmath422 .    in order to finish the proof",
    ", we divide   by @xmath4 , take the limit as @xmath150 , and replace   in the latter .",
    "in this section we obtain a simpler proof of a result by gray , hashimoto and arimoto  @xcite , which compares the rate distortion function ( rdf ) of a non - stationary auto - regressive gaussian process @xmath423 ( of a certain class ) to that of a corresponding stationary version , under mse distortion .",
    "our proof is based upon the ideas developed in the previous sections , and extends the class of non - stationary sources for which the results in  @xcite are valid .    to be more precise , let @xmath424 and @xmath425 be the impulse responses of two linear time - invariant filters @xmath426 and @xmath427 with rational transfer functions @xmath428 where @xmath429 , @xmath430 . from these definitions",
    "it is clear that @xmath176 is unstable , @xmath431 is stable , and @xmath432 notice also that @xmath433 and @xmath434 , and thus @xmath435    consider the non - stationary random sequences ( source ) @xmath423 and the asymptotically stationary source @xmath436 generated by passing a stationary gaussian process @xmath437 through @xmath176 and @xmath431 , respectively , which can be written as @xmath438 ( a block - diagram associated with the construction of @xmath70 is presented in fig .  [",
    "fig : rdfns ] . )    define the rate - distortion functions for these two sources as @xmath439 where , for each @xmath4 , the minimums are taken over all the conditional probability density functions @xmath440 and @xmath441 yielding @xmath442 and @xmath443 , respectively .",
    "the above rate - distortion functions have been characterized in  @xcite for the case in which @xmath437 is an i.i.d .",
    "gaussian process .",
    "in particular , it is explicitly stated in  @xcite that , for that case , @xmath444 we will next provide an alternative and simpler proof of this result , and extend its validity for general ( not - necessarily stationary ) gaussian @xmath437 , using the entropy gain properties of non - minimum phase filters established in section  [ sec : entropy_gain_output_disturb ] . indeed , the approach in  @xcite is based upon asymptotically - equivalent toeplitz matrices in terms of the signals covariance matrices .",
    "this restricts @xmath437 to be gaussian and i.i.d . and",
    "@xmath176 to be an all - pole unstable transfer function , and then , the only non - stationary allowed is that arising from unstable poles .",
    "for instance , a cyclo - stationarity innovation followed by an unstable filter @xmath176 would yield a source which can not be treated using gray and hashimoto s approach .",
    "by contrast , the reasoning behind our proof lets @xmath241 be any gaussian process , and then let the source be @xmath445 , with @xmath176 having unstable poles ( and possibly zeros and stable poles as well ) .",
    "the statement is as follows :    [ thm : rdf_non_stat ] let @xmath437 be any gaussian stationary process with bounded differential entropy rate , and let @xmath423 and @xmath436 be as defined in   and  , respectively",
    ". then   holds .",
    "thanks to the ideas developed in the previous sections , it is possible to give an intuitive outline of the proof of this theorem ( given in the appendix , page  ) by using a sequence of block diagrams .",
    "more precisely , consider the diagrams shown in fig .",
    "[ fig : rdfnsproof ] .    in the top diagram in this figure ,",
    "suppose that @xmath446 realizes the rdf for the non - stationary source @xmath70 .",
    "the sequence @xmath447 is independent of @xmath71 , and the linear filter @xmath448 is such that the error @xmath449 ( a necessary condition for minimum mse optimality ) .",
    "the filter @xmath450 is the blaschke product of @xmath176 ( see   in the appendix ) ( a stable , nmp filter with unit frequency response magnitude such that @xmath451 ) .",
    "if one now moves the filter @xmath450 towards the source , then the middle diagram in fig .",
    "[ fig : rdfnsproof ] is obtained . by doing this , the stationary source @xmath452 appears with an additive error signal @xmath453 that has the same asymptotic variance as @xmath447 , reconstructed as @xmath454 . from the invertibility of @xmath450",
    ", it also follows that the mutual information rate between @xmath452 and @xmath455 equals that between @xmath70 and @xmath456 .",
    "thus , the channel @xmath457 has the same rate and distortion as the channel @xmath458 .",
    "however , if one now adds a short disturbance @xmath459 to the error signal @xmath453 ( as depicted in the bottom diagram of fig .  [ fig : rdfnsproof ] ) , then the resulting additive error term @xmath460 will be independent of @xmath452 and will have the same asymptotic variance as @xmath453 .",
    "however , the differential entropy rate of @xmath461 will exceed that of @xmath453 by the rhs of  .",
    "this will make the mutual information rate between @xmath452 and @xmath462 to be less than that between @xmath452 and @xmath455 by the same amount .",
    "hence , @xmath463 be at most @xmath464 .",
    "a similar reasoning can be followed to prove that @xmath465 .      here",
    "we revisit the setup shown in fig .",
    "[ fig : fbksystem ] and discussed in section  [ sec : intro ] .",
    "recall from   that , for this general class of networked control systems , it was shown in  ( * ? ? ?",
    "* lemma 3.2 ) that @xmath466 where @xmath467 are the poles of @xmath238 ( the plant in fig .",
    "[ fig : fbksystem ] ) .    by using the results obtained in section  [ sec : entropy_gain_initial_stat ] we show next that equality holds in   provided the feedback channel satisfies the following assumption :    [ assu : fbck_channel ] the feedback channel in fig .",
    "[ fig : fbksystem ] can be written as @xmath468 where    1 .",
    "@xmath426 and @xmath469 are stable rational transfer functions such that @xmath470 is biproper , @xmath471 has the same unstable poles as @xmath35 , and the feedback @xmath470 stabilizes the plant @xmath35 .",
    "@xmath318 is any ( possibly non - linear ) operator such that @xmath472 satisfies @xmath473 , for all @xmath23 , and 3 .",
    "@xmath474 .",
    "an illustration of the class of feedback channels satisfying this assumption is depicted on top of fig .",
    "[ fig : fbkplant ] .",
    "trivial examples of channels satisfying assumption 5 are a gaussian additive channel preceded and followed by linear operators  @xcite .",
    "indeed , when @xmath318 is an lti system with a strictly causal transfer function , the feedback channel that satisfies assumption  [ assu : fbck_channel ] is widely known as a _ noise shaper with input pre and post filter _ , used in , e.g.  @xcite .",
    "[ thm : equality_in_martins ] in the networked control system of fig .",
    "[ fig : fbksystem ] , suppose that the feedback channel satisfies assumption  [ assu : fbck_channel ] and that the input @xmath48 is entropy balanced .",
    "if the random initial state of the plant @xmath238 , with poles @xmath475 , satisfies @xmath42 , then @xmath476    let @xmath477 and @xmath478 .",
    "then , from lemma  [ lem : initial_states ] ( in the appendix ) , the output @xmath479 can be written as @xmath480 where @xmath481 is the initial state of @xmath482 and @xmath483 ( see fig .  [",
    "fig : fbkplant ] bottom ) . then @xmath484   )   \\\\ &   =   h(\\boldsymbol{\\lambda}_{n } [ \\tilde{\\bg}_{n}\\tilde{\\rveu}^{1}_{n } + \\tilde{\\bc}_{n}\\rves_{0 } + \\bar{\\bc}_{n}\\rvex_{0 } ] + \\bc_{n}\\rvex_{0 } ) -    h(\\boldsymbol{\\lambda}_{n } [ \\tilde{\\bg}_{n}\\tilde{\\rveu}^{1}_{n } + \\tilde{\\bc}_{n}\\rves_{0 } ] )   \\\\ &   =   h(\\boldsymbol{\\lambda}_{n } [ \\tilde{\\bg}_{n}\\tilde{\\rveu}^{1}_{n } + \\tilde{\\bc}_{n}\\rves_{0 } + \\bar{\\bc}_{n}\\rvex_{0 } ] + \\bc_{n}\\rvex_{0 } ) -      h(\\tilde{\\bg}_{n}\\tilde{\\rveu}^{1}_{n } + \\tilde{\\bc}_{n}\\rves_{0 }   ) ,   \\label{eq : i_as_h}\\end{aligned}\\ ] ] where @xmath485 maps the initial state @xmath481 to @xmath135 , @xmath486 maps the initial state @xmath38 to the output of @xmath487 , and @xmath488 maps the initial state @xmath38 ( of @xmath489 ) to @xmath135 . since @xmath48 is entropy balanced and @xmath490 has finite entropy rate , it follows from lemma  [ lem : sum_yields_entropy_balanced ] that @xmath154 is entropy balanced as well",
    "thus , we can proceed as in the proof of theorem  [ thm : eg - due - to - random - xo ] to conclude that @xmath491 this completes the proof .",
    "consider a non - white additive gaussian channel of the form @xmath492 where the input @xmath70 is subject to the power constraint @xmath493 and @xmath86 is a stationary gaussian process .",
    "the feedback information capacity of this channel is realized by a gaussian input @xmath70 , and is given by @xmath494 where @xmath495 is the covariance matrix of @xmath496 and , for every @xmath497 , the input @xmath498 is allowed to depend upon the channel outputs @xmath499 ( since there exists a causal , noise - less feedback channel with one - step delay ) .    in  @xcite",
    ", it was shown that if @xmath500 is an auto - regressive moving - average process of @xmath60-th order , then @xmath501 can be achieved by the scheme shown in fig .",
    "[ fig : kim_fbk_cap_system ] . in this system , @xmath469 is a strictly causal and stable finite - order filter and @xmath173 is gaussian with @xmath502 for all @xmath503 and such that @xmath265 is gaussian with a positive - definite covariance matrix @xmath504 .",
    "here we use the ideas developed in section  [ sec : entropy_gain_output_disturb ] to show that * the information rate achieved by the capacity - achieving scheme proposed in  @xcite drops to zero if there exists any additive disturbance of length at least @xmath60 and finite differential entropy affecting the output , no matter how small*.    to see this , notice that , in this case , and for all @xmath505 , @xmath506 since @xmath507 . from theorem",
    "[ thm : eg_n_instate_w_disturb ] , this gap between differential entropies is precisely the entropy gain introduced by @xmath508 to an input @xmath138 when the output is affected by the disturbance @xmath509 .",
    "thus , from theorem  [ thm : eg_n_instate_w_disturb ] , the capacity of this scheme will correspond to @xmath510 , where @xmath511 are the zeros of @xmath512 , which is precisely the result stated in  ( * ? ? ?",
    "* theorem 4.1 ) .    however , if the output is now affected by an additive disturbance @xmath513 not passing through @xmath450 such that @xmath514 , @xmath515 and @xmath516 , with @xmath517 , then we will have @xmath518 in this case , @xmath519 but @xmath520 which follows directly from applying theorem  [ thm : eg_n_instate_w_disturb ] to each of the differential entropies .",
    "notice that this result holds irrespective of how small the power of the disturbance may be .",
    "thus , the capacity - achieving scheme proposed in  @xcite ( and further studied in  @xcite ) , although of groundbreaking theoretical importance , would yield zero rate in any practical situation , since every real signal is unavoidably affected by some amount of noise .",
    "this paper has provided a geometrical insight and rigorous results for characterizing the increase in differential entropy rate ( referred to as entropy gain ) introduced by passing an input random sequence through a discrete - time linear time - invariant ( lti ) filter @xmath13 such that the first sample of its impulse response has unit magnitude .",
    "our time - domain analysis allowed us to explain and establish under what conditions the entropy gain coincides with what was predicted by shannon , who followed a frequency - domain approach to a related problem in his seminal 1948 paper . in particular , we demonstrated that the entropy gain arises only if @xmath13 has zeros outside the unit circle ( i.e. , it is non - minimum phase , ( nmp ) ) .",
    "this is not sufficient , nonetheless , since letting the input and output be @xmath447 and @xmath521 , the difference @xmath522 is zero for all @xmath4 , yielding no entropy gain .",
    "however , if the distribution of the input process @xmath447 satisfies a certain regularity condition ( defined as being `` entropy balanced '' ) and the output has the form @xmath523 , with @xmath500 being an output disturbance with bounded differential entropy , we have shown that the entropy gain can range from zero to the sum of the logarithm of the magnitudes of the nmp zeros of @xmath13 , depending on how @xmath500 is distributed .",
    "a similar result is obtained if , instead of an output disturbance , we let @xmath13 have a random initial state .",
    "we also considered the difference between the differential entropy rate of the _ entire _ ( and longer ) output of @xmath13 and that of its input , i.e. , @xmath524 , where @xmath525 is the length of the impulse response of @xmath13 .",
    "for this purpose , we introduced the notion of `` effective differential entropy '' , which can be applied to a random sequence whose support has dimensionality smaller than its dimension .",
    "interestingly , the effective differential entropy gain in this case , which is intrinsic to @xmath13 , is also the sum of the logarithm of the magnitudes of the nmp zeros of @xmath13 , without the need to add disturbances or a random initial state .",
    "we have illustrated some of the implications of these ideas in three problems .",
    "specifically , we used the fundamental results here obtained to provide a simpler and more general proof to characterize the rate - distortion function for gaussian non - stationary sources and mse distortion .",
    "then , we applied our results to provide sufficient conditions for equality in an information inequality of significant importance in networked control problems .",
    "finally , we showed that the information rate of the capacity - achieving scheme proposed in  @xcite for the autoregressive gaussian channel with feedback drops to zero in the presence of any additive disturbance in the channel input or output of sufficient ( finite ) length , no matter how small it may be .",
    "let @xmath526 be the per - sample variance of @xmath48 , thus @xmath527 .",
    "let @xmath528 .",
    "then @xmath529 , where @xmath530 is the @xmath531 identity matrix . as a consequence , @xmath532/2)\\log(2\\pi\\expo{}\\sigsq_{\\rvau})$ ] , and thus @xmath533 .",
    "let @xmath534 be the intervals ( bins ) in @xmath535 where the sample pdf is constant .",
    "let @xmath536 be the probabilities of these bins .",
    "define the discrete random process @xmath37 , where @xmath537 if and only if @xmath538 .",
    "let @xmath539 where @xmath540 has orthonormal rows .",
    "then @xmath541 where the inequality is due to the fact that @xmath28 and @xmath542 are deterministic functions of @xmath28 , and hence @xmath543 .",
    "subtracting @xmath544 from   we obtain @xmath545 hence , @xmath546 where the last equality follows from lemma  [ lem : entropy_bounded_different_supports ] ( see appendix  [ subsec : technical_lemmas ] ) whose conditions are met because , given @xmath547 , the sequence @xmath28 has independent entries each of them distributed uniformly over a possibly different interval with bounded and positive measure .",
    "the opposite inequality is obtained by following the same steps as in the proof of lemma  [ lem : entropy_bounded_different_supports ] , from   onwards , which completes the proof .",
    "let @xmath548^{t}\\rvew^{1}_{n}$ ] , where @xmath549^{t}\\in\\rl^{n\\times n}$ ] is a unitary matrix and where @xmath550 and @xmath540 have orthonormal rows .",
    "then @xmath551 we can lower bound @xmath552 as follows : @xmath553 substituting this result into  , dividing by @xmath4 and taking the limit as @xmath150 , and recalling that , since @xmath48 is entropy balanced , then @xmath554 , lead us to @xmath555 .    the opposite bound over @xmath552 can be obtained from @xmath556 where @xmath557 is a jointly gaussian sequence with the same second - order moment as @xmath558 .",
    "therefore , @xmath559 , with @xmath560 being the variance of the sample @xmath561 . the fact that @xmath558 has a bounded second moment at each entry @xmath561 , and replacing the latter inequality in  , satisfy @xmath562 , which finishes the proof .",
    "let @xmath563^{t}\\rvew^{1}_{n}$ ] where @xmath564^{t}\\in\\rl^{n\\times n}$ ] is a unitary matrix and where @xmath550 and @xmath540 have orthonormal rows .",
    "since @xmath565 , we have that @xmath566 let @xmath567 be the svd of @xmath568 , where @xmath569 is an orthogonal matrix , @xmath570 has orthonormal rows and @xmath571 is a diagonal matrix with the singular values of @xmath572 . hence @xmath573 it is straightforward to show that the diagonal entries in @xmath574 are lower and upper bounded by the smallest and largest singular values of @xmath114 , say @xmath575 and @xmath576 , respectively , which yields @xmath577 but from lemma  [ lem : singular_values_bounded ] , @xmath578 , and thus @xmath579 where the last equality is due to the fact that @xmath48 is entropy balanced .",
    "this completes the proof .",
    "the fact that @xmath580 is upper bounded follows directly from the fact that @xmath176 is a stable transfer function . on the other hand , @xmath581 is positive definite ( with all its eigenvalues equal to @xmath96 ) , and so @xmath582 is positive definite as well , with @xmath583 .",
    "suppose that @xmath584 .",
    "if this were true , then it would hold that @xmath585 .",
    "but @xmath586 is the lower triangular toeplitz matrix associated with @xmath587 , which is stable ( since @xmath176 is minimum phase ) , implying that @xmath588 , thus leading to a contradiction .",
    "this completes the proof .",
    "[ proof : lem_gap_with_two_terms ] since @xmath140 is unitary , we have that @xmath589 where @xmath590 applying the chain rule of differential entropy , we get @xmath591 notice that @xmath592^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\rvez^{1}_{n}$ ] . thus , it only remains to determine the limit of @xmath593 as @xmath150 .",
    "we will do this by deriving a lower and an upper bound for this differential entropy and show that these bounds converge to the same expression as @xmath150 .",
    "to lower bound @xmath593 we proceed as follows @xmath594 where @xmath595 follows from including @xmath596 ( or @xmath597 as well ) to the conditioning set , while @xmath598 and @xmath599 stem from the independence between @xmath243 and @xmath600 .",
    "inequality @xmath601 is a consequence of @xmath602 , and @xmath603 follows from including @xmath604 to the conditioning set in the second term , and noting that @xmath605 is not reduced upon the knowledge of @xmath606 .    on the other hand , @xmath607^{1}_{m}\\br_{n}\\rveu^{1}_{n } )",
    "=    \\sumfromto{i=1}{m}\\log d_{n , i }   +    h([\\br_{n}]^{1}_{m}\\rveu^{1}_{n } ) , \\label{eq : arowana}\\end{aligned}\\ ] ] then , by inserting   and   in  , dividing by @xmath4 , and taking the limit @xmath150 , we obtain @xmath608^{1}_{m}\\rveu^{1}_{n } )    \\right )   \\\\ &   =   \\bar{h}(\\rvau_{1}^{\\infty } )   -   \\lim_{n\\to\\infty}\\frac{1}{n}\\sumfromto{i=1}{m}\\log d_{n , i } , \\label{eq : the_lower_bound}\\end{aligned}\\ ] ] where the last equality is a consequence of the fact that @xmath48 is entropy balanced .",
    "we now derive an upper bound for @xmath593 . defining the random vector @xmath609^{m+1}_{n}\\rveu^{1}_{n},\\ ] ]",
    "we can write @xmath262^{m+1}_{n } \\br_{n}\\rveu^{1}_{n } =   { { ^{m+1}\\![\\bd_{n}]_{n}}}\\rvex^{m+1}_{n}\\end{aligned}\\ ] ] where @xmath610_{n}}}\\eq \\diag\\set{d_{n , m+1},d_{n , m+2},\\ldots , d_{n , n } } .\\end{aligned}\\ ] ] therefore , @xmath611_{n}}}\\rvex^{m+1}_{n } + \\bar{\\rvez}^{m+1}_{n } ) \\\\ & = \\log\\det({{^{m+1}\\![\\bd_{n}]_{n } } } ) + h(\\rvex^{m+1}_{n } + ( { { ^{m+1}\\![\\bd_{n}]_{n}}})^{-1}\\bar{\\rvez}^{m+1}_{n } ) .\\label{eq : agnus_dei}\\end{aligned}\\ ] ] notice that by assumption  [ assu : z ] , @xmath612^{m+1}_{n}\\rvez^{1}_{n } = [ \\bq_{n}]^{m+1}_{n}[{\\boldsymbol{\\phi}}]^{1}_{n}\\rves^{1}_{\\kappa}$ ] , and thus is restricted to the span of @xmath187^{m+1}_{n}[{\\boldsymbol{\\phi}}]^{1}_{n}$ ] of dimension @xmath613 , for all @xmath614 .",
    "then , for @xmath615 , one can construct a unitary matrix @xmath616 , such that the rows of @xmath617 span the space spanned by the columns of @xmath618_{n}}})^{-1}[\\bq_{n}]^{m+1}_{n}[{\\boldsymbol{\\phi}}]^{1}_{n}$ ] and such that @xmath619_{n}}})^{-1}[\\bq_{n}]^{m+1}_{n}[{\\boldsymbol{\\phi}}]^{1}_{n}=0 $ ] .",
    "therefore , from  , @xmath620_{n } } } ) + h(\\bh_n\\rvex^{m+1}_{n } + \\bh_n({{^{m+1}\\![\\bd_{n}]_{n}}})^{-1}\\bar{\\rvez}^{m+1}_{n } ) \\nonumber \\\\ & =   \\log\\det({{^{m+1}\\![\\bd_{n}]_{n } } } ) + h(\\bb_{n}\\rvex^{m+1}_{n } ) + h(\\ba_{n}\\rvex^{m+1}_{n } + \\ba_{n}({{^{m+1}\\![\\bd_{n}]_{n}}})^{-1}\\bar{\\rvez}^{m+1}_{n}|\\bb_{n}\\rvex^{m+1}_{n } ) \\nonumber \\\\ & \\leq \\log\\det({{^{m+1}\\![\\bd_{n}]_{n } } } ) + h(\\bb_{n}\\rvex^{m+1}_{n } ) + h(\\ba_{n}\\rvex^{m+1}_{n } + \\ba_{n}({{^{m+1}\\![\\bd_{n}]_{n}}})^{-1}\\bar{\\rvez}^{m+1}_{n } ) \\nonumber \\\\ & \\leq   \\log\\det({{^{m+1}\\![\\bd_{n}]_{n } } } ) + h(\\bb_{n}\\rvex^{m+1}_{n } ) + \\frac{1}{2}\\log\\left(2\\pi\\expo { } \\det\\left(\\bk_{\\ba_n\\rvex^{m+1}_n } + \\bk_{\\ba_n({}^{m+1 }                          [ \\bd_n]_n)^{-1}\\bar{\\rvez}^{m+1}_n}\\right)\\right ) \\nonumber \\\\ & \\leq   \\log\\det({{^{m+1}\\![\\bd_{n}]_{n } } } ) + h(\\bb_{n}\\rvex^{m+1}_{n } ) \\nonumber + \\frac{1}{2}\\log\\left(2\\pi\\expo { }   \\left [ \\lambda_{\\max}(\\bk_{\\rvex^{m+1}_{n } } ) +    \\frac{\\lambda_{\\max}(\\bk_{\\bar{\\rvez}^{m+1}_{n}})}{\\lambda_{\\min}({{^{m+1}\\![\\bd_{n}]_{n}}})^{2 } } \\right]^{\\kappa_{n } } \\right)\\label{eq : laultima}\\end{aligned}\\ ] ] where @xmath621 and @xmath622_n)^{-1}\\bar{\\rvez}^{m+1}_n}$ ] are the covariance matrices of @xmath623 and @xmath624_n)^{-1}\\bar{\\rvez}^{m+1}_n$ ] , respectively , and where the last inequality follows from  @xcite .",
    "the fact that @xmath625 and @xmath626 are bounded and remain bounded away from zero for all @xmath4 , and the fact that @xmath627_{n}}})$ ] either grows with @xmath4 or decreases sub - exponentially ( since the @xmath142 first singular values decay exponentially to zero , with @xmath628 ) , imply in   that @xmath629_{n } } } ) +   \\lim_{n\\to\\infty}\\frac{1}{n }     h(\\bb_{n}\\rvex^{m+1}_{n}).\\end{aligned}\\ ] ] but the fact that @xmath630 implies that @xmath631_{n}}})=-\\sumfromto{i=1}{m}\\log d_{n , i}$ ] .",
    "this , together with the assumption that @xmath48 is entropy balanced yields @xmath632 which coincides with the lower bound found in  , completing the proof .",
    "[ proof : lem_hashimoto_iir ] the transfer function @xmath13 can be factored as @xmath633 , where @xmath487 is stable and minimum phase and @xmath290 is stable with all the non - minimum phase zeros of @xmath13 , both being biproper rational functions . from lemma  [ lem : singular_values_bounded ] , in the limit as @xmath150 ,",
    "the eigenvalues of @xmath634 are lower and upper bounded by @xmath635 and @xmath636 , respectively , where @xmath637 .",
    "let @xmath638 and @xmath639 be the svds of @xmath640 and @xmath641 , respectively , with @xmath642 and @xmath261 being the diagonal entries of the diagonal matrices @xmath643 , @xmath644 , respectively",
    ". then @xmath645 denoting the @xmath73-th row of @xmath152 by @xmath646 be , we have that , from the courant - fischer theorem  @xcite that @xmath647 likewise , @xmath648 thus @xmath649 the result now follows directly from lemma  [ lem : hashimoto ] ( in the appendix ) .",
    "[ proof : thm_eg_n_instate_w_disturb_ineq ] in this case @xmath262^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\rvez^{1}_{n }     &   =   [ \\bd_{n}]^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n}\\rves^{1}_{\\kappa}.\\end{aligned}\\ ] ] notice that the columns of the matrix @xmath187^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n}\\in\\rl^{m\\times \\kappa}$ ] span a space of dimension @xmath650 , which means that one can have @xmath187^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n}=\\bzero$ ] ( if @xmath651 ) . in this case",
    "( i.e. , if @xmath652^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n}=\\bzero$ ] ) then the lower bound is reached by inserting the latter expression into   and invoking lemma  [ lem : hashimoto_iir ] .",
    "we now consider the case in which @xmath652^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n}\\neq \\bzero$ ] .",
    "this condition implies that there exists an @xmath242 sufficiently large such that @xmath653 for all @xmath654 .",
    "then , for all @xmath654 there exist unitary matrices @xmath655 where @xmath656 and @xmath657 have orthonormal rows , such that @xmath314^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n }   =   \\begin{pmatrix }    \\ba_{n}[\\bq_{n}]^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n }    \\\\    \\bzero   \\end{pmatrix } , \\fspace n\\geq n.\\end{aligned}\\ ] ] thus @xmath284^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m}\\rvez^{1}_{n } \\right )    &   =   h\\left([\\bd_{n}]^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n}\\rves^{1}_{\\kappa}\\right )   \\\\ &   = h\\left(\\bh_{n}([\\bd_{n}]^{1}_{m}\\br_{n}\\rveu^{1}_{n } + [ \\bq_{n}]^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n}\\rves^{1}_{\\kappa})\\right )   \\\\ &   =   h\\left (   \\ba_{n}[\\bd_{n}]^{1}_{m}\\br_{n}\\rveu^{1}_{n }    + \\ba_{n}[\\bq_{n}]^{1}_{m } [ { \\boldsymbol{\\phi}}]^{1}_{n}\\rves^{1}_{\\kappa } \\ , |\\ ,   \\overline{\\ba}_{n}[\\bd_{n}]^{1}_{m}\\br_{n}\\rveu^{1}_{n}\\right)\\nonumber   \\\\ &   \\fspace\\fspace\\fspace\\fspace\\fspace\\fspace\\fspace\\fspace\\fspace\\fspace\\fspace\\fspace   \\fspace\\fspace\\fspace\\fspace   +   h(\\overline{\\ba}_{n}[\\bd_{n}]^{1}_{m}\\br_{n}\\rveu^{1}_{n})\\label{eq : la100}.   \\end{aligned}\\ ] ] the first differential entropy on the rhs of the latter expression is uniformly upper - bounded because @xmath48 is entropy balanced , @xmath285^{1}_{m}$ ] has decaying entries , and @xmath658 . for the last differential entropy , notice that @xmath659^{1}_{m}\\br_{n } = { { ^{1}\\![\\bd_{n}]_{m } } } { [ \\br_{n}]^{1}_{m } } $ ] .",
    "consider the svd @xmath660_{m } } } { [ \\br_{n}]^{1}_{m } } = \\bv_{n}^{t}{\\boldsymbol{\\sigma}}_{n}\\bw_{n}$ ] , with @xmath661 being unitary , @xmath662 being diagonal , and @xmath663 having orthonormal rows .",
    "we can then conclude that @xmath664^{1}_{m}\\br_{n}\\rveu^{1}_{n } ) =   h({\\boldsymbol{\\sigma}}_{n}\\bw_{n}\\rveu^{1}_{n } )   =   \\log\\abs{\\det({\\boldsymbol{\\sigma}}_{n } ) } + h(\\bw_{n}\\rveu^{1}_{n } ) .\\label{eq : maldealturas}\\end{aligned}\\ ] ] now , the fact that @xmath665_{m } } } { [ \\br_{n}]^{1}_{m}}(\\overline{\\ba}_{n}{{^{1}\\![\\bd_{n}]_{m } } } { [ \\br_{n}]^{1}_{m}})^{t }   =    \\overline{\\ba}_{n}{{^{1}\\![\\bd_{n}]_{m}}}{{^{1}\\![\\bd_{n}]_{m } } } \\overline{\\ba}_{n}^{t }    =    \\bv^{t}{\\boldsymbol{\\sigma}}\\bw\\bw^{t}{\\boldsymbol{\\sigma}}^{t}\\bv    =    \\bv^{t}{\\boldsymbol{\\sigma}}{\\boldsymbol{\\sigma}}^{t}\\bv\\end{aligned}\\ ] ] allows one to conclude that @xmath666_{m}}})^{2}\\overline{\\ba}_{n}^{t})| .",
    "\\end{aligned}\\ ] ] recalling that @xmath667^{\\kappa_{n}+1}_{m}}$ ] and that @xmath668 is unitary , it is easy to show ( by using the cauchy interlacing theorem  @xcite ) that @xmath669_{m}}})^{2}\\overline{\\ba}_{n}^{t } ) }   \\leq   \\sumfromto{i=\\kappa_{n}+1}{m}\\log d_{n , i},\\end{aligned}\\ ] ] with equality achieved if and only if @xmath670 $ ] . substituting this into   and then the latter into   we arrive to @xmath671^{1}_{m}\\br_{n}\\rveu^{1}_{n } )    \\leq     h ( [ \\bw_{n}]^{1}_{m}\\rveu^{1}_{n } )    +    \\sum_{i=\\kappa_{n}+1}^{m}\\log d_{n , i}. \\end{aligned}\\ ] ] substituting this into  , exploiting the fact that @xmath672 is entropy balanced and invoking lemma  [ lem : hashimoto_iir ] yields the upper bound in  .",
    "clearly , this upper bound is achieved if , for example , @xmath673^{1}_{\\bar{\\kappa } } } { [ { \\boldsymbol{\\phi}}]^{1}_{n}}({[\\bq_{n}]^{1}_{\\bar{\\kappa } } } { [ { \\boldsymbol{\\phi}}]^{1}_{n}})^{t}$ ] is non - singular for all @xmath4 sufficiently large , since , in that case , @xmath674 and we can choose @xmath675 $ ] and @xmath676 $ ] .",
    "this completes the proof .",
    "[ proof : thm : eg_n_instate_w_disturb ] as in  , the transfer function @xmath13 can be factored as @xmath633 , where @xmath487 is stable and minimum phase and @xmath290 is a stable fir transfer function with all the non - minimum - phase zeros of @xmath13 ( @xmath142 in total ) .",
    "letting @xmath677 , we have that @xmath678 , @xmath679 , and that @xmath680 is entropy balanced ( from lemma  [ lem : filtering_preserves_entropy_balance ] ) .",
    "thus , @xmath681 this means that the entropy gain of @xmath114 due to the output disturbance @xmath86 corresponds to the entropy gain of @xmath641 due to the same output disturbance .",
    "one can then evaluate the entropy gain of @xmath114 by applying theorem  [ thm : eg_n_instate_w_disturb_ineq ] to the filter @xmath290 instead of @xmath13 , which we do next .",
    "since only the first @xmath142 values of @xmath86 are non zero , it follows that in this case @xmath682^{t}$ ] ( see assumption  [ assu : z ] ) .",
    "therefore , @xmath683^{1}_{m}}{[{\\boldsymbol{\\phi}}]^{1}_{n}}({[\\bq_{n}]^{1}_{m}}{[{\\boldsymbol{\\phi}}]^{1}_{n}})^{t } )   =   \\det({{^{1}\\![\\bq_{n}]_{m}}}({{^{1}\\![\\bq_{n}]_{m}}})^{t})$ ] and the sufficient condition given in theorem  [ thm : eg_n_instate_w_disturb_ineq ] will be satisfied for @xmath684 if @xmath685_{m}}})|>0 $ ] , where now @xmath686 is the left unitary matrix in the svd @xmath687 .",
    "we will prove that this is the case by using a contradiction argument .",
    "thus , suppose the contrary , i.e. , that @xmath688_{m}}}=0.\\end{aligned}\\ ] ] then , there exists a sequence of unit - norm vectors @xmath689 , with @xmath690 for all @xmath4 , such that @xmath691_{m } } } } = 0\\end{aligned}\\ ] ] for each @xmath23 , define the @xmath4-length image vectors @xmath692^{1}_{m}}$ ] , and decompose them as @xmath693 such that @xmath694 and @xmath695 .",
    "then , from this definition and from  , we have that      as a consequence , @xmath697_{m } } } { [ \\bq_{n}]^{1}_{m } }   \\bt_{n}},\\end{aligned}\\ ] ] where the last equality follows from the fact that , by construction , @xmath698 is in the span of the first @xmath142 rows of @xmath140 , together with the fact that @xmath140 is unitary ( which implies that @xmath673^{m+1}_{n}}\\bt_{n}=\\bzero$ ] ) . since the top @xmath142 entries in @xmath644 decay exponentially as @xmath4 increases , we have that @xmath699 where @xmath700 is a finite - order polynomial of @xmath4 ( from lemma  [ lem : hashimoto ] , in the appendix ) .",
    "but @xmath701^{1}_{m})^{t}\\balpha_{n } + ( [ \\bf_{n}]^{m+1}_{n})^{t}\\bbeta_{n } }    \\\\ &    \\geq   \\norm{([\\bf_{n}]^{m+1}_{n})^{t}\\bbeta_{n } } -      \\norm { ( [ \\bf_{n}]^{1}_{m})^{t}\\balpha_{n } }       \\\\ &      \\geq      \\sigma_{min } ( ( [ \\bf_{n}]^{m+1}_{n})^{t } ) \\norm{\\bbeta_{n } }     -     \\sigma_{max}(([\\bf_{n}]^{1}_{m})^{t } )     \\norm { \\balpha_{n}}\\end{aligned}\\ ] ] taking the limit as @xmath150 , @xmath702^{m+1}_{n})^{t } ) \\right )      \\left(\\lim_{n\\to\\infty } \\norm{\\bbeta_{n}}\\right )     -     \\sigma_{\\text{max}}(([\\bf_{n}]^{1}_{m})^{t } )     \\left(\\lim_{n\\to\\infty } \\norm { \\balpha_{n}}\\right )     \\\\ &     = \\lim_{n\\to\\infty}\\sigma_\\text{min } ( ( [ \\bf_{n}]^{m+1}_{n})^{t } ) \\label{eq : limitalone}\\end{aligned}\\ ] ] where we have applied   and the fact that @xmath703^{1}_{m})^{t})$ ] is bounded and does not depend on @xmath4 . now , notice that @xmath704^{m+1}_{n } } ( { [ \\bf_{n}]^{m+1}_{n}})^{t } $ ] is a toeplitz matrix with the convolution of @xmath705 and @xmath706 ( the impulse response of @xmath318 and its time - reversed version , respectively ) on its first row and column .",
    "it then follows from  ( * ? ? ?",
    "* lemma  4.1 ) that @xmath707^{m+1}_{n}}({[\\bf_{n}]^{m+1}_{n}})^{t } ) =    \\min_{\\w:\\w\\in\\pipi } |f\\ejw|^{2 }   > 0\\end{aligned}\\ ] ] ( the inequality is strict because all the zeros of @xmath290 are strictly outside the unit disk ) . substituting this into   we conclude that @xmath708^{m+1}_{n } } ) ^{t } )   > 0,\\end{aligned}\\ ] ] which contradicts  .",
    "therefore ,   leads to a contradiction , completing the proof .",
    "[ proof : rdf_non_stat ] denote the blaschke product  @xcite of @xmath176 as @xmath709 which clearly satisfies @xmath710 where @xmath711 is the first sample in the impulse response of @xmath450 .",
    "notice that   implies that @xmath712 for every sequence of random variables @xmath48 with uniformly bounded variance . since @xmath450 has only stable poles and its zeros coincide exactly with the poles of @xmath176 , it follows that @xmath713 is a stable transfer function .",
    "thus , the asymptotically stationary process @xmath436 defined in   can be constructed as @xmath714 where @xmath715 is a toeplitz lower triangular matrix with its main diagonal entries equal to @xmath711 .      for any given @xmath717 , suppose that @xmath448 is chosen and @xmath496 and @xmath28 are distributed so as to minimize @xmath718 subject to the constraint @xmath719 ( i.e. , @xmath720 is a realization of @xmath721 ) , yielding the reconstruction @xmath722 since we are considering mean - squared error distortion , it follows that , for rate - distortion optimality , @xmath28 must be jointly gaussian with @xmath496 . from these vectors ,",
    "define @xmath723 where @xmath724 is a zero - mean gaussian vector independent of @xmath725 with finite differential entropy such that @xmath514 , @xmath726 .",
    "then , we have that . ]",
    "@xmath727    -    n\\gsp     \\right )    \\\\ &       \\overset{(e)}{= }    h(\\tilde{\\rvey}^{1}_{n } )     -    h(\\tilde{\\rveu}^{1}_{n}+\\rved^{1}_{n}|\\tilde{\\rvex}^{1}_{n } )    +    n\\gsp     -[h(\\rveu^{1}_{n})-h(\\tilde{\\rveu}^{1}_{n}+\\rved^{1}_{n } ) ] \\\\ &       \\overset{(f)}{= }    h(\\tilde{\\rvey}^{1}_{n } )     -    h(\\bar{\\rvey}^{1}_{n}|\\bar{\\rvex}^{1}_{n } )    +    n\\gsp     -[h(\\rveu^{1}_{n})-h(\\tilde{\\rveu}^{1}_{n}+\\rved^{1}_{n } ) ]    \\\\ &      =      h(\\tilde{\\rvey}^{1}_{n } )      -      h(\\bar{\\rvey}^{1}_{n } )    +        i(\\tilde{\\rvex}^{1}_{n};\\bar{\\rvey}^{1}_{n } )    +    n\\gsp     -    [ h(\\rveu^{1}_{n})-h(\\tilde{\\rveu}^{1}_{n}+\\rved^{1}_{n } ) ]    \\\\ &    \\overset{\\hphantom{(a)}}{\\geq }      i(\\tilde{\\rvex}^{1}_{n};\\bar{\\rvey}^{1}_{n } )    +    n\\gsp     -    [ h(\\rveu^{1}_{n})-h(\\tilde{\\rveu}^{1}_{n}+\\rved^{1}_{n } ) ] ,    \\end{aligned}\\ ] ] where @xmath595 follows from @xmath715 being invertible , @xmath598 is due to the fact that @xmath728 , @xmath601 holds because @xmath729 .",
    "the equality @xmath599 stems from @xmath730 ( see  ) .",
    "equality holds in @xmath603 because @xmath731 and in @xmath732 because of  .",
    "the last inequality holds because @xmath733 and @xmath734 .",
    "but from theorem  [ thm : eg_n_instate_w_disturb ] , @xmath735 , and thus @xmath736 .    at the same time , the distortion for the source @xmath737 when reconstructed as @xmath738 is @xmath739 where @xmath595 holds because @xmath740 is bounded , and @xmath598 is due to the fact that , in the limit , @xmath450 is a unitary operator . recalling the definitions of @xmath741 and @xmath741 ,",
    "we conclude that @xmath742 , and therefore @xmath743 in order to complete the proof , it suffices to show that @xmath744 . for this purpose , consider now the ( asymptotically ) stationary source @xmath737 , and suppose that @xmath745 realizes @xmath746 .",
    "again , @xmath737 and @xmath28 will be jointly gaussian , satisfying @xmath747 ( the latter condition is required for minimum mse optimality ) . from this , one can propose an alternative realization in which the error sequence is @xmath748 , yielding an output @xmath749 with @xmath750 .",
    "then @xmath751 where @xmath595 follows by recalling that @xmath745 and because @xmath752 , @xmath598 stems from  , @xmath601 is a consequence of @xmath753 , @xmath599 follows from the fact that @xmath754 .",
    "finally , @xmath603 holds because @xmath715 is invertible for all @xmath4 . since",
    ", asymptotically as @xmath150 , the distortion yielded by @xmath135 for the non - stationary source @xmath496 is the same which is obtained when @xmath737 is reconstructed as @xmath755 ( recall  ) , we conclude that @xmath744 , completing the proof .",
    "[ lem : entropy_bounded_different_supports ] let @xmath48 be a random process with independent elements , and where each element @xmath171 is uniformly distributed over possible different intervals @xmath756 $ ] , such that @xmath757 , for some positive and bounded @xmath758 . then @xmath48 is entropy balanced .    without loss of generality",
    ", we can assume that @xmath759 , for all @xmath73 ( otherwise , we could scale the input by @xmath760 , which would scale the output by the same proportion , increasing the input entropy by @xmath761 and the output entropy by @xmath762 , without changing the result ) .",
    "the input vector @xmath28 is confined to an @xmath4-box @xmath763 ( the support of @xmath764 ) of volume @xmath765 and has entropy @xmath766 .",
    "this support is an @xmath4-box which contains @xmath767 @xmath768-boxes of different @xmath768-volume .",
    "each of these @xmath768-boxes is determined by fixing @xmath769 entries in @xmath28 to @xmath770 , and letting the remaining @xmath768 entries sweep freely over @xmath756 $ ] .",
    "thus , the @xmath768-volume of each @xmath768-box is the product of the @xmath768 support sizes @xmath771 of the associated selected free - sweeping entries . but",
    "recalling that @xmath759 for all @xmath73 , the volume of each @xmath768-box can be upper bounded by @xmath772 . with this , the added volume of all the @xmath768-boxes contained in the original @xmath4-box can be upper bounded as @xmath773 we now use this result to upper bound the entropy rate of @xmath542 .",
    "let @xmath563^{t}\\rveu^{1}_{n}$ ] where @xmath774^{t}\\in\\rl^{n\\times n}$ ] is a unitary matrix and where @xmath550 and @xmath540 have orthonormal rows . from this definition",
    ", @xmath542 will distribute over a finite region @xmath775 , corresponding to the projection onto the @xmath768-dimensional span of the rows of @xmath776 .",
    "hence , @xmath777 is upper bounded by the entropy of a uniformly distributed vector over the same support , i.e. , by @xmath778 , where @xmath779 is the @xmath780-dimensional volume of this support . in turn",
    ", @xmath779 is upper bounded by the sum of the volume of all @xmath781-dimensional boxes contained in the @xmath4-box in which @xmath28 is confined , which we already denoted by @xmath782 , and which is upper bounded as in  .",
    "therefore , @xmath783 dividing by @xmath4 and taking the limit as @xmath150 yields @xmath784    on the other hand , @xmath785 where @xmath595 follows because @xmath564^{t}$ ] is an orthogonal matrix .",
    "letting @xmath786 correspond to the jointly gaussian sequence with the same second - order moments as @xmath787 , and recalling that the gaussian distribution maximizes differential entropy for a given covariance , we obtain the upper bound @xmath788 where @xmath595 follows since the @xmath789 are independent , and @xmath598 stems from the fact that @xmath550 has orthonormal rows and from the courant - fischer theorem  @xcite .",
    "since @xmath790 is bounded for all @xmath4 , we obtain by substituting   into   that @xmath791 . the combination of this with   yields @xmath792 , completing the proof .",
    "[ lem : hashimoto ] let the function @xmath793 be as defined in   but for a transfer function @xmath13 with no poles and having only a finite number of zeros , @xmath142 of which lie outside the unit circle . then , @xmath226 where the elements in the sequence @xmath227 are positive and increase or decrease at most polynomially with @xmath4 .",
    "[ lem : initial_states ] let @xmath794 be rational transfer function of order @xmath219 with relative degree 1 , with initial state @xmath795 .",
    "let @xmath796 be a biproper rational transfer function of order @xmath797 with initial state @xmath798 .",
    "let @xmath799 where @xmath800 is an exogenous signal .",
    "then @xmath801 where the initial state of @xmath802 is @xmath803 and the initial state of @xmath804 can be taken to be @xmath805 $ ] .",
    "let @xmath806 and @xmath807 .",
    "define the following variables : @xmath808 then the recursion corresponding to @xmath238 is @xmath809 this reveals that the initial state of @xmath238 corresponds to @xmath810.\\end{aligned}\\ ] ] let @xmath811 and @xmath812 .",
    "then @xmath813 can be written as @xmath814 which reveals that the initial state of @xmath482 can be taken to be @xmath815.\\end{aligned}\\ ] ] since @xmath816 , it follows that @xmath817 combining the above recursions , it is found that @xmath818 is related to the input @xmath800 by the following recursion : @xmath819 which corresponds to @xmath820 $ } }   u}^{x}.\\end{aligned}\\ ] ]                          n.  martins and m.  dahleh , `` feedback control in the presence of noisy channels : `` bode - like '' fundamental limitations of performance , '' _ ieee trans .",
    "53 , no .  7 ,",
    "16041615 , aug .",
    "2008 .",
    "e.  i. silva , m.  s. derpich , and j.  stergaard , `` a framework for control system design subject to average data - rate constraints , '' _ ieee trans .",
    "56 , no .  8 , pp . 18861899 , june 2011",
    ".      s.  yksel , `` characterization of information channels for asymptotic mean stationarity and stochastic stability of nonstationary / unstable linear systems , '' _ ieee transactions on information theory _ , vol .",
    "58 , no .",
    "10 , pp . 63326354 , oct ."
  ],
  "abstract_text": [
    "<S> we study the increase in per - sample differential entropy rate of random sequences and processes after being passed through a non minimum - phase ( nmp ) discrete - time , linear time - invariant ( lti ) filter @xmath0 . for lti discrete - time filters and random processes </S>",
    "<S> , it has long been established that this entropy gain , @xmath1 , equals the integral of @xmath2 . </S>",
    "<S> it is also known that , if the first sample of the impulse response of @xmath0 has unit - magnitude , then the latter integral equals the sum of the logarithm of the magnitudes of the non - minimum phase zeros of @xmath0 ( i.e. , its zeros outside the unit circle ) , say @xmath3 . </S>",
    "<S> these existing results have been derived in the frequency domain as well as in the time domain . in this note , we begin by showing that existing time - domain proofs , which consider finite length-@xmath4 sequences and then let @xmath4 tend to infinity , have neglected significant mathematical terms and , therefore , are inaccurate . </S>",
    "<S> we discuss some of the implications of this oversight when considering random processes . </S>",
    "<S> we then present a rigorous time - domain analysis of the entropy gain of lti filters for random processes . </S>",
    "<S> in particular , we show that the entropy gain between equal - length input and output sequences is upper bounded by @xmath3 and arises if and only if there exists an output additive disturbance with finite differential entropy ( no matter how small ) or a random initial state . </S>",
    "<S> unlike what happens with linear maps , the entropy gain in this case depends on the distribution of all the signals involved . instead , when comparing the input differential entropy to that of the entire ( longer ) output of @xmath0 , the entropy gain equals @xmath3 irrespective of the distributions and without the need for additional exogenous random signals . </S>",
    "<S> we illustrate some of the consequences of these results by presenting their implications in three different problems . specifically : a simple derivation of the rate - distortion function for gaussian non - stationary sources , conditions for equality in an information inequality of importance in networked control problems , and an observation on the capacity of auto - regressive gaussian channels with feedback . </S>"
  ]
}