{
  "article_text": [
    "let @xmath1 be a topological oriented @xmath2-sphere .",
    "the branched coverings @xmath3 considered in this article are all orientation preserving .",
    "let @xmath4 be a finite subset of @xmath1 with @xmath5 . in  @xcite",
    ", hurwitz describes an elegant classification of branched coverings @xmath3 with critical values contained in @xmath6 in terms of _ admissible _ @xmath0-tuples of permutations @xmath7 .",
    "a @xmath0-tuple is admissible if :    * the permutations @xmath8 generate a transitive subgroup of @xmath9 , * @xmath10 and * the cycle lengths satisfy the condition @xmath11    see   [ ss : hurwitz ] for more details regarding the classification .",
    "it is easy , using a computer algebra system such as gap  @xcite , to enumerate all admissible @xmath0-tuples of permutations ; it is an altogether different problem to _ construct _ an analytic model of a covering associated to a given admissible @xmath0-tuple of permutations .",
    "the purpose of this note is to describe such an algorithm and its implementation .",
    "two branched coverings @xmath12 and @xmath13 are equivalent if there is an orientation preserving homeomorphism @xmath14 such that @xmath15 .",
    "hurwitz s result is a classification of equivalence classes of coverings in this sense .",
    "choose a basepoint @xmath16 .",
    "for each @xmath17 , choose a path @xmath18 joining @xmath19 to @xmath20 in @xmath21 , in such a way that    * the paths @xmath18 intersect only at @xmath19 , * the paths @xmath22 are ordered cyclically counterclockwise around @xmath19 .",
    "the fundamental group @xmath23 is generated by paths @xmath24 that follow @xmath18 , wind once counterclockwise around @xmath20 , and return to @xmath19 along @xmath18 .",
    "it has the presentation @xmath25    let @xmath26 be a covering branched over @xmath6 .",
    "number @xmath27 the @xmath28-preimages of @xmath19 .",
    "then , for each @xmath17 and each @xmath29 , the path @xmath30 lifts to a path starting at @xmath31 and ending at @xmath32 for some @xmath33 .",
    "this defines a permutation @xmath34 for each @xmath17 .",
    "note that the @xmath0-tuple @xmath8 is admissible :    * since @xmath35 is connected , the group @xmath36 is transitive on @xmath37 ; * since @xmath38 , we have that @xmath39 ; * computing the euler characteristic of @xmath35 via the riemann - hurwitz formula yields  .",
    "conversely , let @xmath8 be an admissible @xmath0-tuple of permutations .",
    "define a branched covering as follows : start with @xmath40 disjoint copies of @xmath1 , cut open along the paths @xmath18 . if @xmath41 , glue the right boundary of @xmath18 on @xmath42-th sphere to the left boundary of @xmath18 on the @xmath43-th sphere .",
    "this defines a covering with critical values contained in @xmath6 .",
    "it is connected because @xmath36 is transitive on @xmath37 .",
    "the euler characteristic of the cover is @xmath2 , because of   and the riemann - hurwitz formula ; so it is a sphere .    the @xmath0-tuple @xmath8 must be considered up to diagonal conjugation by @xmath9 , which amounts to numbering the spheres differently . the constructions above then define a bijection between equivalence classes of branched coverings and equivalence classes of appropriate @xmath0-tuples of permutations .",
    "a coarser equivalence relation on coverings has also been considered , but is not the main focus of this article : two coverings @xmath44 are _ hurwitz equivalent _ if there exist homeomorphisms @xmath45 with @xmath46 .",
    "hurwitz classes of coverings may also be classified by @xmath0-tuples of permutations ; namely , by the orbits on appropriate @xmath0-tuples of the symmetric group @xmath9 ( acting as above ) and the pure braid group on @xmath0 strings . the latter group s generators act by conjugating , for any two consecutive points @xmath47 in @xmath6 , the permutations @xmath34 and @xmath48 by @xmath49 .",
    "this amounts to changing the `` spider '' @xmath50 by twisting the legs @xmath18 and @xmath51 around each other .",
    "assume now @xmath52 and that @xmath53 is a covering map .",
    "then , @xmath28 defines holomorphic charts on @xmath35 and it is not difficult to see that the points in @xmath54 are removable singularities : we denote by @xmath55 the corresponding riemann surface . by the uniformization theorem , there is a conformal homeomorphism @xmath56 .",
    "the map @xmath57 is a holomorphic branched covering , i.e. , a rational map .",
    "assume @xmath58 for some homeomorphism @xmath14 .",
    "let @xmath59 be a conformal homeomorphism and set @xmath60 be the corresponding rational map .",
    "then , @xmath61 is a mbius transformation and @xmath62 .",
    "therefore , up to precomposition by a mbius transformation , the rational map @xmath63 only depends on the equivalence class of covering @xmath64 .",
    "we say that @xmath28 is an _",
    "analytic model_.      our algorithm is an important step in the more difficult problem of determining an analytic model with given dynamics .",
    "we start by recalling some definitions .",
    "the _ post - critical set _ of a branched self - covering @xmath12 with critical value set @xmath65 is @xmath66 we are interested in the case where @xmath67 is finite and we consider @xmath28 up to isotopy rel @xmath67 ; namely , we that that @xmath28 and @xmath68 are _ combinatorially equivalent _ , and write @xmath69 , if there exists a path of branched self - coverings from @xmath28 to @xmath68 whose post - critical set moves smoothly .",
    "the dynamical problem alluded to above asks to determine , given a branched covering @xmath70 with finite post - critical set , whether there exists a rational map that is combinatorially equivalent to @xmath28 , and in that case to exhibit such a rational map .    a fundamental theorem of thurston ( see  @xcite and theorem  [ thm : thurston ] below ) proves ( except in few well - understood , low - complexity cases ) that such a branched covering @xmath28 is combinatorially equivalent to at most one rational map , up to conjugation by a mbius transformation ; furthermore , if @xmath71 , then it has precisely one holomorphic realization .    in case @xmath28 is a _ topological polynomial _ ( it has a fixed point of maximal ramification ) , the dynamics of @xmath28 may be described by combinatorial data called `` external rays '' , see  @xcite .",
    "an implementation , when @xmath28 has only two critical values , is described in  @xcite , and is called the `` spider algorithm '' ; see also  @xcite treating the general degree-@xmath2 case . in a forthcoming paper",
    ", the first author will describe the implementation of the general case .",
    "if @xmath71 , then we may assume @xmath72 , @xmath73 and @xmath74 within @xmath75 .",
    "furthermore , precomposing @xmath28 by an appropriate mbius transformation , we may also assume that @xmath76 .",
    "in the polynomial case , pilgrim linked in  @xcite the `` dessin denfant '' ( the full preimage of the segment @xmath77 $ ] ) of @xmath28 with a dynamical invariant , its `` hubbard tree '' .    we describe in section  [ sec : cui ] a question by cui in the theory of holomorphic dynamical systems , and give an explicit holomorphic realization of a topological map he constructed",
    ".    this will also be our running example in the text . with @xmath72 , @xmath73 and @xmath74 ,",
    "the permutations representing the map are @xmath78 recall that the cycles of the above permutations correspond to preimages of critical values .",
    "we seek a degree-@xmath79 rational map @xmath28 such that the cycle @xmath80 and its image under @xmath28 are located at @xmath81 , and similarly for the other two cycles and images .    in this specific example , the search can be made more feasible as follows .",
    "setting all critical points as unknowns and eliminating is out of the question . with a little faith",
    "that the symmetry between @xmath82 translates to @xmath28 , let @xmath83 be the rotation permuting @xmath82 , and note that @xmath84 is a sphere , branched at the two fixed points of @xmath85 .",
    "if @xmath28 descends to a map @xmath68 on @xmath84 , then ( after change of variables ) it has the form @xmath86 for degree-@xmath87 polynomials , such that @xmath88 at @xmath89 , and such that @xmath90 is the image of four other points with local degrees @xmath91 respectively .",
    "we are grateful to noam elkies and curt mcmullen for having pointed out to us the feasibility of this approach .",
    "nevertheless , we will show that our algorithm is strong enough to produce a solution even without exploiting the symmetry of the hurwitz data .      if @xmath92 , then there is a unique solution represented , up to diagonal conjugation , by the pair of permutations @xmath93 if @xmath72 and @xmath73 , an analytic model is @xmath94 .",
    "however , the case @xmath71 seems already as complicated as the general case , and has only been addressed in the literature for small @xmath40 .",
    "such maps are often called `` dessins denfant '' , see  @xcite ; the corresponding combinatorial objects for the modular surface @xmath95 are called `` conway diagrams '' , see  @xcite*3.4",
    ". methods of constructing them are addressed , _",
    "inter alia _ , in  @xcite .    in this section , we consider the case @xmath96 which can completely be solved .",
    "if @xmath92 , then as we said above we may choose @xmath97 and @xmath94 . if @xmath98 then we may choose @xmath99 . without loss of generality , we may assume that all points of @xmath6 are branched values , since otherwise we are reduced to the case @xmath92 .",
    "up to permutation of the points in @xmath6 and the indices , the only possible triple of permutations is @xmath100 to find an analytic model , we seek a rational map @xmath28 of degree @xmath101 such that @xmath102 this implies @xmath103 as the only realization .    the next case we consider is @xmath104 and @xmath105 . using mbius transformations , we may normalise @xmath6 to be @xmath106 . up to conjugation in @xmath107",
    "we may take the first permutations to be @xmath108 .",
    "the condition that the permutations generate a transitive group imply that one of them is not @xmath109 . up to conjugation",
    ", we may assume that the first permutation which is not @xmath109 is @xmath110 . since @xmath111 , this gives four possibilities , namely , writing @xmath112 ,    2 & = ( ( 1,2),(1,2),(2,3),(2,3 ) ) , & & = ( ( 1,2),(2,3),(1,2),(1,3 ) ) , + & = ( ( 1,2),(2,3),(1,3),(2,3 ) ) , & & = ( ( 1,2),(2,3),(2,3),(1,2 ) ) .    to find the corresponding @xmath28 ,",
    "assume without loss of generality that @xmath28 maps @xmath113 , @xmath114 , @xmath115 and @xmath116 .",
    "this forces the map @xmath28 to have the form @xmath117 for some parameter @xmath118 subject to @xmath119 ; then @xmath120 .",
    "since @xmath121 , the equation defining @xmath118 in terms of @xmath122 has four distinct roots , leading to four candidate maps @xmath123 . there is a bijection between the maps @xmath28 and the triples of permutations above , but no canonical one  it will depend on the specific choice of @xmath124 generators @xmath24 of @xmath125 .",
    "note also that these four solutions are part of a single hurwitz class .",
    "various methods have already been considered for the computation of branched coverings , at least under some restrictions on the data .",
    "note , first , that a head - on approach , solving numerically the equations after having converted them to a grbner basis , works only for the most simple examples , and in particular is completely unrealistic for the degree-13 example described in   [ ss : dynamics ] .    in case @xmath126 and @xmath127 , the covering",
    "is called a _ belyi map _ ;",
    "if furthermore @xmath128 is a @xmath40-cycle , then the covering is called a _",
    "belyi polynomial_. the explicit construction of belyi maps has been addressed by numerous authors .",
    "couveignes and granboulan describe in  @xcite a method based on writing puiseux series for the solution , after having made initial guesses on the positions of the roots ; they obtain in this manner very high - precision approximations of the cofficients of the map , which allow the determination of their minimal field of definition ( they credit the idea to oesterl ) .",
    "matiyasevich conducted in  @xcite some experiments , and showed that belyi polynomials can be efficiently computed by an iterative process , increasing the polynomial degree and adjusting the critical values by newton s method .",
    "the idea is to iteratively deform the polynomial @xmath129 so as to obtain arbitrary critical values .",
    "a much more efficient approach has been developed recently by marshall and rohde  @xcite , and is based on the zipping algorithm  @xcite . zipping is much faster , and lets one construct belyi maps of very high degree . in particular , marshall and rohde managed to describe all belyi polynomials of degree @xmath130 .",
    "they have been able to reproduce the computations in this article using their method .",
    "we are given a list @xmath131 of permutations in @xmath132 with product @xmath133 , and points @xmath134 .",
    "let @xmath135 be the cycle lengths of @xmath34 ; we have @xmath136 for all @xmath137 , and @xmath138 .",
    "in the first part of the algorithm , we enumerate all rational maps with critical values @xmath139 such that the multiplicities of the preimages of @xmath20 are @xmath140 .",
    "in the second part , we select the appropriate rational map among these candidates .",
    "the approach in the first part of the algorithm seems to originate in malle  @xcite ; see also  @xcite .    for the sake of describing its workflow more clearly",
    ", the actual algorithm ( described in the remainder of the text ) has been slightly simplified .",
    "normalization : :    without loss of generality , we assume @xmath72 ,    @xmath73 and @xmath74 .",
    "we approximate the other    @xmath20 by    @xmath141",
    ".    the rational map we seek will leave @xmath142 fixed .    using this normalization ,",
    "if all @xmath20 are algebraic then    the cofficients of the map will also be algebraic .",
    "finite field solution : :    we pick a prime @xmath143 , such that the points    @xmath144 have distinct realizations    @xmath145 .",
    "we then list all    degree-@xmath40 rational maps @xmath146 over    @xmath147 with poles and zeroes of multiplicities    @xmath148 and @xmath149 respectively , and by    brute force check for each @xmath146 whether    @xmath150 has zeroes of multiplicities    @xmath151 for all @xmath152 .",
    "note that the    rational map @xmath146 is a solution to our original    problem over @xmath147 .",
    "( if there are no    solutions , we restart with a different prime @xmath143 ) .",
    "@xmath143-adic solution : :    write @xmath153 with @xmath154 monic of degree    @xmath40 , and @xmath155 of degree less than    @xmath40 .",
    "( in fact , we later write the denominator as    @xmath156 with @xmath157 monic .",
    "the present    discussion uses a simplified notation . ) for @xmath158 , let    @xmath159 be the numerator of    @xmath150 .",
    "we compute high - precision    @xmath143-adic approximations @xmath160 of the    @xmath144 , and lift each @xmath161    from @xmath147 to a high - precision polynomial    @xmath162 over @xmath163 , in such a    manner that we have @xmath164 for large @xmath165 .",
    "this    lifting can be done by hensel s lemma , because by    corollary  [ cor : buff ] , the jacobian of the system    @xmath166 is invertible at a solution for    almost every prime @xmath143 .",
    "( if @xmath167    happens not to be invertible , we restart with a different prime ) .",
    "algebraic solution : :    using the lattice - reduction algorithm lll  @xcite , we find polynomials    @xmath168 over @xmath169 , with    cofficients of small height ( small degree and cofficients of minimal    polynomial ) that are close to @xmath162 obtained at the    previous step .",
    "using exact arithmetic over    @xmath169 , we check that the solution    @xmath170 is correct .",
    "( if not , we either compute a finer    @xmath143-adic approximation , or higher - degree algebraic number    approximations , or we restart altogether with a larger prime ) .",
    "complex solution : :    for each cofficient    @xmath171 of    @xmath168 , given by its minimal polynomial over    @xmath172 , we compute ( to high , user - specified precision ) all    the roots @xmath173 of its minimal polynomial , as    floating - point complex numbers .",
    "not all choices of    @xmath173 are compatible : there may exist some    extra constraints between one cofficient and another ( such as , for    example , that they are complex conjugates of each other ) .",
    "we determine    these extra constraints as follows : we choose small , random integers    @xmath174 , compute the minimal polynomial of @xmath175 , and compute ( again to high precision ) its    roots @xmath176 .",
    "we then pair together    those roots @xmath177 for    which @xmath178 for    some @xmath179 . by considering enough of these pairs",
    "we can    stitch together a collection of compatible cofficient approximations    @xmath173 embracing all @xmath180 .",
    "+    we call @xmath181 the collection of all cofficients    @xmath182 , and note that the rational map is determined by its    zeroes , its poles , and the normalization condition that    @xmath183 is fixed . since    @xmath184 , these zeroes and poles are    determined by @xmath181 .    the second step of the algorithm checks , by path lifting , that the monodromy around @xmath20 is correct . for each of the galois conjugate solutions",
    "@xmath185 obtained in the first step , we do the following :    triangulate : :    we are given a floating - point approximation @xmath186    of @xmath6 .",
    "we compute a triangulation    @xmath187 of    @xmath75 whose vertex set contains    @xmath186 , and a triangulation    @xmath188 of    @xmath75 whose vertex set contains    @xmath181 . for efficiency reasons , we use _",
    "delaunay    triangulations _ , see   [ ss : mono ] .",
    "we compute the dual triangulation    @xmath189 ; it has one vertex per face of    @xmath187 , and edges transverse to those of    @xmath187 .",
    "we fix a vertex    @xmath190 as our basepoint .",
    "lift the triangulation : :    let @xmath191 denote the vertices of @xmath192 . for each @xmath193 , we number arbitrarily    @xmath194 the @xmath195-preimages    of @xmath122 .    +    for each edge @xmath196 , going from    @xmath197 to @xmath198 , we compute a permutation    @xmath199 such that the    @xmath195-lift of @xmath200 starting    at @xmath201 ends at    @xmath202 .",
    "there are two strategies    for this , one is by subdividing appropriately the path    @xmath200 and playing `` connect - the - dots '' , the other    uses more efficiently the triangulation @xmath188 .",
    "read permutations : :    for each critical value @xmath203 , let    @xmath204 be the sequences of    edges traversed by a path in @xmath189 that    starts and ends in the basepoint @xmath19 , and surrounds once    counterclockwise the point @xmath20 and no other vertex of    @xmath6 .",
    "compute the permutation    @xmath205 .",
    "check : :    the data @xmath206 are a valid solution to the hurwitz    problem if and only if there exists a permutation    @xmath207 such that    @xmath208 .",
    "the fourth - named author has implemented the first part of the algorithm , mainly in c , and the first - named author has implemented the second part of the algorithm , mainly in gap  @xcite . by far the most time - consuming part of the procedure is the search for a solution over a finite field .",
    "example  [ ex : search ] required approximately 15 minutes on a desktop , 30-specint2006 computer .",
    "the code is maintained by the fourth - named author , and is available at @xmath209",
    "we show , in this section , that ( as soon as the prime @xmath143 is sufficiently large ) we may lift every @xmath147-solution to @xmath163 .",
    "this follows from the well known fact that the hurwitz spaces are smooth .",
    "we could not find the precise statement we need in the literature , so we give a complete proof .",
    "let @xmath210 be an integer and denote by @xmath211 the space of rational maps of degree @xmath40 , which may be identified with a zariski open subset of @xmath212 .",
    "let @xmath213 be an integer and let @xmath214 be a ramified covering branched over @xmath215 .",
    "note that , according to the riemann - hurwitz formula , @xmath216 contains exactly @xmath217 points .",
    "we write @xmath218 with @xmath219 , and for each @xmath220 we let @xmath221 be the local degree of @xmath63 at @xmath222 .",
    "let @xmath223 be the smooth quasiprojective variety of injective maps @xmath224 . for @xmath225",
    ", we use the notation @xmath226 .",
    "similarly , let @xmath227 be the smooth quasiprojective variety of injective maps @xmath228 . for @xmath229",
    ", we use the notation @xmath230 .",
    "the quasiprojective variety @xmath231 is smooth .",
    "we shall prove that the subvariety @xmath232 is also smooth , and regularly parametrised :    [ prop : buff ] the variety @xmath233 is smooth of dimension @xmath234 , locally regularly parametrised by @xmath235 .",
    "observe that , for @xmath236 , there is a unique rational map @xmath237 such that @xmath238 and @xmath239 for all @xmath240 . indeed , knowing a rational map above three points completely determines the rational map ( it is even enough to know the full preimage of two points plus one preimage of a third point ) .",
    "note that the group of mbius transformations acts on @xmath227 and @xmath223 by postcomposition : @xmath241 the quotient space may be identified with @xmath242 with @xmath243 and @xmath244 the projection @xmath245 is a submersion .",
    "the action preserves @xmath233 as indicated on the following commutative diagram : @xmath246^{\\mathfrak c}\\dto_f & { { \\mathbb p^1}}({{\\mathbb c}})\\dto^f \\rto^m & { { \\mathbb p^1}}({{\\mathbb c}})\\dto^{n\\circ f\\circ m^{-1 } } \\\\ q\\ar@{^{(}->}[r]^{\\mathfrak q } & { { \\mathbb p^1}}({{\\mathbb c } } ) \\rto^n & { { \\mathbb p^1}}({{\\mathbb c } } ) .",
    "\\enddiagram\\ ] ] it is therefore enough to show that @xmath247 is a smooth subvariety of @xmath248 locally regularly parametrised by @xmath249 .",
    "we first write equations for @xmath250 . to each @xmath251 , we associate a collection of monic polynomials @xmath252 defined by @xmath253 and a collection of rational maps @xmath254 defined by @xmath255 note that these are degree-@xmath40 rational maps with poles of order @xmath256 at @xmath257 . in addition , @xmath258 maps @xmath259 to @xmath260 with local degree @xmath221 .",
    "it follows that @xmath261 if and only if there is a @xmath262 such that @xmath263 for all @xmath264 , that is , @xmath265 with @xmath266 in that case , we use the notation @xmath267    in other words , consider the map @xmath268_{\\deg < d})^{k-2}.\\ ] ] then , @xmath269 if and only if there is a @xmath270 such that @xmath271",
    ".    according to the following lemma and the implicit function theorem , the subvariety of @xmath272 defined by the equation @xmath273 is smooth of dimension @xmath274 , locally regularly parametrised by @xmath249 .",
    "it follows that its projection to the @xmath248 component , namely @xmath250 , is also smooth of dimension @xmath274 , locally regularly parametrised by @xmath249 .",
    "[ lemma : implicit ] if @xmath275 , then the derivative @xmath276 restricts to an isomorphism @xmath277_{\\deg < d})^{k-2}$ ] .",
    "we postpone the proof of the lemma to section  [ sec : prooflemma ] and mention immediately a corollary that we shall use later . for @xmath278 ,",
    "let @xmath279_{\\deg < d})^{k-2}$ ] be defined by @xmath280    [ cor : buff ] assume that @xmath281 is defined over @xmath169 with @xmath282 .",
    "then , for almost every prime @xmath143 , the derivative @xmath283 at @xmath284 is invertible mod @xmath143 .    since the point @xmath281",
    "is defined over @xmath169 , its cordinates may be written using algebraic integers , and reduced mod @xmath143 .",
    "for all except finitely many values of @xmath143 , the resulting reduction gives a genuine point , namely where the reductions of @xmath285 are injective and the reduction of @xmath286 has degree @xmath40 . since @xmath287 is invertible over @xmath169 , it may be written as @xmath288 for a matrix @xmath118 with algebraic integer entries and @xmath289 ; then the reduction modulo @xmath143 of @xmath287 is invertible for all primes not dividing @xmath165 .    before embarking in the proof of the lemma",
    ", we first build up a description of the tangent space of @xmath211 .      consider a rational map @xmath237 . a tangent vector to @xmath28",
    "is @xmath290 for a holomorphic family of rational maps @xmath291 with @xmath292 .    for every @xmath293 ,",
    "the vector @xmath294 is a tangent vector in @xmath75 at @xmath295 ; in other words , @xmath296 is a section of the pullback bundle @xmath297 .",
    "it can be pulled back to a vector field on @xmath75 , as @xmath298 or , in cordinates , @xmath299 .",
    "therefore , @xmath300 is a meromorphic vector field on @xmath75 , holomorphic away from critical points of @xmath28 , and with a pole of order at most @xmath42 at critical points of multiplicity @xmath42 .",
    "geometrically , @xmath300 is the movement at time @xmath301 of the point @xmath302 .",
    "this point @xmath303 can be followed away from critical points , by the implicit function theorem .",
    "we consider now local perturbations of @xmath28 at a critical point , i.e.we assume that the vector field @xmath296 is given by a path @xmath304 with @xmath305 analytic perturbations of the identity at the critical value and point @xmath306 respectively of @xmath28 .",
    "let @xmath307 denote the critical point of @xmath303 and let @xmath308 denote its critical value ; then @xmath309 and @xmath310 .",
    "let @xmath311 denote the motion vector of @xmath307 , and let @xmath312 denote the motion vector of @xmath308 . then @xmath313 and @xmath314 .",
    "now @xmath315 , because @xmath316 .",
    "therefore , @xmath317 at @xmath318 , the vector field @xmath319 takes value @xmath312 , the vector field @xmath320 is holomorphic at @xmath321 , and its constant term is @xmath311 . if @xmath322 , then @xmath323 is holomorphic near @xmath321 and vanishes at @xmath321 .    therefore , whenever we have a family of rational maps @xmath324 for which we can follow a critical point @xmath307 and its associated critical value @xmath308 with @xmath322 , the vector field @xmath325 is holomorphic near @xmath321 and coincides with @xmath311 at @xmath321 .",
    "for @xmath326 , we have @xmath327 recall that if @xmath328 , then @xmath263 for all @xmath264 .",
    "we denote by @xmath28 this common rational map of degree @xmath40 .",
    "if in addition@xmath329 belongs to the kernel of @xmath287 at @xmath330 , then @xmath331 so @xmath332 for all @xmath264 .",
    "we denote by @xmath296 this common tangent vector to @xmath211 at @xmath28 and by @xmath325 the corresponding meromorphic vector field on @xmath75 .",
    "as @xmath281 varies in @xmath333 , the @xmath258-preimages of the points @xmath334 and @xmath260 vary holomorphically : they are the points @xmath257 and @xmath259 . according to the previous remark",
    ", we see that if @xmath335 then , for all @xmath336 , the meromorphic vector field @xmath325 is holomorphic near @xmath257 , coincides with @xmath337 at @xmath257 , and furthermore is holomorphic near @xmath259 and coincides with @xmath338 at @xmath259 .",
    "thus , @xmath325 is a holomorphic vector field on the whole sphere @xmath75 and coincides with @xmath338 at @xmath259 . in particular",
    ", it vanishes at @xmath339 , @xmath340 and @xmath341 . a holomorphic vector field with at least @xmath101 zeroes globally vanishes .",
    "therefore , @xmath342 and @xmath343 for all @xmath240 .",
    "in addition , for all @xmath344 , we have that @xmath345 and for all @xmath326 , we have that @xmath346 this shows that @xmath347 .",
    "let us summarize : if @xmath348 and if @xmath349 belongs to the kernel of @xmath287 at @xmath330 , then @xmath350 and @xmath351 .",
    "so , the restriction of @xmath352 to @xmath353 is injective .",
    "since @xmath354 and @xmath355_{\\deg < d})^{k-2}$ ] have the same dimension , that is @xmath356 , this restriction is an isomorphism as required .",
    "we describe in this section an efficient method of finding a rational function over a finite field with prescribed critical values and multiplicities .",
    "we start by recalling some facts about univariate polynomials over non - algebraically - closed fields @xmath357 of arbitrary characteristic . for this",
    "we need some notation :    an ordered sequence @xmath358 with @xmath359 and @xmath360 is called a _",
    "partition _ of @xmath40 . with the shorthand notation",
    "@xmath361 we can always write @xmath362 with @xmath363 and appropriate @xmath364 .",
    "for example , @xmath365 is written as @xmath366 .",
    "the partition @xmath367 defined by @xmath368 is called the _ dual partition _ of @xmath369 .",
    "for example , @xmath370 .",
    "let @xmath371 $ ] be a degree-@xmath40 polynomial , let @xmath372 $ ] be its distinct linear factors over an algebraic closure of @xmath357 , and let @xmath151 be their multiplicities , so that @xmath373 without restriction we can assume @xmath374 and @xmath358 is a partition of @xmath40 .",
    "in this situation we say that @xmath28 is of _ shape _ @xmath369 .    if we write @xmath362 as above , we can write @xmath375 with @xmath376 and @xmath258 the product of those linear forms that have multiplicity @xmath377 . in this situation",
    "the @xmath258 are coprime .",
    "[ lgcdone ] let @xmath357 be a field of characteristic @xmath143 , let @xmath378 $ ] be a univariate polynomial of shape @xmath369 and write @xmath379 with @xmath380 $ ] .",
    "if @xmath381 for all @xmath137 then @xmath382    we have @xmath383 this shows that @xmath384 divides the @xmath385 .",
    "assume now that there is another linear factor @xmath386 in the @xmath385 .",
    "since the @xmath385 divides @xmath28 there exists an index @xmath387 with @xmath388 .",
    "since the @xmath385 divides @xmath389 we have that @xmath386 divides @xmath390 now all summands except for @xmath391 are divisible by @xmath386 . since @xmath392 and @xmath393 are nonzero in @xmath357 and @xmath394 $ ] respectively , it follows that @xmath386 must divide @xmath395 .",
    "this is impossible since the @xmath396 are pairwise coprime .",
    "[ cgcdall ] with the notations of the previous lemma we have @xmath397    lemma [ lgcdone ] and induction .",
    "[ cdualshape ] with the notations above let @xmath367 be the dual partition of @xmath369 .",
    "then @xmath398    we have",
    "@xmath399 it follows that @xmath400    [ ashape ]    ' '' ''     + a polynomial @xmath401 $ ] + the shape @xmath402 of @xmath28 .",
    "write @xmath403 . for each @xmath404",
    ", compute @xmath405 . for",
    "each @xmath406 define then @xmath407 . return the dual of the partition @xmath408 .",
    "this directly follows from corollary  [ cdualshape ] .",
    "we may collect linear factors of the same multiplicity , so as to avoid field extensions :    [ crational ] with the notation of lemma [ lgcdone ] choose @xmath409 among the @xmath151 such that @xmath410 with @xmath411 . then the @xmath258 are defined over @xmath357 .",
    "since the calculation of a @xmath385 does not require field extensions , we have @xmath412.\\ ] ] by corollary [ cgcdall ] we then have @xmath413\\ ] ] so @xmath414\\cap\\bbbk(x)=\\bbbk[x].\\qedhere\\ ] ]    we are now ready to describe our algorithm searching for rational maps over @xmath147 .",
    "[ aone ]    ' '' ''     + a finite field @xmath357 , a list of points @xmath415 , an integer @xmath40 , and a list of partitions @xmath402 of @xmath40 with @xmath416 satisfying @xmath417 + all rational maps over @xmath357 of degree @xmath40 such that every @xmath418 has @xmath419 preimages with local degrees @xmath140 respectively .",
    "we choose a mbius transformation @xmath420 sending @xmath421 to @xmath81 and @xmath422 to @xmath423 .",
    "we write each partition @xmath151 in compacted form as @xmath424 .",
    "we enumerate all @xmath425-tuples of monic polynomials @xmath426 with @xmath427 , and all @xmath428-tuples of monic polynomials @xmath429 with @xmath430 .    for each such pair of tuples ,",
    "we compute @xmath431    using algorithm  [ ashape ] , we filter those @xmath432 such that the shape of @xmath157 is @xmath148 and the shape of @xmath433 is @xmath149 ( this fails only if a pair @xmath434 is not coprime ) .    by computing their g.c.d .",
    ", we filter those @xmath432 such that @xmath157 and @xmath433 are coprime .    for each @xmath435 , let @xmath436 be the set of @xmath437 such that the shape ( computed using algorithm  [ ashape ] ) of @xmath438 is @xmath151 .",
    "we filter those rational maps for which @xmath439 is non - empty .",
    "we return all the rational maps @xmath440 , for all @xmath441 , that survived the filtering .",
    "let first @xmath442 be a rational map returned by the algorithm . for @xmath443 , consider the rational map @xmath444 . by the very definition of @xmath168 ( compare with  )",
    ", we have @xmath445 .",
    "on the other hand , the @xmath258-preimages of @xmath418 are the zeroes of @xmath168 , so they have multiplicities @xmath151 .",
    "on the other hand , let @xmath28 be a rational map such that every @xmath418 has @xmath419 preimages with local degrees @xmath140 respectively .",
    "then , for every mbius transformation @xmath446 sending @xmath421 to @xmath81 and @xmath422 to @xmath423 , the rational map @xmath447 will be of the form @xmath448 , for monic polynomials @xmath449 of respective shapes @xmath450 and a scalar @xmath437 .",
    "furthermore , by corollary  [ crational ] , both @xmath157 and @xmath433 factor over @xmath451 $ ] into polynomials of degrees @xmath452 and @xmath453 respectively .",
    "the rational map @xmath454 will be of the form @xmath455 with @xmath168 of shape @xmath151 ; therefore , that solution @xmath28 will be returned by the algorithm .",
    "algorithm  [ aone ] is the most computationally - intensive part of our procedure .",
    "its performance is improved in the following ways :    1 .   if @xmath456 for some @xmath180 , then we may assume , after permuting the shapes @xmath151 , that @xmath457 so that @xmath157 contains a power of a linear factor @xmath458 .",
    "fixing the corresponding preimage of @xmath81 to be @xmath81 amounts to the choice @xmath459 , so that the degree of @xmath157 is actually @xmath460 .",
    "this speeds up the search by a factor @xmath143 .",
    "+ similarly , if up to permutation of the indices there are more @xmath461 , with @xmath462 , then the corresponding factors may be assumed to be @xmath463 and @xmath464 .",
    "+ on the other hand , if all @xmath465 , then no normalization of the critical points may be assumed , and in particular @xmath81 should not be assumed to be a preimage of some @xmath418 .",
    "2 .   when using corollary [ cdualshape ]",
    "one can detect a wrong shape already if @xmath466 or for that matter any @xmath467 with @xmath468 has the wrong degree .",
    "we stop the calculation of @xmath385 s as soon as this happens .",
    "this speeds up the process by a factor of about @xmath469 .",
    "similarly , as soon as the intersection of the @xmath470 already computed is empty , the pair @xmath432 should be discarded .",
    "3 .   if the largest @xmath471 is small enough ( e.g. @xmath472 or @xmath473 in @xmath474 ) we can enumerate all monic irreducible homogeneous polynomials of degree @xmath475 and build the @xmath258 and @xmath476 out of them , while taking care that no irreducible piece is used twice . we can then omit checking shape and coprimeness of @xmath157 and @xmath433 as these conditions are then automatically satisfied .",
    "[ ex : search ] over @xmath474 we searched for a rational map of shape @xmath477 , @xmath477 and @xmath477 ; we chose @xmath478 and @xmath479 , and did nt specify @xmath480 , letting on the contrary the algorithm determine choose it for us .",
    "we found the solution @xmath481 it has indeed the desired shape as we have the following factorisation @xmath482 which implies , for the choice @xmath483 , the value @xmath484 .",
    "the lift from @xmath147 to @xmath163 is done using hensel s lemma ( namely , newton s method in positive characteristic ) :    [ phensel ] let @xmath485 be a vector of polynomials , with @xmath486 $ ] , and let @xmath487 be the jacobian matrix of @xmath63 .",
    "assume that @xmath488 satisfies @xmath489 that @xmath490 is invertible modulo @xmath491 , and let @xmath492 be an inverse modulo @xmath491 .",
    "then @xmath493 for @xmath494 furthermore @xmath495 is invertible modulo @xmath496 .",
    "@xmath497 is divisible by @xmath491 since @xmath498 .",
    "therefore @xmath499 is well defined .",
    "we have @xmath500 the invertibility holds more generally .",
    "let @xmath501 and @xmath502 be matrices with @xmath503 .",
    "we can then write @xmath504 in this situation we have @xmath505 since @xmath503 ; so @xmath506 is an inverse to @xmath501 modulo @xmath496 .",
    "consider the following data : a ring @xmath357 ; a family of polynomials @xmath507 $ ] of degree at most @xmath40 , for @xmath508 , with factorisations @xmath509 ; a parameter @xmath510 ; and a sequence of points @xmath511 .",
    "we say that they are _ coherent _ if @xmath512 is independent of @xmath443 .",
    "we say that they are _ normalised _ if the following holds : the first three values @xmath142 are @xmath82 respectively ; and the first three preimages @xmath513 are also respectively @xmath82 .",
    "this means that we assume that @xmath157 has degree @xmath514 , that @xmath515 , and that @xmath516 .",
    "note that this assumption is not innocuous : it may well be that no critical point @xmath222 is defined over @xmath357 .",
    "the normalization may be imposed at no cost if ( after permutation of the indices ) @xmath517 .",
    "we are now ready to detail the lifting algorithm . out of coherent data in @xmath147 and a parameter @xmath165",
    ", it computes a @xmath518-approximation of the corresponding coherent data in @xmath163 , in the form of an approximation in @xmath519 .",
    "[ alift ]    ' '' ''     + coherent data @xmath520 $ ] , @xmath521 , and @xmath522 ; a parameter @xmath289 ; and lifts @xmath523 of the points @xmath418 + coherent data @xmath524 $ ] and @xmath525 that reduce mod @xmath143 to @xmath161 .",
    "first , we assume that the data may be normalised .",
    "this amounts to requiring at least three of the @xmath526 , for distinct @xmath137 s , to have a linear factor .",
    "this holds for a positive proportion of primes @xmath143 .",
    "if no such three factors exist , the algorithm aborts .",
    "otherwise , we silently replace the three corresponding @xmath527 by @xmath528 in the shapes so as to create a term with @xmath461 .",
    "we write now each @xmath526 in the form @xmath529 for unknowns @xmath530 .",
    "recall from   the expressions @xmath531 and @xmath532 .",
    "the @xmath533 are polynomials in the variables @xmath534 .",
    "we lift the cofficients of the coherent data @xmath535 to @xmath536 , to obtain an initial parameter @xmath537 .",
    "since the original data is coherent , we have @xmath538 . for almost all @xmath143 ,",
    "the jacobian @xmath287 is invertible by corollary  [ cor : buff ] ; if @xmath287 is not invertible at @xmath539 , then we abort the algorithm .",
    "otherwise , we apply repeatedly hensel s lemma  [ phensel ] to obtain a solution @xmath118 to @xmath540 .    finally , we reconstruct the polynomials @xmath526 out of their cofficients ( which are just cordinates of @xmath118 ) .",
    "the invertibility of the jacobian was expressed in corollary  [ cor : buff ] in terms of the variables @xmath222 .",
    "this does not make any difference : here we express them in terms of the @xmath541 , which are elementary symmetric functions of the @xmath222 .",
    "consider the shapes @xmath542 .",
    "our example @xmath543 gives a vector of cofficients @xmath544{c@{}c@{}c } ( & w_{1,2,1},w_{1,3,1},w_{1,3,2},w_{1,3,3 } , \\\\",
    "& w_{2,2,1},w_{2,3,1},w_{2,3,2},w_{2,3,3 } , \\\\        &",
    "w_{3,2,1},w_{3,3,1},w_{3,3,2},w_{3,3,3},&\\lambda )      \\end{array}\\\\      & = ( -5,3,2,3,\\ ; 3,-3,0,-5,\\ ; -3,-2,0,-3,\\ ; -4 )    \\end{aligned}\\ ] ] with @xmath545 .",
    "the lift is @xmath546 with @xmath547",
    ". we can continue this process inductively .",
    "notice that the precision doubles in every step .",
    "if the hurwitz problem has a solution over @xmath549 that reduces to a given solution over @xmath147 , then hensel lifting will find it after a finite number of steps .",
    "unfortunately the solutions usually involve fractional cofficients , and are usually defined over a finite extension @xmath548 of @xmath550",
    ". our first goal will therefore be to determine this extension .",
    "consider a degree-@xmath551 extension @xmath548 of the rationals , and @xmath552 .",
    "then @xmath553 are linearly dependent over @xmath550 , and therefore also over @xmath549 , i.e there exists a polynomial @xmath554 with all @xmath555 and @xmath556 .",
    "let now @xmath557 be a prime such that @xmath558 splits over @xmath163 ; so that we may view @xmath559 as a subfield of @xmath560 .",
    "assume also that @xmath118 is invertible modulo @xmath143 , so that we may consider @xmath118 as an element of @xmath163 .",
    "consider now @xmath561 ; then we have the equation @xmath562 which is linear in @xmath563 .",
    "we use the lll algorithm  @xcite to find small integer solutions to this linear equation .",
    "the default implementation uses a simple heuristic to guess the correct precision @xmath165 and the correct extension degree : for a initial precision we start with extension degree @xmath564 and increase @xmath551 until a solution is found ( i.e.  @xmath565 ) or the computed shortest lattice basis vector norm is the same for @xmath551 and @xmath566 .",
    "if the computed vector norm did not change , we increase the @xmath143-adic precision .",
    "if we have a - priori knowledge about the minimum or maximum expected extension degree , then it can be passed to the algorithm , which is more likely to find quickly a solution .",
    "the following algorithm is described as a process that , receiving as input an infinite feed of ever - more - precise approximations of a @xmath143-adic number that is known to be algebraic , produces an infinite stream of ever - more - likely minimal polynomials of that @xmath143-adic number .",
    "[ alll ]    ' '' ''     + approximations , to arbitrary precision , of an algebraic number @xmath567 + polynomials @xmath568 $ ] whose likelihood converges to @xmath90 of being the minimal polynomial of @xmath118 , as the precision of @xmath118 improves .",
    "assume that , for each @xmath569 , the algorithm may receive an approximation @xmath570 , to @xmath165 base-@xmath143 digits , of @xmath118 .",
    "the element @xmath570 is represented as an integer in @xmath571 .    start with @xmath572 and @xmath573 .",
    "then , repeat the following . consider the lattice in @xmath574 generated by the columns of the matrix @xmath575 using the lll algorithm , find a vector @xmath576 in the lattice , of small norm @xmath577 .",
    "form the polynomial @xmath578 .",
    "if @xmath579 , or if @xmath580 and @xmath581 , then output @xmath558 as a candidate polynomial . repeat then , after having incremented @xmath40 if the first case holds , and doubled @xmath165 otherwise .",
    "the algorithm repeatedly increases @xmath165 and @xmath40 .",
    "note that the polynomials returned may have degree @xmath582 , so increasing @xmath40 is harmless , and the precision is increased as soon as increase in maximal degree does not improve the solution .",
    "let @xmath583 be a short lattice vector .",
    "then this vector is @xmath584 and in particular @xmath585 . on the other hand ,",
    "the cofficients @xmath586 are small , so @xmath558 is likely to be the minimal polynomial of @xmath118 .",
    "considering our example @xmath587 we found @xmath588 and @xmath589 for @xmath590 higher precision values of @xmath591 are also zeroes of the same polynomial @xmath592 .",
    "we take this as a hint that @xmath592 is indeed the minimal polynomial of the cordinate @xmath591 in the lift of our finite field solution .",
    "having found the minimal polynomials @xmath593 $ ] for all cordinates @xmath541 of our solution vector , we determine the field @xmath548 on which they are all defined , as the compositum of all field extensions defined by the @xmath594 . if these field extensions were independent , then we should just consider all zeroes in @xmath595 of the @xmath594 and return the corresponding rational functions .",
    "however , in general , the field extensions will be highly dependent . to simplify notation ,",
    "let us assume that all @xmath594 are of degree @xmath551 , and that @xmath548 itself is a degree-@xmath551 extension .",
    "then there are @xmath551 possible values for each cordinate . at this stage",
    "we do not know how to combine these single cordinate solutions to a solution vector ( there are @xmath596 possible combinations ) .",
    "to solve this problem we use the following method .    to illustrate our method , consider @xmath597 and let @xmath598 $ ] be minimal polynomials of @xmath599 respectively .",
    "assume furthermore that @xmath600 , @xmath601 and @xmath602 are of degree @xmath551 , and let @xmath603 , @xmath604 and @xmath605 respectively be approximations over @xmath595 of the zeroes of @xmath600 , @xmath601 and @xmath602 . consider the @xmath606 `` root compatibility matrix '' @xmath607 defined by @xmath608 if @xmath446 is a permutation matrix , then it describes which root @xmath609 should be paired with @xmath610 , namely it is characterised by @xmath611 . in this manner , all other cordinates are chosen , dependent on the first choice of a root of @xmath592 .",
    "tentative minimal polynomials of @xmath612 and @xmath613 are @xmath614    we obtain the following approximate zeroes over @xmath595 using brent s method , implemented in pari  @xcite ; we preserve the ordering in which the roots were returned .",
    "@xmath615 now consider the compatibility matrix @xmath446 .",
    "it is @xmath616 i.e.  @xmath617 is @xmath90 precisely when @xmath618 approximates one of the values in the last column of the table above .",
    "we note that @xmath446 is a permutation matrix . applying the permutation @xmath446 to the list of roots",
    "@xmath619 of @xmath620 leads to a valid cordinate pairing : now @xmath621 corresponds to the @xmath622 .",
    "there are situations in which the matrix @xmath446 is not a permutation matrix but nevertheless contains useful information .",
    "consider the finite algebraic set @xmath623 in this case the minimal polynomials of the cordinates are @xmath624 and @xmath625 and the root compatibility matrix is @xmath626 .",
    "all @xmath87 possible pairings lead to correct solutions .",
    "there are also situations in which the matrix @xmath446 differs from the permutation matrix giving the correct identification of cordinates , even with exact arithmetic .",
    "for example , if @xmath627 denotes a fifth root of unity , and @xmath628 then the cordinates have respectively @xmath629 and @xmath630 as their minimal polynomial , and the root compatibility matrix is insufficient to recover @xmath631 .",
    "indeed the sum of the cordinates @xmath632 , which has minimal polynomial @xmath633 , does not distinguish solutions in @xmath631 from the non - solutions @xmath634 note that @xmath631 and @xmath635 are distinguished by the equation @xmath636 which holds in @xmath631 but not in @xmath635 .",
    "a linear form @xmath637 with @xmath638 would also do .",
    "there are also situations with more than two variables in which all compatibility matrices between two variables lead to possible pairings , but their combined information is not enough to identify the correct solutions .",
    "for example , consider @xmath639 all pairings between two cordinates are allowed , but there are @xmath87 solutions in total , and not @xmath473 .    above we have used the linear forms @xmath640 to determine the compatibility .",
    "our algorithm uses random linear forms to avoid these problems , or at least make them less probable .",
    "we are now ready to explain the algorithm computing the solutions in number fields that reduce modulo @xmath491 to given approximate solutions in @xmath163 .",
    "that problem is in fact an instance of the following , more general problem .",
    "the following algorithm is described as a process that , receiving as input an algebraic system over @xmath549 and an infinite feed of ever - more - precise @xmath143-adic approximations of a solution , produces a stream of algebraic solutions ( in the form of minimal polynomials over @xmath549 and complex numbers singling out roots of the minimal polynomials ) .",
    "the stream eventually exhausts all solutions conjugate to the @xmath143-adic solution .",
    "[ amatch ]    ' '' ''     + a polynomial system of equations @xmath641 in variables @xmath642 , having a finite number of solutions ; and approximations , to arbitrary precision , of a solution @xmath643 in @xmath163 + a number field @xmath644 , and exact solutions @xmath645 in @xmath548 , for @xmath646 ; each element of @xmath548 is given by its minimal polynomial and an approximation in @xmath595 of a particular root .",
    "we construct the solutions @xmath645 iteratively , entry by entry , by constructing partial tables @xmath647 .",
    "we start by an empty table , with @xmath648 and @xmath649 , and let @xmath650 be a small number .",
    "then , for each @xmath651 , we do the following . using algorithm  [ alll ]",
    ", we compute a likely minimal polynomial @xmath652 of @xmath653 , say of degree @xmath551 .",
    "we compute , to precision better than @xmath650 , approximate roots @xmath654 of @xmath652 .",
    "set @xmath655 if @xmath656 , we halve @xmath650 and restart all over .",
    "we next choose randomly a linear form @xmath657 with @xmath658 . again using algorithm  [ alll ] , we compute a minimal polynomial @xmath659 for @xmath660",
    ". if the degree of @xmath659 is not divisible by @xmath387 , we choose a different linear form @xmath661 and repeat the above .",
    "otherwise , we let @xmath662 be the minimal distance between roots of @xmath659 .",
    "if @xmath656 , we halve @xmath650 and restart all over .",
    "we then compute the @xmath663 matrix @xmath664 with @xmath665 let the degree of @xmath659 be @xmath666 .",
    "if @xmath446 contains @xmath179 ones per row and one one per column , then we replace @xmath387 by @xmath666 and replace each row @xmath667 is the partial table by @xmath179 rows @xmath668 for all @xmath669 such that @xmath611 .",
    "otherwise , we repeat the step with a different linear form or , if that failed more than ten times in a row , we simply skip the iteration .",
    "when the iteration finished with @xmath670 , we have obtained @xmath387 candidate solutions , which we check algebraically by evaluating @xmath671 on them .",
    "we output all those that are certifiably valid solutions , and restart the algorithm with better approximations of the @xmath672 .    first , all the solutions returned are valid , since they were checked ( using exact algebra ) by evaluating @xmath671 on them .",
    "let now @xmath673 be a solution that is conjugate to @xmath643 .",
    "in particular , the minimal polynomials of the @xmath674 and @xmath675 are the same , so they will eventually be found by algorithm  [ alll ] .",
    "similarly , for every linear form @xmath661 with integer cofficients , @xmath676 and @xmath677 also have the same minimal polynomial , so it will also be eventually found by algorithm  [ alll ] .",
    "we apply this algorithm to the same polynomial equations  .",
    "the variables @xmath674 are a relabeling of the @xmath541 from  .",
    "in this section , we detail the second part of the algorithm sketched in   [ ss : algo ] .",
    "we are given an approximation of a degree-@xmath40 rational map @xmath678 , as well as an approximation of the critical values @xmath679 , and the local degrees @xmath140 above each critical value @xmath20 .",
    "we are asked to compute the monodromy of the covering induced by @xmath28 .",
    "the first step is to compute a triangulation @xmath187 of @xmath75 by arcs of circle , and containing @xmath6 among its vertices .",
    "a particularly efficient triangulation is the _",
    "delaunay triangulation_. this is a decomposition of @xmath75 into triangles , such that , for any two triangles with a common edge , the sum of their opposite angles is @xmath680 .",
    "such a triangulation always exists ; is essentially unique ; and may be computed e.g.using  @xcite .    for performance reasons ,",
    "we refine the triangulation by adding vertices to it : whenever we encounter a triangle whose ratio `` circumradius / shortest side '' is larger than @xmath681 , we add its circumcenter to the triangulation .",
    "this process converges , and gives a reasonably good triangulation in that its triangles are not too acute ; see  @xcite .",
    "the dual decomposition @xmath189 of the sphere is the associated _",
    "vorono diagram_. it has one vertex , called a _",
    "dual vertex _ , per delaunay triangle and one edge , called _ dual edge _ , across every delaunay edge .",
    "each of its edges @xmath200 is parametrised as the preimage , under a mbius transformation @xmath682 , of the arc @xmath77 $ ] .",
    "we denote by @xmath191 the vertex set of @xmath189 , and choose a basepoint @xmath683 . for each @xmath193 ,",
    "we number arbitrarily the elements of the fibre @xmath684 as @xmath685 .",
    "because @xmath191 is far from @xmath6 , there are @xmath40 preimages of each @xmath193 , and their computation is numerically stable .",
    "there are now two strategies , which have both been tested and implemented .",
    "the first one is a bit simpler , but the second one performs better in practice .",
    "both associate a permutation @xmath686 of @xmath37 with each edge @xmath196 from @xmath687 to @xmath688 , in such a way that the the @xmath28-lift of @xmath200 that starts at @xmath689 ends at @xmath690 .",
    "both are explained below ; assuming them , we finish the description of the algorithm .",
    "let @xmath691 be non - crossing ( but possibly overlapping ) paths in @xmath189 that start and end in @xmath19 , cyclically ordered around @xmath19 , such that @xmath24 surrounds once counterclockwise the point @xmath20 and no other vertex of @xmath6 .",
    "these paths may be selected as follows : choose first the path @xmath692 arbitrarily , and mark its edges .",
    "then , for @xmath443 , choose the path @xmath24 in such a manner that it does not cross the previously chosen paths ( i.e. , it may follow a marked path , but must depart from it on the same side as it joined it ) , and starts at @xmath19 in counterclockwise order between the paths @xmath693 and @xmath692 .",
    "these paths @xmath24 are of the following form : follow some edges ; then follow counterclockwise the perimeter of the cell of @xmath189 containing @xmath20 , i.e.  in counterclockwise order the perpendiculars of the edges of @xmath187 touching @xmath20 ; and then follow in reverse the first edges .",
    "these paths form a basis for the fundamental group @xmath694 , compatible with the description from   [ ss : hurwitz ] .",
    "let @xmath695 be the edges along @xmath24 , and compute the permutation @xmath696 .",
    "then the monodromy representation of @xmath28 is given by the family @xmath697 .",
    "for each dual edge @xmath196 , going from @xmath197 to @xmath198 , we do the following . knowing the spherical distance from @xmath197 to @xmath198 and using coarse estimates on @xmath698",
    ", we have an upper bound on the length of each of the @xmath40 preimages of @xmath200 .",
    "we attempt to match each @xmath689 with a @xmath699 for some permutation @xmath700 , by matching each @xmath689 to the closest @xmath699 .",
    "if more than one match is compatible with the upper bound on the length of an arc above the arc from @xmath197 to @xmath198 , we subdivide the edge @xmath200 .    ' '' ''     + a rational map @xmath701 , an edge @xmath702 $ ] from @xmath703 to @xmath704 and orderings @xmath705 and @xmath706 of the preimages of @xmath707 respectively + a permutation @xmath700 such that the @xmath28-lift of @xmath200 starting at @xmath689 ends at @xmath699    more generally , the algorithm computes , for arbitrary @xmath708 , the matching between @xmath28-preimages of @xmath709 and of @xmath710 ; the solution is provided by the matching for @xmath711 and @xmath712 .",
    "we write @xmath713 for the @xmath28-preimages of @xmath710 .",
    "if there is only one possible match between the sets @xmath714 and @xmath715 , given by a permutation @xmath716 , then the algorithm returns that permutation .",
    "otherwise , set @xmath717 , compute the preimages @xmath718 of @xmath719 , recursively compute the matching between the @xmath720 and @xmath721 and between the @xmath721 and @xmath722 , and return the product of the corresponding permutations .",
    "the second algorithm is more efficient , and uses fundamentally the fact that the arcs in the triangulation @xmath189 and in its @xmath28-preimage are given by algebraic curves .",
    "we initially compute the delaunay triangulation @xmath188 on @xmath723 , and parametrise its edges @xmath551 via mbius transformations @xmath724 such that @xmath725)$ ] .",
    "it is straightforward to lift @xmath189 through @xmath28 : its edges are all the curves defined by equations @xmath726 $ ] .    ' '' ''",
    "+ a rational map @xmath701 , an edge @xmath702 $ ] from @xmath703 to @xmath704 and orderings @xmath705 and @xmath706 of the preimages of @xmath707 respectively + a permutation @xmath700 such that the @xmath28-lift of @xmath200 starting at @xmath689 ends at @xmath699    for each @xmath727 , we seek the @xmath728 such that the lift of @xmath200 starting at @xmath201 ends at @xmath729 .",
    "the permutation to return is then the map @xmath730 .",
    "we first determine in which triangle @xmath731 of @xmath188 the lift @xmath201 lies .",
    "then we compute whether the lift @xmath732 of @xmath200 starting at @xmath201 leaves @xmath731 .",
    "if this happens , then it must cross an edge @xmath551 of @xmath731 , namely , we have @xmath733)\\in[0,1]$ ] .",
    "this entails , firstly , that the imaginary part of @xmath734 vanishes , and secondly that its real part belongs to @xmath77 $ ] . both are polynomial conditions imposed on real - valued polynomials , and are efficiently computable numerically .",
    "we also keep track of the point of intersection @xmath735 of @xmath732 and @xmath551 .    in that case",
    ", we move to the neighbouring triangle @xmath736 of @xmath731 along edge @xmath551 , and continue .",
    "when we do not detect more intersections with edges of @xmath188 , we know in which triangle of @xmath737 the vertex @xmath729 lies .",
    "it may happen that two or more vertices @xmath729 belong to the same triangle @xmath731 that we have found in the previous paragraph . in that case",
    ", we let @xmath738 denote the last point on @xmath732 that was computed  possibly @xmath201 ; it also belongs to @xmath731 .",
    "we consider in turn all candidates @xmath729 , and compute the straight path @xmath739 from @xmath738 to @xmath729 and its image @xmath740 .",
    "if there exists a unique @xmath669 such that @xmath740 lies in the two triangles of @xmath187 to which @xmath200 belongs , then we have found the desired @xmath669 .",
    "if there are no such @xmath669 , then we interpolate .",
    "let @xmath741 $ ] be such that @xmath742 .",
    "consider @xmath743 , and those lifts @xmath744 that belong to @xmath731 ; we then consider the paths @xmath739 from @xmath122 to @xmath729 as before , and continue with increasing @xmath179 .",
    "additional care must be taken for tangent crossings of edges ( when the imaginary part of @xmath745 has a multiple zero ) , and when vertices of @xmath188 lie on edges of @xmath189 or conversely ; these are treated as special cases . however , because of the necessary crudeness of norm estimates on @xmath698 in the first method , this second method is preferable .",
    "we recall from the introduction that the _ post - critical set _ of a branched self - covering @xmath12 with critical value set @xmath65 is @xmath66 we are interested in the case where @xmath67 is finite and we consider @xmath28 up to isotopy rel @xmath67 ; namely , @xmath69 if there exists a path of branched self - coverings from @xmath28 to @xmath68 whose post - critical set moves smoothly .",
    "we say that @xmath28 is _ _ combinatorially equivalent _ _ to a rational map @xmath63 if there are orientation - preserving homeomorphisms @xmath746 and @xmath747 such that @xmath748 and @xmath749 is isotopic to @xmath750 rel @xmath67 .    on the one hand , many examples of branched self - coverings can be constructed combinatorially , via triangulations ;",
    "for these , it is natural to consider the maps up to isotopy rel the vertices of the triangulation . on the other hand , a fundamental theorem by thurston points to the rigidity of these objects :    [ thm : thurston ] let @xmath12 be branched self - covering with finite post - critical set @xmath67 . for each @xmath751 ,",
    "set @xmath752 , and assume that @xmath753 .",
    "this condition is usually abbreviated into `` @xmath28 has hyperbolic orbispace ''",
    ".    then @xmath28 is combinatorially equivalent to a rational map if and only if @xmath28 admits no `` thurston obstruction '' , namely , if and only if , for every collection @xmath754 of isotopy classes of non - peripheral disjoint curves on @xmath755 , the @xmath756-endomorphism @xmath757 has spectral radius @xmath758 .",
    "cui guizhen suggested in 2010 that if @xmath28 is a `` sierpiski map '' , namely a rational map whose julia set is a sierpiski carpet , then there should exist an essential , non - peripheral , simple curve @xmath759 such that @xmath760 contains at least two components homotopic to @xmath759 rel @xmath67 , for some @xmath43 large enough .",
    "he then found a counterexample to his suggestion , given combinatorially as follows :    ( 30:0.7 )  ( 150:0.7 ) ",
    "( 270:0.7 )  cycle ; circle [ radius=3 ] ; /in 90/,210/0,330/1 ( a ) at ( : 1.2 ) ; ( b ) at ( + 60:0.7 ) ; ( -60:0.7 )  ( a )  ( -7:1.6 )  cycle ; ( b )  ( a )  ( + 7:1.6 )  cycle ; ( -7:1.6 )  ( + 7:1.6 )  ( : 2.9 )  cycle ; ( : 2.9 ) .. controls ( + 10:2.2 ) and ( + 50:0.9 ) .. ( b ) .. controls ( + 70:0.9 ) and ( + 110:2.2 ) .. ( + 120:2.9 )  cycle ; ( : 0.9 ) node @xmath761 ;    ( 0,0 ) node @xmath90 ; ( 0.8,-0.75 ) node @xmath2 ; ( 1.12,-0.42 ) node @xmath101 ; ( 0.3,1 ) node @xmath87 ; ( -0.3,1 ) node @xmath762 ; ( -1.1,-0.42 ) node @xmath763 ; ( -0.8,-0.75 ) node @xmath472 ; ( 1.75,-1.0 ) node @xmath473 ; ( 0.0,2 ) node @xmath764 ; ( -1.75,-1.0 ) node @xmath765 ; ( 0,-1.2 ) node @xmath766 ; ( 0.9,0.8 ) node @xmath767 ; ( -0.9,0.8 ) node @xmath79 ;        in that case , @xmath768 with @xmath769 , @xmath770 and @xmath771 , and @xmath28 fixes @xmath67 pointwise .",
    "since @xmath28 has only three post - critical points , all curves are peripheral . on the other hand ,",
    "the julia set of @xmath28 is a sierpiski carpet , as we now show . for all @xmath772 , let @xmath773 be the immediate basin of @xmath20 .",
    "given @xmath774 not necessarily distinct , there exists up to isotopy a unique properly embedded arc with endpoints at @xmath775 whose interior avoids @xmath67 .",
    "direct inspection of the triangulation shows that none of these arcs are invariant under @xmath28 up to isotopy . from this",
    "it follows that the closures of the @xmath776 are pairwise disjoint , and that the boundary of each @xmath776 is a jordan domain .",
    "consider next the preimages of the basins @xmath773 .",
    "using the fact that @xmath28 is hyperbolic , no branching occurs on their boundaries , so all iterated @xmath28-preimages of the @xmath773 have disjoint closures and the julia set is a sierpiski carpet as claimed .",
    "kevin pilgrim indicated to us a degree-@xmath101 rational map exhibiting the same phenomenon ( its julia set is a sierpiski carpet , and it contains no self - replicating multicurve ) : start by the degree-@xmath2 rational map coming from the torus endomorphism @xmath777 on @xmath778 via the weierstrass map @xmath779 .",
    "then blow up the edge between @xmath780 and the fixed point .    from the above picture , it is easy to compute the monodromy action about @xmath6 : the permutations are those given in  , namely @xmath781 furthermore , the cycles mark which preimage of a critical value should be fixed .",
    "this extra dynamical data is required to determine the combinatorial equivalence class of @xmath28 , and it is also sufficient since @xmath782 so the pure mapping class group of @xmath783 is trivial .",
    "the orbispace of @xmath28 is hyperbolic , because @xmath784 for each @xmath751 . because @xmath782 , all curves on @xmath785 are peripheral , so no thurston obstruction may occur . by theorem  [ thm : thurston ] , there is then , up to mbius conjugacy , a unique map with monodromy @xmath786 , fixing @xmath82 with local degree @xmath2 , and such that @xmath82 are critical points marked by the cycles @xmath787 respectively .    therefore , the map computed by our algorithm , after precomposition with a suitable mbius transformation that puts the preimages of @xmath6 at the points determined by the cycles @xmath787 respectively , is the required solution .",
    "our algorithm searched in fact for a map @xmath63 with @xmath82 of order @xmath87 .",
    "this is an improvement to searching immediately for the correct map , because there are three points of order @xmath2 above each of @xmath82 , and they may lie in a strict field extension .    it remains to determine the appropriate mbius transformation with which to precompose @xmath63 .",
    "the first author developed an algorithm that determines , from a rational map given by its cofficients , both the monodromy about the critical values and the identification of critical points with cycles of the monodromy permutations .",
    "this algorithm is part of the software package img within the computer algebra system gap  @xcite , and will be described elsewhere .",
    "note , however , that there are finitely many possibilities to consider for the sought mbius transformation , and the correct one can be found by inspection . to find the appropriate one and",
    "thus determine the solution to cui s problem , it suffices to draw the preimage of the upper hemisphere under @xmath63 , and to identify on the picture the appropriate preimages of @xmath82 . in the image below , @xmath63 was normalized so that the order-@xmath87 critical points above @xmath82 are at cube roots of unity @xmath788 respectively .",
    "the appropriate preimages of @xmath82 are marked by a small red circle , based on the figure above :      our algorithm found a solution @xmath789 of the defining equations for a map ; then lifted them @xmath790 and finally obtained six galois conjugate solutions .",
    "the correct one ( with correct choice of point of order @xmath2 above @xmath82 ) was then found .",
    "the original map is of the form @xmath791 here are the preimages @xmath792 of @xmath82 respectively : @xmath793 the required mbius transformation @xmath794 maps @xmath795 to @xmath796 respectively , so @xmath797        we are grateful to kevin pilgrim for valuable remarks on a preliminary version of the text , and for more examples of sierpiski maps with three post - critical points .",
    "the referee pointed out with great acuity some deficiencies in the exposition , and contributed a shorter proof of the assertion that the julia set of cui s map is a sierpiski carpet ."
  ],
  "abstract_text": [
    "<S> we describe an algorithm that , given a @xmath0-tuple of permutations representing the monodromy of a rational map , constructs an arbitrarily precise floating - point complex approximation of that map .    </S>",
    "<S> we then explain how it has been used to study a problem in dynamical systems raised by cui . </S>"
  ]
}