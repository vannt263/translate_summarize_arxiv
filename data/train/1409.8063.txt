{
  "article_text": [
    "a _ lattice _ is the set of all integer combinations of @xmath7 linearly independent vectors @xmath8 in @xmath9 .",
    "these vectors are known as a _ basis _ of the lattice . in the last couple of decades , lattices became a central object of investigation in theoretical computer science due to their wide range of algorithmic and cryptographic applications .",
    "the two most fundamental lattice problems are the shortest vector problem ( svp ) and the closest vector problem ( cvp ) . given an @xmath7-dimensional lattice @xmath10 ( specified using an arbitrary basis ) , the is to find a shortest non - zero vector in @xmath10 , and , given in addition a target point @xmath11 , the is to find a closest vector to @xmath12 in @xmath10 . for their approximation versions ,",
    "the goal is to compute solutions whose length or distance is within some factor of optimal , and in the associated decisional versions , one must estimate the length or distance to within the desired factor .    from a computational complexity point of view , lattice problems are quite fascinating . for the nearly exponential approximation factor of @xmath13 ,",
    "efficient algorithms are known  @xcite . on the other hand , for solving the exact problems ( or even for approximating to within @xmath14 factors ) the best known algorithms run in time @xmath15",
    "it is known that for some @xmath16 , approximating to within @xmath17 is np - hard ( see  @xcite as well as  @xcite and references therein ) . under reasonable complexity assumptions , is also known to be hard for the same approximation factor  @xcite .",
    "finally , for approximation factor @xmath18 both problems are known to be in np@xmath19conp and hence unlikely to be np - hard  @xcite . for an introduction to the area",
    "see , e.g. ,  @xcite .    in this paper",
    "we also consider a natural variant of known as the _ closest vector problem with preprocessing ( ) _ .",
    "the motivation comes from applications in coding theory and cryptography where the lattice is often fixed once and for all , and the input only consists of the target point @xmath12 . in , the algorithm is allowed to spend an unlimited amount of time _ preprocessing _ the given lattice and output at the end a polynomial - size description of the lattice .",
    "then , given that description and a target point @xmath12 , our goal is to efficiently solve @xmath20 . as usual",
    ", one can consider either the search or the decision versions .",
    "the computational hardness of was investigated in a sequence of works @xcite , culminating in a hardness factor of @xmath21 for any @xmath22 by khot , popat , and vishnoi under reasonable complexity assumptions  @xcite . behind the latest two hardness results",
    "is a preprocessing version of the pcp theorem .",
    "the situation in terms of positive results , which is the focus of this work , is even more interesting .",
    "it follows from the early work of lagarias , lenstra , and schnorr  @xcite on so - called korkine - zolotarev bases that there exists an @xmath23 approximation algorithm for .",
    "somewhat surprisingly , prior to this work , their algorithm was still the best known approximation algorithm for .",
    "improved algorithms were known only for the _ decision _ variant of in which the task is to approximate the distance of the target point to the lattice .",
    "an @xmath6 approximation algorithm was given in  @xcite and then improved by aharonov and regev  @xcite to an @xmath24 approximation algorithm , a natural approximation factor that seems very difficult to beat .",
    "we are therefore in the ( somewhat absurd ! ) situation that we know that there is a close vector but we somehow ca nt find it ! we note that an equivalence between the search and decision versions of holds for the exact case  @xcite , but is not known to hold for the approximate case .",
    "since the latter algorithm is very natural and closely related to our work , we describe it here briefly .",
    "the main idea is to define for any lattice @xmath25 the _ periodic gaussian function _",
    "@xmath26 , given by @xmath27 where @xmath28 .",
    "see figure  [ fig : periodicgauss ] for an illustration .",
    "the algorithm now follows from two observations .",
    "the first is that for points @xmath12 at distance greater than @xmath18 from the lattice , @xmath29 is essentially zero , whereas for @xmath12 at distance less than @xmath30 , @xmath29 is non - negligible , so being able to compute @xmath31 would suffice to solve the decision problem .",
    "the second crucial idea is that the function @xmath31 , despite being defined in terms of a sum over infinitely many lattice points , can be approximated to within any @xmath32 by a function with a polynomial - size circuit .",
    "_ finding _ that circuit seems hard , but since it only depends on the lattice , we can do it in the preprocessing phase . to show that such an estimator exists , they first observe that the poisson summation formula gives the identity @xmath33 \\ ; , \\ ] ] where @xmath34 is a vector of the dual lattice @xmath35 sampled from @xmath36 , the so - called _ discrete gaussian distribution _ over @xmath35 .",
    "this naturally leads to the definition of the estimator @xmath37 where @xmath38 are i.i.d .",
    "samples from @xmath36 , which one can show satisfies @xmath39 with high probability over the choice of @xmath40 assuming @xmath41 is a large enough @xmath14 .",
    "once the vectors in @xmath40 are given as preprocessing advice , computing @xmath42 is clearly efficient .",
    "this completes the description of the decision algorithm from  @xcite .        moving on to the search problem ,",
    "a natural approach is to perform some sort of hill - climbing or gradient ascent on the periodic gaussian function @xmath31 ( using our estimator @xmath42 ) starting from the target point .",
    "as can be seen in figure  [ fig : periodicgauss ] , @xmath31 attains its maxima in lattice points , and so one would expect this process to converge to the nearest lattice point . indeed , this is the approach followed by liu , lyubashevsky , and micciancio  @xcite : they showed ( improving on earlier work of klein  @xcite ) how , given the estimator @xmath42 , to efficiently find the nearest lattice point to any target that is within distance @xmath43 of the lattice , where @xmath44 denotes the length of the shortest non - zero vector in @xmath10 .",
    "notice , however , that this falls short of solving since the algorithm is only guaranteed to work for target points that are close to the lattice .",
    "this problem is known as the _ bounded distance decoding problem _ ( ) , or in its preprocessing version .    extending these ideas to the search version of , or even just to for a larger decoding radius ,",
    "has proved to be elusive .",
    "the bound @xmath43 arises as a result of the following tension . on one hand , we would like to choose the width of the gaussians in @xmath31 as wide as possible in order to increase the radius in which @xmath31 is detectable and in which we can apply gradient ascent . on the other hand , making them",
    "too wide causes `` interference '' between the various peaks so we no longer have as clean a picture as in figure  [ fig : periodicgauss ] .",
    "we demonstrate this interference in section  [ sec : localmaxima ] by presenting a simple example in which @xmath31 has a local maximum at distance @xmath45 from the lattice whose value is exponentially close to the global maximum of @xmath46 .      [",
    "[ solving - by - hill - climbing . ] ] solving by hill climbing .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    our main technical contribution , given in sections  [ sec : bddalg ] and  [ sec : bddproof ] , is an improvement of the hill - climbing algorithm of llm .",
    "while the basic approach is the same , our algorithm uses a more natural gradient ascent procedure , compared with llm s `` discrete '' version .",
    "namely , at each step we replace the current point @xmath12 with an approximation of @xmath47 letting @xmath48 be the closest lattice point to @xmath12 and ignoring the interference coming from other peaks , we can think of @xmath31 as @xmath49 , in which case   is easily seen to equal @xmath48 , our desired output . for comparison",
    ", llm uses small axis - aligned steps , replacing @xmath12 with @xmath50 for some @xmath51 and @xmath52 $ ] . combining our more natural algorithm with a rather detailed analysis of the periodic gaussian function",
    "@xmath31 ( which is of independent interest , see section  [ sec : boundsongaussian ] ) and of its estimator @xmath42 ( section  [ sec : estimator ] ) , we obtain improvements on several fronts .",
    "firstly , we are able in some cases to extend the decoding radius .",
    "namely , instead of @xmath53 , we can handle targets at distance of up to @xmath54 for @xmath55 , or slightly above the inverse of the smoothing parameter of the dual lattice ( see section  [ sec : prelims - dgs - smoothing ] for the definition ) .",
    "this is never worse and is sometimes significantly better than the bound in llm .",
    "for instance , already for @xmath56 , we get distance @xmath57 , which is a constant factor of @xmath44 , compared with @xmath58 in llm .",
    "this improvement is a result of our refined analysis of @xmath31 , and highlights the fact that @xmath59 is the right measure of the interference between the peaks of @xmath31 .",
    "a second improvement is in the size of the advice required from preprocessing , which apart from being inherently interesting , is a good proxy for the efficiency of the algorithm .",
    "in llm , the advice consisted of an unspecified polynomial number of dual lattice vectors . in our algorithm , we require only @xmath60 dual lattice vectors .",
    "third , we show that our gradient ascent converges in just two steps ( after which we apply a simple rounding procedure ) compared to @xmath14 steps for llm . in both algorithms , the time complexity of each step",
    "is @xmath6 times the number of preprocessing vectors , which is also significantly lower in our algorithm .",
    "this fast convergence is due to the fact that a single step of our algorithm reduces the distance to the nearest lattice point by at least a constant factor , starting from any target within the decoding radius , and it reduces this distance by a polynomial factor when the target is closer by a constant factor . in comparison",
    ", the llm algorithm reduces this distance by a factor of only @xmath61 .",
    "finally , we note that our hill - climbing algorithm is quite interesting also in the regime of superpolynomial running time , and provides a smooth tradeoff between running time and decoding radius .",
    "for instance , by an appropriate setting of parameters , we obtain for any @xmath62 an algorithm that can handle targets at distance up to @xmath63 using @xmath64 vectors as advice and runs in time @xmath3 .",
    "( see corollary  [ cor : bddparams ] for the precise statement . )",
    "[ [ reducing - to - on - close - targets . ] ] reducing to on close targets .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in our second main contribution , appearing in sections  [ sec : cvppbdd ] and  [ sec : sparsification ] , we show that in order to solve either or , _ it suffices to answer queries on target points that are close to the lattice_.    in section  [ sec : cvppbdd ] we focus on the preprocessing setting .",
    "we show in theorem  [ thm : cvpptopromise ] that for any non - increasing function @xmath65 , in order to solve @xmath66-approximate it suffices to answer queries within distance @xmath63 . by combining this reduction with the llm algorithm ( or our improved algorithm )",
    ", we immediately obtain an @xmath4 approximation algorithm for search , improving on lagarias et al.s algorithm  @xcite . in terms of techniques , we closely follow kannan s idea  @xcite of looking for a projection of the lattice in which the target point is relatively close to the lattice .    by refining the ideas used in theorem  [ thm : cvpptopromise ] ,",
    "we give in theorem  [ thm : mastertheorem ] a similar reduction with the additional property that it incurs almost no blowup in the amount of preprocessing advice needed . combining this reduction ( as it appears in corollary  [ cor : cvpptobdd ] ) with our improved algorithm",
    ", we obtain an algorithm for @xmath6- that uses only @xmath6 vectors of advice .",
    "this is quite remarkable since @xmath6 vectors are `` not much more '' than the @xmath7 needed to form a basis ; and it is an interesting open question whether there exists a basis using which one can obtain even a polynomial approximation for ( see below ) . apart from the theoretical interest in minimizing the advice , this might have applications in cryptography or coding theory .    in section  [ sec :",
    "sparsification ] , we consider the setting without preprocessing and show for any @xmath67 and @xmath68 , a reduction from @xmath69-approximate to with the slightly harder approximation factor @xmath70 but with a distance bound of @xmath71 .",
    "we note that this reduction also applies to approximation factors well below @xmath18 , in contrast to our reduction in the preprocessing setting .",
    "notice that here we also require distance guarantees above @xmath44 , while the preprocessing setting can work well below the unique decoding radius of @xmath72 .",
    "when combined with the hardness result of  @xcite , our reduction shows that approximate is hard even when the target is guaranteed to be close to the lattice .",
    "see corollary  [ cor : hardnessofcvp ] for the precise hardness result .",
    "our reduction relies on a lattice sparsification technique introduced by dadush and kun  @xcite who used it to develop deterministic single - exponential time algorithms for approximate under general norms .",
    "the main open question is whether one can improve our @xmath4 approximation factor of search , and possibly match the best known approximation factor @xmath24 for the decision version .",
    "another open problem is to provide a deeper understanding of the computational complexity of both with and without preprocessing .",
    "liu et al .",
    "@xcite showed that @xmath73- is np - hard in the non - preprocessing version , however nothing is known for smaller distance bounds .",
    "this is in contrast to the situation for and , where _ any _ constant factor approximation is np - hard .",
    "a natural question is therefore : is @xmath1- np - hard for any constant @xmath1 ?",
    "an open question already mentioned briefly above is whether there exists a _",
    "basis _ that one can use to obtain a polynomial approximation for .",
    "a natural approach is to use babai s algorithm ( see section  [ sec : babai ] ) , whose approximation factor can be shown to be @xmath74 where the @xmath75 are the gram - schmidt orthogonalization of the given basis .",
    "the open question , once specialized to babai s algorithm , is therefore equivalent to asking whether every lattice has a basis with @xmath76 .",
    "the best known upper bound is @xmath77  @xcite using a korkine - zolotarev basis .",
    "finally , we note that our reductions in section  [ sec : cvppbdd ] and section  [ sec : sparsification ] are to the _ approximate _ bounded - distance problem .",
    "that is , we are guaranteed to be close to the lattice and are required to output a nearby lattice point , but _ not necessarily the closest_. in contrast , the llm algorithm and our improvement both have the property that they actually output the closest lattice point , an apparently harder problem .",
    "so , we are seemingly unable to use the full strength of our reduction .",
    "this leads to the following intuitive question : can the presence of one very close lattice point help in finding a _ different _ relatively close lattice point ?",
    "alternatively , is there a reduction from the approximate distance - bounded problem to its exact version ?",
    "the current gap between the search and decision versions of @xmath78 seems to suggest that being very close to the lattice may provide useful information that is still insufficient to find the nearest vector .",
    "a rank @xmath79 lattice @xmath25 is the set of all integer linear combinations of @xmath79 linearly independent vectors @xmath80 .",
    "@xmath81 is called a basis of the lattice and is not unique .",
    "we sometimes write @xmath82 to signify the lattice generated by @xmath81 .",
    "the length of the shortest nonzero vector , also known as the first successive minimum , is denoted by @xmath83 .    for any point @xmath84",
    ", we define @xmath85 as the minimum of @xmath86 for all @xmath87 .",
    "the covering radius @xmath88 is the supremum of @xmath85 for all @xmath89 .    for any lattice @xmath10 ,",
    "the dual lattice , denoted @xmath35 , is defined as the set of all points in @xmath90 that have integer inner products with all lattice points , @xmath91 similarly , for a lattice basis @xmath92 , we define the dual basis @xmath93 to be the unique set of vectors in @xmath90 satisfying @xmath94 .",
    "it is easy to show that @xmath35 is itself a rank @xmath79 lattice and @xmath95 is a basis of @xmath35 .    in what follows ,",
    "we typically consider only lattices @xmath25 whose rank is @xmath7 ( lattices of full rank ) .",
    "we note that all of our results apply to more general lattices , as we can simply think of the lattice as embedded in @xmath90 .",
    "we sometimes make use of this fact implicitly .",
    "the following technical lemma gives rough bounds on lattice parameters in terms of representation size .",
    "[ lem : bitlength ] let @xmath96 be a lattice with basis @xmath81 .",
    "let @xmath97 be the bit length of @xmath81 in a standard binary representation .",
    "then , @xmath98 and @xmath99 .",
    "let @xmath100 . then clearly @xmath101 similarly ,",
    "if @xmath102 , then any integer linear combination of the @xmath103 must be expressible as @xmath104 where @xmath105",
    ". therefore , @xmath106 .    given a basis , @xmath100",
    ", we define its gram - schmidt orthogonalization @xmath107 by @xmath108 and the gram - schmidt coefficients @xmath109 by @xmath110 here , @xmath111 is the orthogonal projection on the subspace @xmath112 and @xmath113 denotes the subspace orthogonal to @xmath114 .",
    "a basis @xmath115 of @xmath10 is a hermite - korkin - zolotarev ( hkz ) basis if    1 .   @xmath116 ; 2 .",
    "the gram - schmidt coefficients of @xmath81 satisfy @xmath117 for all @xmath118 ; and 3 .",
    "@xmath119 is an hkz basis of @xmath120 .      for any approximation parameter @xmath121 ,",
    "the search problem @xmath122 ( shortest vector problem ) is defined as follows : the input is a basis @xmath81 for a lattice @xmath25 .",
    "the goal is to output a vector @xmath123 satisfying @xmath124 .    for any approximation parameter @xmath121 ,",
    "the search problem @xmath125 ( closest vector problem ) is defined as follows : the input is a basis @xmath81 for a lattice @xmath25 and a vector @xmath11 , the target .",
    "the goal is to output a vector @xmath123 satisfying @xmath126 .",
    "we often ignore the basis and simply refer to @xmath10 and @xmath12 as the input .",
    "the decision problems @xmath127 is the decision analogue of @xmath128 , defined as follows : the input is a basis @xmath81 of a lattice @xmath25 and a target vector @xmath129 .",
    "it is a yes instance if @xmath130 .",
    "it is a no instance if @xmath131 .",
    "dinur et al .",
    "@xcite showed the current best known hardness result for @xmath127 , which of course immediately implies a hardness result for @xmath125 .",
    "[ thm : cvphard ] there is some constant @xmath132 such that @xmath127 ( and therefore @xmath125 ) is np - hard for @xmath133 .",
    "let @xmath134 be a positive - valued function on lattices and @xmath135 .",
    "then , @xmath136 is the problem of solving @xmath125 when the input lattice @xmath10 and target point @xmath12 satisfy @xmath137 .",
    "if the target point is outside of this range , any output is acceptable .",
    "we note that the standard reduction from @xmath122 to @xmath125 ( see , for example , @xcite ) is actually a reduction from @xmath122 to @xmath136 where @xmath138 .",
    "[ thm : svptocvp ] there is a polynomial - time reduction from @xmath122 to @xmath136 where @xmath138 for any lattice @xmath10 and @xmath68 .",
    "an algorithm with preprocessing consists of two phases .",
    "the first phase , called the preprocessing algorithm , takes input @xmath139 and outputs an advice string @xmath112 .",
    "the second phase , called the query algorithm , takes input @xmath112 and @xmath140 , the query , and outputs a solution @xmath141 .",
    "we say that such an algorithm runs in polynomial time if the advice @xmath112 is polynomial in the length of @xmath139 and the query algorithm runs in time polynomial in the lengths of @xmath139 and @xmath140 .",
    "the preprocessing algorithm may take arbitrary time .",
    "the search problems @xmath142 and @xmath143 ( closest vector problem with preprocessing ) are the preprocessing analogues of @xmath125 and @xmath136 respectively , defined as follows : the input to preprocessing is a basis @xmath81 of a lattice @xmath25 .",
    "the input to the query phase is a vector @xmath129 .",
    "the goal is to return a valid solution to @xmath125 or @xmath136 respectively .    for any approximation parameter @xmath144 ,",
    "the search problem with preprocessing @xmath145 ( bounded distance decoding ) is simply @xmath146 where @xmath147 for any lattice @xmath10 .      for any @xmath148",
    ", we define the function @xmath149 as @xmath150 . when @xmath151 , we simply write @xmath152 . for a set",
    "@xmath112 we define @xmath153 .    for a lattice @xmath25 and a vector @xmath11 ,",
    "let @xmath154 be the probability distribution over @xmath155 such that the probability of drawing @xmath156 is proportional to @xmath157 .",
    "we call this the discrete gaussian distribution over @xmath155 with parameter @xmath158 .    for any lattice @xmath25 and @xmath159 , let @xmath160    banaszczyk proved the following two lemmas in @xcite .",
    "we include proofs for completeness .    for an @xmath7-dimensional lattice @xmath10 , shift @xmath161 , and any @xmath162 , @xmath163 \\leq \\frac{\\rho({\\mathcal{l}})}{\\rho({\\mathcal{l}}+{\\ensuremath{\\mathbf{c } } } ) } e^{-\\frac{n}{2}(t^2 - 2 \\log t - 1 ) } \\leq \\frac{\\rho({\\mathcal{l}})}{\\rho({\\mathcal{l}}+{\\ensuremath{\\mathbf{c } } } ) } e^{-\\frac{n}{2}(t-1)^2 } \\ ; .\\ ] ] [ lem : strong - tailbound ]    for any @xmath164 , we have that @xmath165   & = \\frac{\\rho({\\mathcal{l}})}{\\rho({\\mathcal{l}}+{\\ensuremath{\\mathbf{c } } } ) } \\frac{\\rho_{1/(\\sqrt{1-\\alpha})}({\\mathcal{l}}+{\\ensuremath{\\mathbf{c}}})}{\\rho({\\mathcal{l } } ) } \\\\   & = \\frac{\\rho({\\mathcal{l}})}{\\rho({\\mathcal{l}}+{\\ensuremath{\\mathbf{c}}})}\\big(\\frac{1}{\\sqrt{1-\\alpha}}\\big)^n       \\frac{\\sum_{{\\ensuremath{\\mathbf{y } } } \\in { \\mathcal{l}}^ * } e^{2\\pi i{\\langle{{\\ensuremath{\\mathbf{y } } } , { \\ensuremath{\\mathbf{c}}}}\\rangle}}\\rho_{\\sqrt{1-\\alpha}}({\\ensuremath{\\mathbf{y}}})}{\\rho({\\mathcal{l}}^ * ) }   & \\text{(poisson summation formula ) } \\\\   & \\leq \\frac{\\rho({\\mathcal{l}})}{\\rho({\\mathcal{l}}+{\\ensuremath{\\mathbf{c } } } ) } \\big(\\frac{1}{\\sqrt{1-\\alpha}}\\big)^n       \\frac{\\rho_{\\sqrt{1-\\alpha}}({\\mathcal{l}}^*)}{\\rho({\\mathcal{l}}^ * ) } \\\\ & \\leq \\frac{\\rho({\\mathcal{l}})}{\\rho({\\mathcal{l}}+{\\ensuremath{\\mathbf{c}}})}\\big(\\frac{1}{\\sqrt{1-\\alpha}}\\big)^n   \\ ; .\\end{aligned}\\ ] ] using the above and markov s inequality , we have that @xmath166            & =               \\pr\\big[e^{\\pi \\alpha \\|{\\ensuremath{\\mathbf{y}}}\\|^2 } \\geq e^{\\alpha n t^2/2}\\big ] \\\\           & \\leq \\frac{\\rho({\\mathcal{l}})}{\\rho({\\mathcal{l}}+{\\ensuremath{\\mathbf{c } } } ) }          \\frac{(1/\\sqrt{1-\\alpha})^n}{e^{\\alpha n t^2/2 } } \\\\          & = \\frac{\\rho({\\mathcal{l}})}{\\rho({\\mathcal{l}}+{\\ensuremath{\\mathbf{c } } } ) }          e^{-\\frac{n}{2}(\\alpha t^2 + \\log(1-\\alpha ) ) }          \\ ; .\\end{aligned}\\ ] ] the first bound now follows by setting @xmath167 .    for the simplified bound , using the fact that @xmath168 , for @xmath162 , we get that @xmath169 as needed .",
    "[ lem : betterrholtbound ] let @xmath170 be a lattice of rank @xmath7 . then , for all @xmath11 , @xmath171 .",
    "@xmath172    for @xmath173 and @xmath170 a lattice , we define the smoothing parameter @xmath174 as the unique value satisfying @xmath175 .",
    "the name smoothing parameter comes from the fact that , for @xmath176 , @xmath177 varies by at most a multiplicative factor of @xmath178 @xcite .",
    "the function @xmath179 is quite important for our algorithm , so we analyze its behavior here .",
    "our first lemma shows that @xmath180 is strictly monotonically decreasing as @xmath181 increases .",
    "( this is not obvious since both the numerator and the denominator are monotonically decreasing . )",
    "it is a simple modification of ( * ? ?",
    "* lemma 2.4 ) .",
    "[ lem : gmonodecrease ] let @xmath25 be a lattice of rank at least one .",
    "let @xmath182 for any @xmath183 .",
    "then , @xmath180 is strictly monotonically decreasing .",
    "our goal is to prove that for any @xmath183 , @xmath184 , @xmath185 , or equivalently , that @xmath186 where @xmath187 this follows from @xmath188    the next lemma and its corollary show the relationship between @xmath180 and @xmath44 .",
    "similar analysis appears in @xcite .",
    "let @xmath189 be an @xmath7-dimensional lattice .",
    "then , for @xmath183 , @xmath190 [ lem : tighter - smoothing - bound ]    for the lower bound , we note that for @xmath191 , we have that @xmath192 as needed . for the upper bound , we note that @xmath193 if and only if @xmath194 \\leq \\frac{{\\varepsilon}}{1+{\\varepsilon}}$ ] . by lemma  [ lem : strong - tailbound ] , letting @xmath195 , for @xmath162 , we have that @xmath196                                 = \\pr_{{\\ensuremath{\\mathbf{y } } } \\sim d_{{\\mathcal{l}},1/s}}[\\|{\\ensuremath{\\mathbf{x}}}\\| \\geq \\lambda_1({\\mathcal{l } } ) ] = \\pr_{{\\ensuremath{\\mathbf{y } } } \\sim d_{{\\mathcal{l}}}}[\\| { \\ensuremath{\\mathbf{y } } } \\| \\geq t\\cdot \\sqrt{n/2\\pi } ]                                \\leq e^{-\\frac{n}{2}(t-1)^2 } \\ ; .\\ ] ] setting @xmath197 , we get that @xmath194 \\leq \\frac{{\\varepsilon}}{1+{\\varepsilon}}$ ] .",
    "therefore @xmath198 as needed .",
    "[ cor : smoothing - to - lambda ] let @xmath189 be an @xmath7-dimensional lattice .",
    "then , for @xmath183 , @xmath199      we next introduce subgaussian and subexponential random variables , and in particular , the subgaussianity of @xmath200 .",
    "we say that a random variable @xmath201 ( or its distribution ) over @xmath9 is subgaussian with parameter @xmath148 if @xmath202 = { \\ensuremath{\\mathbf{0}}}$ ] , and for all @xmath203 and all unit vectors @xmath204 , @xmath205 \\leq 2\\cdot e^{-\\pi t^2/s^2 }   \\ ; .\\ ] ]    [ lem : subgaussian ] let @xmath170 be a lattice of rank @xmath7 .",
    "then for any @xmath206 , @xmath200 is subgaussian with parameter @xmath207 .",
    "we say that a random variable @xmath208 ( or its distribution ) over @xmath209 is subexponential with parameter @xmath158 if , for any @xmath210 @xmath211 \\leq e^{1-t / s } \\ ; .\\ ] ]    vershynin proved a basic relationship between subgaussian and subexponential random variables , from which we derive a simple corollary .",
    "[ lem : subgausssquared ] if @xmath212 is a subgaussian random variable over @xmath9 with parameter @xmath158 , then for any unit vector @xmath204 , @xmath213 is subexponential with parameter @xmath214 .",
    "[ cor : subgaussianproduct ] if @xmath212 and @xmath215 are subgaussian random variables over @xmath9 with parameter @xmath158 , then for any two unit vectors @xmath216 , @xmath217 is subexponential with parameter @xmath214    it follows immediately from the definitions that subgaussian random variables with parameter @xmath214",
    "are closed under addition and multiplication by constants , as are subexponential random variables with parameter @xmath214 .",
    "therefore , @xmath218 is subexponential with parameter @xmath214 as claimed .",
    "vershynin showed the next useful property of subexponential random variables .",
    "[ lem : subexp ] let @xmath219 be independent subexponential random variables over @xmath209 with parameter s , and suppose @xmath220 = 0 $ ] for all @xmath221 .",
    "then , for any @xmath222 , @xmath223   \\leq 2^{1-\\omega(n\\min(t / s , t^2/s^2 ) ) } \\ ; .\\ ] ]    we will also need the chernoff - hoeffding bound  @xcite .",
    "[ lem : chernoff ] let @xmath224 be independent and identically distributed random variables with @xmath225 . then , for @xmath226 @xmath227 - \\frac{1}{n}\\cdot\\sum x_i \\big| \\geq s \\big ] \\leq 2^{1-\\omega(ns^2/a^2 ) } \\ ; .\\ ] ]      babai s nearest plane algorithm ( denoted ) is an algorithm introduced by babai @xcite for rounding a target vector to a nearby lattice point one coordinate at a time .",
    "the input is a basis @xmath228 for a lattice @xmath10 and a target @xmath229 .",
    "we first project @xmath12 onto @xmath90 .",
    "we then choose the last coordinate @xmath230 of our nearby lattice point by simple rounding , setting @xmath231 next we call recursively on @xmath232 and @xmath233 and receive the result @xmath48 .",
    "we then return @xmath234 .",
    "stated more intuitively , chooses the lattice hyperplane @xmath235 with @xmath230 that is nearest to the target and recurses on this hyperplane .",
    "babai proved the following standard fact about his algorithm .",
    "[ lem : babai ] let @xmath170 be a lattice of rank @xmath7 . for any basis , @xmath100 of @xmath10 with gram - schmidt orthogonalization @xmath236 and any target vector @xmath11 , @xmath237 outputs @xmath123 satisfying @xmath238      for any @xmath239 , @xmath240 is a @xmath241-net of @xmath141 if @xmath242 , and for each @xmath243 , there is some @xmath244 such that @xmath245 .",
    "we ll be interested in the case when @xmath141 is a ball , a sphere , or a shell .",
    "the next lemma shows that we can do this without many points .",
    "the proof is by a standard packing argument .",
    "( see lemma 5.2 of @xcite , for example . )",
    "[ lem : smallnet ] for any @xmath239 , there exists a @xmath241-net of the unit ball in @xmath9 with @xmath246 points .",
    "nets of the same cardinality exist for spherical shells of outer radius one , and for the unit sphere .",
    "a @xmath241-net of the unit sphere can be used to accurately approximate the length of any vector .",
    "[ lem : deltanorm ] let @xmath247 , and let @xmath112 be a @xmath241-net of the unit sphere in @xmath9 . then",
    ", for any @xmath84 , @xmath248    without loss of generality , assume @xmath249 .",
    "the first inequality is trivial . by hypothesis",
    ", there is some @xmath250 such that @xmath251 .",
    "then , @xmath252 the result follows .",
    "similarly , a @xmath241-net can be used to approximate the spectral norm of a matrix , as defined below .    for a matrix @xmath253 ,",
    "the spectral norm of @xmath254 is defined as @xmath255    for a symmetric matrix @xmath254 , @xmath256 is equivalently the largest absolute value of an eigenvalue of @xmath254 .    [",
    "lem : deltaeigenvalues ] for a symmetric matrix @xmath253 and a @xmath241-net of the unit sphere @xmath112 with @xmath257 , @xmath258",
    "in this section we prove the following theorem , which gives an efficient solution to for points within distance essentially @xmath259 . by corollary  [ cor : smoothing - to - lambda ] , for @xmath55 this radius is at least as large as the radius @xmath260 achieved by  @xcite , and moreover , as @xmath181 goes to zero , it converges to the unique decoding radius @xmath72 .",
    "also , by lemma  [ lem : gmonodecrease ] , this radius is ( essentially ) increasing as @xmath181 decreases , and thus our algorithm solves a harder problem for smaller @xmath181 .    [ thm : polyeps ] let @xmath261 and @xmath262 where @xmath263and @xmath264 .",
    "then , there exists an algorithm that solves @xmath265 using @xmath266 arithmetic operations , where @xmath267 and @xmath268 is the number of arithmetic operations needed to compute the inverse of an @xmath269 matrix .",
    "moreover , the preprocessing consists of @xmath41 vectors sampled from @xmath270 .",
    "we note that we can achieve a run - time of @xmath271 arithmetic operations by computing the inverse of a matrix as part of the preprocessing .",
    "our result will follow easily from a proposition about @xmath42 , whose proof is in section  [ sec : bddproof ] .",
    "[ prop : estimatorisgreat ] let @xmath25 be a lattice with @xmath272 with @xmath273 .",
    "let @xmath263 , @xmath264 , and @xmath274 .",
    "let @xmath275 be sampled independently from @xmath36 . if @xmath276 , then with probability at least @xmath277 , @xmath278 holds simultaneously for all @xmath11 with @xmath279 .",
    "we note that for @xmath280 , @xmath281 , so the right hand side of   is at most @xmath282 .",
    "we present an algorithm with probabilistic preprocessing and argue that with positive probability the preprocessing algorithm will output advice that results in a query algorithm that is successful on all relevant inputs . clearly this implies a deterministic algorithm .",
    "the preprocessing algorithm takes as input a lattice @xmath25 of rank @xmath7 .",
    "it returns as advice a sequence of samples @xmath283 from @xmath284 where @xmath267 is large to satisfy proposition  [ prop : estimatorisgreat ] .",
    "the query algorithm takes a target point @xmath11 and advice @xmath40 from preprocessing .",
    "it then iteratively updates @xmath285 a total of @xmath286 times .",
    "it then scans @xmath40 .",
    "let @xmath287 be the first @xmath7 linearly independent vectors it finds of length bounded by @xmath288 ( it aborts if no such vectors exist ) .",
    "the algorithm computes @xmath289 satisfying @xmath290 and returns @xmath291 for @xmath292 .    by scaling the lattice appropriately",
    ", we can assume without loss of generality that @xmath272 so that @xmath293",
    ". moreover , it suffices to prove correctness for the case when @xmath294 is the closest lattice vector to @xmath12 , and therefore @xmath295 .",
    "the reason is that for @xmath123 , @xmath296 so @xmath297 is periodic over the lattice , and so is its gradient , and also @xmath298 for any @xmath123 .",
    "we now argue that with probability @xmath277 taken over the preprocessing , the query algorithm succeeds in finding the set @xmath299 ( and hence also @xmath300 ) .",
    "let @xmath301 for @xmath302 .",
    "by lemma  [ lem : strong - tailbound ] , we have that @xmath303 < e^{-\\frac{n}{2}(\\sqrt{2\\pi}-1)^2 } \\leq e^{-n}$ ] , and hence with probability at least @xmath304 , all vectors in @xmath305 are of norm at most @xmath18 . in order to show that the vectors in @xmath305 span @xmath9 we can , e.g. , apply lemma  [ lem : hess ] below to @xmath305 .",
    "we get that for @xmath306 large enough , the hessian of @xmath307 satisfies @xmath308 with probability @xmath277 , where we used @xmath280 . in particular , the matrix @xmath309 ( see eq .  ) is invertible , and hence @xmath305 spans @xmath9 .",
    "now assume that @xmath40 contains such a subset @xmath299 and satisfies the property in proposition  [ prop : estimatorisgreat ] . by",
    "the union bound this happens with probability at least @xmath277 over the preprocessing .",
    "then using the remark below proposition  [ prop : estimatorisgreat ] , for any target @xmath12 satisfying @xmath279 , the length of @xmath12 shrinks by a factor of at least @xmath310 in the first iteration .",
    "in each subsequent iteration , @xmath311 , and hence the target shrinks by a factor of at least @xmath312 .",
    "therefore , after @xmath313 total iterations , we have @xmath314 .",
    "so , by cauchy - schwarz , @xmath315 and @xmath316 for all @xmath221 .",
    "therefore , @xmath317 , and correctness follows .",
    "the running time consists of @xmath318 iterations , each dominated by the computation of @xmath319 dot products , followed by a matrix inversion .",
    "each dot product takes @xmath6 arithmetic operations , and the matrix inversion takes @xmath268 .",
    "so , the total running time is @xmath320 arithmetic operations as claimed .",
    "we remark that for small enough @xmath321 ( @xmath322 suffices ) , the number of iterations of gradient ascent used by the algorithm is only @xmath323 .",
    "[ cor : bddparams ] for @xmath324 , there exists an algorithm that solves @xmath325 with preprocessing consisting of @xmath326 vectors using @xmath327 arithmetic operations .",
    "let @xmath181 be given by @xmath328 and notice that @xmath329 using lemma  [ lem : tighter - smoothing - bound ] , the decoding radius given by theorem  [ thm : polyeps ] satisfies @xmath330 where we have used the inequality @xmath331 for @xmath332 .",
    "we remark that one can strengthen the bound in lemma  [ lem : tighter - smoothing - bound ] using the first bound in lemma  [ lem : strong - tailbound ] , and as a result get improved dependence on @xmath1 in corollary  [ cor : bddparams ] especially for large @xmath1 . since the resulting expressions have no nice closed form , we leave the straightforward calculation to the interested reader .",
    "our goal is to show that @xmath333 is close to @xmath334 when @xmath335 is small .",
    "we start by showing in section  [ sec : boundsongaussian ] that this is satisfied by the _ exact _",
    "function @xmath31 , i.e. , that @xmath336 is close to @xmath334 .",
    "we also prove several other bounds on @xmath31 .",
    "we then complete the proof in section  [ sec : estimator ] by arguing that @xmath42 and @xmath31 are sufficiently close and so are their gradients .",
    "we first give in lemma  [ lem : rhol ] a general bound ( illustrated in figure  [ fig : boundonf ] ) on @xmath29 itself .",
    "this will not be used in the sequel and is included here as a warmup and for future reference .",
    "we then use a similar idea in lemma  [ lem : expectation ] to show that @xmath337 is close to @xmath12 , and in corollary  [ cor : simpleexpectbound ] bring this bound to a more convenient form . finally , in lemma  [ lem : exacthess ] we similarly bound the hessian @xmath338 .",
    "[ lem : rhol ] let @xmath22 and @xmath25 a lattice with @xmath272 . then , for any @xmath11 , @xmath339 where @xmath263 .",
    "contrast this with the easy lower bound @xmath340 from lemma  [ lem : betterrholtbound ] valid for all lattices and all @xmath12 .",
    "we can write @xmath341.\\end{aligned}\\ ] ] we now use the fact that for any real - valued random variable @xmath208 and ( sufficiently nice ) even function @xmath342 , @xmath343 = \\operatorname*{\\mathbb{e}}_x[g(|x| ) ] = g(0 ) + \\int_0^\\infty g'(s ) \\pr_x[\\abs{x } > s]{\\rm d}s   \\ ; .\\ ] ] therefore , the expectation in eq .",
    "is given by @xmath344 \\sinh(2 \\pi s\\length{{\\ensuremath{\\mathbf{t } } } } ) { \\rm d}s.\\end{aligned}\\ ] ] we can upper bound the probability using lemma  [ lem : subgaussian ] ( and noticing that @xmath48 is nonzero with probability @xmath345 ) by @xmath346 \\le \\min\\big(\\frac{{\\varepsilon}}{1+{\\varepsilon}},\\ , 2 e^{-\\pi s^2 } \\big).\\ ] ] the minimum is determined by the second term for @xmath347 .",
    "we can therefore bound the integral in eq .   from above by the sum of two integrals , the first being @xmath348 and the second being @xmath349 putting it all together , we obtain the desired bound @xmath350    [ lem : expectation ] let @xmath173 and @xmath25 a lattice with @xmath272 . then , for any @xmath11 , @xmath351 where @xmath263 .",
    "using eq .   to compute @xmath352 and recalling that @xmath353 , @xmath354 \\ ; .\\ ] ] fix a unit vector @xmath355 . for any @xmath48 ,",
    "let @xmath356 be the indicator that @xmath357 , @xmath358 , and @xmath359 .",
    "then , @xmath360 taking expectations on both sides , we get @xmath361 & \\leq 2\\pi\\length{{\\ensuremath{\\mathbf{t } } } } \\int_{0}^\\infty \\int_{0}^\\infty \\cosh(2\\pi \\length{{\\ensuremath{\\mathbf{t}}}}r)\\operatorname*{\\mathbb{e}}[p_{r , s}({\\ensuremath{\\mathbf{y}}})]{\\rm d}s{\\rm d}r \\ ; .\\end{aligned}\\ ] ]    as in the previous proof , note that @xmath362 \\leq \\min\\big(\\frac{{\\varepsilon}}{1+{\\varepsilon } } , 2 e^{-\\pi s^2 } , 2 e^{-\\pi r^2}\\big)\\ ] ] by lemma  [ lem : subgaussian ] .",
    "so , we partition the positive quadrant of the @xmath363-plane into three regions and bound the integral separately in each region .    1 .",
    "when @xmath364 and @xmath365 , @xmath366 $ ] is at most @xmath345 , and the integral in this region is bounded by @xmath367 2 .",
    "when @xmath368 and @xmath369 , @xmath370 $ ] is at most @xmath371 , and the integral in this region is bounded by @xmath372 3 .",
    "when @xmath373 and @xmath347 , @xmath366 $ ] is at most @xmath374 .",
    "so , the integral in this region is bounded by @xmath375    combining everything together , and applying lemma  [ lem : betterrholtbound ] , @xmath376    [ cor : simpleexpectbound ] let @xmath261 and @xmath25 a lattice with @xmath272 .",
    "let @xmath263 .",
    "then for all @xmath11 satisfying @xmath377 , @xmath378 where @xmath379 .",
    "in particular , for @xmath380 , @xmath381    recall from lemma  [ lem : expectation ] that @xmath382 because @xmath383 is convex on @xmath384 , @xmath385 , and @xmath386 , @xmath387 using the above , @xmath388 turning to the integral and using the above bound on @xmath389 again , @xmath390    combining everything together , @xmath391 the first result follows by noting that @xmath392 for @xmath280 and @xmath393 .",
    "the second result follows by noting that @xmath394 for @xmath395 .",
    "[ lem : exacthess ] let @xmath22 and @xmath25 a lattice with @xmath272 . then ,    1 .",
    "@xmath396 for all @xmath11 .",
    "2 .   @xmath397 .    from eq .",
    ", we have that for any @xmath11 @xmath398 \\big\\| \\\\ & \\leq 4\\pi^2 \\big\\| \\operatorname*{\\mathbb{e}}_{{\\ensuremath{\\mathbf{w } } } \\sim",
    "d_{{\\mathcal{l}}^*}}[{\\ensuremath{\\mathbf{w } } } { \\ensuremath{\\mathbf{w}}}^t ] \\big\\| \\\\ & = \\length{h f ( { \\ensuremath{\\mathbf{0 } } } ) } \\ ; .\\end{aligned}\\ ] ] from eqs .   and",
    ", we have a representation of @xmath399 in both the primal and the dual , @xmath400 = 2\\pi \\operatorname*{\\mathbb{e}}_{{\\ensuremath{\\mathbf{w } } } \\sim d_{{\\mathcal{l}}^*}}[{\\ensuremath{\\mathbf{w}}}{\\ensuremath{\\mathbf{w}}}^t]\\,.\\ ] ] noting that both expectations are positive semidefinite , it follows that @xmath401 .    for the second",
    "bound , following the technique used in the proofs of lemmas  [ lem : rhol ] and [ lem : expectation ] , @xmath402 \\\\ & = 8\\pi^2\\cdot \\max_{\\length{{\\ensuremath{\\mathbf{v } } } } = 1 }   \\int_{0}^\\infty r \\pr_{{\\ensuremath{\\mathbf{y } } } \\sim d_{\\mathcal{l}}}[\\abs{\\inner{{\\ensuremath{\\mathbf{y } } } , { \\ensuremath{\\mathbf{v } } } } } \\geq r]{\\rm d}r\\\\ & \\leq 8\\pi^2 \\int_{0}^\\infty r \\min({\\varepsilon}/(1+{\\varepsilon } ) , 2e^{-\\pi r^2}){\\rm d}r & \\text{(lemma~\\ref{lem : subgaussian})}\\\\ & = \\frac{4\\pi { \\varepsilon}}{1+{\\varepsilon}}\\big(\\log \\frac{2(1+{\\varepsilon})}{{\\varepsilon } } + 1\\big ) \\ ; .\\end{aligned}\\ ] ]      in this section we complete the proof of proposition  [ prop : estimatorisgreat ] .",
    "the basic plan of the proof is straightforward : after having shown in corollary  [ cor : simpleexpectbound ] the analogous property for the exact function @xmath31 , it suffices to show that @xmath403 is close to @xmath404 for all relevant @xmath12 .",
    "it is obviously enough to argue separately that @xmath405 is close to @xmath406 and that @xmath42 is close to @xmath31 ( with appropriate notions of closeness ; see the technical claim  [ claim : fraction_id_impr ] for the precise statement ) .",
    "the former will be shown to hold with high probability for any fixed @xmath12 in lemma  [ lem : gradestimator ] and then to hold with high probability simultaneously for all relevant @xmath12 in lemma  [ lem : gradcloseallpoints ] .",
    "similarly , the latter will be shown to hold with high probability for any fixed @xmath12 in lemma  [ lem : festimator ] and then to hold with high probability simultaneously for all relevant @xmath12 in lemma  [ lem : festimatorallpoints ] . in both cases , showing that the result holds simultaneously for all @xmath12 is done by taking a union bound over an appropriately chosen net and showing that the functions do not vary much .",
    "one minor complication in the proof is that in the former case ( closeness of @xmath405 ) the net has to become denser as we get closer to the origin . in order to keep the net finite , lemma  [ lem : gradcloseallpoints ] actually does not handle tiny vectors @xmath12 .",
    "instead we include lemma  [ lem : verycloset ] which proves proposition  [ prop : estimatorisgreat ] directly for the case of tiny vectors .",
    "finally , many of our proofs require quantitative statements about the smoothness @xmath42 and @xmath405 , which are shown in lemma  [ lem : hess ] and lemma  [ lem : lipshitz ] .",
    "[ lem : hess ] let @xmath25 be a lattice with @xmath272 for some @xmath173 , and let @xmath407 be sampled independently from @xmath36 . then , for @xmath408 , @xmath409 , and @xmath410 , we have    1 .",
    "@xmath411 \\leq 2^{-\\omega(n\\min(s , s^2))}$ ] .",
    "2 .   @xmath412 \\leq 2^{-\\omega(n)}$ ] .",
    "@xmath413 \\leq   2^{-\\omega(n\\min(s , s^2))}$ ] .    for bound @xmath414",
    ", using the triangle inequality and lemma [ lem : exacthess ] , we have that @xmath415 it now suffices to bound the probability that @xmath416 . for this , note that @xmath417 by lemma  [ lem : subgaussian ] , @xmath418 are subgaussian random variables with parameter 1 .",
    "it follows from lemma  [ lem : subgausssquared ] that @xmath419 is subexponential with parameter @xmath420 .",
    "then , applying lemma  [ lem : subexp ] , @xmath421 \\leq 2^{1-\\omega(n\\min(s , s^2 ) ) } , \\;\\ ] ] for any @xmath408 . by lemma  [ lem : smallnet ] , there is a @xmath422-net of the unit sphere @xmath112 with @xmath423 .",
    "taking union bound over @xmath112 and applying lemma  [ lem : deltaeigenvalues ] gives @xmath424 \\leq 2^{-\\omega(n\\min(s , s^2 ) ) + o(n ) } = 2^{-\\omega(n\\min(s , s^2 ) ) } \\ ; \\text{,}\\ ] ] by our assumption that @xmath425 .    for bound @xmath426 , using the triangle inequality as above , we have that @xmath427 by equation  , we know that @xmath428 with probability at most @xmath429 . hence it suffices to prove that @xmath430 , for some @xmath11 , with probability at most @xmath431 .    using the inequality @xmath432 and cauchy - schwarz",
    ", we have that @xmath433 it now suffices to bound the sum in the last expression with probability @xmath277 .",
    "let @xmath434 : \\length{{\\ensuremath{\\mathbf{w}}}_i } \\geq e^j \\sqrt{n}}$ ] , for @xmath435 .",
    "using lemma  [ lem : strong - tailbound ] , we have that @xmath436 = n \\pr[\\length{{\\ensuremath{\\mathbf{w}}}_i } \\geq e^j \\sqrt{n } ] \\leq",
    "n e^{-\\frac{n}{2}(\\sqrt{2\\pi}e^j-1)^2 } \\leq n e^{-n e^{2j } } \\text{.}\\ ] ] by markov s inequality , @xmath437 \\leq e^{-n(j+1)}$ ] . by the union bound ,",
    "the event @xmath438 , @xmath439 , occurs with probability at least @xmath440 . conditioning on this event",
    ", we will show the desired bound .    for all @xmath441",
    "$ ] , we have that @xmath442 . using this , we get that @xmath443 plugging in gives @xmath444 .    for bound @xmath445",
    ", we simply note that @xmath446 the bound now follows from equation , the fact that @xmath447 ( lemma  [ lem : exacthess ] ) , and the triangle inequality .",
    "the following lemma establishes strong continuity properties for @xmath31 , @xmath406 , and their respective approximations .",
    "[ lem : lipshitz ] let @xmath25 be a lattice . then , for all @xmath448 ,    1 .",
    "2 .   @xmath450 .",
    "let @xmath407 be sampled independently from @xmath36 .",
    "then for @xmath226 , @xmath451 , the following both hold simultaneously for all @xmath448 with probability at least @xmath452 .    1 .",
    "@xmath453 2 .",
    "@xmath454    by lemma  [ lem : exacthess ] , we have that @xmath455 for all @xmath456 . from this",
    ", we get that @xmath457 since @xmath458 , using the above we get that @xmath459 , for all @xmath456 . using this inequality",
    ", we get that @xmath460    for the second part , by lemma  [ lem : hess ] the event @xmath461 , for all @xmath456 , holds with probability @xmath462 .",
    "the claim now follows by the same proof as above replacing @xmath31 by @xmath42 .",
    "[ lem : verycloset ] let @xmath25 be a lattice with @xmath272 for @xmath273 .",
    "let @xmath275 be sampled independently from @xmath36 with @xmath463 .",
    "then , @xmath464 \\leq 2^{-\\omega(n)}\\ ; .\\ ] ]    let @xmath465 as in lemma  [ lem : hess ] , and note that @xmath466 for @xmath280 . then , by lemma",
    "[ lem : hess ] , setting @xmath467 , we have that @xmath468 holds simultaneously for all @xmath469 with @xmath470 with probability at least @xmath277 .",
    "suppose this holds .",
    "noting that @xmath471 , it follows that for all @xmath472 , @xmath473 , we have that @xmath474{\\int_0 ^ 1 hf_w(r{\\ensuremath{\\mathbf{x}}}'){\\ensuremath{\\mathbf{x}}}'dr + 2\\pi { \\ensuremath{\\mathbf{x } } } ' } = \\length[\\big]{\\int_0 ^ 1 ( hf_w(r{\\ensuremath{\\mathbf{x}}}')+2\\pi i_n){\\ensuremath{\\mathbf{x}}}'dr } \\\\ & \\leq \\length{{\\ensuremath{\\mathbf{x}}}'}\\int_0 ^ 1 \\length{hf_w(r{\\ensuremath{\\mathbf{x}}}')+2\\pi i_n}dr \\leq 4{\\varepsilon}^{1/4 } \\cdot\\length{{\\ensuremath{\\mathbf{x } } } ' } \\ ; .\\end{aligned}\\ ] ]    in particular , @xmath475 .",
    "since @xmath476 , it follows that for any @xmath12 with @xmath477 , we have @xmath478    putting it all together , @xmath479 as needed .    [",
    "claim : fraction_id_impr ] let @xmath261 and @xmath25 be a lattice with @xmath480 . let @xmath481 , @xmath482 , and @xmath483 be vectors in @xmath35 .",
    "suppose that for some @xmath484 and @xmath11 it holds that    1 .",
    "@xmath485 , 2 .",
    "@xmath486 , and 3 .",
    "@xmath487 .",
    "then , @xmath488    by lemma  [ lem : betterrholtbound ] and the first assumption , we see that @xmath489 .    by the triangle inequality @xmath490 for the first term in  , by the second and third assumption",
    ", we have @xmath491 for the second term in  , by corollary  [ cor : simpleexpectbound ] and the first and third assumption , @xmath492 combining , , and together , we have @xmath493 as needed .",
    "[ lem : gradestimator]for @xmath25 a lattice , @xmath494 sampled independently from @xmath36 , @xmath11 , and @xmath408 , @xmath495 \\leq 2^{-\\omega(n\\min(s , s^2 ) ) + o(n ) }   \\ ; .\\ ] ]    for any @xmath221 and any unit vector @xmath355 , @xmath496 it follows from the subgaussianity of the discrete gaussian and corollary  [ cor : subgaussianproduct ] that @xmath497 is subexponential with parameter @xmath420 . applying lemma  [ lem : subexp ]",
    ", we get that    @xmath498 \\leq 2^{1-\\omega(n\\min(s , s^2 ) ) } \\ ; .\\ ] ] by lemma  [ lem : smallnet ] , there is a @xmath499-net of the sphere , @xmath112 with @xmath423 .",
    "taking a union bound over @xmath112 and applying lemma  [ lem : deltanorm ] gives @xmath500 \\leq 2^{-\\omega(n\\min(s , s^2 ) ) + o(n)},\\ ] ] as needed .",
    "[ lem : gradcloseallpoints ] let @xmath25 be a lattice with @xmath272 with @xmath261 .",
    "let @xmath263 .",
    "let @xmath494 be sampled independently from @xmath36 .",
    "then , for @xmath501 , if @xmath502 , @xmath503 \\leq 2^{-\\omega(ns^2 ) } \\ ; .\\ ] ]    we wish to find a set a vectors @xmath504 such that for any @xmath12 with @xmath505 , there is a @xmath506 with @xmath507 .",
    "for @xmath508 to @xmath509 , let @xmath510 be a @xmath511-net of the shell of inner radius radius @xmath512 and outer radius @xmath513 .",
    "by lemma  [ lem : smallnet ] , we can take @xmath514 .",
    "let @xmath515 .",
    "there are @xmath516 such nets , so @xmath517 .",
    "we show that two bounds hold with high probability .    1 .   by lemma  [ lem : lipshitz ]",
    ", @xmath518 holds simultaneously for all @xmath519 with probability at least @xmath520 .",
    "2 .   by lemma  [ lem : gradestimator ] and union bound over @xmath112",
    ", @xmath521 holds simultaneously for all @xmath522 with probability at least @xmath523 .",
    "suppose that both bounds hold , which happens with probability at least @xmath524 .",
    "for a target vector @xmath12 with @xmath525 , let @xmath522 be the closest vector to @xmath12 in @xmath112 .",
    "then , by the first bound , @xmath526 . again , using lemma  [ lem : lipshitz ] , @xmath527 . applying triangle inequality repeatedly and noting that @xmath528 , @xmath529    [ lem : festimator ] for a lattice @xmath25 , @xmath494 sampled independently from @xmath36 , @xmath11 , and @xmath408 , @xmath530 \\leq 2^{1-\\omega(ns^2 ) }",
    "\\ ; .\\ ] ]    the result follows immediately from lemma  [ lem : chernoff ] ( the chernoff - hoeffding bound ) and the definitions of @xmath297 and @xmath29 ( see eqs .   and  ) .",
    "[ lem : festimatorallpoints ] let @xmath25 be a lattice with @xmath272 for @xmath261 .",
    "let @xmath263 .",
    "let @xmath494 be sampled independently from @xmath36 .",
    "then , for @xmath531 , if @xmath532 , @xmath533 \\leq 2^{-\\omega(ns^2 ) }   \\ ; .\\ ] ]    our proof is quite similar to that of lemma  [ lem : gradcloseallpoints ]",
    ". let @xmath112 be a @xmath534-net of the ball of radius @xmath535 .",
    "by lemma  [ lem : smallnet ] , and since @xmath536 , we can take @xmath537 .",
    "the following events hold with high probability .    1 .   by lemma  [ lem : lipshitz ] , we have that @xmath538 holds simultaneously for all @xmath539 with @xmath540 with probability at least @xmath520 .",
    "2 .   by lemma  [ lem : festimator ] and",
    "union bound , we have that @xmath541 holds simultaneously for all @xmath506 with probability at least @xmath542 .",
    "suppose that both bounds hold , which happens with probability at least @xmath543 .",
    "for a target vector @xmath12 with @xmath544 , let @xmath522 be the closest point to @xmath12 in @xmath112 .",
    "from the first event , we have that @xmath545 .",
    "similarly , by lemma  [ lem : lipshitz ] , we have @xmath546 . then , using the triangle inequality , @xmath547    lemma  [ lem : verycloset ] shows that the proposition is satisfied for all @xmath12 with @xmath477 with probability at least @xmath277 .",
    "so , we consider the case when @xmath548 . by lemma  [ lem : betterrholtbound ] , for such @xmath12 , @xmath549",
    "we first show that the estimators @xmath550 are close to their expectations .    1 .   by lemma  [ lem : gradcloseallpoints ] , we have that @xmath551 holds simultaneously for all @xmath12 with @xmath552 with probability at least @xmath553 .",
    "2 .   by lemma  [ lem : festimatorallpoints ]",
    ", we have that @xmath554 holds simultaneously for all relevant @xmath12 with probability at least @xmath555 .",
    "suppose that both of these bounds hold , which happens with probability at least @xmath556 .",
    "then , applying claim  [ claim : fraction_id_impr ] with @xmath557 , we have that for all relevant @xmath12 , @xmath558 as needed . in the next - to - last inequality we used the straightforward inequality @xmath559 .",
    "in this section , we present our kannan - style reductions from @xmath560 to @xmath561 .",
    "[ thm : cvpptopromise ] let @xmath562 , and let @xmath65 be a non - increasing function .",
    "then , a polynomial - time algorithm that solves @xmath143 , where @xmath563 for any lattice @xmath10 of rank @xmath7 , implies a polynomial - time algorithm that solves @xmath564 , where @xmath565 with the convention that @xmath566 . in particular , if @xmath567 and @xmath568 , we have @xmath569 .",
    "the reduction of theorem  [ thm : cvpptopromise ] uses as preprocessing an hkz basis and the preprocessing of the underlying @xmath561 algorithm on @xmath7 lattices of dimension @xmath6 , so it incurs a blowup of roughly @xmath7 in the size of the preprocessing .",
    "we now present a more elaborate reduction based on similar ideas that incurs almost no blowup in the size of preprocessing for an appropriate setting of parameters .",
    "[ thm : mastertheorem ] let @xmath570 be a non - increasing function and @xmath571 be a non - decreasing function .",
    "let @xmath572 where @xmath573 is a non - decreasing integer - valued function satisfying @xmath574 .",
    "let @xmath575 and @xmath576 for any lattice @xmath10 of rank @xmath7 .",
    "then , a polynomial - time algorithm that solves @xmath143 implies a polynomial - time algorithm that solves @xmath564 using as preprocessing only an hkz basis of the input lattice and the preprocessing of the @xmath143 algorithm for a collection of lattices @xmath577 with @xmath578 , where @xmath7 is the dimension of the input lattice .    of particular interest to us",
    "is the special case @xmath579 and @xmath580 in theorem  [ thm : mastertheorem ] , which we highlight in the following corollary . with these parameters ,",
    "the reduction achieves @xmath581 , which is intuitively optimal .",
    "[ cor : cvpptobdd ] let @xmath582 be a non - increasing function and define @xmath568 .",
    "then , there is a polynomial - time reduction from @xmath142 to @xmath145 that uses as preprocessing an hkz basis of the input lattice and the preprocessing of the @xmath145 algorithm for a collection of lattices @xmath577 with @xmath581 , where @xmath7 is the dimension of the input lattice .",
    "another interesting special case , obtained by setting @xmath583 and @xmath584 , gives a reduction that matches the approximation factor @xmath70 achieved by theorem  [ thm : cvpptopromise ] up to a factor of @xmath310 but incurs only a logarithmic blow - up in preprocessing , @xmath585 ( as opposed to linear ) .",
    "finally , setting @xmath586 and @xmath587 for any integer @xmath588 gives a reduction with @xmath589 that achieves @xmath590 blow - up , @xmath591 .",
    "lastly , we show that similar ideas can be made to work without preprocessing with worse parameters .    [ prop : cvptocvpreduction ] let @xmath592 where @xmath571 is a non - decreasing function .",
    "let @xmath138 for any lattice .",
    "then , there is a polynomial - time reduction from @xmath125 to @xmath593 .",
    "suppose that we have an efficient algorithm that solves @xmath143 with preprocessing algorithm @xmath594 and query algorithm @xmath595 .",
    "we assume without loss of generality that @xmath596 .",
    "we construct an algorithm that solves @xmath564 as follows .    on input @xmath25",
    ", the preprocessing algorithm first computes an hkz basis @xmath597 of @xmath10 . for @xmath598 ,",
    "let @xmath599 and @xmath600 . then , the preprocessing algorithm returns as its advice @xmath81 and the advice strings @xmath601 for all @xmath221 .    on input @xmath11 ,",
    "the query algorithm does the following for each @xmath602 .",
    "it computes @xmath603 .",
    "write @xmath604 for some coefficients @xmath605 and let @xmath606 be a `` lift '' of @xmath607 .",
    "let @xmath608 and @xmath609 the query algorithm then returns the vector nearest to the target @xmath12 among the vectors @xmath610 .",
    "in other words , for each @xmath602 , we use @xmath611 to compute a close point to @xmath12 in @xmath612 , and output the closest .    clearly , the advice from preprocessing has polynomial length and the query algorithm runs in polynomial time .",
    "let @xmath613 be minimal such that @xmath614 , where @xmath236 is the gram - schmidt orthogonalization of @xmath81 . if no such @xmath221 exists , we take @xmath221 to be @xmath7 .",
    "we will complete the proof by showing that @xmath615 is close to @xmath12 . by separating the norm into its projection on the two orthogonal subspaces , @xmath616 for the first term , using the definition of @xmath143 and our choice of @xmath221 , we have that @xmath617 for the second term , by lemma  [ lem : babai ] and again by our choice of @xmath221 , @xmath618 the theorem follows by combining the two inequalities .",
    "suppose that we have an algorithm that solves @xmath143 in polynomial time with preprocessing algorithm @xmath594 and query algorithm @xmath595 .",
    "we construct an algorithm that solves @xmath564 as follows .    on input @xmath25 a lattice of rank @xmath7",
    ", the preprocessing algorithm first computes an hkz basis @xmath597 of @xmath10 with gram - schmidt orthogonalization @xmath236 .",
    "fix @xmath619 and @xmath620 .",
    "we define a series of indices @xmath621 in the following recursive way : for each @xmath622 such that @xmath623 , define @xmath624 to be minimal such that @xmath625 or equivalently , the largest such that @xmath626 notice that we have @xmath627 let @xmath628 and @xmath629 .",
    "then , the preprocessing algorithm returns as its advice @xmath81 and the advice strings @xmath630 for all @xmath622 . notice that each vector @xmath631 is included in the definition of @xmath632 for at most @xmath633 different values of @xmath622 . as a result , @xmath634 as claimed .",
    "let @xmath635 . before describing the query algorithm",
    ", we define a key recursive sub - procedure @xmath636 that will be used to find solutions to @xmath637 . on input @xmath12 and @xmath622 , if @xmath638 , then @xmath639 simply outputs @xmath640 .",
    "otherwise , it calls itself recursively , setting @xmath641 .",
    "write @xmath642 , and let @xmath643 be a `` lift '' of @xmath469 . then @xmath639 outputs @xmath644 . in other words , @xmath639 uses @xmath595 to find a close point to @xmath645 in @xmath646 and outputs it .    on input",
    "@xmath11 , the query algorithm does the following for each @xmath622 .",
    "it first computes @xmath647 .",
    "let @xmath648 be a `` lift '' of @xmath649 .",
    "let @xmath650 and @xmath651 the query algorithm then returns the vector nearest to the target @xmath12 among the vectors @xmath652 . in other words , for each @xmath622 , we use @xmath611 to compute a close point to @xmath12 in @xmath653 , and output the closest .",
    "it is clear that the algorithm runs in polynomial time .",
    "first , assume that @xmath636 returns a valid solution to @xmath637 .",
    "then , the proof of correctness proceeds nearly identically to that of theorem  [ thm : cvpptopromise ] .",
    "in particular , let @xmath654 be maximal such that @xmath655 . if no such @xmath622 exists , we take @xmath656 . as in the previous proof , @xmath657 for the first term , since @xmath658",
    ", we have @xmath659 for the second term , by lemma  [ lem : babai ] , eq .  , and our choice of @xmath622 , @xmath660 combining the two inequalities",
    ", we get @xmath661 .",
    "it remains to show that the sub - procedure @xmath636 returns a valid solution to @xmath637 .",
    "we prove this by induction .",
    "if @xmath662 , the claim follows immediately from the fact that @xmath663 . otherwise , we claim that @xmath664 contains the closest vector to @xmath645 in @xmath665 .",
    "this claim immediately implies the correctness of @xmath639 using the correctness of @xmath595 and the fact that @xmath666 and @xmath667 . to prove the claim , first notice from eqs .   and   that @xmath668 , and so @xmath669 as a result , @xmath670 , and so by the induction hypothesis and eq .",
    ", @xmath671 so , @xmath469 is the unique closest vector in @xmath672 to @xmath673 .",
    "finally , by eq .  , @xmath674 , yet all vectors @xmath675 must be at distance at least @xmath676 from @xmath645 and hence can not be closest to @xmath645 in @xmath665 .",
    "let @xmath677 be an algorithm solving @xmath593 .",
    "we say that a basis @xmath100 of @xmath10 is a @xmath678-hkz basis if @xmath679 and @xmath680 is a @xmath678-hkz basis .",
    "note that theorem  [ thm : svptocvp ] immediately implies that @xmath677 can be used to compute a @xmath678-hkz basis in polynomial time .    on input @xmath10 and target vector @xmath12 , first use @xmath677 to compute a @xmath678-hkz basis , @xmath100 of @xmath10 . then , as in the proof of theorem  [ thm : cvpptopromise ] , for @xmath598 , let @xmath599 and @xmath600 .",
    "compute @xmath681 and lift it to a vector @xmath682 .",
    "similarly , let @xmath608 and @xmath609 finally , return the vector nearest to the target @xmath12 among the vectors @xmath610 .",
    "let @xmath613 be minimal such that @xmath683 . if no such @xmath221 exists , we take @xmath684 . as in the proof of theorem  [ thm : cvpptopromise ] , @xmath685 by our choice of @xmath221 and the definition of a @xmath678-hkz basis , @xmath686",
    ", so @xmath112 is guaranteed to output @xmath607 satisfying @xmath687 where we define @xmath688 . by lemma  [ lem : babai ] , @xmath689 combining the two inequalities",
    "gives @xmath690 as claimed .",
    "in this section we prove theorem  [ thm : cvpreduction ] , our second reduction to the bounded distance case .",
    "[ thm : cvpreduction ] for any @xmath691 and @xmath68 , there is a randomized polynomial - time reduction from @xmath692 to @xmath136 where @xmath693 .",
    "note that for @xmath694 , proposition  [ prop : cvptocvpreduction ] provides a strictly stronger reduction .",
    "the above theorem and theorem  [ thm : cvphard ] ( the np - hardness of @xmath695 ) immediately imply a hardness result for @xmath136 .",
    "[ cor : hardnessofcvp ] there exists a constant @xmath696 such that @xmath136 is np - hard for @xmath697 and @xmath133 .",
    "we follow the sparsification idea of  @xcite .",
    "basically , given a target @xmath12 , we try to find a sublattice @xmath698 of @xmath10 , such that @xmath698 has minimum distance proportional to @xmath699 with @xmath699 not much larger than @xmath700 .",
    "notice that the first condition is needed to ensure that a distance - bounded solver will succeed on @xmath698 and @xmath12 , and the second condition allows us to bound the loss in approximation when passing from @xmath10 to @xmath698 .",
    "implicit in the work of  @xcite is the fact that a random sublattice @xmath698 of @xmath10 of index @xmath701 ( for an appropriate @xmath701 ) will work . to obtain the approximation factor stated in the theorem",
    ", we actually work with a random coset of @xmath698 , and we also do a slightly more careful analysis in order to avoid the loss incurred by a triangle inequality .    for a full rank lattice @xmath10 with basis @xmath81 , a prime @xmath701 , a vector @xmath702 , and @xmath703 ,",
    "we define @xmath704 and @xmath705 .",
    "note that @xmath706 is a sublattice of @xmath10 and @xmath707 is a coset of @xmath706 .",
    "we wish to argue that , for any @xmath12 and appropriate @xmath701 , if @xmath708 and @xmath709 are chosen uniformly at random , then with constant positive probability , @xmath710 will be relatively large but @xmath711 will be relatively close to @xmath712 .",
    "the next lemma is a modification of ( * ? ? ?",
    "* lemma 4.3 ) more suited to our purposes and is the key to the reduction .",
    "[ lem : shortcosets ] let @xmath713 , @xmath25 a full rank lattice with basis @xmath81 , @xmath714 , and @xmath715 a prime .",
    "let @xmath716 be sampled uniformly from @xmath717 , and define @xmath718 then ,    * @xmath719 \\leq \\frac{n}{p}$ ] , and * @xmath720 \\leq { \\varepsilon}$ ] for any @xmath183 .",
    "first , we wish to show that for any @xmath721 , @xmath722 is uniformly distributed mod @xmath701 over the choice of @xmath723 let @xmath724 and @xmath725 . then , @xmath726 .",
    "so , it suffices to show that at least one @xmath727 is not @xmath728 mod @xmath701 , or equivalently that @xmath729 .",
    "suppose @xmath730 .",
    "then there is some @xmath731 such that @xmath732 , so clearly the vectors @xmath733 are all in @xmath734 .",
    "this contradicts the fact that there are exactly @xmath735 vectors in @xmath734 .",
    "it follows that @xmath722 is uniformly distributed mod @xmath701 over the choice of @xmath708 .",
    "now , to prove the first result , let @xmath736 . since @xmath722 is uniformly distributed mod @xmath701 , @xmath737 = 1/p$ ] .",
    "we simply apply union bound and recall the definition of @xmath41 to get @xmath738 \\leq n / p $ ] as claimed .    to prove the second result , for @xmath739 let @xmath740 , and let @xmath741 the set of pairs of short vectors in the same coset .",
    "then , recalling the definition of @xmath41 and applying cauchy - schwarz , @xmath742 therefore @xmath743 .",
    "so , it suffices to bound @xmath744 $ ] .",
    "let @xmath745 be distinct .",
    "since @xmath746 , it follows that @xmath747 is uniformly distributed mod @xmath701 over the choice of @xmath708 .",
    "so , @xmath748 = 1/p $ ] .",
    "therefore , @xmath749 = n + n(n-1)/p = n\\cdot \\frac{p+n-1}{p } \\ ; .\\ ] ] applying markov s inequality , @xmath750 \\leq { \\varepsilon}\\;,\\ ] ] and the result follows .",
    "let @xmath751 be an algorithm that solves @xmath136 .",
    "our input is a lattice @xmath96 with basis @xmath81 and target vector @xmath11 .",
    "we assume without loss of generality that @xmath10 is full rank .",
    "let @xmath752 , and @xmath753 .",
    "our reduction needs to have a prime number @xmath701 satisfying @xmath754 .",
    "since we do not know @xmath41 , we simply run the reduction with each of polynomially many values for @xmath701 , one of which is guaranteed to be in the right range , and then output the closest of all lattice vectors we find .",
    "in more detail , assume @xmath755 since otherwise the reduction already follows from proposition  [ prop : cvptocvpreduction ] . by lemma  [ lem : bitlength ] and a simple packing argument , @xmath41 is at most @xmath756 for some fixed polynomial in the bit length @xmath97 of the description of @xmath10 .",
    "so it suffices to try for each @xmath757 , a prime @xmath701 with @xmath758 .",
    "we now continue with the description of the reduction assuming we know a prime @xmath701 satisfying @xmath754 .    with this , the reduction is straightforward .",
    "it samples @xmath759 and @xmath760 uniformly at random .",
    "it then returns @xmath761 where @xmath48 is an arbitrary point in @xmath762 .",
    "i.e. , we find a close vector to @xmath12 in the coset @xmath762 . by lemma  [ lem : shortcosets ] ,",
    "we have that @xmath763 and @xmath764 where @xmath765 with probability at least @xmath766 over the choice of @xmath708 .",
    "suppose both of these hold .",
    "let @xmath767 be the closest lattice vector to @xmath12 , and for each coset @xmath768 , let @xmath769 be a closest vector in @xmath770 to @xmath771 .",
    "if there are multiple choices for @xmath772 , we take one that maximizes @xmath773 .",
    "we wish to argue that , with positive constant probability over the choice of the random coset @xmath709 , both ( 1 ) @xmath774 and ( 2 ) @xmath775 hold .",
    "since @xmath776 is a uniformly distributed random coset , our assumption on @xmath777 implies that at least @xmath778 cosets satisfy condition ( 1 ) .",
    "let @xmath779 be such that @xmath780 .",
    "note that for all @xmath768 , @xmath781 is a closest vector to @xmath469 in @xmath782 .",
    "it follows that @xmath783 , and if @xmath784 , then @xmath785 .",
    "it follows that for each coset @xmath768 that satisfies ( 1 ) but not ( 2 ) , @xmath786 satisfies both ( 1 ) and ( 2 ) . since the map @xmath787 is a bijection on @xmath788 , we obtain that with probability @xmath789 over the choice of the coset @xmath709 , both ( 1 ) and ( 2 ) hold .",
    "when this is the case , by expanding the squared norm as an inner product , we have @xmath790 finally , note that @xmath791 .",
    "so , by the definition of @xmath751 , the distance of our output from @xmath12 is at most @xmath792 it follows that the reduction succeeds with probability at least @xmath793 .",
    "[ claim : localmaxima ] for any sufficiently large @xmath7 there exists a lattice @xmath25 such that the function @xmath31 has a local maximum that is not a global one .",
    "furthermore , the local maximum is at distance @xmath794 from the lattice , and the value of @xmath31 at this point is exponentially close to @xmath46 ( the value at global maxima ) .",
    "let @xmath795 be the standard basis of @xmath9 , and let @xmath796 .",
    "note that the shortest non - zero vectors of @xmath10 are of the form @xmath797 , @xmath798 , and hence @xmath799 .",
    "then , it is easy to see that @xmath800 , where @xmath801 .",
    "let @xmath12 be any point in @xmath802 , say @xmath803 .",
    "note that @xmath804 . since @xmath31 is a periodic function and @xmath805 , @xmath806 . on the other hand",
    ", @xmath406 is an odd function , and therefore @xmath807 .",
    "we will now show that @xmath29 approaches @xmath808 as @xmath7 approaches @xmath809 by exploiting the multiplicative structure of @xmath810 on @xmath56 and @xmath811 . in particular , @xmath812 and @xmath813 .",
    "so , @xmath814\\\\ & = \\frac{1}{\\rho({\\mathcal{l}}^*)}\\cdot(\\rho({\\ensuremath{\\mathbb{z}}}^n ) - \\rho({\\ensuremath{\\mathbb{z}}}^n + { \\ensuremath{\\mathbf{u}}}))\\\\ & = \\frac{1}{\\rho({\\mathcal{l}}^*)}\\cdot\\big(\\rho({\\ensuremath{\\mathbb{z}}})^n - \\rho({\\ensuremath{\\mathbb{z}}}+ 1/2)^n\\big ) \\ ; .\\end{aligned}\\ ] ] similarly , we have that @xmath815 since , @xmath816 the difference between @xmath817 and @xmath29 is exponentially small in @xmath7 .",
    "it remains to show that @xmath338 is negative definite .",
    "note that @xmath818\\\\ & = -\\frac{4\\pi^2}{\\rho({\\mathcal{l}}^ * ) } \\cdot \\big ( \\sum_{{\\ensuremath{\\mathbf{z } } } \\in { \\ensuremath{\\mathbb{z}}}^n}{\\ensuremath{\\mathbf{z } } } { \\ensuremath{\\mathbf{z}}}^t\\rho({\\ensuremath{\\mathbf{z } } } ) - \\sum_{{\\ensuremath{\\mathbf{z } } } \\in { \\ensuremath{\\mathbb{z}}}^n + { \\ensuremath{\\mathbf{u}}}}{\\ensuremath{\\mathbf{z } } } { \\ensuremath{\\mathbf{z}}}^t\\rho({\\ensuremath{\\mathbf{z } } } ) \\big ) \\ ; .\\end{aligned}\\ ] ] again exploiting the multiplicative structure of @xmath810 on @xmath56 and @xmath811 , we have @xmath819 a similar calculation shows that @xmath820 the result then follows by again noting that @xmath816 , so for sufficiently large @xmath7 , the @xmath821 term dominates .",
    "( in fact , @xmath822 suffices . )",
    "s.  khot .",
    "inapproximability results for computational problems on lattices . in p.",
    "q. nguyen and b.  valle , editors , _ the lll algorithm _ , information security and cryptography , pages 453473 .",
    "springer berlin heidelberg , 2010 .",
    "liu , v.  lyubashevsky , and d.  micciancio . on bounded distance decoding for general lattices . in _ international workshop on randomization and computation - proceedings of random 2006 _ , volume 4110 of _ lecture notes in computer science _ ,",
    "pages 450461 .",
    "springer , barcellona , spain , august 2006 .",
    "d.  micciancio and s.  goldwasser . _",
    "complexity of lattice problems : a cryptographic perspective _ ,",
    "volume 671 of _ the kluwer international series in engineering and computer science_. kluwer academic publishers , boston , massachusetts , march 2002 .",
    "d.  micciancio and c.  peikert .",
    "trapdoors for lattices : simpler , tighter , faster , smaller . in d.",
    "pointcheval and t.  johansson , editors , _ advances in cryptology ",
    "eurocrypt 2012 _ , volume 7237 of _ lecture notes in computer science _ , pages 700718 .",
    "springer berlin heidelberg , 2012 .",
    "d.  micciancio and p.  voulgaris . a deterministic single exponential time algorithm for most lattice problems based on voronoi cell computations .",
    "_ siam journal on computing _",
    ", 42(3):13641391 , 2013 .",
    "preliminary version in stoc10 .",
    "o.  regev . on the complexity of lattice problems with polynomial approximation factors . in p.",
    "q. nguyen and b.  valle , editors , _ the lll algorithm _ , information security and cryptography , pages 475496 .",
    "springer berlin heidelberg , 2010 .",
    "r.  vershynin .",
    "ntroduction to the non - asymptotic analysis of random matrices . in y.",
    "eldar and g.  kutyniok , editors , _ compressed sensing : theory and applications _",
    ", pages 210268 .",
    "cambridge univ press , 2012 ."
  ],
  "abstract_text": [
    "<S> we present a substantially more efficient variant , both in terms of running time and size of preprocessing advice , of the algorithm by liu , lyubashevsky , and micciancio  @xcite for solving ( the preprocessing version of the closest vector problem , ) with a distance guarantee . </S>",
    "<S> for instance , for any @xmath0 , our algorithm finds the ( unique ) closest lattice point for any target point whose distance from the lattice is at most @xmath1 times the length of the shortest nonzero lattice vector , requires as preprocessing advice only @xmath2 vectors , and runs in time @xmath3 .    as our second main contribution , we present reductions showing that it suffices to solve , both in its plain and preprocessing versions , when the input target point is within some bounded distance of the lattice . </S>",
    "<S> the reductions are based on ideas due to kannan  @xcite and a recent sparsification technique  @xcite . </S>",
    "<S> combining our reductions with the llm algorithm gives an approximation factor of @xmath4 for search , improving on the previous best of @xmath5 due to lagarias , lenstra , and schnorr  @xcite . </S>",
    "<S> when combined with our improved algorithm we obtain , somewhat surprisingly , that only @xmath6 vectors of preprocessing advice are sufficient to solve with ( the only slightly worse ) approximation factor of @xmath6 . </S>"
  ]
}