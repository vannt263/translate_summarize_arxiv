{
  "article_text": [
    "properly designed low - density parity - check ( ldpc ) codes , decoded using efficient message - passing belief propagation ( bp ) decoders , achieve near shannon limit performance in the so - called `` water - fall '' regime where the signal - to - noise ratio ( snr ) is near the code threshold @xcite . unfortunately , bp decoders of ldpc codes often suffer from `` error floors '' in the high snr regime , which is a significant problem for applications that have extreme reliability requirements , including magnetic recording and fiber - optic communication systems .",
    "there has been considerable effort in trying to find ldpc codes and decoders that have improved error floors while maintaining good water - fall behavior . in general ,",
    "such work can be divided into two approaches .",
    "the first line of attack tries to construct codes or representations of codes that have improved error floors when decoded using bp .",
    "error floors in ldpc codes using bp decoders are usually attributed to closely related phenomena that go under the names of `` pseudocodewords , '' `` near - codewords , '' `` trapping sets , '' `` instantons , '' and `` absorbing sets '' @xcite@xcite@xcite@xcite@xcite@xcite .",
    "the number of these trapping sets ( to choose one of these terms ) , and therefore the error floor performance , can be improved by removing short cycles in the code graph @xcite@xcite@xcite .",
    "one can also consider special classes of ldpc codes with fewer trapping sets , such as eg - ldpc codes @xcite , or generalized ldpc codes @xcite@xcite .",
    "the second approach , taken herein , is to try to improve upon the sub - optimal bp decoder .",
    "this approach is logical because already when he introduced regular ldpc codes , gallager showed that they have excellent distance properties and therefore will not have error floors if decoded using optimal maximum - likelihood ( ml ) decoding @xcite .",
    "building on the theory of trapping sets , han and ryan propose a `` bi - mode syndrome - erasure decoder . ''",
    "this decoder can improve error floor performance given the knowledge of dominant trapping sets @xcite .",
    "however , determining the dominant trapping sets of a particular code can be a challenging task .",
    "another recently introduced improved decoder is the mixed - integer linear programming ( milp ) decoder @xcite , which requires no information about trapping sets and approaches ml performance , but with a large decoding complexity . to deal with the complexity of the milp decoder ,",
    "a multi - stage decoder is proposed in @xcite , where very fast but poor - performing decoders are combined with the more powerful but much slower milp decoder .",
    "the result is a decoder that performs as well as the milp decoder and with a high average throughput .",
    "this multi - stage decoder nevertheless poses considerable practical difficulties for certain applications in that it requires implementation of multiple decoders , and the worst - case throughput will be as slow as the milp decoder .",
    "our goal in this paper is to develop decoders that perform much better in the error floor regime than bp , but with comparable complexity , and no significant disadvantages .",
    "our starting point is the iterative `` divide and concur '' ( dc ) algorithm recently proposed by gravel and elser @xcite for constraint satisfaction problems .",
    "when using dc , one first describes a problem as a set of variables and local constraints on those variables .",
    "one then introduces `` replicas '' of the variables ; one replica for each constraint a variable is involved in . the dc algorithm",
    "then iteratively performs `` divide '' projections which move the replicas to the values closest to their current values that also satisfy the local constraints , and `` concur '' projections which equalize the values of the different replicas of the same variable . a key idea in the dc algorithm",
    "is to avoid local traps in the dynamics by using the so - called `` difference - map '' ( dm ) combination of `` divide '' and `` concur '' projections at each iteration .",
    "ldpc codes have a structure that make them a good fit for the dc algorithm .",
    "in fact , gravel reported on a dc decoder for ldpc codes in his ph.d .",
    "thesis , although his simulations were very limited in scope @xcite .",
    "we were curious about whether a dc decoder could be competitive with  or better than  more standard bp decoders .",
    "we were particularly motivated by the idea that the `` traps '' that the dc algorithm s `` difference - map '' dynamics promises to avoid might be related to the `` trapping sets '' that plague bp decoders of ldpc codes .    to construct a dc decoder , we need to add an important `` energy '' constraint , in addition to the more obvious parity check constraints .",
    "the energy constraint enforces that the correlation between the channel observations and the desired codeword should be at least some minimum amount .",
    "the effect of this constraint is to ensure that during the decoding process the candidate solution does not wander too far from the channel observation .",
    "we found that the dc decoder can be competitive with bp decoders , but only if many iterations are allowed .",
    "unfortunately , dc errors are often `` undetected errors '' in that the decoder returns a codeword that is not the most likely one .",
    "failures of bp decoding , in contrast , almost always correspond to failures to converge or convergence to a non - codeword , and therefore are detectable .",
    "we show how the dc decoder can be described as a message - passing algorithm . using this formulation",
    ", we can see how to import the difference - map idea into a bp setting .",
    "we thus also constructed a novel decoder called the `` difference - map belief propagation '' ( dmbp ) decoder . essentially , dmbp is a min - sum bp decoder with modified dynamics motivated by the dc decoder .",
    "our simulations show that the dmbp decoder improves performance in the error floor regime quite significantly when compared with standard sum - product belief propagation ( bp ) decoders .",
    "we present results for both the additive white gaussian noise ( awgn ) channel and the binary symmetric channel ( bsc ) .",
    "the rest of the paper is organized as follows . in section",
    "ii , the dc algorithm is presented , and re - formulated as a message - passing algorithm .",
    "the dc decoder for ldpc codes is described in section iii .",
    "the dmbp algorithm is introduced in section iv . in section",
    "v we present simulation results .",
    "conclusions are given in section vi .",
    "in this section , we review gravel and elser s `` divide and concur '' ( dc ) algorithm . gravel and elser",
    "did _ not _ formulate dc as a message - passing algorithm , or otherwise compare dc to bp , but the comparison is illuminating , and helped us design the dmbp decoder .",
    "thus we present dc in a way that is consistent with gravel and elser s presentation , but makes comparisons to bp easier .",
    "we start by introducing the idea of `` replicas '' in section  [ replicasap ] in the context of the familiar alternating projection approach to constrained satisfaction problems . in section  [ dmsec ]",
    "we introduce and discuss the difference - map dynamics of dc .",
    "then , in section  [ dacmp ] we reformulate dc as a message - passing algorithm directly comparable to bp .      consider a system with @xmath0 variables and @xmath1 constraints on those variables .",
    "we seek a configuration of the @xmath0 variables such that all @xmath1 constraints are satisfied . for each constraint that a variable is involved in ,",
    "we create one `` replica '' of the variable .",
    "the idea behind dc is that by constructing a dynamics of replicas rather than of variables , each constraint can be locally satisfied ( the `` divide '' step ) , and then later the possibly different values of replicas of the same variable can be forced to equal each other ( the `` concur '' step ) .",
    "denote using @xmath2 the vector containing the values of all the replicas associated with the @xmath3th constraint and let @xmath4}}$ ] be the vector of all the values of replicas associated with the @xmath5th variable .",
    "let @xmath6 be the vector containing all the values of replicas of all the variables",
    ". now @xmath2 for @xmath7 and @xmath4}}$ ] for @xmath8 are two different ways to partition @xmath6 into mutually exclusive sets .",
    "there are two projection operations , the `` divide '' projection and the `` concur '' projection , denoted by @xmath9 and @xmath10 , respectively .",
    "both projections act on @xmath6 and output a new @xmath6 that satisfies certain requirements . since @xmath6 can be partitioned into mutually exclusive sets , the projections",
    "are actually applied to each set independently .",
    "the divide projection is a product of local divide projections @xmath11 that operate on each @xmath2 for @xmath12 . if @xmath2 satisfies the @xmath3th constraint , @xmath13 ; otherwise , @xmath14 such that @xmath15 is the closest vector to @xmath2 that satisfies the @xmath3th constraint .",
    "the metric used is normally ordinary euclidean distance .",
    "the divide projection forces all constraints to be satisfied , but has the effect that replicas of the same variable do not necessarily agree with one another .",
    "the concur projection is a product of local concur projections @xmath16}})$ ] that act on @xmath4}}$ ] for @xmath8 .",
    "let @xmath17}}$ ] be the average of all the elements in @xmath4}}$ ] and construct a vector @xmath18}}$ ] with each element equal to @xmath17}}$ ] , with dimensionality the same as @xmath4}}$ ]",
    ". then @xmath16}})={\\bar{{\\textit{\\textbf{r}}}}_{[i]}}$ ] .",
    "while the concur projection equalizes the values of the replicas of the same variable , the new values of the replicas may violate some constraints .",
    "the overall projection @xmath19 [ alternately @xmath20 is defined as applying @xmath21 [ @xmath22 to @xmath2 for @xmath23 [ @xmath4}}$ ]  for @xmath24 .",
    "the @xmath1 [ @xmath0 ] output vectors are then reassembled into the updated @xmath6 vector through appropriate ordering .",
    "a strategy is needed to combine these two projections to find a set of replica values such that all constraints are satisfied and all replicas of the same variable are equal .",
    "the simplest approach is to alternate two projections , i.e. , @xmath26 , where @xmath27 is the vector of replica values at the @xmath28th iteration .",
    "this scheme works well for convex constraints , but it is prone to getting stuck in short cycles ( `` traps '' ) that do not correspond to solutions .    to illustrate this point ,",
    "consider the situation shown in fig .",
    "[ trap ] , where we imagine that the space of replicas of a particular variable is only two - dimensional , i.e. , the variable in question participates in two constraints .",
    "the diagonal line represents the requirement that all replicas are equal , since they are replicas of the same variable .",
    "the points @xmath29 and @xmath30 are the two pairs of replica values that satisfy the variable s constraints .",
    "the only common value that the replicas can take that satisfies both constraints is zero , i.e. point @xmath29 .",
    "however , if one initializes replica values near point @xmath30 , say at @xmath31 , and applies the divide projection , then one will move to @xmath30 , the nearest point that satisfies the constraints .",
    "next , the concur projection will move to point c , the nearest point ( along the diagonal ) where the replica values are equal . continued application of divide and concur projections , in sequence , moves the system to @xmath30 , then back to @xmath32 , then back to @xmath30 , and so forth .",
    "alternating projections cause the system to be stuck in a simple trap .",
    "of course , this is only a toy two - dimensional example , but in non - convex high - dimensional spaces it is plausible that an iterated projection strategy is prone to falling into such traps .     or @xmath30 ) , and then the nearest point where the replica values are equal ( the diagonal line ) one may be trapped in a short cycle ( @xmath30 to @xmath32 to @xmath30 and so on ) and never find the true solution at point @xmath29.,scaledwidth=35.0% ]      the difference map ( dm ) is a strategy that improves alternating projections by turning traps in the dynamics into repellers .",
    "it is defined by gravel and elser as follows : @xmath33\\end{aligned}\\ ] ] where @xmath34 for @xmath35 or @xmath31 with @xmath36 and @xmath37 .",
    "the parameter @xmath38 can be chosen to optimize performance .",
    "we focus here exclusively on the case @xmath39 , which is usually an excellent choice and corresponds to what fienup called the `` hybrid input - output '' algorithm , originally developed in the context of image reconstruction @xcite@xcite .",
    "see @xcite for a review of fienup s algorithm and other projection algorithms for image reconstruction , and their relationship with earlier convex optimization methods .",
    "for @xmath40 , the dynamics  ( [ dm ] ) simplify to @xmath41\\big)-[p_d({\\textit{\\textbf{r}}}_{t})-{\\textit{\\textbf{r}}}_t].\\end{aligned}\\ ] ] it can be proved that if a fixed point in the dynamics @xmath42 is reached , i.e. , @xmath43 , then that fixed point must _ correspond _ to a solution of the problem .",
    "it is important to note that the fixed point itself is _ not necessarily _ a solution .",
    "the solution @xmath44 corresponding to a fixed point @xmath42 can be obtained using @xmath45 or @xmath46)$ ] .",
    "we have found it very useful to think of the difference - map dynamics for a single iteration as breaking down into a three - step process .",
    "the expression @xmath47 $ ] represents the change to the current values of the replicas resulting from the divide projection . in the first step , the values of the replicas move _",
    "twice _ the desired amount indicated by the divide projection .",
    "we refer to these new values of the replicas as the `` overshoot '' values @xmath48 $ ] .",
    "next the concur projection is applied to the overshoot values to obtain the `` concurred '' values of the replicas @xmath49 .",
    "finally the overshoot , i.e. , the extra motion in the first step , is subtracted from the concur projection result to obtain the replica value for the next iteration @xmath50 $ ] .    in fig .",
    "[ trap2 ] we return to our previous example and see that the dm dynamics do not get stuck in a trap .",
    "suppose , as before , that point @xmath29 is at @xmath51 , point @xmath30 is at @xmath52 , and and that we now start initially at point @xmath53",
    ". the divide projection would take us to point @xmath30 , but the overshoot takes us twice as far to @xmath54 .",
    "the concur projection takes us back to @xmath55 .",
    "finally , the overshoot is corrected so that @xmath56 .",
    "the next full iteration takes us to @xmath57 ( sub - steps are tabulated in fig .",
    "[ trap2 ] ) .",
    "now however , we are closer to @xmath29 then to @xmath30 .",
    "therefore , the next overshoot take us to @xmath58 , from which we would move to @xmath59 , and @xmath60 .",
    "finally , at @xmath61 we have reached a fixed point in the dynamics that corresponds to the solution at @xmath29 ( which can be obtained from the final value of @xmath62 or @xmath63 ) .",
    ", an iterated projections dynamics would be trapped between point @xmath30 and @xmath64 , and never find the solution at @xmath29 .",
    "dm dynamics will instead be repelled from the trap and move to @xmath65 ( via the three sub - steps denoted with dashed lines @xmath66 , @xmath67 , and @xmath65 ) , then move to @xmath68 , and then end at the fixed point @xmath69 , which corresponds to the solution at @xmath29.,width=288 ]    [ cols=\"^,^,^,^,^\",options=\"header \" , ]     we can generalize from this example to understand how the dm dynamics turns a trap into a `` repeller , '' where at each iteration , one moves away from the repeller by an amount equal to the distance between the constraint involved and the nearest point that satisfies the requirement that the replicas be equal .",
    "of course , dm dynamics are not a panacea ; it is possible that dc can get caught in more complicated cycles or `` strange attractors '' and never find an existing solution ; but least it will does not get caught in simple traps .",
    "we now turn to developing an alternative interpretation of dc , as a message - passing algorithm on a graph .",
    "`` messages '' and `` beliefs '' are similar to those in bp , but message - update and belief - update rules are different .",
    "to begin with , we construct a bi - partite `` constraint graph '' of variable nodes and constraint nodes , where each variable is connected to the constraints it is involved in .",
    "a constraint graph can be thought of as a special case of a factor graph @xcite , where each allowed configuration is given the same weight , and disallowed configurations are given zero weight .",
    "we identify the dc `` replicas '' with the edges of the graph .",
    "we denote by @xmath70 a}}(t)$ ] the value of the replica on the edge joining variable @xmath5 to constraint @xmath3 at the beginning of iteration @xmath28 , i.e. , the appropriate element of @xmath4}}(t)$ ] .",
    "we similarly denote by @xmath70 a}^{over}}(t)$ ] and @xmath70 a}^{conc}}(t)$ ] the `` overshoot '' and `` concurred '' values of the same replica .",
    "we note that these are all scalars .",
    "we can alternatively think of the initial value of a replica @xmath70 a}}(t)$ ] as a `` message '' from the variable node @xmath5 to the constraint node @xmath3 that we denote as @xmath71 .",
    "the set of incoming messages to constraint node @xmath3 , @xmath72 where @xmath73 is the set of variable indexes involved in constraint @xmath3 , can therefore be expressed as @xmath74 .    in the three - step interpretation of the dm dynamics described above",
    ", these replica values are next transformed into overshoot values by moving by twice the amount indicated by the divide projection . because the overshoot values are computed locally at a constraint node using the messages into to the constraint node",
    ", we can think of the overshoot values @xmath70 a}^{over}}(t)$ ] as messages from the constraint node @xmath3 to their neighboring variable nodes @xmath5 , denoted by @xmath75 .",
    "the set of outgoing messages from constraint node @xmath3 is @xmath76 .",
    "this set can thus be calculated as @xmath77 = \\textit{\\textbf{m}}_{\\rightarrow a}(t ) + 2 [ p_d^a ( \\textit{\\textbf{m}}_{\\rightarrow a}(t))- \\textit{\\textbf{m}}_{\\rightarrow a}(t ) ] $ ] .",
    "the next step of the dc algorithm takes the overshoot replica values @xmath70 a}^{over}}(t)$ ] and computes concurred values @xmath70 a}^{conc}}(t)$ ] using the concur projection .",
    "note that the concurred values for replicas that are connected to the same variable node @xmath5 are all equal to each other .",
    "we can think of these concurred values as `` beliefs , '' denoted by @xmath78 . just as in bp ,",
    "the beliefs at a variable node @xmath5 are computed using all the messages coming into that variable node . however , while the bp belief is a sum of incoming messages , the dc belief is an average : @xmath79}^{\\over } ( t ) ) = \\frac{1}{|\\mbox{$\\cal m$}(i)| } \\sum_{a \\in \\mbox{$\\cal m$ } ( i ) } m_{a \\rightarrow i}(t)\\ ] ] where @xmath80 is the set of constraint indexes in which variable @xmath5 participates .    finally , the dc rule for computing the new replica values at the next iteration is to take the concurred values and subtract a correction for the amount we overshot when we computed the overshot values . in terms of our belief and message formulation ,",
    "we compute the outgoing messages from a variable node at the next iteration using the rule @xmath81.\\ ] ] comparing with the ordinary bp rule @xmath82 we note that the message out of a variable node in dc also depends on the value of the same message at the previous iteration , which is not the case in bp .",
    "to summarize , the overall structure of bp and dc as message - passing algorithms is similar . in",
    "both one iteratively updates beliefs at variable nodes and messages between variable nodes and constraint nodes .",
    "furthermore , messages out of a constraint node are computed based on the messages into the constraint node , beliefs are computed based on the messages into a variable node , and the messages out of the variable node depend on the beliefs and the messages into a variable node .",
    "the differences are in the specific forms of the message - update and belief - update rules , and the fact that a message - update rule for a message out of a variable node in dc also depends on the value of the same message in the previous iteration .",
    "decoding of ldpc codes can be described as a constraint satisfaction problem .",
    "we restrict ourselves here to binary ldpc codes , although generalizations to @xmath83-ary codes are straightforward . searching for a codeword",
    "is equivalent to seeking a binary sequence which satisfies all the single - parity check ( spc ) constraints simultaneously .",
    "we also add one important additional constraint , which is that the likelihood of a binary sequence must be greater than some minimum amount .",
    "then the decoding problem can be divided into many simple sub - problems which can be solved independently using the dc approach .",
    "let @xmath1 and @xmath0 be the number of spc constraints and bits of a binary ldpc code , respectively .",
    "let @xmath84 be the parity check matrix which defines the code .",
    "assume bpsk signaling with unit energy , which maps a binary codeword @xmath85 into a sequence @xmath86 , according to @xmath87 , for @xmath88 .",
    "the sequence @xmath89 is transmitted through a channel and the received channel observations are denoted @xmath90 .",
    "let the log - likelihood ratios ( llr s ) corresponding to the received channel observations be @xmath91 , where @xmath92}{\\pr[y_i | x_i = -1 ] } \\right ) .",
    "\\nonumber\\end{aligned}\\ ] ] our goal is to recover the transmitted sequence of variables @xmath89 . to do this",
    ", we will search for a sequence of @xmath93 s that satisfies all the spc constraints and has the highest likelihood or , equivalently , the lowest `` energy , '' where the energy is defined as @xmath94 note that although our desired sequence consists only of @xmath93 variables , the `` replica '' values , or equivalently `` messages '' and `` beliefs , '' are real - valued .    in all",
    ", we have @xmath0 variables @xmath95 , and @xmath96 constraints , of which @xmath1 are spc constraints , with one additional energy constraint .",
    "we will write the energy constraint as @xmath97 , where different choices of @xmath98 result in different decoders .",
    "it is not obvious how to choose @xmath98 ; we performed preliminary experiments to search for an @xmath98 that optimizes decoding performance .",
    "somewhat surprisingly , the best choice for @xmath98 is one that for which the energy constraint can never actually be satisfied : we found that @xmath99 , with @xmath100 was an excellent choice .",
    "the fact that the energy constraint is never satisfied is not a problem because the decoder terminates if it finds a codeword that satisfies all the spc constraints . until then",
    ", the effect of the energy constraint is to keep the replica values near the transmitted sequence .",
    "we will describe the dc decoder as an iterative message - update algorithm on a constraint graph , following the formulation in section [ dacmp ] .",
    "we use @xmath0 variable indexes @xmath101 and @xmath96 constraint indexes @xmath102 , where the @xmath103th constraint is the energy constraint .",
    "spc constraints involve a small number of variables , but the energy constraint involves every variable . to lay the groundwork for the overall dc decoder ,",
    "we now explain how to perform the divide and concur projections .",
    "the divide projection @xmath9 can be partitioned into a collection of @xmath96 projections @xmath104 , where each projection operates independently on a vector of messages @xmath105 and outputs a vector ( of the same dimensionality ) of projected messages @xmath106 .",
    "the output vector is as close as possible to the original values @xmath107 while satisfying the @xmath3th constraint .",
    "the spc constraints require that the variables involved in a constraint are all @xmath93 , with an even number of @xmath108 s .",
    "for these constraints we efficiently perform the divide projection as follows :    * make a hard decision @xmath109 on each of @xmath110 such that @xmath111 if @xmath112 , @xmath113 if @xmath114 , and @xmath109 is chosen to be @xmath115 or @xmath108 randomly if @xmath116 .",
    "* check if @xmath117 contains an even number of @xmath108 s .",
    "if it does , set @xmath118 and return .",
    "* otherwise , let @xmath119 .",
    "especially for the bsc , it is possible that several messages have equally minimal @xmath120 . in this case",
    ", we randomly pick one of them and use its index as @xmath121 .",
    "* flip @xmath122 , i.e. , if @xmath123 , set it to @xmath115 and if @xmath124 , set it to @xmath108 .",
    "then set @xmath125 and return .",
    "recall that the energy constraint is @xmath126 .",
    "this implies a divide projection on the vector of messages @xmath127 , performed as follows :    * if the energy constraint is already satisfied by the messages @xmath127 , return the current messages , i.e. , @xmath128 .",
    "( recall however that the energy constraint will never be satisfied for the choice of @xmath129 that we use in our simulations . )",
    "* otherwise , find @xmath130 which is the closest vector to @xmath127 and satisfies the energy constraint .",
    "an easy application of vector calculus can be used to derive that the @xmath5th component @xmath131 is given by the formula @xmath132 set @xmath133 and return .",
    "finally , the concur projection @xmath10 can be partitioned into a set of @xmath0 projection operators @xmath134 , where each @xmath134 operates independently on the vector of messages @xmath135 and outputs the belief @xmath78 , the average over the components of the vector @xmath136 .",
    "the overall dc decoder proceeds as follows .    *",
    "set the maximum number of iterations to @xmath137 and the current iteration to @xmath138 .",
    "initialize the messages out of variable nodes @xmath139 for all @xmath5 and @xmath140 to equal @xmath141 , where @xmath142 is the _ a priori _ probability that the @xmath5th transmitted symbol @xmath143 was a @xmath115 , given by @xmath144 . * given the messages @xmath145 into each constraint @xmath3 , compute the messages out of each constraint @xmath146 using the overshoot formula @xmath147\\ ] ] where @xmath106 is the divide projection operation for constraint @xmath3 . *",
    "compute the beliefs at each variable node @xmath5 using the concur projections @xmath148 * create @xmath149 such that @xmath150 if @xmath151 , @xmath152 if @xmath153 and flip a coin to decide @xmath154 if @xmath155 .",
    "if @xmath156 output @xmath157 as the decoded codeword and stop .",
    "* increment @xmath158 . if @xmath159 stop and return failure .",
    "otherwise , update each message out of the variable nodes using the `` overshoot correction '' rule given in equation ( [ overshootcorrect ] ) and go back to step 1 .",
    "as already mentioned in the introduction , the dc decoder performs reasonably well , but with some problems .",
    "we defer a detailed discussion of the dc simulation results until section [ simulations ] .",
    "first we describe a second and novel decoder , the difference - map belief propagation ( dmbp ) decoder .",
    "our motivation in creating the dmbp decoder was that bp decoders generally perform well , but they seem to use something like an iterated projection strategy , and perhaps the trapping sets that plague the error - floor regime are related to the `` traps '' that the difference - map dynamics is supposed to ameliorate . since we can also describe dc decoders as message - passing decoders , we could try to create a new bp decoder that was a mixture of bp and difference - map ideas .    for simplicity ,",
    "we work with a min - sum bp decoder using messages and beliefs that correspond to log - likelihood ratios .",
    "note that the min - sum message update rule is much simpler to implement in hardware than the standard sum - product rule .",
    "normally , sum - product ( or some approximation to sum - product ) bp decoders are favored over min - sum bp decoders because they perform better , but we found that the straightforward min - sum dmbp decoder will out - perform the more complicated sum - product bp decoder .",
    "our preliminary simulations also show , somewhat surprisingly , that the min - sum dmbp decoder slightly out - performs a sum - product dmbp decoder .",
    "( we do nt further discuss the sum - product dmbp decoder herein . )",
    "we use the same notation for messages and beliefs that were used in the discussion of the dc decoder in section  [ dcdecdefs ] .",
    "we compare , on an intuitive level , the min - sum bp decoder with the dc decoder in terms of belief updates and message - updates at both the variable and check nodes .    beginning with the message - updates at a check node , the standard min - sum bp update rules are to take incoming messages @xmath160 and compute outgoing messages according to the rule that @xmath161 where @xmath162 if @xmath163 , and @xmath164 if @xmath165 . comparing with the dc `` overshoot '' message - update rule",
    ", we note that the min - sum updates , in some sense , also `` overshoot '' .",
    "for example , at a check node that has three incoming positive messages and one incoming negative message , we obtain three outgoing negative messages and one outgoing positive message .",
    "this overshoots the `` correct '' solution of having an even number of negative messages ( since the parity check must ultimately be connected to an even number of variables with value @xmath108 ) . because the min - sum rule for messages outgoing towards a particular variable ignore the incoming message from that variable , all the outgoing messages move beyond what is necessary ( at least in terms of sign ) to satisfy the constraint .",
    "_ want _ an overshoot , we decided to leave this rule unmodified .    turning to the belief update rule ,",
    "the standard bp rule is to compute the belief as the _ sum _ of incoming messages ( including the message from the observation ) , while the dc rule is that the belief is the _ average _ of incoming messages .",
    "we decided to use the compromise rule @xmath166 where @xmath167 is a parameter chosen by optimizing decoder performance .",
    "finally , for the message - update rule for messages at the variable nodes , we directly copy the `` correction '' rule from dc .",
    "our intuitive idea is that perhaps standard bp is missing the correction that is important in repelling dm dynamics from traps .    to summarize , the dmbp decoder works as follows :    * set the maximum number of iterations to @xmath137 and the current iteration to @xmath138 .",
    "initialize the the messages out of variable nodes @xmath168 for all @xmath5 and @xmath140 to equal @xmath169 .",
    "* given the messages @xmath71 coming into the constraint node @xmath3 , compute the outgoing messages using the min - sum message update rule given in equation ( [ minsumupdate ] ) . *",
    "compute the beliefs at each variable node @xmath5 using the belief update rule given in equation ( [ beliefupdate ] ) .",
    "* create @xmath149 such that @xmath150 if @xmath151 , @xmath152 if @xmath153 and flip a coin to decide @xmath154 if @xmath155 .",
    "if @xmath156 output @xmath157 as the decoded codeword and stop . * increment @xmath158 . if @xmath159 stop and return failure . otherwise , update each message out of the variable nodes using the `` overshoot correction '' rule given in equation ( [ overshootcorrect ] ) and go back to step 1 .",
    "in this section , we compare simulation results of the dc and dmbp decoders to those of a variety of other decoders .",
    "the decoding algorithms are applied to two kinds of ldpc codes and simulated over both the bsc and the awgn channel .",
    "one code is a random regular ldpc code with length 1057 and rate 0.77 , obtained from @xcite .",
    "the other code is a quasi - cyclic ( qc ) `` array '' ldpc code @xcite@xcite with length 2209 and rate 0.916 .",
    "the first point of comparison of our proposed decoders is to sum - product bp decoding .",
    "when simulating transmission over the bsc , in order better to probe the error floor region , we implement the multistage decoder introduced in  @xcite .",
    "multistage decoders pre - append simpler decoders ( in our case richardson & urbanke s algorithm - e  @xcite and/or regular sum - product bp ) to the more complex decoders of interest ( e.g. , dc ) .",
    "the simpler decoders either decode or fail to decode in a detectable way ( e.g. , by not converging in bp s case ) .",
    "failures to decode trigger the use of the more complex decoders . in this way",
    "one can often achieve the wer performance of the most complex decoder at an expected complexity close to that of the most simple decoder .",
    "our first use of the multistage approach in this paper is to calculate the performance of sum - product bp decoding for the bsc .",
    "we implement a multistage decoder that combines a first - stage algorithm - e to a second - stage sum - product bp .",
    "we term the combination e - bp .",
    "for the sum - product bp simulations of the awgn channel simulations we implement a standard sum - product bp decoder ( and not a multistage decoder ) as we have found algorithm - e has very poor performance on the awgn channel and thus does not appreciably reduce simulation time .    for dc and dmbp",
    "we provide results for standard ( single - stage ) implementations of both algorithms as well as for multi - stage implementations . as per the discussion above , we use e - bp as the initial stages for simulations over the bsc and bp by itself as a first stage for simulations of the awgn channel .",
    "we denote the resulting multi - stage decoders by e - bp - dmbp , e - bp - dc , bp - dmbp and bp - dc .",
    "our final points of comparison are to linear programming ( lp ) decoding and mixed - integer lp ( milp ) decoding .",
    "our lp decoders were accelerated using taghavi and siegel s `` adaptive '' methods  @xcite , and ultimately relied on the simplex algorithm as implemented in the glpk linear programming library @xcite . for the bsc",
    ", we implement the multistage decoders e - bp - lp and e - bp - milp(@xmath170 ) for @xmath171 , where @xmath170 is the maximum number of integer ( in fact binary ) constraints the milp decoder is allowed .",
    "further details of these decoders and results can be found in  @xcite .",
    "regarding the decoding parameters of our new algorithms , for the random ldpc code , we use @xmath172 for the dmbp decoder over both bsc and the awgn channel . for the array code",
    ", we use @xmath173 over the bsc and @xmath174 over the awgn channel .",
    "finally , we are often able to estimate a lower bound on the word error rate ( wer ) of ml decoding . when our decoders return a codeword that is different from the transmitted codeword , but has a higher probability , we know that an optimal ml decoder would also have made a decoding `` error .",
    "'' the proportion of such events provides an estimated lower bound on ml performance .",
    "( the true ml wer could be above the lower bound because an ml decoder may also make errors on blocks for which our decoder fails to converge , events that our estimate assumes ml would decode correctly . )",
    "figure [ n1057bsc ] plots the word error rates of the various algorithms for the length-1057 random ldpc code when transmitted over the bsc .",
    "we plot wer versus snr , assuming that the bsc results from hard - decision demodulation of a bpsk @xmath93 sequence transmitted over an awgn channel .",
    "the resulting relation between the crossover probability @xmath175 of the equivalent bsc-@xmath175 and the snr of the awgn channel is @xmath176 where @xmath177 is the rate of the code and @xmath178 is the q - function . in figure  [ n1057bsc_a ]",
    "we plot results when all iterative algorithms are limited to @xmath179 iterations , and in figure  [ n1057bsc_b ] to @xmath180 iterations .",
    "we observe that e - bp - dmbp improves the error floor performance dramatically compared with e - bp ( e - bp - dc also improves significantly compared with e - bp if one allows for 300 iterations ) and in the high snr region e - bp - dmbp with 50 iterations is very close to the estimated lower bound of the maximum likelihood ( ml ) decoder .",
    "note also that a pure dmbp decoder has almost the same performance as e - bp - dmbp for both 50 and 300 iterations , so the e - bp - dmbp performance in the very high snr regime should be indicative of the pure dmbp performance .    from figure [ n1057bsc ]",
    ", we also observe that the pure dc decoder needs many more iterations to obtain good performance compared with both bp and dmbp . for 300 iterations , dc performs better than e - bp at lower snr , but exhibits an apparent error floor as the snr increases .",
    "this high error floor is mostly the result of the dc decoder returning a codeword with _",
    "probability than the transmitted codeword .",
    "for example , for an snr of 6.60 db , 80% of dc errors are of this type , while for an snr of 7.31 db , the percentage rises to 98% .",
    "in contrast , the bp and dmbp decoders essentially never make this kind of error .    notice that e - bp - lp has a very similar performance to dmbp , and also that e - bp - milp with 10 fixed bits performs the best among all the decoders and almost approaches the estimated ml lower bound",
    ". however , dmbp decoders should be significantly more practical to construct in hardware , because they are message - passing decoders similar to existing bp decoders , while lp and milp decoders do not currently have efficient and hardware - friendly message - passing implementations .",
    "figure [ n2209bsc ] depicts the wer performance comparison of the length-2209 array ldpc code over the bsc . for this qc - ldpc code",
    ", we observe broadly similar performance to the random ldpc code .",
    "figure [ n1057awgn ] shows the wer performance comparison of the length-1057 random ldpc code over the awgn channel .",
    "we observe that the bp decoder for this code exhibits an error floor .",
    "dmbp improves the error floor performance compared with bp and does not have an apparent error floor .",
    "when 200 iterations are used , the dc decoder has a similar performance to bp . in the high snr region ,",
    "the dc decoder does not converge to an incorrect codeword as frequently as it does over the bsc .",
    "note also that on the awgn channel , while the dmbp decoder outperforms bp in the error - floor regime , it actually starts out worse in the low snr regime .",
    "figure [ n2209awgn ] depicts the wer performance comparison of the length-2209 array ldpc code over the awgn channel . for this qc - ldpc code",
    ", we observe similar performance to the random ldpc code .",
    "note again that while all decoders benefit from additional allowed iterations , the dc decoder in particular becomes increasingly competitive as the number of allowed iterations increases .",
    "our basic motivation for the dc and dmbp decoders was that the difference - map dynamics may help a decoder avoid dynamical `` traps '' that could be related to the trapping sets that are believed to cause error floors .",
    "the very good performance of the dmbp decoder in the error floor regime indicates that there may in fact be a reduction in the number of trapping sets , but on the other hand , some trapping sets clearly continue to exist , even for the dmbp decoder . in particular , we followed the approach of @xcite and performed some preliminary investigations of individual `` absorbing sets '' in the array code that they studied , and found that although the dmbp decoder performed better on average than the bp decoder , it still would not escape if started sufficiently close to particular difficult absorbing sets .",
    "in this paper , we investigate two decoders for ldpc codes : a dc decoder that directly applies the divide and concur approach to decoding ldpc codes , and a dmbp decoder that imports the difference - map idea into a min - sum bp - type decoder .",
    "the dmbp decoder shows particularly promising improvements in error - floor performance compared with the standard sum - product bp decoder , with comparable computational complexity , and is amenable to hardware implementation .",
    "the dmbp decoder can be criticized for lacking a solid theoretical basis : it was constructed using intuitive ideas and is mostly interesting because of its excellent performance . the fact that its performance closely parallels that of linear programming decoders suggests that it might be related to them .",
    "in fact , our work was partially motivated by our earlier results which showed that lp decoders can significantly improve upon bp performance in the error floor regime @xcite ; we aimed to develop a message - passing decoder that could reproduce lp performance with complexity similar to bp .",
    "work in the direction of creating an efficient message - passing linear programming decoder that could replace lp solvers that relied on simplex or interior point methods was begun by vontobel and koetter @xcite , and message - passing algorithms that converge to an lp solution for some problems were suggested by globerson and jaakkola @xcite .",
    "our dmbp update equations are quite similar to those in the gemplp algorithm suggested by globerson and jaakkola , but our limited experiments with a gemplp decoder show that it does not reproduce lp decoding performance . for that matter",
    ", we have been unable to devise any other message - passing decoder with complexity similar to bp that exactly reproduces linear programming decoding .",
    "elucidating the precise relationship between dmbp and lp decoders remains an outstanding theoretical problem , but from the practical point of view , our results show that the dmbp decoder already serves as an efficient message - passing decoder that significantly improves error floor performance compared with standard bp",
    ".          p.  o.  vontobel and r.  koetter , `` graph - cover decoding and finite - length analysis of message - passing iterative decoding of ldpc codes , '' to appear in _ ieee trans .",
    "inform . theory",
    "_ http://www.arxiv.org/abs/cs.it/0512078 .",
    "l. dolecek , p. lee , z. zhang , v. anatharam , b. nikolic , and m.j .",
    "wainwright , `` predicting error floors of structured ldpc codes : deterministic bounds and estimates , '' to appear in _ ieee jour .",
    "areas in comm .",
    "_ , 2009 .",
    "t. tian , c. jones , j. d. villasenor , and r. d. wesel , `` construction of irregular ldpc codes with low error floors , '' _ ieee international conference on communications _ , vol . 5 ,",
    "anchorage , ak , may 2003 , pp . 31253129 .",
    "y. wang , j.  s.  yedidia , s.  c.  draper , `` construction of high - girth qc - ldpc codes , '' _ fifth international symposium on turbo codes and related topics _ 2008 .",
    "available online at http://www.merl.com / publications / tr2008 - 061/.                            h.  h.  baushke , p.  l.  combettes , and d.  r.  luke , `` phase retrieval , error reduction algorithm , and fienup variants : a view from convex optimization , '' _",
    "19 , july 2002 , pp .",
    "1334 - 1345 ."
  ],
  "abstract_text": [
    "<S> the `` divide and concur '' ( dc ) algorithm , recently introduced by gravel and elser , can be considered a competitor to the belief propagation ( bp ) algorithm , in that both algorithms can be applied to a wide variety of constraint satisfaction , optimization , and probabilistic inference problems . </S>",
    "<S> we show that dc can be interpreted as a message - passing algorithm on a constraint graph , which helps make the comparison with bp more clear . </S>",
    "<S> the `` difference - map '' dynamics of the dc algorithm enables it to avoid `` traps '' which may be related to the `` trapping sets '' or `` pseudo - codewords '' that plague bp decoders of low - density parity check ( ldpc ) codes in the error - floor regime .    </S>",
    "<S> we investigate two decoders for low - density parity - check ( ldpc ) codes based on these ideas . </S>",
    "<S> the first decoder is based directly on dc , while the second decoder borrows the important `` difference - map '' concept from the dc algorithm and translates it into a bp - like decoder . </S>",
    "<S> we show that this `` difference - map belief propagation '' ( dmbp ) decoder has dramatically improved error - floor performance compared to standard bp decoders , while maintaining a similar computational complexity . </S>",
    "<S> we present simulation results for ldpc codes on the additive white gaussian noise and binary symmetric channels , comparing dc and dmbp decoders with other decoders based on bp , linear programming , and mixed - integer linear programming .    </S>",
    "<S> iterative algorithms , graphical models , ldpc decoding , projection algorithms </S>"
  ]
}