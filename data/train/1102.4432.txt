{
  "article_text": [
    "the setting in which abc operates is the approximation of a simulation from the posterior distribution @xmath0 when distributions associated with both the prior @xmath1 and the likelihood @xmath2 can be simulated ( the later being unavailable in closed form ) .",
    "the first abc algorithm was introduced by @xcite as follows : given a sample @xmath3 from a sample space @xmath4 , a sample @xmath5 is produced by + * algorithm 1 : abc sampler *    [ algo : abc0 ] generate @xmath6 from the prior distribution @xmath7 generate @xmath8 from the likelihood @xmath9 set @xmath10 ,    the parameters of the abc algorithm are the so - called summary statistic @xmath11 , the distance @xmath12 , and the tolerance level @xmath13 .",
    "the approximation of the posterior distribution @xmath14 provided by the abc sampler is to instead sample from the marginal in @xmath15 of the joint distribution @xmath16where @xmath17 denotes the indicator function of @xmath18 and @xmath19 the basic justification of the abc approximation is that , when using a sufficient statistic @xmath20 and a small ( enough ) tolerance @xmath21 , we have @xmath22 in practice , the statistic @xmath20 is necessarily insufficient ( since only exponential families enjoy sufficient statistics with fixed dimension , see @xcite ) and the approximation then converges to the less informative @xmath23 when @xmath21 goes to zero .",
    "this loss of information is a necessary price to pay for the access to computable quantities and @xmath23 provides a convergent inference on @xmath15 when @xmath15 is identifiable in the distribution of @xmath24 @xcite .",
    "while acknowledging the gain brought by abc in handling bayesian inference in complex models , and the existence of involved summary selection mechanisms @xcite , we demonstrate here that the loss due to the abc approximation may be arbitrary in the specific setting of bayesian model choice via posterior model probabilities .",
    "the standard bayesian tool for model comparison is the marginal likelihood @xcite @xmath25 which leads to the bayes factor for comparing the evidences of models with likelihoods @xmath26 and @xmath27 , @xmath28 as detailed in @xcite , it provides a valid criterion for model comparison that is naturally penalised for model complexity .",
    "bayesian model choice proceeds by creating a probability structure across @xmath29 models ( or likelihoods ) .",
    "it introduces the model index @xmath30 as an extra unknown parameter , associated with its prior distribution , @xmath31 ( @xmath32 ) , while the prior distribution on the parameter is conditional on the value @xmath33 of the @xmath30 index , denoted by @xmath34 and defined on the parameter space @xmath35 . the choice between those models",
    "is then driven by the posterior distribution of @xmath30 , @xmath36 where @xmath37 denotes the marginal likelihood for model @xmath38 .",
    "while this posterior distribution is straightforward to interpret , it offers a challenging computational conundrum in bayesian analysis . when the likelihood is not available , abc represents the almost unique solution .",
    "@xcite describe the use of model choice based on abc for distinguishing between different mutation models .",
    "the justification behind the method is that the average abc acceptance rate associated with a given model is proportional to the posterior probability corresponding to this approximative model , when identical summary statistics , distance , and tolerance level are used over all models . in practice ,",
    "an estimate of the ratio of marginal likelihoods is given by the ratio of observed acceptance rates .",
    "using bayes formula , estimates of the posterior probabilities are straightforward to derive .",
    "this approach has been widely implemented in the literature ( see , e.g. , @xcite , @xcite , @xcite , and @xcite ) .",
    "a representative illustration of the use of an abc model choice approach is given by @xcite which analyses the european invasion of the western corn rootworm , north america s most destructive corn pest .",
    "because this pest was initially introduced in central europe , it was believed that subsequent outbreaks in western europe originated from this area . based on an abc model choice analysis of the genetic variability of the rootworm ,",
    "the authors conclude that this belief is false : there have been at least three independent introductions from north america during the past two decades .",
    "the above estimate is improved by regression regularisation @xcite , where model indices are processed as categorical variables in a polychotomous regression .",
    "when comparing two models , this involves a standard logistic regression .",
    "rejection - based approaches were lately introduced by @xcite , @xcite and @xcite , in a monte carlo simulation of model indices as well as model parameters .",
    "those recent extensions are already widely used in population genetics , as exemplified by @xcite .",
    "another illustration of the popularity of this approach is given by the availability of four softwares implementing abc model choice methodologies :    * abc - sysbio , which relies on a smc - based abc for inference in system biology , including model - choice @xcite . * abctoolbox which proposes smc and mcmc implementations , as well as bayes factor approximation @xcite .",
    "* diyabc , which relies on a regularised abc - mc algorithm on population history using molecular markers @xcite .",
    "* popabc , which relies on a regular abc - mc algorithm for genealogical simulation @xcite .",
    "as exposed in e.g. @xcite , @xcite , or @xcite , once @xmath30 is incorporated within the parameters , the abc approximation to its posterior follows from the same principles as in regular abc .",
    "the corresponding implementation is as follows , using for the summary statistic a statistic @xmath39 that is the concatenation of the summary statistics used for all models ( with an obvious elimination of duplicates ) . + * algorithm 2 : abc - mc *    [ algo : abcmoc ] generate @xmath33 from the prior @xmath31 generate @xmath40 from the prior @xmath41 generate @xmath8 from the model @xmath42 set @xmath43 and @xmath44    the abc estimate of the posterior probability @xmath45 is then the frequency of acceptances from model @xmath33 in the above simulation @xmath46 this also corresponds to the frequency of simulated pseudo - datasets from model @xmath33 that are closer to the data @xmath3 than the tolerance @xmath21 . in order to improve the estimation by smoothing , @xcite follow the rationale that motivated the use of a local linear regression in @xcite and",
    "rely on a weighted polychotomous regression to estimate @xmath45 based on the abc output .",
    "this modelling is implemented in the diyabc software .",
    "there is a fundamental discrepancy between the genuine bayes factors / posterior probabilities ) and the approximations resulting from abc - mc .",
    "the abc approximation to a bayes factor , @xmath47 say , resulting from algorithm 2 is @xmath48 an alternative representation is given by @xmath49 where the pairs @xmath50 are simulated from the joint prior and @xmath51 is the number of simulations necessary for @xmath52 acceptances in algorithm 2 . in order to study the limit of this approximation",
    ", we first let @xmath51 go to infinity .",
    "( for simplification purposes and without loss of generality , we choose a uniform prior on the model index . )",
    "the limit of @xmath53 is then @xmath54 }                               { \\mathbb{p}[\\mathcal{m}=2,\\rho\\{{\\boldsymbol{\\eta}}({\\mathbf{z}}),{\\boldsymbol{\\eta}}({\\mathbf{y}})\\ } \\le \\epsilon]}\\\\                       & = & \\dfrac{\\iint \\mathbb{i}_{\\rho\\{{\\boldsymbol{\\eta}}({\\mathbf{z}}),{\\boldsymbol{\\eta}}({\\mathbf{y}})\\ } \\le \\epsilon }   \\pi_1({\\boldsymbol{\\theta}}_1)f_1({\\mathbf{z}}|{\\boldsymbol{\\theta}}_1)\\,\\text{d}{\\mathbf{z}}\\,\\text{d}{\\boldsymbol{\\theta}}_1 }                               { \\iint \\mathbb{i}_{\\rho\\{{\\boldsymbol{\\eta}}({\\mathbf{z}}),{\\boldsymbol{\\eta}}({\\mathbf{y}})\\ } \\le \\epsilon }   \\pi_2({\\boldsymbol{\\theta}}_2)f_2({\\mathbf{z}}|{\\boldsymbol{\\theta}}_2)\\,\\text{d}{\\mathbf{z}}\\,\\text{d}{\\boldsymbol{\\theta}}_2}\\\\                       & = & \\dfrac{\\iint \\mathbb{i}_{\\rho\\{{\\boldsymbol{\\eta}},{\\boldsymbol{\\eta}}({\\mathbf{y}})\\ } \\le \\epsilon }   \\pi_1({\\boldsymbol{\\theta}}_1)f_1^{{\\boldsymbol{\\eta}}}({\\boldsymbol{\\eta}}|{\\boldsymbol{\\theta}}_1)\\,\\text{d}{\\boldsymbol{\\eta}}\\,\\text{d}{\\boldsymbol{\\theta}}_1 }                               { \\iint \\mathbb{i}_{\\rho\\{{\\boldsymbol{\\eta}},{\\boldsymbol{\\eta}}({\\mathbf{y}})\\ } \\le \\epsilon }   \\pi_2({\\boldsymbol{\\theta}}_2)f_2^{{\\boldsymbol{\\eta}}}({\\boldsymbol{\\eta}}|{\\boldsymbol{\\theta}}_2)\\,\\text{d}{\\boldsymbol{\\eta}}\\,\\text{d}{\\boldsymbol{\\theta}}_2}\\,,\\end{aligned}\\ ] ] where @xmath55 and @xmath56 denote the densities of @xmath57 when @xmath58 and @xmath59 , respectively . by lhospital formula ,",
    "if @xmath21 goes to zero , the above converges to @xmath60 namely the bayes factor for testing model @xmath61 versus model @xmath62 based on the sole observation of @xmath63 .",
    "this result reflects the current perspective on abc : the inference derived from the ideal abc output when @xmath64 only uses the information contained in @xmath63 .",
    "thus , in the limiting case , i.e.  when the algorithm uses an infinite computational power , the abc odds ratio does not account for features of the data other than the value of @xmath63 , which is why the limiting bayes factor only depends on the distribution of @xmath65 under both models .",
    "when running abc for point estimation , the use of an insufficient statistic does not usually jeopardise convergence of the method .",
    "as shown , e.g. , in ( * ? ? ?",
    "* theorem 2 ) , the noisy version of abc as an inference method is convergent under usual regularity conditions for model - based bayesian inference @xcite , including identifiability of the parameter for the insufficient statistic @xmath65 .",
    "in contrast , the loss of information induced by @xmath65 may seriously impact model - choice bayesian inference . indeed",
    ", the information contained in @xmath63 is lesser than the information contained in @xmath3 and this even in most cases when @xmath63 is a sufficient statistic for _ both models_. in other words , _",
    "@xmath63 being sufficient for both @xmath26 and @xmath27 does not usually imply that @xmath63 is sufficient for @xmath66 . _ to see why this is the case , consider the most favourable case , namely when @xmath63 is a sufficient statistic for both models .",
    "we then have by the factorisation theorem @xcite that @xmath67 @xmath68 , i.e. @xmath69 thus , unless @xmath70 , as in the special case of gibbs random fields detailed below , the two bayes factors differ by the ratio @xmath71 , which is only equal to one in a very small number of known cases . this decomposition is a straightforward proof that a model - wise sufficient statistic is usually not sufficient across models , hence for model comparison .",
    "an immediate corollary is that the abc - mc approximation does not always converge to the exact bayes factor .",
    "the discrepancy between limiting abc and genuine bayesian inferences does not come as a surprise , because abc is indeed an approximation method .",
    "users of abc algorithms are therefore prepared for some degree of imprecision in their final answer , a point stressed by @xcite and @xcite when they qualify abc as exact inference on a wrong model . however , the magnitude of the difference between @xmath72 and @xmath73 expressed by is such that there is no direct connection between both answers . in a general",
    "setting , if @xmath65 has the same dimension as one component of the @xmath74 components of @xmath3 , the ratio @xmath71 is equivalent to a density ratio for a sample of size @xmath75 , hence it can be arbitrarily small or arbitrarily large when @xmath74 grows .",
    "contrastingly , the bayes factor @xmath76 is based on an equivalent to a single observation , hence does not necessarily converge with @xmath74 to the correct limit , as shown by the poisson and normal examples below and in si .",
    "the conclusion derived from the abc - based bayes factor may therefore completely differ from the conclusion derived from the exact bayes factor and there is no possibility of a generic agreement between both , or even of a manageable correction factor .",
    "this discrepancy means that a theoretical validation of the abc - based model choice procedure is currently missing and that , due to this absence , potentialy costly simulation - based assessments are required when calling for this procedure .",
    "therefore , users must be warned that abc approximations to bayes factors do not perform as standard numerical or monte carlo approximations , with the exception of gibbs random fields detailed in the next section . in all cases when @xmath71 differs from one , no inference on the true bayes factor can be derived from the abc - mc approximation without further information on the ratio @xmath71 , most often unavailable in settings where abc is necessary .",
    "@xcite also derived this relation between both bayes factors in their formula * [ 18]*. while they still advocate the use of abc model choice in the absence of sufficient statistic , we stress that no theoretical guarantee can be given on the validity of the abc approximation to the bayes factor and hence of its use as a model choice procedure .",
    "note that @xcite resort to full allelic distributions in an abc framework , instead of chosing summary statistics .",
    "they show how to apply abc using allele frequencies to draw inferences in cases where selecting suitable summary statistics is difficult ( and where the complexity of the model or the size of dataset prohibits to use full - likelihood methods ) . in such settings",
    ", abc - mc does not suffer from the divergence exhibited here because the measure of distance does not involve a reduction of the sample .",
    "the same comment applies to the abc - sysbio software of @xcite , which relies on the whole dataset .",
    "the theoretical validation of abc inference in hidden markov models by @xcite should also extend to the model choice setting because the approach does not rely on summary statistics but instead on the whole sequence of observations .",
    "in an apparent contradiction with the above , @xcite showed that the computation of the posterior probabilities of gibbs random fields under competition can be done via abc techniques , which provide a converging approximation to the true bayes factor .",
    "the reason for this result is that , for these models in the above ratio , @xmath70 .",
    "the validation of an abc comparison of gibbs random fields is thus that their specific structure allows for a sufficient statistic vector that runs across models and therefore leads to an exact ( when @xmath64 ) simulation from the posterior probabilities of the models .",
    "each gibbs random field model has its own sufficient statistic @xmath77 and @xcite exposed the fact that the vector of statistics @xmath78 is also sufficient for the joint parameter @xmath79 .",
    "@xcite point out that this specific property of gibbs random fields can be extended to any exponential family ( hence to any setting with fixed - dimension sufficient statistics , see @xcite ) .",
    "their argument is that , by including all sufficient statistics and all dominating measure statistics in an encompassing model , models under comparison are submodels of the encompassing model .",
    "the concatenation of those statistics is then jointly sufficient across models . while this encompassing principle holds in full generality , in particular when comparing models that are already embedded , we think it leads to an overly optimistic perspective about the merits of abc for model choice : in practice , most complex models do not enjoy sufficient statistics ( if only because they are beyond exponential families ) .",
    "the gibbs case processed by @xcite therefore happens to be one of the very few realistic counterexamples . as demonstrated in the next section and in the normal example in si ,",
    "using insufficient statistics is more than a mere loss of information .",
    "looking at what happens in the limiting case when one relies on a common model - wise sufficient statistic is a formal but useful study since it brings light on the potentially huge discrepancy between the abc - based and the true bayes factors . to develop a solution to the problem in the formal case of the exponential families does not help in understanding the discrepancy for non - exponential models .",
    "the difficulty with the discrepancy between @xmath72 and @xmath76 is that this discrepancy is impossible to evaluate in a general setting , while there is no reason to expect a reasonable agreement between both quantities .",
    "a first illustration was produced by @xcite in the case of ma@xmath80 models .    a simple illustration of the discrepancy due to the use of a model - wise sufficient statistic is a a sample @xmath81 that could come either from a poisson @xmath82 distribution or from a geometric @xmath83 distribution , already introduced in @xcite as a counter - example to gibbs random fields and later reprocessed in @xcite to support their sufficiency argument . in this case , the sum @xmath84 is a sufficient statistic for both models but not across models .",
    "the distribution of the sample given @xmath85 is a multinomial @xmath86 distribution when the data is poisson , while it is the uniform distribution over the @xmath3 s such that @xmath87 in the geometric case , since @xmath85 is then a negative binomial @xmath88 variable .",
    "the discrepancy ratio is therefore @xmath89 when simulating @xmath74 poisson or geometric variables and using prior distributions as exponential @xmath90 and uniform @xmath91 on the parameters of the respective models , the exact bayes factor is available and the distribution of the discrepancy is therefore available . fig [ fig : poisneg ] gives the range of @xmath72 versus @xmath76 , showing that @xmath76 is then unrelated with @xmath72 : the values produced by both approaches have nothing in common . as noted above , the approximation @xmath76 based on the sufficient statistic @xmath85 is producing figures of the magnitude of a _ single _ observation , while the true bayes factor is of the order of the sample size .",
    "comparison between the true log - bayes factor _",
    "( first axis ) _ for the comparison of a poisson model versus a negative binomial model and of the log - bayes factor based on the sufficient statistic @xmath92 _ ( second axis ) _ , for poisson _",
    "( left ) _ and negative binomial _ ( left ) _ samples of size @xmath93 , based on @xmath94 replications ]    the discrepancy between both bayes factors is in fact increasing with the sample size , as shown by the following result :    consider model selection between model 1 : @xmath82 with prior distribution @xmath95 equal to an exponential @xmath96 distribution and model 2 : @xmath83 with a uniform prior distribution @xmath97 when the observed data @xmath3 consists of iid observations with expectation @xmath98 = \\theta_0 > 0 $ ] .",
    "then @xmath99 is the minimal sufficient statistic for both models and the bayes factor based on the sufficient statistic @xmath100 , @xmath76 , satisfies @xmath101    therefore , the bayes factor based on the statistic @xmath100 is _ not _ consistent ; it converges to a non - zero , finite value .    in this specific setting , @xcite show that adding @xmath102 to the @xmath85 creates a statistic @xmath103 that is sufficient across both models .",
    "while this is mathematically correct , it does not provide further understanding of the behaviour of abc - model choice in realistic settings : outside formal examples as the one above and well - structured if complex exponential families like gibbs random fields , it is not possible to devise completion mechanisms that ensure sufficiency across models , or even select well - discriminating statistics .",
    "it is therefore more fruitful to study and detect the diverging behaviour of the abc approximation as given , rather than attempting at solving the problem in a specific and formal case .",
    "we recall that abc has first been introduced by population geneticists @xcite for statistical inference about the evolutionary history of species , because no likelihood - based approach existed apart from very simple and hence unrealistic situations .",
    "this approach has since been used in an increasing number of biological studies @xcite , most of them including model choice .",
    "it is therefore crucial to get insights in the validity of such studies , particularly when they deal with species of economical or ecological importance ( see , e.g. , @xcite ) . to this end",
    ", we need to compare abc estimates of posterior probabilities to reliable likelihood - based estimates . combining different modules based on @xcite ,",
    "it is possible to approximate the likelihood of population genetic data through importance sampling ( is ) even in complex scenarios . in order to evaluate the potential discrepancy between abc - based and likelihood - based posterior probabilities of evolutionary scenarios",
    ", we designed two experiments based on simulated data with limited information content , so that the choice between scenarios is problematic .",
    "this setting thus provides a wide enough set of intermediate values of model posterior probabilities , in order to better evaluate the divergence between abc and likelihood estimates .    in the first experiment , we consider two populations ( 1 and 2 ) having diverged at a fixed time in the past and a third population ( 3 ) having diverged from one of those two populations ( scenarios 1 and 2 respectively ) .",
    "times are set to 60 generations for the first divergence and to 30 generations for the second divergence .",
    "one hundred pseudo observed datasets have been simulated , represented by 15 diploid individuals per population genotyped at five independent microsatellite loci .",
    "these loci are assumed to evolve according to the strict stepwise mutation model ( smm ) , i.e.  when a mutation occurs , the number of repeats of the mutated gene increases or decreases by one unit with equal probability .",
    "the mutation rate , common to all five loci , has been set to @xmath104 and effective population sizes to 30 . in this experiment ,",
    "both scenarios have a single parameter : the effective population size , assumed to be identical for all three populations .",
    "we chose a uniform prior @xmath105 $ ] for this parameter ( the true value being 30 ) .",
    "the is algorithm was performed using 100 coalescent trees per particle .",
    "the marginal likelihood of both scenarios has been computed for the same set of 1000 particles and they provide the posterior probability of each scenario .",
    "the abc computations have been performed with diyabc @xcite .",
    "a reference table of 2 million datasets has been simulated using 24 usual summary statistics ( provided in table s1 ) and the posterior probability of each scenario has been estimated as their proportion in the 500 simulated datasets closest to the pseudo observed one .",
    "this population genetic setting does not allow for a choice of sufficient statistics , even at the model level .",
    "summary statistics used in the population genetic experiments , the subset column corresponding to the abc operated with 15 summary statistics and the last three statistics being only used in this reduced collection    @lll name & subset & definition +   + nal1 & yes & average number of alleles in population 1nal2 & yes & average number of alleles in population 2nal3 & yes & average number of alleles in population 3het1 & yes & average heterozygothy n population 1het2 & yes & average heterozygothy n population 2het3 & yes & average heterozygothy n population 3var1 & yes & average variance of the allele size in population 1var2 & yes & average variance of the allele size in population 2var3 & yes & average variance of the allele size in population 3mgw1 & no & garza - williamson m in population 1mgw2 & no & garza - williamson m in population 2mgw3 & no &",
    "garza - williamson m in population 3fst1 & no & average fst in population 1fst2 & no & average fst in population 2fst3 & no & average fst in population 3lik12 & no & probability that sample 1 is from population 1lik13 & no & probability that sample 1 is from population 3lik21 & no & probability that sample 2 is from population 1lik23 & no & probability that sample 2 is from population 3lik31 & no & probability that sample 3 is from population 1lik32 & no & probability that sample 3 is from population 2das12 & yes & shared allele distance between populations 1 and 2das13 & yes & shared allele distance between populations 1 and 3das23 & yes & shared allele distance between populations 2 and 3dm212 & yes & distance @xmath106 between populations 1 and 2dm213 & yes & distance @xmath106 between populations 1 and 3dm223 & yes & distance @xmath106 between populations 2 and 2 +    the second experiment also opposes two scenarios including three populations , two of them having diverged 100 generations ago and the third one resulting of a recent admixture between the first two populations ( scenario 1 ) or simply diverging from population 1 ( scenario 2 ) at the same time of 5 generations in the past . in scenario 1 , the admixture rate is @xmath107 from population 1 .",
    "pseudo observed datasets ( 100 ) of the same size as in experiment 1 ( 15 diploid individuals per population , 5 independent microsatellite loci ) have been generated for an effective population size of 1000 and mutation rates of @xmath108 .",
    "in contrast with experiment 1 , analyses included the following 6 parameters ( provided with corresponding priors ) : admixture rate ( @xmath109 $ ] ) , three effective population sizes ( @xmath110 $ ] ) , the time of admixture / second divergence ( @xmath111 $ ] ) and the time of the first divergence ( @xmath112 $ ] ) . to account for an higher complexity in the scenarios ,",
    "the is algorithm was performed with 10,000 coalescent trees per particle .",
    "apart from this change , both abc and likelihood analyses have been performed in the same way as experiment 1 .",
    "fig [ fig : res11 ] shows a reasonable fit between the exact posterior probability of model 1 ( evaluated by is ) and the abc approximation in the first experiment on most of the 100 simulated datasets , even though the abc approximation is biased towards @xmath113 . when using @xmath113 as the decision boundary between model 1 and model 2 , there is hardly any discrepancy between both approaches , demonstrating that model choice based on abc can be trusted in this case .",
    "fig [ fig : res12 ] considers the same setting when moving from 24 to 15 summary statistics ( given in table s1 ) : the fit somehow degrades .",
    "in particular , the number of opposite conclusions in the model choice moves to @xmath114 . in the more complex setting of the second experiment , the discrepancy worsens ,",
    "as shown on fig [ fig : res2 ] . the number of opposite conclusions reaches @xmath115 and the fit between both versions of the posterior probabilities is considerably degraded , with a correlation coefficient of @xmath116 .",
    "comparison of is and abc estimates of the posterior probability of scenario 1 in the first population genetic experiment , using 24 summary statistics ]    same caption as fig [ fig : res11 ] when using 15 summary statistics ]    comparison of is and abc estimates of the posterior probability of scenario 1 in the second population genetic experiment ]    the validity of the importance sampling approximation can obviously be questioned in both experiments , however fig [ fig : repeat1 ] and fig [ fig : repeat2 ] display a strong stability of the posterior probability is approximation across 10 independent runs for 5 different datasets and gives proper confidence in this approach .",
    "increasing the number of loci to 50 and the sample size to 100 individuals per population ( see si ) leads to posterior probabilities of the true scenario overwhelmingly close to one ( fig [ fig : resml2 ] ) , thus bluring the distinction between abc and likelihood based estimates but also reassuring on the ability of abc to provide the right choice of model with a higher information content of the data . actually , we note that , for this experiment , all abc - based decisions conclude in favour of the correct model",
    ".     boxplots of the posterior probabilities evaluated over 10 independent monte carlo evaluations , for five independent simulated datasets in the first population genetic experiment ]     boxplots of the posterior probabilities evaluated over 10 independent monte carlo evaluations , for five independent simulated datasets in the second population genetic experiment ]     comparison between two approximations of the posterior probabilities of scenario 1 based on importance sampling with 50,000 particles _ ( first axis ) _ and abc _",
    "( second axis ) _ for the larger population genetic experiment ]",
    "since its introduction by @xcite and @xcite , abc has been extensively used in several areas involving complex likelihoods , primarily in population genetics , both for point estimation and testing of hypotheses . in realistic settings , with the exception of gibbs random fields , which satisfy a resilience property with respect to their sufficient statistics ,",
    "the conclusions drawn on model comparison can not be trusted _ per se _ but require further simulations analyses as to the pertinence of the ( abc ) bayes factor based on the summary statistics .",
    "this paper has examined in details only the case when the summary statistics are sufficient for both models , while practical situations imply the use of insufficient statistics .",
    "the rapidly increasing number of applications estimating posterior probabilities by abc indicates a clear need for further evaluations of the worth of those estimations .",
    "further research is needed for producing trustworthy approximations to the posterior probabilities of models . at this stage , unless the whole data is involved in the abc approximation as in @xcite , our conclusion on abc - based model choice is to exploit the approximations in an exploratory manner as measures of discrepancies rather than genuine posterior probabilities .",
    "this direction relates with the analyses found in @xcite .",
    "furthermore , a version of this exploratory analysis is already provided in the diy - abc software of @xcite .",
    "an option in this software allows for the computation of a monte carlo evaluation of false allocation rates resulting from using the abc posterior probabilities in selecting a model as the most likely .",
    "for instance , in the setting of both our population genetic experiments , diy - abc gives false allocation rates equal to @xmath117 ( under scenarios 1 and 2 ) and @xmath118 and @xmath119 ( under scenarios 1 and 2 ) , respectively .",
    "this evaluation obviously shifts away from the performances of abc as an approximation to the posterior probability towards the performances of the whole bayesian apparatus for selecting a model , but this nonetheless represents a useful and manageable quality assessment for practitioners .    the first three authors work has been partly supported by agence nationale de la recherche via the 20092013 project emile .",
    "they are grateful to the reviewers and to michael stumpf for their comments .",
    "computations were performed on the inra cbgp and migale clusters .",
    "the following reproduces the poisson geometric illustration in a normal model .",
    "if we look at a fully normal @xmath120 setting , we have @xmath121 hence @xmath122 if we reparameterise the observations into @xmath123 , we do get @xmath124 ^ 2   \\big/2 \\right\\}\\end{aligned}\\ ] ] since the jacobian is @xmath61 .",
    "hence @xmath125 ^ 2   /2 \\right\\ } \\sigma^{-n}\\ ] ] considering both models @xmath126 the discrepancy ratio is then given by @xmath127 ^ 2   \\right)\\right\\}\\ ] ] and is connected with the lack of consistency of the bayes factor :    consider model selection between model 1 : @xmath128 and model 2 : @xmath129 , @xmath130 and @xmath131 being given , with prior distributions @xmath132 equal to a @xmath133 distribution and when the observed data @xmath3 consists of iid observations with finite mean and variance .",
    "then @xmath99 is the minimal sufficient statistic for both models and the bayes factor based on the sufficient statistic @xmath100 , @xmath76 , satisfies @xmath134    fig [ fig : twonormal ] illustrates the behaviour of the discrepancy ratio when @xmath135 and @xmath136 , for datasets of size @xmath137 simulated according to both models . the discrepancy ( expressed on a log scale )",
    "is once again dramatic , in concordance with the above lemma .",
    "empirical distributions of the log discrepancy @xmath138 for datasets of size @xmath137 simulated from @xmath128 _",
    "( left ) _ and @xmath129 _ ( right ) _ distributions when @xmath135 and @xmath136 , based on @xmath139 replications and a flat prior ]    if we now turn to an alternative choice of sufficient statistic , using the pair @xmath140 with @xmath141 we follow the solution of @xcite . using a conjugate prior @xmath142 , the true bayes factor is equal to the bayes factor based on the corresponding distributions of the pair @xmath140 in the respective models .",
    "therefore , with sufficient computing power , the abc approximation to the bayes factor can be brought arbitrarily close to the true bayes factor . however",
    ", this coincidence does not bring any intuition on the behaviour of the abc approximations in realistic settings .",
    "we also considered a more informative population genetic experiment with the same scenarios ( 1 and 2 ) as in the second experiment .",
    "one hundred datasets were simulated under scenario 1 with 3 populations , i.e.  6 parameters .",
    "we take 100 diploid individuals per population , 50 loci per individual .",
    "this thus corresponds to 300 genotypes per dataset .",
    "the is algorithm was performed using 100 coalescent trees per particle .",
    "the marginal likelihood of both scenarios has been computed for the same set for both 1000 particles ( is1 ) and 50,000 particles ( is2 ) .",
    "a national cluster of 376 processors ( including 336 quad core processors ) was used for this massive experiment ( which required more than 12 calendar days for the importance sampling part ) .",
    "the confidence about the is approximation can be assessed on fig [ fig : resml2 ] , which shows that both runs most always provide the same numerical value , which almost uniformly is very close to one .",
    "this makes the fit of the abc approximation to the true value harder to assess , even though we can spot a trend towards under - estimation .",
    "furthermore , they almost all lead to correctly select model 1 ."
  ],
  "abstract_text": [
    "<S> approximate bayesian computation ( abc ) have become an essential tool for the analysis of complex stochastic models . </S>",
    "<S> grelaud et al . </S>",
    "<S> ( 2009 , bayesian ana 3:427442 ) advocated the use of abc for model choice in the specific case of gibbs random fields , relying on a inter - model sufficiency property to show that the approximation was legitimate . </S>",
    "<S> we implemented abc model choice in a wide range of phylogenetic models in the diy - abc software ( cornuet et al . </S>",
    "<S> ( 2008 ) bioinfo 24:27132719 ) . </S>",
    "<S> we now present arguments as to why the theoretical arguments for abc model choice are missing , since the algorithm involves an unknown loss of information induced by the use of insufficient summary statistics . </S>",
    "<S> the approximation error of the posterior probabilities of the models under comparison may thus be unrelated with the computational effort spent in running an abc algorithm . </S>",
    "<S> we then conclude that additional empirical verifications of the performances of the abc procedure as those available in diyabc are necessary to conduct model choice .    </S>",
    "<S> nference on population genetic models such as coalescent trees is one representative example of cases when statistical analyses like bayesian inference can not easily operate because the likelihood function associated with the data can not be computed in a manageable time @xcite . </S>",
    "<S> the fundamental reason for this impossibility is that the model associated with coalescent data has to integrate over trees of high complexity .    in such settings , traditional approximation tools like monte carlo simulation @xcite from the posterior distribution </S>",
    "<S> are unavailable for practical purposes . indeed , due to the complexity of the latent structures defining the likelihood ( like the coalescent tree ) , their simulation is too unstable to bring a reliable approximation in a manageable time . </S>",
    "<S> such complex models call for a practical if cruder approximation method , the abc methodology @xcite . </S>",
    "<S> this rejection technique bypasses the computation of the likelihood via simulations from the corresponding distribution ( see @xcite and @xcite for recent surveys , and @xcite for the wide and successful array of applications based on implementations of abc in genomics and ecology ) .    </S>",
    "<S> we argue here that abc is a generally valid approximation method for doing bayesian inference in complex models . </S>",
    "<S> however , without further justification , abc methods can not be trusted to discriminate between two competing models when based on insufficient summary statistics . </S>",
    "<S> we exhibit simple examples in which the information loss due to insufficiency leads to inconsistency , i.e.  when the abc model selection fails to recover the true model , even with infinite amounts of observation and computation . on the one hand </S>",
    "<S> , abc using the entire data leads to a consistent model choice decision but it is clearly infeasible in most settings . on the other hand , too much information loss due </S>",
    "<S> to insuffiency leads to a statistically invalid decision procedure . </S>",
    "<S> the challenge is in achieving a balance between information loss and consistency . </S>",
    "<S> theoretical results that mathematically validate model choice for insufficient statistics are currently lacking on a general basis .    </S>",
    "<S> our conclusion at this stage is to opt for a cautionary approach in abc model choice , handling it as an exploratory tool rather than trusting the bayes factor approximation . </S>",
    "<S> the corresponding degree of approximation can not be evaluated , except via monte carlo evaluations of the model selection performances of abc . </S>",
    "<S> more empirical measures such as those proposed in the diy - abc software @xcite and in @xcite thus seem to be the only available solution at the current time for conducting model comparison .    </S>",
    "<S> we stress that , while @xcite repeatedly expressed reservations about the formal validity of the abc approach in statistical testing , those criticisms were rebutted in @xcite and are not relevant for the current paper . </S>"
  ]
}