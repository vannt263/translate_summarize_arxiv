{
  "article_text": [
    "stochastic spiking neurons are often used in biological network models to account for the variability of neural responses  @xcite .",
    "stochastic neural responses can have important computational implications such as allowing neural networks to sample from probability distributions  @xcite or to transmit small subthreshold input signals  @xcite . in machine learning ,",
    "networks using neuron - like units with stochastic activation functions are often used to realize probabilistic generative models of input data  @xcite .",
    "many multi - layer networks used in classification and encoding tasks  @xcite also make use of stochastic neuron elements to limit the amount of information that flows from one layer to another during unsupervised pre - training .",
    "an open question is how such stochastic networks can be realized efficiently on custom silicon chips .",
    "custom chip implementations of either machine learning network architectures  @xcite or the more biologically inspired spiking networks  @xcite can offer significant performance gains compared to simulating these networks on conventional general - purpose cpus or gpus .",
    "straightforward implementations of stochastic networks would use an explicit true- or pseudo - random noise source in each unit to realize uncorrelated fluctuations .",
    "we propose here an efficient , distributed , and easily implementable scheme for the generation of largely uncorrelated fluctuations in a large number of neuron elements .",
    "the scheme exploits the non - repeating phase relations in a quasi - periodic system .",
    "each neuron element has access to the state of an analog oscillator . due to the inevitable inhomogeneities in the silicon fabrication process",
    ", the different oscillators are guaranteed to be incommensurable , i.e , have oscillation frequencies that are not rational multiples of each other .",
    "the phase relations between these oscillators varies irregularly in an aperiodic manner . by developing the communication scheme between the neuron elements",
    "so that the interaction strength between a group of neurons depends both on the weights between them as well as the phase relations within the group , we can obtain neural activity that changes in a non - repeating manner and that can be modelled in stochastic terms . in this paper",
    "we present a stochastic formulation that matches the statistics of this quasi - periodic system and that replaces each deterministic neuron with an equivalent neuron having a stochastic activation function .",
    "we investigate the fidelity of this approximation and evaluate how the quasi - periodic system performance differs from a system that uses high quality pseudo - random number generators .",
    "we focus on digital neurons where each neuron is a simple finite state machine ( fsm )",
    ". the neurons / fsms communicate in an event based fashion .",
    "we use this system to implement a prototypical stochastic network which is the restricted boltzmann machine .",
    "we present measurements from a physical implementation of such a system on a custom vlsi chip to demonstrate that the mismatch inherent in a standard vlsi process is sufficient to make different instances of the the same oscillator circuit oscillate at different frequencies .",
    "we use the custom vlsi chip to implement a simple sampling task .",
    "figure  [ fig : sigmoid_a ] shows the general structure of a neuron .",
    "it is composed of a fsm in which events arriving on the inputs ports @xmath0 trigger state transitions . associated with the fsm",
    "is an analog oscillator that generates a regular train of events .",
    "the neuron routes each event from this internal oscillator to one of the output ports .",
    "if the fsm is in state @xmath1 when the analog oscillator generates an event , this event is routed to output port @xmath2 .",
    "a neuron with @xmath3 output ports can transmit @xmath4 bits of information in each oscillator cycle .",
    "we consider the index of the output port on which a neuron last generated an event as the neuron s current value .",
    "neurons can be connected together ( output ports to input ports ) and we assume the oscillator frequencies in the different neurons are incommensurable .    [",
    "fig : sigmoid ]    0.4   neurons with value @xmath5 and @xmath6 neurons with value @xmath7 .",
    "( ) fraction of @xmath5 events generated by the target neuron in after @xmath8 events as a function of @xmath9 ( the fraction of afferent @xmath5 neurons ) .",
    "( ) shape of the target neuron activation function crucially depends on the depth of its counter / fsm .",
    "( ) activation functions when each neuron generates a periodic train of events ( quasi - periodic ) or a poisson train ( poisson ) , or calculated directly from the stationary distribution of the neuron - equivalent markov chain ( stationary ) . lines in , , and are averages over 5 trials .",
    "error bars are the standard deviation .",
    "oscillator frequencies redrawn in each trial uniformly from the range @xmath10$]hz .",
    ", title=\"fig : \" ] [ fig : sigmoid_a ]    0.45   neurons with value @xmath5 and @xmath6 neurons with value @xmath7 .",
    "( ) fraction of @xmath5 events generated by the target neuron in after @xmath8 events as a function of @xmath9 ( the fraction of afferent @xmath5 neurons ) .",
    "( ) shape of the target neuron activation function crucially depends on the depth of its counter / fsm .",
    "( ) activation functions when each neuron generates a periodic train of events ( quasi - periodic ) or a poisson train ( poisson ) , or calculated directly from the stationary distribution of the neuron - equivalent markov chain ( stationary ) . lines in , , and are averages over 5 trials .",
    "error bars are the standard deviation .",
    "oscillator frequencies redrawn in each trial uniformly from the range @xmath10$]hz .",
    ", title=\"fig : \" ] [ fig : sigmoid_b ]     +    0.25   neurons with value @xmath5 and @xmath6 neurons with value @xmath7 .",
    "( ) fraction of @xmath5 events generated by the target neuron in after @xmath8 events as a function of @xmath9 ( the fraction of afferent @xmath5 neurons ) .",
    "( ) shape of the target neuron activation function crucially depends on the depth of its counter / fsm .",
    "( ) activation functions when each neuron generates a periodic train of events ( quasi - periodic ) or a poisson train ( poisson ) , or calculated directly from the stationary distribution of the neuron - equivalent markov chain ( stationary ) . lines in , , and are averages over 5 trials .",
    "error bars are the standard deviation .",
    "oscillator frequencies redrawn in each trial uniformly from the range @xmath10$]hz .",
    ", title=\"fig : \" ] [ fig : sigmoid_c ]    0.25   neurons with value @xmath5 and @xmath6 neurons with value @xmath7 .",
    "( ) fraction of @xmath5 events generated by the target neuron in after @xmath8 events as a function of @xmath9 ( the fraction of afferent @xmath5 neurons ) .",
    "( ) shape of the target neuron activation function crucially depends on the depth of its counter / fsm .",
    "( ) activation functions when each neuron generates a periodic train of events ( quasi - periodic ) or a poisson train ( poisson ) , or calculated directly from the stationary distribution of the neuron - equivalent markov chain ( stationary ) .",
    "lines in , , and are averages over 5 trials .",
    "error bars are the standard deviation .",
    "oscillator frequencies redrawn in each trial uniformly from the range @xmath10$]hz .",
    ", title=\"fig : \" ] [ fig : sigmoid_d ]    0.45   neurons with value @xmath5 and @xmath6 neurons with value @xmath7 .",
    "( ) fraction of @xmath5 events generated by the target neuron in after @xmath8 events as a function of @xmath9 ( the fraction of afferent @xmath5 neurons ) .",
    "( ) shape of the target neuron activation function crucially depends on the depth of its counter / fsm .",
    "( ) activation functions when each neuron generates a periodic train of events ( quasi - periodic ) or a poisson train ( poisson ) , or calculated directly from the stationary distribution of the neuron - equivalent markov chain ( stationary ) . lines in , , and are averages over 5 trials .",
    "error bars are the standard deviation .",
    "oscillator frequencies redrawn in each trial uniformly from the range @xmath10$]hz .",
    ", title=\"fig : \" ] [ fig : sigmoid_e ]     +    0.45   neurons with value @xmath5 and @xmath6 neurons with value @xmath7 .",
    "( ) fraction of @xmath5 events generated by the target neuron in after @xmath8 events as a function of @xmath9 ( the fraction of afferent @xmath5 neurons ) .",
    "( ) shape of the target neuron activation function crucially depends on the depth of its counter / fsm .",
    "( ) activation functions when each neuron generates a periodic train of events ( quasi - periodic ) or a poisson train ( poisson ) , or calculated directly from the stationary distribution of the neuron - equivalent markov chain ( stationary ) .",
    "lines in , , and are averages over 5 trials .",
    "error bars are the standard deviation .",
    "oscillator frequencies redrawn in each trial uniformly from the range @xmath10$]hz .",
    ", title=\"fig : \" ] [ fig : sigmoid_f ]    0.45   neurons with value @xmath5 and @xmath6 neurons with value @xmath7 .",
    "( ) fraction of @xmath5 events generated by the target neuron in after @xmath8 events as a function of @xmath9 ( the fraction of afferent @xmath5 neurons ) .",
    "( ) shape of the target neuron activation function crucially depends on the depth of its counter / fsm .",
    "( ) activation functions when each neuron generates a periodic train of events ( quasi - periodic ) or a poisson train ( poisson ) , or calculated directly from the stationary distribution of the neuron - equivalent markov chain ( stationary ) .",
    "lines in , , and are averages over 5 trials .",
    "error bars are the standard deviation .",
    "oscillator frequencies redrawn in each trial uniformly from the range @xmath10$]hz .",
    ", title=\"fig : \" ] [ fig : sigmoid_g ]    consider the fsm of a simple neuron , neuron @xmath11 , that is shown in the top part of fig .",
    "[ fig : sigmoid_b ] .",
    "this neuron receives a stream of @xmath5 events from two neurons and a stream of @xmath7 events from one neuron . from the fsm of @xmath11 , it is clear that @xmath11 will route the internal oscillator events to the @xmath5 ( @xmath7 ) port if the last event it received was @xmath5 ( @xmath7 ) as shown in fig .",
    "[ fig : sigmoid_b ] . even though the values of the three source neurons are constant , eventually , the @xmath7 input event arrives just before the end of the cycle of @xmath11 , and the value of @xmath11 changes from @xmath5 to @xmath7 .",
    "the value of a neuron ( the identity of its last output event ) thus does not solely depend on the values of the source neurons but it also crucially depends on the order of arrival of their events .",
    "this order is continuously changing in an aperiodic manner due the incommensurable oscillation frequencies of the oscillators inside the neurons .",
    "figure  [ fig : sigmoid_c ] shows the fsm of a slightly more complex neuron that also has two input ports and two output ports .",
    "we refer to neurons having such a counter - like fsm as sigmoidal neurons .",
    "assume this neuron is receiving events from @xmath12 constant - value source neurons as shown in fig .",
    "[ fig : sigmoid_d ] where @xmath13 of the source neurons are sending @xmath5 events and @xmath6 are sending @xmath7 events .",
    "figure  [ fig : sigmoid_e ] shows that the fraction of @xmath5 events generated by the sigmoidal neuron of fig .",
    "[ fig : sigmoid_c ] is a sigmoidal function of @xmath9 or the fraction of @xmath5 events impinging on the neuron ( the neuron has to generate either a @xmath5 or a @xmath7 event for each event from its internal oscillator ) .",
    "the shape of the activation function in fig .",
    "[ fig : sigmoid_e ] is robust to changes in @xmath12 .",
    "it , however , crucially depends on the depth of the counter in the sigmoidal neuron as shown in fig .",
    "[ fig : sigmoid_f ] . the fsm of the sigmoidal neuron shown in fig .",
    "[ fig : sigmoid_c ] has depth @xmath14 while the fsm of the neuron in fig .",
    "[ fig : sigmoid_b ] has depth @xmath5 .    to accurately calculate the fraction of @xmath5 events generated by the target sigmoidal neuron",
    ", we need to enumerate all possible orderings of the @xmath12 source neurons events within one cycle of the target neuron and calculate what fraction of these orderings will put the target neuron s fsm in one of the @xmath5 output states ( the yellow states ) .",
    "the calculation will depend on the target neuron s initial state and is further complicated by the difference in oscillator frequencies which might lead to some source neurons not generating any events , or generating multiple events , during one cycle of the target neuron .",
    "the analysis can be greatly simplified if we interpret the system behavior in stochastic terms . at the heart of this stochastic interpretation",
    "is the following approximation :    _ the periodic train of events generated by a neuron is treated as a poisson train _",
    "this approximation is similar to the stochastic approximation previously used to analyze the behavior of quasi - periodic winner - take - all networks  @xcite . under the poisson event generation assumption ,",
    "the probability at any time that the next input event is @xmath5 is @xmath9 ( the fraction of @xmath5 source neurons ) , and the probability that the next input event is @xmath7 is @xmath15 .",
    "the fsm of a neuron can thus be cast as a markov chain having the same structure but with each @xmath5 edge replaced by an edge with transition probability @xmath9 and each @xmath7 edge by an edge with transition probability @xmath15 .",
    "the probability of a particular output is the sum of the probabilities of the states yielding that output in the markov chain stationary distribution . for each @xmath9 value",
    ", we can thus calculate the stationary distribution of the markov chain and obtain the probability of generating a @xmath5 event .",
    "this is plotted in fig .",
    "[ fig : sigmoid_g ] together with the activation functions of the deterministic quasi - periodic system and the stochastic system where the oscillators generate a poisson ( instead of a periodic ) train of events .",
    "the stochastic approximation is valid but becomes less accurate as the depth of the sigmoidal neuron fsm / counter increases .",
    "that is because the state of a deeper counter reflects a longer history of events and in that longer history , differences between the periodic and the poissonian event generation mechanisms become apparent .",
    "for instance , the poissonian neuron can generates two events in quick succession which is impossible in the periodic case .",
    "the sequence of bits / events generated by the target neuron in the quasi - periodic system in fig .  [ fig : sigmoid_d ] has small but non - decaying correlations as shown in fig .",
    "[ fig : corr_a ] . a deeper counter ( longer memory ) in the target neuron results in higher correlations",
    "as it becomes more difficult for incoming events to yield a state / value at the cycle s end that is independent of the state at the cycle s beginning ( which reflects the previous bit value ) .",
    "the non - decaying and non - repeating correlation structure is a product of the quasi - periodic nature of the system which causes the phase relations among the oscillators to almost repeat after a while and yield similar event orderings .",
    "two target neurons having different frequencies and receiving events from the same neurons generate sequences of bits with small cross - correlation which is on par with the poissonian system as shown in fig .",
    "[ fig : corr_b ] .    in summary , the quasi - periodic event - based system shown in fig .",
    "[ fig : sigmoid_d ] admits a stochastic interpretation in which event generation in each neuron is assumed to be poissonian instead of periodic .",
    "this interpretation works because of the finite memory in each neuron which renders its output sensitive to the order of arrival of input events .",
    "since this order changes in an irregular manner , the target neuron can see it as `` random '' .",
    "empirically , we observe that the stochastic approximation is accurate for other types of neurons / fsms as long as the number of source neurons is large compared to the number of states in the target neuron s fsm .    [",
    "fig : corr ]    0.45   bits generated by a target neuron when @xmath16 in the periodic and poissonian event generation cases .",
    "( ) cross - correlation of 2 sequences of bits generated by two target neurons receiving the same input when @xmath16 .",
    "cross - correlation was calculated after adjusting the sequence of bits generated by one neuron so that the temporally closest events / bits in the two sequences occur in the same sequence position.,title=\"fig : \" ] [ fig : corr_a ]    0.45   bits generated by a target neuron when @xmath16 in the periodic and poissonian event generation cases .",
    "( ) cross - correlation of 2 sequences of bits generated by two target neurons receiving the same input when @xmath16 .",
    "cross - correlation was calculated after adjusting the sequence of bits generated by one neuron so that the temporally closest events / bits in the two sequences occur in the same sequence position.,title=\"fig : \" ] [ fig : corr_b ]      the behavior of a network of neurons , where each neuron has the form shown in fig .",
    "[ fig : sigmoid_c ] can be interpreted in probabilistic sampling terms .",
    "the network connectivity ( the way events are routed ) induces a probability distribution over the possible states of the network . in a gibbs sampling fashion",
    ", we interpret each event from a neuron as a sample drawn from the distribution over this neuron s values conditioned on the current state of all other neurons . under this interpretation",
    ", we show that the quasi - periodic network can reproduce the sampling behavior of a stochastic rbm .",
    "an rbm is a markov random field on a bipartite graph of binary 0/1 units .",
    "the graph has @xmath17 visible units and @xmath18 hidden units .",
    "visible and hidden units are bidirectionally connected according to the @xmath19 weight matrix @xmath20",
    ". there are no connections between visible units or between hidden units . @xmath21 and @xmath22 are the visible and hidden bias vectors respectively . @xmath23 and @xmath24 are the vectors representing the states of the visible and hidden units respectively . the probability of a particular configuration is :    [ eq : rbm ] @xmath25 @xmath26    where @xmath27 is the energy of configuration @xmath28 $ ] , @xmath11 the model temperature , and @xmath29 the normalizing constant or partition function . generating samples from the distribution in eq .",
    "[ eq : rbm ] is typically done through gibbs sampling which updates a visible(hidden ) unit conditioned on the current state of the hidden(visible ) units by drawing a sample from :    @xmath30    where @xmath31 is the logistic sigmoid function . a hidden or visible unit / neuron thus needs to have a logistic sigmoid stochastic activation function so that its output corresponds to a gibbs sampling update step .    figure  [ fig : rbm_a ] shows that the activation function of a sigmoidal neuron with depth @xmath14 closely matches that of a logistic sigmoid . as shown in fig .",
    "[ fig : sigmoid_e ] , the shape of the activation function is robust to the number of source neurons .",
    "the sigmoidal neuron shown in fig .",
    "[ fig : sigmoid_c ] could thus be used to represent a unit in an rbm .",
    "the sigmoidal neuron s activation function is plotted as a function of the excess fraction of incoming @xmath5 events : @xmath32 . for each neuron , we thus need to make the quantity @xmath32 equal to a weighted sum of the states of the source units , plus a bias term as in eq .",
    "[ eq : sample ] .    due to the discrete nature of the neurons",
    ", we can only use discrete weights and biases . to implement an rbm using @xmath33 possible weights / biases : @xmath34",
    ", we need to use the neuron shown in fig .",
    "[ fig : rbm_b ] to implement each rbm unit .",
    "the neuron is similar to the one in fig .",
    "[ fig : sigmoid_c ] except that it has @xmath35 independent oscillators that each generates a periodic train of events .",
    "the events from each oscillator can go to one of two output ports based on the state of the neuron s fsm .",
    "thus , the neuron generates four event streams .",
    "if the neuron s state is @xmath36 , @xmath37 , or @xmath38 .",
    "the events from the @xmath35 oscillators are routed to output ports @xmath39 , @xmath40 , @xmath41 , and @xmath42 , otherwise they are routed to @xmath43 , @xmath44 , @xmath45 , and @xmath46 .",
    "figure  [ fig : rbm_c ] is an example of how to connect neurons / units to implement weighted connections with discrete weights . only the visible to hidden connections ( which are a mirror of the hidden to visible connections ) and",
    "the hidden biases are shown .",
    "the four @xmath7 event streams from a visible unit are distributed equally on the @xmath7 and @xmath5 input ports of the target neurons .",
    "the four @xmath5 event streams of a visible unit are distributed on each target neuron s input ports so as to implement weighted connections .",
    "the connection scheme ensures that regardless of the state of the visible units , the number of incoming event streams at a hidden units ( @xmath12 ) is always @xmath47 .",
    "the hidden biases are implemented as weighted connections from an always @xmath5 neuron .",
    "it is easy to verify in fig .",
    "[ fig : rbm_c ] that the excess fraction of incoming @xmath5 events is @xmath48 and @xmath49 for hidden units / neurons @xmath50 and @xmath51 respectively ( the weights are scaled by a constant factor ) .",
    "arbitrary rbms with weights / biases in the range @xmath34 can be similarly implemented .",
    "we implemented an rbm with @xmath52 visible and @xmath52 hidden units whose weights and biases are drawn randomly from the integers between @xmath53 and @xmath14 ( each neuron / unit has @xmath54 oscillators and @xmath54 output event streams ) . the rbm is small enough to enable the numerical calculation of the probabilities of each of the @xmath55 configurations .",
    "figure  [ fig : rbm_c ] shows the evolution of the @xmath56 divergence between the sample distribution and the true rbm distribution in two cases : when the samples are generated from a conventional rbm using gibbs sampling and when they are generated from the quasi - periodic network implementation . in the quasi - periodic network ,",
    "sampling is done in a decentralized manner .",
    "each neuron / unit generates an event / sample whenever one of its internal oscillators generates an event .",
    "the latest event / sample generated by each unit defines the current state of the network .",
    "a new sample is obtained as soon as each oscillator has generated at least one event since the last sample was recorded .",
    "as the number of samples increases , the sampling distribution approaches the true rbm distribution in both cases as shown in fig .",
    "[ fig : rbm_d ] .",
    "the quasi - periodic network sampling distribution eventually becomes quite close to the true rbm distribution , yet not as close as the gibbs sampler distribution .",
    "we believe this is because the neuron / unit activation function is not exactly a logistic sigmoid ( fig .",
    "[ fig : rbm_a ] ) which renders the quasi - periodic network distribution slightly different from the ideal distribution in eq .",
    "[ eq : rbm ] .",
    "this shows , however , that a quasi - periodic event - based system can closely approximate a gibbs sampler .",
    "[ fig : rbm ]    0.45   neuron activation as a function of the excess fraction of input @xmath5 events closely matches a logistic sigmoid function .",
    "( ) implementation of a sigmoidal neuron with @xmath35 output event streams .",
    "( ) example rbm with weights @xmath57 , @xmath58 , @xmath59 , and @xmath60 , and hidden biases @xmath61 and @xmath62 . only visible to hidden connections and hidden biases are shown .",
    "next to each input port of a hidden unit is a list of the output ports of the visible units whose events are routed to that input port .",
    "@xmath7 output ports are in red , and @xmath5 output ports are in blue .",
    "the probability of generating a @xmath5 event for each hidden neuron is shown .",
    "@xmath63 is the sigmoidal neuron activation function shown in .",
    "( ) @xmath56 divergence between the sampling distribution and the true probability distribution of an rbm when the samples are generated by a gibbs sampler ( blue ) and by the quasi - periodic network implementation of the rbm ( red ) .",
    "simulation was repeated four times with different random rbms and yielded virtually identical curves.,title=\"fig : \" ] [ fig : rbm_a ]    0.27   neuron activation as a function of the excess fraction of input @xmath5 events closely matches a logistic sigmoid function .",
    "( ) implementation of a sigmoidal neuron with @xmath35 output event streams .",
    "( ) example rbm with weights @xmath57 , @xmath58 , @xmath59 , and @xmath60 , and hidden biases @xmath61 and @xmath62 . only visible to hidden connections and hidden biases are shown .",
    "next to each input port of a hidden unit is a list of the output ports of the visible units whose events are routed to that input port .",
    "@xmath7 output ports are in red , and @xmath5 output ports are in blue .",
    "the probability of generating a @xmath5 event for each hidden neuron is shown .",
    "@xmath63 is the sigmoidal neuron activation function shown in .",
    "( ) @xmath56 divergence between the sampling distribution and the true probability distribution of an rbm when the samples are generated by a gibbs sampler ( blue ) and by the quasi - periodic network implementation of the rbm ( red ) .",
    "simulation was repeated four times with different random rbms and yielded virtually identical curves.,title=\"fig : \" ] [ fig : rbm_b ]     +    0.5   neuron activation as a function of the excess fraction of input @xmath5 events closely matches a logistic sigmoid function .",
    "( ) implementation of a sigmoidal neuron with @xmath35 output event streams .",
    "( ) example rbm with weights @xmath57 , @xmath58 , @xmath59 , and @xmath60 , and hidden biases @xmath61 and @xmath62 . only visible to hidden connections and hidden biases are shown .",
    "next to each input port of a hidden unit is a list of the output ports of the visible units whose events are routed to that input port .",
    "@xmath7 output ports are in red , and @xmath5 output ports are in blue .",
    "the probability of generating a @xmath5 event for each hidden neuron is shown .",
    "@xmath63 is the sigmoidal neuron activation function shown in .",
    "( ) @xmath56 divergence between the sampling distribution and the true probability distribution of an rbm when the samples are generated by a gibbs sampler ( blue ) and by the quasi - periodic network implementation of the rbm ( red ) .",
    "simulation was repeated four times with different random rbms and yielded virtually identical curves.,title=\"fig : \" ] [ fig : rbm_c ]    0.45   neuron activation as a function of the excess fraction of input @xmath5 events closely matches a logistic sigmoid function .",
    "( ) implementation of a sigmoidal neuron with @xmath35 output event streams .",
    "( ) example rbm with weights @xmath57 , @xmath58 , @xmath59 , and @xmath60 , and hidden biases @xmath61 and @xmath62 . only visible to hidden connections and hidden biases are shown .",
    "next to each input port of a hidden unit is a list of the output ports of the visible units whose events are routed to that input port . @xmath7",
    "output ports are in red , and @xmath5 output ports are in blue .",
    "the probability of generating a @xmath5 event for each hidden neuron is shown .",
    "@xmath63 is the sigmoidal neuron activation function shown in .",
    "( ) @xmath56 divergence between the sampling distribution and the true probability distribution of an rbm when the samples are generated by a gibbs sampler ( blue ) and by the quasi - periodic network implementation of the rbm ( red ) .",
    "simulation was repeated four times with different random rbms and yielded virtually identical curves.,title=\"fig : \" ] [ fig : rbm_d ]",
    "we fabricated a custom chip that contains 2048 binary units / neurons in a standard @xmath64 nm vlsi process .",
    "each unit has two input ports and two output ports and a 2-state fsm similar to the one shown in fig .",
    "[ fig : sigmoid_b ] .",
    "the neuron binary state encodes the input port on which the last input event arrived .",
    "when the internal oscillator in a neuron generates an event , the event is routed to the output port corresponding to the current state of the neuron ( see fig .  [ fig : sigmoid_b ] ) . as shown in fig .",
    "[ fig : hwnw_a ] , due to transistor mismatch , the oscillator frequencies in the different units are significantly different and , since physical uncoupled analog oscillators are used , incommensurable . fig .",
    "[ fig : hwnw_b ] shows the structure of the network implemented on the chip .",
    "the network has @xmath52 pattern units , @xmath65 to @xmath66 .",
    "each receives input events from @xmath67 input units .",
    "the uni - directional connection from an input unit to a pattern unit can either have weight @xmath5 ( example @xmath68 to @xmath65 ) or weight @xmath7 ( example @xmath69 to @xmath66 ) .",
    "pattern unit @xmath70 is thus associated with a binary weight vector @xmath71 that defines its preferred pattern , i.e , the input unit values that will maximize its probability of generating a @xmath5 event .",
    "whenever a pattern unit generates a @xmath5 event , it shuts down all pattern units ( including itself ) .",
    "an event from the clk unit activates the pattern units and sets them at state @xmath7 .",
    "let the binary vector @xmath72 denote the state of the input units .",
    "define @xmath73 as the number of matching entries in the vectors @xmath71 and @xmath72 , divided by the vector lengths ( @xmath67 ) . assuming the oscillator frequencies in the different units are not very different",
    ", the number of events arriving at the @xmath74 port of pattern unit @xmath70 in one oscillation cycle divided by the total number of received event , @xmath75 , is on average equal to @xmath73 . assuming event generation in each unit is poissonian instead of periodic , the probability of a pattern unit generating a one event @xmath76 is proportional to @xmath77 ( see the linear activation function in fig .",
    "[ fig : sigmoid_f ] ) .",
    "but since pattern units are in a competitive configuration , only one pattern unit can generate a @xmath5 event for each clk event , the renormalized @xmath76 is : @xmath78    in the chip experiment , each weight vector @xmath71 was randomly initialized . @xmath67",
    "different input layer patterns @xmath79 were then applied to the input layer .",
    "the events of the pattern units were collected and @xmath80 evaluated from the events / samples for each input pattern .",
    "the resulting @xmath81 data points are plotted in fig .",
    "[ fig : hwnw_c ] as a function of the @xmath80 values predicted by the poisson assumption ( eq .  [ eq : hwideal ] ) .",
    "the discrepancy is largely because the poisson approximation assumes all units generate a poisson train with the same rate , while the frequencies of the physical oscillators are different ( fig .",
    "[ fig : hwnw_a ] ) , thus biasing the competition in favor of pattern units with higher frequencies .",
    "if the fsm in the pattern units were a depth @xmath14 counter ( as in fig .",
    "[ fig : sigmoid_c ] ) , then the competition would be between a number of units whose activation functions closely approximate the logistic sigmoid and @xmath76 would then approximately be the softmax function : @xmath82 .",
    "[ fig : hwnw ]    0.38   event from a pattern unit ( @xmath65 to @xmath66 ) shuts down all pattern units .",
    "a normal binary unit is designated as a clock unit ( clk ) and its events reactivate the pattern units and puts them at state @xmath7 .",
    "( ) the observed relative frequencies of the @xmath5 events from each pattern unit in the chip for each input pattern compared to the predictions of eq .",
    "[ eq : hwideal ] .",
    ", title=\"fig : \" ] [ fig : hwnw_a ]    0.2   event from a pattern unit ( @xmath65 to @xmath66 ) shuts down all pattern units .",
    "a normal binary unit is designated as a clock unit ( clk ) and its events reactivate the pattern units and puts them at state @xmath7 .",
    "( ) the observed relative frequencies of the @xmath5 events from each pattern unit in the chip for each input pattern compared to the predictions of eq .",
    "[ eq : hwideal ] .",
    ", title=\"fig : \" ] [ fig : hwnw_b ]    0.38   event from a pattern unit ( @xmath65 to @xmath66 ) shuts down all pattern units .",
    "a normal binary unit is designated as a clock unit ( clk ) and its events reactivate the pattern units and puts them at state @xmath7 .",
    "( ) the observed relative frequencies of the @xmath5 events from each pattern unit in the chip for each input pattern compared to the predictions of eq .  [ eq : hwideal ] . , title=\"fig : \" ] [ fig : hwnw_c ]",
    "many stochastic algorithms used in machine learning and optimization applications or as models of biological computation are formulated as a distributed stochastic network where each element integrates incoming messages / spikes , applies a stochastic non - linear transformation , then emits a message / spike . we have shown that these stochastic networks can be reformulated in a radically different way as a quasi - periodic event - based system .",
    "the combined effect of several periodic , but incommensurable , event / message streams on a target neuron with limited memory can be formulated in stochastic terms by assuming the event streams are poissonian instead of periodic .",
    "this allows the fsm in a neuron to be treated as a markov chain that is then used to accurately approximate the relative frequencies of the occupancies of the different fsm states in the quasi - periodic system    the scheme we describe for realizing approximations of stochastic units is quite suitable for large distributed systems as noise - generating resources in each unit are not required . by simply changing the communication scheme so that messages / events are communicated in a decentralized quasi - periodic manner , good approximation of stochastic behavior can be obtained ( see the comparison to gibbs sampling in fig .  [",
    "fig : rbm_d ] ) .",
    "one advantage of the proposed scheme is the ease by which different approximations of stochastic activation functions can be `` programmed '' , simply by changing the form of the neuron s fsm ( see fig .",
    "[ fig : sigmoid_f ] ) .",
    "we showed that the fabrication mismatch inherent in a vlsi process gives rise to incommensurable frequencies in identical oscillator circuits and the resulting quasi - periodic physical system can be used in sampling applications . by reformulating quasi - periodic event - based dynamics in stochastic terms ,",
    "our results highlight a new direction for physical implementations of distributed stochastic systems .",
    "pascal vincent , hugo larochelle , isabelle lajoie , yoshua bengio , and pierre - antoine manzagol .",
    "stacked denoising autoencoders : learning useful representations in a deep network with a local denoising criterion .",
    ", 11:33713408 , 2010 .",
    "phi - hung pham , d.  jelaca , c.  farabet , b.  martini , y.  lecun , and e.  culurciello .",
    "neuflow : dataflow vision processing system - on - a - chip . in _ circuits and systems ( mwscas ) , 2012 ieee 55th international midwest symposium on _ , pages 10441047 , aug 2012 .",
    "paul  a. merolla , john  v. arthur , rodrigo alvarez - icaza , andrew  s. cassidy , jun sawada , filipp akopyan , bryan  l. jackson , nabil imam , chen guo , yutaka nakamura , bernard brezzo , ivan vo , steven  k. esser , rathinakumar appuswamy , brian taba , arnon amir , myron  d. flickner , william  p. risk , rajit manohar , and dharmendra  s. modha . a million spiking - neuron integrated circuit with a scalable communication network and interface .",
    ", 345(6197):668673 , august 2014 ."
  ],
  "abstract_text": [
    "<S> many networks used in machine learning and as models of biological neural networks make use of stochastic neurons or neuron - like units . </S>",
    "<S> we show that stochastic artificial neurons can be realized on silicon chips by exploiting the quasi - periodic behavior of mismatched analog oscillators to approximate the neuron s stochastic activation function . </S>",
    "<S> we represent neurons by finite state machines ( fsms ) that communicate using digital events and whose transitions are event - triggered . </S>",
    "<S> the event generation times of each neuron are controlled by an analog oscillator internal to that neuron / fsm and the frequencies of the oscillators in different fsms are incommensurable . </S>",
    "<S> we show that within this quasi - periodic system , the transition graph of a fsm can be interpreted as the transition graph of a markov chain and we show that by using different fsms , we can obtain approximations of different stochastic activation functions . </S>",
    "<S> we investigate the quality of the stochastic interpretation of such a deterministic system and we use the system to realize and sample from a restricted boltzmann machine . </S>",
    "<S> we implemented the quasi - periodic event - based system on a custom silicon chip and we show that the chip behavior can be used to closely approximate a stochastic sampling task . </S>"
  ]
}