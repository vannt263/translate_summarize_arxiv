{
  "article_text": [
    "random heterogeneous multiphase materials or media are ubiquitous .",
    "examples include composites , porous media , biological materials as well as cosmological structures , and their macroscopic properties are of great interest @xcite . in the first part of this series of two papers @xcite ( henceforth referred to as paper i ) , we proposed a theoretical formalism to model and categorize heterogeneous materials via two - point correlation functions @xmath1 , which can be interpreted as the probability of finding two points separated by the the dsiplacement vector @xmath2 in one of the phases @xcite .",
    "in particular , we introduced the idea of the two - point correlation function space and its basis functions .",
    "in general , @xmath0 of a medium can be expressed by a map @xmath3 on the associated basis functions , which is composed of convex - combination and product operations .",
    "we also suggested a set of basis functions by examining certain known realizable analytical two - point correlation functions .",
    "moreover , we introduced an efficient isotropy - preserving @xmath0-sampling algorithm , namely the _ lattice - point _",
    "algorithm , but left the details of the algorithm for another paper .    here",
    "we will provide algorithmic details of the lattice - point methodology and consider several nontrivial applications to illustrate the practical utility of our theoretical formalism .",
    "in particular , we will apply the lattice - point algorithm to generate three - dimensional ( 3d ) digitized realizations of a fontainebleau sandstone and a boron carbide / aluminum composite from two - dimensional ( 2d ) tomographic images of their slices through the materials . to justify whether the reconstructions are successful , one should also measure other statistical descriptors of the media @xcite . here",
    "we compute the two - point cluster function @xmath4 @xcite ( see definition and discussions in sec .",
    "iv ) , which contains nontrivial `` connectedness '' information of the phases of interest . by comparing @xmath4 of the target and reconstructed media ,",
    "we demonstrate that @xmath0 is indeed sufficient to capture the salient structural features in these cases .",
    "we also study the reconstruction of a binary laser - speckle pattern in two dimensions , and find that the algorithm fails to reproduce the target pattern accurately .",
    "we conclude that in general reconstructions using @xmath0 only work well for heterogeneous materials with single - scale structures ( those having only one characteristic length scale ) .",
    "however , two - point information via @xmath0 is not sufficient to accurately model multi - scale media ( those composed of structural elements associated with multiple characteristic length scales ) .",
    "moreover , we will show how the proper convex combinations of basis functions enable one to obtain two - point correlation functions with desired properties and thus enable one to generate a variety of structures with controllable morphological features .",
    "note that here we will mainly focus on modeling heterogeneous materials in three dimensions , which complements the two - dimensional examples that we considered in paper i.    yeong and torquato formulated the ( re)construction problem as an energy - minimization problem using simulated annealing @xcite .",
    "this has become a very popular ( re)construction technique @xcite . in this method , a nonnegative objective function @xmath5 , called the  energy , \" is defined as the sum of squared differences between the target and sampled correlation functions . in our case , the energy is given by    @xmath6 ^ 2,\\ ] ]    where @xmath7 and @xmath8 is the target and sampled two - point correlation function , respectively .",
    "an important issue in the ( re)constructions based on the method of simulated annealing is the choice of the _ energy threshold _ @xmath9 , i.e. , the error tolerance of discrepancies between the correlation functions of generated medium and the imposed ones . when the energy of the ( re)constructed medium is below @xmath9 , the ( re)construction process is terminated .",
    "the energy threshold is a key indicator of how accurately the medium is ( re)constructed . in our previous work , @xmath9 was always chosen to be a very small number , e.g. , @xmath10 ; however , no quantitative analysis on why such a value should be chosen was given . in this paper",
    ", we will discuss in detail the significance of the energy threshold for both the orthogonal @xmath0-sampling algorithm ( only sampling @xmath0 along convenient orthogonal directions ) @xcite and the lattice - point algorithm .    in the lattice - point procedure , we consider the digitized medium ( pixel system ) to be a  lattice - gas \" system , in which the black pixels behave like nonoverlapping `` particles '' moving from one lattice site to another .",
    "the two - point correlation function of the medium is obtained by binning all the distances between the black pixels and dividing the number in each bin by the total number of distances between all lattice sites within that bin . to generate a trial configuration , a randomly selected `` particle '' ( black pixel )",
    "is given a random displacement subjected to the nonoverlapping constraint .",
    "only the distances between the moved `` particle '' and all the others need to be recomputed in order to obtain @xmath0 of the trial configuration . in this way",
    ", all directions in the digitized medium are effectively sampled ; moreover , the complexity of the algorithm is linear in @xmath11 , i.e. , the number of nonoverlapping particles .    for heterogeneous materials containing well - defined inclusions",
    ", we will show that the computational speed of the ( re)construction process can be increased by an algorithm modification using surface optimization , which is essentially a biased pixel - selection procedure .",
    "this algorithm modification is based on the fact that in the later stages of ( re)constructions , further refinements of the configurations are achieved by the moves of black pixels on the surfaces of formed pixel - clusters .",
    "thus , only the `` surface pixels '' are selected and given random moves to generate trial configurations , i.e. , the surfaces are optimized .",
    "the physical analog of this process is solidification , in the later stage of which the re - arrangements of solutes only occur on the surfaces of nucleated particles .",
    "we will see in the following that one can obtain a much lower error ( discrepancies between the correlation functions of the ( re)constructed medium and the imposed ones ) when surface optimization is properly applied .",
    "this improvement enables one to quantitatively study the non - uniqueness problem of the ( re)constructions @xcite .",
    "the rest of the paper is organized as follows : in sec .",
    "ii , we describe the lattice - point algorithm and the algorithm modification using surface optimization in great detail . the choice of different pixel - lattices is also discussed . in sec .",
    "iii , we discuss the significance of the energy threshold for both the orthogonal @xmath0-sampling method and the lattice - point algorithm . in sec .",
    "iv , we suggest a general form of the map @xmath3 and apply the theoretical formalism to model a fontainebleau sandstone , a boron carbide / aluminum composite and a binary laser - speckle pattern .",
    "we also show how to construct materials with structural properties of interest by manipulating the parameters in the basis functions and choosing proper combination coefficients . in sec .",
    "v , we make concluding remarks .",
    "in paper i , we derived the exact algebraic equations for the ( re)construction problem and showed that the equations have an infinite number of solutions and can not be solved rigorously . in principle",
    ", the yeong - torquato scheme enables one to obtain one of the solutions efficiently .",
    "the most time - consuming steps of the scheme are the samplings of the two - point correlation function at every trial configuration .",
    "an efficient @xmath0-sampling method would dramatically speed up the ( re)construction process .",
    "furthermore , an isotropy - preserving algorithm is required in ( re)constructions whenever a radial two - point correlation function @xmath8 ( @xmath12 ) is employed for the case of statistically homogeneous and isotropic media .",
    "the lattice - point algorithm is designed to sample the digitized representation of a statistically homogeneous and isotropic medium in all possible directions efficiently . for simplicity",
    ", we will illustrate the idea in 2d .",
    "implementation of the algorithm in three dimensions is a straightforward extension . instead of considering the digitized medium as a collection of black and white pixels",
    ", one can think of the medium as a lattice - gas system : the black pixels are the `` gas molecules '' and the white pixels are unoccupied lattice sites , as shown in fig .",
    "the `` gas molecules '' are free to move from one lattice site to another , subject to the impenetrability condition , i.e. , each lattice site can only be occupied by one `` gas molecule '' .",
    "thus , the black pixels behave like hard particles and the volume fraction of black phase is conserved during the evolution of the system",
    ".    @xmath13{fig1a.eps } & \\includegraphics[height=5cm , keepaspectratio]{fig1b.eps } \\\\ \\mbox{\\bf ( a ) } & \\mbox{\\bf ( b ) } \\end{array}$ ]    for a statistically homogeneous and isotropic particle system ( e.g. , an equilibrium hard - sphere system or an equilibrium lattice - gas system in @xmath14-dimensional euclidean space @xmath15 ) , the most basic statistical descriptor of the spatial correlations of the particles is the pair correlation function @xmath16 @xcite .",
    "the quantity @xmath17 is proportional to the conditional probability of finding the center of a particle in a @xmath14-dimensional spherical shell of volume @xmath18 , given that there is another particle at the origin . here",
    "@xmath19 is the number density of the system and @xmath20 is the surface area of a @xmath14-dimensional sphere of radius @xmath21 , which is given by    @xmath22    where @xmath23 is the euler - gamma function .",
    "hence , for a finite system , integrating @xmath24 over the volume yields @xmath25 , i.e. , all the particles except the one at the origin .",
    "alternatively , @xmath17 is the average number of particles at a radial distance between @xmath21 and @xmath26 from a reference particle .",
    "practically , @xmath16 can be obtained from simulations by generating a histogram for the number of particles @xmath27 contained in a concentric shell of finite thickness ( `` bin '' width ) @xmath28 at radial distance @xmath21 from a arbitrarily chosen reference particle .",
    "the two - point correlation function @xmath8 of a statistically homogeneous and isotropic medium can be interpreted as the probability that both of ends of a randomly oriented line segment with length @xmath21 fall into the phase of interest , say , the `` black '' phase . by comparison",
    ", we can see that the method of computing @xmath16 of an isotropic particle system implies a natural way of obtaining @xmath8 of a statistically isotropic digitized medium , which efficiently uses all possible vector - information in the medium . for each black pixel ( or `` gas molecule '' ) @xmath29 , the distances between pixel @xmath29 and all the other pixels @xmath30 are computed and binned to generate a histogram for the number of black pixels separated from each other by distance @xmath21 .",
    "another histogram for the number of lattice sites separated from a reference site by distance @xmath21 is also generated by computing and binning all possible site - separation distances .",
    "suppose the histograms for black pixels and lattice sites are stored in the array @xmath31 $ ] and @xmath32 $ ] , respectively .",
    "it is easy to show that the two - point correlation function can be obtained from    @xmath33 = bn[r]/sn[r],\\ ] ]    ( see fig .",
    "[ fig2 ] ) . in other words , to compute @xmath0 we first calculate the fraction of occupied lattice sites separated by distance @xmath21 ( @xmath34 is an integer ) from a reference black pixel .",
    "then we average this fraction over all black pixels ( by choosing every black pixel as reference pixel once ) to obtain @xmath8 .",
    "this procedure is consistent with the geometrical probability interpretation of @xmath0 . for the digitized media",
    ", a natural bin width could be the characteristic size of the pixel of the lattice , e.g. , the edge length of a square pixel if square lattice is used .    @xmath13{fig2a.eps } & \\includegraphics[height=5cm , keepaspectratio]{fig2b.eps } \\\\ \\mbox{\\bf ( a ) } & \\mbox{\\bf ( b ) } \\end{array}$ ]    at each step in the simulated annealing process , a trial configuration is generated by moving a randomly selected black pixel to an unoccupied lattice site .",
    "configuration array _ can be used to speed up this process . in our 2d implementation ,",
    "the configuration array is a 2d array with the entries being 1 and 0 , corresponding to the occupied and unoccupied lattice sites , respectively .",
    "when a trial move is made , first we need to test whether it violates the impenetrability condition by checking whether the underlying lattice site is occupied or not .",
    "this process just requires constant access time to an entry of the configuration array .",
    "note that several trial moves can be attempted before a trial configuration is found for a high - density system . after a trial configuration",
    "is generated , the old position information of the selected pixel is stored in the array designated @xmath35 .    the next step is to recompute the two - point correlation function for the trial configuration . to do this efficiently , a _ distance matrix _ is set up when the system is initialized and updated if a trial configuration is accepted .",
    "note that this matrix is symmetric .",
    "for each trial configuration , only the position of a randomly selected black pixel is changed , e.g. , the @xmath36 pixel .",
    "thus , only the @xmath36 row and column of the distance matrix need to be updated , which requires @xmath11 operations ( @xmath11 is the total number of black pixels in the system ) .",
    "the old entries in the @xmath36 row ( or column ) of the distance matrix are stored in the array @xmath37 .",
    "it is also unnecessary to recompute the entire array @xmath31 $ ] . recall that @xmath31 $ ] contains the binned number of black pixels separated from each other by distances between @xmath21 and @xmath38 ( @xmath28 is the bin width )",
    "once the @xmath36 pixel is selected , the distances between pixel @xmath39 and all the other pixels are binned and stored in the array @xmath40 $ ] . after the trial configuration",
    "is generated , the new distances between pixel @xmath39 and all the other pixels are binned and stored in the array @xmath41 $ ] .",
    "the array @xmath31 $ ] is updated as follows for each @xmath21 :    @xmath42 - bno[r ] + bnn[r ] \\rightarrow bn[r].\\ ] ]    @xmath43 $ ] is then recomputed using eq .",
    "( [ eq2 ] ) and the trial configuration is accepted with the probability given by eq .",
    "( 57 ) in paper i. if the trial configuration is rejected , all information of the old configuration can be restored easily using the arrays @xmath35 , @xmath37 , @xmath40 $ ] and @xmath41 $ ] . for example , @xmath31 $ ] of the old configuration can be restored by    @xmath44 - bnn[r ] + bno[r ] \\rightarrow bn[r].\\ ] ]    the above procedures are repeated until the energy of the ( re)constructed medium is below the energy threshold [ see eq .",
    "( [ eq201 ] ) in sec .",
    "iii ] or the total number of evolutions reaches the prescribed limit value .      in the ( re)construction of media composed of well - defined `` particles '' or large clusters , we find out that in the later stages of simulated annealing , the random pixel - selection process is very inefficient .",
    "many trial moves are rejected because a majority of selected pixels are inside the formed `` particles '' or clusters and it is energetically unfavorable to move them outside .",
    "this requires the use of a biased pixel - selection process , i.e. , surface optimization .",
    "the idea of surface optimization is analogous to the physical process of solidification : when the nuclei of proper sizes have been formed , they capture more solutes from surrounding solution to further decrease the total free energy . in the simulated annealing process ,",
    "once the `` nuclei '' are formed , the random pixel - selection process is replaced by a biased pixel - selection process , i.e. , only those in the surrounding `` solution '' or on the surface of a `` nucleus '' are selected to be moved to or along the surface of randomly selected `` nuclei '' .",
    "it is natural and easy to incorporate the surface optimization with the lattice - point algorithm because the black pixels are already considered as `` molecules '' .",
    "each black pixel is assigned a `` free energy '' , which is the minus of the number of the nearest neighbors of that pixel . if a pixel is inside a `` nuclei '' , it has the largest number of nearest neighbors and the lowest `` free energy '' , which equals @xmath45 if a square lattice is used and @xmath46 if a triangular lattice is used .",
    "if the pixel is on the surface of a `` nucleus '' or in the surrounding `` solution '' , its `` free energy '' will be relatively higher .",
    "the highest free energy is @xmath47 , which means the pixel is separated from all the others .",
    "thus , the black pixels are grouped into two subsets : the _ low - energy _",
    "subset that contains pixels with lowest `` free energy '' and the _ high - energy _",
    "subset that contains the other pixels .",
    "when the trial move is made , only the pixels in the high - energy subset are selected to bias the move . if the trial move is accepted , the free energy of the moved pixel and its neighbor pixels are recomputed ; the subsets are updated .",
    "@xmath48{fig3.eps } \\end{array}$ ]    numerical experiments show that applying surface optimization properly will further decrease the final energy of the ( re)constructed medium by a factor of @xmath49 ( see fig .",
    "[ fig3 ] ) , if the same cooling schedule is used .",
    "thus , surface optimization enables one to efficiently produce more accurate structures associated with the imposed correlation functions .",
    "moreover , by setting a lower energy threshold , one can address the non - uniqueness issue quantitatively .",
    "progress on this topic will be reported in our future publications .      a 2d digitized heterogeneous material ( medium )",
    "can be represented as a 2d array and the real morphology of the material also depends on the lattice on which the system of pixels is built @xcite . here , we mainly focus on two commonly used lattices in the literatures , namely , the square lattice and the triangular lattice ( see fig .  [ fig4 ] ) .",
    "@xmath13{fig4a.eps } & \\includegraphics[height=5cm , keepaspectratio]{fig4b.eps } \\\\ \\mbox{\\bf ( a ) } & \\mbox{\\bf ( b ) } \\end{array}$ ]    implementation of the algorithms discussed above on a square lattice is easier than that on a triangular lattice because the former has orthogonal lattice vectors .",
    "however , the pixels of a square lattice ( squares ) only have @xmath50-fold symmetry while those of a triangular lattice ( hexagons ) have @xmath51-fold symmetry , as shown in fig .  [ fig4 ] .",
    "we find that for the media with long - range correlations or large - scale structures , using a square lattice usually introduces undesirable anisotropy in the ( re)constructed systems , as shown in fig .",
    "[ fig5 ] ; while for the media without long - range order or large - scale structures , both lattices work well .",
    "@xmath13{fig5a.eps } & \\includegraphics[height=5cm , keepaspectratio]{fig5b.eps } \\\\ \\mbox{\\bf ( a ) } & \\mbox{\\bf ( b ) } \\end{array}$ ]    it is worth pointing out that the triangular lattice is superior to the square lattice in the ( re)construction of _ anisotropic _ materials . in that case",
    ", one can not count on lattice - point algorithm , which only uses radial averaged structural information .",
    "several optimization directions need to be specified and processed separately .",
    "the triangular lattice has six intrinsic directions due to the higher symmetry of its pixel shape while the square lattice only has four ( see fig .",
    "[ fig4 ] ) .",
    "methods using more optimization directions have been proposed by torquato and coworkers @xcite , i.e. , along the @xmath52- and @xmath53-degree directions in the square lattice ; but one needs to pay the cost of complexity of implementation in these cases .",
    "an important issue that has not been emphasized in our previous work on the ( re)construction algorithms is the choice of the _ energy threshold _ @xmath9 , i.e. , the error tolerance of discrepancies between the statistical properties of the generated structure and the imposed ones . recall that in our case , the _ energy _ is defined as the sum of squared differences between target @xmath7 and @xmath8 of the constructed medium [ see eq .",
    "( [ eq201 ] ) ] and the energy threshold @xmath9 is a prescribed value of @xmath5 such that when @xmath54 , the ( re)construction is terminated . @xmath9",
    "indicates how accurately the medium is ( re)constructed . a smaller @xmath9 means the two - point correlation function of the generated medium matches the imposed one better .    in the following , we will estimate the change of the energy of a digitized medium caused by a perturbation of its original structure ( i.e. , displacing a randomly selected black pixel ) .",
    "this change of energy can be considered as the energy difference between the target and the constructed medium .",
    "thus , by imposing a particular value of the energy difference ( i.e. , @xmath9 ) , we can in turn estimate the number of perturbed black pixels . in this way",
    ", we quantitatively relate the energy threshold to the question of how well the medium is ( re)constructed . in general , the energy difference depends on how @xmath0 is sampled , the linear size of the system @xmath55 and the number of black pixels @xmath11 ( volume fraction of black phase @xmath56 ) , which will be discussed accordingly .",
    "first , we consider the energy threshold of the lattice - point algorithm",
    ". the two - point correlation function of a digitized medium is computed from eq .",
    "( [ eq2 ] ) . if the generated structure perfectly matches the target structure , the energy given by eq .",
    "( [ eq201 ] ) should be exactly 0 .",
    "suppose the perfect ( re)constructed structure is perturbed by moving one of its black pixels to an unoccupied lattice site ; then @xmath8 is different from @xmath7 and @xmath5 becomes a small positive number .",
    "note that we assume the perturbed structure does not have the same @xmath0 as the original structure , i.e. , there is no structural degeneracy .",
    "let @xmath57 denote the smallest positive value of @xmath5 . from eq .",
    "( [ eq201 ] ) , we see that the difference between @xmath0 and @xmath58 of every bin contributes to @xmath5 . from eq .",
    "( [ eq2 ] ) and the fact that the last bin ( farthest away from the reference center ) contains the largest number of pairs of lattice sites , we have    @xmath59\\right ) - \\hat{s}_2\\left(\\left[\\frac{n}{2}\\right]\\right)}\\right ] ^2 = \\frac{4}{\\omega_n^2},\\ ] ]    where @xmath60 $ ] is the integer part of @xmath61 and @xmath62 is the number of elements of the integer set @xmath63 , which is defined by    @xmath64 \\le m , n \\le \\left [ \\frac{n}{2}\\right ] , \\left ( \\left[\\frac{n}{2}\\right]-1\\right)^2 \\le m^2+n^2 \\le \\left(\\left [ \\frac{n}{2}\\right]\\right)^2   \\right\\}.\\ ] ]    in other words , eq .  ( [ eq801 ] ) estimates @xmath57 using the change of @xmath5 from 0 caused by removing ( adding ) one pair of black pixels from ( to ) the last bin ( the pixels bounded in pairs due to the symmetry of the distance matrix ) .",
    "also note that the pair of pixels are originally in ( or moved to ) a `` bin '' for the pair distance larger than @xmath60 $ ] , which we do not take into account for computation of @xmath0 .    for a particular value of @xmath9",
    ", the maximum number of _ misplaced pairs _ of black pixels can be estimated by    @xmath65    the ratio of the number of misplaced pairs of black pixels over the total number of pairs of black pixels is given by    @xmath66    instead of specifying @xmath9 , one can also specify the ratio @xmath67 ; and the threshold can be computed from eq .",
    "( [ eq804 ] ) :    @xmath68    for example , consider a system composed of @xmath69 pixels ( @xmath70 ) and @xmath71 .",
    "the total number of lattice sites is @xmath72 and the total number of black pixels is @xmath73 .",
    "@xmath62 can be obtained numerically , which is @xmath74 . from eq .",
    "( [ eq801 ] ) , we have @xmath75 .",
    "suppose we choose the threshold @xmath76 , from eq .",
    "( [ eq803 ] ) , we have the number of misplaced pairs of black pixels @xmath77 , which seems to be a large number . however , when considering the total number of pairs in the system , we have @xmath78 ; from eq .",
    "( [ eq804 ] ) , the ratio is given by    @xmath79    which means only one out of a half million pairs is put in the wrong bin .",
    "thus , the medium is ( re)constructed to a very high accuracy . in our simulations ,",
    "we choose the threshold @xmath76 .      for the orthogonal @xmath0-sampling algorithm ,",
    "@xmath8 is sampled line ( column ) by line ( column ) by moving a line ( column ) segment of length @xmath21 one pixel distance each time and counting the times that both ends of the segment are black pixels .",
    "this number is then divided by the total number of times that one moves the line ( column ) segment ( total number of pixels on the line ( column ) ) to obtain @xmath0 of that line ( column ) .",
    "finally , the @xmath0 sampled from different lines and columns of the digitized medium are averaged to compute the @xmath0 of the whole medium .",
    "similarly , consider the perfect ( re)constructed structure is perturbed by moving one of its black pixels to an unoccupied lattice site and there is no structural degeneracy , @xmath57 is given by    @xmath80    where @xmath55 is the linear size of the system .",
    "for a particular @xmath9 , the maximum number of _ misplaced black pixels _ is given by    @xmath81    thus , the ratio of misplaced black pixels over the total number of black pixels can be obtained by    @xmath82    if stead , @xmath67 is specified , the required energy threshold @xmath9 can be obtained from eq .",
    "( [ eq903 ] ) :    @xmath83    consider the same system used in the previous section ( @xmath70 , @xmath71 ) . if we require only 10 black pixels are misplaced , thus , the ratio @xmath84 . from eq .",
    "( [ eq904 ] ) , we have    @xmath85    in other words , if we choose the threshold @xmath76 , only 10 black pixels in the system are misplaced . the medium is ( re)constructed to a high accuracy .",
    "it is worth noting that in the above discussions , we assume that the perturbed structure does not have the same @xmath0 of the original structure , i.e. , there is no structural degeneracy . in general , however , structural degeneracy does exist ( i.e. , media with the same @xmath0 but different @xmath86 , @xmath87 , ... ) .",
    "results concerning these non - uniqueness issues will be reported in our future publications .",
    "in this section , we illustrate the practical utility of our theoretical formalism in both two and three dimensions . in particular , we will consider two kinds of applications .",
    "firstly , given a set of basis functions ( may not be complete ) , one can express the scaled autocovariance functions ( two - point correlation functions ) of a statistically homogeneous and isotropic medium in terms of the specified basis functions with certain accuracy .",
    "realizations of the materials can be generated using proper ( re)construction procedures and subsequent analysis can be performed on the images to obtain effective macroscopic properties of interest ; see , e.g. , ref .",
    "secondly , the map @xmath3 ( see the discussion below ) enables one to construct candidates of realizable two - point correlation functions with properties of interest , which in turn enables one to design and investigate materials with desired structural characteristics .",
    "the ( re)construction of realizations of 3d medium from the information obtained from a 2d micrograph or image is of great value in practice @xcite .",
    "therefore , we will apply the lattice - point algorithm to generate three - dimensional digitized realizations of a fontainebleau sandstone and a boron carbide / aluminum composite from two - dimensional tomographic images of their slices through the materials . in a successful reconstruction ,",
    "other deemed crucial structural characteristics besides @xmath0 obtained from the reconstructed medium should also agree closely with that of the target medium .",
    "consequently , in order to judge quantitatively how well the reconstructions are , we will measure and compare another important morphological descriptor , i.e. , the two - point cluster function @xmath88 , defined to be the probability of finding two points at @xmath89 and @xmath90 in the same cluster of the phase of interest @xcite .",
    "for statistically homogeneous and isotropic media , @xmath4 only depends on the relative scaler distances between the points , i.e. , @xmath91 .",
    "note that @xmath4 contains nontrivial topological `` connectedness '' information .",
    "when large clusters are present in the medium , @xmath4 becomes a long - ranged function and its integral will diverge if the phase of interest percolates .",
    "the measurement of @xmath4 for a 3d material sample can not be made from a 2d cross - section of the material , since it is an intrinsically 3d microstructural function @xcite .",
    "to sample @xmath4 from a digitized medium , we associate each pixel with a cluster - index that indicates to which cluster the pixel belongs , and only bin the distances of pixel - pairs in the same cluster",
    ". then the number of pair distances in each bin is normalized by the total number of distances between the lattice sites within that bin , which is similar to the procedure of sampling @xmath0 discussed in sec .",
    "we will also study the reconstruction of a binary laser - speckle pattern in two dimensions and show that the algorithm can not reproduce the pattern accurately .",
    "moreover , we introduce and discuss a classification of heterogeneous materials into _ multi - scale media _ and _ single - scale media_. a multi - scale medium ( msm ) is the one in which there are multiple characteristic length scales associated with different structural elements .",
    "examples of msm include fractal patterns and hierarchical laminate composites @xcite .",
    "a single - scale medium ( ssm ) is the one composed of structural elements associated with only one characteristic length scale , such as a fontainebleau sandstone and a boron carbide / aluminum composite .",
    "we conclude that in general reconstructions using @xmath0 only work well for heterogeneous materials with single - scale structures .",
    "however , two - point information via @xmath0 is not sufficient to capture the key structural features of multi - scale media . before presenting the aforementioned applications",
    ", we will first consider a general form of @xmath3 , which includes all possible convex combinations of the basis functions .      in paper",
    "i , we introduced the idea of expressing the two - point correlation function of a statistically homogeneous and isotropic medium through a selected set of bases of the two - point correlation function space . in practice , it is convenient to use the scaled autocovariance functions that are equivalent to the two - point correlation functions , which are defined as follows :    @xmath92    suppose @xmath93 is a set of bases of scaled autocovariance functions and @xmath3 is an map on @xmath93 composed of convex combinations and products of @xmath94 ( @xmath95 ) , thus    @xmath96 = \\wp[f_1(r),f_2(r), ... ,f_m(r)],\\ ] ]    is also a realizable scaled autocovariance function .",
    "note that the choice of basis functions is not unique .    in general",
    ", one can consider that @xmath97 $ ] takes the form    @xmath98 = \\sum\\limits_i \\alpha_i f_i(r ) + \\sum\\limits_{i , j } \\beta_{ij } f_i(r)f_j(r ) + \\cdots,\\ ] ]    where the coefficients satisfy the condition    @xmath99    then one can use standard regression methods to obtain the set of coefficients such that @xmath100 $ ] is the best approximation of the target function pointwisely .",
    "the basis functions we consider here include debye random medium function @xmath101 , the family of polynomial functions @xmath102 , damped oscillating function @xmath103 , overlapping - sphere function @xmath104 and symmetric - cell material function @xmath105 , which are discussed in paper i.        @xmath106{fig6a.eps}\\\\ \\mbox{\\bf ( a ) } \\\\\\\\\\\\",
    "\\includegraphics[height=5.5cm , keepaspectratio]{fig6b.eps}\\\\ \\mbox{\\bf ( b ) } \\end{array}$ ]    first , we investigate structural properties of a fontainebleau sandstone from a two - dimensional tomographic image of a slice through the material sample .",
    "sandstone is an important porous medium in geo - physical and petroleum applications and has been the focus of many studies @xcite . a microstructural image of a slice of a fontainebleau sandstone is shown in fig .",
    "[ fig6](a ) , in which the black areas are solid phases ( phase 1 ) and the white areas are void phases ( phase 2 ) .",
    "the two - point correlation function of the _ void _ phase @xmath107 is shown in fig .  [",
    "fig6](b ) .",
    "@xmath108{fig7a.eps } & \\includegraphics[height=5cm , keepaspectratio]{fig7b.eps } \\\\ \\mbox{\\bf ( a ) } & \\mbox{\\bf ( b ) } \\end{array}$ ]    the scaled autocovariance function of the void phase in fontainebleau sandstone @xmath109 can be approximated by the convex combination of @xmath101 and @xmath103 as follows :    @xmath110    where @xmath111 , @xmath112 are the combination coefficients and    @xmath113    @xmath114    where @xmath115 , @xmath116 are the effective correlation length ; @xmath117 is the oscillating frequency and @xmath118 is the phase angle .",
    "the two - point correlation function @xmath107 is approximated by    @xmath119    where @xmath120 , @xmath121 are volume fractions of the solid and void phase , respectively ; @xmath122 is the discrepancy between the sampled two - point correlation function and the basis - function approximation .",
    "the average of the absolute values of discrepancies @xmath123 , which indicates how well the sampled two - point correlation function is approximated by the convex combination , is defined as :    @xmath124    where @xmath125 is the sample - length .",
    "note that although the general form of @xmath3 given by eq .",
    "( [ eq7 ] ) would work well if a complete set of basis functions is given , in the present case ,",
    "our practical approach is enough .",
    "@xmath126{fig8.eps}\\\\ \\end{array}$ ]    the 3d reconstruction of the fontainebleau sandstone from @xmath107 obtained from the digitized image of a 2d slice [ fig .",
    "[ fig6](a ) ] is shown in fig .",
    "visually , the reconstruction provides a good rendition of the true sandstone microstructure , as can be seen by comparing the 2d images .",
    "as pointed out earlier , to ascertain whether the reconstruction is quantitatively successful , we also measure @xmath4 of the target and generated media .",
    "since it is an intrinsically 3d microstructural function , we only compute and compare the two - point cluster functions of the 2d slices .",
    "the measured @xmath127 for the void phase of the target and the reconstructed slices of the fontainebleau sandstone are shown in fig .",
    "[ fig71 ] .",
    "the figure reveals that although @xmath127 of the generated medium is slightly below that of the target medium , the discrepancies are acceptable ( e.g. , the largest discrepancy @xmath128 ) .",
    "thus , we consider the reconstruction is successful .",
    "also note that the close agreement of the two - point cluster function indicates that @xmath127 is largely determined by @xmath129 of the medium and suggests that @xmath127 might be expressed as a functional of @xmath129 .",
    "@xmath106{fig9a.eps}\\\\ \\mbox{\\bf ( a ) } \\\\\\\\\\\\",
    "\\includegraphics[height=5.5cm , keepaspectratio]{fig9b.eps}\\\\ \\mbox{\\bf ( b ) } \\end{array}$ ]    @xmath108{fig10a.eps } & \\includegraphics[height=5cm , keepaspectratio]{fig10b.eps } \\\\ \\mbox{\\bf ( a ) } & \\mbox{\\bf ( b ) } \\end{array}$ ]    @xmath126{fig11.eps}\\\\ \\end{array}$ ]    a 2d digitized image of a boron carbide / aluminum ( @xmath130/@xmath131 ) inter - penetrating composite and the sampled two - point correlation function of the _ aluminum _ phase ( white phase ) @xmath132 @xcite are shown in fig .  [ fig8 ] .",
    "as we can see from fig .",
    "[ fig8](b ) , @xmath132 is essentially an exponentially decreasing function without any significant short - range correlation .",
    "thus , @xmath132 can be approximated by    @xmath133    where @xmath134 , @xmath135 are combination coefficients ; @xmath136 and @xmath137 are volume fractions of the boron carbide ( black ) phase and the aluminum ( white ) phase , respectively . @xmath101 and @xmath103",
    "are given by eq .",
    "( [ eq101 ] ) and eq .",
    "( [ eq102 ] ) , respectively ; the parameters used are @xmath115 , @xmath138 and @xmath139 , @xmath118 .",
    "the average of the absolute values of discrepancies @xmath140 is given by    @xmath141    where @xmath125 is the sample - length .",
    "the 3d reconstruction of the boron carbide / aluminum composite from @xmath132 obtained from the digitized image of a 2d slice [ fig .  [ fig8](a ) ] is shown in fig .",
    "[ fig9 ] . as in the previous section ,",
    "to verify that the reconstruction is quantitatively successful , we compute and compare the two - point cluster function @xmath142 for the aluminum phase of the target and reconstructed 2d slices of the composite . as shown in fig .",
    "[ fig91 ] , the reconstruction also slightly underestimates @xmath142 with acceptable discrepancies ( e.g. , the largest discrepancy @xmath143 ) .",
    "the medium can be considered as successfully reconstructed .",
    "also note that @xmath142 is long - ranged , indicating large clusters of the aluminum phase present in the media .",
    "although in the above two examples our theoretical formalism works well , there are situations where the microstructural information contained in @xmath8 alone is not sufficient to accurately reconstruct a heterogeneous material .",
    "one such example is the multi - scale structure of a binary laser - speckle pattern ( fig .",
    "[ fig10 ] ) .",
    "the figure reveals that there are three structural elements : `` particles '' , `` stripes '' and a background `` noise '' ( individual black pixels dispersed throughout the white phase ) .",
    "thus , there are three characteristic length scales in the medium associated with these structural elements .",
    "@xmath106{fig12a.eps}\\\\ \\mbox{\\bf ( a ) } \\\\\\\\\\\\",
    "\\includegraphics[height=5.5cm , keepaspectratio]{fig12b.eps}\\\\ \\mbox{\\bf ( b ) } \\end{array}$ ]    the reconstruction of the speckle pattern is shown in fig .",
    "[ fig11 ] . comparing fig .",
    "[ fig11 ] with fig .",
    "[ fig10 ] , we can see that instead of reproducing all the structural elements in the target medium , the ( re)construction program seems to mix them up to generate a single - scale structure that has the same ( or to a very high accuracy ) two - point correlation function as the target medium .",
    "we note that this is a numerical example of structural degeneracy of @xmath8 .",
    "@xmath106{fig13.eps}\\\\ \\end{array}$ ]    the laser - speckle pattern we considered is also an example of the _ multi - scale media _ (",
    "the separation of length scales in msm results in the inefficiency of the bulk - based structure characteristics ( e.g. , @xmath144-point correlation functions ) , since usually they can only pick up structural information associated with the largest length scale . for example , consider the dislocations in a crystalline solid as the phase of interest ; it is clear that the two - point correlation function of the `` dislocation '' phase is identically zero since the `` dislocation '' phase has no measure compared with the bulk `` crystal '' phase ( i.e. , the volume of dislocations is zero compared with that of the bulk crystal ) . in this extreme example , the ratio @xmath145 of the two characteristic length scales associated with the `` dislocation '' phase @xmath146 and the `` crystal '' phase @xmath147 is zero , i.e. , @xmath148 . in digitized media ,",
    "the ratio of length scales is always positive due to the discrete nature of the system ; however when the ratio is significantly different from unity , the two - point correlation function alone is not able to capture the key structural features . on the other hand , extensive experience with successful reconstructions of single - scale media ( ssm ) from @xmath0",
    "shows that the two - point correlation functions are indeed sufficient to determine the structures of ssm to a high accuracy .",
    "thus , we conclude that in general reconstructions using @xmath0 work well for heterogeneous materials with single - scale structures , while the microstructural information contained in @xmath0 is not sufficient to accurately model multi - scale media .",
    "note that more morphological information ( e.g. , the lineal - path function @xcite and the two - point cluster function , etc . ) can be used to model msm more accurately . however , even the cluster - type functions containing connectedness information of the media such as @xmath4 can not completely characterize msm statistically .      from eq .",
    "( [ eq4 ] ) , one can construct candidates of realizable two - point correlation functions using the basis functions .",
    "given a set of basis functions with diverse and interesting properties , one would be able to construct a two - point correlation function that exhibits all the useful properties of the basis functions to some extend and generate an `` optimal '' structure that realizes all the desired structural features .",
    "thus , the theoretical formalism enables one to design materials with _ structural _ properties of interest .",
    "given an accurate structure - property relation , one could even design materials with _",
    "physical _ properties of interest by manipulating their two - point correlation functions .",
    "for example , adams , gao and kalidindi recently developed a methodology to obtain finite approximations of the second - order properties closure in single phase polycrystalline materials , from which the second - order microstructure design can proceed @xcite .",
    "as pointed out in paper i , we know very little about the basis function set @xmath93 at this stage .",
    "our choice of @xmath93 is based on the criteria that @xmath94 s should have simple analytical forms and they present typical features of certain known two - point correlation functions .",
    "important features exhibited by most realizable two - point correlation functions are monotonically deceasing or damped oscillating , which corresponds to materials without or with significant short - range order , respectively .",
    "another feature of two - point correlation functions that may affect the structures of the corresponding materials is the smoothness of the function , which is not emphasized in our previous work . in the following",
    ", we will see through several examples that the properties of basis functions can be observed in the generated structures ; also the media with desired structural properties can be obtained by manipulating the combination coefficients and the parameters ( e.g. , effective correlation length ) in the basis functions .    in the paper",
    "i , we already investigated hypothetical correlation functions combining the exponentially decreasing and damped - oscillating features . in this section",
    ", we provide an example of non - smooth correlation functions ( with discontinuous derivatives ) , i.e. , the polynomial function of order two @xmath149 , which is defined as    @xmath150    where the parameter @xmath151 is the effective correlation length .",
    "other correlation functions having this non - smooth feature include the functions of known constructions ( e.g. , @xmath104 , @xmath105 , etc . ) and other polynomial functions @xcite . a typical medium associated with this type of functions is composed of dispersions of fully penetrable `` particles '' .",
    "the monotonically decaying part of the functions determines the size and shape of the `` particles '' and the penetrability is consistent with the flat `` tail '' of the functions , which implies no spatial correlation between the `` particles '' .",
    "when these functions are use as dominant basis functions , one can expect the generated media also contain well - defined overlapping `` particles '' ; thus , surface optimization could be applied in the ( re)constructions .",
    "however , when functions like debye random medium function are dominant in the convex combination , this algorithm modification should be used with care because the media could contain `` clusters '' of all sizes and shapes , which would significantly reduce the efficiency of the modified algorithm using surface optimization .",
    "besides @xmath152 , we also use debye random medium function @xmath101 and damped - oscillating function @xmath103 as the basis functions . consider the simplest form of @xmath3 for these three basis functions , i.e.",
    ",    @xmath153    where @xmath154 ( @xmath155 ) satisfies @xmath156 and @xmath157 ; and @xmath101 , @xmath103 and @xmath152 are given by eq .",
    "( [ eq101 ] ) , eq .",
    "( [ eq102 ] ) and eq .",
    "( [ eq14 ] ) , respectively .",
    "the characteristic length scales of the generated structures are determined by the parameters in the basis functions ; and the ratios of the characteristic lengths are chosen to be close to unity , i.e. , the hypothetical media belong to ssm .",
    "@xmath126{fig14.eps}\\\\ \\end{array}$ ]    @xmath108{fig15a.eps } & \\includegraphics[height=5cm , keepaspectratio]{fig15b.eps } \\\\ \\mbox{\\bf ( a ) } & \\mbox{\\bf ( b ) } \\end{array}$ ]    suppose we choose the combination coefficients @xmath158 ; and choose the following values for the parameters in the basis functions : @xmath159 ; @xmath160 , @xmath161 , @xmath118 ; @xmath162 .",
    "the combined autocovariance function @xmath163 is shown in fig .",
    "[ fig12 ] and the constructed structure with volume fraction of black phase @xmath71 is shown in fig .",
    "[ fig120 ] . from the figures",
    ", we can see the effects of each basis function on the generated structure .",
    "the short - range correlations in the structure are determined by @xmath152 , which allows spatially uncorrelated `` particles '' with diameter @xmath151 to form .",
    "these `` particles '' would form clusters of different sizes as the volume fraction of the black phase increases .",
    "the middle - range correlations in the structure are dominated by the oscillation part in @xmath163 , which is the contribution of @xmath103 . as we have shown in paper i ,",
    "the parameter @xmath164 is manifested as a characteristic repulsion among different structure elements ( appearing in different forms at different volume fraction ) with diameter of order @xmath164 ; while @xmath165 controls the overall exponential damping , and thus , the effective range of the repulsion .",
    "the large - scale correlation is dominated by the long `` tail '' of @xmath101 , which allows clusters of all shapes and sizes to form . in fig .",
    "[ fig120 ] , we can clearly identify the structure elements associated with each basis function .",
    "for example , the stripe - like structures are associated with the oscillating feature of @xmath163 , the width of which is approximately @xmath164 .",
    "several `` particles '' with diameter @xmath166 can be found dispersed in the white phase , which correspond to the contribution of @xmath152 .",
    "note that most `` particles '' form clusters together with the `` stripes '' at this relatively high volume fraction @xmath71 .",
    "finally , the spatial distribution of large - scale clusters is determined by the `` tail '' of @xmath101 .",
    "@xmath126{fig16.eps}\\\\ \\end{array}$ ]    @xmath108{fig17a.eps } & \\includegraphics[height=5cm , keepaspectratio]{fig17b.eps } \\\\ \\mbox{\\bf ( a ) } & \\mbox{\\bf ( b ) } \\end{array}$ ]    suppose now we would like to generate a similar structure as the one in fig .",
    "[ fig120 ] but with larger `` particles '' and clusters .",
    "to `` grow '' the `` particles '' , we need to increase the parameter @xmath151 in @xmath152 , which controls the effective diameter of the `` particles '' .",
    "to form larger clusters , we need to reduce the `` repulsion '' between the structural elements ; or equivalently , to suppress the oscillation introduced by @xmath103 .",
    "this can be done by either increasing the parameter @xmath165 in @xmath103 or decreasing the coefficient @xmath167 .",
    "we first adopt the former method .",
    "thus , to construct a new structure with the required properties , we use the following parameters : @xmath159 ; @xmath168 , @xmath169 , @xmath118 ; @xmath170 ; and use the same @xmath154 @xmath171 as the last example . the combined autocovariance function @xmath163 is shown in fig .",
    "[ fig13 ] and the constructed structure with volume fraction of black phase @xmath71 is shown in fig .",
    "[ fig130 ] . from the figures",
    ", we can see the generated medium indeed contains larger `` particles '' and clusters ; besides , there are still stripe - like structures associated with the repulsion part of @xmath163 .",
    "@xmath126{fig18.eps}\\\\ \\end{array}$ ]    @xmath108{fig19a.eps } & \\includegraphics[height=5cm , keepaspectratio]{fig19b.eps } \\\\ \\mbox{\\bf ( a ) } & \\mbox{\\bf ( b ) } \\end{array}$ ]    now we would like to further increase the size of clusters in the constructed medium while keeping all the parameters in the basis functions unchanged .",
    "this time we need to adjust the combination coefficients to obtain the required structure . to generate larger clusters , the repulsion effect need to be further suppressed",
    "; thus , we need to reduce @xmath167 . since the sum of the coefficients must equal 1 , we also need to increase the other two @xmath154 ( @xmath172 ) .",
    "note that further increasing @xmath173 makes @xmath152 dominant in the combination ; however , as we discussed before , @xmath152 corresponds to spatial uncorrelated `` particles '' and the size of clusters formed by these `` particles '' is determined by the volume fraction the `` particle '' phase , which can not be changed here .",
    "so we choose to increase @xmath174 of @xmath101 based on the fact that the large correlation length and long `` tail '' of @xmath101 significantly stimulate the forming of large clusters .",
    "thus , in the construction we use the following combination coefficients : @xmath175 ; and use the same parameters in the basis functions as the last example .",
    "the combined autocovariance function @xmath163 is shown in fig .",
    "[ fig14 ] and the constructed structure with volume fraction of black phase @xmath71 is shown in fig .",
    "[ fig140 ] .    from the above examples , we see that even a simple convex combination of the basis functions ( the simplest form of map @xmath3 ) can provide variety of candidates of realizable two - point correlation functions .",
    "we can also obtain desired structures by manipulating the combination coefficients and the parameters in the basis functions .",
    "thus , we argue that in general given a complete set of basis functions , eq .",
    "( [ eq7 ] ) enables one to construct candidates of realizable functions with desired properties and to design materials with structural properties of interest .",
    "in this paper , we described in great detail the lattice - point algorithm , which has been shown to be both efficient and isotropy - preserving for ( re)constructing statistically homogeneous and isotropic media .",
    "the digitized medium ( pixel system ) can be considered as a lattice - gas system , in which the black pixels behave like nonoverlapping `` particles '' moving from one lattice site to another .",
    "the two - point correlation function of the medium is sampled by binning all distances between black pixels and dividing the number in each bin by the total number of distances between all lattice sites in that bin . the energy threshold indicating to what accuracy the medium is ( re)constructed has been discussed in detail for the first time . this quantity is directly related to the issue of non - uniqueness of ( re)constructions .",
    "we have also described an algorithm modification using surface optimization to further speed up the ( re)construction process and discussed its implementation based on our lattice - gas version of the digitized media .",
    "numerical experiments have shown that by applying the surface optimization algorithm properly ( i.e. , in the ( re)constructions of media composed well - defined `` particles '' ) , the final energy can be reduced by a factor of @xmath49 if the same cooling schedule is used . the choice of different pixel - lattices has also been discussed .",
    "we have applied the theoretical formalism proposed in paper i to model several examples of real materials . in particular",
    ", we used the lattice - point algorithm to generate 3d realizations of a fontainebleau sandstone and a boron carbide / aluminum composite from 2d images of their slices through the materials .",
    "the two - point cluster functions in the reconstructions in these two different cases matched the corresponding ones in the original materials , thus demonstrating the efficiency and accuracy of the ( re)construction algorithm in these cases .",
    "we also studied the reconstruction of a binary laser - speckle pattern in 2d , in which the algorithm fails to reproduce the target pattern accurately .",
    "we conclude that in general reconstructions using @xmath0 only work well for heterogeneous materials with single - scale structures .",
    "however , two - point information via @xmath0 is not sufficient to accurately model multi - scale media . in paper",
    "i , we pointed out that given a complete set of basis functions , one can obtain the basis - function approximations of the two - point correlation functions for the materials of interest to any accuracy . here",
    "we only used a simple form of eq .",
    "( [ eq7 ] ) due to our limited knowledge of the basis functions set .",
    "we also constructed realizations of materials with desired structural characteristics by manipulating the combination coefficients and the parameters in the basis functions .",
    ".  ( [ eq7 ] ) enables one to construct candidates of realizable functions with desired properties and to design materials with structural properties of interest .",
    "we are now developing efficient ( re)construction procedures that take into account additional microstructural information that characterize the media .",
    "for example , using our lattice - gas version of the digitized media , the two - point cluster functions @xmath4 can be directly incorporated into the yeong - torquato scheme @xcite , which enables one to obtain more accurate ( re)constructions of the target media . also , a quantitative structure - property relation is necessary for the further applications of the theoretical formalism .",
    "finite element analysis on the generated media will be performed to establish the relation . such work will be reported in our future publications ."
  ],
  "abstract_text": [
    "<S> in the first part of this series of two papers , we proposed a theoretical formalism that enables one to model and categorize heterogeneous materials ( media ) via two - point correlation functions @xmath0 and introduced an efficient heterogeneous - medium ( re)construction algorithm called the `` lattice - point '' algorithm . here </S>",
    "<S> we discuss the algorithmic details of the lattice - point procedure and an algorithm modification using surface optimization to further speed up the ( re)construction process . </S>",
    "<S> the importance of the error tolerance , which indicates to what accuracy the media are ( re)constructed , is also emphasized and discussed . </S>",
    "<S> we apply the algorithm to generate three - dimensional digitized realizations of a fontainebleau sandstone and a boron carbide / aluminum composite from the two - dimensional tomographic images of their slices through the materials . to ascertain whether the information contained in @xmath0 is sufficient to capture the salient structural features , we compute the two - point cluster functions of the media , which are superior signatures of the microstructure because they incorporate topological connectedness information . </S>",
    "<S> we also study the reconstruction of a binary laser - speckle pattern in two dimensions , in which the algorithm fails to reproduce the pattern accurately . </S>",
    "<S> we conclude that in general reconstructions using @xmath0 only work well for heterogeneous materials with single - scale structures </S>",
    "<S> . however , two - point information via @xmath0 is not sufficient to accurately model multi - scale random media . </S>",
    "<S> moreover , we construct realizations of hypothetical materials with desired structural characteristics obtained by manipulating their two - point correlation functions . </S>"
  ]
}