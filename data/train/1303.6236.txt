{
  "article_text": [
    "in the nonlinear filtering problem one observes a system whose state is known to follow a given stochastic differential equation .",
    "the observations that have been made contain an additional noise term , so one can not hope to know the true state of the system .",
    "however , one can reasonably ask what is the probability density over the possible states .",
    "when the observations are made in continuous time , the probability density follows a stochastic partial differential equation known as the kushner  stratonovich equation .",
    "this can be seen as a generalization of the fokker ",
    "planck equation that expresses the evolution of the density of a diffusion process .",
    "thus the problem we wish to address boils down to finding approximate solutions to the kushner  stratonovich equation .    for a quick introduction to the filtering problem",
    "see davis and marcus ( 1981 ) @xcite . for a more complete treatment from a mathematical point of view see lipster and shiryayev ( 1978 ) @xcite .",
    "see jazwinski ( 1970 ) @xcite for a more applied perspective . for recent results",
    "see the collection of papers @xcite .",
    "the main idea we will employ is inspired by the differential geometric approach to statistics developed in @xcite and @xcite .",
    "one thinks of the probability distribution as evolving in an infinite dimensional space @xmath1 which is in turn contained in some hilbert space @xmath2 .",
    "one can then think of the kushner ",
    "stratonovich equation as defining a vector field in @xmath1 : the integral curves of the vector field should correspond to the solutions of the equation . to find approximate solutions to the kushner ",
    "stratonovich equation one chooses a finite dimensional submanifold @xmath3 of @xmath2 and approximates the probability distributions as points in @xmath3 .",
    "at each point of @xmath3 one can use the hilbert space structure to project the vector field onto the tangent space of @xmath3 .",
    "one can now attempt to find approximate solutions to the kushner ",
    "stratonovich equations by integrating this vector field on the manifold @xmath3 .",
    "this mental image is slightly innaccurate .",
    "the kushner ",
    "stratonovich equation is a stochastic pde rather than a pde so one should imagine some kind of stochastic vector field rather than a smooth vector field .",
    "thus in this approach we hope to approximate the infinite dimensional stochastic pde by solving a finite dimensional stochastic ode on the manifold .",
    "note that our approximation will depend upon two choices : the choice of manifold @xmath3 and the choice of hilbert space structure @xmath2 . in this paper",
    "we will consider two possible choices for the hilbert space structure : the direct @xmath0 metric on the space of probability distributions ; the hilbert space structure associated with the hellinger distance and the fisher information metric .",
    "our focus will be on the direct @xmath0 metric since projection using the hellinger distance has been considered before .",
    "as we shall see , the choice of the `` best '' hilbert space structure is determined by the manifold one wishes to consider  for manifolds associated with exponential families of distributions the hellinger metric leads to the simplest equations , whereas the direct @xmath0 metric works well with mixture distributions .",
    "we will write down the stochastic ode determined by this approach when @xmath4 and show how it leads to a numerical scheme for finding approximate solutions to the kushner ",
    "stratonovich equations in terms of a mixture of normal distributions .",
    "we will call this scheme the _ @xmath0 normal mixture projection filter _ or simply the l2 nm projection filter .    the stochastic ode for the hellinger metric was considered in @xcite , @xcite and @xcite .",
    "in particular a precise numerical scheme is given in @xcite for finding solutions by projecting onto an exponential family of distributions .",
    "we will call this scheme the _",
    "hellinger exponential projection filter _ or simply the he projection filter .",
    "we will compare the results of a c++ implementation of the l2 nm projection filter with a number of other numerical approaches including the he projection filter and the optimal filter .",
    "we can measure the goodness of our filtering approximations thanks to the geometric structure and , in particular , the precise metrics we are using on the spaces of probability measures .",
    "what emerges is that the two projection methods produce excellent results for a variety of filtering problems .",
    "the results appear similar for both projection methods ; which gives more accurate results depends upon the problem .",
    "as we shall see , however , the l2 nm projection approach can be implemented more efficiently . in particular",
    "one needs to perform numerical integration as part of the he projection filter algorithm whereas all integrals that occur in the l2 nm projection can be evaluated analytically .",
    "we also compare the l2 nm filter to a particle filter with the best possible combination of particles with respect to the lvy metric . introducing the lvy metric",
    "is needed because particles densities do not compare well with smooth densities when using @xmath0 induced metrics .",
    "we show that , given the same number of parameters , the l2 nm may outperform a particles based system .",
    "the paper is structured as follows : in section [ sec : nonlinfp ] we introduce the nonlinear filtering problem and the infinite - dimensional stochastic pde ( spde ) that solves it . in section [ sec : sman ] we introduce the geometric structure we need to project the filtering spde onto a finite dimensional manifold of probability densities . in section",
    "[ sec : pf ] we perform the projection of the filtering spde according to the l2 nm framework and also recall the he based framework . in section [ sec :",
    "nimp ] we briefly discuss the numerical implementation , while in section [ sec : soft ] we discuss in detail the software design for the l2 nm filter . in section [ numres ]",
    "we look at numerical results , whereas in section [ sec : part ] we compare our outputs with a particle method .",
    "section [ sec : conc ] concludes the paper .",
    "in the non - linear filtering problem the state of some system is modelled by a process @xmath5 called the signal .",
    "this signal evolves over time @xmath6 according to an it stochastic differential equation ( sde ) .",
    "we measure the state of the system using some observation @xmath7 .",
    "the observations are not accurate , there is a noise term .",
    "so the observation @xmath7 is related to the signal @xmath5 by a second equation .",
    "@xmath8    in these equations the unobserved state process @xmath9 takes values in @xmath10 , the observation @xmath11 takes values in @xmath12 and the noise processes @xmath13 and @xmath14 are two brownian motions .",
    "the nonlinear filtering problem consists in finding the conditional probability distribution @xmath15 of the state @xmath16 given the observations up to time @xmath6 and the prior distribution @xmath17 for @xmath18 .",
    "let us assume that @xmath18 , and the two brownian motions are independent .",
    "let us also assume that the covariance matrix for @xmath19 is invertible .",
    "we can then assume without any further loss of generality that its covariance matrix is the identity .",
    "we introduce a variable @xmath20 defined by :    @xmath21    with these preliminaries , and a number of rather more technical conditions which we will state shortly , one can show that @xmath15 satisfies the a stochastic pde called the kushner ",
    "stratonovich equation .",
    "this states that for any compactly supported test function @xmath22 defined on @xmath23    @xmath24\\ ,     [ dy_s^k-\\pi_s(b_s^k)\\,ds]\\ , \\ ] ]    where for all @xmath25 , the backward diffusion operator @xmath26 is defined by @xmath27    equation  ( [ fkk ] ) involves the derivatives of the test function @xmath28 because of the expression @xmath29 .",
    "we assume now that @xmath15 can be represented by a density @xmath30 with respect to the lebesgue measure on @xmath10 for all time @xmath25 and that we can replace the term involving @xmath31 with a term involving its formal adjoint @xmath32 .",
    "thus , proceeding formally , we find that @xmath30 obeys the following it - type stochastic partial differential equation ( spde ) : @xmath33 [ { { \\mathrm d}}y_t^k - e_{p_t } \\{b_t^k \\ } { { \\mathrm d}}t ] \\ ] ] where @xmath34 denotes the expectation with respect to the probability density @xmath30 ( equivalently the conditional expectation given the observations up to time @xmath6 ) .",
    "the forward diffusion operator @xmath35 is defined by : @xmath36 + { { { \\textstyle\\frac{1}{2}}}}\\sum_{i , j=1}^n      \\frac{\\partial^2}{\\partial x_i \\partial x_j } [ a_t^{ij } \\phi ] .\\ ] ]    this equation is written in it form .",
    "when working with stochastic calculus on manifolds it is necessary to use stratonovich sde s rather than it sde s .",
    "this is because one does not in general know how to interpret the second order terms that arise in it calculus in terms of manifolds .",
    "the interested reader should consult @xcite .",
    "a straightforward calculation yields the following stratonvich spde :    @xmath37 \\,dt     + \\sum_{k=1}^d p_t\\ , [ b_t^k - e_{p_t}\\{b_t^k\\ } ] \\circ dy_t^k\\ .\\ ] ]    we have indicated that this is the stratonovich form of the equation by the presence of the symbol ` @xmath38 ' inbetween the diffusion coefficient and the brownian motion of the sde .",
    "we shall use this convention throughout the rest of the paper .    in order to simplify notation , we introduce the following definitions  : @xmath39\\ p , \\\\ \\\\",
    "\\gamma_t^k(p ) & : = & [ b_t^k - e_p\\{b_t^k\\ } ] p \\ , \\end{array}\\ ] ] for @xmath40 .",
    "the str form of the kushner ",
    "stratonovich equation reads now @xmath41    thus , subject to the assumption that a density @xmath30 exists for all time and assuming the necessary decay condition to ensure that replacing @xmath42 with its formal adjoint is valid , we find that solving the non - linear filtering problem is equivalent to solving this spde . numerically approximating",
    "the solution of equation  ( [ kse : str ] ) is the primary focus of this paper .",
    "for completeness we review the technical conditions required in order for equation  [ fkk ] to follow from  ( [ lanc1 - 1 ] ) .",
    "* local lipschitz continuity  : for all @xmath43 , there exists @xmath44 such that @xmath45 for all @xmath46 , and for all @xmath47 , the ball of radius @xmath48 . * non  explosion  : there exists @xmath49 such that @xmath50 for all @xmath46 , and for all @xmath51 . * polynomial growth  : there exist @xmath49 and @xmath52 such that @xmath53 for all @xmath46 , and for all @xmath51 .",
    "under assumptions  ( a ) and  ( b ) , there exists a unique solution @xmath54 to the state equation , see for example  @xcite , and @xmath16 has finite moments of any order . under the additional assumption  ( c ) the following _ finite energy _ condition holds @xmath55    since the finite energy condition holds , it follows from fujisaki , kallianpur and kunita  @xcite that @xmath56 satisfies the kushner  stratonovich equation  [ fkk ] .",
    "as discussed in the introduction , the idea of a projection filter is to approximate solutions to the kushner ",
    "stratononvich equation  [ fkk ] using a finite dimensional family of distributions .",
    "normal mixture _ family contains distributions given by : @xmath57 with @xmath58 and @xmath59 .",
    "it is a @xmath60 dimensional family of distributions .    a _ polynomial exponential family _",
    "contains distributions given by : @xmath61 where @xmath62 is chosen to ensure that the integral of @xmath63 is equal to @xmath64 . to ensure the convergence of the integral we must have that @xmath65 is even and @xmath66",
    "this is an @xmath65 dimensional family of distributions .",
    "polynomial exponential families are a special case of the more general notion of an exponential family , see for example @xcite .",
    "a key motivation for considering these families is that one can reproduce many of the qualitative features of distributions that arise in practice using these distributions .",
    "for example , consider the qualitative specification : the distribution should be bimodal with peaks near @xmath67 and @xmath64 with the peak at @xmath67 twice as high and twice as wide as the peak near @xmath64 .",
    "one can easily write down a distribution of this approximates form using a normal mixture .    to find a similar exponential family ,",
    "one seeks a polynomial with : local maxima at @xmath67 and @xmath64 ; with the maximum values at these points differing by @xmath68 ; with second derivative at @xmath64 equal to twice that at @xmath67 .",
    "these conditions give linear equations in the polynomial coefficients .",
    "using degree @xmath69 polynomials it is simple to find solutions meeting all these requirements .",
    "a specific numerical example of a polynomial meeting these requirements is plotted in figure  [ fig : bimodalsextic ] .",
    "the associated exponential distribution is plotted in figure  [ fig : bimodalexponential ] .    ]    ]    we see that normal mixtures and exponential families have a broadly similar power to describe the qualitative shape of a distribution using only a small number of parameters .",
    "our hope is that by approximating the probability distributions that occur in the kushner ",
    "stratonovich equation by elements of one of these families we will be able to derive a low dimensional approximation to the full infinite dimensional stochastic partial differential equation .",
    "we have given direct parameterisations of our families of probability distributions and thus we have implicitly represented them as finite dimensional manifolds . in this section we will see how families of probability distributions can be thought of as being embedded in a hilbert space and hence they inherit a manifold structure and metric from this hilbert space .",
    "there are two obvious ways of thinking of embedding a probability density function on @xmath10 in a hilbert space .",
    "the first is to simply assume that the probability density function is square integrable and hence lies directly in @xmath70 .",
    "the second is to use the fact that a probability density function lies in @xmath71 and is non - negative almost everywhere .",
    "hence @xmath72 will lie in @xmath70 .",
    "for clarity we will write @xmath73 when we think of @xmath70 as containing densities directly . the @xmath74 stands for direct .",
    "we write @xmath75 where @xmath76 is the set of square integrable probability densities ( functions with integral @xmath64 which are positive almost everywhere ) .",
    "similarly we will write @xmath77 when we think of @xmath70 as being a space of square roots of densities .",
    "the @xmath2 stands for hellinger ( for reasons we will explain shortly )",
    ". we will write @xmath78 for the subset of @xmath79 consisting of square roots of probability densities .",
    "we now have two possible ways of formalizing the notion of a family of probability distributions . in the next section we will define a smooth family of distributions to be either a smooth submanifold of @xmath80 which also lies in @xmath76 or a smooth submanifold of @xmath79 which also lies in @xmath81 . either way the families we discussed earlier will give us finite dimensional families in this more formal sense .",
    "the hilbert space structures of @xmath80 and @xmath79 allow us to define two notions of distance between probability distributions which we will denote @xmath82 and @xmath83 .",
    "given two probability distributions @xmath84 and @xmath85 we have an injection @xmath86 into @xmath0 so one defines the distance to be the norm of @xmath87 .",
    "so given two probability densities @xmath84 and @xmath85 on @xmath10 we can define :    @xmath88    here @xmath89 is the lebesgue measure .",
    "@xmath83 defines the _",
    "hellinger distance _ between the two distributions , which explains are use of @xmath2 as a subscript .",
    "we will write @xmath90 for the inner product associated with @xmath83 and @xmath91 or simply @xmath92 for the inner product associated with @xmath82 .",
    "in this paper we will consider the projection of the conditional density of the true state of the system given the observations ( which is assumed to lie in @xmath76 or @xmath81 ) onto a submanifold .",
    "the notion of projection only makes sense with respect to a particular inner product structure .",
    "thus we can consider projection using @xmath83 or projection using @xmath82 .",
    "each has advantages and disadvantages .",
    "the most notable advantage of the hellinger metric is that the @xmath83 metric can be defined independently of the lebesgue measure and its definition can be extended to define the distance between measures without density functions ( see jacod and shiryaev  @xcite or hanzon  @xcite ) . in particular",
    "the hellinger distance is indepdendent of the choice of parameterization for @xmath10 .",
    "this is a very attractive feature in terms of the differential geometry of our set up .    despite the significant theoretical advantages of the @xmath83 metric",
    ", the @xmath82 metric has an obvious advantage when studying mixture families : it comes from an inner product on @xmath80 and so commutes with addition on @xmath80 .",
    "so it should be relatively easy to calculate with the @xmath82 metric when adding distributions as happens in mixture families . as we shall see in practice ,",
    "when one performs concrete calculations , the @xmath83 metric works well for exponential families and the @xmath82 metric works well for mixture families . while the @xmath83 metric leads to the fisher information and to an equivalence with assumed density filters when used on exponential families ,",
    "see @xcite , the @xmath82 metric for simple mixture families is equivalent to a galerkin method , see for example @xcite .      to make our notion of smooth families precise we need to explain what we mean by a smooth map into an infinite dimensional space .",
    "let @xmath93 and @xmath94 be hilbert spaces and let @xmath95 be a continuous map ( @xmath96 need only be defined on some open subset of @xmath93 ) .",
    "we say that @xmath96 is frehet differentiable at @xmath97 if there exists a bounded linear map @xmath98 satisfying : @xmath99 if @xmath100 exists it is unique and we denote it by @xmath101 .",
    "this limit is called the frehet derivative of @xmath96 at @xmath97 .",
    "it is the best linear approximation to @xmath96 at @xmath102 in the sense of minimizing the norm on @xmath94 .",
    "this allows us to define a smooth map @xmath103 defined on an open subset of @xmath93 to be an infinitely frehet differentiable map .",
    "we define an _ immersion _ of an open subset of @xmath10 into @xmath94 to be a map such that @xmath101 is injective at every point where @xmath96 is defined .",
    "the latter condition ensures that the best linear approximation to @xmath96 is a genuinely @xmath104 dimensional map .",
    "given an immersion @xmath96 defined on a neighbourhood of @xmath97 , we can think of the vector subspace of @xmath94 given by the image of @xmath101 as representing the tangent space at @xmath97 .    to make these ideas more concrete ,",
    "let us suppose that @xmath105 is a probability distribution depending smoothly on some parameter @xmath106 where @xmath93 is some open subset of @xmath107 .",
    "the map @xmath108 defines a map @xmath109 . at a given point @xmath110 and for a vector @xmath111",
    "we can compute the frchet derivative to obtain : @xmath112    so we can identify the tangent space at @xmath113 with the following subspace of @xmath80 : @xmath114    we can formally define a smooth @xmath104-dimensional family of probability distributions in @xmath80 to be an immersion of an open subset of @xmath10 into @xmath76 .",
    "equivalently it is a smoothly parameterized probability distribution @xmath63 such that the above vectors in @xmath0 are linearly independent .",
    "we can define a smooth @xmath65-dimensional family of probability distributions in @xmath79 in the same way .",
    "this time let @xmath115 be a square root of a probability distribution depending smoothly on @xmath113 .",
    "the tangent vectors in this case will be the partial derivatives of @xmath116 with respect to @xmath113 .",
    "since one normally prefers to work in terms of probability distributions rather than their square roots we use the chain rule to write the tangent space as : @xmath117    we have defined a family of distributions in terms of a single immersion @xmath96 into a hilbert space @xmath94 . in other words",
    "we have defined a family of distributions in terms of a specific parameterization of the image of @xmath96 .",
    "it is tempting to try and phrase the theory in terms of the image of @xmath96 . to this end",
    ", one defines an _ embedded submanifold _ of @xmath94 to be a subspace of @xmath94 which is covered by immersions @xmath118 from open subsets of @xmath10 where each @xmath118 is a homeomorphisms onto its image . with this definition",
    ", we can state that the tangent space of an embedded submanifold is independent of the choice of parameterization .",
    "one might be tempted to talk about submanifolds of the space of probability distributions , but one should be careful . the spaces @xmath81 and @xmath76 are not open subsets of @xmath79 and @xmath80 and so do not have any obvious hilbert - manifold structure . to see why , consider figure  [ fig : perturbednormal ] where we have peturbed a probability distribution slightly by subtracting a small delta - like function .     arbitrarily close to the normal distribution but not in @xmath2 ]      given two tangent vectors at a point to a family of probability distributions we can form their inner product using @xmath90 .",
    "this defines a so - called _ riemannian metric _ on the family . with respect to a particular parameterization",
    "@xmath113 we can compute the inner product of the @xmath120 and @xmath121 basis vectors given in equation  [ basisforh ] .",
    "we call this quantity @xmath122 .",
    "@xmath123 up to the factor of @xmath124 , this last formula is the standard definition for the fisher information matrix .",
    "so our @xmath125 is the fisher information matrix .",
    "we can now interpret this matrix as the fisher information metric and observe that , up to the constant factor , this is the same thing as the hellinger distance .",
    "see @xcite , @xcite and @xcite for more in depth study on this differential geometric approach to statistics .",
    "the gaussian family of densities can be parameterized using parameters mean @xmath126 and variance @xmath127 . with this parameterization",
    "the fisher metric is given by : @xmath128\\ ] ]    the representation of the metric as a matrix depends heavily upon the choice of parameterization for the family .",
    "the gaussian family may be considered as a particular exponential family with parameters @xmath129 and @xmath130 given by : @xmath131 where @xmath132 is chosen to normalize @xmath63 .",
    "it follows that : @xmath133 this is related to the familiar parameterization in terms of @xmath126 and @xmath127 by : @xmath134 one can compute the fisher information metric relative to the parameterization @xmath129 to obtain : @xmath135\\ ] ]    the particular importance of the metric structure for this paper is that it allows us to define orthogonal projection of @xmath79 onto the tangent space .",
    "suppose that one has @xmath65 linearly independent vectors @xmath136 spanning some subspace @xmath137 of a hilbert space @xmath94 .",
    "by linearity , one can write the orthogonal projection onto @xmath137 as : @xmath138 w_i\\ ] ] for some appropriately chosen constants @xmath139 . since @xmath140 acts as the identity on @xmath136",
    "we see that @xmath139 must be the inverse of the matrix @xmath141 .",
    "we can apply this to the basis given in equation  [ basisforh ] . defining @xmath142 to be the inverse of the matrix @xmath125 we obtain the following formula for projection , using the hellinger metric , onto the tangent space of a family of distributions : @xmath143 \\frac{1}{2 \\sqrt{p } } \\frac { \\partial p } { \\partial \\theta_i}\\end{aligned}\\ ] ]      the ideas from the previous section can also be applied to the direct @xmath0 metric .",
    "this gives a different riemannian metric on the manifold .",
    "we will write @xmath144 to denote the @xmath0 metric when written with respect to a particular parameterization .    in coordinates @xmath126 , @xmath145 ,",
    "the @xmath0 metric on the gaussian family is : @xmath146\\ ] ]    we can obtain a formula for projection in @xmath80 using the direct @xmath0 metric using the basis given in equation  [ basisford ] .",
    "we write @xmath147 for the matrix inverse of @xmath148 .",
    "@xmath149 \\frac { \\partial p } { \\partial \\theta_i}.\\end{aligned}\\ ] ]",
    "given a family of probability distributions parameterised by @xmath113 , we wish to approximate an infinte dimensional solution to the non - linear filtering spde using elements of this family .",
    "thus we take the kushner ",
    "stratonovich equation  [ kse : str ] , view it as defining a stochastic vector field in @xmath76 and then project that vector field onto the tangent space of our family .",
    "the projected equations can then be viewed as giving a stochastic differential equation for @xmath113 . in this section",
    "we will write down these projected equations explicitly .",
    "let @xmath108 be the parameterization for our family .",
    "a curve @xmath150 in the parameter space corresponds to a curve @xmath151 in @xmath76 .",
    "for such a curve , the left hand side of the kushner ",
    "stratonovich equation  [ kse : str ] can be written :    @xmath152    where we write @xmath153 .",
    "@xmath154 is the basis for the tangent space of the manifold at @xmath155 .",
    "given the projection formula given in equation  [ l2projectionformula ] , we can project the terms on the right hand side onto the tangent space of the manifold using the direct @xmath0 metric as follows : @xmath156 & = & \\sum_{i=1}^m \\left [ \\sum_{j=1}^m h^{ij } \\langle { \\cal l}^ * p ,   v_j \\rangle \\right ] v_i \\\\ & = &   \\sum_{i=1}^m \\left [ \\sum_{j=1}^m h^{ij } \\langle p , { \\cal",
    "l } v_j \\rangle \\right ] v_i \\\\ \\pi_d^{\\theta } [ \\gamma^k ( p ) ] & = & \\sum_{i=1}^m \\left[\\sum_{j=1}^m h^{ij } \\langle \\gamma^k ( p ) , v_j \\rangle \\right ] v_i\\end{aligned}\\ ] ]    thus if we take @xmath0 projection of each side of equation  ( [ kse : str ] ) we obtain : @xmath157 v_i\\ ] ] since the @xmath158 form a basis of the tangent space , we can equate the coefficients of @xmath158 to obtain : @xmath159 this is the promised finite dimensional stochastic differential equation for @xmath113 corresponding to @xmath0 projection .",
    "if preferred , one could instead project the kushner ",
    "stratonovich equation using the hellinger metric instead .",
    "this yields the following stochastic differential equation derived originally in @xcite : @xmath160 note that the inner products in this equation are the direct @xmath0 inner products : we are simply using the @xmath0 inner product notation as a compact notation for integrals .",
    "equations  [ kse : l2projected ] and [ kse : hellingerprojected ] both give finite dimensional stochastic differential equations that we hope will approximate well the solution to the full kushner ",
    "stratonovich equation .",
    "we wish to solve these finite dimensional equations numerically and thereby obtain a numerical approximation to the non - linear filtering problem .",
    "because we are solving a low dimensional system of equations we hope to end up with a more efficient scheme than a brute - force finite difference approach .",
    "a finite difference approach can also be seen as a reduction of the problem to a finite dimensional system .",
    "however , in a finite difference approach the finite dimensional system still has a very large dimension , determined by the number of grid points into which one divides @xmath10 .",
    "by contrast the finite dimensional manifolds we shall consider will be defined by only a handful of parameters .",
    "the specific solution algorithm will depend upon numerous choices : whether to use @xmath0 or hellinger projection ; which family of probability distributions to choose ; how to parameterize that family ; the representation of the functions @xmath96 , @xmath161 and @xmath162 ; how to perform the integrations which arise from the calculation of expectations and inner products ; the numerical method selected to solve the finite dimensional equations .    to test the effectiveness of the projection idea",
    ", we have implemented a c++ engine which performs the numerical solution of the finite dimensional equations and allows one to make various selections from the options above .",
    "currently our implementation is restricted to the case of the direct @xmath0 projection for a @xmath64-dimensional state @xmath5 and @xmath64-dimensional noise @xmath137 .",
    "however , the engine does allow one to experiment with various manifolds , parameteriziations and functions @xmath96 , @xmath161 and @xmath162 .",
    "we use object oriented programming techniques in order to allow this flexibility .",
    "our implementation contains two key classes and .    to perform the computation",
    ", one must choose a data structure to represent elements of the function space .",
    "however , the most effective choice of representation depends upon the family of probability distributions one is considering and the functions @xmath96 , @xmath161 and @xmath162 .",
    "thus the c++ engine does not manipulate the data structure directly but instead works with the functions via the interface .",
    "a uml ( unified modelling language @xcite ) outline of the interface is given in table  [ uml : functionring ] .",
    ".uml for the interface [ cols=\"<\",options=\"header \" , ]     the other key abstraction is the . we give a uml representation of this abstraction in table  [ uml : manifold ] . for readers unfamiliar with uml",
    ", we remark that the @xmath163 symbol can be read `` list '' . for example , the computetangentvectors function returns a list of functions .",
    "the uses some convenient internal representation for a point , the most obvious representation being simply the @xmath65-tuple @xmath164 . on request",
    "the is able to provide the density associated with any point represented as an element of the .",
    "in addition the can compute the tangent vectors at any point .",
    "the method returns a list of elements of the corresponding to each of the vectors @xmath165 in turn .",
    "if the point is represented as a tuple @xmath166 , the method simply adds the components of the tuple @xmath167 to each of the components of @xmath113 .",
    "if a different internal representation is used for the point , the method should make the equivalent change to this internal representation .",
    "the method is called by our algorithm at the end of every time step . at this point",
    "the implementation can choose to change its parameterization for the state .",
    "thus the allows us ( in principle at least ) to use a more sophisticated atlas for the manifold than just a single chart .",
    "one should not draw too close a parallel between these computing abstractions and similarly named mathematical abstractions . for example , the space of objects that can be represented by a given do not need to form a differential ring despite the method .",
    "this is because the function will not be called infinitely often by the algorithm below , so the functions in the ring do not need to be infinitely differentiable .",
    "similarly the method allows the implementation more flexibility than simply changing chart . from one time step to the next it could decide to use a completely different family of distributions .",
    "the interface even allows the dimension to change from one time step to the next . we do not currently take advantage of this possibility , but adapatively choosing the family of distributions would be an interesting topic for further research",
    "the c++ engine is initialized with a object , a copy of the initial and objects representing @xmath96 , @xmath161 and @xmath162 .    at each time",
    "point the engine asks the manifold to compute the tangent vectors given the current point . using the multiply and integrate functions of the class , the engine can compute the inner products of any two functions , hence it can compute the metric matrix @xmath148 . similarly , the engine can ask the manifold for the density function given the current point and can then compute @xmath168 . proceeding in this way ,",
    "all the coefficients of @xmath169 and @xmath170 in equation  [ kse : l2projected ] can be computed at any given point in time .    were equation  [ kse : l2projected ] an it sde one could now numerically estimate @xmath167 , the change in @xmath113 over a given time interval @xmath171 in terms of @xmath171 and @xmath172 , the change in @xmath7 .",
    "one would then use the method to compute the new point and then one could repeat the calculation for the next time interval . in other words , were equation  [ kse : l2projected ] an it sde we could numerically solve the sde using the euler scheme .    however , equation  [ kse : l2projected ] is a stratonovich sde so the euler scheme is no longer valid .",
    "various numerical schemes for solving stochastic differential equations are considered in @xcite and @xcite .",
    "one of the simplest is the stratonovich ",
    "heun method described in @xcite .",
    "suppose that one wishes to solve the sde : @xmath173 the stratonvich ",
    "heun method generates an estimate for the solution @xmath174 at the @xmath104-th time interval using the formulae : @xmath175 in these formulae @xmath171 is the size of the time interval and @xmath176 is the change in @xmath137 .",
    "one can think of @xmath177 as being a prediction and the value @xmath178 as being a correction .",
    "thus this scheme is a direct translation of the standard euler ",
    "heun scheme for ordinary differential equations .",
    "we can use the stratonovich  heun method to numerically solve equation  [ kse : l2projected ] . given the current value @xmath179 for the state ,",
    "compute an estimate for @xmath180 by replacing @xmath169 with @xmath171 and @xmath181 with @xmath182 in equation  [ kse : l2projected ] . using the method",
    "compute a prediction @xmath183 .",
    "now compute a second estimate for @xmath180 using equation  [ kse : l2projected ] in the state @xmath183 .",
    "pass the average of the two estimates to the function to obtain the the new state @xmath184 .    at the end of each time step , the method is called .",
    "this provides the manifold implementation the opportunity to perform checks such as validation of the state , to correct the normalization and , if desired , to change the representation it uses for the state .",
    "one small observation worth making is that the equation  [ kse : l2projected ] contains the term @xmath147 , the inverse of the matrix @xmath148 .",
    "however , it is not necessary to actually calculate the matrix inverse in full .",
    "it is better numerically to multiply both sides of equation  [ kse : l2projected ] by the matrix @xmath148 and then compute @xmath185 by solving the resulting linear equations directly .",
    "this is the approach taken by our algorithm .",
    "as we have already observed , there is a wealth of choices one could make for the numerical scheme used to solve equation  [ kse : l2projected ] , we have simply selected the most convenient .",
    "the existing and implementations could be used directly by many of these schemes  in particular those based on runge  kutta schemes . in principle",
    "one might also consider schemes that require explicit formulae for higher derivatives such as @xmath186 . in this case one",
    "would need to extend the manifold abstraction to provide this information .",
    "similarly one could use the same concepts in order to solve equation  [ kse : hellingerprojected ] where one uses the hellinger projection . in this case",
    "the would need to be extended to allow division .",
    "this would in turn complicate the implementation of the integrate function , which is why we have not yet implemented this approach .",
    "let @xmath187 denote the space of functions which can be written as finite linear combinations of terms of the form : @xmath188 where @xmath104 is non - negative integer and @xmath189 , @xmath162 and @xmath190 are constants .",
    "@xmath187 is closed under addition , multiplication and differentiation , so it forms a differential ring .",
    "we have written an implementation of corresponding to @xmath187 .",
    "although the implementation is mostly straightforward some points are worth noting .",
    "firstly , we store elements of our ring in memory as a collection of tuples @xmath191 .",
    "although one can write : @xmath192 for appropriate @xmath116 , the use or such a term in computer memory should be avoided as it will rapidly lead to significant rounding errors .",
    "a small amount of care is required throughout the implementation to avoid such rounding errors .",
    "secondly let us consider explicitly how to implement integration for this ring .",
    "let us define @xmath193 to be the integral of @xmath194 . using integration by parts one has :    @xmath195    since @xmath196 and @xmath197 we can compute @xmath193 recursively .",
    "hence we can analytically compute the integral of @xmath198 for any polynomial @xmath63 . by substitution",
    ", we can now integrate @xmath199 for any @xmath126 . by completing the square",
    "we can analytically compute the integral of @xmath200 so long as @xmath201 . putting all this together one",
    "has an algorithm for analytically integrating the elements of @xmath187 .",
    "let @xmath202 denote the space of probability distributions that can be written as @xmath203 for some real numbers @xmath204 , @xmath205 and @xmath206 with @xmath207 .",
    "given a smooth curve @xmath208 in @xmath202 we can write :    @xmath209    we can then compute : @xmath210    we deduce that the tangent vectors of any smooth submanifold of @xmath202 must also lie in @xmath187 .",
    "in particular this means that our implementation of will be sufficient to represent the tangent vectors of any manifold consisting of finite normal mixtures .    combining these ideas we obtain the main theoretical result of the paper .",
    "let @xmath113 be a parameterization for a family of probability distributions all of which can be written as a mixture of at most @xmath211 gaussians .",
    "let @xmath96 , @xmath212 and @xmath162 be functions in the ring @xmath187 . in this case",
    "one can carry out the direct @xmath0 projection algorithm for the problem given by equation  ( [ lanc1 - 1 ] ) using analytic formulae for all the required integrations .",
    "although the condition that @xmath96 , @xmath189 and @xmath162 lie in @xmath187 may seem somewhat restrictive , when this condition is not met one could use taylor expansions to find approximate solutions .",
    "although the choice of parameterization does not affect the choice of , it does affect the numerical behaviour of the algorithm .",
    "in particular if one chooses a parameterization with domain a proper subset of @xmath107 , the algorithm will break down the moment the point @xmath113 leaves the domain . with this in mind , in the numerical examples given later in this paper we parameterize normal mixtures of @xmath213 gaussians with a parameterization defined on the whole of @xmath10 .",
    "we describe this parameterization below .",
    "label the parameters @xmath214 ( with @xmath215 ) , @xmath216 , @xmath217 ( with @xmath218 ) and @xmath219 ( with @xmath220 ) .",
    "this gives a total of @xmath221 parameters .",
    "so we can write @xmath222 given a point @xmath113 define variables as follows : @xmath223 where the @xmath224 function sends a probability @xmath225 $ ] to its log odds , @xmath226 .",
    "we can now write the density associated with @xmath113 as : @xmath227    we do not claim this is the best possible choice of parameterization , but it certainly performs better than some more nave parameteriations with bounded domains of definition .",
    "we will call the direct @xmath0 projection algorithm onto the normal mixture family given with this projection the _",
    "l2 nm projection filter_.      a similar algorithm is described in @xcite for projection using the hellinger metric onto an exponential family .",
    "we refer to this as the _ he projection filter_.    it is worth highlighting the key differences between our algorithm and the exponential projection algorithm described in @xcite .    * in @xcite",
    "only the special case of the cubic sensor was considered .",
    "it was clear that one could in principle adapt the algorithm to cope with other problems , but there remained symbolic manipulation that would have to be performed by hand .",
    "our algorithm automates this process by using the abstraction . * when one projects onto an exponential family , the stochastic term in equation  ( [ kse : hellingerprojected ] ) simplifies to a term with constant coefficients .",
    "this means it can be viewed equally well as either an it or stratonovich sde .",
    "the practical consequence of this is that the he algorithm can use the euler ",
    "maruyama scheme rather than the stratonvoich ",
    "heun scheme to solve the resulting stochastic ode s .",
    "moreover in this case the euler - maruyama scheme coincides with the generally more precise milstein scheme . * in the case of the cubic sensor , the he algorithm requires one to numerically evaluate integrals such as : + @xmath228 + where the @xmath229 are real numbers . performing such integrals",
    "numerically considerably slows the algorithm . in effect one ends up using a rather fine discretization scheme to evaluate the integral and this somewhat offsets the hoped for advantage over a finite difference method .",
    "in this section we compare the results of using the direct @xmath0 projection filter onto a mixture of normal distributions with other numerical methods . in particular we compare it with :    1 .   a finite difference method using a fine grid which we term the _ exact filter_. various convergence results are known ( @xcite and @xcite ) for this method . in the simulations shown below we use a grid with @xmath230 points on the @xmath97-axis and @xmath231 time points . in our simulations",
    "we could not visually distinguish the resulting graphs when the grid was refined further justifying us in considering this to be extremely close to the exact result .",
    "the precise algorithm used is as described in the section on `` partial differential equations methods '' in chapter 8 of bain and crisan  @xcite .",
    "2 .   the _ extended kalman filter _ ( ek ) .",
    "this is a somewhat heuristic approach to solving the non - linear filtering problem but which works well so long as one assumes the system is almost linear .",
    "it is implemented essentially by linearising all the functions in the problem and then using the exact kalman filter to solve this linear problem - the details are given in @xcite .",
    "the ek filter is widely used in applications and so provides a standard benchmark .",
    "however , it is well known that it can give wildly innaccurate results for non - linear problems so it should be unsurprising to see that it performs badly for most of the examples we consider",
    "the he projection filter .",
    "in fact we have implemented a generalization of the algorithm given in @xcite that can cope with filtering problems where @xmath162 is an aribtrary polynomial , @xmath161 is constant and @xmath232 .",
    "thus we have been able to examine the performance of the exponential projection filter over a slightly wider range of problems than have previously been considered .    to compare these methods , we have simulated solutions of the equations  [ lanc1 - 1 ] for various choices of @xmath96 , @xmath161 and @xmath162 .",
    "we have also selected a prior probability distribution @xmath233 for @xmath5 and then compared the numerical estimates for the probability distribution @xmath63 at subsequent times given by the different algorithms . in the examples below",
    "we have selected a fixed value for the intial state @xmath18 rather than drawing at random from the prior distribution .",
    "this should have no more impact upon the results than does the choice of seed for the random number generator .",
    "since each of the approximate methods can only represent certain distributions accurately , we have had to use different prior distributions for each algorithm . to compare the two projection filters we have started with a polynomial exponential distribution for the prior and then found a nearby mixture of normal distributions .",
    "this nearby distribution was found using a gradient search algorithm to minimize the numerically estimated @xmath0 norm of the difference of the normal and polynomial exponential distributions . as indicated earlier ,",
    "polynomial exponential distributions and normal mixtures are qualitatively similar so the prior distributions we use are close for each algorithm .    for the extended kalman filter ,",
    "one has to approximate the prior distribution with a single gaussian .",
    "we have done this by moment matching .",
    "inevitably this does not always produce satisfactory results .",
    "for the exact filter , we have used the same prior as for the @xmath0 projection filter .",
    "the first test case we have examined is the linear filtering problem . in this case",
    "the probability density will be a gaussian at all times  hence if we project onto the two dimensional family consisting of all gaussian distributions there should be no loss of information . thus both projection filters should give exact answers for linear problems .",
    "this is indeed the case , and gives some confidence in the correctness of the computer implementations of the various algorithms .",
    "the second test case we have examined is the _",
    "quadratic sensor_. this is problem  [ lanc1 - 1 ] with @xmath232 , @xmath234 and @xmath235 for some positive constants @xmath236 and @xmath237 . in this problem",
    "the non - injectivity of @xmath162 tends to cause the distribution at any time to be bimodal . to see why ,",
    "observe that the sensor provides no information about the sign of @xmath97 , once the state of the system has passed through @xmath102 we expect the probability density to become approximately symmetrical about the origin . since we expect the probability density to be bimodal for the quadratic sensor it makes sense to approximate the distribution with a linear combination of two gaussian distributions .    in figure  [ quadraticsensortimepoints ]",
    "we show the probability density as computed by three of the algorithms at 10 different time points for a typical quadratic sensor problem . to reduce clutter",
    "we have not plotted the results for the exponential filter .",
    "the prior exponential distribution used for this simulation was @xmath238 .",
    "the initial state was @xmath239 and @xmath240 .",
    "as one can see the probability densities computed using the exact filter and the l2 nm filter become visually indistinguishable when the state moves away from the origin .",
    "the extended kalman filter is , as one would expect , completely unable to cope with these bimodal distributions . in this case",
    "the extended kalman filter is simply representing the larger of the two modes .",
    "time points for the problem @xmath241    in figure  [ quadraticsensorresiduals ] we have plotted the _",
    "@xmath0 residuals _ for the different algorithms when applied to the quadratic sensor problem .",
    "we define the @xmath0 residual to be the @xmath0 norm of the difference between the exact filter distribution and the estimated distribution .",
    "@xmath242 as can be seen , the l2 nm projection filter outperforms the he projection filter when applied to the quadratic sensor problem .",
    "notice that the @xmath0 residuals are initially small for both the he and the l2 nm filter .",
    "the superior performance of the l2 nm projection filter in this case stems from the fact that one can more accurately represent the distributions that occur using the normal mixture family than using the polynomial exponential family .",
    "if preferred one could define a similar notion of residual using the hellinger metric .",
    "the results would be qualitatively similar .",
    "one interesting feature of figure  [ quadraticsensorresiduals ] is that the error remains bounded in size when one might expect the error to accumulate over time .",
    "this suggests that the arrival of new measurements is gradually correcting for the errors introduced by the approximation .",
    "residuals for the problem @xmath241      a third test case we have considered is the _ general cubic sensor_. in this problem one has @xmath232 , @xmath234 for some constant @xmath236 and @xmath162 is some cubic function .    the case when @xmath162 is a multiple of @xmath243 is called the _ cubic sensor _ and was used as the test case for the exponential projection filter using the hellinger metric considered in @xcite .",
    "it is of interest because it is the simplest case where @xmath162 is injective but where it is known that the problem can not be reduced to a finite dimensional stochastic differential equation @xcite .",
    "it is known from earlier work that the exponential filter gives excellent numerical results for the cubic sensor .",
    "our new implementations allow us to examine the general cubic sensor . in figure  [ cubicsensortimepoints ]",
    ", we have plotted example probability densities over time for the problem with @xmath232 , @xmath244 and @xmath245 . with two turning points for @xmath162",
    "this problem is very far from linear .",
    "as can be seen in figure  [ cubicsensortimepoints ] the l2 nm projection remains close to the exact distribution throughout .",
    "a mixture of only two gaussians is enough to approximate quite a variety of differently shaped distributions with perhaps surprising accuracy .",
    "as expected , the extended kalman filter gives poor results until the state moves to a region where @xmath162 is injective .",
    "the results of the exponential filter have not been plotted in figure  [ cubicsensortimepoints ] to reduce clutter .",
    "it gave similar results to the l2 nm filter .",
    "the prior polynomial exponential distribution used for this simulation was @xmath246 .",
    "the initial state was @xmath239 , which is one of the modes of prior distribution .",
    "the inital value for @xmath247 was taken to be @xmath102 .",
    "time points for the problem @xmath248    one new phenomenon that occurs when considering the cubic sensor is that the algorithm sometimes abruptly fails .",
    "this is true for both the l2 nm projection filter and the he projection filter .    to show the behaviour over time more clearly , in figure  [ cubicsensormeansandsds ] we have shown a plot of the mean and standard deviation as estimated by the l2 nm projection filter against the actual mean and standard deviation .",
    "we have also indicated the true state of the system .",
    "the mean for the l2mn filter drops to @xmath102 at approximately time @xmath249 .",
    "it is at this point that the algorithm has failed .",
    "]    what has happened is that as the state has moved to a region where the sensor is reasonably close to being linear , the probability distribution has tended to a single normal distribution .",
    "such a distribution lies on the boundary of the family consisting of a mixture of two normal distributions .",
    "as we approach the boundary , @xmath148 ceases to be invertible causing the failure of the algorithm .",
    "analogous phenomena occur for the exponential filter .",
    "the result of running numerous simulations suggests that the he filter is rather less robust than the l2 nm projection filter .",
    "the typical behaviour is that the exponential filter maintains a very low residual right up until the point of failure .",
    "the l2 nm projection filter on the other hand tends to give slightly inaccurate results shortly before failure and can often correct itself without failing .",
    "this behaviour can be seen in figure  [ cubicsensorresiduals ] . in this figure ,",
    "the residual for the exponential projection remains extremely low until the algorithm fails abruptly - this is indicated by the vertical dashed line .",
    "the l2 nm filter on the other hand deteriorates from time @xmath69 but only fails at time @xmath249 .",
    "residuals for the problem @xmath248    the @xmath0 residuals of the l2mn method are rather large between times @xmath69 and @xmath249 but note that the accuracy of the estimates for the mean and standard deviation in figure  [ cubicsensormeansandsds ] remain reasonable throughout this time . to understand this note that for two normal distributions with means a distance @xmath97 apart , the @xmath0 distance between the distributions increases as the standard deviations of the distributions drop .",
    "thus the increase in @xmath0 residuals between times @xmath69 and @xmath249 is to a large extent due to the drop in standard deviation between these times . as a result",
    ", one may feel that the @xmath0 residual does nt capture precisely what it means for an approximation to be `` good '' . in the next section",
    "we will show how to measure residuals in a way that corresponds more closely to the intuitive idea of them having visually similar distribution functions . in practice",
    "one s definition of a good approximation will depend upon the application .",
    "although one might argue that the filter is in fact behaving reasonably well between times @xmath69 and @xmath249 it does ultimately fail .",
    "there is an obvious fix for failures like this .",
    "when the current point is sufficiently close to the boundary of the manifold , simply approximate the distribution with an element of the boundary . in other words , approximate the distribution using a mixture of fewer gaussians .",
    "since this means moving to a lower dimensional family of distributions , the numerical implementation will be more efficient on the boundary .",
    "this will provide a temporary fix the failure of the algorithm , but it raises another problem : as the state moves back into a region where the problem is highly non linear , how can one decide how to leave the boundary and start adding additional gaussians back into the mixture ?",
    "we hope to address this question in a future paper .",
    "particle methods approximate the probability density @xmath63 using discrete measures of the form : @xmath250 these measures are generated using a monte carlo method .",
    "the measure can be thought of as the empirical distributions associated with randomly located particles at position @xmath251 and of stochastic mass @xmath252 .",
    "particle methods are currently some of the most effective numerical methods for solving the filtering problem .",
    "see @xcite and the references therein for details of specific particle methods and convergence results .",
    "the first issue in comparing projection methods with particle methods is that , as a linear combination of dirac masses , one can only expect a particle method to converge weakly to the exact solution . in particular",
    "the @xmath0 metric and the hellinger metric are both inappropriate measures of the residual between the exact solution and a particle approximation .",
    "indeed the @xmath0 distance is not defined and the hellinger distance will always take the value @xmath253 .    to combat this issue , we will measure residuals using the lvy metric .",
    "if @xmath63 and @xmath116 are two probability measures on @xmath254 and @xmath255 and @xmath256 are the associated cumulative distribution functions then the lvy metric is defined by : @xmath257 this can be interpreted geometrically as the size of the largest square with sides parallel to the coordinate axes that can be inserted between the completed graphs of the cumulative distribution functions ( the completed graph of the distribution function is simply the graph of the distribution function with vertical line segments added at discontinuities ) .",
    "the lvy metric can be seen as a special case of the lvy ",
    "prokhorov metric .",
    "this can be used to measure the distance between measures on a general metric space . for polish spaces ,",
    "prokhorov metric metrises the weak convergence of probability measures @xcite .",
    "thus the lvy metric provides a reasonable measure of the residual of a particle approximation .",
    "we will call residuals measured in this way lvy residuals .",
    "a second issue in comparing projection methods with particle methods is deciding how many particles to use for the comparison .",
    "a natural choice is to compare a projection method onto an @xmath65-dimensional manifold with a particle method that approximates the distribution using @xmath258 particles .",
    "in other words , equate the dimension of the families of distributions used for the approximation .",
    "a third issue is deciding which particle method to choose for the comparison from the many algorithms that can be found in the literature .",
    "we can work around this issue by calculating the best possible approximation to the exact distribution that can be made using @xmath258 dirac masses .",
    "this approach will substantially underestimate the lvy residual of a particle method : being monte carlo methods , large numbers of particles would be required in practice .    ]    in figure [ levyresiduals ] we have plotted bounds on the lvy residuals for the two projection methods for the quadratic sensor .",
    "since mixtures of two normal distributions lie in a @xmath259 dimensional family , we have compared these residuals with the best possible lvy residual for a mixture of three dirac masses .    to compute the lvy residual between two functions we",
    "have approximated first approximated the cumulative distribution functions using step functions .",
    "we have used the same grid for these steps as we used to compute our `` exact '' filter .",
    "we have then used a brute force approach to compute a bound on size of the largest square that can be placed between these step functions . thus if we have used a grid with @xmath104 points to discretize the @xmath97-axis",
    ", we will need to make @xmath260 comparisons to estimate the lvy residual .",
    "more efficient algorithms are possible , but this approach is sufficient for our purposes .",
    "the maximum accuracy of the computation of the lvy metric is constrained by the grid size used for our `` exact '' filter . since the grid size in the @xmath97 direction for our `` exact '' filter is @xmath261 , our estimates for the projection residuals",
    "are bounded below by @xmath262 .",
    "the computation of the minimum residual for a particle filter is a little more complex .",
    "let @xmath263 denote the minimum lvy distance between a distribution with cumulative distribution @xmath264 and a distribution of @xmath104 particles .",
    "let @xmath265 denote the minimum number of particles required to approximate @xmath264 with a residual of less than @xmath266 .",
    "if we can compute @xmath267 we can use a line search to compute @xmath268 .    to compute @xmath265 for an increasing step function @xmath264 with @xmath269 and @xmath270",
    ", one needs to find the minimum number of steps in a similar increasing step function @xmath271 that is never further than @xmath266 away from @xmath264 in the @xmath272 metric .",
    "one constructs candidate step functions @xmath271 by starting with @xmath273 and then moving along the @xmath97-axis adding in additional steps as required to remain within a distance @xmath266 .",
    "an optimal @xmath271 is found by adding in steps as late as possible and , when adding a new step , making it as high as possible .    in this way",
    "we can compute @xmath267 and @xmath274 for step functions @xmath264 .",
    "we can then compute bounds on these values for a given distribution by approximating its cumulative density function with a step function .",
    "as can be seen , the exponential and mixture projection filters have similar accuracy as measured by the lvy residual and it is impossible to match this accuracy using a model containing only @xmath275 particles .",
    "projection onto a family of normal mixtures using the @xmath0 metric allows one to approximate the solutions of the non - linear filtering problem with surprising accuracy using only a small number of component distributions . in this regard",
    "it behaves in a very similar fashion to the projection onto an exponential family using the hellinger metric that has been considered previously .",
    "the l2 nm projection filter has one important advantage over the he projection filter , for problems with polynomial coefficients all required integrals can be calculated analytically .",
    "problems with more general coefficients can be addressed using taylor series .",
    "one expects this to translate into a better performing algorithm  particularly if the approach is extended to higher dimensional problems .",
    "we tested both filters against the optimal filter in simple but interesting systems , and we provided a metric to compare the performance of each filter with the optimal one .",
    "we also tested both filters against a particle method , showing that with the same number of parameters the l2 nm filter outperforms the best possible particle method in levy metric .",
    "areas of future research that we hope to address include : the relationship between the projection approach and existing numerical approaches to the filtering problem ; the convergence of the algorithm ; improving the stability and performance of the algorithm by adaptively changing the parameterization of the manifold ; numerical simulations in higher dimensions .",
    "brigo , d. diffusion processes , manifolds of exponential densities , and nonlinear filtering , in : ole e. barndorff - nielsen and eva b. vedel jensen , editor , geometry in present day science , world scientific , 1999                  m. h. a. davis , s. i. marcus , an introduction to nonlinear filtering , in : m. hazewinkel , j. c. willems , eds . , _",
    "stochastic systems : the mathematics of filtering and identification and applications _",
    "( reidel , dordrecht , 1981 ) 5375 .",
    "hanzon , b. a differential - geometric approach to approximate nonlinear filtering . in c.t.j .",
    "dodson , geometrization of statistical theory , pages 219 - 223,ulmd publications , university of lancaster , 1987 .",
    "kenney , j. , stirling , w. nonlinear filtering of convex sets of probability distributions .",
    "presented at the 1st international symposium on imprecise probabilities and their applications , ghent , belgium , 29 june - 2 july 1999"
  ],
  "abstract_text": [
    "<S> we examine some differential geometric approaches to finding approximate solutions to the continuous time nonlinear filtering problem . </S>",
    "<S> our primary focus is a projection method using the direct @xmath0 metric onto a family of normal mixtures . </S>",
    "<S> we compare this method to earlier projection methods based on the hellinger distance / fisher metric and exponential families , and we compare the @xmath0 mixture projection filter with a particle method with the same number of parameters . </S>",
    "<S> we study particular systems that may illustrate the advantages of this filter over other algorithms when comparing outputs with the optimal filter . </S>",
    "<S> we finally consider a specific software design that is suited for a numerically efficient implementation of this filter and provide numerical examples .    * keywords : * finite dimensional families of probability distributions , exponential families , mixture families , hellinger distance , fisher information metric , direct l2 metric , stochastic filtering    * ams classification codes : 53b25 , 53b50 , 60g35 , 62e17 , 62m20 , 93e11 * </S>"
  ]
}