{
  "article_text": [
    "the methods developed in the context of statistical mechanics and , more in general , in the study of complex systems have found in the last years broad application in many different scientific fields .",
    "economic sciences particularly benefited from interdisciplinary approaches and borrowed some crucial ideas , powerful tools and techniques @xcite from those fields .",
    "however , these efforts have been devoted almost exclusively to the study of the financial risk @xcite , and only more recently also other typologies of risk @xcite as the operational risk @xcite are gaining more and more attention .",
    "operational risk is `` the risk of [ money ] loss [ in banks ] resulting from inadequate or failed internal processes , people and systems or from external events '' @xcite , including legal risk , but excluding strategic and reputation linked risks .",
    "let us make an example to clarify the dynamics underlying the generation of operational losses ; suppose that a material damage in the system that controls and authorizes the transactions occurs and is discovered at the time @xmath3 , but repaired only later at the time @xmath4 ; a loss equal to the amount of money needed to repair the damage is generated at the time @xmath3 in the process of machinery servicing , but the failure has likely generated losses delayed up to the time @xmath4 , because some transactions have failed or have been wrongly authorized .",
    "this example shows that the different processes may be strongly correlated , and that their typical correlations extend over time .",
    "the primary goal of the management of operational risk is to determine the capital charge that the bank has to put aside ( e.g.  every year ) to cover the operational losses .",
    "the new basel capital accord @xcite roughly proposes to set this capital to the @xmath5 of the bank s gross income , or to consider the gross income per business line and weight each one with a coefficient ranging from @xmath6 to @xmath7 ; we will call these approaches `` macroscopic '' , since they assume that the capital requirement does not depend on the details of the internal structure of the bank , but only on its size",
    ". however , the basic assumption of these approaches seems not to be realistic and they do not provide any insight on the mechanisms underlying the generation of losses , not allowing any practice aimed to foresee or reduce the future losses .",
    "the new basel capital accord also envisages that each bank is free to develop its own approach to the evaluation of the capital requirement as long as it satisfies some general requirements .",
    "one possible approach is the `` microscopic '' one in which one tries to take into account all the fundamental mechanisms involved in the generation of operational losses ; it is clear that in this framework one should deal not only with variables representing operational losses but with heterogeneous variables which strongly depend on the particular mechanism under examination .",
    "although these approaches are more solidly founded than the macroscopic ones , they suffer from practical drawbacks ; firstly , it is extremely difficult to introduce a dynamical model that couples all the microscopic variables in a realistic way : for this reason some attempts in this sense @xcite have been done using bayesian networks , which allow to model statistical correlations among heterogeneous variables , but do not allow to follow the evolution of losses in time .",
    "secondly , the implementation of such an approach inside a bank requires that all the relevant variables should be monitored reliably with a certain frequency , which can be an extremely resource demanding task , especially for a small or medium sized bank .",
    "an alternative approach may be to provide a description of loss events based on an effective model consisting of much fewer degrees of freedom than a microscopic one , but still able to distinguish the internal structure of a bank ; it is natural to call such an approach `` mesoscopic '' , since one can think that the effective variables are obtained by integrating out the details contained in the microscopic ones . in the non - macroscopic approaches the capital requirement is usually identified with the value - at - risk ( var ) over one year and with @xmath8 level of confidence , i.e.  the @xmath9 percentile of the yearly loss distribution ; this implies that the probability of registering a loss being greater than the value of the var in one year is equal to @xmath10 or , equivalently , that such a loss may occur on average every @xmath11 years .",
    "the most widely used non - macroscopic approach is mesoscopic : the loss distribution approach ( lda ) @xcite classifies the loss events in @xmath12 business lines ( sectors of activity of the bank ) and @xmath13 event types ( causes of the loss ) and identifies the relevant variables with the number of losses occurred during a certain time horizon ( frequency ) and with the amount of a single loss ( severity ) for each of the @xmath14 couples ( business line , event type ) ; the lda makes use of the distributions of frequency and severity to derive the loss distribution over the given time horizon , usually assuming that frequency and severity for each process are independent random variables , and thus failing in capturing the correlations among different couples .",
    "there are some proposals of how to take into account the correlations in the context of lda , e.g.  among frequency of different couples @xcite , frequency and severity of the same couple @xcite , frequency and severity of different couples @xcite or aggregate losses of different couples @xcite , or in different frameworks @xcite , but no one has gained a general consensus .",
    "it is worth pointing out that it is very unlikely that mechanism of loss production involves frequency and severity , which should be simply considered statistical tools to model the loss distribution over the given time horizon : for this reason it is not obvious how to incorporate the time dependence into the lda framework .",
    "a different possible mesoscopic approach consists in assuming that the effective variables are the degrees of freedom of a dynamical system and postulating an effective equation of motion @xcite .",
    "the model should be sufficiently general to explain the dynamics of loss production in all the banks , but flexible enough to adapt to the particular internal structure of a specific bank , for example by properly tuning the parameters appearing in the equation of motion .",
    "once the parameters have been estimated , the advantage of a dynamical approach is immediately evident : one may follow the production of the losses during time and thus may be able to make predictions about the evolution of losses . in the approach presented in this paper",
    "the effective variables are the amount of losses registered at a certain time in a certain process ; processes are categories in which losses are classified and depend on the specific structure of a bank ; examples are material damage , failed transaction or fraud .",
    "the equation of motion includes two general mechanisms for the generation of losses in a process : the interactions with other processes and the spontaneous generation due to a random noise ; the possibility that the bank invests money to avoid the occurrence of losses is also taken into account . as the equation of motion contains a noise term , the loss distribution will naturally arise considering several realization of the noise : therefore the var can be still taken as a measure of the capital requirement .",
    "since the different - time correlations play a crucial role , the interaction term is non - local in time .",
    "let us point out that , even in the case in which the microscopic dynamics of the system was local in time , it is perfectly reasonable to assume an effective dynamics that is non - local in time : it is a well known result @xcite that the reduced dynamical system obtained integrating out some degrees of freedom from a dynamical system with equation of motion local in time is in general characterized by an equation of motion which is non - local in time . from this point of view",
    ", the non - locality in the equation of motion is justified a priori , basing on very general considerations , rather than a posteriori , basing on some peculiar features of the loss distributions .",
    "a dynamical model for operational risk has been already proposed in @xcite , and also applied to the study of credit risk @xcite .",
    "there are some important differences between the approach in @xcite and the one proposed in this paper .",
    "firstly , while the dynamics in @xcite is local in time , the one proposed here is not , for the reasons that we have just discussed .",
    "secondly , as explained in section  [ sec : alt_model ] , the dynamics proposed here allows the estimation of the parameters of the noise .",
    "in addition , even if it is possible to show that the proposed dynamics is equivalent to a dynamical generalization of the lda @xcite ( see section  [ sec : alt_model ] ) , it is possible to interpret all the terms in the equation of motion as general mechanisms which are responsible for the generation of operational losses . from this point of view , it is natural to build a dynamics which directly involves the amount of losses registered in each process .",
    "such an approach has been introduced in @xcite , where also a detailed comparison with the framework of frequency and severity is made .",
    "the methodological advantage is that one has not to make direct assumptions on the shape of the loss distribution , but only on the basic mechanisms that generate the losses : in a sense , the features of the loss distribution _ emerge _ from those mechanisms .",
    "this is a fundamental difference with respect to @xcite , where the form of both frequency and severity distributions are imposed a priori .",
    "the paper is organized as follows : in section  [ sec : model ] the model is introduced and in section  [ sec : solutions ] it is shown that under some hypothesis it can be exactly solved ; in section  [ sec : learning ] it is illustrated how some parameters of the model can be estimated from real data ; in section  [ sec : tests ] the proposed procedure to estimate the parameters is validated by means of simulated data ; moreover , the capability of model to forecast future operational losses is tested by estimating the parameters only from a fraction of simulated data and comparing the forecasts made by the model with the remaining part ; in section  [ sec : alt_model ] the model is compared with an alternate one , while in section  [ sec : outro ] some conclusions are drawn .",
    "the model consists of @xmath15 positive real variables @xmath16 that represent the amount of loss ( in some currency ) registered in the process @xmath17 at the time @xmath18 and that evolve by means of a discrete time equation of motion .",
    "the variables are coupled through the matrix @xmath19 which in general is not symmetric : @xmath20 means that @xmath21 is influenced by @xmath22 and not vice versa ; the equation of motion is non - local in time in the sense that , if @xmath20 , @xmath16 depends on @xmath23 which are the values that @xmath22 takes in the past @xmath24 time steps ; @xmath24 can thus be thought as an asymmetric time of correlation between the variables @xmath22 and @xmath21 .",
    "the equation of motion is : @xmath25 where the ramp function : @xmath26 ensures that @xmath27 , @xmath28 .",
    "the positive terms in the argument of the ramp function in tend to generate a loss , while the negative terms tend to avoid the occurrence of a loss .",
    "the presence of the ramp function in excludes the possibility of negative losses which could be interpreted as reserves of money put aside to automatically lower future losses .",
    "@xmath29 simply counts the number of @xmath30 greater than zero in the time interval @xmath31 $ ] : @xmath32 \\ , , \\ ] ] where @xmath33 is the heaviside function .",
    ".   implies that @xmath34 and the coupling term in can assume only the values @xmath35 , so that , if @xmath20 , @xmath16 does not depend on the values of @xmath36 , but only on the number of times in which @xmath36 is greater than zero for @xmath37 $ ] .",
    "this means that , if @xmath38 , each loss occurred in the process @xmath39 between the time steps @xmath40 and @xmath41 generates a _ potential _ loss of amount @xmath42 in the process @xmath17 at time @xmath18 ; on the other hand @xmath43 means that a loss in the process @xmath39 may help the process @xmath17 to function properly . such an interaction term implies the following approximation : a potential loss generated by other losses does not depend on their amount , but only on their number within a certain maximum correlation time .",
    "the non - locality in time of is crucial to take into account the different - time correlations , as pointed out in section  [ sec : intro ] .",
    "let us incidentally notice that requires an initial condition consisting of a number of time steps equal to the maximum of @xmath24 .",
    "the inhomogeneous external field @xmath44 has two very different interpretations depending on its sign ; a field term @xmath45 can be interpreted as the effort ( investment ) made by the bank to avoid the occurrence of losses in the process @xmath17 : in fact the sum of the interaction term and @xmath46 has to be greater than @xmath47 to effectively produce a loss . in this scenario the fact that @xmath44 does not depend on time implies that the amount of money ( per unit of time ) to invest on each process is chosen a priori and kept fixed for a long period of time , rather than dynamically adjusted `` on the fly '' .",
    "a field term @xmath48 could be interpreted as a pathological tendency of the process @xmath17 to produce losses at every time step and thus is undesirable in this context .",
    "@xmath46 is a random noise @xmath49-correlated in time that accounts for spontaneously generated losses , i.e.  losses that are not caused by the occurrence of other losses ; this interpretation implies that it must have a positive support .",
    "as discussed in detail in section  [ sec : solutions ] , the analytical results that will be obtained are very general , in the sense that they can be easily extended to different distributions of the noise , provided it satisfies some very general hypotheses . to fix the ideas we choose @xmath46 to have an exponential distribution :    [ eq : noise ] @xmath50 @xmath51 @xmath52    the rationale behind such a choice is the following : as it can be intuitively argued , spontaneous losses ( like those caused by human errors , or machine failures ) are relatively rare events :",
    "such a behavior can be obtained by setting @xmath45 and @xmath53 since the chosen distribution is exponential and the majority ( @xmath54 ) of the _ potential _ losses generated by the noise are smaller than its mean value @xmath55 . because of the presence of noise in @xmath16 is a random variable",
    "; from this point of view we say that the model can be exactly solved if all the moments of the probability distribution of @xmath16 can be calculated .",
    "the crucial quantity for the study of operational risk is the cumulative loss up to the time @xmath18 : @xmath56 which can be taken as an approximated indicator of the capital that should be put aside to face operational risk over a time horizon @xmath18 .",
    "in this section it will be shown that , if the structure of the coupling matrix @xmath19 satisfies some peculiar hypotheses , the model can be exactly solved in the sense specified in section  [ sec : model ] and the asymptotic behaviour of @xmath57 can be determined .",
    "we give some preliminary definitions : a process @xmath17 is said to be _ influenced _ by a process @xmath39",
    "if @xmath20 ; a process @xmath17 is said to be _",
    "free _ if it is not influenced by any process ( including itself ) , i.e.  @xmath58 , @xmath59 .",
    "these definitions are coherent with the mechanism of the interaction term in : in fact a loss occurred in the process @xmath39 may cause a loss in the process @xmath17 only if @xmath20 . the hypothesis on the structure of @xmath19 can be stated in the following way : let us associate to each process a node in a graph and , if the process @xmath17 is influenced by the process @xmath39 , let us draw a directed edge from the node @xmath39 to the node @xmath17 ; the graph obtained considering only the nodes influencing directly or indirectly the node @xmath17 , together with the node @xmath17 itself will be called the subgraph associated to the process @xmath17 ; if the subgraph associated to the process @xmath17 is a directed acyclic graph , i.e.  if the edges in the graph do not form any closed loop ( see @xcite for basic definitions about graphs ) , all the moments of the distribution of @xmath60 can be exactly calculated .",
    "in such a case we say that the subgraph associated to the process @xmath17 _ has no causal loops _ ; the meaning of this definition can be understood considering a graph with a loop like @xmath61 : in such a case the losses occurred in the process @xmath17 may cause other losses in the process @xmath39 , which in turn may cause other losses in the process @xmath17 , resulting in a causal loop .",
    "if the whole graph associated with the coupling matrix @xmath19 is a directed acyclic graph we say that the matrix @xmath19 has no causal loops : in such a case the subgraphs associated to all the processes have no causal loops , and therefore the model can be exactly solved .",
    "we remark that the absence of causal loops is a commonly accepted hypothesis , e.g.  in the context of other tools which are widely used to take into account the correlations among different process , like bayesian networks @xcite .",
    "only the cases relative to the two simplest subgraphs will be treated here , deferring a more general discussion to the appendix .",
    "let us start with a free process @xmath17 , i.e.  the subgraph associated to the process @xmath17 is just a node with no incident edges . in this case",
    "the random variable @xmath16 is independent from @xmath62 , @xmath63 and the @xmath64-th moment of its distribution is simply the average of @xmath65 over the noise , i.e.  the average over the random variable @xmath46 ( we will use @xmath66 as a shorthand for @xmath67 ) : @xmath68^n \\ , \\tilde{d \\xi_i}(t ) \\ , ;      \\end{split}\\ ] ] defining @xmath69^n \\",
    ", \\tilde{d \\xi_i}(t)\\ ] ] we have : @xmath70 where @xmath71 has been used ( and will be used in the following ) as a shorthand for @xmath72 .",
    "the mean of @xmath73 can be analogously calculated : @xmath74 so that the variance of @xmath16 is : @xmath75 as expected for a free process , @xmath60 and @xmath76 do not depend on time , and all the moments of the probability distribution of @xmath16 do not as well ; @xmath57 is thus the sum of @xmath18 independent and identically distributed ( i.i.d .",
    ")  variables with finite variance and , by means of the central limit theorem , for sufficiently large @xmath18 it has a gaussian distribution with mean and variance :    [ eq : zeta_analytical ] @xmath77 @xmath78    the next step is to repeat the calculation of and for the process @xmath17 in the case in which it is influenced only by a single process @xmath39 and the process @xmath39 is a free process ( @xmath79 ) . since in this case @xmath16",
    "depends through @xmath29 only on @xmath23 , the average over the noise equals to the average over the random variables @xmath80 :",
    "@xmath81      \\prod_{1 \\leq s \\leq t_{ij}^ * } \\tilde{d \\xi_j}(t - s ) \\ ; \\tilde{d \\xi_i}(t ) \\ , ; \\ ] ] let us observe that the domain of integration of the variables @xmath82 can be divided in subsets obtained by fixing the value of @xmath29 ; since the events @xmath83 are mutually exclusive and cover the entire domain of integration : @xmath84 each term in the summation on the right hand side of is simply the probability that @xmath85 , i.e.  the probability that @xmath86 elements in the set @xmath87 are greater than zero and @xmath88 elements are less than or equal to zero ; since the process @xmath39 is free , the probability that @xmath89 is easily calculated : @xmath90 & =           \\int_{0}^{\\infty } \\theta \\left [ l_i(t ) \\right ] \\ , \\tilde{d \\xi_i}(t ) \\\\",
    "& = \\int_{0}^{\\infty } \\theta \\left [ \\theta_i + \\xi_i(t ) \\right ] \\ , \\tilde{d \\xi_i}(t )",
    "\\\\      \\end{split}\\ ] ] defining @xmath91 \\ , \\tilde{d \\xi_i}(t)\\ ] ] we have : @xmath92 = p_i^f(\\theta_i ) =          \\begin{cases }              e^{\\lambda_i \\theta_i } & \\text{if } \\;\\ ; \\theta_i < 0 \\\\              1 & \\text{if } \\;\\ ; \\theta_i \\geq 0          \\end{cases }          \\ , , \\ ] ] that yields : @xmath93^c \\left [ 1 - p_j^f(\\theta_j ) \\right]^{t_{ij}^ * - c } \\ , .\\ ] ] using and , becomes : @xmath94 \\",
    ", \\tilde{d \\xi_i}(t ) \\\\          & = \\sum_{c=0}^{t_{ij}^ * }   \\binom{t_{ij}^*}{c } \\left [ p_j^f(\\theta_j ) \\right]^c \\left [ 1 - p_j^f(\\theta_j ) \\right]^{t_{ij}^ * - c } \\ ,           m_i^f(c j_{ij } + \\theta_i ) \\ , .      \\end{split}\\ ] ] the same line of reasoning leading from to can be followed to calculate the variance : @xmath95^c \\left [ 1 - p_j^f(\\theta_j ) \\right]^{t_{ij}^ * - c } \\",
    ", m_i^{(2)f}(c j_{ij } + \\theta_i ) \\right ] - \\langle l_i(t ) \\rangle^2 \\,\\ ] ] or any moment of the distribution of @xmath16 . even in this case",
    "@xmath57 is the sum i.i.d .",
    "variables with finite variance and thus is also valid ; in the appendix it is shown that still holds in the more general case in which the coupling matrix @xmath19 has no causal loops ; as a consequence , the non - locality of the equation of motion alone is not sufficient to modify the shape of the cumulative loss distribution",
    ". actually has a crucial importance : while , at least in principle , it is possible to think at an extension of the technique used here and in the appendix to calculate the moments of @xmath16 also in the case in which the matrix @xmath19 has causal loops , the random variables @xmath16 for different values of @xmath18 would be neither independent nor identically distributed in that case , and would not hold anymore .",
    "determining the moments of @xmath57 by the explicit calculation of the moments of @xmath96 , @xmath97 is also hopeless , since it would become exponentially complex in @xmath18 , as shown in the appendix .",
    "it is worth noting that , and their analogous in the appendix reduce the calculation of the mean and the variance of @xmath16 to the calculation of @xmath71 and @xmath98 and @xmath99 , which are the only quantities that depend on the particular distribution of the noise .",
    "this means that those expressions may be easily generalized to a different distribution of the noise simply by recalculating @xmath71 , @xmath98 and @xmath99 from and , provided that the corresponding integrals converge ; in particular , while @xmath99 is always finite , it can be easily shown that @xmath71 ( @xmath98 ) is finite if and only if the mean ( second central moment ) of the noise is finite . however ,",
    "if @xmath98 diverges , the central limit theorem does not apply and the distribution of @xmath57 at large @xmath18 is not gaussian .",
    "in this section a scheme for estimating the parameters of the model from real data will be presented . in the more general case @xmath100 and @xmath19 can be estimated , but the parameters @xmath101 of the noise must be known a priori . if the graph associated to the matrix @xmath19 is known and has no loops , i.e.  if according to the definition given in section  [ sec : solutions ] the matrix @xmath19 has no causal loops , the model can be integrated and the additional constraint imposed by the exact solution can be exploited to estimate also @xmath101 .",
    "let us remark that knowing the graph associated with @xmath19 does not mean knowing the values of the elements of @xmath19 , but only which elements of @xmath19 are equal to @xmath102 , i.e.  knowing the relationships of influence among the processes .",
    "the matrix @xmath103 of the times of correlation must be known a priori in every case .    in the context of operational risk real data",
    "come in the form of a database of historical operational losses ; such a database is a collection of loss events occurred inside a bank ; in order to be suitable for the estimation scheme that we are describing , the database must keep track of the amount , the process in which and the time at which each loss event occurred .",
    "the time resolution of the database is identified with the discrete time step of the model and the time at which the oldest loss occurred with @xmath104 , so that the database can be thought of as a realization of . since in this section",
    "there is no risk of ambiguity in the notation , the amount of loss registered in the database at the time step @xmath18 in the process @xmath17 will be denoted with @xmath16 .      in order to estimate @xmath44",
    "let us look in the database of operational losses for the events such that @xmath105 , @xmath59 ; assuming that the database is a realization of we have : @xmath106 \\ , ; \\ ] ] the probability that @xmath107 , conditioned on the occurrence on such events is : @xmath108 = \\pr \\left [ \\xi_i \\leq - \\theta_i \\right ] \\ , , \\ ] ] where the dependence of @xmath109 on @xmath18 has been dropped since its distribution does not depend on time .",
    "in order to make a frequentist estimate of the left hand side of one would need a sample of values of @xmath16 , which is obviously not possible using a single database which contains only one value of @xmath21 at the time @xmath18 ; however , since the right hand side of does not depend on time , also the left hand side must not : @xmath110 & = \\pr \\left [ \\xi_i \\leq - \\theta_i \\right ] \\\\          & = \\int_{0}^{-\\theta_i } { \\lambda_i e^{-\\lambda_i \\xi_i } d\\xi_i } \\\\          & = 1 - e^{\\lambda_i \\theta_i } \\",
    ", ,      \\end{split}\\ ] ] where the left hand side has the meaning of a frequentist estimate from the database : @xmath111 = \\frac{\\operatorname{fr}\\left [ ( l_i=0 ) , \\ ; ( c_{ij } = 0 , \\ ; \\forall \\ , j ) \\right]}{\\operatorname{fr}\\left [ c_{ij } = 0 , \\ ; \\forall \\ , j \\right ] } \\ , .\\ ] ] @xmath44 can be estimated inverting : @xmath112 \\right ) \\ , ; \\ ] ] let us explicitly notice from that the values of @xmath44 estimated in such a way are negative .",
    "let us make an example using the excerpt of a possible database shown in tab .",
    "[ tab : data ] ; for simplicity we assume that @xmath113 , @xmath114 and @xmath39 . let us suppose to be interested in estimating the value of @xmath115 ; according to we need to count the events such that @xmath116 , @xmath59 ; the counting starts from the first time step and proceeds using a moving window of width equal to @xmath117 time steps : in this case one starts considering time steps @xmath118 and subsequently moves to @xmath119 , @xmath120 , etc . from tab .",
    "[ tab : data ] and using we see that for the event corresponding to time steps @xmath118 we have @xmath116 , @xmath59 , meaning that @xmath121 $ ] must be incremented by one . to count the events such that @xmath122 _ and _ @xmath116 , @xmath59 one has to consider one more time step : as @xmath123 , also @xmath124 $ ] must be incremented by one .",
    "0.75 cccccc & 1 & 2 & 3 & 4 & 5 + 1 & & & & & + 2 & & & & & + 3 & & & & & + 4 & & & & & + 5 & & & & & + 6 & & & & & +  & & & & & +      the estimation of @xmath42 uses the same line of reasoning followed to estimate @xmath44 from which differs only by the fact that it is based on different kinds of events ; in this case we look for the events such that @xmath125 with @xmath126 and @xmath127 ; for such events reads : @xmath128 \\ , ; \\ ] ] the probability that @xmath107 , conditioned on the occurrence on such events is : @xmath129      = \\pr \\left [ \\xi_i \\leq - \\theta_i - c j_{ij } \\right ] \\ , ; \\ ] ] proceeding like in we find : @xmath130 & = \\pr \\left [ \\xi_i \\leq - \\theta_i - c j_{ij } \\right ] \\\\          & = \\int_{0}^{-\\theta_i - c j_{ij } } { \\lambda_i e^{-\\lambda_i \\xi_i } d\\xi_i } \\\\          & = 1 - e^{\\lambda_i \\left ( \\theta_i + c j_{ij } \\right ) } \\ , ,      \\end{split}\\ ] ] where the left hand side of has again the meaning of a frequentist estimate : @xmath131 = \\frac{\\operatorname{fr}\\left [ ( l_i=0 ) , \\ ; ( c_{ij } = c , \\ , c_{ik } = 0 , \\ ; k \\neq j ) \\right]}{\\operatorname{fr}\\left [ c_{ij } = c , \\ , c_{ik } = 0 , \\ ; k \\neq j \\right]}\\ ] ] and @xmath42 can be estimated inverting : @xmath132 \\right ) \\right ] \\ , .\\ ] ] let us notice that puts a subtle constraint on the parameters that can be estimated : @xmath133 , @xmath134 ; if @xmath45 ( which is the case we are interested in ) this translates into @xmath135 .    in the context of operational risk the constraints imposed by and mean that the bank is exerting a control on the processes so strong that the interactions alone are not sufficient to generate a loss ; in such a scenario a loss occurs when the noise is greater than the threshold set by the negative @xmath44 and the interaction term ( if @xmath38 ) provides a mechanism to dynamically lower this threshold . in the case of a practical implementation , the soundness of these contraints should be certainly checked by experts in the organizational structure of the bank .    also in this case tab .",
    "[ tab : data ] can be used to clarify how the events relative to the estimation of @xmath42 are identified .",
    "let us suppose to be interested in the estimation of @xmath136 ; from we see that we need to count the events such that @xmath137 , @xmath138 , for @xmath139 ; from tab .",
    "[ tab : data ] we see that time steps @xmath119 contribute to the case in which @xmath140 , while time steps @xmath120 contribute to the case in which @xmath141 , meaning that both @xmath142 $ ] and @xmath143 $ ] must be incremented by one .",
    "since @xmath144 , also @xmath145 $ ] is incremented by one , while it is not the case for @xmath146 $ ] , since @xmath147 .      in order to estimate the value of @xmath148 the exact expression of @xmath60",
    "will be exploited ; since it is available only in the case in which the subgraph associated to the process @xmath17 has no loops , the discussion will be restricted to this case . if this is true for all the processes , the whole graph associated with the coupling matrix @xmath19 has no loops and @xmath148 can be estimated @xmath114 .",
    "let us start with the case of a free process @xmath17 ; using , and we have : @xmath149 \\right ) \\",
    ", , \\ ] ] where the case @xmath45 of has been considered since does not allow positive estimates of @xmath44",
    ". in @xmath150 has been replaced by the actual value calculated from the database of operational losses basing on the following argument ; @xmath151 is the sample average of the random variables @xmath16 which are i.i.d .  with finite mean given by ; according to the law of large numbers @xmath152 that , together with , yields @xmath153 ; as discussed at the end of section  [ sec : solutions ] , this argument only applies to all the cases in which the coupling matrix @xmath19 has no loops .    for a process @xmath17",
    "that is influenced only by a single free process @xmath39 , , , and yield : @xmath154 \\right ) \\\\",
    "\\cdot \\binom{t_{ij}^*}{c } \\left ( 1 - \\pr \\left [ l_i=0 \\ , | \\ , c_{ij } = 0 , \\ ; \\forall \\ , j \\right ] \\right)^c \\\\       \\cdot \\left ( \\pr \\left [ l_i=0 \\ , | \\ ,",
    "c_{ij } = 0 , \\ ; \\forall \\ , j \\right ] \\right)^{t_{ij}^ * - \\ , c } \\ , , \\end{gathered}\\ ] ] where again the case @xmath45 from has been considered and @xmath150 has been replaced by @xmath155 . once @xmath148 has been estimated through or and inserted into and , @xmath44 and @xmath42 can be also estimated .    in the more general case",
    "in which the coupling matrix @xmath19 has no loops still applies and and can be extended using , and the results in the appendix . in the most general case",
    "in which the matrix @xmath19 has causal loops , @xmath148 may be elicited in an empirical way by assessing the mean value of a spontaneous loss in the process @xmath17 , or by inverting and assessing the probability that a spontaneous loss occurs in the same process .",
    "in order to check the consistency of the method proposed to estimate the parameters of the model we go after the following steps : i ) we let the system evolve for @xmath156 time steps , ii ) interpret the resulting trajectory ( which will be called original trajectory in the following ) as a database of operational losses and estimate the parameters , iii ) insert the estimated parameters in and sample a great number of trajectories , iv ) compare @xmath157 , the cumulative loss of the original trajectory , with the average of @xmath57 over the sample of trajectories .",
    "since from there may be up to @xmath24 different estimates of @xmath42 one may use the mean of the estimated @xmath42 or sample from them .",
    "there are two reasons to perform the comparison basing on the cumulative losses @xmath57 rather on @xmath16 : first , as already pointed out in section  [ sec : model ] , @xmath57 is the quantity of interest in the context of operational risk ; second , at least in the case in which @xmath19 has no causal loops , @xmath57 has the peculiar property to be self - averaging in time , i.e.  @xmath158 ( see section  [ subsec : learning_lambda ] ) , being perfectly suitable to be compared with its average .",
    "a slightly modified version of the previous strategy allows to test for the forecasting capability of the model as well : it is sufficient to estimate the parameters using only the first @xmath159 ( with @xmath160 ) time steps in the original trajectory , but still sampling trajectories lasting @xmath156 time steps ; in this way we try to reproduce the behavior of @xmath57 in the last @xmath161 time steps ignoring the information contained in the same time steps of the original trajectory . for @xmath162",
    "the test on the forecasting capabilities reduces to the consistency check . in the case in which the matrix @xmath19 is known to have no causal loops",
    "it is not necessary to simulate the trajectories using , but all the quantities of interest such as @xmath163 or @xmath164 may be rather directly calculated by means of the exact solutions .",
    "let us briefly comment on the parameters chosen to generate the original trajectory .",
    "from we see that @xmath44 may be chosen to be the unit of measurement of @xmath21 by properly rescaling @xmath44 , @xmath42 and the noise , so that one can take @xmath165 , the sign being the same of @xmath44 before the rescaling ; we are forced to choose @xmath166 , @xmath114 because does not allow the estimation of positive @xmath44 .",
    "we stress that the number of processes ( @xmath167 in this case ) does not play any significant role ; actually the only relevant element is the complexity of the subgraphs contained into the graph associated with the matrix @xmath19 : for this reason we start from the simplest subgraph ( a free process ) and move on considering progressively more complex ones . in fact , the structure of the matrix @xmath19 is chosen to encompass all the cases explicitly treated in the appendix : free process ( @xmath168 ) , process influenced only by a free process ( @xmath169 ) , process influenced only by a process which is influenced only by a free process ( @xmath170 ) and process influenced by two free processes ( @xmath171 ) .",
    "the graph representing the influences among the processes is shown in fig .",
    "[ fig : graph ] : since it has no loops it is possible to estimate also @xmath101 . in order to satisfy the constraint imposed by we choose : @xmath172 and @xmath173 , for @xmath17 and @xmath39 such that @xmath20 .",
    "the values @xmath148 are chosen basing on the following argument ; the more events suitable for the estimation of @xmath100 and @xmath19 are found , the more the estimated values will be reliable ; the events suitable for the estimation of @xmath100 ( see ) are more likely to be found in a database with a low density of losses , however , if this density becomes too low , there will be no events left to perform the estimation of @xmath19 ( see ) .",
    "we find that a reliable estimation of @xmath100 and @xmath19 is obtained using : @xmath174 and @xmath175 .",
    "the initial condition used is : @xmath176 , for @xmath177 , corresponding to a state in which all processes do not generate losses and thus can be considered perfectly functional .    for @xmath162",
    "the parameters are estimated with the following relative errors : @xmath178 while for @xmath1 : @xmath179    in fig .",
    "[ fig : cumul ] we compare @xmath157 , the cumulative loss of the original trajectory ( solid line ) with @xmath163 , the average over the noise of @xmath57 obtained estimating the parameters from the original trajectory and calculated with , , and , for @xmath162 ( dashed line ) and @xmath1 ( dashed - dotted line ) ; the semi - transparent regions span one standard deviation @xmath180 around @xmath163 and have been calculated by means of , and the analogues of and for the variance .",
    "since both the process @xmath181 and the process @xmath182 are free and their results are qualitatively identical , we only show those relative to the process @xmath181 ; only the last @xmath183 time steps are shown for the sake of readability .",
    "the fact that @xmath157 is reproduced for all the processes with an error which is far less than one standard deviation for @xmath162 proves the consistency of the estimation of the parameters proposed in section  [ sec : learning ] ; the same result for @xmath1 shows that the model exhibits the capability to forecast the cumulative losses in the last quarter of the original trajectory .",
    "moreover , the error regions relative to @xmath162 and @xmath1 overlap almost completely for all the processes : this means that all the relevant information about the parameters of the model is contained in the fraction of the database used for the estimation and that the information contained in the remaining part is redundant .    in fig .",
    "[ fig : dist ] we show @xmath184 ( dashed - dotted line ) and the gaussian distribution of @xmath185 obtained estimating the parameters from the original trajectory , for @xmath162 ( solid dark line ) and @xmath1 ( solid light line ) . fig .",
    "[ fig : dist ] refers to the process @xmath170 since its associated subgraph is the more complex ; the results obtained for the other processes are completely analogous .",
    "we notice that the two distributions overlap almost completely and that their peaks correspond to @xmath184 .",
    "the var over the time horizon @xmath156 and with level of confidence @xmath186 can be easily calculated for a gaussian distribution , being equal to @xmath187 ; in fig .",
    "[ fig : dist ] the vars of the process @xmath188 for @xmath162 ( dashed dark line ) and @xmath1 ( dashed light line ) are shown to be almost identical : their relative error is @xmath189 . in tab .",
    "[ tab : var ] the vars are reported for @xmath162 and @xmath1 , together with their relative error @xmath190 which is @xmath2 for all the processes .",
    "0.75 cccc i & ^f=1 & ^f=0.75 & + 1 & 13 906.79 & 13 886.83 & 1.43 10 ^ -3 + 2 & 3 337.36 & 3 360.42 & 6.88 10 ^ -3 + 3 & 430.68 & 433.29 & 6.05 10 ^ -3 + 4 & 299.79 & 301.61 & 6.03 10 ^ -3 + 5 & 524.13 & 520.70 & 6.56 10 ^ -3 +    as pointed out in section  [ sec : solutions ] , if the variance of the noise is not finite , the distribution of @xmath57 for large @xmath18 is not gaussian ; using the generalized limit theorem @xcite , it is possible to show that the distribution of @xmath57 must be positively skewed and heavy - tailed , in agreement with some empirical results @xcite .",
    "however , the analysis of the model with infinite variance of the noise poses both conceptual and computational problems : since the variance of @xmath16 diverges as well , another reliable measure of the width of the distribution must be found to quantify the goodness of the model predictions ; the relationship between the parameters of the distribution of @xmath16 and the parameters of the cumulative loss distribution @xmath57 is entirely different from and must be found ; the rate of convergence to the non - gaussian limit distributions is much slower and even a purely numerical analysis is much more computationally expensive .",
    "let us now consider an alternative model with a slightly different dynamics : @xmath191 where @xmath192 is drawn from some distribution , which we are leaving unspecified for the moment , and independently from the noise , while @xmath193 this dynamics involves only the variables @xmath194 , while the time dependence in @xmath192 should be intended has a mere label to distinguish different values drawn from the same distribution .",
    "@xmath195 has still the meaning of the loss of the process @xmath17 at the time @xmath18 and , according to , is nonzero if @xmath194 is equal to one , i.e.  if the argument of the heaviside function in is larger than zero , which is the same condition under which @xmath16 in is nonzero .",
    "the dynamics of @xmath194 controls the number of time steps in which the losses occur , while the amount of the losses depends on the distribution of @xmath192 . from this point of view , such a dynamics model can be considered a generalization of the lda , and it makes sense to call frequency the stochastic process associated to @xmath194 and severity the random variable associated to @xmath192 .",
    "models based on a dynamics similar to the one defined by and have been introduced in @xcite .",
    "since frequency and severity are independent , one can imagine to fix the severity distribution so that the dynamics of is equivalent to the one of _ on average _ , in the sense that @xmath16 and @xmath195 have the same distribution ; it can be done by choosing the severity so that : @xmath196 = \\frac{\\pr[l_i(t ) > x]}{\\pr[n_i(t ) = 1 ] } = \\frac{\\pr[l_i(t ) > x]}{\\langle n_i(t ) \\rangle } \\",
    ", , \\ ] ] where the r.h.s .",
    "can be calculated once that all the parameters ( @xmath100 , @xmath19 , and @xmath101 ) are known . as a consequence ,",
    "the dynamics defined by and appears more general than the one defined by , since , at least in principle , it permits to use arbitrary severity distributions , even the ones not satisfying .",
    "however , using an arbitrary severity distribution in general does not allow to employ the procedure described in section  [ subsec : learning_lambda ] to estimate the parameters of the noise .",
    "actually it is possible to show that fixing the mean of the severity so that : @xmath197 is sufficient to estimate @xmath148 . for a free process @xmath17 and for @xmath45",
    "one has that : @xmath198 \\right ) } = \\frac{1}{\\lambda_i } \\ , ,      \\end{split}\\ ] ] where has been used , and the last equalities derive respectively from the self - averaging property of the cumulative loss and from . depends only on the parameters of the noise . ] with a little thought this result can be easily extended to the more general case in which the matrix @xmath19 has no causal loops .",
    "is similar to the one of @xmath60 that has been carried out in section  [ sec : solutions ] and in the appendix .",
    "] nevertheless , there is no solid argument that justifies to impose the constraint on the severity .",
    "in particular , it is not clear why the mean should be the only moment of the severity depending on the parameters of the model ( more specifically of the noise ) .",
    "therefore , it would be desirable to have a coherent model that allows to derive , and thus to estimate the parameters of the noise .",
    "the crucial observation is that the constraint , and consequently the model whose dynamics is defined by , implies the constraint .",
    "hence , the model whose dynamics is defined by has the virtue that it allows to estimate the parameters of the noise in a coherent way , both in the sense that the constraint has not to be imposed `` by hand '' and in the sense that all the terms appearing in the equation of motion have a clear interpretation ( explicitly corresponding to a mechanism for producing or avoiding operational losses , as explained in section  [ sec : model ] ) .",
    "moreover , it is worth to point out that , in the case in which holds , the severity has a much clearer relationship with the parameters of the model ; it is straightforward to show can be calculated observing that @xmath199 = \\int_0^\\infty \\theta[l_i(t ) - x ] d\\tilde{\\xi}_i(t)$ ] . ]",
    "that for a free process @xmath17 and for @xmath45 : @xmath200 i.e.  that the severity has the excess distribution of the noise over the threshold @xmath44 ( with @xmath201 $ ] we denote the distribution of the random variable @xmath202 , evaluated in @xmath203 ) . as regards the more general case in which the matrix @xmath19 has no causal loops , it is still possible to show that a generalized version of holds , where both the numerator and the denominator are replaced by linear combinations whose coefficients depends on the topology of the graph associated to the matrix @xmath19 , similarly to the cases treated in the appendix .",
    "in this paper we proposed a dynamical model to forecast operational losses in banks .",
    "the equation of motion provides two different mechanisms for the generation of losses in a process : the interaction with other processes and the spontaneous generation due to a random noise ; since the different - time correlations play a crucial role in this context , the interactions are non - local in time ; the effort made by the bank to avoid the occurrence of losses is also taken into account by means of an inhomogeneous external field .",
    "we have shown that , if the coupling matrix @xmath19 is known to have no causal loops , all the parameters of the model except the maximum times of correlations @xmath24 can be estimated from real data , so that the model can be tailored on the internal organizational structure of a specific bank ; in the most general case also the parameters of the noise must be known a priori . focusing on the case in which the coupling matrix @xmath19 is known to have no causal loops , we exactly solve the model and find the asymptotic behaviour of the cumulative loss , showing that the non - locality of the equation of motion is not sufficient alone to modify the shape of the cumulative loss distribution .",
    "we specialize the procedure for estimating @xmath100 and @xmath19 suggested in @xcite to the considered model , propose a procedure to estimate the parameters of the noise , and validate it .",
    "many statistical approaches , like the static lda , are founded on the implicit hypothesis that the basic statistical properties of the distributions of operational losses do not change in time ; basing on this assumption the capital charge that the bank has to put aside to face operational risk the _ next _ year is calculated from the loss distribution built from historical data .",
    "the assumption made by the approach proposed here and in @xcite is definitely weaker and consists in assuming that the basic mechanisms underlying the generation of operational losses do not change in time .",
    "the crucial advantage of such an approach is that it allows to make forecasts about future losses .",
    "the forecasting power of the model has been investigated estimating the parameters of the model only from a fraction @xmath0 of a simulated database of operational losses and comparing the cumulative losses of the remaining part with those forecast by the model .",
    "we have shown that the model exhibits surprisingly good capabilities in forecasting the future losses even for @xmath1 : in particular the relative error between the actual var ( @xmath162 ) and the forecast var ( @xmath1 ) is @xmath2 for all the processes . in order to check the performances of the proposed model ,",
    "both the validation of the parameters estimation and the test of the forecasting power has been carried out using simulated data .",
    "we think that the general framework of dynamical models for operational risk deserves further investigation in several directions ; let us just cite few examples : the case in which the coupling matrix has causal loops could be explored , more complex terms of interaction in the equation of motion could be considered or different mechanisms for the generation of losses included ; as explained in section  [ sec : tests ] , the study of the case in which the variance of distribution of the noise is not finite looks particularly promising as it may lead to the emergence of heavy - tailed cumulative loss distributions .    [ [ section ] ]    the results , , and will be extended in two particular cases . in the first case",
    "the process @xmath17 is influenced only by the process @xmath39 , which in turn is influenced only by the process @xmath204 which is free ( @xmath205 ) . in this case",
    "the average over the noise is : @xmath206 the events @xmath83 still cover the entire domain of integration , but are not mutually exclusive : in fact @xmath29 depends through @xmath207 on @xmath208 which in turn have crossed dependences from @xmath209 so that , for example , both @xmath210 and @xmath211 depend on @xmath212 .",
    "however , it is still possible to rewrite in the following way : @xmath213 = c_{s''}\\}_{s '' } } \\prod_{1 \\leq s \\leq t_{ij}^ * } \\tilde{d \\xi_j}(t - s ) \\ ,       \\prod_{2 \\leq r \\leq t_{ij}^ * + t_{jk}^ * } \\tilde{d \\xi_k}(t - r ) = \\\\          = & \\sum_{\\{c\\ } }",
    "m_i^f \\big ( j_{ij } \\sum_{s'=1}^{t_{ij}^*}c_{s ' } + \\theta_i",
    "\\big ) \\\\          & \\cdot \\int_{\\ { \\theta \\left [ l_j(t - s '' ) \\right ] = c_{s''}\\}_{s '' } } \\prod_{1 \\leq s \\leq t_{ij}^ * } \\tilde{d \\xi_j}(t - s ) \\ ,       \\prod_{2 \\leq r",
    "\\leq t_{ij}^ * + t_{jk}^ * } \\tilde{d \\xi_k}(t - r ) \\ , ,      \\end{split}\\ ] ] where the sum over @xmath214 is over all the possible configurations @xmath215 @xmath216 .",
    "once a particular configuration @xmath214 has been assigned , the integral on the right hand side of is simply the probability that @xmath217 = c_{s''}$ ] , for @xmath218 and equals to : @xmath219 + \\theta_j + \\xi_j(t - s '' ) \\right ] = c_{s '' } \\big\\}_{s '' } } \\prod_{1 \\leq s \\leq t_{ij}^ * } \\tilde{d \\xi_j}(t - s ) \\ , \\\\      \\cdot \\prod_{2 \\leq",
    "r \\leq t_{ij}^ * + t_{jk}^ * } \\tilde{d \\xi_k}(t - r ) = \\\\      = \\sum_{\\",
    "{ d \\ } } \\int_{\\big\\ { \\theta \\left [ j_{jk } + \\sum_{r''=s''}^{s''+t_{jk}^ * } d_{r '' } + \\theta_j + \\xi_j(t - s '' ) \\right ] = c_{s '' } \\big\\}_{s '' } } \\ ; \\prod_{1 \\leq s \\leq t_{ij}^ * } \\tilde{d \\xi_j}(t - s ) \\\\      \\cdot \\int_{\\big\\ { \\theta \\left [ l_k(t - r ' ) \\right ] = d_{r ' } \\big\\}_{r ' } } \\prod_{2 \\leq r \\leq t_{ij}^",
    "* + t_{jk}^ * } \\tilde{d \\xi_k}(t - r ) \\ , , \\end{gathered}\\ ] ] where again the sum over @xmath220 is analogous to the sum over @xmath214 and @xmath221 . we notice that integrals on the right hand side of are decoupled and can be respectively rewritten as : @xmath222 = c _ { s } } \\tilde{d \\xi_j}(t - s ) = \\\\      = \\prod_{1",
    "\\leq s \\leq t_{ij}^ * } \\left [ p_j^f \\big(j_{jk } \\sum_{r'=s}^{s+t_{jk}^ * } d_{r ' } + \\theta_j\\big )   \\delta_{c_s,1 } + \\big [ 1 - p_j^f \\big(j_{jk } \\sum_{r'=s}^{s+t_{jk}^ * } d_{r ' } + \\theta_j\\big ) \\big ] \\delta_{c_s,0 } \\right ] \\ , , \\end{gathered}\\ ] ] @xmath223 = d_{r } } \\tilde{d \\xi_k}(t - r ) = \\prod_{2 \\leq r \\leq t_{ij}^ * +   t_{jk}^ * } \\left [ p_j^f \\left ( \\theta_k \\right )   \\delta_{c_r,1 } + \\big [ 1 - p_j^f \\left ( \\theta_k\\right ) \\big ] \\delta_{c_r,0 } \\right ] \\ , .\\ ] ] using , , and one finally obtains : @xmath224 \\delta_{c_s,0 } \\right ] \\\\",
    "\\cdot \\prod_{2 \\leq",
    "r \\leq t_{ij}^ * + t_{jk}^ * } \\left [ p_j^f \\left ( \\theta_k \\right )   \\delta_{c_r,1 } + \\big [ 1 - p_j^f \\left ( \\theta_k\\right ) \\big ] \\delta_{c_r,0 } \\right ] \\ , , \\end{gathered}\\ ] ] while the variance is easily obtained from by replacing @xmath71 with @xmath98 and subtracting @xmath225 .",
    "the value of @xmath148 can again be estimated from , , and , analogously to .",
    "this case can be trivially extended to all the graphs which are simple paths and contain @xmath226 nodes , i.e.  to all the graphs of the type @xmath227 .",
    "we point out that in one has to sum @xmath228 terms ; in the case in which the simplest loop were present in the graph associated with the matrix @xmath19 , i.e.  a loop of the process @xmath17 with itself ( @xmath229 ) , it is easy to argue that the number of terms to sum in order to calculate @xmath60 would be equal to @xmath230 ; in fact , such a topology is equivalent to a simple path containing @xmath18 copies of the process @xmath17 .    in the second case that we will consider the process @xmath17 is influenced only by two processes @xmath231 and @xmath232 that are both free . in this case @xmath16 depends only on @xmath233 through @xmath234 and on @xmath235 through @xmath236 , so that the average over the noise equals to the average over the random variables @xmath237 and and read : @xmath238 \\\\      \\cdot \\prod_{1 \\leq s_1 \\leq t_{ij_1}^ * } \\tilde{d \\xi_{j_1}}(t - s_1 )",
    "\\prod_{1 \\leq s_2 \\leq t_{ij_2}^ * } \\tilde{d \\xi_{j_2}}(t - s_2 ) \\ ; \\tilde{d \\xi_i}(t ) \\",
    ", , \\end{gathered}\\ ] ] @xmath239 where the domain of integration of the variables @xmath240 has been divided in subsets with fixed values of @xmath234 and @xmath236 . inserting and into one obtains : @xmath241^{c_1 } \\left [ 1 - p_{j_1}^f(\\theta_{j_1 } ) \\right]^{t_{ij_1}^ * - \\ , c_1 } \\\\          & \\cdot \\sum_{c_2=0}^{t_{i{j_2}}^ * }   \\binom{t_{i{j_2}}^*}{c_2 } \\left [ p_{j_2}^f(\\theta_{j_2 } ) \\right]^{c_2 } \\left [ 1 - p_{j_2}^f(\\theta_{j_2 } ) \\right]^{t_{ij_2}^ * - \\ , c_2 } \\\\          & \\cdot \\",
    ", m_i^f(c_1 j_{i{j_1 } } + c_2 j_{i{j_2 } } + \\theta_i ) \\ , .",
    "\\end{split}\\ ] ] as in the aforementioned case , the variance is obtained from by replacing @xmath71 with @xmath98 and subtracting @xmath225 .",
    "analogously to , the value of @xmath148 can be estimated from , , and and the constraint @xmath242 emerges .",
    "this case can be also trivially extended to all the graphs in which the process @xmath17 is influenced by an arbitrary number of ( say @xmath226 ) free processes , leading to the general constraint @xmath243 .    in the more general case",
    "in which the graph representing the interactions has no loops both @xmath60 and @xmath76 are sums over all the simple paths starting from a leaf node and ending to the node @xmath17 which can be calculated combining the extensions to the first and second case treated in the appendix .",
    "also in this general case both @xmath60 and @xmath76 do not depend on time and are finite , allowing to extend the results and of section  [ subsec : learning_lambda ] .",
    "m.  b. would like to thank maria valentina carlucci for the countless suggestions and useful discussions ."
  ],
  "abstract_text": [
    "<S> a novel dynamical model for the study of operational risk in banks and suitable for the calculation of the value at risk ( var ) is proposed . </S>",
    "<S> the equation of motion takes into account the interactions among different bank s processes , the spontaneous generation of losses via a noise term and the efforts made by the bank to avoid their occurrence . </S>",
    "<S> since the model is very general , it can be tailored on the internal organizational structure of a specific bank by estimating some of its parameters from historical operational losses . </S>",
    "<S> the model is exactly solved in the case in which there are no causal loops in the matrix of couplings and it is shown how the solution can be exploited to estimate also the parameters of the noise . </S>",
    "<S> the forecasting power of the model is investigated by using a fraction @xmath0 of simulated data to estimate the parameters , showing that for @xmath1 the var can be forecast with an error @xmath2 .    operational risk , dynamical systems , value at risk , capital allocation    89.65.gh , 02.50.-r </S>"
  ]
}