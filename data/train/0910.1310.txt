{
  "article_text": [
    "the space density of peaks in a cosmological density field smoothed with a filter is sensitive to the shape of the linear power spectrum of mass fluctuations , even for filter sizes where the fluctuations are in the non - linear regime ( croft & gaztaaga 1998 ) . in de & croft ( 2007 ) ,",
    "hereafter paper i we explored the sensitivity of the peak density to parameters related to the initial power spectrum , as well as redshift distortions and variations in the galaxy halo occupation distribution ( e.g. , berlind & weinberg 2002 ) . the theory of peaks in a gaussian density field was set out in detail by bardeen ( 1986 , hereafter bbks ) .",
    "the relationship between the peak density and power spectrum in bbks can be used to explore such parameters as the spectral index and its dependence on scale ( kosowsky and turner , 1991 ) along with the neutrino mass . in this paper",
    "we use data from the 2df galaxy redshift survey ( hereafter 2dfgrs , colless 2001 ) , to constrain cosmological parameters using the peak density .    in a recent analysis of the 2dfgrs final data set cole ( 2005 ) employed a direct fourier method to compute the power spectrum .",
    "these authors put constraints on several parameters using the directly measured power spectrum shape .",
    "they assumed a primordial form for p(k ) with @xmath11 and @xmath12 along with a negligible neutrino mass .",
    "this gave preferred values of @xmath13 and a baryon fraction of @xmath14 ( 1@xmath15 errors ) .",
    "this analysis therefore implies a significantly lower mass density compared to the @xmath16 often taken as standard . in combination with cmb data from wmap ( spergel 2003 ) cole",
    "find @xmath17 also on large scales some evidence was seen by cole of the baryon oscillations predicted by cdm models .",
    "our present work is complimentary to this large scale linear theory analysis , with the peak density enabling constraints to be placed on the linear power spectrum and cosmological parameters from data on smaller scales .",
    "this paper is the second in a series . in paper",
    "i , we examined the number density of peaks in cosmological simulations and compared to results from linear peak theory ( bardeen 1986 , hereafter bbks ) over a range of density field smoothing filter scales .",
    "this provided knowledge of the length scales for which agreement between theory and simulation can be expected .",
    "the dark matter simulations used to compare to peak theory showed good agreement for filter scales between 3 - 30@xmath18 .",
    "this was assuming that the mean interparticle separation was smaller than the filter scale ( for agreement at better than the @xmath19 level ) .",
    "in addition to simple tests using simulations , we created galaxy catalogues using lists of dark matter halos and the halo occupation distribution formalism ( zheng 2005 . )",
    "good correspondance was found between the peak density measured from the galaxies and dark matter for filter scales @xmath20 .",
    "the peak density can be used to constrain cosmology through its dependence on the power spectrum of mass fluctuations , @xmath21 .",
    "in particular we work with the asymptotic number density of maxima , i.e. the number density of peaks of all heights and which is found by bbks to be : @xmath22 where @xmath23 is defined to be the following ratio of moments of the power spectrum : @xmath24 here @xmath25 the scale dependence of @xmath21 is probed by smoothing the density field with gaussian filter with comoving radius @xmath26 , i.e. multiplying @xmath21 by @xmath27 .",
    "croft & gaztaaga ( 1998 ) found that there is an simple relationship that holds to high accuracy between the local slope of the power spectrum @xmath1 at wavenumber @xmath2 and the filter scale @xmath28 .",
    "the peak number density is therefore sensitive to the power spectrum slope ( but not its amplitude ) and the parameters which govern it can be tested .",
    "paper i focussed on several such aspects of the power spectrum such as the neutrino mass , the possible rolling of the spectral index @xmath1 , and redshift distortions .",
    "it was seen that upon increasing the neutrino mass the peak density decreases , as it does when the rolling of the spectral index is made more negative .",
    "the effect of redshift distortions was also quantified , showing that they act to suppress the number density of peaks on small scales .",
    "this information is useful for the present paper which deals with the peak density in redshift space measured from an observed galaxy catalogue .",
    "our approach in this paper is to first test our recovery of the true peak density using mock catalogues derived from simulations that have had the 2df masks and selection function applied to them .",
    "we then apply the same estimation techniques to the 2df data , using the recovery from mock data to estimate the reliability of the method .",
    "the 2df peak density as a function of filter scale is then used to constrain cosmological parameters .",
    "the plan for the paper is as follows : in section 2 we describe the simulated observations ( mock catalogues ) , including the detailed reasoning behind their use .",
    "we give an overview of the 2dfgrs and in appendix a describe how the mock catalogues were generated .",
    "the latter includes a description of the selection function , magnitude limits and geometrical limitations of the survey and how they were applied to n - body simulations to produce mock catalogues . in section 3",
    "we detail tests of the process of finding peaks in the simulations and mock catalogues , including selection of the volume limits for a given filter size and how we deal with incomplete sky coverage . in section 4",
    "we describe the calculation of the observed peak density from the 2df survey data using the completeness functions calibrated from mock catalogues .",
    "we also describe various sources of uncertainty , and how they propagate into our evaluation of cosmological parameters . in section 5",
    "we present the best fit values of @xmath3 , @xmath1 and d@xmath1/dln@xmath2 including error estimates , using markov chain monte carlo analysis . in section 5",
    "we conclude and discuss possible future work .",
    "the main aim of this paper is the extraction of accurate information about particular cosmological parameters , the neutrino mass , slope of the power spectrum and variation of spectral index with scale ( rolling . ) we can make good estimates of these quantities if we marginalize over parameters whose values are already well known .",
    "this involves use of present day knowledge regarding certain other parameters such as the density of matter , cosmological constant , and baryon density , @xmath29,@xmath30 , @xmath31 .",
    "we work with the space density of peaks in the smoothed galaxy density field . to recover the actual space density of peaks we need to address the issues related to the limitations and particular nature of the galaxy survey . in the 2df",
    "survey data , limitations arise for several reasons .",
    "for example certain galaxies may not make it into the survey because they are faint , but the magnitude limit varies over the survey s angular extent .",
    "very bright objects affect the detection of those nearby , and so there are exclusion holes in the survey .",
    "the survey geometry also has a complicated nature , making it different from the uniform contiguous volume best suited for finding and quantifying peaks .    to be able to estimate the space density of peaks in the universe from the observations it is therefore important to be able to compute a completeness function for each sub volume of the survey region .",
    "we do this by computing the ratio of the number of peaks in simulations with full sampling and no boundary effects to the peak density estimated from mock catalogues covering the same simulation volume .",
    "the mock catalogues are simulated observations ( simulations combined with all the relevant observational constraints ) .",
    "when using the mock catalogues , we make the assumption that the completeness function which we generate using them can be applied to the real universe .",
    "this means that we assume that the simulations which are the basis of the mock catalogues are a close enough approximation to the statistical distribution of matter in the real universe that the completeness is valid .",
    "we show in section 3.1 that in practice this is not an important restriction as the completeness is in fact unity ( i.e. no peaks are missed ) for most of the survey volume we actually use . in appendix",
    "a we describe how we generate the mock catalogues . as they are created to have the same geometry and limitations as the 2dfgrs we first describe the observational dataset .",
    "the 2dfgrs ( colless 2001 ) resulted in one of the largest catalogues of galaxy redshifts made so far , following a major spectroscopic survey which took advantage of the unique capabilities of the 2df facility at the anglo - australian observatory . the 2dfgrs obtained spectra for 245591 objects , mainly galaxies , brighter than a nominal extinction - corrected magnitude limit of @xmath32 .",
    "reliable ( 2df quality flag @xmath33 ) redshifts were obtained for 221414 galaxies .",
    "the galaxies cover an area of approximately 1500 square degrees selected from an extended version of the apm galaxy survey ( maddox 1996 ) in three regions : an ngp strip , an sgp strip and random fields scattered around the sgp strip . in figure [ 2df ] we show a projection of the galaxy distribution in the 2dfgrs in the equatorial plane as well as the positions of peaks found after smoothing the density field with a gaussian filter of radius @xmath34 .",
    "( the peak finding will be described later ) .",
    "different masks are used when interpreting the 2df data to characterize the completeness of the survey in various ways as a function of position on sky .",
    "the magnitude limit mask gives the extinction - corrected magnitude limit of the survey at each position on sky .",
    "the redshift completeness mask quantifies the fraction of galaxies above the magnitude limit with measured redshifts .",
    "we use the recommended method ( colless 2001 ) to define this latter mask , it being specified by the complete set of 2 degree fields that were used to tile the survey region for spectroscopic observations . each point on the sky inside the survey boundary",
    "is covered by at least one 2 degree field , but more often by several overlapping fields .",
    "a sector is defined as the region delimited by a unique set of overlapping 2 degree fields .",
    "this is the most natural way of partitioning the sky , as it takes into account the geometry imposed by the pattern of 2 degree fields and the way in which the galaxies were targeted for spectroscopic observations . within each sector with position angle @xmath35 , the redshift completeness @xmath36 , is the ratio of the number of galaxies for which redshifts have been obtained , @xmath37 , to the total number of objects contained in the parent catalogues , @xmath38 so that @xmath39 .",
    "we note that when analyzing the data , the redshift completeness of a given sector , @xmath36 , should be clearly distinguished from the redshift completeness of a given field denoted , by @xmath40 , since multiple overlapping fields can contribute to a single sector .",
    "the @xmath41-mask gives the dependence of the redshift completeness on apparent magnitude .",
    "we describe the @xmath41-mask in more detail in the appendix a. we use these masks ( i.e. values of completeness for different patches of sky ) along with the incorporation of redshift limits , magnitude limits and a completeness cut - off to make our mock catalogues from simulations ( see appendix a ) .",
    "in order to get a feel for how well peaks that are seen in the fully sampled dark matter density field can be recovered in the mock galaxy catalogues , we carry out a one to one comparison . to find peaks operationally ,",
    "we first assign the galaxy ( or particle ) positions to a grid , which is then smoothed with a gaussian filter .",
    "peaks are then associated with local maxima in this smoothed density field ( grid cells which have a higher density than the surrounding 26 cells ) .",
    "the first step towards comparing peak locations in mocks and the fully sampled dark matter density field is to ensure that the same piece of the simulation is used in both the mock catalogues and the fully sampled case .",
    "as mentioned before , our simulations have a box size of @xmath42 mpc and we replicate this box , making use of the periodic boundaries to get the desired survey volume for the mock catalogues .",
    "we apply the 2df mask and selection function , resulting in a volume that matches the shape of the 2df redshift survey .    when finding peaks from the mock catalogues it is important to assign weights to the galaxies , the appropriate ones being related to the inverse of the selection function . in order to find the weights , we generate _ random catalogues _ ,",
    "in which points are initially randomly distributed .",
    "we apply the 2df survey mask and selection function to these points , in the same way as with the mock galaxy catalogues .",
    "we then place a grid on top of this distribution of points and count the number of points in each grid cell .",
    "the ratio of the number of points in the grid cell to the expected number for a uniform distribution gives the inverse of the appropriate weight to use for that cell . in this way",
    ", we compute a weight for each cell on the grid . in order to make sure the weights have an acceptably low contribution from poisson noise",
    "we make the number of points in the random catalogues twenty times that in the mock galaxy catalogues .",
    "we place the same three - dimensional grid ( of size @xmath43 cells ) onto the distribution of galaxies in the mock catalogues .",
    "the box size was set equal to the distance @xmath44 as described earlier .",
    "we assign the weighted galaxy density to the grid and smooth this field in fourier space with a gaussian filter .",
    "we carry this out for several different smoothing filter radii , @xmath45 , each time locating the local maxima in the field .    for our one - to - one comparison ,",
    "we compare directly the positions of peaks found from the mock catalogues and from the fully sampled simulations . because of shot noise , we do nt expect peaks in the mocks to be found in exactly the same places . in figure [ matching_sim_mock ] , we plot projections of the ngp and sgp regions for one of the mock catalogues , with symbols showing where the peaks were found and other symbols showing where the true peaks lie ( measured from the full simulation . )",
    "we can see there that the distrbutions of points are similar in general , but that there are differences , particularily at the far edges of the survey .",
    "we quantify this in figure [ random_match ] where we show the fraction of peaks in the mock catalogues which have a true peak within one filter radius .",
    "we can see that good peak detections , defined in this way occur approximately 50% of the time , roughly independent of the filter size . in the same plot we have carried out this comparison with peaks found from the random catalogues , to show",
    "how likely it is that false peaks arise from poisson fluctuations .",
    "we can see that this is @xmath46 times less likely , showing that we are truly extracting peak information from the mock catalogues .",
    "the one - to - one test carried out in this section is meant to be illustrative of how well peaks can be identified in galaxy catalogues .",
    "the information presented in figures [ matching_sim_mock ] and [ random_match ] is not used in our measurement of the peak density from observations .",
    "the completeness corrections used for this purpose are described in the next section .      in order to compare an observed peak density with theoretical models , we need to statistically correct for the effects of shot noise and of survey boundaries .",
    "our one - to - one comparison above does not show the aggregate effect on the peak density of these effects , but only that approximately 50% of peaks are found within 1 filter radius of their true locations .",
    "if we make the assumption that the 2df observations are affected in the same way by boundaries and shot noise as our mock catalogues , we can use our mock catalogues to compute an effective completeness ( which varies spatially ) .",
    "this will enable us to translate an observed peak density into the density we would have measured with fully information and denser sampling .",
    "our calculations of the effective completeness involve first locating the local maxima in the simulation with full sampling and in the mock catalogues , as described above . by examining the peak density as a function of distance from the edge to the survey we have found that boundaries do have a substantial effect ( for example , in figure [ 2df ]",
    "it can be seen that peaks occur preferentially at the edges ) . rather than applying a large correction for this effect , we decide to not consider the peaks in the volume near the boundaries .",
    "we choose to remove from our number density computation all peaks and volume closer to the side edges of each bin within @xmath47 in azimuthal distance and @xmath48 in declination distance on each side .",
    "our approach is to only include regions of the simulation for which the completeness correction is of order unity ( see below . )",
    "we compare the number of peaks from fully sampled simulations and mock catalogues to yield the completeness . to do this we divide space into radial bins ( distance measured from the origin ) of width @xmath49 for filter radii less than @xmath50 mpc and of width of @xmath51 for larger filter radii .",
    "for each radial bin @xmath52 , a completeness @xmath53 given by @xmath54 @xmath55 and @xmath56 are respectively the number of peaks in the @xmath57 bin measured from the simulation and the mock catalogues .",
    "the completeness correction for a particular filter size , @xmath45 ( denoted by @xmath58 ) is found by averaging over completeness values obtained from 20 mock catalogues . from an observed number of peaks , the corrected number of peaks in the @xmath57 bin",
    ", @xmath59 can therefore be computed from @xmath60 where @xmath61 is observed number of peaks in the @xmath57 radial bin for the same filter radius .    for most of the mock survey volume , the completeness we which we compute in this way is @xmath62 , indicating that we are statistically finding all peaks , with no need for any correction .",
    "the completeness correction therefore has a small effect , and there is no significant difference in our results if we do not include it .",
    "the completeness correction does however enable us to include a larger volume of the survey than without it , resulting in smaller error bars .",
    "the completeness correction @xmath58 rises above 1.0 for large distances from the origin , as the number density of galaxies goes down .",
    "for example , with a filter scale @xmath63 between a radial distance of 300 @xmath18 ( where @xmath64 ) and the edge of the survey volume used ( at @xmath65 ) @xmath58 averages approximately @xmath66 .    in figure [ mock_sgp_ngp ]",
    "we have plotted peak densities for different @xmath45 values for both ngp and sgp mock catalogues .",
    "we have also shown with lines the average for mock catalogues .",
    "the averaged corrected peak densities ( multiplied by @xmath67 ) are shown for both the ngp and sgp mocks .",
    "we find that for all @xmath45 values they agree very well with the peak densities from the fully sampled simulations .    in figure [ number_counts ]",
    "we have shown the number of galaxies in 30 radial bins for @xmath68 mpc .",
    "we have already seen that in the very nearby universe it was necessary to superimpose two mock catalogues in order to achieve the required number density .",
    "we use equation [ correct ] to calculate the peak density in the observed universe from the 2dfgrs data . to compute the correction factors , we use 20 mock catalogues which have a comparable number density of objects to that in the survey .",
    "these mocks are used to calculate the error bar on each data point corresponding to each @xmath45 . in figure",
    "[ obs_peaks ] we show the peak densities for the sgp and ngp .",
    "we also indicate the best - fit theoretical curve which corresponds to a model with @xmath69 , @xmath70 , @xmath71 ev ( total mass of three massive neutrino species in ev ) .",
    "we descibe how the model fitting was done in section 5 below .    in figure [ weight_obs ]",
    "we show the weighted average of the peak density measured from the sgp and ngp . for illustrative purposes",
    ", we also show the peak densities predicted by various models .",
    "the observational weighted average of ngp and sgp data was calculated using : @xmath72 where @xmath73 and @xmath74 are respectively the number density of peaks in the sgp region of the survey and the fractional error on that value .",
    ".[pktab ] the space density of peaks measured from the 2df redshift survey data , as a function of filter scale @xmath45 [ cols=\"^,^,^ \" , ]     in figure [ mcmc1d ] we show the 1 dimensional marginalized probability distributions for the 3 parameters @xmath1 , @xmath75 , @xmath3 .",
    "the width of the likelihood distributions for @xmath1 , @xmath76 are large , indicating that the peak density constrainty will not be competitive with other measures of these parameters .",
    "the @xmath3 probability distributions are relatively narrow , however .",
    "the best fit values of the parameters in the marginalized distributions and their range of uncertainty are give in table [ params ] .",
    "we can see that @xmath1 is consistent within the large 1 @xmath15 error bars with the wmap5 results ( dunkley 2009 ) , @xmath77 .",
    "the 2 @xmath15 upper limit on the total mass of 3 neutrino species , @xmath3 is 2.48 ev .",
    "this is in the same range as upper limits from a variety of other cosmological probes ( see elgaroy 2007 for a recent review . )",
    "by measuring the space density of peaks in the smoothed 2df galaxy survey density field as a function of filter scale , we have constrained the values of the cosmological power spectrum parameters d@xmath1/dln@xmath2 , @xmath1 and @xmath78 .",
    "we find values that are consistent within 1 @xmath15 of those measured from other cosmological observables ( e.g. , dunkley 2009 , seljak 2005 ) , and are in support of the standard @xmath79cdm scenario . in linear theory ,",
    "the peak density is not affected by the amplitude of fluctuations . as simulation tests have shown",
    "that this is also true in the non - linear regime , for filter scales as small as @xmath80 , this means that our constraints on cosmological parameters come entirely from the shape of the power spectrum . because of degeneracies in the shape of the power specrum with cosmological parameters it was necessary to assume prior values for some parameters ( @xmath81 and @xmath82 ) from the wmap ( spergel 2003 ) results in order to derive our own limits .",
    "various sources of systematic errors are possible , when measuring peak statisics , for example those related to the fact that the peak density in a smoothed field is sensitive to boundary effects , which are difficult to correct for ( unlike the case of the correlation function , for example . ) in the present work , we have made conservative cuts , ignoring space close to the survey boundaries and validated these using mock catalogs to test both the overall recovery of the peak density and the recovery of individual peaks .",
    "an additional source of error comes from the fact that redshift distortions tend to merge peaks together which are separate in real space , as was seen in paper i. we have dealt with this effect , by including a power spectrum suppression term due to the small scale random velocity dispersion ( see paper i for details and tests ) .",
    "this is the one part of the analysis for which peak finding may be most sensitive to the relationship between mass and light .",
    "our tests using the halo occupation distribution in paper i have show that this is unlikely to be a problem at the level of current observational uncertainties .",
    "our constraints have come from an analysis of filter lengthscales between @xmath83 .",
    "this approach is therefore complementary to much work in large scale structure which has been done by analyzing the galaxy power spectrum on somewhat larger length scales ( wavenumber @xmath84 , corresponding to wavelengths @xmath85 ) . on these larger scales ,",
    "galaxy fluctuations are assumed to be linearly related to mass , and direct measurements of the galaxy power spectrum are used to constrain the mass power spectrum and hence cosmological parameters ( e.g. , tegmark 2004 ) .",
    "recently , it was shown by sanchez & cole ( 2007 ) that shapes of the power spectra measured from the 2df and sdss galaxy surveys ( e.g. , cole 2005 , tegmark 2004 ) are not in agreement , due to the @xmath86-band selected sdss galaxies having a stronger scale - dependent bias .",
    "this results in differences in the cosmological parameters inferred from the two surveys which are larger than the quoted measurement uncertainties . from the tests in cg97 and paper i",
    ", we expect that our peak based measurement to be more robust both to differences in galaxy bias and non - linear evolution . in the future it will be useful to compute the peak number density from the sdss survey data , in order to check consistency",
    ". the larger size of the sdss final dataset will enable the use of larger filter scales and reduce the error bars on parameters .",
    "sd was supported in part by nsf grant ast-0707704 and department of energy award number de - fg02 - 07er41517 .",
    "we thank the referee for useful comments which improved the paper .",
    "bardeen j. , bond j.r .",
    ", kaiser n. , szalay a.s . , 1986 , , 304 , 15    berlind , a. , & weinberg , d.h .",
    ", 2002 , , 575 , 587    bond j.r .",
    ", efstathiou g. , 1984 , , 285 , l45-l48    cole et al . , 2005 , mnras , 362 , 505c    colless et al .",
    ", 2001 , mnras , 328 , 1039c    croft r.a.c .",
    ", gaztaaga e. , 1998 , , 495 , 554c    croft r.a .",
    "c. , weinberg d.h . ,",
    "bolte m. , burles s. , hernquist l. , katz n. , kirkman d. , tytler d. , 2002 , , 581 , 20c    de , s. and croft r.a.c . , mnras , 2007 , 382 , 1591    dunkley , j. el al . , 2009 ,",
    "apjs , 180,306    eisenstein d.j . , hu w. , 1999 , , 511 , 5    elgaroy , o. , 2007 , nuclear physics b , 168 , 51    erdodu et al . , 2004 , mnras , 352 , 939    kosowsky a. , turner m. , 1995 , phrvd , 52 , 1739    maddox , s. j. , efstathiou , g. & sutherland , w. j. , , 1996 , 283 , 1227    matsubara t. , szalay a.s . , pope a.c . , 2004 , , 606 , 1    norberg et al .",
    ", 2001 , mnras , 328 , 64    peacock et al . , 2001 , nature , 410 , 169    sanchez , a. g. , & cole , s. , 2007 , submitted , arxiv:0708.1517    schechter , p. , 1976",
    ", , 203 , 297    seljak , u. , et al . , 2005 , phys .",
    "d , 71 , 103515    2005 , , 203 , 297    spergel , d. , et al . , 2003 , , 148 , 175s    tegmark , m. , et al .",
    ", 2004 , phys rev d. , 69 , 3501    verde et al . , 2003 , , 148 , 195v    zheng et al . , 2005 , , 633 , 791z",
    "in order to incorporate observational constraints into a simulation we need to first compute the the selection function .",
    "we choose our luminosity function to have the form of a schechter ( 1976 ) function ( following erdodu 2004 ) and define      where @xmath88 is the radial selection function at a distance @xmath86 which is obtained by integrating over the luminosity function @xmath89 .",
    "@xmath90 is the minimum luminosity which could be observed at a distance @xmath86 .",
    "@xmath91 is the lowest measured luminosity in the survey , which is taken as the luminosity @xmath90 at the comoving distance @xmath86 of @xmath92 mpc , equivalent to a lower redshift cutoff for the data sample we use .    to choose magnitudes for the galaxies in our mock catalogues",
    ", we numerically solve equation @xmath93 for @xmath94 using a random value of the selection function between 0 to 1 . using this value of the luminosity we estimate the apparent magnitude at point ( @xmath86,@xmath95,@xmath96 ) , @xmath95 being the azimuthal angle , @xmath96 being the declination and @xmath86 being the comoving radial distance .",
    "there is a dependence on angular coordinates that comes from the fact that @xmath91 is estimated as the minimum luminosity at a fixed radial distance but its value varies with @xmath95 and @xmath96 .",
    "once we have found the minimum luminosity at @xmath86 from the last integral equation , we use following equation to compute the apparent magnitude ( @xmath97 ) :      where @xmath99 is the luminosity distance , @xmath100 is the redshift , and @xmath101 , equivalent to the absolute @xmath102 limit .",
    "the extra factor of @xmath103 is due to the inclusion of the @xmath2 correction .",
    "the mock catalogues are made by applying the mask and luminosity function mentioned above to the outputs of n - body simulations . to generate the simulation we use the same cosmology as described in paper i , an lcdm running spectral model with spectral index @xmath11 , @xmath104 , @xmath16 , @xmath105 , and without massive neutrinos .",
    "we use the transfer function described in eisenstein and hu ( 1999 ) .",
    "these simulations are identical to those used in paper i with respect to box size ( @xmath106 ) , mass fluctuation amplitude , and other relevant parameters ( particle number @xmath107 ) .    in paper",
    "i , we tested the effect on the space density of peaks of using a galaxy halo occupation distribution ( hod , e.g. , berlind & weinberg 2002 ) to create the galaxy density field rather than particles .",
    "we found no measurable difference for filter scales @xmath108 and therefore in the present paper , in the interests of having the maximal space density of objects , we use particles as proxies for galaxies in our mock catalogues .    in order to produce mock catalogues ,",
    "we first apply the geometrical constraints ( angular coverage ) of the survey to our simulations .",
    "there are galaxies in the 2df survey at redshifts as deep as @xmath109 . to cover the whole of this observed volume it is necessary to replicate the particle distribution of the simulation ( box size of @xmath110 mpc ) so that it can cover a sphere of radius @xmath111 mpc .",
    "to do this , we translate all particles in the same direction with a comoving distance equal to the box size ( the simulations have periodic boundary conditions ) , repeating this in three mutually orthogonal directions to yield enough volume to inscribe the sphere in it .",
    "we note that although the box has been replicated several times , the actual volume of a single box is similar to that of the survey , because of the wedge like geometry of the survey .",
    "having carried out this replication , we compute the comoving distance from the observer for our lcdm cosmology , and compute the redshifts of all the particles , including the effect of peculiar velocities .",
    "after we select the simulation particles which have the same angular coverage as in the real survey , we reject those which have a sector completeness , @xmath40 less than @xmath112 .",
    "we assign random values to the selection function to calculate @xmath94 as described above .",
    "this equation is then solved to obtain apparent magnitudes for each galaxy .",
    "we apply magnitude limits ( described below ) to exclude faint objects from the mock catalogues .",
    "one important point to note is that in the survey there is also a bright magnitude limit .",
    "it is necessary to ignore very bright galaxies as they can affect observations of neighboring galaxies .",
    "the presence of holes in the angular mask to exclude them also results in holes in our mock catalogues .",
    "our chosen values for the bright and faint magnitude limits are @xmath113 and @xmath114 respectively .",
    "galaxies falling outside this range are ignored . using the computed apparent magnitude we calculate the magnitude dependent incompleteness @xmath115 , which is given by      where @xmath117 and @xmath41 ( different for each mask cell ) are parameters which were set by colless ( 2001 ) by comparing to a simple power law model for galaxy number counts ( see equations @xmath118 of colless 2001 . )",
    "these values of @xmath41 were obtained from masks made publically available by the 2dfgrs collaboration for each mock galaxy we compare this completeness to a randomly generated number between 0 and 1 , rejecting galaxies when the number is greater than the completeness .",
    "after this , the final mock catalogue is output . to be able to average over random fluctuations we make many catalogues from 5 simulations generated with different random seeds as well as by randomizing the observer positions in the simulations .",
    "we use 4 different observer positions per simulation , making 20 different mock catalogues .",
    "one problem we encounter when making the mocks is that for small distances from the observer the number density of particles in the simulations is less than the number density of galaxies in the survey . for this region , we clone particles to make up the difference .",
    "our results are insensitive to whether this is done , as we restrict our analysis to smoothing filter radii much larger than the particle mean separation at this distance .",
    "we describe this procedure in more detail below .      before determining the peak density from the catalogues",
    "it is necessary to choose the region which can be analysed for each given filter size .",
    "this is because the space density of galaxies decreases with distance from the origin .",
    "if the space density of galaxies is too low for a given filter size , the smoothed density field from the catalogue will not give a correct representation of the smoothed underlying density field .",
    "in paper i , it was shown that the smoothing filter scale should be greater than the mean separation between galaxies to avoid serious underestimation of the peak density .",
    "additionally , we have a finite sized ( @xmath43 cells ) grid which we use to locate peaks ( local maxima on the grid ) .",
    "we make sure at all times that the grid cell size is also less than the mean separation between galaxies , in order to avoid missing peaks . if _",
    "w _ is the cell width and @xmath119 is the mean intergalaxy distance , then we ensure that @xmath120 .",
    "we have checked to see that this criterion is sufficient , and our results are not sensitive to this exact choice .    for a given value of @xmath121",
    ", we construct a volume limited catalogue , and compute the mean separation between galaxies . in figure [ mean_sep ]",
    "we show the dependence of this average inter - galaxy separation @xmath119 ( @xmath122^{\\frac{1}{3}}$ ] , where _ v _ is the volume in a radial bin centered on @xmath44 and @xmath123 is the number of galaxies ) with distance from the origin @xmath44 in both mock catalogues and the actual 2df survey .",
    "as mentioned above , for each filter radius @xmath45 we can safely increase @xmath44 to the maximum value where @xmath124 . in order to determine this value , we averaged over the mock catalogues and fitted a fourth order polynomial in @xmath125 to yield a fitting function for the radial distance,@xmath126 ."
  ],
  "abstract_text": [
    "<S> we use the number density of peaks in the smoothed cosmological density field taken from the 2df galaxy redshift survey to constrain parameters related to the power spectrum of mass fluctuations , @xmath0 ( the spectral index ) , d@xmath1/dln@xmath2 ( rolling in the spectral index ) , and the neutrino mass , @xmath3 . in a companion paper </S>",
    "<S> we use n - body simulations to study how the peak density responds to changes in the power spectrum , the presence of redshift distortions and the relationship between galaxies and dark matter halos . in the present paper </S>",
    "<S> we make measurements of the peak density from 2df galaxy redshift survey data , for a range of smoothing filter scales from @xmath4 . </S>",
    "<S> we use these measurements to constrain the cosmological parameters , finding @xmath5 , @xmath6ev , @xmath7n@xmath8k@xmath9 , at the 68 % confidence level , where @xmath3 is the total mass of three massive neutrinos . at 95% confidence </S>",
    "<S> we find @xmath10 ev . </S>",
    "<S> these measurements represent an alternative way to constrain cosmological parameters to the usual direct fits to the galaxy power spectrum , and are expected to be relatively insensitive to non - linear clustering evolution and galaxy biasing .    </S>",
    "<S> [ firstpage ] </S>"
  ]
}