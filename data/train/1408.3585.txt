{
  "article_text": [
    "the systematic detection and parameterization of sources of interest in astronomical images is central to a vast array of different scientific goals .",
    "these can range from exploring the nature of galaxy formation using high resolution imaging of clumpy , extended gas resevoirs ( e.g. @xcite ) , to surveys such as boss ( e.g. @xcite ) , that seek to characterise barycentric acoustic oscillations ( the imprint of acoustic waves that propogated pre - recombination on the large scale structure of the universe ) .",
    "a common tool in source finding is the serch algorithm described in @xcite . in brief",
    ", a gaussian kernal of specified width is used to perform a weighted average over a set of channels , after which detections over some signal to noise ( s : n ) threshold will be accepted as candidate objects .",
    "different kernal widths can then be iterated over such that the maximum s : n can be obtained for each candidate .",
    "ultimately however this approach relys on the user to determine via visual inspection whether or not to consider a candidate real , or simply a fluctuation in the noise .",
    "this is a problem made all the worse given any real image will likely contain artifacts and spikes in the noise that will sum coherently with the signal using such an approach , making manual post processing a necessity .",
    "more recently the duchamp algorithm @xcite was introduced that does not impose any spectral or spatial model for the source during the search and so returns only the locations of candidates above some s : n threshold .",
    "it allows the user to smooth the image either spatially or spectrally at some chosen scale in order to improve s : n at that scale , or uses a wavelet reconstruction that does not require any assumptions be made about the size of the objects in the image , but assumes that the noise between pixels is uncorrelated , which will not be true for any interferometric observation where the point spread function ( psf ) of the interferometer acts to correlate the noise across the image",
    ".    in @xcite , henceforth d14 , an analysis is described of a blind survey of the hubble deep field north covering the entire 3 mm window ( 79 - 115  ghz ) using the iram plateau de bure interferometer ( pdbi ) . here",
    "two different techniques were introduced in order to perform the search .",
    "the first defines a ` spread ' parameter that models the deviation in the noise from a normal gaussian distribution introduced by the prescense of a source due to an excess of positive flux .",
    "the second is based on the finder ` cprops ' which uses a simple signal to noise cut of the image cube , onto which a mask is applied that identifies an excess over multiple concurrent channels .",
    "the lack of any parametric model being applied to the properties of the source , however , both in these methods , and in the duchamp algorithm , makes it difficult to objectively quantify how likely that source is to be real given our knowledge of galaxy formation .",
    "the preferred method should be to take a set of physically meaningful models and to use these in the search , determining in a robust way the probability that any given model is supported by the data .",
    "in this paper we present a bayesian search algorithm designed to address just such problems .",
    "we fit different parametric models to an observed dataset using the inference tool multinest @xcite to efficiently calculate the bayesian evidence and so objectively quantify the probability of the existence of those sources , and allow for selection between the different models .    whilst this algorithm has already been used in several publications ( e.g. @xcite ) here",
    "we describe the details of the method , and apply it to both a simulated data set , and to the pdbi survey of the hubble deep field north .",
    "details of the survey and its cosmological implications are presented in detail in d14 and @xcite ( henceforth w14 ) . here",
    "we focus on the technical aspects of our methodology of performing such a search and the results of its application to this survey .    in sections [ section :",
    "bayes ] and [ section : mu ] we discuss bayes theory , and its application to our search method in terms of quantifying the proability that a source exists in the data . in section [ section :",
    "likes ] we discuss the technical aspects of the algorithm , and the galactic models used .",
    "section [ section : sim ] sees this method applied to a simulated data set designed to represent the proceeding survey , and finally in section [ section : hdf ] we show our results of performing the search on the pdbi observation with concluding remarks in section [ section : conclusions ] .",
    "we adopt a concordance @xmath1cdm cosmology throughout , with @xmath2 = 71  km@xmath3 , @xmath4 = 0.27 , and @xmath5 = 0.73 @xcite .",
    "our galaxy modeling methodology is built upon the principles of bayesian inference ; here we give a summary of this framework .",
    "bayesian inference methods provide a consistent approach to the estimation of a set of parameters @xmath6 in a model or hypothesis @xmath7 given a set of data , @xmath8 .",
    "bayes theorem states that    @xmath9    where @xmath10 is the posterior probability distribution of the parameters , @xmath11 is the likelihood , @xmath12 is the prior probabiltiy of the parameters given the model , and @xmath13 is the bayesian evidence .    in parameter estimation , the normalizing evidence factor",
    "is usually ignored , since it is independent of the parameters @xmath6 , and inferences are obtained by taking samples from the ( unnormalised ) posterior using , for example , standard markov chain monte carlo ( mcmc ) sampling methods .",
    "the posterior obtained constitutes the complete bayesian inference of the parameter values , and can , for example , be marginalized over each parameter to obtain individual parameter constraints .",
    "in contrast to parameter estimation , for model selection the evidence takes the central role and is simply the factor required to normalize the posterior over @xmath6 :    @xmath14    where @xmath15 is the dimensionality of the parameter space . as the average of the likelihood over the prior ,",
    "the evidence is larger for a model if more of its parameter space is likely and smaller for a model with large areas in its parameter space having low likelihood values , even if the likelihood function is very highly peaked .",
    "thus , the evidence automatically implements occam s razor : a simpler theory with a compact parameter space will have a larger evidence than a more complicated one , unless the latter is significantly better at explaining the data . the question of model selection between two models @xmath16 and @xmath17",
    "can then be decided by comparing their respective posterior probabilities , given the observed data set @xmath8 , via the model selection ratio @xmath18 :    @xmath19    where @xmath20 is the a priori probability ratio for the two models , which can often be set to unity but occasionally requires further consideration .",
    "evaluation of the multidimensional integral in [ eq : evidence ] is a challenging numerical task .",
    "the nested sampling approach , introduced by skilling ( 2004 ) , is a monte - carlo method targeted at the efficient calculation of the evidence , but also produces posterior inferences as a by - product .",
    "feroz @xmath21 hobson ( 2008 ) and feroz et al . ( 2008 ) built on this nested sampling framework , and introduced the multinest algorithm , which is very efficient in sampling from posteriors that may contain multiple modes and/or large ( curving ) degeneracies , and also calculates the evidence .",
    "this technique has greatly reduced the computational cost of bayesian parameter estimation and model selection , and is employed in this paper .",
    "we now discuss how one may calculate the probability that the observed field does indeed contain a real galaxy .",
    "this quantification is most naturally performed via a bayesian model selection by evaluating the evidence associated with the posterior for competing models for the data ( see e.g. hobson @xmath21 mclachlan ( 2003 ) ) .",
    "it is convenient to consider the following models :    * @xmath22 = no galaxy exists in @xmath23 * @xmath24 = a galaxy exists in @xmath23    where @xmath23 is the spatial volume contained in the prior .",
    "we must calculate the model selection ratio @xmath18 given in eq .",
    "[ eq : rval ] between the hypotheses @xmath25 . for each hypothesis @xmath26 , the evidence is given by    @xmath27    where    @xmath28    is the prior for the @xmath29 parameters that describe our model for hypothesis @xmath30 , and @xmath31 the prior for parameter @xmath32 .",
    "the priors on all model parameters apart from the amplitude of the source @xmath33 may be taken to be the same in each hypothesis .",
    "for source amplitude however , we take @xmath34 to be uniform between some range @xmath35 $ ] and @xmath36 is a delta function centered on a=0 .",
    "therefore our evidence for @xmath16 will be :    @xmath37    which is independant of both @xmath23 and the particular set of parameters @xmath38 .",
    "following feroz et al .",
    "( 2008 ) , we can calculate the model selection ratio @xmath18 then as    @xmath39    where @xmath40 is the expected number of detectable sources in the survey area .",
    "this then gives us the probability that a given candidate source is ` real ' by    @xmath41",
    "writing our image as a vector @xmath42 , we can write the value of a given pixel @xmath43 as the sum ,    @xmath44    where @xmath45 is our signal of interest , and @xmath46 is an additional noise term .",
    "we model the noise term as a random gaussian process ( although we note that in real datasets non  gaussianity in the noise can have a significant impact on the statistics , and describe methods to account for this in section [ section : hdf ] ) , and write the probability that our data is described by our model for the signal , which we denote @xmath47 as ,    @xmath48\\mathrm{pr } ( { \\mathbf{\\theta}})\\ ] ]    where @xmath49 is the set of parameters that describe our model , and @xmath50 is our noise covariance matrix , such that    @xmath51      we can write our noise vector in the image ,    @xmath52    where @xmath53 is the noise vector in the visibility domain , and @xmath54 represents a fourier transform . the covariance matrix in the image",
    "can then be written    @xmath55    in our likelihood evaluation however we are interested in the inverse of the covariance matrix and so we write    @xmath56    in the visibility domain , @xmath57 is diagonal , with elements @xmath58 corresponding to the weight of visibility @xmath59 .",
    "[ eq : eq9 ] therefore simplifies to    @xmath60}\\omega_k\\exp{[i\\theta_{jk}]},\\ ] ]    where @xmath61 is the number of data points in the visibility domain , @xmath62 , with @xmath63 the @xmath64 co - ordinates of visibility @xmath59 , and @xmath65 the angular separation on the sky of pixel @xmath30 from the phase centre of the observation .",
    "we are left with our final description of the noise covariance matrix ,    @xmath66}\\omega_k , \\label{eq : covmatrix}\\ ] ]    which is simply the point spread function ( psf ) of the interferometer .    the optimal method for evaluating our likelihood",
    "would then be to describe our model @xmath67 in the uv domain , and to fft this using the uv coverage of the observation , calculating the probability of the model according to eq .",
    "[ eq : prob ] and using eq .",
    "[ eq : covmatrix ] as our description of the covariance between the pixels . in the following work",
    "however we are able to make a set of additional assumptions that allow us to greatly simplify the evaluation of eq .",
    "[ eq : prob ] :    * given the resolution of the observations ( @xmath68 3or 25kpc at @xmath69 ) we do not expect to see any extended structure in the image . *",
    "given the expected sparsity in the field for sources in our detection regime , we do not expect to have overlapping sources .",
    "as such we can take our model in the visibility domain to be a delta function , such that in the image it will be described by the psf of the interferometer , and we need only be concerned with correlations in the image on the scale of the resolution of the observations .      as we are only concerned with correlations in the image on small scales we model the central region of the psf as an elliptical gaussian , with fwhm of the major and minor axes denoted @xmath70 and @xmath71 respectively , and denote the position angle on the sky of the major axis in degrees as @xmath72 .",
    "we will justify this assumption in section [ section : sim ] .",
    "our model for the source in one channel of the image plane can then be written ,    @xmath73,\\ ] ]    with @xmath74 with @xmath75 and @xmath76 , and @xmath77 the amplitude of the source in the channel at some velocity @xmath78 .    in order to account for the correlations between the pixels in the image we can define the quantity @xmath79 , where we sum all the pixels for which @xmath80 .",
    "the data can then be described by a single number which we will denote @xmath81 , given by @xmath82 where @xmath83 is the area of the fwhm of the synthesised beam .",
    "[ eq : prob ] can then be rewritten for a single channel as ,    @xmath84\\mathrm{pr } ( { \\mathbf{\\theta}})\\ ] ]    where @xmath85 is the rms of the noise in the image channel .",
    "we use three different models for the spectral properties of the source , a gaussian , double gaussian , and a more physically motivated model using brandt s parametrization @xcite . the first is described simply by a set of three parameters ( @xmath86,@xmath87 , @xmath33 ) as ,    @xmath88\\ ] ]    with @xmath86 the central velocity of the emission line , @xmath87 the scale parameter and @xmath33 the amplitude at the peak .",
    "the double gaussian is then described with a set of five parameters ( @xmath86,@xmath87 , @xmath89 , @xmath90 , @xmath91 ) as , @xmath92",
    "\\\\ \\nonumber        & + &   a_2\\exp\\left[-\\frac{1}{2}(v - v_0 + \\delta v)^2/\\sigma_v^2\\right]\\end{aligned}\\ ] ] where @xmath93 describe the amplitudes of the two peaks , and @xmath89 is the separation of the two components , centered at @xmath86 as before . finally , brandt s parameterisation describes the rotational velocity of a galaxy , modelled as a thin disk , at some radius @xmath94 as ,    @xmath95^{\\frac{3}{2n}}},\\ ] ]    where @xmath96 is the radius at which the galaxy obtains it s maximum rotational velocity @xmath97 , and @xmath15 describes how quickly the rotational velocity drops away with radius .",
    "the line profile can then be calculated following the same method as in @xcite ; starting with a thin ring , the observed circular velocity at any point will be given by @xmath98 , so that the luminosity density @xmath99 as a function of @xmath100 will be given by :    @xmath101    this however is divergent as @xmath100 approaches @xmath102 , and so we need to smooth it by taking into account the normal distribution of velocities produced by the random motions in the gas . in eq .",
    "[ eq : gasdisp ] the gas dispersion @xmath103 is taken to be constant with a value of @xmath104 , however the exact value is not critical , so that the final velocity profile is given by :    @xmath105\\phi(v , v_{\\mathrm{c}})\\ ] ]    assuming an exponential profile for the gas within the disk , described by some scale radius @xmath106 the emission line @xmath107 can then be modelled by integrating :    @xmath108    this function is then normalized to have a peak of unity to facilitate later scaling by the amplitude , such that    @xmath109      given a spectral model @xmath77 we can then write the final likelihood that we will use in our search as a product over a set of channels where the likelihood in any one channel is given by eq [ eq : improb ] .",
    "our final probability is therefore given by :    @xmath110,\\ ] ]    where @xmath111 is the number of channels in the image .",
    "we can briefly consider the two main differences between eq .",
    "[ eq : improbfinal ] and the serch algorithm .",
    "serch performs a weighted coherent sum over the the channels in the image , where the weighting is defined by a gaussian of some width .    denoting the normalised model gaussian in velocity space such that the peak of the model is equal to 1 as @xmath112 , we can write this sum for any pixel in the image @xmath113 as :    @xmath114    where @xmath115 is the reference velocity for channel @xmath116 . similarily the noise in the summed image will be    @xmath117    and the expected signal will simply be @xmath118 using this notation we could then rewrite eq .",
    "[ eq : improb ] as :    @xmath119\\mathrm{pr } ( { \\mathbf{\\theta}}),\\ ] ]    where @xmath120 is calculated as in eq . [ eq : imsum ] , but now in the summed image .",
    "this has the disadvantage however that it does not correctly take into account large positive spikes in the noise , as it will simply add to the s : n of the final summed image . in eq .",
    "[ eq : improbfinal ] this can not happen , as the difference between the model and the noise spike will be large if the surrounding channels do not also support a model with high amplitude , and so the candidate will be appropriately down weighted .",
    "secondly eq [ eq : imsum ] takes better account for the correlation between pixels in the image , averaging over the values within the fwhm of the psf , and will therefore be more robust to individual outliers that will trigger a detection if the s : n threshold is set on a per pixel basis .",
    "we now apply our search technique to a simulated data set , in order to test both the robustness of parameter estimation , and to determine a suitable probability threshold @xmath121 for use in the analysis of the survey data such that , if the probability given by eq .",
    "[ eq : prob ] is greater than @xmath121 , we consider it to be a real source .      in order to make the simulation as applicable to our survey as possible",
    ", we use the uv sampling function from the observation described in section [ section : hdf ] to create a set of empty uv data points . in order to recreate the same variation in noise across baselines , frequency and time present in the survey",
    "we add uncorrelated gaussian noise to each uv point with rms determined by the weight of that data point in the survey data .",
    "a set of 100 model galaxies are then added to the simulation , uniformly distributed in both space and frequency .",
    "these sources are described spatially by a circular gaussian , and use the brandt parameterization in velocity space , as described in section [ section : specmodel ] . with the exception of source amplitude the model parameters are chosen uniformly across the priors described in table [ table : priors ] .",
    "source amplitudes are then chosen such that the distribution of model flux follows an arbitrary power law . setting a detection limit such that the integrated signal to noise of a given source within the data is greater than 4 , this results in a value of @xmath40 of 22 .",
    ".parameter ranges used for the simulated galaxies . [ cols=\"^,^,^,^ \" , ]     [ table : dcomp ]    in d14 candidate detections are assigned a quality rating from 1 - 3 using a spectrum - based s : n , which we will denote sn@xmath122 , computed as the ratio between the fitted gaussian line flux and its uncertainty .",
    "the ratings then correspond to : quality flag 1 ) objects with sn@xmath123 , quality flag 2 ) those with sn@xmath122 between 3.5 and 5 , and quality flag 3 ) those with sn@xmath124 .",
    "two candidates are , in addition to this quality flag , assigned a ` secure ' rating , corresponding to those candidates which have been confirmed through follow - up observations .",
    "table [ table : dcomp ] lists the probabilities of the 17 candidate sources from d14 that result from either the blind search described in section [ section : blind ] with @xmath125 for all sources , or the directed search in section [ section : directed ] .",
    "in addition to these d14 includes 4 sources with negative fluxes which we have not listed in this table .    of the two detections given a secure rating in d14 one ( b1 ) is detected in our blind analysis at high significance , while the second was highly significant in the context of the directed search , in addition , both candidates assigned a quality rating of 1 are returned with high probability in the bayesian analysis .    in comparison , of the 11 candidates",
    "given a quality rating of 2 , only one of the two lines that correspond to hdf850.1 , and the second secure detection are found to exceed our threshold for acceptance of @xmath126 .",
    "the remaining quality 2 , and 3 candidates are all @xmath68 4.5@xmath127 and below which as discussed in section [ section : blind ] means that given the non - gaussian nature of the noise in the dataset they are unlikely to have significant probabilities .",
    "we have presented an efficient and statistically robust bayesian approach to detecting galactic emission lines in the image domain . in the most general case",
    "we are able to parameterise both the spatial and spectral characteristics of each of the detected galaxies during the search , whilst using the bayesian evidence to return the probability that any given detection is real. when detections are made the evidence can also be used to select between different source models in order to find the optimal description supported by the data .    using observations taken with the plateau de bure interferometer of the hubble deep field north over the entire 3 mm window ( 79.7 - 114.8 ghz ) we have used this technique to perform the first bayesian blind survey for cold molecular gas in the universe . in the context of a blind survey , where no additional prior information is included in the search such as known source positions or redshifts a total of 4 detections",
    "are made with probabilites that exceed our threshold for acceptance :    * the most significant source is associated with the co(@xmath128 ) transition for a bzk galaxy at redshift 1.784 .",
    "followup observations presented in d14 confirm the detection . * the second most significant line is associated with the co(@xmath129 ) transition line for the smg hdf850.1 .",
    "* the third most significant has no known counterpart in any optical / nir / mir wavelengths * the final detection has two possible counterparts in the fly99 photometric redshift catalogue within 1.5@xmath130 with redshifts that are within @xmath131 of the co detection .",
    "the most likely of these has the detection represent the co(@xmath132 ) transition at a redshift of @xmath133 .",
    "we then perform a directed search - including position and constraining redshift information for a set of 20 known sources in the field . in doing",
    "so we are able to probe lower signal to noise levels and detect a further source :    * a bzk galaxy at a redshift of @xmath134 with an optical / nir counterpart    this study acts as a demonstration for how to perform a robust statistical analysis of blind surveys of molecular gas in the universe . in the near future surveys",
    "will be carried out both for low-@xmath0 co transitions of high redshift galaxies using the jvla , and at millimeter wavelengths with alma . here",
    "the sensitivies reached will allow us to explore currently inaccessible portions of the co luminosity function , and an analysis such as that presented here will be required in order to exract the most from the data , inferring reliable scientific conclusions about the history of the molecular gas properties of star - forming galaxies in the universe through cosmic time .",
    "aravena m. , et al . , 2012 , mnras , 426 , 258"
  ],
  "abstract_text": [
    "<S> a new bayesian method for performing an image domain search for line - emitting galaxies is presented . </S>",
    "<S> the method uses both spatial and spectral information to robustly determine the source properties , employing either simple gaussian , or other physically motivated models whilst using the evidence to determine the probability that the source is real . in this paper , we describe the method , and its application to both a simulated data set , and a blind survey for cold molecular gas using observations of the hubble deep field north taken with the plateau de bure interferometer . </S>",
    "<S> we make a total of 6 robust detections in the survey , 5 of which have counterparts in other observing bands . </S>",
    "<S> we identify the most secure detections found in a previous investigation , while finding one new probable line source with an optical i d not seen in the previous analysis . </S>",
    "<S> this study acts as a pilot application of bayesian statistics to future searches to be carried out both for low-@xmath0 co transitions of high redshift galaxies using the jvla , and at millimeter wavelengths with alma , enabling the inference of robust scientific conclusions about the history of the molecular gas properties of star - forming galaxies in the universe through cosmic time .    </S>",
    "<S> [ firstpage ]    methods : data analysis , galaxies : evolution , galaxies : high - redshift </S>"
  ]
}