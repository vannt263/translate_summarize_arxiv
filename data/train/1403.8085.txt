{
  "article_text": [
    "large - scale evolutionary equations for many - body systems arise ubiquitously in numerical modeling .",
    "the cases of particular interest and difficulty involve many configuration coordinates .",
    "for instance , the time - dependent _ schroedinger _",
    "equation describes the wavefunction , depending on all positions of all quantum particles or states of spins .",
    "another important example is the simulation of the joint probability density function either in continuous ( _ fokker - planck _ equation ) or discrete ( _ master _ equation ) variables .    in case of @xmath0 configuration variables , solutions of these problems",
    "are @xmath0-variate functions . on the discrete level",
    ", one may typically assume that finite sets of @xmath1 admissible values are introduced for each coordinate independently ( e.g. a standard tensor product discretization grid ) .",
    "thereby , we do not discriminate the variables from the very beginning .",
    "however , the total amount of entries , defining the multivariate function , scales as @xmath2 . even if the _ dimension _",
    "@xmath0 is of the order of hundreds and @xmath3 ( a modest size for spin dynamics problems ) , this becomes an enormously large number , and straightforward computations are unthinkable .    to cope with such _ high - dimensional _ problems , one has to employ _",
    "( data-)sparse _ techniques , i.e. describe the solution by much less unknowns than @xmath2 .",
    "different state of the art approaches were developed for this task . among the most successful ones we may identify monte carlo methods @xcite , sparse grids @xcite , and tensor product representations . in this paper ,",
    "we follow the latter framework .    _ tensor product methods",
    "_ rely on the idea of separation of variables : a @xmath0-variate array ( or _ tensor _ ) may be defined or approximated by sums and products of univariate vectors .",
    "extensive information can be found in recent reviews and books , e.g. @xcite .",
    "a promising potential of tensor product methods stems from the fact that each univariate _ factor _ requires only @xmath1 elements to store instead of @xmath2 .",
    "if a tensor can be approximated up to the required accuracy with a moderate amount of such terms , the memory and complexity savings may be outstanding .",
    "there exist different tensor product _",
    "formats _ , i.e. rules how to map univariate factors to the initial array . in case of two dimensions ,",
    "one ends up with the well - known low - rank dyadic factorization of a matrix .",
    "this straightforward sum of direct products of vectors in higher dimensions is called cp format , and traces back to @xcite .",
    "however , the error function recast to the entries of the cp factors may not have a minimizer @xcite .",
    "therefore , even if all elements of a tensor are given , it is difficult to detect its cp rank .",
    "certain heuristics are available , for example , one may increase the rank one by one in a try - and - dispose als procedure @xcite or greedy algorithms @xcite .",
    "nevertheless , such methods typically exhibit a fast saturation of the convergence for rather modest ranks , and more accurate calculations become struggling .",
    "a family of reliable tools exploits recurrent two - dimensional factorizations to make the computations stable . in this work ,",
    "we focus on the simplest member of this family , rediscovered several times under different names : _ valence bond states _",
    "@xcite , _ matrix product states _ ( mps ) @xcite and _ density matrix renormalization group _ ( dmrg )  @xcite in condensed matter quantum physics , and _ tensor train _ ( tt ) @xcite in numerical linear algebra .",
    "this format possesses all power of the recurrent model reduction concept , but the description of algorithms may benefit from some transparency and elegance . for higher flexibility in particular problems ,",
    "one may use more general tree - based constructions , such as the _ ht _ @xcite or _ extended tt / qtt - tucker _ @xcite formats .",
    "the dmrg is not only the name of the representation , but also a variety of computational tools .",
    "it was originally developed to find ground states ( lowest eigenpairs ) of high - dimensional hamiltonians of spin chains .",
    "the main idea behind the dmrg is the alternating optimization of a function ( e.g. rayleigh quotient ) on tensor format blocks in a sequence .",
    "it was noticed that this method may manifest a remarkably fast convergence @xcite , and later extensions to the energy function followed @xcite .    besides the stationary problems ,",
    "the same framework was applied to the dynamical spin schroedinger equation .",
    "two conceptually similar techniques , the _ time - evolving block decimation _ ( tebd ) @xcite and the _ time - dependent dmrg _ ( tdmrg )",
    "@xcite take into account the nearest - neighbor form of the hamiltonian to split the operator exponent into two parts using the trotter decompositions",
    ". for each part , the exact exponentiation may be performed , but at the cost of increased sizes of tensor format factors . to reduce the storage ,",
    "the truncated singular value decomposition is employed .",
    "thus , the method introduces two types of error : the truncated part of the trotter series , and the truncated part of the tensor format .",
    "if many time steps are required , the error may accumulate in a very unwanted manner : it lacks a reasonable separation of variables , and hence inflates the tensor format storage of the solution ( see e.g. @xcite ) .    to stick the evolution to the manifold , generated by the tensor format , the so - called _ dirac - frenkel _ principle",
    "may be exploited @xcite .",
    "this scheme projects the time derivative onto the tangent space of the tensor product manifold , and formulates the dynamical equations for the factor elements directly .",
    "the storage of the format is now fixed , but approximation errors become generally uncontrollable . in addition , the projected dynamical equations may be ill - conditioned .    as an alternative approach",
    ", one may consider time just as another variable , since the dimension contributes linearly to the complexity of tensor product methods , and solve the global system for many time layers simultaneously @xcite . in this work",
    "we follow this way .",
    "contrarily to @xcite , we use the spectral differentiation in time on the chebyshev grid , see @xcite .",
    "this makes the time discretization error negligible , and we show that a long - time dynamics is possible without explosion of the tensor format storage .",
    "the linear system arising from this scheme is always non - symmetric and requires a reliable solution algorithm in a tensor format .",
    "the traditional dmrg may suffer from a stagnation at a local minimum , far from the requested error level .",
    "recently , the _ alternating minimal energy _ ( amen ) method was proposed @xcite , which augments the tensor format of the solution in the dmrg technique by the tensor format of the global residual , mirroring the classical steepest descent iteration .",
    "this endows the method with the rank adaptivity and a guaranteed global convergence rate .",
    "importantly , the practically manifesting convergence appears to be much faster than the theoretical predictions , which yields a solution with a nearly - optimal tensor product representation for a given accuracy .",
    "another problem reported for tdmrg ( it takes place for the techniques in @xcite as well ) is the corruption of system invariants .",
    "even if the storage remains bounded during the dynamics , the magnitude of the error may rise . though we may be satisfied with the resulting approximation of the whole solution , it is worth sometimes to preserve a linear or quadratic function of the solution exactly ( see e.g. a remark in @xcite ) . in this paper",
    "we address this issue for linear functions and the second norm of the solution by including the vectors , defining the invariants , into the amen enrichment scheme .    in the next section",
    "we formulate the ode problem , investigate its properties related to the first- and the second - order invariants , show the galerkin model reduction concept and how the invariants may be preserved in the reduced system , and suggest the spectral discretization in time .",
    "section [ sec : tensor ] gives a brief introduction to tensor product formats and methods , and finally , the new tamen algorithm ( the name is motivated by tdmrg ) is proposed and discussed .",
    "section 4 demonstrates supporting numerical examples , and section 5 contains concluding remarks .",
    "our central problem , considered in particular in the numerical examples , is the homogeneous linear system of odes , @xmath4 in section [ sec : spectral ] and in the final version of the algorithm , we will extend to the general quasi - linear form @xmath5 .",
    "analogously , the inhomogeneous case @xmath6 may be taken into account with a few technical changes .",
    "nevertheless , basic features may be illustrated already on the simple linear system , and we will keep it in focus in the first part of the paper .    throughout the paper , @xmath7 and other quantities denoted by small letters",
    "will be considered as @xmath8 vectors , such that the _ dot _ ( inner , scalar ) product @xmath9 may be written as @xmath10 .",
    "the time discretization relies on both the finite approximation of the time derivative and boundary conditions for the cauchy problem . a simple way to derive them",
    "is presented below .",
    "given @xmath11 ( not necessarily linear ) together with @xmath12 , we introduce a new variable @xmath13 , and obtain @xmath14 to discretize this equation , we use the chebyshev spectral differentiation scheme @xcite . the base _ chebyshev _ nodes on the interval @xmath15 $ ] are written as @xmath16 , and after rescaling onto @xmath17 $ ] we obtain @xmath18 , @xmath19 .",
    "since @xmath20 starts from @xmath21 , the point @xmath22 is excluded , in accordance with the zero dirichlet boundary condition .",
    "now , we represent any function in the form @xmath23 , where @xmath24 be the lagrange interpolation polynomial built on @xmath25 , i.e. @xmath26 .",
    "therefore , the time derivative can be approximated by the matrix - by - vector product , @xmath27 where @xmath28 $ ] is the so - called _ chebyshev differentiation matrix_. taking into account the form of the lagrange polynomials , the elements @xmath29 can be calculated , @xmath30 \\dfrac{1+\\delta_{i,\\i}}{1+\\delta_{j,\\i } } \\dfrac{(-1)^{i+j}}{\\hat t_i- \\hat t_j } , & i \\neq j , \\\\[1em ] \\dfrac{2\\i^2 + 1}{6 } , & i = j=\\i . \\end{array}\\right.\\ ] ] note that in the right - hand side we use the dimensionless points @xmath16 . substituting back @xmath13 ,",
    "obtain the following discretized equation , @xmath31    the accuracy of the chebyshev differentiation is given by the next statement .",
    "[ st : cheb ] suppose @xmath32 , defined on @xmath33 $ ] , is analytically extensible to the complex ellipse @xmath34 with @xmath35 .",
    "then the error of the chebyshev derivative converges exponentially , @xmath36    if the ode solution is not smooth in time , more sophisticated hp - techniques may be required @xcite . in many cases , however , the chebyshev interpolation is preferable , since it allows to work with pointwise samples of functions instead of galerkin coefficients , and increases the sparsity of involved matrices .",
    "the chebyshev differentiation matrices can be also used for spatial variables in e.g. the fokker - planck equation , see @xcite .    in many practical models ,",
    "the right - hand side of the ode system is _ quasi - linear _ , i.e. @xmath37 . in case of a mild non - linearity , the straightforward _",
    "iteration may exhibit a satisfactory convergence .",
    "given the initial vector @xmath38 , composed from the stacked samples @xmath39 at the chebyshev nodes in time , we write a counterpart of as the following linear system , @xmath40 where @xmath41 denotes the `` reversed '' kronecker product , @xmath42 $ ] , @xmath43 is the identity matrix of size @xmath44 , and @xmath45",
    ". the reversed rule of the kronecker product is introduced for more convenient connection with tensor product schemes , see the next section .",
    "if the residual @xmath46 is too large , one may put @xmath47 and solve again , performing several picard steps .",
    "obviously , if @xmath48 does not depend on @xmath7 , the very first iteration gives the exact solution .",
    "if in addition , the matrix @xmath48 is stationary , the block - diagonal matrix in may be written as the kronecker product @xmath49 , and the simplified system reads @xmath50 here we denoted @xmath51 , the right - hand sides stacked .",
    "note that if @xmath52 , i.e. the ode system is stable , the spectrum of @xmath53 consists of values @xmath54 , and lies essentially in the right half of the complex plane .",
    "it is important for the convergence of the tensor product iterative algorithms , cf .",
    "the analysis of the minimal residual method @xcite .",
    "our goal will be to seek an ode solution in a compressed data - sparse form .",
    "a particular question of interest is the following : if the system preserves some quantities in time , is it possible to maintain this property in the data - sparse algorithms , which are based on the galerkin projection approach ?    one of the most ubiquitous conserving quantities are the linear function of the solution , and the second norm . given some _ detecting _",
    "vector @xmath55 , the linear function can be written as @xmath56 .",
    "it corresponds , for example , to the probability normalization in the fokker - planck equation : @xmath7 has the meaning of the discretized probability distribution , and it holds that @xmath57 , for @xmath55 being a vector of all ones .    among the second - order invariants",
    ", we investigate the euclidean ( frobenius ) norm of the solution , @xmath58 .",
    "the conservation condition @xmath59 is a well - known property of the schroedinger equation @xmath60 , where @xmath61 is the imaginary unity , and @xmath62 .",
    "the following well - known algebraic properties of the system matrix guarantee conservation of a linear function or the second norm .",
    "[ st : inv1 ] if a matrix @xmath63 possesses a vector @xmath55 in the co - kernel , i.e. @xmath64 , the ode system conserves the linear function @xmath65 .    [",
    "st : inv2 ] the condition @xmath66 yields the conservation of the frobenius norm of the solution , @xmath59 .",
    "generally , the opposite is not true : a linear function may persist even if the detecting vector does not belong to the co - kernel of @xmath48 .",
    "however , in many practical examples ( fokker - planck , schroedinger equations ) , it is the property @xmath67 ( or @xmath68 ) that available at the problem formulation stage .",
    "so , we will focus on these stronger conditions , and investigate how they can be brought into the galerkin projection .",
    "an abstract model reduction may be written as follows .",
    "given an orthogonal set of columns @xmath69 , @xmath70 , one considers instead of the large system a reduced ode , @xmath71 numerical treatment of this equation is cheap if the basis size is small , @xmath72 .",
    "the approximate solution of the initial problem writes as @xmath73 .",
    "many approaches exist to determine the basis sets @xmath74 , see e.g. the reviews @xcite .",
    "the well - known krylov method for the computation of the matrix exponential @xcite belongs to this class as well .",
    "another celebrated technique is the proper orthogonal decomposition @xcite , which extracts principal components from a set of _ snapshots _ @xmath75 using the singular value decomposition .",
    "the accuracy @xmath76 of the reduced model depends on the approximation quality of the basis set . in this paper , we employ the alternating tensor product optimization scheme to calculate a sequence of bases similar to the proper orthogonal decomposition adaptively , and both the implementation and the convergence properties will be discussed in section [ sec : tensor ] .",
    "however , an invariant linear function of the solution can be preserved under the galerkin projection independently on the particular basis .",
    "suppose we are given vectors @xmath77 , such that @xmath78 .",
    "let us include them into the basis : we concatenate @xmath79 and @xmath74 , and perform the orthogonalization , @xmath80 since the first @xmath81 columns of @xmath82 belong to the kernel of @xmath83 , the reduced matrix writes @xmath84 where we denote @xmath85 .",
    "now , derive the reduced solution in the new set , given as @xmath86 .",
    "the recursion step for the exponential series establishes as follows .",
    "@xmath87 for any @xmath88 hence we obtain @xmath89 therefore , since the first line contains only the identity w.r.t .",
    "the @xmath90-part , the solution writes in the form @xmath91 with the linear invariants @xmath92 preserved .",
    "the skew - symmetry , yielding the conservation of the second norm , is even easier to consider , since it is maintained under any galerkin projection .",
    "indeed , @xmath93 so , if @xmath68 , the same holds for the reduced system , and @xmath94 . moreover , since @xmath74 is orthogonal , it holds @xmath95 .",
    "thus , it is enough to guarantee @xmath96 .",
    "one way to do this is to expand the basis @xmath74 by @xmath97 in the same way as @xmath98 were incorporated in .",
    "however , it would inflate the storage in a tensor product scheme exponentially with time .",
    "since no further invariants are considered , we may adopt the rescaling .",
    "given @xmath99 , we keep the top part , representing the exact values of the first - order invariants , and update only the bottom as follows .",
    "we are looking for the value @xmath100 , satisfying @xmath101 and derive @xmath102 due to the orthogonality , it always holds that @xmath103 , and hence @xmath100 is well - defined as soon as @xmath104 . in numerical practice , however , one should be careful if @xmath105 becomes close to the machine precision .",
    "note that the galerkin reduction may be combined with the chebyshev discretization in time straightforwardly .",
    "given the orthogonal basis set @xmath74 , we assemble and solve the following @xmath106 system , @xmath107 where @xmath108 .",
    "both linear and quadratic invariants may be taken into account in the same way as shown in and , respectively .",
    "in the end of the previous section we saw that the chebyshev discretization of the ode may result in a matrix , given by a sum of two kronecker products . note that the kronecker product is a heavy memory consuming operation : if @xmath63 and @xmath109 contain @xmath110 entries , the product @xmath111 is defined already by @xmath112 elements .",
    "the ultimate goal thus may be formulated as follows : _ never expand kronecker products_. in the rest of the paper , we represent or approximate both the matrix and the solution by a multilevel summation of the kronecker products .      by _ tensor",
    "_ , we mean nothing else but an array with three or more indices , and denote it as @xmath113 \\in\\c^{n_1\\times\\cdots\\times n_d}$ ] . a tensor may come from a discretized multidimensional pde , for example : suppose a function @xmath114 is discretized by sampling at grid nodes @xmath115 , then the sampled values may be collected into a tensor @xmath116 .",
    "however , when we pose a linear system problem , or an ode , @xmath116 should be considered as a vector , cf . .",
    "we will denote the same data , re - arranged as a vector , by @xmath117 the _ multi - index _ operation @xmath118 stands for renumeration of the elements of @xmath116 .",
    "we use the rule @xmath119 consistent with the reversed kronecker product from the previous section : suppose @xmath120_{i_k=1}^{n_k},$ ] @xmath121 then @xmath122      the tensor train ( tt ) , or matrix product states ( mps ) representation for a tensor @xmath116 ( resp .",
    "vector @xmath7 ) is defined as follows , @xmath123 the summation indices @xmath124 are called the _",
    "indices , and their ranges @xmath125 are the _ tensor train _ ranks ( tt ranks ) .",
    "we keep @xmath126 and @xmath127 for uniformity of presentation , but agree that @xmath128 .",
    "the right - hand side consists from the tt _ blocks _ @xmath129 , and is denoted as @xmath130 .",
    "note that each tt block depends only on one initial index @xmath131 , thus , the tt format is a generalization of the direct product . introducing the asymptotic bounds",
    "@xmath132 , @xmath133 , we may estimate the memory compression : @xmath134 entries of @xmath116 reduce to @xmath135 elements of the format @xmath136 .    a matrix @xmath48 , corresponding to the solution @xmath7 , may be similarly seen as a @xmath137-dimensional tensor @xmath138 . however , since usually @xmath48 is a full - rank matrix , the straightforward @xmath137-dimensional tt is inefficient , as it contains the rank @xmath139 in the middle . instead , the _ matrix _ tt format is written with the index permutation , @xmath140 note that if all @xmath141 , this construction resolves to the kronecker product of matrices , @xmath142 .",
    "a pleasant confirmation of consistency is for example the identity matrix , having tt ranks 1 in this form .",
    "we may not limit ourselves with @xmath128 , and introduce a _ subtrain _ with nontrivial border indices , defined as follows , @xmath143    note that for @xmath144 or @xmath145 , one of the border indices vanishes .",
    "therefore , such cases will be convenient to denote as the _ interface _ matrices , @xmath146 we may also agree that @xmath147 , and @xmath148 .",
    "the interface matrices help us to show an important linearity of the tt map w.r.t .",
    "each tt block @xmath149 .",
    "indeed , construct the _ frame _ matrix , @xmath150 which does not contain @xmath151 , then it is easy to see that @xmath152 .",
    "note that the vector notation @xmath153 and the tensor notation @xmath129 share the same data , similarly to @xmath7 and @xmath116 .",
    "different notations are introduced to make the matrix products of the form @xmath154 consistent .",
    "a powerful approach for solution of various equations is the optimization of a certain function .",
    "for example , a typical problem arising in quantum physics is the calculation of the ground state , i.e. the lowest eigenpair of a symmetric matrix .",
    "it may be posed as the minimization of the _ rayleigh quotient _ @xmath155 . to seek the solution in the tt format ,",
    "the density matrix renormalization group ( dmrg ) formalism was proposed in @xcite and extensively developed since then .",
    "in particular , it was generalized to the _ energy function _",
    "@xmath156 @xcite to solve a linear system @xmath157 with the symmetric positive definite matrix @xmath48 and the right - hand side @xmath158 given in the tt format , @xmath159 , @xmath160 .",
    "if we restrict the solution to the tt format @xmath161 with _ fixed _ tt ranks @xmath162 , the exact minimization formulates as @xmath163 this highly nonlinear and nonconvex problem can rarely be solved at once . instead , the dmrg , or als ( alternating linear scheme ) algorithm performs a sequence of local steps , optimizing over each tt block @xmath149 while the others are fixed , @xmath164 the active blocks are selected in an iterative ( or _ sweeping _ ) manner , @xmath165 , and so on until convergence .",
    "the frame matrices and linearity of the tt map reduce to the _ local _ linear system , @xmath166    it is important that the frame matrix can be also represented as a matrix tt format with the tt ranks not larger than those of @xmath116 .",
    "indeed , introduce the reshapes @xmath167 and @xmath168 .",
    "for the rest @xmath169 , define the fictitious indices @xmath170 and assume that @xmath171 .",
    "then @xmath172 with the tt ranks @xmath173 .",
    "therefore , @xmath174 and @xmath175 in can be assembled efficiently using the matrix products in the tt format ( see @xcite ) .",
    "the tt map is not unique : if @xmath176 for any nonsingular @xmath177 of consistent sizes , it holds @xmath178 . therefore , we may ensure the orthogonality of @xmath179 and @xmath180 , and hence of the frame matrix @xmath181 . as a result ,",
    "the  _ condition numbers _ of the local systems satisfy @xmath182 i.e. is conditioned not worse than the initial problem @xmath157 .",
    "the orthogonalization requires qr decompositions of @xmath183 or @xmath184 matrices , containing the elements of @xmath149 , and is never a bottleneck in tt computations .",
    "so , we will omit it in algorithms , and assume implicitly that the frame matrices are always orthogonal at the moment they are required for .",
    "however , the alternating sweeping in a prescribed tt format suffers from several drawbacks .",
    "first , the tt ranks must be properly chosen a priory , which is a difficult task in a general problem .",
    "second , even with a correctly given initial guess , the iteration may stagnate at a spurious local minimum of @xmath185 constrained to the tt elements , far away from the optimal accuracy level for the given ranks .",
    "the first remedy to this situation was the so - called _ two - site _",
    "dmrg @xcite .",
    "it optimizes not over one @xmath186-th block , but over two blocks simultaneously : we merge @xmath187 , perform the update , and then compute the svd to separate back @xmath188 . in this operation ,",
    "the tt rank @xmath125 is likely to change , and the convergence may be improved .",
    "nevertheless , the latter takes place not always , for non - symmetric linear systems even the two - site dmrg may demonstrate no convergence .",
    "besides , we have to solve a ( more difficult ) two - dimensional system at each step . the new family of algorithms , the so - called _ alternating minimal energy _ ( amen )",
    "@xcite performs an explicit enrichment of tt blocks by the residual information similarly to .",
    "suppose we have solved for @xmath189 and are holding the new @xmath190 and all the other solution blocks @xmath191 are old .",
    "compute the low - rank tt approximation of the residual , @xmath192 and perform the enrichment of the first block ( followed by the orthogonalization ) , @xmath193 the next interface @xmath194 and frame @xmath195 matrices contain the residual components @xmath196 , and if the approximation quality @xmath197 is ensured , the global convergence rate may be proved .    in practice",
    "it is usually sufficient to perform the approximation of the residual via the simple alternating least squares algorithm , starting from a low - rank initial guess @xmath198 .",
    "this approach is heuristic , since no accuracy is guaranteed for the fixed - rank als .",
    "nevertheless , even with as small enrichment ranks as @xmath199@xmath200 , the algorithm converges very satisfactory , while the complexity may be substantially reduced , compared to the accurate svd - based calculation .",
    "the enrichment in the transition @xmath201 may be similarly written for the general step @xmath202 . for more details and theoretical analysis of the amen scheme",
    "we refer to @xcite . here",
    ", the final algorithm will be formulated in the next subsection directly for the temporal system .",
    "the time - dependent version of the amen algorithm agglomerates both the residual - based enrichment and the augmentation by the constraint vectors related to the linear system invariants .",
    "besides , the second norm correction takes place in the last step .",
    "we are given the @xmath203-dimensional system , and apply the amen algorithm for it . in the @xmath186-th step , we are solving the local system and obtain @xmath204 . to treat it as the `` first '' block and associate the residual and the enrichment",
    ", we consider the _",
    "@xmath186-th reduced _ system @xmath205 where @xmath206 and @xmath207 are the matrix and the right - hand side of , @xmath208 , \\quad g =   x_0 \\otimes ( se)+f.\\ ] ] now it holds @xmath209 , i.e. the @xmath186-th block is the first block of the @xmath186-th reduced system .",
    "therefore , we may compute the reduced residual and use it for the enrichment , @xmath210 the block @xmath211 may be derived simultaneously with the als update of the global residual approximation @xmath212 : we need to project @xmath213 onto the right interface @xmath214 of @xmath215 .    besides",
    ", assuming that the constraint vectors are also given in the tt formats , @xmath216 , we may include them in the enrichment at the very same step , and write @xmath217 with column - orthogonal @xmath149 , @xmath218 . the _ partial projections _",
    "@xmath219 , bringing the vectors @xmath98 to the tt format of @xmath7 , read @xmath220 . in practice , they can be extracted from the @xmath221-factor of the qr decomposition in with no additional calculations , @xmath222 compared to , it appears to be more accurate to put the solution @xmath204 at the first place in the enrichment and orthogonalization procedures .",
    "the augmentation is performed for @xmath165 , i.e. the spatial part only .",
    "note that it adapts the rank @xmath223 as well , i.e. the rank for the space - time separation .",
    "the last block @xmath224 corresponds to the temporal variable , and contains the second norm correction , if necessary .",
    "the latter , however , must be reformulated a bit , to account for the @xmath79-part staying after the @xmath7-part in .",
    "note that in the @xmath0-th step , the partial projections @xmath225 turn to the standard galerkin projections of the vectors @xmath98 onto the spatial part of the solution , @xmath226 .",
    "aggregate them into a matrix , and find its qr decomposition , @xmath227 now , the projection @xmath228 extracts exactly the coefficients of @xmath229 in @xmath97 , and we may rewrite as follows , @xmath230 after that , the right - hand side for the local problem with @xmath231 writes @xmath232 .",
    "a few words must be devoted to the solution of local systems for the spatial tt blocks , and the last system . for the inner blocks ,",
    "the local system size is @xmath233 , which may become too large for the direct gaussian elimination already for @xmath234 . as an alternative",
    ", we may use an iterative solver for this step , since the matrix @xmath174 inherits the tt structure of @xmath48 , and the fast matrix - vector product is available @xcite .",
    "in particular , we employ the bicgstab algorithm ( see e.g. @xcite ) with no preconditioner .",
    "however , the stopping threshold for the iterative solver enters as an additional parameter .",
    "the first idea is to take the same @xmath235 as is used for the svd approximations .",
    "it appears though that some problems require higher accuracy .",
    "we define thus a _ local accuracy gap _ @xmath236 , and solve the local systems with the residual tolerance @xmath237 .",
    "the last ( temporal ) system is solved directly , in order to restore the invariants with the machine precision .",
    "fortunately , this is usually not an issue , since the size @xmath238 of this system is small .",
    "the whole procedure summarizes to algorithm [ alg : tamen ] .",
    "note that it always performs the _ forward _ sweep , i.e. the dimension index runs through @xmath239 .",
    "it differs from the traditional als and dmrg schemes ( for symmetric problems ) , where the two - side iteration is conducted .",
    "however , it was found that with non - symmetric systems , the error may increase when we change the direction .",
    "therefore , since the orthogonalization steps 24 in alg .",
    "[ alg : tamen ] are not the bottleneck , we prefer to update the solution on the forward sweep only .",
    "temporal points @xmath240 ; matrix @xmath241 $ ] , right - hand side @xmath242 , initial guesses for the solution @xmath161 and the residual @xmath243 in @xmath203-dimensional tt formats ; initial state @xmath97 and detection vectors @xmath244 in @xmath0-index tt formats ; truncation threshold @xmath235 and local accuracy gap @xmath245 .",
    "updated solution @xmath7 , residual @xmath246 in the tt formats .",
    "prepare @xmath247 $ ] and @xmath248 in the tt format .",
    "make @xmath249 and @xmath250 row - orthogonal .",
    "initialize @xmath251 , @xmath252 .",
    "form @xmath253 and @xmath254 as in , solve @xmath255 up to the residual @xmath237 .",
    "reduce the rank by svd , @xmath256 ,   @xmath257 . update the global residual @xmath258 . update the reduced residual @xmath259 .",
    "assemble @xmath260 .",
    "compute the qr decomposition @xmath261 , extract @xmath262 .",
    "compute the qr decomposition @xmath263 .",
    "form the reduced temporal system with @xmath264 .",
    "correct the norm according to . solve and return @xmath265 .",
    "we have implemented the algorithm [ alg : tamen ] in matlab , and conducted simulations on a linux machine with 2.0 ghz intel xeon cpu using one thread .",
    "the code is available at http://github.com/dolgov/tamen[`http://github.com/dolgov/tamen ` ] .      as the first example of the ode with the skew - symmetric matrix ,",
    "consider the transport equation in the periodic domain @xmath266 ^ 2 $ ] with the central difference discretization scheme , @xmath267 where @xmath268 is the mesh step of the uniform grid @xmath269 , @xmath270 , @xmath271 .",
    "the pure convection is a notoriously fragile problem , since inaccurate discretizations may cause large spurious oscillations . in this test",
    ", we select a smooth initial state @xmath272 , and consider large grids , @xmath273@xmath274 , such that the spatial part is properly resolved , and we may focus on the time integration scheme .",
    "we choose this model example for demonstration purposes _ deliberately_. it allows a comparison with a known analytical solution , and contains both types of invariants considered in the paper .",
    "moreover , fine grids still make the problem challenging , cf .",
    "large cpu times of the straightforward matrix exponentiation in table [ tab : conv_timeerror ] .",
    "the initial state is a rank-1 @xmath275-dimensional tt tensor if we separate @xmath276 and @xmath277 .",
    "however , to achieve higher cost reduction , we employ the so - called qtt format @xcite : we choose @xmath278 , and decompose each index @xmath131 to the binary digits , @xmath279 after that , all tensors are reshaped to the new indexing and compressed into the @xmath280-dimensional tt format , for example , @xmath281 the matrix in is exactly ( and constructively , see @xcite ) representable in the qtt format with the maximal tt rank @xmath282 , but @xmath283 does not possess an exact decomposition anymore , and the accuracy threshold @xmath235 plays a nontrivial role .     and @xmath284 vs. time and accuracy.,title=\"fig : \" ] and @xmath284 vs. time and accuracy.,title=\"fig : \" ]        .convection example .",
    "cpu times ( seconds ) and errors in different methods and parameters . [ cols=\"^,^,^,^,^,^,^ \" , ]      with and without additional enrichments .",
    "degeneracy of the normalization @xmath285 ( right ) is shown only for the test with enrichments.,title=\"fig : \" ] with and without additional enrichments .",
    "degeneracy of the normalization @xmath285 ( right ) is shown only for the test with enrichments.,title=\"fig : \" ]     ( left ) and maximal errors in @xmath286 ( right),title=\"fig : \" ] ( left ) and maximal errors in @xmath286 ( right),title=\"fig : \" ]    as the initial state , we choose the multinomial function according to @xcite , @xmath287 where @xmath288 , and @xmath289 is the heaviside function .",
    "though even infinite copy numbers are potentially allowed , the probability function @xmath290 vanishes in the limit @xmath291 . in practice",
    ", we have to deal with a finite problem , so we restrict the copy numbers to finite values . to ensure that the truncated part outside is negligible , we take @xmath292 .",
    "moreover , we adjust the propensities of generation reactions as follows : @xmath293 together with the natural condition @xmath294 for @xmath295 , we obtain the _ normalization conservation _ property @xcite , @xmath296 , where @xmath297 is a vector of all ones .    therefore , our first constraint vector @xmath298 .",
    "besides , as one of statistical outputs , we may be interested in the _ mean copy numbers _ , computed as @xmath299 where @xmath300 are the all - ones vectors of size @xmath301 . to make the computations of more accurate",
    ", we also include @xmath302 in the enrichment set , which reads therefore @xmath303 .    in fig .",
    "[ fig : cme - time - rank ] , we investigate the tt ranks of the solution and the cpu times of the calculations with the following parameters : the tensor truncation threshold @xmath304 , local residual gap @xmath305 , number of chebyshev points in time @xmath306 , the residual tt rank in tamen @xmath307 , and the time grid is exp - uniform in accordance with @xcite , @xmath308 , @xmath309 , such that @xmath310 for the step @xmath311 . to cope with large grid sizes ( @xmath312 ) ,",
    "we employ the qtt format , as in the first example .",
    "we remind that the crank - nicolson calculations in @xcite required about one hour on the same computer . from fig .",
    "[ fig : cme - time - rank ] we may observe that the straightforward tamen algorithm requires less time , but the enrichments @xmath79 make it larger . in fig .",
    "[ fig : cme - meanconc ] , we show the evolution of the mean copy numbers in time , and compare them with the reference values @xmath313 , computed with smaller tolerance @xmath314 .",
    "we may notice that the enrichments improve the accuracy significantly .",
    "we would like to emphasize that the artifacts in the left plane of fig .",
    "[ fig : cme - meanconc ] do not reflect explicitly the error in the solution @xmath290 , rather than in the means . recall that the maximal value of @xmath315 is @xmath316 .",
    "the exact solution would have a fast decay of the elements , which compensates large values of the index in .",
    "however , the approximate solution may conceal this decay by oscillations at the magnitude @xmath317 . taking into account @xmath304",
    ", we may conclude that @xmath318 may be of the order of @xmath319 , as appears in fig .",
    "[ fig : cme - meanconc ] .",
    "the same consideration holds for @xmath320 in the end of the dynamics . nevertheless , if we keep @xmath302 in the tt format for @xmath290 exactly , the inner products in recover satisfactory accuracy .    as in the previous example",
    ", the degeneracy of the normalization @xmath285 stays below @xmath321 in the enriched version of the algorithm ( see fig . [ fig : cme - time - rank ] ) . for the sake of clarity , we do not plot this quantity for the algorithm without enrichments , since it grows up to @xmath322 .",
    "we have proposed and studied the alternating iterative algorithm for approximate solution of ordinary differential equations in the mps / tt format .",
    "the method combines advances of dmrg techniques and classical iterative methods of linear algebra",
    ". started from the solution at the previous time interval as the initial guess , it often converges in 24 iterations , and delivers accurate solution even for strongly non - symmetric matrices in the right - hand side of an ode .    another important ingredient is the spectral discretization scheme in time .",
    "the high - order approximation allows to simulate systems with purely imaginary spectrum without blowing the solution storage up , due to the absence of a poorly - separable noise , an unfortunate phenomenon in low - order schemes .",
    "the method possesses a simple mechanism how to bring linear conservation laws into the reduced tensor product model exactly , provided the generating vectors admit low - rank representations .",
    "the second norm of the solution can be also preserved easily .",
    "the numerical experiments reveal a promising potential of this method in long time simulations with the chemical master and similar equations .",
    "nevertheless , several further research directions open . the second norm conservation benefits from the orthogonality properties of the tensor format .",
    "is it possible to maintain general quadratic and high - order invariants ?",
    "we saw that accurate solution of the reduced systems in the tensor product scheme may be crucial for the robustness of the whole process . to what extent can we relax this demand ?",
    "are there reliable ways to precondition the local problems ?",
    "stiff problems may require either small time steps or large numbers of chebyshev points in time .",
    "are there ways to refine temporal grids adaptively inside the tensor format ?",
    "we are planning to address some of these questions in future work .",
    "another part of research will involve verification of the technique in a broad range of applications .",
    "recently , the amen algorithm for linear systems was employed in the simulation of a nuclear magnetic resonance experiment for large proteins @xcite .",
    "the tt formalism allows to consider the whole quantum hilbert space with a controllable accuracy  an unprecedented flexibility in nmr calculations . in future , we plan to extend the proposed approach to more complicated time - dependent nmr problems . concerning the non - linear modeling , it is intriguing to revisit the simulations of plasma @xcite ."
  ],
  "abstract_text": [
    "<S> we propose an algorithm for solution of high - dimensional evolutionary equations ( odes and discretized time - dependent pdes ) in tensor product formats . </S>",
    "<S> the solution must admit an approximation in a low - rank separation of variables framework , and the right - hand side of the ode ( for example , a matrix ) must be computable in the same low - rank format at a given time point . </S>",
    "<S> the time derivative is discretized via the chebyshev spectral scheme , and the solution is sought simultaneously for all time points from the global space - time linear system . to compute the solution adaptively in the tensor format , </S>",
    "<S> we employ the alternating minimal energy algorithm , the dmrg - flavored alternating iterative technique .    besides , we address the problem of maintaining system invariants inside the approximate tensor product scheme . </S>",
    "<S> we show how the conservation of a linear function , defined by a vector given in the low - rank format , or the second norm of the solution may be accurately and elegantly incorporated into the tensor product method .    </S>",
    "<S> we present a couple of numerical experiments with the transport problem and the chemical master equation , and confirm the main beneficial properties of the new approach : conservation of invariants up to the machine precision , and robustness in long evolution against the spurious inflation of the tensor format storage .    </S>",
    "<S> _ keywords : _    </S>",
    "<S> high  dimensional problems , tensor train format , mps , als , dmrg , ode , conservation laws , dynamical systems .    </S>",
    "<S> _ msc2010 : _    15a69 , 33f05 , 65f10 , 65l05 , 65m70 , 34c14 . </S>"
  ]
}