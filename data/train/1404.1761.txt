{
  "article_text": [
    "suppose the price evolution of a stock follows a geometric brownian motion , whose drift will change at an unknown future time to an unknown level .",
    "an investor , who purchases a certain small number of shares at an initial time , can only observe the evolution of prices . based on these observed prices and some reasonable _ a priori _ knowledge about the change in the drift , what is the best time to sell the shares , in order to maximize the investor s expected profit ?",
    "under the same circumstances , what about the optimal discretely - balanced buying / selling trading strategies with a larger number of shares ?    at a more abstract level , this is a question about optimal stopping and impulse control of a diffusion , whose drift term has an unobservable parameter with a change point .",
    "there have been three common approaches to such problems .",
    "the conservative approach is the mini - max philosophy that optimizes the worst - case scenario , formulated as a zero - sum game between a controller and a stopper by @xcite karatzas and zamfirescu ( 2008 ) .",
    "the approach employed by many practitioners is to divide model calibration and decision making into two separate steps .",
    "another approach is to convert the decision - making problem with partial observations , into one with full observations , by augmenting the state process with the posterior probability distribution of the parameter .",
    "one illustration of this method is the work @xcite dai , zhang and zhu ( 2010 ) . in a geometric brownian motion price model with drift uncertainty , the authors assume no impact of the trading activities , and find two optimal sequences of times to place , respectively , buy and sell orders .",
    "the topics mentioned in the previous paragraph are all very well developed fields of research with an extensive literature from the past decades : among them , @xcite shiryaev ( 1969 ) and @xcite karatzas ( 2003 ) for sequential detection ; @xcite shiryaev ( 1978 ) or appendix d in @xcite karatzas and shreve ( 1998 ) for optimal stopping problems ; @xcite , @xcite , @xcite and @xcite by bensoussan and lions and @xcite ksendal and sulem ( 2007 ) for impulse controls ; as well as @xcite liptser and shiryaev ( 2001 ) and @xcite bensoussan ( 1992 ) for solving partially observed control problems using filtering techniques .",
    "this paper is an attempt at solving impulse control problems in the bayes sequential framework in one step , without tracking the posterior probability processes .",
    "the conversion from partial to full observations is facilitated by a change of probability measure , which hides the drift part of the diffusion .",
    "the measure change method was originally developed for solving change - point detection problems . for our problem ,",
    "the state process augmented by the likelihood ratios is markovian under the reference probability measure , and one can derive the dynamic programming principle satisfied by the value functions .",
    "the current values of the augmented state process provide all the information necessary for decision making .",
    "there are at least three widely used methods for describing the value functions of stochastic control problems - pde , dynamic programming , and backward sde .",
    "they are different formulations of the notion of the ",
    "stochastic maximum principle \" ( c.f .",
    "@xcite kushner ( 1972 ) and @xcite davis ( 1973 ) ) .",
    "the common mechanism of all three methods is that the sum of the value function and the cumulative reward , when evaluated along the state process corresponding to any admissible control strategy , yields a supermartingale  which becomes a martingale if and only if the control strategy is optimal .",
    "after reduction to the markovian case , we represent the optimal impulse control via the dynamic programming principle . unlike in the pioneering papers @xcite , @xcite , @xcite , @xcite and @xcite of bensoussan and lions , the variational inequalities associated with the value functions",
    "will not be presented here , because they are numerically inefficient to implement due to the dimensionality of the augmented state process . from a numerical point of view , we adapt the longstaff - schwartz algorithm for multiple optimal stopping times .",
    "based on the formulation of the dynamic programming principle in terms of stopping times , this method is computationally efficient although it uses monte carlo simulation .",
    "we also show the good accuracy of the obtained results for a simple problem involving geometric brownian motion and two optimal stopping times .",
    "the reduction to full observation via the change of measure and the proposed algorithm that involves monte carlo are well suited to a high dimensional state process .",
    "they are a contribution to the methodology of solving partial observation control problems .    in section [ sec model 1.1 ]",
    ", we specify the model and the quantity that we want to optimize .",
    "section [ sec general theory 2.2 ] deals with the main theoretical results related to writing and solving the impulse control problem under a different probability measure .",
    "section [ subsec gbm ] illustrates how to use the theoretical results through the implementation of longstaff - schwartz algorithm for multiple optimal stopping times .",
    "finally , we show in section [ discu ] that the method presented in this paper provides a better framework for multidimensional problems than the usual one that involves the posterior probabilities .",
    "this section sets up the diffusion model with a change point in its drift with section [ subsec 2.1 ] and lays out the impulse control problem of the diffusion with section [ subsec 2.2 ] .",
    "we consider a probability space @xmath0 , which supports two independent , @xmath1-measurable random variables @xmath2 and @xmath3 , as well as a one - dimensional standard brownian motion @xmath4 with respect to its natural filtration @xmath5 .",
    "the vector of random variables @xmath6 is independent of the brownian motion @xmath4 .",
    "let @xmath7 denote the filtration generated by @xmath2 , @xmath3 and @xmath4 .",
    "the unobservable process @xmath8\\times\\omega \\rightarrow \\theta,\\\\   & ( t,\\omega)\\mapsto \\theta(t,\\omega)=:\\theta(t ) \\end{split}\\ ] ] takes values in the parameter space @xmath9 .",
    "the process @xmath10 starts with initial value @xmath11 , and keeps this value until an unobservable time @xmath2 of _ regime change_. at the time @xmath2 , the parameter @xmath10 changes to a new level @xmath3 , a random variable taking values in the set @xmath12 , and remains at that level until the fixed terminal time @xmath13 . if regime change does not occur by time @xmath14",
    ", then @xmath10 takes the value @xmath15 throughout the interval @xmath16 $ ] , namely , @xmath17 the change point @xmath2 and the level @xmath3 have prior distributions @xmath18 and @xmath19 for any possible values @xmath20 , the given measurable functions @xmath21\\times { \\mathbb{r}}\\rightarrow { \\mathbb{r}}$ ] and @xmath22\\times { \\mathbb{r}}\\rightarrow { \\mathbb{r}}$ ] satisfy the following lipschitz and boundedness condition .",
    "[ assump sde 1.1 ] there exists a constant @xmath23 , such that + ( i ) for all @xmath24 , @xmath25\\times { \\mathbb{r}}$ ] , and for all @xmath26 , we have @xmath27 whereas + ( ii ) for all @xmath28\\times { \\mathbb{r}}$ ] and all @xmath26 , we have @xmath29    the assumption [ assump sde 1.1 ] ( i ) implies a linear growth condition on the functions @xmath30 and @xmath31 : there exists another constant @xmath32 , such that @xmath33 holds for all @xmath26 and all @xmath28\\times { \\mathbb{r}}$ ] .",
    "let @xmath34 be a positive integer , @xmath35 be stopping times with respect to the filtration @xmath36 , and @xmath37 be an @xmath38-valued @xmath39 - measurable random variable for @xmath40 .",
    "the @xmath34-tuple @xmath41 is called an _",
    "impulse control_. the set of _ admissible controls _ , denoted as @xmath42 , is the collection of all such impulse controls @xmath43 .",
    "the jump size @xmath44 is a given bounded , measurable function . given an arbitrary impulse control @xmath45 , the controlled state process @xmath46 is the unique strong solution to the equation @xmath47 by assumption [ assump sde 1.1 ] ( ii ) and equation ( [ sde 1.2 ] ) , the brownian filtration @xmath5 coincides with @xmath48 , which denotes the filtration generated by the process @xmath46 .",
    "the collection of all @xmath49-stopping times with values in @xmath16 $ ] is denoted as @xmath50 , and the collection of all @xmath49-stopping times with values in @xmath51 $ ] is denoted as @xmath52 .",
    "@xmath53 in order to define another probability measure @xmath54 on the space @xmath55 and on the sigma algebra @xmath56 , the one with respect to which we shall formulate our impulse control problem , we introduce the @xmath57-adapted process @xmath58 which will play the role of radon - nikodym derivative of the new measure @xmath54 with respect to the  reference probability measure \" @xmath59 .",
    "whereas , for every number @xmath26 , the @xmath49-adapted likelihood ratio process is defined as @xmath60 from the expression ( [ theta 1.1 ] ) for @xmath10 , the radon - nikodym derivative @xmath61 can be written , in terms of the likelihood ratio process @xmath62 and of the random vector @xmath63 , as @xmath64 the radon - nikodym process @xmath61 in ( 2.10 ) is a @xmath65-martingale , because of assumption [ assump sde 1.1 ] ( ii ) on the boundedness of the ratio @xmath66 and of the novikov condition ; the same is true for the likelihood ratio process @xmath67 in ( 2.11 ) , for any @xmath68 .",
    "there exists then a probability measure @xmath54 equivalent to @xmath59 , satisfying @xmath69 under this new probability measure @xmath54 , the random variables @xmath2 and @xmath3 are still independent and retain the prior distributions of ( [ rho prior 1.1 ] ) and ( [ theta prior 1.1 ] ) . by a generalization of the girsanov theorem to local martingales in @xcite van schuppen and wong ( 1974 ) ,",
    "the process @xmath70 is a local @xmath71-martingale , having the instantaneous quadratic variation @xmath72 ; and the process @xmath73 defined as @xmath74 is a standard @xmath54-brownian motion .",
    "the process @xmath46 defined by ( [ sde 1.2 ] ) is also the unique strong solution to the equation @xmath75      the impulse control problem we study in this paper , consists in choosing an optimal impulse control @xmath76 to achieve the maximal expected reward @xmath77 , \\end{split}\\ ] ] over all admissible impulse controls @xmath41 in @xmath42 .",
    "the reward functions @xmath78 and @xmath79 are measurable and satisfy conditions ( i ) and ( ii ) in assumption [ assump rwd 1.1 ] below .",
    "furthermore , we impose growth condition on the deterministic measurable functions @xmath80 and @xmath81 in the state variable , as follows .",
    "[ assump rwd 1.1 ] ( i ) the function @xmath82 is twice continuously differentiable , with first and second order derivatives denoted as @xmath83 and @xmath84 .",
    "+ ( ii ) the functions @xmath85 , @xmath82 , @xmath83 and @xmath84 are locally lipschitz and have polynomial growth . + ( iii ) the function @xmath86 is bounded for all @xmath87 and @xmath88 , and the function @xmath89 has polynomial growth rate in @xmath87 uniformly for all @xmath88 .",
    "both functions @xmath86 and @xmath89 are continuous in @xmath90 , for any arbitrarily fixed @xmath88 .",
    "this section provides a theoretical solution to the impulse control problem ( [ opt value 2.1.0 ] ) : section [ subsec measure change ] reduces the partially observable problem into one of full observation , by changing to the reference probability measure under which the state process is a martingale and augmenting the state process with the likelihood ratios and their integrals .",
    "section [ subsec solution ] solves the fully observable impulse control problem under the reference probability measure , by representing the optimal control in terms of the value functions and the augmented state process .      by the  measure change method \" ,",
    "we mean considering the impulse control problem ( [ opt value 2.1.0 ] ) under the reference probability measure @xmath59 which removes the unobservable drift of the state process @xmath46 . using the bayes rule and the properties of conditional expectations , the maximal expected reward @xmath91 from ( [ opt value 2.1.0 ] ) can be written as @xmath92\\\\ = & \\sup\\limits_{(\\tau,\\zeta)\\in\\textbf{i}}{\\mathbb e } ^0\\left [ { \\mathbb e } ^0\\left[z(t)\\left|{\\textbf{f}}(t)\\right.\\right ]",
    "\\left(\\int_0^t h(x(t))dt+\\xi(x(t))+\\sum\\limits_{i=1}^n c(x(\\tau_i-),\\zeta_i)\\right)\\right ] .",
    "\\end{split}\\ ] ] from the bayes point of view , the quantity @xmath93 $ ] in ( [ opt value 2.1 ] ) is the posterior expectation of the radon - nikodym derivative @xmath61 under the reference probability measure @xmath59 , given the observations of @xmath46 up to date . because of the independence of @xmath94 and @xmath46 under @xmath59 , from the prior @xmath59-distributions ( [ rho prior 1.1 ] ) and ( [ theta prior 1.1 ] ) , and by ( [ rn deriv 1.2 ] ) , this posterior expectation has the form @xmath95 = \\sum_{j=1}^m \\left(p_j l(t;\\mu_j)\\int_0^t\\frac{l(s;\\mu_0)}{l(s;\\mu_j ) } \\lambda e^{-\\lambda s}ds\\right ) + e^{-\\lambda t}l(t;\\mu_0 ) , \\;0\\leq t\\leq t. \\end{split}\\ ] ] for every @xmath26 , the likelihood ratio process @xmath67 defined in ( [ lr 2.1 ] ) is a @xmath96-martingale satisfying the stochastic integral equation @xmath97 with respect to the standard @xmath96-brownian motion @xmath4 . from equations ( [ post expect 1.1 ] ) and ( [ dlr 2.1 ] ) we obtain , for @xmath98 , that @xmath99\\right ) \\hspace{-2 mm } & = & \\hspace{-3mm}\\displaystyle \\hspace{-1mm}\\sum_{j=1}^m p_j\\left(\\int_0^t\\frac{l(s;\\mu_0)}{l(s;\\mu_j ) } \\lambda e^{-\\lambda s}ds\\right)dl(t;\\mu_j ) + e^{-\\lambda t}dl(t;\\mu_0 ) \\vspace{2 mm } \\\\",
    "\\hspace{-2 mm } & = & \\hspace{-3mm}\\left(\\hspace{-2mm}\\begin{array}{c } \\displaystyle \\sum_{j=1}^m p_j\\left(\\int_0^t \\hspace{-1mm}\\frac{l(s;\\mu_0)}{l(s;\\mu_j ) } \\lambda e^{-\\lambda s}ds\\right)l(t;\\mu_j)\\frac{b(t , x(t);\\mu_j ) } { \\sigma(t , x(t ) ) } \\\\ \\displaystyle + e^{-\\lambda t}l(t;\\mu_0)\\frac{b(t , x(t);\\mu_0 ) } { \\sigma(t , x(t))}\\end{array}\\hspace{-2mm}\\right)\\hspace{-1mm}dw^0(t ) , \\end{array}\\hspace{-5mm}\\end{aligned}\\ ] ] so the posterior expectation @xmath100\\right\\}_{0\\leq t\\leq t}$ ] is a local @xmath96-martingale ; in fact a @xmath96-martingale , as is easily checked from the definition ( 2.13 ) .",
    "+ applying it s formula , we shall see that the random variable inside the @xmath59-expectation on the second line of ( [ opt value 2.1 ] ) is a @xmath96-semimartingale evaluated at the time @xmath14 . lemma [ lem mart 1.1 ] will show that its local martingale part is in fact a square - integrable @xmath96-martingale of class @xmath101 ( definition 4.8 , page 24 of @xcite karatzas and shreve ( 1988 ) ) , because of the uniform integrability result from lemma [ lem ui 1.1 ] .",
    "[ lem ui 1.1 ] for every @xmath20 , consider the process @xmath102 defined as @xmath103 for any nonnegative integers @xmath104 , @xmath105 and @xmath106 , we have @xmath107<\\infty\\text { , } { \\mathbb e } ^0\\left [ \\sup\\limits_{0\\leq t\\leq t}l^{q_2}(t;u)\\right]<\\infty~~\\text { and } ~~ { \\mathbb e } ^0\\left[r^{q_3}(t;u)\\right]<\\infty\\,;\\ ] ] furthermore , the family @xmath108 is uniformly integrable with respect to the probability measure @xmath59 .      @xmath132    [ lem mart 1.1 ] for @xmath98 , @xmath87 , @xmath133 , and @xmath134 , consider the function @xmath135 defined as @xmath136 and the function @xmath137 defined as @xmath138 then , for @xmath98 , we have @xmath139\\left(\\int_0^t h(x(s))ds+\\xi(x(t))+\\sum\\limits_{\\tau_i\\leq t}c(x(\\tau_i-),\\zeta_i))\\right)\\\\ = \\,&m^0(t)+\\int_0^t\\alpha \\big(s ,",
    "x(s),l(s ) , r(s)\\big)ds+\\sum\\limits_{\\tau_i\\leq t}\\beta \\big(\\tau_i , x(\\tau_i-),l(\\tau_i-),r(\\tau_i-),\\zeta_i\\big ) , \\end{split}\\ ] ] where @xmath140 is some square integrable @xmath96-martingale with @xmath141 , @xmath142 and @xmath143    * proof : * applying it s formula for semimartingales with jumps , we get @xmath144 \\left(\\int_0^t h(x(s))ds+\\xi(x(t))+\\sum\\limits_{\\tau_i\\leq t}c(x(\\tau_i-),\\zeta_i)\\right ) \\\\",
    "= & \\hspace{1 mm } \\xi(x_0)+\\int_0^t\\left(\\int_0^{s- } \\hspace{-2 mm } h(x(u))du+\\xi(x(s-))+\\hspace{-2mm}\\sum\\limits_{\\tau_i\\leq s-}c(x(\\tau_i-),\\zeta_i)\\right)d { \\mathbb e } ^0\\left[z(s)\\left|{\\textbf{f}}(s)\\right.\\right]\\\\ & + \\int_0^t{\\mathbb e } ^0\\left[z(s-)\\left|{\\textbf{f}}(s-)\\right.\\right]\\xi'(x(s-))\\sigma(t , x(t))dw^0(t)\\\\ & + \\int_{0+}^t \\alpha\\big(s-,x(s-),l(s- ) , r(s-)\\big)ds+ \\sum\\limits_{\\tau_i\\leq t}\\beta \\big(\\tau_i , x(\\tau_i-),l(\\tau_i-),r(\\tau_i-),\\zeta_i\\big ) .",
    "\\end{split}\\ ] ] by change of variables and the continuity of riemann integrals , @xmath145 define @xmath146 \\\\",
    "+ & \\int_0^t{\\mathbb e } ^0\\left[z(s-)\\left|{\\textbf{f}}(s-)\\right.\\right]\\xi'(x(s- ) ) \\sigma(t , x(t))dw^0(t ) .",
    "\\end{split}\\ ] ] equations ( [ dyn 1.1])-([mart 2.1 ] ) imply that ( [ dyn 1.0 ] ) holds . substituting ( [ post expect 1.2 ] ) into ( [ mart 2.1 ] )",
    ", we get @xmath147\\xi'(x(s- ) ) \\vspace{2 mm } \\\\",
    "\\hspace{-2 mm } + \\left(\\hspace{-1mm}\\begin{array}{c } \\displaystyle \\sum_{j=1}^m p_j\\left(\\int_0^t \\hspace{-1mm}\\frac{l(s;\\mu_0)}{l(s;\\mu_j ) } \\lambda e^{-\\lambda s}ds\\right)l(t;\\mu_j)\\frac{b(t , x(t);\\mu_j ) } { \\sigma(t , x(t ) ) } \\\\",
    "\\displaystyle + e^{-\\lambda t}l(t;\\mu_0)\\frac{b(t , x(t);\\mu_0 ) } { \\sigma(t , x(t))}\\end{array}\\hspace{-1mm}\\right ) \\hspace{-2 mm } \\left ( \\hspace{-1mm}\\begin{array}{c}\\int_0^{s- } h(x(u))du\\\\ \\displaystyle+\\xi(x(s-))\\\\ \\displaystyle + \\sum\\limits_{\\tau_i\\leq s- } \\hspace{-2 mm } c(x(\\tau_i-),\\zeta_i)\\end{array } \\hspace{-1 mm } \\right)\\bigg ] .",
    "\\end{array}\\end{aligned}\\ ] ] by lemma [ lem ui 1.1 ] , @xmath140 is an integral of @xmath59-square integrable processes with respect to the @xmath96-brownian motion @xmath4 , hence @xmath140 is also a local @xmath96-martingale .",
    "we need to show that @xmath140 is a @xmath96-martingale , not just a local martingale .",
    "it suffices to show that the family @xmath148 is uniformly integrable under the probability measure @xmath59 . by equations ( [ post expect 1.1 ] ) and ( [ dyn 1.0 ] ) , @xmath140 can be expressed alternatively as @xmath149 @xmath150 from the expressions ( [ mart 1.2 ] ) , ( [ cross var 1.1 ] ) , ( [ cross var 2.1 ] ) , ( [ cond linear ] ) and assumption [ assump rwd 1.1 ] ( ii)(iii ) , we know that there exist a constant @xmath23 and a positive integer @xmath151 , such that @xmath152 for all @xmath153\\times\\omega$ ] . then , from lemma [ lem ui 1.1 ] , we know that , under the probability measure @xmath59 , the local martingale @xmath140 is both square - integrable and of class @xmath101 on @xmath16 $ ] .",
    "the latter implies that @xmath140 is a @xmath96-martingale .",
    "@xmath132    because the process @xmath140 in ( [ dyn 1.0 ] ) and ( [ mart 2.1 ] ) is a @xmath96-martingale , it should vanish from inside the @xmath59-expectation of ( [ opt value 2.1 ] ) , leaving only the initial value and the finite variation part of the semimartingale .",
    "this property enables lemma [ lem opt value 2.1 ] to rewrite the @xmath59-expectations in ( [ opt value 2.1 ] ) in a more convenient manner .",
    "[ lem opt value 2.1 ] for any impulse control @xmath154 , @xmath155 \\left(\\int_0^t h(x(t))dt+\\xi(x(t))+\\sum\\limits_{i=1}^n c(x(\\tau_i-),\\zeta_i)\\right)\\right]\\ ] ] @xmath156.\\ ] ]    * proof : * this is because the process @xmath157\\left(\\int_0^t",
    "h(x(s))ds+\\xi(x(t))\\right)-\\int_0^t \\alpha\\left(s , x(s),l(s ) , r(s)\\right)ds\\\\ & -\\sum\\limits_{\\tau_i\\leq t}\\beta(\\tau_i , x(\\tau_i-),l(\\tau_i-),r(\\tau_i-),\\zeta_i)\\,\\text { , } \\quad 0\\leq t\\leq t \\end{split}\\ ] ] is a @xmath96-martingale by lemma [ lem mart 1.1 ] , hence @xmath158=m^0(0)=\\xi(x_0)$ ] .",
    "equivalently , equation ( [ opt value 2.3 ] ) holds .",
    "@xmath132    up to this point , the @xmath59-expected reward from ( [ opt value 2.1 ] ) has been rewritten into the @xmath59-expectation of the sum of a reward @xmath135 cumulated over the time interval @xmath16 $ ] , and of a reward @xmath137 received only at the times of intervention , as in equation ( [ opt value 2.3 ] ) .",
    "both @xmath135 and @xmath137 are functions of the processes @xmath46 , @xmath159 and @xmath160 , which are adapted to the observation filtration @xmath49 .",
    "lemma [ lem markov 2.1 ] and proposition [ prop non explosion ] will show that the triple of processes @xmath161 forms a well - behaved markov process , because it is the unique strong solution to a stochastic differential equation with locally lipschitz coefficients and this solution does not explode .",
    "[ lem markov 2.1 ] the triple @xmath161 is a @xmath162-dimensional markov process on every time interval @xmath163 , for @xmath164 .",
    "* proof : *    @xmath132    denoting @xmath165 as the @xmath166-dimensional row vector of 1 s , and @xmath167 as the @xmath168-dimensional row vector of 0 s . over the time interval @xmath169 , the triple @xmath161 constitutes a strong solution to the @xmath162-dimensional sde @xmath170 driven by the standard @xmath59-brownian motion @xmath4 , with the initial value @xmath171 at time 0 and the initial value @xmath172 at the time @xmath173 . from assumption [ assump sde 1.1 ] ( i)(ii ) and inequality ( [ cond linear ] ) , the coefficients of the sde ( [ sde 1.4 ] ) are bounded on compact subsets of @xmath174 and are locally lipschitz .",
    "the sde ( [ sde 1.4 ] ) has a pathwise unique , strong solution .",
    "the well - posedness of the sde ( [ sde 1.4 ] ) ( equivalently , the well - posedness of the associated martingale problem ) implies the @xmath59-strong markov property of @xmath161 , with respect to the borel @xmath175algebra @xmath1 ( @xcite stroock and varadhan ( 1997 ) ) .",
    "but the filtration @xmath49 generated by @xmath46 is contained in @xmath1 , and the process @xmath161 is @xmath49-adapted .",
    "then @xmath161 has the strong markov property under the probability measure @xmath59 with respect to @xmath49 .",
    "[ prop non explosion ] the solution @xmath161 to the sde ( [ sde 1.4 ] ) does not explode within the time horizon @xmath16 $ ] .",
    "* proof : * by the definition of the explosion time of an sde with locally lipschitz coefficients ( e.g. page 330 of @xcite karatzas and shreve ( 1988 ) ) , this follows from lemma [ lem ui 1.1 ] .",
    "@xmath132    eventually , we are able to reformulate in theorem [ thm contr ref meas ] the partially observable impulse control problem ( [ opt value 2.1.0 ] ) . under the reference probability measure @xmath59 , it becomes a fully observable impulse control problem of the @xmath162-dimensional @xmath49-adapted state process @xmath161 from the sde ( [ sde 1.4 ] ) .",
    "to prove this theorem , we use equations ( [ opt value 2.1.0 ] ) , ( [ opt value 2.1 ] ) and lemma [ lem opt value 2.1 ] .",
    "[ thm contr ref meas ] the impulse control problem ( [ opt value 2.1.0 ] ) under the physical measure @xmath54 is equivalent to an impulse control problem under the reference probability measure @xmath59 , by choosing an optimal @xmath76 to achieve the maximal expected reward @xmath176.\\ ] ] furthermore , the two maximal expected rewards are related by @xmath177 .    because the best expected values @xmath91 and @xmath178 are different only up to a constant @xmath179 , the two suprema in ( [ opt value 2.1.0 ] ) and ( [ opt value 2.3.1 ] ) are achieved by the same set of optimal control @xmath180 , if any .",
    "the impulse control problem ( [ opt value 2.3.1 ] ) is the one we shall solve .",
    "this subsection will solve the impulse control problem ( [ opt value 2.3.1 ] ) , by representing the optimal control @xmath180 in proposition [ prop optimal contr ] in terms of the value function and the state process .",
    "the cornerstone of the representation is the dynamic programming principle of lemma [ lem dpp 2.1 ] . to satisfy the technical condition of the snell envelope argument for proposition [ prop optimal contr ] ,",
    "the continuity of the value functions is provided in lemma [ lem cont ] .",
    "+   + to save notations , some abbreviations are introduced first .",
    "we denote by @xmath181 the range of the solution @xmath161 , and its boundaries as @xmath182\\times { \\textbf{o}}\\quad \\text { and } \\quad \\partial^ * q:= \\{t\\}\\times { \\textbf{o}}.\\ ] ] the state space @xmath181 differs for different parameters @xmath183 and @xmath184 . without loss of generality",
    ", the variational inequalities associated with the impulse control problem shall be studied over the largest possible domain , which is @xmath185 for every @xmath186 , denote the bounded domain @xmath187 the closure of @xmath188 , denoted as @xmath189 , is strictly contained in @xmath181 . as @xmath190 , the sets @xmath188 increase to @xmath181 , hence the sets @xmath191\\times { \\textbf{o}}_n$ ] increase to @xmath192 .",
    "we introduce the abbreviations @xmath193 @xmath194 @xmath195 and @xmath196 for all @xmath197 in @xmath192 . with this notation ,",
    "the sde ( [ sde 1.4 ] ) , which has a pathwise unique , strong solution @xmath198 can be written in the vector form @xmath199 here the initial value is @xmath200 and @xmath4 is a standard @xmath59-brownian motion .",
    "+   + in the abbreviated notation , the maximal expected reward in equation ( [ opt value 2.3.2 ] ) can be written as @xmath201.\\ ] ] the rest of this section will use the above abbreviated notations .    [ lem dpp 2.1]*dynamic programming principle . * for any @xmath202 , and any @xmath98 , let @xmath203 be the set of admissible interventions @xmath204 such that @xmath205 .",
    "suppose the current value of the state process @xmath206 .",
    "there exist deterministic measurable functions @xmath207 @xmath208 , such that @xmath209 , \\end{split}\\ ] ] for @xmath210 , and @xmath211 .",
    "\\end{split}\\ ] ] the value functions @xmath212 satisfy the dynamic programming principle @xmath213 @xmath214.\\ ] ]    * proof : * the existence of the functions @xmath215 comes from the markovian structure of the state process @xmath216 , by lemma [ lem markov 2.1 ] .    to prove the equation ( [ dpp 2.1 ] ) , fix an arbitrary @xmath217 , an arbitrary @xmath218 $ ] and arbitrary admissible interventions @xmath219",
    ", we denote @xmath220 then @xmath221\\\\ = \\,&\\,{\\mathbb e } ^0\\left[\\left.a_k(t)+{\\mathbb e } ^0\\left[b_k\\left|{\\textbf{f}}(\\tau_{n - k+1})\\right.\\right]\\right|{\\textbf{f}}(t)\\right ] .",
    "\\end{split}\\ ] ] on one hand , taking supremum over @xmath222 on both sides of the inequality @xmath223\\right|{\\textbf{f}}(t)\\right]\\\\",
    "\\leq \\,&\\,{\\mathbb e } ^0\\left[\\left.a_k(t)+v_{k-1 } ( \\tau_{n - k+1},\\gamma(y(\\tau_{n - k+1}),\\zeta_{n - k+1}))\\right|{\\textbf{f}}(t)\\right ] \\end{split}\\ ] ] shows @xmath224 less than or equal to the right hand side of ( [ dpp 2.1 ] ) . on the other hand",
    ", the inequality @xmath225\\right|{\\textbf{f}}(t)\\right]\\ ] ] implies @xmath226\\ ] ] and thus @xmath224 greater than or equal to the right hand side of ( [ dpp 2.1 ] ) .",
    "see @xcite fleming & soner ( 1993 ) , @xcite krylov ( 1980 ) or @xcite pham ( 2009 ) for a more detailed account for the dynamic programming principle .",
    "@xmath132    [ lem cont ] the value functions @xmath215 defined in ( [ opt value 2.5 ] ) and ( [ opt value 2.5.1 ] ) are continuous in @xmath227 .",
    "over the compact set @xmath189 , they admit moduli of continuity @xmath228 , uniformly for all @xmath98 , meaning that @xmath229\\times \\bar{{\\textbf{o}}}_n.\\ ] ]    * proof : * by the continuity of solutions to sdes ( theorem 5.2 in chapter ii on page 229 of @xcite kunita ( 1982 ) ) , and by the continuity of the function @xmath80 given in assumption [ assump rwd 1.1 ] ( iii ) , the unique strong solution to the controlled sde ( [ sde 1.4 ] ) is continuous in its initial value @xmath230 .",
    "we shall also use the continuity of the functions @xmath135 and @xmath137 in equations ( [ cross var 1.1 ] ) and ( [ cross var 2.1 ] ) , assumption [ assump rwd 1.1 ] ( ii)(iii ) and the uniform integrability lemma [ lem ui 1.1 ] .",
    "inductively applying the proof of proposition 2.2 in @xcite jaillet , lamberton and lapeyre ( 1990 ) to @xmath231 , for @xmath232 , we know that the value functions @xmath215 are continuous in @xmath227 .    restricted on the compact set @xmath233\\times \\bar{{\\textbf{o}}}_n$ ] , the value functions @xmath215 are uniformly continuous in @xmath234 , hence they admit moduli of continuity @xmath235 in the space variable @xmath236 , for all @xmath237 $ ] .",
    "@xmath132    the collection of all continuous functions over the domain @xmath192 , which admit the modulus of continuity @xmath235 for @xmath238 in the compact set @xmath189 uniformly for all @xmath98 , is denoted as @xmath239 .",
    "it is the very set of properties described in lemma [ lem cont ] .",
    "+   + the optimal impulse controls are then obtained in terms of the value functions @xmath215 , and of the triple @xmath240 .",
    "the triple @xmath240 of processes in ( [ sde 1.4 ] ) , which is adapted to the filtration @xmath49 generated by the observation @xmath46 , can be viewed as a  sufficient statistic \" for the optimization problem ( [ opt value 2.1.0 ] ) .",
    "this  sufficient statistic \" that the decision maker needs to monitor remains the same for all cumulative reward functions @xmath85 , all impulse control costs @xmath241 and all terminal reward functions @xmath82 in ( [ opt value 2.1.0 ] ) .",
    "[ prop optimal contr ] ( iterative procedure for optimization ) for any measurable function @xmath242 , define a mapping @xmath243 by @xmath244 for every @xmath245 , iteratively define an @xmath49-stopping time @xmath246 with the convention that @xmath247 .",
    "suppose the supremum @xmath248 can be attained by a real number @xmath249 , and define an @xmath250-measurable random variable @xmath251 for every @xmath245 .",
    "then the suprema in ( [ opt value 2.1.0 ] ) and ( [ opt value 2.1 ] ) are attained by the set of impulse controls @xmath252 in @xmath42 . furthermore , the maximal expected rewards @xmath253 and @xmath254 .    when bensoussan and lions were originally formulating the impulse control problem in the 1970 s , their number of interventions @xmath255 .",
    "there is no fundamental difference whether @xmath34 is finite or infinite , except that slightly different technical conditions on the coefficients and the admissible control set are required to derive properties like well - posedness , continuity and even differentiability of the value function .",
    "it has been pointed out by bensoussan and lions in theorem 4 of @xcite that the value function of @xmath34 interventions converges to that of infinitely many interventions , as @xmath256 . to extend results in this paper to @xmath255 means modifying the technical assumptions .",
    "in this part , we discuss how to approximate the optimal stopping time distribution @xmath257)$ ] thanks to a monte carlo simulation , and use the results for constructing a trading strategy .",
    "thus , we start by introducing in section [ sec41 ] the example on which we implement the theoretical setting of sections [ subsec measure change ] and [ subsec solution ] . then , we present in section [ sec42 ] a method based on longstaff - schwartz algorithm to simulate the optimal stopping times @xmath258 family . in section [ sec43 ] ,",
    "we give a simple static trading strategy that allows to test the simulation results .      to illustrate the model ( [ sde impulse 2.1 ] ) , we discuss geometric brownian motion as a commonly seen simple example .",
    "the parameter @xmath10 is the drift with the initial value @xmath15 .",
    "the random variable @xmath3 has the prior distribution @xmath259 and @xmath2 has an exponential @xmath260 prior distribution as in ( [ rho prior 1.1 ] ) .",
    "the diffusion @xmath46 in ( [ sde impulse 2.1 ] ) is the geometric brownian motion @xmath261 in this example , the volatility @xmath262 is a deterministic positive number .",
    "the parameter @xmath10 with the initial value @xmath15 is the percentage drift of the geometric brownian motion .",
    "suppose @xmath46 is the price process of a certain stock , and there is zero interest rate , no transaction cost and no price impact . observing the price evolution only , an optimal trading problem is finding two stopping times @xmath263 in @xmath50 , to achieve the supremum in @xmath264.\\ ] ] in terms of the money received , the value ( [ opt value 2.8 ] ) is the best possible average profit from first buying , then selling , one share of this stock . comparing the sdes ( [ gbm 1.2.1 ] ) and ( [ sde impulse 2.1 ] ) , and the goal ( [ opt value 2.1.0 ] ) with ( [ opt value 2.8 ] ) , we are trying to solve the impulse control problem with @xmath265 , @xmath266 and @xmath267 .",
    "we should set @xmath268 for @xmath269 and @xmath88 , @xmath270 , @xmath271 and @xmath272 . to incorporate transaction costs and price impact , it only remains to modify the functions @xmath273 and @xmath274 .",
    "for the geometric brownian motion example , we may compute to get the likelihood ratio processes @xmath275 the process @xmath276 defined in ( [ lr 1.2 ] ) can then be written as @xmath277 for @xmath20 .",
    "the dimensionality of the variational inequality can be reduced , by using this alternative expression of @xmath278 in terms of @xmath279 . substituting @xmath280 , @xmath265 , @xmath266 , @xmath267 and @xmath268 in two the functions @xmath135 and",
    "@xmath137 defined in ( [ cross var 1.1 ] ) and ( [ cross var 2.1 ] ) , we get @xmath281 @xmath282    under the measure @xmath59 , the supremum in ( [ opt value 2.8 ] ) becomes @xmath283\\\\ = \\sup\\limits_{\\tau_1\\text { and } \\tau_2\\in { \\textbf{s}}\\text { , } \\tau_1\\leq\\tau_2 } { \\mathbb e } ^0&\\left[\\bar{\\beta}(\\tau_2,x(\\tau_2),r(\\tau_2),1)+ \\bar{\\beta}(\\tau_1,x(\\tau_1),r(\\tau_1),-1)\\right ] .",
    "\\end{split}\\ ] ] there exist deterministic measurable functions @xmath284 and @xmath285\\times(0,\\infty)\\times [ 0,\\infty)^2 $ ] , such that @xmath286;\\\\ \\bar{v}_2(t , x(t),r(t))=&\\sup\\limits_{\\tau_1\\in{\\textbf{s}}_t } { \\mathbb e } ^0\\left[\\bar{\\beta}(\\tau_1,x(\\tau_1),r(\\tau_1),-1 ) + \\bar{v}_1(\\tau_1,x(\\tau_1),r(\\tau_1))\\left|{\\textbf{f}}(t)\\right.\\right ] .",
    "\\end{split } \\label{v1v2}\\ ] ] the optimal value of the round - way transaction is @xmath287=\\bar{v}_2(0,x(0),\\mathbf{0}).\\ ] ]      proposed in @xcite for pricing american options , the longstaff - schwartz procedure was rigourously formulated by clment , lamberton and protter ( 2002 ) in @xcite using stopping times instead of the value function for the dynamic programming algorithm .",
    "this method also involves a regression approximation of the conditional expectation and the discretization of the interval on which the stopping times take their values .",
    "the convergence due to each approximation step is studied in @xcite and we aim at reusing this algorithm for our multiple optimal stopping problem",
    ".    applied also by tsitsiklis and van roy ( 2001 ) in @xcite , the regression approximation of the conditional expectation was extended to bsdes ( backward stochastic differential equations ) by gobet , lemor and warin ( 2005 ) in @xcite .",
    "the regression approximation generally uses one regression vector for the whole set of trajectories and it is then considered as a global method .",
    "thus , other authors use more local approximations of the conditional expectation , based on either malliavin calculus as in @xcite or quantization method as in @xcite . to keep the presentation of our algorithm simple ,",
    "we apply a monomial regression method .",
    "however , one has to keep in mind that in some problems , especially when the dimension becomes high ( more than two assets ) , a good approximation of the conditional expectation is a key ingredient .    to proceed , we first need to approach stopping times in @xmath50 with stopping times taking values in the finite set @xmath288 .",
    "then , the computation of can be reduced to the implementation of two dynamic programming algorithms that we express in terms of the optimal stopping times @xmath289 and @xmath290 , for each path , as follows @xmath291 @xmath292 and , denoting @xmath293 the conditional expectation knowing @xmath294 , the sets @xmath295 and @xmath296 are given by @xmath297 \\right\\ } ; \\vspace{2mm}\\\\ a_{2k } \\hspace{-1 mm } = \\hspace{-1 mm } \\left\\ { \\begin{array}{c } \\bar{\\beta}(t_k , x(t_k),r(t_k),-1 ) \\vspace{1 mm } \\\\ + \\bar{v}_1(t_{k},x(t_{k}),r(t_{k } ) ) \\end{array } > { \\mathbb e } ^0_{t_k } \\hspace{-1 mm } \\left[\\bar{v}_2(t_{k+1},x(t_{k+1}),r(t_{k+1 } ) ) \\right ] \\right\\}. \\end{array } \\label{a1a2}\\end{aligned}\\ ] ]    while the simulation of @xmath298 under @xmath59 is straightforward , the simulation of @xmath299 is performed thanks to a trapezoidal approximation of the time integral applied in @xcite for asian options .",
    "it remains then to compute @xmath300 $ ] for @xmath301 . employing the markov property established in lemma [ lem markov 2.1 ]",
    ", a conditional expectation according to @xmath294 can be replaced by a conditional expectation according to @xmath302 . in our application",
    ", this latter quantity will be approximated by a regression on the monomial family @xmath303 .",
    "formally , for the auxiliary functions @xmath304 , @xmath301 @xmath305 the vector @xmath306 minimizes the quadratic error @xmath307 and thus equal to @xmath308 where the matrix @xmath309 and @xmath310 is the transpose operator .",
    "consequently , at each time step , the matrix inversion ( [ valch1 ] ) can be implemented by the singular value decomposition ( svd ) explained in @xcite and the expectations are approximated by an arithmetic average @xmath311 @xmath312 and @xmath313 is the number of simulated trajectories .",
    "then , using @xmath314 known from @xmath315,0 \\right)\\ ] ] is the approximation of .",
    "also , for @xmath301 we make the approximation @xmath316 ) \\approx { \\mathbb{p}}^0 ( \\tau^1_i = t_{k+1}).\\ ] ] finally , we should point out that the proposed procedure can be generalized for more than two optimal stopping times .",
    "the convergence of the overall algorithm can be established in the same way as it is presented in @xcite for one optimal stopping time . besides",
    ", the reader should notice that we only considered the deterministic case @xmath270 , @xmath271 and @xmath272 .",
    "in fact , one can propose a randomized version of the algorithm proposed above that includes an optimization over @xmath317 , however our purpose here is only to give an illustration of a simple case . as a future work",
    ", we will study the convergence of a more general method for impulse control based on the multiple optimal stopping times algorithm presented above .      to present this trading strategy , we need first to change the probability measure and go back to @xmath54 thanks to and the simulation of @xmath318 using . for @xmath301",
    ", we obtain then the approximation @xmath319 ) \\approx { \\mathbb e } ^0 \\left ( z(t_{k+1 } ) 1_{\\tau^1_i = t_{k+1 } } \\right).\\ ] ]    now , let us assume that we can buy and sell not only one stock but a bigger volume @xmath320 of stocks .",
    "consequently , one can use the approximation @xmath321 \\approx q \\max \\left({\\mathbb e } ^0\\left[\\bar{v}_2(\\tau^1_1,x(\\tau^1_1),r(\\tau^1_1))\\right],0 \\right).\\ ] ] using the value obtained in , we decide at a first stage if it is interesting to trade or not .",
    "indeed , if this value is not big `` enough '' then it is not worthwhile taking the trading risks of losing money .",
    "in this one dimensional example , one should invest on @xmath298 only if it is drifting more positively than negatively . besides , if we are satisfied by the expected profits , we can establish the following static trading strategy on the spot prices @xmath322 for @xmath323 : the money received is @xmath324 ) - { \\mathbb{p}}(\\tau^*_1 \\in ( t_{k } , t_{k+1}])\\right ] x(t_{k+1}),\\ m^{r*}_{0 } = 0.\\end{aligned}\\ ] ] @xmath325 can take negative values which mean that we are buying stocks .",
    "we are going to compare @xmath326 to @xmath327 where @xmath328 is defined by @xmath329 x(t_{k+1}),\\ m^{r}_{0 } = 0.\\ ] ] and the quantities @xmath330 , @xmath331 are simulated thanks to the following increasing induction on @xmath323 @xmath332 where @xmath333 is the uniform law on @xmath334 $ ] .    consequently , we are going to compare the money earned from our static trading strategy to some @xmath335 arbitrary strategies specified by .",
    "we process this comparison on a large number @xmath336 ( given later ) of newly simulated trajectories of @xmath298 under the probability @xmath54 . in the following ,",
    "we denote respectively by @xmath337 and @xmath338 the average value of @xmath326 and @xmath327 on the @xmath336 newly simulated trajectories of @xmath298 .",
    "also we denote by @xmath339 and @xmath340 the maximum value of respectively @xmath326 and @xmath327 on the @xmath336 newly simulated trajectories of @xmath298 .",
    "although we tested our algorithm for a large number of model parameters , we present here the results associated to only one choice of values .",
    "we refer the reader to the first author web page to download the c++ code of the algorithm in order to test it with other parameters values .",
    "figures [ fig1 ] , [ fig2 ] and [ fig3 ] involve the following choice : number of simulated trajectories for longstaff - schwartz algorithm @xmath341 , number of time steps @xmath342 , @xmath343 , @xmath344 , @xmath345 @xmath346 , @xmath347 , @xmath348 , @xmath349 and @xmath350 .    using @xmath351 new scenarios of the evolution of @xmath298 ,",
    "we compare in figures [ fig1 ] and [ fig2 ] the average profit as well as the maximum profit generated by the @xmath352 arbitrary strategies to the ones generated by the static optimal strategy . in figure [ fig1 ] , the optimal strategy outperforms all the arbitrary strategies which confirms the effectiveness of the method implemented in section [ sec42 ] . moreover , even the maximum profit provided by the optimal strategy is among the best according to figure [ fig2 ] . in figure",
    "[ fig3 ] , we show the stability of the optimal strategy to reach the average value of profits even for small numbers of scenarios @xmath353 .    to conclude this section , although one can establish more elaborate trading strategies using the approximated values of @xmath257)$ ] , the one that we provided in this section allowed us to show the efficiency of the longstaff - schwartz algorithm for multiple optimal stopping times .",
    "in section [ sec51 ] , we discuss how the change of measure method can be extended to the multidimensional case . in section [ sec52 ] ,",
    "we briefly present the posterior probabilities method and explain what make it difficult to apply to the multidimensional partially - observed control problems .      the measure change method proposed in section [ sec general theory 2.2 ]",
    "can be extended to the case when the diffusion in section [ subsec 2.1 ] is multidimensional , mostly by replacing the notations for scalars to those for matrices",
    ". this subsection will give the multidimensional version of the formulae whose modifications are not very straightforward .",
    "suppose the diffusion @xmath46 in equation ( [ sde 1.2 ] ) becomes a @xmath354-dimensional process driven by a @xmath355-dimensional brownian motion @xmath4 with independent components .",
    "correspondingly , the coefficients should be modified according to the dimensionality .    for any possible values @xmath20 ,",
    "the drift @xmath21\\times { \\mathbb{r}}^d \\rightarrow { \\mathbb{r}}^d$ ] is a mapping valued in @xmath356 and the volatility @xmath22\\times { \\mathbb{r}}^d \\rightarrow { \\mathbb{r}}^{d\\times d}$ ] is a @xmath357-matrix - valued mapping .",
    "let @xmath358 denote the euclidean norm .",
    "assumption [ assump sde 1.1 ] is replaced by assumption [ assump sde 5.1 ] .    [ assump sde 5.1 ] there exists a constant @xmath23 , such that + ( i ) for all @xmath24 , @xmath25\\times { \\mathbb{r}}^d$ ] , and for all @xmath26 , we have @xmath359 ( ii ) for all @xmath28\\times { \\mathbb{r}}^d$ ] and all @xmath26 , the matrix @xmath360 is invertible and @xmath361    the reward functions @xmath78 and @xmath362 , as well as the intervention impact @xmath80 and the reward from intervention @xmath363 , satisfy assumption [ assump rwd 5.1 ] instead of assumption [ assump rwd 1.1 ] .",
    "[ assump rwd 5.1 ] ( i ) the function @xmath82 is twice continuously differentiable , with first and second order derivatives denoted as @xmath364 and @xmath365 , for @xmath366 .",
    "+ ( ii ) the functions @xmath85 , @xmath82 , @xmath364 and @xmath365 are locally lipschitz and have polynomial growth , for @xmath366 .",
    "+ ( iii ) the function @xmath86 is bounded for all @xmath367 and @xmath88 , and the function @xmath89 has polynomial growth rate in @xmath367 uniformly for all @xmath88 .",
    "both functions @xmath86 and @xmath89 are continuous in @xmath90 , for any arbitrarily fixed @xmath88 .    to change between the physical measure @xmath54 and the reference probability measure @xmath59 , the likelihood ratio process ( [ lr 2.1 ] )",
    "is replaced by @xmath368 where @xmath310 is the transpose operator .",
    "then , by the same derivation as in section [ subsec measure change ] , we arrive at the impulse control problem ( [ opt value 2.3.1 ] ) under the reference probability measure @xmath59 .",
    "let @xmath369 denote the gradient operator of a function . instead of equations ( [ cross var 1.1 ] ) and ( [ cross var 2.1 ] )",
    ", the reward functions @xmath135 and @xmath137 in ( [ opt value 2.3.1 ] ) are defined as @xmath370 and @xmath371 the solution to the impulse control problem ( [ opt value 2.3.1 ] ) with the multidimensional @xmath46 process will follow exactly the same steps as in section [ subsec solution ] .",
    "the traditional method to reduce a partially - observed control problem to one with full observation is to augment the state process @xmath46 by the posterior probability processes @xmath372 this method is presented in section 2.4.6 of @xcite pham(2005 ) for a survey of the control problem and in chapter 9 of @xcite lipster and shiryaev ( 2001 ) for the derivation of the posterior expectation and probabilities . in this subsection",
    ", we shall first outline how to solve our problem in dimension one by the posterior probability method , modulus technical assumptions , and then briefly explore the relation between the two methods .",
    "+   + define a function @xmath373\\times { \\mathbb{r}}\\times [ 0,1]^{m+1}\\rightarrow { \\mathbb{r}}$ ] , @xmath374 , by @xmath375 .",
    "then the uncertain drift projected onto the observation filtration is @xmath376 = \\bar{b}(t , x(t),\\pi(t)).\\ ] ] let @xmath377 be the innovation brownian motion . given an arbitrary admissible impulse control @xmath154 , the augmented state process @xmath378 is a @xmath379-dimensional markov process on every time interval @xmath380 , for @xmath381 , because it is the unique strong solution to the controlled sde @xmath382 one can then use the state process @xmath378 to solve the impulse control problem ( [ opt value 2.1.0 ] ) under the physical measure , as a problem of full observation .",
    "the optimal impulse controls are represented through the routine dynamic programming arguments in terms of the value functions and the state process .",
    "+   + let us proceed to demonstrate that the posterior probability method and the measure change method are theoretically equivalent . comparing with those in lemma [ lem dpp 2.1 ] ,",
    "there exist value functions @xmath383 @xmath384\\times { \\mathbb{r}}\\times [ 0,1]^{m+1}\\rightarrow { \\mathbb{r}}$ ] such that @xmath385 , \\end{split}\\ ] ] for @xmath210 , and @xmath386 .",
    "\\end{split}\\ ] ] by the same reasoning that derives theorem [ thm contr ref meas ] , the two sets of value functions respectively from the posterior probability method and the measure change method are related by the equations @xmath387 for all @xmath87 , @xmath388^{m+1}$ ] , @xmath389 and @xmath390 . in the case where the conditions in the implicit mapping theorem are satisfied , there exists an implicit mapping @xmath391^{m+1}$ ] , @xmath392 , such that @xmath393 for all @xmath87 , @xmath389 and @xmath390 . the expression ( [ post prob relation 5.2 ] ) suggests that , when applicable , the value functions before and after the change of measure are different up to a change of variable .    despite of the above equivalence",
    ", the measure change method has an advantage in several dimensions when it comes to the numerical implementation of monte carlo .",
    "indeed , even when @xmath298 is one - dimensional , one can easily remark that the monte carlo simulation of is easier to perform and study than the simulation of . with the latter sdes system , one has to propose an efficient discretization scheme and prove its convergence with an error control .",
    "however , this is not standard even when @xmath394 .",
    "unlike , with , one needs only to use some usual methods of simulating diffusions as the ones presented in @xcite for @xmath298 , then simulate @xmath395 and @xmath299 as deterministic functionals of @xmath298 . when both @xmath298 and the brownian motion are @xmath354-dimensional processes , the contrast between the two methods become clearer .",
    "add to this the complexity of studying how the discretization error of effects the longstaff - schwartz multiple optimal stopping algorithm proposed in section [ sec42 ] .    to conclude this section",
    ", we would like to point out that the method based on posterior probabilities is theoretically equivalent to the change of probability method .",
    "moreover , to solve the problem when @xmath394 , one can use some discretization and weak convergence for both methods ( we refer to @xcite for more details ) . nevertheless , when implementing an algorithm based on monte carlo as longstaff - schwartz , the use of the change of probability is more appropriate and could be the method by default when @xmath396 .",
    "we would like to thank professor rama cont , professor paul feehan , professor steven shreve , professor ivan yutov , and especially professor huyn pham and dr .",
    "camelia pop , for helpful conversations with the third author .",
    "we are grateful to professor hitoshi ishii for sending to us some hard - to - find classical literature on viscosity solutions to hjb equations .",
    "the first author s research is supported by matheon .",
    "the second author s research is supported by the national science foundation under grant nsf - dms-09 - 05754 .",
    "i. karatzas and i - m .",
    "zamfirescu , _ martingale approach to stochastic differential games of control and stopping _ , the annals of probability , vol .",
    "36 , no . 4 ( 2008 ) , 1495 - 1527 .",
    "krylov , _ controlled diffusion processes _ , springer - verlag , 1980 ."
  ],
  "abstract_text": [
    "<S> this paper solves a bayes sequential impulse control problem for a diffusion , whose drift has an unobservable parameter with a change point . </S>",
    "<S> the partially - observed problem is reformulated into one with full observations , via a change of probability measure which removes the drift . </S>",
    "<S> the optimal impulse controls can be expressed in terms of the solutions and the current values of a markov process adapted to the observation filtration . </S>",
    "<S> we shall illustrate the application of our results using the longstaff - schwartz algorithm for multiple optimal stopping times in a geometric brownian motion stock price model with drift uncertainty .    </S>",
    "<S> * keywords * bayes sequential optimization ; impulse control ; change point ; change of measure ; longstaff - schwartz algorithm </S>"
  ]
}