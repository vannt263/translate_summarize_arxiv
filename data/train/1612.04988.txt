{
  "article_text": [
    "as digital information gains more and more prominence , there is now a trend to organize this information to make it easier to query and to derive insights .",
    "one such trend is the creation of large _ knowledge - bases _ ( kbs )  repositories of crisp , precise information , which are machine readable . indeed",
    "the creation of such knowledge - bases has been a goal for decades now with projects such as cyc @xcite and wordnet @xcite .    with advances in information extraction research , and the availability of large amounts of structured and unstructured",
    "( textual ) data , _ automatic _ construction of knowledge - bases are not only possible , but also desirable because of the coverage they can offer .",
    "there are already many such general - purpose knowledge - bases such as yago @xcite and dbpedia @xcite .",
    "moreover , projects such as openie @xcite and nell @xcite aim to extract information from unstructured textual sources on a large scale .",
    "however , as the technology to automatically build large knowledge - bases matures , there is a paucity of high quality and _ specialized _ kbs for specific domains .",
    "for some domains , for example , for the bio - medical domain , there are well - curated ontologies which partially address this gap ( see , for example , the gene ontology project @xcite ) . however , for domains such as computer science or it in general , where such curation efforts are hard and the field itself is rapidly growing , it becomes critical to revisit the automatic construction processes that take advantage of domain - specific resources .    in this paper , our aim is to automatically construct a _ technical _ knowledge - base , called teknowbase , of computer science concepts .",
    "one of the most important tasks in building any such `` vertical '' kb is the identification of the right kinds of resources .",
    "for example , even though wikipedia contains technical content , identifying the right subset of this content is crucial . similarly , while free online technical content , such as textbooks are available , it is important to identify what kind of extractions are possible .",
    "the identification of the right resources can sometimes yield bigger gains than using an elaborate information extraction technique .",
    "a preliminary examination of computer science - related resources show that information can be extracted from many different kinds of sources , including , wikipedia , technical websites such as webopedia , online textbooks , technical question answer fora such as stackoverflow , etc . by studying these resources more closely , we developed simple , but effective techniques to build teknowbase .",
    "our first step is to acquire a dictionary of concepts and entities relevant to computer science . using this dictionary",
    ", we can further extract relationships among them .",
    "we make use of the semantic web standard , rdf , where information is represented as triples of the form @xmath0subject@xmath1@xmath0predicate@xmath1@xmath0object@xmath1  in a nutshell , each triple makes a statement about the @xmath0subject@xmath1 .",
    "table [ tab : examples ] shows examples of the kind of triples we extract and the number of such triples in our knowledge - base .",
    "[ cols=\"<,<,<\",options=\"header \" , ]",
    "in this paper , we described the construction of teknowbase , a knowledge - base of technical concepts related to computer science .",
    "our approach consisted of two steps  constructing a dictionary of terms related to computer science and to extract relationships among them .",
    "we made use of both structured and unstructured information source to extract relationships .",
    "our experiments showed an accuracy of about 88% on a subset of triples .",
    "we further used our kb in a classification task and showed how the features generated using the kb can increase classification accuracy .    there are lot of improvements that can be made to our system , purely to increase coverage .",
    "we used simple techniques , such as surface patterns , to extract relationships from textual sources .",
    "we can try more complex , supervised techniques to do the same . in order to extract unknown relationships , we are interested in exploring open ie techniques in more detail , particularly in identifying interesting and uninteresting relationships .",
    "ashburner , m. , ball , c.a . ,",
    "blake , j.a . ,",
    "botstein , d. , butler , h. , cherry , j.m . ,",
    "davis , a.p .",
    ", dolinski , k. , dwight , s.s . ,",
    "eppig , j.t . ,",
    "harris , m.a . , hill , d.p .",
    ", issel - tarver , l. , kasarskis , a. , lewis , s. , matese , j.c . ,",
    "richardson , j.e . , ringwald , m. , rubin , g.m . ,",
    "sherlock , g. : gene ontology : tool for the unification of biology .",
    "nature genetics 25(1 ) , 2529 ( 2000 )              ferrucci , d.a .",
    ", 0001 , e.w.b . , chu - carroll , j. , fan , j. , gondek , d. , kalyanpur , a. , lally , a. , murdock , j.w . , nyberg , e. , prager , j.m . , schlaefer , n. , welty , c.a .",
    ": building watson - an overview of the deepqa project . ai magazine ( 2010 )        lehmann , j. , isele , r. , jakob , m. , jentzsch , a. , kontokostas , d. , mendes , p.n . ,",
    "hellmann , s. , morsey , m. , van kleef , p. , auer , s. , bizer , c. : dbpedia - a large - scale , multilingual knowledge base extracted from wikipedia .",
    "semantic web ( 2015 )"
  ],
  "abstract_text": [
    "<S> in this paper , we describe the construction of teknowbase , a knowledge - base of technical concepts in computer science . </S>",
    "<S> our main information sources are technical websites such as webopedia and techtarget as well as wikipedia and online textbooks . </S>",
    "<S> we divide the knowledge - base construction problem into two parts  the acquisition of entities and the extraction of relationships among these entities . </S>",
    "<S> our knowledge - base consists of approximately 100,000 triples . </S>",
    "<S> we conducted an evaluation on a sample of triples and report an accuracy of a little over 90% . </S>",
    "<S> we additionally conducted classification experiments on stackoverflow data with features from teknowbase and achieved improved classification accuracy . </S>"
  ]
}