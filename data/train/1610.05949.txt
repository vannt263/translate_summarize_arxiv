{
  "article_text": [
    "motion estimation from onboard sensors is currently a hot topic in robotics and computer vision communities , as it can enable emerging technologies such as autonomous cars , augmented and virtual reality , service robots and drone navigation . among different sensor modalities ,",
    "visual - inertial setups provide a cheap solution with great potential .",
    "on the one hand cameras provide rich information of the environment , which allows to build 3d models , localize the camera and recognize already visited places . on the other hand imu sensors provide self - motion information , allowing to recover metric scale for monocular vision , and to estimate gravity direction , rendering absolute pitch and roll of the sensor .",
    "visual - inertial fusion has been a very active research topic in the last years .",
    "the recent research is focus on tightly - coupled ( i.e. joint optimization of all sensor states ) visual - inertial odometry , using keyframe - based non - linear optimization @xcite or filtering @xcite .",
    "nevertheless these approaches are only able to compute incremental motion and lack the capability to close loops and reuse a map of an already mapped environment .",
    "this implies that estimated trajectory accumulates drift without bound , even if the sensor is always localizing in the same environment .",
    "this is due to the use of the marginalization of past states to maintain a constant computational cost @xcite , or the use of full smoothing @xcite , with an almost constant complexity in exploration but that can be as expensive as a batch method in the presence of loop closures @xcite .    in this paper",
    "we present visual - inertial orb - slam , to the best of our knowledge the first keyframe - based visual - inertial slam that is able to close loops and reuse its map .",
    "inspired by @xcite our tracking optimizes current frame assuming a fixed map , and our backend performs local bundle adjustment ( ba ) , optimizing a local window of keyframes , including an outer window of fixed keyframes that ensures global consistency .",
    "this approach allows for a constant time local ba , in contrast to full smoothing , and as not marginalizing past states we are able to reuse them .",
    "we detect large loops using place recognition and a lightweight pose - graph optimization , followed by full ba in a separate thread not to interfere with real - time operation .",
    "[ fig : view ] shows the reconstruction of our system in a sequence with continuous revisiting .",
    "both tracking and local ba work fixing states , which could potentially bias the solution , therefore we need a very good visual - inertial initialization that provides accurate state values before we start fixing states . to this end",
    "we propose in section [ sec : ini ] a novel imu initialization method that estimates scale , gravity direction , velocity , and gyroscope and accelerometer biases , by processing the keyframes created by orb - slam @xcite from a few seconds of video .",
    "in contrast to @xcite where vision and imu are jointly estimated , we only need to estimate the imu variables , as the vision part is already solved by orb - slam .",
    "we divide the initialization into simpler subproblems .",
    "we first propose a method to estimate gyroscope biases which are ignored in @xcite .",
    "we then solve scale and gravity without considering accelerometer bias , in a similar way to @xcite ( which ignored gyroscope biases and did not solve scale as it uses stereo vision ) .",
    "we then introduce the knowledge of gravity magnitude and solve for accelerometer bias , ignored in @xcite , also refining scale and gravity direction . in a final step",
    "we compute the velocity of all keyframes .",
    "we validate the method in real sequences , concluding that it is an efficient , reliable and accurate method that solves imu biases , gravity , velocity and scale .",
    "moreover our method is general and could be applied to any monocular slam system .",
    "the input for our visual - inertial orb - slam is a stream of imu measurements and monocular camera frames .",
    "we consider a conventional pinhole - camera model @xcite with a projection function @xmath1 , which transforms 3d points @xmath2 in camera reference @xmath3 , into 2d points on the image plane @xmath4 : @xmath5 f_v\\frac{y_\\mathtt{c}}{z_\\mathtt{c } } + c_v \\end{bmatrix } ,   \\quad \\mathbf{x_\\mathtt{c}}=\\left[x_\\mathtt{c}\\,\\,y_\\mathtt{c}\\,\\,z_\\mathtt{c}\\right]^t\\ ] ] where @xmath6^t$ ] is the focal length and @xmath7^t$ ] the principal point .",
    "this projection function does not consider the distortion produced by the camera lens .",
    "when we extract keypoints on the image , we undistort their coordinates so that they can be matched to projected points using .",
    "the imu , whose reference we denote with @xmath8 , measures the acceleration @xmath9 and angular velocity @xmath10 of the sensor at regular intervals @xmath11 , typically at hundreds of herzs .",
    "both measurements are affected , in addition to sensor noise , by slowly varying biases @xmath12 and @xmath13 of the accelerometer and gyroscope respectively . moreover",
    "the accelerometer is subject to gravity @xmath14 and one needs to subtract its effect to compute the motion .",
    "the discrete evolution of the imu orientation @xmath15 , position @xmath16 and velocity @xmath17 , in the world reference @xmath18 , can be computed as follows @xcite : @xmath19    the motion between two consecutive keyframes can be defined in terms of the preintegration @xmath20 , @xmath21 and @xmath22 from all measurements in - between @xcite .",
    "we use the recent imu preintegration described in @xcite : @xmath23 where the jacobians @xmath24 and @xmath25 account for a first - order approximation of the effect of changing the biases without explicitly recomputing the preintegrations .",
    "both preintegrations and jacobians can be efficiently computed iteratively as imu measurements arrive @xcite .",
    "camera and imu are considered rigidly attached and the transformation @xmath26 $ ] between their reference systems known from calibration @xcite .",
    "the base of our visual - inertial system is orb - slam @xcite .",
    "this system has three parallel threads for tracking , local mapping and loop closing .",
    "the system is designed to work on large scale environments , by building a covisibility graph that allows to recover local maps for tracking and mapping , and by performing lightweight pose - graph optimizations at loop closure .",
    "in addition orb - slam allows to build a map of an environment and switch to a less cpu - intensive _ localization - only _ mode ( i.e. mapping and loop closing are disabled ) , thanks to the relocalization capability of the system .",
    "orb - slam is open - source and has been extensively evaluated on public datasets achieving top performing results . in this section",
    "we detail the main changes in visual - inertial orb - slam with respect to the original system .",
    "our system initializes first using only monocular vision , as in the original orb - slam . after few seconds",
    "it performs a specific initialization of the scale , gravity direction , velocity , and accelerometer and gyroscope biases .",
    "the reason for this delayed initialization is twofold .",
    "firstly the sensor has to perform a motion that makes all variables observable .",
    "secondly our tracking and local ba works fixing old keyframes in the optimization .",
    "we need these values to have converged , before we can actually fix a keyframe .",
    "this imu initialization is detailed in section [ sec : ini ] .",
    "our visual - inertial tracking is in charge of tracking sensor pose , velocity and imu biases , at frame - rate .",
    "this allows us to predict the camera pose very reliably , instead of using an ad - hoc motion model as in the original monocular system .",
    "once the camera pose is predicted , the map points in the local map are projected and matched with keypoints on the frame .",
    "we then optimize current frame @xmath27 by minimizing the feature reprojection error of all matched points and an imu error term .",
    "this optimization is different depending on the map being updated or not by the local mapping or the loop closing thread , as illustrated in fig .",
    "[ fig : tr ] .    when tracking is performed just after a map update , the imu error term links current frame j with last keyframe @xmath28 : @xmath29 where the feature reprojection error @xmath30 for a given match , is defined as follows : @xmath31 where @xmath32 is the keypoint location in the image , @xmath33 the map point in world coordinates , and @xmath34 the information matrix associated to keypoint scale .",
    "the imu error term @xmath35 is : @xmath36   \\bm{\\sigma}_i \\left[\\mathbf{e}^t_r \\ ,",
    "\\mathbf{e}^t_v \\ , \\mathbf{e}^t_p\\right]^t\\right ) \\\\ + \\rho",
    "\\left(\\mathbf{e}^t_b\\bm{\\sigma}_{r}\\mathbf{e}_b\\right ) \\\\ \\begin{aligned }   \\mathbf{e}_r & = \\mathrm{log } \\left(\\left(\\delta \\mathbf{r}_{ij } \\mathrm{exp}\\left(\\mathbf{j}^g_{\\delta r}\\mathbf{b}^j_g \\right)\\right)^t   \\mathbf{r}_\\mathtt{bw}^i \\mathbf{r}_\\mathtt{wb}^j\\right ) \\\\",
    "\\mathbf{e}_v & = \\mathbf{r}_\\mathtt{bw}^i \\left(_\\mathtt{w}\\mathbf{v}_\\mathtt{b}^j-{_\\mathtt{w}\\mathbf{v}_\\mathtt{b}^i}- \\mathbf{g}_\\mathtt{w } \\delta t_{ij}\\right ) \\\\ & -\\left ( \\delta \\mathbf{v}_{ij } + \\mathbf{j}^g_{\\delta v }",
    "\\mathbf{b}^j_g   +   \\mathbf{j}^a_{\\delta v } \\mathbf{b}^j_a\\right ) \\\\",
    "\\mathbf{e}_p & = \\mathbf{r}_\\mathtt{bw}^i \\left(_\\mathtt{w}\\mathbf{p}_\\mathtt{b}^j-{_\\mathtt{w}\\mathbf{p}_\\mathtt{b}^i } -{_\\mathtt{w}\\mathbf{v}_\\mathtt{b}^i } \\delta t_{ij } - \\frac{1}{2 } \\mathbf{g}_\\mathtt{w } \\delta t_{ij}^2\\right ) \\\\ & -\\left ( \\delta \\mathbf{p}_{ij } + \\mathbf{j}^g_{\\delta p } \\mathbf{b}^j_g   +   \\mathbf{j}^a_{\\delta p } \\mathbf{b}^j_a\\right ) \\\\",
    "\\mathbf{e}_b & = \\mathbf{b}^j-\\mathbf{b}^i   \\end{aligned }   \\end{gathered}\\ ] ] where @xmath37 is the information matrix of the preintegration and @xmath38 of the bias random walk @xcite , and @xmath39 is the huber robust cost function .",
    "we solve this optimization problem with gauss - newton algorithm implemented in g2o @xcite .",
    "after the optimization , the resulting estimation and hessian matrix serves as prior for next optimization .    assuming no map update , the next frame @xmath40 will be optimized with a link to frame @xmath27 and using the prior computed in the previous optimization : @xmath41 where @xmath42 is a prior term : @xmath43 \\bm{\\sigma}_p    \\left[\\mathbf{e}^t_r \\ , \\mathbf{e}^t_v \\ , \\mathbf{e}^t_p \\",
    ", \\mathbf{e}^t_b\\right]^t\\right ) \\\\ \\begin{aligned }   \\mathbf{e}_r & = \\mathrm{log } \\left(\\mathbf{\\bar{r}}_\\mathtt{bw}^j \\mathbf{r}_\\mathtt{wb}^j\\right ) & \\mathbf{e}_v   = \\mathbf{_\\mathtt{w}\\bar{v}}_\\mathtt{b}^j-{_\\mathtt{w}\\mathbf{v}_\\mathtt{b}^j } \\\\",
    "\\mathbf{e}_p   & = { _ \\mathtt{w}\\mathbf{\\bar{p}}_\\mathtt{b}^j}-{_\\mathtt{w}\\mathbf{p}_\\mathtt{b}^j }   & \\mathbf{e}_b   = \\mathbf{\\bar{b}}^j-\\mathbf{b}^j \\end{aligned } \\end{gathered}\\ ] ] where @xmath44 are the estimated states from previous optimization and @xmath45 the prior information matrix ( i.e. the resulting hessian matrix from previous optimization ) .",
    "after this optimization , frame @xmath27 is marginalized out @xcite .",
    "this optimization linking two consecutive frames and using a prior is performed until a map change , when the prior will be no longer valid .",
    "note that this is the optimization that is always performed in _ localization - only _ mode , as the map is not updated .",
    "the local mapping performs local ba after a new keyframe insertion .",
    "it optimizes the last @xmath46 keyframes ( local window ) and all points seen by those @xmath46 keyframes .",
    "all other keyframes that share observations of local points ( i.e. are connected in the covisibility graph to any local keyframe ) , but are not in the local window , contribute to the total cost but are fixed during optimization ( fixed window ) .",
    "the keyframe @xmath47 is always included in the fixed window as it constraints the imu states .",
    "[ fig : ba ] illustrates the differences between local ba in original orb - slam and visual - inertial orb - slam .",
    "the cost function is a combination of imu error terms and reprojection error terms .",
    "note that the visual - inertial version , compared to the vision only , is more complex as there are 9 additional states ( velocity and biases ) to optimize per keyframe .",
    "a suitable local window size has to be chosen for real - time performance .",
    "the local mapping is also in charge of keyframe management .",
    "the original orb - slam policy discards redundant keyframes , so that map size does not grow if localizing in a well mapped area .",
    "this policy is problematic for using imu information , which constraints the motion of consecutive keyframes .",
    "the longer the temporal difference between consecutive keyframes , the weaker information imu provides .",
    "therefore we allow the mapping to discard redundant keyframes , if that does not make two consecutive keyframes in the local window of local ba to differ more than @xmath48 . to be able to perform full ba , after a loop closure or at any time to refine a map",
    ", we do not allow any two consecutive keyframes to differ more than 3s .",
    "if we switched - off full ba with imu constraints , we would only need to restrict the temporal offset between keyframes in the local window .",
    "+   +   +      the loop closing thread aims to reduce the drift accumulated during exploration , when returning to an already mapped area .",
    "the place recognition module matches a recent keyframe with a past keyframe .",
    "this match is validated computing a rigid body transformation that aligns matched points between keyframes @xcite .",
    "finally an optimization is carried out to reduce the error accumulated in the trajectory .",
    "this optimization might be very costly in large maps , therefore the strategy is to perform a pose - graph optimization , which reduces the complexity , as structure is ignored , and exhibits good convergence as shown in @xcite .",
    "in contrast to the original orb - slam , we perform the pose - graph on 6 degrees of freedom ( dof ) instead of 7 dof @xcite , as scale is observable .",
    "this pose - graph ignores imu information , not optimizing velocity or imu biases .",
    "therefore we correct velocities by rotating them according to the corrected orientation of the associated keyframe .",
    "while this is not optimal , biases and velocities should be locally accurate to continue using imu information right after pose - graph optimization .",
    "we perform afterwards a full ba in a parallel thread that optimizes all states , including velocities and biases .",
    "we propose in this section a method for scale , gravity direction , velocity and imu biases estimation , given a set of keyframes processed by a monocular slam algorithm .",
    "the idea is to run the monocular slam for a few seconds , assuming the sensor performs a motion that make all variables observable .",
    "while we build on orb - slam @xcite , any other slam could be used .",
    "the only requirement is that any two consecutive keyframes are close in time ( see section [ sec : mapping ] ) , to reduce imu noise integration .",
    "the initialization is divided in simpler subproblems : ( 1 ) gyroscopes biases estimation , ( 2 ) scale and gravity approximation , considering no accelerometer bias , ( 3 ) accelerometer biases estimation , and scale and gravity direction refinement , and ( 4 ) velocity estimation .      gyroscope bias can be estimated just from the known orientation of two consecutive keyframes . assuming a negligible bias change , we optimize a constant bias @xmath13 , which minimizes the difference between gyroscope integration and relative orientation computed from orb - slam , for all two consecutive keyframes : @xmath49 where @xmath46 is the number of keyframes .",
    "@xmath50 is computed from the orientation @xmath51 computed by orb - slam and calibration @xmath52 .",
    "@xmath53 is the gyroscope integration between two consecutive keyframes .",
    "we solve with gauss - newton with a zero bias seed .",
    "analytic jacobians for a similar expression can be found in @xcite .",
    "once we have estimated the gyroscope bias , we can preintegrate velocities and positions , rotating correctly the acceleration measurements compensating the gyroscope bias .",
    "the scale of the camera trajectory computed by orb - slam is arbitrary .",
    "therefore we need to include a scale factor @xmath54 when transforming between camera @xmath3 and imu @xmath8 coordinate systems : @xmath55    substituting into the equation relating position of two consecutive keyframes , and neglecting at this point accelerometer bias , it follows : @xmath56    the goal is to estimate @xmath54 and @xmath14 by solving a linear system of equations on those variables . to avoid solving for @xmath46 velocities , and",
    "reduce complexity , we consider two relations between three consecutive keyframes and use velocity relation in , which results in the following expression : @xmath57 where , writing keyframes @xmath58 as @xmath59 for clarity notation , we have : @xmath60    we stack then all relations of three consecutive keyframes into a system @xmath61 which can be solved via singular value decomposition ( svd ) to get the scale factor @xmath62 and gravity vector @xmath63 .",
    "note that we have @xmath64 equations and 4 unknowns , therefore we need at least 4 keyframes .",
    "so far we have not considered accelerometer bias when computing scale and gravity .",
    "just incorporating accelerometer biases in will heavily increase the chance of having an ill - conditioned system , because gravity and accelerometer biases are hard to distinguish @xcite . to increase observability",
    "we introduce new information we did not considered so far , which is the gravity magnitude @xmath65 .",
    "consider an inertial reference @xmath66 with the gravity direction @xmath67 , and the already computed gravity direction @xmath68 .",
    "we can compute rotation @xmath69 as follows : @xmath70 and express now gravity vector as : @xmath71 where @xmath69 can be parametrized with just two angles around x and y axes in @xmath72 , because a rotation around z axis , which is aligned with gravity , has no effect in @xmath14 .",
    "this rotation can be optimized using a perturbation @xmath73 : @xmath74^t , \\quad \\bm{\\delta \\theta_{xy}}= \\left[\\delta\\theta_x   \\,\\ , \\delta\\theta_y \\right]^t   \\end{gathered}\\ ] ] with a first - order approximation : @xmath75    substituting in and including now the effect of accelerometer bias , we obtain : @xmath76    considering three consecutive keyframes as in we can get rid of velocities and get the following relation : @xmath77 where @xmath78 remains the same as in , and @xmath79 , @xmath80 , and @xmath81 are computed as follows : @xmath82_{(:,1:2 ) }   \\\\",
    "\\bm{\\zeta}(i ) & = \\mathbf{r}^{2}_\\mathtt{wb } \\mathbf{j}^a_{\\delta p_{23}}\\delta t_{12 } + \\mathbf{r}^{1}_\\mathtt{wb }",
    "\\mathbf{j}^a_{\\delta v_{23}}\\delta t_{12}\\delta t_{23 }   \\\\   & - \\mathbf{r}^{1}_\\mathtt{wb } \\mathbf{j}^a_{\\delta p_{12}}\\delta t_{23 }    \\\\",
    "\\bm{\\psi}(i ) & = \\left(\\mathbf{r}^{2}_\\mathtt{wc}-\\mathbf{r}^{1}_\\mathtt{wc}\\right){_\\mathtt{c}\\mathbf{p}_\\mathtt{b } } \\delta t_{23 }   - \\left(\\mathbf{r}^{3}_\\mathtt{wc}-\\mathbf{r}^{2}_\\mathtt{wc}\\right){_\\mathtt{c}\\mathbf{p}_\\mathtt{b}}\\delta t_{12 }    \\\\   & +   \\mathbf{r}^{2}_\\mathtt{wb } \\delta \\mathbf{p}_{23 }   \\delta t_{12 } +   \\mathbf{r}^{1}_\\mathtt{wb } \\delta \\mathbf{v}_{12 } \\delta t_{12 } \\delta t_{23 }   \\\\   & - \\mathbf{r}^{1}_\\mathtt{wb } \\delta \\mathbf{p}_{12 } \\delta t_{23 } + \\frac{1}{2 } \\mathbf{r}_\\mathtt{wi } \\ , \\hat{\\mathbf{g}}_\\mathtt{i } \\ , g \\delta t^2_{ij }   \\end{aligned}\\ ] ] where @xmath83_{(:,1:2)}$ ] means the first two columns of the matrix .",
    "stacking all relations between three consecutive keyframes we form a linear system of equations @xmath84 which can be solved via svd to get the scale factor @xmath62 , gravity direction correction @xmath85 and accelerometer bias @xmath86 . in this case",
    "we have @xmath64 equations and 6 unknowns and we need again at least 4 keyframes to solve the system",
    ". we can compute the condition number ( i.e. the ratio between the maximum and minimum singular value ) to check if the problem is well - conditioned ( i.e. the sensor has performed a motion that makes all variables observable ) .",
    "we could relinearize and iterate the solution , but in practice we saw that a second iteration does not produce a noticeable improvement .",
    "we considered relations of three consecutive keyframes in equations and , so that the resulting linear systems do not have the @xmath87 additional unknowns corresponding to velocities .",
    "the velocities for all keyframes can now be computed using equation , as scale , gravity and bias are known . to compute the velocity of the most recent keyframe",
    ", we use the velocity relation .",
    "when the system relocalizes after a long period of time , using place recognition , we reinitialize gyroscope biases by solving .",
    "the accelerometer bias is estimated by solving a simplified , where the only unknown is the bias , as scale and gravity are already known .",
    "we use 20 consecutive frames localized with only vision to estimate both biases .",
    "we evaluate the proposed imu initialization method , detailed in section [ sec : ini ] and our visual - inertial orb - slam in the euroc dataset @xcite .",
    "it contains 11 sequences recorded from a micro aerial vehicle ( mav ) , flying around two different rooms and an industrial environment .",
    "sequences are classified as _ easy _ , _ medium _ and _ difficult _ , depending on illumination , texture , fast / slow motions or motion blur .",
    "the dataset provides synchronized global shutter wvga stereo images at @xmath88 with imu measurements at @xmath89 and trajectory ground - truth .",
    "these characteristics make it a really useful dataset to test visual - inertial slam systems .",
    "the experiments were performed processing left images only , in an intel core i7 - 4700mq computer with 8 gb ram .",
    "+     +     +     +          we evaluate the imu initialization in sequences _",
    "v1_01_easy _ and _ v2_01_easy_. we run the imu initialization from scratch every time a new keyframe is inserted by orb - slam .",
    "we run the sequences at a lower frame - rate so that the repetitive initialization does not interfere with the normal behavior of the system .",
    "the goal is to analyze the convergence of the variables as more keyframes , i.e. longer trajectories , are processed by the initialization algorithm .",
    "[ fig : ini ] shows the estimated scale and imu biases .",
    "it can be seen that between 10 and 15 seconds all variables have already converged to stable values and that the estimated scale factor is really close to the optimal .",
    "this optimal scale factor is computed aligning the estimated trajectory with the ground - truth by a similarity transformation @xcite .",
    "[ fig : ini ] also shows the evolution in the condition number , indicating that some time is required to get a well - conditioned problem .",
    "this confirms that the sensor has to perform a motion that makes all variables observable , especially the accelerometer bias . the last row in fig .",
    "[ fig : ini ] shows the total time spent by the initialization algorithm , which exhibits a linear growth .",
    "this complexity is the result of not including velocities in and , which would have resulted in a quadratic complexity when using svd to solve these systems . subdividing the initialization in simpler subproblems , in contrast to @xcite , results in a very efficient method .",
    "the proposed initialization allows to start fusing imu information , as gravity , biases , scale and velocity are reliably estimated .",
    "for the euroc dataset , we observed that 15 seconds of mav exploration gives always an accurate initialization .",
    "as a future work we would like to investigate an automatic criterion to decide when we can consider an initialization successful , as we observed that an absolute threshold on the condition number is not reliable enough .",
    ".keyframe trajectory accuracy in euroc dataset [ cols=\"<,^,^,^,^ \" , ]     we evaluate the accuracy of our visual - inertial orb - slam in the 11 sequences of the euroc dataset .",
    "we start processing sequences when the mav starts exploring .",
    "the local window size for the local ba is set to 10 keyframes and the imu initialization is performed after 15 seconds from monocular orb - slam initialization .",
    "the system performs a full ba just after imu initialization .",
    "table [ t : acc ] shows the translation root mean square error ( rmse ) of the keyframe trajectory for each sequence , as proposed in @xcite .",
    "we use the raw vicon and leica ground - truth as the post - processed one already used imu .",
    "we observed a time offset between sensor and ground - truth of @xmath90 in the _ vicon _ _ room _ _ 2 _ sequences and @xmath91 in the _ machine _ _ hall _ , that we corrected when aligning both trajectories .",
    "we also measure the scale factor that would align best the estimated trajectory and ground - truth .",
    "this scale factor can be regarded as the residual scale error of the trajectory and reconstruction .",
    "our system is able to process all these sequences in real - time , except sequence _ v1_03_difficult _",
    ", where the movement is too extreme for the monocular system to initialize .",
    "the results show that our system is able to recover motion with metric scale , with a scale error typically below @xmath0 .",
    "the system achieves a typical precision of @xmath92 for @xmath93 room environments and of @xmath94 for @xmath95 industrial environments .",
    "note that our system is able to close loops and localize using the existing map when revisiting , which avoids drift accumulation .",
    "these results can be improved by applying a full ba afterwards , as seen in table [ t : acc ] .",
    "the reconstruction for sequence _",
    "v1_02_medium _ can be seen in fig .",
    "[ fig : view ] , and in the accompanying video .    in order to test the capability of our system to reuse a previous map of an environment ,",
    "we run in a row all sequences of the same scene .",
    "we first process the first sequence and perform a full ba",
    ". then we run the rest of the sequences , where our system performs relocalization and continue doing slam .",
    "we then compare the accumulated keyframe trajectory with the ground - truth .",
    "bottom rows of table [ t : acc ] show accuracy results .",
    "as there exists a previous map , our system is now able to localize the camera in sequence _ v1_03_difficult_.",
    "these results show that there is no drift accumulation when revisiting the same scene , as the rmse for all sequences is not larger than for individual sequences .",
    "we have compared our system with the state - of - the - art direct visual - inertial odometry for stereo cameras @xcite , which also showed results in _ vicon room 1 _ sequences , allowing for a direct comparison .",
    "[ fig : comp ] shows the relative pose error ( rpe ) @xcite . to compute the rpe for our method",
    ", we need to recover the frame trajectory , as only keyframes are optimized by our backend . to this end ,",
    "when tracking a frame we store a relative transformation to a reference keyframe , so that we can retrieve frame pose from the estimated keyframe pose at the end of the execution .",
    "we have not run a full ba at the end of the experiment .",
    "we can see the error for the visual - inertial odometry method grows with the traveled distance , while our visual - inertial slam system does not accumulate error due to map reuse .",
    "the stereo method @xcite is able to work in _ v1_03_difficult _ , while our monocular method fails .",
    "our monocular slam successfully recovers metric scale , and achieves comparable accuracy in short paths , where the advantage of slam is negligible compared to odometry .",
    "this is a remarkable result of our feature - based monocular method , compared to @xcite which is direct and stereo .",
    "+     + sequence : v1_01_easy +     + sequence : v1_02_medium",
    "we have presented in this paper a novel tightly coupled visual - inertial slam system , that is able to close loops in real - time and localize the sensor reusing the map in already mapped areas .",
    "this allows to achieve a _ zero - drift _ localization , in contrast to visual odometry approaches where drift grows unbounded .",
    "the experiments show that our monocular slam recovers metric scale with high precision , and achieves better accuracy than the state - of - the - art in stereo visual - inertial odometry when continually localizing in the same environment .",
    "we consider this _ zero - drift _ localization of particular interest for virtual / augmented reality systems , where the predicted user viewpoint must not drift when the user operates in the same workspace .",
    "moreover we expect to achieve better accuracy and robustness by using stereo or rgb - d cameras , which would also simplify imu initialization as scale is not longer unknown .",
    "we thanks the authors of @xcite for releasing the euroc dataset and the authors of @xcite for providing their data to compare our results in fig . [",
    "fig : comp ] ."
  ],
  "abstract_text": [
    "<S> in recent years there have been excellent results in visual - inertial odometry techniques , which aim to compute the incremental motion of the sensor with high accuracy and robustness . </S>",
    "<S> however these approaches lack the capability to close loops , and trajectory estimation accumulates drift even if the sensor is continually revisiting the same place . in this work we present a novel tightly - coupled visual - inertial simultaneous localization and mapping system that is able to close loops and reuse its map to achieve zero - drift localization in already mapped areas . </S>",
    "<S> while our approach can be applied to any camera configuration , we address here the most general problem of a monocular camera , with its well - known scale ambiguity . </S>",
    "<S> we also propose a novel imu initialization method , which computes the scale , the gravity direction , the velocity , and gyroscope and accelerometer biases , in a few seconds with high accuracy . </S>",
    "<S> we test our system in the 11 sequences of a recent micro - aerial vehicle public dataset achieving a typical scale factor error of @xmath0 and centimeter precision . </S>",
    "<S> we compare to the state - of - the - art in visual - inertial odometry in sequences with revisiting , proving the better accuracy of our method due to map reuse and no drift accumulation .    </S>",
    "<S> slam , sensor fusion , visual - based navigation </S>"
  ]
}