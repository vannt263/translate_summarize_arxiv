{
  "article_text": [
    "in many natural language applications , such as automatic document summarization , machine translation , question answering and information retrieval , it is advantageous to pre - process text documents to identify references to entities .",
    "an entity , loosely defined , is a person , location , organization or geo - political entity ( gpe ) that exists in the real world .",
    "being able to identify references to real - world entities of these types is an important and difficult natural language processing problem .",
    "it involves finding text spans that correspond to an entity , identifying what _ type of entity _ it is ( person , location , etc . ) , identifying what _ type of mention _ it is ( name , nominal , pronoun , etc . ) and finally identifying which _ other _ mentions in the document it corefers with .",
    "the difficulty lies in the fact that there are often many ambiguous ways to refer to the same entity .",
    "for example , consider the two sentences below :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ @xmath0 gave a speech today to @xmath1 .",
    "@xmath2 outlined @xmath3 plan for budget reform to @xmath4 .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    there are five entity _ mentions _ in these two sentences , each of which is underlined ( the corresponding mention type and entity type appear as superscripts and subscripts , respectively , with coreference chains marked in the subscripts ) , but only two _ entities _ : \\ { bill clinton , the president , his } and \\ { the senate , them } . the _ mention detection _",
    "task is to identify the entity mentions and their types , without regard for the underlying entity sets , while _ coreference resolution _",
    "groups a given mentions into sets .",
    "current state - of - the - art solutions to this problem split it into two parts : mention detection and coreference @xcite .",
    "first , a model is run that attempts to identify each mention in a text and assign it a type ( person , organization , etc . ) .",
    "then , one holds these mentions fixed and attempts to identify which ones refer to the same entity .",
    "this is typically accomplished through some form of clustering , with clustering weights often tuned through some local learning procedure .",
    "this pipelining scheme has the significant drawback that the mention detection module can not take advantage of information from the coreference module .",
    "moreover , within the coreference task , performing learning and clustering as separate tasks makes learning rather ad - hoc .    in this paper",
    ", we build a model that solves the mention detection and coreference problems in a simultaneous , joint manner . by doing so , we are able to obtain an empirically superior system as well as integrate a large collection of features that one can not consider in the standard pipelined approach . our ability to perform this modeling",
    "is based on the _ learning as search optimization _",
    "framework , which we review in section  [ sec : laso ] . in section  [ sec : model ] , we describe our joint edt model in terms of the search procedure executed . in section  [ sec : features ] , we describe the features we employ in this model ; these include the standard lexical , semantic ( wordnet ) and string matching features found in most other systems .",
    "we additionally consider many other feature types , most interestingly _ count - based features _ , which take into account the distribution of entities and mentions ( and are not expressible in the binary classification method for coreference ) and _ knowledge - based features _ , which exploit large corpora for learning name - to - nominal references . in section  [ sec : results ] , we present our experimental results . first , we compare our joint system with a pipelined version of the system , and show that joint inference leads to improved performance .",
    "next , we perform an extensive feature comparison experiment to determine which features are most useful for the coreference task , showing that our newly introduced features provide useful new information .",
    "we conclude in section  [ sec : discussion ] .",
    "when one attempts to apply current , standard machine learning algorithms to problems with combinatorial structured outputs , the resulting algorithm implicitly assumes that it is possible to find the best structures for a given input ( and some model parameters ) .",
    "furthermore , most models require much more , either in the form of feature expectations for conditional likelihood - based methods @xcite or local marginal distributions for margin - based methods @xcite . in many cases  including edt and coreference  this is a false assumption . often , we are not able to find the _",
    "best _ solution , but rather must employ an approximate search to find the best possible solution , given time and space constraints .",
    "the learning as search optimization ( laso ) framework exploits this difficulty as an opportunity and seeks to find model parameters that are good _ within the context of search . _    more formally , following the laso framework",
    ", we assume that there is a set of input structures @xmath5 and a set of output structures @xmath6 ( in our case , elements @xmath7 will be documents and elements @xmath8 will be documents marked up with mentions and their coreference sets ) . additionally , we provide the structure of a search space @xmath9 that results in elements of @xmath6 ( we will discuss our choice for this component later in section  [ sec : model ] ) .",
    "the laso framework relies on a _",
    "monotonicity _ assumption : given a structure @xmath8 and a node @xmath10 in the search space , we must be able to calculate whether it is _ possible _ for this node @xmath10 to eventually lead to @xmath11 ( such nodes are called @xmath11-good ) .",
    "laso parameterizes the search process with a weight vector @xmath12 , where weights correspond to features of search space nodes and inputs . specifically , we write @xmath13 as a function that takes a pair of an input @xmath14 and a node in the search space @xmath10 and produces a vector of features .",
    "laso takes a standard search algorithm and modifies it to incorporate learning in an online manner to the algorithm shown in figure  [ fig : learn ] .",
    "the key idea is to perform search as normal until a point at which it becomes impossible to reach the correct solution . when this happens , the weight vector @xmath15 is updated in a corrective fashion .",
    "the algorithm relies on a parameter update formula ; the two suggested by @xcite are a standard perceptron - style update and an approximate large margin update of the sort proposed by @xcite . in this work",
    ", we only use the large margin update , since in the original laso work , it consistently outperformed the simpler perceptron updates .",
    "the update has the form given below :    @xmath16\\end{aligned}\\ ] ]    where @xmath17 is the update number , @xmath18 is a tunable parameter and @xmath19 projects a vector into the unit sphere .",
    "the laso framework essentially requires us to specify two components : the search space ( and corresponding operations ) and the features .",
    "these two are inherently tied , since the features rely on the search space , but for the time being we will ignore the issue of the feature functions and focus on the search .",
    "we structure search in a left - to - right decoding framework : a hypothesis is a complete identification of the initial segment of a document . for instance , on a document with @xmath20 words , a hypothesis that ends at position @xmath21 is essentially what you would get if you took the full structured output and chopped it off at word @xmath10 . in the example given in the introduction , one hypothesis might correspond to `` gave a '' ( which would be a @xmath11-good hypothesis ) , or to `` clinton '' ( which would not be a @xmath11-good hypothesis ) .",
    "a hypothesis is expanded through the application of the search operations . in our case",
    ", the search procedure first chooses the number of words it is going to consume ( for instance , to form the mention `` bill clinton , '' it would need to consume two words ) .",
    "then , it decides on an entity type and a mention type ( or it opts to call this chunk not an entity ( nae ) , corresponding to non - underlined words ) .",
    "finally , assuming it did not choose to form an nae , it decides on which of the foregoing coreference chains this entity belongs to , or none ( if it is the first mention of a new entity ) .",
    "all these decisions are made simultaneously , and the given hypothesis is then scored .      for concreteness , consider again the text given in the introduction .",
    "suppose that we are at the word `` them '' and the hypothesis we are expanding is correct .",
    "that is , we have correctly identified `` bill clinton '' with entity type `` person '' and mention type `` name ; '' that we have identified `` the senate '' with entity type `` organization '' and mention type `` name ; '' and that we have identified both `` the president '' and `` his '' as entities with entity type `` person '' and mention types `` nominal '' and `` pronoun , '' respectively , and that `` the president '' points back to the chain @xmath22bill clinton@xmath23 and that `` his '' points back to the chain @xmath22bill clinton , the president@xmath23 .    at this point of search",
    ", we have two choices for length : one or two ( because there are only two words left : `` them '' and a period ) .",
    "a first hypothesis would be that the word `` them '' is nae .",
    "a second hypothesis would be that `` them '' is a named person and is a new entity ; a third hypothesis would be that `` them '' is a named person and is coreference with the `` bill clinton '' chain ; a fourth hypothesis would be that `` them '' is a pronominal organization and is a new entity ; next , `` them '' could be a pronominal organization that is coreferent with `` the senate '' ; and so on .",
    "similar choices would be considered for the string `` them . '' when two words are selected .",
    "one significant issue that arises in the context of assigning a hypothesis to a coreference chain is how to compute features over that chain .",
    "as we will discuss in section  [ sec : features ] , the majority of our coreference - specific features are over _ pairs _ of chunks : the proposed new mention and an antecedent . however , since in general a proposed mention can have well more than one antecedent , we are left with a decision about how to combine this information .",
    "the first , most obvious solution , is to essentially do nothing : simply compute the features over all pairs and add them up as usual .",
    "this method , however , intuitively has the potential for over - counting the effects of large chains . to compensate for this , one might advocate the use of an _ average link _ computation , where the score for a coreference chain is computed by averaging over its elements .",
    "one might also consider a _",
    "max link _ or _ min link _",
    "scenario , where one of the extrema is chosen as the value .",
    "other research has suggested that a simple _ last link _ , where a mention is simply matched against the most recent mention in a chain might be appropriate , while _ first link _ might also be appropriate because the first mention of an entity tends to carry the most information .",
    "in addition to these standard linkages , we also consider an _",
    "intelligent link _ scenario , where the method of computing the link structure depends on the _ mention type_. the intelligent link is computed as follow , based on the mention type of the current mention , @xmath24 :    if @xmath25nam then : : :    match _ first _ on nam elements in the chain ; if there are none , match    against the _ last _ nom element ; otherwise , use _ max link_. if @xmath25nom then : : :    match against the _ max _ nom in the chain ; otherwise , match against the    most _ last _ nam ; otherwise , use _ max link_. if @xmath25pro then : : :    use _ average link _ across all pro or nam",
    "; if there are none , use _ max    link_.    the construction of this methodology as guided by intuition ( for instance , matching names against names is easy , and the first name tends to be the most complete ) and subsequently tuned by experimentation on the development data",
    ". one might consider _ learning _ the best link method , and this may result in better performance , but we do not explore this option in this work .",
    "the initial results we present will be based on using intelligent link , but we will also compare the different linkage types explicitly .",
    "all the features we consider are of the form _ base - feature _ @xmath26 _ decision - feature _ , where base features are functions of the input and decisions are functions of the hypothesis .",
    "for instance , a base feature might be something like `` the current chunk contains the word clinton'' and a decision feature might be something like `` the current chunk is a named person . ''      for pedagogical purposes and to facility model comparisons , we have separated the base features into eleven classes : lexical , syntactic , pattern - based , count - based , semantic , knowledge - based , class - based , list - based , inference - based , string match features and history - based features .",
    "we will deal with each of these in turn .",
    "finally , we will discuss how these base features are combined into _",
    "meta - features _ that are actually used for prediction .",
    "[ [ lexical - features . ] ] lexical features .",
    "+ + + + + + + + + + + + + + + + +    the class of lexical features contains simply computable features of single words .",
    "this includes : the number of words in the current chunk ; the unigrams ( words ) contained in this chunk ; the bigrams ; the two character prefixes and suffixes ; the word stem ; the case of the word , computed by regular expressions like those given by @xcite ; simple morphological features ( number , person and tense when applicable ) ; and , in the case of coreference , pairs of features between the current mention and an antecedent .",
    "[ [ syntactic - features . ] ] syntactic features .",
    "+ + + + + + + + + + + + + + + + + + +    the syntactic features are based on running an in - house state of the art part of speech tagger and syntactic chunker on the data .",
    "the words include unigrams and bigrams of part of speech as well as unigram chunk features .",
    "we have not used any parsing for this task .",
    "[ [ pattern - based - features . ] ] pattern - based features .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    we have included a whole slew of features based on lexical and part of speech patterns surrounding the current word .",
    "these include : eight hand - written patterns for identifying pleonastic `` it '' and `` that '' ( as in `` it is raining '' or `` it seems to be the case that  '' ) ; identification of pluralization features on the previous and next head nouns ( this is intended to help make decisions about entity types ) ; the previous and next content verb ( also intended to help with entity type identification ) ; the possessor or possessee in the case of simple possessive constructions ( `` the president s speech '' would yield a feature of `` president '' on the word `` speech '' , and vice - versa ; this is indented to be a sort of weak sub - categorization principle ) ; a similar feature but applied to the previous and next content verbs ( again to provide a weak sort of sub - categorization ) ; and , for coreference , a list of part of speech and word sequence patterns that match up to four words between nearby mentions that are either highly indicative of coreference ( e.g. , `` of , '' `` said , '' `` am '' `` , a '' ) or highly indicative of non - coreference ( e.g. , `` s , '' `` and , '' `` in the , '' `` and the '' ) .",
    "this last set was generated by looking at intervening strings and finding the top twenty that had maximal mutual information with with class ( coreferent or not coreferent ) across the training data .",
    "[ [ count - based - features . ] ] count - based features .",
    "+ + + + + + + + + + + + + + + + + + + + +    the count - based features apply only to the coreference task and attempt to capture regularities in the size and distribution of coreference chains .",
    "these include : the total number of entities detected thus far ; the total number of mentions ; the entity to mention ratio ; the entity to word ratio ; the mention to word ratio ; the size of the hypothesized entity chain ; the ratio of the number of mentions in the current entity chain to the total number of mentions ; the number of intervening mentions between the current mention and the last one in our chain ; the number of intervening mentions of the same type ; the number of intervening sentence breaks ; the hobbs distance computed over syntactic chunks ; and the `` decayed density '' of the hypothesized entity , which is computed as @xmath27 , where @xmath24 ranges over all previous mentions ( constrained in the numerator to be in the same coreference chain as our mention ) and @xmath28 is the number of entities away this mention is .",
    "this feature is captures that some entities are referred to consistently across a document , while others are mentioned only for short segments , but it is relatively rare for an entity to be mentioned once at the beginning and then ignored again until the end .",
    "[ [ semantic - features . ] ] semantic features .",
    "+ + + + + + + + + + + + + + + + + +    the semantic features used are drawn from wordnet @xcite . they include : the two most common synsets from wordnet for all the words in a chunk ; all hypernyms of those synsets ; for coreference , we also consider the distance in the wordnet graph between pairs of head words ( defined to be the final word in the mention name ) and whether one is a part of the other .",
    "finally , we include the synset and hypernym information of the preceding and following verbs , again to model a sort of sub - categorization principle .",
    "[ [ knowledge - based - features . ] ] knowledge - based features .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    based on the hypothesis that many name to nominal coreference chains are best understood in terms of background knowledge ( for instance , that `` george w. bush '' is the `` president '' ) , we have attempted to take advantage of recent techniques from large scale data mining to extract lists of such pairs .",
    "in particular , we use the name / instance lists described by @xcite and available on fleischman s web page to generate features between names and nominals ( this list contains @xmath29 pairs mined from @xmath30gbs of news data ) .",
    "since this data set tends to focus mostly on person instances from news , we have additionally used similar data mined from a @xmath31 gb web corpus , for which more general `` isa '' relations were mined @xcite .    [",
    "[ class - based - features . ] ] class - based features .",
    "+ + + + + + + + + + + + + + + + + + + + +    the class - based features we employ are designed to get around the sparsity of data problem while simultaneously providing new information about word usage .",
    "the first class - based feature we use is based on word classes derived from the web corpus mentioned earlier and computed as described by @xcite .",
    "the second attempts to instill knowledge of collocations in the data ; we use the technique described by @xcite to compute multi - word expressions and then mark words that are commonly used as such with a feature that expresses this fact .    [",
    "[ list - based - features . ] ] list - based features .",
    "+ + + + + + + + + + + + + + + + + + + +    we have gathered a collection of about 40 lists of common places , organization , names , etc .",
    "these include the standard lists of names gathered from census data and baby name books , as well as standard gazetteer information listing countries , cities , islands , ports , provinces and states .",
    "we supplement these standard lists with lists of airport locations ( gathered from the faa ) and company names ( mined from the nasdaq and nyse web pages ) .",
    "we additionally include lists of semantically plural but syntactically singular words ( e.g. , `` group '' ) which were mined from a large corpus by looking for patterns such as ( `` members of the  '' ) .",
    "finally , we use a list of persons , organizations and locations that were identified at least 100 times in a large corpus by the bbn identifinder named entity tagger @xcite .",
    "these lists are used in three ways .",
    "first , we use simple list membership as a feature to improve detection performance .",
    "second , for coreference , we look for word pairs that appear on the same list but are not identical ( for instance , `` russia '' and `` england '' appearing on the `` country '' list but not being identical hints that they are different entities ) .",
    "finally , we look for pairs where one element in the pair is the head word from one mention and the other element in the pair is a list .",
    "this is intended to capture the notion that a word that appears on out `` country list '' is often coreferent with the word `` country . ''",
    "[ [ inference - based - features . ] ] inference - based features .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    the inference - based features are computed by attempting to infer an underlying semantic property of a given mention . in particular",
    ", we attempt to identify gender and semantic number ( e.g. , `` group '' is semantically plural although it is syntactically singular ) .",
    "to do so , we created a corpus of example mentions labels with number and gender , respectively .",
    "this data set was automatically extracted from our edt data set by looking for words that corefer with pronouns for which we know the number or gender .",
    "for instance , a mention that corefers with `` she '' is known to be singular and female , while a mention that corefers with `` they '' is known to be plural . in about 5% of the cases , this was ambiguous ",
    "these cases were thrown out .",
    "we then used essentially the same features as described above to build a maximum entropy model for predicting number and gender .",
    "the predictions of this model are used both as features for detection as well as coreference ( in the latter case , we check for matches ) .",
    "additionally , we use several pre - existing classifiers as features .",
    "this are simple maximum entropy markov models trained off of the muc6 data , the muc7 data and our ace data .",
    "[ [ string - match - features . ] ] string match features .",
    "+ + + + + + + + + + + + + + + + + + + + + +    we use the standard string match features that are described in every other coreference paper .",
    "these are : string match ; substring match ; string overlap ; pronoun match ; and normalized edit distance .",
    "in addition , we also use a string nationality match , which matches , for instance `` israel '' and `` israeli , '' `` russia '' and `` russian , '' `` england '' and `` english , '' but not `` netherlands '' and `` dutch . ''",
    "this is done by checking for common suffixes on nationalities and matching the first half of the of the words based on exact match .",
    "we additionally use a linguistically - motivated string edit distance , where the replacement costs are lower for vowels and other easily confusable characters .",
    "we also use the jaro distance as an additional string distance metric .",
    "finally , we attempt to match acronyms by looking at initial letters from the words in long chunks .    [ [ history - based - features . ] ] history - based features .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    finally , for the detection phase of the task , we include features having to do with long - range dependencies between words .",
    "for instance , if at the beginning of the document we tagged the word `` arafat '' as a person s name ( perhaps because it followed `` mr . '' or `` palestinian leader '' ) , and later in the document",
    "we again see the word `` arafat , '' we should be more likely to call this a person s name , again .",
    "such features have previously been explored in the context of information extraction from meeting announcements using conditional random fields augmented with long - range links @xcite , but the laso framework makes no markov assumption , so there is no extra effort required to include such features .",
    "our decision features are divided into three classes : simple , coreference and boundary features .",
    "[ [ simple .",
    "] ] simple .",
    "+ + + + + + +    the simple decision features include : is this chunk tagged as an entity ; what is its entity type ; what is its entity subtype ; what is its mention type ; what is its entity type / mention type pair .",
    "[ [ coreference . ] ] coreference .",
    "+ + + + + + + + + + + +    the coreference decision features include : is this entity the start of a chain or continuing an existing chain ; what is the entity type of this started ( or continued ) chain ; what is the entity subtype of this started ( or continued ) chain ; what is the mention type of this started chain ; what is the mention type of this continued chain and the mention type of the most recent antecedent .",
    "[ [ boundary . ] ] boundary .",
    "+ + + + + + + + +    the boundary decision features include : the second and third order markov features over entity type , entity subtype and mention type ; features appearing at the previous ( and next ) words within a window of three ; the words that appear and the previous and next mention boundaries , specified also by entity type , entity subtype and mention type .",
    "we use the official 2004 ace training and test set for evaluation purposes ; however , we exclude from the training set the fisher conversations data , since this is very different from the other data sets and there is no fisher data in the 2004 test set .",
    "this amounts to @xmath32 training documents , consisting of @xmath33 sentences and @xmath34 words .",
    "there are a total of @xmath35 mentions in the data corresponding to @xmath36 entities ( note that the data is not annotated for cross - document coreference , so instances of `` bill clinton '' appearing in two different documents are counted as two different entities ) .",
    "roughly half of the entities are people , a fifth are organizations , a fifth are gpes and the remaining are mostly locations or facilities .",
    "the test data is @xmath37 documents , @xmath38 sentences and @xmath39 words , with @xmath36 mentions to @xmath40 entities . in all cases",
    ", we use a beam of 16 for training and test , and ignore features that occur fewer than five times in the training data .",
    "there are many evaluation metrics possible for this data",
    ". we will use as our primary measure of quality the ace metric .",
    "this is computed , roughly , by first matching system mentions with reference mentions , then using those to match system entities with reference entities .",
    "there are costs , once this matching is complete , for type errors , false alarms and misses , which are combined together to give an ace score , ranging from @xmath41 to @xmath42 , with @xmath42 being perfect ( we use v.10 of the ace evaluation script ) .      we compare the performance of the joint system with the pipelined system . for the pipelined system , to build the mention detection module , we use the same technique as for the full system , but simply do nt include in the hypotheses the coreference chain information ( essentially treating each mention as if it were in its own chain ) . for the stand - alone coreference system , we assume that the correct mentions and types are always given , and simply hypothesize the chain ( though still in a left - to - right manner ) .",
    "ace score , so we use this for the experiments reported in this section . ]",
    "run as such , the joint model achieves an ace score of @xmath43 and the pipelined model achieves an ace score of @xmath44 , a reasonably substantial improvement for performing both task simultaneously .",
    "we have also computed the performance of these two systems , ignoring the coreference scores ( this is done by considering each mention to be its own entity and recomputing the ace score ) . in this case , the joint model , ignoring its coreference output , achieves an ace score of @xmath45 and the pipelined model achieves a score of @xmath46 .",
    "the joint model does marginally better , but it is unlikely to be statistically significant . in the 2004 ace evaluation , the best three performing systems achieved scores of @xmath47 , @xmath48 and @xmath49 ; it is unlikely that our system is significantly worse than these .      in this section ,",
    "we analyze the effects of the different base feature types on coreference performance .",
    "we use a model with perfect mentions , entity types and mention types ( with the exception of pronouns : we do not assume we know pronoun types , since this gives away too much information ) , and measure the performance of the coreference system . when run with the full feature set , the model achieves an ace score of @xmath50 and when run with no added features beyond simple biases , it achieves @xmath51 . the best performing system in the 2004 ace competition achieved a score of @xmath52 on this task ; the next best system scored @xmath53 , which puts us squarely in the middle of these two ( though , likely not statistically significantly different ) .",
    "moreover , the best performing system took advantage of additional data that they labeled in house .    to compute feature performance , we begin with all feature types and iteratively remove them one - by - one so that we get the best performance",
    "( we do not include the `` history '' features , since these are not relevant to the coreference task ) .",
    "the results are shown in figure  [ fig : feature - sel ] . across the top line",
    ", we list the ten feature classes .",
    "the first row of results shows the performance of the system after removing just one feature class . in this case , removing lexical features reduces performance to @xmath54 , while removing string - match features reduces performance to @xmath55 . the non - shaded box ( in this case , syntactic features )",
    "shows the feature set that can be removed with the least penalty in performance .",
    "the second row repeats this , after removing syntactic features .    as we can see from this figure",
    ", we can freely remove syntax , semantics and classes with little decrease in performance . from that point , patterns are dropped , followed by lists and inference , each with a performance drop of about @xmath56 or @xmath57 . removing the knowledge based features results in a large drop from @xmath58 down to @xmath45 and removing count - based features",
    "drops the performance another @xmath59 points . based on this",
    ", we can easily conclude that the most important feature classes to the coreference problem are , in order , string matching features , lexical features , count features and knowledge - based features , the latter two of which are novel to this work .",
    "as stated in the previous section , the coreference - only task with intelligent link achieves an ace score of @xmath50 .",
    "the next best score is with min link ( @xmath60 ) followed by average link with a score of @xmath61 .",
    "there is then a rather large drop with max link to @xmath62 , followed by another drop for last link to @xmath63 and first link performs the poorest , scoring @xmath64 .",
    "in this paper , we have applied the _ learning as search optimization ( laso ) _ framework to the entity detection and tracking task .",
    "the framework is an excellent choice for this problem , due to the fact that many relevant features for the coreference task ( and even for the mention detection task ) are highly non - local .",
    "this non - locality makes models like markov networks intractable , and laso provides an excellent framework for tackling this problem .",
    "we have introduced a large set of new , useful features for this task , most specifically the use of knowledge - based features for helping with the name - to - nominal problem , which has led to a substantial improvement in performance .",
    "we have shown that performing joint learning for mention detection and coreference results in a better performing model that pipelined learning .",
    "we have also provided a comparison of the contributions of our various feature classes and compared different linkage types for coreference chains . in the process , we have developed an efficient model that is competitive with the best ace systems .    despite these successes ,",
    "our model is not perfect : the largest source of error is with pronouns .",
    "this is masked by the fact that the ace metric weights pronouns low , but a solution to the edt problem should handle pronouns well . we intend to explore more complex features for resolving pronouns , and to incorporate these features into our current model . we also intend to explore more complex models for automatically extracting knowledge from data that can help with this task and applying this technique to a real application , such as summarization ."
  ],
  "abstract_text": [
    "<S> entity detection and tracking ( edt ) is the task of identifying textual mentions of real - world entities in documents , extending the named entity detection and coreference resolution task by considering mentions other than names ( pronouns , definite descriptions , etc . ) . like </S>",
    "<S> ne tagging and coreference resolution , most solutions to the edt task separate out the mention detection aspect from the coreference aspect . by doing so , </S>",
    "<S> these solutions are limited to using only local features for learning . </S>",
    "<S> in contrast , by modeling both aspects of the edt task simultaneously , we are able to learn using highly complex , non - local features . </S>",
    "<S> we develop a new joint edt model and explore the utility of many features , demonstrating their effectiveness on this task . </S>"
  ]
}