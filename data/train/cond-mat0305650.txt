{
  "article_text": [
    "in this article we will try to contribute to the study of biological neural networks , in particular with respect to learning .",
    "since we are interested in the basic principles rather than subtle biological details , we will use simplified models , although we do not allow for any properties that are unrealistic from a biological point of view . in this way we hope to reveal the essentials , without blurring the analysis with ( irrelevant , biological ) details .",
    "it is also not our aim to construct a network that is optimized for some particular task ; our only purpose is to study a model that resembles an actual biological neural net and the way it might learn .    in section [ model ] we define the model that we will study : a simple feed ",
    "forward network with one hidden layer of which not all possible connections are present ( i.e. , dilution unequal zero ) .",
    "each neuron of the net has three variables associated with it : a ( fixed ) threshold potential @xmath0 , a ( variable ) membrane potential @xmath1 and a state @xmath2 , which is assumed to take two values only , depending on the fact whether the neuron fires or is quiescent .",
    "this article fits into a line of biologically motivated research .",
    "chialvo and bak @xcite suggested learning by punishment only , via the release of some hormone .",
    "heerema et al .",
    "@xcite derived rules for a biological neural net when it acts as a memory .",
    "bosman et al .",
    "@xcite added this rule to the model of chialvo and bak , and , thereby , found a significant improvement of the network s performance .",
    "the dynamics of a neural net is determined by a rule that tells a neuron when to fire . a biological neuron fires if its membrane potential @xmath1 exceeds its threshold @xmath0 . in the model of chialvo and bak",
    "this biological rule is replaced by the rule that in each layer a fixed number of neurons , having the highest membrane potentials , fire .",
    "they refer to this rule by the name of ` extremal dynamics ' .",
    "extremal dynamics has the drawback that the number of active neurons is artificially fixed , restricting the number of possible output states .",
    "alstrm and stassinopoulos @xcite did not use extremal dynamics , but they ran into the difficulty that the network s activity became too small or too large for the network to function satisfactorily . in order to keep the activity at a desired level",
    ", they adapted the neuron threshold potentials @xmath0 at each step of the learning process .",
    "it is one of our purposes to find a way in which a biological net can keep its neuronal activity around an acceptable level . instead of putting in , by hand , some controlling mechanism ,",
    "we started from four biologically motivated assumptions ( [ hebbvsantihebb ] ) , which lead to the conclusion that only the so  called hebbian and anti ",
    "hebbian learning rules are the plausible ones .",
    "we show that the hebbian learning rule fixes and strengthens the action of the network at the moment it is applied , while the anti ",
    "hebbian learning rule does the opposite , and , when applied repeatedly , will change the network s action .",
    "we conclude that hebbian learning should be associated with reward , and should be applied if the network realizes the desired output state in reaction to its input , while anti  hebbian learning should be associated with punishment , and should be applied when the output of the network is wrong , in order to enable the network to search for better output ( [ reinf ] ) .    in section [ explicitrules ]",
    "we propose a particularly simple anti ",
    "hebbian learning rule ( essentially two constants ) of which we expect , however , that it will keep the activity of the neural network around a desired value automatically , i.e. , without the need of some controlling mechanism . in section [ num1 ]",
    ", we perform a number of numerical simulations , the details of which are given in section [ num0 ] , in order to verify whether our rule is capable of keeping the activity around a desired level .",
    "because the hebbian learning rule is already studied in @xcite , we will first focus , in section [ num1 ] , on the effect of the anti ",
    "hebbian learning rule .",
    "our simulations show that our anti ",
    "hebbian learning rule indeed is successful in keeping the average activity around a desired level , and , moreover , is very efficient in generating different output states with adequate activities .",
    "having studied the effect of the anti ",
    "hebbian learning rule we simulate , in section [ num2 ] , networks using the complete learning rule , including both the hebbian and the anti  hebbian contributions .",
    "we show that the complete learning rule enables the network to learn a number of input  output relations with an acceptable efficiency .",
    "furthermore , it is shown that for non ",
    "zero threshold potentials , the performance is only acceptable if the network is sufficiently diluted .",
    "so ` cutting away ' synaptic connections enhances the performance of the network .",
    "the observation that  in our model  some degree of non  connectedness is a conditio sine qua non for a properly functioning biological net , is one of our main observations .",
    "the article closes with conclusions ( section [ conclusions ] ) and an outlook ( section [ outlook ] ) .",
    "in this section we describe our model and define quantities like activity and performance .       of the net",
    "belongs to one of these layers we will write @xmath3 , @xmath4 or @xmath5 , respectively . furthermore , @xmath6 denotes the number of neurons in layer x ( x = i , h or o ) .",
    "the weights of the synapses connecting either the input layer with the hidden layer or the hidden layer with the output layer both are indicated by the symbol @xmath7 . in this feed  forward network",
    "there are maximally @xmath8 possible connections from the input layer to the hidden layer .",
    "if only the fraction @xmath9 , @xmath10 , of these connections to the hidden layer is actually realized , we call @xmath11 the dilution ( of the connections with h ) . similarly , @xmath12 is the dilution of the connections from the hidden layer to the output layer . ]",
    "we consider a feed  forward neural net with one hidden layer ( figure [ fig1 ] ) .",
    "the net is taken to be diluted , i.e.  not all neurons are connected to all others .",
    "there are connections from the input layer to the hidden layer and from the hidden layer to the output layer but there are no direct connections from the input layer to the output layer nor any lateral or feed  back connections .    let us suppose that the neural net consists of @xmath13 binary neurons @xmath14 , @xmath15 .",
    "we will use the symbols i , h and o to refer to the input , hidden and output layers . in order to denote that a neuron @xmath14 of the net belongs to one of these layers",
    "we will write @xmath3 , @xmath4 or @xmath5 , respectively .",
    "the state @xmath16 of neuron @xmath14 either is active ( @xmath17 ) or is non  active ( @xmath18 ) .",
    "the potential @xmath19 , the difference in potential between the inner and the outer part of a neuron , is supposed to depend linearly on the activities of the incoming synaptic connections : @xmath20 where @xmath21 is the collection of neurons @xmath22 that have an afferent synaptic connection to neuron @xmath14 .",
    "this formula can be viewed as the defining expression for the weights @xmath7 . since the @xmath16 s",
    "are chosen to be dimensionless , the weights have the dimension of a potential .",
    "let @xmath23 be the potential that should be exceeded in order that neuron @xmath14 becomes active , i.e. , @xmath24 an alternative way to specify the state of neuron @xmath14 as given by equation ( [ state ] ) , is to write @xmath25 the function @xmath26 is the heaviside step  function [ @xmath27 if @xmath28 and @xmath29 if @xmath30 .",
    "the state of the neurons of the input layer determine the state of the hidden layer via ( [ potential ] ) and ( [ dynamics ] ) .",
    "the state of the hidden layer , in turn , determines the state of the output layer .",
    "thus , if the states @xmath16 for @xmath3 are given at each time step @xmath31 , we can determine the network state at every time @xmath31 , once we have a rule that fixes the @xmath7 at time @xmath31 ( @xmath32 ) .",
    "the number of neurons in layer x ( x = i , h or o ) is denoted by @xmath6 .",
    "the activity @xmath33 in layer x is defined by @xmath34 the weights of the synapses connecting either the input layer with the hidden layer or the hidden layer with the output layer both are indicated by the symbol @xmath7 .",
    "in this feed  forward network there are maximally @xmath8 possible connections from the input layer to the hidden layer . if only the fraction @xmath9 , @xmath35 , of these connections to the hidden layer is actually realized , we call @xmath11 the dilution ( of the connections with h )",
    ". similarly , @xmath12 is the dilution of the connections from the hidden layer to the output layer .",
    "let us denote the state of layer x by @xmath36 .",
    "we want the network to associate with a particular , prescribed input state @xmath37 , chosen from a collection of @xmath38 input states @xmath37 ( @xmath39 ) , the particular state @xmath40 , chosen from a collection of @xmath38 prescribed output states @xmath40 ( @xmath39 ) .",
    "the goal of the learning process is that the network will be able to generate , for _ all _ input patterns @xmath37 , the correct output pattern @xmath40 .",
    "this will be achieved by a learning procedure , in which the weights are adapted , stepwise , according to some rule .",
    "if we present a pattern @xmath37 to the network by setting @xmath41 equal to @xmath37 , the network will respond by generating an output state @xmath42 which , in general , will not be equal to the desired output state @xmath40 .",
    "we will associate a variable @xmath43 with each of the following two possibilities : @xmath44 if the output is right , i.e. , if @xmath45 and @xmath46 if the output is wrong , i.e. , if @xmath47 .",
    "in practice , we proceed as follows .",
    "we present the first input pattern @xmath48 to the net , which results in an output state @xmath42 .",
    "we keep repeating this until @xmath42 equals @xmath49 , the output pattern to be associated with the input pattern @xmath48 .",
    "the net then has ` learned ' the first input  output relation @xmath50 .",
    "next , we present the second input pattern , and continue until the second input  output relation @xmath51 has been learned , and so on until the @xmath38th input ",
    "output relation @xmath52 has been learned .",
    "while doing so , we continuously change the weights according to some @xmath43dependent rule : the ` learning rule ' .",
    "when an input  output relation has been learned , one or more input  output relations learned earlier may have been forgotten .",
    "therefore , we start a second round , in which we try to learn all @xmath38 input  output relations @xmath53 again . in order to prevent possible effects due to a specific learning order ,",
    "the patterns are presented to the network in random order : each round their order is shuffled . after a number of rounds all input  output relations should be recalled at once , i.e. , input @xmath37 should result immediately in output @xmath40 for all input  output relations .",
    "do learning rules exist which accomplish all this ?",
    "the answer is positive @xcite .",
    "a particular useful one is the one proposed in section [ seclearning ] .      in order to judge the performance of our network ,",
    "we need some measure .    the a priori probability @xmath54 that the state of the output layer @xmath42 equals @xmath55 , i.e.",
    ", the state with the first @xmath56 elements equal to one and the remaining last @xmath57 elements equal to zero , is given by @xmath58 where @xmath59 is the probability that an arbitrary neuron of the output layer is active ( @xmath60 ) .",
    "note that the probability to find an output pattern with @xmath56 active neurons at arbitrary places is also given by ( [ pee ] ) .",
    "let @xmath61 be the number of active neurons in pattern @xmath40 .",
    "then , the average a priori number of trials needed to arrive at the desired output pattern equals @xmath62 .",
    "if @xmath38 input  output relations @xmath53 are to be realized , ( @xmath63 ) , the average a priori number @xmath64 of trials needed equals @xmath65 comparing the average a priori number of trials and the actual average number of trials @xmath66 needed to learn all @xmath38 input ",
    "output relations we get a measure of how well the network performs .",
    "this leads us to define the performance @xmath67 as the quotient @xmath68 with @xmath64 given by ( [ ma ] ) .",
    "note that the performance tends to zero when the network is unable to learn all input  output relations ( @xmath69 ) and the performance will be 1 for an ` ideal ' network ( @xmath70 ) .    in some models",
    "@xcite , the number of neurons that fire is fixed in some way .",
    "the a priori probability @xmath71 that the output state @xmath42 equals the output pattern @xmath40 is then given by @xmath72 the inverse of the number of ways that a state with @xmath56 active neurons can be realized .",
    "let us consider an arbitrary collection of @xmath66 neurons , all of which have ( independent ) probabilities @xmath38 to fire ( @xmath73 ) .",
    "then the probability @xmath74 that the activity of this collection of @xmath66 neurons equals @xmath75 is given by @xmath76!}p^{ma}(1 - p)^{m(1 - a)},\\ ] ] where @xmath77 is the number of neurons that fire ( @xmath77 is an integer ) .",
    "this formula differs from ( [ pee ] ) by a binomial factor , corresponding to the fact that there are @xmath78!\\}$ ] possible states with the same activity @xmath75 .",
    "we will use this formula in section [ num1 ] when we compare @xmath74 to the actual activity of the net .",
    "let us define the ` two time stability coefficient ' @xmath79 which is a generalization of the usual stability coefficient @xcite . with equation ( [ dynamics ] )",
    "it follows that , at two times @xmath31 and @xmath80 we have @xmath81 @xmath82 in particular , if @xmath83 , we have @xmath84 the state of neuron @xmath14 does not change if @xmath85 is positive . moreover , the larger @xmath86 , the more stable the system is with respect to changes in the synaptic weights @xcite .",
    "the @xmath87 s will play a role in section [ reinf ] .",
    "as noted in the introduction , many neural networks have a tendency to develop into a state where most neurons are either all active or non  active .",
    "chialvo and bak @xcite and alstrm and stassinopoulos @xcite solved this problem in a biologically less plausible way : the authors do not consider the threshold potentials at all @xcite , or allow them to grow indefinitely @xcite .",
    "we approach the problem in a different way : we start from four biologically plausible restrictions on the learning rule .",
    "this leads to the conclusion that the learning rule can be seen as a superposition of two types of learning , hebbian and anti ",
    "hebbian learning .",
    "taking for the anti ",
    "hebbian part the most simple ansatz one can think of in dependence of the state @xmath16 of the postsynaptic neuron @xmath14 , we arrive at a learning rule that , a priori , is biologically plausible .",
    "moreover , it turns out that the learning rule found in this way is such that the neuronal activity is well  behaved .",
    "let us suppose that the weights @xmath88 may be changed stepwise by some learning process @xmath89 where @xmath22 is the presynaptic and @xmath14 the postsynaptic neuron .",
    "the changes , given by @xmath90 , are the quantities we are after .",
    "we start from four assumptions , each of which needs not be strictly true , but each of which is very plausible biologically , at least in first approximation .",
    "the contents of these assumptions generalize the assumptions of heerema and van leeuwen @xcite by including the effect of the feed  back signal @xmath43 .",
    "* the changes in @xmath7 , @xmath91 , depend on the global variable @xmath43 and the local variables @xmath16 ,",
    "@xmath92 , @xmath19 , @xmath23 and @xmath7 , i.e. , @xmath93 + biologically this means that only variables that can be ` felt ' at the synapse between @xmath22 and @xmath14 can influence the weight change .",
    "of course , this includes the global variable @xmath43 , which could be realized in an actual biological system by some chemical substance released throughout the brain , and the strength of the weight @xmath7 itself . since the state @xmath92 of neuron @xmath22 determines whether or not neurotransmitters are released at the synapse , @xmath92 can influence the weight change .",
    "because the synapse is located at the dendrites or cell body of neuron @xmath14 , we suppose that variables local to neuron @xmath14 , the state @xmath16 and the potentials @xmath19 and @xmath23 , also can influence the strength of the weight change .",
    "* the _ sign _ of @xmath91 depends on @xmath43 , and the neuron states @xmath16 and @xmath92 _ only _ , i.e. , @xmath94 where @xmath95 equals @xmath96 or @xmath97 and where @xmath98 .",
    "+ biologically this means that as long as the states of the presynaptic and postsynaptic neurons do not change _ and _ the global feed ",
    "back signal @xmath43 does not change , the sign of the weight change will not change , i.e. , the variables @xmath19 , @xmath23 and @xmath7 can influence the _ magnitude _ of the weight change , but they can not switch the learning from an increase to a decrease as long as the states and @xmath43 do not change .",
    "* there is only a change in @xmath7 if the presynaptic neuron @xmath92 is active , i.e. , @xmath99 + biologically this means that if the presynaptic neuron @xmath22 does not fire , there will be no change in the synaptic efficacy @xmath7 .",
    "this is supposed because we think that it is unlikely that the synaptic efficacy will change if nothing happens , i.e. , no neurotransmitters are released into the synaptic gap . substituting ( [ j3 ] ) into ( [ j2 ] )",
    "we find @xmath100 where we replaced @xmath101 by @xmath102 , which is allowed since @xmath91 is only non ",
    "zero if @xmath92 equals @xmath103 .",
    "* both in case @xmath46 and @xmath44 , there is not only enhancement or only diminishment of the weights .",
    "this implies that @xmath104 must take on both the values @xmath97 and @xmath96 .",
    "the same is true for @xmath105 . since @xmath16 is the only variable that is still available to influence @xmath95 , we must have @xmath106 , or , equivalently @xmath107 where @xmath108 equals @xmath96 or @xmath97 .",
    "+ biologically , this means that we think that it is implausible that weights can either only increase or only decrease .",
    "if the weights would only increase , all the membrane potentials ( [ potential ] ) would only increase , and all neurons would end up firing [ see eq .",
    "( [ dynamics ] ) ] . in case",
    "the weights would only decrease , all membrane potentials would only decrease , and all neurons would become non  active . since @xmath46 can be true for long times as long as something is not learned , and @xmath44 can also last for long times as long as the behavior is as desired , the assumption must hold true both for @xmath46 and @xmath44 .    inserting ( [ w4 ] ) into ( [ j3a ] ) we finally have @xmath109 where @xmath110 ( where @xmath43 can take on the values @xmath111 and @xmath103 ) and @xmath98 .",
    "we will now discuss the effects of the weight changes ( [ j4 ] ) for @xmath112 and @xmath113 .",
    "to that end , consider neuron @xmath14 , a fixed but arbitrary neuron of the network .",
    "suppose that the neurons @xmath114 do not change their states during the time step @xmath115 : @xmath116 now , we multiply both sides of ( [ wij ] ) by @xmath117 , sum over all indices @xmath114 , and subtract the threshold potential @xmath23 to obtain @xmath118 where we used ( [ potential ] ) and ( [ xjtn ] ) .",
    "next , we multiply by the factor @xmath119 . using equation ( [ gamma ] ) , we then get @xmath120 we now distinguish between @xmath112 and @xmath113 .    substituting ( [ j4 ] ) into ( [ gitn ] ) with @xmath112",
    "we find , using @xmath121 and @xmath122 , that @xmath123 recalling that @xmath86 and @xmath124 are positive , we see that @xmath125 is positive .",
    "hence , according to ( [ gammaposnm ] ) the state of neuron @xmath14 has not changed : @xmath126 in our case of a feed  forward network , the neurons of the hidden layer get their input from neurons of the input layer only . consequently ,",
    "if the input layer does not change , going from time @xmath31 to time @xmath127 , the state of a neuron @xmath14 of the hidden layer does not change .",
    "this holds true for any neuron @xmath14 of the hidden layer , implying that the input of the output layer will not change either . in other words , the output of the net does not change when the input remains the same , although the weights @xmath88 change to @xmath128 according to the rule ( [ wij ] ) .",
    "hence , the rule ( [ j4 ] ) with @xmath112 conserves an input  output relation .    moreover , since @xmath125 is larger than @xmath86 , as follows from ( [ gitnp1 ] ) , the new net is more stable . in other words ,",
    "learning with @xmath112 engraves an input  output relation into the memory of the net by properly adapting its weights .",
    "next , substituting ( [ j4 ] ) into ( [ gitn ] ) , but now with @xmath113 , we find @xmath129 since both @xmath86 and @xmath124 are positive , @xmath125 is smaller than @xmath86 .",
    "hence , the learning rule ( [ j4 ] ) with @xmath113 has the effect of decreasing the stability of the network .",
    "as long as the state of the network does not change ( i.e.  @xmath130 for all @xmath22 ) , all stability coefficients @xmath125 decrease , and , at a certain moment @xmath80 ( @xmath131 ) , @xmath132 will become negative , at least for one neuron @xmath14 , implying , with ( [ gammanegnm ] ) , that @xmath133 consequently , repeated learning with @xmath113 will result in a change of the output related to the same input .",
    "we now come to the main conclusion of this section .",
    "if the network output is the wrong one ( @xmath46 ) , we must adapt the weights such that other output results , i.e. , we should use @xmath134 .",
    "if the network output is the right one ( @xmath44 ) , we should use @xmath135 to consolidate this situation .",
    "hence , we may conclude @xmath136 with ( [ sigma ] ) we may write instead of ( [ j4 ] ) @xmath137 where @xmath138 with @xmath139 if both the presynaptic and postsynaptic neurons are active ( @xmath140 ) , the terms @xmath141 and @xmath142 are positive and negative , respectively",
    ". we will refer to them by the names of hebbian and anti  hebbian learning .",
    "in conclusion , we see from ( [ j1wij ] ) that reward ( @xmath44 ) and punishment ( @xmath46 ) may be associated in a unique way with hebbian and anti ",
    "hebbian learning , respectively .",
    "a similar rule has been postulated by barto and anandan @xcite .",
    "what remains is to find explicit expressions for the ( positive ) functions @xmath143 and @xmath144 .",
    "this will be the subject of the next section .      for the hebbian function @xmath143 we choose the biologically plausible expression derived in @xcite",
    ": @xmath145\\ ] ] where @xmath146 and @xmath147 are constants .",
    "note that @xmath147 must be large enough in order that @xmath143 be positive .",
    "we now come to the anti  hebbian function @xmath148 .",
    "experimentally nor theoretically there are clues regarding the precise form of this term .",
    "therefore , we simply choose two ( positive ) constants , @xmath149 and @xmath150 : @xmath151 and @xmath152 .",
    "since any two positive constants can be expressed as @xmath153 and @xmath154 where @xmath155 and @xmath156 are two other constants with @xmath157 and @xmath158 , we can write @xmath159 or , equivalently , @xmath160.\\ ] ] note that the expression ( [ epsilonija ] ) can be obtained from ( [ epsilonijh ] ) by the substitutions @xmath161 , @xmath162 , @xmath163 and @xmath164 . however , for ( [ epsilonijh ] ) exists a derivation , whereas ( [ epsilonija ] ) is an educated guess only .    upon substituting ( [ epsilonijh ] ) and",
    "( [ epsilonija ] ) into ( [ h ] ) and ( [ a ] ) we obtain @xmath165x_j\\\\ \\label{deltawija2 } \\delta w_{ij}^\\text{a } & = & -\\rho_i(x_i - \\alpha_i)x_j.\\end{aligned}\\ ] ]    the numerical study of section [ num1 ] will show that the effect of the anti ",
    "hebbian term ( [ deltawija2 ] ) is that the average neuronal activity of the network takes a value controlled by the parameter @xmath166 .",
    "this section is intended mainly for readers interested in technical details of the simulations .      up to now",
    "we did not specify the parameters @xmath146 , @xmath147 , @xmath23 , @xmath155 and @xmath156 occurring in the learning rule ( [ j1wij ] ) combined with ( [ deltawijh2 ] ) and ( [ deltawija2 ] ) . in @xcite",
    "it is argued that the hebbian learning rate @xmath146 should be proportional to the inverse of the average number of neurons @xmath114 that fire .",
    "it is argued also that a reasonable approximation will suffice .",
    "therefore , we may choose @xmath146 equal to @xmath167 for all @xmath168 , i.e. , we may choose @xmath146 the same for all neurons @xmath14 of layer x ( @xmath169 ) : @xmath170 with @xmath171 where the bar denotes a time average and where @xmath172 is some positive constant , which we will call the ( global ) learning rate .",
    "note that @xmath173 is the learning rate associated with the connections from the input layer i to the hidden layer h. similarly , @xmath174 is associated with connections from h to o.    analogously we take for the anti ",
    "hebbian learning rate , or punishment rate , @xmath175 : @xmath176 with @xmath177    we will set the parameters @xmath178 , @xmath168 and @xmath179 , @xmath168 , i.e. , we take these parameters the same also for neurons belonging to one and the same layer .",
    "the margin parameter @xmath147 will be fixed at the value 1 , in agreement with literature ( see e.g.  @xcite ) .",
    "this can be done , because , instead of varying @xmath147 , one can also vary both the learning and punishment rates @xmath172 and @xmath175 , with the same effect .",
    "since the equations describing the network dynamics are deterministic , and the number of possible states of the network is finite , the system may suffer from periodic behavior , which is not realistic biologically , since in an actual biological net there is always some disturbing effect .",
    "therefore , when performing our simulations , we add some noise , in order to mimic reality .    to that end",
    "we employ the gaussian distribution @xmath180 with mean @xmath181 and standard deviation @xmath95 . in our simulations",
    "we will replace the deterministic value @xmath91 by the probabilistic value @xmath182 , the distribution of which is given by @xmath183 with @xmath184 i.e. , we replaced @xmath91 by a gaussian distributed quantity @xmath185 with mean value @xmath91 and standard deviation @xmath186 .",
    "note that we have chosen the standard deviation of the noise proportional to @xmath91 with proportionality constant @xmath187 .      as long as a network does not memorize input ",
    "output relations , the anti  hebbian term of the learning rule will adapt the weights in such a way that all neurons will ` hesitate ' between firing and not firing .",
    "when the anti  hebbian learning rule is applied for a long time , the network can be viewed as ` fresh ' : the network has not stored any information and can quickly change its behavior .",
    "we want to start our simulations with networks that have their weights distributed according to such a fresh distribution .",
    "this can be accomplished by starting with arbitrary weights and applying the anti ",
    "hebbian learning rule a large number of times .",
    "we will use this approach , and , in every step , offer an arbitrary input pattern with activity @xmath188 to the net .    since it may take a very long time before the distribution of all weights has reached its equilibrium by the effect of the anti ",
    "hebbian learning rule , we will not start with entirely arbitrary weights , but , instead , start from a rough approximation . we choose to initialize with weights that are distributed according to the gaussian distribution ( [ fx ] ) . for weights connecting neurons of the input layer to neurons of the hidden layer , the changes of the weights due to the anti",
    " hebbian learning rule will be of the order of @xmath189 .",
    "therefore , we suppose that the width of the distribution of the weights will also be of the order of @xmath189 , and we take @xmath190 for the standard deviation of the initial gaussian distribution . for the mean @xmath181 we will use a value @xmath191 , which is a rough approximation of the average value of the strength of the weights connecting neurons of the input layer to neurons of the hidden layer . since the anti ",
    "hebbian learning rule causes each neuron to change its state @xmath16 over and over again , the membrane potentials @xmath19 will fluctuate around the threshold potentials @xmath23 . as an approximation",
    "we suppose that each membrane potential @xmath19 of a neuron of the hidden layer will be , on average , equal to its threshold potential : @xmath192 we now approximate @xmath19 , given by ( [ potential ] ) , according to @xmath193 the sum in this formula can be approximated by @xmath194 with @xmath195 the average activity of the input layer , which , in our model , will be equal to the average activity of the input patterns .",
    "furthermore , @xmath196 is an approximation for the number of presynaptic neurons . substituting ( [ hi2 ] ) and ( [ hi0 ] ) into ( [ hi1 ] )",
    ", we obtain a rough approximation of the average value of the strengths of the weights @xmath191 : @xmath197    in the same way , we find for the weights connecting the neurons of the hidden layer to the neurons of the output layer @xmath198 where @xmath199 is the average activity of the hidden layer .",
    "as will turn out later , this average activity will be around the parameter @xmath200 occurring in the anti  hebbian learning rule .",
    "we will use @xmath200 as an estimation for @xmath201 in the above formula .",
    "analogous with ( [ sigmah ] ) , @xmath202 will be used for the standard deviation @xmath95 for the weights connecting neurons of the hidden layer to neurons of the output layer .",
    "it proves useful to study the hebbian and anti ",
    "hebbian learning rules separately .",
    "since the hebbian rule has been studied earlier , we here consider anti ",
    "hebbian learning ; in the next section the complete rule will be discussed .",
    "we will show that the activities , averaged in time , of the hidden and output layers are given by @xmath200 and @xmath203 respectively .",
    "moreover , we will show that the distribution of the activities around the value @xmath200 ( or @xmath203 ) is such that , effectively , each neuron @xmath14 in layer h ( or o ) has a probability @xmath200 ( or @xmath203 ) to fire , independent of the activities of the other neurons .",
    "in other words , the proposed learning rule ( [ deltawija2 ] ) focuses the average activity in a natural way around the values @xmath200 and @xmath203 .    in case",
    "the threshold potentials @xmath204 and @xmath205 vanish , we will find that the state of a neuron in the output layer behaves independently of the states of the other neurons of the output layer . in case",
    "the threshold potentials do not vanish , we will observe strong correlations between the states of the output neurons , which vanish , however , when the dilution is taken to be sufficiently high .",
    "we start by studying the case that @xmath206 and @xmath207 . in order to get a first impression of the network behavior",
    ", we will plot the activity as a function of time , as well as , in a histogram , the distribution of its values ( @xmath208 ) .",
    "we will offer the network @xmath209 input patterns .",
    "each input pattern will be repeatedly offered to the net until the output pattern to be associated with the input pattern is found .",
    "the input and associated output patterns are chosen at random but with a certain specified activity .",
    "as soon as the correct output is produced , the next pattern is presented until all output patterns associated with the input patterns have been found .",
    "+      in figure [ figa ] ( top ) we can observe that the activity @xmath201 of the hidden layer fluctuates around the value @xmath210 , the value which we have chosen in the learning rule for changes of weights of connections between the input and hidden layers .",
    "this is what we had hoped to achieve when we postulated ( [ deltawija2 ] ) .",
    "the larger fluctuations occur when the net is confronted with a new input pattern , to which it must learn to react by a new , prescribed output pattern .",
    "we see that it takes only a short period of time before the net has found back its balance .",
    "similar observations can be made with respect to the output layer : in figure [ figa ] ( bottom ) the activity is seen to fluctuate around the value @xmath211 , chosen in the learning rule ( [ deltawija2 ] ) .",
    "it can also be seen that the distributions closely resemble the distribution @xmath74 [ eq .  ( [ qa ] ) ] .",
    "this means that the anti ",
    "hebbian learning rule effectively causes each neuron to behave and fire , with a probability @xmath33 , as if it is independent of the states of the other neurons .          in this section",
    "we study a network that is the same as in the preceding section , but with non  vanishing threshold potentials : we will take @xmath212 . when we now repeat the simulations , we find one important difference : the neurons of the output layer turn out to exhibit strong correlations : almost always , either all of them are active or all of them are non  active .",
    "this can be seen in figure [ d ] ( left ) .",
    "this is alarming and most undesirable , since it would imply that the network has , effectively , only two different output states .",
    "note , that although the probability that @xmath213 equals @xmath203 now is very small , its average @xmath214 is still close to @xmath203 .",
    "it can be expected that if the average number of neurons of some layer @xmath215 that are postsynaptic to a neuron of a preceding layer @xmath216 becomes lower , the correlated behavior of the neurons of @xmath215 , which , apparently , was induced by the neurons of @xmath216 , will decrease . in order to verify this",
    ", we now study a network with non  vanishing dilution . in figure [ d ] ( right ) , we plotted the distribution of the activity @xmath213 of the output layer for five different values of the dilution @xmath12 . comparing the left and right pictures of figure [ d ] we observe a dramatic change in the behavior indeed : the undesired effect quickly diminishes with increasing dilution .",
    "note that the distribution is shifted somewhat towards zero in comparison with the distribution of uncorrelated output neurons .",
    "the shift decreases when the number of neurons of the hidden layer increases : for @xmath217 there is a better resemblance to the @xmath74curve than for @xmath218 . for non  zero dilution",
    "the probability that none of the neurons that are presynaptic to an output neuron fire increases , resulting in a lower average activity .",
    "this causes the shift of the activity distribution to lower values .",
    "in the preceding section we saw that the anti ",
    "hebbian part of the learning rule adapts the weights in such a way that a desired input ",
    "output relation is found after a number of time steps , while , at the same time the network activities @xmath201 and @xmath213 stay within acceptable bounds . in this section we study the complete learning rule ( [ j1wij ] ) with ( [ deltawijh2 ] ) and ( [ deltawija2 ] ) .      in order to make contact with existing literature , we also simulate systems with extremal dynamics .",
    "we consider input  output relations with the same number of active neurons @xmath219 in the input and output patterns . in figure",
    "[ explore ] we plotted the performance @xmath67 of a network as a function of the number of input  output relations @xmath38 to be learned , for @xmath220 , @xmath221 and @xmath222 .",
    "the two pictures at the top are for the case of extremal dynamics , the pictures at the bottom correspond to simulations for the more realistic case that the neurons fire if their membrane potentials exceed their thresholds .",
    "the two pictures at the left are without reward ( @xmath223 ) , those at the right are with reward ( @xmath224 ) .      +      we conclude that the net is able to learn a number of input  output relations indeed .",
    "the situation @xmath220 ( top , left ) is analogous to the case considered by chialvo and bak . in the simple case that @xmath220 , the performance is almost perfect , i.e.",
    ", @xmath67 is close to 1 .",
    "however , the performance decreases quickly for the case that more than two neurons are active in the input and output patterns . in figure",
    "[ explore ] ( top , right ) we observe that rewarding significantly increases the performance @xmath67 if @xmath225 is larger than 1 .",
    "a similar observation has been made earlier by bosman et al .",
    "@xcite .",
    "figure [ explore ] ( left , bottom ) is to be compared with figure [ explore ] ( left , top ) . for @xmath220 ,",
    "the performance is not as good as in case of extremal dynamics , but it still works satisfactory .",
    "however , for values of @xmath225 larger than one , the performance is very bad . adding reward to the learning rule",
    ", we find the results of figure [ explore ] ( right , bottom ) .",
    "the improvement of the performance is impressive .",
    "hence , our model performs the task of realizing prescribed input ",
    "output relations reasonably well , although its performance is not as good as in the less realistic case that extremal dynamics is used .",
    "we close this section with the following observation : in case only one input  output relation is to be learned by the net , i.e. , @xmath226 , the performance @xmath67 is close to 1 , as can be read off from figure [ explore ] .",
    "this implies that the period of search for the correct output by means of the anti ",
    "hebbian term is close to the random search time . in other words , in case the feed ",
    "back is binary only ( @xmath46 or @xmath44 ) , anti  hebbian learning enables a way of search which is close to optimal .",
    "the performance of a neural net depends on many parameters , e.g. , the coefficients @xmath172 , @xmath175 and @xmath166 occurring in the learning rule , the dilution @xmath227 and the threshold potential @xmath0 . in this section",
    "we take the thresholds @xmath228 ( @xmath229 ) . in order to get more insight regarding the behavior of the net in dependence of variations of all these parameters , we will study two particular cases .     as a function of the parameter",
    "@xmath200 determining the activity of the hidden layer for @xmath230 input  output relations .",
    "we set @xmath231 , @xmath232 , @xmath233 , @xmath234 , @xmath207 , @xmath235 , @xmath236 , @xmath237 .",
    "the performance is best for values of @xmath200 between @xmath238 and @xmath239 . ]    in figure [ alphah ] we plotted the performance @xmath67 of the net as a function of the parameter @xmath200 , the coefficient occurring in the anti ",
    "hebbian part of the learning rule , which determines the activity of the hidden layer .",
    "there is seen to be an optimum in the performance . for values of @xmath200 below @xmath238 ,",
    "the performance decreases rapidly .",
    "it follows that the parameter @xmath200 occurring in the anti ",
    "hebbian part of the learning rule , a neuron property , has an important effect on the performance of the net .",
    "it is seen that the performance diminishes when the activity becomes too large , in agreement with earlier results @xcite .",
    "input  output relations .",
    "we chose @xmath240 , @xmath241 and @xmath172 was varied between @xmath242 and @xmath243 .",
    "other parameters where chosen the same as in the simulations of figure [ alphah ] . for values of @xmath244 around 2",
    ", the performance seems optimal . ]    in figure [ etarho ] we plotted the performance @xmath67 as a function of @xmath244 for @xmath241 . for values of @xmath172 around two times the value of @xmath175",
    ", the performance is optimal .",
    "we conclude that when the rewarding part of the learning rule ( proportional to @xmath172 ) becomes smaller and smaller , the performance of the net strongly decreases .",
    "on the other hand , if the rewarding part becomes larger and larger , the performance also diminishes , albeit more slowly .",
    "these observations do not come as a surprise : evidently , if the memorizing hebbian term is too weak  relative to the anti ",
    "hebbian term  learning will be slow , whereas it will also be slow if the hebbian term becomes too strong , since then the learning of any pattern will change the existing connections too wildly .       as a function of the number of input  output relations @xmath38 for different values of the dilution",
    "@xmath12 : @xmath245 , @xmath246 , @xmath247 .",
    "we chose @xmath240 .",
    "other parameters are the same as those in figure [ alphah ] .",
    "the network performance is best in this picture for @xmath248 . ]    in view of section [ nonvan ] we expect that also in case of use of the full learning rule ( [ j1wij ] ) with ( [ deltawijh2 ] ) and ( [ deltawija2 ] ) we will only get satisfactory results if we take the dilution @xmath227 unequal to zero . in figure [ thetad ] the performance is plotted as a function of the number of input  output relations @xmath38 for different values of the dilution @xmath12 .",
    "the network performance is optimal around @xmath248 .",
    "the fact that a dilution here actually enhances the performance is a consequence of the fact that undesired correlations ( see section [ nonvan ] ) diminish with increasing dilution .",
    "our goal to model , in a biologically plausible way , neural networks capable of learning without the use of extremal dynamics @xcite or some other mechanism to control the neuronal activity was reached successfully .    in section [ hebbvsantihebb ]",
    "we found , on the basis of four biological assumptions , two possible learning rules , given by the equations ( [ h ] ) and ( [ a ] ) . by analyzing their effects , we were able to associate them in a unique way with reward and punishment , and to formulate a plausible learning rule ( [ j1wij ] ) .",
    "for the rewarding part , we used a form derived in @xcite . for the punishing part we chose two constants",
    "[ see eq .",
    "( [ epsilonijaprime ] ) ] . by studying the effects of this specific form with two constants",
    ", we found that this punishing part of our learning rule is able to control the average activity ( average fraction of firing neurons ) in a neuronal net .",
    "we showed that the activity remained around a desired level while , at the same time , the network is searching for the correct output by generating random patterns with a desired activity with great efficiency .",
    "finally , we showed that for neurons with non  zero threshold potentials , the neural net must be diluted in order to achieve a reasonable performance : dilution is found to enhance the functionality of a biological neural net .",
    "this is because the neurons start to behave correlated when the threshold potentials are non  zero . when the dilution increases , these undesired correlations decrease . in nature",
    "neural nets normally are strongly diluted : the human brain , for example , has of the order of @xmath249 neurons but there are only @xmath250@xmath251 synapses per neuron .",
    "evidently , the study on the behavior of biologically inspired neural networks is far from complete .",
    "one may , for instance , include more biologically known features into the model like time delay of the axonal signal or the refractory period of a neuron .",
    "also , the architecture of the net could be made more realistic by including more layers and adding feed  back and lateral connections .",
    "furthermore , the model of the surrounding world , i.e. , the input  output relations to be learned could be made more realistic , for example by using a dynamic model of a realistically changing world . also , the neuron model could be made to resemble closer real neurons by including different types of neurons and synapses , or using the fact that excitatory synapses are probably more plastic than the inhibitory ones .",
    "another extension would be to refine the measure of success .",
    "instead of just a binary feed  back signal indicating whether the output is _ right _ or _",
    "wrong _ in reaction to some input , a feed  back signal that can take on a range of values is possible .",
    "also , a relative measure could be used , telling the network if it has performed better or worse than during a previous attempt .",
    "a most obvious first extension of our particular model would be to include ( inhibitory ) lateral connections inside layers and possibly also feed  back connections .",
    "it would be interesting to study the influence of these non  feed  forward connections on the behavior of the network , and , especially , the effect they will have on the ( average ) activity of the network .",
    "another extension of our model could be to associate hebbian and anti ",
    "hebbian learning with different types of neurons ( or synapses ) instead of letting the same neurons behave differently under different conditions of success or failure .",
    "such a model could have the advantage that the hebbian connections , in which the input  output relations are memorized on success , would not have to be changed on failure .",
    "thus , instead of changing the same connections , different , anti ",
    "hebbian connections could possibly do the job of searching for successful output patterns , without changing the already learned input  output relations .    as a final remark",
    ", we mention that different extensions or alterations are possible to enhance the performance of the network , which may , however , be implausible biologically .",
    "for example , if an input  output relation would not be strengthened over and over again once it has been learned , the network generally would perform better ."
  ],
  "abstract_text": [
    "<S> a feed  forward neural net with adaptable synaptic weights and fixed , zero or non  zero threshold potentials is studied , in the presence of a global feedback signal that can only have two values , depending on whether the output of the network in reaction to its input is right or wrong .    </S>",
    "<S> it is found , on the basis of four biologically motivated assumptions , that only two forms of learning are possible , hebbian and anti  hebbian learning . </S>",
    "<S> hebbian learning should take place when the output is right , while there should be anti  </S>",
    "<S> hebbian learning when the output is wrong .    for the anti  </S>",
    "<S> hebbian part of the learning rule a particular choice is made , which guarantees an adequate average neuronal activity without the need of introducing , by hand , control mechanisms like extremal dynamics . a network with realistic , i.e. , non  zero threshold potentials is shown to perform its task of realizing the desired input  </S>",
    "<S> output relations best if it is sufficiently diluted , i.e.  if only a relatively low fraction of all possible synaptic connections is realized . </S>"
  ]
}