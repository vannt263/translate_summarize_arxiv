{
  "article_text": [
    "in statistical mechanics the physical properties of fluctuating systems are usually described in terms of correlation functions which are defined as the expectation values of products of observables located at different points in space and/or time . for example , the critical equilibrium state of the ising model is known to be characterized by spin - spin correlations of the form @xmath0 here @xmath1 is the local classical ising spin at site @xmath2 , @xmath3 denotes the ensemble average , @xmath4 is the dimension , and @xmath5 is the associated critical exponent .    another important pillar of statistical physics is the concept of entropy which describes the information content of a system . more specifically , if a randomly evolving system is characterized by a set of possible configurations ( microstates ) @xmath6 with a probability distribution @xmath7 , the amount of information needed to specify a particular configuration @xmath8 ( in bit times @xmath9 ) is given by @xmath10 averaging over all configurations one obtains the boltzmann - gibbs or shannon entropy @xmath11 which describes the mean information content of the system .",
    "for example , in the equilibrium state of the ising model , where the probability of a configuration @xmath12 is given by the boltzmann weight @xmath13 normalized by the partition sum @xmath14 , the average entropy is given by @xmath15 .",
    "clearly , entropy as defined above is a quantity that characterizes the system globally .    in the present work",
    "we suggest to look at entropy from a different perspective : instead of defining entropy as a _",
    "quantity @xmath16 , we want to use it as a _ local _ observable  @xmath17 which describes the information content of a microscopic portion of the system , in the simplest case the information of a single site @xmath2 .",
    "such a local entropy is particularly interesting in models with infinitely many possible configurations per lattice site . as a natural candidate",
    ", we will study here a particular growth process , where the height above a lattice site is unrestricted .",
    "the local entropy @xmath17 , as will be defined below , can be viewed as a special kind of one - point function .",
    "likewise it is possible to study the joint entropy @xmath18 at two different lattice sites @xmath2 and @xmath19 .",
    "if these sites are uncorrelated one expects that @xmath20 .",
    "therefore , it is useful to consider the `` connected part '' @xmath21 which is known as the _ mutual information _ in information theory  @xcite .",
    "roughly speaking @xmath22 quantifies how much information site @xmath2 has about the state of site @xmath19 and vice versa .",
    "this concept can be easily generalized to @xmath23-point functions by considering the corresponding multivariate mutual information .",
    "note that this concept differs from previous studies , where the mutual information between sections of a bipartite system was studied  @xcite .",
    "entropic correlation functions like the mutual information differ from ordinary correlation functions insofar as the logarithm is a nonlinear function and therefore involves arbitrary high powers of the local field variables .",
    "for this reason it is not obvious whether such a correlation function exhibits the same type of phenomenological scaling laws as ordinary ones in the vicinity of a phase transition .",
    "however , the results of the present work suggest that it is possible to establish a set of consistent scaling laws .",
    "( b ) solitary particles and particles at the edges of plateaus evaporate at rate @xmath24 .",
    "( c ) particles from the middle of a plateau desorb at rate @xmath25 .",
    "( d ) deposition and evaporation is forbidden if the resulting configuration would violate the rsos constraint ( [ rsos]).,width=453 ]    as an example of a model with infinitely many possible configurations per lattice site , we study a simple solid - on - solid growth process which was discussed some time ago in the context of non - equilibrium wetting  @xcite . the model is defined on a one - dimensional periodic lattice with @xmath26 sites labeled by @xmath27 .",
    "each site carries an unbounded variable @xmath28 which describes the height of an interface above an inert substrate .",
    "moreover , an effective interaction ( surface tension ) is introduced by imposing the so - called restricted solid - on - solid ( rsos ) condition @xmath29 ) .",
    "it is controlled by two parameters , namely , a growth rate @xmath30 , and another parameter @xmath25 for the desorption from the middle of plateaus which allows one to interpolate between equilibrium and non - equilibrium ( see ref .",
    "@xcite for further details ) .",
    "the growth model defined above is known to exhibit a continuous phase transition from a bound to a moving phase at a particular threshold @xmath31 .",
    "this transition can be described in terms of two different order parameters , namely , the interface width @xmath32 defined as the standard deviation of the height , and the density @xmath33 of contact points at the bottom layer . moreover ,",
    "the critical behavior is characterized by a typical correlation length @xmath34 and correlation time @xmath35 . in the stationary bound phase close to the transition , where the critical parameter @xmath36 is small and positive",
    ", these quantities scale as @xmath37 provided that the system size @xmath38 is large enough . at the critical point @xmath39 ( @xmath40 ) one finds instead an asymptotic time dependence of the form @xmath41 where @xmath42 , @xmath43 , and @xmath44 . starting with a flat initial state in the bound phase near the critical point one observes a crossover from ( [ timescaling ] ) to ( [ statscaling ] ) which can be expressed by scaling forms with certain universal scaling functions .",
    "for example , one finds that the interface width grows with time according to the scaling form @xmath45 the values of the critical exponents and the scaling functions are determined by the universality class of the phase transition . in the present model the parameter @xmath25 allows one to choose between three different classes , namely , the bounded kpz class with positive and negative nonlinearity ( bkpz@xmath46 ) for @xmath47 and @xmath48 , as well as the bounded edwards wilkinson class ( bew ) for @xmath49 .",
    "the expected values of the critical exponents and the corresponding critical thresholds are listed in table [ tab : exponents ] .",
    ".values of the critical parameters and the expected critical exponents  @xcite of the growth process in 1 + 1 dimensions .",
    "the exponents are related by the scaling relations @xmath43 , @xmath42 , @xmath50 , and in 1 + 1 dimensions by @xmath51 . [ cols=\"^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]      for @xmath49 and @xmath52 the model defined above",
    "is known to relax into an boltzmann - distributed equilibrium state obeying detailed balance .",
    "this state is characterized by the partition sum @xmath53 which runs over all configurations compatible with the rsos constraint ( [ rsos ] ) . to see this note that in a model _ without _ the rsos constraint ( [ rsos ] ) each site would independently perform a bounded biased random walk in height direction .",
    "these decoupled random walks would evolve into a stationary state obeying detailed balance , where the probability of finding the value @xmath54 is proportional to  @xmath55 .",
    "clearly , such a decoupled system would be described by the partition sum  ( [ z ] ) with unrestricted summation .",
    "then , imposing the additional constraint ( [ rsos ] ) , it is easy to see that detailed balance is not violated and that the boltzmann weights are preserved ,  the only thing what changes is the summation ( [ z ] ) which is now restricted to configurations satisfying the constraint ( [ rsos ] ) .",
    "the stationary state for @xmath49 can be described in terms of a transfer matrix formalism  @xcite by reorganizing the partition sum ( [ z ] ) as @xmath56    \\ , , \\nonumber \\\\\\end{aligned}\\ ] ] where @xmath57 is the transfer matrix with the infinite - dimensional tridiagonal representation @xmath58 defining canonical basis vectors @xmath59 and @xmath60 the probability of finding site @xmath2 at height @xmath54 is then given by @xmath61 } { \\tr[t^l ] } \\;=\\ ; \\frac{\\langle h|t^l| h \\rangle}{z}\\,.\\ ] ] the transfer matrix @xmath57 is symmetric and has a non - degenerate spectral decomposition @xmath62 with real eigenvalues @xmath63 and pairwise orthonormal eigenvectors @xmath64 and @xmath65 . since a high power of such a matrix is dominated by its largest eigenvalue , we may therefore approximate @xmath66 in the thermodynamic limit @xmath67 by @xmath68 where @xmath69 denotes the largest eigenvalue of @xmath57 with the corresponding eigenvectors @xmath70 and @xmath71 .",
    "consequently @xmath72 so that the expectation value of finding a site at height @xmath54 is given by @xmath73 remarkably , the transfer formalism reminds one of the dirac formalism in quantum mechanics although the present problem is classical .    for general @xmath52",
    "the determination of the dominating eigenvector is non - trivial and to our knowledge a closed solution is not yet known .",
    "however , close to the transition , where @xmath74 is small , the eigenvector @xmath75 can be approximated by an airy function of the form  @xcite @xmath76\\,,\\ ] ] where @xmath77 is the largest root of ai@xmath78 and @xmath79 is the corresponding normalization .",
    "in a growth process the local entropy at site @xmath2 is given by @xmath80 near criticality , where @xmath81 is small , the probability @xmath82 to find the interface at height @xmath54 is expected to obey the scaling form @xmath83 where @xmath84 is a scaling function determined by the universality class selected by @xmath25 . replacing the sum in ( [ onepoint ] ) by an integral and inserting this scaling form",
    "one can show that the one - point entropy scales as @xmath85 in the limit @xmath86 , where @xmath87 since the universal scaling function @xmath84 is only defined up to a rescaling the constant @xmath88 is non - universal . for @xmath49 , where the exact solution ( [ airy ] ) leads to the scaling function @xmath89",
    ", we obtain the numerical value @xmath90 .        to confirm the predicted scaling behavior , we measured the local entropy in a numerical simulation ( see fig .  [",
    "fig : entropy ] ) . in the edwards - wilkinson case",
    "@xmath49 the numerical data ( red dots ) agree very well with the transfer matrix results . moreover , the logarithmic decay with a slope @xmath91 is in agreement with the expected exponent @xmath92 . for @xmath93",
    "the measured slope @xmath94 is not in full agreement with the expected exponent @xmath95 of the bkpz- class .",
    "this confirms that the crossover from ew to kpz behavior of this particular model is very slow , see ref .",
    "@xcite for a detailed discussion .",
    "by means of the rsos constraint ( [ rsos ] ) the lattice sites are not independent , but exchange some information about their local state .",
    "as outlined in the introduction , this information exchange is most naturally quantified by the mutual information @xmath96 between two sites @xmath2 and @xmath19 . because of periodic boundary conditions the mutual information will only depend on the distance @xmath97 between the points , i.e. , @xmath98 .    in the special case of @xmath49 the transfer matrix formalism",
    "provides a tool to calculate the mutual information analytically . to this end",
    "one has to compute the joint entropy @xmath99 in terms of the joint probability @xmath100 .",
    "this probability is given by @xmath101 were the sum runs over all possible configurations while keeping the heights @xmath102 and @xmath103 at the positions @xmath2 and @xmath19 fixed .",
    "using the transfer matrix method these probabilities can be expressed as @xmath104 although it is not trivial to calculate the mutual information from this expression , one can find useful approximations in the limit of short as well as very large distances .",
    "* short distance limit : * + if the distance between the two points is much shorter than the correlation length , one can estimate the decay of the mutual information as follows . first note that the mutual information can be written as @xmath105 with the conditional entropy    @xmath106    for neighboring sites the conditional probability to find sites @xmath107 at height @xmath108 given that site @xmath2 is at height",
    "@xmath109 reads @xmath110 in the limit @xmath111 , where @xmath112 , this expression reduces to @xmath113 this shows that on short distances the interface height @xmath109 increases or decreases by one unit or stays at the same height with equal probability as we move to the neighboring lattice site . in other words , on short distances the interface describes an unbiased random walk in height direction .",
    "therefore , if the distance @xmath97 is sufficiently larger than 1 , but still smaller than the correlation length , the central limit theorem implies that the conditional probability @xmath114 is approximately given by a normal distribution centered around @xmath109 with the width proportional to @xmath115 .",
    "consequently the conditional entropy is of the form @xmath116 with the numerical offset @xmath117 .",
    "inserted into  ( [ mi_m1 ] ) and using ( [ i0 ] ) this leads to @xmath118 with the numerical value @xmath119 .",
    "* long distance limit : * + in the limit where @xmath97 is much larger than the correlation length , the two sites are almost statistically independent so that the joint probability distribution @xmath100 differs only slightly from @xmath120 , i.e. @xmath121 where @xmath122 .",
    "this allows the mutual information to be expanded as @xmath123 \\fl\\qquad \\qquad\\quad   = -\\sum_{h_i , h_j}p(h_i)p(h_j)\\ln [ p(h_i)p(h_j ) ] + \\sum_{h_i , h_j}p(h_i , h_j)\\ln p(h_i , h_j)\\\\ \\fl\\qquad \\qquad \\quad = \\sum_{h_i , h_j } \\bigl[\\biggl(1+\\ln p(h_i)p(h_j)\\biggr ) \\eta_{h_i , h_j } + \\frac{\\eta^2_{h_i.h_j}}{2p(h_i)p(h_j)}\\bigr ] + \\mathcal{o}(\\eta^3)\\,.\\nonumber\\end{aligned}\\ ] ] to compute the small deviation @xmath124 , we insert the spectral decomposition ( [ specdec ] ) into eq .",
    "( [ pij ] ) one obtains @xmath125 thus we can identify @xmath126 with the first summand , i.e. @xmath127 where @xmath128 is the gap ratio between the leading and the next - to - leading eigenvalue . inserting this expression back into the expansion ( [ expansion ] ) one can show by using the orthogonality of the eigenvectors @xmath129 that the first - order contribution vanishes . therefore , to second order in @xmath126 the mutual information is given by @xmath130 this means that in the long - distance limit the mutual information decays exponentially as @xmath131 with the correlation length @xmath132 the correlation length , which is determined by the first gap ratio @xmath133 of the transfer matrix , depends on @xmath81 . as expected",
    ", one finds numerically that @xmath134 in agreement with the scaling behavior of eq .",
    "( [ airy ] ) .    * scaling form : * + the two asymptotic formulas ( [ shorteq ] ) and ( [ longeq ] ) , which both depend on the scale - invariant ratio @xmath135 , suggest that the crossover from one behavior to the other is given by a scaling law of the form @xmath136 where @xmath137 is a scaling function which is expected to be universal . because of ( [ shorteq ] ) and ( [ longeq ] ) this scaling function behaves asymptotically as @xmath138 note that in contrast to conventional scaling forms , there is no leading power law in front of the scaling function @xmath137 in eq .",
    "( [ scalingform ] ) .     plotted as a function of the scale - invariant combination @xmath139 , leading to a data collapse according to the scaling form ( [ scalingform ] ) . left : numerical data for the bounded edward - wilkinson case @xmath49 together with the short- and long - time approximations in eqs .",
    "( [ shorteq ] ) and ( [ longeq ] ) shown as dashed lines .",
    "right : corresponding data collapse in the bkpz case @xmath93 ( see text ) .",
    ", width=529 ]    to test this hypothesis we measured the mutual information as a function of @xmath140 in a numerical simulation for various values of @xmath141 . as shown fig .",
    "[ fig : mutual ] one obtains a convincing data collapse in the case @xmath49 .",
    "similar results are obtained by using the transfer matrix formalism . for @xmath93 the best possible data collapse is obtained for @xmath142 which differs from the expected value @xmath143 for the bkpz- class .",
    "this discrepancy is again caused by the slow crossover from ew to kpz in this model .",
    "in stochastic lattice models the local entropy describes the information content or uncertainty of the local state of a single lattice site .",
    "likewise the mutual information describes how strongly two sites are correlated .",
    "these quantities are particularly interesting in models with infinitely many states per site , where they can not expressed as finite linear combinations of ordinary correlation functions .",
    "this leads to the question how entropic observables behave in systems with a continuous phase transition .    as an example",
    ", we have studied a simple growth model of a one - dimensional interface . in this model",
    "the interface at site @xmath2 is described by a local height @xmath144 and thus it has infinitely many states per site . moreover",
    ", the model exhibits an unbinding transition from the substrate controlled by the growth rate .",
    "another parameter allows one to select various universality classes with different critical exponents .    as for the local entropy ,",
    "interpreted here as a one - point function , we find a logarithmic scaling behavior of the form @xmath145 where @xmath81 parametrizes the distance from criticality and @xmath146 is one of the critical exponents listed in table [ tab : exponents ] .",
    "this result is expected since this exponent characterizes the width of the interface close to the transition .",
    "the scaling behavior of the mutual information between two lattice sites , interpreted here as a two - point function , depends on the distance @xmath140 between the two points . for @xmath49",
    "we find the asymptotic behaviors @xmath147 where @xmath148 denotes the correlation length .",
    "we expect these limits to remain valid in the kpz case @xmath149 , using the corresponding kpz exponents .",
    "this asymptotic limits in eq .",
    "( [ concmutual ] ) suggest the general scaling form @xmath150 in the present model this scaling form can be confirmed numerically , leading us to the conjecture that the scaling function @xmath137 is universal in the same sense as for ordinary correlation functions .",
    "however , in contrast to ordinary scaling functions , which usually describe the crossover between different power laws or the crossover from a power law to an exponential decay towards a constant , the function @xmath137 describes a crossover from a logarithmic to an exponential decay .",
    "moreover , it is important to note that there is no leading power law in front of  @xmath137 , meaning that the mutual information does not carry an intrinsic scaling dimension .",
    "ordinary correlation functions carry an intrinsic scaling dimension which is usually determined by the scaling dimensions of the local observables . in entropic correlation functions , however , the logarithm involves arbitrary powers of local observables and therefore it is plausible that it can not carry an intrinsic dimension . whether or not this is a general feature of entropic correlation functions remains to be seen .",
    "the proposed concept of entropic one- and two - point functions can easily be generalized to @xmath151 points by considering the so - called multivariate information between these points .",
    "moreover , it is straight forward to apply similar ideas to quantum systems by replacing the local shannon with the corresponding von - neumann entropy .",
    "99 mackay djc , _ information theory , inference , and learning algorithms _ , cambridge university press , cambridge , u.k ."
  ],
  "abstract_text": [
    "<S> in statistical physics entropy is usually introduced as a global quantity which expresses the amount of information that would be needed to specify the microscopic configuration of a system . however , for lattice models with infinitely many possible configurations per lattice site it is also meaningful to introduce entropy as a local observable that describes the information content of a single lattice site . </S>",
    "<S> likewise , the mutual information can be interpreted as a two - point correlation function . studying a particular growth model </S>",
    "<S> we demonstrate that the mutual information exhibits scaling properties that are consistent with the established phenomenological scaling picture . </S>"
  ]
}