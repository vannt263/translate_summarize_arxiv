{
  "article_text": [
    "while it is widely accepted that the enormous luminosities of active galactic nuclei  ( agns ) are attributable to accretion of matter onto supermassive black holes  ( bh ) , detailed studies are extremely challenging on account of the small angular scales of the regions involved in the accretion process .",
    "direct probes of the sub - microarcsecond structure of agns has been therefore limited to vlbi studies of the radio - emitting regions , gravitational microlensing studies of the accretion disk  ( see review by @xcite ) and reverberation mapping of the broad - line regions  ( @xcite ) . the technique of reverberation mapping ( a.k.a .",
    "echo mapping ) exploits the light travel time between the central engine and the broad - line region  ( blr ) to deduce the structure of the blr ( see @xcite for a tutorial ) . the continuum radiation from the accretion disk photoionizes gas clouds near the agn to produce broad emission lines , thus encoding the geometry and kinematics of the clouds  ( @xcite ) .",
    "the physical _ ansatz _ for reverberation mapping is straightforward :    1 .",
    "the continuum emission of the quasar shows ( stochastic ) variability that drives emission - line variations after a light travel - time delay .",
    "2 .   the unobservable ionizing uv continuum that drives the emission lines is simply related to the observable satellite uv or optical continuum ( i.e.",
    ", the pattern and phase of variations are closely correlated ) .",
    "the light - travel time is the most important time scale ; specifically , the local emission - line response time to continuum changes is assumed to be instantaneous and the dynamical time scale of the blr is much larger than the light - travel time across it .",
    "the relationship between the observables , continuum light curve @xmath1 and the emission - line light curve @xmath2 where @xmath3 is the line - of - sight velocity , is taken to be @xmath4 where @xmath5 is known as the `` transfer function '' or `` velocity  delay map . ''",
    "in reality , the relationship between the continuum and emission - line variations can be non - linear , but the amplitude of variation on reverberation time scales is sufficiently small that the linear approximation seems to be justified .",
    "inspection of equation ( [ eq : rmdefn ] ) shows that @xmath6 is the observed response of the broad emission - line region to a delta - function continuum outburst , mapped into the observable quantities time delay @xmath7 and line - of - sight velocity @xmath3 .",
    "the data requirements for successful recovery of the transfer function are quite demanding @xcite and consequently most efforts to date have concentrated on measuring only the _ total _ emission - line response to continuum variations .",
    "the transfer equation ( eq . [ eq : rmdefn ] ) then becomes @xmath8 where @xmath9 is variously known as the `` one - dimensional transfer function '' ( so that @xmath10 is the `` two - dimensional transfer function '' or the `` delay map '' ) .",
    "for the remainder of this paper , we will refer to @xmath11 simply as the `` transfer function . '' in most investigations to date , it is the mean response time or `` lag '' @xmath12 that one tries to measure , generally by cross - correlation of the continuum and emission - line light curves , as we discuss further below .",
    "the importance of measuring the emission - line lag is two - fold : first , @xmath12 yields a characteristic physical scale for emission of a particular line , @xmath13 , and this can be combined with some measure of the emission - line doppler width @xmath14 to obtain an estimate of the central black hole mass . assuming that gravity is the dominant force on the line - emitting gas , the virial equation for the central black hole mass is @xmath15 where @xmath16 is the gravitational constant and @xmath17 is a dimensionless factor of order unity that depends on the geometry , velocity field , and inclination of the blr .",
    "we note in passing that there is currently an active debate about the relative importance of radiation pressure on the blr gas and how this affects reverberation - based mass measurements ( @xcite ) . while the possible",
    "role of radiation pressure in measurement of black hole masses is an important issue , it has no direct bearing on the present discussion , which is about measuring time delays . similarly , there is still active discussion about the mean value of the scaling factor @xmath18 ( e.g. , @xcite ) that is beyond the scope of this contribution .",
    "second , reverberation studies have established a tight empirical relationship between the blr size and the agn continuum luminosity ( @xcite ) that allows us to use the luminosity as a surrogate for the blr size in eq .",
    "( [ eq : virial ] ) and thus estimate the masses of black holes in agns from individual spectra ( @xcite ) . this allows us to explore bh properties and evolution with redshift  ( e.g. , @xcite ) , thus providing valuable insights into the mystery of black hole growth and its connection to galaxy evolution at high redshift , where the quasar population is evolving dramatically .",
    "the potential for obtaining simple estimates for the masses of black holes in quasars provide a means of exploring the correlations between the bh mass and global properties of their host galaxies such as the bulge luminosity  ( @xmath19@xmath20 relationship ; @xcite ) and bulge stellar velocity dispersion  ( @xmath19@xmath21 relationship ; @xcite  gebhardt et al .",
    "2000a , b ;  @xcite ) both locally and potentially over cosmic time .    as a practical problem in aperiodic time - series data analysis ,",
    "reverberation mapping requires high - fidelity spectroscopic monitoring of the continuum and emission - line variations for a duration long compared to the emission - line lag  @xcite , which is observed to range from hours to a year or more , depending on the luminosity of the agn and the cosmic time dilation at its redshift .",
    "emission - line lags have been measured for more than three dozen agns by cross correlation of the continuum and emission - line light curves .",
    "the particular challenge of dealing with reverberation time series is that they are generally irregularly sampled for various reasons , including unfavorable weather and , for higher - luminosity objects with larger lags , annual conjunctions with sun that cause seasonal gaps in the observed time series . in practice ,",
    "two methodologies have been widely employed to deal with unevenly sampled data .",
    "the first method is to interpolate between real data points to obtain a regular sampling grid for computation of the cross - correlation function ( ccf ) as a function of time delay @xmath7 ( @xcite ) .",
    "the second method , the discrete correlation function ( dcf ) method @xcite , bins the data over discrete time intervals on which the data are reasonably well - sampled and a correlation coefficient is computed for the time delays between each pair of continuum / emission - line time bins .",
    "a variant on this is the @xmath22-transformed dcf @xcite which varies the width of the time bins to better distribute the data points among the time bins .",
    "@xcite show that when common assumptions and normalizations are used , the interpolation ccf method and the dcf method give similar results .",
    "however , as the time - sampling becomes sparser , the interpolation method significantly outperforms the dcf method as long as interpolation of the light curves ( usually linear in practice ) remains a reasonable assumption ) , thus providing an empirical justification for using equation ( [ eq : virial ] ) to estimate the black hole mass .",
    "analysis of these same data with the dcf method @xcite obscured this result at least in part because of `` discretization noise '' introduced by the dcf : because of the regular 4-day sampling , the smallest usable time bin for the dcf was also four days , resulting in lag measurements that were integer multiples of 4 days , significantly reducing the time resolution of the lag measurements and smearing out the @xmath23@xmath14 anticorrelation . ] .",
    "presumably even more accurate lags could be measured given more realistic modeling of the continuum behavior between real measurements of the continuum and emission - line fluxes .",
    "this now seems to be a real possibility given the recent work of @xcite , who find that quasar variability can be well described by a damped random walk . by applying the variability model to the light curves of known quasars and comparing them to other variable sources , @xcite",
    "show that quasars occupy a very distinctive region in the model parameter space of time scale and variability amplitude .",
    "@xcite then apply the model to @xmath24 9,000 spectroscopically identified quasars in sdss stripe 82 .",
    "they confirm that the model can describe quasar variability well and they explore the correlation of the variability parameters with other properties of quasars such as wavelength , luminosity , bh mass , and eddington ratios in detail .",
    "importantly for reverberation studies , the formalism is able to statistically predict the value of light curve at an unmeasured time based on the overall statistical properties of the light curve .",
    "it provides a well - defined statistical model for interpolating light curves and can do appropriate statistical averages over the uncertainties in the model predictions .    given a complete statistical framework for describing the continuum variability , and the overall _ ansatz _ that emission - line variability is a scaled and smoothed version of the continuum , we can build an alternative approach to measuring reverberation lags , aspects of which were previously noted by @xcite . among the advantages of this approach",
    "are :    1 .",
    "it not only interpolates between data points , but also self - consistently estimates and includes the uncertainties in the interpolation .",
    "2 .   it can separate light curve means , trends , and systematic errors in flux calibration from variability signals and meansurement noise in a self - consistent way .",
    "correlated errors can be treated naturally .",
    "lags of multiple emission lines and their covariances can be derived simultaneously .",
    "it provides statistical confidence limits on the lag estimates as well as other parameters .",
    "we describe the methodology of our approach in detail in ",
    "[ sec : method ] . in  [ sec : cont ] , we present the statistical process model for the continuum light curves .",
    "we briefly describe our data set and apply this method to the estimate of h@xmath0 lags in  [ sec : hbeta ] .",
    "we further show how the method can address the problem of correlated errors in  [ sec : corr ] and how it can be used to improve lag estimates , particularly in the presence of seasonal gaps , by fitting multiple lines simultaneously in ",
    "[ sec : doublehat ] .",
    "we also fit the @xmath25@xmath26 relationship using h@xmath0 lags determined by our method in  [ sec : rlrelation ] . in  [ sec : breath ] , we add a luminosity dependence to the lag and solve for the lag  luminosity relationship of ngc  5548 . we summarize our main findings and discuss future applications and expansions of our approach in  [ sec : dis ] .",
    "@xcite and @xcite developed a method to statistically analyze irregularly sampled light curves , and @xcite applied the variant we now consider to four seasons of optical reverberation data on ngc  5548 .",
    "here we reintroduce this approach , which we have named `` stochastic process estimation for agn reverberation ( spear ) , '' with several modest changes in algorithm and a broad range of new applications .    except for the transfer function @xmath27 ,",
    "our notation is chosen for comparison with @xcite .",
    "we start with a model process driving the continuum @xmath1 that has a covariance between times @xmath28 and @xmath29 of @xmath30 we adopt here an exponential covariance matrix for concreteness , since we know from @xcite , @xcite and @xcite that quasar light curves are well modeled by this process .",
    "physically , the model corresponds to a random walk described by an amplitude @xmath31 on long time scales and an exponential damping time scale @xmath32 , where @xmath33 and @xmath32 are used as our model parameters .",
    "@xcite estimated the covariance matrix based on the structure function of the continuum light curve , while here we adopt a specific parametrized model that will be optimized as part of the analysis .    slightly rewriting equation ( [ eq : tfdefn ] ) for convenience and to facilitate comparison with @xcite ,",
    "the light curve of a line is @xmath34 since the lines and continuum are related by the transfer function , we can also determine the covariance between the line and continuum @xmath35 between the line and itself @xmath36 and between two different lines @xmath37 if the light curve of the line is divided into velocity bins @xmath38 , then there is a transfer function for each bin @xmath39 and we can compute all the expected covariances between the light curves . for convenience , let @xmath40 be a vector comprised of all the light curves , both line and continuum , and @xmath41 be the covariance matrix between all the elements of @xmath42 . by definition , in gaussian statistics the probability of the light curve is simply @xmath43 we do not measure the actual light curve , but some realization of it , @xmath44 , in which there is measurement error @xmath45 , whose probability distribution is @xmath46 where @xmath47 is the covariance matrix of the noise .",
    "note that nothing requires @xmath48 to be diagonal , so there is no formal difficulty to including covariances in the noise between the line and continuum .    in defining @xmath49 ,",
    "we have also allowed for the simultaneous fitting of a general trend defined by a response matrix @xmath26 and a set of linear coefficients @xmath50 .",
    "in particular , we use this to fit and remove separate means from the light curves . in this application to a model with two light curves , @xmath26 is a @xmath51 matrix with entries of @xmath52 for the continuum data points and @xmath53 for the line data points , where @xmath54 is the total number of data points .",
    "the linear parameters are a very general tool .",
    "for example , separate linear trends would be removed with a @xmath55 matrix with entries of @xmath56 for continuum epoch @xmath28 and @xmath57 for line epoch @xmath29 .",
    "two sources of data with potentially different _ but constant _ levels of contamination from the host galaxy can be reconciled by using different means for each line and continuum data source , corresponding to a @xmath58 matrix with entries of @xmath59 for the first continuum source , @xmath60 for the second continuum source , @xmath61 for the first line source and @xmath62 for the second line source . unlike current approaches focused on cross - correlation functions , the uncertainties in these linear parameters are fully incorporated into the uncertainties in any other parameter estimate .",
    "given these definitions , the probability of the data @xmath49 given the linear coefficients @xmath50 , the intrinsic light curves @xmath42 , and any other parameters of the model @xmath63 is @xmath64 after evaluating the dirac delta function , we `` complete the squares '' in the exponential with respect to both the unknown intrinsic source variability @xmath42 and the linear coefficients @xmath50 .",
    "this exercise determines our best estimate for the intrinsic variability @xmath65 and the linear coefficients @xmath66 where @xmath67 is the overall covariance matrix of the data and @xmath68 . with these definitions",
    "we can factor the argument of the exponential into @xmath69 where @xmath70 is the component of @xmath71 that is orthogonal to the fitted linear functions , the variances in the linear parameters are @xmath72 @xmath73 and @xmath74 .",
    "we can marginalize the probability over the light curve @xmath42 and the linear parameters @xmath50 under the assumption of uniform priors for these variables to find that @xmath75 where @xmath76 represents the likelihood function we are to maximize , and the remaining parameters @xmath63 are those describing the process ( equation  [ eqn : cfunc ] ) and the transfer functions .",
    "the term in the exponent , @xmath77 , is the generalized @xmath78 that we present throughout the paper .",
    "while this treatment of linear parameters was included by @xcite , @xcite chose to subtract fixed means rather than marginalizing over them as part of the analysis as we do here .",
    "the variance in the estimate for the mean light curve is @xmath79    we can estimate the light curve @xmath80 at any unmeasured time using the same formalism .",
    "the simplest means of doing so is simply to pad the data vector @xmath81 with additional fake points @xmath82 that have infinite measurement uncertainties in the sense that @xmath83 for these points .",
    "after appropriately partitioning the matrices , the estimate of the light curve at the unmeasured points is @xmath84 with variance relative to the true light curve of @xmath85 where @xmath86 , @xmath87 , @xmath88 and @xmath89 are the data - data , fake - fake , fake - data and data - fake covariance matrices of the process and @xmath90 is the noise matrix of the data .",
    "the inclusion of the fake points has no effect on the expected results for the measured data points .",
    "just to re - emphasize the point , this formalism was first outlined by @xcite based on @xcite and @xcite .",
    "we have refined it slightly to use a specific process model , to optimize the parameters of that model and to include the means of the light curves as parameters that are automatically marginalized .",
    "unfortunately , we will not be able to use the fast implementation of this method for exponential covariance matrices from @xcite , because the inclusion of the transfer functions means that @xmath91 is not a simple exponential covariance matrix and hence does not have a simple , tridiagonal inverse for the fast method .",
    "we can , however , use the fast methods for generating simulated light curves .",
    "in particular , we are interested in light curves constrained to resemble the continuum light curve . as discussed by @xcite ,",
    "such a light curve is simply the estimated mean light curve given by equation ( [ eqn : shat ] ) with an added random component that has the covariance matrix @xmath92 .",
    "@xcite suggest determining the eigenmodes of @xmath93 which are then the independent `` normal '' modes that can be added to the mean light curve to produce a random realization constrained by the continuum light curve .",
    "this is computationally expensive .",
    "instead , we note that if we cholesky decompose @xmath94 , where @xmath95 is an upper triangular matrix , and define the random component of the light curve by @xmath96 where @xmath97 is a vector of zero - mean , unit - dispersion gaussian random deviates , that @xmath98 since the covariance matrix @xmath99 of the gaussian deviates is simply the identity matrix and @xmath93 is symmetric .",
    "since @xmath100 is a tridiagonal matrix given the exponential covariance matrix and a diagonal noise matrix , we can generate very high dimension @xmath101 that can be convolved with the transfer function to produce a simulated line light curve in @xmath102 operations rather than the @xmath103 needed following the eigenmode approach .",
    "the original application of the method by @xcite was to cross correlate the light curves of two images of a lensed quasar in order to estimate the time delay between them .",
    "while this was not discussed in terms of transfer functions , it does correspond to a transfer function of the form @xmath104 , making the second light curve a lagged version of the first .",
    "@xcite also treated the parameters corresponding the process as fixed parameters , derived by fitting a power law to the structure functions of the light curve .",
    "it is likely that some combination of neglecting uncertainties in the process model or covariances in the errors of the light curves led @xcite to obtain an incorrect estimate of the time delay despite the elegance of the approach .    in rybicki & kleyna s  ( 1994 )",
    "expansion of the method to reverberation mapping , they used rising and falling sawtooth and isosceles triangle transfer functions , finding little difference between the results or ability to discriminate between them . thus , for this initial reconnaissance , we will simply use a top - hat ( rectangular function ) for the transfer function , @xmath105 which has a mean lag of @xmath106 and a temporal width of @xmath107 .",
    "the necessary integrals for equations  ( [ eqn : lc ] ) , ( [ eqn : lauto ] ) , and ( [ eqn : lcross ] ) are all analytic ( see the appendix ) and the model includes the limits of a delta function as @xmath108 and a uniform thin shell as @xmath109 .",
    "the scaling coefficient @xmath110 determines the line response for a given change in the continuum  ( i.e. , the responsivity of blr clouds ) , but for present purposes we will largely view it as a nuisance variable .",
    "we use the _ amoeba _ minimization method @xcite to optimize the solution and then either a monte carlo markov chain  ( mcmc , @xcite ) or optimization over a grid to estimate parameter uncertainties .",
    "we carry out the analysis in two phases .",
    "we first analyze the continuum light curve on its own , using logarithmic priors for @xmath32 and @xmath33 to determine the range of the variability process parameters consistent with the continuum light curve .",
    "the logarithmic prior on @xmath32 essentially penalizes values that deviate from the median sampling intervals to avoid both unphysically large @xmath32 and a second class of solutions of @xmath111 , when all data are completely uncorrelated and the model simply uses @xmath112 to broaden the uncertainties until obtaining an acceptable fit .",
    "then we do the joint analysis of the continuum and the lines using gaussian priors for @xmath32 and @xmath33 determined from the analysis of the continuum in isolation . in detail , we take the results of the mcmc analysis of the continuum and used uncorrelated priors on @xmath113 and @xmath114 ( which is conservative ) , where the prior for each variable was centered at the median value with the gaussian width chosen to match the upper and lower @xmath115 confidence regions .",
    "we then used uniform priors for @xmath110 , @xmath116 and @xmath117 .",
    "the reason for using the continuum to define a stronger gaussian prior on the process variable before carrying out the joint analysis is to eliminate the aforementioned second class of solutions of @xmath111 that could potentially bias our lag estimates .",
    "this secondary solution always exists at some level because of the finite temporal sampling . for modeling the continuums",
    ", we are only analyzing cases with significant variability , so this is not an issue for the individual light curves .",
    "however , in the joint analysis , if we fit the line and continuum light curves simultaneously at the wrong lag , the optimal solution will be to let @xmath111 since there are then no correlations between data points .",
    "physically , it made more sense to consider only the ranges for the process variables @xmath32 and @xmath33 that were statistically consistent with the continuum variability .",
    "this approach depends on using a statistical model for the variability process of the continuum in order to optimally model the underlying light curve of the continuum . here",
    "we use the exponential covariance matrix suggested by @xcite , although it was also introduced by @xcite to enable a fast version of the spear approach .",
    "physically , the exponential covariance matrix in equation  [ eqn : cfunc ] corresponds to a damped random walk with an amplitude scale @xmath33 and a damping time scale @xmath32 . on long time",
    "scales the variance of the light curve is @xmath118 and on short time scales it is @xmath119 .",
    "@xcite use this to model the light curves of 100 quasars , including some of the objects we will consider here , using a light curve forecasting approach to estimate the process parameters .",
    "@xcite show how the @xcite approach can be derived from the spear approach and demonstrated that forecasting is less statistically optimal for parameter estimation than using the complete light curve modeling method of spear , and then applied the process model and the spear method to the ogle - iii @xcite light curves of @xmath120 mid - infrared - selected quasars behind the magellanic clouds @xcite .",
    "they confirm that the damped random - walk model describes quasar light curves well , and that quasars occupy a well - defined region of @xmath121@xmath33 parameter space .",
    "this is further confirmed by @xcite , who used this approach to model 9,000 sdss quasars to examine the correlations of @xmath112 and @xmath32 with other quasar properties .    unlike the previous papers , we fit flux rather than magnitude light curves because the line flux is more closely related to the continuum flux than to the continuum magnitude .",
    "thus , we start by examining how well the damped random - walk process models the 60 continuum flux light curves for the 31 systems we consider in  [ sec : hbeta ] .",
    "figure  [ fig : chi2dof ] shows the distribution of the @xmath78 per degree of freedom for the best - fit models of all the continuum light curves we consider . since half of the continuum light curves in our sample have less than 50 data points , the expected @xmath122 distribution is broader than that of the ogle light curves  ( @xmath24 500 points ) considered by @xcite .",
    "nevertheless , the @xmath122 distribution indicates that the statistical process model provides a reasonable fit to the light curves .",
    "the fact that the distribution is narrower than expected for correctly estimated gaussian uncertainties suggests that the reported photometric errors are somewhat larger than the true uncertainties , or that there has been some pruning of outliers from the light curves .",
    "figure  [ fig : contlc ] shows three examples of modeled continuum light curves interpolated and extrapolated from equation  ( [ eqn : shat ] ) and their uncertainties from equation  ( [ eqn : svar ] ) , as well as the observed light curve . the estimated light curve at time",
    "@xmath123 is in essence a weighted average over data points within the damping time @xmath124 that balances the variance expected on those time scales due to the process against the uncertainties in the data point to determine how closely the model light curve approaches a particular data point .",
    "far from any data points , the model returns to the light curve mean on the time scale @xmath32 .",
    "remember , however , that equation  ( [ eqn : shat ] ) is an estimate for the average of all possible light curves that could be drawn from the process that would be consistent with the data  a particular realization of such a light curve would show additional structure ( see @xcite ) .",
    "the `` error snake '' surrounding the model light curve is the variance in these possible light curves . near data points",
    ", its width approaches that of the measurement errors and then grows as the distance @xmath125 from any data point increases .",
    "the variance from the process initially increases as @xmath126 , but then saturates at the overall process variance once @xmath127 .",
    "thus , in the extrapolated regions we see the model light curve becomes a constant and the error snake expands and then becomes constant .",
    "the three objects shown in figure  [ fig : contlc ] represent three typical levels of light - curve sampling quality for the objects we consider . generally , the light curves of the palomar ",
    "green  ( pg ) quasars obtained by @xcite were sampled every 14 months over a baseline as long as 7.5 yr , as opposed to most of the low - luminosity seyfert 1 agns that were more densely sampled over shorter baselines .",
    "the rest of the sample mainly consists of nearby bright seyfert galaxies @xcite whose light curves are sparsely sampled over a short baseline . @xcite",
    "discuss the data in detail .",
    "in addition , we also include new light curves from a recent high sampling rate , multi - month reverberation mapping campaign on six local seyfert galaxies  @xcite .",
    "we expect the damping timescales @xmath32 to show correlations with the physical characteristics of the accretion disk such as the mass of the central black hole , and the agn luminosity @xcite . @xcite demonstrated this scaling relationship between @xmath32 and @xmath128 by performing a linear regression of @xmath32 on @xmath128 , while @xcite also found a positive correlation between the characteristic timescale and black hole masses .",
    "their characteristic timescale , which is defined by the timescale where the structure functions flattened , is roughly equivalent to @xmath32 .",
    "figure  [ fig : taul ] shows that the more luminous central engines have longer exponential damping timescales , as we would expect from @xcite , up to any minor differences from fitting fluxes rather than magnitudes .",
    "note that @xcite argue that the dependence of @xmath32 on black hole mass @xmath19 is the real driver of the correlation between @xmath32 and luminosity .",
    "we can use these correlations to estimate @xmath32 for sources lacking sufficiently good light curves .",
    "as our first application of the spear method we recompute the lags of 101 emission - line light curves for 31 objects in the literature  ( the compilation of @xcite with the addition of data from @xcite , @xcite , and @xcite ) .",
    "we carried out the analysis in three stages .",
    "first , as discussed in  [ sec : cont ] , we modeled the continuum alone to determine the range of process parameters ( @xmath32 , @xmath33 ) consistent with the continuum light curve .",
    "we use this distribution of estimated @xmath32 and @xmath33 as a prior for the joint models of the continuum and line light curves in order to avoid the secondary solutions with @xmath129 as discussed in ",
    "[ sec : method ] .",
    "second , for each joint model , we find the best - fit top hat transfer function  ( equation  [ eqn : tophat ] ) which maximizes the model likelihood calculated by equation ( [ eqn : likefit ] ) , along with an updated set of process parameters . finally , we ran an mcmc analysis on each joint model to calculate the statistical confidence limits on each best - fit parameter found by global optimization on a grid , especially the time lag .",
    "we then compare these estimates to those derived from previous ccf analyses .",
    "we refer to these models as the `` single - line '' fits since they are solving for a single top - hat transfer function .",
    "the dotted histogram in figure  [ fig : chi2dof ] shows the @xmath122 distribution of the single - line model .",
    "it has a similar shape to the @xmath122 distribution of the stochastic model for only the continuum light curve , and confirms that the statistical model provides a good fit to the quasar variability , as well as the overall _ ansatz _ that the h@xmath0 variability is a scaled and smoothed version of the continuum .",
    "the @xmath122 distribution of the single - line model is somewhat worse than for fitting the continuum alone , but still reasonably consistent with statistical expectations .    for the sake of uniformity of emission - line species in the comparison between the spear and the ccf methods , and to avoid confusion in the figures for sources with multiple line observations",
    ", we will focus on the the 66 h@xmath0 light curves in our subsequent analyses , and tabulate all the other emission - line lags we successfully computed with spear in table  [ tab : lags ] .",
    "figure  [ fig : hbetacomp ] shows the comparison between ccf centroid time lags @xmath130 and our lags @xmath131 for all the h@xmath0 lines .",
    "the range of uncertainties for @xmath130 contains @xmath132 of monte carlo realizations in the cross - correlation centroid distribution  ( cccd ) , while our estimated error boundaries are defined by the @xmath132  ( @xmath133 ) confidence levels that encloses the best - fit lags ( i.e. , @xmath134 errors if the probability distribution is gaussian in both cases ) .",
    "based on the structure of the lag probability distribution , we can divide the `` single - line '' fits into five quality groups :    * in most of the cases  ( 43 of 66 ) , the likelihood distribution for the lags has a single peak and there is an unambiguous h@xmath0 lag . * in 9 cases , the likelihood distribution has multiple peaks with significant ( @xmath135 ) likelihood differences .",
    "this occurred for one season of akn  120 ( jd4998050175 ) , mrk  110 ( jd4895349149 ) , and mrk  590 ( jd4918349338 ) ; two seasons of mrk  79 ( jd4819348393 and jd4999650220 ) ; ngc  4051 , pg  0844 , pg  1411 , and pg  1617 .",
    "compared to our estimate , the ccf analysis picks a lower likelihood peak or aliases several peaks into one broad peak .",
    "generally , the two peaks are so close that the differences between the results from the two methods are insignificant compared to the uncertainties . * in 7 cases , the likelihood distribution has multiple peaks of comparable significance  ( @xmath136 : one series of ngc  3516 ( jd4789448047 ) , fairall  9 , pg  0026 , pg  0052 , pg  1211 , pg  1226 , and pg  1307 ) . they are shown in figure  [ fig : hbetacomp ] as the objects with a dashed line connecting the possible solutions .",
    "the traditional ccf method seems to find one broad peak for these sources , rather than multiple peaks , leading to large reported uncertainties for the estimate of @xmath130 .",
    "these degeneracies are largely caused by poor light curve sampling that allows the light curve of the emission line to be mapped into the sampling gaps of the continuum .",
    "this problem is worst for the pg objects , which have many `` seasonal gaps '' over the long observing baselines ( @xmath24 7.5 yr ) , leading to a clustering of solutions around 180 days in the observed - frame .",
    "such seasonal aliasing problems affect the ccf - based methods as well  @xcite . * in four cases ,",
    "the light curves are very poorly sampled : ic  4329a , one season on ngc  4593 ( jd4789448049 ) , one season of mrk  279 ( jd4720547360 ) , and one season of ngc  3227 ( jd4789448045 ) .",
    "these cases were also flagged as unreliable by @xcite , so we exclude them from our subsequent analyses . *",
    "the lags derived from the spear method appear to be wrong in two cases , 3c120 and pg  1613 .",
    "we also exclude both from our subsequent analyses .",
    "the 3c120 light curves have a baseline of 7 years , but are very sparsely sampled .",
    "the ccf method finds a lag @xmath24 40 days in the observed frame .",
    "although we find a sub - peak at 40 days , the model favors another peak of much higher significance at 259 days . for pg  1613",
    "we obtain a lag of @xmath24 575 days in the observed - frame , much larger than the @xmath24 50 day ccf estimate . in both cases ,",
    "the longer lag is favored because it minimizes the data overlap  259 and 575 days put most of the line data in the seasonal gaps , and many points also lie before the start of the continuum light curve . this is essentially an aliasing problem in our method .",
    "we also note that the continuum flux varied by up to 50% over the 7 year span of the light curves . we know empirically that the scaling coefficient @xmath110 in the transfer function is inversely correlated with ionizing continuum flux  ( see the right panel of figure  [ fig : lrs ] and the discussion in  [ sec : breath ] ) , but we treat @xmath110 as a constant parameter in each individual fit",
    ". this may create problems for light curves with the significant long term trends observed for these objects . allowing @xmath110 to vary and adopting a prior that penalizes large lags that minimize light curve overlap",
    "would likely solve these problems .",
    "correlated errors have long been viewed as a problem in traditional ccf analysis .",
    "observations made at a common epoch are inevitably correlated by the processes required for calibration , light curve extraction , broad / narrow line modeling and removal of host or feii contamination . because no assumption about the properties of the noise matrix @xmath48 was made in ",
    "[ sec : method ] , it is easy to include the effects of correlated errors within our approach . while we did not make an extensive survey of our ability to model noise correlations between the continuum and lines , we did carry out some experiments for objects noted as potentially having strong covariances by @xcite .",
    "the simplest test is to introduce a covariance factor @xmath137 and add off - diagonal terms to the noise matrix @xmath48 for line and continuum points measured at the same epoch of @xmath138 in order to examine the sensitivity of the lag estimates to correlated noise between the line and the continuum measured at each epoch .",
    "this should be present in the data at some level because of the challenge of consistently subtracting the contribution of the host galaxy to the line and the continuum in the presence of variable observational conditions .",
    "figure  [ fig : covtest ] illustrates the effects of adding off - diagonal correlated noise terms on the h@xmath0 lag estimate of pg  0844 .",
    "the shift in the estimated lag  ( left top panel ) induced by @xmath139 varying from @xmath140 to @xmath141 is only about 0.25 days , much smaller than the median sampling interval of the light curves .",
    "the corresponding change in the likelihood  ( left bottom panel ) shows a plateau at @xmath142 and slowly asymptotes to a maximum at @xmath143 , suggesting that the errors in the two light curves are positively correlated .",
    "the lag likelihood distribution  ( right panel ) changes if we assume different levels of correlations @xmath139 between the light curves .",
    "while the overall lag likelihood is greatly depressed in the @xmath144 case , the likelihood distributions are nearly identical in the @xmath145 and @xmath143 cases . however , the peaks near the best lag estimate  ( @xmath24 12 days ) are slightly more significant in the @xmath143 case than in the @xmath145 case .",
    "we explored this issue for several other systems , and generally the impact on the estimated lag is negligible , although different levels of ( anti-)correlations are detected .",
    "in  [ sec : hbeta ] , we found that poor light curve sampling was a significant problem in many systems , particularly in objects with observed - frame lags on time scales similar to the seasonal gap spacing .",
    "however , if multiple lines have been measured , then we have significant , additional data to better sample the light curves under our overall _ ansatz _ that all light curves are scaled , smoothed , and displaced versions of the continuum .",
    "simultaneous fits also determine the covariance between the lags of the different lines . in this section ,",
    "we explore simultaneously fitting the continuum and two emission - line light curves  ( hereafter `` two - line '' fits , as opposed to the `` single - line '' fits in  [ sec : hbeta ] , as we are now fitting two top - hat transfer functions ) .",
    "figure  [ fig : joint2_ngc3516 ] summarizes the significant improvement in estimating the h@xmath0 time lag of ngc  3516 of the @xcite data ( jd4789448047 ) after including the h@xmath146 light curve  ( two - line ) compared to using the h@xmath0 line alone  ( single - line ) .",
    "ngc  3516 is a case where the single - line h@xmath0 fits shows a secondary peak at @xmath24 42 days whose likelihood relative to the main peak at @xmath24 6 days is high , @xmath147  ( solid curve in panel b )",
    ". the h@xmath146 fit does not show such a secondary peak  ( panel a ) .",
    "when we fit both simultaneously , the h@xmath146 light curve together with its well - determined lag adds extra information to the continuum light curve , and thus better constrains the h@xmath0 lag .",
    "the second h@xmath0 peak is suppressed and there is a single unambiguous h@xmath0 lag for the two - line fit  ( dotted curve in panel b ) .",
    "the improvement is most clearly seen in the structure of the h@xmath146/h@xmath0 lag likelihood plane  ( panel c and d ) .",
    "if we zoom in on the remaining peak and run a mcmc chain using a flat prior on lags in the zoomed region , we can see that the two - line fits not only suppress the secondary peaks but also shrink the uncertainties in the primary peak to produce better results for both lines  ( panel e ) .",
    "the joint analysis of multiple lines is especially useful for the pg objects , whose light curves show observational gaps of period @xmath24180 days in the observed - frame . in the single line",
    "fits , the model would always show ( sub)peaks for lags @xmath24180 days because of the seasonal aliases  ( the seasonal stripes in figure  [ fig : hbetacomp ] ) .",
    "it is not possible , however , to do this for 2 lines simultaneously , so the two - line fits largely eliminate seasonal aliasing .",
    "figure  [ fig : joint2_pg0026 ] illustrates this for pg  0026 . in particular , the broad h@xmath0 likelihood distribution shrinks significantly and the maximum likelihood lag drops from @xmath24160 days to @xmath24106 days ( @xmath24 140 to @xmath24 93 in the rest frame ) and is in better agreement with the h@xmath146 results .",
    "although the traditional ccf method makes similar estimates  ( green and blue bands in two top panels ) , it yields significantly larger uncertainties by aliasing several peaks into one broad ccf centroid distribution .",
    "lcccc 3c 390.3&h@xmath0&4971850012&@xmath148&a + 3c 390.3&ly@xmath146&4971850147&@xmath149&d + 3c 390.3&civ@xmath150&4971850147&@xmath151&c + akn 120&h@xmath0&4814848344&@xmath152&a + akn 120&h@xmath0&4998050175&@xmath153&b + fairall 9&h@xmath0&5047350665&@xmath154&d + fairall 9&heii@xmath155&5047350713&@xmath156&c + fairall 9&ly@xmath146&5047350713&@xmath157&c + mrk 79&h@xmath0&4783848044&@xmath158&b + mrk 79&h@xmath0&4819348393&@xmath159&a + mrk 79&h@xmath0&4890549135&@xmath160&b + mrk 79&h@xmath0&4999650220&@xmath161&a + mrk 110&h@xmath0&4895349149&@xmath162 & b + mrk 110&h@xmath0&4975149874&@xmath163&a + mrk 110&h@xmath0&5001050262&@xmath164&a + mrk 279&h@xmath0&5009550289&@xmath165&a + mrk 290&h@xmath0&5418454301&@xmath166&a + mrk 335&h@xmath0&4915649338&@xmath167&a + mrk 335&h@xmath0&4988950118&@xmath168&a + mrk 509&h@xmath0&4765350374&@xmath169&a + mrk 509&heii@xmath170&4765350374&@xmath171&d + mrk 590&h@xmath0&4809048323&@xmath172&a + mrk 590&h@xmath0&4884849048&@xmath173&a + mrk 590&h@xmath0&4918349338&@xmath174&b + mrk 590&h@xmath0&4995850122&@xmath175&a + mrk 817&h@xmath0&4900049212&@xmath176&a + mrk 817&h@xmath0&4940449528&@xmath177&a + mrk 817&h@xmath0&4975249924&@xmath178&a + mrk 817&h@xmath0&5420054330&@xmath179&a + ngc 3227&h@xmath0&4862348776&@xmath180&a + ngc 3227&h@xmath0&5418054273&@xmath181&a + ngc",
    "3516&h@xmath146&4789448047&@xmath182&a + ngc 3516&h@xmath0&4789448047 & @xmath183&c + ngc 3516&h@xmath0&5418154300 & @xmath184&a + ngc 3783&h@xmath0&4860748833 & @xmath185&a + ngc 4051&h@xmath0&5418054311 & @xmath186&b + ngc 4151&h@xmath0&5343053471 & @xmath187&a + ngc 4593&h@xmath0&5343053471 & @xmath188&a + ngc 7469&h@xmath0&5023750295 & @xmath189&a + ngc 7469&siiv@xmath190&5024550293&@xmath191&a + ngc 7469&civ@xmath150&5024550293&@xmath192&a + ngc 7469&heii@xmath155&5024550293&@xmath193&a + pg 0026 + 129&h@xmath146&4883651084&@xmath194&b + pg 0026 + 129&h@xmath0&4854551084&@xmath195&c + pg 0052 + 251&h@xmath146&4883751084&@xmath196&a + pg",
    "0052 + 251&h@xmath0&4846151084&@xmath197&c + pg 0052 + 251&h@xmath198&4846151084&@xmath199&c + pg 0804 + 761&h@xmath146&4831951085&@xmath200&c + pg 0804 + 761&h@xmath0&4831951085&@xmath201&a + pg 0804 + 761&h@xmath198&4831951085&@xmath202&d + pg 0844 + 349&h@xmath146&4831951085&@xmath203&a + pg 0844 + 349&h@xmath0&4831951085&@xmath204&b + pg 0844 + 349&h@xmath198&4831951085&@xmath205&c + pg 0953 + 414&h@xmath0&4831950997&@xmath206&a + pg",
    "0953 + 414&h@xmath198&4831950997&@xmath207&d + pg",
    "1211 + 143&h@xmath146&4831951000&@xmath208&c + pg",
    "1211 + 143&h@xmath0&4831951000&@xmath209&d + pg",
    "1211 + 143&h@xmath198&4831951000&@xmath210&a + pg 1226 + 023&h@xmath146&4836150997&@xmath211&b + pg 1226 + 023&h@xmath0&4836150997&@xmath212&d + pg 1226 + 023&h@xmath198&4836150997&@xmath213&a + pg 1229 + 204&h@xmath146&4831950997&@xmath214&a +",
    "pg 1229 + 204&h@xmath0&4831950997&@xmath215&a    lcccc pg 1307 + 085&h@xmath146&4913051000&@xmath216&a + pg 1307 + 085&h@xmath0&4831951042&@xmath217&c + pg 1307 + 085&h@xmath198&4831951042&@xmath218 & d + pg 1411 + 442&h@xmath146&4831951038&@xmath219&a + pg 1411 + 442&h@xmath0&4831951038&@xmath220&b + pg",
    "1426 + 015&h@xmath0&4833451042&@xmath221&a + pg",
    "1617 + 175&h@xmath146&4836251085&@xmath222&b + pg 1617 + 175&h@xmath0&4836251085&@xmath223&b + pg",
    "2130 + 099&h@xmath0&5435254450&@xmath224&a + pg 2130 + 099&heii@xmath170&5435254450&@xmath225&a + ngc 5548&h@xmath0&4750947809&@xmath226&a + ngc 5548&h@xmath0&4786148179&@xmath227&a + ngc 5548&h@xmath0&4822548534&@xmath228&a + ngc 5548&h@xmath0&4862348898&@xmath229&a + ngc 5548&h@xmath0&4895449255&@xmath230&a + ngc 5548&h@xmath0&4930949636&@xmath231&a + ngc 5548&h@xmath0&4967950008&@xmath232&a + ngc 5548&h@xmath0&5004450373&@xmath233&a + ngc 5548&h@xmath0&5043450729&@xmath234&a + ngc 5548&h@xmath0&5077551085&@xmath235&a + ngc 5548&h@xmath0&5114251456&@xmath236&a + ngc 5548&h@xmath0&5151751791&@xmath237&a + ngc 5548&h@xmath0&5187852174&@xmath238&b + ngc 5548&h@xmath0&5418054332&@xmath239&a [ tab : lags ]    we performed similar joint analyses for the 21 sources for which we have multiple emission line light curves and recompile the results for the h@xmath0 lags , as shown in figure  [ fig : hbetacomp2 ] .",
    "fortunately , all the sources whose h@xmath0 lags were found to be ambiguous in the single - line fits  ( i.e. , the 7 h@xmath0 lags from groups slowromancap3@ in  [ sec : hbeta ] ) are improved by the two - line fits , although the degree of improvement varies .",
    "we also dropped lag estimates that were either flagged as unreliable or believed to be wrong ( i.e. , the 6 h@xmath0 lags from groups slowromancap4@ and slowromancap5@ in  [ sec : hbeta ] ) and keep only those objects deemed to give robust estimates of lag by our method ( i.e. , the 60 h@xmath0 lags from groups slowromancap1@ , slowromancap2@ and slowromancap3@ ) . to illustrate the quality of the final result for each source , we divide all 60 remaining sources into 4 new groups based on the results of both the single - line fits in   [ sec : hbeta ] and the two - line fits , using different symbols for the 4 new groups in figure  [ fig : hbetacomp2 ] .",
    "* the 43 group  slowromancap1@ light curves from   [ sec : hbeta ] with a single unambiguous h@xmath0 lag .",
    "seven of the objects have light curves of lines other than h@xmath0 to carry out two - line fits , but they provided little gain when the single - line fits already provided good lag estimates . *",
    "the 10 group  slowromancap2@ sources from ",
    "[ sec : hbeta ] with a robust h@xmath0 lag estimate but potentially larger uncertainties due to the presence of low significance  ( @xmath240 ) sub - peaks in the lag likelihood distribution .",
    "most of those sources do not have the multiple line light curves needed to carry out two - line fits .",
    "* the four group  slowromancap3@ sources  ( ngc  3516 , pg  0026 , pg  0052 , and pg  1307 ) from  [ sec : hbeta ] with multiple peaks in the single - line lag likelihood distribution where the ambiguity is removed by the two - line fits .",
    "* the three group  slowromancap3@ sources  ( fairall  9 , pg  1211 , and pg  1226 ) from  [ sec : hbeta ] with multiple peaks in the single - line lag likelihood distribution where the two - line fits fail to remove the ambiguity .",
    "we picked the most significant peak as the solution and extended the uncertainty to cover all the possible solutions .",
    "lccccccccc a , b , c , d&60&@xmath241&@xmath242&8.13&0.229&@xmath243&@xmath244&3.50&0.203 + a , b , c&57&@xmath241&@xmath245&8.52&0.207&@xmath246&@xmath247&3.54&0.205 + a , b&53&@xmath241&@xmath248&8.39&0.206&@xmath246&@xmath249&3.81&0.213 + a&43&@xmath241&@xmath250&9.44&0.196&@xmath243&@xmath251&4.22&0.211 [ tab : rl ]    recall that we have dropped the 6 group  slowromancap4@ and slowromancap5@ sources  ( ic  4329a , ngc  4593 , one season of mrk  279 , one season of ngc  3227 , 3c  120 , and pg  1613 ) out of all 66 h@xmath0 light curves following the discussion in ",
    "[ sec : hbeta ] .",
    "green circles , blue pentagons , dark violet squares , and red triangles correspond to sources of group a , b , c , and d , respectively .",
    "there is general agreement between the two methods , but also several discrepancies , as 7 of our h@xmath0 lag estimates are inconsistent with the ccf results given their error estimates .",
    "we marked these sources in figure  [ fig : hbetacomp2 ] and now discuss each case individually ,    [ [ ngc7469 .",
    "] ] ngc  7469 .",
    "+ + + + + + + + +    we estimate an h@xmath0 lag of 11.7@xmath252 days , as opposed to @xmath2534.7@xmath254 .",
    "however , if we use a dirac delta function for the transfer function instead of a tophat , the estimated time lag changes to 4.3 days , in agreement with the ccf result .",
    "thus , the discrepancy originates from the improvement of fit with a tophat smoothing kernel .",
    "the continuum of ngc  7469 was intensively monitored to search for time lags between the uv and optical continuum  @xcite , so its continuum light curve is densely sampled while the h@xmath0 light curve is much less so .",
    "the model has to smooth the continuum light curve heavily  ( i.e. , a broad tophat width ) to obtain a good fit , which at the same time shifts the time lag estimate to a longer value than it would be with a zero width  ( i.e. , a delta function ) .",
    "this is suggestive of the continuum errors being underestimated , or a more realistic transfer function is required .",
    "[ [ mrk79years-2-and-4 . ] ] mrk  79  ( years 2 and 4 ) .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    in both cases , we estimate larger time lags than the ccf results , although there are sub - peaks which correspond to the ccf lags . for year 2 ( jd4783848044 ) , while the ccf centroid gives a lag of 16.4@xmath255 days , the ccf peak estimate is 19@xmath256 days , more consistent with our estimate of 30.9@xmath257 days . for year 4 ( jd4999650220 ) , @xcite flagged it as `` unreliable '' for the poor light curve sampling .",
    "our method shows a dense array of sub - peaks in the lag likelihood distribution , but the most significant peak is at 43.6@xmath258 days .",
    "[ [ pg0844 . ] ] pg  0844 . + + + + + + + +    as discussed in ",
    "[ sec : corr ] , the ccf estimate of the h@xmath0 lag  ( 34.4@xmath259 ) for pg  0844 is likely susceptible to correlated errors , while our method estimates a lag of 12.2@xmath260 days regardless of the value of correlation coefficient @xmath139 .",
    "[ [ pg0052 . ] ] pg  0052 .",
    "+ + + + + + + +    we estimate an h@xmath0 lag of 149.3@xmath261 days , as opposed to @xmath253103@xmath262 .",
    "the single - line fit shows multiple peaks and usually one would be inclined to mistrust a peak at the seasonal alias  ( a rest - frame lag of 150 days corresponds to 170 days in the observed - frame ) .",
    "however , the joint h@xmath146/h@xmath0 fit clearly reinforced this solution .",
    "[ [ pg1307 . ] ] pg  1307 .",
    "+ + + + + + + +    we estimate an h@xmath0 lag of 188.8@xmath263 days , as opposed to @xmath264 121.9@xmath265 . the joint h@xmath146/h@xmath0 fit suppressed the false peak which corresponds to the @xmath130 lag , favoring a longer lag that is more consistent with lags of the other balmer lines .",
    "[ [ pg1426 . ] ] pg  1426 .",
    "+ + + + + + + +    we estimate an h@xmath0 lag of 161.6@xmath266 days , as opposed to @xmath264 103.2@xmath267 .",
    "similar to pg  0052 and pg  1307 , the joint h@xmath146/h@xmath0 fit reinforced a solution which is otherwise susceptible to the seasonal gap effect .",
    "we carried out a similar analysis for each data set , including all emission lines besides h@xmath0 , as summarized in table  [ tab : lags ] .",
    "note that in the table we only include 87 light curves for which we have successfully computed lags .",
    "the object is identified in column ( 1 ) .",
    "the emission line and its light curve heliocentric julian date range are listed in columns ( 2 ) and ( 3 ) , respectively .",
    "column ( 4 ) gives the rest - frame time lag estimate from the spear method , while column ( 5 ) indicates the associated `` ambiguity ''  ( i.e. , the group membership ) defined above .",
    "with the revised set of h@xmath0 lags , and the starlight - corrected optical luminosity of each agn from @xcite , we have calculated the fit to the @xmath25@xmath26 relationship for our sample @xmath268 and compared it to that based on ccf lags in figure  [ fig : rl ] .",
    "we obtained a slope @xmath269 for all the spear lags regardless of the level of `` ambiguity '' at which we probe the slope .",
    "this slope is slightly steeper than previous estimates , and only marginally consistent with the nave theoretical prediction of @xmath270 . compared to the ccf - based @xmath25@xmath26 fit of the same sample of agns  ( blue filled circles )",
    ", our @xmath25@xmath26 fit has a steeper slope but comparable rms scatter @xmath271 , which grows smaller as we use more reliable lags .",
    "table  [ tab : rl ] gives the results from the different fits using the 4 combinations of groups indicated by column ( 1 ) .",
    "column ( 2 ) gives the number of data points used in each fit .",
    "we fit each combinatorial data set using lag estimates from both the spear  ( columns 36 ) and ccf methods  ( columns 710 ) .",
    "two parameters in equation  ( [ eqn : rl ] ) are listed in columns ( 3 ) and ( 4 ) for spear method , and in column ( 7 ) and ( 8) for ccf method , respectively .",
    "column ( 5 ) and ( 6 ) give the @xmath122 and rms scatter for our fit , while column ( 9 ) and ( 10 ) give these statistics correspondingly for the ccf method .",
    "our @xmath25@xmath26 fits have a larger @xmath122 than the ccf ones .",
    "this does not necessarily mean they are poorer fits , because our lag estimates generally have tighter errorbars than the ccf estimates .",
    "it could indicate that our approach underestimates uncertainties , that the ccf method overestimates uncertainties , or that we are not taking into account intrinsic scatter in the @xmath272@xmath26 relationship . since most of the group c and d sources are high - redshift luminous pg objects , the rms scatter for our method decreases from 0.229 dex to 0.196 dex after dropping them from the fit .",
    "three outliers from the ccf @xmath25@xmath26 relation  ( ngc  7469 , years 1 and 4 of mrk  79 ) are also the sources where our lag estimates are inconsistent with ccf results .",
    "when we use our lag estimates , these three ccf outliers lie on the @xmath272@xmath26 relation , which reduces the rms scatter near @xmath273 ergs s@xmath274 .",
    "note that there is significant scatter in the @xmath25@xmath26 relation even for multiple estimates for a single source , as shown in the left panel of figure  [ fig : lrs ] for ngc  5548 .",
    "so far , we have carried out our calculations assuming that the parameters are constant during a season .",
    "this is likely true for the underlying variability process .",
    "if we model either the full continuum light curve or the individual seasons , we find estimates for the process parameters @xmath32 and @xmath33 that are statistically consistent .",
    "we do observe lags that vary from season to season , and these are arguably correlated with luminosity . if so , they should also be varying within seasons , and we have not accounted for this .",
    "similarly , we assume the scaling between the continuum and line fluxes does not vary over a season , although we do observe it to vary between seasons .",
    "the nearby seyfert 1 galaxy ngc  5548 , with its many continuous years of monitoring data , serves as an ideal example of an agn changing its variability levels from season to season .",
    "figure  [ fig : lrs ] illustrates the continuum flux dependence of both the h@xmath0 lag @xmath12 and the scaling coefficient @xmath110 for 14 seasons of ngc  5548 data .",
    "we clearly see trends that the lag increases with luminosity and the amplitude of the response diminishes .",
    "if we fit the lag , we find a steep slope , @xmath275 that is inconsistent with the expected @xmath276 .",
    "however , the poor fit ( @xmath277 ) suggests that either the uncertainties are underestimated or intrinsic scatter dominates the goodness - of - fit .",
    "if we rescale the uncertainties so that the best - fit model has @xmath278 , the flatter @xmath279 slope is not ruled out , with a @xmath280 of only @xmath281 .",
    "these problems can be addressed by making the lags and the line - to - continuum scaling a function of the continuum luminosity . for the luminosity dependence of lags",
    ", the simplest approach would be to de - lag the line light curve as @xmath282 instead of shifting the entire light curve by the same @xmath283 , and then optimize the fits over the additional parameter @xmath146 .",
    "unfortunately , we can not fit the full ngc  5548 light curve because the resulting matrix dimensions are impractically high ( @xmath54=3085 data points ) .",
    "we instead estimate the normalized likelihood distribution for @xmath146 in each season and then combined the likelihoods , as shown in figure  [ fig : breath ]  ( we did not include year 13 , which was part of the less reliable group b ) .",
    "this `` breathing '' effect is clearly detected , and the logarithmic slope estimate of @xmath284 is consistent with the nave expectation @xmath285 and the @xmath25@xmath26 relation in figure  [ fig : rl ] . using almost the same set of light curves from ngc  5548  ( we add year 14 and exclude year 13 ) , @xcite",
    "find a much shallower slope  ( @xmath286@xmath287 ) with a luminosity - dependent delay map , in better agreement with the prediction of photoionization models  ( @xmath288 ; @xcite ) .",
    "however , their small correction for the host galaxy starlight may artificially flatten their estimate of the slope  @xcite .",
    "note that for this experiment we did not make the line - to - continuum scaling coefficient @xmath110 a function of continuum luminosity in the fit .",
    "such a full scale calculation should be carried out using the complete data set .",
    "we have demonstrated that direct fitting of continuum and line light curves is a viable approach to measuring reverberation lags , confirming the initial study of @xcite .",
    "it provides a full statistical framework for determining time lags and estimating their uncertainties , including the full contributions from correlated noise , de - trending and interpolation .",
    "in essence , the lags are determined using a weighted average of all statistically acceptable models for interpolating the underlying _ true _ light curve .",
    "while we used the assumption that the underlying variable process had an exponential correlation function corresponding to a damped random walk , any other statistical process could be substituted .",
    "we note , however , that @xcite , @xcite and @xcite have found the exponential correlation function to be an excellent model of quasar light curves , just as we have found here , although we modeled the light curves in flux rather than magnitude .    because we are explicitly modeling the light curves",
    ", we must include an explicit model of the transfer function .",
    "here we used a top hat for simplicity .",
    "it includes the simple limits of a delta function and a uniform thin shell , and is likely a reasonable model for any single - peaked transfer function given the available data  ( see @xcite ) . as with the model for the variability process , using an alternative transfer function simply requires computing the appropriate terms of the covariance matrix . aside from the case of ngc  7469 where it seemed to affect the lag estimation , we did not discuss the tophat width .",
    "in general , there is a relatively strong degeneracy between @xmath289 , the width , and @xmath110 , the scaling between the continuum and line light curves .",
    "when @xmath289 is large and the continuum is heavily smoothed , the model will try to increase the variability amplitude by artificially boosting @xmath110 to re - align the continuum and line light curves .",
    "however , the degeneracy does not seem to lead to problems in estimating the mean lag unless the line light curve is very poorly sampled .",
    "the traditional ccf method does not implicitly assume a shape for the transfer function but calculates the lag as either the barycenter ( @xmath290 ) or the peak ( @xmath291 ) of underlying transfer function ( convolved with data ) .",
    "the difference between the two sometimes can be large and hard to reconcile unless the transfer function can be modeled explicitly . for future high - fidelity datasets , our approach should also have no difficulty constraining the shape of transfer functions .",
    "the most important future path for this method is to simultaneously fit multiple line components , whether different lines ( e.g. , h@xmath0 , h@xmath146 , etc . ) , velocity sub - components of individual lines or multiple continuum bands .",
    "as long as the overall _ ansatz _ that all light curves are scaled and smoothed versions of the continuum holds , combining many light curves with differing lags means that the lag estimate for any given light curve is now derived from a better sampled estimate of the continuum variability .",
    "a second advantage , particularly for attempts to study the velocity structure of a particular broad line , is that such joint analyses will correctly infer the covariances between the individual lags .",
    "current velocity - dependent lags have uncertainties comparable to their differences  ( @xcite ) , but it may be true that these differences actually have a strong covariances , so that the differences are far more significant than estimates from analyzing the light curves in isolation .",
    "the method can also allow for luminosity - dependent lags or line - continuum scaling factors . also note that while we only use the linear parameters of the model to remove the light curve means , it is a very flexible tool for de - trending or cross - calibrating light curves whose model uncertainties will be fully included in lag estimate .",
    "the most important observational implication of this approach is the value of measuring multiple lines , especially those with high ionization potentials . in our approach ,",
    "multiple lines with differing lags allow one to overcome many of the sampling problems inherent to cross - correlation methodologies . at its simplest",
    ", one light curve can be aliased into a ( seasonal ) sampling gap , but two can not be unless the transfer functions are similar  ( i.e. , the lines have similar lags ) .",
    "given the radial ionization stratification of the blr  @xcite , the lag difference between two lines is proportional to the difference in their ionization levels . in this paper , however , the lines we used for two - line fits are mostly pairs of two balmer lines , which have similarly low ionization levels .",
    "thus , the observational goal should be to obtain data for multiple lines with a broad range of ionization potentials . indeed , with a wide variety of emission - line lines , it is in principle possible to combine the reverberation results with photoionization equilibrium modeling to highly constrain the geometry and physics of the blr @xcite .",
    "the only significant algorithmic challenge comes from the @xmath103 scaling of the computational cost with the number of data points @xmath54 .",
    "unfortunately , the reverberation mapping problem is very different from simply using the damped random walk to model the continuum light curves , where we can take advantage of the particular structure of the covariance matrix to calculate the necessary matrix inversions in @xmath102 operations .",
    "since the expensive matrix inversion is required for each likelihood calculation , it becomes difficult to analyze large data sets , particularly if the number of parameters also increases greatly as in a full simultaneous model of lags as a function of line velocity .",
    "these problems can be addressed using hyper  threaded or parallel versions of the underlying algorithm .",
    "we thank kelly d. denney and catherine j. grier for kindly providing some of the light curves .",
    "thanks also to misty c. bentz for her starlight corrected agn luminosities .",
    "csk is supported by nsf grant ast-0708082 and ast-1009756 .",
    "bmp is supported by nsf grant ast-1008882 and yz is supported by an osu distinguished university fellowship .",
    "the expressions for the covariance matrices used in this paper and the accompanying code assume that the transfer function is a simple top hat , @xmath292 for this transfer function , we can analytically calculate the correlation functions in equation  ( [ eqn : lc ] ) , ( [ eqn : lauto ] ) and ( [ eqn : lcross ] ) , respectively .",
    "consider the case when the first line @xmath293 has transfer function @xmath297 as defined in equation  ( [ app : tf ] ) and the other line @xmath298 has transfer function @xmath299 @xmath300 where @xmath301 .",
    "the covariance between line @xmath293 at time @xmath28 and line @xmath298 at time @xmath29 ( equation  [ eqn : lcross ] ) is @xmath302 where @xmath303    by definition , the covariance for the autocorrelation of line @xmath293 between time @xmath28 and @xmath29 ( equation  [ eqn : lauto ] ) can be obtained by equating @xmath299 with @xmath297 so that @xmath304 , @xmath305 and @xmath306 .                                                                                                                                              , g.  b. , & kleyna , j.  t. 1994 , in asp conf .",
    "69 , reverberation mapping of the broad - line region in active galactic nuclei , ed .",
    "m.  gondhalekar , k.  horne , & b.  m.  peterson ( san francisco : asp ) , p.  85"
  ],
  "abstract_text": [
    "<S> motivated by recent progress in the statistical modeling of quasar variability , we develop a new approach to measuring emission - line reverberation lags to estimate the size of broad - line regions  ( blrs ) in active galactic nuclei . assuming that all emission - line light curves are scaled , smoothed , and displaced versions of the continuum , this alternative approach fits the light curves directly using a damped random walk model and aligns them to recover the time lag and its statistical confidence limits . </S>",
    "<S> we introduce the mathematical formalism of this approach and demonstrate its ability to cope with some of the problems for traditional methods , such as irregular sampling , correlated errors , and seasonal gaps . </S>",
    "<S> we redetermine the lags for 87 emission lines in 31 quasars and reassess the blr size  luminosity relationship using 60 h@xmath0 lags . </S>",
    "<S> we confirm the general results from the traditional cross - correlation methods , with a few exceptions . </S>",
    "<S> our method , however , also supports a broad range of extensions . </S>",
    "<S> in particular , it can simultaneously fit multiple lines and continuum light curves which improves the lag estimate for the lines and provides estimates of the error correlations between them . determining these correlations </S>",
    "<S> is of particular importance for interpreting emission - line velocity  delay maps . </S>",
    "<S> we can also include parameters for luminosity - dependent lags or line responses . </S>",
    "<S> we use this to detect the scaling of the blr size with continuum luminosity in ngc  5548 . </S>"
  ]
}