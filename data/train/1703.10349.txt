{
  "article_text": [
    "the emergence of the web of data , particularly supported through w3c standards such as rdf and the linked data principles  @xcite , has led to a wide range of semi - structured rdf data being available on the web .",
    "data is spread across datasets , complemented through a growing amount of entities as part of structured annotations of web documents , using rdfa or microformats .",
    "recent studies have shown that approximately 26% of pages already contain structured annotations  @xcite .",
    "web data forms a highly heterogeneous knowledge - graph spanning an estimated 100 billion triples  @xcite , with a wide variety of languages , schemas , domains and topics  @xcite . even though a large number of entities and concepts are highly overlapping , that is they represent the same or related concepts , explicit links are still limited and often concentrated within large established knowledge graphs , like dbpedia  @xcite .",
    "the entity - centric nature of the web of data has led to a shift towards tasks related to entity and object retrieval  @xcite or entity - driven text summarization  @xcite .",
    "major search engine providers such as google and yahoo ! already exploit such data to facilitate semantic search using knowledge graphs , or as part of similar efforts such as the _ entitycube - renlifang _ project at microsoft research  @xcite . in such scenarios ,",
    "data is aggregated from a range of sources calling for efficient means to search and retrieve entities in large data graphs",
    ". specifically , _ entity retrieval _ ( also known as ad - hoc object retrieval )  @xcite aims at retrieving relevant entities given a user query .",
    "the result is a ranked list of entities  @xcite . by simply applying standard keyword search algorithms , like the bm25f",
    ", promising results can be achieved .",
    "a common practice is to construct indexes over the textual descriptions ( _ literals _ ) of entities .    in most cases ,",
    "queries are entity centric . however , there are a large number of queries that are also topic - based , e.g. `` u.s . presidents ` ' .",
    "therefore , approaches like  @xcite have proposed retrieval techniques that make use of the explicit links between entities in the wod for results or query expansion .",
    "for instance , following ` owl : sameas ` or ` rdfs : seealso ` predicates from ` dbp : barack_obama ` , one can retrieve co - references or highly related entities . however , considering the size of the wod such statements are very sparse ( see figure  [ fig : related_types ] ) .    in this work ,",
    "we propose a method for improving entity retrieval results in two aspects .",
    "we improve the task by _ expanding _ and _ re - ranking _ the result set from a baseline retrieval model ( bm25f ) .",
    "sparsity of explicit links is addressed through clustering of entities based on their similarity , using a combination of lexical and structural features .",
    "consequently , we expand the result set with additional entities from the _ cluster space _ ( clusters with which the baseline entities are associated ) , retrieved from the baseline .    for the expanded result set , there is a need for re - ranking .",
    "the re - ranking considers the similarity of entities to the user query , and their relevance likelihood based on the corresponding entity type , defined as _ query type affinity_. we empirically model the query type affinity between the entity type in a query ( e.g. _ ` barack obama ' _ ` isa person ` ) and the entity types in the result set ( see section [ subsec : motivation_approach ] ) .    in terms of _ scalability _ and _ efficiency _ , the clustering process is carried out offline , where we _ bucket _ entities of particular types together before clustering .",
    "this improves the efficiency by reducing the run - time of the clustering algorithms ( section  [ subsec : bucketing_clustering ] and [ subsec : discussion ] ) .",
    "the entity retrieval , expansion and re - ranking on the other hand are performed online and the computational overhead is negligible ( section  [ sec : retrieval ] and [ subsec : discussion ] ) .    our experimental evaluation is carried out on the btc12 dataset  @xcite , and using the semsearch query dataset .",
    "the individual steps in our approach are evaluated through a reliable crowdsourced evaluation approach .",
    "the results show that the proposed approach outperforms existing basslines for the entity retrieval task .",
    "the main contributions of our work are as follows : ( a ) an entity retrieval model combining keyword search and entity clustering , and ( b ) an entity ranking model considering the query type affinity w.r.t the set of relevant entity types .",
    "a large portion of queries issued in web search engines target entities or contain semantic resources ( such as types , relations and attributes ) @xcite as a primary intent .",
    "consequently , the identification of entity - centric queries has become of particular concern for commercial search engines serving as a means to narrow the search space and to provide contextual query results @xcite .",
    "thus , the traditional task of ad - hoc document retrieval ( adr ) @xcite is moving towards an entity retrieval task @xcite . hence , instead of top@xmath0 document retrieval that match a keyword query , the task and therefore the results are increasingly becoming entity - centric .    following this direction , tonon et al .",
    "@xcite proposed a hybrid approach based on query expansion and relevance feedback techniques on top of the bm25 ranking function to build an entity retrieval framework .",
    "in contrast to this work , we use the state - of - the - art bm25f @xcite to assign varying degrees of importance to different parts of a document .",
    "further , through an offline pre - processing step we are able to infer links between similar entities for the retrieval process .",
    "this is particularly important when considering datasets that have less links between entities , a significant feature of the work by tonon et al @xcite .",
    "another advantage of adopting bm25f is penalising documents / entities , consisting of long textual literals , in the final ranking @xcite .",
    "sindice  @xcite is another approach focusing on indexing rdf documents .",
    "it supports data discovery and integration by taking advantage of dbpedia entities as a source to actively index resources .",
    "the process performed by sindice plays a key role in centralising disparate data sources on the web .",
    "the adoption of entities and foremost entity types ( topics ) is also supported by @xcite in the recommendation of entities in web search .",
    "our approach can benefit sindice by indexing documents following a topic - based fashion .",
    "zhiltsov and agichtein  @xcite propose a learning to rank approach , where they model the relations between entities through a various set of features , such as language models and other query related features ( e.g query length ) .",
    "finally , through tensor matrix factorisation they find latent similarities between entities , later used in their learning to rank model .",
    "one major disadvantage of this approach is that it is supervised , hence , unlikely to perform reasonably well on ad - hoc entity search tasks .",
    "in this section , we motivate and define our work in the context of the addressed challenge , and provide an overview of our approach .      the _ entity retrieval ( er ) task _ , also known as ad - hoc object retrieval , is concerned with retrieving a top@xmath0 ranked set of entities from dataset for a given a user query @xmath1 .",
    "user queries are typically entity centric .",
    "dataset _ in our case is a set of triples @xmath2 , where @xmath3 is the _ subject _ ( the uri of an entity ) , @xmath4 is the _ predicate _ , and @xmath5 is the _ object _ ( a uri or a literal ) . an",
    "_ entity _ profile of @xmath6 is the set of triples sharing the same subject uri @xmath3 .",
    "the _ type _ of an entity is determined by the object of the triple @xmath7 ` rdf : type`@xmath8 . additionally , we define the _ query type _ @xmath9 , corresponding to the entity type in @xmath1 , e.g. _ ` barack obama ' _ , hence @xmath10 ` hastype person ` .",
    "recent studies @xcite have shown that _",
    "explicit similarity statements _ , which indicate some form of similarity or equivalence between entities , for instance through predicates such as @xmath11 , are useful for improving entity retrieval results as retrieved through approaches like bm25f , i.e. improving significantly on standard precision / recall metrics .",
    "however , such explicit similarity statements usually are sparse and often focused towards a few well established datasets like dbpedia , freebase etc .",
    "one main reason is that these datasets represent known , and well structured graphs , which show a comparably high proportion of such dedicated similarity statements , in turn linking similar entities within and beyond their original namespace .    in figure",
    "[ fig : related_types ] we show the total amount of explicit similarity statements ( on the x  axis ) that interlink entities in the btc12 dataset . referring to @xcite , here we specifically consider triples of the form @xmath12 where the predicate @xmath13`owl : sameas ` , ` skos : related ` , ` dbp : wikipageexternallink ` , ` dbp : wikipagedisambiguates ` , ` dbp : synonym`@xmath14 .",
    "these are plotted against the total number of _ object properties _ ( y  axis ) , where each point in the plot represents a graph in the btc12 collection .",
    "from the figure , it is obvious that the number of explicit similarity statements is very sparse , considering the size of the dataset .            nonetheless , missing links between entities can be partially remedied by computing their pair - wise similarity , thereby complementing statements like ` owl : sameas ` or ` skos : related ` .",
    "given the semi - structured nature of rdf data , graph - based and lexical features can be exploited for similarity computation . particularly , lexical features derived from literals provided by predicates such as _ rdfs : label _ or _ rdfs : description _ are prevalent in lod .",
    "our analysis on the btc12 dataset reveals that a large portion of entities ( around 90% ) have an average literal length of 50 characters .    furthermore , while the query type usually is not considered in state of the art er methods , we investigated its correlation with the corresponding entity types from the query result set .",
    "we refer to a ground truth using the btc10 dataset .",
    "we focus only on relevant entities for @xmath1 .",
    "we analyze the _ query type affinity _ of the result sets by assessing the likelihood of an entity in the results to be of the same type as the query type .",
    "figure  [ fig : query_affinity ] shows the query type affinity . on the x - axis",
    "we show the query type , whereas on the y - axis the corresponding relevant entity types are shown .",
    "figure  [ fig : query_affinity ] shows that most queries have high affinity with a specific entity type , with the difference being the query type ` person ` , where relevant entities have a wider range of types .",
    "our work exploits such _ query type affinity _ to improve the ranking of entities for a query @xmath1 ( see section  [ sec : retrieval ] ) . based on these observations",
    ", we argue that ( a ) _ entity clustering _ can remedy the lack of existing linking statements and ( b ) entity _ re - ranking _ considering the _ query type affinity _ are likely to improve the entity retrieval task .      in this work",
    "we propose a novel approach for the _ entity retrieval _ task which builds on the observations described earlier .",
    "figure  [ fig : workflow ] shows an overview of the proposed approach .",
    "the individual steps are outlined below and described in detail in section  [ sec : preprocessing ] and [ sec : retrieval ] .",
    "we distinguish between two main steps : ( i ) _ offline pre - processing _ , including step i.a and i.b in the following overview , and ( ii ) _ online entity retrieval _ , covered by steps ii.a to ii.c .",
    "* i.a entity feature vectors :",
    "* we construct the entity feature vector as follows : @xmath15 , where @xmath16 and @xmath17 represent the _ unigrams _ and _ bigrams _ extracted from literals of @xmath6 , and @xmath18 represents the structural features .",
    "* i.b entity bucketing & clustering : * is used to compute implicit relationships between entities emerging from their feature vectors . for the sake of efficiency ,",
    "before we proceed with entity clustering , we exploit the locality - sensitive hashing ( lsh ) algorithm for bucketing .",
    "* ii.a query analysis : * as part of the retrieval task , we initially analyse the given user queries @xmath1 . from the query terms , which typically represent named entities , we determine the type of the named entity , e.g. `` location ` ' in order to support the query type affinity - based reranking at a later stage .",
    "* ii.b entity retrieval : * in the retrieval process , we rely on a combination of standard ir approaches , like bm25f and further expand the result set with entities showing a high similarity according to the computed clusters .",
    "* ii.c entity ranking .",
    "* in the final step , we rank the expanded entity result set for @xmath1 , taking into account similarity to the query and the modelled query type affinity .",
    "in this section , we describe the offline pre - processing to cluster entities and remedy the sparsity of explicit entity links .      entity similarity is measured based on a set of structural and lexical features , denoted by the _ entity feature vector _ @xmath19 .",
    "the features for clustering are described below .    *",
    "lexical features : * we consider a weighted set of _ unigrams _ and _ bigrams _ for an entity @xmath6 , by extracting all textual literals used to describe @xmath6 denoted as @xmath16 and @xmath17 .",
    "the weights are computed using the standard _",
    "lexical features represent core features when considering the entity retrieval task , more so for the clustering process .",
    "a high lexical similarity between an entity pair is a good indicator for expanding the result set from the corresponding cluster space .",
    "* structural features : * the feature set @xmath20 considers the set of all object properties that describe @xmath6 .",
    "the range of values for the structural features is @xmath21 $ ] , i.e. , to indicate if a object value is present in @xmath6 . *",
    "feature space : * to reduce the feature space , we filter out items from the lexical and structural features that occur with low frequency across entities and presumably , have a very low impact on the clustering process due to their scanty occurrence .      *",
    "entity bucketing . * in this step we _ bucket _ entities of a given _ entity type _ by computing their _ minhash _ signature , which is used thereafter by the lsh algorithm  @xcite .",
    "this step is necessary as the number of entities is very large . in this way",
    "we reduce the number of pair - wise comparisons for the entity clustering , and limit it to only the set of entities within a bucket . depending on the _ clustering algorithm _ ,",
    "the impact of bucketing on the clustering scalability varies . since the lsh algorithm itself has linear complexity , bucketing entities presents a scalable approach considering the size of datasets in our experimental evaluation .",
    "a detailed analysis is presented in section  [ sec : evaluation ] .",
    "* entity clustering . * based on the computed feature vectors , we perform entity clustering for the individual entity types and the computed lsh buckets . taking into account scalability aspects of such a clustering process we consider mainly two clustering approaches : ( i ) _ x  means _ and ( ii ) _ spectral clustering_. in both approaches we use euclidean distance as the similarity metric .",
    "the dimensions of the euclidean distance are the feature items in @xmath22 .",
    "the similarity metric is formally defined in equation  [ eq : entity_sim ] .",
    "@xmath23 where the sum aggregates over the union of feature items from @xmath24 .",
    "the outcome of this process is a set of clusters @xmath25 .",
    "the clustering process represents a core part of our approach from which we expand the entity results set for a given query , beyond the entities that are retrieved by a baseline as a starting point . the way the clusters are computed has an impact on the entity retrieval task ,",
    "thus we present a thorough evaluation of cluster configurations in section  [ subsec : clustering_eval ] .",
    "* x  means * to cluster entities bucketed together through the lsh algorithm and of specific entity types , we adopt an extended version of _ k - means _",
    "clustering , presented by pelleg et al . which estimates the number of clusters efficiently @xcite .",
    "_ x  means _ overcomes two major drawbacks of the standard _ k - means _ clustering algorithm ; ( i ) computational scalability , and ( ii ) the requirement to provide the number of clusters _ k _ beforehand .",
    "it extends the _ k  means _",
    "algorithm , such that a user only specifies a range [ @xmath26 , @xmath27 in which the number of clusters , _ k _ , may reasonably lie in .",
    "the bounds for @xmath28 in our case are set to @xmath29 $ ] clusters .    * spectral clustering * in order to proceed with the _ spectral clustering _",
    "process , we first construct the adjacency matrix @xmath30 .",
    "the adjacency matrix corresponds to the similarity between entity pairs @xmath31 of a given entity type and bucket .",
    "next , from @xmath30 we compute the unnormalised graph laplacian  @xcite as defined in equation  [ eq : graph_laplacian ] : @xmath32 where , @xmath33 corresponds to the diagonal matrix , i.e. , @xmath34 for @xmath35 .",
    "from matrix @xmath36 we are particularly interested in specific properties , which we use for _ clustering _ and which are extracted from the _ eigenvectors _ and _ eigenvalues _ by performing a singular value decomposition on @xmath36 .",
    "the eigenvectors correspond to a square matrix @xmath37 , where each row represents the projected entity into a @xmath38-dimensional space .",
    "eigenvectors are later used to cluster entities using standard _",
    "k  means _ algorithm .    however , an important aspect that has impact on the clustering accuracy , is the number of dimensions considered for the _ k  means _ and the @xmath0 itself .",
    "we adopt a heuristic proposed in  @xcite .",
    "the number of dimensions that are used in the clustering step corresponds to the first spike in the eigenvalue distribution .",
    "in addition , this heuristic is also used to determine the number @xmath0 for the clustering step .",
    "in this section , we describe the online process of entity retrieval , including the process of _ expansion _ and _ re - ranking _ of the query result set .      having obtained an initial result set @xmath39 through a state of the art er method ( bm25f ) , the next step deals with expanding the result set for a given user query . from entities in @xmath40 ,",
    "we extract their corresponding set of clusters @xmath41 as computed in the pre - processing stage .",
    "the result set is expanded with entities belonging to the clusters in @xmath41 .",
    "we denote the entities extracted from the clusters with @xmath42 .",
    "there are several precautions that need to be taken into account in this step .",
    "we define two threshold parameters for expanding the result set .",
    "the first parameter , _ cluster size _ , defines a threshold with respect to the number of entities belonging to a cluster .",
    "if the number is above a specific threshold , we do not take into account entities from that cluster .",
    "the underlying rationale is that clusters with a large number of entities tend to be generic and less homogeneous , i.e. they tend to be a weak indicator of similarity .",
    "the second parameter deals with the _ number of entities _ with which we expand the result set for a given entity cluster .",
    "the entities are considered based on their distance to the entity @xmath43 .",
    "we experimentally validate the two parameters in section  [ sec : evaluation ] .",
    "the _ fit _ of expanded entities @xmath44 concerns their similarity to query @xmath1 and the similarity to @xmath43 , which serves as the starting point for the expansion of @xmath45 .",
    "we measure the _ query - biased _ entity similarity in equation  [ eq : linkscore ] , where the first component of the equation measures the _ string _ distance of @xmath45 to @xmath1 , that is @xmath46 .",
    "furthermore , this is done relative to entity @xmath43 , such that if the @xmath43 is more similar to @xmath1 , @xmath47 the similarity score will be increased , hence , the expanded entity @xmath45 will be penalized later on in the ranking ( note that we measure distance , therefore , the lower the @xmath48 score the more similar an entity is to @xmath1 ) .",
    "the second component represents the actual distance score @xmath49 .",
    "@xmath50 we set the parameter @xmath51 , such that entities are scored equally with respect to their match to query @xmath1 and the distance between entities , based on our baseline approach .",
    "the main outcome of this step is to identify possibly relevant entities that have been missed by the scoring function of bm25f .",
    "such entities could be suggested as relevant from the extensive clustering approaches that consider the structural and lexical similarity .      following the motivation example in figure  [ fig : query_affinity ] , an important factor on the re - ranking of the result set is the _ query type affinity_. it models the relevance likelihood of a given entity type @xmath52 for a specific query type @xmath9 .",
    "we give priority to entities that are most likely to be relevant to the the given query type @xmath9 and are least likely to be relevant for other query types @xmath53 .",
    "the probability distribution is modeled empirically based on a previous dataset , btc10 .",
    "the score @xmath54 , we assign to any entity coming from the expanded result set is computed as in equation  [ eq : type_affinity ] .",
    "@xmath55    an additional factor we use in the re - ranking process is the _ context score_. to better understand the query intent , we decompose a query _ q _ into its _ named entities _ and additional _",
    "contextual terms_. an example is the query @xmath56 from our query set , in which case the contextual terms would be ` _ _ movie _ _ ' and the named entity ` _ _ harry potter _ _ ' respectively . in case of ambiguous queries , the contextual terms can further help to determine the query intent .",
    "the _ context score _ ( see equation  [ eq : context ] ) indicates the relevance of entity @xmath6 to the contextual terms @xmath57 of the query @xmath1 . for entities with a high number of textual literals , we focus on the main literals like _ labels , name _ etc . @xmath58      the final step in our entity retrieval approach , re - ranks the expanded entity result set for a query @xmath1 .",
    "the result set is the union of entities @xmath59 . in the case of entities retrieved through the baseline approach @xmath60",
    ", we simply re - use the original score , but normalize the values between @xmath61 $ ] . for entities from @xmath42",
    "we normalize the similarity score relative to the rank of entity @xmath43 ( the position of @xmath43 in the result set ) which was used to suggest @xmath45 .",
    "this boosts entities which are the result of expanding top - ranked entities . @xmath62    the final ranking score @xmath63 , for entity @xmath6 and query type @xmath9 assigns higher rank score in case the entity has high similarity with @xmath1 and its type has high relevance likelihood of being relevant for query type @xmath9 .",
    "finally , depending on the query set , in case @xmath1 contains contextual terms we can add @xmath64 by controlling the weight of @xmath65 ( in this case @xmath51 ) .",
    "@xmath66 the score @xmath67 is computed for all entities in @xmath68 . in this way based on observations of similar cases in previous datasets , like the btc10 we are able to rank higher entities of certain types for specific queries .",
    "here we describe our experimental setup , specifically the datasets , baselines and the ground truth .",
    "the setup and evaluation data are available for download .      * dataset . * in our experimental setup we use the btc12 dataset  @xcite .",
    "it represents one of the largest periodic crawls of linked data , also containing well - known knowledge bases like freebase and dbpedia .",
    "the overall statistics of the data are : ( i ) 1.4 billion triples , ( ii ) 107,967 graphs , ( iii ) 3,321 entity types , and ( iv ) 454 million entities",
    ".    * entity clusters . * the statistics for the generated clusters are as follows : the average number of entities fed into the _ lsh _ bucketing algorithm is 77,485 , whereas the average number of entities fed into _ x  means _ and _ spectral _ is 400 .",
    "the number of generated entity buckets by lsh is 20,2009 , while the number of clusters for _ x  means _ and _ spectral _ is 13 and 38 , with an average of 10 and 20 entities per cluster respectively .",
    "* query dataset .",
    "* to evaluate our retrieval approach we use the _ _ semsearch _ _ query set from 2010 with 92 queries .",
    "the semsearch query set is a standard collection for evaluating entity retrieval tasks .      *",
    "baseline . *",
    "we distinguish between two cases for the original bm25f baseline : ( i ) @xmath69 and ( ii ) @xmath70 . in the first case",
    ", we use the _ title _ or _ label _ of an entity as a query field , whereas in the second case we use the full _ body _ of an entity ( consisting of all textual literals ) .",
    "the scoring of the fields is performed similar as in @xcite .",
    "* state of the art .",
    "* we consider the approach proposed in  @xcite as the state - of - the - art .",
    "similar to their experimental setup , we analyze two cases : ( i ) @xmath71 and ( ii ) @xmath72 . @xmath71 expands the entity set from the baseline approach with directly connected entities , and @xmath72 expands with entities up to the second hop . for further details we refer the reader to @xcite . in our experiments",
    ", we found that the @xmath72 did not result in any significant change in performance when compared to @xmath71 , and we therefore do not report further on @xmath72 .    * our approaches .",
    "* we analyze two entity retrieval techniques from our approach .",
    "the first is based on the _ x  means _ clustering approach , which we denote by @xmath73 .",
    "the second technique is based on _ spectral _ clustering and is denoted by @xmath74 . in both cases , we only expand the result set with entities coming from clusters with a total of ten entities associated with a cluster ( see section  [ subsec : entity_similarity ] ) , and finally add only the most relevant entity based on the @xmath75 score .",
    "* btc indexes . * for the baseline , we generate a lucene index , where we index entity profiles on two fields ` title ` and ` body ` ( consisting of all the textual literals of an entity ) .",
    "the second index is an rdf index over the btc dataset with support for sparql queries , for which we use the rdf3x tool  @xcite .",
    "the first index is used for the baseline approach , while the second for the state of the art approach .      for each query in the _",
    "semsearch2010 _ query set , we first establish the ground truth through crowdsourcing .",
    "crowdsourced evaluation campaigns for the task of ad - hoc object retrieval have been shown to be reliable @xcite .",
    "for each of the 92 queries , we pool the top 50 entities retrieved by the various methods , resulting in the top - k pooled entities corresponding to the query . by doing",
    "so we generate 4,600 query - entity pairs .",
    "we deploy atomic tasks in order to acquire relevance labels from the crowd for each query - entity pair .",
    "we follow the key prescriptions for task design and deployment that emerged from the work of blanco et al .",
    "@xcite to build a ground truth .",
    "workers are asked to assess the relevance of each retrieved entity to the corresponding query on a 5-point likert - type scale .",
    "we collect 5 judgements from different workers for each pair to ensure reliable relevance assessments and discernible agreement between workers .",
    "this results in a total of 23,000 judgements .",
    "the final relevance of an entity is considered to be the aggregated relevance score over the 5 judgements .",
    "we assess and compare the performance of the different methods by relying on the ground truth thus generated ( see section 7 ) .",
    "evaluation metrics assess the clustering accuracy and the retrieval performance",
    ".    * cluster accuracy .",
    "* as an initial evaluation , we assess the quality of our clusters . from a set of entities belonging to the same cluster",
    ", the accuracy is measured as the ratio of entities that _ belong together _ over the total number of entities in a cluster , where assessments are obtained through crowdsourcing ( see section [ sec : evaluation ] ) .",
    "* precision . * p@k measures the precision at rank @xmath0 , in our case @xmath76 .",
    "it is measured as the ratio of retrieved and relevant entities up to rank @xmath0 over the total number of entities retrieved up to rank @xmath0",
    ".    * recall .",
    "* r@k is measured as the ratio of retrieved and relevant entities up to rank @xmath0 over the total number of relevant entities up to rank @xmath0 .",
    "the total number of relevant entities for a query is determined by the relevance judgements on a large pool of entities .",
    "* mean average precision*. map provides an overall precision of a retrieval approach across all considered ranks .",
    "* normalized discounted cumulative gain*. it takes into account the ranking of entities generated using one of the retrieval approaches and compares it against the ideal ranking in the _ ground truth_. @xmath77 where @xmath78 represents the discounted cumulative gain at rank @xmath0 , and @xmath79 is the ideal @xmath78 computed from the _ ground truth_.",
    "in this section we report evaluation results of the two main steps in our approach .",
    "we first evaluate the quality of the pre - processing step , i.e. , the clustering results for the _ x  means _ and _ spectral _ clustering algorithms .",
    "next , we present the findings from our rigorous evaluation of the entity retrieval task .      considering the large number of clusters that are produced in the pre - processing step for a given _ type _ and _ bucket _ , evaluating the accuracy and quality of all clusters is infeasible .",
    "we randomly select 10 entity types and 10 buckets , resulting in 100 clusters for evaluation , where for each cluster we randomly select a maximum of 10 entities .    to evaluate the _ cluster accuracy _ , we deploy atomic microtasks modeled such that a worker is presented with sets of 10 entities belonging to a cluster , along with a description of the entity in the form of the entity profile .",
    "the task of the worker is to pick the odd entities out ( if any ) .",
    "we gather 5 judgments from different workers for each cluster . by enforcing restrictions available on the crowdflower platform , and following state of the art task design recommendations ,",
    "we ensure that we receive judgments from the best workers ( workers with high reputation as indicated by crowdflower ) .",
    "figure  [ fig : cluster_accuracy_percentage ] presents our findings for the evaluation of the clustering process .",
    "we note that for _ x  means _ and _ spectral _ clustering approaches , nearly 35% and 38% of the clusters are judged to be perfect respectively ( i.e. , the entities within the cluster were all found to belong together ) .",
    "39% of the clusters corresponding to _ spectral _ clustering and 40% of the clusters corresponding to _ x - means _",
    ", have an accuracy of 80% .",
    "considering its multidimensional representation of the entities , _ spectral _ clustering has higher accuracy and it does not have clusters below 70% accuracy . the lowest accuracy of 70% for _ spectral _ clustering implies that in each cluster there were only 3 entities that did not belong to the cluster . the implications of an accurate clustering process become clearer in the next section , where we assess the accuracy of finding relevant entities in the generated entity clusters .",
    "figure [ fig : cluster_agreement ] presents the pairwise agreement between workers on the quality of each cluster . in case of the _ spectral _ clustering",
    ", we observe a high inter - worker agreement of 0.75 as per krippendorf s alpha .",
    "we observe a moderate inter - worker agreement of 0.6 as per krippendorf s alpha on the clusters resulting from _ x ",
    "means_.      figure [ fig : precision_k ] presents a detailed comparison between the @xmath80 for the different methods .",
    "the proposed approaches outperform the baseline and state of the art at all ranks .",
    "the precision is highest at @xmath81 whereas for the later ranks it stabilizes at 0.4 .",
    "in contrast to our approach , the performance of the baseline and the state of the art is more uniform , and is around @xmath82 .",
    "the best overall performing approach is the retrieval approach based on spectral clustering @xmath83 .",
    "table  [ tbl : overal_results ] shows the details about the performance of the respective approaches as measured for our evaluation metrics .",
    "an interesting observation is that for our approaches the best performance is achieved when querying for the field _",
    "title_. in the case of the baseline , the best performance is achieved when querying for the field _ body _ ( @xmath84 ) while the same is inconclusive in case of the state - of - the - art methods ( * @xmath85 * and * @xmath86 * ) .",
    "we achieve a significantly higher retrieval performance when using the title field .",
    "this can be explained by the fact that entities that match a query on their _ title _ field when compared to those that match a query on their _ body _ field , have a higher likelihood of being an exact match .",
    "the high gain in performance through our methods ( _ sp _ and _ xm _ ) stems mainly from the two steps in our approach .",
    "the first step expands the result set with relevant entities as shown in figure  [ fig : relevance_histogram ] .",
    "the figure shows the number of relevant entities corresponding to the different grading scales as described in section [ subsec : clustering_eval ] . in all cases we note that our methods find more relevant entities",
    "the second step which re - ranks the expanded result set helps in reducing the number of _ `",
    "non - relevant ' _ entities .",
    "we find that @xmath85 has a 14% decrease of non - relevant entities , whereas @xmath87 and @xmath88 depict a 35% decrease , respectively . in second case where we query the _ body _ field , the number of _ ` non - relevant ' _ entities for @xmath86 decreases by about 13% , while @xmath89 and @xmath90 depict a 24% decrease .    .",
    "[ cols=\"<,<,<,<,<,<,<,<,<\",options=\"header \" , ]     we additionally analyze the performance of the entity retrieval approaches through the @xmath91 metric .",
    "figure  [ fig : ndcg ] shows the ndcg scores . similar to our findings for @xmath80 presented in table 1 , our approaches perform best for the query field _ title _ and significantly outperform the approaches under comparison .",
    "next , we present observations concerning the different _ query types _ and the entity result set expansion ( see section  [ subsec : entity_similarity ] ) parameters . in figure",
    "[ fig : query_improvement ] we show the improvement we gain in terms of map for the different _ query types_. we observe that there is quite a variance for the different query types , however , in nearly all cases , the biggest improvement is achieved through the @xmath83 approach .",
    "interestingly for the query type _ ` creative work ' _ the state of the art is nearly as good as the @xmath92 approach , whereas in the case of _",
    "` weapon ' _ the baseline performs best .",
    "one possible explanation for this is that in the case of _ ` creative work ' _ the explicit entity similarity statements are abundant .        addressing the case of optimizing our retrieval approaches , @xmath83 and @xmath92 , we experimentally show the impact that the expansion of the result set has on the measured performance metrics . here",
    ", we show the impact on the _ average ndcg _ score .",
    "figure  [ fig : result_expansion ] shows the performance at average ndcg for the varying _",
    "cluster size _ and _ number of entities _ added ( result set expansion ) for every entity in @xmath40 . the best performance is achieved for a rather smaller _ cluster size _ ranging between 5 and 10 entities per cluster . regarding the number of entities with which the result set is expanded for every @xmath43 , the best performance is achieved by expanding with one entity per cluster .",
    "the increase in cluster size and number of entities attributes to a decrease in performance .         and",
    "@xmath92.,scaledwidth=70.0% ]      * scalability . * in the pre - processing stage we introduced the clustering approaches , which first bucket entities together based on the lsh algorithm .",
    "this particular step significantly improves the _ scalability _ of such an offline step . if considering the _ x - means _",
    "algorithm , under the simplistic assumption that it represents the original _ k  means _ for which the complexity is @xmath93 ( we assume the number of dimensions for the euclidean space is fixed ) for a fixed number of clusters and dimensions .",
    "now , clustering without the bucketing step , we would have around @xmath94 entities for clustering with an average of @xmath95 clusters .",
    "hence , @xmath96 , where after bucketing we have on average @xmath97 .",
    "thus , we see a significant decrease in the runtime ( while the complexity in theory remains of the same magnitude ) . for the case of _",
    "spectral _ clustering this is even more evident , where for the adjacency matrix we consider @xmath98 entity pairs , and its singular value decomposition ( dependent on the algorithm used ) is cubical in terms of big - o notation .",
    "* crowdsourced evaluation : precautions . * in order to ensure that we acquire reliable responses from the crowd workers , we take several precautions while designing the tasks for the evaluation of clusters , as well as establishing the ground - truth for the retrieval of entities .",
    "we provide clear instructions and examples to avoid misinterpretations in the relevance scoring , leading to a bias in the judgements .",
    "we compensate workers with monetary incentives that are proportionate to their contribution .",
    "in addition , we use _ gold standard questions _ as recommended by previous works to curtail malicious activity .",
    "* caveats and limitations .",
    "* considering the optimization of the pre - processing step , the process scales well even for large datasets like the btc .",
    "the retrieval task itself is an online process with no complex approaches and hence the corresponding computational overhead is negligible for the user .",
    "we acknowledge the need to re - cluster entities periodically in order to maintain a persistently good entity retrieval performance",
    ". however , we believe that this is a relatively minor overhead , when compared to the improvement in performance that it brings about , and given the fact that it is an offline process which can be scaled using parallel infrastructure .",
    "in this work , we presented an approach to improve the performance of entity retrieval on structured data . building on existing state of the art methods ,",
    "we follow an approach consisting of offline preprocessing clustering , and online retrieval , results expansion and reranking .",
    "preprocessing exploits _ x  means _ and _ spectral _ clustering algorithms using lexical as well as structural features .",
    "the clustering process was carried out on a large set of entities ( over 450 million ) .",
    "the evaluation of the clustering process shows that over 80% of clusters have an accuracy of more than 80% . as part of the online entity retrieval , for",
    "a given a starting result set of entities as retrieved by the baseline approach bm25f we further expand the result set with relevant entities .",
    "additionally , we propose an entity ranking model that takes into account the query type affinity .",
    "finally , we carry out an extensive evaluation of the retrieval process using the semsearch and the btc12 datasets .",
    "the results show that our methods outperform the baseline and state of the art approaches . in terms of standard",
    "ir metrics , our method in combination with one of the clustering approaches , e.g. @xmath87 improves over @xmath85 with @xmath99 , @xmath100 and @xmath101 .",
    "r.  blanco , h.  halpin , d.  m. herzig , p.  mika , j.  pound , h.  s. thompson , and d.  t. tran .",
    "repeatable and reliable search system evaluation using crowdsourcing . in _ proceeding of the 34th acm sigir _ , pages 923932 , 2011 ."
  ],
  "abstract_text": [
    "<S> the increasing amount of data on the web , in particular of linked data , has led to a diverse landscape of datasets , which make entity retrieval a challenging task . </S>",
    "<S> explicit cross - dataset links , for instance to indicate co - references or related entities can significantly improve entity retrieval . however , only a small fraction of entities are interlinked through explicit statements . in this paper </S>",
    "<S> , we propose a two - fold entity retrieval approach . in a first , offline preprocessing step , </S>",
    "<S> we cluster entities based on the _ x  means _ and _ spectral _ clustering algorithms . in the second step , we propose an optimized retrieval model which takes advantage of our precomputed clusters . for a given set of entities retrieved by the bm25f retrieval approach and a given user query </S>",
    "<S> , we further expand the result set with relevant entities by considering features of the queries , entities and the precomputed clusters . </S>",
    "<S> finally , we re - rank the expanded result set with respect to the relevance to the query . </S>",
    "<S> we perform a thorough experimental evaluation on the billions triple challenge ( btc12 ) dataset . </S>",
    "<S> the proposed approach shows significant improvements compared to the baseline and state of the art approaches . </S>"
  ]
}