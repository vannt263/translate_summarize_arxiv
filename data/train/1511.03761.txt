{
  "article_text": [
    "as a simple starting example , consider the classic random effects model @xcite , with data @xmath0 modeled as    @xmath1    for an unknown constant @xmath2 and with @xmath3 and @xmath4 modeled at random variables having mean 0 and variances @xmath5 and @xmath6 respectively .",
    "these random variables are assumed independent across @xmath7 and @xmath8 , though assumptions will generally not be made about their distributions .",
    "the present paper advocates treating quantities such as the @xmath9 as random variables , using a capital letter to emphasize this , @xmath10 :    @xmath11    as seen below , we will also treat regressor variables , if any , to be random .    in short ,",
    "the goal of this paper is to encourage analysts to model all quantities as random , even in most cases those fixed by experimental design .",
    "advantages to this approach will turn out to include :    * much richer , more probing analyses can be devised . *",
    "the derivation of estimators and their standard errors can be simplified . * for some large problems",
    ", the computation for fully random models can be parallelized , under a method known as software alchemy .",
    "let s begin with the @xmath12 . why model them as random ?    as a motivating example of the topic here , consider recommnder systems @xcite , such those that might be applied to the movie lens data @xcite , with ratings of many movies by many users .",
    "if one views this ratings data in matrix form , as do gao and owen @xcite , with rows and columns corresponding to users and movies , respectively , then the matrix is sparse : in the notation of @xcite , @xmath13 for most @xmath7 and @xmath8 , where @xmath14 is an indicator variable for whether user @xmath7 has rated movie @xmath8 . the authors in that paper consider the users to be a random sample from the potential population of all users , and similarly for the movies , and thus use a random effects model .",
    "details on that model will be presented shortly , but for now , let s consider only the users , not the movies .",
    "then we might model the data using ( [ classic ] ) or ( [ nrand ] ) , with @xmath5 being a measure of ratings variability from user to user .",
    "our fr approach might be used , for instance , if we suspect that users who rate a lot of movies become jaded , thus tending to give lower ratings . in other words , there may be a statistical relation between @xmath12 and @xmath3 . if such a relation were estatblished , we may wish to discount the ratings of users having large @xmath12 .",
    "having a statistically significant but small relation to @xmath12 ]    to investigate this , it is natural to model the @xmath12 as random variables , just as we do for the @xmath3 , say with a model    @xmath16    the quantities @xmath17 are now assumed independent conditional on @xmath12 , and their variances , @xmath5 and @xmath6 , are now conditional on @xmath12 as well .",
    "the quantity @xmath3 now represents the overall rating tendency for user @xmath7 , after the effect of count of ratings has been removed .",
    "the modeling of the @xmath12 as a variance component could be useful in many different application fields .",
    "it is known , for example , that there is a negative correlation between family size and household income @xcite .",
    "if the observation units in a study are children within families , it would be thus useful to incorporate the number of children @xmath12 into the analysis .",
    "a study of workers at various companies may be similar to this .",
    "it is common to include linear - model terms into ( [ classic ] ) :    @xmath18    for a vector of regressors @xmath19 and unknown constant vector @xmath20 .",
    "( our old term @xmath2 is now folded in by inserting a 1 element in @xmath19 . ) but it may be helpful to consider the regressors random also , so that our model becomes    @xmath21    where again the use of a capital letter indicates a random variable .    in ( [ randomx ] ) , we may even wish to reverse the usual prediction relationship , predicting one or more of the regressors from the @xmath0 . in the case of recommender systems , for example , the analyst may wish to infer certain information about the user .",
    "some values of the regressors may be missing , for instance , and we may wish to impute them using the other variables . this would be even more reason to treat the regressors as random .",
    "similarly , consider the * instval * data included with the r random - effects modeling package * lme4*. it s essentially another recommender system , with university students rating their instructors .",
    "presumably the higher - quality instructors are chosen by more students , and a valuable approach to studying this could be to try to predict the @xmath12 by the @xmath0 .    in this manner , very elaborate , powerful models can be developed .",
    "for instance , the fr approach can be used to extend and enhance popular recommender systems methodology such as _ collaborative filtering_.",
    "the approach can also be used in models with more than one variance component . for instance , consider the model used by @xcite with the movie dats ,    @xmath22    here @xmath23 is the number of users and @xmath24 is the number of movies .    applying our method to this model",
    ", we treat the @xmath14 as random variables @xmath25 ,    @xmath26    and define the analogs of the @xmath12 above to be the row and column observation counts :    @xmath27    @xmath28    the @xmath12 and @xmath29 are then random as before .",
    "we might also bring in random regressors , for both users and movies :    @xmath30",
    "the method of moments ( mm ) is an attractive approach here , as it will enable estimation of , for instance , @xmath5 in ( [ nrand ] ) without assuming a particular distribution family for the @xmath3 @xcite @xcite @xcite .",
    "let s take ( [ nrand ] ) as our example , using    @xmath31    as our pivot quantity .",
    "it will be very helpful to define generic versions of the variables : let @xmath32 , @xmath33 , @xmath34 and @xmath35 have the same distributions as @xmath12 , @xmath3 , @xmath4 and @xmath36 .",
    "also , let @xmath37 be i.i.d .  with the distribution of @xmath34 .",
    "then write    @xmath38    now apply the `` pythagorean theorem for expectations , ''    @xmath39 + var \\left [ e(u |v ) \\right ] \\ ] ]    to ( [ seqn ] ) . first ,    @xmath40 & = & e \\left [ n^2 \\sigma_a^2 + n \\sigma_e^2 \\right ] \\\\   & = & ( \\nu_2+\\nu_1 ^ 2 ) \\sigma_a^2 + \\nu_1 \\sigma_e^2\\end{aligned}\\ ] ]    where @xmath41 are the population mean and variance of @xmath32 .    next ,    @xmath42 = \\mu^2 \\nu_2\\ ] ]    in other words ,    @xmath43    also ,    @xmath44    we have 5 unknowns to estimate  @xmath5 , @xmath45 , @xmath2 , @xmath46 and @xmath47  and thus need 5 equations for mm .",
    "( [ vars ] ) and ( [ vary ] ) provide the right - hand sides of 2 equations , with the left - hand sides being the sample variances of the @xmath36 and the @xmath0 , respectively .",
    "the other 3 equations come quite simply : we estimate the @xmath48 by the sample mean and variance of @xmath32 , and estimate @xmath2 by @xmath49 , where @xmath50 .",
    "the estimation of more advanced models can be approached similarly , i.e.  deriving expressions for variances and means , typically with the aid of the `` pythagorean theorem . ''    in the regression setting ( [ xigamma ] ) , since we have    @xmath51    we can estimate @xmath20 separately using standard linear model methods , and proceed as before .",
    "note , though , that with the fr approach , the resulting equations may be nonlinear .",
    "for example , consider ( [ famsize ] ) .",
    "the details will not be presented here , but the key points are as follows : the term @xmath52 in ( [ seqn ] ) now becomes    @xmath53    taking the variance of this quantity then brings in the third and fourth moments of @xmath32 , and produces product terms such as @xmath54 .",
    "the former issue is no problem , as the moments are readily estimated from the @xmath12 , but the latter issue means we are now dealing with nonlinear equations .",
    "computation then must be done iteratively .",
    "it is convenient to not write explicit expressions for the variance of ( [ nneqn ] ) , but simply write    @xmath55    at each iteration , we take our current estimates of the @xmath56 , and compute the sample variance of the quantities    @xmath57    as our estimate of ( [ newvarn ] ) .",
    "in many applications of random effects models , quantities such as @xmath58 and @xmath59 above are fixed in the experimental design .",
    "however , one can show that typically the same estimators emerge , whether one assumes a random @xmath12 or fixed @xmath58 .",
    "the same is true for regressors .    as a quick example , consider ( [ classic ] ) . instead of ( [ vars ] ) , we have    @xmath60    also , @xmath61 .",
    "say we set up mm by equating the sample average of the @xmath62 to its expectation .",
    "the latter would be    @xmath63 = \\frac{1}{r }   \\sum_{i=1}^r   [ n_i^2 \\sigma_a^2 + n_i \\sigma_e^2 + ( n_i \\mu)^2]\\ ] ]    even without algebraic simplification , it s clear that the result will be essentially the same as that obtained for the random @xmath12 model .",
    "for instance , the term    @xmath64    corresponds to the term    @xmath65    in ( [ vars ] ) .",
    "in essence , the above derivation is implicitly treating the ( constant ) row counts as random , having a uniform distribution on @xmath66 .",
    "the significance of this is that one can enjoy the benefits of the fr approach ( sections [ simplified ] and [ sa ] ) even if the quantities truly are fixed .",
    "equations in random effects analysis can become quite complex .",
    "note for instance the conditions needed merely to establish consistency in @xcite .",
    "this complexity certainly includes the settings of mm estimation .",
    "for instance , even in the simplest model , ( [ vars ] ) seems rather complicated in its form here , but is even more sprawling if the @xmath58 are taken as fixed .",
    "we argue here that our fr method can greatly ease the derivation of the mm equations .",
    "this is especially true in light of our use of generic variables , as in ( [ seqn ] ) , which can reduce large amounts of equation clutter .",
    "consider for example the model ( [ movie ] ) .",
    "suppose we need to find the covariance between @xmath67 and @xmath68 .",
    "once again , the details will not be shown here , but a glance at ( [ seqn ] ) shows that when we will apply the covariance form of the `` pythagorean theorem , '' the key quantity will be distributed as    @xmath69    where @xmath70 is the number of columns that rows @xmath71 and @xmath72 have in common . the distribution of @xmath70 can be estimated empirically , as we did for @xmath32 above .",
    "the point is that all this can be done without any explcit writing of the @xmath25 .",
    "the difference in complexity of expressions between the fr and fixed-@xmath14 approaches will be quite substantial .",
    "in random - effects modeling applications involving very large data sets , a major concern is computation time and space . as noted in @xcite , the reml method of estimation in a two - component model , for example",
    ", requires @xmath73 time and memory space , where @xmath74 would be either @xmath23 or @xmath24 in the movie ratings example above .",
    "indeed , @xcite reported that `` sas proc mixed ran out of memory when we attempted to fit a model with random smoking effects . ''    a method that i call software alchemy @xcite can help remedy both time and memory problems in contexts of i.i.d .",
    "data , , using a very simple idea .",
    "say we are estimating a population value @xmath75 , typically vector - valued .",
    "one breaks the data into @xmath76 approximately equal - size chunks , finds @xmath77 on each one , and then takes the one s overall estimate to be    @xmath78    this changes the original problem into an `` embarrassingly parallel '' computational problem , i.e.  easy to compute in parallel , say on @xmath76 machines in a cluster or on @xmath76 cores in a multicore machine .",
    "this speeds up computation by a factor of @xmath76 , and since each @xmath77 requires only @xmath79 of the memory space requirement , the method may remedy memory limitation problems in cluster settings .",
    "in fact , the same is true even on a single - core machine , since one would still need only @xmath79 of the memory space requirement at each iteratioo .",
    "the procedure also gives us a mechanism for empirical computation of standard errors .",
    "it is shown in @xcite that if @xmath77 is asymptotically normal , then the same will be true for @xmath80 , and moreover , the latter will have the same asymptotic covariance matrix as the former .",
    "thus no statistical efficiency is lost .",
    "the point then is that this can be applied profitably to random - effects models  if the i.i.d .",
    "requirement of software alchemy is satisfied . by making quantities like the @xmath12 random ,",
    "this can be done in many cases .",
    "consider the model ( [ nrand ] ) , for instance .",
    "a set of key quantities in the estimation procedure consists of the @xmath36 . by modeling the @xmath12 as i.i.d .",
    ", the same will be true for the @xmath36 , and software alchemy can used",
    ".    now consider ( [ nrand1 ] ) , a more subtle setting .",
    "let @xmath81 , @xmath82 ... denote the @xmath0 , arranged in the order in which the ratings are submitted , and write    @xmath83    where the @xmath84 and @xmath85 are now drawn in an i.i.d .",
    "manner from distributions on 1, ... ,r and 1, ... ,c . assuming that submissions come in to the rating site in an i.i.d .",
    "manner , this structure is reasonable . we can then divide the @xmath86 into chunks , estimate @xmath2 , @xmath5 and @xmath6 as before on each chunk , then average over chunks",
    "note that random effects models can be viewed in terms of mixing distributions , with the advantage , for example , that the entire distribution of @xmath33 might be estimated , rather than just its variance @xcite @xcite .",
    "this might be used to develop prediction intervals , say for a continuous @xmath87 .",
    "this paper has presented full randomness , a proposed framework for the enhanced analysis of random effects .",
    "fr enables the formation of richer models of the phenomena under study , simplifies derivations of complex models , and can facilitate parallel speedup of computation .",
    "many further directions in methodology could be explored under this framework , with applications to a number of specific fields , such as the aforementioned collaborative filtering .",
    "j. herlocker , j. konstan , a. borchers , j. riedl ( 1999 ) .",
    "an algorithmic framework for performing collaborative filtering , _ proceedings of the 1999 conference on research and development in information retrieval _"
  ],
  "abstract_text": [
    "<S> a different general philosophy , to be called full randomness ( fr ) , for the analysis of random effects models is presented , involving a notion of reducing or preferably eliminating fixed effects , at least formally . </S>",
    "<S> for example , under fr applied to a repeated measures model , even the number of repetitions would be modeled as random . </S>",
    "<S> it is argued that in many applications such quantities really are random , and that recognizing this enables the construction of much richer , more probing analyses . </S>",
    "<S> methodology for this approach will be developed here , and suggestions will be made for the broader use of the approach . </S>",
    "<S> it is argued that even in settings in which some factors are fixed by the experimental design , fr still `` gives the right answers . '' in addition , computational advantages to such methods will be shown . </S>"
  ]
}