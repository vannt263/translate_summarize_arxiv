{
  "article_text": [
    "we will now describe the algorithm as implemented for producing numerical results in this work , aiming to include sufficient technical detail that it may be fully replicated based on this account .",
    "this specification focuses on the resulting performance more than ease of implementation , and most of its prescriptions can be legitimately simplified as needed .",
    "a source code release , to be made available as a python scikit under the code - name cumin , is also in preparation .",
    "a common thread in derivative - based optimisation @xcite , aiming to minimise an objective function @xmath60 , is the repeated update of a variable @xmath61 storing what can be thought of as the current base point for the domain @xmath62 .",
    "we will write @xmath63 for the sequence of values taken by @xmath61 , but omit the superscript when referring to its value at some present state of the algorithm . on each iteration ,",
    "say the @xmath64 , a model for @xmath65 valid locally about the outgoing base point @xmath66 for this iteration is constructed based on the value of certain derivatives of function @xmath65 at the point @xmath66 .",
    "the idea is then to take for the next base point @xmath67 the minimum @xmath68 of this model for @xmath65 , possibly restricted to some neighbourhood of @xmath66 .",
    "however , since the model is only valid locally , we can not guarantee @xmath69 ie . that using @xmath68 as the next base point will lead to a reduction of the current objective value @xmath70 .",
    "two families of approaches exist for resolving this problem : line search methods look for a suitable point along the line starting at @xmath71 in the direction of @xmath68 , while trust region methods consider rescaling the neighbourhood of @xmath66 to which they constrain minimisation of the model for @xmath65 .",
    "the main performance characteristic which can be reliably affected in choosing between derivative - based optimisation algorithms is the run - time required to achieve convergence to a given accuracy .",
    "when methods have different asymptotic rates of convergence , one of them is determined in advance to eventually be closer to the limit than all others . prior to this regime",
    ", there is a trade - off in the accuracy of models used on each iteration , where more derivative information can be acquired at higher computational cost to construct better models , which should in contrast enable greater progress per iteration . in this respect ,",
    "the hessian matrix of all @xmath72 second derivatives is prohibitively expensive to compute except for special @xmath65 , so that widely effective algorithms only require the gradient vector of @xmath73 first derivatives .    for example quasi - newton optimisation methods , of",
    "which bfgs is an instance , use the model @xmath74 where @xmath75 is the gradient vector of @xmath65 at @xmath61 , and @xmath27 is constructed iteratively to approximate the hessian matrix of @xmath65 at @xmath61 . at least for bfgs , the model minimum @xmath68 , namely @xmath76 since @xmath27 is always positive definite , is used within a line search routine at each iteration . in this context , steepest descent would correspond to replacing @xmath27 by the identity matrix @xmath5 , but we do not consider this method since it can not be recommended in general , and performs particularly slowly on gate control problems @xcite . for comparison , convergence of bfgs iterates to a local minimum @xmath77 where the hessian of @xmath65 is positive definite is understood to happen at a rate , measured either by @xmath78 or @xmath79 , between @xmath80 @xcite and @xmath81 @xcite for some problem specific @xmath82 . while convergence for conjugate gradient @xcite and limited memory bfgs @xcite , without being restarted every @xmath73 iterations only goes as @xmath83 asymptotically , which is also the rate for steepest descent albeit with @xmath82 deteriorating significantly @xcite on poorly conditioned problems .",
    "this description can be adapted to cover newton - raphson root finding applied to the vector valued function @xmath84 by introducing an objective function @xmath85 and specifying that the model , hence the derivatives used to construct it , should be of @xmath55 rather than @xmath65 .",
    "the model in this case reads @xmath86 where @xmath87 is the jacobian matrix of @xmath55 at the point @xmath61 , with entry @xmath88 equal to the @xmath89 partial derivative @xmath90 of the @xmath91 component of @xmath92  in the notation of differential geometry , we can succinctly write @xmath87 as @xmath93 .",
    "if the model were exact , assuming the rank of @xmath87 equals @xmath94 , a global minimum of @xmath65 could be found where @xmath55 is @xmath95 , namely at @xmath96 with @xmath97 being any solution to @xmath98 .",
    "indeed the classical newton - raphson algorithm , applicable for dimensions @xmath99 , uses the update rule @xmath100 for which @xmath101 goes to zero doubly exponentially in @xmath102 , specifically as @xmath103 for some @xmath43 ( known as quadratic convergence ) , for suitable initial conditions @xmath104 .",
    "generalising this to the under - determined regime @xmath105 , the value of @xmath97 is no longer explicitly determined as @xmath106 , and a suitable choice for @xmath97 which preserves the quadratic convergence property is the minimum norm solution of @xmath107 @xcite , computable as @xmath108 . in either case ,",
    "a suitable initial @xmath104 would be any point sufficiently close to some solution @xmath77 of @xmath109 where the jacobian @xmath110 has full rank @xmath94 , in such a way that @xmath111 is always full rank so that all iterates @xmath67 are well - defined .",
    "finding such an initial point is itself difficult , and for general points @xmath61 the neighbourhood in which the model at @xmath61 is accurate contains neither a root @xmath77 of @xmath55 , nor a root @xmath96 of the model .",
    "the rationale behind the update rule @xmath100 , that @xmath112 should be close to a root of @xmath55 since @xmath113 , therefore no longer applies for general @xmath67 and we are compelled to invoke a line search or trust region method to find a usable @xmath114 .",
    "but before we delve further into this , let us deal more specifically with the function @xmath55 which we use for the unitary map control problem .",
    "note in passing that for a general objective @xmath65 which is strictly convex at some minimiser @xmath77 , applying newton - raphson to its gradient vector @xmath115 will seek a critical point of @xmath65 so must converge to @xmath77 when starting sufficiently close to it .",
    "the direction of line searches would then be @xmath116 where @xmath87 is the hessian matrix of @xmath65 , justifying the approximating @xmath117 used in bfgs .",
    "consider the dynamical lie algebra @xmath118 of our control system , ie .",
    "the linear space spanned by all iterated commutator expressions starting with the matrices @xmath119 . by the frobenius theorem , the propagators @xmath120 must remain within the associated group @xmath121 , consisting of matrix exponentials of matrices in @xmath118 , for all time and over all possible control vectors @xmath122 .",
    "conversely , the controllability theory of bi - linear systems shows that for compact @xmath121 there is a critical time @xmath123 depending only on the system such that every point of @xmath121 is accessible in some time @xmath124 using some control vector * f*. this result also holds if the class of admissible controls is restricted to both smooth or piecewise constant functions .",
    "at least when in addition @xmath118 is semi - simple @xcite , the set of unitary matrices @xmath59 which are accessible at a fixed time @xmath9 using some control vector * f * has non - empty interior within @xmath121 @xcite , for each @xmath125 , and in fact equals @xmath121 for @xmath9 sufficiently large .",
    "the conditions of @xmath121 being compact and @xmath118 semi - simple will be assumed in what follows  they hold in particular for the lie algebra of traceless @xmath126 anti - hermitian matrices @xmath127 , which is of special interest as it corresponds to full controllability up to global phase .",
    "once we have introduced a desired parametrisation of the controls , the discretised propagator @xmath128 is a function mapping @xmath129 , taking a vector @xmath61 composed of all parameters @xmath22 to the unitary matrix describing the evolution under the corresponding controls .",
    "explicitly , @xmath128 equals the functional @xmath59 composed with the synthesis operator taking @xmath61 to the vector * f * of functions such that @xmath130 . solving @xmath131",
    "can naturally be phrased as finding the root of either @xmath132 or @xmath133 , but both of these functions range over a non - linear space , making them unsuitable for use in the newton - raphson algorithm .",
    "now let @xmath134 denote the real linear space of all @xmath135 anti - hermitian matrices with inner product @xmath136 . amongst maps taking the unitary group to a linear space ,",
    "the inverse @xmath137 of the well - studied exponential map is a complex analytic function whose value at @xmath5 is @xmath138 and derivative there is the identity on @xmath134  for @xmath139 , it is crucially the only such function taking the global phase neglecting subgroup @xmath140 to a linear space @xcite . the most natural way to linearise",
    "our problem is therefore to look for a root of @xmath141 where the branches of the logarithm are chosen to give a result in @xmath142 of minimal norm and",
    "@xmath47 then expresses this in an orthonormal basis of @xmath118 , dropping any @xmath143 component .",
    "note that when @xmath118 is @xmath144 , the choice of branches for each eigenvalue is the standard one with imaginary part in @xmath145 $ ] , while the implementation of @xmath47 can just keep each strictly upper triangular entry of the input matrix and expresses the imaginary part of its diagonal in any orthonormal basis containing the vector of all @xmath146 .",
    "this choice for @xmath55 also has the advantage , when @xmath121 is compact , of making the corresponding error @xmath147 equal the geodesic distance between @xmath148 and @xmath8 over the group @xmath149 , ie . @xmath121 quotiented out by global phase ( see @xcite sect .",
    "3.2 ) .    in its strong form @xcite",
    ", sard s theorem gives that the set of target gates @xmath8 in @xmath150 for which a solution @xmath77 to @xmath151 exists with rank deficient jacobian @xmath110 is of hausdorff dimension at most @xmath152 .",
    "here @xmath94 is still the dimension of the co - domain of @xmath55 , namely @xmath118 , which makes @xmath153 in the most prominent case when @xmath118 is @xmath144 .",
    "suppose the @xmath26 , with @xmath154 , linearly independent basis functions @xmath23 are not so degenerate that the image of @xmath55 is a measure zero set . with respect to choosing a target @xmath8 from the accessible set , of all @xmath128 for fixed @xmath9 , the full rank condition implying",
    "quadratic convergence of the newton - raphson algorithm therefore occurs with probability one .",
    "the chain rule gives a decomposition for each column @xmath155 of the jacobian of @xmath55 , with the derivative of the discretised propagator known to be @xmath156 writing @xmath157 , given that the composition @xmath158 is the identity on @xmath159 , the @xmath160 part of ( [ col ] ) is simply latexmath:[$\\left ( { \\mathrm{d}}\\exp    expression .",
    "indeed , for a general anti - hermitian matrix @xmath53 , if @xmath162 are the eigenvalues of @xmath53 and @xmath163 a corresponding matrix of eigenvectors ( one per column ) , @xmath164 can be computed as @xmath165 . here",
    "the dot denotes elementwise multiplication and @xmath166 is the matrix with entries @xmath167 where @xmath168 is the function @xmath169 continuously extended , so that @xmath170 .",
    "so @xmath171 is @xmath172 where division is carried out elementwise and the @xmath162 and @xmath163 are those from the eigen - decomposition of @xmath173 .    for computing the propagator @xmath128 ,",
    "we use a fixed time stepping scheme which for @xmath174 successively evaluates the two point propagator @xmath175 , defined as @xmath176 , numerically where @xmath177 , @xmath178 , and @xmath179 is the same for each @xmath180 . in the piecewise constant control parametrisation case , we let @xmath181 so that all the @xmath182 are matrix exponentials  computing the eigen - decomposition of the constant hamiltonian over each time interval @xmath183 then renders the computation of both the propagators and their derivatives relatively inexpensive . in other cases , such as our hermite function parametrisation , any general ode solver could be used , but we found the magnus-4 method @xcite which is specialised for linear odes to be accurate for a smaller number of steps @xmath184 than in particular the standard runge - kutta method , also of fourth order . to evaluate the integral from ( [ deriv ] ) , given that we know @xmath185 at the endpoints of each interval @xmath186 a lobatto quadrature rule is most appropriate , particularly the fourth order rule in order to match the accuracy of the propagator @xmath187 .",
    "this rule would approximate an integral @xmath188 by the weighted sum @xmath189\\ ] ] so that for the whole @xmath190 each value @xmath191 enters twice .",
    "we also used polynomial interpolation , based on the value and first derivative at @xmath192 and @xmath193 , to evaluate @xmath185 at the midpoint of each interval @xmath194 , together with precomputed values for each @xmath23 at the full set of quadrature nodes @xmath193 and @xmath195 .",
    "as described earlier , as soon as @xmath61 is sufficiently close to a solution we should update @xmath61 to @xmath96 , where @xmath97 is a solution to @xmath196 , on all subsequent iterations for which the jacobian @xmath197 is full rank .",
    "however , we need an update rule which is effective in general , and for this purpose we have found in practise that far from a solution the trust region method readily delivers larger decreases in square error @xmath65 than doing a line search could , so for this reason we focus on the former .",
    "the trust region approach to the newton - raphson method consists in finding @xmath198 for some trust region radius @xmath35 , with the situation when the unconstrained minimum can be achieved requiring that we find the solution to @xmath199 having smallest norm . in the over - determined case @xmath200 , independently of whether the original root finding problem is solvable , the equation @xmath201 generically admits no solution so that minimising the norm of the residual @xmath202 is the best we can aim for . in this case one would solve the optimisation problem ( [ nrsp ] ) directly as an instance @xmath203 of the so called trust region sub - problem , which consists in minimising a quadratic function @xmath204 over a ball of radius @xmath35 . without loss of generality @xmath53 can be taken symmetric and the ball centred at the origin , then for @xmath53 semi - definite as in our situation a solution to the sub - problem can always be found of the form @xmath205 for some @xmath206 . to find the appropriate @xmath207",
    ", we use the higher order analogue of the method from @xcite , although for ease of implementation a general convex optimisation package such as cvxopt could be invoked to solve the sub - problem itself .    otherwise when @xmath208 ,",
    "we can restrict attention to @xmath209 orthogonal to the null space of @xmath87 by expressing it as @xmath210 , reducing the problem to @xmath211 where the matrix @xmath212 is defined on the co - domain of @xmath55 . this last problem can be solved through the trust region sub - problem instance @xmath213 then using any solution of @xmath214 , all of them being equivalent in that they yield the same final @xmath209 .",
    "such a reformulation is advantageous since it makes the corresponding matrix @xmath53 lower dimensional , and importantly for performance , instances of @xmath215 in the algorithm we use appear in such a way that it never needs to be computed .    in adapting the choice of trust region radius @xmath35",
    ", we strive on each iteration to use the value @xmath216 of @xmath35 for which @xmath217 attains its minimum , where @xmath218 is the solution from ( [ nrsp ] ) with radius @xmath35 .",
    "note that by definition any choice of radius @xmath35 above the norm @xmath219 of the least square solution to @xmath220 is equivalent , moreover along @xmath221 the model for @xmath65 , namely @xmath222 , is strictly decreasing as @xmath35 ranges over @xmath223 $ ] . as long as the model for @xmath224 is accurate , the true value of @xmath65 along @xmath221 must track its model value and therefore be decreasing ",
    "but once @xmath35 is large enough that the model for @xmath55 starts to break down in the vicinity of @xmath221 , the increments @xmath225 quickly become meaningless , making them overwhelmingly likely to lead the true @xmath226 to increase .",
    "this causes the relative error of the model for @xmath227 to undergo a swift transition from small , in fact vanishing as @xmath228 , to large magnitudes as @xmath35 grows past the minimiser @xmath216 . in our implementation , we adjusted @xmath35 to make this relative error satisfy @xmath229 which typically places @xmath35 close to @xmath216 , although the choice is a valid one irrespectively ( see @xcite sect .",
    "4.0 ) .      at the null control vector ie .",
    "@xmath230 , the propagator @xmath187 reduces to the matrix exponential @xmath231 , so that working in an eigenbasis of @xmath232 it is easy to see that within any @xmath233 expression from ( [ deriv ] ) , each diagonal entry will be a constant function .",
    "therefore over @xmath144 , only @xmath7 out of @xmath234 possible linear combinations of diagonal entries can be generated by any integral @xmath235 where @xmath236 is a scalar valued function .",
    "hence the jacobian at null controls of @xmath187 , thus also of @xmath55 , will be rank deficient for non - trivial systems , since it would be unrealistic for a system to have @xmath237 controls unless it were of very low dimension @xmath2 .",
    "then the model for @xmath55 at @xmath230 almost surely admits no exact solution , so that the ill - conditioning defined as @xmath238 is effectively infinite there , and by continuity tends to infinity as @xmath239 .    at the other extreme , * f * being large introduces high frequency oscillation in @xmath120 and @xmath240 , which cancels out when integrating @xmath241 for any fixed basis elements @xmath23 . in other words , eigenfunctions of the infinite dimensional jacobian @xmath242 have a lot of their spectrum in high fourier components , and this is lost when restricting to the lower frequency subspace spanned by the @xmath23 to obtain the finite dimensional @xmath87 . as a consequence",
    "the singular values of the discretised jacobian @xmath87 shrink as @xmath243 grows , with the corresponding ill - conditioning almost surely going to infinity .",
    "this explains why the ill - conditioning curve from fig .",
    "2(a ) grows towards both small and large norms , thereby attaining its minimum at some finite norm value .    for any given target gate @xmath8",
    ", there is a minimal norm @xmath244 below which no solution in the chosen basis can be found to the control problem , up to the tolerated error . due to the high dimensionality @xmath21 of the discretised control space , the volume of parameter vectors @xmath61 below some norm @xmath245 increases extremely quickly with @xmath245 , eg . for our test problem increasing @xmath245 by @xmath246 will make the volume grow by a factor of over @xmath247 .",
    "while it is tautological that any successful algorithm run must terminate with @xmath243 above @xmath244 , there should be no shortage of solutions with norms slightly above @xmath244 , so we can expect the final norm to be close to @xmath244 when starting with @xmath248 .",
    "when the norm of any iterate @xmath67 is above @xmath244 , it is reasonable to assume the update @xmath249 has no preferred direction , which by the high dimensionality would imply it is near orthogonal to @xmath250 with high probability .",
    "since the trust region radius @xmath35 , hence the update , should be noticeably smaller than the current iterate @xmath67 by a factor @xmath251 say , we would conclude that @xmath252 is only a factor of @xmath253 greater than @xmath254 .",
    "therefore when starting with @xmath255 , none of the algorithm iterations change the norm of @xmath61 substantially , making the final norm close to the initial norm .",
    "these considerations account for the characteristic shape of the curve in fig .",
    "2(c ) , which matches the identity function down to some floor level , presumably equal to @xmath244 , below which it hovers just above the floor level .    given that the ill - conditioning measures how difficult it is to decrease the error on a given iteration , when @xmath255 and all iterates @xmath61 have the same norm , runs of the algorithm are faster if and only if the ill - conditioning is lower for this norm . otherwise the norm of iterates @xmath61 increases up to some value above @xmath244 , but since the ill - conditioning curve is increasing below @xmath244 , lower initial norms lead to runs being slower .",
    "the runtime does not however blow up as @xmath256 because even starting from @xmath95 , although the first iteration may only reduce the error by a negligible amount , the resulting @xmath257 equal to the trust region radius will be substantial .",
    "finally , this explains the correspondence in fig . 2 between the runtime curve and ill - conditioning curve .",
    "the system used for numerical illustrations in this letter was a chain of five qubits with nearest neighbour ising coupling , with a linear gradient inhomogeneity in the magnetic field to enable some degree of frequency selective addressing .",
    "explicitly , the intrinsic hamiltonian is @xmath258 with frequencies @xmath259 , and where @xmath260 is the pauli @xmath261 matrix acting on the @xmath64 spin , eg .",
    "the control hamiltonians are @xmath263 corresponding to the @xmath245-coordinate and @xmath264-coordinate components @xmath265 and @xmath266 of an electric pulse applied simultaneously to all qubits . for this problem , the total evolution time",
    "is fixed at @xmath267 , and the number of basis functions ( per control ) is chosen to be @xmath32 , with all data in the first three figures coming from using piecewise constant controls . by piecewise",
    "constant , we formally mean that @xmath268 is vanishing for @xmath269 outside the interval @xmath270 and constant equal to one inside , with each @xmath23 equal to the previous @xmath271 translated forward in time by @xmath272 .",
    "the hermite functions refer to the eigenfunctions of the quantum harmonic oscillator , shifted to be centred at @xmath273 , and jointly scaled about @xmath273 so that the maximum any of the first @xmath26 attain outside @xmath274 is @xmath275 .",
    "moreover , the definition of integrated power norm for the control vector * f * we use satisfies @xmath276 which equals the standard euclidian norm of the parameter vector @xmath61 when the basis functions @xmath277 are orthonormal .       of different norms ,",
    "( b ) the wall time needed to reach an error @xmath12 of @xmath1 and ( c ) the norm of the corresponding solution pulses , with a dashed ` initial equals final ' line . in addition , ( a ) the ill - conditioning of the jacobian at several randomly sampled pulses of each norm . ]    as a second test problem , we can consider implementing a logical t - gate encoded with the five physical qubit stabilizer code as described in @xcite .",
    "the underlying system is a heisenberg spin chain of length five , with a fixed external coupling field at a rabi frequency of @xmath278 , so that @xmath232 reads @xmath279 with an evolution time @xmath280 .",
    "this has a single control corresponding to @xmath281 enabling the first spin to be detuned , through a local voltage which is piecewise constant over @xmath282 intervals ."
  ],
  "abstract_text": [
    "<S> we introduce a novel algorithm for the task of coherently controlling a quantum mechanical system to implement any chosen unitary dynamics . </S>",
    "<S> it performs faster than existing state of the art methods by one to three orders of magnitude ( depending on which one we compare to ) , particularly for quantum information processing purposes . </S>",
    "<S> this substantially enhances the ability to both study the control capabilities of physical systems within their coherence times , and constrain solutions for control tasks to lie within experimentally feasible regions . </S>",
    "<S> natural extensions of the algorithm are also discussed .    the coherent control of quantum mechanical systems </S>",
    "<S> @xcite has been sucessfully applied to a growing number of tasks in recent years @xcite . </S>",
    "<S> the early approaches such as two pathway quantum interference , pump - dump schemes , or stimulated raman adiabatic passage are intrinsically understandable in terms of interference due to the coordinated activation of resonant transitions between few energy levels @xcite . in order to extend such strategies and tackle more challenging problems , </S>",
    "<S> the field has moved towards employing pulse shapers and optimization algorithms @xcite .    </S>",
    "<S> the field has also broadened its scope , from problems of state preparation , or more generally maximizing the value of an observable over an ensemble @xcite , to , in particular , implementing unitary maps @xcite . </S>",
    "<S> this latter bridges the gap between physical dynamics and the gate formalism of quantum information processing , for which high accuracy solutions are sought , ultimately aiming to reach an error correction threshold around @xmath0 to @xmath1 per gate or below @xcite . in applying the same methods to both state , and map or gate problems , </S>",
    "<S> the additional structure inherent to gate problems has however been neglected  the aim of this letter is to describe how this structure can be exploited to better understand and substantially ease the solving of gate problems .    </S>",
    "<S> formally , a closed @xmath2-level system undergoes controlled unitary dynamics given by @xmath3 satisfying @xmath4 u_{\\text{{{\\textbf{f } } } } } ( t ) , \\quad    u_{\\text{{{\\textbf{f } } } } } ( 0 ) = i\\ ] ] with @xmath5 the identity matrix , and a time dependent hamiltonian @xmath6 = h_0 + \\sum_{r = 1}^r      \\text{{{\\textbf{f}}}}_r ( t ) h_r \\label{bilin}\\ ] ] where * f * is a set of @xmath7 controls pulses , altering the system potential within a semi - classical model under the bilinear approximation . the abstract control problem for a target unitary gate @xmath8 consists in finding a set of real valued functions * f * and an evolution time @xmath9 such that the dynamics satisfies @xmath10 . </S>",
    "<S> since this entails transferring a full basis of states to another ( with relative phases ) , the intuition applicable to state problems is no longer available , and in fact schemes to solve it explicitly are limited to two level systems , or special cases with few levels . for practical purposes , we would only require the actual @xmath11 and target @xmath8 to match up to some prescribed error level @xmath12 , with respect to a notion of distance @xmath13 . </S>",
    "<S> optimisation , whereby a sequence of pulses @xmath14 is generated iteratively with the requisite distance @xmath15 decreasing at each step , has emerged as the strategy of choice for achieving this . </S>",
    "<S> the definitions of distance @xmath16 to measure the error have generally been based on the hilbert - schmidt norm , using either @xmath17 or , quotienting out the unphysical global phase of the dynamics and normalising , @xmath18 which we will be using herein . </S>",
    "<S> in contrast to state control problems where intuitive understanding often plays a role in choosing the initial trail pulses @xmath19 , the serious limitations of intuitive insight for gate problems lead to @xmath19 typically being chosen arbitrarily , eg . at random . moreover , to get any measure of gate error based on experimental measurement would require exhaustive and arduous process tomography , so that there has been an overwhelming preference towards working with numerical simulation of a model for the system .    running a numerical optimisation algorithm </S>",
    "<S> requires that the control pulses be discretised , and in order to incorporate experimental constraints we can choose a basis for discretisation corresponding to the capabilities of our pulse shaping equipment . </S>",
    "<S> thus we let @xmath20 and then optimise over the set of @xmath21 coefficients @xmath22 ; ideally the basis elements @xmath23 would be precisely calibrated to the equipment , but for definiteness we will consider representatives of two important cases . </S>",
    "<S> a common choice in the literature , and the main one we will use , is that of piecewise constant functions , as can be produced by an arbitrary waveform generator @xcite . in the case of frequency domain pulse shaping </S>",
    "<S> , we are dealing with functions which , up to gaussian tails , are both time and spectral bandwidth limited . to capture this property , under suitable scaling we can let @xmath24 be the hermite function of index @xmath25 , and restrict to the first @xmath26 of these . </S>",
    "<S> such a choice has on the other hand not been used in the quantum control setting to our knowledge , although the benefits of hermite functions have certainly been exploited in other applications , eg . </S>",
    "<S> @xcite  while the smoother alternatives to piecewise constant functions used , such as truncated interpolating polynomials @xcite , have much fatter tails in frequency domain . </S>",
    "<S> in addition to the basis constraint on the pulses * f * , there must clearly be some bound @xmath27 on the pulse fluences , equivalently their magnitude in the integrated power norm .    </S>",
    "<S> performance comparison between several runs of the newton - raphson ( red , labeled ` n ' ) , bfgs grape ( green , labeled ` b ' ) and krotov ( blue , labeled ` k ' ) algorithms with small initial pulses @xmath19 . also shown ( in black , labeled ` a ' ) are newton - raphson runs initialised at the norm with least ill - conditioning ; the cost of finding this norm , on average 21 seconds , is included . ]    for generic intrinsic and control hamiltonians @xmath28 of ( [ bilin ] ) , as well as many specific cases of physical interest , full controllability is known to hold , meaning that any target gate can be achieved given sufficient evolution time @xmath9 and freedom in shaping the control pulses @xcite . </S>",
    "<S> while this is a strong result , it does not identify which gates are achievable for particular evolution times and constraints on the controls , in any given experimental context . </S>",
    "<S> indeed , such specific results are currently lacking , and one must resort to numerical investigations in order to gain better understanding into the capabilities of each physical system @xcite . </S>",
    "<S> this motivates the need for an optimisation algorithm to solve the gate problem in runtimes on a scale rendering the process interactive or faster . </S>",
    "<S> it is the purpose of this letter to introduce a newton - raphson root finding approach for this problem , which performs substantially faster than existing methods ( see fig . </S>",
    "<S> [ cmp ] ) , thereby achieving this goal on non - trivial examples . </S>",
    "<S> such an approach also sheds light on the strong influence of the pulse initialisation @xmath19 , leading to a prescription for how to choose it .    for consistency , all numerical examples herein are for the canonical problem of implementing a quantum fourier transform on a five qubit ising coupled spin chain in a magnetic field gradient using two controls . </S>",
    "<S> but these are qualitatively representative of the results for different evolution times , target gates , and modes of control  a different problem scenario illustrates such similarity in the supplement . in terms of pauli matrices @xmath29 , the hamiltonian in question is @xmath30 = \\sum_{n = 1}^4    \\sigma_z^{\\left ( n \\right ) } \\sigma_z^{\\left ( n + 1 \\right ) } - \\sum_{n = 1}^5    \\left ( n + 2 \\right ) \\sigma_z^{\\left ( n \\right ) } \\\\ + \\text{{{\\textbf{f}}}}_1    \\left ( t \\right ) \\sum_{n = 1}^5 \\sigma_x^{\\left ( n \\right ) } +    \\text{{{\\textbf{f}}}}_2 \\left ( t \\right ) \\sum_{n = 1}^5 \\sigma_y^{\\left ( n    \\right ) }    \\end{gathered}\\ ] ] while we fix an evolution time @xmath9 of @xmath31 and use @xmath32 basis functions , with piecewise constant controls unless stated otherwise .    over the last fifteen years , most techniques successfully applied to model - based quantum control problems have either come from mainstream gradient - driven optimisation theory , eg . </S>",
    "<S> conjugate gradient and bfgs @xcite based grape @xcite algorithms , or can be understood in this context , as with the krotov method @xcite . </S>",
    "<S> these state of the art techniques have led to advances such as towards implementing logic gates fault - tolerantly @xcite or with minimal errors given the decoherence time @xcite . </S>",
    "<S> they owe their performance to the use of gradient information , but a key realisation is that the full jacobian matrix @xmath33 of @xmath11 for the gate problem can be computed as efficiently as its single row constituting the gradient vector . </S>",
    "<S> indeed the usual gradient computation @xcite , for @xmath34 say , effectively proceeds through @xmath33 by inner producting each row of @xmath33 with @xmath8 , so that using the gradient alone means discarding a lot of valuable information .    </S>",
    "<S> looking at the singular value decomposition of the jacobian matrix leads to a clean geometric picture , whereby changes to the pulses below a certain norm @xmath35 ( beyond which higher order terms cease being negligible ) induce changes in the implemented gate within a prescribed ellipsoid . </S>",
    "<S> the basic newton - raphson iteration @xcite then consists in using this jacobian model , with a heuristic choice of @xmath35 , to compute new pulses bringing the implemented @xmath36 closer to the target @xmath8 , which reduces to a linear algebraic task . in order to have the modelling ellipsoid </S>",
    "<S> strictly track the unitary group , one can map its elements down via the matrix exponential , or conversely , group elements up via the matrix logarithm , as we describe later . </S>",
    "<S> the volume of this ellipsoid determines the ability of all algorithms mentioned herein to shift @xmath11 in general directions , while for the specific target @xmath8 a more relevant quantity correlated to this volume is the distance to exact solution controls upon ignoring higher order terms , which we shall refer to as the level of ill - conditioning .    for newton - raphson runs with initial pulses @xmath19 of different norms , ( b ) the wall time needed to reach an error @xmath12 of @xmath1 and ( c ) the norm of the corresponding solution pulses , with a dashed ` initial equals final ' line . </S>",
    "<S> in addition , ( a ) the ill - conditioning of the jacobian at several randomly sampled pulses of each norm . ]    the situation for our test problem depicted in fig . [ split ] </S>",
    "<S> is representative of the general structure , as described in detail in the supplemental material , which can be expected of all problems . </S>",
    "<S> we see that both the ill - conditioning and the newton - raphson runtime strongly depend on the integrated power of the pulses ( specifically of @xmath19 in the latter case ) , but are well concentrated beyond this along a single curve , with the minimum of these two curves coinciding . </S>",
    "<S> when solution pulses are required to have a fluence below @xmath27 , we can cheaply find the minimum of the ill - conditioning curve restricted to the interval @xmath37 $ ] say , and use an arbitrary @xmath19 with this norm to initialise the algorithm . </S>",
    "<S> it is clear from fig . </S>",
    "<S> [ split](c ) that this choice will yield a solution satisfying the fluence constraint unless no choice can , while the correspondance between ill - conditioning and runtime curves makes it the most efficient choice . </S>",
    "<S> the benefit of this prescription over less deliberate ones is evident from comparing the ` a ' and ` n ' series of runs in fig . </S>",
    "<S> [ cmp ] .    </S>",
    "<S> the original equation @xmath10 should be thought of as over - determined when the dimension @xmath38 of the unitary group is greater than that of the control space @xmath21 , since then it is only solvable to arbitrarily high accuracy for an exceptional set of targets @xmath8 . </S>",
    "<S> this makes it an unfavourable case in the context of low error control , because it is implausible for a target gate @xmath8 of interest to be special in this sense . on the other hand , whenever solvability is not so limited then almost every achievable target @xmath8 admits an @xmath39 dimensional set of control pulses implementing it . </S>",
    "<S> although the number of iterations for algorithms to reach a given error tolerance @xmath12 is , as expected , reduced as this dimension of degeneracy increases , there is a counter - intuitive downside to under - determined problems .    </S>",
    "<S> in general when converging to an exact solution , the error of krotov iterates decays exponentially , ie . </S>",
    "<S> eventually as @xmath40 for some @xmath41 , while with conjugate gradient or bfgs , the error decay is faster than exponential , and newton algorithms have error decaying doubly exponentially @xcite , as @xmath42 for some @xmath43 . </S>",
    "<S> but in the under - determined context , one can only count on exponential convergence from all of these algorithms except for newton - raphson root finding which retains its double exponential convergence . </S>",
    "<S> indeed , the directions of degeneracy about a solution form a null space to the hessian there , rendering inapplicable the analysis @xcite on which faster than exponential convergence results for bfgs are based @xcite . </S>",
    "<S> the stark difference between these rates is illustrated in fig . </S>",
    "<S> [ rates ] , where all newton - raphson runs surpass @xmath1 in a single iteration once they reach @xmath44 error .    </S>",
    "<S> illustration of the different convergence behaviours of newton - raphson ( red , labeled ` n ' ) , bfgs grape ( green , labeled ` b ' ) and krotov ( blue , labeled ` k ' ) algorithms with initial norms having minimal ill - conditioning . although several runs were carried out from very different initial pulses , the performance profile of each algorithm remains the same . ]    in order to make best use of newton - raphson root finding , we must re - formulate our problem over a linear space , and the most natural choice here is to seek for the functional @xmath45 to equal zero within the space @xmath46 of anti - hermitian matrices . </S>",
    "<S> the resulting algorithm then has the elegant property of reducing the geodesic distance between the actual @xmath11 and target gate @xmath8 on each iteration . </S>",
    "<S> it can usefully be made more general by restricting attention to a subspace of @xmath46 , specified by an orthogonal projection @xmath47 , ie . </S>",
    "<S> seeking a zero of @xmath48 . </S>",
    "<S> in particular , restricting to the space @xmath49 of traceless anti - hermitian matrices makes the root finding insensitive to the unphysical global phase .    </S>",
    "<S> a less obvious application is to implement a gate on a system interacting coherently with an environment @xcite , which contrary to markovian interaction with a bath is reversible so need not fundamentally limit the achievable error . </S>",
    "<S> the full hilbert space then splits as @xmath50 , and for a given gate on the system @xmath51 our aim would be to implement any gate of the form @xmath52 for an ancillary evolution @xmath53  this corresponds to letting @xmath54 in @xmath55 and projecting it out of the space @xmath56 with @xmath47 . </S>",
    "<S> although the newton - raphson algorithm can certainly be applied to lindblad dynamics , choosing a short evolution time @xmath9 to limit dissipation and finding a control for the system without bath should still be a first step , since computing the evolution super - operator is much more expensive . in both extensions , </S>",
    "<S> having @xmath57 becomes far from sufficient to justify concluding the problem is exactly solvable .    </S>",
    "<S> spectrum of typical minimal norm solutions with error below @xmath1 , in the piecewise constant ( left ) and hermite function ( right ) bases . </S>",
    "<S> these are symmetric about @xmath58 , but the hermite functions could just as easily be made bandlimited about any chosen carrier frequency . ]    up until now , all numerical examples have been in the piecewise constant basis , but our algorithm applies to general bases , and of particular interest is the hermite basis to find spectrally narrow solution pulses . note that the same bandwidth as seen in the right panel of fig . </S>",
    "<S> [ spec ] could be obtained by a suitable basis of low frequency fourier components , but implementing such a pulse in a finite time duration would lead to distortion , thereby deteriorating the achieved error . </S>",
    "<S> interestingly , using the same number of basis functions @xmath26 , the curve from fig . </S>",
    "<S> [ split](c ) and the most efficient initial fluence remain unchanged across both bases  the average number of iterations to reach the same error tolerance @xmath12 is also similar ( 10.1 vs. 12.5 ) for this initial fluence . </S>",
    "<S> the piecewise constant basis is however special in how operations are cheaper with it than in general bases , eg . for our test problem computing </S>",
    "<S> the propagator @xmath59 takes 0.9 seconds , as opposed to around 50 seconds in the hermite basis . </S>",
    "<S> this makes it all the more important to choose the initial @xmath19 in a general basis carefully , and to this end information from the more tractable piecewise constant case seems to suffice .    </S>",
    "<S> we have seen how viewing unitary map control problems from the root finding perspective motivates an algorithm offering vast performance improvements over existing methods , and reveals particularly clean structure within the space of controls . </S>",
    "<S> this formulation can moreover naturally be made in the full generality of pulses represented in arbitrary bases and accounting for an environment to the system . </S>",
    "<S> for state preparation problems , considering the newton - raphson algorithm analogue @xcite in that case promises to lead to further fruitful developments .    </S>",
    "<S> this work was funded by epsrc , via case / cna/07/47 , and hitachi . </S>",
    "<S> the author wishes to thank sophie schirmer and peter pemberton - ross for valuable exchanges .    </S>",
    "<S> 10 h.  m. wiseman and g.  j. milburn . </S>",
    "<S> _ quantum measurement and control_. ( cambridge university press , 2009 )    m. shapiro and p. brumer . _ </S>",
    "<S> principles of the quantum control of molecular processes_. ( wiley - interscience , 2003 )    j.  p. dowling and g.  j. milburn . _ </S>",
    "<S> phil . </S>",
    "<S> trans . </S>",
    "<S> r. soc . </S>",
    "<S> london a _ , * 361 * , 1655 ( 2003 )    h. mabuchi and n. khaneja . </S>",
    "<S> _ int . </S>",
    "<S> j. robust & nonlin . </S>",
    "<S> cont . </S>",
    "<S> _ , * 15 * , 647 ( 2005 )    c. brif , r. chakrabarti , and h. rabitz . _ new j. phys . _ , * 12 * , 075008 ( 2010 )    k. singer , u. poschinger , m. murphy , p. ivanov , f. ziesel , t. calarco , and f. schmidt - kaler . _ rev . </S>",
    "<S> mod . </S>",
    "<S> phys . </S>",
    "<S> _ , * 82 * , 2609 ( 2010 )    d.  j. tannor and s.  a. rice </S>",
    "<S> . _ j. chem . </S>",
    "<S> phys . </S>",
    "<S> _ , * 83 * , 5013 ( 1985 )    t.  schulte - herbrggen , a.  sprl , n.  khaneja , and s.  j. glaser . </S>",
    "<S> _ phys . </S>",
    "<S> rev . </S>",
    "<S> a _ , * 72 * , 042331 ( 2005 )    a.  m. steane . </S>",
    "<S> _ phys . </S>",
    "<S> rev . </S>",
    "<S> a _ , * 68 * , 042322 ( 2003 )    f.  motzoi , j.  m gambetta , s.  t merkel , and f.  k wilhelm . </S>",
    "<S> _ arxiv:1102.0584 _ , ( 2011 )    p.  k. higuchi and s. karp . </S>",
    "<S> _ u.s . </S>",
    "<S> patent _ 3384715 ( 1968 )    </S>",
    "<S> j .- s . </S>",
    "<S> li , j. ruths , t .- y . </S>",
    "<S> yu , h. arthanari , and g. wagner . </S>",
    "<S> _ p. nat </S>",
    "<S> . acad . </S>",
    "<S> sci . </S>",
    "<S> _ , * 108 * , 1879 ( 2011 )    v. jurdjevic and h.  j. sussmann . </S>",
    "<S> _ j. diff . </S>",
    "<S> eq . </S>",
    "<S> _ , * 12 * , 313 ( 1972 )    t.  caneva , m.  murphy , t.  calarco , r.  fazio , s.  montangero , v.  giovannetti , and g.  e. santoro . _ </S>",
    "<S> phys . </S>",
    "<S> rev . </S>",
    "<S> lett . </S>",
    "<S> _ , * 103 * , 240501 ( 2009 )    p. </S>",
    "<S> de fouquieres , s.  g. schirmer , s.  j. glaser , and i. kuprov . _ j. mag </S>",
    "<S> . res . </S>",
    "<S> _ , * 212 * , 412 ( 2011 )    n. khaneja , t. reiss , c. kehlet , t. schulte - herbrggen , and s.j </S>",
    "<S> . glaser . </S>",
    "<S> _ j. mag . </S>",
    "<S> res . </S>",
    "<S> _ , * 172 * , 296 ( 2005 )    y. maday and g. turinici . </S>",
    "<S> _ j. chem . </S>",
    "<S> phys . </S>",
    "<S> _ , * 118 * , 8191 ( 2003 )    r  nigmatullin and s  g schirmer . </S>",
    "<S> _ new j. phys . </S>",
    "<S> _ , * 11 * , 105032 ( 2009 )    a.  sprl , t.  schulte - herbrggen , s.  j. glaser , v.  bergholm , m.  j. storcz , j.  ferber , and f.  k. wilhelm . </S>",
    "<S> _ phys . </S>",
    "<S> rev . </S>",
    "<S> a _ , * 75 * , 012302 ( 2007 )    i. kuprov and c.  t. rodgers . </S>",
    "<S> _ j. chem . </S>",
    "<S> phys . </S>",
    "<S> _ , * 131 * , 234108 ( 2009 )    c.  t. kelley . </S>",
    "<S> _ solving nonlinear equations with newton s method_. ( siam , 2003 )    a. ben - israel </S>",
    "<S> . _ j. math . </S>",
    "<S> anal . & </S>",
    "<S> appl . </S>",
    "<S> _ , * 15 * , 243 ( 1966 )    j.  e dennis and j.  j mor . </S>",
    "<S> _ math . of comp . </S>",
    "<S> _ , * 28 * , 549 ( 1974 )    m.j.d </S>",
    "<S> . powell . </S>",
    "<S> _ siam - ams p. nonlin . </S>",
    "<S> prog . </S>",
    "<S> _ , * 9 * , 53 ( 1976 )    d.  h li and m. fukushima . </S>",
    "<S> _ siam j. optim . </S>",
    "<S> _ , * 11 * , 1054 ( 2001 )    p.  rebentrost , i.  serban , t.  schulte - herbrggen , and f.  k. wilhelm . </S>",
    "<S> _ phys . </S>",
    "<S> rev . </S>",
    "<S> lett . </S>",
    "<S> _ , * 102 * , 090401 ( 2009 )    j. martnez . _ j. comp . & appl . math . </S>",
    "<S> _ , * 34 * , 171 ( 1991 ) </S>"
  ]
}