{
  "article_text": [
    "current standard sets of parton distribution function ( pdf ) do not include uncertainties  @xcite . in practice ,",
    "as long as the pdf s are used to calculate observables that themselves have large experimental uncertainties this shortcoming is obviously not a problem . in the past",
    "the precision of the hadron collider data was such that there was no ostensible need for the pdf uncertainties , as was testified by the good agreement between the theory and measurements .",
    "however , the need for pdf uncertainties became apparent with the measurement of the one jet inclusive transverse energy at the tevatron  @xcite . at large transverse jet energies the data was significantly above the theoretical prediction , a possible signal for new physics .",
    "the deviation was ultimately `` fixed '' by changing the pdf s in such a manner that they still were consistent with the observables used to determine the pdf  @xcite .",
    "this is a reflection of the significant pdf uncertainties for this observable . knowing the uncertainties on the pdf s would have cleared the situation immediately .",
    "note that once the data is used in the pdf fit , it can not be used for other purposes . specifically , setting limits on possible physics beyond the standard model . in that case",
    ", one should fit the pdf s and the new physics simultaneously .",
    "the technique presented in this paper is well suited for this sort of problem .",
    "the spread between different sets of pdf s is often associated with pdf uncertainties .",
    "currently , this is what is used for the determination of the pdf uncertainty on the @xmath0-boson mass at the tevatron .",
    "it is not possible to argue that this spread is an accurate representation of all experimental and theoretical pdf uncertainties . for the next planned high luminosity run at fermilab , assuming an integrated luminosity of @xmath1 , the expected 40 mev uncertainty on the @xmath0-boson mass is dominated by a 30 mev production model uncertainty .",
    "the latter uncertainty itself is dominated by the pdf uncertainty , estimated to be 25 mev  @xcite .",
    "this determination of the pdf uncertainty is currently nothing more than an educated guess .",
    "it is made by ruling out existing pdf s using the lepton charge asymmetry in @xmath0-boson decay events .",
    "the spread of the remaining pdf s determines the uncertainty on the extracted @xmath0-boson mass . because the pdf uncertainty seems to be the dominant source of uncertainty in the determination of the @xmath0-boson mass ,",
    "such a procedure must be replaced by a more rigorous quantitative approach .",
    "the method described in this paper is well suited for this purpose .    in this paper , using the framework of statistical inference  @xcite , we illustrate a method that can be used for many purposes .",
    "first of all , it is easy to propagate the pdf uncertainties to a new observable without the need to calculate the derivative of the observable with respect to the different pdf parameters .",
    "secondly , it is straightforward to assess the compatibility of new data with the current fit and determine whether the new data should be included in the fit .",
    "finally , the new data can be included in the fit without redoing the whole fit .",
    "this method is significantly different from more traditional approaches to fit the pdf s to the data .",
    "it is very flexible and beside solving the problems already mentioned , it offers additional advantages .",
    "first , the experimental uncertainties and the probability density distributions for the fitted parameters do not have to be gaussian distributed .",
    "however , such a generalization would require a significant increase in computer resources .",
    "second , once a fit has been made to all the data sets , a specific data set can be easily excluded from the fit .",
    "such an option is important in order to be able to investigate the effect of the different data sets .",
    "this is particularly useful in the case of incompatible new data . in that case",
    "one can easily investigate the origin of the incompatibility .",
    "finally , because it is not necessary to redo a global fit in order to include a new data set , experimenters can include their own new data into the pdf s during the analysis phase .",
    "the outline for the rest of the paper is as follows . in sec .",
    "[ sect : method ] , we describe the inference method . the flexibility and simplicity of the method is illustrated in sec .",
    "[ sect : expanding ] , by applying it to the cdf one jet inclusive transverse jet energy distribution  @xcite and the cdf lepton charge asymmetry data  @xcite . in sec .",
    "[ sect : conclusions ] we draw our conclusions and outline future improvements and extensions to our method .",
    "statistical inference requires an initial probability density distribution for the pdf parameters",
    ". this initial distribution can be rather arbitrary , in particular it can be solely based on theoretical considerations .",
    "once enough experimental data are used to constrain the probability density distribution of the parameters the initial choices become irrelevant  . obviously , the initial choice does play a role at intermediate stages .",
    "the initial distribution can also be the result of a former fit to other data .",
    "the data that we will use later in this paper do not constrain the pdf s enough by themselves to consider using an initial distribution based only on theory .",
    "the final answer would depend too much on our initial guess .",
    "we therefore decided to use the results of ref .",
    "@xcite . in this work",
    "the probability density distribution was assumed to be gaussian distributed and was constrained using deep inelastic scattering ( dis ) data .",
    "all the experimental uncertainties , including correlations , were included in the fit , but no theoretical uncertainties were considered . the fact that no tevatron data were used allows us to illustrate the method with tevatron data  .",
    "we briefly summarize ref .",
    "@xcite in the appendix .    in sec .",
    "2.1 we explain the propagation of the uncertainty to new observables .",
    "2.2 shows how the compatibility of new data with the pdf can be estimated . finally , in sec .",
    "2.3 we demonstrate how the effect of new data can be included in the pdf s by updating the probability density distribution of the pdf parameters .",
    "we now assume that the pdf s are parametrized at an initial factorization scale @xmath2 , with @xmath3 parameters , @xmath4 and that the probability density distribution is given by @xmath5 . note that @xmath5 does not have to be a gaussian distribution",
    ".    by definition @xmath5 is normalized to unity , @xmath6 where the integration is performed over the full multi - dimensional parameter space and @xmath7 . to calculate the parameter space integrals we use a monte - carlo ( mc ) integration approach with importance sampling .",
    "we generate @xmath8 random sets of parameters @xmath9 distributed according to @xmath10 .",
    "this choice should minimize the mc uncertainty for most of the integrals we are interested in . for reference",
    "we also generate one set at the central values of the @xmath9 , the @xmath11 .",
    "the number of parameter sets to be used depends on the quality of the data .",
    "the smaller the experimental uncertainty is compared to the pdf uncertainty , the more pdf s we need .",
    "we must ensure a sufficient fraction of pdf s span the region of interest ( i.e. close to the data ) .",
    "for the purposes of this paper , we found that @xmath12 is adequate .",
    "clearly , to each of the @xmath8 sets of parameters @xmath9 correspond a set of unique pdf s .",
    "each of these pdf sets have to be evolved using the altarelli - parisi evolution equations .",
    "we used the cteq package to do this evolution  @xcite .",
    "we now can evaluate any integral @xmath13 over the parameter space as a finite sum  @xcite @xmath14 with @xmath15 is the @xmath16-th random set of @xmath9 .",
    "the function @xmath17 represents an integrable function of the pdf parameters .",
    "the uncertainty on the integral @xmath13 due to the mc integration is given by , @xmath18    for any quantity , @xmath19 , that depends on the pdf parameters @xmath20 ( for example an observable , one of the flavor pdf s or for that matter one of the parameter itself ) , the theory prediction is given by its average value , @xmath21 , and its uncertainty , @xmath22  : @xmath23 note that @xmath21 is not necessarily equal to the value of @xmath24 evaluated at the central value of the @xmath9 .",
    "however , this is how observables are evaluated if one has only access to pdf s without uncertainties .",
    "given @xmath25 , another quantity calculable from the @xmath9 , the covariance of @xmath19 and @xmath25 is given by the usual expression : @xmath26 the correlation between @xmath19 and @xmath25 is given by @xmath27 .",
    "for example , this can be used to calculate the correlation between two experimental observables , between an observable and one of the pdf parameters , or between an observable and a specific flavor pdf at a fixed bjorken-@xmath28 .    using eq .  [",
    "eq : deltai ] , the mc uncertainty on the average and ( co)variance is given by @xmath29    the mc technique presented in this sub - section , gives a simple way to propagate uncertainties to a new observable , without the need for calculating the derivatives of the observable with respect to the parameters .",
    "we will assume that one or several new experiments , not used in the determination of the initial probability density distribution , have measured a set of @xmath30 observables @xmath31 .",
    "the experimental uncertainties , including the systematic uncertainties , are summarized by the @xmath32 experimental covariance matrix @xmath33 .",
    "note that the correlations between experiments are easily incorporated .",
    "here however , we have to assume that the new experiments are not correlated with any of the experiments used in the determination of @xmath34 .",
    "the probability density distribution of @xmath35 is given by @xmath36 where @xmath37 is the conditional probability density distribution ( often referred to as likelihood function ) .",
    "this distribution quantifies the probability of measuring the specific set of experimental values \\{@xmath38 } given the set of pdf parameters @xmath9 . in pdf sets without uncertainties",
    ", @xmath10 is a delta function and @xmath39 .    instead of dealing with the probability density distribution of eq .",
    "[ eq : pxe ] , one often quotes the confidence level to determine the agreement between the data and the model .",
    "the confidence level is defined as the probability that a repeat of the given experiment(s ) would observe a worse agreement with the model . the confidence level of \\{@xmath38 }",
    "is given by @xmath40 where @xmath41 is the confidence level of \\{@xmath38 } given @xmath9 .",
    "if @xmath42 is larger than an agreed value , the data are considered consistent with the pdf and can be included in the fit .",
    "if it is smaller , the data are inconsistent and we have to determine the source of discrepancy .    for non - gaussian uncertainties the calculation of the confidence level might be ambiguous . in this paper",
    "we assume that the uncertainties are gaussian .",
    "the conditional probability density distribution and confidence level are then given by @xmath43 where @xmath44 is the chi - squared of the new data .",
    "the theory prediction for the @xmath45-th experimental observable , @xmath46 , is calculated using the pdf set given by the parameters @xmath9 .",
    "the matrix @xmath47 is the inverse of the total covariance matrix , @xmath48 , which in turn is given by the sum of the experimental , @xmath33 , and theoretical , @xmath49 , covariance matrix .",
    "we assume that there is no correlation between the experimental and theoretical uncertainties .",
    "we will use a minimal value of 0.27% on the confidence level , corresponding to a three sigma deviation , as a measure of compatibility of the data with the theory .",
    "if the new data are consistent with the theory prediction then the maximum of the distribution of the @xmath50 should be close to @xmath30 ( within the expected @xmath51 uncertainty ) .",
    "the standard deviation of @xmath50 , @xmath52 , tells us something about the relative size of the pdf uncertainty compared to the size of the data uncertainty .",
    "the larger the value of @xmath52 is compared to @xmath51 , the more the data will be useful in constraining the pdf s .    note that if there are several uncorrelated experiments , the total @xmath50 is equal to the sum of the @xmath50 of the individual experiments and the conditional probability is equal to the product of the individual conditional probabilities .",
    "once we have decided that the new data are compatible with the initial pdf s , we can constrain the pdf s further .",
    "we do this within the formalism of statistical inference , using bayes theorem .",
    "the idea is to update the probability density distribution taking into account the new data .",
    "this new probability density distribution is in fact the conditional probability density distribution for the @xmath9 considering the new data \\{@xmath38 } and is given directly by bayes theorem @xmath53 where @xmath54 , defined in eq .",
    "[ eq : pxe ] , acts as a normalization factor such that @xmath55 is normalized to one . because @xmath56 is normalized to unity , we can replace @xmath37 in eq .",
    "[ eq : pnew ] simply by @xmath57 .",
    "this factor acts as a new weight on each of the pdf s .",
    "we can now replace @xmath10 by @xmath56 in the expression for the average , standard deviation and covariance given in sec .",
    "2.1 and obtain predictions that include the effect of the new data . with the mc integration technique described before , these quantities can be estimated by weighted sums over the @xmath8 pdf sets @xmath58 where the weights are given by @xmath59 note that for the calculation of the monte - carlo uncertainty of the weighted sums , the correlation between the numerator and denominator in eq .",
    "[ eq : newmusig ] has to be taken into account properly .",
    "our strategy is very flexible .",
    "once the theory predictions @xmath60 using the @xmath8 pdf sets are known for each of the experiments , it is trivial to include or exclude the effect of one of the experiments on the probability density distribution .",
    "if the different experiments are uncorrelated then all what is needed is the @xmath50 of each individual experiments for all the pdf sets . in that case , each experiment is compressed into @xmath8 @xmath50 values .",
    "one other advantage is that all the needed @xmath61 can be calculated beforehand in a systematic manner , whereas standard chi - squared or maximum likelihood fits require many evaluations of @xmath62 during the fit as the parameters are changed in order to find the extremum .",
    "these methods are not very flexible , as a new fit is required each time an experiment is added or removed .",
    "the new probability density distribution of the pdf parameters is gaussian if the following three conditions are met .",
    "first , the initial probability density distribution , @xmath10 , must be gaussian .",
    "second , all the uncertainties on the data points must be gaussian distributed ( that includes systematic and theoretical uncertainties ) .",
    "finally , the theory predictions , @xmath63 , must be linear in @xmath9 in the region of interest .",
    "this last requirement is fulfilled once the pdf uncertainties are small enough . for the studies in this paper",
    "all three requirements are fulfilled .",
    "the new probability density distribution can therefore be characterized by the average value of the parameters and their covariance matrix , which can be calculated , together with their mc integration uncertainty , using eq .",
    "[ eq : newmusig ] .",
    "once the new values of the average and the covariance matrix have been calculated , a new set of pdf parameters can be generated according to the new distribution and used to make further prediction instead of using the initial set of pdf with the weights .    an alternative way to generate a pdf set distributed according to @xmath56 is to unweight the now weighted initial pdf set .",
    "the simplest way to unweight the pdf sets is to use a rejection algorithm .",
    "that is , define @xmath64 as the largest of the @xmath8 weights given in eq .",
    "next generate for each pdf set a uniform stochastic number , @xmath65 , between zero and one .",
    "if the weight @xmath66 is larger or equal to @xmath67 we keep pdf set @xmath45 , otherwise it is discarded .",
    "the surviving pdf s are now distributed according to @xmath56 .",
    "the number of surviving pdf s is on average given by @xmath68 .",
    "we can now apply all the techniques of the previous sub - sections , using the new unweighted pdf set .",
    "the mc integration uncertainties are easily estimated using the expected number of surviving pdf s . in the extreme case",
    "that @xmath64 is close to one and only a few pdf survive the unweighting procedure , the number of initial pdf s must be increased .",
    "the other extreme occurs when all the weights are approximately equal , i.e. @xmath69 . in that case",
    "the new data puts hardly any additional constraints on the pdf .",
    "the @xmath50 is only used to calculate the weight of a particular pdf , so that the new probability density distribution of the pdf parameters can be determined .",
    "we do not perform a chi - squared fit . however , if the new probability density distribution of the parameters is gaussian distributed then our method is equivalent to a chi - squared fit . in that case",
    "the average value of the parameters correspond to the maximum of the probability density distribution .",
    "the minimum chi - squared can be estimated ( with mc uncertainties ) from the average @xmath50 calculated with the new probability density distribution .",
    "indeed , by definition this average must be equal to the minimum chi - squared , @xmath70 , plus the known number of parameter .",
    "note that the variance of the @xmath50 must itself be equal to twice the number of parameters . to obtain the overall minimum chi - squared , the value of the minimum chi - squared of the initial fit must be added to @xmath70 .",
    "as long as the confidence level of the new data that were included in the fit is sufficiently high , the overall minimum chi - squared obtained is guaranteed to be in accordance with expectations   was within expectations . ] .",
    "the viability of the method described in sec .  2 is studied using two cdf measurements . in sec .",
    "3.1 the one jet inclusive transverse energy distribution is considered , while the lepton charge asymmetry in @xmath0-boson decay is examined in sec .",
    "3.2 . the statistical , systematic , and theoretical uncertainties on the observables will be taken into account .",
    "the cdf results on the one jet inclusive transverse energy distribution  @xcite demonstrated the weakness of the current standard pdf sets due to the absence of uncertainties on the pdf parameters .",
    "the observables are the inclusive jet cross section at different transverse energies  ,",
    "@xmath71 @xmath72 we first have to construct the experimental covariance matrix , @xmath73 , using the information contained in ref .",
    "the paper lists the statistical uncertainty at the different experimental points , @xmath74 , together with eight independent sources of systematic uncertainties , @xmath75 .",
    "hence , the experimental measurements , @xmath76 are given by @xmath77 where as before , @xmath78 is the theoretical prediction for the observable calculated with the set of parameters @xmath9 .",
    "the @xmath79 and @xmath80 are independent random variables normally distributed with zero average and unit standard deviation .",
    "note that some of the systematic uncertainties given in ref .",
    "@xcite are asymmetric . in those cases",
    "we symmetrized the uncertainty using the average deviation from zero . from eq .",
    "[ eq : xie ] we can construct the experimental covariance matrix @xmath81    we also need to estimate the theoretical uncertainty . in eq .  [",
    "eq : xie ] no theoretical uncertainties were taken into account .",
    "we consider two types of uncertainties : the uncertainty due to the numerical monte carlo integration over the final state particle phase space , @xmath82 , and the renormalization / factorization scale , @xmath83 , uncertainty , @xmath84 .",
    "the theoretical prediction in eq .",
    "[ eq : xie ] must then be replaced by @xmath85 from which we can derive the theoretical covariance matrix @xmath86 here we assume that there is no bin to bin correlation in the mc uncertainty . on the other hand ,",
    "we take the correlation of the scale uncertainty fully into account .",
    "both @xmath87 and @xmath88 are evaluated at the central values of the pdf parameters , assuming that the variation is small .",
    "we evaluate the scale uncertainty in a very straightforward manner . as the central prediction the renormalization and factorization scale",
    "are taken to be equal to half the transverse energy of the leading jet in the event , @xmath89 . to estimate the uncertainty we make another theoretical prediction now choosing as a scale @xmath90 .",
    "the `` one - sigma '' uncertainty is defined as @xmath91 as we will see later in this section the theoretical uncertainties are small compared to the other uncertainties",
    ". therefore this crude estimate suffices for the purposes of this paper . in the future",
    "a more detailed study of the theoretical uncertainty is required .",
    "the scale uncertainty is often associated with the theoretical uncertainty due to the truncation of the perturbative series .",
    "however , it is important to realize this is only a part of the full theoretical uncertainty .    in fig .",
    "[ fig3]@xmath92 we present results for the single inclusive jet cross section as a function of the jet transverse energy .",
    "both data and theoretical predictions are divided by the average prediction of the initial pdf s .",
    "the nlo predictions are calculated using the jetrad prediction  @xcite .",
    "the inner ( outer ) error bar on the experimental points represent the diagonal part of the experimental ( total ) covariance matrix .",
    "the dotted lines represent the initial one - sigma pdf uncertainties .",
    "the solid lines are the theory predictions calculated with the new pdf s ( i.e. , the new probability density distribution ) .",
    "the plot is somewhat misleading because of the large point - to - point correlation of the uncertainties .",
    "the confidence level of 50% is very high , indicating a good agreement between the prediction and the data .",
    "this leads us to the conclusion that the one jet inclusive transverse energy distribution is statistically in agreement with the nlo theoretical expectation based on the initial probability density distribution of the pdf parameters .",
    "no indication of new physics is present .",
    "note that the prediction using the initial pdf differs quite a bit from the more traditional fits such as mrsd0 , see the dashed line in fig .",
    "[ fig3]@xmath92 . having no uncertainties on the traditional",
    "fits it is hard to draw any quantitative conclusion from this observation .",
    "the larger value of the jet cross section calculated using the initial pdf set at high transverse energies compared to mrsd0 was anticipated in ref .",
    "@xcite and can probably be traced back to the larger @xmath93 and @xmath94 quark distribution at the reference scale @xmath2 and moderate @xmath95 .",
    "this difference in turn was partially attributed to the different way of treating target mass and fermi motion corrections .    given the confidence level of 50%",
    "the one jet inclusive data can be included in the fit . using eq .",
    "[ chisqnew ] we calculate for each pdf set @xmath45 the corresponding @xmath96 .",
    "this gives us the 100 weights @xmath66 ( conditional probabilities ) defined in eq .",
    "using eq .",
    "[ eq : newmusig ] , we can calculate the effects of including the cdf data into the fit .",
    "the results are shown in figs .",
    "[ fig3]@xmath92 and  [ fig3]@xmath97 . as can be seen in fig .",
    "[ fig3]@xmath92 the effect is that the central value is pulled closer to the data and the pdf uncertainty is reduced substantially .",
    "two of the fourteen pdf parameters are affected the most .",
    "as expected these are the strong coupling constant @xmath98 and the gluon pdf coefficient @xmath99 , which controls the high @xmath28 behavior ( the gluon pdf is proportional to @xmath100 at the initial scale ) . in fig .",
    "[ fig3]@xmath97 we show the correlation between these two parameters before and after the inclusion of the cdf data .",
    "as can be seen the impact on @xmath99 is very significant .",
    "similarly , the uncertainty on @xmath101 is reduced substantially and the correlation between the two parameters is also changed .",
    "this indicates that the one jet inclusive transverse energy distribution in itself has a major impact on the uncertainty of @xmath101 and the determination of the gluon pdf .",
    "note that we do not address the issue of the parametrization uncertainty .",
    "other choices of how to parameterize the initial pdf s will change the results . to obtain a value and uncertainty of @xmath98 which is on the same footing as the one obtained from @xmath102-colliders",
    ", one needs to address this issue .",
    "[ ryw ]    our second example is the lepton charge asymmetry in @xmath0-boson decay at the tevatron .",
    "as already explained , this observable is important for the reduction of the pdf uncertainties in the @xmath0-boson mass extraction at hadron colliders .",
    "the asymmetry is given by @xmath103 where @xmath104 and @xmath105 are respectively the number of positrons and electrons at the pseudo - rapidity @xmath106 .    in fig .",
    "[ fig : asym]@xmath92 , we show the preliminary cdf data of run  1@xmath97 ( solid points ) for the asymmetry , along with the nlo predictions ( dotted lines ) including the pdf uncertainties , relative to the theory average prediction using the initial pdf s . for the nlo calculations",
    "the dyrad prediction  @xcite was used .",
    "the inner error bars on the experimental points are the statistical uncertainties ; the systematic uncertainties are small and we can safely neglect them .",
    "the outer error bars are the diagonal of the total covariance matrix . in this case",
    ", the theoretical uncertainty is dominated by the phase space monte carlo integration uncertainty ; we took its bin to bin correlation into account .",
    "similar to the one jet inclusive transverse energy case , the scale uncertainty is defined by the difference between the theoretical prediction calculated using two scales , @xmath107 and @xmath108 .    as is clear from fig .",
    "[ fig : asym]@xmath92 , there is a good agreement between the data and the nlo prediction , except for the last experimental point at the highest pseudo - rapidity . the confidence level including the last point is well below our threshold of 0.27% . in order to be able to include the data into the pdf fit we decided to simply exclude this data point from our analysis . without the highest pseudo - rapidity point",
    "we obtain a reasonable confidence level of 4% .",
    "it is not as good as in the single inclusive jet case even though the plots appear to indicate otherwise .",
    "the reason for this is the absence of significant point - to - point correlation for the charge asymmetry uncertainties .",
    "we can now include the lepton charge asymmetry data into the fit by updating the probability density distribution with bayes theorem , as described in the previous section .",
    "in fig .  [",
    "fig : asym]@xmath92 the prediction obtained with the new probability density distribution are shown by the solid lines . as expected , the data are pulling the theory down and reducing the pdf uncertainties .",
    "it is difficult to correlate the change in the asymmetry to a change in a particular pdf parameter . on the other hand",
    ", it is well known that the lepton asymmetry can be approximately related to the following asymmetry of the ratio of up quark ( @xmath94 ) and down quark ( @xmath93 ) distribution function @xmath109 the bjorken-@xmath28 are given by @xmath110 where @xmath111 is the mass of the @xmath0-boson , @xmath112 the center of mass of the collider , and @xmath113 the @xmath0-boson rapidity .",
    "the pdf s were evaluated with the factorization scale equal to @xmath111 .",
    "the ratio @xmath114 is approximately the @xmath0-boson asymmetry and obviously is sensitive to the slope of the @xmath94/@xmath93 ratio .    in fig .",
    "[ ryw]@xmath97 we show the ratio @xmath114 calculated with both the initial and the new probability density distributions .",
    "as can be seen , the change is very similar to the change experienced by the lepton charge asymmetry itself .",
    "the change in @xmath114 can be traced to a simultaneous increase in the anti - up quark distribution and decrease in the anti - down quark distribution at low @xmath28 .",
    "current standard sets of pdf do not include uncertainties .",
    "it is clear that we can not continue to discount them .",
    "already current measurements at the tevatron have highlighted the importance of these uncertainties for the search of physics beyond the standard model .",
    "furthermore , the potential of future hadron colliders to measure @xmath115 and the @xmath0-boson mass is impressive , but can not be disentangled from pdf uncertainties .",
    "the physics at the lhc will also undoubtedly require a good understanding of the pdf uncertainties . on a more general level , if we want to quantitatively test the framework of perturbative qcd over a very large range of parton collision energies the issue of pdf uncertainties can not be sidestepped .    in this paper",
    "we have illustrated a method , based on statistical inference , that can be used to easily propagate uncertainties to new observables , assess the compatibility of new data , and if the latter is good to include the effect of the new data on the pdf without having to redo the whole fit .",
    "the method is versatile and modular : an experiment can be included in or excluded from the new pdf fit without any additional work .",
    "the statistical and systematic uncertainties with the full point - to - point correlation matrix can be included as well as the theoretical uncertainties .",
    "none of the uncertainties are required to be gaussian distributed .",
    "one remaining problem is the uncertainty associated with the choice of parametrization of the input pdf .",
    "this is a difficult problem that does not have a clear answer yet and will require a compromise between the number of parameters and the smoothness of the pdf .",
    "we plan to address this question in another paper",
    ". the next phase would then be to obtain a large number of initial pdf s sets based on theoretical consideration only , in the spirit of the inference method and bayes theorem .",
    "the dis and tevatron data could then be used to constraint the range of these pdf s resulting in a set of pdf s which would include both experimental and theoretical uncertainties .",
    "for our initial pdf parameter probability density distribution we use the results of ref .",
    "there a chi - squared fit was performed to dis data from bcdms  @xcite , nmc  @xcite , h1  @xcite and zeus  @xcite .",
    "both statistical uncertainties and experimental systematic uncertainties with point - to - point correlations were included in the fit , assuming gaussian distributions . however , _ no _ theoretical uncertainties were considered .",
    "it is important to include the correlation of the systematic uncertainties because the latter usually dominate in dis data . simply adding them in quadrature to the statistical uncertainty",
    "would result in a overestimation of the uncertainty .",
    "a standard parametrization at @xmath116 is used with 14 ( = @xmath3 ) parameters : @xmath117 , @xmath118 , @xmath119 , @xmath120 , and @xmath121 are parametrized using the functional form @xmath122 whereas @xmath123 is parametrized as @xmath124 . here",
    "@xmath28 is the bjorken-@xmath28 .",
    "parton number and momentum conservation constraints are imposed .",
    "the full covariance matrix of the parameters , @xmath125 , is extracted at the same time as the value of the parameters that minimize the chi - squared .",
    "the uncertainties on the parameters were assumed to be gaussian , such that the fitted values also correspond to the average values of the parameters , @xmath126 .",
    "the probability density distribution is then given by @xmath127 where @xmath128 is the difference between the total chi - squared of the experimental data used in the fit and the minimum chi - squared ( 1256 for 1061 data points ) with the pdf s fixed by the set of parameters @xmath9 .",
    "the matrix @xmath129 is the inverse of the covariance matrix @xmath125 .",
    "the @xmath130 is the determinant of the covariance matrix .",
    "all the calculations were done in the @xmath131-scheme .    comparison with",
    "mrs and cteq sets showed a good overall agreement with a few exceptions .",
    "one example is the difference in the gluon distribution function at large values of @xmath28 .",
    "the cteq and mrs distribution are somewhat above the result of ref .",
    "this difference was attributed to the fact that prompt photon data were included in the cteq and mrs fits .",
    "note that the direct photon data have large scale uncertainty , and it might be misleading to include them in a fit without taking the theoretical uncertainty into account . also , it is important to keep in mind that it is misleading to compare specific pdf s , as the correlations between different pdf parameters are large .",
    "99 h.  l.  lai et al . , phys .",
    "d55 ( 1997 ) 1280 ; + a.  d.  martin et al . , dtp-96 - 102 , dec 1996 , hep - ph/9612449 . the cdf collaboration , f.   abe et al . ,",
    "lett .  77 ( 1996 ) 438 .",
    "j.  huston et al . , phys .",
    "77 ( 1996 ) 444 . the cdf ii collaboration , f.  abe et al .",
    ", the cdf ii detector technical design report , fermilab - pub-96/390-e .",
    "r.  m.  barnett et al .",
    "d54 , 1 ( 1996 ) .",
    "numerical recipes , w.  h.  press et al . , cambridge university press .",
    "the cdf collaboration , phys .",
    "lett .  74 ( 1995 ) 850 ; + r.  g.  wagner , for the cdf collaboration , published proceedings 5th international conference on physics beyond the standard model , balholm , norway , april 29-may 4 , 1997 .",
    "s.  alekhin , ifve-96 - 79 ( sep 1996 ) , hep - ph/9611213 .",
    "the program was obtained from the cteq collaboration www - site `` http://www.phys.psu.edu/@xmath132cteq/ '' .",
    "w.  t.  giele , e.  w.  n.  glover and d.  a.  kosower , nucl .",
    "* b403 * ( 1993 ) 633 .",
    "the bcdms collaboration , a.  c.  benvenuti et al .",
    "223b ( 1989 ) 485 ; phys .",
    "lett 237b ( 1990 ) 592 .",
    "the nm collaboration , m.  arneodo et al .",
    "b483 ( 1997 ) 3 .",
    "the h1 collaboration , s.  aid et al .",
    "470b ( 1996 ) 3 . the zeus collaboration , m.  derrick et al . ,",
    "c72 ( 1996 ) 399 ."
  ],
  "abstract_text": [
    "<S> .1 in    standard parton distribution function sets do not have rigorously quantified uncertainties . in recent years </S>",
    "<S> it has become apparent that these uncertainties play an important role in the interpretation of hadron collider data . in this paper , using the framework of statistical inference , we illustrate a technique that can be used to efficiently propagate the uncertainties to new observables , assess the compatibility of new data with an initial fit , and , in case the compatibility is good , include the new data in the fit </S>",
    "<S> .    # 1 # 2 # 3 _ phys . </S>",
    "<S> lett . _ * # 1 * ( # 3 ) # 2 # 1 # 2 # 3 _ nucl . </S>",
    "<S> phys . _ * # 1 * ( # 3 ) # 2 # 1 # 2 # 3 _ z. phys . _ * # 1 * ( # 3 ) # 2 # 1 # 2 # 3 _ phys . </S>",
    "<S> rev . </S>",
    "<S> lett . _ * # 1 * ( # 3 ) # 2 # 1 # 2 # 3 _ phys . </S>",
    "<S> rev . _ </S>",
    "<S> * # 1 * ( # 3 ) # 2 # 1 # 2 # 3 _ mod . </S>",
    "<S> phys . </S>",
    "<S> lett . _ * # 1 * ( # 3 ) # 2 # 1 # 2 # 3 _ rev .  </S>",
    "<S> mod . </S>",
    "<S> phys . _ * # 1 * ( # 3 ) # 2    = cmbx10 = cmr10 = cmti10 = cmbx10 scaled1 = cmr10 scaled1 = cmti10 scaled1 = cmbx9 = cmr9 = cmti9 = cmbx8 = cmr8 = cmti8 = cmr7    -0.5 cm 0.1 cm    implications of hadron collider observables .4 cm on parton distribution function uncertainties 1.4 cm    walter t. giele and stephane keller + 0.2 cm    _ fermilab , ms 106 + batavia , il 60510 , usa _ </S>"
  ]
}