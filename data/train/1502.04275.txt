{
  "article_text": [
    "in the past two years , convolutional neural networks ( cnns ) have revolutionized computer vision .",
    "they have been applied to a variety of general vision problems , such as recognition  @xcite , segmentation  @xcite , stereo  @xcite , flow  @xcite , and even text - from - image generation  @xcite , consistently outperforming past work .",
    "this is mainly due to their high generalization power achieved by learning complex , non - linear dependencies across millions of labelled examples .",
    "it has recently been shown that increasing the depth of the network increases the performance by an additional impressive margin on the imagenet challenge  @xcite .",
    "it remains to be seen whether recognition can be solved by simply pushing the limits of computation ( the size of the networks ) and increasing the amount of the training data .",
    "we believe that the main challenge in the next few years will be to design computationally simpler and more efficient models that can achieve a similar or better performance compared to the very deep networks .        for object detection ,",
    "a successful approach has been to generate a large pool of candidate boxes  @xcite and classify them using cnns  @xcite .",
    "the quality of such a detector thus largely depends on the quality of the object hypotheses .",
    "interestingly , however , using much better proposals obtained via a high - end bottom - up segmentation approach  @xcite has resulted only in small improvements in accuracy .    in this paper , we show how to exploit a small number of accurate object segment proposals in order to significantly improve object detection performance .",
    "we frame the detection problem as inference in a markov random field as in figure  [ figure : intro ] , in which each detection hypothesis scores object appearance as well as contextual information using convolutional neural networks .",
    "each hypothesis can choose and score a segment out of a small pool of accurate object segmentation proposals .",
    "this enables our approach to place more accurate object bounding boxes in parts of the image where an object segmentation hypothesis  @xcite exists or where strong contextual cues are available .",
    "we additionally show that a significant performance boost can be obtained by a sequential approach , where the network iterates between adjusting its spatial scope ( the bounding box ) and classifying its content .",
    "this strategy reduces the dependency on the initial candidate boxes obtained by  @xcite and enables our approach to recover from the potentially bad initial localization .",
    "we show that our model , called segdeepm , outperforms the baseline r - cnn  @xcite approach by @xmath2 with almost no extra computational cost .",
    "we get a total of @xmath3 improvement by incorporating contextual information at the cost of doubling the running time of the method . on pascal voc 2010 test",
    ", our method achieves @xmath0 improvement over r - cnn and @xmath4 over the current state - of - the - art .",
    "object detection and semantic segmentation are one of the core challenges of computer vision .",
    "object detection aims at placing a tight bounding box around each ground - truth object of a particular class , while semantic segmentation targets to assign a label to each pixel in a given image .",
    "these two tasks , although typically treated separately , are closely related : knowing where e.g. a car is should help us to carve it out in the image . on the other hand , knowing",
    "the car segmentation in an image should help us detect specific instances more accurately .",
    "some recent approaches have shown that using cues from one task can greatly benefit the other  @xcite , whereby holistic models typically result in additional boosts  @xcite .",
    "fidler proposed segdpm , which leveraged state - of - the - art segmentation techniques @xcite to score detections better , which boosted the mean average precision ( map ) over the original object detector  @xcite by @xmath5 on the challenging pascal voc 2010 dataset  @xcite .",
    "this was a very significant improvement at the time where the state - of - the - art performance was at a saturation point .",
    "the success of segdpm  @xcite has given us important insight in exploiting segmentation cues in object detection systems , but its impact fades with the rise of the deep learning methods  @xcite that can efficiently pre - train with millions of examples . in this paper , we build on the r - cnn framework  @xcite and show how to exploit segmentation in a very simple and efficient way in order to gain a large improvement over the original approach .",
    "our model scores each bounding box candidate  @xcite via the cnn features as well as our segmentation features . similarly to segdpm , our model allows each bounding box candidate to pick a segment out of a pool of segment and score compatibility between the box and the segment .",
    "unlike segdpm , which extracts segmentation features from the final output of semantic segmentation , our model utilizes multiple overlapped object - like segments generated by cpmc  @xcite and their potentials computed by second - order - pooling  @xcite to incorporate per - instance segmentation information .",
    "moreover , given the segments and their corresponding potentials , our model has the same computational complexity as the original r - cnn  @xcite .",
    "we coin the acronym segdeepm for our approach .",
    "our second contribution deals with one of the most common mistakes of the r - cnn approach : duplicate detections of the same object . due to how r - cnn are trained , yes - no depending on whether a box overlaps ground - truth more than 50% or not , the final network produces similar responses across several region proposals intersecting the same object .",
    "while some of these problems are dealt with via nms , our analysis shows a high drop in performance due to this issue .",
    "we propose an effective way of dealing with this problem by `` looking outside of the box '' .",
    "this simple concept gives the network the opportunity to re - adjust its scores by exploiting loose contextual information around each region proposal .",
    "meanwhile , a brief analysis on rcnn and segrcnn model reveals that those models mainly fail in duplicated detections on the same object , as well as false - negatives , especially for small objects .",
    "we address this issue by introducing context cues in our model .",
    "although the role of context in object detection task has been widely recognized in vision community @xcite , incorporating such information usually requires elaborate , hand - made model which is hard to train@xcite .",
    "however , experiments show that the most advanced object detector  our visual system spend similar time in recognizing low - resolution images with context information @xcite , which indicates human generally perceives context information with little extra effort",
    ". motivated by this fact , our segrcnn model adopts a concise yet effective way to utilize context cues by `` looking out of the box '' .",
    "our method adopts another cnn model that looks around the object region and combines its response with that of segrcnn .",
    "we show that our expanded network could significantly improve detection accuracy and is particular effective for small objects .",
    "in the past years , a variety of segmentation algorithms that exploit object detections as a top - down cue have been explored .",
    "the standard approach has been to use detection features as unary potentials in an mrf  @xcite , or as candidate bounding boxes for holistic mrfs  @xcite . in  @xcite ,",
    "segmentation within the detection boxes has been performed using a grabcut method . in  @xcite ,",
    "object segmentations are found by aligning the masks obtained from poselets  @xcite .",
    "there have been a few approaches to use segmentation to improve object detection .",
    "@xcite cast votes for the object s location by using a hough transform with a set of regions .",
    "@xcite uses dpm to find a rough object location and refines it according to color information and occlusion boundaries . in  @xcite ,",
    "segmentation is used to mask - out the background inside the detection , resulting in improved performance .",
    "segmentation and detection has also been addressed in a joint formulation in  @xcite by combining shape information obtained via dpm parts as well as color and boundary cues .",
    "our work is inspired by the success of segdpm  @xcite . by augmenting the dpm detector  @xcite with very simple segmentation features that can be computed in constant time ,",
    "segdpm improved the detection performance by @xmath6 on the challenging pascal voc dataset .",
    "the approach used segments computed from the final segmentation output of cpmc  @xcite in order to place accurate boxes in parts of the image where segmentation for the object class of interest was available . this idea was subsequently exploited in  @xcite by augmenting the dpm with an additional set of deformable context `` parts '' which scored contextual segmentation features around the object . in  @xcite ,",
    "the segdpm detector  @xcite was augmented with part visibility reasoning , achieving state - of - the - art results for detection of articulated classes . in  @xcite ,",
    "the authors extended segdpm to incorporate segmentation compatibility also at the part level .    in this paper , we build on r - cnn framework  @xcite and transfer the core ideas of segdpm .",
    "we use appearance features from  @xcite , a rich contextual appearance description around the object , and a mrf model that is able to exploit segmentation in a more efficient way than segdpm .    for context , most approaches for object detection either serves as post - processing @xcite or based on semantic segmentation results around bounding box region @xcite .",
    "we argue that context information should be classified into local - context ( the regions around target object ) , spatial - context ( relationship between detected objects in the same image ) and out - of - image context ( image tags or descriptions ) . in this paper",
    ", we mainly focus on local - context and build our context features specifically for it .",
    "in this paper , we are interested in introducing semantic segmentation and context information to boost object detection .",
    "specifically , we utilize region - based bottom - up segmentation followed by class - specific regressor to score each regions , and combine them with both local and context cues . to achieve this goal , we design a unified model that fuses a powerful appearance model , a compact segmentation model and a concise context model .",
    "we refer to the efficient segmentation feature in segdpm @xcite and design our own variations , which could better capture the information in segments .",
    "meanwhile , we also leverage the power of cnns to encode context information in our model .",
    "the goal of our approach is to efficiently exploit segmentation and contextual cues in order to facilitate object detection . following the r - cnn setup ,",
    "we compute the selective search boxes  @xcite yielding approximately 2000 object candidates per image . for each box",
    "we extract the last feature layer of the cnn network  @xcite , that is fine - tuned on the pascal dataset as proposed in  @xcite . we obtain object segment proposals via the cpmc approach  @xcite ,",
    "although our approach is independent of this choice .",
    "following  @xcite , we take the top @xmath7 proposals given by an object - independent ranker , and train class - specific classifiers for all classes of interest by the second - order pooling method o2p  @xcite .",
    "we remove all segments that have less than @xmath8 pixels .",
    "our method will make use of these segments along with their class - specific scores .",
    "this is slightly different than segdpm which takes only 1 or 2 segments carved out from the final o2p s pixel - level labeling of the image .    in the remainder of this section",
    "we first define our model and describe its segmentation and contextual features .",
    "we next discuss inference and learning .",
    "finally , we detail a sequential inference scheme that iterates between correcting the input bounding boxes and scoring them with our model .",
    "we define our model as a markov random field with random variables that reason about detection boxes , object segments , and context .",
    "similar to  @xcite , we define @xmath9 as a random variable denoting the location and scale of a candidate bounding box in the image .",
    "we also define @xmath10 to be a set of random variables , one for each class , i.e. @xmath11 .",
    "each random variable @xmath12 represents an index into the set of all candidate segments . here",
    "@xmath13 is the total number of object classes of interest and @xmath14 is the total number of segments in image @xmath15 .",
    "the random variable @xmath16 allows each candidate detection box to _ choose _ a segment for each class and score its confidence according to the agreement with the segment .",
    "the idea is to ( 1 ) boost the confidence of boxes that are well aligned with a high scoring object region proposal for the class of interest , and ( 2 ) adjust its score based on the proximity and confidence of region proposals for other classes , serving as context for the model .",
    "this is different from segdpm that only had a single random variable @xmath17 which selected a segment belonging to the detector s class .",
    "it is also different from  @xcite in that the model chooses contextual segments , and does not score context in a fixed segmentation window .",
    "note that @xmath18 indicates that no segment is selected for class @xmath19 .",
    "this means that either no segment for a class of interest is in the vicinity of the detection hypothesis , or that none of the regions corresponding to the contextual class @xmath19 help classification of the current box .",
    "we define the energy of a configuration as follows : @xmath20 where @xmath21 , @xmath22 , and @xmath23 are the candidate s appearance , segmentation , and contextual potential functions ( features ) , respectively .",
    "we describe the potentials in detail below .",
    "* appearance : * to extract the appearance features we follow  @xcite . the image in each candidate detection s box",
    "is warped to a fixed size @xmath24 .",
    "we run the image through the cnn  @xcite trained on the imagenet dataset and fine - tuned on pascal s data  @xcite . as our appearance feature",
    "@xmath25 we use the @xmath26-dimensional feature extracted from the @xmath27 layer .    * segmentation : * similar to  @xcite , our segmentation features attempt to capture the agreement between the candidate s bounding box and a particular segment .",
    "the features are complementary in nature , and , when combined within the model , aim at placing the box tightly around each segment .",
    "we emphasize that the weights for each feature will be learned , thus allowing the model to adjust the importance of each feature s contribution to the joint energy .",
    "we use slightly more complex features tailored to exploit a much larger set of segments than  @xcite .",
    "in particular , we use a grid feature that aims to capture a loose geometric arrangement of the segment inside the candidate s box .",
    "we also incorporate class information , where the model is allowed to choose a different segment for each class , depending on the contextual information contained in a segment with respect to the class of the detector .",
    "we use multiple segmentation features , one for each class , thus our segmentation term decomposes : @xmath28    specifically , we consider the following features :    * segmentgrid - in : * let @xmath29 denote the binary mask of the segment chosen by @xmath16 . for a particular candidate box  @xmath9 , we crop the segment s mask via the bounding box of @xmath9 and compute the segmentgrid - in feature on a @xmath30 grid @xmath31 placed over the cropped mask .",
    "the @xmath32 dimension represents the percentage of segment s pixels inside the @xmath32 block , relative to the number of all pixels in @xmath29 .",
    "@xmath33 where @xmath34 is the @xmath32 block of pixels in grid @xmath31 , and @xmath35 indexes the segment s mask in pixel @xmath36 .",
    "that is , @xmath37 when pixel @xmath36 is part of the segment and @xmath38 otherwise .",
    "for @xmath19 matching the detector s class , this feature will attempt to place a box slightly bigger than the segment while at the same time trying to localize it such that the spatial distribution of pixels within each grid matches the class expected shape .",
    "for @xmath19 other than the detector s class , this feature will try to place the box such that it intersects as little as possible with the segments of other classes .",
    "the dimensionality of this feature is @xmath39 .",
    "* segment - out : * this feature follows  @xcite , and computes the percentage of segment pixels outside the candidate box . unlike the segmentgrid - in",
    ", this feature computes a single value for each segment / bounding box pair .",
    "@xmath40 where @xmath41 is the bounding box corresponding to @xmath9 .",
    "the aim of this feature is to place boxes that are smaller compared to the segments , which , in combination with segmentgrid - in , achieves a tight fit around the segments .    *",
    "backgroundgrid - in : * this feature is also computed with a @xmath30 grid @xmath31 for each bounding box @xmath9 .",
    "we compute the percentage of pixels in each grid cell that are * not * part of the segment : @xmath42 with @xmath43 the area of the largest segment for the image .",
    "* background - out : * this scalar feature measures the @xmath44 of segment s background outside of the candidate s box : @xmath45    * overlap : * similarly to  @xcite , we use another feature to measure the alignment of the candidate s box and the segment @xmath46 .",
    "it is computed as the intersection - over - union ( iou ) between the box or @xmath9 and a tightly fit bounding box around the segment @xmath46 .",
    "@xmath47 where @xmath48 is tight box around @xmath49 , and @xmath50 a bias term which we set to @xmath51 in our experiments .",
    "* segmentclass : * since we are dealing with many segments per image , we add an additional feature to our model .",
    "we train the o2p  @xcite rankers for each class which uses several region - aware features as input into our segmentation features .",
    "each ranker is trained to predict the iou overlap of the given segment with the ground - truth object s segment .",
    "the output of all the class - specific rankers defines the following feature : @xmath52 where @xmath53 is the score of class @xmath19 for segment @xmath46 .",
    "segmentgrid - in , segment - out , backgroundgrid - in , and background - out can be efficiently computed via integral images  @xcite .",
    "note that  @xcite s features are a special case of these features with a grid size @xmath54 .",
    "overlap and segment features can also be quickly computed using matrix operations .    *",
    "context : * cnns are typically trained for the task of image classification where in most cases an input image is much larger than the object . this means that part of their success may be due to learning complex dependencies between the objects and their contextual information ( sky for aeroplane , road for car and bus ) .",
    "however , the appearance features that we use are only computed based on the candidate s box , thus hardly capturing useful information from the scene .",
    "we thus add an additional feature that looks at a bigger scope than the candidate s box .",
    "in particular , we enlarge each input candidate box by a fixed percentage @xmath55 along its horizontal and vertical direction . for big boxes , or those close to the image boundary , we clip the enlarged region to be fully inside the image .",
    "we keep the object labels for each expanded box the same as that for the original boxes , even if the expanded box now encloses objects of other classes .",
    "we then warp the image in each enlarged box to @xmath56 and fine - tune the original imagenet - trained cnn using these images and labels .",
    "we call the fine - tuned network the _ expanded cnn_. for our contextual features @xmath57 we extract the @xmath27 layer features of the expanded cnn by running the warped image in the enlarged window through the network .",
    "in the inference stage of our model , we score each candidate box @xmath9 as follows : @xmath58 observe that the first two terms in eq .",
    "[ eqn : inference ] can be computed efficiently by matrix multiplication , and the only part that depends on @xmath10 is its last term .",
    "although there could be exponential number of candidates for @xmath10 , we can greedily search each dimension of @xmath10 and find the best segment @xmath29 w.r.t .",
    "model parameters @xmath59 for each class @xmath19 .",
    "since our segmentation features do not depend on the pairwise relationships in @xmath10 , this greedy approach is guaranteed to find the global maximum of @xmath60 .",
    "finally , we sum the three terms to obtain the score of each bounding box location @xmath9 .",
    "[ cols=\"<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<,<\",options=\"header \" , ]",
    "we evaluate our method on the main object detection benchmark pascal voc .",
    "we provide a details ablative study of different potentials and choices in our model in subsec .",
    "[ sec : ablative ] . in subsec .",
    "[ sec : test ] we test our method on pascal s held - out test set and compare it to the current state - of - the - art methods .",
    "we first evaluate our detection performance on @xmath61 set of the pascal voc 2010 detection dataset .",
    "we train all methods on the @xmath62 subset and evaluate the detection performance using the standard pascal criterion .",
    "we provide a detailed performance analysis of each proposed potential function , which we denote with @xmath63 ( segmentation ) and expanded network @xmath64 ( the contextual network ) in table  [ table : val ] .",
    "we also compare our iterative bounding box regression approach , referred to as @xmath65 , to the standard bounding box regression , referred to as @xmath66 ,  @xcite .",
    "r - cnn  @xcite serves as our main baseline . to better justify our model",
    ", we provide an additional baseline , where we simply augment the set of selective search boxes used originally by the r - cnn with the cpmc proposal set .",
    "we call this approach rcnn+cpmc in the table ( second row ) . to contrast our model with segdpm , which originally uses segmentation features in a dpm - style formulation , we simplify our model to use their exact features . instead of hog , however , we use cnns for a fair comparison",
    ". we also use their approach to generate segments , by finding connected components in the final output of cpmc - o2p segmentation  @xcite .",
    "this approach is referred to as segdpm+cnn ( third row in table  [ table : val ] ) .",
    "observe that using a small set of additional segments brings a @xmath67 improvement for rcnn+cpmc over the r - cnn baseline .",
    "using a segdpm+cnn approach yields a more significant improvement of @xmath68 . with our segmentation",
    "features we get an additional @xmath69 increase over segdpm+cnn , thus justifying our feature set .",
    "interestingly , this @xmath70 boost over r - cnn is achieved by our simple segmentation features which require only @xmath71 additional parameters .",
    "the table also shows a steady improvement of each additional added potential / step , with the highest contribution achieved by the expanded contextual network .    ) .",
    "@xmath72 indicates no segments are used . *",
    "( right ) * box expansion ratio @xmath55 .",
    "@xmath73 disables context and @xmath74 indicates full image context . only contextual features used in this experiment . both plots for pascal voc 2010 @xmath75.,title=\"fig:\",scaledwidth=24.2% ] ) .",
    "@xmath72 indicates no segments are used . *",
    "( right ) * box expansion ratio @xmath55 .",
    "@xmath73 disables context and @xmath74 indicates full image context . only contextual features used in this experiment . both plots for pascal voc 2010 @xmath75.,title=\"fig:\",scaledwidth=24.2% ]    our full approach , in the setting without any post - processing ,",
    "outperforms the strong baseline detector  @xcite by @xmath76 , a significant improvement .",
    "after post - processing , the improvement is slightly lower , achieving a @xmath77 performance gain .",
    "we note that we improve over the baseline in 19 out of 20 object classes .",
    "the pr curves for the first 10 classes are shown in figure  [ figure : pr ] and the qualitative results are shown in figure  [ figure : qual ] . a detailed error analysis as proposed in  @xcite of r - cnn and our detector",
    "is shown in figure  [ fig : error ] .    [ [ performance - vs .- grid - size - and - of - segments . ] ] performance vs. grid size and # of segments .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we evaluate the influence of different grid sizes and different number of cpmc segments per image .",
    "for each cpmc segment we compute the best o2p ranking score across all classes , and choose the top @xmath78 segments according to these scores .",
    "figure  [ ap_vs_numseg ] , left panel , shows that the highest performance gain is due to the few best scoring segments .",
    "the differences are minor across different values of @xmath79 and @xmath78 .",
    "interestingly , the model performs worse with more segments and a coarse grid , as additional low - quality segments add noise and make l - svm training more difficult .",
    "when using a finer grid , the performance peaks when more segments are use , and achieves an overall improvement over a single - cell grid .",
    "figure  [ ap_vs_numseg ] , left panel , shows that the highest performance gain is due to the best few scoring segments .",
    "segdeepm performs best with @xmath80 .",
    "however , the differences are minor across different values of @xmath78 .",
    "figure  [ ap_vs_numseg ] also indicates that having more segments per image does not necessarily result in higher accuracy , as additional low - quality segments add noise and make l - svm training more difficult .",
    "[ [ performance - expansion - ratio . ] ] performance expansion ratio .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + +    we evaluate the influence of the box expansion ratio @xmath55 used in our contextual model .",
    "the results for varying values of @xmath55 are illustrated in figure  [ ap_vs_numseg ] , right panel .",
    "note that even a small expansion ratio ( @xmath81 in each direction ) can boost the detection performance by a significant @xmath82 , and the performance reaches its peak at @xmath83 .",
    "this indicates that richer contextual information leads to a better object recognition .",
    "notice also that the detection performance decreases beyond @xmath83 .",
    "this is most likely due to the fact that most contextual boxes obtained this way will cover most or even the full image , and thus the positive and negative training instances in the same image will share the identical contextual features .",
    "this confuses our classifier and results in a performance loss . if we take the full image as context , the gain is less than @xmath67 .    [",
    "[ iterative - bounding - box - prediction . ] ] iterative bounding box prediction .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we next study the effect of iterative bounding box prediction .",
    "we report a @xmath4 gain over the original r - cnn by starting with our set of re - localized boxes ( one iteration ) .",
    "note that re - localization in the first iteration only affects @xmath84 of boxes ( only @xmath84 of boxes change more than @xmath85 from the original set , thus feature re - computation only affects half of the boxes ) .",
    "this performance gain persists when combined with our full model .",
    "if we apply another bounding box prediction as a post - processing step , this approach still obtains a @xmath86 improvement over r - cnn with bounding box prediction . in this iteration",
    ", re - localization affects @xmath87 of boxes .",
    "we have noticed that the performance saturates after two iterations .",
    "the second iteration improves map by only a small margin ( about @xmath88 ) .",
    "the interesting side result is that , the mean average best overlap ( mabo ) measure used by bottom - up proposal generation techniques  @xcite to benchmark their proposals , remains exactly the same ( @xmath89 ) with or without our bounding box prediction , but has a significant impact on the detection performance .",
    "this may indicate that mabo is not the best or at least not the only indicator of a good bottom - up grouping technique .",
    "0.24     0.24     0.24     0.24     , using only the contextual features box expansion ratio @xmath55 . @xmath73 disables context and @xmath74 indicates full image context.,scaledwidth=35.0% ]    [ [ missing - annotations . ] ] missing annotations .",
    "+ + + + + + + + + + + + + + + + + + + +    an interesting issue arises when analyzing the top false - positives of our segdeepm .",
    "we have noticed that a non - neglible number of false - positives are due to missing annotations in pascal s ground - truth .",
    "some examples are shown in figure  [ figure : missed_dets ] .",
    "these missed annotations are mostly due to small objects ( figure  [ figure : missed_dets1 ] ,  [ figure : missed_dets3 ] ) , ambiguous definition of an `` object '' ( figure  [ figure : missed_dets2 ] ) , and labelers mistakes ( figure  [ figure : missed_dets4 ] ) .",
    "while missing annotations were not an issue a few years ago when performance was at @xmath90 , it is becoming a problem now , indicating that perhaps a re - annotation is needed .",
    "we evaluate our approach on the pascal voc 2010 @xmath91 subset in table  [ table : test ] . for this experiment we trained our segdeepm model , as well as its potentials ( the cpmc class regressor ) on the pascal voc @xmath92 subset using the best parameters tuned on the @xmath62/@xmath75 split .",
    "we only submitted one result to the evaluation server , thus no tuning on the test set was involved .",
    "table  [ table : test ] shows results of our full segdeepm ( including all post - processing steps ) .",
    "we achieve a @xmath0 improvement over r - cnn with a 7-layer network , and a @xmath4 over the best reported method using a 7-layer network .",
    "notice that the best results on the current leader board are achieved by the recently released 16-layer network  @xcite .",
    "this network has @xmath93 million parameters , compared to @xmath94 million parameters used in our network .",
    "our approach , with only a few additional parameters , scores rather high relative to the much larger network .",
    "our result is `` only '' @xmath95 lower than the very deep state - of - the - art .",
    "we also run our method using a recently released 16-layer oxfordnet  @xcite .",
    "the results on @xmath62/@xmath75 and @xmath92/@xmath91 are shown in table  [ table : val_16 ] and table  [ table : test ] respectively . on the @xmath91 set",
    ", our segdeepm achieves @xmath96 mean ap and outperforms others in @xmath97 out of @xmath97 object classes .    [",
    "[ performance - on - pascal - voc-2012 . ] ] performance on pascal voc 2012 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we also test our full segdeepm model on pascal voc 2012 .",
    "we use the parameters tuned on the pascal voc 2010 @xmath62/@xmath75 split .",
    "the result are reported and compared to the current state - of - the - art in table  [ table : val2012 ] .",
    "0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210     0.210",
    "we proposed a mrf model that scores appearance as well as context for each detection , and allows each candidate box to select a segment and score the agreement between them .",
    "we additionally proposed a sequential localization scheme , where we iterate between scoring our model and re - positioning the box ( changing the spatial scope of the input to the model ) .",
    "we demonstrated that our approach achieves a significant boost over the rcnn baseline , @xmath0 on pascal voc 2010 test in the 7-layer setting and @xmath98 in the 16-layer setting .",
    "the final result places segdeepm at the top of the current pascal s leaderboard ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose an approach that exploits object segmentation in order to improve the accuracy of object detection . </S>",
    "<S> we frame the problem as inference in a markov random field , in which each detection hypothesis scores object appearance as well as contextual information using convolutional neural networks , and allows the hypothesis to choose and score a segment out of a large pool of accurate object segmentation proposals . </S>",
    "<S> this enables the detector to incorporate additional evidence when it is available and thus results in more accurate detections . </S>",
    "<S> our experiments show an improvement of @xmath0 in map over the r - cnn baseline on pascal voc 2010 , and @xmath1 over the current state - of - the - art , demonstrating the power of our approach . </S>"
  ]
}