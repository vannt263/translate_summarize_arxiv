{
  "article_text": [
    "scientific investigation represents an important source of big data . science generate massive amounts of data through high - rate measurements of physical conditions , environmental and astronomical observations , and high - precision simulations of physical phenomena .",
    "while effectively storing the data is a challenge in itself , the main problem scientists face is how to efficiently process data in order to obtain novel insights and gain knowledge . considering the plethora of application - specific solutions available in the scientific data processing landscape , selecting the optimal solution for a given problem is a challenging task .",
    "the lack of standardized benchmarks that allow for a principled evaluation of the available alternatives makes the selection process even more difficult .",
    "the _ standard science dbms benchmark ( ss - db ) _",
    "@xcite is a recent attempt to create a general benchmark for the evaluation of scientific data processing systems .",
    "similar to other popular benchmarks , e.g. , the tpc benchmark suite  @xcite , ss - db is modeled after a real application workload based on a complete workflow for processing astronomical images .",
    "nonetheless , the benchmark operations are representative for a large class of scientific data manipulations . unlike the sloan digital sky survey  @xcite which is targeted at a specific aspect in the scientific processing pipeline",
    ", the ss - db benchmark encompasses a full spectrum of operations over raw and derived data .",
    "while this is an important step toward generality , it also introduces some serious problems . the uttermost limitation which hinders a broader benchmark implementation is that operations are expressed in plain language .",
    "there is no formal representation for the benchmark operations .",
    "the lack of a generally accepted formalism to represent multi - dimensional array operations  the main component of the benchmark  is a valid argument in this respect .",
    "the immediate effect is nevertheless negative  we are aware of only two implementations of the benchmark , both presented in  @xcite  since lack of formalization makes impossible the definition of reference implementations .",
    "other factors that drive the community away are the original results published in  @xcite and the evolving state of scidb  @xcite  the reference system for the benchmark .",
    "the original benchmark results compare scidb to a relational - based implementation on top of mysql database .",
    "the difference between the two systems is enormous  1 to 3 orders of magnitude  in favor of scidb , mostly due to architectural differences and the inefficient mapping of arrays on top of relations in mysql .",
    "the extraordinary scidb performance discourages others from implementing the benchmark .",
    "moreover , scidb is only a prototype suffering considerable modifications from one version to another .",
    "these propagate to frequent modifications to the scidb implementation of the benchmark resulting in frequent updates to the reference benchmark results .",
    "as illustrated by the ss - db benchmark , scientific data have dual structure .",
    "raw data are ordered multi - dimensional arrays while derived data are best represented as unordered relations . at the same time",
    ", scientific data processing requires complex operations over arrays and relations .",
    "these operations can not be expressed using only standard linear and relational algebra operators , respectively .",
    "existing scientific data processing systems address only a subset of these requirements .",
    "they are typically designed for a single data model , e.g. , multi - dimensional arrays in scidb , or they can handle complex processing only at the application level .",
    "_ extascid ( extensible system for analyzing scientific data ) _ on the other hand is a complete and extensible system for scientific data processing .",
    "it supports natively both arrays as well as relational data .",
    "complex processing is handled by a metaoperator that can execute any user code .",
    "extascid provides unlimited extensibility by making the execution of arbitrary user code a central part of its design through the well - established user - defined aggregate ( uda ) mechanism . as a result",
    ", extascid supports in - database processing of full scientific workflows over both raw and derived data . given all these desirable features provided in extascid and the generality of the ss - db benchmark , it is natural to ask what is the performance of extascid on the ss - db benchmark",
    "can all the complex benchmark operations be executed inside extascid without moving data in the application layer ? and how does the performance compare to scidb ?    in this paper",
    ", we address the aforementioned shortcomings of the ss - db benchmark and answer the questions on the generality and performance of extascid . our end goal is to propose a sound formal representation for the benchmark operations together with a reference extascid implementation and reference results . on one hand , this strengthens dramatically the relevance of the benchmark and enforces its position as the reference benchmark for scientific data processing . given that no alternatives exist , a broad acceptance of the ss - db benchmark fills an important void in the evaluation of a large class of big data applications . on the other hand",
    ", the extascid implementation of the benchmark provides another reference point in the evaluation of scientific data processing systems .",
    "the results prove that the integrated extascid architecture supporting natively both arrays and relations is more suited for complex scientific processing over raw and derived data requiring a high degree of extensibility . to this end",
    ", our contributions can be summarized as follows :    we give a formal representation of the ss - db benchmark in terms of arrayql algebra operators  @xcite .",
    "we provide statements for the benchmark queries in the arrayql  @xcite and sciql  @xcite query languages .",
    "these are the first formal representations of the ss - db benchmark .",
    "they can be used as reference for implementation in other systems .",
    "we present the design and implementation of extascid  a novel system for scientific data processing .",
    "extascid is complete in providing native support both for array and relational data and extensible in executing any user code inside the system by the means of a configurable metaoperator .",
    "we provide a reference ss - db implementation in extascid starting from the formal representation of the benchmark in arrayql algebra .",
    "we present results obtained by executing the ss - db benchmark in extascid .",
    "these are only the third reported results in the short history of the benchmark .",
    "when compared to the scidb reference results , extascid provides an order of magnitude improvement at data loading , extracting derived data , and operations over derived data .",
    "this is impressive considering the initial performance gap between scidb and other scientific data processing systems .",
    "the rest of the paper is organized as follows .",
    "section  [ sec : query - lang ] presents array algebra formalisms and array query languages used to represent the ss - db benchmark operations which are described in detail in section  [ sec : ssdb ] .",
    "the extascid design and implementation are introduced in section  [ sec : extascid ] . the ss - db implementation in extascid starting from the formal array algebra representation",
    "is given in section  [ sec : bench - implement ] while the benchmark results and the comparison with scidb are presented in section  [ sec : results ] .",
    "related work is presented in section  [ sec : rel - work ] .",
    "we conclude in section  [ sec : conclusions ] .",
    "in order to analyze the ss - db benchmark specification , we have to represent the benchmark operations in a formal query language . while relational algebra and sql are standard formalisms for unordered relational data , there is no such algebra or query language commonly accepted for ordered array data . as a result",
    ", we settle for arrayql algebra  @xcite and arrayql  @xcite as our array algebra and query language , respectively .",
    "there are two reasons for our choice .",
    "first , these two formalisms are the most recent proposed in the literature . and second , they are part of the scidb ecosystem  @xcite , similar to ss - db .",
    "we discuss alternative array algebra formulations and query languages in the related work .",
    "arrays are formalized as 3-tuples of the form ` ( box , valid , content ) ` , where ` box ` represents the domain of the array with fixed bounds on all dimensions , ` valid ` is a boolean map indicating which cells have valid values , and ` content ` is a function providing the values for the array cells .",
    "this is the first algebra that represents cell validity explicitly .",
    "the benefit is that both dense and sparse arrays can be formalized within the same algebra constructs .    given the representation of an array as a 3-tuple , a new array is created by each operator , with a corresponding new 3-tuple .",
    "operators define mappings between the original 3-tuple components and the new components . without going into details , we present the most important operators defined in arrayql algebra in the following :    ` shift ` array origin to a new position by changing the domain of the array components accordingly .",
    "it is useful when moving between coordinate systems .    `",
    "rebox ` changes the dimension sizes .",
    "it can either clip or extend the array domain . `",
    "rebox ` implements subsampling or range queries over dimensions , one of the most important array operations .    `",
    "filter ` invalidates some array cells based on a content - only predicate .",
    "it is the direct equivalent of selection from relational algebra .    `",
    "fill ` transforms all the invalid cells to valid and assigns them a default value . essentially , `",
    "fill ` transforms a sparse array into a dense one .    `",
    "apply ` applies a function to each valid cell of an array .    `",
    "combine ` combines the content of two arrays having the same shape , but not necessarily the same validity .",
    "the content of the new array is computed by a function over the content of the argument arrays .    `",
    "innerdjoin ` and ` innerejoin ` are join operators over dimensions , and dimensions and attributes , respectively .",
    "their semantics is equivalent to the natural join operator in relational algebra .    `",
    "reduce ` generates a reduced version of an array by aggregating over one or more dimensions . supported aggregate functions",
    "include the standard sql aggregates .",
    "while arrayql algebra allows for a large variety of array operations to be expressed , there is an important feature that is completely missing from the algebra .",
    "this is the notion of adjacency or cell neighborhood .",
    "there is no operator that allows for aggregate functions to be applied to multiple adjacent cells centered on all the valid cells in the original array . while this operation can be expressed as a series of ` rebox ` and ` reduce ` operators applied at all the cells in the original array",
    ", we argue that it is common enough to deserve an operator by itself .",
    "an operator that handles adjacency is ` apply ` from aml  @xcite  this is a generalization of ` apply ` from arrayql algebra .",
    "we name this operator ` apply+ ` to avoid confusion . the argument function is defined over an array shape and generates as output another shape .",
    "it is applied to every cell in the input array ",
    "shape centered on each cell , to be precise .",
    "the most common case is when the output array has exactly the same shape as the input array . in this case",
    ", the output shape is a single array cell and there is direct correspondence between the origin cell in the input array and the output cell .",
    "the main difference from ` apply ` is that the value of the output cell is a function of multiple adjacent cells in the input array . moreover , ` apply+ ` can specify which cells in the input array are considered as origin cells . in this situation",
    ", the output shapes are concatenated following the order in the input array to generate a dense array .",
    "arrayql is an array creation and query language based on arrayql algebra .",
    "it is highly reminiscent of sql and contains only two statements  create array to create arrays at the schema level and select from to query arrays .",
    "arrayql queries take as input arrays",
    ". the output can be either a new array  with dimensions specified explicitly in the query as brackets  or a relation  without any ordering constraint .",
    "ranges on dimensions can be specified both for the input and the output arrays . in the case of input arrays ,",
    "ranges correspond to sub - arrays , while in the case of the result array , ranges implement the ` shift ` operator .",
    "if no ranges are provided , the complete dimension ranges of the input array(s ) are automatically inherited .",
    "structural joins between two arrays are specified by enumerating the arrays in the from clause and matching the dimension names .",
    "overall , algebra operators are mostly implemented through index mappings .",
    "not all arrayql algebra operators are specified in the language though . and not all the operations possible in the language by means of intricate index mappings are part of arrayql algebra .",
    "sciql  @xcite is a direct precursor of arrayql with almost identical syntax .",
    "it has a very important feature not present in arrayql though .",
    "it supports the ` apply+ ` operator as structural grouping .",
    "thus , whenever the benchmark operations require it , we use sciql queries instead of the less expressive arrayql .",
    "the ss - db benchmark  @xcite is modeled based upon a real workflow for processing astronomical images .",
    "although application - specific , ss - db includes a full spectrum of operations over raw and derived data representative across various scientific domains .",
    "queries in ss - db are on 1-d arrays ( e.g. , polygon boundaries ) , dense and sparse 2-d arrays ( e.g. , images and astrophysical objects ) , and 3-d arrays ( e.g. , trajectories in space and time ) .",
    "raw data ingestion and the computation of derived data are also part of the benchmark . in the following ,",
    "we provide a detailed description of the ss - db benchmark components and operations .",
    "our contribution is to provide a formal representation for the benchmark operations based on the arrayql algebra and query language presented in section  [ sec : query - lang]the original specification in  @xcite is in plain language .",
    "the abstract benchmark representation simplifies the understanding considerably and provides a clear specification for implementation in other systems .",
    "the basic data element is represented by a 2-d grid , i.e. , dense array , corresponding to a sky image .",
    "the default size of the grid is a configurable parameter .",
    "the origin of the grid lies on a large 2-d plane @xmath0 corresponding to the entire sky .",
    "the origin has a higher chance to be placed towards the center of the domain than at other position in the space .",
    "this results in a dense region of grids lying in the central region of the domain and sparse everywhere else .",
    "each grid cell contains @xmath1 integer values corresponding to a set of measurements taken at that point .",
    "the distribution of the values is chosen to reflect as close as possible real scientific data .",
    "an instance of the benchmark consists of multiple grids spread across the domain .",
    "they are grouped into cycles according to the time when the image was taken , thus introducing a third dimension .",
    "in essence , the complexity of the benchmark is given by the size of the grid and the number of cycles , with more and larger grids corresponding to more difficult benchmarks .",
    "as a concrete example , consider the specifics of the normal ss - db instance .",
    "the size of each grid is @xmath2 .",
    "there are a total of @xmath3 grids in the dataset , grouped into cycles of @xmath4 , for a total of @xmath4 cycles .",
    "the overall size of the dataset is approximately @xmath5each grid is @xmath6 .",
    "the arrayql definition for the raw dataset is : @xmath7,}\\\\ & \\hspace*{0.5 cm } \\texttt{x integer dimension [ 0:7499],}\\\\ & \\hspace*{0.5 cm } \\texttt{y integer dimension [ 0:7499],}\\\\ & \\hspace*{0.5 cm } \\texttt{v1 integer , $ \\dots$ , v11 integer}\\\\ & \\texttt { ) } \\end{split}\\ ] ] it is important to notice that this representation is in the local coordinate system corresponding to each image .",
    "the origin of the images does not need to coincide .",
    "the origin of the grids in the global coordinate system is stored in the 1-d array ` image_origin ` : @xmath8,}\\\\ & \\hspace*{0.5 cm } \\texttt{x integer , y integer}\\\\ & \\texttt { ) } \\end{split}\\ ] ] in the global coordinate system , ` images ` is a sparse array over the 3-d space @xmath9 with a single @xmath10 dense sub - array at each ` img_id ` index .",
    "the distinction between these two representations is significant for query execution .",
    "depending on which coordinate system is used , the ` shift ` operator in arrayql algebra has to be applied to change the origin of the array prior to query processing .",
    "raw data consist of dense grids with values associated to each cell in the domain .",
    "if we consider the entire 3-d space ( ` img`_`id`-`x`-`y ` ) though , raw data are very sparse , i.e. , only a fraction of @xmath11 cells have values .",
    "derived data are generated from the raw data through clustering .",
    "there are two types of clustering specified in the benchmark .",
    "cooking , or observation creation , is local clustering inside each grid based on cell values and cell neighborhood relationships .",
    "grouping is distance - based clustering applied to the previously obtained observations across the grids in the same cycle .",
    "it is important to notice that derived data represent sparse arrays both in the 2-d domain ( ` x`-`y ` ) as well as in the 3-d space ( ` img`_`id`-`x`-`y ` ) .",
    "observations are extracted , i.e. , `` cooked '' , from raw data based on a user - defined function ( udf ) over cell values . intuitively , all the cells that are part of an observation satisfy two conditions : they are neighbors and the udf holds for each individual cell .",
    "they form a cluster with a common property . as an example , consider adjacent pixels in an image with the r component in rgb having values greater than @xmath12 . the actual number of observations in a grid is strictly determined by the parameters of the udf .",
    "it is likely though that only a small number of cells are part of observations . to enforce this explicitly ,",
    "the benchmark imposes two conditions .",
    "it limits the size of the bounding box and the number of edges in the boundary polygon corresponding to each observation .",
    "in addition to the data corresponding to each individual cell , a series of aggregated attributes are defined for an observation : the center , the bounding box and the boundary polygon , and some additional domain - specific properties .",
    "to understand the semantics of the cooking operation , we examine how it can be expressed as an array algebra formula  a sequence of array algebra operators , to be precise .",
    "abstractly , cooking corresponds to the labeling operation from image processing , i.e. , identify all the groups of adjacent cells , i.e. , observations , satisfying some common property . in this case , the property is that the value of one attribute , e.g. , ` v1 ` , is greater than a given threshold .",
    "the adjacent cells are defined as a hypercube of a configurable size and centered on each cell in the input array  the hypercube is statically specified at query time and is fixed for all the cells in the array .",
    "the result of cooking is an array with exactly the same shape and size .",
    "cell values correspond to the unique identifier assigned to each observation .",
    "other properties corresponding to the whole observation , e.g. , center , bounding box , and boundary polygon , can also be computed once the observation is determined .    the sequence of array algebra operators  arrayql algebra enhanced with the generalized ` apply+ ` from aml  that implement cooking is the following :    ` filter ` the array with the cell predicate .",
    "` valid ` is set to true only for the cells satisfying the predicate .",
    "assign a unique i d to each cell that is still valid .",
    "this can be done using a function of the array indexes .",
    "the i d is an additional attribute to the original array .    `",
    "apply+ ` a function that sets each cell to the minimum i d of all the neighbor cells .",
    "this is done for each cell in the input array .",
    "the result is a new array with the same i d in the cells corresponding to an observation . to generate the entire observation , ` apply+ ` has to be invoked iteratively until the source and result arrays are identical  steady state .",
    "computing observation properties is not a straightforward algebra operation either because observations have arbitrary shapes .",
    "the following steps are executed for each observation , extracted iteratively by ` filter ` on the observation i d :    ` innerdjoin ` is used to get the raw data corresponding to the cells in the observation .    `",
    "reduce ` is applied to generate aggregate properties .",
    "these can be stored at all the cells that are part of the observation or only at a designated cell , e.g. , the center .",
    "the sciql query corresponding to ` apply+ ` for the first image in the array ` images ` is : @xmath13 , [ y ] , min(id)}\\\\ & \\texttt{from images[0]}\\\\ & \\texttt{group by images[0][x-1:x+1][y-1:y+1 ] } \\end{split}\\ ] ] for cooking to work correctly , it is required that both the array algebra operator ` apply+ ` and the structural grouping in sciql can identify the valid array cells .",
    "the second form of derived data consist of groups of observations .",
    "a group contains observations from different grids in the same cycle having the centers close to each other  the centers are not required to coincide .",
    "the actual definition of closeness is specified through a udf .",
    "intuitively , a group can be imagined as a cluster in the 3-d space of grid cycles .",
    "there is no requirement though that the observations need to be in adjacent grids  as is the case for observations  since the distance function already takes into account the distance across the time dimension , i.e. , ` img`_`id ` .",
    "the center and bounding box of a group are defined as in the case of observations , from the centers and the bounding boxes corresponding to member observations .    in order to write an array algebra expression for grouping",
    ", we need to get a better understanding of the operation .",
    "the important detail to remark is that the neighbors are determined according to a distance function rather than using a fixed shape centered on the observation center .",
    "nonetheless , the neighbors can be represented as an irregular 3-d array computed based on a discretized version of the distance function .",
    "thus , we can view grouping as a 3-d version of cooking with an irregular neighborhood shape operating on observation centers . given an origin or reference observation , the neighborhood hypercube expands with the distance along the time dimension .",
    "the difficult part is to compute the discrete hypercube from the continuous distance function .    to compute the group corresponding to a reference observation",
    ", the following arrayql algebra operators have to be invoked :    ` apply+ ` labeling  set the observation i d  to all the observations in the reference observation neighborhood . in this case , labeling is done in a single shot , not iteratively .    ` apply+ ` the same labeling as above for all the observations labeled before ",
    "they are part of the same group .",
    "this is done step - by - step along the time dimension .",
    "once the observations in a group are determined , ` reduce ` is called on the ` innerdjoin ` result with the observation data corresponding to all the observations in the group to compute aggregate properties for the group .",
    "the main difference between cooking and grouping is the irregular shape passed as argument to ` apply+ ` .",
    "this difference is very significant in the case of sciql though .",
    "based on the examples given in  @xcite , we argue that it is not possible to write grouping as a sciql query because sciql can handle only regular hypercubes .",
    "the benchmark defines a series of nine queries ",
    "three on raw data , three on observations , and three on groups .",
    "a general characteristic across all the queries is that instead of applying them to an entire grid , they typically operate on a slab of the space which is specified as part of the query .",
    "the size and position of the slab are important parameters that control the difficulty level of the benchmark .",
    "this operation is known as _",
    "subsampling _ or _ range _ query and is highly dependent on the storage strategy .",
    "the ideal situation is to execute all the queries by reading only the required data and nothing extra .",
    "this is hard to enforce across all the possible ranges .",
    "before we proceed to provide the array algebra expression for each query in the benchmark , we discuss how to handle subsampling since it is embedded in almost all the benchmark queries .",
    "subsampling can be expressed in arrayql algebra by the ` rebox ` operator . `",
    "rebox ` clips the original array to the query slab by effectively reducing the size of its ` box ` .",
    "the position of the array origin changes accordingly .",
    "if the dimension sizes have to be preserved , a second call to ` rebox ` can extend the array to its original size while invalidating the cells that are not part of the subsample .",
    "intuitively , the same effect can be achieved by a single call to ` filter ` with the range conditions on dimensions .",
    "this is not supported in the current arrayql algebra  @xcite since ` filter ` accepts conditions exclusively on the cell content and not on dimensions .",
    "we assume that in all the queries that require subsampling , ` rebox ` is first applied to clip the array to the query range .",
    "thus , our array algebra expressions do not represent ` rebox ` explicitly unless necessary .",
    "* q1 aggregation .",
    "* `` for the @xmath4 images in each cycle and for a slab of size @xmath14 $ ] in the local coordinate space , starting at @xmath15 $ ] , compute the average value of ` vi ` for a random value of ` i ` . ''",
    "@xcite    the arrayql algebra operators for the first cycle are : @xmath16)}\\\\ & \\texttt{r2 = reduce(r1 , \\{img\\_id , x , y\\ } , avg(vi ) ) } \\end{split}\\ ] ] similar expressions can be written for the other cycles by changing the range on ` img_id ` in the ` rebox ` operator .",
    "while q1 supports different aggregate operators , it can be generalized further by allowing induced functions  @xcite over attribute values inside the aggregate .",
    "this can be done by adding a call to the ` apply ` operator before ` reduce ` : @xmath17    the arrayql syntax for q1 is a simple sql aggregation with the ranges specified after the array rather than in the ` where ` clause : @xmath18 } \\end{split}\\ ] ]    * q2 recooking .",
    "* `` for a slab of size @xmath14 $ ] starting at @xmath15 $ ] , recook the raw imagery for the first image in the cycle with a different clustering function . ''",
    "@xcite    the same cooking process for computing observations is applied to a slab of an image and with a different filtering condition .",
    "these are marginal modifications to the sequence of array algebra operators presented in section  [ ssec : ssdb : cooking ] .",
    "* q3 regridding . *",
    "`` for a slab of size @xmath14 $ ] starting at @xmath15 $ ] , regrid the raw data for the images in the cycle , such that the cells collapse @xmath19 .",
    "all the ` vi ` values in the raw data are regridded in this process by an interpolation function . ''",
    "@xcite    this operation modifies the size of the grid dimensions . while q3 corresponds to image shrinking , it is equally possible to imagine a version that enlarges the grid with a specified ratio .",
    "the important aspect is that the number of cells reduces and the values in each new cell have to be determined accordingly .",
    "the standard solution is to compute the new value based on the values in adjacent cells using an interpolation function .",
    "think of a mapping from a set of cells in the original grid to a single cell in the new grid , each making its share of contribution to the new value . in terms of array algebra operators ,",
    "regridding is very similar to cooking , i.e. , a neighborhood shape is applied at cell positions in the input array to generate cells in the output array .",
    "the main difference is that not all the cells in the input array are considered as origin in the case of regridding .",
    "how many and which is determined by the regrid ratio .    out of all the array algebra formulations in the literature , only aml  @xcite supports cell selection through bit patterns .",
    "thus , the same generalized ` apply+ ` operator used for cooking can be also used for regridding .",
    "in addition to the neighborhood shape and the aggregate function , a bit pattern identifying the cells where ` apply+ ` is invoked has to be specified .",
    "the bit pattern takes the form of a regular expression of 0 s and 1 s that is applied repetitively along the dimension domain .",
    "there is one such bit pattern for each dimension . `",
    "apply+ ` is invoked only at those cells where the bit pattern is 1 for all the dimensions . for q3 , the bit pattern on both ` x ` and ` y ` is the same : @xmath20 since none of the array query languages in the literature implements the generalized ` apply+ ` operator  with the bit pattern selection ",
    "we argue that q3 can not be expressed directly as a query  only as a udf over the entire array .",
    "* q4 observation aggregation . *",
    "`` for the observations in the cycle with centers in a slab of size @xmath21 $ ] starting at @xmath22 $ ] in the world coordinate space , compute the average value of observation attribute ` oi ` , for a randomly chosen ` i ` .",
    "''  @xcite    q4 has exactly the same array algebra representation as q1 if we consider observation centers to be the only valid cells of a sparse array ` obs_center ` .",
    "the evaluation of the two queries is completely different though because ` obs_center ` is a sparse array and the range condition is given in the global coordinate space . as a result ,",
    "not every image has observations in the given range ",
    "there are images that do not even overlap the range .",
    "q4 for the first cycle can be written in arrayql as follows : @xmath23 } \\end{split}\\ ] ]    * q5 polygons . * `` for the observations in the cycle and for a slab of size @xmath21 $ ] starting at @xmath22 $ ] in the world coordinate space , compute the observations whose polygons overlap the slab . ''",
    "@xcite    this query is similar to q4 with the difference that instead of requiring the observation center to be contained in the slab , the query considers the observations for which the boundary polygon intersects with the slab .",
    "an alternative is to consider the bounding box instead of the polygon .",
    "consider observations to be represented as the only valid cells of a sparse array ` obs ` .",
    "the observation i d is the single value stored in each cell that is part of an observation .",
    "the arrayql algebra expression for q5 can then be written as : @xmath24)}\\\\ & \\texttt{r2 = reduce(r1 , \\{img\\_id , x , y\\},}\\\\ & \\hspace*{1.2cm}\\texttt{count distinct(obs\\_id ) ) } \\end{split}\\ ] ] the arrayql syntax is identical to eq .",
    "( [ eq : aql : q1 ] ) .",
    "the only difference is that ` count distinct ` is used instead of ` avg ` .",
    "* q6 density .",
    "* `` for the observations in the cycle and for a slab of size @xmath21 $ ] starting at @xmath22 $ ] in the world coordinate space , group the observations spatially into ` d4 ` by ` d4 ` tiles , where each tile may be located at any integral coordinates within the slab .",
    "find the tiles containing more than ` d5 ` observations . ''",
    "@xcite    it is not clear from the query definition when an observation is considered to be part of a tile  if the observation center is contained in the tile or if any observation cell is part of the tile .",
    "we consider the first version and use the array corresponding to observation centers in the array algebra expressions . as with all the other queries that require access to neighboring cells",
    ", q6 can not be expressed using only arrayql algebra operators .",
    "the generalized ` apply+ ` operator has to be used for grouping at every cell with a neighborhood shape @xmath25 having the upper left corner at the cell . with this extension ,",
    "the arrayql algebra representation is : @xmath26)}\\\\ & \\texttt{r2 = apply+(r1[i ] , [ 1,d4,d4],}\\\\ & \\hspace*{1.2cm}\\texttt{count(center ) as density)}\\\\ & \\texttt{r3 = filter(r2 , density $ \\geq$ d5 ) } \\end{split}\\ ] ] notice that ` r2 ` and ` r3 ` are computed separately for each image @xmath27 $ ] in the cycle . in sciql",
    ", they correspond to structural grouping followed by ` having ` : @xmath28[x2:x2+t2][y2:y2+u2]}\\\\ & \\texttt{group by obs\\_center[1][cx : cx+d4][cy : cy+d4]}\\\\ & \\texttt{having density $ \\geq$ d5 } \\end{split}\\ ] ]      * q7 centroid .",
    "* `` find each group whose center falls in the slab of size @xmath21 $ ] starting at @xmath22 $ ] in the world coordinate space at any time ` t ` .",
    "the center is defined to be the average value of the centers recorded for all the observations in the group . ''",
    "@xcite    this is a 3-d query over an array ` group_center ` containing valid cells only for the group centers .",
    "one such array corresponds to each cycle .",
    "this array can be computed after the groups are determined . with this representation",
    ", the query for the first cycle can be expressed as a simple ` rebox ` in arrayql algebra : @xmath29 ) } \\end{split}\\ ] ] and in arrayql as : @xmath30 } \\end{split}\\ ] ]    * q8 center trajectory .",
    "* `` define trajectory to be the sequence of centers of the observations in an observation group . for each trajectory that intersects a slab of size",
    "@xmath31 $ ] starting at @xmath22 $ ] in the world coordinate space , produce the raw data for a ` d6 ` by ` d6 ` tile centered on each center for all images that intersect the tile . ''",
    "@xcite    q8 consists of two phases .",
    "first , the groups whose trajectory intersects a given slab are determined .",
    "second , for each grid containing an observation in the group , the cells in a given tile centered on the group center in that grid are returned .",
    "it is important to notice that q8  as well as q9  requires access both to the raw images as well as to groups .    while in q7 the center of a group is defined as a single 2-d point over all the observations in the group , in q8 there is a center at each image that has observations in the group  there are at most @xmath4 centers for a group .",
    "they define the trajectory of a group as a 3-d array in the global coordinate space .",
    "then the trajectories that intersect the query slab , i.e. , at least one center is contained in the slab , can be extracted with a simple ` rebox ` operator applied to the corresponding ` group_center_img ` array : @xmath32 ) } \\end{split}\\ ] ] for each valid cell in ` r1 ` , raw data have to be extracted from the corresponding image .",
    "this can be done with ` rebox ` on the image representation in the global coordinate space .",
    "assuming we operate on the first image in the cycle at observation center @xmath33 , the arrayql algebra operator sequence is : @xmath34 , < orig\\_x , orig\\_y>)}\\\\ & \\texttt{r3 = rebox(images[0],}\\\\ & \\hspace*{1.2cm}\\texttt{[ocx - d6:ocx+d6 , ocy - d6:ocy+d6 ] ) } \\end{split}\\ ] ] ` < orig_x , orig_y > ` is the image origin in the global coordinate system as stored in ` image_origin ` ( eq .",
    "[ eq : orig - def ] ) .",
    "since the conversion of ` rebox ` to arrayql is standard ( see eq .",
    "( [ eq : aqla : q7 ] ) and  ( [ eq : aql : q7 ] ) ) , we do not include it here .",
    "* q9 polygon trajectory .",
    "* `` define trajectory to be the sequence of polygons that correspond to the boundary of the observation group . for a slab",
    "@xmath31 $ ] starting at @xmath22 $ ] , find the groups whose trajectory overlaps the slab at some time ` t ` and produce the raw data for a ` d6 ` by ` d6 ` tile centered on each center for all images that intersect the slab . ''",
    "@xcite    q9 is similar to q8 .",
    "the only difference is the array used in ` rebox ` over the derived data .",
    "the original observations array ` obs ` containing the groups the observation is part of and shifted to the origin in the global coordinate space has to be used instead of the ` group_center_img ` array .",
    "this array contains valid cells for all the points that are part of observations .",
    "it allows us to identify the groups overlapping the query slab and their centers at each position in the cycle .",
    "given the algebra representation for all the operations in the benchmark , we analyze what array structures and operators are required for an actual implementation . the 3-d array corresponding to the raw images is given in eq .",
    "( [ eq : raw - def ] ) . `",
    "images ` is represented in the local coordinate system .",
    "this representation suffices to answer q1q3 and to execute the cooking . for q8 and q9 , the representation of ` images ` in the global coordinate system is required .",
    "this can be obtained by shifting the origin of the images based on ` image_origin ` . for grouping ,",
    "only the observation centers are required .",
    "a sparse 3-d array ` obs_center ` over the global coordinates containing valid cells only where observation centers are located can do the job .",
    "the data inside the cell contain the observation i d and a set of attributes ( q4 , q6 ) .",
    "all the cells that are part of observations are required for q5 .",
    "they can be represented as a sparse 3-d array ` obs ` with the observation i d as the single attribute .",
    "this array is also required to answer q9 .",
    "group centers are required to answer q7 and q8 . in q7 ,",
    "the single group centers can be represented as a sparse 3-d array ` group_center ` containing the group ids in the valid cells . in q8 ,",
    "group centers are recorded for each image in the cycle  they can be different from one image to another .",
    "thus , a sparse 4-d array ` group_center_img ` with the group ids stored in the valid cells is required .",
    "notice that cycle represents the additional dimension in the arrays corresponding to groups .",
    "table  [ tbl : bench - arrays ] summarizes the arrays required to answer the benchmark queries .",
    ".arrays used in the ss - db benchmark . [ cols=\"<,<,<\",options=\"header \" , ]      there are multiple conclusions we can draw from the experimental results presented in this section .",
    "the most important point to remark is that although extascid and scidb share common design and implementation features , their performance is quite different for the ss - db benchmark .",
    "extascid outperforms scidb by a large margin ",
    "a factor of @xmath35 on average  on data loading and derived data computation .",
    "this is mostly due to the extensive parallelism available in extascid for this kind of tasks .",
    "the relationship between the two systems is more nuanced when considering query performance .",
    "scidb is slightly faster on queries over raw data whenever compression and chunk caching can be applied . for queries over derived data ",
    "amenable to a relational representation  extascid provides the better execution time since it supports natively both dense as well as sparse arrays . since scidb is targeted at dense arrays , mapping between the two representations is required .",
    "overall , the extascid performance is truly remarkable , getting close to the physical bounds imposed by the experimental system for many of the ss - db benchmark tasks .",
    "there are three lines of research on scientific and array data processing that we consider related to the topics addressed in this paper  benchmarking , array query algebras and languages , and scientific data processing systems . to the best of our knowledge ,",
    "sloan digital sky survey ( sdss )  @xcite is the single other benchmark targeted specifically at scientific processing .",
    "similar to ss - db , sdss is also based on processing astronomical images . unlike ss - db though , sdss operates exclusively on relational data obtained as a bi - product of astronomical observations .",
    "ss - db is more general and contains a full spectrum of operations ranging from raw data processing to the creation and querying of derived observation data .",
    "these operations manipulate array - oriented data through relatively sophisticated user - defined functions , not always expressible in sql .",
    "while typical implementations of the sdss benchmark are sql - based , e.g. , ms sql server and monetdb  @xcite , scidb and mysql  @xcite are the only two implementations of the ss - db benchmark we are aware of . with our implementation in extascid",
    ", we provide another reference point for a larger adoption of the ss - db benchmark  the only general benchmark for scientific data processing .",
    "arrayql algebra  @xcite and query language  @xcite are formalisms introduced in the scidb context  similar to the ss - db benchmark .",
    "this is the main reason we choose these formalisms to represent the ss - db operations .",
    "they are not commonly accepted though as the representative array algebra and query language .",
    "in fact , there is no commonly accepted array algebra and query language . in the following ,",
    "we discuss other such alternatives proposed in the literature .",
    "aql  @xcite is a declarative query language for multi - dimensional arrays that treats arrays as functions from index sets to values rather than as collection types .",
    "aql is based on the nested relational calculus with arrays which plays the same role relational calculus and algebra play for the relational data model .",
    "the rasdaman  @xcite array algebra conceptualizes arrays as functions from rectangular domains to cell values .",
    "three core constructs  marray , cond , and sort  that can express every array operation when composed together are introduced . in the corresponding rasql query language  @xcite , arrays are treated as a composite attribute type with a set of corresponding operators .",
    "aml  @xcite is an algebra consisting of three operators that manipulate dense arrays and take bit patterns as parameters .",
    "a significant aml limitation is that it contains only structural operators , i.e. , operators that consider the indexes . at query language level , aml is more like an elevated execution plan description than a declarative array query language .",
    "ram  @xcite and sram  @xcite are array algebras for dense and sparse arrays , respectively , developed in the context of the monetdb  @xcite columnar database system . since the execution happens inside a relational database engine ,",
    "array queries follow a sequence of transformations that take arrays represented in the comprehension syntax to relational operators through an intermediate array algebra stage .",
    "although a series of rewriting rules and optimizations are applied at each of these two steps , relying on the relational algebra operators to map and process array operations introduces inefficiencies due to the impedance mismatch in representation .",
    "sciql  @xcite is the most comprehensive extension to the sql:2003 standard with support for arrays .",
    "it provides seamless integration of set , sequence , and array semantics .",
    "the goal is to make minimal modifications to the sql syntax while allowing for maximum expressiveness in the array operations supported by the language .",
    "an interesting characteristic of all the array algebras discussed above is their equivalence . in  @xcite",
    ", it is shown that all the array algebras can be reduced to rasql  both in array representation as well as operations .",
    "this is primarily due to the equivalence between comprehensions and the marray operator for creating arrays .",
    "we point the interested reader to  @xcite for a comprehensive discussion on these and other array algebras and query languages .",
    "extascid is part of a long series of parallel systems for scientific data processing .",
    "titan  @xcite and t2  @xcite are the first systems designed with extensibility in mind .",
    "they adopt an execution strategy closely related to the map - reduce  @xcite paradigm .",
    "more recently , scihadoop  @xcite implements array processing on top of the popular hadoop map - reduce framework .",
    "the main differences between extascid and these systems are the different execution strategy , i.e. , uda vs. map - reduce , and the native support for arrays and relations in extascid .",
    "rasdaman  @xcite is a general middleware for array processing with array chunks stored as blobs in a back - end database .",
    "the processing is specified through a limited number of second - order operators integrated into sql and executed entirely inside the middleware .",
    "rasdaman is targeted only at array data  relational data have to be processed either at the application level or inside the middleware  and it is not parallel .",
    "the ram  @xcite and sram  @xcite systems provide support for array processing on top of the monetdb  @xcite columnar database .",
    "they do not provide native support for arrays since arrays are represented as relations and array operations are mapped over relational algebra operators .",
    "ram and sram are not parallel .",
    "scidb  @xcite is the system extascid resembles the most",
    ". both are parallel systems designed to be extensible .",
    "scidb supports natively only arrays .",
    "extascid provides native support both for arrays and relations .",
    "the execution strategy in extascid is well - defined through the uda interface which makes reasoning about parallelism clear .",
    "the same is not true in scidb where a series of udfs are arbitrarily interconnected .",
    "while there are discussions on the implementation of the ss - db benchmark in multiple of these systems , the scidb implementation is the only we are aware of at the time when the paper is written .",
    "consequently , this is our reference for the extascid evaluation on the ss - db benchmark .",
    "in this paper , we present a formal representation of the ss - db benchmark in terms of array algebra operators and array query language constructs .",
    "these are meant to simplify the implementation in other systems and foster the acceptance of ss - db as the standard benchmark to evaluate scientific data processing applications . given that no alternatives exist , ss - db fills an important void in the evaluation of a large class of big data applications . to verify the soundness of our formalization",
    ", we give a reference implementation and present benchmark results in extascid , a novel system for scientific data processing we have developed .",
    "extascid is complete in providing native support both for array and relational data and extensible in executing any user code inside the system by the means of a configurable metaoperator .",
    "these features result in an order of magnitude improvement over scidb at data loading , extracting derived data , and operations over derived data .",
    "the results prove that the integrated extascid architecture supporting natively both arrays and relations is more suited for complex scientific processing over raw and derived data requiring a high degree of extensibility .",
    "j.  b. buck , n.  watkins , j.  lefevre , k.  ioannidou , c.  maltzahn , n.  polyzotis , and s.  brandt . .",
    "in _ proceedings of 2011 sc international conference for high performance computing , networking , storage and analysis _ , pages 66:166:11 , 2011 ."
  ],
  "abstract_text": [
    "<S> evaluating the performance of scientific data processing systems is a difficult task considering the plethora of application - specific solutions available in this landscape and the lack of a generally - accepted benchmark . </S>",
    "<S> the dual structure of scientific data coupled with the complex nature of processing complicate the evaluation procedure further . </S>",
    "<S> ss - db is the first attempt to define a general benchmark for complex scientific processing over raw and derived data . </S>",
    "<S> it fails to draw sufficient attention though because of the ambiguous plain language specification and the extraordinary scidb results . in this paper </S>",
    "<S> , we remedy the shortcomings of the original ss - db specification by providing a formal representation in terms of arrayql algebra operators and arrayql / sciql constructs . </S>",
    "<S> these are the first formal representations of the ss - db benchmark . </S>",
    "<S> starting from the formal representation , we give a reference implementation and present benchmark results in extascid , a novel system for scientific data processing . </S>",
    "<S> extascid is complete in providing native support both for array and relational data and extensible in executing any user code inside the system by the means of a configurable metaoperator . </S>",
    "<S> these features result in an order of magnitude improvement over scidb at data loading , extracting derived data , and operations over derived data . </S>"
  ]
}