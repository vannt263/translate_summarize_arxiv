{
  "article_text": [
    "with the availability of cheap computing power , modern cameras can rely on computational post - processing to extend their capabilities under the physical constraints of existing sensor technology .",
    "sophisticated techniques , such as those for denoising  @xcite , deblurring  @xcite , etc . , are increasingly being used to improve the quality of images and videos that were degraded during acquisition . moreover ,",
    "researchers have posited novel sensing strategies that , when combined with post - processing algorithms , are able to produce higher quality and more informative images and videos .",
    "for example , coded exposure imaging  @xcite allows better inversion of motion blur , coded apertures  @xcite allow passive measurement of scene depth from a single shot , and compressive measurement strategies  @xcite combined with sparse reconstruction algorithms allow the recovery of visual measurements with higher spatial , spectral , and temporal resolutions .",
    "key to the success of these latter approaches is the co - design of sensing strategies and inference algorithms , where the measurements are designed to provide information complimentary to the known statistical structure of natural scenes .",
    "so far , sensor design in this regime has largely been either informed by expert intuition ( _ e.g. _ ,  @xcite ) , or based on the decision to use a specific image model or inference strategy_e.g .",
    "_ ,  measurements corresponding to random  @xcite , or dictionary - specific  @xcite , projections are a common choice for sparsity - based reconstruction methods . in this paper , we seek to enable a broader data - driven exploration of the joint sensor and inference method space , by learning both sensor design and the computational inference engine end - to - end .",
    "we leverage the successful use of back - propagation and stochastic gradient descent ( sgd )  @xcite in learning deep neural networks for various tasks  @xcite .",
    "these networks process a given input through a complex cascade of layers , and training is able to jointly optimize the parameters of all layers to enable the network to succeed at the final inference task .",
    "treating optical measurement and computational inference as a cascade , we propose using the same approach to learn both jointly .",
    "we encode the sensor s design choices into the learnable parameters of a `` sensor layer '' which , once trained , can be instantiated by camera optics .",
    "this layer s output is fed to a neural network that carries out inference computationally on the corresponding measurements .",
    "both are then trained jointly .",
    "we demonstrate this approach by applying it to the sensor - inference design problem in a standard digital color camera .",
    "since image sensors can physically measure only one color channel at each pixel , cameras spatially multiplex the measurement of different colors across the sensor plane , and then computationally recover the missing intensities through a reconstruction process known as demosaicking .",
    "we jointly learn the spatial pattern for multiplexing different color channels  that requires making a hard decision to use one of a discrete set of color filters at each pixel  along with a neural network that performs demosaicking .",
    "together , these enable the recovery of high - quality color images of natural scenes .",
    "we find that our approach significantly outperforms the traditional bayer pattern  @xcite used in most color cameras .",
    "we also compare it to a recently introduced design  @xcite based on making sparse color measurements , that has superior noise performance and fewer aliasing artifacts .",
    "interestingly , our network automatically learns to employ a similar measurement strategy , but is able outperform this design by finding a more optimal spatial layout for the color measurements .",
    "possible color filters that could be placed at each pixel , we parameterize the incident light as a @xmath0channel image .",
    "this acts as input to a `` sensor layer '' that learns to select one of these channel at each pixel .",
    "a reconstruction network then processes these measurements to yield a full - color rgb image .",
    "we jointly train both for optimal reconstruction quality .",
    "( * bottom left * ) since the hard selection of individual color channels is not differentiable , we encode these decisions using a soft - max layer , with a `` temperature '' parameter @xmath1 that is increased across iterations .",
    "( * bottom right * ) we use a bifurcated architecture with two paths for the reconstruction network .",
    "one path produces @xmath2 possible values for each color intensity through multiplicative and linear interpolation , and the other weights to combine these into a single estimate.,scaledwidth=94.3% ]",
    "since both cmos and ccd sensors can measure only the total intensity of visible light incident on them , color is typically measured by placing an array of color filters ( cfa ) in front of the sensor plane .",
    "the cfa pattern determines which color channel is measured at which pixel , with the most commonly pattern used in rgb color cameras being the bayer mosaic  @xcite introduced in 1976 .",
    "this is a @xmath3 repeating pattern , with two measurements of the green channel and one each of red and blue .",
    "the color values that are not directly measured are then reconstructed computationally by demosaciking algorithms .",
    "these algorithms  @xcite typically rely on the assumption that different color channels are correlated and piecewise smooth , and reason about locations of edges and other high - frequency image content to avoid creating aliasing artifacts .",
    "this approach yields reasonable results , and the bayer pattern remains in widespread use even today .",
    "however , the choice of the cfa pattern involves a trade - off .",
    "color filters placed in front of the sensor block part of the incident light energy , leading to longer exposure times or noisier measurements ( in comparison to grayscale cameras ) .",
    "moreover , since every channel is regularly sub - sampled in the bayer pattern , reconstructions are prone to visually disturbing aliasing artifacts even with the best reconstruction methods .",
    "most consumer cameras address this by placing an anti - aliasing filter in front of the sensor to blur the incident light field , but this leads to a loss of sharpness and resolution .    to address this , chakrabarti _ et al . _",
    "@xcite recently proposed the use of an alternative cfa pattern in which a majority of the pixels measure the total unfiltered visible light intensity .",
    "color is measured only sparsely , using @xmath4 bayer blocks placed at regularly spaced intervals on the otherwise unfiltered sensor plane .",
    "the resulting measured image corresponds to an un - aliased full resolution luminance image ( _ i.e. _ ,  the unfiltered measurements ) with `` holes '' at the color sampling site ; with point - wise color information on a coarser grid . the reconstruction algorithm in @xcite is significantly different from traditional demosaicking , and involves first recovering missing luminance values by hole - filling ( which is computationally easier than up - sampling since there is more context around the missing intensities ) , and then propagating chromaticities from the color measurement sites to the remaining pixels using edges in the luminance image as a guide .",
    "this approach was shown to significantly improve upon the capabilities of a bayer sensor  in terms of better noise performance , increased sharpness , and reduced aliasing artifacts .    that @xcite s cfa pattern required",
    "a very different reconstruction algorithm illustrates the fact that both the sensor and inference method need to be modified together to achieve gains in performance . in @xcite s case ,",
    "this was achieved by applying an intuitive design principles  of making high snr non - aliased measurements of one color channel .",
    "however , these principles are tied to a specific reconstruction approach , and do not tell us , for example , whether regularly spaced @xmath4 blocks are the optimal way of measuring color sparsely .    while learning - based methods have been proposed for demosaicking  @xcite ( as well as for joint demosaicking and denoising  @xcite ) , these work with a pre - determined cfa pattern and training is used only to tune the reconstruction algorithm .",
    "in contrast , our approach seeks to learn , automatically from data , _ both _ the cfa pattern and reconstruction method , so that they are jointly optimal in terms of reconstruction quality .",
    "we formulate our task as that of reconstructing an rgb image @xmath5 , where @xmath6 indexes pixel location , from a measured sensor image @xmath7 . along with this reconstruction task",
    ", we also have to choose a multiplexing pattern which determines the color channel that each @xmath8 corresponds to .",
    "we let this choice be between one of @xmath9 channels  a parameterization that takes into account which spectral filters can be physically synthesized .",
    "we use @xmath10 denote the intensity measurements corresponding to each of these color channels , and a zero - one selection map @xmath11 to encode the multiplexing pattern , such that the corresponding sensor measurements are given by @xmath12 .",
    "moreover , we assume that @xmath13 repeats periodically every @xmath14 pixels , and therefore only has @xmath15 unique values .    given a training set consisting of pairs of output images @xmath16 and @xmath9-channel input images @xmath17 , our goal then is to learn this pattern @xmath13 , jointly with a reconstruction algorithm that maps the corresponding measurements @xmath8 to the full color image output @xmath16 .",
    "we use a neural network to map sensor measurements @xmath8 to an estimate @xmath18 of the full color image .",
    "furthermore , we encode the measurement process into a `` sensor layer '' , which maps the input @xmath17 to measurements @xmath8 , and whose learnable parameters encode the multiplexing pattern @xmath13 .",
    "we then learn both the reconstruction network and the sensor layer simultaneously , with respect to a squared loss @xmath19 between the reconstructed and true color images .",
    "the key challenge to our joint learning problem lies in recovering the optimal multiplexing pattern @xmath13 , since it is ordinal - valued and requires learning to make a hard non - differentiable decision between @xmath9 possibilities . to address this , we rely on the standard soft - max operation , which is traditionally used in multi - label classification tasks .    however , we are unable to use the soft - max operation directly  unlike in classification tasks where the ordinal labels are the final output , and where the training objective prefers hard assignment to a single label , in our formulation @xmath13 is used to generate sensor measurements that are then processed by a reconstruction network . indeed ,",
    "when using a straight soft - max , we find that the reconstruction network converges to real - valued @xmath13 maps that correspond to measuring different weighted combinations of the input channels .",
    "thresholding the learned @xmath13 to be ordinal valued leads to a significant drop in performance , even when we further train the reconstruction network to work with this thresholded version .",
    "our solution to this is fairly simple .",
    "we use a soft - max with a temperature parameter that is increased slowly through training iterations . specifically , we learn a vector @xmath20 for each location @xmath21 of the multiplexing pattern , with the corresponding @xmath13 given during training as : @xmath22,\\ ] ] where @xmath23 is a scalar factor that we increase with iteration number @xmath24 .",
    "therefore , in addition to changes due to the sgd updates to @xmath25 , the effective distribution of @xmath13 become `` peakier '' at every iteration because of the increasing @xmath23 , and as @xmath26 , @xmath13 becomes a zero - one vector .",
    "note that the gradient magnitudes of @xmath25 also scale - up , since we compute these gradients at each iteration with respect to the current value of @xmath24 .",
    "this ensures that the pattern can keep learning in the presence of a strong supervisory signal from the loss , while retaining a bias to drift towards making a hard choice for a single color channel .    as illustrated in fig .",
    "[ fig : teaser ] , our sensor layer contains a parameter vector @xmath25 for each pixel of the @xmath27 multiplexing pattern . during training , we generate the corresponding @xmath13 vectors using above , and the layer then outputs sensor measurements based on the @xmath9-channel input @xmath17 as @xmath28 . once training is complete ( and for validation during training ) , we replace @xmath13 with its zero - one version as @xmath29 for @xmath30 , and @xmath31 otherwise .    as we report in sec .",
    "[ sec : exp ] , our approach is able to successfully learn an optimal sensing pattern , which adapts during training to match the evolving reconstruction network .",
    "we would also like to note here two alternative strategies that we explored to learn an ordinal @xmath13 , which were not as successful .",
    "we considered using a standard soft - max approach with a separate entropy penalty on the distribution @xmath13however , this caused the pattern @xmath13 to stop learning very early during training ( or for lower weighting of the penalty , had no effect at all ) .",
    "we also tried to incrementally pin the lowest @xmath13 values to zero after training for a number of iterations , in a manner similar to han _",
    "@xcite approach to network compression .",
    "however , even with significant tuning , this approach caused a large parts of the pattern search space to be eliminated early , and was not able to adapt to the fact that a channel with a low weight at a particular location might eventually become desirable based on changes to the pattern at other locations , and corresponding updates to the reconstruction network .",
    "traditional demosaicking algorithms  @xcite produce a full color image by interpolating the missing color values from neighboring measurement sites , and by exploiting cross - channel dependencies .",
    "this interpolation is often linear , but in some cases takes the form of transferring chromaticities or color ratios ( _ e.g. _ ,  in @xcite ) .",
    "moreover , most demosaicking algorithms reason about image textures and edges to avoid smoothing across boundaries or creating aliasing artifacts .",
    "we adopt a simple bifurcated network architecture that leverages these intuitions . as illustrated in fig .",
    "[ fig : teaser ] , our network reconstructs each @xmath27 patch in @xmath16 from a receptive field that is centered on that patch in the measured image @xmath8 , and thrice as large in each dimension .",
    "the network has two paths , both of operate on the entire input and both output @xmath32 values , _",
    "i.e. _ ,  @xmath2 values for each output color intensity .",
    "we denote these outputs as @xmath33 .",
    "one path produces @xmath34 by first computing multiplicative combinations of the entire @xmath35 input patch ",
    "we instantiate this using a fully - connected layer without a bias term that operates in the log - domain  followed by a linear combinations across each of the @xmath36 values at each location .",
    "we interpret these @xmath34 values as @xmath2 proposals for each @xmath16 .",
    "the second path uses a more standard cascade of convolution layers  all of which have @xmath37 outputs with the first layer having a stride of @xmath14followed by a fully connected layer that produces the outputs @xmath38 with the same dimensionality as @xmath34 .",
    "we treat @xmath38 as gating values for the proposals @xmath34 , and generate the final reconstructed patch @xmath18 as @xmath39 .",
    "we follow a similar approach to @xcite for training and evaluating our method .",
    "like @xcite , we use the gehler - shi database  @xcite that consists of 568 color images of indoor and outdoor scenes , captured under various illuminants .",
    "these images were obtained from raw sensor images from a camera employing the bayer pattern with an anti - aliasing optical filter , by using the different color measurements in each bayer block to construct a single rgb pixel .",
    "these images are therefore at half the resolution of the original sensor image , but have statistics that are representative of aliasing - free full color images of typical natural scenes . unlike @xcite who only used 10 images for evaluation , we use the entire dataset  using 56 images for testing , 461 images for training , and the remaining 51 images as a validation set to fix hyper - parameters .",
    "we treat the images in the dataset as the ground truth for the output rgb images @xmath16 . as sensor measurements , we consider @xmath40 possible color channels .",
    "the first three correspond to the original sensor rgb channels . like @xcite",
    ", we choose the fourth channel to be white or panchromatic , and construct it as the sum of the rgb measurements .",
    "as mentioned in @xcite , this corresponds to a conservative estimate of the light - efficiency of an unfiltered channel .",
    "we construct the @xmath9-channel input image @xmath17 by including these measurements , followed by addition of different levels of gaussian noise , with high noise variances simulating low - light capture .",
    "we learn a repeating pattern with @xmath41 . in our reconstruction network , we set the number of proposals @xmath2 for each output intensity to 24 , and the number of convolutional layer outputs @xmath37 in the second path of our network to 128 .",
    "when learning our sensor multiplexing pattern , we increase the scalar soft - max factor @xmath23 in according to a quadratic schedule as @xmath42 , where @xmath43 in our experiments .",
    "we train a separate reconstruction network for each noise level ( positing that a camera could select between these based on the iso settings ) .",
    "however , since it is impractical to employ different sensors for different settings , we learn a single spatial multiplexing pattern , optimized for reconstruction under moderate noise levels with standard deviation ( std ) of @xmath44 ( with respect to intensity values in @xmath17 scaled to be between @xmath31 and @xmath45 ) .",
    "we train our sensor layer and reconstruction network jointly at this noise level on sets of @xmath46 @xmath16 patches and corresponding @xmath47 @xmath17 patches sampled randomly from the training set .",
    "we use a batch - size of 128 , with a learning rate of 0.001 for 1.5 million iterations .",
    "then , keeping the sensor pattern fixed to our learned version , we train reconstruction networks from scratch for other noise levels  training again with a learning rate of 0.001 for 1.5 million iterations , followed another 100,000 iterations with a rate of @xmath48 .",
    "we also train reconstruction networks at all noise levels in a similar way for the bayer pattern , as well the pattern of @xcite ( with a color sampling rate of 4 ) .",
    "moreover , to allow consistent comparisons , we re - train the reconstruction network for our pattern at the @xmath44 noise level from scratch following this regime .",
    "we begin by comparing the performance of our learned reconstruction networks to traditional demosaicking algorithms for the standard bayer pattern , and the pattern of @xcite .",
    "note that our goal is not to propose a new demosaicking method for existing sensors .",
    "nevertheless , since our sensor pattern is being learned jointly with our proposed reconstruction architecture , it is important to determine whether this architecture can learn to reason effectively with different kinds of sensor patterns , which is necessary to effectively cover the joint sensor - inference design space .",
    "we compare our learned networks to zhang and wu s method  @xcite for the bayer pattern , and chakrabarti _ et al .",
    "_ s method  @xcite for their own pattern .",
    "we measure performance in terms of the reconstruction psnr of all non - overlapping @xmath49 patches from all test images ( roughly 40,000 patches ) .",
    "table [ tab : trad ] compares the median psnr values across all patches for reconstructions using our network to those from traditional methods , at two noise levels  low noise corresponding to an std of @xmath50 , and moderate noise corresponding to @xmath44 . for the pattern of @xcite",
    ", we find that our network performs similar to their reconstruction method at the low noise level , and significantly better at the higher noise level . on the bayer pattern ,",
    "our network achieves much better performance at both noise levels .",
    "we also note here that reconstruction using our network is significantly faster  taking 9s on a six core cpu , and 200ms when using a titan x gpu , for a 2.7 mega - pixel image . in comparison ,",
    "@xcite and @xcite s reconstruction methods take 20s and 1 min .  respectively on the cpu .",
    "[ cols=\"^,^,^,^,^,^ \" , ]     [ tab : trad ]        in fig .",
    "[ fig : evolve ] , we visualize the evolution of our sensor pattern during the training process , while it is being jointly learned with the reconstruction network . in the initial iterations ,",
    "the sensor layers displays a preference for densely sampling the rgb channels , with very few panchromatic measurements  in fact , in the first row of fig .",
    "[ fig : evolve ] , we see panchromatic pixels switching to color measurements .",
    "this is likely because early on in the training process , the reconstruction network hasnt yet learned to exploit cross - channel correlations , and therefore needs to measure the output channels directly .",
    "however , as training progresses , the reconstruction network gets more sophisticated , and we see the number of color measurements get sparser and sparser , in favor of panchromatic pixels that offer the advantage of higher snr .",
    "essentially , the sensor layer begins to adopt one of the design principles of @xcite .",
    "however , it distributes the color measurement sites across the pattern , instead of concentrating them into separated blocks like @xcite . in the last 500k iterations , we see that most changes correspond to fine refinements of the pattern , with a few individual pixels swapping the channels they measure .    while the patterns themselves in fig .  [ fig : evolve ]",
    "correspond to the channel at each pixel with the maximum value in the selection map @xmath13 , remember that these maps themselves are soft .",
    "therefore , we also report the mean entropy of the underlying @xmath13 for each pattern in fig .  [",
    "fig : evolve ] .",
    "we see that this entropy decreases across iterations , as the choice of color channel for more and more pixels becomes fixed , with their distributions in @xmath13 becoming peakier and closer to being zero - one vectors .",
    "finally , we evaluate the performance of neural network - based reconstruction from measurements with our learned pattern , to those with the bayer pattern and the pattern of @xcite .",
    "table  [ tab : psnr ] shows different quantiles of reconstruction psnr for various noise levels , with noise stds raning from 0 to 0.04 .",
    "even though our sensor pattern was trained at the noise level of std=0.01 , we find it achieves the highest reconstruction quality over a large range of noise levels .",
    "specifically , it always outperforms the bayer pattern , by fairly significant margins at higher noise levels .",
    "the improvement in performance over @xcite s pattern is less pronounced , although we do achieve consistently higher psnr values for all quantiles at most noise levels .",
    "figure  [ fig : qual ] shows examples of color patches reconstructed from our learned sensor , and compare these to those from the bayer pattern and @xcite .",
    "we see that the reconstructions from the bayer pattern are noticeably worse .",
    "this is because it makes lower snr measurements , and the reconstruction networks learn to smooth their outputs to reduce this noise .",
    "both @xcite and our pattern yield significantly better reconstructions . indeed ,",
    "most of our gains over the bayer pattern come from choosing to make most measurements panchromatic , a design principle shared by @xcite .",
    "however , remember that our sensor layer learns this principle entirely automatically from data , without expert supervision .",
    "moreover , we see that @xcite s reconstructions tend to have a few more instances of `` chromaticity noise '' , in the form of contiguous regions with incorrect hues , which explain its slightly lower psnr values in table  [ tab : psnr ] .    [ tab : psnr ]",
    "in this paper , we proposed learning sensor design jointly with a neural network that carried out inference on the sensor s measurements , specifically focusing on the problem of finding the optimal color multiplexing pattern for a digital color camera .",
    "we learned this pattern by joint training with a neural network for reconstructing full color images from the multiplexed measurements .",
    "we used a soft - max operation with an increasing temperature parameter to model the non - differentiable color channel selection at each point , which allowed us to train the pattern effectively .",
    "finally , we demonstrated that our learned pattern enabled better reconstructions than past designs .",
    "an implementation of our method , along with trained models , data , and results , is available at our project page at http://www.ttic.edu / chakrabarti / learncfa/.    our results suggest that learning measurement strategies jointly with computational inference is both useful and possible .",
    "in particular , our approach can be used directly to learn other forms of optimized multiplexing patterns_e.g .",
    "_ ,  spatio - temporal multiplexing for video , viewpoint multiplexing in light - field cameras , etc .",
    "moreover , these patterns can be learned to be optimal for inference tasks beyond reconstruction .",
    "for example , a sensor layer jointly trained with a neural network for classification could be used to discover optimal measurement strategies for say , distinguishing between biological samples using multi - spectral imaging , or detecting targets in remote sensing ."
  ],
  "abstract_text": [
    "<S> recent progress on many imaging and vision tasks has been driven by the use of deep feed - forward neural networks , which are trained by propagating gradients of a loss defined on the final output , back through the network up to the first layer that operates directly on the image . </S>",
    "<S> we propose back - propagating one step further  to learn camera sensor designs jointly with networks that carry out inference on the images they capture . in this paper </S>",
    "<S> , we specifically consider the design and inference problems in a typical color camera  where the sensor is able to measure only one color channel at each pixel location , and computational inference is required to reconstruct a full color image . </S>",
    "<S> we learn the camera sensor s color multiplexing pattern by encoding it as layer whose learnable weights determine which color channel , from among a fixed set , will be measured at each location . </S>",
    "<S> these weights are jointly trained with those of a reconstruction network that operates on the corresponding sensor measurements to produce a full color image . </S>",
    "<S> our network achieves significant improvements in accuracy over the traditional bayer pattern used in most color cameras . </S>",
    "<S> it automatically learns to employ a sparse color measurement approach similar to that of a recent design , and moreover , improves upon that design by learning an optimal layout for these measurements .    </S>",
    "<S> = 1 </S>"
  ]
}