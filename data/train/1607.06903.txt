{
  "article_text": [
    "the use of approximate bayesian computation ( abc ) methods in models with intractable likelihoods has gained increased momentum over recent years , extending beyond the original applications in the biological sciences .",
    "( see marin _ et al . , _",
    "2011 , sisson and fan , 2011 and robert , 2015 , for recent reviews . ) whilst abc evolved initially as a practical tool , attention has begun to shift to the investigation of its formal statistical properties , including as they relate to the choice of summary statistics on which the technique typically relies ; see , for example , fearnhead and prangle ( 2012 ) , gleim and pigorsch ( 2013 ) , marin _ et al . _",
    "( 2014 ) , creel and kristensen ( 2015 ) , creel _ et al . _",
    "( 2015 ) , drovandi _",
    "et al_. ( 2015 ) , li and fearnhead ( 2015 ) and martin _ et al . _",
    "( 2016 ) .",
    "in this paper we study large sample properties of both posterior distributions and posterior means * *  * * obtained from abc . * *  * * under mild regularity conditions on the summary statistics used in abc , we characterize the rate of posterior concentration and show that the limiting shape of the posterior crucially depends on the interplay between the rate at which the summaries converge ( in distribution ) and the rate at which the tolerance used to accept parameter draws in abc shrinks to zero",
    ". critically , concentration around the truth and , hence , bayesian consistency , * *  * * places a less stringent condition on the speed with which the tolerance declines to zero than does asymptotic normality of the abc posterior .",
    "further , and in contrast to the textbook bernstein - von mises result , we show that asymptotic normality of the abc posterior mean does not necessarily require asymptotic normality of the posterior itself , with the former result being attainable under weaker conditions on the tolerance than required for the latter .",
    "validity of all of these results depends critically on the satisfaction of an identification condition guaranteeing that , asymptotically , simulated summary statistics are unique functions of parameter draws .",
    "the satisfaction of this condition is examined in several examples , with the results indicating that this condition can fail in even simple applications .    while the asymptotic properties of likelihood - based bayesian methods are now well documented in the case of finite - dimensional parameters ( see , e.g. , le cam , 1953 , walker , 1969 , and chen , 1985 ; plus textbook treatments in van der vaart , 1998 , and ghosh and ramamoorthi , 2003 ) , a thorough study on the asymptotic properties of posterior distributions obtained from so - called likelihood free methods , such as abc , has yet to be undertaken .",
    "this represents an important gap in the literature , which we look to fill with this work .",
    "existing asymptotic results are often derived under boundedness conditions for the underlying density function of the true model in the style of ibragimov and hasminskii ( 1981 ) . in the abc setting , conditions based on this density function",
    "are not practically useful since the density generating the data is by definition analytically unavailable . herein , we take a different approach and only consider conditions on the abc summaries themselves .",
    "the most stringent of these conditions ( as noted above ) *  * requires that the simulated summaries converge toward some limiting counterpart at some known rate , and that this limit counterpart , viewed as a mapping from parameters to simulated summaries , be injective .",
    "these conditions have a close correspondence with those required for theoretical validity of indirect inference and related ( frequentist ) estimators ( gourieroux _ et al_. , 1993 , heggland and frigessi , 2004 ) .",
    "our focus on all three aspects of the asymptotic behavior of abc * *  * * - * *  * * posterior consistency , limiting posterior shape , and  the asymptotic distribution of the posterior mean - is much broader than that of existing studies on the large sample properties of abc , in which the asymptotic properties of point estimators derived from abc have been the primary focus ; see , creel _ et al_. ( 2015 ) , jarsa ( 2015 ) and li and fearnhead ( 2015 ) .",
    "our approach allows for weaker conditions than those given in the aforementioned papers ,  permits a complete characterization of the limiting shape of the posterior , and distinguishes between the conditions ( on both the summary statistics and the tolerance ) required for concentration and the conditions required for specific distributional results . in particular , we highlight the fact that asymptotic normality is only one possible scenario for the limiting shape of the posterior , and that asymptotic normality of the posterior is not a necessary condition for asymptotic normality of the abc posterior mean .",
    "the separation of these two latter asymptotic results is a particular point of contrast with work cited above .",
    "our approach also allows for an exploration of asymptotic behaviour in a host of interesting situations not covered by existing results , such as cases where the summaries do not satisfy a central limit theorem , examples where summaries satisfy a central limit theorem at different rates , and situations where the tolerance used in abc converges to zero too slowly .",
    "the paper proceeds as follows . in section [ sect2 ]",
    "we briefly outline the setup and review the principles of abc .",
    "section [ aux ] discusses posterior concentration and consistency in abc , with the required identification condition given particular attention .",
    "the impact of adding statistics to a set for which consistency has already been established is also demonstrated , which has important consequences in practice . as part of this section",
    "we also specialize the results to abc based on summaries generated from estimating equations derived from an auxiliary model .",
    "section [ norm ] develops results for the limiting shape of the posterior distribution obtained by abc , whilst section [ mean ] outlines the conditions required for asymptotic normality of the posterior mean . in section [ pract ]",
    "we highlight some important implications of the theoretical results for practitioners , in particular with regard to choosing a tolerance that is optimal from a computational perspective .",
    "we then conclude the paper in section [ disc ] with a summary of the asymptotic results presented herein and the important conclusions drawn regarding implementation of abc .",
    "all proofs are collected in an appendix .",
    "we observe data @xmath0 , @xmath1 , drawn from the model @xmath2 , where @xmath3 admits the corresponding conditional density @xmath4 , and * *  * * @xmath5 . given a prior @xmath6 , the aim of abc is to produce draws from an approximation to the posterior distribution @xmath7 in the case where both the parameters and pseudo - data @xmath8 can be easily simulated from @xmath9 , but where @xmath10 is intractable .",
    "the simplest ( accept / reject ) form of the algorithm ( tavar _ _  et al . , _ _ 1997 , pritchard _ et al .",
    "_ , 1999 ) is detailed in algorithm [ abc ] .",
    "simulate @xmath11 , @xmath12 , from @xmath13 simulate @xmath14 , @xmath12 , from the likelihood , @xmath15 select @xmath11 such that:@xmath16where @xmath17 is a ( vector ) statistic , @xmath18 is a distance function ( or metric ) , and @xmath19 is the tolerance level .",
    "algorithm [ abc ] thus samples @xmath20 and @xmath21 from the joint _ _  _ _ posterior:@xmath22}{\\textstyle\\int_{\\boldsymbol{\\theta } } \\int_{\\boldsymbol{z}}p(\\boldsymbol{\\theta } ) p(\\boldsymbol{z|\\theta } ) \\mathbb{i}_{\\varepsilon } [ \\boldsymbol{z}(\\boldsymbol{\\theta } ) ] d\\boldsymbol{z}d\\boldsymbol{\\theta } } , \\]]where @xmath23:=\\mathbb{i}[d\\{\\boldsymbol{\\eta } ( \\boldsymbol{y}),\\boldsymbol{\\eta } ( \\boldsymbol{z}(\\boldsymbol{\\theta } ) ) \\}\\leq \\varepsilon ] $ ] is one if @xmath24 and zero else .",
    "is used to emphasize the dependence of the simulated @xmath21  on @xmath20 . ] clearly , when @xmath17 is sufficient and @xmath25 arbitrarily small,@xmath26approximates the exact posterior , @xmath27 , and draws of @xmath20 from @xmath28 can be used to estimate features of the true posterior . in practice",
    "however , the complexity of the models to which abc is applied implies , almost by definition , that sufficiency is unattainable .",
    "hence , in the limit , as @xmath29 , the draws can be used only to approximate features of @xmath30 for a given total number of draws , @xmath31 , reducing @xmath25 comes at a cost of reducing the probability of a draw being accepted and , hence , increasing the error associated with estimating @xmath32 using the accepted draws .",
    "the problem is exacerbated the larger is the dimension of @xmath33 ; see blum ( 2010 ) , blum _",
    "( 2013 ) , biau _",
    "et al_. ( 2014 ) and nott _ et al . _",
    "( 2014 ) . in practice",
    "@xmath25 tends to be chosen such that a certain ( small ) proportion of draws ( from the total @xmath31 ) are selected , with attempts made to reduce the ( kernel - based ) estimation error via various post - sampling corrections ( beaumont _ et al .",
    "_ , 2002 , blum , 2010 , blum and franois , 2011 ) .",
    "other work gives emphasis to choosing @xmath17 and/or the manner in which draws of @xmath20 are produced in such a way that @xmath32 is a good match to @xmath27 .",
    "this may involve the replacement of the basic accept / reject scheme with markov chain monte carlo ( mcmc ) and/or sequential monte carlo ( smc ) steps ( marjoram _ et al .",
    "_ , 2003 , sisson _",
    "et al . , _ 2007 , beaumont _",
    "et al . _ , 2009 , toni _ et al . _ , 2009 and wegmann _ et al . _ , 2009 ) ; or the selection of a vector @xmath17 that is informative in some well - defined sense",
    "; see joyce and marjoram ( 2008 ) , wegmann _ et al . _",
    "( 2009 ) , blum ( 2010 ) , and fearnhead and prangle ( 2012 ) . in this latter spirit - and mimicking the frequentist techniques of indirect inference and efficient method of moments ( emm ) ( gallant and tauchen , 1996 ) - drovandi _ et al . _",
    "( 2011 ) , gleim and pigorsch ( 2013 ) , creel and kristensen ( 2015 ) , creel _ et al_. ( 2015 ) , drovandi _ et al . _",
    "( 2015 ) and martin _ et al_. ( 2016 ) exploit an auxiliary model to produce the summary statistic vector @xmath17 .",
    "( 2016 ) invoke the asymptotic sufficiency of the mle of the auxiliary parameters as motivation for defining @xmath17 via an accurate approximating model . under strong sufficient conditions on the auxiliary likelihood ,",
    "similar to those invoked in the indirect inference literature , the authors also demonstrate consistency of the abc posterior for this particular form of @xmath33 , and for the specific ( state space ) models that are investigated therein .",
    "first , let us set some notation used throughout the remainder of the paper . define @xmath34 as the space of simulated data ; @xmath35 the range of the simulated summaries - i.e. @xmath36 ; @xmath37 a metric on @xmath38 ; @xmath39 a metric on @xmath40 ; @xmath41 a generic constant ; @xmath42 the measure generating @xmath43 ; and @xmath44 the measure generating @xmath21 .",
    "we have @xmath45 for @xmath46 , and denote @xmath47 as the true parameter value .",
    "let @xmath48 * *  * * denote the prior measure with density @xmath6 .    for sequences @xmath49 and @xmath50 , real valued , @xmath51 denotes @xmath52 , @xmath53 denotes equivalent order of magnitude , @xmath54 indicates a larger order of magnitude and the symbols @xmath55 have their usual meaning .",
    "we use @xmath56 to denote the euclidean norm , @xmath57 a matrix norm and @xmath58 the absolute value .",
    "unlike the standard notion of posterior concentration , analyzing convergence of abc posteriors requires the use of simultaneous asymptotics since @xmath59 in ( abc_post ) * *  * * depends both on @xmath60 , through @xmath33 , and @xmath25 , via the selection criterion @xmath61 . in this way , for @xmath62 , the posterior probability of @xmath63 that underpins abc is most appropriately expressed as@xmath64with this notation , we say abc is bayesian consistent ( or posterior consistent ) at @xmath65 if for any @xmath66,latexmath:[\\[\\pi \\left ( d_{1}\\{\\boldsymbol{\\theta } , \\boldsymbol{\\theta } _ { 0}\\}>\\delta    @xmath42-probability ) as @xmath68 .",
    "bayesian consistency implies that sets containing @xmath69 have posterior probability tending to one as @xmath70 with an implication of this result being the existence of a specific rate at which posterior probability concentrates on sets containing @xmath71 .",
    "we say that @xmath72 concentrates at rate @xmath73 if @xmath74 in @xmath42-probability when @xmath75 goes to infinity .    in general terms",
    ", the posterior rate of concentration is related to the rate at which information about the true parameter vector * *  * * accumulates in the sample . for abc ,",
    "information about @xmath71 is not obtained from the likelihood , assumed intractable , but through @xmath33 and , in particular , through draws from @xmath6 and @xmath76 that satisfy @xmath77 .",
    "note , in particular , that when working with a fixed dimension for the summary statistic ( vector ) @xmath78 , the abc posterior distribution learns ( and concentrates ) about @xmath20 only if @xmath78 concentrates around some fixed value @xmath79 depending on @xmath20 .",
    "therefore , the amount of information abc obtains about @xmath71 depends on two factors : ( a ) the rate at which the observed ( resp .",
    "simulated ) summaries converge to a well - defined limit counterpart @xmath80 ( resp . ,",
    "@xmath79 ) ; is non - random . ]",
    "( b ) the rate at which @xmath29 . to link both factors we consider @xmath25 as a @xmath60-dependent sequence @xmath81 as @xmath82 .",
    "hence , by connecting the abc tolerance @xmath83 and @xmath60 , we can now state the technical assumptions necessary for establishing the first * *  * * main result of the paper .    *",
    "[ a1 ] * the map @xmath84 satisfies , for @xmath85 , @xmath86 .    * [ a2 ] * there exists @xmath87 as @xmath88 for all @xmath89 , and @xmath90 monotone non - increasing in @xmath89 ( for any given * *  * * @xmath60 ) , such that @xmath91where * *  * * @xmath92 , and we assume either of the following assumptions on @xmath93 :    1 .   there exist @xmath94 and @xmath66 such that for all @xmath20 satisfying @xmath95 then @xmath96 .",
    "2 .   there exists @xmath97 such that@xmath98    * [ a3 ] * there exists some @xmath99 such that , for all @xmath100 small enough , the prior probability satisfies @xmath101 \\gtrsim \\varepsilon ^{d}.\\ ] ]    * [ a4 ] * * ( i ) * the map @xmath84 is continuous . *",
    "( ii ) * the map @xmath84 is injective and satisfies @xmath102on some open neighbourhood of @xmath71 with @xmath103 and @xmath104 .",
    "[ thm1 ] assume that assumptions * [ a1 ] * and * [ a3 ] * are satisfied .",
    "we then have the following result : if * [ a2](i ) * holds , or if * [ a2](ii ) * holds with @xmath105 such that @xmath106 , then , for @xmath75large enough , @xmath107moreover , if * [ a4 ] * holds then @xmath108all statements apply for @xmath88 and @xmath109",
    ".    not only does theorem [ thm1 ] imply posterior consistency but it also leads to a posterior concentration rate , denoted generically by @xmath110 , that depends on the deviation control @xmath90 of @xmath111 .",
    "from we see that the posterior concentration rate for @xmath79 is bounded from below by @xmath112 .",
    "we will see in section [ norm ] that this is indeed a lower bound ; see in particular equations and .    to understand the dependence on @xmath113 ,",
    "consider the following two standard situations for * [ a2]*.    1 .",
    "polynomial deviations : there exists @xmath114 and @xmath115 such that @xmath116from ( [ rho_poly ] ) we have @xmath117 , so that @xmath118 .",
    "this implies that @xmath119 , which implies , in turn , that the posterior distribution of @xmath79 concentrates at a rate that is bounded above by@xmath120to @xmath121 . note that in the case of assumption * [ a2](ii ) * , the same rate can be achieved for all @xmath97 .",
    "2 .   exponential deviations",
    ": there exists @xmath122 such that@xmath123and there exist @xmath124 such that @xmath125hence if @xmath126 is bounded from above and @xmath127 is bounded from below by @xmath128 for @xmath129 in a neighborhood of the set @xmath130 , then @xmath131 and @xmath132 .",
    "this implies in particular that if @xmath133 , one obtains posterior concentration at a rate that is bounded above by @xmath134    for instance if @xmath135 and if @xmath136 are weakly dependent , say independent and identically distributed for simplicity and with finite @xmath137-th moment for all @xmath20 in the interior of @xmath138 , then @xmath139 .",
    "furthermore , the markov inequality implies that @xmath140 ) , * *  * * @xmath141 * *  * * @xmath142 and @xmath143 on the other hand if @xmath144 allows for an exponential moment : @xmath145 , then for @xmath146 @xmath147choosing @xmath148 provided @xmath149 .",
    "thus , with reference to the case of exponential deviations , @xmath150 and @xmath151 . in both cases if the maps @xmath152 , @xmath153 and @xmath154 are continuous at @xmath71 and positive , then * [ a2](i ) * and * [ a2](ii ) * are satisfied.@xmath155    * remark 1 : * the role of assumption * [ a3 ] * in posterior concentration can be illustrated by analyzing the role played by the constant @xmath156 , which controls the degree of prior mass in a neighborhood of * *  * * @xmath157 for @xmath158 small , the larger @xmath156 is , the smaller is the amount of prior mass in the region of the truth and  with reference to case ( a )  the slower is the rate of posterior concentration in ( [ lam_poly ] ) , for any @xmath159 . furthermore , if exponential deviations are assumed ( in reference to case ( b ) above ) , the rate of posterior convergence in ( [ lam_exp ] ) is unaffected by the value of @xmath160    * remark 2 : * assumptions * [ a3 ] * and * [ a4 ] * are satisfied under regularity conditions on the inverse of the function @xmath161 .",
    "in particular , assumption * [ a4 ] * requires that the map @xmath162 behaves in the same manner as the binding function  in indirect inference ; see gouriroux _ et al . _ ( 1993 ) and gouriroux and monfort ( 1996 ) for a general discussion of binding functions . to this end , if @xmath163 , then a necessary condition for satisfying * [ a4](ii ) * is @xmath164 and @xmath165 .      convergence of the abc - based posterior depends on the particular form of @xmath79 . if @xmath166 is injective and the remaining assumptions in theorem [ thm1 ] hold , abc based on @xmath167 will be bayesian consistent .",
    "there is generally no guarantee that @xmath79 will be injective , and the satisfaction of this condition depends on both the true structural model and the particular choice of @xmath33 .",
    "example [ exams1 ] below illustrates a situation where * *  * * @xmath162 * *  * * is not injective , whilst example [ exams2 ] shows how injectivity _ can _ be achieved by adding an appropriate summary to the initial set of summaries .",
    "we further provide a general result regarding the addition of summaries to a set that already yields consistency .",
    "[ exams1 ] consider the moving average model of order two ( ma(2)):@xmath168where @xmath169 i.i.d and @xmath170 satisfy the following invertibility conditions @xmath171following marin _ et al . _",
    "( 2011 ) , we consider as our summary statistics the sample autocovariances @xmath172 , for @xmath173 consider applying the abc algorithm [ abc ] , based on @xmath174    for true value @xmath175 corresponding to the observed data @xmath43 , by the weak law of large numbers @xmath176=1+(\\theta _ { 01})^{2}+(\\theta _ { 02})^{2}$ ] and @xmath177=\\theta _ { 01}(1+\\theta _ { 02})$ ] .",
    "in addition , for @xmath178 satisfying equation , @xmath179 and @xmath180 for @xmath181 obtained from the above algorithm to be degenerate at @xmath71 it must be that for all @xmath182 , @xmath183 has a unique solution @xmath184 clearly,@xmath185as in marin _ et al . _ ( 2011 ) , take @xmath186 .",
    "then the question becomes , does there exist @xmath187 such that @xmath188numerical calculations reveal that has two solutions : @xmath189 and @xmath190 , where the latter solution remains in the feasible region for @xmath191 therefore , @xmath161 is not injective and an _ abc _ algorithm based on @xmath192 concentrates increasing posterior mass on the set @xmath193 as the sample size grows .    [ exams2 ] consider the same ma(2 ) model as in example [ exams1 ] , but now consider the use of the three - dimensional vector of summary statistics to select @xmath20 : @xmath194assumption * [ a4](ii ) * will be satisfied if the following has a unique solution @xmath46 for all @xmath195 @xmath196 : @xmath197the linear restriction , @xmath198 , ensures that the only value satisfying @xmath199 is @xmath200 , and bayesian consistency will be achieved as a consequence .    simply adding summary statistics to the abc procedure is , _",
    "however , _ not guaranteed to yield consistent inference : the chosen summary statistics must be truly informative about the underlying parameters @xmath20 governing the statistical properties of the model .",
    "to illustrate this point , consider again the above example , but with the three - dimensional vector summary statistic:@xmath201where @xmath202 clearly , @xmath203=0 $ ] and by construction @xmath204=0 $ ] for all @xmath20 .",
    "hence ,  @xmath205 yields no information about @xmath71 and will not aid in identifying @xmath71 .",
    "example [ exams2 ] demonstrates that posterior consistency can be achieved with the appropriate addition of summary statistics _ _",
    "if _ _ * *  * * those additional statistics lead to satisfaction of the required injectivity condition .",
    "however , * *  * * given that adding summary statistics for any given * *  * * @xmath206 @xmath158 and * *  * * a fixed number of simulations * *  * * @xmath31 , diminishes our ability to accurately estimate @xmath207 , adding summary statistics to any initial abc procedure must be embarked upon with care .",
    "moreover , a further question remains as to what happens if statistics that are useless for identification are added to a set that already yields posterior consistency .",
    "expressed more formally , this question means that , given @xmath33 satisfying the constraints of theorem [ thm1 ] , if we augment @xmath33 with additional summary statistics @xmath208 , not satisfying * [ a4](ii ) * of theorem [ thm1 ] , does abc based on @xmath209 still yield posterior consistency ?",
    "the following corollary answers this question in the affirmative . to make this result completely rigorous , we assume @xmath33 ( resp . ,",
    "@xmath208 ) has a well - defined limit @xmath210 ( resp . , @xmath211 ) and we denote the limit quantity of @xmath78 ( resp . ,",
    "@xmath212 ) as @xmath213 ( resp . , @xmath214 ) .",
    "[ corr1 ] if assumptions * [ a1]*-*[a4](i ) * are satisfied for @xmath215 , and if @xmath216on some open neighborhood of @xmath71 with @xmath103 and @xmath104 , then , for @xmath75 large enough , @xmath217(in @xmath42-probability ) as @xmath70 @xmath218 , so long as either @xmath219 or @xmath220 is injective .",
    "it is also important to note that the above result does not alter the earlier posterior concentration rates , provided the choice of @xmath221 is not modified .",
    "however , increasing the dimension of @xmath167 does impact on the computational time required , or equivalently , if thresholding is made by considering the @xmath222 empirical quantile of the simulated @xmath223 , the dimension of @xmath167 will have an impact on the threshold @xmath158 . a detailed discussion of this point is given in section [ sec : implications ] .",
    "an alternative mean of obtaining informative summary statistics is through the use of an auxiliary model that depends on parameters @xmath224 , where @xmath225 , and for which the likelihood function of the auxiliary model , denoted by @xmath226 , is known in closed form . given a simple auxiliary likelihood @xmath226 , a growing literature ( see , for example , drovandi _ et al_. , 2015 ; and martin _ et al_. , 2016 ) suggests using summary statistics @xmath227 where @xmath228 , or @xmath33 is taken as the vector score of @xmath226 evaluated at @xmath229 .",
    "however , by its very nature any auxiliary model , and by proxy the @xmath33 derived from @xmath226 , is ( are ) likely to describe only _ certain _ salient features of the data generating process . given this limitation , there is nothing special about choosing the auxiliary _ likelihood function _ to generate summary statistics for use within abc and other alternative criterion functions could instead be used to obtain @xmath33 in an abc algorithm .",
    "examples include sums of squared errors and least absolute deviations .    to this end",
    ", we now consider the wholly general scenario where the auxiliary model under study defines a @xmath230-dimensional vector of estimating equations based on @xmath43 ( resp",
    ". , @xmath21 ) denoted by @xmath231 ( resp . , @xmath232 ) , and @xmath229 ( resp . , @xmath233",
    ") is ( are ) defined as the corresponding zero of @xmath234 ( resp . ,",
    "@xmath235 ) ; i.e. , @xmath229 and @xmath233 are @xmath236-estimators .",
    "an abc algorithm could be obtained by simply using @xmath237 and @xmath238 ; however , such an algorithm would be computationally burdensome given the need to solve for @xmath78 at each draw .",
    "in the spirit of the score - based approach of indirect inference , gourieroux et al .",
    "( 1993 ) , gallant and tauchen ( 1996 ) , one can instead consider an abc algorithm using the estimating equations themselves .",
    "such an approach yields the following computationally attractive abc algorithm .",
    "obtain @xmath239 , simulate @xmath11 , @xmath12 , from @xmath6 simulate @xmath14 , @xmath12 , from the likelihood , @xmath15 select @xmath11 such that:@xmath240and @xmath241 is the tolerance level .",
    "the following corollary to theorem [ thm1 ] gives conditions under which ( [ consistency ] ) holds with @xmath242 and @xmath243     [ thm2 ] for an auxiliary model with parameters @xmath244 , @xmath245 compact , and sample criterion @xmath246 , if the following are satisfied :    [ b1 ] : :    there exists deterministic    @xmath247    and    @xmath248 [ b2 ] : :    * ( i ) * @xmath249 is the unique zero of    @xmath250 ;    * ( ii ) *    @xmath251 ,    for @xmath252 as    @xmath88 [ b3 ] : :    for @xmath253 and any    @xmath254 ,    @xmath255 , with @xmath57 an    appropriate matrix norm .",
    "[ b4 ] : :    for @xmath253 , and for    @xmath256and @xmath126    as in assumption * [ a2 ] * ,    @xmath257 [ b5 ] : :    * * ( i)**the map @xmath258 is continuous ;    * ( ii ) *    @xmath259 if and only if    @xmath260 [ b6 ] : :    assumption * [ a3 ] * is satisfied with    @xmath261    and    @xmath262    then , for @xmath263large enough,@xmath264(in @xmath42-probability ) as @xmath265 , _  with the rate of convergence , _",
    "@xmath266 , determined by the nature of @xmath267    * remark 3 : * if the chosen auxiliary model poorly represents the data , no set of summary statistics derived from the auxiliary model will be adequate for use in abc . in this way , using summary statistics from an auxiliary model inside of abc is not a panacea . in particular , auxiliary model - based abc can fail for precisely the same reason as abc based on arbitrary summary statistics , namely , failure of the identification condition ( condition * [ b5 ] * ) .",
    "satisfaction of * [ b5 ] * is affected by both the choice of the auxiliary model and the estimating equations used to define the auxiliary estimators .",
    "since these choices are example - specific , attempting to give hard and fast guidelines for how one should determine those selections is a separate research topic in its own right .",
    "rather , we simply advocate that validation of [ * b2*]-[*b5 * ] should at least be attempted , for any specified auxiliary model - based set of estimating equations , before implementing abc .",
    "( also , note that using several auxiliary models in parallel increases the set of summary statistics and hence the chances for identifiability and other conditions to hold . )    before ending this section , we provide support for the need to check these conditions by illustrating a case in which consistency is not yielded via a sensible abc specification : namely , the use of an ar(2 ) auxiliary model along with an ols criterion function to produce inference about the ma(2 ) model .",
    "consider again the ma(2 ) model from example 1 . instead of a summary statistic",
    "based abc approach , consider implementing abc using summary statistics generated via an ar(2 ) auxiliary model , @xmath268 , with @xmath269 and the ols estimating equations : @xmath270 given the particular structure of @xmath246 in ( [ ols ] ) , verification of the conditions * [ b1]-[b4 ] * is straightforward .",
    "therefore , all that remains is to verify * [ b5]*. @xmath232 yields the limit estimating equations @xmath271where @xmath272 denotes expectation under the simulated process .",
    "define the autocovariances , conditional on @xmath20 , as    _ 0&=(1+(_1)^2+(_2)^2),_1=(_1+_1_2),_2=_2 .",
    "we then re - write as @xmath273solving for @xmath274 in yields the following : @xmath275 } { \\left [ \\gamma _ { 0}-\\left ( \\frac{(\\gamma _ { 1})^{2}}{\\gamma _ { 0}}\\right ) \\right ] } , \\;\\;\\beta _ { 2}(\\boldsymbol{\\theta } ) : = \\frac{\\gamma _ { 2}}{\\gamma _ { 0}}-\\frac{\\gamma _ { 1}}{\\gamma",
    "_ { 0}}\\beta _ { 1}(\\boldsymbol{\\theta } ) .\\]]equations do not admit a unique solution .",
    "for example , @xmath276 yields two solutions satisfying the conditions of : @xmath277 and @xmath278 .",
    "hence , * [ b5 ] * is violated and abc will not yield posterior consistent inference in this example .",
    "there is one solution satisfying the conditions of , namely @xmath279 ( a second solution , @xmath280 , exists but does not satisfy the parameter restrictions ) . ]",
    "in this section we analyze the limiting shape of the abc posterior measure .",
    "we again take @xmath158 to be sample - size dependent , and we consider the shape of @xmath281 for various relationships between @xmath158 and the rate at which summary statistics satisfy a central limit theorem ( clt ) . * *  * * the results are expressed in terms of the posterior for @xmath79 with assumption * *  [ a4 ] * * in section [ aux ] required to state the corresponding results for the posterior of * *  * * @xmath282 * *  * * for compactness of notation , in this and the following section , we denote @xmath283 as @xmath284    we assume that there exists a sequence of positive definite matrices @xmath285 such that for all @xmath20 in a neighborhood of @xmath47 , @xmath286with @xmath287 , @xmath288 for all @xmath289 and the @xmath290 all possibly distinct .",
    "thus , we do not restrict ourselves to identical convergence rates for the components of the statistic @xmath291 .",
    "for simplicity s sake we order the components so that @xmath292for all @xmath289 , we assume @xmath293 . for any square matrix @xmath294 of dimension @xmath137 , if @xmath295 , @xmath296 } $ ] denotes the @xmath297 square upper sub - matrix of @xmath294 . also , let @xmath298 and if , for all @xmath289 , @xmath299 then @xmath300 .",
    "while assumption [ * a4 * ] requires the map @xmath162 be injective ( but not necessarily bijective ) in this section we also maintain the assumption that @xmath161 is continuously differentiable at @xmath301 , and that the jacobian @xmath302 has full rank @xmath303 .",
    "in addition to this assumption and assumptions * [ a1]*-*[a4 ] * in section [ aux ] , the following conditions are needed to establish the limiting shape of @xmath304 .    *",
    "[ a5 ] * there exists @xmath66 such that for all @xmath305 , @xmath306where @xmath307 is the @xmath308 identity matrix .    *",
    "[ a6 ] * the sequence of functions @xmath309 is equicontinuous at @xmath71 .    the following condition will only be used in cases where at least one of the coordinates satisfies @xmath310 .    * [ a7 ] * for some positive @xmath311 and all @xmath305 , and for all ellipsoids @xmath312with @xmath313 for all @xmath314 and all @xmath315 fixed , @xmath316_{[k_{1}]}(\\boldsymbol{\\eta } ( \\boldsymbol{z})-\\boldsymbol{b}(\\boldsymbol{\\theta } ) ) -u\\in b_{t}\\right ) } { \\prod_{j=1}^{k_{1}}h_{t}(j ) } & = \\varphi _ { k_{1}}(u ) , \\\\ \\frac{p_{\\boldsymbol{\\theta } } \\left ( [ \\boldsymbol{\\sigma } _ { t}(\\boldsymbol{\\theta } ) ] _ { [ k_{1}]}(\\boldsymbol{\\eta } ( \\boldsymbol{z})-\\boldsymbol{b}(\\boldsymbol{\\theta } ) ) -u\\in b_{t}\\right ) } { \\prod_{j=1}^{k_{1}}h_{t}(j ) } & \\leq h(u),\\quad \\int h(u)du<+\\infty , \\end{split } \\label{dens : cond}\\]]for @xmath317 the density of a @xmath318-dimensional normal random variate .",
    "[ normal_thm]assume that assumptions * [ a1 ] * -*[a6 ] * are satisfied and take @xmath319 an arbitrary compact .",
    "the following results hold :    * ( i ) * @xmath320 : with probability approaching one ( wpa1 ) , for @xmath321 , @xmath322    * ( ii ) * there exists @xmath323 such that @xmath324 , @xmath325 , and @xmath326 : assume that @xmath327 with @xmath328 positive definite and that @xmath329 _ { [ j]}\\right\\ } ^{2}\\leq c\\epsilon _ { t}^{2}\\right ) = + \\infty , $ ] then @xmath330    * ( iii ) * there exists @xmath331 such that @xmath332 and @xmath333 : assume that @xmath334 with @xmath328 positive definite , and that assumption * [ a7 ] * is satisfied , then is satisfied .    *",
    "( iv ) * @xmath335 for all @xmath336 or that @xmath337(j)\\right\\ } ^{2}\\leq c\\epsilon _ { t}^{2}\\right ) <",
    "+ \\infty $ ] in case * ( ii ) * : there exists a non - gaussian probability distribution on @xmath338 , @xmath339 which depends on @xmath340 and is such that @xmath341more precisely , @xmath342    * ( v ) * @xmath343 : assume that @xmath334 with @xmath328 positive definite and that assumption * [ a7 ] * , i.e. , , holds for @xmath344 , then @xmath345    * remark 4 : * theorem [ normal_thm ] asserts that the crucial feature for determining the limiting shape of the abc posterior is the behavior of @xmath346 , for @xmath347 . if @xmath348 too slowly so that some ( or all ) of the components satisfy @xmath349 , as in results * ( i)*-*(iii ) * above , the _ only _ conclusion that can be drawn is one of posterior concentration . * *  * * in short , so long as @xmath350 for all @xmath351 with strict equality for at least one @xmath289 , no bernstein - von mises ( bvm , hereafter ) result is available for the abc posterior .",
    "however , if @xmath343 , a bvm result _ is _",
    "available for the abc posterior .",
    "taking for simplicity s sake @xmath352 the intuition behind theorem [ normal_thm ] is as follows : limiting shape information in abc requires @xmath353 , while gaussianity of the limiting distribution requires the stronger condition @xmath354 . without these rate requirements ,",
    "i.e. , if * *  * * @xmath355 * *  * * the posterior concentrates in a manner that can not yield a bvm result or other shape information .",
    "when the bvm result does not hold , the posterior concentrates at the rate @xmath356 , in the sense that @xmath357for @xmath75 large enough and @xmath358if @xmath359 .",
    "the upper bound in ( [ upper ] ) is a consequence of theorem [ thm1 ] .",
    "the lower bound in ( [ lower ] ) can be deduced using similar arguments : indeed , following from equation in the proof of theorem [ thm1 ] in the appendix , we have    _ ( d_2\\ { ( ) , ( _ 0)}_t_t| ( ) ) & = + & = o(1 ) ,    where the @xmath360 term appears as a consequence of assumption [ * a3 * ] . from this reasoning",
    ", we conclude that @xmath361    * remark 5 : * the abc bvm result deduced herein is thus of a different nature than that derived in li and fearnhead ( 2015 ) , which relies on arguments similar to those of yuan and clark ( 2004 ) . in particular",
    ", the bvm result of li and fearnhead ( 2015 ) requires uniformity conditions and strict differentiability conditions on the intractable likelihood function that guarantee , among other things , the validity of a second - order taylor series expansion .",
    "conversely , the bvm result obtained herein requires no such strict differentiability conditions , nor any strict uniformity conditions .",
    "* remark 6 : * the results derived in this section , as well as all remarks made above , remain applicable in the case where @xmath167  is taken to be a vector of estimating equations derived from an auxiliary model , provided conditions * [ b1 ] * to * [ b6 ] * and conditions corresponding to those in * [ a5 ] * to * [ a7 ] * are satisfied .",
    "* remark 7 : * condition * [ a7 ] * only applies to random variables @xmath78 that are absolutely continuous with respect to lebesgue measure ( or , in the case of sums of i.i.d random variables , to sums that are non - lattice ; see bhattacharya and rao , 1986 ) .",
    "the case of discrete @xmath78 s requires an adaptation of condition * [ a7 ] * that leads to the same conclusions in theorem [ normal_thm ] . for simplicity s sake we write this adaptation in the case where @xmath362 , so that we need only study case * ( v ) * in theorem [ normal_thm ] .",
    "then * [ a7 ] * can be replaced by :    * * [ a7**@xmath363 * ] * there exist @xmath66 and a countable set @xmath364 such that for all @xmath365 , @xmath366and there exists a continuous and positive map @xmath367 at @xmath71 such that @xmath368    under this alternative condition , the conclusion of case**(v ) * * of theorem [ normal_thm ] still holds",
    ".    condition * * [ a7**@xmath369 * ] * is satisfied , for instance , in the case when @xmath78 is a sum of i.i.d .",
    "lattice random variables , as in the population genetic experiment detailed in section 3.3 of marin _ et al . _",
    "furthermore , this population genetic example is such that assumptions * [ a1 ] * -*[a6 ] * and * [ a8 ] * also hold , which means that the  conclusions of both theorems [ thm1 ] and [ normal_thm ] apply to this model .",
    "as noted above , the current literature on  the asymptotics of abc has focused primarily on conditions guaranteeing asymptotic normality of the posterior mean ( or functions thereof ) . to this end , it is important to stress that the posterior normality result in theorem [ normal_thm ] is not a weaker , or stronger , result than that of asymptotic normality of an abc point estimator ; both results simply focus on different objects .",
    "that said , existing proofs of the asymptotic normality of the abc posterior mean all require asymptotic normality of the posterior . in this section , we demonstrate that asymptotic normality of the posterior is not a _ necessary _ condition for  asymptotic normality of the abc posterior mean . to present the ideas in as transparent a manner as possible , we focus on the simple case of an unknown scalar parameter @xmath370 and known scalar summary @xmath371 .",
    "in addition to assumptions * [ a1 ] * to * [ a7 ] * , we maintain the following assumptions on the prior .",
    "[ * a8 * ] the prior density @xmath372 satisfies the following : * ( i ) * for @xmath373 , @xmath374 . *",
    "( ii ) * for some @xmath103 and all @xmath375 , @xmath376 . * ( iii ) * for @xmath377 , we have @xmath378 .",
    "[ mean_thm ] assume that assumptions * [ a1 ] * - * [ a6 ] * , together with assumption * [ a8 ] * , are satisfied and assume @xmath379 exists and is non - zero . denoting @xmath380 as the abc posterior mean",
    ", we then have the following results :    if * ( i ) * : @xmath381 or if * ( ii ) * : @xmath382 and * [ a7 ] * holds , then @xmath383    where @xmath384 $ ]    * remark 8 : * part * ( i ) * of theorem [ mean_thm ] demonstrates that asymptotic normality of the posterior mean does not require asymptotic normality of the abc posterior .",
    "however , part * ( ii ) * of theorem [ mean_thm ] states that asymptotic normality of the posterior and asymptotic normality of the posterior mean can be simultaneously achieved provided @xmath385 .    *",
    "remark 9 : * the results of theorem [ mean_thm ] completely rest  on the injectivity of the map @xmath386 .",
    "in particular , theorem [ mean_thm ] relies on the fact that if the posterior distribution of @xmath370 is given by @xmath387by the injectivity of @xmath386 , the posterior distribution of @xmath388 follows as @xmath389where @xmath390 is the transformed measure of the prior @xmath391 by @xmath392 .",
    "hence , the results of theorem [ mean_thm ] can be obtained by analyzing the posterior mean @xmath393=\\frac{\\int_{b(\\theta ) } d_{t}(b - b_{0})p_{b}\\left ( d(\\eta ( \\boldsymbol{z}),\\eta ( \\boldsymbol{y}))\\leq \\varepsilon _ { t}\\right ) d\\tilde{\\pi}(b)}{\\int_{b(\\theta ) } p_{b}\\left ( d(\\eta ( \\boldsymbol{z}),\\eta ( \\boldsymbol{y}))\\leq \\varepsilon _ { t}\\right ) d\\tilde{\\pi}(b)}.   \\label{post_mean}\\]]from , the result for @xmath394 follows from the delta theorem",
    ".    * remark 10 : * once again , under appropriate conditions , the results in this section remain applicable if @xmath395 is derived via an auxiliary model in the manner described in section [ crit ] .",
    "li and fearnhead ( 2015 ) ( hereafter , lf ) have * *  * * analyzed the asymptotic properties of the abc posterior mean , or some function thereof .",
    "( see also creel _ et al_. , 2015 . ) under a clt for the summaries and differentiability conditions for the unknown data density @xmath396 ( where we continue to reference the scalar case here for ease of exposition ) , * *  * * lf demonstrate asymptotic normality of the abc posterior mean ( or some smooth function thereof ) .",
    "heuristically , this result follows by obtaining and applying a bvm result for @xmath397 , approximating the abc posterior density @xmath398 through a taylor series , allowing the application of the aforementioned bvm result to @xmath399 , and using properties of the mle conditional on @xmath371 .",
    "the latter results and a similar bvm theorem for @xmath397 were discussed in yuan and clarke ( 2004 ) .",
    "the results of lf rely on an abc algorithm that selects draws of @xmath370 with probability @xmath400 , for some kernel function @xmath401 and bandwidth @xmath25 , with the abc posterior density assumed to satisfy @xmath402using the univariate parameter and summary case for illustration , asymptotic normality of the posterior mean in the abc approach of lf follows as a consequence of the kernel smoothing approach , which ensures that the second term in the taylor series expansion ,    p(()+_tv|l)k(v)dv&= p(()|)+__t=0v_tk(v)dv + & + _ _",
    "t=|_tv^2 ^ 2_tk(v)dv ,    is zero when @xmath401 is a symmetric kernel .",
    "the remainder term in this expansion is of the order @xmath403 . using this approximation and the requirement that @xmath404 , lf are able to use a bvm result for @xmath397 to directly obtain asymptotic normality of the posterior mean .",
    "our stricter requirement of @xmath385 for asymptotic normality of the posterior itself arises from the fact that , in contrast to the approach of lf , our analysis is carried out in the case where abc is conducted according to some accept - reject or k - nn type of abc algorithm .",
    "this particular focus , and corresponding lack of smoothing , means that a stronger condition on the tolerance is needed to obtain the bvm result .",
    "lf also demonstrate that when the dimension of @xmath371 is equivalent to that of @xmath370 , as it is in the scalar case , their weaker condition on the tolerance is sufficient for the abc posterior mean to be as ( asymptotically ) efficient as what they refer to as the mle conditional on @xmath371 ( mles ) .",
    "for the usual case in which the dimension of the summary statistic exceeds that of the parameter vector , the stronger condition @xmath385 is required for the abc posterior mean to have an asymptotic efficiency that is equivalent to that of the mles .",
    "in contrast with the results of lf , theorem [ mean_thm ] demonstrates that a bvm result for the abc posterior measure is not required for asymptotic normality of the abc posterior mean .",
    "indeed , our theorem [ mean_thm ] * ( i ) * demonstrates that asymptotic normality of the posterior mean is achievable when @xmath405 , which puts _ no _ lower bound on the speed at which @xmath158 converges to zero , so long as @xmath109 at the rate that admits posterior concentration .",
    "that is , and with reference to remark 5 above , not only does theorem [ mean_thm ] require weaker conditions than those of lf , but we also obtain asymptotic normality of the posterior mean under a broader rate condition for @xmath158 .",
    "it is common practice in abc to define the tolerance @xmath158 implicitly by considering an empirical quantile over the prior simulated distances @xmath406 .",
    "the implications of theorems [ thm1 ] and [ thm2 ] for the choice of * *  * * @xmath158 * *  * * can be extended straightforwardly to this scenario and , as we will show , several relevant practical insights into the application of abc ensue . with reference to the rates in equation ( [ d_values ] ) ,",
    "consider , for simplicity s sake , the case where @xmath407 and the distances are euclidean , * *  * * with @xmath408 .",
    "then , let us consider two cases regarding the tolerance @xmath158 : one where @xmath385 , as required for the bvm result in theorem thm2 ; and a second one where @xmath409 , as required for theorem [ thm1 ] . in the first case , using the same types of computations as in the proof of theorem [ thm2 ] in the appendix , we have , for @xmath410 @xmath411 & = \\int_{\\boldsymbol{\\theta } } p_{\\boldsymbol{\\theta } } \\left ( \\vert z_{t}-z_{t}^{0}-d_{t}(\\boldsymbol{b}(\\boldsymbol{\\theta } ) -\\boldsymbol{b}(\\boldsymbol{\\theta } _ { 0}))\\vert \\leq \\varepsilon _ { t}d_{t}\\right ) p(\\boldsymbol{\\theta } ) d\\boldsymbol{\\theta } \\\\ & \\asymp ( \\varepsilon _ { t}d_{t})^{k}\\int_{\\boldsymbol{\\theta } } \\varphi ( z_{t}^{0}+d_{t}\\boldsymbol{b}^{\\prime } ( \\boldsymbol{\\theta } _ { 0})(\\boldsymbol{\\theta } -\\boldsymbol{\\theta } _ { 0}))d\\boldsymbol{\\theta _ { { } } } \\asymp \\varepsilon _ { t}^{k}d_{t}^{k - d_{\\boldsymbol{\\theta } } } ; \\end{split}\\]]while , in the second case ( @xmath409 ) we have @xmath412 \\asymp \\int_{\\theta } \\varphi ( z_{t}^{0}+d_{t}\\boldsymbol{b}^{\\prime } ( \\boldsymbol{\\theta } _ { 0})(\\boldsymbol{\\theta } -\\boldsymbol{\\theta } _ { 0}))d\\boldsymbol{\\theta } \\asymp \\varepsilon _ { t}^{d_{\\boldsymbol{\\theta } } } .\\]]in particular",
    ", we note that choosing a tolerance , @xmath109 , is equivalent to choosing an @xmath413 quantile of @xmath414 . with regard to both cases above",
    ", choosing @xmath415 induces a tolerance @xmath416 , while taking @xmath417 induces the tolerance @xmath418 .    from the above * *  * * results we can conclude the following . first , by linking the order of @xmath158 with the quantile of the distances @xmath419 , we theoretically rationalize the oft - used practice in abc of only selecting draws of @xmath20 that yield distances in the left tail of @xmath420 .",
    "see , for example , biau _ et al_. ( 2014 ) .",
    "secondly , this construction allows us to explicitly * *  * * express the impact of @xmath421 on the choice of tolerance : everything else unchanged , the larger @xmath303 is , the smaller is the tolerance @xmath158 ( and associated quantile level , @xmath222 ) required to achieve a given level of accuracy for the selected draws in abc .",
    "this result thus gives theoretical evidence of the so - called curse - of - dimensionality encountered in abc _ as the dimension of the parameters of interest increases_. while this has been acknowledged heuristically elsewhere , to our knowledge this is the first piece of work to pinpoint the underlying cause .",
    "in addition , this finding gives theoretical justification for the commonly used dimension reduction methods in abc that treat parameter dimensions individually and independent of the other remaining dimensions ; see , for example , the regression adjustment approaches of beaumont _ et al_. ( 2002 ) and blum ( 2010 ) , and the integrated ( auxiliary ) likelihood approach of martin _ et al_. ( 2016 ) , all of which treat parameters one - at - a - time in the hope of obtaining more accurate marginal posterior inference .",
    "a third implication of the above result is that , by linking @xmath422 and @xmath222 as shown , one has a means of choosing the @xmath222quantile of the simulations ( or equivalently the tolerance @xmath158 ) in such a way that a particular type of posterior behavior is expected to be evident , at least for large  @xmath60 .",
    "that is , * *  * * if @xmath423 the posterior can be expected to concentrate , but if one is willing to impose the more stringent condition @xmath354 the posterior will both concentrate _ and _ be approximately gaussian in large samples .",
    "such results are important as they give to practitioners of abc an understanding of what to expect from the abc procedure , and a means of detecting potential issues if this expected posterior behavior is not in evidence when choosing a certain @xmath222quantile ( or tolerance @xmath158 ) .    in addition , whilst the general consensus in abc is that , everything else unchanged , choosing @xmath158 smaller yields more accurate results for larger computing budgets , these theoretical results demonstrate that what really matters for accurate abc inference is to choose @xmath424 small enough to enable the ( limiting ) shape of the posterior to be determined by the ( asymptotic behaviour of the )  summaries @xmath425 , rather than being influenced by the choice of @xmath158 itself . to this end",
    ", we can interpret the results of theorem [ thm2 ] as follows : if @xmath385 , choosing a smaller tolerance @xmath426 and re - running abc will not significantly alter the shape of the posterior ( for @xmath31 sufficiently large so that monte carlo error is minimal , and for large enough @xmath60 ) , with the result holding equivalently for choosing some quantile level such that ( with obvious notation ) @xmath427 .",
    "stated another way , once @xmath158 has reached the @xmath428 threshold , decreasing the tolerance further , at the cost of more expensive numerical computations , will not necessarily yield a more accurate posterior estimate where , by ` accurate ' we mean here an abc posterior that is in close accordance with the asymptotic gaussian distribution that obtains theoretically , under regularity .",
    "this latter result thus contradicts the existing abc wisdom that the tolerance should always be taken as small as the computing budget allows .",
    "theorem [ thm2 ] states that @xmath158 should indeed be ` small ' but , simultaneously , * *  * * it gives an upper bound on the gain in accuracy one can hope to achieve by taking @xmath158  small . *",
    "*  * * to demonstrate this idea , consider the following simple numerical illustration .",
    "the example adopted is sufficiently regular to ensure that the clt that underpins the  bvm result holds for a reasonably small sample size , and that the associated order condition on @xmath158 has some practical content .",
    "that is , the illustration highlights the fact that , despite the asymptotic foundations of the conclusions drawn above regarding the optimal choice of the tolerance @xmath158 ( or equivalently the quantile @xmath222 ) , those conclusions can be relevant even in the moderately sized samples often encountered in practice .",
    "consider the simple example where we observe a sample @xmath429 from @xmath430 and * *  * * @xmath431 and our goal is posterior inference on @xmath432 .",
    "we use as our summaries for abc inference the sample mean and variance @xmath433 , @xmath434 .",
    "the above summaries satisfy a clt at rate @xmath142 , and so if we wish to guarantee approximate posterior normality , we choose an @xmath435 quantile of the simulated distances according to @xmath436 , since we wish to conduct joint inference on @xmath437 and @xmath438 . for the purpose of this illustration",
    ", we will compare abc - based inference using four different choices of @xmath222 , where we drop the subscript @xmath60 for notational simplicity : @xmath439 @xmath440 , @xmath441 and @xmath442 .",
    "draws for @xmath443 in abc are simulated on @xmath444\\times \\lbrack .5,1.5]$ ] according to independent uniforms @xmath445 $ ] .",
    "the number of simulation draws @xmath31 is chosen so that we retain 250 accepted draws for each of the different choices ( @xmath446 ) . the exact ( finite sample )",
    "marginal posteriors of @xmath437  and @xmath438 are produced by numerically evaluating the likelihood function , normalizing over the support of the prior and marginalizing with respect to each parameter .",
    "we note that , given the sufficiency of @xmath447 , the exact marginal posteriors for @xmath448 and @xmath449 are equal to those based directly on the summaries themselves .",
    "we summarize the accuracy of the resulting abc posterior estimates , across these four quantile choices , by computing the average , over 50 replications , of the root mean squared error ( rmse ) of the abc - based estimates of the * *  * * exact posteriors for each parameter . for example , in the case of the parameter @xmath437 , we define the rmse between the marginal abc posterior , obtained using @xmath450 and denoted by @xmath451 , and the exact marginal posterior @xmath452 as @xmath453where @xmath454 is the ordinate of the abc density estimate and @xmath455 the ordinate of the exact posterior density , at the @xmath456-th grid point upon which the density is estimated .",
    "the rmse for the @xmath438 marginal is computed analogously . across the @xmath457 replications we fix @xmath458 and generate observations according to the parameter values @xmath459 .    before presenting the results across the replications ,",
    "it is perhaps instructive to consider the graphical representation of one particular run of abc ( and for each of the four different values of @xmath450 ) .",
    "figure [ fig1 ] plots the resulting marginal posterior estimates and compares these with the exact ( finite sample ) marginal posteriors of @xmath437 and @xmath438 ( respectively ) .",
    "recall that the results of theorem [ thm2 ] imply that , for large enough @xmath60 , after @xmath158 reaches a certain threshold , decreasing the tolerance further will not necessarily result in better performance of the abc algorithm .",
    "this implication is clearly in evidence in figure [ fig1 ] : in the case of @xmath437 , there is a clear visual decline in the accuracy with which abc estimates the exact marginal posterior when choosing quantiles smaller than @xmath460 ;  whilst in the case of @xmath438 , the worst performing estimate is the one associated with the smallest value of @xmath461    the results in table [ tab1 ] illustrate that qualitatively similar patterns obtain once we factor in random variation across ( 50 ) abc runs and report average rmses , each as a ratio to the value associated with @xmath462 values smaller than one thus indicate that the larger ( and , hence , less computationally burdensome ) value of @xmath450 yields ( on average ) a more accurate posterior estimate than that yielded by @xmath463 . in brief , we see that for @xmath438 , the abc estimates based on @xmath450 , @xmath464  are all more accurate ( on average ) than those based on @xmath465 , with there being no gain in accuracy ( in fact , we observe a slight decline ) beyond @xmath466 in the case of @xmath437 , estimates based on @xmath460 and @xmath467 are both more accurate that those based on @xmath465 and with there being minimal gain in pushing the quantile below @xmath468 .",
    "these numerical results clearly have important computational implications . to wit , and as we have been done in this study , the retention of 250 draws ( and , hence , the maintenance of a given level of monte carlo accuracy ) requires taking : @xmath469 for @xmath439 @xmath470 for @xmath471 , @xmath472 for @xmath441 and @xmath473 for @xmath442 .",
    "that is , the computational burden associated with decreasing the quantile in the manner indicated increases drastically : abc based on @xmath465  ( for example ) requires a value of @xmath31 that is three orders of magnitude greater than abc based on * *  * * @xmath474 , but this increase in computational burden yields no , or minimal , gain in accuracy ! * *  * * the extension of such explorations to more scenarios is beyond the scope of this paper ; however , we speculate that , with due consideration given to the properties of both the true data generating process and the chosen summary statistics and , hence , of the sample sizes for which theorem [ thm2 ] has practical content , the same sort of qualitative results will continue to hold .",
    ".rmse of the estimated marginal posterior over 50 runs of abc and across four different quantile choices ; recorded as a ratio to the rmse for abc based on the smallest quantile , @xmath475 .",
    "numbers above one signify worse performance , and numbers below one signify better performance .",
    "for all replications the sample size is held fixed at @xmath458 and each abc posterior estimate is based on 250 retained draws . [ cols=\">,>,>,>,>,>,>\",options=\"header \" , ]     [ tab1 ]",
    "in this paper we have presented , and explored the validity thereof , conditions guaranteeing certain large sample properties of abc posteriors . in particular , we give conditions guaranteeing posterior concentration , posterior normality , and asymptotic normality of the abc posterior mean .",
    "the weakest of these concepts , posterior concentration , guarantees that as @xmath476 the abc posterior concentrates all mass on sets containing the true value generating the data @xmath71 , with bayesian consistency of the abc posterior requiring a further identification condition . * *  * * identification requires that in the limit the simulated summaries are an injective function of the parameters .",
    "in addition to conditions guaranteeing that the simulated summaries satisfy a central limit theorem , this injectivity condition is also the critical requirement for abc to yield an asymptotically normal posterior for * *  * * @xmath20 and a posterior mean that is asymptotically normal . while noted briefly elsewhere , this is the first work to discuss in detail the importance of this injectivity condition to the asymptotic validity of abc .",
    "simple examples given herein demonstrate that this injectivity condition may or may not be fulfilled in practice ; the implication being that care is needed when choosing sets of summary statistics on which selection is based .",
    "the difference in the @xmath60-dependent rates at which the abc tolerance ( or , equivalently , the associated quantile of a given distribution of abc draws ) is required to go to zero , depending on the type of asymptotic result that is to be verified , has been clarified . in particular , both posterior concentration and asymptotic normality of the posterior mean require a much weaker condition on the tolerance than does asymptotic normality of the posterior  a result that is completely new in the literature . moreover , preliminary numerical investigations indicate that the order results that * *  * * have been provided for the tolerance may have significant implications for the types of tolerances used in practice",
    ". in particular , there could be little gain in accuracy in taking the tolerance ( or quantile ) below the bound required to achieve the bernstein - von mises result and , hence , in suffering the attendant increase in computational burden .",
    "the link between parameter dimension and the chosen quantile has also been formalized .    finally ,",
    "while we have not expressly considered the monte carlo error resulting from approximating the posterior measure by means of @xmath477-nearest neighbor ( k - nn ) or kernel methods , we note that there is now a well - established body of work discussing such issues .",
    "for example , blum ( 2010 )  and * *  * * biau _ et al_. ( 2014 ) give conditions on @xmath31  the number of simulation draws  and @xmath25  the abc tolerance  guaranteeing that , for any sample size * *  * * @xmath60 , the monte carlo error associated with approximating the partial posterior in ( [ abc_post ] ) converges to zero .",
    "these existing results could be considered simultaneously with our results . in this way",
    ", one could link all three quantities @xmath478 @xmath60 and @xmath25 to present a unified asymptotic framework that describes the properties of abc as @xmath478 @xmath479 and @xmath480 ; however , we leave such an endeavour for future research .",
    "let @xmath481 and assume that @xmath482 . from assumption @xmath483 @xmath484 .",
    "consider the joint event @xmath485 .",
    "we have , that for all @xmath486 @xmath487so that @xmath488 implies that @xmath489and choosing @xmath490 leads to@xmath491and      moreover , since @xmath492as soon as @xmath493 , then @xmath494if part * ( i ) * of assumption * [ a2 * ] holds , @xmath495and for @xmath158 small enough , @xmath496which combined with and assumption @xmath497 leads to @xmath498by choosing @xmath499 with @xmath500 large enough .",
    "if part * ( ii ) * of assumption * [ a2 * ] holds , a hlder inequality implies that @xmath501and if @xmath158 satisfies @xmath502then remains valid .",
    "the result follows directly from applying theorem 1 and the following observation . without loss of generality ,",
    "let @xmath219 be injective .",
    "the key observation is then that the set @xmath503 always includes the point @xmath504 , but can include other points since @xmath505 need not be injective",
    ". however , by injectivity of @xmath506 , the only value of @xmath20 for which @xmath507@xmath508is @xmath509 the result then follows by the same arguments as theorem [ thm1 ] .",
    "the proof follows similarly to that of theorem 1 and so we only sketch the proof .",
    "define , for ease of notation , @xmath510 and @xmath511 .",
    "first , let us study , for @xmath512 , the probability @xmath513where , without loss of generality , we take @xmath514 throughout . consider the set @xmath515take @xmath516 , which is satisfied under * [ b1]-[b2 ] * and the definition of @xmath517 . by the triangle inequality , for any @xmath518",
    ",                                we work with @xmath526 instead of @xmath20 as the parameter , with injectivity of @xmath527 required to re - state all results in terms of @xmath528 set @xmath529 , for @xmath530 , and @xmath321 .",
    "we bound from above the abc posterior probability that @xmath531 : @xmath532where the second equality uses the posterior concentration of @xmath533 at the rate @xmath534 .",
    "now , @xmath535set @xmath536 .",
    "the injectivity of @xmath537 and continuity of the prior at @xmath538 implies that          @xmath544 .",
    "we have , for all @xmath545 fixed , @xmath546 \\right )   \\\\ & = 1 \\end{split}\\]]when @xmath60 is large enough , uniformly in @xmath547 by the equicontinuity condition * [ a2 ] * and choosing @xmath311 small enough@xmath548with @xmath549 . since",
    "@xmath75 can be chosen arbitrarily large , * ( i ) * is proved .",
    "@xmath550 and @xmath551 . set @xmath552 such that for all @xmath553 , @xmath554 and for all @xmath555 , @xmath556 .",
    "we write @xmath557 , so that @xmath558 as @xmath60 goes to infinity , where @xmath328 is symmetric .",
    "@xmath559where @xmath560 and @xmath561 .",
    "we then have for @xmath562 such that @xmath563 .",
    "@xmath564this implies that for all @xmath545 and all @xmath565 @xmath566since @xmath567 , if @xmath329 _ { [ j]}\\right\\ } ^{2}\\leq c\\varepsilon _ { t}^{2}\\right ) = + \\infty $ ] , then similarly to case * ( i ) * we can bound @xmath568which goes to zero when @xmath75 goes to infinity . since",
    "@xmath75 can be chosen arbitrarily large , is proven .",
    "@xmath569 and @xmath570 .",
    "we have similarly to the computations leading to : setting @xmath571 , under assumption * [ a7 ] * , @xmath572})(1+o(1))\\prod_{j=1}^{k_{1}}(d_{t}(j)\\varepsilon _ { t } ) , \\end{split}\\]]when @xmath573 where @xmath574 is the centered gaussian density of the @xmath318 dimensional vector , with covariance @xmath575}$ ] .",
    "this implies as in case * ( ii ) * that @xmath576})dx}{\\int_{|x|\\leq m}\\varphi _ { k_{1}}(x_{[k_{1}]})dx}\\leq m^{-(k - k_{1})}+o(1)\\]]and choosing @xmath75 arbitrary large leads to .    if @xmath577 for all @xmath336 . to prove",
    ", we use the computation of case * ( ii ) * with @xmath578 , so that implies that @xmath579and for all @xmath66 , choosing @xmath75 large enough , and when @xmath60 is large enough @xmath580since @xmath75 can be chosen arbitrarily large and since when @xmath75 goes to infinity , @xmath581 is proved .",
    "we shall prove that if , for @xmath584 and @xmath585 , we define @xmath586 ( with @xmath587 ) , then @xmath588we first bound from above the numerator .",
    "note that @xmath589 and that @xmath590 .",
    "denote @xmath591 , then @xmath592where the condition @xmath405 is used in the representation of the real line over which the integral defining @xmath593 is specified**. * *    we first study the second integral term after the inequality . if @xmath594 then @xmath595 implies that @xmath596 and choosing @xmath75 large enough implies that if @xmath597 , @xmath598similarly the last term in @xmath593 can be bounded by @xmath599finally we study the middle term in @xmath593 . using the assumption that @xmath600 is lipshitz at @xmath601 , @xmath602with @xmath75 fixed but arbitrarily large . by the dominating convergence theorem and the gaussian limit of @xmath603 , @xmath604moreover",
    "if @xmath603 is continuous @xmath605or else , for the same reasons as above , @xmath606this implies that @xmath607where the @xmath608 holds as @xmath60 goes to infinity .",
    "we now study the denominator .",
    "when @xmath609 , @xmath610 contains @xmath611 so that , since @xmath612 in this region , @xmath613and @xmath614 in conclusion , holds and @xmath615 -z_{t}^{0}=o_{p}(1)\\]]since @xmath616 is asymptotically gaussian with mean 0 and variance @xmath617 the same holds for @xmath618 .",
    "fearnhead , p. and prangle , d. 2012 .",
    "constructing summary statistics for approximate bayesian computation : semi - automatic approximate bayesian computation .",
    "_ j. royal statistical soc .",
    "series b _ , 74 , 419474 .",
    "nott d. , fan , y. , marshall , l. and sisson , s. 2014 .",
    "approximate bayesian computation and bayes linear analysis : towards high - dimensional abc , _ journal of computational and graphical statistics _",
    ", 23 , 6586 .",
    "pritchard , j.k .",
    ", seilstad , m.t . , perez - lezaun , a. and feldman , m.w .",
    "population growth of human y chromosomes : a study of y chromosome microsatellites , _ molecular biology and evolution _ , 16 , 17911798 ."
  ],
  "abstract_text": [
    "<S> approximate bayesian computation ( abc ) is becoming an accepted tool for statistical analysis in models with intractable likelihoods . with the initial focus being primarily on the practical import of abc , exploration of its formal statistical properties has begun to attract more attention . in this paper </S>",
    "<S> we consider the asymptotic behavior of the posterior obtained from abc and the ensuing posterior mean . </S>",
    "<S> we give general results on : ( i ) the rate of concentration of the abc * *  * * posterior on sets containing the true parameter ( vector ) ;  ( ii ) * *  * * the limiting shape of the posterior ; and  ( iii ) the asymptotic distribution of the abc posterior mean . </S>",
    "<S> these results hold under given rates for the tolerance used within abc , mild regularity conditions on the summary statistics , and a condition linked to identification of the true parameters . using simple illustrative examples that have featured in the literature , </S>",
    "<S> we demonstrate that the required identification condition is far from guaranteed . </S>",
    "<S> the implications of the theoretical results for practitioners of abc are also highlighted . </S>"
  ]
}