{
  "article_text": [
    "the cern virtual machine file system ( cvmfs )  @xcite is widely adopted by the high energy physics ( hep ) community for the distribution of project software .",
    "cvmfs is a read - only network file system that provides access to files from a cvmfs server over http .",
    "when cvmfs is used on a cluster of worker nodes , a http web proxy can be used to cache the file system contents , so that all subsequent requests for that file will be delivered from the local http proxy server .",
    "typically , a hep computing site has a local or regional squid http web proxy  @xcite , with the central cvmfs servers located at the main laboratory , such as cern for the lhc experiments .",
    "the use of iaas cloud resources is becoming a realistic solution for hep workloads  @xcite , and cvmfs is an effective means of providing the software to the virtual machines ( vms ) .",
    "each vm has a list of the available squid servers and , in most cases , the squids are remote",
    ". the optimal squid may be different depending on the location of the cloud .",
    "further , one can imagine dynamically instantiating squid servers in an opportunistic cloud environment to meet application demand .",
    "however , there is currently no mechanism for locating the optimal squid server . as a result",
    ", we have developed as a new service that can dynamically publish and advertise the available squid servers .",
    "is ideal for an environment using both static and dynamic squid servers .",
    "is divided into three logical modules , a server , an agent , and a client .",
    "each package is uploaded to the python package index  @xcite ( the standard method of distributing new components in the python language ) .",
    "each component is designed to provide the functionality of different parts of the system as follows :    shoal server : :    - is responsible for the following key tasks :    +    1 .   maintaining a list of active squid servers in volatile memory and    handling amqp messages sent from active squid servers .    2 .",
    "providing a restful interface for clients to retrieve a list of    geographically closest squid servers .",
    "3 .   providing basic support for web proxy auto - discovery protocol    ( wpad ) .    4 .   providing a web user interface to easily view squid servers",
    "being    tracked .",
    "shoal agent : :    - is a daemon process run on squid servers to send an advanced message    query protocol ( amqp )  @xcite message to server on a set interval .",
    "every squid server wishing to publish its existence runs agent on    boot .",
    "agent sends periodic heartbeat messages to the server ( typically    every 30 seconds ) .",
    "shoal client : :    - is used by worker nodes to query server to retrieve a list of    geographically nearest squid servers via the    rest interface .",
    "client is designed to be simple ( less than 100 lines    of python ) with no dependencies beyond a standard python installation .",
    "figure  [ shoal - image ] shows an overview of and the interaction between each module .",
    "server runs at a centralized location with a public ip address . for agents ( i.e.  squid servers )",
    ", server will consume the heartbeat messages sent and maintain an up - to - date list of active squids . for clients",
    ", server will return a list of squids organized by geographical distance and load . for regular users of server ,",
    "a web server is provided .",
    "the web server generates dynamic web pages that display an overview of .",
    "all of the tracked squid servers are displayed and updated periodically on server s web user interface , and all client requests are available in the access logs .",
    "amqp forms the communications backbone of server .",
    "all information exchanges between agent ( squid servers ) and server are done using this protocol , and all messages are routed through a rabbitmq  @xcite server .",
    "figure  [ rabbitmq - flowchart ] gives a high level overview of message routing between agents and server .",
    "the exchange will route the message according to a routing key that is set on the agent , and can be dynamic .",
    "the message will enter through the exchange and will then be delivered to a specific queue .",
    "server creates this queue , and will receive all messages sent to the specific exchange .",
    "if server is not running , all messages sent to the exchange will be discarded as there will be no queue for them to be routed to .",
    "more complicated routing can be done with the exchange - queue system , but currently it is a simple message hand - off from exchange to queue .",
    "was designed to handle large numbers of requests for the location of squid caches and to receive continuous updates from many squid caches .",
    "amqp was selected for the method of communication between agent and server because of its robustness and the possibility of using message queues to scale system components horizontally .        in order to ensure that the amqp messaging system would work effectively ,",
    "a rabbitmq server was configured on a vm running scientific linux  6.3  @xcite with 1 gb of ram and a single processing core .",
    "the server was sent 10000 agent messages per minute and the load average  @xcite was measured over a period of three minutes .",
    "this is equivalent to 5000 squid agents contacting the server every 30 seconds .",
    "figure [ shoalserver - loadavg-5000squid ] shows that the system load average during the test was consistently below 0.5 , showing that rabbitmq can handle a significant load with minimal resources .    in order to ensure",
    "that is able to function at the scale required , a number of benchmark tests were performed .",
    "the server was set up on a 16 core x86_64 machine with 64 gb of ram .",
    "a rabbitmq server was set up on the previously described virtual machine .",
    "a client machine with the apache benchmarking tool _ ab _  @xcite was set up to access the server with a configurable number of parallel accesses , thus simulating the load from many worker nodes .",
    "+        the top plot in figure  [ apache - rt-10 ] shows the response time of the server as a function of the number of squid servers .",
    "the test was conducted using 1 , 100 , 200 , and 400 concurrent connections .",
    "we observed that the response times increased roughly linearly with the number of squid caches , with an approximate slope of 10 ms per 1000 squid caches .",
    "the bottom plot of figure  [ apache - rt-10 ] shows the same benchmark with the data plotted as total number of requests which can be satisfied per second .",
    "we see that a single server , tracking 800 squid servers , is able to respond to 1000 requests per second .",
    "this is equivalent to handling 1.8 million worker nodes requesting their nearest squid proxy every 30 minutes , demonstrating that has sufficient scalability for large - scale deployments .",
    "the algorithm for finding the nearest squid server can be substantially improved if a temporary cache is used for different ip subnets .",
    "this would allow server to use a hash table to store the nearest squid servers , reducing the majority of restful api calls to complete in @xmath0 time , whereas in its current implementation each web request requires @xmath1 time , where _ n _ is the number of tracked squids .",
    "work is underway to authenticate the squid caches registering with the server using secure socket layer and x.509  @xcite certificates .",
    "this measure is necessary to prevent malicious squids from advertising themselves to the server .",
    "however , it is important to note that the cvmfs repositories are cryptographically signed , so malicious squid caches pose a denial of service risk for cvmfs rather than a code injection risk .",
    "we have developed a highly scalable application , called , for tracking and utilizing a distributed set of squid http web caches .",
    "we see that a single server tracking 800 squid servers is able to respond to 1000 client requests per second .",
    "this is equivalent to handling over 1 million worker nodes requesting their nearest squid proxy every 30 minutes , demonstrating that can scale for massive deployments .",
    "the support of canarie and the natural sciences and engineering research council of canada are acknowledged ."
  ],
  "abstract_text": [
    "<S> we have developed a highly scalable application , called , for tracking and utilizing a distributed set of http web caches . </S>",
    "<S> our application uses the squid http cache . </S>",
    "<S> squid servers advertise their existence to the server via amqp messaging by running agent . </S>",
    "<S> the server provides a simple rest interface that allows clients to determine their closest squid cache . </S>",
    "<S> our goal is to dynamically instantiate squid caches on iaas clouds in response to client demand . provides the vms on iaas clouds with the location of the nearest dynamically instantiated squid cache . in this paper , we describe the design and performance of . </S>"
  ]
}