{
  "article_text": [
    "since the early work of hahn and lindquist@xcite , smarr@xcite and eppley @xcite , numerical relativity has become an important subfield of the theory of gravitation . to outsiders",
    "the progress often seems marginal and unsatisfactory .",
    "the classic goal of providing waveform catalogs for the newly built gravitational wave detectors has still not been reached ( although considerable progress has been made recently @xcite ) . by the nature of general relativity",
    ", the simulation of isolated systems poses particularly hard problems .",
    "mathematically such systems can be formalized by the concept of asymptotically flat spacetimes ( see e.g. the standard textbook of wald @xcite ) , but it turns out that important quantities such as the total mass , ( angular ) momentum or emitted gravitational radiation can only consistently be defined at infinity .",
    "the traditional approach of introducing an arbitrary spatial cutoff introduces ambiguities and is not satisfactory at least from a mathematical point of view .",
    "a remedy is suggested by conformal compactification methods , such as the characteristic approach presented by luis lehner in this volume , or friedrich s conformal field equations , which he describes in this volume .",
    "the latter approach avoids the problems associated with the appearance of caustics in the characteristic formulation by allowing to foliate the compactified metric by spacelike hypersurfaces .",
    "these hypersurfaces are analogous to the standard hyperboloid in minkowski spacetime and are _ asymptotically null _ in the physical spacetime .",
    "the price to pay is the loss of the simplicity inherent in the use of null coordinates , and one has to deal with the full complexity of 3 + 1 numerical relativity .",
    "the fundamental ideas of the numerical solution of the conformal field equations have been laid out by frauendiener in this volume , and in a _ living review _",
    "@xcite , and he has also discussed his code to treat spacetimes with a hypersurface - orthogonal killing vector and toroidal @xmath0 s . the purpose of the present article is to show the status of numerical simulations based on the conformal field equations in 3d ",
    "i.e. three space dimensions without assuming any continuous symmetries  and to discuss what is needed in order to render this approach a practical tool to investigate physically interesting spacetimes . by making future null infinity accessible to ( completely regular and well defined ) local computations , the approach excels at the extraction of radiation  e.g. the quantities to hopefully be measured within the next years by new large - scale detectors .",
    "one of the main pedagogical goals will be to explain the challenges of numerical relativity and to highlight some open problems related to constructing hyperboloidal initial data and actually carrying out long - time stable and accurate simulations .",
    "for an even more condensed account of the conformal approach to numerical relativity see @xcite .",
    "the organization is as follows : sec .",
    "[ sec : algorithms ] introduces the algorithms developed in the last years by peter hbner ( the radiation extraction procedure , which i will only mention briefly , is based on work of hbner and marsha weaver ) , and implemented in a set of codes by peter hbner ( who has recently left the field ) .",
    "all results presented here have been obtained with these codes , which hbner has described in a series of articles @xcite .",
    "[ sec : weakdata ] will start with a brief description of the evolution of weak initial data which possess a regular point @xmath1 representing future timelike infinity , based on the work of hbner @xcite .",
    "then i will discuss the evolution of slightly stronger initial data which exhibit various problems that will have to be solved , e.g. the choice of gauge , and use this as a starting point for discussing the main current problems . in sec .",
    "[ sec : computational ] purely computational aspects of this project will be discussed , and in sec .",
    "[ sec : discussion ] i will sum up the current status and sketch a possible roadmap for further work .",
    "the conformal field equations are formulated in terms of an unphysical lorentzian metric @xmath2 defined on an unphysical manifold @xmath3 which gives rise to a physical metric @xmath4 , where the conformal factor @xmath5 is determined by the equations .",
    "the physical manifold @xmath6 is then given by @xmath7 .",
    "contrary to the formalism used by frauendiener in his contribution , we use a metric based formulation of the conformal field equations : [ konfgl ] @xmath8 here the ricci scalar @xmath9 of @xmath2 is considered a given function of the coordinates . for any solution @xmath10 , @xmath11 is the traceless part of the ricci tensor , and @xmath12 the weyl tensor of  @xmath2 . note that the equations are regular even for @xmath13 .",
    "these `` conformal field equations '' render possible studies of the global structure of spacetimes , e.g. reading off radiation at null infinity , by solving regular equations .",
    "the 3 + 1 decomposition of the conformal geometry can be carried out as usual in general relativity , e.g. @xmath14 where @xmath15 and @xmath16 are the riemannian 3-metrics induced by @xmath2 respectively @xmath17 on a spacelike hypersurface with unit normals @xmath18 , and equivalently @xmath19 ( our signature is @xmath20 ) .",
    "the relation of the extrinsic curvatures ( @xmath21 , @xmath22 ) is then easily derived as @xmath23 , where @xmath24 .",
    "note that for regular components of @xmath15 and @xmath25 , the corresponding components of @xmath16 and @xmath26 with respect to the same coordinate system will in general diverge due to the compactification effect .",
    "however for the coordinate independent traces @xmath27 , @xmath28 we get @xmath29 which can be assumed regular everywhere .",
    "note that at @xmath0 , @xmath30 . since @xmath31 is an ingoing null surface ( with @xmath32 but @xmath33 )",
    ", we have that @xmath34 at @xmath31 .",
    "it follows that @xmath35 at @xmath31",
    ". we will thus call regular spacelike hypersurfaces in @xmath3 hyperboloidal hypersurfaces , since in @xmath6 they are analogous to the standard hyperboloids @xmath36 in minkowski space , which provide the standard example .",
    "since such hypersurfaces cross @xmath0 but are everywhere spacelike in @xmath3 , they allow to access @xmath0 and radiation quantities defined there by solving a cauchy problem ( in contrast to a characteristic initial value problem which utilizes a null surface slicing ) .",
    "note that hyperboloidal hypersurfaces which cross @xmath31 are only cauchy surfaces for the _ future _ domain of dependence of the initial slice of @xmath6 , we therefore call our studies _",
    "we will not discuss the full @xmath37 equations here for brevity , but rather refer to @xcite .",
    "what is important , is that the equations split into symmetric hyperbolic evolution equations plus constraints which are propagated by the evolution equations @xcite .",
    "the evolution variables are @xmath15 , @xmath25 , the connection coefficients @xmath38 , projections @xmath39 and @xmath40 of the traceless 4-dimensional ricci tensor @xmath41 , the electric and magnetic components of the rescaled weyl tensor @xmath42 @xmath43 , @xmath44 , as well as @xmath5 , @xmath45 , @xmath46 , @xmath47  in total this makes @xmath48 quantities .",
    "in addition the gauge source functions @xmath49 , @xmath9 and @xmath50 have to be specified , in order to guarantee symmetric hyperbolicity they are given as functions of the coordinates . here @xmath49 determines the lapse as @xmath51 and @xmath50 is the shift vector .",
    "the ricci scalar @xmath9 can be thought of as implicitly steering the conformal factor @xmath5 .",
    "the numerical treatment of the constraints and evolution equations will be described below .",
    "but before , let us spend some time on general considerations about the treatment of null infinity .",
    "since @xmath5 is an evolution variable and not specified a priori , @xmath0 will in general not be aligned with grid points , and interpolation has to be used to evaluate computed quantities at locations of vanishing @xmath5 . for the physically interesting case of modeling an isolated system , `` physical '' @xmath0  i.e. the component of @xmath0 that idealizes us outside observers and our gravitational wave detectors ( neglecting cosmological effects such as redshift etc . )",
    " has spherical topology",
    ". there may be more than one component of @xmath0 , i.e. additional spherical components associated with `` topological black holes '' ( see sec .",
    "[ subsec : bh ] ) . in principle",
    "it is possible of course to control the movement of @xmath0 through the grid by the gauge choice ",
    "see @xcite for how to achieve such @xmath0 _ fixing _ within frauendiener s formulation .",
    "an example would be the so called @xmath0 _ freezing _ , where @xmath0 does not change its coordinate location .    what is the significance of how @xmath0 moves through the grid ?",
    "this question is directly related to the question for the global structure of spacetime .",
    "although many questions are left open , the present understanding of the global structure of generic vacuum spacetimes , which can be constructed from regular initial data , does provide some hints .",
    "first , note that spacetimes which are asymptotically flat in spacelike and null directions ",
    "i.e. isolated systems  do not necessarily have to be asymptotically flat in timelike directions .",
    "an example would be a spacetime that contains a star or a black hole .",
    "in such cases where the end state of the system is not flat space , we can not expect the conformal spacetime @xmath52 to contain a regular point @xmath1 . in the case of sufficiently weak data however , friedrich has shown in @xcite that a regular point @xmath1 will exist[fig : slicings ]  consistent with our intuition .",
    "the global structure is then similar to minkowski space .",
    "the standard conformal compactification of minkowski space is discussed in textbooks ( see e.g. @xcite ) as a mapping to the einstein static universe .",
    "there @xmath0 moves inward and contracts to a point within finite coordinate time . in order to resolve such situations",
    "it seems most appropriate to choose a gauge which mimics this behavior , i.e. where @xmath0 contracts to a point after finite coordinate time .",
    "the boundary of the computational domain is set in the unphysical region and the physical region contracts in coordinate space .",
    "accordingly , the initial data are also extended beyond the physical region of spacetime .",
    "it is this scenario which is best understood so far , and which is presented in some more detail in sec .",
    "[ sec : weakdata ] .    for sufficiently strong regular data it is known that singularities develop @xcite  according to the cosmic censorship conjecture @xcite such singularities",
    "should generically be hidden inside of black holes .",
    "for such data we can not expect a regular point @xmath1 to exist . in the case when @xmath1 is singular ( and not much else is currently known even about the @xmath1 of kruskal spacetime ",
    "see however bernd schmidt s contribution in this volume ) we have to expect structure like sharp gradients near @xmath1 , which makes it unlikely that we can afford to significantly reduce the size of the physical region in coordinate space ( at least not without adaptive mesh refinement  a technology not yet available for 3d evolutions ) .",
    "a @xmath0-freezing gauge may be appropriate for such a situation .",
    "furthermore , phenomena like quasi - normal ringdown , or the orbital motion of a two - black hole system suggest that the numerical time - coordinate better be adapted to the intrinsic time scale of the system . associated with quasi - normal ringdown for example is a fixed period in bondi - time , which suggests bondi time as a time coordinate near @xmath0 in a situation dominated by ringdown .",
    "thus , for black hole spacetimes it might turn out that the best choice of gauge fixes @xmath0 to a particular coordinate position , and shifts @xmath1 into the infinite future .",
    "it could be possible that in such a case the boundary can be chosen to either coincide with @xmath0 , or to be put just a small number of gridpoints outside , which would raise the question for an evolution algorithm that does not require a topologically rectangular grid .",
    "we see that the optimal choice of numerical algorithms and gauges may be tightly related to the global structure of the investigated spacetimes  which is actually one of the main questions our simulations should be able to answer !",
    "evolution of a solution to the einstein equations starts with a solution to the constraints .",
    "the constraints of the conformal field equations ( see eq . ( 14 ) of ref .",
    "@xcite ) are regular equations on the whole conformal spacetime @xmath52 .",
    "however , they have not yet been cast into a standard type of pde system , such as a system of elliptic pdes .",
    "one therefore resorts to a 3-step method @xcite :    1 .   obtain data for the einstein equations : the first and second fundamental forms @xmath16 and @xmath53 induced on @xmath54 by @xmath17 , corresponding in the compactified picture to @xmath15 , @xmath55 and @xmath5 and @xmath45 .",
    "this yields so - called `` minimal data '' .",
    "2 .   complete the minimal data on @xmath56 to data for _ all _ variables using the conformal constraints  _ in principle _ this is mere algebra and differentiation .",
    "3 .   extend the data from @xmath56 to @xmath57 in some ad hoc but sufficiently smooth and `` well - behaved '' way .    in order to simplify the first step ,",
    "the implementation of the code is restricted to a subclass of hyperboloidal slices where initially @xmath53 is pure trace , @xmath58 .",
    "the momentum constraint @xmath59 then implies @xmath60 .",
    "we always set @xmath35 . in order to reduce the hamiltonian constraint @xmath61 to _ one _ elliptic equation of second order",
    ", we use a modified lichnerowicz ansatz @xmath62 with _ two _ conformal factors @xmath63 and @xmath64 . the principal idea is to choose @xmath15 and @xmath63 , and solve for @xmath64 , as we will describe now .",
    "first , the `` boundary defining '' function @xmath63 is chosen to vanish on a 2-surface @xmath65  the boundary of @xmath56 and initial cut of @xmath0  with non - vanishing gradient on @xmath65 .",
    "the topology of @xmath65 is chosen as spherical for asymptotically minkowski spacetimes .",
    "then we choose @xmath15 to be a riemannian metric on @xmath57 , with the only restriction that the extrinsic 2-curvature induced by @xmath15 on @xmath65 is pure trace , which is required as a smoothness condition @xcite . with this ansatz @xmath66 is singular at @xmath65 , indicating that @xmath65 represents an infinity .",
    "the hamiltonian constraint then reduces to the yamabe equation for the conformal factor @xmath64 : @xmath67 this is a semilinear elliptic equation  except at @xmath65 , where the principal part vanishes for a regular solution .",
    "this however determines the boundary values as @xmath68 existence and uniqueness of a positive solution to the yamabe equation and the corresponding existence and uniqueness of regular data for the conformal field equations using the approach outlined above have been proven by andersson , chruciel and friedrich  @xcite .",
    "solutions to the yamabe equation  and thus minimal initial data  can either be taken from exact solutions or from numerical solutions of the yamabe equation . exact solutions which possess a @xmath0 of spherical topology have been implemented for minkowski space and for kruskal spacetime ",
    "see the contribution of bernd schmidt in this volume .",
    "these solutions are defined even outside of @xmath0 , and thus can directly be completed to initial data for all variables by using the conformal constraints .",
    "if the yamabe equation is solved numerically , the boundary has to be chosen at @xmath65 , the initial cut of @xmath0 , with boundary values satisfying eq .",
    "( [ boundaryvals ] ) .",
    "if the equation would be solved on a larger ( more convenient cartesian ) grid , generic boundary conditions would cause the solution to lack sufficient differentiability at @xmath65 , see hbner s discussion in @xcite .",
    "this problem is due to the degeneracy of the yamabe equation at @xmath69 .",
    "unfortunately , this means that we have to solve an elliptic problem with _",
    "spherical boundary_. this problem is solved by combining the use of spherical coordinates with pseudo - spectral collocation methods . in pseudo - spectral methods",
    "the solution is expanded in ( analytically known ) basis functions  here a fourier series for the angles and a chebychev series for the radial coordinate . for an introduction to pseudo - spectral methods",
    "see e.g. @xcite .",
    "this allows to take care of coordinate singularities in a clean way , provided that all tensor components are computed with respect to a regular ( e.g. cartesian ) basis and that no collocation points align with the coordinate singularities .",
    "another significant advantage of spectral methods is their fast convergence : for smooth solutions they typically converge exponentially with resolution .",
    "the necessary conversions between the collocation and spectral representations are carried out as fast fourier transformations with the fftw library @xcite .",
    "the nonlinearities are dealt with by a newton iteration @xcite , the resulting linear equations are solved by an algebraic multigrid linear solver ( the amg library @xcite ) .    the constraints needed to complete minimal initial data to data for all evolution variables split into two groups : those that require divisions by the conformal factor @xmath5 to solve for the unknown variable , and those which do not .",
    "the latter do not cause any problems and can be solved without taking special care at @xmath70 .",
    "the first group , needed to compute @xmath71 , @xmath43 and @xmath44 , however does require special numerical techniques to carry out the division , and furthermore it is not known if their solution outside of @xmath0 actually allows solutions which are sufficiently smooth beyond @xmath0 .",
    "thus , at least for these we have to find some ad - hoc extension .",
    "note that in the case of analytical minimal data , the additional constraints are solved on the whole time evolution grid .",
    "the simplest approach to the division by @xmath5 would be an implementation of lhospital s rule , however this leads to nonsmooth errors and consequently to a loss of convergence @xcite . instead hbner @xcite has developed a technique to replace a division @xmath72 by solving an elliptic equation of the type ( actually some additional terms added for technical reasons are omitted here for simplicity ) @xmath73 for @xmath74 .",
    "for the boundary values @xmath75 , the unique solution is @xmath76 . for technical details",
    "see @xcite .",
    "the resulting linear elliptic equations for @xmath74 are solved by the same numerical techniques as the yamabe equation . for technical details",
    "see hbner @xcite .",
    "finally , we have to extend the initial data to the full cartesian spatial grid in some way .",
    "since solving all constraints also outside of @xmath0 will in general not be possible in a sufficiently smooth way , we have to find an ad hoc extension , which violates the constraints outside of @xmath0 but is sufficiently well behaved to serve as initial data .",
    "the resulting constraint violation is not necessarily harmful for the evolution , since @xmath0 causally disconnects the physical region from the region of constraint violation . on the numerical level , errors from the constraint violating region _",
    "will _ in general propagate into the physical region , but if our scheme is consistent , these errors have to converge to zero with the convergence order of the numerical scheme ( fourth order in our case )",
    ". there may still be practical problems , that prevent us from reaching this aim , of course : making the ad - hoc extension well behaved is actually quite difficult , the initial constraint violation may trigger constraint violating modes in the equations , which take us away from the true solution , singularities may form in the unphysical region , etc . since the time evolution grid is cartesian",
    ", its grid points will in general not coincide with the collocation points of the pseudo - spectral grid .",
    "thus fast fourier transformations can not be used for transformation to the time evolution grid .",
    "the current implementation instead uses standard discrete ( `` slow '' ) fourier transformations , which typically take up the major part of the computational effort of producing initial data .",
    "it turns out , that the combined procedure works reasonably well for certain data sets . for",
    "other data sets the division by @xmath5 is not yet solved in a satisfactory way , and constraint violations are of order unity for the highest available resolutions . in particular this concerns the constraint @xmath77 ( eq .",
    "( 14d ) in @xcite ) , since @xmath43 is computed last in the hierarchy of variables and requires two divisions by @xmath5 .",
    "further research is required to analyze the problems and either improve the current implementation or apply alternative algorithms .",
    "ultimately , it seems desirable to change the algorithm of obtaining initial data to a method that solves the conformal constraints directly and therefore does not suffer from the current problems .",
    "this approach may of course introduce new problems like an elliptic system too large to be handled in practice .      since the standard definition of a black hole as the interior of an event horizon is a global concept , it is a priori not clear what one should consider as `` black hole initial data '' . in practice ,",
    "the singularity theorems @xcite and the assumption of cosmic censorship @xcite usually lead to the identification of `` black hole initial data '' with data that contain apparent horizons , and to associate the number of apparent horizons with the number of black holes in the initial data .",
    "a common strategy to produce apparent horizons is to use topologically nontrivial data , that is data which possess more than one asymptotically flat region . in the time - symmetric case such data obviously possess a minimal surface !",
    "asymptotic ends that extend to spatial infinity @xmath78 are relatively easy to produce by compactification methods , see e.g. @xcite or the contribution of dain in this volume . from the numerical point of view",
    "it is important that the topology of the computational grid is independent of the number of asymptotic regions or apparent horizons considered : suitable regularization procedures allow to treat spatial infinities as grid points .    in the current approach to the hyperboloidal initial value problem , where first the yamabe equation needs to be solved , the grid topology _ does depend _ on the number of topological black holes  in this case the number of initial cuts of @xmath0 s , which have spherical topology .",
    "one option would be of course to combine both ingredients and consider `` mixed asymptotics '' initial data , which extend to the physical @xmath0 and to unphysical interior spacelike infinities which only serve the purpose of acting as `` topological sources '' for apparent horizons .",
    "another option , suggested by hbner in @xcite , is to generalize the current code for the initial data , which only allows for one cut of @xmath0 , which has spherical topology , to multiple @xmath0 s of spherical topology . for the case of one black hole",
    "this would correspond to the relatively simple modification to @xmath79 topology . for the case of two black holes one could implement the schwarz alternating procedure ( as described in sec .",
    "6.4.1 of ref .",
    "@xcite ) to treat three @xmath0 s with three coordinate patches , where each patch is adapted to a spherical coordinate system with its @xmath0 . a more practical approach ( at least to get started ) could be to produce topologically trivial black hole initial data .",
    "since we expect physical black holes to result from the collapse of topologically trivial regular initial data , such data would in some sense be more physical .",
    "theorems on the existence of apparent horizons in cauchy data have been presented by beig and  murchadha in @xcite . numerical studies in this spirit",
    "have been performed by the author @xcite .",
    "such data could in principle be produced with the current code once it gets coupled to an apparent horizon finder . for the hyperboloidal initial value problem it is actually not known , whether such data actually exist , but it seems physically reasonable .",
    "finding such data numerically by parameter studies would be an interesting result in itself .",
    "a natural question in this context is whether there is any qualitative difference between `` topological '' and `` non - topological '' black holes outside of the event horizon , e.g. regarding their waveforms ?",
    "the time evolution algorithm is an implementation of a standard fourth order method of lines ( see e.g. @xcite ) , with centered spatial differences and runge - kutta time integration .",
    "additionally , a dissipation term of the type discussed in theorems  6.7.1 and  6.7.2 of gustafsson , kreiss and oliger @xcite is added to the right - hand - sides to damp out high frequency oscillations and keep the code numerically stable .",
    "numerical experiments show that usually small amounts if dissipation are sufficient ( the dissipation term used contains a free parameter ) , and do not change the results in any significant manner .",
    "a particularly subtle part of the evolution usually is the boundary treatment . in the conformal approach we are in the situation that the boundary is actually situated outside of the physical region of the grid",
    " this is one of its essential advantages ! in typical explicit time evolution algorithms , such as our runge - kutta method of lines ,",
    "the numerical propagation speed is actually larger than the speed of all the characteristics ( in our case the speed of light ) .",
    "thus @xmath0 does _ not _ shield the physical region from the influence of the boundary  but this influence has to converge to zero with the convergence order of the algorithm ",
    "fourth order in our case .",
    "one therefore does not have to choose a `` physical '' boundary condition , the only requirements are stability and `` practicality ''  e.g. the boundary condition should avoid , if possible , the development of large gradients in the unphysical region to reduce the numerical `` spill over '' into the physical region , or even code crashes .",
    "the current implementation relies on a `` transition layer '' in the unphysical region , which is used to transform the rescaled einstein equations to trivial evolution equations , which are stable with a trivial copy operation at outermost gridpoint as a boundary condition ( see ref .",
    "@xcite for details and references ) .",
    "we thus modify the evolution equations according to replace @xmath80 where @xmath81 is chosen as @xmath82 for @xmath83 and @xmath84 for @xmath85 .",
    "this procedure works reasonably well for weak data , however there are some open problems .",
    "one is , that the region of large constraint violations outside of @xmath0 may trigger constraint violating modes of the equations that can grow exponentially .",
    "another problem ist that a `` thin '' transition zone causes large gradients in the coefficients of the equations ",
    "thus eventually leading to large gradients in the solution , while a `` thick '' transition zone means to loose many gridpoints .",
    "if no transition zone is used at all , and the cartesian grid boundary touches @xmath0 , the ratio of the number of grid points in the physical region versus the number of grid points in the physical region is already @xmath86 .      extracting physics from a numerical solution to the einstein equations is a nontrivial task .",
    "results typically show a combination of physics and coordinate effects which are hard to disentangle , in particular in the absence of a background geometry or preferred coordinate system . in order to understand what is going on in a simulation , e.g. to find `` hot spots '' of inaccuracy or instability or bugs in an algorithm ,",
    "it is often very important to visualize the `` raw '' data of a calculation . here",
    "the visualization of scalar and in particular tensor fields in 3d is a subtle task in itself .",
    "but beyond that , one also wants ways to factor out coordinate effects in some way , and ideally access physical information directly .",
    "one way commonly used to partially factor our coordinate effects is to look at curvature invariants , another possibility is to trace geodesics through spacetime . in the current code",
    "this is done by concurrent integration of geodesics by means of the same 4th order runge - kutta scheme used already in the method of lines .",
    "both null and timelike geodesics , as well as geodesics of the physical and rescaled metrics can be computed , and various quantities such as curvature invariants are computed by interpolation along the geodesics .    particularly important are null geodesics propagating along @xmath0 , since they can be used to define a bondi system and thus compute radiation quantities such as the bondi mass or news . note that the foliation of spacetime chosen for evolution will in general _ not _ reproduce cuts of @xmath0 of constant bondi time .",
    "hbner has therefore implemented postprocessing algorithms ( using the idl programming language / software system ) which construct slices of constant bondi time in the data corresponding to the null geodesics propagating on @xmath0 by interpolation ( the algorithms are based on unpublished work of hbner and weaver ) .",
    "this evolution of geodesics is illustrated by fig .",
    "[ meetingpoint ] , which shows three timelike geodesics originating with different initial velocities at the same point @xmath87 meeting a generator of @xmath0 at @xmath1 .",
    "in this section i will discuss results of 3d calculations for initial data which evolve into a regular point @xmath1 , and which thus could be called `` weak data '' .",
    "bernd schmidt presents results for the kruskal spacetime in this volume ( see also @xcite ) .",
    "the initial conformal metric is chosen in cartesian coordinates as @xmath88 the boundary defining function is chosen as @xmath89 it is used to satisfy the smoothness condition for the conformal metric at @xmath0 .    these data have been evolved previously by hbner for @xmath90 as reported in @xcite . for the gauge source functions he has made the `` trivial '' choice : @xmath91 , @xmath92 , @xmath93 , i.e. the conformal spacetime has vanishing scalar curvature , the shift vanishes and",
    "the lapse is given by @xmath94 .",
    "this simplest choice of gauge is completely sufficient for @xmath90 data , and has lead to a milestone result of the conformal approach  the evolution of weak data which evolve into a regular point @xmath1 of @xmath95 , which is resolved as a single grid cell . with this result hbner",
    "has illustrated a theorem by friedrich , who has shown that for sufficiently weak initial data there exists a regular point @xmath1 of @xmath95 @xcite . the complete future of ( the physical part of ) the initial slice can thus be reconstructed in a finite number of computational time steps .",
    "this calculation is an example of a situation for which the usage of the conformal field equations is ideally suited : main difficulties of the problem are directly addressed and solved by using the conformal field equations .    the natural next question to ask is : what happens if one increases the amplitude @xmath96 ? to answer this question ,",
    "i have performed and analyzed runs for integer values of @xmath96 up to @xmath97 .",
    "the results presented here have been produced with low resolutions of @xmath98 ( but for higher or slightly lower resolutions we essentially get the same results ) . for convergence tests of the code",
    "see @xcite .",
    "while for @xmath99 the code continues beyond @xmath1 without problems , for all higher amplitudes the `` trivial '' gauge leads to code crashes before reaching @xmath1 . here by `` code crash ''",
    "we mean that computational values get undefined , e.g. the code produces `` not a number '' ( nan ) values .",
    "while the physical data still decay quickly in time , a sharp peak of the lapse develops outside of @xmath0 and crashes the code after bondi time @xmath100 for @xmath101 and @xmath102 for @xmath97 ( here @xmath103 is the initial bondi mass ) . in figs .",
    "[ lapse - n1 ] and [ lapse - n5 ] the lapse @xmath104 is plotted for runs with @xmath90 and @xmath105 . while for @xmath90 the lapse only shows significant growth after @xmath106 ( @xmath1 is located at @xmath107 , @xmath106 ) , for @xmath105 a very sharp peak grows outside of @xmath0 and crashes the code at @xmath108 .",
    "where does this rapid growth come from ?",
    "note that the initial conformal metric eq .",
    "( [ eq : standard - h ] ) shows significant growth outside of @xmath0 .",
    "combined with the lapse @xmath109 this leads to a growth of the lapse toward the grid boundary . in the present case a positive feedback effect with a growth of metric components in time seems to be responsible for the eventual crash of the code .",
    "note that this feedback only takes place in a small region outside of @xmath0  further outward it is prevented by the transition to trivial evolution equations .",
    "[ lapse - n5q ] shows a cure of the problem : a modified gauge source function @xmath110 ( @xmath111 ) with @xmath112 leads to a very smooth lapse ( and correspondingly also to smooth metric components ) .",
    "note that in fig .",
    "[ lapse - n5q ] , due to the different lapse , the point @xmath1 is _ not _ located at @xmath106 .",
    "the value of @xmath112 here is found by moderate tuning of @xmath113 to a best value ( significantly decreasing or increasing @xmath113 crashes the code before @xmath1 is reached ) .",
    "unfortunately , this modification of the lapse is not sufficient to achieve much higher amplitudes .",
    "as @xmath96 is increased , the parameter @xmath113 requires more fine tuning , which was only achieved for @xmath114 . for higher amplitudes",
    "the code crashes with significant differences in the maximal and minimal bondi time achieved , while the radiation still decays very rapidly and the news scales almost linearly .",
    "furthermore , the curvature quantities do not show excessive growth ",
    "it is thus natural to assume that we are still in the weak - field regime , and the crash is not connected to the formation of an apparent horizon or singularity .",
    "these results suggest that in order to model a gauge source function @xmath49 that would allow to evolve up to @xmath1 , one would need more that one parameter , e.g. at least 3 parameters for a non - isotropic ansatz such as @xmath115 or something similar .",
    "to tune 3 or more parameters for each evolution seems however computationally prohibitive . while some improvement is obviously possible through simple non - trivial models for the lapse ( or other gauge source functions ) , this approach seems very limited and more understanding will be necessary to find practicable gauges .",
    "an interesting line of research would be to follow the lines of ref .",
    "@xcite in order to find evolution equations for the gauge source functions which avoid the development of pathologies .",
    "a particular aim would be to find equations such that the resulting system of evolution equations is symmetric hyperbolic .",
    "[ fig : news ] shows the news function from three different runs : for @xmath116 and @xmath93 , and for @xmath105 , @xmath117 . the news from the runs for @xmath90",
    "have been multiplied by a factor of 25 , which would exactly compensate scaling with the amplitude in the linear regime .",
    "we see that the three curves line up very well initially .",
    "the line for @xmath105 and @xmath93 deviates significantly to larger values of the news when the runs starts to get inaccurate , but at this time most of the physical radiation has already left the system .",
    "the curves from @xmath90/@xmath93 and @xmath105/@xmath117 line up perfectly until the value of the news drops below @xmath118 , where the curves level off at different values , due to numerical inaccuracy .    fig .",
    "[ fig : bondimass ] shows the bondi mass for this situation , again the @xmath90 curve is scaled by a factor of 25 : again we see the quick decay of a sharp pulse of radiation .",
    "there is no particular structure except falloff at late times , the deviation of the curves at late times seems to be caused by numerical inaccuracy , in particular in the computation of the bondi mass .",
    "in this section i will give a brief description of some computational aspects , such as the computational resources needed to carry out simulations in 3 spatial dimensions .",
    "computations of this scale rely on parallel processing , that means execution of our algorithms is spread over different cpu s . from a simplistic point of view",
    "there are two ways to program for parallel execution : we only take care of parallelizing the algorithm  but",
    "we require that all cpu s can access the same memory  or we both parallelize the algorithm and the data structures , and separate the total data into smaller chunks that fit into the local memory of each processor .",
    "the first alternative requires so called shared memory machines , where the operating system and hardware take care of making data accessible to the cpu s consistently , taking care of several layers of main and cache memory ( which gets increasingly difficult and expensive as the size of the machine is increased ) .",
    "the present code has been implemented using a shared memory programming model .",
    "the advantage is that this can generally be somewhat easier to program , and avoids overheads in memory .",
    "the disadvantage is the high cost of such systems , which makes them difficult to afford and thus nonstandard for most large academic parallel applications .",
    "the second alternative , usually referred to as distributed memory , requires more work to be done by the programmer , but more flexibly adapts to different kinds of machines such as clusters of cheap workstations commonly available in academic environments .",
    "while this approach usually implies a larger overhead in total memory requirements , speed and programming complexity , it is currently the only approach capable of scaling from small to very large simulations . for a general introduction to the issues of high performance computing , ref .",
    "@xcite provides a good starting point .",
    "so , how much memory do we need ?",
    "let us assume a run with @xmath119 grid points ( the size of the largest simulations carried out with the present code so far ) .",
    "the current implementation of the fourth order runge - kutta algorithm uses 4 time levels and a minimum of 62 grid functions ( 57 variables and 5 gauge source functions ) . in double precision",
    "this amounts to @xmath120 gbyte .",
    "temporary variables , information on geodesics and various overheads result in a typical increase of memory requirements by roughly @xmath121 . for 150 time steps ( approximately what it takes to reach @xmath1 for weak data ) the total amount of processed data then corresponds to roughly 1 terabyte !    if we half the grid spacing , the allocated memory increases by a factor of @xmath122 ( neglecting overheads ) , the total amount of processed data by a factor of @xmath123 , and the total required cpu time also by a factor of @xmath123 , while the error _ reduces _ by a factor of @xmath123  * if * we are already in the convergent regime ! given that the biggest academic shared memory machines in germany have 16 gbyte of memory available ( the aei s origin 2000 and the hitachi sr8000 at lrz in munich ) this shows that the margin for increasing resolution is currently quite small .",
    "such an increase in resolution will however be necessary to resolve physically interesting situations with more structure , such as a black hole , or two merging black holes . a move toward distributed memory processing",
    "will therefore be likely in the long run .",
    "the current software - standard for distributed ( scalable ) computing is mpi ( message passing interface ) @xcite . unfortunately",
    ", writing large scale sophisticated codes in mpi is very time consuming .",
    "however , several software packages are available which introduce a software layer between the application programmer and mpi , and thus significantly reduce the effort to write parallel applications .",
    "two prime examples are the cactus computational toolkit @xcite and petsc @xcite .",
    "while petsc is a general purpose tool developed at argonne national laboratory as parallel framework for numerical computations , cactus has been developed at the albert einstein institute with numerical relativity in mind .",
    "while petsc offers more support for numerical algorithms , in particular for parallel elliptic solvers , cactus already contains some general numerical relativity functionality like apparent horizon finders  but no support for generic numerical algorithms .",
    "apart from its numerical relativity flavor , the cactus computational toolkit also has the advantage of broad support for parallel i / o and large scale 3d visualization .",
    "the ability to successfully mine tens or hundreds of gigabytes of data for relevant features is paramount to successful simulations in 3d .    among the essential problems in writing and maintaining large scientific codes",
    "are the software engineering aspects and the control of complexity .",
    "in other words , codes should be reasonably documented and maintainable . for large scientific codes written and maintained by part - time - programmer scientists",
    "this poses a significant challenge . writing a clear , modular code that can be understood , maintained and extended to suit new scientific needs requires a good deal of design and planning ahead . for an introduction to software engineering issues",
    "see e.g. @xcite , @xcite .",
    "another important issue for scientific codes is flexibility .",
    "being able to do good science often depends on the ability to easily change algorithms , equations , discretization schemes etc .  without having to restructure the code , without high risk of introducing new bugs . in the present case examples for",
    "the need of trying different things would be experiments with different evolution equations ( e.g. metric versus frame formalism ) , different boundary treatments or different elliptic solvers .",
    "the 3d numerical simulations performed so far show that the evolutions are _ numerically _ stable and quite robust .",
    "however , one of the main problems in numerical relativity is the stability of the constraint propagation : while the constraints _ do _ propagate when they are satisfied identically initially , this assumption does not hold for numerical simulations . on the contrary ",
    "it seems to be quite typical observation that the constraints diverge exponentially , if the evolution does not start at the constraint surface .",
    "preliminary results exhibit this behavior of resolution - independent exponential growth associated with a violation of the constraints also for the conformal approach .",
    "one of the major goals for the future thus has to be the improvement of the understanding of the constraint propagation equations , and an according modification of the evolution equations ( see ref .",
    "@xcite for previous work in this direction ) .",
    "this is essentially an analytical problem , but will certainly require the numerical testing of ideas .    another area where new developments are necessary on the analytical side  along with numerical testing  is the problem of finding gauges that prevent pathologies like unnecessarily strong gradients .",
    "ideally one would want to keep the symmetric hyperbolic character of the evolution system while allowing for a maximum of flexibility in writing down evolution equations for the gauge source functions .",
    "well - posedness of the evolution equations is important  but by far not sufficient for numerical purposes . while well - posedness unfortunately still has not yet been shown rigorously for many formulations used in numerical relativity , another important task seems to be to improve the understanding of the non - principal part of the equations , including their nonlinearities , in order to be able to construct numerically well - conditioned algorithms .    the third area where significant progress seems necessary on the analytical side is the construction of initial data .",
    "problems with the current algorithm which necessitates divisions by zero and an ad - hoc extension beyond @xmath0 have not yet been resolved .",
    "a possible road toward resolving these problems has been outlined by butscher in this volume .    an important role in improving the analytical understanding and in setting up numerical experiments",
    "will be played by the utilization of simplifications . particularly important",
    "are spacetime symmetries and perturbative studies .",
    "a particularly interesting case to be studied actually is minkowski space . besides being an important case for code testing",
    ", it is used in current investigations to learn more about gauges and the stability of constraint propagation .",
    "more complicated are general spherically symmetric spacetimes . in the vacuum case ,",
    "this only leaves the kruskal spacetime aside from minkowski space  but understanding the gauge problem for kruskal spacetime is an important milestone toward long - time black hole simulations .",
    "moreover , spherical symmetry provides a natural testing ground for all kinds of new ideas , e.g. of how to treat the appearance of singularities , of how to treat the unphysical region , numerical methods , etc .",
    "an alternative route to simplification , which has been very successful in numerical relativity , is perturbative analysis , e.g. with minkowski or schwarzschild backgrounds . in the context of compactification",
    "this has been carried out numerically with characteristic codes in @xcite , some of the problems that showed up there are likely to be relevant also for the conformal approach .",
    "what can we expect from the conformal approach in terms of physics results ?",
    "where can we expect contributions to our understanding of general relativity ? one of the most important features of the conformal approach is that it excels at radiation extraction without ambiguities , and  at least in principle  enables numerical codes to study the global structure of spacetimes describing isolated systems .",
    "as has been demonstrated in this paper , in some weak field regime the code works well with relatively simple choices of gauge , and could be used to investigate some of the above problems .",
    "it could also provide a very clean way to study nonlinear deviations from linear predictions . for strong fields , in particular one or two black holes ,",
    "the problem is much more difficult .",
    "an even more difficult problem is the investigation of the structure of singularities . in the spherically symmetric case",
    "this has been achieved by hbner @xcite , but it is not clear whether these methods can be carried over to the generic case without symmetries , where the structure of the singularity has to be expected to be much more complicated .",
    "what is the roadmap for the future ? as far as 3d simulations are concerned , i believe that one should try to go from relatively well controlled weak data to stronger data and try to identify and solve problems as they come up . in parallel , it will be important to study simplified situations , like spacetimes with symmetries or linear perturbations with a mixture of analytical and numerical techniques",
    ". both lines of research are hoped to improve our understanding of issues associated with choosing the gauge source functions , and controlling the growth of constraints .",
    "future 3d codes , aimed at producing novel physical results will also require a significant effort devoted to `` computational engineering '' , since flexible and solidly written codes are an absolute necessity for good computational science ! these well known problems plaguing 3d numerical relativity will have to be addressed and solved in the conformal approach in order to harvest its benefits .",
    "developing the conformal approach to numerical relativity into a mature tool poses an important challenge for mathematical relativity : not only is the problem hard and requires long - term investments , it also requires to merge sophisticated mathematical analysis with computational engineering .",
    "the aim is to produce a solid handle on exciting new physics  and some of the physics will even be accessible to experiments .",
    "the author thanks h. friedrich , b. schmidt , m. weaver and j. frauendiener for helpful discussions and explanations of their work , c. lechner and j. thornburg for a careful reading of the manuscript , and p. hbner for giving me access to his codes and results , and for support in the early stages of my work on this subject .",
    "o. brodbeck , s. frittelli , p. hbner and o. reula , j. math .",
    "40 ( 1999 ) 909923 ; m. alcubierre , g. allen , b. bruegmann and e. seidel , wai - mo suen , phys .",
    "d62 ( 2000 ) 124011 ; g. yoneda and h. shinkai , class .",
    "18 ( 2001 ) 441462 ; f. siebel and p. hbner , phys .",
    "d64 ( 2001 ) 024021 .",
    "s. balay , w. d. gropp , l. curfman mcinnes and b. f. smith , `` petsc users manual '' , technical report anl-95/11 , 2001 ; s. balay , w. d. gropp , l. curfman mcinnes and b. f. smith , \" efficient management of parallelism in object oriented numerical software libraries  , in modern software tools in scientific computing , ed . by e. arge and a. m. bruaset and h. p. langtangen , birkhauser press , 1997 ; http://www.mcs.anl.gov/petsc ."
  ],
  "abstract_text": [
    "<S> this talk reports on the status of an approach to the numerical study of isolated systems with the conformal field equations . </S>",
    "<S> we first describe the algorithms used in a code which has been developed at the aei in the last years , and discuss a milestone result obtained by hbner . </S>",
    "<S> then we present more recent results as examples to sketch the problems we face in the conformal approach to numerical relativity and outline a possible roadmap toward making this approach a practical tool . </S>"
  ]
}