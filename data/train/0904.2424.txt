{
  "article_text": [
    "the gluon distribution @xmath0 plays an important role in high energy collider phenomenology , both for standard model and new physics .",
    "yet it is the most elusive of the parton distribution functions ( pdfs ) in contemporary global qcd analysis . at moderate values of the momentum fraction @xmath1 ,",
    "extensive high precision data on deep inelastic scattering ( dis ) constrain @xmath0 fairly well through the @xmath2-dependence that is predicted by qcd .",
    "the little information we have at large @xmath1 comes mostly from inclusive jet production at hadron colliders , which receives contributions directly from the gluon distribution at leading order in @xmath3 .",
    "the recently published inclusive jet data from tevatron run ii measurements by cdf @xcite and d0 @xcite are therefore of considerable interest for improving our knowledge of the gluon distribution .",
    "previous cteq studies @xcite have used only the run i jet data @xcite .",
    "a recent mstw study @xcite includes the run ii data in an analysis with aims parallel to this one .",
    "a comparison with their results is presented in sec .",
    "[ sec : comparemstw ] .    in this paper",
    ", we make a detailed study of several issues that bear on the behavior of the gluon distribution and its range of uncertainties , focusing on the use of tevatron inclusive jet data .",
    "( inclusive jet production in dis processes can also provide constraints on the gluon distribution ; but those constraints are considerably weaker and we do not include them here . ) some of the results and techniques described here are known to many practitioners in the field , but have not been previously documented in the literature .",
    "some of these results are frequently misunderstood ",
    "e.g . , in discussions at workshops ",
    "so it seems worthwhile to set them out in systematic detail .",
    "the methods discussed here for the inclusive jet data thus serve as a pedagogical study of techniques that can be applied in general when new data sets become available to advance the pdf analysis .",
    "one of the techniques we use is presented here for the first time .",
    "it involves orienting the choice of eigenvector directions in the hessian method in order to simplify the study of uncertainty for any particular quantity of interest .",
    "up to now , the cteq global analyses of jet cross sections as a function of jet transverse momentum @xmath4 have been based on the eks nlo program @xcite .",
    "recently , the fastnlo implementation @xcite of the nlojet++ @xcite calculation has gained increasing use  in part because of its convenient interface .",
    "( fastnlo allows the dependence on the pdfs of the nlo cross section to be included in the computation of @xmath5 at every step within the fitting procedure .",
    "however , we find that calculating the ratio k = nlo / lo for each data point using a single typical fit to the data provides an adequate approximation . ) to make sure that the two calculations are consistent in the global analysis context , we have directly compared their results in the tevatron run i and ii kinematic ranges .",
    "the theoretical results also depend on choices of : ( i ) the renormalization and factorization scales in pqcd , usually taken to be the same , say @xmath2 ; and ( ii ) the jet algorithm , including parameters such as @xmath6 ( for separation of neighboring jets ) @xcite .",
    "we have performed the comparison using a variety of these choices .",
    "the results provide information on the importance of these factors for the global analysis .",
    "figure [ fig : figone ] shows the k - factor , defined by k = nlo / lo , for the tevatron run ii @xmath7 range in several of the experimental rapidity intervals .",
    "each plot shows results from fastnlo for two choices of the scale : @xmath8 ( upper two curves ) , and @xmath9 ( lower two dashed curves ) . within each of these pairs",
    ", the upper curve uses the midpoint cone jet algorithm with @xmath10 , while the lower curve uses the midpoint algorithm with @xmath11 . the solid curve shows the result of the eks program for @xmath9 and @xmath11 .",
    "( the wiggles in this curve are caused by fluctuations from the monte carlo integration used in eks . )",
    "we observe the following :    @xmath12 the overall agreement between the eks and fastnlo calculations is satisfactory , though not perfect .",
    "our results from parallel global analyses based on these two methods for calculating jets , with all other options identical , show good agreement , which indicates that results of the global analysis are not sensitive to deviations of the magnitude shown .",
    "we use the fastnlo results for the remainder of this investigation .",
    "@xmath12 the effect of @xmath6 choice is quite small .",
    "since the scale choice affects the predicted cross section directly through the lo cross section , as well as through the k factor , we explore it further in fig .",
    "[ fig : figtwo ] , which shows the predicted cross section for various scale choices normalized by our `` standard '' choice . the plots on the left correspond to the conventional nlo calculation",
    ", while those on the right also include a `` 2-loop '' correction derived from threshold resummation @xcite , which is available in fastnlo .",
    "we only show results from one central and one large rapidity bin ; results at intermediate @xmath13 interpolate between these two .",
    "the bands in each plot represent the estimated uncertainty due to the pdfs , for comparison .",
    "we conclude the following :    @xmath12 the low - scale choice @xmath14 leads to results that are far from the other choices at large rapidity , and shows unstable behavior with respect to 2-loop corrections , which lie mostly outside the pdf uncertainty bands .",
    "this scale choice is thus unsuitable for theoretical calculations , as is also apparent from the fact that k = nlo / lo is far from @xmath15 with this choice , which suggests that still higher order corrections would be very important .",
    "by contrast , the other three scale choices show consistent patterns and yield stable results .",
    "@xmath12 one may use the range @xmath16 to empirically estimate the uncertainty due to uncalculated higher - order corrections .",
    "this range of theoretical uncertainty is seen to be fairly independent of @xmath7 , in contrast to the uncertainty due to pdfs , which has a strong @xmath7 dependence .",
    "the theory uncertainty is comparable to the pdf uncertainty in the low @xmath7 range , but is much smaller than it in the high @xmath7 range .",
    "@xmath12 the theoretical uncertainties are reduced in the calculation that includes the partial 2-loop correction . whether this reduction provides a genuine increase in accuracy depends on the reliability of the approximation , which is still controversial .",
    "we do not use this correction in the remainder of the paper .    with these theoretical background studies completed",
    ", we now proceed to study the impact of the tevatron jet data on determining the gluon distribution .",
    "we use the published cteq6.6 pdf set @xcite as the reference fit for our comparison study .",
    "unless otherwise stated , the theoretical and experimental inputs are kept the same as in @xcite except for the addition of the cdf @xcite and d0 @xcite run ii data sets .",
    "we use the cdf run ii results obtained from the midpoint cone jet algorithm , rather than the earlier results based on the @xmath17 algorithm @xcite .",
    "the two analyses were carried out on the same events , so it be incorrect to include them both ; and the ratio of the resulting cross sections agrees well with the ratio predicted by nlo qcd , as stated in @xcite .",
    "( the cdf data were supplied to us by one of the cdf authors , so we were not affected by errors in the original publication @xcite , which have now been corrected as described in its first reference . )",
    "the cteq6.6 central fit and its eigenvector sets which characterize the uncertainty are known to describe the run ii jet data fairly well , even though those data were not available at the time of the cteq6.6 analysis .",
    "thus from the outset we know that no revolutionary changes will result from incorporating the new data into the global analysis .",
    "the purpose of our study is to quantify what changes there are ; and to investigate some subtle features that have not been explored before , which have implications for our efforts to pin down the gluon pdf .    with the addition of the tevatron run ii jet data",
    ", our global analysis includes 37 data sets with a total of 2898 data points . as a baseline , when cteq6.6 pdfs are used directly to compute the cross sections and",
    "then compared to these data points , we obtain a good overall fit with @xmath18 . _ here and in all our fits , the full correlated experimental errors are used in computing @xmath19 , for all experiments that report their errors in this form . _ to get a first look at the impact of the run ii jet data , we performed a preliminary fit using the same theoretical input as cteq6.6 . in this fit ,",
    "the weighted @xmath19 becomes @xmath20a reduction of @xmath21 .",
    "this is a very small reduction when spread over all 2898 data points , or even when spread over the 182 new ones  as was anticipated since cteq6.6 already provided a reasonably good fit to the new data .    the only significant change in the best - fit pdfs from cteq6.6 to the preliminary fit occurs in the gluon pdf .",
    "this can be demonstrated by repeating the global fit with all of the quark distribution parameters frozen at their cteq6.6 values , thus only allowing the gluon distribution to change .",
    "the reduction in @xmath19 is nearly the same and the resulting fit is essentially equivalent to the preliminary fit .",
    "this confirms our expectation that the inclusive jet data provide a handle on @xmath0 and little else .",
    "since the jet data are sensitive to the gluon distribution , it is essential to use a sufficiently flexible parametrization for the gluon at the starting scale @xmath22 for dglap evolution , which we choose to be @xmath23 as in previous analyses .",
    "the form we use is @xmath24 we add a penalty to the overall @xmath5 to force parameter @xmath25 , which controls the behavior at @xmath26 , to lie within a reasonable but generous range @xmath27 .",
    "the form ( [ eq : gluonparametrization ] ) is more general than what was used in cteq6.6 , which was equivalent to @xmath28 and @xmath29 .",
    "alternative parametrizations have also been tested , to assure that our results are not sensitive to the particular form of smooth function that we choose to multiply the basic @xmath30 and @xmath31 factors .    because the gluon distribution is not strongly constrained by existing data",
    ", it has been common to use a fairly restricted functional form for the nonperturbative input function , compared to the better - constrained light quark distributions .",
    "a frequent practice is to start with the minimal form @xmath32 and incrementally add new parameters until the quality of the global fit ceases to improve .",
    "this is a sensible approach for finding a reasonable `` best fit '' pdf set .",
    "but it can produce misleading results by artificially reducing the estimated uncertainties  as happened famously when the cdf run i measurements of the jet cross section at first appeared to lie outside the range of standard model predictions at large @xmath7 @xcite .",
    "we will discuss related examples of this in secs .",
    "[ subsec : restrictedgluon ] and [ sec : gluonuncertaintyresults ] .    in current practice , the number of parameters used by various groups shows wide variation , which depends both on the constraining power of the input experiments included in the analysis and on the stability of the analysis method .",
    "using too few parameters can lead to uncertainty estimates that reflect the assumed functional forms more than the experimental constraints .",
    "this fact appears to be under - appreciated , since the number of parameters used for uncertainty studies is commonly kept at a minimum level based only on the central fit .",
    "a technical reason to restrict the number of parameters in the uncertainty study is the instability of the hessian method for determining the extreme pdf eigenvector sets , which occurs as the number of fitting parameters approaches the limit of constraining power of the experimental input .",
    "we have been able to overcome this problem by using the iterative method developed in @xcite to control both the instabilities due to vast disparities in the unscaled eigenvalues and instabilities caused by the numerical evaluation of the second derivatives that define the hessian matrix .",
    "the set of tools we have developed provide an orderly way to obtain stable results as the number of parameters is increased .",
    "this is the reason why the cteq analyses have consistently used a larger number of uncertainty eigenvector sets than other groups .",
    "the fits described in sec .  [ sec : gluonuncertaintyresults ] use 24 parameters to describe the pdfs at @xmath22 .    a neural network approach to the pdf analysis ( nnpdf ) @xcite has been developed recently to circumvent the parametrization issue .",
    "this appears highly promising .",
    "however , to make this approach as effective as possible , it may be important to retain some theory - based guidelines on the pdfs at scale @xmath22 .",
    "in particular , there are good physical arguments behind the traditionally assumed behaviors @xmath33 at @xmath34 and @xmath35 at @xmath26 , which even predict estimates for the constants @xmath36 and @xmath25 that one may wish to harness .",
    "the validity of those arguments is supported by the observation that for the @xmath37 quark distribution , which is the most accurately measured of the pdfs , the fitted results for @xmath36 and @xmath25 lie close to their theoretical expectations .",
    "we now proceed to a detailed study of the compatibility of the jet data sets with each other and with the nonjet data .",
    "this study also serves as a case study of methods to apply when adding new data sets to a global fit .",
    "when one contemplates adding new sets of experimental data to an existing global analysis , one begins by asking a series of questions that can be answered systematically by making fits in which the @xmath5 for the new data sets are multiplied by various weight factors .",
    "these weight factors multiply the contributions from individual data sets before they are added to the global @xmath5 that is minimized in the fit , in order to vary how much influence each set is allocated in determining the fit . for a related discussion of these ideas , see @xcite .    _",
    "are the new data consistent with theory ? _ can be addressed in a minimal way by seeing if @xmath5 for the new data is acceptably close to its nominal range of @xmath39 for @xmath40 data points , at least when these data are assigned a sufficiently large weight .",
    "( in the ideal situation of gaussian experimental errors , this range corresponds to a @xmath41 confidence interval around the best - fit @xmath5 . in the present case , where the bulk of the experimental error may come from systematic effects",
    ", this comparison may also reveal deviations from gaussian behavior , which are known to occur when the experimental errors are predominantly systematic . )    _ are the new data consistent with the previous experiments ? _ can be addressed by observing the increase in @xmath5 for the original data that occurs when the fit is adjusted to accommodate the new data .",
    "_ are the new data sets consistent with each other ?",
    "_ can be studied by observing the change in @xmath5 for each new data set in response to changing the weights for the other new data sets .",
    "this will reveal whether two new data sets `` pull '' in the same direction , or whether on the contrary there is a `` tension '' between them ; or whether they measure different features , and so have little effect on each other .    _",
    "do the new data sets provide significant new constraints ? _ can be studied in a simple way by exploring the range of acceptable fits to the original data using the hessian ( eigenvector ) method , and observing how many of these eigenvector sets produce acceptable fits to the new data .",
    ".@xmath5 for jet experiments with various weights [ cols= \" > , > , > , > , > , > , > , > , > \" , ]",
    "in this section , we discuss various methods to determine the uncertainty of parton distributions .",
    "we focus on the gluon distribution at large @xmath1 because that is the primary aspect of the global analysis that is influenced by the jet experiments .",
    "because the uncertainty in the gluon is large , it serves as a strong test of the methods used to estimate uncertainties .    within the usual context of our global analysis @xcite , parton distribution shape parameters that minimize an effective weighted @xmath5 function define the `` best fit '' .",
    "all parton distributions defined by the other choices of the parameters are deemed acceptable ( and delineate the region of the pdf uncertainty allowed by the analysis ) if they produce a value of @xmath5 that exceeds the minimum value by no more than a given tolerance value @xmath42 ( i.e. , @xmath43 ) . appropriate weights and the tolerance criterion must be chosen to ensure that all of the accepted fits provide adequate descriptions of every data set . in the present case , we estimate that @xmath44 provides an approximately 90% confidence limit for all experiments included in the fit .      the uncertainty of the gluon distribution can be found in a straightforward way by the lagrange multiplier ( lm ) method @xcite : at",
    "any given value of @xmath1 , a term @xmath45 is added to the @xmath5 function that is minimized by varying the fitting parameters .",
    "the parameter @xmath46 is adjusted to make the increase in @xmath5 above its minimum value equal to @xmath42 .",
    "this yields two allowed pdf sets ( one from positive @xmath46 and one from negative ) that provide the minimum and maximum @xmath47 .",
    "the procedure is carried out at a number of @xmath1 values to map out the extremes of the uncertainty range .",
    "results for the gluon uncertainty obtained in this way are shown in fig .",
    "[ fig : figthree ] , together with some of the specific curves that produced the envelope of extremes .",
    "the shapes that provide the extremes do not violate any strong intuition , although those showing a peaked structure in @xmath48 at large @xmath1 might not be expected _ a priori_. ( still larger uncertainties might be found if more fine structure were allowed by the parametrization ; but sharp structures in @xmath1 are not physically expected , and their effect would tend to go away at higher scales through the smoothing character of dglap evolution . )    it is natural to ask if the extensive new jet data from run ii reduce the gluon uncertainty . to answer that question , fig .",
    "[ fig : figfour ] compares the uncertainty range from fig .",
    "[ fig : figthree ] with the uncertainty range obtained by a similar lagrange multiplier calculation with the run ii data removed from the fit .",
    "_ one sees that the run ii data somewhat reduce the gluon uncertainty at large @xmath1 . _",
    "a pdf set that deviates from the minimum @xmath5 by an amount @xmath44 usually provides an acceptable fit to all experiments and thus can not be ruled out as a valid possibility within the uncertainty range according to the conservative `` hypothesis testing '' criterion .",
    "but if the increase in @xmath5 is not spread widely over the @xmath493000 data points , but rather is concentrated in one or two experiments , or in any small subset of the data points , it may be an unacceptable fit .",
    "this is found to happen for some of the extreme gluon distributions obtained in sec .",
    "[ subsec : lagrangemultiplier ] , because only the inclusive jet experiments are sensitive to the gluon distribution at large @xmath1 .    to avoid this problem",
    ", we could increase the weight for the jet experiments in the total @xmath5 by trial and error .",
    "but we find it simpler and more effective to add a penalty to @xmath5 that is proportional to @xmath50 for each of the jet experiments , in order to force the final fit to agree acceptably with each of those experiments , without introducing much change in the central fit . with this change in the definition of the weighted @xmath5 that is minimized",
    ", we can continue to use our established calculational tools .",
    "( an alternative method used by mstw @xcite is to abandon a fixed @xmath42 and instead to set the maximum allowed displacement along each eigenvector direction independently , by monitoring the quality of fit to each of the data sets along that direction . )",
    "the quartic form for the penalty adds little to @xmath5 except near the boundary , so it does not significantly alter our @xmath44 tolerance estimate .",
    "these `` quartic penalties '' are included in all subsequent fits in this paper .",
    "our final uncertainty for the gluon distribution is therefore appreciably smaller than what is shown in the preliminary study of figs .",
    "[ fig : figthree ] and [ fig : figfour ] .",
    "in addition to the lm method , the other standard technique for estimating pdf uncertainties is the hessian eigenvector method @xcite .",
    "that method works as follows .",
    "the first derivatives of @xmath5 with respect to the fitting parameters are zero at the minimum , so in the neighborhood of the minimum , @xmath5 can be approximated by taylor series as a quadratic form in the fitting parameters .",
    "the coefficients of that quadratic form are the hessian matrix , which is the matrix of second derivatives of @xmath5 with respect to the fitting parameters .",
    "the eigenvectors of the hessian matrix can be used to define eigenvector pdf sets that characterize the allowed uncertainty range .",
    "the uncertainty of any prediction is calculated by computing the deviation from the best fit along each eigenvector direction , and adding those deviations in quadrature separately for the positive and negative deviations .",
    "the gluon uncertainty calculated this way is shown in fig .  [",
    "fig : figfive ] , together with extremes calculated by lm at @xmath51 , @xmath52 , and @xmath53 .",
    "the agreement between the two methods is seen to be quite good , although a slightly larger upper limit is found at @xmath54 by the lm method , which is not subject to the quadratic approximation .",
    "the eigenvector method is of course much more convenient to use than lm , because the lm method requires tuned fittings of the lagrange multiplier parameter for every extremum point that is desired .",
    "so it is comforting to see this agreement .",
    "the eigenvectors of the hessian matrix can be thought of as a choice of basis vectors that define new fitting parameters @xmath55 for which @xmath56 the choice of these eigenvectors is not unique , because the form ( [ eq : chidiag ] ) is preserved by any further orthogonal transformation of the coordinates @xmath57 .",
    "in the approximation that @xmath5 is a quadratic function of the shape parameters which parametrize pdfs at @xmath22 , such a transformation would not affect the calculation of the uncertainty .    the freedom to make an additional orthogonal transformation may offer the possibility to reduce the number of eigenvectors that are needed to effectively describe the uncertainty of a particular quantity of interest .",
    "one possible way to attempt this is to diagonalize the parameter dependence of that quantity , using a procedure that is sketched in the appendix and described explicitly in @xcite .",
    "an example of this is shown in fig .",
    "[ fig : figsix ] , which shows the gluon uncertainty calculated by the eigenvector method , together with the 48 extreme eigenvector sets ( positive and negative directions along each of the 24 eigenvectors ) . in the left panel ,",
    "the eigenvectors are defined in the traditional way as eigenvectors of the hessian .",
    "note that many eigenvectors contribute to the uncertainty at each value of @xmath1 .",
    "( a common method to make a quick estimate of uncertainty is simply to look at the extremes over the eigenvector sets , without adding the individual contributions in quadrature .",
    "that can easily underestimate the uncertainty by a factor of two or more , as seen here . )    in the right panel of fig .",
    "[ fig : figsix ] , the eigenvectors are defined by choosing @xmath58 in eq .",
    "( a3 ) of the appendix .",
    "note that close to @xmath59 , almost all of the uncertainty comes from just one pair of eigenvector sets . in cteq6.1 , it happened by convenient accident that most of the uncertainty in the gluon distribution was embodied in a single eigenvector set . by `` rediagonalizing '' the hessian matrix ,",
    "this type of simplicity can be gained in other situations ; though as seen in fig .",
    "[ fig : figsix ] it may take more than one eigenvector direction to span the important variations .    a rediagonalization based on the second - derivative matrix , such as the one carried out here , is not necessarily the best way to choose the new eigenvector directions , since there is no theorem to guarantee that it will result in only a few dominant coefficients .",
    "for example in this particular case it might have worked better to ignore the second derivatives , and instead to simply choose the first new eigenvector direction along the gradient direction for , say @xmath60 in the 24-dimensional space ; then the second eigenvector could be chosen along the gradient direction for , say @xmath61 in the 23-dimensional subspace that is orthogonal to the first eigenvector , etc . in any case , the option of redefining the eigenvector directions to simplify the description of uncertainties in other physics analyses shows promise for further study .      another possible way to characterize the uncertainties would be to generate a random collection of pdf sets that lie inside or at the edge of the acceptable range @xmath62 .",
    "( in the quadratic approximation , this would correspond to a sphere in the n - dimensional hyperspace spanned by @xmath57 . )",
    "for example , a set at the edge can be constructed by generating a random unit vector in the @xmath40-dimensional parameter space using the eigenvectors as basis vectors , and moving away from the minimum point in that direction until @xmath5 has increased by the tolerance @xmath63 .",
    "the envelope of results obtained from 500 pdf sets obtained this way is shown in fig .",
    "[ fig : figseven ] , together with 50 of the individual results . also shown is the uncertainty obtained by the hessian method .",
    "_ we see that the envelope of the random sets covers a much smaller range than the full uncertainty  even though every one of the 500 sets is at the upper limit for @xmath5 .",
    "_ this is not surprising , since the extreme @xmath64 at any given @xmath1 can be thought of as corresponding to a specific direction in the n - dimensional parameter space .",
    "the probability distribution for the component , @xmath65 , of a random unit vector along any particular direction in @xmath40 dimensions can be shown to be @xmath66 , which becomes extremely small as @xmath65 approaches its limit of 1 .",
    "for example , when @xmath67 , the probability for @xmath68 is less than 1 in 1000 , so the chance of finding a value close to the true extreme of 1.0 by random sampling is very small .",
    "this conclusion can be understood qualitatively in a simple way : it is unlikely for the direction cosine along any particular direction to lie close to its maximum of 1 , since there are @xmath40 random direction cosines whose sum of squares must add up to 1 .",
    "the point of this exercise is to show that no conveniently small collection of pdfs that are all acceptable fits to the data can approximately cover the full uncertainty range .",
    "it is therefore essential to have a well - defined way to combine the uncertainties associated with the various fits in such a collection . in the hessian method",
    ", this is provided by the rule of adding uncertainties from eigenvector sets in quadrature . in the case of random pdf sets",
    ", it would require estimating the uncertainty range for a prediction of a quantity @xmath69 using the dispersion @xmath70 in values calculated from the random sets .",
    "the above limitation does not apply to monte carlo based sampling methods such as nnpdf @xcite , since those methods produce a collection of pdf sets that directly samples the space of uncertainties .",
    "such a collection naturally includes some pdf sets that are not `` acceptable '' fits to the input data ",
    ", in a collection of 100 monte carlo sets , one obviously expects to find @xmath4910 sets that lie outside of the 90% confidence region . in this approach ,",
    "the pdf uncertainty for a quantity is obtained by simply calculating that quantity for each of the sample pdf sets : the distribution of results directly represents the predicted uncertainty range .",
    "the ct09 fit discussed in secs .",
    "[ subsec : hessian ] and [ subsec : choiceofeigenvectors ] is our most up - to - date set of parton distributions .",
    "the central gluon fit and its uncertainty are shown in fig .",
    "[ fig : figeight ] at scales @xmath71 and @xmath72 , compared with the previous cteq6.6 @xcite fit . the uncertainty band has narrowed somewhat as a result of including the new jet data and the quartic penalties  except at extremely large @xmath1 , where the more flexible gluon parametrization in ct09 has broadened the allowed range .",
    "there is a strong overlap between the old and new uncertainty bands , and the central fit has shifted by an amount that is within or just at the edge of those bands . at a large scale such as @xmath73 , there is rather little change between the old and new determinations .",
    "[ fig : figeight ] shows that the ct09 central fit at small scale has a featureless behavior at large @xmath1 , in contrast to the mild `` shoulder '' structure of cteq6.6 .",
    "( the appearance of this shoulder is enhanced by the factor @xmath74 that multiplies @xmath64 in the plot to emphasize the large @xmath1 behavior . ) indeed , mstw @xcite remark that in fitting the new jet data , they no longer need to use their former convoluted method of parametrizing the gluon in the dis scheme and transforming it to @xmath75 .",
    "however , we find that with a properly flexible parametrization , some type of shoulder structure is not ruled out  indeed , the original cteq6.6 central fit for the gluon distribution still lies within our allowed uncertainty range . in detail , @xmath5 for the jet experiments ( cdf@xmath76 , d0@xmath76 , cdf@xmath77 , d0@xmath77 ) are @xmath78 in ct09 ; @xmath79 in a fit with the gluon shape identical to cteq6.6 ; and @xmath80 in a fit using the cteq6.6 gluon parametrization with the parameters refitted .    the change between cteq6.6 and ct09 in the shape of the gluon distribution is a consequence of interplay between adding the run ii jet data and increasing the flexibility of the gluon parametrization .",
    "this is studied in fig .",
    "[ fig : fignine ] . the solid curve and shaded region are again ct09 and its uncertainty .",
    "the dotted curve is cteq6.6 .",
    "the dot - dash curve is the result of repeating the cteq6.6 fit using the ct09 gluon parametrization .",
    "note that this increased freedom for the gluon shape enhances the shoulder , and does not move the fit closer to ct09 .",
    "the short - dashed curve is the result of including the run ii data , with all other details of the fit being the same as in cteq6.6 : this changes the fit about half way to ct09 . but",
    "with the run ii data included , bringing in the more flexible gluon parametrization now produces the rest of the change to ct09 .",
    "finally , the long - dashed curve is a fit that is identical to ct09 except for dropping the run i jet data .",
    "this answers the question raised earlier regarding the degree of tension between run i and run ii jet data from a practical point of view : we see that the effect of the run i data on the fit is noticeable but small compared to the other uncertainties .",
    "it is instructive to examine the preferences of various combinations of the four jet data sets in the fit .",
    "this is shown in fig .",
    "[ fig : figten ] .",
    "the solid curve and shaded region are again ct09 in both panels .",
    "the other curves were obtained by fits with weight 1 for all nonjet experiments , and weights 0 or 1 for each jet experiment as listed in the captions .",
    "the four curves in the left panel correspond to the first four fits in table  [ table : table1 ] .",
    "there is a slight difference between the ( 1,1,1,1 ) curve and ct09 , because we have chosen to apply somewhat larger weights ( 1.3,1.3,2.1,2.1 ) to these experiments in ct09 .",
    "the fit with no input from jet data ( 0,0,0,0 ) is substantially lower than any of the other fits at large @xmath1this is a review of why the first jet data made such a strong impact on the gluon determination ! the four curves in the right panel show the preferences of the individual jet experiments .",
    "the d0@xmath76 data shows its famous preference for a peak at large @xmath1 ; though table  [ table : table1 ] shows that it can be fit with nearly as good @xmath5 without the peak .",
    "the difference between the cdf@xmath77 and d0@xmath77 curves is comparable to our error estimate , which affirms that our error estimate is not overly conservative .",
    "figure [ fig : figeleven ] explores the consequences of some of the choices that were made in producing ct09 .",
    "the solid curve and shaded region are ct09 itself at scale @xmath81 .",
    "we first change the quark masses @xmath82 and @xmath83 , and change @xmath84 to maintain @xmath85 .",
    "these changes are found to have a negligible effect on the gluon distribution : the change is smaller than the width of the line in the figure .    in our basic fitting procedure",
    "@xcite we routinely employ weight factors to improve the quality of fit to certain key experiments .",
    "in particular , weights of 1.3 and 2.1 were applied to the run i and run ii data respectively in ct09 , and a further contribution proportional to @xmath50 was added for these experiments as discussed in sec .",
    "[ subsec : modifiedweights ] . the dotted curve in fig .",
    "[ fig : figeleven ] shows the effect of setting all of the weight factors to 1 ( including those for the jet experiments ) and dropping the quartic penalty .",
    "the resulting change is very small .",
    "( the real purpose of the weights is toward maintaining acceptable fits to all experiments as we move away from the best fit to estimate uncertainties . )",
    "the short - dash curve in fig .",
    "[ fig : figeleven ] shows the effect of dropping the run i data , keeping the weights at 1 , but restoring the quartic penalties on run ii jet @xmath5 values .",
    "finally , the long - dash curve is similar except that the quartic penalties have also been dropped .",
    "this fit has weight 1 for all experiments except for dropping the older jet data , and no extra penalties added to @xmath5 .",
    "some would argue this to be the most natural choice ; though our belief is that it is preferable to apply some emphasis in the global fit to experiments that measure an important feature with a relatively small number of data points . in any case",
    ", the uncertainty band shown is seen to do a reasonable job of encompassing the results of various plausible choices . if it were made much narrower by a smaller @xmath63 criterion",
    ", it would not do so .",
    "_ thus we see that a large part of the uncertainty  and the need for the @xmath86 criterion  arises from differences in plausible choices involved in making the global fit , rather than directly from propagating the experimental errors given in the data . _",
    "we compare our work with recent results from mstw @xcite in fig .",
    "[ fig : figtwelve ] .",
    "the solid curve and shaded region show the central fit and uncertainty range for ct09 , as in the preceding figures . to make a straightforward comparison , all other curves in fig .",
    "[ fig : figtwelve ] use the mstw values @xmath87 , @xmath88 , @xmath89 .",
    "the dotted long dashed curve is a fit that is the same as ct09 except for the change in @xmath90 ( and the change in quark masses , which has a negligible effect ) .",
    "the dotted short dashed curve is mstw2008nlo .",
    "it is surprisingly different from the @xmath3-modified ct09 , though it lies within our estimated 90% confidence region .    to look for the cause of the difference between the @xmath3-modified ct09 result and mstw",
    ", we explore a series of modifications to the ct09 procedure that make it more like that of mstw .",
    "these are the same modifications that were discussed in connection with fig .",
    "[ fig : figeleven ] .",
    "first we drop the cdf@xmath76 and d0@xmath76 data sets .",
    "this leads to the dotted curve in fig .",
    "[ fig : figtwelve ] , which is closer to the mstw result at large @xmath1 , but still quite far from it .    the dashed curve in fig .  [ fig : figtwelve ] corresponds to again dropping the run i data sets , while also setting the weight factors for all experiments to 1 and dropping the quartic penalties on @xmath91 .",
    "this reduces the influence of the jet data , and hence results in a fit that is closer to no - jets fits , which have a lower gluon at large @xmath1 .",
    "this dashed - curve fit is the most similar in its approach and result to that of mstw ; but a noticeable difference still remains .",
    "we can only speculate on what might be responsible for this difference , with obvious suspects being the different parametrizations used , or the neglect of correlated systematic errors for dis data in the mstw fit .",
    "other possible sources for the difference is that there are some differences in which data sets are included in the fits , and a difference in the kinematical cuts in @xmath92 and @xmath93 that are applied to those data sets .",
    "furthermore , there are small differences in the treatment of heavy quarks ; and a small difference in the definition of @xmath94 at nlo , even when the values are matched at @xmath95 ( see @xcite ) .",
    "the good agreement of the central fits with the run ii jet data , when systematic error shifts allowed by the published data are included , is shown in figs .",
    "[ fig : figthirteen ] and [ fig : figfourteen ] .",
    "the unshifted data points are also shown .",
    "these are quite far from the theory curves : the systematic errors are much larger than the statistical ones here , so fitting the systematic error parameters is an essential part of fitting these data sets .",
    "there are 24 systematic shifts for cdf@xmath77 , whose fitted values come out of order 1 as they should : -0.1 , -1.0 , -0.3 , -1.0 , 0.7 , -0.2 , 0.8 , -0.7 , -0.7 , -0.9 , 0.1 , 0.6 , 1.0 , -0.3 , -0.3 , 0.5 , -1.2 , 0.4 , 0.9 , 0.0 , -1.3 , 0.1 , -0.1 , -0.3 .",
    "the fitted overall normalization factor is @xmath96 , which is well within the published 6% error .",
    "there are 22 systematic shifts for d0@xmath77 ( in addition to the overall normalization ) .",
    "some of these come out a bit larger , though they are still of order 1 : -0.5 , -1.6 , 0.0 , 0.1 , -0.8 , -0.5 , 0.1 , 1.1 , -0.4 , 1.1 , -1.1 , -0.4 , 0.4 , -1.6 , -0.2 , -1.9 , 0.5 , 0.3 , 0.2 , 1.7 , -1.1 , -0.1 .",
    "we presume these shifts to be reasonable , since their overall @xmath5 probability is acceptable , and since  as is typical of systematic errors  their experimental assessment must be partly subjective . for what it is worth ,",
    "we find it absolutely necessary for some of these shift parameters ( most notably , `` dsys015 : eta - intercalibration fit '' ) to have magnitude larger than 1.5 in order to achieve an acceptable fit to these data within the global fit .",
    "the fitted overall normalization factor is @xmath97 , which is well within the published error estimate .",
    "we have carefully examined the nlo treatment of inclusive jet data and its influence on the determination of the gluon distribution in a qcd global analysis .",
    "key features of the analysis are the use of sufficiently flexible functional forms to reduce parametrization dependence , and full inclusion of the correlated systematic errors published by the experiments .",
    "the difference between the new ct09 gluon results and our previous cteq6.6 analysis @xcite is shown in fig .",
    "[ fig : figeight ] . at a large scale like @xmath73 , where the high - x gluon pdf is important for many high - profile signal and background processes at the tevatron and lhc ,",
    "the impact of the new jet data is quite small compared to the remaining uncertainty  as was expected from the outset , since the new data agreed fairly well with their prediction from cteq6.6 and its uncertainty range .    at the small scale @xmath71 , where the constraints on the gluon are rather indirect , fig .",
    "[ fig : figeight ] shows that the change in the central prediction at some values of @xmath1 is close to the 90% confidence limit of the uncertainty estimated in cteq6.6 .",
    "this demonstrates that our method does not overestimate those uncertainties , is spite of its tolerance for a range of @xmath5 that is large by ideal statistical standards .",
    "we have introduced an extension of the familiar hessian matrix method @xcite for uncertainty analysis .",
    "the extension involves making a further orthogonal transformation of the coordinates , after the transformation that diagonalizes the hessian has been carried out .",
    "this leaves the hessian matrix in its convenient diagonal form , while offering the possibility to describe the uncertainty on a given quantity using a small number of important eigenvector sets .",
    "this is illustrated in the right - hand side of fig .",
    "[ fig : figsix ] , where most of the gluon uncertainty near @xmath98 is given by just one or two eigenvector pairs . a further application of this extension of the hessian method provides a new and improved method to study the compatibility of the data sets in a global fit .",
    "this is described in a separate publication @xcite .",
    "one value of this paper is to document and illustrate methods that can be used to incorporate new data sets into a global analysis .",
    "there will be many opportunities to apply this in the near future , as data from tevatron run ii and hera run ii continue to arrive , and with data from the lhc on the horizon .    to conclude with a speculation , it is interesting to compare the extracted gluon distribution with the distributions for up and down quarks .",
    "this comparison is shown in fig .",
    "[ fig : figfifteen ] .",
    "the quark distributions have smaller uncertainties than the gluon  particularly the up quark , whose larger electric charge makes it prominent in the extensive body of neutral - current dis measurements .",
    "surprising as it may seem , we observe that at a small scale like @xmath99 , the gluon pdf is most likely larger than the down quark distribution even at very large @xmath1 .",
    "it may or may not even be larger than the up quark distribution  more data will be needed to determine that .",
    "an important challenge for further study would be to see if perhaps one can argue convincingly from models of the nonperturbative physics of the proton that `` valence - like '' gluon alternatives where @xmath100 at large @xmath1 are unphysical , in which case the uncertainty in pdfs could be significantly reduced .",
    "_ in memoriam : _ it has been our pleasure to work with , and be inspired by , our late mentor , colleague , and friend wu - ki tung .",
    "much of the methodology of modern pdf global analysis was his innovation , and he remained involved in this work to the end of his life .",
    "we thank d.  soper for discussions on the eks nlo jet program .",
    "we thank kenichi hatakeyama for providing the cdf run ii data files .",
    "we thank m.  ubiali , a.  guffanti , s.  forte , and j.  rojo for discussions on the nnpdf approach .",
    "the revised version of the paper benefited from insightful suggestions from the anonymous referee for phys .",
    "d.    this research was supported by the u.s .",
    "national science foundation under grants phy-0354838 , phy-055545 , and phy-0757758 ; u.s .",
    "department of energy under grant de - fg02 - 04er41299 ; national center for theoretical sciences and national science council of taiwan under grant nsc-97 - 2112-m-133 - 001 ; and by the lightner - sams foundation .",
    "here we sketch how the eigenvector pdf sets in a global qcd analysis can be recalculated to more simply represent the uncertainty of a particular physics quantity , such as the gluon distribution at large @xmath1 that is studied in this paper .",
    "see @xcite for a more detailed description .",
    "the standard hessian method for error analysis is based on a quadratic expansion of @xmath19 in the neighborhood of the minimum of a global fit .",
    "this expansion follows from taylor series : @xmath101 where there are no first - order terms because the expansion is about the minimum , and terms higher than second order have been dropped .",
    "the @xmath102 in eq .",
    "( [ eq : chi1 ] ) are the parton parameters of the global fit , and quantities with superscript @xmath103 are evaluated at the minimum of @xmath5 .",
    "formally , one can express the displacements @xmath104 as linear combinations of the normalized eigenvectors of the matrix of second derivatives to obtain a diagonal expression @xmath105 in which the new coordinates @xmath57 are the coefficients that multiply the eigenvectors . because nonquadratic behavior appears at widely different scales in different directions of the parameter space , and",
    "because the second - derivative matrix must be calculated numerically by finite differences , it is necessary in practice to compute the linear transformation from coordinates @xmath106 to coordinates @xmath57 by a series of iterative steps @xcite .",
    "the choice of eigenvectors that define the transformation to the diagonal form ( [ eq : chi2 ] ) is not unique , because any further orthogonal transformation of the parameters @xmath107 will preserve that form .",
    "this freedom to make a further orthogonal transformation can be used to simultaneously diagonalize any one additional function of the coordinates within the quadratic approximation .",
    "specifically , if @xmath108 is a function of the original coordinates , one can choose the new coordinates such that @xmath109 while maintaining ( [ eq : chi2 ] ) .",
    "this form ( [ eq : gappendix ] ) , which is accurate through second order in the @xmath107 , is obtained by the following recipe : ( 1 ) calculate the symmetric matrix @xmath110 using the `` old '' @xmath107 by finite differences ; ( 2 ) express these `` old '' @xmath107 as linear combinations of the eigenvectors of that matrix ; ( 3 ) the coefficients of these linear combinations become the desired `` new '' @xmath107 .",
    "these steps are iterated a few times to refine the transformation .",
    "this procedure is described explicitly in @xcite .    in the iterative procedure used in our previous uncertainty",
    "analyses @xcite , the quantity @xmath108 defining the transformation ( [ eq : gappendix ] ) was the overall length - squared of the displacement from the minimum in the space of the original shape parameters : @xmath111 . to study the uncertainties of @xmath0 at large @xmath1 , we can instead choose @xmath108 to be a mellin moment of some pdf , such as @xmath112 with @xmath113 ; or we can simply choose @xmath114 , e.g. , at @xmath115 as was done to create the right hand side of fig .",
    "[ fig : figsix ] . to facilitate the study of some interesting physical quantities",
    ", one might want to choose @xmath108 to be , say , the cross section for @xmath93 , @xmath116 , or higgs boson production .",
    "another choice , which is useful for exploring the internal consistency of a global fit , is to define @xmath108 as the contribution to @xmath5 from a particular subset of the data .",
    "this application is the subject of @xcite .",
    "v.  m.  abazov _ et al . _",
    "[ d0 collaboration ] , phys .",
    "* 101 * , 062001 ( 2008 ) [ arxiv:0802.2400 [ hep - ex ] ] .",
    "a.  abulencia _ et al .",
    "_ [ cdf - run ii collaboration ] , phys .  rev .",
    "d * 75 * , 092006 ( 2007 ) [ erratum - ibid .",
    "d * 75 * , 119901 ( 2007 ) ] [ arxiv : hep - ex/0701051 ] .",
    "j.  pumplin , d.  r.  stump , j.  huston , h.  l.  lai , p.  m.  nadolsky and w.  k.  tung , jhep * 0207 * , 012 ( 2002 ) [ arxiv : hep - ph/0201195 ] ; d.  stump , j.  huston , j.  pumplin , w.  k.  tung , h.  l.  lai , s.  kuhlmann and j.  f.  owens , jhep * 0310 * , 046 ( 2003 ) [ arxiv : hep - ph/0303013 ] ; w.  k.  tung , h.  l.  lai , a.  belyaev , j.  pumplin , d.  stump and c.  p.  yuan , jhep * 0702 * , 053 ( 2007 ) [ arxiv : hep - ph/0611254 ] .",
    "m.  nadolsky _ et al .",
    "_ , phys .",
    "d * 78 * , 013004 ( 2008 ) [ arxiv:0802.0007 [ hep - ph ] ] .",
    "a.  d.  martin , w.  j.  stirling , r.  s.  thorne and g.  watt , arxiv:0901.0002 [ hep - ph ] .",
    "a.  a.  affolder _ et al .",
    "_ [ cdf collaboration ] , phys .  rev .",
    "d * 64 * , 032001 ( 2001 ) [ erratum - ibid .",
    "d * 65 * , 039903 ( 2002 ) ] [ arxiv : hep - ph/0102074 ] .",
    "b.  abbott _ et al . _",
    "[ d0 collaboration ] , phys .",
    "d * 64 * , 032003 ( 2001 ) [ arxiv : hep - ex/0012046 ] .",
    "f.  abe _ et al . _",
    "[ cdf collaboration ] , phys .",
    "lett .   * 77 * , 438 ( 1996 ) [ arxiv : hep - ex/9601008 ] . j.  huston , e.  kovacs , s.  kuhlmann , h.  l.  lai , j.  f.  owens , d.  e.  soper and w.  k.  tung , phys .  rev",
    ".  lett .",
    "* 77 * , 444 ( 1996 ) [ arxiv : hep - ph/9511386 ] .",
    "j.  pumplin , d.  r.  stump and w.  k.  tung , phys .",
    "d * 65 * , 014011 ( 2001 ) [ arxiv : hep - ph/0008191 ] .",
    "r.  d.  ball _ et al . _",
    "[ nnpdf collaboration ] , nucl .",
    "b * 809 * , 1 ( 2009 ) [ arxiv:0808.1231 [ hep - ph ] ] .",
    "j.  c.  collins and j.  pumplin , arxiv : hep - ph/0105207 .",
    "m.  nadolsky , `` correlated systematic errors in the global qcd analysis , '' manuscript in preparation .",
    "s.  chekanov _ et al .",
    "_ [ zeus collaboration ] , eur .",
    "j.   c * 42 * , 1 ( 2005 ) [ arxiv : hep - ph/0503274 ] .",
    "d.  stump _ et al .",
    "_ , phys .",
    "d * 65 * , 014012 ( 2001 ) [ arxiv : hep - ph/0101051 ] .",
    "j.  pumplin _ et al .",
    "_ , phys .",
    "d * 65 * , 014013 ( 2001 ) [ arxiv : hep - ph/0101032 ] .",
    "j.  pumplin , a.  belyaev , j.  huston , d.  stump and w.  k.  tung , jhep * 0602 * , 032 ( 2006 ) [ arxiv : hep - ph/0512167 ] .",
    "j.  huston , j.  pumplin , d.  stump and w.  k.  tung , jhep * 0506 * , 080 ( 2005 ) [ arxiv : hep - ph/0502080 ] ."
  ],
  "abstract_text": [
    "<S> inclusive jet production data are important for constraining the gluon distribution in the global qcd analysis of parton distribution functions . with the addition of recent cdf and d0 run ii jet data </S>",
    "<S> , we study a number of issues that play a role in determining the up - to - date gluon distribution and its uncertainty , and produce a new set of parton distributions that make use of that data . </S>",
    "<S> we present in detail the general procedures used to study the compatibility between new data sets and the previous body of data used in a global fit . </S>",
    "<S> we introduce a new method in which the hessian matrix for uncertainties is `` rediagonalized '' to obtain eigenvector sets that conveniently characterize the uncertainty of a particular observable . </S>"
  ]
}