{
  "article_text": [
    "many gamma ray experiments have to deal with the problem of separating gammas from hadrons . the experiments usually generate large data sets with many attributes in them .",
    "this multi - dimensional data classification problem offers a daunting challenge of extracting small number of interesting events ( gammas ) from an overwhelming sea of background ( hadrons ) .",
    "many techniques are in active research for addressing this problem .",
    "the list includes classical statistical multivariate techniques to more sophisticated techniques like neural networks , classification trees and kernel functions .",
    "the class of neural networks provides an automated technique for the classification of the data set into given number of classes  @xcite .",
    "it is in active research in both artificial intelligence and machine learning communities .",
    "several neural network models have been developed to address the classification problem .",
    "usually , one makes the distinction between supervised and unsupervised classifiers : the former are trained with data for which the classification is known and then used to classify raw data , while the latter attempt to find the best - fitting class structure in the input data by using some measure of merit ( usually an euclidean metric is used  @xcite ) . from a mathematical perspective ,",
    "a neural network is simply a mapping from @xmath0 , where @xmath1 is the input data set dimension and @xmath2 is the output dimension of the neural network .",
    "the network is typically divided into various layers ; each layer has a set of neurons also called nodes or information units , connected together by the links .",
    "the artificial neural networks are able to classify data by learning how to discriminate patterns in features ( or parameters ) associated with the data .",
    "the neural network learns from the data set when each data vector from the input set is subjected to it .",
    "the learning or information gain is stored in the links associated with the neurons .",
    "the output structure of the network is dependent on both the problem and the network type . for a gamma / hadron separation problem",
    "the network maps each input vector onto the [ 0,1 ] interval in supervised networks , whereas in unsupervised networks the nodes are adapted to the input vector in such a way that the output of the network represents the natural groups that exist in the data set . the output of the unsupervised network is generally stored in an ascii file .",
    "a visualization technique is then used to view the groups by processing the output file generated by the network .",
    "section 2 describes the data sets used for the classification .",
    "section 3 deals with the multilayer perceptron network and its classification results .",
    "section 4 deals with the self - organizing tree algorithm and its variant along with their classification results .",
    "conclusions and future perspectives are discussed in the section 5 .",
    "the data sets are generated by a montecarlo simulation program , corsika  @xcite .",
    "they contain 12332 gammas , 7356 on events ( mixture of gammas and hadrons ) , and 6688 hadron or off events .",
    "these events are stored in different files .",
    "the files contain event parameters in ascii format , each line of 10 numbers being one event  @xcite with the parameters defined below .    1",
    ".   _ length _ : major axis of ellipse [ mm ] 2 .",
    "_ width _ : minor axis of ellipse [ mm ] 3 .   _",
    "size _ : 10-log of sum of content of all pixels 4 .",
    "_ conc _ : ratio of sum of two highest pixels over fsize [ ratio ] 5 .   _",
    "conc1 _ : ratio of highest pixel over fsize [ ratio ] 6 .",
    "_ asym _ : distance from highest pixel to centre , projected onto major axis [ mm ] 7 .   _",
    "m3long _ : 3rd root of third moment along major axis [ mm ] 8 .   _",
    "m3trans _ : 3rd root of third moment along minor axis [ mm ] 9 .",
    "_ alpha _ : angle of major axis with vector to origin [ deg ] 10 .",
    "_ dist _ : distance from origin to centre of ellipse [ mm ]    these hillas image parameters @xcite are derived from pixel analysis and are used for classification .",
    "for this approach we used the root analysis package ( v4.00/02 ) and in particular the multilayer perceptron class  @xcite which implements a generic layered network .",
    "since this is a supervised network we took two thirds of gamma and off data to train the network and the remaining data to test it.the code of the root package is very flexible and simple to use .",
    "it allowed us to create a network with a 10 nodes input layer , a hidden layer with the same number of nodes and an output layer with just a single neuron which should return `` 0 '' if the data represent hadrons or `` 1 '' if they are gammas .",
    "weights are put randomly at the beginning of the training session and then adjusted from the following runs in order to minimize errors ( back - propagation ) .",
    "errors at cycle @xmath3 are defined as : @xmath4 where @xmath5 is the error of the output node .",
    "data to input and output nodes are transferred linearly , while for hidden layers they use a sigmoid ( usually : @xmath6 ) .",
    "we have tested the same network using different learning methods proposed by the code authors , as for example the so called `` stochastic minimization '' , based on the robbins - monro stochastic approximation , but the default `` broyden , fletcher , goldfarb , shanno '' ( bfgs ) method has proved to be the quickest and with the best error approximation .",
    "figures [ mlp].a and [ mlp].b represent a possible output when using the root package on those data .",
    "the first one depicts the error function for each run of the network , comparing the training and the test data .",
    "note that the greater is the number of runs , the better the network behaves .",
    "the second one shows the distributions of output nodes , that is how many times the network decides to give a value near to `` 0 '' or to `` 1 '' .",
    "the self - organizing tree algorithm @xcite is an unsupervised neural network which implements a growing hierarchical clustering and is based on the self organising map network @xcite .",
    "it hierarchically clusters the data into a binary tree of natural groups that exist in the data set .",
    "initially the tree consists of one root node linked to 2 child cells .",
    "all the input events are randomly distributed between the 2 initial child nodes .",
    "the tree grows by expanding the child node having the most heterogeneous population of associated inputs .",
    "two new descendants are generated from this heterogeneous cell that changes its state from cell to node .",
    "the tree then grows by descending the cells into child nodes until each cell has one single input sequence , producing a complete classification of the sequences .",
    "classification results.,width=302 ]    alternatively , the expansion can be stopped at the desired level of heterogeneity in the cells , producing in this way a classification of sequences at a higher taxonomic level .",
    "this kind of classification could be useful for astrophysics when a multi - event separation is needed on the same dataset , that is when multiple particles have been detected simultaneously and the analysis software should assign them a label ( as `` proton '' , `` muon '' , `` gamma '' , etc . ) .",
    "they are also used as a data mining tool to explore the natural groups that exists in data sets .",
    "using the magic datasets the tree has grown up to 10 levels , with the training sets taken from the montecarlo simulations ( figure [ sotares ] ) .",
    "this approach gives a hierarchical view of data , is robust for noisy data and is faster than traditional hierarchical clustering .",
    "flow for a sota - mlp network using montecarlo datasets.,width=340 ]      figure [ schema1 ] shows the combination of sota with mlp for the separation task .",
    "the sota method is applied to the initial montecarlo datasets ( gamma , on and off ) to find the natural clusters that exist in the datasets .",
    "the sota tree produced two clusters of gamma and hadron which are used to train the mlp .",
    "preliminary result using an mlp feeded with sota labelled datasets.,width=302 ]    the sota cluster emulates the data distribution of the patterns , thus reducing the number of events in the training set .",
    "the use of these clustered data can result in fast training for the mlp .",
    "the trained mlp network is then used to perform testing through the on dataset and producing hadron probability for each event .",
    "the preliminary results for this approach are shown on figure [ sotamlp ] where we can notice a better separation in the histograms respect to the non - treated mlp results ( figure [ mlp].b ) .",
    "in this article we classified the gamma ray data using mlp and sota .",
    "both mlp and sota shown some good classification results .",
    "the algorithms used here suggest that a complex problem could not be solved using standalone methods even if they are suitable for a large part of other data analysis problems .",
    "sota algorithm clusters the data set into groups thus reducing the number of events in the training set",
    ". this can be useful for the magic experiment where there are overwhelming events to be classified .",
    "mlp based on supervised technique identifies the group labels , but the training session could be longer . by combining sota with mlp we can significantly decrease the training period and yield better classification results .",
    "the work can be further extended by using combination of different models in both self - organizing networks and supervised networks .",
    "future experiments can be done using growing cell structures and growing neural gas models @xcite in the unsupervised category . in",
    "supervised networks , tests can be performed by using probabilistic networks and mlp trained with fast back - propagation .",
    "99 a.m.  hillas , proc .",
    "19th icrc , la jolla 3 ( 1985 ) 445 d.  heck , et al . ,",
    "corsika , _ a monte carlo code to simulate extensive air showers _ , forschungszentrum karlsruhe , report fzka 6019  ( 1998 ) s.  lawrence et al .",
    ", _ neural network classification and prior class probabilities _ , lecture notes in computer science state - of - the - art surveys , edited by g.  orr et al . , springer verlag , pp .",
    "299 - 314  ( 1998 ) c.  delaere , _ multilayer perceptron root class _ , http://root.cern.ch r.k .",
    "bock et al . , _ methods for multidimensional event classification : a case study using images from a cherenkov gamma - ray telescope _ , nuclear instruments and methods in physics research , a 516  ( 2003 ) rajaniemi et al .",
    ", _ classifying gamma - ray bursts using self - organizing maps _",
    "t.  kohonen _ self - organizing maps _ , 2nd ed .",
    ", springer  ( 1997 ) j.  dopazo , j.m .",
    "carazo _ phylogenetic reconstruction using an unsupervised growing neural network that adopts the topology of a phylogenetic tree _",
    ", j.  mol .",
    "( 1997 ) 44:226 - 233 b.  fritzke , _ a growing neural gas network learns topologies _ , in _ advances in neural information processing systems 7 _ , g.  tesauro , d.s .",
    "touretzky and t.  k.  leen , editors , mit press  ( 1995 )"
  ],
  "abstract_text": [
    "<S> neural networks have proved to be versatile and robust for particle separation in many experiments related to particle astrophysics . </S>",
    "<S> we apply these techniques to separate gamma rays from hadrons for the magic erenkov telescope . </S>",
    "<S> two types of neural network architectures have been used for the classification task : one is the multilayer perceptron ( mlp ) based on supervised learning , and the other is the self - organising tree algorithm ( sota ) , which is based on unsupervised learning . </S>",
    "<S> we propose a new architecture by combining these two neural networks types to yield better and faster classification results for our classification problem . </S>"
  ]
}