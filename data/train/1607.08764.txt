{
  "article_text": [
    "depiction - invariant object recognition is the ability to determine an object s category regardless of how the object is visually depicted ( line drawing , realistic shaded drawing , photograph etc . ) . given the varying level of abstraction and complexity in depiction ( see figure [ fig : datasetpic ] ) , this is a challenging task .",
    "human beings easily accomplish depiction - invariant recognition but machine - based systems are nowhere close to a similar level of performance .",
    "current state - of - the - art object recognition architectures do achieve good performance but they are specialized for a single depiction style ( e.g. photos  @xcite , sketches  @xcite ) .",
    "therefore , designing architectures which recognize objects regardless of depiction style can facilitate progress towards matching human - level abilities . moreover",
    ", the associated performance scores can also aid in quantitatively determining the semantic gap between human and machine capabilities  @xcite .",
    "surprisingly , not much work exists for depiction - invariant object recognition . to address this gap",
    ", we propose a convolutional neural network ( cnn ) architecture for depiction - invariant object category recognition which we call swiden ( section [ sec : framework ] ) .",
    "a novel aspect of our architecture is a ` deep ' dynamic switching mechanism between two parallel cnn sub - architectures ( section [ switch ] ) .",
    "our switch - based design not only reduces the overall burden of the generalized object recognition task but also enables the system to address depiction - specific and depiction - invariant aspects of the problem .",
    "we compare our approach with baselines , alternative architectures ( section [ sec : comparisonarch ] ) and previous work on a @xmath0-category photo - art dataset containing multiple depictions of objects ( section [ sec : experiments ] ) .",
    "experimental results show that our architecture outperforms other architectures , especially for non - photo object depictions ( section [ sec : results ] ) .",
    "object class ( category ) recognition , albeit restricted to photographic depictions , has been studied extensively by researchers  @xcite .",
    "however , little previous work exists for truly general multi- depiction object recognition .",
    "wu et al .",
    "@xcite construct multi - attribute part - graphs for object categories and use graph matching for classification on the same dataset we use . however , their evaluation procedure , also used by cai et al .",
    "@xcite , induces an unreasonable amount of category bias which makes comparison difficult .",
    "we present an alternative evaluation procedure which is more principled ( see section [ datasets ] ) .",
    "xiao et al .",
    "@xcite present a graph - based object modelling approach and evaluate it on @xmath1 augmented classes of caltech-256 .",
    "shrivastava et al  @xcite utilize a depiction - invariant method for image matching .",
    "domain adaption approaches have been also been tried  @xcite",
    ". however , when the domain - specific identifiers ( e.g. target domain labels ) are available as in our case , a domain - adaptation procedure unnecessarily makes the overall problem harder since the objective in domain - adaptation is typically to  forget \" the source domain .",
    "all the approaches mentioned above utilize multiple hand - crafted modules in the recognition pipeline . to the best of our knowledge ,",
    "ours is the first end - to - end deep learning approach for depiction - invariant recognition of object categories .",
    "instead of learning from scratch , a common paradigm is to utilize pre - trained cnns as a starting point while constructing deep networks of interest .",
    "we follow a similar paradigm in our approach .    in an effort to represent the sheer variety seen in image content ,",
    "the convolutional layers in a cnn typically contain a large number of learnable filters .",
    "however , the filters are only sufficient to the extent that the depiction style remains unchanged ( e.g. photographs ) .",
    "to accommodate the increase in variety when images from additional depiction styles need to be recognized , a nave strategy would be to add additional learnable filters for each convolution layer of a pre - trained network and perform fine - tuning .",
    "however , this strategy results in an unbalanced learning regime since convolutional layers now contain a mixture of learnt and non - learnt filters .",
    "in addition , the added filters necessitate an ad - hoc grouping of filter layers to ensure operational consistency which further complicates the overall framework .",
    "an alternative design would be to learn the filters for each depictive style separately . in this design ,",
    "a set of shallow layer sub - networks exist for each depictive style ( see figure [ fig:3imgs](c ) ) .",
    "since our final objective is to achieve depiction - invariant recognition , we require our network to learn a depiction - invariant feature representation .",
    "this is achieved by having a final set of layers . to serve as a relay mechanism between the initial depiction - specific sub - network branches and the shared , deeper depiction - invariant fully - connected layers ,",
    "we employ a custom - designed  switch \" ( section [ switch ] ) .",
    "the switch is trained such that given an image , it determines its depictive style and selects the corresponding depiction - specific sub - network for processing the image . the output of this sub - network",
    "is then processed by the depiction - invariant layers of the network .",
    "the network culminates in a typical softmax - based classification layer which determines the image category , regardless of its depictive style ( figure [ fig:3imgs](c ) ) .",
    "next , we describe the depiction style - based switching mechanism .",
    "subsequently , we delve into the architectural details of the main network pipeline which we dub swiden ( switching deep network ) .      to realize the switching mechanism mentioned in section [ sec : motivation ] , we design and train a switch network ( see figure [ fig:3imgs ] ( c ) ) , henceforth referred to as switch , that determines the depiction style of the input image and passes the image to corresponding depiction sub - network ( photo or art ) .",
    "the switch has two convolution layers which capture depiction - discriminative features such as edges , textures , corners , colors and their conjunctions  @xcite .",
    "the first convolution layer is initialized from alexnet  @xcite .",
    "the features from the first layer are max pooled while the features from the second convolution layer are average pooled globally  @xcite .",
    "the pooled features are processed by two fully connected layers and passed to a classifier layer which determines the depiction style of the input image as ` art ' or ` photo ' . for better generalization , we use dropout for fully connected layers with @xmath2 as the dropout value .",
    "we trained switch using stochastic gradient descent ( sgd )  @xcite with a base learning rate @xmath3 and momentum @xmath4 .",
    "overall , switch achieves an average accuracy of @xmath5 ( @xmath6 for ` art ' and @xmath7 for ` photo ' ) .",
    "switch s inability to achieve @xmath8 accuracy can be attributed to the fact that some photo images have a predominantly artistic quality and vice - versa ( see supplementary material ) .",
    "while this may seem like a liability , in practice , all we require is that switch achieve a reasonably high accuracy which ensures an overall burden reduction for the filter learning process .",
    "the initial portion of swiden consists of two separate sub - networks , one each for photo and art depiction style . during training , switch ( section [ switch ] )",
    "selects the sub - network branch through which the input image is passed in the forward pass and ensures that the corresponding network loss is backpropagated through the branch selected during the forward pass . the layers after switch are shared layers , designed to learn depiction - style invariant representations .",
    "for our problem , we build swiden using vgg-19 deep network  @xcite layers .",
    "we select a subset of initial convolutional layers of vgg-19 and utilize them as the sub - networks for each depictive style .",
    "the rest of the vgg-19 layers ( except the final classification layer ) are used as the shared layers of swiden .",
    "figure [ fig:3imgs](c ) illustrates a swiden architecture where the first four convolutional layers of vgg-19 are used for the depictive style sub - networks ( ` c1a ` - ` c4a ` for ` art ' and ` c1p ` - ` c4p ` for ` photo ' ) and the rest of vgg-19 layers ( ` c-5,fc-6,fc-7 ` ) form the shared portion .    in our experiments , we systematically examined the effect on recognition performance when the first @xmath9 convolutional layers of vgg-19 are used as depiction - style sub - networks ( section [ sec : results ] ) . for the rest of the paper",
    ", we refer to the corresponding architectures as * c1-s , c2-s , c3-s , c4-s * and * c5-s*. thus , the architecture in figure [ fig:3imgs](c ) is * c4-s*.",
    "we evaluate the classification performance on the photo - art-50 dataset  @xcite .",
    "this dataset contains @xmath0 classes and @xmath10 to @xmath11 images in each class with approximately half photo and half art images .",
    "the authors also provide train - test splits for comparative evaluation .",
    "however , the splits are unbalanced and do not include a validation split , thus inducing significant class bias during evaluation . to avoid this issue , we create our own train , validation and test splits .",
    "we create five random splits , each containing @xmath12 images from each category for training ( @xmath13 art and @xmath13 photo ) and @xmath14 images for testing ( @xmath1 art and @xmath1 photo ) .",
    "the remaining images from each category are used for validation .",
    "we augment the dataset by taking 5 crops of size @xmath15 ( four corner crops and the center crop ) after rescaling the smallest side of the image to @xmath16 . for training images ,",
    "the center crop alone is centered around the bounding box .",
    "multiple objects of same class in a single image are ignored .",
    "we plan to release our balanced splits to the public .        as a natural baseline , we fine - tune vgg-19 using the training data for the @xmath0 classes described in section [ datasets ] . for training",
    ", we used a stochastic gradient descent ( sgd ) method with a base learning rate @xmath17 and momentum @xmath4 to learn the weights .",
    "the learning rate was stepped down by a factor of @xmath1 when the validation accuracy plateaued .",
    "ganin et al .",
    "@xcite propose a deep network - based domain - adaptation framework .",
    "the authors aim to maximize the target domain accuracy by simultaneously minimizing the target - domain label loss function and maximizing the loss for domain type ( target or source ) classification . to achieve this",
    ", they introduce a gradient reversal layer which not only assists domain - adaptation but also helps learn a domain - invariant representation ( fc-8 in figure [ fig:3imgs](b ) ) .",
    "intrigued by this domain - invariance feature , we wished to examine the architecture s suitability for our cross - depiction problem by viewing depictive styles as domains .",
    "however , in their original formulation , ganin et al . maximize the accuracy for a single domain ( depictive style ) .",
    "therefore , we modify their formulation such that the overall network loss for _ both _ the domains ( ` art ' and ` photo ' ) is minimized . in addition , we replace alexnet used by ganin et al . with vgg-19 . for the rest of the paper",
    ", we shall refer to this modified formulation as gradient reversal network ( grn ) .",
    "we initialize grn with vgg-19 model weights and performed training using sgd with base learning rate of @xmath17 and momentum @xmath4 .",
    "a uniform learning rate was maintained throughout training .",
    "for the gradient reversal layer s scaling factor @xmath18 ( see @xcite for details ) , we tried values of @xmath19 and found that @xmath20 gave the best result .",
    "the same training procedure and hyperparameters as in the baseline were used for training swiden architectures * * c1-s , c2-s**@xmath21*c5-s * ( section [ swiden ] ) with the exception of the the learning rates for the depictive style sub - networks . for the ` art ' sub - network",
    ", we used a learning rate scaled by a factor of @xmath22 since the base network ( vgg ) is primarily trained for non - art images .",
    "the learning rate was stepped down by a factor of @xmath1 when the validation accuracy plateaued .      for evaluation",
    ", we determined the final label by pooling the results for five crops of the test image ( four corner crops and one center crop ) for all the architectures .",
    "we used caffe  @xcite for all experiments on the baseline .",
    "for swiden , we integrated the switch layer from a branch of caffe  @xcite into the master branch  @xcite and customized it for our experiments involving swiden . for experiments on grn , we used the caffe version provided by ganin et al .",
    ".classification accuracy for different architectures . [ cols=\"^,^,^,^\",options=\"header \" , ]",
    "in this paper , we have described swiden , our end - to - end deep learning framework for recognizing objects regardless of depiction .",
    "a key aspect of swiden is the ` deep ' depictive style - based switching mechanism which judiciously addresses depiction - specific and depiction - invariant aspects of the problem .",
    "addressing these aspects enables us to achieve state - of - the - art results on a challenging dataset containing ` photo ' and ` art ' style object depictions . in future , we plan to explore unsupervised network learning approaches .",
    "our code and pre - trained models can be accessed at https://github.com/val-iisc/swiden .",
    "h.  cai , q.  wu , and p.  hall . beyond photo - domain object recognition : benchmarks for the cross - depiction problem . in _ proceedings of the ieee international conference on computer vision workshops _ ,",
    "pages 16 , 2015 .",
    "r.  fergus , p.  perona , and a.  zisserman .",
    "object class recognition by unsupervised scale - invariant learning . in _ computer vision and pattern recognition , 2003 . proceedings .",
    "2003 ieee computer society conference on _ , volume  2 , pages ii264 .",
    "ieee , 2003 .",
    "s.  fidler and a.  leonardis . towards scalable representations of object categories : learning a hierarchy of parts . in _",
    "computer vision and pattern recognition , 2007 .",
    "ieee conference on _ , pages 18 .",
    "ieee , 2007 .",
    "b.  xiao , s.  yi - zhe , and p.  hall . learning invariant structure for object identification by using graph methods .",
    ", 115(7):1023  1031 , 2011 .",
    "special issue on graph - based representations in computer vision ."
  ],
  "abstract_text": [
    "<S> current state of the art object recognition architectures achieve impressive performance but are typically specialized for a single depictive style ( e.g. photos only , sketches only ) . in this paper , we present swiden : our convolutional neural network ( cnn ) architecture which recognizes objects regardless of how they are visually depicted ( line drawing , realistic shaded drawing , photograph etc . ) . in swiden , we utilize a novel ` deep ' depictive style - based switching mechanism which appropriately addresses the depiction - specific and depiction - invariant aspects of the problem . we compare swiden with alternative architectures and prior work on a @xmath0-category photo - art dataset containing objects depicted in multiple styles . </S>",
    "<S> experimental results show that swiden outperforms other approaches for the depiction - invariant object recognition problem . </S>"
  ]
}