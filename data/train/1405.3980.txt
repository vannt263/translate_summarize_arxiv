{
  "article_text": [
    "shannon s rate distortion theory finds the optimal compression rate for a given distortion for an i.i.d .  discrete signal . for continuous signals",
    ", shannon assumes that the signal is sampled at the nyquist rate .",
    "thus , in shannon s protocol , distortion occurs at the quantization phase ; no information about the signal is discarded in the sampling phase .",
    "but since only the end - to - end distortion is of importance , one can accept some distortion at the sampling phase , by sampling the signal below the nyquist rate .",
    "in other words , we can discard information about the signal in both the sampling and quantization phases .",
    "this has the benefit of saving in the sampling rate , which can improve power and computational efficiency of the system @xcite .",
    "furthermore , choosing the sampling locations ( _ nonuniform sampling _ ) , one can further reduce the sampling rate .",
    "nonuniform sampling works by measuring signal values at a set of arbitrary locations in time .",
    "this can occur when we are either unable to uniformly sample the signal due to some physical constraints , or when we lose some of the samples after uniform sampling . furthermore , nonuniform sampling is helpful in dealing with aliasing @xcite , even though characterizing  the effective bandwidth \" under nonuniform sampling is difficult .",
    "similar to uniform sampling , it has been shown that for reliable recovery , the average sampling rate must be at least twice the bandwidth of the signal @xcite .",
    "see @xcite for an overview of nonuniform sampling .",
    "consider the problem of finding the best locations for sampling a continuous signal to minimize the reconstruction distortion . to find the optimal sampling points",
    ", one should utilize any available prior information about the structure of the signal .",
    "furthermore , sampling noise should be taken into account . due to its importance , nonuniform sampling and its stability analysis has been the subject of numerous works .",
    "however , there has been relatively less work for a fully bayesian model of the signal and sampling noise , where one is interested in the statistical _ average _ distortion of signal reconstruction over a class of signals . in this paper",
    ", we study this problem for stationary periodic bandlimited signals .",
    "* previous works : * while there has been some previous work on the tradeoffs between sampling rate , quantization of samples and reconstruction distortion @xcite-@xcite ; there has been relatively fewer papers on finding the best locations of nonuniform sampling for minimizing reconstruction distortion @xcite-@xcite .",
    "the best locations of nonuniform sampling via an _ adaptive sampling _ method is considered in @xcite for a first order markov source . they propose a new framework based on dynamic programming and greedy methods to compute the sampling time increments using the @xmath0 most recent sampling times and values . a tradeoff among sampling rate , information rate and distortion of uniform sampling",
    "is derived in @xcite for gaussian sources corrupted by noise .",
    "one major difference between the assumptions in @xcite and ours is that they looks at uniform sampling while we consider both uniform and nonuniform sampling .",
    "the authors in @xcite look at choosing the sampling points for a stationary gaussian signal with auto - correlation function @xmath1 .",
    "it is shown that uniform sampling is optimal in this case .",
    "matthews @xcite considers a wide - sense stationary process , and computes the linear mmse estimate from sub - nyquist uniform samples .",
    "the authors in @xcite compute the optimal pre- and post - filters for a signal corrupted by noise , when uniform sampling is used .",
    "the problem is formulated in such a way that it is applicable to different types of modulation systems such as pam , pcm and dpcm .",
    "the authors in @xcite derive a rate distortion function for lossy reconstruction of a multi - component signal , when only a subset of the signal components are sampled .",
    "there has been some work in compressed sensing on the tradeoffs between the number of samples and the reconstruction error . here the samples are linear measurements , and the goal is to recover the sparsity pattern with a given distortion level . in @xcite , a sampling rate - distortion region",
    "is found ; it is shown that arbitrarily small but constant distortion is achievable with a constant measurement rate and per - sample signal - to - noise ratio .",
    "the authors in @xcite define a sampling - rate distortion function for an i.i.d .",
    "source , and derive lower bounds on the achievable performance .",
    "application of the sampling - rate distortion framework to compressed imaging with a multi - resolution statistical image model are also considered .",
    "computing optimal sampling points when limited information about the signal is available , has also been considered in the literature .",
    "universal _ set of sampling points for a class of signals is one that allows reliable reconstruction , uniformly for all signals in this class . in @xcite ,",
    "a class of discrete signals with a limited number of non - zero frequency components are considered , and universal sampling locations are specified .    finally ,",
    "the problem of finding optimal sampling points is a task of general importance and has been studied in miscellaneous applications , e.g. @xcite-@xcite .",
    "* system model : * in this paper , we consider a continuous stationary periodic signal .",
    "the signal is assumed to be bandlimited , with at most @xmath2 non - zero fourier series coefficients from frequency @xmath3 to @xmath4 where @xmath5 is the fundamental frequency .",
    "since there are @xmath6 free variables , the signal can be uniquely reconstructed from @xmath7 noiseless samples ( landau rate ) .",
    "but as we consider taking @xmath8 _ noisy _ samples ( at time instances that we choose ) , unique reconstruction is not feasible , and distortion is inevitable .",
    "we also consider a pre - sampling filter in our model .",
    "see fig .",
    "[ fig1 ] for a description of our problem .",
    "the fourier series coefficients and the sampling noise are all random variables . therefore",
    ", both the input signal and its reconstruction from its samples are random signals , and so is the reconstruction distortion .",
    "one measure of fidelity is the expected value of distortion .",
    "another measure is the probability that the distortion exceeds a certain threshold ; this probability will be small if both the expectation and variance of the reconstruction distortion are small . in this paper",
    ", we consider minimizing both the expected value and variance of distortion , by choosing the best sampling points and the pre - sampling filter .",
    "we denote the minimum of the expected value and variance of distortion by @xmath9 and @xmath10 , respectively . a small",
    "@xmath9 guarantees a good _ average _ performance over all instances of the random signal , while a small @xmath10 guarantees that with high probability , we are close to the promised average distortion for a given random signal ( see also appendix [ appendixa ] for further justification ) .",
    "in essence , our goal is to find the tradeoffs between the number of samples ( @xmath8 ) , the pre - sampling filter , the variance of noise ( @xmath11 ) and the optimal expected value and the variance of distortion ( @xmath9 and @xmath10 ) .",
    "the literature in sampling theory looks only at minimizing the average distortion and ignores the variance of distortion .",
    "* overview of main contributions :",
    "* we provide tight results or bounds on the tradeoffs among various parameters such as distortion , sampling rate and sampling noise .",
    "when we are below half the landau rate , @xmath12 , we find the optimal average distortion ( @xmath9 ) and variance ( @xmath10 ) .",
    "interestingly , we show that the minimum of both @xmath9 and @xmath10 are obtained at the same sampling locations and the same pre - sampling filter .",
    "these two minima are obtained when we use no pre - sampling filter on the signal bandwidth , and use a nonuniform sampling procedure as given below : any arbitrary @xmath8 points from the set @xmath13 , which are uniform sampling points at the landau rate .",
    "observe that for @xmath14 , this is a non - uniform set of sampling points .",
    "it is worth to note that the sampling locations only depend on the bandwidth of the signal ; they are optimal for all values of the noise variance ( @xmath11 ) and @xmath15 . moreover , the sampling points are robust with respect to missing samples .",
    "note that the optimal sampling points are any arbitrary @xmath8 points from the set @xmath13 .",
    "thus , if we sample at these positions and we miss some samples , _",
    "i.e. , _ getting @xmath16 samples instead of @xmath8 samples , the set of @xmath17 sample points is still a subset of @xmath13 , and hence optimal .",
    "therefore , if we knew in advance that we get @xmath17 samples , this knowledge would not have helped us .",
    "finally , complete characterization of distortion in terms of @xmath8 and @xmath18 allows us to answer the question of whether it is better to collect a few accurate samples from a signal , or collect many inaccurate samples from the same signal ( a similar question has been raised in @xcite ) . for rates above half the landau rate , we provide lower and upper bounds that are shown to be tight in some cases . when @xmath19 , _",
    "i.e. , _ between half the landau rate and the landau rate , we find optimal average distortion when @xmath20 , using a non - uniform set of sampling locations .",
    "in addition , when @xmath21 , uniform sampling is shown to be optimal under certain constraints .",
    "whenever we find @xmath9 and @xmath10 explicitly , the minima are achieved simultaneously at the same optimal sampling points and the same pre - sampling filter .    as discussed earlier",
    ", there are two stages in compression of a continuous signal : sampling phase and quantization phase .",
    "the overall reconstruction distortion depends on the choices that we make in both phases .",
    "we show that the optimal distortion can be written as the sum of two terms : one for sampling distortion and one for quantization distortion .",
    "therefore , the problem essentially decomposes into two independent subproblems .",
    "furthermore , we show that the asymptotic shannon s rate distortion theory yields a lower bound on the compression distortion term .",
    "* structure of the paper : * this paper is organized as follows : the preliminaries are given in section [ preliminaries ] . in section [ sec : problemdef ] , the problem is formally defined . in section [ sec : main - results ] , the main results of the paper are presented ; the proofs are relegated to appendix [ proofs ] . in section [ simulation ] ,",
    "numerical simulation results are provided . in section [ future ] , the future work is stated and finally the proofs and technical details are given in the appendices .    [ cols=\"^,^\",options=\"header \" , ]",
    "in this section , some theorems and lemmas that are used in the proofs of the main results are provided .",
    "@xcite[peierl ] ( peierl s inequality ) + let @xmath22 be an @xmath23 hermitian matrix , and @xmath24 be any convex function on @xmath25 .",
    "let @xmath26 be any orthonormal base of @xmath27 .",
    "then , @xmath28\\geq\\sum_{j=1}^{n}f(\\langle u_j , au_j\\rangle),\\ ] ] where @xmath29 is the inner product between @xmath30 and @xmath31 .",
    "furthermore , for a strictly convex function @xmath24 , equality holds if and only if each @xmath30 is an eigenvector of @xmath22 .",
    "[ t2]@xcite every @xmath32 circulant matrix   @xmath33 $ ] has eigenvectors @xmath34,\\ ] ] for @xmath35 and corresponding eigenvalues @xmath36and can be expressed in the form @xmath37 , where @xmath38 has the eigenvectors as columns in order and @xmath39 is a diagonal matrix with diagonal elements @xmath40 .",
    "[ t3]@xcite let @xmath41 $ ] and @xmath42 $ ] be two @xmath32 circulant matrices with eigenvalues @xmath43 respectively",
    ". then matrices @xmath44 and @xmath45 commute and @xmath46 where @xmath47 and @xmath48 is also a circulant matrix .",
    "[ t4]@xcite let @xmath22 be an @xmath49 matrix with singular values",
    "@xmath50 let @xmath44 be a @xmath51 submatrix of @xmath22 ( intersection of any @xmath52 rows and any @xmath53 columns of @xmath22 ) with singular values @xmath54 then , + @xmath55",
    "[ fig1 ]    we consider a continuous stationary bandlimited periodic signal defined as follows : @xmath56,\\label{eqdefs}\\end{aligned}\\ ] ] where @xmath5 is the fundamental frequency .",
    "the summation is from @xmath57 to @xmath58 , indicating that the signal is bandlimited .",
    "we assume that @xmath59 and @xmath60 for @xmath61 are mutually independent gaussian rv s , distributed according to @xmath62 for some @xmath63 .",
    "thus , the signal power is @xmath64 where @xmath65 .    the discrete version of the signal is @xmath66=\\sum_{\\ell = n_1}^{n_2}[a_\\ell\\cos(\\ell\\omega_0 n)+b_\\ell\\sin(\\ell\\omega_0 n)]\\label{eqdefs - discrete}\\end{aligned}\\ ] ] where @xmath5 for some integer @xmath67 .",
    "our model is depicted in figure [ fig1 ] .",
    "the signal @xmath68 , given in , is passed through a pre - sampling filter , @xmath69 , to produce @xmath70 .",
    "the signal @xmath70 is sampled at time instances @xmath71 , where @xmath72 .",
    "these samples are then corrupted by @xmath73 , an i.i.d .",
    "zero - mean gaussian noise denoted as @xmath74 .",
    "thus , our observations are @xmath75 .",
    "an estimator uses the noisy samples @xmath76 to reconstruct the original signal , denoted by @xmath77 .",
    "the incurred sampling distortion given by mmse criterion is equal to @xmath78 this distortion is a random variable .",
    "our goal is to compute the minimum of the expected value and minimum of the variance of this random variable , _",
    "i.e. , _ to minimize @xmath79 we are free to choose @xmath69 and sampling locations @xmath80 s , @xmath81 .",
    "therefore , the optimal average and variance of distortion are defined as follows : @xmath82 where the minimization is taken over the sampling locations and the pre - sampling filter .",
    "we assume that @xmath69 is a real lti filter such that @xmath83 meaning that the frequency gain of the signal is at most one ; in other words , we assume that the filter is passive and hence can not increase the signal energy in each frequency .",
    "in particular , all pass filters @xmath84 satisfy this assumption .",
    "the reason for introducing this assumption is that we can always normalize the power gain of the filter by scaling the sampling noise power .",
    "more specifically , replacing some given @xmath69 with @xmath85 for some @xmath86 , changes @xmath87 to @xmath88 .",
    "hence , @xmath89 would change to @xmath90 . but",
    "reconstruction from @xmath91 s yields the same distortion as the reconstruction from @xmath92 , which is equivalent to dividing the noise power by @xmath86 .",
    "in this section , we first state two general lower bounds on the average and variance of distortion and then , using these lower bounds , we provide the main results of the paper .",
    "note that @xmath93 and @xmath94 is proportional to the bandwidth of the signal .",
    "remember that @xmath8 is the number of noisy samples .",
    "the proofs of the main results are given appendix [ proofs ] .",
    "we did not provide the formal proofs below the statement of the theorems because we first need to represent the problem in a matrix form , as given in appendix [ sec : matrix - form ] .",
    "[ lemma : lower:1 ] for any noise variance @xmath95 and any choice of the pre - sampling filter , the following lower bounds hold for all values of @xmath8 : @xmath96 when we do not use a pre - sampling filter on the signal bandwidth ( _ i.e. , _",
    "@xmath97 for @xmath98 ) , equality in the above equations hold if and only if for any time instances @xmath80 and @xmath99 one of the following two equations hold : @xmath100 for a proof .    in the next lemma ,",
    "alternative lower bounds on @xmath101 and @xmath10 are given , which are tighter than the ones given in lemma [ lemma : lower:1 ] for @xmath102 .",
    "[ lemma : lower:2 ] for any @xmath95 and any choice of the pre - sampling filter , the following lower bounds hold for all values of @xmath8 : @xmath103 furthermore , equality in the above equations hold if and only if @xmath104 for @xmath105 and the sampling time instances satisfy the following equation : @xmath106    see appendix [ lower2proof ] for a proof .      here , the sampling - rate distortion tradeoffs are studied when the sampling rate is lower than the landau rate . the optimal sampling strategy and thus the optimal distortion and variance",
    "are given in the following theorems .",
    "[ t1a ] for @xmath12 , the optimal average and variance of distortion for any given pre - sampling filter are @xmath107 both the minimal average distortion and its variance are obtained with the pre - sampling filter @xmath97 for @xmath98 and choosing @xmath8 distinct time instances arbitrarily from the following set of @xmath108 samples samples , unless @xmath109 .",
    "uniform sampling for @xmath8 points takes the samples at times @xmath110 @xmath111 the optimal interpolation formula for this set of sampling points is given by @xmath112 where @xmath91 is the noisy sample of the signal at @xmath113",
    ".    see appendix [ proof:4:2:1 ] for a proof .",
    "_ consider .",
    "observe that for fixed values of @xmath114 and @xmath115 , the minimum distortion is linear in @xmath8 .",
    "but it is not linear in @xmath108 ( as snr in the denominator is @xmath116 ) , except when @xmath117 goes to infinity . in the case of noiseless samples , @xmath118",
    ", the snr will be infinity and the minimal distortion will be @xmath119 to intuitively understand this equation , observe that there are @xmath120 free variables and we can recover @xmath8 of them using the samples .",
    "therefore , we will have @xmath121 free variables , giving a total distortion of @xmath122 as the power of each sinusoidal function is @xmath123 .",
    "moreover , the maximum distortion is @xmath124 , which is obtained when @xmath125 ( @xmath126 ) or @xmath127 . finally , observe that when @xmath117 is large , @xmath128 which is linear in both @xmath114 and @xmath11 .",
    "observe that @xmath9 is increasing in both @xmath114 and @xmath11 , since @xmath129 for @xmath12 .",
    "furthermore , @xmath130 when @xmath12 , implying that the coefficient of @xmath114 is greater than or equal to that of @xmath11 .",
    "figure [ fig3 ] depicts @xmath9 as a function of @xmath114 , @xmath11 , @xmath8 and @xmath108 . _    [ fig3 ]    [ thm : unique ] if we do not use a pre - sampling filter , the optimal sampling times @xmath131 given in the statement of theorem [ t1a ] are essentially unique if @xmath108 does not divide @xmath132 .",
    "more specifically , sampling times @xmath131 are optimal if there exists some constant @xmath133 such that for at least @xmath134 of the sampling points @xmath80 we have @xmath135 more generally , a set of sampling points @xmath131 are optimal if and only if @xmath80 s are the solutions of the following equation for @xmath136 and @xmath137 @xmath138    see appendix [ proof:4:2:3 ] for a proof .",
    "when @xmath12 , we have aliasing and can not reconstruct the signal even when the sampling noise is zero .",
    "assume that the number of samples , @xmath8 , is even and consider a low - pass filter of bandwidth @xmath139 as follows : @xmath140 for some @xmath141 $ ] .",
    "this filter makes all of the coefficients @xmath142 and @xmath60 equal to zero , except for @xmath8 variables @xmath143 when @xmath144 .",
    "therefore , the number of remaining non - zero coefficients will be equal to the number of samples , @xmath8 , and we will not have aliasing at the time of sampling .",
    "therefore , there will be no interference from other signal coefficients .",
    "however , we incur a distortion when we filter out some of the coefficients @xmath59 and @xmath60 .",
    "this scheme resembles an interference cancellation strategy . on the other hand , if we use the following filter with bandwidth @xmath8 , @xmath145 we have kept more coefficients but with aliasing and interference from other coefficients .",
    "we compare the performance of these two filters under uniform sampling in the following theorem :    [ thm : unifmlessn ] suppose that we insist on using uniform sampling at rate @xmath8 , _",
    "i.e. , _ taking the points @xmath146 then , the performance of filter @xmath147 is equal to @xmath148 on the other hand , the performance of filter @xmath149 satisfies : @xmath150 which is strictly greater than @xmath151 , even when we increase the signal power by a factor of two .",
    "see appendix [ proof:4:2:2 ] for a proof .    _",
    "filter @xmath149 is like an _ interference cancellation _",
    "scheme when we interpret aliasing as interference . but with filter @xmath147 , we can do _ interference management _ and use the interfered aliased information to recover the signal .",
    "this yields an snr gain of @xmath152 , comparing and . to convey the essential intuition ,",
    "consider the following different but simpler problem : suppose @xmath153 are two independent gaussian random variables .",
    "we are interested in recovering these two variables via one observation that is corrupted by a gaussian noise of variance @xmath11 .",
    "the interference cancellation strategy corresponds to discarding @xmath154 and observing @xmath155 where @xmath156 is the noise .",
    "this yields an estimation error of @xmath157 where the @xmath114 and @xmath158 are the estimation errors for @xmath154 and @xmath159 , respectively , and @xmath117 is defined as @xmath160 . on the other hand , an interference management scheme observes @xmath161 . here",
    "both @xmath159 and @xmath154 are interference terms for each other .",
    "the total estimation error in this case is equal to @xmath162 in comparison to , the snr gain of two is attained due to the interference management . _      here , the sampling - rate distortion tradeoffs for the rates between half the landau rate and the landau rate are stated .",
    "[ t : nm2n ] for @xmath164 and any choice of the pre - sampling filter , the optimal average distortion can be bounded as follows @xmath165 in which @xmath166 and @xmath167 is equal to @xmath168 where @xmath169 is the remainder of dividing @xmath170 by @xmath171 .",
    "the lower bound given in is tight when @xmath20 for any arbitrary @xmath172 . to achieve the optimal distortion ,",
    "no pre - sampling filter is necessary ; a set of optimal time instances is @xmath173    moreover , the upper bound on the average distortion given in is obtained when we do not use a filter on the signal bandwidth , and choose the @xmath8 sample points as follows : @xmath174    see appendix [ proof:4:3 ] for a proof .    [ th m : unique2 ] _ if we do not use a pre - sampling filter on the signal bandwidth , the necessary and sufficient conditions for optimality of the lower bound on average distortion is the one given in .",
    "the proof is similar to that given in proposition . _      in this subsection , we develop the sampling - rate distortion tradeoffs for the rates above the landau rate .",
    "we have the following theorems :    [ t1c ] for @xmath176 and any choice of the pre - sampling filter , the following lower bounds on optimal average and variance of distortion hold : @xmath177 moreover , these lower bounds are tight if and only if @xmath178 for @xmath179 and time instances @xmath80 s satisfy the following equation : @xmath180 uniform sampling , _",
    "@xmath181 is a solution to the above equation if for each @xmath182 in the interval @xmath183 , we have @xmath184 . in particular ,",
    "uniform sampling is optimal when @xmath185 .",
    "also the reconstruction formula for the optimal set of sampling points is given by @xmath186 where @xmath91 is the noisy sample of the signal at @xmath113 .",
    "see appendix [ proof:4:4:1 ] for a proof .    _ when @xmath8 goes to infinity , the minimum distortion @xmath187 goes to zero , regardless of the value of sampling noise . to see this ,",
    "observe that when @xmath8 is very large ( @xmath185 ) , the lower bounds given in and are tight . _    [ remarks3 ] _ unlike the case of @xmath12 where the optimal sampling points could be found without any need to know @xmath15 , observe that the constraint given in depends on @xmath15 .",
    "furthermore , the uniform sampling strategy , @xmath188 , is not in general a solution to the above equation .",
    "for instance , uniform sampling is not an optimal strategy if @xmath189 for some @xmath190 , since @xmath191 _    below are some examples of non - uniform solutions of :    _ when @xmath192 , @xmath193 and @xmath194 , sampling points @xmath195 are optimal . _    _ given any @xmath15 and @xmath58 , let @xmath196 .",
    "let us show @xmath197 by @xmath198 .",
    "then the following @xmath199 non - uniform sampling points are optimal for @xmath200 $ ] : let @xmath201 where @xmath202 is the binary expansion of time index @xmath203 $ ] .",
    "we verify that holds : @xmath204 which is zero if @xmath205 , _ i.e. , _ @xmath206 for some @xmath169 .",
    "_      so far we have focused on sampling distortion .",
    "we now consider a more general model depicted in fig .",
    "[ fig2 ] , consisting of a pre - sampling filter , a sampling strategy , a compressor and a decompressor .",
    "the compressor ( or the encoder ) takes in the @xmath8 samples of the signal and maps it to @xmath207 bits , via a function @xmath208 .",
    "the decoder @xmath209 uses the @xmath207 bits to recover the signal @xmath210 .",
    "this is done via a decoding function @xmath211 where @xmath212 is the space of all periodic signals with bandwidth @xmath213 $ ] .    here",
    "the compression rate @xmath214 bits per second , and the sampling rate is @xmath8 samples per @xmath67 seconds , i.e. @xmath215 samples per second .    the goal is to minimize the average distortion between the original signal @xmath216 and the decoder s reconstruction @xmath217 , where @xmath218 are the @xmath8 noisy samples of @xmath216 . in other words , we would like to minimize @xmath219 the minimization is taken over the sampling points , the pre - sampling filter , and the choice of the encoder @xmath220 and the decoder @xmath209 . to minimize the total distortion over these four parameters , we fix the first two parameters ( the sampling points and the pre - sampling filter ) and minimize distortion over the encoder and decoder functions .",
    "then , one should take the minimum over the first two parameters .",
    "the following theorem addresses the first minimization over the encoding and decoding functions , when the sampling instances and the pre - sampling filter are fixed .",
    "[ thm : compression]for a fixed pre - sampling filter and sampling instances @xmath80 s , the optimal encoder works as follows : it first computes its best estimate of the original signal , @xmath221 , from the noisy samples . in other words , it first finds a signal @xmath221 as a function of samples @xmath218 that minimizes @xmath222 then , it tries to convey @xmath221 to the decoder , by compressing it to @xmath207 bits .",
    "the optimal decoder works as follows : it takes the @xmath207 bits and computes @xmath223 such that its average distortion with @xmath221 is minimized , _",
    "@xmath224 is minimized at the decoder .",
    "this choice of encoder and decoder is optimal as it will also minimize the end - to - end distortion @xmath219 moreover , the optimal total distortion is equal to the sum of sampling distortion and compression distortions , _",
    "i.e. , _ @xmath225    see appendix [ proof:4:5:1 ] for a proof .",
    "_ the tradeoff between sampling distortion and quantization distortion is evident from the above theorem .",
    "for instance , if we do not sample at all , the optimal reconstruction @xmath221 will be the all zero signal . in this case",
    ", we will have a high sampling distortion but the compression distortion @xmath226 will be zero . on the other hand , if we use the optimal sampling strategy for the signal , by assuming a constant total distortion , if the sampling distortion decreases , we can endure more compression distortion .",
    "unfortunately , we lack an exact closed form expression for rate distortion of a given source when we have a single copy of the source ( not many i.i.d .",
    "copies ) . therefore",
    ", solving the joint optimization seems difficult . _",
    "[ proposition : compression ] for a given pre - sampling filter and sampling instances @xmath80 s , the value of @xmath227 in the statement of theorem [ thm : compression ] is given by @xmath228 which is given in .",
    "furthermore , by employing a known result in rate - distortion theory , given @xmath207 bits for compression , we must have @xmath229 where @xmath230 s are the eigenvalues of @xmath231 , and @xmath232 is some constant such that @xmath233 .",
    "see appendix [ proof:4:5:2 ] for a proof",
    ".      it would be interesting to extend our results to the case when the coefficients @xmath59 and @xmath60 in are mutually independent zero - mean gaussian rv s with arbitrary variances @xmath234 and @xmath235 respectively for @xmath236 .",
    "the signal @xmath216 will be stationary if and only if @xmath237 for some @xmath238 . to see this ,",
    "observe that @xmath239 & = \\mathbb{e}\\{s(t)^2\\ } -\\mathbb{e}^2\\{s(t)\\ }   \\\\&= \\mathbb{e}\\{\\sum_{\\ell = n_1}^{n_2}[a_\\ell\\cos(\\ell\\omega_0 t)+b_\\ell\\sin(\\ell\\omega_0 t)]\\}^2   \\\\&=\\sum_{\\ell = n_1}^{n_2}\\left(\\alpha_\\ell\\cos^2(\\ell\\omega_0 t)+\\beta_\\ell\\sin^2(\\ell\\omega_0",
    "t)\\right ) \\\\&=\\sum_{\\ell = n_1}^{n_2}\\left(\\frac{\\alpha_\\ell+\\beta_\\ell}{2}+\\frac{\\alpha_\\ell-\\beta_\\ell}{2}\\cos(2\\ell\\omega_0 t)\\right)\\end{aligned}\\ ] ] which is independent of @xmath240 if and only if @xmath237 for some @xmath238 .",
    "observe that the signal is _ sparse _ if @xmath238 is non - negligible for few values of @xmath241 .",
    "for the case of equal variances @xmath242 for @xmath179 , we stated two general lower bounds on the average distortion ( see subsection [ sec:4:1 ] ) . when @xmath238 values are distinct , we can generalize the second lower bound given in lemma [ lemma : lower:2 ] as follows ( we assume that the frequency support is known ) :    [ proposition : sparse ] for any @xmath95 and any choice of the pre - sampling filter , the following lower bound on the average distortion holds for all values of @xmath8 : @xmath243 furthermore , equality in the above equation holds if and only if @xmath178 for @xmath179 and the sampling time instances satisfy the following equation : @xmath106 uniform sampling , _",
    "@xmath181 is a solution to the above equation if for each @xmath182 in the interval @xmath183 , @xmath184 . in particular , for the rates above the nyquist rate , _",
    "i.e. , _ @xmath185 , uniform sampling is optimal .",
    "see appendix [ proof:4:5:2 ] for a proof .",
    "similar to the proof of theorem  [ t1c ] , one can find optimal sampling points for a sparse signal under certain conditions : uniform sampling with no filter on the signal bandwidth is optimal when we are above the nyquist rate @xmath185 .",
    "consider a real periodic discrete signal of the form @xmath66=\\sum_{\\ell = n_1}^{n_2}[a_\\ell\\cos(\\ell\\omega_0 n)+b_\\ell\\sin(\\ell\\omega_0 n)],\\label{eqdefs - discrete}\\end{aligned}\\ ] ] where @xmath244 for some integer @xmath67 , and @xmath245 are natural numbers .",
    "observe that @xmath67 is the period of the discrete signal and @xmath246 is the @xmath241-th dft coefficients of the discrete signal @xmath247 $ ] .",
    "suppose that we have @xmath8 noisy samples at time instances @xmath248 .",
    "we would like to use these samples to reconstruct the discrete signal @xmath247 $ ] .",
    "if the reconstruction is @xmath249=\\sum_{\\ell = n_1}^{n_2}[\\hat{a}_\\ell\\cos(\\ell\\omega_0 n)+\\hat{b}_\\ell\\sin(\\ell\\omega_0 n)]$ ] , the distortion @xmath250-\\hat{s}[n]|^2   $ ] is proportional to @xmath251 .",
    "thus , the formulation for minimizing the distortion is the same as that of the continuous signals which is given in [ sec : matrix - form ] .",
    "the only exception is that we additionally have the restriction that @xmath80 s should be integers .",
    "below , is an observation about the discrete time formulation :    whenever the optimal sampling points in the continuous formulation turns out to be integer values , they are the optimal points in the discrete case . and when the optimal sampling points are not integers , simulation results with exhaustive search show that their closest integer values are either optimal or nearly optimal .",
    "for example , when the signal period is @xmath252 and @xmath253 . in this case @xmath254 and the optimal sampling points in the continuous case are @xmath255 for some @xmath256 $ ] .",
    "the rounds of these point for @xmath257 are optimal in the discrete case , _",
    "i.e. , _ any choice of time instances from the set @xmath258 is optimal . on the other hand , when the signal period is @xmath252 and @xmath259 . here",
    "again @xmath254 and @xmath260 are the only continuous optimal points . rounding these points to their closest integers yields @xmath261 .",
    "however , the optimal points are @xmath262 resulting in @xmath263 .",
    "note that the distance between the first two optimal points is 1 , which can not be achieved by choosing any arbitrary value of @xmath264 , since the distance between any of the points in @xmath265 is 2.5 .",
    "in this section , we evaluate the optimal reconstruction interpolation formulas derived in the previous sections and also simulate an iterative method for the reconstruction of optimal non - uniform positions .",
    "we will see that the simulation results match the stated results .",
    "[ reconstructio ] illustrates the mmse reconstruction from optimal sampling points given in for high snr scenario .",
    "the figure also depicts the reconstruction result using an iterative method @xcite .",
    "its performance is near optimal in the high snr scenario .",
    "[ reconstruction2 ] uses the same parameters for generating the signal , but the variance of the noise is higher ( low snr scenario ) .    figs .",
    "[ dvarm2n24 ] and [ fig : dvarm2n1n12 ] represent the average distortion , @xmath266 , and the variance of distortion , @xmath267 , for different values of @xmath8 , @xmath268 and @xmath108 .",
    "these figures show that whenever the average distortion is minimum , the variance of distortion is also minimum .",
    "this confirms the results given in theorems [ t1a ] and [ t1c ] .",
    "even though we can not prove the same result for all values of @xmath269 , simulation results for @xmath270 indicate that the two terms are minimized at the same sampling locations .    in fig .",
    "[ lower12 ] , the two lower bounds on average distortion derived in lemmas [ lemma : lower:1 ] and [ lemma : lower:2 ] are plotted .",
    "the first lower bound is tight for @xmath12 , as shown in theorem [ t1a ] .",
    "the second lower bound is tight for sufficiently large @xmath21 , as discussed in theorem [ t1c ] .",
    "the maximum of these lower bounds is depicted in fig .",
    "[ lowersupper ] . in this figure",
    ", the distortion of uniform sampling without any pre - sampling filter on the signal bandwidth is also depicted .",
    "we make the following observations in this figure : the performance of the uniform sampling is close to optimal for @xmath12 ( its curve almost matches that of the lower bound in lemma [ lemma : lower:1 ] which is optimal for @xmath12 ) .",
    "while we expect that increasing the number of uniform samples should lead to a better performance , we see that near the landau rate , increasing the sampling points does not decrease the uniform sampling distortion . here",
    ", the curve for uniform sampling reaches its maximum at @xmath271 , whereas the landau rate is 16 .",
    "the curve decreases from @xmath271 onwards and matches the second lower bound at @xmath272 .",
    "thus , uniform sampling is optimal for @xmath273 .",
    "finally , the explicit upper bound on the performance of the sampling points given in in theorem [ t : nm2n ] is also depicted in this figure .",
    "it matches that of uniform sampling at @xmath109 and @xmath7 , as expected .",
    "[ lowersupper2 ] is similar to fig .",
    "[ lowersupper ] , but for different values of @xmath15 and @xmath108 .",
    "it shows that the explicit upper bound of theorem [ t : nm2n ] can be below the distortion of uniform sampling .",
    "while the above figures have been plotted for @xmath274 , our simulation results show that decreasing the variance of noise will reduce the gap between the lower and the upper bounds .    finally , fig .",
    "[ lowersupper3 ] compares uniform sampling ( without a pre - sampling filter ) with the optimal non - uniform sampling strategy for @xmath12 .",
    "the performances of these two strategies are close to each other .",
    "more specifically , the figure depicts the difference of the distortion of the two strategies , divided by the distortion of optimal sampling .",
    "it shows that we can get a gain of at most 0.3 percentage of the distortion obtained by using the optimal non - uniform sampling strategy",
    ". however , a main advantage of the optimal nonuniform sampling is its _ robustness _ with respect to missing samples ( as discussed in the introduction ) .",
    "1   are depicted .",
    "their reconstruction with @xmath275 samples are also depicted , employing the optimal mmse method and the iterative method of @xcite .",
    "the sampling points are optimally chosen .",
    "the average reconstruction distortion ( mmse ) over _ all _ random signals with the given parameters is @xmath276 .",
    "subfigure @xmath277 : the distortion of the optimal mmse method is @xmath278 and the distortion of the iterative method is @xmath279 .",
    "subfigure @xmath280 : the distortion of the optimal mmse method is @xmath281 and the distortion of the iterative method is @xmath282 . , title=\"fig : \" ]    1   are depicted .",
    "their reconstruction with @xmath275 samples are also depicted , employing the optimal mmse method and the iterative method of @xcite .",
    "the sampling points are optimally chosen .",
    "the average reconstruction distortion ( mmse ) over _ all _ random signals with the given parameters is @xmath276 .",
    "subfigure @xmath277 : the distortion of the optimal mmse method is @xmath278 and the distortion of the iterative method is @xmath279 .",
    "subfigure @xmath280 : the distortion of the optimal mmse method is @xmath281 and the distortion of the iterative method is @xmath282 .",
    ", title=\"fig : \" ]    1   are depicted .",
    "their reconstruction with @xmath275 samples are also depicted , employing the optimal mmse method and the iterative method of @xcite .",
    "the sampling points are optimally chosen .",
    "the average reconstruction distortion ( mmse ) over _ all _ random signals with the given parameters is @xmath283 .",
    "subfigure @xmath277 : distortion of the optimal mmse method is @xmath284 and the distortion of the iterative method is @xmath285 .",
    "subfigure @xmath280 : distortions of the optimal mmse method is @xmath286 and the distortion of the iterative method is @xmath287.,title=\"fig : \" ]    1   are depicted .",
    "their reconstruction with @xmath275 samples are also depicted , employing the optimal mmse method and the iterative method of @xcite .",
    "the sampling points are optimally chosen .",
    "the average reconstruction distortion ( mmse ) over _ all _ random signals with the given parameters is @xmath283 .",
    "subfigure @xmath277 : distortion of the optimal mmse method is @xmath284 and the distortion of the iterative method is @xmath285 .",
    "subfigure @xmath280 : distortions of the optimal mmse method is @xmath286 and the distortion of the iterative method is @xmath287.,title=\"fig : \" ]     and @xmath108 .",
    "the signal period is @xmath288 . here",
    "@xmath192 and @xmath289",
    ". the only degree of freedom is therefore @xmath290 , which is shown on the x - axis . ]     and",
    "the signal period is @xmath288 . here",
    "@xmath192 and @xmath289",
    ". the only degree of freedom is therefore @xmath290 , which is shown on the x - axis . ]    .",
    "the signal period is @xmath288 . here",
    "@xmath192 and @xmath289",
    ". the only degree of freedom is therefore @xmath290 , which is shown on the x - axis . ]",
    "[ lower12 ]",
    "[ future ] we studied the effect of sampling strategy and a pre - sampling filter on the reconstruction distortion of a periodic bandlimited signal of the form given in . deriving the optimal points for the discrete case in general is also of importance .",
    "moreover , it would be interesting to find the optimal quantizer .",
    "other extensions include considering a more general class of signals .",
    "furthermore , we consider only the sampling noise in this work ; one can consider adding noise to the signal itself , before sampling .",
    "it would be interesting to extend our results to the case of non - uniform power spectrum of the input signal . in",
    ", we had assumed that @xmath59 and @xmath60 are normal random variables with variance @xmath114 .",
    "more generally , one can assume coefficients with different variances .",
    "in this case @xmath291 is still diagonal but not proportional to identity matrix . for the case of @xmath292 , one can use and similar arguments to show that @xmath293 is minimized if ( @xmath294 ) is diagonal .",
    "therefore , we get the same sufficient condition for optimality , as given in proposition [ thm : unique3 ] .",
    "the case of @xmath295 is more complicated and the optimal sampling points depend on the values of variances of the coefficients .",
    "the authors would like to thank amin gohari , salman beigi and arash amini for helpful discussions .",
    "in particular , the proof of theorem [ mmse - var ] is due to amin gohari .",
    "the conventional mmse estimation problem for estimating a vector @xmath296 from vector @xmath297 asks for minimizing the expected value of @xmath298 where the estimator @xmath299 is created as a function of observation @xmath297 .",
    "however , this would only ensure that the distortion is minimized on _",
    "average_. in practice , we get one copy of @xmath296 and @xmath297 , and we want to ensure that the distortion that we obtain is small for that one copy , not just on average . minimizing the variance of @xmath300 makes sense for the following two reasons :    * if random variables @xmath300 and @xmath301 are independent and have the same distribution , then @xmath302.\\ ] ] in other words , if we take two independent instances of the problem ( @xmath303 ) and ( @xmath304 ) .",
    "then the average gap between the distortion of these two problems , _",
    "@xmath300 and @xmath301 , has average @xmath305 ; * by chebyshev s inequality , the probability of @xmath300 exceeding a threshold depends not only on the average of @xmath300 , but also on its variance .    in this appendix",
    "we show that for jointly gaussian random variables , the estimator that minimizes the expected value of @xmath300 , also minimizes its variance .",
    "[ mmse - var ] suppose @xmath296 and @xmath297 are two correlated jointly gaussian vectors , having covariance matrices @xmath291 , @xmath306 and @xmath307 .",
    "let @xmath299 be a function of @xmath297 , and consider the cost @xmath308 the estimator @xmath299 that minimizes the above cost constraint is @xmath309 $ ] , and the minimum variance is equal to @xmath310 where @xmath311    we have @xmath312.\\end{aligned}\\ ] ] we claim that both of the terms @xmath313 and @xmath314 $ ] are minimized when @xmath309 $ ] .",
    "the second term is always non - negative and becomes zero when @xmath309 $ ] .",
    "this is because @xmath315 will be equal to @xmath316 which is a constant and does not depend on the value of @xmath297 for jointly gaussian random variables .",
    "therefore , its variance is zero if @xmath309 $ ] .    to prove that the second term is minimized at @xmath309 $ ] , it suffices to show that this claim for all values of @xmath317 .",
    "we will be done if we have the following statement : for any jointly gaussian vector @xmath296 , the function @xmath318 is minimized at @xmath319 $ ] .",
    "let @xmath320 .",
    "then observe that @xmath321 .",
    "if we replace @xmath322 by @xmath323 for some unitary matrix @xmath38 , the norm @xmath324 remains invariant .",
    "therefore , without loss of generality we can assume that @xmath325 is diagonal .",
    "then @xmath326 is the sum of independent gaussian random variables .",
    "let @xmath327 be the variance of @xmath328 .",
    "therefore @xmath329 which is clearly minimized when @xmath330 , and the minimum will be equal to @xmath331 .    coming back to the original minimization problem , we see that the covariance matrix of @xmath296 given any value for @xmath332 , does not depend on the value of @xmath317 , and is equal to @xmath333 , where @xmath311 therefore , the overall minimum variance is equal to @xmath334",
    "here , we first provide a matrix representation of the problem .",
    "let @xmath296 be the vector of coefficients @xmath59 and @xmath60 ( @xmath335 ) of the original signal , @xmath216 , given in , _ i.e. , _ @xmath336^\\dagger.\\label{eqn : def : coef : ab}\\end{aligned}\\ ] ] since the vector @xmath296 consists of real numbers , @xmath337 is just the transpose operation in the above equation . after filtering @xmath216 , we get @xmath338\\label{eqdefs2}\\end{aligned}\\ ] ] in which @xmath339 for @xmath335 , where @xmath340 and @xmath341 are the real and imaginary parts of @xmath69 , respectively .",
    "if we denote the vector of coefficients of @xmath70 as @xmath342^\\dagger\\ ] ] and express in matrix form , we get @xmath343 where @xmath344 and @xmath345 @xmath346 the signal @xmath70 is then sampled at time instances @xmath80 for @xmath347 .",
    "we have @xmath348.\\ ] ] let @xmath349 be the vector of the samples @xmath350^\\dagger.\\ ] ] therefore , in matrix form , we have @xmath351 where @xmath352 is an @xmath353 matrix of the form @xmath354finally , the vector of observations denoted by @xmath297 can be writen as @xmath355 where @xmath356 is the noise vector .",
    "estimation of @xmath216 is equivalent to the estimation of its fourier coefficients .",
    "if we denote the coefficients of the reconstruction signal by @xmath357^\\dagger,\\ ] ] using the parseval s theorem , we will have @xmath358      our goal is to use @xmath297 to estimate the signal with minimal distortion , _",
    "i.e. , _ from , we would like to minimize @xmath359 since all the random variables are gaussian , the linear mmse is optimal and thus we would like to use @xmath360 to find @xmath299 such that @xmath361 is minimized .",
    "the mmse estimator and the mean square error are given by @xmath362\\right\\}={\\mathtt{tr}}(c_e ) , \\label{eqn : mmsece}\\end{aligned}\\ ] ] where the matrix @xmath363 and the error covariance @xmath333 are of the forms : @xmath364 in the above formulas , we have used the fact that @xmath365 and @xmath366 .",
    "also we have defined @xmath367 using the alternative form for the linear mmse estimator derived in @xcite , we have @xmath368 where @xmath369    the value of @xmath300 is equal to @xmath370 from and if we use , it follows : @xmath371 where results from the fact that the trace operator is invariant under cyclic permutations . if @xmath172 , by setting @xmath118 , we get a distortion @xmath372 regardless of @xmath373 ( as long as they are distinct ) .",
    "when @xmath21 , from , one can observe that distortion becomes arbitrary small as @xmath374 .",
    "equivalently , @xmath266 can be found using as @xmath375 the main challenge is to find the minimum of @xmath376 or @xmath377 over all choices of @xmath80 s and all pre - sampling filters .",
    "+ note that the matrix @xmath378 equals to @xmath379 , where the entries of the matrix @xmath380 for @xmath381 are of the following form : @xmath382 in which @xmath383 and @xmath384 for @xmath385 ( see ) .",
    "also , a direct calculation shows that the diagonal entries of matrix @xmath386 are given by : @xmath387 ;   \\\\\\qquad \\qquad \\qquad \\qquad\\text{where } \\ell = k+n_1 - 1 \\text { for } k   = 1 , \\cdots , n , \\\\",
    "\\\\\\sigma^2+{\\mathsf{p}}\\sum_{i = 1}^{m}\\big[h_i^2(\\ell\\omega_0)\\cos^2(\\ell\\omega_0 t_i)\\\\\\quad + 2h_r(\\ell\\omega_0)h_i(\\ell\\omega_0)\\cos(\\ell\\omega_0 t_i)\\sin(\\ell\\omega_0t_i)+h_r^2(\\ell\\omega_0)\\sin^2(\\ell\\omega_0 t_i)\\big ] ; \\\\\\qquad\\qquad   \\qquad \\qquad\\text{where } \\ell = k+n_1 - 1-n\\text { for } k= n+1 , \\cdots , 2n.\\end{cases } \\label{eqn : gammaentries}\\end{aligned}\\ ] ] * computing variance of distortion : *    the variance of distortion , using the parseval s theorem given in , is of the form @xmath388 using theorem [ mmse - var ] from appendix [ appendixa ] , we have @xmath389 hence , using similar steps as the ones used in computing average distortion , from , @xmath267 is found to be @xmath390 \\nonumber \\\\ & = { \\mathsf{p}}^2 [ 2n + { \\mathtt{tr}}\\left(- 2\\pi   { \\mathsf{p}}ql l^\\dagger q^\\dagger + ( \\pi   { \\mathsf{p}}ql l^\\dagger q^\\dagger)^2\\right ) ] \\nonumber \\\\ & = { \\mathsf{p}}^2 [ 2n   -{\\mathtt{tr}}(i_{m\\times m})+ { \\mathtt{tr}}\\left(i_{m\\times m}- 2\\pi   { \\mathsf{p}}ql l^\\dagger q^\\dagger + ( \\pi   { \\mathsf{p}}ql l^\\dagger q^\\dagger)^2\\right ) ] \\nonumber \\\\ & = { \\mathsf{p}}^2 [ 2n - m   + { \\mathtt{tr } } ( ( i - \\pi   { \\mathsf{p}}ql l^\\dagger q^\\dagger ) ^2 ) ] \\nonumber \\\\ & = { \\mathsf{p}}^2 [ 2n - m   +   { \\mathtt{tr}}(\\sigma^2 \\pi)^2 ] \\nonumber \\\\ & = { \\mathsf{p}}^2 [ 2n - m   + \\sigma^4 { \\mathtt{tr}}(\\pi^2 ) ]    \\label { var1}.\\end{aligned}\\ ] ] alternatively , using , we get @xmath391    so far , two closed formulas for @xmath266 and @xmath267 have been derived in equations , , and . in the following subsections , the proof of the main results will be developed using the notation and formulas given in this subsection .",
    "the matrix @xmath392 is positive definite and real , since @xmath393 .",
    "in addition , the entries of matrix @xmath394 as stated in are of the form @xmath395 where @xmath383 and @xmath384 for @xmath385 . therefore , all the diagonal entries of matrix @xmath396 are ( @xmath397 ) which are less than or equal to @xmath398 for @xmath399 .",
    "using peierl s inequality ( see lemma [ peierl ] in section [ preliminaries ] ) for the convex function @xmath400 on @xmath401 , the positive matrix @xmath402 and the normal basis @xmath403 s ( @xmath404 ) , where @xmath405 is the unit vector with 1 in the @xmath406th position and 0 elsewhere , we have @xmath407 substituting into , results in a lower bound on distortion as follows @xmath408 since sampling time instances @xmath80 s and pre - sampling filter @xmath69 are arbitrary , for any value of @xmath8 , we get @xmath409 since @xmath400 is a strictly convex function for @xmath401 , equality in the above equation holds if and only if @xmath30 s are eigenvectors of @xmath378 , _",
    "i.e. , _ if and only if @xmath378 is a diagonal matrix . in particular , assuming that that we do not use a pre - sampling filter on the signal bandwidth _",
    "@xmath410 , equality holds if and only if @xmath411 is a diagonal matrix .",
    "therefor , we have the following equation for @xmath412 : @xmath413(i , k ) & =   \\sum_{\\ell = n_1}^{n_2}\\cos(\\ell\\omega_0(t_i - t_k))\\\\&=\\mathsf{real } \\ { \\sum_{\\ell = n_1}^{n_2 } e^{j2\\pi \\frac{t_i - t_k}{t } \\ell } \\ }   \\\\&= \\mathsf{real } \\ {   e^{j\\pi \\frac{t_i - t_k}{t } ( n_1+n_2)}. ~\\frac{\\sin(\\pi   \\frac{t_i - t_k}{t } n)}{\\sin(\\pi   \\frac{t_i - t_k}{t } ) } \\ } \\\\&=\\cos(\\pi \\frac{t_i - t_k}{t } ( n_1+n_2 ) ) .~",
    "\\frac{\\sin(\\pi   \\frac{t_i - t_k}{t } n)}{\\sin(\\pi   \\frac{t_i - t_k}{t } ) } = 0.\\end{aligned}\\ ] ] consequently , the sampling time instances @xmath80 s should satisfy the following equations : @xmath414 thus , given any @xmath415 and @xmath406 , we should either have @xmath416 . then , @xmath417 hence , using , we have @xmath418 = { \\mathsf{p}}^2 \\left[2n - m   + \\frac{m}{(1 + snr)^2}\\right ] .\\ ] ] here again , equality holds if and only if @xmath378 is a diagonal matrix .",
    "_ from the proof , one can see that the lower bounds given in lemma [ lemma : lower:1 ] are achieved if and only if matrix @xmath419 ( defined in ) is diagonal for the optimizing @xmath80 s and the pre - sampling filter .",
    "_ [ rmk : suff - cond - lemma1 ]      we use the distortion formula given in and minimize distortion subject to the sampling locations and the pre - sampling filter .",
    "let @xmath400 for @xmath401 .",
    "we have @xmath420\\nonumber\\\\ & = { \\min_{h(.),\\{t_i , i = 1 , \\cdots , m\\}}}[\\frac12 { \\mathsf{p}}\\sigma^2{\\mathtt{tr}}(f(\\gamma^{-1}))]\\nonumber \\\\&\\geq \\frac12{\\mathsf{p}}\\sigma^2   { \\min_{h(.),\\{t_i , i = 1 , \\cdots , m\\ } } } \\sum_{k = 1}^{2n } f(\\gamma^{-1}(k , k ) ) \\label{eq .",
    "1 }   \\\\&= \\frac12{\\mathsf{p}}\\sigma^2    { \\min_{h(.),\\{t_i , i = 1 , \\cdots , m\\}}}\\sum_{\\ell = n_1}^{n_2 } \\frac{1}{\\eta_\\ell}+\\frac{1}{\\gamma_\\ell},\\label{eq . 6}\\end{aligned}\\ ] ] where follows from the peierl s inequality ( lemma [ peierl ] ) for the covex function @xmath421 and is written by using with the following values for @xmath422 and @xmath423 : @xmath424 and @xmath425 observe that @xmath426 where @xmath427 for @xmath385 .",
    "the proof for the variance is similar .",
    "using , and the peierl s inequality for the choice of @xmath430 we have @xmath431\\nonumber\\\\ & = { \\min_{h(.),\\{t_i , i = 1 , \\cdots , m\\}}}[\\frac12 { \\mathsf{p}}\\sigma^2{\\mathtt{tr}}(f(\\gamma^{-1}))]\\nonumber \\\\&\\geq { \\mathsf{p}}^2 \\sigma^4   { \\min_{h(.),\\{t_i , i = 1 , \\cdots , m\\ } } } \\sum_{k = 1}^{2n } f(\\gamma^{-1}(k , k ) ) \\nonumber   \\\\&= { \\mathsf{p}}^2 \\sigma^4   { \\min_{h(.),\\{t_i , i = 1 , \\cdots , m\\}}}\\sum_{\\ell = n_1}^{n_2 } \\frac{1}{\\eta^2_\\ell}+\\frac{1}{\\gamma^2_\\ell}\\nonumber,\\end{aligned}\\ ] ] where @xmath422 and @xmath423 are given in and . from the convexity of the function",
    "@xmath432 we have @xmath433 for nonzero values of @xmath170 and @xmath171 .",
    "therefore , @xmath434    _ necessary and sufficient conditions for tightness of the lower bounds : _ the ideas are similar to the ones given in the proof of lemma [ lemma : lower:1 ] . for pierel s inequality to be tight ,",
    "we need @xmath435 defined in to be a diagonal matrix .",
    "we further need @xmath436 to have all the inequalities as equalities . we also need @xmath437 for all @xmath241 , implying that @xmath410 .",
    "therefore , the equality holds if and only if matrix ( @xmath438 ) is diagonal , and all of its diagonal entries are equal .",
    "+ the off - diagonal and diagonal entries of ( @xmath438 ) are given by @xmath439 ( i , k ) = \\begin{cases }    { \\mathsf{p}}\\cdot \\sum_{\\ell=1}^{m}\\cos((n_1+i-1)\\omega_0t_\\ell ) \\cos((n_1+k-1)\\omega_0t_\\ell)~~~;~1",
    "\\leq i < k \\leq n\\\\    { \\mathsf{p}}\\cdot \\sum_{\\ell=1}^{m}\\cos((n_1+i-1)\\omega_0t_\\ell ) \\sin((n_1+k - n)\\omega_0t_\\ell)~~;~1 \\leq i\\leq n\\leq",
    "k \\leq2 n\\\\     { \\mathsf{p}}\\cdot \\sum_{\\ell=1}^{m}\\sin((n_1+i - n)\\omega_0t_\\ell ) \\sin((n_1+k - n)\\omega_0t_\\ell)~;~ n\\leq i \\leq2 n,~ n\\leq k \\leq2 n\\\\    \\end{cases},\\ ] ] @xmath440 ( i , i ) = \\begin{cases } \\frac{m{\\mathsf{p}}}{2}+\\sigma^2 + \\frac{{\\mathsf{p}}}{2}\\cdot \\sum_{\\ell=1}^{m}\\cos(2(n_1+i-1)\\omega_0t_\\ell)~;~",
    "1\\leq i\\leq n\\\\ \\frac{m{\\mathsf{p}}}{2}+\\sigma^2 - \\frac{{\\mathsf{p}}}{2}\\cdot \\sum_{\\ell=1}^{m}\\cos(2(n_1+i-1)\\omega_0t_\\ell)~;~ n\\leq i \\leq2n \\end{cases},\\ ] ] respectively .",
    "if we put the off - diagonal entries zero and write the above equations in a simpler form , we get @xmath441 substituting @xmath442 in the above equations , we obtain @xmath443 or in another form , we have @xmath444 these equations imply that the off - diagonal entries are all zero .",
    "but they also imply that the diagonal entries are all equal to zero , _",
    "i.e. , _ @xmath445      here we are in the case of @xmath12 . in lemma [ lemma : lower:1 ] ,",
    "the desired lower bounds on @xmath9 and @xmath10 were developed .",
    "moreover , we showed that these lower bounds are achievable if we do not use the pre - sampling filter and for any time instances @xmath80 or @xmath99 @xmath446 is optimal .    to find the interpolation formula ,",
    "consider the mmse estimator given in and the matrix @xmath363 in .",
    "we have @xmath447 since in the optimal case , @xmath448 and @xmath449 , the fourier coefficients of the reconstructed signal are as follows : @xmath450 which results in the desired reconstruction formula in .",
    "remember the lower bounds given in lemma [ lemma : lower:1 ] .",
    "we showed that , when we do not use a pre - sampling filter , equality in this lemma holds if and only if latexmath:[\\ ] ] where @xmath600 and @xmath601 are of the forms : @xmath602 and @xmath603 observe that @xmath604 where @xmath427 for @xmath385 .",
    "similar to the proof of lemma [ lemma : lower:2 ] , using inequality we continue @xmath605 furthermore , the distortion given in is achieved under the same conditions given in lemma [ lemma : lower:2 ] that ensures the matrix @xmath606 becomes diagonal .",
    "the proof of theorem  [ t1c ] can be mimicked to show that uniform sampling , _",
    "@xmath181 is a solution to the above equation if for each @xmath182 in the interval @xmath183 , @xmath184 . in particular , for the rates above the nyquist rate , _",
    "i.e. , _ @xmath185 , uniform sampling is optimal .",
    "a. kipnis , a. goldsmith , t. weissman , y. eldar ,  distortion rate function of sub - nyquist sampled gaussian sources corrupted by noise , \" in proc .",
    "allerton conf . on comm . , control , and computing , 2013 , pp .",
    "901 - 908 .",
    "d. chan and r. donaldson ,  optimum pre- and post - filtering of sampled signals with application to pulse modulation and data compression systems , \" ieee trans . on commun .",
    "141 - 157 , apr .",
    "1971 .",
    "d. i. shuman , s. k. narang , p. frossard , a. ortega , and p. vandergheynst ,  the emerging field of signal processing on graphs : extending high - dimensional data analysis to net- works and other irregular domains , \" ieee signal process . mag .",
    "83 - 98 , 2013 .",
    "l. j. alvarez - vazquez , a. martinez , m. e. vazquez - mendez and m. a. vilar ,  optimal location of sampling points for river pollution control , \" mathematics and computers in simulation , vol .",
    "149 - 160 , feb . 2006 .",
    "s. rajendran and k. m. liew ,  optimal stress sampling points of plane triangular elements for patch recovery of nodal stresses \" international j. for numerical methods in engineering , vol .",
    "579 - 607 , apr . 2003 .",
    "r. venkataramani and y. bresler ,  perfect reconstruction formulas and bounds on aliasing error in sub - nyquist nonuniform sampling of multiband signals , \" ieee trans .",
    "inf . theory , vol .",
    "46 , no . 6 , pp . 2173 - 2183 , jun ."
  ],
  "abstract_text": [
    "<S> in this paper , the optimal sampling strategies ( uniform or nonuniform ) and distortion tradeoffs for stationary gaussian bandlimited periodic signals with additive white gaussian noise are studied . unlike the previous works that commonly consider the average distortion as the performance criterion </S>",
    "<S> , we justify and use both the average and variance of distortion as the performance criteria . to compute the optimal distortion </S>",
    "<S> , one needs to find the optimal sampling locations , as well as the optimal pre - sampling filter . a complete characterization of optimal distortion for the rates lower than half the landau rate is provided . </S>",
    "<S> it is shown that nonuniform sampling outperforms uniform sampling . </S>",
    "<S> in addition , this nonuniform sampling is robust with respect to missing sampling values . </S>",
    "<S> next , for the rates higher than half the landau rate , we find bounds that are shown to be tight for some special cases . </S>",
    "<S> an extension of the results for random discrete periodic signals is discussed , with simulation results indicating that the intuitions from the continuous domain carry over to the discrete domain . </S>",
    "<S> sparse signals are also considered where it is shown that uniform sampling is optimal above the nyquist rate . </S>",
    "<S> finally , we consider a sampling / quantization scheme for compressing the signal . here , we show that the total distortion can be expressed as the sum of sampling and quantization distortions . </S>",
    "<S> this implies a lower bound on the distortion via shannon s rate distortion theorem . </S>"
  ]
}