{
  "article_text": [
    ") ( e ) 2-wasserstein distance.,width=291 ]    -.5 cm    comparing , summarizing and reducing the dimensionality of empirical probability measures defined on a space @xmath0 are fundamental tasks in statistics and machine learning .",
    "such tasks are usually carried out using pairwise comparisons of measures .",
    "classic information divergences @xcite are widely used to carry out such comparisons .    unless @xmath0 is finite , these divergences can not be directly applied to empirical measures , because they are ill - defined for measures that do not have continuous densities . they also fail to incorporate prior knowledge on the geometry of @xmath0 , which might be available",
    "if , for instance , @xmath0 is also a hilbert space .",
    "both of these issues are usually solved using @xcite s approach @xcite to smooth empirical measures with smoothing kernels before computing divergences : the euclidean @xcite and @xmath1 distances @xcite , the kullback - leibler and pearson divergences @xcite can all be computed fairly efficiently by considering matrices of kernel evaluations .",
    "the choice of a divergence defines implicitly the _ mean _ element , or barycenter , of a set of measures , as the particular measure that minimizes the sum of all its divergences to that set of target measures @xcite .",
    "the goal of this paper is to compute efficiently barycenters ( possibly in a constrained subset of all probability measures on @xmath0 ) defined by the _ optimal transport distance _ between measures @xcite .",
    "we propose to minimize directly the sum of optimal transport distances from one measure ( the variable ) to a set of fixed measures by gradient descent .",
    "these gradients can be computed for a moderate cost by solving smoothed optimal transport problems as proposed by @xcite .",
    "wasserstein distances have many favorable properties , documented both in theory @xcite and practice @xcite .",
    "we argue that their versatility extends to the barycenters they define .",
    "we illustrate this intuition in figure  [ fig : nines ] , where we consider 30 images of nested ellipses on a @xmath2 grid .",
    "each image is a discrete measure on @xmath3 ^ 2 $ ] with normalized intensities .",
    "computing the euclidean , gaussian rkhs mean - maps or jeffrey centroid of these images results in mean measures that hardly make any sense , whereas the 2-wasserstein mean on that grid ( defined in  [ subsec : defbaryc ] ) produced by algorithm  [ algo : discwass ] captures perfectly the structure of these images .",
    "note that these results were recovered without any prior knowledge on these images other than that of defining a distance in @xmath3 ^ 2 $ ] , here the euclidean distance .",
    "note also that the gaussian kernel smoothing approach uses the same distance , in addition to a bandwidth parameter @xmath4 which needs to be tuned in practice .",
    "this paper is organized as follows : we provide background on optimal transport in   [ sec : back ] , followed by the definition of wasserstein barycenters with motivating examples in   [ sec : baryc ] .",
    "novel contributions are presented from   [ sec : computing ] : we present two subgradient methods to compute wasserstein barycenters , one which applies when the support of the mean measure is known in advance and another when that support can be freely chosen in @xmath0 .",
    "these algorithms are very costly even for measures of small support or histograms of small size .",
    "we show in   [ sec : smooth ] that the key ingredients of these approaches  the computation of primal and dual optimal transport solutions  can be bypassed by solving smoothed optimal transport problems .",
    "we conclude with two applications of our algorithms in  [ sec : exp ] .",
    "let @xmath0 be an arbitrary space , @xmath5 a metric on that space and @xmath6 the set of borel probability measures on @xmath0 .",
    "for any point @xmath7 , @xmath8 is the dirac unit mass on @xmath9 .    for @xmath10 and probability measures",
    "@xmath11 in @xmath6 , their @xmath12-wasserstein distance @xcite is @xmath13where @xmath14 is the set of all probability measures on @xmath15 that have marginals @xmath16 and @xmath17 .",
    "we will only consider empirical measures throughout this paper , that is measures of the form @xmath18 where @xmath19 is an integer , @xmath20 and @xmath21 lives in the probability simplex @xmath22 , @xmath23 let us introduce additional notations :    * measures on a set @xmath24 with constrained weights .",
    "* let @xmath25 be a non - empty closed subset @xmath25 of @xmath22 .",
    "we write @xmath26**measures supported on up to @xmath27 points . * * given an integer @xmath27 and a subset @xmath25 of @xmath28 , we consider the set @xmath29 of measures of @xmath0 that have discrete support of size up to @xmath27 and weights in @xmath25 , @xmath30 when no constraints on the weights are considered , namely when the weights are free to be chosen anywhere on the probability simplex , we use the shorter notations @xmath31 and @xmath32 .",
    "consider two families @xmath33 and @xmath34 of points in @xmath0 .",
    "when @xmath18 and @xmath35 , the wasserstein distance @xmath36 between @xmath16 and @xmath17 is the @xmath37 root of the optimum of a network flow problem known as the _ transportation problem _ @xcite .",
    "this problem builds upon two elements : the _ * matrix * _ @xmath38 _ * of pairwise distances * _ between elements of @xmath24 and @xmath39 raised to the power @xmath12 , which acts as a cost parameter , @xmath40_{ij } \\in\\mathbb{r}^{n\\times m},\\ ] ] and the _ * transportation polytope * _ @xmath41 of @xmath42 and @xmath43 , which acts as a feasible set , defined as the set of @xmath44 nonnegative matrices such that their row and column marginals are equal to @xmath45 and @xmath46 respectively .",
    "writing @xmath47 for the @xmath19-dimensional vector of ones , @xmath48    let @xmath49 be the frobenius dot - product of matrices .",
    "combining eq .",
    "& , we have that @xmath50the distance @xmath36 raised to the power @xmath12can be written as the optimum of a parametric linear program @xmath51 on @xmath44 variables , parameterized by the marginals @xmath52 and a ( cost ) matrix @xmath38 : @xmath53",
    "we present in this section the wasserstein barycenter problem , a variational problem involving all wasserstein distances from one to many measures , and show how it encompasses known problems in clustering and approximation .      a wasserstein barycenter of @xmath54 measures @xmath55 in @xmath56 is a minimizer of @xmath57 over @xmath58 , where @xmath59    @xcite consider more generally a non - negative weight @xmath60 in front of each distance @xmath61 .",
    "the algorithms we propose extend trivially to that case but we use uniform weights in this work to keep notations simpler .",
    "we highlight a few special cases where minimizing @xmath57 over a set @xmath58 is either trivial , relevant to data analysis and/or has been considered in the literature with different tools or under a different name . in",
    "what follows @xmath62 and @xmath63 are arbitrary finite subsets of @xmath0 .",
    "* @xmath64 * when only one measure @xmath17 , supported on @xmath63 is considered , its closest element @xmath16 in @xmath65if no constraints on weights @xmath45 are given  can be computed by defining a weight vector @xmath45 on the elements of @xmath24 that results from assigning all of the mass @xmath66 to the closest neighbor in metric @xmath5 of @xmath67 in @xmath24 . + * centroids of histograms * : @xmath68 finite , @xmath69 .",
    "when @xmath0 is a set of size @xmath70 and a matrix @xmath71 describes the pairwise distances between these @xmath70 points ( usually called in that case bins or features ) , the @xmath72-wasserstein distance is known as the earth mover s distance ( emd ) @xcite . in that context",
    ", wasserstein barycenters have also been called emd prototypes by @xcite . *",
    "euclidean @xmath0 * : @xmath73 , @xmath74 . minimizing @xmath57 on @xmath75",
    "when @xmath76 is a euclidean metric space and @xmath77 is equivalent to the @xmath27-means problem @xcite .",
    "*  constrained @xmath27-means * : @xmath73 , @xmath78 .",
    "consider a measure @xmath17 with support @xmath63 and weights @xmath43 .",
    "the problem of approximating this measure by a uniform measure with @xmath27 atoms  a measure in @xmath79in @xmath80-wasserstein sense was to our knowledge first considered by @xcite , who proposed a variant of @xcite s algorithm @xcite for that purpose .",
    "more recently , @xcite remarked that such an approximation can be used in the resampling step of particle filters and proposed in that context two ensemble methods inspired by optimal transport , one of which reduces to a single iteration of @xcite s algorithm .",
    "such approximations can also be obtained with kernel - based approaches , by minimizing an information divergence between the ( smoothed ) target measure @xmath17 and its ( smoothed ) uniform approximation as proposed recently by @xcite and @xcite .",
    "@xcite consider conditions on the @xmath81 s for a wasserstein barycenter in @xmath6 to be unique using the multi - marginal transportation problem .",
    "they provide solutions in the cases where either ( i ) @xmath82 ; ( ii ) @xmath83 using @xcite s interpolant @xcite ; ( iii ) all the measures @xmath81 are gaussians in @xmath84 , in which case the barycenter is a gaussian with the mean of all means and a variance matrix which is the unique positive definite root of a matrix equation ( * ? ? ?",
    "* eq.6.2 ) .",
    "@xcite were to our knowledge the first to consider practical approaches to compute wasserstein barycenters between point clouds in @xmath85 .",
    "to do so , @xcite propose to approximate the wasserstein distance between two point clouds by their _ sliced _",
    "wasserstein distance , the expectation of the wasserstein distance between the projections of these point clouds on lines sampled randomly . because the optimal transport between two point clouds on the real line can be solved with a simple sort",
    ", the sliced wasserstein barycenter can be computed very efficiently , using gradient descent .",
    "although their approach seems very effective in lower dimensions , it may not work for @xmath86 and does not generalize to non - euclidean metric spaces .",
    "we propose in this section new approaches to compute wasserstein barycenters when ( i ) each of the @xmath54 measures @xmath81 is an empirical measure , described by a list of atoms @xmath87 of size @xmath88 , and a probability vector @xmath66 in the simplex @xmath89 ; ( ii ) the search for a barycenter is not considered on the whole of @xmath6 but restricted to either @xmath90 ( the set of measures supported on a predefined finite set @xmath24 of size @xmath19 with weights in a subset @xmath25 of @xmath91 ) or @xmath29 ( the set of measures supported on up to @xmath27 atoms with weights in a subset @xmath25 of @xmath28 ) .",
    "looking for a barycenter @xmath16 with atoms @xmath24 and weights @xmath45 is equivalent to minimizing @xmath57 ( see eq .",
    "[ eq : primal ] for a definition of @xmath51 ) , @xmath92 over relevant feasible sets for @xmath45 and @xmath24 . when @xmath24 is _ fixed _",
    ", we show in  [ subsec : dualityconvexity ] that @xmath57 is convex w.r.t @xmath45 regardless of the properties of @xmath0 .",
    "a subgradient for @xmath57 w.r.t @xmath45 can be recovered through the _ dual optimal solutions _ of all problems @xmath93 , and @xmath57 can be minimized using a projected subgradient method outlined in ",
    "[ subsec : xrestricted ] .",
    "if @xmath24 is _ free _ , constrained to be of cardinal @xmath27 , and @xmath0 and its metric @xmath5 are both _ euclidean _ , we show in  [ subsec : xeuclidean ] that @xmath57 is not convex w.r.t @xmath24 but we can provide subgradients for @xmath57 using the _ primal optimal solutions _ of all problems @xmath93 .",
    "this in turn suggests an algorithm to reach a local minimum for @xmath57 w.r.t .",
    "@xmath45 and @xmath24 in @xmath29 by combining both approaches .      *",
    "dual transportation problem . * given a matrix @xmath95 , the optimum @xmath96 admits the following dual linear program ( lp ) form ( * ? ? ?",
    "* ,  7.8 ) , known as the dual optimal transport problem : @xmath97 where the polyhedron @xmath98 of dual variables is @xmath99 by lp duality , @xmath100 .",
    "the dual optimal solutions  which can be easily recovered from the primal optimal solution ( * ? ? ?",
    "* eq.7.10)define a subgradient for @xmath51 as a function of @xmath45 :    [ prop : convex ] given @xmath43 and @xmath95 , the map @xmath101 is a polyhedral convex function .",
    "any optimal dual vector @xmath102 of @xmath103 is a subgradient of @xmath96 with respect to @xmath45 .",
    "these results follow from sensitivity analysis in lp s @xcite .",
    "@xmath104 is bounded and is also the maximum of a finite set of linear functions , each indexed by the set of extreme points of @xmath98 , evaluated at @xmath45 and is therefore polyhedral convex .",
    "when the dual optimal vector is unique , @xmath102 is a gradient of @xmath51 at @xmath45 , and a subgradient otherwise .",
    "because for any real value @xmath105 the pair @xmath106 is feasible if the pair @xmath107 is feasible , and because their objective are identical , any dual optimum @xmath107 is determined up to an additive constant . to remove this degree of freedom  which arises from the fact that one among all @xmath108 row / column sum constraints of @xmath41 is redundant ",
    "we can either remove a dual variable or normalize any dual optimum @xmath102 so that it sums to zero , to enforce that it belongs to the tangent space of @xmath22 .",
    "we follow the latter strategy in the rest of the paper .",
    "let @xmath109 be fixed and let @xmath25 be a closed convex subset of @xmath22 .",
    "the aim of this section is to compute weights @xmath110 such that @xmath111 is minimal .",
    "let @xmath112 be the optimal dual variable of @xmath113 normalized to sum to 0 .",
    "@xmath57 being a sum of terms @xmath93 , we have that :    the function @xmath114 is polyhedral convex , with subgradient @xmath115    assuming @xmath25 is closed and convex , we can consider a naive projected subgradient minimization of @xmath57 . alternatively ,",
    "if there exists a bregman divergence @xmath116 for @xmath117 defined by a prox - function @xmath118 , we can define the proximal mapping @xmath119 and consider accelerated gradient approaches @xcite .",
    "we summarize this idea in algorithm  [ algo : discwass ] .    * inputs * : @xmath120 . for @xmath121 .",
    "form all @xmath122 matrices @xmath123 , see eq .  .",
    "set @xmath124 .",
    "@xmath125 , @xmath126 .",
    "form subgradient @xmath127 using all dual optima @xmath112 of @xmath128 .",
    "@xmath129 . @xmath130 .",
    "notice that when @xmath131 and @xmath132 is the kullback - leibler divergence @xcite , we can initialize @xmath133 with @xmath134 and use the multiplicative update to realize the proximal update : @xmath135 , where @xmath136 is schur s product .",
    "alternative sets @xmath25 for which this projection can be easily carried out include , for instance , all ( convex ) level set of the entropy function @xmath137 , namely @xmath138 where @xmath139 .",
    "we consider now the case where @xmath84 with @xmath140 , @xmath5 is the euclidean distance and @xmath77 .",
    "when @xmath84 , a family of @xmath19 points @xmath24 and a family of @xmath141 points @xmath39 can be represented respectively as a matrix in @xmath142 and another in @xmath143 .",
    "the pairwise squared - euclidean distances between points in these sets can be recovered by writing @xmath144 and @xmath145 , and observing that @xmath146 * transport cost as a function of @xmath24 . * due to the margin constraints that apply if a matrix @xmath147 is in the polytope @xmath41 , we have : @xmath148    discarding constant terms in @xmath149 and @xmath46 , we have that minimizing @xmath94 with respect to locations @xmath24 is equivalent to solving @xmath150 as a function of @xmath24 , that objective is the sum of a convex quadratic function of @xmath24 with a piecewise linear concave function , since @xmath151 is the minimum of linear functions indexed by the vertices of the polytope @xmath41 . as a consequence , @xmath94 is not convex with respect to @xmath24 . + * quadratic approximation . *",
    "suppose that @xmath152 is optimal for problem @xmath94 .",
    "updating eq .",
    ", @xmath153 minimizing a local quadratic approximation of @xmath51 at @xmath24 yields thus the newton update @xmath154 a simple interpretation of this update is as follows : the matrix @xmath155 has @xmath19 column - vectors in the simplex @xmath156",
    ". the suggested update for @xmath24 is to replace it by @xmath19 barycenters of points enumerated in @xmath39 with weights defined by the optimal transport @xmath152 .",
    "note that , because the minimization problem we consider in @xmath24 is not convex to start with , one could be fairly creative when it comes to choosing @xmath5 and @xmath12 among other distances and exponents .",
    "this substitution would only involve more complicated gradients of @xmath38 w.r.t .",
    "@xmath24 that would appear in eq .  .",
    "we now consider , as a natural extension of  [ subsec : xrestricted ] when @xmath84 , the problem of minimizing @xmath57 over a probability measure @xmath16 that is ( i ) supported by _ at most @xmath27 atoms _ described in @xmath24 , a matrix of size @xmath158 , ( ii ) with weights in @xmath159 .",
    "* alternating optimization .",
    "* to obtain an approximate minimizer of @xmath111 we propose in algorithm  [ algo : general ] to update alternatively locations @xmath24 ( with the newton step defined in eq .",
    "[ eq : newton ] ) and weights @xmath45 ( with algorithm  [ algo : discwass ] ) .    * input * : @xmath160 for @xmath161 initialize @xmath162 and @xmath110 @xmath163 using algorithm  [ algo : discwass ] .",
    "@xmath164 optimal solution of @xmath165 @xmath166 , setting @xmath167 $ ] with line - search or a preset value .",
    "* algorithm  [ algo : general ] and @xcite/@xcite algorithms . * as mentioned in ",
    "[ sec : back ] , minimizing @xmath57 defined in eq .   over @xmath168 , with @xmath73 , @xmath77 and",
    "no constraints on the weights ( @xmath169 ) , is equivalent to solving the @xmath27-means problem applied to the set of points enumerated in @xmath170 . in that particular case ,",
    "algorithm  [ algo : general ] is also equivalent to @xcite s algorithm .",
    "indeed , the assignment of the weight of each point to its closest centroid in @xcite s algorithm ( the maximization step ) is equivalent to the computation of @xmath171 in ours , whereas the re - centering step ( the expectation step ) is equivalent to our update for @xmath24 using the optimal transport , which is in that case the trivial transport that assigns the weight ( divided by @xmath54 ) of each atom in @xmath172 to its closest neighbor in @xmath24 .",
    "when the weight vector @xmath45 is constrained to be uniform ( @xmath173 ) , @xcite proposed a heuristic to obtain uniform @xmath27-means that is also equivalent to algorithm  [ algo : general ] , and which also relies on the repeated computation of optimal transports . for more general sets @xmath25 , algorithm  [ algo : discwass ]",
    "ensures that the weights @xmath45 remain in @xmath25 at each iteration of algorithm  [ algo : general ] , which can not be guaranteed by neither @xcite s nor @xcite s approach .",
    "* algorithm  [ algo : general ] and @xcite s @xcite transform .",
    "* @xcite has recently suggested to approximate a weighted measure @xmath17 by a uniform measure supported on as many atoms .",
    "this approximation is motivated by optimal transport theory , notably asymptotic results by @xcite , but does not attempt to minimize , as we do in algorithm  [ algo : general ] , any wasserstein distance between that approximation and the original measure .",
    "this approach results in one application of the newton update defined in eq .",
    ", when @xmath24 is first initialized to @xmath39 and @xmath174 to compute the optimal transport @xmath152 .",
    "* summary * we have proposed two original algorithms to compute wasserstein barycenters of probability measures : one which applies when the support of the barycenter is fixed and its weights are constrained to lie in a convex subset @xmath25 of the simplex , another which can be used when the support can be chosen freely .",
    "these algorithms are relatively simple , yet  to the best of our knowledge  novel .",
    "we suspect these approaches were not considered before because of their prohibitive computational cost : algorithm  [ algo : discwass ] computes at each iteration the dual optima of @xmath54 transportation problems to form a subgradient , each with @xmath175 variables and @xmath122 inequality constraints .",
    "algorithm  [ algo : general ] incurs an even higher cost , since it involves running algorithm  [ algo : discwass ] at each iteration , in addition to solving @xmath54 primal optimal transport problems to form a subgradient to update @xmath24 .",
    "since both objectives rely on subgradient descent schemes , they are also likely to suffer from a very slow convergence .",
    "we propose to solve these issues by following @xcite s approach @xcite to smooth the objective @xmath57 and obtain strictly convex objectives whose gradients can be computed more efficiently .",
    "to circumvent the major computational roadblock posed by the repeated computation of primal and dual optimal transports , we extend @xcite s approach @xcite to obtain smooth and strictly convex approximations of both primal and dual problems @xmath51 and @xmath104 . the matrix scaling approach advocated by @xcite was motivated by the fact that it provided a fast approximation @xmath176 to @xmath51 .",
    "we show here that the same approach can be used to smooth the objective @xmath57 and recover for a cheap computational price its gradients w.r.t . @xmath45 and @xmath24 .",
    "a @xmath44 transport @xmath147 , which is by definition in the @xmath177-simplex , has entropy @xmath178 @xcite has recently proposed to consider , for @xmath179 , a regularized primal transport problem @xmath176 as @xmath180    we introduce in this work its dual problem , which is a smoothed version of the original dual transportation problem , where the positivity constraints of each term @xmath181 have been replaced by penalties @xmath182 : @xmath183    these two problems are related below in the sense that their respective optimal solutions are linked by a unique positive vector @xmath184 :    [ prop : primdual]let @xmath185 be the elementwise exponential of @xmath186 , @xmath187 .",
    "then there exists a pair of vectors @xmath188 such that the optimal solutions of @xmath176 and @xmath189 are respectively given by @xmath190    the result follows from the lagrange method of multipliers for the primal as shown by ( * ? ? ?",
    "* lemma 2 ) , and a direct application of first - order conditions for the dual , which is an unconstrained convex problem .",
    "the term @xmath191 in the definition of @xmath192 is used to normalize @xmath192 so that it sums to zero as discussed in the end of  [ subsec : dualityconvexity ] .",
    "the positive vectors @xmath193 mentioned in proposition  [ prop : primdual ] can be computed through @xcite s matrix scaling algorithm applied to @xmath185 , as outlined in algorithm  [ algo : sk ] :    [ theo : sk ] for any positive matrix @xmath194 in @xmath195 and positive probability vectors @xmath42 and @xmath43 , there exist positive vectors @xmath196 and @xmath197 , unique up to scalar multiplication , such that @xmath198 .",
    "such a pair @xmath193 can be recovered as a fixed point of the sinkhorn map @xmath199    the convergence of the algorithm is linear when using hilbert s projective metric between the scaling factors @xcite .",
    "although we use this algorithm in our experiments because of its simplicity , other algorithms exist @xcite which are known to be more reliable numerically when @xmath200 is large .",
    "* input * @xmath201 @xmath202 ; @xmath203 % use ` bsxfun(@rdivide , k , a ) ` set @xmath204`ones(n,1)/n ` ; ` u=1./(\\widetilde{k}(b./(k^tu ) ) ) ` .",
    "@xmath205 @xmath206 . @xmath207 . % use @xmath208 ;        * summary : * given a smoothing parameter @xmath179 , using sinkhorn s algorithm on matrix @xmath185 , defined as the elementwise exponential of @xmath209 ( the pairwise gaussian kernel matrix between the supports @xmath24 and @xmath39 when @xmath77 , using bandwidth @xmath210 ) we can recover smoothed optima @xmath211 and @xmath212 for _ both _ smoothed primal @xmath176 and dual @xmath189 transport problems . to take advantage of this",
    ", we simply propose to substitute the smoothed optima @xmath211 and @xmath212 to the original optima @xmath102 and @xmath152 that appear in algorithms  [ algo : discwass ] and [ algo : general ] .",
    "we present two applications , one of algorithm  [ algo : discwass ] and one of algorithm [ algo : general ] , that both rely on the smooth approximations presented in ",
    "[ sec : smooth ] .",
    "the settings we consider involve computing respectively tens of thousands or tens of high - dimensional optimal transport problems2.500@xmath2132.500 for the first application , @xmath214 for the second  which can not be realistically carried out using network flow solvers . using network flow solvers ,",
    "the resolution of a single transport problem of these dimensions could take between several minutes to several hours .",
    "we also take advantage in the first application of the fact that algorithm  [ algo : sk ] can be run efficiently on gpgpus using vectorized code ( * ? ? ?",
    "* alg.1 ) .",
    "we use @xmath215 images of the mnist database , with approximately @xmath216 images for each digit from 0 to 9 .",
    "each image ( originally @xmath217 pixels ) is scaled randomly , uniformly between half - size and double - size , and translated randomly within a @xmath218 grid , with a bias towards corners .",
    "we display intermediate barycenter solutions for each of these 10 datasets of images for @xmath219 gradient iterations .",
    "@xmath200 is set to @xmath220 , where @xmath221 is the squared - euclidean distance matrix between all 2,500 pixels in the grid .",
    "using a quadro k5000 gpu with close to 1500 cores , the computation of a single barycenter takes about 2 hours to reach 100 iterations . because we use warm starts to initialize @xmath222 in algorithm  [ algo : sk ] at each iteration of algorithm  [ algo : discwass ] , the first iterations are typically more computationally intensive than those carried out near the end .",
    "-1.2 cm ) centroids .",
    "the size of each of the 57.647 blue crosses is proportional to the local average of the relevant variable ( income above and population below ) at that location , normalized to sum to 1 .",
    "each downward triangle is a centroid of the @xmath27-means clustering ( equivalent to a wasserstein barycenter with @xmath169 ) whose size is proportional to the portion of mass captured by that centroid .",
    "red dots indicate centroids obtained with a uniform constraint on the weights , @xmath173 . since such centroids are constrained to carry a fixed portion of the total weight , one can observe that they provide a more balanced clustering than the @xmath27-means solution.,title=\"fig:\",width=415 ]      in practice , the @xmath27-means cost function applied to a given empirical measure could be minimized with a set of centroids @xmath24 and weight vector @xmath45 such that the entropy of @xmath45 is very small .",
    "this can occur when most of the original points in the dataset are attributed to a very small subset of the @xmath27 centroids , and could be undesirable in applications of @xmath27-means where a more regular attribution is sought .",
    "for instance , in sensor deployment , when each centroid ( sensor ) is limited in the number of data points ( users ) it can serve , we would like to ensure that the attributions agree with those limits .    whereas the original @xmath27-means can not take into account such limits",
    ", we can ensure them using algorithm  [ algo : general ] .",
    "we illustrate the difference between looking for optimal centroids with `` free '' assignments ( @xmath169 ) , and looking for optimal `` uniform '' centroids with constrained assignments ( @xmath173 ) using us census data for income and population repartitions across 57.647 spatial locations in the 48 contiguous states .",
    "these weighted points can be interpreted as two empirical measures on @xmath223 with weights directly proportional to these respective quantities .",
    "we initialize both `` free '' and `` uniform '' clustering with the actual 48 state capitals .",
    "results displayed in figure  [ fig : america ] show that by forcing our approximation to be uniform , we recover centroids that induce a more balanced clustering .",
    "indeed , each cell of the voronoi diagram built with these centroids is now constrained to hold the same aggregate wealth or population .",
    "these centroids could form the new state capitals of equally rich or equally populated states . on an algorithmic note ,",
    "we notice in figure  [ fig : graphe ] that algorithm  [ algo : general ] converges to its ( local ) optimum at a speed which is directly comparable to that of the @xmath27-means in terms of iterations , with a relatively modest computational overhead .",
    "unsurprisingly , the wasserstein distance between the clusters and the original measure is higher when adding uniform constraints on the weights .    ) and its unconstrained equivalent ( @xmath27-means ) to the income empirical measure .",
    "note that , because of the constraints on weights , the wasserstein distance of the uniform wasserstein barycenter is necessarily larger . on a single cpu core ,",
    "these computations require 12.5 seconds for the constrained case , using sinkhorn s approximation , and 1.55 seconds for the regular @xmath27-means algorithm . using a regular transportation solver , computing",
    "the optimal transport from the 57.647 points to the 48 centroids would require about 1 hour for a single iteration , width=283 ]      we have proposed in this paper two original algorithms to compute wasserstein barycenters of empirical measures .",
    "using these algorithms in practice for measures of large support is a daunting task for two reasons : they are inherently slow because they rely on the subgradient method ; the computation of these subgradients involves solving optimal and dual optimal transport problems .",
    "both issues can be substantially alleviated by smoothing the primal optimal transport problem with an entropic penalty and considering its dual .",
    "both smoothed problems admit gradients which can be computed efficiently using only matrix vector products .",
    "our aim in proposing such algorithms is to demonstrate that wasserstein barycenters can be used for visualization , constrained clustering , and hopefully as a core component within more complex data analysis techniques in future applications .",
    "we also believe that our smoothing approach can be directly applied to more complex variational problems that involve multiple wasserstein distances , such as wasserstein propagation  @xcite ."
  ],
  "abstract_text": [
    "<S> we present new algorithms to compute the mean of a set of empirical probability measures under the optimal transport metric . </S>",
    "<S> this mean , known as the wasserstein barycenter , is the measure that minimizes the sum of its wasserstein distances to each element in that set . </S>",
    "<S> we propose two original algorithms to compute wasserstein barycenters that build upon the subgradient method . </S>",
    "<S> a direct implementation of these algorithms is , however , too costly because it would require the repeated resolution of large primal and dual optimal transport problems to compute subgradients . extending the work of @xcite </S>",
    "<S> , we propose to smooth the wasserstein distance used in the definition of wasserstein barycenters with an entropic regularizer and recover in doing so a strictly convex objective whose gradients can be computed for a considerably cheaper computational cost using matrix scaling algorithms . </S>",
    "<S> we use these algorithms to visualize a large family of images and to solve a constrained clustering problem . </S>"
  ]
}