{
  "article_text": [
    "the sample average and standard deviation are the classical estimators of the location and the scale parameters of a statistical distribution .",
    "it is well - known that these classical estimators , although being optimal under normality assumptions , are extremely sensitive to the presence of outliers in the data ; a small proportion of outliers in the data can have a large distorting effect on the sample mean and covariance .",
    "robust statistics is concerned with the development of methods for computing estimators that are justifiably resistant to the presence of outliers in the data .",
    "the focus of this work is to estimate the unknown location parameter @xmath1 of a family of distributions @xmath2 given some observational data which is contaminated with an unknown number of outliers .",
    "detecting outliers and unusual data structures is one of the main problems in statistical data analysis since this occurs in many different application domains .",
    "one such application is in large scale complex networks , where the graph data may arrive in streams  @xcite . given that the degrees in social networks typically follow a power law distribution , it is of importance to identify outlier nodes which do not follow the degree distribution of the majority of the nodes , since these nodes may affect the computation of several graph characteristics such as community detection , clustering coefficient etc .",
    "projection pursuit is one of the typical approaches for outlier detection .",
    "the idea is to repeatedly project the multivariate data into the univariate space since univariate outlier detection is much simpler to handle by applying order statistics and visualization .",
    "such methods are usually computationally intensive , but they are particularly useful for high - dimensional data with small sample size .",
    "one such technique is the principal components analysis in  @xcite .",
    "outlier detection can also be done based on estimations of the covariance matrix .",
    "the idea is to use estimated covariance structure in order to find a distance , usually the well - known mahalanobis distance , from each observation to the center of the data cloud .",
    "one such method is the minimum covariance determinant ( mcd ) introduced in @xcite and in @xcite .",
    "desirable properties for an estimator include high breakdown values , high efficiency , and fast computation .",
    "one famous robust location estimator is the multivariate least euclidean distance ( led ) as studied in @xcite .",
    "other methods for robust location estimation include the transformation median ( @xcite ) and the oja multivariate half samples median ( homm ) @xcite .",
    "the corresponding univariate cases of the half samples ( homm ) and mcd are the least trimmed absolute deviation ( ltad ) and least trimmed squared ( lts ) estimators respectively .",
    "the ltad robust estimator for univariate data was introduced in  @xcite , where it was shown that it has desirable asymptotic properties such as robustness , consistently , high breakdown and normality . moreover , in  @xcite the author also presents an algorithm to efficiently compute the ltad in @xmath3 time .",
    "however , these methods do not generalize to higher dimensions . in",
    "@xcite the ltad is generalized to handle multivariate data using the euclidean norm , and the resulting combinatorial optimization problem is solved by an approximate fixed - point like iterative procedure .",
    "computational experiments in  @xcite on both real and artificial data indicate that the proposed method efficiently identifies both location and scatter outliers in varying dimensions and high degree of contamination . in this work",
    "we extend the results in  @xcite , and present a different generalization of ltad which is based on the @xmath0 norm .",
    "it is shown that the linear programming relaxation of the resulting mixed integer program is integral , after applying an appropriate equidistance data transformation .",
    "this implies that the ltad can be computed as a series of linear programs , which can be solved efficiently using a subgradient optimization approach .",
    "the rest of this paper is structured as follows . in section  [ sec_ltad ]",
    "we present the generalized ltad for multivariate data using the @xmath0 norm while it s mixed integer programming formulation is given in section  [ sec_mip_ltad ] .",
    "the integrality of the relaxation is presented in section  [ sec_lp_ltad ] , along with the procedure to perform the data transformation .",
    "the subgradient optimization approach for solving the related linear programs is presented in section  [ sec_lps ] and in section  [ sec_computations ] we perform computational experiments in real and simulated data to verify the performance of the proposed estimator .",
    "conclusions are given in  [ sec_conclusions ] .",
    "given a sample of @xmath4 univariate observations @xmath5 where @xmath6 we can state the well known location parameter _ median _ as follows : @xmath7 letting @xmath8 to denote the order of the data points , a trivial solution to ( [ eq_median ] ) is @xmath9 then @xmath10 the _ mean _ is another example of a location estimator for a data set @xmath11 , as well as the _ least median of squares _",
    "@xcite which is the midpoint of the subset that contains half of the observations with the smallest range .",
    "three statistically desirable properties of an estimator are _ equivariance _ , _ monotonicity _ and _ 50% breakdown point_. equivariance implies that if the data points are scaled and shifted then the value of the estimator will change accordingly , while monotonicity implies that the estimator can not decrease in value if an observation increases .",
    "an estimator has 50% breakdown point if its value will be bounded for any arbitrary change of less than half of the observations .",
    "basset  @xcite has proven that the median is the only estimator that satisfies all three properties .",
    "if we make the assumption that @xmath12 of observations are outliers , where @xmath13 , we can define a robust version of the median which will be called _ least trimmed absolute deviations _ ( ltad ) estimator , defined by the following problem : @xmath14 which implies that we have to find that subset @xmath15 of @xmath16 observations out of @xmath4 which have the least median value . in order to satisfy the high breakdown property , the value of @xmath16",
    "is set to @xmath17 . solving ( [ eq_ltad ] ) by complete enumeration would require the computation of the median for all possible @xmath18 subsets @xmath19 and choosing the one with the minimum value , which is computationally infeasible even for moderate values of @xmath4 and @xmath20 .",
    "the ltad was introduced by tableman  @xcite for fixed @xmath21 , where in addition to showing favorable theoretical properties the author also provides a simple procedure for its computation based on the observation that the solution to will be the median of one of the following @xmath12 contiguous subsets @xmath22 therefore , it suffices to compute the @xmath12 median values for the above subsets , a process that will require @xmath3 time to order the data points according to increasing value .",
    "consider now the multidimensional version of the ltad defined in , where we have @xmath20-variate observations @xmath23 with @xmath24 .",
    "moreover , without loss of generality we can assume that the observations are rescalled .",
    "the multivariate ltad is defined as @xmath25 where @xmath26 stands for the one norm i.e. @xmath27 . for the ease of exposition in the rest of the paper",
    ", we refer to both the univariate and the multivariate ltad as the _ ltad problem_.    the ltad problem can be approximated by an iterative algorithm similar to the procedure described in  @xcite for solving the related _ least trimmed euclidean distances _ ( lted ) estimator , which is defined as the ltad in with the only exception that the euclidean norm is used instead of the one norm .",
    "the same necessary optimality condition that is proved for lted in  @xcite can also be proved for the ltad , which leads to a highly convergent heuristic algorithm . however , although this algorithm is very fast , it almost always converges to a local optimum of unknown quality .    in this paper",
    "we present a different solution method for the ltad , by approximating its natural mixed integer nonlinear programming formulation with with a mixed integer linear program whose linear programming relaxation is integral . we also develop specialized efficient solution methods for the resulting linear program , since the iterative nature of the proposed method requires multiple calls for solving them .",
    "the ltad estimate can be equivalently stated as the following mixed integer nonlinear programming problem @xmath28 where the zero - one weights @xmath29 indicate whether observation @xmath30 is an outlier ( @xmath31 ) or a good observation ( @xmath32 ) . for any feasible tuple @xmath33 to ,",
    "let @xmath34 denote the vector @xmath35 with the @xmath30-th smallest @xmath36 value , and @xmath37 its corresponding weight .",
    "we can now write as follows @xmath38 since @xmath39 for all @xmath40 .",
    "observe that as @xmath1 approaches zero , then @xmath41 approaches @xmath42 , thus , for small values of @xmath1 problem can be approximated by the following @xmath43 which is equivalent to the following mixed integer linear program @xmath44 where @xmath45 is an @xmath46 matrix with values @xmath47 , and @xmath48 is the @xmath46 observations matrix whose rows are @xmath49 for @xmath50 .",
    "there are two issues with approximating with .",
    "first of all , we need to ensure that milp - ltad is a good approximation of the minlp - ltad . secondly , we need to be able to solve efficiently",
    ". we will resolve the first issue by iteratively transforming the data such that the optimal @xmath1 approaches zero .",
    "for the second issue we will show that the resulting mixed integer linear programming problem is equivalent to a linear programming problem under certain assumptions .",
    "denote with lp - ltad the linear programming relaxation of where @xmath51^{n } $ ] , consider the linear programming relaxation of @xmath52^{n } \\nonumber\\end{aligned}\\ ] ] let @xmath53 be the optimum solution of lp - ltad . if @xmath54 is integer , then this lp solution is also an optimal solution of .",
    "we show next , that if in the linear programming optimum solution @xmath55 is equal to zero , then @xmath56 is optimal for the milp - ltad ; that is , we can solve the linear programming relaxation and use it to obtain an optimal solution for the milp in .",
    "[ lemma1 ] for any @xmath57 , if @xmath58 , then @xmath59 is an optimal solution of milp - ltad .",
    "let @xmath60 and @xmath61 be the optimal solutions of lp - ltad and milp - ltad respectively . if @xmath58 then @xmath62 which implies that @xmath63 if @xmath64 and zero otherwise ; or equivalently @xmath65 .",
    "thus , @xmath59 is feasible to milp - ltad and @xmath66 .",
    "lemma  [ lemma1 ] implies that if we could transform the data in such a way that @xmath67 gets closer to zero , then we can just solve the lp problem to obtain an approximated solution for the ltad .",
    "this leads to the procedure described in algorithm  [ alg : ltad ] , where the data is iteratively transformed such that its median value is less than some small value @xmath68 .",
    "@xmath69 = lp - ltad(@xmath70 ) @xmath71 @xmath72",
    "in algorithm  [ alg : ltad ] we have to solve the associated linear programming problem in each iteration , until @xmath73 converges to a value smaller than @xmath68 .",
    "the lp as defined in , has @xmath74 decision variables and @xmath75 constraints and can be solved efficiently for relatively small @xmath76 . however , for large values of @xmath77 ( e.g. @xmath78 and @xmath79 ) , the problem has a million decision variables and two million constraints .",
    "although this is still solvable , we need to find an efficient solution method since there will be multiple calls to the solution of this lp . in what follows",
    "we will exploit the special structure of the problem to develop such a method .",
    "given @xmath80 , let @xmath81 be the corresponding median of vector @xmath82 .",
    "this means @xmath83 is an optimal solution of for a fixed @xmath80 . letting @xmath84 we can write as @xmath85 here",
    "we have transformed the original problem into a new optimization problem in @xmath86 that has a nice constraint set .",
    "however , the objective function is non - linear .",
    "rewriting @xmath87 we have @xmath88,\\\\\\end{aligned}\\ ] ] which is a piece - wise convex function because it is the sum of a linear function and the maximum of linear functions .",
    "this in turn implies that we can solve the problem using a projected subgradient method , which is shown in algorithm  [ alg : subgradient ] .",
    "@xmath89 find subgradient @xmath90 and set @xmath91 find the projection @xmath92 of @xmath93 on the polyhedron @xmath94 @xmath92 @xmath95    in order to apply the projected subgradient method depicted in algorithm  [ alg : subgradient ] , we need to resolve the following three issues : ( a ) find good initial starting @xmath96 , ( b ) compute the subgradients , and ( c ) perform efficient projection onto the polyhedron .",
    "methods for resolving these issues will be presented in the next subsections .",
    "we will find an initial starting point @xmath97 by finding a local optimal solution @xmath98 for the original problem .",
    "the idea is to start with an arbitrary initial solution @xmath99 , set @xmath89 , and repeat the following steps :    * fix @xmath100 and solve for the corresponding optimal @xmath92 * if @xmath101 , return @xmath92 and terminate the procedure .",
    "otherwise , fix @xmath102 and solve for the corresponding optimal @xmath103 . set @xmath95 and go back to step ( a ) .    in step ( b )",
    ", for each fixed @xmath80 finding the corresponding optimal @xmath1 is easy , as @xmath104 can be set as the median of @xmath82 .",
    "finding the optimal @xmath80 for each fixed @xmath1 is non - trivial unless we reformulate it as an lp , but this will be computationally inefficient for large @xmath76 . a more efficient method is to use a subgradient method to solve the lagrangian dual problem by noticing that the problem has only one linking constraint @xmath105 .",
    "specifically , for a given @xmath1 , we need to solve @xmath106 let @xmath107 be the lagrangian multiplier of the equality constraint ( [ constr : init_w ] ) .",
    "the lagrangian dual problem is @xmath108 which can be further simplified as @xmath109 \\right),\\end{aligned}\\ ] ] for each fixed @xmath107 , the inner problem has a closed form solution for @xmath110 by noticing that the function @xmath111 is piece - wise convex with at most @xmath112 pieces that join each other at @xmath113 .",
    "this means we can find the optimal @xmath110 by simply comparing the objective values at those joints that belong to @xmath114 $ ] . as the inner problem has a closed - form solution and as the outer problem has only a single variable @xmath107 , the lagrangian dual problem can be solved very efficiently . summarizing ,",
    "we can repeatedly find improving @xmath115 and stop the process at a local optimal solution of .    for finding subgradients , we notice that @xmath116 where @xmath117      the projection of a point on a polyhedron can be found by solving a convex quadratic optimization problem .",
    "however , this is not a computationally efficient way and we need to find an alternative by exploiting the special constraint set for @xmath80 . notice that this includes only one hyperplane @xmath105 and a set of box constraints .",
    "thus , the projection of any point @xmath80 into this polyhedron can be found through two steps :    * finding the projection @xmath118 of @xmath80 onto the plane @xmath105 which has a closed form solution . * finding the projection @xmath119 of @xmath118 into the box constraints .",
    "this is simply done by setting : @xmath120",
    "in this section the performances of lp - ltad and milp - ltad estimators are compared against the performance a heuristic iterative algorithm for solving the ltad based on the algorithm 2.1 given in  @xcite .",
    "the solutions of the associated problems and , were computed using the solver fortmp / qmip which is a fortran code provided by @xcite .",
    "the computation of the ltad solutions were obtained by a matlab implementation of the algorithm in @xcite .",
    "most of the robust estimators in the literature choose a priori a coverage of @xmath121 , which yields a clean subsample of minimum size .",
    "however , if there are fewer outliers in the sample than half of the observations , then information will be discarded when calculating robust estimates based on this . as a consequence",
    "these estimates suffer from low efficiency .",
    "one solution to this problem is to adapt @xmath16 , resulting in more efficient estimators which have lower breakdown points . in other words ,",
    "most robust estimators have to deal with this robustness versus efficiency trade off .",
    "a typical procedure for empirically evaluating the efficiency of robust estimators , is to apply the estimators on a clean data set and compare their performance .",
    "we conducted a simulation with a a sample data set of 100 observations that follow the standard normal distribution with @xmath122 .",
    "after 100 replications , the comparison criterion is the average classical center estimate , or median , for the different coverage sizes @xmath123 and @xmath124 as it is demonstrated in table [ tltad_21 ] .",
    ".median estimate for data set of normal distribution , @xmath125 [ cols=\"^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     in summary , based on the computational results we can conclude that there are negligible differences between the three estimators for non - correlated data and contaminated with strong outliers . in the case of correlated data lp - ltad has the best performance .",
    "also , if the data is contaminated with intermediate outliers the lp - ltad has is superior because it can work with coverage less than @xmath126 while , on the other hand , the ltad includes some of the intermediate outliers into the coverage set so they become masked .",
    "in this work , we develop numerical methods for computing the multivariate ltad estimator based on the @xmath0 norm , by reformulating its original mixed integer nonlinear formulation .",
    "we show that the minlp is equivalent to an milp and subsequently to an lp under some conditions on the location estimate .",
    "an lp - based iterative approach is then developed for computing the estimator , by transforming the data and solving the resulting linear programs by subgradient optimization .",
    "the new lp - ltad formulation can also be viewed as a new trimming procedure that trims away large residuals implicitly by shrinking the associated observations to zero .",
    "the new approach yields a robust location estimate without loosing efficiency .",
    "we perform numerical experiments and show that the new estimate performs well even in the case of contaminated and correlated multivariate data .",
    "the lp - ltad procedure can be used when the data involves both type of outliers , strong and intermediate , and also when the coverage is smaller than half the sample observations .",
    "charu c. aggarwal , yuchen zhao and philip s. yu .",
    "outlier detection in graph streams . in _ proceedings of the 2011 ieee 27th international conference on data engineering _",
    ", pages 399409 .",
    "ieee computer society , 2011 ."
  ],
  "abstract_text": [
    "<S> given a dataset an outlier can be defined as an observation that it is unlikely to follow the statistical properties of the majority of the data . </S>",
    "<S> computation of the location estimate of is fundamental in data analysis , and it is well known in statistics that classical methods , such as taking the sample average , can be greatly affected by the presence of outliers in the data . using the median instead of </S>",
    "<S> the mean can partially resolve this issue but not completely . </S>",
    "<S> for the univariate case , a robust version of the median is the least trimmed absolute deviation ( ltad ) robust estimator introduced in  @xcite , which has desirable asymptotic properties such as robustness , consistently , high breakdown and normality . </S>",
    "<S> there are different generalizations of the ltad for multivariate data , depending on the choice of norm . in  </S>",
    "<S> @xcite we present such a generalization using the euclidean norm and propose a solution technique for the resulting combinatorial optimization problem , based on a necessary condition , that results in a highly convergent local search algorithm . in this subsequent work </S>",
    "<S> we use the @xmath0 norm to generalize the ltad to higher dimensions , and show that the resulting mixed integer programming problem has an integral relaxation , after applying an appropriate data transformation . </S>",
    "<S> moreover , we utilize the structure of the problem to show that the resulting lp s can be solved efficiently using a subgradient optimization approach . </S>",
    "<S> the robust statistical properties of the proposed estimator are verified by extensive computational results .    </S>",
    "<S> * keywords : * robust location estimation ; least trimmed absolute deviation ; outlier detection ; linear programming ; mixed integer programming </S>"
  ]
}