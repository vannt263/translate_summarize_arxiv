{
  "article_text": [
    "compressive sensing ( cs ) aims to solve the following optimization problem to estimate the sparsest vector @xmath3    @xmath4    where the @xmath5 counts the number of nonzeros in @xmath3 .",
    "this problem is known to be np - hard , and the theory of compressive sensing has found many approximations to solve this problem .",
    "one such approximation is known as _ basis pursuit _ ( bp ) and solves the following convex approximation to ( [ cs ] )    @xmath6    this approach allows one to solve for the sparsest vector @xmath3 for a linear model under certain conditions , which have been studied extensively @xcite .",
    "recently , there has been an interest to generalize cs to nonlinear models . in particular in this report",
    "we will focus on solving    @xmath7    where , @xmath8 solving ( [ qcs ] ) will allow us to solve cs problems where the model takes a quadratic form rather than a linear form .",
    "in this section we give reasons why we want to solve the sparse solution of undetermined systems of linear equations .",
    "this is the most direct application . lets consider a equation , @xmath9 in which @xmath10 is an under sampled version of image @xmath11 in a fourier domain .",
    "if we no before hand that @xmath11 is sparse image , we can recover @xmath11 from @xmath10 using equation that provides an approximation of @xmath11 from @xmath10 .",
    "compressive sensing ( cs ) aims to solve the following optimization problem to estimate the sparsest vector @xmath3    @xmath4    where the @xmath5 counts the number of nonzeros in @xmath3 .",
    "this problem is known to be np - hard , and the theory of compressive sensing has found many approximations to solve this problem .",
    "one such approximation is known as _ basis pursuit _ ( bp ) and solves the following convex approximation to ( [ cs ] )    @xmath6    this approach allows one to solve for the sparsest vector @xmath3 for a linear model under certain conditions , which have been studied extensively @xcite .",
    "recently , there has been an interest to generalize cs to nonlinear models .",
    "in particular in this report we will focus on solving    @xmath7    where , @xmath8 solving ( [ qcs ] ) will allow us to solve cs problems where the model takes a quadratic form rather than a linear form .",
    "let @xmath12 be a vector which has encoded @xmath11 by a linear system .",
    "a of size @xmath13 where @xmath14 . that is @xmath15 .",
    "now if the the @xmath12 obtained is corrupted by noise such that @xmath16 .",
    "in such a case we need to obtain the error corrupting @xmath12 , lets consider a matrix @xmath17 which is @xmath18 such that @xmath19 hence we obtain @xmath20 , we consider @xmath21 therefore we get a linear equation @xmath22 we can use ( 1 ) to solve for @xmath23 if @xmath10 is constant .",
    "similarly to ( [ cs ] ) the optimization problem in ( [ qcs ] ) is not convex due to the @xmath5 objective function .",
    "therefore first we introduce a convex relaxation to ( [ qcs ] ) . first note that we can rewrite the ( [ qcs ] ) into a general quadratic form    @xmath24    since @xmath25 is a scalar using the trace operator we have    @xmath26    where we define @xmath27 and @xmath28 . by definition @xmath29",
    "is a hermitian matrix and it satisfies the constraints @xmath30 and @xmath31 .",
    "the optimization problem ( [ qcs ] ) can then be rewritten as    @xmath32    recasting the optimization problem to solve for the matrix @xmath29 in this form is known as matrix lifting @xcite , and it was shown that solving for @xmath29 one can obtain @xmath3 by the rank 1 decomposition of @xmath29 by the singular value decomposition ( svd ) .",
    "the problem ( [ qcs2 ] ) is still not convex , and the convex approximation is given by    @xmath33    here , the @xmath34 denotes the element - wise @xmath35-norm , or the sum of magnitudes of all elements in @xmath29 , and @xmath36 is a design parameter . the trace of @xmath29 is known to be the convex surrogate of the low rank constraint , and the @xmath34 is the convex surrogate of @xmath37 . the problem ( [ qbp ] ) is referred to as quadratic basis pursuit ( qbp ) and the remainder of this report will be based on solving this optimization problem .",
    "we provide a solution of an undetermined linear system . consider a linear problem @xmath38 in which @xmath39 is a a @xmath40 where @xmath41 is the number of measurement and @xmath42 , in which . here",
    "@xmath11 will have many solution but we require the sparsest solution .",
    "the formulation is @xmath43 the solution thus obtained will be the sparse solution for the linear equation @xmath38 but the above optimization problem will be a np hard problem .",
    "the method described above is very computationally expensive .",
    "eq(1 ) is a np - hard problem and can not be solved optimization algorithm hence we can construct other ways of obtaining sparse solution like following problems : @xmath44 or    @xmath45      consider a linear equation , @xmath46 now using equation ( 1 ) to obtain @xmath3 from @xmath47 that will be equal to or close to @xmath48 .",
    "the condition for the equality is derived using the restricted isometry property .",
    "further restricted isometry property of @xmath39 prevents any amplification of noise .",
    "a vector is said to be s - sparse if it has at most @xmath49 nonzero entries .",
    "consider now equation ( 1 ) , we will explain how the restricted isometry is applied to ( 1 ) to construct a constrain on @xmath39 in order to maintain the uniqueness of the solution . from ( 6 ) we know that @xmath46 , and we know that @xmath3 can be derived from @xmath47 using equation ( 1 ) , lets consider that @xmath50 is the solution for ( 1 ) along with @xmath48 .",
    "although the problem in ( 1 ) needs a non polynomial time to solve , in general it can be much more effectively solved using @xmath0 minimisation approach . let us review this approach in this approach in the section .",
    "the @xmath0 minimization problem is the following , @xmath44    since the @xmath0 minimization is a convex problem and can be converted easily into linear programming problem it can be easily solved .",
    "now we have to see under what condition does the solution of ( 1 ) is same as the solution of ( 11 ) .",
    "we can define the condition by too concept : 1 ) mutual coherence , 2 ) restricted isometric property . in this paper",
    "we will provide solution using restricted isometric property .      in this section",
    "some , theoretical results are presented on uniqueness and recoverability of qbp in the noiseless case .",
    "proofs are omitted in this report but can be found in @xcite . for convenience",
    "we first introduce a linear operator @xmath51    @xmath52    using ( [ b ] ) we can define the restricted isometry property .",
    "@xmath53 for all @xmath54 and @xmath55 .",
    "a linear operator @xmath56 is ( @xmath57)-rip if    @xmath53    for all @xmath54 and @xmath55 .    from @xcite",
    "it we have the following theorem for uniqueness ,    @xmath58 is a solution to ( [ qcs ] ) and if @xmath59 satisfies @xmath60 , @xmath61 , @xmath62 , @xmath63 and if @xmath56 is a @xmath64-rip with @xmath65 then the rank-1 decomposition of @xmath59 is equal to @xmath66^t$ ] .",
    "the next concern is on recoverability of the qbp algorithm , first we define the mutual coherence of a dictionary matrix @xmath67    for a matrix @xmath67 the mutual coherence @xmath68 is given by    @xmath69    also define a matrix @xmath70 be a matrix satisfying @xmath71 where @xmath72 .",
    "then the rank-1 decomposition of the solution of qbp is equal to @xmath73^t$ ] if @xmath74      in the previous section we proved condition for exact recovery for @xmath0 norm now we move further and prove the condition for stability .",
    "when we apply an undetermined linear transform @xmath75 to a signal @xmath48 there could be some error induced in the undetermined linear system or x0 could have noise in it .",
    "in such cases we need to guarantee that the x calculated from measurement y will not blow up in comparison to x0 for this there are two set of theorem defining the upper limit of error between original signal and the recovered signal .",
    "we consider that y is contaminated and incomplete observation @xmath76 , e is the error term .",
    "in this section some , theoretical results are presented on uniqueness and recoverability of qbp in the noiseless case .",
    "proofs are omitted in this report but can be found in @xcite . for convenience",
    "we first introduce a linear operator @xmath51    @xmath52    using ( [ b ] ) we can define the restricted isometry property .",
    "@xmath53 for all @xmath54 and @xmath55 .",
    "a linear operator @xmath56 is ( @xmath57)-rip if    @xmath53    for all @xmath54 and @xmath55 .    from @xcite",
    "it we have the following theorem for uniqueness ,    @xmath58 is a solution to ( [ qcs ] ) and if @xmath59 satisfies @xmath60 , @xmath61 , @xmath62 , @xmath63 and if @xmath56 is a @xmath64-rip with @xmath65 then the rank-1 decomposition of @xmath59 is equal to @xmath66^t$ ] .",
    "the next concern is on recoverability of the qbp algorithm , first we define the mutual coherence of a dictionary matrix @xmath67    for a matrix @xmath67 the mutual coherence @xmath68 is given by    @xmath69    also define a matrix @xmath70 be a matrix satisfying @xmath71 where @xmath72 .",
    "then the rank-1 decomposition of the solution of qbp is equal to @xmath73^t$ ] if @xmath74      in the previous section we proved condition for exact recovery for @xmath0 norm now we move further and prove the condition for stability .",
    "when we apply an undetermined linear transform @xmath75 to a signal @xmath48 there could be some error induced in the undetermined linear system or x0 could have noise in it .",
    "in such cases we need to guarantee that the x calculated from measurement y will not blow up in comparison to x0 for this there are two set of theorem defining the upper limit of error between original signal and the recovered signal .",
    "we consider that y is contaminated and incomplete observation @xmath76 , e is the error term .",
    "in this section we demonstrate the use of qbp . we draw @xmath77 , and @xmath78 from a complex gaussian random variable .",
    "we set @xmath79 and @xmath80 , @xmath81 , @xmath82 , and @xmath3 is real and shown in fig .",
    "1 . all scenarios are the noiseless case .",
    "2 shows the output of using the basis pursuit de - noising algorithm which takes a similar form as ( [ bp ] ) .",
    "the optimization problem that was solved instead of ( [ bp ] ) was ,    @xmath83    this optimization problem was solved rather than ( [ bp ] ) because it was found that solving ( [ bp ] ) often led to the result that the problem is infeasible .",
    "the regularization parameter @xmath36 was chosen to be 50 .",
    "as expected since basis pursuit algorithms can only account for the linear portion of the model it performs badly and the estimate is far from the truth .",
    ", estimate is far from the ground truth ]    fig .",
    "3 shows the result of the qbp with @xmath84 , the result is a perfect reconstruction and qbp can account for both the quadratic and the linear terms .",
    ", perfect reconstruction is obtained ]    fig .",
    "4 shows the result of the qbp without applying a regularization parameter or setting @xmath85 , this is the same as not enforcing the sparsity constraint .",
    "it is seen that without the sparsity constraint we recover a very dense estimate that and many solutions can exist .",
    ", dense estimate is obtained ]",
    "]     for recovery of x from y such that @xmath86 and hence no exact recovery ]     and the tube constrain , and conic constrain induced due to @xmath0 minimization ]     for successful recovery of x from y such that @xmath87 .",
    "the decoder used here is @xmath88 and x is minimized over optimisation problem ]     for successful recovery of x from y such that @xmath87 .",
    "the decoder used here is @xmath88 and x is minimized over optimisation problem ]     for successful recovery of x from y such that @xmath87 .",
    "the decoder used here is @xmath88 and x is minimized over optimisation problem ]     for successful recovery of x from y such that @xmath87 .",
    "the decoder used here is @xmath88 and x is minimized over optimisation problem ]",
    "this paper helped understand that geometrically description of a basic pursuit problem and i can use a similar theory for making a @xmath1 minimisation problem have a global minima .",
    "1 h. ohlsson , a. y. yang , r. dong , m. verhaegen , and s. sastry .",
    "quadratic basis pursuit .",
    "technical report arxiv:1301.7002 , university of california , berkeley , 2013 vu , phuoc , shuangqing wei , and benjamin carroll .",
    "`` effects of downsampling on statistics of discrete - time semi - markov processes . ''",
    "information sciences and systems ( ciss ) , 2015 49th annual conference on .",
    "ieee , 2015 .",
    "vu , phuoc doan huu , `` graphical models in characterizing the dependency relationship in wireless networks and social networks '' master thesis , louisiana state university and agricultural and mechanical college , 2014 .",
    "enhancing sparsity by reweighted l1 minimization by emmanuel j. candes , micheal b. walkin stephen p. boyd stable signal recovery from incomplete and inaccurate measurement sparsest solution of undetermined linear system via @xmath1 minimisation restricted isometry and its implication for compresses sensing by emmanuel j. candes exact reconstruction of sparse signal via non convex minimization"
  ],
  "abstract_text": [
    "<S> this work proposes a research problem of finding sparse solution of undetermined linear system with some applications . </S>",
    "<S> two approaches how to solve the compressive sensing problem : using @xmath0 approach , the @xmath1 approach with @xmath2 . </S>",
    "<S> compressive sensing algorithms are designed to cope with ambiguities introduced by under - sampling . </S>",
    "<S> we propose an algorithm for restricted isometry and how it can be used to constrain the undetermined linear system to eventually get a unique solution . </S>"
  ]
}