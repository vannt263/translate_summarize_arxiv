{
  "article_text": [
    "the rgb - d images have been provided in the real - world visual analysis systems thanks to the wide availability of affordable rgb - d sensors , _",
    "e.g. _ the microsoft kinect . compared with the primitive rgb",
    ", the rgb - d can bring remarkable performance improvement for various visual tasks due to the access to the depth information complementary to rgb  @xcite . actually , the depth has some profitable attributes for visual analysis , _",
    "e.g. _ being invariant to lighting or color variations , and providing geometrical cues for image structures  @xcite . for object detection , which is one of typical complex visual tasks , the acquisition of rgb - d images is applicable and beneficial .",
    "however , how to effectively utilize the provided depth information of rgb - d images is still an open question .    in recent years , convolutional neural network(cnn ) has achieved great success in computer vision and obtained the best performance in various visual tasks  @xcite .",
    "cnn is generally considered as an end - to - end feature extractor to automatically learn discriminative features from millions of input images  @xcite . in this paper",
    ", we also adopt cnn to extract rich features from the rgb - d images , _",
    "i.e. _ we are under the cnn model to investigate the exploitation of the depth information .        for the rgb - d object detection with cnn ,",
    "the key is how to elegantly coordinate the rgb with depth information in feature learning . in the previous literatures ,",
    "some intuitive methods have been proposed  @xcite .",
    "roughly , we can divide them into two broad categories according to the strategy the depth is treated .",
    "the first one is to straightforwardly add the depth map to cnn as the fourth channel along with the rgb  @xcite .",
    "that is , the depth is processed in the same way as the rgb , and they are together convolved for granted",
    ". however , it makes no semantic sense to directly merge the depth and color maps , since they contain disparate information .",
    "the second is to process the color and depth separately , and they are combined before being fed into the final classifier , where the extracted features are joint .",
    "specifically , two independent cnn networks are learned : one for rgb and one for depth  @xcite . as for the depth network",
    ", the input can be the original depth data or encoded data from the depth , _",
    "e.g. _ height above ground , and angle with gravity  @xcite .",
    "it has been empirically shown that the second way usually outperforms the first one . in this paper , we further investigate how to deeply exploit the depth information with aims of boosting the detection performance .    before introducing our proposed method , we review the primary mechanism of human visual systems .",
    "first , multiple visual properties are always used together to describe one object when people try to recognize it , _",
    "e.g. _ geometry contour , color , and contrast  @xcite . and it is usually thought that exploiting more properties is much helpful .",
    "second , the primary visual cortex ( @xmath0 ) , which consists of six functionally distinct layers and is highly specialized in pattern recognition  @xcite , abstracts different visual properties independently in the low layers and integrates in the relatively high layers . inspired by the working mechanism of @xmath0 area , we propose a novel method to deeply exploit the depth information for object detection . figure .",
    "[ fig_concatenate_features ] illustrates the main ideas of our method .",
    "firstly , various visual property maps are derived through analyzing the provided color and depth pairs .",
    "it is believed that more properties can contribute to the accurate description of the object and thus help boost the detection performance .",
    "specifically , the derived properties include the contour , height , and angle maps .",
    "secondly , we systematically investigate the method to fuse different visual properties under the cnn model , _",
    "i.e. _ how to represent a property , and from which layer the properties need to be fused together",
    ". the result of our analysis shows that the multiple properties should have complete and independent semantics in accordance with the human cognition , _",
    "e.g. _ rgb channels should be treated as a whole to represent the color property rather than separate them from each other , and it is better to fuse the different properties after they have been explicitly transformed into the high - level features .",
    "we evaluate the proposed method on the challenging dataset _",
    "nyud2 _ , and the experimental results show that our method outperforms all the baselines and achieves state - of - the - art performance .",
    "object detection  @xcite is to mark out and label the bounding boxes around the objects in an image . particularly , the adopted features are critical in determining the detection performance  @xcite",
    ". traditional methods , including the mrf  @xcite and dpm  @xcite , are all based on the hand - crafted features such as sift  @xcite and hog  @xcite . however , these features are difficult to adapt to the specific characteristics in a given task . and",
    "more recent works  @xcite have turned to the convolutional neural network ( cnn ) , which can learn discriminative features automatically from millions of rgb images .",
    "a typical cnn consists of a number of convolution and pooling layers optionally followed by the fully connected layers  @xcite , and is able to learn multi - level features ranging from edges to entire object  @xcite .    for object detection with cnn ,",
    "a proposed method is to build a sliding - window detector and then take the cnn for classification , which is usually applied on constrained object categories , _",
    "e.g. _ faces  @xcite and pedestrians  @xcite . and the object detection is formulated as a regression problem in  @xcite then the cnn is involved in predicting the localization and labels of the bounding boxes .",
    "the most remarkable work lies in  @xcite .",
    "the system called r - cnn first generates around 2000 category - independent region proposals for an input image and then computes features of each region with the cnn .",
    "a category - specific svm is appended to predict the label and score for each proposal .",
    "when it comes to the rgb - d object detection , @xcite proves that cnn can also be trained to learn depth features from the depth map .",
    "indeed , the extra depth exactly makes it easy to recognize human pose  @xcite , align 3d models  @xcite , and detect objects  @xcite . under the cnn model ,",
    "two typical methods for rgb - d object detection have been proposed about how to utilize the depth information  @xcite .",
    "one is to directly add the fourth channel for depth , and then equally convolve all channels in one network  @xcite .",
    "the other is to separately process the depth and color ( rgb ) using two independent networks  @xcite .",
    "obviously , these works mainly focus on the extraction of depth features , rather than considering thoroughly how to better coordinate the color and depth pairs for accurately describing the objects .",
    "a more related work is the one by gupta  @xcite , in which the depth data is encoded to three channels of horizontal disparity ( d ) , height above ground ( h ) , angle with gravity ( a ) , and then form the dha image into cnn to learn depth features , besides the rgb network . in our work",
    ", differently , the d , h , a are derived as new maps describing the object from different perspectives , and used to separately learn particular types of features encoding the multiple visual properties .",
    "more than that , we propose to use the depth combining with the rgb to derive new maps to provide extra information , _",
    "e.g. _ the geometry contour .",
    "furthermore , we systematically investigate the fusion way of different properties under the cnn model .",
    "we believe that our proposed detection framework and the investigation of feature fusion would inspire more advanced works to significantly improve the performance of object detection .",
    "intuitively , acquiring more information contents about the object can contribute to the more accurate recognition .",
    "meanwhile , for human being , the visual cortex of the brain is exactly to abstract various types of visual information from the input scenes in the inception phase  @xcite .",
    "inspired by such a principle , more informational sources are always desired in computer vision for high performance , _",
    "e.g. _ developing more powerful or precise sensors  @xcite . in practical applications , however , the accessible sources are rather limited because of the constraints on deployment and cost . in this paper",
    ", we attempt to mine as much useful information as possible by analyzing thoroughly the available data , for the sake of boosting the performance of rgb - d object detection , only the color image of single view and the corresponding depth map are originally provided .    to this end",
    ", we propose a novel two - stage feature learning framework for object detection on the rgb - d data , as shown in figure  [ fig_approach ] .",
    "specifically , we first derive more property maps from the input color and depth pairs .",
    "this procedure functionally emulates the abstracting mechanism of primary visual cortex .",
    "these properties describe the object from multiple views , and combine with the raw data to form a relatively complete set of feature maps .",
    "then we adopt the well - performed convolutional neural network ( cnn ) model to generate image representations from these feature maps .",
    "specially , the method to fuse different properties under the cnn model would be investigated systematically in this work . finally , we feed the joint representations into the svm for classification . in the proposed framework ,",
    "the property derivation and property fusion are especially important to determine the performance of object detection .",
    "it is unlikely for any of existing methods , including the cnn , to learn the various properties of the objects accurately from the same input scene as the human brain does , especially when only limited data is available .",
    "so it is essential to derive more property maps complementary to the original color and depth . for human visual system",
    ", the geometric properties usually play an important role in recognizing the object , shape and outline .",
    "fortunately , the availability of depth information makes it possible to compute the geometric properties with greater accuracy , compared to only using the plain color data . in this paper",
    "we mainly focus on the properties that can be derived from the raw color and depth data directly .",
    "specifically , the adopted properties include ultrametric contour map ( ucm ) , horizontal disparity ( d ) , height above ground ( h ) , and angle with gravity ( a ) .",
    "in particular , ucm representing the geometry contour is calculated using both the color and depth data , and the other three properties are only from the depth map .",
    "the horizontal disparity is an encoded version of the original depth map since it is more suitable for feature leaning with cnn  @xcite .",
    "along with the color image , the final property maps comprise of rgb , ucm , d , h , and a. now we elaborate on the computation of _ geometry contour _ , _ height above ground _ and _ angle with gravity_.      in philosophy , _ geometry contour _ tells directly the boundaries between the objects of interest and the background  @xcite . in object detection with cnn",
    ", however , the input data is only the images of rectangular area , which are produced by either sliding windows or region proposals  @xcite .",
    "that is , both the objects and context in bounding boxes are processed blindly .",
    "so explicitly providing the contour map would help cnn to mark out the objects more accurately . in this work ,",
    "we particularly adopt the ultrametric contour map ( ucm ) produced by the gpb - ucm algorithm  @xcite combining the rgb and depth data .",
    "_ height above ground _ indicates the position of the objects different categories  @xcite , a television is usually put on a table and a pillow is on the bed or sofa .",
    "the height map exactly represents such relations between the objects and thus is beneficial to distinguish the objects of interest . in this work",
    ", we produce the height map in an approximate way .",
    "specifically , the 3d point cloud is first gained by processing the depth map .",
    "then the height value of each pixel is roughly calculated by subtracting the lowest point ( with the minimum height ) within an image , which can be regarded as a surrogate for the supporting ground plane .      _",
    "angle with gravity _ gives a lot of cues about the image structures and what the real world looks like , the surface of a table or bed is usually horizontal while the wall or door is vertical .",
    "such information provides important clues to the shape of the objects , and thus would be helpful for the object detection . in this work ,",
    "we adopt the method in  @xcite to calculate the angle map .",
    "specifically , we first estimate the direction of gravity ( dog ) , denoted by @xmath1 , using the depth data . in practice , @xmath1 is updated in an iterative manner and initialized with the y - axis .",
    "for the current dog ( @xmath2 ) , the aligned set @xmath3 and orthogonal set @xmath4 are produced with a angle threshold @xmath5 , @xmath6 where @xmath7 represents the local surface normal , and @xmath8 denotes the angle between @xmath9 and @xmath2 .",
    "then a new @xmath10 is estimated by solving the following optimization problem , @xmath11 it means the estimated gravity is expected to be aligned to the normals in @xmath3 and orthogonal to the ones in @xmath4 .",
    "once the dog is obtained , we assign each pixel with the value of angle made by its local surface normal with @xmath10 .",
    "consequently , the angle map is formed with the same size as the original image .",
    "so far we have obtained multiple visual property maps to represent the rich information of the object , which include the color ( rgb ) , geometry contour ( ucm ) , horizontal disparity ( d ) , height above ground ( h ) , and angle with gravity ( a ) . for object detection , an unified image representation",
    "is always needed for the final classification that integrates the useful information from all properties . for each property represented by one map ( except the color with three channels of rgb )",
    ", the sophisticated learning model can be directly applied to produce the corresponding feature , cnn . but how to coordinate multiple different properties in feature learning is not fully explored yet .",
    "for example , an intuitive method is to straightforwardly input all property maps together into cnn with multiple channels  @xcite , but the resulting performance may be unsatisfying .",
    "thus the key of generating the joint discriminative image representations is to determine an integration method , which can better fuse the multiple properties .    in this section",
    ", we attempt to deeply investigate the ways to fuse the different properties under the cnn model .",
    "particularly , part of property maps obtained in the previous stage would be directly adopted when the numerical analysis is needed .",
    "cnn can naturally learn the hierarchical features by different layers  @xcite , in which the input map is finally transformed into a feature vector through a series of operations represented by convolution and pooling  @xcite . when multiple property maps of the same scene are fed into cnn",
    ", we can view these maps as the lowest level features .",
    "then the property fusion is essentially to determine that , from which layer different property features should be arithmetically calculated together .",
    "there are two extreme cases for property fusion .",
    "one is to directly increase the number of channels in the input layer of cnn and accept all property maps equivalently .",
    "the other is to separately learn different property features with independent networks and concatenate them before passing into the final classifier . in this work ,",
    "both cases are denoted by _ input _ and _ final _ respectively for convenience . of course",
    ", we can also fuse different properties from certain middle layer , which actually means that different property features are learned independently before that layer and then drawn from the synthesis of properties in the subsequent layers .",
    "we first analyze the underlying reasons for the difference of fusing the properties in multiple layers , and the classical alexnet  @xcite is adopted here .",
    "figure  [ fig_fused ] provides an exemplar of network architecture for fusion , where the properties are fused from the _ fc6 _ layer , and the three property maps of d , h and a are used without loss of generality . for a specific fusion network , fusing from _ fc6 _ here , the learned features in the previous layer are straightly stacked into multiple feature maps , and then these maps are processed without distinction in the subsequent layers .",
    "it can be observed that the inter - layer connections between different property features are added after the first fused layer ( _ fc6 _ ) , which formally increases the network parameters .",
    "however , it is still not clear that how these connections impact on the final representations and also on the detection performance .",
    "the typical cnn model has three major functional components , _ convolution _ , _ rectified linear units(relu ) _ , and _ max - pooling_. in particular , the _ convolution _ belongs to the linear operators and thus theoretically has no great impact on fusing from different layers .",
    "in contrast , both the _ relu _ and _ max - pooling _ are of high nonlinearity .",
    "so it is naturally supposed that different fusion schemes are through the _ relu _ and _ max - pooling _ to impact the learning results .",
    "we conduct an evaluation experiment in order to show the effect of three cnn components more intuitively . here",
    "the dataset of _ nyud2 _",
    "@xcite is used , and the performance is evaluated on the _ val _ set ( see section .",
    "[ sec_experiments ] for the details of dataset and model training ) .",
    "it is noticeable that we measure the impact of functional components by comparing the resulting performance of the two extreme fusion schemes ( _ input _ and _ final _ ) .",
    "in addition , the pca is conducted on the joint image representations in _ final _ scheme to keep the same dimension of classification features .",
    "the results are shown in the table  [ tab_nyud2_fuse_analysis ] .",
    ".*the performance on nyud2 _ val _ set to analysis the effect of _ relu _ and _ max - pooling _ on fusion*. for fusion schemes of _ input _ and _ final _ , the architecture of cnn for feature learning are respectively _ full _ , _ conv+pool _ , _ conv _ , _ conv+relu_. the input are dha image and d+h+a maps .",
    "the results are all mean @xmath12 in percentage .",
    "see section .",
    "[ sec_fusion_analysis ] . [ cols=\"^ \" , ]      when it comes to the performance on _ test _ set , we compare our final system with the existing remarkable methods : rgbd dpm , rgb+d cnn and rgb+dha cnn . the result is shown in table  [ tab_nyud2_test ] .",
    "the row 1 shows the result of rgbd dpm from  @xcite , which is the state - of - art method before the revival of cnn . and the row 2 and row 3 are the results of rgb+d cnn and rgb+dha cnn , which agree with  @xcite ( with no data augmentation ) .",
    "then the row 4 gives the mean @xmath12 of 40.18% achieved by our system when finetuning the cnns on the @xmath13 set .",
    "we improve the performance by 4.04% over the best baseline ( 36.14% to 40.18% , 11.18% relative ) .",
    "then we finetune the network again on the _ trainval _ set .",
    "thanks to more training data , the trained cnn gains higher generalization power .",
    "we get the performance shown in row 5 to 7 .",
    "our system s result ( row 7 ) is still much better than the baselines ( row 5 and row 6 ) .",
    "our final system improves the best mean @xmath12 on the _ test _ set of _ nyud2 _ from 38.94% to 41.85% .",
    "we have noticed that  @xcite reported competitive performance with us by adding region features besides the bounding boxes .",
    "they expanded the system in  @xcite in a different way from us .",
    "certainly we can also add regions features in our system .",
    "however , that s not the point of this paper",
    ". we have already gotten state - of - the - art performance even without region features .",
    "in this paper , we addressed the problem of deeply exploiting the deep information for rgb - d object detection , and proposed a novel framework . specifically , we first derived more properties by mining the provided rgb and depth data .",
    "particularly , several properties that could be directly derived from the color / depth or pairs were adopted here , which included the geometry contour , horizontal disparity , height above ground , and angle with gravity .",
    "then we systematically investigated the fusion schemes of different properties under the cnn model . by the means of analysis and evaluation ,",
    "it was recommended that the features encoding the different object properties should be learned independently and fused at the highest level , not joint until passing into the classifier .",
    "finally , we experimentally verified the effectiveness of the proposed method , which indeed achieved state - of - the - art performance on _ nyud2_. and it was gained with no data augmentation or region features . besides , we only considered the properties that could be computed in relatively straightforward methods . exploring more useful properties",
    "is one of our future works , , equipping more powerful sensors or developing more advanced algorithms for property derivation .",
    "this work is supported partially by the national high technology research and development program of china ( 863 program , 2014aa06a503 ) , national natural science foundation of china under grant 61233003 and 61203256 , natural science foundation of anhui province ( 1408085mf112 ) , and the fundamental research funds for the central universities ( wk3500000002 and wk3490000001 ) .",
    "and we express heartfelt thanks for the generous donation of tesla gpu k40 m from the nvidia corporation ."
  ],
  "abstract_text": [
    "<S> this paper addresses the issue on how to more effectively coordinate the depth with rgb aiming at boosting the performance of rgb - d object detection . particularly , we investigate two primary ideas under the cnn model : property derivation and property fusion . </S>",
    "<S> firstly , we propose that the depth can be utilized not only as a type of extra information besides rgb but also to derive more visual properties for comprehensively describing the objects of interest . </S>",
    "<S> so a two - stage learning framework consisting of property derivation and fusion is constructed . here </S>",
    "<S> the properties can be derived either from the provided color / depth or their pairs ( _ e.g. _ the geometry contour adopted in this paper ) . </S>",
    "<S> secondly , we explore the fusion method of different properties in feature learning , which is boiled down to , under the cnn model , from which layer the properties should be fused together . </S>",
    "<S> the analysis shows that different semantic properties should be learned separately and combined before passing into the final classifier . </S>",
    "<S> actually , such a detection way is in accordance with the mechanism of the primary neural cortex ( @xmath0 ) in brain . </S>",
    "<S> we experimentally evaluate the proposed method on the challenging dataset , and have achieved state - of - the - art performance . </S>"
  ]
}