{
  "article_text": [
    "channel polarization gives rise to elegant and provably optimal channel codes , called _ polar codes _",
    "@xcite , whose decoding complexity under successive cancellation ( sc ) decoding is @xmath0 , where @xmath1 is the blocklength of the code . in implementations of channel decoders",
    "it is often desirable to trade performance for complexity in order to meet system requirements at minimal cost .",
    "these trade - off decisions can be offline , i.e. , taken during the design phase of the system , or online , i.e. , taken by the system during its operation . a trivial way to vary the decoding complexity",
    "is to alter the blocklength of the code .",
    "this is usually an offline decision , although some recent communications standards ( e.g. , ieee 802.11n @xcite ) require the support of codes of various lengths . unfortunately , using this method , polar codes do not offer a fine trade - off granularity because their blocklength is constrained to powers of two when using the simple @xmath2 polarizing matrix introduced by arikan .",
    "thus , any complexity reduction may lead to a large loss in performance .",
    "moreover , due to its successive nature , the sc decoding algorithm is not amenable to online complexity tuning .",
    "other codes which are used in modern systems , such as ldpc  @xcite and turbo codes @xcite , which are usually decoded using iterative decoding algorithms , can be tuned online by varying the number of performed iterations , according to e.g. , the channel conditions .",
    "fortunately , a simple observation allows us to trade decoding complexity for performance for sc decoding in small steps , both offline and online , without the need to change the blocklength by altering the set of channels which are used to transmit information .      in this work",
    ", we populate the complexity - performance trade - off curve for sc decoding by formulating the frozen channel selection step of polar code construction as an optimization problem .",
    "this is achieved by reformulating the original problem of polar code construction with the objective to minimize the complexity while respecting quality constraints that represent the various dynamically changing operating conditions , or the offline system constraints .",
    "the proposed reformulation enables complexity - performance trade - offs which where not evident before .",
    "finally , we also present a low complexity greedy algorithm which seems to approximate the original problem reasonably well .",
    "following the notation of @xcite , we use @xmath3 to denote a row vector @xmath4 and @xmath5 to denote the subvector @xmath6 . if @xmath7 , then the subvector @xmath5 is empty .",
    "we use @xmath8 to denote the binary logarithm .",
    "let @xmath9 denote a binary input discrete and memoryless channel with input @xmath10 , output @xmath11 , and transition probabilities @xmath12 .",
    "a polar code is constructed by applying a @xmath2 _ channel combining _ transformation recursively on @xmath9 for @xmath13 times , followed by a _ channel splitting _",
    "step  @xcite .",
    "this results in a set of @xmath14 channels , denoted by @xmath15 . in principle , it is possible to compute the mutual information values @xmath16 . in practice ,",
    "finding an analytical expression turns out to be a very hard problem , except for the case of the binary erasure channel ( bec ) , where an exact recursive calculation is possible @xcite .",
    "methods for approximating the mutual information values in more general cases are described in @xcite .",
    "the construction of a polar code is completed by choosing the good channels as _ non - frozen _ channels which carry information bits , while _ freezing _ the remaining channels to some known values @xmath17 .",
    "the set of frozen channel indices is denoted by @xmath18 and the set of non - frozen channel indices is denoted by @xmath19 .      in the sc decoding algorithm",
    "@xcite , decoding starts by computing an estimate of @xmath20 , denoted by @xmath21 , based only on @xmath22 .",
    "subsequently , @xmath23 is estimated using @xmath24 etc .",
    "decisions are taken according to @xmath25 the channel likelihoods @xmath26 are combined through the stages of a decoding graph in order to calculate @xmath27  @xcite .",
    "the decoding graph contains @xmath28 nodes .",
    "if intermediate results are stored , then each node has to be activated only once during decoding .",
    "thus , we need exactly @xmath28 node - computations per codeword .      complexity reduction can be achieved by pruning nodes from the decoding graph whose descendant nodes at stage @xmath29 all correspond to frozen channels , since these nodes calculate likelihoods that will never actually be used by the decoding rule  @xcite .",
    "for example , consider a rate-1/2 code corresponding to the decoding graph of fig .",
    "[ fig : grapha ] and let @xmath30 and @xmath31 . in this case ,",
    "( [ eq : scdec ] ) does not require the likelihoods @xmath32 and @xmath33 to estimate @xmath20 and @xmath34 , respectively .",
    "so , the corresponding node - computations at stage @xmath29 can be pruned .",
    "however , the computations at stage @xmath35 can not be pruned , since their results are required to estimate @xmath23 and @xmath36 .",
    "if , instead , @xmath37 were chosen as frozen , then the computations for @xmath20 and @xmath23 at stage 0 , as well as the two preceding computations at stage @xmath35 could be pruned . in the first example we can prune two node - computations , while in the second example we can prune four node - computations . however , in the second case the error rate performance of the code will be worse since we do not allow the two best channels to carry information .",
    "the total number of computations that can be saved by pruning the decoding graph , denoted by @xmath38 , is used as a complexity metric . let the blocklength @xmath1 and the rate @xmath39 be fixed and let the mutual information values of the @xmath1 channels be denoted by @xmath40 .",
    "we use the sum mutual information of the set of non - frozen channels as a performance metric , i.e. , @xmath41 note that the polar code construction proposed in  @xcite maximizes this metric under the constraint @xmath42 and let @xmath43 denote this maximum , i.e. , @xmath44 since @xmath45 the maximization amounts to selecting the channel indices with the @xmath46 largest @xmath47 values .      from a complexity perspective , it is favorable to form clusters of @xmath48 , frozen channels in order to maximize pruning . in this section ,",
    "we describe an optimization problem which constructs a polar code of rate @xmath49 , in a way that maximizes @xmath38 while ensuring that @xmath50 is larger than a predefined performance constraint @xmath51 . to this end",
    ", the indices of the @xmath1 channels are grouped into clusters of @xmath52 consecutive channels as illustrated in fig .",
    "[ fig : grapha ] , where the illustration of the groups has been spread across the stages of the data dependency graph to reduce congestion .",
    "let the set of all the groups be denoted by @xmath53 .",
    "we have @xmath54     with channel groups .",
    "an optimization variable @xmath55 is associated with each group @xmath56 .",
    "setting @xmath57 corresponds to freezing all channels in @xmath56.,scaledwidth=30.0% ]    , i.e. , @xmath58 , and their corresponding optimization variables .",
    "if @xmath59 , then @xmath60 has to be enforced for all @xmath61.,scaledwidth=30.0% ]    we associate each of the groups @xmath62 with a binary optimization variable @xmath63 .",
    "the assignment @xmath57 means that all channels contained in group @xmath64 are frozen .",
    "each group also has a cost , denoted by @xmath65 .",
    "this cost is equal to the number of channel indices that are contained in @xmath56 , i.e. , @xmath66 , and it reflects the rate loss incurred by setting @xmath67 .",
    "this leads to the _ rate constraint _ @xmath68 observe that , if in the example of fig .",
    "[ fig : grapha ] , say , @xmath69 , then the cost @xmath70 is paid",
    ". however , due to the tree structure of the groups , @xmath70 includes the costs for freezing the channels in groups @xmath71 to @xmath72 , so , when @xmath67 for any non - leaf group , @xmath60 has to be enforced for all the descendants of this group in order not to count any costs more than once .",
    "let the descendants of group @xmath62 be denoted by @xmath73 .",
    "an example is illustrated in fig .",
    "[ fig : graphb ] .",
    "let @xmath74 .",
    "since @xmath75 , the _ mutual exclusiveness _ constraint can be formalized as @xmath76 moreover , we have @xmath77 from ( [ eqn : varnum ] ) and ( [ eqn : mutexnum ] ) , it can be seen that the number of variables grows linearly with the code length and the number of constraints in ( [ eqn : mutex ] ) grows as @xmath28 .",
    "each group @xmath62 has an associated gain in the number of computations , denoted by @xmath78 .",
    "this gain is the number of computations that is saved via pruning if all the channels in this group are frozen .",
    "let @xmath79 denote the stage to which group @xmath62 corresponds .",
    "for example , in fig .",
    "[ fig : grapha ] , group @xmath80 corresponds to stage @xmath35 .",
    "then , we have @xmath81 due to ( [ eqn : mutex ] ) , no complexity gain is counted more than once .",
    "finally , freezing the channels in group @xmath62 results in a loss in total mutual information , denoted by @xmath82 , with @xmath83 again , due to ( [ eqn : mutex ] ) , no loss is counted more than once .",
    "a _ performance constraint _",
    "@xmath84 is enforced , which can equivalently be written as @xmath85 an optimization problem which maximizes the complexity gain , while ensuring that the resulting code has rate @xmath49 and satisfies the performance constraint , can be formulated  as @xmath86 the above problem is a binary integer linear programming formulation of a multidimensional 01 knapsack problem  @xcite , which is known to be np - hard . if @xmath87 is chosen carefully so that @xmath88 , then ( [ prob : init ] ) is always feasible . moreover , for @xmath89 , the optimization problem reduces to the construction proposed by arikan , while @xmath90 results in a construction that maximizes the number of saved computations while completely disregarding performance . by varying @xmath87 between these two extremal values ,",
    "various complexity - performance trade - offs can be achieved .      ,",
    "@xmath91 and transmission over a bec@xmath92.,scaledwidth=40.0% ]    even though is np - hard , relatively small instances can still be solved by using standard branch - and - bound methods . for simplicity in calculating the mutual information values @xmath93 , we present results only for the bec@xmath94 , where @xmath95 denotes the erasure probability .",
    "however , the proposed approach can be used for any other channel and input distribution , provided that @xmath93 , are available . moreover ,",
    "given @xmath93 , the complexity of and of the greedy algorithm presented in section  [ sec : greedy ] does not depend on the type of channel .",
    "we assume that the capacity achieving input distribution is used , so that @xmath96 . in fig .",
    "[ fig : pareto ] , we present the solutions of ( [ prob : init ] ) for transmission over a bec@xmath92 with a polar code of rate @xmath97 for @xmath98 , which are obtained by solving the problem for various @xmath99 .",
    "we use the complexity in operations per bit on the vertical axis and the average mutual information on the horizontal axis .",
    "the former can be easily obtained from any solution @xmath100 as @xmath101 , while the latter is equal to @xmath102 .",
    "in order to solve for practically relevant blocklengths , like @xmath103 , in reasonable time , we present a greedy algorithm that takes advantage of the structure of the problem to provide useful solutions with negligible running time .",
    "our greedy algorithm consists of three steps , namely the _ greedy maximization _ step , the _ feasibility _ step , and the _ post - processing _ step . in the first step ,",
    "the goal is to greedily maximize the objective function while satisfying all inequality constraints .",
    "the second step ensures that the equality constraint is also satisfied , while the last step finalizes and improves the solution .",
    "recall that @xmath104 is the number of bits that need to be frozen .",
    "let @xmath105 denote the @xmath106 bit right - msb binary representation of @xmath107 and let @xmath108 denote the @xmath109-th bit of @xmath105 .",
    "the greedy maximization step is inspired by the following observation .",
    "[ prop : optimal ] if there were no performance constraint present in ( [ prob : init ] ) , the problem could be solved exactly as follows",
    ".    1 .   set @xmath110 and @xmath111 .",
    "2 .   if @xmath112 , then set @xmath67 for one @xmath113 , denoted by @xmath114 , and set @xmath60 for all remaining @xmath113 . remove all @xmath115 from the problem .",
    "3 .   set @xmath116 and go to 2 . until @xmath117 .    by eliminating all @xmath115 from the problem at step 2 , we guarantee that the mutual exclusiveness constraint is not violated . moreover ,",
    "stage @xmath118 contains two groups , of which only one can be frozen , and for each group in stage @xmath109 there are two groups in stage @xmath119 , so that step 2 can always be executed .",
    "we now show that any optimal solution must freeze at most one group per stage .",
    "suppose that , for some solution , more than one groups were frozen in some stage @xmath109 .",
    "then , it is possible to replace any two frozen groups at stage @xmath109 with some frozen group at stage @xmath120 without violating any constraint .",
    "based on , for the complexity gains we have @xmath121 so this would strictly increase the objective function , meaning that the original solution could not have been optimal . since all groups in stage @xmath109 contain @xmath122 bits and the binary representation of @xmath107 is unique",
    ", it follows that the only way to freeze exactly @xmath107 channels by freezing at most one group per stage , thus satisfying the rate constraint , is to freeze the groups according to the pattern dictated by @xmath105 .",
    "the greedy maximization step is different than the procedure of proposition [ prop : optimal ] in that it makes sure that the performance constraint is satisfied . in the following procedure , @xmath105 is again initialized to @xmath106 bit right - msb binary representation of @xmath107 , but @xmath123 .    1 .   set @xmath110 and @xmath111 .",
    "2 .   if @xmath124 , then try the following . *",
    "find the @xmath113 with the smallest @xmath82 in stage @xmath109 and set @xmath67 .",
    "* if @xmath125 , then remove all @xmath115 from the problem , set @xmath126 , and go to 2 . * else , set @xmath127 , set @xmath60 , and go to 3 .",
    "set @xmath116 and go to 2 . until @xmath117 .    at step 2.3 .",
    ", we set @xmath127 because for each group that could not be frozen at stage @xmath109 due to the performance constraint , we need to freeze two groups at stage @xmath128 in order to ( hopefully ) satisfy the rate constraint .",
    "unfortunately , there is no longer a guarantee that the procedure will be able to freeze exactly @xmath107 bits as required to satisfy the rate constraint .",
    "however , the mutual exclusiveness and performance constraints are guaranteed to be met .    ) and of the greedy algorithm for @xmath129 , @xmath91 and transmission over a bec@xmath92.,scaledwidth=42.0% ]      the second step of the algorithm sacrifices the objective function in a systematic step - by - step fashion until the solution is feasible , i.e. , until the rate constraint is satisfied .",
    "let @xmath130 denote the number of additional bits that need to be frozen after the greedy maximization step is finished so that the rate constraint is satisfied , i.e. , @xmath131 .    if @xmath132 then the feasibility step starts greedily unfreezing frozen groups to free up mutual information .",
    "more and more groups are unfrozen until the total number of unfrozen groups that can be frozen at stage @xmath29 is equal to @xmath130 plus the number of variables in the groups that were unfrozen so far . since during this step",
    "only groups at stage @xmath29 are refrozen which provide the smallest complexity gain , no direct effort is made to minimize the loss in the objective function .",
    "the feasibility step starts at stage @xmath133 , because by unfreezing a group in this stage it is possible to satisfy the rate constraint in a single step , thus making an indirect effort to minimize the objective function loss .",
    "subsequently , all stages up to @xmath134 are visited , and the procedure continues with stages @xmath29 to @xmath135 , thus visiting all stages , if required . if @xmath88 , the feasibility step is guaranteed to find a feasible solution .",
    "the post - processing step identifies pairs of consecutive frozen groups at each stage @xmath109 and replaces them with their parent group at stage @xmath120 , which improves the objective function without violating any of the constraints .",
    "the solutions obtained by solving ( [ prob : init ] ) exactly as well as by using the greedy algorithm for various constraints and blocklength up to @xmath136 and for @xmath137 are compared in fig .",
    "[ fig : fullvsgreedy ] .",
    "the greedy algorithm is able to find most of the optimal solutions for small instances of the problem .",
    "the solutions found by the greedy algorithm are presented in fig .",
    "[ fig : greedy ] for various blocklengths and for @xmath137 . for @xmath138 the average running time of the greedy algorithm is less than @xmath139 seconds , which is negligible given that the optimization is carried out offline .",
    "we observe that the rightmost part of the curve is relatively steep , thus providing favorable trade - offs . for a fixed blocklength ,",
    "the codes corresponding to some solution points can be chosen and stored in order to provide the system with online performance - complexity trade - offs . moreover , during the design phase one can choose the solution with the largest performance among all blocklengths that satisfies a given complexity constraint .",
    ", @xmath140 over a bec@xmath92 . the circled codes for @xmath141 are simulated in fig .",
    "[ fig : degradation].,scaledwidth=42.0% ]",
    "our choice of performance metric requires some intuitive justification .",
    "let @xmath142 denote the bhattacharyya parameter of a channel @xmath9 and let @xmath143 .",
    "it is known that @xmath144 is an upper bound on the probability of block error @xcite .",
    "it was shown in @xcite that , for the bec , it is also a lower bound .",
    "moreover , for the bec we have @xmath145 , so by maximizing @xmath146 one can minimize the probability of block error .",
    "similarly , by placing a constraint on @xmath146 , we are implicitly placing a constraint on @xmath147 , which is directly related with the probability of block error .",
    "so , for the case of the bec , the metric that we use has an explicit relation with the probability of block error . for more general channels ,",
    "one intuitively expects there to be at least an implicit relation between the two quantities .",
    "ideally , one would like to use the probability of block error itself as a metric , but , to the best of our knowledge , this can not be described analytically as a function of @xmath19 , and especially not in a linear way which enables a simple formulation of the optimization problem .    moreover , in principle",
    ", it is possible that a solution of contains a very bad channel in @xmath19 .",
    "this would lead to a catastrophic failure of the code , resulting in a block error rate ( bler ) close to 1 .",
    "this problem can be circumvented by adding the following additional constraints to @xmath148 where @xmath149 if @xmath62 contains a channel with @xmath150 , where @xmath151 is chosen as the lowest acceptable mutual information of the channels used for the information bits , and @xmath152 otherwise .",
    "however , we have observed in simulations that the useful codes ( a code is said to be _ useful _ if it lies on the pareto frontier of the set of obtained solutions ) have performance which degrades gracefully with decreasing values of the performance metric .",
    "an example of this behavior for @xmath153 can be seen in fig .",
    "[ fig : degradation ] , where code 1 corresponds to the construction in @xcite , while codes 2 to 8 provide different performance - complexity trade - offs ( annotated in fig .",
    "[ fig : greedy ] ) .",
    "in this paper , we showed how to achieve fine - grained trade - offs between complexity and performance of sc decoding of polar codes by reformulating the frozen channel selection step of the standard polar code construction procedure as a 0 - 1 knapsack problem .",
    "moreover , we described a low - complexity greedy algorithm , which is tailored to fit our specific knapsack problem instance .",
    "the greedy algorithm was used to approximately solve the optimization problem in order to construct polar codes of blocklength up to @xmath154 .",
    "the authors would like to thank the anonymous reviewers for their helpful comments .",
    "this work was kindly supported by the swiss nsf under project i d 200021_149447 and by the european union under marie curie grant 304186 .",
    "11 e.  arikan , `` channel polarization : a method for constructing capacity - achieving codes for symmetric binary - input memoryless channels , '' _ ieee trans .",
    "inf . theory _ ,",
    "55 , no .  7 , pp .",
    "30513073 , july 2009 ."
  ],
  "abstract_text": [
    "<S> polar codes are one of the most recent advancements in coding theory and they have attracted significant interest . while they are provably capacity achieving over various channels , they have seen limited practical applications . unfortunately , the successive nature of successive cancellation based decoders hinders fine - grained adaptation of the decoding complexity to design constraints and operating conditions . in this paper </S>",
    "<S> , we propose a systematic method for enabling complexity - performance trade - offs by constructing polar codes based on an optimization problem which minimizes the complexity under a suitably defined mutual information based performance constraint . </S>",
    "<S> moreover , a low - complexity greedy algorithm is proposed in order to solve the optimization problem efficiently for very large code lengths . </S>"
  ]
}