{
  "article_text": [
    "quantum random walks exhibit features that can be significantly different to their classical counterparts . as a famous example",
    ", the hitting time , which is a fundamental quantity in the theory of random walks , can be exponentially reduced if so - called coined quantum walks are employed @xcite . however , such strong results are only known to hold for a few special classes of undirected random walks .",
    "alternative approaches to quantization of random walks over more general graphs , in which case we talk about markov chains ( mcs ) , most often aim at more modest polynomial improvements . using the so - called szegedy - type quantum walks , a generic quadratic improvement in hitting times @xcite",
    "was shown for all time - reversible mcs .",
    "the generality of the setting , while preventing superpolynomial speedups , compensates with its greater applicability .",
    "early on , related approaches have e.g. provided a basis for a quadratic improvement of algorithms for element distinctness @xcite , element detection @xcite and the triangle problem @xcite .",
    "setting aside hitting times , quantum walks have been investigated for their capacity to speed up mixing processes , that is , the task of preparing stationary distributions of a given mc .",
    "this task constitutes another fundamental problem of markov chain theory .",
    "efficient mixing is , for instance , important in the context of markov chain monte carlo ( mcmc ) algorithms .",
    "mcmc methods are , for instance , central to many algorithmic solutions to hard combinatorial problems and problems stemming from statistical physics @xcite . quantum improvements in this context have already been reported @xcite . beyond mcmc - related applications ,",
    "efficient mixing also extends the applicability of the aforementioned quantum hitting time speedups , as the preparation of the relevant stationary distributions is sometimes assumed to be an affordable primitive @xcite .",
    "however , despite the considerable interest , the quantum speedup of mixing processes has only been shown for certain classes of mcs @xcite , and it is an open conjecture that a generic quadratic speedup for mixing can be obtained for all time - reversible mcs @xcite . for a recent review on quantum walks",
    "see _ e.g. _ @xcite .    in this work",
    "we consider the problem of sequentially generating stationary distributions of sequences of slowly evolving markov chains , illustrated in fig [ fig1]b .",
    "[ fig1 ]   we produce a sample from the distribution @xmath5 which need not be exactly the stationary distribution of the markov chain mc@xmath6 .",
    "this is used as the initial distribution for the next markov chain .",
    "however , the last sample is distributed ( approximately ) according to @xmath7 which is the stationary distribution of mc@xmath8 and the target distribution .",
    "part b ) of the figure represents our setting : the sequential sampling from a slowly evolving sequence of markov chains . at each time - step @xmath9",
    "we are required to produce an element sampled from @xmath10 which is a good approximation of the stationary distribution of the markov chain mc@xmath6 .",
    "the sequence need not terminate , or it may be arbitrarily long .",
    ", title=\"fig:\",scaledwidth=76.0% ]    this setting is similar to the scenario of simulated annealing , in which case quantum improvements have already been achieved @xcite .",
    "there is , however , a key distinction between the annealing settings and ours : in annealing settings , the target is to produce a sample from the stationary distribution of the final chain only , whereas the intermediary chains have only an accessory role .",
    "in contrast , in our case , we must produce samples sequentially , for each chain in the sequence ( and , indeed , the sequence can in principle be infinite ) .",
    "the motivation for this problem stems from recent work in artificial intelligence ( ai ) @xcite , by the authors and other collaborators , but may have broader applicability .",
    "we will comment on this further later .    for our problem , we first identify two classes of markov chains , characterized by the distance of their stationary distribution from the uniform distribution .",
    "these two classes cover all discrete time - reversible markov chains , and for both classes mixing can be achieved in time @xmath4 , neglecting logarithmic terms .",
    "the methods used for mixing differ for the two classes , and the second technique ( utilized when the target distribution is , in a sense we specify later , _ far _ from the uniform distribution ) requires additional information about the underlying markov chain .",
    "in particular , it requires a small number of samples from the very underlying stationary distribution we seek to construct .",
    "while this additional information can not be straightforwardly recovered given just one mc , we show that in the context of slowly evolving markov chains , it can .",
    "the structure of this paper is as follows . in section [ sect2 ]",
    "we present related work and clarify the distinction between our and previously studied settings . following this , in section [ sect3 ] we cover the preliminaries and introduce all the ( sub)-protocols required for our main result .",
    "finally , in section [ sect4 ] we give our main result , and finish off with a brief discussion in section [ sect5 ] .",
    "the setting of slowly evolving mcs is especially relevant in the pervasive simulated annealing methods . in mcmc methods in general ,",
    "the task is to produce a sample from the stationary distribution of some target mc @xmath11 . for concreteness",
    ", this can be the gibbs distribution @xmath12 of a physical system at a target ( low ) temperature @xmath13 .",
    "markov chains which have @xmath12 as the stationary distribution are easy to construct , but , in general , the _ mixing time _ required to achieve stationarity is prohibitive .",
    "better results are often achieved by using simulated annealing methods , in which one constructs a sequence of mcs @xmath14 , which , for instance , encode the gibbs distributions at gradually decreasing temperatures .",
    "the choice of the temperature - dependent sequence is often referred to as the annealing schedule .",
    "the fact that the temperatures decrease gradually ensures that the stationary distributions of neighboring chains are close , so the sequence is slowly evolving . as the temperature corresponding to @xmath15 is high , the stationary distribution of @xmath15 is essentially uniform , and @xmath15 mixes rapidly ( effectively in one step ) .",
    "simulated annealing is then realized by sequentially applying the chains @xmath15 to @xmath16 to the initial distribution . in this process ,",
    "no individual chain fully mixes , but nonetheless , often the reached distribution approximates the target distribution well , even when the number of steps @xmath17 is substantially smaller than the mixing time of @xmath11 itself .    quantum variants ( and generalizations ) of the classical annealing approach have been previously addressed in , for instance , @xcite .",
    "there , the so - called szegedy walk operators are employed instead of the classical transition matrices @xmath16 .",
    "the approaches differ , with one commonality : at each time - step , the quantum state obtained from the previous step is used in the subsequent step , and thus quantum coherence is maintained throughout the steps of the protocols .",
    "our setting is inspired by a recent result by the authors and other collaborators where szegedy - type quantum walks are used in problems of ai @xcite .",
    "in the so - called reflective projective simulation ( rps ) model of artificial intelligence , at each time - step @xmath17 , the target action of an rps agent is encoded in the stationary distribution of a mc @xmath16 which is gradually modified as the agent learns through the interaction with the environment .",
    "the agent s action , which is chosen by sampling from this distribution , has to be output at each time - step .",
    "for more details on the projective simulation model for ai , we refer the reader to @xcite .",
    "viewed abstractly , in this setting we have an , in principle , infinite sequence ( a stream ) of mcs @xmath18 which is slowly evolving . at each time - step @xmath17",
    ", we are required to produce an element sampled according to the stationary distribution of @xmath16 .",
    "in contrast , in simulated annealing , the sequence is finite , and we are only required to produce a sampled element distributed according to the stationary distribution of the _ last _ mc . the quantum approaches to simulated annealing can not be straightforwardly applied to our setting , as this would require measuring the quantum state at each step .",
    "this would prevent all the quantum speedup .",
    "alternatively , the sequence would have to be re - run from the beginning at each time - step , which is not acceptable as the sequence can be of arbitrary length .",
    "the differences between the two settings are illustrated in figs .",
    "[ fig1]a and [ fig1]b .",
    "it is worthwhile noting that even the classical simulated annealing methods do not immediately help with our task . in classical simulated annealing , at each time step @xmath17 we are dealing with a classical sample ( corresponding to step @xmath17 ) which can be copied .",
    "however , one can not output the classical sample at time - step @xmath17 , and use it as a seed for the next time - step : this would induce correlations between the samples at different time - steps whereas we require independent samples @xcite .",
    "in this section , we will set up the notation and define the basic tools we will employ throughout this paper .",
    "part of the presentation is inspired , and closely follows , the approach given in @xcite .",
    "the basic building block we will use in this work is the so - called szegedy walk operator @xmath19 defined for any ergodic , aperiodic and time - reversible markov chain @xmath20 .",
    "first , we will briefly recap a few basic notions regarding markov chains for the convenience of the reader , and refer to @xcite for further details . throughout this paper , with @xmath20",
    "we will denote a left - stochastic matrix ( a matrix with non - negative , real entries which add up to one in every column ) .",
    "as @xmath21 along with an initial distribution , specifies a markov chain , we will refer to @xmath20 as the transition matrix and the markov chain , interchangeably .",
    "if @xmath20 is irreducible and aperiodic , then there exists a unique stationary distribution @xmath22 such that @xmath23 . here , @xmath24 denotes a distribution over the state space , represented as a non - negative column vector @xmath25 @xmath26 , such that @xmath27 if @xmath24 is a distribution , then we will refer to the element which occurs with a largest probability @xmath28 as a mode of the distribution @xmath22 and the corresponding largest probability @xmath29 as the probability of a mode . note that while the mode need not be unique , the probability of the / a mode is .",
    "the final property we will require is that the markov chain @xmath20 is time - reversible , that is , that it satisfies detailed balance : an ergodic markov chain @xmath20 with stationary distribution @xmath24 is time - reversible if the following holds : more generally , for an ergodic markov chain @xmath21 over the state space of size @xmath30 with stationary distribution @xmath24 , we define the time - reversed markov chain @xmath31 with @xmath32 where @xmath33 is the diagonal matrix @xmath34 always exists , as stationary distributions of irreducible aperiodic markov chains have non - zero support over the entire state space . ]",
    "then , @xmath20 is time - reversible if @xmath35    next , we review the basics of so - called szegedy - type quantum walks , to an extent inspired by the presentation given in @xcite      while the szegedy walk operator @xmath36 can be defined directly , it will be useful for us to construct it from a more basic building block , the diffusion operator @xmath37 the diffusion operator @xmath38 acts on two quantum registers of @xmath30 states , ( partially ) defined as follows : the operator @xmath38 is a natural quantum analog of the operator @xmath20 in the sense that a classical random walk can be recovered by applying @xmath38 , measuring the second register , re - setting the first register to @xmath39 , and swapping the registers . while @xmath38 is not uniquely defined , any operator satisfying eq .",
    "( [ up ] ) will do the job .",
    "the operator @xmath40 and its adjoint are then used to construct the following operator : where @xmath41 reflects over the state @xmath39 .",
    "the operator @xmath42 is itself a reflector , reflecting over the subspace @xmath43 .",
    "the szegedy quantum walk is often explained as a bi - partite walk between two copies of the original graph , and @xmath42 corresponds to one direction .",
    "the other direction is established by defining the diffusion operator in the opposite direction : @xmath44 and proceeding analogously as in the case for the set @xmath45 , to generate the @xmath46 operator , reflecting over @xmath47 .",
    "the szegedy walk operator is then defined as @xmath48 . in @xcite",
    "it was shown that the operator @xmath36 and @xmath20 are closely related , in particular in the case when @xmath20 is time - reversible .",
    "often we will be referring to the _ coherent encoding _ of a distribution @xmath22 denoted @xmath49 the state @xmath50 is a pure state of an @xmath3level system given by @xmath51 it is clear that a computational basis measurement ( so a projective measurement w.r.t . the basis @xmath52 ) of the state @xmath50 outputs an element distributed according to @xmath24 .    in the context of szegedy - type",
    "quantum walks , it is convenient to define another type of a coherent encoding , relative to a markov chain @xmath20 , which we temporarily denote @xmath53 this encoding is defined by @xmath54 , where @xmath38 is the szegedy diffusion operator .",
    "it is easy to see that @xmath50 and @xmath55 are trivially related via the diffusion map ( more precisely , the isometry @xmath56 ) and moreover that the computational measurement of the first register of @xmath55 also recovers the distribution @xmath24 . due to this , by abuse of notation , we shall refer to both encodings as _ the coherent encoding _ of the distribution @xmath22 and denote them both with @xmath57 where the particular encoding will be clear from the context .",
    "however , for the majority of the text , we will be using the latter meaning .    with these definitions in place",
    "we can further clarify the relationship between the classical transition operator @xmath20 and the szegedy walk operator @xmath58 let @xmath24 be the stationary distribution of @xmath21 so @xmath23 .",
    "then the coherent encoding of the stationary distribution @xmath24 of @xmath20 , given by @xmath59 is also a + 1 eigenstate of @xmath36 , that is , @xmath60 .",
    "moreover , in the subspace @xmath61 , so - called _ busy subspace _ , it is the unique @xmath62 eigenstate . on the orthogonal complement of the busy subspace , @xmath36 acts as the identity .",
    "moreover , the spectrum of @xmath20 and @xmath36 is intimately related , and in particular the spectral gap where @xmath63 denote the eigenvalues of @xmath20 and @xmath64 denotes the spectrum of @xmath20 , is essentially quadratically smaller than the phase gap where @xmath65 denote the arguments of the eigenvalues , i.e. eigenphases , of @xmath36 .",
    "this relationship is at the very basis of all speedup obtained from employing szegedy - type quantum walks , which we shall elaborate further . in this paper",
    "we will not use other results than those we briefly exposed here , and we refer the interested reader to @xcite for further details .",
    "the first application of the walk operator @xmath36 allows us to approximate a projective measurement on the @xmath50 state , where @xmath24 is the stationary distribution of @xmath20 .",
    "this is achieved by using kitaev s phase detection algorithm ) on the phase containing register .",
    "this algorithm can be , for our purposes , further simplified by substituting the @xmath66 with the suitable number of hadamard gates , as suggested in @xcite .",
    "this substitution maintains the probability of observing a zero phase , and the corresponding post - selected state , thus can be used to detect a non - zero phase . for this reason , this slightly tweaked algorithm",
    "is called the phase _ detection _ algorithm . ]",
    "@xcite on @xmath36 ( with precision @xmath67 ) , which , if followed by the measurement of the phase - containing register , approximates the projective measurement on the state @xmath49 to understand why this holds , recall that the @xmath36 operator has the state @xmath50 as the unique @xmath62 eigenstate , in the busy subspace",
    ". moreover the values of the phases of all other eigenstates ( in the same subspace ) are at least @xmath68 .",
    "thus , provided the state we perform the measurement on is in @xmath69 , the residual state , conditioned on detecting zero phase , is a good approximation of @xmath49 the error can be further suppressed by iterating the procedure , as was suggested in @xcite , there for the purpose of approximate reflection , which we will elaborate on next .",
    "more precisely , the errors can be made exponentially small with linear overhead , yielding an overall cost @xmath70 . here",
    ", the @xmath71 , the so - called soft - o notation ignores the logarithmically contributing factors , in this case stemming from the quality of the approximation .",
    "this result can be seen as a consequence of theorem 6 in @xcite .",
    "this is a very useful tool for purifying an already good approximation of the target state @xmath49 however , this projective measurement behaves correctly only if we are guaranteed the state we have is in the space @xmath72 fortunately , this is easy to achieve . in particular , testing whether a given state is in @xmath45 ( or @xmath73 ) is straightforward : one simply applies @xmath74 ( or @xmath75 ) and checks the contents of the second ( or first ) register .",
    "provided we observe the state @xmath76 we are guaranteed that we are in the correct subspace . since the target state @xmath50 is in @xmath77 it will suffice to check whether the initial state is in @xmath45 first and if it is perform the @xmath50 projective measurement .",
    "the sequence of these two measurement ( @xmath45 membership measurement , followed by the phase measurement ) constitutes the @xmath50 projective measurement .",
    "the success probability of this measurement , applied on the pure state @xmath78 is in @xmath79 that is on the order of the fidelity @xmath80 between the input state and the @xmath50 state . note that if the measurement were perfect , the success probability would be exactly the fidelity .",
    "one of the central tools in the theory of szegedy - type quantum walk is the so - called approximate reflection operator @xmath81 , which approximately reflects over the state @xmath50 @xcite .",
    "the basic idea for the construction of this operator is similar to the one we gave for the @xmath50 projective measurement . by applying kitaev s phase detection algorithm on @xmath36 ( with precision @xmath82 ) , applying a phase flip to all states with phase different from zero , and by undoing the phase detection algorithm",
    ", we obtain an arbitrarily good approximation of the reflection operator @xmath83 , for any state within @xmath61 .",
    "the errors of the approximation can be efficiently suppressed by iteration ( by the same arguments as for the @xmath50 measurement ) @xcite , so the cost of the approximate reflection operator is again in @xmath84    thus , the second gadget in our toolbox is the operator @xmath85 which approximates a perfect reflection @xmath86 on @xmath61 , while incurring a cost of @xmath70 calls to the walk operator @xmath36 .",
    "the operator @xmath87 is central to many of the results employing szegedy - type walks @xcite , in particular in tasks of element finding , as we shall clarify next .",
    "the approximate reflection operator @xmath87 , along with the capacity to flip the phase of a chosen subset of the computational basis elements , suffices for the implementation of an amplitude amplification @xcite algorithm .",
    "this , in turn , allows us to find the chosen elements with a quantum speed - up . to illustrate this ,",
    "assume we are given the state @xmath57 the ( ideal ) reflector @xmath88 and assume we are interested in finding some set of elements @xmath89 .",
    "the subset @xmath90 is typically specified by an oracular access to a phase flip operator defined with @xmath91 .",
    "the element searching then reduces to iterated applications of @xmath92 ( which can be understood as a generalized grover iteration , more precisely amplitude amplification ) onto the initial state @xmath49 let @xmath93 denote the conditional probability distribution obtained by post - selecting on elements in @xmath90 from @xmath22 so with @xmath94 let @xmath95 denote the coherent encoding of @xmath96 note that the measurement of the first register of @xmath97 outputs an element in @xmath90 with probability 1 .",
    "thus the capacity for preparing this state implies that the desired element from @xmath90 can be found , directly by measurement .",
    "as it was shown in @xcite , applications of @xmath98 and @xmath86 leave the register state in the two - dimensional subspace @xmath99 and moreover , using @xmath100 applications of the two reflections will suffice to produce a state @xmath101 such that @xmath102 is a large constant . measuring the first register of such a state will result in an element in @xmath90 with a constant probability , which means that iterating this process @xmath103 times ensures an element in @xmath90 is found with an exponentially increasing probability in @xmath103 .",
    "however , since the state @xmath78 is also in @xmath104 it is easy to see that the measured outcome , conditional on being in the set @xmath90 , will indeed be distributed according to @xmath93 .    in our recent work @xcite , and also in @xcite",
    ", these results were used to produce a sample from the truncated stationary distribution @xmath105 in time @xmath106 where the @xmath1 term stems from the cost of generating the approximate reflection operator @xmath87 , and @xmath70 corresponds to the number of iterations which have to be applied .",
    "this is a quadratic improvement relative to using classical mixing , and position checking processes which would result in the same distribution .",
    "however , the same process can be used _ in reverse _ to generate the state @xmath50 starting from some fixed basis state @xmath107 with cost @xmath108 .",
    "note that @xmath109 is the probability of sampling the element @xmath110 from the distribution @xmath24 . to see that this works , let @xmath111 correspond to the product of all @xmath112 reflections ( so @xmath113 of them ) that need to be applied to find the element @xmath110 .",
    "the correctness of the search algorithm then guarantees that the trace distance between the final state and the target state is a ( small ) constant @xmath114 , so @xmath115 .",
    "but since the trace distance ( and also fidelity ) are preserved under unitary maps , and since @xmath111 is unitary , we also have that @xmath116 .",
    "thus the resulting state obtained by reversing the search process is constantly close to the state @xmath49 but then , the @xmath50 projection measurement we described previously will recover ( an arbitrary good approximation of ) the @xmath50 state with a constant probability . by iterating this entire process",
    ", should it fail ( the iteration is possible , since we can generate @xmath117 cheaply on demand ) , we will get the desired state @xmath50 with exponentially increasing probability in the number of attempts .",
    "such a process of recovering the state @xmath50 corresponds to a classical mixing process .",
    "classical mixing ( for time - reversible markov chains ) can be achieved in @xmath118 ( ignoring error terms ) , whereas the quantum process terminates in @xmath119 in both cases . ] , where @xmath120 denotes the smallest occurring probability in @xmath24 , in the worst case .",
    "hence we can see a quadratic improvement w.r.t the @xmath1 term in the quantum case .",
    "however , the scaling relative to the probability term @xmath120 constitutes an exponential slowdown relative to the classical mixing bounds , and this trade - off is prohibitive .",
    "we highlight that the approach we have just described for attaining stationary distributions by running hitting algorithms in reverse was first proposed by richter @xcite , extending on observations by made by childs  @xcite .    the basic idea of",
    "this work will be to ensure that the choice of the initial seed state @xmath117 is in fact the best possible .",
    "however , the best possible situation can still be to costly as the highest probability may still be as small as @xmath121 , as is the case for the uniform distribution . in these cases",
    "there is a more efficient way to prepare the initial state , which we clarify next .      as we have described previously , the access to the @xmath36 operator .",
    "] operator allows us to perform a projective measurement to the state @xmath49 thus , if we prepare the coherent encoding of the uniform distribution state @xmath122 , simply by performing the @xmath50 projective measurement on it , we still have the probability @xmath123 of collapsing to the correct state . by repeating this process",
    "until we succeed , we obtain a preparation algorithm with expected running time of @xmath124 however , we can improve on this by  goverizing \" this process , that is , by using amplitude amplification @xcite",
    ". this amounts to reflecting over @xmath125 and @xmath50 iteratively , starting from @xmath126 until we reach a state close to the target state @xmath57 with an overall cost @xmath127 .",
    "we use the generalizations of this approach in @xcite to generate coherent encodings of stationary distributions in the cases where the shape of the target distribution is to some extent known . for the purposes of this paper ,",
    "however , we will only require unsearching from the uniform and from kronecker - delta distributions .",
    "the preparation method starting from the uniform distribution , and also the unsearch approach from a fixed state , are a special cases of the more general amplitude amplification protocol we have just described .",
    "the two methods , unsearching and preparation from uniform , of preparing the state @xmath50 are complementary , in the sense that the latter method is more efficient when the stationary distribution is close to uniform , where the unsearching becomes efficient when an element has a high probability ( roughly , when the distribution is far from uniform ) .",
    "our overall approach we present next will use both methods for preparation , and provide a method for identifying the right candidates ( elements with the highest probability in @xmath24 ) for the unsearching approach . in",
    "what follows , we will say that the ( coherent encoding of ) distribution @xmath24 is _ far from uniform _ , if @xmath128 and otherwise , we will say the distribution ( equivalently , its coherent encoding ) is _ close to uniform . _",
    "we will first establish the notation for the remainder of the paper . a given element of a sequence we are referring to , will , in the remainder of the paper , be specified by a superscript in the cases of transition matrices and spectral gaps , e.g. @xmath129 for the @xmath130 element . in the case of distributions , we will use parentheses ( e.g. @xmath131 ) , since we have reserved the subscripts to denote a particular probability in a given distribution .",
    "we proceed by formally specifying the setting we consider .",
    "we assume we are , at each time - step @xmath132 given the szegedy walk operators @xmath133 associated with a sequence of time - reversible markov chains @xmath134 over the same state space of @xmath30 elements , along with each spectral gap @xmath135 .",
    "the task is , at each time - step @xmath17 , to generate the coherent encoding of the stationary distribution @xmath136 , with cost in @xmath137    to achieve this , we require further assumptions , namely that the markov chains are slowly - evolving . more precisely , we require that the stationary distributions @xmath138 of neighboring markov chains @xmath139 , respectively , are sufficiently close in terms of the fidelity of their coherent encodings .",
    "that is , we require that @xmath140 , where @xmath141 is a real constant independent from the spectral gaps , and the state space size .",
    "moreover , we will require that the spectral gaps @xmath142 of neighboring chains @xmath139 are relatively close , in the sense which we will specify later .",
    "as we will explain , this last assumption is not vital , but allows for a more convenient statement of the main result .",
    "finally , we will assume that the coherent encoding of the stationary distribution @xmath143 of the first markov chain is easy to generate .",
    "these assumptions are essentially equivalent to the assumptions in @xcite .",
    "however , as we have clarified , in contrast to those works , in our result , at each time - step @xmath132 the stationary distribution can be prepared _ de novo _ , that is without using any quantum memory from step @xmath144 , with cost @xmath137 this , for instance implies that multiple copies can be generated at each time - step as well , if desired , without having to re - run the entire sequence of markov chains .",
    "moreover , our approach does not depend on the length of the sequence , as each stationary distribution is prepared `` on the fly '' , independently from the quantum states utilized in previous steps .",
    "both properties are vital in the context of active learning agents that we have mentioned previously .    to explain how our protocol works",
    ", we will describe two particular settings where the cost of preparation of the encoding of the stationary distribution @xmath50 of an @xmath3state markov chain @xmath20 with spectral gap @xmath1 is in @xmath145    in the first setting the fidelity between the coherent encoding of the uniform distribution @xmath125 and @xmath50 is above @xmath146 . in this case , as we have shown , the preparation starting from uniform has the desired overall cost @xmath147    in the second setting the stationary distribution @xmath24 of @xmath20 has the probability of a mode @xmath148 ( the largest occurring probability ) larger than @xmath146 , and the mode state itself @xmath149 is known .",
    "in this case , unsearching from the element @xmath149 will produce the target state with cost in @xmath150 .",
    "our first technical result shows that any markov chain @xmath20 fits in one of the two settings above , which is captured by the following lemma , proven in the appendix .",
    "[ fid : mode : bounds ] let @xmath24 be a distribution over @xmath30 states , such that @xmath151 then @xmath152 .",
    "moreover , if @xmath153 then @xmath154    the lemma above has a few immediate consequences .",
    "first of all , if we are given a markov chain @xmath21 ( over @xmath30 states ) with known @xmath1 , the mode @xmath149 of the corresponding stationary distribution @xmath22 along with the probability of the mode @xmath155 , then it is clear that we can prepare the stationary distribution within cost @xmath156 : if @xmath157 we use the  unsearch from @xmath117 \" approach .",
    "if it is not , then by the second claim of lemma [ fid : mode : bounds ] , we know that we can prepare the initial state by the preparation from the uniform distribution within cost @xmath156 .",
    "it is also easy to see that the assumption of knowing the probability of the mode @xmath158 is actually not needed .",
    "one can first attempt the preparation from the uniform distribution a suitable number of times , where the number of reflections used is upper bounded by @xmath159 .",
    "this is achieved by directly performing the @xmath50 projective measurement on the uniform distribution state a couple of times .",
    "if it succeeds , we are done , should it fail , we can conclude that the overlap is below @xmath160 , as required , except with an exponentially decaying probability in the number of attempts . the same approach ,",
    "albeit applied to the task of element finding , was first suggested in @xcite . ] - if the target distribution closer than @xmath161 to the uniform distribution , in terms of the fidelity , then this will succeed with exponentially high probability in the number of attempts .",
    "if all attempts fail , we are ( except with exponentially small probability ) then sure we are in the regime where the mode has a probability higher than @xmath162 and this is all we need to know .",
    "then , the unsearching approach , starting from the mode @xmath149 will ( with high probability ) produce the target state if we employ @xmath159 iterations , so with overall cost @xmath156 .",
    "we will take care of the failure probability of this approach later .",
    "however , even the assumption that the mode ( but not the probability of the mode ) is known is most often too strong to be justified . nonetheless , if we are dealing with a scenario in which we have a sequence of markov chains , such that a ) the stationary distributions of consecutive markov chains are sufficiently close , and b ) the first markov chain has a known , easy to prepare stationary distribution , then we can recover the same results without the need to explicitly find a mode .    to illustrate how this is achieved ,",
    "consider the setting of just two markov chains , @xmath15 and @xmath163 , ( with corresponding stationary distributions @xmath164",
    ", @xmath165 , such that @xmath143 is easy to prepare .",
    "by easy to prepare we mean within the cost @xmath166 so it will , for instance , suffice that we know the mode of @xmath164 and it is above @xmath162 or that the fidelity ( relative to the uniform distribution ) is above @xmath161 .    to prepare the ( coherent encoding of the ) stationary distribution of @xmath163",
    ", we first proceed with the attempt to recover it by unsearching from the uniform distribution .",
    "if this succeeds , we are done .",
    "if this approach should fail , we proceed as follows : we first prepare @xmath167 copies of the state @xmath143 , where @xmath168 is a ( small ) confidence parameter .",
    "recall , we have assumed the stationary distributions of @xmath15 and @xmath163 are close , so we will have that @xmath169 where @xmath170 is some ( large ) constant .",
    "this implies that a projective measurement on the state @xmath171 of the state @xmath143 will succeed with average probability @xmath170 .",
    "this measurement has cost @xmath172 so with overall cost @xmath173 we can prepare , on average , @xmath174 copies of the state @xmath171 is very small ( but the assumption is it is independent from @xmath30 and the spectral gaps ) we can do better by utilizing quantum amplitude amplification @xcite again - given the initial state @xmath143 , by using the reflection over it , and the reflection over @xmath171 , we can obtain the target state @xmath171 with a quadratic smaller cost with respect to @xmath170 .",
    "however , since for this work we assume @xmath170 is constant this still yields the same overall scaling . ] . in the actual protocol",
    ", we will iterate the preparation until we do have @xmath114 copies , and @xmath168 above then establishes the expected number of iterations .",
    "next , we simply measure ( the first register of ) all of the @xmath114 copies of the state , obtaining @xmath114 independent single element samples from the distribution @xmath165 .",
    "as it turns out , this is sufficient for the task at hand .",
    "if the fidelity of @xmath175 relative to the uniform distribution state @xmath125 , is below @xmath161 , then with probability @xmath176 , at least one state @xmath110 , out of the @xmath114 independently sampled states , has the corresponding probability @xmath177 .",
    "this result is captured by the following lemma , and proven in the appendix :    [ main : lemma ] let @xmath24 be a distribution over @xmath30 states , and let @xmath178 then there exists a set of indices @xmath179 such that the two following properties hold :    * @xmath180 and * @xmath181    as the next step , we simply sequentially attempt to prepare the target state through unsearching from the sampled states and employing @xmath159 iterations of the reflections .",
    "with probability at least @xmath176 , one of the attempts will succeed .",
    "what we have shown is that having a collection of @xmath114 independent single element samples from @xmath165 suffices to efficiently prepare @xmath175 in the regime where the preparation from uniform distribution would not be efficient . from these observations ,",
    "the presented approach for two markov chains inductively extends to the setting with a sequence of markov chains that we wish to consider .",
    "we now give the full protocol , along with a more rigorous analysis .    in what follows",
    ", we will be assuming all the approximate reflection operators are in fact exact , and we will deal with the errors induced by approximations later .",
    "the protocol will use two subroutines .",
    "the subroutine _",
    "preparefromuniform(c ) _ attempts the preparation from the uniform distribution , using @xmath159 reflections . if the target distribution state close to the uniform distribution state ( in the sense we defined previously ) , then by utilizing the randomized approach @xcite we will obtain the target state except with probability below @xmath182 times - failing to generate the target state , if the fidelity is above or equal to 1/4 , will then occur with probability below @xmath183 .",
    "since the cost of the projective measurements does not depend on @xmath30 , we may ignore this in the complexity analysis . ] .",
    "we will , for this subroutine , allow for @xmath114 attempts to prepare the target distribution .",
    "then we will succeed , whenever the fidelity relative to the uniform distribution state is above @xmath184 except with probability @xmath185 the output of this subroutine is either the coherent encoding of the stationary distribution , or ",
    "unsuccessful \" - a flag indicating that the preparation failed and that the target distribution is far from uniform , except with small probability .",
    "the cost of this procedure is @xmath186 at time step @xmath17 .",
    "the second is the _",
    "preparesamples(c ) _ subroutine . in the context of the overall protocol",
    ", we will make sure that , at each step we generate in total @xmath114 elements sampled from the target distribution .",
    "one of these is output , and all are saved , in the case we need them for the next step .",
    "the @xmath187 subroutine , used at time - step @xmath188 back - tracks to the previous step , and first prepares the coherent encoding for the previous step @xmath189 depending on whether the previous stationary distribution is close or far from the uniform ( that is , closer or further than @xmath162 in terms of the fidelity with the uniform distribution ) for this we may require @xmath114 samples from the previous distribution itself .",
    "as we have clarified , we will make sure we always have those in the overall protocol . given the @xmath114 samples for the previous step ,",
    "the encoding @xmath190 can be generated with cost @xmath191 except with probability @xmath192 by lemma [ main : lemma ] ( in the case we accidentally have bad samples ) , either by using the preparation from the samples , or by preparing from the uniform . following this , on the state @xmath190",
    "we apply a @xmath193 projective measurement ( with cost @xmath194 ) and with probability @xmath170 we succeed to project onto @xmath136 .",
    "this process is repeated until @xmath114 copies of @xmath136 are generated , and they may be immediately measured .",
    "one of the sampled elements ( measurement outcomes ) is output , and the other @xmath114 sampled elements are stored for future use by the @xmath195 subroutine .    the situation is analogous in the case the previous distribution was prepared from the uniform .",
    "we highlight that , irrespective of the method we used at time step @xmath144 , @xmath187 will attempt to regenerate the states @xmath190 by using the original approach first , but , if that should fail , it will switch to the alternative independently sampled elements . ] .",
    "in the case @xmath187 is run at time - step @xmath196 the procedure is analogous as above , with the difference that , by assumption , we can cheaply generate the required encodings @xmath143 of the previous step .",
    "this subroutine has expected running time @xmath197 and a failure probability @xmath192 .",
    "since we do not consider the scaling in @xmath170 , we obtain @xmath198    now we can give the protocol , where @xmath17 denotes the time - steps :    * the protocol * +    1 .   if @xmath199 prepare the corresponding coherent encoding of the stationary distribution , measure , and output the outcome .",
    "keep the operator @xmath200 ( and @xmath201 ) in memory for one additional time - step .",
    "2 .   if @xmath202 execute @xmath203 @xmath114 times . if each run generated the target distribution , save @xmath114 sampled elements for future use , and output one as the current output .",
    "if any run returns  unsuccessful \" , abort , and run @xmath204 in both cases replace the stored operator @xmath205 with the current @xmath206 ( also @xmath207 with @xmath208 , ) and proceed to the next time - step .",
    "first , we analyze the protocol under the assumption that the realized approximate reflection operators are perfect . in this case",
    ", the protocol above has , at each time - step @xmath17 ( for @xmath209 , ) the expected running time in @xmath210 , where @xmath114 is a confidence parameter , as this expression is the maximum of the costs of both possible preparation subroutines .",
    "if we have the assumption that the neighboring spectral gaps @xmath207 and @xmath208 are multiplicatively close , meaning that there exists a constant @xmath211 ( independent from @xmath30 ) such that for all @xmath209 we have that then the cost of preparation is in @xmath212 for each @xmath17 , which was the desired cost .",
    "the protocol can , however , fail with probability @xmath213 which we clarify next .",
    "first , note that the @xmath214 subroutine may fail - that is , report `` unsuccessful '' , although the distribution is in the right regime ( close to uniform ) . in our protocol",
    ", we call this subroutine @xmath114 times , with parameter @xmath215 this entire iteration fails if at least one of the runs reported  unsuccessful \" , although the target distribution was close enough to the uniform distribution . if the target distribution is in the required regime , @xmath216 run once reports  unsuccessful \" with probability @xmath217 the probability at least one  unsuccessful \" report in a sequence of @xmath114 runs is then given with @xmath218 .",
    "however , we have that @xmath219 which we here prove for completeness .",
    "we have that for the expression @xmath220 we have , by the bernoulli s inequality , that @xmath221 so it will suffice to show that @xmath222 , which is equivalent to @xmath223 which is true .",
    "thus in our protocol , failure to prepare the required @xmath114 independently sampled elements , in the case the distribution is sufficiently close to the uniform distribution , occurs at most with probability @xmath192 .",
    "if the distribution is not close to uniform , we may end up running the @xmath187 subroutine , which will attempt the preparation of the @xmath114 samples , by regenerating the encodings of the stationary distributions of the previous step .",
    "for this , it may utilize either the @xmath114 samples from that distribution or attempt preparation from the uniform distribution state , and in the worst case , it will attempt both . since the target distribution must be in one of the two regimes , and since both cases have a failure probability of @xmath224 this also gives the overall failure probability .    hence , we have shown that our protocol , under the assumption that all the reflection operators ( and measurements ) are perfect , generates a sample from ( or a coherent encoding of ) the target stationary distribution , with cost in @xmath225 with a failure probability in @xmath226    in the real protocol , the reflection over the target state @xmath50 is not ideal ( as we only achieve an approximation of the reflection ) and neither is the @xmath50 projective measurement . taking into account the effects of these imperfections , we obtain the expected run - time of @xmath227 with the same failure probability in @xmath226 analysis of this is provided in the appendix .",
    "we finish of this section with a comment on how total failure can be dealt with , when failure is not an option . in the context of ( effectively ) infinite sequences of markov chains ,",
    "the exponentially unlikely failure will still occur . in this case , if we are required to proceed although the protocol failed at time - step @xmath17 , one can always prepare a sufficient number of samples from @xmath228 in time @xmath229 by forcing the preparation from the uniform distribution .",
    "although this constitutes a quadratic slowdown ( w.r.t . the state space size ) , it will only occur exponentially rarely , which means that , at least the average preparation cost for each time step can be kept arbitrarily close to @xmath230",
    "we have presented a quantum algorithm for sequentially generating stationary distributions of an arbitrarily large sequence of markov chains .",
    "the quantum algorithm outperforms classical approaches whenever the spectral gaps @xmath1 of the markov chains are below @xmath161 , where @xmath30 is the size of the state space . in contrast , straightforward application of themixing by reverse hitting \" approach would yield improvements only in a quadratically more stringent regime where @xmath231 .",
    "the basic observation we have used is that the bottle - neck of direct mixing by running hitting algorithms in reverse , can be ameliorated when only a small number of elements sampled from the target distribution are available beforehand .",
    "we have shown that this can guarantee that the initial state of the unsearch approach is far from the worse case setting . following this ,",
    "we have shown how these samples can be made available in the context of slowly evolving markov chains .",
    "as we have clarified , the presented algorithm has an immediate application in a recent approach to ( quantum ) artificial intelligence @xcite , but it may be useful in other context as well .",
    "for instance , it may offer improvements for problems stemming from statistical physics .",
    "one application could be in the case when strictly independent samples from gibbs distributions of physical systems are required in a large range of temperatures , which include the computationally difficult low - temperature regimes .",
    "other applications may be possible as well , for instance in applications where subsequent markov chains may depend on the actual outputs of previous mixing steps . in this case ,",
    "quantum - enhanced classical annealing methods become unsuitable , as they need to keep coherence through the protocol steps @xcite .    as a feature of our protocol",
    ", we point out that at each time step can output not just a classical sample from the target stationary distribution , but a coherent encoding of this distribution .",
    "this is not a guaranteed characteristic of quantum mixing protocols @xcite , and makes our approach suitable for combining with other quantum protocols which start from such a coherent encoding @xcite .",
    "in the protocol we have presented , as in other related works , it is always assumed that aside from the markov chains themselves , one also has access to the values of the spectral gaps .",
    "this is potentially a problematic assumption , since , at least in the general cases , spectral gaps are often difficult to determine .",
    "consequently , methods which do not rely on good lower bounds of the spectral gaps , or , more precisely , which can adaptively estimate the changes in spectral gaps in the context of slowly evolving sequences , are part of ongoing work .    *",
    "acknowledgments : + * the authors acknowledge the support by the austrian science fund ( fwf ) through the sfb foqus f4012 , and the templeton world charity foundation grant twcf0078/ab46 .",
    "vd thanks g. d. paparo for initial discussions .",
    "in this section we prove the technical lemmas from the main body of the paper , which we repeat for the benefit of the reader . following this",
    ", we provide an analysis of our protocol covering the imperfections in the reflection operators .",
    "assume first that @xmath233 then , we ask what distribution @xmath24 minimizes the fidelity , relative to the uniform distribution , satisfying the given constraint on the mode(s ) .",
    "we claim that the distribution which minimizes the fidelity is the distribution @xmath24 ( up to permutation of the probabilities , which does not change the overlap with the uniform distribution ) defined as follows .      to see this is the case , first note that the permutation of the probabilities does not change the overlap with the uniform distribution .",
    "thus it will suffice to consider distributions whose probabilities are ordered in a decreasing order according to the indices .",
    "we will call such distributions decaying distributions @xcite .",
    "next , we will say that the decaying distribution @xmath240 is obtained from the decaying distribution @xmath241 _ by separating the probabilities of elements _ @xmath110 _ and _ @xmath242 _ in _ @xmath243 ( for @xmath244 ) if the following holds : @xmath245 for all @xmath246 and @xmath247 , and @xmath248 and @xmath249 . intuitively , to obtain @xmath240 from @xmath241 we simply shift a part of the mass of the probability at state @xmath242 to the state at @xmath110 while maintaining the order .",
    "next , note that the distribution @xmath24 is the extreme point of such a probability separation process , for all decaying distributions satisfying the constraint on the probability of the mode : @xmath24 can be obtained by iterating this process from any decaying distribution @xmath250 , which satisfies the constraint @xmath251 .    for completeness",
    ", we illustrate why this works .",
    "for instance , by starting from the smallest non - zero probability element @xmath110 in @xmath250 , decreasing it , while increasing the largest probability element in @xmath242 in the distribution @xmath250 which is smaller than @xmath252 until the modified value of @xmath253 equals @xmath252 , or until we deplete @xmath254 . by iterating this procedure , in a finite number of steps we will have reached @xmath24 .",
    "next , we claim that if the decaying distribution @xmath240 is obtained from the decaying distribution @xmath241 by separating the probabilities of elements @xmath110 and @xmath242 , then @xmath255 this follows from the convexity of the fidelity relative to the uniform distribution : since we are only changing the probabilities of the elements @xmath110 and @xmath242 , the distance from the uniform distribution ( fixing all other parameters ) is up to squaring proportional to @xmath256 where @xmath257 is constant .",
    "this function clearly decreases as @xmath258 grows at the expense of @xmath259 .",
    "but since @xmath24 is the extremal point of the process of separating the probabilities ( under the constraint that @xmath260 ) , the distribution @xmath24 as defined minimizes the fidelity under the given constraint on the mode of the distribution .",
    "the fidelity between @xmath50 and @xmath125 is now easy to compute : we have that @xmath261 and we will evaluate @xmath262      this expression can be further simplified . in the following ,",
    "let for @xmath263 , @xmath264 denote the fractional part of @xmath265 .",
    "then we have : since the fractional part is always between 0 and 1 , and since on that interval it holds that @xmath266 we have that the expression @xmath267 is always non - negative , the minimum is zero , and the maximum reached at @xmath268 where it reaches the value @xmath160 .",
    "thus we have @xmath269 so this proves the second direction of the lemma .",
    "next , we prove lemma [ main : lemma ] . for convenience we will rephrase it in terms of the function @xmath272 defined as @xmath273 which is up to a square proportional to the fidelity w.r.t .",
    "the uniform distribution :        let @xmath276 be the set of all the indices of all probabilities occurring in @xmath22 which are larger or equal to @xmath277 .",
    "note that by lemma [ fid : mode : bounds ] , since @xmath278 , there exists at least one probability larger or equal to @xmath279 thus the set @xmath276 is non - empty and @xmath280 .",
    "now , consider the renormalized distribution @xmath105 where all probabilities corresponding to elements in @xmath276 are set to zero . by eq .",
    "( [ eq : max1 ] ) , the renormalization factor is below 2 . then , since @xmath284 it holds that @xmath285 finally , we proceed analogously to the proof of the second direction of the first lemma ( eq .  ( [ eq - first ] ) to eq .",
    "( [ eq - last ] ) ) to find a bound on the @xmath286 function under the constraint that @xmath287 we obtain          here we consider the propagation of errors when the reflection operator over the stationary distribution , and the @xmath50 projective measurement , are approximate . recall that both in the cases of the preparation from the uniform distribution , and in the cases of preparation from a given sampled element @xmath110 , the precision of the approximation of the target state comes into play only logarithmically .",
    "more precisely , if @xmath293 is the desired bound on the trace distance between the realized distribution and the targeted distribution , and if @xmath294 is the fidelity between the initial state ( uniform distribution or the given sample state @xmath117 ) , and the target state , then the total cost of the preparation procedure is given with @xmath295 in the last expression , the second log term compensates for the fact that an imperfect reflector will be applied @xmath296 times , accumulating errors .",
    "thus , the precision of the approximation contributes only logarithmically in the overall complexity , even in the iterated setting .",
    "however , we must make sure that the inductive steps of our protocol , going from one time step to another , are not overly sensitive to small imperfections .",
    "there are two moments where the imperfections can cause problems .",
    "first , except for the first time - step , the @xmath114 samples we have stem not from the exact distribution , but rather the approximation .",
    "second , in the generation of the @xmath114 samples at step @xmath17 we used an approximate projective measurement to go from an approximation of @xmath190 to an approximation of @xmath136 , which succeeds with probability @xmath170 ( the fidelity between the two states ) , only in the exact case .",
    "for the second problem , a simple way to bound the deviation on the success probability is by considering the ideal @xmath50 projective measurement as a completely positive trace - preserving ( cptp ) map @xmath297 which outputs just the success or failure status ( since we care only about the perturbations of the success probabilities ) .",
    "so the approximate projective measurement ( precise within @xmath293 ) can be represented in the same way by the map @xmath298 and we have that for any state @xmath240 , where @xmath299 represents the standard trace norm on quantum states .",
    "the above holds for any pure state @xmath300 so we get the above by triangle inequalities for arbitrary states .",
    "we point out that the claim holds when complete maps ( which also output the heralded quantum state , not just the success / failure bit ) are considered , but as tracing out only reduces trace distances this claim also holds .",
    "note that we do not need to consider purified systems ( nor completely bounded norms on the maps ) , for our problem",
    ". then if @xmath301 we have that but then also @xmath302 in the following , let @xmath303 denote the @xmath304close approximation of @xmath190 ( in the trace distance ) , and let @xmath305 be the success probability of the approximate projection measurement on the approximation @xmath306 so then we have that and then by adding and subtracting @xmath307 , and by the triangle inequality we obtain which by the contractivity of cptp maps yields @xmath308 . then by setting @xmath293 to @xmath309 we get that if @xmath310 ( which is the problematic case ) then @xmath311 in other words , as long as we make sure the error is below @xmath309 ( which is still a constant ) , we are sure that the success probability of the approximate measurement on the approximate state is in the worse case halved .",
    "this constitutes only a a constant multiplicative increase in the run - time of our protocol , so the overall complexity expression is unchanged .",
    "the other problem we face in the light of the approximate nature of the operators we use , is that the @xmath114 sampled elements we obtain do not stem from the distribution @xmath22 but an @xmath304close approximation ( in terms of the trace distance ) . to analyze the worst case scenario how this influences our protocol",
    ", we shall employ similar arguments as above .",
    "note that thepreparation from @xmath114 samples \" subroutine can be viewed as a cptp map applied on @xmath114 mixed states , all encoding the underlying probability distribution , which outputs success ( heralds that the preparation succeeded ) , except with probability @xmath224 if the target distribution is in the right regime , i.e. far from uniform .",
    "the @xmath114 mixed states are obtained by computational basis measurements of the ideal coherent encoding of the target probability distribution @xmath312 in the non - ideal case , we have as input @xmath114 mixed states obtained by a computational - basis measurement of @xmath114 approximations , which are within @xmath293 distance from the ideal states . since the trace distance can only decrease by measurements , and by its subaditivity w.r.t .",
    "tensor products , the total inputs , in the ideal and non - ideal case , differ by at most @xmath313 ( in the trace distance ) .",
    "but then the output of the procedures ( hence , also the success probability ) can not differ by more than @xmath314 thus we obtain that the failure probability for the non - ideal case is no greater than @xmath315 .",
    "if we set @xmath316 the failure probability is lower bounded by @xmath317 which is obeys the same scaling .",
    "since the error term @xmath293 appears logarithmically in the overall complexity , we get an additional multiplicative pre - factor of @xmath318 which is in @xmath319 .",
    "then , the worst case complexity of our approach is given with @xmath320 with failure probability @xmath321 by adding one to all confidence parameters of the protocol , since @xmath322 , we obtain the cost in @xmath323 and the same failure probability , as for the ideal reflectors case , of @xmath192 ."
  ],
  "abstract_text": [
    "<S> in this work we consider the problem of preparation of the stationary distribution of irreducible , time - reversible markov chains , which is a fundamental task in algorithmic markov chain theory . for the classical setting </S>",
    "<S> , this task has a complexity lower bound of @xmath0 , where @xmath1 is the spectral gap of the markov chain , and other dependencies contribute only logarithmically . in the quantum case , </S>",
    "<S> the conjectured complexity is @xmath2 ( with other dependencies contributing only logarithmically ) . </S>",
    "<S> however , this bound has only been achieved for a few special classes of markov chains . in this work , </S>",
    "<S> we provide a method for the sequential preparation of stationary distributions for sequences of general time - reversible @xmath3state markov chains , akin to the setting of simulated annealing methods . </S>",
    "<S> the complexity of preparation we achieve is @xmath4 , neglecting logarithmic factors . </S>",
    "<S> while this result falls short of the conjectured optimal time , it still provides at least a quadratic improvement over other straightforward approaches for quantum mixing , applied in this setting . </S>"
  ]
}