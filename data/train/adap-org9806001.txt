{
  "article_text": [
    "this paper has three goals :    first , to demonstrate the value of a new class of neural network which provides a crucial component needed for brain - like intelligent control systems for the future .",
    "second , to demonstrate that this new kind of neural network provides better function approximate ability for use in more ordinary kinds of neural network applications for supervised learning .",
    "third , to demonstrate some practical implementation techniques necessary to make this kind of network actually work in practice .      at present , in the neural network field perhaps @xmath1 of neural network applications involve the use of neural networks designed to performance a task called supervised learning(figure 1 ) .",
    "supervised learning is the task of learning a nonlinear function which may have several inputs and several outputs based on some examples of the function .",
    "for example , in character recognition , the inputs may be an array of pixels seen from a camera .",
    "the desired outputs of the network may be a classification of character being seen .",
    "another example would be for intelligent sensing in the chemical industry where the inputs might be spectral data from observing a batch of chemicals , and the desired outputs would be the concentrations of the different chemicals in the batch .",
    "the purpose of this application is to predict or estimate what is in the batch without the need for expensive analytical tests .",
    "the work in this paper will focus totally on certain tasks in supervised learning . even though existing neural networks can be used",
    "in supervised learning , there can be performance problems depending on what kind of function is learned .",
    "many people have proven many theorems to show that neural networks , fuzzy logic , taylor theories and other function approximation have a universal ability to approximate functions on the condition that the functions have certain properties and that there is no limit on the complexity of the approximation . in practice , many approximation schemes become useless when there are many input variables because the required complexity grows at an exponential rate .    for example , one way to approximate a function would be to construct a table of the values of the function at certain points in the space of possible inputs .",
    "suppose there are 30 input variables and we consider 10 possible values of each input .",
    "in that case , the table must have @xmath2 numbers in it .",
    "this is not useful in practice for many reasons .",
    "actually , however , many popular approximation methods like radial basis function(rbf ) are similar in spirit to a table of values .    in the field of supervised learning , andrew barron[30 ] has proved some function approximation theorems which are much more useful in practice .",
    "he has proven that the most popular form of neural networks , the multi - layer perceptron(mlp ) , can approximate any smooth function .",
    "unlike the case with the linear basis functions ( like rbf and taylor series ) , the complexity of the network does not grow rapidly as the number of input variables grows .",
    "unfortunately there are many practical applications where the functions to be approximated are not smooth . in some cases ,",
    "it is good enough just to add extra layers to an mlp[1 ] or to use a generalized mlp[2 ] .",
    "however , there are some difficult problems which arise in fields like intelligent control or image processing or even stochastic search where feed - forward networks do not appear powerful enough .",
    "the main goal of this paper is to demonstrate the capability of a different kind of supervised learning system based on a kind of recurrent network called simultaneous recurrent network(srn ) . in the next chapter",
    "we will explain why this kind of improved supervised learning system will be very important to intelligent control and to approximate dynamic programming . in effect",
    "this work on supervised learning is the first step in a multi - step effort to build more brain - like intelligent systems .",
    "the next step would be to apply the srn to static optimization problems , and then to integrate the srns into large systems for adp .",
    "even though intelligent control is the main motivation for this work , the work may be useful for other areas as well .",
    "for example , in zip code recognition , @xmath3[3 ] has demonstrated that feed - forward networks can achieve a high level of accuracy in classifying individual digits .",
    "however , @xmath3 and the others still have difficulty in segmenting the total zip codes into individual digits .",
    "research on human vision by von der malsburg[4 ] and others has suggested that some kinds of recurrency in neural networks are crucial to their abilities in image segmentation and binocular vision .",
    "furthermore , researchers in image processing like laveen kanal have showed that iterative relaxation algorithms are necessary even to achieve moderate success in such image processing tasks .",
    "conceptually the srn can learn an optimal iterative algorithm , but the mlp can not represent any iterative algorithms . in summary , though we are most interested in brain - like intelligent control , the development of srns could lead to very important applications in areas such as image processing in the future .",
    "the network described in this paper is unique in several respects .",
    "however , it is certainly not the first serious use of a recurrent neural network .",
    "chapter 3 of this paper will describe the existing literature on recurrent networks .",
    "it will describe the relationship between this new design and other designs in the literature .",
    "roughly speaking , the vast bulk of research in recurrent networks has been academic research using designs based on ordinary differential equations(ode ) to perform some tasks very different from supervised learning  tasks like clustering , associative memory and feature extraction .",
    "the simple hebbian learning methods[13 ] used for those tasks do not lead to the best performance in supervised learning .",
    "many engineers have used another type of recurrent network , the time lagged recurrent network(tlrn ) , where the recurrency is used to provide memory of past time periods for use in forecasting the future . however , that kind of recurrency can not provide the iterative analysis capability mentioned above .",
    "very few researchers have written about srns , a type of recurrent network designed to minimize error and learn an optimal iterative approximation to a function .",
    "this is certainly the first use of srns to learn a @xmath0 function from dynamic programming which will be explained more in chapter 2 .",
    "this may also be the first empirical demonstration of the need for advanced training methods to permit srns to learn difficult functions .",
    "chapter 4 will explain in more detail the two test problems we have used for the srn and the mlp , as well as the details of architecture and learning procedure .",
    "the first test problem was used mainly as an initial test of a simple form of srns . in this problem",
    ", we tried to test the hypothesis that an srn can always learn to approximate a randomly chosen mlp , but not vice versa .",
    "although our results are consistent with that hypothesis , there is room for more extensive work in the future , such as experiments with different sizes of neural networks and more complex statistical analysis .",
    "the main test problem in this work was the problem of learning the @xmath0 function of dynamic programming .",
    "for a maze navigation problem , many neural network researchers have written about neural networks which learn an optimal policy of action for one particular maze[5 ] .",
    "this paper will address the more difficult problem of training a neural network to input a picture of a maze and output the @xmath0 function for this maze . when the @xmath0 function is known , it is a trivial local calculation to find the best direction of movement .",
    "this kind of neural network should not require retraining whenever a new maze is encountered .",
    "instead it should be able to look at the maze and immediately `` see '' the optimal strategy .",
    "training such a network is a very difficult problem which has never been solved in the past with any kind of neural network .",
    "also it is typical of the challenges one encounters in true intelligent control and planning .",
    "this paper has demonstrated a working solution to this problem for the first time .",
    "now that a system is working on a very simple form for this problem , it would be possible in the future to perform many tests of the ability of this system to generalize its success to many mazes .    in order to solve the maze problem , it was not sufficient only to use an srn .",
    "there are many choices to make when implementing the general idea of srns or mlps .",
    "chapter 5 will describe in detail how these choices were made in this work .",
    "the most important choices were :    \\1 .",
    "both for the mlp and for the feed - forward core of the srn we used the generalized mlp design[2 ] which eliminates the need to decide on the number of layers .",
    "\\2 . for the maze problem",
    ", we used a cellular or weight - sharing architecture which exploits the spatial symmetry of the problem and reduces dramatically the number of weights . in effect",
    "we solved the maze problem using only five distinct neurons .",
    "there are interesting parallels between this network and the hippocampus of the human brain .",
    "\\3 . for the maze problem , an adaptive learning rate(alr ) procedure was used to prevent oscillation and ensure convergence .",
    "initial values for the weights and the initial input vector for the srn were chosen essentially at random , by hand . in the future ,",
    "more systematic methods are available .",
    "but this was sufficient for success in this case .",
    "finally chapter 6 will discuss the simulation results in more detail , give the conclusions of this paper and mention some possibilities for future work .",
    "in this chapter we will explain the importance of this work . as discussed above ,",
    "the paper shows how to use a new type of neural network in order to achieve better function approximation than what is available from the types of neural networks which are popular today .",
    "this chapter will try to explain why better function approximation is important to approximate dynamic programming(adp ) , intelligent control and understanding the brain .",
    "image processing and other applications have already been discussed in the introduction .",
    "these three topics  adp , intelligent control and understanding the brain  are all closely related to each other and provide the original motivation for the work of this paper .",
    "the purpose of this paper is to make a core contribution to developing the most powerful possible system for intelligent control .    in order to build the best intelligent control systems ,",
    "we need to combine the most suitable mathematics together with some understanding of natural intelligence in the brain .",
    "there is a lot of interest in intelligent control in the world .",
    "some control systems which are called intelligent are actually very quick and easy things .",
    "there are many people who try to move step by step to add intelligence into control , but a step - by - step approach may not be enough by itself .    sometimes to achieve a complex difficult goal",
    ", it is necessary to have a plan , thus some parts of the intelligent control community have developed a more systematic vision or plan for how it could be possible to achieve real intelligent control .",
    "first , one must think about the question of what is intelligent control .",
    "then , instead of trying to answer this question in one step , we try to develop a plan to reach the design .",
    "actually there are two questions :    \\1 .",
    "how could we build an artificial system which replicates the main capabilities of brain - like intelligence , somehow unified together as they are unified together in the brain ?",
    ". how can we understand what are the capabilities in the brain and how they are organized in a functional engineering view ?",
    "i.e. how are those circuits in the human brain arranged to learn how to perform different tasks ?",
    "it would be best to understand how the human brain works before building an artificial system .",
    "however , at the present time , our understanding of the brain is limited .",
    "but at least we know that local recurrency plays critical rule in the higher part of the human brain[6][7][8][4 ] .    another reason to use srns is that srns can be very useful in adp mathematically .",
    "now we will discuss what adp can do for intelligent control and understanding the brain .",
    "the remainder of this chapter will address three questions in order : + 1 .",
    "what is adp ?",
    "what is the importance of adp to intelligent control and understanding the brain ?",
    "+ 3 . what is the importance of srns to adp ?      to explain what is adp , let us consider the original bellman equation[9 ] :    @xmath4    where @xmath5 and @xmath6 are constants that are used only in infinite - time - horizon problems and then only sometimes , and where the angle brackets refer to expectation value .",
    "in this paper we actually use :    @xmath7    since the maze problem do not involve an infinite time - horizon .    instead of solving for the value of @xmath0 in every possible state , @xmath8 , we can use a function approximation method like neural networks to approximate the @xmath0 function .",
    "this is called approximate dynamic programming(adp ) .",
    "this paper is not doing true adp because in true adp we do not know what the @xmath0 function is and must therefore use indirect methods to approximate it .",
    "however , before we try to use srns as a component of an adp system , it makes sense to first test the ability of an srn to approximate a @xmath0 function , in principle .",
    "now we will try to explain what is the intuitive meaning of the bellman equation(equation(1 ) ) and the @xmath0 function according to the treatment taken from[2 ] .    to understand adp",
    ", one must first review the basics of classical dynamic programming , especially the versions developed by howard[28 ] and bertsekas .",
    "classical dynamic programming is the only exact and efficient method to compute the optimal control policy over time , in a general nonlinear stochastic environment .",
    "the only reason to approximate it is to reduce computational cost , so as to make the method affordable ( feasible ) across a wide range of applications .",
    "in dynamic programming , the user supplies a utility function which may take the form @xmath9  where the vector r is a representation or estimate of the state of the environment ( i.e. the state vector )  and a stochastic model of the plant or environment .",
    "then `` dynamic programming '' ( i.e. solution of the bellman equation ) gives us back a secondary or strategic utility function @xmath10 .",
    "the basic theorem is that maximizing @xmath11 yields the optimal strategy , the policy which will maximize the expected value of @xmath12 added up over all future time .",
    "thus dynamic programming converts a difficult problem in optimizing over many time intervals into a straightforward problem in short - term maximization . in classical dynamic programming ,",
    "we find the exact function @xmath0 which exactly solves the bellman equation . in adp",
    ", we learn a kind of `` model '' of the function @xmath0 ; this `` model '' is called a `` critic . ''",
    "( alternatively , some methods learn a model of the derivatives of @xmath0 with respect to the variables @xmath13 ; these correspond to lagrange multipliers , @xmath14 , and to the `` price variables '' of microeconomic theory .",
    "some methods learn a function related to @xmath0 , as in the action - dependent adaptive critic ( adac)[29 ] .      to understand the human brain scientifically , we must have some suitable mathematical concepts . since the human brain makes decisions like a control system ,",
    "it is an example of an intelligent control system .",
    "neuroscientists do not yet understand the general ability of the human brain to learn to perform new tasks and solve new problems even though they have studied the brain for decades .",
    "some people compare the past research in this field to what would happen if we spent years to study radios without knowing the mathematics of signal processing .",
    "we first need some mathematical ideas of how it is possible for a computing system to have this kind of capability based on distributed parallel computation .",
    "then we must ask what are the most important abilities of the human brain which unify all of its more specific abilities in specific tasks .",
    "it would be seen that the most important ability of brain is the ability to learn over time how to make better decisions in order to better maximize the goals of the organism . the natural way to imitate",
    "this capability in engineering systems is to build systems which learn over time how to make decisions which maximize some measure of success or utility over future time . in this context ,",
    "dynamic programming is important because it is the only exact and efficient method for maximizing utility over future time . in the general situation , where random disturbances and nonlinearity are expected ,",
    "adp is important because it provides both the learning capability and the possibility of reducing computational cost to an affordable level .",
    "for this reason , adp is the only approach we have to imitating this kind of ability of the brain .",
    "the similarity between some adp designs and the circuitry of the brain has been discussed at length in [ 10 ] and [ 11 ] .",
    "for example , there is an important structure in the brain called the limbic system which performs some kinds of evaluation or reinforcement functions , very similar to the functions of the neural networks that must approximate the @xmath0 function of dynamic programming .",
    "the largest part of the limbic system , called the hippocampus , is known to possess a higher degree of local recurrency[8 ] .    in",
    "general , there are two ways to make classical controllers stable despite great uncertainty about parameters of the plant to be controlled .",
    "for example , in controlling a high speed aircraft , the location of the center of the gravity is not known .",
    "the center of gravity is not known exactly because it depends on the cargo of the air plane and the location of the passengers .",
    "one way to account for such uncertainties is to use adaptive control methods .",
    "we can get similar results , but more assurance of stability in most cases[16 ] by using related neural network methods , such as adaptive critics with recurrent networks .",
    "it is like adaptive control but more general .",
    "there is another approach called robust control or @xmath15 control , which trys to design a fixed controller which remains stable over a large range in parameter space . baras and patel[31 ] have for the first time solved the general problem of @xmath15 control for general partially observed nonlinear plants .",
    "they have shown that this problem reduces to a problem in nonlinear , stochastic optimization .",
    "adaptive dynamic programming makes it possible to solve large scale problems of this type .",
    "adp systems already exist which perform relatively simple control tasks like stabilizing an aircraft as it lands under windy conditions [ 12 ] . however",
    "this kind of task does not really represent the highest level of intelligence or planning .",
    "true intelligent control requires the ability to make decisions when future time periods will follow a complicated , unknown path starting from the initial state .",
    "one example of a challenge for intelligent control is the problem of navigating a maze which we will discuss in chapter 4 .",
    "a true intelligent control system should be able to learn this kind of task .",
    "however , the adp systems in use today could never learn this kind of task .",
    "they use conventional neural networks to approximate the @xmath0 function . because the conventional mlp can not approximate such a @xmath0 function",
    ", we may deduce that adp system constructed only from mlps will never be able to display this kind of intelligent control .",
    "therefore , it is essential that we can find a kind of neural network which can perform this kind of task .",
    "as we will show , the srn can fill this crucial gap .",
    "there are additional reasons for believing that the srn may be crucial to intelligent control as discussed in chapter 13 of [ 9 ] .",
    "there is a huge literature on recurrent networks .",
    "biologists have used many recurrent models because the existence of recurrency in the brain is obvious .",
    "however , most of the recurrent networks implemented so far have been classic style recurrent networks , as shown on the left hand of figure 2 .",
    "most of these networks are formulated from ordinary differential equation(ode ) systems .",
    "usually their learning is based on a restricted concept of hebbian learning .",
    "originally in the neural network field , the most popular neural networks were recurrent networks like those which hopfield[14 ] and grossberg[15 ] used to provide associative memory .",
    "associative memory networks can actually be applied to supervised learning .",
    "but in actuality their capabilities are very similar to those of look - up tables and radial basis functions .",
    "they make predictions based on similarity to previous examples or prototypes .",
    "they do not really try to estimate general functional relationships . as a result",
    "these methods have become unpopular in practical applications of supervised learning .",
    "the theorems of barron discussed in the introduction show that mlps do provide better function approximation than do simple methods based on similarity .",
    "there has been substantial progress in the past few years in developing new associative memory designs .",
    "nevertheless , the mlp is still better for the specific task of function approximation which is the focus of this paper .    in a similar way",
    ", classic recurrent networks have been used for tasks like clustering , feature extraction and static function optimization .",
    "but these are different problems from what we are trying to solve here .",
    "actually the problem of static optimization will be considered in future stages of this research .",
    "we hope that the srn can be useful in such applications after we have used it for supervised learning .",
    "when people use the classic hopfield networks for static optimization , they specify all the weights and connections in advance[14 ] .",
    "this has limited the success of this kind of network for large scale problems where it is difficult to guess the weights . with the srn",
    "we have methods to train the weights in that kind of structure .",
    "thus the guessing is no longer needed . however , to use srns in that application requires refinement beyond the scope of this paper .",
    "there have also been researchers using ode neural networks who have tried to use training schemes based on a minimization of error instead of hebbian approaches . however , in practical applications of such networks , it is important to consider the clock rates of computation and data sampling .",
    "for that reason , it is both easier and better to use error minimizing designs based on discrete time rather than ode .",
    "if the importance of neural networks is measured by the number of words published , then the classic networks dominate the field of recurrent networks .",
    "however , if the value is measured based on economic value of practical application , then the field is dominated by time - lagged recurrent networks(tlrns ) .",
    "the purpose of the tlrn is to predict or classify time - varying systems using recurrency as a way to provide memory of the past .",
    "the srn has some relation with the tlrn but it is designed to perform a fundamentally different task .",
    "the srn uses recurrency to represent more complex relationships between one input vector @xmath16 and one output @xmath17 without consideration of the other times @xmath18 .",
    "figure 3 and figure 4 show us more details about the tlrn and the srn .    in control applications",
    ", @xmath19 represents the control variables which we use to control the plant . for example , if we design a controller for a car engine , the @xmath16 variables are the data we get from our sensors .",
    "the @xmath19 variables would include the valve settings which we use to try to control the process of combustion .",
    "the @xmath8 variables provide a way for the neural networks to remember past time cycles , and to implicitly estimate important variables which can not be observed directly .",
    "in fact , the application of tlrns to automobile control is the most valuable application of recurrent networks ever developed so far .",
    "a simultaneous recurrent network(figure 4 ) is defined as a mapping :    @xmath20    which is computed by iterating over the following equation :    @xmath21    where @xmath22 is some sort of feed - forward network or system , and @xmath23 is defined as :    @xmath24    when we use @xmath23 in this paper , we use @xmath25 instead of @xmath26 here .    in figure 4 ,",
    "the outputs of the neural network come back again as inputs to the same network .",
    "however , in concept there is no time delay .",
    "the inputs and outputs should be simultaneous .",
    "that is why it is called a simultaneous recurrent network(srn ) . in practice ,",
    "of course , there will always be some physical time delay between the outputs and the inputs .",
    "however if the srn is implemented in fast computers , this time delay may be very small compared to the delay between different frames of input data .    in figure 4",
    ", @xmath27 refers to the input data at the current time frame @xmath18 .",
    "the vector @xmath28 represents the temporary output of the network , which is then recycled as an additional set of inputs to the network . at the center of",
    "the srn is actually the feed - forward network which implements the function @xmath22 .",
    "( in designing an srn , you can choose any feed - forward network or system as you like .",
    "the function @xmath22 simply describes which network you use ) .",
    "the output of the srn at any time @xmath18 is simply the limit of the temporary output @xmath28 .    in equation ( 3 ) and ( 4 ) , notice that there are two integers  @xmath29 and @xmath18  which could both represent some kind of time .",
    "the integer @xmath18 represents a slower kind of time cycle , like the delay between frames of incoming data .",
    "the integer @xmath29 represents a faster kind of time , like the computing cycle of a fast electronic chip .",
    "for example , if we build a computer to analyze images coming from a movie camera , `` @xmath18 '' and `` @xmath30 '' represent two successive incoming pictures with a movie camera .",
    "there are usually only 32 frames per second .",
    "( in the human brain , it seems that there are only about 10 frames per second coming into the neocortex . )",
    "but if we use a fast neural network chip , the computational cycle  the time between `` @xmath29 '' and `` @xmath31 ''  could be as small as a microsecond .",
    "in actuality , it is not necessary to choose between time - lagged recurrency ( from @xmath18 to @xmath30 ) and simultaneous recurrency ( from @xmath29 to @xmath31 ) .",
    "it is possible to build a hybrid system which contains both types of recurrency .",
    "this could be very useful in analyzing data like movie pictures , where we need both memory and some ability to segment the images .",
    "[ 9 ] discusses how to build such a hybrid .",
    "however , before building such a hybrid , we must first learn to make srns work by themselves .",
    "finally , please note that the tlrn is not the only kind of neural network used in predicting dynamical systems .",
    "even more popular is the time delayed neural network(tdnn ) , shown in figure 5 .",
    "the tdnn is popular because it is easy to use .",
    "however , it has less capability , in principle , because it has no ability to estimate unknown variables .",
    "it is especially weak when some of these variables change slowly over time and require memory which persists over long time periods .",
    "in addition , the tlrn fits the requirements of adp directly , while the tdnn does not[9][16 ] .",
    "there are many types of training that have been used for recurrent networks .",
    "different types of training give rise to different kinds of capabilities for different tasks .",
    "for the tasks which we have described for the srn and the tlrn , the proper forms of training all involve some calculation of the derivatives of error with respects to the weights . usually after these derivatives are known , the weights are adapted according to a simple formula as follows :    @xmath32    where @xmath33 is called the learning rate",
    ".    there are five main ways to train srns , all based on different methods for calculating or approximating the derivatives .",
    "four of these methods can also be used with tlrns .",
    "some can be used for control applications .",
    "but the details of those applications are beyond the scope of this paper .",
    "these five types of training are listed in figure 6 . for this paper , we have used two of these methods : backpropagation through time(btt ) and truncation .",
    "the five methods are :    \\1 .",
    "backpropagation through time(btt ) . this method and forward propagation are the two methods which calculate the derivatives exactly .",
    "btt is also less expensive than forward propagation .",
    "this is the simplest and least expensive method .",
    "it uses only one simple pass of backpropagation through the last iteration of the model .",
    "truncation is probably the most popular method used to adapt srns even though the people who use it mostly just call it ordinary backpropagation .",
    "simultaneous backpropagation .",
    "this is more complex than truncation , but it still can be used in real time learning .",
    "it calculates derivatives which are exact in the neighborhood of equilibrium but it does not account for the details of the network before it reaches the neighborhood of equilibrium .",
    "error critics(shown in figure 7 ) .",
    "this provides a general approximation to btt which is suitable for use in real - time learning[9 ] .",
    "forward propagation .",
    "this , like btt , calculates exact derivatives .",
    "it is often considered suitable for real - time learning because the calculations go forward in time . however , when there are @xmath29 neurons and @xmath34 connections , the cost of this method per unit of time is proportional to @xmath35 . because of this high cost , forward propagation is not really brain - like any more than btt .      btt is a general method for calculating all the derivative of any outcome or result of a process which involves repeated calls to the same network or networks used to help calculate some kind of final outcome variable or result @xmath36 . in some applications ,",
    "@xmath36 could represent utility , performance , cost or other such variables .",
    "but in this paper , @xmath36 will be used to represent error .",
    "btt was first proposed and implemented in [ 17 ] .",
    "the general form of btt is as follows : + for @xmath37 to @xmath38 do forward@xmath39calculation(@xmath40 ) ; + calculate result @xmath36 ; + calculate direct derivatives of @xmath36 with respect to outputs of forward calculations ; + for @xmath41 to 1 backpropagate through forwards@xmath39calculation(@xmath40 ) , calculating running totals where appropriate .",
    "these steps are illustrated in figure 8 .",
    "notice that this algorithm can be applied to all kinds of calculations .",
    "thus we can apply it to cases where @xmath40 represents data frames @xmath18 as in the tlrns , or to cases where @xmath40 represents internal iterations @xmath29 as in the srns .",
    "also note that each box of calculation receives input from some dashed lines which represent the derivatives of @xmath36 with respect to the output of the box . in order to calculate the derivatives coming out of each calculation box ,",
    "one simply uses backpropagation through the calculation of that box starting out from the incoming derivatives .",
    "we will explain in more detail how this works in the srn case and the tlrn case .",
    "so far as we know btt has been applied in published working systems for tlrns and for control , but not yet for srns until now .",
    "however , rumelhart , hinton and williams[18 ] did suggest that someone should try this .",
    "the application of btt for tlrns is described at length in [ 2 ] and [ 9 ] .",
    "the procedure is illustrated in figure 9 . in this example",
    "the total error is actually the sum of error over each time @xmath18 where @xmath18 goes from 1 to @xmath38 .",
    "therefore the outputs of the tlrn at each time @xmath18 @xmath42 have two ways of changing total errors :    ( 1)a direct way when the current predictions @xmath43 are different from the current targets @xmath17 ;    ( 2)an indirect way based on the impact of @xmath8 on errors in later time periods",
    ".    therefore the derivative feedback coming into the tlrn is actually the sum of two feedbacks from two different sources . as a technical detail , note that @xmath44 needs to be specified somehow .",
    "however , we will not discuss this point here because the focus of this paper is on srns .",
    "figure 10 shows the application of btt to training an srn .",
    "this figure also provides some explanation of our computer code in the appendix . in this figure ,",
    "the left - hand side(the solid arrows ) represents the neural network which predicts our desired output @xmath45 .",
    "( in our example , @xmath45 represents the true values of the @xmath0 function across all points in the maze ) . each box on the left represents a call to a feed - forward system .",
    "the vector @xmath16 represents the external inputs to the entire system . in our case , @xmath16 consists of two variables , indicating which squares in the maze contain obstacles and which contains the goal respectively . for simplicity ,",
    "we selected the initial vector @xmath46 as a constant vector as we will describe below .",
    "each call to the feed - forward system includes calls to a subroutine which implements the generalized mlp .    on the right - hand side of figure 10",
    ", we illustrate the backpropagation calculation used to calculate the derivatives . for the srn , unlike the tlrn , the final error depends directly only on the output of the last iteration .",
    "therefore the last iteration receives feedback only from the final error but the other iterations receive feedback only from the iterations just after them .",
    "each box on the right - hand side represents a backpropagation calculation through the feed - forward system on its left .",
    "the actual backpropagation calculation involves multiple calls to the dual subroutine @xmath47 , which is similar to a subroutine in chapter 8 of [ 2 ] .",
    "notice that the derivative calculation here costs about the same amount as the forward calculation on the left - hand side .",
    "thus btt is very inexpensive in terms of computer time .",
    "however , the backpropagation calculations do require the storage of many intermediate results .",
    "also we know that the human brain does not perform such extended calculations backward through time . therefore btt is not a plausible model of true brain - like intelligence .",
    "we use it here because it is exact and therefore has the best chance to solve this difficult problem never before solved . in future research",
    ", we may try to see whether this problem can also be solved in a more brain - like fashion .",
    "truncation is probably the most popular method to train srns even though the term truncation is not often used .",
    "for example , the `` simple recurrent networks '' used in psychology are typically just srns adapted by truncation[19 ] .",
    "strictly speaking there are two kinds of truncation  ordinary one - step truncation(figure 11 ) and multi - step truncation which is actually a form of btt .",
    "ordinary truncation is by far the most popular . in the derivative calculation of ordinary truncation ,",
    "the memory inputs to the last iteration are treated as if they were fixed external inputs to the network . in truncation",
    "there is only one pass of ordinary backpropagation involving only the last iteration of the network .",
    "many people have adapted recurrent networks in this simple way because it seems so obvious .",
    "however , the derivatives calculated in this way are not exactly the same because they do not totally represent the impact of changing the weights on the final error .",
    "the reason for this is that changing the weights will change the inputs to the final iteration .",
    "it is not right to treat these inputs as constants because they are changed when the weights are changed .",
    "the difference between truncation and btt can be seen even in a simple scalar example , where n=2 and the feed - forward calculation is linear . in this case , the feed - forward calculation is :    @xmath48    @xmath49    in additon ,    @xmath50    @xmath51    in truncation , we use equation ( 8) and deduce :    @xmath52    but for a complete calculation , we substitute ( 7 ) into ( 8) , deriving :    @xmath53    which yields :    @xmath54    the result in equation(11 ) is usually different from the result in equation(13 ) , which is the true result , and comes from btt . depending on the value of @xmath55 ,",
    "these results could even have opposite signs .    in this paper",
    ", we have tried to used truncation because it is so easy and so popular .",
    "if truncation had worked , it would be the easiest way to solve this problem .",
    "however , it did not work .",
    "simultaneous backpropagation is a method developed independently in different forms by werbos , almeida and pineda[20][21][22 ] .",
    "the most general form of this method for srns can be found in chapter 3 of[9 ] and in [ 23 ] .",
    "this method is guaranteed to converge to the exact derivatives for the neighborhood of the equilibrium @xmath56 in the case where the forward calculations have reached equilibrium[20 ] .    as with btt ,",
    "the derivative calculations are not expensive .",
    "unlike btt there is no need for intermediate storage or for calculation backward through time .",
    "therefore simultaneous backpropagation could be plausible as a model of learning in the brain .",
    "on the other hand , these derivative calculations do not account for the details of what happened in the early iterations .",
    "unlike btt , they are not guaranteed to be exact in the case where the final @xmath57 is not an exact equilibrium . even in modeling the brain there",
    "may be some need to train srns so as to improve the calculation in early iterations . in summary , though simultaneous backpropagation may be powerful enough to solve this problem , there was sufficient doubt that we decided to wait until later before experimenting with this method .",
    "the error critic , like simultaneous backpropagation , provides approximate derivatives .",
    "unlike simultaneous backpropagation , it has no guarantee of yielding exact results in equilibrium . on the other hand , because it approximates btt directly in a statistically consistent manner , it can account for the early iterations .",
    "chapter 13 of [ 9 ] has argued that the error critic is the only plausible model for how the human brain adapts the tlrns in the neocortex .",
    "it would be straightforward in principle to apply the error critic to training srns as well .",
    "figure 7 shows the idea of an error critic for tlrns .",
    "this figure should be compared with figure 10 .",
    "the dashed input coming into the tlrn in figure 7 is intended to be an approximation of the same dashed line coming into the tlrn in the figure 9 . in effect , the error critic is simply a neural network trained to approximate the complex calculations which lead up to that dashed line in the figure 8 . the line which ends as the dashed line in figure 7 begins as a solid line because those derivatives are estimated as the ordinary output of a neural network , the error critic . in order to train the error critic to output such approximations",
    ", we use the error calculation illustrated on the lower right of figure 7 . in this case , the output of the error critic from the previous time period is compared against a set of targets coming from the tlrn .",
    "these targets are simply the derivatives which come out of the tlrn after one pass of backpropagation starting from these estimated derivatives from the later time period",
    ". this kind of training may seem a bit circular but in fact it has an exact parallel to the kind of bootstrapping used in the well known designs for adaptive critics or adp .    as with simultaneous backpropagation",
    ", we intend to explore this kind of design in the future , now that we have shown how srns can in fact solve the maze problem .",
    "the major characteristics of this method have been described above .",
    "this method has been independently rediscovered many times with minor variations .",
    "for example , in 1981 werbos called it conventional perturbation[2 ] .",
    "williams has called it the williams  zipser method[5 ] .",
    "narendra has called it dynamic backpropagation .    nevertheless , because this method is more expensive than btt , has no performance advantage over btt , and is not plausible as a model of learning in the brain , we see no reason to use this method .",
    "in this paper we use two examples to show that the srn design has more general function approximation capabilities than does the mlp .",
    "our primary focus was on the maze problem because of its relation to intelligent control as discussed in chapters 1 and 2 .",
    "however , before studying this more specialized example , we performed a few experiments on a more general problem which we call net a / net b. this chapter will discuss these two problems in more detail .      in the net a / net b problem ,",
    "our fundamental goal is to explore the idea that the functions that an mlp can approximate are a subset of what an srn can . in other words",
    ", we hypothesize that an srn can learn to approximate any functions which an mlp can represent without adding too much complexity , but not vice versa . to consider the functions which an mlp can represent",
    ", we can simply sample a set of randomly selected mlps , and then test the ability of srns to learn those functions .",
    "similarly we can generate srns at random and test the ability of mlps to learn to approximate the srns .    in order to implement this idea",
    ", we used the approach shown in figure 12 . the first step in",
    "the process was to pick net a at random .",
    "in some experiments , net a was an srn , while in the other experiments , it was an mlp .",
    "in all these experiments , net b was chosen to be the opposite kind of network from net a. in picking net a , we always used the same feed - forward structure .",
    "but we used a random number generator to set the weights .",
    "after net a was chosen and net b was initialized , we generated a stream of random inputs between -1 and + 1 following a uniform distribution .",
    "for each set of inputs , we trained net b to try to imitate the output of net a. of course net a was fixed .",
    "the results gave an indication of the ability of net b to approximate net a.    our preliminary experiments did show that the srns have some advantage over the mlps .",
    "however , in all of these experiments , the srn was trained with truncation , not btt . to fully explore all the theoretical issues would require a much larger set of computer runs . still , these initial experiments were very useful in testing some general computer code in order to prepare for the complexities of the maze problem .      in the classic form of the maze problem ,",
    "a little robot is asked to find the shortest path from the starting position to a goal position on a two - dimensional surface where there are some obstacles . for simplicity , this surface is usually represented as a kind of chess board or grid of squares in which every square is either clear or blocked by an obstacle . in formal terms",
    ", this means that we can describe the state of the maze by providing three pieces of information : + ( 1 ) an array @xmath58[iy]$ ] which has the value 0 when the square is clear and 1 when it is covered by an obstacle ; + ( 2 ) the coordinates of the goal ; + ( 3 ) the coordinates of the starting square . + in our case , we used a large number to represent the obstacles .    as discussed in the introduction ,",
    "many researchers have trained neural networks to learn an individual maze[5 ] .",
    "our goal was to train a network to input the array @xmath55 and to output @xmath59[iy]$ ] for all the clear squares . according to dynamic programming ,",
    "the best strategy of motion for a robot is simply to move to that neighboring square which has the smallest @xmath0 .",
    "this more general problem has not been solved before with neural networks .",
    "for example , houillon etc[24 ] initially attempted to solve this problem with mlps , but were unsuccessful .",
    "widrow in several plenary talks has reported that his neural truck backer upper has some ability to see and avoid obstacles . however",
    ", this ability was based on an externally developed potential function which was not itself learned by neural networks .",
    "such potential functions are analogous to the @xmath0 function which we are trying to learn .    in fact , this maze problem",
    "can always be solved directly and economically by dynamic programming .",
    "why then do we bother to use a neural network on this problem ?",
    "the reason for using this test is not because this simple maze is important for its own sake , but because this is a very difficult problem for a learning system , and because the availability of the correct solution is very useful for testing .",
    "it is one thing for a human being to know the answer to a problem .",
    "it is a different thing to build a learning system which can figure out the answer for itself .",
    "once the simple maze problem is fully conquered , we can then move on to solve more difficult navigation problems which are too complex for exact dynamic programming .    in order to represent the maze problem as a problem for supervised learning , we need to generate both the inputs to the network(the array @xmath55 ) and the desired outputs(the array @xmath60)(refer to the appendix ) . for this basic experiment",
    ", we chose to study the example maze shown in figure 13 .",
    "in this figure , @xmath61 represents the goal position , which is assigned a value of `` 1 '' ; the other numbers represent the true values of the @xmath0 function as calculated by dynamic programming ( subroutine `` synthesis '' in the attached code in the appendix ) .",
    "intuitively each @xmath0 value represents the length of the shortest path from that square to the goal .",
    "initially we chose to study this particular maze because it poses some very unique difficulties .",
    "in particular there are four equally good directions starting from one of these squares in this maze  a feature which can be very confusing to neural networks , even human .",
    "if we had used a fully connected conventional neural network , then the use of a single test maze would have led to over - training and meaningless results . however , as we will discuss later in this chapter , we constrained all of our networks to prevent this problem",
    ". nevertheless , a major goal of our future research will be to test the ability of srns to predict new mazes after training on different mazes .",
    "this problem of maze navigation has some similarity to the problem of connectedness described by minsky[25 ] . logically we know that the desired output in any square can depend on the situation in any other square",
    "therefore , it is hard to believe that a simple feed - forward calculation can solve this kind of problem . on the other hand , the bellman equation(equation(1 ) ) itself is a simple recurrent equation based on relationships between `` neighboring''(successive ) states .",
    "therefore it is natural to expect that a recurrent structure could approximate a @xmath0 function .",
    "the empirical results in this paper confirm these expections .",
    "the architecture and learning used for the net a / net b problem were all very standard .",
    "they will be discussed briefly in section 5.1 .",
    "the bulk of this chapter will then describe the two special feature  cellular architecture and adaptive learning rate(alr ) used for the maze problem .      in all these experiments ,",
    "the mlp network and the feed - forward network @xmath22 in the srn was a standard mlp with two hidden layers .",
    "the input vector @xmath27 consisted of six numbers between -1 and + 1 .",
    "the two hidden layers and the output layers all had three neurons .",
    "the initial weights were chosen at random according to a uniform distribution between -1 and + 1 .",
    "training was done by standard backpropagation with a learning rate of @xmath62 .        in theoretical terms ,",
    "weight - sharing is a generalized technique for exploiting prior knowledge about some symmetry in the function to be approximated .",
    "weight - sharing has sometimes been called `` windowing '' or `` lie group '' techniques .    weight - sharing has been used almost exclusively for applications like character recognition or image processing where the inputs form a two - dimensional array of pixels[3][26 ] . in our maze problem",
    "the inputs and outputs also form arrays of pixels .",
    "weight - sharing leads to a reduction in the number of weights .",
    "fewer weights lead in turn to better generalization and easier learning .",
    "as an example , suppose that we have an array of hidden neurons with voltages @xmath63[iy]$ ] , while the input pixels form an array @xmath64[iy]$ ] .",
    "in that case , the voltages for a conventional mlp would be determined by the equation :    @xmath65[j]={\\sum_{ix , iy } w(i , j , ix , iy)*x(ix , iy)}\\ ] ]    thus if each array has a size @xmath66 , the weights form an array of size @xmath67 .",
    "this means 160,000 weights  a very big problem . in basic weight - sharing , this equation would be replaced by :    @xmath65[j]={\\sum_{d1,d2 } w(d1,d2)*x(i+d1,i+d2)}\\ ] ]    furthermore , if @xmath68 and @xmath69 are limited to an range like @xmath70 $ ] , then the number of weights can be reduced to just over 100 .",
    "actually this would make it possible to add two or three additional types of hidden neurons without exceeding 1,000 weights .",
    "this trick was used by guyon etc[3 ] .",
    "they used it to develop the most successful zip code digit recognizer in existence .",
    "intuitively @xmath71 justified this idea by arguing that similar patterns in different locations have similar meanings .",
    "however , there is a more rigorous mathematical justification for this procedure as we will see .",
    "the technique of weight - sharing in neural networks is really just a special case of the lie - group method pioneered much earlier by laveen kanal and others in image processing . formally speaking",
    ", if we know that the function @xmath72 to be approximated must obey a certain symmetry requirement then we can impose the same symmetry on the neural network which we use to approximate @xmath72 .",
    "more preciously , if @xmath73 always implies that @xmath74 , where @xmath75 is some kind of simple linear transformation , then we can require that the neural network possess the same symmetry .    both in image processing and in the maze problem , we can use the symmetry with respect to those transformations @xmath75 which move all the pixels by the same distance to the left , to the right or up and down . in the language of physics ,",
    "these are called spatial translations .",
    "because we know that the best form of the neural network must also obey this symmetry , we have nothing to lose by restricting our weights as required by the symmetry .      in order to exploit lie group symmetry in a rigorous way , we first reformulated the task to be solved so as to ensure exact lie group symmetry . to do this , we designed our neural network to solve the problem of maze defined over a torus . for our purposes ,",
    "a torus was simply an @xmath76 by @xmath76 square where the right - hand neighbor of @xmath77 $ ] is the point @xmath78 $ ] , and likewise for the other edges .",
    "this system can still solve an ordinary maze as in figure 13 , where the maze is surrounded by walls of obstacles .",
    "next we used a cellular structure for our neural network including both the mlps and srns .",
    "a cellular structure means that the network is made up of a set of cells each made up of a set of neurons .",
    "there is one cell for each square in the maze .",
    "the neurons and the weights in each cell are the same as those in any other cell . only the inputs and outputs are different because they come from different locations .    the general idea of our design",
    "is shown in figure 14 .",
    "notice that each cell is made up of two parts : a connector part and a local memory part which includes 4 neighbors and the memory from itself in fingure 15 .",
    "the connector part receives the inputs to the cell and transmits its output to all four neighboring cells .",
    "in addition , the local memory part sends all its outputs back as inputs , but only to the same cell . finally the forecast of @xmath0",
    "is based on the output of the local memory part .",
    "the exact structure which we used is shown completely in figure 15 . in this figure",
    "it can be seen that each cell receives 11 inputs on each iteration .",
    "two of these inputs represent the goal and obstacle variables , @xmath58[iy]$ ] and @xmath79[iy]$ ] , for the current pixel .",
    "the next four inputs represent the outputs of the connector neuron from the four neighboring cells from the previous iteration .",
    "the final five inputs are simply the outputs of the same cell from the previous iteration .",
    "then after the inputs , there are only five actual neurons .",
    "the connector part is only one neuron in our case .",
    "the local memory part is four neurons .",
    "the prediction of @xmath59[iy]$ ] results from multiplying the output of the last neuron by @xmath80 , a weight used to rescale the output .    to complete this description",
    ", we must specify how the five active neurons work . in this case",
    ", each neuron takes inputs from all of the neurons to its left , as in the generalized mlp design[2 ] .",
    "except for @xmath81 , all of the inputs and outputs range between -1 and 1 , and the tanh function is used in place of the usual sigmoid function .",
    "to initialize the srn on iteration zero , we simply picked a reasonable looking constant vector for the first four neurons out of the five .",
    "we set the initial starting value to -1 . for the last neuron",
    ", we set it to 0 . in future work",
    ", we shall probably experiment with the adaptation of the starting vector @xmath46 .    in order to backpropagate through this entire cellular structure ,",
    "we simply applied the chain rule for ordered derivatives as described in [ 2 ] .      in our initial experiments with this structure ,",
    "we used ordinary dynamic programming with only one special trick .",
    "the trick was that we set the number of iterations for srn to only 1 on the first 20 trials , and then to 2 for the next 20 trials ... and so on up until there were 20 iterations .",
    "we found that ordinary weight adjustment led to extremely slow learning due to oscillation .",
    "this was not totally unexpected because slow learning and oscillation are a common result of simple steepest descent methods .",
    "there are many methods available to accelerate the learning .",
    "some of these like the dekf method developed by ford motor company are similar to quasi - newton methods[27 ] which are very powerful but also somewhat expensive . for this work we chose to use a method called the adaptive learning rate(alr ) as described in chapter 3 of [ 9 ] .",
    "this method is relatively simple and cheap , but far more flexible and powerful than other simple alternatives .    in this method",
    ", we maintain a single adapted learning rate for each group of weights .",
    "in this case , we chose three groups of weights : + 1 .",
    "the weight @xmath80 used for rescaling of the output ; + 2 .",
    "the constant or bias weights @xmath82 ; + 3 . all the other weights @xmath83 . + for each group of weights the learning rate is updated on each trial according to the following formula :    @xmath84    where the sum over @xmath40 actually refers to the sum over all weights in the same group . in addition , to prevent overshoot , we would reset the learning rate to :    @xmath85    where the sum is taken over all weights . in this special case",
    "where the error on the next iteration would be predicted to be less than zero , i.e. :    @xmath86    where @xmath87 is the new value for the weights which would be used if the learning rates were not reset . in our case , we modified this procedure slightly to apply it separately to each group of weights .",
    "after the adaptive learning rates were installed the process of learning became far more reliable .",
    "nevertheless , because of the complex nature of the function @xmath0 , there was still some degree of local minimum problem . for our purposes",
    ", it was good enough to simply try out a handful of initial values which we guessed at random .",
    "however , in future research , we would like to explore the concept of shaping as described in [ 9 ] .",
    "in this chapter , we will see some simulation results for the two test problems discussed before . from analyzing the results",
    ", we can conclude that compared to the mlps , the srns are more powerful in nonsmooth function approximation .",
    "in addition , our new design  the cellular structure  can really solve the maze problem .      from figure 16 to figure 19 we can see that the srn using the same three - layered neural network structure(9 inputs , 3 outputs , and 3 neurons for each hidden layer ) as the mlp can achieve better simulation result .",
    "the srn not only converged more rapidly than the mlp(figure 16 and figure 17 , but also reached a smaller error(figure 18 and figure 19 ) , about @xmath88 , while the mlp reached @xmath89 .",
    "thus we can say that , in this typical case , an srn has better ability to learn an mlp than an mlp to learn an srn .",
    "there are two parts of the results for the maze problem .",
    "first , we compare the @xmath0 function in each pixels of the same maze as predicted by an srn trained by btt and an srn trained by truncation respectively with the actual j function for the maze .",
    "figure 20 and figure 21 show that the srn trained by btt can really approximate the @xmath0 function , but the srn trained by truncation can not .",
    "moreover , the srn trained by btt can learn the ability to find the optimal path from the start to the goal as calculated by dynamic programming .",
    "although there is some error in the approximation of @xmath0 by the srn trained by btt , the errors are small enough that a system governed by the approximation of @xmath0 would always move in an optimal direction .",
    "second , we show some error curves from figure 22 to figure 27 . from the figures we can see the error curve of srn trained by btt not only converged more rapidly than the curve of the srn trained by truncation , but also reached a much smaller level of error .",
    "the errors with the mlp did not improve at all after about 80 trials(figure 26 and figure 27 ) .      in this paper",
    ", we have described a new neural network design for @xmath0 function approximation in dynamic programming .",
    "we have tested this design in two test problems : net a / net b and the maze problem . in the net a/ net b problem , we showed that srns can learn to approximate mlps better than mlps can learn srns .    in the maze problem , a much more complex problem",
    ", we showed that we can achieve good results only by training an srn with a combination of btt and adaptive learning rates .",
    "in addition , we needed to use a special design  a cellular structure  to solve this problem . on the other hand , neither an mlp nor an srn trained by truncation could solve this problem .",
    "now that it has been proven that neural networks can solve these kinds of problems , the next step in research is to consider many variations of these problems in order to demonstrate generalization ability and the ability to solve optimization problems while the @xmath0 function is not known .",
    "* acknowledgments *    the work described herein was truly collaborative work .",
    "more than half of it was performed when both authors worked together at the university of maryland , college park , or a nearby location .",
    "neither author received any financial support covering the time when this paper was written ; however , this work would have been impossible without prior support and ongoing connections involving : the university of maryland ( prof .",
    "john s. baras and robert w. newcomb ) ; the national university of singapore ; the ieee singapore section ; scientific cybernetics inc . ; the international joint conference on neural networks ; the national science foundation of the u.s . and the national natural science foundation of china .    99    e. d. sontag , `` feedback stabilization using two - hidden - layer nets '' , _ ieee trans . neural networks _ , vol .",
    "3 , no.6 , 1992 .",
    "p. werbos , _ the roots of backpropagation : from ordered derivatives to neural networks and political forecasting _ , wiley , 1994 .",
    "i. guyon , i. poujaud , l. personnaz , g. dreyfus , j. denker , and y. le cun , `` comparing different neural network architectures for classifying handwritten digits '' , _ proceedings of the ieee international joint conference on neural networks _ , june 1989 .",
    "von der malsburg , c. & schneider , w. biol .",
    "_ cybernetic _ , vol .",
    "54 , pp .  29 - 40 , 1986 .",
    "w. miller , r. sutton & p. werbos ( eds . ) , _ neural networks for control _ , mit press , 1990 .    v. b. brooks , _ the neural basis of motor control _ , oxford press .",
    "k. pribram , _ brain and perception : holonomy and structure in fi+gural processing _ , erlbaum , 1991 .",
    "h. chang , w.j .",
    "freeman , `` parameter optimization in models of the olfactory neural system '' , _ neural networks _ ,",
    "vol . 9 , no",
    ". 1 , pp   1 - 14,1996 .",
    "d.white & d.sofge ( eds.),_handbook of intelligent control : neural , adaptive and fuzzy approaches _ , van nostrand , 1992 .",
    "p. werbos , `` the brain as a neurocontroller : new hypotheses and new experimental possibilities '' , in k.pribram ( eds . ) , _ origins : brain and self - organization _ , erlbaum , 1994 .",
    "p. werbos , `` learning in the brain : engineering interpretation '' , in k. pribram , ( eds . ) , _ learning as self - organization _ , erlbaum , 1996 .",
    "d. prokhorov , r. santiago & d. wunsch , `` adaptive critic designs : a case study for neurocontrol '' , _ neural networks _ , vol.8 , no.9 , 1995 .",
    "d.o.hebb,_organization of behavior _ , wiley , new york , 1949 .",
    "j. hopfield and d. tank,computing with neural circuits : a model  , _ science _ ,",
    "233 , pp .",
    "625 - 633 , 1986 .",
    "s. grossberg , _ the adaptive brain i _ , north - holland , 1987",
    ".    p. werbos , `` optimization methods for brain - like intelligent control '' , _ ieee conference on decision and control _ , 1995 .",
    "p. werbos , _ beyond regression : new tools for predictions and analysis in the behavioral science _ , ph.d .",
    "dissertation , committee on applied mathematics , harvard university , cambridge , ma , nov .",
    "d. rumelhart , g. hinton and r. williams , `` learning internal representations by error propagation '' , in d.rumelhart and j.mcclelland(eds . ) , _ parallel distributed processing _ , vol.1 , mit press , 1986 .",
    "l. fausett , _ fundamentals of neural networks : architectures , algorithms and applications _ , prentice hall , 1994",
    ".    p. werbos , `` generalization of backpropagation with application to a recurrent gas market model , neural networks '' , vol .",
    "1 , pp .  339 - 365 , 1988 .",
    "l. b. almeida , `` a learning rule for asynchronous perceptrons with feedback in a combinatorial environment '' , _ proceedings of the ieee international conference on neural networks _",
    ", 1987 .",
    "f. j. pineda , `` generalization of backpropagation to recurrent and higher oder networks '' in it proceedings of the ieee international conference on neural information processing systems , 1987 .",
    "p. werbos , `` supervised learning : can it escape its local minimum '' , _",
    "wcnn93 proceedings _ , erlbaum , 1993 .",
    "reprinted in v. roychowdhury et al ( eds . ) , _ theoretical advances in neural computation and learning _ , kluwer , 1994 .",
    "p. houillon and a. caron , `` planar robot control in cluttered space by artificial neural network '' , _ math modeling and science computing _ , vol .",
    "498502 , 1993 .",
    "m. l. minsky and s. a. papert , _ perceptrons _ , mit press , 1990 , expanded edition .",
    "t. maxwell , l. giles and y. c. lee , `` generalization in neural networks : the contiguity problem '' , _",
    "ieee first international conference on neural networks _ , 1987 .",
    "phua and s.b.w .",
    "chew , _ symmetric rank - one update and quasi - newton methods _ , _ optimization techniques and applications , proceedings of the international conference on optimization techniques and applications _ , k.h .",
    "phua et al .",
    ", eds . , world scientific , 1992 , singapore , pp .",
    "r. howard , _",
    "dynamic programming and markhov processes _ , mit press , cambridge , ma , 1960 .",
    "p. werbos , neural networks for control and system identification , _ ieee conference on decision and control_(florida ) , ieee , new york , 1989 .",
    "a. barron , `` asymptotically optimal functional estimation by minimum complexity criteria '' , _ proceedings of 1994 ieee international symposium on information theory _ , ieee , new york , 1994 .",
    "j. s. baras and n. s. patel , `` information state for robust control of set - valued discrete time systems '' , _ proceedings of 34th conference on decision and control _ , ieee , 1995 , p. 2302 .",
    ".... / * the program of the maze problem using srn trained by btt*/ / * using the srn trained by btt to learn the optimal path of a 5 * 5 maze :    * / / * learning rate adaptive   --- lr_ws , lr_w , lr_ww * / / * when change line 136 and 137 into p=0 then the program will be mlp*/ / * when change line 243 into f_x[n+i]=0 then the program will be the srn trined by truncation*/        void net(double w[30][30],double x[30],double ww[30 ] ,                  int n , int m , int n , double yhat[30 ] ) ; void synthesis(int b[30][30],int a[30][30],int n1,int n2 ) ; void pweight(double ws , double f_ws_t , double ww[30],double f_net_t[30 ] ,                  double w[30][30 ] , double f_w_t[30][30],int n , int n , int m ) ;                 double w[30][30],x[30],f_net_t[30],f_ws[30],f_w_o[30][30],f_w[30][30 ] ;          double f_w_t[30][30],f_net[30],ww[30],yy[21][12][8][8 ] ;          double yhat[30],f_y[21][12][8][8],f_x[30],f_jhat[30][30 ] ;          double s_f_w1,s_f_w2,lr_w , s_f_net1,s_f_net2,lr_ww , lr_ws , f_ws_o ;          double y[50][50],f_net_o[50 ] , f_ws1 , f_ws2,w_o[50][50],ww_o[50],ws_o ;          file * f ;            / * number of inputs , neurons and output:7,3,1 * /          / * ' n ' is the number of the active neurons * /           / * ' m ' and ' n ' both are the number of inputs * /          / * ' nm ' is the number of memory is : 5 * /          / * ' nn+1'*'nn+1 ' is the size of the maze ' * /          / * ' tt ' is the number of trials * /          / * ' lt ' is the number of the interval time * /          / * ' maxt ' is the max number for t in figure[8 ] * /          / * lr - ws , lr_ww and lr_w are the learning rates for ws , ww and w*/                   a=0.9 ; b=0.2 ;          n=5;m=11;n=11;nn=6;nm=5;tt=30000;lt=50;maxt=20;wi=25;ws=40 ;          e=0;po = pow(2,31 ) -1 ;            / * initial values of old   * /                   f_ws_o=1 ;          for(i = m+1;i < n+n+1;i++ )          {                 for(j=1;j <",
    "i;j++ )                          f_w_o[i][j]=1 ;                 f_net_o[i]=1 ;           }          lr_w = lr_ww = lr_ws=10 ;                   / * initial values of weights * /                   for ( i=1;i < n+n+1;i++ )                  x[i]=0 ;          for ( i = m+1;i < n+n+1;i++ )                  for ( j=0;j < i;j++ )                  {                          srand(rand ( ) ) ;                          w[i][j]=rand ( ) ;                          w[i][j]=0.2091 ;                  }          for ( i = m+1;i",
    "< n+n+1;i++ )          {                  srand(rand ( ) ) ;                  ww[i]=rand ( ) ;                  ww[i]=0.00678 ;          }            / * input maze * /                   n2=5 * 5 ;          n1=5 * 5 - 1 ;          for ( i=0;i<7;i++ )                  for(j=0;j<7;j++ )                  {                          if ( ( i==0)||(j==0)||(i==6)||(j==6 ) )                                  b[i][j]=n2 ;                          else                                  b[i][j]=n1 ;                  }          / * generate obstacle * /                        if((f = fopen(\"results5\",\"w\"))==null ) {          printf(\"cannot open file \" ) ;          exit(1 ) ;          }                   / * learning pattern * /                   for(t=0;t < tt;t++ )          {                  for(i = m+1;i < n+n+1;i++ )                  {                          for(j=1;j < i;j++ )                          {                                  f_w_t[i][j]=0 ;                          }                          f_net_t[i]=0 ;                  }                  for ( i=1;i < n;i++ )                          for(ix=0;ix < nn+1;ix++ )                                  for(iy=0;iy < nn+1;iy++ )                                          yy[0][i][ix][iy]=-1 ;                  for(ix=0;ix < nn+1;ix++ )                                  for(iy=0;iy < nn+1;iy++ )                                          yy[0][n][ix][iy]=0 ;              / * if the next two lines are changed into p=0 then it is mlp * /                  p=(t / lt)+1 ;                  p=(p < maxt ?",
    "p : maxt ) ;                  for(q=0;q <",
    "p+1;q++ )                  {                          e=0 ;                          for(ix=0;ix <",
    "nn+1;ix++ )                                  for(iy=0;iy <",
    "nn+1;iy++ )                                  {                                          if ( b[ix][iy]==25 )                                                  x[1]=b[ix][iy ] ;                                          else if ( b[ix][iy]!=1 )                                                  x[1]=0 ;                                          x[2]=1 ;                                          if ( ix!=0 )                                                  x[3]=yy[q][1][ix-1][iy ] ;                                          else                                                  x[3]=yy[q][1][nn][iy ] ;                                          if ( iy!=0 )                                                  x[4]=yy[q][1][ix][iy-1 ] ;                                          else                                                  x[4]=yy[q][1][ix][nn ] ;                                          if ( ix!=nn )                                                  x[5]=yy[q][1][ix+1][iy ] ;                                          else                                                  x[5]=yy[q][1][0][iy ] ;                                          if ( iy!=nn )                                                  x[6]=yy[q][1][ix][iy+1 ] ;                                          else                                                                           x[6]=yy[q][1][ix][0 ] ;                                          for ( i=1;i < n+1;i++ )                                                  x[6+i]=yy[q][i][ix][iy ] ;                                          net(w , x , ww , n , m , n , yhat ) ;                                          for ( i=1;i < n+1;i++ )                                                  yy[q+1][i][ix][iy]=yhat[i ] ;                                  }                  }                  e=0 ;                  for ( ix=0;ix < nn+1;ix++ )                          for(iy=0;iy <",
    "nn+1;iy++ )                          {                                  if ( t==(tt-1 ) )                                          y[ix][iy]=yy[p+1][n][ix][iy ] ;                                  if ( b[ix][iy]!=25 )                                          f_jhat[ix][iy]=ws*yy[p+1][n][ix][iy ]                                                          -a[ix][iy ] ;                                  else                                          f_jhat[ix][iy]=0 ;                                  e+=f_jhat[ix][iy]*f_jhat[ix][iy ] ;                          }                  printf(\"\\n t e % d % e\",t , e ) ;                  fprintf(f,\"\\n%d % e\",t , e ) ;                        for(q=1;q<21;q++ )                          for(ix=0;ix < nn+1;ix++ )                                  for(iy=0;iy < nn+1;iy++ )                                          for(i=1;i < n+1;i++ )                                                  f_y[q][i][ix][iy]=0 ;                  for(q = p;q>-1;q-- )                  {                          for ( ix=0;ix < nn+1;ix++ )                                  for(iy=0;iy < nn+1;iy++ )                                  {                                          if ( b[ix][iy]==25 )                                                  x[1]=b[ix][iy ] ;                                          else if ( b[ix][iy]!=1 )                                                  x[1]=0 ;                                          x[2]=1 ;                                          if ( ix!=0 )                                                  x[3]=yy[q][1][ix-1][iy ] ;                                          else                                                  x[3]=yy[q][1][nn][iy ] ;                                          if ( iy!=0 )                                                  x[4]=yy[q][1][ix][iy-1 ] ;                                          else                                                  x[4]=yy[q][1][ix][nn ] ;                                          if ( ix!=nn )                                                  x[5]=yy[q][1][ix+1][iy ] ;                                          else                                                  x[5]=yy[q][1][0][iy ] ;                                          if ( iy!=nn )                                                  x[6]=yy[q][1][ix][iy+1 ] ;                                          else                                                  x[6]=yy[q][1][ix][0 ] ;                                          for ( i=1;i < n+1;i++ )                                                  x[6+i]=yy[q][i][ix][iy ] ;                                          net(w , x , ww , n , m , n , yhat ) ;                                          if ( q==p )                                          {                                                  f_yhat = f_jhat[ix][iy ] ;                                                  for(i=1;i < n+1;i++ )                                                          f_x[n+i]=0 ;                                          }                                          else                                          {                                                  f_yhat=0 ;                                                  for(i=1;i < n+1;i++ )                                                    f_x[n+i]=f_y[q+1][i][ix][iy ] ;                                          }                                          f_net2(f_yhat , w , x , n , m , n , f_w , f_net ,                                                  f_ws , ws , f_x ) ;                                          if ( ix!=0 )                                                  f_y[q][1][ix-1][iy]+=f_x[3 ] ;                                          else                                                  f_y[q][1][nn][iy]+=f_x[3 ] ;                                          if ( iy!=0 )                                                  f_y[q][1][ix][iy-1]+=f_x[4 ] ;                                          else                                                  f_y[q][1][ix][nn]+=f_x[4 ] ;                                          if ( ix!=nn )                                                  f_y[q][1][ix+1][iy]+=f_x[5 ] ;                                          else                                                  f_y[q][1][0][iy]+=f_x[5 ] ;                                          if ( iy!=nn )                                                  f_y[q][1][ix][iy+1]+=f_x[6 ] ;                                          else                                                  f_y[q][1][ix][0]+=f_x[6 ] ;                                          for(i=1;i < n+1;i++ )                                                  f_y[q][i][ix][iy]+=f_x[6+i ] ;                                              for(i = m+1;i <",
    "n+n+1;i++ )                                          {                                                  for(j=1;j < i;j++ )                                                  {                                                          f_w_t[i][j]+=f_w[i][j ] ;                                                  }                                                  f_net_t[i]+=f_net[i ] ;                                          }                                  }                  }                  dot=0 ;                  for(i = m+1;i < n+n+1;i++ )                          for(j=1;j <",
    "i;j++ )                          {                                  dot+=f_w_o[i][j]*f_w_t[i][j ] ;                          }                                     s_f_w1=s_f_w2=0 ;                  for(i = m+1;i <",
    "n+n+1;i++ )                          for(j=1;j",
    "< i;j++ )                          {                                  s_f_w1 + = f_w_o[i][j ] * f_w_t[i][j ] ;                                  s_f_w2 + = f_w_o[i][j ] * f_w_o[i][j ] ;                                  s+=f_w_t[i][j]*f_w_t[i][j ] ;                          }                  if ( ( s_f_w1>s_f_w2 ) || ( s_f_w1==s_f_w2 ) )                          lr_w = lr_w*(a+b ) ;                  else if ( s_f_w1<(-2)*s_f_w2 )                          lr_w = lr_w*(a-2*b ) ;                       else                          lr_w = lr_w*(a+b*(s_f_w1/s_f_w2 ) ) ;                                     s_f_net1=s_f_net2=0 ;                  for(i = m+1;i <",
    "n+n+1;i++ )                  {                          s+=f_net_t[i]*f_net_t[i ] ;                          s_f_net1 + = f_net_o[i ] * f_net_t[i ] ;                          s_f_net2 + = f_net_o[i ] * f_net_o[i ] ;                  }                  if ( ( s_f_net1>s_f_net2 ) || ( s_f_net1==s_f_net2 ) )                          lr_ww = lr_ww*(a+b ) ;                  else if ( s_f_net1<(-2)*s_f_net2 )                          lr_ww = lr_ww*(a-2*b ) ;                       else                                   lr_ww = lr_ww*(a+b*(s_f_net1/s_f_net2 ) ) ;                  f_ws1=f_ws_o*f_ws_t ;                  f_ws2=f_ws_o*f_ws_o ;                  if ( ( f_ws1>f_ws2 ) || ( f_ws1==f_ws2 ) )                          lr_ws = lr_ws*(a+b ) ;                  else if ( f_ws1<(-2)*f_ws2 )                          lr_ws = lr_ws*(a-2*b ) ;                       else                             lr_ws = lr_ws*(a+b*(f_ws1/f_ws2 ) ) ;                  s+=f_ws_t*f_ws_t ;                  es = e / s ;                  if ( ( e - lr_w*s)<0 )                          lr_w = lr_w*es ;                  if ( ( e - lr_ww*s)<0 )                          lr_ww = lr_ww*es ;                   for(i = m+1;i < n+n+1;i++ )                  {                          for(j=1;j <",
    "i;j++ )                          {                                  w_o[i][j]=w[i][j ] ;                                  w[i][j]-=lr_w*f_w_t[i][j ] ;                          }                          ww_o[i]=ww[i ] ;                          ww[i]-=lr_ww*f_net_t[i ] ;                  }                  if ( ( e - lr_ws*s)<0 )                           lr_ws = lr_ws*es ;                  ws_o = ws ;                  ws-=lr_ws*f_ws_t ;                    sum=0 ;                  for(i = m+1;i < n+n+1;i++ )                  {                          for(j=1;j <",
    "i;j++ )                          {                                  f_w_o[i][j]=f_w_t[i][j ] ;                          }                          f_net_o[i]=f_net_t[i ] ;                  }                  f_ws_o = f_ws_t ;          }          fclose(f ) ; }                    / * calculating the utility * /          no = n2 - 3 - 1 ;          while ( k!=no )          {                  k=0 ;                  for(i=1;i<6;i++ )                          for(j=1;j<6;j++ )                          {                    mini = 1 + minimum(a[i-1][j],a[i][j-1],a[i+1][j],a[i][j+1 ] ) ;                                  if ( ( a[i][j]!=n2 ) & & ( a[i][j]!=1 ) )                                  {                                          if ( ( a[i][j]==mini ) & & ( a[i][j]!=n1 ) )                                                  k++ ;                                          else                                                  if ( mini!=n2 )                                                          a[i][j]=mini ;                                  }                          }          } }                  void f_net2(double f_yhat , double w[30][30],double x[30],int n , int m , int   n , double f_w[30][30],double f_net[30],double f_ws[30],double ws ,    double f_x[30 ] ) / * this subroutine calculates the f_w terms needed to adapt a fully connected * / / *       generalized mlp .",
    "it does not backpropagate through the network and it * / / *       does not permit the switching off of weights . * / {          int i , j ;          for ( i=1;i < n+1;i++ )                  f_x[i]=0 ;          f_x[n+n]+=f_yhat*ws ;          f_ws[1]=f_yhat*x[n+n ] ;          f_net[n+n]=f_x[n+n]*(1-x[n+n]*x[n+n])*0.5 ;          for ( j=1;j < n+n;j++ )                  f_w[n+n][j]=f_net[n+n]*x[j ] ;          for ( i = n+n-1;i > m;i-- )          {                  for ( j = i+1;j < n+n+1;j++ )                  {                          f_x[i]+=w[j][i]*f_net[j ] ;                  }                  f_net[i]=f_x[i]*(1-x[i]*x[i])*0.5 ;                  for ( j=1;j < i;j++ )                  {                          f_w[i][j]=f_net[i]*x[j ] ;                  }          }          for(i = m;i>0;i-- )                  for(j = m+1;j <",
    "n+n+1;j++ )                         f_x[i]+=w[j][i]*f_net[j ] ;        void pweight(double ws , double f_ws_t , double ww[30],double f_net_t[30 ] ,                  double w[30][30 ] , double f_w_t[30][30],int n , int n , int m ) {          int i , j ;          for(i = m+1;i <",
    "n+n+1;i++ )                  {                          for(j=1;j < i;j++ )                          {                                   printf(\"\\n w[i][j ] f_w_t % e % e\",w[i][j],f_w_t[i][j ] ) ;                          }                          printf(\"\\n ww f_net_t % e % e\",ww[i],f_net_t[i ] ) ;                  }                  printf(\"\\n ws f_ws_t % e % e\",ws , f_ws_t ) ;"
  ],
  "abstract_text": [
    "<S> this paper will show that a new neural network design can solve an example of difficult function approximation problems which are crucial to the field of approximate dynamic programming(adp ) . </S>",
    "<S> although conventional neural networks have been proven to approximate smooth functions very well , the use of adp for problems of intelligent control or planning requires the approximation of functions which are not so smooth . as an example </S>",
    "<S> , this paper studies the problem of approximating the @xmath0 function of dynamic programming applied to the task of navigating mazes in general without the need to learn each individual maze . </S>",
    "<S> conventional neural networks , like multi - layer perceptrons(mlps ) , can not learn this task . </S>",
    "<S> but a new type of neural networks , simultaneous recurrent networks(srns ) , can do so as demonstrated by successful initial tests . </S>",
    "<S> the paper also examines the ability of recurrent neural networks to approximate mlps and vice versa .    </S>",
    "<S> * keywords : * simultaneous recurrent networks(srns ) , multi - layer perceptrons(mlps ) , approximate dynamic programming , maze navigation , neural networks . </S>"
  ]
}