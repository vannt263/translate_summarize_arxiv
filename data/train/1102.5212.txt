{
  "article_text": [
    "with the advancement of modern technology , data sets which contain repeated measurements obtained on a dense grid are becoming ubiquitous .",
    "such data can be viewed as a sample of curves or functions and are referred to as functional data .",
    "we consider here the extension of the linear regression model to the case of functional data . in this extension ,",
    "both predictors and responses are random functions rather than random vectors .",
    "it is well known ( ramsay and dalzell ( @xcite ) ; ramsay and silverman ( @xcite ) ) that the traditional linear regression model for multivariate data , defined as @xmath0 may be extended to the functional setting by postulating the model , for @xmath1 , @xmath2    writing all vectors as row vectors in the classical model ( [ basic ] ) , @xmath3 and @xmath4 are random vectors in  @xmath5 , @xmath6 is a random vector in @xmath7 , and @xmath8 and @xmath9 are , respectively , @xmath10 and @xmath11 matrices containing the regression parameters . the vector @xmath4 has the usual interpretation of an error vector , with @xmath12=0 $ ] and @xmath13=\\sigma^{2}i$ ] , @xmath14 denoting the identity matrix . in the functional model ( [ linear ] ) , random vectors @xmath15 and @xmath16 in ( [ basic ] ) are replaced by random functions defined on the intervals  @xmath17 and @xmath18 .",
    "the extension of the classical linear model ( [ basic ] ) to the functional linear model ( [ linear ] ) is obtained by replacing the matrix operation on the right - hand side of ( [ basic ] ) with an integral operator in ( [ linear ] ) . in the original approach of ramsay and dalzell ( @xcite ) , a penalized least - squares approach using l - splines was adopted and applied to a study in temperature - precipitation patterns , based on data from canadian weather stations .",
    "the functional regression model ( [ linear ] ) for the case of scalar responses has attracted much recent interest ( cardot and sarda ( @xcite ) ; mller and stadtmller ( @xcite ) ; hall and horowitz ( @xcite ) ) , while the case of functional responses has been much less thoroughly investigated ( ramsay and dalzell ( @xcite ) ; yao , mller and wang ( @xcite ) ) .",
    "discussions on various approaches and estimation procedures can be found in the insightful monograph of ramsay and silverman ( @xcite ) . in this paper",
    ", we propose an alternative approach to predict @xmath19 from @xmath20 , by adopting a novel canonical representation of the regression parameter function @xmath21 .",
    "several distinctive features of functional linear models emerge in the development of this canonical expansion approach .",
    "it is well known that in the classical multivariate linear model , the regression slope parameter matrix is uniquely determined by @xmath22 , as long as the covariance matrix @xmath23 is invertible .",
    "in contrast , the corresponding parameter function @xmath24 , appearing in ( [ linear ] ) , is typically not identifiable .",
    "this identifiability issue is discussed in section [ sec2 ] .",
    "it relates to the compactness of the covariance operator of the process @xmath25 which makes it non - invertible . in section [ sec2 ] , we demonstrate how restriction to a subspace allows this problem to be circumvented . under suitable restrictions , the components of model ( [ linear ] ) are then well defined .",
    "utilizing the canonical decomposition in theorem [ th3.3 ] below leads to an alternative approach to estimating the parameter function @xmath26 .",
    "the canonical decomposition links @xmath27 and @xmath25 through their functional canonical correlation structure .",
    "the corresponding canonical components form a bridge between canonical analysis and linear regression modeling .",
    "canonical components provide a decomposition of the structure of the dependency between @xmath27 and @xmath25 and lead to a natural expansion of the regression parameter function @xmath24 , thus aiding in its interpretation .",
    "the canonical regression decomposition also suggests a new family of estimation procedures for functional regression analysis .",
    "we refer to this methodology as _ functional canonical regression analysis_. classical canonical correlation analysis ( cca ) was introduced by hotelling ( @xcite ) and was connected to function spaces by hannan ( @xcite ) .",
    "substantial extensions and connections to reproducing kernel hilbert spaces were recently developed in eubank and hsing ( @xcite ) ; for other recent developments see cupidon _ et al . _  ( @xcite ) .",
    "canonical correlation is known not to work particularly well for very high - dimensional multivariate data , as it involves an inverse problem .",
    "leurgans , moyeed and silverman ( @xcite ) tackled the difficult problem of extending cca to the case of infinite - dimensional functional data and discussed the precarious regularization issues which are faced ; he , mller and wang ( @xcite ) further explored various aspects and proposed practically feasible regularization procedures for functional cca . while cca for functional data is worthwhile , but difficult to implement and interpret , the canonical approach to functional regression is here found to compare favorably with the well established principal - component - based regression approach in an example of an application ( section [ sec5 ] ) .",
    "this demonstrates a potentially important new role for canonical decompositions in functional regression analysis .",
    "the functional linear model ( [ linear ] ) includes the varying coefficient linear model studied in hoover _",
    "et al . _  ( @xcite ) and fan and zhang ( @xcite ) as a special case , where @xmath28 ; here , @xmath29 is a delta function centered at @xmath30 and  @xmath31 is the varying coefficient function . other forms of functional regression models with vector - valued predictors and functional responses were considered by faraway ( @xcite ) , shi , weiss and taylor ( @xcite ) , rice and wu ( @xcite ) , chiou , mller and wang ( @xcite ) and ritz and streibig ( @xcite ) .",
    "the paper is organized as follows . functional canonical analysis and functional linear models for @xmath32-processes",
    "are introduced in section [ sec2 ] .",
    "sufficient conditions for the existence of functional normal equations are given in proposition [ pr2.2 ] .",
    "the canonical regression decomposition and its properties are the theme of section [ sec3 ] . in section [ sec4 ] ,",
    "we propose a novel estimation technique to obtain regression parameter function estimates based on functional canonical components .",
    "the regression parameter function is the basic model component of interest in functional linear models , in analogy to the parameter vector in classical linear models .",
    "the proposed estimation method , based on a canonical regression decomposition , is contrasted with an established functional regression method based on a principal component decomposition .",
    "these methods utilize a dimension reduction step to regularize the solution of the inverse problems posed by both functional regression and functional canonical analysis . as a selection criterion for tuning parameters , such as bandwidths or numbers of canonical components , we use minimization of prediction error via leave - one - curve - out cross - validation ( rice and silverman ( @xcite ) ) .",
    "the proposed estimation procedures are applied to mortality data obtained for cohorts of medflies ( section [ sec5 ] ) .",
    "our goal in this application is to predict a random trajectory of mortality for a female cohort of flies from the trajectory of mortality for a male cohort which was raised in the same cage .",
    "we find that the proposed functional canonical regression method gains an advantage over functional principal component regression in terms of prediction error .",
    "additional results on canonical regression decompositions and properties of functional regression operators are compiled in section [ sec6 ] .",
    "all proofs are collected in section [ sec7 ] .",
    "in this section , we explore the formal setting as well as identifiability issues for functional linear regression models . both response and predictor functions are considered to come from a sample of pairs of random curves .",
    "a basic assumption is that all random curves or functions are square - integrable stochastic processes . consider a measure @xmath33 on a real index set @xmath34 and let @xmath35 be the class of real - valued functions such that @xmath36 .",
    "this is a hilbert space with the inner product @xmath37 and we write @xmath38 if @xmath39 .",
    "the index set @xmath34 can be a set of time points , such as @xmath40 , a compact interval @xmath41 $ ] or even a rectangle formed by two intervals @xmath42 and @xmath43 , @xmath44 .",
    "we focus on index sets @xmath34 that are either compact real intervals or compact rectangles in @xmath45 and consider @xmath33 to be the lebesgue measure on  @xmath46 or @xmath47 .",
    "extensions to other index sets @xmath34 and other measures are self - evident .",
    "an @xmath32-process is a stochastic process @xmath48 , @xmath49 , with @xmath50 < \\infty , e[x(t)^2]<\\infty$ ] for all @xmath51 .",
    "let @xmath52 and @xmath53 .",
    "processes @xmath54 are subject to a functional linear model if @xmath55 where @xmath56 is the parameter function , @xmath57 is a random error process with @xmath58=0 $ ] for @xmath59 , and @xmath60 and @xmath25 are uncorrelated , in the sense that @xmath61=0 $ ] for all @xmath62 .    without loss of generality ,",
    "we assume from now on that all processes considered have zero mean functions , @xmath63 and @xmath64 for all @xmath30 , @xmath65 .",
    "we define the regression integral operator @xmath66 by @xmath67 equation ( [ linear1 ] ) can then be rewritten as @xmath68 denote the auto- and cross - covariance functions of @xmath25 and @xmath27 by @xmath69,\\qquad s , t\\in t_{1},\\\\ r_{yy}(s , t)&=&\\operatorname{cov}[y(s),y(t)],\\qquad s , t \\in t_{2 } , \\quad\\mbox{and}\\\\ r_{xy}(s , t)&=&\\operatorname{cov}[x(s),y(t)],\\qquad s\\in t_{1 } , t\\in t_{2}.\\end{aligned}\\ ] ] the autocovariance operator of @xmath25 is the integral operator @xmath70 , defined by @xmath71 replacing @xmath72 by @xmath73 , @xmath74 , we analogously define operators @xmath75 and @xmath76 , similarly @xmath77 . then @xmath78 and @xmath79 are compact , self - adjoint and non - negative definite operators , and @xmath80 and @xmath77 are compact operators ( conway ( @xcite ) ) . we refer to he _",
    "et al . _  ( @xcite ) for a discussion of various properties of these operators .",
    "another linear operator of interest is the integral operator @xmath81 , @xmath82 the operator equation @xmath83 is a direct extension of the least - squares normal equation and may be referred to as the functional population normal equation .",
    "[ pr2.2 ] the following statements are equivalent for a function @xmath84 :    @xmath85 satisfies the linear model ( [ linear2 ] ) ;    @xmath85 is a solution of the functional normal equation ( [ norm ] ) ;    @xmath85 minimizes @xmath86 among all @xmath87 .",
    "the proof is found section [ sec7 ] . in the infinite - dimensional case ,",
    "the operator @xmath88 is a hilbert  schmidt operator in the hilbert space @xmath32 , according to proposition [ pr6.6 ] below .",
    "a problem we face is that it is known from functional analysis that a bounded inverse does not exist for such operators .",
    "a consequence is that the parameter function @xmath85 in ( [ linear1 ] ) , ( [ linear2 ] ) is not identifiable without additional constraints . in a situation where the inverse of the covariance matrix does not exist in the multivariate case",
    ", a unique solution of the normal equation always exists within the column space of @xmath23 and this solution then minimizes @xmath89 on that space . our idea to get around the non - invertibility issue in the functional infinite - dimensional case is to extend this approach for the non - invertible multivariate case to the functional case .",
    "indeed , as is demonstrated in theorem [ th2.3 ] below , under the additional condition [ condc1 ] , the solution of ( [ norm ] ) exists in the subspace defined by the range of @xmath88 .",
    "this unique solution indeed minimizes @xmath89 .",
    "we will make use of the karhunen ",
    "love decompositions ( ash and gardner ( @xcite ) ) for @xmath32-processes @xmath25 and @xmath27 ,",
    "@xmath90 with random variables @xmath91 , @xmath92 , @xmath93 , and orthonormal families of @xmath32-functions @xmath94 and @xmath95 . here , @xmath96 , @xmath97 , @xmath98 and @xmath99 are the eigenvalues and eigenfunctions of the covariance operators @xmath78 and @xmath100 , respectively , with @xmath101 , @xmath102 .",
    "note that @xmath103 is the kronecker symbol with @xmath104 for @xmath105 , @xmath106 for @xmath107 .",
    "we consider a subset of @xmath32 on which inverses of the operator @xmath108 can be defined . as a  hilbert  schmidt operator ,",
    "@xmath108 is compact and therefore not invertible on @xmath109 according to conway ( @xcite ) , page 50 , the range of @xmath110 @xmath111 is characterized by @xmath112 where @xmath113 defining @xmath114 we find that @xmath88 is a one - to - one mapping from the vector space @xmath115 onto the vector space @xmath116 thus , restricting @xmath88 to a subdomain defined by the subspace @xmath117 we can define its inverse for @xmath118 as @xmath119 @xmath120 then satisfies the usual properties of an inverse , in the sense that @xmath121 for all @xmath122 and @xmath123 for all @xmath124    the following condition [ condc1 ] for processes @xmath54 is of interest .",
    "[ condc1 ] the @xmath32 -processes @xmath25and @xmath27 with karhunen  love decompositions ( [ kl ] ) satisfy @xmath125}{\\lambda_{xm}}\\biggr\\}^2 < \\infty.\\ ] ]    if [ condc1 ] is satisfied , then the solution to the non - invertibility problem as outlined above is viable in the functional case , as demonstrated by the following basic result on functional linear models .",
    "[ th2.3 ] a unique solution of the linear model ( [ linear2 ] ) exists in @xmath126 if and only if @xmath127 and @xmath128 satisfy condition . in this case , the unique solution is of the form @xmath129    as a consequence of proposition [ pr2.2 ] , solutions of the functional linear model ( [ linear2 ] ) , solutions of the functional population normal equation ( [ norm ] ) and minimizers of @xmath89 are all equivalent and allow the usual projection interpretation .",
    "[ pr2.4 ] assume @xmath25 and @xmath27 satisfy condition .",
    "the following are then equivalent :    1 .",
    "the set of all solutions of the functional linear model ( [ linear2 ] ) ; 2 .",
    "the set of all solutions of the population normal equation ( [ norm ] ) ; 3 .",
    "the set of all minimizers of @xmath86 for @xmath87 ; 4 .",
    "the set @xmath130 .",
    "it is well known that in a finite - dimensional situation , the linear model ( [ norm ] ) always has a unique solution in the column space of @xmath131 , which may be obtained by using a generalized inverse of the matrix @xmath88 .",
    "however , in the infinite - dimensional case , such a solution does not always exist .",
    "the following example demonstrates that a pair of @xmath32-processes does not necessarily satisfy condition [ condc1 ] . in this case , the linear model ( [ norm ] ) does not have a solution .",
    "[ ex2.5 ] assume processes @xmath25 and @xmath27 have karhunen  love expansions ( [ kl ] ) , where the random variables @xmath91 , @xmath92 satisfy @xmath132=\\frac{1}{m^{2 } } , \\qquad \\lambda _ { yj}=e[\\zeta_{j}^{2}]=\\frac{1}{j^{2}}\\ ] ] and let @xmath133=\\frac{1}{(m+1)^{2}(j+1)^{2 } } \\qquad \\mathrm{for } \\",
    "m , j\\geq1.\\ ] ] as shown in he _",
    "et al . _  ( @xcite ) , ( [ ex1 ] ) and ( [ ex2 ] ) can be satisfied by a pair of @xmath32-processes with appropriate operators @xmath78 , @xmath79 and @xmath80 .",
    "then @xmath134}{\\lambda_{xm}}\\biggr\\ } ^{2}&=&\\lim_{n\\rightarrow\\infty } \\sum_{m ,",
    "j=1}^{n}\\biggl [ \\frac{m}{(m+1)(j+1)}\\biggr ] ^{4}\\\\ & = & \\lim_{n\\rightarrow\\infty } \\sum_{m=1}^{n}\\biggl [ \\frac{m}{(m+1)}\\biggr ] ^{4}\\sum_{j=1}^{\\infty}\\frac{1}{(j+1)^{4}}=\\infty\\end{aligned}\\ ] ] and , therefore , condition [ condc1 ] is not satisfied .",
    "canonical analysis is a time - honored tool for studying the dependency between the components of a pair of random vectors or stochastic processes ; for multivariate stationary time series , its utility was established in the work of brillinger ( @xcite ) . in this section ,",
    "we demonstrate that functional canonical decomposition provides a useful tool to represent functional linear models .",
    "the definition of functional canonical correlation for @xmath32-processes is as follows .",
    "[ def3.1 ] the first canonical correlation @xmath135 and weight functions @xmath136 and @xmath137 for @xmath32-processes @xmath25 and @xmath27 are defined as @xmath138 where @xmath139 and @xmath140 are subject to @xmath141 for @xmath142 . the @xmath143th canonical correlation @xmath144 and weight functions @xmath145 , @xmath146 for processes @xmath25 and @xmath27 for @xmath147 are defined as @xmath148 where @xmath139 and @xmath140 are subject to ( [ def2 ] ) for @xmath149 and @xmath150 for @xmath151 we refer to @xmath152 and @xmath153 as the @xmath143th canonical variates and to @xmath154 as the @xmath143th canonical components .",
    "it has been shown in he _",
    "et al . _",
    "( @xcite ) that canonical correlations do not exist for all @xmath32-processes , but that condition [ condc2 ] below is sufficient for the existence of canonical correlations and weight functions .",
    "we remark that condition [ condc2 ] implies condition [ condc1 ] .",
    "[ condc2 ] let @xmath25 and @xmath27 be @xmath32-processes , with karhunen ",
    "love decompositions ( [ kl ] ) satisfying @xmath125}{\\lambda_{xm}\\lambda_{yj}^{1/2}}\\biggr\\ } ^{2}<\\infty.\\ ] ]    the proposed functional canonical regression analysis exploits features of functional principal components and of functional canonical analysis . in functional principal component analysis ,",
    "one studies the structure of an @xmath32-process via its decomposition into the eigenfunctions of its autocovariance operator , the karhunen  love decomposition ( rice and silverman ( @xcite ) ) . in functional canonical analysis ,",
    "the relation between a pair of @xmath32-processes is analyzed by decomposing the processes into their canonical components .",
    "the idea of canonical regression analysis is to expand the regression parameter function in terms of functional canonical components for predictor and response processes .",
    "the canonical regression decomposition ( theorem [ th3.3 ] ) below provides insights into the structure of the regression parameter functions and not only aids in the understanding of functional linear models , but also leads to promising estimation procedures for functional regression analysis .",
    "the details of these estimation procedures will be discussed in section [ sec4 ] .",
    "we demonstrate in section [ sec5 ] that these estimates can lead to competitive prediction errors in a finite - sample situation .",
    "we now state two key results .",
    "the first of these ( theorem [ th3.2 ] ) provides the canonical decomposition of the cross - covariance function of processes @xmath25 and @xmath27 .",
    "this result plays a central role in the solution of the population normal equation ( [ norm ] ) .",
    "this solution is referred to as _ canonical regression decomposition _ and it leads to an explicit representation of the underlying regression parameter function @xmath155 of the functional linear model ( [ linear2 ] ) .",
    "the decomposition is in terms of functional canonical correlations @xmath156 and canonical weight functions @xmath157 and @xmath158 .",
    "given a predictor process @xmath159 , we obtain , as a consequence , an explicit representation for @xmath160 , where @xmath161 is as in ( [ linear2 ] ) . for the following main results , we refer to the definitions of @xmath156 , @xmath157 , @xmath158 , @xmath162 , @xmath163 in definition [ def3.1 ] .",
    "all proofs are found in section [ sec7 ] .",
    "[ th3.2 ] assume that @xmath32-processes @xmath25 and @xmath27 satisfy condition .",
    "the cross - covariance function @xmath74 then allows the following representation in terms of canonical correlations @xmath156 and weight functions @xmath157 and @xmath158 : @xmath164    [ th3.3 ] assume that the @xmath32-processes @xmath25 and @xmath27 satisfy condition .",
    "one then obtains , for the regression parameter function @xmath165 ( [ regsol ] ) , the following explicit solution : @xmath166    to obtain the predicted value of the response process @xmath27 , we use the linear predictor @xmath167    this canonical regression decomposition leads to approximations of the regression parameter function @xmath168 and the predicted process @xmath169 via a finitely truncated version of the canonical expansions ( [ canreg1 ] ) and ( [ canreg2 ] ) .",
    "the following result provides approximation errors incurred from finite truncation .",
    "thus , we have a vehicle to achieve practically feasible estimation of @xmath170 and associated predictions @xmath171 ( section [ sec4 ] ) .",
    "[ th3.4 ] for @xmath172 , let @xmath173 be the finitely truncated version of the canonical regression decomposition ( [ canreg1 ] ) for @xmath168 and define @xmath174 .",
    "then , @xmath175 with @xmath176=0 $ ] .",
    "moreover , @xmath177 and @xmath178    in finite - sample implementations , to be explored in the next two sections , truncation as in ( [ k - pred ] ) is a practical necessity ; this requires a choice of suitable truncation parameters .",
    "estimating the regression parameter function and obtaining fitted processes from the linear model  ( [ linear ] ) based on a sample of curves is central to the implementation of functional linear models . in practice ,",
    "data are observed at discrete time points and we temporarily assume , for simplicity , that the @xmath179 time points are the same for all observed predictor curves and are equidistantly spaced over the domain of the data .",
    "analogous assumptions are made for the @xmath180 time points where the response curves are sampled .",
    "thus , the original observations are @xmath181 , @xmath182 , where @xmath183 is an @xmath179-dimensional vector sampled at time points @xmath184 , and @xmath185 is an @xmath180-dimensional vector sampled at time points @xmath186 .",
    "we assume that @xmath187 and @xmath188 are both large . without going into any analytical details ,",
    "we compare the finite - sample behavior of two functional regression methods , one of which utilizes the canonical decomposition for regression and the other a well established direct principal component approach to implement functional linear regression .",
    "the proposed practical version of functional regression analysis through functional canonical regression analysis ( fcr ) is discussed in section [ sec4.2 ] .",
    "this method is compared with a more standard functional linear regression implementation that is based on principal components and referred to as _ functional principal regression _",
    "( fpr ) , in section [ sec4.3 ] . for the choice of the smoothing parameters for the various smoothing steps , we adopt leave - one - curve - out cross - validation ( rice and silverman ( @xcite ) ) . smoothing is implemented by local linear fitting for functions and surfaces ( fan and gijbels ( @xcite ) ) , minimizing locally weighted least squares .    in a pre - processing step ,",
    "all observed process data are centered by subtracting the cross - sectional means @xmath189 , and analogously for @xmath185 .",
    "if the data are not sampled on the same grid for different individuals , a smoothing step may be added before the cross - sectional average is obtained . as in the previous sections , we use in the following the notation @xmath190 to denote centered processes and trajectories .    when employing the karhunen ",
    "love decomposition ( [ kl ] ) , we approximate observed centered processes by the fitted versions @xmath191 where @xmath192 and @xmath193 are the estimated first @xmath194 smoothed eigenfunctions for the random processes @xmath25 and @xmath27 , respectively , with the corresponding estimated eigenscores @xmath195 and @xmath196 for the @xmath197th subject .",
    "we obtain these estimates as described in yao _",
    "et al . _  ( @xcite )",
    ". related estimation approaches , such as those of rice and silverman ( @xcite ) or ramsay and silverman ( @xcite ) , could alternatively be used .      to obtain functional canonical correlations and the corresponding weight functions as needed for fcr",
    ", we adopt one of the methods proposed in he _",
    "et al . _  ( @xcite ) . in preliminary studies",
    ", we determined that the eigenbase method as described there yielded the best performance for regression applications , with the fourier base method a close second . adopting the eigenbase method , the implementation of fcr is as follows :    starting with the eigenscore estimates as in ( [ klest ] ) , estimated raw functional canonical correlations @xmath198 and @xmath194-dimensional weight vectors @xmath199 , @xmath200 , are obtained by applying conventional numerical procedures of multivariate canonical analysis to the estimated eigenscore vectors @xmath201 and @xmath202 .",
    "this works empirically well for moderately sized values of @xmath194 , as typically obtained from automatic selectors .",
    "smooth weight function estimates @xmath203 are then obtained as @xmath204 where @xmath205    the estimated regression parameter function @xmath206 is obtained according to ( [ canreg1 ] ) by @xmath207 where @xmath208 is an estimate of the covariance function of @xmath27 , obtained by two - dimensional smoothing of the empirical autocovariances of @xmath27 . this estimate is obtained as described in yao _",
    "_  ( @xcite ) .",
    "since the data are regularly sampled , the above integrals are easily obtained by the approximations @xmath209 , with @xmath210 defined analogously to @xmath211 in ( [ int ] ) below .",
    "fitted / predicted processes @xmath212 are obtained , where the integral is again evaluated numerically by @xmath213 here , @xmath214 is chosen such that @xmath215 .",
    "this procedure depends on two tuning parameters , a bandwidth @xmath216 for the smoothing steps ( which are defined in detail , e.g. , in yao _",
    "et al . _  ( @xcite ) ) and the number of canonical  @xmath194 that are included .",
    "these tuning parameters may be determined by leave - one - out cross - validation ( rice and silverman ( @xcite ) ) as follows . with @xmath217 , the @xmath197th",
    "leave - one - out estimate for @xmath218 is @xmath219 where @xmath220 is the @xmath221th canonical correlation , and @xmath222 and @xmath223 are the @xmath221th weight function untransformed and transformed with the covariance operator , respectively , all obtained while leaving out the data for the @xmath197th subject .",
    "computation of these estimates follows steps ( iii ) and ( iv ) above , using tuning parameter @xmath217 , and omitting the @xmath197th pair of observed curves @xmath181 .",
    "the average leave - one - out squared prediction error is then @xmath224 the cross - validation procedure then selects the tuning parameter that minimizes the approximate average prediction error , @xmath225 where @xmath226 is obtained by replacing the integrals on the right - hand side of ( [ pe ] ) by sums of the type ( [ int ] ) .",
    "yao _ et al .",
    "_  ( @xcite ) considered an implementation of functional linear regression whereby one uses functional principal component analysis for predictor and response functions separately , followed by simple linear regressions of the response principal component scores on the predictor scores .",
    "we adopt this approach as fpr .",
    "briefly , defining @xmath227 , this approach is based on representations @xmath228 of the regression parameter function @xmath229 , where @xmath230 for all @xmath231 and @xmath232 .    for estimation ,",
    "one first obtains a smooth estimate @xmath233 of the cross - covariance @xmath74 by smoothing sample cross - covariances , for example , by the method described in yao _",
    "et al . _  ( @xcite ) .",
    "this leads to estimates @xmath234 of @xmath235 by plugging in estimates @xmath233 for @xmath74 and @xmath236 for eigenfunctions @xmath237 ( as described in section [ sec4.2 ] ) , in combination with approximating the integrals in ( [ sig ] ) by appropriate sums .",
    "one may then use these estimates in conjunction with estimates  @xmath238 of eigenvalues @xmath239 to arrive at the estimate @xmath240 of the regression parameter function  @xmath229 given by @xmath241 for further details about numerical implementations , we refer to yao _",
    "et al . _  ( @xcite ) .",
    "in this section , we present an application to age - at - death data that were collected for cohorts of male and female medflies in a biodemographic study of survival and mortality patterns of cohorts of male and female mediterranean fruit flies ( _ ceratitis capitata _ ; for details , see carey _ et al . _  ( @xcite ) ) .",
    "a point of interest in this study is the relation of mortality trajectories between male and female medflies which were raised in the same cage .",
    "one specifically desires to quantify the influence of male survival on female survival .",
    "this is of interest because female survival determines the number of eggs laid and thus reproductive success of these flies .",
    "we use a subsample of the data generated by this experiment , comprising 46 cages of medflies , to address these questions .",
    "each cage contains both a male and a female cohort , consisting each of approximately 4000 male and 4000 female medflies .",
    "these flies were raised in the shared cage from the time of eclosion . for each cohort , the number of flies alive at the beginning of each day was recorded , simply by counting the dead flies on each day ; we confined the analysis to the first 40 days .",
    "the observed processes @xmath242 and @xmath243 , @xmath244 are the estimated random hazard functions for male and female cohorts , respectively .",
    "all deaths are fully observed so that censoring is not an issue . in a pre - processing step ,",
    "cohort - specific hazard functions were estimated nonparametrically from the lifetable data , implementing the transformation approach described in mller _",
    "et al . _  ( @xcite ) .",
    ".results for medfly data , comparing functional canonical regression ( fcr ) and functional principal component regression ( fpr ) with regard to average leave - one - out squared prediction error ( pe ) ( [ pe ] ) ; values for bandwidth @xmath245 and number @xmath194 of components as chosen by cross - validation are also shown [ cols= \" < , < , < , < \" , ]     a functional linear model was used to study the specific influence of male mortality on female mortality for flies that were raised in the same cage , with the hazard function of males as predictor process and that of females as response process .",
    "we applied both the proposed regression via canonical representation ( fcr ) and the more conventional functional regression based on principal components ( fpr ) , implementing the estimation procedures described in the previous section .",
    "tuning parameters were selected by cross - validation .",
    "table [ t1 ] lists the average squared prediction error ( pe ) ( [ pe ] ) obtained by the leave - one - out technique . for this application",
    ", the fcr procedure is seen to perform about 20% better than fpr in terms of pe .",
    "the estimated regression parameter surface @xmath246 that is obtained for the fcr regression when choosing the cross - validated values for @xmath245 and @xmath194 , as given in table [ t1 ] , is shown in figure [ f1 ] .",
    "the shape of the regression surface indicates that female mortality at later ages is very clearly affected by male mortality throughout male lifespan , while female mortality at very early ages is not much influenced by male mortality .",
    "the effect of male mortality on female mortality is periodically elevated , as evidenced by the bumps visible in the surface .",
    "the particularly influential predictive periods are male mortality around days 10 and 20 , which then has a particularly large influence on female mortality around days 15 and 25 , that is , about five days later , and , again , around days 35 and 40 , judging from the locations of the peaks in the surface of @xmath246 .",
    "in contrast , enhanced male mortality around day 30 leads to lessened female mortality throughout , while enhanced male mortality at age 40 is associated with higher older - age female mortality . these observations point to the existence of periodic waves of mortality , first affecting males and subsequently females .",
    "while some of the waves of increased male mortality tend to be associated with subsequently increased female mortality , others are associated with subsequently decreased female mortality .",
    "these waves of mortality might be related to the so - called `` vulnerable periods '' that are characterized by locally heightened mortality ( mller _ et al . _  ( @xcite ) ) .",
    "one such vulnerable period occurs around ages 10 and 20 , and the analysis suggests that heightened male mortality during these phases is indicative of heightened female mortality .",
    "in contrast , heightened male mortality during a non - vulnerable period such as the time around 30 days seems to be associated with lower female mortality .",
    "a word of caution is in order as no inference methods are available to establish that the bumps observed in @xmath246 are real , so one can not exclude the possibility that these bumps are enhanced by random fluctuations in the data .",
    "examples of observed , as well as predicted , female mortality trajectories for three randomly selected pairs of cohorts ( male and female flies raised in the same cages ) are displayed in figure  [ f2 ] .",
    "the predicted female trajectories were constructed by applying both regression methods ( fcr and fpr ) with the leave - one - out technique .",
    "the prediction of an individual response trajectory from a predictor trajectory can not , of course , be expected to be very close to the actually observed response trajectory , due to the extra random variation that is a large inherent component of response variability ; this is analogous to the situation of predicting an individual response in the well - known simple linear regression case .",
    "nevertheless , overall , fcr predictions are found to be closer to the target .",
    "we note the presence of a `` shoulder '' at around day 20 for the three female mortality curves .",
    "this `` shoulder '' is related to the wave phenomenon visible in @xmath246 as discussed above and corresponds to a phase of elevated female mortality .",
    "the functional regression method based on fcr correctly predicts the shoulder effect and its overall shape in female mortality . at the rightmost points , for ages near 40 days ,",
    "the variability of the mortality trajectories becomes large , posing extra difficulties for prediction in the right tail of the trajectories .",
    "theorems [ th6.3 ] and [ th6.4 ] in this section provide a functional analog to the sums - of - squares decomposition of classical regression analysis . in addition , we provide two results characterizing the regression operators @xmath161 .",
    "we begin with two auxiliary results which are taken from he _",
    "et al . _  ( @xcite ) .",
    "the first of these characterizes the correlation operator between processes @xmath25 and @xmath27 .",
    "[ le6.1 ] assume that the @xmath32-processes @xmath25 and @xmath27 satisfy condition .",
    "the correlation operator @xmath247can then be extended continuously to a hilbert  schmidt operator @xmath248 on @xmath249 to @xmath250 .",
    "hence , @xmath251 is also a hilbert  schmidt operator with a countable number of non - zero eigenvalues and eigenfunctions @xmath252 , @xmath253 , @xmath254 then :    @xmath255 , @xmath256 @xmath257 and both @xmath258 and @xmath259 are @xmath32-functions ;    @xmath260 ;    @xmath261 ;    @xmath262 .",
    "one of the main results in he _",
    "et al . _  ( @xcite ) reveals that the @xmath32-processes @xmath25 and @xmath27 can be expressed as sums of uncorrelated component functions and the correlation between the @xmath231th components of the expansion is the @xmath231th corresponding functional canonical correlation between the two processes .",
    "[ le6.2 ] assume @xmath32-processes @xmath25 and @xmath27 satisfy condition .",
    "there then exists a decomposition :    @xmath263 where @xmath264 the index @xmath265 stands for canonical decomposition with @xmath265 components , and @xmath266 @xmath267 @xmath268 @xmath158 are as in definition [ def3.1 ] .",
    "here , @xmath269 and @xmath270 share the same first @xmath265 canonical components , and @xmath270 and @xmath271 are uncorrelated , that is , @xmath272    let @xmath273 and @xmath274 then @xmath275 where @xmath276 @xmath277 @xmath278 @xmath279 . here ,",
    "@xmath280 and @xmath54 share the same canonical components , @xmath281 , and @xmath282 and @xmath280 are uncorrelated .",
    "moreover , @xmath283 if @xmath284 forms a basis of the closure of the domain of @xmath78 and @xmath285 if @xmath286 forms a basis of the closure of the domain of @xmath79 .",
    "since the covariance operators of @xmath32-processes are non - negative self - adjoint , they can be ordered as follows .",
    "the definitions of @xmath287 are in ( [ canreg2 ] ) , ( [ k - pred ] ) and lemma [ le6.2](b ) , respectively .",
    "[ th6.3 ] for @xmath288 @xmath289 .    in multiple regression analysis ,",
    "the ordering of the operators in theorem [ th6.3 ] is related to the ordering of regression models in terms of a notion analogous to the regression sum of squares ( ssr ) .",
    "the canonical regression decomposition provides information about the model in terms of its canonical components .",
    "our next result describes the canonical correlations between observed and fitted processes .",
    "this provides an extension of the coefficient of multiple determination , @xmath290 an important quantity in classical multiple regression analysis , to the functional case ; compare also yao _ et al . _",
    "( @xcite ) .",
    "[ th6.4 ] assume that @xmath32-processes @xmath25 and @xmath27 satisfy condition .",
    "the canonical correlations and weight functions for the pair of observed and fitted response processes @xmath291 are then @xmath292 and the corresponding @xmath265-component ( or @xmath293-component ) canonical decomposition for @xmath294 as defined in lemma [ le6.2 ] for @xmath295 and denoted here by @xmath296 ( or @xmath297 ) , is equivalent to the process @xmath298 or @xmath171 given in theorem [ th3.4 ] , that is , @xmath299    we note that if @xmath27 is a scalar , then @xmath300 and for a functional response @xmath27 , @xmath301 is replaced by the set @xmath302 @xmath303    the following two results serve to characterize the regression operator @xmath161 defined in ( [ linear2 ] ) .",
    "they are used in the proofs provided in the following section .",
    "[ pr6.5]the adjoint operator of @xmath161 is @xmath304 , where @xmath305    we have the following relation between the correlation operator @xmath306 defined in ( [ gamma ] ) and the regression operator @xmath161 .",
    "[ pr6.6 ] the operator @xmath307 is a self - adjoint non - negative hilbert ",
    "schmidt operator and satisfies @xmath308.$ ]",
    "in this section , we provide sketches of proofs and some auxiliary results .",
    "we use tensor notation to define an operator @xmath309 @xmath310    proof of proposition [ pr2.2 ] to prove ( a ) @xmath311 ( b ) , we multiply equation ( [ linear2 ] ) by @xmath25 on both sides and take expected values to obtain @xmath312 .",
    "equation ( [ norm ] ) then follows from @xmath313 @xmath314 ( by propositions [ pr6.5 ] and [ pr6.6 ] ) and @xmath315 .    for ( b ) @xmath316 ( c ) ,",
    "let @xmath85 be a solution of equation ( [ norm ] ) .",
    "for any @xmath317 , we then have @xmath318.$ ] since @xmath319-e[\\mathcal{l}_x^{\\ast } \\mathcal{l}_x\\beta_{0}],\\beta_{0}-\\beta\\rangle=\\langle r_{xy}-\\gamma _ { xx}\\beta_{0},\\beta_{0}-\\beta\\rangle=0,\\end{aligned}\\ ] ] by proposition [ pr6.6 ] , we then have @xmath320 which implies that @xmath85 is indeed a minimizer of @xmath89 .    for @xmath321 ,",
    "let @xmath322 then , for any @xmath323 @xmath324 @xmath325,\\beta \\rangle+a^{2}e\\|\\mathcal{l}_x\\beta\\|^{2}.\\end{aligned}\\ ] ] choosing @xmath326,\\beta \\rangle / e\\|\\mathcal{l}_x\\beta\\|^{2},$ ] it follows that @xmath327,\\beta \\rangle|^{2}/\\break e\\|\\mathcal{l}_x\\beta\\|^{2}\\leq0 $ ] and @xmath328,\\beta\\rangle=0.$ ] since @xmath218 is arbitrary , @xmath329=0 $ ] and therefore @xmath330 satisfies the functional linear model ( [ linear2 ] ) .",
    "proof of theorem [ th2.3 ] note , first , that @xmath331\\theta_{m}(s)\\varphi _ { j}(t).$ ] thus , condition  [ condc1 ] is equivalent to @xmath332 .",
    "suppose that a unique solution of ( [ linear2 ] ) exists in @xmath333 this solution is then also a solution of ( [ norm ] ) , by proposition [ pr2.2](b ) .",
    "therefore , @xmath332 , which implies [ condc1 ] . on the other hand ,",
    "if [ condc1 ] holds , then @xmath334 which implies that @xmath335 is a solution of ( [ norm ] ) , is in @xmath336 and , therefore , is the unique solution in @xmath336 and also the unique solution of ( [ linear2 ] ) in @xmath333    proof of proposition [ pr2.4 ] the equivalence of ( a ) , ( b ) and ( c ) follows from proposition [ pr2.2 ] and ( d ) @xmath316 ( b ) is a consequence of theorem [ th2.3 ]",
    ". we now prove ( b ) @xmath337 ( d ) .",
    "let @xmath85 be a solution of  ( [ norm ] ) .",
    "proposition [ pr2.2 ] and theorem [ th2.3 ] imply that both @xmath85 and @xmath168 minimize @xmath338 for @xmath339 hence , @xmath340 which , by proposition [ pr6.6 ] , implies that @xmath341 therefore , @xmath342 it follows that @xmath343 or @xmath344 for an @xmath345    proof of theorem [ th3.2 ] according to lemma [ le6.2](b ) , condition [ condc2 ] guarantees the existence of the canonical components and canonical decomposition of @xmath25 and @xmath27 .",
    "moreover , @xmath346 = e\\bigl[\\bigl(x_{c,\\infty}(s)+x_{c,\\infty } ^{\\bot}(s)\\bigr)\\bigl(y_{c,\\infty}(t)+y_{c,\\infty}^{\\bot}(t)\\bigr)\\bigr]\\\\ & = & e[x_{c,\\infty}(s)y_{c,\\infty}(t ) ] = e\\biggl[\\sum_{m=1}^{\\infty } u_{m}r_{xx}u_{m}(s)\\sum_{m=1}^{\\infty}v_{m}r_{yy}v_{m}(t)\\biggr ] \\\\&=&\\sum_{m , j=1}^{\\infty } e[u_{m}v_{j}]r_{xx}u_{m}(s)r_{yy}v_{m}(t ) = \\sum_{m=1}^{\\infty}\\rho _ { m}r_{xx}u_{m}(s)r_{yy}v_{m}(t).\\end{aligned}\\ ] ] we now show that the exchange of the expectation with the summation above is valid . from lemma [ le6.1](b ) , for any @xmath347 and the spectral decomposition @xmath348 , @xmath349\\|r_{xx}^{1/2}p_{m}\\|^{2}=\\sum _",
    "{ m=1}^{k}\\langle p_{m},r_{xx}p_{m}\\rangle \\\\ & = & \\sum_{m=1}^{k } \\sum_{j=1}^{\\infty}\\lambda_{xj}\\langle p_{m},\\theta_{j}\\rangle^{2}=\\sum_{j=1}^{\\infty}\\lambda _ { xj}\\biggl(\\sum_{m=1}^{k}\\langle p_{m},\\theta_{j}\\rangle^{2}\\biggr)\\\\ \\\\ & \\leq & \\sum_{j=1}^{\\infty}\\lambda_{xj}\\|\\theta _ { j}\\|^{2}=\\sum_{j=1}^{\\infty}\\lambda_{xj}<\\infty,\\end{aligned}\\ ] ] where the inequality follows from the fact that @xmath350 is the square length of the projection of @xmath351 onto the linear subspace spanned by @xmath352 .",
    "similarly , we can show that for any @xmath347 , @xmath353    proof of theorem [ th3.3 ] note that condition [ condc2 ] implies condition [ condc1 ] .",
    "hence , from theorem  [ th2.3 ] , @xmath354 exists and is unique in @xmath336",
    ". we can show ( [ canreg1 ] ) by applying @xmath120 to both sides of ( [ norm ] ) , exchanging the order of summation and integration . to establish ( [ canreg2 ] ) , it remains to show that @xmath355 where @xmath356 in @xmath357 note that @xmath358 where the operator @xmath359 is defined in lemma [ le6.1 ] and can be written as @xmath360 with @xmath361/\\sqrt{\\lambda_{xk}\\lambda_{y\\ell}},$ ] using the karhunen  love expansion ( [ kl ] ) .",
    "then , @xmath362 and , therefore , @xmath363 \\|r_{yy}v_{m}\\|^{2}\\\\ & & \\quad=\\sum_{m}\\biggl[\\sum_{j}\\frac{1}{\\lambda_{xj}}\\biggl\\ { \\sum_{k}r_{kj}\\langle \\varphi_{k},q_{m}\\rangle\\biggr\\ } ^{2}\\biggr]\\|r_{yy}v_{m}\\|^{2}\\\\ & & \\quad \\leq \\sum_{m}\\biggl[\\sum_{j}\\frac{1}{\\lambda_{xj } } \\sum_{k}r_{kj}^{2}\\sum_{\\ell}\\langle \\varphi _ { \\ell},q_{m}\\rangle^{2}\\biggr]\\|r_{yy}v_{m}\\|^{2}\\\\ & & \\quad=\\biggl[\\sum_{j}\\frac{1}{\\lambda _ { xj}}\\sum_{k}r_{kj}^{2}\\biggr]\\sum _ { m}\\biggl[\\sum_{\\ell}\\langle \\varphi _ { \\ell},q_{m}\\rangle^{2}\\biggr]\\|r_{yy}v_{m}\\|^{2}\\\\ & & \\quad=\\sum_{j , k}\\frac{r_{kj}^{2}}{\\lambda_{xj}}\\sum _ { m}\\|r_{yy}v_{m}\\|^{2}\\qquad \\mbox{as } \\|q_{m}\\|=1.\\end{aligned}\\ ] ] note that by [ condc2 ] , the first sum on the right - hand side is bounded . for the second sum , @xmath364 which implies ( [ p1 ] ) .",
    "proof of theorem [ th3.4 ] observing @xmath365\\langle r_{yy}v_{m},r_{yy}v_{j}\\rangle = \\sum_{m=1}^{\\infty}\\rho_{m}^{2}\\|r_{yy}v_{m}\\|^{2}<\\infty,\\end{aligned}\\ ] ] we infer that @xmath366 as @xmath367 from @xmath368=0,$ ] for @xmath369 we have @xmath176=0 $ ] and , moreover , @xmath370 since @xmath371 and as @xmath168 is the solution of the normal equation ( [ norm ] ) , we obtain @xmath372 likewise , @xmath373 implying ( [ conv ] ) .",
    "proof of theorem [ th6.3 ] from ( [ canreg2 ] ) , ( [ k - pred ] ) for any @xmath172 , @xmath374 r_{yy}^{1/2}=r_{yy}^{1/2}r_{k+1}^{\\ast } r_{k+1}r_{yy}^{1/2},\\ ] ] where @xmath375 and hence , @xmath376 note that @xmath377=\\sum_{m , j=1}^{\\infty } e[v_{m}v_{j}]r_{yy}v_{m}(s)r_{yy}v_{j}(t ) \\\\ & = & \\sum_{m=1}^{\\infty } r_{yy}v_{m}(s)r_{yy}v_{j}(t)=\\sum_{m=1}^{\\infty } r_{yy}^{1/2}(q_{m})(s)r_{yy}^{1/2}(q_{m})(t),\\end{aligned}\\ ] ] implying that @xmath378r_{yy}^{1/2}\\geq0.\\end{aligned}\\ ] ] finally , from lemma [ le6.2](b ) , we have @xmath379 therefore @xmath380 this leads to @xmath381 and @xmath382    we need the following auxiliary result to prove theorem [ th6.3 ] .",
    "we call two @xmath32-processes @xmath25 and  @xmath27 _ uncorrelated _ if and only if @xmath383=0 $ ] for all @xmath32-functions @xmath139 and @xmath140 .",
    "[ le7.1]@xmath384 and @xmath171 are uncorrelated .    for any @xmath385 @xmath386 , write @xmath387 , with @xmath388  @xmath389 , which is equivalent to @xmath390 and @xmath388  @xmath391",
    ". then @xmath392 with @xmath393 write @xmath394 furthermore , from lemma [ le6.2](b ) , @xmath395=0 $ ] for all @xmath396 .",
    "we conclude that @xmath397=0.$ ]    proof of theorem [ th6.4 ] calculating the covariance operators for @xmath291 , @xmath398 = \\sum_{m , j}\\rho_{m}\\rho _ { j}e[u_{m}u_{j}]r_{yy}u_{m}(s)r_{yy}v_{j}(t ) \\\\ & = & \\sum_{m}\\rho_{m}^{2}r_{yy}u_{m}(s)r_{yy}v_{m}(t ) = \\sum_{m}\\rho _ { m}^{2}r_{yy}^{1/2}q_{m}(s)r_{yy}^{1/2}q_{m}(t)\\end{aligned}\\ ] ] so that @xmath399r_{yy}^{1/2 } = r_{yy}^{1/2}\\biggl[\\sum_{m}\\rho_{m}^{2}q_{m}\\otimes q_{m}\\biggr]r_{yy}^{1/2}=r_{yy}^{1/2}r_{0}r_{yy}^{1/2}.\\ ] ] now , from lemmas [ le6.2 ] and [ le7.1 ] , @xmath400=e\\bigl[\\bigl(y_{c,\\infty } ( s)+y_{c,\\infty}^{\\bot}(s)\\bigr)y^{\\ast}(t)\\bigr ] \\\\ & = & e[y_{c,\\infty}(s)y^{\\ast } ( t)]=e\\biggl[\\sum_{m}v_{m}r_{yy}v_{m}(s)\\sum_{j}\\rho _ { j}u_{j}r_{yy}v_{j}(t)\\biggr ] \\\\ & = & \\sum_{m , j}e[v_{m}u_{j}\\rho _",
    "{ j}r_{yy}v_{m}(s)r_{yy}v_{j}(t)]\\\\ & = & \\sum_{m}\\rho _ { m}^{2}r_{yy}v_{m}(s)r_{yy}v_{j}(t)=r_{y^{\\ast}y^{\\ast}}(s , t).\\end{aligned}\\ ] ] hence , @xmath401 .",
    "the correlation operator for @xmath291 is @xmath402 with @xmath403 hence , @xmath404 @xmath405 and @xmath406 moreover , @xmath407 and @xmath408 note that @xmath409 with @xmath410 substituting into the equation on the left - hand side of ( [ t6.4 ] ) , one obtains the equation on the right - hand side of ( [ t6.4 ] ) .",
    "proof of proposition [ pr6.5 ] from the definition , @xmath411 must satisfy @xmath412 @xmath413for @xmath87 and @xmath414 note that @xmath412 @xmath415 and @xmath416 for the differences , we obtain @xmath417\\,\\mathrm{d}s\\,\\mathrm{d}t=0 $ ] for arbitrary @xmath87 and @xmath418 .",
    "this implies that @xmath419    proof of proposition [ pr6.6 ] by proposition [ pr6.5 ] , @xmath420 $ ] .",
    "since the integral operator @xmath88 has the @xmath32-integral kernel @xmath72 , it is a hilbert  schmidt operator ( conway ( @xcite ) ) .",
    "moreover , for @xmath421 , @xmath422 implying that @xmath88 is self - adjoint .",
    "furthermore , @xmath307 is non - negative definite because , for arbitrary @xmath423 , @xmath424\\beta(w , t)\\beta(s , t)\\,\\mathrm{d}w\\,\\mathrm{d}s\\,\\mathrm{d}t\\\\ & = & e\\biggl[\\int(\\mathcal{l}_x\\beta)(t)(\\mathcal{l}_x\\beta ) ( t)\\,\\mathrm{d}t\\biggr]=e\\|\\mathcal{l}_x\\beta\\|^{2}\\geq0.\\end{aligned}\\ ] ]",
    "we wish to thank two referees for careful reading and are especially indebted to one reviewer and the associate editor for comments which led to substantial changes and various corrections .",
    "this research was supported in part by nsf grants dms-03 - 54448 , dms-04 - 06430 , dms-05 - 05537 and dms-08 - 06199 .",
    "mller , h.g . ,",
    "wang , j.l . , capra , w.b .",
    ", liedo , p. and carey , j.r .",
    "( 1997b ) .",
    "early mortality surge in protein - deprived females causes reversal of sex differential of life expectancy in mediterranean fruit flies .",
    "usa _ * 94 * 27622765 ."
  ],
  "abstract_text": [
    "<S> we study regression models for the situation where both dependent and independent variables are square - integrable stochastic processes . </S>",
    "<S> questions concerning the definition and existence of the corresponding functional linear regression models and some basic properties are explored for this situation . </S>",
    "<S> we derive a  representation of the regression parameter function in terms of the canonical components of the processes involved . </S>",
    "<S> this representation establishes a connection between functional regression and functional canonical analysis and suggests alternative approaches for the implementation of functional linear regression analysis . </S>",
    "<S> a specific procedure for the estimation of the regression parameter function using canonical expansions is proposed and compared with an established functional principal component regression approach . as an example of an application , we present an analysis of mortality data for cohorts of medflies , obtained in experimental studies of aging and longevity .    ,    ,     + </S>"
  ]
}