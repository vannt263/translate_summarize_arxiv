{
  "article_text": [
    "in recent years various examples of complex adaptive systems , such as neural nets @xcite , genetic algorithms@xcite , and evolutionary models including artificial life @xcite have been used in carrying out computational optimizations .",
    "in addition adaptive algorithms and evolutionary models have been used to mimic the evolution of biological and social systems @xcite . when used for the prediction of a complex dynamics common features , such as a tendency to evolve their internal dynamics to the edge of chaos @xcite and the emergence of adaptive predictors with a bounded rationality or a limited memory @xcite",
    "have been observed in many of those systems .",
    "however it is typical for the systems which have been studied that they have many parameters and often their properties depend sensitively on the adjustment of those parameters @xcite .    as a first step toward the development of an approach which incorporates a quantitative understanding of common features of complex adaptive systems , we have carried out computer simulations of a simple `` toy model '' of a complex adaptive system : individual agents , operating in an evolving chaotic environment specified by a logistic map ,",
    "seek to predict the future states of their environment by modeling and controlling it .",
    "we study the dynamics of adaptive predictive agents responding to an evolving chaotic environment and to one another .",
    "our simulations are designed to quantify adaptation and to explore co - adaptation for a simple calculable model of a complex adaptive system .",
    "although elementary , and in large part calculable , our adaptive agents ( predictors ) meet the definition of a complex adaptive system proposed by murray gell - mann@xcite :    * information gathering entities * respond both to the environment and to one another * segregate information from random noise * compress regularities into a model ( schema ) * modify their internal characteristics to improve their predictive ( adaptive ) capacity    in our model the chaotic environment to which an agent responds is specified by a simple logistic map , with parameters which can be altered , plus random or dynamic noise which can also be altered",
    ". a given agent may be either passive or active ; thus agents both respond to the environment ( by receiving signals from it ) and attempt to control it ( by sending signals to it)@xcite . more specifically , an agent measures and models the chaotic environment and employs various control strategies to predict its future states .",
    "for each agent we give explicit quantitative measures of :    * adaptation ( the predictive ability of the agent ) * complexity ( the number of parameters used to specify an agent s model ) * memory ( the data used in the modelling process )    we determine both experimentally ( via our computer simulations ) and analytically the conditions for optimal predictive behavior ( adaptation ) , complexity , memory .",
    "we first consider the ability of a single agent , exposed to a chaotic environment , to model , control , and predict the future states of that environment .",
    "we then introduce a second agent which , in attempting to model and control both the chaotic environment and the first agent , modifies the extent to which that agent can identify patterns and exercise control .",
    "our computer simulations demonstrate the consequences of competition between the two agents .",
    "competition leads to chaos , if the agents follow typical learning strategies , or to emergent metastable behavior , if the agents develop a new learning strategy .",
    "thus , we find metastable solutions ( strategies ) in which the two agents optimize their joint predictive capacities by co - adapting in a leader - follower relationship .",
    "a sufficient condition for arriving at this joint strategy is the development of adaptive predictions which enable one agent to recognize the presence of another .",
    "our results suggest a correlation between optimal adaptation , optimal complexity , and emergent behavior .",
    "preliminary support is provided for the concept of optimal co - adaptation near an order - disorder transition@xcite    the computer simulations were performed on a silicon graphics 340 vgx machine .",
    "the length of time for a given study varies from 1000 time steps ( the number required to determine numerically the optimal response of a single agent ) to 100,000 time steps ( the number required to explore in detail the competition between two active agents which leads , over time , to their arriving at dynamic controls near the edge of chaos ) . for two agents , each time step required @xmath0 sec of cpu time .    in sec .",
    "2 we specify our model , and consider the behavior of a single agent .",
    "we consider competition ( and cooperation ) between two agents in sec  3 .",
    "extensions and possible applications are discussed in sec 4 .",
    "we consider an environment described by a simple logistic map.the state of the environment at some time @xmath1 determines its state at a later time @xmath2 : @xmath3 where @xmath4 represents the state of the environment at time @xmath1 , and @xmath5 is a control parameter .",
    "each transition from @xmath6 to @xmath7 is an event .",
    "depending on the choice of @xmath8 , the environment may be stationary , periodic , or chaotic in nature .",
    "the dynamics of the logistic map converges to a non zero fixed point for @xmath9,labelled as stationary in our plots ; it converges to a period 2-cycle for @xmath10 , labelled as periodic , and to more and more complicated period-@xmath11 cycles , @xmath12 , for @xmath13 . above @xmath14 the attractor of the map is chaotic , except in special `` periodic windows''@xcite . in our plots",
    "this last parameter region is labelled as chaotic , since most of our simulations are done at a large noise level , where the periodic windows have little impact on the dynamics @xcite . the liapunov exponent of the map , defined by @xmath15 is positive for @xmath16 ( apart from periodic windows ) , and is negative otherwise ; here @xmath17 .",
    "the use of a simple logistic map to describe a typical high dimensional complex environment may be considered an oversimplification .",
    "however , there is a long history of similar approaches in studies of physical systems .",
    "most physical systems are in reality high dimensional systems .",
    "a physical pendulum , often used as an example of low dimensional motion , has many degrees of freedom . when stimulated by a short kick , such as the impact of an hammer",
    ", many kinds of vibrations may be stimulated .",
    "usually those vibrations die out fast , which means that the dynamics settles down to a low dimensional approximate inertial manifold . often , the trajectories are complicated but confined to a very small region on this approximate inertial manifold .",
    "if the inertial manifold and the flow vector field are smooth in this region , one may expand the flow vector field in a taylor series and drop higher order terms . in this case , the limiting dynamics is low dimensional and the nonlinearity of the corresponding flow vector field is of low order .",
    "lorenz has shown@xcite that low dimensional , low order systems can exhibit deterministic chaos , _ i.e. _ irregular motion which is sensitive to initial conditions .",
    "since the flow vector field of such systems is smooth , their dynamics is usually smooth and oscillatory with trajectories which may have a simple or fractal geometry@xcite .",
    "moreover , poincare @xcite has shown that it is in general useful to study the dynamics of the amplitudes of the smooth oscillatory motion of a low dimensional , low order system and to model it with low order maps .",
    "therefore , we model the environment with logistic map dynamics , a simple , nontrivial deterministic chaotic system .    in many systems of interest , noise is present and the control parameters vary over time .",
    "we thus wish to consider environments in which additive background noise is present , and in which the control parameter is noisy : @xmath18 where @xmath19 describes additive system noise and , @xmath20 is parametric noise .",
    "the noise parameters @xmath19 , @xmath20 have a mean which is zero and standard deviations , @xmath21 and @xmath22 .",
    "@xmath23 determines the rate of change of the environment , whereas @xmath24 measures the noise level .",
    "we assume that the rate of change of the control parameter of the environment is small , _",
    "i.e. _ @xmath25 . fig .",
    "[ fignoise ] illustrates the dynamics of such an environment .        in our numerical experiments ,",
    "the primary goal of each agent is prediction of the environment to which it and , where present , other possible agents are responding .",
    "an agent seeks to discover patterns or regularities in the environment ; this process of constructing a model of the environment is greatly facilitated if the agent has the option of turning on or off a control signal which may entrain the environmental dynamics to a predetermined sequence of states , defined as the * goal dynamics * of the agent , a process of active adaptation .",
    "as we shall see , by pursuing a reasonably well defined strategy , a single agent can arrive at a goal dynamics which maximizes its predictive power .",
    "a given agent samples a set of @xmath26 successive events @xmath27 , @xmath28,@xmath29 , which characterize the time evolution of the environment and uses it to predict the next @xmath30 events , @xmath31 , @xmath32 , @xmath33 the success of the prediction process of the agent is measured by the * prediction error * , @xmath34 defined with respect to the background noise level , @xmath24 , as : @xmath35 where @xmath36 is a @xmath30-step prediction of the environment by the agent .",
    "the prediction error is a sliding average of length @xmath37 over an ensemble of rapidly fluctuating values .",
    "it depends on the time of prediction , @xmath1 , and the number of steps predicted , @xmath30 .",
    "the best prediction is limited by the background noise level @xmath24;. from eq .",
    "[ enmm ] the minimum value of the prediction error is @xmath38 .    at each step",
    "@xmath1 , the agent can modify its model .",
    "this process of modification , or updating , represents the * adaptive behavior * of the agent . for our adaptive agents , * learning * is a two step process :    * first , acquire and apply a predetermined class of schemata or fitting functions to model the past events of the environment * second , choose fitting function parameters that do the best job of prediction .    in the present context ,",
    "* innovation * involves the development and application of a new and different class of models to analyze the past and predict the future .",
    "it may include active adaptation , an exploration of the response of the environment to an imposed goal dynamics .",
    "we assume that the time scale of the innovation process is in general longer than the time scale of the learning process @xmath26 .",
    "we also assume that the probability an agent decides to try to improve a parameter of the modelling and control processes is given by : @xmath39 here @xmath40 ( a constant ) is the minimum rate of adaptation and @xmath34 is the current @xmath30 step prediction error of the agent averaged over @xmath37 time steps .",
    "the minimum rate of adaptation , @xmath40 , may be different for each parameter of the modelling and control processes .",
    "typical values of @xmath40 are such that @xmath41 .",
    "the agent begins with a given initial setting of the model and control processes and observes the environment for at least @xmath26 time steps .",
    "it then calculates an initial model and updates the model and prediction error at each subsequent time step .",
    "in addition , at each time step , the agent selects a random number , @xmath42 , which lies between @xmath43 and @xmath38 . if @xmath44 , the agent does nothing ; if @xmath45 the agent innovates . with this procedure ,",
    "the probability that an agent will innovate is simply @xmath46 , as long as @xmath47 .",
    "whenever @xmath48 , the agent will always innovate .",
    "thus after , say , @xmath49 time steps the agent will innovate , _",
    "i.e. _ try another class of fitting functions , switch the control on , or alter the goal dynamics .",
    "@xmath49 is short if the prediction error is large and vice versa according to eq.[p ] .",
    "the expectation value of @xmath49 is @xmath50 .",
    "eq.[p ] also guarantees perpetual novelty ; no matter how well an agent is doing , that agent will , sooner or later , be prompted to innovate . for",
    "optimally predictive agents , whose prediction error is of order unity , the minimum rate of innovation is @xmath40 .",
    "the trial period for innovation is assumed to last @xmath51 steps .",
    "after that period the parameter is reset to its previous value if the prediction error has increased on average during the last @xmath37 steps of the trial period .",
    "an agent develops a model , @xmath52 , of the environmental dynamics for single and multiple step predictions of the environment @xmath53 where @xmath54 and where @xmath55 counts the number of steps .",
    "this is based on the assumption that a good predictor for the observed events is a good predictor for future events .",
    "the first step of the modelling process is for the agent to represent the observed events in a state space ( see fig.[interpolation ] ) . in the simulations ,",
    "we restrict the attention of each agent to events that lie within a region of interest , a range of events such that @xmath56 .",
    "@xmath57 and @xmath58 are the boundaries of the region of interest at time step @xmath1 . in * modeling",
    "* the environmental dynamics each agent uses those @xmath59 events which are most recent and in which the initial state is in the region of interest . in our numerical examples the region of interest is usually slightly larger than the region where events have been observed during the first 1000 time steps of each simulation .",
    "further we introduce a equidistant grid @xmath60 , j=1, ..",
    ",@xmath61 , @xmath62 and estimate the events @xmath63 at these grid points through linear interpolation@xcite ( see fig .",
    "[ interpolation ] ) .",
    "the interpolation represents a generalization of the observed events , since the agent is guessing the behavior of the environment for those states where no observations are available .",
    "the relation between @xmath64 and @xmath65 is represented by a fourier series : @xmath66 where @xmath67 and @xmath68 are parameters of the fourier analysis chosen to improve the convergence of the fourier series . unless we specify otherwise",
    ", we assume that the observed events are almost homogeneously distributed in the region of interest , and that interpolation errors are small compared to statistical errors . in this case",
    "the standard deviation @xmath69 of the fourier coefficients is given by @xmath70 .",
    "the last step of the modeling process is to compress the information which is contained in the generalized observed events by segregating information from random noise . the values of the model parameters @xmath71 are determined by a least - squares fit which minimizes the prediction error by minimizing the difference between the generalized events at zero noise level and a model for single step predictions ( eq . [ model ] ) for the observed events .",
    "if we assume that the observed states are homogeneously distributed in the region of interest , that the additive noise is uncorrelated and that the rate of change of the environment is small , the fit problem has a unique solution and the optimal parameters @xmath71 are given given by the fourier coefficients @xmath72 of @xmath65@xcite , or are equal to zero , if the fourier coefficient is smaller than its standard deviation @xmath73 .",
    "an analogous procedure , pruning , is followed in neural nets , where it is found to improve their performance@xcite .",
    "if we define * complexity * , @xmath74 , as the number of model parameters used by the agent , it is possible to determine the complexity @xmath75 of an optimal model .",
    "the optimal model neglects all parameters with value smaller than the error bar for that parameter , estimated by its standard deviation .",
    "this concept is illustrated in fig .",
    "[ optimal]@xmath76 . the minimum prediction error in fig .",
    "[ optimal]@xmath77 is at approximately @xmath78 . in fig .",
    "[ optimal]@xmath79 the fourier coefficients equal the error bar also at @xmath78 .",
    "the optimal complexity is small for a large rate of change of the environment and vice versa .",
    "the environmental dynamics is a parabolic function with only one parameter .",
    "therefore , a tschebycheff series or a legendre series would converge even faster than the fourier series since these are also polynomial .",
    "however we intentionally program the agents to use a fourier series in order to illustrate the point that an exact match between the set of models ( schemata ) and environmental dynamics is not necessary .",
    "the fourier coefficients of many continuous , piecewise linear functions converge parabolically@xcite , _ i.e. _ @xmath80 , with an appropriate choice of @xmath67 and @xmath68 and converge linearly otherwise _ i.e. _ @xmath81 , where @xmath82 is a number .",
    "for parabolic convergence an estimate of @xmath75 is given by @xmath83    the prediction error for an agent with complexity @xmath74 can be estimated by writing @xmath84 where @xmath85 and where @xmath86 if @xmath87 and @xmath88 otherwise .",
    "another quantity which can be optimized by an agent is the number @xmath26 of states of the environment which are used in the modelling process . in principle",
    ", an agent is assumed to have access to the whole history of the environmental dynamics . in practice",
    ", the agent will find it advantageous to use only a small portion of this information .",
    "since @xmath26 measures how much of this information is used for the modeling process , @xmath26 is a measure for the * memory * of the agent .",
    "if @xmath26 is large , outdated data may decrease the quality of the model .",
    "if @xmath26 is too small , statistical errors may prevent an agent from choosing an optimal description .",
    "therefore , there is an * optimal memory * @xmath89 of an agent , which strikes a balance between the errors introduced by the noise level and those produced by the rate of change of the environment . fig .",
    "[ optimal]@xmath40 shows how a proper choice of @xmath26 minimizes the prediction error .",
    "the last term of eq.[e1 ] increases with the rate of change of the environment @xmath22 and @xmath26 . since the first term in eq .",
    "[ e1 ] decreases with @xmath26 , the prediction error @xmath90 is minimal for @xmath91   + as depicted in fig .",
    "[ optimal ] .",
    "agents with optimal memory and optimal complexity possess a prediction error , @xmath92    the noise level in the environment and the rate of change of the environment determine the optimal memory of the agent .",
    "if the fourier series converges parabolically the optimal complexity of the agent with optimal memory is :    @xmath93    since @xmath26 data are used to fit the model , a delay of @xmath26 time steps is needed to model the environment after a sudden change of the parameter @xmath94 .",
    "therefore , it is possible to establish a relation between the complexity of the agent s model and the * learning rate * , the minimum time required to extract a completely new model from the environmental dynamics .",
    "this result provides a method to determine experimentally whether an adaptive agent is functioning optimally . to evaluate an agent s performance",
    "an observer can introduce a sudden change of the environment and then measure the recovery of an adaptive agent , as shown in fig.[recovery ] . a match between the recovery rate and the optimal learning rate",
    "indicates that the agent is optimally adapted .",
    "an important feature of the modeling process is that the resulting model parameters are unique .",
    "if the relation between the evolving control parameters of the environmental dynamics and the model parameters is continuous , it may be possible to apply the same modeling procedure to the time series of the model parameters and to construct hierarchical models , of the kind considered by crutchfield@xcite .",
    "the process just described represents passive adaptive behavior of the agent .",
    "however , an agent can modify the environment in an effort to improve his predictive power , by turning on or off a control signal , which may entrain the environmental dynamics to a particular goal dynamics .",
    "our control strategy for such an active agent is based on the approach developed by one of us @xcite for the control of chaos .",
    "the agent applies a suitably chosen driving force to * entrain * the chaotic environment to a predetermined goal dynamics .",
    "there is a close relation between entrainment and optimal prediction .",
    "entrained oscillators may have an optimal energy exchange since they are at resonance @xcite while the concept of optimal information transfer has widespread application in research on phase locked loops@xcite .",
    "as we shall see , for the problem at hand entrainment makes optimal prediction possible .    to control the environmental dynamics an active adaptive agent iterates a logistic map time series @xmath95 of desired environmental states ; this * goal dynamics *",
    "is specified by a parameter @xmath96 :    @xmath97     + to impose the goal dynamics on the environment , the agent applies a driving force ; @xmath98 tailored to make up the difference between the agent s model of the uncontrolled environmental dynamics and the desired state of the environment .",
    "the resulting controlled environment dynamics is given by : @xmath99    control is advantageous .",
    "it enables the agent to avoid the exponential growth of the prediction error with the number of steps , found in the case of chaotic systems with positive liapunov exponents ( see fig .",
    "[ sp ] and fig.[sc ] ) .",
    "if the agent succeeds in controlling the environment , the prediction error becomes bounded ; the upper boundary becomes small if the control which is exercised is stable over long periods of time .",
    "for an example of the way in which control reduces the prediction error , see fig.[control ] .",
    "the type of the goal dynamics has both a direct and indirect impact on the prediction error .",
    "since the size of prediction error depends on the stability of the control , an agent may improve the prediction error by choosing a goal dynamics which provides a very stable control . from this point of view",
    ", the prediction error would be as small as possible if the goal dynamics is , or is close to a stationary state , or some other superstable stationary orbit@xcite of the unperturbed system .",
    "however , this discussion takes only statistical errors into account .",
    "if the goal dynamics is a stationary state , for example at @xmath100 , the interpolation procedure may lead to large systematic errors .",
    "this is illustrated in fig .",
    "[ withcontrol ] .",
    "there we assume the region of interest is the whole interval and that @xmath101 is known at the boundaries of the interval .",
    "[ withcontrol]a shows that the prediction error may be significantly higher than the statistical estimate as long as the goal dynamics is not chaotic , _ i.e. _ @xmath102 .",
    "this is because the linear interpolation produces edges which are very sharp for stationary states close to @xmath100 ( fig .",
    "[ withcontrol]b ) , much less sharp for period two dynamics , and essentially absent for a chaotic goal dynamics .",
    "of course , other interpolation schemes could weaken this effect , but the best solution to this problem is to pick a chaotic or random goal dynamics which covers the entire state space and makes interpolations unnecessary .",
    "likewise , a small amount of additive noise in the environmental dynamics or the goal dynamics may help to reduce the prediction error , since it reduces systematic errors in the modelling process@xcite .",
    "moreover a control with a chaotic goal dynamics makes the system more robust against sudden changes in the noise level , since the agent has a global model of the flow vector field .",
    "as might be expected , the results change dramatically when two agents are present .",
    "for example , a second agent may alter the environmental dynamics of the first agent sufficiently to make it impossible for the latter to exercise effective control and make accurate predictions . or , without establishing direct communication , one agent may identify the presence of a second , and the two may establish a cooperative relationship which improves their joint predictive abilities .",
    "we assume that the agents have the same region of interest but may have different goal dynamics , and different models of the environmental dynamics . to distinguish between the parameters of the two agents , we attach a superscript @xmath103 to the model parameters @xmath104 , the memory @xmath105 , the complexity , @xmath106 , the parameter of the goal dynamics @xmath107 , the on / off switch of the control , @xmath108 , the liapunov exponent of the goal dynamics @xmath109 , the control coefficient @xmath110 , the prediction error @xmath111 and the control force @xmath112 .",
    "the dynamics of the environmental system is then given by :    @xmath113    in the following we discuss the prediction errors of the two agents for the situation where both are passive , _",
    "i.e. _ both have their control switched off , both are active , _ i.e. _ both have their control switched on , and the leader follower situation , in which one is active ( leader ) and one is passive(follower ) .",
    "we study the lifetime of those structures , _",
    "i.e. _ the number of time steps between the start and end of such a configuration , where trial periods do not count as the end of a configuration if this configuration reemerges after the trial period .",
    "unless we specify otherwise , we assume that both agents have a memory and complexity which would be optimal for single agent systems .",
    "there are three scenarios for dual agent behavior : both may be passive ; one may be passive while the other is active , i.e. exercises control to improve its predictive power , a leader - follower situation ; or both may be active , vying for control ( and optimal predictive power ) .",
    "we consider these scenarios in turn , assuming that each agent is capable of optimizing its memory and complexity in response to an environment in which the other agent is absent .",
    "when both agents are passive , the prediction error of each will be as though the other agent were not present . for a chaotic environmental dynamics",
    "the prediction error is usually very large compared to the leader follower situation . following a trial period , one or the other agent will turn on its control , and the scenario becomes one of leader ( the active agent ) and follower ( the passive agent ) .",
    "the life time of a configuration with two passive agents may be estimated by : @xmath114 where the prediction errors are the same as of single passive agents . for a chaotic environment ,",
    "passive agents have a large prediction error .",
    "therefore the lifetime of a configuration with two passive agents is quite short .",
    "as long as the second agent remains passive , the scenario for the behavior of the first agent , the leader , is identical to that of a single agent .",
    "the leader explores various controls , entrains the environment , and improves his predictive power .",
    "however , as this process of active adaptation proceeds , the passive second agent , the follower , senses a changed environment .",
    "if the leader switches off its control infrequently , the follower will see an environment which is mainly determined by the goal dynamics of the control exercised by the leader . such a controlled environment is easier to predict as long as the goal dynamics of the leader is not chaotic . under these circumstances , the optimal memory of the follower",
    "may , in fact , exceed that of the leader , whose memory depends on both the noise level and rate of change of the environment .",
    "the results of our numerical experiments on the role played by the goal dynamics of the leader are displayed in fig.[predlf ] .    in the * leader - follower situation * , where one agent is active and one agent is passive , the prediction error can be estimated by : @xmath115 for the leader , and by @xmath116 for the follower .",
    "the lifetime of the leader follower configuration can be estimated by : @xmath117 where @xmath118 and @xmath119 are the boundaries of the parameter range .",
    "the second term in eq.[llf ] increases for larger @xmath120 whereas the first term decreases sharply when the goal dynamics becomes chaotic at @xmath121 .",
    "therefore the lifetime of the configuration has a maximum close to @xmath121 , the edge of chaos ( see fig.[lifeb ] ) .",
    "this means that if the leader chooses a simple periodic goal dynamics , it is very likely that he will be successfully challenged by the follower , since the probability is high that the goal dynamics of the follower is more complicated than the goal dynamics of the leader .",
    "however , if the goal dynamics of the leader is highly chaotic , than the follower will also challenge the leader often since the follower s prediction error is poor .",
    "eq.[llf ] is only a rough estimate since it does not account for the periodic windows @xcite of the logistic map dynamics , which are important at low noise levels@xcite .",
    "the passive agent will eventually try to improve his predictions by switching on a control ; when he does , the environment will follow his goal only if it is more complicated than the goal of the agent which is already active .",
    "for example if the active agent entrains the environment to a period four dynamics by using a period four driving force , the other agent can not disentrain the environment to a period two dynamics with a period two driving force , since a period two entrainment would be disturbed by the period four driving force of the first agent",
    ". however if the second agent tries to entrain the environment to a period eight dynamics , this may be stable if the period four driving force of the first agent is taken into account by the second agent .",
    "another situation arises if the goal dynamics of the follower is chaotic .",
    "it is then difficult to compensate the periodic driving force of the leader and the environment does not entrain with the follower during the trial period .",
    "an overview of situations in which it is advantageous for the follower to become active is given in fig.[lifebb ] .",
    "in region @xmath122 the follower has a more complicated dynamics than the leader . therefore it can entrain the environment successfully and does not increase its prediction error by becoming active . in region",
    "@xmath123 the goal dynamics of the follower is simple compared to that of the leader .",
    "the prediction error increases significantly if the follower becomes active . in region",
    "@xmath124 the goal dynamics of the follower is chaotic and usually does not lead to entrainment of the environment .",
    "therefore it is not advantageous for the follower to switch on its control in regions @xmath123 or @xmath124 . in the region",
    "@xmath125 the goal dynamics of the leader is chaotic .",
    "this leads to very large prediction errors for the follower and makes control for the follower almost always advantageous .",
    "if the leader chooses a goal dynamics at the edge of chaos , _ i.e. _ @xmath126 , the probability that the follower would become active is minimized , since regions @xmath123 and @xmath124 contain the entire range of @xmath127 values .",
    "therefore the leader follower - relation is most stable for a goal dynamics at the edge of chaos .",
    "if we assume that the challenge of the follower is successful if the complexity of its goal dynamics is larger than that of the leader , the lifetime of the leader - follower relation increases as @xmath120 increases .",
    "however as soon as the goal dynamics of the leader becomes chaotic the prediction error of the follower rises sharply .",
    "this shortens the time span between two trial periods of the follower and makes it much more likely that the follower challenges the leader successfully .",
    "therefore the lifetime of the leader follower configuration has a maximum for parameters which are close to @xmath128 , the edge of chaos . as may be seen in fig.[lifeb ]",
    ", our numerical studies indicate that * leader - follower configuration * at the edge of chaos is the most stable among all configurations including those where both agents are active , or both are passive .",
    "since a leader follower configuration with a goal dynamics at the edge of chaos possesses a long lifetime , this configuration may be considered as an emerging structure . despite the fact that no social aspects are included in the system ,",
    "since both agents only seek to optimize their own prediction error , a structure with social aspects emerges , in which one of the agents takes the lead and the other agent follows the moves of the leader .      as noted above , the second agent will not remain passive , no matter how well he predicts his environment .",
    "he will , in time , switch on his controls in an attempt to improve his prediction powers .",
    "the system dynamics , for the general case of two active agents , with different goal dynamics , is complicated .",
    "if both agents use a control dynamics with a positive exponent , it leads to hyperchaos . while it is difficult to estimate analytically the prediction errors and configuration lifetimes , we observe in our numerical experiments that the resulting system dynamics settles into a state in which the environmental dynamics follows very closely one of the two imposed goal dynamics , in general the one which is more complicated ( see fig.[competition2 ] ) .",
    "thus , if the goal dynamics of one agent is a stationary state , while the goal dynamics of the other agent is a period two dynamics , the environmental dynamics would follow the period two dynamics .",
    "if one agent uses a highly chaotic goal dynamics , for example @xmath129 and the other agent a less chaotic goal dynamics , for example @xmath130 , then the environment follows the first agent s goal .",
    "this `` competition principle '' would suggest that the agent with the more complicated goal dynamics has a good chance to outperform his competitor , as illustrated in fig.[competition ] .",
    "we also observe that the driving force of the unsuccessful competitor tends to approach a constant , even if its goal dynamics is not stationary .    in this winner - loser configuration ,",
    "the prediction error of the successful competitor is the same as for an active agent without any competitor , whereas the prediction error of the unsuccessful competitor is significantly larger .",
    "the difference between the two prediction errors can be estimated by the average difference of the goal dynamics of the two agents .    if * both * agents are * active * , with one emerging as a successful competitor , the other as a unsuccessful competitor , a rough estimate of the prediction error for the successful competitor(winner ) , labeled here as the first agent is given by : @xmath131 and by @xmath132 for the unsuccessful competitor(loser ) .",
    "the prediction error of the winner is the same as for a single active agent , whereas the prediction error of the loser is generally dominated by a term which measures the average difference between the two goal dynamics .",
    "the lifetime @xmath133 of this configuration can be estimated from the equation , @xmath134    since the unsuccessful competitor can usually improve his prediction error by switching his control off , the lifetime of the winner - loser configuration depends only on time span between two trial periods of the loser , and is determined by the prediction error of the unsuccessful competitor .",
    "the loser may be considered to be maladapted since his goal dynamics is too simple . in this case",
    "the maladapted agent would lose the competition .",
    "preliminary results indicate that other types of maladaptation , such as suboptimal memory or suboptimal complexity , may also lead an agent to lose the competition .",
    "our preliminary studies also indicate that time span required before the winner - loser configuration emerges from a state where both agents are active increases with the liapunov exponent of the goal dynamics of the successful competitor .",
    "this observation suggests that an agent that has a slightly more complicated goal dynamics than his competitor has the best chance for a rapid improvement of his prediction error .",
    "a scenario for transitions between successive configurations is presented in fig.[cycle ] .",
    "it takes the following form :    * first configuration : * two passive agents * * second configuration : one agent switches on its control and becomes the leader ; the prediction error of both agents typically goes down .",
    "one thus arrives at the * leader - follower * * configuration*. * while comparatively stable , the leader - follower configuration will not persist because as noted earlier , no matter how low the prediction error of the follower , it will eventually switch on its control .",
    "most of the time this will not initially increase its prediction error . however",
    "the prediction error of the leader will increase ; the leader will then respond by adjusting his controls , reducing his prediction error , but increasing that of the `` follower '' .",
    "the follower will in turn challenge the leader , who loses his leadership role .",
    "this chain of events is full blown * competition * which can continue for a long time .",
    "eventually there emerges a clear * winner * ( the agent with the more complicated goal dynamics ) and a clear * loser*. * the * winner - loser * configuration is , of course not stable , since on the average , the loser , who has the larger prediction error , will switch off his control , returning the system to * the * leader*-*follower * situation in which the loser significantly improves his prediction error .",
    "+ in the course of the competition each agent will find , by trial and error , that when it improves a goal dynamics with a complexity greater than that of the apparent leader , its prediction powers improve as it assumes a leadership role . on the other hand ,",
    "the prediction error of the `` new '' follower increases sharply when the goal dynamics of the `` new '' leader is chaotic ; this condition will lead it , in turn , to shorten the time between two successive trial periods , and make it likely that the `` new '' follower becomes active after a short period of time .",
    "eventually the leader will use a goal dynamics at the edge of chaos .",
    "this configuration is the most stable one , since the follower no longer find it advantageous to switch on his control .",
    "this is illustrated in fig.[edge ] .",
    "it is natural to ask whether one agent can detect the presence of a second . if the second is passive , the answer is obviously no .",
    "if , however , that other agent is active , the answer is yes .",
    "the strategy for detection is to switch on a control : if the control works , there is no other active agent present . if , however , the environment can not be entrained to a simple goal dynamics , it is likely that another agent is already entraining the environment .",
    "our adaptive agents use this information in the sense that if they detect the other agent and therefore experience an increase of their prediction error during the trial period , they become passive .",
    "however , if they do not detect another agent , _ i.e. _ improve their prediction error during the trial period , they become active themselves .",
    "the adaptive agents we have studied , although following a comparatively simple strategy , are able to identify regularities , generalize and compress observed data by using different sets of schemata and explore strategies to change their environment .",
    "we find that quantitative measures of adaptation in a complex environment , such as complexity , or the learning rate of the agents , approach limiting values which depend on the rate of change of the environment and the noise level in the environment .",
    "we hope it is possible to use these measures to test theoretical predictions experimentally in physical systems , such as phase locked loops , as well as in economic systems . in our examination of the co - evolution of two agents",
    "we observe the emergence of leader - follower configurations , in which the leader entrains the environment to a weakly chaotic dynamics .",
    "this suggests that a primary goal , such as a small prediction error , or a large return for an investment in an airline company in a highly competitive market , may cause secondary goals which are chaotic : the chaotic goal dynamics for the environment in this study or a chaotic dynamics of the pricing of products such as air fares",
    ".    it will be interesting to explore the relationship of the tendency of the agents to move to the edge of chaos with the general idea of adaptation to the edge of chaos as discussed by langton@xcite , packard@xcite , kauffman@xcite , and crutchfield@xcite .",
    "it is also interesting to speculate on the applicability to real world situations of some of the results we have obtained from our toy model . for example , we have seen that active adaptation , using control to improve prediction , is under most circumstances the preferred strategy .",
    "this finding seems in accord with experience , whether one is analyzing the way an infant develops predictive power by exercising control of its immediate environment ( parents ) through cries or smiles , or analyzing the behavior of two interacting adults .",
    "consider , too , the attempt by traders on a stock market in the early minutes after the opening , to exercise control and improve their short term predictive powers , by carrying out a series of trades designed to probe , actively , likely subsequent trading patterns on that day .    to cite another example ; we have seen that in active competition between agents , the agent with the more complicated strategy will win .",
    "this finding accords with experience on the political scene .",
    "it helps suggest why , for example , the serbs have proved so successful to date in pursuing their strategy of ethnic cleansing ; their strategy may be regarded as one involving a series of controlled experiments which enable them to predict the un response .",
    "although the system which we study is simple , it makes possible a quantitative comparison between numerical and analytical results .",
    "we hope that some of our findings for simple adaptive agents in a chaotic environment are applicable to the behavior of real adaptive agents in complicated economic and/or biochemical systems . of course , to extend our approach to economic systems it is important to incorporate into our model the cost of constructing a model , exercising control , etc .",
    "still , even at the present level , our approach would seem to provide insight into the success of technical trading systems .",
    "technical trading systems usually use time bars to describe the spread of values of a time series , whereas in physics and engineering the variance is commonly used for that purpose .",
    "it can be shown@xcite that for chaotic time series time bars are maximum likelihood estimates of the spreading of the data in contrast to the variance .",
    "to the extent that economic time series are chaotic , this could explain why it is advantageous to use time bars for analyzing their behavior .",
    "we intend in the future to extend in a number of ways the numerical experiments presented here .",
    "we plan to study the competition between agents of markedly different adaptive capacities ( as manifested both in the ability to model the environment and to control it ) and to extend our approach to many interacting agents in order to examine possible collective behavior . while we have seen that the outcome of the present simulations of the interaction between two agents appears to lead to either a `` win - win '' or a `` win - lose '' situation",
    ", we anticipate that the actions of a powerful maladaptive agent can lead to a `` lose - lose '' situation , and it will be interesting to specify the conditions under which this comes about . as our program is currently written , no matter how well an agent is doing , it will , over time , seek to improve its predictive powers by changing its strategy , which means that all the configurations we have considered are metastable .",
    "we therefore plan to modify our innovation paradigm , eq.(5 ) by introducing a threshold for change ; we expect that the resulting `` happy agent '' configuration may lead , in some circumstances , to stable `` win - win '' configurations . finally , in order to make more direct contact with economics , we intend to introduce both a cost of computation and a cost of control in our numerical experiments .    in another direction ,",
    "we call the attention of the reader to a closely related set of independent numerical experiments carried out by kaneko and suzuki@xcite on a model for the evolution of the complex song of a bird .",
    "they use a simple logistic map for the song dynamics and consider a two person game between competing `` birds '' .",
    "their agent `` birds '' adapt to one another , exercising control through their songs .",
    "kaneko and suzuki find that the dynamics of the complex song evolves toward the edge of chaos .",
    "it will be interesting to explore the relationship between their simulations and our own , and to see to what extent a complicated environment might play a role in that evolution .",
    "we wish to thank john miller for his helpful advice in the early stages of our specification of this model as well as his cautions concerning its immediate applicability to economics , and gottfried mayer - kress for advice on the development of our graphic displays and for stimulating discussions on these and related topics .",
    "we thank bill fulkerson for a critical reading of a preliminary version of this manuscript , and a number of helpful suggestions .",
    "this work was begun at the santa fe institute with support from a robert maxwell professorship , and has been subsequently supported both by the santa fe institute and by the center for complex systems research at the beckman institute of the university of illinois at urbana champaign ; we thank both institutions for their support .",
    "the present version of our manuscript has profited from the informal remarks of our fellow participants at the integrative themes workshop of the santa fe institute , whom we thank for their advice and encouragement .",
    "literature anderson , p.w . ,",
    "arrow , k. , and pines , d. , _ the economy as an evolving complex system _ , proceedings of the santa fe institute vol .",
    "v , reading , ma : addison - wesley , 1988 .",
    "arthur , w.b .",
    ", `` designing economic agents that act like human agents : a behavioral approach to bounded rationality '' , aea papers and proceedings , * 81 * , ( 1991):353 - 39 .",
    "brock , w.a .",
    ", `` causality , chaos , explanation and prediction in economics and finance '' .",
    "in _ beyond belief : randomness , prediction , and explanation in science _ edited by casti , j. and karlqvist a. , boca raton , fl : crc press , 1991 .",
    "breeden , j. , f. dinkelacker , a. hbler , `` noise in the modeling and control of dynamical systems . ''",
    "phys.rev.a * 42 * , ( 1990):5827 - 5836 ; breeden , j. , a. hbler , `` reconstructing equations of motion from experimental data with hidden variables . ''",
    "phys.rev.a * 42 * , ( 1990):5817 - 5826 .",
    "bronshtein , i.n .",
    "semendyayev , _ handbook of mathematics _ , edited by k.a .",
    "hirsch , 581 - 591 .",
    "new york : van nostrand reinhold company , 1985 .",
    "chang , k. , s. kodogeorgiou , a. hbler , e.a .",
    "jackson , `` general resonance spectroscopy . ''",
    "physica d * 51 * , ( 1991):99 - 108 .",
    "crutchfield , j.p .",
    ", k. young , `` inferring statistical complexity . '' phys.rev.lett .",
    "* 63 * , ( 1989):105 - 108 .",
    "endo , t. and l.o .",
    "chua , `` synchronization of chaos in phase - locked loops .",
    "'' memorandum no .",
    "ucb / erl m91/59 , university of california at berkeley , 1991 .",
    "eisenhammer , t. , a. hbler , t. geisel , e. lscher , `` scaling behavior of the maximum energy exchange between coupled anharmonic oscillators . ''",
    "phys.rev.a * 41 * , ( 1990):3332 - 3342 .",
    "feigenbaum , m. , `` quantitative universality for a class of nonlinear transformations .",
    "'' j.stat.phys .",
    "* 19 * , ( 1978):25 - 52 .",
    "gell - mann , m. , to appear in _ complexity : from metaphor to reality _ ,",
    "proceedings of a conferece on integrative themes in complex adaptive systems edited by cowan g. , pines , d. , and meltzer , d. , readings : addison - wesley , 1993 .",
    "grassberger , p. , i. procaccia , `` characterization of strange attractors .",
    "'' phys.rev.lett . *",
    "50 * , ( 1983):346 - 349 .",
    "hertz , j. , a. krogh , r.g .",
    "palmer , _ introduction to the theory of neural computation _ , lecture notes of the santa fe institute vol .",
    "i , p. 157 .",
    "redwood city , ca : addison - wesley , 1991 .",
    "holland , j.h .",
    ", _ adaptation in natural and neural systems_. ann arbor : univ .",
    "of michigan press , 1975 .",
    "hbler , a. , `` modeling and control of nonlinear systems . ''",
    "thesis , technical university of munich , germany , 1987 .",
    "hbler , a. , e. lscher , `` resonant stimulation and control of nonlinear oscillators . ''",
    "naturwissenschaften * 76 * , ( 1989):67 - 69 .",
    "jackson , e.a .",
    ", _ perspectives of nonlinear dynamics_. 2 vols . , 142 - 225 .",
    "cambridge : cambridge university press , 1991 .",
    "jackson , e.a .",
    ", `` controls of dynamic flows with attractors . ''",
    "* 44 * , ( 1991):4839 - 4853 ; jackson , e.a . and s. kodogeorgiou , `` entrainment and migration controls of 2-dimensional maps . ''",
    "physica d * 54 * , ( 1992):253 - 265 .",
    "kaneko , k. , j. suzuki `` evolution to the edge of chaos in imitation game '' , presentation at the artificial life conference , santa fe , nm , june 1992 and preprint 1992 .",
    "kauffman , s.a .",
    "smith , `` adaptive automata based on darwinian selection . ''",
    "physica d * 22 * , ( 1988):68 - 82 .",
    "keefe , l.r .",
    ", `` two nonlinear control schemes contrasted on a hydrodynamic - like model . ''",
    "nielsen engineering and research , mountain view , ca . to appear in physics of fluids a , march 1993 .",
    "langton , c.g . ,",
    "thesis , university of michigan , 1988 .",
    "langton , c.g . ,",
    "taylor , c. , farmer , j.d . , and rasmussen , s. , _ artificial life ii _ , lecture notes of the santa fe institute vol .",
    "x , reading , ma : addison - wesley , 1992 .    lorenz , e.n .",
    ", `` deterministic nonperiodic flow . ''",
    "j. atmos.sci .",
    "* 20 * , ( 1963):130 .",
    "mayer - kress , g. and h. haken , `` the influence of noise on the logistic model .",
    "'' j.stat.phys .",
    "* 26 * , ( 1981):149 - 171 .",
    "merten , j. , b. wohlmuth , a. hbler , e. lscher , `` beschreibung und steuerung des getrieberauschen in einstufigen getrieben . ''",
    ". acta . * 61 * , ( 1988):88 - 91 .",
    "mittenthal , j.e . ,",
    "baskin , a.b .",
    ", _ the principles of organization in organisms _ , lecture notes of the santa fe institute vol .",
    "xiii , reading , ma : addison - wesley , 1992 .",
    "ohle , f. , a. hbler , and m. welge , `` adaptive control of chaotic systems . '' in _ proceedings of the twelfth turbulence symposium _ , edited by x.b .",
    "reed , jr .",
    ", a11 - 1-a11 - 9 , university of missouri - rolla , 1990 .",
    "packard , n.h .",
    ", `` adaptation toward the edge of chaos . '' in _ dynamics patterns in complex systems _ , edited by j.a.s .",
    "kelso , a.j .",
    "mandell , m.f .",
    "schlesinger , 293 - 301 , singapore : world scientific , 1988 .",
    "poincar , h. , _ les methodes nouvelles de la mechanique celeste _ , paris : gautier - villars , 1892 .",
    "rechenberg , i. , `` the evolution strategy . a mathematical model of darwinian evolution '' . in _ synergetics - from microscopic to macroscopic order _ edited by frehland e. , pp .",
    "122 - 132 .",
    "berlin : springer - verlag , 1984 .",
    "schuster , h.g .",
    ", _ deterministic chaos _ , p. 38 .",
    "weinheim : physik - verlag , 1984 .",
    "de sousa vieira , m. , a.j .",
    "lichtenberg , `` on sychronization of regular and chaotic systems '' , memorandum no .",
    "ucb / erl m92/72 , university of california at berkeley , 1992 , to appear in phys.rev.*e*.    wolfram , s. , `` statistical mechanics of cellular automata '' , rev .",
    "phys . * 55 * , ( 1983):601 - 653 ."
  ],
  "abstract_text": [
    "<S> we describe the results of analytic calculations and computer simulations of adaptive predictors ( predictive agents ) responding to an evolving chaotic environment and to one another . </S>",
    "<S> our simulations are designed to quantify adaptation and to explore co - adaptation for a simple calculable model of a complex adaptive system . </S>",
    "<S> we first consider the ability of a single agent , exposed to a chaotic environment , to model , control , and predict the future states of that environment . </S>",
    "<S> we then introduce a second agent which , in attempting to model and control both the chaotic environment and the first agent , modifies the extent to which that agent can identify patterns and exercise control . </S>",
    "<S> we find that ( i ) optimal adaptive predictors have an optimal memory and an optimal complexity , which are small for a a rapidly changing map dynamics and ( ii ) that the predictive power can be increased by imposing chaos or random noise onto the map dynamics . </S>",
    "<S> the competition between the two predictive agents can lead either to chaos , or to metastable emergent behavior , best described as a leader - follower relationship . </S>",
    "<S> our results suggest a correlation between optimal adaptation , optimal complexity , and emergent behavior , and provide preliminary support for the concept of optimal co - adaptation near the edge of chaos . </S>"
  ]
}