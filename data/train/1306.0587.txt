{
  "article_text": [
    "seventy years of coding research has resulted in many remarkable efficient error correction codes . the culmination is reflected in the discovery of turbo codes and and the re - discovery of low - density parity - check ( ldpc ) codes  practical linear codes that are capable of approaching the shannon limit on additive white gaussian noise ( awgn ) channels . since these codes are digital codes , analog sources , such as sound , color , images , and the vast geo- , physical- , chemical- , bio - signals acquired by the sensors , must first be sampled ( discretizing the time ) and quantized ( discretizing the amplitude ) .",
    "the communication theory states that as long as sampling is performed at or above the nyquist rate , the discrete - time samples can losslessly recover the original continuous - time signals . in comparison , however , quantization will result in permanent granularity error that is irrecoverable . to keep the granularity error small in general requires more quantization levels and/or higher - dimension quantization ( i.e. vector quantization ) .",
    "the former may cause non - negligible bandwidth expansion , and the latter can be very hard to design .",
    "one possibility to avoid the burden of quantization and the associated granularity error is to transmit the discrete - time continuous - valued analog source directly in its analog form . since",
    "real - world channels are inevitably noisy , to ensure adequate transmission fidelity requires practical analog error correction codes ( aecc ) , or , simply , analog codes  codes that encode ( discrete - time ) continuous - valued analog source sequences to ( discrete - time ) continuous - valued analog codeword to combat channel noise and distortion @xcite .",
    "although not nearly as popular as digital codes , the notion of `` analog error correction coding '' actually dated back to the early 80 s , when wolf @xcite and marshall @xcite independently introduced the concept .",
    "( it was termed _ real number coding _ in marshall s work and _ analog coding _ in wolf s work . ) to put the digital systems in perspective , the combination of quantization , digital error correction codes and the qam ( quadratic amplitude modulation ) digital modulation - order qam . ]",
    "may be viewed as a single analog error correction code .",
    "a noteworthy advantage of using a single analog code in lieu of its digital counter - part is the simplicity . to design a good digital system",
    "requires not only the careful design of individual components , but also a judicious balance of the rates between them , i.e. how many bits to use for quantization , error correction coding and modulation , respectively .",
    "all of this involves a lot of complicated design issues .",
    "although analog error correction follows much the same philosophy as digital error correction , good aeccs are hard to find .",
    "early ideas of analog codes were a natural outgrowth of digital codes , by extending conventional digital codes from the finite field to the real - valued or the complex - valued field ( namely , symbols from a very large finite field can approximate real values ) .",
    "this has resulted in , for example , analog bch codes and analog rs codes @xcite .",
    "since these ( linear ) analog codes also rely heavily on the conventional decoding algorithms such as the modified berlekamp - massey and forney algorithm , they perform best on a special _ pulse _ channel where noise only occurs to a limited number of coded symbols . for practical awgn channels , however , the performance of these analog codes can be rather disappointing , since every coded symbol is distorted by the channel .",
    "xie and li recently established a mean square error ( mse ) lower bound ( i.e. best achievable performance ) for linear analog codes @xcite .",
    "the fact that nonlinear analog codes can outperform this lower bound clearly speaks for the necessity and benefits of going nonlinear .    to design good analog error correction codes ,",
    "let us re - evaluate the profound idea underpinning error correction , namely , the principle of _ distance expansion_. in digital encoding ( a discrete function ) , the _ source space _ in which elements have relatively small hamming distance and may easily get confused with each other , is mapped to a _ code space _ in which elements have ( much ) larger hamming distance and can therefore tolerate ( much ) larger distortion .",
    "for analog codes to effectively achieve distance expansion and combat distortion would require good continuous functions that can effectively magnify euclidean distance . for this , we propose to exploit _ chaotic _ functions ( or chaotic systems ) , a specially class of continuous - valued , nonlinear functions with bounded state spaces exhibiting a topological mixing feature .",
    "chaotic systems are widely existent in the natural world as well as the engineering world , and many of them can be realized using simple electric circuits . despite the rich variety of formalities , chaotic systems",
    "share one common property , namely , high sensitivity to the initial state . popularly dubbed the _ butterfly effect , _ this property states that a small perturbation to the initial state(s ) of a chaotic system will cause a huge difference some time later .",
    "although this butterfly effect is in general viewed as a system penalty , it can actually be cleverly exploited to satisfy the distance expansion property required by a good channel code .",
    "specifically , if one treats the initial state(s ) of a chaotic system as the source ( to be encoded ) , and treats some later states as the codeword ( having been encoded ) , then the chaotic system naturally enacts a channel encoder that successfully magnifies the small differences ( distance ) among the source sequences to large ones .",
    "this elegant feature was first noted by chen and wornell some twelve years ago . in their pioneering work @xcite , they proposed the first chaotic analog code , the _ tent map code_. the first of its kind , this code directly employs a _ tent map _  a nonlinear , discrete - time , real - valued chaotic map with simple formulation  as the chaotic generator to achieve channel encoding .",
    "a near maximum likelihood ( ml ) detector is also developed to perform effective channel decoding @xcite .",
    "however , in part because the tent map code performs nowhere comparable to digital codes , and in part because chaotic functions are rather foreign to the coding community , the beautiful idea exposed in @xcite was largely ignored .    in this paper",
    ", we reclaim this intriguing idea and propose a new and effective way to utilize chaotic functions in designing analog codes .",
    "our studies show that direct application of chaotic functions may be insufficient , since a single chaotic function usually has imbalanced protection of some kind , namely , some part of the codeword may be protected ( much ) weaker and hence are more prone to error than the others . to mitigate this defect and provide balanced protection to all",
    ", we propose to exploit the powerful structure of digital turbo codes .",
    "recall that a turbo code is built on two convolutional codes , which are parallelly concatenated in such a way that if one convolutional code produces a low - weight ( i.e. weak ) codeword , the other will most likely produce a high - weight ( i.e. strong ) one .",
    "as such , the overall codeword weight is rarely very small , thus significantly improving the worst case and reducing the chance for worst case .",
    "borrowing this idea , we can arrange a similar `` buddy system '' by arranging two simple chaotic functions in a parallel concatenation , such that the vulnerable part of one is properly paired with the robust part of the other .",
    "our new codes are to turbo codes , as single chaotic functions ( e.g. the tent map code ) are to convolutional codes .",
    "to demonstrate our idea , below we present two constructive examples , using the tent map and the baker s map , respectively .",
    "we discuss how turbo - like structures can be devised for component codes to effectively cover for each other , and verify the effectiveness of our approaches through simulations .",
    "we show that the proposed turbo - like chaotic analog codes not only significantly outperform their processor ( i.e. the tent map code @xcite ) , but can also perform on par with , or better than , their digital counter - parts ( i.e. the combination of quantization , digital coding and digital modulation ) .",
    "we consider building analog codes from chaotic functions .",
    "prominent features of chaos includes continuous but bounded state space , deterministic randomness , nonlinearity , nonperiodicity , topological mixing , and sensitivity to initial conditions .",
    "the last is widely known as the butterfly effect , due to lorentz s 1972 paper , `` does the flap of a butterfly s wings in brazil set off a tornado in texas ? ''",
    "this very feature , i.e. the fast - diverging nature of chaotic functions , is usually measured by a lyapunov exponent that is @xmath0 .",
    "in general , a chaotic function is a real - valued or complex - valued recursive function in the form of : @xmath1 where @xmath2 is the initial state vector ( the seed ) , and @xmath3 is the state vector at time @xmath4 .",
    "a straightforward way to build a rate @xmath5 systematic chaotic analog code , such as how the tent map code is constructed , is to feed the source sequence to the chaotic function as the initial state ( the systematic part ) , and to collect @xmath6 subsequent states as parities to protect the source .    in theory , a code",
    "is well defined as long as the codebook is specified . in practice ,",
    "there is also need for encoding and especially decoding procedure . for digital codes , irrespective of complexity , one can always perform brute - force exhaustive search ( e.g. comparing the received sequence with @xmath7 valid codewords ) or syndrome decoding ( i.e. placing all the @xmath8 sequences in the standard array and performing table look - up ) to achieve good performance . note that such universal procedures become impossible for analog codes , since the codeword space is now continuous , consisting of unaccountably infinite points all of which are valid . if an analog codes is constructed by directly taking a known chaotic function as the encoder ( e.g. the tent map code ) , then the decoder may employ existing chaotic estimation methods . however , as mentioned before , more sophisticated and better - performing code structure would involve the concatenation or compounding of two or multiple chaotic functions , and judicious decoding procedure must be designed case by case .    consider an analog code @xmath9 with mapping @xmath10 , where the source space @xmath11 and the codeword space @xmath12 are assumed to be continuous and differentiable .",
    "consider transmitting the codeword @xmath13 and receiving the sequence @xmath14 at the output of a noise channel .",
    "we can define the ml decoder for a general analog code as @xmath15 where @xmath16 is short for @xmath17 , and @xmath18 is the decoder estimation for the source vector @xmath16 .",
    "suppose the channel transfer function is also differentiable ( a condition that is satisfied for most continuous - output channels such as awgn channels and fading channels ) .",
    "suppose there are only a finite number of local maximums for the target function in ( [ equ : ml decoder of analog decoder ] ) ( again a condition that is generally satisfied for linear and nonlinear mappings ) , then we will have a finite number of candidates for possible @xmath16 .",
    "the ml decoder can compare all of these candidates to identify the best @xmath16 with the largest probability .",
    "the complexity of the ml decoder will be linear to the number of candidates ( local maximums ) .    in general",
    ", one may find the local maximum in each subsection by taking a derivative of the target function with respect to @xmath19 .",
    "since all chaotic functions are by nature nonlinear , to keep down the decoding complexity , we focus on those chaotic functions that are piece - wise linear .",
    "the tent map code @xcite is constructed by employing a single tent map function as the encoder .",
    "the tent map , a simple 1-dimension piece - wise linear function that offers as rich dynamics as infinite length binary shift register , is defined as follows .",
    "@xmath20 specifically , parameter @xmath21 is used @xcite , such that the tent map maps @xmath22 $ ] to itself .",
    "the tent map code has successfully demonstrated the possibility of exploiting chaotic systems to achieve error correction , but its performance awaits to be desired . in our study , we performed a careful investigation of the tent map as well as other chaotic functions . here , coding gain is generally attained through expanding a _ neighborhood _ source ( sub)space and hence magnifying the differences ( distances ) of two close - by symbols .",
    "since the entire space is bounded and each neighborhood subspace gets expanded , two or more neighborhood subspaces that were previously disjoint will have to overlap to sustain the same bounded space .",
    "this gives rise to the renowned topologically mixing feature of a chaotic function , at the same time , it also introduces `` backward ambiguity . ''",
    "that is , a previous state can unequivocally derive a later state ( forward determinism ) , whereas the reverse operation almost always leads to ambiguity ( backward ambiguity ) . specifically , there are two values of @xmath23 ( same magnitude but opposite signs ) , both of which can generate @xmath24 .",
    "thus , to deduce @xmath23 from @xmath24 in the tent map requires the knowledge of the sign of @xmath25 , denoted as @xmath26 . more generally , for parity @xmath27 to be useful in deriving the source @xmath28 , the sign sequence , @xmath29 ( termed the `` symbolic coding '' in the chaos jargon ) must be available .",
    "if the symbolic coding sequence is _ accurately _ known to the decoder , then a parity @xmath27 , which is distorted by awgn with variance @xmath30 , can guarantee to derive the source @xmath31 with an impressively small mean square error ( mse ) of @xmath32 !",
    "however , symbolic coding is not known _ a priori _ , and must be estimated from the received symbols . because of the forward determinism and the backward ambiguity , state @xmath23 carries information about its own sign and the signs for all the succeeding states ( but not the preceding states ) .",
    "that is , the information on symbolic coding is actually _ unequally _ embedded in the codeword @xmath33 , with @xmath34 being the most reliable ( since @xmath35 all bear information of @xmath36 ) and @xmath37 being the least reliable ( only @xmath31 bears information of @xmath38 ) .",
    "such unequal protection is particularly undesirable , because the distortion error introduced by erroneous @xmath38 is the largest of all  that is , exactly where the protection is most needed actually receives the least of it .",
    "this probably explains why the tent map code by itself does not perform well .",
    "the previous analysis of the tent map code motivates us to consider a parallel structure that assembles two tent maps in a turbo - like manner for a much needed enhanced protection of the symbolic coding .",
    "recall that a fundamental reason for the remarkable performance of a digital turbo code is that , when one component code produces a low - weight sequence , the other will produce a high - weight one ( with a high probability ) .",
    "recall also that such `` complementary protection '' is achieved by means of interleaving .",
    "exploiting these powerful ideas gives rise to the proposed _",
    "tent map turbo code_.        as depicted in fig .",
    "[ fig : cat ] , a second tent map is introduced and is assigned a pre - determined symbolic coding sequence : the same symbolic coding sequence generated by the first tent map but in a reverse order . the detailed coding procedure is as follows :    1 .",
    "a source symbol @xmath39 is used as the initial state and fed to the first tent map ( as defined in ( [ equ : tent_mapping ] ) ) , generating a ( half ) codeword @xmath40 , which has a sign sequence @xmath41 .",
    "the symbolic coding sequence is scrambled through a `` reverse interleaver '' to get @xmath42 ( here @xmath43 is not needed and therefore discarded ) , and fed to the second component tent map to guide encoding . to make use of the given symbolic coding sequence ,",
    "the second tent map code is actually encoded backward : using the source symbol @xmath39 as the last state @xmath44 and subsequently deriving states @xmath45 through the inverse function of the tent map : @xmath46 3 .",
    "outputs from both tent maps , @xmath47 and @xmath48 , together form a length-@xmath49 codeword , resulting in a code rate @xmath50 . here , the systematic symbol @xmath39 is transmitted twice , both in the first and in the second tent map .",
    "one may also puncture @xmath51 and transmit only one copy of the systematize symbol , leading to a code rate of @xmath52 .    with this coding strategy , @xmath26 with",
    "a small indice @xmath4 , which gets weak protection from the first tent map , is now gaining a stronger protection from the second tent map .",
    "the encoder of this tent map follows the general ml concept discussed in section [ sec : ml ] .",
    "more detailed discussion , as well as an iterative decoding approach , can also be found in @xcite .",
    "the performance advantage of the resultant tent map turbo code over the single tent map code is verified by computer simulations .",
    "both codes have rate 1/11 and are operated on awgn channels with ml decoding .",
    "analog source symbols are generated uniformly at random from @xmath22 $ ] , and the performance is evaluated via mse ( plotted in @xmath53 scale ) .",
    "as shown in fig .",
    "[ fig : catsimu ] , the proposed tent map turbo code significantly outperforms the tent map code , with a gain as much as 8 db .",
    "the design philosophy exposed in the previous example has certainly demonstrated an elegant way of exploiting chaotic functions , but there is room for further improvement  by exploiting more powerful component chaotic functions .",
    "the less - than - desirable performance of the tent map code may be attributed , in part , to the insufficient and unequal protection for symbolic coding , and in part , to the low dimensionality of the underlying chaotic function : the tent map is a 1-dimensional nonlinear function with a scalar input and offers relatively simple relation between the time - evolving states .",
    "the tent map turbo code strengthens the inter - state relation by concatenating two tent maps , thus creating a higher level of protection , but the input is nevertheless a scalar . from the coding theory , we know that a larger block size will in general offer a richer correlation context and",
    "hence promises a better error correction capability . in this second constructive example , we explore a 2-dimensional chaotic function as the component code . leveraging the rich literature of the chaos theory , we identify the _ baker s map _ , a 2-dimensional nonlinear function from a unit square to itself , as a desirable candidate .",
    "the baker s map is a nonlinear chaotic function named after a kneading operation that bakers apply to dough : the dough is compressed and cut in half and the two halves are stacked on one - another .",
    "there are two slightly different versions of the baker s map : one may fold over or rotate one of the sliced halves before joining it , or does not fold over the top half . here",
    "we consider the former , i.e. , the folded baker s map , which represents a two - dimensional analog of the tent map ( see fig . [",
    "fig : bakersmap ] .",
    "mathematically , the folded baker s map is expressed as : @xmath54        although the baker s map can be directly employed to construct an analog code , just like the tent map code , it does not produce a desirable performance .",
    "a close inspection reveals that @xmath55 is not symmetric , i.e. @xmath56 carries information from both @xmath25 and @xmath57 , but @xmath24 only carries information from @xmath25 . to effectively improve the weak spot and enhance the overall performance",
    ", we again exploit the parallel structure of the digital turbo codes . the resultant _ baker s map turbo code _ , as depicted in fig . [",
    "fig : bakers ] , comprises a pair of baker s maps , engineered in a simple mirrored replication structure to protect against the weaker dimension of each other .",
    "specifically , a pair of source symbols @xmath58 is fed to the first baker s map as seed @xmath59 , and fed to the second baker s map as seed @xmath60 .",
    "similar to the case of the tent map turbo code , the systematic part @xmath39 and @xmath61 , may be transmitted only once or in both times , resulting in a code rate of @xmath62 or @xmath63 , respectively .",
    "note that the baker s map , although being 2-dimensional , is a piece - wise linear function , and since parallel concatenation is also a linear operation , the resultant baker s map turbo code remain a piece - wise linear function .",
    "hence , the same ml decoding philosophy discussed in section [ sec : ml ] applies .",
    "the entire decoding algorithm is actually quite simple , and the exact details can be found in @xcite .        the simple turbo construction in fig .",
    "[ fig : bakers ] turns out to be extremely powerful , and the resultant code demonstrates a surprisingly good performance that is not only better than the tent map turbo codes , but is also comparable to their digital counterparts !    fig .",
    "[ fig : bakersimu ] compares the simulation performance of a digital convolutional code , a digital turbo code , and a rate-1/6 analog baker s map turbo code , in terms of transmitting analog data , uniformly distributed over @xmath22 $ ] .",
    "the convolutional code ( 8 states ) and the digital turbo code ( with 8-state recursive systematic convolutional codes as component codes ) both have a source block size of 1000 bits , and the baker s map turbo code has a source block size of only 2 symbols ( and hence requires much shorter delay and memory size ) .",
    "uniform scalar quantization ( either 3-bit/8-level or 6-bit/64-level quantization ) and pulse amplitude modulation ( pam ) of the appropriate levels are used together with the digital codes , such that the overall bandwidth expansion ( i.e. rate of the entire system ) is always 1:6 .",
    "several observations can be made .",
    "first , the digital systems is ultimately limited by the quantization error floor ( the flat performance curve ) , whereas the analog code does not seem to have this limitation .",
    "second , a performance trade - off is unavoidable for digital systems . with a high - level quantization ( e.g. 6-bit ) and hence fewer bits for coding and modulation",
    ", the overall performance will have a low quantization error floor , but the waterfall region is also pushed to the far right ( the high snr level ) .",
    "alternatively , we may allocate more bits to coding and modulation , to push the water - fall region towards the low snr region , but then fewer bits are available for quantization , which leads to a coarse quantization and hence a high quantization floor .",
    "finally , we see that the baker s map turbo code actually performs comparable to the digital systems  it consistently outperforms the digital convolutional coding systems , and in some snr regions also outperforms the digital turbo coding system !",
    "analog error correction codes , by relaxing the source space and the codeword space from discrete fields to continuous fields , present a generalization of digital codes . by cleverly exploiting the `` butterfly effect '' of the chaotic systems , and by designing practical and effective coding structure ,",
    "we have succeeded in constructing two classes of turbo - like chaotic analog codes : the tent map turbo codes , and the baker s map turbo codes .",
    "the fundamental idea underpinning the parallel concatenation is presented , and the general principle of maximum likelihood decoding is discussed .",
    "computer simulations show that our new codes outperform the existing chaotic analog codes , and some are even comparable to the conventional digital systems ( turbo or convolutional codes ) ! we conclude by advocating turbo - like ( higher - dimensional ) analog coding as a new way to encode and protect analog sources .",
    "the analog coding approach is simple , and particularly suitable for channels that are highly varying , where it is difficult to design or adapt to an appropriate quantization / digital - coding / digital - modulation scheme .",
    "y. liu , j. li , and k. xie , `` analysis of linear channel codes with continuous code space , '' _",
    "46th annual conf .",
    "science systems ( ciss ) _ , princeton , nj , march , 2012 .",
    "k. xie , p. tan , b. c. ng , and j. li ( tiffany ) , `` analog turbo codes : a chaotic construction , '' _ ieee intl symp .",
    "info . theory ( isit ) _ , pp .",
    "894 - 898 , seoul , south korea , june 2009 ."
  ],
  "abstract_text": [
    "<S> analog error correction codes , by relaxing the source space and the codeword space from discrete fields to continuous fields , present a generalization of digital codes . </S>",
    "<S> while linear codes are sufficient for digital codes , they are not for analog codes , and hence nonlinear mappings must be employed to fully harness the power of analog codes . </S>",
    "<S> this paper demonstrates new ways of building effective ( nonlinear ) analog codes from a special class of nonlinear , fast - diverging functions known as the chaotic functions . </S>",
    "<S> it is shown that the `` butterfly effect '' of the chaotic functions matches elegantly with the distance expansion condition required for error correction , and that the useful idea in digital turbo codes can be exploited to construct efficient turbo - like chaotic analog codes . </S>",
    "<S> simulations show that the new analog codes can perform on par with , or better than , their digital counter - parts when transmitting analog sources . </S>"
  ]
}