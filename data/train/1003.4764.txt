{
  "article_text": [
    "the use of multiple antennas in wireless networks offers the promise of mitigating interference and enabling high spectral efficiencies . however achieving these benefits in a decentralized network requires distributed algorithms for coordinating the pre - coding matrices used by each transmitter with minimal overhead .",
    "a number of such algorithms have been studied for multiple - input multiple - output ( mimo ) interference networks including those in @xcite under the assumption that transmitters have perfect channel state information ( csi ) for channel matrices to all receivers . our focus in this work is to relax this assumption and develop adaptive algorithms for time - varying channels without assuming any csi at the transmitters or receivers .",
    "we consider a mimo interference network with block fading .",
    "each transmitter uses a rank one pre - coding matrix , i.e. a beamformer , and the receivers are assumed to be linear , with all interference treated as noise , so that the rate is determined by the received signal - to - interference plus noise ratio ( sinr ) .",
    "our objective is to design an adaptive distributed algorithm for updating the precoders and beamformers to maximize the sum - rate while accounting for the needed overhead . to accomplish this",
    ", we consider an algorithm for a synchronous time - division duplex ( tdd ) system that uses one or more bi - directional training periods at the beginning of each block .",
    "each period consists of a forward phase followed by a reverse phase . during the forward phase , all transmitters simultaneously send pilots using their current beamformers and each receiver updates their receive filters . during the backward phase ,",
    "the receivers transmit pilots , using the current receive filter as a beamformer and the transmitters update their beamformers .",
    "the updates during each phase are used to directly adapt the beamformers and receive filters based on a standard least - squares criterion .",
    "for a given number of channel users per coherence block , we consider the net throughput achieved after subtracting the channel uses used for training and via numerical results study the effect of varying the training length on these metric",
    ". for short coherence blocks , the optimal training length becomes small leading to imprecise estimation and degraded performance .",
    "for such settings , we also study a recursive variation of our algorithm based on using exponentially weighted data from previous blocks .",
    "the algorithms we study are inspired by the max - sinr algorithm in @xcite .",
    "this algorithm also iterates between transmitter and receiver updates assuming perfect csi and static channels .",
    "though no convergence proof for this algorithm is given in @xcite , numerical results show that it has good performance and at high snrs can achieve the optimal multiplexing gain by successfully aligning the interference at each receiver  @xcite .",
    "related iterative algorithms ( also assuming perfect csi ) are given in @xcite .",
    "the bi - directional training method presented here is also related to schemes for two - way channel estimation presented in @xcite .",
    "the key difference here is that we are directly estimating the optimal beamformer and receive filter as opposed to estimating the csi needed to compute those coefficients .",
    "we consider a peer - to - peer wireless network with @xmath0 transmitter - receiver pairs ( henceforth referred to as _ users _ ) communicating through mimo links , sharing the same spectrum .",
    "each transmitter has @xmath1 antennas , each receiver has @xmath2 antennas , and the channel from the @xmath3-th transmitter to the @xmath4-th receiver is denoted by a complex matrix @xmath5 .",
    "the channels are assumed to be block - fading , i.e. , @xmath6 remains constant for @xmath7 symbol periods and jumps to another value for the next @xmath7 symbols , according to the update @xmath8 where @xmath9 is the block index and @xmath10 is a matrix with _",
    "i.i.d _ complex gaussian entries having zero mean and the same variance as @xmath6 .",
    "( the index @xmath9 will sometimes be omitted if no confusion results . )",
    "we assume that neither transmitters nor receivers have _ a priori _ channel information .",
    "for simplicity , we assume each transmitter transmits only one beam to its desired receiver , i.e. , the precoding matrix has rank one .",
    "the beamforming vector for transmitter @xmath3 is @xmath11 and satisfies the power constraint @xmath12 .",
    "the @xmath13-th received signal vector at the @xmath3-th receiver in the @xmath9-th block is then given by @xmath14 where @xmath15 is the unit variance data symbol from transmitter @xmath3 and @xmath16 is the additive noise with covariance matrix @xmath17 = { \\mathbf{r}}_k$ ] .",
    "we assume linear receivers , so that the estimated symbol for user @xmath3 is @xmath18 where @xmath19 is the corresponding receive filter .",
    "given a set of beamformers @xmath20 s and receive filters @xmath19 s , the signal - to - interference - plus - noise ratio ( sinr ) for user @xmath3 can be written as @xmath21    ideally , we would like to choose the set of beamforming vectors @xmath22 and set of receive filters @xmath23 to maximize the sum rate @xmath24 within each block .",
    "this is complicated by the assumption that the channels are time - varying , and initially unknown at all nodes . estimating the channels requires overhead , which reduces the rate , and furthermore , if the channels vary too quickly , then the channel estimates are likely to be inaccurate",
    ". therefore we desire an estimation scheme with minimal overhead , and which adapts to the time - variations of the channel .",
    "the adaptive bi - directional training scheme to be described is based on the max - sinr algorithm presented in @xcite .",
    "that algorithm iteratively optimizes the transmit precoders and receivers , assuming the transmitters / receivers each know their direct- and cross - channel matrices .",
    "it consists of the following steps : ( i ) fix the precoders and optimize the receivers ; ( ii ) reverse the direction of transmission , so that the roles of the receiver filters and precoders are swapped , and optimize the precoders ( now the receivers ) .    the optimization criterion in each step",
    "is the associated sinr , i.e. , in step ( i ) the receiver for user @xmath3 is obtained by solving @xmath25 and in step ( ii ) the beamformer for user @xmath3 is updated by solving @xmath26    although inspired by a duality type of argument , which applies to the uplink / downlink , the max - sinr method does not appear to maximize a particular objective .",
    "hence so far , there is no proof that the algorithm converges .",
    "nevertheless , numerical results show that for the scenario considered ( i.e. , one beam per user ) the max - sinr algorithm essentially achieves the maximum sum rate over a wide range of snrs @xcite .",
    "maximizing the received sinr in and is equivalent to minimizing the mean squared error ( mse ) at the output of the corresponding filter .",
    "this leads to an adaptive version in which the mse is replaced by a least squares ( ls ) cost function . here",
    "we assume that in each step the set of transmitters or the set of receivers synchronously transmit training sequences in each direction .",
    "specifically , in the @xmath9-th block , we assume that the transmitters synchronously transmit the sequence of @xmath27 training symbols given by the matrix @xmath28 where @xmath29 $ ] and @xmath30 is the @xmath31 row vector containing the training symbols @xmath32",
    ". the received signal at receiver @xmath3 is then given by where @xmath33 . at receiver @xmath3 the estimated symbol at time @xmath13 is then @xmath34 .",
    "the corresponding sequence of estimated symbols is @xmath35 , where @xmath36\\label{eq : y}\\ ] ] the filter @xmath19 is then selected to @xmath37 which gives @xmath38    this is referred to as _",
    "forward training_. the beamformers @xmath39 are similarly updated via _ backward training _ exploiting channel reciprocity . specifically , the reverse channel from receiver @xmath3 to transmitter @xmath4 is @xmath40 .",
    "fixing the set of ( original ) receive filters @xmath23 , receiver @xmath3 then applies @xmath41 as the beamformer , and all receivers synchronously transmit training sequences in the reverse direction .",
    "let @xmath42 denote the training sequence from receiver @xmath3 .",
    "then the observed signal at transmitter @xmath3 is given by @xmath43 where @xmath44 $ ] is the vector of @xmath27 independent noise samples .",
    "note that @xmath45 corresponds to the reverse signal used to compute the sinr in the max - sinr algorithm , where the transmitted symbol @xmath46 . hence replacing the corresponding mse by the ls cost function",
    ", we wish to select @xmath20 to @xmath47 giving the solution @xmath48 we must normalize the beamformer / receive filter after each update to satisfy the power constraint .",
    "this does not change the sinr of the corresponding reverse / forward link .",
    "however , it does influence the results in subsequent updates .",
    "( this normalization is also included in the max - sinr algorithm and has been empirically observed to improve performance relative to unnormalized updates . )",
    "the _ bi - directional _ ls algorithm therefore consists of the following steps :    1 .",
    "_ backward training _ : the receivers synchronously transmit @xmath27 training symbols given by the backward training matrix @xmath49 .",
    "receiver @xmath3 uses the current estimate @xmath41 as the beamformer , and each transmitter @xmath3 updates the beamformer @xmath20 according to ( [ eq : v_k ] ) .",
    "forward training _ : the transmitters synchronously transmit @xmath27 training symbols given by the training matrix @xmath50 , and each receiver @xmath3 updates the filter @xmath19 according to ( [ eq : g_k ] ) with a normalization to satisfy a power constraint .",
    "3 .   iterate the preceding steps up to a maximum number of iterations .",
    "4 .   transmit data in the forward direction .",
    "the algorithm repeats each block .",
    "the training sequences must be linearly independent across transmitters / receivers in order to distinguish all sources , and ideally should have low cross - correlation to improve the estimation accuracy .",
    "as the training length @xmath27 becomes large , the solution given by and approaches the corresponding minimum mse solution , or equivalently , the update in the max - sinr algorithm .",
    "hence by running sufficiently many forward - backward cycles within each block , each with sufficiently long training sequences , the performance should approach that of the max - sinr algorithm .    for a fixed amount of training data",
    "there is generally an optimal number of forward - backward iterations . with too few iterations the transmit beam and receiver filter",
    "do not converge to the appropriate fixed point , whereas with too many iterations each segment contains insufficient training symbols to obtain accurate filter estimates .",
    "this is illustrated in the next section .",
    "for high snrs , the trade - off generally favors more iterations since the number of iterations needed to achieve the optimal fixed point increases with snr .    when consecutive blocks are highly correlated , i.e. , @xmath51 in is close to one , and with a fixed set of users , the optimal number of iterations per block is close to one in steady - state ( i.e. , once the beams and receivers start to track the channel variations ) .",
    "for this scenario the numerical results in the next section assume that each block starts with forward training using beams estimated from the preceding block .",
    "here we do not account for the possibility that the receivers continue to train during the data phase",
    ". if the receivers are able to track the channel variations during the block , then further improvements are possible by starting each block with backward training using the optimized ( updated ) receivers as beams .",
    "( this also reduces the number of switches between forward and backward training . )    with new users ( or channels ) the algorithm can be initialized with either the forward or backward training phase .",
    "initializing with the backward phase may be best if the receivers have _ a priori _ csi ( e.g. , from previous transmissions ) .",
    "otherwise , the transmitters may initialize by transmitting pilots through random beams .    as we noted previously ,",
    "our bi - direction ls algorithm differs from other schemes for two - way channel estimation as in @xcite in that we directly estimate the filter coefficients as opposed to estimating the csi needed to compute those coefficients .",
    "the main advantages of direct filter estimation are that it automatically accounts for varying interference levels and filter estimation error .",
    "that is , pilots from distant transmitters / receivers have little effect on the filter estimate , so are automatically ignored .",
    "in contrast , channel estimation schemes must determine what csi needs to be estimated .",
    "obtaining accurate csi via two - way training may also preclude all users from training simultaneously , which extends the training period .",
    "finally , the filter estimation criterion ( e.g. , least squares ) provides the best filter estimate at the transmit / receive side given the current set of filters / beams at the opposite side .",
    "in contrast , filter estimates must be modified to account for inaccurate csi @xcite .",
    "the main disadvantage of the bi - directional filter estimation scheme proposed here , relative to channel estimation , is that it takes multiple iterations to converge .      for a given coherence block length @xmath7",
    "there is an optimal amount of training per block ; more training gives better filter estimates , but takes away symbols for data transmission .",
    "as the length of the coherence block decreases , the optimal training length decreases .",
    "one way to effectively increase the amount of training for small @xmath7 is to include training data from previous blocks . because the channels , beams , and filters are assumed to vary over successive blocks , it is also important to discount the data from past blocks when computing the current estimates .",
    "one possibility is to modify the least squares cost function by including exponentially weighted data from previous blocks , namely , @xmath52 where @xmath9 is the current block index , @xmath53 and @xmath54 are , respectively , the @xmath13-th training symbol and the corresponding received signal vector for user @xmath3 in block @xmath55 , the summation in the parentheses is the sum error square for the @xmath55-th block , and @xmath56 $ ] is the exponential weighting factor .",
    "roughly speaking , the memory of the algorithm spans @xmath57 coherence blocks .",
    "taking @xmath58 corresponds to infinite memory .",
    "we also add a regularization term @xmath59 , where @xmath60 is a small positive constant .",
    "this helps to stabilize the solution when @xmath9 is small , since the amount of training may be insufficient to estimate the filters .",
    "similar to the ls algorithm in the preceding subsection , for the receive filter update in the original direction , given the training sequence @xmath61 and the received signals @xmath62 for block @xmath63 , the receive filter of user @xmath3 is updated by solving @xmath64 the solution to this minimization problem can be computed for each block @xmath9 .",
    "however , it is not necessary to store all of the past data to update the solution . a block recursive algorithm for updating @xmath19",
    "is shown in table [ table1 ] , and consists of updating the state variables @xmath65 ( @xmath66 matrix ) , and calculating @xmath67 ( @xmath68 matrix ) at each block using the current training data .    .block",
    "recursive ls algorithm [ cols=\"<\",options=\"header \" , ]     similarly , in the backward direction , we update the beamformer @xmath20 using the analogous exponentially weighted ls objective , i.e. , @xmath69 the recursive method in table [ table1 ] is again applicable where each transmitter updates the matrix @xmath70 as the counterpart of @xmath65 . the _ bi - directional recursive least squares ( rls ) _ algorithm is then given by the following steps :    1 .",
    "_ initialization : _ the first training phase can be through an arbitrary set of beamformers / receive filters , although the updates in table 1 are initialized by setting @xmath71 to the all - zero vector , @xmath72 , and @xmath73 .",
    "_ backward training : _ the receivers synchronously transmit @xmath27 training symbols using the current normalized receivers as beams , i.e. , receiver @xmath3 sends the training symbols @xmath74 to its associated transmitter with the normalized version of the beam @xmath75 .",
    "each receiver @xmath3 then updates @xmath76 according to table [ table1 ] substituting @xmath77 and @xmath78 for @xmath19 and @xmath79 .",
    "forward training : _ the transmitters synchronously transmit @xmath27 training symbols using the current normalized beams , i.e. , transmitter @xmath3 transmits the @xmath27 training symbols @xmath80 using the normalized version of the beam @xmath81 . each receiver @xmath3 then updates @xmath82 , @xmath67 , and @xmath65 according to the algorithm in table [ table1 ] .",
    "the transmitters synchronously transmit data in the forward direction using the updated beams for the duration of the coherence block .",
    "in contrast with the ( unweighted ) ls algorithm , here we assume that there is only one iteration per block . this is because the training length is assumed to be relatively short , so that multiple iterations would likely perform worse .",
    "in this section , we present numerical results for a network of three users with @xmath83 mimo channels . in each simulation run , all channel matrices ( direct and cross ) are independently generated following the block - fading model in with unit variance and a given choice of @xmath51 .",
    "white gaussian additive noise is assumed with variance @xmath84 so that the snr is then @xmath85 .",
    "all results shown are averaged over multiple channel realizations .",
    "next , we present results for the bi - directional ls algorithm .",
    "we then consider the bi - directional rls algorithm .",
    "all training schemes presented in this section also include an additional receive filter update during the data transmission .",
    "specifically , each receiver applies the current filter to estimate the transmitted binary symbols , and at the end of each block , updates the receive filter again to minimize the sum error square of those estimated symbols , similar to the forward training in the bi - directional ls algorithm .",
    "however , the sum rate is still evaluated at the beginning of the data transmission period for each block .",
    "we first consider the bi - directional ls algorithm for constant channels ( @xmath86 ) with a snr of @xmath87  db . in this case , as the training length goes to infinity , the sum - rate achieved by the algorithm should approach that achieved by the max - sinr algorithm with perfect csi .",
    "this is illustrated in figure  [ fig1 ] , which shows the sum - rate achieved with bi - directional training and that achieved by the max - sinr algorithm as a function of the training length ( @xmath88 ) normalized by @xmath7 , which is 1000 symbols here .",
    "the figure also shows the throughput achieved the bi - directional scheme , where throughput is given by the rate per channel use after subtracting off the overhead for training . after accounting for this overhead",
    ", it can be seen that the optimal normalized training length is around 0.02 .",
    "a single iteration of bi - directional training per block is applied in this example . for comparison",
    ", we also show the sum - rate and throughput achieved by a `` forward training only '' scheme in which the initial beamformer of each user is fixed and only the receiver filters are updated using by the same training method .",
    "clearly the two - way training significantly improves over only one - way training .",
    "next , to illustrate the effect of varying the number of iterations per coherence block , we consider a network with _",
    "_ block fading channels ( i , e , @xmath89 ) .",
    "figure  [ fig_multicycles ] shows the sum - rate versus the total training length for a snr of @xmath90  db .",
    "each curve corresponds to a different number of iterations ( cycles ) per block , where the total amount of training is evenly divided among each iteration .",
    "for example , with 128 training symbols and 4 bi - directional iterations , the training alternates between the forward and reverse directions every 16 symbols . as in the previous case",
    ", we also show the performance of the max - sinr algorithm and that of forward training only . again for this case , the bi - directional training scheme can provide a substantial benefit relative to forward training only .",
    "however , the results also indicate that significant training is needed to approach the sum rate possible with perfect channel knowledge .",
    "it can also be seen that given a fixed training length there is an optimal number of bi - directional iterations ; with too few iterations the transmit beam and receiver filter do not converge to the appropriate fixed point , whereas with too many iterations each segment contains insufficient training symbols to obtain accurate filter estimates .",
    "for high snrs , the tradeoff generally favors more iterations since the number of iterations needed to achieve the optimal fixed point increases with snr .",
    "next , to gain insight into the performance of the bi - directional ls algorithm as a function of the snr , we consider a limiting model in which their is a single iteration per block and the training data per iteration goes to infinity . in this case",
    ", each update will be equivalent to the corresponding update in the max - sinr algorithm .",
    "[ fig4 ] shows the sum rate yielded by this limiting scheme above versus the snr for channels with correlated fading corresponding to different choices of @xmath51 .",
    "we also show the performance of two schemes in which only two of the three users are allowed to transmit and the two users either update their beams using bi - directional training or forward training only , still assuming an infinite number of training bits per update .",
    "first consider the scheme corresponding to three users with @xmath91 . in this case",
    "the channel is not changing from one iteration to the next and thus the algorithm is the same as the max - sinr algorithm , which appears to be achieving the optimal high - snr slope here .",
    "when the channel is not constant ( @xmath92 ) , the beamformers and receive filters are always mismatched due to the channel fading ; this mismatch eventually limits the growth of the sum - rate for the three user schemes as the snr increases .",
    "the two schemes in which only two user transmit have nearly identical performance and both appear to achieve the optimal high - snr slope for two users with rank 1 codebooks . only shows the curves for the two - user schemes corresponding to the case of @xmath89 ; the performance for other choices of @xmath51 is very similar . ]",
    "this is because for a two - user @xmath93 mimo system , it is much easier to orthogonalize the two users and indeed this can be done by only adapting the receive filters , while for a three - user system , both the beamformers and receive filters need to be chosen to achieve alignment .",
    "this suggests that for a high enough snr in a time - varying channel , it may be better to only allow two - users to transmit in this way .",
    "now we turn to the performance of the bi - directional rls algorithm .",
    "recall , that this algorithm was motivated for cases where the number of channel uses per block is small and there is significant correlation between blocks . figures  [ fig3 ] and [ fig2 ] show the performance of the bi - directional rls with different choices of @xmath94 and ls algorithms as a function of the training length in a channels with correlated fading corresponding to @xmath95 and @xmath96 , respectively .",
    "both the sum - rate ( solid lines ) and the throughput ( dashed lines ) of each algorithm is shown as well as for forward - training only .",
    "for all the algorithms , a single iteration of training is used per block and the snr is 10db . it can be seen that when the total training length is limited the bi - directional rls algorithm with an appropriate @xmath94 gives a higher sum - rate than the ls algorithm , while if training bits are sufficient the ls algorithm gives the high rate .",
    "the gains of the bi - directional rls algorithm are more significant when @xmath51 is closer to @xmath97 , i.e. , the channel is varying more slowly .",
    "when we consider the throughput accounting for training overhead , the gains of the bi - directional rls algorithm diminish , and for @xmath98 become insignificant for most ranges of training .",
    "of course this comparison depends on the block - length @xmath7 , which here we assume is given by @xmath99 .",
    "in other simulations , we have also observed that the performance benefits of the rls algorithm are greater at lower snrs , i.e.  when estimation becomes more difficult .",
    "( @xmath95).,width=336 ]     ( @xmath96).,width=336 ]",
    "we have presented a distributed algorithm for iteratively adapting beamformers and receive filters in mimo interference networks without csi .",
    "the algorithm is based on using bi - directional training in a synchronous tdd system .",
    "this algorithm approaches the performance of the max - sinr algorithm with full csi as the amount of training and the number of training cycles increase . a recursive modification of the algorithm that uses exponentially weighted data from previous blocks was also given and shown to offer better performance when the channels are highly correlated and the training length very small .",
    "here we mainly demonstrated the performance of these algorithms via simulations ; analyzing the performance is an interesting direction for future work .",
    "d. a. schmidt , c. shi , r. a. berry , m. l. honig , and w. utschick , `` minimum mean squared error interference alignment , '' in _ proc . of asilomar conference on signals , systems , and computers _ ,",
    "nov . , 2009 .",
    "c. shi , d. a. schmidt , r. a. berry , m. l. honig , and w. utschick , `` distributed interference pricing for the mimo interference channel , '' in _ proc .",
    "ieee international conference on communications _ ,",
    "june 2009 .",
    "v. r. cadambe and s. a. jafar , `` interference alignment and the degrees of freedom for the k user interference channel , '' _ ieee transactions on information theory _ , vol .",
    "54 , no .",
    "8 , pp . 3425 - 3441 , aug .",
    "2008 .",
    "r. osawa , h. murata , k. yamamoto , and s. yoshida , `` performance of two - way channel estimation technique for multi - user distributed antenna systems with spatial precoding , '' in _ proc .",
    "vehicular technology conference fall ( vtc 2009-fall ) _ , sept ."
  ],
  "abstract_text": [
    "<S> we study distributed algorithms for adjusting beamforming vectors and receiver filters in multiple - input multiple - output ( mimo ) interference networks , with the assumption that each user uses a single beam and a linear filter at the receiver . </S>",
    "<S> in such a setting there have been several distributed algorithms studied for maximizing the sum - rate or sum - utility assuming perfect channel state information ( csi ) at the transmitters and receivers . </S>",
    "<S> the focus of this paper is to study adaptive algorithms for time - varying channels , without assuming any csi at the transmitters or receivers . </S>",
    "<S> specifically , we consider an adaptive version of the recent max - sinr algorithm for a time - division duplex system . </S>",
    "<S> this algorithm uses a period of bi - directional training followed by a block of data transmission . </S>",
    "<S> training in the forward direction is sent using the current beam - formers and used to adapt the receive filters . </S>",
    "<S> training in the reverse direction is sent using the current receive filters as beams and used to adapt the transmit beamformers . </S>",
    "<S> the adaptation of both receive filters and beamformers is done using a least - squares objective for the current block . in order to improve the performance </S>",
    "<S> when the training data is limited , we also consider using exponentially weighted data from previous blocks . </S>",
    "<S> numerical results are presented that compare the performance of the algorithms in different settings . </S>"
  ]
}