{
  "article_text": [
    "constraint programming ( cp ) is a widely used and efficient technique to solve combinatorial optimization problems .",
    "however in practice many problems are over - constrained ( intrinsically or from being badly stated ) .",
    "several frameworks have been proposed to handle over - constrained problems , mostly by introducing _ soft constraints _ that are allowed to be ( partially ) violated .",
    "the most well - known framework is the partial constraint satisfaction problem framework ( pcsp @xcite ) , which includes the max - csp framework that tries to maximize the number of satisfied constraints . since in this framework",
    "all constraints are either violated or satisfied , this objective is equivalent to minimizing the number of violations .",
    "it has been extended to the _ weighted - csp _",
    "@xcite , associating a degree of violation ( not just a boolean value ) to each constraint and minimizing the sum of all weighted violations .",
    "the _ possibilistic - csp _",
    "@xcite associates a preference to each constraint ( a real value between 0 and 1 ) representing its importance .",
    "the objective of the framework is the hierarchical satisfaction of the most important constraints , that is , the minimization of the highest preference level for a violated constraint .",
    "the _ fuzzy - csp _",
    "@xcite is somewhat similar to the possibilistic - csp but here a preference is associated to each tuple of each constraint .",
    "a preference value of 0 means the constraint is highly violated and 1 stands for satisfaction .",
    "the objective is the maximization of the smallest preference value induced by a variable assignment .",
    "the last two frameworks are different from the previous ones since the aggregation operator is a @xmath0 function instead of addition .",
    "max - csps are typically encoded and solved with one of two generic paradigms : valued - csps @xcite and semi - rings @xcite .",
    "another approach to model and solve over - constrained problems involves _ meta - constraints _ @xcite .",
    "the idea behind this technique is to introduce a set of domain variables @xmath1 that capture the violation cost of each soft constraint . by correctly constraining these variables it is possible to replicate the previous frameworks and even to extend the modeling capability to capture other types of violation measures .",
    "namely the authors argue that although the max - csp family of frameworks is quite efficient to capture local violation measures it is not as adequate to model violation costs involving several soft constraints simultaneously . by defining ( possibly global ) constraints on @xmath1 such",
    "a behaviour can be easily achieved .",
    "the authors propose to replace each soft constraint @xmath2 present in a model by a disjunctive constraint specifying that either @xmath3 and the constraint @xmath2 is hard or @xmath4 and @xmath2 is violated .",
    "this technique allows the resolution of over - constrained problem within traditional cp solvers .",
    "comparatively few efforts have been invested in developing soft versions of common global constraints @xcite .",
    "global constraints are often key elements in successfully modeling real applications and being able to easily and effectively soften such constraints would yield a significant improvement in flexibility . in this paper",
    "we study two global constraints : the widely known global cardinality constraint ( ) @xcite and the new @xcite constraint . for each of these",
    "we propose new violation measures and provide the corresponding filtering algorithms to achieve domain consistency .",
    "all the constraint softening is achieved by enriching the underlying graph representation with additional arcs that represent possible relaxations of the constraint .",
    "violation costs are then associated to these new arcs and known graph algorithms are used to achieve domain consistency .",
    "the two constraints studied in this paper are useful to model and solve personnel rostering problems ( prp ) .",
    "the prp objective is typically to distribute a set of working shifts ( or days off ) to a set of employees every day over a planning horizon ( a set of days ) .",
    "the  is a perfect tool to restrict the number of work shifts of each type ( day , evening , and night for instance ) performed by each employee .",
    "other types of constraints involve sequences of shifts over time , typically forbidding non ergonomic schedules .",
    "the  constraint has the expressive power necessary to cope with the complex regulations found in many organizations .",
    "since most real rostering applications are over - constrained ( due to lack of personnel or over - optimistic scheduling objectives ) , soft versions of the  and constraints promise to significantly improve our modelling flexibility .",
    "this paper is organized as follows .",
    "section  [ background ] presents background information on constraint programming and the softening of ( global ) constraints . in section  [ gcc ] and [ reg ]",
    "we describe the softening of the  and the  constraint respectively .",
    "both constraints are softened with respect to two violation measures .",
    "we also provide corresponding filtering algorithms achieving domain consistency .",
    "section  [ agg ] discusses the aggregation of several soft ( global ) constraints by meta - constraints .",
    "finally , a conclusion is given in section  [ conclusion ] .",
    "we assume familiarity with the basic concepts of constraint programming . for a thorough explanation of constraint programming , see  @xcite .",
    "a constraint satisfaction problem ( csp ) consists of a finite set of variables @xmath5 with finite domains @xmath6 such that @xmath7 for all @xmath8 , together with a finite set of constraints @xmath9 , each on a subset of @xmath10 .",
    "a constraint @xmath11 is defined as a subset of the cartesian product of the domains of the variables that are in @xmath12 .",
    "a tuple @xmath13 is a solution to a csp if for every constraint @xmath11 on the variables @xmath14 we have @xmath15 .",
    "a constraint optimization problem ( cop ) is a csp together with an objective function to be optimized .",
    "a solution to a cop is a solution to the corresponding csp that has an optimal objective function value .",
    "[ def : hac ] a constraint @xmath12 on the variables @xmath16 @xmath17 is called domain consistent if for each variable @xmath18 and value @xmath19 , there exist values @xmath20 in @xmath21 , such that @xmath22 .",
    "our definition of domain consistency corresponds to hyper - arc consistency or generalized arc consistency , which are also often used in the literature .",
    "a csp is domain consistent if all its constraints are domain consistent .",
    "a csp is inconsistent if it has no solution .",
    "similarly for a cop .",
    "when a csp is inconsistent it is also said to be over - constrained .",
    "it is then natural to identify soft constraints , that are allowed to be violated , and minimize the total violation according to some criteria . for each soft constraint @xmath12",
    ", we introduce a function that measures the violation , and has the following form : @xmath23 this approach has been introduced in @xcite and was developed further in @xcite",
    ". there may be several natural ways to evaluate the degree to which a global constraint is violated and these are not equivalent usually .",
    "a standard measure is the variable - based cost :    [ def : varcost ] given a constraint @xmath12 on the variables @xmath24 and an instantiation @xmath25 with @xmath19 , the variable - based cost of violation of @xmath12 is the minimum number of variables that need to change their value in order to satisfy the constraint .",
    "alternative measures exist for specific constraints .",
    "for example , if a constraint is expressible as a conjunction of binary constraints , the cost may be defined as the number of these binary constraints that are violated . for the soft  and the soft  constraint",
    ", we will introduce new violation measures , that are likely to be more effective in practical applications .",
    "a global cardinality constraint ( ) on a set of variables specifies the minimum and maximum number of times each value in the union of their domains should be assigned to these variables .",
    "rgin developed a domain consistency algorithm for the , making use of network flows @xcite .",
    "a variant of the  is the cost- , which can be seen as a weighted version of the @xcite . for the cost-",
    "a weight is assigned to each variable - value assignment and the goal is to satisfy the   with minimum total cost .    throughout this section",
    ", we will use the following notation ( unless specified otherwise ) .",
    "let @xmath10 denote a set of variables @xmath26 with respective finite domains @xmath27 .",
    "we define @xmath28 and we assume a fixed but arbitrary ordering on @xmath29 . for @xmath30 ,",
    "let @xmath31 , with @xmath32 .",
    "finally , let @xmath33 be a variable with finite domain @xmath34 , representing the cost of violation of the .",
    "[ def : gcc ] @xmath35    we first give a generic definition for a soft version of the .",
    "[ def : softgcc ] @xmath36(x , l , u , z ) =   \\{(d_1 , \\dots , d_n , \\tilde{d } ) \\mid   &",
    "d_i \\in d_i , \\tilde{d } \\in d_z , \\\\ & { \\rm violation}_{{\\textup{\\texttt{soft\\_gcc}}}[\\star]}(d_1 , \\dots , d_n ) \\leq \\tilde{d } \\ } , \\end{array}\\ ] ] where @xmath37 defines a violation measure for the .",
    "in order to define measures of violation for the , it is convenient to introduce the following functions .    given @xmath38 , define for all @xmath30 @xmath39 @xmath40    let @xmath41}$ ] denote the variable - based cost of violation ( see definition  [ def : varcost ] ) of the .",
    "the next lemma expresses @xmath41}$ ] in terms of the above functions .",
    "[ lem : varcost ] given @xmath38 , @xmath42}(x ) =   \\max \\left ( \\sum_{d \\in d_x } { \\rm overflow}(x , d ) , \\sum_{d \\in d_x } { \\rm underflow}(x , d ) \\right)\\ ] ] provided that @xmath43    the variable - based cost of violation corresponds to the minimal number of re - assignments of variables until both @xmath44 and @xmath45 .",
    "assume @xmath46 .",
    "variables assigned to values @xmath47 with @xmath48 can be assigned to values @xmath49 with @xmath50 , until @xmath51 . in order to achieve @xmath44 , we still need to re - assign the other variables assigned to values @xmath47 with @xmath48 .",
    "hence , in total we need to re - assign exactly @xmath52 variables .    similarly when we assume @xmath53 .",
    "if ( [ eq : assumption ] ) does not hold , there is no variable assignment that satisfies the .",
    "+ without assumption ( [ eq : assumption ] ) , the variable - based violation measure for the  can not be applied .",
    "therefore , we introduce the following value - based violation measure , which can also be applied when assumption ( [ eq : assumption ] ) does not hold .",
    "[ def : valcost ] for @xmath38 the value - based cost of violation is @xmath54    we denote the value - based violation measure for the  by @xmath55}$ ] .",
    "first , we introduce the concept of a flow in a directed graph , following schrijver  @xcite .",
    "a directed graph is a pair @xmath56 where @xmath57 is a finite set of vertices and @xmath58 is a family of ordered pairs from @xmath57 , called arcs . for @xmath59 ,",
    "let @xmath60 and @xmath61 denote the family of arcs entering and leaving @xmath62 respectively .",
    "a ( directed ) walk in @xmath63 is a sequence @xmath64 where @xmath65 , @xmath66 , @xmath67 and @xmath68 for @xmath69 .",
    "if there is no confusion , @xmath70 may be denoted as @xmath71 .",
    "a ( directed ) walk is called a ( directed ) path if @xmath72 are distinct .",
    "a closed ( directed ) walk , i.e. @xmath73 , is called a ( directed ) circuit if @xmath74 are distinct .",
    "let @xmath75 .",
    "we apply a capacity function @xmath76 , a demand function @xmath77 and a cost function @xmath78 on the arcs .",
    "a function @xmath79 is called a _ feasible flow _ from @xmath80 to @xmath81 , or an @xmath82 flow , if @xmath83 where @xmath84 for all @xmath85 .",
    "property ( [ eq : flow ] ) ensures flow conservation , i.e. for a vertex @xmath86 , the amount of flow entering @xmath62 is equal to the amount of flow leaving @xmath62 .",
    "the value of an @xmath82 flow @xmath87 is defined as @xmath88 in other words , the value of a flow is the net amount of flow leaving @xmath80 , which can be shown to be equal to the net amount of flow entering @xmath81 .",
    "the cost of a flow @xmath87 is defined as @xmath89 a _ minimum - cost flow _ is a feasible @xmath82 flow of minimum cost .",
    "the _ minimum - cost flow problem _ is the problem of finding such a minimum - cost flow .",
    "a solution to @xmath38 corresponds to a feasible @xmath82 flow of value @xmath90 in the graph @xmath91 with vertex set @xmath92 and edge set @xmath93 where @xmath94 with demand function @xmath95 and capacity function @xmath96    consider the csp @xmath97 where @xmath98 , @xmath99 , @xmath100 , @xmath101 and @xmath102 . in figure",
    "[ fig : gcc].a the corresponding graph @xmath103 for the  by applying the above procedure is presented .",
    "+ a.  original     + b.  [ var ]     + c.  [ val ]      for the variable - based violation measure , we adapt the graph @xmath103 in the following way .",
    "we add the arc set @xmath104 , with demand @xmath105 , capacity @xmath106 for all arcs @xmath107 .",
    "further , we apply a cost function @xmath108 , where @xmath109 let the resulting graph be denoted by @xmath110 .",
    "consider the csp @xmath111(x , l , u , z)\\\\ \\texttt{minimize } z \\end{array}\\ ] ] where @xmath98 , @xmath99 , @xmath100 , @xmath101 and @xmath102 .",
    "in figure  [ fig : gcc].b the graph @xmath110 for the [ var ] is presented .",
    "[ thm : var ] a minimum - cost flow in the graph @xmath110 corresponds to a solution to the @xmath112 $ ] , minimizing the variable - based violation .    an assignment @xmath113 corresponds to the arc @xmath114 with @xmath115 . by construction ,",
    "all variables need to be assigned to a value and the cost function exactly measures the variable - based cost of violation .",
    "the graph @xmath110 corresponds to a particular instance of the cost-  @xcite .",
    "hence , we can apply the filtering procedures developed for that constraint directly to the [ var ] .",
    "the [ var ] also inherits from the cost-  the time complexity of achieving domain consistency , being @xmath116 where @xmath117 and @xmath118 .",
    "note that @xcite also consider the variable - based cost measure for a different version of the soft .",
    "their version considers the parameters @xmath119 and @xmath120 to be variables too .",
    "hence , the variable - based cost evaluation becomes a rather poor measure , as we trivially can change @xmath119 and @xmath120 to satisfy the .",
    "they fix this by restricting the set of variables to consider to be the set @xmath10 , which corresponds to our situation .",
    "however , they do not provide a filtering algorithm for that case .      for the value - based violation measure",
    ", we adapt the graph @xmath103 in the following way .",
    "we add arc sets @xmath121 and @xmath122 , with demand @xmath105 for all @xmath123 and capacity @xmath124 further , we again apply a cost function @xmath108 , where @xmath125 let the resulting graph be denoted by @xmath126 .",
    "consider the csp @xmath127(x , l , u , z)\\\\ \\texttt{minimize } z \\end{array}\\ ] ] where @xmath98 , @xmath99 , @xmath128 , @xmath129 and @xmath130 . in figure",
    "[ fig : gcc].c the graph @xmath126 for the  with respect to value - based cost is presented .",
    "a minimum - cost flow in the graph @xmath126 corresponds to a solution to the @xmath131 $ ] , minimizing the value - based violation .",
    "an assignment @xmath113 corresponds to the arc @xmath114 with @xmath115 . by construction , all variables need to be assigned to a value and the cost function exactly measures the value - based cost of violation .",
    "unfortunately , the graph @xmath126 does not preserve the structure of the cost-  because of the arcs @xmath132 .",
    "therefore we can not blindly apply the same filtering algorithms .",
    "however , it is still possible to design an efficient filtering algorithm for the value - based  ( in the same spirit of the filtering algorithm for the cost- ) , based again on flow theory . for this",
    ", we need to introduce the residual graph @xmath133 of a flow @xmath87 on @xmath56 ( with respect to @xmath134 and @xmath135 ) , where @xmath136 here @xmath137 if @xmath138 .",
    "we extend @xmath139 to @xmath140 by defining @xmath141 for each @xmath142 .",
    "let @xmath87 be a minimum - cost flow in @xmath126",
    ". then @xmath131(x , l , u , z)$ ] is domain consistent if and only if @xmath143 and @xmath144 where @xmath145 denotes the cost of a shortest path from @xmath135 to @xmath18 in the residual graph @xmath146 .    from flow theory @xcite we know that , given a minimum - cost flow @xmath87 in @xmath126 , if we enforce arc @xmath147 to be in a minimum - cost flow @xmath148 in @xmath126 , @xmath149 where @xmath150 is the shortest @xmath151 path in @xmath152 .",
    "in order for a value @xmath153 to be consistent , the cost of a minimum - cost flow that uses @xmath147 should be less than or equal to @xmath154 . by the above fact",
    ", we only need to compute a shortest path from @xmath135 to @xmath18 instead of a new minimum - cost flow .     +",
    "a minimum - cost flow @xmath87 in @xmath126 can be computed in @xmath155 time ( see @xcite ) , where again @xmath117 and @xmath118 .",
    "compared to the complexity of the [ var ] , we have a factor @xmath156 instead of @xmath90 .",
    "this is because computing the flow for [ val ] is dependent on the number of arcs @xmath156 rather than on the number variables @xmath90 .",
    "a shortest @xmath151 path in @xmath126 can be computed in @xmath157 time .",
    "hence the  with respect to the value - based violation measure can be made domain consistent in @xmath158 time as we need to check @xmath159 arcs for consistency .",
    "when @xmath160 in @xmath131(x , l , u , z)$ ] , the arc set @xmath132 is empty . in that case , @xmath126 has a particular structure , i.e. the only costs appear on arcs from @xmath29 to @xmath81 .",
    "as pointed out in @xcite for the  constraint , constraints with this structure can be checked for consistency in @xmath161 time , and domain consistency can be achieved in @xmath162 time .",
    "the result is obtained by exploiting the strongly connected components is a subset of vertices @xmath163 such that there exists a directed @xmath164 path in @xmath103 for all @xmath165 . ] in @xmath126 restricted to vertex sets @xmath10 and @xmath29 .",
    "a  constraint @xcite on a fixed - length sequence of finite - domain variables requires that the corresponding sequence of values taken by these variables belong to a given regular language .",
    "a _ deterministic finite automaton _ ( dfa ) may be described by a @xmath166-tuple @xmath167 where @xmath168 is a finite set of states , @xmath169 is an alphabet , @xmath170 is a partial transition function , @xmath171 is the initial state , and @xmath172 is the set of final ( or accepting ) states . a finite sequence of symbols from an alphabet is called a _ string_. strings processed by @xmath173 and ending in an accepting state from @xmath174 are said to belong to the language defined by @xmath173 , denoted @xmath175 .",
    "the languages recognized by dfas are precisely regular languages .    given a sequence @xmath176 of finite - domain variables with respective domains @xmath177 , @xmath178 ,  , @xmath179",
    ", there is a natural interpretation of the set of possible instantiations of @xmath180 , @xmath181 , as a subset of all strings of length @xmath90 over @xmath169 , @xmath182 .",
    "we are now ready to state the constraint .",
    "let @xmath183 @xmath184 denote a deterministic finite automaton and @xmath185 a sequence of finite - domain variables @xmath186 with respective domains @xmath177 , @xmath178 ,  , @xmath179 . under a _ regular language membership constraint _",
    "@xmath187 ) , any sequence of values taken by the variables of @xmath180 corresponds to a string in @xmath175 .    in @xcite , a domain consistency algorithm for the constraint processed the sequence @xmath180 with the automaton @xmath173 , building a layered directed multi - graph @xmath188 where each layer @xmath189 contains a different node for each state of @xmath173 and arcs only appear between consecutive layers .",
    "each arc corresponds to a consistent variable - value pair : there is an arc from @xmath190 to @xmath191 if and only if there exists some @xmath192 such that @xmath193 and the arc belongs to a path from @xmath194 in the first layer to a member of @xmath174 in the last layer .",
    "the existence of such an arc , labeled @xmath195 , constitutes a support for variable @xmath18 taking value @xmath195 .",
    "for example , consider a sequence @xmath180 of five variables with @xmath196 , @xmath197 , @xmath198 , @xmath199 , and @xmath200 .",
    "figure [ digraph ] gives an automaton @xmath173 ( with its initial state labeled @xmath201 ) and the resulting graph for constraint regular(@xmath187 ) . as a result ,",
    "value @xmath202 is removed from @xmath178 and @xmath203 .",
    "we first give a generic definition for a soft version of the  constraint .",
    "let @xmath183 @xmath184 denote a deterministic finite automaton and @xmath185 a sequence of finite - domain variables @xmath186 with respective domains @xmath177 , @xmath178 ,  , @xmath179 .",
    "let @xmath33 be a finite - domain variable of domain @xmath204 representing the cost of a violation and let @xmath205 be some distance function over strings . under a _",
    "soft regular language membership constraint _",
    "x},m , z)$ ] , for any sequence of values @xmath207 taken by the variables of @xmath180 we have @xmath208 .",
    "our first instantiation of the distance function yields the variable - based cost :    the number of positions in which two strings of same length differ is called their _",
    "hamming distance_.    intuitively , such a distance represents the number of symbols we need to change to go from one string to the other , or equivalently the number of variables whose value must change . using the hamming distance for @xmath135 in the previous definition ,",
    "@xmath33 becomes the variable - based cost .",
    "another distance function that is often used with strings is the following :    the smallest number of insertions , deletions , and substitutions required to change one string into another is called the _ edit distance_.    it captures the fact that two strings that are identical except for one extra or missing symbol should be considered close to one another .",
    "for example , the edit distance between strings `` bcdea '' and `` abcde '' is two : insert an a at the front of the first string and delete the a from its end .",
    "the hamming distance between the same strings is five : every symbol must be changed .",
    "edit distance is probably a better way to measure violations of a constraint .",
    "we provide a more natural example in the area of rostering . given a string , we call _ stretch _ a maximal substring of identical values . we often need to impose restrictions on the length of stretches of work shifts , and these can be expressed with a  constraint .",
    "suppose stretches of @xmath209 s and @xmath202 s must each be of length @xmath210 and consider the string `` abbaabbaab '' : its hamming distance to a string belonging to the corresponding regular language is @xmath166 since changing either the first @xmath209 to a @xmath202 or @xmath202 to an @xmath209 has a domino effect on the following stretches ; its edit distance is just @xmath210 since we can insert an @xmath209 at the beginning to make a legal stretch of @xmath209 s and remove the @xmath202 at the end . in this case , the edit distance reflects the number of illegal stretches whereas the hamming distance is proportional to the length of the string .",
    "for both cost measures , we proceed by modifying the layered directed graph @xmath103 built for the `` hard '' version of  into graph @xmath110 .",
    "before , we added an arc from @xmath190 to @xmath191 if @xmath193 for some @xmath192 ; now we relax it slightly to any @xmath211 .",
    "this only makes a difference if the domains of the variables are not initially full .",
    "arcs are never removed in @xmath110 but their labels are updated instead .",
    "the label of an arc @xmath212 is generalized to the invariant @xmath213 ; as values are removed from the domain of variable @xmath18 , they are also removed from the corresponding @xmath214 s .",
    "the cost of using an arc @xmath212 for variable - value pair @xmath215 will be zero if @xmath195 belongs to @xmath214 and some positive integer cost otherwise .",
    "this cost represents the penalty for an individual violation . in the remainder of the section we will consider unit costs but the framework also makes it possible to use varying costs , e.g. to distinguish between insertions and substitutions when using the edit distance",
    ". the graph on the left at figure [ soft - digraph ] is a shorthand version of @xmath110 for the automaton of figure [ digraph ] .",
    "since all values in @xmath169 are considered , the same arcs appear between consecutive layers .",
    "what changes from one layer to the other are the @xmath214 labels .",
    "taking into account _ substitutions _",
    ", common to both hamming and edit distances , is immediate from the previous modification .",
    "it is not difficult to see that the introduction of costs transforms a supporting path in the domain consistency algorithm for  into a zero - cost path in the modified graph .",
    "the cost of a shortest path from @xmath194 in the first layer to a member of @xmath174 in the last layer corresponds to the smallest number of variables forced to take a value outside of their domain .",
    "[ thm : cost - eval ] a minimum - cost path from @xmath216 to @xmath217 in @xmath110 corresponds to a solution to @xmath218 $ ] minimizing the variable - based cost ( hamming distance ) .    just as the existence of a path through a given arc representing a variable - value pair constituted a support for that pair in the filtering algorithm for , the existence of a path whose cost does nt exceed @xmath154 constitutes a support for that variable - value pair in a cost - based filtering algorithm for .",
    "[ thm : cost - filt ] @xmath218({\\mathbf x},m , z)$ ] is domain consistent on @xmath185 and bound consistent on @xmath33 if and only if @xmath219 and @xmath220 where @xmath221 and @xmath222 denotes the cost of a shortest path from @xmath120 to @xmath62 in @xmath110 .    computing shortest paths from the initial state in the first layer to every other node and from every node to a final state in the last layer can be done in @xmath223 time refers to the number of transitions in the automaton . ] through topological sorts because of the special structure of the graph . that computation can also be made incremental in the same way as in @xcite",
    "recently , that same result was independently obtained in @xcite .",
    "we however go further by considering edit distance , for which insertions and deletions are allowed as well .    for",
    "_ deletions _ we need to allow `` wasting '' a value without changing the current state . to this effect ,",
    "we add to @xmath110 an arc @xmath224 , with @xmath225 , if it is nt already present in the graph .",
    "to allow _ insertions _ , inspired by @xmath226-transitions in dfas , we introduce some special arcs between nodes in the same layer : if @xmath227 then we further add an arc @xmath228 with fixed positive cost .",
    "figure [ soft - digraph ] provides an example of the resulting graph ( on the right ) .",
    "unfortunately , those special arcs modify the structure of the graph since cycles ( of strictly positive cost ) are introduced .",
    "consequently shortest paths can no longer be computed through topological sorts .",
    "an efficient implementation of dijkstra s algorithm increases the time complexity to @xmath229 .",
    "regardless of this increase in computational cost , theorems [ thm : cost - eval ] and [ thm : cost - filt ] can be generalized to hold for [ edit ] as well .",
    "the preceding sections have introduced filtering algorithms based on different violation measures for two soft global constraints .",
    "if these filtering techniques are to be effective , especially in the presence of soft constraints of a different nature , they must be able to cooperate and communicate .",
    "even though there are many avenues for combining soft constraints , the objective almost always remains to minimize constraint violations .",
    "we propose here a small extension to the approach of @xcite , where meta - constraints on the cost variables of soft constraints are introduced .",
    "we illustrate this approach with the newly introduced .",
    "let @xmath230 be a set of soft constraints and @xmath231 the variable indicating the violation cost of @xmath232 .",
    "the _ soft global cardinality aggregator ( sgca ) _ is defined as @xmath233(z , l , u , z_{\\rm agg})$ ] where @xmath234 , @xmath235 is the interval defining the allowed number of occurrences of each value in the domain of @xmath236 and @xmath237 the cost variable based on the violation measure @xmath37 .",
    "when all constraints are either satisfied or violated ( @xmath238 ) the max - csp approach can be easily obtained by setting @xmath239 , @xmath240 , @xmath241 and reading the number of violations in @xmath242 .",
    "the sgca could also be used as in @xcite to enforce homogeneity ( in a soft manner ) or to define other violation measures like restricting the number of highly violated constraint .",
    "for instance , we could wish to impose that no more then a certain number of constraints are highly violated , but since we can not guarantee that this is possible the use of sgca allows to state this wish without risking to create an inconsistent problem . more generally , by defining the values of @xmath119 and @xmath120 accordingly it is possible to limit ( or at least attempt to limit ) the number violated constraints by violation cost .",
    "another approach could be to set all @xmath120 to 0 and adjust the violation function so that higher violation costs are more penalized . the use of soft meta - constraints , when possible , is also an alternative to the introduction of disjunctive constraints since they need not be satisfied for the problem to be consistent .    in the original meta - constraint framework",
    ", similar behaviour can be established by applying a cost-  to @xmath1 .",
    "for instance , we can define for each pair @xmath243 ( @xmath244 ) a cost @xmath135 which penalizes higher violations more . with the",
    ", this cost function can be stated as @xmath245 . however , as for this variant of the  we have @xmath160 , the  will be much more efficient than the cost- , as was discussed at the end of section  [ gcc ] .",
    "in fact , the sgca can be checked for consistency in @xmath161 time and made domain consistent in @xmath162 time ( where @xmath246 and @xmath247 whenever @xmath160 and @xmath248 for any cost function @xmath249 .",
    "we have presented soft versions of two global constraints : the global cardinality constraint and the regular constraint .",
    "different violation measures have been presented and the corresponding filtering algorithms achieving domain consistency have been introduced .",
    "these new techniques are based on the addition of `` relaxation arcs '' in the underlying graph and the use of known graph algorithms .",
    "we also have proposed to extend the meta - constraint framework for combining constraint violations by using the soft version of .",
    "since these two constraints are very useful to solve personnel rostering problems the next step is thus the implementation of these algorithms in order to model such problems and benchmark these new constraints .",
    "n.  beldiceanu , m.  carlsson , and t.  petit . .",
    "in _ proceedings of the tenth international conference on principles and practice of constraint programming ( cp 2004 ) _ , volume 3258 of _ lncs_. springer , 2004 .",
    "h.  fargier , j.  lang , and t.  schiex . selecting preferred solutions in fuzzy constraint satisfaction problems . in _ proceedings of the first european congress on fuzzy and intelligent technologies _ , 1993 .              t.  petit , j",
    "rgin , and c.  bessire .",
    "meta constraints on violations for over constrained problems . in _ proceedings of the 12th ieee international conference on tools with artificial intelligence ( ictai ) _ , pages 358365 , 2000 .",
    "t.  petit , j .-",
    "c . rgin , and c.  bessire . .",
    "in _ proceedings of the seventh international conference on principles and practice of constraint programming ( cp 2001 ) _ , volume 2239 of _ lncs _ , pages 451463 .",
    "springer , 2001 ."
  ],
  "abstract_text": [
    "<S> we describe soft versions of the global cardinality constraint and the regular constraint , with efficient filtering algorithms maintaining domain consistency . for both constraints , </S>",
    "<S> the softening is achieved by augmenting the underlying graph . </S>",
    "<S> the softened constraints can be used to extend the meta - constraint framework for over - constrained problems proposed by petit , rgin and bessire . </S>"
  ]
}