{
  "article_text": [
    "we present in this section the method first introduced by giardin , kurchan and peliti  @xcite to simulate cumulant generating functions in discrete time markov chains . in this case , the dynamics is defined by the transition _ probabilities _ @xmath26 between configurations and the corresponding the master equation reads @xmath27 conservation of probability enforces the matrix @xmath28 to be stochastic , i.e. for all @xmath29 , @xmath30 . starting from a fixed configuration @xmath31 the explicit solution of   is@xmath32_{{{\\cal c}}{{\\cal c}}_0}.               \\label{eqn : explicit_sol_tdisc }            \\label{eqn : explicit_sol_tdisc_power}\\ ] ] the dynamical observable @xmath5 can be written as a sum over configuration changes @xmath33 . to compute the dynamical free energy @xmath11 , we first rewrite the dynamical partition function as @xmath34_{{{\\cal c}}{{\\cal c}}_0},\\end{aligned}\\ ] ] where we have introduced the matrix @xmath35_{{{\\cal c}}{{\\cal c } } ' } = u_{{{\\cal c}}{{\\cal c } } ' } e^{-\\beta\\,q_{{{\\cal c}}{{\\cal c}}'}}$ ] .",
    "let us note that @xmath36 is given by the log of the largest eigenvalue of @xmath37 .",
    "a possible strategy , used for instance in  @xcite , is thus to compute numerically this eigenvalue .",
    "the matrix @xmath37 is however exponentially large in the system size , which limits this strategy to small systems .",
    "the main advantage of this method is to yield a numerical approximation of an exact expression - as pointed out in @xcite - as opposed to our approach , efficient for large systems , but relying on importance sampling .",
    "note that the ` exact ' approach can be used to check the validity of the importance sampling approach for small system sizes , before going to larger ones , as was actually done for the simulations presented in  @xcite .",
    "comparison of expressions  ( [ eqn : explicit_sol_tdisc ] ) and  ( [ eqn : exp_s_a_explicit ] ) leads one to think that @xmath36 could be obtained from a new dynamics , induced by @xmath37 .",
    "however , the matrix @xmath37 is not stochastic , as in general @xmath38_{{{\\cal c}}{{\\cal c}}'}= \\sum_{{{\\cal c } } } u_{{{\\cal c}}{{\\cal c } } ' }   e^{-\\beta\\,q_{{{\\cal c}}{{\\cal c } } ' } } \\neq 1\\ ] ] and we should not understand   as a stochastic process with conserved probability but as a population dynamics with branching and death , where the population size is not constant .",
    "to do so , let us define @xmath39_{{{\\cal c}}{{\\cal c}}'}}{y_{{{\\cal c}}'}}=\\frac{u_{{{\\cal c}}{{\\cal c}}'}}{y_{{{\\cal c } } ' } }   e^{-\\beta\\,q_{{{\\cal c}}{{\\cal c}}'}}.\\ ] ] the matrix @xmath40 is stochastic and   now writes @xmath41 this expression is now closer to   as @xmath40 is stochastic , and can be interpreted as follows : @xmath24 agents evolve with the stochastic dynamics defined by @xmath40 and are replicated with a rate @xmath42 when they are in configuration @xmath43 .",
    "this interpretation is possible as @xmath42 _ depends solely on the initial configuration  @xmath43 _ and can thus be interpreted as a configuration - dependent reproduction rate .",
    "this was less apparent in  , where factors @xmath44 depend on both initial and final configurations .",
    "this interpretation as a population dynamics can be implemented using a diffusion monte carlo algorithm .",
    "let us consider an ensemble of @xmath45 agents ( @xmath46 ) evolving in the configuration space @xmath0 .",
    "at each time step @xmath47 ,    1 .",
    "each agent evolves according to the @xmath20-modified dynamics @xmath48 , [ itm : stoch_evol ] 2 .",
    "each agent in configuration @xmath43 is replicated / killed with probability @xmath42 , @xmath49 is replaced by @xmath50 copies , where + @xmath51 + concretely , the agent is replaced by @xmath50 copies of itself , so that the population size is increased by @xmath52 ( decreased by @xmath21 if @xmath53 ) .",
    "[ itm : clonage ]    let us show that the size of the population at time @xmath2 yields the large deviation function .",
    "_ for a given history _ , the number @xmath54 of copies in configuration @xmath43 at intermediate time @xmath55 satisfies @xmath56 , so that for the whole history @xmath57 consequently , we see from   that the population size @xmath58 behaves as @xmath59 . as usual in importance sampling approaches , the ensemble average @xmath60 has been replaced by an average over a finite number of simulations .",
    "whereas in principle correct , this approach is however impracticable since the population size varies exponentially in time and we thus add a third step to the previous algorithm :    1 .",
    "after the cloning step , the population is rescaled by a factor @xmath61 to its initial size @xmath45 , by uniformly pruning / replicating the agents .",
    "[ itm : rescaling ]    at each time step @xmath55 , the rescaling factor is given by @xmath62 so that @xmath63 and finally @xmath64",
    "for a continuous time dynamics defined by rates @xmath65 the master equation reads @xmath66 where @xmath67 is the escape rate from configuration @xmath43 .",
    "there are many different ways of deriving the algorithm presented in the previous section and we shall follow here a derivation of the continuous time algorithm slightly different from the one we introduced in  @xcite .",
    "the formal solution of reads @xmath68 where @xmath69 $ ] represents the probability distribution of the time intervals between jumps .",
    "the sum over @xmath70 corresponds to all the possible numbers of jumps between 0 and @xmath2 , the sum over the @xmath71 s to the different configurations which can be visited .",
    "the integrals over @xmath72 account for all the possible times at which jumps occur .",
    "last , the ratio @xmath73 gives the _ probability _ that the system goes to configuration @xmath71 , when it quits configuration @xmath74 .",
    "multiplying the second line of by @xmath18 yields an explicit formula for @xmath75 : @xmath76 further introducing the biased rates @xmath77 , the corresponding escape rates @xmath78 and time distributions between two jumps @xmath79 , can be rewritten ( after some algebra ) as @xmath80 where @xmath81 .",
    "@xmath75 is thus a weighted sum over all possible trajectories generated by the biased rates @xmath82 , where the weights are given by the factors @xmath83 .",
    "a first idea which can come to mind is to simply evolve the population with the rates @xmath82 , without cloning and to simply average @xmath84 over these trajectories , as was proposed in  @xcite .",
    "this however fails as soon as @xmath2 is large , for the same reason as the one described in the introduction : the weight is exponentially large in @xmath2 and large fluctuations of the exponent are exponentially rare .",
    "one thus has to use a biased sampling to compute the average .",
    "following the philosophy of the `` go with the winner methods ''",
    "@xcite , the general idea is to stochastically replace a trajectory with weight @xmath85 by ` @xmath86 ' trajectories with weight @xmath21 , so that trajectories which high rates are favoured whereas those with small weights are not investigated .",
    "if the re - weighting procedure is made systematic , every time an agent @xmath87 changes of configuration at time @xmath88 , one gets the following algorithm :    1 .   the time is set to @xmath88 .",
    "@xmath87 jumps from its configuration @xmath43 to another configuration @xmath29 with probability @xmath89 .",
    "the time interval @xmath90 until the next jump of @xmath87 is chosen from the poisson law @xmath79 of parameter @xmath91 .",
    "the agent @xmath87 is either cloned or pruned with a rate @xmath92 * one computes @xmath93 where @xmath94 is uniformly distributed on @xmath95 $ ] . * if @xmath53 , the copy @xmath87 is erased . *",
    "if @xmath96 , we make @xmath52 new copies of @xmath87 .",
    "if @xmath53 , one agent @xmath97 is chosen at random and copied , while if @xmath96 , @xmath52 agents are chosen uniformly among the @xmath98 agents and erased .",
    "we store the rescaling factor @xmath99 .",
    "to reconstruct the dynamical free energy , we keep track of all @xmath100 factors @xmath101 once again the step ( 4 ) ensures constant population .",
    "the methods presented above only apply for dynamical observables , which can be decomposed as sums of individual contributions over each configuration change .",
    "one could also be interested in averages of static observables along the histories @xmath102 . in this case",
    ", the above procedure simplifies and the algorithm is identical apart from two points .    * first , there is no bias in the rate .",
    "the agents are evolved with the unmodified markov rates @xmath65 . *",
    "second , the cloning rate is simply given by @xmath103 .",
    "this can best be seen in formula by replacing the weight @xmath104 which depends on the configurations before and after the jump by @xmath103 which depends solely on the configuration @xmath71 and can thus be seen as a constant cloning rate for the whole time the system spends in the configuration @xmath71 .",
    "as pointed out in  @xcite , the configurations probed along the simulation are representative of the typical ones at _ final time _",
    "@xmath2 in the evolution , rather than at intermediate times ( @xmath105 ) .",
    "in particular , the weighted average value @xmath106 of a static observable @xmath107 at final time @xmath2 is obtained in the algorithm by computing the average of @xmath108 among the agents at the end of the simulation .",
    "in general , the value of @xmath109 at intermediate times @xmath105 differs from the one at final time , yet @xmath109 is of particular interest since it is representative of configurations visited during most of the weighted evolution ( see  @xcite for examples ) . a way to compute @xmath109",
    "numerically can be read in its formal expression : @xmath110 one simply runs the same algorithm as before , which generates the bias on trajectories , except that whenever an agent arrives at a time @xmath72 such that @xmath111 , the corresponding value @xmath112 is attached to the agent . then , each time an agent is cloned , the corresponding value of @xmath108 is copied accordingly . at the end of the simulation , @xmath109 is obtained from the average of the values of @xmath113 attached to the surviving clones . of course , thanks to the cloning process between @xmath114 and @xmath2 , this average differs from the one we could have done at the intermediate time @xmath114 in the simulation .",
    "the same kind of scheme also applies to compute the weighted average of any observable @xmath108 depending on the whole history of the system and the crucial step is to copy the value of the observable when cloning events occur .",
    "note in particular that the determination of @xmath115 can be quite noisy since only a few instances of @xmath113 have survived at time @xmath2 . in the long time",
    "limit one may gain similar information by studying @xmath116 @xcite which is a less noisy dynamical observable .",
    "these numerical methods have been applied successfully in many different situations but it is important to keep in mind their limitations .",
    "first , as pointed out in  @xcite convergence problems are met when the evolution operator is gapless .",
    "this can for instance happen in systems where the configuration space is unbounded , as in the zero range process but will however not be a problem as long as the configuration space remains finite .",
    "( in log scale ) for the total current of particles in the ssep at density @xmath117 ( @xmath118 sites ) .",
    "the points ( + ) are the result of the continuous - time numerical algorithm .",
    "the line is the analytic result   valid for very large deviations @xmath119 . ]",
    "the other important limitation is the finiteness of the population of agents , which can be problematic for very large deviations yielding large cloning rates .",
    "for all applications considered in  @xcite , we thus ensured that the cloning factor would never grow larger than few percent of the total population size and agreement with theory - when at hand - was very good .",
    "as an example , one can compare ( figure  [ fig : sepbigbeta ] ) for the simple symmetric exclusion process ( ssep ) the numerical result in the regime of very large deviations with the analytical result  @xcite @xmath120 valid for @xmath119 , for the total current of particles in the system .",
    "agreement is very good although the values of @xmath20 correspond to very large deviations . for large cloning rates",
    ", it may also be necessary to modify step ( 4 ) of the continuous time algorithm so that agents are not pruned uniformly but according to the weight they carry since their last change of configuration @xmath121}$ ] but in our simulations we never ran into this problem . in this worst case scenario ,",
    "the efficiency of the continuous time implementation would fall back to that of the discrete time where at every step the whole population is re - sampled .",
    "we thank r.j .",
    "harris , a. rkos and h. touchette for many useful discussions and p. hurtado for suggesting this review .",
    "jt acknowledges funding from epsrc grants ep/030173 .",
    "vl was supported by the swiss fns , under manep and division ii ."
  ],
  "abstract_text": [
    "<S> in these notes we present a pedagogical account of the population dynamics methods recently introduced to simulate large deviation functions of dynamical observables in and out of equilibrium . after a brief introduction on large deviation functions and their simulations , we review the method of giardin _ et al . _ for discrete time processes and that of lecomte _ et al . </S>",
    "<S> _ for the continuous time counterpart . </S>",
    "<S> last we explain how these methods can be modified to handle static observables and extract information about intermediate times .     </S>",
    "<S> address = supa , school of physics and astronomy , university of edinburgh , mayfield road , edinburgh eh9 3jz , scotland     address = dpmc , universit de genve , 24 , quai ernest ansermet 1211 genve , switzerland    the main achievement of equilibrium statistical mechanics is probably the simplification it offers in the study of static observables in steady state . </S>",
    "<S> indeed , the resolution of dynamical equations is replaced by static averages and ensemble approaches </S>",
    "<S> . this can still be very difficult , but from a conceptual point of view , the problem is much simpler . on the other hand , </S>",
    "<S> when one is interested in dynamical observables , like currents of particles , or in out - of - equilibrium situations , like for glassy or driven systems , such static ensemble approaches are not available anymore and there is no general formalism on which one can rely .    for the last ten years , physicists have been interested in large deviation functions mainly because they are good candidates to extend the concept of thermodynamic potentials to out - of - equilibrium situations and to dynamical observables ( for a review , see  @xcite ) . </S>",
    "<S> of course the mere definition of out - of - equilibrium potentials is not useful in itself and the challenge is thus to go beyond their construction . </S>",
    "<S> to do so , two strategies can be followed . </S>",
    "<S> first , one can try to derive general properties of large deviation functions . </S>",
    "<S> an example of success in this direction is provided by the fluctuation theorem  @xcite , which can be read as a symmetry of large deviation functions and is one of the few general results valid out - of - equilibrium . </S>",
    "<S> another strategy is to consider specific examples and to compute the large deviation function explicitly . </S>",
    "<S> for some simple yet non - trivial interacting particle systems , exact computations have been possible ( for a review see  @xcite ) , but one has to rely on numerics for more generic systems . from the algorithmic point of view , two paths can be followed . for small system sizes , </S>",
    "<S> exact procedures can be used ( see for instance  @xcite ) but as soon as mesoscopic systems are considered , one has to rely on importance sampling approaches . generalising a procedure followed previously to study rare events in chemical reactions  @xcite , kurchan and co - workers developed methods to compute large deviation functions in dynamical systems  @xcite , and discrete  @xcite or continuous  @xcite time markov chains . </S>",
    "<S> we shall concentrate here on the statistical mechanical aspects and review the methods available for markov chains .    </S>",
    "<S> let us consider a system and call @xmath0 its set of configurations . </S>",
    "<S> as time goes from @xmath1 to a final time @xmath2 , the system typically jumps into successive configurations @xmath3 at distinct times @xmath4 . </S>",
    "<S> a _ dynamical _ </S>",
    "<S> observable @xmath5 is defined as a sum along the history of small contributions @xmath6 , one for each _ transition _ between two successive configurations . </S>",
    "<S> the simplest example of such observable is probably a current of particles @xmath5 in a one - dimensional lattice gas , which is either incremented of decremented every time a particle jumps to the right or to the left , respectively . </S>",
    "<S> this contrasts with static observables , like the number of particles at a given site , which depend solely on the configuration of the system at a given time . </S>",
    "<S> we will see below that the algorithms used to obtain the large deviation functions slightly differ in these two cases . to characterise the fluctuations of the observable @xmath5 , the first thing one can do is to extend the microcanonical approach to the space of trajectories and compute the corresponding macrostate entropy @xmath7.\\ ] ] however one knows from usual statistical mechanics that working in the microcanonical ensemble is often harder than in the canonical one and we rather introduce a dynamical partition function and the corresponding dynamical free energy @xmath8 these definitions differ slightly from those used in the mathematical literature , where one rather speaks about rate functions @xmath9 and cumulants generating functions @xmath10 .    </S>",
    "<S> the main purpose of this short review is to explain how one can compute @xmath11 using an approach relying on population dynamics . but </S>",
    "<S> let us first sketch why direct sampling would be inefficient . </S>",
    "<S> consider for simplicity the case where @xmath12 has a single maximum at @xmath13 , which satisfies @xmath14 ( for normalisation purpose ) . </S>",
    "<S> fluctuations around @xmath15 which occur with probabilities of order one must typically be of order @xmath16 so that @xmath17 whence a probability of larger fluctuations exponentially small in @xmath2 . </S>",
    "<S> on the other hand , the dynamical partition function has a weight @xmath18 ( with @xmath19 ) exponential in @xmath2 . as a result </S>",
    "<S> , there is a competition between the exponentially rare fluctuations and their exponential weight such that for @xmath20 of order @xmath21 the trajectories which dominate the average in ( [ eqn : partfunc ] ) are exponentially rare . a more quantitative way to rephrase this </S>",
    "<S> can be read in the legendre relation between @xmath12 and @xmath11 : @xmath22.$ ] the maximum is realised for a value @xmath23 which dominates the average in . </S>",
    "<S> it thus differs from @xmath13  which maximises only @xmath12  by a factor independent of @xmath2 . from </S>",
    "<S> we see that the corresponding trajectories indeed have a probability exponentially small in @xmath2 . to have a good sampling over @xmath24 unbiased simulations , @xmath24 </S>",
    "<S> should thus be of order @xmath25 , an impracticable requirement . </S>",
    "<S> direct sampling is thus a hopeless strategy to observe large deviations . </S>"
  ]
}