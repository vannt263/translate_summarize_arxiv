{
  "article_text": [
    "we present a thermostatistical theory based on the notion of kolmogorov - nagumo ( kn ) mean @xcite .",
    "it deals with the problem of maximizing average information content under the constraint that the ( nonlinear ) average of some energy function has a given value .    from the point of view of information theory and the principle of maximal entropy @xcite",
    "there are at least two ways to generalize the boltzmann - gibbs formalism of statistical mechanics .",
    "one can modify the definition of entropy / information , or one can modify the definition of average energy .",
    "we will make use of both possibilities .",
    "many definitions of entropy can be found in literature @xcite .",
    "in contrast , kn - averages , although known in statistics since many years , appear not to be used in the context of physics .",
    "therefore , we will discuss in detail how they fit with basic principles of statistical mechanics .",
    "originally , our plan was to generalize the boltzmann - gibbs formalism by replacing shannon s entropy by rnyi s @xmath0-entropies , and by simultaneously replacing the usual linear statistical average by an appropriate kn - average .",
    "the resulting formalism is what we call rnyi thermostatistics in the sequel .",
    "however , the formalism allows further generalization which consists of replacing rnyi entropies by equivalent entropies , each time choosing appropriate kn - averages . by equivalent entropies",
    "we mean monotonically increasing continuous functions of rnyi entropies . indeed , replacing an entropy by an equivalent one does not change the maximum entropy problem .",
    "one such entropy which is equivalent with rnyi s , and which is quoted often in literature , is tsallis entropy @xcite , studied earlier by harvda and charvat @xcite and by darczy @xcite .",
    "the thermostatistics which we propose is not equivalent with the non - extensive thermostatistics proposed by the tsallis school because of the non - linear averages used in the present paper .",
    "rnyi thermostatistics is extensive , as we will show",
    ". the more general formalism can be non - extensive , and , in fact , comprises tsallis thermostatistics as a special case .",
    "note that throughout the paper units are used in which boltzmann s constant @xmath1 equals one .",
    "the paper is organized as follows . in section 2",
    "the general formalism is explained . the standard boltzmann - gibbs formalism and some other formalisms",
    "are shown to be special cases . in section 3",
    "equilibrium distributions are discussed .",
    "special attention is paid to the definition of thermodynamic temperature .",
    "section 4 shows how nonlinear averages fit with the fundaments of statistical mechanics .",
    "the curie - weiss model is treated as an example .",
    "section 5 deals with rnyi thermostatistics and its obvious non - extensive generalization .",
    "the curie - weiss model serves again as an example , together with the two - level system .",
    "the last section contains a short discussion of our results . throughout the paper we use deformed exponential and logarithmic functions with a definition which is broader than that found in literature .",
    "details about these are found in appendix .",
    "for simplicity we restrict ourselves initially to functions @xmath2 with integer @xmath3 .",
    "we use the index notation @xmath4 .",
    "the kolmogorov - nagumo ( kn ) average @xcite depends on a monotonically increasing function @xmath5 and on parameters @xmath6 .",
    "essential for the present approach is that the latter are probabilities satisfying @xmath7 and @xmath8 .",
    "the definition is @xmath9 we will not make use of the possibility that @xmath10 may be decreasing instead of increasing .    fix an additional monotonically increasing function @xmath11 .",
    "it is used to define information content @xmath12 by @xmath13 because @xmath14 is increasing , less probable events ( i.e.  smaller @xmath6 ) carry more information .",
    "the average information content is now given by @xmath15    generalized thermostatistics studies the problem of maximizing average information content under the condition that average values of functions @xmath16 have predetermined values @xmath17 @xmath18    throughout the paper we consider the optimization problem with exactly one constraint , i.e. , we fix some real function @xmath19 and optimize information content under the condition that @xmath20 has a predetermined value @xmath21 .",
    "it is tradition to call @xmath22 the energy functional and to call @xmath23 the internal energy .",
    "note that we introduce here a constant @xmath24 with dimension of inverse energy .",
    "its first purpose is to make quantities dimensionless .",
    "its actual role in the theory will be clarified later on .",
    "the maximum attained by @xmath25 is denoted @xmath26 and is called thermodynamic entropy ( not to be confused with the entropy functionals introduced below ) .",
    "the variation is with respect to the choice of probabilities @xmath6 . in principle",
    ", it might be interesting to vary also the choice of functions @xmath5 resp .",
    "this extension is not considered in the present paper .",
    "it is tradition @xcite to solve this kind of optimization problem by introduction of two lagrange parameters @xmath27 and @xmath28 , one to ensure normalization of the probabilities @xmath6 , the other to enforce the energy constraint .",
    "since @xmath10 is a monotonically increasing function an equivalent optimization problem is to minimize a free energy of the form @xmath29 the set of conditions for an extremum reads @xmath30 using ( [ kn ] ) and ( [ avinfcont ] ) this simplifies to @xmath31 = \\frac{\\beta}{\\beta_0}\\left(\\phi(\\beta_0e_k)-\\gamma\\right ) .",
    "\\label{varprin}\\ ] ] this equation has to be solved to obtain @xmath6 as a function of @xmath27 and @xmath28 .",
    "it is not easy to progress with a problem of this generality .",
    "let us therefore consider first some important examples .",
    "consider first the rather trivial case that the energy function @xmath22 is constant and that the index @xmath32 takes on a finite number @xmath33 of values .",
    "then entropy is optimal with @xmath34 this implies immediately the result @xmath35 with @xmath11 replaced by @xmath36 this is the famous result obtained by boltzmann in the nineteenth century .",
    "let @xmath37 and @xmath38 . with this choice of @xmath14",
    "the information measure is @xmath39 it represents hartley s notion of information @xcite .",
    "the expression for average information content becomes @xmath40 this expression is called shannon s entropy functional @xcite .",
    "( [ varprin ] ) becomes @xmath41 this implies @xmath42 with normalisation factor @xmath43 given by @xmath44 this is the boltzmann - gibbs distribution .",
    "for simplicity , only the base @xmath45 will be used in the sequel .",
    "the notations @xmath46 and @xmath47 will be used from now on with the different meaning of @xmath0-deformed logarithm resp .",
    "exponential .",
    "fix some @xmath48 , @xmath49 , and let @xmath37 and @xmath50 where @xmath51 we use here the @xmath0-deformed logarithm ( @xcite , see also the appendix ) . in the limit @xmath52 it reduces to the natural logarithm .",
    "its inverse is the deformed exponential @xmath53_+^{1/(1-\\alpha ) } , \\qquad x\\ge 0.\\ ] ] throughout the text @xmath54_+$ ] equals the maximum of @xmath55 and 0 .",
    "note that the present example is an obvious generalization of the previous one .",
    "the average information content is @xmath56 this is tsallis entropy @xcite .",
    "( [ varprin ] ) becomes @xmath57 it can be written as @xmath58^{1/(\\alpha-1)}.\\ ] ] which means that @xmath6 is inversely proportional to @xmath59 .",
    "this solution , with some modification , will be discussed in more detail further on .",
    "it is well - known @xcite that averaging information @xmath60 , as given by ( [ hartley ] ) , leads to rnyi s entropy of order @xmath0 , if the function @xmath10 is chosen of the form @xmath61 , ( @xmath49 ) .",
    "let us make an innocent modification to this function and let @xmath62 with @xmath63 note that the kn - mean is invariant under this kind of modification .",
    "one obtains ( assuming @xmath64 as in the shannon case ) @xmath65 the latter is the usual expression for rnyi s entropy of order @xmath0 .",
    "it is now straightforward to solve ( [ varprin ] ) for the present choice of @xmath10 and @xmath14 .",
    "however , note that in course of calculation ( [ renyi ] ) the expression for tsallis entropy ( [ tsallisentropy ] ) appears .",
    "this shows that in the context of kn - means , there is an intrinsic relation between the entropies of rnyi and of tsallis ( this relation seems to be known since quite some time  see @xcite ) . instead of maximizing rnyi s entropy under the constraint that @xmath66 one can as well maximize tsallis entropy @xmath67 under the constraint that @xmath68 . in other words ,",
    "the present example is reduced to the previous one .",
    "note that there exist other pairs @xmath69 which are linked to tsallis entropy in a way similar to the previous example .",
    "this is the case whenever @xmath70 for some @xmath49 .",
    "one can see ( [ assume ] ) as a definition of @xmath14 in case @xmath10 is given , or as a constraint on @xmath10 if @xmath14 is given .",
    "condition ( [ assume ] ) implies that @xmath10 maps average information content @xmath25 onto tsallis entropy .",
    "hence all entropies in this class are equivalent in the sense that they are increasing functions of tsallis @xmath0-entropy or , if you wish , of rnyi s @xmath0-entropy .",
    "note that the result of the optimization problem does not change if the entropy is replaced by a monotonic function of the entropy .",
    "hence all what happens is that for a given ( nonlinear ) constraint we adapt the @xmath0-entropy to an equivalent entropy which is technically better adapted for solving the optimization problem .",
    "in this section @xmath0 is fixed and @xmath10 and @xmath14 are related by ( [ assume ] ) .",
    "the original optimization problem is reformulated as maximizing tsallis entropy @xmath71 under the constraint @xmath72      the formulas that follow are based on results already found in literature in many places , e.g.  in @xcite .",
    "the equilibrium average is the kn - mean ( [ kn ] ) with @xmath6 given by @xmath73_+^{1/(\\alpha-1 ) } = \\frac{1}{z_1}\\,\\exp_\\alpha(-a(x_k - u ) ) \\label{alphaless}\\ ] ] with @xmath74 and @xmath75 for all @xmath32 , with normalization @xmath76 given by @xmath77_+^{1/(\\alpha-1 ) } \\label { z1def}\\ ] ] and with @xmath78 . the unknown parameters @xmath79 and @xmath80 have to be fixed in such a way that ( [ constraint ] ) holds . this condition can be written as @xmath81 with @xmath82 given by @xmath83_+^{\\alpha/(\\alpha-1)}. \\label{z0less}\\ ] ]",
    "there is only one condition to determine the two parameters @xmath79 and @xmath80 .",
    "a convenient way to fix @xmath80 is to take it equal to the lower bound of the @xmath84 ( we assume that @xmath84 is bounded from below ) . in that case one",
    "can guarantee @xcite that the solution of the optimization problem , if it exists , occurs for @xmath85 .",
    "the entropy @xmath86 follows from ( [ tsallisentropy ] ) using ( [ alphaless ] ) .",
    "one obtains @xmath87    expression ( [ alphaless ] ) with @xmath88 is related to the kappa - distribution or generalized lorentzian distribution @xcite @xmath89^{1+\\kappa}}.\\ ] ] it is frequently used , e.g.  in plasma physics to describe an excess of highly energetic particles @xcite .",
    "typical for distribution ( [ alphaless ] ) with @xmath90 is that the probabilities @xmath6 are identically zero whenever @xmath91 .",
    "this cut - off for high values of @xmath22 is of interest in many areas of physics . in astrophysics",
    "it has been used @xcite to describe stellar systems with finite average mass .",
    "a statistical description of an electron captured in a coulomb potential requires the cut - off to mask scattering states @xcite . in standard statistical mechanics",
    "the treatment of vanishing probabilities requires infinite energies which lead to ambiguities .",
    "these can be avoided if distributions of the type ( [ alphaless ] ) , with @xmath90 , are used .      for further use",
    "we calculate now the derivative of @xmath92 w.r.t  @xmath23 .",
    "since the equilibrium state depends only on the fee parameter @xmath79 ( @xmath80 may be kept constant ) we start with calculating the dependence of @xmath92 on @xmath79 .    equations ( [ uless ] ) and ( [ sless ] ) can be written as @xmath93 hence , ( [ sless ] ) can be written as @xmath94^\\alpha z_0^{1-\\alpha}-1 \\right)\\ ] ] on the other hand , ( [ z0less ] ) implies @xmath95 combining these two expressions one obtains @xmath96 the final result is then @xmath97 note that @xmath79 in this expression is still a function of @xmath23 .",
    "the standard thermodynamical relation for temperature @xmath98 is @xmath99 in generalized thermostatistics this definition of temperature is not necessarily correct @xcite .",
    "the problem is that the thermodynamic definition of temperature ( [ standtemp ] ) is not invariant under substitution of entropy by an equivalent entropy .",
    "this means that one can generalize definition ( [ standtemp ] ) to @xmath100 where @xmath101 is any strictly increasing function of @xmath55 i.e.  the derivative @xmath102 is positive",
    ". however , not all choices of @xmath101 are physically acceptable .",
    "minimal requirements are that @xmath98 is an increasing function of @xmath23 , and that @xmath103 corresponds with @xmath104 , where @xmath105 .",
    "the formalism of tsallis thermostatistics@xcite has been modified a few times @xcite .",
    "in particular , the correct definition of temperature has been a difficult point @xcite .",
    "one can easily verify that the proposed definitions of thermodynamic temperature are of the form ( [ gendeftemp ] ) . as argued in @xcite , ( [ standtemp ] ) is correct in case the entropy is extensive . only rnyi s @xmath0-entropies are extensive  see the next section .",
    "hence we propose that @xmath101 should be fixed in such a way that @xmath106 is rnyi s entropy .",
    "this is the case if @xmath107 indeed , one has @xmath108 note that , taking @xmath37 in ( [ fdef ] ) , one obtains @xmath109 this coincides with the formula proposed in @xcite .      combine ( [ thermorel],[gendeftemp ] ) with the above choice of function @xmath101 , one obtains @xmath110 make now the following choice of the parameter @xmath80 @xmath111 then ( [ gentempexpr ] ) can be written as @xmath112 this is our general result for the relation between the parameter @xmath79 and thermodynamic temperature @xmath98 . from this expression",
    "it is immediately clear that , in case @xmath88 , temperature @xmath98 is always positive .",
    "the analysis of what happens if @xmath90 is more complex and falls out of the scope of the present paper .",
    "in addition , if @xmath79 tends to infinity , then @xmath23 will become equal to @xmath113 . in this limit ( [ gentempexpr2 ] )",
    "implies that temperature @xmath98 goes to zero , as is physically expected .",
    "an open questions is wether @xmath98 is always an increasing function of @xmath23 , as it should be .",
    "this analysis is not made in the present paper .",
    "next , use ( [ gentempexpr ] ) to eliminate @xmath79 from expression ( [ alphaless ] ) for the probabilities @xmath6 .",
    "one obtains @xmath114_+^{1/(\\alpha-1 ) } \\label{ftdistr}\\end{aligned}\\ ] ] with @xmath115 the appropriate normalization constant .",
    "the limit @xmath52 of this expression is @xmath116 .",
    "\\label{phidistr}\\ ] ] if @xmath37 then this is the boltzmann - gibbs distribution .",
    "consider the case that @xmath117 then ( [ alphaless ] ) simplifies to @xmath118 with @xmath119 the appropriate normalization factor .",
    "formula ( [ gentempexpr2 ] ) becomes @xmath120 in case of rnyi thermostatistics is @xmath62 as given by ( [ phirenyi ] ) .",
    "then the r.h.s .  of the above expression",
    "is identically equal to @xmath0 so that one obtains the condition @xmath121 .",
    "this shows that in this case the special temperature for which ( [ genbgdist ] ) holds is @xmath122 .",
    "one concludes that , because of the nonlinear averages , the value of @xmath24 can not be chosen arbitrarily .",
    "in the present section we try to clarify the role nonlinear averages can play in statistical mehanics .",
    "a fundament of equilibrium statistical mechanics is the equivalence of ensembles , known as the equipartition theorem @xcite in information theory .",
    "a related @xcite property is the asymptotic expression @xmath123 where @xmath124 is an appropriate rate function . with @xmath125 we mean here that @xmath126 with @xmath127 we mean that @xmath55 should ly in a small open neighborhood of @xmath128 , of size independent of @xmath129 .",
    "this result from the theory of large deviations @xcite states that the probability that energy @xmath130 deviates from its average value @xmath23 is exponentially small in the size of the system @xmath129 .",
    "physically , minus the rate function @xmath124 has the meaning of a relative entropy density in the microcanonical ensemble with energy @xmath131 .",
    "the rate function @xmath124 is expected to be minimal for @xmath132 because the equilibrium state maximizes entropy under the constraint that average energy equals @xmath23 .    in case of identically distributed independent stochastic variables @xmath133 ,",
    "@xmath134 , @xmath135 with average value @xmath136 , the central limit theorem implies that @xmath137 where @xmath138 is the variance of the distribution .",
    "comparison with ( [ largedev ] ) shows that in this case @xmath139 . in general , ( [ largedev ] )",
    "will hold with different rate functions .",
    "e.g. , in the high temperature phase of the curie - weiss model , is @xmath140 and @xmath141 \\right ) , \\label{cwht}\\end{aligned}\\ ] ] ( @xmath142 ) , with @xmath98 the temperature , with @xmath143 the interaction constant of the model , and with @xmath144 ( @xmath145 , see section ( [ sect_cw ] ) below ) .",
    "let us now make the link with nonlinear averages .",
    "fix a strictly increasing function @xmath5 .",
    "then ( [ largedev ] ) is equivalent with @xmath146 for thermostatistics it is important that the rate function @xmath124 is convex , at least in a neighborhood of @xmath132 . but clearly , that @xmath124 is convex does not imply that @xmath147 is convex .",
    "conversely , if @xmath124 is not convex , as is e.g.  the case in the curie - weiss model at low temperatures , then one might search for a function @xmath5 such that @xmath147 is convex .",
    "this is a possible motivation for introducing kn - averages .",
    "the strictly increasing function @xmath5 changes the scale used to observe energy fluctuations .",
    "the choice of function should be such that the resulting rate function is convex .",
    "for example , if we take @xmath148 and apply rescaling to ( [ cwht ] ) we obtain @xmath149 \\label{cwht2}\\ ] ] note that in the curie - weiss model the square root of energy is proportional to total magnetization @xmath150 .",
    "in fact , it is tradition to study large deviations of the curie - weiss model in terms of @xmath150 instead of @xmath130 , in the context of a grand canonical ensemble instead of the canonical ensemble studied here .",
    "the link with kolmogorov - nagumo ( kn ) averages ( see definition ( [ kn ] ) ) is immediate , be it on an intuitive basis . we introduce probabilities @xmath6 of a canonical ensemble based on ( [ largedev2 ] ) , i.e.  after rescaling energy fluctuations with the function @xmath10 , because then we can expect equivalence of ensembles to be valid .",
    "the actual need for nonlinear averages , as given by ( [ kn ] ) , will be discussed in section [ wna_sect ] .      for a mathematical treatment of the curie - weiss model in the context of the boltzmann - gibbs formalism ,",
    "see @xcite .",
    "the energy of the model is given by @xmath151 the spin variables @xmath152 take on the values @xmath153 .",
    "the constant @xmath154 is strictly positive . for simplicity ,",
    "assume @xmath155 .",
    "fix @xmath156 .",
    "introduce an increasing function @xmath5 by @xmath157 because @xmath158 is singular at @xmath159 when @xmath160 we have to be carefull with the denominator @xmath161 appearing in ( [ phidistr ] ) .",
    "let @xmath162 and @xmath163 and assume @xmath164 .",
    "there follows @xmath165\\cr & = & \\frac{1}{\\zeta_1'}\\exp\\left [ n\\frac{v^{1-\\gamma}}{\\gamma t } \\phi(jm^2/2+hm ) \\right]\\end{aligned}\\ ] ] hence the probability of a given magnetization @xmath150 is @xmath166\\cr & \\sim & \\exp(-nr(m ) ) \\label{apppm}\\end{aligned}\\ ] ] with @xmath167 ( see ( [ infrate ] ) for the definition of @xmath168 ) . to obtain this asymptotic expression ,",
    "stirling s formula has been used . note that ( [ cwg ] ) is _",
    "not _ in agreement with ( [ cwht],[cwht2 ] )",
    "! the result obtained here is ( @xmath169 ) @xmath170 \\label{cwht3}\\ ] ] the temperature @xmath98 in this expression is defined by the thermodynamic relation ( [ standtemp ] ) , while in ( [ cwht],[cwht2 ] ) it is a lagrange multiplier .",
    "since @xmath171 throughout the high - temperature phase the second contribution to the rate function in ( [ cwht3 ] ) vanishes in the limit of large @xmath129 .",
    "assume @xmath172 is minimal at @xmath173 .",
    "the condition @xmath174 reads @xmath175 because @xmath176 holds , this simplifies to @xmath177 this is the standard mean - field equation . it does not depend on the choice of @xmath27 .",
    ". expansion of the exponent in ( [ apppm ] ) around @xmath179 , assuming @xmath180 , gives @xmath181\\end{aligned}\\ ] ] with @xmath182 hence fluctuations do depend on the choice of @xmath27 .",
    "let us now consider the case @xmath183 and @xmath184 in more detail . then @xmath185 is a solution of the mean - field equation at all temperatures .",
    "the corresponding value of @xmath186 is of the order @xmath187 and can be neglected . hence expression ( [ cwg ] )",
    "reduces to the result of the ideal paramagnet .",
    "one concludes that , contrary to what happens in the @xmath188-case , this solution is ( meta)stable at all temperatures ( a solution of the mean - field equation is said to be stable if it optimizes entropy for the given average energy , it is metastable if it is not stable but the rate function is convex in a neighborhood of the origin ) .",
    "rnyi s entropy corresponds with the choice @xmath62 ( given by ( [ phirenyi ] ) ) and @xmath60 given by ( [ hartley ] ) , i.e.  @xmath189 and @xmath64 . in the present section we study an obvious generalization of this entropy .",
    "it contains both rnyi and tsallis thermostatistics as subcases .",
    "introduce the function @xmath190 given by @xmath191_+^{\\theta(\\alpha,\\rho)}-1 \\right ) \\label{alfarodef}\\end{aligned}\\ ] ] here , and in what follows , we use @xmath192 as an abbreviation for @xmath193 . equation ( [ alfarodef ] ) is the obvious generalization of ( [ phirenyi ] ) obtained by deforming the exponential occurring in it .",
    "we use extended definitions of @xmath194 and @xmath195 , introduced in appendix .",
    "the inverse function of @xmath196 is @xmath197 .",
    "the entropy function is chosen in such a way that ( [ assume ] ) holds .",
    "now , @xmath198 implies @xmath199 .",
    "the average information content then equals @xmath200 \\equiv s_{\\alpha\\rho}(p ) \\label{twoparam}\\end{aligned}\\ ] ] the two interesting limiting cases are @xmath201 and @xmath202 . if @xmath201 the expression reduces to that of rnyi s entropies ( [ renyi ] ) .",
    "if @xmath202 it reduces to the tsallis expression ( [ tsallisentropy ] ) . note that all entropies with the same @xmath0-value belong to the same equivalence class .",
    "the constraint @xmath203 can be written as @xmath204 it depends of course on the choice of both @xmath0 and @xmath205 .",
    "rnyi proved @xcite that the only additive measures of information content are shannon s entropy ( [ shannonentr ] ) and the family of rnyi @xmath0-entropies ( [ renyi ] ) .",
    "additivity means here that when a system is composed of two independent subsystems a and b then the entropy of the total system is the sum of the entropies of the subsystems .",
    "let us consider additivity in more detail .",
    "a system consisting of two independent subsystems is described by probabilities @xmath206 of the product form @xmath207 a short calculation gives @xmath208\\cr & = & \\frac{1}{1-\\rho}\\left [ \\left(\\sum_{j}(p_{j}^{(1)})^\\alpha\\right)^{\\theta(\\alpha,\\rho ) } \\left(\\sum_{k}(p_{k}^{(2)})^\\alpha\\right)^{\\theta(\\alpha,\\rho ) } -1 \\right]\\cr & = & \\langle i\\rangle^{(1)}+\\langle i\\rangle^{(2 ) } + ( 1-\\rho)\\langle i\\rangle^{(1 ) } \\langle i\\rangle^{(2)}\\end{aligned}\\ ] ] if @xmath201 this implies additivity of rnyi s entropy functional . if @xmath202 this result is well - known @xcite in the literature about tsallis thermostatistics .",
    "next assume that the relation between the energy functional of the composed system and those of the subsystems is @xmath209 for @xmath201 this simply means that @xmath210",
    ". for arbitrary @xmath205 ( [ energprod ] ) implies that @xmath211 so that @xmath212^{1-\\alpha}-1 \\right)\\cr & = & \\frac{1}{1-\\alpha}\\bigg [ \\sum_jp_j^{(1)}\\exp_\\rho(\\beta_0e_j^{(1)})^{1-\\alpha } \\sum_kp_k^{(2)}\\exp_\\rho(\\beta_0e_k^{(2)})^{1-\\alpha } -1 \\bigg]\\cr & = & \\frac{1}{1-\\alpha}\\bigg [ \\sum_jp_j^{(1)}(1+(1-\\alpha)\\phi_{\\alpha\\rho}(\\beta_0e_j^{(1)})\\cr & & \\times \\sum_kp_k^{(2)}(1+(1-\\alpha)\\phi_{\\alpha\\rho}(\\beta_0e_k^{(2 ) } ) -1\\bigg]\\cr & = & x^{(1)}+x^{(2)}+(1-\\alpha)x^{(1)}x^{(2)}\\end{aligned}\\ ] ] with @xmath213 on the other hand is @xmath214 combination of the two expressions gives the result @xmath215 for @xmath201 this proves the additivity for energies as expected .",
    "when @xmath216 this is a nontrivial result , even if @xmath202 , in which case the average is linear .    in general , equilibrium probabilities of generalized thermostatistics",
    "are not of the product form . therefore , thermodynamic entropy @xmath92 , which is the maximum value attained by @xmath25 is not necessarily equal to the sum of thermodynamic entropies of the subsystems",
    "of course , the product form is also absent in the standard formalism of thermostatistics when there are correlations between subsystems .",
    "if correlations are not too strong then the system in equilibrium is still extensive , by which is meant that thermodynamic entropy @xmath92 and internal energy @xmath23 grow linearly with the size of the system .",
    "this is usually expressed by stating that the so - called thermodynamic limit exists .",
    "we expect that also in the present case ( i.e.  with @xmath217 given by ( [ phirenyi ] ) and @xmath60 given by ( [ hartley ] ) ) thermodynamic limit exists under suitable conditions .",
    "this point has still to be studied .",
    "as an example , consider a system with two energy levels @xmath218 and @xmath219 .",
    "assume @xmath220 and @xmath221 .",
    ". then one has @xmath223_+^{\\theta(\\alpha,\\rho)}-1 \\right ) \\label{2levx}\\end{aligned}\\ ] ] from ( [ alphaless ] ) follows @xmath224 and @xmath225_+^{-1/(1-\\alpha ) } \\label{2levp}\\ ] ] note for further use that @xmath226 from @xmath227 follows @xmath228_+^{\\theta(\\alpha,\\rho)}-1\\right ) .",
    "\\label{exless}\\end{aligned}\\ ] ] this is the solution of the optimization problem maximizing information content given the constraint that @xmath229 .",
    "entropy can be calculated using ( [ exz0z1 ] ) .",
    "one obtains @xmath230 so that @xmath231    the optimum as a function of temperature is calculated now . from definition ( [ gendeftemp ] ) of thermodynamic temperature , with @xmath101 given by ( [ fdef ] ) , there follows @xmath232 with @xmath233    let us shortly discuss these results .",
    "the condition @xmath234 requires that @xmath235 holds .",
    "the latter is also expected on physical grounds .",
    "the equality @xmath236 is reached when temperature @xmath98 goes to infinity .",
    "expansion for small @xmath237 , assuming @xmath88 , gives @xmath238 this means that for small temperatures the population of the excited level goes like @xmath239 . on the other hand ,",
    "if @xmath90 then the limit @xmath240 is reached at a finite temperature @xmath241 given by @xmath242 below @xmath241 is @xmath240 . due to the cutoff in the probability distribution the first excited level is not populated at all .",
    "see figure 1",
    ".    in the special case @xmath243 one obtains directly from ( [ 2levx],[2levp ] ) that @xmath244 .",
    "the corresponding temperature is calculated using ( [ spectemp ] ) and satisfies @xmath245 in particular , as noted earlier , if @xmath201 , then the special temperature satisfies @xmath121 . hence , as a funtion of @xmath246 , curves plotting @xmath237 as a function of @xmath98 for different @xmath0 , but @xmath201 , all intersect in the same point",
    " see figure 1 .",
    "we now show how nonlinear averages arise in a natural way .",
    "note that @xmath247 with @xmath248 .",
    "in particular , the equation @xmath249 appearing in the l.h.s .  of ( [ largedev2 ] ) , can be rewritten as @xmath250 this implies that ( [ largedev2 ] ) can be written as @xmath251 with @xmath252    the problem is now to find a probability distribution @xmath253 for which ( [ largedevext ] ) is satisfied .",
    "a candidate solution to this problem is obtained by maximizing entropy with the constraint that @xmath254 the latter condition can be written as @xmath255 with average @xmath256 calculated as a kn - mean w.r.t .  the function @xmath257 .",
    "this justifies the use of nonlinear kn - averages .    remains the question which entropy should be optimized .",
    "we believe that in many applications the right choice is either shannon s entropy or an @xmath0-entropy of rnyi ( or an equivalent entropy like that of tsallis ) .",
    "the reason for this belief is that these are the only entropies with nice additivity properties .",
    "we reconsider the curie - weiss model , now with the function @xmath10 equal to @xmath258 .",
    "it is not the intention here to treat this model in detail , with arbitrary values of @xmath0 and @xmath205 .",
    "we rather want to to discuss the thermodynamic limit in the extensive @xmath201-case .",
    "introduce the notations @xmath162 and @xmath259 , and @xmath260 the equilibrium probabilities are , assuming @xmath88 , ( see ( [ ftdistr ] ) and the discussion of the previous subsection ) @xmath261^{1/(\\alpha_n-1)}\\cr & = & { n\\choose \\frac{n+m}{2}}\\frac{1}{z } \\left[\\alpha_n -\\frac{1}{\\beta_0 t}\\left ( 1-\\frac{1}{\\gamma(m)}\\right ) \\right]^{-n/(1-\\alpha)}\\cr & \\sim & \\exp\\bigg[-ns(m ) \\bigg],\\end{aligned}\\ ] ] with @xmath262\\end{aligned}\\ ] ] ( assuming @xmath263 ) .",
    "the first derivative of @xmath264 is @xmath265",
    "let @xmath179 be the value of @xmath266 for which @xmath264 is maximal .",
    "it is a solution of @xmath267 .",
    "hence it satisfies @xmath268 but @xmath269 holds for large @xmath129 , so that the previous equation simplifies to the standard mean - field equation ( [ mfeq ] ) .    in case @xmath263 the rate function @xmath264 does not differ significantly from the standard result @xmath270 . if @xmath271 the difference consists in the first place of a constant term .",
    "all together , the present treatment of the curie - weiss model seems to yield results which are very similar to the standard one .",
    "we have presented a formalism of thermostatistics based on kolmogorov - nagumo averages and hartley s information measure .",
    "it treats the problem of maximizing average information @xmath25 under the constraint that average energy @xmath20 has some given value @xmath21 .",
    "the kn - average @xmath256 is determined by a monotonic function @xmath10 and by probabilities @xmath6 .",
    "the same kn - average is used to define average energy and to define entropy as an average information content . in the present paper the function @xmath10",
    "is kept constant while the probabilities @xmath6 are varied",
    ". it could be interesting to consider cases where @xmath10 is varied as well .    of particular interest",
    "is the case when @xmath10 is an exponential function because then the average information @xmath25 coincides with rnyi s entropy . as proved by rnyi , his @xmath0-entropies ,",
    "together with that of shannon , are the only additive ones . instead of exponential @xmath10",
    "we use a slightly modified function ( [ phirenyi ] ) , for which @xmath25 is still rnyi s entropy .",
    "we call the statistical formalism obtained in this way rnyi thermostatistics .",
    "it generalizes the standard formalism of boltzmann - gibbs .",
    "note that rnyi thermostatistics is extensive in the sense that , when a system is composed of independent subsystems and the probabilities are of the product form , then both average information and average energy of the total system are the sum of the corresponding subsystem averages . from the examples of the curie - weis model ( section [ cw2_sect ] ) and the two - level model ( section [ 2lev_sect ] )",
    "it seems that rnyi thermostatistics behaves quite similar to the standard formalism .",
    "the most striking difference is the energy cut - off which can occur in case @xmath90 .",
    "when this happens then the probability of occupation of high - energy levels is exactly zero . in particular , this kind of equilibrium state is not a gibbs measure .",
    "we have tried to justify the use of kn - averages in statistical mechanics .",
    "in essence , a kn - average consists of a change of scale by means of a function @xmath10 , followed by a statistical average using probabilities @xmath6 , and a final back transformation using the inverse function @xmath272 .",
    "a basic ingredient of statistical mechanics is the equivalence of ensembles .",
    "a possible reason for combining the canonical ensemble with a change of scale is that in this way the equivalence of ensembles might be restored .",
    "we did not consider equivalence of ensembles directly , but argued on the level of fluctuations of energy .",
    "these should be exponentially small in order to apply the theory of large deviations .",
    "it is intuitively clear that a change of scale influences the scale of fluctuations .",
    "this is indeed confirmed by calculations on the curie - weiss model which we used as an example .",
    "now , if the function @xmath10 is the function involved in the definition of rnyi s entropy , then scaled energy fluctuations can be expressed as fluctuations of the scaled energy . in this way we can justify that scaled energy",
    "is the relevant quantity of the canonical ensemble .    in a natural way tsallis",
    "entropy appears as a tool for calculating equilibrium averages in rnyi thermostatistics .",
    "this offers the opportunity to reuse knowledge from tsallis - like thermostatistics .",
    "it shines also new light onto tsallis nonextensive thermostatistics because there is a one - to - one translation of problems from the one formalism to the other .",
    "there are many applications of the tsallis formalism  see e.g.  the review paper @xcite . an open question is how many of these applications have a natural formulation in terms of rnyi thermostatistics . as a first guess",
    "this would be the case whenever extensivity is important .",
    "we consider also a further generalization of extensive rnyi thermostatistics to a non - extensive formalism .",
    "this extended formalism includes , besides the extensive case , also nonextensive tsallis thermostatistics . in particular ,",
    "an argument has been presented which settles the problem of defining thermodynamic temperature in a nonextensive context .",
    "a short version of the present paper has appeared in @xcite .",
    "one of the authors ( mc ) wishes to thank the nato for a research fellowship enabling his stay at the universiteit antwerpen .",
    "definition ( [ defln ] ) of the @xmath0-deformed logarithm @xmath194 , without the condition @xmath273 , is what is found in literature @xcite .",
    "the inverse function @xmath274 is not defined for all @xmath55 , while we need it for all @xmath55 in section [ renyisect ] .",
    "therefore we propose the following extended definition @xmath275 ( we assume @xmath48 , @xmath49 ) .",
    "it satisfies @xmath276 .",
    "the deformed logarithm @xmath194 converges in the limit @xmath52 to the natural logarithm @xmath277 .",
    "the derivative of @xmath194 is a continuous positive function given by @xmath278 in particular , this implies that @xmath194 is a strictly increasing function of @xmath55 .",
    "note that @xmath279 while for @xmath88 the deformed logarithm takes on any real value .",
    "hence , the inverse function @xmath274 has a limited domain of definition in the former case .",
    "one finds @xmath280_+^{1/(1-\\alpha ) } \\qquad\\hbox { if } x\\ge 0\\cr & = & \\left[1+(\\alpha-1)x\\right]_+^{1/(\\alpha-1 ) } \\qquad\\hbox { if } x\\le 0\\end{aligned}\\ ] ] clearly , @xmath281 and @xmath274 can not be negative . in the limit @xmath52 the deformed exponential function @xmath274 converges to the usual exponential function @xmath282 .",
    "lewis , c .- e .",
    "pfister , w.g .",
    "sullivan , _ large deviations and the thermodynamic formalism : a new proof of the equivalence of ensembles , _ in : _ on three levels , _ ed",
    ". m. fannes , c. maes , a. verbeure ( plenum press , new york , 1994 )                    a. v. milovanov and l. m. zelenyi , _ functional background of the tsallis entropy : `` coarse - grained '' systems and `` kappa '' distribution functions , _ nonlinear processes in geophysics , * 7*(3/4 ) , 211 - 221 2000 .",
    "j. naudts and m. czachor , _ dynamic and thermodynamic stability of non - extensive systems , _ in : `` nonextensive statistical mechanics and its applications '' , ed .",
    "s. abe , y. okamoto , lecture notes in physics 560 ( springer - verlag , 2001 ) , p. 243 - 252 .",
    "j. naudts , _ dual description of nonextensive ensembles , _ in : `` classical and quantum complexity and nonextensive thermodynamics '' , eds . c. tsallis , p. grigolini , and b. west , chaos , solitons , and fractals * 13*(3),445 - 450 ( 2002 ) ."
  ],
  "abstract_text": [
    "<S> we introduce a generalized thermostatistics based on kolmogorov - nagumo averages and appropriately selected information measures . </S>",
    "<S> the formalism includes tsallis non - extensive thermostatistics , but also extensive thermostatistics based on rnyi entropy . </S>",
    "<S> the curie - weiss model is discussed as an example .    </S>",
    "<S> keywords : generalized thermostatistics , kolmogorov - nagumo mean , rnyi entropy , tsallis entropy , kappa distribution , nonlinear averages , non - extensive thermodynamics , mean - field model . </S>"
  ]
}