{
  "article_text": [
    "discrete time homogeneous semi - markov chains have been recognized as a flexible and efficient tool in the modelling of stochastic systems .",
    "recent results and applications are retrievable in @xcite .",
    "the idea to link rewards to the occupancy of a semi - markov state led to the construction of semi - markov reward processes .",
    "these processes have been studied in @xcite and since then many developments and applications have been discussed .",
    "non - homogeneous semi - markov reward processes were defined in @xcite .",
    "a method of computing the distribution of performability in a semi - markov reward process was discussed in @xcite .",
    "the asymptotic behaviour of a time homogeneous semi - markov reward process was studied in @xcite .",
    "more recent developments includes the derivations of higher order moments of the homogeneous semi - markov reward process with initial backward ( @xcite ) and for the non - homogeneous case ( @xcite ) , both the papers presented applications in the field of disability insurance . in @xcite the reward paths in non - homogeneous semi - markov systems in discrete time are examined with stochastic selection of the transition probabilities .",
    "the mean entrance probabilities and the mean rewards in the course of time are evaluated .",
    "this paper has been further generalized in @xcite .",
    "finally in the paper by @xcite duration dependent non - homogeneous semi - markov chains were proposed in a disability insurance model .",
    "+ in this paper we generalize some of the previous contributions by defining and analyzing the second order semi - markov reward process in state and duration and giving relations for computing the higher order moments of this process .",
    "moreover , we propose to employ a matrix notation that makes calculations easier and also provides a compact form for equations of moments of the reward process .",
    "the second order semi - markov model in state and duration constitutes a generalization of the semi - markov chain model because it allows the transition probabilities to vary depending on the last two visited states of the system and on the sojourn time lenght between these states .",
    "+ the second order semi - markov model in state and duration was proposed in @xcite were it was applied in the modeling of wind speed . in that paper first and second order semi - markov models were proposed with the aim of generating reliable synthetic wind speed data .",
    "there , it was shown that all the semi - markov models perform better than the markov chain model in reproducing the statistical properties of wind speed data .",
    "in particular , the model recognized as being more suitable is the second order semi - markov chain in state and duration .",
    "this model has been further investigated in @xcite where classical reliability measures were computed with application to wind energy production . continuing the effort in the searching of models ever more able to describe wind speed data , in this paper",
    "we apply the theoretical results concerning moments of the reward process to provide methods for computing the accumulated energy produced by a blade in a bounded time interval .",
    "the expected total energy produced gives important information on the feasibility of the investment in a wind farm and the riskiness of the investment can be measured in terms of variance , skewness , and kurtosis of the reward process .",
    "finally notice that the technological characteristics of different blades are captured by the permanence reward and consequently we are able to choose among different blades to be installed at a given location .",
    "+ the paper is divided in this way : first , the second order semi - markov model in state and duration is presented .",
    "second , the reward structure is introduced and the equations of the higher order moments of the reward process are determined . finally , the proposed approach is applied to compute moments of the total energy produced by a commercial blade applied to real wind speed data .",
    "in this section we give a short description of the second order semi - markov chain in state and duration , see @xcite and @xcite for additional results .",
    "+ let us consider a finite set of states @xmath0 in which the system can be into and a complete probability space @xmath1 on which we define the following random variables : @xmath2 they denote the state occupied at the @xmath3-th transition and the time of the @xmath3-th transition , respectively .",
    "to be more concrete , by @xmath4 we denote the wind speed at the @xmath3-th transition and by @xmath5 the time of the @xmath3-th transition of the wind speed .",
    "+ we assume that @xmath6\\\\ & \\quad = \\mathbb{p}[j_{n+1}=j , t_{n+1}-t_{n}= t |j_{n}=k , j_{n-1}=i , t_{n}-t_{n-1}=x ] : = \\,\\,_{x}q_{i.k , j}(t ) . \\end{aligned}\\ ] ] relation @xmath7 asserts that , the knowledge of the values @xmath8 suffices to give the conditional distribution of the couple @xmath9 whatever the values of the past variables might be . therefore to make probabilistic forecasting we need the knowledge of the last two visited states and the duration time of the transition between them .",
    "for this reason we called this model a second order semi - markov chains in state and duration .",
    "+ it should be remarked that in the paper by @xcite were defined nth order semi - markov chains in continuous time .",
    "anyway the dependence was only on past states and not on durations .",
    "+ the conditional probabilities @xmath10\\ ] ] are stored in a matrix of functions @xmath11 named the second order kernel ( in state and duration ) .",
    "the element @xmath12 represents the probability that next wind speed will be in speed @xmath13 at time @xmath14 given that the current wind speed is @xmath15 and the previous wind speed state was @xmath16 and the duration in wind speed @xmath16 before of reaching wind speed @xmath15 was equal to @xmath17 units of time .",
    "+ from the knowledge of the kernel we can define the cumulated second order kernel probabilities : @xmath18\\\\ & = \\sum_{s=1}^{t } { _ { x}q_{i.k , j}(s)}. \\end{aligned}\\ ] ] the process @xmath19 is a second order markov chain with state space @xmath20 and transition probability matrix @xmath21",
    ". we shall refer to it as the embedded markov chain .",
    "+ define the unconditional waiting time distribution function in states @xmath15 coming from state @xmath16 with duration @xmath17 as @xmath22=\\sum_{j\\in e}{_{x}q_{i.k , j}(t)}.\\ ] ] the conditional cumulative distribution functions of the waiting time in each state , given the state subsequently occupied is defined as @xmath23\\\\ & = \\frac{1}{_{x}p_{i.k , j}}\\sum_{s=1}^{t}{_{x}q_{i.k , j}(s)}\\cdot 1_{\\{_{x}p_{i.k , j}\\neq 0\\}}+1_{\\{_{x}p_{i.k , j}=0\\ } } \\end{aligned}\\ ] ] define by @xmath24 @xmath25 .",
    "we define the second order ( in state and duration ) semi - markov chain as @xmath26 .",
    "+ for this model ordinary transition probability functions and transition probabilities with initial and final backward recurrence times were defined and computed in @xcite and reliability measures applied to wind energy production were presented in @xcite .",
    "in this section , following the line of research in @xcite , we determine recursive equations for higher order moments of the second order semi - markov reward chain in state and duration . + let @xmath27 denote the accumulated discounted reward during the time interval @xmath28 $ ] defined by the following relation , @xmath29 where : @xmath30 is the backward recurrence time process , @xmath31 is the sojourn time in state @xmath32 before the @xmath33 transition and @xmath34 with @xmath35 $ ] is the one period deterministic discount factor .",
    "+ the reward @xmath36 measures the performance of the system at time @xmath37 . in our model",
    "the actual performance is a function of the current state @xmath32 occupied by the system ; it depends on the last two visited states @xmath38 ; it is duration dependent in the current state because it is a function of the backward process @xmath39 and finally it depends on the sojourn time in the past states being dependent on @xmath40 .",
    "our reward model is more general than those considered in @xcite because in that paper the authors considered a first order semi - markov chain and the permanence reward @xmath41 do depend only on the couple @xmath42 .",
    "+ let also denote by @xmath43 the random variable , which has the distribution the same with the conditional distribution for the random variable @xmath27 given that @xmath44 and let denote by @xmath45 $ ] . + in order to propose a matrix representation that simplifies calculations and provides a compact form for next equations we need to introduce the adopted notation and products .    given two @xmath46 matrices @xmath47 and @xmath48 , their hadamard matrix product @xmath49 gives the @xmath46 matrix @xmath50",
    "whose generic element is given by : @xmath51    let @xmath52 be a @xmath53 matrix and @xmath54 be a @xmath55 vector , their @xmath56 matrix product gives the @xmath55 vector whose elements , for all @xmath57 are expressed by @xmath58    the first order moment of the reward process @xmath43 is computed in the following theorem .",
    "the first order moment of the second order semi - markov chain in state and duration satisfies the following matrix equation : @xmath59 where @xmath60 @xmath61 @xmath62 @xmath63 is @xmath64 and @xmath65 is @xmath64 , @xmath66 @xmath67 and @xmath68 is the unitary row vector .    * proof * : let consider the random variable @xmath69 .",
    "the time of next transition @xmath70 can be greater of @xmath14 or not .",
    "consequently it results that : @xmath71=e [ _ { x , v}\\xi_{i , k}(t)1_{\\{t_{n(0)+1}>t\\}}]+e [ _ { x , v}\\xi_{i , k}(t)1_{\\{t_{n(0)+1}\\leq t\\}}].\\ ] ] in the case @xmath72 we have that @xmath73 and this event occurs with probability @xmath74 then it results that @xmath75= \\ , _ { x , v}d_{i , k}(t)\\sum_{u=1}^{t } \\ : _ { x}\\psi_{i , k;k } ( u+v)e^{- \\delta u}.\\ ] ] the elements @xmath76 are stored in the matrix @xmath77 of dimension @xmath78 according to the following rule : @xmath79 the elements @xmath80 are stored in the matrix @xmath81 of dimension @xmath78 according to the rule : @xmath82 consequently the right hand side of @xmath83 can be expressed in matrix form as follows : @xmath84 in the second case , when @xmath85 , if we consider the next visited state @xmath86 and the time of next transition @xmath70 we have : @xmath87 the event @xmath88 occurs with probability @xmath89 notice that the random variable @xmath90 is independent of the distribution of the joint random variable @xmath91 because the accumulation process has the markov property at transition times and consequently once the state @xmath86 and the @xmath70 are known its behaviour does nt depends on the distribution of @xmath91 .",
    "then by taking the expectation in @xmath92 we get @xmath93\\\\   & = \\sum_{j \\in e } \\sum_{s=1}^{t } \\frac{_{x}q_{i , k;j}(s+v)}{1-\\ , _",
    "{ x}h_{i , k}(v ) } \\cdot \\sum_{s'=1}^{s}\\ : _ { x}\\psi_{i , k;k } ( v+s')e^{- \\delta s'}\\\\ & + \\sum_{j \\in e } \\sum_{s=1}^{t } \\frac{_{x}q_{i , k;j}(s+v)}{1-\\ , _ { x}h_{i , k}(v ) } \\cdot \\ , _ { v+s,0}v_{k , j}^{(1 ) } ( t - s)e^{-\\delta s}. \\end{aligned}\\ ] ] the elements @xmath94 are stored in the matrix @xmath95 of dimension @xmath96 according to the rule : @xmath97 then @xmath98 become the elements of the vector @xmath99 where @xmath68 is the unitary row vector .",
    "+ having defined these matrices it is simple to realize that @xmath100 is a @xmath78 vector and @xmath101 this argument , applied also to the second term on the r.h.s . of equation @xmath102 , allows to represent @xmath102 in matrix form as : @xmath103 a substitution of @xmath104 and @xmath105 in @xmath106 concludes the proof .",
    "@xmath107    by using similar techniques it is possible to get recursive equations for the higher order moments of the reward process .",
    "the higher order moments of the reward process satisfy the following equation : @xmath108    * proof * : @xmath109\\\\ & = e [ ( _ { x , v}\\xi_{i , k}(t))^{n}1_{\\{t_{n(0)+1}>t\\}}]+e [ ( _ { x , v}\\xi_{i , k}(t))^{n}1_{\\{t_{n(0)+1}\\leq t\\ } } ]",
    ". \\end{aligned}\\ ] ] in the case @xmath72 we have that @xmath110 and this event occurs with probability @xmath76 , see ( [ tre ] ) .",
    "consequently it results that @xmath111=\\ , _ { x , v}d_{i , k}(t)\\big(\\sum_{u=1}^{t } \\ : _ { x}\\psi_{i , k;k } ( u+v)e^{- \\delta u}\\big)^{n}.\\ ] ] in the opposite case , when @xmath112 , we have that @xmath113 the event @xmath88 occurs with probability @xmath114 . + then , by using the already mentioned independence between @xmath90 and the joint random variable @xmath91 , by taking the expectation in @xmath115 we get : @xmath116= \\\\ & + \\sum_{j \\in e } \\sum_{s=1}^{t } \\frac{_{x}q_{i , k;j}(s+v)}{1-\\ , _ { x}h_{i , k}(v ) } \\cdot \\left ( \\sum_{s'=1}^{s}\\ : _ { x}\\psi_{i , k;k } ( v+s')e^{- \\delta s ' } \\right)^n\\\\ & + \\sum_{j \\in e } \\sum_{s=1}^{t } \\frac{_{x}q_{i , k;j}(s+v)}{1-\\ , _ { x}h_{i , k}(v ) } \\cdot \\ , _ { v+s,0}v_{k , j}^{(n ) } ( t - s)e^{-\\delta s n}\\\\ & + \\sum_{j \\in e } \\sum_{s=1}^{t } \\sum_{l=1}^{n-1 }   \\frac{_{x}q_{i , k;j}(s+v)}{1-\\ , _ { x}h_{i , k}(v ) }   \\left ( \\begin{array}{c }",
    "n\\\\ l\\\\ \\end{array } \\right ) \\left ( \\sum_{s'=1}^{s}\\ : _ { x}\\psi_{i , k;k } ( v+s')e^{- \\delta s ' } \\right)^{n - l}\\\\ & \\cdot \\ , _ { v+s,0}v_{k , j}^{(l ) } ( t - s)e^{-\\delta s l}. \\end{aligned}\\ ] ] if we substitute @xmath117 and @xmath118 in @xmath119 and we represent the resulting expression in matrix form we obtain the equation @xmath120 .    @xmath107    if @xmath121 and @xmath122 we have that @xmath123 then the second order semi - markov reward chain model in state and duration collapses in a standard semi - markov reward chain model and we recover exactly the results by @xcite .",
    "the adopted matrix notation for the moments of the second order semi - markov reward chain in state and duration permits the computation of the moments with no more difficulties as compared to those necessary for the standard semi - markov chain reward model .",
    "in two previous papers @xcite we showed that wind speed can be well described by a second order semi - markov process . given these results we try to verify here if the reward model , described in the previous section , is able to well describe the production of energy by a wind turbine .",
    "the data used in this analysis are freely available from @xmath124 .",
    "the database is composed of about 230000 wind speed measures ranging from 0 to 16 @xmath125 with a sample frequency of 10 minutes .",
    "more accurate information about our database can be found in @xcite .",
    "the state space of wind speed has been discretized into 8 states chosen to cover all the wind speed distribution .",
    "the state space is numerically represented by the set @xmath126 . from the discretized trajectory @xmath127 of the wind speed process",
    "@xmath128 we have to estimate the probabilities @xmath129 and @xmath130 .",
    "the quantity @xmath131 is the censored sojourn time in the last wind speed state @xmath132 .",
    "first of all we introduce the following counting processes : @xmath133 formula @xmath134 expresses the number of transitions from the state @xmath15 to the state @xmath13 with a sojourn time @xmath14 which are preceded by a transition from the state @xmath16 into the state @xmath15 with sojourn time equal to @xmath17 .",
    "+ @xmath135 formula @xmath136 expresses the number of transitions from the state @xmath15 to the state @xmath13 which are preceded by a transition from the state @xmath16 into the state @xmath15 with sojourn time equal to @xmath17 .",
    "+ @xmath137 formula @xmath138 expresses the number of transitions from the state @xmath16 into the state @xmath15 with sojourn time equal to @xmath17 .",
    "+ the transition probabilities of the embedded markov chain @xmath139\\ ] ] can be estimated by @xmath140 the estimation of the conditional waiting time distributions is executed by considering the corresponding probability mass functions @xmath141 which can be estimated by @xmath142 if @xmath143 then @xmath144 . if @xmath145 then @xmath146 .",
    "+ starting from estimators @xmath147 and @xmath148 it is possible to obtain estimators of all the quantities of interest through a plug - in procedure .",
    "+ to have a realistic energy production we choose a commercial wind turbine , a 10 kw aircon hawt with a power curve given in figure [ power ] .",
    "the power curve of a wind turbine represents how it produces energy as a function of the wind speed . in this case",
    "we have no production of energy in the interval 0 - 2 @xmath125 , the wind turbine produces energy linearly from 3 @xmath125 to 10 @xmath125 , then , with increasing wind speed the production remains constant until the limit of wind speed in which the wind turbine is stopped for structural reason .",
    "note that the power curve is a graphical representation of the rewards @xmath149 . in this application",
    "the rewards depend only on the present wind speed and @xmath150 is settled to be zero .    in figure [ ener1 ]",
    "we compare the average cumulated energy produced by real data and the expected value @xmath151 as calculated using formula @xmath152 where @xmath153 .",
    "the comparison is made by varying the sojourn time and the starting state .",
    "particularly , the cumulated energy is plotted for two different initial states _",
    "i _ maintaining constant the current state _",
    "k _ for two different sojourn times _",
    "left and right panel of the figure have different values for the current speed state .",
    "( left panel ) and current speed state is @xmath154 ( right panel),title=\"fig:\",height=151 ]   ( left panel ) and current speed state is @xmath154 ( right panel),title=\"fig:\",height=151 ]    it is possible to note that all the cumulated energies plotted above depend strongly on the initial and current states and that there is also a great dependence on the sojourn time @xmath17 .",
    "in fact , the expected value @xmath151 has different values also if only the sojourn time @xmath17 is changed keeping constant initial states @xmath16 and final state @xmath15 .",
    "for example , from figure [ ener1 ] left panel it is possible to see that @xmath155,\\ ] ] while @xmath156.\\ ] ] this reveals that it is important to dispose of a model that is able to distinguish between these different situations which are determined only from a different duration of permanence in the initial state @xmath16 before making a transition to the current state @xmath15 .",
    "models based on markov chains or classical semi - markov chain are unable to capture this important effect that our second order semi - markov chain in state and duration reproduces according to the real data . + in figure [ ener2 ] we compare the second central moment of the reward process again for real data and as obtained from the model calculated according to equation @xmath120 .",
    "( left panel ) and current speed state is @xmath154 ( right panel),title=\"fig:\",height=151 ]   ( left panel ) and current speed state is @xmath154 ( right panel),title=\"fig:\",height=151 ]    also in this case it is possible to recognize that the model describes well real data behavior especially when the dependence from current states , past states and sojourn times is concerned . in this case",
    "the dependence is less evident but still present .",
    "the purposes of this paper is to provide theoretical methods for computing the moments of a second order semi - markov reward process in state and duration .",
    "the model is then used also to provide theoretical methods for computing the cumulated energy produced by a blade in a temporal interval @xmath157 $ ] .",
    "we have reached this aim by modeling wind speed as a second order semi - markov process .",
    "all the equations for the reward process are then derived under this hypothesis .",
    "our model is tested against real data on wind speed freely available from the web .",
    "we have shown that the proposed model is able to reproduce well the behavior of real data as far as energy production from wind speed is concerned .",
    "in particular , we have shown that the cumulated energy produced by a commercial blade does depend on the initial state _",
    "i _ , the current state _",
    "k _ and on the sojourn times _ x_. these results confirm the second order semi - markov hypothesis .",
    "f. stenberg , r. manca , d. silvestrov , an algorithmic approach to discrete time non - homogeneous backward semi - markov reward processes with an application to disability insurance .",
    "_ methodology and computing in applied probability _ @xmath162 ( 2007 ) 497 - 519 .",
    "papadopoulou , g. tsaklidis , some reward paths in semi - markov models with stochastic selection of the transition probabilities .",
    "_ methodology and computing in applied probability _",
    "@xmath162(3 ) ( 2007 ) 399 - 411 .",
    "papadopoulou , g. tsaklidis , s. mcclean , l. garg , on the moments and the distribution of the cost of a semi - markov model for healthcare systems .",
    "_ methodology and computing in applied probability _",
    "@xmath163(3 ) ( 2012 ) 717 - 737 ."
  ],
  "abstract_text": [
    "<S> in this paper a general second order semi - markov reward model is presented . </S>",
    "<S> equations for the higher order moments of the reward process are presented for the first time and applied to wind energy production . </S>",
    "<S> the application is executed by considering a database , freely available from the web , that includes wind speed data taken from l.s.i . </S>",
    "<S> - lastem station ( italy ) and sampled every 10 minutes . </S>",
    "<S> we compute the expectation and the variance of the total energy produced by using the commercial blade aircon hawt - 10 kw . </S>"
  ]
}