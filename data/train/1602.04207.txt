{
  "article_text": [
    "over the last decade , video delivery has emerged as the main driving factor of the wireless traffic . in this context",
    ", there is often a large library of pre - recorded content ( e.g. movies ) , out of which , users may request to receive a specific file .",
    "one way to reduce the burden of this traffic is to employ memories distributed across the networks and closer to the end users to prefetch some of the popular content .",
    "this can help system to deliver the content with higher throughput and less delay .    as a result",
    ", there have been significant interests in both academia and industry in characterizing the impact of caching on the performance of communication networks ( see , e.g. @xcite ) . in particular , in a network with only one transmitter broadcasting to several receivers , it was shown in @xcite that local delivery attains only a small fraction of the gain that caching can offer , and by designing a particular pattern in cache placement at the users and exploiting coding in delivery , a significantly larger _",
    "throughput gain can be achieved , which is a function of the entire cache throughout the network .",
    "this also demonstrates that the gain of caching scales with the size of the network . as a follow - up , this work has been extended to the case of multiple transmitters in  @xcite , where it was shown that the gain of caching can be improved if several transmitters have access to the entire library of files .",
    "caching at the transmitters was also considered in  @xcite and used to induce collaboration between transmitters in the network .",
    "it is also shown in  @xcite that caches at the transmitters can improve load balancing and increase the opportunities for interference alignment .",
    "more recently , the authors in @xcite evaluated the performance of cellular networks with edge caching via a hypergraph coloring problem .",
    "furthermore , in @xcite , the authors studied the problem of maximizing the delivery rate of a fog radio access network for arbitrary prefetching strategies .",
    "in this paper , we consider a general network setting with caches at both transmitters and receivers , and demonstrate how one can utilize caches at both transmitters and receivers to manage the interference and enhance the system performance in the physical layer . in particular",
    ", we consider a library of @xmath0 files and a wireless network with @xmath1 transmitters and @xmath3 receivers , in which each transmitter and each receiver is equipped with a cache memory of a certain size .",
    "in particular , each transmitter and each receiver can cache up to @xmath2 and @xmath4 files , respectively .",
    "the system operates in two phases . the first phase is called the prefetching phase , where each cache is populated up to its limited size from the content of the library .",
    "this phase is followed by a delivery phase , where each user reveals its request for a file in the library .",
    "the transmitters then need to deliver the requested files to the receivers .",
    "note that in the prefetching phase , the system is still unaware of the files that the receivers will request in the delivery phase .",
    "the goal is to design the cache contents in the prefetching phase and communication scheme in the delivery phase to achieve the maximum throughput for arbitrary set of requested files . due to their practical appeal , in this work we focus on one - shot linear delivery strategies .",
    "interestingly , many of the previous works on caching have relied on one - shot schemes for content delivery ( see , e.g. @xcite ) .",
    "our main result in this paper is the characterization of the one - shot linear sum degrees - of - freedom ( sum - dof ) of the network , i.e. , number of the receivers that can be served interference - free simultaneously , within a factor of 2 for all system parameters .",
    "in fact , we show that the one - shot linear sum - dof of @xmath5 is achievable , and this is within a factor of 2 of the optimum .",
    "this result shows that the one - shot linear sum - dof of the network grows linearly with the aggregate cache size in the network ( i.e. , the cumulative memory available at all nodes ) .",
    "it also implies that caches at the transmitters side are equally valuable as the caches on the receivers side in the one - shot linear sum - dof of the network .",
    "our result , therefore , establishes a fundamental limit on the performance of one - shot delivery schemes for cache - aided interference management .",
    "to achieve the aforementioned sum - dof , we propose a particular pattern in cache placement so that each piece of each file in the library is available in the caches of @xmath6 transmitters and @xmath7 receivers .",
    "once caching is done this way , we can show that for delivering any set of requested contents to the receivers , @xmath5 of the receivers can be served at each time , interference - free .",
    "this gain is achieved by simultaneously exploiting the opportunity of collaborative interference cancellation ( i.e. zero - forcing ) at the transmitters side and opportunity of eliminating known interference contributions at the receivers side .",
    "the first opportunity is created by caching the pieces of each file at several transmitters . the second opportunity is available since pieces of a file requested by one user has been cached at some other receivers , and thus do not impose interference at those receivers effectively .",
    "our proposed cache placement pattern maximizes the overall gain achieved by these opportunities for any arbitrary set of receiver requests and this gain can be achieved even with a simple one - shot linear delivery scheme .",
    "moreover , we demonstrate that our achievable sum - dof is within a factor of 2 of the optimal sum - dof for one - shot linear schemes . to prove the outer bound , we take a four - step approach in order to lower bound the number of communication blocks needed to deliver any set of requested files to the receivers .",
    "first , we show that the network can be converted to a virtual miso interference channel in each block of communication . using this conversion ,",
    "we next write an integer optimization problem for the minimum number of communication blocks needed to deliver a fixed set of requests for a given caching realization . we then show how we can focus on average demands instead of the worst - case demands to derive an outer optimization problem on the number of communication blocks optimized over the caching realizations . finally , we present a lower bound on the value of the aforementioned optimization problem , which leads to the desired upper bound on the one - shot linear sum - dof of the network .",
    "this result illustrates that in this setting , caches at transmitters side are equally valuable as caches at receivers side .",
    "it also shows that caching offers a throughput gain that scales linearly with the size of the network .",
    "the rest of the paper is organized as follows .",
    "we present the problem formulation in section [ sec : model ] .",
    "we state the main result in section [ sec : result ] .",
    "we prove the achievability of our main result in section [ sec : ach ] and the converse in section [ sec : converse ] .",
    "finally , we conclude the paper in section [ sec : conc ] .",
    "in this section , we first provide a high - level description of the problem setting and the main parameters in the system model , and then we present a detailed description of the problem formulation .      consider a wireless network , as illustrated in figure [ fig : network_model ] , with @xmath1 transmitters and @xmath3 receivers , and also a library of @xmath0 files , each of which contains @xmath8 packets , where each packet is a vector of @xmath9 bits .",
    "each node in the network is equipped with a local cache memory of a certain size that can be used to cache contents arbitrarily from the library before the receivers reveal their requests and communication begins .",
    "in particular , each transmitter and each receiver is equipped with a cache of size @xmath10 and @xmath11 packets , respectively .",
    "transmitters and @xmath3 receivers , where each transmitter and each receiver caches up to @xmath10 packets and @xmath11 packets , respectively , from a library of @xmath0 files , each composed of @xmath8 packets.,scaledwidth=50.0% ]    we assume that the system operates in two phases , namely the _ prefetching phase _ and the _ delivery phase_. in the prefetching phase , each node can cache contents arbitrarily from the library subject to its cache size constraint .",
    "in particular , each transmitter selects up to @xmath10 packets out of the entire library to store in its cache , and each receiver selects up to @xmath11 packets out of the entire library to store in its cache . in the delivery phase",
    ", each receiver requests an arbitrary file from the library . since each receiver may have cached parts of its desired file in the prefetching phase , the transmitters need to deliver the rest of the requested packets to the receivers over the wireless channel .",
    "we assume that at each time , the transmitters employ a one - shot linear scheme , where a subset of requested packets are selected to be delivered interference - free to a corresponding subset of receivers .",
    "each transmitter transmits a linear combination of the subset of the selected packets which it has cached in the prefetching phase .",
    "the interference is cancelled with the aid of cached contents as follows . since each requested packet",
    "may be cached at multiple transmitters , the transmitters can collaborate in order to zero - force the outgoing interference of that packet at some of the unintended receivers .",
    "moreover , the receivers can also use their cached packets as side information to eliminate the remaining incoming interference from to undesired packets .",
    "our objective is to design a cache placement scheme and a delivery scheme which maximize the number of packets that can be delivered at each time interference - free .    in this setting , we define the one - shot linear sum - degrees of freedom as the ratio of the number of delivered packets over the number of blocks needed for communicating those packets for any set of receiver demands .",
    "finally , we define the one - shot linear sum - dof of the network , denoted by @xmath12 , as the maximum achievable one - shot linear sum - dof over all caching realizations .",
    "we consider a discrete - time additive white gaussian noise channel , as illustrated in figure [ fig : network_model ] , with @xmath1 transmitters denoted by @xmath13 and @xmath3 receivers denoted by @xmath14 .",
    "the communication at time @xmath15 over this channel is modeled by @xmath16 where @xmath17 denotes the signal transmitted by @xmath18\\triangleq\\{1, ...",
    ",k_t\\}$ ] and @xmath19 denotes the receive signal by @xmath20 $ ] .",
    "moreover , @xmath21 denotes the channel gain from @xmath22 to @xmath23 , assumed to stay fixed over the course of communication , and @xmath24 denotes the additive white gaussian noise at @xmath23 at time slot @xmath15 , distributed as @xmath25 .",
    "the transmit signal at @xmath18\\triangleq\\{1, ...",
    ",k_t\\}$ ] is subject to the power constraint @xmath26\\leq p$ ] .",
    "we assume that each receiver will request an arbitrary file out of a library of @xmath0 files @xmath27 , which should be delivered by the transmitters .",
    "each file @xmath28 in the library contains @xmath8 packets @xmath29 , where each packet is a vector of @xmath9 bits ; i.e. , @xmath30 .",
    "furthermore , we assume that each node in the network is equipped with a cache memory of a certain size that can be used to cache arbitrary contents from the library before the receivers reveal their requests and communication begins .",
    "in particular , each transmitter and each receiver is equipped with a cache of size @xmath10 and @xmath11 packets , respectively .",
    "we assume that the network operates in two phases , namely the prefetching phase and the delivery phase , which are described in more detail as follows .",
    "_ prefetching phase : _ in this phase , each node can store an arbitrary subset of the packets from the files in the library up to its cache size .",
    "in particular , each transmitter @xmath22 chooses a subset @xmath31 of the @xmath32 packets in the library , where @xmath33 , to store in its cache .",
    "likewise , each receiver @xmath34 stores a subset @xmath35 of the packets in the library , where @xmath36 .",
    "caching is done at the level of whole packets and we do not allow breaking the packets into smaller subpackets . also , this phase takes place unaware of the receivers future requests .",
    "_ delivery phase : _ in this phase , each receiver @xmath20 $ ] , reveals its request for an arbitrary file @xmath37 from the library for some @xmath38 $ ] .",
    "we let @xmath39^t$ ] denote the demand vector .",
    "depending on the demand vector @xmath40 and the cache contents , each receiver has already cached some packets of its desired file and there is no need to deliver them .",
    "the transmitters will be responsible for delivering the rest of the requested packets to the receivers . in order to make sure that any piece of content in the library is stored at the cache of at least one transmitter in the network ,",
    "we assume that the transmitter cache size satisfies @xmath41 .",
    "each transmitter first employs a random gaussian coding scheme @xmath42 of rate @xmath43 to encode each of its cached packets into a _ coded packet _ composed of @xmath44 complex symbols , so that each coded packet carries one degree - of - freedom ( dof ) .",
    "we denote the coded version of each packet @xmath45 in the library by @xmath46 .",
    "afterwards , the communication takes place over @xmath47 blocks , each of length @xmath44 time slots . in each block",
    "@xmath48 $ ] , the goal is to deliver a subset of the requested packets , denoted by @xmath49 , to a subset of receivers , denoted by @xmath50 , such that each packet in @xmath49 is intended to exactly one of the receivers in @xmath50 .",
    "in addition , the set of transmitted packets in all blocks and the cache contents of the receivers should satisfy @xmath51,\\end{aligned}\\ ] ] which implies that for any receiver @xmath20 $ ] , each of its requested packets should be either transmitted in one of the blocks or already stored in its own cache .    in each block",
    "@xmath48 $ ] , we assume a one - shot linear scheme where each transmitter transmits an arbitrary linear combination of a subset of the coded packets in @xmath49 that it has cached . particularly , @xmath18 $ ] transmits @xmath52\\in\\mathbb{c}^{\\tilde{b}}$ ] , where @xmath53=\\sum_{\\substack{(n , f):\\\\\\mathbf{w}_{n , f}\\in\\mathcal{p}_i \\cap \\mathcal{d}_m } } v_{i , n , f}[m ] ~ \\tilde{\\mathbf{w}}_{n , f},\\end{aligned}\\ ] ] and @xmath54 $ ] s denote the complex beamforming coefficients that @xmath22 uses to linearly combine its coded packets in block @xmath55 .    on the receivers side , the received signal of each receiver @xmath56 in block @xmath55 , denoted by @xmath57\\in\\mathbb{c}^{\\tilde{b}}$ ] ,",
    "can be written as @xmath58=\\sum_{i=1}^{k_t } h_{ji } \\mathbf{x}_i[m]+\\mathbf{z}_j[m],}\\end{aligned}\\ ] ] where @xmath59\\in\\mathbb{c}^{\\tilde{b}}$ ] denotes the noise vector at @xmath23 in block @xmath55 .",
    "then , receiver @xmath23 will use the contents of its cache to cancel ( subtract out ) the interference of some of undesired packets in @xmath49 , if they exist in its cache .",
    "in particular , each receiver @xmath60 , forms a linear combination @xmath61 , as @xmath62 , \\tilde{\\mathcal{q}}_j   ) \\end{aligned}\\ ] ] to recover @xmath63 , where @xmath64 denotes the set of coded packets cached at receiver @xmath23 .",
    "the communication in block @xmath65 to transmit the packets in @xmath49 is successful , if there exist linear combinations at the transmitters side and at receivers side , such that for all @xmath56 , @xmath66 , \\tilde{\\mathcal{q}}_j )   = \\tilde{\\mathbf{w}}_{d_j , f}+\\mathbf{z}_j[m ] .",
    "\\end{aligned}\\ ] ] the channel created in is a point - to - point channel , whose capacity is @xmath67 .",
    "hence , since each coded packet @xmath68 is coded with rate @xmath67 , it can be decoded with vanishing error probability as @xmath9 increases .",
    "we assume that the communication continues for @xmath47 blocks until all the desired packets are successfully delivered to all receivers .",
    "the resulting vector @xmath69 $ ] in ( [ eq : decoding ] ) represents receiver @xmath23 s estimate of one of the packets of the file @xmath37 in block @xmath55 which it has not already cached .",
    "now , note that if we concatenate all the @xmath32 coded packets in the library in a single matrix @xmath70 , we can alternatively write @xmath71 and @xmath72 as @xmath73 where @xmath74 is the @xmath75 identity matrix and for a set @xmath76 $ ] , @xmath77 denotes the matrix which consists of the columns of @xmath74 with indices in @xmath78 . combining ( [ eq : tx_rx_cache ] ) with ( [ eq : decoding ] ) , we will get @xmath79 & = \\mathbf{l } \\left[u_j[m ] \\left(\\sum_{i=1}^{k_t } h_{ji } \\mathbf{i}_{\\mathcal{p}_i } \\mathbf{v}_i[m ] \\right ) + \\mathbf{i}_{\\mathcal{q}_j } \\tilde{\\mathbf{u}}_j[m]\\right]\\nonumber\\\\ & \\qquad\\qquad\\qquad\\qquad+u_j[m ] \\mathbf{z}_j[m].\\label{eq : final_decoding}\\end{aligned}\\ ] ]    for a large enough @xmath9 , this implies that @xmath23 is able to decode its desired packet at a specific coding rate @xmath80 if for almost all values of channel gains , the @xmath81 vector inside brackets in ( [ eq : final_decoding ] ) is of the form @xmath82 \\left(\\sum_{i=1}^{k_t } h_{ji } \\mathbf{i}_{\\mathcal{p}_i } \\mathbf{v}_i[m ] \\right ) + \\mathbf{i}_{\\mathcal{q}_j } \\tilde{\\mathbf{u}}_j[m ] = \\mathbf{i}_{\\{d_j[m]\\}},\\end{aligned}\\ ] ] where @xmath83 $ ] is the index of the packet to be decoded within the entire library of @xmath32 packets .",
    "since each packet carries one degree - of - freedom , the one - shot linear sum - degrees - of - freedom ( sum - dof ) of @xmath84 is achievable in each block @xmath85 $ ] .",
    "this implies that throughout the @xmath47 blocks of communication , the one - shot linear sum - dof of @xmath86 is achievable .",
    "therefore , for a given caching realization , we define the one - shot linear sum - dof to be maximum achievable one - shot linear sum - dof for the worst case demands ; i.e. , @xmath87    this leads us to the definition of the one - shot linear sum - dof of the network as follows .",
    "[ def : sumdof ] for a network with a library @xmath0 files , each containing @xmath8 packets , and cache size of @xmath2 and @xmath4 files at each transmitter and receiver , respectively , we define the one - shot linear sum - dof of the network as the maximum achievable one - shot linear sum - dof over all caching realizations ; i.e. , @xmath88$}}\\\\ & \\hspace{.68 in } { |\\mathcal{q}_i|\\leq m_r f , ~\\forall i\\in[k_r],}\\end{aligned}\\ ] ] where @xmath89 is defined in .",
    "in this section , we present our main result on the one - shot linear sum - dof of the network and its implications .",
    "[ thm : main ] for a network with a library of @xmath0 files , each containing @xmath8 packets , and cache size of @xmath2 and @xmath4 files at each transmitter and each receiver , respectively , the one - shot linear sum - dof of the network , as defined in definition [ def : sumdof ] , satisfies @xmath90 for sufficiently large @xmath8 .    in the following , we highlight the implications of theorem [ thm : main ] and its connections to some prior works :    1 .",
    "( _ within a factor of 2 characterization _ ) the upper bound in ( [ eq : ach_dof ] ) is within a factor of 2 of the lower bound in ( [ eq : ach_dof ] ) .",
    "therefore , theorem [ thm : main ] characterizes the one - shot linear sum - dof of a cache - aided wireless network to within a factor of 2 , for all system parameters . 2 .",
    "( _ aggregate cache size matters _ ) the one - shot linear sum - dof characterized in theorem [ thm : main ] is proportional to the _ aggregate _ cache size that is available throughout the network , even - though these caches are _",
    "isolated_. 3 .",
    "( _ equal contribution of transmitter and receiver caches _ ) perhaps interestingly , the caches at both sides of the network , i.e. , the transmitters side and the receivers side , are equally valuable in the achievable one - shot linear sum - dof of the network . note that in practice , size of each transmitter s cache , @xmath2 , could be large .",
    "however , the number of transmitters ( e.g. , base stations ) @xmath1 is often small . on the other hand , size of the cache @xmath4 at the receivers ( e.g. , cellphones ) is small , whereas the number of receivers @xmath3 is large .",
    "therefore @xmath91 could be comparable with @xmath92 .",
    "our result in theorem [ thm : main ] shows that neither caches at the transmitters nor caches at the receivers should be ignored .",
    "( _ linear scaling of dof with network size _ ) letting @xmath93 , we observe that the one - shot linear sum - dof scales _ linearly _ with the number of users in a _ fully - connected _ interference channel .",
    "note that without caches , the one - shot linear sum - dof of a fully - connected interference channel is bounded by 2 , as shown in @xcite .",
    "hence , caching enables linear growth of the dof without the need for more complex physical layer schemes .",
    "( _ role of transmitter and receiver caches _ ) as we will show in section [ sec : ach ] , in  , @xmath94 represents the contribution of collaborative zero - forcing at the transmitters side , and @xmath95 represents the gain of canceling the known interference at the receivers side . 6 .",
    "( _ connection to single - server coded caching _",
    "@xcite ) a special case of our network model is the case with a single transmitter , which was previously considered in @xcite . in this case",
    ", it can be shown that a sum - dof of @xmath96 is achievable , which is equivalent to the global caching gain introduced in @xcite , indicating the number of receivers in the network that can be served simultaneously , interference - free .",
    "hence , our result subsumes the result of @xcite by generalizing it for the case of multiple transmitters .",
    "( _ connection to multi - server coded caching _",
    "@xcite ) another special case of our network model is the case where each transmitter has space to cache the entire library ; i.e. , @xmath97 .",
    "this case was previously considered in @xcite and it can be verified that in this case , a sum - dof of @xmath98 is achievable . hence , our result can also be viewed as a generalization of the result in @xcite where the cache size of each transmitter may be arbitrarily smaller than the entire library size .    in practice , the files in the library have nonuniform demands and some of them are more popular than the rest . in this case , our algorithm can be used to cache and deliver the @xmath0 most popular files .",
    "if a user requests one of the remaining less popular files , it can be directly served by a central base station .",
    "the parameter @xmath0 can be tuned , based on the popularity pattern of the contents , in order to attain the best average performance .    as an illustrative example , consider a cellular network with 5 base stations as transmitters , each with a 10 tb memory and 100 cellphones as receivers , each with a 32 gb memory .",
    "moreover , consider a library of the 1000 most popular movie titles on netflix , each with size of 5 gb .",
    "then , theorem [ thm : main ] implies that at each time , around 11 cellphones can be served simultaneously interference - free , no matter what their demands are , in contrast to the naive time - sharing scheme , where at each time only 1 cellphone can be served .",
    "the rest of the paper is devoted to the proof of theorem [ thm : main ] .",
    "in particular , we illustrate the achievable scheme in section [ sec : ach ] and we present the converse argument in section [ sec : converse ] .",
    "in this section , we prove the achievability of theorem [ thm : main ] by presenting an achievable scheme which utilizes the caches at the transmitters and receivers efficiently to exploit the zero - forcing and interference cancellation opportunities at the transmitters and receivers sides , respectively . in particular , we introduce a prefetching strategy which maximizes the gains attained by the aforementioned opportunities in the delivery phase , no matter what the receiver demands are .",
    "we first explain our achievable scheme through a simple , illustrative example and then proceed to mention our general achievable scheme .",
    "consider a system with @xmath99 transmitters and @xmath100 receivers , where each transmitter has space to cache @xmath101 files and each receiver has space to cache @xmath102 file .",
    "the library has @xmath103 files @xmath104 , @xmath105 , and @xmath106 , each consisting of @xmath8 packets . in the following",
    ", we will describe the prefetching and delivery phases in detail .    _ prefetching phase : _ in this phase",
    ", each file @xmath107 $ ] in the library is broken into @xmath108 disjoint subfiles @xmath109 for any @xmath110=[3]$ ] and @xmath111=[3]$ ] such that @xmath112 and @xmath113 , where each subfile consists of @xmath114 packets .",
    "each subfile @xmath109 is then stored at the caches of the two transmitters in @xmath115 and the single receiver in @xmath116 .",
    "for example , file @xmath117 is broken into 9 subfiles as follows : @xmath118 where @xmath119 is stored at transmitters @xmath120 and @xmath121 as well as receiver @xmath122 , @xmath123 is stored at transmitters @xmath120 and @xmath121 as well as receiver @xmath124 , etc .",
    "we do the same partitioning for files @xmath9 and @xmath125 , as well .",
    "it is easy to verify that each transmitter caches 6 subfiles of each file , hence the total size of its cached content is @xmath126 packets which satisfies its memory constraint .",
    "also , each receiver caches 3 subfiles of each file and its total cached content has size @xmath127 packets , hence satisfying its memory constraint .",
    "note that in this phase , we are unaware of receivers future requests .    _ delivery phase : _ in this phase , each receiver reveals its request for a file in the library . without loss of generality ,",
    "assume that receivers @xmath122 , @xmath124 and @xmath128 request files @xmath129 , @xmath130 and @xmath131 , respectively .",
    "note that each receiver has already stored 3 subfiles of its desired file in its own cache , and therefore the transmitters need to deliver the 6 remaining subfiles of each requested file .",
    "in particular , the following 18 subfiles need to be delivered by the transmitters to the requesting receivers : @xmath132    we now show that we can break the 18 subfiles in into 6 sets , each containing 3 subfiles , such that the subfiles in each set can be delivered simultaneously to the receivers , interference - free .",
    "such a partitioning is illustrated through the 6 steps in figure [ fig : ex1delivery ] , where each step takes @xmath133 blocks . in each step ,",
    "3 subfiles are delivered to all the receivers simultaneously , while all the inter - user interference can be eliminated .",
    "for example , in the first step , as in figure [ fig : ex1delivery](a ) , subfiles @xmath134 are respectively delivered to receivers @xmath122 , @xmath124 , and @xmath128 at the same time . in figure [ fig : ex1zf ] , we show in detail how the interference is cancelled in this step .",
    "the transmit signals of transmitters @xmath120 , @xmath121 and @xmath135 can be respectively written as @xmath136 where for any subfile @xmath109 , @xmath137 denotes its coded version . for simplicity , in this example",
    ", we ignore the power constraint at the transmitters . on the other hand ,",
    "the received signals by receivers @xmath122 , @xmath124 and @xmath128 can be respectively written as @xmath138    now , note that receivers @xmath122 , @xmath124 and @xmath128 can cancel the interference due to @xmath139 , @xmath123 , and @xmath140 , respectively , since they already have each respective subfile in their own cache .",
    "therefore , all the interference in the network can be effectively eliminated and the receivers will be able to decode their desired subfiles .",
    "likewise , one can verify that all the receivers can receive their desired subfiles interference - free in all the 6 steps of communication depicted in figure [ fig : ex1delivery ] .     for respective requests of files @xmath117 , @xmath9 and @xmath125 by receivers @xmath122 , @xmath124 and @xmath128 , where @xmath141 denotes some linear combination of @xmath142 and @xmath143 . in every step , each pair of transmitters collaborate to zero - force the interference due to a specific subfile at a certain undesired receiver .",
    "moreover , each receiver also uses its cache contents to cancel the interference due to the other interfering packet .",
    "therefore , the communication is interference - free in all 6 steps . ]",
    "(a ) . in this step ,",
    "@xmath120 and @xmath121 zero - force @xmath123 at @xmath128 , @xmath120 and @xmath135 zero - force @xmath139 at @xmath124 , and @xmath121 and @xmath135 zero - force @xmath140 at @xmath122 .",
    "moreover , @xmath122 , @xmath124 and @xmath128 can cancel the interference due to @xmath139 , @xmath123 , and @xmath140 , respectively , since they already have each respective subfile in their own cache . ]",
    "consequently , the 18 subfiles in , each of which consists of @xmath114 packets , are delivered to the receivers in 6 steps , each consisting of @xmath114 blocks .",
    "note that our particular file splitting pattern in the prefetching phase and the particular scheduling pattern in the delivery phase allows us to maximally exploit the two gains of zero - forcing the outgoing interference on the transmitters side and canceling the known interference on the receivers side , no matter what the receiver demands are in the delivery phase .",
    "therefore , the sum - dof of @xmath144 is achievable in this network .",
    "our general achievable scheme is given in algorithm [ ach_alg ] .",
    "in this algorithm , we use the notation @xmath145 and for now , we assume that @xmath146 and @xmath147 are integers . recall that in the example in section [ sec : scheme_example ] , @xmath148 and @xmath149 .    in the following",
    ", we will describe the prefetching and delivery phases in more detail .    _ prefetching phase : _ * for * @xmath150 partition @xmath28 into @xmath151 disjoint subfiles @xmath152 , |\\mathcal{t}|=t_t , \\mathcal{r}\\subseteq[k_r ] , |\\mathcal{r}|=t_r}}$ ] of equal sizes .",
    "* end * * for * @xmath153 @xmath22 caches all @xmath109 for which @xmath154 .",
    "* end * * for * @xmath155 @xmath23 caches all @xmath109 for which @xmath156 . *",
    "end *    _ delivery phase : _ * for * @xmath157 $ ] * for * @xmath158 \\text { s.t . } |\\mathcal{t}|=t_t}$ ] * for * @xmath159 \\setminus \\{j\\ } \\text { s.t . }",
    "|\\mathcal{r}|=t_r}$ ] partition @xmath160 to @xmath161!}{[k_r-(t_r+t_t)]!}$ ] disjoint subfiles @xmath162\\setminus ( \\mathcal{r}\\cup \\{j\\}),t_t-1}\\crcr      }   } } } $ ] of equal sizes .",
    "* end * * end * * end *    * for * @xmath158 \\text { s.t . } |\\mathcal{t}|=t_t}$ ] * for * @xmath159 \\text { s.t . } |\\mathcal{r}|=t_t+t_r}$ ] * for * @xmath163 each transmitter @xmath22 transmits a linear combination of the coded subfiles as in @xmath164,\\pi[l+t_r+1:l+t_r+t_t-1 ] } : l\\in[t_t+t_r ] , i \\in \\mathcal{t } \\oplus_{k_t } ( l-1)\\right\\ } \\right)$ ] using the linear combinations shown in lemma [ lem : sch_packets ] such that the subfiles @xmath165,\\pi[l+t_r+1:l+t_r+t_t-1 ] } : l\\in[t_t+t_r]\\right\\}$ ] are simultaneously delivered to the receivers in @xmath116 interference - free . *",
    "end * * end * * end *      for any file @xmath28 in the library , @xmath166 $ ] , we partition it into @xmath151 disjoint subfiles of equal sizes is sufficiently large , we can assume that it is an integer multiple of @xmath151 .",
    "] , denoted by @xmath167 : |\\mathcal{t}|=t_t\\\\ \\mathcal{r}\\subseteq[k_r ] : |\\mathcal{r}|=t_r}}.\\end{aligned}\\ ] ]    based on the above partitioning , in the prefetching phase , each transmitter @xmath22 stores a subset @xmath31 of the packets in the library as described below .",
    "@xmath168    for instance , in the example network considered in section [ sec : scheme_example ] , transmitter @xmath135 stores the following subset of packets in its cache .",
    "@xmath169    based on the above caching strategy , we can verify that the total number of packets cached by transmitter @xmath22 equals @xmath170 hence satisfying its memory size constraint , where @xmath171 is the number of subsets @xmath110 $ ] of size @xmath146 which include the transmitter index @xmath172 .",
    "likewise , in the prefetching phase , each receiver @xmath23 stores a subset @xmath173 of the packets in the library as described below .",
    "@xmath174    for instance , in the example network considered in section [",
    "sec : scheme_example ] , receiver @xmath124 stores the following subset of packets in its cache .",
    "@xmath175    this suggests that the total number of packets cached by receiver @xmath23 is equal to @xmath176 which also satisfies its memory size constraint .      in this section ,",
    "we first describe the delivery phase for the case where @xmath177 , so that the first term in the lower bound in ( [ eq : ach_dof ] ) is dominant .",
    "we will later show how to deal with the case where @xmath178 .    in the delivery phase , the receiver requests are revealed , and in particular , each receiver @xmath20 $ ] requests a file @xmath37 from the library and the transmitters need to deliver the subfiles in @xmath179 to receiver @xmath23 ; i.e. , the subfiles of file @xmath37 which have not been already stored in the cache of receiver @xmath23 .    in the following ,",
    "our goal is to show that the set of packets which need to be delivered to the receivers can be partitioned into subsets of size @xmath180 such that the packets in each subset can be scheduled together . to this end",
    ", we need to further break each subfile to smaller subfiles .",
    "in particular , for any @xmath181 , \\mathcal{t}\\subseteq[k_t]$ ] s.t .",
    "@xmath182\\setminus\\{j\\}$ ] s.t .",
    "@xmath183 , we partition @xmath160 to @xmath161!}{[k_r-(t_r+t_t)]!}$ ] smaller disjoint subfiles of equal sizes denoted by @xmath184\\setminus ( \\mathcal{r}\\cup \\{j\\}),t_t-1}\\crcr      }   } } } , \\end{aligned}\\ ] ] where for a set @xmath185 , @xmath186 denotes the set of permutations of @xmath185 , and for any @xmath187 , @xmath188 denotes the set of all permutations of all subsets of @xmath185 of size @xmath15 ; i.e. , @xmath189    note that in the example setting discussed in section [ sec : scheme_example ] , @xmath161!}{[k_r-(t_r+t_t)]!}=1 $ ] , which implies that further partitioning of the subfiles is not needed .",
    "the advantage of further breakdown of the subfiles in is that we can now partition the set of the subfiles which need to be delivered to the receivers into certain subsets of size @xmath180 such that each subfile @xmath190 intended for receiver @xmath23 is zero - forced at the receivers with indices in @xmath191 .",
    "moreover , since this subfile is also already cached at the receivers with indices in @xmath192 , the communication will be interference - free for each set of the @xmath180 subfiles .",
    "we show how to do such a partitioning in lemma [ lem : partition_packets ] . in this lemma , we use the following notation : for a set @xmath116 , we let @xmath193 denote the set of @xmath194 circular permutations of @xmath116 . is a way of arranging the elements of @xmath116 around a fixed circle .",
    "the number of distinct circular permutations of a set @xmath116 is equal to @xmath194 .",
    "for example , if @xmath195 , then @xmath196,[1,3,2]\\}$ ] .",
    "] moreover , for a set @xmath185 , a permutation @xmath197 and two integers @xmath198 satisfying @xmath199 , we define @xmath200 $ ] as @xmath201=[\\pi(i \\ : \\oplus_{|\\mathcal{s}| } 0 ) ~~ \\pi(i \\ : \\oplus_{|\\mathcal{s}| } 1 ) ~~ \\pi(i \\ : \\oplus_{|\\mathcal{s}| } 2 ) ~~ ... ~~ \\pi(i \\ : \\oplus_{|\\mathcal{s}| } ( j - i))],\\end{aligned}\\ ] ] where for an integer @xmath55 , @xmath202 is defined as @xmath203    finally , for a set @xmath115 and an integer @xmath204 , we let @xmath205 denote entry - wise addition of elements of @xmath115 with @xmath204 modulo @xmath55 , as defined in .",
    "[ lem : partition_packets ] given the prefetching phase in section [ sec : caching ] , for any receivers demand vector @xmath40 , the set of subfiles which need to be delivered to the receivers can be partitioned into disjoint subsets of size @xmath180 as @xmath206 : |\\mathcal{t}|=t_t \\\\",
    "\\mathcal{r}\\subseteq[k_r ] : |\\mathcal{r}|=t_t+t_r \\\\",
    "\\pi \\in \\pi_{\\mathcal{r}}^{\\emph{circ } } } } \\left\\{w_{d_{\\pi(l)},\\mathcal{t}\\oplus_{k_t}(l-1),\\pi[l+1:l+t_r],\\pi[l+t_r+1:l+t_r+t_t-1 ] } : l\\in[t_t+t_r]\\right\\}.\\end{aligned}\\ ] ]    see appendix [ apx : proof_lem_partition ] .    for the example network mentioned in section [ sec : scheme_example ] , the set of 18 subfiles which need to be delivered to the receivers , as in , can be partitioned to the following 6 sets .",
    "@xmath207    based on the partitioning of the small subfiles that need to be delivered to the receivers in lemma [ lem : partition_packets ] , we will have @xmath208 steps of communication , where at each step , specific sets @xmath115 and @xmath116 and a permutation @xmath192 are fixed as in , and each transmitter @xmath22 will transmit a linear combination of the coded subfiles for which @xmath209 ; i.e. , @xmath210,\\pi[l+t_r+1:l+t_r+t_t-1 ] } : l\\in[t_t+t_r ] , i \\in \\mathcal{t } \\oplus_{k_t } ( l-1)\\right\\ } \\right),\\end{aligned}\\ ] ] where for any subfile @xmath190 , @xmath211 denotes the corresponding coded subfile containing phy coded symbols , and @xmath212 represents the linear combination that transmitter @xmath22 chooses for sending the subfiles in .",
    "we will next show that under such a delivery scheme , there always exists a choice of linear combinations at the transmitters so that at each step , the communication will be interference - free and all the @xmath180 receivers in @xmath116 can decode their desired packets , as we also showed in the example setting in section [ sec : scheme_example ] .",
    "[ lem : sch_packets ] for any subset of @xmath146 transmitters @xmath213 $ ] , any subset of @xmath180 receivers @xmath111 $ ] , and any circular permutation @xmath214 , there exists a choice of the linear combinations @xmath215 in such that the set of @xmath180 subfiles in @xmath216,\\pi[l+t_r+1:l+t_r+t_t-1 ] } : l\\in[t_t+t_r]\\right\\},\\end{aligned}\\ ] ] can be delivered simultaneously and interference - free by the transmitters in @xmath217 } \\big(\\mathcal{t}\\oplus_{k_t}(l-1)\\big)$ ] to the receivers in @xmath116 .    for ease of notation and without loss of generality , assume @xmath218.\\ ] ] first , we need to determine the subset of the subfiles which is available at each transmitter .",
    "it is easy to verify that    * if @xmath219 , then transmitter @xmath22 has subfiles @xmath220,\\pi[l+t_r+1:l+t_r+t_t-1 ] } : l\\in \\{1, ... ,i\\ } \\right\\};\\end{aligned}\\ ] ] * if @xmath221 , then transmitter @xmath22 has subfiles @xmath220,\\pi[l+t_r+1:l+t_r+t_t-1 ] } : l\\in \\{i - t_t+1, ... ,i\\ } \\right\\};\\end{aligned}\\ ] ] * and if @xmath222 , then transmitter @xmath22 has subfiles @xmath220,\\pi[l+t_r+1:l+t_r+t_t-1 ] } : l\\in \\{i - t_t+1, ... ,t_t+t_r\\ } \\right\\}.\\end{aligned}\\ ] ]    since each transmitter sends a linear combination of the subfiles that it has , the transmit signal of transmitter @xmath22 can be written as @xmath223    this implies that the received signal at receiver @xmath224 can be written as @xmath225    now , note that in , the first term corresponds to the desired subfile of receiver @xmath23 , while the second and third terms correspond to the undesired subfiles whose interference needs to be canceled at this receiver .",
    "however , note that the subfiles in the third term are already cached at receiver @xmath23 and hence it is able to cancel their incoming interference .",
    "hence , in order for all receivers @xmath224 to receive their subfiles interference - free , there should exist a choice of linear combination coefficients @xmath226 such that @xmath227    equations - introduce a system of @xmath228 linear equations . on the other hand ,",
    "the number of variables @xmath226 is also equal to @xmath228 .",
    "this indicates that there always exists a choice of linear combination coefficients @xmath226 such that - are satisfied .",
    "finally , note that by scaling all the transmit signals by a large enough factor , the power constraint at all the transmitters can also be satisfied . hence the proof is complete .    as mentioned in section [ sec : model ] , we assume that the channel gains remain constant over the course of communication .",
    "however , for the delivery scheme presented in the proof of lemma [ lem : sch_packets ] , this assumption can be relaxed , since we only need the channel gains to remain unchanged for each block of communication and they can be allowed to vary among different blocks .    in the delivery scheme presented in the proof of lemma [ lem : sch_packets ]",
    ", we only used zero - forcing at the transmitters in order to cancel their outgoing interference , which is dof - optimal .",
    "however , in general one can use any scheme that exploits the collaboration among the transmitters in order to optimize the actual rates in the finite - snr regime ( such as the schemes suited for the mimo broadcast channels  @xcite ) .      as a result of lemmas [ lem : partition_packets ] and [ lem : sch_packets ]",
    ", it is clear that for any set of receiver demands in the delivery phase , we can schedule all the requested subfiles in groups of size @xmath180 .",
    "now , if @xmath146 and/or @xmath147 are not integers , we can split the memories and the files proportionally so that for each new partition , the aforementioned scheme can be applied for updated @xmath146 and @xmath147 which are integers .",
    "hence , combining the schemes over different partitions allows us to serve @xmath180 simultaneously , interference - free , for any values of @xmath146 and @xmath147 such that @xmath177 .    finally ,",
    "if @xmath229 , then since we can not serve more than @xmath3 receivers , we can neglect some of the caches at either the transmitters side or the receivers side and use a fraction of the caches with new sizes @xmath230 and @xmath231 so that @xmath232 .",
    "we can then use algorithm [ ach_alg ] to serve all the @xmath3 receivers simultaneously without interference .    as we showed in section",
    "[ sec : caching ] , our prefetching phase respects the cache size constraint of all the transmitters and receivers . moreover , given our prefetching phase , each receiver @xmath23 caches @xmath233 packets of each file in the library .",
    "hence , for each set of requested files by the receivers , a total of @xmath234 packets need to be delivered by the transmitters to the receivers .    therefore , based on the delivery phase mentioned in section [ sec : ach_general ] ,",
    "the number of blocks required to deliver all the @xmath234 packets to the receivers is equal to @xmath235 .",
    "this suggests that for any set of receiver demands , sum - dof of @xmath236 is achievable , hence completing the proof of achievability of theorem [ thm : main ] .",
    "in this section , we prove the converse of theorem [ thm : main ] .",
    "in particular , we show that the lower bound on the one - shot linear sum - dof in ( [ eq : ach_dof ] ) is within a factor of 2 of the optimal one - shot linear sum - dof . in order to prove the converse , we take four steps as detailed in the following sections .",
    "first , we demonstrate how in each block of communication , the network can be converted into a virtual miso interference channel .",
    "second , we use this conversion to write an integer optimization problem for the minimum number of communication blocks needed to deliver a set of receiver demands for a given caching realization .",
    "third , we show how we can focus on average demands instead of the worst - case demands to derive an outer optimization problem on the number of communication blocks optimized over the caching realizations .",
    "finally , we present a lower bound on the value of the aforementioned outer optimization problem , which leads to the desired upper bound on the one - shot linear sum - dof of the network .      consider any caching realization @xmath237 and any demand vector @xmath40 . as discussed in section [ sec : model ] , in each communication blocks a subset of requested packets are selected to be sent to a corresponding subset of distinct receivers .",
    "now , we can state the following lemma , which bounds the number of packets that can be scheduled together in a single communication block using a one - shot linear scheme .    [",
    "lem : one_shot_ub ] consider a single communication block where a set @xmath238 of @xmath239 packets are scheduled to be transmitted together to @xmath239 distinct receivers . in order for each receiver to successfully decode its desired packet ,",
    "the number of these concurrently - scheduled packets should be bounded by @xmath240 } |\\mathcal{t}_l|+|\\mathcal{r}_{l}|,}\\end{aligned}\\ ] ] where for any @xmath241 $ ] , @xmath242 and @xmath243 denote the set of transmitters and receivers which have cached the packet @xmath244 , respectively .",
    "for ease of notation and without loss of generality , suppose that in the considered block , @xmath239 packets @xmath245 are scheduled to be sent to @xmath239 receivers @xmath246 , respectively .",
    "each transmitter @xmath18 $ ] will transmit @xmath247 where we have dropped the dependency on the block index , since we are focusing on a single block . since the communication takes places with the coded packets , we can co    suppose that for any @xmath241 $ ] , each packet of the subfile @xmath248 which is scheduled in the considered time slot is mapped to a scalar symbol @xmath249 and each transmitter @xmath18 $ ] transmits a linear combination of a subset of these symbols which are available in its cache as @xmath250 where @xmath251 is the coefficient that transmitter @xmath22 uses for the symbol @xmath249 . on the other hand ,",
    "the received signal of receiver @xmath252 $ ] can be written as @xmath253    therefore , ( [ eq : rx_signals_cache_rx ] ) implies that we can effectively convert the network into a new miso interference channel with @xmath239 _ virtual _",
    "transmitters @xmath254 , where @xmath255 is equipped with @xmath256 antennas , and @xmath239 single - antenna receivers @xmath257 , in which each virtual transmitter @xmath255 intends to send the coded packet @xmath258 to receiver @xmath259 .",
    "each antenna in the new network corresponds to a transmitter in the original network .",
    "hence , the channel vectors are correlated in the new network . in fact , as ( [ eq : rx_signals_cache_rx ] ) suggests , all the antennas corresponding to the same transmitter in the original network have the same channel gain vectors to the receivers in the new network .    in the constructed miso interference channel ,",
    "we take a similar approach as in @xcite in order to bound the one - shot linear sum - dof of the network .",
    "each virtual transmitter @xmath255 in the constructed miso network will select a beamforming vector @xmath260 ( which consists of the coefficients chosen by the original transmitters corresponding to its antennas ) to transmit its desired symbol . denoting the channel gain vector between transmitter @xmath255 and receiver @xmath23 as @xmath261 ,",
    "the decodability conditions can be written as @xmath262.\\end{gathered}\\ ] ]    now , each of the vectors @xmath263 $ ] can be written as @xmath264 where @xmath265 is a non - zero scalar , @xmath266 is a @xmath267 permutation matrix and @xmath268 is a vector of size @xmath269 .",
    "also , for any two distinct pairs @xmath270 , the channel gain vector @xmath271 can be permuted as @xmath272 , and we can partition @xmath273 as @xmath274 where @xmath275 is a scalar and @xmath276 is of size @xmath269 .",
    "therefore , the nulling condition in ( [ eq : algn_cache_rx ] ) can be rewritten as @xmath277    now , since the packet sent by the virtual transmitter @xmath255 is available in the caches of at most @xmath278 receivers in the network , the interference of each transmitter should be nulled at least at @xmath279 unintended receivers .",
    "this implies that the free beamforming variables at transmitter @xmath280 , i.e. , @xmath268 , should satisfy at least @xmath279 linear equations in the form of ( [ eq : algn2_cache_rx ] ) .",
    "this is not possible unless the number of equations is no greater than the number of variables , or @xmath281    since the above inequality holds for all @xmath241 $ ] , the proof is complete .",
    "equipped with lemma [ lem : one_shot_ub ] , we define a set of packets @xmath49 selected to be transmitted at block @xmath55 to be _ feasible _ if its size satisfies condition in lemma [ lem : one_shot_ub ] .",
    "we can then write the following integer program ( p1 ) to minimize the number of required communication blocks for any given caching realization and set of receiver demands : @xmath282,\\tag{p1 - 3}\\end{aligned}\\ ] ] where ( [ eq : cover_all_packets ] ) states that all the demanded packets that are not cached at the requesting receivers need to be delivered by the transmitters over the @xmath47 blocks of communication .      we can now write an optimization problem to minimize the number of communication blocks required for delivering the worst - case demands optimized over the caching realizations . however , before that , we need to introduce some notation .    given any caching realization @xmath237",
    ", we can break each file @xmath283 $ ] , in the library into @xmath284 subfiles @xmath285,\\mathcal{r}\\subseteq [ k_r]}$ ] , where @xmath109 denotes the subfile of @xmath28 exclusively stored in the caches of the transmitters in @xmath115 and receivers in @xmath116 , and we use the shorthand notation @xmath286 $ ] to denote @xmath213,\\mathcal{t}\\neq \\emptyset$ ] . we define @xmath287 as the number of packets in @xmath109 .    denoting the answer to the optimization problem ( p1 ) by @xmath288 , the below optimization problem",
    "yields the number of communication blocks required for delivering the worst - case demands , minimized over all caching realizations : @xmath289 } \\sum\\limits_{\\mathcal{r}\\subseteq[k_r ] } a_{n,\\mathcal{t},\\mathcal{r}}=f,~\\forall n\\in [ n]}\\tag{p2 - 2}\\\\ & { \\sum\\limits_{n=1}^n \\sum\\limits_{\\mathcal{r}\\subseteq[k_r ] } \\sum\\limits_{\\substack{\\mathcal{t}\\subseteq [ k_t]:\\\\i \\in \\mathcal{t } } } a_{n,\\mathcal{t},\\mathcal{r}}\\leq m_t f , \\forall i\\in [ k_t]}\\tag{p2 - 3}\\\\ & \\sum\\limits_{n=1}^n \\sum\\limits_{\\mathcal{t}\\subseteq_{\\emptyset}[k_t ] } \\sum\\limits_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\j \\in \\mathcal{r } } } a_{n,\\mathcal{t},\\mathcal{r}}\\leq m_r f , \\forall j\\in [ k_r]\\tag{p2 - 4}\\\\ & a_{n,\\mathcal{t},\\mathcal{r}}\\geq 0 , \\forall n\\in [ n ] , \\forall \\mathcal{t}\\subseteq_{\\emptyset}[k_t],\\forall \\mathcal{r}\\subseteq[k_r].\\tag{p2 - 5}\\label{eq : opt_outer_end_rx_cache}\\end{aligned}\\ ] ]    to lower bound the value of the above optimization problem , we can write the following optimization problem , which yields the number of communication blocks averaged over all the @xmath290 permutations of distinct receiver demands , denoted by @xmath291 : @xmath292 } \\sum\\limits_{\\mathcal{r}\\subseteq[k_r ] } a_{n,\\mathcal{t},\\mathcal{r}}=f,~\\forall n\\in [ n]}\\tag{p3 - 2}\\label{eq : opt_outer_start_rx_cache_sum_f_constraint}\\\\ & { \\sum\\limits_{n=1}^n \\sum\\limits_{\\mathcal{r}\\subseteq[k_r ] } \\sum\\limits_{\\substack{\\mathcal{t}\\subseteq [ k_t]:\\\\i \\in \\mathcal{t } } } a_{n,\\mathcal{t},\\mathcal{r}}\\leq m_t f , \\forall i\\in [ k_t]}\\tag{p3 - 3}\\label{eq : opt_cache_size_constraint_tx}\\\\ & \\sum\\limits_{n=1}^n \\sum\\limits_{\\mathcal{t}\\subseteq_{\\emptyset}[k_t ] } \\sum\\limits_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\j \\in \\mathcal{r } } } a_{n,\\mathcal{t},\\mathcal{r}}\\leq m_r f , \\forall j\\in [ k_r]\\tag{p3 - 4}\\label{eq : opt_cache_size_constraint_rx}\\\\ & { a_{n,\\mathcal{t},\\mathcal{r}}\\geq 0 , \\forall n\\in [ n ] , \\forall \\mathcal{t}\\subseteq_{\\emptyset}[k_t],\\forall \\mathcal{r}\\subseteq[k_r].}\\tag{p3 - 5}\\label{eq : opt_outer_end_rx_cache_sum}\\end{aligned}\\ ] ]      having the optimization problem in ( p3 ) , we now present the following lemma which provides a lower bound on the value of ( p3 ) .",
    "[ lem : opt_bound_rx ] the value of the optimization problem ( p3 ) is bounded from below by @xmath293 .",
    "see appendix [ apx : proof_lem_opt ] .",
    "since the total number of packets delivered over the channel is @xmath234 in the optimization problem ( p3 ) , lemma [ lem : opt_bound_rx ] immediately yields the following upper bound on the one - shot linear sum - dof : @xmath294    combining the above bound with the trivial bound on the one - shot linear sum - dof which is the number of receivers , @xmath3 , we have @xmath295    now , consider the following two cases :    * @xmath296 : in this case , ( [ eq : final_bound ] ) implies that @xmath297 * @xmath298 : in this case , ( [ eq : ach_dof ] ) implies that one - shot linear sum - dof of @xmath299 can be achieved , while the upper bound in ( [ eq : final_bound ] ) implies that @xmath300 .",
    "therefore , in both cases , the inner bound in ( [ eq : ach_dof ] ) is within a factor of 2 of the outer bound in ( [ eq : ach_dof ] ) , which completes the proof of the converse of theorem [ thm : main ] .",
    "in this work , we considered a wireless network setting with arbitrary numbers of transmitters and receivers , where all transmitters and receivers in the network are equipped with cache memories of specific sizes .",
    "we characterized the one - shot linear sum - dof of the network to within a gap of 2 .",
    "in particular , we showed that the one - shot linear sum - dof of the network is proportional to the aggregate cache size in the network , even though the cache of each node is isolated from all the other nodes .",
    "we presented an achievable scheme which loads the caches carefully in order to maximize the opportunity for zero - forcing the outgoing interference from the transmitters and interference cancellation due to previously - cached content at the receivers .",
    "we also demonstrated that the achievable one - shot linear sum - dof of our scheme is within a multiplicative factor of 2 of the optimal one - shot linear sum - dof by bounding the number of communication blocks required to deliver any set of requested files to the receivers using an integer programming approach .",
    "there are several interesting directions following this work .",
    "first , in this work we assumed all the links in the network to be present in the network topology .",
    "however , due to fading effects , some links between certain transmitter - receiver pairs might be absent from the network topology .",
    "it would be interesting to study what type of caching strategies are optimal in this case and to explore its connections to the index coding problem  @xcite .",
    "another direction would be to combine caching with more sophisticated interference management schemes .",
    "some initial results have been reported in @xcite , in which the authors used the replication in the cache contents at the transmitters in order to improve the system performance using the itlinq scheme @xcite .",
    "it would be interesting to study the role of transmitter and receiver caches illustrated in this work in improving the achievable system throughput that more sophisticated delivery schemes such as itlinq can provide .",
    "for any @xmath110 $ ] s.t .",
    "@xmath301 and for any @xmath302 $ ] , it is clear that the set @xmath303 is of size @xmath146 .",
    "also , for any @xmath111 $ ] s.t .",
    "@xmath304 , and for any permutation @xmath163 , the vector @xmath305 $ ] is of size @xmath147 and the vector @xmath306 $ ] is of size @xmath307 .    furthermore , note that @xmath308,\\pi[l+t_r+1:l+t_r+t_t-1]}$ ] is a subfile of the file @xmath309 requested by receiver @xmath310 .",
    "however , since @xmath311 $ ] , receiver @xmath310 has not stored the packets in this subfile in its cache and therefore , this subfile needs to be delivered to this receiver .      on the other hand",
    ", each receiver @xmath23 has already cached @xmath314 subfiles as in in its cache , and needs the rest of the subfiles of its requested file , i.e. , @xmath315 subfiles , where each subfile is further partitioned into @xmath316!}{[k_r-(t_r+t_t)]!}$ ] smaller subfiles . hence",
    ", the total number of small subfiles that need to be delivered to all the receivers is equal to @xmath317 \\left [ \\frac{t_r![k_r-(t_r+1)]!}{[k_r-(t_r+t_t)]!}\\right]=\\binom{k_t}{t_t}\\binom{k_r}{t_t+t_r } ( t_t+t_r)!,\\end{aligned}\\ ] ] which equals the total number of small subfiles in , calculated in .",
    "consequently , the set of requested subfiles which are not cached at the corresponding receivers can be partitioned as in , hence the proof is complete .      according to the constraint , each of the packets of _ order _",
    "@xmath318 , which are available at @xmath318 nodes , either on the transmitter side or the receiver side , can be scheduled with at most @xmath319 packets of the same order .",
    "therefore , for any given caching realization and set of demands , we have the lower bound @xmath320:\\\\|\\mathcal{t}|\\in[s ] } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=s-|s_t|\\\\j\\notin\\mathcal{r } } } \\frac{a_{d_j,\\mathcal{t},\\mathcal{r}}}{k_r}+\\sum_{s=1}^{k_r-1 } \\sum_{j=1}^{k_r } \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|\\in[s ] } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=s-|s_t|\\\\j\\notin\\mathcal{r } } } \\frac{a_{d_j,\\mathcal{t},\\mathcal{r}}}{s}\\\\ & \\geq \\sum_{s=1}^{k_t+k_r } \\sum_{j=1}^{k_r } \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|\\in[s ] } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=s-|s_t|\\\\j\\notin\\mathcal{r } } } \\frac{a_{d_j,\\mathcal{t},\\mathcal{r}}}{s}.{\\addtocounter{equation}{1}\\tag{\\theequation}}\\end{aligned}\\ ] ] now , denoting the objective function in by @xmath321 , we have @xmath322:\\\\|\\mathcal{t}|\\in[s ] } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=s-|s_t|\\\\j\\notin\\mathcal{r } } }   \\pi(n-1,k_r-1 ) \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & = \\frac{1}{n } ~ \\sum_{s=1}^{k_t+k_r }   \\frac{1}{s } \\sum_{j=1}^{k_r } \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|\\in[s ] } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=s-|s_t|\\\\j\\notin\\mathcal{r } } }    \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & = \\frac{1}{n } ~ \\sum_{r=1}^{k_t } \\sum_{r'=0}^{k_r }   \\frac{1}{r+r ' } \\sum_{j=1}^{k_r } \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|=r } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r'\\\\j\\notin\\mathcal{r } } }    \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & = \\frac{1}{n } ~ \\sum_{r=1}^{k_t } \\sum_{r'=0}^{k_r }   \\frac{k_r - r'}{r+r ' } \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|=r } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r ' } }    \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & = \\frac{1}{n } ~ \\sum_{r=1}^{k_t } \\sum_{r'=0}^{k_r-1 }   \\frac{b_{r , r'}}{r+r'},{\\addtocounter{equation}{1}\\tag{\\theequation}}\\label{eq : bound_avg_opt}\\end{aligned}\\ ] ] where for any @xmath323 $ ] and @xmath324 \\cup \\{0\\}$ ] , we define @xmath325:\\\\|\\mathcal{t}|=r } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r'\\\\j\\notin\\mathcal{r } } }    \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r } } = ( k_r - r ' ) \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|=r } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r ' } }    \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r}}.\\end{aligned}\\ ] ]    moreover , adding the constraint in ( [ eq : opt_cache_size_constraint_tx ] ) over all transmitters yields @xmath326 } \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\i \\in \\mathcal{t } } } a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & =   \\sum_{n=1}^n \\sum_{\\mathcal{r}\\subseteq[k_r ] } \\sum_{i=1}^{k_t } \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\i \\in \\mathcal{t } } } a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & =   \\sum_{n=1}^n \\sum_{\\mathcal{r}\\subseteq[k_r ] } \\sum_{r=1}^{k_t } r \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|=r } } a_{n,\\mathcal{t},\\mathcal{r}}.\\label{eq : adding_tx_caches}\\end{aligned}\\ ] ]    likewise , adding the constraint in ( [ eq : opt_cache_size_constraint_rx ] ) over all receivers yields @xmath327 } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\j \\in \\mathcal{r } } } a_{n,\\mathcal{t},\\mathcal{r}}\\label{eq : adding_rx_caches1}\\\\ & =   \\sum_{n=1}^n \\sum_{\\mathcal{t}\\subseteq_{\\emptyset}[k_t ] } \\sum_{j=1}^{k_r } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\j \\in \\mathcal{r } } } a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & =   \\sum_{n=1}^n \\sum_{\\mathcal{t}\\subseteq_{\\emptyset}[k_t ] } \\sum_{r'=0}^{k_r } r ' \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r ' } } a_{n,\\mathcal{t},\\mathcal{r}},\\label{eq : adding_rx_caches}\\end{aligned}\\ ] ] and from ( [ eq : adding_tx_caches ] ) and ( [ eq : adding_rx_caches ] ) , we have @xmath328 } \\sum_{r=1}^{k_t } r \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|=r } } a_{n,\\mathcal{t},\\mathcal{r } } + \\sum_{\\mathcal{t}\\subseteq[k_t ] } \\sum_{r'=0}^{k_r } r ' \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r ' } } a_{n,\\mathcal{t},\\mathcal{r } } \\right]\\\\ & = \\sum_{r=1}^{k_t } \\sum_{r'=0}^{k_r } ( r+r ' ) \\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|=r } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r ' } }    \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & \\geq \\sum_{r=1}^{k_t } \\sum_{r'=0}^{k_r-1 } \\frac{r+r'}{k_r - r ' } b_{r , r'}.\\label{eq : ineq_sbs_rx_cache}\\end{aligned}\\ ] ]      summing the above inequality over @xmath330 yields @xmath331\\\\ & \\leq    \\sqrt{\\sum_{r=1}^{k_t } \\sum_{r'=0}^{k_r-1 } \\frac{r+r'}{k_r - r ' } b_{r , r ' } } \\sqrt{\\sum_{r=1}^{k_t } \\sum_{r'=0}^{k_r-1 } \\frac{k_r - r'}{r+r ' } b_{r , r'}}\\label{eq:2nd_cauchy}\\\\ & \\leq \\sqrt{(k_t m_t + k_r m_r ) f } \\sqrt{\\sum_{r=1}^{k_t } \\sum_{r'=0}^{k_r-1 } \\frac{k_r - r'}{r+r ' } b_{r , r'}},\\label{eq : total_cache_plug_in}\\end{aligned}\\ ] ] where in we have invoked the cauchy - schwarz inequality again and follows from ( [ eq : ineq_sbs_rx_cache ] ) . on the other hand , we have @xmath332:\\\\|\\mathcal{t}|=r } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r'\\\\j\\notin\\mathcal{r } } }    \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & = \\sum_{r=1}^{k_t } \\sum_{r'=0}^{k_r } \\sum_{j=1}^{k_r } \\left[\\left(\\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|=r } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r ' } }    \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r}}\\right)-\\left(\\sum_{\\substack{\\mathcal{t}\\subseteq[k_t]:\\\\|\\mathcal{t}|=r } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\|\\mathcal{r}|=r'\\\\j\\in\\mathcal{r } } }    \\sum_{n=1}^n a_{n,\\mathcal{t},\\mathcal{r}}\\right)\\right]\\\\ & = k_r \\left(\\sum_{n=1}^n \\sum_{\\substack{\\mathcal{t}\\subseteq_{\\emptyset}[k_t ] } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r ] } }     a_{n,\\mathcal{t},\\mathcal{r}}\\right)- \\sum_{j=1}^{k_r } \\sum_{n=1}^n \\sum_{\\substack{\\mathcal{t}\\subseteq_{\\emptyset}[k_t ] } } \\sum_{\\substack{\\mathcal{r}\\subseteq[k_r]:\\\\j\\in\\mathcal{r } } }     a_{n,\\mathcal{t},\\mathcal{r}}\\\\ & \\geq k_r(n - m_r)f,\\label{eq : whole_uncached_lib}\\end{aligned}\\ ] ] where the inequality is due to and .",
    "therefore , we can continue to bound the objective function in as @xmath333 where and follow from and , respectively .",
    "this completes the proof ."
  ],
  "abstract_text": [
    "<S> we consider a system , comprising a library of @xmath0 files ( e.g. , movies ) and a wireless network with @xmath1 transmitters , each equipped with a local cache of size of @xmath2 files , and @xmath3 receivers , each equipped with a local cache of size of @xmath4 files . </S>",
    "<S> each receiver will ask for one of the @xmath0 files in the library , which needs to be delivered . the objective is to design the cache placement ( without prior knowledge of receivers future requests ) and the communication scheme to maximize the throughput of the delivery . in this setting , we show that the sum degrees - of - freedom ( sum - dof ) of @xmath5 is achievable , and this is within a factor of 2 of the optimum , under one - shot linear schemes . </S>",
    "<S> this result shows that ( i ) the one - shot sum - dof scales _ linearly _ with the _ aggregate cache size in the network _ </S>",
    "<S> ( i.e. , the cumulative memory available at _ all nodes _ ) , ( ii ) the transmitters caches and receivers caches contribute equally in the one - shot sum - dof , and ( iii ) caching can offer a throughput gain that scales linearly with the size of the network .    to prove the result </S>",
    "<S> , we propose an achievable scheme that exploits the redundancy of the content at transmitters caches to cooperatively zero - force some outgoing interference , and availability of the unintended content at the receivers caches to cancel ( subtract ) some of the incoming interference . </S>",
    "<S> we develop a particular pattern for cache placement that maximizes the overall gains of cache - aided transmit and receive interference cancellations . for the converse </S>",
    "<S> , we present an integer optimization problem which minimizes the number of communication blocks needed to deliver any set of requested files to the receivers . </S>",
    "<S> we then provide a lower bound on the value of this optimization problem , hence leading to an upper bound on the linear one - shot sum - dof of the network , which is within a factor of 2 of the achievable sum - dof . </S>"
  ]
}