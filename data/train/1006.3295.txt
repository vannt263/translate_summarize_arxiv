{
  "article_text": [
    "this paper is motivated by the study of the nonhomogeneous linear recursion @xmath6 where @xmath2 is a nonnegative random vector with @xmath7 , @xmath8 , @xmath9 , and @xmath10 is a sequence of iid random variables , independent of @xmath2 , having the same distribution as @xmath0 .",
    "this recursion appeared recently in the stochastic analysis of google s pagerank algorithm , see @xcite and the references therein for the latest work in the area .",
    "these types of weighted recursions , also studied in the literature on weighted branching processes @xcite and branching random walks @xcite , are found in the probabilistic analysis of other algorithms as well @xcite , e.g. , quicksort algorithm @xcite .    in order to study the preceding recursion in its full generality we extend the implicit renewal theory of goldie @xcite to cover recursions on trees .",
    "the extension of goldie s theorem is presented in theorem  [ t.newgoldie ] of section  [ s.renewal ] .",
    "one of the observations that allows this extension is that an appropriately constructed measure on a weighted branching tree is a renewal measure , see lemma [ l.renewalmeasure ] and equation . in the remainder of the paper",
    "we apply the newly developed framework to analyze a number of linear and non - linear stochastic recursions on trees , starting with .",
    "note that the majority of the work in the rest of the paper goes into the application of the main theorem to specific problems .    in this regard , in section  [ s.linearrec ]",
    ", we first construct an explicit solution to on a weighted branching tree and then provide sufficient conditions for the finiteness of moments and the uniqueness of this solution in lemmas [ l.moments_r ] and [ l.convergence ] , respectively .",
    "furthermore , it is worth noting that our moment estimates are explicit , see lemma  [ l.generalmoment ] , which may be of independent interest .",
    "then , the main result , which characterizes the power - tail behavior of @xmath0 is presented in theorem [ t.linearrecursion ] .",
    "in addition , for integer power exponent ( @xmath11 ) the asymptotic tail behavior can be explicitly computed as stated in corollary [ c.explicit ] .",
    "furthermore , for non integer @xmath12 , lemma [ l.alpha_moments ] yields an explicit bound on the tail behavior of @xmath0 .",
    "related work in the literature of weighted branching processes ( wbps ) for the case when @xmath13 and @xmath14 are nonnegative deterministic constants can be found in @xcite ( see theorem 5 ) , and more recently , for real valued constants , in @xcite .",
    "however , these deterministic assumptions fall outside of the scope of this paper ; for more details see the remarks after theorem  [ t.linearrecursion ] in section  [ ss.mainlinear ] .",
    "next , we show how our technique can be applied to study the tail asymptotics of the solution to the critical , @xmath15 = 1 $ ] , homogeneous linear equation @xmath16 where @xmath17 is a nonnegative random vector with @xmath7 and @xmath18 is a sequence of iid random variables independent of @xmath17 having the same distribution as @xmath0 .",
    "this type of recursion has been studied to a great extent under a variety of names , including branching random walks and multiplicative cascades .",
    "our work is more closely related to the results of @xcite and @xcite , where the conditions for power - tail asymptotics of the distribution of @xmath0 with power exponent @xmath19 were derived . in theorem [ t.linearhomog ] of section [ ss.mainlinear ]",
    "we provide an alternative derivation of theorem 2.2 in @xcite and proposition 7 in @xcite .",
    "furthermore , we note that our method yields a more explicit characterization of the power - tail proportionality constant , see corollary  [ c.explicithom ] . for the full description of the set of solutions to see the very recent work in @xcite . for additional references on weighted branching processes and multiplicative cascades see @xcite and the references therein . for earlier historical references see @xcite .    as an additional illustration of the newly developed framework , in section [ s.maxrec ] we study the recursion @xmath20 where @xmath2 is a nonnegative random vector with @xmath7 , @xmath21 and @xmath4 is a sequence of iid random variables independent of @xmath2 having the same distribution as @xmath0 .",
    "we characterize the tail behavior of @xmath22 in theorem [ t.maximumrecursion ] . similarly to the homogeneous linear case , this recursion was previously studied in @xcite under the assumption that @xmath23 , @xmath13 , and the @xmath24 are real valued deterministic constants .",
    "the more closely related case of @xmath23 and @xmath25 being random was studied earlier in @xcite .",
    "furthermore , these max - type stochastic recursions appear in a wide variety of applications , ranging from the average case analysis of algorithms to statistical physics ; see @xcite for a recent survey .",
    "we conclude the paper with a brief discussion of other non - linear recursions that could be studied using the developed techniques , including the solution to @xmath26 the majority of the proofs are postponed to section  [ s.proofs ] .",
    "first we construct a random tree @xmath27 .",
    "we use the notation @xmath28 to denote the root node of @xmath27 , and @xmath29 , @xmath30 , to denote the set of all individuals in the @xmath31th generation of @xmath27 , @xmath32 .",
    "let @xmath33 be the number of individuals in the @xmath31th generation , that is , @xmath34 , where @xmath35 denotes the cardinality of a set ; in particular , @xmath36 .",
    "next , let @xmath37 be the set of positive integers and let @xmath38 be the set of all finite sequences @xmath39 , where by convention @xmath40 contains the null sequence @xmath28 . to ease the exposition , for a sequence @xmath41 we write @xmath42 , provided @xmath43 , and @xmath44 to denote the index truncation at level @xmath31 , @xmath30 .",
    "also , for @xmath45 we simply use the notation @xmath46 , that is , without the parenthesis . similarly , for @xmath47 we will use @xmath48 to denote the index concatenation operation , if @xmath49 , then @xmath50 .",
    "we iteratively construct the tree as follows .",
    "let @xmath51 be the number of individuals born to the root node @xmath28 , @xmath52 , and let @xmath53 be iid copies of @xmath51 .",
    "define now @xmath54 it follows that the number of individuals @xmath34 in the @xmath31th generation , @xmath55 , satisfies the branching recursion @xmath56    now , we construct the weighted branching tree @xmath57 as follows .",
    "the root node @xmath28 is assigned a vector @xmath58 with @xmath7 and @xmath59 ; @xmath51 determines the number of nodes in the first generation of @xmath27 according to .",
    "each node in the first generation is then assigned an iid copy @xmath60 of the root vector and the @xmath61 are used to define the second generation in @xmath27 according to .",
    "in general , for @xmath62 , to each node @xmath63 , we assign an iid copy @xmath64 of the root vector and construct @xmath65 ; the vectors @xmath66 , @xmath63 are chosen independently of all the previously assigned vectors @xmath67 , @xmath68 . for each node in @xmath57",
    "we also define the weight @xmath69 via the recursion @xmath70 where @xmath71 is the weight of the root node .",
    "note that the weight @xmath72 is equal to the product of all the weights @xmath73 along the branch leading to node @xmath74 , as depicted in figure [ f.tree ] . in some places ,",
    "e.g. in the following section , the value of @xmath75 may be of no importance , and thus we will consider a weighted branching tree defined by the smaller vector @xmath17 .",
    "this tree can be obtained form @xmath57 by simply disregarding the values for @xmath76 and is denoted by @xmath77 .",
    "( 430,160)(0,0 ) ( 0,0 ) ( 125,150)@xmath78 ( 69,83)@xmath79 ( 131,83)@xmath80 ( 219,83)@xmath81 ( 22,17)@xmath82 ( 78,17)@xmath83 ( 126,17)@xmath84 ( 162,17)@xmath85 ( 213,17)@xmath86 ( 268,17)@xmath87 ( 350,150)@xmath36 ( 350,83)@xmath88 ( 350,17)@xmath89    studying the tail behavior of the solutions to recursions and fixed point equations embedded in this weighted branching tree is the objective of this paper .",
    "in this section we present an extension of goldie s implicit renewal theorem @xcite to weighted branching trees . the observation that facilitates this generalization is the following lemma which shows that a certain measure on a tree is actually a product measure ; a similar measure was used in a different context in @xcite . its proof is given in section  [ ss.implicitproofs ] for completeness . throughout the paper we use the standard convention @xmath90 for all @xmath91 .    [ l.renewalmeasure ]",
    "let @xmath92 be the weighted branching tree defined by the nonnegative vector @xmath17 , where @xmath7 .",
    "for any @xmath93 and @xmath94 , let @xmath95 .",
    "for @xmath91 define the measure @xmath96 , \\quad n = 1 , 2 , \\dots,\\ ] ] and let @xmath97 .",
    "suppose that there exists @xmath98 with @xmath99 such that the measure @xmath100 is nonarithmetic , @xmath101 ~ < ~\\infty$ ] and @xmath102 = 1 $ ] .",
    "then , @xmath103 is a nonarithmetic probability measure on @xmath104 that places no mass at @xmath105 and has mean @xmath106 .\\ ] ] furthermore , @xmath107 , where @xmath108 denotes the @xmath31th convolution of @xmath109 with itself .",
    "we now present a generalization of goldie s implicit renewal theorem @xcite that will enable the analysis of recursions on weighted branching trees . note that except for the independence assumption , the random variable @xmath0 and the vector @xmath17 are arbitrary , and therefore the applicability of this theorem goes beyond the recursions that we study here . throughout the paper we use @xmath110 as @xmath111 to denote @xmath112 .",
    "[ t.newgoldie ] let @xmath17 be a nonnegative random vector , where @xmath7 .",
    "suppose that there exists @xmath98 with @xmath113 such that the measure @xmath100 is nonarithmetic .",
    "assume further that @xmath114 < \\infty$ ] , @xmath115 = 1 $ ] , @xmath116 < \\infty$ ] for some @xmath117 , and that @xmath0 is independent of @xmath17 with @xmath118 < \\infty$ ] for any @xmath119 . if @xmath120 \\right| t^{\\alpha-1 } dt < \\infty,\\ ] ] then @xmath121 where @xmath122 is given by @xmath123 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p(r > v ) - e\\left [ \\sum_{j=1}^{n } \\indicator(c_{j } r > v ) \\right ]     \\right ) dv .\\end{aligned}\\ ] ]    remarks : ( i ) as pointed out in @xcite , the statement of the theorem only has content when @xmath0 has infinite moment of order @xmath12 , since otherwise the constant @xmath124 is zero .",
    "( ii ) similarly as in @xcite , this theorem can be generalized to incorporate negative weights @xmath24 at the expense of additional technical complications .",
    "however , when the @xmath125 and @xmath0 is real - valued , one can use exactly the same proof to derive the asymptotics of @xmath126 ; we omit the statement here since our applications do not require it .",
    "( iii ) when the @xmath127 are lattice valued , a similar version of the theorem can be derived by using the corresponding renewal theorem for lattice random walks .",
    "( iv ) it appears , as noted in @xcite , that some of the early ideas of applying renewal theory to study the power tail asymptotics of autoregressive processes ( perpetuities ) is due to @xcite and @xcite . the proof given below follows the corresponding proof in @xcite .",
    "let @xmath92 be the weighted branching tree defined by the nonnegative vector @xmath17 . for each @xmath94 and",
    "all @xmath128 define @xmath129 ; note that @xmath130 is independent of @xmath131 but not of @xmath132 for any @xmath133 . also note that @xmath134 since @xmath94",
    "let @xmath135 , @xmath136 , denote the @xmath137-algebra generated by @xmath138 , and let @xmath139 , @xmath140 .",
    "assume also that @xmath0 is independent of the entire weighted tree , @xmath92 .",
    "then , for any @xmath141 , we can write @xmath142 via a telescoping sum as follows ( note that all the expectations in are finite by markov s inequality and ) @xmath143 - e\\left [ \\sum_{({\\bf i}|k+1 ) \\in a_{k+1 } } \\indicator({\\pi}_{{\\bf i}|k+1 } r >",
    "e^t ) \\right ]   \\right ) \\label{eq : telescoping } \\\\ & \\hspace{5 mm } + e\\left [ \\sum_{({\\bf i}|n ) \\in a_n } \\indicator({\\pi}_{{\\bf i}|n } r > e^t ) \\right ] \\notag \\\\ & = \\sum_{k=0}^{n-1 }   e\\left [ \\sum_{({\\bf i}|k ) \\in a_{k } } \\left ( \\indicator ( { \\pi}_{{\\bf i}|k } r >",
    "e^t ) -   \\sum_{j=1}^{n_{{\\bf i}|k } } \\indicator({\\pi}_{{\\bf i}|k } c_{({\\bf i}|k , j ) } r > e^t ) \\right ) \\right ]   \\notag \\\\",
    "& \\hspace{5 mm } + e\\left [ \\sum_{({\\bf i}|n ) \\in a_n } \\indicator({\\pi}_{{\\bf i}|n } r > e^t ) \\right ] \\notag \\\\ & = \\sum_{k=0}^{n-1 } e\\left [",
    "\\sum_{({\\bf i}|k ) \\in a_{k } } e\\left [ \\left .",
    "\\indicator ( r > e^{t - v_{{\\bf i}|k } } ) -   \\sum_{j=1}^{n_{{\\bf i}|k } } \\indicator ( c_{({\\bf i}|k , j ) } r > e^{t - v_{{\\bf i}|k } } )   \\right| \\mathcal{f}_k   \\right ] \\right ]   \\notag \\\\ & \\hspace{5 mm } + e\\left [ \\sum_{({\\bf i}|n ) \\in a_n } \\indicator({\\pi}_{{\\bf i}|n } r >",
    "e^t ) \\right ] .\\end{aligned}\\ ] ]    now , define the measures @xmath144 according to lemma [ l.renewalmeasure ] and let @xmath145     \\right),\\ ] ] @xmath146.\\ ] ]    recall that @xmath0 and @xmath147 are independent of @xmath135 , from where it follows that @xmath148   = e^{\\alpha(v_{{\\bf i}|k}-t ) } g\\left ( t - v_{{\\bf i}|k }   \\right).\\ ] ] then , for any @xmath141 and @xmath93 , @xmath149 + \\delta_n(t ) = ( g*\\nu_{n-1})(t ) + \\delta_n(t).\\end{aligned}\\ ] ]    next , define the operator @xmath150 and note that @xmath151    now , we will show that one can let @xmath152 in the preceding identity . to this end , let @xmath153 , and note that by lemma [ l.renewalmeasure ] @xmath103 is a nonarithmetic probability measure on @xmath104 that places no mass at @xmath105 and has mean , @xmath154 > 0 .\\ ] ] moreover , by lemma [ l.renewalmeasure ] , @xmath155    = \\sum_{k=0}^\\infty \\eta^{*k}(dt)\\ ] ] is its renewal measure .",
    "since @xmath156 , then @xmath157 for all @xmath158 whenever @xmath159 is directly riemann integrable . by",
    "we know that @xmath160 , so by lemma 9.1 from @xcite , @xmath161 is directly riemann integrable , resulting in @xmath162 for all @xmath158 .",
    "thus , @xmath163   < \\infty$ ] , which implies that @xmath164 $ ] exists and , by fubini s theorem , @xmath165   \\\\ & = \\sum_{k=0}^\\infty e\\left [ \\sum_{({\\bf i}|k ) \\in a_{k } } e^{\\alpha v_{{\\bf i}|k } } \\breve{g}(t - v_{{\\bf i}|k } ) \\right ]   = \\lim_{n\\to \\infty }   ( \\breve{g}*\\nu_n)(t).\\end{aligned}\\ ] ]    to see that @xmath166 as @xmath152 for all fixed @xmath158 , note that from the assumptions @xmath167",
    "< \\infty$ ] , @xmath115 = 1 $ ] , and @xmath116 < \\infty$ ] for some @xmath117 , there exists @xmath168 such that @xmath169 < 1 $ ] ( by convexity ) .",
    "then , for such @xmath170 , @xmath171   du \\notag \\\\ & \\leq e^{(\\alpha-\\beta)t }   e\\left [ \\sum_{({\\bf i}|n ) \\in a_n }   \\int_{-\\infty}^t e^ { \\beta u } \\indicator\\left({\\pi}_{{\\bf i}|n }   r > e^u",
    "\\right )   du \\ , \\right ]   \\notag \\\\ & = e^{(\\alpha-\\beta ) t }   e\\left [ \\sum_{({\\bf i}|n ) \\in a_n }   \\int_{-\\infty}^{\\min\\{t , \\log({\\pi}_{{\\bf i}|n } r)\\ } }   e^{\\beta u }    du \\ , \\right ]   \\notag \\\\ & \\leq \\frac{e^{(\\alpha-\\beta ) t}}{\\beta } e\\left [ \\sum_{({\\bf i}|n ) \\in a_n }    ( { \\pi}_{{\\bf i}|n } r)^{\\beta }    \\right ]   .",
    "\\label{eq : delta_error}\\end{aligned}\\ ] ] it remains to show that the expectation in converges to zero as @xmath152 .",
    "first note that from the independence of @xmath0 and @xmath77 , @xmath172   = e[r^\\beta ]   e\\left [ \\sum_{({\\bf i}|n ) \\in a_n }    ( { \\pi}_{{\\bf i}|n})^{\\beta }    \\right],\\ ] ] where @xmath118 < \\infty$ ] , for @xmath173 . for",
    "the expectation involving @xmath174 condition on @xmath175 and use the independence of @xmath176 from @xmath175 as follows @xmath177 & = e\\left [    \\sum_{({\\bf i}|n-1 ) \\in a_{n-1 } } e\\left [ \\left .",
    "\\sum_{j=1}^{n_{{\\bf i}|n-1 } }    ( { \\pi}_{{\\bf i}|n-1})^{\\beta } c_{({\\bf i}|n-1,j)}^{\\beta } \\right| \\mathcal{f}_{n-1 } \\right ] \\right ] \\notag \\\\ & = e\\left [    \\sum_{({\\bf i}|n-1 ) \\in a_{n-1 } } ( { \\pi}_{{\\bf i}|n-1})^{\\beta } e\\left [ \\left .",
    "\\sum_{j=1}^{n_{{\\bf i}|n-1 } }     c_{({\\bf i}|n-1,j)}^{\\beta } \\right| \\mathcal{f}_{n-1 } \\right ] \\right ] \\notag \\\\ & = e\\left [   \\sum_{j=1}^n     c_j^{\\beta }   \\right ]   e\\left [    \\sum_{({\\bf i}|n-1 ) \\in a_{n-1 } } ( { \\pi}_{{\\bf i}|n-1})^{\\beta } \\right ] \\notag \\\\ & = \\left ( e\\left [      \\sum_{j=1}^{n }   c_{j}^{\\beta }    \\right ] \\right)^n",
    "\\qquad \\text{(iterating $ n-1 $ times)}. \\label{eq : pimoments}\\end{aligned}\\ ] ] since @xmath178 < 1 $ ] , then the above converges to zero as @xmath152 .",
    "hence , the preceding arguments allow us to pass @xmath152 in , and obtain @xmath179    now , by the key renewal theorem for two - sided random walks , see theorem 4.2 in @xcite , @xmath180 clearly , @xmath181 since the left - hand side of the preceding equation is positive , and thus , by lemma 9.3 in @xcite , @xmath182    finally , @xmath183",
    "\\right ) dt \\\\ & = \\frac{1 } { \\mu } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p(r > v ) - e\\left [ \\sum_{j=1}^{n } \\indicator(c_{j } r > v ) \\right ]     \\right ) dv .",
    "\\end{aligned}\\ ] ]",
    "motivated by the information ranking problem on the internet , e.g. google s pagerank algorithm @xcite , in this section we apply the implicit renewal theory for trees developed in the previous section to the following linear recursion : @xmath185 where @xmath186 is a nonnegative random vector with @xmath7 , @xmath187 , and @xmath4 is a sequence of iid random variables independent of @xmath2 having the same distribution as @xmath0 .",
    "note that the power tail of @xmath0 in the critical homogeneous case @xmath188 was previously studied in @xcite and @xcite . in section  [ ss.homogeneous ]",
    "we will give an alternative derivation of those results using our method and will provide pointers to the appropriate literature .",
    "as for the nonhomogeneous case , the first result we need to establish is the existence and finiteness of a solution to . for the purpose of existence we will provide an explicit construction of the solution @xmath0 to on a tree . note that such constructed @xmath0 will be the main object of study of this section .",
    "recall that throughout the paper the convention is to denote the random vector associated to the root node @xmath28 by @xmath189 .",
    "we now define the process @xmath190 on the weighted branching tree @xmath191 , as constructed in section [ s.modeldescription ] .",
    "define the process @xmath192 according to @xmath193 that is , @xmath194 is the sum of the weights of all the nodes on the tree up to the @xmath31th generation .",
    "it is not hard to see that @xmath194 satisfies the recursion @xmath195 where @xmath196 are independent copies of @xmath197 corresponding to the tree starting with individual @xmath198 in the first generation and ending on the @xmath31th generation ; note that @xmath199 .",
    "similarly , since the tree structure repeats itself after the first generation , @xmath200 satisfies @xmath201 where @xmath202 is a sequence of iid random variables independent of @xmath17 and having the same distribution as @xmath203 .",
    "next , define the random variable @xmath0 according to @xmath204 where the limit is properly defined by and monotonicity .",
    "hence , it is easy to verify , by applying monotone convergence in , that @xmath0 must solve @xmath205 where @xmath206 are iid , have the same distribution as @xmath0 , and are independent of @xmath2 .",
    "the derivation provided above implies in particular the existence of a solution in distribution to .",
    "moreover , under additional technical conditions , @xmath0 is the unique solution under iterations as we will define and show in the following section .",
    "the constructed @xmath0 , as defined in , is the main object of study in the remainder of this section .      in this section",
    "we derive estimates for the moments of @xmath200 and @xmath0 .",
    "we start by stating a lemma about the moments of a sum of random variables .",
    "the proofs of lemmas [ l.alpha_moments ] , [ l.momentsmaller_1 ] and [ l.generalmoment ] are given in section  [ ss.momentsproofs ] .",
    "[ l.alpha_moments ] for any @xmath207 let @xmath208 be a sequence of nonnegative random variables and let @xmath209 be a sequence of nonnegative iid random variables , independent of the @xmath24 , having the same distribution as @xmath210 . for @xmath211 set @xmath212 , and if @xmath213 assume that @xmath214 a.s .",
    "then , @xmath215 \\leq \\left ( e\\left [ y^{p-1 } \\right ] \\right)^{\\beta/(p-1 ) } e\\left [ \\left(\\sum_{i=1}^k c_i \\right)^\\beta   \\right].\\ ] ]    remark : note that the preceding lemma does not exclude the case when @xmath216 = \\infty$ ] but @xmath217 < \\infty$ ] .",
    "we now give estimates for the @xmath170-moments of @xmath200 for @xmath218 $ ] and @xmath211 in lemmas  [ l.momentsmaller_1 ] and [ l.generalmoment ] , respectively . throughout the rest of the paper define @xmath219 $ ] for any @xmath220 , and @xmath221 .",
    "[ l.momentsmaller_1 ] for @xmath222 and all @xmath30 , @xmath223 \\leq   e[q^\\beta ] \\rho_\\beta^{n}.\\ ] ]    [ l.generalmoment ] for @xmath211 suppose @xmath224 < \\infty$ ] , @xmath225 < \\infty$ ] , and @xmath226 .",
    "then , there exists a constant @xmath227 such that for all @xmath30 , @xmath223 \\leq k_\\beta ( \\rho \\vee \\rho_\\beta   ) ^{n}.\\ ] ]    now we are ready to establish the finiteness of moments of the solution @xmath0 given by in section [ s.linearrec ] .",
    "the proof of this lemma uses well known contraction arguments , but for completeness we provide the details below .",
    "[ l.moments_r ] assume that @xmath224 < \\infty$ ] for some @xmath220 .",
    "in addition , suppose that either ( i ) @xmath228 if @xmath229 , or ( ii ) @xmath230 and @xmath231 < \\infty$ ] if @xmath232 .",
    "then , @xmath233 < \\infty$ ] for all @xmath234 , and in particular , @xmath235 a.s . moreover , if @xmath232 , @xmath236 , where @xmath237 stands for convergence in @xmath238 norm .",
    "remark : it is interesting to observe that for @xmath211 the conditions @xmath228 and @xmath225 < \\infty$ ] are consistent with theorem 3.1 in @xcite , proposition 4 in @xcite and theorem 2.1 in @xcite , which give the conditions for the finiteness of the @xmath170-moment of the solution to the related critical ( @xmath239 ) homogeneous ( @xmath23 ) equation .",
    "let @xmath240 then by lemmas [ l.momentsmaller_1 ] and [ l.generalmoment ] , @xmath241 \\leq k \\eta^n\\ ] ] for some @xmath242 .",
    "suppose @xmath232 , then , by monotone convergence and minkowski s inequality , @xmath243 & = e\\left [ \\lim_{n\\to\\infty } \\left(\\sum_{k=0}^n w_k \\right)^\\beta   \\right ] = \\lim_{n\\to \\infty } e\\left [ \\left(\\sum_{k=0}^n w_k\\right)^\\beta   \\right ] \\\\",
    "& \\leq \\lim_{n\\to\\infty } \\left ( \\sum_{k=0}^n \\left ( e[w_k^\\beta ] \\right)^{1/\\beta } \\right)^\\beta \\leq k \\left ( \\sum_{k=0}^\\infty \\eta^{k/\\beta }    \\right)^\\beta < \\infty.\\end{aligned}\\ ] ] this implies that @xmath235 a.s .",
    "when @xmath244 use the inequality @xmath245 for any @xmath246 instead of minkowski s inequality .",
    "furthermore , for any @xmath247 , @xmath248 = e\\left [ ( r^\\beta)^{\\gamma/\\beta}\\right ] \\leq \\left(e[r^\\beta ] \\right)^{\\gamma/\\beta } < \\infty.\\ ] ]    that @xmath236 whenever @xmath232 follows from noting that @xmath249 $ ] @xmath250 $ ] and applying the same arguments used above to obtain the bound @xmath249 \\leq k \\eta^{n+1}/(1 - \\eta^{1/\\beta})^\\beta$ ] .",
    "next , we show that under some technical conditions , the iteration of recursion results in a process that converges in distribution to @xmath0 for any initial condition @xmath251 . to this end , consider a weighted branching tree @xmath57 , as defined in section [ s.modeldescription ] .",
    "now , define @xmath252 where @xmath197 is given by , @xmath253 and @xmath254 are iid copies of an initial value @xmath251 , independent of the entire weighted tree @xmath57 .",
    "it follows from and that , for @xmath30 , @xmath255 where @xmath256 are independent copies of @xmath197 corresponding to the tree starting with individual @xmath198 in the first generation and ending on the @xmath31th generation , and @xmath257 is the set of all nodes in the @xmath258th generation that are descendants of individual @xmath198 in the first generation .",
    "it follows that @xmath259 where @xmath260 are the expressions inside the parenthesis in .",
    "clearly , @xmath260 are iid copies of @xmath261 , thus we show that @xmath261 is equal in distribution to the process derived by iterating with an initial condition @xmath251 .",
    "the following lemma shows that @xmath262 for any initial condition @xmath251 satisfying a moment assumption , where @xmath263 denotes convergence in distribution .",
    "[ l.convergence ] for any initial condition @xmath264 , if @xmath224 , e[(r_0^*)^\\beta ] < \\infty$ ] and @xmath219 < 1 $ ] for some @xmath222 , then @xmath265 with @xmath118 < \\infty$ ] . furthermore , under these assumptions",
    ", the distribution of @xmath0 is the unique solution with finite @xmath170-moment to recursion .    since @xmath266 a.s .",
    ", the result will follow from slutsky s theorem ( see theorem 25.4 , p. 332 in @xcite ) once we show that @xmath267 . to this end , note that @xmath268 , as defined by , is the same as @xmath200 if we substitute the @xmath269 by the @xmath270 .",
    "then , for every @xmath271 we have that @xmath272 \\\\ & \\leq \\epsilon^{-\\beta } \\rho_\\beta^n e[(r_0^*)^\\beta ] \\qquad \\text{(by lemma \\ref{l.momentsmaller_1 } ) } .\\end{aligned}\\ ] ] since by assumption the right - hand side converges to zero as @xmath152 , then @xmath262 .",
    "furthermore , @xmath118",
    "< \\infty$ ] by lemma [ l.moments_r ] . clearly , under the assumptions , the distribution of @xmath0 represents the unique solution to , since any other possible solution with finite @xmath170-moment would have to converge to the same limit .",
    "remarks : ( i ) note that when @xmath273 < 1 $ ] the branching tree is a.s .",
    "finite and no conditions on the @xmath24 are necessary for @xmath235 a.s .",
    "this corresponds to the second condition in theorem 1 of @xcite .",
    "( ii ) in view of the same theorem from @xcite , one could possibly establish the convergence of @xmath274 under milder conditions .",
    "however , since in this paper we only study the power tails of @xmath0 , the assumptions of lemma [ l.convergence ] are not restrictive .",
    "( iii ) note that if @xmath102 = 1 $ ] with @xmath275 $ ] , then there might not be a @xmath173 for which @xmath276 < 1 $ ] , e.g. , the case of deterministic @xmath277 s that was studied in @xcite .",
    "we now characterize the tail behavior of the distribution of the solution @xmath0 to the nonhomogeneous equation , as defined by .",
    "[ t.linearrecursion ]",
    "let @xmath2 be a nonnegative random vector , with @xmath7 , @xmath59 and @xmath0 be the solution to given by .",
    "suppose that there exists @xmath98 with @xmath113 such that the measure @xmath278 is nonarithmetic , and that for some @xmath91 , @xmath279 < \\infty$ ] , @xmath280 < \\infty$ ] and @xmath281 = 1 $ ] .",
    "in addition , assume    1 .",
    "@xmath15 < 1 $ ] and @xmath282 < \\infty$ ] , if @xmath283 ; or , 2 .",
    "@xmath284 < \\infty$ ] for some @xmath285 , if @xmath286 .    then , @xmath121 where @xmath122 is given by @xmath287 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p(r > v ) - e\\left [ \\sum_{i=1}^{n } \\indicator(c_{i } r >",
    "v ) \\right ]     \\right ) dv \\\\ & = \\frac{e\\left [ \\left ( \\sum_{i=1}^n c_i r_i + q \\right)^\\alpha - \\sum_{i=1}^n ( c_i r_i ) ^\\alpha \\right]}{\\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log c_i   \\right ] } .\\end{aligned}\\ ] ]    remarks : ( i ) the nonhomogeneous equation has been previously studied for the special case when @xmath75 and the @xmath24 are deterministic constants . in particular , theorem 5 of @xcite analyzes the solutions to when @xmath75 and the @xmath24 are nonnegative deterministic constants , which , when @xmath288 , @xmath289 , implies that @xmath290 for all @xmath291 and @xmath292 , falling outside of the scope of this paper .",
    "the solutions to for the case when @xmath75 and the @xmath277 s are real valued deterministic constants were analyzed in @xcite . for the very recent work ( published on arxiv after the first draft of this paper ) that characterizes all the solutions to for @xmath75 and @xmath24",
    "random see @xcite .",
    "( ii ) when @xmath283 , the condition @xmath282",
    "< \\infty$ ] is needed to ensure that the tail of @xmath0 is not dominated by @xmath51 .",
    "in particular , if the @xmath24 are iid and independent of @xmath51 , the condition reduces to @xmath293 < \\infty$ ] since @xmath294 < \\infty$ ] is implied by the other conditions ; see theorems 4.2 and 5.4 in @xcite . furthermore , when @xmath286 the condition @xmath282",
    "< \\infty$ ] is redundant since @xmath282 \\leq e\\left [   \\sum_{i=1}^n c_i^\\alpha \\right ] = 1 $ ] , and the additional condition @xmath295 < \\infty$ ] is needed .",
    "when the @xmath296 are iid and independent of @xmath51 , the latter condition reduces to @xmath297 < \\infty$ ] ( given the other assumptions ) , which is consistent with theorem 4.2 in @xcite .",
    "( iii ) note that the second expression for @xmath124 is more suitable for actually computing it , especially in the case of @xmath12 being an integer , as will be stated in the forthcoming corollary  [ c.explicit ] .",
    "when @xmath19 is not an integer , we can derive an explicit upper bound on @xmath124 by using lemma  [ l.max_approx ] .",
    "regarding the lower bound , the elementary inequality @xmath298 for @xmath299 and @xmath300 , yields @xmath301}{\\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log c_i   \\right ] } > 0.\\ ] ] similarly , for @xmath302 , using the corresponding inequality @xmath303 for @xmath304 , @xmath300 , we obtain @xmath305}/{\\left(\\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log",
    "c_i   \\right ] \\right)}.$ ] ( iv ) let us also observe that the solution @xmath0 , given by , to equation may be a constant ( non power law ) @xmath306 when @xmath307 .",
    "however , similarly as in remark ( i ) , such a solution is excluded from the theorem since @xmath308 implies @xmath309\\le 0 , \\alpha>0 $ ] .    before proceeding with the proof of theorem [ t.linearrecursion ] ,",
    "we need the following two technical results ; their proofs are given in section [ ss.linearproofs ] .",
    "lemma [ l.max_approx ] below will also be used in subsequent sections for other recursions . with some abuse of notation",
    ", we will use throughout the paper @xmath310 to denote @xmath311 in case @xmath13 .",
    "[ l.max_approx ] suppose @xmath17 is a nonnegative random vector , with @xmath7 and let @xmath10 be a sequence of iid nonnegative random variables independent of @xmath17 having the same distribution as @xmath0 . for @xmath312 ,",
    "suppose that @xmath313 a.s . and",
    "@xmath118 < \\infty$ ] for any @xmath173 . furthermore , assume that @xmath284 < \\infty$ ] for some @xmath285 . then , @xmath314 - p\\left ( \\max_{1\\leq i \\leq n } c_i r_i > t \\right ) \\right )   t^{\\alpha -1 } \\ , dt \\\\ & = \\frac{1}{\\alpha } e \\left [   \\sum_{i=1}^n   \\left(c_i r_i \\right)^\\alpha - \\left ( \\max_{1\\leq i \\leq n } c_i r_i \\right)^\\alpha    \\right ]   < \\infty.\\end{aligned}\\ ] ]    [ l.extraq ] let @xmath2 be a nonnegative vector with @xmath7 and let @xmath315 be a sequence of iid random variables , independent of @xmath2 .",
    "suppose that for some @xmath283 we have @xmath279 < \\infty$ ] , @xmath282 < \\infty$ ] , @xmath118 < \\infty$ ] for any @xmath173 , and @xmath316 a.s .",
    "then @xmath317   < \\infty.\\ ] ]    by lemma [ l.moments_r ] , we know that @xmath118 < \\infty$ ] for any @xmath173 . to verify that @xmath318 < \\infty$ ] for some @xmath117 note that if @xmath283 we have , by the assumptions of the theorem and jensen s inequality , @xmath319 \\leq e\\left [ \\left ( \\sum_{i=1}^n c_i \\right)^\\gamma \\right ] \\leq \\left ( e\\left [ \\left(\\sum_{i=1}^n c_i \\right)^\\alpha \\right ] \\right)^{\\gamma/\\alpha } < \\infty\\ ] ] for any @xmath320 . if @xmath286 , then for @xmath321 we have @xmath319 \\leq e\\left [ \\left ( \\sum_{i=1}^n c_i^{\\alpha/(1+\\epsilon ) } \\right)^{1+\\epsilon/2 } \\right ] \\leq \\left ( e\\left [ \\left ( \\sum_{i=1}^n c_i^{\\alpha/(1+\\epsilon ) } \\right)^{1+\\epsilon } \\right ]   \\right)^\\frac{1+\\epsilon/2}{1+\\epsilon } < \\infty.\\ ] ]    the statement of the theorem with the first expression for @xmath124 will follow from theorem [ t.newgoldie ] once we prove that condition holds . to this end , define @xmath322 then , @xmath323 \\right|   & \\leq \\left|",
    "p(r > t ) - p\\left ( \\max_{1\\leq i \\leq n } c_i r_i > t \\right ) \\right|    \\\\ & \\hspace{5 mm } + \\left| p\\left ( \\max_{1\\leq i \\leq n } c_i r_i > t   \\right )    - e\\left [ \\sum_{i=1}^n \\indicator(c_ir_i > t ) \\right ]   \\right|.\\end{aligned}\\ ] ] since @xmath324 , the first absolute value disappears . for the second one , note that @xmath325   -   p\\left (   \\max_{1\\leq i \\leq n } c_i r_i > t   \\right )   \\\\ & = e\\left [ \\sum_{i=1}^n \\indicator(c_ir_i >",
    "t ) \\right ]   - e\\left [ \\indicator\\left (   \\max_{1\\leq i \\leq n } c_i r_i > t    \\right ) \\right ] \\geq 0.\\end{aligned}\\ ] ] now it follows that @xmath326 \\right|   \\notag \\\\ & \\leq p(r > t ) - p\\left ( \\max_{1\\leq i \\leq n } c_i r_i > t \\right ) \\notag \\\\ & \\hspace{5 mm } + e\\left [ \\sum_{i=1}^n \\indicator(c_ir_i > t ) \\right ] - p\\left ( \\max_{1\\leq i \\leq n } c_i r_i > t \\right )   .",
    "\\label{eq : term2}\\end{aligned}\\ ] ]    note that the integral corresponding to is finite by lemma [ l.max_approx ] if we show that the assumptions of lemma  [ l.max_approx ] are satisfied when @xmath283 .",
    "note that in this case we can choose @xmath271 such that @xmath327 and use the inequality @xmath328 for @xmath329 , @xmath300 , @xmath330 to obtain @xmath331 \\leq e\\left [ \\left ( \\sum_{i=1}^n c_i \\right)^\\alpha \\right ]",
    "< \\infty.\\ ] ] therefore , it only remains to show that @xmath332    to see this , note that @xmath333 and @xmath334 , and thus , by fubini s theorem , we have @xmath335.\\ ] ]    if @xmath286 , we apply to obtain @xmath336 \\leq e \\left [ q^\\alpha + \\sum_{i=1}^n ( c_ir_i)^\\alpha - \\left ( \\max_{1\\leq i \\leq n } c_i r_i \\right)^\\alpha    \\right],\\ ] ] which is finite by lemma [ l.max_approx ] and the assumption @xmath279 < \\infty$ ] .    if @xmath283 , we have @xmath337 , @xmath300 , @xmath330 , implying that we can split the expectation as follows @xmath338   & =    e \\left [ ( r^*)^\\alpha - \\sum_{i=1}^n   \\left(c_i r_i \\right)^\\alpha    \\right ]   \\\\ & \\hspace{5 mm } +    e \\left [   \\sum_{i=1}^n   \\left(c_i r_i \\right)^\\alpha - \\left ( \\max_{1\\leq i \\leq n } c_i r_i \\right)^\\alpha    \\right],\\end{aligned}\\ ] ] which can be done since both expressions inside the expectations on the right - hand side are nonnegative .",
    "the first expectation is finite by lemma [ l.extraq ] and the second expectation is again finite by lemma [ l.max_approx ] .",
    "finally , applying theorem [ t.newgoldie ] gives @xmath339 where @xmath340 \\right)^{-1 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p(r > v ) - e\\left [ \\sum_{j=1}^{n } \\indicator(c_{j } r > v ) \\right ]     \\right ) dv$ ] .    to obtain the second expression for @xmath124 note that @xmath341     \\right ) dv \\notag \\\\ & = \\int_0^\\infty v^{\\alpha-1 }    e\\left[\\indicator\\left(\\sum_{i=1}^n c_i r_i + q > v \\right ) - \\sum_{i=1}^n \\indicator(c_ir_i > v )   \\right ] \\ , dv \\notag \\\\   & = e \\left [    \\int_0^\\infty v^{\\alpha-1 }   \\left (   \\indicator\\left(\\sum_{i=1}^n c_i r_i + q > v \\right ) - \\sum_{i=1}^n \\indicator(c_ir_i > v ) \\right ) dv   \\right ] \\label{eq : fubini } \\\\ & = e \\left [    \\int_0^{\\sum_{i=1}^n c_i r_i + q } v^{\\alpha-1 } dv   -   \\sum_{i=1}^n \\int_0^{c_i r_i } v^{\\alpha-1 }   dv   \\right ] \\label{eq : diffintegrals } \\\\ & = \\frac{1}{\\alpha } e\\left [ \\left ( \\sum_{i=1}^n c_i r_i + q \\right)^\\alpha - \\sum_{i=1}^n ( c_i r_i)^\\alpha    \\right ] , \\notag\\end{aligned}\\ ] ] where is justified by fubini s theorem and the integrability of @xmath342 which is a consequence of and lemma [ l.max_approx ] ; and follows from the observation that @xmath343 are each almost surely absolutely integrable with respect to @xmath344 as well .",
    "this completes the proof .    as indicated earlier ,",
    "when @xmath345 is an integer , we can obtain the following explicit expression for @xmath124 .",
    "[ c.explicit ] for integer @xmath346 , and under the same assumptions of theorem [ t.linearrecursion ] , the constant @xmath124 can be explicitly computed as a function of @xmath347 , e[c^k ] , e[q^k]$ ] , @xmath348 . in particular , for @xmath349 , @xmath350}{e\\left [ \\sum_{i=1}^n c_i \\log c_i   \\right ] } , \\ ] ] and for @xmath351 , @xmath352 + 2 e[r ] e\\left [ q \\sum_{i=1}^n c_i \\right ] + 2 ( e[r])^2 e\\left [ \\sum_{i=1}^n \\sum_{j = i+1}^n c_i c_j   \\right ] } { 2 e\\left [ \\sum_{i=1}^n c_i^2 \\log c_i   \\right ] } , \\\\ & e[r ] = \\frac{e[q]}{1-e\\left [ \\sum_{i=1}^n c_i \\right]}.\\end{aligned}\\ ] ]    the proof follows directly from multinomial expansions of the second expression for @xmath124 in theorem  [ t.linearrecursion ] .      in this section",
    "we briefly describe how the methodology developed in the previous sections can be applied to study the critical , @xmath15 = 1 $ ] , homogeneous linear recursion @xmath353 where @xmath17 is a nonnegative random vector with @xmath7 and @xmath354 is a sequence of iid random variables independent of @xmath17 having the same distribution as @xmath0 .",
    "this equation has been studied extensively in the literature under various different assumptions ; for recent results see @xcite and the references therein .    based on the model from section  [ s.linearrec ] we can construct a solution to as follows .",
    "consider the process @xmath355 defined by with @xmath356 .",
    "then , the @xmath357 satisfy in distribution the homogeneous recursion in and , given that @xmath15 = 1 $ ] , we have @xmath358=1 $ ] . hence , @xmath355 is a nonnegative martingale and by the martingale convergence theorem @xmath359 a.s . with @xmath360\\leq 1 $ ] .",
    "next , provided that @xmath361 < 0 \\quad\\text { and } \\quad   e\\left [ \\left ( \\sum_{i=1}^n c_i \\right ) \\log^+ \\left ( \\sum_{i=1}^n c_i \\right ) \\right ] < \\infty\\ ] ] it can be shown that @xmath360=1 $ ] , see theorem 1.1(d ) in @xcite ( see also theorem 2 in @xcite ) ; @xmath362 . furthermore ,",
    "as argued in equation ( 1.9 ) of @xcite , it can easily be shown that this @xmath0 is a solution to .",
    "note that the same construction of the solution @xmath0 on a branching tree was given in @xcite and @xcite .",
    "since the solutions to are scale invariant , this construction also shows that for any @xmath363 there is a solution @xmath0 with mean @xmath364 ; or equivalently , it is enough to study the solutions with mean @xmath365 .",
    "moreover , under additional assumptions it can be shown that this constructed @xmath0 is the only solution with mean @xmath365 , e.g. see @xcite . however , it is not the objective of this section to study the uniqueness of this solution , rather we focus on studying the tail behavior of any such possible solution ( since our theorem  [ t.newgoldie ] does not require the uniqueness of @xmath0 ) . as a side note ,",
    "we point out that can have solutions if @xmath276=1 $ ] for some @xmath366 , as studied in @xcite .    a version of the following theorem , with a possibly less explicit constant , was previously proved in theorem  2.2 in @xcite and proposition  7 in @xcite ; they also study the lattice case .",
    "regarding the lattice case , as pointed out earlier in the remark after theorem  [ t.newgoldie ] , all the results in this paper can be developed for this case as well by using the corresponding renewal theorem .",
    "[ t.linearhomog ] suppose that there exists @xmath98 with @xmath113 such that the measure @xmath100 is nonarithmetic .",
    "suppose further that for some @xmath283 ,",
    "@xmath282 < \\infty$ ] , @xmath367 < \\infty$ ] and @xmath15 = e \\left [ \\sum_{i=1}^n c_i^\\alpha \\right ] = 1 $ ] . then , equation has a solution @xmath0 with @xmath368 <",
    "\\infty$ ] such that @xmath121 where @xmath122 is given by @xmath287 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p(r > v ) - e\\left [ \\sum_{i=1}^{n } \\indicator(c_{i } r > v ) \\right ]     \\right ) dv \\\\ & = \\frac{e\\left [ \\left ( \\sum_{i=1}^n c_i r_i \\right)^\\alpha - \\sum_{i=1}^n ( c_i r_i ) ^\\alpha \\right]}{\\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log c_i   \\right ] } .\\end{aligned}\\ ] ] furthermore , if @xmath369 , @xmath370 , then @xmath371 .    by the assumptions , the function @xmath372 $ ] is convex , finite , and continuous on @xmath373 $ ] , since @xmath374 .",
    "furthermore , by standard arguments , it can be shown that both @xmath375 and @xmath376 exist on the open interval @xmath377 and , in particular , @xmath378.\\ ] ] clearly , @xmath379 provided that @xmath380 . to see that this is indeed the case , note that @xmath15 = 1 $ ] implies that @xmath381 , which combined with the nonarithmetic assumption yields @xmath380 .",
    "hence , there exists @xmath382 such that @xmath383 and @xmath384 , implying by the monotonicity of @xmath385 and monotone convergence that @xmath386",
    "\\leq e\\left [ \\sum_{i=1}^n c_i^{\\alpha } \\log^+ c_i \\right ] < \\infty \\qquad \\text{and}\\ ] ] @xmath387 < 0 .\\ ] ] the last expression and the observation",
    "@xmath388 < \\infty$ ] ( implied by @xmath282 < \\infty$ ] ) yields , as argued at the beginning of this section , that recursion has a solution with finite positive mean , see theorem 1.1(d ) and equation ( 1.9 ) in @xcite ( see also theorem 2 in @xcite ) .    next , in order to apply theorem [ t.newgoldie ] , we use and @xmath389 < \\infty$ ] for any @xmath173",
    "; the latter follows from theorem 3.1 in @xcite and the strict convexity of @xmath390 argued above ( see also , proposition  4 in @xcite and theorem  2.1 in @xcite ) .",
    "the rest of the proof , except for the @xmath371 part , proceeds exactly as that of theorem  [ t.linearrecursion ] by setting @xmath23 .",
    "regarding the @xmath371 statement , the assumption @xmath369 implies that there exist @xmath391 and @xmath392 such that @xmath393 , which further yields , for some @xmath394 , @xmath395 next , by using the inequality @xmath396 for @xmath397 and @xmath283 , the second expressions for @xmath124 in the theorem can be bounded from below by @xmath398}{\\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log c_i   \\right ] } .\\ ] ] to further bound the numerator in we define the function @xmath399 where @xmath400 , @xmath401 and @xmath402 . it can be shown that @xmath403 for @xmath404 $ ] , since @xmath405 and @xmath406 on @xmath407 $ ] . hence , by using the inequality @xmath403 , we derive for @xmath408 , @xmath409 and @xmath410 @xmath411 the inequality clearly holds even if @xmath412 since both of its sides are zero .",
    "thus , by applying this last inequality to and using , we obtain @xmath413}{\\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log c_i   \\right ] } \\\\ & \\geq   \\frac{c \\delta^\\alpha p(n\\ge i_2 , c_{i_1}>\\delta , c_{i_2}>\\delta ) e[\\left(\\min \\{r_{i_1},r_{i_2}\\}\\right)^\\alpha ] } { \\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log c_i   \\right ] } > 0.\\end{aligned}\\ ] ] this completes the proof .",
    "remarks : ( i ) note that the assumptions of theorem [ t.linearhomog ] differ slightly from those of theorem [ t.linearrecursion ] in the condition @xmath414",
    "< ~\\infty$ ] , which is implied by @xmath415 < \\infty$ ] , the strict convexity of @xmath416 $ ] and the hypothesis that @xmath374 , as argued in the preceding proof .",
    "( ii ) the assumption @xmath369 is the minimal one to ensure the existence of a nontrivial solution , see conditions ( h0 ) in @xcite and ( c4 ) in @xcite .",
    "otherwise , when @xmath417 , @xmath200 is a simple multiplicative random walk with no branching ; clearly , in this case our expression for @xmath124 reduces to zero . also ,",
    "if @xmath418 , @xmath0 can only be a constant ; see the remark above theorem  2.1 in @xcite . however , this last case is excluded from the theorem since @xmath418 implies @xmath419 a.s . , which , in conjunction with @xmath420 , yields @xmath421 , but this can not happen due to the nonarithmetic assumption .",
    "( iii ) note also that condition ( c3 ) in @xcite ( equivalent to @xmath380 in our notation ) is implied by the nonarithmetic assumption of our theorem .",
    "interestingly enough , if this last condition fails , lemma  1.1 of @xcite shows that equation has no nontrivial solutions .",
    "( iv ) as stated earlier , a version of this theorem was proved in theorem 2.2 of @xcite , by transforming recursion into a first order difference ( autoregressive / perpetuity ) equation on a different probability space , see lemma 4.1 in @xcite .",
    "however , it appears that the method from @xcite does not extend to the nonhomogeneous and non - linear problems that we cover here , since the proof of lemma  4.1 in @xcite critically depends on having both @xmath360 = 1 $ ] and @xmath15 = 1 $ ] .",
    "similarly as in corollary [ c.explicit ] , the constant @xmath124 can be computed explicitly for integer @xmath422 .",
    "[ c.explicithom ] for integer @xmath422 , and under the same assumptions of theorem [ t.linearhomog ] , the constant @xmath124 can be explicitly computed as a function of @xmath347 , e[c^k]$ ] , @xmath423 . in particular , for @xmath351 , @xmath424 } { e\\left [ \\sum_{i=1}^n c_i^2 \\log c_i   \\right ] } .\\ ] ]    the proof follows directly from multinomial expansions of the second expression for @xmath124 in theorem  [ t.linearhomog ] .",
    "we also want to point out that for non - integer general @xmath283 we can use lemma [ l.alpha_moments ] to obtain the following bound for @xmath124 , @xmath425 \\right)^{\\alpha/(p-1 ) } e\\left [ \\left ( \\sum_{i=1}^n c_i   \\right)^\\alpha\\right]}{\\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log c_i   \\right ] } , \\ ] ] where @xmath426 .",
    "in order to show the general applicability of the implicit renewal theorem , we study in this section the following non - linear recursion : @xmath428 where @xmath2 is a nonnegative random vector with @xmath7 , @xmath59 and @xmath4 is a sequence of iid random variables independent of @xmath2 having the same distribution as @xmath0 .",
    "note that in the case of page ranking applications , where the @xmath315 represent the ranks of the neighboring pages , the potential ranking algorithm defined by the preceding recursion , determines the rank of a page as a weighted version of the most highly ranked neighboring page .",
    "in other words , the highest ranked reference has the dominant impact .",
    "similarly to the homogeneous linear case , this recursion was previously studied in @xcite under the assumption that @xmath23 , @xmath13 , and the @xmath24 are real valued deterministic constants .",
    "the more closely related case of @xmath23 and @xmath25 being random was studied earlier in @xcite .",
    "furthermore , these max - type stochastic recursions appear in a wide variety of applications , ranging from the average case analysis of algorithms to statistical physics ; see @xcite for a recent survey .    using standard arguments , we start by constructing a solution to on a tree and then we show that this solution is finite a.s . and",
    "unique under iterations and some moment conditions , similar to what was done for the nonhomogeneous linear recursion in section [ s.linearrec ] .",
    "our main result of this section is stated in theorem [ t.maximumrecursion ] .",
    "following the same notation as in section [ s.linearrec ] , define the process @xmath429 on the weighted branching tree @xmath191 , as constructed in section [ s.modeldescription ] .",
    "recall that the convention is that @xmath430 denotes the random vector corresponding to the root node .    with a possible abuse of notation relative to section [ s.linearrec ] ,",
    "define the process @xmath192 according to @xmath431 just as with the linear recursion from section [ s.linearrec ] , it is not hard to see that @xmath194 satisfies the recursion @xmath432 where @xmath433 are independent copies of @xmath197 corresponding to the tree starting with individual @xmath198 in the first generation and ending on the @xmath31th generation .",
    "one can also verify that @xmath434 where @xmath435 is a sequence of iid random variables independent of @xmath17 and having the same distribution as @xmath436 .",
    "we now define the random variable @xmath0 according to @xmath437 note that @xmath194 is monotone increasing sample - pathwise , so @xmath0 is well defined .",
    "also , by monotonicity of @xmath194 , and monotone convergence , we obtain that @xmath0 solves @xmath438 where @xmath439 are iid copies of @xmath0 , independent of @xmath2 .",
    "clearly this implies that @xmath0 , as defined by , is a solution in distribution to .",
    "however , this solution might be @xmath440 .",
    "now , we establish the finiteness of the moments of @xmath0 , and in particular that @xmath235 a.s .",
    ", in the following lemma ; its proof uses standard contraction arguments but is included for completeness .",
    "[ l.moments_r_max ] assume that @xmath219<1 $ ] and @xmath224 < \\infty$ ] for some @xmath441 .",
    "then , @xmath233 < \\infty$ ] for all @xmath234 , and in particular , @xmath235 a.s . moreover , if @xmath442 , @xmath236 , where @xmath237 stands for convergence in @xmath238 norm .    by following the same steps leading to , we obtain that for any @xmath443 , @xmath444 = e\\left [ \\bigvee_{{\\bf i } \\in a_k } q_{\\bf i}^\\beta { \\pi}_{\\bf i}^\\beta \\right ]",
    "\\leq e\\left [ \\sum_{{\\bf i } \\in a_k } q_{\\bf i}^\\beta { \\pi}_{\\bf i}^\\beta \\right ] = e[q^\\beta ] \\rho_\\beta^k.\\ ] ] hence , @xmath445 = e\\left [ \\bigvee_{k=0}^\\infty v_k^\\beta \\right ] \\leq e\\left [ \\sum_{k=0}^\\infty v_k^\\beta \\right ] \\leq \\frac{e[q^\\beta]}{1-\\rho_\\beta } < \\infty,\\ ] ] implying that @xmath233 < \\infty$ ] for all @xmath247 .",
    "that @xmath236 whenever @xmath446 follows from noting that @xmath249 \\le e\\left [ \\left ( \\bigvee_{k = n+1}^\\infty v_k \\right)^\\beta \\right ] \\leq e\\left [ \\sum_{k = n+1}^\\infty v_k^\\beta   \\right]$ ] and applying the preceding geometric bound for @xmath447 $ ] .    just as with the linear recursion from section [ s.linearrec",
    "] , we can define the process @xmath448 as @xmath449 where @xmath450 and @xmath254 are iid copies of an initial value @xmath251 , independent of the entire weighted tree @xmath57 .",
    "it follows from and that @xmath451 where @xmath256 are independent copies of @xmath197 corresponding to the tree starting with individual @xmath198 in the first generation and ending on the @xmath31th generation , and @xmath257 is the set of all nodes in the @xmath258th generation that are descendants of individual @xmath198 in the first generation .",
    "moreover , @xmath260 are iid copies of @xmath261 , and thus , @xmath261 is equal in distribution to the process obtained by iterating with an initial condition @xmath251 .",
    "this process can be shown to converge in distribution to @xmath0 for any initial condition @xmath251 satisfying the following moment condition .",
    "[ l.convergencemax ] for any @xmath264 , if @xmath224 , e[(r_0^*)^\\beta ] < \\infty$ ] and @xmath228 for some @xmath452 , then @xmath265 with @xmath118 < \\infty$ ] .",
    "furthermore , under these assumptions , the distribution of @xmath0 is the unique solution with finite @xmath170-moment to recursion",
    ".    the result will follow from slutsky s theorem ( see theorem 25.4 , p. 332 in @xcite ) once we show that @xmath453 . to this end ,",
    "recall that @xmath454 is the same as @xmath455 if we substitute the @xmath269 by the @xmath270 .",
    "then , for every @xmath271 we have that @xmath456 \\\\ & \\leq \\epsilon^{-\\beta } \\rho_\\beta^n e[(r_0^*)^\\beta ] \\qquad \\text{(by \\eqref{eq : vmoment } ) } .\\end{aligned}\\ ] ] since by assumption the right - hand side converges to zero as @xmath152 , then @xmath262 .",
    "furthermore , @xmath118",
    "< \\infty$ ] by lemma [ l.moments_r_max ] . clearly , under the assumptions , the distribution of @xmath0 represents the unique solution to , since any other possible solution with finite @xmath170-moment would have to converge to the same limit .",
    "now we are ready to state the main result of this section .",
    "[ t.maximumrecursion ] let @xmath2 be a nonnegative random vector , with @xmath7 , @xmath59 and @xmath0 be the solution to given by .",
    "suppose that there exists @xmath98 with @xmath113 such that the measure @xmath100 is nonarithmetic , and that for some @xmath91 , @xmath279 < \\infty$ ] , @xmath280 < \\infty$ ] and @xmath281 = 1 $ ] .",
    "in addition , assume    1 .",
    "@xmath282 < \\infty$ ] , , if @xmath283 ; or , 2 .",
    "@xmath284 < \\infty$ ] for some @xmath285 , if @xmath286 .",
    "then , @xmath121 where @xmath122 is given by @xmath287 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p(r > v ) - e\\left [ \\sum_{i=1}^{n } \\indicator(c_{i } r > v ) \\right ]     \\right ) dv \\\\ & = \\frac{e\\left [ \\left ( \\bigvee_{i=1}^n c_i r_i \\right)^\\alpha \\vee q^\\alpha - \\sum_{i=1}^n ( c_i r_i ) ^\\alpha \\right]}{\\alpha e\\left [ \\sum_{i=1}^n c_i^\\alpha \\log c_i   \\right ] } .\\end{aligned}\\ ] ]    by lemma [ l.moments_r_max ] we know that @xmath118 < \\infty$ ] for any @xmath173 . the same arguments used in the proof of theorem [ t.linearrecursion ] give that @xmath318 < \\infty$ ] for some @xmath457 .",
    "the statement of the theorem with the first expression for @xmath124 will follow from theorem [ t.newgoldie ] once we prove that condition holds .",
    "define @xmath458 then , @xmath323 \\right|   & \\leq \\left|",
    "p(r > t ) - p\\left ( \\max_{1\\leq i \\leq",
    "n } c_i r_i > t \\right ) \\right|    \\\\",
    "& \\hspace{5 mm } + \\left| p\\left ( \\max_{1\\leq i \\leq n } c_i r_i > t   \\right )    - e\\left [ \\sum_{i=1}^n \\indicator(c_ir_i > t ) \\right ]   \\right|.\\end{aligned}\\ ] ] since @xmath324 , the first absolute value disappears .",
    "the integral corresponding to the second term is finite by lemma [ l.max_approx ] , just as in the proof of theorem  [ t.linearrecursion ] . to see that the integral corresponding to the first term",
    ", @xmath459 is finite we proceed as in the proof of theorem [ t.linearrecursion ] .",
    "first we use fubini s theorem to obtain that @xmath460   \\\\ & = \\frac{1}{\\alpha } e \\left [ \\left ( \\bigvee_{i=1}^n c_i r_i \\right)^\\alpha \\vee q^\\alpha - \\left ( \\bigvee_{i=1}^n c_i r_i \\right)^\\alpha    \\right ] \\\\ & \\leq \\frac{e[q^\\alpha]}{\\alpha}.\\end{aligned}\\ ] ]    now , applying theorem [ t.newgoldie ] gives @xmath339 where @xmath340 \\right)^{-1 } \\int_{0}^\\infty v^{\\alpha-1 } \\left ( p(r > v ) - e\\left [ \\sum_{j=1}^{n } \\indicator(c_{j } r > v ) \\right ]     \\right ) dv$ ] .",
    "the same steps used in the proof of theorem [ t.linearrecursion ] give the second expression for @xmath124 .",
    "as an illustration of the generality of the methodology presented in this paper , we mention in this section other recursions that fall within its scope .",
    "one example that is closely related to the recursions from sections  [ s.linearrec ] and [ s.maxrec ] is the following @xmath461 where @xmath2 is a nonnegative vector with @xmath7 , @xmath59 , and @xmath462 is a sequence of iid random variables independent of @xmath2 having the same distribution as @xmath0 .",
    "recursion was termed  discounted tree sums \" in @xcite ; for additional details on the existence and uniqueness of its solution see section 4.4 in @xcite .",
    "similarly as in @xcite , it appears that one could study other non - linear recursions on trees using implicit renewal theory .",
    "for example , one could analyze the solution to the equation @xmath463 where @xmath2 is a nonnegative vector with @xmath7 , @xmath59 , and @xmath464 is a sequence of iid random variables independent of @xmath2 . here",
    ", the primary difficulty would be in establishing the existence and uniqueness of the solution as well as the finiteness of moments .",
    "we give in this section the proof of lemma [ l.renewalmeasure ] .",
    "observe that the measure @xmath465 $ ] is nonarithmetic ( nonlattice ) by our assumption since , if we assume to the contrary that it is lattice on a lattice set @xmath466 , then on the complement @xmath467 of this set we have @xmath468\\ge p(\\log c_j \\in l^c , c_j>0,n \\ge j)>0,\\ ] ] which is a contradiction .",
    "hence , @xmath109 is nonarithmetic as well , and it places no mass at @xmath105 due to the exponential term @xmath469 . to see that it is a probability measure note that @xmath470 \\\\ & = e\\left [ \\sum_{j=1}^n \\int_{-\\infty}^\\infty e^{\\alpha u } \\indicator(\\log c_j \\in du )   \\right ] \\qquad \\text{(by fubini 's theorem ) } \\\\ & =   e\\left [ \\sum_{j=1}^n c_j^\\alpha \\right ] = 1.\\end{aligned}\\ ] ] similarly , its mean is given by @xmath471 .\\ ] ]    to show that @xmath472 we proceed by induction .",
    "let @xmath473 denote the @xmath137-algebra generated by @xmath474 , @xmath139 , and for each @xmath94 set @xmath475 .",
    "hence , using this notation we derive @xmath476 ) & = \\int_{-\\infty}^t e^{\\alpha u } e\\left [   \\sum_{{\\bf i } \\in a_{n } } \\sum_{j=1}^{n_{{\\bf i } } } \\indicator(v_{{\\bf i } } + \\log c_{({\\bf i},j ) } \\in du )    \\right ] \\\\ & = \\int_{-\\infty}^t e^{\\alpha u } e\\left [   \\sum_{{\\bf i } \\in a_{n } } e\\left [ \\left .",
    "\\sum_{j=1}^{n_{{\\bf i } } } \\indicator(v_{{\\bf i } } + \\log c_{({\\bf i},j ) } \\in du ) \\right|",
    "\\mathcal{f}_n \\right ]   \\right ] \\\\ & =   e\\left [   \\sum_{{\\bf i } \\in a_{n } } e^{\\alpha v_{\\bf i } } \\int_{-\\infty}^t e^{\\alpha ( u- v_{\\bf i } ) } e\\left [ \\left .",
    "\\sum_{j=1}^{n_{{\\bf i } } } \\indicator ( \\log c_{({\\bf i},j ) } \\in du - v_{\\bf i } ) \\right| \\mathcal{f}_n \\right ]   \\right ] \\\\ & = e\\left [   \\sum_{{\\bf i } \\in a_{n } } e^{\\alpha v_{\\bf i } } \\eta((-\\infty , t - v_{{\\bf i } } ] )   \\right ] \\\\ &",
    "= \\int_{-\\infty}^\\infty   \\eta((-\\infty , t - v ] )   \\mu_n(dv),\\end{aligned}\\ ] ] where in the fourth equality we used the independence of @xmath477 from @xmath473 . therefore @xmath478 and the induction hypothesis gives the result .",
    "in this section we prove lemmas [ l.alpha_moments ] , [ l.momentsmaller_1 ] and [ l.generalmoment ] .",
    "we also include a result that provides bounds for @xmath479 $ ] for integer @xmath480 , which will be used in the proof of lemma [ l.generalmoment ] .",
    "let @xmath481 and @xmath482 $ ] .",
    "suppose first that @xmath483 and define @xmath484 .",
    "then , for any sequence of nonnegative numbers @xmath485 we have @xmath486 where for the last step we used the well known inequality @xmath487 for @xmath488 and @xmath300 .",
    "we now use the conditional jensen s inequality to obtain @xmath489 \\\\ & \\leq e\\left [   \\left ( \\sum_{(j_1,\\dots , j_k ) \\in a_p(k ) } \\binom{p}{j_1,\\dots , j_k } ( c_1y_1)^{j_1 } \\cdots ( c_k y_k)^{j_k } \\right)^\\gamma \\right ] \\qquad \\text{(by \\eqref{eq : scalarbound } ) } \\\\ & \\leq     e\\left [ \\left (   e\\left [ \\left .",
    "\\sum_{(j_1,\\dots , j_k ) \\in a_p(k ) } \\binom{p}{j_1,\\dots , j_k } ( c_1y_1)^{j_1 } \\cdots ( c_k y_k)^{j_k } \\right| c_1,\\dots , c_k \\right ] \\right)^\\gamma \\right ]   \\\\ & = e \\left [ \\left (   \\sum_{(j_1,\\dots , j_k ) \\in a_p(k ) } \\binom{p}{j_1,\\dots , j_k } c_1^{j_1 } \\cdots c_k^{j_k } e\\left [ \\left . y_1^{j_1 } \\cdots y_k^{j_k } \\right| c_1,\\dots , c_k \\right ] \\right)^\\gamma   \\right].\\end{aligned}\\ ] ] since @xmath490 is a sequence of iid random variables having the same distribution as @xmath210 , independent of the @xmath277 s we have that @xmath491 = e\\left [ y_1^{j_1 } \\cdots y_k^{j_k } \\right ]   = || y ||_{j_1}^{j_1 }   \\cdots || y ||_{j_k}^{j_k},\\ ] ] where @xmath492 \\right)^{1/\\kappa}$ ] for @xmath493 and @xmath494 .",
    "since @xmath495 is increasing for @xmath493 it follows that @xmath496 . hence @xmath497 which in turn implies that @xmath498 & \\leq e \\left [ \\left (   \\sum_{(j_1,\\dots , j_k ) \\in a_p(k ) } \\binom{p}{j_1,\\dots , j_k } c_1^{j_1 } \\cdots c_k^{j_k } || y ||_{p-1}^p \\right)^\\gamma   \\right ] \\\\ & = || y ||_{p-1}^\\beta e\\left [ \\left ( \\left(\\sum_{i=1}^k c_i \\right)^p - \\sum_{i=1}^k c_i^p \\right)^\\gamma   \\right ]   \\\\ & \\leq || y ||_{p-1}^\\beta e\\left [ \\left(\\sum_{i=1}^k c_i \\right)^\\beta   \\right].\\end{aligned}\\ ] ] this completes the proof for @xmath499 finite .    when @xmath213 , first note that from the well known inequality @xmath500 for @xmath397 and @xmath211 we obtain the monotonicity in @xmath499 of the following difference @xmath501 hence , @xmath502 \\notag \\\\ & = \\lim_{k\\to \\infty } e\\left [   \\left ( \\left ( \\sum_{i=1}^k c_iy_i \\right)^\\beta - \\sum_{i=1}^k ( c_i y_i)^{\\beta } \\right ) \\right ] \\label{eq : exchange1 } \\\\ & \\leq \\lim_{k\\to \\infty } e\\left [   \\left ( \\sum_{(j_1,\\dots , j_k ) \\in a_p(k ) } \\binom{p}{j_1,\\dots , j_k } ( c_1y_1)^{j_1 } \\cdots ( c_k y_k)^{j_k } \\right)^\\gamma   \\right ]   \\notag \\\\ & \\leq \\lim_{k \\to \\infty } || y ||_{p-1}^\\beta   e\\left [ \\left(\\sum_{i=1}^k c_i \\right)^\\beta   \\right ]   \\notag \\\\ & = || y ||_{p-1}^\\beta   e\\left [ \\left(\\sum_{i=1}^\\infty c_i \\right)^\\beta   \\right ] , \\label{eq : exchange2}\\end{aligned}\\ ] ] where and are justified by monotone convergence .",
    "we use the well known inequality @xmath503 for @xmath222 , @xmath246 , @xmath330 , to obtain @xmath504 & = e\\left [ \\left ( \\sum_{i=1}^n c_i w_{(n-1),i } \\right)^\\beta \\right ] \\notag \\\\ & \\leq e\\left [ \\sum_{i=1}^n c_i^\\beta   w_{(n-1),i}^\\beta \\right ] \\notag \\\\ & = e[w_{n-1}^\\beta ] \\rho_\\beta \\qquad \\text{(by conditioning on $ n , c_i$ and fubini 's theorem ) } \\notag \\\\ & \\leq \\rho_\\beta^{n } e[w_0^\\beta ] \\qquad \\text{(iterating $ n$ times ) } \\notag \\\\ & = \\rho_\\beta^{n } e[q^\\beta ] .",
    "\\end{aligned}\\ ] ]    before proving the moment inequality for general @xmath211 , we will show first the corresponding result for integer moments .",
    "[ l.integermoment ] let @xmath505 and recall that @xmath506 $ ] , @xmath221 .",
    "< \\infty$ ] , @xmath508 < \\infty$ ] , and @xmath509 .",
    "then , there exists a constant @xmath510 such that @xmath511 \\leq k_p \\left ( \\rho \\vee \\rho_p \\right)^n\\ ] ] for all @xmath30 .",
    "we will give an induction proof in @xmath480 .",
    "for @xmath512 we have @xmath513 & = e\\left [ \\left ( \\sum_{i=1}^n c_i w_{(n-1),i } \\right)^2   \\right ] \\\\ & = e\\left [ \\sum_{i=1}^n c_i^2 w_{(n-1),i}^2 + \\sum_{i \\neq j } c_i w_{(n-1),i } c_j w_{(n-1),j }   \\right ] \\\\ & = e[w_{n-1}^2 ] e\\left [ \\sum_{i=1}^n c_i^2 \\right ] + \\left ( e[w_{n-1 } ] \\right)^2 e\\left [ \\sum_{i \\neq j } c_i   c_j   \\right ] \\\\ & \\hspace{4.5 cm } \\text{(by conditioning on $ n , c_i$ and fubini 's theorem ) } \\\\ & \\leq \\rho_2 e[w_{n-1}^2 ] + e\\left [ \\left ( \\sum_{i=1}^n c_i \\right)^2 \\right ] \\left ( e[w_{n-1 } ] \\right)^2 .\\end{aligned}\\ ] ]    using the preceding recursion and noting that , @xmath514 = \\rho^{n-1 } e[q],\\ ] ] we obtain @xmath515 \\leq \\rho_2 e[w_{n-1}^2 ] + k \\rho^{2(n-1)},\\ ] ] where @xmath516 \\left ( e[q ] \\right)^2 $ ] .",
    "now , iterating gives @xmath513 & \\leq \\rho_2 \\left ( \\rho_2 e[w_{n-2}^2 ] +   k \\rho^{2(n-2 ) } \\right ) +   k \\rho^{2(n-1 ) } \\\\ & \\leq \\rho_2^{n-1 } \\left ( \\rho_2 e[w_{0}^2 ] + k   \\right ) + k \\sum_{i=0}^{n-2 } \\rho_2^i \\ , \\rho^{2(n-1-i ) } \\\\ & = \\rho_2^n e[q^2 ] + k   \\sum_{i=0}^{n-1 } \\rho_2^i \\ , \\rho^{2(n-1-i ) }   \\\\ & \\leq ( \\rho_2 \\vee \\rho)^n e[q^2 ] + k ( \\rho_2 \\vee \\rho)^n \\sum_{i=0}^{n-1 } ( \\rho_2 \\vee \\rho)^{n-2 - i   }   \\\\ & \\leq \\left ( e[q^2 ] + \\frac{k}{\\rho_2 \\vee \\rho } \\sum_{j=0}^{\\infty } ( \\rho_2 \\vee \\rho)^{j }   \\right ) ( \\rho_2 \\vee \\rho)^n \\\\ & = k_2 ( \\rho_2 \\vee \\rho)^n , \\end{aligned}\\ ] ] which completes the case @xmath512 .",
    "suppose now that there exists a constant @xmath517 such that @xmath518 \\leq k_{p-1 } \\left ( \\rho_{p-1 } \\vee \\rho \\right)^n\\ ] ] for all @xmath30 .",
    "then , by lemmas [ l.alpha_moments ] and [ l.momentsmaller_1 ] , we have @xmath519 & = e\\left [ \\left ( \\sum_{i=1}^n c_i w_{(n-1),i } \\right)^p - \\sum_{i=1}^n c_i^p w_{(n-1),i}^p \\right ] + e\\left [   \\sum_{i=1}^n c_i^p w_{(n-1),i}^p \\right ] \\\\ & \\leq \\left ( e\\left [ w_{n-1}^{p-1 } \\right ] \\right)^{p/(p-1 ) } e\\left [ \\left ( \\sum_{i=1}^n c_i \\right)^p \\right ] + e\\left [   \\sum_{i=1}^n c_i^p w_{(n-1),i}^p \\right ] \\\\ & = \\left ( e\\left [ w_{n-1}^{p-1 } \\right ] \\right)^{p/(p-1 ) } e\\left [ \\left ( \\sum_{i=1}^n c_i \\right)^p \\right ] + \\rho_p e\\left [ w_{n-1}^{p } \\right ] \\\\ & \\leq   e\\left [ \\left ( \\sum_{i=1}^n c_i \\right)^p \\right ]   ( k_{p-1})^{p/(p-1 ) } ( \\rho_{p-1 } \\vee \\rho)^{(n-1)p/(p-1 ) } + \\rho_p e[w_{n-1}^p],\\end{aligned}\\ ] ] where in the second equality we conditioned on @xmath520 and used fubini s theorem , and the last inequality corresponds to the induction hypothesis .",
    "we then obtain the recursion @xmath521",
    "\\leq \\rho_p e[w_{n-1}^p ] + k ( \\rho_{p-1 } \\vee \\rho)^{\\frac{(n-1)p}{p-1}},\\ ] ] where @xmath522   ( k_{p-1})^{p/(p-1)}$ ] . iterating as for the case @xmath523 gives @xmath519 & \\leq \\rho_p^n e[q^p ] + k   \\sum_{i=0}^{n-1 } \\rho_p^i \\ , ( \\rho_{p-1 } \\vee \\rho)^{(n-1-i)p/(p-1 ) } \\notag \\\\ & \\leq ( \\rho_p \\vee \\rho)^n e[q^p ] + k \\sum_{i=0}^{n-1 } ( \\rho_p \\vee \\rho)^{((n-1)p -i)/(p-1 ) } \\label{eq : mgfconvexity }   \\\\ \\phantom{e[w_n^p]}&= ( \\rho_p \\vee \\rho)^n e[q^p ] + k ( \\rho_p \\vee \\rho)^{n-1 }    \\sum_{i=0}^{n-1 } ( \\rho_p \\vee \\rho)^{(n- i - 1)/(p-1 ) }   \\notag   \\\\ & \\leq   \\left ( e[q^p ] + k ( \\rho_p \\vee \\rho)^{-1 }    \\sum_{j=0}^{\\infty } ( \\rho_p \\vee \\rho)^{\\frac{j}{p-1 } } \\right ) ( \\rho_p \\vee \\rho)^n \\notag \\\\ & = k_p ( \\rho_p \\vee \\rho)^n , \\notag\\end{aligned}\\ ] ] where in we used the convexity of @xmath524 , i.e. @xmath525 .    the proof for the general @xmath170-moment , @xmath211 , is given below .",
    "set @xmath526 .",
    "then , by lemmas [ l.alpha_moments ] and [ l.momentsmaller_1 ] , @xmath504 & = e\\left [ \\left ( \\sum_{i=1}^n c_i w_{(n-1),i } \\right)^\\beta - \\sum_{i=1}^n c_i^\\beta w_{(n-1),i}^\\beta \\right ] + e\\left [   \\sum_{i=1}^n c_i^\\beta w_{(n-1),i}^\\beta \\right ] \\\\ & \\leq \\left ( e\\left [ w_{n-1}^{p-1 } \\right ] \\right)^{\\beta/(p-1 ) } e\\left [ \\left ( \\sum_{i=1}^n c_i \\right)^\\beta \\right ] + e\\left [   \\sum_{i=1}^n c_i^\\beta w_{(n-1),i}^\\beta \\right ] \\\\ & = \\left ( e\\left [ w_{n-1}^{p-1 } \\right ] \\right)^{\\beta/(p-1 ) } e\\left [ \\left ( \\sum_{i=1}^n c_i \\right)^\\beta \\right ] + \\rho_\\beta e\\left [ w_{n-1}^{\\beta } \\right ]    .\\end{aligned}\\ ] ] by lemma [ l.integermoment ] , @xmath504 & \\leq   \\rho_\\beta e[w_{n-1}^\\beta ] + e\\left [ \\left ( \\sum_{i=1}^n c_i \\right)^\\beta \\right ]   ( k_{p-1})^{\\beta/(p-1 ) } ( \\rho_{p-1 } \\vee \\rho)^{(n-1)\\beta/(p-1 ) } \\\\ & = \\rho_\\beta e [ w_{n-1}^\\beta ] + k ( \\rho_{p-1 } \\vee \\rho)^{(n-1)\\gamma},\\end{aligned}\\ ] ] where @xmath527",
    ". finally , iterating the preceding bound @xmath528 times gives @xmath504 & \\leq \\rho_\\beta^n e[w_0^\\beta ] + k \\sum_{i=0}^{n-1 } \\rho_\\beta^i ( \\rho \\vee \\rho_{p-1})^{\\gamma(n-1-i ) } \\\\ & \\leq e[w_0^\\beta ]   ( \\rho \\vee \\rho_\\beta)^n + k   \\sum_{i=0}^{n-1 } ( \\rho \\vee \\rho_\\beta)^{\\gamma(n-1-i ) +",
    "i } \\qquad \\text{(by convexity of $ \\varphi(\\beta ) = \\rho_\\beta$ ) } \\\\ & = e[q^\\beta ] ( \\rho \\vee \\rho_\\beta)^n + k ( \\rho \\vee \\rho_\\beta)^{n-1 } \\sum_{i=0}^{n-1 } ( \\rho \\vee",
    "\\rho_\\beta)^{(\\gamma-1 ) i } \\\\ & \\leq k_\\beta ( \\rho \\vee \\rho_\\beta)^n .\\end{aligned}\\ ] ] this completes the proof .      in this section",
    "we give the proofs of the technical lemmas [ l.max_approx ] and [ l.extraq ] for the linear recursion .",
    "note that the integral is positive since @xmath529 & \\leq e\\left [    \\sum_{i=1}^n \\indicator\\left ( c_i r_i > t   \\right )   \\right ] .\\end{aligned}\\ ] ]    to see that the integral is equal to the expectation involving the @xmath12-moments note that @xmath530 - p\\left ( \\max_{1\\leq i \\leq n } c_i r_i > t \\right ) \\right )   t^{\\alpha -1 } \\ , dt \\\\",
    "& = \\int_0^\\infty e\\left [ \\sum_{i=1}^n \\indicator(c_i r_i > t ) - \\indicator\\left(\\max_{1\\leq i \\leq n } c_i r_i > t \\right )    \\right ]   t^{\\alpha -1 } \\ , dt \\\\ & = e\\left [   \\int_0^\\infty \\left (    \\sum_{i=1}^n   \\indicator(c_i r_i > t )   - \\indicator\\left ( \\max_{1\\leq i \\leq",
    "n } c_i r_i > t \\right ) \\right )   t^{\\alpha -1 } \\ , dt    \\right ] \\qquad \\text{(by fubini 's theorem ) } \\\\ & = e\\left [    \\sum_{i=1}^n   \\frac{1}{\\alpha } ( c_i r_i)^{\\alpha }   - \\frac{1}{\\alpha } \\left(\\max_{1\\leq",
    "i \\leq n } c_i r_i \\right)^{\\alpha }   \\right ] , \\end{aligned}\\ ] ] where the last equality is justified by the assumption that @xmath313 a.s .",
    "it now remains to show that the integral ( expectation ) is finite .",
    "to do this let @xmath531 .",
    "similar arguments to those used above give @xmath532 - p\\left ( \\max_{1\\leq i \\leq n } c_i r_i > t \\right ) \\right )   t^{\\alpha -1 } \\ , dt \\\\ & = \\int_0^\\infty e\\left [ e\\left [ \\left .",
    "\\sum_{i=1}^n \\indicator(c_i r_i >",
    "t ) - \\indicator\\left(\\max_{1\\leq i \\leq",
    "n } c_i r_i > t \\right ) \\right| { \\bf x } \\right ]   \\right ]    t^{\\alpha -1 } \\ , dt \\\\",
    "& = e\\left [   \\int_0^\\infty e\\left [ \\left . \\sum_{i=1}^n \\indicator(c_i r_i > t ) - \\indicator\\left(\\max_{1\\leq i \\leq n } c_i r_i > t \\right ) \\right| { \\bf x } \\right ]      t^{\\alpha -1 } \\ , dt     \\right ] , \\end{aligned}\\ ] ] where in the last step we used fubini s theorem .",
    "furthermore , @xmath533    \\\\ & = e\\left [ \\left .",
    "\\indicator\\left ( \\max_{1\\leq",
    "i \\leq n } c_i r_i \\leq t \\right ) \\right|   { \\bf x } \\right ] - 1 + \\sum_{i=1}^n   e\\left [ \\indicator(c_i r_i >",
    "t ) | { \\bf x}\\right ] . \\end{aligned}\\ ] ]    note that given @xmath534 , the random variables @xmath535 are independent ( since the @xmath0 s are ) , so if we let @xmath536 , then @xmath537 = \\prod_{i=1}^n e\\left [ \\left .",
    "\\indicator\\left ( c_i r_i \\leq t \\right ) \\right|   { \\bf x } \\right ] = \\prod_{i=1}^n \\left(1 - \\overline{f}(t / c_i ) \\right).\\ ] ] we now use the inequality @xmath538 for @xmath539 to obtain @xmath540 next , let @xmath541 and set @xmath542 . by markov s inequality , @xmath543 t^{-\\beta } = t^{-\\beta } e[r^\\beta ] \\sum_{i=1}^n c_i^\\beta.\\ ] ]    now , define the function @xmath544 and note that @xmath545 is increasing for @xmath539 .",
    "therefore , @xmath546",
    "\\sum_{i=1}^n c_i^\\beta \\right).\\ ] ] this observation combined with the previous derivations gives @xmath547     t^{\\alpha -1 } \\ , dt   \\\\ & \\leq \\int_0^\\infty \\left ( e^{-r s_\\beta t^{-\\beta } } - 1 + r s_\\beta t^{-\\beta }   \\right ) t^{\\alpha-1 } dt,\\end{aligned}\\ ] ] where @xmath548 and @xmath549 < \\infty$ ] .",
    "hence , using the change of variables @xmath550 gives @xmath551 our choice of @xmath542 guarantees that @xmath552 . to see that the ( non - random ) integral is finite note that @xmath553 and @xmath554 for any @xmath539 , implying @xmath555 now , it follows that @xmath530 - p\\left ( \\max_{1\\leq i \\leq n }",
    "c_i r_i > t \\right ) \\right )   t^{\\alpha -1 } \\ , dt   \\\\ &",
    "\\leq e\\left [   k ( r s_\\beta)^{\\alpha/\\beta }   \\right ] = k   r^{\\alpha/\\beta } e\\left [ \\left ( \\sum_{i=1}^n c_i^\\beta   \\right)^{\\alpha/\\beta }   \\right ] .\\end{aligned}\\ ] ] the last expectation is finite by assumption ( @xmath556 ) , which completes the proof .",
    "let @xmath557 a.s . , @xmath426 and note that @xmath558 .",
    "then , since @xmath559 and @xmath560 , we can break the expectation as follows @xmath561 & = e\\left [ ( s+q)^\\alpha - s^\\alpha \\right ] + e\\left [ \\left ( \\sum_{i=1}^n c_i r_i \\right)^\\alpha - \\sum_{i=1}^n ( c_ir_i)^\\alpha \\right ] \\\\ & \\leq e\\left [ ( s+q)^\\alpha - s^\\alpha \\right ]   + \\left ( e [ r^{p-1 } ] \\right)^{\\alpha/(p-1 ) }   e\\left [ \\left(\\sum_{i=1}^n c_i \\right)^\\alpha   \\right ] , \\end{aligned}\\ ] ] where the inequality is justified by lemma [ l.alpha_moments ] .",
    "the second expectation is finite since by assumption @xmath118 < \\infty$ ] for any @xmath562 .",
    "for the first expectation we use the inequality @xmath563 for any @xmath564 .",
    "we apply the second inequality @xmath565 times and then the first one to obtain @xmath566 hence , it follows that @xmath567 \\leq \\alpha^p e[q^\\alpha ] + \\alpha^p\\sum_{i=1}^{p-1 } e[s^{\\alpha - i } q^i].\\ ] ]    to see that each of the expectations involving a product of @xmath568 and @xmath75 is finite let @xmath569 and note that for @xmath570 , @xmath571 \\\\ & = e\\left [ e\\left [ \\left .",
    "\\left (   q^{(p-1)/(\\alpha - p+1 ) } \\sum_{j=1}^n c_j r_j \\right)^{\\alpha - p+1 }   \\right|   { \\bf x } \\right ]   \\right ] \\notag \\\\ & \\leq e\\left [   \\left (   e\\left [ \\left .",
    "q^{(p-1)/(\\alpha - p+1 ) } \\sum_{j=1}^n c_j r_j    \\right|   { \\bf x } \\right ]   \\right)^{\\alpha - p+1 } \\right ] \\quad \\text{(by jensen 's inequality ) } \\notag \\\\ & = ( e [ r ] ) ^{\\alpha - p+1 } e\\left [   q^{p-1 } \\left ( \\sum_{j=1}^n c_j     \\right)^{\\alpha - p+1 } \\right ] , \\label{eq : prodmoments_1}\\end{aligned}\\ ] ] where the last equality was obtained by using the independence of @xmath572 and @xmath534 .    for @xmath573 let @xmath574 and condition on @xmath75 and @xmath534 , respectively , to obtain @xmath575 & = e\\left [ \\left ( s^{\\alpha - i } - \\sum_{j=1}^n ( c_j r_j)^{\\alpha - i } \\right ) q^i \\right ] + e\\left [ q^i \\sum_{j=1}^n ( c_j r_j)^{\\alpha - i }   \\right ] \\notag \\\\ & = e\\left [ q^i e\\left [ \\left .",
    "s^{\\alpha - i } - \\sum_{j=1}^n ( c_j r_j)^{\\alpha - i } \\right| q \\right ] \\right ] + e [ r^{\\alpha - i } ] e\\left [ q^i \\sum_{j=1}^n c_j^{\\alpha - i }   \\right ] \\notag \\end{aligned}\\ ] ] @xmath576 \\right)^{\\frac{\\alpha - i}{q_i - 1 } } e\\left [ \\left . \\left ( \\sum_{j=1}^n c_j \\right)^{\\alpha - i } \\right| q \\right ] \\right ] \\\\ &",
    "\\hspace{5 mm } + e [ r^{\\alpha - i } ] e\\left [ q^i \\left ( \\sum_{j=1}^n c_j \\right)^{\\alpha - i }   \\right ] \\notag \\\\ & = \\left ( \\left ( e[r^{q_i - 1 } ] \\right)^{\\frac{\\alpha - i}{q_i - 1 } } + e[r^{\\alpha - i } ] \\right ) e\\left [     q^i \\left ( \\sum_{j=1}^n c_j \\right)^{\\alpha - i }   \\right ] , \\label{eq : prodmoments_2}\\end{aligned}\\ ] ] where for the inequality we used lemma [ l.alpha_moments ] ( @xmath577 ) and the inequality @xmath578 for any @xmath232 and @xmath246 .",
    "note that all the expectations involving @xmath0 in and are finite since @xmath118 < \\infty$ ] for all @xmath173 by assumption .",
    "next , observe that all the other expectations are of the form @xmath579 $ ] for @xmath580 . to see that these are finite use hlder s inequality with @xmath581 and @xmath582 to obtain @xmath583 & \\leq \\left|\\left|\\left ( \\sum_{j=1}^n c_j \\right)^{\\alpha - i }",
    "\\right|\\right|_q ||q^i||_r \\\\ & = \\left ( e\\left [ \\left ( \\sum_{j=1}^n c_j \\right)^{\\alpha }    \\right ] \\right)^{1/q } \\left ( e \\left [ q^\\alpha \\right ] \\right)^{1/r } < \\infty.\\end{aligned}\\ ] ]",
    "we would like to thank an anonymous referee and matthias meiners for their helpful comments .",
    "p. jagers and u. rsler .",
    "stochastic fixed points involving the maximum . in _ mathematics and computer science _ * iii * ( m. drmota , p. flajolet , d. gardy and b. gittenberger , eds . ) , 325 - 338 .",
    "birkhuser , basel , 2004 ."
  ],
  "abstract_text": [
    "<S> we extend goldie s ( 1991 ) implicit renewal theorem to enable the analysis of recursions on weighted branching trees . </S>",
    "<S> we illustrate the developed method by deriving the power tail asymptotics of the distributions of the solutions @xmath0 to @xmath1 and similar recursions , where @xmath2 is a nonnegative random vector with @xmath3 , and @xmath4 are iid copies of @xmath0 , independent of @xmath2 ; here @xmath5 denotes the maximum operator . </S>"
  ]
}