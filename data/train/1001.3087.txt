{
  "article_text": [
    "we introduce the notion of `` source polarization '' which complements `` channel polarization '' that was studied in @xcite .",
    "one immediate application of source polarization is the design of polar codes for lossless source coding .",
    "lossless source coding using polar codes has already been considered extensively in the pioneering works @xcite and @xcite , which reduced this problem to one of channel polarization using the duality between the two problems .",
    "the approach in this paper is direct and offers an alternative ( primal ) viewpoint .",
    "this paper is restricted mostly to binary memoryless sources .",
    "we indicate in the end briefly the possible generalizations to non - binary sources .",
    "we use the notation of @xcite .",
    "in particular , we write @xmath0 to denote a vector @xmath1 and @xmath2 to denote the sub - vector @xmath3 for any @xmath4 . if @xmath5 , @xmath2 is the null vector .",
    "the logarithm is to the base 2 unless otherwise indicated .",
    "we write @xmath6 to denote a bernoulli random variable ( rv ) with values in @xmath7 and @xmath8 .",
    "the entropy @xmath9 of such a rv is denoted sometimes as @xmath10 .",
    "let @xmath11 be an arbitrary pair of random variables over @xmath12 with @xmath13 and @xmath14 an arbitrary countable set . throughout this section ,",
    "we regard @xmath15 as a memoryless source , with @xmath16 as the part to be compressed and @xmath17 in the role of `` side - information '' about @xmath16 .",
    "we consider a sequence @xmath18 of independent drawings from @xmath15 and write @xmath19 to denote the first @xmath20 elements of this sequence , for any integer @xmath21 .",
    "( 0,0)(4,4 ) ( 0,0)(0,2)2(0,1)(3,1 ) ( 1.5,1)(0,4)1(0,0)(0,2 ) ( 1.5,1)(0,4)1(0,2)0.4(0,2)@xmath22(0,0)0.1    ( -0.5,1)@xmath23 ( -0.5,3)@xmath24 ( 3.5,1)@xmath25 ( 3.5,3)@xmath26    the basic idea of source polarization is contained in the transformation shown in fig .",
    "[ fig1 ] , where `` @xmath27 '' denotes addition mod-2 .",
    "the operation @xmath28 performed by the circuit preserves entropy , _",
    "@xmath29 but is polarizing in the sense that @xmath30 it is easy to show that equalities hold here if and only if @xmath31 equals 0 or 1 . thus ,",
    "unless the entropies at the input of the circuit are already perfectly polarized , the entropies at the output will polarize further .",
    "( 0,0)(7,8 ) ( 0,0)(0,2)4(0,1)(6,1 ) ( 1.5,1)(0,4)2(0,0)(0,2 ) ( 1.5,1)(0,4)2(0,2)0.4(0,2)@xmath22(0,0)0.1 ( 3.5,1)(0,8)1(0,0)(0,4 ) ( 3.5,1)(0,8)1(0,4)0.4(0,4)@xmath22(0,0)0.1 ( 4.5,3)(0,8)1(0,0)(0,4 ) ( 4.5,3)(0,8)1(0,4)0.4(0,4)@xmath22(0,0)0.1 ( -0.3,1)@xmath32 ( -0.3,3)@xmath33 ( -0.3,5)@xmath23 ( -0.3,7)@xmath24    ( 6.3,1)@xmath34 ( 6.3,3)@xmath25 ( 6.3,5)@xmath35 ( 6.3,7)@xmath36    ( 2.5,1.4)@xmath37 ( 2.5,3.4)@xmath38 ( 2.5,5.4)@xmath39 ( 2.5,7.4)@xmath40    figure  [ fig2 ] shows the recursive continuation of the construction to the case where four independent copies of @xmath15 are processed .",
    "the entropy conservation law states that @xmath41 using the chain rule , we may split the output entropy as @xmath42 note that the variables @xmath43 are assigned to the output terminals of the circuit in fig .  [ fig2 ] in a shuffled order .",
    "this is motivated by the observation that , with this ordering , the pair @xmath44 is obtained from two i.i.d .",
    "rvs , namely , @xmath45 , by the same two - by - two construction as in fig .",
    "a similar remark applies to the relationship between @xmath46 and @xmath47 .",
    "these observations lead to the the following inequalities , which are special cases of those in .",
    "@xmath49 there is no general inequality between @xmath50 and @xmath51 .",
    "the conclusion to be drawn is that polarization is enhanced further by repeating the basic construction .    for any @xmath52 , @xmath53 , the general form of the source polarization transformation",
    "is defined algebraically as @xmath54^{\\otimes n } b_n\\ ] ] where `` @xmath55 '' denotes the @xmath56th kronecker power and @xmath57 is the `` bit - reversal '' permutation ( see @xcite ) .",
    "it is easy to check that the transforms in figures  [ fig1 ] and [ fig2 ] conform to @xmath58 .",
    "the main result on source polarization for binary alphabets is the following .",
    "[ theorem : binary ] let @xmath15 be a source as above",
    ". for any @xmath52 , @xmath53 , let @xmath59 then , for any @xmath60 , as @xmath61 , @xmath62\\colon          h(u_i| y^n , u^{i-1})\\in(1-\\delta,1]\\bigr\\}\\right|      } { n } \\to h(x| y)\\ ] ] and @xmath62\\colon          h(u_i| y^n , u^{i-1})\\in[0,\\delta)\\bigr\\}\\right|      } { n } \\to 1-h(x| y).\\ ] ]    we omit the full proof but sketch the idea , which follows the proof of the channel polarization result in @xcite .",
    "the first step is to define a tree random process for tracking the evolution of the conditional entropy terms @xmath63 .",
    "the analysis is aided by an accompanying supermartingale based on the source bhattacharyya parameters . for the basic source @xmath11 ,",
    "this parameter is defined as @xmath64 the source bhattacharyya parameters satisfy the following as they undergo the two - by - two polarization transformation .",
    "let @xmath15 be a source as above , and @xmath65 and @xmath66 two independent drawings from @xmath15 .",
    "then , @xmath67 and @xmath68    we omit the proof of this result since it is very similar to the proof of a similar inequality on channel bhattacharyya parameters given in @xcite .",
    "thus , we have the inequality @xmath69 which is the basis of the bhattacharyya supermartingale .",
    "convergence results about the bhattacharyya supermartingale may be translated into similar results for the entropy martingale through the following pair of inequalities .",
    "[ proposition : zvsh ] for @xmath15 a source as above , the following inequalities hold @xmath70 either both inequalities are strict or both hold with equality . for equality to hold ,",
    "it is necessary and sufficient that @xmath16 conditioned on @xmath17 is either deterministic or ber@xmath71 .",
    "the proof is given in the appendix .",
    "these inequalities serve the purpose of showing that @xmath72 is near 0 or 1 if and only if @xmath73 is near 0 or 1 , respectively .",
    "hence , the parameters @xmath74 and @xmath75 polarize simultaneously .    for coding theorems",
    ", it is important to have a rate of convergence result .",
    "let @xmath15 be a source as above , and let @xmath76 .",
    "for @xmath52 , @xmath53 , let @xmath77 denote a subset of @xmath78 such that @xmath79 and @xmath80 for all @xmath81 and @xmath82 .",
    "we refer to @xmath77 as a `` high - entropy '' ( index ) set of rate @xmath83 and block - length @xmath20 . for the special case where",
    "@xmath17 is absent or unavailable , we write @xmath84 to denote the high - entropy set of @xmath16 only .",
    "when @xmath20 and @xmath83 are clear from the context , we simplify the notation by writing @xmath85 or @xmath86 .",
    "[ thm : rate ] let @xmath15 be a source as above and @xmath87 be fixed . consider a sequence of high - entropy sets @xmath88 .",
    "for any such sequence , any fixed @xmath89 , and asymptotically in @xmath20 , we have @xmath90    we omit the proof , which is covered by the results of @xcite .",
    "let @xmath15 be a source as in the previous section and @xmath19 denote an output block of length @xmath21 produced by this source .",
    "shannon s lossless source coding theorem states that an encoder can compress @xmath19 into a codeword of length roughly @xmath91 bits so that a decoder observing the codeword and @xmath92 can recover @xmath93 reliably , provided @xmath20 is sufficiently large .",
    "we now describe a method based on polarization that achieves this compression bound . in the absence of any side information @xmath92 , the method given here is algorithmically identical to the source coding method proposed in @xcite and @xcite ; however , our viewpoint is different .",
    "instead of reducing the source coding problem to a channel coding problem by exploiting a duality relationship between the two problems , we use direct arguments based solely on source polarization .",
    "fix @xmath52 for some @xmath53 .",
    "fix @xmath87 and a high - entropy set @xmath94 .",
    "_ encoding : _ given a realization @xmath95 , compute @xmath96 and output @xmath97 as the compressed word .",
    "( note that the encoder does not require knowledge of the realization of @xmath92 to implement this scheme . )    _ decoding : _ having received @xmath97 and observed the realization @xmath98 , the decoder sequentially builds an estimate @xmath99 of @xmath0 by the rule @xmath100 where @xmath101 is a likelihood ratio , which can be computed recursively using the formulas : @xmath102 and @xmath103 where @xmath104 and @xmath105 denote , respectively , the parts of @xmath106 with odd and even indices , and @xmath107 equals 1 or -1 according to @xmath108 being 0 or 1 , respectively . having constructed @xmath99 , the decoder outputs @xmath109 as the estimate of @xmath110 .",
    "( it is easy to verify that @xmath111 . )    _ performance : _ the performance of the decoder is measured by the probability of error @xmath112 which can be upper - bounded by standard ( union - bound ) techniques as @xmath113    the following is a simple corollary to theorem  [ thm : rate ] and .    for any fixed @xmath87 and @xmath114 ,",
    "the probability of error for the above polar source coding method is bounded as @xmath115 .    _",
    "complexity : _ the complexity of encoding and that of decoding are both @xmath116 .",
    "the above source coding scheme can be used to design a capacity - achieving code for any binary - input memoryless channel .",
    "let such a channel be defined by the transition probabilities @xmath117 , @xmath118 and @xmath119 .",
    "consider the block coding scheme shown in fig .",
    "[ fig3 ] , where signals flow from right to left . here",
    ", @xmath52 , @xmath53 , is the code block length ; @xmath120 denotes the message vector , @xmath121 the channel input vector , and @xmath92 the channel output vector .",
    "due to memorylessness , @xmath122 for any @xmath123 , @xmath124 .",
    "( 0,0)(10,2 ) ( 1,1)(2,1 ) ( 2,0.2)(4,1.8 ) ( 3,1)@xmath125 ( 4,1)(6,1 ) ( 6,0.2)(8,1.8 ) ( 7,1)@xmath126 ( 8,1)(9,1 ) ( 1,1)0.1 ( 0.8,1)@xmath92 ( 5,1)0.1 ( 5,1.6)@xmath93 ( 9,1)0.1 ( 9.2,1)@xmath120    we turn the triple @xmath127 into a joint ensemble of random vectors by assigning the probabilities @xmath128 for all @xmath129",
    ". under this assignment , @xmath19 may be regarded as independent samples from a source @xmath130 where @xmath131 is the uniform distribution on @xmath7 .",
    "we let @xmath132 denote the symmetric channel capacity and fix @xmath133 .",
    "this implies that @xmath134 .",
    "let @xmath135 denote a high - entropy set of rate @xmath136 for the source @xmath15 .",
    "the following coding scheme achieves reliable communication at rate @xmath83 over the channel @xmath137 .    _",
    "encoding : _ prepare a binary source vector @xmath120 as follows . pick the pattern @xmath138 at random from the uniform distribution and make it available to the decoder ahead of the session . in each round , fill @xmath139 with uniformly chosen data bits .",
    "( thus , @xmath140 bits are sent in each round , for a data transmission rate of roughly @xmath83 . )",
    "encode @xmath120 into a channel codeword by computing @xmath141 and transmit @xmath93 over the channel @xmath137 .",
    "_ decoding : _ having received @xmath92 , use the source decoder of the previous section to produce an estimate @xmath142 of the data bits @xmath143 .    _ analysis : _ the error probability @xmath144 is bounded as @xmath145 for any fixed @xmath89 since the source coding rate is @xmath146 . the complexity of the scheme is bounded as @xmath116 .",
    "_ the above argument reduces the channel coding problem for achieving the symmetric capacity @xmath147 of a binary - input channel @xmath137 to a source coding problem for a source @xmath148 where @xmath131 is uniform on @xmath7 .",
    "this reduction exploits the duality of the two problems .",
    "this dual approach provides an alternative proof of the channel coding results of @xcite .",
    "it also complements the duality arguments in @xcite and @xcite , where the source coding problem for a @xmath149 source was reduced to a channel coding problem for a binary symmetric channel with cross - over probability @xmath150 .",
    "the above source coding method can be easily extended to the slepian - wolf setting @xcite .",
    "suppose @xmath18 are independent samples from a source @xmath15 where both @xmath16 and @xmath17 are binary rvs .",
    "in the slepian - wolf scenario , there are two encoders and one decoder .",
    "fix a block - length @xmath52 , @xmath53 , and rates @xmath151 and @xmath152 for the two encoders .",
    "encoder 1 observes @xmath93 only and maps it to an integer @xmath153 $ ] , encoder 2 observes @xmath92 only and maps it to an integer @xmath154 $ ] .",
    "the decoder in the system observes @xmath155 and tries to recover @xmath19 with vanishing probability of error .",
    "the well - known slepian - wolf theorem states that this is possible provided @xmath156 , @xmath157 , and @xmath158 .",
    "it is straightforward to design a polar coding scheme that achieves the corner point @xmath159 of the slepian - wolf rate region .",
    "fix @xmath160 and @xmath161 . for @xmath52 , @xmath53 , consider a pair of high - entropy sets @xmath162 and @xmath163 .",
    "_ encoding : _ given a realization @xmath95 , encoder 1 calculates @xmath164 and sends @xmath97 to the common decoder .",
    "given a realization @xmath98 , encoder 2 calculates @xmath165 and sends @xmath166 .    _",
    "decoding : _ the decoder first applies the decoding algorithm of section  [ sec : lossless ] to obtain an estimate @xmath167 of @xmath168 from @xmath166 .",
    "next , the decoder applies the same algorithm to obtain an estimate of @xmath110 using @xmath167 ( as a substitute for the actual realization @xmath168 ) and @xmath97 .",
    "we omit the analysis of this scheme since it essentially consists of two single - user source coding schemes of the type treated in section  [ sec : lossless ] .",
    "it is clear that polar coding can achieve all points of the slepian - wolf region by time - sharing between the corner points @xmath169 and @xmath170 .",
    "we should remark that polar coding for slepian - wolf problem was first studied in @xcite , @xcite , and @xcite under the assumptions that @xmath171 , and @xmath172 .",
    "the above approach to slepian - wolf coding reduces the problem to single - user source coding problems .",
    "a direct appoach would be to have each encoder apply polar transforms locally , with encoder 1 computing @xmath58 and encoder 2 computing @xmath173 .",
    "preliminary analyses show that such local operations polarize @xmath174 and @xmath175 not only individually but also in a joint sense .",
    "a detailed study of such schemes is left for future work .",
    "[ theorem : prime ] let @xmath176 be a memoryless source over @xmath177 for some prime @xmath178 . for @xmath53 and @xmath52 , let @xmath179 be @xmath20 independent drawings from the source @xmath16 .",
    "let @xmath58 where @xmath126 is as defined in but the matrix operation is now carried out in gf(@xmath180 ) .",
    "then , the polarization limits in theorem  [ theorem : binary ] remain valid provided the entropy terms are calculated with respect to base-@xmath180 logarithms .",
    "if @xmath180 is not prime , the theorem may fail .",
    "consider @xmath16 over @xmath181 with @xmath182 .",
    "then , it is straightforward to check that @xmath120 has the same distribution as @xmath93 for all @xmath20 . on closer inspection",
    ", we realize that @xmath16 is actually a binary source under disguise .",
    "more precisely , @xmath16 is already polarized over @xmath183 , which is a subfield of @xmath184 , and vectors over this subfield are closed under multiplication by @xmath126 .",
    "the preceding example illustrates the difficulties in making a general statement regarding source polarization over arbitrary alphabets .",
    "if we introduce some randomness into the construction as in @xcite , it is possible to polarize sources over arbitrary alphabets , still maintaining the @xmath116 complexity of the construction .",
    "helpful discussions with e. aolu and s. b. korada are gratefully acknowledged .",
    "this work was supported in part by the scientific and technological research council of turkey ( tbitak ) under contract no .",
    "107e216 , and in part by the european commission fp7 network of excellence newcom++ ( contract no . 216715 ) .",
    "first we prove that @xmath185 for any @xmath6 with equality if and only if @xmath186 .",
    "let @xmath187 , and compute @xmath188 - 4 + 8p,\\ ] ] @xmath189 + 8,\\ ] ] @xmath190.\\ ] ] inspection of the third order derivative shows that @xmath191 is strictly convex for @xmath192 and strictly concave for @xmath193 $ ] .",
    "thus , @xmath194 can have at most one solution in each interval @xmath195 and @xmath196 $ ] . since @xmath194 at @xmath197 ,",
    "the number of zeros of @xmath191 over @xmath198 $ ] is at most three .",
    "thus , @xmath199 can have at most three zeros over @xmath198 $ ] . since @xmath200 for @xmath186",
    ", there can be no other zeros .",
    "n.  hussami , s.  b. korada , and r.  urbanke , `` performance of polar codes for channel and source coding , '' in _ proc .",
    "2009 ieee int .",
    "inform . theory _ , ( seoul , south korea ) , pp .",
    "14881492 , 28 june - 3 july 2009 ."
  ],
  "abstract_text": [
    "<S> the notion of source polarization is introduced and investigated . </S>",
    "<S> this complements the earlier work on channel polarization . </S>",
    "<S> an application to slepian - wolf coding is also considered . </S>",
    "<S> the paper is restricted to the case of binary alphabets . </S>",
    "<S> extension of results to non - binary alphabets is discussed briefly .    </S>",
    "<S> polar codes , source polarization , channel polarization , source coding , slepian - wolf coding . </S>"
  ]
}