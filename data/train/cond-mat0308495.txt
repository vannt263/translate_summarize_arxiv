{
  "article_text": [
    "monte carlo ( mc ) simulations are powerful numerical tools for high - precision studies of many - body systems , both in the classical and quantum regime . especially near second - order phase transitions , where physical length scales diverge",
    ", it is essential to simulate large systems , which has become possible due to significant algorithmic advances within the last 15 years .    in classical simulations , conventional mc algorithms sample the canonical partition function by making local configurational updates .",
    "while being straightforward , this approach turns out to slow down simulations near phase transitions and gives rise to long autocorrelation times in the measurement of the relevant physical observables . for classical spin - like systems , this",
    "critical slowing down can be overcome using cluster algorithms  @xcite , which update large clusters of spins in a single mc step .",
    "the generalization of these non - local update schemes to the case of quantum monte carlo ( qmc ) simulations was initiated by the development of the loop algorithm in the world - line representation  @xcite .",
    "this very efficient method has been used in many studies , where it allowed the simulation of large systems at very low temperatures . in the original formulation ( either in discrete  @xcite or continuous  @xcite imaginary time ) , the loop algorithm however has a major drawback : to work efficiently , its application is restricted to specific parameter regimes . in the case of quantum spin models for example , it suffers from severe slowing down upon turning on a magnetic field  @xcite .",
    "this problem can be circumvented by performing cluster constructions in an extended configuration space , which includes world line configurations with two open world line fragments  @xcite , representing physical operators inserted into a mc configuration .",
    "the resulting worm algorithm  @xcite proceeds by first creating a pair of open world line fragments ( a worm ) .",
    "one of these fragments is then moved through space - time , using local metropolis or heat bath updates until the two ends of the worm meet again .",
    "this algorithm thus consists of only local updates of worm ends in the extended configuration space , but can perform non - local changes in the mc configurations .",
    "the cluster generation process of the worm algorithm allows for self intersections and backtracking of the worm , which might undo previous changes . while not being as efficient as the loop algorithm in cases with spin - inversion or particle - hole symmetry ,",
    "the great advantage of the worm algorithm is that it remains efficient in an extended parameter regime , e.g. in the presence of a magnetic field for spin models  @xcite .",
    "an alternative qmc approach , which is not based upon the world - line representation , is the stochastic series expansion ( sse )  @xcite , a generalization of handscomb s algorithm @xcite for the heisenberg model .",
    "while in the original implementation  @xcite local mc updates were used , sandvik later developed a cluster update , called the operator - loop update for the sse representation  @xcite , which allows for non - local changes of mc configurations . within this sse approach",
    "one can efficiently simulate models for which the world line loop algorithm suffers from a slowing down .",
    "furthermore , loop algorithms are recovered in models with spin - inversion or particle hole symmetry  @xcite .",
    "in fact the two approaches , world - line and sse qmc are closely related  @xcite .",
    "recently , it has been realized that the rules used to construct the operator - loops in the original implementation  @xcite , were just one possible choice and that one can consider generalized rules , which give rise to more efficient algorithms  @xcite .",
    "this new approach led to the construction of the `` directed loop '' update scheme by syljusen and sandvik , first for spin-@xmath0 systems  @xcite .",
    "later it was adapted to general spin-@xmath1 models by harada and kawashima through a coarse - grained picture of the loop algorithm  @xcite . using a holstein - primakov transformation of the large spin-@xmath1 algorithm , a coarse - grained loop algorithm for softcore bosonic models",
    "was also developed  @xcite .",
    "the improvements achieved using the directed loop approach have been demonstrated in various recent studies  @xcite . for a recent review of non - local updates in qmc ,",
    "see ref .  @xcite .    in this work ,",
    "we show that the equations which determine the directed loop construction allow for additional weight factors , which were not considered by syljusen and sandvik  @xcite or used in  @xcite .",
    "we explain how these weight factors naturally arise from a formulation of the directed loop construction within the extended configuration space . instead of viewing",
    "the worm ends as link discontinuities  @xcite we consider them to represent physical operators with in general non - unity matrix elements  @xcite . taking these natural weight factors into account , and numerically optimizing solutions to the generalized directed loop equations , we are able to construct algorithms which display larger regions in parameter space where the worm propagation is bounce free , i.e. a worm never backtracks .",
    "this numerical approach allows for the implementation of directed loop algorithms in a generic qmc simulation code , which is not restricted to specific models .",
    "in particular , it provides directed loop algorithms for spin-@xmath1 and softcore boson systems directly using the numerical solution , without coarse graining , or using the split - spin representation and holstein - primakov transformation  @xcite .    performing simulations and calculating autocorrelation times of different observables , we find that minimizing bounces does not necessarily imply more efficient algorithms . in certain cases ,",
    "the generalized directed loop algorithm presented in this paper has superior performances to the standard directed loop scheme , but in other cases it does not .",
    "we identify the non - uniqueness of bounce minimized solutions as the source of this observation : in the general case there are many solutions to the directed loop equations with minimal bounces , which however do not lead to the same performance of the algorithm .    to further improve the algorithm , we thus propose various _ additional _ strategies , which select out certain solutions in the subset of those which minimize bounces .",
    "these additional strategies can also be used in the standard directed loop approach . calculating again autocorrelation times with these different strategies",
    ", we indeed find that the efficiency can be further improved largely .",
    "however , we find that the specific strategy that gives rise to the best performances depends on the specific hamiltonian and on the observable of interest .",
    "the conclusion we reach from these results is that in most cases short simulations on small systems are needed in order to identify the optimal strategy before performing production runs .    throughout this work ,",
    "we use the sse qmc scheme  @xcite in order to present our framework , since it appears to be the more natural approach to many problems .",
    "however , the ideas presented here can as well be implemented within the path integral approach  @xcite .",
    "the outline of the paper is as follows : we review in section  [ sec : sse ] the sse method and the operator - loop update scheme .",
    "then we introduce the generalized directed loop equations in in section  [ sec : dir.loops ] . in section  [ sec : num ] we show how to numerically solve these equations in order to obtain directed loop schemes with minimized bounces using linear programming techniques . in section  [ sec : phased ]",
    "we present algorithmic phase diagrams obtained within the framework proposed here , and compare them with those obtained using previous directed loop schemes .",
    "we discuss in section  [ sec : auto ] results on autocorrelation times obtained from the simulation of the magnetization process of various quantum spin chains .",
    "our results indicate , that minimizing bounces alone does not necessary lead to reduced autocorrelations of physical observables .",
    "we therefore introduce in sec .",
    "[ sec : strat ] supplementary strategies in order to improve the performance of directed loop algorithms , and present autocorrelation times obtained using these additional strategies .",
    "we finally conclude in sec .",
    "[ sec : conc ] .",
    "the sse qmc method was first introduced by sandvik and kurkijrvi @xcite . in this original implementation local mc updates schemes",
    "were employed .",
    "later sandvik developed the operator - loop update  @xcite , which has recently been improved by employing the idea of directed loops @xcite . before discussing our scheme , which steams from an extension of these ideas , we review in this section the formulation of the sse method , and the extended configuration space interpretation of the operator - loop update .    to develop the sse qmc scheme , we start from a high temperature series expansion of the partition function @xmath2 where @xmath3 denotes the hamiltonian and @xmath4 a hilbert space basis of the system under consideration .",
    "the sse approach aims to develop an importance sampling framework for the terms contributing to the partition function for a given temperature @xmath5 .",
    "the resulting monte carlo scheme can be applied to a large variety of hamiltonians , including multiple - particle exchange and long - ranged interaction terms . here",
    "we restrict ourselves to models with on - site and short - ranged two - site interactions in order to simplify the following discussion .",
    "the hamiltonian can then be decomposed into a sum of bond hamiltonians @xmath6 where each term @xmath7 is associated with one of the @xmath8 bonds of the lattice , @xmath9 , connecting lattice sites @xmath10 and @xmath11 .",
    "we assume that all contributions to @xmath3 involving on - site terms have been expressed as additional two - site terms within the @xmath7 .",
    "for example , a chemical potential term for two sites , @xmath12 and @xmath13 , can be added to @xmath14 as @xmath15 , with suitable constants @xmath16 , assuring the sum over all such terms recovers the initial sum .    inserting this decomposition of the hamiltonian into the partition function we obtain @xmath17 where @xmath18 denotes the set of all concatenations of @xmath19 bond hamiltonians @xmath7 ,",
    "each called an operator string .",
    "we have furthermore inserted sets @xmath20 of hilbert space basis vectors between each pair of consecutive bond hamiltonians .",
    "therefore @xmath20 is the state that results after applying the first @xmath21 bond hamiltonians in the operator string to the initial state @xmath22 : @xmath23 furthermore @xmath24 , reflecting the periodicity in the propagation direction . in the following we also denote by @xmath25 the local state at site @xmath26 given the state vector @xmath20 , so that @xmath27 , where @xmath28 denotes the number of lattice sites .    for a finite system and at finite temperature",
    "the relevant exponents of this power series are centered around @xmath29 hence we can truncate the infinite sum over @xmath19 at a finite cut - off length @xmath30 without introducing any systematic error for practical computations .",
    "the best value for @xmath31 can be determined and adjusted during the equilibration part of the simulation , e.g. by setting @xmath32 after each update step .    in order to retain a constant length of the operator strings in the truncated expansion of eq .",
    "( [ sec2_3 ] ) we insert @xmath33 unit operators @xmath34 into every operator string of length @xmath35 , and define @xmath36 .",
    "taking the number of such possible insertions into account , we obtain @xmath37 where @xmath19 now denotes the number of non - unity operators in the operator string @xmath38 .",
    "each such operator string is thus given by an index sequence @xmath39 , where on each propagation level @xmath40 either @xmath41 for an unit operator , or @xmath42 for a bond hamiltonian .    instead of evaluating all possible terms in the expansion of eq .",
    "( [ sec2_5 ] ) , in a sse qmc simulation one attempts to importance sample over all contributions to eq .",
    "( [ sec2_5 ] ) according to their relative weight . in order to interpret these weights as probabilities , all the matrix elements of each bond",
    "hamiltonian @xmath7 should be positive or zero . concerning the diagonal part of the hamiltonian",
    ", one can assure this by adding a suitable constant c to each bond hamiltonian .",
    "the constant @xmath43 can be decomposed as @xmath44 , where @xmath45 is the minimal value for which all diagonal matrix elements are positive , and an additional offset @xmath46 .",
    "the effects of a finite value for @xmath47 on the efficiency of the sse algorithm will be discussed in section [ sec : phased ] .    for the non - diagonal part of the hamiltonian an equally simple remedy does not exist . however , if only operator strings with an even number of negative matrix elements have a finite contribution to eq .",
    "( [ sec2_5 ] ) , the relative weights are again well suited to define a probability distribution .",
    "one can show that this is in general the case for bosonic models , ferromagnetic spin models , and antiferromagnetic spin models on bipartite lattices .    given the positivity of the relative weights ,",
    "one then has to construct efficient update schemes , that generate new configurations from a given one . within sse simulations that employ operator - loop updates ,",
    "each monte carlo step consists of two parts .",
    "in the first step attempts are made to change the expansion order @xmath19 by inserting and removing the number of unit operators . during this update step ,",
    "all propagation levels @xmath40 are traversed in ascending order . if the current operator is an unit operator @xmath48 it is replaced by a bond hamiltonian with a certain probability which guarantees detailed balance .",
    "the reverse process , i.e. substitution of a bond hamiltonian by a unit operator is only attempted if the action of the current bond hamiltonian does not change the propagated state , i.e. , if @xmath49 , since otherwise the resulting contribution to eq .",
    "( [ sec2_5 ] ) would vanish .",
    "the acceptance probabilities for both substitutions , as determined from detailed balance , are @xmath50,\\\\\\nonumber p(h_b\\!\\rightarrow \\ !",
    "h_0)\\!\\ ! & = & \\!\\ !",
    "\\min\\left[1 , \\!\\frac{(\\lambda - n+1 ) \\delta_{|\\alpha(p)\\rangle,|\\alpha(p-1)\\rangle}}{m\\beta\\langle",
    "\\alpha(p )    | h_b | \\alpha(p-1 ) \\rangle}\\right].\\end{aligned}\\ ] ]    the second part of a mc update step consists of performing a certain fixed number of operator - loop updates , modifying the configuration obtained from the preceding diagonal update . keeping the expansion order @xmath19 unchanged , attempts are made to change the intermediate state vectors @xmath20 .",
    "most importantly , the employed cluster updates significantly reduce autocorrelations between successive mc configurations .",
    "the operator - loop update makes use of a representation for the operator string @xmath38 as a quadruply - linked list of vertices , each vertex being associated with a non - unity operator in the operator string . to construct this representation , consider a propagation level @xmath21 with a corresponding bond hamiltonian @xmath51 .",
    "since the bond @xmath52 connects two - lattice sites @xmath53 and @xmath54 , we can represent it by a four - leg vertex , where the legs carry the local states on sites @xmath53 and @xmath54 , given by @xmath55 , respectively @xmath56 before , and by @xmath57 , respectively @xmath58 after the action of the bond hamiltonian @xmath51 , see fig .",
    "[ fig : vertex ] .",
    "we denote the direct product of the four states on the legs of a vertex by @xmath59 so that on the propagation level @xmath21 the vertex state is @xmath60 of a vertex with an associated bond @xmath61 , we define the weight of this vertex by @xmath62 where @xmath63 is the restriction of the bond hamiltonian @xmath7 , acting on the states at sites @xmath10 and @xmath11 . with this definition ,",
    "the vertex weight for a vertex at propagation level @xmath21 equals its contribution to the matrix element in eq .",
    "( [ sec2_5 ] ) , @xmath64     is equal to the direct product of the local states on its four legs : @xmath65.,width=264 ]    for each leg @xmath66 of the vertex at propagation level @xmath21 there is a leg @xmath67 of another vertex at some propagation level @xmath68 , for which there is no other vertex in between the propagation levels @xmath21 and @xmath68 acting on the corresponding site of the lattice . in particular , for a leg @xmath69 @xmath70 , we find the corresponding leg , by moving along the decreasing ( increasing ) propagation levels , until we find the first vertex and leg @xmath67 , corresponding to the same lattice site . doing so , the periodic boundary of the propagating state must be taken into account , so that upon moving beyond @xmath71 we return at @xmath72 .",
    "each leg then has an outgoing and incoming link , such obtaining a bidirectional linked list for the vertices .",
    "in fact , this vertex list contains the complete information about the operator string .",
    "the operator - loop update performs changes in this vertex list along closed loops , resulting in a new operator string and basis state , i.e. a new mc configuration .",
    "each operator - loop results from the stepwise construction of a closed path through the vertex list , which represents changes on the leg states and the bond - operator content of the visited vertices . for the remainder of this work we call the path generated in the vertex list a _ worm _ , which upon closure constitutes the operator - loop .    during construction",
    "the worm is extended at one end , called the _ head _ , whereas the other end ( called _ tail _ ) remains static  @xcite .",
    "the body of the worm represents part of the new configuration .",
    "the goal of the following discussion is to find rules for the motion of the worm head , which lead to efficient updates of the operator string . in analogy with the worm algorithm  @xcite",
    "we think of each intermediate worm configuration as being defined in an extended configuration space , which includes operator strings that in addition to bond - operators contain source terms for the worm ends .",
    "for example , in a bosonic model these would be the operators @xmath73 or @xmath74 , which decrement or increment the local occupation number .",
    "for spin models , these operators would be @xmath75 and @xmath76 .",
    "in fact , this interpretation suggests to associate weight factors to both the creation ( insertion ) and closure ( removal ) of the worm , as well as the motion of the worm head , depending on the action of the corresponding operators ( @xmath73 and @xmath74 in the bosonic example ) .    : ( a ) insertion of a pair @xmath77 , ( b ) insertion of a pair @xmath78.,width=188 ]    within this view the creation of a worm corresponds to the insertion of two operators , which we denote @xmath79 and @xmath80 ( @xmath81 being the hermitian conjugate of @xmath79 ) .",
    "one operator stands for the worm head , the other the tail .",
    "we choose to insert these two operators randomly , either as @xmath77 ( fig .",
    "[ fig : insert.pair]a ) or as @xmath78 ( fig .",
    "[ fig : insert.pair]b ) at a random point in the operator list , between two ( non - identity ) vertices with a certain probability , which will be specified below .",
    "furthermore , the state of the vertex legs at the insertion point is denoted @xmath82 .",
    "then we randomly choose to move one of the two operators , which thus becomes the head of the worm .",
    "the other operator remains at the insertion position , constituting the worm s tail .",
    "the worm head is associated with a transformation @xmath83 acting on the state @xmath82 along the direction of propagation , so that @xmath82 is changed to @xmath84 , where @xmath85 denotes the normalized state  @xcite @xmath86    .",
    "( a ) the operator @xmath79 is moved _ upwards _ in propagation direction . as a result ,",
    "the transformation induced on the state @xmath87 is @xmath88 ( the new state is @xmath89 ) .",
    "( b ) the operator @xmath80 is moved _ downwards _ in negative propagation direction .",
    "the transformation induced on the state @xmath87 is again @xmath88 ( the new state being @xmath89 ) . dashed horizontal lines indicate where the operators were before they were moved.,width=264 ]    for example , consider the case where we insert a pair @xmath78 ( fig .",
    "[ fig : insert.pair]b ) .",
    "if we choose to move the operator @xmath79 along the positive direction of propagation , this corresponds to the case where a transformation @xmath88 operates on the state @xmath82 in the positive propagation direction ( fig .",
    "[ fig : first.move]a ) .",
    "if we choose to instead propagate the operator @xmath80 in the negative direction , this corresponds to a transformation @xmath88 on the state @xmath82 , but now in the negative direction of propagation ( fig .",
    "[ fig : first.move]b ) .",
    "more generally speaking , the transformation @xmath90 performed on the state depends on the propagated operator @xmath91 , and on its direction of propagation in the following way : @xmath92    a proposed insertion of the worm ( the pair of operators ) is accepted with a probability @xmath93 , which depends on the effective transformation @xmath83 and the state @xmath82 .",
    "this insertion probability is determined by the requirements of detailed balance , and will be discussed in section [ subsec : insertionprobabilities ] .",
    "once these initial decisions are made , the worm head is propagated to the next ( non - identity ) vertex @xmath94 in the operator string along the current direction of propagation .",
    "the worm enters vertex @xmath94 on the entrance leg @xmath95 $ ] , which is currently in the state @xmath82 before the passage of the worm , and will be modified to @xmath96 by the action of the worm head . at the vertex @xmath94 the worm chooses an exit leg @xmath97 according to certain probabilities as discussed in the next section .",
    "depending on the particular exit leg @xmath97 ( i ) the direction of the worm s propagation may change , ( ii ) the operator corresponding to the worm head may be hermitian conjugated ( @xmath98 ) or stay the same ( @xmath99 ) , and as a consequence of ( i ) , ( ii ) , and eq .",
    "( [ eq : at ] ) the type of transformation performed by the worm head may be inverted ( @xmath100 ) or remain unchanged ( @xmath101 ) .",
    "we denote the new operator that is carried by the worm head after passage of @xmath94 by @xmath102 , and the corresponding transformation @xmath103 .",
    "the state of the exit leg @xmath97 is denoted @xmath104 before the passage of the worm , and @xmath105 after the worm action .    for general models the modifications ( i ) and ( ii ) can occur independently . for a model with conservation laws ( e.g. of the number of particles for bosonic models or of magnetization for spin models ) , these lead to the following restriction : if the direction of propagation stays constant , the operator remains the same , so that @xmath106 .",
    "otherwise it is inverted , i.e. @xmath107 .",
    "after the worm head leaves the first vertex @xmath94 from the exit leg @xmath97 it continues on to the second vertex @xmath108 , entering on leg @xmath109 .",
    "this inter - vertex propagation of the worm head proceeds along the connections within the quadruply - linked vertex list .",
    "the state on leg @xmath109 before the worm passes through is @xmath110 , and will be transformed to @xmath111 upon passage .",
    "the worm head leaves @xmath108 from exit leg @xmath112 , where the leg state changes from @xmath113 to @xmath114 , @xmath115 being the transformation which corresponds to the new operator @xmath116 associated with the worm head after it passed @xmath108 .",
    "[ fig : insert.pair]b ) , and the first move the propagation of @xmath79 upward in propagation direction ( fig .",
    "[ fig : first.move]a ) , so that the initial transformation is @xmath88 .",
    "( a ) for a bounce loop , the final transformation @xmath117 .",
    "( b ) for a normal loop , the final transformation @xmath118 .",
    "the dashed horizontal line indicates the initial position of the operator @xmath79.,height=264 ]    this process continues until the worm exits a vertex @xmath119 from a leg @xmath120 , and from there returns to the insertion point .",
    "there are two possibilities for the worm head to approach the insertion point : either the final transformation @xmath121 is the same as @xmath83 , or @xmath117 . in the first case we call the resulting operator - loop a `` normal '' loop , otherwise a `` bounce '' loop ( fig .",
    "[ fig : endings ] ) .",
    "the bounce loop corresponds to the case in which the order of the operators after the return of the head to the tail has the same orientation as directly after insertion ( fig .",
    "[ fig : endings]a ) . for a normal loop",
    "the relative order of the operators is inverted ( fig .",
    "[ fig : endings]b ) .    in the method presented there , the worm always stops when it has reached its starting point .",
    "we note that there are other schemes  @xcite where the worm does not necessary do so , but continues with a certain probability . in section  [ sec : stop ] , we discuss the efficiency of our choice .",
    "for the actual construction of the operator - loop we need to specify the probabilities for choosing exit legs at each visited vertex . in this section ,",
    "we focus on how to derive generalized equations for these probabilities .",
    "consider a worm entering a vertex @xmath122 , which is entirely specified by the values of the states at its four legs , as well as the lattice - bond @xmath123 corresponding to this vertex ( here @xmath123 denotes the bond type of the @xmath26th vertex ) .",
    "the state of the vertex before the entrance of the worm is @xmath124 ) .",
    "the worm enters @xmath122 from the entrance leg @xmath125 , and exits from leg @xmath126 .",
    "the states at these legs before the worm passes are denoted @xmath127 and @xmath128 , respectively , i.e. @xmath129 , and @xmath130 .",
    "both states are changed by the worm s passage , and become @xmath131 and @xmath132 , respectively .",
    "correspondingly , the total state of this vertex becomes @xmath133 , where @xmath134 except for @xmath135 , and @xmath136 .",
    "we define @xmath137 to be the conditional probability of exiting on leg @xmath126 , given that the worm head enters on leg @xmath125 .",
    "this `` scattering '' probability can in general depend on the bond type @xmath123 , the transformation of the worm head before ( @xmath138 ) and after ( @xmath139 ) passing @xmath122 , the state @xmath140 , and on the actual path of the worm through this vertex , i.e. the legs @xmath125 and @xmath126 . for a model with conservations laws , @xmath139 is implicitly given by @xmath138 and @xmath125 and @xmath126 , as discussed in the previous section . for clarity",
    "we illustrate our notations in figs .",
    "[ fig : worm1 ] and  [ fig : worm2 ] .",
    "what are the possible values for the scattering probabilities so that the resulting operator - loop construction fulfills detailed balance ? in the original operator - loop implementation  @xcite , sandvik showed that a generic solution for any model is to set @xmath141 proportional to @xmath142 , i.e. the weight of the vertex after the passage of the worm ( this solution is often referred to as the heat - bath solution ) .",
    "however , this choice turns out to be inefficient in many cases , because of `` bounce '' processes ( i.e. the worm head exits a vertex from the same leg from which it entered the vertex )  @xcite .",
    "an algorithm which minimizes the number of these bounce processes is often more efficient  @xcite . in this context ,",
    "syljusen and sandvik proposed the `` directed loop '' update  @xcite , with probabilities @xmath137 chosen as to minimize or even eliminate bounces .",
    "these probabilities are derived analytically for spin-@xmath0 models in ref .",
    "@xcite , and a more general framework to obtain them is given in ref .",
    "@xcite .",
    "the optimization ( with respect to the bounce minimization ) of the scattering probabilities has to be performed under the constraint of fulfilling detailed balance for the resulting operator - loop update .",
    "syljusen and sandvik showed that in order to fulfill detailed balance of the directed - loop update the following condition on the scattering probabilities is sufficient : @xmath143 which we refer to as the _ local _ detailed balance condition , since it demands detailed balance during each step of the worm head propagation .",
    "the original algorithm by sandvik  @xcite , where @xmath144 , obviously fulfills this condition . with this choice",
    ", the probabilities do not depend on the entrance leg @xmath125 .",
    "this is not true for the bounce - minimized solution , which by definition results in direction - dependent scattering probabilities for the directed loop update .",
    "the idea behind the work presented here is to consider the motion of the worm head in the extended configuration space .",
    "we show that this leads to a general set of equations for the scattering probabilities , which also guarantee detailed balance .",
    "these generalized equations have solutions that allow us to further reduce the bounce probabilities , and to even eliminate bounces in large regions of parameter space .",
    "if we consider the worm construction process in the extended configuration space , it appears natural to view the worm head as an operator acting on the local states of the world - line configuration , and to assign the corresponding matrix element as an additional weight factor to its propagation .",
    "the worm head matrix element is @xmath145 .",
    "let us denote by @xmath146 the additional worm weight factor that will be used in the generalized equations . here",
    "@xmath90 denotes the transformation corresponding to the worm head , and @xmath87 the local state of the world - line configuration , where the worm head acts . even though @xmath147 is _",
    "always _ equal to the worm head matrix element in the scheme presented in this paper , we use this notation such that one can recover the standard directed loop framework by putting @xmath147 equal to @xmath148 in all equations given below .    with this definition of @xmath147 , the following hermiticity condition",
    "is then fulfilled for all @xmath90 and @xmath87 : @xmath149 we also denote the weight of the worm head before it enters the vertex @xmath122 by @xmath150 , depending on both the transformation @xmath138 and the state @xmath127 . in the extended configuration space ,",
    "the local detailed balance equation then reads : @xmath151 which constitutes our generalized directed loop equation .",
    "note that we recover the previous scheme of syljusen and sandvik upon setting @xmath152 for all @xmath90 and @xmath87 in this equation and in those given below . in the following section",
    ", we prove that eq .",
    "( [ my.dl.eq ] ) indeed guarantees detailed balance of the operator - loop update , as long as the worm weight @xmath147 fulfills the hermiticity condition , eq .",
    "( [ eq : f.hermit ] ) .",
    "the following proof of detailed balance uses the _ worm_/_antiworm _ construction principle  @xcite .",
    "we first calculate the probability to create a worm @xmath153 , hitting @xmath154 vertices before coming back to the insertion point :    @xmath155    where @xmath156 denotes the uniform probability of choosing the insertion point in the operator string .",
    "now we consider an _ antiworm _ @xmath157 , traversing exactly the path created by @xmath153 but in the reverse direction .",
    "the antiworm acts on the configuration that has been obtained _",
    "after _ passage of the worm @xmath153 .",
    "the antiworm thus completely undoes the action of the worm @xmath153 , leading back to the configuration prior to the insertion of the worm @xmath153 .",
    "the antiworm is inserted at the same place as @xmath153 , and its initial head operator is exactly the inverse of the last worm head operator , so that its insertion probability is @xmath158 . the probability to create",
    "the antiworm is thus    @xmath159    the ratio of the two probabilities is @xmath160 using eq .",
    "( [ my.dl.eq ] ) , we obtain @xmath161 since @xmath162 we obtain , using eq .",
    "( [ eq : f.hermit ] ) , @xmath163 for all @xmath164 . for a `` normal '' loop , we furthermore have @xmath118 and @xmath165 , so that @xmath166 again using eq .",
    "( [ eq : f.hermit ] ) . in case of a `` bounce '' loop , where @xmath117 and @xmath167 , we obtain the same relation , since @xmath168    the factors of @xmath147",
    "thus exactly cancel each other in the numerator and denominator of eq .",
    "[ eq : intermediate ] , and we obtain @xmath169 detailed balance is thus fulfilled , provided @xmath170    for a `` bounce '' loop , where @xmath171 and @xmath172 , this condition is always fulfilled . in case of a `` normal '' loop , where @xmath118 and @xmath173 , we need for eq .",
    "( [ eq : above.cond ] ) to hold , that @xmath174 in other words , the probability to insert ( at the same place ) an antiworm that will undo exactly what a worm just did must be equal to the probability used to insert this original worm . if this condition is fulfilled for all transformations @xmath83 and all possible states @xmath82 , we obtain a detailed balanced operator - loop update .",
    "let us be more specific now , and discuss the kind of operators @xmath79 that can be used as operator insertions , and which corresponding insertion probabilities fulfill eq .",
    "( [ eq : insert.condition ] ) .",
    "we focus on two cases : quantum spin-@xmath1 and softcore bosonic systems .    for a quantum spin-@xmath1 system , the local state at a given site",
    "is given by the projection of the spin value at that site , e.g. onto the @xmath175 axis .",
    "we denote this projection by @xmath176 which can take @xmath177 values in the range @xmath178 .    for bosonic systems ,",
    "the local state is given by the number @xmath19 of bosons at the site .",
    "if we truncate the hilbert space by restricting the number of bosons per site to a maximum value @xmath179 , @xmath19 can take integer values in the range @xmath180 .",
    "what are the possible operators @xmath79 to be used in the operator pair insertion for these models ? in many cases ,",
    "a good choice is to construct so called @xmath181 worms : a @xmath182 ( @xmath183 ) worm head acting on state @xmath87 changes it to @xmath184 ( @xmath185 ) .",
    "the operators @xmath79 associated with the worm ends are then simply the creation ( annihilation ) operators @xmath186 ( @xmath187 ) for bosons , and the ladder operators @xmath188 ( @xmath189 ) for spins , respectively .      for @xmath181 worms , eq .",
    "( [ eq : insert.condition ] ) becomes @xmath190 in the case of bosonic models and @xmath191 for spin models .",
    "for a spin-@xmath1 model , we can not insert a @xmath182 ( @xmath183 ) worm onto a given initial state with @xmath192 ( @xmath193 ) .",
    "since we always want to create a worm in all other cases , we propose the following insertion probabilities : @xmath194 if @xmath195 , we use @xmath196 instead , so always inserting a worm .    for a softcore bosonic model limiting the maximum number of bosons per site to @xmath179 , we equivalently use :    @xmath197    for hardcore bosons ( @xmath198 ) , we instead use @xmath199 and @xmath200 , thus always inserting a worm .",
    "these insertion probabilities differ from the weight assigned to the operators in the extended configuration space , namely the matrix elements of these operators ( see subsection  [ subsec : wormweight ] ) . as suggested in ref .",
    "@xcite , it is possible to set @xmath201 proportional to @xmath145 , similar to the worm algorithm  @xcite .",
    "indeed , this choice satisfies eq .",
    "( [ eq : insert.condition ] ) .      in the extended configuration space , where the worm head is associated with an operator acting on the local state in the world - line configuration , the worm weights are equal to the matrix elements , @xmath202 .    to be more specific , consider employing @xmath181 worms for a spin model",
    ". then @xmath90 can be @xmath188 or @xmath189 , so we obtain @xmath203    for a bosonic model with @xmath181 worms , @xmath90 is either @xmath187 or @xmath186 and thus @xmath204    we note , that the operators used here ( corresponding to @xmath181 worms ) are not unique , as we can for example also employ @xmath205 or @xmath206 worms .",
    "it is also possible that other choices of weights such that @xmath147 is not equal to @xmath207 might lead to more efficient algorithms . indeed , in the proof of detailed balance , the only requirement on @xmath147 is eq .",
    "( [ eq : f.hermit ] ) . however , the above choices naturally appear within the extended configuration space , and lead to algorithms with less bounces , as will be shown below .",
    "we propose to always close a worm when the worm head returns to the insertion point .",
    "it is possible , as noted in references  @xcite , to not necessary do so , but to offer the worm the possibility to continue depending on the value of the final state . as a consequence ,",
    "the worm insertion probabilities need to be changed accordingly , in order to retain detailed balance .",
    "it is not a priori clear which approach results in a more efficient algorithm",
    ". only precise studies of autocorrelation times could answer this question for each specific model and set of parameters , which is however well beyond the scope of this work .",
    "instead we present an intuitive argument , why we expect closing worms immediately to be more efficient :    the goal of using worm updates is the generation of large non - local changes in each mc configuration , in order to decorrelate two consecutive measurements",
    ". a precise quantification of this decorrelation effect in terms of cpu time must take into account the worm size .",
    "making a long worm and thus obtaining large decorrelation effects should grossly be equivalent to making two short worms with only half the decorrelation .",
    "however , if after the first encounter of the initial point the worm has already resulted in large enough decorrelation , it becomes less meaningful to continue this worm , as we can already perform an independent measurement instead of spending more cpu time for the construction of a longer worm .      with the above choices , the measurement of green s functions during the worm construction needs to be slightly modified in order to account for the presence of the explicit worm weights in the worm s propagation . for a detailed account on how the green s functions measurements are performed using heat bath and standard directed loops with the insertion and stopping probabilities of sec .",
    "[ subsec : insertionprobabilities ] , and [ sec : stop ] respectively , we refer to ref .",
    "@xcite . here ,",
    "we only summarize the main point : in the standard directed loop algorithm , the value of the green s function measurement for a given distance ( in space and imaginary time ) between the worm head and the worm tail equals the product of the matrix element of the operator inserted at the head of the worm ( which would be in our notations @xmath145 , where @xmath90 denotes again the transformation corresponding to the worm head , and @xmath87 the local state of the world - line configuration , onto which the worm head acts ) times the matrix element inserted at its tail ( in our notations @xmath208 , where @xmath83 denotes the transformation corresponding to the ( static ) worm tail , and @xmath209 the local state of the world - line configuration , onto which the worm tail acts ) . for a detailed graphical illustration of this measurement process",
    "we refer to ref .",
    "the only modification to this scheme , which arises from using generalized directed loops is as follows : in the generalized directed loop algorithm , the propagation of the worm head fulfills detailed balance in the extended configuration space .",
    "the worm head s matrix elements are thus taken into account in the probability to obtain a given configuration ( in space and imaginary time ) between the worm head and the worm tail .",
    "therefore , in the generalized directed loop algorithm the value of the green s function measurement equals @xmath210 .",
    "note , that this is independent of @xmath90 and @xmath87 , and involves only the value of the matrix element @xmath211 from the static worm tail .",
    "the green s function measurement in the generalized directed loop algorithm thus requires significantly less evaluations of matrix elements , or accesses to their look - up table .",
    "if one would furthermore choose @xmath212 proportional to @xmath208 , similar to the worm algorithm  @xcite discussed in sec .",
    "[ subsec : insertionprobabilities ] , the value of each green s function measurement would be equal to @xmath148 , as for the worm algorithm  @xcite .",
    "in fact , this way the matrix elements of both the worm head and tail would be accounted for explicitly during the construction of the worm and its propagation .",
    "in the preceding sections we derived generalized conditions on the scattering probabilities @xmath141 , which describe the motion of the worm head at each vertex during the worm construction .",
    "we now look for solutions of eq .",
    "( [ my.dl.eq ] ) , for which the bounce probability for each possible vertex configuration is as small as possible .",
    "we expect this to lead to an optimal algorithm in terms of autocorrelation times . here",
    ", we explain how to numerically solve eq .",
    "( [ my.dl.eq ] ) for such probabilities .",
    "note , that the numerical procedure outline below also applies to the standard directed loop approach , by simply setting @xmath147 equal to @xmath148 .    for a given vertex configuration we can construct from the scattering probabilities @xmath213 a @xmath214 `` scattering matrix '' @xmath215 , whose elements are @xmath216 so that the element @xmath217 corresponds to the probability of exiting from leg @xmath218 , given that the worm head entered the vertex on leg @xmath219 .",
    "there are various constraints on the matrix @xmath215 .",
    "in particular , eq .  ( [ my.dl.eq ] )",
    "constraints the elements of @xmath215 according to detailed balance . furthermore , in order to be interpreted as probabilities , all the matrix elements of @xmath215 must be contained within @xmath220 $ ] , that is to say @xmath221 since the worm always leaves a vertex , we must have @xmath222 i.e. each column of @xmath215 must be normalized to @xmath148 .",
    "it is possible to add additional symmetry constraints on @xmath215 .",
    "while these are not necessary conditions , they might increase the numerical accuracy in looking for the matrix @xmath215 .",
    "given an entrance leg @xmath219 , let us call two legs @xmath218 and @xmath223 _ equivalent _ , @xmath224 , if the product @xmath225 on the right hand side of eq .",
    "( [ my.dl.eq ] ) gives the same value , independent of choosing @xmath218 or @xmath223 as the exit leg .",
    "if two equivalent legs @xmath218 and @xmath223 both differ from the entrance leg @xmath219 , they must be chosen as the exit leg with equal probability , i.e. @xmath226 a similar condition can be derived for equivalent entrance legs by consideration of the reversed process .    after characterizing the constraints on the scattering matrix @xmath215 , we can now formulate our optimization criterion in terms of @xmath215 .",
    "our goal is to construct an optimal directed - loop update , and as argued before  @xcite we aim to minimize the number of bounce processes , i.e. the bounce probabilities . in our @xmath215-matrix language",
    ", this means that we need to minimize all _ diagonal _ matrix elements . in order not to introduce any additional bias among the different bounce probabilities , we require for the actual implementation to minimize the trace of the matrix @xmath215 , thereby treating all bounce probabilities equally , @xmath227    in previous studies  @xcite ,",
    "sets of probabilities satisfying all these conditions were obtained analytically for specific models . from the constraints  ( [ my.dl.eq],[eq.p.constraint2 ] , [ eq.p.constraint3],[eq.p.constraint4 ] ) and the optimization goal  ( [ eq.p.min ] ) , we see that we arrive in front of a _ linear programming _ problem for each scattering matrix @xmath215  @xcite . this can be be solved numerically using standard linear programming routines  @xcite .",
    "in most cases , we found that at most one diagonal matrix element was non zero .",
    "we also note here that the linear programming routines picks one of the many possibly equally optimal ( with respect to condition  ( [ eq.p.min ] ) ) solutions depending on its initial search point .",
    "this issue will be further discussed later .",
    "this direct way of looking for the optimal ( in terms of bounce minimization ) solutions of the directed loop equations is not specific to any model and needs no preceding analytical calculation .",
    "it allows for a rather generic implementation of the sse algorithm , where after implementation of the hamiltonian , a standard minimization routine  @xcite can be employed in order to obtain the scattering matrices prior to starting the actual simulation .",
    "in this section , we apply the preceding method to the simulation of quantum systems which have been extensively studied previously using the sse qmc method .    to ensure that all diagonal matrix elements of the bond hamiltonians are positive , we add a constant @xmath44 per bond to the original hamiltonian where @xmath45 is the minimal value for which all diagonal matrix elements are positive , and @xmath228 .",
    "we will see that usually a finite value of @xmath47 is required in order to allow for regions in parameter space which are completely bounce - free .",
    "in general , we find that increasing @xmath47 results in lower bounce probabilities . however , as the size of the operator string grows with @xmath47 , this leads to increasing simulation times : there is clearly a tradeoff between more bounces but less cpu time ( small @xmath47 ) and less bounces but more cpu time ( large @xmath47 ) .",
    "we expect that there is no general rule how to a priori choose the value of @xmath47 in order to obtain the smallest autocorrelation times .",
    "first we consider the easy - axis spin-@xmath1 heisenberg model in an external magnetic field @xmath223 , @xmath229 where @xmath230 denotes the easy - axis anisotropy , and the first sum extends over all nearest neighbors on the @xmath231-dimensional hypercubic lattice .    numerically scanning the parameter space ( @xmath232 ) , we search for regions where our optimization procedure finds bounce - free solutions ( i.e. @xmath233 for all allowed vertices ) . from this procedure",
    "we obtain the algorithmic phase diagram displayed in fig .",
    "[ fig : algos ] .     heisenberg model in a magnetic field @xmath223 field , on a @xmath231-dimensional cubic lattice with nearest neighbor exchange @xmath234 .",
    "the easy - axis anisotropy is denoted @xmath230 .",
    "the shaded region indicates those parameters , for which a bounce - free solution of the generalized directed loop equations can be found.,width=264 ]    we find a finite region of the parameter space ( @xmath235 ) which corresponds to bounce - free solutions of the generalized directed - loop equations . within this region",
    "typically one needs @xmath236 .",
    "however , for @xmath237 , we find bounce - free solutions also for @xmath238 . outside the bounce - free region",
    "at least one of the scattering matrices does not allow for a traceless solution .    for @xmath195 , syljusen and sandvik",
    "analytically found the same bounce - free region  @xcite . by monitoring the parameter dependence of the finite bounce probabilities",
    ", we verified that our numerical approach indeed yields their analytical solution .",
    "syljusen recently extended the directed loop framework proposed in  @xcite to spin-@xmath1 models  @xcite . within our framework",
    ", his ansatz corresponds to setting @xmath152 .",
    "he finds no region in parameter space where the directed loop equations allow for bounce - free solutions for any @xmath239 .",
    "we have verified this by setting @xmath152 and find that for @xmath239 , there is indeed no bounce free solution , using syljusen s choice .",
    "for @xmath195 and @xmath240 , syljusen recovers the phase diagram shown in fig .",
    "[ fig : algos ] .",
    "this reflects the fact that for @xmath195 and @xmath240 all non - zero matrix elements of the @xmath241 operators are equal and thus the factors @xmath147 cancel out of the generalized directed loop equations , making our generalization equivalent to the standard approach . for @xmath239",
    "the generalized directed loop equations , including the worm weights as extra degrees of freedom , however allow for more bounce free solutions .    the algorithmic phase diagram shown in fig .",
    "[ fig : algos ] was also found to hold for the coarse - grained loop algorithm  @xcite .",
    "this suggests that the numerically determined scattering probabilities are similar to those of the coarse graining approach .",
    "this equivalence is also pointed out more clearly in ref .",
    "@xcite .      here",
    "we present algorithmic phase diagrams for the bosonic hubbard model , with hamiltonian @xmath242 where the @xmath74 ( @xmath73 ) denote boson creation ( destruction ) operators on sites @xmath26 , @xmath243 is the local density , @xmath244 is hopping amplitude , @xmath245 the on - site interaction , and @xmath246 the chemical potential .",
    "we need to restrict the simulation to a maximum number @xmath247 of bosons per lattice site , in order to obtain positive diagonal bond hamiltonian matrix elements . for the hardcore bosonic case @xmath198",
    ", we refer to the preceding section , since the hardcore bosonic hubbard model exactly maps onto a spin-@xmath0 antiferromagnetic heisenberg model .    using our numerical optimization technique we arrive at the algorithmic phase diagram shown in fig .",
    "[ fig : algob ] .",
    "there is a finite region of bounce - free solutions to the directed loop equations .",
    "however , this region shrinks upon increasing @xmath179 , and we need to allow @xmath248 in order to recover the complete bounce free region .",
    "-dimensional cubic lattice with nearest neighbor hopping @xmath244 , onsite interaction strength @xmath245 , and a chemical potential @xmath246 .",
    "@xmath179 denotes the cutoff in the local occupation number .",
    "the shaded region indicates the regime of bounce - free solutions of the generalized directed loop equations.,width=264 ]    syljusen studied the directed loop equations for bosonic models and did not obtain bounce - free regions for any @xmath247  @xcite .",
    "the same result was obtained in ref .",
    "again this indicates the importance of allowing the additional weight factors within our approach .",
    "smakov _ et al . _",
    "@xcite presented a coarse - grained loop algorithm for the simulation of softcore bosons .",
    "they present results for free bosons , for which no constraint on the occupation number is necessary within the sse approach . since their method proceeds directly in the @xmath249 limit",
    ", we expect that using their algorithm there will remain no bounce - free regions for finite on - site interaction .    for a softcore bosonic model without a cutoff on the maximum value of bosons per site ,",
    "it is also possible to perform simulations by imposing an initial cutoff @xmath179 , which is then adjusted during the course of the thermalization process . with the numerical procedure at hand",
    ", it is easy to recalculate the scattering matrices @xmath215 when needed , namely when the current cutoff becomes too small , and needs to be increased .",
    "the results presented in the previous section suggest that the generalized directed loop equations lead to efficient update schemes .",
    "in particular , in many cases we could greatly extend bounce - free regions in parameter space using the generalized directed loop method .",
    "it is generally expected that reducing bounce processes leads to more efficient algorithms . in this section ,",
    "we therefore compare the efficiency of an arbitrarily picked solution to the generalized directed loop algorithm to earlier approaches : the original heat bath choice for the scattering probabilities by sandvik  @xcite , and the directed loop approach by syljusen and sandvik  @xcite .",
    "this comparison is performed using the example of the magnetization process of quantum spin chains .",
    "we define each mc step to consist of a full diagonal update , followed by a fixed number @xmath250 of worms updates , where @xmath250 is chosen such that on average twice the number of vertices in the operator string are hit by those worms .",
    "we perform a measurement after each such monte carlo step , and determine integrated autocorrelation times using standard methods  @xcite .    in case",
    "the effort for a single mc step was the same for each of the three algorithms , the integrated autocorrelation time would establish a valid comparison between these algorithms in terms of cpu time .",
    "suppose , however , that a mc step of alg .",
    "a took twice the cpu time than a mc step using alg .",
    "b. in that case even with a 50% reduction of the autocorrelation time upon using alg .",
    "a , both would be equally efficient , since in order to obtain a given number of independent configurations , the same cpu time would be needed . in the following , we therefore present a measure of autocorrelations , which takes the effort of each update scheme into account in a machine independent way .    for this purpose",
    ", we define the worm size @xmath153 as the total number of vertices that have been visited by the worm , including those visited during bounce processes  @xcite .",
    "the number @xmath250 , calculated self - consistently during thermalization , is then defined such that @xmath251 , where @xmath252 is the average number of non - identity operators in the operator string ( @xmath253 denotes mc averages ) . in counting @xmath250",
    "we include worms that are immediately stopped .",
    "the number @xmath250 can fluctuate from one simulation to another , and more importantly depend on the underlying algorithm : indeed , the worms constructed using different algorithms are not expected to be of the same size . in order to account for this difference in effort",
    ", we multiply the integrated autocorrelation times by a factor @xmath254 , which is close to @xmath255 by definition , but which might differ , depending on the underlying algorithm .    the results presented below",
    "were obtained by the following procedure : for each of the three algorithms we run simulations containing @xmath256 mc steps and calculate integrated autocorrelation times @xmath257 for various observables  @xcite . from these",
    "we obtain effort - corrected autocorrelation times @xmath258 , leading to a machine - independent measure of efficiency .",
    "we applied the above procedure to the autocorrelations of the uniform magnetization and energy of antiferromagnetic spin chains in finite magnetic fields , and present results for the spin-@xmath259 @xmath260 and the spin-@xmath255 heisenberg case .",
    "we simulated the spin-@xmath259 @xmath260 model ( eq .",
    "( [ eq : hsm ] ) with @xmath261 ) on a @xmath262 sites chain at an inverse temperature @xmath263 , for fields from zero up to saturation , @xmath264 . for the simulations presented here , we chose @xmath265 which is found to be the minimal value to have a bounce free algorithm for a @xmath260 chain in a field .",
    "the magnetic field dependence of the bounce probability is shown for all three algorithms in fig .",
    "[ fig : bounce.proba.xy ] .",
    "the bounce probability is rather large ( @xmath266 for all fields ) for the heat bath algorithm and significantly reduced ( to less than 2% ) using the standard directed loop equations , while it vanishes all the way up to the saturation field using generalized directed loops",
    ".     sites spin-@xmath259 @xmath260 chain in a magnetic field @xmath223 at @xmath263 .",
    "a different scale is used for the heat bath algorithm.,width=302 ]    the rescaled autocorrelation times of the magnetization ( @xmath267 ) and energy ( @xmath268 ) are shown as functions of the magnetic field strength in figs .",
    "[ fig : taum.xy ] and  [ fig : taue.xy ] , respectively . using the heat bath algorithm",
    ", @xmath267 increases upon increasing @xmath223 , while @xmath268 decreases .",
    "the uniform magnetization of the mc configuration is updated only during the operator - loop updates , while the energy is not changed during this update step @xcite",
    ". therefore autocorrelations in the energy measurements are less sensitive to the efficiency of the operator loop update , and mainly decrease with field strength , due to increasing operator string lengths . in both the low and the high field region , the improvements of standard and generalized directed loops upon using the heat bath algorithm are clearly seen for both the energy and magnetization in figs .",
    "[ fig : taum.xy ] and  [ fig : taue.xy ] . within our scheme",
    ", we find small but not significant improvements over the standard directed loops , and for @xmath269 , the bounce - free solution even results in slightly larger autocorrelation times than the heat bath method .",
    "this clearly indicates that one must include further strategies , besides the bounce minimization in order to obtain a better algorithm , as will be discussed in sec .",
    "[ sec : strat ] .",
    "sites spin-@xmath259 @xmath260 chain in a magnetic field @xmath223 at @xmath263.,width=264 ]     sites spin-@xmath259 @xmath260 chain in a magnetic field @xmath223 at @xmath263.,width=264 ]      next , we consider the isotropic ( @xmath270 ) antiferromagnetic spin-@xmath255 heisenberg model in a magnetic field .",
    "we simulated a chain with @xmath262 sites at @xmath271 and for fields ranging from zero up to saturation at @xmath272 , and using @xmath273 . in fig .",
    "[ fig : bounce.proba.af ] , the resulting bounce probabilities are shown as functions of magnetic field strength for the three algorithms .",
    "similar to the previous case , the bounce probabilities are rather high using heat bath , @xmath274 ) , whereas they are significantly reduced using the directed loop algorithms ( less than @xmath275 in both cases ) .",
    "even though the bounce probabilities are finite at @xmath276 for the generalized directed loop algorithm , they are smaller than for the standard directed loop algorithm . furthermore , in the limit of zero field , using generalized directed loops leads to a vanishing bounce probability .",
    "sites spin-@xmath255 antiferromagnetic heisenberg chain in a magnetic field @xmath223 at @xmath263 .",
    "a different scale is used for the heat bath algorithm.,width=302 ]    in fig .",
    "[ fig : taum.af ] and fig .",
    "[ fig : taue.af ] , we present results for rescaled autocorrelation times of the magnetization ( @xmath267 ) and energy ( @xmath268 ) .",
    "the dependence of @xmath267 on the magnetic field has a similar tendency for all three algorithms : starting from a small value at zero field , @xmath277 is sharply peaked at @xmath278 , and decreases rapidly upon further increasing the field strength , reaching an almost constant value .",
    "this sharp peak around @xmath278 probably corresponds to the closure of the haldane gap ( estimated as @xmath279 for the spin 2 chain  @xcite ) by the magnetic field .",
    "we observe that @xmath277 is larger by nearly a factor of 3 using heat bath rather than directed loops .",
    "this is expected given the larger bounce probabilities in fig .",
    "[ fig : bounce.proba.af ] .",
    "we find that independent of the magnetic field strength , @xmath267 is less for the generalized directed loop algorithm than for the standard one",
    ".    concerning the autocorrelation times @xmath268 shown in fig .",
    "[ fig : taue.af ] , we reach similar conclusions as for the spin-@xmath259 @xmath260 case : the autocorrelation times of the energy are reduced by a factor around 2 from those using the heat bath algorithm .",
    "sites spin-@xmath255 antiferromagnetic heisenberg chain in a magnetic field @xmath223 at @xmath263 .",
    "the inset shows on a larger scale the autocorrelation times using directed loops at small values of the field.,width=264 ]     sites spin-@xmath255 antiferromagnetic heisenberg chain in a magnetic field @xmath223 at @xmath263.,width=264 ]",
    "the results in the previous section clearly indicate that minimizing bounces alone is not sufficient to obtain an efficient algorithm , since the bounce - free ( or bounce - minimized ) solution is not unique  @xcite .",
    "the numerical lineal programming solver employed picks a particular solution , which might not be the optimal one in terms of autocorrelations . in this section ,",
    "we present supplementary strategies aiming at locating more efficient solutions .",
    "we note that these strategies are not specific to the generalized directed loop scheme presented in the previous sections , but can also be used to optimize the standard directed loop approach  @xcite .      apart from the `` bounce '' path , where the worm backtracks , there are three other paths that a worm can take across a vertex .",
    "we denote these other paths as `` jump '' , `` straight '' and `` turn ''  @xcite .",
    "see fig .",
    "[ fig : paths ] for an illustration of these definitions .",
    "once the bounces have been minimized or even eliminated , one might consider the effects of the remaining three paths of the worm - scattering process on the autocorrelation times .",
    "a practical means of doing so is as follows : first , we use linear programming to minimize the bounces ( eq .  [ eq.p.min ] ) and to obtain for each vertex configuration the lowest value of the bounce ( denoted @xmath61 , where @xmath61 can take a different value for each possible vertex ) . in a second step , we then _ impose _ the condition @xmath280 as a new constraint , in addition to eqs .",
    "( [ eq.p.constraint2 ] , [ eq.p.constraint3],[eq.p.constraint4 ] ) , so that any feasible solution will be in the optimal subspace with respect to bounce minimization .",
    "we then consider new optimization goals , each chosen from the six following possibilities : we could minimize or maximize the jump , straight or turn probabilities .",
    "the jump probabilities simply correspond to the scattering matrix elements @xmath281 , @xmath282 , @xmath283 , @xmath284 , the straight probabilities to @xmath285 , @xmath286 , @xmath287 , @xmath288 and the turn probabilities to @xmath289 , @xmath290 , @xmath291 , @xmath292 . for each of the six different strategies , we use linear programming with the additional constraint to minimize or maximize the sum of these matrix elements for each vertex configuration .",
    "then we use the resulting scattering matrices in the sse algorithm .",
    "note , that due to the additional constraint , we explicitly ensure that these algorithms will have a minimal number of bounces .",
    "doing so , we obtain six sets of scattering matrices , each corresponding to one of the above optimization goals .      as an example of testing the efficiency of these strategies",
    ", we consider the @xmath293 @xmath260 chain in the parameter regime , where we found the generic solution of the generalized directed loop equations in sec .",
    "[ sec : spin32 ] to perform worse than the heat bath solution . in particular , we consider a chain with @xmath262 , @xmath294 , @xmath273 , and a value of the magnetic field @xmath295 .    in tab .",
    "[ tab : auto ] we present results for the autocorrelation times of the magnetization ( @xmath277 ) , staggered magnetization ( @xmath296 ) and energy ( @xmath297 ) from using each of the six different strategies .",
    ".[tab : auto ] autocorrelation times for the uniform magnetization ( @xmath277 ) , the staggered magnetization ( @xmath296 ) , and the energy ( @xmath268 ) for the generalized directed loop algorithm applied to a @xmath262 sites spin-@xmath259 @xmath260 chain in a magnetic field @xmath298 at @xmath263 , obtained using algorithms where supplementary strategies have been used after minimization of bounces , as explained in the text , for @xmath299 . [ cols=\"<,>,>,>\",options=\"header \" , ]     the subspace of bounce - free solutions contains algorithms with autocorrelation times varying by about an order of magnitude ; this indicates that a solution taken from this subspace without further guidance in general will not be the optimal one .    from tab .",
    "[ tab : auto ] we furthermore find , that the optimal additional strategy depends on the observable of interest .",
    "for example , in order to minimize the autocorrelation times of the energy , maximizing jumps is more efficient than maximizing the straight path , whereas for the staggered magnetization the two strategies perform opposite .",
    "this indicates , that in general it will _ not _ be possible to obtain a unique optimal strategy beyond the minimization of bounces .",
    "minimizing bounces appears reasonable from an algorithmic point of view , in order to prevent undoing previous changes to a qmc configuration .",
    "however , autocorrelations are also related to the physical phases of the model under consideration , and thus less well captured by a generic local prescription for the worm propagation . in practice , the most efficient way to proceed for a given model will be to perform simulations for each different strategy on small systems , in order to determine the optimal strategy for the observable of interest before performing production runs on larger systems .",
    "sites spin-@xmath259 @xmath260 chain in a magnetic field @xmath223 at @xmath263 , for @xmath299.,width=336 ]    in order to illustrate the reduction of autocorrelation times that can be achieved using this scheme , we finally consider the spin-@xmath259 @xmath260 chain throughout the whole region of magnetic fields , @xmath300 , where we found the unexpected increase in the autocorrelation times ( see fig .",
    "[ fig : taum.xy ] ) .",
    "the resulting minimal autocorrelation times for the magnetization are shown in fig .",
    "[ fig : taum.optimal ] , along with the results for the autocorrelation times using heat - bath , standard and generalized directed loops ( without additional constraints ) .",
    "our results clearly demonstrate , that the optimal algorithm gives rise to much better performance , in particular curing the autocorrelation time anomaly found in the previous section .",
    "we find that the optimal strategy depends on the magnetic field strength : for example , we find the best strategy to be ( i ) maximizing jumps for fields strengths @xmath301 , and @xmath302 , ( ii ) minimizing turns for @xmath303 , and @xmath304 , and ( iii ) maximizing straight moves for @xmath305 and @xmath306 .",
    "in this paper we presented a generalized approach to the construction of directed loops in quantum monte carlo simulations . viewing the worms",
    "ends not as artificial discontinuities , but as physical operators with corresponding weights we arrived at generalizations of the directed loop equations . using linear programming techniques to solve these equations we can avoid the analytical calculations needed in previous approaches , and arrive at a generic qmc algorithm .",
    "the generalized directed loop equations allow bounce - free solutions in larger regions of parameter space , but measurements of autocorrelation times for several models showed that minimizing bounces is not always sufficient to obtain an efficient algorithm .",
    "we therefore proposed a different means of further optimizing directed loop algorithms inside the subspace of bounce - minimal solutions .",
    "additional strategies were presented , the use of which improves the performance up to an order of magnitude . however , the optimal strategy in general depends on both the model _ and _ the observable of interest .",
    "one therefore needs to perform preliminary simulations to find out which supplementary strategy is optimal for a given problem before turning to long calculations , in order to account for the physical phase realized in the specific parameter regime .",
    "a recent paper  @xcite discussed issues similar to the ones addressed here : can one obtain strategies that improve the efficiency of qmc algorithms beyond the directed loop scheme  ? in our understanding of their work , the authors of ref .",
    "@xcite propose to _ always _ keep a non - zero bounce probability to vertices with the largest weight .",
    "they then provide a precise form of the scattering matrices . in ref .",
    "@xcite , syljusen also proposed to keep a non - zero bounce probability for the vertex with the largest weight in situations where he did not find bounce - free solutions .",
    "the main difference between the approach of pollet _ et al .",
    "_ , and syljusen thus concerns the off - diagonal elements of the scattering matrix . as shown explicitly in sec .",
    "[ sec : strat ] , the off - diagonal matrix elements strongly affect the efficiency of the algorithm in a parameter- and observable - dependent way .",
    "this indicates that there will be no simple rule for the construction of the scattering matrices , which perform optimal in all cases .",
    "similar conclusions were reached in ref .",
    "a full sse code featuring the implementation of the generalized directed loop technique described in the present paper is available as part of the alps project  @xcite .",
    "we thank k. harada , n. kawashima , a. sandvik , e. srensen , o. syljusen and s. todo for fruitful discussions .",
    "the simulations were done using the alps libraries  @xcite and performed on the asgard beowulf cluster at eth zrich .",
    "this work is supported by the swiss national science foundation ."
  ],
  "abstract_text": [
    "<S> efficient quantum monte carlo update schemes called _ directed loops _ have recently been proposed , which improve the efficiency of simulations of quantum lattice models . </S>",
    "<S> we propose to generalize the detailed balance equations at the local level during the loop construction by accounting for the matrix elements of the operators associated with open world - line segments . </S>",
    "<S> using linear programming techniques to solve the generalized equations , we look for optimal construction schemes for directed loops . </S>",
    "<S> this also allows for an extension of the directed loop scheme to general lattice models , such as high - spin or bosonic models . </S>",
    "<S> the resulting algorithms are bounce - free in larger regions of parameter space than the original directed loop algorithm . </S>",
    "<S> the generalized directed loop method is applied to the magnetization process of spin chains in order to compare its efficiency to that of previous directed loop schemes . </S>",
    "<S> in contrast to general expectations , we find that minimizing bounces alone does not always lead to more efficient algorithms in terms of autocorrelations of physical observables , because of the non - uniqueness of the bounce - free solutions . </S>",
    "<S> we therefore propose different general strategies to further minimize autocorrelations , which can be used as supplementary requirements in any directed loop scheme . </S>",
    "<S> we show by calculating autocorrelation times for different observables that such strategies indeed lead to improved efficiency ; however we find that the optimal strategy depends not only on the model parameters but also on the observable of interest . </S>"
  ]
}