{
  "article_text": [
    "understanding the patterns of correlations between the components of complex systems is a fundamental issue in various scientific fields , ranging from neurobiology to genomic , from finance to sociology , ... a recurrent problem is to distinguish between direct correlations , produced by physiological or functional interactions between the components , and network correlations , which are mediated by other , third - party components .",
    "various approaches have been proposed to infer interactions from correlations , exploiting concepts related to statistical dimensional reduction @xcite , causality @xcite , the maximum entropy principle @xcite , markov random fields @xcite ... a major practical and theoretical difficulty in doing so is the paucity and the quality of data : reliable analysis should be able to unveil real patterns of interactions , even if measures are affected by under- or noisy sampling .",
    "the size of the interaction network can be comparable to or larger than the number of data , a situation referred to as high - dimensional inference .",
    "the purpose of the present work is to establish a quantitative correspondence between two of those approaches , namely the inference of boltzmann machines ( also called ising model in statistical physics and undirected graphical models for discrete variables in statistical inference @xcite ) and principal component analysis ( pca ) @xcite .",
    "inverse boltzmann machines ( bm ) are a mathematically well - founded but computationally challenging approach to infer interactions from correlations .",
    "our scope is to find the interactions among a set of @xmath0 variables @xmath4 . for simplicity , we consider variables @xmath5 taking binary values @xmath6",
    "only ; the discussion below can be easily extended to the case of a larger number of values , _",
    "e.g. _ to genomics where nucleotides are encoded by four - letter symbols , or to proteomics where amino - acids can take twenty values .",
    "assume that the average values of the variables , @xmath7 , and the pairwise correlations , @xmath8 are measured , for instance , through the sampling of , say , @xmath9 configurations @xmath10 .",
    "solving the inverse bm problem consists in finding the set of interactions , @xmath11 , and of local fields , @xmath12 , defining an ising model , such that the equilibrium magnetizations and pairwise correlations coincide with , respectively , @xmath13 and @xmath14 .",
    "many procedures have been designed to tackle this inverse problem , including learning algorithms @xcite , advanced mean - field techniques @xcite , message - passing procedures @xcite , cluster expansions @xcite , graphical lasso @xcite and its variants @xcite .",
    "the performance ( accuracy , running time ) of those procedures depend on the structure of the underlying interaction network and on the quality of the sampling , _",
    "i.e. _ how large @xmath9 is",
    ".    principal component analysis ( pca ) is a widely popular tool in statistics to analyze the correlation structure of a set of variables @xmath4 .",
    "the principle of pca is simple .",
    "one starts with the correlation matrix , @xmath15 which expresses the covariance between variables @xmath5 and @xmath16 , rescaled by the product of the expected fluctuations of the variables taken separately .",
    "@xmath17 is then diagonalized .",
    "the projections of @xmath18 along the top eigenmodes ( associated to the largest eigenvalues of @xmath17 ) identify the uncorrelated variables which contribute most to the total variance .",
    "if a few , say , @xmath19 , eigenvalues are notably larger than the remaining ones pca achieves an important dimensional reduction .",
    "the determination of the number @xmath20 of components to be retained is a delicate issue .",
    "it may be done by comparing the spectrum of @xmath17 to the marcenko - pastur ( mp ) spectrum for the null hypothesis , that is , for the correlation matrix calculated from the sampling of @xmath9 configurations of @xmath0 independent variables @xcite .",
    "generally those two spectra coincide when @xmath0 is large , except for some large or small eigenvalues of @xmath17 , retained as the relevant components .",
    "the advantages of pca are multiple , which explains its success .",
    "the method is very versatile and fast as it only requires to diagonalize the correlation matrix , which can be achieved in a time polynomial in the size @xmath0 of the problem .",
    "in addition , pca may be extended to incorporate _",
    "prior _ information about the components , which is particularly helpful for processing noisy data .",
    "an illustration is sparse pca , which looks for principal components with many vanishing entries @xcite .    in this paper",
    "we present a conceptual and practical framework which encompasses bm and pca in a controlled way .",
    "we show that pca , with appropriate modifications , can be used to infer bm and discuss in detail the amount of data necessary to do so .",
    "our framework is based on an extension of a celebrated model of statistical mechanics , the hopfield model @xcite .",
    "the hopfield model was originally introduced to model auto - associative memories , and relies on the notion of patterns @xcite .",
    "informally speaking , a pattern @xmath21 defines an attractive direction in the @xmath0-dimensional space of the variable configurations , _",
    "i.e. _ a direction along which @xmath18 has a tendency to align .",
    "the norm of @xmath22 characterizes the strength of the attraction .",
    "while having only attractive patterns makes sense for auto - associative memories , it is an unnecessary assumption in the context of bm .",
    "we therefore generalize the hopfield model by including repulsive patterns @xmath23 , that is , directions in the @xmath0-dimensional space which @xmath18 tends to be orthogonal to @xcite . from a technical point of view , the generalized hopfield model with @xmath20 attractive patterns and @xmath24 repulsive patterns is simply a particular case of bm with an interaction matrix , @xmath25 , of rank equal to @xmath26 . if one knows _ a priori _ that the rank of the true @xmath27 is indeed small , _",
    "i.e. _ @xmath28 , using the generalized hopfield model rather than a generic bm allows one to infer much less parameters and to avoid overfitting in the presence of noisy data .",
    "we first consider the case where the components @xmath29 and @xmath30 are very small compared to @xmath2 . in this limit case",
    "we show that maximum likelihood ( ml ) inference with the generalized hopfield model is closely related to pca .",
    "the attractive patterns are in one - to - one correspondence with the largest components of the correlation matrix , while the repulsive patterns correspond to the smallest components , which are normally discarded by pca . when all patterns are selected ( @xmath31 ) inference with the generalized hopfield model is equivalent to the mean - field approximation @xcite .",
    "retaining only few significative components helps , in principle , to remove noise from the data .",
    "we present a simple geometrical criterion to decide in practice how many attractive and repulsive patterns should be considered .",
    "we also address the question of how many samples ( @xmath9 ) are required for the inference to be meaningful .",
    "we calculate the error bars over the patterns due to the the finite sampling .",
    "we then analyze the case where the data are sampled from a generalized hopfield model , and inference amounts to learn the patterns of that model . when the system size , @xmath0 , and the number of samples , @xmath9 , are both sent to infinity with a fixed ratio , @xmath32",
    ", there is a critical value of the ratio , @xmath33 , below which learning is not possible .",
    "the value of @xmath33 depends on the amplitude of the pattern components .",
    "this transition corresponds to the retarded learning phenomenon discovered in the context of supervised learning with continuous variables and rigorously studied in random matrix and probability theories , see @xcite for reviews .",
    "we validate our findings on synthetic data generated from various ising models with known interactions , and present applications to neurobiological and proteomic data .    in the case of a small system size , @xmath0 , or of very strong components , @xmath34",
    ", the ml patterns do not coincide with the components identified by pca .",
    "we make use of techniques from the statistical mechanics of disordered systems originally intended to calculate averages over ensembles of matrices to compute the likelihood to the second order in powers of @xmath35 for a given correlation matrix .",
    "we give explicit expressions for the ml patterns in terms of non - linear combinations of the eigenvalues and eigenvectors of the correlation matrix .",
    "these corrections are validated on synthetic data .",
    "furthermore , we discuss the issue of how many sampled configurations are necessary to improve over the leading  order ml patterns as a function of the amplitude of the pattern components and of the system size .",
    "the plan of the paper is as follows . in section [ mainres ]",
    "we define the generalized hopfield model , the bayesian inference framework and list our main results , that is , the expressions of the patterns without and with corrections , the criterion to decide the number of patterns , and the expressions for the error bars on the inferred patterns .",
    "tests on synthetic data are presented in section [ secsyn ] .",
    "section [ secbio ] is devoted to the applications to real biological data , _",
    "i.e _ recordings of the neocortical activity of a behaving rat and consensus multi - sequence alignment of the pdz protein domain family .",
    "readers interested in applying our results rather than in their derivation need not read the subsequent sections .",
    "derivation of the log - likelihood with the generalized hopfield model and of the main inference formulae can be found in section [ secinf ] . in section [ size ]",
    "we study the minimal number @xmath9 of samples necessary to achieve an accurate inference , and how this number depends on the number of patterns and on their amplitude .",
    "perspectives and conclusions are given in section [ conc ] .",
    "we consider configurations @xmath36 of @xmath0 binary variables taking values @xmath37 , drawn according to the probability @xmath38 = \\frac{\\exp - e[\\boldsymbol\\sigma , { \\bf h } ,   \\{\\boldsymbol \\xi^\\mu\\},\\{\\hat{\\boldsymbol \\xi}^\\mu\\}]}{z[{\\bf h } ,   \\{\\boldsymbol \\xi^\\mu\\},\\{\\hat{\\boldsymbol \\xi}^\\mu\\ } ] } \\ , \\ ] ] where the energy @xmath39 is given by @xmath40 & = & -\\sum_{i=1}^n h_{i}\\sigma _ { i } - \\frac 1{2n } \\sum_{\\mu=1}^{p } \\left ( \\sum_{i=1}^n \\xi_{i}^\\mu\\sigma_{i}\\right)^2   \\nonumber \\\\ & + & \\frac 1{2n } \\sum_{\\mu=1}^{\\hat p } \\left ( \\sum_{i=1}^n \\hat\\xi_{i}^\\mu\\sigma_{i}\\right)^2 \\ .\\end{aligned}\\ ] ] the partition function @xmath41 in ( [ likelihood ] ) ensures the normalization of @xmath42 .",
    "the components of @xmath43 are the local fields acting on the variables .",
    "the patterns @xmath44 , with @xmath45 , are attractive patterns : they define preferred directions in the configuration space @xmath46 , along which the energy @xmath39 decreases ( if the fields are weak enough ) .",
    "the patterns @xmath47 , with @xmath48 , are repulsive patterns : configurations @xmath46 aligned along those directions have a larger energy .",
    "the pattern components , @xmath49 , and the fields , @xmath50 , are real - valued .",
    "our model is a generalized version of the original hopfield model @xcite , which has only attractive patterns and corresponds to @xmath51 . in the following",
    ", we will assume that @xmath26 is much smaller than @xmath0 .",
    "energy function ( [ energy ] ) implicitly defines the coupling @xmath11 between the variables @xmath5 and @xmath16 , @xmath52 note that any interaction matrix @xmath11 can be written under the form ( [ defcoupl ] ) , with @xmath20 and @xmath24 being , respectively , the number of positive and negative eigenvalues of @xmath53 . here",
    ", we assume that the total number of patterns , @xmath26 , _",
    "i.e. _ the rank of the matrix @xmath53 is ( much ) smaller than the system size , @xmath0 .",
    "the data to be analyzed consists of a set of @xmath9 configurations of the @xmath0 spins , @xmath54 , @xmath55 .",
    "we assume that those configurations are drawn , independently from each other , from the distribution @xmath42 ( [ likelihood ] ) .",
    "the parameters defining @xmath42 , that is , the fields @xmath56 and the patterns @xmath57 are unknown . our scope is to determine the most likely values for those fields and patterns from the data . in bayes inference framework",
    "the posterior distribution for the fields and the patterns given the data @xmath58 is @xmath59&= &   \\frac{p_{0}[{\\bf h } , \\{\\boldsymbol \\xi^\\mu\\},\\{\\hat{\\boldsymbol \\xi}^\\mu\\}]}{p_{1}[\\{\\boldsymbol \\sigma ^b\\ } ] }   \\\\ & \\times&\\prod",
    "_ { b=1}^b p_h[\\boldsymbol\\sigma ^b | { \\bf h } , \\{\\boldsymbol \\xi^\\mu\\},\\{\\hat{\\boldsymbol \\xi}^\\mu\\}]\\ , \\nonumber\\end{aligned}\\ ] ] where @xmath60 encodes some _ a priori _ information over the parameters to be inferred and @xmath61 is a normalization .",
    "it is important to realize that many transformations affecting the patterns can actually leave the coupling matrix @xmath25 ( [ defcoupl ] ) and the distribution @xmath42 unchanged .",
    "a simple example is given by an orthogonal transformation @xmath62 over the attractive patterns : @xmath63 .",
    "this invariance entails that the the problem of inferring the patterns is not statistically consistent : even with an infinite number of sampled data no inference procedure can distinguish between a hopfield model with patterns @xmath64 and another one with patterns @xmath65 .",
    "however , the inference of the couplings is statistically consistent : two distinct matrices @xmath25 define two distinct distributions over the data .    in the presence of repulsive patterns",
    "the complete invariance group is the indefinite orthogonal group @xmath66 , which has @xmath67 generators . to select one particular set of most likely patterns",
    ", we explicitly break the invariance through @xmath60 .",
    "a convenient choice we use throughout this paper is to impose that the weighted dot products of the pairs of attractive and/or repulsive patterns vanish : @xmath68\\ , \\nonumber \\\\",
    "\\sum_i \\xi_i^\\mu \\hat \\xi_i^\\nu(1-m_i^2 )   & = & 0 \\quad \\bigg [ p \\hat p\\ \\hbox{\\rm constraints}\\bigg]\\ ,",
    "\\\\ \\sum_i \\hat \\xi_i^\\mu \\hat \\xi_i^\\nu(1-m_i^2)&= & 0 \\quad \\bigg[\\frac 12 \\hat p(\\hat p-1)\\ \\hbox{\\rm constraints}\\bigg]\\ .",
    "\\nonumber \\end{aligned}\\ ] ] in the following we will use the vocable maximum likelihood inference to refer to the case where the prior @xmath69 is used to break the invariance only . @xmath60 may also be chosen to impose specific constraints on the pattern amplitude , see section [ secregu ] devoted to regularization .      due to the absence of three- or higher",
    "order - body interactions in @xmath39 ( [ energy ] ) , @xmath70 depends on the data @xmath58 only through the @xmath0 magnetizations , @xmath13 , and the @xmath71 two - spin covariances , @xmath14 , of the sampled data : @xmath72 we consider the correlation matrix @xmath17 ( [ defgamma ] ) , and call @xmath73 its eigenvalues .",
    "@xmath74 denotes the eigenvector attached to @xmath75 and normalized to unity .",
    "we also introduce another notation to label the same eigenvalues and eigenvectors in the reverse order : @xmath76 and @xmath77 , _",
    "e.g. _ @xmath78 is the smallest eigenvalue of @xmath17 ; the motivation for doing so will be transparent below .",
    "note that @xmath17 is , by construction , a semi - definite positive matrix : all its eigenvalues are positive .",
    "in addition , the sum of the eigenvalues is equal to @xmath0 since @xmath79 .",
    "hence the largest and smallest eigenvalues are guaranteed to be , respectively , larger and smaller than unity .    in the following greek indices , _",
    "i.e. _ @xmath80 , correspond to integers comprised between 1 and @xmath20 or @xmath24 , while roman letters , _ i.e. _ @xmath81 denote integers ranging from 1 to @xmath0 .",
    "finding the patterns and fields maximizing @xmath70 ( [ post ] ) is a very hard computational task .",
    "we introduce an approximation scheme for those parameters @xmath82 the derivation of this systematic approximation scheme and the discussion of how smaller the contributions get with the order of the approximation can be found in section [ exp67 ] . to the lowest order the patterns are given by @xmath83",
    "the above expressions require that @xmath84 for an attractive pattern and @xmath85 for a repulsive pattern .",
    "once the patterns are computed the interactions , @xmath86 , can be calculated from ( [ defcoupl ] ) , @xmath87 the values of the local fields are then obtained from @xmath88 which has a straightforward mean - field interpretation .",
    "the above results are reminiscent of pca , but differ in several significative aspects .",
    "first , the patterns do not coincide with the eigenvectors due to the presence of @xmath13-dependent terms .",
    "secondly , the presence of the @xmath89-dependent factor in ( [ ordre0xi ] ) discounts the patterns corresponding to eigenvalues close to unity .",
    "this effect is easy to understand in the limit case of independent spins and perfect sampling ( @xmath90 ) : @xmath17 is the identity matrix , which gives @xmath91 , and the patterns rightly vanish .",
    "thirdly , and most importantly , not only the largest but also the smallest eigenmodes must be taken into account to calculate the interactions .    the couplings @xmath92 ( [ j0 ] ) calculated from the lowest - order approximation for the patterns are closely related to the mean - field ( mf ) interactions @xcite , @xmath93 where @xmath94 denotes the inverse matrix of @xmath17 ( [ defgamma ] ) .",
    "however , while all the eigenmodes of @xmath17 are taken into account in the mf interactions ( [ jtap ] ) , our lowest - order interactions ( [ j0 ] ) include contributions from the @xmath20 largest and the @xmath24 smallest eigenmodes only .",
    "as the values of @xmath95 can be chosen depending on the number of available data , the generalized hopfield interactions ( [ j0 ] ) is _ a priori _ less sensitive to overfitting . in particular , it is possible to avoid considering the bulk part of the spectrum of @xmath17 , which is essentially due to undersampling ( @xcite and section [ rl ] ) .      the posterior distribution @xmath70 can locally be approximated with a gaussian distribution centered in the most likely values for the patterns , @xmath96 , and the fields , @xmath97 .",
    "we obtain the covariance matrix of the fluctuations of the patterns around their most likely values , @xmath98_{ij}^{\\mu \\nu}}{b\\sqrt{(1-m_i^2)(1-m_j^2)}}\\ ; \\ . \\label{errorbar}\\ ] ] and identical expressions for @xmath99 and @xmath100 upon substitution of @xmath101_{ij}^{\\mu \\nu}$ ] with , respectively , @xmath102_{ij}^{\\mu \\nu}$ ] and @xmath103_{ij}^{\\mu \\nu}$ ] .",
    "the entries of the @xmath104 matrices are @xmath105_{ij}^{\\mu \\nu}\\!\\!\\!&=&\\!\\ ! \\delta^{\\mu\\nu}\\!\\ ! \\left [ \\sum _ { k = p+1}^{n-\\hat p } \\frac{v_i^k\\,v_j^k}{|\\lambda^k-\\hat\\lambda^\\mu| } + \\sum _ { \\rho = 1 } ^{p } \\frac{|\\lambda^\\mu-1| \\lambda^\\rho\\ , v_i^\\rho\\ , v_j^\\rho } { g_1(\\lambda ^\\rho,\\lambda^\\mu)}\\right.\\nonumber\\\\ & + & \\left . \\sum",
    "_ { \\rho=1}^{\\hat p } \\frac{|\\lambda^\\mu-1|\\hat\\lambda^\\rho\\ , \\hat v_i^\\rho\\ , \\hat v_j^\\rho } { g_1(\\hat \\lambda ^\\rho,\\lambda^\\mu)}\\right]+ \\frac{g_2 ( \\lambda^\\mu , \\lambda^\\nu)}{g_1 ( \\lambda^\\mu , \\lambda^\\nu)}\\ ,   v_j^\\mu\\ , v_i^\\nu \\ , \\nonumber",
    "\\\\   \\big [ { \\bf m}_{\\xi\\hat\\xi}\\big]_{ij}^{\\mu \\nu}\\!\\!\\!&=&\\!\\ !",
    "\\frac{g_2(\\lambda^\\mu,\\hat \\lambda^\\nu)}{g_1(\\lambda^\\mu,\\hat \\lambda^\\nu ) } \\ , v_j^\\mu\\ , \\hat v_i^\\nu\\ , \\end{aligned}\\ ] ] and @xmath106_{ij}^{\\mu \\nu}$ ] is obtained from @xmath107_{ij}^{\\mu \\nu}$ ] upon substitution of @xmath108 with , respectively , @xmath109 .",
    "functions @xmath110 and @xmath111 are defined through @xmath112 the covariance matrix of the fluctuations of the fields is given in section [ secerrcal ] .",
    "error bars on the couplings ( [ defcoupl ] ) can be calculated from the ones on the patterns .",
    "formula ( [ errorbar ] ) tells us how significative are the inferred values of the patterns in the presence of finite sampling .",
    "for instance , if the error bar @xmath113 is larger than , or comparable with the pattern component @xmath114 calculated from ( [ ordre0xi ] ) then this component is statistically compatible with zero . according to formula ( [ errorbar ] ) we expect error bars of the order of @xmath115 over the pattern components , where @xmath116 .",
    "we now determine the numbers of patterns , @xmath20 and @xmath24 , based on a simple geometric criterion ; the reader is referred to section [ secoptim ] for detailed calculations . to each attractive pattern",
    "@xmath117 we associate the rescaled pattern @xmath118 , whose components are @xmath119 .",
    "we write @xmath120 where @xmath121 is a positive coefficient , and @xmath122 is a vector orthogonal to all rescaled patterns by virtue of ( [ gauge ] ) ( fig .",
    "[ fig - schema0 ] ) .",
    "our lowest order formula ( [ ordre0xi ] ) for the maximum likelihood estimators gives @xmath123 and @xmath124 , see fig .",
    "[ fig - schema0 ] .",
    "this result is , to some extent , misleading .",
    "while the most likely value for the vector @xmath125 is indeed zero , its norm is almost surely not vanishing !",
    "the statement may appear paradoxical but is well - known to hold for stochastic variables : while the average or typical value of the location of an isotropic random walk vanishes , its average squared displacement does not .",
    "here , @xmath126 represents the stochastic difference between the pattern to be inferred and the direction of one of the largest eigenvectors of @xmath17 .",
    "we expect the squared norm @xmath127 to have a non - zero value in the @xmath128 limit at fixed ratio @xmath129 .",
    "its average value can be straightforwardly computed from formula ( [ errorbar2 ] ) , @xmath130_{ii}^{\\mu \\mu } = \\frac 1b\\sum _ { k = p+1}^{n-\\hat p } \\frac 1{\\lambda^\\mu-\\lambda^k } \\ , \\ ] ] where @xmath131 is the index of the pattern .",
    "we define the angle @xmath132 between the eigenvector @xmath133 and the rescaled pattern @xmath134 through @xmath135 see fig .",
    "[ fig - schema0 ] .",
    "small values of @xmath132 correspond to reliable patterns , while large @xmath132 indicate that the maximum likelihood estimator of the @xmath136 pattern is plagued by noise .",
    "the value of @xmath20 such that @xmath137 is , say , about @xmath138 is our estimate for the number of attractive patterns .",
    "the above approach can be easily repeated in the case of repulsive patterns .",
    "we obtain , with obvious notations , @xmath139_{ii}^{\\mu \\mu } = \\frac 1b\\sum _ { k = p+1}^{n-\\hat p } \\frac 1{\\lambda^k-\\hat\\lambda^\\mu } \\ , \\ ] ] and @xmath140 the value of @xmath24 such that @xmath141 is , say , about @xmath138 is our estimate for the number of repulsive patterns .",
    "so far we have considered that the prior probability @xmath60 over the patterns was uniform , and was used to break the invariance through the conditions ( [ gauge ] ) .",
    "the prior probability can be used to constrain the amplitude of the patterns .",
    "for instance , we can introduce a gaussian prior on the patterns , @xmath142 , \\ ] ] which penalizes large pattern components @xcite .",
    "the presence of the @xmath143 factor entails that the effective strength of the regularization term , @xmath144 , depends on the site magnetization .",
    "regularization is particularly useful in the case of severe undersampling .",
    "with regularization ( [ regu1 ] ) the lowest order expression for the pattern is still given by ( [ ordre0xi ] ) , after carrying out the following transformation on the eigenvalues , @xmath145 the values of @xmath20 and @xmath24 must be such that the transformed @xmath146 and @xmath147 are , respectively , larger and smaller than unity .",
    "regularization ( [ regu1 ] ) ensures that the couplings do not blow up , even in the presence of zero eigenvalues in @xmath17 .",
    "applications will be presented in sections [ secsyn ] and [ secbio ] .",
    "the value of the regularization strength @xmath148 can be chosen based on a bayesian criterion @xcite .",
    "we now give the expression for the first - order correction to the attractive patterns , @xmath149 where @xmath150 \\end{aligned}\\ ] ] and @xmath151 and @xmath152 similarly , the first corrections to the repulsive patterns are @xmath153 the definition of @xmath154 is identical to ( [ defb ] ) , with @xmath155 and @xmath156 replaced with , respectively , @xmath157 and @xmath158 .",
    "finally , @xmath159 the first order corrections to the fields @xmath12 can be found in section [ foh ] .",
    "it is interesting to note that the corrections to the pattern @xmath160 involve non - linear interactions between the eigenmodes of @xmath17 .",
    "formula ( [ defb ] ) for @xmath161 shows that the modes @xmath131 and @xmath162 interact through a multi - body overlap with mode @xmath163 ( provided @xmath164 ) .",
    "in addition , @xmath161 does not _ a priori _ vanish for @xmath165 : corrections to the patterns have non  zero projections over the noisy modes of @xmath17 .",
    "in other words , valuable information over the true values of the patterns can be extracted from the eigenmodes of @xmath17 associated to bulk eigenvalues .",
    "the accuracy @xmath166 on the inferred pattern is limited both by the sampling error resulting from the finite number of data and the intrinsic error due to the expansion ( [ correxp ] ) . according to section [ secsam ] ,",
    "the sampling error on the pattern component is expected to decrease as @xmath167 .",
    "the intrinsic error depends on the order of the expansion , on the size @xmath0 and on the amplitude of the patterns .",
    "no inference is possible unless the ratio @xmath168 exceeds a critical value , referred to as @xmath33 in the following ( section [ weak1 ] ) .",
    "this phenomenon is similar to the retarded learning phase transition discovered in the context of unsupervised learning @xcite .",
    "assume that the pattern components @xmath29 are of the order of one ( compared to @xmath0 ) , that is , that the couplings are almost all non zero and of the order of @xmath169 .",
    "then , the intrinsic error is of the order of @xmath169 with the lowest order formula ( [ ordre0xi ] ) , and of the order of @xmath170 when corrections ( [ ordre1xi ] ) are taken into account ; for a more precise statement see section [ exp67 ] and formula ( [ expr ] ) .",
    "the corresponding values of @xmath9 at which saturation takes place are , respectively , of the order of @xmath171 and @xmath172 .",
    "the behaviour of the relative error between the true and inferred patterns , @xmath166 ( [ epsj ] ) , is summarized in fig .",
    "[ fig - symbolsum ] . in general",
    "we expect that @xmath173 samples at least are required to have a more accurate inference with @xmath174-order patterns than with @xmath175-order patterns .",
    "furthermore there is no need to sample more than @xmath176 configurations when using the @xmath174-order expression for the patterns .    if the system has @xmath177 non vanishing couplings @xmath11 of the order of @xmath53 , then patterns have few large components , of the order of @xmath178 . in this case",
    "the intrisic error over the patterns will be of the order of @xmath53 with the lowest order inference formulae , and of the order of @xmath179 with the first corrections .",
    "the numbers of sampled configurations , @xmath9 , required to reach those minimal errors will be , respectively , of the order of @xmath180 and @xmath181 .",
    "in this section we test the formulae of section [ mainres ] for the patterns and fields against synthetic data generated from various ising models with known interactions .",
    "we consider four models :    * _ model a _ is a hopfield model with @xmath182 spins , @xmath20 (= 1 or 3 ) attractive patterns and no repulsive pattern ( @xmath51 ) .",
    "the components of the patterns are gaussian random variables with zero mean and standard deviation @xmath1 , specified later .",
    "the local fields @xmath12 are set equal to zero . * _ model b : _ model b consists of @xmath0 spins , grouped into four blocks of @xmath183 spins each .",
    "the @xmath184 patterns have uniform components over the blocks : @xmath185 , @xmath186 , @xmath187 .",
    "the fields are set to zero .",
    "those choices ensure that the pattern are orthogonal to each other , and have a weak intensity : on average , @xmath188 . *",
    "_ model c _ is a very simple ising model where all fields and couplings vanish , except coupling @xmath189 between the first two spins . * _ model d _ is an ising model with @xmath190 spins , on an erdos - renyi random graph with average connectivity ( number of neighbors for each spin ) equal to @xmath191 and coupling values @xmath53 distributed uniformly between -1 and 1 .",
    "model d is an instance of the viana - bray model @xcite . in the thermodynamic limit @xmath192 this model is in the spin glass phase since @xmath193 @xcite .    for each one of the models above",
    ", the magnetizations and pairwise correlations can be estimated through the sampling of @xmath9 configurations at equilibrium using monte carlo simulations .",
    "this allows us to estimate the consequence of sampling noise on the inference quality by varying the value of @xmath9 .",
    "furthermore , for models @xmath9 and @xmath194 , it is possible to obtained the exact gibbs values for @xmath13 and @xmath14 ( corresponding to a perfect sampling , @xmath195 ) ) depends on the @xmath0spin configuration through the four block magnetizations ( sums of the @xmath183 spins in each block ) only .",
    "hence , the correlations @xmath14 and magnetizations @xmath13 can be calculated in a time growing as @xmath196 ( instead of @xmath197 ) , which allows us to reach sizes equal to a few hundreds easily . ] .",
    "this allows us to study the systematic error resulting from formulae ( [ ordre0xi],[ordre1xi],[ordre1xir ] ) , irrespectively of the sampling noise",
    ".    model a is used to test the lower order formula for the patterns , and how the quality of inference depends on the amplitude of the patterns .",
    "models c and d are highly diluted networks with strong @xmath198 interactions , while models a and b correspond to dense networks with weak @xmath199 couplings .",
    "models c and d are , therefore , harder benchmarks for the generalized hopfield model . in addition , the couplings implicitly define , through ( [ defcoupl ] ) , both attractive and repulsive patterns . those models can thus be used to determine how much repulsive patterns are required for an accurate inference of general ising models .      we start with model a with @xmath200 pattern . in this case , no ambiguity over the inferred pattern is possible since the energy @xmath39 is not invariant under continuous transformations , see section [ secgenhop ] .",
    "we may therefore directly compare the true and the inferred patterns .",
    "figures  [ fig - compar-1patt ] and [ fig - compar-1patt - bis ] show the accuracy of the lowest order formula for the patterns , eqn ( [ ordre0xi ] ) .",
    "if the pattern components are weak , each sampled configuration @xmath201 is weakly aligned along the pattern @xmath202 .",
    "if the number @xmath9 of sampled configurations is small , the largest eigenvector of @xmath17 is uncorrelated with the pattern direction ( fig .",
    "[ fig - compar-1patt ] ) . when the size of the data set is sufficiently large , _",
    "i.e. _ @xmath203 ( section [ weak1 ] ) , formula ( [ ordre0xi ] ) captures the right direction of the pattern , and the inferred couplings are representative of the true interactions .",
    "conversely , if the amplitudes of the components of the pattern @xmath202 are strong enough , each sampled configuration @xmath46 is likely to be aligned along the pattern .",
    "a small number @xmath9 ( compared to @xmath0 ) of those configurations suffice to determine the pattern ( fig .",
    "[ fig - compar-1patt - bis ] ) . in the latter case , we see that the largest components @xmath204 are systematically underestimated .",
    "a systematic study of how large @xmath9 should be for the inference to be reliable can be found in section [ size ] .",
    "we now use model b to generate the data .",
    "as model @xmath9 includes more than one pattern , the inferred patterns can not be compared to the true one easily due to the invariance of section [ secgenhop ] .",
    "we therefore compare in fig .",
    "[ fig - compar-3patt ] the true couplings and the interactions found using ( [ ordre0xi ] ) for three sizes , @xmath205 , @xmath206 and @xmath207 .",
    "the size @xmath0 sets also the amplitude of the couplings , which decreases as @xmath169 from ( [ defcoupl ] ) . as the patterns are uniform among each one of the four blocks there are ten possibles values for the couplings @xmath11 , depending on the labels @xmath208 and @xmath209 of the blocks to which @xmath210 and @xmath211 belong , with @xmath212 .",
    "for @xmath182 spins , the relative errors range between 3 and 5.5% .",
    "when the number of spins is doubled ( respectively , halved ) the relative errors are about twice smaller ( respectively , larger ) .",
    "this result confirms that formula ( [ ordre0xi ] ) is exact in the infinite @xmath0 limit only , and that corrections of the order of @xmath213 are expected for finite system sizes ( inset of fig .",
    "[ fig - compar-3patt ] ) .",
    "this scaling was expected from section [ secqual ] .",
    "we now consider model c. for perfect sampling ( @xmath195 ) the correlation matrix ( [ defgamma ] ) is @xmath214 the top eigenvalue , @xmath215 , and the smallest eigenvalue , @xmath216 , are attached to the eigenvectors @xmath217 the remaining @xmath218 eigenvalues are equal to 1 .",
    "using formula  ( [ j0 ] ) for the lowest order coupling , @xmath92 , we find that those eigenmodes do not contribute and that the interaction can take three values , depending on the choices for @xmath20 and @xmath24 : @xmath219 those expressions are plotted in fig .",
    "[ infj12 ] .",
    "the coupling @xmath220 ( dashed line ) , corresponding to the standard hopfield model , saturates at the value @xmath221 and does not diverge with @xmath53 .",
    "even the small @xmath53 behavior , @xmath222 , is erroneous .",
    "adding the repulsive pattern leads to a visible improvement , as fluctuations of the spin configurations along the eigenvector @xmath223 ( one spin up and the other down ) are penalized .",
    "the inferred coupling , @xmath224 ( bold line ) , is now correct for small @xmath53 , @xmath225 , and diverges for large values of @xmath53 .",
    ".5 cm    we now turn to model d. figure [ fig - d2 ] compares the inferred and true couplings for @xmath226 sampled configurations .",
    "the generalized hopfield model outperforms the standard hopfield model ( @xmath51 ) , showing the importance of repulsive patterns in the inference of sparse networks with strong interactions .",
    "large couplings , either positive or negative , are overestimated by the lowest order ml estimators for the patterns .",
    "an illustration of formula ( [ errorbar ] ) for the error bars is shown in fig .",
    "[ fig - compar-1patt ] , where we compare the components of the true pattern used to generate data in model a with the inferred one , @xmath227 , and the error bar , @xmath228 . for small @xmath32",
    "the inferred pattern components are uncorrelated with the true pattern and compatible with zero within the error bars . for larger values of @xmath229 , the discrepancy between the inferred and the true components are stochastic quantities of the order of the calculated error bars .",
    "we report in fig .",
    "[ fig - optimalp ] the tests of the criterion for determining @xmath20 and @xmath24 on artificially generated data from an extension of model a with @xmath184 patterns .",
    "for very poor sampling ( fig .",
    "[ fig - optimalp ] , top ) the angle @xmath230 is close to @xmath231 : even the first pattern can not be inferred correctly .",
    "this prediction is confirmed by the very poor comparison of the true interactions and the inferred couplings calculated from the first inferred pattern . for moderately accurate sampling ( fig .",
    "[ fig - optimalp ] , middle ) the strongest pattern can be inferred ; the accuracy on the inferred couplings worsens when the second pattern is added .",
    "excellent sampling allows for a good inference of the structure of the underlying model : the angle @xmath132 is small for @xmath232 ( fig .",
    "[ fig - optimalp ] , bottom ) , and larger than @xmath231 for @xmath233 ( not shown ) .",
    "not surprisingly large couplings are systematically affected by errors .",
    "those errors can be corrected by taking into account @xmath234 corrections to the patterns if the number of data , @xmath9 , is large enough ( section [ size ] ) .",
    "+ .5 cm + .3 cm    figure [ fig - d1 ] compares the inferred and true couplings for @xmath226 sampled configurations of model d. the optimal number of patterns given by the geometrical criterion is ( @xmath235 ) , see fig .",
    "[ fig - d2 ] .",
    "hence most of the components of @xmath17 are retained and the interactions inferred with the generalized hopfield model do not differ much from the mf couplings .      formula ( [ ordre1xi ] ) for the corrections to the patterns was tested on model b in the case of perfect sampling .",
    "results are reported in fig .",
    "[ fig - compar-3patt - corr ] and show that the errors in the inferred couplings are much smaller than in fig .",
    "[ fig - compar-3patt ] .",
    "inset of fig .",
    "[ fig - compar-3patt - corr ] shows that the relative errors are of the order of @xmath170 only .",
    "this scaling was expected from section [ secqual ] . pushing our expansion of @xmath1 to the next order in powers of @xmath169 could in principle give explicit expressions for those corrections .",
    "we have also tested our higher order formula when the fields @xmath12 are non - zero .",
    "for instance we have considered the same hopfield model with @xmath184 patterns as above , and with block pseudo - magnetizations @xmath236 .",
    "hence , @xmath237 was orthogonal to the patterns , and the field components were simply given by @xmath238 , according to ( [ changevar ] ) . for @xmath205 spins . ] for @xmath205 spins the relative error over the pseudo - magnetizations ( averaged over the four blocks @xmath208 ) was @xmath239 with the large-@xmath0 formula ( [ ordre0xi ] ) and @xmath240 with the finite-@xmath0 formulae ( [ ordre1xi ] ) and ( [ ordre1h ] ) .    corrections to the pca were also tested when data are corrupted by sampling noise .",
    "we compare in fig .",
    "[ fig - compar - patt1-corr ] the components of the pattern of model a found with the lowest order approximation ( [ ordre0xi ] ) and with our first order formulae ( [ ordre1xi ] ) ( case of strong pattern ) .",
    "a clear improvement in the quality of the inference is observed , even when the sampling noise is strong .",
    "our second example is model b. we show in fig .",
    "[ fig - compar - pca - corr ] the relative errors @xmath241 between the true and the inferred couplings , with formulas ( [ ordre0xi ] ) and ( [ ordre1xi ] ) , as a function of the number of sampled configurations , @xmath9 , and for @xmath205 spins .",
    "as @xmath9 increases the relative error with the lowest order patterns ( pca ) first decreases as @xmath242 , then saturates to the value @xmath243 , as expected from fig .",
    "[ fig - compar-3patt ] . the relative error with the correction to the patterns also decreases as @xmath242 , and is expected to saturate to the lower value @xmath244 ( fig .",
    "[ fig - compar-3patt - corr ] ) .",
    "we remark that the gain in accuracy over the inferred couplings resulting from the corrections ( [ ordre1xi ] ) to the patterns is obtained only when @xmath9 is very large .",
    "@xmath245 configurations at least should be sampled to obtain an improvement over the lowest order formula ( [ ordre0xi ] ) .",
    "this scaling holds when the couplings are weak , and decrease as @xmath169 .",
    "if the interaction network is diluted and carries couplings @xmath198 , we expect that @xmath246 configurations have to be sampled to make the first - corrections to the patterns effective .",
    "we have applied our formula ( [ ordre1xi ] ) to calculate the first correction to the couplings ( [ couplc ] ) for models c and d. as for model c , we find that the correction to the coupling @xmath224 vanishes ; this result is due to the fact that @xmath224 is already correct to the second order in @xmath53 , and that higher order corrections would be needed .",
    "the corrections to the coupling @xmath220 are equal to @xmath247 the resulting coupling , @xmath248 , is plotted as a function of @xmath53 in fig .",
    "[ infj12 ] , and qualitatively improves over the lowest order result ( [ couplc ] ) . in particular , for small @xmath53 , the inferred coupling is now @xmath249 , which is definitely closer to @xmath53 than ( [ couplc ] ) . in the case of model d ,",
    "the first - order corrections improve only slightly the estimates for the large couplings .",
    "in this section we show how the inference approach can be applied to real biological data , and compared to other boltzmann machine learning procedures .",
    "we have first analyzed data coming from the recording of 37 neurons in the prefrontal cortex of rats .",
    "the experiment , done by a. peyrache , f. battaglia and their collaborators , consists in recording the neural activity during a task and during the slow wave sleep preceding and following the learning of the task @xcite .",
    "pca allowed peyrache et al . to identify patterns in the activity , which are generated when the rat learns a task and are replayed during the sleep @xcite .",
    "we have analyzed with the generalized hopfield model the data corresponding to a 20 minute - long recording of the activity of a rat during the task ( data shown in fig . 1 of  @xcite ) .",
    "the raster plot was binned with a 10 msec window to obtain binary configurations of the neurons ( active or silent in the time - bin ) .",
    "we have then calculated the average frequencies , @xmath13 , and the pairwise correlations , @xmath14 .",
    "we calculate the couplings with @xmath20 attractive and @xmath250 repulsive patterns according to ( [ ordre0xi ] ) and ( [ j0 ] ) . the numbers @xmath20 and @xmath24 are calculated according to the geometrical criteria ( [ gc ] ) and ( [ gcr ] ) .",
    "hereafter , we compare the couplings obtained this way to the ones found with the adaptive cluster expansion ( ace ) of @xcite , which is not based on the expansion of the loglikelihood used in the present work .    in fig .",
    "[ adrien ] ( top ) we compare the hopfield ( @xmath51 ) couplings with @xmath251 selected patterns to the ace couplings .",
    "the agreement is quite good for @xmath252 . in @xcite @xmath253 patterns",
    "were kept in the pca ; this value is close to the optimal value , @xmath254 , we find using the geometrical criterion .",
    "addition of repulsive patterns ( bottom of fig .",
    "[ adrien ] ) slightly improves the similarity with the ace couplings .",
    "we find , indeed , that the couplings @xmath11 are rather weak , and that repulsive patterns do not play an important role .",
    "calculating the couplings with all eigenmodes ( @xmath255 ) is equivalent ot the mean - field ( mf ) approximation . a clear discrepancy between the hopfield and the ace couplings",
    "is found for the largest ( in absolute value ) interactions .",
    "we have checked that this discrepancy is not reduced when the first order corrections to the patterns are included , presumably because the number of data is not sufficient .",
    "couplings are not significatively changed in the presence of the regularization ( [ regu1 ] ) for sensible values of @xmath148 .",
    "we have next analyzed the alignement of a family of 240 sequences of pdz , a commonly encountered domain binding the c - terminus of proteins , with @xmath256 amino - acids @xcite .",
    "r. ranganathan and collaborators have elaborated an approach , called statistical coupling analysis(sca ) , to extract interactions between residues by using evolutionary data for the protein , _",
    "i.e. _ by sampling the single - site and pairwise frequencies from multi - sequence alignments of the family @xcite . briefly speaking ,",
    "sca consists in doing a pca analysis of a weighted correlation matrix , @xmath257 , where the weight @xmath258 on site @xmath210 is small for poorly conserved residues @xcite .",
    "we have taken the binary data representation of the 240 pdz sequences in the alignement given in  @xcite ( supplementary material ) .",
    "this consensus approximation amounts to replace the amino - acid on each site ( 20 possible types ) with a binary variable @xmath259 , equal to @xmath260 if the amino - acid @xmath210 in the @xmath261 sequence is the most common amino - acid at that position in the alignment , to @xmath262 otherwise .",
    "the consensus representation does not allow to keep track of all the information contained in the alignment but is indicative of the conservation pattern in the family .",
    "the inferred couplings , denoted by @xmath263 , are shown in fig .",
    "[ jpdz ] . as in the case of model d in section [ secsyn ]",
    "we find that proteomic data are better accounted with the generalized hopfield model than with the standard hopfield model : repulsive patterns seems necessary to recover the couplings found with the ace method .",
    "the couplings found with attractive patterns only are not correlated with the ace couplings ( top of fig .",
    "[ jpdz ] ) , while the agreement is quite good when taking into account attractive and repulsive patterns ; the optimal numbers of patterns are @xmath264 and @xmath265 .",
    "we have also calculated the couplings when discarding all but the most weighted sites .",
    "more precisely , we have recalculated the distribution of the weights @xmath258 as in @xcite , and found a bimodal distribution , which suggests a natural cut - off between large and small weights .",
    "we have redone the previous inference when keeping only the 44 residues ( out of 92 ) with the largest weights , corresponding to the red sites in fig .",
    "c of @xcite .",
    "the resulting interactions , denoted by @xmath266 , are shown in fig .",
    "[ jvsjpdz44 ] .",
    "again we compare the couplings found with the hopfield model and with the ace .",
    "the agreement is not good with attractive patterns only ( as done in usual pca ) , and is very good when repulsive patterns are included .",
    "an interesting question is whether the couplings obtained between the 44 most conserved residues are strongly affected by the presence or the absence of the remaining 48 residues in the inference .",
    "the interactions in the @xmath267-site model are effective and _ a priori _ differ from their values in the @xmath256-site model , in that they account for chains of interactions going through the remaining 48 sites .",
    "nevertheless , we find that the couplings calculated with all 92 residues and the couplings obtained from the subset of 44 sites with large weights are similar , see fig.[j92vsj44 ] .",
    "this result suggests that the 48 residues removed from our second analysis are not strongly interacting with the 44 retained sites .",
    "this section is intended to provide the derivations of the results announced in section [ mainres ] . maximizing the posterior probability ( [ post ] ) with respect to the patterns and",
    "the fields is equivalent to minimizing the cross entropy of the hopfield model given the data , @xmath268=\\log{z }   [ { \\bf h},\\ { \\boldsymbol \\xi^\\mu\\ } ] + u [ { \\bf h},\\ { \\boldsymbol \\xi^\\mu\\},\\{\\boldsymbol \\sigma ^b\\}]\\ , \\label{fi}\\ ] ] where @xmath41 is the partition function appearing in ( [ likelihood ] ) , @xmath269 = \\sum_{\\boldsymbol\\sigma } \\exp \\big ( - e[\\boldsymbol\\sigma , { \\bf h } ,   \\{\\boldsymbol \\xi^\\mu\\}]\\big)\\ , \\ ] ] and @xmath270 is the average value of the energy @xmath39 ( [ energy ] ) over the sampled configurations : @xmath271= -\\sum_{i=1}^n   h_i m_{i}-\\frac 1{2 } \\sum_{i , j } j_{ij } \\ , c_{ij}\\ ,   \\label{secexpa}\\ ] ] where the couplings @xmath11 are calculated from the patterns according to ( [ defcoupl ] ) . the calculation of the partition function , which is defined as a sum over @xmath197 configurations , can not generally be done in a reasonable time for large sizes @xmath0 . in the next section we show how the use of statistical mechanics techniques allows one to obtain a systematic expansion of @xmath41 , and , thus , of the cross entropy @xmath272 in powers on @xmath273 and @xmath274 .      to lighten notations calculations are presented for the case of attractive patterns only .",
    "we explain at the end of the section how formulae are modified in the presence of repulsive patterns .    for technical reasons to be made clear below it results convenient to make the change of variables @xmath276 described by @xmath277 where the @xmath278 , hereafter called pseudo - magnetizations , are real - valued numbers comprised between @xmath262 and @xmath279 . hereafter , we will infer the most likely values for @xmath280 , and will recover the fields @xmath281 through ( [ changevar ] ) .",
    "the change @xmath276 amounts to consider the energy function @xmath282 instead of the original expression for @xmath39 ( [ energy ] ) ( with @xmath51 ) .",
    "obviously , when the identities ( [ changevar ] ) are fulfilled , both energies are equal ( up to a @xmath46-independent additive term ) and define the same likelihood function ( [ likelihood ] ) .",
    "we unravel the squared terms in the partition function ( [ pf ] ) through a set of @xmath20 auxiliary gaussian variables @xmath283 , and carry out the summation over the spin configurations .",
    "we obtain @xmath284\\ ; .\\end{aligned}\\ ] ] if @xmath0 is large enough the dominant contribution to the integral will come from @xmath285 , the value of @xmath286 maximizing the argument of the exponential above .",
    "we obtain the following saddle point equation for @xmath286 , @xmath287 where @xmath288 we then write @xmath289 and expand the hyperbolic cosine function in powers of @xmath290 .",
    "the change of variable ( [ changevar ] ) is such that the linear term in @xmath291 in the expansion of the hyperbolic cosine function cancels out with the linear term in the exponential , @xmath292 , independently of the value of @xmath293 . expanding the hyperbolic cosine up to the second order in @xmath294 we find our lowest order approximation to the partition function , @xmath295   =   \\frac { e^{f^*}}{\\sqrt{\\hbox{\\rm det a } } } \\nonumber   \\label{z0}\\end{aligned}\\ ] ] where @xmath296 is the the argument of the exponential in ( [ zz ] ) calculated in @xmath297 , @xmath298 and @xmath299 is the @xmath300 matrix with entries , @xmath301",
    "we then compute the average energy @xmath270 ( [ secexpa ] ) , @xmath302 our lowest order approximation for the cross entropy is , according to ( [ fi ] ) , ( [ z0 ] ) and ( [ u ] ) : @xmath303 ^ 2\\ .\\end{aligned}\\ ] ] the first order contribution to the cross entropy , @xmath304 in ( [ expphi ] ) , is obtained by retaining the fourth order in @xmath294 in the expansion of the hyperbolic cosine function in ( [ zz ] ) , @xmath305 we expect the differences @xmath306 and @xmath307 between , respectively , the true and the lowest order cross entropies and the true and the first order cross entropies to be of the order of , respectively , @xmath308 and @xmath309 , where @xmath310 here , @xmath311 is the order of magnitude of the pattern components , which can range from 1 if the patterns are extended over the whole system to @xmath312 for highly sparse patterns , @xmath313 is the typical value of the local magnetization , and @xmath314 is the order of magnitude of the eigenvalues of @xmath315 , which can range from 1 to @xmath0 .",
    "the value of @xmath316 fixes the instrinsic error @xmath166 on the inferred patterns discussed in section [ secqual ] , @xmath317 for the lowest order approximation and @xmath318 with the first order corrections .",
    "the above calculation can be straightforwardly extended to the case of the generalized hopfield model by considering the @xmath24 repulsive patterns as patterns with purely imaginary components , @xmath319 , with @xmath320 .",
    "for instance the general lowest order expression for the cross entropy is @xmath321 ^ 2   \\nonumber \\\\ & -&\\frac 1{2n } \\sum _ { \\mu=1}^{\\hat p } \\left [ \\sum_i \\hat{\\xi}_i^\\mu\\big(t_i - m_i\\big)\\right]^2   \\nonumber \\\\ & -&\\frac 12 \\log \\det \\left ( \\begin{array } { c c } a & i \\hat a\\\\ - i { \\hat a}^t & \\hat{\\hat a }   \\end{array}\\right)\\ , \\end{aligned}\\ ] ] where @xmath322 the first order correction ( [ logppost1 ] ) can be easily written for the case of repulsive patterns , too .",
    "the hopfield model was first introduced as a model for which a set of @xmath20 desired ground states @xmath117 ( or fixed points of the zero temperature glauber dynamics ) could be programmed through an adequate choice of the interactions .",
    "each fixed point has a basin of attraction in the configuration space , corresponding to a phase of the system .",
    "the order parameters are the overlaps @xmath323   \\ \\left ( \\frac 1n \\sum _",
    "i \\xi_i^\\mu \\,\\sigma _ i \\right ) \\ , \\ ] ] which quantify how much the configurations are on average aligned along each pattern .",
    "the amplitudes and directions of the pattern and the field vectors determine if spin configurations tend to be aligned along the field , or along one or more patterns . in the infinite size limit ( @xmath192 )",
    "the overlaps are the roots of @xmath20 coupled and self - consistent equations , @xmath324 using ( [ changevar ] ) and the saddle point equation ( [ xmu ] ) it is easy to check that the overlaps @xmath325 are solutions to the set of equations ( [ scm ] ) .",
    "solutions are in one - to - one correspondance with the saddle points @xmath326 .",
    "the saddle - point solution @xmath327 corresponds to @xmath328 .",
    "the average interaction term in the energy function ( [ energy2 ] ) vanishes , meaning that configurations tend to be mainly determined by the fields .",
    "such a behaviour corresponds to the paramagnetic phase .",
    "the solution @xmath329 is locally stable if the eigenvalues of the matrix @xmath299 are all positive and , thus , if the patterns are weak enough .",
    "solutions with @xmath330 correspond to stronger patterns and interaction terms in ( [ energy2 ] ) having non zero values on average : they correspond to magnetized phases .",
    "the cross entropy @xmath331 depends on the solution @xmath285 through the variables @xmath332 only .",
    "once the @xmath332 s and the patterns @xmath117 s are inferred , it is easy to calculate the value of the fields @xmath12 based on equations ( [ changevar ] ) , ( [ xmu ] ) and ( [ deftig ] ) .",
    "one finds that @xmath12 is given by ( [ changevar ] ) where @xmath278 is substituted with @xmath332 .",
    "hence , the inferred parameters do not explicitely depend on the value of @xmath333 .",
    "the procedure followed to infer the patterns and the fields is not affected by the physical phase ( paramagnetic or magnetized ) of the system , though the values of the data @xmath13 and @xmath14 obviously depend on those physical properties .",
    "it may accidentally happen that equations ( [ xmu ] ) have different solutions with equal or almost equal contributions to the partition function @xmath41 .",
    "the most natural illustration is the case of zero field ( @xmath334 ) and one strong pattern , where two ferromagnetic states with opposite overlaps , @xmath335 and @xmath336 , coexist . in this latter case",
    "both states give equal contributions to the partition function .",
    "we first infer the patterns and the pseudo - magnetizations from @xmath337 .",
    "minimization of @xmath337 ( [ logppost0 ] ) over @xmath338 immediately shows that , up to @xmath339 corrections , pseudo- and true magnetizations coincide : @xmath340 without loss of generality we may write the patterns to infer as @xmath341 where @xmath342 are real - valued coefficients , and @xmath133 and @xmath343 are eigenvectors of @xmath17 . according to identity ( [ ordre0 t ] ) the conditions ( [ gauge ] ) are fulfilled in the large @xmath0 limit if the ( @xmath26 ) vectors @xmath344 and @xmath345 are orthogonal to each other , and to all the patterns @xmath346 and @xmath347 .",
    "the matrices @xmath299 ( [ matrixa ] ) and @xmath348 ( [ matrixab ] ) are then diagonal , while @xmath349 vanishes .",
    "we rewrite the cross entropy ( [ logppost0b ] ) as @xmath350    \\nonumber \\\\ & - & \\frac 1{2 } \\sum _ \\mu \\log \\left [ 1 + \\hat{a}^\\mu+   \\sum _ i ( \\hat{\\beta}_i^\\mu)^2\\right]\\end{aligned}\\ ] ] where @xmath351 is the restriction of @xmath17 to the @xmath352dimensional subspace orthogonal to the @xmath20 largest and @xmath24 smallest eigenvectors : @xmath353 minimizing @xmath337 over the coefficients @xmath121 and the vectors @xmath344 gives the coupled set of equations @xmath354 where @xmath355 is the squared norm of @xmath344",
    ". if the vector @xmath344 were non zero , it would be an eigenvector of @xmath17 with eigenvalue @xmath89 according to ( [ map2 ] ) .",
    "this can not be true as the largest eigenvalue of @xmath356 is smaller than @xmath146 .",
    "hence , @xmath357 . from ( [ map1 ] )",
    "we obtain @xmath358 we conclude that the maximum likelihood values for the @xmath20 attractive patterns are given by ( [ ordre0xi ] ) .",
    "the minimization of @xmath337 over the coefficients @xmath359 and the vectors @xmath360 can be done along the same lines .",
    "we find @xmath361 and @xmath362 .",
    "the maximum likelihood estimators for the @xmath24 repulsive patterns are given by ( [ ordre0xi ] ) again .",
    "once the patterns are computed the values of the local fields @xmath12 are obtained from ( [ ordre0hbis ] ) .",
    "notice that @xmath363 are typically of the order of @xmath364 , which entails that the components of the patterns are of the order of unity .",
    "though keeping each @xmath365 of the order of unity is a natural scaling in the infinite size limit @xmath192 , other scalings are possible . consider a pair of strongly coupled spins , _",
    "i.e. _ such that the correlation @xmath366 is sizeably larger than @xmath169 .",
    "according to expression ( [ defcoupl ] ) for the coupling @xmath11 induced by the patterns between spins @xmath210 and @xmath211 , we expect the pattern components to be of the order of @xmath2 .",
    "there is thus no compelling reason to assume that @xmath367 is vanishingly small for all components @xmath210 .    to end with",
    "we compute the decrease in cross entropy when adding a pattern attached to the eigenvalue @xmath368 or @xmath369 . inserting expressions ( [ amumap1],[amumap1b ] ) for @xmath370 in ( [ logppost2 ] ) we obtain @xmath371 a quantity which is strictly negative for @xmath372 .",
    "not surprisingly , adding more parameters to the model allows for a better fit of the data .",
    "we will see in section [ secoptim ] how the values of @xmath20 and @xmath24 can be determined .      when the sample size @xmath9 is large the posterior distribution @xmath70 tends to a gaussian law centered in the most likely values for the patterns , @xmath373 , and the pseudo - magnetizations , @xmath338 . for the sake of simplicty we consider below the case of attractive patterns only ; repulsive patterns can formally be seen as purely imaginary attractive patterns , see section [ exp67 ] .",
    "let @xmath374 denote the hessian matrix of @xmath337 .",
    "we find , to the leading orders , @xmath375 \\nonumber \\\\ & + & \\frac{\\lambda^\\mu\\lambda^\\nu}{n^2}(1-m_i^2)(1-m_j^2 ) ( \\xi^0)_i^\\nu ( \\xi^0)_j^\\mu \\ , \\\\ ( { \\bf h}^{t\\xi})_{ij}^{\\nu } & \\equiv & \\frac{\\partial^2\\phi^0 } { \\partial t_i\\partial   ( \\xi^0)^\\nu_j } \\simeq 0 \\ .\\end{aligned}\\ ] ] here , @xmath376 denotes the kronecker function and the expression of the lowest order coupling matrix , @xmath92 , is given in ( [ j0 ] ) .",
    "the sum over @xmath163 runs over all pattern indices .",
    "the cross second derivative , @xmath377 , of the order of @xmath378 , is much smaller than the expected order , @xmath379 , and can be neglected .",
    "the covariance matrix of the gaussian posterior probability @xmath70 is the inverse matrix of @xmath380 .",
    "the inverse is properly defined in the subspace of dimension @xmath381 , orthogonal to the modes generating the invariance over the patterns , see section [ secgenhop ] .",
    "we write @xmath382 , where @xmath383 is a diagonal matrix with elements : @xmath384 in the @xmath338-sector , and @xmath385 in the @xmath386-sector .",
    "matrix @xmath387 has a particularly simple expression in the eigenbasis of the correlation matrix @xmath17 , and can be diagonalized exactly after some simple algebra .",
    "we obtain the following expression for the covariance matrix of the fluctuations : @xmath388 _ { ij}\\ ,   \\label{errorbarh}\\ ] ] where @xmath389_{ij } = \\delta _ { ij}+ \\sum _ { \\rho=1}^p ( \\lambda^\\rho -1)\\ , v_i^\\rho\\ , v_j^\\rho   + \\sum _ { \\rho=1}^{\\hat p } ( \\hat\\lambda^\\rho -1)\\ , \\hat v_i^\\rho\\ , \\hat v_j^\\rho \\ .\\ ] ] the expressions for the fluctuations of the pattern components are reported in ( [ errorbar ] ) .",
    "note that the cross - term @xmath390 vanishes at the expected order of @xmath391 , and is actually of the order of @xmath392 only .",
    "using formula ( [ changevar ] ) we find that the error over the fields @xmath12 is of the order of @xmath393 , where @xmath32 .",
    "so far we have assumed that the number of patterns , @xmath20 , was known . in practice @xmath20",
    "is often determined based on simple criteria , such as how many eigenvalues come out from the spectrum of the correlation matrix ( section  [ rl ] ) .",
    "alternative approaches exist , _",
    "e.g. _ bayesian information criterion ( bic ) @xcite . in the bic",
    "the decrease @xmath394 ( [ gainphi ] ) in cross entropy obtained with a new pattern is added a cost @xmath395 , equal to the number of new parameters times the logarithm of the number of data .",
    "as the index @xmath131 increases the selected eigenvalue @xmath89 or @xmath396 gets closer to one ; @xmath397 ( [ gainphi ] ) decreases in absolute value , and , eventually , is counterbalanced by the cost term @xmath395 . the value of @xmath131 for which the two terms balance each other depends on the size of the data set : the higher @xmath9 , the more significative are the correlations and the more patterns we need to represent the interactions .",
    "however bic is mathematically justified when @xmath9 is large compared to @xmath0 , which is not always the case in real data sets .",
    "hereafter , we propose a different approach based on bayesian and geometric considerations . based on the discussion in section [ secresupatt ] we expect the squared norm @xmath398 of the transerve fluctuations @xmath399 to be non vanishing in the @xmath400 limits .",
    "let us call @xmath121 the squared projection of the @xmath136 rescaled pattern onto @xmath133 ( [ fluc78 ] ) .",
    "the same quantities , @xmath401 and @xmath402 , can be defined for repulsive patterns .",
    "we define the marginal probability @xmath403 of the squared projections @xmath404 and of the squared norms @xmath405 through @xmath406 \\nonumber\\\\ & \\times & \\exp\\bigg[-   \\frac{\\alpha}{2 } \\sum_\\nu \\hat \\omega ^\\nu \\",
    ", \\big ( ( \\hat{\\boldsymbol \\beta}^\\nu)^2-n\\,\\hat b^\\nu\\big ) \\bigg]\\\\ & \\times&p\\bigg[\\{t_i^0,\\frac{\\sqrt { n\\,a^\\mu } \\ ; v_i^\\mu + \\sqrt n\\beta^\\mu _ i}{\\sqrt{1-m_i^2}},\\frac{\\sqrt { n\\,\\hat a^\\nu } \\ ; \\hat v_i^\\nu + \\sqrt n\\hat \\beta^\\nu _ i}{\\sqrt{1-m_i^2}}\\}\\bigg ] \\ , \\nonumber\\end{aligned}\\ ] ] where @xmath70 is the posterior probability ( [ post ] ) , and the sums over @xmath131 and @xmath407 run from 1 to , respectively , @xmath20 and @xmath24 . after carrying out the integrals over the fluctuations @xmath344 and @xmath345 we obtain @xmath408\\nonumber\\end{aligned}\\ ] ] where @xmath409 is a normalization constant and @xmath410   + o\\big ( \\frac { \\log n}{n}\\big)\\ , \\nonumber \\\\ \\delta\\hat \\phi_m ( \\hat\\omega^\\nu ) & = & -\\hat \\lambda^\\nu \\ , \\hat a^\\nu + \\hat \\omega^\\nu \\,\\hat b^\\nu+\\log \\left ( 1 + \\hat a^\\nu+ \\hat b^\\nu\\right ) \\\\&- & \\frac 1{b}\\log \\det \\big [ \\hat\\omega^\\nu \\ , { \\bf 1 } + \\gamma^{(r)}\\big ]   + o\\big ( \\frac { \\log n}{n}\\big)\\ , \\nonumber\\end{aligned}\\ ] ] here @xmath411 denotes the @xmath0-dimensional identity matrix .",
    "when @xmath9 is large the integrals in ( [ trans ] ) are dominated by the contributions coming from the vicinity of the roots of @xmath412 maximimization of @xmath413 with respect to the @xmath414 s gives equations ( [ map1 ] ) and @xmath415 for each @xmath416 . we then compute the squared norm @xmath398 from the extremization condition ( [ calculbmu ] ) and obtain @xmath417 repeating the same procedure to maximize @xmath418 gives @xmath419    the difference between expressions ( [ amumap1 ] ) and ( [ amumap2 ] ) for the coefficients @xmath121 must be emphasized .",
    "@xmath70 defined in ( [ post ] ) is a probability density over @xmath420 pattern components , once the pseudo - magnetizations have been inferred .",
    "maximization of @xmath70 , or , equivalently , of @xmath331 over this large - dimensional space gives expression ( [ amumap1 ] ) for the projection @xmath421 of the pattern @xmath160 onto the @xmath136 largest eigenvector of @xmath17 , @xmath133 .",
    "instead of directly maximizing @xmath70 , we may first integrate out the orthogonal fluctuations to @xmath422 in @xmath70 , and obtain the marginal probability density @xmath403 for @xmath423 parameters only , namely the squared projections on the eigenvectors , @xmath121 , and the squared norms of the orthogonal fluctuations , @xmath398 . maximizing the marginal probability density @xmath403 or , equivalently , minimizing @xmath424 shows that @xmath398 ( [ amumap2 ] ) does not vanish , and that the value of the squared projection @xmath121 ( [ amumap2 ] ) is smaller than ( [ amumap1 ] ) .",
    "figure [ fig - schema0 ] sketches the geometrical meaning of the coefficient @xmath425 and the fluctuations @xmath399 , see ( [ fluc78 ] ) .",
    "small values of the angle @xmath132 are expected for reliable patterns .",
    "a similar picture can be drawn for repulsive patterns .",
    "we will see how expression ( [ amumap2 ] ) for the squared norm @xmath398 naturally arises in the context of random matrix theory .",
    "we now look for the corrections to the lowest order expressions of the patterns and the fields ( [ ordre0xi],[ordre0 t ] ) , encoded in expressions ( [ correxp ] ) and @xmath426 . the first order contribution to the cross entropy , @xmath304 ,",
    "can be seen as a perturbation to the lowest order cross entropy , @xmath337 , according to ( [ expphi ] ) .",
    "within linear response theory this perturbation will shift the maximum likelihood estimators by @xmath427 where the inverse of the hessian matrix of @xmath337 , @xmath374 , was given in section [ secerrcal ] .",
    "the calculation of the gradient of @xmath304 does not present any particular difficulty .",
    "the resulting corrections to the patterns are given in eqn ( [ ordre1xi ] ) .",
    "the expression for the shift in the pseudo - magnetization is @xmath428   \\\\ & + & \\sum _ { \\mu = 1}^{\\hat p } ( \\hat \\lambda^\\mu-1 ) \\ ; \\bigg [ c^{n+1-\\mu } \\ , \\hat v_i^\\mu\\ ,   \\sqrt{1-m_i^2}+ m_i\\ , ( \\hat v_i^\\mu)^2\\bigg]\\ .\\nonumber\\end{aligned}\\ ] ] where @xmath429 is given in ( [ defc3 ] ) . notice that , if the magnetizations @xmath13 vanish , so do the dominant and first - order contributions to the pseudo - magnetizations .",
    "an important issue is to determine how many configurations should be sampled in order to ensure that the inference of the patterns is accurate . to do so",
    ", we assume that the examples @xmath430 are drawn independently and at random from the equilibrium probability @xmath431 ( [ likelihood ] ) of a hopfield model , with fixed fields @xmath432 and patterns @xmath433 .",
    "we call @xmath434 $ ] the entropy of the posterior distribution @xmath70 ( [ post ] ) for the fields @xmath56 and patterns @xmath435 . in the large @xmath0 limit , we expect this entropy to be self - averaging , that is , to depend on the set of examples only through their number @xmath9 .",
    "we want to determine how fast @xmath436 decays with @xmath9 .",
    "to do so it is instructive to first consider the simple case where the local fields are known , and only one pattern has to be inferred .",
    "this specific situation is treated in great analytical details in section [ zeroh ] .",
    "the general ( and harder ) case where both fields and patterns have to inferred is treated in section [ nonzeroh ] .      throughout this section ,",
    "we assume that the local fields vanish , @xmath437 and that the number of patterns to be inferred is @xmath200 .",
    "the posterior entropy , @xmath438= -\\sum _ { \\{\\xi_i = \\pm \\tilde \\xi\\ } } p[0 , { \\boldsymbol \\xi}|\\{{\\boldsymbol\\sigma}^b\\ } ] \\ ; \\log p[0 , { \\boldsymbol \\xi}|\\{{\\boldsymbol\\sigma}^b\\ } ] \\ , \\ ] ] therefore measures the uncertainty about this unique pattern given a set @xmath9 sampled configurations .",
    "intuitively , the dependence of @xmath436 on @xmath9 is closely related to the physics of the hopfield model ( with pattern @xmath439 and zero fields ) used to generate the examples .",
    "if the model is in the paramagnetic phase , _ i.e. _ if the components of the pattern are weak @xcite , the examples @xmath430 have vanishingly small overlap ( [ defqmu ] ) with the pattern .",
    "we expect that a large number @xmath9 ( diverging with @xmath0 ) of examples is necessary to convey reliable information about the pattern .",
    "conversely , few configurations sampled in a ferromagnetic state around a strong pattern ( or its opposite ) should be sufficient to reconstruct the pattern .",
    "we now make this scenario quantitative in various cases .",
    "an important simplication arises when the pattern is restricted to have binary components , @xmath440 , with @xmath441 .",
    "hamiltonian ( [ energy ] ) with @xmath200 pattern is invariant under the exchange of the spin configuration and the pattern : @xmath442=e[\\boldsymbol \\xi , 0 , \\boldsymbol \\sigma]$ ] .",
    "our inference problem can thus be mapped onto a dual hopfield model , where the normalized inferred pattern , @xmath443 , plays the role of the dual spin configuration and the sampled spin configurations , @xmath430 , @xmath444 correspond to the @xmath9 dual patterns . in particular ,",
    "the posterior entropy @xmath436 is equal to the entropy of the dual hopfield model at inverse temperature @xmath445 the duality property allows us to exploit the well - understood physics of the hopfield model @xcite to simplify the study of our inference problem .      in the ferromagnetic regime ( @xmath446 )",
    ", the dual spin configuration is strongly magnetized along the dual patterns .",
    "going back to the inference problem , we find that the overlap between the inferred pattern and a sampled configuration , @xmath447\\prod_{b } p_h[\\boldsymbol\\sigma ^b,\\tilde { \\boldsymbol \\xi } ] \\ ; \\frac 1n\\sum_{i } \\xi_{i } \\sigma_{i}^1\\ , \\ ] ] may take values @xmath448 or @xmath449 , where @xmath450 is the positive root of @xmath451 .",
    "the sign of the overlap @xmath452 is random , depending on which one of the two states with opposite magnetizations the configuration @xmath453 in sampled in ; it is equal to @xmath454 or @xmath455 with equal probabilities @xmath456 .",
    "these statements hold if the thermodynamical limit , @xmath192 , is taken while @xmath9 is kept fixed .",
    "we find that @xmath436 is equal to the entropy of a single spin at inverse temperature @xmath457 , interacting with @xmath9 other spins of magnetization @xmath450 , @xmath458 where @xmath459 .",
    "figure  [ fig - entropy]a shows that the entropy is almost a pure exponential : @xmath460 where the decay constant , @xmath461 , is finite ( compared to @xmath0 ) . in the ferromagnetic regime",
    "few sampled configurations are sufficient to determine @xmath439 accurately .",
    "this result also applies to the case of a single ferromagnetic state .",
    "if the field @xmath56 does not strictly vanish and explicitely breaks the reversal symmetry between the two states , all configurations are sampled from the same state , with probability @xmath462 . remarkably , expression ( [ expresss ] ) for the entropy still holds .",
    "again we find that @xmath463 configurations are sufficient to infer the pattern .",
    "we will discuss in more details the inference in the ferromagnetic regime in sections [ ferro1 ] and [ secferro2 ] .      in the paramagnetic phase ( @xmath464 )",
    ", the overlap ( [ defm ] ) between the inferred pattern and an example is typically very small , @xmath465 .",
    "no inference is possible unless the number of examples , @xmath9 , scales linearly with @xmath0 ; we denote @xmath466 . in this regime",
    ", we expect the entropy to be self - averaging : @xmath467 $ ] does not depend on the detailed composition of the data set and is a function of the value of the macroscopic parameters , _",
    "e.g. _ the ratio @xmath229 , only . to calculate this function @xmath436 we use the replica method @xcite .",
    "we report below the results of the replica symmetric calculation ; technical details can be found in appendix .",
    "the order parameter is the average overlap @xmath468 between the inferred and the true patterns , @xmath469\\prod_{b } p_h[\\boldsymbol\\sigma ^b,\\tilde { \\boldsymbol \\xi } ] \\ ; \\frac 1n\\sum_{i } \\xi_{i } \\tilde \\xi_{i}\\ .\\ ] ] which is solution of the self - consistent equation @xmath470 where @xmath471 is the gaussian measure , and @xmath472 the posterior entropy is equal to @xmath473 and is plotted in fig .",
    "[ fig - entropy]b . to check this analytical prediction",
    "we have run extensive numerical simulations on small - size systems ( @xmath474 ) .",
    "the numerical procedure follows three steps : 1 .",
    "evaluate the partition function @xmath41 in ( [ likelihood ] ) through an exact enumeration ; 2 . generate a data set of @xmath475 configurations @xmath476 according to the hopfield measure @xmath42 by rejection sampling ; 3 . evaluate @xmath61 in ( [ post ] ) and @xmath436 in ( [ defs1 ] ) through exact enumerations .",
    "the resulting entropy , averaged over one hundred data sets , is compatible with the analytical prediction and the existence of @xmath477 finite - size effects .",
    "inset of fig .",
    "[ fig - entropy]b shows that the overlap @xmath468 remains null until @xmath229 reaches the critical value @xmath478 hence , in the range @xmath479 $ ] , the posterior probability becomes more concentrated ( @xmath436 decreases ) , but not around the true pattern @xmath480 .",
    "the existence of a lagging phase before any meaningful inference is possible is similar to the retarded learning phenomenon discovered in the field of unsupervised learning , where the variables to be learned are real - valued @xcite . in the present case of binary spins",
    "we expect the replica symmetric assumption to break down at large @xmath229 .",
    "the entropy ( [ sentro ] ) indeed becomes negative when @xmath481 for the case studied in fig .",
    "[ fig - entropy]b .",
    "nevertheless we may conjecture that the entropy decays as @xmath482 when @xmath483 .",
    "the dual hopfield model has random couplings @xmath11 , with second moment equal to @xmath484 .",
    "hence @xmath485 sets the temperature scale of the dual model .",
    "the low temperature scaling of the entropy of the sherrington - kirkpatrick ( sk ) model suggests that @xmath486 @xcite ; this scaling is compatible with the small@xmath0 results of fig .",
    "[ fig - entropy]b",
    ". however the dual and sk models are not strictly identical when @xmath487 : the coupling matrix @xmath27 of the dual model is guaranteed to be semidefinite positive , while the entries of @xmath27 are independent in the sk model . a complete calculation of the entropy valid for any ( large ) @xmath229 would require a replica symmetry broken ansatz for the order parameters @xcite , and is beyond the scope of this article .",
    "note that the calculations above can be extended to real patterns ; @xmath457 in ( [ defbeta ] ) is then replaced with @xmath488 , where the average is taken over the pattern components .",
    "the entropy is not constrained to be positive as in the binary case .",
    "the distinction between the strong- and weak - component regimes remains qualitatively unchanged , and so does the value of the critical ratio @xmath489 ( [ alphac ] ) , which does not depend on the third and higher moments of @xmath490 .      in this section ,",
    "we first interpret the above results .",
    "we show that , while @xmath463 configurations can be sufficient in a particular context , @xmath491 data are generally necessary for the inference to be sucessful . the connection between the results of section [ zeroh ] and random matrix theory are emphasized .",
    "consider first the case where a single state exists , _",
    "i.e. _ equations ( [ scm ] ) admit a single solution @xmath492 ; the case where states coexist will be discussed in section [ secferro2 ] . for large @xmath0 ,",
    "the average value of spin @xmath210 with the measure @xmath42 ( [ likelihood ] ) is @xmath493 as the error on the estimate of @xmath13 decreases as @xmath494 with @xmath9 , @xmath495 configurations are sufficient to sample the magnetizations accurately .",
    "few sampled configurations therefore give access to the knowledge of a linear combination of the field vector and pattern vectors with non zero - overlaps @xmath496 .",
    "this linear combination is simply @xmath497 , and equation ( [ localmi ] ) coincides with ( [ ordre0 t ] ) .",
    "when the fields @xmath12 are known and the model consists of a single strong pattern ( @xmath200 ) the pattern components @xmath498 can be readily calculated from the magnetizations ( [ localmi ] ) through @xmath499 this particular case was encountered at the end of section [ strong1 ] , when the fields @xmath12 are sent to zero after having broken the reversal symmetry of the system to avoid state coexistence . in the generic situation of unknown fields and patterns , knowledge of the magnetizations",
    "does not suffice to determine the field and the patterns , and must be supplemented with the information coming from the correlation matrix @xmath366 .",
    "what is the order of magnitude of @xmath366 ?",
    "we first consider the ideal case of perfect sampling ( @xmath90 while @xmath0 is large but finite ) . as a result of the presence of the patterns in the energy ( [ energy ] )",
    "the spins are correlated .",
    "the entries of the correlation matrix are , for large @xmath0 , ) can be found by inverting identity ( [ jtap ] ) , with @xmath500 . ]",
    "@xmath501 where we have considered the case of a single pattern ( @xmath502 ) to lighten notations .",
    "though the pattern affects each correlation @xmath366 by @xmath213 only , these small contributions add up to boost the largest eigenvalue from one ( in the absence of pattern ) to @xmath503 the eigenvector attached to @xmath504 has components @xmath505 and ml inference perfectly recovers the pattern .    in the presence of sampling noise ( finite @xmath9 ) , each correlation ( [ cc ] ) is corrupted by a stochastic term of the order of @xmath506 .",
    "this stochastic term will , in turn , produce an overall contribution of the order of @xmath507 to the largest eigenvalue .",
    "intuitively , whether @xmath229 is large or small compared to @xmath508 should tell us how hard or easy it is to extract the pattern @xmath202 from @xmath17 .",
    "several studies in the physics @xcite and in the mathematics @xcite literatures have indeed found that an abrupt phase transition takes place at the critical ratio @xmath509 it is a simple check that @xmath489 coincides with the ratio ( [ alphac ] ) for the retarded learning transition calculated in sections [ weak1 ] .    in the strong noise regime ( @xmath510 )",
    "the largest eigenvector @xmath511 of @xmath17 is uncorrelated with ( orthogonal to ) the pattern @xmath435 , and the spectrum of @xmath17 is identical to the one of the sample correlation matrix of independent spins , whose density of eigenvalues is given by the marcenko - pastur ( mp ) law , @xmath512 with @xmath513 @xcite .",
    "the edges of the continuous component of the mp spectrum are given by @xmath514 the largest eigenvalue of @xmath17 , @xmath515 , is not related to the value of @xmath504 .",
    "in the weak noise regime ( @xmath516 the largest eigenvalue of @xmath17 is @xcite @xmath517 it exceeds @xmath504 for any finite @xmath229 , and converges to @xmath504 when @xmath487 .",
    "the rest of the spectrum is described by the mp density ( [ mpd ] ) .",
    "expression ( [ aaabbb ] ) for the squared norm @xmath518 of the orthogonal fluctuations leads to the analytical formula @xmath519 where we have used the analytical expression of the stieltjes transform of @xmath520 @xcite . using ( [ amumap2 ] ) we deduce the value of the squared projection of the inferred rescaled pattern @xmath521 onto @xmath511 , @xmath522 identities ( [ valueb ] ) and ( [ valuea ] ) are graphically interpreted in fig .",
    "[ fig - schema0 ] : @xmath518 is the squared norm of the orthogonal fluctuations @xmath523 , while @xmath524 is the squared projection of the rescaled pattern @xmath202 onto @xmath511 .",
    "the above discussion is illustrated on the simple case of a hopfield model with @xmath502 patterns in fig .",
    "[ fig - spectre ] , see caption for the description of the model .",
    "using formula ( [ valuel ] ) we compute the largest eigenvalue of the correlation matrix for perfect sampling , @xmath525 .",
    "figure  [ fig - spectre ] shows that a large eigenvalue clearly pulls out from the bulk spectrum for the ratio @xmath526 ( top spectrum ) , larger than the critical ratio @xmath527 according to ( [ ac ] ) ( bottom ) . for @xmath526 ,",
    "the infinite@xmath0 predicted values for the largest eigenvalue , @xmath528 ( [ valuel1 ] ) , and for the edges of the mp spectrum , @xmath529 ( [ valuemp ] ) , are in good agreement with the numerical results for @xmath182 .",
    "b    formulae ( [ valueb ] ) and ( [ valuea ] ) hold for each pattern @xmath131 when @xmath530 patterns are present , provided that @xmath20 remains finite when @xmath192 .",
    "the case of @xmath531 patterns , where one pattern is strong and has overlap @xmath532 ( [ defm ] ) with the sampled configurations , and the second pattern has weak components , is of particular interest .",
    "again , we assume that the fields vanish . repeating the calculation of section",
    "[ weak1 ] and appendix a we find that the entropy @xmath533 quickly decreases with @xmath9 from 2 bits down to 1 for @xmath463 .",
    "when @xmath534 , the entropy decreases from 1 down to 0 ; the expression of @xmath436 coincides with ( [ sentro ] ) where @xmath457 is replaced with @xmath535 .",
    "hence we have a two - step behaviour : the strong pattern is determined with @xmath495 examples , the weak pattern requires @xmath177 sampled configurations .",
    "learning of the weak pattern is possible if @xmath536 according to ( [ alphac ] ) .",
    "the two - step behaviour agrees with the discussion of section [ ferro1 ] .",
    "consider now the case of the coexistence of two ferromagnetic states exposed in section [ seccoex ] .",
    "data are generated from a hopfield model , with zero fields and one strong pattern @xmath202 , as in fig .",
    "[ fig - compar-1patt - bis ] . in the up - state the spins",
    "are magnetized with @xmath537 . in the down - state",
    "the local magnetization is @xmath538 . on the overall",
    "the local magnetization is @xmath539 , up to @xmath540 fluctuations .",
    "the discrepancy between the gibbs magnetizations , @xmath541 , and the state magnetizations , @xmath542 , results in a @xmath495 contribution @xmath543 to the correlation matrix entry @xmath366 , dominating the @xmath213 contributions due to the interactions between spins .",
    "the largest eigenvalue of @xmath17 , @xmath544 is of the order of @xmath0 ; the corresponding eigenvector is @xmath545 . informally speaking ,",
    "the information about the state magnetizations is not conveyed by the gibbs magnetizations ( as in section [ ferro1 ] ) but by the correlation matrix @xcite . according to formula ( [ ordre0 t ] ) the pseudo - magnetization @xmath332 vanishes",
    "; hence we correctly infer that the fields @xmath12 have zero values .",
    "using formula ( [ ordre0xi ] ) we obtain @xmath546 therefore , the inferred pattern component is not equal to the true pattern component , but is proportional to its hyperbolic tangent .",
    "this non linear transform is clearly seen in fig .",
    "[ fig - compar-1patt - bis ] .",
    "the discrepancy between the true and inferred components is a nice illustration of the claimed scaling for the higher order corrections in ( [ expr ] ) ( recall that the eigenvalues of @xmath315 are the @xmath20 largest eigenvalues of @xmath17 ) . in the presence of coexistent states , while @xmath311 is small compared to @xmath0 , @xmath547 is of the order of @xmath0 , making the ratio @xmath548 of the order of unity .",
    "corrections are required and shown to improve the quality of the inferred pattern in fig .",
    "[ fig - compar - patt1-corr ] .",
    "in this paper we have studied how to infer a small - rank interaction matrix between @xmath0 binary variables given the average values and pairwise correlations of those variables .",
    "we have seen that the generalized hopfield model , where the interactions are encoded into a set of attractive and repulsive patterns @xmath435 , is a natural framework for maximum likelihood ( ml ) inference . using techniques from the statistical physics of disordered systems ,",
    "we have presented a systematic expansion of the log - likelihood in powers of @xmath549 , where @xmath550 is the largest eigenvalue of the correlation matrix @xmath17 ( [ defgamma ] ) .",
    "we have then calculated the ml estimators for the patterns and the fields to the lowest and first order in this expansion in a variety of physical regimes .",
    "the lowest order is a simple extension of principal component analysis , where not only the largest but also the smallest eigenmodes build in the interactions .",
    "first order corrections involve non - linear combinations of the eigenvalues and eigenvectors of @xmath17 .",
    "we have validated our ml expressions for the patterns on synthetic data generated by hopfield models with known patterns and fields , and by ising models with sparse interactions .",
    "we have also presented a simple geometrical criterion for deciding the number of patterns .",
    "those results have been discussed and compared to previous studies in the unsupervised learning and random matrix literatures .",
    "the quality of the inference strongly depends on the number of sampled configurations , @xmath9 .",
    "the sampling error on each magnetization , @xmath13 , and pairwise correlation , @xmath14 , is of the order of @xmath242 .",
    "elementary insights from random matrix theory suggest that the resulting errors on the eigenvectors of the matrix @xmath17 are @xmath2 times larger .",
    "the error on the inferred patterns , @xmath166 , picks up a contribution @xmath551 due to finite sampling , as found in section [ secsam ] .",
    "this scaling has several important consequences .",
    "first , inference is retarded : no information about the true couplings can be obtained unless the ratio @xmath552 exceeds a critical value ( sections [ weak1 ] and [ rl ] ) .",
    "secondly , for larger @xmath9 , @xmath166 decreases as @xmath242 , which is confirmed by the simulations presented in fig .",
    "[ fig - compar - pca - corr ] , and then saturates to the intrinsic error resulting from our approximate expressions for the patterns .",
    "the intrinsic error depends on the order in the expansion used for the calculation of the cross - entropy in section [ secinf ] .",
    "note that other inference methods , looking for the local structure of the interaction network @xcite , may unveil strong couplings @xmath198 from a much smaller number of sampled configurations , @xmath553 , and do not suffer from the retarded learning transition .",
    "our study could be extended in several directions .",
    "it would be particularly interesting to consider the case of spins taking @xmath554 values ( potts model ) , _",
    "e.g. _ for applications to the study of coevolution between residues in protein sequences @xcite .",
    "mean - field inference methods provide a simple and efficient way to get interactions from correlations @xcite . knowing how mf interactions are modified when some eigenmodes are rejected ( using the criterion of section [ secresupatt ] ) or first - order corrections are taken into account",
    "would be of interest .",
    "however the linear increase in the number of possible symbols with @xmath555 ( @xmath556 for amino - acids ) may make the effective size of the problem , @xmath557 , larger than the number of configurations , @xmath9 , in practical applications .",
    "a large number of vanishing eigenvalues is expected in those cases , and extracting repulsive patterns may become a difficult task .",
    "appropriate priors @xmath60 could also be used to force many pattern components to identically vanish , instead of acquiring small values as in section [ secregu ] .",
    "this can be particularly useful when the true patterns are known to be highly sparse and few data are available .",
    "inspired by the so - called lasso regression method @xcite , a natural prior is @xmath558\\ .\\ ] ] contrary to the case of the quadratic penalty ( [ regu1 ] ) the most likely values for the patterns can not be expressed by means of simple analytical formulae .",
    "however , they could be efficiently obtained using convex optimization algorithms minimizing the sum of the cross entropy and of the penalty term ( [ regu2 ] ) .",
    "last of all , we have considered in this work that the configurations were sampled at equilibrium . in practice , when more than one state exist , the equilibration time may be prohibitive and a reasonable assumption would be to sample from one state only .",
    "to what extent ergodicity breaking in the sampling affects the quality of inference is an interesting question .",
    ".3 cm * acknowledgments : * we thank s. leibler for numerous discussions .",
    "thanks the simons center for systems biology for its hospitality .",
    "this work was partially funded by the anr contract 06-jc - jc-051 .",
    "when the pattern has binary components @xmath559 we make the change of variables @xmath560 to rewrite the partition function ( [ pf ] ) of the hopfield model through @xmath561 \\ , \\label{eq_mattis_cw}\\ ] ] where the inverse temperature @xmath457 is defined in ( [ defbeta ] ) .",
    "the partition function is thus independent of the pattern direction , which makes the calculation considerably simpler .",
    "the posterior entropy ( [ defs1 ] ) can be written as @xmath562 = \\left ( 1 - \\beta \\;\\frac{\\partial}{\\partial \\beta}\\right ) \\log \\tilde n [ \\{\\boldsymbol\\sigma ^b\\},\\beta ] \\ , .",
    "\\label{eq_entro11}\\ ] ] where @xmath563 = \\sum_{\\{\\boldsymbol\\xi\\}}\\exp \\left(\\frac{\\beta}{n } \\sum_{b=0}^b \\sum_{i < j } \\xi_i \\xi_j \\sigma_i^b   \\sigma_j^b \\right)\\ , , \\label{eq_ntil}\\ ] ] thus , we are left with the calculation of @xmath564 $ ] .",
    "the expression for @xmath565 is formally identical to the partition function of a dual hopfield model where the @xmath9 measured configurations @xmath566 play the role of the dual patterns and @xmath202 plays the role of the dual spin variables .",
    "the posterior entropy @xmath436 is simply the entropy of this dual hopfield model",
    ".    equation ( [ eq_entro11 ] ) gives the entropy of the system for a particular set of measures @xmath567 .",
    "it is natural to expect the entropy to be reproducible across different sets of measurements . in this context , we are interested in evaluating the average of the entropy with respect to all possible measurements . assuming that the configurations @xmath567 are sampled from the equilibrium measure of a hopfield model with one pattern @xmath439 , we write the average entropy as @xmath568 where @xmath569 \\ , , \\end{aligned}\\ ] ] where we have introduced a new variable @xmath570 since we should not take the derivative only with respect to @xmath457 in ( [ eq_entro11bis ] ) .    to calculate the average value of the logarithm of @xmath571 in ( [ a5 ] ) we use the replica trick @xcite and estimate the @xmath572 moment of @xmath571 , @xmath573 \\ .\\end{aligned}\\ ] ] we introduce auxiliary gaussian variables , denoted by @xmath574 , to linearize the quadratic term in the spins @xmath575 .",
    "we obtain , after summation over the spins , @xmath576 \\",
    ", .\\nonumber \\end{aligned}\\ ] ] in the paramagnetic phase we expect the variables @xmath577 and @xmath574 to be of the order of @xmath578 . expanding the hyperbolic cosine to the second order in those variables and carrying out the resulting gaussian integral we obtain @xmath579^{-b/2}\\ , .\\ ] ] here , @xmath580 is the @xmath581 matrix with elements @xmath582 with the overlaps defined through @xmath583 and @xmath584 .",
    "we now enforce the definitions of the overlaps using conjugated lagrange multipliers , @xmath585 and @xmath586 , and obtain @xmath587 where @xmath588 is given by @xmath589 \\ , .\\end{aligned}\\ ] ] we look for a replica - symmetric saddle point of @xmath588 : @xmath590 , @xmath591 , @xmath592 and @xmath593 .",
    "we obtain , after some elementary algebra ,      where @xmath595 is the gaussian measure and @xmath596 \\ .\\end{aligned}\\ ] ] we now send @xmath597 to zero .",
    "the saddle - point equations show that @xmath598 ; this result was expected from the fact that , if @xmath599 , the true pattern @xmath600 plays the role of an extra replicated pattern @xmath1 .",
    "in addition , @xmath601 , where @xmath148 is defined in ( [ defgop ] ) .",
    "the self - consistent equations for @xmath468 and the entropy @xmath436 are given by , respectively eqns ( [ defrop ] ) and ( [ sentro ] ) ."
  ],
  "abstract_text": [
    "<S> we consider the problem of inferring the interactions between a set of @xmath0 binary variables from the knowledge of their frequencies and pairwise correlations . the inference framework is based on the hopfield model , a special case of the ising model where the interaction matrix is defined through a set of patterns in the variable space , and is of rank much smaller than @xmath0 . </S>",
    "<S> we show that maximum likelihood inference is deeply related to principal component analysis when the amplitude of the pattern components , @xmath1 , is negligible compared to @xmath2 . using techniques from statistical mechanics , we calculate the corrections to the patterns to the first order in @xmath3 . we stress that it is important to generalize the hopfield model and include both attractive and repulsive patterns , to correctly infer networks with sparse and strong interactions . </S>",
    "<S> we present a simple geometrical criterion to decide how many attractive and repulsive patterns should be considered as a function of the sampling noise . </S>",
    "<S> we moreover discuss how many sampled configurations are required for a good inference , as a function of the system size @xmath0 and of the amplitude @xmath1 . </S>",
    "<S> the inference approach is illustrated on synthetic and biological data . </S>"
  ]
}