{
  "article_text": [
    "since the discovery of impredictability in deterministic systems that led to the study of chaotic dynamical systems , much work has been done to find properties of chaos that could give a classification of these systems . in particular indicators like lyapounov exponent , kolmogorov - sinai entropy , topological entropy and others have been developed .",
    "nevertheless , in recent years there have been found dynamical systems for which all the known indicators do nt give the presence of chaos , but numerical results show a high order of impredictability for orbits of these systems .",
    "this phenomenon has led to attempts to generalize the known indicators ( for example see @xcite,@xcite ) , but has also stimulated the research for new properties of these systems .",
    "one of the possible new approaches to these _ weakly chaotic _",
    "dynamical systems is related to information theory , that is to the notion of information content of a symbolic string . in section [ sioss ]",
    "we give the definition of information content and show how to apply this technique to dynamical systems .",
    "in particular we study the dynamics of the logistic map ( see equation ( [ logmap ] ) ) at the chaos threshold , that represents one of the best known examples of weak chaos . in section [ stlmfipov ]",
    "we give the theoretical results that allow a classification of our map among the weakly chaotic dynamical systems .",
    "our theoretical approach is based on the notion of _ algorithmic information content",
    "_ introduced by kolmogorov and chaitin ( see section [ sioss ] ) , and unfortunately this notion of information is not computable , in the sense that can not exist an algorithm which computes this function .",
    "hence to numerically confirm our results , we have to use an approximate notion of information content . in section [ sca ] , we present a possible approach to this problem , that consists on the use of compression algorithms to obtain an estimate for the information contained in a string .",
    "in particular a new compression algorithm , called castore , is presented and some of its properties are illustrated .",
    "finally in section [ serotlm ] , we apply castore to the logistic map at the chaos threshold to confirm the theoretical predictions for the behaviour of the algorithmic information content of the strings generated by the map .",
    "in our approach the basic notion is the _ information content of a symbolic sequence_. given a finite string @xmath1 of length @xmath2 , that is a finite sequence of symbols @xmath3 , @xmath4 , taken in a given alphabet , the intuitive meaning of _ quantity of information _",
    "@xmath5 contained in @xmath1 is the following one :    @xmath5 _ is the length of the smallest binary message from which you can reconstruct _ @xmath1 .",
    "formally , this notion leads to the definition of the _ algorithmic information content ( aic ) _ ( or _ kolmogorov complexity _ ) introduced by chaitin ( @xcite ) and kolmogorov ( @xcite ) . in order to define it ,",
    "it is necessary to define the _ partial recursive functions_. we limit ourselves to give an intuitive idea which is very close to the formal definition .",
    "we can consider a partial recursive function as a computer @xmath6 which takes a program @xmath7 ( namely a binary string ) as an input , performs some computations and gives a string @xmath8 , written in the given alphabet , as an output .",
    "the aic of a string @xmath9 is defined as the shortest binary program @xmath7 which gives @xmath9 as its output , that is @xmath10 where @xmath11 means the length of the string @xmath7 . a computing machine is called _ universal _ ( namely it is a computer in the usual sense of the word ) if it can simulate any other machine ( for a precise definition see any book on recursion ) . in particular if @xmath6 and @xmath12 are universal then @xmath13 , where the constant depends only on @xmath6 and @xmath12 .",
    "this implies that , if @xmath6 is universal , the complexity of @xmath9 with respect to @xmath6 depends only on @xmath9 up to a fixed constant and then its asymptotic behavior does not depend on the choice of @xmath6 .",
    "thus , we will just write @xmath14 in equation ( [ eaic ] ) when referring to the aic of the string @xmath9 .",
    "we now extend the concept of information to strings generated by a dynamical system @xmath15 . using the usual procedure of symbolic dynamics , given a partition @xmath16 of the phase space of the dynamical system @xmath15 , it is possible to associate a string @xmath17 to the orbit having @xmath18 as initial condition . if @xmath19 then @xmath20 if and only if @xmath21 with @xmath22 .",
    "the aic of a single orbit of the dynamical system is then the aic of the symbolic string generated by the orbit .",
    "if we want not to have dependence on the partition @xmath16 of the phase space , then we have to make some procedure of looking for the supremum varying the partitions .",
    "the first results have been obtained by brudno ( @xcite ) using open covers of the phase space .",
    "another possible approach , using computable partitions , is introduced in @xcite .",
    "we are not interested in this problem , but we will just assume that the partitions we consider are _ generating _ in the sense that they give the best approximation for the aic of an orbit of our dynamical system .",
    "there exist some results connecting the information content of a string generated by a dynamical system and the kolmogorov - sinai entropy @xmath23 of the system .",
    "first of all it is proved that in a dynamical system with an ergodic invariant measure @xmath24 with positive k - s entropy @xmath25 , the aic of a string @xmath2 symbols long behaves like @xmath26 for almost any initial condition with respect to the measure @xmath24 ( @xcite ) .    instead ,",
    "in a periodic dynamical system , we expect to find @xmath27 . indeed , the shortest program that outputs the string @xmath1 would contain only information on the period of the string and on its length .",
    "it is possible to have also intermediate cases , in which the k - s entropy is null for all the invariant measures that are physically relevant and the system is not periodic .",
    "these systems , whose behaviour has been defined _ weak chaos _ , are an important challenge for research on dynamical systems .",
    "indeed no information are given by the classical properties , such as k - s entropy or lyapounov exponents , and in the last years some generalized definitions of entropy of a system have been introduced to characterize the behaviour of such systems ( for example see @xcite ) .",
    "we believe that an approach to weakly chaotic systems using the order of increasing of their aic could be a powerful way to classify these systems .",
    "this approach has already been used for the manneville map ( @xcite , @xcite):@xmath28\\ , \\",
    "z\\geq 1\\ .\\ ] ] in the cited papers it is proved that the aic of the manneville map behaves , for values @xmath29 of its parameter , as @xmath30 and this behaviour has been defined _",
    "sporadicity_.    among the weakly chaotic systems , one can identify behaviours different from the sporadic one . as an example",
    ", the aic can have order smaller than any power law ( with respect to the length of the encoded string ) .",
    "we choose to call this behaviour * mild chaos*.    in this paper we show that the aic of the logistic map at the chaos threshold is of order of @xmath31 ( theorem [ taic ] and section [ serotlm ] ) .",
    "then , we will prove that the weakly chaotic dynamics of the logistic map at the chaos threshold is in particular _",
    "we now apply the theory of the algorithmic information content of an orbit of a dynamical system to the logistic map at the chaos threshold .",
    "we first give some well known results on the dynamics of the map , and then use these results to obtain an estimate for the aic .",
    "the logistic map , defined by @xmath32\\ , \\quad 1 \\leq \\lambda \\leq 4 , \\label{logmap}\\ ] ] is a very simple example of a map with an extremely complicated behaviour for some values of the parameter @xmath33 .",
    "the dynamics of the map have been studied extensively , and there are many important results that have been generalized to one dimensional dynamical systems . here",
    "we give a brief description of the well known period doubling sequence , and recall some results for the dynamics at the chaos threshold .",
    "the references for the first part of this section are @xcite , @xcite , @xcite .",
    "consider first @xmath34 .",
    "there are two fixed points , @xmath35 and @xmath36 .",
    "the fixed point at the origin is unstable and the point @xmath37 is stable .",
    "then every orbit ends up on the fixed point @xmath37 .    when @xmath38 , we have the first bifurcation .",
    "the derivative of @xmath39 at the point @xmath37 is -1 , and the fixed point is now neutrally stable .",
    "moreover one periodic orbit of period 2 is generated and it becomes stable as soon as @xmath33 becomes greater than @xmath40 .",
    "this is a period doubling bifurcation .",
    "this kind of bifurcation repeats over and over at different values @xmath41 of the parameter .",
    "that is , when @xmath42 , there is one stable periodic orbit of period @xmath43 , and unstable periodic orbits of period @xmath44 , @xmath45 .",
    "when @xmath46 , the stable periodic orbit loses its stability and a new periodic orbit of period @xmath47 is generated .",
    "one of the main features of this bifurcation sequence is that the bifurcation parameters @xmath41 accumulate at @xmath48 , where @xmath49 moreover it holds @xmath50 where @xmath51 is the so - called _ feigenbaum constant _ and @xmath52 is a suitable constant ( @xcite ) .",
    "the behaviour of the logistic map at the chaos threshold has attracted much attention , in particular for being a map with null kolmogorov entropy for any invariant probability measure , and nevertheless showing a weakly chaotic behaviour .",
    "we recall that in this paper by _ weak chaos _",
    "we mean the behaviour of a map with null kolmogorov entropy for all the physically relevant invariant measures and with a dynamics that is neither periodic nor regular in some sense . as we have seen in section [ sioss ] , a way to classify weakly chaotic maps is given by the _",
    "algorithmic information content ( aic ) _ of a string generated by the map .",
    "let s consider now the map @xmath53 .",
    "for this map there are countably many unstable periodic orbits of periods @xmath44 , for all @xmath54 , and an attractor @xmath55 that is a cantor set , the so - called _",
    "feigenbaum attractor_. it holds the following theorem ( @xcite , theorem iii.3.5 ) :    [ teckmann ] the logistic map @xmath53 at the chaos threshold has an invariant cantor set @xmath55 .",
    "\\(1 ) there is a decreasing chain of closed subsets @xmath56 each of which contains @xmath57 , and each of which is mapped onto itself by @xmath53 .",
    "\\(2 ) each @xmath58 is a disjoint union of @xmath59 closed intervals .",
    "@xmath60 is constructed by deleting an open subinterval from the middle of each of the intervals making up @xmath58 .",
    "\\(3 ) @xmath53 maps each of the intervals making up @xmath58 onto another one ; the induced action on the set of intervals is a cyclic permutation of order @xmath59 .",
    "\\(4 ) @xmath61 .",
    "@xmath53 maps @xmath55 onto itself in a one - to - one fashion .",
    "every orbit in @xmath55 is dense in @xmath55 .",
    "\\(5 ) for each @xmath62 , @xmath53 has exactly one periodic orbit of period @xmath63 .",
    "this periodic orbit is repelling and does not belong to @xmath64 .",
    "moreover this periodic orbit belongs to @xmath65 , and each point of the orbit belongs to one of the intervals of @xmath66 .",
    "\\(6 ) every orbit of @xmath53 either lands after a finite number of steps exactly on one of the periodic orbits enumerated in 5 , or converges to the cantor set @xmath55 in the sense that , for each @xmath67 , it is eventually contained in @xmath66 .",
    "there are only countably many orbits of the first type .",
    "a characteristic of chaotic dynamical systems is the _ sensitivity to initial conditions_. roughly speaking we can say that a system has sensitive dependence on initial conditions if two orbits that start close diverge .    it is well known that the kolmogorov - sinai entropy is related to the sensitivity to initial conditions of the orbits .",
    "the exact relations between the k - s entropy and the instability of the system is given by the ruelle - pesin theorem .",
    "we will recall this theorem in the one - dimensional case .",
    "suppose that the average rate of separation of nearby starting orbits is exponential , namely @xmath68 where @xmath69 denotes the distance of these two points at time @xmath2 .",
    "if the lyapounov exponent @xmath33 is positive then the system is unstable and @xmath33 can be considered a measure of its instability ( or sensibility with respect to the initial conditions ) .",
    "the ruelle - pesin theorem implies that , under some regularity assumptions , @xmath33 equals the k - s entropy .",
    "the logistic map at the chaos threshold has null kolmogorov entropy for any invariant probability measure ( it is shown by continuity of topological entropy and by the variational principle ) , and null lyapounov exponent ( experimental results ) , but nevertheless numerical experiments show that there is a power law divergence for nearby orbits .",
    "this feature of the logistic map has induced the application of a generalized version of the thermo - dynamical entropy ( @xcite , @xcite ) .",
    "formally , we have :    [ sti ] a dynamical system @xmath70 has _ sensitivity to initial conditions _ if there exists @xmath71 such that , for all @xmath72 and for all neighbourhoods @xmath73 of @xmath74 , there exist @xmath75 and @xmath76 such that @xmath77 .    [ tsti ]",
    "the logistic map at the chaos threshold has no sensitivity to initial conditions .",
    "indeed there exists a subset @xmath78 $ ] with @xmath79 , for the lebesgue measure @xmath80 , such that for all @xmath71 and for all @xmath72 , there exists a neighbourhood @xmath81 of @xmath74 such that @xmath82 and @xmath83 we have @xmath84 .",
    "* by theorem [ teckmann](6 ) , we have that eventually almost every orbit , with respect to the lebesgue measure @xmath80 , ends up on @xmath66 for all @xmath67 .",
    "moreover by theorem [ teckmann](1 ) , we have that @xmath85 .",
    "let now @xmath71 be fixed .",
    "being @xmath55 a cantor set , there exists @xmath86 such that @xmath87 for all @xmath88 , where by @xmath89 we denote the intervals making up @xmath90 .",
    "we have ( theorem [ teckmann](3 ) ) that the action of @xmath53 on @xmath90 is a cyclic permutation of the @xmath91 intervals .",
    "then if @xmath92 , for some @xmath93 , and @xmath81 is a neighbourhood of @xmath74 contained in @xmath89 , then , for all @xmath2 , @xmath94 , for some @xmath95 . hence @xmath82 and @xmath83 , we have @xmath84 .",
    "let now @xmath96 be the set of the points whose orbit is eventually contained in @xmath90 . by theorem [ teckmann](6 )",
    ", we have @xmath79 .",
    "let now be @xmath18 , then there exists a neighbourhood @xmath81 of @xmath74 , such that , if @xmath97 for some @xmath93 , then @xmath98 .",
    "the neighbourhood @xmath81 exists by continuity of the map @xmath53 .",
    "now , we can repeat the same argument as before , showing that @xmath82 and @xmath83 , we have @xmath84 ( if necessary it is possible to shrink the neighbourhood @xmath81 to have the previous relation for all @xmath99 ) .    0.5 cm    hence it remains the problem of explaining the power law divergence of nearby orbits .",
    "one way to give an estimate of the order of this divergence is by considering the dimension of the set of points that remain close for some iterations .",
    "[ idc ] for @xmath100 $ ] , we define @xmath101 \\ | \\",
    "d(f_{\\lambda_\\infty}^i(x),f_{\\lambda_\\infty}^i(y ) ) < \\epsilon \\ ; \\forall i=0,\\dots , n \\}.\\ ] ]    using this definition , we apply theorem [ tsti ] to obtain    [ cidc ] for all @xmath102 and for all @xmath72 , there exists a @xmath103 , such that @xmath104 for all @xmath105 .",
    "hence , given a point @xmath72 and @xmath106 , the set @xmath107 shrinks as @xmath2 increases , until @xmath2 reaches the value @xmath108 .",
    "at this point the set @xmath107 does nt change any more .",
    "but , if we are interested in estimate the order of divergence of nearby orbits at the point @xmath74 , we have to consider the limit @xmath109 we find that @xmath110 , for all @xmath72 , hence the function @xmath111 is a decreasing function of @xmath2 , whose order gives information on the order of the local divergence . in the next subsection",
    "we derive an estimate for the _ aic _ of a string generated by @xmath53 , and hence , by a theorem of @xcite , we find the order of @xmath111 .",
    "in this subsection we show an approach to the dynamics of the logistic map at the chaos threshold , @xmath53 , that allows us to find an estimate for the aic ( equation ( [ eaic ] ) ) of almost every orbit generated by @xmath53 .",
    "this approach uses the notion of _ kneading invariant_. to have a complete treatment of _ kneading theory _",
    "see , for example , @xcite .",
    "let @xmath112\\to [ 0,1]$ ] be a @xmath113 _ unimodal _ map , that is there exists only one point @xmath114 $ ] such that @xmath115 , and @xmath39 is increasing on @xmath116 and decreasing on @xmath117 .",
    "we can then define the _ kneading sequence _",
    "@xmath118 of a point @xmath119 $ ] .",
    "[ dks ] for @xmath119 $ ] , we define coefficients @xmath120 by : @xmath121 -1 & \\mbox { if } \\frac{d}{dx } f^{(i+1 ) } < 0 \\\\[5 mm ] 0   & \\mbox { if } \\frac{d}{dx } f^{(i+1 ) } = 0 \\\\ \\end{array } \\right.\\ ] ] then the _ kneading sequence _ relative to @xmath74 is the formal power series @xmath122    [ tks ] it is possible to introduce a distance @xmath123 on the space of kneading sequences , given by @xmath124 this distance makes the function @xmath125 a continuous function for all @xmath100 $ ] , but the preimages of the critical point @xmath126 .",
    "[ dki ] if @xmath74 is a preimage of the critical point @xmath126 , we define @xmath127 where the limit is taken through sequences of points @xmath128 that are not preimages of @xmath126 . for the critical point @xmath126 , it holds @xmath129",
    ". then we define the _ kneading invariant _",
    "@xmath130 of the function @xmath39 as the sequence @xmath131 .",
    "using classical results on renormalization of maps with null topological entropy ( @xcite ) , one can prove the following :    [ tkiml ] the kneading invariant of the logistic map at the chaos threshold @xmath53 is given by @xmath132    let s consider now the partition @xmath133 , given by @xmath134 $ ] and @xmath135 $ ] , of the interval @xmath136 $ ] for the map @xmath53 .",
    "if we take a point @xmath119 $ ] , we can code its orbit into a string @xmath9 with @xmath137 , according to whether @xmath138 is in @xmath139 or in @xmath140 .    from the definition of the coefficients @xmath120 , for any point @xmath74",
    ", we can see that @xmath141 .",
    "hence , in the coding of the orbit of @xmath74 into the string @xmath9 , we have @xmath142 if there is a permanence in the sign of @xmath143 and @xmath120 , @xmath144 otherwise .",
    "we denote by @xmath145 the string generated by the orbit with initial condition @xmath74 .",
    "let s start studying the string generated by the point @xmath146 , that is the critical point of @xmath53 .",
    "the coding of the orbit of @xmath57 into a string @xmath9 is related to the kneading invariant of the map @xmath147 , given by theorem [ tkiml ] .",
    "thanks to the particular form of the kneading invariant ( eqn .",
    "( [ ekiml ] ) ) , we obtain that to reconstruct the string @xmath9 , it is sufficient to make the following operations :    * the first symbol is 0 ; * given @xmath1 , that is the first @xmath2 symbols of the string , we construct @xmath148 by @xmath149 , where @xmath150 is equal to @xmath1 if @xmath151 , otherwise @xmath150 is obtained by @xmath1 changing the first symbol .    hence we have that @xmath152 , indeed it is enough to specify the length of the string @xmath1 . moreover , by theorem [ teckmann](1 ) , we have that @xmath153 , the attractor of @xmath53 , and the orbit of @xmath57 is dense in @xmath55 ( theorem [ teckmann](4 ) ) .",
    "hence for all @xmath72 ( see theorem [ tsti ] ) , there exists @xmath154 such that for all @xmath155 , @xmath156 can be obtained by @xmath157 .",
    "this implies the following result :    [ taic ] for almost any point @xmath119 $ ] , the aic of the string @xmath145 generated by the orbit of the map @xmath53 with @xmath74 as initial condition , is such that @xmath158 where the constant depends on the point @xmath74 .",
    "[ raic ] we remark that we have actually proved only the behaviour of the aic for the partition @xmath16 . indeed to obtain the aic of the orbits of our dynamical system we should consider the supremum on either all the open covers or the computable partitions ( see section [ sioss ] ) .",
    "but we have that @xmath16 is a _ generating _ partition , that is @xmath159 , where @xmath160 is the diameter of a partition , and @xmath161 .",
    "hence we suppose that the aic we estimated is a good approximation of the real one , following the same arguments used , for example , for the kolmogorov - sinai entropy .",
    "we are now ready to give an estimate on the behaviour of the function @xmath111 defined in equation ( [ esti ] ) . indeed ,",
    "using theorem 40 in @xcite , we have :    [ csti ] for almost any point @xmath119 $ ] , the function @xmath111 is of the order of @xmath162 , for some constant @xmath163 .",
    "hence , we can say that we have a power law divergence for nearby orbits , for almost any orbit .",
    "this result confirms the experiments made on the logistic map at the chaos threshold .",
    "the constant @xmath67 has been found to be approximately @xmath164 ( @xcite ) .",
    "we have thus derived an estimate for the behaviour of the algorithmic information content for the logistic map at the chaos threshold , showing its connection with the sensitivity to initial conditions .",
    "we remark that the aic is not a computable function , that is it does not exist an algorithm able to compute the aic of any string . in the next section ,",
    "we show how to obtain an estimate of the aic for our map .",
    "in section [ sioss ] we have introduced the notion of algorithmic information content ( aic ) of a finite string @xmath9 , following the work of chaitin ( @xcite ) and kolmogorov ( @xcite ) . since",
    "the notion of aic is not computable , it has been approximated by other notions of information content of a string that can be computed .",
    "one measure of the information content of a finite string built on an alphabet @xmath165 can be defined by a lossless ( reversible ) data compression algorithm @xmath166 that is a coding procedure such that from the coded string we can reconstruct the original string .",
    "hence it is natural to consider the length of the coded string as an approximate measure of the quantity of information that is contained in the original string .",
    "we then define the information content @xmath167 of the string @xmath9 as @xmath168 where @xmath169 denotes the length of the compressed string @xmath170 .",
    "the information content @xmath171 turns out to be a computable function and for this reason we will call it computable information content @xmath172 . for a more accurate discussion on compression algorithms and the cic",
    "we refer to @xcite .",
    "in @xcite and @xcite , it has been presented a new compression algorithm , called castore , which has been created in order to give information on null entropy dynamics and has been used to study a case of sporadic dynamics , the manneville map . in the following , the algorithm castore will be used to evaluate the computable information content @xmath173 of the strings ( equation ( [ ecic ] ) ) . as will be better shown later in the case of regular strings , this new algorithm will be a sensitive measure of the information content of the string .",
    "that s why it is called * castore * : * c*ompression * a*lgorithm , * s*ensitive * to * * re*gularity . in particular , in @xcite the algorithm castore has been tested on fully chaotic and sporadic strings , confirming the theoretical results .",
    "we now give a short description of the algorithm .",
    "castore is a compression algorithm which is a modification of the lz78 algorithm ( @xcite ) .    as it will be proved in theorem ( [ teocost ] )",
    ", the information @xmath173 of a constant sequence , originally with length @xmath2 , is @xmath174 $ ] , if the algorithm @xmath175 is castore .",
    "the theory predicts that the best possible information is @xmath176const . in @xcite , it is shown that the algorithm @xmath177 encodes a constant @xmath2 digits long sequence to a string with length about @xmath178 bits ; so , we can not expect that @xmath177 is able to distinguish a sequence whose information grows like @xmath179 ( @xmath180 ) ( sporadic dynamics ) from a constant or periodic one , while it has been proved ( @xcite ) that castore is a very useful tool to identify the correct exponent in the sporadic case .",
    "the algorithm castore is based on an adaptive dictionary . roughly speaking",
    ", this means that it translates an input stream of symbols ( the file we want to compress ) into an output stream of numbers , and that it is possible to reconstruct the input stream knowing the correspondence between output and input symbols .",
    "this unique correspondence between sequences of symbols ( words ) and numbers is called _",
    "the dictionary_.    at the beginning of encoding procedure , the dictionary is empty . in order to explain the principle of encoding ,",
    "let s consider a point within the encoding process , when the dictionary already contains some words .",
    "we start analyzing the stream , looking for the longest word w in the dictionary matching the stream .",
    "then we look for the longest word y in the dictionary where w + y matches the stream .",
    "suppose that we are compressing an english text , and the stream contains `` basketball ... '' , we may have the words `` basket '' ( number 119 ) and `` ball '' ( number 12 ) already in the dictionary , and they would of course match the stream .",
    "the output from this algorithm is a sequence of word - word pairs ( w , y ) , or better their numbers in the dictionary , in our case ( 119 , 12 ) .",
    "the resulting word `` basketball '' is then added to the dictionary , so each time a pair is output to the code - stream , the string from the dictionary corresponding to w is extended with the word y and the resulting string is added to the dictionary .    in the following subsections",
    ", we will estimate the information content @xmath173 , where the algorithm @xmath175 is castore , in the case of constant sequences and periodic sequences with period @xmath181 .",
    "indeed this is important for the application of castore to the logistic map at the chaos threshold ( section [ serotlm ] ) .",
    "we first study the case of period @xmath182 ( constant strings ) .",
    "if we have a string given by @xmath183 the algorithm castore gives a codification @xmath184 \\\\ 2 & : & ( 1,1 ) & [ aa ] \\\\ 3 & : & ( 2,2 ) & [ aaaa ] \\\\ 4 & : & ( 3,3 ) & [ aaaaaaaa ] \\\\   &   & \\dots & \\\\ k & : & ( k-1,k-1 ) & [ a \\dots a ] \\end{array}\\ ] ] so if we compute the information @xmath185 , as function of the length @xmath2 of the string to be compressed , we can immediately deduce that @xmath186 .",
    "indeed a much more accurate estimate of the cic for constant strings is obtained in the following theorem .",
    "[ teocost ]",
    "let @xmath9 be a constant string as in ( [ successionecostante ] ) , then the information function @xmath185 obtained applying the compression algorithm castore is approximated by the function @xmath187 : @xmath188 where the approximation is given by the identification of the integer part of @xmath189 with its real value .",
    "* proof . *",
    "we notice that the algorithm castore acts on @xmath9 in such a way that at the end of each term of the codification , the length @xmath2 of the codified string is of the form @xmath190 .",
    "then we look for the value of @xmath191 .",
    "we can easily obtain that if @xmath192 $ ] , where @xmath193 $ ] denotes the integer part , then @xmath194 = & 2 + \\sum_{i=0}^{k-1 } ( i+1 ) 2^{i+1 } + 2 ( n-2^k ) \\log_2 ( 2^{k+1 } ) \\\\[0.3 cm ] = & 4 + ( k-1)2^{k+1 } + 2 ( n-2^k ) \\log_2 ( 2^{k+1 } ) , \\end{array } \\label{inf1}\\ ] ] where we used @xmath195 at this point it is enough to approximate @xmath67 with its real value @xmath196 , and substitute to @xmath197 its value @xmath198 to obtain equation ( [ infcost ] ) .",
    "the theorem is proved .",
    "we now look at strings @xmath9 with prime period @xmath199 . from the point of view of the information content",
    ", we expect that periodic strings are not so different from constant strings .",
    "indeed we find that the algorithm castore is able to recognize periodic strings as constant strings after having encoded @xmath200 symbols , depending on @xmath7 .",
    "then , the cic @xmath185 must behave as in the constant case for @xmath201 , indeed it is given by @xmath187 plus a constant term @xmath202 that depends on the particular string @xmath9 .",
    "this term @xmath202 can be estimated as the amount of information obtained from @xmath9 at the @xmath200-th symbol .",
    "we first prove the following theorem    let @xmath9 be a periodic string with prime period @xmath199 , then there exists a constant @xmath200 , depending on @xmath9 , such that , when the algorithm castore reaches the @xmath200-th term of the string , it starts codifying the string @xmath9 as if it were a constant string .",
    "the constant @xmath200 has as upper bound @xmath203 \\label{stimaperiodiche}\\ ] ] where @xmath204 is the number of symbols in the alphabet used to construct the string @xmath9 .",
    "note that @xmath205 depends only on the period @xmath7 .",
    "[ teoperiodiche ]    * proof .",
    "* let us assume that @xmath206 .",
    "since @xmath9 has prime period @xmath7 , we can look at it as a sequence of substrings , each one @xmath7 symbols long ; they will be called @xmath7-substrings .",
    "once the codification has started and the first @xmath7 characters have been read , the last encoded word will be @xmath207 symbols long and will end at some @xmath67-th ( mod .",
    "@xmath7 ) site in the second @xmath7-substring .",
    "then , after at most @xmath208 subsequent reading of contiguous @xmath7-substrings , the algorithm will arrive at the end of an already known word ; this word will finish at some @xmath197-th ( mod .",
    "@xmath7 ) site of the @xmath209-th @xmath7-substring of @xmath9 .",
    "let us assume that the number of words needed by the algorithm to codify the fragment starting from the @xmath197-th symbol of a previous @xmath7-substring to its correspondent belonging to the @xmath209-th @xmath7-substring of @xmath9 is @xmath80 ; we will indicate the collection of that @xmath80 words by @xmath210 . let us analyse the different cases .    _",
    "first case : @xmath211 . _",
    "the algorithm continues to process the remaining part of @xmath9 , codifying the next fragment @xmath210 by coupling two words each time .",
    "so , after @xmath126 steps only _",
    "one _ word will be necessary and later the algorithm will follow the period .    _",
    "second case : @xmath212 , where @xmath213 is odd_. the algorithm first behaves @xmath214 times as described above , and after just @xmath213 words will be needed to process the following @xmath210 .",
    "let us call @xmath215 those known words .",
    "after one step , the algorithm castore will have built the new words @xmath216 , and @xmath217 .",
    "then , the algorithm will reach the period after @xmath218 steps , where @xmath219 .    _",
    "third case : m is odd .",
    "_ the algorithm will behave as in the second case , with @xmath220 .",
    "so we have proved the existence of the constant @xmath200 .",
    "let us estimate its upper bound , @xmath205 .",
    "it holds : @xmath221\\ ] ] where @xmath222 .",
    "now , we estimate @xmath80",
    ". it does hold @xmath223 where @xmath224 is the number of words necessary to cover up a @xmath7-substring .",
    "since @xmath225 different symbols are available in the alphabet @xmath226 , then it must be @xmath227 where @xmath228 is the smaller integer such that it holds @xmath229 .",
    "since we have @xmath230 and we are interested in an estimation of @xmath228 , let us look for the smallest integer @xmath228 such that @xmath231 let @xmath232 the real solution of the following equation : @xmath233 then the integer @xmath228 we looked for is @xmath234 and it holds @xmath235 .",
    "so , we have @xmath236 . finally ,",
    "if we approximate @xmath237 with @xmath7 , we obtain @xmath238\\ ] ] and the theorem is proved .",
    "in this section we show how to obtain an estimation for the computable information content @xmath185 for a finite string @xmath1 generated by the logistic map at the chaos threshold , using castore as compression algorithm @xmath175 . in the remainder of this section we drop the subscript @xmath175 from the cic , since we are always referring to castore .",
    "the plan of our experiments on the logistic map is to apply castore to strings generated by the logistic map @xmath239 for different values of @xmath33 that approximate the chaos threshold @xmath240 .",
    "in particular we consider two approximating sequences of values of @xmath33 : the sequence of values @xmath241 at which the period doubling bifurcations occur ( section [ stpds ] ) and the sequence of values @xmath242 at which the inverse tangent bifurcations occur ( section [ sitb ] ) .",
    "thus we obtain approximations for the cic at the chaos threshold from below and from above , and the two coincide .",
    "we can then say to have obtained an approximation for the cic computed with castore for the logistic map at the chaos threshold @xmath53 .",
    "we remark that the symbolic strings are obtained from the orbits of the logistic map at the chaos threshold considering the partition @xmath243 of @xmath136 $ ] given by @xmath244 and @xmath135 $ ] .",
    "the choice of this partition for the experiments is justified by its optimality as remarked in section [ staatct ] .      in section [ scops ]",
    "we have analysed the behaviour of our algorithm castore on periodic strings , obtaining that the cic @xmath245 of a periodic string @xmath9 behaves with respect to the length @xmath2 of the encoded string as @xmath246 where @xmath187 is given by equation ( [ infcost ] ) and @xmath247 is a constant depending on the string @xmath9 ( theorem [ teoperiodiche ] ) .",
    "we start considering the logistic map for values of the parameter @xmath33 in the sequence @xmath248 given by the period doubling bifurcations , for which values the logistic map is periodic .",
    "the sequence @xmath248 converges to the chaos threshold value @xmath240 from below and can be generated by the equation ( [ feigrel ] ) ( section [ stdotlm ] ) .",
    "we generated the terms of the sequence @xmath248 ( where the differences are given up to 38 decimal digits ) and iterated the logistic map @xmath249 times .",
    "so we had strings of @xmath249 symbols .",
    "when studying the cic @xmath250 for each @xmath251 , where @xmath1 is the symbolic orbit of the logistic map with parameter @xmath252 , we first tried to obtain the constant terms @xmath253 , as expected from equation ( [ ecicper ] ) .",
    "we have obtained an increasing sequence of values @xmath253 ( for @xmath95 that tends to infinity ) , and our results about the compression of periodic strings by the algorithm castore ( see theorem [ teoperiodiche ] ) are supported by the computations of the following limits @xmath254    as expected , equation ( [ limiticoncost ] ) tells us that , after the compression of a long enough substring of our string @xmath9 , we obtain the same information function as for constant strings , simply translated by a constant . if we denote by @xmath255 the number of symbols that the algorithm has to process before reaching that behaviour , we have @xmath256 as @xmath257 .",
    "so we have that @xmath258 as @xmath257 .",
    "the approximation of the information content @xmath250 with a function @xmath187 of the form given by ( [ infcost ] ) plus a constant term is not very good for periodic strings with high period .",
    "this is because of the poorness of the upper bound of our computations : indeed , we know that this approximation is accurate for values of @xmath259 and there are strings whose @xmath255 is bigger than @xmath249 , the length of our orbits . in our case",
    "the period @xmath260 of the strings @xmath261 is already big enough for @xmath262 , indeed @xmath263 , so @xmath264 .",
    "this means that we have to look for another way of approximation to the information function for values of @xmath2 lower than @xmath255 . at the bifurcation",
    "points it is well known from experimental results that the orbit separation is polynomial and , thanks to the results in @xcite , we can say that the algorithmic information content is at most logarithmic .",
    "so , we can expect our computable information content to behave like @xmath265 c_j + \\psi(n ) & \\hbox { for } n > n_j \\end{array } \\right . \\quad j \\in { \\mathbb n}\\label{inftot}\\ ] ] with @xmath253 as given before . to find the functions @xmath266",
    ", we simply have to compute the fraction @xmath267       first of all , we deduce from equation ( [ limiticoncost ] ) that @xmath268 for all @xmath95 .",
    "moreover the numerical experiments show that the sequence of functions @xmath269 is point - wise increasing in @xmath95 and bounded from above ( see figure [ funzionis ] on the left ) .",
    "then we define the bounding function @xmath270 as @xmath271 } } ( n ) + \\chi_{_{[n_j,\\infty ] } } ( n ) \\right)\\ ] ] for each @xmath99 , where @xmath272}}(n)$ ] denotes the characteristic function of the real interval @xmath273 $ ] .      in order to establish the behaviour of the information function @xmath274 at the chaos threshold",
    ", we applied the same method as before , building up a sequence @xmath275 of parameters approximating @xmath276 from above .    in the interval",
    "@xmath277 $ ] , the logistic map has a general chaotic behaviour , except from narrow ranges ( called _ periodic windows _ ) of parameters for which the map is periodic . inside each window ,",
    "a new period doubling sequence can be identified , that leads the map to chaos .",
    "the behaviour becomes periodic from chaotic via a _",
    "tangent bifurcation _",
    ", that is we can find a fixed point of a given iterate of the map having 1 as its eigenvalue ( @xcite ) .",
    "the values of the parameter at which the tangent bifurcations occur converge to @xmath276 from above and can be generated using the following relation : @xmath278 where @xmath126 is a suitable constant and @xmath51 is the feigenbaum constant .",
    "as we can see in figure [ funzionis ] on the right , the numerical evidence is that the sequence @xmath283 is point - wise decreasing in @xmath67 and the same function @xmath284 found in the previous subsection is a lower bound for the sequence .",
    "then we have @xmath285 for each @xmath2 .      from the previous subsections we can draw some conclusions . first of all",
    ", we can say that for all @xmath99 the information function @xmath250 of the logistic map ( [ logmap ] ) with parameter @xmath252 ( as shown in section [ stpds ] ) is @xmath286 } } ( n ) + ( \\psi(n ) + c_j ) \\chi_{_{[n_j,\\infty ] } } ( n ) \\quad \\forall \\ ; j \\in { \\mathbb n},\\ ] ] and with parameter @xmath287 ( as shown in subsection [ sitb ] ) is @xmath288            finally we remark that the feature of @xmath274 and in particular of @xmath284 is typical of the logistic map , and is not simply due to the fact that we are considering periodic orbits with period going to infinity . indeed , from the behaviour of the function @xmath284",
    ", we deduce that @xmath294 and this means that for @xmath295 , for example , @xmath274 is less than approximately @xmath296 .",
    "but we can construct periodic strings with period less than @xmath297 , such that the information after @xmath298 symbols is more than @xmath296 .",
    "we can consider , for example , a string with period given by all the possible combinations of two symbols in pieces of length from 1 to 4 .",
    "this string has period @xmath299 , but @xmath300 , much more than @xmath296 ."
  ],
  "abstract_text": [
    "<S> we study the logistic map @xmath0 on the unit square at the chaos threshold . by using the methods of symbolic dynamics , the information content of an orbit of a dynamical system </S>",
    "<S> is defined as the _ algorithmic information content ( aic ) _ of a symbolic sequence . </S>",
    "<S> we give results for the behaviour of the aic for the logistic map . since the aic is not a computable function we use , as approximation of the aic , a notion of information content given by the length of the string after it has been compressed by a compression algorithm , and in particular we introduce a new compression algorithm called castore . </S>",
    "<S> the information content is then used to characterise the chaotic behaviour . </S>"
  ]
}