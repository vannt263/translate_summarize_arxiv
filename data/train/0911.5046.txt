{
  "article_text": [
    "apache lucene is a high - performance and full - featured text search engine library written entirely in java .",
    "it is a technology suitable for nearly any application that requires full - text search .",
    "lucene is scalable and offers high - performance indexing , and has become one of the most used search engine libraries in both academia and industry @xcite .",
    "lucene ranking function , the core of any search engine applied to determine how relevant a document is to a given query , is built on a combination of the vector space model ( vsm ) and the boolean model of information retrieval .",
    "the main idea behind lucene approach is the more times a query term appears in a document relative to the number of times the term appears in the whole collection , the more relevant that document will be to the query @xcite .",
    "lucene uses also the boolean model to first narrow down the documents that need to be scored based on the use of boolean logic in the query specification .    in this paper ,",
    "the implementation of bm25 probabilistic model and its extension for semi - structured ir , bm25f , is described in detail .",
    "one of the main lucene s constraints to be widely used by ir community is the lack of different retrieval models implementations .",
    "our goal with this work is to offer to ir community a more advanced ranking model which can be compared with other ir software , like terrier , lemur , clairlib or xapian .",
    "there exists previous implementations of alternative information retrieval models for lucene .",
    "the most representative case of that is the language model implementation from intelligent systems lab amsterdam .",
    "another example is described at @xcite where lucene is compared with juru system . in this case lucene document length normalization",
    "is changed in order to improve the lucene ranking function performance .",
    "bm25 has been widely use by ir researchers and engineers to improve search engine relevance , so from our point of view , a bm25/bm25f implementation for lucene becomes necessary to make lucene more popular for ir community .",
    "the developed models are based in the information that can be found at @xcite .",
    "more specifically the implemented ranking functions are as next :      @xmath0    where @xmath1 is the term frequency of @xmath2 in @xmath3 ; @xmath4 is the document @xmath3 length ; @xmath5 is the document average length along the collection ; @xmath6 is a free parameter usually chosen as 2 and @xmath7 $ ] ( usually 0.75 ) .",
    "assigning 0 to @xmath8 is equivalent to avoid the process of normalisation and therefore the document length will not affect the final score . if @xmath8 takes 1 , we will be carrying out a full length normalisation .",
    "the classical inverse document frequency is computed as next : @xmath9 where @xmath10 is the number of documents in the collection and @xmath11 is the number of documents where appears the term @xmath2 .    a different version of this formula , as can be found at wikipedia , multiplies the obtained bm25 weight by the constant @xmath12 in order to normalize the weight of terms with a frequency equals to 1 that occurs in documents with an average length .",
    "first we obtain the accumulated weight of a term over all fields as next :    @xmath13    where @xmath14 is the field length ; @xmath15 is the average length for the field @xmath16 ; @xmath17 is a constant related to the field length , similar to @xmath8 in bm25 and @xmath18 is the boost factor applied to field @xmath16 .",
    "next , a non - linear saturation @xmath19 , in order to reduce the effect of term frequency to the final score is applied .",
    "@xmath20    @xmath21 is computed as in the bm25 case    @xmath22    where @xmath10 is the number of documents in the collection and @xmath11 is the number of documents where appears the term @xmath2 .",
    "the main goal of this implementation was to integrate the new ranking model into the search lucene functionalities . in order to accomplish this objective",
    "a new query , weight , and several scorers were developed .",
    "the main functionalities are implemented at scorer level , since the main responsibilities of query and weight are to prepare the necessary parameters for the scorers , and create scorers instances when the search method is invoked .",
    "more information in the query - weight - scorer model can be found at http://lucene.apache.org / java/2_4_0/scoring.html[. ]      the execution of a query can be divided in two parts , a boolean filtering and the documents ranking . the boolean filtering is carried out by the scorers shouldbooleanscorer , mustbooleanscorer and notbooleanscorer depending on the logic operators applied , while ranking functions are implemented in the score method of bm25termscorer and bm25ftermscorer .",
    "bm25booleanscorer will create bm25termscorer or bm25ftermscorer instances depending on the invoked constructor , as next :    * to use bm25 ranking function + + .... public bm25booleanquery(string query , string field , analyzer analyzer )       throws parseexception , ioexception .... * to use bm25f ranking function + + .... public bm25booleanquery(string query , string [ ] fields , analyzer analyzer )       throws parseexception , ioexception ....    bm25booleanscorer will ignore any information related to fields that is treated by lucene queryparser , thus the search will be carried out only with the field(s ) , passed as parameters in the constructor .",
    "besides only boolean queries are supported , any other query type will be split into terms and executed as a boolean query .",
    "it should be noted that both ranking functions do not use query weights , therefore all computation can be done at scorer level .",
    "* almost all necessary information in order to compute bm25 relevance can be obtained through the lucene expert api ( termdocs , numdocs , docfreq , ... ) , apart from the document average length that can not be obtained directly from the api supplied .",
    "this value , can be obtained at index time , implementing a specific similarity that counts and store the length of the document fields .",
    "as next + .... public class collectionsimilarityindexer extends defaultsimilarity {      private static map < string , long > length = new hashmap < string , long > ( ) ;      @override    public float lengthnorm(string fieldname , int numtokens ) {",
    "long aux = collectionsimilarityindexer.length.get(fieldname ) ;      if ( aux==null )        aux = new long(0 ) ;      aux+=numtokens ;      collectionsimilarityindexer.length.put(fieldname,aux ) ;      return super.lengthnorm(fieldname , numtokens ) ;    }    public static long getlength(string field ) {      return collectionsimilarityindexer.length.get(field ) ;    } } .... + after the indexing process we can retrieve the length of a specific field , and following can be divided by collection numdocs and save the computed value to a file . this value can be read when a searcher is opened . in the provided implementation a method load(string filepath )",
    "is supplied in bm25parameters in order to load average lengths , more details about the file format can be found in the javadoc documentation at @xcite . *",
    "the specific bm25 parameters are fixed within the bm25parameters class , where by default are set at @xmath23 and @xmath24 .",
    "the bm25f case is more complex , since it needs more specific parameters , mainly an array of string that includes the fields where the term should be searched .",
    "all the parameters can be found at bm25fparameters , the same @xmath6 is applied .",
    "related to @xmath8 is set to 0.75 for each field , but is recommended to use better parameters ( supplied as a float array ) that can be set when the query is initialised .",
    "fixing boost for each field is carried out in a similar fashion , these have been initialised with a value of 1 , but it may be supplied with a float array .",
    "all bm25f based arrays parameters as @xmath25 and @xmath26 must be supplied ordered , that means that for field @xmath27 into the array of fields , the @xmath28 and the @xmath8 parameter for that field will be at @xmath27 position in both arrays . * in both models idf is computed in bm25similarity and must be calculated at document level with _ docfreq _ and _ numdocs_. lucene returns docfreq at field level , that is the number of fields ( within documents ) where a term @xmath2 appears .",
    "this functionality is not a problem for bm25 since the search is accomplished just in a field . for the bm25f case",
    "this is a serious problem , because idf can not be computed at document level , unless a new field that contains all terms is indexed .",
    "the supplied implementation ( as an heuristic ) computes _ docfreq _ in the field with the longest average length .",
    "the supplied implementation can be used in a similar way as searches are carried out with lucene , except that * bm25parameters or bm25fparameters must be set before the query is executed , this has to be done in order to set the average length(s ) * , other parameters can be omitted since they are set to default values .",
    "examples of the bm25 and bm25f raking function appear below :      ....      indexsearcher searcher = new indexsearcher(\"indexpath \" ) ;        //load average length      bm25parameters.load(avglengthpath ) ;      bm25booleanquery query = new bm25booleanquery(\"this is my query \" ,           \" search - field \" ,          new standardanalyzer ( ) ) ;           topdocs top = searcher.search(query , null , 10 ) ;      scoredoc [ ] docs = top.scoredocs ;           //print results      for ( int i = 0 ; i $ < $ top.scoredocs.length ; i++ ) {            system.out.println(docs[i].doc + \" : \" + docs[i].score ) ;      }     ....      ....      string [ ] fields = { \" field1\",\"field2 \" } ;      indexsearcher searcher = new indexsearcher(\"indexpath \" ) ;        //set explicit average length for each field      bm25fparameters.setaveragelength(\"field1 \" , 123.5f ) ;      bm25fparameters.setaveragelength(\"field2 \" , 42.2f ) ;           //set",
    "explicit k1 parameter      bm25fparameters.setk1(1.2f ) ;           //using boost and b defaults parameters      bm25booleanquery queryf = new bm25booleanquery(\"this is my query \" ,          fields , new standardanalyzer ( ) ) ;           //retrieving not normalized scorer values      topdocs top = searcher.search(queryf , null , 10 ) ;      scoredoc [ ] docs = top.scoredocs ;           //print results      for ( int i = 0 ; i $ < $ top.scoredocs.length ; i++ ) {            system.out.println(docs[i].doc + \" : \" + docs[i].score ) ;      } ....",
    "authors want to thank hugo zaragoza for his review and comments .",
    "http://lucene.apache.org / java / docs/. stephen robertson , hugo zaragoza _ the probabilistic relevance model : bm25 and beyond_. the 30th annual international acm sigir conference 23 - 27 july 2007 , amsterdam _ integrating bm25 & bm25f into lucene_. website 2008 .",
    "http:\\/\\/nlp.uned.es\\/~jperezi\\/lucene - bm25\\/jar\\/models.jar[http : nlp.uned.es  jperezilucene-bm25jarmodels.jar ] _ integrating bm25 & bm25f into lucene - javadoc_. website 2008 .",
    "jperezi / lucene - bm25/javadoc ] doron cohen , einat amitay and david carmel _ lucene and juru at trec 2007 : 1-million queries track _ , trec 2007,http://trec.nist.gov / pubs / trec16/papers / ibm - haifa.mq.final.pdf ]"
  ],
  "abstract_text": [
    "<S> this document describes the bm25 and bm25f implementation using the lucene java framework . </S>",
    "<S> the implementation described here can be downloaded from @xcite . </S>",
    "<S> both models have stood out at trec by their performance and are considered as state - of - the - art in the ir community . </S>",
    "<S> bm25 is applied to retrieval on plain text documents , that is for documents that do not contain fields , while bm25f is applied to documents with structure . </S>"
  ]
}