{
  "article_text": [
    "the most common hypothesis tests for large samples are the likelihood ratio @xcite , the wald @xcite , and the rao score @xcite tests .",
    "these tests are widely used in areas such as economics , biology , and engineering , among others , since exact tests are not always available . an alternative test uses the gradient statistic recently proposed by @xcite .",
    "an advantage of the gradient statistic over the wald and the score statistics is that it does not involve knowledge of the information matrix , neither expected nor observed .",
    "additionally , the gradient statistic is quite simple to be computed .",
    "this has been emphasised by c.r .",
    "rao @xcite , who wrote : ` the suggestion by terrell is attractive as it is simple to compute .",
    "it would be of interest to investigate the performance of the [ gradient ] statistic ' .",
    "let @xmath1 be a random sample of size @xmath2 with joint probability density function @xmath3 , which depends on a @xmath4-dimensional vector of unknown parameters @xmath5 .",
    "let @xmath6 and @xmath7 be the log - likelihood function and the score vector , respectively ; notice that , for convenience , both are divided by @xmath2 .",
    "we wish to test the null hypothesis @xmath8 against the two - sided alternative hypothesis @xmath9 , where @xmath10 is a fixed @xmath11-dimensional vector , @xmath12 and @xmath13 .",
    "the partition in @xmath14 induces the corresponding partition in @xmath15 : @xmath16 .",
    "let @xmath17 and @xmath18 be the unrestricted and the restricted ( under @xmath19 ) maximum likelihood estimators of @xmath20 , respectively .",
    "the gradient statistic for testing @xmath19 is defined as @xmath21 and can also be written as @xmath22 , since @xmath23 . like the likelihood ratio , the wald , and the score statistics , the gradient statistic has an asymptotic @xmath24 distribution under the null hypothesis , @xmath11 being the number of restrictions imposed by @xmath19 .",
    "equation is the inner product of the score vector evaluated at @xmath19 and the difference between the unrestricted and the restricted maximum likelihood estimators of @xmath14 .",
    "although the gradient statistic was derived by @xcite from the score and the wald statistics , it is of a different nature .",
    "the score statistic measures the squared length of the score vector evaluated at @xmath19 using the metric given by the inverse of the fisher information matrix , whereas the wald statistic gives the squared distance between the unrestricted and the restricted maximum likelihood estimators of @xmath14 using the metric given by the fisher information matrix .",
    "moreover , both are quadratic forms .",
    "the gradient statistic , on the other hand , is not a quadratic form and measures the distance between the unrestricted and the restricted maximum likelihood estimators of @xmath14 from a different perspective .",
    "it measures the orthogonal projection of the score vector at @xmath19 on the vector @xmath25 .",
    "recently , the gradient test has been the subject of some research papers .",
    "in particular , @xcite obtained the local power of the gradient test under pitman alternatives ( a sequence of alternative hypotheses converging to the null hypothesis at the rate of @xmath26 ) .",
    "the authors compared the local power of the gradient test with those of the likelihood ratio , the wald , and the score tests .",
    "they showed that none of the tests is uniformly more powerful than the others , and therefore , the gradient test is not only very simple to be calculated but it is also competitive with the others in terms of local power .",
    "other recent works in which the gradient test is investigated are @xcite and @xcite .    the main result in @xcite regarding the local power of the gradient test up to an error of order @xmath27 represents the first step in the study of higher order asymptotic properties of the gradient test . in the present paper",
    ", we wish to go further by focusing on deriving the second - order approximation to the null distribution of the gradient statistic . in other words ,",
    "our aim is to obtain an asymptotic expansion for the cumulative distribution function of the gradient statistic under the null hypothesis up to an error of order @xmath0 .",
    "the usual route for deriving expansions for the distribution of asymptotic chi - square test statistics involves multivariate edgeworth series expansions .",
    "although such a route has been followed by many authors , it is extremely lengthy and tedious ( see , for example , * ? ? ?",
    "* ; * ? ? ?",
    "* ) . here ,",
    "on the other hand , in order to derive an asymptotic expansion for the null distribution of the gradient statistic up to order @xmath28 , we follow a bayesian route based on a shrinkage argument originally suggested by @xcite and described later in @xcite .",
    "although it uses a bayesian approach , this technique can be used to solve frequentist problems , such as the derivation of bartlett corrections and tail probabilities @xcite .",
    "additionally , we obtain a bartlett - type correction factor for the gradient statistic from the results in @xcite . under the null hypothesis ,",
    "the corrected statistic is distributed as chi - square up to an error of order @xmath0 , while the uncorrected gradient statistic has a chi - square distribution up to an error of order @xmath27 ; that is , the bartlett - type correction factor makes the approximation error be reduced from @xmath27 to @xmath0 . for a detailed survey on bartlett and bartlett - type corrections ,",
    "the reader is referred to @xcite .",
    "the paper unfolds as follows . in section [ main_results ]",
    ", we present our main results , namely an asymptotic expansion for the cumulative distribution function of the gradient statistic and its bartlett - type correction . in sections",
    "[ onefamily ] and [ twofamily ] , we particularise our general results to one - parameter families and to families with two orthogonal parameters , respectively . a small monte carlo study is also presented in section [ twofamily ] .",
    "section [ conclusion ] closes the paper with a brief discussion .",
    "technical details are collected in two appendices .",
    "first , let us introduce some notation .",
    "let @xmath29 ( @xmath30 ) be the differential operator .",
    "we define @xmath31 , @xmath32 , @xmath33 , and so on .",
    "we make the same assumptions , such as the regularity of the first four derivatives of @xmath34 with respect to @xmath14 and the existence and uniqueness of the maximum likelihood estimator of @xmath14 , as those fully outlined by @xcite .",
    "let @xmath35 , @xmath36 , @xmath37 , @xmath38 , @xmath39 , @xmath40 , @xmath41 , @xmath42 , etc .",
    ", denote the cumulants of log - likelihood derivatives . the cumulants are not functionally independent , for instance , @xmath43 , @xmath44 , @xmath45 , @xmath46 , where @xmath47 and @xmath48 , etc .",
    "relations among them were first obtained by @xcite .",
    "further , let @xmath49 be the fisher information matrix @xmath50 with @xmath51 denoting its inverse .",
    "finally , define the matrices @xmath52 in what follows , we use the einstein summation convention , where @xmath53 denotes summation over all components of @xmath14 ; that is , the indices @xmath54 , @xmath55 , @xmath56 , @xmath57 , @xmath58 and @xmath59 range over @xmath60 to @xmath4 .",
    "we now establish the following theorem .",
    "[ theorem1 ] the asymptotic expansion for the null distribution of the gradient statistic for testing @xmath8 against @xmath9 is @xmath61 where @xmath62 is the cumulative distribution function of a chi - square random variable with @xmath63 degrees of freedom , @xmath64 , @xmath65 , @xmath66 , @xmath67 , @xmath68\\\\ & \\quad + 12\\sum\\nolimits^{\\prime}\\bigl(\\kappa_{jrsu}+\\kappa_{j , rsu}+\\kappa_{jsu , r } + \\kappa_{ju , rs}+\\kappa_{j , u , rs}\\bigl)\\bigr(\\kappa^{j , s}\\kappa^{u , r}-a^{js}a^{ur}\\bigr),\\end{aligned}\\ ] ] @xmath69\\\\ & \\quad+3\\sum\\nolimits^{\\prime}\\bigl(\\kappa_{jrsu}+2\\kappa_{jrs , u}\\bigr)m^{jr}m^{su},\\end{aligned}\\ ] ] @xmath70    the proof is presented in appendix 1 .    basically , in order to prove theorem [ theorem1 ] , we follow a bayesian route based on a shrinkage argument . this argument is described in appendix 2",
    ".    if the null hypothesis is simple , we have @xmath71 , @xmath72 and @xmath73 .",
    "therefore , an immediate consequence of theorem [ theorem1 ] is the following corollary .",
    "[ corollary1 ] the asymptotic expansion for the null distribution of the gradient statistic for testing @xmath74 against @xmath75 is given by with @xmath71 , @xmath64 , @xmath65 , @xmath66 , @xmath67 and the @xmath76 s are @xmath77 , @xmath78 @xmath79    we are now able to present a bartlett - type corrected gradient statistic . a bartlett - type correction is a multiplying factor , which depends on the statistic itself , that results in a modified statistic that follows a chi - square distribution with approximation error of order less than @xmath28 .",
    "@xcite obtained a general formula for a bartlett - type correction for a wide class of statistics that have a chi - square distribution asymptotically .",
    "a special case is when the cumulative distribution function of the statistic can be written as , independently of the coefficients @xmath80 , @xmath81 , and @xmath82 .",
    "hence , from theorem [ theorem1 ] and the results in @xcite , we have the following corollary .",
    "[ col_corr_grad ] the modified statistic @xmath83 where @xmath84 has a @xmath24 distribution up to an error of order @xmath0 under the null hypothesis .",
    "the factor @xmath85 in can be regarded as a bartlett - type correction factor for the gradient statistic in such a way that the null distribution of @xmath86 is better approximated by the reference @xmath87 distribution than the distribution of the uncorrected gradient statistic .    instead of modifying the test statistic as in",
    ", we may modify the reference @xmath87 distribution using the inverse expansion formula in @xcite . to be specific ,",
    "let @xmath88 be the desired level of the test , and @xmath89 be the @xmath90 percentile of the @xmath87 limiting distribution of the test statistic . from expansion",
    ", we have the following corollary .    the asymptotic expansion for the @xmath90 percentile of @xmath91 to order @xmath28 takes the form @xmath92 , \\end{split}\\end{aligned}\\ ] ] where @xmath93 .    in general , equations and",
    "depend on unknown parameters . in this case",
    ", we can replace these unknown parameters by their maximum likelihood estimates obtained under @xmath19 .",
    "it should be noticed that the improved gradient test of the null hypothesis @xmath19 may be performed in three ways : ( i ) by referring the corrected statistic @xmath94 in to the @xmath95 distribution ; ( ii ) by referring the gradient statistic @xmath91 to the approximate cumulative distribution function ; ( iii ) by comparing @xmath91 with the modified upper percentile in .",
    "these three procedures are equivalent to order @xmath28 .    finally , the three moments , up to order @xmath28 under the null hypothesis , of the gradient statistic are presented in the following corollary .",
    "[ col_momen_grad ] the first three moments , up to order @xmath28 under the null hypothesis , of the gradient statistics are @xmath96 @xmath97    in the next sections , we consider some applications of the general results derived in this section in two special cases : a one - parameter model and a two - parameter model under orthogonality of parameters .",
    "we initially assume that the model is indexed by a scalar unknown parameter , say @xmath98 .",
    "the interest lies in testing the null hypothesis @xmath99 against @xmath100 , where @xmath101 is a fixed value .",
    "let @xmath102 , @xmath103 , @xmath104 , @xmath105 , @xmath106 , and @xmath107 .",
    "the gradient statistic for testing @xmath19 is @xmath108 , where @xmath109 is the maximum likelihood estimator of @xmath98 . here",
    ", @xmath110 , @xmath111 , and @xmath112 given in corollary [ corollary1 ] reduce to @xmath113 @xmath114 @xmath115    we now present some examples .",
    "( exponential distribution )    let @xmath1 be a random sample of an exponential distribution with density @xmath116 here , @xmath117 , @xmath118 , and @xmath119 .",
    "the gradient statistic assumes the form @xmath120 , where @xmath121 , which equals the score statistic .",
    "it is easy to see that @xmath122 , @xmath123 , and @xmath124 .",
    "the first three moments ( up to order @xmath28 ) of @xmath91 are @xmath125 , @xmath126 , and @xmath127 . a partial verification of our results can be accomplished by comparing the exact moments of @xmath91 with the approximate moments given above .",
    "since @xmath128 has a gamma distribution with parameters @xmath2 and @xmath129 , it can be shown that the first three exact moments of @xmath91 are @xmath60 , @xmath130 , and @xmath131 , respectively .",
    "these moments differ from the approximate moments obtained from corollary [ col_momen_grad ] only in terms of order less than @xmath28 .",
    "the bartlett - type corrected gradient statistic obtained from corollary [ corr_grad ] is @xmath132 .",
    "( one - parameter exponential family )    let @xmath1 be a random sample of size @xmath2 in which each @xmath133 has a distribution in the one - parameter exponential family with density @xmath134 where @xmath135 , @xmath136 , @xmath137 , and @xmath138 are known functions .",
    "also , @xmath135 and @xmath138 are assumed to have first three continuous derivatives , with @xmath139 , @xmath140 , and @xmath141 being different from zero for all @xmath98 in the parameter space , where @xmath142 . here ,",
    "primes denote derivatives with respect to @xmath98 .",
    "for instance , @xmath143 .",
    "it can be shown that @xmath144 , @xmath145 , and @xmath146 .",
    "the gradient statistic takes the form @xmath147 , where @xmath148 . from @xmath149 , @xmath150 , and @xmath151 ,",
    "we can write @xmath152 @xmath153,\\ ] ] @xmath154    we now present some special cases .    1 .",
    "normal ( @xmath155 , @xmath156 , @xmath157 ) : * @xmath158 known : @xmath159 , @xmath160 , @xmath161 , and @xmath162 .",
    "we have @xmath163 , @xmath164 , and @xmath165 .",
    "the first three moments of @xmath91 up to order @xmath28 are @xmath125 , @xmath166 , and @xmath167 .",
    "the bartlett - corrected gradient statistic is @xmath168 .",
    "* @xmath98 known : @xmath169 , @xmath170 , @xmath171 , and @xmath172 . here , @xmath173 , as expected .",
    "inverse normal ( @xmath155 , @xmath174 , @xmath175 ) : * @xmath158 known : @xmath176 , @xmath177 , @xmath178 , and @xmath179 . here , @xmath180 , @xmath181 , and @xmath182 , and the three first moments of @xmath91 are @xmath183 , @xmath184 , and @xmath185 .",
    "the bartlett - corrected gradient statistic takes the form @xmath186 .",
    "* @xmath98 known : @xmath187 , @xmath188 , @xmath171 , and @xmath189 .",
    "we have @xmath122 and @xmath190 .",
    "the first three approximate moments of @xmath91 are @xmath125 , @xmath191 , and @xmath192 .",
    "also , @xmath193 .",
    "3 .   gamma ( @xmath57 known , @xmath194 , @xmath155 , @xmath175 ) : @xmath176 , @xmath195 , @xmath171 , and @xmath196 , where @xmath197 denotes the gamma function .",
    "we have @xmath198 , @xmath199 , @xmath200 , and first three approximate moments @xmath201 , @xmath202 , and @xmath203 . also , @xmath204 .",
    "4 .   truncated extreme value ( @xmath155 , @xmath175 ) : @xmath205 , @xmath206 , @xmath207 , and @xmath208 .",
    "we have @xmath122 , @xmath209 , @xmath210 , @xmath125 , @xmath211 , @xmath212 , and @xmath213 .",
    "pareto ( @xmath155 , @xmath194 , @xmath57 known , @xmath214 ) : @xmath215 , @xmath216 , and @xmath217 . here ,",
    "@xmath218 , @xmath219 , @xmath220 , @xmath221 , @xmath222 , @xmath223 , and @xmath224 .",
    "power ( @xmath225 , @xmath155 , @xmath226 known , @xmath227 ) : @xmath228 , @xmath229 , and @xmath217 .",
    "the @xmath76 s , the first three approximate moments , and the bartlett - type corrected statistic coincide with those obtained for the pareto distribution .",
    "7 .   laplace ( @xmath225 , @xmath230 ,",
    "@xmath57 known , @xmath157 ) : @xmath231 , @xmath232 , @xmath233 , and @xmath234 .",
    "we have @xmath122 , @xmath235 , @xmath210 , @xmath125 , @xmath126 , @xmath127 , and @xmath132 .",
    "the two - parameter families of distributions under orthogonality of the parameters @xcite , say @xmath98 and @xmath236 , will be the subject of this section .",
    "the null hypothesis under test is @xmath237 , where @xmath101 is a fixed value , and @xmath236 acts as a nuisance parameter .",
    "the orthogonality between @xmath98 and @xmath236 leads to considerable simplification in the formulas of @xmath238 @xmath111 , and @xmath112 . here , @xmath239 , @xmath240 , etc .",
    "after some algebra , we have @xmath241 where @xmath242 and @xmath243 are equal to @xmath110 and @xmath111 given in and , respectively , and @xmath244 @xmath245 the expressions for @xmath246 and @xmath247 in can be regarded as the additional contribution introduced in the expansion of the cumulative distribution function of the gradient statistic owing to the fact that @xmath236 is unknown and has to be estimated from the data . in the following , we present some examples .",
    "( normal distribution )    let @xmath248 be a random sample from a normal distribution @xmath249 .",
    "the gradient statistic can be written in the form @xmath250 where @xmath251 and @xmath252 , where @xmath253 . under the null hypothesis , @xmath254 and @xmath255",
    "are independent with distributions @xmath256 and @xmath257 , respectively .",
    "it can be shown that @xmath258 has a beta distribution with parameters @xmath259 and @xmath260 .",
    "the first three exact moments of @xmath91 are @xmath60 , @xmath261 , and @xmath262 , respectively . here , @xmath263 and @xmath264 .",
    "the first three approximate moments of @xmath91 are @xmath265 , @xmath266 , and @xmath267 .",
    "these moments differ from the approximate moments only by terms of order less than @xmath28 .",
    "the bartlett - type corrected gradient statistic is @xmath268 .",
    "( bivariate two - parameter exponential distribution )    let @xmath269 and @xmath270 be two independent random samples from exponential distributions with means @xmath158 and @xmath271 , respectively .",
    "it can be shown that @xmath98 and @xmath272 are globally orthogonal .",
    "the parameter of interest is @xmath98  the ratio of the means  and the interest lies in testing @xmath273 , which is equivalent to the equality of the two population means , against @xmath274 .",
    "we consider the balanced case ( @xmath275 , @xmath276 even ) .",
    "let @xmath277 and @xmath278 be the sample means .",
    "the log - likelihood function can be written as @xmath279 the gradient statistic for testing @xmath19 takes the form @xmath280 where @xmath281 .",
    "the cumulants of log - likelihood derivatives are @xmath282 , @xmath283 , @xmath284 , @xmath285 , @xmath286 , @xmath287 , @xmath288 , @xmath289 , and @xmath290 . from , we have @xmath180 , @xmath291 , and @xmath292 . the corrected gradient statistic becomes @xmath293 .",
    "( two - parameter birnbaum  saunders distribution )    the two - parameter birnbaum ",
    "saunders distribution was proposed by @xcite and has cumulative distribution function in the form @xmath294 , with @xmath295 , where @xmath296 , @xmath297 , and @xmath298 is the standard normal cumulative distribution function ; @xmath155 and @xmath299 are the shape and scale parameters , respectively .",
    "we wish to test @xmath99 against the alternative hypothesis @xmath100 , where @xmath101 is a known positive constant .",
    "the gradient statistic to test @xmath19 is @xmath300 where @xmath301 , @xmath302 , and @xmath303 is the maximum likelihood estimator of @xmath236 obtained under @xmath19 .",
    "we have @xmath304 , @xmath305 , and @xmath306 , where @xmath307 .",
    "after some algebra , we obtain @xmath308 , @xmath309 , @xmath310 $ ] , @xmath311 , and @xmath312 since the necessary quantities to obtain the @xmath76 s were derived , a bartlett - corrected gradient statistic may be obtained from corollary [ col_corr_grad ] .",
    "it is interesting to note that the @xmath76 s do not depend on the unknown scalar parameter @xmath236 .",
    "next , we shall present a small monte carlo simulation regarding the test of the null hypothesis @xmath273 .",
    "the simulations were performed by setting @xmath313 and sample sizes ranging from 5 to 22 observations .",
    "all results are based on 10,000 replications .",
    "the size distortions ( i.e.  estimated minus nominal sizes ) for the 5% nominal level of the gradient statistic and its bartlett - corrected version for different sample sizes are plotted in figure [ plots](a ) .",
    "it is clear from this figure that the bartlett - corrected test displays smaller size distortions than the original gradient test .",
    "finally , we set @xmath314 and consider the first - order approximation ( @xmath315 distribution ) for the distribution of the gradient statistic and the expansion obtained in this paper .",
    "figure [ plots](b ) presents the curves .",
    "the difference between the curves is evident from this figure , and hence , the @xmath315 distribution may not be a good approximation for the null distribution of the gradient statistic in testing the null hypothesis @xmath273 for the two - parameter birnbaum  saunders model if the sample is small .",
    "( dashes ) of the null cumulative distribution function of the gradient statistic.,title=\"fig : \" ]   ( dashes ) of the null cumulative distribution function of the gradient statistic.,title=\"fig : \" ]",
    "@xcite showed that the gradient test can be an interesting alternative to the classic large - sample tests , namely the likelihood ratio , the wald , and the rao score tests , since none is uniformly superior to the others in terms of second - order local power .",
    "additionally , as remarked before , the gradient statistic does not require to obtain , estimate , or invert an information matrix , unlike the wald and the rao score statistics .",
    "its formal simplicity is always an attraction .",
    "the exact null distribution of the gradient statistic is usually unknown and the test relies upon an asymptotic approximation .",
    "the chi - square distribution is used as a large - sample approximation to the true null distribution of this statistic . however , for small sample sizes , the chi - square distribution may be a poor approximation to the true null distribution ; that is , the asymptotic approximation may deliver inaccurate inference . in order to overcome this shortcoming ,",
    "an alternative strategy is to use a higher - order asymptotic theory .",
    "the asymptotic expansion up to order @xmath28 for the null distribution function of the gradient statistic was derived in this paper . a bayesian route based on the shrinkage argument @xcite proved to be extremely useful in this context .",
    "the expansion is very general in the sense that the null hypothesis can be composite in the presence of nuisance parameters .",
    "we show that the coefficients which define this expansion depend on the joint cumulants of log likelihood derivatives for the full data . unfortunately , these coefficients are very difficult to interpret in generality .",
    "@xcite showed that , quite generally , continuous statistics having a chi - square distribution asymptotically can be modified by a suitable correction term that makes the modified statistic have chi - square distribution to order @xmath28 .",
    "their work can be viewed as an extension of bartlett corrections to the likelihood ratio statistic @xcite to other statistics having a chi - square distribution asymptotically .",
    "the correction term comes from the coefficients of the @xmath316 term in the expansion of the cumulative distribution function of the test statistic in such a way that it becomes better approximated by the reference chi - square distribution .",
    "it is known as the bartlett - type correction .",
    "it is well known that bartlett and bartlett - type corrections have become a widely used method for improving the large - sample chi - square approximation to the null distribution of the likelihood ratio and rao score statistics , respectively . in recent years",
    "there has been a renewed interest in bartlett factors and several papers have been published giving expressions for computing these corrections for special models .",
    "some references are @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , and @xcite .    from the general expansion derived in this paper and using results in @xcite",
    ", we also obtained a bartlett - type correction factor for the gradient statistic .",
    "our results are very general and not tied to special classes of models .",
    "they allow the parameter vector to be multidimensional and are valid regardless of whether nuisance parameters are present or not . additionally , as the coefficients in the expansion , and consequently in the bartlett - type correction factor ,",
    "are written as functions of cumulants of log - likelihood derivatives , they can be obtained for all the classes of parametric models for which those cumulants can be determined .",
    "therefore , applications of our general results in several parametric models , such as the generalised linear models and extensions , can be studied in future research .",
    "we gratefully acknowledge grants from fapesp and cnpq ( brazil ) .",
    "except when indicated , the indices @xmath54 , @xmath55 , @xmath56 , @xmath59 , @xmath317 , and @xmath318 range over @xmath60 to @xmath4 and the indices @xmath319 , @xmath320 , @xmath321 , @xmath322 , @xmath323 , and @xmath324 range over @xmath60 to @xmath11 . also , an array index repeated as both a superscript and a subscript indicates an implied summation over the appropriate range .",
    "let @xmath325 , @xmath326 , @xmath327 , etc .",
    "the matrix @xmath328 is the observed information matrix evaluated at @xmath329 .",
    "the partition of @xmath330 induces the partition @xmath331 where @xmath332 is the inverse of @xmath333 .",
    "let @xmath334 , @xmath335 , @xmath336 , @xmath337 $ ] , @xmath338 $ ] , and @xmath339 $ ] , where @xmath340 $ ] denotes a summation with the number in brackets indicating the number of terms obtained by permutation of indices .",
    "for instance , @xmath341=\\sigma^{su}\\sigma^{vw}+\\sigma^{sv}\\sigma^{uw}+\\sigma^{sw}\\sigma^{uv}$ ] .",
    "let @xmath342 , @xmath343 , @xmath344 , @xmath345    [ lemma1 ] an asymptotic expansion under the null hypothesis for the gradient statistic @xmath346 is @xmath347    using a procedure analogous to that of @xcite , the result holds .",
    "let @xmath348 be a prior density for @xmath349 , @xmath350 , @xmath351 , @xmath352 , @xmath353 , @xmath354 , @xmath355 @xmath356 @xmath357 from @xcite , @xcite derive an expansion up to order @xmath28 for the marginal posterior density of @xmath358 , which takes the form @xmath359+o(n^{-1 } ) , \\end{split}\\end{aligned}\\ ] ] where @xmath360 denotes the density of the @xmath11-variate normal distribution with mean @xmath361 and covariance matrix @xmath362 .",
    "we now follow the bayesian route described in @xcite ; see appendix 2 . + * step 1 . *",
    "the approximate posterior characteristic function of @xmath91 is @xmath363 where @xmath364 with @xmath365 . from lemma [ lemma1 ] and after some algebra , we can write @xmath366\\epsilon_{j'}\\epsilon_{r'}\\epsilon_{s'}\\epsilon_{u'}\\\\ & \\quad+\\gamma_{j'r'}^{(2)}\\bigl(\\epsilon_{j'}\\epsilon_{r ' } -\\lambda^{j'r'}\\bigr)-\\gamma_{j'r's'u'}^{(4)}\\lambda^{(1)}_{j'r's'u'}\\biggr]\\biggr]+o_p(n^{-1}).\\end{aligned}\\ ] ] now , by writing @xmath367 , @xmath368 , and assuming that @xmath349 is in the interior of the support of @xmath369 , we obtain after some algebra @xmath370 where @xmath371 , @xmath372 @xmath373 @xmath374    * step 2 . *",
    "let @xmath375 be an auxiliary prior density for @xmath14 satisfying the conditions in @xcite .",
    "we now obtain an approximate posterior characteristic function of @xmath91 under the prior @xmath375 , say @xmath376 . from",
    ", we have @xmath377 where @xmath378 denotes the counterpart of @xmath379 obtained by replacing @xmath380 with @xmath375 . after some algebra",
    ", we have @xmath381 where @xmath382 , @xmath383 @xmath384,\\end{aligned}\\ ] ] @xmath385    * step 3 .",
    "* we now compute @xmath386 by integrating the @xmath387 s with respect to @xmath388 . after integrating each term that depends on the prior distributions and by allowing @xmath375 to converge weakly to the degenerate prior at the true value of @xmath14",
    ", we arrive at @xmath389 where the @xmath390 s are functions of cumulants of log - likelihood derivatives . by writing @xmath391 and using the fact that @xmath392 , we arrive at @xmath393 with @xmath394 , @xmath395 , and @xmath396",
    ". we can write @xmath397 @xmath398 @xmath399 inverting @xmath400 in and interchanging the indices in a suitable manner , after some algebra , we arrive at the expression for @xmath110 , @xmath111 , and @xmath112 as given in theorem @xmath401 .",
    "let @xmath402 be a random vector with density @xmath403 , where @xmath404 is a @xmath4-dimensional parameter and @xmath405 is an open subset of the euclidean space .",
    "let @xmath406 be a measurable function .",
    "assume that @xmath407 is continuous for all @xmath14 and that its expectation exists . a bayesian route for obtaining @xmath408 based on a shrinkage argument involves the three steps described below .",
    ": :    obtain    @xmath409 , the    posterior expectation of @xmath407 under the prior    @xmath380 for @xmath14 .",
    ": :    find    @xmath410=\\delta(\\bm{\\theta})$ ] ,    for @xmath411 , where    @xmath412 denotes the interior of the support of    @xmath369 .",
    ": :    integrate @xmath413 with respect to    @xmath380 and allow @xmath380 to    converge weakly to the degenerate prior at @xmath14 ,    where @xmath411 .",
    "this yields    @xmath414 .",
    "score test : historical review and recent developments . in _ advances in ranking and selection , multiple comparisons , and reliability _ , n.  balakrishnan , n.  kannan and h.  n. nagaraja , eds .",
    "birkhuser , boston ."
  ],
  "abstract_text": [
    "<S> we obtain an asymptotic expansion for the null distribution function of the gradient statistic for testing composite null hypotheses in the presence of nuisance parameters . the expansion is derived using a bayesian route based on the shrinkage argument described in @xcite . using this expansion </S>",
    "<S> , we propose a bartlett - type corrected gradient statistic with chi - square distribution up to an error of order @xmath0 under the null hypothesis . </S>",
    "<S> further , we also use the expansion to modify the percentage points of the large sample reference chi - square distribution . </S>",
    "<S> a small monte carlo experiment and various examples are presented and discussed . + _ key - words : _ asymptotic expansion ; bartlett - type correction ; bayesian route ; gradient statistic ; shrinkage argument . </S>"
  ]
}