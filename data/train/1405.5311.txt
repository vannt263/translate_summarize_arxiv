{
  "article_text": [
    "in recent years there has been a huge explosion in the variety of sensors and the dimensionality of the data produced by these sensors and this has been in a large number of applications ranging from imaging to other scientific applications.the total amount of data produced by the sensors is much more than the available storage .",
    "so we often need to store a subset of the data .",
    "we want to reconstruct the entire data from it .",
    "the famous nyquist - shannon sampling theorem [ 5 ] tells us that if we can sample a signal at twice its highest frequency we can recover it exactly . in applications",
    "this often results in too many samples which must be compressed in order to store or transmit .",
    "an alternative is compressive sampling ( cs ) which provides a more general data acquisition protocol by reducing the signal directly into a compressed representation by taking linear combinations . in this paper",
    "we present a brief of the conventional approach of compressive sampling and propose a new approach that makes use of the em algorithm to reconstruct the entire signal from the compressed signals .",
    "when a signal is sparse in some basis , a few well chosen observations suffice to reconstruct the most significant nonzero components .    [",
    "[ consider - a - signal - mathbfx - represented - in - terms - of - a - basis - expansion - as ] ] consider a signal @xmath0 represented in terms of a basis expansion as + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    @xmath1 the basis @xmath2 is such that only @xmath3 coefficients @xmath4 have significant magnitude .",
    "many natural and artificial signals are sparse in the sense that there exists a basis where the above representation has just a few large coefficients and other small coefficients . as an example natural images are likely to be compressible in discrete cosine transform(dct ) and",
    "wavelet bases [ 1 ] . in general we do not know apriori which coefficients are significant .",
    "the data collected by a measurement system consists of some linear combinations of the signals    @xmath5 where @xmath6 is a measurement matrix ( also called sensing matrix ) which is chosen by the statistician .",
    "the measurement process is non - adaptive as @xmath7(and hence @xmath8 does not depend in any way on the signal @xmath0 .",
    "@xmath9 is the error which is assumed to be bounded or bounded with high probability .",
    "[ [ our - aim - here - is - to ] ] our aim here is to : + + + + + + + + + + + + + + + + + + + +    * design a stable measurement matrix that preserves the information in any @xmath10-sparse signal during the dimensionality reduction from @xmath11 to @xmath12 .",
    "* design a reconstruction algorithm to recover the original data @xmath0 from the measurements @xmath13 .",
    "[ [ we - note - that - the - recovery - algorithm - addresses - the - problem - of - solving - for - mathbfx - when - the - number - of - unknowns - i.e .-",
    "n - is - much - larger - than - the - number - of - observations - i.e .- m-.-in - general - this - is - an - ill - posed - problem - but - cs - theory - provides - a - condition - on - phi - which - allows - accurate - estimation . ] ] we note that the recovery algorithm addresses the problem of solving for @xmath0 when the number of unknowns ( i.e. @xmath14 ) is much larger than the number of observations ( i.e. @xmath15 ) . in general",
    "this is an ill - posed problem but cs theory provides a condition on @xmath7 which allows accurate estimation .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one such popularly used property is restricted isometry property ( rip ) [ 2 ] .",
    "the matrix @xmath16 satisfies the restricted isometry property of order @xmath10 with parameters @xmath17 if    @xmath18 holds simultaneously for all sparse vectors @xmath19 having no more than @xmath10 nonzero entries .",
    "matrices with this property are denoted by rip(@xmath20",
    "[ [ the - following - theorem - shows - that - matrices - satisfying - rip - will - yield - accurate - estimates - of - mathbfx - with - the - help - of - recovery - algorithms . ] ] the following theorem shows that matrices satisfying rip will yield accurate estimates of @xmath0 with the help of recovery algorithms .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath16 be a matrix satisfying rip@xmath21 with @xmath22 and let @xmath23 be a vector of noisy observations , where @xmath24 .",
    "let @xmath25 be the best @xmath10-sparse approximation of @xmath2 , that is , @xmath26 is the approximation obtained by keeping the @xmath10 largest entries of @xmath27 and setting others to zero .",
    "then the estimate    @xmath28    obeys @xmath29 where @xmath30 and @xmath31 are constants depending on @xmath10 but not on @xmath14 or @xmath15 .",
    "[ [ the - reconstruction - in-3.1-is - equivalent - to ] ] the reconstruction in ( 3.1 ) is equivalent to + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    @xmath32    where @xmath33 is a regularization parameter which depends on @xmath34 .",
    "in this approach we apply em algorithm for the reconstruction of the signal .",
    "since we observe some linear combinations of the signals instead of the entire signals we can treat the observed linear combinations as our observed data and the entire signals as the complete data which is unobserved . hence we apply em algorithm as a most natural tool of missing data analysis to reconstruct the data . here",
    "we assume that data are coming from a population with mean @xmath35 and that @xmath35 is sparse ( w.r.t some basis ) . without loss of generality",
    "we assume that @xmath35 is sparse with respect to euclidean basis.we assume that at most @xmath10 elements of * @xmath35 * is nonzero .",
    "[ [ let - us - assume - that - the - parent - population - is - normal - viz .- nmathbfboldsymbolmathbfmusigma2i_n ] ] let us assume that the parent population is normal viz . @xmath36 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ then - we - have - the - signal - as - mathbfxboldsymbolmathbfmuboldsymbolepsilon - where - mathbfboldsymbolepsilonsim - n0i_n ] ] then we have the signal as @xmath37 where @xmath38 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    then with the help of the sensing matrix we have the observed data as    @xmath39 where @xmath40    [ [ thus - unlike - the - conventional - approach - here - we - assume - that - the - signals - themselves - are - subject - to - error - and - consequently - the - observed - combinations - of - the - signals - are - also - subject - to - error .- here - we - try - to - reconstruct - the - unobserved - true - signals - which - are - free - from - error . ]",
    "] thus unlike the conventional approach here we assume that the signals themselves are subject to error and consequently the observed combinations of the signals are also subject to error .",
    "here we try to reconstruct the unobserved true signals which are free from error .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we then treat @xmath0 as the complete data and @xmath13 as the observed data and try to estimate @xmath41 from the observed data using em algorithm .thus we have @xmath42    @xmath43    @xmath44    [ [ the - complete - data - likelihood - is - given - by - fmathbfxfrac1sigmasqrt2pine - frac12sigma2mathbfx - boldsymbolmathbfmux - boldsymbolmathbfmumathbfxinmathbbrnmathbfboldsymbolmathbfmuinmathbbrnsigma0-the - conditional - distribution - of - the - complete - data - given - the - observed - data - is ] ] the complete data likelihood is given by @xmath45 the conditional distribution of the complete data given the observed data is + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    @xmath46    [ [ after - t - iterations - in - em - algorithm - we - have ] ] after @xmath47 iterations in em algorithm we have , + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    * * * : we compute the expected complete data log - likelihood w.r.t the conditional distribution of @xmath48.now @xmath49 @xmath50 also @xmath51 define @xmath52 * * * : here we try to maximize @xmath53 with respect to @xmath35.we know that @xmath54 is sparse i.e. some of the @xmath55 are zero .",
    "so we need to maximize @xmath56 w.r.t . @xmath35 belonging to a subset @xmath57 thus we find @xmath58    [ [ for - this - we - note - that - scup_i1n - choose - ks_i - where - s_iboldsymbolmutextrmat - most - ensuremathispecific - elements - of - ensuremathboldsymbolmu - are - nonzero - we - then - find - argmax_boldsymbolmuin - s_iqboldsymbolmu - for - each - i - and - call - the - estimate - as - mathbfhatmut1s_ihatmu_1t1s_ihatmu_2t1s_i ...",
    "hatmu_kt1s_i - now - the ] ] for this we note that @xmath59 where @xmath60 we then find @xmath61 for each @xmath62 and call the estimate as @xmath63 now the + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ setting - fracpartialpartialmu_jqboldsymbolmu0-for - those - j - such - that - mu_jneq0-we - find - that - hatmu_jt1s_imu_jtalpha_jbeta_j - where - alpha_jtextrmensuremathjthelement - ofphiphiphi-1y - and - beta_jtextrmensuremathjthelement - ofphiphiphi-1phiboldsymbolmut . ] ] setting @xmath64 for those @xmath65 such that @xmath66 we find that @xmath67 where @xmath68 and @xmath69 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ then - we - choose - the - mathbfhatboldsymbolmut1s_i - for - which - qmathbfhatboldsymbolmut1s_i - is - maximum - as - the - new - estimate - of - mathbfboldsymbolmu - at - t1th - iteration.thus - the - estimate - of - boldsymbolmu - is - hatboldsymbolmut1hatboldsymbolmut1s_i - such - that - qmathbfhatboldsymbolmut1s_igeq - qmathbfhatboldsymbolmut1s_jforall - jneq - i - we - iterate - until - convergence . ] ] then we choose the @xmath70 for which @xmath71 is maximum as the new estimate of @xmath72 at @xmath73 iteration.thus the estimate of @xmath74 is @xmath75 such that @xmath76 we iterate until convergence .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +",
    "the new approach discussed in the previous section requires the maximization of @xmath77 over @xmath78 subspaces and then choose the one for which it is maximum at the m step of each em iteration .",
    "this is computationally expensive and practically impossible to implement for large @xmath14 .",
    "hence we suggest an alternative way which instead of maximization over @xmath78 subspaces in each em iteration identifies a particular subspace where @xmath74 is most likely to belong , and then finds the maximum over that subspace in each m step .",
    "[ [ let - s_boldsymbolmu - be - the - subspace - where - boldsymbolmu - lies - that - is - s_boldsymbolmux_1x_2ldotsx_ninmathbbrnforall - imu_i0rightarrow - x_i0-we - note - that - if - we - find - the - unrestricted - maximizer - of - qboldsymbolmu - in - each - m - step - of - the - em - algorithm - henceforth - call - unrestricted - em - that - is - if - we - find - hatboldsymbolmuunargmax_boldsymbolmuinmathbbrqboldsymbolmu - then - the - unrestricted - em - estimate - hatboldsymbolmuun - should - lie - close - to - s_boldsymbolmu .- hence - the - unrestricted - estimate - should - provide - an - indication - of - the - subspace - in - which - the - original - parameter - lies .- hence - we - find - which - components - of - hatboldsymbolmuun - are - significant - so - that - we - can - take - the - other - insignificant - components - to - be - zero - and - take - the - corresponding - subspace - thus - formed - to - be - the - one - in - which - our - estimate - should - lie .- we - test - which - components - of - hatboldsymbolmuun - are - significantly - different - from - zero . ]",
    "] let @xmath79 be the subspace where @xmath74 lies , that is @xmath80 we note that if we find the unrestricted maximizer of @xmath77 in each m step of the em algorithm ( henceforth call unrestricted em ) , that is if we find @xmath81 then the unrestricted em estimate @xmath82 should lie close to @xmath79 .",
    "hence the unrestricted estimate should provide an indication of the subspace in which the original parameter lies .",
    "hence we find which components of @xmath82 are significant so that we can take the other insignificant components to be zero and take the corresponding subspace thus formed to be the one in which our estimate should lie .",
    "we test which components of @xmath82 are significantly different from zero .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    now for the unrestricted em algorithm the estimate of @xmath74 should converge to the maximizer of the observed log - likelihood .",
    "the observed log - likelihood is @xmath83 setting @xmath84 we get @xmath85 where @xmath86 .",
    "[ [ the - above - equation - eqrefeqmyequation1-does - not - have - a - unique - solution - as - rankphiv-1phi_ntimes - nmll - n .- hence - the - observed - likelihood - does - not - have - a - unique - maximum - and - our - unrestricted - em - algorithm - will - produce - many - estimates - of - boldsymbolmu .- among - these - many - estimates - we - choose - the - sparsest - solution .- this - is - taken - care - of - by - taking - the - initial - estimate - of - boldsymbolmuas - boldsymbol0-in - the - iterative - process - as - then - the - estimate - will - hopefully - converge - to - nearest - solution - which - will - be - the - sparest - one .- we - will - justify - this - later - with - the - help - of - simulation . ] ] the above equation @xmath87 does not have a unique solution as @xmath88=m\\ll n$ ] . hence the observed likelihood does not have a unique maximum and our unrestricted em algorithm will produce many estimates of @xmath74 . among these many estimates",
    "we choose the sparsest solution .",
    "this is taken care of by taking the initial estimate of @xmath74as @xmath89 in the iterative process as then the estimate will hopefully converge to nearest solution which will be the sparest one .",
    "we will justify this later with the help of simulation",
    ". + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ we - have - hatboldsymbolmuunphiv-1phiphiv-1ypmathbfy - where - pphiv-1phiphiv-1 ] ] we have @xmath90 where @xmath91 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ here - we - take - the - moore - penrose - inverse - of - phiv-1phi - as - we - want - to - find - the - least - norm - solution - of - eqrefeqmyequation1- . ] ] here we take the moore - penrose inverse of @xmath92 as we want to find the least norm solution of @xmath87 . + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ now - hatboldsymbolmuunsimmathbfn_npphiboldsymbolmu - pvpmathbf - thus - ehatboldsymbolmuunpphiboldsymbolmu - and - hatboldsymbolmuun - should - lie - close - to - the - sparseboldsymbolmu .- hence - pphiboldsymbolmu - should - be - close - to - boldsymbolmuand ] ] now @xmath93 thus @xmath94 and @xmath82 should lie close to the sparse@xmath74 . hence @xmath95 should be close to @xmath74and + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ we - want - to - test - n - hypotheses - h_0imu_i0qquadforall - i11n - let - hatboldsymbolmuunhatmu_1unhatmu_2unldotshatmu_nun - then - the - test - statistics - for - testing - h_0i - is - tau_ifrachatmu_iunsqrts_iisim - n01quadtextrmunder - ensuremathh_0iqquadforall - i11n - where - s_iiithtextrmdiagonal - element - of - pvp ] ] we want to test @xmath14 hypotheses @xmath96 let @xmath97 then the test statistics for testing @xmath98 is @xmath99 where @xmath100 + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ thus - we - estimate - the - subspace - where - boldsymbolmu - lies - as - hats_boldsymbolmux_1x_2ldotsx_ninmathbbrnforall - itau_ileq - z_alpha2rightarrow - x_i0-with - this - new - estimated - subspace - we - apply - our - original - restricted - em - algorithm - as - in - the - previous - section - as - follows ] ] thus we estimate the subspace where @xmath74 lies as @xmath101 with this new estimated subspace we apply our original restricted em algorithm as in the previous section as follows : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ after - t - iterations - in - em - algorithm - we - have-1 ] ] after @xmath47 iterations in em algorithm we have , + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    * * * : compute @xmath102 * * * : we find @xmath103 and take the maximizer as the new estimate of @xmath74 , that is , @xmath104 .    [ [ we - iterate - until - convergence . ] ] we iterate until convergence",
    ". + + + + + + + + + + + + + + + + + + + + + + + + + + + + +",
    "in this section we compare the different approaches with the help of simulation .",
    "we will also verify the convergence of @xmath82 to the sparsest solution as claimed in the previous section .",
    "the performance of the new proposed algorithm will be studied using simulation technique where we will investigate to what extent we can reduce the dimension of the observed data using the proposed approach in order to have a fair reconstruction of the parameter .",
    "here we see that in the unrestricted em algorithm the em estimate of @xmath74 converge to the sparsest solution of equation @xmath87 if we take our initial estimate as @xmath105 ( or very close to @xmath105 ) .",
    "we take different initial estimates of @xmath74 randomly and check the @xmath106 norm of the final estimates @xmath82 in each case . for demonstration we work with @xmath107 .",
    "we find that we reach the minimum norm solution if the initial estimate of @xmath74 is taken close to @xmath105 .",
    "[ cols=\"^,^\",options=\"header \" , ]      next we compare the accuracy of the different approaches discussed in the paper . from * theorem 2",
    "* we find that the accuracy of the reconstructed signal is shown by @xmath108 .",
    "hence we take @xmath109as measure of closeness between the original and the reconstructed signal .",
    "we note that there is difference in the setup of the data in the approaches @xmath110 .",
    "the conventional approach reconstruct the signal @xmath0 whereas the new approaches reconstruct what is called true signal ( free from noise ) @xmath74 .",
    "hence for comparison we reconstruct signals from same population using conventional approach and average out the residuals to remove the effect of the noise .",
    "[ [ for - the - comparison - of - approaches - we - adopted - the - following - technique ] ] for the comparison of approaches we adopted the following technique : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    * we set the actual number of observations @xmath14 and the observed number of observations @xmath15 .",
    "@xmath10 , the maximum number of nonzero components in @xmath74 , is taken to be equal to @xmath15 ( maximum possible value ) , that is , we do not use any prior information about the number of nonzero components in @xmath74 .",
    "* we fix a @xmath74 such that its first @xmath111 components are @xmath112 and the rest are zero .",
    "* we start with a value of @xmath113 between @xmath114 and @xmath115 .    * * assessing conventional approach : * we generate data @xmath0 from @xmath116 and reconstruct @xmath117 using @xmath118 from the conventional approach and find @xmath109 .",
    "this process is repeated 1000 times to find the residuals in each case and then we compute the mean residual @xmath119 to remove the effect of randomness and get a measure of closeness among the original and reconstructed @xmath74 .    * * assessing new approaches : * we again generate data @xmath0 from @xmath116 .we apply the naive approach ( wherever possible ) and the new approach to reconstruct @xmath74 and find @xmath120 as a measure of closeness between the original and estimated values .",
    "* for each value of @xmath113 in we repeat the process of assessing the conventional and new approaches @xmath121 times each to get the average residual and standard error of the residuals for each of the conventional and the proposed algorithms .",
    "* we repeat the above procedures for different values of @xmath113 in @xmath122 $ ] and plot the mean residuals along with the standard error bars .    for small values of @xmath14",
    "we plot the average residuals for the three approaches discussed earlier .",
    "[ [ for-n10-we-find-that-the-naive-approach-works-uniformly-best-for-different-values-of-sigma.thus-it-would-have-been-nice-if-we-can-apply-this-naive-approach-for-all-values-of-n-but-unfortunately-due-to-the-inapplicability-of-this-procedure-we-turn-our-attention-towards-the-new-approach . ] ] for @xmath123 we find that the naive approach works uniformly best for different values of @xmath113.thus it would have been nice if we can apply this naive approach for all values of @xmath14 , but unfortunately due to the inapplicability of this procedure we turn our attention towards the new approach .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ for - moderate - to - large - values - of - n - we - cannot - plot - the - residuals - of - the - naive - approach - as - it - is - computationally - impossible .- also - the - comparison - between - the - new - and - the - conventional - approach - cannot - be - performed - for - very - large - values - of - n - because - of - computational - time .- we - find - that - the - new - approach - works - uniformly - better - for - different - values - of - sigma - for - both - n50-and - n100 . ] ] for moderate to large values of @xmath14 we can not plot the residuals of the naive approach as it is computationally impossible .",
    "also the comparison between the new and the conventional approach can not be performed for very large values of @xmath14 because of computational time .",
    "we find that the new approach works uniformly better for different values of @xmath113 for both @xmath124 and @xmath125 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ imageimage ] ]    + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +      the value of @xmath126 in the above procedures is an important point of consideration .",
    "it signifies the sampling fraction , that is to what extent we can reduce the dimensionality of the problem .",
    "we fix @xmath127 and with @xmath128 we plot the average residuals for varying @xmath15 .    [ [ section ] ] +        [ [ the - procedure - works - good - if - we - take - m500-that - is - at - this - variance - level - we - can - afford-50-dimensionality - reduction . ] ] the procedure works good if we take @xmath129 , that is at this variance level we can afford @xmath130 dimensionality reduction .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ [ thus - we - find - that - the - new - approach - works - better - than - the - conventional - method - of - signal - reconstruction .- the - conventional - method - of - reconstructing - the - signal - assumes - the - noise - to - be - bounded - with - high - probability - and - thus - fail - to - perform - well - for - large - error - variance - whereas - the - new - approach - allows - the - error - variance - to - be - large - enough - and - thus - make - it - applicable - to - other - situations .- also - the - conventional - approach - assumes - that - the - signal - is - sparse - and - sparsity - is - an - essential - ingredient - in - the - reconstruction - algorithm .- the - new - proposed - approach - can - easily - be - generalized - to - even - situations - where - signals - need - not - to - be - sparse .- however - we - find - that - the - naive - approach - we - proposed - earlier - works - best - if - it - can - be - implemented .- for - moderate - to - large - dimensional - problems - which - are - common - in - practice - the - new - algorithm - works - better - than - the - conventional - approach . ] ] thus we find that the new approach works better than the conventional method of signal reconstruction .",
    "the conventional method of reconstructing the signal assumes the noise to be bounded with high probability and thus fail to perform well for large error variance whereas the new approach allows the error variance to be large enough and thus make it applicable to other situations . also the conventional approach assumes that the signal is sparse and sparsity is an essential ingredient in the reconstruction algorithm .",
    "the new proposed approach can easily be generalized to even situations where signals need not to be sparse .",
    "however we find that the naive approach we proposed earlier works best if it can be implemented . for moderate to large dimensional problems which are common in practice the new algorithm works better than the conventional approach .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +",
    "the present paper treats observations or signals as iid samples from a population .",
    "this can be extended assuming a non - iid setup where the signals may be generated from a stochastic process .",
    "further here we work with linear combinations of all signals .",
    "a further extension can be done where we builld the model with linear combinations of some signals and apply it for future signals in the process ."
  ],
  "abstract_text": [
    "<S> conventional approaches of sampling signals follow the celebrated theorem of nyquist and shannon . </S>",
    "<S> compressive sampling , introduced by donoho , romberg and tao , is a new paradigm that goes against the conventional methods in data acquisition and provides a way of recovering signals using fewer samples than the traditional methods use . </S>",
    "<S> here we suggest an alternative way of reconstructing the original signals in compressive sampling using em algorithm . </S>",
    "<S> we first propose a naive approach which has certain computational difficulties and subsequently modify it to a new approach which performs better than the conventional methods of compressive sampling . </S>",
    "<S> the comparison of the different approaches and the performance of the new approach has been studied using simulated data . </S>"
  ]
}