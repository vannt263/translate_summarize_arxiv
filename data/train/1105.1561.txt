{
  "article_text": [
    "live in a digitized information world , but many of the physical sources , such as sound and images , are by nature analog . to transmit analog sources using digital communication systems require the signals to first of all",
    "be a / d ( analog - to - digital ) converted , which involves sampling and quantization .",
    "sampling , the operation that transforms a signal from `` continuous in time '' to `` discrete in time '' , is reversible , i.e. the original continuous - time signal can be reconstructed from the discrete samples loss - free , provided the samples were taken at ( or above ) the nyquist rate .",
    "however , quantization , the operation that transforms a signal from `` continuous in amplitude '' to `` discrete in amplitude '' , is irreversible , i.e. , the distortion caused by rounding off the signal amplitude can not be recovered after quantization . to keep down the granularity error in general",
    "requires a large number of quantization levels and/or high - dimension ( vector ) quantization .",
    "since vector quantizers are very challenging to design , and usually require the knowledge of high - order source statistics ( e.g. joint probability distribution of the @xmath0th order for @xmath0-dimension quantization ) which may not be easily available , real - world systems tend to use simpler scalar quantizers with many levels , at the cost of a large bandwidth expansion .    however , quantization error and bandwidth expansion are not all the problems .",
    "another practical issue concerns the labeling .",
    "an @xmath0-level quantization scheme takes @xmath1 bits to label each level .",
    "regardless of what labeling scheme is used ( gray , natural or mixed label ) , different bits in the label will have different levels of importance , but this natural hierarchy is not reflected in the communication channel which treats all the bits equal .",
    "for example , consider a 256-level monochrome image via natural labeling , where each pixel takes 8 bits to represent .",
    "an error in the least significant bit causes the pixel to be distorted by only one gray level , whereas an error in the most significant bit causes a drastic distortion of 128 levels ! to avoid ( wasteful ) over - protection of some bits and/or ( disastrous ) under - protection of others , one must employ unequal error protection ( uep ) , but to provision the right protection to bits in accordance with their individual importance is nevertheless challenging .",
    "many design issues arise , such as how much more important and hence how much more protection one bit deserves in comparison to another , what error correction codes ( lengths , rates , error correction capabilities ) are appropriate for each , and how to balance the rates between quantization , error correction and modulation .",
    "most of these issues are difficult to quantify or optimize .    while all of the above issues appear like a fact - of - life that one has to accept , they actually need not be so .",
    "they stand in the way only because we force analog signals into a _ digitalized _ transmission paradigm .",
    "consider an analog alternative that leaves out quantization altogether and directly transmits discrete - time continuous - valued analog signals ( see fig .",
    "[ fig : analogdigital ] ) , then all the quantization problems would be gone @xcite .",
    "the only obstacle , however , is that efficient analog error correction codes ( aecc ) are hard to find .",
    "one exciting result we wish to report here is that practical and efficient aecc _ can _ be designed and analog transmission can be made reliable _ and _ simple ! a much under - studied topic ( especially compared to the prolific literature on digital error correction codes ) , the notion of _ analog error correction codes _ , or , _ real number codes _ , actually dates back to the early 80 s , when marshall and wolf independently introduced the concept @xcite@xcite .",
    "early ideas of analog codes were a natural outgrowth of digital codes , by extending conventional digital codes from the finite field to the real - valued or complex - valued field ( i.e. symbols from a very large finite field can approximate real values ) .",
    "this has resulted in , for example , discrete fourier transform ( dft ) codes ( a subclass of which become analog bch codes and analog reed - solomon codes ) @xcite@xcite@xcite , discrete cosine transform ( dct ) codes @xcite , and graph - based analog codes @xcite .",
    "although linear codes dominate the short literature of analog codes like they do in digital codes , linear analog codes are not nearly as powerful as linear digital codes linear analog code , and it is shown that a carefully - designed _ nonlinear _ analog code can easily beat this bound @xcite . ] , and _ nonlinear _ analog codes are true cause for excitement @xcite .",
    "nonlinear analog codes rely on nonlinear transforms to encode analog data . of particular interest",
    "is _ chaotic analog codes _ ( cac ) , a special class of nonlinear aecc that make essential use of chaotic systems to transform signals .",
    "chaotic systems are nonlinear dynamical systems with bounded state spaces exhibiting a topological mixing feature @xcite .",
    "they are widely existent in the natural world and the engineering world ( e.g. climate change , mechanical vibration , acoustic signals and ecology systems are all chaotic systems ) , and many of them can be realized or emulated using simple electric circuits ( e.g. chua s circuit @xcite ) . despite the rich variety of formalities ,",
    "chaotic systems share an important common property of _ high sensitivity to the initial state_. popularly dubbed the `` butterfly effect , '' this property states that a small perturbation to the initial state of a chaotic system will cause a huge difference later on .",
    "although this butterfly effect is in general viewed as a system penalty , it can actually be cleverly exploited to satisfy the _ distance expansion _ property required by a good error correction code . specifically ,",
    "if one treats the initial state of a chaotic system as the source ( to be encoded ) , and treats some later states as the codeword ( having been encoded ) , then the chaotic system naturally enacts an error correction encoder that successfully magnifies the small differences among the source sequences ( i.e. distance expansion ) .",
    "this elegant feature was first exploited by chen and wornell in the late nineties , when they proposed the first - ever chaotic analog code , the _ tent map code _ @xcite . using a single _ tent map _",
    "( a simple one - dimension chaotic function ) as the encoder , they demonstrated the feasibility of constructing error correction codes using chaotic systems .",
    "sadly , however , their code did not perform nearly as well as digital codes , and hence the wonderful idea exposed therein slept for a decade before it was recently picked up by xie , tan , ng and li @xcite . leveraging the successful experience from digital turbo codes , i.e. building long , powerful codes by concatenating shorter , weaker codes , @xcite succeeded in constructing _",
    "chaotic analog turbo _ ( cat ) codes by parallelly concatenating two tent maps .",
    "just like turbo codes significantly outperform convolutional codes , cat codes significantly outperform tent map codes .",
    "the work of @xcite further extends the parallel concatenation idea to 2-dimension chaotic maps and proposed _ mirrored baker s map codes_. in this paper we present a further generalization of the idea of constructing a long , powerful system using a set of shorter , weaker components .",
    "the key is to carefully leverage the strength of one another to cover up their individual weaknesses .",
    "specifically , we develop a class of _ tail - biting analog codes _ ( tac ) based on 2-dimensional chaotic maps .",
    "previous work has considered a two - branch mirrored construction @xcite . here",
    "we present a constructive example that engages three branches of _ baker s maps _ in a looped tail - biting manner , and discuss its maximum - likelihood ( ml ) decoding algorithm . to support our proposal of analog image transmission",
    ", we apply our analog codes in image transmission , and compare it with the state - of - the - art digital systems ( i.e. turbo codes ) .",
    "simulations reveal a surprisingly good performance achieved by our analog codes , which , for practical purposes , is considerably better than digital turbo codes !",
    "the result is particularly exciting , considering that 1 ) the proposed analog coding system incurs considerably less complexity , memory and delay than the turbo coding system , and 2 ) turbo codes , the well - known class of capacity - approaching codes , represent the culmination of 70 years of mature digital coding research , whereas the research of analog codes is still at a very early stage .",
    "error correction is based on a simple but profound idea of _ distance expansion_. through a linear or nonlinear map ( i.e. encoding ) , the _ source space _ in which elements have relatively small separations and are therefore easily distorted , is transformed to a _ code space _ of a larger dimension , where elements have ( much ) larger separation and can therefore tolerate ( much ) larger perturbation .",
    "distance expansion is generally achieved by adding redundancy and hence incurs bandwidth expansion .",
    "an @xmath2 code that encodes a length-@xmath3 source sequence to a length-@xmath0 codeword has increased the bandwidth consumption from @xmath3 units to @xmath0 units .",
    "the code rate , defined as @xmath4 , provides a measure of the amount of bandwidth expansion .",
    "chaotic systems are described by nonlinear chaotic functions whose lyapunov exponents @xmath5 .",
    "a discrete - time chaotic function describes the time evolution of the state vector @xmath6 , @xmath7 = f(\\mathbf{z}[i-1 ] ) , \\end{aligned}\\ ] ] where @xmath8 $ ] denotes the initial state ( seed ) .",
    "a rate @xmath9 code can be realized by feeding source symbols to the chaotic function as the seed @xmath8 $ ] , and collecting @xmath10 consecutive states .",
    "the proposed tail - biting analog codes are based on 2-dimension chaotic maps , whose state vector @xmath6 has a dimension of 2 .",
    "previous chaotic analog codes , such as the tent map code proposed in @xcite and the chaotic analog turbo code proposed @xcite , are based on 1-dimension chaotic maps ( e.g. the tent map ) , and hence have an source block size of only 1 , that is , the resultant code is always an @xmath11 code which encodes one source symbol to a codeword of @xmath0 encoded symbols . from the information theory , a larger block size in general provides a richer context , a better `` diversity '' and hence a better performance .",
    "however , high - order - dimension discrete - time chaotic functions , those that have relatively simple structures and hence allow for practical detection with manageable complexity , are very difficult to find .",
    "for this reason , we resort to 2-dimension chaotic maps , and employ a looped tail - biting structure to connect them .",
    "that is , we can take @xmath3 branches of 2-dimension chaotic map , take a block of @xmath3 source symbols , @xmath12 , and feed the source symbols as initial states to the @xmath3 branches : @xmath13    below we detail an example of triple branches .",
    "in what follows , we will use regular fonts to denote scalars ( e.g. @xmath14 ) , and bold fonts to denote vectors and matrices ( e.g. @xmath15 ) .",
    "@xmath16 denotes the vector @xmath17 , x_1[m\\!+\\!1 ] , \\cdots , x_1[l])$ ] , and @xmath15 is short for @xmath18 .",
    "we consider using folded baker s map , a simple , 2-dimension chaotic map from a unit square to itself , as the base function .",
    "the baker s map is named after a kneading operation that bakers apply to dough : the dough is cut in half , and one half is folded over and stacked on the other , and compressed .",
    "it is nonlinear but piece - wise linear , and presents a 2-dimension analogy of the tent map : @xmath19,y[i]\\ } \\nonumber\\\\   = & f(\\,\\{x[i\\!-\\!1],y[i\\!-\\!1]\\}\\ , ) \\nonumber \\\\ = & \\left\\{\\!\\!\\!\\ ! \\begin{array}{ll } \\ { 2x[i\\!-\\!1]\\!+\\!1 , \\ , ( y[i\\!-\\!1]\\!-\\!1)/2\\ } , & \\mbox{if\\ } -\\!1\\!\\le\\ !",
    "\\\\   \\{1\\!-\\!2x[i\\!-\\!1 ] , \\ , ( 1\\!-\\!y[i\\!-\\!1])/2\\ } , & \\mbox{if\\ } 0\\!\\le \\ ! x[i\\!-\\!1]\\!\\le \\!1 \\end{array }",
    "\\right.\\label{eqn : baker_func0}\\end{aligned}\\ ] ]    now consider building analog codes by engaging three baker s maps in a looped tail - biting manner , as shown in fig .",
    "[ fig:3branchbaker ] .",
    "a block of three real - valued symbols ( e.g. pixels in an image ) , @xmath20 , is paired and fed into the three branches as the initial states : @xmath21 , @xmath22 and @xmath23 .",
    "each branch encoder recursively performs the baker s map @xmath24 in ( [ eqn : baker_func0 ] ) , to generate additional @xmath10 pairs of states ( in addition to the initial states ) : @xmath25,y_{j}[i]\\ } = & f(\\{x_{j}[i\\!-\\!1],y_{j}[i\\!-\\!1]\\})\\nonumber \\\\ = & f^{i}(\\{x_{j}[0],y_{j}[0]\\ } ) ,   \\label{eqn : baker_recursive}\\end{aligned}\\ ] ] where the subscript @xmath26 denotes the @xmath27th branch , and @xmath28 denotes the time index of the states .",
    "the collection of all the states from @xmath29 to @xmath10 , @xmath30 , @xmath31 and @xmath32 , forms the sub - codeword for the first , second , and third branch , respectively .",
    "altogether @xmath33 symbols are generated symbols include two copies of the source symbols @xmath34 .",
    "it is also possible to transmit the systematic symbols only once , which will lead to a codeword of @xmath35 symbols and code rate @xmath36 .",
    "] , corresponding to the three source symbols @xmath37 .",
    "hence , the code is a @xmath38 systematic code with a rate of @xmath39 .",
    "the codewords are transmitted through the noisy channel .",
    "each analog symbol takes value from -1 to 1 , and is modulated as variations in the amplitude of a carrier wave , in a way similar to digital amplitude shift keying ( ask ) .",
    "the only difference is that an @xmath40-ary ask only allows a fixed set of @xmath40 discrete amplitude values to be valid ( e.g. @xmath41 , @xmath42 , @xmath43 and @xmath44 for 4-ary ask ) , whereas in this _ continuous ask _ ( cask ) , amplitudes may be any real value between @xmath41 and @xmath44 .",
    "hence , our cask may be regarded as an @xmath45-ary ask .    from the communication theory , two",
    "@xmath40-array ask modulations can be packed to form a @xmath46-ary quadrature amplitude modulation ( qam ) . when the two carrier waves use sinusoids that are out of phase with each other by @xmath47 ( termed @xmath48-channel and @xmath49-channel respectively ) , then the @xmath46-ary qam achieves twice the data rate ( @xmath50 bits / symbol ) on the same bandwidth as a single @xmath40-ary ask .",
    "likewise , we can also pack two cask to form a _ continuous qam _ ( cqam ) to double our data rate . from the perspective of signal space , this is to take two of our real - valued symbols to form a complex - valued symbol , and projected it onto an @xmath45-ary qam .",
    "mathematically , the noisy reception at the decoder is : @xmath51 where @xmath52 and @xmath53 are noise sequences .",
    "if we adopt the additive white gaussian noise ( awgn ) channel model , then these noise samples follow independent and identically distributed ( i.i.d . )",
    "gaussian distribution @xmath54 .      when two copies of the systematic symbols , @xmath55\\!=\\!y_3[0]\\!=\\!u_1 $ ] , @xmath56\\!=\\!y_1[0]\\!=\\!u_2 $ ] , @xmath57\\!=\\!y_2[0]\\!=\\!u_3 $ ] , are transmitted , it is advisable to first perform maximum ratio combining ( mrc ) before proceeding to the actual decoding . on a homogeneous channel such as awgn channel , mrc is equivalent to equal gain combining ( egc ) : @xmath58= ry'_{3}[0]=   \\frac{rx_{1}[0]+ry_{3}[0]}{2},\\\\ rx'_{2}[0]=ry'_1[0]= \\frac { rx_{2}[0]+ry_{1}[0]}{2 } , \\\\",
    "rx'_{3}[0]=ry'_2[0]= \\frac { rx_{3}[0]+ry_{2}[0]}{2},\\end{aligned}\\ ] ] where the apostrophe @xmath59 denotes the symbols after mrc .",
    "for convenience , we abuse the notation , and omit the apostrophe in @xmath60 $ ] and @xmath61 $ ] in the following discussion .",
    "the maximum - likelihood decoder tries to make the best decision of the initial states , @xmath62 , based on the noisy observation of a sequence of states . from the definition of baker s map in ( [ eqn : baker_func0 ] ) , a later @xmath63-state @xmath64 $ ]",
    "can be deduced unequivocally from a previous one @xmath65 $ ] , but not the other way around ; and the same holds for the @xmath66-states .",
    "the ambiguity in the backward derivation is caused by the unknown sign of the previous @xmath63-state @xmath67 $ ] .",
    "hence , to facilitate decoding , we introduce a sign sequence @xmath68 for @xmath69 ( the signs of @xmath70 are irrelevant ) : @xmath71=sign(x_j[i ] ) , \\ \\",
    "i\\!=\\!0,1, ... ,n\\!-\\!1,\\ \\ j\\!=\\!1,2,3.\\end{aligned}\\ ] ]    with the sign sequence established , we can establish a one - to - one mapping between @xmath64 $ ] and @xmath72 $ ] and between @xmath73 $ ] and @xmath74 $ ] @xmath75= -\\frac{1}{2}s_j[i\\!-\\!1](x_j[i]-1 ) , \\\\",
    "\\end{array } \\right.\\end{aligned}\\ ] ]    recall that the baker s map is a piece - wise linear function . with each time evolution ,",
    "the number of segments doubles , but linearity preserves within each ( new ) segment .",
    "hence , one can rewrite the encoding function in ( [ eqn : baker_func0 ] ) by directly establishing a linear relation between the @xmath76th state @xmath77,y_{j}[i]\\}$ ] with the initial state @xmath78,y_{j}[0]\\}$ ] in each segment : @xmath79 = a_{j}[i]x_{j}[0]+b_{j}[i],\\\\ y_{j}[i ] = c_{j}[i]y_{j}[0]+d_{j}[i ] , \\end{array } \\right .",
    "\\label{eqn : linear}\\end{aligned}\\ ] ] in general , the values of the parameters @xmath80,b_j[i],c_j[i],d_j[i]$ ] not only depend on the time index @xmath76 but also on which segment @xmath64 $ ] and @xmath73 $ ] fall in .",
    "observe that the sign sequence @xmath68 actually serves as the natural label for all the segments , namely , @xmath81\\in\\{-1,+1\\}$ ] specifies the two segments at time index @xmath82 , @xmath83s_j[1])\\in\\{-1 - 1,-1 + 1,+1 - 1,+1 + 1\\}$ ] specifies the four segments at time index @xmath84 , and so on .",
    "thus , carefully arranging the sign sequence , we can derive the parameters @xmath80,b_j[i],c_j[i],d_j[i]$ ] in a unified recursive form across all the segments : @xmath85   =   -2s_{j}[i\\!-\\!1]a_{j}[i\\!-\\!1],\\\\ b_{j}[i ]   =   1 - 2s_{j}[i\\!-\\!1]b_{j}[i\\!-\\!1],\\\\ c_{j}[i ]   =   - 0.5\\ , s_{j}[i\\!-\\!1]c_{j}[i\\!-\\!1],\\\\ d_{j}[i ] =   0.5\\ , ( s_{j}[i\\!-\\!1]-s_{j}d_{j}[i\\!-\\!1]),\\\\ \\end{array } \\right .",
    "\\label{eqn : abcd}\\end{aligned}\\ ] ]    given the linear relation in ( [ eqn : linear ] ) and ( [ eqn : abcd ] ) , an efficient ml decoding can be derived to obtain an estimation of the information bits @xmath86 .",
    "@xmath87\\mid u_1 ) \\pr\\big(ry_{1}[i ] \\mid u_2\\big)\\nonumber \\\\ & \\ \\ \\ \\ \\ \\   \\ \\ \\ \\ \\ \\ \\",
    "\\cdot    \\pr\\big(rx_{2}[i]\\mid u_2 ) \\pr\\big(ry_{2}[i ] \\mid u_3\\big ) \\nonumber \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\",
    "\\cdot \\pr\\big(rx_{3}[i]\\mid u_3\\big ) \\pr\\big(ry_{3}[i ] \\mid u_1 \\big)\\big\\ } \\label{eqn : ml_1 } \\\\ = &   \\underset{-1\\leq u_{1},u_{2},u_{3}\\leq 1}{\\arg\\min }   \\sum_{i=0}^{n-1}\\big\\ { \\big(rx_{1}[i]\\!-\\!x_{1}[i]\\big)^2 \\!+\\ ! ( ry_{1}[i]\\!-\\!y_{1}[i]\\big)^2 \\nonumber \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ + \\big ( rx_{2}[i]\\!-\\!x_{2}[i]\\big)^2 \\!+\\ ! ( ry_{2}[i]\\!-\\!y_{2}[i]\\big)^2 \\nonumber \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ + \\big ( rx_{3}[i]\\!-\\!x_{3}[i]\\big)^2 \\!+\\ ! \\big(ry_{3}[i]\\!-\\!y_{3}[i]\\big)^2   \\big\\ } , \\label{eqn : ml}\\end{aligned}\\ ] ] where the equality in ( [ eqn : ml_1 ] ) is due to the independence of the noise ( i.e. memoryless channel ) , and the equality in ( [ eqn : ml ] ) is due to the gaussianity of the noise . using the segmented linear function expressions in ( [ eqn : linear ] ) and noting that @xmath55=y_3[0]=u_1 $ ] , @xmath56=y_1[0]=u_2 $ ] , and @xmath57=y_2[0]=u_3 $ ] , we can further simplify ( [ eqn : ml ] ) to : @xmath88\\!-\\!a_{1}[i]u_{1}\\!-\\!b_{1}[i]\\big)^{2 } + \\big(ry_{1}[i]\\!-\\!c_{1}[i]u_{2}\\!-\\!d_{1}[i]\\big)^{2 }   \\nonumber \\\\ & \\big(rx_{2}[i]\\!-\\!a_{2}[i]u_{2}\\!-\\!b_{2}[i]\\big)^{2 } + \\big(ry_{1}[i]\\!-\\!c_{2}[i]u_{3}\\!-\\!d_{2}[i]\\big)^{2 }   \\nonumber \\\\ & \\big(rx_{3}[i]\\!-\\!a_{3}[i]u_{3}\\!-\\!b_{3}[i]\\big)^{2 } + \\big(ry_{3}[i]\\!-\\!c_{3}[i]u_{1}\\!-\\!d_{3}[i]\\big)^{2 }   \\big\\ } \\label{eqn : ml_2}\\end{aligned}\\ ] ] where the parameters @xmath80,b_{j}[i ] , c_{j}[i],d_{j}[i]$ ] are given in ( [ eqn : abcd ] ) .",
    "the quadratic minimization problem in ( [ eqn : ml_2 ] ) can be solved by taking the derivatives with respect to @xmath89 , @xmath90 and @xmath91 , respectively .",
    "the `` global '' optimal solutions @xmath92 , @xmath93 and @xmath94 that minimize ( [ eqn : ml_2 ] ) are : @xmath95a_{1}[i]\\!+\\!ry_{3}[i]c_{3}[i]\\!-\\!a_{1}[i]b_{1}[i]\\!-\\!c_{3}[i]d_{3}[i])}{\\sum_{i=0}^{n-1}(a_{1}^{2}[i]+c_{3}^{2}[i])}\\nonumber\\\\ u_{2}^{\\ast } \\ ! = \\ !",
    "\\frac{\\sum_{i=0}^{n-1}(rx_{2}[i]a_{2}[i]\\!+\\!ry_{1}[i]c_{1}[i]\\!-\\!a_{2}[i]b_{2}[i]\\!-\\!c_{1}[i]d_{1}[i])}{\\sum_{i=0}^{n-1}(a_{2}^{2}[i]+c_{1}^{2}[i])}\\nonumber\\\\ u_{3}^{\\ast } \\!=\\ !",
    "\\frac{\\sum_{i=0}^{n-1}(rx_{3}[i]a_{3}[i]\\!+\\!ry_{2}[i]c_{2}[i]\\!-\\!a_{3}[i]b_{3}[i]\\!-\\!c_{2}[i]d_{2}[i])}{\\sum_{i=0}^{n-1}(a_{3}^{2}[i]+c_{2}^{2}[i ] ) } % \\end{array } % \\right .",
    "\\label{eqn : mlresult1}\\end{aligned}\\ ] ]    it should be noted that the `` global '' optimal decisions @xmath96 in ( [ eqn : mlresult1 ] ) are not always the feasible solution , since they may fall outside the support range , i.e. the respective linear segment of length @xmath97 . to account for the boundary conditions , note that , for @xmath26 , @xmath98=a_{j}[n-1]u_{j}\\!+\\!b_{j}[n-1]\\le 1,\\ ] ] which leads to @xmath99\\!+\\!1}{a_{j}[n\\!-\\!1 ] } , \\",
    "\\frac{-\\!b_{j}[n\\!-\\!1]\\!-\\!1}{a_{j}[n\\!-\\!1]}\\right ) \\le    u_j \\nonumber \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\le   \\max\\left(\\frac{-\\!b_{j}[n\\!-\\!1]\\!+\\!1}{a_{j}[n\\!-\\!1 ] } , \\frac{-b_{j}[n\\!-\\!1]\\!-\\!1}{a_{j}[n\\!-\\!1]}\\right ) .",
    "\\label{eqn : boundary}\\end{aligned}\\ ] ] combining the quadratic minimal solution in ( [ eqn : mlresult1 ] ) and the boundary solution in ( [ eqn : boundary ] ) , the ml decoder will produce the following decision : @xmath100 + 1}{a_{j}[n-1 ] } ,   \\frac{-b_{j}[n-1]-1}{a_{j}[n-1]}\\big ) , \\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\mbox{if\\ } u_{j}^{\\ast}\\!\\!<\\!\\!\\min\\big(\\frac{-b_{j}[n-1]+1}{a_{j}[n-1]},\\frac{-b_{j}[n-1]-1}{a_{j}[n-1]}\\big ) , \\\\",
    "\\max\\big(\\frac{-b_{j}[n-1]+1}{a_{j}[n-1 ] } , \\frac{-b_{j}[n-1]-1}{a_{j}[n-1]}\\big),\\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\    \\mbox{if\\ } u_{j}^{\\ast}\\!\\!>\\!\\!\\max\\big(\\frac{-b_{j}[n-1]+1}{a_{j}[n-1]},\\frac{-b_{j}[n-1]-1}{a_{j}[n-1]}\\big ) , \\\\ u_{j}^{\\ast } ,   \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   \\ \\mbox{otherwise } , \\end{array } \\right.\\nonumber\\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   \\mbox{for\\ } j=1,2,3 .",
    "\\label{eqn : mlresult2}\\end{aligned}\\ ] ]",
    "analog codes are most useful for transmitting analog sources as shown in fig .",
    "[ fig : analogdigital ] , but they can also be used to transmit digital data , and especially digitized images .    to illustrate , consider a monochrome image , the @xmath101 ( pixel ) lena , where each pixel is represented by a byte valued between 0 and 255 . in the conventional digital transmission paradigm ,",
    "all the bits are assembled into a bit - stream ( @xmath102 bits altogether ) , and digitally coded and modulated . in the proposed analog transmission paradigm",
    ", the pixels are viewed as stream of real - valued analog symbols ( @xmath103 symbols in the range of @xmath104 $ ] , i.e. each pixel @xmath105 is linearly scaled to @xmath104 $ ] via @xmath106 ) , and then coded by an analog code .",
    "we simulate and compare the analog system with some of the best - known digital systems : 1 ) .",
    "the analog system consists of the proposed @xmath107 3-branch tail - biting baker s map code with code rate 1/4 .",
    "the encoded symbols are transmitted via the continuous ask modulation ( @xmath108 total symbols ) .    2 ) .",
    "the digital system consists of a digital turbo code , one of the best error correction codes known to date , and the ask modulation .",
    "we consider @xmath109 16-state turbo codes with constituent convolutional codes @xmath110 and code rate 1/2 , and 16-ary ask .",
    "thus , with the default 8-bit quantization per pixel , the overall bandwidth expansion is @xmath111 , which is the same as the analog system ( i.e. @xmath112 symbols ) . at the decoder ,",
    "the 16-ary ask is softly demodulated , and the resultant log - likelihood ration ( llr ) is passed to the soft iterative turbo decoder which uses the bcjr algorithm as the sub - decoders .",
    "six iterations are performed before the decoder outputs hard decisions .",
    "the transmission quality is evaluated using the mean square error ( mse ) between the original @xmath113 monochrome image @xmath48 and the reconstructed image @xmath114 , @xmath115 as well as the peak signal - to - noise ratio ( psnr ) , @xmath116 where @xmath117 is the maximum possible pixel value of the image ( e.g. 255 for 8-bit quantized monochrome images ) .",
    "[ fig : psnr ] plots the psnr performance ( db ) of the digital system and the analog system on awgn channels with signal - to - noise ratio ( snr ) measured in terms of @xmath118 ( db ) , where @xmath119 is the average energy per pixel in the original image .",
    "because of the bandwidth expansion in digital system ( 1 pixel becomes 8 bits ) , the digital turbo code can not get to its waterfall region until after a rather high @xmath118 of @xmath120 db . as a consequence",
    ", the proposed analog code noticeably outperforms the digital turbo code for a wide range of channel conditions . in general , a psnr of 30 db or more is reckoned as good quality image .",
    "this is achieved by the analog system at @xmath121 db , but is not achieved by the digital system until @xmath122 db !        to provide a visual feel of the transmission quality , fig .",
    "[ fig : lena ] further demonstrates the reconstructed images for the two systems at @xmath118 of 10 , 14 , 18 , 22 and 24 db , respectively .",
    "we see that the digital system ( right column ) still experiences annoying pepper - and - slat errors at a high @xmath118 of 22 db , whereas the analog system ( left column ) can deliver quality image for as low as 14 db .",
    "the advantages of the analog system are rather obvious , including the capability of delivering good quality on poor channel conditions , graceful performance degradation , and considerably lower complexity .",
    "the last is particularly noteworthy . in the digital system , soft - demodulation and soft turbo decoding are both very complex and time - consuming , and involve nonlinear operations ( e.g. the @xmath123 operation in the bcjr decoding ) . in comparison , the proposed analog code entails only a few simple linear operations .",
    "further , the digital turbo code has a considerably longer block length ( 2048 bits or 256 pixels ) than the analog system ( 3 pixels ) , and hence requires considerably longer memory consumption and delay .",
    "our simulations are currently run over raw or tiff ( tagged image file format ) images , a popular lossless format especially for high color - depth images .",
    "although many consumer electronics use lossy jpeg format , raw images which allow editing and re - saving without losing image quality play an important role in image archive and especially in bio - medical applications .",
    "further , the proposed analog codes can also be extended to compressed images , as there is no fundamental conflict between analog error correction coding and compression .",
    "for example , in a jpeg image , the dct ( discrete cosine transform ) coefficients ( which are by nature real - valued ) are each represented as a binary bit stream in the digital coding systems ; but they can be directly taken in as analog symbols in the analog coding systems .",
    "analog coding can also provide data accuracy as required ; for example , if an analog code operating on sources bounded between @xmath104 $ ] can provide an mse @xmath124 , then it can on average guarantee the accuracy of @xmath125 binary bits after the decimal .",
    "hence , with careful arrangement , analog coding schemes can also find good use in transmitting compressed images ( including the control data and the efficients ) .",
    "we have developed an efficient triple - branch tail - biting baker s map analog code . using a simple linear - operation - based maximum likelihood decoding scheme ,",
    "we apply the code to image transmission , and show that , despite its considerably lower complexity , memory consumption and delay , the analog code actually significantly outperforms turbo - code - based digital systems ! we conclude by promoting analog coding as a new and potentially very rewarding technology for transmitting images as well as other analog sources .",
    "( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ]   ( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ] +   ( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ]   ( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ] +   ( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ]   ( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ] +   ( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ]   ( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ] +   ( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ]   ( pixel ) lena picture by the proposed analog code ( left ) and the digital turbo code ( right ) , for @xmath126 at @xmath127 , @xmath128 , @xmath129 , @xmath120 and @xmath130 db ( from top to bottom ) .",
    "@xmath119 stands for energy per pixel .",
    "both systems have a bandwidth expansion of @xmath131.,title=\"fig : \" ]"
  ],
  "abstract_text": [
    "<S> this paper presents a new paradigm for image transmission through analog error correction codes . </S>",
    "<S> conventional schemes rely on digitizing images through quantization ( which inevitably causes significant bandwidth expansion ) and transmitting binary bit - streams through digital error correction codes ( which do not automatically differentiate the different levels of significance among the bits ) . </S>",
    "<S> to strike a better overall performance in terms of transmission efficiency and quality , we propose to use a single analog error correction code in lieu of digital quantization , digital code and digital modulation . </S>",
    "<S> the key is to get analog coding right . </S>",
    "<S> we show that this can be achieved by cleverly exploiting an elegant `` butterfly '' property of chaotic systems . specifically , we demonstrate a tail - biting triple - branch baker s map code and its maximum - likelihood decoding algorithm . </S>",
    "<S> simulations show that the proposed analog code can actually outperform digital turbo code , one of the best codes known to date ! the results and findings discussed in this paper speak volume for the promising potential of analog codes , in spite of their rather short history . </S>"
  ]
}