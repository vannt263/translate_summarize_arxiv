{
  "article_text": [
    "simulation is inevitable in studying the evolution of complex cellular systems .",
    "large cellular array simulations might require long runs on a serial computer .",
    "parallel processing , wherein each cell or a group of cells is hosted by a separate processing element ( pe ) , is a feasible method to speed up the runs .",
    "the strategy of a parallel simulation should depend on whether the simulated system is synchronous or asynchronous .",
    "a _ synchronous _ system evolves in discrete time @xmath1 .",
    "the state of a cell at @xmath2 is determined by the state of the cell and its neighbors at @xmath3 and may explicitly depend on @xmath3 and the result of a random experiment .    an obvious and correct way to simulate the system synchrony using a parallel processor",
    "is simply to mimic it by the executional synchrony .",
    "the simulation is arranged in rounds with one round corresponding to one time step and with no pe processing state changes of its cells for time @xmath2 before all pes have processed state changes of their cells for time @xmath3 .",
    "an _ asynchronous _ system evolves in continuous time .",
    "state changes at different cells occur asynchronously at unpredictable random times . here",
    "two questions should be answered : ( a ) how to specify the asynchrony precisely ? and ( b ) how to carry out the parallel simulations for the specified asynchrony ?    unlike the synchronous case , simple mimicry does not work well in the asynchronous case .",
    "when geman and geman @xcite , for example , employ executional _ physical _ asynchrony ( introduced by different speeds of different pes ) to mimic the model asynchrony , the simulation becomes irreproducible with its results depending on executional timing .",
    "such dependence may be tolerable in tasks other than simulation ( @xcite describes one such task , another example is given in @xcite ) .",
    "in the task of simulation , however , it is a serious shortcoming as seen in the following example .",
    "suppose a simulationist , after observing the results of a program run , wishes to look closer at a certain phenomenon and inserts an additional ` print ' statement into the code . as a result of the insertion , the executional timing changes and the phenomenon under investigation vanishes .",
    "ingerson and buvel @xcite and hofmann @xcite propose various reproducible computational procedures to simulate asynchronies in cellular arrays .",
    "however no uniform principle has been proposed , and no special attention to developing parallel algorithms has been paid .",
    "it has been observed that the resulting cellular patterns may depend on the computational procedure @xcite .",
    "two main results of this paper are : ( i ) a definition of a natural class of asynchronies that can be associated with cellular arrays and ( ii ) efficient parallel algorithms to simulate systems in this class .",
    "the following properties specify the _ poisson asynchrony _ , a most common member in the introduced class : +   + @xmath4arrivals for a particular cell form a poisson point process .",
    "+ @xmath4arrivals processes for different cells are independent .",
    "+ @xmath4the arrival rate is the same , say @xmath5 , for each cell .",
    "+ @xmath4when there is an arrival , the state of the cell instantaneously changes ; the new state is computed based on the states of the cell and its neighbors just before the change ( in the same manner as in the synchronous model ) .",
    "the new state may be equal to the old one .",
    "+ @xmath4the time of arrival and a random experiment may be involved in the computation . +",
    "a familiar example of a cellular system with the poisson asynchrony is the ising model @xcite in the continuous time formulation of glauber @xcite . in this model",
    "a cell configuration is defined by the spin variables @xmath6 specified at the cells @xmath7 of a two or three dimensional array .",
    "when there is an arrival at a cell @xmath7 , the spin @xmath8 is changed to @xmath9 with probability @xmath10 . with probability @xmath11 ,",
    "the spin @xmath8 remains unchanged .",
    "the probability @xmath10 is determined using the values of @xmath8 and neighbors @xmath12 just before the update time .",
    "it is instructive to review the computational procedures for ising simulations .",
    "first , the ising simulationists realized that the standard procedure by metropolis , rosenbluth , rosenbluth , teller , and teller @xcite could be applied . in this procedure , the evolution of the configuration is simulated as a sequence of one - spin updates : given a configuration , define the next configuration by choosing a cell @xmath7 uniformly at random and changing or not changing the spin @xmath8 to @xmath9 as required . in the original standard procedure time",
    "is discrete .",
    "time continuity could have been simply introduced by letting the consecutive arrivals form the poisson process with rate @xmath13 , where @xmath14 is the total number of spins ( cells ) in the system .",
    "the problem of long simulation runs became immediately apparent .",
    "bortz , kalos , and lebowitz @xcite developed a serial algorithm ( the bkl algorithm ) which avoids processing unsuccessful state change attempts , and reported up to a 10-fold speed - up over the straight - forward implementation of the standard model .",
    "ogielski @xcite built special purpose hardware for speeding up the processing .",
    "the bkl algorithm is serial .",
    "attempts were made to speed up the ising simulation by parallel computations ( friedberg and cameron @xcite , creutz @xcite ) .",
    "however , in these computations the original markov chain of the continuous time ising model was modified to satisfy the computational procedure .",
    "the modifications do not affect the equilibrium behavior of the chain , and as such are acceptable if one studies only the equilibrium .",
    "in the cellular models however , the transient behavior is also of interest , and no model revision should be done .",
    "this paper presents efficient methods for parallel simulation of the continuous time asynchronous cellular arrays without changing the model or type of asynchrony in favor of the computational procedure .",
    "the methods promise unlimited speed - up when the array and the parallel computer are sufficiently large . for the poisson asynchrony case",
    ", it is also shown how the bkl algorithm can be incorporated , further contributing to speed - up .",
    "for the ising model , presented algorithms can be viewed as exact parallel counterparts to the standard algorithm by metropolis et al . the latter has been known and believed to be inherently serial since 1953 .",
    "yet , the presented algorithms are parallel , efficient , and fairly simple .",
    "the `` conceptual level '' codes are rather short ( see figures  [ fig : a1c1pe ] , [ fig : s1c1pe ] , [ fig : amcgen ] , [ fig : amcpoi ] , and [ fig : genout ] , ) .",
    "an implementation in a real programming language given in the appendix is longer , of course , but still rather simple .",
    "this paper is organized as follows : section [ sec : model ] presents a class of asynchronies and a comparison with other published proposals .",
    "then section [ sec : algo ] describes the new algorithms on the conceptual level .",
    "while the presented algorithms are simple , there is no simple theory which predicts speed - up of these algorithms for cellular arrays and parallel processors of large sizes .",
    "section [ sec : perf ] contains a simplified computational procedure which predicts speed - ups faster than it takes to run an actual parallel program .",
    "the predictions made by this procedure are compared with actual runs and appear to be rather accurate .",
    "the procedure predicts speed - up of more than 8000 for the simulation of @xmath15 poisson asynchronous cellular array in parallel by @xmath16 pes .",
    "actual speed - ups obtained thus far were : more than 16 on 25 pes of the balance ( tm ) computer and more than 1900 on @xmath0 pes of the connection machine ( r ) .",
    "time @xmath3 is continuous .",
    "each cell @xmath7 has a state @xmath17 . at random times , a cell is granted a chance to change the state . the changes , if they occur , are instantaneous events .",
    "random attempts to change the state of a cell are independent of similar attempts for other cells .",
    "the general model consists of two functions : _",
    "time_of_next_arrival ( ) _ and _ next_state ( ) _ .",
    "they are defined as follows : given the old state of the cell and the states of the neighbors just before time @xmath3 , @xmath18 , the next_state @xmath19 is @xmath20 where the possibility @xmath21 is not excluded ; and the time @xmath22 of the next arrival is @xmath23 where always @xmath24 .    in and , @xmath25 denotes the result of a random experiment , e.g. , coin tossing , @xmath26 denotes the indexed set of states of all the neighbors of @xmath7 including @xmath7 itself .",
    "thus , if @xmath27 , then @xmath28 .",
    "subscript @xmath29 expresses the idea of ` just before @xmath3 ' , e.g. , @xmath30 .",
    "according to , the value of @xmath8 instantaneously changes at time @xmath3 from @xmath31 to @xmath32 . at time @xmath3",
    ", the value of @xmath8 is already new .",
    "the ` just before ' feature resolves a possible ambiguity if two neighbors attempt to change their states at the same simulated time .",
    "compare now the class of asynchronies defined by with the ones proposed in the literature :    ( a ) model 1 in @xcite reads : `` ... the cells iterate randomly , one at a time . ''",
    "let @xmath33 be the probability that cell @xmath7 is chosen .",
    "then the following choice of law yields this model @xmath34 where @xmath35 is a random number uniformly distributed on ( 0,1 ) , and @xmath36 is the natural logarithm , @xmath37 . for @xmath38 , the asynchrony was called the _ poisson asynchrony _ in section  [ sec : intro ] ; it coincides with the one defined by the standard model @xcite , and by glauber s model @xcite for the ising spin simulations .",
    "( b ) model 2 in @xcite assigns `` each cell a period according to a gaussian distribution ...",
    "the cells iterate one at a time each having its own definite period . '' while it is not quite clear from @xcite what is meant by a `` definite period '' ( is it fixed for a cell over a simulation run ? ) , the following choice of law yields this model in a liberal interpretation : @xmath39 where @xmath40 if @xmath41 , and @xmath42 is the cumulative function for the gaussian probability distribution with mean @xmath43 and variance @xmath44 .",
    "the probability of @xmath45 is small when @xmath46 and is ignored in @xcite if this interpretation is meant . in a less liberal interpretation ,",
    "@xmath47 for all @xmath7 , and @xmath48 is itself random and distributed according to the gaussian law .",
    "this case is even easier to represent in terms of model than the previous one : @xmath49 .",
    "( 3 ) model trivially extends to a synchronous simulation , where the initial state changes arrive at time 0 and then always @xmath50 is identical to 1 .",
    "the first model in @xcite is `` to choose a number of cells at random and change only their values before continuing . ''",
    "this is a variant of synchronous simulation ; it is substantially different from both models ( a ) and ( b ) above . in ( a ) and ( b )",
    ", the probability is 1 that no two neighbors attempt to change their states at the same time . in contrast , in this model many neighboring cells are simultaneously changing their values . how the cells are chosen for update is not precisely specified in @xcite .",
    "one way to choose the cells is to assign a probability weight @xmath33 for cell @xmath7 , @xmath51 , and to attempt to update cell @xmath7 at each iteration , with probability @xmath33 , independent of any other decision .",
    "such a method conforms with the law because the method is local : a cell does not need to know what is happening at distant cells . the second model in @xcite changes states of a fixed number @xmath52 of randomly chosen cells at each iteration .",
    "if @xmath53 , this method is not local and does not conform with the law .",
    "deterministic computers represent randomness by using pseudo - random number generators .",
    "thus , equations and are substituted in the computation by equations @xmath54 and @xmath55 respectively , which do not contain the parameter of randomness @xmath25 .",
    "this elimination of @xmath25 symbolizes an obvious but important difference between the simulated system and the simulator : in the simulated system , the observer , being a part of the system , does not know in advance the time of the next arrival .",
    "in contrast , the simulationist who is , of course , not a part of the simulated system , can know the time of the next arrival before the next arrival is processed .",
    "for example , it is not known in advance when the next event from a poisson stream arrives . however , in the simulation , the time @xmath22 of the next arrival is obtained in a deterministic manner , given the time @xmath3 of the previous arrival : @xmath56 where @xmath5 is the rate , @xmath57 is the @xmath58-th pseudo - random number in the sequence uniformly distributed on @xmath59 , and @xmath60 is the invocation counter .",
    "thus , after the previous arrival is processed , the time of the next arrival is already known .",
    "if needed , the entire sequence of arrivals can be precomputed and stored in a table for later use in the simulation , so that all future arrival times would be known in advance . + * asynchronous one - cell - per - one - pe algorithm*. the algorithm in figure  [ fig : a1c1pe ] is the shortest of those presented in this paper .    to understand this code , imagine a parallel computer which consists of a number of pes running concurrently .",
    "one pe is assigned to simulate one cell .",
    "the pe which is assigned to simulate cell @xmath61 , pe@xmath61 , executes the code in figure  [ fig : a1c1pe ] with @xmath62 .",
    "the pes are interconnected by the network which matches the topology of the cellular array .",
    "a pe can receive information from its neighbors .",
    "pe@xmath7 maintains state @xmath8 and local simulated time @xmath63 .",
    "variables @xmath63 and @xmath8 are visible ( accessible for reading only ) by the neighbors of @xmath7 .",
    "time @xmath63 has no connection with the physical time in which the parallel computer runs the program except that @xmath63 may not decrease when the physical time increases . at a given physical instance of simulation , different cells @xmath7 may have different values of @xmath63 .",
    "value @xmath64 is a constant which is known to all pes .",
    "the algorithm in figure  [ fig : a1c1pe ] is very asynchronous : different pes can execute different steps concurrently and can run at different speeds . a statement ` wait_until  _ condition _ ' ,",
    "like the one at step 2 in figure  [ fig : a1c1pe ] , does not imply that the _ condition _ must be detected immediately after it occurs . to detect the _ condition _ at step 2 involving local times of neighbors",
    "a pe can poll its neighbors one at a time , in any order , with arbitrary delays , and without any respect to what these pes are doing meanwhile . +    despite being seemingly almost chaotic , the algorithm in figure  [ fig : a1c1pe ] is free from deadlock .",
    "moreover , it produces a unique simulated trajectory which is independent of executional timing , provided that : + ( i ) for the same cell , the pseudo - random sequence is always the same , + ( ii ) no two neighboring arrival times are equal . + freedom from deadlock follows from the fact that the cell , whose local time is minimal over the entire array , is always able to make progress .",
    "( this guaranteed worst case performance , is substantially exceeded in an average case .",
    "see section  [ sec : perf ] . )",
    "the uniqueness of the trajectory can be seen as follows . by ( ii ) , a cell @xmath7 passes the test at step 2 only if its local time @xmath63 is smaller than the local time @xmath65 of any its neighbor @xmath66 .",
    "if this is the case , then no neighbor @xmath66 is able to pass the test at step 2 before @xmath7 changes its time at step 4 .",
    "this means that processing of the update by @xmath7 is safe : no neighbor changes its state or time before @xmath7 completes the processing . by ( i ) , functions @xmath67 and @xmath68 are independent of the run .",
    "therefore , in each program run , no matter what the neighbors of @xmath7 are doing or trying to do , the next arrival time and state for @xmath7 are always the same .",
    "it is now clear why assumption ( ii ) is needed .",
    "if ( ii ) is violated by two cells @xmath7 and @xmath66 which are neighbors , then the algorithm in figure  [ fig : a1c1pe ] does not exclude concurrent updating by @xmath7 and @xmath66 . such concurrent updating introduces an indeterminism and inconsistency .",
    "a scenario of the inconsistency can be as follows : at step 3 the _ old _ value of @xmath12 is used to update state @xmath8 , but immediately following step 4 uses the _",
    "new _ value of @xmath12 to update time @xmath63 .    in practice ,",
    "the algorithm in figure  [ fig : a1c1pe ] is safe , when @xmath69 for different @xmath7 are independent random samples from a distribution with a continuous density , like an exponential distribution . in this case",
    ", ( ii ) holds with probability 1 .",
    "unless the pseudo - random number generators are faulty , one may imagine only one reason for violating ( ii ) : finite precision of computer representation of real numbers .",
    "+ * synchronous one - cell - per - one - pe algorithm*. if ( ii ) can be violated with a positive probability ( if @xmath3 takes on only integer values , for example ) , then the errors might not be tolerable . in this case the synchronous algorithm in figure  [ fig : s1c1pe ] should be used .",
    "observe that while the algorithm in figure  [ fig : s1c1pe ] is synchronous , it is able to simulate correctly both synchronous and asynchronous systems",
    ". two main additions in the algorithm in figure  [ fig : s1c1pe ] are : private variables @xmath70 and @xmath71 for temporal storage of updated @xmath72 and @xmath3 , and synchronization barriers ` synchronize ' .",
    "when a pe hits a ` synchronize ' statement it must wait until all the other pes hit a ` synchronize ' statement ; then it may resume .",
    "two dummy synchronizations at steps 9 and 10 are executed by idling pes in order to match synchronizations at steps 5 and 8 executed by non - idling pes .",
    "when ( ii ) is violated , the synchronous algorithm avoids the ambiguity and indeterminism ( which in this case are possible in the asynchronous algorithm ) as follows : in processing concurrent updates of two neighbors @xmath7 and @xmath66 for the same simulated time @xmath73 , first , @xmath7 and @xmath66 read states @xmath74 and times @xmath3 of each other and compute their private @xmath70 s and @xmath71 ( steps 3 and 4 in figure  [ fig : s1c1pe ] ) ; then , after the synchronization barrier at step 5 , @xmath7 and @xmath66 write their states and times at steps 6 and 7 , thus making sure that no write interferes with a read . +     + * aggregation .",
    "* in the two algorithms presented above , one pe hosts only one cell .",
    "such an arrangement may be wasteful if the communication between pes dominates the computation internal to a pe .",
    "a more efficient arrangement is to assign several cells to one pe . for concreteness , consider a two - dimensional @xmath75 array with periodic boundary conditions .",
    "let @xmath58 be a multiple of @xmath76 and @xmath77 pes be available .",
    "pe@xmath78 carries @xmath79 subarray @xmath78 , where @xmath80 .",
    "( capital @xmath78 will be used without confusion to represent both the subarray index and the set of cells @xmath7 the subarray comprises , e.g. as in @xmath81 ) a fragment of a square cellular array in an example of such an aggregation is represented in figure  [ fig : aggr]@xmath82 , wherein @xmath83 .",
    "the neighbors of a cell carried by pe1 are cells carried by pe2 , pe3 , pe4 , or pe5 .",
    "pe1 has direct connections with these four pes ( figure  [ fig : aggr]@xmath84 ) .",
    "given cell @xmath7 in the subarray hosted by pe1 , one can determine with which neighboring pes communication is required in order to learn the states of the neighboring cells .",
    "let @xmath85 be the set of these pes .",
    "examples in figure  [ fig : aggr]@xmath82 : @xmath86 is empty , @xmath87\\{pe5 } , @xmath88\\{pe3 , pe4}.    ) mapping of cells to pes , @xmath84 ) the interconnection among the pes which supports the neighborhood topology among the cells , width=556 ]    figure  [ fig : amcgen ] presents an aggregated variant of the algorithm in figure  [ fig : a1c1pe ] .",
    "pe@xmath78 , which hosts subarray @xmath78 , maintains the local time register @xmath89 .",
    "pe@xmath90 simulates the evolution of its subarray using the algorithm in figure  [ fig : amcgen ] with @xmath91 .",
    "each cell @xmath92 is represented in the memory of pe@xmath78 by its current state @xmath8 and its next arrival time @xmath63 .",
    "note that unlike the one - cell - per - one - pe algorithm , the @xmath63 does not represent the current local time for cell @xmath7 . instead",
    ", local times of all cells within subarray @xmath78 are the same , @xmath89 .",
    "@xmath89 moves from one @xmath63 to another in the order of increasing value .",
    "three successive iterations of this algorithm are shown in figure  [ fig : timlin ] , where the subarray @xmath78 consists of four cells : @xmath93 .",
    "circles in figure  [ fig : timlin ] represent arrival points in the simulated time .",
    "a crossed - out circle represents an arrival which has just been processed , i.e. , steps 3 , 4 , and 5 of figure  [ fig : amcgen ] have just been executed , so that @xmath89 has just taken on the value of the processed old arrival time @xmath63 , while the @xmath63 has taken on a new larger value .",
    "this new value is pointed to by an arrow from @xmath89 in figure  [ fig : timlin ] .",
    "it is obvious that always @xmath94 if @xmath92 .",
    "local times @xmath89 maintained by different pe@xmath78 might be different .",
    "a wait at step 3 can not deadlock the execution since the pe@xmath78 whose @xmath89 is the minimum over the entire cellular array is always able to make a progress .",
    "slides along a sequence of @xmath63 s in successive iterations of the aggregated algorithm , width=595 ]    assuming property ( ii ) as above , the algorithm correctly simulates the history of updates .",
    "the following example may serve as an informal proof of this statement .",
    "suppose pe1 is currently updating the state of cell @xmath95 ( see figure  [ fig : aggr]@xmath82 ) and its local time is @xmath96 . since @xmath97 , this update is possible because the local time of pe5 , @xmath98 , is currently larger than @xmath96 . at present",
    ", pe1 receives the state of @xmath99 from pe5 in order to perform the update .",
    "this state is in time @xmath98 , i.e. , in the future with respect to local time @xmath96 .",
    "however , the update is correct , since the state of @xmath99 was the same at time @xmath96 , as it is at time @xmath98 .",
    "indeed , suppose the state of @xmath99 were to be changed at simulated local time @xmath100 , @xmath101 . at the moment when this change would have been processed by pe5",
    ", the local time of pe1 would have been larger than @xmath100 , and @xmath100 would have been the local time of pe5 . after this processing has supposedly taken place , the local time of pe1 should not decrease . yet at the present it is @xmath96 , which is smaller that @xmath100 .",
    "this contradiction proves that the state of @xmath99 can not in fact change in the interval ( @xmath102 ) .    in the example in figure  [ fig : timlin ] , only one @xmath63 supplies @xmath103 .",
    "however , the algorithm in figure  [ fig : amcgen ] at step 2 commands to select _ a _ cell not _ the _ cell .",
    "this covers the unlikely situation of several cells having the same minimum time .",
    "if @xmath104 for different @xmath7 are independent random samples from a distribution with a continuous density , this case occurs with the probability zero . on the other hand ,",
    "if several cells can , with positive probability , update simultaneously , a synchronous version of the aggregated algorithm should be used instead . to eliminate indeterminism and inconsistency , the latter would use synchronization and intermediate storage techniques .",
    "these techniques were demonstrated in the algorithm in figure  [ fig : s1c1pe ] and their discussion is not repeated here .    for an important special case of * poisson asynchrony in the aggregated algorithm * ,",
    "the algorithm of figure  [ fig : amcgen ] is rewritten in figure  [ fig : amcpoi ] .",
    "this specialization capitalizes on the additive property of poisson streams , specifically , on the fact that sum of @xmath105 independent poisson streams with rate @xmath5 each is a poisson stream with rate @xmath106 . in the algorithm , @xmath107 ; this @xmath105 is equal to @xmath108 in the special case of partitioning into @xmath79 subarrays . unlike the general algorithm of figure  [ fig : amcgen ] , in the specialization in figure  [ fig : amcpoi ]",
    "neither individual streams for different cells are maintained , nor future arrivals @xmath63 for cells are individually computed . instead",
    ", a single cumulative stream is simulated and cells are delegated randomly to meet these arrivals .    at step 5 in figure  [ fig : amcpoi ]",
    ", @xmath109 is an @xmath110-th pseudo - random number in the sequence uniformly distributed in ( 0,1 ) .",
    "it follows from the notation that each pe has its own sequence .",
    "if this sequence is independent of the run ( which is condition ( i ) above ) and if updates for neighboring cells never coincide in time ( which is condition ( ii ) above ) , then this algorithm produces a unique reproducible trajectory .",
    "the same statement is also true for the algorithm in figure  [ fig : amcgen ] .",
    "however , uniqueness provided by the algorithm in figure  [ fig : amcpoi ] is weaker than the one provided by the algorithm in figure  [ fig : amcgen ] : if the same array is partitioned differently and/or executed with different number of pes , a trajectory produced by the algorithm in figure  [ fig : amcpoi ] may change ; however , a trajectory produced by the algorithm in figure  [ fig : amcgen ] is invariant for such changes given that each cell @xmath7 uses its own fixed pseudo - random sequence . + * efficiency of aggregated algorithms*. both many - cells - per - one - pe algorithms in figure  [ fig : amcgen ] and figure  [ fig : amcpoi ] are more efficient than the one - cell - per - one - pe counterparts in figure  [ fig : a1c1pe ] and figure  [ fig : s1c1pe ] .",
    "this additional efficiency can be explained in the example of the square array , as follows : in the algorithms in figure  [ fig : a1c1pe ] and figure  [ fig : s1c1pe ] , a pe may wait for its four neighbors .",
    "however , in the algorithms in figure  [ fig : amcgen ] and figure  [ fig : amcpoi ] , a pe waits for at most two neighbors .",
    "for example ,",
    "when the state of cell @xmath111 in figure  [ fig : aggr]@xmath82 is updated , pe1 might wait for pe3 and pe4 .",
    "moreover , for at least @xmath112 cells @xmath7 out of @xmath108 , pe1 does not wait at all , because @xmath113 .",
    "the cells @xmath7 such that @xmath113 form the dashed square in figure  [ fig : aggr]@xmath82 .",
    "this additional efficiency becomes especially large if , instead of set @xmath114 in the original formulation of the model , one uses sets @xmath115 or , more generally , @xmath116-th degree neighborhood , @xmath117 .",
    "the latter is defined for @xmath118 inductively @xmath119 where @xmath120 for a set @xmath121 of cells is defined as @xmath122 .",
    "it is easy to rewrite the algorithms in figure  [ fig : a1c1pe ] and figure  [ fig : s1c1pe ] for the case @xmath118 .",
    "the obtained codes have low efficiency however .",
    "for example , in the square array case , one has @xmath123 .",
    "thus , if @xmath124 , a cell might have to wait for 12 cells in order to update .",
    "in the same example , if one pe carries an @xmath79 subarray , and @xmath125 , then the pe waits for at most three other pes no matter how large the @xmath116 is .",
    "moreover , if @xmath126 then in @xmath127 cases out of @xmath108 the pe does not wait at all . +",
    "* the bkl algorithm * @xcite was originally proposed for ising spin simulations .",
    "it was noticed that the probability @xmath10 to flip @xmath8 takes on only a finite ( and small ) number @xmath128 of values @xmath129 , each corresponding to one or several combinations of old values of @xmath8 and neighboring spins @xmath12 .",
    "thus the algorithm splits the cells into @xmath128 pairwise disjoint classes @xmath130 , @xmath131, ... @xmath132 .",
    "the rates @xmath133 of changes ( not just of the attempts to change ) for all @xmath134 are the same . at each iteration",
    ", the bkl algorithm does the following : +    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\(a ) selects @xmath135 at random according to the weights @xmath136 , @xmath137 , and selects a cell @xmath138 uniformly at random .",
    "+ ( b ) flips the state of the selected cell , @xmath139 .",
    "+ ( c ) increases the time by @xmath140 , where @xmath141 is a pseudo - random number uniformly distributed in ( 0,1 ) .",
    "+ ( d ) updates the membership in the classes .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    if the asynchrony law is poisson , the idea of the bkl algorithm can be applied also to a deterministic update . here",
    "the probability @xmath10 of change takes on just two values : + @xmath142 if @xmath143 , and @xmath144 if @xmath145 .",
    "+ accordingly , there are two classes : @xmath146 , the cells which are not going to change and @xmath130 , the cells which are going to change . as with the original bkl algorithm ,",
    "a substantial overhead is required for maintaining an account of the membership in the classes ( step ( d ) ) .",
    "the bkl algorithm is justified only if a large number of cells are not going to change their states .",
    "the latter is often the case .",
    "for example , in the conways s synchronous _ game of life _",
    "( gardner @xcite ) large regions of white cells ( @xmath147 ) remain unchanged for many iterations with very few black cells ( @xmath148 ) .",
    "one would expect similar behavior for an asynchronous version of the game of life .",
    "the basic bkl algorithm is serial .",
    "to use it on a parallel computer , an obvious idea is to run a copy of the serial bkl algorithm in each subarray carried by a pe .",
    "such a procedure , however , causes roll - backs , as seen in the following example :    suppose pe1 is currently updating the state of cell @xmath95 ( figure  [ fig : aggr]@xmath82 ) and its local time is @xmath96 , while the local time of pe5 , @xmath98 , is larger than @xmath96 . since @xmath99 is a nearest neighbor to @xmath149 , @xmath99 s membership might change because of @xmath95 s changed state .",
    "suppose @xmath99 s membership were to indeed change .",
    "although this change would have been in effect since time @xmath96 , pe5 , which is responsible for @xmath99 , would learn about the change only at time @xmath150 .",
    "as the past of pe5 is not , therefore , what pe5 has believed it to be , interval [ @xmath151 must have been simulated by pe5 incorrectly , and must be played again .",
    "this original roll - back might cause a cascade of secondary roll - backs , third generation roll - backs etc .",
    "+ * a modified bkl algorithm * applies the original bkl procedure only to a subset of the cells , whereas the procedure of the standard model is applied to the remaining cells . more specifically :",
    "an additional separate class @xmath146 is defined .",
    "unlike other @xmath152 , @xmath153 , class @xmath146 always contains the same cells .",
    "steps ( a ) - ( d ) are performed as above with the following modifications :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\1 ) the weight of @xmath146 at step ( a ) is taken to be @xmath154 .",
    "+ 2 ) if the selected @xmath7 belongs to @xmath146 , then at step ( b ) the state of @xmath7 may or may not change .",
    "the probability @xmath10 of change is determined as in the standard model .",
    "+ 3 ) the time at step ( c ) should be increased by @xmath155 , where @xmath156 is a pseudo - random number uniformly distributed in @xmath59 .",
    "+ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    now consider again the subarray carried by pe1 in figure  [ fig : aggr]@xmath82 .",
    "the subarray can be subdivided into the @xmath157 `` kernel '' square and the remaining boundary layer . if first degree neighborhood , @xmath158 , is replaced with the @xmath116-th degree neighborhood , @xmath117",
    ", then the kernel is the central @xmath159 square , and the boundary layer has width @xmath116 . in figure",
    "[ fig : aggr]@xmath82 , the cells in the dashed square constitute the kernel with @xmath160 .",
    "to apply the modified bkl procedure to the subarray carried by pe1 , the boundary layer is declared to be the special fixed class @xmath146 .",
    "similar identification is done in the other subarrays . as a result",
    ", the fast concurrent bkl procedures on the kernels are shielded from each other by slower procedures on the layers .",
    "the roll - back is avoided , since state change of a cell in a subarray does not constitute state or membership change of a cell in another subarray .",
    "unless the performance of pe1 is taken into account , the neighbors of pe1 can not even tell whether pe1 uses the standard or the bkl algorithm to update its kernel . as the size of the subarray increases , so does both the relative weight of the kernel and the fraction of the fast bkl processing . + * generating the output*. consider the task of generating cellular patterns for specified simulated times .",
    "a method for performing this task in a serial simulation or a parallel simulation of a synchronous cellular array is obvious : as the global time reaches a specified value , the computer outputs the states of all cells . in an asynchronous simulation , the task becomes more complicated because there is no global time : different pes may have different local times at each physical instance of simulation .",
    "suppose for example , one wants to see the cellular patterns at regular time intervals @xmath161 on a screen of a monitor attached to the computer . without getting too involved in the details of performing i / o operations and the architecture of the parallel computer",
    ", it would be enough to assume that a separate process or processes are associated with the output ; these processes scan an output buffer memory space allocated in one or several pes or in the shared memory ; the buffer space consists of @xmath149 frames , numbered 0,1, ... ,@xmath162 , each capable of storing a complete image of the cellular array for one time instance .",
    "the output processes draw the image for time @xmath163 on the screen as soon as the frame number @xmath164 ( the reminder of the integer division @xmath165 by @xmath149 ) is full and the previous images have been shown . then the frame is flashed for the next round when it will be filled with the image for time @xmath166 and so on .",
    "+    the algorithm must fill the appropriate frame with the appropriate data as soon as both data and the frame become available .",
    "the modifications that enable the asynchronous algorithm in figure  [ fig : amcgen ] to perform this task are presented in figure  [ fig : genout ] . in this algorithm , variables @xmath167 and @xmath165 are private ( i.e. , local to pe ) and @xmath168 and @xmath169 are constants whose values are the same for all the pes .",
    "note that different pes may fill different frames concurrently .",
    "if the slowest pe is presently filling an image for time @xmath163 , then the fastest pe is allowed to fill the image for time no later than @xmath170 .",
    "an attempt by the fastest pe to fill the image for time @xmath171 will be blocked at step 4 , until the frame number @xmath172 becomes available .",
    "thus , the finiteness of the output buffer introduces a restriction which is not present in the original algorithm in figure  [ fig : amcgen ] .",
    "according to this restriction , the lag between concurrently processed local times can not exceed a certain constant .",
    "the exact value of the constant in each particular instance depends on the relative positions of the update times within the @xmath168-slots . in any case , the constant is not smaller than @xmath173 and not larger than @xmath174 .",
    "however , even with a single output buffer segment , @xmath175 , the simulation does not become time - driven . in this case , the concurrently processed local times might be within a distance of up to @xmath168 of each other , whereas @xmath168 might be relatively large .",
    "no precision of update time representation is lost , although efficiency might degrade when both @xmath168 and @xmath149 become too small , see section  [ sec : perf ] .",
    "modeling and analysis of asynchronous algorithms is a difficult theoretical problem . strictly speaking ,",
    "the following discussion is applicable only to synchronous algorithms .",
    "however , one may argue informally that the performance of an asynchronous algorithm is not worse than that of its synchronous counterpart , since expensive synchronizations are eliminated .",
    "first , consider the synchronous algorithm in figure  [ fig : s1c1pe ] .",
    "let @xmath14 be the size of the array and @xmath176 be the number of cells which passed the test at step 2 , figure  [ fig : s1c1pe ] .",
    "the ratio of useful work performed , to the total work expended at the iteration is @xmath177 .",
    "this ratio yields the _ efficiency _ ( or _ utilization _ ) at the given iteration . assuming that in the serial algorithm all the work is useful , and that the algorithm performs the same computation as its parallel counterpart , the speed - up of the parallel computation is the average efficiency times the number of pes involved . here the averaging is done with equal weights over all the iterations .    in the general algorithms , @xmath178",
    "is determined using the states of the neighbors of @xmath7 . however , in the important applications , such as an ising model , @xmath178 is independent of states .",
    "the following assessment is valid only for this special case of independence . here",
    "the configuration is irrelevant and whether the test succeeds or not can be determined knowing only the times at each iteration .",
    "this leads to a simplified model in which only local times are taken into account : at an iteration , the local time of a cell is incremented if the time does not exceed the minimum of the local times of its neighbors .",
    "a simple ( serial ) algorithm which updates only local times of cells @xmath63 according to the rules formulated above was exercised for different array sizes @xmath58 and three different dimensions : for an @xmath58-element circular array , an @xmath75 toroidal array , and for @xmath179 array with periodic boundary conditions .",
    "two types of asynchronies are tried : the poisson asynchrony for which @xmath180 is distributed exponentially , and the asynchrony for which @xmath180 is uniformly distributed in ( 0,1 ) . in both cases ,",
    "random time increments for different cells are independent .        the results of these six experiments are given in figure  [ fig : perf1t1 ] .",
    "each solid line in figure  [ fig : perf1t1 ] is enclosed between two dashed lines .",
    "the latter represent 99.99% student s confidence intervals constructed using several simulation runs , that are parametrically the same but fed with different pseudo - random sequences .",
    "in figure  [ fig : perf1t1 ] , for each array topology there are two solids lines .",
    "the poisson asynchrony always corresponds to the lower line .",
    "the corresponding limiting values of performances ( when @xmath58 is large ) are also shown near the right end of each curve .",
    "for example , the efficiency in the simulation of a large @xmath75 array with the poisson asynchrony is about 0.121 , with the other asynchrony , it is about 0.132 .",
    "no analytical theory is available for predicting these values or even proving their separation from zero when @xmath181 .",
    "it follows from figure  [ fig : perf1t1 ] that replacing exponential distribution of @xmath50 with the uniform distribution results in efficiency increase from 0.247 to 0.271 for a large @xmath58-circle ( @xmath181 ) .",
    "the efficiency can be raised even more . if @xmath182 , where @xmath141 is distributed uniformly in ( 0,1 ) , then in the limit @xmath181 , with the student s confidence 99.99% , the efficiency is @xmath183 .",
    "it is not known how high the efficiency can be raised this way ( degenerated cases , like a synchronous one , in which the efficiency is 1 , are not counted ) .",
    "an efficiency of 0.12 means the speed - up of @xmath184 ; for @xmath185 this comes to more than 1900 .",
    "this assessment is confirmed in an actual full scale simulation experiment performed on @xmath186 pes of a connection  machine  ( r ) ( a quarter of the full computer ) .",
    "this simd computer appears well - suited for the synchronous execution of the one - cell - per - one - pe algorithm in figure  [ fig : s1c1pe ] on a toroidal array , poisson asynchrony law .",
    "since an individual pe is rather slow , it executes several thousand instructions per second , and its absolute speed is not very impressive : it took roughly 1 sec . of real time to update all @xmath187 spins when the traffic generated by other tasks running on the computer was small ( more precise measurement was not available ) .",
    "this includes about @xmath188 rounds of the algorithm , several hundred instructions of one pe per round",
    ".    the 12% efficiency in the one - cell - per - one - pe experiments could be greatly increased by aggregation .",
    "the many - cells - per - one - pe algorithm in figure  [ fig : amcpoi ] is implemented as a @xmath78 language parallel program for a balance  ( tm ) computer , which is a shared memory mimd bus machine .",
    "the @xmath75 array was split into @xmath79 subarrays , as shown in figure  [ fig : aggr ] , where @xmath58 is a multiple of @xmath76 . because the computer has 30 pes , the experiments could be performed only with @xmath189 , and 25 pes for different @xmath58 and @xmath76 .    along with these experiments , a simplified model , similar to the one - cell - per - one - pe case ,",
    "was run on a serial computer . in this model ,",
    "quantity @xmath190 is maintained for each pe , @xmath191 .",
    "the update of @xmath192 is arranged in rounds , wherein each @xmath192 is updated as follows : +  ( i ) with probability @xmath193 , pe@xmath78 updates @xmath192 : @xmath194 where @xmath141 and @xmath36 are the same as in step 5 in figure  [ fig : amcpoi ] . here",
    "@xmath195 is the probability that the pe chooses a cell @xmath7 so that @xmath196 ; +  ( ii ) with probability @xmath197 , the pe must check the @xmath198 of one of its four neighbors @xmath199 before making the update .",
    "the @xmath199 is chosen uniformly at random among the four possibilities . if @xmath200 , then @xmath192 gets an increment according to ;",
    "otherwise , @xmath192 is not updated . here",
    "@xmath201 is the probability that pe will choose a cell @xmath7 in an edge but not in a corner , so that @xmath202 +  ( iii ) with the remaining probability @xmath203 , the pe checks @xmath198 and @xmath204 of two of its adjacent neighbors ( for example in figure  [ fig : aggr ] , neighbors pe2 and pe3 can be involved in the computation for pe1 ) .",
    "the two neighbors are chosen uniformly at random from the four possibilities . again ,",
    "if both @xmath205 and @xmath206 , then @xmath192 gets an increment according to ; otherwise , @xmath192 is not updated . here",
    "@xmath207 is the probability to choose a cell @xmath7 in a corner , so that @xmath208 .",
    "as in the previous case , this simplified model simulates a possible but not obligatory synchronous timing arrangement for executing the real asynchronous algorithm .",
    "figure  [ fig : perfmt1 ] shows excellent agreement between actual and predicted performances for the aggregated ising model .",
    "the efficiency presented in figure  [ fig : perfmt1 ] is computed as    @xmath209    the parallel speed - up can be found as efficiency@xmath210number  of  pes . for 25 pes simulating a 120@xmath211120 ising model ,",
    "efficiency is 0.66 ; hence , the speed - up is greater than 16 .",
    "for the currently unavailable sizes , when @xmath16 pes simulate a @xmath212 array , the simplified model predicts an efficiency of about 0.8 and a speed - up of about 8000 .        in the experiments reported above , the lag between the local times of any two pes was not restricted . as discussed in section  [ sec : algo ] , an upper bound on the lag might result from the necessity to produce the output . to see how the bound affects the efficiency , one experiment reported in figure  [ fig : perfmt1 ] , is repeated with various finite values of the lag bound . in this experiment ,",
    "an @xmath75 array is simulated and one pe carries an @xmath79 subarray , where @xmath213 and @xmath214 .",
    "the results are presented in figure  [ fig : perfbl ] .    in figure",
    "[ fig : perfbl ] , the unit of measure for a lag is the expectation of time intervals between consecutive arrivals for a cell . for lag bounds greater than 16 , degradation of efficiency",
    "is almost unnoticeable , when compared with the base experiment where lag@xmath215 .",
    "substantial degradation starts at about 8 ; for the unity lag bound , the efficiency is about half that of the base experiment . however , even for lag bound 0.3 , the simulation remains practical , with an efficiency of about 0.1 ; since 1024 pes execute the task , this efficiency means a speed - up of more than 100 .",
    "this paper demonstrates an efficient parallel method for simulating asynchronous cellular arrays .",
    "the algorithms are quite simple and easily implementable on appropriate hardware .",
    "in particular , each algorithm presented in the paper can be implemented on a general purpose asynchronous parallel computer , such as the currently available bus machines with shared memory .",
    "the speed of such implementation depends on the speed of pes and the efficiency of the communication system .",
    "a crucial condition for success in such implementation is the availability of a good parallel generator of pseudo - random numbers . to assure reproducibility ,",
    "each pe should have its own reproducible pseudo - random sequence .",
    "the proposed algorithms present a number of challenging mathematical problems , for example , the problem of proving that efficiency tends to a positive limit when the number of pes increases to infinity . + * acknowledgments*. + i acknowledge the personnel of the thinking machine corp . for their kind invitation , and help in debugging and running the parallel * lisp program on one of their computers . particularly , the help of mr .",
    "gary rancourt and mr .",
    "bernie murray was invaluable . also , i thank andrew t. ogielski and malvin h. kalos for stimulating discussions , debasis mitra for a helpful explanation of a topic in markov chains , and brigid moynahan for carefully reading the text .    mmmm s. geman and d. geman , stochastic relaxation , gibbs distributions , and the bayesian restoration of images , _ ieee transactions on pattern analysis and machine intelligence _ , * pami-6 * , 6 , ( novem .",
    "1984 ) , 721741 .",
    "# define shared_mem_size ( sizeof(double)*10000 ) # define end_time 1000 .",
    "# define a 24        / * side of small square a pe takes care of*/ # define m 5         / * number of pes along a side of the big square*/    shared int npes = m*m , spin[m*a][m*a ] ; shared float time[m][m ] ;   /*local times on subarrays*/ shared float prob[10 ] ;   / * probabilities of state change * / shared float j = 1 . ,",
    "h = 0 . ;      / * energy= -j sum spin spin ' - h sum spin * / shared float t = 1 .",
    ";                 / * temperature * / shared int ato2 = a*a ; shared int am = a*m ;      / * compute flip probabilities * /      for ( i = 0 ; i < 5 ; i++ )          for ( j = 0 ; j < 2 ; j++ )            { index = i + 5*j ;     / * index = 0,1, ... ,9 * /              my_spin = 2*j - 1 ;             sum_nei = 2*i - 4 ;             d_e = 2.*(j * my_spin * sum_nei + h * my_spin ) ;             x = exp(-d_e / t ) ;             prob[index ] = x/(1.+x ) ;     / *       printf(\"prob[%d]=%f\\n\",index , prob[index ] ) ;   * /            } ;      / * initialize spins at random , in seedran(seed , b ) , b is dummy*/      seedran(31234,1 ) ;      for (",
    "i = 0 ; i < m*a ; i++ )          for ( j = 0 ; j < m*a ; j++ ) {              bit = 2*frand(1 ) ;                 / * bit becomes 0 or 1 * /              spin[i][j ] = 2*bit - 1 ;           / * spin becomes -1 or 1 * /     / *        printf(\"spin[%d][%d]=%d\\n\",i , j , spin[i][j ] ) ;       * /      } ;          for ( child_id = 0 ; child_id < npes ; child_id++ )            if ( fork ( ) = = 0 ) {                tmp_affinity(child_id ) ;      / * fixing a pe for process child_id * /                work(child_id ) ;               / * starting a child pe process * /                exit(0 ) ;            }      work(my_id ) int my_id ; {    int i , j ;    int coord , var ;    int x , y , my_i , my_j , sum_nei , nei_i , nei_j ;    int   up_i , down_i , left_j , right_j ;    int i_base , j_base ;    int index ;    double frand ( ) ;     double r ;    double end_time ;              while(time[my_i][my_j ] < end_time )     {      r = frand(my_id ) ;         /*pe",
    "my_id obtains next pseudo - random number from its own sequence*/      x = r*a ;                     y = ( r*a - x)*a ;           /*pick a random cell with internal address ( x , y ) within the a*a square*/    /*compute sum of neighboring spins*/      sum_nei = 0 ;                for ( coord = 0 ;   coord < 2 ; coord + = 1 )          for ( var = -1 ;   var < 2 ; var + = 2 )      {            nei_i = x ;            nei_j = y ;            if(coord = = 0 ) nei_i + = var ;            if(coord = = 1 ) nei_j + = var ;              if(0 < = nei_i & & nei_i < a & & 0 <",
    "= nei_j & & nei_j < a )             {               nei_i + = i_base ;               nei_j + = j_base ;            }            else             {         / * 4 possible reasons to wait for a neighboring pe * /              if(-1 = = nei_i ) while ( time[down_i][my_j ]   < time[my_i][my_j ] ) ;              if(-1 = = nei_j ) while ( time[my_i][left_j ]   < time[my_i][my_j ] ) ;              if(nei_i = = a )   while ( time[up_i][my_j ]     < time[my_i][my_j ] ) ;              if(nei_j = = a )   while ( time[my_i][right_j ] < time[my_i][my_j ] ) ;"
  ],
  "abstract_text": [
    "<S> a definition for a class of asynchronous cellular arrays is proposed . </S>",
    "<S> an example of such asynchrony would be independent poisson arrivals of cell iterations . </S>",
    "<S> the ising model in the continuous time formulation of glauber falls into this class . </S>",
    "<S> also proposed are efficient parallel algorithms for simulating these asynchronous cellular arrays . in the algorithms , one or several cells are assigned to a processing element ( pe ) , local times for different pes can be different . </S>",
    "<S> although the standard serial algorithm by metropolis , rosenbluth , rosenbluth , teller , and teller can simulate such arrays , it is usually believed to be without an efficient parallel counterpart . </S>",
    "<S> however , the proposed parallel algorithms contradict this belief proving to be both efficient and able to perform the same task as the standard algorithm . </S>",
    "<S> the results of experiments with the new algorithms are encouraging : the speed - up is greater than 16 using 25 pes on a shared memory mimd bus computer , and greater than 1900 using @xmath0 pes on a simd computer . the algorithm by bortz , kalos , and lebowitz can be incorporated in the proposed parallel algorithms , further contributing to speed - up . </S>"
  ]
}