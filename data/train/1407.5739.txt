{
  "article_text": [
    "optimization can be characterized as a process to minimize an objective function over a bounded or unbounded space . of the widely used class of optimization algorithms known as meta - heuristics , that many of them imitate natural processes such as simulated annealing ( sa - originated in physics ) , genetic algorithm ( ga - imitating the darwinian process of natural selection ) @xcite , ant colony optimization ( aco mimicking behavior of foraging ants ) @xcite and particle swarm optimization ( pso modeling the flocking and schooling by birds ) @xcite . in particular ,",
    "sa and ga have been practically successful although they never guarantee to reach global optima within limited time .",
    "this paper studies a group of stochastic processes frequently observed in physics and biology called _ lvy flights _",
    "the goal is to realize the claim by gutowski that lvy flights can be used in optimization @xcite . a new class of meta - heuristic algorithms called lfo ( lvy flights optimization )",
    "is introduced . to our knowledge ,",
    "similar work has not been introduced in the optimization literature .",
    "the rest of paper is organized as the following .",
    "2 outlines some fundamentals of lvy flights .",
    "3 introduces four new lfo algorithms . sec .  4 reports experiments and results .",
    "the last section provides several possible outlooks .",
    "extensive investigations in diffusion processes have revealed that there exist some processes not obeying brownian motion .",
    "one class is _ enhanced diffusion _ , which has been shown to comply with lvy flights @xcite .",
    "the lvy flights can be characterized by following probability density function : @xmath0 note that with @xmath1 , the distribution in eq .",
    "( [ eq : levy ] ) can not be normalized , therefore it has no physical meaning although our computation needs not be concerned about such problem . for @xmath2 , the expectation does not exist .    for the interest of this paper",
    ", we consider a random walk where step length @xmath3 obeys the distribution : @xmath4 this is a normalized version of @xcite with the scale factor @xmath5 added since it is more natural to think in term of physical dimension of given space .",
    "this form preserves the property of distribution in eq .",
    "( [ eq : levy ] ) for large @xmath3 but it is much simpler to deal with small @xmath3 .",
    "the distribution is heavy - tailed , as shown on fig .",
    "[ fig : flight - length - distribution](a ) .",
    "it is not difficult to verify that @xmath3 can be randomly generated as follows : @xmath6 where @xmath7 is uniformly distributed in the interval @xmath8 .    [",
    "cols=\"^,^ \" , ]     figs .",
    "[ fig : flight - length - distribution](b - d ) show lvy fights on a 2d landscape with @xmath9 .",
    "note that the scale of fig .",
    "[ fig : flight - length - distribution](b ) is much larger than that of fig .",
    "[ fig : flight - length - distribution](d ) ( around order of 102 ) . for small @xmath10",
    ", the random walker tends to get crowded around a central location and occasionally jumps a very big step to a new location . as @xmath10 increases , the probability of performing a long jump decreases . note that fig .",
    "[ fig : flight - length - distribution](d ) shows the random walks as @xmath11 , which gets outside of the range given in eq .",
    "( [ eq : levy ] ) .",
    "however , for the computational purposes , we need not to strictly be consistent with physics laws .",
    "the goal in optimization is to efficiently explore the search space in order to find globally optimal .",
    "lvy flights provide a mechanism to achieve this goal .",
    "we use the term `` particle '' to call the abstract entity that moves on the search landscape . from each position , the particle can `` fly '' to a new feasible position at a distance , which is randomly generated from lvy flights distribution .",
    "it is known that a good search algorithm often maintains balance between _ local exploitation _ and _ global exploration _",
    "lvy flights offer a nice way : as in eq .",
    "( [ eq : random - walk ] ) , we control the frequency and the length of long jumps by adjusting the parameters @xmath10 and @xmath5 , respectively . ideally , algorithms will dynamically tune these two parameters to best fit a given landscape .",
    "there are several ways to formulate an algorithm that employs such lvy - based distance .",
    "firstly , lvy flights define a manageable move strategy , which can include small local steps , global jumps and ( or ) mixing between the two . as the lvy process",
    "can occasionally generate long jumps , it can be employed in the multistart model . secondly , one can use a single particle ( as in greedy , sa , tabu search ) @xcite or a set of particle(s ) ( as in ga , evolution strategy , genetic programming , aco and scatter search ) @xcite moving over the search space .",
    "the third way , and probably the most promising , is to combine generic movement model provided by lvy flights with other known single - solution , or population - based meta - heuristics .",
    "such combinations could result in more powerful hybrid algorithms than the originals @xcite .      here",
    "we propose five algorithms under the class of lvy flights optimization ( lfo ) .",
    "we first provide the brief description .",
    "pseudocode for the first four algorithms is then given in algorithms  [ alg : lfo - b][alg : lfo - ils ] .",
    "[ [ basic - lfo - lfo - b . ] ] basic lfo ( lfo - b ) .",
    "+ + + + + + + + + + + + + + + + + +    this basic algorithm uses a set of particles at each generation . starting from one best - known location ,",
    "the algorithm will generate a new generation at distances which are randomly distributed according to lvy flights . the new generation",
    "will then be evaluated to select the most promising one .",
    "the process is repeated until stopping criteria are satisfied .",
    "the algorithm is quite closed to ga in a way that it iterates through generations of particle population , and at each generation it selects the good individuals for the next step .",
    "however , there selection policy in lfo - b is quite simple : only the best of population survives at each iteration .",
    "[ [ hybrid - lfo - with - local - search - lfo - ls . ] ] hybrid lfo with local search ( lfo - ls ) .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this is an extension of lfo - b algorithm , where before the selection is made each particle performs its own search to reach local optima .",
    "the selection procedure then locates the best local optima found so far , and lvy flights mechanism helps escape from such trap .",
    "it is open to implement the local search algorithm .",
    "[ [ local - search - with - multiple - lfo - restarts - lfo - mls . ] ] local search with multiple lfo restarts ( lfo - mls ) .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this can be viewed as a sequential version of lfo - ls algorithm and actually behaves as a multi - start local search . here",
    "only one particle is used . in each iteration",
    "the particle tries local search until getting trapped in local optima . to escape from such trap",
    ", it will jump to new location by a step generated from lvy distribution .",
    "the jump is immediately accepted without further selection .",
    "[ [ lfo - with - iterated - local - search - lfo - ils . ] ] lfo with iterated local search ( lfo - ils ) .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this is very similar to lfo - mls except for the local minima escape strategy . instead of immediately accepting the lvy - based jump ,",
    "the algorithm tries a number of jumps until a better solution is found .",
    "this behavior is identified as iterated local search @xcite .",
    "[ [ lfo - mls - sa - lfo - sa . ] ] lfo - mls + sa ( lfo - sa ) .",
    "+ + + + + + + + + + + + + + + + + + + + + +    this is a combination of lfo - mls and sa separated in time : lfo - mls is run first , then the sa takes the solution as the starting point .",
    "the idea is that lfo algorithms may locate the good solution quickly while sa helps improve the quality in the long run .",
    "* procedure : * lfo_b ( )    @xmath12__init_position _ _ ( ) ;    @xmath12**while * * ( stopping_criteria_not_met )    @xmath12@xmath12*for * each member in the new generation    @xmath12@xmath12@xmath12@xmath3__@xmath13l___vy_flights_(@xmath5,@xmath10 ) ;    @xmath12@xmath12@xmath12__jump_randomly_at_distance__(@xmath3 ) ;    @xmath12@xmath12*endfor *    @xmath12@xmath12_return_to_best_known_position _ ( ) ;    @xmath12**endwhile * *    * endprocedure *    * procedure : * lfo_ls ( )    @xmath12__init_position _ _ ( ) ;    @xmath12**while * * ( stopping_criteria_not_met )    @xmath12@xmath12*for * each member in the new generation    @xmath12@xmath12@xmath12@xmath3__@xmath13l___vy_flights_(@xmath5,@xmath10 ) ;    @xmath12@xmath12@xmath12__jump_randomly_at_distance__(@xmath3 ) ;    @xmath12@xmath12@xmath12__perform_local_search _ _ ( ) ;    @xmath12@xmath12*endfor *    @xmath12@xmath12_return_to_best_known_position _ ( ) ;    @xmath12**endwhile * *    * endprocedure *    * procedure : * lfo_mls ( )    @xmath12__init_position _ _ ( ) ;    @xmath12**while * * ( stopping_criteria_not_met )    @xmath12@xmath12_perform_local_search _ ( ) ;    @xmath12@xmath12__@xmath3@xmath13l___vy_flights_(@xmath5,@xmath10 ) ;    @xmath12@xmath12_jump_randomly_at_distance_(@xmath3 ) ;    @xmath12**endwhile * *    * endprocedure *    * procedure : * lfo_ils ( )    @xmath12__init_position _ _ ( ) ;    @xmath12**while * * ( stopping_criteria_not_met )    @xmath12@xmath12_perform_local_search _ ( ) ;    @xmath12@xmath12__@xmath3@xmath13l___vy_flights_(@xmath5,@xmath10 ) ;    @xmath12@xmath12*while*(not found better solution )    @xmath12@xmath12@xmath12__jump_randomly_at_distance__(@xmath3 ) ;    @xmath12@xmath12*endwhile *    @xmath12**endwhile * *    * endprocedure *",
    "test problems are @xmath14 of @xcite , @xmath15 ( rosenbrocks saddle ) and @xmath16 ( shekels foxholes ) in de jongs test function suite @xcite , rastrigins @xmath17 @xcite and keanes bump @xcite .",
    "[ [ f_0 ] ] @xmath14 : + + + + + + + + + + + + + + + + + + + +    @xmath18    [ [ f_2 ] ] @xmath15 : + + + + + + + + + + + + + + + + + + + +    @xmath19    [ [ f_5 ] ] @xmath16 : + + + + + + + + + + + + + + + + + + + +    @xmath20    [ [ f_6 ] ] @xmath17 : + + + + + + + + + + + + + + + + + + + +    @xmath21    [ [ bump ] ] bump : + + + + +    @xmath22    function @xmath14 is very difficult to minimize with @xmath23 local minima , and @xmath15 is also considered to be hard despite of being uni - modal @xcite .",
    "@xmath17 is interesting because of the sinuous component . according to keane @xcite ,",
    "the bump is a seriously hard test - function for optimization algorithms because the landscape surface is highly `` bumpy '' with very similar peaks and global optimum is generally determined by the product constraint . among those functions ,",
    "@xmath14 and @xmath16 have fixed dimensions while the rest can be set freely . in our tests ,",
    "the dimension of 10 is set for @xmath15 and @xmath17 and of 50 for the bump .",
    "we compare four proposed algorithm with the classic sa .",
    "this subsection provides greater details in algorithm realization , which can be classified into _ move strategy _ , _ stopping criteria _ , and _",
    "algorithm specificity_.    [ [ move - strategy . ] ] move strategy .",
    "+ + + + + + + + + + + + + +    each move is selected in random directions spanning in all dimensions of search space where move length is measured in euclidean metric . in the case of",
    "infeasible move to the region outside bounded space , two strategies are used : ( i ) the move selection is repeated until a feasible one is found , and ( ii ) the move is stopped at the edges .",
    "the first strategy is quite intuitive but it may result in many repetitions in case of long lvy flights .",
    "the second gives chance to explore the boundary regions , in which high quality solutions may be found .",
    "[ [ stopping - criteria . ] ] stopping criteria .",
    "+ + + + + + + + + + + + + + + + + +    the main stopping criteria used in main algorithms are time and the quality of best solution found so far ( compared with known optimal one ) .",
    "another stopping criterion is number of non - improvement moves .",
    "this can be either number of steps in neighborhood exploitation or number of jumps in global exploration .",
    "the first is used in greedy search , while the second applies for multiple restart type .",
    "[ [ algorithm - specificity . ] ] algorithm specificity .",
    "+ + + + + + + + + + + + + + + + + + + + + +    in sa , the initial temperature @xmath24 is chosen as 10% of randomly generated initial solution while the stopping temperature @xmath25 is fixed at @xmath26 .",
    "although there are no exact reasons for such choice , it is based on authors experience with sa so that transition probability is always 1 at the beginning and very close to 0 at the end of each run .",
    "the cooling schedule is the widely used power type : @xmath27 and @xmath28 is the maximum allocated run time . in all lfo algorithms , we use the power index @xmath29 . the number of jumps is set at 100 for lfo - b and lfo - mls algorithms , while the jump distance is limited at a half of largest size of search spaces dimensions .",
    ".[fig : test - results - for - f0],scaledwidth=70.0% ]    .[fig : test - results - for - f2],scaledwidth=70.0% ]    .[fig : test - results - for - f5],scaledwidth=70.0% ]    .[fig : test - results - for - f6],scaledwidth=70.0% ]    .[fig : test - results - for - bump],scaledwidth=70.0% ]    the tests were run on 2.5ghz intel computer within given periods of time .",
    "every test was run repeatedly and best found solutions were sampled at relevant intervals and then averaged .",
    "numbers of replications were 100 times for @xmath14 , @xmath15 , and @xmath16 , 20 times for @xmath17 and 10 times for the bump .",
    "algorithms performances on the five test problems are presented in figs .",
    "[ fig : test - results - for - f0][fig : test - results - for - bump ] .    in all cases ,",
    "some of lfo algorithms outperform sa although sa appears to improve its performance in the long runs .",
    "this is a proven beauty of sa but it will be impractical if the required time is too long for daily activities .",
    "lfo algorithms tend to sample good quality solutions ( compared to initial random solution ) very quickly , in most cases within a second .",
    "the only exception is the bump problem , where sa seems to work best after a significant time .",
    "although there are not enough representative test cases to statistically conclude on the power of lfo algorithms over sa , there are several interesting points to note .",
    "firstly , lvy flights portrays well the distribution of flight lengths and times performed by foragers observed in natural experiments @xcite . in the process of foraging over a given landscape",
    ", lvy distribution helps reduce the probability of returning previously visited locations , compared to normal distribution .",
    "this is particularly advantageous in memoryless algorithms like basic stochastic sa or ga , where there are no built - in mechanisms to avoid revisits .",
    "secondly , as mentioned early in this paper , lfo algorithms work under assumption that good quality solutions can be found around local minima . such property can be found in most test cases , where experiments have proved the algorithms favor .",
    "however , in the bump problem , such `` big valley '' hypothesis does not hold because the global minimum is located on search space boundary .",
    "this property can help explain why lfo algorithms fail to model the bump landscape structure but succeed in other cases .",
    "finally , the hybrid lfo - sa appears to work as well as or better sa in all cases while keeping the similar search power to other lfo algorithms .",
    "it is obvious that lfo - sa behaves exactly like lfo - mls in the short run ( in @xmath14 , @xmath15 , @xmath16 and @xmath17 , see figs .",
    "[ fig : test - results - for - f0][fig : test - results - for - f6 ] ) and like sa in the long course ( in bump , see fig .  [",
    "fig : test - results - for - bump ] ) .",
    "the paper has proposed a set of optimization algorithms based on lvy flights .",
    "the algorithms were validated against simulated annealing on several hard continuous test functions .",
    "experiments have demonstrated that lfo ( lvy flights optimization ) could be superior to sa .",
    "algorithms implemented in this paper are rather basic , and there are rooms for further extension .",
    "for example , the two main parameters of mean lvy distance and the power index can be adjusted dynamically during the run . or one may wish to extend the idea of particle swarm optimization ( pso ) in the way that the whole population keeps continuous flying while dynamically adjusting speed and direction based on information collected so far .",
    "even each flying particle can be treated as an autonomous agent involving collective intelligent decision making . for those who are familiar with ga ,",
    "it is possible to extend the practice of ga in the way that at each generation , we select a set of particles in stead of the best one to form the next generation .",
    "m.  dorigo , v.  maniezzo , and a.  colorni , `` ant system : optimization by a colony of cooperating agents , '' _ systems , man , and cybernetics , part b : cybernetics , ieee transactions on _ , vol .",
    "26 , no .  1 ,",
    "pp . 2941 , 1996 .",
    "r.  c. eberhart and y.  shi , `` particle swarm optimization : developments , applications and resources , '' in _ evolutionary computation , 2001 .",
    "proceedings of the 2001 congress on _ , vol .",
    "1.1em plus 0.5em minus 0.4emieee , 2001 , pp .",
    "8186 .",
    "a.  corana , m.  marchesi , c.  martini , and s.  ridella , `` minimizing multimodal functions of continuous variables with the `` simulated annealing '' algorithm , '' _ acm transactions on mathematical software ( toms ) _ , vol .  13 , no .  3 , pp .",
    "262280 , 1987 ."
  ],
  "abstract_text": [
    "<S> this paper studies a class of enhanced diffusion processes in which random walkers perform lvy flights and apply it for global optimization . </S>",
    "<S> lvy flights offer controlled balance between exploitation and exploration . </S>",
    "<S> we develop four optimization algorithms based on such properties . </S>",
    "<S> we compare new algorithms with the well - known simulated annealing on hard test functions and the results are very promising . +   + * key words * : lvy flights , global optimization . </S>",
    "<S> + _ this is an edited version of a paper originally published in proceedings of second national symposium on research , development and application of information and communication technology _ </S>",
    "<S> ( ict.rda04__)__ , hanoi , sept 24 - 25 , 2004 . </S>"
  ]
}