{
  "article_text": [
    "single view 3d face shape estimation methods originally proposed using their 3d shapes for recognition  @xcite .",
    "this makes sense because 3d shapes are discriminative ",
    "different people have different face shapes  yet invariant to lighting , texture changes and more .",
    "indeed , previous work showed that when available , high resolution 3d face scans are excellent face representations which can even be used to distinguish between the faces of identical twins  @xcite .",
    "curiously , however , despite their widespread use , single view face reconstruction methods are rarely employed by modern face recognition systems . the highly successful 3d morphable models ( 3dmm ) , for example ,",
    "were only ever used for recognition in limited , controlled viewing conditions  @xcite . to our knowledge",
    ", there are no reports of successfully using single view face shape estimation  3dmm or any other method  to recognize faces in challenging unconstrained , _ in the wild _ settings .",
    "an important reason why this maybe so , is that these methods can be unstable in unconstrained viewing conditions .",
    "we later verify this quantitatively but it can also be seen in fig .",
    "[ fig : teaser ] which presents 3d shapes estimated from three unconstrained photos by three different methods ( fig .",
    "[ fig : teaser ]  ( b - d ) ) . clearly , though the same subject appears in all photos , _ shapes produced by the same method are either very different ( b , c ) or highly regularized and generic ( d)_. it is therefore unsurprising that these shapes are poor representations for recognition .",
    "it also explains why some recently proposed using coarse , simple 3d shape approximations only as proxies when rendering faces to new views rather than as face representations  @xcite .",
    "contrary to previous work , we show that robust and discriminative 3d face shapes can , in fact , be estimated from single , unconstrained images ( fig .",
    "[ fig : teaser ]  ( e ) ) .",
    "we propose estimating 3d facial shapes using a very deep convolutional neural network ( cnn ) to regress 3dmm shape and texture parameters directly from single face photos .",
    "we identify shortage of labeled training data as an obstacle to using data - hungry cnns for this purpose .",
    "we address this problem with a novel means for generating a huge labeled training set of unconstrained faces and their 3dmm representations .",
    "coupled with additional technical novelties , we obtain a method which is fast , robust and accurate .",
    "the accuracy of our estimated shapes is verified on the micc data set  @xcite and _ quantitatively shown to surpass the accuracy of other 3d reconstruction methods_. we further show that our estimated shapes are robust and discriminative by presenting face recognition results on the labeled faces in the wild ( lfw )  @xcite , youtube faces ( ytf )  @xcite and ijb - a  @xcite benchmarks . to our knowledge , _ this is the first time single image 3d face shapes are successfully used to represent faces from modern , unconstrained face recognition benchmarks_. finally , to promote reproduction of our results , we publicly release our code and models ..",
    "over the years , many attempts were made to estimate the 3d surface of a face appearing in a single view . before listing them",
    ", it is important to mention recent _ multi image _ methods which use image sets for reconstruction ( e.g. ,  @xcite ) .",
    "although these methods produce accurate 3d reconstructions , they require many images from multiple sources to produce a single 3d face shape whereas we reconstruct faces from single images .",
    "methods for _ single view _",
    "3d face reconstructions can broadly be categorized into the following types .    * statistical shape representations * , such as the widely popular 3dmm  @xcite , use many aligned 3d face shapes to learn a distribution of 3d faces , represented as a high dimensional subspace .",
    "each point on this subspace is a parameter vector representing facial geometry and sometimes expression and texture .",
    "reconstruction is performed by searching for a point on this subspace that represents a face similar to the one in the input image .",
    "these methods do not attempt to produce discriminative facial geometries and indeed , as mentioned earlier , were only used for face recognition under controlled settings .",
    "the very recent method of  @xcite also uses a cnn to regress 3dmm parameters for face photos .",
    "they too recognize absence of training data as a major concern .",
    "contrary to us , they propose synthesizing training faces with known geometry by sampling from the 3dmm distribution .",
    "this approach produces synthetic looking photos which can easily cause overfitting problems when training large networks  @xcite .",
    "they were therefore able to train only a shallow residual network ( seven layers compared to our 101 ) and their estimated shapes were not shown to be more robust or discriminative than other methods .    * scene assumption methods . * in order to obtain _ correct _ reconstructions , some make strong assumptions on the scene and the viewing conditions in the input image .",
    "shape from shading methods  @xcite , for example , make assumptions on the light sources , facial reflectance and more .",
    "others instead use facial symmetry  @xcite .",
    "the assumptions they and others make often do not hold in practice , limiting the application of these methods to controlled settings .",
    "* example based methods * , beginning from the work of  @xcite and more recently  @xcite , modify the 3d surface of example face shapes , fitting them to the face appearing in input photo . these methods favor robustness to challenging viewing conditions over detailed reconstructions .",
    "they were thus only used for face recognition to synthesize new views from unseen poses .",
    "* landmark fitting methods . *",
    "finally , some reconstruction techniques fit a 3d surface to detected facial landmarks rather than to face intensities directly .",
    "these include methods designed for videos ( e.g. ,  @xcite ) and the cnn based approaches of  @xcite .",
    "these focus more on landmark detection than 3d shape estimation and so do not attempt to produce detailed and discriminative facial geometries .",
    "we propose to regress 3dmm face shape parameters directly from an input photo using a very deep cnn .",
    "ostensibly , cnns are ideal for this task : after all , they are being successfully applied to many related computer vision tasks . but",
    "despite their success , apart from  @xcite , we are unaware of published reports of using cnns for 3dmm parameter regression .",
    "we believe cnns were not used here because this is a regression problem where both the input photo and the output 3dmm shape parameters are high dimensional . solving such problems requires deep networks and",
    "these need massive amounts of training data .",
    "unfortunately , existing unconstrained face sets with ground truth 3d shapes are far too small for this purpose and obtaining large quantities of 3d face scans is labor intensive and impractical .",
    "we therefore instead leverage three key observations .    1 .",
    "as discussed in sec .",
    "[ sec : related ] , accurate 3d estimates can be obtained by using _ multiple images _ of the same face .",
    "2 .   unlike the limited availability of ground truth",
    "3d face shapes , there is certainly no shortage of challenging face sets containing multiple photos per subject .",
    "highly effective deep networks are available for the related task of extracting robust and discriminative face representations for face recognition .    from ( 1 ) , we have a reasonable way of producing 3d face shape estimates for training , as surrogates for ground truth shapes : by using a robust method for multi - view 3dmm estimation .",
    "getting multiple photos for enough subjects is very easy ( 2 ) .",
    "this abundance of examples further allows balancing any reconstruction errors with potentially limitless subjects to train on .",
    "finally , ( 3 ) , a state of the art cnn for face recognition may be fine - tuned to this problem .",
    "it should already be tuned for unconstrained facial appearance variations and trained to produce similar , discriminative outputs for different images of the same face .          to generate training data",
    ", we use a simple yet effective _ multi image _ 3dmm estimation method , loosely based on the one recently proposed by  @xcite .",
    "we run it on the unconstrained faces in the casia webface dataset  @xcite .",
    "these multi image 3dmm estimates are then used as ground truth 3d face shapes when training our cnn 3dmm regressor .",
    "multi image 3dmm reconstruction is performed by first estimating 3dmm parameters from the 500k single images in casia .",
    "3dmm estimates for images of the same subject are then aggregated into a single 3dmm per subject ( @xmath010k subjects ) .",
    "this process is described next ( see also , fig .",
    "[ fig : system ] ) .    * the 3dmm representation . *",
    "our system uses the popular basel face model ( bfm )  @xcite .",
    "it is a publicly available 3dmm representation and one of the state of the art methods for single view 3d face modeling .",
    "a face is modeled by decoupling its shape and texture giving the following two independent generative models .",
    "@xmath1 here , the vectors @xmath2 and @xmath3 are the mean face shape and texture , computed over the aligned facial 3d scans in the basel faces collection and represented by the concatenated 3d coordinates of the 3d point clouds and the concatenated rgb values of their textures .",
    "matrices @xmath4 and @xmath5 are the principle components , computed from the same aligned facial scans",
    ". finally , @xmath6 and @xmath7 are each 99d parameter vectors , representing shape and texture respectively .",
    "* single image 3dmm fitting . * fitting a 3dmm to each training image is performed with a slightly modified version of the two standard methods of  @xcite and  @xcite .",
    "given an image @xmath8 , we estimate parameter vectors @xmath9 and @xmath10 which represent a face similar to the one in  @xmath8 ( eq .  ( [ eq:3dmm ] ) ) . unlike previous work , we begin processing by applying the clnf  @xcite state of the art facial landmark detector .",
    "it provides @xmath11 facial landmarks @xmath12 , @xmath13 , and a confidence score value @xmath14 ( which we use later on ) .",
    "landmarks are used to obtain an initial estimate for the pose of the input face , in the reference 3dmm coordinate system .",
    "pose is represented by six degrees of freedom for rotation , @xmath15 $ ] , and translation , @xmath16 $ ] , and estimated similar to  @xcite .",
    "3dmm fitting then proceeds by optimizing over the shape , texture , pose , illumination , and color model following  @xcite .",
    "we found that clnf makes occasional localization errors . to introduce more stability",
    ", our optimization also uses the edge - based cost of  @xcite . for more details on this optimization ,",
    "we refer to  @xcite and  @xcite .",
    "once the optimization converges , we take the shape and texture parameters , @xmath9 and @xmath10 , from the last iteration as our single image 3dmm estimate for the input image @xmath8 .",
    "importantly , though this process is known to be computationally expensive , it is applied in our pipeline only in preprocessing and once for every training image .",
    "we later show our cnn regressor to be much faster .",
    "* multi image 3dmm fitting .",
    "* although a number of multi image 3d face shape estimation methods were proposed in the past , we found the following simple approach , inspired by the very recent work of  @xcite , to be particularly effective .",
    "specifically , we pool the shape and texture 3dmm parameters @xmath17 , i\\in 1 .. n$ ] across all the @xmath18 single view estimates belonging to the same subject .",
    "pooling is performed by element wise weighted averaging of the @xmath18 3dmm vectors , resulting in a single 3dmm estimate for that subject , @xmath19 .",
    "that is , @xmath20 where @xmath21 are normalized per - image confidences provided by the clnf facial landmark detector .",
    "note that unlike  @xcite , we do not use a rank - list based on distances of normals as a quality measure to pool 3dmm parameters , instead taking the landmark detection confidence measure for these weights . following this process ,",
    "each casia subject is associated with a single , pooled 3dmm parameter vector @xmath19 . for ease of notation , henceforth we will drop the _ hat _ when denoting pooled features , assuming all training set 3dmm parameters were pooled .      following the process described in sec .",
    "[ sec : gendata ] , each subject in our data set is associated with a number of images and a single , pooled 3dmm .",
    "we now use this data to learn a function which , ideally , regresses the _ same _ pooled 3dmm feature vector for different photos of the same subject .    to this end , we use a state of the art cnn , trained for face recognition .",
    "we use the very deep resnet architecture  @xcite with 101 layers , recently trained for face recognition by  @xcite .",
    "we modify its last fully - connected layer to output the 198d 3dmm feature vector @xmath22 .",
    "the network is then fine - tuned on casia images using the pooled 3dmm estimates as target values ; different images of the same subject presented to the cnn using the same target 3dmm shape .",
    "we note that we also tried using the vgg - face cnn of  @xcite with 16 layers .",
    "its results were similar to those obtained by the resnet architecture , though somewhat lower .",
    "* the asymmetric euclidean loss . * training our network requires some care when defining its loss function .",
    "3dmm vectors , by construction , belong to a multivariate gaussian distribution with its mean on the origin , representing the mean face ( sec .",
    "[ sec : gendata ] ) . consequently , during training , using the standard euclidean loss to minimize distances between estimated and target 3dmm vectors will favor estimates closer to the origin : these will have a higher probability of being closer to their target values than those further away . in practice",
    ", we found that a network trained with the euclidean loss tends to output less detailed faces ( fig .",
    "[ fig : qual_loss ] ) .    to counter this bias towards a mean face shape , we introduce an _ asymmetric euclidean loss_. it is designed to encourage the network to favor estimates further away from the origin by decoupling under - estimation errors ( errors on the side of the 3dmm target closer to the origin ) from over - estimation errors ( where the estimate is further out from the origin than the target ) .",
    "it is defined by :    @xmath23    using the element - wise operators : @xmath24 here , @xmath22 is the target pooled 3dmm value , @xmath25 is the output , regressed 3dmm and @xmath26 control the trade - off between the over and under estimation errors .",
    "when both equal 1 , this reduces to the traditional euclidean loss . in practice , we set @xmath27 , @xmath28 , thus changing the behavior of the training process , allowing it to escape under - fitting faster and encouraging the network to produce more detailed , realistic 3d face models ( fig .  [",
    "fig : qual_loss ] ) .",
    "loss and ( c ) our proposed asymmetric @xmath29 loss . ]",
    "* network hyperparameters . * eq .",
    "( [ eq : loss ] ) is solved using stochastic gradient descent ( sgd ) with a mini - batch of size 144 , momentum set to 0.9 and with regularization over the weights provided by @xmath29 with a weight decay of 0.0005 . when performing back - propagation , we learn the inner product layer ( fc ) after pool5 faster , setting the learning rate to @xmath30 , since it is trained from scratch for the regression problem .",
    "other network weights are updated with a learning rate an order of magnitude lower .",
    "when the validation loss saturates , we decrease learning rates by an order of magnitude , until the validation loss stops decreasing .",
    "* discussion : render - free 3dmm estimator . *",
    "it is important to note that by choosing to use a cnn to regress 3dmm parameters , we obtain a function that is _ render - free_. that is , 3dmm parameters are regressed directly from the input image , without an optimization process which renders the face and compares it to the photo , as do existing methods for 3dmm estimation ( including our method for generating training data in sec .",
    "[ sec : gendata ] ) . by using a cnn ,",
    "we therefore hope to gain not only improved accuracy , but also much faster 3dmm estimation speeds .",
    "the cnn we train in sec .",
    "[ sec : learning ] represents a function @xmath31 , giving us 3dmm parameters @xmath25 for an input image @xmath8 .",
    "we later use our 3dmm estimates in face recognition benchmarks , to test how robust and discriminative they are .",
    "we next describe the method used for that purpose to evaluate the similarity of two face shapes and textures to determine if they represent the same subject .    *",
    "3d-3d recognition with a single image .",
    "* we perform face recognition using the 3dmm parameters regressed by our network : by using the 3dmm parameters @xmath25 as face descriptors .",
    "because different benchmarks often exhibit specific appearance biases , we apply principal component analysis ( pca ) , learned from the training splits of the test benchmark , to adapt our estimated parameter vectors to the benchmark .",
    "signed , element wise square rooting of these vectors is then used to further improve representation power  @xcite .",
    "finally , the similarity of two faces , @xmath32 , is evaluated by computing their cosine score :    @xmath33    * 3d-3d recognition with multiple - images . * in some scenarios ,",
    "a subject is represented by a set of images , rather than just one .",
    "this is the case in the ytf benchmark  @xcite where videos are used , each containing multiple frames , and in the recent ijb - a  @xcite , which uses _ templates _ containing heterogeneous visual data ( images , videos and possibly more ) .",
    "we use the same pipeline for single images also for image sets . here , however , 3dmm parameters for different images or frames are first pooled using eq .",
    "( [ eq : pooling ] ) . unlike the process applied in sec .",
    "[ sec : gendata ] , all images here have equal weights , as we do not run landmark detection prior to 3dmm fitting with our cnn ( see below ) .",
    "when using templates with both videos and images , following  @xcite , we first pool the 3dmm estimates for frames in each video separately , obtaining one 3dmm per video .",
    "we then pool these 3dmms with those of other images in the same template .    * face alignment . *",
    "facial landmark detection and face alignment are known to improve recognition accuracy ( e.g. ,  @xcite ) .",
    "in fact , the recent , related work of  @xcite manually assigned landmarks before using their 3dmm fitting method for recognition on controlled images .",
    "we , however , _ did not align faces _ beyond using the bounding boxes provided in their data sets .",
    "we found our method robust to misalignments and so spared the runtime this required .",
    "we test our proposed method , comparing the accuracy of its estimated 3d shapes , its speed and its ability to represent faces for recognition with existing methods . importantly , _ we are unaware of any previous work on single view 3d face shape estimation which reported as many quantitative tests as we do _ , in terms of the number of benchmarks used , the number of baseline methods compared with and the level of difficulty of the photos used in these tests .    specifically , we evaluate the accuracy of our estimated 3d shapes using videos and photos and their corresponding scanned , ground truth 3d shapes from the micc florence faces dataset  @xcite ( sec .",
    "[ sec : exp : acc ] ) . to test",
    "how discriminative and robust our shapes are when estimated from unconstrained images , we perform single image and multi image face recognition using the lfw  @xcite , ytf  @xcite and the new iarpa janus benchmark - a ( ijb - a )  @xcite ( sec .",
    "[ sec : exp : rec ] ) .",
    "finally we also provide qualitative results in sec .",
    "[ sec : exp : qual ] .    as baseline 3d reconstruction methods we used standard 3dmm fitting  @xcite , which we implemented ourselves , the flow - based method of  @xcite , the edge based method of  @xcite , the multi resolution , multi - view approach of  @xcite and the recent 3ddfa  @xcite , were all tested with their authors implementations .      the micc dataset  @xcite contains challenging face videos of 53 subjects .",
    "the videos span the range of controlled to challenging unconstrained outdoor settings . for each of the subjects in these videos ,",
    "the data set contains also a ground - truth 3d model acquired using a structured - light scanning system with high precision .",
    "this allows comparing our 3d face shape estimates with the ground truth shapes .",
    "[ tab : micc ]    [ tab : lfw - ytf ]    lccl*4y method & 3d & text .",
    "& tar-10% & tar-1% & rank-1 & rank-5 & rank-10 + ( r)1 - 1 ( l)2 - 8 augnet & &  & 88.6@xmath341.6 & 90.6@xmath341.2 & 96.2@xmath340.6 & 97.7@xmath340.4 + ( r)1 - 1 ( l)2 - 8 & & & 60.7@xmath342.0 & 30.6@xmath343.2 & 34.3@xmath342.2 & 55.1@xmath342.1 & 65.1@xmath342.0 + & & & 71.1@xmath341.8 & 39.5@xmath344.8 & 49.8@xmath342.5 & 69.5@xmath341.4 & 76.8@xmath341.0 + & & & 75.4@xmath341.6 & 46.6@xmath345.1 & 57.2@xmath341.9 & 74.4@xmath341.3 & 80.5@xmath341.1 + ( r)1 - 1 3ddfa__+p .",
    "_ _ & & & 43.3@xmath342.5 & 12.5@xmath341.9 & 16.7@xmath341.9 & 38.3@xmath342.7 & 51.3@xmath343.0 + ( r)1 - 1 & & & 86.0@xmath341.7 & 55.9@xmath345.5 & 72.3@xmath341.4 & 88.0@xmath341.4 & 91.8@xmath341.1 + & & & 83.5@xmath342.2 & 50.3@xmath345.8 & 70.9@xmath341.5 & 87.3@xmath341.1 & 91.5@xmath341.0 + & & & & & & & +    [ tab : ijba ]    these videos were used for single image and multi frame 3d reconstructions , comparing our method to existing alternatives . in these tests , estimated and ground truth shape parameters were converted to 3d using eq .",
    "( [ eq:3dmm ] ) , cropped at a radius of 95@xmath35 around the tip of the nose and globally aligned using the standard , rigid iterative closest point ( icp ) method  @xcite , obtaining @xmath36 , respectively .",
    "they were additionally projected to a frontal view , obtaining depth maps @xmath37 and @xmath38 .",
    "estimation accuracy was then computed with standard error measures  @xcite :    * * 3d root mean square error * ( 3drmse ) : + @xmath39 * * root mean square error * ( rmse ) : + @xmath40 * @xmath41 : @xmath42 * * relative error * ( rel ) : @xmath43    here , @xmath44 is the number of 3d vertices and @xmath45 the number of pixels in these representations .",
    "single view estimation was performed on the most frontal frame .",
    "multi frame reconstructions were given the entire videos .",
    "our multi frame results were produced by pooling 3dmm estimates from different frames , using eq .",
    "( [ eq : pooling ] ) , with equal weights used for all frames . for all 3dmm fitting baselines  @xcite , we found that estimating shape , texture _ and expression _ parameters but using only shape and texture for comparisons , gave the best results .",
    "this approach was therefore used in all our tests .",
    "results are reported in tab .",
    "[ tab : micc ] .",
    "error rates are averaged across all videos and provided @xmath34 standard deviation .",
    "our method is clearly the most accurate .",
    "remarkably , both its single view and multiple frame versions outperform the method used to produce the training set target 3dmm labels ( 3dmm__+pool _ _ )",
    ". this may be due to our use of such a large dataset to train the cnn and their known robustness to training label errors and noise  @xcite .",
    "our estimates are more accurate than the very recent state - of - the - art .",
    "this includes 3ddfa  @xcite which fits 3dmm parameters by using a cnn to deal with large pose variations as well as  @xcite and  @xcite .",
    "to better appreciate these numbers , note that our improvement over standard 3dmm fitting is comparable to their improvement over using a unmodified , generic basel face shape  @xcite .      tab .",
    "[ tab : micc ] ( rightmost column ) also reports the average , per image runtime in seconds , required by the various methods to predict 3d face shapes . we compared our approach with iterative methods such as classic 3dmm implementations  @xcite , the flow - based method of  @xcite and also with a recent cnn based method  @xcite .    as mentioned earlier",
    ", our method is render - free , without optimization loops which render the estimated parameters and compare them to the input photo .",
    "unsurprisingly , at 0.088s ( @xmath011hz ) , our cnn is _ several orders of magnitude faster _ predicting 3dmm parameters than most of the methods we tested .",
    "the second fastest method , by a wide gap , is the 3ddfa of  @xcite , requiring 0.146s ( @xmath07hz ) for prediction .",
    "runtime was measured on two different systems .",
    "all our baselines required ms - windows to run and were tested on an intel core i7 - 4820k cpu @ 3.7ghz with 16 gb ram and a nvidia geforce gtx 770 .",
    "our method requires linux and so was tested on an intel xeon cpu @ 3.60ghz , with 12 gb of ram and geforce gtx 590 .",
    "importantly , the system used to measure our runtime is the slower of the two .",
    "our runtimes may therefore be exaggerated .",
    "we next consider the robustness of our 3dmm estimates and how discriminative they are .",
    "we aim to see if our 3dmm estimates for different unconstrained photos of the same person are more similar to each other than to those of other subjects . an effective way of doing this is by testing our 3dmm estimates on face recognition benchmarks .",
    "we emphasize that our goal is _ not _ to set new face recognition records . doing so would require competing with state of the art systems designed exclusively for that problem .",
    "we provide performances of relevant ( though not necessarily state of the art ) recognition systems only as a reference .",
    "nevertheless , our results below are the highest we know of that were obtained with meaningful features ( here , shape and texture parameters ) rather than opaque representations .",
    "our tests use the pipeline described in sec .",
    "[ sec : matching ] and report multiple recognition metrics for verification ( in lfw and ytf ) and identification metrics ( in ijb - a ) .",
    "these metrics are verification accuracy , 100%-eer ( equal error rate ) , area under the curve ( auc ) , and recall ( true acceptance rate ) at two cut - off points of the false alarm rate ( tar-\\{10%,1% } ) . for identification",
    "we report the recognition rates at various ranks from the cmc ( cumulative matching characteristic ) . for each tested method",
    "we also indicate its use of estimated 3d shape and/or texture . finally , bold values indicate best scoring 3d reconstruction methods .",
    "* labeled faces in the wild ( lfw ) *  @xcite results are provided in tab .  [ tab : lfw - ytf ] ( top ) and fig .",
    "[ fig : allcurves ] ( left ) .",
    "evidently , the shapes estimated by 3ddfa  @xcite are only slightly more robust and discriminative than the classical eigenfaces  @xcite .",
    "fitting 3dmms using  @xcite does better , but falls behind the hybrid method of  @xcite , one of the first results on lfw , now nearly a decade old . both results suggest that the shapes estimated by these methods are unstable in unconstrained settings and/or are too generic . by comparison ,",
    "recognition performances with our estimated 3dmm parameters is not far behind those recently reported by facebook , using their multi - cnn approach trained on four million images  @xcite .",
    "* youtube faces ( ytf ) *  @xcite accuracy on ytf videos is reported in tab .",
    "[ tab : lfw - ytf ] ( bottom ) and fig .",
    "[ fig : allcurves ] ( mid - left ) .",
    "though video frames in this set are often low in quality and resolution , our method performs well .",
    "it is outperformed by the facebook cnn ensemble system  @xcite , explicitly designed for face recognition , by an auc gap of only @xmath01% .",
    "the 3dmm shapes and textures estimated by other methods perform far worst , with  @xcite doing only slightly better than the mbgs face recognition system  @xcite , which is the oldest result on that benchmark and  @xcite falling far behind .",
    "* iarpa janus benchmark a. ( ijb - a ) *  @xcite  released recently , ijb - a was designed to offer elevated challenges compared to other face recognition benchmarks . in particular",
    ", it presents faces in near profile poses , almost nonexistent in previous face sets .",
    "it further contains faces in extremely low resolution and often strongly affected by noise .",
    "we evaluated both the face verification ( 1:1 ) and recognition ( 1:n ) protocols and report results in tab .",
    "[ tab : ijba ] and fig .",
    "[ fig : allcurves ] ( mid - right , right ) . here too",
    ", performances adopt the same pattern as in the previous two benchmarks , with 3d shapes estimated by 3ddfa  @xcite performing far worst than other methods .",
    "our own method performs quite well , though it is outperformed by a wide margin by the very recent face recognition system of  @xcite , which was designed for this set .",
    "errors on faces from micc videos and their ground truth 3d shapes .",
    "left to right , top to bottom : frame from input and 3d ground - truth shape ; the generic face ; estimates for flow - based method  @xcite , huber et al .",
    "@xcite , 3ddfa  @xcite , bas et al .",
    "@xcite , 3dmm _ + pool _",
    "@xcite , our method _ + pool_. ]          fig .",
    "[ fig : heatmap ] provides a qualitative comparison of the surface errors in @xmath35 for different methods for a subject in the micc dataset .",
    "our method produces visually smaller errors compared to ground - truth .",
    "the areas around the nose and mouth in particular have very low errors , while other methods are more sensitive in these regions ( e.g 3ddfa  @xcite ) .",
    "we provide also qualitative 3d reconstructions of faces in the wild , using images from lfw and single frames from ytf videos .",
    "[ fig : lfwquall ] presents these results showing both rendered 3d shapes and ( when available ) also its estimated texture .",
    "these results show that our method generates more visually plausible 3d and texture estimates compared with those produced by other methods .",
    "[ fig : heatmap ] also shows a few failure cases , here due to facial hair which was missing from the original 3dmm representation and extreme out - of - plane rotation which produced a thin , unrealistic 3d shape .",
    "we show that existing methods for estimating 3d face shapes may either be sensitive to changing viewing conditions , particularly in unconstrained settings , or too generic .",
    "their estimated shapes therefore do not capture identity very well , despite the fact that true 3d face shapes are known to be highly discriminative .",
    "we propose instead to use a very deep cnn architecture to regress 3dmm parameters directly from input images .",
    "we provide a solution to the problem of obtaining sufficient labeled data to train this network .",
    "we show our regressed 3d shapes to be more accurate than those of alternative methods .",
    "we further run extensive face recognition tests showing these shapes to be robust to unconstrained viewing conditions and discriminative .",
    "our results are furthermore the highest recognition results we know of , obtained with interpretable representations rather than opaque features .",
    "we leave it to future work to regress more 3dmm parameters ( e.g. , expressions ) and design state of the art recognition systems using these shapes instead of the abstract features used by others .",
    "this research is based upon work supported in part by the office of the director of national intelligence ( odni ) , intelligence advanced research projects activity ( iarpa ) , via iarpa 2014 - 14071600011 .",
    "the views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements , either expressed or implied , of odni , iarpa , or the u.s .",
    "government is authorized to reproduce and distribute reprints for governmental purpose notwithstanding any copyright annotation thereon .",
    "v.  blanz , s.  romdhani , and t.  vetter .",
    "face identification across different poses and illuminations with a 3d morphable model . in _ int .",
    "conf . on automatic face and gesture recognition _ ,",
    "pages 192197 , 2002 .",
    "g.  b. huang , m.  ramesh , t.  berg , and e.  learned - miller .",
    "labeled faces in the wild : a database for studying face recognition in unconstrained environments .",
    "technical report 07 - 49 , umass , amherst , october 2007 .",
    "p.  huber , g.  hu , r.  tena , p.  mortazavian , w.  koppen , w.  christmas , m.  rtsch , and j.  kittler . a multiresolution 3d morphable face model and fitting framework . in _ int .",
    "conf . on computer vision theory and applications _ , 2016 .",
    "k.  kim , t.  baltruaitis , a.  zadeh , l .- p .",
    "morency , and g.  medioni .",
    "holistically constrained local model : going beyond frontal poses for facial landmark detection . in _ proc .",
    "british mach .",
    "vision conf .",
    "_ , 2016 .",
    "b.  f. klare , b.  klein , e.  taborsky , a.  blanton , j.  cheney , k.  allen , p.  grother , a.  mah , m.  burge , and a.  k. jain . pushing the frontiers of unconstrained face detection and recognition : iarpa janus benchmark - a . in _ proc .",
    "vision pattern recognition _ , 2015 .",
    "i.  masi , a.  tran , t.  hassner , j.  t. leksut , and g.  medioni .",
    "do we really need to collect millions of faces for effective face recognition ? in _",
    "european conf .",
    "comput . vision _ , 2016 .",
    "available  www.openu.ac.il/home/hassner/projects/augmented_faces .",
    "s.  romdhani and t.  vetter . estimating 3d shape and texture using pixel intensity , edges , specular highlights , texture constraints and a prior . in _ proc .",
    "vision pattern recognition _ ,",
    "volume  2 , pages 986993 , 2005 .",
    "h.  tang , y.  hu , y.  fu , m.  hasegawa - johnson , and t.  s. huang .",
    "real - time conversion from a single 2d face image to a 3d text - driven emotive audio - visual avatar . in _ int",
    ". conf . on multimedia and expo _ , pages 12051208 .",
    "ieee , 2008 ."
  ],
  "abstract_text": [
    "<S> the 3d shapes of faces are well known to be discriminative . yet despite this , they are rarely used for face recognition and always under controlled viewing conditions . </S>",
    "<S> we claim that this is a symptom of a serious but often overlooked problem with existing methods for single view 3d face reconstruction : when applied `` in the wild '' , their 3d estimates are either unstable and change for different photos of the same subject or they are over - regularized and generic . in response , we describe a robust method for regressing discriminative 3d morphable face models ( 3dmm ) . </S>",
    "<S> we use a convolutional neural network ( cnn ) to regress 3dmm shape and texture parameters directly from an input photo . </S>",
    "<S> we overcome the shortage of training data required for this purpose by offering a method for generating huge numbers of labeled examples . </S>",
    "<S> the 3d estimates produced by our cnn surpass state of the art accuracy on the micc data set . coupled with a 3d-3d face matching pipeline , </S>",
    "<S> we show the first competitive face recognition results on the lfw , ytf and ijb - a benchmarks using 3d face shapes as representations , rather than the opaque deep feature vectors used by other modern systems . </S>"
  ]
}