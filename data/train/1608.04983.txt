{
  "article_text": [
    "originating from the same speech source usually appear differently due to a variety of acoustic reverberation effects . in speech recognition",
    ", these acoustic effects result in mismatches between trained speech recognition models and input speech .",
    "two general approaches for reducing acoustic mismatch include feature mapping and model adaptation . in feature mapping techniques , input signal waveforms or feature vectors",
    "are converted to their enhanced versions before being fed into a recognizer .",
    "this is done using front - end processing techniques such as packet loss concealment [ 1 ] , linear filtering [ 2 ] , [ 3 ] , spectral enhancement [ 4]-[6 ] , and feature enhancement [ 7 ] , [ 8 ] , which reflect long - term acoustic context . the first approach , termed linear filtering , dereverberates in time or transform domains , while spectral enhancement dereverberates corrupted power spectra .",
    "additionally , feature enhancement aims to directly remove the effect of reverberation from corrupted feature vectors .",
    "recently , deep neural networks ( dnns ) have been used for matching reverberant speech to its anechoic version [ 9]-[14 ] .",
    "the mapper is trained with an architecture of multiple - layers , where the input is the spectral representation of reverberant speech and the desired output is that of anechoic speech .",
    "hence , the feature mapping design can be treated as a problem during system identification , with a set of input and corresponding output feature vector sequences .",
    "notice that this approach is still confined to the front - end of the speech recognition system , and thus the recognition results do not affect the design of the dnn - based feature enhancement .",
    "another possible approach to reduce this mismatch is to train the acoustic model by using far more data under various reverberant conditions , which adjusts the speech recognition model parameters to more closely fit the input speech signal .",
    "this approach is termed the back - end - based speech recognition system , which includes a hidden markov model ( hmm ) adaptation , such as the maximum likelihood linear regression ( mllr ) [ 15 ] and the maximum _ a posteriori _ ( map ) adaptation [ 16 ] .",
    "these techniques can also be used to mitigate the mismatch between clean hmms and reverberant data , but their recognition performance in reverberant environments is often insufficient .    in recent years",
    ", acoustic modeling for the emission distribution of hmms in speech recognition has been successfully replaced by neural networks with multiple - layers , which are generatively pre - trained without the use of discriminative information .",
    "once generative pre - training is performed , discriminative fine - tuning ( using back - propagation ) adjusts the weights to improve their ability to predict a probability distribution over the states of monophone hmms . more recently",
    ", neural network has been used to jointly train a single dnn for both feature mapping and acoustic modeling in noisy environments [ 14 ] , [ 17 ] , [ 18 ] . instead of extracting acoustic features from enhanced speech ,",
    "dnns are employed as highly nonlinear mapping functions for the estimated clean speech features obtained from noisy speech .",
    "then , a hybrid dnn architecture is designed in order to jointly train dnns for both feature mapping and acoustic modeling .",
    "consequently , the output layer of feature mapping becomes the input layer for acoustic modeling .",
    "thus , joint training enables error back - propagation up to the feature mapping layer . to summarize the previous studies :     1",
    "can we handle a wide range of sophisticated reverberation in real - world situations , using a single dnn - based acoustic model ?     2 .",
    "no joint training techniques incorporating both feature mapping for dereverberation and acoustic modeling have been developed .    to answer the first question",
    ", it is worth mentioning the neural network ensemble , which builds a set of separately trained neural networks and combines the sets to form the unified prediction model [ 19]-[27 ] .",
    "each trained neural network in the ensemble can serve a different role in modeling and can be applied to various deep learning systems to achieve greater recognition accuracy .",
    "indeed , there have been efforts to build ensemble acoustic models ( eams ) by using neural networks for speech recognition .",
    "these techniques have generally exploited the sensitivity of acoustic models in order to yield inter - model diversity .",
    "motivated by insights mentioned above , we propose an ensemble of dnn acoustic models under a variety of reverberant conditions . toward this end , we first split the reverberant data into multiple cases according to reverberation time 60 ( @xmath0 ) in a training step .",
    "next , one acoustic model is trained in a conventional manner for each @xmath0 range , where @xmath0 is one of the main parameters describing the reverberant degree .",
    "once the eams using dnns are trained , two types of dnns are chosen in a probabilistic manner .",
    "this is done in a test step for which the probability is found in an independent module based on map criteria . as for the map criteria , maximum likelihood ( ml )",
    "estimation is used for the blind estimation of @xmath0 [ 28 ] , [ 29 ] , which is based on a statistical model for representing sound decay under reverberant conditions . indeed , the posterior probability outputs from two acoustic models are combined using a probabilistic average , and this combination yields superior performance when compared to a single acoustic model .",
    "in addition , inspired by the joint training technique [ 14 ] , we propose jointly training each model in the ensemble for both feature mapping and acoustic modeling , which enables us to use the back - propagation algorithm up to the feature mapping layer . as a result ,",
    "the feature mapping network is closely refined to the specified acoustic model in each network of ensemble models by connecting the output layer of the feature mapping dnn to the input layer of the dnn acoustic models .",
    "each jointly trained dnn acoustic model is used again to develop the eam , which is then selected in the same manner as the @xmath0-based map criteria .",
    "the remainder of this paper is organized as follows . in the next section ,",
    "we review the conventional methods for robust speech recognition . in section iii",
    ", we describe the design of the proposed ensemble joint acoustic model ( ejam ) using ml and a model - selecting method .",
    "extensive evaluation of the proposed method is discussed in section iv , and conclusions are presented in section v.",
    "we begin with a brief description of related work to provide sufficient background for understanding our approach . in the ensemble model ,",
    "we first elaborate on the design of the ensemble classifier . in the second subsection ,",
    "dnn joint training is introduced .",
    "the ensemble classifier is known to be an effective approach for enhancing the recognition accuracy [ 21]-[23 ] for which individual models are independently designed , and the decoding word hypotheses of multiple models are combined to score the speech frames . in a recent study ,",
    "multiple datasets were generated through normalized noisy features by which beamforming and speech enhancement techniques are used , and additional speaker related features as well as other auxiliary features are also included [ 23 ] .",
    "one acoustic model is trained from each dataset , which builds up the acoustic model ensemble , as illustrated in fig .",
    "then , the eam outputs are combined via a simple posterior strategy , in which the output probability for the triphone hmm state @xmath1 is obtained as the average of the state posterior probabilities @xmath2 of the @xmath3th acoustic model ( @xmath4 ) as given by : @xmath5 where @xmath6 is an input feature vector .",
    "the state posterior probabilities @xmath7 are utilized in decoding searches . in averaging posterior probabilities , simple averaging methods [ 21 ] , [ 23 ] and weighted averaging method [ 22 ]",
    "have been presented .",
    "it is worth noting that the recognition performance of the combined model is enhanced when models are used from a variety of different sources . for a more detailed discussion of the eam",
    ", please refer to [ 23 ] .          instead of extracting acoustic features from the speech waveform",
    ", the dnn is used as a nonlinear feature mapping function .",
    "then , the joint training method is developed by integrating the dnn for feature mapping and the dnn for acoustic modeling , and subsequently jointly training the integrated dnn , as shown in fig .",
    "2 . in feature mapping",
    ", the dnn is designed to estimate the clean speech feature from a noisy feature , for which minimizing the mean squared error ( mse ) between the dnn output and reference target clean speech feature can be described as follows : @xmath8 where @xmath9 and @xmath10 are the @xmath11-dimensional vectors of the estimated and reference clean features for the @xmath3th frame , respectively .",
    "@xmath12 is a @xmath11-dimensional vectors of input noisy features with the neighboring left and right @xmath13 frames as the acoustic context .",
    "additionally , @xmath14 and @xmath15 denote the weight and bias parameters , respectively , with @xmath16 representing the regularization weighting coefficient and @xmath17 denoting the mini - batch frame size .",
    "the acoustic model is then trained by using the enhanced features obtained from feature mapping and acoustic modeling dnn layers are stacked on top of the feature mapping layer .",
    "naturally , the output layer of feature mapping becomes the input layer for acoustic modeling .",
    "then , the error back - propagation algorithm is utilized in order to jointly train the single dnn , which includes both feature mapping and acoustic modeling .",
    "consequently , the jointly trained dnn is advantageous , in that feature mapping is refined to acoustic modeling ( and vice versa ) .",
    "this seamless connection between two dnns permits high levels of recognition accuracy .",
    "in this section , we introduce the proposed algorithm for the dnn ensemble model and ensemble of jointly trained dnn models .",
    "we then present the manner in which to combine the acoustic model ensemble , for which the blind estimation of @xmath0 is described .",
    "in short , we design seven different classes of neural networks for acoustic modeling , each of which quantifies a unique reverberant condition .",
    "after filterbank feature extraction from reverberant speech , features are divided into multiple training sets . for this , the reverberant condition is divided into seven points , from @xmath18 to @xmath19 , in increments of @xmath20 . from the dataset for each point ,",
    "the dnn - based eam is separately established using the pre - training and fine - tuning techniques as described in the previous section . as a result ,",
    "the eam consists of seven different dnns , as shown in fig .",
    "3 . in a test step ,",
    "the posterior weighted averaging technique is then applied to combine the results of the dnn ensemble .",
    "if we assume that @xmath17 acoustic models are generated from @xmath17 multiple datasets , the output probability at the @xmath3th acoustic model is defined by @xmath21 , where @xmath1 denotes the hmm states . for the eam ,",
    "the final posterior probability is computed with @xmath22 as @xmath23 by fusing the two weighted outputs from the two most likely dnns among seven different dnns ensemble .",
    "the weights are determined by the map probability computation , which is given by the blind ml estimation of @xmath0 [ 29 ] .",
    "specifically , to determine weights , we first need to blindly estimate @xmath0 , a core parameter for characterizing reverberant environments .",
    "blind estimation , which implies estimation of @xmath0 , is performed without prior knowledge of speech sources or room geometry .",
    "indeed , the diffuse tail of reverberation is instead mathematically modeled as a simplified noise decay curve [ 29 ] : @xmath24 where @xmath25 , @xmath26 , and @xmath27 are the real amplitude , decay rate , and unit step sequence , respectively .",
    "additionally , @xmath28 denotes the sampling period , and @xmath29 is a sequence of random variables . since the sequence @xmath30 for @xmath31",
    "is modeled by @xmath17 independent random variables , we can find an ml estimator of @xmath0 .",
    "thus , the log - likelihood function can be expressed as : @xmath32 where @xmath33 .",
    "then , the decay rate @xmath26 is estimated based on the ml , as given by : @xmath34 then , @xmath35 is transformed into @xmath0 as follows : @xmath36 note that we use a downsampling operation and simple pre - selection of possible sound decays in order to reduce the computational complexity and increase the online estimation speed .",
    "later , if the estimated @xmath0 falls to one of the seven points between @xmath37 and @xmath38 , the two most likely dnns ( @xmath39 and @xmath40 ) are chosen as the candidates to be combined as in ( 3 ) .",
    "other dnn models are ignored to avoid the unwanted effect of outliers . for this",
    ", two weights are determined by the ratio of likelihoods , both computed as in ( 5 ) at the two most likely @xmath0 points , given by : @xmath41 and @xmath42      0.25     0.23     0.23     0.23     0.23     0.23     0.23     0.23     0.23     in this subsection , we present the jointly trained dnn for the ensemble model by applying both feature mapping and acoustic modeling .",
    "thus , the ejam in this approach deals with reverberant speech at seven @xmath0 points , as in the previous eam , which can be described as a convolution of clean speech with the room impulse response ( rir ) at each @xmath0 point .",
    "the reverberant speech is employed as an input for feature mapping , for which the reverberant filterbank features are converted to the target clean filterbank features .",
    "thus , design of the feature mapping rule is regarded as a problem of system identification , with a set of input and corresponding output feature vector sequences .",
    "estimation of dnn model parameters relevant to feature mapping is performed based on three hidden layers with 2048 units in each layer by training to minimize the mse function between the input and output .",
    "a total of seven dnn models are established from @xmath18 to @xmath19 in increments of @xmath20 , as in the previous section .",
    "since feature mapping can solve the problem of system identification , an example of feature mapping is shown in fig .  4 , which includes the filterbank features of clean speech and reverberant speech with @xmath18 , @xmath43 , @xmath44 , and @xmath38 .",
    "note that the prominent distinction between dereverberant speech and reverberant speech can be seen in the smearing of word boundaries .",
    "once the training for feature mapping is completed , the acoustic modeling layer at each @xmath0 point is independently trained using the output of the corresponding feature mapping layer . as shown in fig .  2 , the acoustic modeling dnn , which includes seven hidden layers with 2048 hidden units in each layer ,",
    "is directly stacked on top of the feature mapping dnn .",
    "the combined ensemble dnn is jointly trained to minimize the total cross entropy error function by using the error back - propagation algorithm , as shown in fig .",
    "what remains is how to select the dnn from the ejam , established on each @xmath0 point .",
    "again , after the integration step for joint training is completed , the two joint dnns that maximize the likelihood at each time are identified .",
    "similar to the previous ensemble model , the ml - based weights are employed to achieve the final acoustic score @xmath45 for each feature @xmath6 , as in ( 3 ) .",
    "this section describes the performance evaluation of the proposed eam and ejam for distant speech recognition . in order to assess the proposed method",
    ", we present a number of experiments performed in various reverberant environments .",
    "moreover , the proposed method was compared with a conventional single dnn acoustic model and a single dnn acoustic model , which set the topological complexity equivalent to that of eam [ 30 ] .",
    "the proposed method was evaluated on timit db [ 31 ] , which was first applied to the rir generator [ 32 ] in order to simulate reverberant environments . as shown in fig .",
    "6 , we generated a simulated room with size @xmath46 , and varied reflection coefficients to yield specific @xmath0 conditions .",
    "the distance between the microphone and source was set to 50 cm in order to avoid close - talking scenarios . in order to simulate the system ,",
    "reverberation times were increased from @xmath37 to @xmath38 , which correspond to specific @xmath0 conditions . in time , 3696 utterances from timit were employed to form the training set in each @xmath0 condition . as a result ,",
    "the number of utterances used for training was @xmath47 , a number also used in building background models .",
    "the development set included 376 utterances mixed with seven @xmath48 for cross validation .",
    "it is worth noting that the test set was prepared to include 192 reverberant sentences , corresponding to seventy @xmath48 ( @xmath49-@xmath38 , increment of @xmath50 ) .",
    "note that no overlap was permitted in utterances in training , development , or test sets . in the case of speech features ,",
    "72 components were generated , including 24-dimensional filterbank features and their first - order and second - order derivatives .",
    "then , feature analysis was performed from each frame of 25 ms , with a 10 ms frame shift for the 16 khz speech waveforms .",
    "triphone modeling was used for hmms , each of which was modeled by three emitting states .",
    "the number of tied states was 2021 .",
    "we used a phone - based bigram language model estimated from training utterances .",
    "training of hmm parameters and decoding for speech recognition was carried out using the kaldi software [ 33 ] .      [",
    "cols=\"^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     we evaluated the performance of the proposed eam algorithm in terms of the phone error rate ( per ) compared to the single dnn background model ( sbm ) [ 30 ] .",
    "an sbm whose computational complexity was the same as that of the single network of the eam and which consists of seven hidden layers , was designed .",
    "further , for fair comparison , we developed an extended sbm ( esbm ) with the same computational complexity as the eam , and the esbm consisted of 10 hidden layers with 3990 units .",
    "additionally , two background models , eam and ejam , were trained using data recorded from @xmath37 to @xmath38 , for which a 792-dimensional feature vector consisting of 11 frames of 24-dimensional filterbank features with delta and delta - delta was used in the input layer . in the target layer ,",
    "2021 tied states were used , and the learning rate was 0.0001 with a value of 0.9 for momentum . in jointly training the ejam ,",
    "a 792-dimensional feature vector was used with three hidden layers , without the softmax output layer .",
    "each of the hidden layers had 2048 units .",
    "the target of the feature mapping dnn was a 792-dimensional feature vector of clean speech , and the learning rate and momentum were initially set to 0.0000001 and 0.9 , respectively .",
    "all dnns , including the sbm , esbm , eam , and ejam , were initialized using restricted boltzmann machine ( rbm ) pre - training followed by fine - tuning using the error back - propagation algorithm ( cross entropy for acoustic modeling and mse for feature mapping ) .",
    "the mini - batch size was set to be 512 for the stochastic gradient algorithm in the error back - propagation algorithm .",
    "comparison of the single background models and ensemble models under various reverberant environments , width=359 ]    in the test step , final acoustic scores were measured for the eam and ejam , and were compared to scores of the sbm and esbm ( figs .  3 , 5 ) .",
    "the proposed ensemble models yielded better performance than the single dnn - based background models in matched test conditions ( table  i ) . from this , the single matched model in the proposed ensemble network , including the eam and ejam , were superior to the single dnn - based background models for a given @xmath0 condition ( fig .",
    "it is also noteworthy that the esbm yielded a slightly worse performance than the sbm , particularly for high values of @xmath0 .",
    "this indicates that deeper layers ( e.g. esbm ) over the sbm do not exhibit an advantage if the different topological network structures are not presented in high reverberant conditions , unlike our presented ensemble models .",
    "0.35     0.35     0.35     in addition , we examined the performance of the eam and ejam in an online test condition . for this , the @xmath0 was blindly estimated at runtime in an ml fashion in order to find the weights for the ensemble structure .",
    "this evaluation was performed for @xmath0 values between @xmath37 and @xmath38 in increments of @xmath50 .",
    "ml - based estimates are displayed in fig .",
    "8 , and we adopted the parameters used in [ 29 ] .",
    "the @xmath0 estimates of test speech at each @xmath0 condition are plotted in fig .",
    "the estimated ml of each @xmath0 condition did not yield drastic changes ; therefore , we used the average of the ml estimates over frames for each utterance .",
    "for example , as shown in fig .",
    "8(c ) , when the utterance was generated in the @xmath51 condition , the two most likely @xmath0 conditions ( @xmath52 and @xmath53 ) were selected by two types of largest ml .",
    "further , the ml estimate for @xmath53 was larger than the ml estimate for @xmath52 , so the weight of @xmath53 became larger than the weight of @xmath52 .",
    "additionally , it appears that two weights computed by ml estimates , as in ( 8) and ( 9 ) , are changed over the test utterance .",
    "this makes it possible to use this estimator in an online scenario .",
    "it is evident from fig .",
    "7 that the eam achieved relative per reductions of 8.44% over the sbm and 12.37% over the esbm .",
    "it is notable that the esbm does not yield improved performance when compared to the eam , though it utilized the same amount of computational complexity .",
    "it is clear that the proposed ensemble methods have stronger generalization abilities at runtime conditions , made possible by choosing the best matched models with enhanced sensitivity .    as for the comparison between the eam and ejam , it is clear that the ejam is superior to the eam when the reverberant time is normal ( @xmath54 ) .",
    "however , when acoustic reverberation is severe ( @xmath55 ) , the ejam performed slightly worse than the eam .",
    "one possible explanation is that the presented dnn - based feature mapping is not good at representing very long reverberation , as it requires a long - term feature vector as an input of the dnn in order to characterize the long - term evolution of reverberant speech .",
    "future work may benefit from additional features , which might be good at reflecting the long - term pattern of reverberant speech . to summarize ,",
    "the prepared ensemble models are effective for distant speech recognition in various reverberant conditions .",
    "moreover , performance is improved when using the ejam in normal reverberant environments .",
    "to the best of our knowledge , this study is the first to use an ensemble model for speech recognition under reverberant conditions . the ensemble structure was initially built where each @xmath0 in a specific range served as a single dnn - based acoustic modeling .",
    "then , the two most likely dnns from the ensemble model are chosen based on the ml blind estimation for @xmath0 .",
    "the eam is further enhanced by jointly training the acoustic and feature models , which serve as the dereverberation . from the experimental results , the dnn - based ensemble structure for acoustic modeling was superior to the single dnn - based background model .",
    "in particular , the blind ml estimation for @xmath0 was successfully responsible for choosing the most likely dnns in the ensemble model .",
    "the design of the ejam permitting improved performance in normal reverberant conditions was verified in terms of speech recognition accuracy .",
    "lee and j .- h .",
    "chang ,  packet loss concealment based on deep neural networks for digital speech transmission , \" _ ieee / acm trans .",
    "audio , speech , language process .",
    "_ , vol . 24 , no .",
    "378 - 387 , feb . 2016 .",
    "m. i. gurelli and c. l. nikias ,  evam : an eigenvector - based algorithm for multichannel blind deconvolution of input colored signals , \" _ ieee trans . signal process .",
    "134 - 149 , jan . 1995 .",
    "m. wu and d. wang ,  a two - stage algorithm for one - microphoe reverberant speech enhancement , \" _ ieee trans .",
    "audio , speech , language process .",
    "3 , pp . 774 - 784 , may .",
    "k. kinoshita , m. delcroix , t. nakatani , and m. mioshi ,  supression of late reverberation effect on speech signal using long - term multiple - step linear prediction , \" _ ieee trans .",
    "audio , speech , language process .",
    "534 - 545 , may . 2009 .",
    "p. a. naylor and n. d. gaubitch , _",
    "speech dereverberation_. new york , ny , usa : springer , 2010 . e. a. p. habets , ",
    "single- and multi - microphone speech dereverberation using spectral enhancement , \" ph.d .",
    "dissertation , technische univ .",
    "eindhoven , eindhoven , the netherlands , 2007 .",
    "m. delcroix , t. hikichi , and m. miyoshi ,  on the use of lime dereverberation algorithm in an acoustic environment with a noise source , \" in _ proc .",
    "icassp _ , 2006 ,",
    "825 - 828 .",
    "a. rosenberg , c .- h .",
    "lee , and f. soong ,  cepstral channel normalization techniques for hmm - based speaker verification , \" in _ proc .",
    "icslp _ , 1994 , pp .",
    "1835 - 1838 .",
    "t. yoshioka and m. j. f. gales ,  environmentally robust asr front - end for deep neural network acoustic models , \" _ comput .",
    "speech language _ , vol .",
    "65 - 86 , 2015 .",
    "z. zhang , l. wang , a. kai , t. yamada , w. li , and m. iwahashi ,  deep neural network - based bottleneck feature and denoising autoencoder - based dereverberation for distant - talking speaker identification , \" _ eurasip j. audio , speech , music .",
    "_ , pp . 1 - 13 , may . 2015 .",
    "x. xiao , s. zhao , d. nguyen , x. zhong , d. l. jones , e. chng , and h. li ,  speech dereverberation for enhancement and recognition using dynamic features constrained deep neural networks and feature adaptation , \" _",
    "eurasip j. advances in signal process .",
    "_ , pp . 1 - 18 , dec . 2016 .",
    "m mimura , s sakai , and t kawahara ,  exploring deep neural networks and deep autoencoders in reverberant speech recognition , \" in _ proc .",
    ", 2014 , pp .",
    "197 - 201 .",
    "k. han , y. wang , d. wang , w. s. woods , i. merks , and t. zhang ,  learning spectral mapping for speech dereverberation and denoising , \" _ ieee / acm trans .",
    "audio , speech , language process .",
    "23 , no . 6 , pp .",
    "982 - 992 , jun .",
    "2015 . t. gao , j. du , l .- r .",
    "dai , and c .- h .",
    "lee ,  joint training of front - end and back - end deep neural networks for robust speech recognition , \" in _ proc .",
    "icassp _ , 2015 , pp .",
    "4375 - 4379 . c. j. legetter and p. c. woodland ,  maximum likelihood linear regression for speaker adaptation of continuous density hidden markov models , \" _ comput .",
    "speech language _ , vol . 9 , no .",
    "171 - 185 , 1995 .",
    "j. gauvain and c .- h .",
    "lee ,  maximum a posteriori estimation for multivariate gaussian mixture observation of markov chains , \" _",
    "ieee trans .",
    "speech audio process .",
    "291 - 298 , 1994 .",
    "q. wang , j. du , x. bao , z .- r .",
    "wang , l .- r .",
    "dai , and c .- h .",
    "lee ,  a universal vad based on jointly trained deep neural networks , \" _ proc .",
    "interspeech _ , 2015 , pp .",
    "2282 - 2286 .",
    "a. narayann and d. wang ,  improving robustness of deep neural network acoustic models via speech separation and joint adaptive training , \" _ ieee / acm trans .",
    "audio , speech , language process .",
    "1 , pp . 92 - 101 , jan .",
    "j. xue and y. zhao ,  random forests of phonetic decision trees for acoustic modeling in conversational speech recognition , \" _ ieee trans .",
    "audio , speech , language process .",
    "519 - 528 , mar .",
    "t. g. dietterich ,  ensemble methods in machine learning , \" in _ proc .",
    ", 2000 , pp . 1 - 15 .",
    "t. zhao , y. zhao , and x. chen ,  building an ensemble of cd - dnn - hmm acoustic model using random forests of phonetic decision trees , \" in _ proc .",
    "isclp _ , 2014 , pp .",
    "x. chen and y. zhao ,  building acoustic model ensembles by data sampling with enhanced trainings and features , \" _ ieee trans .",
    "audio , speech , language process .",
    "498 - 507 , mar .",
    "j. du , q. wang , y .- h .",
    "tu , x. biao , l .- r .",
    "dai , and c .- h .",
    "lee ,  an information fusion approach to recognizing microphone array speech in the chime-3 challenge based on a deep learning framework , \" in _ proc .",
    "asru _ , 2015 , pp .",
    "430 - 435 .",
    "l. deng and j. c. platt ,  ensemble deep learning for speech recognition . \"",
    "interspeech _ , 2014 , pp .",
    "1915 - 1919 .",
    "k. audhkhasi , a. m. zavou , p. g. georgiou , and s. s. narayanan ,  theoretical analysis of diversity in an ensemble of automatic speech recognition systems , \" _ ieee / acm trans .",
    "audio , speech , language process .",
    "711 - 726 , mar .",
    "y. obuchi ,  framewise speech - nonspeech classification by neural networks for voice activity detection with statistical noise supression , \" in _ proc .",
    "icassp _ , 2016 , pp .",
    "5715 - 5719",
    ". i. hwang , h .-",
    "park , and j .- h .",
    "ensemble of deep neural networks using acoustic environment classification for statistical model - based voice activity detection , \" _ comput .",
    "speech language _ , vol .",
    "38 , pp . 1 - 12 , jul .",
    "r. ratnam , d. l. jones , b. c. wheeler , w. d. obrien , c. r. lansing , and a. s. feng ,  blind estimation of reverberation time , \" _ j. acoust . soc .",
    "5 , pp . 2877 - 2892 , nov .",
    "h. w. lollmann , e. yilmaz , m. jeub , and p. vary ,  an improved algorithm for blind reverberation time estimation , \" in _ proc .",
    "iwaenc _ , 2010 ,",
    "1 - 4 . m. l. seltzer , d. yu , and y. wang ,  an investigation of deep neural networks for noise robust speech recognition , \" in _ proc .",
    "icassp _ , 2013 , pp .",
    "7398 - 7402 .",
    "j. s. garofolo , l. f. lamel , w. m. fisher , j. g. fiscus , d. s. pallett , and n. l. dahlgren ,  timit acoustic phonetic continuous speech corpus , \" in _ proc .",
    "linguistic data consortium _ , 1993 .",
    "e. a. p. habets ,  room impulse response generator , \" tech .",
    ", technische univ .",
    "eindhoven , eindhoven , the netherlands , 2010 .",
    "d. povey , a. ghoshal , g. boulianne , l. burget , o. glembek , n. goel , m. hannemann , p. motlicek , y. qian , p. schwarz , j. silovsky , g. stemmer , and k. vesely ,  the kaldi speech recognition toolkit , \" in _ proc .",
    "asru _ , 2011 ."
  ],
  "abstract_text": [
    "<S> distant speech recognition is a challenge , particularly due to the corruption of speech signals by reverberation caused by large distances between the speaker and microphone . in order to cope with a wide range of reverberations in real - world situations , we present novel approaches for acoustic modeling including an ensemble of deep neural networks ( dnns ) and an ensemble of jointly trained dnns . </S>",
    "<S> first , multiple dnns are established , each of which corresponds to a different reverberation time 60 ( @xmath0 ) in a setup step . also , each model in the ensemble of dnn acoustic models is further jointly trained , including both feature mapping and acoustic modeling , where the feature mapping is designed for the dereverberation as a front - end . in a testing phase , the two most likely dnns are chosen from the dnn ensemble using maximum _ a posteriori _ ( map ) </S>",
    "<S> probabilities , computed in an online fashion by using maximum likelihood ( ml)-based blind @xmath0 estimation and then the posterior probability outputs from two dnns are combined using the ml - based weights as a simple average . </S>",
    "<S> extensive experiments demonstrate that the proposed approach leads to substantial improvements in speech recognition accuracy over the conventional dnn baseline systems under diverse reverberant conditions .    </S>",
    "<S> lee and chang : ensemble of jointly trained deep neural network - based acoustic models for reverberant speech recognition    reverberant speech recognition , deep neural network , joint training , ensemble acoustic model </S>"
  ]
}