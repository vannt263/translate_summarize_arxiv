{
  "article_text": [
    "partially recursive acceptance rejection ( ) is a new protocol for creating algorithms for exactly generating random variates from high dimensional distributions .",
    "the method is simple to implement efficiently , and results in algorithms that can be proved to have an expected running time that is linear in problem size over a wider range of parameters than known previously for several problems of interest .",
    "consider a distribution defined either by an unnormalized weight function @xmath3 for discrete spaces , or an unnormalized density function @xmath4 for continuous spaces . in the past ,",
    "techniques for perfect simulation from these distributions have been very different depending on whether the spaces were continuous or discrete .",
    "operates the same way in both situations .",
    "the problems where is useful often use approximate sampling via markov chain monte carlo ( ) . however , these are not true algorithms unless the mixing time of the markov chain being used can be somehow bounded .",
    "one such technique for bounding the mixing time of a markov chain is dobrushin uniqueness  @xcite ( see also the work on path coupling of bubley and dyer  @xcite ) .",
    "requires a condition very similar to dobrushin uniqueness , the difference being that even if dobrushin uniqueness can not be shown mathematically , it can be verified algorithmically",
    ".    one can prove ( up to an arbitrarily small chance of error ) that a markov chain is slowly mixing through computer experiment , however , there is no generally effective way to show that a markov chain is rapidly mixing .",
    "however , with perfect simulation protocols like , it is possible through computer experiment to verify that the resulting output comes exactly from the target distribution , thereby making them more useful in practice for certain problems than the markov chain approach .",
    "our concern here is with fast algorithms that use an expected number of random choices that is linear in the size of the problem .",
    "there are currently two protocols for generating samples in expected linear time from these types of problems .",
    "the first method is the _ clan of ancestors _ method of  @xcite .",
    "this method is an extension of the coupling from the past  @xcite protocol or propp and wilson .",
    "it looks backwards in time at the events that could affect the state in the present .",
    "the set of backwards events is called the clan of ancestors , which gives the name to the method .",
    "this approach has rarely been implemented ( see  @xcite for one such implementation ) because unless special care is taken it can be very computationally expensive to keep track of how clans arising from different dimensions interact .",
    "one of the advantages of is that such interactions can not occur with this approach , making the implementation much easier .",
    "the second linear time method is the _ randomness recycler _ method of  @xcite .",
    "like ( and unlike clan of ancestors ) it is straightforward to implement , however , the range of parameters for which the algorithm is provably linear time is in all known cases more restricted than with .",
    "the protocol is illustrated with the following applications .",
    "* for independent sets of a graph with @xmath1 nodes , maximum degree @xmath5 , and parameter @xmath6 , the method allows @xmath2 expected sampling time when @xmath7 , beating the previously best known linear time algorithm which required @xmath8 .",
    "* for the continuous state space autonormal model on a graph with @xmath1 nodes and parameter @xmath9 , the method allows @xmath2 expected sampling time when @xmath10 , beating the previously best known linear time algorithm which required @xmath11 .",
    "* for the random cluster model on a graph with @xmath1 nodes and maximum degree @xmath5 , and parameters @xmath12 and @xmath13 , the method allows @xmath2 expected sampling time when @xmath14 .    of course , if the expected running time is allowed to be @xmath15 rather than linear , other methods with wider parameter ranges exist .",
    "for instance , in  @xcite it was shown using bounding chains and coupling from the past  @xcite how to sample independent sets in @xmath0 time when @xmath16 . but for @xmath2 algorithms , appears to have the widest bounds .",
    "the rest of the paper is organized as follows .",
    "the next section presents the applications , followed by a section describing the theory of the protocol .",
    "then section  [ sec : apply ] applies the protocol to the different applications , proving the running time results listed above .",
    "section  [ sec : popping ] then shows how this method can be viewed as a generalization of the popping method of wilson for sampling directed rooting spanning trees of a graph .",
    "each of the applications will be described as an unnormalized density @xmath3 with respect to a base finite measure @xmath17 from which it is easy to sample from .",
    "consider coloring the nodes of a graph @xmath18 with either 0 or 1 , so the state space is @xmath19 .",
    "the underlying measure we use has a parameter @xmath20 that controls the average number of nodes in a randomly drawn coloring : @xmath21 say that @xmath22 is a bernoulli random variable with mean @xmath12 ( write @xmath23 ) if @xmath24 and @xmath25 .",
    "to sample from @xmath17 , generate @xmath26 independently for all @xmath27 .",
    "we use the convention @xmath28 so that when @xmath29 the only state with positive measure is the all 0 coloring , while as @xmath6 grows the measure favors labelings with more 1 s .",
    "an _ independent set _ of a graph is a labeling such that no two adjacent nodes receive a 1 .",
    "hence the density of interest is @xmath30 note that for all @xmath31 , @xmath32 as well .",
    "the strauss process  @xcite extends the independent set model by allowing two adjacent nodes to both be labeled 1 , but assigns a penalty factor of @xmath33 $ ] when this occurs .",
    "the underlying measure @xmath17 still is defined by  , now the density becomes @xmath34 with the convention that @xmath28 , then when @xmath35 this is just the independent set density .",
    "the autonormal model  @xcite is a continuous extension of the ising model  @xcite used for modeling images and other spatial experiments . for a graph @xmath36 ,",
    "the state space is @xmath37^v$ ] , the underlying measure @xmath17 has density @xmath38 with respect to lebesgue measure . here",
    "@xmath39 and @xmath40 are known parameters .",
    "to sample from @xmath17 , each node label @xmath41 is independently normal with mean @xmath40 , variance @xmath42 , and conditioned to lie in @xmath43 $ ] .",
    "the density is @xmath44 where @xmath9 is another constant .",
    "the random cluster model  @xcite is another way of viewing the potts model  @xcite , which is itself a different extension of the ising model  @xcite .",
    "given a graph @xmath36 the state space is now a coloring of edges with 0 and 1 .",
    "given @xmath45 , and parameter @xmath12 , the underlying measure @xmath17 is @xmath46 again this measure @xmath17 is easy to sample from : draw ( for all @xmath47 ) @xmath48 independently .    a second parameter @xmath13 controls the density @xmath49 through the use of @xmath50 , which is the number of connected components in the graph using only the edges with @xmath51 .",
    "@xmath52 when @xmath53 , a sample from the random cluster model can be transformed into a sample from the ising model in linear time  @xcite , and for @xmath13 an integer greater than 2 , it can be transformed in linear time into a sample from the potts model .",
    "( 0,1 ) ; ( 0,0 ) grid ( 1,1 ) ; in 0,1 in 0,1 ( , ) circle(5pt ) ;        independent sets of a graph label each node either 0 or 1 . in this case",
    "where there are only two colors , the general can be simplified .",
    "if the label of a node is 0 , then the node is immediately accepted .",
    "but if the label is 1 , then all the neighbors of the node must also be 0 .",
    "if a neighbor is 1 , then we can immediately track down its neighbors to ensure that they are all 0 , and so on .",
    "so if a neighbor of the end of the backbone is labeled 1 , that increases the length of the backbone by 1 . on the other hand ,",
    "if all the neighbors of the end of the backbone at labeled 0 , then the node that is the end of the backbone accepts its label of 1 .",
    "if the backbone had length 1 , then we are done . otherwise , that meant the the second to the end node in the backbone rejects  because it comes into conflict with the end of the backbone that is labeled 1 .",
    "therefore the last two nodes in backbone are removed from the backbone and return to being unresolved .",
    "the process then starts over again .",
    "this gives us a connected sequence of nodes labeled 1 that grows and shrinks in length .",
    "call this sequence the backbone of the current state , and the method backbone_prar .",
    "see figure  [ fig : backbone ] for an illustration .",
    "( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 1 ; ( 0,2 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 1,-.8 ) node step 2 ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 3 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 0,1 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 4 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 0,1 ) circle(5pt ) ; ( 1,1 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 5 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 0,1 ) circle(5pt ) ; ( 1,1 ) circle(5pt ) ; ( 2,1 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 6 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 0,1 ) circle(5pt ) ; ( 1,1 ) circle(5pt ) ; ( 2,1 ) circle(5pt ) ; ( 2,0 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 7 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 0,1 ) circle(5pt ) ; ( 1,1 ) circle(5pt ) ; ( 2,1 ) circle(5pt ) ; ( 2,0 ) circle(5pt ) ; ( 1,0 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 8 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 0,1 ) circle(5pt ) ; ( 1,1 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 9 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 0,1 ) circle(5pt ) ; ( 1,1 ) circle(5pt ) ; ( 2,1 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 10 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 0,1 ) circle(5pt ) ; ( 1,1 ) circle(5pt ) ; ( 2,1 ) circle(5pt ) ; ( 1,0 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 11 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ;    ( 0,0 ) grid ( 2,2 ) ; in 0,1,2 in 0,1,2 ( , ) circle(5pt ) ; ( 1,-.8 ) node step 12 ; ( 0,2 ) circle(5pt ) ; ( 1,2 ) circle(5pt ) ; ( 0,1 ) circle(5pt ) ;    this idea of a backbone works on other applications with two colors , such as the ising model and the strauss model .",
    "the backbone method for independent sets only requires an independent , identically distributed stream of bernoulli random variables with mean @xmath122 .",
    "let @xmath5 be the maximum degree of the graph and @xmath123 if @xmath124 , then the expected number of bernoulli s needed to resolve one node is bounded above by @xmath125 .",
    "since this is a constant with respect to the size of the graph , the time needed to generate a sample over the entire graph is at most @xmath126 .",
    "when the backbone resolves , it resolves either as an acceptance or a rejection . the number of resolutions until acceptance is stochastically bounded above by a geometric random variable with parameter @xmath127 .",
    "therefore , the expected number of resolutions of the backbone is at most @xmath128 .",
    "how many draws does it take to resolve a node ? it certainly takes one to determine the label for the node .",
    "so if @xmath129 is the resolution time , then @xmath130 \\leq 1 + \\delta r$ ] , where @xmath131 is an upper bound on the expected resolution time for subsequent nodes .",
    "these subsequent nodes have maximum degree at most @xmath132 .",
    "the first neighbor takes at most @xmath131 expected time .    on to the second neighbor .",
    "note that the second neighbor only needs to be resolved if the first neighbor resolved to a 0 .",
    "if the first neighbor had resolved to a 1 , then the original node is rejected , there is no need for further action .",
    "the chance that a neighbor resolves to 1 is at least @xmath133[1/(1+\\lambda)]^{\\delta - 1}$ ] .",
    "so the second neighbor is only activated with probability @xmath134 .",
    "similarly , the third neighbor can also take time distributed as @xmath131 , but only if the first two neighbors fail . adding this up over the ( up to @xmath132 ) neighbors",
    "gives @xmath135",
    "\\left[\\frac{1}{1+\\lambda}\\right]^{\\delta - 1}\\right)^{i-1},\\ ] ] which gives the result .",
    "it is straightforward to verify that for @xmath7 we have @xmath124 .",
    "this gives the result presented in section  [ sec : introduction ] .",
    "call the value of @xmath6 where @xmath136 the _ critical value _ of @xmath6 , and denote it @xmath137 . for @xmath138 , the algorithm",
    "is guaranteed to generate samples in polynomial time . for @xmath139 , the algorithm might operate in polynomial time , or it might not .    [ cols=\">,<,<,<\",options=\"header \" , ]      now consider what happens in the strauss process . again",
    "consider drawing an initial node and accepting or rejecting based upon the neighbors of the node .",
    "if the node is labeled 0 , then we always accept as before . if the node is labeled 1 , then the chance of accepting is @xmath140 raised to the power of each of the neighbors of the node labeled 1 .",
    "another way to view this , is to , for each edge adjacent to the original node , draw a @xmath141 random variable . if this variable is 1 , then the neighbor does not matter . if this variable is 0 , then the neighbor does matter , and recursion needs to be used to find out its value .",
    "this changes the expected number of neighbors to be considered from @xmath132 to @xmath142 .",
    "the chance of a node being labeled 1 is strictly greater in the recursion , therefore , the new value of @xmath143 is at most @xmath144 note that @xmath145 is equivalent to @xmath146 $ ] , so a similar argument to the previous section gives the following result .",
    "when @xmath147^{-1},$ ] then generates a sample from the strauss process using @xmath2 expected number of bernoulli draws .      as with the independent set density ,",
    "the idea is to consider what happens when a single node is drawn , the rest of the graph is drawn , and the combination is either accepted or rejected .",
    "the value that @xmath56 from line 6 in the general protocol must fall below is the product of the chance of rejecting because of each of the neighboring edges .    that is , in order to determine if node @xmath80 can be combined with the state of @xmath148 , it is necessary to independently draw a uniform @xmath43 $ ] random variable for each of the neighbors @xmath49 of @xmath80 .",
    "only if every edge accepts can the entire state be said to accept .",
    "if the single node @xmath80 is assigned value @xmath149 , the chance of rejecting based on @xmath49 is at most @xmath150 where the upper bound on the right hand side does not depend on @xmath151 !",
    "therefore , only if @xmath152 does the value @xmath151 need to be determined .",
    "therefore , the expected number of neighbors of the original node @xmath80 that need to be found out is bounded above by @xmath153 the original node @xmath80 might have had up to @xmath5 neighbors , but subsequent nodes will only have at most @xmath132 neighbors . therefore ,",
    "if @xmath154 , then on average the number of new nodes to consider generated by a node will be negative , and will terminate after a finite number of steps .",
    "this argument yields the following lemma .",
    "let @xmath155 . if @xmath124 , then can generate a sample from the autonormal model in @xmath2 random choices on a graph with @xmath1 nodes and maximum degree @xmath5 .    a similar analysis for the clan of ancestors approach requires @xmath156 , therefore the parameter range with guaranteed performance here is slightly wider .",
    "suppose that @xmath157 in the random cluster model with density given by  .",
    "then the density of a configuration gains a factor of @xmath13 for each connected component in the graph .",
    "viewed as a penalty , this means that for a particular edge , there is a penalty of @xmath158 if it connects two previously disconnected components in the rest of the graph . in other words , if @xmath159 , where @xmath1 is the number of nodes in the graph , then the density can be written as @xmath160    now consider a single edge @xmath161 chosen from the underlying measure .",
    "if the edge is labeled 0 ( which happens with probability @xmath162 ) , then the edge is accepted regardless of the rest of the components .",
    "if the edge is labeled 1 ( which happens with probability @xmath12 ) , then the edge is accepted with probability @xmath158 if the rest of the state does not connect nodes @xmath163 and @xmath164 , and accepted with probability 1 otherwise .",
    "suppose that @xmath165 is randomly chosen to be 1 .",
    "then draw @xmath56 uniformly over @xmath43 $ ] .",
    "if @xmath166 , then the edge @xmath161 is accepted regardless of the rest of the state and the edge value becomes known .",
    "otherwise , recursion must be used to determine enough of the rest of the state in order to determine if the nodes @xmath161 are connected or not .",
    "the first edge @xmath161 can be connected to as many as @xmath167 different edges , each of which must be considered to determine if @xmath168 .",
    "let @xmath169 be one of these edges ( either of the form @xmath170 or @xmath171 for some nodes @xmath172 . )",
    "if @xmath169 is chosen to be labeled 0 in the recursion , then it is removed from the `` needs a value '' list .",
    "otherwise , it is adjacent to at most @xmath132 new edges that might need a value .",
    "hence the expected change of the size of the number of edges that need values is bounded above by @xmath173 if this quantity is less than 0 , then the number of edges to be considered drops ( on average ) at each step , and the expected number of steps is bounded .",
    "this gives the following lemma .",
    "let @xmath174 be a graph with @xmath1 nodes , @xmath175 edges , and maximum degree @xmath5 . if @xmath14 , then the expected number of random choices made in the algorithm is @xmath176 .",
    "the well - known acceptance rejection method requires two properties to hold :    1 .",
    "it is easy to sample from the underlying measure @xmath17 .",
    "the target density is bounded by a known constant @xmath54 .",
    "when these hold ( and they do for each of the applications of the previous section ) , the acceptance rejection ( ) technique is as follows .",
    "rl + ) & randomly draw @xmath55 + ) & draw @xmath56 uniformly from @xmath43 $ ] + ) & if @xmath57 output @xmath22 and quit + ) & else + ) & @xmath58 , output @xmath22 and quit +    it is well - known  @xcite that the output is a draw from density @xmath3 with respect to measure @xmath17 .    now suppose that @xmath59 for color set @xmath60 and dimension set @xmath61 ( as it is for all of our applications . )",
    "let @xmath62 be a partition of the dimensions @xmath61 .",
    "note that for each of our applications , the product nature of @xmath3 means that we can write @xmath63 for instance , for the independent sets model , if @xmath64 is a partition of the nodes @xmath65 , then @xmath66\\left[\\prod_{\\{i , j\\ } \\in v_2 } ( 1-x(i)x(j))\\right ]    \\left[\\prod_{i \\in v_1,j \\in v_2 } ( 1-x(i)x(j))\\right]\\ ] ] and @xmath3 has been nicely factored into @xmath67 , @xmath68 , and @xmath69 .",
    "when for @xmath70 and @xmath71 there is an @xmath54 such that @xmath72 , fully recursive is as follows .",
    "rl + ) & parition @xmath73 into @xmath70 and @xmath71 + ) & @xmath74 , @xmath75 + ) & draw @xmath56 uniformly from @xmath43 $ ] + ) & if @xmath76 output @xmath22 and quit + ) & else + ) & @xmath77 , output @xmath78 and quit +    fully recursive generates output @xmath22 according to @xmath49 with respect to @xmath17 .",
    "this is similar to the self - reducibility of jerrum , valiant , and vazirani  @xcite .",
    "more recently , this approach has also been formalized in  @xcite .",
    "the proof follows immediately from the correctness of basic and an induction on the number of times line 2 has been used .",
    "suppose we desire only to know @xmath79 for a single node @xmath80 .",
    "then first generate @xmath79 and @xmath81 separately , and then choose to accept or reject the combination .",
    "the key idea of is that sometimes this does not require that we generate @xmath81 .",
    "for example , in the independent set model , if @xmath82 , then we accept no matter what @xmath81 is .",
    "even if @xmath83 , we do not need to know the entirely of @xmath81 , only those neighbors of @xmath80 .",
    "the general protocol looks like this .",
    "rl +   +   + ) & if @xmath84 then output @xmath85 $ ] + ) & else + ) & let @xmath86 be any element of @xmath73 , let @xmath87 + ) & draw @xmath88 randomly from @xmath67 over @xmath17 + ) & draw @xmath56 uniformly from @xmath43 $ ] + ) & if @xmath89 + ) & draw @xmath90 \\leftarrow                               { \\tt partially\\_recursive\\_ar}(s \\setminus \\{d\\},d \\setminus \\{d\\})$ ] + ) & @xmath91 .",
    "output @xmath92 $ ] and quit + ) & else + ) & let @xmath93 be the smallest set such that @xmath94 determines @xmath95 + ) & @xmath90 \\leftarrow { \\tt partially\\_recursive\\_ar}(d_3,d \\setminus \\{d\\})$ ] + ) & if @xmath96 , then @xmath91 , output @xmath92 $ ] + ) & else let @xmath97 \\leftarrow { \\tt partially\\_recursive\\_ar}(s , d)$ ] and output @xmath92 $ ] +    suppose partially_recursive_ar@xmath98 terminates with probability 1 with output @xmath99 .",
    "then @xmath78 has the same distribution as the coordinates of @xmath73 from @xmath22 where @xmath22 is a complete draw from density @xmath49 with respect to @xmath17 over dimensions @xmath61 .",
    "the fundamental theorem of perfect simulation  @xcite says that if the algorithm terminates with probability 1 , then we assume that lines 1 , 6 , 11 , and 13 have the correct output when proving that the overall algorithm is correct .    with that assumption ,",
    "lines 7 and 11 are drawing a state @xmath22 , and then reporting @xmath100 for some set of dimensions @xmath101 that contain @xmath73 .",
    "so the algorithm s output has the same distribution as fully_recursive_ar , but not all coordinates of @xmath22 are reported in the output .",
    "it is the analysis of the running time where we see a dobrushin like condition .",
    "let @xmath102 be the probability that line 13 is reached .",
    "let @xmath103 denote the probability that line 10 is reached given @xmath104 .",
    "suppose for all @xmath105 , there exists @xmath106 with @xmath107 \\leq b$ ] , and that @xmath107p(d ) \\leq",
    "c_2 <   1 $ ] . given @xmath73 then the expected number of times line 4",
    "is called ( or equivalently line 5 ) is at most @xmath108 .",
    "consider two temporary changes to the algorithm .",
    "first , at line 13 , change it to else , output @xmath85 $ ] and quit .",
    "second , at line 3 , add @xmath109 to the end . because of our previous change to line 13 , this does not alter the algorithm any further .",
    "consider the expected time needed to either reach our new line 13 , or to quit",
    ". then there might be several recursive calls to paritall_recursive_ar over the run of the algorithm .",
    "let @xmath110 be the number of dimensions in the union of the @xmath73 sets after @xmath111 recursive calls to the algorithm",
    ". then @xmath112 .",
    "now consider @xmath113 given @xmath110 .",
    "two things can happen .",
    "if lines 7 and 8 activate , then @xmath114 . if lines 10 and 11 activate , then @xmath115",
    "this second event happens with probability @xmath103 .",
    "= n_t - 1 + p(d ) { \\mathbb{e}}[\\#(d_3)|d].$ ]    when this right hand side is at most @xmath117 , standard martingale theory ( see for instance  @xcite ) gives that the expected amount of time for the @xmath110 process to reach 0 is @xmath118 .",
    "now consider what happens if line 13 is changed back .",
    "then the expected time between reaching line 13 is @xmath119 .",
    "each time through the algorithm there is at least a @xmath120 chance line 13 is not executed and the algorithm does not recurse further .",
    "therefore , the total expected number of steps taken is at most @xmath121 .",
    "this protocol can be viewed as an extension of the cycle popping algorithm of wilson for uniformly generating from rooted trees in a directed graph .    consider a graph @xmath18 , and construct a directed graph by taking each edge @xmath161 and adding directed arcs @xmath177 and @xmath178 .",
    "designate a special node @xmath179 known as the root of the graph .",
    "then let a configuration consist of a @xmath180 labeling of arcs such that every node @xmath181 has exactly one outgoing edge @xmath182 labeled 1 .",
    "let @xmath17 be the underlying measure that is uniform over all such labelings .",
    "then it is easy to sample from @xmath17 : independently for each node @xmath163 select a neighbor @xmath164 uniformly at random and label that outgoing arc 1 , and all other outgoing arcs from @xmath163 label 0 .",
    "the density @xmath3 then is 1 if every node has a directed path using edges labeled 1 to the root , and is 0 otherwise .",
    "when @xmath3 is 1 , say that @xmath183 encodes a _ directed rooted tree _ in the original graph .",
    "then wilson  @xcite presented a simple algorithm for generating from @xmath3 over @xmath17 .",
    "start with an arbitrary node @xmath163 , and uniformly choose a neighbor @xmath164 . from @xmath164",
    "choose neighbor @xmath172 , and continue until one of two things happens .",
    "if the directed path reaches a node already examined , then there is a loop .",
    "erase the loop and continue onwards .",
    "for instance , if the choices where @xmath184 , then @xmath185 forms a loop , and the next step would start with @xmath186 .",
    "the other thing that can happen is that the directed path reaches @xmath187 . in this case , fix the labeling for all nodes along the path .",
    "now choose another node in the graph and repeat , choosing random neighbors , erasing loops as they form , and stopping when reaching either @xmath187 or a previously fixed node .",
    "this algorithm is just with the backbone method applied to @xmath17 and @xmath49 ! at each step of the algorithm we are recursively moving deeper into the graph in order to determine if acceptance should occur .",
    "if a loop forms , then rejection occurs , and all the edges in the loop are eliminated .",
    "but if the path should encounter a previously fixed path , then acceptance occurs not only for the original edge but all along the path as well .",
    "wilson gave a proof tailored for his algorithm .",
    "because this is also a algorithm , we immediately have correctness for the loop - erased random walk method of uniformly generating rooted trees .",
    "an earlier version of this technique appears in  @xcite ( without the backbone method , connection to popping , and the general running time bound given here . )",
    "the recent development of this method was supported by nsf grant dms-1418495 ."
  ],
  "abstract_text": [
    "<S> generating random variates from high - dimensional distributions is often done approximately using markov chain monte carlo . in certain cases , </S>",
    "<S> perfect simulation algorithms exist that allow one to draw exactly from the stationary distribution , but most require @xmath0 time , where @xmath1 measures the size of the input . in this work a new protocol for creating perfect simulation algorithms that runs in @xmath2 time for a wider range of parameters on several models ( such as strauss , ising , and random cluster ) than was known previously . </S>",
    "<S> this work represents an extension of the popping algorithms due to wilson . </S>"
  ]
}