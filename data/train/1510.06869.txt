{
  "article_text": [
    "it has become increasingly common in various research areas for statistical analysis to involve data that lies in non - euclidean spaces .",
    "one such an example is the statistical analysis of shape ; cf . @xcite and @xcite .",
    "consequently , many statistical concepts and techniques have been generalised and developed to adapt to such phenomena .",
    "frchet means , as a generalisation of euclidean means , of random variables on a metric space have been widely used for statistical analysis of non - euclidean data .",
    "a point @xmath2 in a metric space @xmath4 with distance function @xmath5 is called a frchet mean of a random variable @xmath6 on @xmath4 if it satisfies @xmath7.\\ ] ] influenced by the structure of the underlying spaces , frchet means , unlike their euclidean counterparts , exhibit many challenging probabilistic and statistical features .",
    "various aspects of frchet means have been studied for non - euclidean spaces , including riemannian manifolds and certain stratified spaces . among others ,",
    "the strong law of large numbers for frchet means on general metric spaces was obtained in @xcite .",
    "the first use of frchet means to provide nonparametric statistical inference , such as confidence regions and two - sample tests for discriminating between two distributions , was carried out in @xcite and @xcite for both extrinsic and intrinsic inference applied to manifolds .",
    "when @xmath4 is a riemannian manifold with the distance function being that induced by its riemannian metric , the results on central limit theorems for frchet means can be found in @xcite and @xcite .",
    "the results in both papers imply that , since manifolds are locally homeomorphic to euclidean spaces , the limiting distributions for sample frchet means on riemannian manifolds are usually gaussian , a phenomenon similar to that for euclidean means .    in the case of euclidean space , the link between the sample means of i.i.d .",
    "random vectors and random walks leads to the fact that the rescaled sample means converge weakly to brownian motion , possibly up to a linear transformation associated with the covariance structure of the random vectors .",
    "on the other hand , the authors of @xcite constructed a stochastic gradient algorithm from a given sequence of i.i.d .",
    "random variables on a riemannian manifold where , under certain conditions , the random sequence resulting from the algorithm converges almost surely to the frchet mean @xmath2 of the given random variables .",
    "moreover , it showed that , if one rescales the images , under @xmath0 , of the random walks associated with the algorithm , they converge weakly to an inhomogeneous diffusion process on the tangent space of the manifold at @xmath2 .",
    "the following questions are raised from this paper : if one rescales the images , under @xmath0 , of the sample frchet means of the random variable , will they converge weakly ?",
    "if they do , do they converge to the same diffusion process as the one given in @xcite ? if not",
    ", what is the limiting diffusion process ? this paper addresses these questions .",
    "we show that the rescaled images of the sample frchet means of i.i.d .",
    "random variables @xmath8 on a riemannian manifold converge weakly to a diffusion process which is a brownian motion up to a linear transformation .",
    "moreover , in addition to the covariance structure of @xmath3 , this linear transformation also depends on the global riemannian structure of the manifold . for this",
    "we first , in the next section , construct a sequence of simpler inhomogeneous markov processes , each of which is also a martingale , and consider the behaviour of their weak convergence .",
    "in addition to their intrinsic interest , the results in this section also form a basis for our investigations of `` rescaled '' sample frchet means in the following section .",
    "in particular , we relate the constructed sequence of processes to the `` rescaled '' sample frchet means in such a way that the result for the latter is a direct consequence of the former .",
    "let @xmath4 be a complete riemannian manifold of dimension @xmath9 with covariant derivative @xmath10 and riemannian distance @xmath5 , whose sectional curvature is bounded below by @xmath11 and above by @xmath12 . for any @xmath13 ,",
    "we denote by @xmath14 the cut locus of @xmath15 .",
    "note that , for any fixed @xmath16 , the squared distance function @xmath17 to @xmath16 is not @xmath18 on @xmath19 .    for a fixed @xmath20 ,",
    "consider the vector field on @xmath21 defined , at @xmath22 , by @xmath23 , where @xmath24 denotes the tangent space of @xmath4 at @xmath15 , and then define the linear operator @xmath25 on the tangent space @xmath24 by @xmath26 the operator @xmath25 so defined will play an important role in the following study of the asymptotic behaviour of sample frchet means on @xmath4 . note first that @xmath25 is closely linked with @xmath27 , the hessian of the function @xmath28 , as follows ( cf .",
    "@xcite , page 145 ) : @xmath29 for any @xmath22 and any tangent vectors @xmath30 , and so the assumption on the bounds for the sectional curvature of @xmath4 implies that , for any unit tangent vector @xmath31 , @xmath32 \\label{eqn0}\\\\[-8pt ] \\nonumber & & \\qquad \\leqslant\\bigl\\langle h_{x , y}(v),v\\bigr\\rangle\\leqslant \\sqrt{- \\kappa_0}\\rho(x , y)\\coth\\bigl(\\sqrt{-\\kappa_0}\\rho(x , y ) \\bigr),\\end{aligned}\\ ] ] where we require that if @xmath33 , @xmath34 for the first inequality to hold ; cf .",
    "@xcite , page 203 .",
    "in contrast to euclidean means , there is generally no closed form for frchet means . on the other hand",
    ", the result of @xcite implies that the euclidean random variable @xmath35 is almost surely defined , where @xmath2 is a frchet mean of the random variable @xmath6 on @xmath4 .",
    "then , since @xmath36 where grad@xmath37 denotes the gradient operator acting on the first argument of a function on @xmath38 and since @xmath39 \\bigr )    } = \\mathrm{e}\\bigl[\\operatorname{grad}_1 \\bigl ( \\rho(x , x)^2 \\bigr ) |_{x=\\mu}\\bigr]=0\\ ] ] by the definition of frchet means , the frchet mean @xmath2 satisfies the condition that @xmath40=0.\\ ] ] thus @xmath2 is linked to the euclidean mean in the sense that the origin of the tangent space of @xmath4 at @xmath2 , @xmath41 is the euclidean mean of the euclidean random variable @xmath42 .    let @xmath8 be a sequence of i.i.d .",
    "random variables on @xmath4 , and for a fixed @xmath43 , assume that @xmath44<\\infty$ ] .",
    "this assumption ensures the existence of fr ' echet means of @xmath45 . for simplicity , in the following , we shall assume that the frchet mean @xmath2 of @xmath45 is unique .",
    "however , we do not require the support of the probability measure of @xmath45 to be contained in any geodesic ball .",
    "note that the result of @xcite ensures that @xmath46 under some mild condition on @xmath4 .",
    "we further assume that @xmath47<\\infty \\quad\\mbox{and } \\nonumber \\\\[-8pt ] \\label{eqn3}\\\\[-8pt ] \\nonumber & & \\bigl(\\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-1 } , \\mbox{the inverse of the linear operator } \\mathrm{e}[h_{\\mu , x_1 } ] , \\mbox{exists}.\\end{aligned}\\ ] ] these two assumptions ensure that the linear operator @xmath48 $ ] is well defined and nonsingular .    for each fixed @xmath49 , consider the time - inhomogeneous markov chain @xmath50 defined on the tangent space @xmath51 in terms of @xmath8 as @xmath52 \\bigr)^{-1 } \\bigl(\\exp ^{-1}_\\mu(x_1 ) \\bigr ) , \\\\",
    "v^n_{k+1}&=&\\frac{1}{\\sqrt n } \\bigl(\\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-1 } \\bigl(\\exp ^{-1}_\\mu(x_{k+1 } ) \\bigr ) \\\\ & & { } + \\biggl\\{\\frac{k+1}{k}i-\\frac{1}{k } \\bigl(\\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-1}h_{\\mu , x_{k+1 } } \\biggr\\}\\bigl(v^n_k \\bigr ) , \\qquad k\\geqslant1.\\end{aligned}\\ ] ] one may check that @xmath50 is a martingale .",
    "we are interested in the asymptotic behaviour of @xmath53}\\vert t\\geqslant 0\\}$ ] as @xmath54 tends to infinity .",
    "firstly , for this , the following lemma gives an upper bound for the sequence @xmath55}\\vert n\\geqslant1\\}$ ] for @xmath56 .",
    "[ lem1 ] suppose that the assumptions ( [ eqn3 ] ) hold .",
    "then there is a constant @xmath57 such that , for any @xmath56 and @xmath58 , @xmath59}\\bigr|^2 \\bigr]\\leqslant\\alpha\\mathrm{e}\\bigl[\\rho ( \\mu , x_1)^2 \\bigr ] \\biggl\\ { \\frac{1}{n_0}+\\varepsilon_0c_0 \\biggr\\},\\ ] ] where @xmath60 ) ^{-1}{\\vert}^2 $ ] .",
    "write @xmath61 \\bigr)^{-\\top } \\bigl ( \\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-1}h_{\\mu , x_1}\\bigr].\\ ] ] then , by the definition of @xmath62 , @xmath63 \\\\ & & \\qquad = \\frac{1}{n } \\mathrm{e}\\bigl[\\bigl|\\bigl(\\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-1}\\exp^{-1}_\\mu ( x_1)\\bigr|^2 \\bigr]+ \\biggl\\langle v^n_k , \\biggl\\{\\frac{k^2 - 1}{k^2}i+ \\frac { 1}{k^2}b \\biggr\\}v^n_k \\biggr\\rangle \\\\ & & \\qquad\\quad{}+\\frac{2}{\\sqrt{n } } \\mathrm{e}\\bigl [ \\bigl\\langle\\bigl ( \\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-1}\\exp^{-1}_\\mu ( x_{k+1}),g_{k+1}v^n_k \\bigr\\rangle\\vert v^n_k\\bigr],\\end{aligned}\\ ] ] where @xmath64 \\bigr)^{-1}h_{\\mu , x_{k+1}}.\\ ] ] under the given conditions , there is a constant @xmath65 such that , for any @xmath66 , @xmath67 .",
    "thus , using the facts that @xmath68=0 $ ] and that @xmath69 is independent of @xmath62 , we have @xmath63 \\\\ & & \\qquad",
    "\\leqslant \\frac{\\alpha}{n}\\mathrm{e}\\bigl[\\rho(\\mu , x_1)^2 \\bigr]+ \\biggl(1+\\frac{\\beta } { k^2 } \\biggr)\\bigl|v^n_k\\bigr|^2 \\\\ & & \\qquad\\quad{}-\\frac{2}{\\sqrt{n}k } \\bigl\\langle\\mathrm{e}\\bigl[h_{\\mu , x_{k+1}}^\\top \\bigl(\\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-\\top } \\bigl ( \\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-1}\\exp ^{-1}_\\mu ( x_{k+1})\\bigr],v^n_k \\bigr\\rangle.\\end{aligned}\\ ] ] noting that @xmath50 is a martingale with zero expectation , the above implies that @xmath70 \\leqslant\\frac{\\alpha } { n}\\mathrm{e}\\bigl[\\rho(\\mu , x_1)^2 \\bigr]+ \\biggl(1+\\frac{\\beta}{k^2 } \\biggr)\\mathrm{e}\\bigl[\\bigl|v^n_k\\bigr|^2 \\bigr].\\ ] ] hence , by induction , we have @xmath71 \\leqslant\\frac{\\alpha}{n}\\mathrm{e}\\bigl[\\rho(\\mu , x_1)^2 \\bigr ] \\biggl\\{1+\\sum_{i=1}^k\\prod _ { j = i}^k \\biggl(1 + \\frac{\\beta}{j^2 } \\biggr ) \\biggr \\}.\\ ] ] since @xmath72 the above implies , in particular , that @xmath73}\\bigr|^2\\bigr ] \\leqslant\\alpha \\mathrm{e}\\bigl[\\rho(\\mu , x_1)^2 \\bigr ] \\biggl\\ { \\frac{1}{n}+\\varepsilon_0 \\prod _ { j=1}^\\infty \\biggl(1+\\frac{\\beta } { j^2 } \\biggr ) \\biggr\\}.\\ ] ] the required result then follows from the fact that @xmath74 .",
    "the next lemma gives various bounds on the differences @xmath75 for sufficiently large @xmath54 and @xmath76 .",
    "[ lem2 ] in addition to the assumptions in ( [ eqn3 ] ) , assume that , for some @xmath77 , @xmath78<\\infty$ ] .",
    "then , for any @xmath56 and @xmath79 , there are constants @xmath80 , @xmath81 , and @xmath82 depending on @xmath83 and @xmath84 such that , when @xmath54 is sufficiently large , for @xmath85 and for @xmath86 with @xmath87 :    for any @xmath88 @xmath89    @xmath90\\bigr{\\vert}\\leqslant c_2n^{-(1+\\min\\{1/2,\\delta/4\\})};\\ ] ]    @xmath91 \\bigr{\\vert}\\nonumber \\\\[-8pt ] \\label{eqn6}\\\\[-8pt ] \\nonumber & & \\qquad\\leqslant c_3n^{-(1+\\min\\{1,\\delta/(2+\\delta)\\})}.\\end{aligned}\\ ] ]    for any @xmath88 , write @xmath92\\|$ ] .",
    "then , by the definition of  @xmath62 , we have @xmath93-h_{\\mu , x_1 } \\bigr\\ } ( v)\\biggr{\\vert}>\\varepsilon'\\sqrt{n}\\biggr ) \\\\ & & \\qquad\\leqslant \\mathrm{p}\\biggl(\\bigl{\\vert}\\exp^{-1}_\\mu(x_1 ) \\bigr{\\vert}>\\varepsilon'\\frac{\\sqrt n}{2}\\mbox { or } \\bigl{\\vert}\\bigl\\{\\mathrm{e}[h_{\\mu , x_1}]-h_{\\mu , x_1 } \\bigr\\ } ( v)\\bigr { \\vert}>\\varepsilon'\\frac { k}{2}\\biggr ) \\\\ & & \\qquad \\leqslant \\mathrm{p}\\biggl(\\bigl{\\vert}\\exp^{-1}_\\mu(x_1 ) \\bigr{\\vert}>\\varepsilon'\\frac{\\sqrt n}{2}\\biggr)+\\mathrm{p } \\biggl(\\bigl{\\vert}\\mathrm{e}[h_{\\mu , x_1}]-h_{\\mu , x_1}\\bigr { \\vert}>\\varepsilon'\\frac{k}{2|v|}\\biggr).\\end{aligned}\\ ] ] thus if @xmath94 , it follows from chebyshev s inequality that @xmath95 \\frac { 2^{2+\\delta}}{(\\varepsilon ' \\sqrt{n})^{2+\\delta}}+\\operatorname{var}\\bigl(\\|h_{\\mu , x_1}\\|\\bigr)\\frac { ( 2|v|)^2}{(\\varepsilon'k)^2 } \\\\ & & \\qquad \\leqslant \\mathrm{e}\\bigl[\\rho(\\mu , x_1)^{2+\\delta}\\bigr ] \\frac { 2^{2+\\delta}}{(\\varepsilon ' \\sqrt{n})^{2+\\delta}}+\\mathrm{e}\\bigl[\\|h_{\\mu , x_1}\\|^2\\bigr ] \\frac { ( 2|v|)^2}{(\\varepsilon ' k)^2},\\end{aligned}\\ ] ] when @xmath54 is sufficiently large .",
    "note that the assumption that @xmath94 implies that @xmath96 . if @xmath97 , a modified argument will show that the above still holds for @xmath96 .",
    "hence , ( [ eqn4 ] ) follows .",
    "similarly , using the definition of @xmath62 , we have @xmath98 \\\\ & & \\qquad \\leqslant \\frac{2}{n}\\mathrm{e}\\bigl[\\bigl{\\vert}\\bigl ( \\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-1}\\exp ^{-1}_\\mu(x_1 ) \\bigr{\\vert}^2\\bigr]+\\frac{2}{k^2}\\mathrm{e}\\bigl[\\bigl { \\vert}\\bigl(i- \\bigl(\\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-1}h_{\\mu , x_1 } \\bigr)v\\bigr{\\vert}^2\\bigr].\\end{aligned}\\ ] ] thus , under the given conditions , result ( i ) also implies that , for any @xmath79 and some constant @xmath81 depending on @xmath83 and @xmath84 , we have @xmath99\\bigr{\\vert}\\\\ & & \\qquad \\leqslant   \\mathrm{e}\\bigl[\\bigl{\\vert}v^n_{k+1}-v^n_k \\bigr{\\vert}^2\\vert v^n_k = v \\bigr]^{1/2 } \\mathrm{p}\\bigl(\\bigl{\\vert}v^n_{k+1}-v^n_k \\bigr{\\vert}>1\\vert v^n_{k}=v\\bigr)^{1/2 } \\\\ & & \\qquad \\leqslant c_2n^{-(1+\\min\\{1/2,\\delta/4\\})},\\end{aligned}\\ ] ] for @xmath85 , for sufficiently large @xmath54 and for all @xmath66 such that @xmath87 , so that ( [ eqn5 ] ) holds .    to show ( [ eqn6 ] ) , we note that there are positive constants @xmath100 independent of @xmath54 and @xmath76 such that , for given @xmath101 , @xmath102 thus , by result ( i ) , @xmath103 \\bigr{\\vert}\\\\ & & \\qquad \\leqslant   \\frac{a}{n}\\mathrm{e}\\bigl[\\bigl|\\exp^{-1}_{\\mu } ( x_1)\\bigr|^21_{\\{{\\vert}v^n_{k+1}-v^n_k{\\vert}>1\\ } } \\vert v^n_k = v\\bigr]+\\frac{b}{k^2}\\mathrm{e } \\bigl[c+\\|h_{\\mu , x_1}\\|^2\\bigr]|v|^2 \\\\ & & \\qquad \\leqslant\\frac{a}{n}\\mathrm{e}\\bigl[\\bigl|\\exp^{-1}_{\\mu } ( x_1)\\bigr|^{2+\\delta } \\bigr]^{2/(2+\\delta ) } \\mathrm{p}\\bigl(\\bigl{\\vert}v^n_{k+1}-v^n_k \\bigr{\\vert}>1\\vert v^n_k = v\\bigr)^{\\delta/(2+\\delta ) } \\\\ & & \\qquad \\quad{}+\\frac{b}{k^2}\\mathrm{e}\\bigl[c+\\|h_{\\mu , x_1}\\|^2 \\bigr]|v|^2 \\\\ & & \\qquad \\leqslant \\frac{a}{n}\\mathrm{e}\\bigl[\\bigl|\\exp^{-1}_{\\mu } ( x_1)\\bigr|^{2+\\delta } \\bigr]^{2/(2+\\delta ) } \\times\\frac{c'}{n^{\\delta/(2+\\delta)}}+\\frac { b}{k^2}\\mathrm{e } \\bigl[c+\\|h_{\\mu , x_1}\\|^2\\bigr]|v|^2\\end{aligned}\\ ] ] for some constant @xmath104 dependent on @xmath105 , so that the required result follows .",
    "[ cor1 ] under the assumptions of lemma  [ lem2 ] , for any @xmath56 and @xmath79 , the following limits hold uniformly in @xmath85 :    for any @xmath88 , @xmath106    @xmath107\\bigr{\\vert}=0;\\ ] ]    @xmath108-a\\bigr{\\vert}\\\\ & & \\qquad = 0,\\end{aligned}\\ ] ]    where @xmath109^{-1}\\gamma \\mathrm{e}[h_{\\mu , x_1}]^{-\\top}$ ] and @xmath110.\\ ] ]    by ( [ eqn4 ] ) , for any @xmath85 , @xmath111 \\frac { 2^{2+\\delta}}{(\\varepsilon ' \\sqrt{n})^{2+\\delta}}+\\mathrm{e}\\bigl[\\|h_{\\mu , x_1}\\|^2\\bigr ] \\frac { ( 4|v|)^2}{(\\varepsilon ' \\varepsilon_0n)^2},\\end{aligned}\\ ] ] when @xmath54 is sufficiently large .",
    "thus ( i ) holds . noting that @xmath112=v^n_k$ ]",
    ", ( ii )  follows from ( [ eqn5 ] ) . since @xmath113 \\bigr)^{-1}\\bigl(\\exp^{-1}_\\mu ( x_1 ) \\bigr ) \\biggr)=\\frac{1}{n}a,\\ ] ] ( iii ) is equivalent to @xmath114 \\bigr{\\vert}=0,\\ ] ] which follows from ( [ eqn6 ] ) .",
    "the properties that we have obtained so far on @xmath115 enable us to prove the weak convergence of @xmath53}\\vert t\\geqslant0\\}$ ] as follows .",
    "[ prop ] in addition to the assumptions in ( [ eqn3 ] ) , assume that , for some @xmath77 , @xmath78<\\infty$ ]",
    ". then the sequence of processes @xmath53}\\vert t\\geqslant0\\}$ ] converges weakly in @xmath116 , the space of right continuous functions with left limits on the tangent space of @xmath4 at @xmath2 , to @xmath117 as @xmath118 , where @xmath119 is the solution of the stochastic differential equation @xmath120 \\bigr)^{-1}\\gamma \\bigl(\\mathrm{e}[h_{\\mu , x_1 } ] \\bigr)^{-\\top } \\bigr\\ } ^{1/2}\\ , db_t\\ ] ] with @xmath121 , @xmath122 a standard brownian motion in @xmath123 and @xmath124 is defined by ( [ eqn8 ] ) .",
    "let @xmath125 .",
    "then @xmath126 is a time - homogeneous markov chain .",
    "for each @xmath127 , write @xmath128 for the transition probability distribution associated with @xmath126 , that is , @xmath129 where @xmath130 is any borel set in @xmath131 .    for any @xmath56",
    ", the result of lemma  [ lem1 ] implies that @xmath132}\\vert n\\geqslant1\\}$ ] is tight .",
    "hence , there is a subsequence @xmath133}\\vert j\\geqslant1\\}$ ] that converges weakly in @xmath134 to a random variable @xmath135 .",
    "then it follows from corollary  7.4.2 in @xcite ( pages 355356 ) that the results of the imply that the sequence of processes @xmath136}\\vert t\\geqslant\\varepsilon_0\\}$ ] converges weakly in @xmath137 to a diffusion @xmath138 , where @xmath139 with the initial condition that @xmath140 has the same distribution as @xmath141 and where @xmath119 satisfies the stochastic differential equation ( [ eqn7 ] ) .",
    "this implies ( cf .",
    "@xcite , page 355 ) that @xmath142}\\vert t\\geqslant\\varepsilon_0\\}$ ] converges weakly in @xmath143 to @xmath144 , where @xmath145 has the same distribution as @xmath146 .    to show the required result ,",
    "it is now sufficient to show that , for any subsequence of @xmath53}\\vert t\\geqslant0\\}$ ] , there is a further subsequence which converges weakly to @xmath117 . without loss of generality",
    ", we may rename the subsequence as @xmath147}^n\\vert t\\geqslant0\\}$ ] and apply the above to @xmath148 . for each @xmath149 , this gives a subsequence @xmath150}\\vert t\\geqslant0\\}$ ] indexed by @xmath151 , of @xmath152}\\vert t\\geqslant0\\}$ ] , which converges weakly on @xmath153 to @xmath154 .",
    "hence , we obtain a sequence indexed by @xmath151 of subsequences , and we then take the diagonal subsequence .",
    "the diagonal subsequence converges weakly in @xmath155 to @xmath156 .",
    "however , the result of lemma  [ lem1 ] shows that @xmath157\\rightarrow0 $ ] as @xmath158 and so the required result follows by noting that @xmath159 must be equal in law to @xmath117 .",
    "we now return to consider the sample frchet means of @xmath8 . for this , we denote by @xmath160 a sample frchet mean of @xmath161 for each @xmath76 , so that @xmath160 converges to @xmath2 almost surely ( cf .",
    "it follows from ( [ eqn1 ] ) that @xmath162 satisfies the condition @xmath163 thus the origin of the tangent space of @xmath4 at @xmath160 , @xmath164 , is the sample euclidean mean of the euclidean random variables @xmath165 , @xmath166 .",
    "nevertheless , although these relations resemble those for euclidean means , these conditions are generally imposed on different tangent spaces , resulting in the difficulty in obtaining a usable form of the relation between consecutive sample frchet means .",
    "moreover , the usual difference `` @xmath167 '' makes no sense here .",
    "however , in the context of manifolds , @xmath168 plays a similar role to @xmath169 in the euclidean case .",
    "this leads us to consider , for each @xmath49 , the re - scaled sequence @xmath170 it is clear from ( [ eqn9 ] ) , which the sample frchet means must satisfy , that @xmath171 can not generally be expected to be determined by @xmath160 and @xmath69 alone so that in particular , @xmath172 , and so @xmath173 , is in general _ not _ a markov chain .",
    "however , the following result shows that , for sufficiently large @xmath54 and @xmath76 , the behaviour of @xmath173 is close to that of a markov chain .",
    "[ lem3 ] in addition to the assumptions in ( [ eqn3 ] ) , assume that @xmath174=0,\\ ] ] where @xmath175 denotes the parallel transport from @xmath15 to @xmath176 along the geodesic between the two points .",
    "then , for any @xmath56 , @xmath79 , and @xmath177 , @xmath178}-v^n_{[nt ] } \\bigr)-\\bigl(w^n_{[\\varepsilon_0n]}-v^n_{[\\varepsilon _ 0n]}\\bigr ) \\bigr{\\vert}\\stackrel{\\mathrm{p } } { \\longrightarrow}0 \\qquad\\mbox{as } n\\rightarrow \\infty,\\ ] ] where @xmath50 are the markov chains defined in the previous section and @xmath179}|\\geqslant r\\mbox { or } |w^n_{[nt]-1}|\\geqslant r\\}$ ] .      note also that @xmath180 is , as a mapping from @xmath181 , smooth with respect to @xmath15 if @xmath182 and , by ( [ eqn0 ] ) , it is positive - definite provided @xmath183 .",
    "thus the relationship between @xmath25 and @xmath184 ensures that all three assumptions required for lemma  [ lem3 ] are satisfied if the support for the distribution of @xmath6 is a compact subset of the open ball @xmath185 .",
    "proof of lemma  [ lem3 ] define , for each given @xmath76 , the random vector field @xmath186 on  @xmath187 by @xmath188 for @xmath189 . for each fixed @xmath15",
    ", @xmath190 is the sample euclidean mean of random variables @xmath191 . by hypothesis on @xmath192 and the result of @xcite",
    ", @xmath193 is defined almost surely , and it follows from ( [ eqn1 ] ) that @xmath194=0 $ ] .",
    "moreover , @xmath160 being a sample frchet mean of @xmath161 implies that @xmath195 almost surely .",
    "using these facts and using parallel transport followed by taylor s expansion , kendall and le @xcite show that @xmath196 where the correction operator @xmath197 satisfies the condition that , for any given @xmath88 , there exists @xmath198 such that the ball , @xmath199 , that is centred at @xmath2 and with radius  @xmath200 is contained in @xmath201 and , for any @xmath15 in that ball , @xmath202 thus , noting by ( [ eqn2 ] ) that @xmath203 we can rewrite ( [ eqn10 ] ) as @xmath204 which leads to a link between @xmath205 and the rescaled sample euclidean mean @xmath193 .",
    "on the other hand , @xmath206 where @xmath207 this , together with ( [ eqn11 ] ) , gives @xmath208 it then follows from the definition of @xmath205 that the difference @xmath209 can be expressed as @xmath210 or equivalently as @xmath211 however , under the given assumptions , we have @xmath212 \\quad\\mbox{and}\\quad \\frac{1}{k}\\bigl\\|\\delta_k(\\mu_k;x_1 , \\ldots , x_k)\\bigr\\|\\stackrel{\\mathrm { p}}{\\longrightarrow}0\\ ] ] ( cf .",
    "@xcite ) , so that in particular , @xmath213 .",
    "hence , it follows that @xmath214 \\bigr)^{-1}\\exp^{-1}_\\mu ( x_{k+1 } ) \\\\ & & { } + \\biggl\\{\\frac{k+1}{k}i-\\frac{1}{k}\\bigl(e[h_{\\mu , x_1 } ] \\bigr)^{-1}h_{\\mu , x_{k+1 } } \\biggr\\}\\bigl(w^n_k \\bigr)+ o\\bigl(k^{-1}\\bigr ) \\qquad \\mbox{a.s.},\\end{aligned}\\ ] ] where @xmath215 is the identity operator .",
    "this implies that , for @xmath216 , @xmath217}-v^n_{[nt]}\\bigr)- \\bigl(w^n_{[\\varepsilon_0n]}-v^n_{[\\varepsilon_0n]}\\bigr ) \\\\ & & \\qquad = \\bigl(w^n_{[nt]-1}-v^n_{[nt]-1}\\bigr)- \\bigl(w^n_{[\\varepsilon_0n]}-v^n_{[\\varepsilon _ 0n]}\\bigr ) \\\\ & & \\qquad = \\frac{1}{[nt]-1 } \\bigl\\{i-\\bigl(e[h_{\\mu , x_1}]\\bigr)^{-1}h_{\\mu , x_{[nt ] } } \\bigr\\}\\bigl(w^n_{[nt]-1}-v^n_{[nt]-1 } \\bigr)\\\\ & & \\qquad\\quad{}+o\\bigl([nt]^{-1}\\bigr)\\qquad \\mbox{a.s.}\\end{aligned}\\ ] ] so that , for @xmath218 , @xmath219}-v^n_{[nt ] } \\bigr)-\\bigl(w^n_{[\\varepsilon_0n]}-v^n_{[\\varepsilon _ 0n]}\\bigr ) \\bigr{\\vert}\\\\ & & \\qquad \\leqslant \\bigl{\\vert}\\bigl(w^n_{[nt]-1}-v^n_{[nt]-1 } \\bigr)-\\bigl(w^n_{[\\varepsilon _ 0n]}-v^n_{[\\varepsilon_0n]}\\bigr ) \\bigr{\\vert}+o\\bigl([nt]^{-1}\\bigr).\\end{aligned}\\ ] ] the required result then follows .",
    "we are now in the position to state and prove the main result of the paper concerning the limiting diffusion associated with the sequences of the rescaled images @xmath220 , under @xmath221 , of the frchet means @xmath160 of @xmath161 .",
    "[ thm1 ] under the assumptions of the and lemma  [ lem3 ] , the sequence of processes @xmath222}\\vert t\\geqslant0\\}$ ] converges weakly in @xmath223 to @xmath224 , where @xmath225 ; @xmath205 , @xmath96 , is defined by ( [ eqn12 ] ) , and the @xmath119 are as given in the .    by the",
    ", we only need to show that , for any @xmath79 and @xmath177 , @xmath226}-v^n_{[nt ] } \\bigr{\\vert}\\stackrel{\\mathrm{p } } { \\longrightarrow } 0\\qquad \\mbox{as } n\\rightarrow \\infty,\\ ] ] where @xmath179}|\\geqslant r\\mbox { or } |w^n_{[nt]-1}|\\geqslant r\\}$ ] .",
    "since @xmath227 , we have @xmath228}-v^n_{[nt ] } \\bigr{\\vert}\\\\ & & \\qquad = \\lim_{\\varepsilon_0\\downarrow0}\\sup_{\\varepsilon_0\\leqslant t\\leqslant t\\wedge\\sigma_n^r}\\bigl{\\vert}\\bigl(w^n_{[nt]}-v^n_{[nt]}\\bigr)\\bigr { \\vert}\\\\ & & \\qquad\\leqslant \\lim_{\\varepsilon_0\\downarrow0}\\bigl\\{\\sup_{\\varepsilon _ 0\\leqslant t\\leqslant t\\wedge\\sigma_n^r}\\bigl { \\vert}\\bigl(w^n_{[nt]}-v^n_{[nt]}\\bigr)- \\bigl(w^n_{[\\varepsilon_0n]}-v^n_{[\\varepsilon _ 0n]}\\bigr)\\bigr { \\vert}\\\\ & & \\hspace*{133pt}\\qquad\\quad{}+\\bigl{\\vert}w^n_{[\\varepsilon_0n]}\\bigr{\\vert}+\\bigl{\\vert}v^n_{[\\varepsilon _ 0n]}\\bigr{\\vert}\\bigr\\}.\\end{aligned}\\ ] ] thus , for any @xmath88 , we have for all sufficiently small @xmath56 , @xmath229}-v^n_{[nt]}\\bigr)\\bigr { \\vert}>6\\varepsilon\\bigr ) \\\\ & & \\qquad   \\leqslant   \\mathrm{p}\\bigl(\\sup_{\\varepsilon _ 0\\leqslant t\\leqslant t\\wedge\\sigma_n^r}\\bigl{\\vert}\\bigl(w^n_{[nt]}-v^n_{[nt]}\\bigr)- \\bigl(w^n_{[\\varepsilon _ 0n]}-v^n_{[\\varepsilon _ 0n]}\\bigr)\\bigr { \\vert}\\\\ & & \\hspace*{87pt}\\qquad\\qquad{}+\\bigl{\\vert}w^n_{[\\varepsilon_0n]}\\bigr{\\vert}+\\bigl{\\vert}v^n_{[\\varepsilon_0n]}\\bigr{\\vert}>3\\varepsilon\\bigr ) \\\\ & & \\qquad   \\leqslant \\mathrm{p}\\bigl(\\sup_{\\varepsilon _ 0\\leqslant t\\leqslant t\\wedge\\sigma_n^r}\\bigl{\\vert}\\bigl(w^n_{[nt]}-v^n_{[nt]}\\bigr)- \\bigl(w^n_{[\\varepsilon _ 0n]}-v^n_{[\\varepsilon _ 0n]}\\bigr)\\bigr { \\vert}>\\varepsilon\\bigr ) \\\\ & & \\qquad\\quad{}+ \\mathrm{p}\\bigl(\\bigl{\\vert}w^n_{[\\varepsilon_0n]}\\bigr { \\vert}>\\varepsilon \\bigr)+\\mathrm{p}\\bigl(\\bigl{\\vert}v^n_{[\\varepsilon_0n ] } \\bigr{\\vert}>\\varepsilon\\bigr).\\end{aligned}\\ ] ] the first term on the right tends to zero as @xmath118 by lemma  [ lem3 ] .",
    "it follows from the that the distribution @xmath230 of @xmath145 is gaussian with mean zero and covariance matrix @xmath231^{-1}\\gamma \\mathrm{e}[h_{\\mu , x_1}]^{-\\top}$ ] , where @xmath124 is given by ( [ eqn8 ] ) .",
    "this implies that the limiting distribution of @xmath232}$ ] is @xmath233 .",
    "moreover , the result of @xcite implies that @xmath233 is also the limiting distribution of @xmath234}$ ] .",
    "thus , as @xmath118 , both the second and third terms on the right are bounded above by var@xmath235 , so that @xmath236}-v^n_{[nt ] } \\bigr)\\bigr{\\vert}>6\\varepsilon\\bigr)\\leqslant2\\frac { \\operatorname{var}(|v_{\\varepsilon_0}|)}{\\varepsilon^2}.\\ ] ] since @xmath237 , the independence of the left - hand side above on @xmath83 then gives the required result .",
    "it is interesting to note the relationship between the result of the and the central limit theorem for frchet means obtained in @xcite , in comparison with that between the corresponding results for euclidean means .",
    "it is also interesting to see the difference between the limiting diffusion obtained here and that obtained in @xcite .",
    "the latter should shed some light on the difference between the asymptotic behaviour of the sample frchet means and that of the random sequence obtained using the stochastic gradient algorithm constructed in @xcite ."
  ],
  "abstract_text": [
    "<S> this paper studies rescaled images , under @xmath0 , of the sample frchet means of i.i.d . </S>",
    "<S> random variables @xmath1 with frchet mean @xmath2 on a riemannian manifold . </S>",
    "<S> we show that , with appropriate scaling , these images converge weakly to a diffusion process . </S>",
    "<S> similar to the euclidean case , this limiting diffusion is a brownian motion up to a linear transformation . </S>",
    "<S> however , in addition to the covariance structure of @xmath3 , this linear transformation also depends on the global riemannian structure of the manifold .    </S>",
    "<S> ./style / arxiv - general.cfg </S>"
  ]
}