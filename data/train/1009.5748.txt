{
  "article_text": [
    "in this paper , we consider the multiparameter version of the classic optimal detection problem ; the goal is to detect the occurrence of a random set on which an observable poisson process changes its intensity . to be precise , we let @xmath0 be a nonexplosive point process defined on the positive quadrant of the plane and let @xmath1 be its jump points , numbered in some arbitrary way .",
    "then @xmath2 ( cf .",
    "@xcite ) . here , `` @xmath3 '' denotes the usual partial order on @xmath4 . on some random set @xmath5 ,",
    "the intensity of @xmath6 changes from @xmath7 to @xmath8 , where @xmath9 : specifically , given @xmath5 , @xmath6 is a poisson process with intensity @xmath10 the problem is that the `` change - set '' @xmath5 is unobservable and we must detect @xmath5 as well as possible , given our observation of the point process @xmath6 . in particular , our goal is to find a random set @xmath11 that maximizes the expected value of a specified valuation or gain function .",
    "the random set @xmath11 must be adapted to the underlying information structure : if the information available to us at @xmath12 is represented by the @xmath13-field @xmath14 , then we must have @xmath15 .",
    "there are many potential areas of application .",
    "for example :    * environment : the increased occurrence of polluted wells in a rural area could indicate a geographic region that has been subjected to industrial waste .",
    "* population health : unusually frequent outbreaks of a disease such as leukemia near a nuclear power plant could signal a region of possible air or ground contamination . *",
    "astronomy : a cluster of black holes could be the result of an unobservable phenomenon affecting a region in space . * quality control : an increased rate of breakdowns in a certain type of equipment might follow the failure of one or more components . *",
    "archaeology : an increased number of archaeological items such as ancient coins found in a particular region could indicate the location of an event of historical interest .",
    "* forestry : the spread of an airborne disease through a forest would occur at a higher rate on @xmath5 , the set of points to the northeast of the ( unobserved ) point ( @xmath13 ) of initial infection if the prevailing winds are from the southwest .",
    "it is this final type of example , illustrated in figure  [ fig1 ] , that motivates the model to be studied in this paper .     generated by a single point @xmath13 . ]",
    "as will be discussed in the conclusion , this paper represents only a first step in the solution of what we call the `` optimal set - detection problem . ''",
    "here , we consider the case in which the change - set @xmath5 is a random _ upper layer _ ( cf .",
    "section  [ model ] ) generated by a locally finite set of incomparable points . in general , the optimal solution @xmath11 will be a random upper layer which is adapted to the available information structure .",
    "this means that the solution is exact in the sense that it is explicitly defined by the observed data points .",
    "this problem can not be solved by one - parameter methods .",
    "indeed , even if the random set is characterized by a single change - point , it will be seen that the optimal solution does not necessarily correspond to a point .    in the one - parameter case ,",
    "the optimal detection of an exponential change time in a poisson process was thoroughly studied in @xcite using martingale techniques combined with bayesian arguments ( see also @xcite for a different approach to the same problem ) . in the general set - indexed framework , we found only a very few papers addressing the problem of a change - point or a change - set ( cf . @xcite , @xcite and @xcite ) .",
    "however , none of these papers deal with the question of the existence of an optimal solution to the detection problem .",
    "our approach , inspired by that of @xcite , makes use of the general theory of set - indexed martingales as developed in @xcite .",
    "we are then able to solve the problem with a bayes - type formula .",
    "the paper is structured as follows . in the next section ,",
    "the model is presented and the optimal detection problem is formally defined . in section  [ preliminaries ] ,",
    "we give the necessary background for the multiparameter martingale approach that is the key for proving the existence of an optimal solution , and develop a semimartingale representation of the gain function . in section",
    "[ solution ] , sufficient conditions for the existence of an optimal solution are developed , and then applied to two examples in section  [ examples ] . finally , in section [ conclusion ] , we discuss possible extensions and directions for further research .",
    "in order to better understand the two - dimensional model , we review the change - point problem on @xmath16 considered in @xcite . we have a nonexplosive point process @xmath17 on @xmath16 , and a random time @xmath18 . given @xmath13 ,",
    "@xmath6  is a poisson process with intensity @xmath7 on @xmath19 and intensity @xmath8 on @xmath20 ( @xmath21 ) . modifying the notation of @xcite slightly ,",
    "the gain function at @xmath22 is defined by @xmath23 where @xmath24 , @xmath25 and @xmath26 .",
    "the parameters can be interpreted as follows : the gain function is piecewise linear , increasing at rate @xmath27 before the jump point and decreasing at rate @xmath28 after . when @xmath29 , a penalty equivalent to @xmath30 is incurred for stopping the process before the change has occurred .",
    "the gain is maximized when @xmath31 .",
    "let @xmath32 denote the filtration which characterizes the underlying information available ( in @xcite , the process @xmath6 is always @xmath33-adapted ) . for various filtrations ,",
    "it is shown in @xcite that @xmath34 has a _ smooth semimartingale _ ( ssm ) representation with respect to @xmath33 : @xmath35 where @xmath36 is an @xmath33-martingale and @xmath37 is @xmath33-progressive ( i.e. , observable ) . if @xmath37 is _ monotone _ in the sense that @xmath38 , then it is straightforward to see that ( cf .",
    "@xcite , theorem 1 ) @xmath39 is an optimal @xmath33-stopping rule for @xmath40 in terms of expected values : we have @xmath41=\\sup\\{e[z_\\tau]{}\\dvtx{}\\tau\\mbox { an $ { \\mathcaligr}{f}$-stopping time}\\}.\\ ] ] to motivate the model on @xmath42 , we will rewrite ( [ ( 1 ) ] ) in terms of the single jump point process @xmath43 and the random set @xmath44 : @xmath45\\\\[-8pt ] & = & k_0+\\int_{a_t } \\bigl(-c_1+(c_0+c_1)x_u \\bigr)\\,du+k_1l_t,\\nonumber\\end{aligned}\\ ] ] where @xmath46 $ ] , @xmath47 denotes lebesgue measure and @xmath48 .",
    "we are now ready to describe the two - dimensional model .",
    "we are given a random borel set @xmath49 .",
    "@xmath6 is a nonexplosive point process on @xmath50 such that given @xmath5 , @xmath6 is poisson with intensity @xmath7 on @xmath51 and @xmath8 on @xmath5 .",
    "it is always assumed that @xmath21 .",
    "( the case @xmath52 will be briefly discussed at the end of section  [ solution ] . )",
    "we will assume that the set @xmath5 is generated by a _ single line point process _",
    "@xmath53 : that is , @xmath53 is a nonexplosive point process whose jump points are all incomparable ( @xmath54 are incomparable if both @xmath55 and @xmath56 ) .",
    "it is noted in @xcite that in two or more dimensions , the single line process is the natural generalization of the single jump process , and in analogy with the change - point model on @xmath16 , we define @xmath57 .",
    "we observe that @xmath5 is an _ upper layer _",
    "( @xmath5 is an upper layer if @xmath58 ) .",
    "when @xmath53 has only one jump point @xmath13 , we observe that @xmath5 consists of the points to the northeast of @xmath13 .",
    "this is illustrated in figure  [ fig1 ] .",
    "the more general situation in which @xmath53 is a single line process is illustrated in figure  [ fig2 ] . in this case , @xmath5 consists of all the points to the northeast of one or more jump points of  @xmath53 .     generated by a single line process @xmath53 . ]    using notation similar to that used for the one - dimensional problem , for @xmath59 let @xmath60 and @xmath61 .",
    "the definition of the gain function at @xmath12 is exactly the same is in ( [ ( 4 ) ] ) : @xmath62\\\\[-8pt ] & = & k_0+\\int_{a_t } \\bigl(-c_1+(c_0+c_1)x_u \\bigr)\\,du+k_1l_t.\\nonumber\\end{aligned}\\ ] ] once again , we assume that @xmath24 , @xmath25 and @xmath63 , and that @xmath47 denotes lebesgue measure on @xmath42 .     and the change - set @xmath5 . ]    any point process",
    "@xmath6 can be indexed by the borel sets in @xmath64 . as in the , if @xmath1 denotes the jump points of @xmath6 numbered in some arbitrary way , then for any borel set @xmath65 , @xmath66 .",
    "[ therefore , we have @xmath67 . ]",
    "consequently , we can define the gain function more generally over the class of _ lower layers _",
    "@xmath68 : a set @xmath69 is a lower layer if @xmath70 . the gain function at @xmath71",
    "is defined as @xmath72 a lower layer @xmath65 and the change - set @xmath5 are illustrated in figure  [ fig3 ] ; we observe that @xmath73 in this case .",
    "we see that the gain function defined in ( [ ( 6 ) ] ) is a natural generalization of the one - dimensional gain function ( [ ( 1 ) ] ) .",
    "the gain evaluated at @xmath65 increases in proportion to the area of @xmath65 outside of the change - set @xmath5 , and decreases in proportion to the area inside of @xmath5 . when @xmath29 , there is a penalty incurred that is equivalent to @xmath30 times the number of points in @xmath53 that lie outside of ( or `` after '' ) @xmath65 .",
    "the gain is maximized when @xmath74 .",
    "we would like to find a random lower layer that maximizes the expected value of the gain function .",
    "the lower layer will depend on the available information , or more precisely , the underlying _ filtration .",
    "_    a class of @xmath13-fields @xmath75 is a filtration if :    * @xmath33 is increasing : @xmath76 , and * @xmath33 is outer - continuous : @xmath77 for every decreasing sequence @xmath78 with @xmath79 .",
    "[ dfstopping ] a closed random lower layer @xmath80 is an @xmath33-stopping set if @xmath81    the general optimal set - detection problem in two dimensions can now be stated as follows : for a given filtration @xmath33 , our goal is to maximize @xmath82 $ ] , where @xmath80 is an @xmath33-stopping set . if it can be shown that a stopping set @xmath83 exists that satisfies the condition @xmath84=\\sup\\{e[z({\\rho})]{}\\dvtx{}\\rho\\mbox { an $ { \\mathcaligr}{f}$-stopping set}\\},\\ ] ] then our optimal estimate of @xmath5 is @xmath85 [ @xmath86 denotes set closure ] .",
    "it is trivial that @xmath11 is an upper layer , and by outer continuity of @xmath33 , it is easily seen that @xmath11 is also an adapted random set ( i.e. , @xmath87",
    ".    in this paper , we will be focussing on the _ sequential _ estimation problem : that is , we will be assuming that @xmath88 .",
    "if @xmath80 is an @xmath89-stopping set , then @xmath90 is a function of the number and locations of jump points of @xmath6 in the set @xmath91 .",
    "for technical reasons , we shall see that in general it is necessary to restrict the detection problem to a bounded rectangle @xmath92 ^ 2 $ ] .",
    "the goal is to find a stopping set @xmath93 that is optimal in the following sense :    [ dfsolution ] an @xmath94-stopping set @xmath95 is called an optimal solution to the sequential detection problem on @xmath96 provided that @xmath83 satisfies the following equation : @xmath97=\\sup\\{e[z({\\rho})]{}\\dvtx{}\\rho\\subseteq r \\mbox { an $ { \\mathcaligr}{f}^n$-stopping set}\\}.\\ ] ]    restricting our attention to @xmath96 ensures that @xmath83 is bounded and so @xmath98 $ ] is always well defined . in this case , we have an optimal estimate @xmath99 of @xmath100 , defined by @xmath101 .",
    "in this section we present the mathematical tools needed in the sequel . in @xcite , herberts and jensen make use of martingale techniques to provide a simple and elegant method of finding sufficient conditions for the existence of an optimal solution to the detection problem on @xmath16 .",
    "martingale methods have been extended to more general spaces in @xcite , and we are able to exploit this theory in a similar way . to motivate the necessary technical details that follow ,",
    "we first describe our overall plan of attack .",
    "recall that @xmath94 denotes the filtration representing the data that can be observed , and below @xmath102 will denote a larger filtration containing additional information , some of which can not be observed .",
    "_ plan of attack _ :    * the gain function @xmath40 can be rewritten as a ( two - parameter ) semimartingale ( definition  [ defssm ] ) : @xmath103 where @xmath36 is a weak martingale ( definition  [ mg ] ) with respect to a filtration @xmath102 and @xmath37 is @xmath102-adapted but not necessarily observable ( cf .",
    "lemma  [ fullssm ] ) . * for the observable filtration @xmath94 and @xmath80 an @xmath89-stopping set , we have @xmath104=0 $ ] ( lemma  [ stopping ] ) and if @xmath105 $ ] ( observable ) , then(lemma  [ projection ] ) @xmath106=k_0+e \\biggl[\\int_\\rho u_t\\,dt \\biggr]\\\\ = k_0+e \\biggl[\\int_\\rho v_t\\,dt \\biggr].\\ ] ] * if @xmath107 satisfies a monotonicity property on @xmath96 ( cf . definition  [ defmonotone ] andlemma  [ projection ] ) , then there exists an optimal solution @xmath83 to the sequential detection problem on  @xmath96 , and the optimal estimate of @xmath100 is @xmath108    keeping this outline of our approach in mind , we continue with the necessary mathematical details .",
    "martingales on @xmath42 can be defined in various ways ( cf .",
    "@xcite ) , but here we need only the weakest definition . in what follows , @xmath109",
    "denotes either @xmath42 or a bounded region @xmath92 ^ 2 $ ] , and @xmath110 is a complete probability space equipped with a @xmath109-indexed filtration @xmath111 ( without loss of generality , assume that @xmath14 contains all the @xmath112-null sets @xmath113 ) .",
    "a  @xmath109-indexed process @xmath114 is adapted to @xmath33 if @xmath115 is @xmath14-measurable , for all @xmath116 .",
    "for any @xmath109-indexed process @xmath114 , for @xmath117 , define the increment of @xmath118 over the rectangle @xmath119=(s_1,t_1]\\times(s_2,t_2]$ ] in the usual way : @xmath120=x_{(t_1,t_2)}-x_{(s_1,t_2)}-x_{(t_1,s_2)}+x_{(s_1,s_2)}.\\ ] ]    [ mg ] let @xmath121 be an integrable process on @xmath109 , adapted to a filtration @xmath111 .",
    "@xmath36 is a weak @xmath33-(sub)martingale if @xmath36 is equal to 0 on the axes , and for every @xmath122 , @xmath123|{\\mathcaligr}{f}_s]=(\\geq)0.\\ ] ] ( a process @xmath118 is integrable if @xmath124<\\infty \\,\\forall",
    "t\\in t$ ] . )",
    "[ increasing ] let @xmath125 be a function on @xmath109 .",
    "we say that @xmath126 is increasing ( decreasing ) if :    * @xmath126 is 0 on the axes , * @xmath126 is outer continuous with inner limits : that is , @xmath126 is continuous from above and with limits from the other three quadrants at each @xmath127 , and * for every @xmath122 , @xmath128\\geq(\\leq ) 0 $ ] .",
    "a process @xmath129 is increasing ( decreasing ) if for each @xmath130 , the function @xmath131 is increasing ( decreasing ) .",
    "[ measure ] an increasing function @xmath126 can be regarded as the distribution of a measure on @xmath42 .",
    "therefore , @xmath132 is well defined for any borel set @xmath65 , where we use @xmath133 and @xmath134 to denote , respectively , the function and the generated measure .",
    "likewise , a decreasing function generates a negative measure , and we will use similar notation .     let @xmath53 be a weak @xmath33-submartingale .",
    "an increasing process @xmath135 is a compensator for @xmath53 if @xmath135 is @xmath33-adapted and @xmath136 is a weak martingale .    as defined above , the compensator of a submartingale need not be unique ( any increasing process is trivially a compensator for itself ) . a type of predictability is required for uniqueness ( cf .",
    "@xcite ) , but this point is not of importance here .",
    "in light of comment  [ measure ] , the following lemma is a special case of of lemma  3.3.5 of @xcite .    [ stopping ] if @xmath36 is a weak martingale which can be expressed as the difference of two increasing integrable processes , and @xmath80 is a stopping set such that @xmath137 ^ 2 $ ] , then @xmath138 is well defined and @xmath139=0 $ ] .",
    "[ defssm ] let @xmath140 be a process on @xmath109 , adapted to a filtration @xmath111 .",
    "@xmath40 is a smooth semimartingale with respect to @xmath33 ( @xmath33-ssm ) if it satisfies a decomposition of the form @xmath141 for each @xmath142 , where @xmath37 is an outer continuous process with inner limits adapted to @xmath33 and @xmath36 is a weak @xmath33-martingale .",
    "we denote the @xmath33-ssm as @xmath143 .    in order to show that an optimal solution exists to the sequential detection problem",
    ", we will require a monotonicity property .",
    "[ defmonotone ] a function @xmath125 is monotone on @xmath109 if @xmath144 .",
    "a process @xmath107 is monotone if @xmath145 is monotone for each @xmath130 .    1 .",
    "note that any decreasing function is monotone , but the converse is not true .",
    "if a process @xmath107 is decreasing in each parameter separately on @xmath109 , then @xmath107 is monotone on @xmath109 but not necessarily decreasing in the sense of definition  [ increasing ] .",
    "3 .   note that if @xmath107 is monotone , then @xmath146 .",
    "if @xmath107 is monotone and adapted to a filtration @xmath33 , the set @xmath147 is an @xmath33-stopping set ( cf . definition  [ dfstopping ] ) .",
    "[ @xmath148 if @xmath149 , and @xmath150 if @xmath151 , @xmath152 . ] clearly , @xmath83 is a random closed lower layer , and the fact that @xmath107 is adapted ensures that @xmath153 : taking any sequence @xmath154 with @xmath155 , by monotonicity it follows that @xmath156    in @xcite , the solution to the optimal stopping problem is based on a ssm representation of the form ( [ ( 2 ) ] ) , which in turn is based on a projection theorem .",
    "the question of the existence of optional and predictable projections in higher dimensions is a delicate one , usually requiring a strong assumption of conditional independence on the underlying filtration [ denoted ( f4 ) in the two - dimensional literature ] . for details , see @xcite , for example . in practice",
    ", one can generally show directly that a suitable projection exists without relying on a general existence theorem , and for our purposes the following lemma will be adequate .",
    "[ projection ] let @xmath37 be a bounded @xmath109-indexed process adapted to a filtration @xmath102 such that @xmath37 is outer - continuous with inner limits . if @xmath33 is a subfiltration of @xmath102 ( i.e. , @xmath157 ) , and if a version of @xmath158 $ ] exists that is outer - continuous with inner limits , then for any @xmath33-stopping set @xmath137 ^ 2 $ ] , @xmath159=e \\biggl[\\int_\\rho v_t\\,dt \\biggr].\\ ] ] in addition , if @xmath107 is monotone on @xmath96 , then the @xmath33-stopping set @xmath93 defined by @xmath160 is optimal in the sense that @xmath161 = \\sup \\biggl\\ { e \\biggl[\\int_\\rho u_t\\,dt \\biggr]{}\\dvtx{}\\rho\\subseteq r , \\rho\\mbox { an $ { \\mathcaligr}{f}$-stopping set }   \\biggr\\}.\\ ] ]    first , the assumption that @xmath37 and @xmath107 have sample paths that are regular ( outer - continuous with inner limits ) and that @xmath37 ( and hence @xmath107 ) is bounded ensures that the integrals and expectations in ( [ ( 10a ) ] ) are well defined .",
    "next , let @xmath162 denote the `` dyadics '' of order @xmath163 in  @xmath96 .",
    "the class of rectangles @xmath164 partitions @xmath96 , where @xmath165 if @xmath166 is of the form @xmath167 for some @xmath168 .",
    "let @xmath169 denote the lower left corner of @xmath166 .",
    "we now define the `` discrete '' approximation @xmath170 of @xmath80 by @xmath171 it is straightforward that @xmath172 is an @xmath33-stopping set , that @xmath173 is decreasing in @xmath163 and @xmath174 . boundedness and uniform integrability ensure that @xmath175=\\lim_ne [ \\int_{\\rho_n } u_t\\,dt ] $ ] and @xmath176=\\lim_ne [ \\int_{\\rho_n } v_t\\,dt ] $ ] . to complete the proof of the first statement in the theorem , observe that by boundedness of @xmath37 , @xmath177 & = & e \\biggl[\\sum_{c\\in{\\mathcaligr}{c}_n}i_{\\{t_{c-}\\in\\rho\\}}\\int_c u_t \\,dt \\biggr]\\\\ & = & e \\biggl[\\sum_{c\\in{\\mathcaligr}{c}_n}i_{\\{t_{c-}\\in\\rho\\}}e \\biggl[\\int_c u_t \\,dt\\big|{\\mathcaligr}{f}_{t_{c- } } \\biggr ] \\biggr]\\\\ & = & e \\biggl[\\sum_{c\\in{\\mathcaligr}{c}_n}i_{\\{t_{c-}\\in\\rho\\}}e \\biggl[\\int_c e[u_t|{\\mathcaligr}{f}_t ] \\,dt\\big|{\\mathcaligr}{f}_{t_{c- } } \\biggr ] \\biggr]\\\\ & = & e \\biggl[\\sum_{c\\in{\\mathcaligr}{c}_n}i_{\\{t_{c-}\\in\\rho\\}}e \\biggl[\\int_c v_t \\,dt\\big|{\\mathcaligr}{f}_{t_{c- } } \\biggr ] \\biggr]\\\\ & = & e \\biggl[\\sum_{c\\in{\\mathcaligr}{c}_n}i_{\\{t_{c-}\\in\\rho\\}}\\int_c v_t \\,dt \\biggr ] = e \\biggl[\\int_{\\rho_n}v_t\\,dt \\biggr].\\end{aligned}\\ ] ] the third equality above follows by fubini and the assumption that @xmath107 has regular sample paths , and since @xmath178 . [ the assumption that @xmath107 has a version with regular sample paths ensures that @xmath107 is jointly @xmath179-measurable , where @xmath180 denotes the borel sets in @xmath96 . ]",
    "next , assume that @xmath107 is monotone . to prove optimality of @xmath83 ,",
    "let @xmath181 be any other stopping set in @xmath96 .",
    "we have @xmath182 = e \\biggl [ \\int_{\\hat\\rho\\setminus\\rho } v_t \\,dt -\\int_{\\rho\\setminus\\hat\\rho } v_t\\,dt \\biggr]\\geq0,\\ ] ] since @xmath183 on @xmath184 ( the interior of @xmath83 ) and @xmath185 on @xmath186 .",
    "we begin this section with an analysis of the single line process @xmath187 : @xmath53 is a nonexplosive point process whose jump points are all incomparable .",
    "single line processes and their compensators were discussed in @xcite , to which the reader may refer for more detail .",
    "heuristically , if @xmath188 , then a process @xmath135 will be an @xmath189-compensator of @xmath53 if @xmath190 ) \\\\ & & \\qquad\\approx i_{\\{l_s=0\\}}e\\bigl [ l ( ( s_1,s_2),(s_1+ds_1,s_2+ds_2 ) ] ) |l_s=0\\bigr],\\end{aligned}\\ ] ] since @xmath53 can not have any jump points in @xmath191)$ ] if @xmath192 and @xmath193 is an atom of @xmath194 .",
    "define the ( deterministic ) increasing function @xmath195|l_s=0]$ ] , for @xmath196 , and when it exists , let @xmath197 in particular , if @xmath198 exists for every @xmath199 and is lebesgue measurable , then @xmath200    in what follows ( and as will be seen to be the case in our examples ) , we will assume that a representation of the form ( [ ( 12 ) ] ) exists for the compensator @xmath135 of @xmath53 , and we will refer to the deterministic function @xmath201 as the _ weak hazard function _ of @xmath53 .",
    "it will always be assumed that @xmath201 is continuous .    to better understand the weak hazard",
    ", we observe that if @xmath202 $ ] of @xmath53 is absolutely continuous with respect to lebesgue measure with radon  nikodym derivative @xmath203 , then for every @xmath204 with @xmath205 , @xmath206 . to see this , simply observe that for each @xmath116 , @xmath207=e[\\lambda_t]=\\int_{a_t } \\lambda_up(l_u=0)\\,du.\\ ] ]    returning to the gain function ( [ ( 6 ) ] ) , let @xmath36 denote the weak martingale @xmath208 and recall that @xmath209 . for any lower layer @xmath210 , @xmath211\\\\[-8pt ] & = & k_0+\\int_{b } \\bigl(-c_1+(c_0+c_1+k_1\\lambda_u)x_u \\bigr)\\,du+k_1m(b).\\nonumber\\end{aligned}\\ ] ] we note that @xmath118 is outer - continuous with inner limits by definition and that @xmath201 is assumed to be continuous , and so we now have an @xmath189-ssm representation of the gain function : @xmath143 , where @xmath212 .",
    "[ noinfo ] as a simple illustration , if the point process @xmath53 and the set @xmath213 are unobservable and no other information is available ( i.e. , @xmath6 is not observed and @xmath214 ) , then for @xmath92 ^ 2 $ ] , we are looking for a deterministic set @xmath215 that maximizes @xmath216&=&e \\biggl[k_0+\\int_{b } \\bigl(-c_1+(c_0+c_1+k_1\\lambda_u)x_u \\bigr)\\ , du+k_1m(b)\\biggr]\\nonumber\\\\[-8.5pt]\\\\[-8.5pt ] & = & k_0+\\int_{b } \\bigl(-c_1+(c_0+c_1+k_1\\lambda_u ) p(l_u=0)\\bigr)\\,du.\\nonumber\\end{aligned}\\ ] ] letting @xmath217 $ ] , it is easily seen that @xmath107 is deterministic and an optimal solution for the detection problem exists if @xmath107 is monotone , in which case @xmath218\\\\[-9pt ] & = & \\biggl\\{t\\in r{}\\dvtx{}p(l_u=0)>\\frac{c_1}{(c_0+c_1+k_1\\lambda_u ) } \\,\\forall u\\ll t \\biggr\\}.\\nonumber\\end{aligned}\\ ] ] the optimal estimate of @xmath100 is @xmath219    [ singlejump ] suppose @xmath220 , where @xmath221 is a @xmath109-valued random variable with distribution @xmath222 and continuous density @xmath223 .",
    "then we have @xmath224 . to verify that the representation ( [ ( 12 ) ] ) is satisfied with this definition , observe first that @xmath225|{\\mathcaligr}{f}_s^l]=\\frac{f(s , t]}{1-f_s}i_{\\{l_s=0\\}}.$ ] next , @xmath226}\\frac{f_u}{1-f_u}i_{\\{l_u=0\\}}\\,du\\big|{\\mathcaligr}{f}_s \\biggr ] & = & \\int_{(s , t]}\\frac{f_u}{1-f_u}p(l_u=0|{\\mathcaligr}{f}_s)\\,du\\\\[-1pt ] & = & \\int_{(s , t]}\\frac{f_u}{1-f_u}\\cdot\\frac{1-f_u}{1-f_s}i_{\\{l_s=0\\}}\\,du\\\\[-1pt ] & = & \\frac{f(s , t]}{1-f_s}i_{\\{l_s=0\\}}.\\end{aligned}\\ ] ] thus , the increasing process @xmath227 is a @xmath189-compensator for @xmath53 , verifying ( [ ( 12 ) ] ) .",
    "it should be noted that in the literature on bivariate survival analysis , the definition of the hazard function is @xmath228 where @xmath229 .",
    "for this reason , we refer to our hazard @xmath230 as the `` weak '' hazard .    returning to comment  [ noinfo ] , when no information is available , @xmath107 is decreasing and ( [ ( 16 ) ] ) defines an optimal deterministic solution if @xmath223 is decreasing in each parameter .",
    "[ poisson ] consider a homogeneous poisson process @xmath231 on @xmath109 with rate @xmath232 . if @xmath233 denotes the set of jump points of @xmath231 , then",
    "the _ first line _ of @xmath231 is the single line point process @xmath53 with ( incomparable ) jump points @xmath234 in this case , @xmath235 .",
    "as is shown in @xcite , the weak hazard of @xmath53 is @xmath232 .",
    "considering the situation in comment  [ noinfo ] when no information is available , we have @xmath236 , which is clearly monotone . in this case , the optimal solution given in ( [ ( 16 ) ] ) becomes @xmath237 and @xmath238    we are now ready to return to the sequential detection problem , and consider the case in which the process @xmath6 is observed ( recall that @xmath6  is a poisson process with rate @xmath7 on @xmath51 and @xmath8 on @xmath5 ) .",
    "we denote the full filtration @xmath239 , where @xmath240 , and ( as before ) the subfiltrations @xmath241 and @xmath242 where @xmath243 and @xmath244 .",
    "although we defined the weak hazard of @xmath53 with respect to @xmath189 , it is easy to see that given the full filtration @xmath245 , @xmath208 is still a weak @xmath245-martingale .",
    "this follows because on @xmath246 , @xmath6 is a poisson process with rate @xmath7 on @xmath247 and so @xmath248 ( @xmath6 restricted to @xmath247 ) adds no additional information about the behavior of @xmath187 for @xmath249 . formally , we have @xmath250|{\\mathcaligr}{f}^{l , n}_s]=i_{\\{l_s=0\\}}\\lambda ^{(s)}_t = e[l(s , t]|{\\mathcaligr}{f}^{l}_s ] . \\ ] ] therefore , from this discussion we have the following lemma and we are ready to proceed with finding an optimal solution to the sequential detection problem .",
    "[ fullssm ] equation ( [ ( 14 ) ] ) defines an @xmath245-ssm representation of the gain function @xmath251 where @xmath212 .",
    "we consider the @xmath245-ssm representation of the gain function ( [ ( 14 ) ] ) : @xmath252 in order to find sufficient conditions for the existence of an optimal solution in the sequential case , we will be appealing to lemma [ projection ] , with @xmath253 , @xmath254 and @xmath255 . in order to find @xmath256 $ ] , it is enough to determine @xmath257=p(l_t=0|{\\mathcaligr}{f}_t^n ) . \\ ] ] as in @xcite , we use a bayesian argument .",
    "the first step is to determine the conditional likelihood @xmath258 of @xmath259 given @xmath53 and use this to find the likelihood @xmath260 of @xmath259 .",
    "next we find the conditional likelihood @xmath261 of @xmath259 on the set @xmath262 . finally , we have @xmath263&=&p(l_t=0|{\\mathcaligr}{f}_t^n)\\nonumber\\\\[-8pt]\\\\[-8pt ] & = & \\frac{\\ell_{n|l_t=0}(t)\\times p(l_t=0)}{\\ell_n(t)}.\\nonumber\\end{aligned}\\ ] ]    when computing the likelihood @xmath264 , in fact it is equivalent to condition on the random upper layer @xmath265 . to see this ,",
    "let @xmath266 denote the collection of closed upper layers in @xmath109 endowed with the hausdorff metric .",
    "it is shown in @xcite that @xmath267 is a complete separable metric space and that @xmath5 can be regarded as the unique jump point in a single jump process @xmath268 on @xmath269 ; in addition , @xmath53 determines and is determined by @xmath268 .",
    "in particular , @xmath270 , where @xmath271 .",
    "let @xmath272 denote the measure induced by @xmath5 on @xmath269 .",
    "given @xmath53 , or equivalently @xmath5 , @xmath6 is a poisson process with rate @xmath7 on @xmath51 and @xmath8 on @xmath5 . using the well - known likelihood for the poisson process ( cf .",
    "@xcite , page  22 ) , we have @xmath273 by considering separately the events @xmath274 and @xmath275 , we use ( [ ( 18 ) ] ) obtain @xmath276,\\nonumber\\end{aligned}\\ ] ] where @xmath277    before continuing , we observe that since @xmath278 , @xmath279 is increasing in each parameter separately because each term in the integrand is increasing in each component for @xmath280 fixed , and the range of integration is increasing since the set @xmath281 decreases with each component .    next , if @xmath282 , then @xmath259 is poisson with rate @xmath7 , and so @xmath283 substituting ( [ ( 19 ) ] ) and ( [ ( 20 ) ] ) in ( [ ( 17 ) ] ) , we obtain @xmath284&=&\\frac{e^{-\\mu_0|a_t|}\\mu_0^{n_t}p(l_t=0 ) } { e^{-\\mu_0|a_t|}\\mu_0^{n_t } [ p(l_t=0)+e^{-(\\mu_1-\\mu_0)|a_t| } q_t ] } \\nonumber\\\\[-8pt]\\\\[-8pt ] & = & \\frac{1}{1+q_tq_t},\\nonumber\\end{aligned}\\ ] ] where @xmath285 . [ if @xmath286 , ( [ ( 21 ) ] ) remains formally valid since @xmath287=0 $ ] and @xmath288 .",
    "] we are now ready to state our main result :    [ main ] let @xmath53 be a single line process with continuous weak hazard  @xmath201 , and define the function @xmath289 by @xmath290 an optimal solution to the sequential detection problem on @xmath92 ^ 2 $ ] exists if @xmath201 and @xmath289 are decreasing and increasing , respectively , in each component on @xmath96 . in this case",
    "@xmath107 is monotone on @xmath96 , and the optimal solution is given by ( [ ( 11 ) ] ) : @xmath291 where @xmath292    we review our results so far .",
    "we have the @xmath245-ssm representation of the gain function @xmath293 , where @xmath294 .",
    "@xmath37 is bounded since @xmath201 is decreasing in each component and @xmath118 is an indicator function . by the argument immediately preceding the theorem",
    ", we have that @xmath295=-c_1+(c_0+c_1+k_1\\lambda_t)\\frac{1}{1+q_tq_t}.\\ ] ] to see that @xmath107 has a version which is outer - continuous with inner limits ( o.c.i.l . ) , recall that @xmath201 is assumed to be continuous and observe that @xmath289 is o.c.i.l . by definition .",
    "turning next to @xmath279 , we see that the integrand in ( [ ( 19a ) ] ) is o.c.i.l . and",
    "increasing in each component in @xmath22 , as is @xmath296 therefore , it follows that @xmath279 , and hence @xmath107 are o.c.i.l .",
    "therefore , lemmas  [ stopping ] and  [ projection ] imply that for any @xmath94-stopping set @xmath181 , @xmath297 = k_0+e \\biggl[\\int_\\rho u_t\\,dt \\biggr ] = k_0+e \\biggl[\\int_\\rho v_t\\,dt \\biggr].\\end{aligned}\\ ] ] to show that an optimal solution @xmath83 exists [ as in ( [ ( 11 ) ] ) ] , it is sufficient to show that @xmath107 is monotone ( again , by lemma  [ projection ] ) . since we have already seen that @xmath279 is increasing in each component on @xmath96 , the assumption that @xmath201 and @xmath289 are decreasing and increasing , respectively , in each component imply that @xmath107 is monotone on @xmath96 .",
    "this completes the proof .",
    "it has been pointed out by an anonymous referee that the case @xmath52 relates to a so - called support estimation problem . in this case",
    ", the random set @xmath5 denotes the support of a poisson process with rate @xmath8 .",
    "the gain function can be defined exactly as before , and the analysis proceeds in very much the same way .",
    "now we know that @xmath298 , and equation  ( [ ( 17 ) ] ) becomes @xmath299 & = & p(l_t=0|{\\mathcaligr}{f}_t^n)\\nonumber\\\\ & = & p(l_t=0|n_t=0)i(n_t=0)\\\\ & = & \\frac{p(l_t=0)}{p(n_t=0)}i(n_t=0).\\nonumber\\end{aligned}\\ ] ] continuing with the same sort of arguments used previously , if @xmath300 , equation  ( [ ( 21 ) ] ) becomes @xmath301 & = & \\frac{1}{1+{q_t}\\dot{q}_t}i(n_t=0),\\label{(21a)}\\end{aligned}\\ ] ] where @xmath302 is defined as before with @xmath52 , and @xmath303 it is easy now to see that the statement of theorem  [ main ] is still valid in this case , with @xmath107 replaced by @xmath304 , where @xmath305",
    "in this section , we apply theorem  [ main ] to our two examples .",
    "we will see that in some sense they are are both analogous to the univariate model of @xcite , in which the change - point is exponentially distributed .",
    "there are two natural generalizations in @xmath42 : first , @xmath53 is the single jump process in which the components of the jump are independent univariate exponential random variables , and second , @xmath53 is the first line of a poisson process , noting that an exponential random variable can be regarded as the `` first line '' of a poisson process on @xmath16 .",
    "although at first glance the single jump process looks more straightforward , we shall see that in fact the analysis is far more complex than in the case of the first line of a poisson process .",
    "[ singlejump2 ] referring to example  [ singlejump ] , we have @xmath306 and @xmath307 . here",
    "we will consider the case in which the components @xmath308 of the jump @xmath221 are independent identically distributed exponential random variables with parameter @xmath232 . in this case",
    ", @xmath309 and is decreasing in each component .",
    "next , we consider @xmath302 : @xmath310 to find sufficient conditions to ensure that @xmath289 is increasing in @xmath311 and @xmath312 on some set @xmath92 ^ 2 $ ] , we will assume that @xmath313 and to simplify the discussion ( without loss of generality , by suitably rescaling the time parameters if necessary ) that @xmath314 .",
    "now rewrite @xmath315 where @xmath316 we will show that if @xmath317 , then @xmath318 for @xmath319 ^ 2 $ ] . by symmetry ,",
    "the same is true for @xmath320 for @xmath321 .",
    "therefore , @xmath322 is decreasing and @xmath323 is increasing in each component on @xmath96 , and an optimal solution exists for the sequential detection model .    to complete the example , we observe that @xmath324 if and only if @xmath325 or equivalently , @xmath326 the left - hand side of ( [ ( 25 ) ] ) is bounded above by @xmath232 since @xmath327 .",
    "the right - hand side of ( [ ( 25 ) ] ) is bounded below by @xmath232 since @xmath328 when @xmath329 , and so @xmath330 .",
    "therefore , it is sufficient that @xmath331 .",
    "[ poisson2 ] from the discussion in example  [ poisson ] , if @xmath53 is the first line of a poisson process with rate @xmath232 , then @xmath332 , and so trivially is decreasing in each component .",
    "we have @xmath333 , which is increasing in each component if @xmath334 .",
    "therefore , an optimal solution to the sequential detection problem exists on any bounded set @xmath92 ^ 2 $ ] if @xmath334 , and is defined by ( [ ( 11 ) ] ) .",
    "in fact , this is exactly the same as the sufficient condition for the univariate detection problem proven in @xcite and  @xcite .",
    "as indicated in the introduction , the sequential detection model considered here is only one of many scenarios that should be analyzed in the general context of the `` optimal set - detection problem . ''",
    "indeed , the model can be extended in many possible ways .    *",
    "the information structure : in addition to the sequential information model , herberts and jensen @xcite consider what they call the `` ex - post '' analysis .",
    "this would correspond to observing @xmath6 on all of @xmath96 , and then trying to optimize the expectation of the valuation function .",
    "( formally , this corresponds to @xmath335 . ) several variants or combinations of the ex - post and sequential schemes can be studied . * the underlying space : we worked here on a bounded subset of @xmath336 .",
    "it would be of interest to consider change - point problems on higher - dimensional euclidean spaces or more general partially ordered sets as in @xcite . * the change mechanism : here the change occurs at either a single random point or at the first line of a more general point process .",
    "the example involving the first line of a poisson process turned out to be ( perhaps surprisingly ) the more natural analog of the one - dimensional exponential change - point problem .",
    "consideration should be given to more general single jump and first line processes , as well as to more general random sets ( not necessarily upper layers ) .",
    "for example , the case in which @xmath53 is the first line of an inhomogeneous poisson process with intensity @xmath337 is considered in @xcite where it is proven that an optimal solution exists if @xmath338 .",
    "* the observed process : on @xmath16 , the process subject to the change can be a more general process , such as the brownian motion process ( cf .",
    "@xcite ) . here",
    "too , we can consider more general processes such as the set - indexed brownian motion ( cf .",
    "@xcite ) . * the parameters : in our analysis , it is implicitly assumed that the parameters of the various processes are all known . how does one approach the problem when",
    "one or more parameters must be estimated ? * the gain function : different valuation functions can be chosen , thereby changing the notion of optimality .",
    "for example , with a change generated by a single jump at @xmath221 , instead of two cost parameters @xmath27 and @xmath28 associated respectively with @xmath339 and @xmath340 , we could have different costs in each of the four quadrants defined by @xmath221 .",
    "another variation considered in @xcite is to replace @xmath187 in ( [ ( 5 ) ] ) with @xmath341 .",
    "although this does not change the valuation when the change is generated by a single jump , the analysis becomes more complex when @xmath53 is the first line of a poisson process .",
    "* number of changes : here we deal with only one change - set .",
    "however , we can imagine that several changes occur on a decreasing sequence of random upper layers , for example .",
    "this would correspond to multiple change points on  @xmath16.=1",
    "the second author thanks g. ivanoff for her optimal hospitality while visiting the university of ottawa ."
  ],
  "abstract_text": [
    "<S> we generalize the classic change - point problem to a `` change - set '' framework : a spatial poisson process changes its intensity on an unobservable random set . </S>",
    "<S> optimal detection of the set is defined by maximizing the expected value of a gain function . in the case that the unknown change - set is defined by a locally finite set of incomparable points , we present a sufficient condition for optimal detection of the set using multiparameter martingale techniques . </S>",
    "<S> two examples are discussed .    .    . </S>"
  ]
}