{
  "article_text": [
    "factor models have met a large success in data analysis in many scientific fields such as psychology , economics and finance , signal processing , to name a few .",
    "one of the strengths of these models relies on its capability to reduce the generally high dimension of the data to a much lower - dimensional common component .",
    "the structure of these models is complex and many different versions of the models have been introduced so far in the long - standing literature on the subject , ranging from _",
    "static _ to _ dynamic _ or _ generalized dynamic _ factor models on one hand , and from _ exact _ to _ approximate _ factor models on the other hand . a recent survey of this literature",
    "can be found in @xcite .",
    "efforts are however still paid to the study of these models because unfortunately their inference is not easy , especially when the cross - sectional dimension @xmath0 and the temporal dimension @xmath1 are both large .    in such high - dimensional context ,",
    "the determination of the number @xmath2 of common factors in in a factor model is a challenging problem .",
    "misspecification of this number can deeply affect the quality of the fitted factor model . in this context , the seminal paper @xcite provided for the first time a consistent estimator of @xmath2 for static factor models .",
    "this estimator has attracted much attention afterwards , and has been improved or generalized , e.g. in @xcite by the authors themselves , in @xcite for dynamic factor models and in @xcite for approximate factor models .",
    "it should be here mentioned that as these developments mainly target at analysis of economic or financial data , the common factors in these models are thought to be _ pervasive _ , or _",
    "strong _ , in the sense that their strength is much higher than the strength of the idiosyncratic ( error ) component .",
    "the asymptotic consistency of the factor number estimator depends in a large extent on this assumption .",
    "however , some recent studies on factor models suggest the importance for accommodating more factors in these models by including some _ weaker factors _ which still have a significant explanation power on both cross - sectional and temporal correlations of the data . for example",
    ", @xcite makes a clear distinction between strong factors and weak factors when considering asymptotic approximations of the square loss function from a principal components - based perspective .",
    "a related work allowing weak factors can be found in @xcite .    in this paper",
    "we consider a factor model for high - dimensional time series proposed by @xcite : the observations @xmath3 is a @xmath4 matrix with @xmath0 cross - sectional units over @xmath1 time periods .",
    "let @xmath5 denote the @xmath0-dimensional vector observed at time @xmath6 , then it consists of two components , a low dimensional common - factor time series @xmath7 and an idiosyncratic component @xmath8 : @xmath9 where @xmath10 is the factor loading matrix of size @xmath11 and @xmath12 is a white noise sequence ( temporal uncorrelated ) .",
    "the factors in @xmath13 are here loaded contemporaneously ; however this is a time series and its temporal correlation implies that of the observations @xmath14 .",
    "however , this is the unique source of temporal correlation , and in this aspect , the model is much more restrictive than the general dynamic models as introduced in @xcite , @xcite and @xcite . nevertheless , there are two advantages in this simplified model .",
    "first , since potentially @xmath13 can be any kind of stationary time series of low dimension , the model can already cover a wide range of applications .",
    "second , inference procedures are here more consistently defined and more precise results can be expected , e.g. for the determination of the number of factors . the factor model can be considered as a good balance between the generality of model coverage and the technical feasibility of underlying inference procedures .    the goal of this paper is to develop a powerful estimator of the number of factors in the model .",
    "@xcite proposed a ratio - based estimator defined as follows .",
    "let @xmath15 and @xmath16 be the lag-1 auto - covariance matrices of @xmath5 and @xmath7 , respectively .",
    "assuming that the factor and the noise are independent , we then have @xmath17 which leads to its symmetric counterpart @xmath18 since in general the @xmath19 matrix @xmath20 is of full rank @xmath2 , the symmetric @xmath21 matrix @xmath22 has exactly @xmath2 nonzero eigenvalues .",
    "moreover , the factor loading space @xmath23 , i.e. the @xmath2-dimensional subspace in @xmath24 generated by the columns of @xmath10 , is spanned by the eigenvectors of @xmath22 corresponding to its nonzero eigenvalues @xmath25 ( factor eigenvalues ) .",
    "let @xmath26 be the sample counterparts of @xmath22 and @xmath27 , respectively .",
    "the main observation is that the @xmath28 null eigenvalues of @xmath22 will lead to @xmath28 `` relatively small '' sample eigenvalues in @xmath29 , while the @xmath2 factor eigenvalues @xmath30 will generate @xmath2 `` relatively large '' eigenvalues in @xmath29 .",
    "this can be made very precisely in a classical _ low - dimensional _ framework where we fix the dimension @xmath0 and let @xmath1 grow to infinity : indeed by law of large numbers , @xmath31 and by continuity , all the eigenvalues @xmath32 ( sorted in decreasing order ) of @xmath29 will converge to the corresponding eigenvalues of @xmath22 .",
    "in particular , for @xmath33 , @xmath34 while @xmath35 for @xmath36 .",
    "consider the ratio estimator ( @xcite ) : @xmath37 as @xmath38 will be the first ratio in this list which tends to zero , @xmath39 will be a consistent estimator of @xmath2 .    in the high - dimensional context however",
    ", @xmath29 will significantly deviate from @xmath22 and the spectrum @xmath40 of @xmath29 will not be close to that of @xmath22 anymore . in particular , the time for the first minimum of the ratios in becomes noisy and can be much different from the target value @xmath2 .",
    "notice that the @xmath2 non - null factor eigenvalues @xmath30 are directly linked to the strength of the factor time series @xmath13 .",
    "the precise relationship between the ratios of sample eigenvalues in will ultimately depend on a complex interplay between the strength of the factor eigenvalues @xmath30 ( compared to the noise level ) , the dimension @xmath0 and the sample size @xmath1 .    despite of the introduction of a very appealing ratio estimator , precise description of the sample ratios @xmath41 is missing in @xcite . indeed , the authors establish the consistency of the ratio estimator @xmath39 by requiring that the factor strengths @xmath30 all explode _ at a same rate _ : @xmath42 for all @xmath43 and some @xmath44 as the dimension @xmath0 grows to infinity .",
    "in other words , the factors are all strong and they have a same asymptotic strength .",
    "this limitation is quite severe because factors with different levels of strength can not be all detected within this framework .",
    "for instance , if we have factors with say three levels of strength @xmath45 ,",
    "@xmath46 where @xmath47 , the ratio estimator @xmath39 above will correctly identify the group of strongest factors @xmath48 while all the others will be omitted . in an attempt to correct such undesirable behavior ,",
    "a two - step estimation procedure is also proposed in @xcite which will identify successively two groups of factors with top two strengths : this means that in the example above , factors of strength @xmath49 proportional to @xmath45 with @xmath50 will be identified while the others will remain omitted .",
    "the issue here is that _ a priori _ , we do not know how many different levels of strength the factors could have and it is unlikely we could attempt to estimate such different levels as this would lead to a problem that is equally ( if not more ) difficult than the initial problem of estimating the number of factors .    inspired by the appropriateness of the ratio estimator @xmath39    in the high - dimensional context , the main objective of this paper is to provide a rigorous theory for the estimation of the number of factors based on the ratios @xmath51 under the high - dimensional setting where @xmath52 and @xmath1 tend to infinity proportionally .",
    "the paper contains two main contributions .",
    "first , _ we characterize completely the limits of both the factor eigenvalues @xmath53 and the noise eigenvalues @xmath54 . _ for the noise part , as @xmath2 ( although unknown ) is much smaller than the dimension @xmath0 , we prove that the spectral distribution generated by @xmath54 has a limit which coincide with the limit of the spectral distribution generated by the @xmath0 eigenvalues of the ( unobserved ) matrix @xmath55 where @xmath56 .",
    "this limiting distribution has been explored elsewhere in @xcite and its support found to be a compact interval @xmath57 $ ] . as for the factor part @xmath53 , although it is highly expected that they should have a limit located outside the base interval @xmath57 $ ] , we establish a _ phase transition phenomenon _ : a factor eigenvalue @xmath58 will tend to a limit @xmath59 ( outlier ) _ if and only if _ the corresponding population factor strength @xmath49 exceeds some critical value @xmath60 .",
    "in other words , if a factor @xmath49 is too weak , then the corresponding sample factor eigenvalue @xmath61 will tend to @xmath62 , the ( limit of ) maximum of the noise eigenvalues and it will be hardly detectable . moreover ,",
    "both the outlier limits @xmath63 and the critical value @xmath60 are characterized through the model parameters .",
    "the second main contribution of the paper is _ the derivation of a new estimator @xmath64 of the number of factors _ based on the finding above . if @xmath65 denotes the number of _ significant factors _",
    ", i.e. with factor strength @xmath66 , then using an appropriate thresholding interval @xmath67 for the sample ratios @xmath51 , the derived estimator @xmath64 is strongly consistent converging to @xmath65 .",
    "in addition to this well - justified consistency , the main advantage of the proposed estimator is its robustness against possibly multiple levels of factor strength ; in theory , all factors with strength above the constant @xmath60 are detectable .",
    "therefore , both strong factors and weak factors can be present , and their strengths can have different asymptotic rates with regard to the dimension @xmath0 in order to be detected from the observed samples .",
    "this is a key difference between the method provided in this paper and most of existing estimators of the factor number as recalled previously ( the reader is however reminded that the model is more restrictive than a general dynamic factor model ) .",
    "notice however that these precise results have been obtained at the cost of some drastic simplification of the idiosyncratic component @xmath68 , namely independence has been assumed both serially and cross - sectionally ( over the time and the dimension ) , and the components are normalized to have a same value of variance ( see assumption 2 in section  [ modass ] ) .",
    "these limitations are required by the technical tools employed in this paper and some non - trivial extension of these tools are needed to get rid of these limitations .    from a methodological point of view , our approach is based on recent advances from random matrix theory , specifically on the so - called spiked population models or more generally on finite - rank perturbations of large random matrices .",
    "we start by identifying the sample matrix @xmath29 as a finite - rank perturbation of the base matrix @xmath69 associated to the noise . in a recent paper @xcite",
    ", the limiting spectral distribution of the eigenvalues of @xmath69 has been found and the base interval @xmath57 $ ] characterized . by developing the mentioned perturbation theory for the autocovariance matrix @xmath70 , we find the characterization of the limits of its eigenvalues @xmath71 .    for the strong consistency of the proposed ratio estimator @xmath64 ,",
    "a main ingredient is the almost sure convergence of the largest eigenvalue of the base matrix @xmath69 to the right edge @xmath62 , recently established in @xcite .",
    "this result serves as the cornerstone for distinguishing between significant factors and noise components .",
    "it is worth mentioning a related paper @xcite where the author stands from a similar perspective with the method in this paper .",
    "however , that paper addresses static approximate factor models without time series dependence and more importantly , the assumption of explosion of all factor eigenvalues is still required which , on the contrary , is released in this paper .",
    "other related references include @xcite and @xcite where the limiting spectral distribution and the strong convergence of extreme eigenvalues are derived for the matrix @xmath72 .",
    "one should mention that these works are more related to the study in @xcite and @xcite on spectral limits of the matrix @xmath73 , and they have no results either on convergence of the spiked ( factor ) eigenvalues or on the estimation of the number of factors as proposed in this paper .",
    "the rest of the paper is organized as follows . in section  [ modass ] , after introduction of the model assumptions we develop our first main result regarding spectral limits of @xmath70 .",
    "the new estimator @xmath64 is then introduced in section  [ estimation ] and its strong convergence to the number of significant factors @xmath65 established . in section [ simulation ] ,",
    "detailed monte - carlo experiments are conducted to check the finite - sample properties of the proposed estimator and to compare it with the ratio estimator @xmath39 from @xcite . both estimators",
    "@xmath39 and @xmath64 are next tested in section [ application ] on a real data set from standard & poor stock returns and compared in details .",
    "notice that some technical lemmas used in the main proofs are gathered in a companion paper of supplementary material @xcite .",
    "the static factor model is further specified to satisfy the following assumptions .",
    "* assumption 1.*the factor @xmath13 is a @xmath2-dimensional ( @xmath74 fixed ) stationary time series , each dimension is independent of each other , with the representation of each component : @xmath75 where @xmath76 is a real - valued and weakly stationary white noise with mean 0 and variance @xmath77 .",
    "the series @xmath78 has variance @xmath79 and lag-1 auto - covariance @xmath80 .",
    "moreover , the variance @xmath79 will be hereafter referred as the _ strength _ of the @xmath81-th factor time series @xmath78 .",
    "* assumption 2.*the idiosyncratic component @xmath82 is independent of @xmath7 .",
    "@xmath8 is @xmath83dimensional real valued random vector with independent entries @xmath84 , not necessarily identically distributed , satisfying @xmath85 and for any @xmath86 , @xmath87    * assumption 3.*the dimension @xmath0 and the sample size @xmath1 tend to infinity proportionally : @xmath88 , @xmath89 and @xmath90 .    assumption 1 defines the static factor model considered in this paper .",
    "assumption 2 details the moment condition and the independent structure of the noise .",
    "in particular , is a lindeberg - type condition widely used in random matrix theory . in particular , if the fourth moments of the variables @xmath91 are uniformly bounded , the lindeberg condition is satisfied .",
    "assumption 3 defines the high - dimensional setting where the dimension and the sample size can be both large without however one dominating the other .",
    "first we have , @xmath92 the matrix @xmath93 is the analogous sample autocovariance matrix associated to the noise @xmath94 . since @xmath10 has rank @xmath2 , the rank of the matrix @xmath95 is bounded by @xmath96 ( we will see in fact that asymptotically , the rank of @xmath95 will be eventually @xmath2 ) . therefore , the autocovariance matrix of interest @xmath97 is seen as a finite - rank perturbation of the noise autocovariance matrix @xmath98 . since the matrix @xmath99 is not symmetric , we consider its singular values , which are also the square root of the eigenvalues of @xmath100 .",
    "therefore , the study of the singular values of @xmath99 reduces to the study of the eigenvalues of @xmath101 , which is also a finite rank perturbation of the base component @xmath102 .",
    "finite - rank perturbations of random matrices have been actively studied in recent years and the theory is much linked to the _ spiked population models _ well known in high - dimensional statistics literature .",
    "for some recent accounts on this theory , we refer to @xcite , @xcite , @xcite , @xcite , @xcite and the references therein .",
    "a general picture from this theory is that first , the eigenvalues of the base matrix will converge to a limiting spectral distribution ( lsd ) with a compact support , say an interval @xmath57 $ ] ; and secondly , for the eigenvalues of the perturbed matrices , most of them ( base eigenvalues ) will converge to the same lsd independently of the perturbation while a small number among the largest ones will converge to a limit outside the support of the lsd ( outliers ) .",
    "however , all the existing literature cited above concern the finite rank perturbation of large - dimensional sample covariance matrices or wigner matrices . as a theoretic contribution of the paper , we extend this theory to the case of a perturbed auto - covariance matrix by giving exact conditions under which the aforementioned dichotomy between base eigenvalues and outliers still hold . specifically , it will be proved in this section that once the @xmath2 factor strengths @xmath30 are not `` too weak '' , they will generate exactly @xmath2 outliers , while the remaining @xmath28 eigenvalues will behave as the eigenvalues of the base @xmath103 , which converges to a compactly supported lsd .",
    "it is then apparent that under such dichotomy and by `` counting '' the outliers outside the interval @xmath57 $ ] , we will be able to obtain a consistent estimator of the number of factors @xmath2 .    in what follows ,",
    "we first recall two existing result on the asymptotic of the singular values of @xmath104 .",
    "then we develop our theory on the limits of largest ( outliers ) and base singular values of @xmath99 .",
    "we first recall two useful results on the base matrix @xmath105 .",
    "firstly , the limiting spectral distribution of the eigenvalues of @xmath105 has been obtained in a recent paper @xcite .",
    "write @xmath106 with the data matrices @xmath107    furthermore , let @xmath108 be a measure on the real line supported on an interval @xmath109 $ ] ( the end points can be infinity ) , with its stieltjes transform defined as @xmath110 and its @xmath1-transform as @xmath111 notice here that the t - transform is a decreasing homeomorphism from @xmath112 onto @xmath113 and from @xmath114 onto @xmath115 , which related to each other by the following equation : @xmath116    [ lsd][@xcite ]    suppose that assumptions 2 and 3 hold with @xmath117 .",
    "then , the empirical spectral distribution of @xmath118 ( which is the companion matrix of @xmath69 ) converges a.s . to a non - random limit f ,",
    "whose stieltjes transform @xmath119 satisfies the equation @xmath120 in particular , this lsd is supported on the interval @xmath121 $ ] whose end points are @xmath122    notice that the companion matrix @xmath123 is @xmath124 and it shares the same @xmath125 non - null eigenvalues as @xmath69 , therefore , the support of @xmath103 is also @xmath57 $ ] the lsd @xmath126 of @xmath123 and the lsd @xmath127 of @xmath128 are linked by the relationship @xmath129 where @xmath130 is the dirac mass at the origin .",
    "the equation can be expressed using the @xmath1-transform : @xmath131    the second result is about the convergence of the largest eigenvalue of @xmath69 .",
    "[ lmax][@xcite ]    suppose that assumptions 2 and 3 hold with @xmath117 .",
    "then , the largest eigenvalue of @xmath103 converges a.s . to the right end point @xmath62 of its lsd given in .",
    "combining propositions  [ lsd ] and [ lmax ] , we have the following corollary .    [ coro ] under the same conditions as in proposition  [ lmax ] ,",
    "if @xmath132 are sorted eigenvalues of @xmath69 , then for any fixed @xmath133 , the @xmath133 largest eigenvalues @xmath134 all converge to @xmath62 .    for any @xmath44 ,",
    "almost surely the number of sample eigenvalues of @xmath135 falling into the interval @xmath136 grows to infinity due to the fact the density of the lsd is positive and continuous on this interval .",
    "then for fixed @xmath133 , a.s .",
    "@xmath137 . by letting @xmath138 ,",
    "we have a.s .",
    "obviously , @xmath140 , i.e a.s . @xmath141 .      the following main result of the section characterizes the limits of the @xmath2-largest eigenvalues of the sample autocovariance matrix @xmath101 .    [ mainth ]",
    "suppose that the model satisfies assumptions 1 , 2 and 3 and that the noise @xmath12 are normal distributed and the loading matrix @xmath10 is normalized as @xmath142 .",
    "let @xmath143 denote the @xmath2 largest eigenvalue of @xmath101 .",
    "then for each @xmath43 , @xmath144 converges almost surely to a limit @xmath61 .",
    "moreover , @xmath145 where @xmath146 otherwise , i.e. @xmath147 , @xmath148 and its value is characterized by the fact that the @xmath1-transform @xmath149 is the solution to the equation : @xmath150    the theorem establishes a _ phase transition phenomenon _ for the @xmath2 sample factor eigenvalues @xmath40 .",
    "define the _ number of significant factors _",
    "@xmath151 therefore , for each of the @xmath65 significant factor , the corresponding sample eigenvalue @xmath58 will converge to a limit @xmath61 outside the base support interval @xmath57 $ ] . in contrary , for the @xmath152 factors for which @xmath153 , they are too weak in the sense that the corresponding sample eigenvalue @xmath58 will converge to @xmath62 which is also the limit of the largest noise eigenvalues @xmath154",
    "( @xmath133 is a fixed number here ) .",
    "therefore , these weakest factors will be merged with noise component and their detection becomes hardly possible .    later in section  [ condition ]",
    ", it will be established that for the @xmath81-th factor time series be significant , the phase transition condition @xmath147 essentially requires the strength @xmath79 be large enough .",
    "( of theorem  [ mainth ] ) the proof consists in four steps where some technical lemmas are to be found in the companion paper of supplementary material @xcite .",
    "simplification of variance @xmath155 of white noise @xmath156.to ease the complexity of the proof of this main theorem , we firstly reduce the variance of the white noise from @xmath155 to 1 . in our model setting , we have equivalent to @xmath157 and if we denote @xmath158 , @xmath159 and @xmath160 , then we are dealing with the model @xmath161 where the white noise @xmath162 has mean zero and unit variance and the variance and autocovariance of the factor process @xmath163 satisfies @xmath164 in which @xmath79 and @xmath80 are the variance and autocovariance of the original factor process @xmath165 . therefore ,",
    "in all the following , we just consider the standardized model .",
    "for convenience , we use notations of the original model and set @xmath117 to investigate model . at the end of the proof",
    ", we will replace the value of @xmath79 and @xmath80 with @xmath166 and @xmath167 to recover the corresponding results for model .",
    "simplification of matrix @xmath10 .",
    "here we argue that it is enough to consider the case where the loading matrix @xmath10 has the canonical form @xmath168     indeed , suppose @xmath10 is not in this canonical form .",
    "since by assumption @xmath142 , we can complete @xmath10 to an orthogonal matrix @xmath169 by adding appropriate orthonormal columns . from the model equation , we have @xmath170 since @xmath171 and @xmath172 is orthogonal , @xmath173 .",
    "let @xmath174 , then @xmath175 satisfies the model equation with a canonical loading matrix .",
    "what happens is that the singular values of the two lag-1 autocovariance matrices @xmath176 are the same : this is simply due to fact that @xmath177    step 3 .",
    "derivation of the main equation from now on we assume that @xmath10 is in its canonical form . by the definition of @xmath5 , we have @xmath178 where we use @xmath10 , @xmath123 , @xmath179 and @xmath180 to denote the four blocks . besides , if we use the notation : @xmath181 then we have @xmath182    since @xmath183 is the extreme large eigenvalue of @xmath184 , @xmath185 is the extreme large singular value of @xmath99 , which is also equivalent to saying that @xmath185 is the positive eigenvalue of the @xmath186 matrix @xmath187 and use the block expression , combining with the definition of each block in , is equivalent to @xmath188 if we interchange the second and third row block and column block in , its eigenvalues remain the same .",
    "therefore , @xmath185 should satisfy the following equation @xmath189 then for block matrix , we have the identity @xmath190 when @xmath180 is invertible , then is equivalent to    @xmath191    which is due to the fact that @xmath185 is the extreme singular value , then @xmath192and therefore is invertible .",
    "then if we do the calculation of @xmath193 is equivalent to @xmath194 and using the simple fact that @xmath195 leads to @xmath196 taking lemmas 1.3 and 1.4 given in @xcite into consideration , the matrix in tends to a block matrix : @xmath197        \\hdashline        \\\\",
    "\\begin{matrix }          -(1+t(\\lambda))\\gamma_1(1 ) & \\cdots & 0   \\\\",
    "\\vdots & \\ddots & \\vdots\\\\          0 & \\cdots   & -(1+t(\\lambda))\\gamma_1(k )        \\end{matrix }   &   \\begin{matrix }          \\frac{\\sqrt{\\lambda } ( y-\\gamma_0(1)t(\\lambda))}{y+t(\\lambda ) } & \\cdots & 0   \\\\",
    "\\vdots & \\ddots & \\vdots\\\\          0 & \\cdots   & \\frac{\\sqrt{\\lambda } ( y-\\gamma_0(k)t(\\lambda))}{y+t(\\lambda ) }        \\end{matrix }      \\end{array }    \\right)~,\\ ] ] so @xmath198 should make the determinant of this matrix equal to @xmath199 .",
    "if we interchange the first and second column block , the matrix becomes the following : @xmath200        \\hdashline        \\\\",
    "\\begin{matrix }          \\frac{\\sqrt{\\lambda } ( y-\\gamma_0(1)t(\\lambda))}{y+t(\\lambda ) } & \\cdots & 0   \\\\",
    "\\vdots & \\ddots & \\vdots\\\\          0 & \\cdots   & \\frac{\\sqrt{\\lambda } ( y-\\gamma_0(k)t(\\lambda))}{y+t(\\lambda ) }        \\end{matrix } & \\begin{matrix }          -(1+t(\\lambda))\\gamma_1(1 ) & \\cdots & 0   \\\\",
    "\\vdots & \\ddots & \\vdots\\\\          0 & \\cdots   & -(1+t(\\lambda))\\gamma_1(k )        \\end{matrix }      \\end{array }    \\right)~.\\ ] ] since the diagonal block @xmath201 we can use the identity @xmath202 again , and this leads to the result : @xmath203~.\\ ] ] combining this equation with and replacing @xmath204 with @xmath205 leads to the equation  .",
    "derivation of the condition @xmath206 .",
    "we now look at the solution of the main equation  .",
    "the equation reduces to @xmath207\\cdot t^2(\\lambda_i)-\\left[\\gamma_1(i)^2 + 2y\\sigma^2\\gamma_0(i)\\right]\\cdot t(\\lambda_i)+\\sigma^4y^2=0~.    \\end{aligned}\\ ] ] since the part @xmath208 and @xmath209 , equation has two positive roots @xmath210          t_2(i)=\\frac{2y\\sigma^2\\gamma_0(i)+\\gamma_1(i)^2+\\sqrt{(2y\\sigma^2\\gamma_0(i)+\\gamma_1(i)^2)^2 - 4y^2\\sigma^4(\\gamma_0 ( i)^2-\\gamma_1(i)^2)}}{2\\gamma_0(i)^2 - 2\\gamma_1(i)^2}~.        \\end{array }      \\right.\\ ] ] recall the definition of the @xmath1-transform that : @xmath211 taking derivatives with respective to @xmath212 on both side leads to @xmath213 so , between the two solutions @xmath214 and @xmath215 , only @xmath214 satisfies this condition . and due to the fact that @xmath148 , the region of @xmath149 is @xmath216 , therefore the condition that there exists a unique solution in the region of @xmath216 is that @xmath217 .",
    "the proof of the theorem is complete .",
    "the normal assumption in theorem  [ mainth ] is used to reduce an arbitrary loading matrix @xmath10 satisfying @xmath142 to its canonical form as explained in step 2 of the proof . if the loading matrix is assumed to have the canonical form , this normal assumption is no more necessary .       in this section ,",
    "we detail the phase transition condition @xmath218 that defines the detection frontier of the factors . unlike similar phenomenon observed for large sample covariance matrices as exposed in @xcite and @xcite , this transition condition for autocovariance matrix",
    "has a more complex nature involving the three parameters : the limiting ratio @xmath219 and the two signal - to - noise ratios ( snr ) @xmath220 and @xmath221 involving the variance and lag-1 autocovariance of the @xmath81-th factor time series @xmath222 .    to start with , we observe that the condition can be reduced to @xmath223 which has two possibilities as follows : @xmath224 or @xmath225     as a function of the limiting ratio @xmath219 .",
    ", width=302 ]    first , we see the value of @xmath226 can be derived using , with the value of @xmath62 given in as a function of @xmath219 , which is presented in figure [ tb ] .",
    "when @xmath219 increases from zero to infinity , the value of @xmath226 also increases from zero to infinity .",
    "observe also that the slope at the origin is infinity : @xmath227 .    once @xmath0 and @xmath1 are given ( @xmath219 is fixed ) ,",
    "the value of @xmath226 is fixed , then the conditions and can be considered as the restriction of the two parameters @xmath220 and @xmath221 . and this defines a complex region in the @xmath228 plan which is depicted in figure [ region ] .",
    "the dashed curve in figure [ region ] stands for the equality @xmath229 and the area inside this curve ( the darker region ) is the condition , while outside ( the lighter region ) stands for condition .",
    "the dotted lines stand for @xmath230 and the upper and lower boundaries in solid lines are due to the fact that we have always @xmath231 ( by cauchy - schwarz inequality ) .",
    "these solid and dotted lines intersect with each other at points @xmath232 and @xmath233 where @xmath234 in other words , we have except for the quadrilateral region @xmath235 , our conditions and will hold true , which means that the corresponding factors are significant ( and thus asymptotically detectable ) .",
    "the quadrilateral region @xmath235 thus defines the phase transition boundary for the significance of the factors .",
    "+   and @xmath221 that will lead to significant factors.[region],title=\"fig:\",width=321 ]    we summarize the above findings as follows .",
    "[ coro1 ] under the same conditions as in theorem  [ mainth ] , the @xmath81-th time series @xmath222 will generate a significant factor in the sense that @xmath218 if and only if either @xmath236 or @xmath237 where the constant @xmath238 is given in .",
    "we now introduce some important comments on the meaning of these conditions .    1 .",
    "the essential message from these conditions is that _ the @xmath81-th factor time series is a significant factor once its strength @xmath79 , or more exactly , its snr @xmath220 exceeds a certain level @xmath60 . _ a sufficient value for this level @xmath60 is @xmath239 as shown in figure  [ region ] .",
    "meanwhile , the snr should at least equal to @xmath238 given in , see point a on the figure which has coordinates @xmath240 .",
    "when @xmath241 , the exact condition also depends on the lag-1 snr @xmath242 as given in eqs .  -",
    "+ this is thus much in line with what is known for the phase transition phenomenon for large sample covariance matrices as exposed in @xcite and @xcite .",
    "2 .   as said in introduction , in most of existing literature on high - dimensional factor models , the factor strengths are assumed to grow to infinity with the dimension @xmath0 .",
    "clearly , such _ growing factors _ are highly significant in our scheme , i.e. @xmath243 , since they will exceed the upper limit @xmath244 very quickly as the dimension @xmath0 grows .",
    "3 .   assume that @xmath245 , i.e. the sample size @xmath1 is much larger than the dimension @xmath0 .",
    "then it can be checked that both the quantities @xmath238 and @xmath244 will vanish .",
    "therefore , when @xmath246 is small enough , any factor time series will generate a significant sample factor eigenvalue .",
    "in other words , we have recovered the classical low - dimensional situation where @xmath0 is hold fixed and @xmath247 for which all the @xmath2 factor time series can be consistently detected and identified .",
    "let @xmath248 be the eigenvalues of @xmath249 , sorted in decreasing order .",
    "assume that among the @xmath2 factors , the first @xmath65 are significant which satisfy the phase transition condition @xmath250 , see eq .. following theorem [ mainth ] , the @xmath2 largest sample eigenvalue @xmath251 converges respectively to a limit @xmath252 , which is larger than the right edge @xmath62 of the limiting spectral distribution for @xmath253 , and equal to @xmath62 for @xmath254 .",
    "it will be proved below that the largest noise sample eigenvalues of a given finite number all converge to @xmath62 , i.e. for any fixed range @xmath255 , @xmath256 consider the sequence of ratios @xmath257 by definition @xmath258 .",
    "therefore , we have almost surely , @xmath259    note that the value of @xmath260 is independent of @xmath155 . in other words",
    ", we do not need the true value of @xmath155 for estimating the number of factors , indeed .",
    "let @xmath261 be a positive constant and we introduce the following estimator for the number of factors @xmath2 : @xmath262    [ khat ] consider the factor model   and assume that the same conditions as in theorem  [ mainth ] are satisfied .",
    "let @xmath65 be the number of significant factors defined in eq .   and",
    "a threshold constant @xmath263 be chosen such that @xmath264 then @xmath265 .",
    "this theorem thus formally establishes the fact that the ratio estimator @xmath64 is able to detect all the significant factors that satisfy the phase transition condition given in theorem  [ mainth ] and detailed in eqs.- .",
    "( of theorem  [ khat ] ) as @xmath266 for @xmath267 and by assumption , almost surely , it will happen eventually that @xmath268 .",
    "next , under the claim and following the limits given in , @xmath269 consequently , almost surely we will have eventually @xmath270 which , combined with the conclusion above , proves the almost sure convergence of @xmath64 to @xmath271 .",
    "it remains to prove the claim .",
    "since @xmath260 is independent of the choice of @xmath155 , we can assume w.l.o.g that @xmath117 as before . recall that in the proof of theorem  [ mainth ] , it has been proved in eqs.- that if @xmath183 is a eigenvalue of @xmath29 , then @xmath272 is a positive eigenvalue of the matrix @xmath273 which is obtained after permutation of the second and third row block and column block in without modifying the eigenvalues .",
    "now @xmath274 is a symmetric block matrix and the positive eigenvalues of the lower diagonal block @xmath275 are associated to the eigenvalues of the matrix @xmath276 which is of dimension @xmath28 ( for the definition of these matrices , see that proof ) .",
    "let @xmath277 be the eigenvalues of @xmath278 .",
    "by cauchy interlacing theorem , we have @xmath279 observing that @xmath180 is distributed as @xmath280 except that the dimension is changed from @xmath0 to @xmath28 .",
    "therefore , the global limit of the eigenvalues of @xmath278 are the same as for the matrix @xmath281 ; in particular , according to corollary  [ coro ] , both @xmath282 and @xmath283 converge to @xmath62 almost surely .",
    "this proves the fact that @xmath284 . using similar arguments",
    ", we can establish the same fact for @xmath285 for any fixed index @xmath286 .",
    "the claim is thus established .",
    "for the estimator @xmath64 in to be practically useful , we need to set up an appropriate value of the tuning parameter @xmath263 .",
    "although in theory , any vanishing sequence @xmath287 will guarantee the consistence of @xmath64 , it is preferable to have an indicated and practically useful sequence @xmath288 for real - life data analysis .",
    "here we propose an _ a priori _ calibration of @xmath263 based on some knowledge from random matrix theory on the largest eigenvalues of sample covariance matrices and of their perturbed versions .",
    "the most important property we will use is that according to such recent results on finite rank perturbations of symmetric random matrices , see e.g. @xcite it is very likely that the asymptotic distribution of @xmath289 is the same as that of @xmath290 , where @xmath291 , @xmath292 are the two largest eigenvalues of the base noise matrix @xmath293 . using this similarity , we calibrate @xmath263 by simulation : for any given pair @xmath294 , the distribution of @xmath290 is sampled using a large number ( in fact 2000 ) of independent replications of standard gaussian vectors @xmath295 and its lower 0.5% quantile @xmath296 is obtained ( notice that the quantile is negative ) . using the approximation @xmath297",
    "we calibrate @xmath263 at the value @xmath298 . in all the simulation experiments in section",
    "[ simulation ] or for the data analysis reported in section  [ application ] , this tuned value of @xmath263 is used for the given pairs @xmath299 .",
    "in this section , we report some simulation results to show the finite - sample performance of our estimator . for the reason of robustness , we will consider a reinforced estimator @xmath300 defined as @xmath301 clearly , @xmath300 is asymptotically equivalent to the initial estimator @xmath64 which uses only one single test value @xmath302 . as for the factor model , we adopt the same settings as in @xcite where @xmath303 @xmath304 where @xmath10 is a @xmath11 matrix , w.l.o.g , we set the variance @xmath155 of the white noise @xmath8 to be 1 .    in @xcite , the factor loading matrix @xmath10",
    "are independently generated from uniform distribution on the interval @xmath305 $ ] first and then divided by @xmath306 where @xmath307 $ ] .",
    "the induced @xmath2 factor strengths are thus of order @xmath308 .",
    "their estimator of number of factors is recalled in .",
    "cases where three factors are either all very strong with @xmath309 or all moderately strong with @xmath310 are discussed in details in that paper .",
    "the results show that @xmath311 performs better when factors are stronger .",
    "an experimental setting with a combination of two strong factors and one moderate factor indicates that a two - step estimation procedure needs to be employed in order to identify all three factors . in each step",
    "only factors with the highest level of strength can be detected .",
    "while in our case , the coefficient matrix @xmath10 satisfies @xmath142 . considering the eigenvalues of @xmath29",
    "are invariant under orthogonal transformation ( see step 2 in the proof of theorem [ mainth ] ) , we fix @xmath168 then we manipulate the factor strength by adjusting the value of @xmath312 and @xmath274 . to ensure the stationarity of @xmath14 process and the independence among the components of the factor process @xmath165 , @xmath312 and @xmath274 are both diagonal matrices and the diagonal elements of @xmath312 lie within @xmath313 . to keep pace with the settings in @xcite ,",
    "we multiply @xmath314 with the diagonal entries of @xmath274 to adjust the corresponding factor strength .",
    "it can be seen that when @xmath309 , the factor is strongest while with @xmath315 , the factor is weakest .    the entire simulation study is mainly composed of four parts formulated in four different scenarios as follows :    * two very strong factors with @xmath316 and @xmath317 and @xmath318 * four weak factors with same strength level @xmath315 ; three of them are significant with their theoretical limits @xmath319 all keeping a moderate distance from @xmath62 while the fourth factor is insignificant with its theoretical limit @xmath320 equal to right edge @xmath62 of the noise eigenvalues .",
    "precisely , @xmath321 * three weak factors with @xmath315 and @xmath322 stays very close to @xmath62 and @xmath323 * a mixed case with two strong factors with @xmath324 , and five weak factors with @xmath315 , and @xmath325 @xmath326    recall that for the estimator @xmath300 , the critical value @xmath263 is calibrated as explained in section [ choosedn ] using the simulated empirical 0.5% lower quantile .",
    "we set @xmath327 , @xmath328 , i.e @xmath329 .",
    "it will be seen below that in general , the cases with @xmath330 will be harder to deal with than the cases with @xmath331 .",
    "we repeat 1000 times to calculate the empirical frequencies of the different decisions @xmath332 , @xmath333 and @xmath334 .",
    "the results are as follows .    * in scenario",
    "i , we have two very strong factors with @xmath316 and @xmath317 and their strengths grow to infinity with @xmath0 .",
    "thus @xmath335 and the two factors must be easily detectable .",
    "as seen from table  [ scena1 ] , our estimator @xmath300 converges very fast to the true number of factors . on the other hand , the one - step estimator @xmath311 of @xcite tends to detect only one factor in each step due to the fact that the two factors are of different strength .",
    "+ + c^c^c^c^c^c|^c^c^c^c^c^c @xmath0 & 100 & 300 & 500 & 1000 & 1500 & @xmath0 & 100 & 300 & 500 & 1000 & 1500@xmath331 & 200 & 600 & 1000 & 2000 & 3000 & @xmath331 & 200 & 600 & 1000 & 2000 & 3000@xmath336 & 0.343 & 0.294 & 0.257 & 0.287 & 0.317 & @xmath337 & 0 & 0 & 0 & 0 & 0 * * @xmath338 & 0.657 & 0.706 & 0.743 & 0.713 & 0.683 & @xmath339 & 0.974 & 0.984 & 0.993 & 0.996 & 0.998@xmath340 & 0 & 0 & 0 & 0 & 0 & @xmath341 & 0.026 & 0.016 & 0.007 & 0.004 & 0.002@xmath0 & 100 & 300 & 500 & 1000 & 1500 & @xmath0 & 100 & 300 & 500 & 1000 & 1500@xmath330 & 50 & 150 & 250 & 500 & 750 & @xmath330 & 50 & 150 & 250 & 500 & 750@xmath336 & 0.786 & 0.801 & 0.876 & 0.96 & 0.992 & @xmath337 & 0.086 & 0 & 0 & 0 & 0 * * @xmath338 & 0.21 & 0.199 & 0.124 & 0.04 & 0.008 & @xmath339 & 0.771 & 0.882 & 0.896 & 0.881 & 0.881@xmath340 & 0.004 & 0 & 0 & 0 & 0 & @xmath341 & 0.143 & 0.118 & 0.104 & 0.119 & 0.119 * in scenario ii , we have four weak factors of same strength level @xmath315 .",
    "the theoretical limits related to theorem [ mainth ] are displayed in table  [ scena2-lim ] .",
    "figure  [ table2y05 ] for @xmath331 and figure  [ table2y2 ] for @xmath330 depict the position of these four factors ( numbered from 1 to 4 ) in the phase transition region defined in corollary  [ coro1 ] and we see three among the four lying inside the detectable area in both situations .",
    "it can be seen from the table that for both combinations of @xmath331 and @xmath330 , the first three limits @xmath61 are far from upper bound @xmath62 and the fourth limit @xmath320 equals to @xmath62 .",
    "we thus have three significant factors ( @xmath342 ) which are detectable while the fourth one is too weak for the detection .",
    "results in table  [ scena2 ] show that both the estimators @xmath39 ( one - step ) and @xmath300 are consistent with however a much higher convergence speed for @xmath300 .",
    "+ + c|^c^c^c^c|^c^c^c^c|^c^c^c^c & & & & & & no.&@xmath312 & @xmath274 & @xmath343 & @xmath344 & @xmath345 & @xmath346 & @xmath347 & @xmath62 & @xmath345 & @xmath346 & @xmath347 & @xmath62(1)&0.6 & 4 & 6.25 & 3.75 & 0.0125 & 0.3076 & 21.2 & 2.7725 & 0.1102 & 0.7775 & 44.8 & 17.6366(2)&-0.5 & 4 & 5.33 & -2.67 & 0.021 & 0.3076 & 13.1 & 2.7725 & 0.1596 & 0.7775 & 33.85 & 17.6366(3)&0.3 & 4 & 4.3956 & 1.3187 & 0.047 & 0.3076 & 6.65 & 2.7725 & 0.2767 & 0.7775 & 23.92 & 17.6366(4 ) & 0.2 & 1 & 1.042 & 0.2083 & 0.3446 & 0.3076 & * 2.7725 * & * 2.7725 * & 1.5296 & 0.7775 & * 17.6366 * & 1 * 7.6366 * * theoretical limits and empirical result for scenario iii are presented in table  [ scena3-lim ] , figures  [ table2y05 ] and [ table2y2 ] , and table  [ scena3 ] . for both situations of @xmath330 and @xmath331 ,",
    "the model has three significant factors ( @xmath348 ) .",
    "notice however that when @xmath330 , the 3rd factor is quite weak and the corresponding limit @xmath349 is very close to the right edge @xmath350 so that this factor would be detectable only in theory ( or with very large sample sizes ) .",
    "this is also easily verified in figure  [ table2y2 ] that the point ( 3 ) corresponding to the weakest factor lies very close to the boundary of the detectable region . as for the empirical values in table  [ scena3 ] , the estimator @xmath300 converges quickly when @xmath331 and much more slowly when @xmath330 .",
    "meanwhile , the estimator @xmath39 ( with one - step ) seems inconsistent even in the easier case of @xmath331 .",
    "+ + c|^c^c^c^c|^c^c^c^c|^c^c^c^c & & & & & & no .",
    "& @xmath312 & @xmath274 & @xmath343 & @xmath344 & @xmath345 & @xmath346 & @xmath347 & @xmath62 & @xmath345 & @xmath346 & @xmath347 & @xmath62(5)&0.6 & 2 & 3.125 & 1.875 & 0.0391 & 0.3076 & 7.65 & 2.7725 & 0.2845 & 0.7775 & 23.79 & 17.6366(6)&-0.5 & 2 & 2.67 & -1.33 & 0.0607 & 0.3076 & 5.48 & 2.7725 & 0.3852 & 0.7775 & 20.45 & 17.6366(7)&0.3 & 2 & 2.20 & 0.659 & 0.1183 & 0.3076 & 3.61 & 2.7725 & 0.6116 & 0.7775 & * 17.95 * & * 17.6366 * * scenario iv is the most complex case with two very strong factors and five weak factors . as predicted by the theory , the two largest factor eigenvalues @xmath351 of @xmath70 blow up to infinity while the following 5 factor eigenvalues @xmath352 converge to a @xmath148 .",
    "the corresponding theoretical limits for the five weak factors are given in table  [ scena4-lim ] and their snr s depicted in figures  [ table2y05 ] and [ table2y2 ] .",
    "meanwhile , all the @xmath353 factors are significant . clearly in this scenario , the performance of the one - step estimator @xmath39 , denoted as @xmath354 , is quite limited and in order to make a closer comparison with our estimator @xmath300 , we have also run the two - step and the three - step versions of the estimator @xmath39 . among these two versions we report the best results obtained by the three - step version ( denoted as @xmath355 ) .",
    "it can be seen from table  [ scena4 ] that our estimator is able to detect the 7 factors with multi - level strength in a single step while @xmath311 can only identify one factor in each step : i.e. @xmath356 and @xmath357 .",
    "+ + c|^c^c^c^c|^c^c^c^c|^c^c^c^c & & & & & & no .",
    "& @xmath312 & @xmath274 & @xmath343 & @xmath344 & @xmath345 & @xmath358 & @xmath347 & @xmath62 & @xmath345 & @xmath358 & @xmath347 & @xmath62(1 ) & 0.6 & 4 & 6.25 & 3.75 & 0.0125 & 0.3076 & 21.2 & 2.7725 & 0.1102 & 0.7775 & 44.8 & 17.6366(2 ) & -0.5 & 4 & 5.33 & -2.67 & 0.021 & 0.3076 & 13.1 & 2.7725 & 0.1596 & 0.7775 & 33.85 & 17.6366(3 ) & 0.3 & 4 & 4.3956 & 1.3187 & 0.047 & 0.3076 & 6.65 & 2.7725 & 0.2767 & 0.7775 & 23.92 & 17.6366(5 ) & 0.6 & 2 & 3.125 & 1.875 & 0.0391 & 0.3076 & 7.65 & 2.7725 & 0.2845 & 0.7775 & 23.79 & 17.6366(6 ) & -0.5 & 2 & 2.67 & -1.33 & 0.0607 & 0.3076 & 5.48 & 2.7725 &",
    "0.3852 & 0.7775 & 20.45 & 17.6366 + + c^c^c^c^c^c|^c^c^c^c^c^c p & 100 & 300 & 500 & 1000 & 1500 & p & 100 & 300 & 500 & 1000 & 1500t=2p & 200 & 600 & 1000 & 2000 & 3000 & t=0.5p & 50 & 150 & 250 & 500 & 750@xmath359 & 0.696 & 0.858 & 0.949 & 0.995 & 1 & @xmath359 & 0.73 & 0.812 & 0.881 & 0.95 & 0.986@xmath360 & 0.244 & 0.137 & 0.051 & 0.005 & 0 & @xmath360 & 0.211 & 0.177 & 0.118 & 0.05 & 0.014@xmath361 & 0.033 & 0.004 & 0 & 0 & 0 & @xmath361 & 0.039 & 0.011 & 0.001 & 0 & 0@xmath362 & 0.019 & 0.001 & 0 & 0 & 0 & @xmath362 & 0.015 & 0 & 0 & 0 & 0@xmath363 & 0.005 & 0 & 0 & 0 & 0 & @xmath363 & 0.004 & 0 & 0 & 0 & 0@xmath364 & 0.002 & 0 & 0 & 0 & 0 & @xmath364 & 0.001 & 0 & 0 & 0 & 0 * * @xmath365 & 0.001 & 0 & 0 & 0 & 0 & @xmath365 & 0 & 0 & 0 & 0 & 0@xmath366 & 0 & 0 & 0 & 0 & 0 & @xmath366 & 0 & 0 & 0 & 0 & 0p & 100 & 300 & 500 & 1000 & 1500 & p & 100 & 300 & 500 & 1000 & 1500t=2p & 200 & 600 & 1000 & 2000 & 3000 & t=0.5p & 50 & 150 & 250 & 500 & 750@xmath367 & 0 & 0 & 0 & 0 & 0 & @xmath367 & 0 & 0 & 0 & 0 & 0@xmath368 & 0 & 0 & 0 & 0 & 0 & @xmath368 & 0 & 0 & 0 & 0 & 0@xmath369 & 0.691 & 0.875 & 0.945 & 0.998 & 0.999 & @xmath369 & 0.71 & 0.802 & 0.862 & 0.955 & 0.982@xmath370 & 0.002 & 0 & 0 & 0 & 0 & @xmath370 & 0 & 0 & 0 & 0 & 0@xmath371 & 0 & 0 & 0 & 0 & 0 & @xmath371 & 0.001 & 0 & 0 & 0 & 0@xmath372 & 0.244 & 0.125 & 0.055 & 0.002 & 0.001 & @xmath372 & 0.212 & 0.192 & 0.135 & 0.045 & 0.018 * * @xmath373 & 0 & 0 & 0 & 0 & 0 & @xmath373 & 0 & 0 & 0 & 0 & 0@xmath374 & 0.063 & 0 & 0 & 0 & 0 & @xmath374 & 0.077 & 0.006 & 0.003 & 0 & 0p & 100 & 300 & 500 & 1000 & 1500 & p & 100 & 300 & 500 & 1000 & 1500t=2p & 200 & 600 & 1000 & 2000 & 3000 & t=0.5p & 50 & 150 & 250 & 500 & 750@xmath337 & 0.012 & 0 & 0 & 0 & 0 & @xmath337 & 0.151 & 0.01 & 0 & 0 & 0@xmath375 & 0.031 & 0.001 & 0 & 0 & 0 & @xmath375 & 0.25 & 0.038 & 0.01 & 0.001 & 0@xmath376 & 0.034 & 0.002 & 0 & 0 & 0 & @xmath376 & 0.28 & 0.065 & 0.027 & 0.003 & 0@xmath377 & 0.062 & 0.015 & 0.006 & 0.001 & 0 & @xmath377 & 0.254 & 0.227 & 0.107 & 0.022 & 0.007@xmath378 & 0.049 & 0 & 0 & 0 & 0 & @xmath378 & 0.06 & 0.384 & 0.295 & 0.035 & 0.002@xmath379 & 0.185 & 0 & 0 & 0 & 0 & @xmath379 & 0.005 & 0.231 & 0.414 & 0.34 & 0.138 * * @xmath339 & 0.597 & 0.939 & 0.958 & 0.95 & 0.959 & @xmath339 & 0 & 0.044 & 0.142 & 0.557 & 0.783@xmath380 & 0.03 & 0.043 & 0.036 & 0.049 & 0.041 & @xmath380 & 0 & 0.001 & 0.005 & 0.042 & 0.07",
    "we analyse the log returns of 100 stocks ( denoted by @xmath5 ) , included in the s&p500 during the period from 2005 - 01 - 03 to 2011 - 09 - 16 .",
    "we have in total @xmath381 observations with @xmath382 .",
    "thorough eigenvalue analysis is applied to the lag-1 sample auto - covariance matrix @xmath383 of @xmath5 .",
    "the largest eigenvalue of @xmath101 is @xmath384 .",
    "the second to the 30th largest eigenvalues and their ratios are plotted in fig [ eigratio ] .",
    "[ eigratio],scaledwidth=80.0% ]    to estimate the number of factors , we first adopt the two - step procedure investigated by @xcite since the ratio plot in fig [ eigratio ] is exhibiting at least two different levels of factor strength . obviously , in the first step , @xmath385 the factor loading estimator of the first factor @xmath386 is the eigenvector of @xmath101 which corresponds to the largest eigenvalue @xmath387 .",
    "the resulting residuals after eliminating the effect of the first factor is @xmath388 repeating the procedure in step one , we treat @xmath389 as the original sequence @xmath5 and get the eigenvalues @xmath390 of the lag-1 sample auto - covariance matrix @xmath391 .",
    "the 30 largest eigenvalues and their ratios are plotted in fig [ eigratiostep2 ] .",
    ", scaledwidth=80.0% ]    it can be seen from the second step that @xmath392 the factor loading estimator of the second level factors @xmath393 are the orthonormal eigenvectors of @xmath394 corresponding to the first two largest eigenvalues .    in conclusion ,",
    "the two - step procedure proposed by @xcite identifies three factors in total with two different levels of factor strength .",
    "the eigenvalues of the lag-1 sample auto - covariance matrix @xmath395 of residuals after subtracting the three factors detected previously are shown in fig [ eigratiostep3 ] .",
    ", scaledwidth=80.0% ]    there is still one isolated eigenvalue in the eigenvalues plot .",
    "if we go one step further and treat it as an extra factor with weakest strength , then the eigenvalue plot of the lag-1 sample auto - covariance matrix @xmath396 of residuals after eliminating four factors looks like in fig [ eigratiostep4 ] .",
    ", scaledwidth=80.0% ]    a major problem of the methodology in @xcite is that it does not provide a clear criterion to stop this two or multi - step procedure .",
    "clearly , this method can only detect factors with one level of strength at each step and can hardly handle problems with factors of multilevel strengths due to the lack of stopping criterion in multi - step detection .    in the following ,",
    "we use the estimator @xmath300 of this paper to estimate the number of factors . at first",
    ",    the tuning parameter @xmath263 is calibrated with @xmath397 using the simulation method indicated in section  [ choosedn ] ; the value found is @xmath398 in this case .",
    "the eigenvalue ratios of the sample matrix @xmath70 are shown in figure  [ eigratiodn ] ( already displayed in the lower panel of figure  [ eigratio ] ) where the detection line of value @xmath399 is also drawn . as displayed , we found @xmath400 factors .",
    "in conclusion , for this data set with @xmath382 stocks , our estimator proposes 4 significant factors while the estimator @xmath39 from @xcite indicate 1 , 3 and 4 factors when one step , two steps and 3 steps are used respectively .",
    "it appears again that multiple steps are needed for the use of the estimator @xmath64 in real data analysis ; it remains however unclear how to decide the number of these necessary steps . on the contrary , our estimator is able to identify simultaneously all significant factors and the procedure is independent of the number of different levels of the factor strengths .",
    ", scaledwidth=80.0% ]",
    "a supplementary file @xcite collects several technical proofs used in the paper .    99    alessi , l. , barigozzi , m. and capasso , m. ( 2010 ) improved penalization for determining the number of factors in approximate factor models _ statist .",
    "letters _ * 80 * , 1806 - 1813 .",
    "bai , j. and ng , s. ( 2002 ) .",
    "determining the number of factors in approximate factor models .",
    "_ econometrica _ , * 70*(1 ) , 191 - 221 .",
    "bai , j. and ng , s. ( 2007 ) .",
    "determining the number of primitive shocks in factor models . _ journal of business and economic statistics _ , * 25*(1 ) , 52 - 60 .",
    "and ng , s. ( 2013 ) . principal components estimation and identification of static factors . _ j. econometrics .",
    "_ , * 176*(1 ) , 1829 .    and yao , j. ( 2008 ) .",
    "central limit theorems for eigenvalues in a spiked population model . , * 44*(3 ) , 447474 .    and yao , j. ( 2012 ) . on sample eigenvalues in a generalized spiked population model . , * 106 * ,",
    "167177 .    and",
    "silverstein , j.w .",
    "eigenvalues of large sample covariance matrices of spiked population models . , * 97 * , 13821408 .    and nadakuditi , r.r .",
    "the eigenvalues and eigenvectors of finite , low rank perturbations of large random matrices .",
    "_ , * 227*(2 ) , 494521 .    and mada , m. ( 2011 ) .",
    "fluctuations of the extreme eigenvalues of finite rank deformations of random matrices . _ electron .",
    "j. probab .",
    "_ * 16*(60 ) , 16211662 .    forni , m. , hallin , m. , lippi , m. and reichlin , l. ( 2000 ) .",
    "the generalized dynamic - factor model : identification and estimation .",
    "_ review of economics and statistics _ , * 82*(4 ) , 540 - 554 .",
    "forni , m. , hallin , m. , lippi , m. and reichlin , l. ( 2004 ) . the generalized dynamic factor model consistency and rates .",
    "_ j. econometrics .",
    "_ , * 119*(2 ) , 231 - 255 .",
    "forni , m. , hallin , m. , lippi , m. and reichlin , l. ( 2005 ) .",
    "the generalized dynamic factor model : one sided estimation and forecasting . _ j. amer .",
    "_ , * 100 * , 830 - 840 .    geweke j. ( 1977 ) . the dynamic factor analysis of economic time series .",
    "_ in latent variables in socio - economic models , _ ed . by d.j.aigner and a.s.goldberger , amsterdam : north - holland .",
    "hallin , m. and liska , r. ( 2007 ) .",
    "determining the number of factors in the general dynamic factor model .",
    "_ j. amer .",
    "_ , * 102*(478 ) , 603 - 617 .",
    "jin , b. , wang , c. , bai , z. , nair , k. and harding , m. ( 2014 ) limiting spectral distribution of a symmetrized auto - cross covariance matrix . _",
    "ann . applied probab . _ * 24*(3 ) , 1199 - 1225 .",
    "( 2001 ) . on the distribution of the largest eigenvalue in principal components analysis . ,",
    "* 29*(2 ) , 295327 .",
    "and yao , q.w . ( 2012 ) .",
    "factor modeling for high - dimensional time series : inference for the number of factors .",
    "_ * 40 * , 694 - 726 .    and yao , j. ( 2014 ) .",
    "on singular value distribution of large - dimensional autocovariance matrices .",
    "_ preprint _ ( arxiv:1402.6149 ) .    and yao , j. ( 2014 ) .",
    "in appendix of this paper :  supplementary material for the paper `` identifying the number of factors from singular values of a large sample auto - covariance matrix '' .",
    "onatski , a. ( 2010 ) .",
    "determining the number of factors from empirical distribution of eigenvalues . _ the review of economics and statistics _",
    ", * 92*(4 ) , 1004 - 1016 .",
    "onatski , a. ( 2012 ) asymptotics of the principal components estimator of large factor models with weakly influential factors .",
    "_ j. econometrics _ * 168 * ( 2 ) , 244 - 258 .",
    "onatski , a. ( 2015 ) asymptotic analysis of the squared estimation error in misspecified factor models .",
    "_ j. econometrics _ * 186 * ( 2 ) , 388 - 406 .    and yao , j. ( 2012 ) . on determining the number of spikes in a high - dimensional spiked population model .",
    "_ random matrices : theory and applications _ , * 1 * , 1150002 .",
    "sargent , t. j. and sims , c. a. ( 1977 ) .",
    "business cycle modeling without pretending to have too much a priori economic theory .",
    "_ new methods in business cycle research , _ * 1 * , 145 - 168",
    ".    stock , j. h. and watson , m w. ( 2011 ) .",
    "dynamic factor models .",
    "oxford handbook of economic forecasting , * 1 * , 35 - 59 .     wang , c. , jin , b. , bai , z. , nair , k. and harding , m. ( 2015 ) strong limit of the extreme eigenvalues of a symmetrized auto - cross covariance matrix .",
    "forthcoming in _ ann . applied .",
    "( ` http://www.imstat.org/aap/future_papers.html ` ) wang , q. w. and yao , j. ( 2014 ) .",
    "moment approach to for singular values distribution of a large auto - covariance matrix .",
    "_ preprint _ ( arxiv:1410.0752 ) .",
    "this supplementary collects several technical lemmas that are used in the main paper .          [",
    "33 ] @xmath405\\\\      & = { \\mathbb{e}}\\left[\\lambda i_k-\\lambda x_0'(\\lambda^2i - e_2e_2'e_1e_1')^{-1}e_2e_2'x_0\\right]\\\\      & = \\begin{pmatrix }        \\lambda-\\frac{\\lambda t(\\lambda^2)}{y+t(\\lambda^2)}(1+\\gamma_0(1 ) ) & \\cdots & 0 \\\\        \\vdots & \\ddots & \\vdots \\\\        0 & \\cdots & \\lambda-\\frac{\\lambda t(\\lambda^2)}{y+t(\\lambda^2)}(1+\\gamma_0(k ) ) \\\\",
    "\\end{pmatrix }    \\end{aligned}\\ ] ]    @xmath405\\\\      & = { \\mathbb{e}}\\left\\{{\\mathbb{e}}\\left[\\lambda i_k-\\lambda x_1'(\\lambda^2i - e_1e_1'e_2e_2')^{-1}e_1e_1'x_1\\big| x_1\\right]\\right\\}\\\\      & = { \\mathbb{e}}\\left\\{\\lambda i_k-\\lambda x_1'e\\left[(\\lambda^2i - e_1e_1'e_2e_2')^{-1}e_1e_1'\\right]x_1\\big| x_1\\right\\}~.    \\end{aligned}\\ ] ]    since @xmath406\\ ] ] is a diagonal @xmath407 matrix according to lemma [ l1 ] , and we denote it as @xmath408 then the @xmath409-th element of @xmath410x_1\\right\\}$ ] equals to @xmath411~ ,    \\end{aligned}\\ ] ] where the second and third equalities are due to the independence between @xmath7 and @xmath8 and the i.i.d feature of @xmath8 .",
    "if we denote @xmath412~ ,    \\end{aligned}\\ ] ] there exists the relationship that : @xmath413 see ( 1 ) in @xcite .",
    "so reduces to : @xmath414 besides , @xmath415\\\\      & = \\begin{cases }        \\int_a^b \\frac{1}{x-\\lambda^2}f(x)dx~,~~~~y>1\\\\[3 mm ]        \\int_0^b \\frac{1}{x-\\lambda^2}f(x)dx-\\frac{1-y}{\\lambda^2}~,~~~~0<y \\leq 1~ ,      \\end{cases }    \\end{aligned}\\ ] ] which leads to @xmath416        \\int_0^b \\frac{x}{x-\\lambda^2}f(x)dx~,~~~~0<y \\leq 1~      \\end{cases}\\\\      & = -t(\\lambda^2)~ ,    \\end{aligned}\\ ] ] where @xmath417 is the density function of the lsd of @xmath418 ( also @xmath419 ) , and @xmath420 is the @xmath1-transform that associated with @xmath417 whose support is @xmath421 $ ] .",
    "all this leads to the fact that @xmath427\\\\      & = \\begin{pmatrix }        \\lambda-\\frac{\\lambda t(\\lambda^2)}{y+t(\\lambda^2)}(1+\\gamma_0(1 ) ) & \\cdots & 0 \\\\        \\vdots & \\ddots & \\vdots \\\\        0 & \\cdots & \\lambda-\\frac{\\lambda t(\\lambda^2)}{y+t(\\lambda^2)}(1+\\gamma_0(k ) ) \\\\",
    "\\end{pmatrix}~.    \\end{aligned}\\ ] ] the same result also holds true for @xmath428~.\\ ] ] the proof of the lemma is complete .",
    "[ 34 ] @xmath429\\\\      = & { \\mathbb{e}}\\left[x_0'\\left(i+(\\lambda^2i - e_2e_2'e_1e_1')^{-1}e_2e_2'e_1e_1'\\right)x_1\\right]\\\\      = & \\begin{pmatrix }        ( 1+t(\\lambda^2))\\gamma_1(1 ) & \\cdots & 0 \\\\        \\vdots & \\ddots & \\vdots \\\\        0 & \\cdots & ( 1+t(\\lambda^2))\\gamma_1(k)\\\\      \\end{pmatrix }    \\end{aligned}\\ ] ]    @xmath429\\\\      = & { \\mathbb{e}}\\left\\{{\\mathbb{e}}\\left[x_1'\\left(i+(\\lambda^2i - e_1e_1'e_2e_2')^{-1}e_1e_1'e_2e_2'\\right)x_0\\big|x_0,x_1\\right]\\right\\}\\\\      = & { \\mathbb{e}}\\left\\{x_1'{\\mathbb{e}}\\left[i+(\\lambda^2i - e_1e_1'e_2e_2')^{-1}e_1e_1'e_2e_2'\\right]x_0\\big|x_0,x_1\\right\\}\\\\    \\end{aligned}\\ ] ]    since @xmath430 is diagonal according to lemma [ l2 ] , and we denote it as @xmath431",
    ". then the @xmath409-th element of @xmath432\\ ] ] equals to @xmath433\\right)\\\\      = & \\gamma_1(i)\\left(1+\\int \\frac{x}{\\lambda^2-x}df(x)\\right)=\\gamma_1(i)(1+t(\\lambda^2))~.    \\end{aligned}\\ ] ]    also for @xmath423 , the @xmath424-th element of @xmath432\\ ] ] equals to @xmath434 where the last equality is due to the independence between the @xmath2 coordinates of @xmath7 and between @xmath7 and @xmath8 ."
  ],
  "abstract_text": [
    "<S> identifying the number of factors in a high - dimensional factor model has attracted much attention in recent years and a general solution to the problem is still lacking . a promising ratio estimator based on the singular values of the lagged autocovariance matrix </S>",
    "<S> has been recently proposed in the literature and is shown to have a good performance under some specific assumption on the strength of the factors . </S>",
    "<S> inspired by this ratio estimator and as a first main contribution , this paper proposes a complete theory of such sample singular values for both the factor part and the noise part under the large - dimensional scheme where the dimension and the sample size proportionally grow to infinity . </S>",
    "<S> in particular , we provide the exact description of the phase transition phenomenon that determines whether a factor is strong enough to be detected with the observed sample singular values . based on these findings and as a second main contribution of the paper , </S>",
    "<S> we propose a new estimator of the number of factors which is strongly consistent for the detection of all significant factors ( which are the only theoretically detectable ones ) . </S>",
    "<S> in particular , factors are assumed to have the minimum strength above the phase transition boundary which is of the order of a constant ; they are thus not required to grow to infinity together with the dimension ( as assumed in most of the existing papers on high - dimensional factor models ) . </S>",
    "<S> empirical monte - carlo study as well as the analysis of stock returns data attest a very good performance of the proposed estimator . in all the tested cases , </S>",
    "<S> the new estimator largely outperforms the existing estimator using the same ratios of singular values . </S>"
  ]
}