{
  "article_text": [
    "in this paper , we study combinatorial optimization problems with a diseconomy of scale .",
    "we consider problems in which we need to minimize the cost of resources used to accomplish a certain task .",
    "often , the cost grows linearly with the amount of resources used . in some applications , the cost is sublinear e.g. , if we can get a discount when we buy resources in bulk .",
    "such phenomenon is known as  economy of scale \" . however , in many applications the cost is superlinear . in such cases , we say that the cost function exhibits a `` diseconomy of scale '' .",
    "a good example of a diseconomy of scale is the cost of energy used for computing .",
    "modern hardware can run at different processing speeds . as we increase the speed",
    ", the energy consumption grows superlinearly .",
    "it can be modeled as a function @xmath19 of the processing speed @xmath20 , where @xmath21 and @xmath4 are parameters that depend on the specific hardware .",
    "typically , @xmath22 $ ] ( see e.g. , @xcite ) .",
    "as a running example , consider the minimum power routing problem studied by andrews , fernndez anta , zhang , and zhao  @xcite .",
    "we are given a graph @xmath23 and a set of demands @xmath24 .",
    "our goal is to route @xmath25 ( @xmath26 ) units of demand @xmath27 from the source @xmath28 to the destination @xmath29 such that every demand @xmath27 is routed along a single path @xmath30 ( i.e. we need to find an unsplittable multi - commodity flow ) .",
    "we want to minimize the energy cost .",
    "every link ( edge ) @xmath31 uses @xmath32 units of power , where @xmath33 is a scaling parameter depending on the link @xmath34 , and @xmath35 is the load on @xmath34 .    the straightforward approach to solving this problem is as follows .",
    "we define a mathematical programming relaxation that routes demands fractionally .",
    "it sends @xmath36 units of demand via the path @xmath37 connecting @xmath38 to @xmath39 .",
    "we require that @xmath40 for every demand @xmath27 .",
    "the objective function is to minimize @xmath41 where @xmath42 is the load on the link @xmath34 .",
    "this relaxation can be solved in polynomial time , since the objective function is convex ( for @xmath43 ) .",
    "but , unfortunately , the integrality gap of this relaxation is @xmath44 @xcite .",
    "andrews et al .",
    "@xcite gave the following integrality gap example .",
    "consider two vertices @xmath20 and @xmath45 connected via @xmath46 disjoint paths .",
    "our goal is to route 1 unit of flow integrally from @xmath20 to @xmath45 .",
    "the optimal solution pays 1 .",
    "the lp may cheat by routing @xmath47 units of flow via @xmath46 disjoint paths .",
    "then , it pays only @xmath48 .    for the case of uniform demands ,",
    "i.e. , for the case when all @xmath49 , andrews et al .",
    "@xcite suggested a different objective function : @xmath50 the objective function is valid , because in the integral case , @xmath35 must be a multiple of @xmath51 , and thus @xmath52 .",
    "andrews et al .",
    "@xcite proved that the integrality gap of this relaxation is a constant .",
    "bampis et al .",
    "@xcite improved the bound to the _ fractional bell number _",
    "@xmath53 that is defined as follows : @xmath53 is the @xmath4-th moment of the poisson random variable @xmath54 with parameter 1 ( see figure  [ fig : plot - aq ] in appendix  [ sec : figures ] ) . i.e. , @xmath55}=\\sum_{t=1}^{+\\infty}t^q \\frac{e^{-1}}{t!}.\\ ] ]    for the case of general demands no constant approximation was known .",
    "the best known approximation due to andrews et al .",
    "@xcite was @xmath56 where @xmath57 is the number of demands and @xmath58 is the size of the largest demand ( theorem 8 in @xcite ) .    in this work ,",
    "we give an @xmath53-approximation algorithm for the general case and thus close the gap between the case of uniform and non - uniform demands .",
    "our approximation algorithm uses a general framework for solving problems with a diseconomy of scale which we present in this paper .",
    "we use this framework to obtain approximation algorithms for several other combinatorial optimization problems .",
    "we give @xmath59-approximation algorithm for load balancing on unrelated parallel machines ( see section  [ section : loadbalancing ] ) , @xmath60-approximation algorithm for unrelated parallel machine scheduling with non - linear functions of completion times ( see section  [ section : unrelatedparallel ] ) and @xmath53-approximation algorithm for the minimum degree balanced spanning tree problem ( see section  [ section : qst ] ) .",
    "the best previously known bound for the first problem with @xmath61 $ ] was @xmath62 ( see figure  [ fig : plot - results ] for comparison ) .",
    "the bound is due to kumar , marathe , parthasarathy and srinivasan  @xcite .",
    "there were no known approximation guarantees for the latter problems .    in the analysis",
    ", we use the de la pea decoupling inequality  @xcite .",
    "let @xmath63 be jointly distributed nonnegative ( non - independent ) random variables , and let @xmath64 be independent random variables such that each @xmath6 has the same distribution as @xmath7 .",
    "then , for every @xmath43 , @xmath65 for some universal constant @xmath66 .",
    "de la pea , ibragimov , and sharakhmetov ( @xcite , corollary  3.4 ) showed that @xmath67 for @xmath68 $ ] , and @xmath69 for @xmath11 .",
    "we give an alternative proof of this inequality , and show that the inequality holds for @xmath70 for any @xmath13 , and moreover this bound is tight ( for any @xmath13 ) .",
    "thus , we improve the known upper bound for @xmath66 for @xmath9 .",
    "[ thm : decoupling ] inequality  ( [ eq : de - la - pena ] ) holds for @xmath71 , where @xmath53 is the fractional bell number ( see  equation  ( [ def : frac - bell - number ] ) and figure  [ fig : plot - aq ] ) .",
    "moreover , @xmath59 is the optimal upper bound on @xmath72 .",
    "in fact we prove a more general inequality for arbitrary convex functions and an analogous inequality for concave functions . in section  [ sec : neg - depend ] ( see corollary  [ cor : neg - assoc ] ) , we extend this theorem to negatively associated random variables  @xmath6 .",
    "we now describe the general framework for solving problems with a diseconomy of scale .",
    "we consider optimization problems with @xmath46 decision variables @xmath73 .",
    "we assume that the objective function equals the sum of @xmath74 terms , where the @xmath75-th term is of the form @xmath76 here @xmath77 s are nonnegative monotonically nondecreasing convex functions , @xmath78 are parameters",
    ". the vector @xmath79 must satisfy the constraint @xmath80 for some polytope @xmath81^n$ ] .",
    "therefore , the optimization problem can be written as the following boolean convex program ( ip ) : @xmath82 } f_j \\big(\\sum_{i\\in [ n ] } d_{ij } y_{i}\\big ) \\label{ip : obj}\\\\ & & y\\in { \\cal p } \\label{ip : poly}\\\\ & & y\\in \\{0,1\\}^{n } \\label{ip : int}\\end{aligned}\\ ] ] we assume that we can optimize any linear function over the polytope @xmath83 in polynomial time ( e.g. , @xmath84 is defined by polynomially many linear inequalities , or there exists a separation oracle for @xmath84 ) .",
    "thus , if we replace the integrality constraint ( [ ip : int ] ) with the relaxed constraint @xmath85^n$ ] ( which is redundant , since @xmath81^n$ ] ) , we will get a convex programming problem that can be solved in polynomial time ( see @xcite ) .",
    "however , as we have seen in the example of minimum power routing , the integrality gap of the relaxation can be as large as @xmath44 for @xmath86 .    in this work ,",
    "we introduce a linear programming relaxation of ( [ ip : obj])-([ip : int ] ) that has an integrality gap of @xmath3 for @xmath87 under certain assumptions on the polytope @xmath84 .",
    "we define auxiliary variables @xmath88 for all @xmath89 $ ] and @xmath90 $ ] . in the integral solution , @xmath91 if and only if @xmath92 for @xmath93 and @xmath94 for @xmath95 .",
    "@xmath96 } \\sum_{s\\subseteq [ n ] } f_j \\left ( \\sum_{i\\in s } d_{ij}\\right)z_{js } \\label{r : obj}\\ ] ] @xmath97}z_{js}&=1 , & \\forall j\\in [ k ] \\label{const1}\\\\ \\sum_{s : i\\in s}z_{js}&=y_i,&\\forall i\\in [ n ] , j\\in [ k ] \\label{const2}&{}\\\\ z_{js}&\\ge 0 , & \\forall s\\subseteq [ n ] , j\\in [ k ] \\label{r : rel3}\\end{aligned}\\ ] ]    in the integral solution , @xmath98 for all @xmath99 and @xmath100 . the reason why we introduced many copies of the same integral variable @xmath101 to the lp is that the lp above is easier to solve than the lp with an extra constraint @xmath98 .",
    "optimization problem ( [ r : obj])-([r : rel3 ] ) is a relaxation of the original problem ( [ ip : obj])-([ip : int ] ) .",
    "the lp has exponentially many variables .",
    "we show , however , that the optimal solution to this lp can be found in polynomial time up to an arbitrary accuracy @xmath102 .",
    "we shall assume that all @xmath103 are integral and polynomially bounded , or , more generally , that all @xmath103 are multiples of some @xmath104 and that @xmath105 are polynomially bounded in @xmath46 and @xmath106 .",
    "given an arbitrary instance of the problem , it is easy to round all @xmath103 s to multiples of a sufficiently small @xmath104 , so that the cost of any solution changes by at most @xmath102 assuming that functions @xmath77 satisfy some mild conditions . in section  [ sec : discr ]",
    "( theorem  [ thm : discr ] ) , we show how to pick @xmath104 for functions @xmath77 satisfying the following conditions :    1 .",
    "each @xmath77 is a convex increasing function ; 2 .   for each @xmath75 , @xmath107",
    "; 3 .   for each @xmath75 and @xmath108 $ ] , @xmath109 , where @xmath37 is some polynomial .",
    "note , that for @xmath110 , we have @xmath111",
    ". so functions @xmath112 satisfy the conditions of theorem  [ thm : discr ] if @xmath113 are polynomially bounded .",
    "[ thm : efficient ] suppose that there exists a polynomial time separation oracle for the polytope @xmath83 , @xmath114 is computable in polynomial time as a function of @xmath75 and @xmath45 , and all @xmath103 are multiples of @xmath104 such that @xmath105 are polynomially bounded in @xmath46 and @xmath106 .",
    "then , for every @xmath115 , there exists a polynomial time algorithm that finds a @xmath102-approximately optimal solution to lp ( [ r : obj])-([r : rel3 ] ) .    for a convex non - decreasing function @xmath116",
    "define @xmath117 as follows : @xmath118,\\ ] ] where @xmath18 is a poisson random variable with parameter 1 .",
    "note that @xmath119 = { \\mathbb{e}}[p^q ] = a_q.\\ ] ]    we prove the following theorem .",
    "[ thm : main ] let @xmath120 .",
    "assume that there exists a randomized algorithm @xmath121 that given a @xmath80 , returns a random integral point @xmath122 in @xmath123 such that    1 .",
    "@xmath124 for all @xmath27 ( where @xmath125 is the @xmath27-th coordinate of @xmath122 ) ; 2 .",
    "random variables @xmath126 are independent or negatively associated ( see section  [ sec : neg - depend ] for the definition ) for every @xmath75 .",
    "then , for every feasible solution @xmath127 to lp ( [ r : obj])-([r : rel3 ] ) , we have @xmath128 } f_j \\big(\\sum_{i\\in [ n ] } d_{ij } r_i(y^*)\\big ) \\big]\\leq \\sum_{j\\in [ k ] } a(f_j ) \\sum_{s\\subseteq [ n ] } f_j\\big ( \\sum_{i\\in s } d_{ij}\\big)z^*_{js},\\ ] ] where @xmath129 is defined as in ( [ eq : def - general - a ] ) .",
    "particularly , since lp ( [ r : obj])-([r : rel3 ] ) is a relaxation for ip ( [ ip : obj])-([ip : int ] ) , if @xmath127 is a @xmath102-approximately optimal solution to lp ( [ r : obj])-([r : rel3 ] ) , then @xmath130 } f_j \\big(\\sum_{i\\in [ n ] } d_{ij } r_i(y^*)\\big ) \\big]\\leq ( 1+\\varepsilon )",
    "\\max_j(a(f_j ) ) \\,ip,\\ ] ] where @xmath131 is the optimal cost of the boolean convex program ( [ ip : obj])-([ip : int ] ) .",
    "this theorem guarantees that an algorithm @xmath121 satisfying conditions ( 1 ) and ( 2 ) has an approximation ratio of @xmath132 for @xmath87 .    in the next section , section  [ sec : applications ] ,",
    "we show how to use the framework to obtain approximation algorithms for four different combinatorial optimization problems .",
    "then , in section  [ sec : thm : efficient ] , we give an efficient algorithm for solving lp ( [ r : obj])-([r : rel3 ] ) . in section  [ sec : thm : main ] , we prove the main theorem ",
    "theorem  [ thm : main ] .",
    "the proof easily follows from the decoupling inequality , which we prove in section  [ sec : thm : decoupling ] . finally , in section  [ sec : generalizations ]",
    ", we describe some generalizations of our framework .",
    "in this section , we show applications of our general technique .",
    "we start with the problem discussed in the introduction  energy efficient routing .",
    "recall , that andrews et al .",
    "@xcite gave an @xmath56-approximation algorithm for this problem where @xmath133 and @xmath134 ( theorem 8 in @xcite ) .",
    "we give an @xmath135-approximation algorithm for any fixed @xmath136 .",
    "we write a standard integer program . each variable",
    "@xmath137 indicates whether the edge @xmath34 is used to route the flow from @xmath38 to @xmath39 .",
    "below , @xmath138 denotes the set of edges outgoing from @xmath139 ; @xmath140 denotes the set of edges incoming to @xmath139 .",
    "@xmath141 @xmath142    using theorem  [ thm : efficient ] , we obtain an almost optimal fractional solution @xmath143 of lp relaxation ( [ r : obj])-([r : rel3 ] ) of ip ( [ energy_obj])-([eqn : r5 ] ) .",
    "we apply randomized rounding in order to select a path for each demand .",
    "specifically , for each demand @xmath144 , we consider the standard flow decomposition into paths : in the decomposition , each path @xmath37 connecting @xmath38 to @xmath39 has a weight @xmath145 .",
    "for every edge @xmath34 , @xmath146 ; and @xmath147 . for each @xmath27 ,",
    "the approximation algorithm picks one path @xmath37 connecting @xmath38 to @xmath39 at random with probability @xmath148 , and routes all demands from @xmath38 to @xmath30 via @xmath37 .",
    "thus , the algorithm always obtains a feasible solution .",
    "we verify that the integral solution corresponding to this combinatorial solution satisfies the conditions of theorem  [ thm : main ] .",
    "let @xmath149 be the integral solution , i.e. , let @xmath150 if the edge @xmath34 is chosen in the path connecting @xmath38 and @xmath39 .",
    "first , @xmath150 if the path connecting @xmath38 and @xmath39 contains @xmath34 , thus @xmath151 second , the paths for all demands are chosen independently .",
    "each @xmath149 depends only on paths that connect @xmath38 to @xmath39 .",
    "thus all random variables @xmath149 ( for a fixed @xmath34 ) are independent . therefore , by theorem  [ thm : main ] , the cost of the solution obtained by the algorithm is bounded by @xmath152 , where @xmath153 is the cost of the optimal solution to the integer program which is exactly equivalent to the minimum energy efficient routing problem",
    ".      we are given @xmath46 jobs and @xmath154 machines .",
    "the processing time of the job @xmath155 $ ] assigned to the machine @xmath156 $ ] is @xmath157 .",
    "the goal is to assign jobs to machines to minimize the @xmath158-norm of machines loads .",
    "formally , we partition the set of jobs into @xmath154 sets @xmath159 to minimize @xmath160 } ( \\sum_{j\\in s_i } p_{ij})^q\\right)^{1/q}$ ] .",
    "this is a classical scheduling problem which is used to model load balancing in practice } ( \\sum_{j\\in s_i } p_{ij})^q$ ] , can be used for energy efficient scheduling .",
    "imaging that we need to assign @xmath46 jobs to @xmath154 processors / cores so that all jobs are completed by a certain deadline @xmath161 .",
    "we can run processors at different speeds @xmath38 . to meet the deadlines we must set @xmath162 .",
    "the total power consumption is proportional to @xmath163 . for this problem",
    ", our algorithm gives @xmath164 approximation . ] .",
    "it was previously studied by azar and epstein  @xcite and by kumar , marathe , parthasarathy and srinivasan  @xcite .",
    "particular , for @xmath165 $ ] the best known approximation algorithm has performance guarantee @xmath62 @xcite ( theorem 4.4 ) .",
    "we give @xmath166{(1+\\varepsilon)a_q}$]-approximation algorithm for any @xmath136 substantially improving upon previous results ( see figure  [ fig : plot - results ] ) .",
    "we formulate the unrelated parallel machine scheduling problem as a boolean nonlinear program : @xmath167 } \\big(\\sum_{j\\in [ n ] } & p_{ij}x_{ij}\\big)^q & \\label{sch_obj}\\\\ \\sum_{i\\in [ m]}x_{ij}&=1 , & \\forall j\\in [ n ] \\label{sch_eqn : r2}\\\\",
    "x_{ij}&\\in \\{0,1\\ } , & \\forall i\\in [ m],\\ , j\\in [ n ] \\label{sch_eqn : r5}\\end{aligned}\\ ] ]    using theorem  [ thm : efficient ] , we obtain an almost optimal fractional solution @xmath168 of the lp relaxation ( [ r : obj])([r : rel3 ] ) corresponding to the ip ( [ sch_obj])([sch_eqn : r5 ] ) .",
    "we use the straightforward randomized rounding : we assign each job @xmath75 to machine @xmath27 with probability @xmath169 .",
    "we claim that , by theorem  [ thm : main ] , the expected cost of our integral solution is upper bounded by @xmath53 times the value of the fractional solution @xmath168 . indeed , the probability that we assign a job @xmath75 to machine @xmath27 is exactly equal to @xmath169 ; and we assign job @xmath75 to machine @xmath27 independently of other jobs .",
    "that implies that our approximation algorithm has a performance guarantee of @xmath166{(1+\\varepsilon)a_q}$ ] for the @xmath158-norm objective .",
    "as in the previous problem , in unrelated parallel machine scheduling with nonlinear functions of completion times , we are given @xmath46 jobs and @xmath154 machines .",
    "the processing time of the job @xmath155 $ ] assigned to the machine @xmath156 $ ] is @xmath157 . we need to assign jobs to machines and set their start times such that job processing intervals do not overlap .",
    "the goal is to minimize @xmath170 where @xmath171 is the completion time of job @xmath75 in the schedule and @xmath172 .",
    "using classical scheduling notation this problem can be denoted as @xmath173 .    the problem @xmath173 is well studied for @xmath174 .",
    "it is known to be apx - hard @xcite while the best known approximation algorithm has a performance guarantee of @xmath175 @xcite . for @xmath176",
    "even the single machine scheduling problem is not understood : it is an open problem whether @xmath177 is @xmath178-hard for @xmath179 , @xmath180 .",
    "bansal and pruhs  @xcite and stiller and wiese  @xcite gave constant factor approximation algorithms for more general functions of completion times for a single machine .",
    "however , there were no known approximation algorithms for multiple machines .",
    "we show how to use our framework for this problem in appendix  [ section : unrelatedparallel - tech ] .",
    "our algorithm gives @xmath181 approximation .",
    "we are given an undirected graph @xmath23 with edge weights @xmath182 .",
    "the goal is to find a spanning tree @xmath183 minimizing the objective function @xmath184 where @xmath185 is the set of edges in @xmath186 incident to the vertex @xmath187 . for @xmath188 ,",
    "a more general problem was considered before in the operations research literature @xcite under the name of adjacent only quadratic spanning tree problem . a related problem , known as degree bounded spanning tree , received a lot of attention in theoretical computer science @xcite .",
    "we are not aware of any previous work on degree balanced spanning tree problem .",
    "let @xmath35 be a boolean decision variable such that @xmath189 if we choose edge @xmath31 to be in our solution ( tree ) @xmath183 .",
    "we formulate our problem as the following convex boolean optimization problem @xmath190 where @xmath191 is the base polymatroid polytope of the graphic matroid in graph @xmath192 .",
    "we refer the reader to schrijver s book  @xcite for the definition of the matroid . using theorem  [ thm : efficient ]",
    ", we obtain an almost optimal fractional solution @xmath193 of lp relaxation ( [ r : obj])-([r : rel3 ] ) corresponding to the above integer problem .    following calinescu et al .",
    "@xcite , we define the continuous extension of the objective function ( [ tree : objective ] ) for any fractional solution @xmath194 @xmath195}f(s)\\prod_{e\\in s}x'_e\\prod_{e\\not\\in s}(1-x'_e),\\ ] ] i.e. @xmath196 is equal to the expected value of the objective function ( [ tree : objective ] ) for the set of edges sampled independently at random with probabilities @xmath197 . the function @xmath198 can be approximated with arbitrary polynomially small precision efficiently via sampling ( see @xcite ) . by theorem",
    "[ thm : main ] , we get the bound @xmath199 , where @xmath200 is the value of the lp relaxation ( [ r : obj])([r : rel3 ] ) on the fractional solution @xmath193 .",
    "the rounding phase of the algorithm implements the pipage rounding technique  @xcite adopted to polymatroid polytopes by calinescu et al .",
    "calinescu et al .",
    "@xcite showed that given a matroid @xmath201 and a fractional solution @xmath202 , one can efficiently find two elements , or two edges in our case , @xmath203 and @xmath204 such that the new fractional solution @xmath205 defined as @xmath206 , @xmath207 and @xmath208 for @xmath209 is feasible in the base polymatroid polytope for small positive and for small negative values of @xmath210 .",
    "they also showed that if the objective function @xmath211 is submodular then the function of one variable @xmath212 is convex . in our case ,",
    "the objective function @xmath211 is supermodular which follows from a more general folklore statement .",
    "the function @xmath213 is supermodular if @xmath214 for @xmath215 $ ] and @xmath216 is a convex function of one variable .",
    "therefore , the function @xmath212 is concave .",
    "hence , we can apply the pipage rounding directly : we start with the fractional solution @xmath193 . at every step ,",
    "we pick @xmath203 and @xmath204 ( using the algorithm from  @xcite ) and move to @xmath205 with @xmath217 or @xmath218 whichever minimizes the concave function @xmath212 on the interval @xmath219 $ ] .",
    "we stop when the current solution @xmath220 is integral .    at every step ,",
    "we decrease the number of fractional variables @xmath35 by at least 1 .",
    "thus , we terminate the algorithm in at most @xmath221 iterations .",
    "the value of the function @xmath222 never increases .",
    "so the cost of the final integral solution is at most the cost of the initial fractional solution @xmath193 , which , in turn , is at most @xmath223 .",
    "note , that we have not used any special properties of graphic matroids .",
    "the algorithm from  @xcite works for general matroids accessible through oracle calls .",
    "so we can apply our technique to more general problems where the objective is to minimize a function like  ( [ tree : objective ] ) subject to base matroid constraints .",
    "we now give an efficient algorithm for finding @xmath102 approximately optimal solution to lp ( [ r : obj])-([r : rel3 ] ) .",
    "observe that for every @xmath80 , there exists a @xmath224 such that the pair @xmath143 is a feasible solution to lp ( [ r : obj])-([r : rel3 ] ) .",
    "for example , one such @xmath224 is defined as @xmath225 . of course",
    ", this particular @xmath224 may be suboptimal .",
    "however , it turns out , as we show below , that for every @xmath226 , we can find the optimal @xmath224 efficiently .",
    "let us denote the minimal cost of the @xmath75-th term in ( [ r : obj ] ) for a given @xmath80 by @xmath227 .",
    "that is , @xmath227 is the cost of the following lp .",
    "the variables of the lp are @xmath88 .",
    "the parameters @xmath80 and @xmath90 $ ] are fixed .",
    "@xmath228 } f_j\\big ( \\sum_{i\\in s } d_{ij}\\big)z_{js } \\label{r - eff : obj}\\ ] ] @xmath229}z_{js}=1 & & \\label{const1-eff}\\\\ \\sum_{s : i\\in s}z_{js}=y_i , & & \\forall i\\in [ n]\\label{const2-eff}\\\\ z_{js}\\ge 0 , & & \\forall s\\subseteq [ n ] \\label{r - eff : rel3}\\end{aligned}\\ ] ] now , lp ( [ r : obj])-([r : rel3 ] ) can be equivalently rewritten as ( below @xmath226 is the variable ) .",
    "@xmath230 } h_j(y ) \\label{lp : eff : obj}\\\\ y\\in { \\cal p } & & \\label{lp : eff : poly}\\end{aligned}\\ ] ] the functions @xmath227 are convex and @xmath231 are the optimal solutions for vectors @xmath232 and @xmath233 , then @xmath234 is a feasible solution for @xmath235 .",
    "hence , @xmath236 .",
    "see section  [ sec : convexfj ] in appendix for details . ] . in lemma",
    "[ lem : find - z ] ( see below ) , we prove that lp  ( [ r - eff : obj])-([r - eff : rel3 ] ) can be solved in polynomial time , and thus the functions @xmath227 can be computed efficiently .",
    "the algorithm for finding @xmath227 also returns a subgradient of @xmath237 at @xmath226 .",
    "hence , the minimum of convex problem  ( [ lp : eff : obj])-([lp : eff : poly ] ) can be found using the ellipsoid method .",
    "once the optimal @xmath232 is found , we find @xmath238 by solving lp  ( [ r - eff : obj])-([r - eff : rel3 ] ) for @xmath232 and each @xmath90 $ ] .    [",
    "lem : find - z ] there exists a polynomial time algorithm for computing @xmath237 and finding a subgradient of @xmath237 .    we need to solve lp  ( [ r - eff : obj])-([r - eff : rel3 ] ) .",
    "recall that in section  [ sec : discr ] ( theorem  [ thm : discr ] ) we show how to choose @xmath239 such that each @xmath105 is an integer polynomially bounded . for simplicity",
    "we assume that @xmath240 ( the proof in general case is almost identical ) .",
    "therefore @xmath103 are integral in this case and polynomially bounded .",
    "we write the dual lp .",
    "we introduce a variable @xmath241 for constraint  ( [ const1-eff ] ) and variables @xmath242 for constraints  ( [ const2-eff ] ) .",
    "@xmath243\\label{dual : constr}\\end{aligned}\\ ] ] the lp has exponentially many constraints .",
    "however , finding a violated constraint is easy .",
    "to do so , we guess @xmath244 for the set @xmath245 violating the constraint . that is possible , since all @xmath103 are polynomially bounded , and so is @xmath246",
    ". then we solve the maximum knapsack problem @xmath247 } \\sum_{i\\in s}\\eta_{i}\\\\ \\sum_{i\\in s } d_{ij}=b^*\\end{aligned}\\ ] ] using the standard dynamic programming algorithm and obtain the optimal set @xmath245 .",
    "the knapsack problem is polynomially solvable , since @xmath246 is polynomially bounded . if @xmath248 , then constraint ( [ dual : constr ] ) is violated for the set @xmath245 ; otherwise all constraints ( [ dual : constr ] ) are satisfied .",
    "let @xmath249 be the optimal solution of the dual lp .",
    "the value of the function @xmath227 equals the objective value of the dual lp .",
    "a subgradient of @xmath237 at @xmath226 is given by the equation @xmath250 this is a subgradient of @xmath237 , since @xmath249 is a feasible solution of the dual lp for every @xmath251 ( note that constraint ( [ dual : constr ] ) does not depend on @xmath226 ) , and , hence , ( [ eq : subgrad ] ) is a lower bound on @xmath252 .",
    "in this section , we prove the main theorem  theorem  [ thm : main ] .",
    "the theorem easily follows from the de la pea decoupling inequality ( theorem  [ thm : decoupling ] and corollary  [ cor : neg - assoc ] ) for @xmath87 , and from the more general inequality presented in theorem  [ thm : cx - main ] ( see also corollary  [ cor : a - f - inequality ] ) for arbitrary convex functions @xmath77 . consider a feasible solution @xmath127 to ip ( [ ip : obj])-([ip : int ] ) .",
    "we prove inequality  ( [ eq : thm : main ] ) term by term .",
    "that is , for every @xmath75 we show that @xmath253\\leq a(f_j ) \\sum_{s\\subseteq [ n ] } f_j\\big ( \\sum_{i\\in s\\cap d_j } d_{ij}\\big)z^*_{js}.\\ ] ] recall that @xmath254 . above , we dropped terms with @xmath255 , since if @xmath255 , then @xmath256 .    fix a @xmath155 $ ] . define random variables @xmath7 for @xmath257 as follows : pick a random set @xmath89 $ ] with probability @xmath88 , and let @xmath258 if @xmath93 , and @xmath259 otherwise .",
    "note that random variables @xmath7 are dependent .",
    "we have @xmath260 it is easy to see that @xmath261 } y_i \\big)\\big ] = \\sum_{s\\subseteq [ n ] } f_j\\big ( \\sum_{i\\in s } d_{ij}\\big ) z_{js}.\\ ] ] the right hand side is simply the definition of the expectation on the left hand side .",
    "now , let @xmath262 for @xmath257 .",
    "note that by conditions of the theorem , @xmath263 ( by condition ( 1 ) ) .",
    "thus , each @xmath6 has the same distribution as @xmath7 .",
    "furthermore , @xmath6 s are independent or negatively associated ( by condition ( 2 ) ) .",
    "therefore , we can apply the decoupling inequality from theorem  [ thm : cx - main ] ( see corollary  [ cor : a - f - inequality ] ) @xmath264 \\leq a(f_j ) { \\mathbb{e}}\\big[f_j\\big(\\sum_{i \\in d_j } y_i\\big)\\big].\\ ] ] the left hand side of the inequality equals the left hand side of ( [ eq : thm : main : need - to - prove ] ) , the right hand side of the inequality equals the right hand side of ( [ eq : thm : main : need - to - prove ] ) .",
    "hence , inequality ( [ eq : thm : main : need - to - prove ] ) holds .",
    "in this section , we prove the decoupling inequality ( theorem  [ thm : decoupling ] ) with the optimal constant @xmath12 . in fact , we prove a more general inequality which works for arbitrary convex functions . to state the inequality we need the notion of _ convex stochastic order_.    we say that a random variable @xmath265 is less than @xmath266 in the convex ( stochastic ) order , and write @xmath267 if for every convex function @xmath268 , @xmath269 whenever both expectations exist .",
    "if @xmath267 and @xmath16 is a _ concave _ function , then @xmath270\\geq { \\mathbb{e}}[\\psi(y)]$ ] , since the function @xmath271 is convex , and therefore @xmath272\\leq -{\\mathbb{e}}[\\psi(y)]$ ] .",
    "it is easy to see that the convex stochastic order defines a partial order on all random variables .",
    "particularly , if @xmath267 and @xmath273 , then @xmath274 . note that the definition depends only on the distributions of @xmath265 and @xmath266 .",
    "that is , if @xmath265 has the same distribution as @xmath275 and @xmath267 , then @xmath276 .",
    "the random variables @xmath265 and @xmath266 may be defined on the same probability space or on different probability spaces .",
    "we refer the reader to the book of shaked and shanthikumar  @xcite for a detailed introduction to stochastic orders .",
    "we now state the general inequality in terms of the convex order .",
    "part ii of the theorem shows that the inequality is tight .",
    "[ thm : cx - main ] i. let @xmath63 be jointly distributed nonnegative ( non - independent ) random variables , and let @xmath64 be independent random variables such that each @xmath6 has the same distribution as @xmath7 .",
    "let @xmath18 be a poisson random variable with parameter 1 independent of @xmath7 s .",
    "then , @xmath277    \\ii . for every nonnegative function @xmath14 with a finite expectation",
    "@xmath278 $ ] and every positive @xmath210 , there exists @xmath46 and random variables @xmath279 , @xmath63 as in part i such that @xmath280}\\geq ( 1+\\varepsilon ) { { \\mathbb{e}}\\left[\\varphi\\big(p \\sum_{i=1}^n y_i \\big)\\right]}.\\ ] ]    theorem  [ thm : cx - main ] implies theorem  [ thm : decoupling ] , since the function @xmath281 is convex and thus @xmath282 } \\leq { { \\mathbb{e}}\\left[\\big(p\\cdot ( y_1+\\dots+y_n)\\big)^q\\right]}\\\\ & = { { \\mathbb{e}}\\left[p^q\\right]}\\cdot { { \\mathbb{e}}\\left[(y_1+\\dots+y_n)^q\\right ] } = a_q { { \\mathbb{e}}\\left[(y_1+\\dots+y_n)^q\\right]}\\\\ & = a_q\\|y_1+\\dots+y_n\\|_q^q.\\end{aligned}\\ ] ] part ii of theorem  [ thm : cx - main ] shows that we can not replace @xmath3 with a smaller constant .    another immediate corollary of theorem  [ thm : cx - main ] is as follows .",
    "[ cor : a - f - inequality ] for an arbitrary nonnegative convex function @xmath116 ,",
    "@xmath283 \\leq a(f ) { \\mathbb{e}}[f(y_1+\\dots+y_n)],\\ ] ] where @xmath117 is defined in ( [ eq : def - general - a ] ) .",
    "write , @xmath283 \\leq { \\mathbb{e}}\\big[f\\big(p \\cdot(y_1+\\dots+y_n)\\big)\\big ] = { \\mathbb{e}}{\\mathbb{e}}\\big[f\\big(p \\cdot(y_1+\\dots+y_n)\\big){\\,\\mid\\,}y_1+\\dots+y_n\\big].\\ ] ] for any @xmath284 , particularly for @xmath285 , we have @xmath286\\leq a(f ) f(t)$ ] , hence @xmath283 \\leq { \\mathbb{e}}[a(f ) f(y_1+\\dots+y_n ) ] = a(f ) { \\mathbb{e}}[f(y_1+\\dots+y_n)].\\ ] ]    we first prove part ii of theorem  [ thm : cx - main ] .",
    "consider the following example .",
    "let @xmath287 , be random variables taking value @xmath288 with probability @xmath47 , and @xmath289 with probability @xmath290 .",
    "we generate @xmath291 s as follows .",
    "we pick a random @xmath292 $ ] and let @xmath293 and @xmath294 for @xmath295 .",
    "random variables @xmath296 are i.i.d .",
    "bernoulli random variables with @xmath297=1/n$ ] . then",
    ", the sum @xmath298 always equals 1 , and @xmath299 } = { { \\mathbb{e}}\\left[\\varphi(p)\\right]}$ ] . as @xmath300",
    ", the sum @xmath301 converges in distribution to @xmath18 ( by the poisson limit theorem ) .",
    "thus ( see lemma  [ lem : limsup ] for details ) , @xmath302 } \\geq { { \\mathbb{e}}\\left[\\varphi(p)\\right]},\\ ] ] and , hence , for some @xmath46 inequality  ( [ eq : cx - counterexample ] ) holds .    before proceeding to the proof of part i , we state some known properties of the convex order .    [ lem : sumx - less - sumy ] suppose @xmath64 are independent random variables and @xmath63 are independent random variables . if @xmath303 for all @xmath27 , then @xmath304 .",
    "[ lem : sum - ax - less - ay ] consider random variables @xmath279 and @xmath266 . if @xmath305 for all @xmath27 , then @xmath306 , for any sequence of nonnegative numbers @xmath307 .    for completeness , we prove lemma  [ lem : sumx - less - sumy ] and lemma  [ lem : sum - ax - less - ay ] in appendix .",
    "to simplify the proof , we will use the following easy lemma .",
    "[ lem : simplify ] if for random variables @xmath265 and @xmath266 condition ( [ eq : def - cx ] ) is satisfied for all convex functions @xmath14 with @xmath308 , then @xmath267 .",
    "consider an arbitrary convex function @xmath14 .",
    "let @xmath309 .",
    "since @xmath310 , we have @xmath311 =   { \\mathbb{e}}[\\tilde{\\varphi}(x ) ] + \\varphi(0 ) \\leq   { \\mathbb{e}}[\\tilde{\\varphi}(y ) ] + \\varphi(0 ) = { \\mathbb{e}}[\\varphi(y)].\\ ] ]    first , we prove that a bernoulli random variable @xmath312 can be upper bounded in the convex order by a poisson random variable @xmath18 with @xmath313   = { \\mathbb{e}}[b]$ ] .",
    "[ lem : b - cx - p ] let @xmath18 be an integral random variable , and @xmath312 be a bernoulli random variable with parameter @xmath314 $ ] . then",
    ", @xmath315 .",
    "particularly , if @xmath18 is a poisson random variable with @xmath313={\\mathbb{e}}[b]$ ] , then @xmath315 .",
    "consider an arbitrary convex function @xmath316 with @xmath308 ( see lemma  [ lem : simplify ] ) .",
    "define linear function @xmath317 as @xmath318 .",
    "the graph of @xmath319 intersects the graph of @xmath14 at points @xmath320 and @xmath321 .",
    "since @xmath14 is convex , we have @xmath322 for @xmath323 . hence , for every integral @xmath74 , @xmath324 , and @xmath325 .",
    "consequently , @xmath326 } \\geq { { \\mathbb{e}}\\left[l(p)\\right ] } = l({{\\mathbb{e}}\\left[p\\right ] } ) = l({{\\mathbb{e}}\\left[b\\right ] } ) = \\varphi(1 ) { { \\mathbb{e}}\\left[b\\right ] } = { \\mathbb{e}}[\\varphi(b)].\\ ] ]    now we consider a very special case of theorem  [ thm : cx - main ] when all @xmath6 s and @xmath7 s are bernoulli random variables scaled by a factor @xmath327 , and all events @xmath328 are mutually exclusive .",
    "as we see later , the general case can be easily reduced to this special case .",
    "[ lem : main - cx - lemma ] consider bernoulli random variables @xmath329 such that @xmath330 , and all events @xmath331 are mutually exclusive .",
    "( that is , with probability 1 one and only one @xmath332 equals  1 . )",
    "let @xmath333 be independent bernoulli random variables such that @xmath334 .",
    "then , for all nonnegative numbers @xmath335 , we have @xmath336 where @xmath18 is a poisson random variable with parameter 1 independent of @xmath332 s .",
    "i. we prove the first inequality .",
    "consider an arbitrary convex function @xmath268 with @xmath337 .",
    "the function @xmath14 is superadditive i.e. , @xmath338 for all positive @xmath339 and @xmath340 ( since the derivative of @xmath14 is monotonically non - decreasing , and @xmath308 ) .",
    "hence , we have @xmath341 and @xmath342}\\geq { { \\mathbb{e}}\\left[\\sum_{i=1}^n b_i \\varphi(\\alpha_i)\\right ] } = \\sum_{i=1}^n\\pr(b_i = 1 ) \\varphi(\\alpha_i ) \\\\= \\sum_{i=1}^n\\pr(\\chi_i = 1 ) \\varphi(\\alpha_i ) = { { \\mathbb{e}}\\left[\\varphi\\big(\\sum_{i=1}^n \\alpha_i \\chi_i\\big)\\right]}.\\end{gathered}\\ ] ]    \\ii .",
    "we prove the second inequality . using lemma  [ lem : b - cx - p ] and lemma  [ lem : sumx - less - sumy ]",
    ", we replace bernoulli random variable @xmath333 with independent poisson random variables @xmath343 satisfying @xmath344 . the sum @xmath345 is distributed as a poisson random variable with parameter  1 . by coupling random variables @xmath346 and @xmath18 , we may assume that @xmath347 .",
    "consider an arbitrary convex function @xmath14 with @xmath337 .",
    "using convexity of the function @xmath14 , we derive @xmath348 } & = \\sum_{k=1}^{\\infty } { { \\mathbb{e}}\\left[\\varphi\\big(\\sum_{i=1}^n \\alpha_i p_i \\big ) { \\,\\mid\\,}p = k\\right]}\\pr(p   = k)\\\\ & = \\sum_{k=1}^{\\infty } { { \\mathbb{e}}\\left[\\varphi\\big(\\sum_{i=1}^n \\frac{p_i}{k } \\cdot \\alpha_i k \\big ) { \\,\\mid\\,}p = k\\right]}\\pr(p   = k)\\\\ & \\leq \\sum_{k=1}^{\\infty } { { \\mathbb{e}}\\left [ \\sum_{i=1}^n \\frac{p_i}{k } \\varphi(\\alpha_i",
    "k )   { \\,\\mid\\,}p = k\\right]}\\pr(p   = k)\\\\ & = \\sum_{k=1}^{\\infty } \\sum_{i=1}^n { { \\mathbb{e}}\\left[\\frac{p_i}{k}{\\,\\mid\\,}p = k\\right ] } \\varphi(\\alpha_i k)\\pr(p = k).\\end{aligned}\\ ] ]    we observe that @xmath349}= k\\,{{\\mathbb{e}}\\left[p_i\\right]}$ ] , which follows from the following well known fact ( see e.g. , feller  @xcite , section ix.9 , problem  6(b ) , p.  237 ) .",
    "[ fact : p12 ] suppose @xmath350 and @xmath351 are independent poisson random variables with parameters @xmath352 and @xmath353",
    ". then , for every @xmath354 , @xmath355 = \\frac{\\lambda_a}{\\lambda_a+\\lambda_b}\\;k$ ] .    in our case , @xmath356 , @xmath357 , @xmath358 .",
    "therefore , we have @xmath359 & \\leq \\sum_{k=1}^{\\infty } \\sum_{i=1}^n { \\mathbb{e}}\\big[\\frac{p_i}{k}{\\,\\mid\\,}p = k\\big ] \\varphi(\\alpha_i k)\\pr(p = k)\\\\ & = \\sum_{k=1}^{\\infty } \\sum_{i=1}^n { { \\mathbb{e}}\\left[p_i\\right ] } \\varphi(\\alpha_i k)\\pr(p = k)\\\\ & = \\sum_{i=1}^n { { \\mathbb{e}}\\left[\\chi_i\\right ] } \\sum_{k=1}^{\\infty } \\varphi(\\alpha_i k)\\pr(p = k)\\\\ & = \\sum_{i=1}^n { { \\mathbb{e}}\\left[\\chi_i\\right ] } { { \\mathbb{e}}\\left[\\varphi(\\alpha_i k)\\right]}\\\\ & = { \\mathbb{e}}\\big[\\varphi(p \\sum_{i=1}^n \\alpha_i \\chi_i)\\big].\\end{aligned}\\ ] ]    denote by @xmath360 the support of the random vector @xmath361 . each @xmath7 can be represented as follows @xmath362 where @xmath363 is the indicator of the event @xmath364 .",
    "here we assume that @xmath360 is finite .",
    "we treat the general case in appendix  [ sec : crv ] . applying lemma  [ lem : main - cx - lemma ] to the random variables",
    "@xmath363 , we get @xmath365 where @xmath366 are independent bernoulli random variables .",
    "each @xmath366 is distributed as the random variable @xmath363 ; that is , @xmath367 .",
    "since each @xmath6 has the same distribution as @xmath7 , we have @xmath368 by lemma  [ lem : sumx - less - sumy ] , we can sum up this inequality over all @xmath27 from @xmath288 to @xmath46 : @xmath369 we apply lemma  [ lem : sum - ax - less - ay ] to every sum in parentheses : @xmath370 again , using lemma  [ lem : sumx - less - sumy ] , we get @xmath371 finally , by lemma  [ lem : main - cx - lemma ] , @xmath372 this concludes the proof of theorem  [ thm : cx - main ] .",
    "the decoupling inequalities  ( [ eq : de - la - pena ] ) and  ( [ eq : cx - main ] ) can be extended to _ negatively associated _ random variables @xmath279 .",
    "the notion of negative association is defined as follows .",
    "random variables @xmath64 are negatively associated if for all disjoint sets @xmath373 $ ] and all non - decreasing functions @xmath374 and @xmath375 the following inequality holds : @xmath376 } \\leq { { \\mathbb{e}}\\left[f(x_i , i\\in i)\\right ] } \\cdot { { \\mathbb{e}}\\left[g(x_j , j\\in j)\\right]}.\\ ] ]    shao  @xcite showed that if @xmath279 are negatively associated random variables , and @xmath377 are independent random variables such that each @xmath378 is distributed as @xmath6 , then for every convex function @xmath268 , @xmath379 } \\leq { { \\mathbb{e}}\\left [ \\varphi ( x^*_1+\\dots+x^*_n)\\right]}.\\ ] ] in other words , @xmath380 ( see also theorem 3.a.39 in @xcite ) .    [ cor : neg - assoc ]",
    "let @xmath63 be jointly distributed nonnegative ( non - independent ) random variables , and let @xmath64 be negatively associated random variables such that each @xmath6 has the same distribution as @xmath7 .",
    "let @xmath18 be a poisson random variable with parameter 1 independent of the random variables @xmath7 .",
    "then , @xmath381 particularly , for every convex nonnegative @xmath116 , @xmath382 and for @xmath43 , @xmath383 where @xmath117 is defined in ( [ eq : def - general - a ] ) , and @xmath53 is the fractional bell number .",
    "we can extend our results to maximization problems with the objective function @xmath384 } f_j\\big(\\sum_{i\\in [ n ] } d_{ij } y_{i}\\big),\\label{eq : gener}\\ ] ] if @xmath77 s are arbitrary non - decreasing nonnegative _ concave _ functions defined on @xmath385 .",
    "the approximation ratio equals @xmath386 , where @xmath387.\\ ] ] it is not hard to see that @xmath388 for all @xmath116 . indeed , if @xmath389 , then @xmath390 , thus @xmath391 \\geq \\pr(p\\geq 1 ) = 1 - 1/e$ ] .",
    "this bound is tight if @xmath392 for @xmath389 .",
    "for example , @xmath393 for the function @xmath394 . note that the approximation ratio of @xmath395 for maximization problems of this form was previously known ( see calinescu et al .",
    "however , for some concave functions @xmath116 we get a better approximation .",
    "for example , for @xmath396 , we get an approximation ratio of @xmath397 .",
    "we would like to thank the anonymous referees for valuable comments .    2    alexander a. ageev and maxim sviridenko .",
    "pipage rounding : a new method of constructing algorithms with proven performance guarantee .",
    "8(3 ) : 307 - 328 , ( 2004 ) .",
    "s. albers .",
    "energy - efficient algorithms .",
    "acm 53(5 ) , 86 - 96 ( 2010 ) .",
    "matthew andrews , antonio fernandez anta , lisa zhang , wenbo zhao .",
    "routing for power minimization in the speed scaling model .",
    "ieee / acm trans .",
    "20(1 ) : 285 - 294 ( 2012 ) .",
    "matthew andrews , spyridon antonakopoulos , lisa zhang .",
    "minimum - cost network design with ( dis)economies of scale .",
    "focs 2010 , pp .  585 - 592 .",
    "a. assad and w. xu .",
    "the quadratic minimum spanning tree problem . naval research logistics v39 .",
    "( 1992 ) , pp .",
    "399 - 417 .",
    "yossi azar , amir epstein .",
    "convex programming for scheduling unrelated parallel machines .",
    "stoc 2005 , pp .",
    "331 - 337 .",
    "gruia calinescu , chandra chekuri , martin pal and jan vondrak . maximizing a submodular set function subject to a matroid constraint .",
    "siam journal on computing 40:6 ( 2011 ) , pp .",
    "1740 - 1766 .    v. chvatal . on certain polytopes associated with graphs .",
    "j. combinatorial theory ser .",
    "b , 18 ( 1975 ) , pp .",
    "138 - 154 .",
    "evripidis bampis , alexander kononov , dimitrios letsios , giorgio lucarelli and maxim sviridenko .",
    "energy efficient scheduling and routing via randomized rounding .",
    "fsttcs 2013 , pp .",
    "449 - 460 .",
    "nikhil bansal and kirk pruhs . the geometry of scheduling .",
    "focs 2010 , pp .  407 - 414 .    stephen boyd and lieven vandenberghe .",
    "convex optimization .",
    "cambridge university press , 2004 .",
    "c. durr and o. vasquez .",
    "order constraints for single machine scheduling with non - linear cost .",
    "the 16th workshop on algorithm engineering and experiments ( alenex ) , 2014 .",
    "m. grotschel , l. lovasz and a. schrijver .",
    "geometric algorithms and combinatorial optimization .",
    "springer - verlag , berlin , 1988 .",
    "w. feller .",
    "an introduction to probability theory and its applications ( 3rd edition ) .",
    "john wiley & sons , new york ( 1968 ) .",
    "d. r. fulkerson . blocking and anti - blocking pairs of polyhedra .",
    "programming , 1 ( 1971 ) , pp .",
    "168 - 194 .",
    "michel x. goemans .",
    "minimum bounded degree spanning trees .",
    "focs 2006 , 273 - 282 .",
    "w. hohn and t. jacobs .",
    "an experimental and analytical study of order constraints for single machine scheduling with quadratic cost .",
    "14th workshop on algorithm engineering and experiments ( alenex ) , pp .",
    "103 - 117 , siam , 2012 .",
    "w. hohn and t. jacobs . on the performance of smith s rule in single - machine scheduling with nonlinear cost .",
    "latin 2012 , pp .  482 - 493 .",
    "han hoogeveen , petra schuurman , gerhard j. woeginger .",
    "non - approximability results for scheduling problems with minsum criteria .",
    "informs journal on computing 13(2 ) , pp .",
    "157 - 168 ( 2001 ) .",
    "s. irani and k. pruhs .",
    "algorithmic problems in power management .",
    "acm sigact news 36 ( 2 ) , 63 - 76 .",
    "kumar joag - dev and frank proschan .",
    "negative association of random variables with applications .",
    "the annals of statistics 11 ( 1983 ) , no . 1 , 286 - 295 .    v. s. a. kumar , m. v. marathe , s. parthasarathy and a. srinivasan .",
    "a unified approach to scheduling on unrelated parallel machines .",
    "journal of the acm , vol .",
    "56 , 2009 .",
    "s. maia , e. goldbarg , and m. goldbarg .",
    "on the biobjective adjacent only quadratic spanning tree problem .",
    "electronic notes in discrete mathematics , 41 , ( 2013 ) , 535 - 542 .",
    "yurii nesterov and arkadi nemirovski .",
    "interior - point polynomial algorithms in convex programming .",
    "society for industrial and applied mathematics , 1987 .",
    "t. oncan and a. punnen .",
    "the quadratic minimum spanning tree problem : a lower bounding procedure and an efficient search algorithm .",
    "computers and operations research v.37 , ( 2010 ) , 1762 - 1773 .",
    "victor de la pea .",
    "bounds on the expectation of functions of martingales and sums of positive rvs in terms of norms of sums of independent random variables .",
    "proceedings of the american mathematical society 108.1 ( 1990 ) : 233 - 239 .",
    "victor de la pea and e. gin .",
    "decoupling : from dependence to independence .",
    "springer , 1999 .    victor de la pea , rustam ibragimov , shaturgan sharakhmetov .",
    "on extremal distributions and sharp @xmath398-bounds for sums of multilinear forms .",
    "the annals of probability , 2003 , vol .",
    "31 ( 2),pp .",
    "630675 .",
    "d. pereira , m. gendreau , a. cunha .",
    "stronger lower bounds for the quadratic minimum spanning tree problem with adjacency costs .",
    "electronic notes in discrete mathematics , 41 , ( 2013 ) , 229 - 236 .",
    "a. schrijver .",
    "theory of linear and integer programming .",
    "wiley , 1998 .",
    "a. schrijver .",
    "combinatorial optimization .",
    "springer , 2002 .",
    "moshe shaked and j. george shanthikumar .",
    "stochastic orders .",
    "springer , 2007 .",
    "qi - man shao . a comparison theorem on moment inequalities between negatively associated and independent random variables .",
    "journal of theoretical probability 13 , no . 2 ( 2000 )",
    ": 343 - 356 .",
    "andreas s. schulz and martin skutella .",
    "scheduling unrelated machines by randomized rounding .",
    "siam j. discrete math , 15(4 ) , pp .",
    "450 - 469 ( 2002 ) .",
    "mohit singh and lap chi lau .",
    "approximating minimum bounded degree spanning trees to within one of optimal .",
    "stoc 2007 : 661 - 670 .",
    "martin skutella .",
    "convex quadratic and semidefinite programming relaxations in scheduling .",
    "j. acm 48(2 ) , 206 - 242 ( 2001 ) .",
    "martin skutella .",
    "approximation and randomization in scheduling .",
    "technische universitat berlin , germany , 1998 .",
    "s. stiller and a. wiese .",
    "increasing speed scheduling and flow scheduling .",
    "isaac ( 2 ) 2010 , pp.279 - 290 .",
    "a. wierman , l. l. h. andrew , and a. tang . power - aware speed scaling in processor sharing systems .",
    "infocom 2009 , pp .  2007 - 2015 .",
    "in this section , we prove a corollary of theorem  [ thm : cx - main ] , which we will need in the next section .",
    "[ cor : decoupling ] let @xmath63 be jointly distributed ( non - independent ) nonnegative integral random variables , and let @xmath64 be independent bernoulli random variables taking values @xmath289 and @xmath288 such that for each @xmath27 , @xmath399 = { \\mathbb{e}}[y_i]$ ] .",
    "then , @xmath400 particularly , for every @xmath43 , @xmath383 where @xmath53 is the fractional bell number .    consider independent random variables @xmath378 such that each @xmath378 is distributed as @xmath7 . by lemma  [ lem : b - cx - p ] , @xmath401 for all @xmath27 .",
    "hence , by lemma  [ lem : sumx - less - sumy ] and theorem  [ thm : cx - main ] , @xmath402",
    "we consider the following linear programming relaxation of the scheduling problem @xmath173 .",
    "the variable @xmath403 if job @xmath75 starts at time @xmath45 on machine @xmath27 . for convenience",
    "we assume that @xmath404 for negative values of @xmath45 .",
    "@xmath167 } \\sum_{j\\in [ n]}\\sum_{t\\ge 0 } w_j(t+p_{ij})^p x_{ijt } \\label{obj_c}\\\\\\ \\sum_{i\\in [ m ] , t\\ge 0}x_{ijt}=1 & \\hspace{2 cm } \\forall j\\in [ n ] \\label{job_c}\\\\ \\sum_{j\\in [ n]}\\sum_{\\tau = t - p_{ij}+1}^tx_{ij\\tau}\\le 1 & \\hspace{2 cm } \\forall i\\in [ m ] , t\\ge 0 \\label{time_c}\\\\ x_{ijt}\\ge 0 & \\hspace{2 cm } \\forall i\\in [ m ] , j\\in [ n ] , t\\ge 0 . \\label{fr_c}\\end{aligned}\\ ] ]    the constraints ( [ job_c ] ) say that each job must be assigned , the constraint ( [ time_c ] ) says that at most one job can be processed in a unit time interval on each machine .",
    "such linear programming relaxation are known under the name of _ strong time indexed formulations_. the standard issue with such relaxations is that they have pseudo - polynomially many variables due to potentially large number of indices @xmath45 .",
    "one way to handle this issue is to partition the time interval into intervals @xmath405 $ ] and round all completion times to the endpoints of such intervals .",
    "this method leads to polynomially sized linear programming relaxations with @xmath406-loss in the performance guarantee ( see @xcite for detailed description of the method ) . from now on we ignore this issue and assume that the planning horizon upper bound @xmath407 is polynomially bounded in the input size .",
    "* algorithm . *",
    "our approximation algorithm solves linear programming relaxation ( [ obj_c])-([fr_c ] ) .",
    "let @xmath193 be the optimal fractional solution of the lp .",
    "each job is tentatively assigned to machine @xmath27 to start at time @xmath45 with probability @xmath408 , independently at random .",
    "let @xmath409 be the tentative start time assigned to job @xmath75 by our randomized procedure .",
    "we process jobs assigned to each machine in the order of the tentative completion times @xmath410",
    ".    * analysis .",
    "* we estimate the expected cost of the approximate solution returned by the algorithm .",
    "we denote the expected cost by @xmath411 . for each machine - job - tentative time",
    "triple @xmath412 , let @xmath413 be the set of triples @xmath414 such that @xmath415 .",
    "let @xmath416 be the random boolean variable such that @xmath417 if job @xmath75 is assigned to machine @xmath27 with tentative start time @xmath45 .",
    "in addition , let @xmath418 be the random boolean variable such that @xmath419 if job @xmath99 is assigned to machine @xmath27 with tentative start time @xmath420 for some @xmath421 by our randomized rounding procedure .",
    "then , @xmath422 suppose that job @xmath75 is tentative scheduled on machine @xmath27 at time @xmath45 i.e. , @xmath417 .",
    "we start processing job @xmath75 after all jobs @xmath99 tentative scheduled on machine @xmath27 at time @xmath420 with @xmath423 are finished .",
    "thus the weighted expected completion time to the power of @xmath37 for @xmath75 equals ( given @xmath417 ) @xmath424 } & = & { \\mathbb{e}}\\big [ \\big(\\sum_{j'\\in [ n]\\setminus \\{j\\ } } p_{i , j'}z^{ijt}_{j'}+p_{ij } \\big)^p { \\;\\;\\mid\\;\\;}x^{ijt}=1\\big]\\\\ & = & { \\mathbb{e}}\\big [ \\big(\\sum_{j'\\in [ n]\\setminus \\{j\\ } } p_{i , j'}z^{ijt}_{j'}+p_{ij } \\big)^p\\big].\\end{aligned}\\ ] ] in the second equality , we used that random variables @xmath418 are independent from the random variable @xmath416 .",
    "then , @xmath425 } \\sum_{i\\in [ m ] } \\sum_{t\\ge 0 } w_j{{\\mathbb{e}}\\left[w_j c_j^p{\\;\\;\\mid\\;\\;}x^{ijt } = 1\\right ] } \\pr\\big ( x^{ijt}=1\\big ) \\nonumber \\\\ & = & \\sum_{j\\in [ n ] } \\sum_{i\\in [ m ] } \\sum_{t\\ge 0 } w_j{\\mathbb{e}}\\big[\\big(\\sum _ { j'\\in [ n]\\setminus \\{j\\ } } p_{i , j'}z^{ijt}_{ij'}+p_{ij } \\big)^p \\big ] \\;x^*_{ijt}. \\label{unrelatedfirst}\\end{aligned}\\ ] ] note , that for fixed @xmath426 , j\\in [ n],t\\ge 0 $ ] random variables @xmath418 are independent from each other .",
    "we claim that @xmath427\\setminus \\{j\\ } } p_{i , j'}z^{ijt}_{j'}+p_{ij } \\big)^p \\big ] \\le a_p ( t+2p_{ij})^p.\\ ] ] combining ( [ unrelatedfirst ] ) and ( [ mainunrelated ] ) , we derive that the performance guarantee of our approximation algorithm is at most @xmath181 .",
    "we now prove inequality ( [ mainunrelated ] ) .",
    "let @xmath428 be the interval graph where the vertex set @xmath429 is the collection of intervals corresponding to triples in @xmath421 such that @xmath430 .",
    "more precisely , every triple @xmath421 corresponds to the interval @xmath431 with corresponding weight @xmath430 .",
    "let @xmath432 be the collection of all independent sets in @xmath428 .",
    "the interval graph @xmath428 is perfect , and the weights @xmath433 satisfy the constraints ( [ time_c ] ) , so there is a collection of weights @xmath434 , @xmath435 ( for more formal argument see below ) such that @xmath436    formally , the claim above follows from the polyhedral characterization of perfect graphs proved by fulkerson @xcite and chvatal @xcite ( see also schrijver s book @xcite , section 9 , application 9.2 on p. 118 ) that a graph @xmath192 is perfect if and only if its stable set polytope is defined by the system below : @xmath437 in the interval graph @xmath428 all clique inequalities are included in the constraints ( [ time_c ] ) and therefore any set of weights @xmath433 can be decomposed into a convex combination of independent sets in @xmath428 .",
    "we define a random variable @xmath438 as follows : sample an independent set @xmath435 with probability @xmath439 and let @xmath440 note that one job @xmath99 may have more than one interval @xmath441 in the set @xmath442 ( for different @xmath420 ) .",
    "random variables @xmath438 may be dependent but @xmath443=\\sum_{(i , j',t')\\in j_{ijt } } x^*_{ij't ' } = { \\mathbb{e}}[z_{j'}^{ijt}].\\ ] ] therefore , by corollary  [ cor : decoupling ] we have @xmath444\\setminus \\{j\\ } } p_{i , j'}z^{ijt}_{j'}+p_{ij } \\big)^p \\big ] \\le a_p{\\mathbb{e}}\\big[\\big(\\sum _ { j'\\in [ n]\\setminus \\{j\\ } } p_{i , j'}y^{ijt}_{j'}+p_{ij } \\big)^p \\big].\\ ] ] now , observe , that @xmath445\\setminus \\{j\\ } } p_{i , j'}y^{ijt}_{j'}$ ] is always bounded by @xmath446 , because all intervals in @xmath442 are disjoint ( @xmath442 is an independent set ) and all intervals are subsets of @xmath447 $ ] .",
    "hence , @xmath444\\setminus \\{j\\ } } p_{i , j'}z^{ijt}_{j'}+p_{ij } \\big)^p \\big ] \\le a_p { \\mathbb{e}}[((t + p_{ij } ) + p_{ij})^p ] \\leq a_p ( t+2p_{ij})^p,\\ ] ] which concludes the proof .",
    "we show that functions @xmath237 defined in section  [ sec : thm : efficient ] are convex .    [",
    "lem : f - convex ] fix real numbers @xmath13 and @xmath448 .",
    "define a function @xmath449^n \\to { \\mathbb{r}}^+$ ] as follows : @xmath450 equals the optimal value of the following lp : @xmath451 } \\big ( \\sum_{i\\in s } d_i\\big)^{q}&z_{s}&\\\\ \\sum_{s\\subseteq [ n]}z_{s}&=1&\\\\ \\sum_{s : i\\in s}z_{s}&=y_i,&\\forall i\\in [ n]\\\\ z_{s}&\\ge 0 , & \\forall s\\subseteq [ n]&\\end{aligned}\\ ] ] then , @xmath452 is a convex function .",
    "consider two vectors @xmath453^n$ ] .",
    "pick an arbitrary @xmath454 $ ] .",
    "we need to show that @xmath455 consider the optimal lp solutions @xmath238 and @xmath231 for @xmath232 and @xmath233 .",
    "then , by the definition of @xmath452 , @xmath456 } \\big ( \\sum_{i\\in s } d_i\\big)^{q } z^*_{s}\\;\\text { and } \\;h(y^ { * * } ) = \\sum_{s\\subseteq [ n ] } \\big ( \\sum_{i\\in s } d_i\\big)^{q } z^{**}_{s}.\\ ] ] observe , that @xmath234 is a feasible solution for @xmath235 ( since all lp constraints are linear ) .",
    "hence , @xmath457 is at most the lp cost of @xmath234 , which equals @xmath458 } \\big ( \\sum_{i\\in s } d_i\\big)^{q } ( \\lambda z^*_{s } + ( 1-\\lambda ) z^{**}_{s } ) = \\lambda h(y^ * ) + ( 1-\\lambda ) h(y^{**}).\\ ] ]",
    "in this section , we show how to discretize values @xmath103 .",
    "we assume that functions @xmath77 satisfy the following conditions :    1 .",
    "all @xmath77 are convex increasing nonnegative functions computable in polynomial time",
    ". 2 .   for every @xmath75 , @xmath107 .",
    "3 .   for every @xmath75 and @xmath459 $ ] , @xmath460 .",
    "we first find an approximate value of the optimal solution @xmath461 and then apply theorem  [ thm : discr ] ( see below ) . note that if the gap @xmath462 is polynomially bounded , then we can pick @xmath210 such that the optimal value @xmath463 of the discretized problem is at most @xmath464 .",
    "we pick such @xmath465 either by using the binary search or by enumerating all powers of 2 in the range @xmath466 $ ] .",
    "[ thm : discr ] there exists a polynomial - time algorithm that given an instance of the integer program ( [ ip : obj])-([ip : int ] ) satisfying conditions ( 1 ) and ( 2 ) above , an upper bound @xmath465 on the cost of the optimal solution @xmath153 , and @xmath115 , returns a new set of coefficients @xmath467 , numbers @xmath468 , and an extra set of constraints @xmath469 for @xmath470 such that each @xmath467 is a multiple of @xmath104 ; @xmath471 is an integer polynomially bounded in @xmath46 , @xmath106 and @xmath18 ( see item 3 above ) such that the following two properties are satisfied .    1",
    ".   the cost of the optimal solution for the new problem is at most the cost of the original problem : @xmath472 2 .   for every feasible solution of the new problem",
    "@xmath473 satisfying @xmath469 for @xmath470 , we have @xmath384 } f_j \\big(\\sum_{i\\in [ n ] } d_{ij } y_{i}\\big)\\leq ( 1+\\varepsilon ) \\sum_{j\\in [ k ] } f_j \\big(\\sum_{i\\in [ n ] } d'_{ij } y_{i}\\big ) + \\varepsilon \\widetilde{opt}.\\ ] ] particularly , @xmath474    the proof is fairly standard : we round all @xmath103 to be multiples of @xmath104 .",
    "then we show that if @xmath104 s are sufficiently small , then the introduced rounding error is at most @xmath475 .",
    "the details are below .",
    "we algorithm finds the set @xmath476 .",
    "if @xmath470 , then @xmath477 must be equal to @xmath289 in every optimal solution , because otherwise , @xmath478 .",
    "thus , for all @xmath470 , we set @xmath477 and all @xmath467 s to be @xmath289 .",
    "then , we let @xmath479 we round down all @xmath103 s to be multiples of @xmath104 . denote the rounded values by @xmath467 .",
    "this is our new instance .",
    "it is clear that @xmath467 are multiples of @xmath104 . since @xmath480 for all @xmath27 and @xmath75",
    ", we have @xmath481 and therefore , all @xmath471 are polynomially bounded .",
    "since @xmath482 and @xmath77 are monotone functions , we have for every @xmath226 , @xmath384 } f_j \\big(\\sum_{i\\in [ n ] } d'_{ij } y_{i}\\big ) \\leq \\sum_{j\\in [ k ] } f_j \\big(\\sum_{i\\in [ n ] } d_{ij } y_{i}\\big).\\ ] ] as we observed earlier if @xmath232 is the optimal solution to the original problem , then @xmath483 for @xmath470 , hence @xmath232 is a feasible solution to the new problem .",
    "consequently , @xmath472    we now need to verify that @xmath384 } f_j \\big(\\sum_{i\\in [ n ] } d_{ij } y_{i}\\big ) - \\sum_{j\\in [ k ] } f_j \\big(\\sum_{i\\in [ n ] } d'_{ij } y_{i}\\big ) \\leq \\varepsilon \\widetilde{opt } + \\varepsilon\\sum_{j\\in [ k ] } f_j \\big(\\sum_{i\\in [ n ] } d'_{ij } y_{i}\\big).\\ ] ] we prove that for every @xmath75 , @xmath484 } d_{ij } y_{i}\\big ) - f_j \\big(\\sum_{i\\in [ n ] } d'_{ij } y_{i}\\big ) \\leq \\frac{\\varepsilon}{k}\\ , \\widetilde{opt } + \\varepsilon f_j \\big(\\sum_{i\\in [ n ] } d'_{ij } y_{i}\\big).\\ ] ] consider two cases .",
    "i. if @xmath485 } d_{ij } y_{i } < \\varepsilon t_j / k$ ] , then @xmath486 } d_{ij } y_{i}\\big)\\leq \\varepsilon f_j(t_j)/k \\leq \\varepsilon \\widetilde{opt}/k,\\ ] ] since @xmath116 is a convex function , @xmath487 , and @xmath488 .",
    "hence , inequality ( [ eq : fj - diff ] ) holds .",
    "now assume that @xmath485 } d_{ij } y_{i}\\geq \\varepsilon t_j / k$ ] .",
    "observe , that @xmath489 } d_{ij } y_{i } - \\sum_{i\\in [ n ] } d'_{ij } y_{i}\\leq n\\delta_j = \\varepsilon \\eta t_j / k \\leq \\eta \\sum_{i\\in [ n ] } d_{ij } y_{i}.\\ ] ] hence ( using that @xmath490 $ ] and thus @xmath491 ) , @xmath489 } d_{ij } y_{i}\\leq \\frac{1}{1-\\eta } \\sum_{i\\in [ n ] } d'_{ij } y_{i } \\leq ( 1 + 2\\eta)\\sum_{i\\in [ n ] } d'_{ij } y_{i}.\\ ] ] we now use claim  [ cl : f - dir ] ( see below ) with @xmath492 } d'_{ij } y_{i};\\;\\;\\;\\text{and}\\;\\;\\;\\eta ' =   \\frac{\\sum_{i\\in [ n ] } d_{ij } y_{i}}{\\sum_{i\\in [ n ] } d'_{ij } y_{i } } - 1\\leq 2\\eta\\leq \\frac{\\varepsilon}{2p}.\\ ] ] we get @xmath486 } d_{ij } y_{i}\\big ) - f_j \\big(\\sum_{i\\in [ n ] } d'_{ij } y_{i}\\big ) \\leq \\varepsilon f_j \\big(\\sum_{i\\in",
    "[ n ] } d'_{ij } y_{i}\\big).\\ ] ] this finishes the proof .",
    "it only remains to prove claim  [ cl : f - dir ] .",
    "[ cl : f - dir ] suppose that @xmath116 is a nonnegative monotonically increasing function such that for every @xmath493 $ ] , @xmath494 .",
    "let @xmath495 $ ] and @xmath496 .",
    "then , for @xmath497 , @xmath498    write , @xmath499 thus , @xmath500 and ( since @xmath501 for @xmath502 $ ] ) @xmath503",
    "[ lem : limsup ] suppose that a sequence of integer random variables @xmath504 converges in distribution to an integer random variable @xmath275 . then",
    ", for every nonnegative function @xmath14 with a finite expectation @xmath505 $ ] , we have @xmath506\\geq { \\mathbb{e}}[\\varphi(z)].\\ ] ]    let @xmath507 for @xmath508 , and @xmath509 , otherwise .",
    "the function @xmath14 is nonzero on finitely many integral points .",
    "hence , @xmath510 = { \\mathbb{e}}[\\varphi_t(z)]$ ] for every fixed @xmath45 .",
    "observe that @xmath511\\geq { \\mathbb{e}}[\\varphi_t(s^n)]$ ] , since @xmath512 for all @xmath2 . on the other hand , @xmath513 = { \\mathbb{e}}[\\varphi(z)]$ ] .",
    "hence , @xmath514\\geq \\sup_{n } \\sup_{t } { \\mathbb{e}}[\\varphi_t(s^n ) ] =   \\sup_{t } \\sup_{n } { \\mathbb{e}}[\\varphi_t(s^n)]\\geq\\\\ \\sup_{t } \\lim_{n\\to\\infty } { \\mathbb{e}}[\\varphi_t(s^n ) ] = \\sup_t { \\mathbb{e}}[\\varphi_t(z)]={\\mathbb{e}}[\\varphi(z)].\\end{gathered}\\ ] ]",
    "for completeness , we give proofs of lemma  [ lem : sumx - less - sumy ] and lemma  [ lem : sum - ax - less - ay ] in this section .",
    "the reader may also find slightly different proofs of these lemmas in the book of shaked and shanthikumar  @xcite .",
    "[ lem : xyz ] consider three independent random variables @xmath265 , @xmath266 , and @xmath275 . if @xmath267 , then @xmath515 .    for every convex function @xmath268 , we have @xmath516 } = { \\mathbb{e}}{\\mathbb{e}}[\\varphi ( x+z){\\,\\mid\\,}z ] \\leq",
    "{ \\mathbb{e}}{\\mathbb{e}}[\\varphi ( y + z){\\,\\mid\\,}z ] = { { \\mathbb{e}}\\left[\\varphi ( y + z)\\right]}.\\ ] ] the inequality above holds , since for any fixed @xmath517 , the function @xmath518 is convex .    using lemma  [ lem : xyz ] , we replace @xmath6 s with @xmath7 s in the sum @xmath519 one by one : for every @xmath74 , let @xmath520 then , by lemma  [ lem : xyz ] , @xmath521 we have @xmath522 this finishes the proof .",
    "consider an arbitrary convex function @xmath14 .",
    "let @xmath523 and @xmath524 . since @xmath525 is a convex function , we have @xmath526 and @xmath527}\\leq { { \\mathbb{e}}\\left[\\tilde{\\varphi}(y)\\right]}$ ] .",
    "hence , @xmath528 } \\leq { { \\mathbb{e}}\\left[\\frac{1}{a}\\sum_{i=1}^n a_i \\tilde{\\varphi}(x_i)\\right ] } = \\frac{1}{a}\\sum_{i=1}^n a_i { { \\mathbb{e}}\\left[\\tilde{\\varphi}(x_i)\\right ] } { \\leq_{cx}}\\frac{1}{a}\\sum_{i=1}^n a_i { { \\mathbb{e}}\\left[\\tilde{\\varphi}(y)\\right ] } = { { \\mathbb{e}}\\left[\\tilde{\\varphi}(y)\\right]}.\\ ] ] substituting @xmath529 , we get @xmath530 } \\leq { { \\mathbb{e}}\\left[\\tilde{\\varphi}\\big(\\sum_{i=1}^n a_i y\\big)\\right]}.\\ ] ]",
    "in section  [ sec : thm : decoupling ] , we proved theorem  [ thm : cx - main ] for discrete random variables . in this section",
    ", we extend this result to arbitrary random variables .",
    "consider two sequences of nonnegative random variables @xmath64 and @xmath63 satisfying conditions of theorem  [ thm : cx - main ] .",
    "fix an arbitrary convex function @xmath316 .",
    "we need to show that @xmath531 \\leq { \\mathbb{e}}[\\varphi(p\\cdot ( y_1+\\dots + y_n))]\\ ] ] assuming that both expectations exist .",
    "observe that @xmath14 can be represented as the sum of two convex functions : a monotonically non - decreasing convex function @xmath532 and monotonically non - increasing convex function @xmath533 .",
    "it suffices to show that @xmath534 & \\leq { \\mathbb{e}}[{\\varphi^{\\text{\\tiny{$\\mathbf{\\uparrow}$}}}}(p\\cdot ( y_1+\\dots + y_n))];\\label{eq : crv - phiup}\\\\ { \\mathbb{e}}[{\\varphi^{\\text{\\tiny{$\\mathbf{\\downarrow}$}}}}(x_1+\\dots+x_n ) ] & \\leq { \\mathbb{e}}[{\\varphi^{\\text{\\tiny{$\\mathbf{\\downarrow}$}}}}(p\\cdot ( y_1+\\dots + y_n))].\\label{eq : crv - phidown}\\end{aligned}\\ ] ] note that if the expectations in ( [ eq : crv : phi ] ) exist than the expectations in ( [ eq : crv - phiup ] ) and ( [ eq : crv - phidown ] ) also exist .",
    "we now prove inequality  ( [ eq : crv - phiup ] ) .",
    "the proof of ( [ eq : crv - phidown ] ) is almost the same . for natural @xmath535 ,",
    "define a function @xmath536 as follows : @xmath537 the function @xmath536 truncates @xmath2 at the level @xmath535 and then rounds @xmath2 down to the nearest multiple of @xmath538 .",
    "observe , that @xmath539 for every @xmath2 .",
    "hence , @xmath540 converges a.s . to @xmath541 as @xmath542 ; and @xmath543 converges a.s . to @xmath544 as @xmath545 . since , @xmath532 is a continuous function @xmath546 and @xmath547 .",
    "notice that @xmath548 for all @xmath2 .",
    "hence , @xmath549 and @xmath550 . by lebesgue s dominated convergence theorem",
    ", we get @xmath551&={\\mathbb{e}}[{\\varphi^{\\text{\\tiny{$\\mathbf{\\uparrow}$}}}}(x_1+\\dots+x_n)];\\label{eq : coverg1}\\\\ \\lim_{m\\to \\infty } { \\mathbb{e}}[{\\varphi^{\\text{\\tiny{$\\mathbf{\\uparrow}$}}}}(p(g_{m}(y_1)+\\dots + g_{m}(y_n ) ) ) ] & =   { \\mathbb{e}}[{\\varphi^{\\text{\\tiny{$\\mathbf{\\uparrow}$}}}}(p(y_1+\\dots+y_n))].\\label{eq : coverg2}\\end{aligned}\\ ] ] for every fixed @xmath535 , the left hand side of ( [ eq : coverg1 ] ) is upper bounded by the left hand side of ( [ eq : coverg2 ] ) , because random variables @xmath552 and @xmath553 are discrete and satisfy the conditions of theorem  [ thm : cx - main ] .",
    "hence , the right hand side of ( [ eq : coverg1 ] ) is upper bounded by the right hand side of ( [ eq : coverg2 ] ) .",
    "this proves inequality  ( [ eq : crv - phiup ] ) and concludes the proof of theorem  [ thm : cx - main ] for arbitrary random variables ."
  ],
  "abstract_text": [
    "<S> we present a new framework for solving optimization problems with a diseconomy of scale . in such problems , </S>",
    "<S> our goal is to minimize the cost of resources used to perform a certain task . </S>",
    "<S> the cost of resources grows superlinearly , as @xmath0 , @xmath1 , with the amount @xmath2 of resources used . </S>",
    "<S> we define a novel linear programming relaxation for such problems , and then show that the integrality gap of the relaxation is @xmath3 , where @xmath3 is the @xmath4-th moment of the poisson random variable with parameter 1 . using our framework , we obtain approximation algorithms for the minimum energy efficient routing , minimum degree balanced spanning tree , load balancing on unrelated parallel machines , and unrelated parallel machine scheduling with nonlinear functions of completion times problems .    </S>",
    "<S> our analysis relies on the decoupling inequality for nonnegative random variables . </S>",
    "<S> the inequality states that @xmath5 where @xmath6 are independent nonnegative random variables , @xmath7 are possibly dependent nonnegative random variable , and each @xmath7 has the same distribution as @xmath6 . </S>",
    "<S> the inequality was proved by de la pea in 1990 . </S>",
    "<S> de la pea , ibragimov , and sharakhmetov showed that @xmath8 for @xmath9 and @xmath10 for @xmath11 . </S>",
    "<S> we show that the optimal constant is @xmath12 for any @xmath13 . </S>",
    "<S> we then prove a more general inequality : for every convex function @xmath14 , @xmath15 } \\leq { { \\mathbb{e}}\\left[\\varphi\\big(p\\sum_{i=1}^n y_i\\big)\\right]},\\ ] ] and , for every _ concave _ function @xmath16 , @xmath17 } \\geq { { \\mathbb{e}}\\left[\\psi\\big(p\\sum_{i=1}^n y_i\\big)\\right]},\\ ] ] where @xmath18 is a poisson random variable with parameter 1 independent of the random variables @xmath7 . </S>"
  ]
}