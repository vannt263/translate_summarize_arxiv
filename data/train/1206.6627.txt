{
  "article_text": [
    "for a biological sample , the dna copy number of a  genomic region is the number of copies of the dna in that region within the genome of the sample , relative to either a single control sample or a  pool of population reference samples .",
    "dna copy number variants ( cnvs ) are genomic regions where copy number differs among individuals .",
    "such variation in copy number constitutes a common type of population - level genetic polymorphism .",
    "see @xcite , @xcite , @xcite and @xcite for detailed discussions on cnv in the human population .    on another front",
    ", the genomes of tumor cells often undergo somatic structural mutations such as deletions and duplications that affect copy number .",
    "this results in copy number differences between tumor cells and normal cells within the same individual .",
    "these changes are often termed copy number aberrations or copy number alternations ( cna ) .",
    "there is significant scientific interest in finding cnvs in normal individuals and cnas in tumors , both of which entail locating the boundaries of the regions in the genome that have undergone copy number change ( i.e. , the breakpoints ) , and estimating the copy numbers within these regions . in this article",
    ", we use next - generation sequencing data for copy number estimation .",
    "microarrays have become a commonly used platform for high - throughput measurement of copy number .",
    "there are many computational methods that estimate copy number using the relative amount of dna hybridization to an array .",
    "see @xcite , @xcite and @xcite for a general review of existing methods for array - based data",
    ". however , the precision of breakpoint estimates with array - based technology is limited by its ability to measure genomic distances between probes , which currently averages about 1000 bases ( 1  kb ) on most arrays .",
    "hence , the lower limit in the length of detectable cnv events is about 1 kb . with sequencing capacity growing and its cost dropping dramatically , massively parallel sequencing is now an appealing method for measuring dna copy number . in these newer sequencing technologies",
    ", a large number of short reads ( 36100 bp ) are sequenced in parallel from the fragmentation of sample dna .",
    "then each read is mapped to a reference genome .",
    "the basic rationale is that _ coverage _ , defined as the number of reads mapped to a region of the reference genome , reflects the copy number of that region in the sample , but with many systematic biases and much variability across the genome .",
    "@xcite was one of the first to use genome - wide sequencing to detect cna events .",
    "the reader is also referred to @xcite for a review of recent studies in cnv / cna detection using sequencing data .",
    "more details of the data , with an illustrative example ( figure [ figillusreads ] ) , are given in section [ secdataexistingmethod ] .",
    "in the shift from array - based to sequencing - based copy number profiling , the main statistical challenge arises from the fundamental change in the type of data observed .",
    "array - based data are represented by a large but fixed number of continuous valued random variables that are approximately normal after appropriate preprocessing , and cnv / cna signals based on array data can be modeled as shifts in mean .",
    "sequencing - based data , as we will discuss further in section [ secdataexistingmethod ] , are realizations of point processes , where cnv / cna signals are represented by shifts in intensity of the process .",
    "while one can apply a normal approximation to the large number of discrete events in sequencing data , hence translating the problem into the familiar array - based setting , this approach is inefficient and imprecise .",
    "a more direct model of the point process is preferred .",
    "this type of data calls for a new statistical model , new test statistics , and , due to the quick growth of sequencing capacity , new and highly efficient computing implementation .    in copy number profiling it is important to assess the confidence in the estimated copy numbers . with the exception of @xcite ,",
    "existing segmentation methods , both for array data and for sequencing data , give a hard segmentation and do not quantify the uncertainty in their change - point estimates .",
    "some methods , such as @xcite and @xcite , provide confidence assessments for the called cnv or cna regions , in the form of false discovery rates or @xmath0-values , thus inherently casting the problem in a hypothesis testing framework .",
    "however , for the analysis of complex regions with nested changes , such as those in tumor data , confidence intervals on the copy number , from an estimation perspective , are often more useful .",
    "intuitively , the copy number estimate is less reliable for a region near a change point than for a region far away from any change points .",
    "also , copy number estimates are more reliable for regions with high coverage than for regions with low coverage , since coverage directly affects the number of observations used for estimation .",
    "this latter point makes confidence intervals particularly important for interpretation of results derived from short read sequencing data , where coverage can be highly uneven across the genome . in this paper",
    ", we take a bayesian approach with noninformative priors to compute point - wise confidence intervals , as described in section [ secbayesianci ] .",
    "the proposed methods are based on a simple and flexible inhomogeneous poisson process model for sequenced reads .",
    "we derive the score and generalized likelihood ratio statistics for this model to detect regions where the read intensity shifts in the target sample , as compared to a reference .",
    "we construct a modified bayes information criterion ( mbic ) to select the appropriate number of change points and propose bayesian point - wise confidence intervals as a way to assess the confidence in the copy number estimates . as a proof of concept ,",
    "we apply seqcbs , our sequencing - based cnv / cna detection algorithm , to a number of actual data sets and found it to have good concordance with array - based results .",
    "we also conduct a spike - in study and compare the proposed method to segseq , a method proposed by @xcite .",
    "the methods developed in this paper have been implemented in an open - source r - package , seqcbs , available from cran ` http://cran.r - project .",
    "org / web / packages / seqcbs / index.html ` .",
    "in a general next - generation genome sequencing / resequencing pipeline , shown in figure [ figseqpipe ] , the dna in the sample is randomly fragmented , and a short sequence of the ends of the fragments is `` read '' by the sequencer .",
    "after the bases in the reads are called , the reads are mapped to the reference genome .",
    "there are many different approaches to the preparation of the dna library prior to the sequencing step , some involving amplification by polymerase chain reaction , which lead to different distribution of reads along the reference genome .",
    "when a region of the genome is duplicated , fragments from this region have a higher representation , and thus its clones are more likely to be read by the sequencer .",
    "hence , when mapped to reference genome , this duplicated region has a higher read intensity .",
    "similarly , a deletion manifests as a decrease in read intensity . since reads are contiguous fixed length sequences , it suffices to keep track of the reference mapping location of one of the bases within the read .",
    "customarily , the reference mapping location of the 5@xmath1 end of the read is stored and reported .",
    "this yields a point process with the reference genome as the event space.=-1        as noted in previous studies , sequencing coverage is dependent on characteristics of the local dna sequence , and fluctuates even when there are no changes in copy number , as shown in @xcite . just as adjusting for probe - effects",
    "is important for interpretation of microarray data , adjusting for these baseline fluctuations in depth of coverage is important for sequencing data .",
    "the bottom panels of figure [ figseqarrayhcc1954 ] show the varying depth of coverage for chromosomes 8 and 11 in the sequencing of a normal human sample , hcc1954 .",
    "many factors cause the inhomogeneity of depth of coverage .",
    "for example , regions of the genome that contain more g / c bases are typically more difficult to fragment in an experiment .",
    "this results in lower depth of coverage in such regions . some regions of the genome are highly repetitive .",
    "it is challenging to map reads from repetitive regions correctly onto the reference genome and , hence , some of the reads are inevitably discarded as unmappable , resulting in loss of coverage in that region , even though no actual deletion has occurred .",
    "some ongoing efforts on the analysis of sequencing data involve modeling the effects of measurable quantities , such as gc content and mappability , on baseline depth .",
    "@xcite demonstrated that read counts in sequencing are highly dependent on gc content and mappability , and discussed a method to account for such systematic biases .",
    "@xcite investigated the relationship between gc content and read count on the illumina sequencing platform with a single position model , and identified a family of unimodal curves that describes the effect of gc content on read count .",
    "we take the approach of empirically controlling for the baseline fluctuations by comparing the sample of interest to a control sample that was prepared and sequenced by the same protocol . in the context of tumor cna detection ,",
    "the control is preferably a matched normal sample , for it eliminates the discovery of germline copy number variants and allows one to focus on somatic cna regions of the specific tumor genome .",
    "if a perfectly matched sample is not possible , a  carefully chosen control or a pool of controls , with sequencing performed on the same platform with the same experimental protocol , would work for our method as well since almost all of the normal human genome are identical .    as a simple and illustrative example of the data",
    ", we generated points according to a nonhomogeneous poisson process .",
    "figure [ figillusreads ] shows the point processes and the underlying @xmath2 function , defined as the probability that a read at genomic position  @xmath3 is from the case / tumor sample , conditional on the existence of a read at position  @xmath3 .",
    "the model is discussed in more detail in section [ secthemodel ] .",
    "the @xmath4-values for the points are jittered for graphical clarity .    .",
    "]    existing methods on cnv and cna detection with sequencing data generally follow the change - point paradigm , which is natural since copy number changes reflect actual breakpoints along chromosomes .",
    "@xcite proposed the algorithm segseq that segments the genomes of a tumor and a matched normal sample by using a sliding fixed size window , reducing the data to the ratio of read counts for each window .",
    "@xcite proposed cnv - seq that detects cnv regions between two individuals based on binning the read counts and then applying methods developed for array data .",
    "@xcite designed a method named event - wise testing ( ewt ) that detects cnv events using a fixed - window scan on the gc content adjusted read counts .",
    "@xcite proposed a method called cnaseg that uses read counts in windows of predefined size , and discovers cnv using a hidden markov model segmentation .",
    "as for single sample cnv detection method , @xcite constructed a computational algorithm that normalizes read counts by gc content and estimates the absolute copy number .",
    "these existing methods approach this statistical problem by binning or imposing fixed local windows .",
    "some methods utilize the log ratio of read counts in the bin or window as a test statistic , thereby reducing the data to the familiar representation of array - based cnv / cna detection , with @xcite being an exception in that it uses the difference in tumor - normal window read counts in their hmm segmentation .",
    "there are a number of downsides to the binning or local window approach .",
    "first , due to the inhomogeneity of reads , certain bins will receive much larger number of reads overall than other bins , and the optimal window size varies across the genome .",
    "if the number of reads in a bin is not large enough , the normal approximations that are employed in many of these methods break down .",
    "second , by binning or fixed - size window sliding , the estimated cnv / cna boundaries can be imprecise if the actual breakpoints are not close to the bin or window boundary .",
    "this problem can be somewhat mitigated by refining the boundary after the change point is called , as done in segseq . in this paper",
    ", we propose a unified model , one that detects the change points , estimates their locations , and assesses their uncertainties simultaneously .    to illustrate and evaluate our method , we apply it to real and spiked - in data based on a pair of nci-60 tumor / normal cell lines , hcc1954 and bl1954 .",
    "the data for these samples were produced and investigated by @xcite .",
    "the whole - genome shotgun sequencing was performed on the illumina platform and the reads are 36  bp long .",
    "after read and mapping quality exclusions , 7.72 million and 6.65 million reads were used for the tumor ( hcc1954 ) and normal ( bl1954 ) samples , respectively .",
    "newer sequencing platforms produce much more massive data sets .",
    "we start with a statistical model for the sequenced reads .",
    "let @xmath5 and @xmath6 be the number of reads whose first base maps to the left of base location @xmath3 of a given chromosome for the case and control samples , respectively .",
    "we can view these count processes as realizations of two nonhomogeneous poisson processes ( nhpp ) , one each for the case and control samples , @xmath7 \\\\[-8pt ] \\nonumber \\ { y_{t}\\ } & \\sim&\\operatorname{nhpp}(\\lambda_{t}).\\end{aligned}\\ ] ] the scale @xmath3 is in base pairs .",
    "the scenario where two or more reads are mapped to the same genomic position is allowed by letting @xmath8 and @xmath9 take values larger than  1 and assuming that the observed process is binned at the integers .",
    "we propose a change - point model on the conditional probability of an event at position @xmath3 being from @xmath10 , given that there is such an event from either @xmath10 or @xmath11 , namely , @xmath12    an example of data according to this model is shown in figure [ figillusreads ] .",
    "the change - point model assumption can be equivalently expressed as    @xmath13 where @xmath14 $ ] is piecewise constant with change points @xmath15 .",
    "of course , we require the collection of change points to lie within the observation window : @xmath16    this model does not force the overall intensity of case and control reads to be the same .",
    "the intensity function @xmath9 reflects the inhomogeneity of the control reads .",
    "one interpretation of the model is that , apart from constant shifts , the fluctuation of coverage in the case sample is the same as that in the control sample .",
    "this is reasonable if the case and control samples are prepared and sequenced by the same laboratory protocol and mapped by the same procedure , as we discussed in section [ secdataexistingmethod ] .",
    "the model would not be valid if the intensity functions for samples have significant differences caused by nonmatching protocols or experimental biases .",
    "let @xmath17 , @xmath18 be the event locations for processes @xmath10 and @xmath19 , respectively .",
    "that is , @xmath20 and @xmath21 are the mapped positions of the reads from the case and control samples .",
    "let @xmath22 be the total number of reads from the case and control samples combined .",
    "we combine the read positions from the case and control processes and keep them ordered in the genome position , obtaining combined read positions @xmath23 and indicators of whether each event is a realization of the case process or the control process @xmath24 : @xmath25 for any read @xmath26 in the combined process , we will sometimes use the term `` success '' to mean that @xmath27 , that is , that the read is from the case process .",
    "notice that the collection of change - point locations that can be inferred with the data is precisely @xmath28 , since we do not have data points to make inference in favor of or against any change points in between observations .",
    "this means that estimating the copy number between two genome positions is equivalent to doing so for the closest pair of reads that span the two genome positions of interest .",
    "namely , there is a one - to - one correspondence between the set of possible change points on @xmath29 and the set of change points @xmath30 defined on the indices @xmath31 through the following : @xmath32    the above statement can be made formal through the equivariance principle .",
    "consider the sample space @xmath33 $ ] of any change point , any monotonically increasing function @xmath34\\rightarrow[0,t]$ ] , and its natural vector extension @xmath35 .",
    "a change - point estimator @xmath36 is monotone transform equivariant if for all monotonically increasing functions @xmath34\\rightarrow[0,t ] $ ] , we have @xmath37    the following theorem shows that any breakpoint estimator @xmath38 satisfying the equivariance condition can be decomposed into a simpler form .    [ thmequivthm ] let @xmath39 , which takes values in @xmath40 , be an estimator of the breakpoints .",
    "then @xmath36 is monotone transform equivariant if and only if @xmath41 , where @xmath42 taking integer values @xmath43 does not depend on @xmath40 .    for ease of notation , we let @xmath44 be the natural extension of @xmath45 .",
    "suppose @xmath46 , where @xmath42 .",
    "note that  @xmath47 is invariant to all monotone transformations of the arrival times , hence so is @xmath48",
    ". therefore , @xmath49 .    in the other direction ,",
    "since @xmath50 and @xmath51 contain the same information as @xmath52 , we must have @xmath53 .",
    "suppose that @xmath54 depend on @xmath40 in a nontrivial way but @xmath36 satisfies the monotone transform equivariance condition .",
    "this means that there exist @xmath55 such that @xmath56 .",
    "but since  @xmath40 and @xmath57 are both increasing finite sequences on @xmath58 $ ] with the same number of elements , we must have some @xmath59 that @xmath60 .",
    "note that @xmath61 induces @xmath62 .",
    "however , @xmath63 .",
    "hence , the equivariance property holds if and only if @xmath48 is only a function of @xmath47 .",
    "theorem [ thmequivthm ] implies that any breakpoint estimation procedure , that is , monotone transform equivariant uses the estimator @xmath48 of integer breakpoints based on @xmath47 , and that the actual read position @xmath40 merely serves as a genomic scale lookup table .",
    "hence , we can define our change - point model on the indices @xmath31 for the read counts , and use the conditional likelihood which depends only on @xmath64 but not on the event positions @xmath65 : @xmath66    for the rest of this section , we will exclusively work with equation ( [ eqmodelspec , indexscale ] ) .",
    "the mapping positions @xmath67 will re - enter our analysis when we compute confidence intervals for the copy number estimates , in section [ secbayesianci ] .",
    "our statistical problem is hence two - fold .",
    "first , given @xmath68 , we need to estimate the change points @xmath69 .",
    "second , we need a method to select model complexity , as dictated by @xmath68 .",
    "we start by considering the following simplified problem : given a single interval spanning reads @xmath26 to @xmath70 in the combined process , we want to test whether the success probability inside this interval , @xmath71 , is different from the overall success probability , @xmath0 .",
    "the null model @xmath72 states that @xmath73 .",
    "we derive two statistics to test this hypothesis .",
    "the first is adopted from the conditional score statistic for a general exponential family model where the signal is represented by a kernel function , as discussed in @xcite , @xmath74 where @xmath75 .",
    "this statistic is simply the difference between the number of observed and expected case events under the null model .",
    "its variance at the null is @xmath76 and is used to standardize @xmath77 for comparison between regions of different sizes .",
    "the standardized score statistic @xmath78 is intuitive and simple , and would be approximately standard normal if @xmath79 were large .",
    "however , the normal approximation is not accurate if the number of reads that map to the region is low . to attain higher accuracy for regions with low read count ,",
    "observe that @xmath80 is a binomial random variable , and use an exact binomial generalized likelihood ratio ( glr ) statistic , @xmath81 where the null model with one overall success probability parameter @xmath0 is compared with the alternative model with one parameter @xmath71 for inside the @xmath82 $ ] interval and another parameter @xmath83 for outside the interval . from the binomial log - likelihood function one obtains @xmath84}\\biggl\\ { z_{k}\\log\\biggl(\\frac { \\hat{p}_{ij}}{\\hat{p}}\\biggr)+(1-z_{k})\\log\\biggl(\\frac { 1-\\hat{p}_{ij}}{1-\\hat{p}}\\biggr)\\biggr\\}\\\\ & & { } + \\sum_{k\\notin[i , j]}\\biggl\\ { z_{k}\\log\\biggl(\\frac{\\hat { p}_{0}}{\\hat{p}}\\biggr)+(1-z_{k})\\log\\biggl(\\frac{1-\\hat { p}_{0}}{1-\\hat{p}}\\biggr)\\biggr\\ } , \\label{eqbinomglr}\\end{aligned}\\ ] ] where @xmath85 , @xmath86 , @xmath87 are maximum likelihood estimates of success probabilities @xmath88}z_{k}/(j - i+1 ) , \\\\",
    "\\hat{p}_{0}&=&\\sum_{k\\notin[i , j]}z_{k}/(m - j+i-1).\\end{aligned}\\ ] ]    the glr and score statistics allow us to measure how distinct a specific interval @xmath82 $ ] is compared to the entire chromosome .",
    "for the more general problem in which @xmath89 is not given but only one such pair exists , we compute the statistic for all unique pairs of @xmath89 to find the most significantly distinct interval .",
    "this operation is @xmath90 and to improve efficiency , we have implemented a search - refinement scheme called iterative grid scan in our software .",
    "it works by identifying larger interesting intervals on a coarse grid and then iteratively improving the interval boundary estimates .",
    "the computational complexity is roughly @xmath91 and hence scales easily .",
    "a similar idea was studied in @xcite .    in the general model with multiple unknown change points",
    ", one could theoretically estimate all change points simultaneously by searching through all possible combinations of @xmath92 .",
    "but this is a combinatorial problem where even the best dynamic programming solution [ @xcite ; @xcite ; @xcite ] would not scale well for a data set containing millions of reads .",
    "thus , we adapted circular binary segmentation [ @xcite ; @xcite ] to our change - point model as a greedy alternative .",
    "in short , we find the most significant region @xmath89 over the entire chromosome , which divides the chromosome in to 3 regions ( or two , if one of the change points lies on the edge ) .",
    "then we further scan each of the regions , yielding a candidate subinterval in each region . at each step , we add the most significant change point(s ) over all of the regions to the collection of change - point calls .",
    "model complexity grows as we introduce more change points .",
    "this brings us to the issue of model selection : we need a method to choose an appropriate number of change points @xmath68 .",
    "@xcite proposed a solution to this problem for gaussian change - point models with shifts in mean . like the gaussian model",
    ", the poisson change - point model has irregularities that make classic measures such as the aic and the bic inappropriate .",
    "an extension of @xcite gives a modified bayes information criterion ( mbic ) for our model , derived as a large sample approximation to the bayes factor in the spirit of @xcite : @xmath93 where @xmath94 is the number of unique values in @xmath95 .",
    "the first term of mbic is the generalized log - likelihood ratio for the model with @xmath68 change points versus the null model with no change points . in our context",
    ", @xmath68 ideally reflects the number of biological breakpoints that yield the copy number variants .",
    "the remaining terms can be interpreted as a `` penalty '' for model complexity .",
    "these penalty terms differ from the penalty term in the classic bic of @xcite due to nondifferentiability of the likelihood function in the change - point parameters @xmath96 and also due to the fact that the range of values for @xmath69 grow with the number of observations @xmath97 . for more details on the interpretation of the terms in the mbic , see @xcite .",
    "finally , we report the segmentation with @xmath98 change points .",
    "as noted in the , it is particularly important for sequencing data to assess the uncertainty in the relative read intensity function at each genomic position .",
    "we approach this problem by constructing approximate bayesian confidence intervals .",
    "suppose @xmath24 are independent realizations of bernoulli random variables with success probabilities @xmath99 .",
    "consider first the one change - point model ( which can be seen as a local part of a multiple change - point model ) , where @xmath100 without loss of generality , we may take @xmath101 .",
    "assume a uniform prior for @xmath102 on this discrete set .",
    "let @xmath103 be the number of successes up to and including the @xmath3th realization , @xmath104    our goal is to construct confidence bands for @xmath105 at each @xmath106 .",
    "assume a @xmath107 prior for @xmath83 and @xmath108 .",
    "if we knew @xmath102 , then the posterior distribution of @xmath83 and @xmath108 is @xmath109 now , without knowing the actual @xmath110 , we compute the posterior distribution of @xmath105 as @xmath111 as before , the first part of the summation term is a beta distribution , @xmath112 and for the second term , we define the likelihood of the change point at @xmath26 as @xmath113 and observe that with the uniform prior on @xmath102 , @xmath114 where @xmath115 and @xmath116 and @xmath117 are with respect to the prior distributions of @xmath83 and @xmath108 . with @xmath118 priors on @xmath83 and @xmath108 , we can find the closed form expression of @xmath119 : @xmath120 \\\\[-8pt ] \\nonumber & = & \\frac{b(\\alpha+s _",
    "{ i},\\beta+ i - s _ { i})b(\\alpha + s_{m}-s _ { i},\\beta+m- i - s_{m}+s _ { i})}{b(\\alpha,\\beta ) ^{2}}\\\\ & = & \\frac{\\gamma(\\alpha+s _ { i})\\gamma(\\beta+",
    "i - s _ { i})}{\\gamma(\\alpha+\\beta+ i)}\\nonumber\\\\ & & { } \\times\\frac{\\gamma(\\alpha+s_{m}-s _ { i})\\gamma(\\beta+m- i - s_{m}+s _ { i})}{\\gamma(\\alpha+\\beta+m- i)}\\frac{\\gamma ( \\alpha+\\beta)^{2}}{\\gamma(\\alpha)^{2}\\gamma ( \\beta)^{2}}.\\nonumber\\end{aligned}\\ ] ] hence , we can compute , without knowing the actual value of @xmath102 , @xmath121    observe that the posterior distribution is a mixture of @xmath122 distributions . in theory , we could compute weights @xmath123 for all positions  @xmath26 and then numerically compute @xmath124 quantiles of the posterior beta mixture distribution to obtain the bayesian confidence intervals . however , in practice , one can approximate the sum in ( [ newlab ] ) by @xmath125,\\ ] ] for some small @xmath126 , hence ignoring the highly unlikely locations for the change points .",
    "empirically , we use @xmath127 .",
    "it is easy to see that the sequence of log likelihood ratios for alternative change points , @xmath128 , form random walks with negative drift as @xmath26 moves away from the true change point @xmath102 [ @xcite ] .",
    "the negative drift depends on the true @xmath129 , @xmath130 and is larger in absolute magnitude when the difference between @xmath83 and @xmath108 is larger . with @xmath102 unknown , since @xmath131 can be made arbitrarily close to 1 for @xmath132",
    ", one can make the same random walk construction for @xmath133 bounded away by @xmath134 from @xmath36 , as done in @xcite .",
    "this implies that , for any @xmath126 , one may find a constant @xmath135 such that for any  @xmath26 at least @xmath135 steps away from @xmath36 , @xmath136 with probability approaching  1 .",
    "hence , it is reasonable to use a small cutoff to produce a close approximation to the posterior distribution .",
    "the extension of this construction to multiple change points is straightforward .",
    "it entails augmenting the mixture components of one change point with that of its neighboring change points .",
    "this gives a computationally efficient way of approximating the bayesian confidence interval using , typically , a few hundred mixture components , which has been implemented in ` seqcbs ` .",
    "there is also an extensive body of literature on constructing confidence intervals and confidence sets for estimators of the change point @xmath102 .",
    "we refer interested readers to @xcite for discussion and efficiency comparison of various confidence sets in change - point problems .",
    "we first applied the proposed method to a matched pair of tumor and normal nci-60 cell lines , hcc1954 and bl1954 .",
    "@xcite conducted the sequencing of these samples using the illumina platform .",
    "for comparison with array - based copy number profiles on the same samples , we obtained array data on hcc1954 and bl1954 from the nci-60 database at http://www.sanger.ac.uk / genetics / cgp / nci60/. we applied the cbs algorithm [ @xcite , @xcite ] with modified bic stopping algorithm [ @xcite ] to estimate relative copy numbers based on the array data .    [ cols=\"^,^ \" , ]     figure [ figperfoverall ] summarizes the performance comparison at default settings for a number of spike - in signal lengths .",
    "the horizontal lines are mean recall and precision rates for the methods . we see that seqcbs , used with either the score test statistic or the glr statistic , offers significant improvement over the existing method in both precision and recall .",
    "the performances of the score and glr statistics are very similar , as their recall and precision curves almost overlap .",
    "the improvement in precision can be largely attributed to the fact that mbic provides a good estimate of model complexity , as can be seen in figure [ fig6](a ) .",
    "@ld1.3d1.3d1.3d1.3d1.3d1.3d1.3d1.3d1.3@ + length & 2.49 & 2.68 & 2.91 & 3.10 & 3.18 & 3.29 & 3.51 & 3.73 & 3.95 +   + segseq & + default & 0.066 & 0.146 & 0.394 & 0.514 & 0.464 & 0.476 & 0.502 & 0.438 & 0.424 + w250 & 0.23 & 0.422 & 0.67 & 0.662 & 0.59 & 0.654 & 0.64 & 0.564 &",
    "0.516 + w750 & & & 0.148 & 0.206 & 0.248 & 0.36 & 0.408 & 0.384 & 0.346 + a500 & & 0.148 & 0.394 & 0.514 & 0.464 & 0.476 & 0.502 & 0.438 & 0.424 + a2000 & & 0.146 & 0.394 & 0.514 & 0.464 & 0.476 & 0.502 & 0.438 & 0.424 + b25 & & 0.182 & 0.404 & 0.532 & 0.484 & 0.502 & 0.506 & 0.452 & 0.458 + b5 & & 0.126 & 0.382 & 0.476 & 0.432 & 0.442 & 0.476 & 0.428 & 0.364 + seqcbs & + scr - def & 0.49 & 0.714 & 0.95 & 0.988 & 0.95 & 0.936 & 0.968 & 0.878 & 0.782 + bin - def & 0.492 & 0.718 & 0.948 & 0.99 & 0.956 & 0.936 & 0.968 & 0.876 & 0.81 + scr - g5 & 0.496 & 0.71 & 0.922 & 0.99 & 0.956 & 0.956 & 0.978 & 0.922 & 0.844 + bin - g5 & 0.496 & 0.712 & 0.928 & 0.99 & 0.958 & 0.962 & 0.98 & 0.946 & 0.844 + scr - g15 & 0.494 & 0.708 & 0.926 & 0.974 & 0.942 & 0.938 & 0.968 & 0.89 & 0.736 + bin - g15 & 0.496 & 0.716 & 0.93 & 0.976 & 0.946 & 0.96 & 0.972 & 0.91 & 0.748 +   + segseq & + default & 0.049 & 0.105 & 0.235 & 0.305 & 0.284 & 0.263 & 0.276 & 0.237 & 0.255 + w250 & 0.174 & 0.317 & 0.490 & 0.472 & 0.467 & 0.478 & 0.442 & 0.405 &",
    "0.399 + w750 & & & 0.107 & 0.137 & 0.165 & 0.227 & 0.242 & 0.232 & 0.212 + a500 & & 0.097 & 0.235 & 0.305 & 0.284 & 0.263 & 0.276 & 0.237 & 0.255 + a2000 & & 0.101 & 0.235 & 0.305 & 0.284 & 0.263 & 0.276 & 0.237 & 0.255 + b25 & & 0.101 & 0.203 & 0.278 & 0.254 & 0.243 & 0.246 & 0.219 & 0.240 + b5 & & 0.104 & 0.278 & 0.361 & 0.323 & 0.308 & 0.327 & 0.295 & 0.271 + seqcbs & + scr - def & 0.980 & 0.997 & 0.985 & 0.988 & 0.985 & 0.944 & 0.968 & 0.878 & 0.839 + bin - def & 0.984 & 0.997 & 0.988 & 0.990 & 0.992 & 0.947 & 0.968 & 0.876 & 0.884 + scr - g5 & 0.984 & 0.997 & 0.956 & 0.990 & 0.992 & 0.980 & 0.994 & 0.945 & 0.942 + bin - g5 & 0.984 & 0.994 & 0.959 & 0.990 & 0.994 & 0.990 & 0.996 & 0.977 & 0.942 + scr - g15 & 0.980 & 0.994 & 0.953 & 0.944 & 0.961 & 0.949 & 0.964 & 0.876 & 0.710 + bin - g15 & 0.984 & 0.994 & 0.953 & 0.946 & 0.973 & 0.984 & 0.972 & 0.910 & 0.733 +    we studied the performance sensitivity on tuning parameters .",
    "segseq allows three tuning parameters : local window size ( w ) , number of false positive candidates for initialization ( a ) , and number of false positive segments for termination  ( b ) .",
    "the proposed method has a step size parameter ( g ) that controls the trade - off between speed and accuracy in our iterative grid scan component , and hence influences performance .",
    "we varied these parameters and recorded the performance measures in table [ tabperformancemeasures ] .",
    "it appears that local window size ( w ) is an important tuning parameter for segseq , and in scenarios with relatively short signal length , a smaller w@xmath137250 provides significant improvement in its performance .",
    "this echoes with our previous discussion that methods using a single fixed window size would perform less well when the signals are not of the corresponding length .",
    "some of the parameter combinations for segseq result in program running errors in some scenarios , and are marked as na .",
    "the step size parameter  ( g ) in seqcbs , in constrast , controls the rate at which coarse segment candidates are refined and the rate at which the program descends into searching smaller local change points , rather than defining a fixed window size .",
    "a smaller step size typically yields slightly better performance .",
    "however , the proposed method is not nearly as sensitive to its tuning parameters .",
    "we also conducted a timing experiment to provide the reader with a sense of the required computational resources to derive the solution .",
    "our proposed method compares favorably with segseq as seen in figure [ fig6](b ) .",
    "the glr statistic is slightly more complex to compute than the score statistic , as is reflected in the timing experiment .",
    "however , copy number profiling is inherently a highly parallelizable computing problem : one may distribute the task for each chromosome among a multi - cpu computing grid , hence dramatically reducing the amount of time required for this analysis .",
    "we proposed an approach based on nonhomogeneous poisson processes to directly model next - generation dna sequencing data , and formulated a change - point model to conduct copy number profiling . the model yields simple score and generalized likelihood ratio statistics , as well as a modified bayes information criterion for model selection .",
    "the proposed method has been applied to real sequencing data and its performance compares favorably to an existing method in a spike - in simulation study .",
    "statistical inference , in the form of confidence estimates , is very important for sequencing - based data , since , unlike arrays , the effective sample size ( i.e. , coverage ) for estimating copy number varies substantially across the genome . in this paper",
    ", we derived a procedure to compute bayesian confidence intervals on the estimated copy number .",
    "other types of inference , such as @xmath0-values or confidence intervals on the estimated change points , may also be useful .",
    "@xcite compares different types of confidence intervals on the change points , and the methods there can be directly applied to this problem .",
    "the reader is referred to @xcite and @xcite for existing methods on significance evaluation .",
    "some sequencing experiments produce paired end reads , where two short reads are performed on the two ends of a longer fragment of dna",
    ". the pairing information can be quite useful in the profiling of structural genomic changes .",
    "it will be important to extend the approach in this paper to handle this more complex data type .",
    "a limitation of the proposed method and the existing methods is that they do not handle allele - specific copy number variants .",
    "it is possible to extend our model to accommodate this need . with deep sequencing",
    ", one may assess whether each loci in a cnv is heterozygous , and estimate the degree to which each allele contributes to the gain or loss of copy number , by considering the number of reads covering the locus with the major allele versus those with the minor allele .",
    "this is particularly helpful for detecting deletion .",
    "furthermore , in the context of assessing the allele - specific copy number , existing snp arrays have the advantage that the assay targets specific sites for that problem , whereas to obtain sufficient evidence of allele - specific copy number variants with sequencing , a much greater coverage would be required since the overwhelming majority of reads would land in nonallelic genomic regions .",
    "spatial models that borrow information across adjacent variant sites , such as @xcite and @xcite , would be helpful for improving power .",
    "recently , there has been increased attention to the problem of simultaneous segmentation of multiple samples [ @xcite ; @xcite ; @xcite ; @xcite ] .",
    "one may also wish to extend this method to the multi - sample setting , where in addition to modeling challenges , one also needs to address more sources of systematic biases , such as batch effects and carry - over problems .",
    "computational challenges remain in this field . with sequencing capacity growing at record speed ,",
    "even basic operations on the data set are resource - consuming .",
    "it is pertinent to develop faster and more parallelizable solutions to the copy number profiling problem .",
    "we thank h.  p. ji , g. walther and d.  o. siegmund for their inputs ."
  ],
  "abstract_text": [
    "<S> we propose a flexible change - point model for inhomogeneous poisson processes , which arise naturally from next - generation dna sequencing , and derive score and generalized likelihood statistics for shifts in intensity functions . </S>",
    "<S> we construct a modified bayesian information criterion ( mbic ) to guide model selection , and point - wise approximate bayesian confidence intervals for assessing the confidence in the segmentation . </S>",
    "<S> the model is applied to dna copy number profiling with sequencing data and evaluated on simulated spike - in and real data sets .    . </S>"
  ]
}