{
  "article_text": [
    "coding techniques for storage systems have been used widely to protect data against errors or erasure for cds , dvds , blu - ray discs , and ssds .",
    "assume the data in a storage system is divided into packets of equal sizes .",
    "an @xmath1 block code takes @xmath2 information packets and encodes them into a total of @xmath3 packets of the same size . among coding schemes ,",
    "maximum distance separable ( mds ) codes offer maximal reliability for a given redundancy : any @xmath2 packets are sufficient to retrieve all the information .",
    "reed - solomon codes  @xcite are the most well known mds codes that are used widely in storage and communication applications .",
    "another class of mds codes are mds array codes , for example evenodd  @xcite and its extension @xcite , b - code @xcite , x - code @xcite , rdp @xcite , and star code @xcite . in an array code , each of the packets consists of a column of elements ( one or more binary bits ) , and the parities are computed by xoring some information bits .",
    "these codes have the advantage of low computational complexity over rs codes because the encoding and decoding only involve xor operations",
    ".    distributed storage systems involving storage nodes connected over networks have recently attracted a lot of attention .",
    "mds codes can be used for erasure protection in distributed storage systems where encoded information is stored in a distributed manner .",
    "if no more than @xmath4 storage nodes are lost , then all the information can still be recovered from the surviving packets .",
    "suppose one packet is erased , and instead of retrieving the entire @xmath2 packets of information , if we are only interested in repairing the lost packet , then what is smallest amount of transmission needed ( called the _ repair bandwidth _ ) ?",
    "if we transmit @xmath2 packets from the other nodes to the erased one , then by the mds property , we can certainly repair this node .",
    "but can we transmit less than @xmath2 packets ? more generally , if no more than @xmath4 nodes are erased , what is the repair bandwidth ?",
    "this _ repair problem _ was first raised in @xcite , and was further studied in several works ( e.g. @xcite-@xcite ) .",
    "a recent survey of this problem can be found in @xcite . in @xcite ,",
    "a cut - set lower bound for repair bandwidth is derived and in @xcite@xcite@xcite , this lower bound is matched for exact repair by code constructions for @xmath5 , @xmath6 and @xmath7 .",
    "all of these constructions however require large finite fields .",
    "very recently it was established that the cut - set bound of  @xcite is achievable for all values of @xmath2 and @xmath3 , @xcite@xcite .",
    "however , the proof is theoretical and is based on very large finite fields .",
    "hence , it does not provide the basis for constructing practical codes with small finite fields and high rate .    in this paper",
    "we take a different route : rather than trying to construct mds codes that are easily repairable , we try to find ways to repair existing codes and specifically focus on the families of mds array codes .",
    "a related and independent work can be found in @xcite , where single - disk recovery for rdp code was studied , and the recovery method and repair bandwidth is indeed similar to our result . besides , @xcite discussed balancing disk i / o reads in the recovery .",
    "our work discusses the recovery of single or double disk recovery for evenodd , x - code , star , and rdp code .",
    "if the whole data object stored has size @xmath8 bits , repairing a single erasure naively would require communicating ( and reading ) @xmath8 bits from surviving storage nodes .",
    "here we show that a single failed systematic node can be rebuilt after communicating only @xmath9 bits .",
    "note that the cut - set lower bound  @xcite scales like @xmath10 , so it remains open if the repair communication for evenodd codes can be further reduced .",
    "interestingly our repair scheme also requires significantly less disk i / o reads compared to naively reading the whole data object .",
    "the rest of this paper is organized as follows . in section [ def ]",
    ", we are going to define evenodd code and the repair problem .",
    "then the repair of one lost node is presented in section [ section evenodd ] for evenodd ( @xmath11 ) and in section [ section ex ] for the extended evenodd ( @xmath12 ) . in section",
    "[ section 2erase ] , we consider the case with two erased nodes and @xmath13 .",
    "at last , conclusion is made in section [ conclusion ] .",
    "an @xmath14 array code contains @xmath15 rows and @xmath3 columns ( or packets ) .",
    "each element in the array can be a single bit or a block of bits .",
    "we are going to call an element a _ block_. in an @xmath1 array code , @xmath2 information columns , or systematic columns , are encoded into @xmath3 columns .",
    "the _ total amount of information _ is @xmath16 blocks .",
    "an evenodd code @xcite is a binary mds array code that can correct up to 2 column erasures . for a prime number @xmath17",
    ", the code contains @xmath18 rows and @xmath19 columns , where the first @xmath20 columns are information and the last two are parity . and the information is @xmath21 blocks .",
    "we will write an evenodd code as : @xmath22 and we define an imaginary row @xmath23 , for all @xmath24 , where @xmath25 is a block of zeros .",
    "the _ slope 0 _ or _ horizontal parity _ is defined as @xmath26 for @xmath27 .",
    "the addition here is bit - by - bit xor for two blocks .",
    "a parity block of _ slope _ @xmath28 , @xmath29 and @xmath30 is defined as @xmath31 where @xmath32 and @xmath33 mod @xmath34 @xmath35 .",
    "sometimes we omit the `` @xmath36 '' notation . when @xmath37 , we call it the _ slope 1 _ , or _ diagonal parity_. in evenodd , parity columns are of slopes 0 and 1 .    a similar code is rdp @xcite , where @xmath18 , @xmath38 , and @xmath39 , for a prime number @xmath34 .",
    "the diagonal parity sums up both the corresponding information blocks and one horizontal parity block .",
    "another related code is x - code @xcite , where the parity blocks are of slope -1 and 1 , and are placed as two additional rows , instead of two parity columns .",
    "the code in @xcite extended evenodd to more than 2 columns of parity .",
    "this code has @xmath40 , @xmath20 , and @xmath18 .",
    "the information columns are the same as evenodd , but @xmath41 parity columns of slopes @xmath42 are used .",
    "it is shown in @xcite that such a code is mds when @xmath43 and conditions for a code to be mds are derived for @xmath44 .",
    "star code @xcite is an mds array code with @xmath45 , and the parity columns are of slope 0 , 1 , and -1 .",
    "a _ parity group _ @xmath46 of slope @xmath28 contains a parity block @xmath47 and the information blocks in the sum in equations ( [ eqn1 ] ) ( [ eq10 ] ) , @xmath48 .",
    "@xmath49 is considered as a single information block . if @xmath50 , it is a _ horizontal parity group _ , and if @xmath37 , we call it a _ diagonal parity group_.    by ( [ eqn1 ] ) , each horizontal parity group @xmath51 contains @xmath52 @xmath53 @xmath54 , for all @xmath55 .",
    "so we say @xmath51 _ crosses with _",
    "@xmath54 , for all @xmath55 .",
    "conversely , each diagonal parity group @xmath56 contains @xmath57 @xmath53 @xmath58 , for all @xmath55 .",
    "therefore , @xmath56 crosses with @xmath58 for all @xmath55 .",
    "the shared block of two parity groups is called the _ crossing_. generally , two parity groups @xmath46 and @xmath59 cross , for @xmath60 , @xmath61 .",
    "if they cross at @xmath62 , we call it a _ zero crossing_. a zero crossing does not really exist since the @xmath34-th row is imaginary .",
    "a zero crossing occurs if and only if @xmath63 moreover , each information block belongs to only one parity group of slope @xmath28 .    suppose the @xmath3 packets are stored in @xmath3 different nodes in a connected network .",
    "each storage node contains exactly one packet ( or one column ) .",
    "assume @xmath64 nodes are erased , @xmath65 .",
    "suppose we recover the nodes successively .",
    "for any specified erased node , how many blocks from the other storage nodes are needed to recover it ?",
    "we can either send data in a single block , or a linear combination of several blocks in one node , both of which are counted as one block of transmission .",
    "the total number of blocks transmitted to recover the specified node is called the _ repair bandwidth _ @xmath66 . the _ repair problem _ for distributed storage system asks what the smallest @xmath66 is , for fixed @xmath67 . in @xcite ,",
    "a cut - set lower bound is derived ( and is achieved only when each node transmits the same number of blocks ) : @xmath68    in this paper , we use mds array codes as distributed storage codes",
    ". we will give repair methods and compute the corresponding bandwidth @xmath66 .",
    "[ example1 ] consider the evenodd code with @xmath69 .",
    "set @xmath70 for all codewords , then the code will contain only 2 columns of information .",
    "the resulting code is a @xmath71 mds code and this is called _ shortened _ evenodd ( see figure [ fig1 ] ) .",
    "it can be verified that if any node is erased , then sending 1 block from each of the other nodes is sufficient to recover it . and",
    "this actually matches the bound ( [ eq3 ] ) .",
    "figure [ fig1 ] shows how to recover the first or the fourth column .",
    "notice that a sum block is sent in some cases .",
    "for instance , to recover the first column , the sum @xmath72 is sent from the fourth column .",
    "evenodd code if the first column ( top graph ) or the fourth column ( bottom graph ) is erased . in both cases , three blocks are transmitted.,scaledwidth=40.0% ]    in this paper , shortening of a code is not considered and we will focus on the recovery of systematic nodes , given that 1 or 2 systematic nodes are erased . and",
    "we send no linear combinations of data except the sum @xmath73 from the parity node of slope @xmath28 , for all @xmath28 defined in an array code .",
    "in addition , we assume that each node can transmit a different number of blocks .",
    "first , let us consider the repair problem of losing one systematic node , @xmath74 , and @xmath75",
    ". we will use evenodd to explain the repair method , and the recovery will be very similar if rdp or x - code is considered .    by the symmetry of the code , we assume that the first column is missing .",
    "each block in the first column must be recovered through either the horizontal or the diagonal parity group including this block .",
    "suppose we use @xmath76 horizontal parity groups and @xmath77 diagonal parity groups to recover the column , @xmath78 .",
    "these parity groups include all blocks of the first column exactly once .",
    "notice that @xmath79 , so we can send @xmath80 from the @xmath81-th node , and @xmath82 from the @xmath83-th node , and recover @xmath84 with 2 blocks of transmission . for the discussion",
    "below , assume @xmath84 is known .    for each horizontal parity group @xmath51",
    ", we send @xmath85 and @xmath86 , @xmath87 .",
    "so we need @xmath34 blocks . for each diagonal parity group @xmath56 ,",
    "as @xmath84 is known , we send @xmath88 and @xmath89 , @xmath90 , which is @xmath91 blocks in total .",
    "if two parity groups cross at one block , there is no need to send this block twice . as shown in section [ def ] ,",
    "any horizontal and any diagonal parity group cross at a block , and each block can be the crossing of two groups at most once .",
    "there are @xmath92 crossings .",
    "the total number of blocks sent is @xmath93 the equality holds when @xmath94 or @xmath95 , where @xmath76 is an integer .",
    "this result states that we only need to send about @xmath0 of the total amount of information . and the slopes of the @xmath3 chosen parity groups do not matter as long as half are horizontal and half are diagonal .",
    "moreover , similar repair bandwidth can be achieved using rdp or x - code . for rdp code",
    ", the repair bandwidth is @xmath96 which was also derived independently in @xcite . for x - code ,",
    "the repair bandwidth is at most @xmath97    the derivation for rdp is the following . for rdp code ,",
    "the first @xmath91 columns are information .",
    "the @xmath34-th column is the horizontal parity .",
    "the @xmath81-th column is the slope 1 diagonal parity ( including the @xmath34-th column ) .",
    "the diagonal starting at @xmath98 is not included in any diagonal parities .",
    "suppose the first column is erased .",
    "each horizontal or diagonal parity group will require @xmath91 blocks of transmission .",
    "every horizontal parity group crosses with every diagonal parity group .",
    "suppose @xmath99 horizontal parity groups and @xmath99 diagonal parity groups are transmitted .",
    "then the total transmission is @xmath100 this result is also derived independently in @xcite .",
    "the derivation for x - code is as follows . for x - code ,",
    "the @xmath101-th row is the parity of slope -1 , excluding the @xmath34-th row . and",
    "the @xmath34-th row is the parity of slope 1 , excluding the @xmath101-th row .",
    "suppose the first column is erased .",
    "first notice that for each parity group , @xmath102 blocks need to be transmitted . to recover the parity block @xmath103 ,",
    "one has to transmit the slope -1 parity group starting at @xmath103 . to recover the parity block @xmath104 , the slope 1 parity group starting at @xmath104 must be transmitted .",
    "but it should be noted that by the construction of x - code , this slope 1 parity group essentially is the diagonal starting at @xmath103 , except for the first element @xmath104 .",
    "zero crossings happen between two parity groups of slopes -1 and 1 , starting at @xmath105 and @xmath106 , if @xmath107 each slope 1 parity group has no more than 2 zero crossings with the slope -1 parity groups .",
    "suppose we choose arbitrarily @xmath99 slope 1 parity groups and @xmath108 slope -1 parity groups for the information blocks in the first column .",
    "then not considering the parity group containing @xmath104 , the number of slope 1 and slope -1 parity groups are both @xmath99 . excluding zero crossings , each slope 1 parity group crosses with at least @xmath109 slope -1 parity groups .",
    "the total transmission is @xmath110    also , equation ( [ eq4 ] ) is optimal in some conditions :    the transmission bandwidth in ( [ eq4 ] ) is optimal to recover a systematic node for evenodd if no linear combinations are sent except @xmath73 , for @xmath111 .    to recover a systematic node , say , the first node , parity blocks @xmath47",
    ", @xmath112 must be sent , where @xmath28 can be 0 or 1 for each @xmath113 .",
    "this is because @xmath105 is only included in @xmath85 or @xmath88 . besides",
    ", given @xmath47 , the whole parity group @xmath46 must be sent to recover the lost block .",
    "therefore , our strategy of choosing @xmath76 horizontal parity groups and @xmath77 diagonal parity groups has the most efficient transmission .",
    "finally , since ( [ eq4 ] ) is minimized over all possible @xmath76 , it is optimal .",
    "the lower bound by ( [ eq3 ] ) is @xmath114 where @xmath115 , @xmath19 , @xmath20 , and @xmath116 .",
    "it should be noted that ( [ eq3 ] ) assumes that each node sends the same number of blocks , but our method does not .",
    "consider the evenodd code with @xmath117 in figure [ fig : 5evenodd ] .",
    "for @xmath118 , the code has information blocks @xmath86 , @xmath119 , and parity blocks @xmath47 , @xmath111 .",
    "suppose the first column is lost .",
    "then by ( [ eq4 ] ) , we can choose parity groups @xmath120 .",
    "the blocks sent are : @xmath121 from the parity nodes and @xmath122 @xmath123 from the systematic nodes .",
    "altogether , we send 16 blocks , the number specified by ( [ eq4 ] ) .",
    "we can see that @xmath124 is the crossing of @xmath125 and @xmath126 .",
    "similarly , @xmath127 are crossings and are only sent once for two parity groups .    .",
    "the first column is erased , shown in the box .",
    "14 blocks are transmitted , shown by the blocks on the horizontal or diagonal lines . each line ( with wrap around )",
    "is a parity group .",
    "2 blocks in summation form , @xmath128 are also needed but are not shown in the graph.,scaledwidth=30.0% ]",
    "next we discuss the repair of array codes with @xmath41 columns of parity , @xmath129 .",
    "and we consider the recovery in the case of one missing systematic column . in this section",
    ", we are going to use the extended evenodd code @xcite , i.e. codes with parity columns of slopes @xmath42 .",
    "similar results can be derived for star code .",
    "suppose the first column is erased without loss of generality .",
    "let us first assume @xmath130 , so the parity columns have slopes @xmath131 .",
    "the repair strategy is : sending parity groups @xmath132 for @xmath133 and @xmath134 .",
    "let @xmath135 .",
    "notice that @xmath136 and each slope has no more than @xmath137 but no less than @xmath138 parity groups .",
    "since there are three different slopes , there are crossings between slope 0 and 1 , slope 1 and 2 , and slope 2 and 0 .",
    "for any two parity groups @xmath56 and @xmath139 , @xmath140 , so ( [ i+v ] ) does not hold .",
    "hence no zero crossing exists for the chosen parity groups .",
    "hence , every crossing corresponds to one block of saving in transmission .",
    "however , the total number of crossings is not equal to the sum of crossings between every two parity groups with different slopes .",
    "three parity groups with slopes 0 , 1 , and 2 may share a common block , which should be subtracted from the sum .",
    "notice that the parity group @xmath46 contains the block @xmath141 .",
    "the modulo function `` @xmath36 '' is omitted in the subscripts . for three transmitted parity groups",
    "@xmath142 , if there is a common block in column @xmath143 , then it is in row @xmath144 . to solve this , we get @xmath145 , or @xmath146 .",
    "notice @xmath147 , so @xmath148 .",
    "therefore , @xmath149 without modulo @xmath34 .",
    "thus @xmath150 must be an even number . for fixed @xmath3 , either @xmath151 , and there are no more than @xmath152 solutions for @xmath153 ; or @xmath154 , and the number of @xmath153 is no more than @xmath155 .",
    "hence , the number of @xmath156 is no more than @xmath157 .",
    "the total number of blocks in the @xmath91 chosen parity groups is less than @xmath158 .",
    "there are no less than @xmath159 parity groups of slope @xmath28 , for all @xmath160 , therefore for @xmath161 , parity groups with slopes @xmath162 and @xmath28 have no less than @xmath163 crossings .",
    "hence the total number of blocks sent in order to recover one column is : @xmath164 where @xmath165 .",
    "the above estimation is an upper bound because there may be better ways to assign the slopes of each parity group .",
    "thus , we need to send no more than @xmath166 blocks if @xmath130 .    by abuse of notation , we write @xmath167 as the set of blocks ( including the imaginary @xmath34-th row ) in the parity group except @xmath49 and @xmath168 .",
    "let @xmath169 , @xmath170 , be disjoint sets such that @xmath171 .",
    "let @xmath172 . for given @xmath173 ,",
    "define a function @xmath174 as @xmath175 , for @xmath176 , and @xmath177 .",
    "then we have the following theorem :    for the extended evenodd with @xmath129 , the repair bandwidth for one erased systematic node is @xmath178    suppose the first column is missing and we transmit the parity groups @xmath179 , @xmath180 for @xmath181 .",
    "since the union of @xmath173 covers @xmath182 , all the blocks in the first column can be recovered .",
    "the repair bandwidth is the cardinality of the union of @xmath183 plus the number of zero crossings and the summation blocks @xmath184 .",
    "the number of zero crossings is no more than the size of the imaginary row , @xmath34 .",
    "the number of the summation blocks is @xmath41 .    by inclusion ",
    "exclusion principle , the cardinality of the union of @xmath183 is @xmath185    every @xmath186 , so @xmath187 .",
    "every two parity groups @xmath188 cross at a block .",
    "hence @xmath189 .",
    "since @xmath179 contains @xmath190 , @xmath191 , the intersection of more than two parity groups @xmath192 is equivalent to the solutions of @xmath193 where @xmath143 is the column index of the intersection . or , @xmath194 therefore , @xmath195 and ( [ eq7 ] ) follows .",
    "we can see that ( [ eq15 ] ) is a special case of ( [ eq7 ] ) , with @xmath196 , for @xmath133 . for @xmath197",
    ", we can derive similar bounds by defining @xmath198 .    choose @xmath199 for @xmath181 .",
    "let @xmath200 . and for @xmath201",
    ", @xmath202 becomes the number of @xmath203 , @xmath204 , such that @xmath205 since @xmath206 , and @xmath207 , the above equation becomes @xmath208 without modulo @xmath34 .",
    "therefore , @xmath209 where @xmath210 is an integer constant , lcm is the least common multiplier and gcd is the greatest common divisor . and for fixed @xmath211 , the number of solutions for @xmath212 is no more than @xmath213 , when @xmath214 ; and no more than @xmath215 , when @xmath216 .",
    "the number of @xmath203 is @xmath217    similarly , for four parity groups , @xmath218 for five parity groups , @xmath219    when @xmath220 , equation ( [ eq7 ] ) becomes @xmath221 by the previous equations , @xmath222 @xmath223 @xmath224 and the repair bandwidth is @xmath225 where the terms of lower orders are omitted .",
    "when @xmath226 , we can use ( [ eq7 ] ) again and get @xmath227 where the terms of lower orders are omitted .",
    "it should be noted that the number of common blocks affects the bandwidth a lot .",
    "if we consider only the first 4 terms in ( [ eq7 ] ) , any assignment of @xmath198 with equal sizes will result in a lower bound of @xmath228 , when @xmath41 is large .",
    "but due to the common blocks , the true @xmath66 values for @xmath197 using ( [ eq16 ] ) has only slight improvement compared to the case of @xmath130 .",
    "the lower bound ( [ eq3 ] ) is @xmath229 . when @xmath130 , this bound is about @xmath230 .",
    "up to now , we have considered the recovery problem given that one column is erased .",
    "next , let us assume that two information columns are erased and we need to recover them successively .",
    "so we first recover one of the erased nodes , and then the other one . the first recovery is discussed in this section , and the second recovery was already discussed in the previous sections .",
    "suppose we have 3 columns of parity with slopes -1 , 0 , and 1 , which is in fact the star code in @xcite .",
    "again , the arguments can be applied to extended evenodd in a similar way . without loss of generality , assume the first and @xmath231-th columns are missing , @xmath232 .",
    "let @xmath51,@xmath56 , and @xmath233 be @xmath113-th parity group of slopes 0 , 1 , and -1 , respectively , @xmath48 .",
    "the following are @xmath234 parity groups that repair the first column : @xmath235 . for each parity block",
    "above , the corresponding recovered blocks are : @xmath236 .",
    "an example of @xmath237 is shown in figure [ fig : star ] .",
    "rearrange the columns in the following order : columns @xmath238 ( every index is computed modulo @xmath34 ) .",
    "we can see that the chosen parity groups @xmath239 , @xmath240 contain the blocks in rows @xmath241 .",
    "@xmath242 contains blocks @xmath243 , for @xmath244 .",
    "and similarly @xmath245 contains blocks @xmath246 , for @xmath247 .",
    "now notice that the blocks included in the above parity groups have the @xmath248-th column as the vertical symmetry axis .",
    "that is , the row indices of the blocks needed in columns @xmath249 and @xmath250 are the same ; those of columns @xmath251 and @xmath252 are the same ; ... ; those of columns @xmath253 and @xmath254 are the same . for example , the second column in figure [ fig : star ] is the symmetry axis .",
    "thus , we only need to consider columns @xmath255 .    for columns",
    "@xmath256 , where @xmath113 is even and @xmath257 , parity groups @xmath258 include the blocks in rows @xmath259 . and",
    "parity groups @xmath260 include the blocks in rows @xmath261 .",
    "since @xmath257 , we have @xmath262 , and @xmath263 .",
    "hence @xmath264 .",
    "thus every block in column @xmath256 needs to be sent , for even @xmath113 .",
    "similarly , for columns @xmath256 , where @xmath113 is odd and @xmath265 , parity groups @xmath258 include the blocks in rows @xmath266 .",
    "parity groups @xmath260 include the blocks in rows @xmath267 . since @xmath257 , we have @xmath268 , and @xmath269 .",
    "therefore , the rows not included in @xmath270 or @xmath271 or @xmath272 are @xmath273 and @xmath274 .",
    "the total saving in block transmissions for all the columns is : @xmath275    the above argument can be summarized in the following theorem .    when two systematic nodes are erased in a star code , there exist a strategy that transmit about @xmath276 of all the information blocks , and about @xmath277 of all the parity blocks so as to recover one node .",
    "the repair bandwidth @xmath66 in the above theorem is about @xmath278 .",
    "comparing it to the lower bound ( [ eq3 ] ) , @xmath279 , we see a gap of @xmath280 in total transmission .    , @xmath281.,scaledwidth=20.0% ]",
    "we presented an efficient way to repair one lost node in evenodd codes and two lost nodes in star codes .",
    "our achievable schemes outperform the naive method of rebuilding by reconstructing all the data . for evenodd codes ,",
    "a bandwidth of roughly @xmath282 is sufficient to repair an erased systematic node .",
    "moreover , if no linear combinations of bits are transmitted , the proposed repair method has optimal repair bandwidth with the sole exception of the sum of the parity nodes .",
    "since array codes only operate on binary symbols , and our repair method involves no linear combination of content within a node except in the parity nodes , the proposed construction is computationally simple and also requires smaller disk i / o to read data during repairs .",
    "there are several open problems on using array codes for distributed storage . although our scheme does not achieve the information theoretic cut - set bound , it is not clear if that bound is achievable for fixed code structures or limited field sizes .",
    "if we allow linear combinations of bits within each node , the optimal repair remains unknown .",
    "our simulations indicate that shortening of evenodd ( using less than @xmath34 columns of information ) further reduces the repair bandwidth but proper shortening rules and repair methods need to be developed .",
    "repairing other families of array codes or reed - solomon codes would also be of substantial practical interest .",
    "p.  corbett , b.  english , a.  goel , t.  grcanac , s.  kleiman , j.  leong , and s.  sankar .",
    "row - diagonal parity for double disk failure correction . in _ proc . of the 3rd usenix symposium on file and storage technologies ( fast 04 ) _ , pages 114 , 2004 .",
    "v.  r. cadambe , s.  a. jafar , and h.  maleki .",
    "distributed data storage with minimum storage regenerating codes - exact and functional repair are asymptotically equally efficient ."
  ],
  "abstract_text": [
    "<S> in distributed storage systems that use coding , the issue of minimizing the communication required to rebuild a storage node after a failure arises . </S>",
    "<S> we consider the problem of repairing an erased node in a distributed storage system that uses an evenodd code . </S>",
    "<S> evenodd codes are maximum distance separable ( mds ) array codes that are used to protect against erasures , and only require xor operations for encoding and decoding . we show that when there are two redundancy nodes , to rebuild one erased systematic node , only @xmath0 of the information needs to be transmitted . </S>",
    "<S> interestingly , in many cases , the required disk i / o is also minimized . </S>"
  ]
}