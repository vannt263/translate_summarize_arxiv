{
  "article_text": [
    "network structure  @xcite is usually defined as the way a network differs from what is expected .",
    "what `` expected '' means depends on the fundamental constraints on the network , and this can vary from system to system .",
    "for example , if the network is made of units that must be connected to two , and only two , others ; then , it is not interesting whether or not a vertex lies on a cycle ( we already know that it will ) .",
    "the ensemble of all networks fulfilling the fundamental constraints on the system is usually called _ null model _ ( or _ reference model _ ) .",
    "when we have pinned down the null model we can measure the network structure by standard quantities . if the values of these quantities differs significantly from the null - model average",
    ", then we call the network structured . the baseline assumption of complex network theory is that network structure carries information about the forces that have formed the network . ever since the studies of barabsi and coworkers  @xcite , the degree distribution ( or , if referring to the set of degrees of one particular network , _ degree sequence _ ) has been regarded as the most fundamental network structure . for many networks ,",
    "the degrees are related to outer factors ( not emerging from the network evolution ) . in such cases",
    "the ensemble of all graphs with the same degree sequence as the original network is a natural null model .",
    "another interpretation is that the network structures measured relative to this null model are of higher order than the degree ",
    ", what remain after the effects of the more fundamental structure ( the degree sequence ) is filtered away .",
    "the usual way to use a null model is to compare a network measure with the ensemble average value of the null model . in this paper",
    "we will argue that one can glean more information about the original network by studying the null model ensemble in greater detail than just measuring averages .",
    "we consider networks that can be modeled as a graph @xmath0 where @xmath1 is the set of @xmath2 vertices and @xmath3 is the set of @xmath4 undirected edges .",
    "we denote the ensemble of graphs with the same degree sequence as @xmath5 as @xmath6 . our basic approach to study",
    "@xmath6 is to resolve its members in the space of higher order network structures .",
    "the two such higher order network structures we consider in this paper are : the correlation between the degrees at either side of an edge ( measured by the _ assortative mixing coefficient _ , @xmath7  @xcite , or simply _ assortativity _ ) ; and , the fraction of triangles in the network ( measured by the _ clustering coefficient _ , @xmath8  @xcite ) . by mapping out @xmath6 in the space defined by @xmath7 and",
    "@xmath8 one can pose questions such as : how large is the region in @xmath7-@xmath8 space where members of @xmath6 actually exist ? ( this helps us answer how constrained the network evolution is if the degrees are given . ) is the real network close to @xmath6 s boundaries in @xmath7-@xmath8 space ? ( which would indicate whether or not @xmath7 or @xmath8 are actively optimized . )",
    "the basis for our exploration of an ensemble @xmath6 is to map out its members in the space defined by some network - structural measures , in our case the assortativity and clustering .",
    "we explore the @xmath7-@xmath8 space by successively rewire pairs of edges , @xmath9 and @xmath10 to @xmath11 and @xmath12 , that takes the system in a desired direction .",
    "rewiring techniques for studying networks are half a century old  @xcite ( randomization for obtaining null models was studied in ref .",
    "@xcite ) . in the physics literature",
    "these techniques were first used in refs .",
    "before going into details of our algorithm , we will review the network structural quantities that we use to describe our networks : both the independent variables ( the assortative and clustering coefficients ) that form the basis for our space of interest ; and the quantities we use for characterizing the regions of this space .",
    "it is quite well accepted that the set of degrees , the degree sequence , is the network quantity that contains most information about both the evolution and function of the network .",
    "degree can ( in most contexts ) be identified as how influential the vertex is  @xcite ( in some sense)high degree vertices are assumed to be more influential both the formation of the network and the flow of dynamic systems on the network . in this paper",
    "we assume the degree sequence is inherent to the system and look at higher order structures arising from how the vertices are linked to one another .",
    "the simplest such higher - order structure is the correlations between the degrees of vertices at either side of an edge .",
    "is it the case that high - degree vertices are primarily connected to other high degree vertices , or are they linked to low - degree vertices ? a simple way of measuring this tendency is by the assortativity  @xcite @xmath7 . basically speaking , @xmath7 is the linear correlation coefficient of the degrees at either side of an edge .",
    "one complication is that since the edges are undirected , @xmath7 has to be symmetric with respect to edge - reversal , but the correlation coefficient is not symmetric .",
    "the solution is to let one edge contribute twice to the covariance , i.e.  represent an undirected edge by two directed edges pointing in opposite directions .",
    "if one use an edge list representation internally ( i.e. , let the edges be stored in an array of ordered pairs @xmath13 ) then  @xcite @xmath14 where , for an edge @xmath9 , @xmath15 is the degree of first argument ( i.e. , the degree of @xmath16 ) and @xmath17 is the degree of the second argument .",
    "the range of @xmath7 is @xmath18 $ ] where negative values indicate a preference for high connected vertices to attach to low - degree vertices , and positive values means that vertices tend to be attached to others with degrees of similar magnitudes .",
    "several simple random network models ( such as the edrs - rnyi  @xcite or the model for generating networks of a given @xmath7-value in ref .",
    "@xcite ) have rather few triangles ( fully connected subgraphs of three vertices ) .",
    "for some classes of real - world networks ( notably social networks  @xcite ) there is a strong tendency for triangles to form , which makes such models fail .",
    "the network measure of the density of triangles is called _",
    "clustering coefficient_. we use the definition of ref .",
    "@xcite : @xmath19 where @xmath20 is the number of triangles and @xmath21 is the number of connected triples ( subgraphs consisting of three vertices and two or three edges ) .",
    "the factor three is included to normalize the quantity to the interval @xmath22 $ ] .",
    "two quantities that are , perhaps more than any other , related to the functionality of dynamic processes on the network are the relative size of the largest component ( connected subgraph ) @xmath23 , and the average distance @xmath24 .",
    "@xmath23 is simply defined as the number of vertices in the largest component divided by @xmath2 .",
    "the distance @xmath25 between two vertices @xmath16 and @xmath26 is defined as the number of edges in the shortest path between these two vertices .",
    "@xmath27 is @xmath25 averaged over all vertex pairs ( @xmath28 ) in the largest component . in a network with large @xmath23 and small @xmath27",
    ", spreading processes will be fast and far - reaching .",
    "this is a good property of information networks , but bad in the context of , for example , disease spreading .",
    "some authors have combined the distance and component size aspects by considering the average reciprocal distances  @xcite . for most purposes ,",
    "we believe , valuable information gets lost in such a combination ( a fragmented network @xmath5 with short average distances can be something very different from a connected graph of large distances and the same average reciprocal distances as @xmath5 ) .",
    "one line of complex network research is the study of the response of the network to attacks , errors , failures and other events that effectively change the structure .",
    "the error response problem is usually formulated as : how does the functionality of the network change if a random fraction of the vertices , or edges , is removed  @xcite ?",
    "the attack problem is the same , except that the vertices are not selected randomly but according to some strategy intended to decrease the networks functionality as rapidly as possible  @xcite .",
    "a frequently used metric for functionality is the ratio of @xmath23 before and after the event  @xcite . in the error and attack robustness problems ,",
    "this quantity is typically plotted as a function of the number of removed vertices .",
    "the idea is that even if one network @xmath5 is more robust than another network @xmath29 to the removal of , say , @xmath30 of the vertices , @xmath29 can be less vulnerable than @xmath5 if @xmath31 of the vertices are deleted . since we aim at mapping out the @xmath7-@xmath8 space of degree sequences , we would like to capture the robustness with just one number .",
    "we will use what we call the @xmath32-_robustness _",
    "@xmath33 of a network as the expected fraction of vertices that needs to be removed for the relative size of the largest component to decrease to a fraction @xmath34 of its original value .",
    "the way of removal can either be random ( the error problem ) or selective ( the attack problem ) .",
    "for the rest of the paper we will set @xmath35 , and refer to the @xmath36-robustness just as `` robustness '' @xmath37 .",
    "other @xmath32-values give slightly different results , but our conclusions will hold for a range of intermediate @xmath32-values .",
    "the fundamental idea of our method is simple : we update the network by choosing pairs of edges randomly , say @xmath9 and @xmath10 , and swap one end of them ( forming @xmath11 and @xmath12 ) .",
    "this guarantees that the degree sequence stays intact .",
    "we navigate in the @xmath7-@xmath8 space by only accepting changes that move us in the desired direction . if an edge - swap would introduce a self - edge ( i.e.  if @xmath38 or @xmath39 ) or a multiple edge ( i.e.  if @xmath11 or @xmath12 belongs to @xmath3 before the swapping , or _ move _ ) it is not performed .",
    "there are many other technicalities concerning the convergence to extremes , uniformity of the sampling and more that we discuss in the appendix .",
    "the members of the ensemble @xmath6 do not , in general , cover the whole range of @xmath40-values .",
    "indeed , for any finite @xmath5 , @xmath6 defines a set of points , rather than a continuous region , in the @xmath7-@xmath8 space . we will perform a more coarse - grained analysis breaking down the @xmath7-@xmath8 space into pixels and average quantities over the graphs of @xmath6 with @xmath40-values within the pixel .",
    "( thus , a pixel constitute a graph ensemble in itself , our aim is to sample its members with uniform randomness . ) for a computationally tractable resolution , the pixels containing members of @xmath6 typically form contiguous regions .",
    "we will refer to the pixels that contain a member of @xmath6 as _ valid pixels _ , and all pixels that are valid or between valid pixels the _ valid region _ of @xmath6 .    to trace the valid region of @xmath6",
    "we start by finding the lowest and highest assortativity value , @xmath41 and @xmath42 respectively . briefly speaking ( more details follow below ) , to find @xmath41 we rewire edge - pairs that lower @xmath7 ( and vice versa for @xmath42 ) . after finding the extremal @xmath7-values , we splice the region between these into @xmath43 segments .",
    "then we go through the region and for each region @xmath44 $ ] we find the minimal and maximal @xmath8-values , @xmath45 and @xmath46 .",
    "the region in @xmath8-space between the lowest @xmath47 and highest @xmath48 observed clustering coefficient is segmented into @xmath43 regions .",
    "( note that @xmath49 , without argument , is the global clustering minimum , whereas @xmath45 is the minimum conditioned on @xmath7 being in the @xmath50th segment . )",
    "thus we ( assuming our method works ) obtain an @xmath51 grid of the @xmath7-@xmath8 space that contains the valid region of @xmath6 .",
    "the method is illustrated in fig .",
    "[ fig : ill ] .    to find the @xmath6 elements of minimal and maximal assortativity is a non - trivial optimization problem .",
    "there are deterministic methods that , if they terminate , are guaranteed to give the maximal ( or minimal ) assortativity  @xcite . to avoid the such technicalities and to simplify the program",
    ", we will use the same kind of optimization algorithm to find @xmath42 and @xmath41 as to find @xmath45 and @xmath46 . in the appendix",
    "we will argue that this method allows us to come as close to the optimal @xmath7-values as we need .",
    "a method we find efficient is to repeat the simple edge - pair swapping procedure ( where only changes in the desired direction are accepted ) with different random seeds until no lower state is found during a number @xmath52 of repetitions  @xcite .",
    "each individual edge - pair is terminated when no lowest state is found for @xmath53 swaps . in general , the larger the network is , the more densely distributed are the points close to the border of the valid region .",
    "if one is satisfied with finding a value a certain distance from the extrema , then @xmath52 and @xmath53 do not need to be increased for larger @xmath2 . to find @xmath45 and @xmath46 almost the same procedure is employed .",
    "first , edge - pairs are swapped until the desired segment of @xmath7 is found . second , unless @xmath7 is outside the segment @xmath50 and the move takes the system yet further from segment , edge - pairs are swapped provided the clustering would decrease ( for @xmath45 ) , or increase , ( for @xmath46 ) . when the valid region is traced out and we sample networks of different pixels , we select the pixels randomly . the idea is to sample the space of networks more randomly .",
    "to summarize , the algorithm for finding the extremal assortativity values , @xmath41 and @xmath42 , is :    1 .",
    "[ step : choose ] choose two undirected edges @xmath9 and @xmath10 at random . if the program makes a difference between the arguments of the edge , the direction of the reading of the edge also has to be randomized ( so @xmath9 is read as @xmath54 with probability @xmath36 ) .",
    "[ step : check ] check if swapping these edges to @xmath11 and @xmath12 would introduce a self - edge or multiple edge in the network .",
    "if so , go to step  [ step : choose ] .",
    "[ step : accept ] let @xmath55 be the change in @xmath7 if the move in step  [ step : choose ] is executed . if @xmath7 is to be minimized and @xmath56 , then accept the change ( vice versa for maximization of @xmath7 ) .",
    "[ step : conclude ] if no move has been executed during the last @xmath53 executions of step  [ step : accept ] , then take the current @xmath7 as @xmath57 ( or @xmath58 ) . 5 .",
    "[ step : stop ] repeat from the beginning @xmath52 times and return the lowest observed @xmath57 during these iterations .",
    "given @xmath41 and @xmath42 , and a division of the @xmath7 space into @xmath43 segments of width @xmath59 , we trace the boundaries of the valid region as follows :    1 .",
    "[ step : choose2 ] go through the regions sequentially .",
    "say the @xmath50th region is the interval @xmath60 .",
    "2 .   perform step  [ step : choose ] and [ step : check ] of the assortativity optimization algorithm .",
    "3 .   let @xmath61 be the change in clustering coefficient during the previous step .",
    "if @xmath62 and @xmath63 , @xmath64 and @xmath56 or @xmath65 and @xmath66 ( for minimization ) or @xmath67 ( for maximization ) , then perform the change of step  [ step : choose2 ] .",
    "[ step : conclude2 ] if , counting from the first time the system entered the desired @xmath7-segment , the minimal ( maximal ) @xmath8-value has been repeated @xmath53 times , take this value as @xmath68 ( @xmath69 ) . 5 .",
    "[ step : stop2 ] repeat from step  [ step : choose2 ] @xmath52 times .",
    "let the lowest @xmath68-values and largest @xmath69 during these iterations be @xmath45 and @xmath46 .",
    "then , when the valid region is mapped out , we split the @xmath8-range ( between @xmath49 and @xmath70 in @xmath43 segments of equal width , thus forming an @xmath51-grid enclosing the valid region .",
    "this grid is sampled as follows :    1 .",
    "[ step : perm ] construct a random permutation of the valid pixels .",
    "[ step : pick ] pick the next pixel @xmath71 from the index - list of step  [ step : perm ] .",
    "denote the center @xmath72 $ ] of the pixel @xmath73 .",
    "let @xmath74 measure the distance in @xmath7-@xmath8 space from the current position @xmath40 to the center of the target pixel .",
    "3 .   pick edge - pair candidates according to steps  [ step : choose ] and [ step : check ] of the assortativity optimization algorithm .",
    "4 .   calculate @xmath75 where @xmath7 and @xmath8 are the current assortativity and clustering values , and @xmath76 and @xmath77 are the values after the pending move has been performed . if @xmath78 perform the move .",
    "[ step : rw ] if the updated @xmath40 belongs to @xmath79 , then : first , make @xmath80 random edge swappings such that @xmath40 does not leave @xmath79 .",
    "( this is to sample the pixel more uniformly . ) then , measure network structural quantities of @xmath79 , save these values for statistics , and go to step  [ step : pick ] .",
    "if not all pixels have been measured go to step  [ step : pick ] .",
    "go to step  [ step : perm ] until each pixel have been sampled @xmath81 times .",
    "the parameter values we use in this study are ( unless otherwise stated ) : @xmath82 , @xmath83 , @xmath84 , @xmath85 and @xmath86 .",
    "the choice of parameters and further considerations are discussed in the appendix . due to the uncertain stopping conditions of steps  [",
    "step : conclude ] , [ step : stop ] , [ step : conclude2 ] and [ step : stop2 ] it is hard to derive meaningful bounds on the computational complexity .",
    "we note , however , that the optimization is faster in @xmath7- than in @xmath8-direction , this probably relates to the observation in fig .",
    "[ fig : ill](b ) that swapping procedure moves faster in the @xmath7- than in the @xmath8-direction .",
    "( the speed in the @xmath8-direction is roughly the same per 1000 steps , but the speed in the @xmath7-direction decrease . )",
    "our method can be applied to every kind of system that can be modeled as an undirected network . to limit ourselves , we use four networks from biology as examples in this paper .",
    "these networks are , nonetheless , representing fundamentally different systems .",
    "r|dddd[tab : stat ] & & & & + @xmath2 & 291 & 4168 & 1905 & 280 + @xmath4 & 278 & 7434 & 3526 & 1973 + @xmath7 & -0.36 & -0.13 & -0.10 & -0.069 + @xmath8 & 0.0016 & 0.034 & 0.039 & 0.20 + @xmath23 & 0.38 & 0.94 & 0.87 & 1 + @xmath27 & 4.2 & 4.8 & 4.5 & 2.6 + @xmath87 & 0.43 & 0.36 & 0.36 & 0.50 + @xmath88 & 0.012 & 0.048 & 0.046 & 0.38 +      cancer is a disease that occurs due to changes in the genome . one important process causing such changes is gene fusion  when two genes merge to form a hybrid gene  @xcite . in ref .",
    "@xcite the authors construct a network of human genes that have been observed to be fused in the development of tumors in humans .",
    "some genes can fuse with many others but most of the genes have only been observed fusing with one , or a few others .",
    "the resulting network structure has a skewed , power - law like degree distribution and is rather fragmented ",
    "the largest component spanning only @xmath89 of the vertices .",
    "statistics of this and the other networks are listed in table  [ tab : stat ] .",
    "a cell can be regarded as a machine driven by biochemical reactions .",
    "the possible reactions of the metabolism ( the cellular biochemistry except signaling processes ) and its environment determine the state of the cell .",
    "the metabolism of an organism is a very complex system  so complex that one has to choose between studying a part of it in detail , or the whole with a coarser method .",
    "one approach in the latter category is to construct a network , connecting the chemical substrates occurring in the same reactions to a network , and employ network analysis to characterize the large - scale structure of the metabolism . the way to construct a biochemical network is not entirely straightforward  @xcite .",
    "should the substances be linked to each other ( in a _ substrate graph _ ) , or to the reactions they participate in ? if one use a substrate graph , should the substrates be linked only to products , or to all reactants ( i.e.  in a reaction a + b @xmath90 c + d , should a be linked to c and d , or to all three other vertices ) ?",
    "furthermore , some chemical substances ( like h@xmath91o , atp , nadh , and so on ) are abundant throughout the cell and seldom pose any restriction on the reaction dynamics . for many purposes , one obtains a more meaningful network by deleting such _",
    "currency metabolites_. the biochemical network we use is the human metabolic network of ref",
    ".  @xcite . in this network",
    ", substrates are linked only to products ( a to c and d in the above example ) .",
    "currency metabolites are identified and deleted according to a self - consistent , graph - theoretic method  @xcite .      in protein interaction networks",
    "the vertices are proteins and two proteins constitute an edge if they can interact physically .",
    "examples of interaction are the ability to form complexes , carrying another protein across a membrane or modifying another protein .",
    "we use the ( `` physical interaction '' ) data set from ref .",
    "@xcite of protein interaction in the budding yeast _",
    "s. cerevisiae_.      for the biochemistry of an organism , the network representation is a crude model of the system as a whole ( as an alternative to a detailed model of a subsystem ) .",
    "neural networks are yet more complex . for these the choices are either to make a coarse - grained network representation  @xcite or study the full network of a very simple organism . in this work ,",
    "we take the latter approach and study the neural network of _ c. elegans _  @xcite . in this data",
    "set , the strength of the neuronal coupling has been measured , but we make the network undirected by letting an edge represent a non - zero coupling .",
    "in this section we present numerical results for our four network - structural measures over the @xmath6 ensembles of the four test graphs . to get a first view , we display the valid region of the gene fusion graph in fig .  [",
    "fig : exp](a ) .",
    "as seen , the valid region is not covering a large part of the theoretical limits of @xmath7 ( @xmath92 ) and @xmath8 ( @xmath93 ) .",
    "( note that only fully connected graphs have @xmath94 , and for these @xmath7 is undefined . )",
    "the requirement that the graph should be simple ( no multiple edges or self - edges ) puts hard constraints on the actual @xmath7-values that can occur ( cf .  ref .",
    "[ fig : exp](a ) shows that , considering the entire @xmath7-@xmath8 plane , such constraints are even harder .",
    "the general shape of the valid region is consistent with the observations that the simple - graph constraint induce a positive correlation between @xmath7 and @xmath8  @xcite .    in fig .",
    "[ fig : exp](b ) , ( c ) and ( d ) we show three example networks of @xmath6 ( where @xmath5 is the gene fusion network ) .",
    "[ fig : exp](b ) displays the relatively fragmented real network .",
    "[ fig : exp](c ) is a random network @xmath29 with the almost the same @xmath7-@xmath8 coordinates as the real network ( @xmath95 ) .",
    "maybe the biggest visible difference between @xmath5 and @xmath29 is the larger size of the largest component of @xmath29 .",
    "is it true that the gene fusion network is unusually fragmented , given the degree sequence and @xmath7-@xmath8 coordinates ?",
    "if so , there might be an evolutionary pressure for gene fusion networks to be fragmented .",
    "( this will be discussed further in sect .",
    "[ sect : size ] . ) fig .",
    "[ fig : exp](d ) shows , as a contrast , a network far away from @xmath5 and @xmath29 .",
    "the network has a well - defined core where high - degree vertices connect to each other .",
    "there are also a number of peripheral triangles , which indicates that the network evolves toward a maximal @xmath8-value , given its assortativity .      in fig .",
    "[ fig : ngc ] we plot the relative size of the largest component of the four test networks .",
    "we also display the locations of the actual networks in the @xmath7-@xmath8 plane , and the @xmath6-averages .",
    "( the @xmath6 averages are obtained from a rewiring sampling of @xmath6 , with step  [ step : check ] of the algorithm as the only constraint . )",
    "we see that the @xmath8-value of the gene fusion graph lies close to the @xmath96-boundary of its valid region .",
    "@xmath8 averaged over the whole @xmath6 is about three times larger ( @xmath97 ) than the observed value ( @xmath98 ) .",
    "furthermore , we see that the assortativity is lower than the @xmath6 average",
    ". this kind of analysis has been used by many authors ( following ref .",
    "the interpretation is usually that the network is , effectively , disassortative and clustered ( i.e. , @xmath99 and @xmath100 ) .",
    "however , looking at the entire valid region , we can get another perspective : if high clustering really would have been an important goal for the network to obtain ( given the degree sequence ) there is large room for improvement . for the assortativity ,",
    "on the other hand , the observed network is rather close to the minimum .",
    "this might be telling us that assortativity is a more important factor , than clustering , in the evolution of the gene fusion networks . the protein interaction network of fig .",
    "[ fig : ngc](b ) is located quite far from the ensemble average  the assortativity is much lower than the @xmath6-average , and given that assortativity , the clustering is maximal . also the metabolic ( fig .",
    "[ fig : ngc](c ) ) and neural ( fig .",
    "[ fig : ngc](d ) ) networks are more clustered than the average , but here the assortativity is slightly larger than the @xmath6 average . from fig .",
    "[ fig : ngc ] we also note that the density of states is very inhomogeneous distributed  the average @xmath40 is close to @xmath101 and ( except for the neural network ) left of the middle of the assortativity spectrum .",
    "the shapes of the valid regions are rather similar , with an exception for the broader region of the neural network .",
    "this can be related to the more narrow degree sequence of the neural network  @xcite .",
    "we have established a correlation between @xmath7 and @xmath8 .",
    "@xcite argues that such correlation occurs in social networks because of their modularity ( or `` community structure '' as the authors call it ) .",
    "however , our large-@xmath7 networks have no explicit bias towards high modularity , which leads us to conjecture that the correlation between @xmath7 and @xmath8 , or more fundamentally the sum @xmath102 ( which , given a degree sequence , is the only factor of eq .  [",
    "eq : assmix ] that can vary ) is a more general phenomenon .",
    "since @xmath7 is normalized by , essentially , the variance of the degree , it follows that the valid region for @xmath6 with more narrow degree sequence will appear stretched ( larger ) .    turning to the average size of the largest component",
    ", we observe that the gene fusion network is indeed more fragmented than the average network of the same @xmath40-coordinates ( as anticipated from comparing figs .",
    "[ fig : exp](b ) and ( c ) ) . the protein interaction and neural networks",
    "have no particular bias in this respect , whereas the metabolic network is more fragmented than expected .",
    "the relatively low @xmath23 of the metabolic network can be attributed to the `` modularity '' of such networks  @xcite .",
    "such modules are subgraphs that are densely connected within , and sparsely inter - connected . sometimes they are even disconnected from the largest component ( which explains the lower @xmath23 ) .",
    "in general , @xmath23 decreases with assortativity .",
    "this is natural  in more assortative networks high degree vertices are connected to each other , forming a highly connected core and a periphery too sparse to be connected ( viz .",
    "[ fig : exp](c ) and ( d ) ) . for the denser networks ( the protein interaction , metabolic and neural networks )",
    "@xmath23 increases with @xmath8 ( for a fixed @xmath7 ) . for the sparser gene - fusion network",
    "@xmath23 has a peak at intermediate @xmath8 .",
    "we do not speculate further about combinatorial cause of these dependencies ; but we note ( comparing e.g.  figs .",
    "[ fig : exp](a ) and ( b ) ) that even though the shape of the valid regions are similar , the @xmath23 behavior can be qualitatively different .      in fig .",
    "[ fig : length ] we display the average distance in the largest component .",
    "as mentioned , measuring the distance can give complementary information to the @xmath103 graphs of fig .",
    "[ fig : ngc]while @xmath23 tells us how much of the network that can be reached , @xmath24 tells us how fast that can happen . for all networks the big picture is that large connected components have large average distances .",
    "this is expected from most network models .",
    "there is , however , more information than this in fig .",
    "[ fig : length ] : for components of the same size , the average distance is increasing with both @xmath7 and @xmath8 .",
    "that @xmath27 should increase with @xmath8 seems quite natural ",
    "if one of a triangle s edges is rewired to connect two distant vertices , the distances in the surrounding of the triangle would increase with one , but this would be more than compensated by the connection of the two previously distant areas .",
    "disassortative networks typically lack a well - defined core .",
    "such cores are known to keep the average distance of general power - law networks short  @xcite .",
    "thus one would expect an increase of @xmath7 to cause a larger @xmath27 , but apparently the clustering related length - increase outweighs this effect .",
    "in contrast to the relative size , the average distances of the real networks are close to the @xmath6-averages at the same @xmath7-@xmath8 coordinates . for the gene fusion network",
    "( with a relatively small largest component ) , this means the distances are rather large .",
    "next , we turn to the error robustness problem . as seen in fig .",
    "[ fig : error ] the gene fusion network ( fig .",
    "[ fig : error](a ) ) , once again , has a qualitatively different behavior than the other three networks ( fig .",
    "[ fig : error](b ) , ( c ) and ( d ) ) .",
    "while the gene fusion network is most robust for high @xmath7- and @xmath8-values the other networks are most robust for low @xmath7 .",
    "a sketchy explanation can be found in the chain - like subgraphs extending from the largest component in a large-@xmath7 network ( cf .",
    "[ fig : exp])with a random deletion of vertices , these subgraphs are likely to be disconnected from the core rather soon ( whereas in a disassortative network alternative paths may still exist ) , then if the deletion - robust core is less than half of the original component size it follows that it may soon be isolated .",
    "the sparsity of the gene fusion network makes the low-@xmath7 @xmath6-graphs much like trees ( i.e. , having few cycles ) , and since cycles provide redundant paths that can make a network robust , it follows that these graphs are fragile . for a fixed @xmath7 ,",
    "@xmath87 is a decreasing function of @xmath8 for the three largest networks .",
    "we believe this is an effect of the local path redundancy induced by triangles  if one vertex of a triangle is deleted , the other two are still connected .",
    "the @xmath87-values for the real networks are always markedly higher than the @xmath6-averages for the same @xmath40-coordinates",
    ". networks with highly skewed degree distributions ( the gene fusion , protein interaction and metabolic networks ) are known to be robust to errors by virtue of degree distribution alone  @xcite , now fig .",
    "[ fig : error ] tells us that all these networks have a yet higher error tolerance which is an indication that error robustness is an important factor in the evolution of these networks .",
    "the final quantity we measure is the attack robustness ( see fig .",
    "[ fig : attack ] ) . @xmath88 s functional dependence on @xmath7 and @xmath8 is quite different from that of @xmath87 .",
    "the gene fusion @xmath6 has the highest attack robustness at high @xmath7- and low @xmath8-values .",
    "the other networks have higher robustness values for high assortativity , but no clear tendency in the @xmath8-direction .",
    "the attack mechanism we study targets the high degree vertices .",
    "having all high degree vertices connected to each other is probably the only way to keep the network from instantaneous fragmentation .",
    "the observed @xmath7-dependence is thus rather expected .",
    "the real - world networks all have @xmath88-values of the same order of magnitude as the average values for the @xmath6 networks of the same location in @xmath7-@xmath8 space .",
    "we note that for studying the attack problem of metabolic networks , the ( less common ) enzyme centric graph representation is more appropriate ( see sect .",
    "[ sect : meta ] ) .",
    "the reason being that one can suppress an enzyme much easier than removing the substrates .",
    "r|dddd[tab : pval ] & & & & + @xmath23 & < & < & < & > + @xmath27 & < & < & < & < + @xmath87 & > & > & > & > + @xmath88 & > & > & > & > +      even though all our example networks are constructed from biological data , they represent fundamentally different systems  the neural network is spatial by nature , the protein interaction and ( even more so ) the metabolic networks are the background topology for an active dynamic system , whereas the gene fusion network is a representation of possible but undesired events . the protein interaction , metabolic and neural networks have one thing in common  the organism needs them to be robust to errors ( caused by injuries , mutations , disease etc . )  @xcite . as mentioned above and summarized in table  [ tab : pval ]",
    "the error robustness is indeed higher for the real networks than the @xmath6-ensemble at the same @xmath40-coordinates . as mentioned above ,",
    "the attack robustness of the real network is of the same order as the @xmath6-average at the same @xmath40-coordinate , but actually there is a significant tendency that these network also are more robust to attacks .",
    "furthermore , the distances in the largest component , and the relative sizes @xmath23 are ( with the neural network @xmath23-value as the only exception ) smaller in the real than the @xmath6 networks .    despite these similarities between the statistics of the real - world networks the @xmath7-@xmath8 space of the different degree sequences have qualitatively different network structure .",
    "especially , the gene fusion network behaves almost the opposite of the other networks ( at least for @xmath23 , @xmath27 and @xmath87 ) .",
    "the source of this opposite behavior ( as we discuss above ) is probably that it is much sparser than the other networks .",
    "the neural network is the densest network and the only one that do not have a power - law like degree distribution .",
    "many complex network studies use the ensemble @xmath6 of graphs with the same degree sequence as the subject graph @xmath5 as a null model .",
    "in contrast to a generative network model , with a few degrees of freedom that has to be fitted approximately , such an ensemble has @xmath104 degrees of freedom that can be matched exactly with the values of @xmath5 .",
    "we argue that @xmath6 is more than a null model  by resolving the graphs of @xmath6 in a space defined by some network - structural measures , one can get a picture of the opportunities and limits there are ( or has been ) in the evolution of @xmath5 . in this work",
    "we map out @xmath6 in the two - dimensional space defined by the clustering coefficient and the assortativity .",
    "then we measure other network structural quantities throughout this space . one formal way to see our method",
    "is that we resolve @xmath6 in the ( high dimensional ) space of all sensible network measures .",
    "then , for simplicity , we project to a few dimensions .",
    "( the case of projection to one dimension has been studied in a less formalized way earlier  projection to assortativity  @xcite or a `` hierarchy '' measure  @xcite . )",
    "an interesting open question is to find the principal components of the space of all sensible network measures .",
    "using four example networks from biology , we measure average values of four network - structural quantities over the @xmath7-@xmath8 space and compare these with the values of the real networks .",
    "the functional characteristics of the @xmath7-@xmath8 spaces varies much between the four example networks .",
    "for example ,",
    "the _ c. elegans _ neural network covers a much larger area of the @xmath7-@xmath8 space , something that probably relates to its more narrow degree distribution .",
    "the human gene fusion network , on the other hand , has a broad degree distribution similar to the _ s. cerevisiae _ protein interaction and human metabolic networks , still the structural dependency on @xmath7 and @xmath8 is very different for the gene fusion network compared to the others .",
    "we argue that this difference stems from the sparseness of the gene fusion network . to achieve a comprehensive understanding about how the network structure throughout the @xmath7-@xmath8 space depends on the degree sequence , one would need a systematic investigation of different artificial degree sequences . in this paper",
    ", we do not pursue this goal beyond the analysis of the four biological data sets .",
    "the position of the real networks in the valid region of the @xmath7-@xmath8 space adds some further information .",
    "for example , it may have been the case that networks with lower assortativity have been favored during the evolution of the gene fusion network .",
    "clustering , on the other hand , has probably not put any constraint on the network evolution .",
    "furthermore we compare the network structure of the real networks with the average values of networks in @xmath6 that are close to the @xmath40-coordinates of the real network . from this analysis",
    ", we conclude that all our four example networks are more robust to both random errors and targeted attacks than what can be expected from a random network constrained to the same degree distribution , assortativity and clustering coefficient . for all networks , except maybe the gene fusion network , this is in line with robustness being an important factor in the network evolution .",
    "note that in this work we assume the subject network to be accurate . to get more valid error estimates one would need to take the accuracy of the edges into account .",
    "the analysis scheme presented in this paper can be further extended and analyzed .",
    "as mentioned , it would be interesting with a quantitative evaluation of the network - structural spaces , and how they depend on the degree sequence .",
    "one can also try , for time - resolved data sets , to incorporate dynamic information in the analysis by monitoring the network - evolutionary trajectory in the @xmath7-@xmath8 space .",
    "in this appendix , we address some technical issues of our method related to the convergence of our optimization algorithm and uniformity of the sampling .",
    "we will also motivate our choice of parameters .      to find the extremal assortativity values we use the edge - swapping algorithm described in sect .",
    "[ sect : analysis ] . to find @xmath41 we start from a random member of @xmath6 and swap random edge - pairs ( keeping the graph simple at all times ) that lower @xmath7 .",
    "when no graph of lower @xmath7 has been found for @xmath53 time steps , we break the iteration . to avoid the effect of being trapped in local minima , this process is repeated @xmath52 times .",
    "the main motivation for using this method is that it is at heart the same scheme as for obtaining the extremal clustering values and sampling the valid region ( and thus we can re - use the same code for many steps of the calculations ) . in this section ,",
    "we argue that the optimization performance of this method is sufficiently good for our purpose .",
    "there is a deterministic method to maximize the assortativity that is , if it exits properly , guaranteed to find @xmath42  @xcite .",
    "the method works as follows : first all vertex - pairs @xmath9 are ranked in decreasing order of the product of their degrees , @xmath105 .",
    "then the edges are added in order of this list unless the degree of one of the vertices already is fulfilled .",
    "there are some other technicalities from the additional constraint ( of the authors ) that the network should be connected . of our networks , only the neural network has such an evolutionary constraint , so we do not impose it .    in fig .",
    "[ fig : conv ] we display the parameter dependence of the convergence for the gene fusion network .",
    "the horizontal line is the theoretical maximum obtained by the algorithm of ref .",
    "@xcite . when @xmath106 we obtain an average maximal assortativity within @xmath107 of the theoretical maximum ( fig .",
    "[ fig : conv](a ) ) . by increasing @xmath52",
    "the accuracy can be increased further ( fig .",
    "[ fig : conv](b ) ) .",
    "the lattice spacing we use is @xmath108 , so we deem a precision of @xmath107 sufficient .",
    "the gene fusion network is our smallest network but the other networks are not harder to converge .",
    "when one edge - pair is swapped so that @xmath7 decreases , the only term of eq .",
    "[ eq : assmix ] that changes is @xmath109 .",
    "the potential change of the sum @xmath102 , in the calculation of @xmath109 ( close to the extrema ) is of the order of the typical degree values of the network .",
    "these values grow slower than the network itself , which means that a larger network can be closer in @xmath7 , but further away in number of edge swaps to reach the global optimum , than a smaller network . some authors  @xcite use @xmath110 to measure the degree correlations ,",
    "but since we strive for a macroscopic level of description ( consistent in the large-@xmath2 limit ) , @xmath7 is a more appropriate quantity for the present work .",
    "the optimization of the clustering to find the minima ( maxima ) of the segments of assortativity space follows the same pattern as the method to find the minimal ( maximal ) @xmath7 .",
    "changes of the parameters ( @xmath53 and @xmath52 ) have the same effect as in fig .",
    "[ fig : conv ] , and the same values seem sufficient .",
    "the other technical issue we address in this appendix is the uniformity of our sampling procedure .",
    "ideally we would like all unique ( i.e. , non - isomorphic ) members of @xmath6 to be sampled with the same probability .",
    "the most important observation is trivial  by edge - pair swapping one can go from one member of @xmath6 to any other , and thus all members of the ensemble will contribute to the averages .",
    "a much harder question is whether or not every member of @xmath6 is sampled with uniform probability . in this section , we will argue that our algorithm does a reasonably good job in the sense that there are no inconsistencies and parameter values are appropriate .",
    "when the target pixel is found ( step  [ step : rw ] of the algorithm ) we perform @xmath80 additional random edge - pair swaps .",
    "the idea is to sample the @xmath6-members of the pixel more uniformly ( and indeed to be able to reach into the interior of the pixel ) . in fig .",
    "[ fig : uni](a ) we illustrate the effect of these random moves .",
    "we plot a normalized histogram of the relative largest cluster size @xmath23 for @xmath111 , @xmath112 and @xmath113 random moves .",
    "we see that these moves do make a difference ( the @xmath114 is different from the @xmath115 ) but it does not matter if @xmath115 or @xmath116 . the same situation is observed for other pixels , networks and quantities .",
    "therefore , we use @xmath85 in this work .",
    "next , we will illustrate the use of the randomly permuted list in the sampling of the pixels ( steps  [ step : perm ] and [ step : pick ] of the algorithm ) .",
    "the motivation for this procedure is that the network structure can depend on the direction from which the search arrives to the pixel . in fig .",
    "[ fig : uni](b ) we illustrate the test procedure  we sample separate histograms from four starting points in the four cardinal directions with respect to the central @xmath117 pixel . in fig .",
    "[ fig : uni](c ) we see that the histograms from the w and s pixels are different .",
    "there appears to be two regions of @xmath6 contributing to these histograms ( one with @xmath118 , one with @xmath119 ) .",
    "searches starting from w seem to arrive at the @xmath120 region more frequently , and searches staring at s ends up around @xmath118 more frequently .",
    "the curve of the actual algorithm weighs the two peaks more equal .",
    "the curves from n and e coincides almost completely the curve for the regular algorithm ( and are therefore omitted for clarity ) .",
    "the impression we get is that the search from one direction can induce a bias in the network structure ( symbolically speaking , the graphs have a preference for ending up in a certain region of @xmath6 ) .",
    "however , from other directions , or by the random sampling of pixels ( step  [ step : perm ] ) , the bias is reduced .",
    "this picture is further strengthened in fig .",
    "[ fig : uni](d ) where we show that the average value of the histograms from the four starting points are overlapping with the histogram of the regular algorithm ."
  ],
  "abstract_text": [
    "<S> nowadays there is a multitude of measures designed to capture different aspects of network structure . to be able to say if the structure of certain network is expected or not , one needs a reference model ( null model ) . </S>",
    "<S> one frequently used null model is the ensemble of graphs with the same set of degrees as the original network . in this paper </S>",
    "<S> we argue that this ensemble can be more than just a null model  </S>",
    "<S> it also carries information about the original network and factors that affect its evolution . by mapping out this ensemble in the space of some low - level network structure  in our case those measured by the assortativity and clustering coefficients </S>",
    "<S>  one can for example study how close to the valid region of the parameter space the observed networks are . </S>",
    "<S> such analysis suggests which quantities are actively optimized during the evolution of the network . </S>",
    "<S> we use four very different biological networks to exemplify our method . among other things , we find that high clustering might be a force in the evolution of protein interaction networks . </S>",
    "<S> we also find that all four networks are conspicuously robust to both random errors and targeted attacks . </S>"
  ]
}