{
  "article_text": [
    "acquisition of 3d surface data is continually becoming more commonplace and affordable , through a variety of modalities ranging from laser scanners to structured light to binocular and multi - view stereo systems .",
    "however , these data are often incomplete and noisy , and robust regularization is needed .",
    "when we are interested in a particular class of objects , such as human faces , we can use prior knowledge about the shape to constrain the reconstruction .",
    "this alleviates not only the problems of noise and incomplete data , but also occlusion . such priors can be learned by computing statistics on databases of registered 3d face shapes .",
    "accurate 3d face capture is important for many applications , from performance capture to tele - presence to gaming to recognition tasks to ergonomics , and considerable resources of data are available from which to learn a statistical prior on the shape of the human face ( e.g.  @xcite ) . in this paper",
    ", we propose a novel statistical model for the shape of human faces , and use it to fit to input 3d surfaces from different sources , exhibiting high variation in expression and identity , and severe levels of data corruption in the forms of noise , missing data and occlusions .",
    "we make the following specific technical contributions :    * a novel statistical shape space based on a wavelet decomposition of 3d face geometry and multilinear analysis of the individual wavelet coefficients . * based on this model , we develop an efficient algorithm for learning a statistical shape model of the human face in varying expressions . *",
    "we develop an efficient algorithm for fitting our model to static and dynamic point cloud data , that is robust with respect to highly corrupted scans .",
    "* we publish our statistical model and code to fit it to point cloud data  @xcite .",
    "our model has the following advantages .",
    "first , it results in algorithms for training and fitting that are highly efficient and scalable . by using a wavelet transform",
    ", we decompose a high - dimensional global shape space into many localized , decorrelated low - dimensional shape spaces .",
    "this dimensionality is the dominant factor in the complexity of the numerical routines used in both training and fitting .",
    "training on thousands of faces takes a few minutes , and fitting to an input scan takes a few seconds , both using a single - threaded implementation on a standard pc .",
    "second , it allows to capture fine - scale details due to its local nature , as shown in figure [ fig : noisydataegs ] , while retaining robustness against corruption of the input data .",
    "the wavelet transform decomposes highly correlated vertex coordinates into decorrelated coefficients , upon which multilinear models can be learned independently .",
    "learning many low - dimensional statistical models , rather than a single high - dimensional model , as used in  @xcite , greatly reduces the risk of over - fitting to the training data ; it avoids the curse of dimensionality .",
    "thus , a much higher proportion of the variability in the training data can be retained in the model . during fitting",
    ", tight statistical bounds can be placed on the model parameters for robustness , yet the model can still fit closely to valid data points .",
    "third , it is readily generalizable and extendable .",
    "our model requires _ no explicit segmentation _ of the face into parts ; the wavelet transform decomposes the surface hierarchically into overlapping patches , and the inverse transform recombines them . unlike manually decomposed part - based models , eg .",
    "@xcite , it requires no sophisticated optimization of blending weights and the decomposition is not class - specific .",
    "further , it can be easily extended to include additional information such as texture .",
    "this work is concerned with learning 3d statistical shape models that can be used in surface fitting tasks . to learn a statistical shape model , a database of shapes with known correspondence information",
    "is required .",
    "computing correspondences between a set of shapes is a challenging problem in general  @xcite .",
    "however , for models of human faces , correspondences can be computed in a fully automatic way using template deformation methods ( e.g.  @xcite ) .    the most related works to our work are part - based multilinear models that were recently proposed to model 3d human body shapes  @xcite . to define the part - based model ,",
    "a segmentation of the training shapes into meaningful parts is required .",
    "this is done manually by segmenting the human models into body parts , such as limbs .",
    "lecron et al .",
    "@xcite use a similar statistical model on human spines , that are manually segmented into its vertebrae .",
    "in contrast , our method computes a suitable hierarchical decomposition automatically , thereby eliminating the need to manually generate a meaningful segmentation .",
    "many statistical models have been used to analyze human faces .",
    "the first statistical model for the analysis of @xmath0d faces was proposed by blanz and vetter  @xcite .",
    "this model is called the morphable model , and uses principal component analysis ( pca ) to analyze shape and texture of registered faces , mainly in neutral expression .",
    "it is applied to reconstruct @xmath0d facial shapes from images  @xcite and @xmath0d face scans  @xcite .",
    "amberg et al .",
    "@xcite extend the morphable model to consider expressions , by combining it with a pca model for expression offsets with respect to the neutral expression geometry .",
    "an alternative way to incorporate expression changes is to use use a multilinear model , which separates identity and expression variations .",
    "this model has been used to modify expressions in videos  @xcite , or to register and analyze @xmath0d motion sequences  @xcite .",
    "multilinear models are mathematically equivalent to tensorfaces  @xcite applied to @xmath0d data rather than images , and provide an effective way to capture both identity and expression variations , and thus in section [ sec_eval ] we compare to a global multilinear model and show that our model better captures local geometric detail .",
    "blanz and vetter  @xcite manually segmented the face into four regions and learned a morphable model on each segment .",
    "the regions are fitted to the data independently and merged in a post - processing step .",
    "this part - based model was shown to lead to a higher data accuracy than the global morphable model .",
    "as part - based models are suitable to obtain good fitting results in localized regions , they have been used in multiple follow - up works , eg .  @xcite . while the model of kakadiaris et al .",
    "@xcite shares some similarities with our model , they use a fixed annotated face model , and wavelet transforms to compare facial geometry images .",
    "in contrast , we learn multilinear models on subdivision wavelet coefficients .",
    "all of the methods discussed so far model shape changes using global or part - based statistical models .",
    "in contrast , by applying a wavelet transform to the data first , statistical models can be constructed that capture shape variation in both a local and multi - scale way .",
    "such wavelet - domain techniques have been used extensively for medical imaging  @xcite , and brunton et al .",
    "@xcite proposed a method to analyze local shape differences of 3d faces in neutral expression in a hierarchical way .",
    "this method decomposes each face hierarchically using a wavelet transform and learns a pca model for each wavelet coefficient independently .",
    "this approach has been shown to capture more facial details than global statistical shape spaces .",
    "hence , in section [ sec_eval ] we compare to a wavelet - domain approach and show that our model better captures expression variation .",
    "we propose a method that combines this localized shape space with a multilinear model , thereby allowing to capture localized shape differences of databases of 3d faces of different subjects in different expressions .",
    "our statistical shape space for human faces consists of a multilinear model for each wavelet coefficient resulting from a spherical subdivision wavelet decomposition of a template face mesh .",
    "the wavelet transform takes a set of highly correlated vertex positions and produces a set of decorrelated wavelet coefficients .",
    "this decorrelation means that we can treat the coefficient separately and learn a distinct multilinear model for each coefficient .",
    "these multilinear models capture the variation of each wavelet coefficient over changes in identity and expression . in the following , we review the two components of our model .",
    "spherical wavelets typically operate on subdivision surfaces  @xcite following a standard subdivision hierarchy , giving a multi - scale decomposition of the surface .",
    "this allows coarse - scale shape properties to be represented by just a few coefficients , while localized fine - scale details are represented by additional coefficients .",
    "second generation wavelets can be accelerated using the lifting scheme  @xcite , factoring the convolution of the basis functions into a hierarchy of local lifting operations , which are weighted averages of neighboring vertices . when combined with subsampling ,",
    "the transform can be computed in time linear in the number of vertices .",
    "the particular wavelet decomposition we use  @xcite follows catmull - clark subdivision , and has been used previously for localized statistical models in multiple application domains  @xcite .",
    "the wavelet transform is a linear operator , denoted @xmath1 . for a @xmath0d face surface @xmath2 ,",
    "the wavelet coefficients are @xmath3 .      to statistically analyze a population of shapes , which vary in multiple ways , such as identity and expression for faces",
    ", one can use a multilinear model .",
    "in general , one constructs a multilinear model by organizing the training data into an @xmath4-mode tensor , where the first mode is the vector representation of each training sample , and the remaining modes contain training samples varied in distinct ways .",
    "we organize our set of parametrized training shapes into a @xmath0-mode tensor @xmath5 , where @xmath6 is the dimension of each shape , and @xmath7 and @xmath8 are the number of training samples in each mode of variation ; in our case , identity and expression .",
    "it would be straightforward to extend this model to allow for more modes , such as varying textures due to illumination changes , if the data were available .",
    "we use a higher - order singular value decomposition ( hosvd )  @xcite to decompose @xmath9 into @xmath10 where @xmath11 is a tensor called a multilinear model , and @xmath12 and @xmath13 are orthogonal matrices .",
    "the @xmath14-th mode product @xmath15 replaces each vector @xmath16 of @xmath17 in the direction of @xmath14-th mode by @xmath18 . to compute the orthogonal matrix @xmath19 ,",
    "@xmath9 is unfolded in the direction of @xmath20-nd mode to the matrix @xmath21 , where the columns of @xmath22 are the vectors of @xmath9 in direction of @xmath20-nd mode .",
    "the decomposition in ( [ eq : tensordecomposition ] ) is exact , if @xmath23 for all @xmath14 .",
    "if @xmath24 for at least one @xmath14 , the decomposition approximates the data .",
    "this technique is called truncated hosvd , and we use this to reduce the dimensionality of the training data .    the multilinear model represents a shape @xmath25 by @xmath26 where @xmath27 is the mean of the training data ( over all identities and expressions ) , and @xmath28 and @xmath29 are identity and expression coefficients . varying only @xmath30 changes identity while keeping the expression fixed , whereas varying only @xmath31 changes the expression of a single identity .",
    "[ cols=\"^ \" , ]     in this section , we discuss the process of fitting our learned model to an input oriented point cloud or mesh @xmath32 , which may be corrupted by noise , missing data or occlusions .",
    "the process is depicted graphically in figure [ fig : overviewfitting ] .",
    "we fit our model by minimizing a fitting energy that captures the distance between @xmath2 and @xmath32 , subject to the constraints learned in our training phase .",
    "we minimize the energy in a coarse - to - fine manner , starting with the multilinear weights of the coarse - scale wavelet coefficients , and refining the result by optimizing finer - scale multilinear weights .",
    "we optimize our model parameters to minimize an energy measuring the distance between @xmath2 and @xmath32 .",
    "our model parameters consist of the per - wavelet coefficient multilinear weights , @xmath33 , @xmath34 for @xmath35 , and a similarity transform ( rigid plus and uniform scaling ) @xmath36 mapping the coordinate frame of @xmath2 to the coordinate frame of @xmath32 .",
    "our fitting energy consists of four parts : a landmark term , a surface fitting term , a surface smoothing term , and a prior term .",
    "that is , @xmath37 where @xmath38 , @xmath39 , @xmath40 and @xmath41 are the landmark energy , surface fitting energy , surface smoothing energy and prior energy , respectively .",
    "we now describe each of these energies in turn .",
    "the landmark energy measures the euclidean distance between corresponding landmark sets @xmath42 and @xmath43 located on the model surface and input data , respectively .",
    "these landmarks may be obtained in a variety of ways , including automatically  @xcite , and do not restrict our method . in section [ sec_eval ] ,",
    "we demonstrate how our method performs using landmarks from multiple sources .",
    "the landmarks are in correspondence such that @xmath44 and @xmath45 and @xmath46 represent the equivalent points on @xmath2 and @xmath32 respectively . with this",
    ", we define our landmark energy as , @xmath47 where @xmath48 is a constant balancing the relative influence of landmarks against that of the rest of the surface .",
    "the surface fitting energy measures the point - to - plane distance between vertices in @xmath2 and their nearest neighbors in @xmath32 .",
    "that is , @xmath49 where @xmath50 is the projection of @xmath51 into the tangent plane of @xmath52 , where @xmath53 is the nearest neighbor of @xmath51 .",
    "the distances are weighted by @xmath54 where @xmath55 is a threshold on the distance to the nearest neighbor , providing robustness to missing data .",
    "we compute nearest neighbors using ann  @xcite .",
    "the prior energy restricts the shape to stay in the learned shape space , providing robustness to both noise and outliers .",
    "we avoid introducing undue bias to the mean shape via a hyper - box prior  @xcite , @xmath56 where @xmath57 restricts each component of @xmath33 to be within a constant amount @xmath58 of the same component of the mode - mean @xmath59 , and similarly for each component of @xmath34 .",
    "the smoothing energy is the bi - laplacian energy , which penalizes changes in curvature between neighboring vertices .",
    "it is needed due to the energy minimization algorithm , described in section [ sec_fitting_min ] , which optimizes each multilinear wavelet independently . without a smoothing energy , this can result in visible patch boundaries in the fitted surface , as can be seen in figure [ fig : smoothingdiff ] .",
    "formally , we write @xmath60 where @xmath61 is the double - umbrella discrete approximation of the bi - laplacian operator  @xcite , and @xmath62 is a constant weight .    the smoothing energy poses a trade - off : visually pleasing smooth surfaces versus fitting accuracy and speed .",
    "leaving out @xmath40 allows the energy minimization to get closer to the data ( as expected ) , and leads to faster fitting due to the energy being more localized .",
    "hence , we retain the option of not evaluating this energy in case the scenario would favor close fitting and fast performance over visually smooth results .",
    "we use either @xmath63 or @xmath64 in all our experiments .",
    "section [ sec_eval ] discusses this trade - off in more concrete terms .",
    "we minimize ( [ eqn_fit_energy ] ) in a two - step procedure . in the first step ,",
    "we iteratively minimize @xmath65 with respect to @xmath36 and the multilinear weights of each wavelet coefficient .",
    "this rigidly aligns the model and the data , and coarsely deforms the surface to fit the landmarks , giving a good initialization for subsequent surface fitting .",
    "we solve for @xmath36 that minimizes @xmath38 , given the landmark positions @xmath66 and @xmath67 .",
    "this involves solving a small over - determined linear system .",
    "then , we optimize @xmath33 and @xmath34 for @xmath35 to minimize @xmath68 .",
    "figure [ fig : overviewfitting ] ( bottom , middle ) shows the result of landmark fitting for a given input data .",
    "in the second step , we fix @xmath36 and minimize ( [ eqn_fit_energy ] ) with respect to only the multilinear weights .",
    "this deforms the surface so that it closely fits the input data @xmath32 .",
    "figure [ fig : overviewfitting ] ( bottom , right ) shows the final fitting result .    the energies @xmath38 , @xmath39 and @xmath40 are nonlinear with respect to the multilinear weights , and we minimize them using the l - bfgs - b  @xcite quasi - newton method .",
    "this bounded optimization allows the prior ( [ eqn_prior_energy ] ) to be enforced simply as bounds on the multilinear weights .",
    "the hierarchical and decorrelating nature of the wavelet transform allows us to minimize the energies separately for each multilinear model in a coarse - to - fine manner . during initialization ,",
    "we recompute @xmath36 and optimize the multilinear weights iteratively at each level of wavelet coefficients . during surface",
    "fitting , nearest neighbors are recomputed and the multilinear weights optimized iteratively at each level . during initialization , we allow greater variation in the model , @xmath69 , because we assume the landmarks are not located on occlusions . during surface",
    "fitting , we restict the shape space further , @xmath70 , unless the particular weight component is already outside this range from the initialization .",
    "fitting many low - dimensional local multilinear models is more efficient than fitting a single high - dimensional global multilinear model , because the dimensionality of the variables to be optimized is the dominant factor in the complexity of the quasi - newton optimization , which achieves super - linear convergence by updating an estimate of the hessian matrix in each iteration .",
    "for a problem size @xmath71 the hessian contains @xmath72 unique entries , which favors solving many small problems even if the total number of variables optimized is greater .",
    "this is confirmed experimentally in section [ sec_eval ] .",
    "further , each multilinear model has compact support on @xmath2 , which reduces the number of distances that must be computed in each evaluation of ( [ eqn_surf_energy ] ) and its gradient .      as an application of our shape space ,",
    "we show how a simple extension of our fitting algorithm can be used to track a facial motion sequence . to the first frame",
    ", we fit both identity and expression weights .",
    "subsequently , we fix identity weights and only fit expression weights .",
    "this ensures that shape changes over the sequence are only due to expression , not identity",
    ". a more elaborate scheme , which averages the identity weights , would also be feasible . to avoid jitter",
    ", we introduce a temporal smoothing term on the vertex positions .",
    "approaches based on global multilinear models often place a temporal smoothing term on the expression weights themselves  @xcite since these are usually much lower dimension than the surface @xmath2 . in our case , the combined dimensionality of all expression weights is equal to that of the vertex positions , so no efficiency is to be gained by operating on the weights rather than the vertex positions .",
    "further , placing a restriction on the vertex positions fits easily into our energy minimization .",
    "we use a simple penalty on the movement of the vertices @xmath73 between frames .",
    "this is easily incorporated into our fitting algorithm by simply adding a euclidean distance penalty to our energy function ( [ eqn_fit_energy ] ) during surface fitting : @xmath74 where @xmath75 is a constant balancing allowing the surface to move versus reducing jitter .",
    "* training data : * for a training database , we use the bu3dfe database  @xcite registered using an automatic template - fitting approach  @xcite with ground truth landmarks .",
    "this database contains @xmath76 subjects in @xmath77 expressions levels each .",
    "we successfully registered @xmath78 subjects in all expressions and used this for training in our experiments .    * test data : * to test our fitting accuracy we use @xmath79 scans from the bosphorus database  @xcite including variation in identity , expression and types of occlusions .",
    "we specifically do _ not _ test on scans from the same database we use for training to avoid bias .",
    "further , the bosphorus scans typically have higher noise levels than those in bu3dfe , and contain occlusions .",
    "this database contains landmarks on each scan ; we use the subset of those shown in figure [ fig : overviewfitting ] present on a given surface ( not blocked by an occlusion ) . in section",
    "[ sec_eval_motion ] , we show the performance of our method when tracking facial motion sequences from the bu4dfe database  @xcite with landmarks automatically predicted using an approach based on local descriptors and a markov network  @xcite .    * comparison : * we compare our fitting results to the localized pca model  @xcite and the global multilinear model  @xcite .",
    "all three models are trained with the same data , with the exception that because the local pca model does not model expression variation , we train it separately for each expression and give it the correct expression during fitting . the other two are given landmarks for fitting .",
    "* performance : * we implemented our model , both training and fitting , in c++ using standard libraries .",
    "we ran all tests on a workstation running windows with an intel xeon e31245 at @xmath80 .",
    "training our model on @xmath81 face shapes each with @xmath82 vertices takes @xmath83 using a single - threaded implementation . in practice",
    "we found our training algorithm to scale approximately linearly in the number of training shapes .",
    "fitting takes @xmath84 on average with @xmath64 , and @xmath85 with @xmath63 , for a surface with approximately @xmath86 vertices ( sections [ sec_eval_noisy ] and [ sec_eval_occluded ] ) . for the motion sequences with approximately @xmath86 vertices per frame ( section [ sec_eval_motion ] )",
    ", fitting takes @xmath87 per frame on average without smoothing and @xmath88 with smoothing .",
    "the global multilinear model takes @xmath89 for fitting to a static scan . a single - threaded implementation of the local pca model takes @xmath90 due to the sampling - based optimization , which avoids local minima .",
    "+    in this section , we demonstrate our model s ability to capture fine - scale detail in the presence of identity and expression variation , and high noise levels .",
    "we fit it to @xmath91 models ( @xmath92 identities in up to @xmath93 expressions ) from the bosphorus database  @xcite .",
    "we measure the fitting error as distance - to - data , and the per - vertex median errors are shown for all three models in figure [ fig : noisydataquant ] ( left ) .",
    "our model has a greater proportion of sub - millimeter errors than either of the other models .",
    "specifically , the local pca and the global multilinear have @xmath94 and @xmath95 , respectively , of vertices with error @xmath96 , whereas our model has @xmath97 with @xmath63 and @xmath98 with @xmath64 .",
    "figure [ fig : noisydataquant ] ( right ) shows cumulative error plots for all three methods for vertices in the characteristic detail region of the face , which is shown next to the plot .",
    "this region contains prominent facial features with the most geometric detail .",
    "we see that our model is more accurate than previous models in this region and has many more sub - millimeter errors ; the local pca and global multilinear have @xmath99 and @xmath100 of errors @xmath96 , respectively , whereas our model has @xmath101 with @xmath63 and @xmath102 with @xmath64 .",
    "this shows that our model has improved accuracy for fine - scale detail compared to existing models , in particular in areas with prominent features and high geometric detail .",
    "figures [ fig : smoothingdiff ] and [ fig : noisydataegs ] show examples of fitting to noisy scans of different subjects in different expressions .",
    "these scans contain acquisition noise , missing data and facial hair .",
    "figure [ fig : smoothingdiff ] ( left ) shows a surprise expression and close - ups of the nose region ; our reconstruction both @xmath63 and @xmath64 capture significantly more fine - scale detail than previous models .",
    "the right part of the figure demonstrates the effect of the smoothing energy in preventing faint grid artifacts appearing in the reconstruction due to the independent optimization scheme .",
    "figure [ fig : noisydataegs ] shows two subjects in fear and happy expressions .",
    "we again see the increased accuracy of our model in terms of fine - scale detail on facial features compared to previous models .",
    "note the accuracy of the nose and mouth shapes in all examples compared to the other models , and the accurate fitting of the underlying face shape in the presence of facial hair .",
    "further note how our model captures the asymmetry in the eyebrow region for the fear expression .",
    "+    in this section , we demonstrate our model s robustness to severe data corruptions in the form of occlusions .",
    "we fit all three models to @xmath103 scans ( @xmath92 subjects , @xmath104 types of occlusions ) from the bosphorus database  @xcite .",
    "figure [ fig : occldata ] ( top right ) shows the cumulative error for all three models .",
    "since distance - to - data is not a valid error measure in occluded areas , we apply different masks , shown next to the error plot , depending on the type of occlusion so that only unoccluded vertices are measured . clockwise from top - left : the mask used for eye , glasses , mouth and hair occlusions . from the cumulative error curves",
    ", we see that our model retains greater accuracy in unoccluded parts of the face than previous models .    the bottom two rows of figure [ fig : occldata ] show example reconstructions in the presence of severe occlusions .",
    "all models show robustness to occlusions and reconstruct plausible face shapes , but our model provides better detail in unoccluded parts of the face than previous models ( see the mouth and chin in the first row , and the nose in the second row ) . for these examples ,",
    "we show our reconstruction with @xmath63 .      in this section",
    ", we show our model s applicability to @xmath0d face tracking using the simple extension to our fitting algorithm described in section [ sec_fitting_track ] .",
    "figure [ fig : motiondata ] shows some results for a selection of frames from three sequences from the bu4dfe database  @xcite .",
    "we see that , as for static scans , high levels of facial detail are obtained , and even the simple extension of our fitting algorithm tracks the expression well . since landmarks are predicted automatically for these sequences , the entire tracking is done automatically .",
    "this simple tracking algorithm is surprisingly stable .",
    "videos can be found in the supplemental material .",
    "we have presented a novel statistical shape space for human faces .",
    "our multilinear wavelet model allows for reconstruction of fine - scale detail , while remaining robust to noise and severe data corruptions such as occlusions , and is highly efficient and scalable .",
    "the use of the wavelet transform has both statistical and computational advantages . by decomposing the surfaces into decorrelated wavelet coefficients",
    ", we can learn many independent low - dimensional statistical models rather than a single high - dimensional model .",
    "lower dimensional models reduce the risk of overfitting , which allows us to set tight statistical bounds on the shape parameters , thereby providing robustness to data corruptions while capturing fine - scale detail .",
    "model dimensionality is the dominant factor in the numerical routines used for fitting the model to noisy input data , and fitting many low - dimensional models is much faster than a single high - dimensional model even when the total number of parameters is much greater .",
    "we have demonstrated these properties experimentally with a thorough evaluation on noisy data with varying expression , occlusions and missing data .",
    "we have further shown how our fitting procedure can be easily and simply extended to give stable tracking of @xmath0d facial motion sequences .",
    "future work includes making our model applicable for real - time tracking .",
    "virtually all aspects of our fitting algorithm are directly parallelizable , and an optimized gpu implementation could likely achieve real - time fitting rates , in particular for tracking , where only expression weights need to be optimized every frame .",
    "such high - detail real - time tracking could have tremendous impact in tele - presence and gaming applications .",
    "i.  kakadiaris , g.  passalis , g.  toderici , m.  murtuza , y.  lu , n.  karamelpatzis , and t.  theoharis .",
    "three - dimensional face recognition in the presence of facial expressions : an annotated deformable model approach .",
    ", 29(4):640649 , 2007 .",
    "g.  tam , z .- q .",
    "cheng , y .- k .",
    "lai , f.  langbein , y.  liu , d.  marshall , r.  martin , x .- f .",
    "sun , and p.  rosin .",
    "registration of 3d point clouds and meshes : a survey from rigid to nonrigid .",
    ", 19(7):11991217 , 2013 ."
  ],
  "abstract_text": [
    "<S> we present a statistical model for @xmath0d human faces in varying expression , which decomposes the surface of the face using a wavelet transform , and learns many localized , decorrelated multilinear models on the resulting coefficients . </S>",
    "<S> using this model we are able to reconstruct faces from noisy and occluded @xmath0d face scans , and facial motion sequences . </S>",
    "<S> accurate reconstruction of face shape is important for applications such as tele - presence and gaming . </S>",
    "<S> the localized and multi - scale nature of our model allows for recovery of fine - scale detail while retaining robustness to severe noise and occlusion , and is computationally efficient and scalable . </S>",
    "<S> we validate these properties experimentally on challenging data in the form of static scans and motion sequences . </S>",
    "<S> we show that in comparison to a global multilinear model , our model better preserves fine detail and is computationally faster , while in comparison to a localized pca model , our model better handles variation in expression , is faster , and allows us to fix identity parameters for a given subject . </S>"
  ]
}