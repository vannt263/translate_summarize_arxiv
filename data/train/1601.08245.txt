{
  "article_text": [
    "large hadron collider ( lhc ) at cern is the highest energy collider ever constructed .",
    "it consists of two counter - circulating proton beams made to interact in four locations around a 17 mile ring straddling the border between switzerland and france .",
    "it is by some measures the largest man - made scientific device on the planet .",
    "the goal of the lhc is to probe the basic building blocks of matter and their interactions . in 2012",
    ", the higgs boson was discovered by the cms and atlas collaborations .",
    "experimentally , we collide proton beams at the center of our detectors and , by measuring the energy and momentum of the escaping particles , infer the existence of massive particles that were created and decayed in the pp collision and measure those massive particles properties . in all cases ,",
    "track reconstruction , i.e. , the determination of the trajectories of charged particles , plays a key role in identifying particles and measuring their charge and momentum .",
    "the track reconstruction as a whole is the most computationally complex and time consuming , sensitive to increased activity in the detector , and traditionally , least amenable to parallelization .",
    "the speed of reconstruction has a direct impact on how much data can be stored from the 40 mhz collisions rate .",
    "the most cpu - intensive part of the event selection in the online trigger process is track reconstruction , to the point that it can only be applied to a few % of the input event rate . at the same time",
    ", the tracker is the most precise instrument in cms .",
    "tracking is thus the essential tool in making surgical decisions in the online selection to optimally use the limited output bandwidth for interesting physics events .",
    "the speed of track reconstruction software thus limits both the total output rate of the experiments via the first cap , and the surgical precision with which interesting events can be selected via the second cap .",
    "our research aims to lift those caps by vastly speeding up the online tracking reconstruction .",
    "the large time spent in track reconstruction will become even more important in the hl - lhc era of the large hadron collider , where the increase in event rate will lead to an increase in detector occupancy ( `` pile - up '' , pu ) , leading to an exponential gain in time taken to do track reconstruction , as can be seen in fig .",
    "[ fig : pileup ] . in the figure",
    ", pu25 corresponds to the data taken during 2012 , and pu140 corresponds to the low end of estimates for the hl - lhc era .",
    "clearly this research will become increasingly important during this era .",
    "a correlated issue is the change in computing architectures in the last decade .",
    "around 2005 , the computing processor market reached a turning point : power density limitations in chips ended the long - time trend of ever - increasing clock speeds , and our applications no longer immediately run exponentially faster on subsequent generations of processors .",
    "this is true even though the underlying transistor count continues to increase per moore s law .",
    "increases in processing speed such as those required by the time increases in fig .",
    "[ fig : pileup ] will no longer come ` for free ' from faster processors .",
    "new processors instead are aggregates of ` small cores ' that in toto still show large performance gains from generation to generation , but their usage requires a re - work of our software to exploit .",
    "the processors in question include arm , gpgpu and the intel xeon phi ; in this work we target the xeon phi architecture .",
    "to realize the new performance gains , a change is required to move from the sequential applications of today to vectorized , parallelized applications of tomorrow .",
    "the algorithm we are targeting for parallelization is a kalman filter ( kf ) based algorithm  @xcite .",
    "kf - based tracking algorithms are widely used since they naturally include estimates of scattering along the trajectory of the particle due to multiple scattering off massive detectors .",
    "other algorithms , more naturally suited to parallelization and coming from the image processing community , have been explored by others .",
    "these include hough transforms and cellular automata , among others ( see , for instance ,  @xcite . )",
    "however , these are not the main algorithms in use at the lhc today , whereas there is extensive understanding how kf algorithms perform .",
    "kf algorithms have proven to be robust and perform well in the difficult experimental environment of the lhc . by porting these algorithms to parallel architectures , we aim to port this robust tool to new architectures .",
    "past work by our group has shown progress in sub - stages of the kf algorithm in simplified detectors ( see , e.g. our presentations at acat2014  @xcite and chep2015  @xcite ) .",
    "[ fig : scaling ] shows a result from the track building part of the problem , where we decide which hits to group together as coming from the passage of a single charged particle , as a function of the increased usage of the processors vector registers .",
    "the black line shows `` ideal behavior '' - perfect scaling , and the blue line shows our measured results .",
    "we observe a significant speedup compared to the baseline , but still room for improvement with respect to the ideal behavior .",
    "all results are for the xeon phi .",
    "we have now implemented an end - to - end algorithm with a semi - realistic detector model .",
    "this talk represents a status report .",
    "the computational problem of kalman filter - based tracking consists of a sequence of matrix operations on matrices of sizes from @xmath0 up to @xmath1 . to allow maximum flexibility for exploring simd operations on small - dimensional matrices , and to decouple the specific computations from the high level algorithm ,",
    "we have developed a new matrix library , matriplex .",
    "the matriplexmemory layout is optimized for the loading of vector registers for simd operations on a set of matrices .",
    "matriplexincludes a code generator for generation of optimized matrix operations supporting symmetric matrices and on - the - fly matrix transposition .",
    "patterns of elements which are known by construction to be zero or one can be specified , and the resulting generated code will be optimized accordingly to reduce unnecessary register loads and arithmetic operations .",
    "the generated code can be either standard c++or simple intrinsic macros that can be easily mapped to architecture - specific intrinsic functions .",
    "we have performed extensive studies of the performance of our software .",
    "both the physics performance and the code performance were examined . for the latter",
    ", we used the intel vtune  @xcite suite of tools to identify bottlenecks and understand the impacts of our optimization attempts .",
    "in particular , as can be expected , we determined that memory management is of critical importance . to this effect",
    "we describe below several studies to optimize memory performance , and discuss the results of these studies .      [ cols= \" < , > , > , > , > , > , > , > \" , ]     the size of the data structures used in our algorithm have a crucial impact on the timing performance .",
    "in particular , the data structures representing the energy deposits in the detector ( the `` hits '' ) and the reconstructed particle trajectories ( the `` tracks '' ) must be optimized in size to fit into the fastest cache memory .",
    "object - oriented data structures require more memory than arrays .",
    "therefore , we replaced the kalman covariance matrices with basic c - style arrays rather than c++-style classes .",
    "these changes allowed us to reduce the size in memory of the track objects by 20% and the hit object by 40% .",
    "[ tab : scaling ] shows the result of these studies .",
    "the table only shows xeon numbers ; xeon phi performance is similar .",
    "in addition to moving to c - style data structures , we optimized the contents of the data structures",
    ". our original implementation of these objects were designed for algorithmic ease of use and contained data members not strictly needed for the track reconstruction . for instance , monte carlo truth information , _",
    "i.e. _ , information about how the trajectories were generated , were stored in the hit objects .",
    "the track objects contained ( duplicate ) copies of the hits themselves , rather than smaller references to the hits in their original locations .",
    "we rewrote the data structures to optimize performance and maintain ease of use by carefully considering what was needed for physics output only and keeping auxiliary information in associated data structures .",
    "we find significant speed - ups from the reduced data formated ( labeled `` r.d.f '' in the table ) .",
    "we also find that with these changes , the improvement of the ce studies is reduced ; presumably since the amount of memory churn overall , which the ce improves , has now been globally reduced .",
    "figure  [ fig : amdahl ] shows the parallelization performance scaling of our code on the xeon architecture .",
    "the plot on the right show the time to process 20,000 tracks as a function of the number of threads .",
    "the curve in green represent ideal scaling from the first data point .",
    "the blue and red curves show two different ways of distributing the data across threads . on the right",
    "the same data is plotted but now as a function of @xmath2 ; this figure can be used to extract the serial fraction of the code . according to amdahl s law , the time spent on @xmath3 threads consists of a serial fraction @xmath4 and a parallel fraction @xmath5 multiplied by the time per thread , @xmath6 .",
    "@xmath7\\ ] ] the @xmath4 parameter can be extracted from the data by fitting to this function , and results are shown for different versions of our code . in the figure , a big improvement was found by optimizing how data structures are re - initialized on each event , leading a reduction of the serial fraction from 26% to 9% .",
    "there is a significant residual contribution to non - ideal scaling due to variation of occupancy within threads : some threads simply take longer than others . in our group",
    "there is work ongoing to define strategies for an efficient ` next in line ' approach or a dynamic reallocation of thread resources to even out timing across threads .",
    "we have made significant progress in parallelized and vectorized kalman - filter - based tracking r&d on xeon and xeon phi architectures .",
    "we have developed a good understanding of bottlenecks and limitations of our implementation .",
    "new versions of the code are faster and exhibit scaling closer to ideal performance .",
    "we are continuing to pursue new ideas to further improve performance    though it was not discussed in the talk , we have also developed tools to process fully realistic data , with encouraging preliminary results .",
    "the project is solid and promising ; however , much work remains .",
    "this work was supported by the u.s . national science foundation .",
    "99 r.  fruehwirth , `` application of kalman filtering to track and vertex fitting , '' http://dx.doi.org/10.1016/0168-9002(87)90887-4[_nucl .",
    "instrum .",
    "a _ * 262 * ( 1987 ) 444450 ] . v.  halyo , p.  legresley , p.  lujan , v.  karpusenko , and a.  vladimirov , `` first evaluation of the cpu , gpgpu and mic architectures for real time particle tracking based on hough transform at the lhc , '' _ journal of instrumentation _ * 9 * no .  04 , ( 2014 )",
    "http://stacks.iop.org/1748-0221/9/i=04/a=p04005 .",
    "g.  cerati _ et al .",
    "_ , traditional track with kalman filter on parallel architectures , proceedings of acat 2014 , arxiv:1409.8213 ( 2014 ) g.  cerati _ et al .",
    "_ , kalman filter tracking on parallel architectures , proceedings of chep 2015 , arxiv:1505.04540 ( 2015 ) ."
  ],
  "abstract_text": [
    "<S> power density constraints are limiting the performance improvements of modern cpus . to address this </S>",
    "<S> we have seen the introduction of lower - power , multi - core processors such as gpgpu , arm and intel mic . to stay within the power density limits but still obtain moore s law performance / price gains </S>",
    "<S> , it will be necessary to parallelize algorithms to exploit larger numbers of lightweight cores and specialized functions like large vector units . </S>",
    "<S> track finding and fitting is one of the most computationally challenging problems for event reconstruction in particle physics . at the high - luminosity large hadron collider ( hl - lhc ) , for example , this will be by far the dominant problem . </S>",
    "<S> the need for greater parallelism has driven investigations of very different track finding techniques such as cellular automata or hough transforms . </S>",
    "<S> the most common track finding techniques in use today , however , are those based on the kalman filter . </S>",
    "<S> significant experience has been accumulated with these techniques on real tracking detector systems , both in the trigger and offline . </S>",
    "<S> they are known to provide high physics performance , are robust , and are in use today at the lhc . </S>",
    "<S> we report on porting these algorithms to new parallel architectures . </S>",
    "<S> our previous investigations showed that , using optimized data structures , track fitting with kalman filter can achieve large speedups both with intel xeon and xeon phi . </S>",
    "<S> we report here our progress towards an end - to - end track reconstruction algorithm fully exploiting vectorization and parallelization techniques in a realistic experimental environment . </S>"
  ]
}