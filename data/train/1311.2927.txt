{
  "article_text": [
    "loops with loop carried @xmath0s having cycle free data dependence graph(ddg ) have been successfully dealt with in the literature@xcite , however few researchers have considered loops having cycles in ddg@xcite .",
    "fewer efforts have considered loops with variable distance data dependence(@xmath1 ) and ddgs with or without cycles@xcite . unlike the case of constant distance , the solutions of ldes for @xmath1 do not seem to have a regular structure among dependent iterations .",
    "this is probably the reason for not enough research reported in this area .",
    "+ our approach builds on a two variable lde for which parametric solutions are well known @xcite .",
    "we have analyzed the parametric solutions and have developed a mathematical formulation that captures the structure among dependent iterations .",
    "the structure leads to partitioning of the iteration space where each component of the partition represents iterations which have to be executed sequentially and distinct components are parallelizable .",
    "further , bounds on the number and size of components have been obtained .",
    "examining the structure of a component , we show that all iterations of the component can be generated from a single iteration , called its seed .",
    "the representation of the partition is consequently reduced to a set of seeds .",
    "this set is used as a basis to generate the components dynamically in a demand driven manner which can lead to schedules .",
    "+ we have extended this approach to partition the iteration space for multiple ldes by combining the components of partitions of the individual ldes .",
    "the correctness of the non - trivial composition of partitions to form the resultant partition is proved .",
    "we have presented algorithms for all important formulations of our work .",
    "the applicability of our approach rests on its ability to extract exploitable parallelism from @xmath1 loops with multiple ldes .",
    "experimental evaluation of effectiveness of our approach requires existence of @xmath1 loops with large number of ldes . since we could not find such loops in the benchmark programs , we chose to create multiple ldes with random coefficients for our experimentation .",
    "we present an algorithm to generate iteration schedule .",
    "results show that loops with @xmath1 offer reasonable parallelism which reduces as the number of ldes increase . to increase the parallelism in case of large number of ldes we have formed an alternate partition using a heuristic .",
    "this heuristic shows non trivial improvement in parallelism .",
    "the approach is motivated by the following example . consider a loop having @xmath0 over iteration space r=[-8,7 ] .    ....",
    "for(i = -8 ; i < 8 ; i++ ) { s1 : g[i ] = ......... ;    s2 : ......... = g[i + 3 ] ; } ....    the @xmath0 is `` + 3 '' and leads to a 3 element partitioning of iteration space for parallelization as follows : \\ { \\{-8,-5,-2,1,4,7 } , \\{-7,-4,-1,2,5 } , \\{-6,-3,0,3,6 } } .",
    "+ consider the following @xmath1 loop .    ....",
    "for(i = -8 ; i < 8 ; i++ ) { s1 : g[2i + 1 ] = ......... ;    s2 : ......... = g[3i + 6 ] ; } ....    the dependent iteration pairs of the loop are modelled by lde : @xmath2 .",
    "the solutions of the lde i.e. dependent iteration pairs over r=[-8,7 ] are : \\ { ( -8,-7 ) , ( -5,-5 ) , ( -2,-3 ) , ( 1,-1 ) , ( 4,1 ) , ( 7,3 ) } .",
    "this leads to partition , @xmath3 , of r as shown in figure [ partition ] where iterations are nodes and edges represent dependence between them .",
    "each connected component(cc ) , @xmath4 , is a set of dependent iterations which should be executed sequentially .",
    "different ccs can be executed parallely without synchronization .",
    "+ partitioning the iteration space exposes all the parallelism naturally present in the loop . here",
    "@xmath5 is the maximum number of parallely executable ccs and the size of largest cc , max(@xmath6 ) is 3 . among many possible semantically equivalent schedules a realizable 4-thread parallel schedule for the loop",
    "is : + \\{\\{-8,-7,-6,-5},\\{-3,-2,3,7},\\{-4,-1,1,4},\\{0,2,5,6}}. + this example though simple , brings out the possibility of parallelizing a @xmath1 loop .",
    "+      our approach rests on using solutions of ldes .",
    "+ without loss of generality , an lde of the form @xmath7 , in this paper is assumed to be normalized where @xmath8 and @xmath9 .",
    "+ given an iteration space and a set of ldes , we use the term * precise dependence(pd ) * to denote the collection of all solutions of all ldes in the iteration space .",
    "a 2 variable lde characterizes @xmath1 , except for the case @xmath10 and @xmath11 where it characterizes @xmath0 .",
    "iterations which do not appear in pd are independent iterations .",
    "a 2 variable lde characterizes pair of 1 dimensional array access in a single non - nested loop .",
    "this section presents structure of p and efficient generation of pd for it .",
    "consider the loop :    .... for(i = lb ; i < ub ; i++ ) { s1 g[ai ] = ......... ;    s2 ......... = g[c - bi ] ; } ....    referring to figure [ partition ] and lde @xmath2 , all solutions of the lde can be derived using parametric solution \\{-5 + 3 t , -5 + 2 t } , where @xmath12 is an integer@xcite .",
    "if ( x , y ) is a solution of lde and x precedes y in iteration order then x is called as source and y is called as sink . using parametric solution it is possible to compute source of a given sink and sink of a given source .",
    "consider @xmath13 , @xmath14 is obtained for t = 2 .",
    "similarly using @xmath15 , @xmath16 is obtained .",
    "hence ( 1,-1 ) and ( 4,1 ) are solutions of lde .",
    "since 1(source in one solution and sink in other ) is an iteration common to both solutions \\{-1,1,4 } is a cc .",
    "the as possible extensions \\{8.5,4 } and \\{-1,-2.33 } are not integer solutions so the size of @xmath17 .",
    "iteration 2 can be neither a sink nor a source , hence 2 is independent iteration .",
    "+   + observations based on aforementioned parametric solution of lde @xmath7 are : + * an iteration which is a source as well as a sink extend a cc . * + * an iteration which either source or sink but not both does not extend a cc . * + * an iteration which neither source nor sink is and independent iteration forming singleton cc . * +      the objective of this section is to formulate the structure of a cc and relationship between its constituent iterations .",
    "the solutions to lde in parametric form @xmath18 , where m is an integer and @xmath19 is a particular solution form ccs of length 2 .",
    "+   + longer ccs are formed if m is a multiple of a or b. as @xmath20 is a common iteration the cc is @xmath21 .",
    "+   + the general structure of ccs for and lde , where m is not a multiple of a or b is : + @xmath22 +   + * seed is a representative iteration of a cc which can generate a cc . * for a single lde single loop case all iterations are seeds of corresponding ccs.if @xmath23 is not an integer cc and seeds are computed using particular solution @xmath24 of lde as : @xmath25 +   + * the seeds for ccs can be computed using the aforementioned structure . *      this",
    "sub - section shows bounds on number @xmath26 and length @xmath27 of ccs for lde in a given range r = [ l , u ] .",
    "+    [ arch_lemma_3 ] number of ccs of length @xmath28 is @xmath29 .",
    "+    every solution of lde is a cc of length 2 .",
    "the number of solutions in the range r is @xmath29 .",
    "hence proved .",
    "number of singleton ccs is @xmath30 .",
    "number of ccs of length @xmath31 ( including sub - ccs of length @xmath32 .",
    "+    proof by induction : number of ccs of length @xmath28 is @xmath29 using lemma [ arch_lemma_3 ] .",
    "+ assumption : number of ccs of length @xmath33 is @xmath34 . + to prove that : number of ccs of length @xmath35 is @xmath36 .",
    "+ an end element of a cc of length k has a form @xmath37 .",
    "+ if @xmath38 is a multiple of a the element @xmath39 adds to the cc .",
    "+ the maximum number of elements having pattern @xmath40 [ lb , ub ] is @xmath36 . hence proved .",
    "+    let @xmath41 be a positive integer such that @xmath42 then the upper bound on length of ccs is @xmath43 .",
    "+   + the upper bound on number of non singleton ccs is : @xmath44 + @xmath45 +   + this gives a closed - form expression for the bounds , a useful input for scheduling .",
    "in multidimensional arrays , subscripts are separable if indices do not occur in other subscripts .",
    "a loop is separable if subscripts of all arrays in it ( excluding arrays which are only read but not written ) are separable .",
    "we construct and prove precise dependence theory for simple loops first and then extend it to all separable loops .",
    "precise dependence information is obtained by solving lde s and obtaining the dependence graph for the given range of the loop . a node from each connected component in undirected dependence graph is selected and stored for generation of the cc and scheduling purpose ( here onwards referred as seed ) .",
    "even though we present a general method for parallelizing and scheduling any type of separable loop , we demonstrate that some special cases have interesting properties which can be exploited for efficiency and effectiveness .",
    "consider a loop @xmath46 having _ n _ pairs of statements such that each pair has exactly one common array access _",
    "( if a statement has more than one common array access , it can be broken into multiple statements having exactly one common array access ) _ , construct a lde per pair ( construction is shown in previous section ) .",
    "let the lde s be lde-1,lde-2,lde-3 , ...",
    "lde - n for @xmath47 pair of statements respectively .",
    "let @xmath48 be the solutions of the lde-1,lde-2,lde-3, ...",
    ",lde - n respectively .",
    "@xmath49    [ lemma_1 ] all the dependent iterations in @xmath46 are elements of s. ( i.e if iterations @xmath50 and @xmath51 are dependent then @xmath52 or @xmath53 .",
    "proof by contradiction .",
    "assume there is a pair of iteration @xmath54 and @xmath55 which are dependent but @xmath56 and @xmath57 .",
    "@xmath54 and @xmath55 access same memory location of atleast one array ( say array _ a _ ) and for some statements @xmath58 and @xmath59 .",
    "this implies @xmath60 or @xmath61 is a solution of lde that represents @xmath58 and @xmath59 .",
    "hence @xmath52 or @xmath53 .",
    "[ lemma_2 ] all elements in _ s _ represent dependent iterations in @xmath46 .",
    "( i.e if @xmath52 or @xmath53 then iterations @xmath50 and @xmath51 are dependent .",
    "proof by contradiction .",
    "assume there is an element @xmath62 but @xmath54 and @xmath55 are not dependent . if @xmath62 then @xmath63 for some @xmath64 pair of statements ( @xmath65 ) and this implies @xmath54 and @xmath55 are dependent .",
    "[ pd_thm_single_loop ] precise dependency information for @xmath46 captures all parallelism present at iteration level granularity .    from lemma [ lemma_1 ] and [ lemma_2 ] .",
    "when dependencies come from two or more lde s , solutions combine to produce dag s which represent the dependence graph of loop .",
    "seeds can be classified as , * common seeds : * seeds that occur in solutions of more than one lde and * unique seeds : * seeds that occur in solution of exactly one lde .",
    "dependence graph can be partitioned into connected components having atleast one node which is common seed for any of the @xmath66 sets of _ k _ lde s each ( where @xmath67 ) .",
    "common seeds of _ k _ lde s can be obtained by intersection of common seeds of @xmath68 disjoint pair of lde s .",
    "common seeds are iterations which are common to solutions of 2 or more ldes",
    ". consider solutions of 2 ldes : @xmath69 and @xmath70 .",
    "common seeds are formed when : @xmath71 or @xmath72 or @xmath73 or @xmath74 +   + common seeds are intersection of solutions of multiple ldes .",
    "+ for n ldes there are @xmath75 ( @xmath76 ) ways of forming common seeds .      a set of seeds is known as unique common seeds if all seeds in the set are common seeds and no two seeds are from the same connected component .",
    "consider a loop in which dependent iterations are captured by @xmath77 lde s , let cs be the set of common seeds ( obtained using method described in [ formulation_of_common_seeds ] ) , ucs be the set of unique common seeds , @xmath78 $ ] @xmath79 , @xmath80 represent the seeds and unique seeds of @xmath81 lde respectively .",
    "[ unique_common_seeds_algorithm ]    @xmath82 @xmath83    pick an element _ e _ from cs @xmath84 @xmath85 @xmath86 of lde s ) ] @xmath87    @xmath88      we consider nested loops having no conditional statements and the body of loop is located inside the inner most loop .",
    "all the array access expressions are affine and are separable .    consider a loop @xmath89 having _ l _ number of nested loops , a common array @xmath90 of @xmath77 dimension , @xmath91 be the number of pair of array accesses for each array such that atleast one of the accesses in the pair is write .",
    "let @xmath92 $ ] , @xmath93 be used in access expressions of @xmath94 number of subscripts and @xmath95 be a set which contains all the subscripts whose access expressions involve @xmath93 .",
    "@xmath96 , where @xmath97 , d_{a , i } \\in [ n]$ ] .    @xmath98 $ ] subscripts are partitioned such that .",
    "@xmath99 \\ \\&\\ i \\neq j , d_i \\cap d_j = \\phi    \\nonumber \\\\",
    "\\bigcup_{\\forall i \\in [ l ] } d_i = [ n]\\end{aligned}\\ ] ]    let @xmath100 $ ] and @xmath101 $ ] , @xmath102 represent the solutions of the lde formed from @xmath103 pair of array accesses on @xmath104 subscript .",
    "let @xmath105 , \\forall a \\in [ l ] , s_{u , a}^{1 } =     \\begin{cases } \\bigcap_{\\forall i \\in d_a } s_{u , i } & \\text{if } d_a \\neq \\phi \\\\ r_a & \\text{otherwise }   \\end{cases}\\ ] ] where @xmath106 is the range of @xmath107 loop .",
    "@xmath108 , t_u = \\prod_{\\forall a \\in [ l ] } s_{u , a}^{1}\\ ] ]    @xmath109    [ lemma_10 ] t captures all the dependent pair of iterations in @xmath89 .",
    "if iterations @xmath110 and @xmath111 are dependent then @xmath112 } \\binom{(x_a , y_a ) \\ if\\   d_i \\notin \\phi } { ( e1,e2 ) | e1,e2",
    "\\in r_i      \\ otherwise } \\in t \\nonumber \\\\    or \\nonumber \\\\",
    "\\prod_{\\forall a \\in [ l ] } \\binom{(y_a , x_a ) \\ if\\   d_i \\notin \\phi } { ( e1,e2 ) | e1,e2",
    "\\in r_i      \\ otherwise } \\in t    \\end{aligned}\\ ] ] where @xmath113 is the range of @xmath81 loop    proof by contradiction .",
    "assume there are two iterations @xmath110 and @xmath111 , which are dependent but do nt satisfy equation [ lemma_10_1 ] .",
    "since the two iterations are dependent , atleast one pair of array accesses should access same memory location . if the two iterations are accessing the same memory location , @xmath92 , ( x_a , y_a)$ ] has to simultaneously satisfy all the lde s where @xmath93 is used in access expression .",
    "the two iterations access same memory location iff @xmath114 or @xmath115 satisfies all the lde s of subscripts in @xmath95 simultaneously .",
    "@xmath116 , \\forall a \\in [ l ] , ( d_a \\neq \\phi ) \\implies     \\nonumber \\\\",
    "\\forall k \\in d_a , ( x_a , y_a ) \\in s_{q , k }    \\nonumber \\\\    or    \\nonumber   \\\\    \\exists",
    "q \\in [ m ] , \\forall a \\in [ l ] , ( d_a \\neq \\phi ) \\implies     \\nonumber \\\\    \\forall k",
    "\\in d_a , ( y_a , x_a ) \\in s_{q , k}\\end{aligned}\\ ] ]    equation [ lemma_10_2 ] and [ eqn_2 ] imply [ eqn_5 ] .",
    "@xmath117 , \\forall a \\in [ l ] , ( x_a , y_a ) \\in s_{q , a}^{1 }    \\nonumber \\\\\\end{aligned}\\ ] ]    equation [ eqn_5 ] , [ eqn_3 ] and [ eqn_4 ] imply equation [ lemma_10_1 ] is true , but this is a contradiction .",
    "hence the proof .",
    "[ lemma_11 ] every element of t represents atleast one pair of dependent iterations in @xmath89 . if @xmath118 , then iterations @xmath110 and @xmath111 are dependent .",
    "proof by contradiction .",
    "assume there exists an element @xmath119 and @xmath120 , but iterations @xmath110 and @xmath111 are not dependent .",
    "equation [ eqn_4 ] implies [ eqn_6 ] and equation [ eqn_6 ] and [ eqn_3 ] imply [ eqn_7 ] .",
    "@xmath121 , e \\in t_q    \\\\",
    "\\label{eqn_7 }    ( \\exists q \\in [ m ] , \\forall a \\in [ l ] , ( x_a , y_a ) \\in s_{q , a}^{1 } \\nonumber    \\\\    or \\nonumber    \\\\    \\exists q \\in [ m ] , \\forall a \\in [ r ] , ( y_a , x_a ) \\in s_{q , a}^{1 } )   \\end{aligned}\\ ] ]    equation [ eqn_6 ] and [ eqn_3 ] imply @xmath92 $ ] , @xmath114 or @xmath115 satisfy all the lde s present in @xmath95 simultaneously .",
    "if @xmath122 then @xmath93 does not appear in access expression of any subscript .",
    "hence the two iterations are accessing atleast one common memory location and are dependent , but this is a contradiction .",
    "hence the proof .",
    "[ theorem_9 ] precise dependence information for @xmath89 captures all the parallelism present at iteration level granularity .    from lemma [ lemma_10 ] and [ lemma_11 ] .",
    "consider a nested loop @xmath123 having _ l _ number of loops and _ n _ be the number of common arrays having @xmath124 dimensions respectively and let @xmath125 be the number of pairs of statements accessing the common arrays respectively .",
    "let @xmath126 be the dependency information as computed by equation [ eqn_4 ] by considering one array at a time .",
    "let @xmath127 .    precise dependence _ p _ for @xmath123 captures all the parallelism present .",
    "@xmath126 captures all the iteration pairs which cause dependence in @xmath128 array respectively(from theorem [ theorem_9 ] ) .",
    "dependencies in loop arise because of dependencies in accessing atleast one common array . hence _",
    "_ captures all the dependencies present in the loop .",
    "a seed is a representative iteration of a cc .",
    "this section gives an algorithm for generating cc from its seed with its proof of correctness .",
    "function : computes a dependency preserving schedule of a connected component .",
    "input : a seed ( belonging to the cc , whose schedule is being computed ) and solutions to the lde s in parametric form .",
    "algorithm :    [ schedule_algorithm ]    add seed to min heap ( referred to as heap in this algorithm ) .",
    "remove minimum element _ e _ discover dependencies of _ e _ and add them to heap add _ e _ to schedule mark _",
    "e _ as visited add @xmath129 to heap add _ e _ to schedule      dependencies of a node are discovered by substituting the value of node in the solution of the lde s .",
    "all nodes on which the given node is dependent on and all the nodes which depend on the given node are discovered ( by theorem [ pd_thm_single_loop ] ) .",
    "let @xmath129 be the minimum value node taken out of min heap , let @xmath130 be the set of nodes on which @xmath129 depends ( i.e nodes in @xmath130 should be executed before @xmath129 and @xmath131 ) , _",
    "( t is constructed in equation [ eqn_4 ] ) _ and @xmath132 be the set of nodes which depend on @xmath129 ( i.e nodes in @xmath132 should be executed after @xmath129 and @xmath133 ) .",
    "since there are no cyclic dependencies , there is atleast one node for which @xmath134 .    1 .",
    "if @xmath135 for @xmath129 then it can be executed and @xmath132 is added to heap .",
    "if @xmath136 for @xmath129 and @xmath129 is not marked as visited then elements of @xmath130 and @xmath132 are added to heap along with @xmath129 marked as visited.hence all the dependencies of @xmath129 have been added to heap .",
    "3 .   if @xmath129 is marked as visited then it can be executed .",
    "since @xmath129 has been visited , nodes in @xmath130 of @xmath129 were added to heap previously .",
    "as @xmath129 is the minimum value node on heap now , this implies that all elements in @xmath130 of @xmath129 have been executed .",
    "since the above mentioned process is repeated till heap is empty , all the nodes in the connected component are scheduled / executed in dependency preserving order .",
    "since every node is examined atmost twice ( i.e if @xmath137 for some node @xmath129 then @xmath129 is examined for first time when @xmath129 is minimum value node on heap and @xmath129 is not marked as visited and examined for second time to when @xmath129 is the minimum value node on heap and it marked as visited ) .",
    "maximum number of steps taken by the algorithm is atmost @xmath138 , where @xmath77 is number of nodes in the connected component .",
    "hence algorithm runs in @xmath139 time .",
    "as heap contains the nodes in the connected component , in the worst case , all but one of the nodes in the connected component will be on heap .",
    "maximum space consumed by the algorithm is @xmath140 units .",
    "hence algorithm runs in @xmath139 space .",
    "consider a nested @xmath77 loop structure , let v contain the loops whose induction variables are used in array access expressions and w contain the loops whose induction variables do not appear in any array access expression , @xmath141 $ ] and @xmath142 .",
    "let loops be numbered as @xmath143 starting from outermost to innermost loop .",
    "let @xmath144 be the set containing seeds to generate connected components of the partition arising out of all the ldes involving @xmath81 loop induction variable .",
    "we present algorithm 3 for scheduling nested loops .",
    "it uses algorithm 2 to schedule individual loops .",
    "sequential nested loops will be executed by a group of synchronization free threads parallely .",
    "[ schedule_algorithm_nested_loop ]    create @xmath145 number of threads . do a one - to - one mapping of threads to seeds in @xmath79 .",
    "each of the created thread runs algorithm 2 to generate a schedule for running @xmath81 loop .",
    "each thread calls schedule_sub(i+1 ) .",
    "exit keep the @xmath81 loop sequential .",
    "schedule consists of iterations in range of @xmath81 loop .",
    "execute body of loop .",
    "create @xmath146 number of threads .",
    "is the range of @xmath81 loop ] do a one - to - one mapping of threads to values in @xmath113 .",
    "keep the @xmath81 loop sequential .",
    "schedule consists of iterations in range of @xmath81 loop .",
    "execute body of loop .",
    "the analysis and algorithms developed and presented in this paper show how partitioning of iteration space can be done in case of @xmath147 and multiple loops with multiple ldes .",
    "we have considered 2 variable ldes with separable loops . in the presence of multiple ldes and the ensuing interactions between their individual partitions",
    "the generation of the overall partition of the system is difficult .",
    "while our formulation successfully captures the overall partition , the experimentation explores the extent of existing parallelism .",
    "+   + the experiments were parametrized by : i ) loop range ii ) number of ldes iii ) randomized coefficients for @xmath148 and iv ) number of experiments carried out .",
    "the loop range was varied from [ @xmath149 to @xmath28 , ... , @xmath150 to @xmath151 , [ 1 .. 90 ] ldes and up to 100 experiments . for each experiment",
    "the partition was evaluated in terms of minimum , maximum and average number of ccs , which are measures of exploitable parallelism .",
    "* table [ table1lde ] shows that the extent of parallelism on the average is atleast 95% across various ranges .",
    "thus , @xmath1 for single lde has significant exploitable parallelism even for large loop ranges .",
    "+ .average exploitable parallelism for single lde [ cols=\"<,<,<,<\",options=\"header \" , ]",
    "capturing dependence in case of loops with @xmath1 is presented in this paper .",
    "our approach uses a two variable lde and its parametric solutions to analyze and mathematically formulate precise dependence , the inherent dependence in the loops .",
    "theoretical methods to compute precise dependence are presented .",
    "the result is a partition of the iteration space , a set of parallel ccs .",
    "we computed bounds on the number and size of ccs .",
    "the partition is represented in a reduced form by a set of seeds .",
    "algorithms to use this set for generation of the components dynamically in a demand driven manner which can lead to schedules are presented .",
    "as we could not find loops with large number of ldes in practice randomly created multiple ldes were used for our experimentation .",
    "results show existence of reasonable parallelism which reduces as the number of ldes increase . to improve results we have formed an alternate partition using a heuristic .",
    "this heuristic shows non trivial improvement in parallelism .",
    "further method to obtain synchronization free parallelism is presented at iteration level granularity using efficient algorithms .",
    "+   + while computing precise dependence in the most general case is np - complete , most of the array access patterns found in practice are amenable to our approach .",
    "our handling of exploitable parallelism in @xmath148 and multiple loops expands the domain of applications that are parallelizable today .",
    "compile time analysis for precise dependence opens opportunity of automatic generation of parallel threads suited for multi - core configuration . even heavily connected dependence graphs show considerable parallelism which can be exploited by a well designed scheduling algorithm .",
    "+   + some of the possible future directions are : characterizing class of loops for which precise dependence can be computed . integrating precise dependence analysis , seed generation and scheduling for automatic generation of parallel code ."
  ],
  "abstract_text": [
    "<S> the extent of parallelization of a loop is largely determined by the dependences between its statements . while dependence free loops are fully parallelizable , those with loop carried dependences are not . dependence distance is a measure of absolute difference between a pair of dependent iterations . </S>",
    "<S> loops with constant distance data dependence(@xmath0 ) , because of uniform distance between the dependent iterations , lead to easy partitioning of the iteration space and hence they have been successfully dealt with . + parallelization of loops with variable distance data dependences(@xmath1 ) is a considerably difficult problem . </S>",
    "<S> it is our belief that partitioning the iteration space in such loops can not be done without examining solutions of the corresponding linear diophantine equations(ldes ) . </S>",
    "<S> focus of this work is to study @xmath1 and examine the relation between dependent iterations . </S>",
    "<S> our analysis based on parametric solution leads to a mathematical formulation capturing dependence between iterations . </S>",
    "<S> our approach shows the existence of reasonable exploitable parallelism in @xmath1 loops with multiple ldes .    * category d.3.4 code generation , compilers , optimization *    * general terms dependence distance , iteration space , partition , parametric solutions , linear diophantine equation , parallelism , algorithms , schedule * </S>"
  ]
}