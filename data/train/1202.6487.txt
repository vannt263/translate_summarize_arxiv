{
  "article_text": [
    "recent statistical developments in the assessment of space  time point process models have resulted in new , powerful model evaluation tools .",
    "these tools include residual point process methods such as thinning , superposition and rescaling , comparative quadrat methods such as pearson residuals and deviance residuals , and weighted second - order statistics for assessing particular features of a model such as its background rate or the degree of spatial clustering .",
    "unfortunately , these methods have not yet become widely used in seismology .",
    "indeed , recent efforts to assess and compare different space  time models for earthquake occurrences have led to developments such as the regional earthquake likelihood models ( relm ) project [ @xcite ] and its successor , the collaboratory for the study of earthquake predictability ( csep ) [ @xcite ] .",
    "the relm project was initiated to create a  variety of earthquake forecast models for seismic hazard assessment in california .",
    "unlike previous projects that were addressing earthquake forecast modeling for seismic hazard assessment , the relm participants decided to develop a  multitude of competing forecasting models and to rigorously and _ prospectively _ test their performance in a dedicated testing center [ @xcite ] . with the end of the relm project , the forecast models became available and the development of the testing center was done within the scope of csep .",
    "csep inherited not only all models developed for relm and is testing them for the previously defined period of 5 years , but also a suite of forecast performance tests that was developed during the relm project . in relm",
    ", a community consensus was reached that all models will be tested with these tests [ @xcite , @xcite ] .",
    "the tests include the number or n - test that compares the total forecasted rate with the observation , the likelihood or l - test that assesses the quality of a forecast in the likelihood space , and the likelihood - ratio or r - test that compares the performance of two forecast models .",
    "however , over time several drawbacks of these tests were discovered [ @xcite ] and the need for more and powerful tests became clear to better discern between closely competing models .",
    "the n - test and l - test simply compare the quantiles of the total numbers of events in each bin or likelihood within each bin to those expected under the given model , and the resulting low - power tests are typically unable to discern significant lack of fit unless the overall rate of the model fits extremely poorly .",
    "further , even when the tests do reject a model , they do not typically indicate _ where _ or _",
    "when _ the model fits poorly , or how it could be improved .",
    "the purpose of the current paper is to review modern model evaluation techniques for space  time point processes and to demonstrate their use and practicality on earthquake forecasting models for california .",
    "the relm project represents an ideal test case for this purpose , as a variety of relevant , competing space ",
    "time models are included , and these models yield genuinely prospective forecasts of earthquake rates based solely on prior data .",
    "the rates are specified per bins which are spatial - magnitude - temporal volumes ( called pixels in the statistical domain ) .",
    "these bins have been predefined in a community consensus process in order to have the model forecast rates in the exact same bins .",
    "the models forecasts translate into strongly different estimates of seismic hazard .",
    "its accurate estimation is important for seismic hazard assessment , urban planning , disaster preparation efforts and in the pricing of earthquake insurance premiums [ @xcite ] , so distinguishing among competing models is an extremely important task .    in section [ sec2 ]",
    "we describe a group of earthquake forecast models to be evaluated , along with the observed earthquake occurrences used to assess the fit of the models .",
    "the methods currently used by seismologists for model evaluation are briefly reviewed in section [ sec3 ] .",
    "pixel - based residuals for model comparison are discussed in section [ sec4 ] . in section [ sec5 ]",
    "weighted second - order statistics , primarily the weighted k - function , are investigated .",
    "section [ sec6 ] reviews various residual methods based on rescaling , thinning and superposition , and introduces and applies the method of super - thinning .",
    "section [ sec7 ] summarizes some of the benefits and weaknesses of these tools .",
    "csep expanded and now collects and evaluates space  time earthquake forecasts for different regions around the world , including california , japan , new zealand , italy , the northwest pacific , the southwest pacific and the entire globe .",
    "the forecasts are evaluated in testing centers in japan , switzerland , new zealand and the united states . the u.s .",
    "testing center is located at the southern california earthquake center ( scec ) and hosts forecast experiments for california , the northwest and southwest pacific , and the global experiments .",
    "we have chosen to apply a variety of measures to assess the fit of a collection of the california forecast models currently being tested at scec .",
    "the forecast models are arranged in classes according to their forecast time period : five - year , three - month and one - day .",
    "there are two types of forecasts , rate - based and alarm - based . within the five - year group",
    "are a set of rate - based models developed as part of the relm project . in this paper",
    "we evaluate the relm project rate - based one - day and five - year models , and will be ignoring the three - month models due to their very recent introduction to the csep testing center .",
    "all csep forecasts are grid - based , providing a forecast in each spatial - magnitude bin within a given time window .",
    "for the one - day models , each bin is of size @xmath1 longitude ( lon ) by @xmath2 latitude ( lat ) by @xmath3 units magnitude for earthquake magnitudes ranging from 3.95 to 8.95 . for magnitudes 8.9510",
    ", there is a single bin of size @xmath1 by @xmath1 by @xmath4 units of magnitude .",
    "the relm forecasts are identical , except with a lower magnitude bound of 4.95 instead of 3.95 . for each bin",
    ", an expected number of earthquakes in the forecast period is forecasted .",
    "there are five models in the relm project that are considered mainshock@xmath5 aftershock models .",
    "these models forecast both mainshocks and aftershocks with a single forecast for a period of five years .",
    "models proposed in @xcite and @xcite , which we will call models a and b , respectively , base their forecasts exclusively on previous seismicity . the model proposed in @xcite , denoted model c here , is based on other geodetic or geological data .",
    "all relm models are five - year forecasts , beginning 1 january 2006 , 00:00 utc and ending 1 january 2011 , 00:00 utc .",
    "csep is also testing two one - day forecast models : the epidemic - type aftershock sequences ( etas ) model [ @xcite , @xcite ] and the short - term earthquake probabilities ( step ) model [ @xcite ] since september of 2007 .",
    "both of these models produce forecasts based exclusively on prior seismicity .",
    "csep evaluates the relm models using a lower magnitude cutoff of  4.95 .",
    "because there are so few earthquakes of magnitude  4.95 and higher in the catalog over the observed period we use a lower magnitude cutoff of  3.95 instead .",
    "the forecasts for models a , b and c were extrapolated using each model s fitted magnitude distribution .",
    "models a and b assume the magnitude distribution follows a tapered gutenberg ",
    "richter law [ @xcite ] with a _",
    "b_-value of 0.95 and a corner magnitude of 8.0 .",
    "model c uses a _",
    "b_-value of 0.975 and the same corner magnitude . model a adjusts the magnitude distribution in a small region in northern california influenced by geothermal activity ( 122.9@xmath6w@xmath7lon@xmath7122.7@xmath6w and @xmath8n@xmath7lat@xmath738.9@xmath6n ) by using a _",
    "b_-value of 1.94 instead of 0.95 .",
    "earthquake catalogs containing the estimated earthquake hypocenter locations and magnitudes were obtained from the advanced national seismic system ( anss ) . from 1 january 2006 to 1 september 2009 there were 142 shallow earthquakes with a magnitude of 3.95 or larger which occurred in relm s spatial - temporal window ( see figure [ alleqs ] ) .     in the relm testing region . ]",
    "note that each relm model does not necessarily produce a forecasted seismicity rate for every pixel in the space ",
    "time region .",
    "hence , each model essentially has its own relevant spatial - temporal observation region , and thus we may have different numbers of observed earthquakes corresponding to different models .",
    "for instance , all 142 recorded earthquakes from 1 january 2006 to 1 september 2009 corresponded to pixels where model a made forecasts , but only 81 corresponded to pixels where model b made forecasts , and 86 where model c made forecasts .",
    "85 earthquakes of magnitude 3.95 or greater occurred since 1  september of 2007 , all of which corresponded to forecasts made by etas but only 83 of which corresponded to forecasts made by step .",
    "csep initially implemented two numerical summary tests , called the likelihood - test ( l - test ) and the number - test ( n - test ) , to evaluate the fit of the earthquake forecast models they collect .",
    "a full description of these methods can be found in @xcite .",
    "these goodness - of - fit tests are similar to other numerical goodness - of - fit summaries such as the akaike information criterion [ @xcite ] and the bayesian information criterion [ @xcite ] in that they provide a score for the overall fit of the model without indicating where the model may be fitting poorly .",
    "the l - test , described in @xcite , works by first simulating some fixed number @xmath9 of realizations from the forecast model . the log - likelihood ( @xmath10 )",
    "is computed for the observed earthquake catalog ( @xmath11 ) and each simulation ( @xmath12 , for @xmath13 ) .",
    "the quantile score , @xmath14 , is defined as the fraction of simulated likelihoods that are less than the observed catalog likelihood : @xmath15 where @xmath16 denotes the indicator function .",
    "if @xmath14 is close to zero , then the model is considered to be inconsistent with the data , and can be rejected . otherwise , the model is not rejected and further tests are necessary .",
    "the n - test is similar to the l - test , except that the quantile score examined is instead the fraction of simulations that contain fewer points than the actual observed number of points in the catalog , @xmath17 .",
    "that is , @xmath18 where @xmath19 is the number of points in the @xmath20th simulation of the model . with the n - test",
    ", the model is rejected if @xmath21 is close to @xmath22 or @xmath23 .",
    "if a model is underpredicting or overpredicting the total number of earthquakes , then @xmath24 or  @xmath22 , respectively , and the model will likely be rejected with the n - test .",
    "table [ tab ] shows results for the l- and n - test for selected models .",
    "the l - test would lead to rejection of models a , b , c and step as seen by the very low @xmath14 scores .",
    "the etas model would not be rejected based on the @xmath14 score alone , requiring the application of the n - test for a final decision . at the @xmath25 level of significance ,",
    "the @xmath21 scores indicate that the step model is underpredicting the total number of earthquakes , while models a , b , c and etas are significantly overpredicting earthquake rates .    @lrccc@ * model * & & & & +   + [ 4pt ] a. helmstetter & @xmath2622881.46 & 0.000 & 142 & * 0.000 * + b. kagan & @xmath2610765.43 & 0.008 & 81 & * 0.001 * + c. shen & @xmath2610265.20 & 0.002 & 86 & * 0.043 * + [ 4pt ] + [ 4pt ] etas & @xmath26387.69 & 1.00 & 85 & * 0.00 * + step & @xmath2650.43 & 0.00 & 83 & * 0.99 * +    unfortunately , in practice , both statistics @xmath14 and @xmath21 test essentially the same thing , namely , the agreement between the observed and modeled _ total _ number of points . indeed , for a typical model , the likelihood for a given simulated earthquake catalog depends critically on the number of points in the simulation .",
    "baddeley et  al . ( @xcite )",
    "introduced methods for residual analysis of purely spatial point processes , based on comparing the total number of points within predetermined bins to the number forecast by the model .",
    "such methods extend readily to the spatial - temporal case , and are quite natural for evaluating the csep forecasts since the models are constrained to have a constant conditional intensity within prespecified bins .",
    "the differences between observed and expected numbers of events within bins can be standardized in various ways , as described in what follows .",
    "earthquake occurrence times and locations are typically modeled as space ",
    "time point processes , with the estimated epicenter or hypocenter of each earthquake representing its spatial location . along with each observation",
    ", one may also record several _ marks _ which may be used in the model to help forecast future events ; an important example of a mark is the magnitude of the event . space ",
    "time point process models are often characterized by their associated conditional intensity , @xmath27 , that is , the infinitesimal rate at which one expects points to occur around time @xmath28 and location @xmath29 , given full information on the occurrences of points prior to time  @xmath28 , and given the marks and possibly other covariate information observed before time @xmath28 .",
    "note that due to the lack of a natural ordering of points in the plane , purely spatial point processes are typically characterized by their papangelou intensities [ @xcite ] , which may be thought of as the limiting rate at which points are expected to accumulate within balls centered at location @xmath29 given what _ other _ points have occurred at all locations outside of these balls , as the size of the balls shrink to zero . for a review of point processes and conditional intensities ,",
    "see @xcite .",
    "an aggregate conditional intensity is derived for each spatial bin for all models by summing the forecast rates over all magnitude bins and then dividing the sum by the area of each pixel .",
    "since we are evaluating the five - year models a , b and c after only 44 of the 60 months of the forecast period have elapsed , their conditional intensities are scaled by a factor of @xmath30 .",
    "consider a model @xmath31 for the conditional intensity at any time @xmath28 and location @xmath32 .",
    "_ raw residuals _ may be defined following @xcite as simply the number of observed points minus the number of expected points in each pixel , that is , @xmath33 where @xmath34 is the number of points in bin @xmath35 .",
    "note that @xcite consider only the case of purely spatial point processes characterized by their papangelou intensities ; @xcite showed that one may nevertheless extend the definition to the spatial - temporal case using the conventional conditional intensity as in ( [ rawres ] ) .",
    "one may wish to rescale the raw residuals in such a way that they have mean 0 and variance approximately equal to 1 .",
    "the _ pearson residuals _ are defined as @xmath36 for all @xmath37 .",
    "these are analogous to the pearson residuals in poisson log - linear regression .",
    "both step and model c have several pixels with forecasted conditional intensities of 0 , which complicates the standardization of the corresponding residuals for these two models .",
    "pearson residuals were obtained for each of the remaining models .",
    "for instance , figure [ kaganpearson ] shows that the largest pearson residual for model b is 2.817 located in a pixel in mexico , just south of the california border near the imperial valley fault zone ( @xmath38w and @xmath39n ) , which is the location of a large cluster of earthquakes .",
    "another very large residual for model b can be seen just above the san bernardino and inyo county border near the panamint valley fault zone ( @xmath40w and @xmath41n ) .",
    "this is also the location of the largest etas pearson residual ( 2.221 ) .",
    "the largest pearson residual for model a ( 4.068 ) is located at a small earthquake cluster near the peterson mountain fault northwest of reno , nevada ( @xmath42w and @xmath43n ) .",
    "note that when spatial - temporal bins are very small and/or the estimated conditional intensity in some bins is very low , as in this example , the raw and especially the standardized residuals are highly skewed . in such cases , the residuals in such pixels where points happen to occur tend to dominate , and the skew may complicate the analysis . indeed , pearson residuals fail to provide much useful information about the model s fit in the other pixels where earthquakes did not happen to occur , and graphical displays of the pearson residuals tend to highlight little more than the locations of the earthquakes themselves .",
    "therefore , while pearson and raw residuals may help to identify individual bins containing earthquakes that require an adjustment in their forecasted rates , pearson and raw residuals generally fail to identify other locations where the models may fit relatively well or poorly .",
    "a useful method for comparing models is using the deviance residuals proposed by @xcite , in analogy with deviances defined for generalized linear models in the regression framework . as with pearson residuals",
    ", @xmath44 is divided into evenly spaced bins , and the differences between the log - likelihoods within each bin for the two competing models are examined .",
    "given two models for the conditional intensity , @xmath45 and @xmath46 , the deviance residual in each bin , @xmath47 , of @xmath48 against @xmath49 is given by @xmath50    positive residuals imply that the model @xmath48 fits better in the given pixel and negative residuals imply that @xmath51 provides better fit . by simply taking the sum of the deviance residuals , @xmath52",
    ", we obtain a log - likelihood ratio score , giving us an overall impression of the improvement in fit from the better fitting model .",
    "if @xmath48 or @xmath49 is estimated , then one may use this estimate in computing the deviance residuals , and similarly if @xmath48 or @xmath49 is given , that is , not estimated , then one would simply use this given model in computing the residuals .",
    "figure [ devcombined](a ) shows the deviance residuals for model a versus model b. model a outperforms model b in almost all locations where earthquakes actually occurred , and , in particular , model a forecasts the imperial earthquake cluster and another cluster near the laguna salada and yuha wells faults just north of the california  mexico border ( @xmath53w and @xmath54n ) much better than model b. the pixel with the largest residual , highlighted in figure [ devcombined](b ) , is located in the imperial cluster .",
    "model b seems to fit better in several selected areas , mostly regions close to known faults but where earthquakes did not happen to occur in the time span considered . in most locations , however , including the vast majority of locations far from seismicity , model a offers better fit , as model b tends to overpredict events in these locations more than model a. overall , the log - likelihood ratio score is 84.393 , indicating a significant improvement from model a compared to model b.        7.468 . ]",
    "results are largely similar for model a versus model c , as seen in figure  [ devcombined2](a ) , with model a forecasting the rate at all observed earthquake clusters , including a cluster at the extreme southern end of the observation region on the baja , mexico peninsula ( @xmath55w and @xmath56n ) , more accurately than model c. overall , model a offers substantial improvement over model c with a likelihood ratio score of 86.427 .",
    "residuals for model b versus model c can be seen in figure [ devcombined2](b ) .",
    "model c forecasts the rate near the imperial cluster better , and model b forecasts more accurately around the laguna salada cluster .",
    "there are vast regions where model b outperforms model c and vice versa .",
    "overall , model c fits slightly better than model b , with a likelihood ratio score of @xmath267.468 .",
    "deviance residuals for etas versus step ( not shown ) reveal that the etas model performs somewhat better for this data set overall , with a log - likelihood ratio score of 76.261 , providing substantially more accurate forecasts in nearly all locations , especially where earthquakes occur .",
    "a common model assessment tool used for detecting clustering or inhibition in a point process is ripley s k - function [ @xcite ] , defined as the average number of points within @xmath57 of any given point divided by the overall rate @xmath0 , and is typically estimated via @xmath58 where @xmath59 is the area of the observation region , @xmath60 is the total number of observed points , and @xmath61 is the proportion of area of the ball centered at @xmath62 and passing through @xmath63 that falls within the observation region [ see @xcite , @xcite ] . for a homogeneous poisson process in @xmath64 , k@xmath65 , @xcite suggested a variance stabilized version of the k - function , called the l - function , given by l@xmath66 .",
    "the null hypothesis for most second - order tests such as ripley s k - function is that the point process is a homogeneous poisson process .",
    "@xcite argues that this is a poor null hypothesis for the case of earthquake occurrences because a homogeneous poisson model fits so poorly to actual data .",
    "@xcite described a variety of weighted analogues of second - order tests that are useful when the null hypothesis in question is more general .",
    "most useful among these is the weighted analogue of ripley s k - function , first introduced by @xcite .",
    "they discussed the case where the null model  @xmath67 , can be any inhomogeneous poisson process , and this was extended by @xcite to the case of non - poisson processes as well .",
    "the weighted k - function is useful for testing the degree of clustering in the model , and was used by @xcite to assess a spatial point process model fitted to southern california earthquake data .",
    "the standard estimate of the weighted k - function is given by @xmath68 where @xmath69min(@xmath70 ) , @xmath16 is the indicator function , and @xmath71 is the conditional intensity at point @xmath62 under the null hypothesis .",
    "edge - corrected modifications can also be used , especially when the observed space is irregular .",
    "@xcite proposed a local empirical k - function which can assess lack - of - fit in subsets of @xmath44 and can be compared to the weighted k - function applied globally to @xmath44 . here , we apply the weighted k - function globally to derive an overall impression of each model s lack of fit .",
    "as with ripley s k - function , under the null hypothesis , for a spatial point process with intensity @xmath72 , @xmath73 [ @xcite ] . to obtain a centered and standardized version , one can also transform the weighted k - function into a weighted l - function as before , and plot @xmath74 versus  @xmath57 .",
    "space  time versions of the l - function have been proposed , but for the purpose of examining , in particular , the range and degree of purely spatial clustering in each model , it seems preferable to apply the purely spatial weighted l - function previously described , after first integrating the conditional intensities of the etas and step models over time .",
    "figure [ allwk ] shows the estimated centered weighted l - functions for the five models considered here , along with 95% confidence bounds based on the normal approximation in @xcite , who showed that asymptotically , the distribution of the weighted k - function should generally obey @xmath75 ^ 2}\\biggr).\\ ] ] the catalog of observed earthquakes is significantly more clustered than would be expected according to model a , especially within distances of  @xmath76 degrees of longitude / latitude , or approximately @xmath77 km .",
    "however , at distances greater than  @xmath78 , or approximately @xmath79 km , the observed data exhibit greater inhibition than one would expect according to model a. this suggests that model a is underpredicting the degree of clustering in the observed seismicity and may be generally underpredicting the seismicity rate within highly active seismic areas , and may be overpredicting seismicity elsewhere .",
    "results are similar for model b and the etas model .",
    "the estimated l - function for model c shows significantly more clustering of the ( weighted ) seismicity than one would expect within distances of @xmath80 or @xmath81 km , that is , model c is significantly underpredicting the degree of clustering within this range , but seems consistent with the data outside of this range .",
    "the estimated l - function shows clear discrepancies between the step model and the data , as the ( weighted ) seismicity is significantly more clustered than one would expect according to the model at both small and large distances .",
    "these results are not surprising considering that step tends to underpredict seismicity overall : according to the step forecasts , one would expect only 63 earthquakes in total during the period in which 85 occurred .",
    "by contrast , etas tends to overpredict the overall rate , forecasting more than 114 earthquakes in this same period .",
    "as shown in section [ sec42 ] , when the spatial - temporal pixels are small , the distribution of raw and pearson residuals tend to be highly skewed , and this limits their utility .",
    "when pixels are larger , however , a  drawback of pixel - based residuals is that considerable information is lost in aggregating over the pixels .",
    "instead , one may wish to examine the extent to which the data and model agree , without relying on such aggregation .",
    "one way to perform such an assessment is to transform the points of the process , by rescaling , thinning , superposition or superthinning , to form a new point process that should be a homogeneous poisson process if and only if the model used to govern this transformation is correct .",
    "the residual points can then be assessed for inhomogeneity as a means of evaluating the goodness of fit of the underlying model .",
    "@xcite observed that the temporal coordinates of a multivariate point process can be rescaled according to the integrated conditional intensity in order to form a sequence of stationary poisson processes . for a space",
    " time point process , one may thus rescale one axis , for example , the @xmath82-axis , moving each observation @xmath83 to the new rescaled position @xmath84 , and assess the space  time homogeneity of the resulting process .",
    "this sort of method was used by @xcite for model evaluation for the purely temporal case and by @xcite for the spatial - temporal case .",
    "the spatial homogeneity of these residual points may be assessed , for instance using ripley s k - function .",
    "if @xmath0 is spatially volatile , the transformed space bounding the rescaled residuals can be highly irregular , which makes it difficult to detect uniformity using the k - function . in this case",
    ", one can rescale the points along a  different axis as in @xcite and see if there is any improvement . unfortunately",
    ", most csep forecast models have volatile conditional intensities , resulting in a highly irregular boundary regardless of which axis is chosen for rescaling . in such cases ,",
    "the k - function is dominated by boundary effects and has little power to detect excessive clustering or inhibition in the residuals .",
    "figure [ combresc ] shows the rescaled residuals for models b and  c ,        which had the most well behaved of the rescaled residuals for the five models we considered .",
    "there is significant clustering in both the vertically and horizontally rescaled residuals for all five models , apparently due to clustering in the observations not adequately accounted for by the models , the most noticeable of which is the very large imperial cluster .",
    "one must be somewhat cautious , however , in interpreting rescaled residuals , because patterns observed in the points in the rescaled coordinates may be difficult to interpret .",
    "thinned residuals are a modification to the simulation techniques used by @xcite and @xcite , and , as shown in @xcite , are useful for assessing the spatial fit of a  space  time point process model and revealing locations where the model is fitting poorly . unlike rescaled residuals , thinned residuals have the advantage that the coordinates of the points are not transformed and , thus , the resulting residuals may be easier to interpret . to obtain thinned residuals ,",
    "each point @xmath85 is kept independently with probability @xmath86 where @xmath87 is the infimum of the estimated intensity over the entire observed space ",
    "time window , @xmath44 .",
    "the remaining points , called _ thinned residual points _ , should be homogeneous poisson with rate @xmath88 if and only if the fitted model for @xmath0 is correct [ @xcite ] . for this method to have sufficient power ,",
    "several realizations of thinned residuals can be collected , each realization being tested for uniformity using the k - function , and then all k - functions may be examined together to get the best overall assessment of the model s fit .    when applied to the csep earthquake forecasts",
    ", @xmath88 tends to be so small that thinning results in very few points ( often zero ) being retained .",
    "one can instead obtain _ approximate thinned residuals _ by forcing the thinning procedure to keep , on average , a certain number , @xmath89 , of points by keeping each point with probability @xmath90 as in @xcite .    ) .",
    "top - center panel : model b ( @xmath91 ) .",
    "top - right panel  :  model  c ( @xmath91 ) .",
    "bottom - left panel : etas ( @xmath92 ) .",
    "bottom - right panel  :  step ( @xmath92 ) . ]    ) .",
    "top - center panel  : model b ( @xmath93 ) .",
    "top - right panel : model  c ( @xmath94 ) .",
    "bottom - left panel : etas ( @xmath95 ) .",
    "bottom - right panel : step ( @xmath95 ) . ]    typical examples of approximate thinned residuals for the five models we consider , using @xmath96 and @xmath97 for models a , b , c , etas and step , respectively , are shown in figure [ thinplotsall ] .",
    "excessive clustering or inhibition in the residual process , compared with what would be expected from a homogeneous poisson process with overall rate @xmath89 , indicates lack of fit . to test the residuals for homogeneity",
    ", one may apply the weighted k - function to the residuals , with @xmath98 for all points @xmath62 .",
    "this is equivalent to using the unweighted version of the k - function on the residuals , except that here the overall rate is @xmath89 , whereas with the conventional unweighted k - function , the overall rate is typically estimated as @xmath99 .",
    "the estimated centered weighted l - functions for each model , along with the 95%-confidence bands based on [ wkbounds ] , are shown in figure [ thinplotsallwk ] .",
    "models a and step most noticeably fail to thin out the small cluster near the peterson mountain fault northwest of reno , nevada , and another small cluster in northern california that occurs approximately 35 kilometers south of the battle creek fault ( @xmath100w and @xmath101n ) .",
    "this residual clustering is significant , as shown by the weighted l - functions in figures [ thinplotsallwk](a ) and ( e ) .",
    "model b has trouble forecasting the imperial cluster , as evidenced by the significant clustering at distances up to 0.6@xmath6 . the residuals for both models",
    "c and etas appear to be closer to uniformly distributed throughout the space , though further investigation of several realizations of thinned residuals reveals that model c has trouble thinning out the baja , california cluster , which leads to some significant clustering in the residuals at very small distances .",
    "superposition is a residual analysis technique similar to thinned residuals , but instead of removing points , one simulates new points to be added to the data and examines the result for uniformity .",
    "this procedure was proposed by @xcite , but examples of its use have been elusive .",
    "points are simulated at each location @xmath102 according to a  cox process with intensity @xmath103 , where @xmath104 . as with thinning and rescaling",
    ", if the model for @xmath0 is correct , the union of the superimposed residuals and observed points will be homogeneous poisson .",
    "any patterns of inhomogeneity in the residuals aid us in identifying spots where the model fits poorly .",
    "superposition helps solve one of the biggest disadvantages of thinned residuals : the lack of information on the goodness of fit of the model in locations where no events occur . however ,",
    "if @xmath105 is large , then there is a possibility that too many points will be simulated , meaning that the behavior of the k - function will be primarily influenced by simulated points rather than actually observed data points . for models a and step , for example , simulated points comprise@xmath10699% of the total points after superposition . for models c and etas , simulated points comprise@xmath10690% of the superposed residual points .",
    "see figure [ shenxtsuper ] for an example of superposed residuals for model c. since the test for uniformity is based almost entirely on the simulated points , which are by construction approximately homogeneous for large  @xmath105 , the test has low power for model evaluation in such situations .        observed earthquakes ; plus signs@xmath107simulated points ) .",
    "right panel  :  estimated centered weighted l - function for superposed residuals ( solid line ) and 95%-confidence bounds ( dashed lines ) . ]    a realization of superposed residuals for model b can be seen in figure  [ kaganxtsuperwk ] , along with the corresponding centered weighted l - function as a test for homogeneity of the residuals .",
    "95%-confidence bands for the l - function are constructed under the null hypothesis @xmath108 for all points @xmath62 .",
    "the superposed residuals are significantly more clustered than would be expected , up to distances of 0.4@xmath6 , or approximately 44.4 km .",
    "this is likely the result of the underprediction of the seismicity rate in the imperial cluster .",
    "one also observes significantly more inhibition in the superposed residuals than would be expected at distances greater than  0.5@xmath109 , or approximately 55.5 km .",
    "this inhibition can most likely be attributed to the model s overprediction of the seismicity rate in areas devoid of earthquakes , which can be seen in the portions of figure [ kaganxtsuperwk](a ) in various regions lacking both simulated and observed points .",
    "a more powerful approach than thinning or superposition individually is a hybrid approach where one thins in areas of high intensity and superposes simulated points in areas of low intensity , resulting in a homogeneous point process if the model for @xmath0 used in the thinning and superposition is correct .",
    "the benefit of this method , called super - thinning by @xcite , is that the user may specify the overall rate of the resulting residual point process , @xmath110 , so that it contains neither too few or too many points .    in super - thinning ,",
    "one first keeps each observed point @xmath102 in the catalog independently with probability @xmath111 and subsequently superposes points generated according to a simulated cox process with rate @xmath112 . the result is a homogeneous poisson process with rate  @xmath89 if and only if the model @xmath113 for the conditional intensity is correct [ @xcite ] and , hence , the resulting super - thinned residuals can be assessed for homogeneity as a way of evaluating the model .",
    "in particular , any clustering or inhibition in the residual points indicates a lack of fit",
    ".    observed earthquakes ; plus signs@xmath114simulated points ) .",
    "top - left panel  :  model  a ( @xmath115 ) .",
    "top - center panel  :  model  b ( @xmath116 ) .",
    "top - right panel  :  model  c ( @xmath117 ) .",
    "bottom - left panel  :  etas ( @xmath118 ) .",
    "bottom - right panel  :  step ( @xmath119 ) . ]    .",
    "top - left panel : model a ( @xmath120 ) .",
    "top - center panel  : model b ( @xmath121 ) .",
    "top - right panel : model c ( @xmath122 ) .",
    "bottom - left panel : etas ( @xmath123 ) .",
    "bottom - right panel : step ( @xmath124 ) . ]    in the application to earthquake forecasts , a natural choice for @xmath89 is the total number of expected earthquakes according to each forecast .",
    "figure  [ allsuperthin ] shows one realization of super - thinned residuals for each model , and figure  [ allsuperthinwk ] shows the estimated centered weighted l - functions for the corresponding residuals , with @xmath98 for all points @xmath62 , along with 95%-confidence bands .",
    "model a appears to fit rather well overall , with some significant clustering in the residuals at very small distances ( from 0@xmath6 to 0.1@xmath6 ) most likely attributable to the same small clusters that remained in the thinned residuals .",
    "however , the l - function in figure [ allsuperthinwk](a ) reveals that there is somewhat more inhibition in the residual process than we would expect .",
    "this is likely attributable to model a s overprediction of the seismicity rate especially in inter - fault zones .",
    "the super - thinned residuals for model b contain a  few significant clusters ( imperial , laguna salada and panamint ) and some slight inhibition due to overprediction of seismicity in two regions devoid of any simulated points or retained earthquakes : the san diego - imperial county areas and the los angeles ",
    "san bernardino areas .",
    "there is also significant clustering for model  c up to distances of 0.2@xmath6 , particularly the laguna salada , baja and panamint clusters .",
    "the etas residuals contain significant clustering at distances up to 0.1@xmath6 , and this is largely attributable to the imperial cluster and to clusters in peterson mountain and the mt .",
    "konocti area near clearlake , california at @xmath125w and @xmath126n .",
    "the step residuals exhibit significant clustering at distances up to 0.4@xmath6 , with obvious clustering at imperial , peterson mountain , battle creek , mt . konocti and the mendocino fault zone off the coast of northwest california .",
    "a litany of residual analysis methods for spatial point processes can be implemented to assess the fit and reveal weaknesses in point process models , and many of these methods provide more reliable estimates of the overall fit and more detailed information than the l - test and n - test .",
    "rescaled residuals can assist in the evaluation of the overall spatial fit , but are not easily interpretable due to the transformed spatial window .",
    "thinned residuals are much more easily interpretable , but suffer from variability in the thinned residual point pattern and low power if @xmath88 is too small .",
    "superposition is similar to thinning in that it also suffers from sampling variability and low power in the case of a very large supremum of @xmath70 .",
    "super - thinning appears to be a promising alternative , but , like superposition , may have low power if the modeled intensity is extremely volatile .",
    "deviance residuals and weighted second - order statistics appear to be quite powerful , especially for comparisons of competing models .",
    "clearly , the availability of a larger number of observed earthquakes in the tests would lead to more detailed and more meaningful results , and this suggests further decreasing the lower magnitude threshold .",
    "however , considerations of catalog incompleteness at lower magnitudes , as well as the fact that not all forecast models in the study are capable of forecasting small events and their spatial - temporal fluctuations , lead to limits on how low one may place the lower magnitude threshold for the catalog . indeed",
    ", lowering the threshold requires stronger time - dependence of the models to account for the short - term fluctuations of microseismicity . due to these considerations",
    ", csep sets the lower magnitude threshold in most cases to 3.95 for the time - varying models like step and etas .",
    "overall , model a seems to be overpredicting seismicity at the time of testing , but this may change once the forecast period is complete if there is a greater amount of seismic activity .",
    "models b and c appear to be significantly underpredicting seismicity in many locations , and unless the seismic activity in these regions slows down considerably , these models will continue to underpredict for the remainder of the forecast period .",
    "the spatial distribution of model a is quite accurate , coupling forecasts of high conditional intensity in areas along active faults with very low intensity forecasts in areas adjacent to these faults which typically are devoid of earthquakes .",
    "models b and c have smooth spatial distributions yielding erroneously high forecasts at distances far from any faults .",
    "the question of what choice of @xmath89 is optimal in thinning or super - thinning remains open for future research .",
    "ideally , @xmath89 should be chosen such that a  poorly fitting model is rejected with high probability , while a `` correct '' or satisfactorily fitting model is rejected with low probability ( i.e. , the type  i error probability , @xmath127 , is small ) .",
    "when thinning , we lose information when points are removed , so we prefer to keep as many points as possible , while keeping @xmath127 low . with super - thinning , we would also ideally want to retain many of the original points while simulating few points , so that any assessment of the homogeneity of the residuals is not highly dependent on the simulations .",
    "simulation and theoretical studies are needed in the future to compare the power of these goodness - of - fit measures under various hypotheses .",
    "we thank yan kagan and alejandro veen for helpful comments , the advanced national seismic system for the earthquake catalog data , and the collaboratory for the study of earthquake predictability and the southern california earthquake center for supplying the earthquake forecasts ."
  ],
  "abstract_text": [
    "<S> modern , powerful techniques for the residual analysis of spatial - temporal point process models are reviewed and compared . </S>",
    "<S> these methods are applied to california earthquake forecast models used in the collaboratory for the study of earthquake predictability ( csep ) . </S>",
    "<S> assessments of these earthquake forecasting models have previously been performed using simple , low - power means such as the l - test and n - test . </S>",
    "<S> we instead propose residual methods based on rescaling , thinning , superposition , weighted and deviance residuals . </S>",
    "<S> rescaled residuals can be useful for assessing the overall fit of a model , but as with thinning and superposition , rescaling is generally impractical when the conditional intensity @xmath0 is volatile . while residual thinning and superposition may be useful for identifying spatial locations where a model fits poorly , these methods have limited power when the modeled conditional intensity assumes extremely low or high values somewhere in the observation region , and this is commonly the case for earthquake forecasting models . </S>",
    "<S> a recently proposed hybrid method of thinning and superposition , called super - thinning , is a more powerful alternative . </S>",
    "<S> the weighted k - function is powerful for evaluating the degree of clustering or inhibition in a  model . </S>",
    "<S> competing models are also compared using pixel - based approaches , such as pearson residuals and deviance residuals . </S>",
    "<S> the different residual analysis techniques are demonstrated using the csep models and are used to highlight certain deficiencies in the models , such as the overprediction of seismicity in inter - fault zones for the model proposed by helmstetter , kagan and jackson [ _ seismological research letters _ * 78 * ( 2007 ) 7886 ] , the underprediction of the model proposed by kagan , jackson and rong [ _ seismological research letters _ * 78 * ( 2007 ) 9498 ] in forecasting seismicity around the imperial , laguna salada , and panamint clusters , and the underprediction of the model proposed by shen , jackson and kagan [ _ seismological research letters _ * 78 * ( 2007 ) 116120 ] in forecasting seismicity around the laguna salada , baja , and panamint clusters .    ,     + and    . </S>"
  ]
}