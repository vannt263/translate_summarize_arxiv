{
  "article_text": [
    "as an alternative type of supervisory information easier to access than the class labels of data points , pairwise constraints are widely used for different machine learning tasks in the literature . to effectively exploit pairwise constraints for clustering or classification @xcite , much attention has been paid to pairwise constraint propagation @xcite .",
    "different from the method @xcite which only adjusts the similarities between constrained data points , these approaches can propagate pairwise constraints to other similarities between unconstrained data points and thus achieve better results in most cases .",
    "more importantly , given that each pairwise constraint is actually defined over a pair of data points from a single view , these approaches can all be regarded as intra - view constraint propagation when multi - view data is concerned . since we have to learn the relationships ( must - link or cannot - link ) between data points , intra - view constraint propagation is more challenging than the traditional label propagation @xcite whose goal is only to predict the labels of unlabeled data points .    however , besides intra - view pairwise constraints , we may also have easy access to inter - view pairwise constraints in multi - view tasks such as cross - view retrieval @xcite , where each pairwise constraint is defined over a pair of data points from different views ( see fig .  [ fig.1 ] ) . in this case",
    ", inter - view pairwise constraints still specify the must - link or cannot - link relationships between data points .",
    "since the similarity of two data points from different views is commonly unknown in practice , inter - view constraint propagation is significantly more challenging than intra - view constraint propagation .",
    "in fact , very little attention has been paid to inter - view constraint propagation for multi - view tasks in the literature .",
    "although pairwise constraint propagation has been successfully applied to multi - view clustering in @xcite , only intra - view pairwise constraints are propagated across different views . here , it should be noted that these two constraint propagation methods _ have actually ignored _ the concept of inter - view pairwise constraints or the strategy of inter - view constraint propagation .    since multi - view data can be readily decomposed into a series of two - view data , we focus on inter - view constraint propagation only across two views in this paper .",
    "however , such inter - view constraint propagation remains a rather challenging task .",
    "fortunately , from a semi - supervised learning viewpoint , we can formulate inter - view constraint propagation as minimizing a regularized energy functional .",
    "specifically , we first decompose the inter - view constraint propagation problem into a set of independent semi - supervised learning @xcite subproblems . through formulating these subproblems uniformly as minimizing a regularized energy functional ,",
    "we thus develop an efficient algorithm for inter - view constraint propagation based on the traditional graph - based label propagation technique @xcite . in summary",
    ", we succeed in giving an insightful explanation of inter - view constraint propagation from a graph - based semi - supervised learning viewpoint .",
    "however , since graph - based label propagation has been adopted for basic optimization , there remains one problem to be concerned in inter - view constraint propagation , i.e. , how to exploit intra - view pairwise constraints for graph construction within each view . in this paper , we develop two constrained graph construction methods for inter - view constraint propagation , which only differ in how the intra - view pairwise constraints are exploited .",
    "the first method limits our inter - view constraint propagation to a single view and then utilize the constraint propagation results to adjust the weight matrix of each view , while the second method formulates graph construction as sparse representation and then directly add the intra - view pairwise constraints into sparse representation .",
    "the flowchart of our inter - view constraint propagation with constrained graph construction is illustrated in fig .",
    "[ fig.1 ] , where only two views ( i.e. text and image ) are considered .",
    "it should be noted that , when multiple views refer to text , image , audio and so on , the output of our inter - view constraint propagation actually denotes the correlation between different media views .",
    "that is , the proposed algorithm can be directly used for cross - view retrieval ( also see examples in fig .  [ fig.3 ] ) which has drawn much attention recently @xcite . for cross - view retrieval , it is not feasible to combine multiple views just as previous multi - view retrieval methods @xcite .",
    "more notably , the two closely related methods @xcite for multi - view clustering are actually incompetent for cross - view retrieval .",
    "finally , to emphasize our main contributions , we summarize the following distinct advantages of our pairwise constraint propagation on multi - view data :    * we have made the first attempt to give an efficient solution to inter - view constraint propagation from a graph - based semi - supervised learning viewpoint .",
    "* we have developed two constrained graph construction methods so that the intra - view pairwise constraints can also be exploited for inter - view constraint propagation .",
    "* when applied to cross - view retrieval , our inter - view constraint propagation has been shown to achieve promising results with respect to the state - of - the - art . *",
    "although only evaluated in cross - view retrieval , our inter - view constraint propagation can be readily extended to many other multi - view tasks .    the remainder of this paper is organized as follows . in section",
    "[ sect : intercp ] , we formulate inter - view constraint propagation from a semi - supervised learning viewpoint . in section [",
    "sect : cgc ] , we develop two constrained graph construction methods for our inter - view constraint propagation . in section [",
    "sect : cmr ] , our inter - view constraint propagation is applied to cross - view retrieval .",
    "finally , sections [ sect : exp ] and [ sect : con ] provide the experimental results and conclusions , respectively .",
    "in this section , we first formulate inter - view constraint propagation as minimizing a regularized energy functional from a semi - supervised learning viewpoint .",
    "furthermore , we develop an efficient algorithm for inter - view constraint propagation based on the label propagation technique @xcite .      given a set of inter - view pairwise constraints defined over pairs of data points from different views , the goal of inter - view constraint propagation is to learn the cross - view relationships from these initial pairwise constraints .",
    "since the similarity of two data points from different views is unknown in practice , inter - view constraint propagation on multi - view data is much more challenging than the traditional pairwise constraint propagation over a single view .",
    "considering that this multi - view problem can be readily decomposed into a series of two - view subproblems , we focus on inter - view constraint propagation on two - view data in the following .",
    "let @xmath0 be a two - view dataset , where @xmath1 and @xmath2 .",
    "it should be noted that we may have @xmath3 . as an example",
    ", a two - view dataset is shown in fig .",
    "[ fig.1 ] , with image and text being the two different views .",
    "for the two - view dataset @xmath0 , we can define a set of initial must - link constraints as @xmath4 and a set of initial cannot - link constraints as @xmath5 , where @xmath6 ( or @xmath7 ) is the class label of @xmath8 ( or @xmath9 ) . here",
    ", the two data points @xmath10 and @xmath11 are assumed to share the same class label set . if the class labels are not provided , the inter - view pairwise constraints can be defined only based on the correspondence between two views , which can be readily obtained from web - based content ( e.g. wikipedia articles ) .",
    "several examples of inter - view pairwise constraints are illustrated in fig .",
    "[ fig.1 ] .",
    "we can now state that the goal of inter - view constraint propagation is to propagate the two sets of initial pairwise constraints @xmath12 and @xmath13 across both @xmath14 and @xmath15 .",
    "in fact , this is equivalent to deriving the best solution @xmath16 from both @xmath12 and @xmath13 , with @xmath17 . here ,",
    "any exhaustive set of inter - view pairwise constraints is denoted as @xmath18 , where @xmath19 means @xmath20 is a must - link constraint while @xmath21 means @xmath20 is a cannot - link constraint , with @xmath22 denoting the confidence score of @xmath20 being a must - link ( or cannot - link ) constraint .",
    "hence , @xmath23 can actually be regarded as the feasible solution set of inter - view constraint propagation .",
    "although it is difficult to directly find the best solution @xmath16 to inter - view constraint propagation , we can tackle this challenging problem by decomposing it into a set of independent semi - supervised learning subproblems .",
    "more concretely , we first denote the two sets of initial pairwise constraints @xmath12 and @xmath13 with a single matrix @xmath24 : @xmath25 moreover , by making vertical and horizontal observations on such initial matrix @xmath26 , we decompose the inter - view constraint propagation problem into independent semi - supervised learning subproblems , which is also illustrated in fig .",
    "[ fig.2 ] . finally , given two graphs @xmath27 and",
    "@xmath28 constructed over @xmath0 with @xmath29 ( or @xmath30 ) being the edge weight matrix defined over the vertex set @xmath14 ( or @xmath15 ) , we utilize the graph - based label propagation method @xcite to uniformly solve these semi - supervised learning subproblems : @xmath31 where @xmath32 ( @xmath33 , or @xmath34 ) denotes the regularization parameter , @xmath35 ( or @xmath36 ) denotes the normalized laplacian matrix defined over @xmath14 ( or @xmath15 ) , @xmath37 denotes the frobenius norm of a matrix , and @xmath38 denotes the trace of a matrix .    .",
    "when we focus on a single pair of data points , e.g. @xmath39 here , the inter - view constraint propagation can be viewed as a two - class semi - supervised learning problem ( in name only ) in both vertical and horizontal directions , where + 1 ( or -1 ) denotes positive ( or negative ) labeled data and 0 denotes unlabeled data.,scaledwidth=30.0% ]    the first and second terms of the above objective function are related to the pairwise constraint propagation over @xmath14 , while the third and fourth terms are related to the pairwise constraint propagation over @xmath15 . moreover",
    ", the fifth term can ensure that the solutions of these two types of pairwise constraint propagation are as approximate as possible .",
    "let @xmath40 and @xmath41 be the best solutions of pairwise constraint propagation over @xmath14 and @xmath15 , respectively .",
    "the best solution of our inter - view constraint propagation is defined as follows : @xmath42 as for the second and fourth terms , they are known as the energy functional @xcite ( or smoothness ) defined over @xmath14 and @xmath15 . in summary , we have formulated intere - view constraint propagation as minimizing a regularized energy functional .",
    "let @xmath43 denote the objective function in equation ( [ eq : intercp ] ) .",
    "the alternate optimization technique can be adopted to solve @xmath44 as follows : 1 ) fix @xmath45 , and find @xmath46 ; 2 ) fix @xmath47 , and find @xmath48 .",
    "* pairwise constraint propagation over @xmath14 : * when @xmath49 is fixed at @xmath41 , the solution of @xmath50 can be found by solving the following linear equation @xmath51 which can be equivalently transformed into : @xmath52 where @xmath53 and @xmath54 . since @xmath55 is positive definite , we then obtain an analytical solution : @xmath56 however , this analytical solution is not efficient for large datasets , since matrix inverse has a time cost of @xmath57 .",
    "fortunately , equation ( [ eq : lex ] ) can also be _ efficiently found using label propagation _",
    "@xcite with @xmath58-nearest neighbor ( @xmath58-nn ) graph .",
    "* pairwise constraint propagation over @xmath15 : * when @xmath59 is fixed at @xmath40 , the solution of @xmath60 can be found by solving the following linear equation @xmath61 which can be equivalently transformed into : @xmath62 where @xmath63 and @xmath54 . since @xmath64 is positive definite , we then obtain an analytical solution : @xmath65 which involves time - consuming matrix inverse .",
    "in fact , the linear equation ( [ eq : ley ] ) can also be efficiently solved using label propagation @xcite with @xmath58-nn graph .",
    "let @xmath66 ( or @xmath67 ) denote the weight matrix of the @xmath58-nn graph constructed over @xmath14 ( or @xmath15 ) .",
    "the complete algorithm for inter - view constraint propagation is summarized as follows :    ( 1 ) : :    compute two matrices @xmath68 and    @xmath69 , where @xmath70 ( or    @xmath71 ) is a diagonal matrix with its    @xmath72-th diagonal entry being the sum of the    @xmath72-th row of @xmath66 ( or    @xmath67 ) ; ( 2 ) : :    initialize @xmath73 ,    @xmath74 , and    @xmath75 ; ( 3 ) : :    iterate @xmath76    until convergence at @xmath40 , where    @xmath77    and @xmath54 ; ( 4 ) : :    iterate @xmath78    until convergence at @xmath41 , where    @xmath79 ; ( 5 ) : :    iterate steps ( 3)(4 ) until convergence , and output the final solution    @xmath80 .",
    "according to the convergence analysis in @xcite , step ( 3 ) converges to @xmath81 , equal to the solution ( [ eq : lpx ] ) given that @xmath82 and @xmath83 .",
    "similarly , step ( 4 ) converges to @xmath84 , equal to the solution ( [ eq : lpy ] ) given that @xmath85 and @xmath86 . in the experiments",
    ", we find that steps ( 3)(5 ) generally converge in very limited iterations ( @xmath8710 ) .",
    "moreover , based on @xmath58-nn graphs , the above inter - view constraint propagation algorithm has a time cost of @xmath88 , which is proportional to the number of all possible inter - view pairwise constraints .",
    "hence , we consider that this algorithm can provide an efficient solution to inter - view constraint propagation ( note that even a simple assignment operator on @xmath89 incurs a time cost of @xmath90 ) .",
    "in the last section , we have just developed an efficient inter - view constraint propagation algorithm based on the graph - based label propagation technique . however , since graph - based label propagation has been adopted as a basic optimization technique , there remains one problem to be concerned in inter - view constraint propagation , i.e. , how to exploit intra - view pairwise constraints for graph construction within each view . in this section , we then develop two constrained graph construction methods for inter - view constraint propagation , which only differ in how the intra - view pairwise constraints are exploited . to ensure our inter - view constraint propagation algorithm runs efficiently even on large datasets , we utilize the traditional @xmath58-nn graph construction as the basis of our constrained graph construction , i.e. , the obtained two constrained graphs can be considered as the variants of @xmath58-nn graph . in the following , we will only elaborate how to construct the graph @xmath27 over @xmath14 .",
    "the graph @xmath28 over @xmath15 can be constructed exactly in the same way .",
    "the first constrained graph construction method limits our inter - view constraint propagation proposed in section  [ sect : intercp ] to a single view ( i.e. intra - view constraint propagation over @xmath14 ) and then utilize the obtained results of intra - view constraint propagation to adjust the weight matrix , which is thus called as constrained weight adjustment ( cwa ) . according to the convergence analysis in section  [ subsect : alg ] , we construct a @xmath58-nn graph over @xmath14 to speed up our intra - view constraint propagation .",
    "we have just provided a sound solution to the challenging problem of intra - view constraint propagation in section  [ sect : intercp ] . in this subsection ,",
    "we further consider pairwise constraint propagation over a single view , where each pairwise constraint is defined over a pair of data points from the same view .",
    "in fact , this intra - view constraint propagation problem can also be solved from a semi - supervised learning viewpoint by limiting our inter - view constraint propagation to a single view .",
    "given the dataset @xmath91 , we denote the set of initial must - link constraints as @xmath92 and the set of initial cannot - link constraints as @xmath93 , where @xmath94 is the label of data point @xmath10 .",
    "similar to our representation of the initial inter - view pairwise constraints , we first denote the initial intra - view pairwise constraints @xmath95 and @xmath96 with a single matrix @xmath97 : @xmath98 furthermore , by making vertical and horizontal observations on @xmath99 , we further decompose the intra - view constraint propagation problem into semi - supervised learning subproblems , just as our interpretation of inter - view constraint propagation from a semi - supervised learning viewpoint .",
    "these subproblems can be similarly merged to a single optimization problem ( similar to @xcite ) : @xmath100 where @xmath101 ( or @xmath34 ) denotes the regularization parameter , and @xmath102 denotes the normalized laplacian matrix defined over the @xmath58-nn graph .",
    "the second and fourth terms of the above equation denote the energy functional @xcite ( or the smoothness measure ) defined over @xmath14 . in summary , we have also formulated intra - view constraint propagation as minimizing a regularized energy functional .",
    "similar to what we have done for solving equation ( [ eq : intercp ] ) , we can adopt the alternate optimization technique to find the best solution to the above intra - view constraint propagation problem .",
    "let @xmath29 denote the weight matrix of the @xmath58-nn graph constructed over the dataset @xmath14 .",
    "the proposed algorithm for our intra - view constraint propagation is outlined as follows :    ( 1 ) : :    compute    @xmath103 ,    where @xmath104 is a diagonal matrix with its entry    @xmath105 being the sum of row @xmath72 of    @xmath29 ; ( 2 ) : :    initialize @xmath106 , @xmath107 , and    @xmath108 ; ( 3 ) : :    iterate @xmath109 until    convergence at @xmath110 , where    @xmath111 and    @xmath112 ; ( 4 ) : :    iterate @xmath113 until    convergence at @xmath114 ; ( 5 ) : :    iterate steps ( 3)(4 ) until the stopping condition is satisfied , and    obtain @xmath115 . ( 6 ) : :    output the normalized solution @xmath116 , where    @xmath117 denotes the maximum entry of    @xmath89 .    in the experiments , we find that steps ( 3)(5 ) generally converge in very limited iterations ( @xmath8710 ) .",
    "moreover , based on @xmath58-nn graph , our algorithm has a time cost of @xmath118 proportional to the number of all possible pairwise constraints .",
    "hence , it can be considered to provide an efficient solution .",
    "it should be noted that the normalized output @xmath119 of our intra - view constraint propagation represents an exhaustive set of intra - view pairwise constraints .",
    "our original motivation is to construct a new graph over @xmath14 that is fully consistent with @xmath89 .",
    "in fact , we can exploit @xmath89 for such graph construction by adjusting the original normalized weight matrix @xmath29 ( i.e. @xmath120 ) just as @xcite : @xmath121 since @xmath122 is nonnegative and symmetric , we then use it as the new weight matrix .",
    "moreover , we can find that @xmath123 ( or @xmath124 ) if @xmath125 ( or @xmath126 ) .",
    "that is , the new weight matrix @xmath127 is derived from the original weight matrix @xmath29 by increasing @xmath128 for the must - link constraints with @xmath129 and decreasing @xmath130 for the cannot - link constraints with @xmath131 .",
    "this is entirely consistent with our original motivation of exploiting intra - view pairwise constraints for graph construction .",
    "once we have constructed the new weight matrix @xmath127 over @xmath14 , we can similarly construct the new weight matrix @xmath132 over @xmath15 .",
    "based on these two new weight matrices , our inter - view constraint propagation can be performed with constrained graph construction ( cgc ) ( as shown in fig .",
    "[ fig.1 ] ) using constrained weight adjustment ( cwa ) developed here .",
    "the second constrained graph construction method formulates graph construction as sparse representation @xcite and then directly add the intra - view pairwise constraints into sparse representation , which is thus called as constrained sparse representation ( csr ) .",
    "our work is mainly inspired by recent effort to exploit sparse representation for graph construction , i.e. , @xmath133-graph construction @xcite .",
    "the basic idea of @xmath133-graph construction is to seek a sparse linear reconstruction of each data point with the other data points .",
    "however , such @xmath133-graph construction may become infeasible since it incurs too much time cost given a large data size @xmath134 .",
    "hence , we only consider the @xmath58 nearest neighbors of each data point for its sparse linear reconstruction , which thus becomes a much smaller scale optimization problem ( @xmath135 ) .",
    "more notably , due to such neighborhood limitation , the obtained @xmath133-graph is actually a variant of @xmath58-nn graph , which can ensure that our inter - view constraint propagation proposed in section  [ sect : intercp ] runs efficiently on large datasets . finally , to exploit intra - view pairwise constraints for @xmath133-graph construction , we seek a constrained sparse linear reconstruction of each data point .",
    "we start with the problem formulation for sparse linear reconstruction of each data point in its @xmath58-nearest neighborhood . given a data point @xmath136 ,",
    "we suppose it can be reconstructed using its @xmath58-nearest neighbors ( their indices are collected into @xmath137 ) , which results in an underdetermined linear system : @xmath138 , where @xmath139 is a vector that stores unknown reconstruction coefficients , and @xmath140_{j\\in \\mathcal{n}_k(i)}$ ] is an overcomplete dictionary with @xmath58 bases . according to @xcite , if the solution for @xmath10 is sparse enough , it can be recovered by : @xmath141 where @xmath142 is the @xmath133-norm of @xmath143 . given the kernel ( affinity ) matrix @xmath144 computed over @xmath14 ,",
    "we make use of the kernel trick and transform the above problem into : @xmath145 where @xmath146_{j\\in \\mathcal{n}_k(i ) } \\in r^k$ ] , @xmath147_{j , j'\\in \\mathcal{n}_k(i ) } \\in r^{k\\times k}$ ] . in practice , due to the noise in the data",
    ", we can reconstruct @xmath148 similar to @xcite : @xmath149 , where @xmath150 is the noise term .",
    "the above @xmath133-optimization problem can then be redefined by minimizing the @xmath133-norm of both reconstruction coefficients and reconstruction error : @xmath151 where @xmath152 \\in r^{k \\times 2k}$ ] and @xmath153^t$ ] .",
    "this convex optimization can be solved by general linear programming and has a globally optimal solution .",
    "after we have obtained the reconstruction coefficients for all the data points by the above sparse linear reconstruction , the weight matrix @xmath154 can be defined by : @xmath155 where @xmath156 denotes the @xmath157-th element of the vector @xmath158 , and @xmath159 means that @xmath160 is the @xmath157-th element of the set @xmath137 . by setting the weight matrix @xmath161 , we construct a graph @xmath27 over @xmath14 , which is called as @xmath133-graph since it is constructed by @xmath133-optimization .      in the above @xmath133-graph construction , we have ignored intra - view pairwise constraints ( see examples in fig .  [ fig.1 ] ) .",
    "in fact , this supervisory information can be exploited for @xmath133-graph construction through laplacian regularization @xcite .",
    "our basic idea is to first derive laplacian regularization from intra - view pairwise constraints and then incorporate this constrained term into sparse linear reconstruction ( the key step of @xmath133-graph construction ) . in the following",
    ", we will first elaborate how to derive a new laplacian regularization term from intra - view pairwise constraints .",
    "given a set of intra - view must - link constraints @xmath162 and a set of intra - view cannot - link constraints @xmath163 defined over @xmath14 , we can represent both @xmath162 and @xmath163 using a single matrix @xmath164 exactly the same as equation ( [ eq : pcs ] ) .",
    "the normalized laplacian matrix limited to the @xmath58-nearest neighborhood of data point @xmath10 can thus be defined as : @xmath165 where @xmath166_{j , j'\\in \\mathcal{n}_k(i)}\\in r^{k\\times k}$ ] , and @xmath167 is a diagonal matrix with its @xmath160-th diagonal element being the sum of the @xmath160-th row of @xmath168 . here",
    ", we define the similarity matrix ( i.e. @xmath168 ) limited to the @xmath58-nearest neighborhood @xmath137 of @xmath10 based on the intra - view pairwise constraints stored in @xmath169 . from this normalized laplacian matrix @xmath170",
    ", we can derive the laplacian regularization term for the sparse representation problem ( [ eq : sr ] ) as @xmath171 , the same as the original definition in @xcite .",
    "after we have formulated @xmath133-norm laplacian regularization based on intra - view pairwise constraints , we can further incorporate this constrained term into sparse linear reconstruction used for @xmath133-graph construction . more concretely , by introducing noise terms for linear reconstruction and @xmath133-norm laplacian regularization , we transform the sparse representation problem ( [ eq : sr ] ) into @xmath185||_1 , \\nonumber \\\\ & & \\mathrm{s.t.}~~\\hat{x}_i = c_i\\alpha_i+\\zeta_i,~0=\\tilde{c}_i \\alpha_i+\\xi_i , \\label{eq : ssr}\\end{aligned}\\ ] ] where the reconstruction error and laplacian regularization with respect to @xmath143 are controlled by @xmath150 and @xmath186 , respectively .",
    "let @xmath187^t$ ] , @xmath188 $ ] , and @xmath189^t$ ] .",
    "we finally solve the following constrained spare representation problem for @xmath133-graph construction : @xmath190 which takes the same form as the original spare representation problem ( [ eq : srsol ] ) .",
    "here , it is noteworthy that this constrained spare representation ( csr ) problem can be solved very efficiently , since it is limited to @xmath58-nearest neighborhood .",
    "the weight matrix @xmath29 of the @xmath133-graph @xmath191 can be defined the same as equation ( [ eq : l1wt ] ) .    in our csr formulation",
    ", the @xmath133-norm laplacian regularization can be smoothly incorporated into the original sparse representation problem ( [ eq : sr ] ) . however , this is not true for the traditional laplacian regularization @xcite , which may introduce extra parameters ( hard to tune in practice ) into the @xmath133-optimization for sparse representation .",
    "meanwhile , our @xmath133-norm laplacian regularization can induce another type of sparsity ( see the extra noise term @xmath186 ) , which can not be ensured by the traditional laplacian regularization .",
    "moreover , the @xmath192-laplacian regularization @xcite can also be regarded as an ordinary @xmath133-generalization of the laplacian regularization when @xmath193 . according to @xcite , by defining a matrix @xmath194 , the @xmath192-laplacian regularization can be formulated as @xmath195 , similar to our @xmath133-norm laplacian regularization .",
    "hence , we can similarly apply the @xmath192-laplacian regularization with @xmath193 to constrained spare representation .",
    "however , such laplacian regularization incurs large time cost due to the large matrix @xmath196 even for small neighborhood size ( e.g. @xmath197 ) .",
    "once we have constructed the @xmath133-graph @xmath27 over @xmath14 , we can similarly construct the @xmath133-graph @xmath198 over @xmath15 .",
    "based on the two weight matrices , our inter - view constraint propagation can be performed with constrained graph construction ( cgc ) ( as shown in fig .",
    "[ fig.1 ] ) using constrained sparse representation ( csr ) developed here .",
    "when multiple views refer to text , image , audio and so on ( see fig .  [ fig.3 ] ) , the output of our inter - view constraint propagation actually can be viewed as the correlation between different media views .",
    "as we have mentioned , given the output @xmath199 of our inter - view constraint propagation , @xmath20 denotes a must - link ( or cannot - link ) constraint if @xmath200 ( or @xmath201 ) . considering the inherent meanings of must - link and cannot - link constraints",
    ", we can state that : @xmath10 and @xmath11 are  positively correlated \" if @xmath200 , while they are  negatively correlated \" if @xmath202 .",
    "hence , we can view @xmath203 as the correlation coefficient between @xmath10 and @xmath11 .",
    "the distinct advantage of such interpretation of @xmath89 as a correlation measure is that @xmath89 can thus be used for ranking on @xmath15 given a query @xmath10 or ranking on @xmath14 given a query @xmath11 .",
    "in fact , this is just the goal of cross - view retrieval which has drawn much attention recently @xcite .",
    "that is , such task can be directly handled by our inter - view constraint propagation .        in this paper",
    ", we focus on a special case of cross - view retrieval , i.e. only text and image views are considered . in this case , cross - view retrieval is somewhat similar to automatic image annotation @xcite and image caption generation @xcite , since these three tasks all aim to learn the relations between the text and image views . however , even if only text and image views are considered , cross - view retrieval is still quite different from automatic image annotation and image caption generation .",
    "more concretely , automatic image annotation relies on very limited types of textual representations and mainly associates images only with textual keywords , while cross - view retrieval is designed to deal with much more richly annotated data , motivated by the ongoing explosion of web - based content such as news archives and wikipedia pages .",
    "similar to cross - view retrieval , image caption generation can also deal with more richly annotated data ( i.e. captions ) with respect to the textual keywords concerned in automatic image annotation .",
    "however , this task tends to model image captions as sentences by exploiting certain prior knowledge ( e.g. the @xmath87object , action , scene@xmath204 triplets used in @xcite ) , different from cross - view retrieval that focuses on associating images with complete text articles using no prior knowledge from the text view ( any general textual representations are applicable actually once their similarities are provided ) .                    in the context of cross - view retrieval ,",
    "one notable recent work is @xcite which first learns the correlation between the text and image views with canonical correlation analysis ( cca ) @xcite and then achieves the abstraction by representing text and image at a more general semantic level .",
    "however , two separate steps , i.e. correlation analysis ( ca ) and semantic abstraction ( sa ) , are involved in this modeling , and the use of semantic abstraction after cca ( i.e. ca+sa ) seems rather ad hoc .",
    "fortunately , this problem can be completely addressed by our inter - view constraint propagation ( inter - cp ) .",
    "the semantic information ( e.g. class labels ) associated with images and text can be used to define the initial must - link and cannot - link constraints based on the training dataset , while the correlation between text and image views can be explicitly learnt by the proposed algorithm in section  [ sect : intercp ] .",
    "that is , the correlation analysis and semantic abstraction has been successfully integrated in our inter - view constraint propagation framework .",
    "the effectiveness of such integration as compared to ca+sa @xcite is preliminarily verified by several cross - view retrieval examples shown in fig .",
    "[ fig.3 ] .",
    "further verification will be provided in our later experiments .",
    "more notably , although only tested in cross - view retrieval , our inter - view constraint propagation can be readily extended to other multi - view tasks , since it has actually learnt the correlation between different views .",
    "in this section , our inter - view constraint propagation ( inter - cp ) algorithm is evaluated in the challenging application of cross - view retrieval .",
    "we focus on comparing our inter - cp algorithm with the state - of - the - art approach @xcite , since they both consider not only correlation analysis ( ca ) but also semantic abstraction ( sa ) for text and image views .",
    "moreover , we also make comparison with another two closely related approaches that integrate ca and sa for cross - view retrieval similar to @xcite but perform correlation analysis by partial least squares ( pls ) @xcite and cross - modal factor analysis ( cfa ) @xcite instead of cca , respectively . in the following ,",
    "these two ca+sa approaches are denoted as ca+sa ( pls ) and ca+sa ( cfa ) , while the state - of - the - art approach @xcite is denoted as ca+sa ( cca ) . finally , to show the effectiveness of constrained graph construction ,",
    "we construct four types of graphs for our inter - cp algorithm : @xmath58-nn graph ( @xmath58-nn ) , @xmath133-graph using sparse representation ( sr ) , @xmath58-nn graph using constrained weight adjustment ( cwa ) , and @xmath133-graph using constrained sparse representation ( csr ) .",
    "we select two different datasets for performance evaluation .",
    "the first one is a wikipedia benchmark dataset @xcite , which contains a total of 2,866 documents derived from wikipedia s  featured articles \" .",
    "each document is actually a text - image pair , annotated with a label from the vocabulary of 10 semantic classes .",
    "this benchmark dataset @xcite is split into a training set of 2,173 documents and a test set of 693 documents .",
    "moreover , the second dataset consists of totally 8,564 documents crawled from the photo sharing website flickr .",
    "the image and text views of each document denote a photo and a set of tags provided by the users , respectively .",
    "although such text presentation does not take a free form as that for the wikipedia dataset , it is rather noisy since many of the tags may be incorrectly annotated by the users .",
    "this flickr dataset is organized into 11 semantic classes .",
    "we split it into a training set of 4,282 documents and a test set of the same size .    for the above two datasets , we take the same strategy as @xcite to generate both text and image representation . more concretely , in the wikipedia dataset",
    ", the text representation for each document is derived from a latent dirichlet allocation model with 10 latent topics , while the image representation is based on a bag - of - words model with 128 visual words learnt from the extracted sift descriptors , just as @xcite . moreover , for the flickr dataset , we generate the text and image representation similarly , and the main difference is that we select a relatively large visual vocabulary ( of the size 2,000 ) for image representation and refine the noisy textual vocabulary to the size 1,000 by a preprocessing step for text representation .    in our experiments ,",
    "the intra - view pairwise constraints used for our cgc and inter - view pairwise constraints used for our inter - cp are initially derived from the class labels of the training documents of each dataset .",
    "the performance of our inter - cp with cgc is evaluated on the test set . here ,",
    "two tasks of cross - view retrieval are considered : text retrieval using an image query , and image retrieval using a text query . in the following ,",
    "these two tasks are denoted as  image query \" and  text query \" , respectively .",
    "for each task , the retrieval results are measured with mean average precision ( map ) which has been widely used in the image retrieval literature @xcite .",
    "let @xmath14 denote the text representation and @xmath15 denote the image representation . for our inter - cp algorithm , we perform cgc over @xmath14 and @xmath15 with the same @xmath58 . the parameters of our inter - cp algorithm with cgc can be selected by fivefold cross - validation on the training set .",
    "for example , according to fig .",
    "[ fig.4 ] , we set the parameters of our inter - cp ( csr is used for cgc ) on the wikipedia dataset as : @xmath205 , @xmath206 , @xmath207 , and @xmath197 .",
    "it is noteworthy that our inter - cp with csr is not sensitive to these parameters .",
    "moreover , the parameters of our inter - cp with cwa can be similarly set to their respective optimal values .",
    "to summarize , we have selected the best values for all the parameters of our ucp algorithm with cgc by cross - validation on the training set . for fair comparison , we take the same parameter selection strategy for other closely related algorithms .",
    "0.18 cm    .the cross - view retrieval results on the test set of the wikipedia dataset measured by the map scores . [ cols=\"^,^,^,^\",options=\"header \" , ]",
    "in this paper , we have investigated the challenging problem of pairwise constraint propagation on multi - view data . by decomposing the inter - view constraint propagation problem into a set of independent semi - supervised learning subproblems ,",
    "we have uniformly formulated them as minimizing a regularized energy functional .",
    "more importantly , these semi - supervised learning subproblems can be solved efficiently using label propagation with @xmath58-nn graph .",
    "we then develop two constrained graph construction methods for our inter - view constraint propagation , and the obtained two graphs can be considered as the variants of @xmath58-nn graph .",
    "the experimental results in cross - view retrieval have shown the promising performance of our inter - view constraint propagation with constrained graph construction . for future work",
    ", our method will be extended to other multi - view tasks .",
    "this work was supported by national natural science foundation of china under grants 61202231 and 61222307 , national key basic research program ( 973 program ) of china under grant 2014cb340403 , beijing natural science foundation of china under grant 4132037 , the fundamental research funds for the central universities and the research funds of renmin university of china under grant 14xnlf04 , and a grant from microsoft research asia .",
    "e.  bruno , n.  moenne - loccoz , and s.  marchand - maillet , `` design of multimodal dissimilarity spaces for retrieval of video documents , '' _ ieee trans .",
    "pattern analysis and machine intelligence _ , vol .",
    "30 , no .  9 , pp . 15201533 , 2008 .",
    "z.  lu and y.  peng , `` exhaustive and efficient constraint propagation : a graph - based learning approach and its applications , '' _ international journal of computer vision _ , vol .",
    "103 , no .  3 , pp .",
    "306325 , 2013 .",
    "d.  donoho , `` for most large underdetermined systems of linear equations the minimal @xmath208-norm solution is also the sparsest solution , '' _ communications on pure and applied mathematics _ ,",
    "59 , no .  7 , pp .",
    "797829 , 2004 ."
  ],
  "abstract_text": [
    "<S> this paper presents a graph - based learning approach to pairwise constraint propagation on multi - view data . </S>",
    "<S> although pairwise constraint propagation has been studied extensively , pairwise constraints are usually defined over pairs of data points from a single view , i.e. , only intra - view constraint propagation is considered for multi - view tasks . </S>",
    "<S> in fact , very little attention has been paid to inter - view constraint propagation , which is more challenging since pairwise constraints are now defined over pairs of data points from different views . in this paper , we propose to decompose the challenging inter - view constraint propagation problem into semi - supervised learning subproblems so that they can be efficiently solved based on graph - based label propagation . to the best of our knowledge , this is the first attempt to give an efficient solution to inter - view constraint propagation from a semi - supervised learning viewpoint . moreover , since graph - based label propagation has been adopted for basic optimization , we develop two constrained graph construction methods for inter - view constraint propagation , which only differ in how the intra - view pairwise constraints are exploited . </S>",
    "<S> the experimental results in cross - view retrieval have shown the promising performance of our inter - view constraint propagation .    </S>",
    "<S> pairwise constraint propagation , multi - view data , label propagation , graph construction , cross - view retrieval </S>"
  ]
}