{
  "article_text": [
    "for many decades , statisticians have made attempts to prepare the bayesian omelette without breaking the bayesian eggs ; that is , to obtain probabilistic likelihood - based inferences without relying on informative prior distributions .",
    "a recent example is murray aitkin s recent book , _ statistical inference _ , which is the culmination of a long research program on the topic of integrated evidence , exemplified by the discussion paper of @xcite .",
    "the book , subtitled _ an integrated bayesian / likelihood approach _ , proposes handling statistical hypothesis testing and model selection via comparisons of posterior distributions of likelihood functions under the competing models or via the posterior distribution of the likelihood ratios corresponding to those models .",
    "( the essence of the proposal is detailed in section [ small ? ] . ) instead of comparing bayes factors or performing posterior predictive checks ( comparing observed data to posterior replicated pseudo - datasets ) , _ statistical inference _  recommends a fusion between likelihood and bayesian paradigms that allows for the perpetuation of noninformative priors in testing settings where standard bayesian practice prohibits their usage @xcite or requires an extended decision - theoretic framework @xcite .",
    "while we appreciate the considerable effort made by aitkin to place his theory within a bayesian framework , we remain unconvinced of the said coherence , for reasons exposed in this note .",
    "l0.22        from our bayesian perspective , and for several distinct reasons detailed in the present note , integrated bayesian / likelihood inference can not fit within the philosophy of bayesian inference . aitkin",
    "s commendable attempt at creating a framework that incorporate the use of arbitrary noninformative priors in model choice procedures is thus incoherent in this bayesian respect . when using improper priors lead to meaningless bayesian procedures for posterior model comparison , we see this as a sign that the bayesian model will not work for the problem at hand . rather than trying at all cost to keep the offending model and define marginal posterior probabilities by fiat ( whether by bic , dic , intrinsic bayes factors , or posterior likelihoods ) , we prefer to follow the full logic of bayesian inference and recognize that , when one s bayesian approach leads to a dead end , one must change either one s methodologies or one s beliefs ( or both ) .",
    "bayesians , both subjective and objective , have long recognized the need for tuning , expanding , or otherwise altering a model in light of its predictions ( see , for example , @xcite and @xcite ) , and we view undefined bayes factors as an example where otherwise useful methods are being extended beyond their applicability .",
    "to try to work around such problems without altering the prior distribution is , we believe , an abandonment of bayesian principles and , more importantly , an abandoned opportunity for model improvement .",
    "the criticisms found in the current review are therefore not limited to aitkin s book ; they also apply to previous patches such as the deviance information criterion ( dic ) of @xcite ( which also uses a  posterior \" expectation of the log - likelihood ) and the pseudo - posteriors of @xcite(which make an extensive use of the data in their product of predictives ) .",
    "unlike the author , who has felt the call to construct a partly new @xcite if tentatively unifying foundation for statistical inference , we have the luxury of feeling that we already live in a comfortable ( even if not flawless ) inferential house .",
    "thus , we come to aitkin s book not with a perceived need to rebuild but rather with a view toward strengthening the potential shakiness of the pillars that support our own inferences .",
    "a key question when looking at any method for probabilistic inference that is not fully bayesian is : for the applied problems that interest us , does the proposed new approach achieve better performances than our existing methods ?",
    "our answer , to which we arrive after careful thought , is no .    as an evaluation of the ideas found in _",
    "statistical inference _ , the criticisms found in this review are inherently limited .",
    "we do not claim here that aitkin s approach is wrong _ per se _ merely that it does not fit within our inferential methodology , namely bayesian statistics , despite using bayesian tools .",
    "we acknowledge that statistical methods do not , and most likely never will , form a seamless logical structure",
    ". it may thus very well be that the approach of comparing posterior distributions of likelihoods could be useful for some actual applications , and perhaps aitkin s book will inspire future researchers to demonstrate this .",
    "_ statistical inference",
    "_  begins with a crisp review of frequentist , likelihood and bayesian approaches to inference and then proceeds to the main issue : introducing the `` integrated bayes / likelihood approach '' , first described in chapter 2 .",
    "much of the remaining methodological material appears in chapters 4 ( `` unified analysis of finite populations '' ) and 7 ( `` goodness of fit and model diagnostics '' ) .",
    "the remaining chapters apply aitkin s principles to various examples .",
    "the present article discusses the basic ideas in _ statistical inference _ , then consider the relevance of aitkin s methodology within the bayesian paradigm .",
    " this quite small change to standard bayesian analysis allows a very general approach to a wide range of apparently different inference problems ; a particular advantage of the approach is that it can use the same noninformative priors . \" _ statistical inference _ , page xiii    the  quite small change \" advocated by _",
    "statistical inference _  consists in envisioning the likelihood function @xmath0 as a generic function of the parameter @xmath1 that can be processed a posteriori ( that is , with a distribution induced by the posterior @xmath2 ) , hence allowing for ( posterior ) cdf , mean , variance and quantiles .",
    "in particular , the central tool for aitkin s model fit is the  posterior cdf \" of the likelihood , @xmath3 as argued by the author ( chapter 2 , page 21 ) , this  small change \" in perspective has several appealing features :    * the approach is general and allows to resolve the difficulties with the bayesian processing of point null hypotheses , being defined solely by the bayesian model associated with @xmath0 ; * the approach allows for the use of generic noninformative and improper priors , again by being relative to a single model ; * the approach handles more naturally the ",
    "vexed question of model fit \" , still for the same reason ; * the approach is `` simple . ''    as noted above , the setting is quite similar to spiegelhalter et al.s ( @xcite ) dic in that the deviance @xmath4 is a renaming of the likelihood and is considered  a posteriori \" both in @xmath5 $ ] and in @xmath6 , where @xmath7 is a bayesian estimator of @xmath1 , since @xmath8 the discussion of @xcite made this point clear , see in particular @xcite , even though the authors disagreed .",
    "@xcite make a similarly ambiguous proposal that also relates to @xcite by its usage of cross - validation quantities .",
    "we however dispute both the appropriateness and the magnitude of the change advocated in _ statistical inference _  and show below why , in our opinion , this shift in paradigm constitutes a new branch of statistical inference , differing from bayesian analysis on many points .",
    "first , using priors and posteriors is no guarantee that inference is bayesian @xcite .",
    "empirical bayes techniques are witnesses of this @xcite .",
    "aitkin s key departure from bayesian principles means that his procedure has to be validated on its own , rather than benefiting from the coherence inherent to bayesian procedures .",
    "the practical advantage of the likelihood / bayesian approach may be convenience , but the drawback is that the method pushes both the user and the statistician _ away _ from progress in model building . within a model , even while giving meaningless ( or at least not universally accepted ) values for marginal likelihoods that are needed for bayesian model comparison .",
    "it does when interest shifts from @xmath9 to @xmath10 that the bayesian must set aside most of noninformative @xmath11 and , perhaps reluctantly , set up an informative model .",
    "see , e.g. , @xcite and @xcite for some current perspectives on bayesian model choice using noninformative priors . ]",
    "we envision bayesian data analysis as comprising three steps : ( 1 ) model building , ( 2 ) inference , and ( 3 ) model checking . in particular , we view steps ( 2 ) and ( 3 ) as separate .",
    "inference works well , with many exciting developments still in the coming , handling complex models , leading to an unlimited range of applications , and a partial integration with classical approaches ( as in the empirical bayes work of @xcite , or more recently the similarities between hierarchical bayes and frequentist false discovery rates discussed by @xcite ) , causal inference , machine learning , and other aims and methods of statistical inference .    even in the face of all this progress on inference ,",
    "bayesian model checking remains a bit of an anomaly , with the three leading bayesian approaches being bayes factors , posterior predictive checks , and comparisons of models based on prediction error and other loss - based measures .",
    "( decision - theoretic analyses as in @xcite , while intellectually convincing , have not gained the same amount of popularity . )",
    "unfortunately , as aitkin points out , none of these model checking methods works completely smoothly : bayes factors depend on aspects of a model that are untestable and are commonly assigned arbitrarily ; posterior predictive checks are , in general ,  conservative \" in the sense of producing @xmath12-values whose probability distributions are concentrated near @xmath13 ; and prediction error measures ( which include cross - validation and dic ) require the user to divide data into test and validation sets , lest they use the data twice ( a point discussed immediately below ) . the setting is even bleaker when trying to incorporate noninformative priors @xcite and new proposals are clearly of interest .       a persistent criticism of the posterior likelihood approach ( ... )",
    "has been based on the claim that these approaches are ` using the data twice , ' or are  violating temporal coherence . \" _ statistical inference _",
    ", page 48     using the data twice \" is not our main reservation about the method  if only because this is a rather vague concept .",
    "obviously , one could criticize the use of the  posterior expectation \" of the likelihod as being the ratio of the marginal of the twice replicated data over the marginal of the original data , @xmath14 = \\int l(\\theta , x ) \\pi(\\theta|x)\\,\\text{d}\\theta = \\dfrac{m(x , x)}{m(x)}\\,,\\ ] ] similar to @xcite ( a criticism clearly expressed in the discussion therein ) .",
    "however , a more fundamental issue is that the  posterior \" distribution of the likelihood function can not be justified from a bayesian perspective . _ statistical inference _  stays away from decision - theory ( as stated on page xiv ) so there is no derivation based on a loss function or such .",
    "our primary difficulty with the integrated likelihood idea ( and dic as well ) is ( a ) that the likelihood function does not exist a priori and ( b ) that it requires a joint distribution to be properly defined in the case of model comparison .",
    "the case for ( a ) is arguable , as aitkin would presumably contest that there exists a joint distribution on the likelihood , even though the case of an improper prior stands out ( see below ) .",
    "we still see the concept of a posterior probability that the likelihood ratio is larger than @xmath15 as meaningless . the case for ( b )",
    "is more clear - cut in that when considering two models , hence a likelihood ratio , a bayesian analysis does require a joint distribution on the two sets of parameters to reach a decision , even though in the end only one set will be used .",
    "as detailed below in section [ prodpost ] , this point is related with the introduction of pseudo - priors by @xcite who needed arbitrary defined prior distributions on the parameters that do not exist .    in the specific case of an improper prior , aitkin s",
    "approach can not be validated in a probability setting for the reason that there is no joint probability on @xmath16 .",
    "obviously , one could always advance that the whole issue is irrelevant since improper priors do not stand within probability theory .",
    "however , improper priors do stand within the bayesian framework , as demonstrated for instance by @xcite and it is easy to give those priors an exact meaning .",
    "when the data are made of @xmath17 iid observations @xmath18 from @xmath19 and an improper prior @xmath20 is used on @xmath1 , we can consider a _ training sample _",
    "@xcite @xmath21 , with @xmath22 such that @xmath23 if we construct a probability distribution on @xmath1 by @xmath24 the posterior distribution associated with this distribution and the remainder of the sample @xmath25 is given by @xmath26 this distribution is independent from the choice of the training sample ; it only depends on the likelihood of the whole data @xmath27 and it therefore leads to a non - ambiguous posterior distribution on @xmath1 .",
    "however , as is well known , this construction does not lead to produce a joint distribution on @xmath28 , which would be required to give a meaning to aitkin s integrated likelihood .",
    "therefore , his approach can not cover the case of improper priors within a probabilistic framework and thus fails to solve the very difficulty with noninformative priors it aimed at solving .",
    "this is further illustrated by the use of haldane s prior in chapter 4 of _ statistical inference _ , despite it not allowing for empty cells in a contingency table @xcite .",
    "`` the @xmath12-value is equal to the posterior probability that the likelihood ratio , for null hypothesis to alternative , is greater than 1 ( ... ) the posterior probability is @xmath12 that the posterior probability of @xmath29 is greater than 0.5 . '' _ statistical inference _",
    ", pages 4243    those two equivalent statements show that it is difficult to give a bayesian interpretation to aitkin s method , since the two  posterior probabilities \" quoted above are incompatible . indeed ,",
    "a fundamental bayesian property is that the posterior probability of an event related with the parameters of the model is not a random quantity but a number . to consider the ",
    "posterior probability of the posterior probability \" means we are exiting the bayesian domain , both from logical and philosophical viewpoints .    in chapter 2 , aitkin exposes his ( foundational ) reasons for choosing this new approach by integrated bayes / likelihood .",
    "his criticism of bayes factors is based on several points we feel useful to reproduce here :    1 .",
    "[ i ]  have we really eliminated the uncertainty about the model parameters by integration ?",
    "the integrated likelihood ( ... ) is the expected value of the likelihood .",
    "but what of the prior variance of the likelihood ? \"",
    "( page 47 ) .",
    "[ ii ]  any expectation with respect to the prior implies that the data has not yet been observed ( ... ) so the  integrated likelihood `` is the joint distribution of random variables drawn by a two - stage process .",
    "( ... ) the marginal distribution of these random variables is not the same as the distribution of @xmath30 ( ... ) and does not bear on the question of the value of @xmath1 in that population '' ( page 47 ) .",
    "[ iii ]  we can not use an improper prior to compute the integrated likelihood .",
    "this eliminate the usual improper noninformative priors widely used in posterior inference . \"",
    "( page 47 ) .",
    "[ iv ]  any parameters in the priors ( ... ) will affect the value of the integrated likelihood and this effect does not disappear with increasing sample size \"",
    "( page 47 ) .",
    "[ v ]  the bayes factor is equal to the posterior mean of the likelihood ratio between the models \" _ [ meaning under the full model posterior ] _",
    "( page 48 ) . 6 .",
    "[ vi ] `` the bayes factor diverges as the prior becomes diffuse .",
    "( ... ) this property of the bayes factor has been known since the lindley / bartlett paradox of 1957 '' ( page 48 ) .",
    "the representation [ i ] of the  integrated \" ( or marginal ) likelihood as an expectation under the prior @xmath31\\ ] ] is unassailable and is for instance used as a starting point for motivating the nested sampling method @xcite .",
    "this does not imply that the extension to the variance or to any other moment stated in [ i ] has a similar meaning , nor that the move to the expectation under the posterior is valid within the bayesian paradigm . while the difficulty [ iii ] with improper priors is real , and while the impact of the prior modelling [ iv ] may have a lingering effect , the other points can be easily rejected on the ground that the posterior distribution of the likelihood is meaningless within a bayesian perspective .",
    "this criticism is anticipated by aitkin who protests on pages 48 - 49 that , given point [ v ] , the posterior distribution must be  meaningful , \" since the posterior mean is  meaningful \" , but the interpretation of the bayes factor as a  posterior mean \" is only an interpretation of an existing integral ( in the specific case of nested models ) , it does not give any validation to the analysis .",
    "( the marginal likelihood may similarly be interpreted as a prior mean , despite depending on the observation @xmath32 , as in the nested sampling perspective .",
    "more generaly , bridge sampling techniques also exploit those multiple representations of a ratio of integrals , @xcite . )",
    "one could just as well take [ ii ] above as an argument _ against _ the integrated likelihood / bayes perspective .",
    "in the case of unrelated models to be compared , the fundamental theoretical argument against using posterior distributions of the likelihoods and of related terms is that the approach leads to parallel and separate simulations from the posteriors under each model . _ statistical inference",
    "_  recommends that models be compared via the distribution of the likelihood ratio values , @xmath33 where the @xmath34 s and @xmath35 s are drawn from the respective posteriors .",
    "this choice is similar to scott s ( @xcite ) and to congdon s ( @xcite ) mistaken solutions exposed in @xcite , in that mcmc simulations are run for each model separately and the resulting samples are then gathered together to produce either the posterior expectation ( in scott s , 2002 , case ) or the posterior distribution ( for the current paper ) of @xmath36 which do not correspond to genuine bayesian solutions ( see @xcite ) .",
    "again , this is not as much because the dataset @xmath32 is used repeatedly in this process ( since reversible mcmc produces as well separate samples from the different posteriors ) as the fundamental lack of a common joint distribution that is needed in the bayesian framework .",
    "this means , e.g. , that the integrated likelihood / bayes technology is producing samples from the product of the posteriors ( a product that clearly is not defined in a bayesian framework ) instead of using pseudo - priors as in @xcite , i.e. of considering a joint posterior on @xmath37 , which is [ proportional to ] @xmath38 this makes a difference in the outcome , as illustrated in figure [ fig : sxot ] , which compares the distribution of the likelihood ratio under the true posterior and under the product of posteriors , when assessing the fit of a poisson model against the fit of a binomial model with @xmath39 trials , for the observation @xmath40 .",
    "the joint simulation produces a much more supportive argument in favor of the binomial model , when compared with the product of the posteriors .",
    "( again , this is inherently the flaw found in the reasoning leading to scott s , 2002 , and congdon s , 2006 , methods for approximating bayes factors . )     _ comparison of the distribution of the likelihood ratio under the correct joint posterior and under the product of the model - based posteriors , when assessing a poisson model against a binomial with @xmath39 trials , for @xmath40 .",
    "the joint simulation produces a much more supportive argument in favor of the negative binomial model , when compared with the product of the posteriors .",
    "_ ]    although we do not advocate its use , a bayesian version of aitkin s proposal can be constructed based on the following loss function that evaluates the estimation of the model index @xmath41 based on the values of the parameters under both models and on the observation @xmath32 : @xmath42 here @xmath43 means that model @xmath41 is chosen , and @xmath44 denotes the likelihood under model @xmath41 . under this loss , the bayes ( optimal )",
    "solution is @xmath45 > 1/2\\\\ 2 & \\text{otherwise , } \\end{cases}\\ ] ] which depends on the _ joint _ posterior distribution on @xmath37 , thus differs from aitkin s solution .",
    "we have @xmath46    = & \\pi(\\mathcal m_1| x   ) \\int_{\\theta_2 }   \\mbox{pr}^{\\pi_1}\\left [ l^1(\\theta_1 ) > l^2(\\theta_2)|   x , \\theta_2 \\right ] \\,\\text{d}\\pi_2(\\theta_2)\\\\ & + \\pi(\\mathcal m_2| x   ) \\int_{\\theta_1 } \\mbox{pr}^{\\pi_2}\\left [ l^1(\\theta_1 ) > l^2(\\theta_2)|   x , \\theta_1\\right ] \\,\\text{d}\\pi_1(\\theta_1)\\,,\\end{aligned}\\ ] ] where @xmath47 and @xmath48 denote the log - likelihoods and where the probabilities within the integrals are computed under @xmath49 and @xmath50 , respectively .",
    "( pseudo - priors as in @xcite could be used instead of the true priors , a requirement when at least one of those priors is improper . )    an asymptotic evaluation of the above procedure is possible : consider a sample of size @xmath17 , @xmath27 .",
    "if @xmath51 is the  true \" model , then @xmath52 and we have @xmath53 & =   \\mbox{pr } \\left [ -\\mathcal x^2_{p_1 } > l^2(\\theta_2)- l^2(\\hat{\\theta_1 } ) \\right ]   + o_p(1/\\sqrt{n } ) \\\\ & = f_{p_1}\\left [ l^1(\\hat{\\theta_1 } ) - l^2(\\theta_2 ) \\right ] + o_p(1/\\sqrt{n})\\,,\\end{aligned}\\ ] ] with obvious notations for the corresponding log - likelihoods , @xmath54 the dimension of @xmath55 , @xmath56 the maximum likelihood estimator of @xmath57 , and @xmath58 a chi - square random variable with @xmath54 degrees of freedom . note",
    "also that , since @xmath59 , @xmath60 where @xmath61 denotes the kullback ",
    "leibler divergence and @xmath62 denotes the _ projection _ of the true model on @xmath63 : @xmath64 , we have @xmath65   = 1 + o_p(1)\\,.\\ ] ] by symmetry , the same asymptotic consistency occurs under model @xmath66 . on the opposite",
    ", aitkin s approach leads ( at least in regular models ) to the approximation @xmath67,\\ ] ] where the @xmath68 and @xmath69 random variables are independent , hence producing quite a different result that depends on the asymptotic behavior of the likelihood ratio .",
    "note that for both approaches to be equivalent one would need a pseudo - prior for @xmath66 ( resp .",
    "@xmath51 if @xmath70 were _ true _ ) as tight around the maximum likelihood as the posterior @xmath71 , which would be equivalent to some kind of empirical bayes type of procedure .",
    "furthermore , in the case of embedded models , @xmath66 and @xmath72 , aitkin s approach can be given a probabilistic interpretation .",
    "to this effect , we write the parameter under @xmath51 as @xmath73 , @xmath74 being a fixed known quantity , and under @xmath75 as @xmath76 , so that comparing @xmath51 with @xmath66 corresponds to testing the null hypothesis @xmath77 .",
    "aitkin does not impose a positive prior probability on @xmath51 , since his prior only bears on @xmath66 ( in a spirit close to the savage - dickey representation , see @xcite ) .",
    "his approach is therefore similar to the inversion of a confidence region into a testing procedure ( or vice - versa ) . under the model @xmath78 , denoting by @xmath79 the log - likelihood of the bigger model , @xmath80 & \\approx & \\mbox{pr}\\left [ \\mathcal x^2_{p_2-p_1 } > - l(\\hat{\\theta}_1(\\psi_0 ) , \\psi_0)+ l(\\hat{\\theta}_1,\\hat{\\psi})\\right ]   \\\\ & \\approx & 1 - f_{p_2-p_1 } [ - l(\\hat{\\theta}_1(\\psi_0 ) , \\psi_0)+ l(\\hat{\\theta}_1,\\hat{\\psi } ) ] , \\end{aligned}\\ ] ] which is the approximate @xmath12-value associated with the likelihood ratio test .",
    "therefore , the aim of this approach seems to be , at least for embedded models where the bernstein ",
    "von mises theorem holds for the posterior distribution , to construct a _",
    "bayesian _ procedure reproducing the @xmath12-value associated with the likelihood ratio test . from a frequentist point of view it is of interest to see that the posterior probability of the likelihood ratio being greater than one is approximately a @xmath12-value , at least in cases when the bernstein - von mises theorem holds , e.g.  for embedded models and proper priors .",
    "this @xmath12-value can then be given a finite - sample meaning ( under the above restrictions ) , however it seems more interesting from a frequentist perspective than from a bayesian one . from a bayesian decision - theoretic viewpoint , this is even more dubious , since the loss function ( [ loss ] ) is difficult to interpret and to justify .",
    " without a specific alternative , the best we can do is to make posterior probability statements about @xmath81 and transfer these to the posterior distribution of the likelihood ratio ( .. ) there can not be strong evidence in favor of a point null hypothesis against a general alternative hypothesis . \" _",
    "statistical inference _ , pages 4244    we further note that , once _ statistical inference _  has set the principle of using the posterior distribution of the likelihood ratio ( or rather of the divergence difference since this is at least symmetric in both hypotheses ) , there is a whole range of outputs available including confidence intervals on the difference , for checking whether or not they contain zero . from our ( bayesian ) perspective , this solution ( a ) is not bayesian for reasons exposed above",
    ", ( b ) is not parameterization invariant , and ( c ) relies once again on an arbitrary confidence level .",
    "we have focused in this review on aitkin s proposals rather than on his characterizations of other statistical methods . in a few places , however , we believe that there have been some unfortunate confusions from his part .    on page 22",
    ", aitkin describes bayesian posterior distributions as `` formally a measure of personal uncertainty about the model parameter , '' a statement that we believe holds generally only under a definition of `` personal '' that is so broad as to be meaningless . as we have discussed elsewhere",
    "( gelman , 2008 ) , bayesian probabilities can be viewed as `` subjective '' or `` personal '' but this is not necessary . or , to put it another way ,",
    "if you want to label my posterior distribution as `` personal '' because it is based on my personal choice of prior distribution , you should also label inferences from the proportional hazards model as `` personal '' because it is based on the user s choice of the parameterization of cox ( 1972 ) ; you should also label any linear regression ( classical or otherwise ) as `` personal '' as based on the individual s choice of predictors and assumptions of additivity , linearity , variance function , and error distribution ; and so on for all but the very simplest models in existence .",
    "in a nearly century - long tradition in statistics , any probability model is sharply divided into `` likelihood '' ( which is considered to be objective and , in textbook presentations , is often simply given as part of the mathematical specification of the problem ) and `` prior '' ( a dangerously subjective entity to which the statistical researcher is encouraged to pour all of his or her pent - up skepticism ) .",
    "this may be a tradition but it has no logical basis . if writers such as aitkin wish to consider their likelihoods as objective and consider their priors as subjective , that is their privilege .",
    "but we would prefer them to restrain themselves when characterizing the models as others .",
    "it would be polite to either tentatively accept the objectivity of others models or , contrariwise , to gallantly affirm the subjectivity of one s own choices .",
    "aitkin also mischaracterizes hierarchical models , writing `` it is important not to interpret the prior as in some sense a",
    "_ model for nature _ [ italics in the original ] that nature has used a random process to draw a parameter value from a higher distribution of parameter values  '' on the contrary , that is exactly how we interpret the prior distribution in the ideal case .",
    "admittedly , we do not generally approach this ideal ( except in settings such as genetics where the population distribution of parameters has a clear sampling distribution ) , just as in practice the error terms in our regression models do not capture the true distribution of errors . despite these imperfections",
    ", we believe that it can often be helpful to interpret the prior as a model for the parameter - generation process and to improve this model where appropriate .",
    "_ statistical inference _  points out several important facts that are individually known well ( but perhaps not well enough ! ) , but by putting them all in one place it foregrounds the difficulty or impossibility of putting all the different approaches to model checking in one place . we all know that the @xmath12-value is in no way the posterior probability of a null hypothesis being true ; in addition , bayes factors as generally practiced correspond to no actual probability model . also , it is well - known that the so - called harmonic mean approach to calculating bayes factors is inherently unstable , to the extent that in the situations where it does  work , \" it works by implicitly integrating over a space different from that of its nominal model .    yes , we all know these things , but as is often the case with scientific anomalies , they are associated with such a high level of discomfort that many researchers tend to forget the problems or try to finesse them .",
    "it is refreshing to see the anomalies laid out so clearly .    at some points , however , aitkin disappoints .",
    "for example , at the end of section 7.2 , he writes : `` in the remaining sections of this chapter , we first consider the posterior predictive @xmath12-value and point out difficulties with the posterior predictive distribution which closely parallel those of bayes factors . ''",
    "he follows up with a section entitled `` the posterior predictive distribution , '' which concludes with an example that he writes `` should be a matter of _ serious _ concern [ emphasis in original ] to those using posterior predictive distributions for predictive probability statements . ''",
    "what is this example of serious concern ?",
    "it is an imaginary problem in which he observes 1 success in 10 independent trials and then is asked to compute the probability of getting at most 2 successes in 20 more trials from the same process .",
    "_ statistical inference",
    "_  assumes a uniform prior distribution on the success probability and yields a predictive probability or 0.447 , which , to him , `` looks a vastly optimistic and unsound statement . '' here , we think aitkin should take bayes a bit more seriously . if you think this predictive probability is unsound , there should be some aspect of the prior distribution or the likelihood that is unsound as well .",
    "this is what good ( @xcite ) called `` the device of imaginary results . ''",
    "we suggest that , rather than abandoning highly effective methods based on predictive distributions , aitkin should look more carefully at his predictive distributions and either alter his model to fit his intuitions , alter his intuitions to fit his model , or do a bit of both .",
    "this is the value of inferential coherence as an ideal .",
    "several of the examples in _ statistical inference _  represent solutions to problems that seem to us to be artificial or conventional tasks with no clear analogy to applied work .    ",
    "they are artificial and are expressed in terms of a survey of 100 individuals expressing support ( yes / no ) for the president , before and after a presidential address ( ... ) the question of interest is whether there has been a change in support between the surveys ( ... ) .",
    "we want to assess the evidence for the hypothesis of equality @xmath82 against the alternative hypothesis @xmath83 of a change . \" _ statistical inference _",
    ", page 147    based on our experience in public opinion research , this is not a real question .",
    "support for any political position is always changing .",
    "the real question is how much the support has changed , or perhaps how this change is distributed across the population .",
    "a defender of aitkin ( and of classical hypothesis testing ) might respond at this point that , yes , everybody knows that changes are never exactly zero and that we should take a more `` grown - up '' view of the null hypothesis , not that the change is zero but that it is nearly zero .",
    "unfortunately , the metaphorical interpretation of hypothesis tests has problems similar to the theological doctrines of the unitarian church .",
    "once you have abandoned literal belief in the bible , the question soon arises : why follow it at all ?",
    "similarly , once one recognizes the inappropriateness of the point null hypothesis , it makes more sense not to try to rehabilitate it or treat it as treasured metaphor but rather to attack our statistical problems directly , in this case by performing inference on the change in opinion in the population .    to be clear",
    ": we are not denying the value of hypothesis testing . in this example",
    ", we find it completely reasonable to ask whether observed changes are statistically significant , i.e. whether the data are consistent with a null hypothesis of zero change .",
    "what we do not find reasonable is the statement that `` the question of interest is whether there has been a change in support . ''",
    "_ ( a ) hypothetical graph of presidential approval with discrete jumps ; ( b ) presidential approval series ( for george w. bush ) showing movement at many different time scales .",
    "if the approval series looked like the graph on the left , then aitkin s  question of interest \" of  whether there has been a change in support between the surveys \" would be completely reasonable . in the context of actual public opinion data , the question does not make sense ; instead , we prefer to think of presidential approval as a continuously - varying process . _ , title=\"fig : \" ]   _ ( a ) hypothetical graph of presidential approval with discrete jumps ; ( b ) presidential approval series ( for george w. bush ) showing movement at many different time scales .",
    "if the approval series looked like the graph on the left , then aitkin s  question of interest \" of  whether there has been a change in support between the surveys \" would be completely reasonable . in the context of actual public opinion data , the question does not make sense ; instead , we prefer to think of presidential approval as a continuously - varying process . _ , title=\"fig : \" ]    all this is application - specific .",
    "suppose public opinion was observed to really be flat , punctuated by occasional changes , as in the left graph in figure [ fig : president ] .",
    "in that case , aitkin s question of `` whether there has been a change '' would be well - defined and appropriate , in that we could interpret the null hypothesis of no change as some minimal level of baseline variation .    real public opinion",
    ", however , does not look like baseline noise plus jumps , but rather shows continuous movement on many time scales at once , as can be seen from the right graph in figure [ fig : president ] , which shows actual presidential approval data . in this example",
    ", we do not see aitkin s question as at all reasonable .",
    "any attempt to work with a null hypothesis of opinion stability will be inherently arbitrary .",
    "it would make much more sense to model opinion as a continuously - varying process .",
    "the statistical problem here is not merely that the null hypothesis of zero change is nonsensical ; it is that the null is in no sense a reasonable approximation to any interesting model .",
    "the sociological problem is that , from @xcite onward , many bayesians have felt the need to mimic the classical null - hypothesis testing framework , even where it makes no sense .",
    "aitkin is unfortunately no exception , taking a straightforward statistical question  estimating a time trend in opinion  and re - expressing it as an abstracted hypothesis testing problem that pulls the analyst away from any interesting political questions .",
    "`` the posterior has a non - integrable spike at zero .",
    "this is equivalent to assigning zero prior probability to these unobserved values . '' _ statistical inference _",
    ", page 98    a skeptical ( or even not so skeptical ) reader might at this point ask , why did we bother to write a detailed review of a somewhat obscure statistical method that we do not even like ?",
    "our motivation surely was not to protect the world from a dangerous idea ; if anything , we suspect our review will interest some readers who otherwise would not have heard about the approach ( as previously illustrated by @xcite ) .    in 1970 , a book such as _ statistical inference _",
    "could have had a large influence in statistics .",
    "as aitkin notes in his preface , there was a resurgence of interest in the foundations of statistics around that time , with lindley , dempster , barnard , and others writing about the intersections between classical and bayesian inference ( going beyond the long - understood results of asymptotic equivalence ) and researchers such as akaike and mallows beginning to integrate model - based and predictive approaches to inference .",
    "a glance at the influential text of cox and hinkley ( 1974 ) reveals that theoretical statistics at that time was focused on inference from independent data from specified sampling distributions ( possibly after discarding information , as in rank - based tests ) , and `` likelihood '' was central to all these discussions .",
    "forty years on , a book on likelihood inference is more of a niche item .",
    "partly this is simply part of the growth of the field  with the proliferation of books , journals , and online publications , it is much more difficult for any single book to gain prominence .",
    "more than that , though , we think statistical theory has moved away from iid analysis , toward more complex , structured problems .",
    "that said , the foundational problems that _ statistical inference _",
    "discusses are indeed important and they have not yet been resolved . as models get larger , the problem of `` nuisance parameters '' is revealed to be not a mere nuisance but rather a central fact in all methods of statistical inference . as noted above",
    ", aitkin makes valuable points  known , but not well - enough known  about the difficulties of bayes factors , pure likelihood , and other superficially attractive approaches to model comparison .",
    "we believe it is a natural continuation of this work to point out the problems of the integrated likelihood approach as well .    for now , we recommend model expansion , bayes factors where reasonable , cross - validation , and predictive model checking based on graphics rather than @xmath12-values .",
    "we recognize that each of these approaches has loose ends .",
    "but , as practical idealists , we consider inferential challenges to be opportunities for model improvement with the bayesian realm rather than motivations for a new theory of noninformative priors that takes us in uncharted territories ."
  ],
  "abstract_text": [
    "<S> for many decades , statisticians have made attempts to prepare the bayesian omelette without breaking the bayesian eggs ; that is , to obtain probabilistic likelihood - based inferences without relying on informative prior distributions . </S>",
    "<S> a recent example is murray aitkin s recent book , _ statistical inference _ , which presents an approach to statistical hypothesis testing based on comparisons of posterior distributions of likelihoods under competing models . </S>",
    "<S> aitkin develops and illustrates his method using some simple examples of inference from iid data and two - way tests of independence . </S>",
    "<S> we analyze in this note some consequences of the inferential paradigm adopted therein , discussing why the approach is incompatible with a bayesian perspective and why we do not find it relevant for applied work .    </S>",
    "<S> * keywords : * foundations , likelihood , bayesian , bayes factor , model choice , testing of hypotheses , improper priors , coherence . </S>"
  ]
}