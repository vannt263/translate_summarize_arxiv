{
  "article_text": [
    "grouping problems aim to partition a set of items into a collection of mutually disjoint subsets according to some specific criterion and constraints .",
    "grouping problems naturally arise in numerous domains .",
    "well - known grouping problems include , for instance , graph coloring ( gcp ) @xcite , timetabling @xcite , bin packing @xcite , scheduling @xcite and clustering @xcite .",
    "formally , given a set @xmath0 of @xmath1 distinct items , the task of a grouping problem is to partition the items of set @xmath0 into @xmath2 different groups @xmath3 @xmath4 ( @xmath2 can be fixed or variable ) , such that @xmath5 and @xmath6 while taking into account some specific constraints and optimization objective .",
    "for instance , the graph coloring problem is to partition the vertices of a given graph into a minimum number of @xmath2 color classes such that adjacent vertices must be put into different color classes .    according to whether the number of groups @xmath2 is fixed in advance ,",
    "grouping problems can be divided into constant grouping problems or variable grouping problems @xcite . in some contexts , the number of groups @xmath2 is a fixed value of the problem , such as identical or non - identical parallel - machines scheduling problem , while in other settings , @xmath2 is variable and the goal is to find a feasible grouping with a minimum number of groups , such as the bin packing problem and graph coloring problem .",
    "grouping problems can also be classified according to the types of the groups .",
    "a grouping problem with identical groups means that all groups have similar characteristics , thus naming of the groups is irrelevant .",
    "aforementioned examples such as identical parallel - machines scheduling , bin - packing and graph coloring belong to this category .",
    "another category of grouping problems have non - identical groups where the groups are of different characteristics .",
    "hence , swapping items between two groups will result in a new grouping , such as the non - identical parallel - machines scheduling problem .",
    "many grouping problems , including the examples mentioned above are np - hard , thus computationally challenging . due to the high computational complexity of these problems ,",
    "exponential times are expected for any algorithm to solve such a problem exactly . on the other hand , heuristic and meta - heuristic methods",
    "are often employed to find satisfactory sub - optimal solutions in acceptable computing time , but without provable optimal guarantee of the attained solutions .",
    "a number of heuristic approaches for grouping problems , in particular based on genetic algorithms , have been proposed in the literature with varying degrees of success @xcite .",
    "these approaches are rather complex since they are population - based and often hybridized with other search methods like local optimization .    in this work , we are interested in investigating a general purpose local search methodology for grouping problems which employs machine learning techniques to process information collected from the search process with the purpose of improving the performance of heuristic algorithms .",
    "indeed , previous work has demonstrated that machine learning can contribute to improve optimization methods @xcite .",
    "existing research in these areas has pursued different objectives .",
    "* algorithm selection and analysis .",
    "for instance , hutter et al . used machine learning techniques such as random forests and approximate gaussian process to model algorithm s runtime as a function of problem - specific instance features .",
    "this model can predict algorithm runtime for the propositional satisfiability problem , travelling salesperson problem and mixed integer programming problem @xcite . *",
    "learning generative models of solutions .",
    "for example , ceberio et al . introduced the plackett - luce probability model to the framework of estimation of distribution algorithms and applied it to solve the linear order problem and the flow - shop scheduling problem @xcite . *",
    "learning evaluation functions .",
    "for instance , boyan and moore proposed the stage algorithm to learn an evaluation function which predicts the outcome of a local search algorithm such as hill - climbing or walk - sat , as a function of state features along its search trajectories .",
    "the learned evaluation function is used to bias future search trajectories towards better solutions @xcite . * understanding the search space .",
    "for example , porumbel et al . used multidimensional scaling techniques to explore the spatial distribution of the local optimal solutions visited by tabu search , thus improving local search algorithms for the graph coloring problem @xcite.for the same problem , the authors of @xcite used the results of an analysis of legal @xmath2-colorings to help finding solutions with fewer colors .    in this paper , we present the reinforcement learning based local search ( rls ) approach for grouping problems , which combines reinforcement learning techniques with a descent - based local search procedure .",
    "our proposed rls approach belongs to the above - mentioned category of learning generative models of solutions . for a grouping problem with its @xmath2 groups , we associate to an item a probability vector with respect to each possible group and determine the group of the item according to the probability vector",
    "once all items are assigned to their groups , a grouping solution is generated .",
    "then , the descent - based local search procedure is invoked to improve this solution until a local optimum is attained .",
    "afterward , the probability vector of each item is updated by comparing the group of the item in the starting solution and in the attained local optimum solution .",
    "if an item stays in its original group , then we reward the selected group of the item , otherwise we penalize the original group and compensate the new group ( i.e. , expected group ) .",
    "there are two key issues that need to be considered , i.e. , how do we select a suitable group for each item according to the probability vector , and how do we smooth the probabilities to avoid potential search traps . to handle these issues",
    ", we design two strategies : a hybrid group selection strategy that uses a noise probability to switch between random selection and greedy selection ; and a probability smoothing mechanism able to forget old decisions .",
    "to evaluate the viability of the proposed rls method , we use the well - known graph coloring problem ( gcp ) as a case study .",
    "gcp is one representative grouping problem which has been object of intensive studies in the past decades .",
    "we show computational experiments on both dimacs and color02 benchmark graphs .",
    "computational results demonstrate that the proposed approach , despite its simplicity , achieves competitive performances on most tested instances compared to many existing algorithms . with an analysis of three important issues of rls",
    ", we show the effectiveness of combining reinforcement learning and descent - based local search .",
    "we also assess the contribution of the probability smoothing technique to the performance of rls .",
    "the rest of the paper is organized as follows .",
    "section [ sec : rlhs ] provides an introduction of reinforcement learning and its applications to enhance heuristic search .",
    "the proposed rls method is described in section [ sec : rls ] .",
    "section [ sec : experiments ] is dedicated to computational assessments and comparisons of rls applied to the graph coloring problem .",
    "concluding comments and future research directions are discussed in section [ sec : conclusion ] .",
    "in this section , we briefly introduce the principles of reinforcement learning ( rl ) and provide a review of some representative examples of using reinforcement learning to solve combinatorial optimization problems .",
    "reinforcement learning is a learning pattern , which aims to learn optimal actions from a finite set of available actions through continuously interacting with an unknown environment .",
    "in contrast to supervised learning techniques , reinforcement learning does not need an experienced agent to show the correct way , but adjusts its future actions based on the obtained feedback signal from the environment @xcite .",
    "there are three key elements in a rl agent , i.e. , states , actions and rewards . at each instant",
    "a rl agent observes the current state , and takes an action from the set of its available actions for the current state .",
    "once an action is performed , the rl agent changes to a new state , based on transition probabilities .",
    "correspondingly , a feedback signal is returned to the rl agent to inform it about the quality of its performed action .",
    "there are a number of studies in the literature where reinforcement learning techniques are put at the service of heuristic algorithms for solving combinatorial problems .",
    "reinforcement learning techniques in these studies have been explored at three different levels .",
    "_ heuristic level _ where rl is directly used as a heuristic to solve optimization problems . in this case ,",
    "rl techniques are used to learn and directly assign values to the variables .",
    "for example , the authors of @xcite proposed to solve combinatorial optimization problems based on a population of rl agents .",
    "pairs of variable and value are considered as the rl states , and the branching strategies as the actions .",
    "each rl agent is assigned a specific area of the search space where it has to learn and find good local solutions .",
    "_ meta - heuristic level _ where rl is integrated into a meta - heuristic .",
    "there are two types of these algorithms .",
    "firstly , rl is used to learn properties of good initial solutions or an evaluation function that guides a meta - heuristic toward high quality solutions .",
    "for example , rl is employed to learn a new evaluation function over multiple search trajectories of the same problem instance and alternates between using the learned and the original evaluation function @xcite .",
    "secondly , rl learns the best neighborhoods or heuristics to build or change a solution during the search , so that a good solution can be obtained at the end .",
    "for instance , xu et al .",
    "@xcite proposed a formulation of constraint satisfaction problems as a rl task .",
    "a number of different variable ordering heuristics are available , and rl learns which one to use , and when to use it .",
    "_ hyper - heuristic level _ where rl is used as a component of a hyper - heuristic .",
    "specifically , rl is integrated into selection mechanisms and acceptance mechanisms in order to select a suitable low - level heuristic and determine when to accept a move respectively .",
    "for example , burke et al .",
    "@xcite presented a hyper - heuristic in which the selection of low - level heuristics makes use of basic reinforcement learning principles combined with a tabu search mechanism . the algorithm increases or decreases the rank of the low - level heuristics when the objective function value is improving or deteriorating .",
    "two other examples can be found in @xcite where rl is used to schedule several search operators ( crossovers , local search ... ) under the genetic and multi - agent based optimization frameworks .",
    "both meta - heuristic level and hyper - heuristic level approaches attempt to replace the random component of an algorithm with a rl component to obtain an informed decision mechanism . based on the above - classification",
    ", our proposed rls approach belongs to first type of the meta - heuristic level category .",
    "specifically , rls combines reinforcement learning techniques with descent - based local search with the purpose of learning properties of good initial solutions .",
    "grouping problems aim to partition a set of items into @xmath2 disjoint groups according to some imperative constraints and an optimization criterion . for our rls approach",
    ", we suppose that the number of groups @xmath2 is given in advance .",
    "note that such a assumption is not necessarily restrictive .",
    "in fact , to handle a grouping problem with variable @xmath2 , one can repetitively run rls with different @xmath2 values .",
    "we will illustrate this approach on the graph coloring problem in section [ sec : experiments ] .      by combining reinforcement learning techniques with a solution improvement procedure ,",
    "our proposed rls approach is composed of four keys components : a descent - based local search procedure , a group selection strategy , a probability updating mechanism ( i.e. , reinforcement learning mechanism ) , and a probability smoothing technique .",
    "we define a probability matrix @xmath7 of size @xmath8 ( @xmath1 is the number of items and @xmath2 is the number of groups , see figure [ fig : probabilitymatrix ] for an example ) .",
    "an element @xmath9 denotes the probability that the @xmath10-th item @xmath11 selects the @xmath12-th group @xmath13 as its group .",
    "therefore , the @xmath10-th row of the probability matrix defines the probability vector of the @xmath10-th item and is denoted by @xmath14 . at the beginning , all the probability values in the probability matrix are set as @xmath15 .",
    "it means that all items select a group from the available @xmath2 groups with equal probability .    ,",
    "scaledwidth=50.0% ]    at instant @xmath16 , each item @xmath11 , @xmath17 selects one suitable group @xmath13 , @xmath18 by applying a group selection strategy ( section [ subsec : groupselect ] ) based on its probability vector @xmath19 . once all the items are assigned to their groups ,",
    "a grouping solution @xmath20 is obtained .",
    "then , this solution is improved by a descent - based local search procedure to attain a local optimum denoted by @xmath21 ( section [ subsec : hillclimb ] ) . by comparing the solution @xmath20 and the improved solution @xmath21",
    ", we update the probability vector of each item based on the following rules ( section [ subsec : probabilityupdating ] ) :    a.   if the item stays in its original group , then we reward the selected group . b.",
    "if the item is moved to a new group , then we penalize the selected group and compensate its new group ( i.e. , expected group ) .",
    "-[subsec : probabilitysmooth ] for more details),scaledwidth=100.0% ]    next , we apply a probability smoothing technique to smooth each item s probability vector ( section [ subsec : probabilitysmooth ] ) . hereafter , rls iteratively runs until a predefined stop condition is reached ( e.g. , a legal solution is found or the number of iterations without improvement exceeds a maximum allowable value ) .",
    "the schematic diagram of rls for grouping problems is depicted in figure [ fig : diagram ] while its algorithmic pseudo - code is provided in algorithm [ algorithm : rls ] . in the following subsections ,",
    "the four key components of our rls approach are presented in detail .",
    "* input * : +  @xmath22 : a grouping problem instance ; +  @xmath2 : the number of available groups ; + * output * : the best solution @xmath23 found so far ; @xmath24_{j = 1 , 2 , ... , k}$ ] ; @xmath25 ;   /@xmath26 section [ subsec : groupselect ] @xmath26/    @xmath27 ;  /@xmath26 section [ subsec : hillclimb ] @xmath26/ @xmath28 ;  /@xmath26 section [ subsec : probabilityupdating ] @xmath26/ @xmath29 ;   /@xmath26 section [ subsec : probabilitysmooth ] @xmath26/      at each iteration of rls , each item @xmath11 needs to select a group @xmath13 from the @xmath2 available groups according to its probability vector @xmath14 .",
    "we consider four possible group selection strategies :    * random selection : the item selects its group at random ( regardless of its probability vector ) .",
    "as this selection strategy does not use any useful information collected from the search history , it is expected that this strategy would not perform well .",
    "* greedy selection : the item always selects the group @xmath13 such that the associated probability @xmath9 has the maximum value .",
    "this strategy is intuitively reasonable , but may cause the algorithm to be trapped rapidly . *",
    "roulette wheel selection : the item selects its group based on its probability vector and the chance for the item to select group @xmath13 is proportional to the probability @xmath9 .",
    "thus a group with a large ( small ) probability has more ( less ) chance to be selected .",
    "* hybrid selection : this strategy combines the random selection and greedy selection strategies in a probabilistic way ; with a noise probability @xmath30 , random selection is applied ; with probability @xmath31 , greedy selection is applied .    as we show in section [ comparison of different group selection strategies ] , the group selection strategy greatly affects the performance of the rls approach . after experimenting the above strategies",
    ", we adopted the hybrid selection strategy which combines randomness and greediness which are controlled by the noise probability @xmath30 .",
    "the purpose of selecting a group with maximum probability ( greedy selection ) is to make an attempt to correctly select the group for an item that is most often falsified at a local optimum .",
    "selecting such a group for this item may help the search to escape from the current trap . on the other hand , using the noise probability has the advantage of flexibility by switching back and forth between greediness and randomness .",
    "also , this allows the algorithm to occasionally move away from being too greedy .",
    "this hybrid group selection strategy proves to be better than the roulette wheel selection strategy , as confirmed by the experiments of section [ comparison of different group selection strategies ] .      even if any optimization procedure can be used to improve a given starting grouping solution . for the reason of simplicity",
    ", we employ a simple and fast descent - based local search ( db - ls ) procedure in this work . to explore the search space",
    ", db - ls iteratively makes transitions from the incumbent solution to a neighboring solution according to a given neighborhood relation such that each transition leads to a better solution .",
    "this iterative improvement process continues until no improved solution exists in the neighborhood in which case the incumbent solution corresponds to a local optimum with respect to the neighborhood .",
    "let @xmath32 denote the search space of the given grouping problem .",
    "let @xmath33 be the neighborhood relation which associates to each solution @xmath34 a subset of solutions @xmath35 ( i.e. , @xmath36 is the set of neighboring solutions of @xmath37 ) .",
    "typically , given a solution @xmath37 , a neighboring solution can be obtained by moving an item of @xmath37 from its current group to another group .",
    "let @xmath38 be the evaluation ( or cost ) function which measures the quality or cost of each grouping solution .",
    "the pseudo code of algorithm [ algorithm : hillclimbing ] displays the general db - ls procedure .",
    "* input * : @xmath37 - an initial candidate grouping solution ; + * output * : @xmath23 - the local optimum solution attained ; @xmath39 ; choose a best neighbor @xmath40 of @xmath37 such that @xmath41 ; @xmath42 ; @xmath43 @xmath44 ;    descent - based local search can find a local optimum quickly .",
    "however , the local optimal solution discovered is generally of poor quality .",
    "it is fully possible to improve the performance of rls by replacing the descent - based local search with a more powerful improvement algorithm . in rls",
    ", we make the assumption that , if the item stays in its original group after the descent - based local search , then the item has selected the right group in the original solution , otherwise its new group in the improved solution would be the right group . this assumption can be considered to be reasonable because the descent - based local search procedure is driven by its cost function and each transition from the current solution to a new ( neighboring ) solution is performed only when the transition leads to an improvement .",
    "reinforcement learning is defined as how an agent should take actions in an environment so to maximize some notion of cumulative reward .",
    "reinforcement learning acts optimally through trial - and - error interactions with an unknown environment .",
    "actions may affect not only the immediate reward but also the next situation and all subsequent rewards .",
    "the intuition underlying reinforcement learning is that actions that lead to large rewards should be made more likely to recur . in rls",
    ", the problem of selecting the most appropriate group for each item is viewed as a reinforcement learning problem . through the interactions with the unknown environment",
    ", rls evolves and gradually finds the optimal or a suboptimal solution of the problem .    at instant @xmath16",
    ", we firstly generate a grouping solution @xmath20 based on the current probability matrix @xmath45 ( see section [ subsec : mainscheme ] ) . in other words ,",
    "each item selects one suitable group from the @xmath2 available groups based on its probability vector ( with the group selection strategy of sect .",
    "[ subsec : groupselect ] ) .",
    "then solution @xmath20 is improved by the descent - based local search procedure , leading to an improved solution @xmath21 .",
    "now , for each item @xmath11 , we compare its groups in @xmath20 and @xmath21 .",
    "if the item stays in its original group ( say @xmath46 ) , we reward the selected group @xmath46 ( called correct group ) and update its probability vector @xmath14 according to eq .",
    "( [ equ : reward ] ) : @xmath47 where @xmath48 is a reward factor . when item @xmath11 moves from its original group @xmath46 of solution @xmath20 to a new group ( say @xmath49 ) of the improved solution @xmath21 , we penalize the discarded group @xmath46 ( called incorrect group ) , compensate the new group @xmath50 ( called expected group ) and finally update its probability vector @xmath14 according to eq .",
    "( [ equ : penalizeandcompensate ] ) : @xmath51 where @xmath52 and @xmath53 are a penalization factor and compensation factor respectively .",
    "this process is repeated until each item can select its group correctly .",
    "the update of the complete probability matrix @xmath7 is bounded by @xmath54 in terms of time complexity .",
    "it is necessary to note that our learning scheme is different from general reinforcement learning schemes such as linear reward - penalty , linear reward - inaction and linear reward-@xmath55-penalty .",
    "the philosophy of these schemes is to increase the probability of selecting an action in the event of success and decrease it when receives a failed signal . unlike these general schemes , our learning scheme not only rewards the correct group and penalizes the incorrect group , but also compensates the expected group .",
    "the intuition behind the probability smoothing technique is that old decisions that were made long ago are no longer helpful and may mislead the current search . therefore , these aged decisions should be considered less important than the recent ones .",
    "in addition , all items are required to correctly select their suitable groups in order to produce a legal grouping solution .",
    "it is not enough that only a part of items can correctly select their groups .",
    "based on these two reasons , we introduce a probability smoothing technique to reduce the group probabilities periodically .",
    "our probability smoothing strategy is inspired by forgetting mechanisms in smoothing techniques in clause weighting local search algorithms for satisfiability ( sat ) @xcite .",
    "based on the way that weights are smoothed or forgotten , there are four available forgetting or smoothing techniques for mvc and sat :    * decrease one from all clause weights which are greater than one such as paws @xcite .",
    "* pull all clause weights to their mean value using the formula @xmath56 like esg @xcite and saps @xcite . * transfer weights from neighboring satisfied clauses to unsatisfied ones like ddwf @xcite .",
    "* reduce all edge weights using the formula @xmath57 when the average weight achieves a threshold like numvc @xcite .",
    "the probability smoothing strategy adopted in our rls approach works as follows ( see algorithm [ algorithm : probabilitysmooth ] ) . for an item , each possible group",
    "is associated with a value between @xmath58 and @xmath59 as its probability , and each group probability is initialized as @xmath15 . at each iteration , we adjust the probability vector based on the obtained feedback information ( i.e. , reward , penalize or compensate a group ) .",
    "once the probability of a group in a probability vector achieves a given threshold ( i.e. , @xmath60 ) , it is reduced by multiplying a smoothing coefficient ( i.e. , @xmath61 ) to forget some earlier decisions .",
    "it is obvious that the smoothing technique used in rls is different from the above - mentioned four techniques . to the best of our knowledge ,",
    "this is the first time a smoothing technique is introduced into local search algorithms for grouping problems .",
    "* input * : +    @xmath45 : probability matrix at instant @xmath16 ; +    @xmath60 : smoothing probability ; +    @xmath62 : smoothing coefficient ; + * output * : new probability matrix @xmath45 after smoothing ; @xmath63 ; @xmath64 ; @xmath65 ;",
    "this section presents an application of the proposed rls method to the well - known graph coloring problem which is a typical grouping problem . after presenting the descent - based local search procedure for the problem",
    ", we first conduct an experimental analysis of the rls approach by investigating the influence of its three important components , i.e. , the reinforcement learning mechanism , the probability smoothing technique and the group selection strategy . then we present computational results attained by the proposed rls method in comparison with a number of existing local search algorithms over well - known dimacs and color02 benchmark instances .",
    "gcp is one of the most studied combinatorial optimization problems @xcite .",
    "gcp is also a nice representative of grouping problems .",
    "given an undirected graph @xmath66 , where @xmath0 is the set of @xmath67 vertices and @xmath68 is the set of @xmath69 edges , a legal @xmath2-coloring of @xmath22 is a partition of @xmath0 into @xmath2 mutually disjoint groups or color classes such that two vertices linked by an edge must belong to two different color classes .",
    "gcp is to determine the smallest @xmath2 for a graph @xmath22 such that a legal @xmath2-coloring exists .",
    "this minimum number of groups ( i.e. , colors ) required for a legal coloring is the _ chromatic number _ @xmath70 .",
    "when the number of color classes @xmath2 is fixed , the problem is called @xmath2-coloring problem ( @xmath2-gcp for short ) . as a grouping problem , items correspond to vertices and groups correspond to color classes .",
    "notice that gcp can be approximated by solving a series of @xmath2-gcp ( with decreasing @xmath2 ) as follows @xcite .",
    "for a given @xmath22 and a given @xmath2 , we use our rls approach to solve @xmath2-gcp by seeking a legal @xmath2-coloring .",
    "if such a coloring is successfully found , we decrease @xmath2 and solve the new @xmath2-gcp again .",
    "we repeat this process until no legal @xmath2-coloring can be reached . in this case , the last @xmath2 for which a legal @xmath2-coloring has been found represents an approximation ( upper bound ) of the chromatic number of @xmath22 .",
    "this general solution approach has been used in many coloring algorithms including most of those reviewed below , and is adopted in our work .    given the theoretical and practical interest of gcp , a huge number of coloring algorithms have been proposed in the past decades @xcite . among them , algorithms based on local search are certainly the most popular approaches , like simulated annealing ( sa ) @xcite , tabu search ( ts ) @xcite , guided local search ( gls ) @xcite , iterated local search ( ils ) @xcite , quantum annealing algorithms @xcite and focused walk based local search ( fwls ) @xcite .",
    "population - based hybrid algorithms represent another class of complex approaches which typically combine local search and dedicated recombination crossover operators @xcite .",
    "recent surveys of algorithms for gcp can be found in @xcite .",
    "to apply the proposed rls approach to @xmath2-gcp , we need to specify three important ingredients of the descent - based local search in rls , i.e. , the search space , the neighborhood and the evaluation function .",
    "first , a legal or illegal @xmath2-coloring can be represented by @xmath71 such that @xmath3 is the group of vertices receiving color @xmath10 .",
    "therefore , the search space @xmath32 is composed of all possible legal and illegal @xmath2-colorings .",
    "the evaluation function @xmath72 counts the number of conflicting edges inducted by @xmath37 such that : @xmath73 where @xmath74 , if @xmath75 and @xmath76 , and otherwise @xmath77 .",
    "accordingly , a candidate solution @xmath37 is a legal @xmath2-coloring @xmath37 if @xmath78 .",
    "the neighborhood of a given @xmath2-coloring is constructed by moving a conflicting vertex @xmath79 from its original group @xmath3 to another group @xmath80 @xcite .",
    "therefore , for a @xmath2-coloring @xmath37 with cost @xmath72 , the size of the neighborhood is bounded by @xmath81 . to evaluate each neighboring solution efficiently",
    ", our descent - based local search adopts the fast incremental evaluation technique introduced in @xcite .",
    "the principle is to maintain a gain matrix which records the variation @xmath82 between the incumbent solution @xmath37 and every neighboring solution @xmath83 .",
    "after each solution transition from @xmath37 to @xmath83 , only the affected elements of the gain matrix are updated accordingly .    the descent - based local search procedure starts then with a random solution taken from the search space @xmath32 and iteratively improves this solution by a neighboring solution of better quality according to the evaluation function @xmath84 .",
    "this process stops either when a legal @xmath2-coloring is found ( i.e. , a solution with @xmath78 , or no better solution exists among the neighboring solutions ( in this later case , a local optimum is reached ) .",
    "we show extensive computational results on two sets of the well - known dimacs and color02 coloring benchmark instances .",
    "these instances are the most widely used benchmark instances for assessing the performance of graph coloring algorithms .",
    "the used dimacs graphs can be divided into six types :    * _ standard random graphs _ are denoted as ` dsjc`@xmath85 , where @xmath1 is the number of vertices of the graph .",
    "the chromatic number @xmath86 of these graphs are unknown . *",
    "_ random geometric graphs _ are composed of ` r125.`@xmath87 , ` r250.`@xmath87 , ` dsjr500.`@xmath87 and ` r1000.`@xmath87 , graphs with letter @xmath88 being complements of geometric graphs . *",
    "_ flat graphs _ are structured graphs produced based on an equi - partitioning of vertices into @xmath2 sets .",
    "this kind of graphs are denoted as ` flat`@xmath89 , where @xmath1 and @xmath2 are the number of vertices and chromatic number respectively . * _ leighton graphs _ are random graphs of density below 0.25 .",
    "this kind of graphs are denoted as ` le450`@xmath90 , where 450 is the number of vertices , @xmath91 is the chromatic number of the graph , @xmath92 is a letter to indicate different graphs with the same characteristics . * _ scheduling graphs _ , i.e. , ` school1 ` and ` school1_nsh ` . * _ latin square graph _ , i.e. , ` latin_square_10 ` .",
    "the used color02 graphs are of three types :    * _ queen graphs _ are highly structured instances and their edge density decreases with their size .",
    "the graphs are denoted as ` queen`@xmath93 , where @xmath94 , with an exception , i.e. , @xmath95 . * _ mycile graphs _ are denoted as ` mycile`@xmath2 , where @xmath96 .",
    "these graphs are based on the mycielski transformation . * _ miles graphs _",
    "( ` miles`@xmath87 , with @xmath97 ) are similar to geometric graphs in that nodes are placed in space with two nodes connected if they are close enough .",
    ".parameters of algorithm rls [ cols=\"<,^,<,<\",options=\"header \" , ]     when we compare our rls algorithm with the five reference algorithms on the color02 graph instances ( table [ tab : asummarytable2 ] ) , we observe that rls dominates these algorithms .",
    "specifically , rls achieves no worse results on these instances than any of the reference algorithms , and obtains @xmath98 better solutions than sa and gls , @xmath59 better solution than ts , ils , and fwls respectively .",
    "we also find that our proposed rls method even achieves competitive performances compared to some complex population algorithms proposed in recent years , such as ant - based algorithm @xcite ( 2008 ) , and modified cuckoo optimization algorithm @xcite ( 2015 ) .",
    "however , given the very simplicity of its underlying local search procedure , it is no surprise that rls alone can not compete with the most powerful coloring algorithms like @xcite .",
    "indeed , these algorithm are typically complex hybrid algorithms mixing several approaches like genetic computing and local optimization . on the other hand ,",
    "given the way the proposed rls approach is composed , it would be interesting to replace the simple descent - based local search by any of these advanced coloring algorithms and investigate the proposed reinforcement learning mechanism in comparison with these advanced coloring algorithms .",
    "in this paper , we proposed a reinforcement learning based optimization approach for solving the class of grouping problems .",
    "the proposed rls approach combines reinforcement learning techniques with a descent - based local search procedure .",
    "reinforcement learning is used to maintain and update a set of probability vectors , each probability vector specifying the probability that an item belongs to a particular group . at each iteration",
    ", rls builds a starting grouping solution according to the probability vectors and with the help of a group selection strategy .",
    "rls then applies a descent - based local search procedure to improve the given grouping solution until a local optimum is reached . at this point ,",
    "the starting solution and the ending local optimum solution are compared to update the probability vector of each item according to the situation of the item .",
    "specifically , rls rewards the selected group of the item if the item stays in the original group , otherwise rls penalizes the selected group and compensates the new group .    experimental analyses and performance assessments of the rls approach",
    "were carried out on the graph coloring problem which is a well - known grouping problem .",
    "based on experimental results on popular dimacs and color02 benchmark graphs , we showed that 1 ) reinforcement learning is highly valuable to increase the performance of the descent - based local search procedure ; 2 ) the probability smoothing technique which forgets old decisions is very useful to avoid search traps ; and 3 ) the hybrid group selection strategy combining randomness and greediness is more suitable than other selection strategies .    in terms of computational results , rls , despite the simplicity of its basic coloring procedure , proved to be competitive compared to five advanced local search algorithms .",
    "it performs even better than some recent and complex optimization algorithms like the ant - based algorithm @xcite and modified cuckoo optimization algorithm @xcite . on the other hand ,",
    "given the competitiveness of the graph coloring problems , rls can not really competes with the most advanced coloring algorithms which are often based on complex hybrid schemes .",
    "fortunately , given the way of reinforcement learning being used in rls , it is reasonable to believe that the proposed reinforcement learning techniques could be combined with these advanced coloring approaches , e.g. , by replacing the descent procedure with a more powerful algorithm within the rls approach .",
    "such a possibility constitutes one of our future research .",
    "finally , another future work is to apply the proposed approach to solve other grouping problems . for this purpose , it is necessary to devise a descent local search procedure ( or any other solution improvement procedure ) for the studied problem while the other ingredients of the rls approach can be kept unchanged .",
    "this work was partially supported by the pgmo project ( 2014 - 2015 , jacques hadamard mathematical foundation , paris ) . the financial support for yangming zhou from the china scholarship council ( csc , 2014 - 2018 ) is acknowledged",
    ".    1 agustn - blas , l. , salcedo - sanz , s. , jimnez - fernndez , s. , carro - calvo , l. , ser , j. d. & portilla - figueras , j. ( 2012 ) , a new grouping genetic algorithm for clustering problems , expert systems with applications , 39 , 9695 - 9703 .",
    "baluja , s. , barto , a. , boese , k. , boyan , j. , buntine , w. , carson , t. , caruana , r. , cook , d. , davies , s. , dean , t. , & others ( 2000 ) . statistical machine learning for large - scale optimization , neural computing surveys , 3 , 1 - 58 .",
    "ceberio , j. , mendiburu , a. , & lozano , j. a. ( 2013 ) . the plackett - luce ranking model on permutation - based optimization problems , proceedings of the ieee congress on evolutionary computation ( cec ) , 494 - 501 .",
    "guo , y. , goncalves , g. , & hsu , t. ( 2013 ) . a multi - agent based self - adaptive genetic algorithm for the long - term car pooling problem , journal of mathematical modelling and algorithms in operations research , 12(1 ) , 45 - 66 .",
    "hamiez , j.p . , &",
    "hao , j.k .",
    "( 1993 ) , an analysis of solution properties of the graph coloring problem .",
    "metaheuristics : computer decision - making , chapter 15 , pp325 - 346 , resende m.g.c . and de sousa j.p .",
    "( eds . ) , kluwer .            johnson , d.s . ,",
    "aragon , c.r . ,",
    "mcgeoch , l.a . , & schevon , c. ( 1991 ) .",
    "optimization by simulated annealing : an experimental evaluation ; part ii , graph coloring and number partitioning , operations research , 39 , 378 - 406 .",
    "lewis , r. ( 2009 ) .",
    "a general - purpose hill - climbing method for order independent minimum grouping problems : a case study in graph colouring and bin packing , computers & operations research , 36(7 ) , 2295 - 2310 .",
    "porumbel , d.c .",
    ", hao , j .- k . , & kuntz , p. ( 2010b ) . an evolutionary approach with diversity guarantee and well - informed grouping recombination for graph coloring , computers & operations research 37(10 ) , 18221832 .",
    "quiroz - castellanos , m. , cruz - reyes , l. , torres - jimnez , j. , gmez , c. , huacuja , h.j . , & alvim , a.c .",
    "f. ( 2015 ) .",
    "a grouping genetic algorithm with controlled gene transmission for the bin packing problem , computers & operations research , 55 , 52 - 64 .",
    "schuurmans , d. , southey , f. , & holte , r.c .",
    "the exponentiated subgradient algorithm for heuristic boolean programming , in proceedings of the 7th international joint conference on artificial intelligence ( ijcai ) , pp .",
    "334 - 341 .",
    "thornton , j. , duc , n.p . , stuart b. , & valnir f.jr . (",
    "additive versus multiplicative clause weighting for sat , in proceedings of the conference of the american association for artificial intelligence ( aaai ) , pp .",
    "191 - 196 .",
    "wu , w. , luo , c. , & su , k. ( 2013 ) .",
    "fwls : a local search for graph coloring , frontiers in algorithmics and algorithmic aspects in information and management , third joint international conference , proceedings , pp.84 - 93 ."
  ],
  "abstract_text": [
    "<S> grouping problems aim to partition a set of items into multiple mutually disjoint subsets according to some specific criterion and constraints . </S>",
    "<S> grouping problems cover a large class of important combinatorial optimization problems that are generally computationally difficult . in this paper </S>",
    "<S> , we propose a general solution approach for grouping problems , i.e. , reinforcement learning based local search ( rls ) , which combines reinforcement learning techniques with descent - based local search . </S>",
    "<S> the viability of the proposed approach is verified on a well - known representative grouping problem ( graph coloring ) where a very simple descent - based coloring algorithm is applied . </S>",
    "<S> experimental studies on popular dimacs and color02 benchmark graphs indicate that rls achieves competitive performances compared to a number of well - known coloring algorithms .    ,    </S>",
    "<S> ,    grouping problems and graph coloring ; reinforcement learning and heuristics ; combinatorial optimization . </S>"
  ]
}