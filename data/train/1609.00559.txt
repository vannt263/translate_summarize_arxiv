{
  "article_text": [
    "measures of semantic similarity and relatedness quantify the degree to which two concepts are similar ( e.g. , @xmath0-@xmath1 ) or related ( e.g. , @xmath0- @xmath2 ) .",
    "semantic similarity can be viewed as a special case of semantic relatedness  to be similar is one of many ways that a pair of concepts may be related .",
    "the automated discovery of groups of semantically similar or related terms is critical to improving the retrieval  @xcite and clustering  @xcite of biomedical and clinical documents , and the development of biomedical terminologies and ontologies  @xcite .",
    "there is a long history of success in using distributional methods to discover semantic similarity and relatedness ( e.g. , @xcite ) .",
    "these methods are all based on the distributional hypothesis , which holds that two terms that are distributionally similar ( i.e. , used in the same context ) will also be semantically similar @xcite .",
    "however , despite these successes distributional methods do not perform well when data is very sparse ( which is common ) .",
    "one possible solution is to use second  order co  occurrence vectors @xcite . in this approach",
    "the similarity between two words is not strictly based on their co  occurrence frequencies , but rather on the frequencies of the other words which occur with both of them ( i.e. , second order co ",
    "occurrences ) .",
    "this approach has been shown to be successful in quantifying semantic relatedness  @xcite . however",
    ", while more robust in the face of sparsity , second  order methods can result in significant amounts of noise , where contextual information that is overly general is included and does not contribute to quantifying the semantic relatedness between the two concepts .",
    "our goal then is to discover methods that automatically reduce the amount of noise in a second  order co  occurrence vector .",
    "we achieve this by embedding pairwise semantic similarity scores derived from a taxonomy into our second ",
    "order vectors , and then using these scores to select only the most semantically similar co  occurrences ( thereby reducing noise ) .    we evaluate our method on two datasets that have been annotated in multiple ways .",
    "one has been annotated for both similarity and relatedness , and the other has been annotated for relatedness by two different types of experts ( medical doctors and medical coders ) .",
    "our results show that embedding second order co  occurrences with measures of semantic similarity increases correlation with our human reference standards .",
    "this suggests that these methods have the potential to improve performance over purely distributional methods .",
    "this section describes the similarity and relatedness measures we embed in our second ",
    "order co  occurrence vectors .",
    "we use two taxonomies in this study , snomed - ct and mesh .",
    "snomed - ct ( _ systematized nomenclature of medicine clinical terms _ ) is a comprehensive clinical terminology created for the electronic representation of clinical health information .",
    "mesh ( _ medical subject headings _ ) is a taxonomy of biomedical terms developed for indexing biomedical journal articles .",
    "we obtain snomed - ct and mesh via the unified medical language system ( umls ) metathesaurus ( version 2014aa ) .",
    "the metathesaurus contains approximately 2 million biomedical and clinical concepts from over 150 different terminologies that have been semi - automatically integrated into a single source .",
    "concepts in the metathesaurus are connected largely by two types of hierarchical relations : @xmath3/@xmath4 ( par / chd ) and @xmath5/@xmath6 ( rb / rn ) .",
    "measures of semantic similarity can be classified into three broad categories : path - based , feature - based and information content ( ic ) .",
    "path - based similarity measures use the structure of a taxonomy to measure similarity - concepts positioned close to each other are more similar than those further apart .",
    "feature - based methods rely on set theoretic measures of overlap between features ( union and intersection ) .",
    "the information content measures quantify the amount of information that a concept provides  more specific concepts have a higher amount of information content .",
    "@xcite introduce the _",
    "conceptual distance _ measure .",
    "this measure is simply the length of the shortest path between two concepts ( @xmath7 and @xmath8 ) in the mesh hierarchy .",
    "paths are based on _ broader than _ ( rb ) and _ narrower than _ ( rn ) relations .",
    "@xcite extends this measure to use _ parent _ ( par ) and _ child _ ( chd ) relations .",
    "our @xmath9 measure is simply the reciprocal of this shortest path value ( equation [ eq : path ] ) , so that larger values ( approaching 1 ) indicate a high degree of similarity .    @xmath10    while the simplicity of @xmath9 is appealing , it can be misleading when concepts are at different levels of specificity .",
    "two very general concepts may have the same path length as two very specific concepts . @xcite",
    "introduce a correction to @xmath9 that incorporates the depth of the concepts , and the depth of their least common subsumer ( lcs ) .",
    "this is the most specific ancestor two concepts share . in this measure , similarity is twice the depth of the two concept s lcs divided by the product of the depths of the individual concepts ( equation [ eq : wup ] ) . note that if there are multiple lcss for a pair of concepts , the deepest of them is used in this measure .",
    "@xmath11    @xcite take a very similar approach and again scale the depth of the lcs by the sum of the depths of the two concepts ( equation  [ eq : zhong ] ) , where @xmath12 . the value of @xmath13 was set to 2 based on their recommendations .",
    "@xmath14    @xcite offer another variation on @xmath9 , where the shortest path of the two concepts to the lcs is used , in addition to the shortest bath between the lcs and the root of the taxonomy ( equation  [ eq : pks ] ) .",
    "@xmath15      feature - based methods represent each concept as a set of features and then measure the overlap or sharing of features to measure similarity . in particular , each concept is represented as the set of their ancestors , and similarity is a ratio of the intersection and union of these features .    @xcite quantify the similarity between two concepts as the ratio of the intersection over their union as shown in equation  [ eq : cmatch ] .",
    "@xmath16    @xcite extend this by excluding any shared features ( in the numerator ) as shown in equation  [ eq : batet ] .",
    "@xmath17      information content is formally defined as the negative log of the probability of a concept .",
    "the effect of this is to assign rare ( low probability ) concepts a high measure of information content , since the underlying assumption is that more specific concepts are less frequently used than more common ones .",
    "@xcite modified this notion of information content in order to use it as a similarity measure .",
    "he defines the similarity of two concepts to be the information content of their lcs ( equation  [ eq : res ] ) .",
    "@xmath18    @xcite , @xcite , and @xcite extend @xmath19 by incorporating the information content of the individual concepts in various different ways .",
    "lin defines the similarity between two concepts as the ratio of information content of the lcs with the sum of the individual concept s information content ( equation  [ eq : lin ] ) .",
    "note that @xmath20 has the same form as @xmath21 and @xmath22 , and is in effect using information content as a measure of specificity ( rather than depth ) .",
    "if there is more than one possible lcs , the lcs with the greatest ic is chosen .",
    "@xmath23    jiang and conrath define the distance between two concepts to be the sum of the information content of the two concepts minus twice the information content of the concepts lcs .",
    "we modify this from a distance to a similarity measure by taking the reciprocal of the distance ( equation  [ eq : jcn ] ) .",
    "note that the denominator of @xmath24 is very similar to the numerator of @xmath25 .",
    "@xmath26    @xcite define the similarity between two concepts as the information content of the two concept s lcs divided by the sum of their individual information content values minus the information content of their lcs ( equation  [ eq : faith ] ) .",
    "note that @xmath25 can be viewed as a set - theoretic version of @xmath27 .",
    "@xmath28      the information content of a concept may be derived from a corpus ( corpus - based ) or directly from a taxonomy ( intrinsic - based ) . in this work",
    "we focus on corpus  based techniques .    for corpus  based information content , we estimate the probability of a concept @xmath29 by taking the sum of the probability of the concept @xmath30 and the probability its descendants @xmath31 ( equation  [ eq : prop ] ) .",
    "@xmath32    the initial probabilities of a concept ( @xmath30 ) and its descendants ( @xmath31 ) are obtained by dividing the number of times each concept and descendant occurs in the corpus , and dividing that by the total numbers of concepts ( @xmath33 ) .",
    "ideally the corpus from which we are estimating the probabilities of concepts will be sense tagged . however , sense - tagging is a challenging problem in its own right , and it is not always possible to carry out reliably on larger amounts of text .",
    "in fact in this paper we did not use any sense tagging of the corpus we derived information content from .    instead , we estimated the probability of a concept by using the _ umlsonmedline _ dataset .",
    "this was created by the national library of medicine and consists of concepts from the 2009ab umls and the counts of the number of times they occurred in a snapshot of medline taken on 12 january , 2009 .",
    "these counts were obtained by using the essie search engine @xcite which queried medline with normalized strings from the 2009ab mrconso table in the umls .",
    "the frequency of a cui was obtained by aggregating the frequency counts of the terms associated with the cui to provide a rough estimate of its frequency .",
    "the information content measures then use this information to calculate the probability of a concept .",
    "another alternative is the use of _ intrinsic information content_. it assess the informativeness of concept based on its placement within a taxonomy by considering the number of incoming ( ancestors ) relative to outgoing ( descendant ) links @xcite ( equation  [ eq : sanchez ] ) .    @xmath34    where @xmath35 are the number of descendants of concept @xmath29 that are leaf nodes , @xmath36 are the number of concept @xmath29 s ancestors and @xmath37 are the total number of leaf nodes in the taxonomy .",
    "@xcite observed that concepts that are related should share more words in their respective definitions than concepts that are less connected .",
    "he was able to perform word sense disambiguation by identifying the senses of words in a sentence with the largest number of overlaps between their definitions .",
    "an overlap is the longest sequence of one or more consecutive words that occur in both definitions .",
    "@xcite extended this idea to wordnet , but observed that wordnet glosses are often very short , and did not contain enough information to distinguish between multiple concepts .",
    "therefore , they created a _ super gloss _ for each concept by adding the glosses of related concepts to the gloss of the concept itself ( and then finding overlaps ) .",
    "@xcite adapted this measure to second - order co - occurrence vectors . in this approach ,",
    "a vector is created for each word in a concept s definition that shows which words co  occur with it in a corpus .",
    "these word vectors are averaged to create a single co - occurrence vector for the concept .",
    "the similarity between the concepts is calculated by taking the cosine between the concepts second - order vectors .",
    "@xcite modified and extended this measure to be used to quantify the relatedness between biomedical and clinical terms in the umls .",
    "the work in this paper can be seen as a further extension of @xcite .",
    "in this section , we describe our _ embedded second  order similarity vector _ measure .",
    "this incorporates both contextual information using the term pair s definition and their pairwise semantic similarity scores derived from a taxonomy .",
    "there are two stages to our approach .",
    "first , a co  occurrence matrix must be constructed .",
    "second , this matrix is used to construct a second  order co  occurrence vector for each concept in a pair of concepts to be measured for relatedness .",
    "we build an @xmath38 @xmath39 @xmath40 similarity matrix using an external corpus where the rows and columns represent words within the corpus and the element contains the similarity score between the row word and column word using the similarity measures discussed above .",
    "if a word maps to more than one possible sense , we use the sense that returns the highest similarity score .    for this paper",
    "our external corpus was the nlm medline bigram data .",
    "this consists of bigram counts obtained from the 2014 medline baseline .",
    "the bigrams are collected from the title and abstract fields in the medline citation resulting in 44,450,245 bigrams .",
    "we then calculate the similarity for each bigram in this dataset and include those that have a similarity score greater than a specified threshold on these experiments .",
    "we obtain definitions for each of the two terms we wish to measure . due to the sparsity and inconsistencies of the definitions in the umls ,",
    "we not only use the definition of the term ( cui ) but also include the definition of its related concepts .",
    "this follows the method proposed by @xcite for general english and wordnet , and which was adapted for the umls and the medical domain by @xcite .",
    "in particular we add the definitions of any concepts connected via a parent ( par ) , child ( chd ) , rb ( broader than ) , rn ( narrower than ) or term ( terms associated with cui ) relation .",
    "all of the definitions for a term are combined into a single _ super ",
    "gloss_. at the end of this process we should have two super  glosses , one for each term to be measured for relatedness .",
    "next , we process each super  gloss as follows .    1 .",
    "we extract a first ",
    "order co  occurrence vector for each term in the super  gloss from the co  occurrence matrix created in the previous step .",
    "2 .   we take the average of the first order co  occurrence vectors associated with the terms in a super - gloss and use that to represent the meaning of the term .",
    "this is a second  order co  occurrence vector .",
    "3 .   after a second ",
    "order co  occurrence vector has been constructed for each term , then we calculate the cosine between these two vectors to measure the relatedness of the terms .",
    "we use two reference standards to evaluate the semantic similarity and relatedness measures .",
    "umnsrs was annotated for both similarity and relatedness by medical residents .",
    "minimayosrs was annotated for relatedness by medical doctors ( md ) and medical coders ( coder ) . in this section",
    ", we describe these data sets and describe a few of their differences .",
    "minimayosrs is a subset of the mayosrs data set  @xcite , and consists of 30 term pairs for which a high level of inter - annotator agreement was attained .",
    "the average correlation between physicians is 0.68 and between medical coders is 0.78 .",
    "we evaluate our method on the mean of the physician scores and the mean of the coders scores in this subset in the same manner as reported by @xcite .",
    "umnsrs ( university of minnesota semantic relatedness set ) was developed by @xcite , and consists of 725 clinical term pairs whose semantic similarity and relatedness was determined independently by four medical residents from the university of minnesota medical school .",
    "the similarity and relatedness of each term pair was annotated based on a continuous scale by having the resident touch a bar on a touch sensitive computer screen to indicate the degree of similarity or relatedness . the intraclass correlation coefficient ( icc ) for the reference standard tagged for similarity was 0.47 , and 0.50 for relatedness .",
    "therefore , as suggested by pakhomov and colleagues , we use a subset of the ratings consisting of 401 pairs for the similarity set and 430 pairs for the relatedness set which each have an icc of 0.73 .",
    "we conducted our experiments using the freely available open source software package umls::similarity  @xcite version 1.41 .",
    "this package takes as input two terms ( or umls concepts ) and returns their similarity or relatedness using the measures discussed in section  [ sec : measures ] .",
    "correlation between the similarity measures and human judgments were estimated using spearman s rank correlation ( @xmath41 ) .",
    "spearman s measures the statistical dependence between two variables to assess how well the relationship between the rankings of the variables can be described using a monotonic function .",
    "we used fisher s r - to - z transformation  @xcite to calculate the significance between the correlation results .",
    "table  [ tbl : correlationresults ] shows the spearman s rank correlation between the human scores from the four reference standards and the scores from the various measures of similarity introduced in section [ sec : measures ] .",
    "each class of measure is followed by the scores obtained when embedding our second order vector approach with these measures of semantic similarity .",
    ".spearman s correlation results [ cols=\"<,^,^,^,^ \" , ]     [ tbl : faith ]    overall , these results indicate that including only those bigrams that have a sufficiently high similarity score increases the correlation results with human judgments , but what quantifies as sufficiently high varies depending on the dataset and measure .",
    "in this paper , we present a method for quantifying the similarity and relatedness between two terms that incorporates pair - wise similarity scores into 2nd order vectors in order to restrict the context used by the vector measure to words that exist in the biomedical domain and weight those word pairs that are more similar higher .",
    "our hypothesis was that this would reduce the amount of noise in the vectors and increase the correlation results .",
    "we evaluated our method on datasets that have been annotated for relatedness and similarity .",
    "the results show that using a combination of contextual information using the term pair s definition and their pairwise semantic similarity scores derived from a taxonomy obtain a high correlation with human judgments for both similarity and relatedness . in the future",
    ", we plan to further explore combining this type of information to quantify the relatedness and similarity between term pairs .    in this work",
    ", we also explored using a threshold cutoff to include only those term pairs that obtained pre - specified similarity score . in the future , we plan to explore metrics to automatically determine the threshold cutoff appropriate given a dataset .",
    "we also plan to look at additional features that can be used with in the second - order vector measure that will reduce the noise but still provide adequate information to quantify relatedness .",
    "satanjeev banerjee and ted pedersen .",
    "the design , implementation , and use of the ngram statistics package . in _ proceedings of the fourth international conference on intelligent text processing and computational linguistics _ , pages 370381 , mexico city , february .",
    "o.  bodenreider and a.  burgun .",
    "2004 . aligning knowledge sources in the umls : methods , quantitative results , and applications . in _ proceedings of the 11th world congress on medical informatics ( medinfo ) _",
    ", pages 327331 , san fransico , ca , november .",
    "aminul islam and diana inkpen . 2006 .",
    "second order co - occurrence pmi for determining the semantic similarity of words . in _ proceedings of the international conference on language resources and evaluation _ , pages 10331038 , genoa , italy .",
    "j.  jiang and d.  conrath .",
    "1997 . semantic similarity based on corpus statistics and lexical taxonomy . in _",
    "proceedings on international conference on research in computational linguistics _ , pages 1933 , taiwan .",
    "m.e . lesk .",
    "automatic sense disambiguation using machine readable dictionaries : how to tell a pine cone from an ice cream cone . in _ proceedings of the 5th annual international conference on systems documentation _ , pages 2426 .",
    "acm press .",
    "y.  liu , b.  mcinnes , t.  pedersen , g.  melton - meaux , and s.  pakhomov . 2012 .",
    "semantic relatedness study using second  order co  occurrene vectors computed from biomedical corpora , umls , and wordnet . in _ proceedings of the 2nd acm sighit international health informatics symposium _",
    ", pages 363371 , miami , fl .",
    "b.  mcinnes , t.  pedersen , and s.  pakhomov .",
    "-interface and umls - similarity : open source software for measuring paths and semantic similarity . in _ proceedings of the annual symposium of the american medical informatics association _ ,",
    "pages 431435 , san francisco .",
    "s.  pakhomov , b.  mcinnes , t.  adam , y.  liu , t.  pedersen , and g.  melton . 2010 .",
    "semantic similarity and relatedness between clinical terms : an experimental study . in _ proceedings of the annual symposium of the american medical informatics association _ ,",
    "washington , dc .",
    "s.  patwardhan and t.  pedersen .",
    "2006 . . in _ proceedings of the eacl 2006 workshop on making sense of sense : bringing computational linguistics and psycholinguistics together",
    ", pages 18 , trento , italy , april .",
    "viktor pekar and steffen staab .",
    "taxonomy learning : factoring the structure of a taxonomy into a semantic classification decision . in _ proceedings of the 19th international conference on computational linguistics - volume 1 _ , coling 02 , pages 17 , stroudsburg , pa , usa .",
    "association for computational linguistics .",
    "kira radinsky , eugene agichtein , evgeniy gabrilovich , and shaul markovitch . 2011 . a word at a time : computing word relatedness using temporal semantic analysis . in _ proceedings of the 20th international conference on world wide web _ ,",
    "pages 337346 .",
    "joseph reisinger and raymond  j mooney .",
    "multi - prototype vector - space models of word meaning . in _ human language technologies :",
    "the 2010 annual conference of the north american chapter of the association for computational linguistics _",
    ", pages 109117 .",
    "association for computational linguistics .",
    "p.  resnik .",
    "1995 . using information",
    "content to evaluate semantic similarity in a taxonomy . in _ proceedings of the 14th international joint conference on artificial intelligence _ , pages 448453 , montreal , august .",
    "julie weeds , david weir , and diana mccarthy .",
    "characterising measures of lexical distributional similarity . in _ proceedings of the 20th international conference on computational linguistics _",
    ", page 1015 .",
    "association for computational linguistics .",
    "wen - tau yih and vahed qazvinian .",
    "2012 . measuring word relatedness using heterogeneous vector space models . in _ proceedings of the 2012 conference of the north american chapter of the association for computational linguistics",
    ": human language technologies _ , pages 616620 .",
    "association for computational linguistics ."
  ],
  "abstract_text": [
    "<S> vector space methods that measure semantic similarity and relatedness often rely on distributional information such as co  occurrence frequencies or statistical measures of association to weight the importance of particular co - occurrences . in this paper </S>",
    "<S> we extend these methods by embedding a measure of semantic similarity based on a human curated taxonomy into a second  order vector representation . </S>",
    "<S> this results in a measure of semantic relatedness that combines both the contextual information available in a corpus  based vector space representation with the semantic knowledge found in a biomedical ontology . </S>",
    "<S> our results show that embedding semantic semantic similarity into a second order co  occurrence matrix improves correlation with human judgments for both similarity and relatedness . </S>"
  ]
}