{
  "article_text": [
    "the _ consecutive 1 s problem _ ( ) @xcite is defined as follows . given a binary matrix @xmath0 the goal is to permute its rows in such a way that the resulting matrix enjoys the _ consecutive 1 s property _ : each of its columns is a vector @xmath1 where @xmath2 if and only if @xmath3 for two integers @xmath4 between @xmath5 and @xmath6 .",
    "this problem has its roots in archeology and especially _ sequence dating _ where the goal is to recover the chronological order of sepultures based on artifacts found in these sepultures where the entry @xmath7 of matrix @xmath0 indicates the presence of artifact @xmath8 in sepulture @xmath9 . in his seminal work , egyptologist flinders petrie  @xcite formulated the hypothesis that two sepultures should be close in the time domain if they present similar sets of artifacts .",
    "already in the noiseless case , this problem presents an interesting algorithmic challenge and is reducible to the famous travelling salesman problem  @xcite as observed by statistician david kendall @xcite who employed early tools from multidimensional scaling as a heuristic to solve it",
    ".  belongs to a more general class of so - called _ seriation _ problems that consist in optimizing various criteria over the discrete set of permutations .",
    "while such problems are hard in general , it can be shown that a subset of the these problems , including , can be solve efficiently using spectral method  @xcite or convex optimization  @xcite .",
    "however , little is known about the robustness to noise of such methods . in order to set the benchmark for the noisy case",
    ", we propose a statistical _ seriation model _ and study optimal rates of estimation in this model .",
    "assume that we observe an @xmath10 matrix @xmath11 , where @xmath12 is an unknown @xmath13 permutation matrix , @xmath14 is an @xmath10 noise matrix and @xmath15 is assumed to belong to a class of matrices that satisfy a certain shape constraint .",
    "our goal is to give estimators @xmath16 and @xmath17 so that @xmath18 is close to @xmath19",
    ". the shape constraint can be the consecutive 1 s property , but more generally , we consider the class of matrices that have unimodal columns , which also include monotonic columns as a special case .",
    "these terms will be formally defined at the end of this section .",
    "the rest of the paper is organized as follows . in section  [ sec : problem ] we formulate the model and discuss related work .",
    "section  [ sec : result ] collects our main results , including uniform and adaptive upper bounds for the least squares estimator together with corresponding minimax lower bounds in the general unimodal case . in section  [ sec : rankscore ] , for the special case of monotone columns , we propose a computationally efficient alternative to the least squares estimator and study its rates of convergence both theoretically and numerically .",
    "appendix  [ sec : upper ] is devoted to the proofs of the upper bounds , which use the metric entropy bounds proved in appendix  [ sec : covering ] .",
    "the proofs of the information - theoretic lower bounds are presented in appendix  [ sec : lower ] . in appendix",
    "[ sec : monotone ] ,",
    "we study the rate of estimation of the efficient estimator for the monotonic case . appendix  [ sec : trivial - upper ] contains a delayed proof of a trivial upper bound .",
    "appendix  [ sec : unimodal ] presents new bounds for unimodal regression implied by our analysis , which are minimax optimal up to logarithmic factors .    notation . for a positive integer @xmath6 ,",
    "define @xmath20=\\{1,\\ldots , n\\}$ ] . for a matrix @xmath15 ,",
    "let @xmath21 denote its frobenius norm , and let @xmath22 be its @xmath9-th row and @xmath23 be its @xmath8-th column .",
    "let @xmath24 denote the euclidean ball of radius @xmath25 centered at @xmath26 in @xmath27 .",
    "we use @xmath28 and @xmath29 to denote positive constants that may change from line to line . for any two sequences @xmath30 and @xmath31 , we write @xmath32 if there exists an absolute constant @xmath33 such that @xmath34 for all @xmath6 .",
    "we define @xmath35 analogously . given two real numbers @xmath36 ,",
    "define @xmath37 and @xmath38 .",
    "denote the closed convex cone of increasing sequences in @xmath27 by @xmath39 .",
    "we define @xmath40 to be the cartesian product of @xmath41 copies of @xmath42 and we identify @xmath40 to the set of @xmath10 matrices with increasing columns .    for any @xmath43",
    "$ ] , define the closed convex cone @xmath44 , which consists of vectors in @xmath27 that increase up to the @xmath45-th entry and then decrease .",
    "define the set @xmath46 of unimodal sequences in @xmath27 by @xmath47 .",
    "we define @xmath48 to be the cartesian product of @xmath41 copies of @xmath46 and we identify @xmath48 to the set of @xmath10 matrices with unimodal columns .",
    "it is also convenient to write @xmath48 as a union of closed convex cones as follows . for @xmath49^m$ ] , let @xmath50 .",
    "then @xmath48 is the union of the @xmath51 closed convex cones @xmath52^m$ ] .",
    "finally , let @xmath53 be the set of @xmath13 permutation matrices and define @xmath54 where @xmath55 , so that @xmath56 is the union of the @xmath57 closed convex cones @xmath58^m$ ] .",
    "in this section , we formally state the problem of interest and discuss several lines of related work .",
    "suppose that we observe a matrix @xmath59 , @xmath60 such that @xmath61 where @xmath62 , @xmath63 and @xmath14 is a centered sub - gaussian noise matrix with variance proxy @xmath64 .",
    "more specifically , @xmath14 is a matrix such that @xmath65=0 $ ] and , for any @xmath66 , @xmath67 \\le",
    "\\exp\\big(\\frac{\\sigma^2\\|m\\|_f^2}{2}\\big)\\ , , \\ ] ] where @xmath68 is the trace operator . we write @xmath69 or simply @xmath70 when dimensions are clear from the context .",
    "given the observation @xmath71 , our goal is to estimate the unknown pair @xmath72 .",
    "the performance of an estimator @xmath73 , is measured by the quadratic loss : @xmath74 in particular , its expectation is the mean squared error . since we are interested in estimating @xmath75 , we can also view @xmath76 as the parameter space .    in the general unimodal case , upper bounds on the above quadratic loss",
    "do not imply individual upper bounds on estimation of the matrix @xmath77 or the matrix @xmath78 due to lack of identifiability . nevertheless , if we further assume that the columns of @xmath78 are monotone increasing , that is @xmath79 , then the following lemma holds .",
    "[ lem : rearrange ] if @xmath80 , then for any @xmath81 , we have that @xmath82 and that @xmath83    let @xmath84 and @xmath85 where @xmath86\\to [ n]$ ] is a permutation .",
    "it is easy to check that @xmath87 , so @xmath88 . applying this inequality to columns of matrices",
    ", we see that @xmath89 since @xmath80 .",
    "moreover , @xmath90 , so @xmath91 by the triangle inequality and the previous display .",
    "lemma  [ lem : rearrange ] guarantees that @xmath92 is a pertinent measure of the performance of @xmath93 .",
    "note further that @xmath92 is large if @xmath93 misplaces rows of @xmath78 that have large differences , and is small if @xmath93 only misplaces rows of @xmath78 that are close to each other .",
    "we argue that , in the seriation context , this measure of distance between permutations is more natural than ad hoc choices such as the trivial 0/1 distance or popular choices such as kendall s @xmath94 or spearman s @xmath95 .    apart from section  [ sec : rankscore ] ( and appendix  [ sec : monotone ] ) , the rest of this paper focuses on the least squares ( ls ) estimator defined by @xmath96 taking @xmath97 , we see that it is equivalent to define the ls estimator by @xmath98 note that in our case , the set of parameters @xmath76 is not convex , but is a union of @xmath57 closed convex cones and it is not clear how to compute the ls estimator efficiently .",
    "we discuss this aspect in further details in the context of monotone columns in section  [ sec : rankscore ] .",
    "nevertheless , the main focus of this paper is the least squares estimator which , as we shall see , is near - optimal in a minimax sense and therefore serves as a benchmark for the statistical seriation model .",
    "our work falls broadly in the scope of statistical inference under shape constraints but presents a major twist : the unknown latent permutation @xmath77 .",
    "to set our goals , we first consider the case where the permutation is known and assume without loss of generality that @xmath99 . in this case",
    ", we can estimate individually each column @xmath100 by an estimator @xmath101 and then get an estimator @xmath17 for the whole matrix by concatenating the columns @xmath101 .",
    "thus the task is reduced to estimation of a vector @xmath102 which satisfies a certain shape constraint from an observation @xmath103 where @xmath104 .    when @xmath102 is assumed to be increasing we speak of isotonic regression @xcite .",
    "the ls estimator defined by @xmath105 can be computed in closed form in @xmath106 using the pool - adjacent - violators algorithm ( pava ) @xcite and its statistical performance has been studied by zhang @xcite ( see also @xcite for similar bounds using empirical process theory ) who showed in the gaussian case @xmath107 that the mean squared error behaves like @xmath108 where @xmath109 } \\theta_i - \\min_{i \\in [ n ] } \\theta_i$ ] is the variation of @xmath110 .",
    "note that @xmath111 for @xmath112 so that this is the minimax rate of estimation of lipschitz functions ( see , e.g. , @xcite ) .",
    "the rate in is said to be _ global _ has it holds uniformly over the set of monotone vectors with variation @xmath113 .",
    "recently , @xcite have initiated the study of _ adaptive _ bounds that may be better if @xmath102 has a simpler structure in some sense . to define this structure ,",
    "let @xmath114 denote the cardinality of entries of @xmath110 .",
    "in this context , @xcite showed that the ls estimator satisfies the adaptive bound @xmath115 this result was extended in @xcite to a sharp oracle inequality where @xmath116 .",
    "this bound was also shown to be optimal in a minimax sense @xcite .",
    "unlike its monotone counterpart , unimodal regression where @xmath117 has received sporadic attention @xcite .",
    "this state of affairs is all the more surprising given that unimodal density estimation has been the subject of much more research @xcite .",
    "it was recently shown in @xcite that the ls estimator also adapts to @xmath113 and @xmath118 for unimodal regression : @xmath119 with probability at least @xmath120 for some @xmath121 .",
    "the exponent @xmath122 in the second term was improved to @xmath5 in the new version of @xcite after the first version of our current paper was posted .",
    "note that the exponents in are different from the isotonic case .",
    "our results will imply that they are not optimal and in fact the ls estimator achieves the same rate as in isotonic regression .",
    "see corollary  [ cor : unimodal ] for more details .",
    "the algorithmic aspect of unimodal regression has received more attention @xcite and @xcite showed that the ls estimator can be computed with time complexity @xmath106 using a modified version of pava . hence there is little difference between isotonic and unimodal regressions from both computational and statistical points of views",
    ".      when the permutation @xmath77 is unknown the estimation problem is more involved .",
    "noisy permutation learning was explicitly addressed in @xcite where the problem of matching two sets of noisy vectors was studied from a statistical point of view . given @xmath123 matrices @xmath124 and @xmath125 , where @xmath126 is an unknown matrix and @xmath127 is an unknown permutation matrix , the goal is to recover @xmath77 .",
    "it was shown in @xcite that if @xmath128 , then the ls estimator defined by @xmath129 recovers the true permutation with high probability .",
    "however they did not directly study the behavior of @xmath130 .    in his celebrated paper on matrix estimation  @xcite",
    ", sourav chatterjee describes several noisy matrix models involving unknown latent permutations .",
    "one is the _ nonparametric bradley - terry - luce _ ( np - btl ) model where we observe a matrix @xmath131 with independent entries @xmath132 for some unknown parameters @xmath133 where @xmath134 $ ] is equal to the probability that item @xmath9 is preferred over item @xmath8 and @xmath135 .",
    "crucially , the np - btl model assumes the so - called _ strong stochastic transitivity ( sst ) _",
    "@xcite assumption : there exists an unknown permutation matrix @xmath136 such that the ordered matrix @xmath137 satisfies @xmath138 for all @xmath139 $ ] . note that the np - btl model is a special case of our model where @xmath140 and @xmath141 is taken to be bernoulli .",
    "chatterjee proposed an estimator @xmath142 that leverages the fact that any matrix @xmath143 in the np - btl model can be approximated by a low rank matrix and proved ( * ? ? ?",
    "* theorem  2.11 ) that @xmath144 , which was improved to @xmath145 by @xcite for a variation of the estimator .",
    "this method does not yield individual estimators of @xmath12 or @xmath0 , and @xcite proposed estimators @xmath16 and @xmath17 so that @xmath146 estimates @xmath143 with the same rate @xmath145 up to a logarithmic factor .",
    "the non - optimality of this rate has been observed in @xcite who showed that the correct rate should be of order @xmath147 up to a possible @xmath148 factor .",
    "however , it is not known whether a computationally efficient estimator could achieve the fast rate .",
    "a recent work @xcite explored a new notion of adaptivity for which the authors proved a computational lower bound , and also proposed an efficient estimator whose rate of estimation matches that lower bound .",
    "also mentioned in chatterjee s paper is the so - called _ stochastic block model _ that has since received such extensive attention in various communities that it is futile to attempt to establish a comprehensive list of references .",
    "instead , we refer the reader to  @xcite and references therein .",
    "this paper establishes the minimax rates for this problem and its continuous limit , the graphon estimation problem and , as such , constitutes the state - of - the - art in the statistical literature . in the stochastic block model with @xmath149 blocks",
    ", we assume that we observe a matrix @xmath150 where @xmath151 is an unknown permutation matrix and @xmath0 has a block structure , namely , there exist positive integers @xmath152 , and @xmath153 real numbers @xmath154 ^ 2 $ ] such that @xmath0 has entries @xmath155 ^ 2}a_{s , t } { { \\rm 1}\\kern-0.24em{\\rm i}}\\{n_s\\le i \\le n_{s+1 } , n_t\\le j \\le n_{t+1}\\}\\ , , \\qquad i , j \\in [ n]\\,.\\ ] ] while traditionally , the stochastic block model is a network model and therefore pertains only to bernoulli observations , the more general case of sub - gaussian additive error is also explicitly handled in  @xcite . for this problem ,",
    "gao , liu and zhou have established that the least squares estimator @xmath142 satisfies @xmath156 together with a matching lower bound .",
    "using piecewise constant approximation to bivariate hlder functions , they also establish that this estimator with a correct choice of @xmath157 leads to minimax optimal estimation of smooth graphons .",
    "both results exploit extensively the fact that the matrix @xmath143 is equal to or can be well approximated by a piecewise constant matrix and our results below take a similar route by observing that monotone and unimodal vectors are also well approximated by piecewise constant ones .",
    "moreover , we allow for rectangular matrices .    in fact , our result can be also formulated as a network estimation problem but on a bipartite graph , thus falling at the intersection of the above two examples .",
    "assume that @xmath6 left nodes represent items and that @xmath41 right nodes represent users .",
    "assume further that we observe the @xmath10 adjacency matrix @xmath71 of a random graph where the presence of edge @xmath158 indicates that user @xmath8 has purchased or liked item @xmath9 .",
    "define @xmath159 $ ] and assume sst across items in the sense that there exists an unknown @xmath13 permutation matrix @xmath77 such that @xmath160 and @xmath78 is such that @xmath161 for all users @xmath162 $ ] .",
    "this model falls into the scope of the statistical seriation model .",
    "for a matrix @xmath163 , let @xmath164 be the number of values taken by the @xmath8-th column of @xmath0 and define @xmath165 .",
    "observe that @xmath166 .",
    "the first theorem shows that the ls estimator adapts to the complexity @xmath167 .",
    "[ thm : adaptive ] for @xmath168 and @xmath169 , let @xmath170 be the ls estimator defined in",
    ". then the following oracle inequality holds @xmath171 with probability at least @xmath172 .",
    "moreover , @xmath173    note that while we assume that @xmath62 in , the above oracle inequalities hold in fact for any @xmath168 even if its columns are _ not _ assumed to be unimodal .",
    "the above oracle inequalities indicate that the ls estimator automatically trades off the approximation error @xmath174 for the stochastic error @xmath175 .",
    "if @xmath78 is assumed to have unimodal columns , then we can take @xmath176 in and to get the following corollary .",
    "[ cor : adaptive ] for @xmath62 and @xmath169 , the ls estimator @xmath170 satisfies @xmath177 with probability at least @xmath178 .",
    "moreover , the corresponding bound with the same rate holds in expectation .",
    "the two terms in the adaptive bound can be understood as follows .",
    "the first term corresponds to the estimation of the matrix @xmath78 with unimodal columuns if the permutation @xmath77 is known .",
    "it can be viewed as a matrix version of the adaptive bound in the vector case .",
    "the ls estimator adapts to the cardinality of entries of @xmath78 as it achieves a provably better rate if @xmath179 is smaller while not requiring knowledge of @xmath179 .",
    "the second term corresponds to the error due to the unknown permutation @xmath77 .",
    "as @xmath41 grows to infinity this second term vanishes , because we have more samples to estimate @xmath77 better .",
    "if @xmath180 , it is easy to check that the permutation term is dominated by the first term , so the rate of estimation is the same as if the permutation is known .      the bounds in theorem  [ thm : adaptive ] adapt to the cardinality of the oracle",
    ". in this subsection , we state another type of upper bounds for the ls estimator @xmath170",
    "they are called global bounds because they hold uniformly over the class of matrices whose columns are unimodal and that have bounded variation .",
    "recall that we call _ variation _ of a vector @xmath181 the scalar @xmath182 defined by @xmath183 we extend this notion to a matrix @xmath184 by defining @xmath185 while this @xmath186-norm may seem odd at first sight , it turns out to be the correct extrapolation from vectors to matrices , at least in the context under consideration here .",
    "indeed , the following upper bound , in which this quantity naturally appears , is matched by the lower bound of theorem  [ thm : lower - global ] up to logarithmic terms .",
    "[ thm : global ] for @xmath168 and @xmath169 , let @xmath170 be the ls estimator defined in .",
    "then it holds that @xmath187 + \\sigma^2 \\frac{\\log n}{n\\wedge m } \\,.\\end{gathered}\\ ] ] with probability at least @xmath172 .",
    "moreover , the corresponding bound with the same rate holds in expectation .    if @xmath62 , then taking @xmath176 in theorem  [ thm : global ] leads to the following corollary that indicates that the ls estimator is adaptive to the quantity  @xmath188 .",
    "[ cor : global ] for @xmath62 and @xmath169 , the ls estimator @xmath170 satisfies @xmath189 with probability at least @xmath172 .",
    "moreover , the corresponding bound with the same rate holds in expectation .",
    "akin to the adaptive bound , the above inequality can be viewed as a sum of a matrix version of and an error due to estimation of the unknown permutation .",
    "having stated the main upper bounds , we digress a little to remark that the proofs of theorem  [ thm : adaptive ] and theorem  [ thm : global ] also yield a minimax optimal rate of estimation ( up to logarithmic factors ) for unimodal regression , which improves the bound . we discuss the details in appendix  [ sec : unimodal ] .",
    "given the model @xmath169 where entries of @xmath14 are i.i.d .",
    "@xmath190 random variables , let @xmath170 denote any estimator of @xmath72 , i.e. , any pair in @xmath191 that is measurable with respect to the observation @xmath71",
    ". we will prove lower bounds that match the rates of estimation in corollary  [ cor : adaptive ] and corollary  [ cor : global ] up to logarithmic factors .",
    "the combination of upper and lower bounds , implies simultaneous near optimality of the least squares estimator over a large scale of matrix classes .    for @xmath192 and @xmath193 ,",
    "define @xmath194 and @xmath195 we present below two lower bounds , one for the adaptive rate uniformly over @xmath196 and one for the global rate uniformly over @xmath197 .",
    "this splitting into two cases is solely justified by better readability but it is worth noting that a stronger lower bound that holds on the intersection @xmath198 can also be proved and is presented as proposition  [ prop : lower - stronger ] .",
    "[ thm : lower - adaptive ] there exists a constant @xmath199 such that for any @xmath200 , and any estimator @xmath170 , it holds that @xmath201   \\ge c , \\ ] ] where @xmath202 and @xmath203 is the probability distribution of @xmath204 .",
    "it follows that the lower bound with the same rate holds in expectation .",
    "in fact , the lower bound holds for any estimator of the matrix @xmath205 , not only those of the form @xmath18 with @xmath206 . the above lower bound matches the upper bound in corollary  [ cor : adaptive ] up to logarithmic factors .",
    "note the presence of a @xmath207 factor in the second term . if @xmath208 then @xmath209 which means that each column of @xmath0 is simply a constant block , so @xmath210 for any @xmath63 . in this case ,",
    "the second term vanishes because the permutation does not play a role .",
    "more generally , the number @xmath211 can be understood as the maximal number of columns of @xmath0 on which the permutation does have an effect .",
    "the larger @xmath45 , the harder the estimation .",
    "it is easy to check that if @xmath212 the second term in the lower bound will be dominated by the first term in the upper bound .",
    "a lower bound corresponding to corollary  [ cor : global ] also holds :    [ thm : lower - global ] there exists a constant @xmath199 such that for any @xmath213 , and any estimator @xmath170 , it holds that @xmath214   \\ge c \\,,\\ ] ] where @xmath203 is the probability distribution of @xmath204 .",
    "the lower bound with the same rate also holds in expectation .",
    "there is a slight mismatch between the upper bound of corollary  [ cor : global ] and the lower bound of theorem  [ thm : lower - global ] above .",
    "indeed the lower bound features a term @xmath215 instead of just @xmath216 . in the regime @xmath217 , where @xmath0 has very small variation , the ls estimator may not be optimal .",
    "proposition  [ prop : special - regime ] indicates that a matrix with constant columns obtained by averaging achieves optimality in this extreme regime .",
    "a particularly interesting subset of unimodal matrices is @xmath40 , the set of @xmath218 matrices with monotonically increasing columns .",
    "while it does not amount to the seriation problem in its full generality , this special case is of prime importance in the context of shape constrained estimation as illustrated by the discussion and references in section  [ sec : related - work ] .",
    "in fact , it covers the example of bipartite ranking discussed at the end of section  [ sec : related - work ] . in the rest of this section , we devote further investigation to this important case . to that end , consider the model where we further assume that @xmath219 .",
    "we refer to this model as the _ monotone seriation model_. in this context , define the ls estimator by @xmath220 since @xmath40 is a convex subset of @xmath48 , it is easily seen that the upper bounds in theorem  [ thm : adaptive ] and [ thm : global ] remain valid in this case .",
    "the lower bounds of theorem  [ thm : lower - adaptive ] ( with @xmath207 replaced by @xmath5 ) and theorem  [ thm : lower - global ] also extend to this case ; see appendix  [ sec : lower ] .",
    "although for unimodal matrices the established error bounds do not imply any bounds on estimation of @xmath78 or @xmath77 in general , for the monotonic case , however , lemma  [ lem : rearrange ] yields that @xmath221 so that the ls estimator @xmath170 also leads to good individual estimators of @xmath77 and @xmath78 respectively .    because it requires optimizing over a union of @xmath222 cones @xmath223 , no efficient way of computing the ls estimator",
    "is known since . as an alternative",
    ", we describe a simple and efficient algorithm to estimate @xmath72 and study its rate of estimation .",
    "let @xmath224 and @xmath225 be defined as before .",
    "moreover , for a matrix @xmath226 , let @xmath227 denote the set of pairs of indices @xmath228 ^ 2 $ ] such that @xmath22 and @xmath229 are not identical .",
    "define the quantity @xmath230 by @xmath231 ^ 2\\\\ |\\mathcal i|",
    "= n } } \\sum_{(i , j ) \\in \\mathcal i \\cap \\mathcal j } \\big ( \\frac{\\|a_{i,\\cdot } - a_{j,\\cdot}\\|_2 ^ 2}{\\|a_{i,\\cdot } - a_{j,\\cdot}\\|_\\infty^2}\\wedge \\frac{m \\|a_{i,\\cdot } - a_{j,\\cdot}\\|_2 ^ 2}{\\|a_{i,\\cdot } - a_{j,\\cdot}\\|_1 ^ 2 } \\big ) \\,.\\ ] ] it can be shown ( see appendix  [ sec : monotone ] ) that @xmath232 . intuitively , the quantity @xmath230 is small if the difference @xmath233 of any two rows of @xmath0 is either very sparse ( @xmath234 is small ) or very dense ( @xmath235 is small ) .",
    "indeed , for any nonzero vector @xmath236 , @xmath237 with equality achieved when @xmath238 , and @xmath239 with equality achieved when all entries of @xmath233 are the same .    for matrices with small @xmath240 values ,",
    "it is possible to aggregate the information across each row to learn the unknown permutation @xmath77 in a simple fashion .",
    "recovering the permutation @xmath77 , is equivalent to ordering ( or ranking reversely ) the rows of @xmath241 from their noisy version @xmath71 .",
    "one simple method to achieve this goal , which we call , is to permute the rows of @xmath71 so that they have increasing row sums .",
    "however , it is easy to observe that this method fails if @xmath242 where @xmath243 and entries of @xmath14 are i.i.d .",
    "standard gaussian variables , because the sum of noise in a row has order @xmath244 which is no less than the gaps between row sums of @xmath78 .",
    "in fact , @xmath245 and it should be easy to distinguish the two types of rows of @xmath78 , for example , by looking at the first entry of a row .",
    "this motivates us to consider the following method called . for @xmath246 $ ] , define @xmath247 } ( a^*_{i ' , j } - a^*_{i , j})\\vee \\frac 1{\\sqrt m } \\sum_{j=1}^m ( a^*_{i ' , j } - a^*_{i , j})\\ ] ] and define @xmath248 analogously . the  procedure is defined as follows :    1 .   for each @xmath249 $ ] , define the score @xmath250 of the @xmath9-th row of @xmath71 by @xmath251 where @xmath252 for some tuning constant @xmath28 ( see appendix  [ sec : monotone ] for more details ) .",
    "2 .   then order the rows of @xmath71 so that their scores are increasing , with ties broken arbitrarily .",
    "the  procedure recovers an order of the rows of @xmath71 , which leads to an estimator @xmath93 of the permutation",
    ". then we define @xmath253 so that @xmath254 is the projection of @xmath71 onto the convex cone @xmath255 .",
    "the estimator @xmath256 enjoys the following rate of estimation .",
    "[ thm : monotone ] for @xmath219 and @xmath169 , let @xmath256 be the estimator defined above using the  procedure with threshold @xmath257 , @xmath33 . then it holds that @xmath258 with probability at least @xmath259 for some constant @xmath260 .",
    "the quantity @xmath261 only depends on the matrix @xmath78 .",
    "if @xmath261 is bounded logarithmically , the estimator @xmath256 achieves the minimax rate up to logarithmic factors . in any case , @xmath262 , so the estimator is still consistent with the permutation error ( the last term ) decaying at a rate no slower than @xmath263 .",
    "furthermore , it is worth noting that @xmath261 is not needed to construct @xmath256 , so the estimator adapts to @xmath261 automatically .    in the same way that theorem  [ thm : global ] follows from theorem  [ thm : adaptive ]",
    ", we can deduce from theorem  [ thm : monotone ] a global bound for the estimator @xmath256 which has rate @xmath264    we conclude this section with a numerical comparison between the  and  procedures .",
    "consider the model with @xmath265 and assume without loss of generality that @xmath99 . for various @xmath10 matrices",
    "@xmath78 , we generate observations @xmath124 where entries of @xmath14 are i.i.d .",
    "standard gaussian variables .",
    "the performance of the estimators given by  and  defined above is compared to the performance of the oracle @xmath266 defined by the projection of @xmath71 onto the cone @xmath40 . for the  estimator",
    "we take @xmath267 .",
    "the curves are generated based on @xmath268 equally spaced points on the base-@xmath269 logarithmic scale , and all results are averaged over @xmath269 replications .",
    "the vertical axis represents the estimation error of an estimator @xmath270 , measured by the sample mean of @xmath271 unless otherwise specified .     of size @xmath272 .",
    "left : rows of @xmath78 are @xmath5-sparse ; right : columns of @xmath78 are identical . ]     of size @xmath272 . left : rows of @xmath78 are @xmath5-sparse ; right : columns of @xmath78 are identical . ]",
    "we begin with two simple examples for which we set @xmath273 . in the left plot of figure  [ fig : plot1 ] , @xmath78 is defined as in .",
    "as expected ,  fails to estimate the true permutation and performs very poorly . on the other hand ,",
    "succeeds in recovering the correct permutation and has roughly the same performance as the oracle . because the difference of any two rows of @xmath78 is @xmath5-sparse , @xmath245 according to and the discussion thereafter .",
    "hence , theorem  [ thm : monotone ] predicts the fast rate , which is verified by the experiment .",
    "the right plot illustrates another extreme case ; more precisely , we set @xmath78 to be the matrix with all @xmath41 columns equal to @xmath274 .",
    "the difference of any two rows of @xmath78 is constant across all entries , so again we have @xmath245 by .",
    "thus  achieves the fast rate as expected .",
    "note that  also performs well in this case .     and randomly generated @xmath78 of size @xmath10 .",
    "left : @xmath275 ; right : @xmath276 . ]     and randomly generated @xmath78 of size @xmath10 .",
    "left : @xmath275 ; right : @xmath276 . ]    in figure  [ fig : plot2 ] , we compare the performance of  to that of the oracle in three regimes of @xmath277 .",
    "the matrices @xmath78 are randomly generated for different values of @xmath6 and @xmath41 as follows .",
    "for the right plot , @xmath78 is generated so that @xmath276 , by sorting the columns of a matrix with i.i.d .",
    "@xmath278 entries . for the left plot",
    ", we further require that @xmath275 by uniformly partitioning each column of @xmath78 into five blocks and assigning each block the corresponding value from a sorted sample of five i.i.d . @xmath278 variables .",
    "since the oracle knows the true permutation , its behavior is independent of @xmath41 , and its rates of estimation are bounded by @xmath279 for @xmath280 and @xmath281 for @xmath282 respectively by theorem  [ thm : adaptive ] and [ thm : global ] .",
    "( the difference is minor in the plots as @xmath6 is not sufficiently large ) . for , the permutation term dominates the estimation term when @xmath283 by theorem  [ thm : monotone ] . from the plots , the rates of estimation are better than @xmath284 predicted by the worst - case analysis in both examples . for @xmath140",
    ", we also observe rates of estimation faster than the worst - case rate @xmath285 and close to the oracle rates .",
    "we could explain this phenomenon by @xmath286 , but such an interpretation may not be optimal since our analysis is based on worst - case deterministic @xmath78 .",
    "potential study of random designs of @xmath78 is left open .",
    "finally , for @xmath287 , the permutation term is of order @xmath288 theoretically , in between of the oracle rates for the two cases .",
    "indeed  has almost the same performance as the oracle experimentally .",
    "overall figure  [ fig : plot2 ] illustrates the good behavior of  in this random scenario .        to conclude our numerical experiments , we consider the @xmath13 lower triangular matrix @xmath78 defined by @xmath289 . for this matrix ,",
    "it is easy to check that @xmath290 and @xmath291 .",
    "we plot in figure  [ fig : plot3 ] the estimation errors of @xmath254 , @xmath292 and @xmath293 given by , in addition to the oracle . by theorem  [ thm :",
    "monotone ] , the rate of estimation achieved by @xmath254 is of order @xmath285 , while that achieved by the oracle is of order @xmath294 since there is no permutation term .",
    "the plot confirms this discrepancy .",
    "moreover , @xmath295 is an appropriate measure of the performance of @xmath93 by lemma  [ lem : approx - est ] and [ lem : rearrange ] , and the plot suggests that the rates of estimation achieved by @xmath292 and @xmath296 are about the same order .",
    "finally @xmath293 seems to have a slightly faster rate of estimation than @xmath254 , so in practice @xmath293 could be used to estimate @xmath0 .",
    "however we refrain from making an explicit conjecture about the rate .",
    "while computational aspects of the seriation problem have received significant attention , the robustness of this problem to noise was still unknown to date . to overcome this limitation ,",
    "we have introduced in this paper the statistical seriation model and studied optimal rates of estimation by showing , in particular , that the least squares estimator enjoys several desirable statistical properties such as adaptivity and minimax optimality ( up to logarithmic terms ) .",
    "while this work paints a fairly complete statistical picture of the statistical seriation model , it also leaves many unanswered questions .",
    "there are several logarithmic gaps in the bounds . in the case of adaptive bounds ,",
    "some logarithmic terms are unavoidable as illustrated by theorem  [ thm : lower - adaptive ] ( for the permutation term ) and also by statistical dimension consideration explained in @xcite ( for the estimation term ) . however , a more refined argument for the uniform bound , namely one that uses covering in @xmath297-norm rather than @xmath298-norm , would allow us to remove the @xmath148 factor from the estimation term in the upper bound of corollary  [ cor : global ] .",
    "such an argument can be found in  @xcite for the larger class of vectors with bounded total variation ( see  @xcite ) but we do not pursue sharp logarithmic terms in this work . for the permutation term , @xmath148 in the upper bound of corollary  [ cor :",
    "adaptive ] and @xmath207 in the lower bound of theorem  [ thm : lower - adaptive ] do not match if @xmath299 .",
    "we do not seek answers to these questions in this paper but note that their answers may be different for the unimodal and the monotone case .",
    "perhaps the most pressing question is that of computationally efficient estimators . indeed , while statistically optimal , the least squares estimator requires searching through @xmath222 permutations , which is not realistic even for problems of moderate size , let alone genomics applications .",
    "we gave a partial answer to this question in the specific context of monotone columns by proposing and studying the performance of a simple and efficient estimator called .",
    "this study reveals the existence of a potentially intrinsic gap between the statistical performance achievable by efficient estimators and that achievable by estimators with access to unbounded computation .",
    "a similar gap is also observed in the sst model for pairwise comparisons  @xcite .",
    "we conjecture that achieving optimal rates of estimation in the seriation model is computationally hard in general but argue that the planted clique assumption that has been successfully used to establish statistical vs. computational gaps in  @xcite for example , is not the correct primitive .",
    "instead , one has to seek for a primitive where hardness comes from searching through permutations rather than subsets .",
    "p.r . is partially supported by nsf grant dms-1317308 and nsf career award dms-1053987 .",
    "n.f . gratefully acknowledges partial support by nsf grant dms-1317308 , the institute for data systems and society and the mathematics department during his visit at mit .",
    "c.m . acknowledges partial support by nsf career award dms-1053987 . p.r .",
    "also thanks enno mammen for his help in retracing the literature on sharp entropy bounds for monotone classes and ramon van handel for a stimulating discussion on entropy numbers .",
    "the authors thank alexandre tsybakov for bringing concurrent work on unimodal regression by pierre c. bellec to their attention .",
    "finally , the authors thank pierre c. bellec for pointing out an error in an earlier version of lemma  a.1 and suggesting that it holds for all closed sets .",
    "before proving the main theorems , we discuss two methods adopted in recent works to bound the error of the ls estimator in shape constrained regression , in a general setting .",
    "consider the least squares estimator @xmath300 of the model @xmath301 , where @xmath102 lies in a parameter space @xmath302 and @xmath303 is gaussian noise .",
    "one way to study @xmath304 is to use the _ statistical dimension _",
    "@xcite of a convex cone @xmath302 defined by @xmath305 \\,.\\ ] ] this has been successfully applied to isotonic and more general shape constrained regression @xcite .",
    "another prominent approach is to express the error of the ls estimator via what is known as _",
    "chatterjee s variational formula _",
    ", proved in  @xcite and given by @xmath306 note that the first term is related to the _ gaussian width _ ( see , e.g. , @xcite ) of @xmath302 defined by @xmath307,$ ] whose connection to the statistical dimension was studied in @xcite .",
    "the variational formula was first proposed for convex regression @xcite , and later exploited in several different settings , including matrix estimation with shape constraints @xcite and unimodal regression @xcite .",
    "similar ideas have appeared in other works , for example , analysis of empirical risk minimization @xcite , ranking from pairwise comparison @xcite and isotonic regression @xcite . in this latter work",
    ", bellec has used the statistical dimension approach to prove spectacularly sharp oracle inequalities that seem to be currently out of reach for methods based on chatterjee s variational formula  . on the other hand ,",
    "chatterjee s variational formula seems more flexible as computations of the statistical dimension based on @xcite are currently limited to convex sets @xmath302 with a polyhedral structure . in this paper , we use exclusively chatterjee s variational formula .",
    "we begin the proof by stating an extension of chatterjee s variational formula . while we only need this lemma to hold for a union of closed convex sets we present a version that holds for all closed sets .",
    "the latter extension was suggested to us by pierre c. bellec in a private communication  @xcite .",
    "[ lem : variational ] let @xmath308 be a closed subset of @xmath309 .",
    "suppose that @xmath310 where @xmath311 and @xmath312 .",
    "let @xmath313 be a projection of @xmath314 onto @xmath315 .",
    "define the function @xmath316 by @xmath317 then we have @xmath318 moreover , if there exists @xmath319 such that @xmath320 for all @xmath321 , then @xmath322    by definition , @xmath323 together with the definition of @xmath324 , this implies that @xmath325 therefore follows .    furthermore , suppose that there is @xmath319 such that @xmath320 for all @xmath321 .",
    "since @xmath326 , we have @xmath327 .",
    "note that this structural result holds for any error vector @xmath328 and any closed set @xmath315 which is not necessarily convex .",
    "in particular , this extends the results in @xcite and @xcite which hold for convex sets and finite unions of convex sets respectively .      for our purpose , we need a standard chaining bound on the supremum of a sub - gaussian process that holds in high probability",
    ". the interested readers can find the proof , for example , in ( * ? ? ?",
    "* theorem  5.29 ) , and refer to @xcite for a more detailed account of the technique .",
    "[ lem : chaining - tail ] let @xmath329 and @xmath330 in @xmath309 .",
    "for any @xmath331 , it holds that @xmath332 with probability at least @xmath333 where @xmath28 and @xmath29 are positive constants .",
    "let @xmath334 . to ligthen the notation",
    ", we define two rates of estimation : @xmath335 and @xmath336 note that @xmath337 .",
    "[ lem : f - bound ] suppose @xmath338 where @xmath339 and @xmath340 . for @xmath334 and all @xmath341 , define @xmath342 then for any @xmath343 , it holds simultaneously for all @xmath341 that @xmath344 with probability at least @xmath345 , where @xmath28 and @xmath29 are positive constants .",
    "define @xmath346 ( see also definition  ) .",
    "in particular , @xmath347 and @xmath348 . since @xmath76 is a finite union of convex cones and",
    "thus is star - shaped , by scaling invariance , @xmath349 by lemma  [ lem : chaining - tail ] , with probability at least @xmath345 , @xmath350 moreover , it follows from lemma  [ lem : cover - matrix - union ] that @xmath351 combining the previous three displays , we see that @xmath352 with probability at least @xmath345 .",
    "therefore @xmath353 with probability at least @xmath345 simultaneously for all @xmath341 .",
    "we are now in a position to prove the adaptive oracle inequalities in theorem  [ thm : adaptive ] .",
    "recall that @xmath170 denotes the ls estimator defined in . without loss of generality , assume that @xmath354 and @xmath338 .",
    "fix @xmath334 and define @xmath355 as in lemma  [ lem : f - bound ] .",
    "we can apply lemma  [ lem : variational ] with @xmath356 , @xmath357 , @xmath358 and @xmath359 to achieve an error bound on @xmath360 since @xmath361 . to be more precise , for any @xmath343 we define @xmath362 where @xmath363 is the constant in .",
    "then it follows from lemma  [ lem : f - bound ] that with probability at least @xmath364 , it holds for all @xmath365 that @xmath366 therefore by lemma  [ lem : variational ] , @xmath367 and thus @xmath368 with probability at least @xmath369    in particular , if @xmath370 , then @xmath371 as @xmath372 .",
    "we see that with probability at least @xmath373 , @xmath374 and thus @xmath375 finally , follows by taking the infimum over @xmath334 on the right - hand side and dividing both sides by @xmath376 .    next , to prove the bound in expectation , observe that yields @xmath377 \\le c \\exp(- \\frac{c s}{\\sigma^2}),\\ ] ] where @xmath378 is defined in . integrating the tail probability",
    ", we get that @xmath379 and therefore @xmath380 dividing both sides by @xmath376 and minimizing over @xmath334 yields .      in the setting of isotonic regression , @xcite derived global bounds from adaptive bounds by a block approximation method , which also applies to our setting . for @xmath139 $ ] ,",
    "let @xmath381 define @xmath382 .",
    "the lemma below is very similar to ( * ? ? ?",
    "* lemma  2 ) and their proof also extends to the unimodal case with minor modifications .",
    "we present the result with proof for completeness .",
    "[ lem : vector - approximation ] for @xmath383 and @xmath139 $ ] , there exists @xmath384 such that @xmath385 in particular , there exists @xmath386 such that @xmath387 moreover , @xmath388    let @xmath389 , @xmath390 } a_i$ ] and @xmath391 } a_i$ ] . for @xmath392",
    "$ ] , consider the intervals @xmath393 , \\ ] ] and @xmath394 $ ] . also for @xmath395 $ ] , let @xmath396 : a_i\\in i_j\\}$ ] .",
    "we define the vector @xmath397 by @xmath398 for @xmath249 $ ] , where @xmath8 is uniquely determined by @xmath399 . since @xmath26 is increasing on @xmath400 and decreasing @xmath401 ,",
    "so is @xmath402 .",
    "thus @xmath403 .",
    "moreover , @xmath404 for @xmath405 $ ] , which implies .",
    "next we prove the latter two assertions .",
    "since @xmath406 , if @xmath386 and @xmath407 then @xmath408 and @xmath409 on the other hand , if @xmath410 , then @xmath411 and @xmath412    it is straightforward to generalize the lemma to matrices . for @xmath413^m$ ] , we write @xmath414 and let @xmath415 then @xmath416 for @xmath417 . define @xmath418 by @xmath419    [ lem : block - approximation ] for @xmath163 , there exists @xmath420 such that @xmath421 and @xmath422    applying lemma  [ lem : vector - approximation ] to columns of @xmath0 , we see that there exists @xmath420 such that @xmath423 and @xmath424 summing over @xmath425 , we get that @xmath426 and similarly @xmath427    for @xmath163 , choose @xmath420 according to lemma  [ lem : block - approximation ]",
    ". then @xmath428 by noting that @xmath429 for @xmath60 , and similarly @xmath430 plugging and into the right - hand side of and , and then minimizing over @xmath163 , we complete the proof .",
    "in this section , we study various _ covering numbers _ or _ metric entropy _ related to the parameter space of the model . first recall some standard definitions that date back at least to @xcite .",
    "an @xmath431-net of a subset @xmath432 with respect to a norm @xmath433 is a set @xmath434 such that for any @xmath435 , there exists @xmath436 $ ] for which @xmath437 .",
    "the covering number @xmath438 is the cardinality of the smallest @xmath431-net with respect to the norm @xmath433 .",
    "metric entropy is defined as the logarithm of a covering number . in the following",
    ", we will consider the euclidean norm unless otherwise specified .",
    "lemma  [ lem : cover - product ] below bounds covering numbers of product spaces and is useful in later proofs .",
    "we start with a well - known result on the covering number of a euclidean ball with respect to the @xmath298-norm ( see e.g. ( * ? ? ?",
    "* lemma  7.14 ) for an analogous result ) .",
    "[ lem : cube - cover - ball ] for any @xmath439 $ ] , @xmath440 for some constant @xmath33 .",
    "we aim at bounding the covering number of a euclidean ball by cubes .",
    "let @xmath441 be a maximal @xmath442-packing of @xmath443 with respect to the @xmath298-norm , where a @xmath444-packing of a set @xmath445 with respect to a norm @xmath433 is a set @xmath446 such that @xmath447 for all distinct @xmath448 $ ] .",
    "then this set is necessarily an @xmath442-net of @xmath443 by maximality , so @xmath449 .",
    "consider the cubes with side length @xmath442 centered at @xmath450 for @xmath451 .",
    "these cubes are disjoint and contained in the set @xmath452 , where @xmath453 is the cube with side length @xmath442 centered at the origin in @xmath454 . since @xmath455 , @xmath456 this proves the following bound on the covering number in terms of a volume ratio : @xmath457    now we study the metric entropy of a cartesian product of convex cones .",
    "let @xmath458 be a partition of @xmath20 $ ] with @xmath459 and @xmath460 . for @xmath181 , the restriction of @xmath26 to the coordinates in @xmath461",
    "is denoted by @xmath462 .",
    "let @xmath463 be a convex cone in @xmath464 and @xmath465 .",
    "[ lem : cover - product ] with the notation above , suppose that @xmath466 .",
    "then for any @xmath467 and @xmath468 $ ] , @xmath469 for some constant @xmath33 .    since a product of balls",
    "@xmath470 is contained in @xmath471 , one could try to cover @xmath472 by such products of balls .",
    "it turns out that this yields an upper bound of order @xmath473 , which is too loose for our purpose .",
    "fortunately , the following argument corrects this dependency .    without loss of generality , we assume that @xmath474 .",
    "we construct a @xmath475-net of @xmath476 as follows .",
    "first , let @xmath477 be an @xmath478-net of @xmath443 with respect to the @xmath298-norm .",
    "define @xmath479}\\mu_i \\ge - \\frac{1}{2 \\sqrt m } \\big\\}.\\ ] ] note that @xmath480 for @xmath481 , and let @xmath482 be a @xmath483-net of @xmath484 .",
    "define @xmath485 , i.e. , @xmath486 we claim that @xmath487 is an @xmath488-net of @xmath476 .",
    "fix @xmath489 .",
    "let @xmath490 be the restriction of @xmath491 to the component space @xmath464 .",
    "then @xmath492 . let @xmath493 be defined by @xmath494 , so @xmath495 .",
    "hence we can find @xmath496 such that @xmath497 .",
    "in particular , for all @xmath498 $ ] , @xmath499 , so @xmath481 .",
    "moreover , @xmath500 and @xmath492 , so by definition of @xmath482 , there exists @xmath501 such that @xmath502 .",
    "let @xmath503 .",
    "since @xmath504 we conclude that @xmath505 therefore @xmath487 is a @xmath475-net of @xmath476 .",
    "it remains to bound the cardinality of this net . by lemma  [ lem : cube - cover - ball ] , @xmath506 moreover , recall that @xmath482 is a @xmath483-net of @xmath484 .",
    "since @xmath466 , for any @xmath467 , @xmath507 hence we can choose the net so that @xmath508 as @xmath509 , therefore @xmath510 taking the logarithm completes the proof .",
    "recall that @xmath42 denotes the closed convex cone of increasing vectors in @xmath27 .",
    "first , we prove a result on the metric entropy of @xmath42 intersecting with a ball using lemma  [ lem : cover - product ] .",
    "[ lem : cover - vector - centered ] let @xmath511 be such that @xmath512 . then for any @xmath341 and @xmath513 , @xmath514    the majority of the proof is due to lemma  5.1 in an old version of @xcite , but we improve their result by a factor @xmath515 and provide the whole proof for completeness .",
    "the bound holds trivially if @xmath516 , since the left - hand side is zero .",
    "it also clearly holds when @xmath517 .",
    "hence we can assume without loss of generality that @xmath518 and @xmath519 .",
    "moreover , assume that @xmath520 for simplicity and the proof will work for any @xmath341 .",
    "let @xmath521 and observe that @xmath522 let @xmath157 be the smallest integer for which @xmath523 .",
    "we partition @xmath524 into @xmath157 blocks @xmath525 for @xmath526 $ ] and let @xmath527 . since @xmath528 , lemma  [ lem : cover - product ] yields that @xmath529    we know from ( * ? ? ?",
    "* lemma 4.20 ) that for any @xmath530 and @xmath531 , @xmath532^n \\cap \\mathcal b^{n}(b,1 ) , \\|\\cdot\\|_2 , { \\varepsilon}\\big)\\leq \\frac{c\\sqrt{n}(d - c)}{\\varepsilon } \\,.\\ ] ] for each @xmath533 , it holds that @xmath534 for @xmath535 ( since either @xmath536 for all @xmath537 or @xmath536 for all @xmath538 ; see e.g. @xcite ) , so @xmath539 .",
    "also @xmath540 , so we get that @xmath541 for all @xmath526 $ ] . substituting this bound into and noting that @xmath542",
    ", we reach the conclusion @xmath543    next , we study the metric entropy of the set of matrices with unimodal columns . recall that @xmath44 for @xmath544 $ ] . for @xmath49^m$ ] , define @xmath545",
    ". moreover , for @xmath546 , @xmath467 and @xmath547 , define @xmath548 note that in particular @xmath549 .",
    "[ lem : cover - matrix - uni ] given @xmath184 and @xmath49^m$ ] , define @xmath550 and @xmath551 then for any @xmath341 and @xmath513 , @xmath552    assume that @xmath518 since otherwise the left - hand side is zero and the bound holds trivially",
    ". for @xmath162 $ ] , define @xmath553 $ ] and @xmath554 \\setminus [ l_j]$ ] .",
    "define @xmath555 and @xmath556 .",
    "let @xmath557 and observe that @xmath558 moreover , let @xmath559 be the partition of @xmath560 such that @xmath561 is a constant vector for @xmath562 $ ] .",
    "note that elements of @xmath563 need not to be consecutive .",
    "define the partition for @xmath564 analogously .    for @xmath162 $ ] and @xmath562 $ ] ( resp .",
    "$ ] ) , let @xmath566 ( resp .",
    "@xmath567 ) denote the set of increasing ( resp .",
    "decreasing ) vectors in the component space @xmath568 ( resp .",
    "@xmath569 ) . lemma  [ lem : cover - vector - centered ] implies that @xmath570 as a matrix in @xmath571 can be viewed as a concatenation of @xmath572 vectors of length @xmath573 , j \\in [ m]$ ] , we define the cone @xmath574 in @xmath575 by @xmath576 , which is clearly a superset of @xmath577 .",
    "it also follows that @xmath578 , and thus by lemma  [ lem : cover - product ] and the previous display , @xmath579 where we used the concavity of the logarithm and jensen s inequality in the second step , and that @xmath580 in the last step .",
    "since @xmath578 ( the cone @xmath581 is pointed at @xmath0 ) we have that @xmath582 for any @xmath583 . in view of definition , it holds @xmath584 in particular , taking @xmath585 , we get @xmath586 .",
    "moreover , @xmath587 , so that @xmath588 . thus the metric entropy of @xmath589 is subject to the above bound as well .    finally , we consider the metric entropy of @xmath590 for @xmath546 , @xmath467 and @xmath54 .",
    "the above analysis culminates in the following lemma which we use to prove the main upper bounds .",
    "[ lem : cover - matrix - union ] let @xmath546 and @xmath224 be defined as in the previous lemma .",
    "then for any @xmath513 and @xmath467 , @xmath591    assume that @xmath518 since otherwise the left - hand side is zero and the bound holds trivially .",
    "note that @xmath592^m }   \\mathcal c_\\mathbf l^m$ ] , and that @xmath54 . thus @xmath76 is the union of @xmath593 cones of the form @xmath594 . by definition , @xmath595 is also the union of @xmath593 sets @xmath596 , each having metric entropy subject to the bound in lemma  [ lem : cover - matrix - uni ] .",
    "therefore , a union bound implies that @xmath597 where the last step follows from that @xmath598 for @xmath599 and that @xmath518 .",
    "for minimax lower bounds , we consider the model @xmath169 where entries of @xmath14 are i.i.d .",
    "@xmath190 . the varshamov - gilbert lemma ( * ? ? ?",
    "* lemma  4.7 ) is a standard tool for proving lower bounds .",
    "[ lem : vg ] let @xmath444 denote the hamming distance on @xmath600 where @xmath601 . then there exists a subset @xmath602 such that @xmath603 and @xmath604 for distinct @xmath605 .",
    "we also need the following useful lemma .",
    "[ lem : lower - general ] consider the model @xmath606 where @xmath607 and @xmath608 .",
    "suppose that @xmath609 and for distinct @xmath610 , @xmath611 where @xmath612 .",
    "then there exists @xmath260 such that @xmath613 \\ge c.\\ ] ]    let @xmath614 denote the probability with respect to @xmath615 . then the kullback - leibler divergence between @xmath616 and @xmath617 satisfies that @xmath618 since @xmath609 . applying ( * ? ? ?",
    "* theorem  2.5 ) with @xmath619 gives the conclusion .",
    "we define @xmath620 and @xmath621 .",
    "define the subset of @xmath622 containing permutations of monotonic matrices by @xmath623 .",
    "since each estimator pair @xmath170 gives an estimator @xmath97 of @xmath624 , it suffices to prove a lower bound on @xmath625 . in fact , we prove a stronger lower bound than the one in theorem  [ thm : lower - adaptive ] .",
    "[ prop : lower - stronger ] suppose that @xmath626",
    ". then @xmath627 \\ge c'\\end{gathered}\\ ] ] for some @xmath628 , where @xmath629 is the probability with respect to @xmath630 .",
    "this bound remains valid for the parameter subset @xmath631 if @xmath632 or @xmath633 .",
    "note that the bound clearly holds for the larger parameter space @xmath634 . by taking @xmath635 and",
    "@xmath636 large enough , we see that the assumption in proposition  [ prop : lower - stronger ] is satisfied and the second term becomes simply @xmath637 , so theorem  [ thm : lower - adaptive ] follows . in the monotonic case , by the last statement of the proposition , if @xmath638 then taking @xmath639 and @xmath636 large enough yields a lower bound of rate @xmath640 for the set of matrices @xmath0 with increasing columns and @xmath641 .",
    "the proof of proposition  [ prop : lower - stronger ] has two parts which correspond to the two terms respectively .",
    "first , the term @xmath642 is derived from the proof of lower bounds for isotonic regression in @xcite .",
    "then we derive the other term @xmath643 for any @xmath644 , which is due to the unknown permutation .",
    "[ lem : lower - est ] suppose that @xmath626 .",
    "for some @xmath628 , @xmath645 \\ge c\\,,\\ ] ] where @xmath646 is the probability with respect to @xmath630 .",
    "we adapt the proof of ( * ? ? ?",
    "* theorem  4 ) to the case of matrices .",
    "let @xmath647 for all @xmath162 $ ] .",
    "since @xmath648,\\ ] ] we can choose @xmath649 $ ] so that @xmath650 and @xmath651 . according to lemma  [ lem : vg ] , there exists @xmath652 such that @xmath653 and @xmath654 for distinct @xmath605 .",
    "consider the partition @xmath655 = \\cup_{m=1}^j i_j$ ] with @xmath656 .",
    "for each @xmath657 , let @xmath658 be the restriction of @xmath659 to coordinates in @xmath660 .",
    "define @xmath661 by @xmath662 where @xmath663 .",
    "it is straightforward to check that @xmath664 , @xmath665 and @xmath666 is increasing , so @xmath667 is in the parameter space .",
    "moreover , for distinct @xmath605 , @xmath668 on the other hand , @xmath669 applying lemma  [ lem : lower - general ] completes the proof .    for the second term in",
    ", we first note that the bound is trivial for @xmath670 since @xmath671 . the next lemma deals with the case @xmath639 .",
    "[ lem : lower - monotone ] there exist constants @xmath628 such that for any @xmath638 and @xmath213 , @xmath672 \\ge c ' \\,,\\ ] ] where @xmath646 is the probability with respect to @xmath630 .    by lemma  [ lem : vg ]",
    ", there exists @xmath673 such that @xmath674 and @xmath675 for distinct @xmath605 . for each @xmath657 , define @xmath676 by setting the first column of @xmath677 to be @xmath678 and all other entries to be zero , where @xmath679 then    1 .",
    "@xmath680 since @xmath681 , @xmath682 and we can permutate the rows of @xmath677 so that its first column is increasing ; 2 .",
    "@xmath683 for distinct @xmath605 ; 3 .",
    "@xmath684 for @xmath605 .",
    "applying lemma  [ lem : lower - general ] completes the proof .    for the previous two lemmas , we have only used matrices with increasing columns",
    "however , to achieve the second term in for @xmath685 , we need matrices with unimodal columns .",
    "the following packing lemma is the key .",
    "[ lem : zero - one - packing ] for @xmath686 $ ] , consider the set @xmath687 of @xmath10 matrices of the form @xmath688 \\text { for each } i \\in [ n ] , \\\\ 0 & \\text{otherwise } . \\end{cases}\\ ] ] for @xmath689 , define @xmath690 .",
    "then there exists an @xmath691-packing @xmath692 of @xmath687 such that @xmath693 if @xmath694 and @xmath695 if @xmath696 .",
    "there are @xmath45 choices of entries to put the one in each row of @xmath667 , so @xmath697 .",
    "fix @xmath698 . if @xmath699 where @xmath700 , then @xmath667 differs from @xmath701 in at most @xmath157 rows . if @xmath696 , taking @xmath702 gives the result .",
    "if @xmath694 then @xmath703 moreover , let @xmath692 be a maximal @xmath704-packing of @xmath687 . then @xmath692 is also an @xmath691-net , so @xmath705 it follows that @xmath706 we conclude that @xmath693 .    for notational simplicity ,",
    "we now consider @xmath707 instead of @xmath708 .",
    "[ lem : lower - approx ] there exist constants @xmath628 such that for any @xmath200 , @xmath213 and @xmath707 , @xmath709 \\ge c ' \\,,\\ ] ] where @xmath646 is the probability with respect to @xmath630 .",
    "set @xmath710 and let @xmath692 be the @xmath711-packing given by lemma  [ lem : zero - one - packing ] . if @xmath712 , then @xmath713 .",
    "now assume that @xmath694 . since @xmath714 is decreasing on @xmath715 $ ] , we have that @xmath716 .",
    "hence for @xmath717 , @xmath718    moreover , for each @xmath719 , consider the rescaled matrix @xmath720    1 .",
    "we can permute the rows of @xmath701 so that each column has consecutive ones ( or all zeros ) , so @xmath721 . moreover , @xmath722 and @xmath723 so @xmath724 for @xmath719 .",
    "2 .   for @xmath725 , @xmath726 , so @xmath727 3 .   for @xmath725 , @xmath728 , so by , @xmath729    since @xmath730 for @xmath717 , applying lemma  [ lem : lower - general ] completes the proof .    combining lemma  [ lem : lower - est ] , [",
    "lem : lower - monotone ] and [ lem : lower - approx ] , and dividing the bound by @xmath376 , we get because the max of two terms is lower bounded by a half of their sum .",
    "the last statement in proposition  [ prop : lower - stronger ] holds since lemma  [ lem : lower - est ] and [ lem : lower - monotone ] are proved for matrices with increasing columns .",
    "the proof will only use lemma  [ lem : lower - est ] and [ lem : lower - monotone ] , so the lower bound of rate @xmath731 holds even if the matrices are required to have increasing columns .",
    "the last term @xmath732 is achieved by lemma  [ lem : lower - monotone ] , so we focus on the trade - off between the first two terms .",
    "suppose that @xmath733 , in which case the first term @xmath734 dominates the second term",
    ". then @xmath735 . setting @xmath736",
    "we see that @xmath737 .",
    "lemma  [ lem : lower - est ] can be applied with this choice of @xmath738 .",
    "then the term @xmath739 is lower bounded by @xmath740 .    on the other hand , if @xmath741 , then the second term @xmath742 dominates the first up to a constant . to deduce a lower bound of this rate",
    ", we apply lemma  [ lem : vg ] to get @xmath743 such that @xmath744 and @xmath745 for distinct @xmath605 . for each @xmath657 , define @xmath676 by setting every row of @xmath677 equal to @xmath746 . then    1",
    ".   @xmath747 since @xmath748 ; 2 .   @xmath749",
    "@xmath750 .",
    "hence lemma  [ lem : lower - general ] implies a lower bound on @xmath751 of rate @xmath752 .",
    "for the model @xmath169 where @xmath219 and @xmath340 , a computationally efficient estimator @xmath256 has been constructed in section  [ sec : rankscore ] using the  procedure",
    ". we will bound its rate of estimation in this section .",
    "recall that the definition of @xmath256 consists of two steps .",
    "first , we recover an order ( or a ranking ) of the rows of @xmath71 , which leads to an estimator @xmath93 of the permutation . then define @xmath253 so that @xmath254 is the projection of @xmath71 onto the convex cone @xmath255 . for the analysis of the algorithm",
    ", we deal with the projection step first , and then turn to learning the permutation .",
    "in fact , for _ any _ estimator @xmath93 , if @xmath293 is defined as above by the projection corresponding to @xmath93 , then the error @xmath753 can be split into two parts : the permutation error @xmath754 and the estimation error of order @xmath755 .",
    "the proof of the following oracle inequality is very similar to that of theorem  [ thm : adaptive ] , so we will sketch the proof without providing all the details .",
    "[ lem : approx - est ] consider the model @xmath169 where @xmath756 and @xmath70 .",
    "for any @xmath757 , define @xmath253 so that @xmath254 is the projection of @xmath71 onto @xmath255 .",
    "then with probability at least @xmath758 , @xmath759    assume without loss of generality that @xmath354 .",
    "let @xmath226 and define @xmath760 since @xmath761 with @xmath762 , by lemma  [ lem : cover - matrix - uni ] , @xmath763 using the proof of lemma  [ lem : f - bound ] , we see that @xmath764 with probability at least @xmath765",
    ". then the proof of theorem  [ thm : adaptive ] implies that with probability at least @xmath758 , @xmath766 minimizing over @xmath226 yields the desired result .    the idea of splitting the error into two terms as in lemma  [ lem : approx - est ] has appeared in @xcite .      by virtue of lemma  [ lem : approx - est ]",
    ", it remains to control the permutation error @xmath767 where @xmath93 is given by the  procedure defined in section  [ sec : rankscore ] .",
    "recall that for @xmath246 $ ] , @xmath247 } ( a^*_{i ' , j } - a^*_{i , j})\\vee \\frac 1{\\sqrt m } \\sum_{j=1}^m ( a^*_{i ' , j } - a^*_{i , j})\\ ] ] and @xmath248 is defined analogously .",
    "since columns of @xmath78 are increasing , @xmath768 recall that the  procedure is defined as follows .",
    "first , for @xmath249 $ ] , we associate with the @xmath9-th row of @xmath71 a score @xmath250 defined by @xmath769 for the threshold @xmath770 where @xmath444 is the probability of failure",
    ". then we order the rows of @xmath71 so that the scores are increasing with ties broken arbitrarily .",
    "this is equivalent to requiring that the corresponding permutation @xmath771 \\to [ n]$ ] satisfies that if @xmath772 then @xmath773 .",
    "define @xmath93 to be the @xmath13 permutation matrix corresponding to @xmath774 so that @xmath775 for @xmath249 $ ] and all other entries of @xmath93 are zero .",
    "moreover , let @xmath776 \\to [ n]$ ] be the permutation corresponding to @xmath77 .",
    "to control the permutation error , we first state a lemma which asserts that if the gap between two rows of @xmath78 is sufficiently large , then the permutation defined above will recover their relative order with high probability .    [",
    "lem : row - gap ] there is an event @xmath777 of probability at least @xmath778 on which the following holds . for any @xmath246",
    "$ ] , if @xmath779 , then @xmath780 .    since @xmath340 ,",
    "@xmath781 and @xmath782 are sub - gaussian random variables with variance proxy @xmath783 .",
    "a standard union bound yields that @xmath784 , j \\in [ m ] } |z_{i , j}| , \\max_{i \\in [ n ] } \\frac 1{\\sqrt m } \\big|\\sum_{j=1}^m   z_{i , j}\\big|\\big ) \\le \\tau = 3 \\sigma \\sqrt{\\log(nm \\delta^{-1})}\\ ] ] on an event @xmath777 of probability at least @xmath785 .",
    "in the sequel , we make statements that are valid on the event @xmath777 .",
    "since @xmath786 , by the triangle inequality , latexmath:[\\[\\label{eq : error - gap }    suppose that @xmath779 .",
    "we claim that @xmath788 .",
    "if for @xmath544 $ ] , @xmath789 , then @xmath790 by . since @xmath78 has increasing columns , @xmath791 .",
    "again by , @xmath792 . by definition , we see that @xmath793 . moreover , @xmath779 so @xmath794 . therefore @xmath788 . according to the construction of @xmath774 , @xmath780 .    next ,",
    "recall that for a matrix @xmath226 , @xmath227 denotes the set of pairs of indices @xmath228 ^ 2 $ ] such that @xmath22 and @xmath229 are not identical .",
    "the quantity @xmath230 is defined by @xmath795 ^ 2\\\\ |\\mathcal i| = n } } \\sum_{(i , j ) \\in \\mathcal i \\cap \\mathcal j } \\big ( \\frac{\\|a_{i,\\cdot } - a_{j,\\cdot}\\|_2 ^ 2}{\\|a_{i,\\cdot } - a_{j,\\cdot}\\|_\\infty^2}\\wedge \\frac{m \\|a_{i,\\cdot } - a_{j,\\cdot}\\|_2 ^ 2}{\\|a_{i,\\cdot } - a_{j,\\cdot}\\|_1 ^ 2 } \\big ) \\,.\\ ] ] for any nonzero vector @xmath236 , @xmath237 with equality achieved when @xmath238 , and @xmath796 with equality achieved when all entries of @xmath233 are the same .",
    "hence @xmath797 .",
    "moreover , @xmath798 by hlder s inequality , so @xmath799 as the product of the two terms is no larger than @xmath41 .",
    "the equality is achieved by @xmath800 where the first @xmath244 entries are equal to one .",
    "therefore , @xmath801 \\,.\\ ] ] intuitively , the quantity @xmath230 is small if the difference of any two rows of @xmath0 is either very sparse or very dense .",
    "[ lem : approx - error ] there is an event @xmath777 of probability at least @xmath778 on which @xmath802    throughout the proof , we restrict ourselves to the event @xmath777 defined in lemma  [ lem : row - gap ] . to simplify the notation , we define @xmath803 . then @xmath804 where @xmath524 is the set of indices @xmath9 for which @xmath805 is nonzero . for each @xmath806 ,",
    "@xmath807 by .",
    "next , we proceed to showing that @xmath808 for any @xmath249 $ ] , where @xmath809 . to that end , note that if @xmath810 , in which case @xmath811 for all @xmath812\\,:\\ , i'\\ge \\nu(i)\\}$ ] , then it follows from lemma  [ lem : row - gap ] that on @xmath813 , @xmath814 .",
    "note that @xmath815 .",
    "hence @xmath814 implies that @xmath816 , which is a contradiction .",
    "therefore , there does not exist such @xmath249 $ ] on @xmath813 .",
    "the case where @xmath817 is treated in a symmetric manner .",
    "combining this bound with and , we conclude that @xmath818 by the definitions of @xmath261 and @xmath94 .",
    "the bound is an immediate consequence of lemma  [ lem : approx - est ] and lemma  [ lem : approx - error ] with @xmath819 for @xmath820 .",
    "in theorem  [ thm : lower - global ] , we have observed the term @xmath821 , whereas the ls estimator only has @xmath822 in the upper bounds .",
    "the next proposition shows that in the case @xmath823 , we can simply use an averaging estimator that achieves the term @xmath824 .",
    "[ prop : special - regime ] for @xmath169 where @xmath340 , let @xmath825 and @xmath17 be defined by @xmath826 for all @xmath228\\times [ m]$ ] .",
    "then , @xmath827 with probability at least @xmath828 and @xmath829    recall that @xmath830 .",
    "since the @xmath297-norm of a vector is no larger than the @xmath831-norm , @xmath832 on the other hand , @xmath833 so we have that @xmath834 , j \\in [ m ] } \\big(\\frac 1n \\sum_{k=1}^n a^*_{k , j } + \\frac 1n \\sum_{k=1}^n z_{k , j } - a^*_{i , j } \\big)^2 \\\\ & \\le 2 \\sum_{i \\in [ n ] , j \\in [ m ] } \\big(\\frac 1n \\sum_{k=1}^n a^*_{k , j } - a^*_{i , j } \\big)^2 + \\frac 2{n^2 } \\sum_{i \\in [ n ] , j \\in [ m ] } \\big(\\sum_{k=1}^n z_{k , j } \\big)^2 \\\\ & \\le 2 n \\sum_{j \\in [ m ] } v_j(a)^2 + \\frac 2n \\sum_{j \\in [ m ] } \\big(\\sum_{k=1}^n z_{k , j } \\big)^2 \\\\ & \\le 2 n m^3 v(a)^2 + 2 \\sum_{j \\in [ m ] } g_j^2 \\ , , \\end{aligned}\\ ] ] where @xmath835 for @xmath162 $ ] so that @xmath836 are centered sub - gaussian variables with variance proxy @xmath783 .",
    "it is well - known that @xmath837 , so @xmath838 moreover , since @xmath839 is a sub - gaussian vector with variance proxy @xmath783 , it follows from ( * ? ? ?",
    "* theorem  2.1 ) that @xmath840 with probability at least @xmath828 . on this event , @xmath841 dividing the previous two displays by @xmath376 completes the proof .",
    "if the permutation in the main model is known , then the estimation problem simply becomes a concatenation of @xmath41 unimodal regressions .",
    "in fact , our proofs imply new oracle inequalities for unimodal regression . recall that @xmath46 denotes the cone of unimodal vectors in @xmath27 .",
    "suppose that we observe @xmath842 where @xmath843 and @xmath303 is a sub - gaussian vector with variance proxy @xmath783 .",
    "define the ls estimator @xmath300 by @xmath844 moreover let @xmath845 and @xmath846 } \\theta_i - \\min_{i \\in [ n ] } \\theta_i$ ] .",
    "[ cor : unimodal ] there exists a constant @xmath260 such that with probability at least @xmath847 , @xmath848 , @xmath849 and @xmath850   + \\alpha \\sigma^2 \\frac{\\log n}{n } \\,.\\ ] ] the corresponding bounds in expectation also hold .",
    "first note that the term @xmath851 in the bound of lemma  [ lem : cover - matrix - union ] comes from a union bound applied to the set of permutations , so it is not present if we consider only the set of unimodal matrices @xmath48 instead of @xmath76 .",
    "hence taking @xmath852 in the lemma yields that @xmath853    for @xmath854 , define @xmath855 following the proof of lemma  [ lem : f - bound ] and using the above metric entropy bound , we see that @xmath856 with probability at least @xmath765 .",
    "then the proof of theorem  [ thm : adaptive ] gives that with probability at least @xmath765 ,",
    "@xmath857 taking @xmath858 for @xmath848 and @xmath28 sufficiently large , we get that with probability at least @xmath847 , @xmath859 minimizing over @xmath854 yields .",
    "the corresponding bound in expectation follows from integrating the tail probability as in the proof of theorem  [ thm : adaptive ] .",
    "note that the bounds in corollary  [ cor : unimodal ] match the minimax lower bounds for isotonic regression in @xcite up to logarithmic factors .",
    "since every monotonic vector is unimodal , lower bounds for isotonic regression automatically hold for unimodal regression .",
    "therefore , we have proved that the ls estimator is minimax optimal up to logarithmic factors for unimodal regression .    a result similar",
    "to   was obtained by bellec in the revision of  @xcite that was prepared independently and contemporaneously to this paper .",
    "chatterjee and lafferty also improved their bounds to having optimal exponents @xcite after the first version of our current paper was posted .",
    "interestingly bellec employs bounds on the statistical dimension by leveraging results from  @xcite , and chatterjee and lafferty use both the variational formula and the statistical dimension .",
    "moreover , their results are presented in the well - specified case where @xmath860 and @xmath861 .",
    "n.  n. anuchina , k.  i. babenko , s.  k. godunov , n.  a. dmitriev , l.  v. dmitrieva , v.  f. dyachenko , a.  v. zabrodin , o.  v. lokutsievski , e.  v. malinovskaya , i.  f. podlivaev , g.  p. prokopov , i.  d. sofronov , and r.  p. fedorenko . .",
    "`` nauka '' , moscow , 1979 .",
    "quentin berthet and philippe rigollet .",
    "complexity theoretic lower bounds for sparse principal component detection . in shai",
    "shalev - shwartz and ingo steinwart , editors , _ colt 2013 - the 26th conference on learning theory , princeton , nj , june 12 - 14 , 2013 _ , volume  30 of _ jmlr w&cp _ ,",
    "pages 10461066 , 2013 .",
    "constantinos daskalakis , ilias diakonikolas , and rocco  a. servedio .",
    "learning k - modal distributions via testing . in _ proceedings of the twenty - third annual acm - siam symposium on discrete algorithms",
    "_ , soda 12 , pages 13711385 , philadelphia , pa , usa , 2012 .",
    "society for industrial and applied mathematics .",
    "constantinos daskalakis , ilias diakonikolas , rocco  a. servedio , gregory valiant , and paul valiant . testing k - modal distributions : optimal algorithms via reductions . in _ proceedings of the twenty - fourth annual acm - siam symposium on discrete algorithms",
    "_ , soda 13 , pages 18331852 , philadelphia , pa , usa , 2013 . society for industrial and applied mathematics .",
    "fajwel fogel , rodolphe jenatton , francis bach , and alexandre daspremont .",
    "convex relaxations for permutation problems . in c.j.c .",
    "burges , l.  bottou , m.  welling , z.  ghahramani , and k.q .",
    "weinberger , editors , _ advances in neural information processing systems 26 _ , pages 10161024 .",
    "curran associates , inc . , 2013 .",
    "thomas  l. gertzen and martin grtschel .",
    "flinders petrie , the travelling salesman problem , and the beginning of mathematical modeling in archaeology . ,",
    "x(extra volume : optimization stories):199210 , 2012 .",
    "michel ledoux and michel talagrand . ,",
    "volume  23 of _ ergebnisse der mathematik und ihrer grenzgebiete ( 3 ) [ results in mathematics and related areas ( 3)]_. springer - verlag , berlin , 1991 .",
    "isoperimetry and processes .",
    "cong  han lim and stephen wright . beyond the birkhoff polytope : convex relaxations for vector permutation problems . in z.",
    "ghahramani , m.  welling , c.  cortes , n.d .",
    "lawrence , and k.q .",
    "weinberger , editors , _ advances in neural information processing systems 27 _ , pages 21682176 .",
    "curran associates , inc . , 2014 ."
  ],
  "abstract_text": [
    "<S> given a matrix , the seriation problem consists in permuting its rows in such way that all its columns have the same shape , for example , they are monotone increasing . </S>",
    "<S> we propose a statistical approach to this problem where the matrix of interest is observed with noise and study the corresponding minimax rate of estimation of the matrices . </S>",
    "<S> specifically , when the columns are either unimodal or monotone , we show that the least squares estimator is optimal up to logarithmic factors and adapts to matrices with a certain natural structure . </S>",
    "<S> finally , we propose a computationally efficient estimator in the monotonic case and study its performance both theoretically and experimentally . </S>",
    "<S> our work is at the intersection of shape constrained estimation and recent work that involves permutation learning , such as graph denoising and ranking .    </S>",
    "<S> ,    statistical seriation , permutation learning , minimax estimation , adaptation , shape constraints , matrix estimation . </S>"
  ]
}