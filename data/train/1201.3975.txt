{
  "article_text": [
    "understanding the collective behaviour of quantum many - body systems remains a central topic in modern physics , as well as one of the greatest computational challenges in science .",
    "quantum monte carlo sampling techniques are capable of addressing a large class of ( unfrustrated ) bosonic and spin lattice models , but fail when applied to other models such as frustrated antiferromagnets and interacting fermions due to the so - called sign problem .",
    "variational approaches , on the other hand , are sign - problem free but are typically strongly biased towards specific many - body wavefunctions .",
    "an important exception is given by the density matrix renormalization group,@xcite a variational approach based on the matrix product state ( mps),@xcite which is capable of providing an extremely accurate approximation to the ground state of most one - dimensional lattice models .",
    "the success of dmrg is based on the fact that an mps can reproduce the structure of entanglement common to most ground states of one - dimensional lattice models .    in order to extend the success of dmrg to other contexts ,",
    "new tensor networks generalizing the mps have been proposed .",
    "for instance , the multi - scale entanglement renormalization ansatz ( mera),@xcite with a network of tensors that extends in an additional direction corresponding to length scales , is particularly suited to address quantum critical systems .",
    "most significant has also been the proposal of tensor networks for systems in two and higher dimensions , where the mps becomes inefficient .",
    "scalable tensor networks include the projected entangled - pair states peps@xcite ( a direct generalization of the mps to larger dimensions ) and higher dimensional versions of the mera.@xcite they can be used to address frustrated antiferromagnets and interacting fermions , since they are free of the sign problem experienced by quantum monte carlo approaches .    in a tensor network state , the size of the tensors is measured by the bond dimension @xmath2 .",
    "this bond dimension @xmath2 indicates how many variational coefficients are used .",
    "crucially , it also regulates both the cost of the simulation , which scales as @xmath3 for some large power @xmath4 , and how much ground state entanglement the many - body ansatz can reproduce . in the large @xmath2 regime , peps and mera",
    "are essentially unbiased methods , but with a huge computational cost that is often unaffordable .",
    "more affordable simulations are obtained in the small @xmath2 regime , but there these methods are biased in favour of weakly entangled phases ( e.g. symmetry - breaking phases ) and against strongly entangled phases ( e.g. spin liquids and systems with a fermi surface ) . identifying more efficient strategies for tensor network contraction ,",
    "so that larger values of the bond dimension @xmath2 can be used and the bias towards weakly entangled states is suppressed , is therefore a priority in this research area",
    ".    refs .  , proposed the use of monte carlo sampling as a means to decrease computational costs in tensor network algorithms .",
    "[ we note that there are other variational anstze , such as so - called correlated product states , entangled plaquette states , and string - bond states , whose contractibility relies on sampling ; see the introduction of ref . for a review ] . in a tensor network approach such as mps , mera or peps ,",
    "sampling over specific configurations of the lattice allows to reduce the cost of contractions ( for single samples ) from @xmath3 to @xmath5 , where @xmath6 is significantly smaller than @xmath4 , typically of the order of @xmath7 .",
    "needless to say , sampling introduces statistical errors .",
    "however , if less than @xmath8 samples are required in order to achieved some pre - established accuracy , then overall sampling results in a reduction of computational costs .    the proposal of refs .  ,",
    "is based on computing the overlap of the tensor network state with a product state ( representing the sampled configuration ) .",
    "as such , it can not be directly applied to the mera , because the overlap of a mera with a product state can not be computed efficiently .",
    "luckily , as discussed in ref .  , a sampling strategy specific to unitary tensor networks ( such as mera and unitary versions of mps and tree tensor networks ) is not only possible , but it actually has several advantages .",
    "most notably , sampling takes place over configurations of a reduced , effective lattice ; and it is possible to perform perfect sampling , by means of which uncorrelated configurations are drawn directly according to the correct probability .     of a translation invariant lattice",
    "@xmath9 made of @xmath10 sites and with periodic boundary conditions .",
    "the tensors on each layer are identical and their labels are displayed to the left .",
    "the @xmath11 tensors ( green rectangles ) are unitary operators ( acting top - to - bottom ) , @xmath12 ( cyan triangles ) are isometric , and @xmath13 ( red circle ) is a normalized ` wavefunction ' .",
    "[ fig_mera],width=245 ]    the main goals of this paper are to propose a variational monte carlo scheme for the mera and to demonstrate its feasibility .",
    "we also discuss possible future applications .",
    "let us briefly list some of the highlights of the approach .",
    "( i ) in a lattice of size @xmath0 , the sampled configurations correspond to an effective lattice of size @xmath14 ; in this way , the cost of evaluating the expectation value of a local observable scales just as @xmath15 and not as @xmath16 as in refs .  , . ( ii )",
    "we employ the perfect sampling strategy of ref .  , thus avoiding the loses of efficiency in the markov chain monte carlo of refs .  , due to equilibration and autocorrelation times .",
    "( iii ) variational parameters are optimized while explicitly preserving the unitary constraints that the tensors in the mera are subjected to .",
    "this is accomplished by a steepest descent method within the set of unitary tensors , which is much more robust to statistical noise than the singular value decomposition methods employed in mera algorithms without sampling.@xcite    we demonstrate the performance of our approach by computing an approximation to the ground state of a finite ising chain with transverse magnetic field . for the binary mera under consideration",
    ", sampling lowers the costs of elementary contractions from @xmath17 to @xmath18 .",
    "we find that the resulting ( approximate ) ground state energy decreases as the number of samples is increased , thus obtaining a demonstration of principle of the approach .",
    "we also notice that the number of samples required to achieve a given accuracy increases as the transverse magnetic field approaches its critical value .    to our knowledge ,",
    "this is the first instance of sampling - based optimization of a relatively complex tensor network .",
    "previous similar optimizations included that of an mps,@xcite which is a considerably simpler tensor network ( with only three - legged tensors ) , and of tensor networks that under sampling break into smaller , simpler tensor networks ( e.g. into mps , single plaquette states , etc).@xcite in more complex tensor networks , such as mera and peps , the optimization becomes much harder due to high sensitivity to statistical noise .",
    "thus , for instance , ref",
    ".   spells out a full variational monte carlo approach for peps but uses an alternative method , not based on sampling , in order to optimize the tensors . indeed , in ref .",
    "sampling is only used to aid in the computation of expectation values . here , instead , we use sampling both to optimize the mera and to compute expectation values .",
    "we emphasize , however , that our results only demonstrate a gain over optimization schemes based on exact contractions ( i.e. without sampling ) in the low accuracy regime , where only a relatively small number of samples are required .",
    "the specific mera ( namely binary mera for a one - dimensional lattice ) and low value of @xmath2 ( @xmath19 ) considered here for illustrative purposes implies that the cost per sample is @xmath20 times smaller than an exact contraction .",
    "recall that the statistical error decreases only as @xmath21 with the number @xmath22 of samples .",
    "if more than @xmath23 samples are required in order to obtain a sufficiently accurate approximation of the exact contraction , then the sampling scheme may be overall less efficient than the exact contraction scheme .",
    "the advantage of sampling over exact contraction schemes is expected to be more evident in mera settings where the cost @xmath3 scales with a larger exponent @xmath4 , and for larger values of @xmath2 .",
    "in particular , we envisage that the method described in this paper , possibly with further improvements , will improve the range of applicability of mera in two and higher dimensions .",
    "the content of this paper is distributed in five more sections . in sec .",
    "[ sec_approach ] , we discuss methods for sampling with the mera . in sec .",
    "[ sec_optimize ] we propose an optimization scheme using sampling techniques . in sec .",
    "[ sec_application ] we benchmark the approach with the quantum ising model . in sec .",
    "[ sec_discussion ] we discuss future applications including extensions to higher dimensions and extracting long - range correlations , before concluding in sec .  [ sec_conclusion ] .",
    "in this section we explain how to use sampling in order to speed - up the computation of expectation values with the mera .",
    "we present both complete and incomplete perfect sampling strategies , building on the proposals of ref .   for generic unitary tensor networks .",
    "we also discuss the importance of the choice of local basis in sampling .",
    "we start by reviewing some necessary background material on the mera .       of the local operator @xmath24 ( yellow rectangle ) , which acts on ( at most )",
    "three neighboring sites .",
    "the flipped tensors , on the bottom half of the diagram , are the hermitian conjugates of the respective tensors above .",
    "the ` causal cone ' is delimited by the dotted line in the left diagram , corresponding to @xmath25 .",
    "the tensors outside the causal cone cancel , significantly simplifying the diagram on the right , corresponding to @xmath26 .",
    "[ fig_causal_cone ] ]    the mera@xcite is a variational wavefunction for ground states of quantum many - body systems on a lattice .",
    "the state @xmath27 of a lattice @xmath9 made of @xmath0 sites is represented by means of a tensor network made of two types of tensors , called _",
    "disentanglers _ and _ isometries_. the tensor network is based on a real - space renormalization group transformation , known as _ entanglement renormalization _ :",
    "disentanglers are used to remove short - range entanglement from the system , whereas isometries are used to coarse - grain blocks of site into single , effective sites .",
    "an example of a mera on a periodic 1d lattice with @xmath28 sites is depicted in fig .",
    "[ fig_mera ] . this structure is called ` binary ' mera because of the 2-to-1 course - graining transformation in each repeating layer . ascending upwards in the figure , the disentanglers @xmath11 remove short - range entanglement in between each course - graining transformation , implemented by isometries @xmath12 until the remaining hilbert space is small enough to deal with directly with some wavefunction @xmath13 .",
    "the mera can also be viewed in the reverse  starting from the top of fig .",
    "[ fig_mera ] , we descend downwards in a unitary quantum circuit , adding ( initially unentangled ) sites in each layer . for instance , let us flow downwards in fig .",
    "[ fig_mera ] . to a three - site system in state @xmath13",
    ", we first add three additional unentangled sites , turning it into a six - site system ; and later we add another six unentangled sites , producing the final twelve - site system . this unitary structure can be exploited when calculating the expectation value @xmath29 of a local operator @xmath24 acting on a few neighboring sites . specifically , all tensors not ` causally ' connected to the few sites supporting @xmath24 cancel , as depicted in fig .",
    "[ fig_causal_cone ] .",
    "the resulting diagram is significantly simpler and can be interpreted as the expectation value @xmath26 of @xmath24 for a state @xmath30 of an effective lattice @xmath31 made of @xmath32 sites ( see fig .",
    "[ fig_sampled_wavefunction ] ) .",
    "we emphasize that , by construction , @xmath33 therefore , we can evaluate the expectation value @xmath25 by contracting the tensor network corresponding to @xmath26 .",
    "the numerical cost of performing this contraction grows linearly with the number of sites in @xmath31 , and thus only logarithmically with the number of site @xmath0 in the original lattice @xmath9 .",
    "the dimension of the hilbert space after each course - graining transformation is an adjustable parameter , the _ bond dimension _",
    "@xmath2 , which plays a central role in the present discussion .",
    "increasing the bond dimension @xmath2 implies including a larger fraction of the original hilbert space and leads to greater accuracy , but also requires greater computational resources .",
    "optimization algorithms to approximate ground states , and to evaluate local expectation values and correlators , are present in the literature.@xcite the numerical cost of finding an expectation value or performing a single optimization iteration using the binary mera scales as @xmath34 for a translation invariant system .",
    "for more complex mera structures , such as those representing 2d lattices , the power of @xmath2 for the cost increases dramatically .",
    "for instance , the 2d mera presented in ref . has a numerical cost of @xmath35 , which on current computers restricts @xmath36 . for many systems ,",
    "this does not allow for enough entanglement to accurately describe the ground state , limiting the accuracy of the approach .    here",
    "we hope to alleviate this problem by reducing the numerical cost as a function of @xmath2 using monte carlo techniques .",
    "we will find that the cost of a single sample scales as @xmath18 for binary 1d mera , compared to the @xmath17 cost of the ` exact ' contraction .       and @xmath30 represented by the mera .",
    "( a ) tensor network for the state @xmath27 of the original lattice @xmath9",
    ". the causal cone is delimited by a discontinuous line .",
    "( b ) tensor network for the state @xmath37 of the effective lattice @xmath31 .",
    "sites further from the center effectively represent increasingly large length scales in the original lattice .",
    "[ fig_sampled_wavefunction ] ]    .",
    "the dashed lines indicate the indices that will be sampled . on the right - hand - side",
    "we explicitly write the tensor contractions outside the causal cone as a sum over a complete , orthonormal set of ` wavefunctions ' @xmath38 ( pink circles ) .",
    "monte carlo sampling will be performed over this set .",
    "each term of the sum can be expressed as the product @xmath39 .",
    "[ fig_mera_structure ] ]    our goal is to compute the expectation value @xmath29 by contracting the tensor network corresponding to @xmath26 , see fig .",
    "[ fig_causal_cone ] .",
    "the first step is to re - express the tensor network contraction as a summation over indices corresponding to the sites of the effective lattice , as shown in fig .",
    "[ fig_mera_structure ] .",
    "we then get @xmath40 where @xmath41 is an orthonormal basis of product states @xmath42 on the effective lattice @xmath31 .",
    "we will approximately evaluate the sum in eq .",
    "( [ energy ] ) by using monte carlo sampling over the states @xmath43 .",
    "notice that in the effective lattice , the sites away from the support of @xmath24 have undergone one or more course - graining transformations . in other words , sites",
    "further from the center represent increasingly larger length - scales .",
    "thus , sampling over sites of the effective lattice corresponds to sampling the system _ at different length scales_. this property is reminiscent of global or cluster updates used in existing monte carlo methods to solve critical systems .    a nave scheme for approximating the sum in eq .",
    "( [ energy ] ) would be to choose @xmath44 at random from @xmath41 , and evaluate @xmath39 according to the tensor networks in fig .",
    "[ fig_mera_structure ] .",
    "the cost of obtaining a single sample scales as @xmath45 .",
    "however , the statistical variance of a sampling scheme can be substantially reduced by implementing importance sampling  in this case choosing configurations @xmath44 that are more likely .",
    "more precisely , sampling is implemented according to the wavefunction _ weight _ , @xmath46 , which can be calculated efficiently as indicated in fig .",
    "[ fig_weight ]",
    ". we can express eq .",
    "( [ energy ] ) in a form more convenient for importance sampling , @xmath47 where @xmath48    note that because the mera is normalized by construction , and therefore the weights sum to one , @xmath49 .",
    "however , during sampling only some subset @xmath50 of the configurations are considered .",
    "one needs to renormalize the weights accordingly , so that the expectation value @xmath51 is approximated as @xmath52          in the case of mera , and indeed any state that can be written as a unitary quantum circuit , a ` perfect ' sample can be generated according to the probability distribution @xmath53 in a single sweep.@xcite this makes markov chain monte carlo unnecessary , simplifying the algorithm and eliminating a source of statistical error ( i.e. autocorrelation effects ) .",
    "this is one advantage of this technique over other tensor network sampling methods in the literature.@xcite    the sample can be constructed by sampling just one index at a time .",
    "beginning at the top layer of the mera , and aiming to sample just the first index ( left - most in fig .",
    "[ fig_mera_structure ]  ( b ) ) , we can construct the one - site reduced density matrix @xmath54 by the tensor contraction in fig .",
    "[ fig_weight ]  ( b ) .",
    "the probability @xmath55 can then be found _ for all possible _ @xmath56 .",
    "a value of @xmath56 is then randomly selected according to any complete basis of our choosing .",
    "after this selection is made , we can then sample the next ( top - most ) index , according to the conditional weights @xmath57 as calculated by the diagram in fig .",
    "[ fig_weight ]  ( b ) ( we refer to ref .   for further details ) .",
    "we continue to sample the state of each site , until we have sampled every site .",
    "each of the diagrams in fig .  [ fig_weight ] can be calculated with cost @xmath18 , while there are @xmath58 layers to the mera .",
    "a single sample can therefore be generated with cost @xmath45 , compared to @xmath34 for the exact contraction .",
    "so long as the number of samples @xmath22 is significantly less than @xmath59 , monte carlo sampling will be faster than exact contraction .    in practice",
    ", we will perform @xmath60 samples in order to get a good estimate of @xmath51 . as",
    "the samples are completely uncorrelated , the variance of @xmath61 @xmath62 \\equiv \\sum_{\\mathbf{r } } p(\\mathbf{r } ) \\left ( a^{\\mathcal{c}}(\\mathbf{r})-\\bar{a^{\\mathcal{c}}}\\right)^2\\ ] ] can be used to estimate statistical error @xmath63 , @xmath64 / n } , \\label{std_error}\\ ] ] while @xmath65 $ ] is itself upper bounded by the variance of the operator to be measured , @xmath62 \\le \\langle \\hat{a}^2 \\rangle - \\langle \\hat{a } \\rangle^2 .",
    "\\label{std_error2}\\ ] ] it is easy to show that the upper bound is saturated when sampling in the diagonal basis of @xmath24 .",
    "however , the actual value of this variance is dependent on the choice of basis @xmath66 , as well as the state being sampled .",
    "therefore , it is worth spending some effort in order to minimize this quantity .",
    "the statistical noise is caused by monte carlo sampling of the tensor contraction , and it stands to reason that sampling _ less _ indices in the tensor network diagram ( see fig .",
    "[ fig_mera_structure ] ) would reduce the statistical error .",
    "indeed , it is possible to exactly contract the three physical indices at the lowest level ( those connected to operator @xmath24 ) while keeping the computational cost at @xmath45 , as depicted in fig .",
    "[ fig_alt_samp_scheme ] .",
    "that is , we sample over configurations @xmath67 of the effective lattice @xmath31 _ minus _ the three central sites on which @xmath24 is supported .",
    "this method effectively generates ( unnormalized ) three - site wave functions @xmath68 from the reduced density operator ( as seen in fig .",
    "[ fig_weight ] ( e , f ) ) .",
    "conversely , the reduced density matrix for the three central sites is @xmath69 .",
    "importance sampling is now achieved by selecting @xmath70 according to the weight @xmath71 in turn , perfect sampling of the sites proceeds exactly as before , but it stops before the three central sites , which are not sampled .",
    "we define the estimator @xmath72 whose expectation value obeys , @xmath73 in analogy with eq .",
    "( [ energy2pre ] ) .",
    "notice that , by construction , the statistical variance @xmath74 $ ] is smaller or equal than @xmath65 $ ] in eq .",
    "( [ std_error2 ] ) , and therefore the numerical accuracy is increased without affecting the computational cost .     and ( b )  @xmath75 with incomplete sampling .",
    "[ fig_alt_samp_scheme ] ]      in general , we are free to choose any complete basis @xmath41 ( or @xmath76 ) from which to draw individual samples .",
    "a good choice is one that produces a small statistical error , eqs .",
    "( [ std_error],[std_error2 ] ) . intuitively , the goal of importance sampling is to decrease the statistical variance by choosing configurations @xmath77 ( or @xmath70 ) with a large overlap with the state @xmath30 . with this in mind",
    ", one could aim to maximize the ` average ' weight , @xmath78 it is easy to show that for a given quantum probability distribution , specified by a density matrix , the above quantity is maximized in the diagonal basis of the density matrix .",
    "inspired by this fact , here we choose to sample site @xmath79 in the basis in which the reduced density matrix @xmath80 is diagonal .",
    "the @xmath81 density matrices @xmath80 , calculated in fig",
    ".  [ fig_weight ] , can be diagonalized with cost @xmath82 .",
    "note that the chosen basis will depend on previously sampled sites , and that the resulting sampling basis is still a complete , orthonormal basis of product states .",
    "we have found that this approach can radically increase the average value of the weight , eq .",
    "( [ eq : weight ] ) with the effect becoming stronger for larger systems and values of @xmath2 .",
    "more importantly , we find that the statistical variance in the observables is decreased ( see sec .",
    "[ sec_application_expectation ] and fig .",
    "[ fig_variance ] ) .",
    "this technique to select the sampling basis is not specific to unitary tensor networks nor perfect sampling methods , and could thus be of benefit to other variational quantum monte carlo algorithms .",
    "finally , we may wish to compute the expectation value of an operator that is the sum of local terms , such as a hamiltonian made of nearest - neighbor interactions : @xmath83 in this case we sample each local term @xmath84 as indicated previously , noticing that the causal cone of each @xmath84 depends on the location of the sites of lattice @xmath9 where the local operator is supported .",
    "one can either choose to ( uniformly ) sample the position @xmath79 in the lattice , or systematically sweep through all the positions @xmath79 .",
    "a complete sweep , where each site @xmath79 is visited once , costs @xmath85 .",
    "in order to find an approximation to the ground state , we need to minimize the energy of the mera .",
    "the direction of steepest _ ascent _ is given by the complex derivative with respect to the conjugate  @xcite of each element of each tensor .",
    "inserting eq .",
    "( [ estimator ] ) ( or eq .  ( [ eofs ] ) ) into eq .",
    "( [ energy2 ] ) and differentiating gives @xmath86 , \\label{derivative}\\end{aligned}\\ ] ] where the derivative with respect to a tensor is element - wise , and similar expressions hold for @xmath12 and @xmath13 .",
    "the derivatives on the right - hand - side of eq .",
    "( [ derivative ] ) can be found by using the usual rules for calculating derivatives in the diagrams , see figs .",
    "[ fig_alt_samp_scheme ] and [ fig_derivatives ] . ) arises from the change in the normalization of the wave function .",
    "although we are dealing with unitary / isometric tensors which ensure @xmath87 , small changes in arbitrary directions may break the unitarity and modify the norm . interestingly , even when projecting into the unitary tangent space ( see below ) where this term averages to zero , its inclusion is important to reduce the sampling error  sometimes by several orders of magnitude . ] in practice @xmath88 and @xmath89 will be estimated simultaneously by sampling .",
    "multiple approaches are possible for updating the mera to minimize the energy and find a good approximation to the ground state .",
    "one approach often used iteratively optimizes each tensor in the mera according to the following algorithm@xcite .",
    "@xmath90 in the above @xmath91 and @xmath92 are unitary , while @xmath93 is diagonal and positive , thus representing the singular value decomposition ( svd ) of the derivative .",
    "this algorithm finds the unitary tensor @xmath11 that minimizes the trace value of its product with the above , called environment with the requirement that @xmath94 is negative - semidefinite .",
    "similar steps apply to @xmath12 and @xmath13 , where the svd ensures that they remain isometric or normalized , respectively .",
    "unfortunately , the above scheme is extremely sensitive to the statistical noise inherent to monte carlo sampling , and results in very poor optimization .",
    "ideally , we would prefer a method in which the statistical noise is able to average out over many iterations .",
    "the most obvious scheme satisfying this requirement is straightforward steepest descent .",
    "again , one must ensure that the tensors obey the unitary / isometric constraints characteristic of the mera , so one can utilize the svd to find the unitary tensor closest ( with respect to the @xmath95norm ) to the usual downhill update . with this method ,",
    "the @xmath79th step is given by @xmath96 where @xmath97 is a number modulating the size of change at the step @xmath98 .",
    "in this paper we avoid using the svd entirely by explicitly remaining in the unitary subspace , along the lines of ref .  .",
    "we define the tangent vector @xmath99 as the derivative projected onto the tangent space of all unitaries located about @xmath11 , @xmath100 the matrix @xmath101 is within @xmath102 of a unitary matrix . noting that @xmath103 is anti - hermitian , then the update @xmath104\\ ] ] both travels in the direction of the tangent vector while @xmath11 remains precisely unitary .",
    "the same approach works for @xmath105 isometric matrices , taking care that @xmath106 , with computational cost scaling similarly to the svd approach as @xmath107 ( see appendix ) .",
    "the performance of the algorithm is highly dependent on the behaviour of @xmath97 , as well as the number of monte carlo samples , @xmath108 , taken in each step .",
    "simple schemes will keep @xmath97 and @xmath108 constant , which is the approach we take here . on the other hand",
    ", one may choose to increase @xmath108 with @xmath98 so that harmful noise is reduced when approaching the optimal solution ; or to decrease @xmath97 with @xmath98 for much the same reason ; or a combination of both .",
    "in this section we demonstrate the above techniques with the well - known transverse - field quantum ising model , @xmath109 such a hamiltonian can be expressed as a sum of nearest - neighbour terms @xmath84 , such that @xmath110 we will pay particular attention to the region around the critical point at @xmath111 , which is the most demanding computationally . for concreteness , we use a three - layer binary mera with periodic boundary conditions , resulting in a lattice of 24 sites in the bottom of the mera structure",
    ". however , each of these sites corresponds to a block of @xmath112 physical spins , making a total of 72 spins .",
    "we choose this blocking so that for @xmath113 the bond dimension only ever decreases when ascending through the mera . in",
    "what follows , we employ incomplete perfect sampling where three sites at the bottom of the mera are contracted exactly .",
    "we now analyze the effectiveness of extracting expectation values from the mera using monte carlo sampling . for perfect sampling techniques",
    ", the accuracy can be easily extracted from the variance using eq .",
    "( [ std_error ] ) .",
    "the scaling of the error in the energy , @xmath114 , is shown explicitly for the critical ( @xmath115 ) system in fig .",
    "[ fig_variance ]  ( a ) .",
    "the variance of the energy estimator @xmath116 as a function of @xmath117 is shown in fig .",
    "[ fig_variance ]  ( b ) .",
    "here we have used mera wavefunctions previously optimized using standard techniques@xcite _ without _ monte carlo sampling , that is , sampling is only employed to extract the expectation values .     as a function of the number of samples @xmath22 follows the classic @xmath118 scaling .",
    "( b ) variance of the energy estimator ( normalized to the expectation value @xmath119 ) for optimized meras with bond - dimension @xmath120 for various values of @xmath117 ( red crosses ) .",
    "estimates of the statistical uncertainty are smaller than the symbols .",
    "the grey area is eliminated by inequality eq .",
    "( [ std_error2 ] ) , bounded by the variance of @xmath94 . for comparison , we include the variances expected from several hypothetical samplings of @xmath121 .",
    "variances from sampling the spins in the @xmath122 ( or @xmath123 ) basis is indicated by a blue , dash - dot ( or green , dashed ) line .",
    "our numerical results ( red crosses ) show remarkable similarity with sampling in the diagonal basis of @xmath121 ( black , solid line ) .",
    "( c )  the entanglement entropy of @xmath121 . in ( b ) and",
    "( c ) , the critical point at @xmath111 is indicated with a red dotted vertical line .",
    ", title=\"fig : \" ]   as a function of the number of samples @xmath22 follows the classic @xmath118 scaling .",
    "( b ) variance of the energy estimator ( normalized to the expectation value @xmath119 ) for optimized meras with bond - dimension @xmath120 for various values of @xmath117 ( red crosses ) .",
    "estimates of the statistical uncertainty are smaller than the symbols .",
    "the grey area is eliminated by inequality eq .",
    "( [ std_error2 ] ) , bounded by the variance of @xmath94 . for comparison",
    ", we include the variances expected from several hypothetical samplings of @xmath121 .",
    "variances from sampling the spins in the @xmath122 ( or @xmath123 ) basis is indicated by a blue , dash - dot ( or green , dashed ) line .",
    "our numerical results ( red crosses ) show remarkable similarity with sampling in the diagonal basis of @xmath121 ( black , solid line ) .",
    "( c )  the entanglement entropy of @xmath121 . in ( b ) and ( c ) , the critical point at @xmath111 is indicated with a red dotted vertical line .",
    ", title=\"fig : \" ]   as a function of the number of samples @xmath22 follows the classic @xmath118 scaling .",
    "( b ) variance of the energy estimator ( normalized to the expectation value @xmath119 ) for optimized meras with bond - dimension @xmath120 for various values of @xmath117 ( red crosses ) .",
    "estimates of the statistical uncertainty are smaller than the symbols .",
    "the grey area is eliminated by inequality eq .",
    "( [ std_error2 ] ) , bounded by the variance of @xmath94 . for comparison , we include the variances expected from several hypothetical samplings of @xmath121 .",
    "variances from sampling the spins in the @xmath122 ( or @xmath123 ) basis is indicated by a blue , dash - dot ( or green , dashed ) line .",
    "our numerical results ( red crosses ) show remarkable similarity with sampling in the diagonal basis of @xmath121 ( black , solid line ) .",
    "( c )  the entanglement entropy of @xmath121 . in ( b ) and ( c ) , the critical point at @xmath111 is indicated with a red dotted vertical line .",
    ", title=\"fig : \" ]    notice that the variance is maximal near the critical point at @xmath111 . as the monte carlo code effectively samples wavefunctions from the reduced three - site ( i.e. nine - spin ) density operator",
    ", one would expect the energy variance to increase with the amount of entanglement in the system .",
    "for reference we have included the entropy of the three - site density matrix @xmath121 in fig .",
    "[ fig_variance ]  ( c ) .",
    "this entropy mostly and @xmath121 share a @xmath124 symmetry which is broken by the mera wavefunction for @xmath125 , and the _ exact _ ground state should have @xmath126 entanglement entropy as @xmath127 . ]",
    "corresponds to the entanglement entropy of three sites with the remainder of the system .",
    "we see a strong correlation between the amount of entanglement and the size of the variance of the energy estimator @xmath116 .",
    "let us emphasize that fig .",
    "[ fig_variance ]  ( b ) shows that our scheme performs significantly better than directly sampling @xmath121 in either the @xmath123 or @xmath122 spin basis .",
    "the measured variances are very similar to a diagonal sampling of @xmath121 ( i.e. in its diagonal basis ) .",
    "this indicates that the sampling scheme is performing as intended in sec .",
    "[ sec_diagonal ] .",
    "in general , an accurate representation of wavefunctions with greater amounts of entanglement will require greater bond dimension @xmath2 .",
    "these results suggest that the statistical variance generated by this scheme will also increase with the entanglement . to achieve a certain precision in the expectation value of local observables",
    ", the number of required samples grows with this variance , and thus with the amount of entanglement and with the minimum suitable value of @xmath2 .",
    "therefore , although a _ single _ sample has cost @xmath18 , the _ total _ cost to obtain a certain precision may have some additional dependence on @xmath2 .",
    "nevertheless , no additional dependence was clearly manifest in our simulations at fixed @xmath117 .",
    "finally , we combine monte carlo sampling with our unitary - subspace steepest descent algorithm to obtain optimized wavefunctions . in fig .",
    "[ fig_optimize ] we plot the energy of the mera during the optimization process at @xmath111 and @xmath128 , where the simulation progresses through a range of different number of sweeps @xmath22 per optimization step . in all cases",
    "the step size is fixed at @xmath129 .",
    "we observe that increasing @xmath22 improves the quality of the optimized wavefunction and for large values of @xmath22 the simulation tends to converge towards the same energy obtained with exact contractions , as expected .",
    "like all tensor network optimizations , care must be taken to ensure the wavefunction has fully converged to the lowest energy state . for instance , in fig .",
    "[ fig_optimize ] ( a ) we see a plateau in energy before around the 4000th iteration that could be mistaken for convergence ( whereas the simulation is actually navigating a stiff region , i.e. a long narrow valley in the energy landscape ) .",
    "non - deterministic features due to statistical fluctuations can also be seen  such as the sudden increase of energy of the @xmath130 simulation around the 13000th iteration .    beyond this , accuracy could be improved by increasing @xmath2 .",
    "it should be noted that we have observed that the steepest descent method ( with either exact contractions or sampling ) will not always produce wavefunctions of the same quality as the svd method as it may be more susceptible to local minima or extreme stiffness .",
    "however , accuracy can still be systematically improved by increasing @xmath2 .     during optimization .",
    "each iteration is update using @xmath22 sweeps , where @xmath22 is @xmath131 in the black crosses , red pluses , green diamonds and blue points respectively .",
    "every 100 iterations , we calculate the exact energy corresponding to the current wavefunction , which is plotted here .",
    "the solid horizontal line indicates the energy of an optimized @xmath19 mera using exact contractions and steepest descent ( which remains @xmath132 above the the true ground state energy , indicated by the dashed line ) .",
    "the simulation converges for large @xmath22 , but @xmath2 may need to increase for greater accuracy .",
    "( b ) difference to the above solid line plotted on a logarithmic scale .",
    "the difference reduces with increasing @xmath22 , and although statistical fluctuations are decreasing , they remain evident on the logarithmic scale.,title=\"fig : \" ]   during optimization .",
    "each iteration is update using @xmath22 sweeps , where @xmath22 is @xmath131 in the black crosses , red pluses , green diamonds and blue points respectively .",
    "every 100 iterations , we calculate the exact energy corresponding to the current wavefunction , which is plotted here . the solid horizontal line indicates the energy of an optimized @xmath19 mera using exact contractions and steepest descent ( which remains @xmath132 above the the true ground state energy , indicated by the dashed line ) .",
    "the simulation converges for large @xmath22 , but @xmath2 may need to increase for greater accuracy .",
    "( b ) difference to the above solid line plotted on a logarithmic scale .",
    "the difference reduces with increasing @xmath22 , and although statistical fluctuations are decreasing , they remain evident on the logarithmic scale.,title=\"fig : \" ]    in the previous section we noted that the statistical uncertainty peaked around the critical point at @xmath111 , where the entanglement is maximal , and one might expect the optimizations to be most difficult around this point . plotted in fig .",
    "[ fig_optimize_vs_h ] is the difference in energy between our wavefunctions and the exact , analytic solution for a range of @xmath117 .",
    "we observe that the error decreases away from the critical point , and that there is a clear relationship between the quality of the wavefunction and the number of samples per step , @xmath22 .    .",
    "the markers indicate the number of monte carlo sweeps taken between updates , @xmath133 for the black cross , red diamond , green circle and blue square , respectively .",
    "there is a clear trend for improved ground state energy as @xmath22 increases , and away from the critical point at @xmath111 ( vertical red dotted line ) . ]",
    "there are several possible limiting factors in variational monte carlo optimizations of mera wavefunctions .",
    "one must balance the cost of increasing @xmath22 , @xmath2 and the total number of iterations , to produce results of the desired accuracy . on top of this ,",
    "the ansatz presents a complicated optimization landscape and one must be careful not to be stuck in local minima .",
    "there is much scope to improve on the above optimization scheme by using more sophisticated approaches .",
    "most obviously , the step - size @xmath97 and number of samples @xmath108 performed in each iteration could be adjusted as the simulation progresses .",
    "for example by choosing the step size to decrease as @xmath134 , with @xmath22 fixed and @xmath135 we are guaranteed convergence to some local minimum@xcite .",
    "equivalently , the noise could be reduced at each step by increasing @xmath136 , or some combination of both .    in ref .",
    "it was found that using just the sign of the derivative , as well as properties resulting from translational invariance , was sufficient for optimizing a periodic mps with monte carlo sampling .",
    "other approaches existing in the literature may result is significant gains , though it should be noted that approaches requiring the second derivative or hessian matrix would increase the order of the numerical cost as a function of @xmath2 , and would have to be made robust to statistical noise .",
    "there are several situations where it is most natural to use monte carlo sampling to speed - up mera algorithms .",
    "let us briefly review them .      in this work we have considered in detail the binary mera for a 1d lattice with translation invariance .",
    "however , even in a translationally invariant , 1d lattice , one has freedom to choose between a large variety of entanglement renormalization schemes , leading to mera structures with different configurations of isometries and disentanglers .",
    "-to-@xmath137 mera described in ref .  .",
    "[ fig_other_meras],title=\"fig:\",width=188]-to-@xmath137 mera described in ref .  .",
    "[ fig_other_meras],title=\"fig:\",width=132 ]    the ternary mera , shown in fig .  [ fig_other_meras ]  ( a ) , has a narrower causal cone , with a width of just two sites , and the traditional algorithms for optimizing it have a cost that scales as @xmath138 . as a result , the ternary mera is sometimes favored over the binary mera .",
    "note that this does not necessarily translate into an improved accuracy in expectation values  the ternary mera is in general less accurate than binary mera for the same value of @xmath2 .",
    "it is interesting to note that , in the ternary mera , the perfect sampling algorithm presented here again has cost @xmath18 , while markov chain monte carlo , as well as expectation value and environment estimation , is possible with cost @xmath139 .",
    "it is unclear whether after including autocorrelation effects the markov chain method performs better , similar , or worse overall compared to the perfect sampling algorithm .",
    "another possible 1d mera includes two layers of disentanglers to account for entanglement over larger distances , as depicted in fig .",
    "[ fig_other_meras ]  ( b ) .",
    "this mera has a causal cone that is five sites wide , and traditional algorithms would have numerical cost @xmath140 and require memory @xmath141  limiting @xmath2 to rather small values .",
    "however , a sampling technique will only require @xmath142 time per sample and @xmath18 memory overall  a huge saving .",
    "note that the power roughly halves when we change from an exact contraction which effectively rescales density matrices from higher layers to lower , to a monte carlo scheme which samples wavefunctions from this distribution .",
    "the scaling of computational cost in @xmath2 in 2d lattices is even more challenging , mostly because the width of the causal cone ( or number of indices included in a horizontal section of the causal cone ) is much larger . once again",
    ", sampling wavefunctions will require roughly square - root the number of operations ( and memory ) needed to calculate the exact reduced - density matrix .",
    "for instance , in the @xmath143-to-@xmath137 mera presented in ref .",
    ", the cost of an exact contraction scales as @xmath35 , while with monte carlo sampling it is possible with just @xmath144 operations per sample ( depicted in fig .",
    "[ fig_other_meras ]  ( c ) ) .",
    "memory might be a limiting factor in 2d mera algorithms , while the temporary memory required for this algorithm is less than that to store the disentanglers and isometries .",
    "another challenge with mera calculations is the numerical cost of long - range correlations .",
    "take for instance the two - site operator @xmath145 , for arbitrary sites @xmath79 and @xmath146 .",
    "the cost required to contract the corresponding tensor network within the binary mera scheme can scale as much as @xmath140  significantly more than the @xmath17 cost for neighbor and next - nearest - neighbor correlations .",
    "however , an estimate of the correlator can be obtained using monte carlo sampling at a reduced cost ( per sample ) . in fig .",
    "[ fig_long_range ] , we depict the causal cone structure of two single - site operators separated by @xmath147 sites in a binary mera . the cost of monte carlo sampling for @xmath148 is just @xmath149 .    .",
    "an exact contraction of the expectation value costs @xmath140 .",
    "[ fig_long_range ] ]    this technique can be extended to 2d lattice systems , where calculating long - range correlations exactly quickly becomes infeasible , even for modest values of @xmath2 .",
    "note again that memory constraints are particularly challenging for 2d mera calculations and monte carlo sampling can alleviate this burden .",
    "we have outlined and tested a scheme for monte carlo sampling with the mera .",
    "uncorrelated samples can be efficiently generated directly from the wavefunction overlap probability distribution , without needing to resort to markov chain monte carlo methods . from this , expectation values can be extracted and we have demonstrated techniques to reduce the statistical error . we have also presented and demonstrated an algorithm to optimize mera wavefunctions using sampled energy derivatives .    the numerical results presented here were not intended to be state - of - the - art solutions of the 1d quantum ising model , but rather to demonstrate feasibility and motivate subsequent applications to 2d systems . in general , monte carlo sampling becomes more advantageous for systems with large numbers of degrees of freedom , and we expect 2d mera to be no exception . because the reduction in cost in two ( and higher ) dimensions is so significant , monte carlo techniques are a very attractive way to achieve reasonable values of @xmath2 with current computers .",
    "obvious improvements to the code include utilizing symmetries and parallelization to supercomputers , which is straightfoward with our perfect sampling algorithm .",
    "further research into optimization strategies may lead to other improvements ( e.g. by reducing the number of iterations or the tendency to find local minima ) .",
    "reweighting techniques@xcite may make the optimization more efficient when approaching the ground state .",
    "the authors would like to thank philippe corboz and anders sandvik for useful discussions .",
    "support from the australian research council ( ff0668731 , dp0878830 , dp1092513 ) , the visitor programme at perimeter institute , nserc and fqrnt is acknowledged .",
    "in this appendix we explain how to compute , with cost @xmath150 , the @xmath151 isometric matrix @xmath152 where @xmath153 is an @xmath151 isometric matrix , @xmath154 is a general @xmath155 matrix , and @xmath156 .",
    "the nave approach would be to evaluate the @xmath157 matrix @xmath158 and compute its exponential , with cost @xmath159 , before multiplying by @xmath153 .",
    "however , noting that the exponent does not have full rank ( the rank is at most @xmath160 ) , we can hope to find a faster method .    taking the taylor expansion @xmath161 we observe that the result can be achieved with a series of multiplications between @xmath162 matrices @xmath163 , @xmath164 and @xmath165 , post - multiplied by either @xmath153 or @xmath154 , requiring total cost @xmath107 .        in the binary mera , where isometries are @xmath178 matrices ( i.e. @xmath179 , @xmath180 )",
    ", the cost of this algorithm scales as @xmath139 , compared with the cost @xmath181 of the nave approach .",
    "this algorithm becomes particularly important for a tree tensor network and for the mera in two dimensions , where the nave approach becomes more expensive , in powers of @xmath2 , than a sampling ( thus becoming the bottle neck of an optimization based on sampling ) , whereas the above algorithm remains competitive ."
  ],
  "abstract_text": [
    "<S> monte carlo sampling techniques have been proposed as a strategy to reduce the computational cost of contractions in tensor network approaches to solving many - body systems . </S>",
    "<S> here we put forward a variational monte carlo approach for the multi - scale entanglement renormalization ansatz ( mera ) , which is a unitary tensor network . </S>",
    "<S> two major adjustments are required compared to previous proposals with non - unitary tensor networks . </S>",
    "<S> first , instead of sampling over configurations of the original lattice , made of @xmath0 sites , we sample over configurations of an effective lattice , which is made of just @xmath1 sites . </S>",
    "<S> second , the optimization of unitary tensors must account for their unitary character while being robust to statistical noise , which we accomplish with a modified steepest descent method within the set of unitary tensors . </S>",
    "<S> we demonstrate the performance of the variational monte carlo mera approach in the relatively simple context of a finite quantum spin chain at criticality , and discuss future , more challenging applications , including two dimensional systems . </S>"
  ]
}