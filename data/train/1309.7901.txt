{
  "article_text": [
    "of generalized reed  solomon codes comes in multiple flavors . among the most widely - deployed techniques for decoding up to @xmath0 errors , where @xmath1 is the length and @xmath2 is the dimension of the code ,",
    "is decoding based on linear shift register synthesis with the berlekamp ",
    "massey algorithm @xcite . other techniques",
    "utilize the extended euclidean algorithm @xcite , newton interpolation @xcite , and bivariate polynomial interpolation @xcite .",
    "apart from implementational speedups , e.g. ,  divide & conquer techniques that allow to implement the berlekamp  massey algorithm in",
    "@xmath3 $ ] as proposed in @xcite , all these algorithms are in @xmath4 $ ] .",
    "decoding beyond @xmath0 is much more complicated and efficient ( polynomial - time ) decoding algorithms for this case have been known only after the invention of the sudan algorithm in 1997 @xcite and the guruswami ",
    "sudan algorithm in 1999 @xcite .",
    "the latter can correct up to @xmath5 errors .    as we will see shortly , the guruswami ",
    "sudan algorithm consists of two steps where one of them  an interpolation problem  is computationally more involved than the other .",
    "extensive efforts to speed up the interpolation problem include exploiting structured matrices @xcite or the underlying algebraic structure @xcite .",
    "the technique of re - encoding was introduced in @xcite ; it allows one to make predictions about the structure of the solutions of the interpolation problem and then to exploit this knowledge in order to reduce the problem .",
    "our contribution in this paper is to show how the size of the interpolation problem can in many cases be reduced beyond re - encoding , utilizing a simple property of the generalized reed  solomon code s base field . in order to provide a framework that unites re - encoding , our proposal , and the combination of both",
    ", we introduce the general notion of a - priori known _",
    "prefactors _ and show how such factors can lead to a reduction of the interpolation problem .    the rest of this paper is organized as follows .",
    "section  [ sec : prelim ] covers generalized reed ",
    "solomon codes as well as the guruswami ",
    "sudan algorithm with its interpolation and factorization steps .",
    "the concept of re - encoding is explained in section  [ sec : reenc ] and a theorem delivers the associated _ re - encoding _ prefactors .",
    "section  [ sec : sierpinski ] represents the main part of the paper .",
    "it introduces the new type of _ sierpinski _ prefactors and gives results about their existence and properties .",
    "section  [ sec : factors ] shows how prefactors of both types can be combined and how they can be used to diminish the size of the interpolation problem .",
    "one of our main results is given in this section , i.e. ,  the reduced interpolation step given by problem  [ prob : interpolation_reduced ] .",
    "the paper is wrapped up in section  [ sec : conclusion ] and two useful algorithms are provided in an appendix .",
    "[ def : grs ] for a prime power @xmath6 and @xmath7 with @xmath8 let @xmath9 be an ordered set of distinct elements ( _ code locators _ ) from the finite field @xmath10 and let @xmath11 be an ordered set of nonzero ( not necessarily distinct ) elements ( _ column multipliers _ ) from @xmath10",
    ". then the set of vectors @xmath12,\\deg[u(x)]<k\\right\\}\\end{gathered}\\ ] ] is a _ generalized reed ",
    "solomon ( grs ) code _",
    "@xcite .    since we frequently assume that _ base field _",
    "@xmath10 , _ code length _",
    "@xmath1 , and _ code dimension _",
    "@xmath2 as well as code locators and column multipliers are fixed , we write @xmath13 for @xmath14 whenever it is convenient .",
    "grs codes fulfill the singleton bound with equality , i.e. ,  their _ minimum distance _",
    "is @xmath15 .",
    "@xmath13 is a linear subspace of @xmath16 , and thus it is a linear code .",
    "note that _ conventional reed ",
    "solomon ( rs ) _ codes are special cases of grs codes with @xmath17 and @xmath18 , where @xmath19 has order @xmath1 and @xmath20 @xcite .",
    "the state - of - the - art of decoding grs codes is the _ guruswami  sudan algorithm ( gsa ) _",
    "it can be divided into two steps : the interpolation step ( problem  [ prob : interpolation ] ) and the factorization step ( problem  [ prob : factorization ] ) . our focus here is on the interpolation step , which is computationally more involved .",
    "let @xmath21 be a codeword , @xmath22 be an error vector of hamming weight @xmath23}}=\\varepsilon$ ] , and @xmath24 be the corresponding received vector obtained from the transmission channel .",
    "furthermore , let @xmath25 and let @xmath26 be two parameters of the gsa with @xmath27 . with any set @xmath28 we associate the polynomial @xmath29 with @xmath30 if @xmath31 . here",
    ", @xmath19 is a primitive element .",
    "[ prob : interpolation ] given a received vector @xmath32 and @xmath33 , find a nonzero bivariate polynomial @xmath34 $ ] such that @xmath35\\leq r(n-\\varepsilon_0)-\\nu(k-1)-1{\\ensuremath{\\triangleq}}{\\ensuremath{d_{q_{\\nu}}}}\\ ] ] for @xmath36 and @xmath37 where @xmath38 .",
    "the nested sum in is called the @xmath39th _ mixed partial hasse derivative _ @xcite of @xmath40 .",
    "the condition that all @xmath39th hasse derivatives with @xmath41 evaluate to zero for all tuples",
    "@xmath42 , @xmath43 , means that these tuples are zeros of multiplicity @xmath44 of @xmath40 .",
    "for that reason , we refer to the parameter @xmath44 as the _ multiplicity _ of the gsa .",
    "a straightforward analysis shows that the homogeneous linear system of equations associated with problem  [ prob : interpolation ] has @xmath45 equations and @xmath46 unknowns .",
    "both numbers are exceedingly large even for short grs codes and intermediate parameters @xmath44 and @xmath47 .",
    "it can be shown that the linear system has a nonzero solution @xmath40 ( i.e. ,  it has more equations than unknowns ) as long as @xmath48    naively solving the linear system with gaussian elimination in order to obtain a solution is in @xmath49 $ ] since @xmath50 and @xmath51 .",
    "one of the fastest methods to solve the interpolation step is ktter interpolation @xcite , which is in @xmath52 $ ] .",
    "a fast algorithm that actually solves the homogeneous linear system was provided in @xcite and is based on results from @xcite .    without loss of generality",
    "we assume in the following that the columns of the coefficient matrix ( from left to right ) are associated with the unknown coefficients @xmath53 such a coefficient matrix can be set up using algorithm  [ alg : gsa_matrix ] in the appendix .",
    "the particular ordering of the coefficients will become important in section  [ sec : factors ] where we apply our results in order to reduce the coefficient matrix .",
    "[ prob : factorization ] given a solution @xmath40 of problem  [ prob : interpolation ] , find all factors of the form @xmath54 with @xmath55 $ ] , @xmath56<k$ ] .",
    "let us collect all such @xmath57 in a set @xmath58 .",
    "from @xmath58 we can calculate the _ result list _ @xmath59 obviously , @xmath60 and @xmath61 . due to the latter fact , we refer to the parameter @xmath47 as the _ list size_. note that all codewords @xmath62 with @xmath63}}>\\varepsilon_0 $ ] can be discarded .",
    "it is proven in @xcite that @xmath64 if @xmath65}}={\\ensuremath{\\mathrm{wt_\\mathrm{h}}\\left[{\\ensuremath{\\boldsymbol{e}}}\\right]}}\\leq\\varepsilon_0 $ ] .",
    "problem  [ prob : factorization ] can be solved with time complexity in @xmath66n^2\\right]$ ] using a technique from @xcite , but this is not the focus of this paper .",
    "it follows from the exposition of the welch ",
    "berlekamp algorithm in @xcite and the interpretation of justesen and hholdt in ( * ? ? ?",
    "* sections  5.2 and 12.2 ) that the gsa simplifies to the sudan algorithm @xcite if we restrict the multiplicity to @xmath67 and that it further simplifies to the welch ",
    "berlekamp algorithm @xcite if we additionally restrict the list size to @xmath68 .",
    "the re - encoding projection in the context of the gsa was first introduced in @xcite and later elaborated for application with interpolation algorithms in @xcite .",
    "its key idea is to project the received vector @xmath69 onto a subspace of @xmath16 with zero components at positions indexed by @xmath70 , @xmath71 .",
    "not surprisingly , it turns out that this allows to skip @xmath2 of the interpolation points @xmath42 in and thus to reduce the size of the interpolation problem  [ prob : interpolation ] from @xmath1 to @xmath72 points .",
    "the _ re - encoding projection _ with respect to @xmath70 , @xmath71 , for @xmath14 is defined as the linear map @xmath73 where @xmath74 , such that @xmath75 .",
    "the re - encoding projection annihilates the components @xmath76 , @xmath77 , and sets them to zero .",
    "it is injective since grs codes fulfill the singleton bound with equality and thus any codeword @xmath78 is uniquely determined by the @xmath2 components @xmath79 , @xmath77 .",
    "the remaining @xmath72 components @xmath79 , @xmath80 , can be efficiently found using an erasures - only decoder .",
    "@xmath81 is indeed a projection , i.e. ,  it is idempotent .",
    "this can be seen by the fact that all components of @xmath82}}={\\ensuremath{\\boldsymbol{v}}}+\\widetilde{{\\ensuremath{\\boldsymbol{c}}}}_1 $ ] at positions @xmath77 are zero by definition . but then @xmath83}}\\right]}}={\\ensuremath{\\boldsymbol{v}}}+\\widetilde{{\\ensuremath{\\boldsymbol{c}}}}_1+\\widetilde{{\\ensuremath{\\boldsymbol{c}}}}_2 $ ] , where @xmath84 is zero at the @xmath2 positions in @xmath85 , which is only possible if it is the all - zero codeword .",
    "[ ex : reenc1 ] consider the conventional rs code @xmath86 with @xmath87 ( primitive element @xmath88 ) and @xmath89 .",
    "for this code , the gsa with multiplicity @xmath90 and list size @xmath91 can correct up to @xmath92 errors . assume the following composition of the received vector :",
    "@xmath93 assume further @xmath94 , i.e. ,  when we apply the re - encoding projection to @xmath32 we obtain @xmath95 and need to correct the @xmath96 using an erasures - only decoder .",
    "the ( unique ) result of this procedure is @xmath97 . with this",
    ", the re - encoding projection of @xmath32 becomes : @xmath98    \\end{array}\\ ] ] but then @xmath99={\\ensuremath{\\boldsymbol{c}}}+\\widetilde{{\\ensuremath{\\boldsymbol{c}}}}+{\\ensuremath{\\boldsymbol{e}}}$ ] with @xmath100 , hence we have a new received vector with ( as we will see ) favorable properties but still the original error vector : @xmath101    \\end{array}\\ ] ]    the example shows how the re - encoding projection can be used in order to simplify the decoding : first , the received vector @xmath32 is projected , which yields a new received vector @xmath99 $ ] with ( at least ) @xmath2 zero components .",
    "then , the gsa is applied to the new received vector in order to obtain the error vector @xmath102 .",
    "this can be done more efficiently than decoding of @xmath32 due to the designed properties of @xmath99 $ ] .",
    "finally , the error vector together with the original received vector can be used to calculate the transmitted codeword @xmath103 .",
    "the following theorem shows that decoding of @xmath99 $ ] with the gsa induces strong structural properties on the bivariate result polynomial @xmath40 of the interpolation step or , more precisely , its constituent univariate polynomials @xmath104 , @xmath36 .",
    "it will become clear in section  [ sec : factors ] how this can be exploited in order to reduce the size of the interpolation problem  [ prob : interpolation ] .",
    "[ thm : reenc_factors ] let @xmath14 be a grs code , @xmath70 with @xmath71 , and @xmath105 such that the gsa can correct at most @xmath106 errors .",
    "let further @xmath21 , @xmath22 with @xmath23}}\\leq\\varepsilon_0 $ ] and @xmath24 .",
    "when the gsa is applied to @xmath99 $ ] it yields a bivariate result polynomial @xmath34 $ ] whose constituent univariate polynomials @xmath104 , @xmath107 , can be factored as @xmath108 where @xmath109\\leq { \\ensuremath{d_{q_{\\nu}}}}-k(r-\\nu){\\ensuremath{\\triangleq}}{\\ensuremath{d_{u_{\\nu}}}}$ ] .",
    "we emphasize that the _ re - encoding prefactors _ @xmath110 in are fixed a - priori , i.e. ,  they do not depend on the received vector @xmath32 .",
    "this fact will be exploited in section  [ sec : factors ] , it basically allows to work with the quotient polynomials @xmath111 instead of the full polynomials @xmath104 . note that we required @xmath51 in section  [ sec : prelim ] , hence there generally are polynomials @xmath104 , @xmath112 that can not be factored .",
    "assume that @xmath40 is a solution of problem  [ prob : interpolation ] for the projected received vector @xmath99 $ ] .",
    "that is , the coefficients of @xmath40 fulfill .",
    "if we restrict to @xmath113 we obtain @xmath114 since @xmath115 . the factor @xmath116 annihilates all summands of the outer sum except the one for @xmath117 , which yields @xmath118 . but then becomes @xmath119 which means that the @xmath120th to @xmath121th hasse derivatives of the @xmath122 , @xmath123 , evaluate to zero at all @xmath124 , @xmath77 .",
    "but then the @xmath124 , @xmath77 , are roots of multiplicity @xmath125 of @xmath122 , which ( after replacing @xmath126 by @xmath127 ) proves our argument .",
    "the bound on the degrees of the @xmath111 is easy to see by comparing the degrees of the involved polynomials .",
    "[ ex : reenc2 ] for the setting of example  [ ex : reenc1 ] , the interpolation step of the gsa could result in the bivariate polynomial @xmath128 with univariate constituent polynomials    rcl q_0(x ) & = & 6x^13 + 2x^12 + 6x^11 + x^10 + 2x^9 + 7x^8 + 2x^7 + & & + 4x^6 + 2x^5 + 7x^4 + 3x^3 + 3x^2 + 8x + 5 + q_1(x ) & = & 7x^9 + x^8 + 9x^7 + 5x^4 + 6x^3 + 4x^2 + 1 + q_2(x ) & = & 2x^5 + 10x^4 + z^2 + 2x + 6 + q_3(x ) & = & 1 .    from @xmath94",
    "and we obtain @xmath129 and it is easy to verify the factorizations @xmath130 that are given by theorem  [ thm : reenc_factors ] .    we have seen in this section that the re - encoding projection can be used in order to obtain structured solutions , i.e. ,  bivariate polynomials @xmath40 , of problem  [ prob : interpolation ] . the computational overhead of re - encoding is negligible , as it is confined to a single erasures - only decoding step for a vector with @xmath72 erased symbols .",
    "in this section , we introduce a new technique that results in structured solutions of problem  [ prob : interpolation ] .",
    "in contrast to the re - encoding projection , this approach does _ not _ require any additional computations , it simply exploits basic properties of the grs code s base field @xmath10 .",
    "the main idea is to exploit the fact that many of the binomial coefficients in are zero modulo the characteristic of @xmath10 .    to see this ,",
    "let us consider the left - aligned pascal triangles in fig .",
    "[ fig : sierpinski ] , where the entries are calculated modulo @xmath131 and modulo @xmath132 , respectively .",
    "obviously , the zero entries of the triangles follow regular patterns .",
    "note that we use the rather uncommon left - aligned representation of the pascal triangle in order to be able to refer to its columns .",
    "the triangle resembles variants of the left - aligned _ sierpinski gasket _ ,",
    "one of the most basic examples of a self - similar set .",
    "the resemblance gets more accurate as more rows of the pascal triangle are considered . in the following",
    ", we will refer to a pascal triangle with entries modulo any positive integer @xmath133 as a _",
    "sierpinski triangle _ and we denote it by @xmath134 .    now consider the interpolation constraints .",
    "the summands of the outer sum are weighted by the binomial coefficients @xmath135 , @xmath136 .",
    "these are exactly the binomial coefficients that appear at the first @xmath137 entries in column @xmath126 of a sierpinski triangle . for any @xmath19 , @xmath138 , where @xmath139 $ ] is the characteristic of @xmath10 .",
    "thus , summands for which @xmath135 is a multiple of @xmath133 are zero .    for given list size @xmath47 and multiplicity @xmath44 ,",
    "let us assume there is a column @xmath140 , @xmath141 , in @xmath134 such that @xmath142 i.e. ,  all entries except the first one ( which is @xmath143 ) are zero .",
    "we refer to such columns as _ _ zero columns _ _ , hence the degenerate zero column with a single entry @xmath144 can not occur in context of the gsa .",
    "however , it will turn out to be useful for the proof of lemma  [ lemma : zerocolumnsspoilers ] to include this case in the definition . ] .",
    "[ fig : sierpinski ] shows that zero columns actually exist , e.g. ,  column @xmath145 for @xmath146 in @xmath147 ( fig .",
    "[ fig : sierpinski2 ] ) or column @xmath148 for @xmath149 in @xmath150 ( fig .",
    "[ fig : sierpinski3 ] ) .",
    "assume that @xmath40 is a solution of problem  [ prob : interpolation ] for a received vector @xmath32 and consider for zero column @xmath140 .",
    "this equation simplifies to @xmath151 since all summands of the outer sum except the first one are annihilated by the zero binomial weights .",
    "but then , with the same argumentation as in the proof of theorem  [ thm : reenc_factors ] , the @xmath124 , @xmath43 , are roots of multiplicity @xmath152 of @xmath153 and thus @xmath153 can be factored as @xmath154 where @xmath155\\leq { \\ensuremath{d_{q_{t_0}}}}-n(r - t_0)$ ] .",
    "the following lemma specifies the conditions for the existence of a zero column @xmath140 and its location .",
    "[ lemma : zerocolumnexists ] let @xmath26 , @xmath51 .",
    "if    * @xmath156 or * @xmath157    then a zero column does _ not _ exist . otherwise , find the least significant base-@xmath133 digit @xmath158 of @xmath47 such that @xmath159 .",
    "then , @xmath160 is a zero column . in particular",
    ", @xmath140 is the maximal ( rightmost ) zero column .",
    "the proof of lemma  [ lemma : zerocolumnexists ] relies on the following well - known theorem about the divisibility of binomial coefficients , which we state in a modified form that is particularly convenient for our purposes .",
    "let @xmath161 and @xmath133 prime .",
    "then @xmath162 if and only if at least one base-@xmath133 digit of @xmath163 is greater than the corresponding base-@xmath133 digit of @xmath164 .",
    "a zero column @xmath140 is defined by property , which can  using lucas theorem  be equivalently formulated as follows : @xmath140 in base @xmath133 must be such that it has at least one base-@xmath133 digit greater than that of @xmath165 , @xmath166 , at least one base-@xmath133 digit greater than that of @xmath47 .    if @xmath156 then @xmath167 are all single - digit numbers and since @xmath168 , @xmath140 can not be greater than @xmath169 , proving the first case . the base-@xmath133 expansion of an integer that fulfills the second case is @xmath170 where @xmath171 .",
    "that is , all digits except the leading one assume the maximal possible value @xmath172 , which can not be exceeded by the digits of any integer modulo @xmath133 , particularly not by those of @xmath140 .",
    "but the most significant digit of @xmath140 can not be larger than @xmath173 as well since @xmath174 .",
    "thus , lucas theorem can not be fulfilled for @xmath175 and @xmath176 , proving the second case .     +    if the first and second cases do not apply then @xmath47 has at least two digits , at least one of them being smaller than @xmath172 .",
    "this guarantees the existence of the least significant such digit , i.e. ,  @xmath158 .",
    "we need to find the greatest @xmath20 , @xmath177 , whose digits @xmath178 , @xmath179 are zero .",
    "this is only possible if @xmath180 is a multiple of @xmath181 .",
    "set @xmath180 to the greatest such multiple smaller than @xmath44 , that is @xmath182 .",
    "let @xmath183 .",
    "this subtraction leads to a carry up to digit @xmath184 and thus @xmath185 for all @xmath179 , i.e. ,  the @xmath186 least significant digits of @xmath187 are maximal .",
    "due to the maximality of @xmath180 there can be no @xmath188 for which both @xmath189 for all @xmath179 and @xmath190 hold . by invalidity of the second case",
    "there can also be no such @xmath191 with @xmath192 .",
    "this shows that lucas theorem is fulfilled for @xmath193 and all @xmath194 , thereby proving the third case .",
    "the maximality of @xmath140 follows from the maximality of @xmath180 .",
    "[ ex : sier1 ] consider the conventional rs code @xmath195 with @xmath196 and @xmath197 .",
    "the characteristic of the code s base field is @xmath198=3 $ ] . for this code , the gsa with multiplicity @xmath199 and list size @xmath200 can correct up to @xmath201 errors .",
    "lemma  [ lemma : zerocolumnexists ] yields @xmath202 , since the binary expansion of @xmath200 is @xmath203",
    ". we can easily check fig .",
    "[ fig : sierpinski3 ] in order to confirm that this is a zero column for @xmath200 .",
    "thus , according to , for any result @xmath204 of the interpolation step of the gsa holds the factorization @xmath205 , where @xmath206 ( from ) and @xmath207 ( from @xmath208 ) .",
    "it follows directly from lemma  [ lemma : zerocolumnexists ] that zero columns can not exist for the special cases @xmath209 ( sudan algorithm ) and @xmath210 ( welch  berlekamp algorithm ) of the gsa .",
    "the statement of the lemma can be interpreted graphically , see fig .",
    "[ fig : zerocolumnexists ] .    in the following",
    ", we will generalize the concept of zero columns to zero columns with resolvable spoilers .",
    "this will reveal additional structure in solutions @xmath40 of problem  [ prob : interpolation ] , i.e. ,  to factorizations of additional univariate polynomials @xmath104 , @xmath211 , besides @xmath153 .",
    "assume that for given gsa parameters @xmath212 and base field @xmath10 with @xmath213 $ ] there exists a zero column @xmath140 in @xmath134 .",
    "further assume there is a column @xmath214 , @xmath215 , in @xmath134 such that @xmath216 we refer to such a column as _ zero column with spoiler at @xmath217 _ , examples are shown in fig .",
    "[ fig : sierpinski2 ] and fig .",
    "[ fig : sierpinski3 ] , respectively .",
    "if @xmath40 is a solution of problem  [ prob : interpolation ] for a received vector @xmath32 then for column @xmath214 , @xmath215 , becomes @xmath218 since all summands except the ones for @xmath219 and @xmath220 are annihilated .",
    "but , according to , the second sum evaluates to zero at all @xmath124 , @xmath43 , since @xmath140 is by assumption a zero column .",
    "we refer to @xmath217 as a _",
    "resolvable spoiler _ for @xmath214 because the sum associated with @xmath217 vanishes . as a result",
    ", we obtain @xmath221 i.e. ,  the @xmath124 , @xmath43 , are roots of multiplicity @xmath152 of @xmath222 and thus it can be factored as @xmath223 where @xmath224\\leq { \\ensuremath{d_{q_{t_1}}}}-n(r - t_0)$ ] .",
    "it is easy to see that if @xmath225 is a spoiler for @xmath226 , @xmath227 , then it is also resolvable .",
    "furthermore , it is easy to see that the concept generalizes to multiple spoilers .",
    "this leads to the following recursive definition :    consider @xmath134 and @xmath26 .",
    "for @xmath228 let @xmath229 and @xmath230 then @xmath127 is a _",
    "zero column with resolvable spoilers _ if and only if @xmath231 .",
    "the basic case is @xmath232 if @xmath140 exists .",
    "note that zero columns are special cases of zero columns with resolvable spoilers where @xmath233 .",
    "the sets of zero columns with resolvable spoilers are non - increasing with @xmath127 , i.e. ,  @xmath234 . we stress that @xmath235 contains all zero columns with resolvable spoilers in @xmath134 , i.e. ,  it is the set that we are interested in .",
    "[ lemma : zerocolumnsspoilers ] let @xmath213 $ ] and @xmath26 , @xmath51 .",
    "if according to lemma  [ lemma : zerocolumnexists ] a maximal zero column @xmath140 of @xmath134 exists then the set of zero columns with resolvable spoilers of @xmath134 is @xmath236 otherwise it is @xmath237 .",
    "assume that @xmath140 exists .",
    "note that it is the maximal zero column not only for @xmath47 but for all @xmath238 since appending an entry to a nonzero column obviously can not make it a zero column .",
    "let us set @xmath239 .",
    "note that in that case , column @xmath140 is degenerate .",
    "we obtain @xmath240 .",
    "if we now advance to column @xmath241 it can either have a spoiler at @xmath242 or no spoiler at all , meaning either @xmath243 or @xmath244 . in both cases @xmath245 and we have @xmath246 . in the same manner ,",
    "column @xmath247 can either have @xmath248 , @xmath249 , @xmath250 , or @xmath251 .",
    "in all cases @xmath252 , resulting in @xmath253 .",
    "this process continues all the way to column @xmath120 and as a result _ all _ spoilers are resolvable and thus _ all _ columns of @xmath134 are zero columns with resolvable spoilers with respect to @xmath239 , eventually resulting in @xmath254 .",
    "now let us gradually increase @xmath255 by one until @xmath256 and recall that @xmath140 stays a maximum zero column . due to the maximality of @xmath140 , any nonzero @xmath257 with @xmath258 is a non - resolvable spoiler and thus such columns @xmath126 must be removed from @xmath259 . but",
    "this means that eventually only the columns @xmath126 for which all @xmath260 , @xmath261 , are zero remain in @xmath262 , which ( after substituting @xmath126 by @xmath127 ) proves the statement .    if @xmath140 does not exist then there exists no zero column and also no resolvable spoilers , hence @xmath263 .",
    "[ ex : sier2 ] lemma  [ lemma : zerocolumnexists ] yields maximal zero column @xmath148 for the setting of example  [ ex : sier1 ] . fig .",
    "[ fig : sierpinski3 ] shows that for @xmath264 we have @xmath265 , i.e. ,  @xmath264 is a zero column with resolvable spoilers and we can set @xmath266 .",
    "for @xmath267 we have @xmath268 and thus it is a zero column with resolvable spoilers as well .",
    "this gives @xmath269 .",
    "for @xmath270 we have @xmath271 and thus it is a zero column with resolvable spoilers as well .",
    "it turns out that for all @xmath272 holds @xmath273 and thus the only zero columns with resolvable spoilers in @xmath150 with respect to @xmath200 are @xmath148 , @xmath264 , @xmath267 , and @xmath270 .",
    "it can be readily checked that lemma  [ lemma : zerocolumnsspoilers ] confirms this result and delivers @xmath274 .",
    "the following map will turn out to be useful in the following , it returns either @xmath127 itself or its greatest spoiler : @xmath275{ll }                   \\max\\{\\mathcal{s}_\\nu^{(\\ell)}\\ } & \\mathcal{s}_\\nu^{(\\ell)}\\neq\\emptyset\\\\                   \\nu & \\mathcal{s}_\\nu^{(\\ell)}=\\emptyset\\\\                 \\end{array}\\right .",
    "\\end{array}\\right .. \\ ] ]    [ thm : sier_factors ] let @xmath14 be a grs code and @xmath105 such that the gsa can correct at most @xmath106 errors .",
    "let further @xmath21 , @xmath22 with @xmath23}}\\leq\\varepsilon_0 $ ] and @xmath24 .",
    "when the gsa is applied to @xmath32 it yields a bivariate result polynomial @xmath34 $ ] whose constituent univariate polynomials @xmath104 , @xmath276 , can be factored as @xmath277},\\ ] ] where @xmath278\\leq { \\ensuremath{d_{q_{\\nu}}}}-n\\left(r - g[\\nu]\\right){\\ensuremath{\\triangleq}}{\\ensuremath{d_{v_{\\nu}}}}$ ] .",
    "let @xmath276 .",
    "since @xmath127 is a zero column with resolvable spoilers , all spoilers @xmath279 with @xmath280 are resolvable , that is , @xmath281 since by definition all terms except the ones weighted by the spoilers vanish , we can write as @xmath282 in order to let the sum over @xmath126 vanish in the case @xmath283 ( i.e. ,  to exploit ) , we must guarantee @xmath284 for all @xmath280 , i.e. ,  @xmath285 . in case",
    "@xmath286 the sum over @xmath126 is empty and thus it is sufficient to guarantee @xmath287 . due to the definition of @xmath288",
    "$ ] we have @xmath289 $ ] in both cases and thus @xmath290 and the @xmath124 , @xmath43 , are roots of multiplicity @xmath291 $ ] of @xmath104 and thus it can be factored as in .",
    "the bound on the degrees of the @xmath292 follows from a comparison of the involved polynomial degrees .    just as the re - encoding prefactors @xmath110 , @xmath107 , from section  [ sec : reenc ] , the _ sierpinski prefactors _",
    "@xmath293}$ ] , @xmath276 , are fixed a - priori and do not depend on the received vector @xmath32 .",
    "[ ex : sier3 ] we have already seen with the help of lemma  [ lemma : zerocolumnexists ] that for the setting of example  [ ex : sier1 ] any result of the polynomial step of the gsa contains a univariate constituent polynomial @xmath294 with factorization @xmath205 , where @xmath206 and @xmath207 . from example",
    "[ ex : sier2 ] we have @xmath295 , i.e. ,  theorem  [ thm : sier_factors ] additionally guarantees factorizations of @xmath296 , @xmath297 , and @xmath298 .",
    "they are @xmath299 with @xmath300 , @xmath301 , and @xmath302 , respectively , because @xmath303=g[6]=g[7]=8 $ ] , @xmath304 , @xmath305 , and @xmath306 .",
    "the situation is depicted in fig .",
    "[ fig : sier_ex ] .",
    "for the zero columns with resolvable spoilers @xmath148 , @xmath264 , @xmath267 , and @xmath270 the summands @xmath260 from lemma  [ lemma : zerocolumnsspoilers ] are enclosed by dashed rectangles and the sets of ( resolvable ) spoilers @xmath307 , @xmath308 , are enclosed by solid rectangles .",
    "the greatest spoilers @xmath288 $ ] are the lowermost entries within the solid rectangles .",
    "we have seen in sections  [ sec : reenc ] and [ sec : sierpinski ] that some of the univariate constituent polynomials of the gsa interpolation step ( problem  [ prob : interpolation ] ) have certain prefactors that are fixed a - priori .",
    "we will show in this section how this knowledge can be exploited in order to simplify solving the interpolation step .",
    "more precisely , we show that the associated linear system of equations in @xmath309 unknowns can be reduced to a linear system of smaller size .",
    "so far , we have treated re - encoding and sierpinski prefactors separately .",
    "this is not practical , one obviously wishes to exploit both types of prefactors jointly whenever possible . since re - encoding and",
    "sierpinski prefactors of a given univariate constituent polynomial @xmath104 , @xmath211 are in general not coprime , we have to calculate the _ combined prefactors _ in the following manner .",
    "[ thm : combined_factors ] let @xmath14 be a grs code , @xmath70 with @xmath71 , and @xmath105 such that the gsa can correct at most @xmath106 errors .",
    "let further @xmath21 , @xmath22 with @xmath23}}\\leq\\varepsilon_0 $ ] and @xmath24 .",
    "when the gsa is applied to @xmath99 $ ] it yields a bivariate result polynomial @xmath34 $ ] whose univariate constituent polynomials @xmath104 can be factored as @xmath310{ll }                   w_\\nu(x)p_\\mathcal{j}(x)^{r-\\nu}p_{\\mathcal{i}\\setminus\\mathcal{j}}(x)^{r - g[\\nu ] } & \\nu < r , \\nu\\in\\mathcal{r}_0^{(\\ell)}\\\\                   u_\\nu(x)p_\\mathcal{j}(x)^{r-\\nu } & \\nu < r,\\nu\\not\\in\\mathcal{r}_0^{(\\ell ) }                 \\end{array}\\right .. \\]]the degrees of the @xmath311 and @xmath111 are bounded by @xmath312\\leq { \\ensuremath{d_{q_{\\nu}}}}-k(r-\\nu)-(n - k)(r - g[\\nu]){\\ensuremath{\\triangleq}}{\\ensuremath{d_{w_{\\nu}}}}\\ ] ] and @xmath109\\leq { \\ensuremath{d_{u_{\\nu}}}}$ ] , respectively .",
    "the second case is a repetition of theorem  [ thm : reenc_factors ] and there is nothing left to prove . as for the first case , we have @xmath70 .",
    "this allows to write the sierpinski prefactors from theorem  [ thm : sier_factors ] as @xmath293}=p_\\mathcal{j}(x)^{r - g[\\nu]}p_{\\mathcal{i}\\setminus\\mathcal{j}}(x)^{r - g[\\nu]}$ ] .",
    "since @xmath313}$ ] is a spoiler , we have @xmath288\\leq \\nu$ ] .",
    "this allows to write the re - encoding prefactors from theorem  [ thm : reenc_factors ] as @xmath314}p_\\mathcal{j}(x)^{\\nu - g[\\nu]}$ ] .",
    "the factor @xmath315}$ ] is common to both factorizations ( sierpinski and re - encoding ) and must be counted not more than once in a combined factorization .",
    "hence , we obtain @xmath316}p_\\mathcal{j}(x)^{\\nu - g[\\nu]}}_{=p_\\mathcal{j}^{r-\\nu}}p_{\\mathcal{i}\\setminus\\mathcal{j}}(x)^{r - g[\\nu]},\\ ] ] which proves the first case .",
    "the degree constraints follow directly from the degree constraints in theorems  [ thm : reenc_factors ] and [ thm : sier_factors ] .    in the following",
    ", it will be convenient to have the sets @xmath317    [ ex : sier4 ] for the setting of example  [ ex : sier1 ] , a solution of the gsa interpolation step problem  [ prob : interpolation ] for the projected received vector @xmath99 $ ] with @xmath318 could be @xmath319 the re - encoding prefactors for @xmath320 according to theorem  [ thm : reenc_factors ] are @xmath321 , where @xmath322 we have @xmath323 and from example  [ ex : sier2 ] we have @xmath324 , @xmath325 , @xmath326 , and , finally , @xmath295 .",
    "@xmath327 since @xmath148 is a zero column . with @xmath303=g[6]=g[7]=g[8]=8",
    "$ ] we obtain the combined prefactors @xmath328 , @xmath329 , @xmath330 , and @xmath331 of @xmath296 , @xmath297 , @xmath298 , and @xmath294 , respectively .",
    "re - encoding- , sierpinski- and combined prefactors for the code under consideration are shown in table  [ tab : sier_example ] .",
    "the table contains upper bounds on the degrees of the quotient polynomials ( after dividing by the prefactors ) for each of the factorizations .",
    "re - encoding and combined prefactors for this example give @xmath332 , while sierpinski prefactors give @xmath333 .",
    "[ 1 ] > + m#1     @xmath127 & bound @xmath334 & re - encoding factorization & bound @xmath335 & sierpinski factorization & bound @xmath336 & combined factorization & bound @xmath335 , @xmath337 + 0 & 199 & @xmath338 & 39 &  & 199 & @xmath338 & 39 + 1 & 184 & @xmath339 & 40 &  & 184 & @xmath339 & 40 + 2 & 169 & @xmath340 & 41 &  & 169 & @xmath340 & 41 + 3 & 154 & @xmath341 & 42 &  & 154 & @xmath341 & 42 + 4 & 139 & @xmath342 & 43 &  & 139 & @xmath342 & 43 + 5 & 124 & @xmath343 & 44 & @xmath344 & 72 & @xmath345 & 24 + 6 & 109 & @xmath346 & 45 & @xmath347 & 57 & @xmath348 & 25 + 7 & 94 & @xmath349 & 46 & @xmath350 & 42 & @xmath351 & 26 + 8 & 79 & @xmath352 & 47 & @xmath353 & 27 & @xmath354 & 27 + 9 & 64 & @xmath355 & 48 &  & 64 & @xmath355 & 48 + 10 & 49 &  & 49 &  & 49 &  & 49 + 11 & 34 &  & 34 &  & 34 &  & 34 + 12 & 19 &  & 19 &  & 19 &  & 19 + 13 & 4 &  & 4 &  & 4 &  & 4 + @xmath356 & 1421 & & 541 & & 1213 & & 461 +    as noted before , gsa interpolation ( problem  [ prob : interpolation ] ) amounts to finding the solution of a linear system of equations .",
    "this can be done naively using gaussian elimination .",
    "several faster methods @xcite have been developed , all of which exploit the _ structure of the involved coefficient matrix_. we conjecture that all these methods can be applied to a reduced linear system of equations , which can be obtained using re - encoding- , sierpinski- , or combined prefactors . the key idea here is to exploit the a - priori known _ structure of the solutions _ , which follows from the a - priori known prefactors .",
    "this can be accomplished using the following lemma .",
    "[ lemma : lincomb_solution ] for an arbitrary field @xmath357",
    "let @xmath358 and @xmath359 be coefficient matrix and vector of constant terms of a linear system of equations @xmath360 that has at least one solution @xmath361 .",
    "let @xmath362 be a linear combination of the solution variables @xmath363 , i.e. ,   @xmath364 where @xmath365 , @xmath366 .",
    "then @xmath367 is the coefficient matrix of a linear system @xmath368 that has a solution @xmath369 .",
    "we can augment the linear system @xmath360 in order to obtain a linear system @xmath370 with @xmath371 and @xmath372 that has a solution @xmath373 .",
    "the last row of this system can be used to annihilate the column vector @xmath374 , which results in @xmath375 this allows to split the system into linear combination and a part @xmath368 that is independent of @xmath376 .",
    "now let us consider the factorization of a univariate constituent polynomial @xmath104 , @xmath377 , into a prefactor ( re - encoding , sierpinski , or combined ) and the corresponding quotient polynomial ( @xmath111 , @xmath292 , or @xmath311 ) .",
    "in order to prescind from the actual type of factorization let us denote the prefactor ( whatever type it is ) by @xmath378 } f_{\\nu , \\mu}x^\\mu$ ] and the corresponding quotient polynomial by @xmath379 } g_{\\nu , \\mu}x^\\mu$ ] with @xmath380\\leq{\\ensuremath{d_{g_{\\nu}}}}$ ] .",
    "this gives @xmath381 for @xmath377 with coefficients @xmath382 where we implicitly used that the @xmath186th coefficient of a polynomial with @xmath383 or @xmath384 the degree of the polynomial is zero .    in order to simplify the following description ,",
    "let us agree on trivial prefactors @xmath385 for all @xmath104 , @xmath386 . in these cases ,",
    "the quotient polynomials are @xmath387 and @xmath388 .",
    "note that the constant term @xmath389 of any prefactor is nonzero due to .",
    "this allows us to write @xmath390 which shows that @xmath391 is a linear combination of the @xmath392 , @xmath393 , and @xmath394 .",
    "what we will do in the following is to exploit for @xmath395 in order to obtain a solvable linear system whose solution comprises the coefficients of @xmath396 ( _ preparation _ ) and then to exploit for @xmath397 in order to dispose of the redundant columns of the coefficient matrix ( _ reduction _ ) . both steps  preparation and reduction",
    " are based on applying lemma  [ lemma : lincomb_solution ] with certain parameters .    for simplicity ,",
    "let us consider @xmath398 .",
    "we can apply the lemma with @xmath399 , and @xmath400 in order to exchange solution variable @xmath401 for @xmath402 .",
    "after that , we can apply the lemma again with @xmath399 , @xmath403 , and @xmath404 in order to exchange @xmath405 for @xmath406 .",
    "the process can be repeated until @xmath407 is replaced by @xmath408 , which closes the preparation step for @xmath409 .",
    "the reduction step is performed by applying lemma  [ lemma : lincomb_solution ] with @xmath410 in order to exchange @xmath411 by @xmath412 .",
    "obviously , this allows to delete the last column from the coefficient matrix .",
    "the process is repeated with @xmath413 in order to exchange @xmath414 by @xmath412 and ( after deletion of the last column ) repeated again until @xmath415 is exchanged by @xmath412 ( allowing to delete the last column ) , which happens for @xmath416 preparation and reduction are then executed for all remaining @xmath127 , i.e. ,  @xmath417 .",
    "algorithm  [ alg : reduction ] cumulates the whole process .    as a result , the original coefficient matrix associated with , whose @xmath309 columns are associated with @xmath418",
    "is converted into a reduced coefficient matrix , whose @xmath419 columns are associated with @xmath420    the quotient polynomials @xmath396 , @xmath377 , as well as the @xmath104 , @xmath386 , can be directly read from any solution vector of the reduced linear system .",
    "the remaining @xmath104 , @xmath377 , can be reconstructed from the corresponding quotient polynomials and the prefactors @xmath421 .",
    "this allows to set up the bivariate polynomial @xmath422 as a solution to the gsa interpolation step .",
    "note that lemma  [ lemma : lincomb_solution ] is formulated such that the leading column of the coefficient matrix @xmath374 and the first solution variable @xmath376 is removed and a new column @xmath423 and a new solution variable is appended .",
    "thus , repeated application of the lemma processes the coefficient matrix from left to right , which makes algorithm  [ alg : reduction ] particularly easy to understand and at the same time saves a few indices in this part of the paper .",
    "a rather technical analysis of the algorithm shows that columns @xmath424 associated with @xmath394 , @xmath377 and @xmath425 , are replaced by @xmath426 and associated with @xmath391 , while columns associated with @xmath394 , @xmath377 and @xmath427 are deleted .",
    "columns associated with @xmath394 , @xmath386 , are simply carried over from the original coefficient matrix .",
    "this allows the following reformulation of the gsa interpolation step :    [ prob : interpolation_reduced ] given a received vector @xmath32 with prefactors @xmath421 , @xmath377 , find a nonzero bivariate polynomial @xmath428\\ ] ] such that @xmath429\\leq{\\ensuremath{d_{g_{\\nu}}}}$ ] and @xmath430\\leq{\\ensuremath{d_{q_{\\nu}}}}$ ] and @xmath431 }     g_{\\nu , \\mu}\\\\      + \\sum_{\\substack{\\nu\\in\\mathcal{f}^c\\\\\\nu\\geq t}}\\binom{\\nu}{t}z^{\\nu - t }     \\sum_{\\mu = s}^{{\\ensuremath{d_{q_{\\nu } } } } }      \\underbrace{\\binom{\\mu}{s}x^{\\mu - s}}_{{\\ensuremath{\\triangleq}}\\mathrm{lut}[s , i , \\nu , \\mu ] }     q_{\\nu , \\mu }      \\bigg|_{(x , z)=\\left(\\alpha^{-i } , y_i\\right)}=0 .",
    "\\end{gathered}\\ ] ]    note that in case of re - encoding or combined prefactors with respect to @xmath70 , @xmath71 , we can replace @xmath432 by @xmath85 in . in that case",
    ", the input vector @xmath32 must be the new received vector after the re - encoding projection , i.e. ,  @xmath433}}$ ] with the actual received vector @xmath434 .",
    "the coefficient matrix associated with the reduced interpolation problem can be set up using algorithm  [ alg : gsa_matrix_reduced ] .",
    "we emphasize that the sums in with summation index @xmath435 are independent of the received vector @xmath32 and thus their addends can be pre - calculated and stored in an @xmath436 lookup table @xmath437 $ ] .",
    "hence , the overlapping double summations that occur for @xmath377 have no negative effect on the complexity of setting up the coefficient matrix .",
    "as mentioned before , a solution @xmath40 of the gsa interpolation step ( problem  [ prob : interpolation ] ) can be recovered from a solution @xmath438 of the reduced gsa interpolation step ( problem  [ prob : interpolation_reduced ] ) using the prefactors .",
    "@xmath40 can then be used as input to the gsa factorization step ( problem  [ prob : factorization ] ) in order to complete the decoding .",
    "a special case of the re - encoding projection that makes the reconstruction of @xmath40 particularly simple and hardware - friendly has been introduced in @xcite . a _ reduced _ gsa factorization step that could operate directly on @xmath438 in order to construct the result list",
    "was proposed in @xcite .",
    "the focus of this paper is on interpolation , which is why we do not delve into the details of factorization .",
    "[ ex : matrix1 ] for the setting of example  [ ex : sier1 ] , table  [ tab : sier_example ] delivers a sum of univariate constituent degrees of @xmath439 , which means that the number of unknowns in the original gsa interpolation step is @xmath440 .",
    "in contrast to this , we obtain @xmath441 unknowns for the reduced gsa interpolation step presented in this section if only sierpinski prefactors are used , @xmath442 unknowns if only re - encoding prefactors are used , and a mere @xmath443 unknowns if both types of prefactors are combined .",
    "the reduced coefficient matrices for the latter three cases can be set up using algorithm  [ alg : gsa_matrix_reduced ] and the following inputs :    1 .",
    "sierpinski : @xmath444 , @xmath333 , @xmath445 and @xmath446}$ ] as in theorem  [ thm : sier_factors ] .",
    "re - encoding : @xmath318 , @xmath332 , @xmath447 and @xmath448 as in theorem  [ thm : reenc_factors ] .",
    "3 .   combined : @xmath318 , @xmath332 , either @xmath449 , @xmath450}$ ] or @xmath447 , @xmath448 as in theorem  [ thm : combined_factors ] .",
    "[ ex : matrix2 ] it turns out that sierpinski prefactors work particularly well for the two conventional rs codes @xmath451 and @xmath452 considered by ktter and vardy in @xcite .",
    "the gsa for @xmath453 can correct up to @xmath454 errors with multiplicity @xmath455 and list size @xmath456 .",
    "this requires solving a linear system in @xmath457 unknowns .",
    "sierpinski prefactors alone reduce the system to @xmath458 unknowns , re - encoding alone to @xmath459 unknowns .",
    "when both techniques are combined , the number of unknowns shrinks to @xmath460 .",
    "a practically probably more relevant example is the gsa with multiplicity @xmath461 and list size @xmath462 for @xmath463 , it can correct up to @xmath464 errors , which is four errors beyond half its minimum distance . the associated linear system has @xmath465 unknowns , which can be diminished to @xmath466 unknowns using sierpinski prefactors alone , @xmath467 unknowns using re - encoding alone , and a mere @xmath468 unknowns when both techniques are combined .",
    "this is only slightly more than the @xmath469 unknowns that are required to decode up to @xmath470 errors with multiplicity @xmath471 and list size @xmath472 using re - encoding prefactors .",
    "hence , the newly introduced combined prefactors ( based on sierpinski prefactors ) allow to correct two additional errors at the comparatively low cost of having @xmath473 additional unknowns .",
    "we introduced the concept of a - priori known prefactors in the gsa interpolation step and showed how the well - known re - encoding projection can be interpreted in this framework .",
    "our main contribution is section  [ sec : sierpinski ] , where we introduced the new type of sierpinski prefactors , which exist for a fairly wide range of code and gsa parameters . as opposing to re - encoding prefactors",
    ", sierpinski prefactors do not require a modification of the received vector since they are based on a simple property of the ground field . in general , prefactors allow to reduce the linear system of equations that is associated with the gsa interpolation step ,",
    "i.e. ,  they allow to reconstruct a solution of the original big system from the solution of a reduced smaller system .",
    "the reduction of the linear system for re - encoding prefactors , sierpinski prefactors , and the ( practically most relevant ) combination of both has been described in section  [ sec : factors ] .",
    "we stress that solving the reduced linear system using gaussian elimination is straightforward with complexity cubic in @xmath1 .",
    "however , it should not be too hard to adapt techniques like those from @xcite for solving the reduced system with _ quadratic _",
    "complexity in @xmath1 since the structure of the original coefficient matrix is only marginally obstructed by the simple linear operator associated with the matrix reduction algorithm  [ alg : reduction ] . in similar manner",
    ", it should be possible to adapt ktter interpolation @xcite such that arbitrary prefactors can be exploited .",
    "this would be a generalization of results from @xcite .",
    "we leave these problems for future work .",
    "another way to generalize our results would be to consider varying multiplicities for the received symbols , e.g. ,  in the context of algebraic soft - decision decoding with the ktter  vardy algorithm @xcite .",
    "note that lines  [ algline : gsa_matrix_reduced : betainit ] , [ algline : gsa_matrix_reduced : deltaloop ] , and [ algline : gsa_matrix_reduced : betaincr ] in algorithm  [ alg : gsa_matrix_reduced ] can be deleted if @xmath474 in line  [ algline : gsa_matrix_reduced : setval ] is replaced by @xmath437 $ ] as in .",
    "the algorithm admits a number of improvements that we ignored for the sake of slender pseudo code , e.g. ,  the binomial coefficient @xmath135 can be calculated directly at the beginning of the @xmath127-loop in line  [ algline : gsa_matrix_reduced : nuloop ] and the rest of the loop can be skipped in case it is zero modulo @xmath133 .    solving the linear system with a reduced coefficient matrix obtained by first calculating the full coefficient matrix with algorithm  [ alg : gsa_matrix ] and then reducing it with algorithm  [ alg : reduction ] results in the same solution ( space ) as directly solving the linear system with reduced coefficient matrix as obtained from algorithm  [ alg : gsa_matrix_reduced ] .",
    "@xmath475 zero matrix over @xmath10 with @xmath476 rows and @xmath477 columns @xmath478 ( ) @xmath479 from @xmath120 to @xmath480 ( ) @xmath126 from @xmath120 to @xmath481 ( ) @xmath482 from @xmath120 to @xmath483 @xmath484 ( ) @xmath127 from @xmath126 to @xmath47 ( ) @xmath435 from @xmath479 to @xmath485 @xmath486 @xmath487 @xmath488    ( ) @xmath127 from @xmath120 to @xmath47 calculate @xmath421 and @xmath485 ( ) @xmath489 , @xmath490 @xmath475 zero matrix over @xmath10 with @xmath491 rows and @xmath492 columns @xmath478 ( ) @xmath479 from @xmath120 to @xmath480 ( ) @xmath126 from @xmath120 to @xmath481 @xmath493 ( ) @xmath482 from @xmath120 to @xmath483 ( ) @xmath494 @xmath495 @xmath496 ( ) @xmath127 from @xmath126 to @xmath47 @xmath497 ( ) @xmath435 from @xmath120 to @xmath485 ( ) @xmath498 from @xmath120 to @xmath499 @xmath500 @xmath501 @xmath502 @xmath503",
    "the author is grateful to frank r.  kschischang for stimulating discussions and valuable comments on the manuscript .",
    "r.  koetter , j.  ma , a.  vardy , and a.  ahmed , `` efficient interpolation and factorization in algebraic soft - decision decoding of reed ",
    "solomon codes , '' in _ international symposium on information theory .",
    "isit 2003_.1em plus 0.5em minus 0.4emieee , jun .",
    "2003 , p. 365 , doi : http://dx.doi.org/10.1109/isit.2003.1228381[10.1109/isit.2003.1228381 ] .",
    "j.  massey , `` shift - register synthesis and bch decoding , '' _ information theory , ieee transactions on _ , vol .",
    "15 , no .  1 ,",
    "122127 , jan .",
    "1969 , doi : http://dx.doi.org/10.1109/tit.1969.1054260[10.1109/tit.1969.1054260 ] .",
    "y.  sugiyama , m.  kasahara , s.  hirasawa , and t.  namekawa , `` a method for solving key equation for decoding goppa codes , '' _ information and control _ , vol .",
    "27 , no .  1 ,",
    "pp . 8799 , jan .",
    "1975 , doi : http://dx.doi.org/10.1016/s0019-9958(75)90090-x[10.1016/s0019-9958(75)90090-x ] .",
    "u.  k. sorger , `` a new reed  solomon code decoding algorithm based on newton s interpolation , '' _ ieee transactions on information theory , _ , vol .",
    "39 , no .  2 ,",
    "358365 , mar .",
    "1993 , doi : http://dx.doi.org/10.1109/18.212267[10.1109/18.212267 ] .",
    "gemmell and m.  sudan , `` highly resilient correctors for polynomials , '' _ information processing letters _ , vol .",
    "43 , no .  4 , pp .",
    "169174 , sep .",
    "1992 , doi : http://dx.doi.org/10.1016/0020-0190(92)90195-2[10.1016/0020-0190(92)90195-2 ] .",
    "m.  sudan , `` decoding of reed ",
    "solomon codes beyond the error - correction bound , '' _ journal of complexity _ , vol .  13 , no .  1 ,",
    "180193 , mar .",
    "1997 , doi : http://dx.doi.org/10.1006/jcom.1997.0439[10.1006/jcom.1997.0439 ] .",
    "v.  guruswami and m.  sudan , `` improved decoding of reed  solomon and algebraic - geometry codes , '' _ ieee transactions on information theory _",
    "45 , no .  6 , pp . 17571767 , sep .",
    "1999 , doi : http://dx.doi.org/10.1109/18.782097[10.1109/18.782097 ] .",
    "v.  olshevsky and m.  a. shokrollahi , _ a displacement approach to decoding algebraic codes _ , ser .",
    "contemporary mathematics ( american mathematical society).1em plus 0.5em minus 0.4emams / siam , 2003 , vol .",
    "265292 .",
    "a.  zeh , c.  gentner , and d.  augot , `` an interpolation procedure for list decoding reed-solomon codes based on generalized key equations , '' _ ieee transactions on information theory _ ,",
    "57 , no .  9 , pp . 59465959 , 2011 ,",
    "doi : http://dx.doi.org/10.1109/tit.2011.2162160[10.1109/tit.2011.2162160 ] .",
    "m.  alekhnovich , `` linear diophantine equations over polynomials and soft decoding of reed  solomon codes , '' in _ proceedings of the 43rd symposium on foundations of computer science _ , ser .",
    "focs 02.1em plus 0.5em minus 0.4emwashington , dc , usa : ieee computer society , 2002 , pp .",
    "439448 .    p.",
    "v. trifonov , `` efficient interpolation in the guruswami-sudan algorithm , '' _ ieee transactions on information theory _ , vol .",
    "56 , no .  9 , pp . 43414349 , sep .",
    "2010 , doi : http://dx.doi.org/10.1109/tit.2010.2053901[10.1109/tit.2010.2053901 ] .",
    "w.  j. gross , f.  r. kschischang , r.  koetter , and p.  g. gulak , `` towards a vlsi architecture for interpolation - based soft - decision reed  solomon decoders , '' _ the journal of vlsi signal processing _ , vol .",
    "39 , no .  1 ,",
    "93111 , jan .",
    "2005 , doi : http://dx.doi.org/10.1023/b:vlsi.0000047274.68702.8d[10.1023/b:vlsi.0000047274.68702.8d ] .",
    "r.  koetter , j.  ma , and a.  vardy , `` the re - encoding transformation in algebraic list - decoding of reed ",
    "solomon codes , '' _ ieee transactions on information theory _ , vol .",
    "57 , no .  2 ,",
    "633647 , feb .",
    "2011 , doi : http://dx.doi.org/10.1109/tit.2010.2096034[10.1109/tit.2010.2096034 ] .",
    "i.  s. reed and g.  solomon , `` polynomial codes over certain finite fields , '' _ journal of the society for industrial and applied mathematics _ , vol .  8 , no .  2 , pp . 300304 , 1960 ,",
    "doi : http://dx.doi.org/10.1137/0108018[10.1137/0108018 ] .",
    "p.  delsarte , `` on subfield subcodes of modified reed  solomon codes ( corresp . ) , '' _ ieee transactions on information theory , _ ,",
    "21 , no .  5 ,",
    "pp . 575576 , sep .",
    "1975 , doi : http://dx.doi.org/10.1109/tit.1975.1055435[10.1109/tit.1975.1055435 ] .",
    "y.  wu , `` new list decoding algorithms for reed-solomon and bch codes , '' _ ieee transactions on information theory _ , vol .  54 , no .  8 , pp . 36113630 , aug .",
    "2008 , doi : http://dx.doi.org/10.1109/tit.2008.926355[10.1109/tit.2008.926355 ] .",
    "h.  hasse , `` theorie der hheren differentiale in einem algebraischen funktionenkrper mit vollkommenem konstantenkrper bei beliebiger charakteristik . ''",
    "_ j. reine angew .",
    "175 , pp . 5054 , 1936 .",
    "a.  zeh , c.  gentner , and m.  bossert , `` efficient list - decoding of reed ",
    "solomon codes with the fundamental iterative algorithm , '' in _ information theory workshop 2009 .",
    "itw 2009_.1em plus 0.5em minus 0.4emieee , oct .",
    "2009 , pp . 130134 ,",
    "doi : http://dx.doi.org/10.1109/itw.2009.5351241[10.1109/itw.2009.5351241 ] .",
    "r.  m. roth and g.  ruckenstein , `` efficient decoding of reed ",
    "solomon codes beyond half the minimum distance , '' _ ieee transactions on information theory _ , vol .",
    "46 , no .  1 ,",
    "246257 , jan .",
    "2000 , doi : http://dx.doi.org/10.1109/18.817522[10.1109/18.817522 ] .",
    "j.  justesen and t.  hholdt , _ a course in error - correcting codes_.1em plus 0.5em minus 0.4emzrich : european mathematical society , feb .",
    "[ online ] .",
    "available : http://www.worldcat.org/isbn/3037190019        c.  senger , `` the periodicity transform in algebraic decoding of reed ",
    "solomon codes , '' in _ communication , control , and computing ( allerton ) , 2012 50th annual allerton conference on_.1em plus 0.5em minus 0.4em ieee , oct .",
    "2012 , pp . 168175 ,",
    "doi : http://dx.doi.org/10.1109/allerton.2012.6483214[10.1109/allerton.2012.6483214 ] .",
    "a.  ahmed , r.  koetter , and n.  r. shanbhag , `` vlsi architectures for soft - decision decoding of reed  solomon codes , '' _ ieee transactions on information theory _ , vol .",
    "57 , no .  2 ,",
    "648667 , feb .",
    "2011 , doi : http://dx.doi.org/10.1109/tit.2010.2095210[10.1109/tit.2010.2095210 ] .",
    "r.  koetter and a.  vardy , `` algebraic soft - decision decoding of reed ",
    "solomon codes , '' _ ieee transactions on information theory _ , vol .",
    "49 , no .  11 , pp . 28092825 ,",
    "2003 , doi : http://dx.doi.org/10.1109/tit.2003.819332[10.1109/tit.2003.819332 ] ."
  ],
  "abstract_text": [
    "<S> the concept of prefactors is considered in order to decrease the complexity of the guruswami  </S>",
    "<S> sudan interpolation step for generalized reed  solomon codes . </S>",
    "<S> it is shown that the well - known re - encoding projection due to ktter et al . </S>",
    "<S> @xcite leads to one type of such prefactors . </S>",
    "<S> the new type of sierpinski prefactors is introduced . </S>",
    "<S> the latter are based on the fact that many binomial coefficients in the hasse derivative associated with the guruswami  </S>",
    "<S> sudan interpolation step are zero modulo the base field characteristic . </S>",
    "<S> it is shown that both types of prefactors can be combined and how arbitrary prefactors can be used to derive a _ reduced _ guruswami  sudan interpolation step .    </S>",
    "<S> generalized reed  </S>",
    "<S> solomon codes , guruswami  </S>",
    "<S> sudan algorithm , list decoding , polynomial interpolation , pascal triangle , sierpinski gasket , binomial coefficients </S>"
  ]
}