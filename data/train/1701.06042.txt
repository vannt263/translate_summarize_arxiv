{
  "article_text": [
    "in the study of mixing time of markov chains , most of the focus has been on determining the asymptotics of the worst - case mixing time , while relatively little is known about the relative effect of different initial conditions .",
    "the latter is quite natural from an algorithmic perspective on sampling , since one would ideally initiate the dynamics from the fastest initial condition .",
    "however , until recently , the tools available for analyzing markov chains on complex systems , such as the ising model , were insufficient for the purpose of comparing the effect of different starting states ; indeed , already pinpointing the asymptotics of the worst - case state for glauber dynamics for the ising model can be highly nontrivial .    in this paper",
    "we compare different initial conditions for the ising model on the cycle . in earlier work  @xcite",
    ", we analyzed three different initial conditions .",
    "the all - plus state is provably the worst initial condition up to an additive constant .",
    "another is a quenched random condition chosen from @xmath4 , the uniform distribution on configurations , which with high probability has a mixing time which is asymptotically as slow .",
    "a third initial condition is an annealed random condition chosen from @xmath4 , i.e. , to start at time 0 from the uniform distribution , which is asymptotically twice as fast as all - plus .",
    "here we consider two natural deterministic initial configurations .",
    "the first is the alternating sequence @xmath5 which we will show is asymptotically the _ fastest _ deterministic initial condition  yet strictly slower than starting from the annealed random condition  for all @xmath6 ( at @xmath7 they match ) .",
    "the second is the bi - alternating sequence @xmath8 for convenience we will assume that @xmath9 is a multiple of 4 , which ensures that the configurations are semi - translation invariant and turns both sequences into eigenvectors of the transition matrix of simple random walk on the cycle .",
    "( this is not necessary for the main result but leads to cleaner analysis . )    in what follows , set @xmath10 , and let @xmath11 denote the time it takes the dynamics to reach total variation distance at most @xmath12 from stationarity , starting from the initial condition @xmath13 .",
    "( plot ) at ( 0,0 ) , compared to the known behavior of worst - case ( all - plus ) and random initial conditions.,title=\"fig:\",scaledwidth=70.0% ] ;    at ( -0.01,0.215 ) @xmath14 ; at ( -0.01,0.36 ) @xmath15 ; at ( 0,0.94 ) @xmath16 ;    at ( -0.01,0.286 ) @xmath17 ; ( 0.032,0.285 )  ( 0.41,0.285 ) ;    at ( 0.426,0.04 ) @xmath18 ; at ( 0.648,0.04 ) @xmath19 ; at ( .96,0.03 ) @xmath0 ;    at ( 0.765,0.86 ) _ all - plus / quenched _ ; at ( 0.75,0.47 ) _ bi - alternating _ ; at ( 0.53,0.26 ) _ annealed _ ; at ( 0.115,0.31 ) _ alternating _ ;    [ fig : initial ]    [ mainthm - trans ] for every @xmath20 and @xmath21 there exist @xmath22 and @xmath23 such that the following hold for glauber dynamics for the ising model on the cycle @xmath24 at inverse - temperature @xmath0 for all @xmath25 .",
    "a.   alternating initial condition : @xmath26 b.   bi - alternating initial condition : @xmath27    surprisingly , the mixing time for the alternating initial condition begins as actually _",
    "faster _ than the infinite temperature model : it _ decreases _ as a function of @xmath0 before increasing when @xmath28 .",
    "the following theorem summarizes the bounds we proved in  @xcite for the all - plus and random initial conditions .",
    "see figure  [ fig : initial ] for the relative performance of all these different initial conditions .",
    "[ mainthm - previous - bounds ] in the same setting of theorem  [ mainthm - trans ] , the following hold .",
    "a.   all - plus initial condition @xmath29 : @xmath30 b.   quenched random initial condition : @xmath31 c.   annealed random initial condition : @xmath32    ( note that , in the case of the all - plus initial conditions , the mixing time @xmath33 is known in higher precision : it was shown  @xcite to be within an additive constant ( depending on @xmath12 and @xmath0 ) of @xmath34 . )    the upper bounds on the mixing times in theorem  [ mainthm - trans ] rely on the information percolation framework introduced by the authors in  @xcite . the asymptotically matching lower bounds in that theorem are derived from two test functions : the autocorrelation function , which for instance matches our upper bound on the alternating initial condition for @xmath3 ; and the hamiltonian test function , which gives rise to the following lower bound on _ every deterministic initial condition_.    [ p : autolowerb ] let @xmath35 be glauber dynamics for the ising model on @xmath24 at inverse - temperature @xmath0 . for every sequence of deterministic initial conditions",
    "@xmath13 , the dynamics at time @xmath36 is at total variation distance @xmath37 from equilibrium ; that is , @xmath38    as a consequence of this result and theorem  [ mainthm - trans ] , part  ( i ) , we see that the initial condition @xmath39 is indeed the optimal _ deterministic _ one in the range @xmath40 , and that @xmath41 marks the smallest @xmath0 where a deterministic initial condition can first match the performance of the annealed random condition .",
    "the mixing time estimates in theorem  [ mainthm - trans ] ( as well as those in theorem  [ mainthm - previous - bounds ] ) imply , in particular , that glauber dynamics for the ising model on the cycle , from the respective starting configurations , exhibits the _ cutoff phenomenon_a sharp transition in its distance from stationarity , which drops along a negligible time period known as the _ cutoff window _ ( here , @xmath42 , vs.  @xmath16 which is of order @xmath43 ) from near its maximum to near 0 . until recently , only relatively few occurrences of this phenomenon , that was discovered by aldous and diaconis in the early 1980 s ( see  @xcite ) , were rigorously verified , even though it is believed to be widespread ( e.g. , peres conjectured  @xcite*conjecture  1,@xcite*23.2 cutoff for the ising model on any sequence of transitive graphs when the mixing time is of order @xmath43 ) ; see  @xcite*18 .    for the ising model on the cycle ,",
    "the longstanding lower and upper bounds on @xmath16 from a worst - case initial condition differed by a factor of 2in our notation , @xmath44 and @xmath45while cutoff was conjectured to occur ( see , e.g. ,  @xcite*theorem  15.4 , as well as  @xcite*pp",
    ".  214,248 and question  8 in p.  300 ) .",
    "this was confirmed in  @xcite , where the above lower bound was shown to be tight , via a proof that relied on log - sobolev inequalities and applied to @xmath46 , for any dimension @xmath47 , so long as the system features a certain decay - of - correlation property known as strong spatial mixing .",
    "this result was reproduced in  @xcite ( with a finer estimate for the cutoff window ) via the new information percolation method .",
    "soon after , a remarkably short proof of cutoff for the cycle  crucially hinging on the correspondence between the one - dimensional ising model and the `` noisy voter '' model  was obtained by cox , peres and steif  @xcite .",
    "it is worthwhile noting that the arguments both in  @xcite and in  @xcite are tailored to worst - case analysis , and do not seem to be able to treat specific initial conditions as examined here . in contrast",
    ", the information percolation approach does allow one to control the subtle effect of various initial conditions on mixing .    to conclude this section",
    ", we conjecture that proposition  [ p : autolowerb ] also holds for @xmath48 , i.e. , that @xmath39 is asymptotically fastest among all the deterministic initial conditions at all @xmath20 .",
    "we further conjecture that the obvious generalization of @xmath39 to @xmath49 for @xmath50 ( a checkerboard for @xmath51 ) is the analogous fastest deterministic initial condition throughout the high - temperature regime .",
    "in this section we define the update support and use the framework of information percolation ( see the papers  @xcite as well as the survey paper  @xcite for an exposition of this method ) to upper bound the total variation distance with alternating and bi - alternating initial conditions .      the ising model on a finite graph @xmath52 with vertex - set @xmath53 and edge - set",
    "@xmath54 is a distribution over the set of configurations @xmath55 ; each @xmath56 is an assignment of plus / minus _ spins _ to the sites in @xmath53 , and the probability of @xmath57 is given by the gibbs distribution @xmath58 where @xmath59 is a normalizer ( the partition - function ) and @xmath0 is the inverse - temperature , here taken to be non - negative ( ferromagnetic ) .",
    "the ( continuous - time ) heat - bath glauber dynamics for the ising model is the markov chain ",
    "reversible w.r.t .",
    "the ising measure @xmath60where each site is associated with a rate-1 poisson clock , and as the clock at some site @xmath61 rings , the spin of @xmath61 is replaced by a sample from the marginal of @xmath60 given all other spins .",
    "see  @xcite for an extensive account of this dynamics . in this paper",
    "we focus on the graph @xmath62 and will let @xmath35 denote the glauber dynamics markov chain on @xmath52 .",
    "an important notion of measuring the convergence of a markov chain @xmath63 to its stationarity measure @xmath60 is its total - variation mixing time , denoted @xmath64 for a precision parameter @xmath21 . from initial condition @xmath13",
    "we denote @xmath65 and the overall mixing time as measured from a worst - case initial condition is @xmath66 where here and in what follows @xmath67 denotes the probability given @xmath68 , and the total - variation distance @xmath69 is defined as @xmath70 .",
    "the dynamics can be viewed as a deterministic function of @xmath71 and a random `` update sequence '' of the form @xmath72 , where @xmath73 are the update times ( the ringing of the poisson clocks ) , the @xmath74 s are i.i.d .  uniformly chosen sites ( which clocks ring ) , and the @xmath75 s are i.i.d .  uniform variables on @xmath76 $ ] ( to generate coin tosses ) .",
    "there are a variety of ways to encode such updates but in the case of the one - dimensional model there is a particularly useful one .",
    "we add an extra variable @xmath77 which is a randomly selected neighbor of @xmath75 then given the sequence of @xmath78 the updates are processed sequentially as follows : set @xmath79 ; the configuration @xmath35 for all @xmath80 ( @xmath81 ) is obtained by updating the site @xmath74 via the unit variable as follows : if @xmath82 update the spin at @xmath74 to a uniformly random value and with probability @xmath83 set it to the spin of @xmath77 .    with this description of the dynamics , we can work backwards to describe how the configurations at time @xmath84 ( or at any intermediate time ) depend on the initial condition .",
    "_ the update support function _",
    ", denoted @xmath85 , as introduced in  @xcite , is the random set whose value is the minimal subset @xmath86 which determines the spins of @xmath87 given the update sequence along the interval @xmath88 $ ] .",
    "we now describe the support of a vertex @xmath89 as it evolves backwards in time from @xmath90 to @xmath91 .",
    "initially , @xmath92 ; then , updates in reverse chronological order alter the support : given the next update @xmath78 , if @xmath93 and @xmath94 then @xmath95 is set to @xmath96 , and if @xmath97 then it is set to @xmath98 . thus , backwards in time @xmath99 performs a continuous - time simple random walk with jump rate @xmath83 which is killed at rate @xmath100 .",
    "we refer to the full trajectory of the update support of a vertex as the _ history _ of the vertex .",
    "the survival time for a walk is exponential and so for @xmath101 , @xmath102 for general sets @xmath87 we have that @xmath103 and taken together the collection of the update supports of the vertices are a set of coalescing killed continuous - time random walks .",
    "a key use of these histories is to effectively bound the spread of information , as achieved by the following lemma .",
    "[ l : spread ] for any @xmath104 we have that @xmath105    by equation   we have that @xmath106 = o(n^{-10})$ ] so it is sufficient to show that @xmath107 this probability is bounded above by the probability of a rate @xmath83 continuous - time random walk to make at least @xmath108 jumps by time @xmath109 .",
    "this is exactly the probability that a poisson with mean @xmath110 is at least @xmath108 , which satisfies the required bound by standard tail bounds .",
    "we will consider the dynamics run up to time @xmath84 and derive an upper bound on its mixing time .",
    "we will first estimate the total variation distance not of the full dynamics but simply at a single vertex from initial conditions @xmath111 and @xmath112 .",
    "[ l : singlepoint ] for @xmath113 we have that , @xmath114    we will begin with the case of initial condition @xmath111 .",
    "of course @xmath115 is the uniform measure on  @xmath116 .",
    "the history @xmath117 is killed before time @xmath118 with probability @xmath119 and on this event is uniform on @xmath116 .",
    "condition that it survives to time @xmath118 and let @xmath120 .",
    "this is simply a continuous - time random walk on @xmath116 which switches state at rate @xmath83 .",
    "thus , @xmath121 it therefore follows that @xmath122 , and altogether , @xmath123 the case of @xmath112 follows similarly , with the exception that @xmath124 has jump rate @xmath125 since it only switches sign with probability @xmath126 each step .      in this subsection",
    "we analyse the geometry of the update support similarly to  @xcite in order to approximate the markov chain as a product measure .",
    "let @xmath127 and define the support time as @xmath128 .",
    "by lemma  [ l : spread ] we expect the histories to not travel `` too far '' along the time - interval @xmath84 to @xmath129 ; precisely , if we define @xmath130 as the event @xmath131 then by lemma  [ l : spread ] , @xmath132 the following event says that the support at time @xmath129 clusters into small well separated components .",
    "let @xmath133 be the event that there exists a set of intervals @xmath134 that ( i ) cover the support : @xmath135 ( ii ) have logarithmic size : @xmath136 and ( iii ) are well - separated : @xmath137    we have that @xmath138 .",
    "define the following intervals on @xmath24 : @xmath139 restricting @xmath130 to @xmath140 , we let @xmath141 since @xmath142 we have that @xmath143 by lemma  [ eq : cbbound ] .",
    "next , let @xmath144 be the event @xmath145 by a union bound and equation  , we have that @xmath146 and so @xmath147 moreover , conditional on @xmath148 the events @xmath144 are conditionally independent since the history of @xmath149 is determined by the updates within the set @xmath150 which are disjoint . hence , for all",
    "@xmath151 , @xmath152 hence , @xmath153 taking a union bound over all @xmath151 we have that @xmath154 we have thus arrived at the following : with probability at least @xmath155 , for every @xmath156 there exists a block of @xmath157 consecutive vertices whose histories are killed before @xmath129 within distance @xmath158 on both the right and the left , implying the existence of the decomposition and completing the lemma .    when the event @xmath133 holds we will assume that there is some canonical choice of the @xmath159 s .",
    "we set @xmath160 on the event that both @xmath161 and @xmath130 hold , the sets @xmath162 are disjoint , and satisfy @xmath163 we will make use of lemma  3.3 from @xcite , a special case of which is the following .    [",
    "l : updatesuppinq ] for any @xmath164 and any set of vertices @xmath165",
    "we have that @xmath166\\ , .\\ ] ]    using this result , we have that @xmath167\\ , .\\ ] ]      on the event @xmath168 we couple @xmath169 and @xmath170 with product measures .",
    "since the @xmath162 s depend only on the updates along the interval @xmath171 $ ] and are independent of the dynamics up to time @xmath129 we will treat the @xmath162 as fixed deterministic sets satisfying  . let @xmath172 be a product measure of @xmath173 copies of @xmath60 . then",
    ", by the exponential decay of correlation of the one - dimensional ising model , @xmath174 next , let @xmath175 be @xmath173 independent copies of the dynamics up to time @xmath129 .",
    "define the event @xmath176 and for each @xmath177 define the analogous event @xmath178 where @xmath179 is the support function for the dynamics @xmath180 . from lemma",
    "[ l : spread ] , together with a union bound , we infer that @xmath181 let @xmath182 denote @xmath35 conditioned on @xmath183 and , similarly , let @xmath184 denote @xmath180 conditioned on @xmath185 .",
    "then @xmath186 and so @xmath187 now , since the laws of the @xmath188 for distinct @xmath151 depend on disjoint sets of updates , they are independent and equal in distribution to @xmath189 , hence @xmath190 since @xmath191 is @xmath192 conditioned on @xmath183 , @xmath193 combining the previous three equations we find that @xmath194 thus , to show that @xmath195 it is sufficient to prove that @xmath196      let @xmath198 , and for each @xmath151 set @xmath199 with @xmath200 if @xmath201 .",
    "first we bound the right tail of the distribution of @xmath77 .",
    "if @xmath202 then at least @xmath203 histories from @xmath162 have survived to time @xmath204 and not intersected .",
    "hence , by equation  , @xmath205 therefore , for @xmath206 we see that @xmath207 let @xmath208 denote the event that for all @xmath151 we have that @xmath209 . by  , @xmath210 and",
    "so @xmath211 implies that @xmath212 . on the event @xmath208",
    ", we define @xmath213 applying lemma  [ l : updatesuppinq ] we have",
    "that @xmath214    [ l : uitvdist ] there exists @xmath215 such that , for every @xmath216 and @xmath217 , @xmath218   & x_0 = x^{{\\mathrm{alt}}}\\,,\\\\ \\noalign{\\medskip } c   { t_{-}}\\exp\\left[-({t_{-}}-s_i )   \\min\\{2\\theta,1\\}\\right ]   & x_0 = x^{{\\mathrm{blt}}}\\ , . \\end{cases}\\end{aligned}\\ ] ]    we will consider the case of @xmath111 , the proof for @xmath112 follows similarly .",
    "let @xmath219 denote the first time the history coalesces to a single point : @xmath220 with the convention @xmath221 if @xmath222",
    ". by equation  , @xmath223 denote the vertex @xmath224 . by lemmas  [ l : singlepoint ] and  [ l : updatesuppinq ] we have",
    "that @xmath225 \\nonumber\\\\   & \\leq { \\mathbb{e}}\\left [ e^{-(2 - \\theta)({t_{-}}-s_i - r_i ) } \\;\\big|\\ ; u_i , s_i\\right]\\ , .",
    "\\label{eq : singleptbound}\\end{aligned}\\ ] ] we estimate the right hand side as follows : @xmath226 & \\leq \\sum_{k=1}^{{\\lceil{t_{-}}-s_i\\rceil } } { \\mathbb{p}}\\left(r_i \\in ( k-1,k)\\right ) e^{-(2 - \\theta)({t_{-}}-s_i - k)}\\nonumber\\\\ & \\leq \\sum_{k=1}^{{\\lceil{t_{-}}-s_i\\rceil } } { l \\choose 2 } e^{-2 ( k-1)\\theta } e^{-(2 - \\theta)({t_{-}}-s_i - k)}\\nonumber\\\\ & \\leq c   { t_{-}}e^{-({t_{-}}-s_i )   \\min\\{2\\theta,2-\\theta\\ } } \\,,\\end{aligned}\\ ] ] where the final inequality follows by taking the maximal term in the sum .",
    "this , together with  , completes the proof of the lemma .",
    "we now appeal to the @xmath227-to-@xmath197 reduction developed in  @xcite .",
    "recall that the @xmath197-distance on measures is defined as @xmath228 and set @xmath229 -   \\pi^{(i)}|_{u_i } \\right\\|^2_{l^2(\\pi^{(i)}|_{u_i})}\\,.\\end{aligned}\\ ] ] by  @xcite*proposition  7 , @xmath230 we are now ready to prove the upper bound for the main theorem .",
    "again we focus on the case of @xmath111 . set @xmath231 with this choice of @xmath84 we have that @xmath232 and so , by equations  , and  , it is sufficient to show that @xmath233\\to 0\\ , .\\ ] ] since each vertex is either plus or minus with probability that is uniformly bounded below by @xmath234 , given any choice of conditioning on the other vertices , we have that @xmath235 comparing the @xmath227 and @xmath197 bounds we have that for any measures @xmath236 and set @xmath75 , @xmath237 thus , by lemma  [ l : uitvdist ] , @xmath238 & \\leq { \\mathbb{e}}\\bigg [ 2^l \\left ( \\frac{e^{-2\\beta } + e^{2\\beta}}{e^{-2\\beta } } \\right)^l \\sum_{i=1}^m \\left\\|{\\mathbb{p}}_{x_0 } [ ( x^{(i)}_{{t_{-}}-s_i}(u_i ) \\in \\cdot \\mid u_i , s_i ] -   \\pi^{(i)}|_{u_i } \\right\\|^2_{{\\textsc{tv}}}\\bigg]\\nonumber\\\\ & \\leq   2^l \\left ( \\frac{e^{-2\\beta } + e^{2\\beta}}{e^{-2\\beta } } \\right)^l n { \\mathbb{e}}\\bigg[\\left(c   { t_{-}}e^{-({t_{-}}-s_i )   \\min\\{2\\theta,2-\\theta\\ } } \\right)^2\\bigg ] \\nonumber\\\\ & \\leq c'(\\beta )    e^{-{t_{-}}\\min\\{4\\theta,4 - 2\\theta\\ } } n \\log^2 n\\ , { \\mathbb{e}}\\left [ e^ {   \\min\\{4\\theta,4 - 2\\theta\\ } s_i}\\right]\\\\ & = c'(\\beta )   \\left ( \\log",
    "n \\right)^{-(3l+4 ) } \\,{\\mathbb{e}}\\left[e^ {   \\min\\{4\\theta,4 - 2\\theta\\ } s_i}\\right]\\ , , \\end{aligned}\\ ] ] for some @xmath239 .",
    "finally , by equation   @xmath240&\\leq \\sum_{k=1}^\\infty e^ {   \\min\\{4\\theta,4 - 2\\theta\\ } k } { \\mathbb{p}}\\left(s_i \\in ( k-1,k)\\right )   \\\\ & \\leq \\sum_{k=1}^\\infty e^ {   \\min\\{4\\theta,4 - 2\\theta\\ } k }   e^{- ( k-1 ) ( l+1)\\theta } \\log^{3(l+1 ) } n   = o(\\log^{3l+3 } n)\\,.\\end{aligned}\\ ] ] combining the previous two inequalities implies that @xmath241 and hence we have that @xmath242 as required .",
    "the proof for @xmath112 follows similarly for the choice of @xmath243",
    "in order to establish the lower bound we will analyze two separate test functions .",
    "first , in order to analyze our test functions , we establish the following decay of correlation bound .      we will prove the result by showing that @xmath249 can be approximated locally .",
    "let @xmath250 and so the @xmath251 are disjoint .",
    "let @xmath252 denote the sigma - algebra of generated by updates in @xmath253 and set @xmath254 $ ] .",
    "since the @xmath251 are disjoint the @xmath255 depend on independent updates and so are independent .",
    "let @xmath256 be the event in lemma  [ l : spread ] . on the event @xmath257 ,",
    "the random variables @xmath258 are completely determined by the initial condition and the updates in @xmath253 and so @xmath259 .",
    "thus , @xmath260 - { \\mathbb{e}}[\\widehat{y}_1 \\widehat{y}_2]\\right| \\leq { \\mathbb{e}}_{x_0}[2 i({\\mathcal{g}}^c ) ] = o(n^{-10})\\,.\\ ] ] and hence @xmath261 which completes the proof .        the magnetization test function achieves , at least up to an additive constant , the mixing time from the all - plus initial condition , which is asymptotically the worst - case ( see  @xcite ) . in this light",
    "it is natural to consider test functions for @xmath111 and @xmath112 based on the autocorrelation , @xmath262 .",
    "this can be seen as a special case of a test function based on conditional expectations , @xmath263.\\ ] ] because of the special structure of the histories as a killed random walk the expectation has the following useful representation .",
    "let @xmath264 be the semigroup of a continuous - time rate-1 simple random walk on @xmath24",
    ". then by the killed random walk representation we have that @xmath265 = e^{-\\theta t } ( p_{(1-\\theta)t } x_0)(i)\\ ] ] the eigenvectors of @xmath264 are @xmath266 with eigenvalues @xmath267 for @xmath268 .",
    "since the simple random walk is reversible with uniform stationary distribution we can write an orthonormal basis of real eigenvectors @xmath269 with eigenvalues @xmath270 . not that both @xmath111 and @xmath112 are eigenvectors of @xmath264 with eigenvalues @xmath271 and @xmath272 respectively and in fact",
    "@xmath271 is the largest eigenvalue .",
    "we first give a condition for the chain to _ not _ be sufficiently mixed starting from @xmath13 .",
    "let @xmath275 be distributed according to the stationary distribution .",
    "then by symmetry , @xmath276 = 0\\,,\\ ] ] while @xmath277= \\sum_{i=1}^n ( { \\mathbb{e}}_{x_0 } [ x_t(i)])^2 = e^{-2t\\theta}\\left\\|p_{(1-\\theta)t } x_0\\right\\|_2 ^ 2.\\ ] ] to estimate the variance , observe that @xmath278,\\ , x_t(i+j ) { \\mathbb{e}}_{x_0 } \\left[x_t(i+j)\\right]\\right)\\\\ & \\leq e^{-2t\\theta}\\sum_{j =- n/2 + 1}^{n/2 } \\sum_{i=1}^n   \\big|(p_{(1-\\theta)t } x_0)(i)\\big|\\ , \\big|(p_{(1-\\theta)t } x_0)(i+j ) \\big| \\ , \\big|\\operatorname{cov}(x_t(i ) , x_t(i+k))\\big|\\,.\\end{aligned}\\ ] ] by lemma  [ l : decorrelation ] , this is at most @xmath279 where the final inequality follows by the rearrangement inequality .",
    "since lemma  [ l : decorrelation ] also applies to the stationary distribution , we further have @xmath280 our test function considers the set @xmath281 .",
    "therefore , by chebyshev s inequality , @xmath282 - \\frac12 e^{-2\\theta t } \\| p_{(1-\\theta)t } x_0 \\|_2 ^ 2   \\right)^2 } = o\\left(\\frac{e^{2\\theta t } \\log^2 n } { \\| p_{(1-\\theta)t } x_0 \\|_2 ^ 2}\\right ) \\",
    ", , \\ ] ] and so by the assumption of the lemma @xmath283 . similarly , @xmath284 so @xmath285 which completes the lemma .",
    "writing @xmath286 we have that @xmath287 where the inequality follows from the fact that all the eigenvalues are bounded by 2 .",
    "thus , @xmath288 and so , by lemma  [ l : lowerboundauto ] , we have that @xmath289 , as claimed .",
    "this gives the right bound in the case of @xmath111 since it is an eigenvector of eigenvalue 2 .",
    "for @xmath112 we get a stronger lower bound . since it has eigenvalue 1 , @xmath290 so , taking @xmath291 , @xmath292 and hence by lemma  [ l : lowerboundauto ] we have that @xmath293      the alternating initial condition @xmath111 is an extreme value for the hamiltonian and measuring its convergence to stationarity gives another test of convergence .",
    "such test functions were studied in  @xcite to analyze the a random annealed initial condition . to treat @xmath111 and @xmath112 in a unified manner ,",
    "consider the function @xmath294 given by @xmath295 for every @xmath13 and @xmath104 we have that , by lemma  [ l : decorrelation ] , @xmath296\\right)= o(n \\log^2 n ) \\ , .\\end{aligned}\\ ] ] if @xmath275 is taken from the stationary distribution by taking a limit as @xmath297 , then we also have that @xmath298 .",
    "let @xmath299 denote the set of all histories of the vertices from time @xmath84 , and consider @xmath300 $ ] .",
    "if the histories of @xmath151 and @xmath301 merge then @xmath302 and @xmath303 must take the same value and @xmath300=1 $ ] .",
    "if the histories do not merge and at least one is killed before reaching time 0 then it is equally likely to be @xmath304 so @xmath300=0 $ ] .",
    "thus , the boundary condition can only play a role when both histories survive to time 0 and do not merge , as captured by the event @xmath305 let @xmath275 be an independent configuration distributed as @xmath60 and let @xmath306 denotes the expectation started from the stationary measure . then @xmath307 & = { \\mathbb{e}}_{\\pi}\\left[x_{0}({\\mathscr{f}_\\textsc{s}}(i,0,t))x_{0}({\\mathscr{f}_\\textsc{s}}(i+1,0,t)){\\mathbbm{1}}_{{\\mathcal{k}}_{i , i+1}}\\mid { \\mathscr{h}}\\right ] \\nonumber\\\\ & = { \\mathbb{e}}[y({\\mathscr{f}_\\textsc{s}}(i,0,t))y({\\mathscr{f}_\\textsc{s}}(i+1,0,t ) ) { \\mathbbm{1}}_{{\\mathcal{k}}_{i , i+1}}\\mid { \\mathscr{h } } ] \\geq 0 \\ , , \\end{aligned}\\ ] ] as the ferromagnetic ising model is positively correlated . in a graph with two vertices connected by an edge",
    ", the correlation of spins of the ising model can be found to be @xmath308 .",
    "correlations are monotone in the edges of the graph , so for neighboring vertices in @xmath24 we have @xmath309 \\geq \\tanh \\theta > 0 $ ] .",
    "it was shown in the proof of theorem  6.4 of  @xcite that @xmath310 and so @xmath311 & \\geq \\tanh(\\theta ) { \\mathbb{p}}\\left({\\mathscr{f}_\\textsc{s}}(i,0,{t_\\star})=\\{i\\},\\,{\\mathscr{f}_\\textsc{s}}(i+1,0,{t_\\star})=\\{i+1\\}\\right)\\nonumber\\\\ & \\geq c_1 \\tanh(\\theta ) { t_\\star}^{-2 } e^{-2\\theta { t_\\star } } \\ , .\\end{aligned}\\ ] ] we will compare this bound with the behavior under the initial conditions @xmath111 and @xmath112 .",
    "we first treat the case of @xmath111 .",
    "let @xmath315 and @xmath316 be independent rate-(@xmath83 ) continuous - time simple random walks with initial conditions @xmath317 and @xmath318",
    ". let @xmath319 denote the first time the walks hit each other and @xmath320 . by the killed random walk representation of the histories , we have that @xmath321 = e^{-2\\theta } { \\mathbb{e}}\\left[x^{{\\mathrm{alt}}}(z_1({t_\\star}))x^{{\\mathrm{alt}}}(z_2({t_\\star})){\\mathbbm{1}}_{t>{t_\\star}}\\right ] = e^{-2\\theta } { \\mathbb{e}}\\left[w({t_\\star}){\\mathbbm{1}}_{t>{t_\\star}}\\right].\\end{aligned}\\ ] ] note that @xmath322 is itself a markov chain with state space @xmath116 and transition rate @xmath323 , and so @xmath324 = e^{-4(1-\\theta ) } w(s)\\,.\\ ] ] thus , since @xmath325 by the definition of @xmath111 , and @xmath326 , applying   we get @xmath327 & = { \\mathbb{e}}\\left[w({t_\\star})\\right ] - { \\mathbb{e}}\\left[w({t_\\star}){\\mathbbm{1}}_{t\\leq{t_\\star}}\\right ] = -e^{-4(1-\\theta){t_\\star } } - { \\mathbb{e}}\\left[{\\mathbbm{1}}_{t\\leq{t_\\star } } { \\mathbb{e}}\\left[w({t_\\star } ) \\big | t \\right ]   \\right]\\\\ & = -e^{-4(1-\\theta){t_\\star } } - { \\mathbb{e}}\\left[{\\mathbbm{1}}_{t\\leq{t_\\star } } e^{-4(1-\\theta)({t_\\star}-t ) }   \\right ] \\leq 0\\,.\\end{aligned}\\ ] ]",
    "hence , @xmath328 \\leq 0 $ ] .    for @xmath112 ,",
    "the process @xmath329 is again a markov chain but with transition rate @xmath83 .",
    "the requirement that @xmath151 is a multiple of 4 was chosen to ensure that @xmath330 .",
    "the argument is otherwise unchanged .",
    "combining lemma  [ eq : rwsignestimate ] with equation  , we obtain that @xmath331 - { \\mathbb{e}}_{x^{{\\mathrm{alt}}}}[x_{{t_\\star}}(i)x_{{t_\\star}}(i+1)]\\\\   & \\qquad= { \\mathbb{e}}_\\pi[x_{{t_\\star}}(i)x_{{t_\\star}}(i+1){\\mathbbm{1}}_{{\\mathcal{k}}_{i , i+1 } } ] - { \\mathbb{e}}_{x^{{\\mathrm{alt}}}}[x_{{t_\\star}}(i)x_{{t_\\star}}(i+1){\\mathbbm{1}}_{{\\mathcal{k}}_{i , i+1 } } ] \\geq c_1 \\tanh(\\theta ) { t_\\star}^{-2 } e^{-2\\theta { t_\\star } } \\ , , \\end{aligned}\\ ] ] and thus @xmath332 - { \\mathbb{e}}_{x_0}[r(x_{{t_\\star } } ) ]",
    "\\geq   c_1 \\tanh(\\theta ) { t_\\star}^{-2 } e^{-2\\theta { t_\\star } } \\frac{n}{4 } \\ , .\\end{aligned}\\ ] ] we are now ready to prove the second lower bound .      denote by @xmath87 the event @xmath335 + { \\mathbb{e}}_{x_0}[r(x_{{t_\\star } } ) ] ) \\big \\}\\,.\\ ] ] by chebyshev s inequality and equations   and   @xmath336 - { \\mathbb{e}}_{x_0}[r(x_{{t_\\star}})])\\right)^2 } = o\\left ( \\frac{n \\log^2 n}{{t_\\star}^{-4 } e^{-4\\theta { t_\\star}}n^2 } \\right ) \\to 0 \\ , , \\ ] ] and similarly @xmath337 - { \\mathbb{e}}_{x_0}[r(x_{{t_\\star}})])\\right)^2 } \\to 0 \\ , .\\ ] ] hence , @xmath338 , as claimed ."
  ],
  "abstract_text": [
    "<S> in the study of markov chain mixing times , analysis has centered on the performance from a worst - case starting state . here , in the context of glauber dynamics for the one - dimensional ising model , </S>",
    "<S> we show how new ideas from information percolation can be used to establish mixing times from other starting states . at high temperatures </S>",
    "<S> we show that the alternating initial condition is asymptotically the fastest one , and , surprisingly , its mixing time is faster than at infinite temperature , accelerating as the inverse - temperature @xmath0 ranges from 0 to @xmath1 . moreover , </S>",
    "<S> the dominant test function depends on the temperature : at @xmath2 it is autocorrelation , whereas at @xmath3 it is the hamiltonian . </S>"
  ]
}