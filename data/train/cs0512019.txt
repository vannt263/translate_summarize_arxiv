{
  "article_text": [
    "we are using genetic algorithms ( ga s ) for solving hard global optimization problems for at least three reasons :    * they are easy to implement in many computer languages , * they are applicable to problems , which can not be easily , if at all , specified analytically as a set of closed - form formulas , * we believe , that their inherent intelligence will automatically , i.e. with almost no programmer s effort , find the way to solve ,  sufficiently well  , our difficult problems .    the very idea of ga s , to simply mimic the nature @xcite , belongs mostly to the sphere of intuition , and is almost lacking a  solid mathematical background . indeed , numerical values of many important  tuning parameters  ( mutation rate , probability of selection for reproduction , etc . ) are largely selected on the base of experience of other people solving problems similar to ours .",
    "the hypothesis of  building blocks  appeared false .",
    "other investigations of ga s and their inner working are rare .",
    "we simply _ believe _ , that following the nature s paths can not be wrong . but are we right ? and , if so , why ?",
    "it is easy to see , that after the crossover operation , the distance between resulting offsprings is identical to the distance between their parents @xcite .",
    "consider a pair of parents , @xmath0 and @xmath1 consisting of @xmath2 genes each .",
    "the distance between them may be calculated in many ways , depending on metrics in use . in the simplest case ,",
    "when each gene is just a binary digit , the hamming distance ( @xmath3 ) is perhaps the most natural choice .",
    "this simply counts the number of bits differing on the corresponding positions in the two given bit - strings .",
    "it is obvious , that in this case @xmath4 since the parents , @xmath5 and @xmath6 , differ on exactly the same positions as their offsprings , @xmath7 and @xmath8 , do  regardless of how many crossover points were used",
    ".    when individual genes are more complex , i.e. when they consist of more bits ( or , more often , are the symbols drawn from finite size alphabet(s ) ) , or even when they are just the real numbers , the same remains true in any metrics induced by @xmath9 norms .",
    "indeed , the expression : @xmath10^{\\frac{1}{p}},\\quad\\ p=1,2,\\ldots\\ ] ] has to be equal to @xmath11 , as the numerical components of the sum , shown above , are identical in both cases ; even their order is preserved .",
    "the property ( [ first ] ) holds also for less frequently used norm @xmath12 @xmath13 .",
    "consider now a  triangle in genetic space defined by vortices : two parent chromosomes , @xmath5 and @xmath6 and any other fixed , but otherwise arbitrary , reference point @xmath14 .",
    "we will apply the crossover operator to the pair @xmath15 , obtaining another pair of chromosomes @xmath16 , as shown in fig .",
    "[ cross ] .",
    "[ cols=\">,<,^ , < \" , ]     we shortly summarize all interesting outcomes of the crossover operation in tab .",
    "[ tabelka ] . analyzing its contents",
    "we see , that the symbol  @xmath17  can be found at advantageous position exactly @xmath18 times , while only twice on disadvantageous one .",
    "does it mean , that the odds for selecting ",
    "offsprings , i.e. to improve at least one trial solution , are @xmath19 ?",
    "the answer would be positive , if the events @xmath20@xmath21 occurred with equal probability , what is unlikely . on the other hand ,",
    "if only the case @xmath21 ( the worst ) occurs again and again , then the random , unbiased selection of one of the offsprings , would give us _ exactly _ ( ! )",
    "@xmath22% chance to move closer to the reference chromosome @xmath14 .",
    "this means , that in practice , the chances for improvement can be even higher than @xmath23 ; we will prove that , rigorously , in the following section .",
    "* important note : * we have to carefully distinguish between continuous and discrete case . in discrete genetic space",
    "the only convergent sequences are constant sequences .",
    "this is because there are no elements of discrete genetic space , which would be located arbitrarily close to any existing chromosome , the optimal one in particular .",
    "therefore the notion of convergence is sensible and usable only in continuous cases .    on the other hand ,",
    "since @xmath14 is arbitrary , then it may have nothing to do with the optimal solution .",
    "that is why the entire evolutionary process may not converge at all without additional driving forces , other than the actions of crossover operators .    as we will show now ,",
    "the key to the question of convergence is the selection process  the practical realization of the darwinian rule of evolution , _ survival of the fittests _ , understood in a  probabilistic sense rather than an absolute rule .",
    "the following text is based on the problem stated and solved by lataa in _ delta _ @xcite  a  popular polish monthly on mathematics , physics and astronomy , targeted mainly at high - school students . the problem and its solution are freely rephrased by the current author .",
    "problem :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ find the winning strategy in the following game : + looking at an integer number , randomly chosen from two such numbers written down by our opponent , guess whether the other ( unknown ) number is higher or lower .",
    "the two numbers in question are distinct .",
    "we win , when our guess is correct , otherwise we loose .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    solution :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ use arbitrary , strictly increasing , sequence of numbers @xmath24 , each belonging to the ( open ) interval @xmath25 , for example @xmath26 .",
    "when the selected ( known ) number is equal to @xmath27 , then with probability @xmath28  guess  , that the other ( unknown ) number is _ lower _ , or , with probability @xmath29 , that it is _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    it is obvious , that this strategy should work equally well not only for unknown integer numbers , but also when the numbers are drawn from any countable subset of reals . but",
    "why does it work at all ?",
    "let @xmath30 denotes the probability , that the numbers chosen by our opponent are @xmath31 and @xmath32 , and that @xmath33 .",
    "the probability , that our guess is correct , may be written as @xmath34 = \\frac{1}{2 } +          \\frac{1}{2 } \\sum_{m , n\\in\\hbox{\\mm z},\\ m >",
    "n } p_{m , n } \\left(c_{m }          - c_{n } \\right)\\ ] ] where is the set of integers .",
    "first  @xmath23  in the r.h.s . of ( [ solve ] ) comes from the fact , that @xmath35 .",
    "the second component is strictly positive , since @xmath36 for arbitrary @xmath33 ( as the sequence @xmath37 is strictly increasing ) and at least one of @xmath30 is greater than zero . in conclusion : our chances to win always _ exceed _ @xmath22% . this would nt be so , if the sequence @xmath37 was not strictly increasing  in such circumstances our chances to win could be estimated only as _ not less _ than @xmath23 .",
    "let us note , that nothing certain can be said about * how much * our chances to win exceed @xmath22% .",
    "they will peak , if all the differences @xmath38 are maximized , at least those of them , which ",
    "meet  non - zero @xmath30 s in formula ( [ solve ] ) .",
    "unfortunately , we know nothing ahead about probabilities @xmath30 s .",
    "how is the above problem related to genetic algorithms ?",
    "quite simply : the sequence @xmath37 should be regarded as a  tool to convert the value of fitness to probability of selection .",
    "the superiority of the soft selection , realized with such a sequence @xmath37 , over the hard selection schemes , is evident .",
    "in the case of soft selection , our chances to win ( i.e. to improve the objective by selecting a  better offspring for further processing ) are always higher than chances for failure . on the contrary , the hard selection for @xmath39 , and @xmath40 otherwise .",
    "if so , then @xmath38 in r.h.s of ( [ solve ] ) is necessarily equal to zero for many pairs @xmath41 . for those pairs @xmath42 , for which @xmath43 , in turn , @xmath30 may be equal to zero  corresponding to the pairs never produced by our malicious ( smart ? ) opponent . ]",
    "implies that , in the unlucky event , both chances can be equal to each other .",
    "the hard selection scheme can be considerably improved to become comparable with the soft selection .",
    "it is enough to select the number @xmath44 ( see footnote ) as any average of fitnesses of all individuals present in the previous generation .",
    "this trick should work best in cases , when our opponent  the objective function  produces only a  few discrete values .",
    "the difference seems rather subtle : sharp versus not sharp inequality . but let us recall the brutal practice of citizens of an ancient greek city of sparta . in strive to have only excellent warriors as their descendants , they used to physically eliminate all ",
    "defective  newborns .",
    "did they succeed ?",
    "consider the objective function with many local extrema of very similar fitness value , yet having exactly one global optimum .",
    "the evolving population will sooner or later split into many loosely connected clusters , concentrated around those extrema . to discover the true , global optimum ,",
    "we need the ability to correctly rank the individuals with very close values of their fitness .",
    "only then the  useless  individuals , located around local extrema , would be extinct .",
    "therefore , in particular computer implementation , not every kind of average used as threshold for hard , stepwise selection , is equally good . to increase our chances for success , and accelerate the convergence as well ,",
    "we should apply the sequence @xmath37 , or its continuous counterpart  which may be selected individually for each new generation  in such a  way , that it changes most significantly around majority of fitness values across the population . when searching for maximum , the following simple and numerically plausible transformations from @xmath45 to @xmath46 ,  often called _ scaling of the fitness function _",
    ", satisfy this requirement : @xmath47 with the first choice being definitely softer .",
    "the subscripted constants @xmath48 denote respective quantiles ( more precisely : quartiles ) of the fitness distribution across the current population , with @xmath49 being the median . put unity into the denominator when @xmath50 .",
    "replace summation in ( [ scale ] ) with subtraction , when searching for minimum .",
    "it is clear , that ga s can be most effective for objectives , for which only a very limited information is available , namely nothing but fitness values computed for every member of the population , usually only the last one .",
    "their ability to quickly detect and then to concentrate in the interesting parts of the search space makes them clearly superior to generic monte carlo approach , which waste time for uniform and fruitless exploration of other regions .",
    "the above is certainly true for objectives , which are at least piecewise continuous and have no singularities .",
    "for such a broad class of problems , with chromosomes coded in a  natural way , the * stopping rules * should be based on compactness of the evolving population , paying only little attention to the behavior of fitness .",
    "the evolutionary process should be continued as long as the volume of the search space occupied by ",
    "better half  of the population still decreases",
    ". one should be aware , however , that this strategy will fail for objectives with more than one global optimum or when the unique extremum is degenerate ( flat , improper ) , i.e. consists of more than a single point , either in reality or due to roundings . if this is the case , then careful analysis of the last generation may be helpful .    for discrete problems ( with integer and maybe boolean variables present ) the notion of continuity does not apply , so the task is to efficiently find the acceptable solution _ without _ performing exhaustive search .",
    "it can be shown @xcite , that for purely discrete problems we need @xmath51 evaluations of the objective instead of @xmath52 , as necessary and required by the exhaustive search .",
    "@xmath2 is the number of bits , not unknowns , in a  single chromosome . to be precise : after @xmath53 evaluations of the objective , the chance that the best so far chromosome is separated no more than @xmath54 unit of distance ( in hamming sense ) from the optimal one , are higher than @xmath22% .",
    "no well justified stopping rules can be given for discrete case .",
    "mixed problems , involving real _ and _ integer unknowns , are even harder to analyze . from the formal point of view , such problems may be regarded as large , but finite , sets of continuous problems .",
    "we have shown , that genetic algorithms are bound for success .",
    "the chances for improvement are always higher than for lack of it , if the selection of parents is performed either in a  soft , or hard but adaptive , manner .",
    "this is a very general result , completely independent on the optimization problem under study .",
    "it applies equally well to discrete , continuous and mixed optimization problems .",
    "as we can see , the quite high chances of genetic algorithms for success are strictly related to their property of not rejecting nor ignoring the  bad  trial points in the search space .",
    "contrary , the rigorous , deterministic search methods are simply unable to  jump over  the barrier surrounding even the single global minimum , if started too far from the solution .",
    "our result is of stochastic nature rather than deterministic .",
    "this may mean in practice , that we may be unable at all to improve the already known , approximate solution of our particular problem .",
    "nothing can be said how quickly we will arrive at any improvement .",
    "this may be significantly influenced by other components of ga s : mutation operators , population size and numerical values of various tuning parameters , not on the selection scheme or crossover mechanism alone .",
    "this work was done as a part of author s statutory activity at the institute of physics , polish academy of sciences .",
    "marek w. gutowski : _ biology , physics , small worlds and genetic algorithms _ , in : _ leading edge computer science research _ , ed .",
    "susan shannon , nova science publishers inc . , hauppage ny , 2005 , ch .  6 , pp .  165218 , ` http://novapublishers.com/catalog/product_info.php?products_id=3703 `"
  ],
  "abstract_text": [
    "<S> there is no proof yet of convergence of genetic algorithms . </S>",
    "<S> we do not supply it too . </S>",
    "<S> instead , we present some thoughts and arguments to convince the reader , that genetic algorithms are essentially bound for success . for this purpose , we consider only the crossover operators , single- or multiple - point , together with selection procedure .    we also give a proof that the soft selection is superior to other selection schemes .    </S>",
    "<S> genotype space ; crossover operators ; soft selection ; convergence ; stopping rules </S>"
  ]
}