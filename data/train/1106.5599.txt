{
  "article_text": [
    "multivariate regression deals with @xmath1 observations of a @xmath2-dimensional vector @xmath3 where @xmath4 is the transpose of a @xmath5 matrix @xmath6 .",
    "we have in mind that @xmath6 has a small ( unknown ) rank and the design @xmath7 is non - random . writing @xmath8 , @xmath9 and @xmath10 for the matrices with respective rows @xmath11 , @xmath12 and @xmath13 , the above equation translate into @xmath14 anderson  @xcite and izenman  @xcite have introduced reduced - rank estimators @xmath15 where @xmath16 is the hilbert - schmidt norm associated to the scalar product @xmath17 . the problem of selecting among the family of estimators @xmath18 by minimizing the criterion @xmath19 has been investigated recently from a non - asymptotic point of view by bunea _",
    "et al . _",
    "@xcite and giraud  @xcite .",
    "both papers provide oracle bounds for the predictive risk @xmath20 with _ no assumption _ on the design @xmath9 .",
    "multivariate regression corresponds to a special case of the trace regression model @xmath21 where @xmath22 .",
    "indeed , we have for all @xmath23 and @xmath24 @xmath25 where @xmath26 is the canonical basis of @xmath27 .",
    "many recent works  @xcite have investigated trace regression with nuclear norm penalization . translated in terms of multivariate regression ,",
    "nuclear - norm - penalized regression estimators are defined by @xmath28 where @xmath29 are the singular values of @xmath30 .",
    "several risk bounds have been obtained for the predictive risk of @xmath31 and they all require the assumption ( semi - ri property ) @xmath32 for some positive @xmath33 .",
    "in other words the smallest eigenvalue of @xmath34 must be larger than @xmath35 .",
    "this enforces the sample size @xmath1 to be larger than the number @xmath36 of parameters .",
    "this assumption on the design needed for @xmath31 is thus very strong , in contrast with the reduced - rank estimator @xmath37 which requires no assumption on the design .      in this note , we emphasize that the assumption   coming from the general trace regression framework can be weaken for the multivariate regression framework . under this ( much ) weaker assumption",
    ", we show that the analysis of kolchinskii _ et al . _",
    "@xcite gives an oracle bound with leading constant 1 for the estimators @xmath31 .",
    "the condition   requires the sample size @xmath1 to be larger than the number @xmath36 of covariates .",
    "is - it still possible to get an oracle bound on @xmath38 when @xmath1 is smaller than @xmath36 ?",
    "the analysis of theorem 12 in bunea _",
    "et al . _",
    "@xcite suggests that the condition   only need to hold true for matrices @xmath30 of rank at most twice the rank of @xmath6 .",
    "unfortunately , when the rank of @xmath6 is positive this condition is still equivalent to require that the smallest eigenvalue of @xmath34 is larger than @xmath35 .    in the analysis of in kolchinskii",
    "et al . _",
    "@xcite , the condition   is needed for comparing @xmath39 to @xmath40 , see for example the display  ( 2.17 ) of  @xcite .",
    "we point out below , that this inequality needs not to hold for all matrices @xmath31 and @xmath30 , so that condition   can be relaxed to handle cases where @xmath41 .",
    "@xmath42 where @xmath43 are the singular values of @xmath9 .",
    "the singular value @xmath44 is always positive but can be arbitrary small .",
    "assumption  1 requires a positive lower bound on this singular value .",
    "write @xmath45 for the range of the linear operator @xmath46 and @xmath47 for the orthogonal projection onto the range of @xmath46 in @xmath48 .",
    "since we have the orthogonal decomposition @xmath49 , we have @xmath50 for any matrix @xmath30 .",
    "in addition , @xmath51 for any @xmath52 and matrix @xmath30 , so @xmath53 with strict inequality if @xmath54 . as a consequence , we have @xmath55 , so @xmath31 is also a minimizer of @xmath56 where @xmath57    under assumption 1 , we have @xmath58 theorem 1 of  kolchinskii _ et al . _",
    "@xcite then gives the upper bound @xmath59 for @xmath60 .",
    "again , since @xmath50 and @xmath61 , the infimum on the right hand side coincides with the infimum on the whole space @xmath62 .",
    "we then have the following result .",
    "let @xmath31 be defined by  .",
    "then , under assumption 1 , for @xmath60 we have @xmath63      the above statement is purely deterministic . in the case of gaussian errors we have the following corollary .",
    "assume that the entries of @xmath10 are i.i.d .  with gaussian @xmath64 distribution .",
    "let @xmath65 and set @xmath66 then , with probability larger than @xmath67 we have @xmath68",
    "the assumption 1 , which requires that the smallest _ positive _ singular value of @xmath9 is lower bounded , is much weaker than the assumption  . in particular , this condition is fully compatible with the setting where the sample size @xmath1 is smaller than the number @xmath36 of covariables .",
    "when this condition is met with @xmath71 of reasonable size , the nnp - estimator achieves under the assumptions of corollary  1 , the oracle inequality @xmath72 with probability larger than @xmath67 .",
    "this inequality ensures that the nnp - estimator is adaptive rate - minimax .",
    "anderson . estimating linear restrictions on regression coefficients for multivariate normal distribution .",
    "annals of mathematical statistics 22 ( 1951 ) , 327351 .",
    "consistency of trace norm minimization , journal of machine learning research , 9 ( 2008 ) , 10191048 . f. bunea , y. she and m. wegkamp",
    ". optimal selection of reduced rank estimation of high - dimensional matrices .",
    "_ to appear in _ the annals of statistics .",
    "c. giraud .",
    "low rank multivariate regression . arxiv:1009.5165v2 ( 2010 ) a.j .",
    "reduced - rank regression for the multivariate linear model .",
    "journal of multivariate analysis 5 ( 1975 ) , 248262 .",
    "v. koltchinskii , k. lounici and a. tsybakov .",
    "nuclear norm penalization and optimal rates for noisy low rank matrix completion .",
    "arxiv:1011.6256v3 ( 2011 ) s. negahban and m.j .",
    "estimation of ( near ) low - rank matrices with noise and high - dimensional scaling .",
    "arxiv:0912.5100v1 ( 2009 ) a. rohde , a.b .",
    "estimation of high - dimensional low - rank matrices .",
    "annals statistics , volume 39 , number 2 ( 2011 ) , 887930 ."
  ],
  "abstract_text": [
    "<S> we give a suitable ri - property under which recent results for trace regression translate into strong risk bounds for multivariate regression . </S>",
    "<S> this pseudo - rip is compatible with the setting @xmath0 . </S>"
  ]
}