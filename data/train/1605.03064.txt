{
  "article_text": [
    "extremal behaviour of gaussian processes has been the subject of numerous studies .",
    "it is of interest from the point of view of the extreme value theory , or large deviations theory and of the theory of sample path properties of stochastic processes .",
    "the asymptotic distribution of the supremum of bounded gaussian processes has been very thoroughly studied ; highlights include @xcite , @xcite and @xcite , and the books of @xcite , @xcite and @xcite . in this paper",
    "we are interested in another type of the asymptotic behaviour of gaussian processes : the situation when an entire sample path of the process is above a high level .",
    "such situations are important for understanding the structure of the high level excursion sets of gaussian random processes and fields .",
    "very loosely speaking , we are interested in the asymptotics of the gaussian minima when these minima are high .",
    "dealing with high gaussian minima is not easy .",
    "a finite - dimensional situation ( in the language of dependent lognormal random variables ) is considered in @xcite .",
    "we , on the other hand , consider minima of zero mean sample continuous gaussian processes .",
    "the processes we consider are often stationary , but some nonstationary processes fall within our framework as well .",
    "we now describe the questions of interest to us more concretely .",
    "let @xmath0 be a centered gaussian process with continuous paths , defined on some probability space @xmath1 .",
    "let @xmath2 $ ] be a compact interval , and let @xmath3 be a high level .",
    "we study a number of problems related to the situation described above , i.e. the situation when the entire sample path @xmath4)$ ] lies above the level @xmath5 .",
    "specifically , we are interested in the following questions .",
    "* question 1*. what is the precise asymptotic behaviour of the probability @xmath6 as @xmath7 ?",
    "* question 2*. given the event @xmath8 how does the conditional distribution of @xmath4)$ ] behave as @xmath7 ?",
    "* question 3*. conditionally on @xmath9 , what can be said about the asymptotics of the overshoot @xmath10 as @xmath7 ?",
    "* question 4*. consider the location of the minimum of the process , @xmath11 taken to be the leftmost location of the minimum in case there are ties ( it is elementary that this location is a well defined random variable ) .",
    "what is the asymptotic distribution of the location of the minimum given @xmath9 , as @xmath7 ?    some information on questions 1 and 2 is contained in @xcite  .",
    "regarding * question 1 * , the latter paper describes the probabilities of the type @xmath12 on the logarithmic level , while in the present paper we are interested in precise asymptotics of that probability . regarding * question 2 * , the latter paper studies the asymptotic behaviour of the ratio @xmath13 given @xmath9 , as @xmath7 , while in the present paper we would like to know the deviations of the sample path from this linear in @xmath5 behaviour .",
    "furthermore , the paper of @xcite  provides no information on * question 3 * and * question 4 * above .    for stationary ( not necessarily gaussian ) processes a general theory of the location of the supremum ( or infimum ) of the process is developed in @xcite .",
    "however , the limiting behaviour of the minimum location in * question 4 * even in the stationary case is outside of that theory .",
    "we obtain fairly precise answers to the above questions .",
    "however , in order to achieve this level of precision , we will impose much stricter smoothness assumptions on the process @xmath14 then those imposed in @xcite .",
    "we describe the precise assumptions on the process in section [ sec : smoothness ] .",
    "section [ sec : preliminary ] contains preliminary results , while the main results of the paper with answers to questions 1 - 4 are stated in section [ sec : results ] .",
    "these results are proved in section [ sec : proofs ] .",
    "finally , section [ sec : examples ] presents two examples illustrating the main results of the paper .",
    "in this section we will state and discuss the assumptions on the gaussian process @xmath14 we will use in the rest of the paper . among others , these assumptions will guarantee that our process is very smooth .",
    "our main interest lies in stationary gaussian processes , and for these processes the assumptions are easy to state . however , our main results in the subsequent sections do not depend on the stationarity of the process .",
    "rather , they depend on certain properties of the process which follow , in the stationary case , from a small number of basic assumptions . these properties are discussed in the remainder of this section .",
    "we use the notation @xmath15 for the covariance function of the process @xmath14 .",
    "if the process is stationary , then its covariance function is related to the spectral measure of the process by writing ( with the usual abuse of notation related to the dual use of @xmath16 to denote both a function of one variable and a function of two variables ) @xmath17 where @xmath18 .",
    "recall that the spectral measure @xmath19 of the process @xmath14 is a finite symmetric borel measure on @xmath20 .",
    "when the process @xmath14 is stationary , we will impose the following conditions on the spectral measure @xmath19 .",
    "* for all @xmath21 , @xmath22 * the support of @xmath19 has at least one accumulation point .",
    "the canonical example of such a gaussian process is the process with the gaussian spectral density @xmath23 this process was considered in detail in @xcite , and we will use it in this paper to illustrate our results .    the following proposition establishes certain consequences of the conditions s1 and s2 in the case of a stationary process . it is these consequences , rather than stationarity itself , that will be used in much of the paper .    [ p0 ] let @xmath14 be a stationary gaussian process whose spectral measure satisfies s1 and s2",
    ". then the process @xmath14 has the following properties .",
    "[ assume1 ] the function @xmath24 has a power expansion @xmath25 for some @xmath26 .    [ assume2 ] for any compact interval @xmath2 $ ] , the family @xmath27)$ ] is non - negatively non - degenerate .",
    "that is , for any probability measure @xmath28 on @xmath2 $ ] , @xmath29    [ assume3 ] the sample paths of @xmath14 are infinitely differentiable , and the covariance matrix of any finite sub - collection of the family @xmath30 is non - singular . here and elsewhere , for any function @xmath31 and @xmath32 , @xmath33 denotes its @xmath34-th derivative whenever it exists , with @xmath35 .",
    "the integral @xmath36 defines , clearly , an analytic function , and then @xmath37 for @xmath38 has property [ assume1 ] .    to check property [ assume2 ] , suppose for the sake of contradiction , that there exists a probability measure @xmath28 on @xmath2 $ ] such that @xmath39 clearly , the left hand side is the same as @xmath40 therefore , it follows that @xmath41 for every @xmath42 in the support of @xmath19 .",
    "the left hand side is an analytic function of the complex variable @xmath42 .",
    "since the equality holds on the support of @xmath19 , which has an accumulation point , by the assumption s2 , the equality holds for all @xmath43 including @xmath44 .",
    "this contradicts the fact that @xmath28 is a probability measure and thus verifies property [ assume2 ] .    for property [ assume3 ] notice that the integral @xmath45 where @xmath46 is a complex - valued gaussian random measure with control measure @xmath19 , has a version that is a random analytic function .",
    "indeed , by all the integrals of the type @xmath47 are well defined complex - valued gaussian random variables for any @xmath48 .",
    "this gives a version of the random function that satisfies the cauchy - riemann conditions .",
    "since the restriction of this random function to @xmath49 coincides distributionally with @xmath14 , there is a version of @xmath14 whose sample paths are infinitely differentiable .",
    "now property [ assume3 ] follows from exercise 3.5 in @xcite .",
    "this completes the proof of the proposition .",
    "we fix an interval @xmath2 $ ] , once and for all , where @xmath50 , and proceed with a number of preliminary results that are important for the main results in the subsequent sections .",
    "most of these results address several issues related to the optimization problem @xmath51}\\int_a^b\\int_a^br(s , t)\\nu(ds)\\nu(dt)\\,,\\ ] ] where the minimum is taken over all borel probability measures on @xmath2 $ ] .",
    "the importance of this problem to the questions studied in this paper was shown in @xcite .",
    "[ p1 ] let @xmath14 be a gaussian process satisfying either ( a ) or ( b ) below .    1 .",
    "the process has property 1 , property 2 and property 3 , and additionally , for every fixed @xmath52 $ ] , @xmath53 2 .",
    "the process is stationary whose spectral measure satisfies s1 and s2 .    then the minimization problem has a unique minimizer @xmath54 .",
    "furthermore , the support of @xmath54 has a finite cardinality and the minimum value in is strictly positive .",
    "we start with the proof under the assumption ( a ) .",
    "the fact that the minimum is achieved follows from continuity of the functional being optimized in the topology of weak convergence on @xmath55 $ ] and compactness of that space .",
    "the claim that the minimum value is positive follows from property [ assume2 ] .",
    "let @xmath54 be a minimizer in the optimization problem , and define @xmath56 let @xmath57 and observe that @xmath58    by theorem 5.1 in @xcite , @xmath59 on @xmath2 $ ] , and @xmath60 on the support of @xmath54 . since @xmath61 is real analytic on @xmath20 by property [ assume1 ] , there are two possibilities .",
    "either @xmath62 or the set @xmath63:\\hat\\mu(t)=1\\}\\ ] ] has no accumulation points and , hence , is a set of finite cardinality . in the latter case ,",
    "the support of @xmath54 is also a finite set .",
    "we will show that is impossible and , hence , the latter option is the only possible one .",
    "indeed , suppose that holds .",
    "then the function @xmath64 is a positive constant .",
    "however , by and fatou s lemma , it follows that @xmath65 leading to a contradiction .",
    "we conclude that @xmath66 is a finite set and so is the support of @xmath54 .    in order to prove the uniqueness of an optimal measure ,",
    "suppose that @xmath67 and @xmath68 are two different optimal measures . by property [ assume3 ] , the finitely many random variables @xmath69 for @xmath70 in the union of the supports of the two measures",
    "are linearly independent and , hence , the function @xmath71 is strictly convex on @xmath72 $ ] .",
    "such a function can not take the same minimal value at the two endpoints @xmath73 and @xmath74 , and the uniqueness follows .",
    "we now prove the same claim under the assumption ( b ) . by proposition [ p0 ] the assumptions s1 and s2 on the spectral measure of a stationary gaussian process @xmath14 imply property [ assume1 ] , property [ assume2 ] and property [ assume3 ] , so the only ingredient missing in an attempt to apply the statement of part ( a ) to part ( b ) is that , in part ( b ) , we have not assumed .",
    "since the only place in the proof of part ( a ) where is used , is in ruling out , we only need to show that can be ruled out under the assumptions of part ( b ) as well .",
    "indeed , suppose that holds .",
    "the assumption s1 implies that @xmath16 can be extended to an analytic function on @xmath75 by @xmath76 then the analytic function @xmath77 must be a real constant . note that @xmath78 where @xmath79 write @xmath80 where @xmath81 is a real even function and @xmath82 is a real odd function .",
    "then , since @xmath83 is a real constant , we have @xmath84 since @xmath83 is an even function ( a constant one ) , the second term in the right hand side vanishes , so that @xmath85 by the uniqueness of the fourier transform , the only finite signed measures to have constant transforms are point masses at the origin , so we must have @xmath86 @xmath19-a.e . on @xmath87 .",
    "since the function @xmath81 is real analytic , and the support of @xmath19 has an accumulation point , we conclude that @xmath81 = 0 everywhere .",
    "this is not possible since @xmath81 is the characteristic function of the probability measure obtained by making @xmath28 a symmetric probability measure on @xmath2\\cup[-b ,- a]$ ] .",
    "this rules out .",
    "[ rk1 ] interestingly , in the non - stationary case the statement of proposition [ p1 ] might be false if is not assumed . to see this ,",
    "consider the following example .",
    "let @xmath88 be a standard normal random variable and @xmath89 be a stationary mean zero gaussian process , independent of @xmath88 , with covariance @xmath90 define @xmath91 clearly , the process @xmath92 has property [ assume1 ] , property [ assume2 ] and property [ assume3 ] .",
    "however , if @xmath2=[0,1]$ ] , then the minimizer in is the lebesgue measure on @xmath72 $ ] , and it does not have a support of a finite cardinality .",
    "we denote by @xmath93 the support of the unique minimizer @xmath54 in the minimization problem .",
    "two objects related to this set will be of crucial importance in the sequel .",
    "first of all , we let @xmath94 the importance of the function @xmath95 stems from the following claim : conditionally on the event @xmath9 in , as @xmath7 , @xmath96 in probability , in @xmath97 $ ] .",
    "indeed , it was shown in @xcite  that holds with the function @xmath95 replaced by the function @xmath98 , @xmath21 , defined in the proof of proposition [ p1 ] .",
    "recall that @xmath99 . therefore , we only need to show that @xmath100 .",
    "enumerate the elements of @xmath93 as @xmath101 ( this is the notation we will use throughout the paper ) and write @xmath102 then @xmath103 since @xmath61 is equal to one at all points of the support of the measure @xmath54 .",
    "that is , @xmath104 as required .",
    "we record for future use several useful facts about the function @xmath95 .",
    "[ l : mu.prop ] the function @xmath95 is a restriction to @xmath20 of an analytic function on @xmath105 and for each @xmath106 and @xmath21 , @xmath107 further , for each @xmath108 there exists an even positive integer @xmath34 such that @xmath109 in particular , there is @xmath110 such that @xmath111 for each @xmath112 .",
    "similarly , if @xmath113 , then @xmath114 . if equality holds , then there is @xmath110 such that @xmath115 if @xmath116 , then @xmath117 . if equality holds , then there is @xmath110 such that @xmath118    we already know that @xmath95 is a restriction to @xmath20 of an analytic function , and is obvious .",
    "the final property of @xmath95 follows from the fact that it is analytic .    if we define the `` essential '' set by @xmath119:\\mu(t)=1\\}\\,,\\ ] ] then we have proved above that @xmath120 , defined in . in particular , we showed in the proof of proposition [ p1 ] that under the assumptions of the proposition , the essential set @xmath121 is a finite set as well .",
    "it turns out that in many cases the support @xmath93 of the optimal measure for the optimization problem contains the endpoint of the interval .",
    "this holds , in particular , under certain monotonicity assumption in the covariance function of the process .",
    "specific sufficient conditions are given in the following proposition .",
    "[ p2 ] ( a )  suppose that the following two conditions hold : for all @xmath122 , @xmath123 and for all @xmath124 $ ] , @xmath125 then any finite support optimal measure for the optimization problem puts positive masses at the endpoints @xmath126 and @xmath127 of the interval .",
    "\\(b )  suppose that @xmath14 is a stationary gaussian process whose covariance function @xmath16 is nonincreasing on @xmath128 $ ] .",
    "if the spectral measure @xmath19 is not a point mass at the origin , then the conclusion of part ( a ) holds .",
    "we start with part ( a ) .",
    "assume , to the contrary , that @xmath28 puts no mass at the point @xmath126 .",
    "enumerate the elements of the support of @xmath28 ( which we still denote by @xmath93 ) as @xmath129 , with the smallest of these elements , @xmath130 .",
    "if @xmath131 , then @xmath132 define a probability measure @xmath133 notice that @xmath134 , and @xmath135\\\\ & < & 0\\,.\\end{aligned}\\ ] ] the inequality follows from the observation that @xmath136 for all @xmath137 and hence by the summands are non - positive , and the term with @xmath138 is strictly negative by .",
    "this contradicts the fact that @xmath28 is an optimal measure .",
    "thus , @xmath113 .",
    "a similar argument shows that @xmath116 .    for part ( b )",
    ", we only need to check that the assumptions of part ( a ) hold .",
    "the assumption follows from monotonicity of the covariance function of the stationary process . the only additional argument needed for is the observation that , unless the spectral measure is concentrated at the origin , the covariance function can not be constant in an neighborhood of the origin .",
    "we will use in the sequel several facts about the finite - dimensional centered gaussian vector @xmath139 .",
    "these facts are collected in the proposition below .",
    "we will use the common notation @xmath140 as @xmath7 ( where @xmath83 is a non - vanishing function ) to mean that @xmath141 note that the possibility @xmath142 is allowed .",
    "[ l : gauss.vector ] under the assumptions of either part ( a ) or part ( b ) of proposition [ p1 ] , let @xmath143 be the finite cardinality support of the unique minimizer in , and let @xmath144 be the covariance matrix of the vector @xmath145 .",
    "\\(i ) denote @xmath146 where @xmath147 is the column vector of length @xmath148 with entries equal to @xmath74 ( in the sequel , vectors are column vectors unless mentioned otherwise ) .",
    "then , @xmath149    \\(ii ) conditionally on the event @xmath150 , we have @xmath151 as @xmath7 ( here and in similar statements in the sequel , the law of the random vector in the left hand side is computed , for every @xmath3 , as the conditional law given @xmath152 ) . here",
    "@xmath153 are independent exponential random variables with parameters @xmath154 respectively .",
    "\\(iii ) the distributional tail of the minimal component of the gaussian vector @xmath145 satisfies @xmath155 as @xmath7 , where @xmath156    we start with part ( i ) . recall that by property 3 , the inverse matrix @xmath157 is well defined and , hence , so is the vector @xmath158 .",
    "suppose , for instance , that , to the contrary , @xmath159 define a @xmath160 vector @xmath161 by @xmath162 where @xmath28 is the unique minimizer in .",
    "in other words , @xmath161 is the minimizer in the problem @xmath163 clearly , @xmath164 for all @xmath165 . for small @xmath110",
    "consider vectors of the form @xmath166 where @xmath167 .",
    "then it follows from that @xmath168 note that @xmath169 since @xmath170 , for small @xmath110 , this expression is strictly smaller than @xmath171 additionally , for small @xmath110 the vector @xmath172 has positive components .",
    "recalling , this contradicts the optimality of @xmath161 in .",
    "this contradiction shows that @xmath173 .",
    "similarly , @xmath174 for all @xmath175 . hence , holds .    for parts ( ii ) and",
    "( iii ) we start by noticing that we can write , with @xmath176 given by , for any @xmath177 , for @xmath3 , @xmath178 for @xmath110 we write @xmath179 note that @xmath180 on the other hand , @xmath181 since @xmath182 we conclude that as @xmath7 , @xmath183 and , hence , @xmath184 as @xmath7 . putting @xmath185 we obtain , which together with proves the claim of part ( ii ) .",
    "in this section we will answer questions 1 - 4 mentioned in the introduction .",
    "these questions are all centered around the overall infimum @xmath186}x_t$ ] of the process @xmath14 and the behaviour of the process when the overall infimum is large .",
    "it turns out that , when the overall infimum is large , its behaviour is similar , but not identical , to the behaviour of a simpler object - the minimal value in a finite - dimensional gaussian vector , formed by several key observations of the process . understanding what happens when the latter minimum is large is an important ingredient in our analysis in this section .",
    "recall ( by proposition [ p1 ] ) that under the assumptions we are imposing in this paper , the optimization problem has a unique minimizer , a probability measure with a support of a finite cardinality , which we denote by @xmath93 .",
    "then the minimal value in a finite - dimensional gaussian vector mentioned above is simply @xmath187 .",
    "we start with question 1 of the introduction .",
    "we will need additional notation , which we introduce now .",
    "let , once again , @xmath93 be the support of a finite cardinality of the unique minimizer in .",
    "denote @xmath188 @xmath21",
    ". then @xmath189 and @xmath89 are two centered gaussian processes .",
    "moreover , the process @xmath89 is independent of @xmath190 . in particular , the process @xmath89 is independent of the random variable @xmath187 . recall that under the assumptions of proposition [ p1 ] ( which we will always assume ) , the sample paths of the processes @xmath191 and @xmath192 are in @xmath193 .",
    "recall the definition of the essential set @xmath194 in , which is a ( not necessarily strict ) superset of @xmath93 .",
    "it is a finite set , and we will enumerate its points as @xmath195 , in such a way that the first @xmath148 points form the support of the unique minimizer in , i.e. @xmath196 , @xmath197 , and @xmath198 .    let @xmath158 be the @xmath148-dimensional vector with positive coordinates defined in , and let @xmath95 be the function defined in .",
    "we define several random variables .",
    "let @xmath199 following the usual convention that a positive number divided by zero is plus infinity , and @xmath200 .",
    "that is , the right hand side of the above is to be interpreted as zero if @xmath201 for some @xmath202 such that @xmath203 .",
    "let , further , @xmath204 if both @xmath205 and @xmath206 , and let @xmath207 otherwise .",
    "similarly , we let @xmath208 if both @xmath209 and @xmath210 , and let @xmath211 otherwise . finally , we let @xmath212    for the rest of this section we will use the notation @xmath144 for the covariance matrix of the gaussian vector @xmath213 and @xmath214 for the optimal value in the optimization problem .",
    "it follows from @xcite  that @xmath215}x_t >",
    "u\\right)\\sim\\log \\p\\left(\\min_{t\\in      s}x_t >",
    "u\\right ) , \\ u\\to\\infty\\,,\\ ] ] in the sense of .",
    "the following theorem both explains how the two tail probabilities are related once the logarithms are removed , and answers question 1 .",
    "[ t.q1 ] suppose that a gaussian process @xmath14 satisfies either ( a ) or ( b ) of proposition [ p1 ] . then",
    ", as @xmath7 , @xmath216}x_t > u\\right)\\sim\\e(w ) \\p\\left(\\min_{t\\in s}x_t > u\\right)\\,,\\ ] ] and hence @xmath217 } x_t > u\\right ) \\sim \\frac{\\e(w)}{(2\\pi)^{k/2}(\\theta_1\\ldots\\theta_k)(\\det\\sigma)^{1/2}}u^{-k } \\exp\\left(-\\frac{u^2}{2v_*}\\right)\\,,\\ ] ] the above equivalences to be interpreted as in , including when @xmath218 . furthermore ,",
    "if and only if @xmath220    we now proceed to address the rest of the questions in the introduction . from now on we assume to hold .",
    "the following result answers question 2 .",
    "[ t3 ] under assumptions of theorem [ t.q1 ] , assume also that holds .",
    "then , as @xmath7 , @xmath221}x_t > u\\right.\\right)\\rightarrow q_w(\\cdot)\\ ] ] weakly on @xmath97 $ ] , where @xmath222 is a probability measure on @xmath97 $ ] defined by @xmath223 , \\",
    "b\\subset c[a , b ] , \\ \\text{borel,}\\ ] ] with @xmath224 given by .",
    "the next result is an answer to question 3 .",
    "[ t4 ] under assumptions of theorem [ t.q1 ] , assume also that holds .",
    "then , as @xmath7 , the conditional distribution of @xmath225}x_t - u\\bigr)$ ] given @xmath226}x_t > u$ ] converges weakly to an exponential distribution with mean @xmath214",
    ".    finally , we answer question 4 .",
    "[ t5 ] under assumptions of theorem [ t.q1 ] , assume also that holds .",
    "let @xmath227}x_s\\,,\\ ] ] where we choose the leftmost location of the minimum in case there are ties . then , as @xmath7 , @xmath228}x_s > u\\right)\\rightarrow \\nu_*\\ , , \\ ] ] where @xmath54 is the unique minimizer in .",
    "we start with several preliminary results .",
    "first , an elementary convergence statement , whose proof is omitted .",
    "[ l3 ] suppose that three families of random variables @xmath229 , @xmath230 and @xmath231 live on the same probability space , and that @xmath232 and @xmath233 are independent .",
    "suppose that , as @xmath234 , @xmath235 then @xmath236 as as @xmath234 , where the random vectors @xmath237 and @xmath238 in the right hand side are independent .",
    "the next lemma is the first step in the proof of theorem [ t.q1 ] .",
    "[ l1 ] under the assumptions of theorem [ t.q1 ] , for all @xmath110 and @xmath32 we have @xmath239    notice that we can write @xmath240 @xmath241 , for some continuous functions @xmath242 from @xmath20 to @xmath20 .",
    "therefore , @xmath243 and probability in the left hand side of equals @xmath244 as @xmath7 because , conditionally on @xmath245 , @xmath246 for each @xmath247 by part ( ii ) of proposition [ l : gauss.vector ] .",
    "the next theorem is the crucial step towards proving theorem [ t.q1 ] .",
    "its statement uses lemma [ l : mu.prop ] .",
    "[ t1 ] suppose that the assumptions of theorem [ t.q1 ] are satisfied , and let @xmath248 .",
    "\\(i ) suppose that @xmath249 .",
    "let @xmath110 be such that @xmath250\\subset[a , b]$ ] and @xmath251 then , as @xmath7 , conditionally on the event @xmath245 , @xmath252}x_s\\right ) { \\stackrel{p}{\\longrightarrow}}\\frac1{2\\mu^{(2)}(t)}\\left(z_t^{(1)}\\right)^2\\,,\\ ] ] and , as before , we interpret the right hand side as @xmath253 if @xmath254 .",
    "\\(ii ) suppose that @xmath255 . then either @xmath256 or @xmath257 and @xmath258 .",
    "then for all @xmath110 small enough , as @xmath7 , conditionally on the event @xmath259 , @xmath260}x_s\\right)\\\\ & { \\stackrel{p}{\\longrightarrow}}&\\begin{cases } 0\\,,&\\mu^{(1)}(a)>0\\,,\\\\ \\frac1{2\\mu^{(2)}(a)}\\left(z_a^{(1)}\\right)^2{{\\bf 1}}\\left(z_a^{(1)}<0\\right)\\,,&\\mu^{(1)}(a)=0 , \\ , \\mu^{(2)}(a)>0\\,,\\\\ \\infty{{\\bf 1}}\\left(z_a^{(1)}<0\\right)\\,,&\\mu^{(1)}(a)=0 , \\ , \\mu^{(2)}(a)=0\\ , .",
    "\\end{cases}\\end{aligned}\\ ] ] here and below , we follow the convention that @xmath261 .",
    "\\(iii ) suppose that @xmath262",
    ". then either @xmath263 or @xmath264 and @xmath265 . then for all @xmath110 small enough , as @xmath7 , conditionally on the event @xmath259 , @xmath266}x_s\\right)\\\\ & { \\stackrel{p}{\\longrightarrow } } & \\begin{cases } 0\\,,&\\mu^{(1)}(b)<0\\,,\\\\ \\frac1{2\\mu^{(2)}(b)}\\left(z_b^{(1)}\\right)^2{{\\bf 1}}\\left(z_b^{(1)}>0\\right)\\,,&\\mu^{(1)}(b)=0 , \\ , \\mu^{(2)}(b)>0\\,,\\\\ \\infty{{\\bf 1}}\\left(z_b^{(1)}>0\\right)\\,,&\\mu^{(1)}(b)=0 , \\ , \\mu^{(2)}(b)=0\\ , .",
    "\\end{cases}\\end{aligned}\\ ] ]    the claims of parts ( ii ) and ( iii ) are similar , so we will only prove the claims of parts ( i ) and ( ii ) .",
    "we start with part ( i ) .",
    "define @xmath267 taken to be the closest to @xmath70 location of the minimum in case there are ties .",
    "we first check that @xmath268 to see this , note that by lemma [ l1 ] , @xmath269 as @xmath7 .",
    "here we have used the fact that by , @xmath270 keeping the definition of @xmath271 unchanged , but replacing @xmath272 by arbitrarily small @xmath273 in the above argument , shows that , as @xmath7 , conditionally on the event @xmath274 , @xmath275 by lemma [ l : mu.prop ] there exists an even positive integer @xmath34 such that @xmath276 consider the series expansion @xmath277 for some @xmath278 in between @xmath70 and @xmath271 . by lemma [ l1 ] and we know that , as @xmath7 , conditionally on the event @xmath274 , @xmath279    the above along with , and imply that , as @xmath7 , conditionally on the event @xmath274 , @xmath280 furthermore , by lemma [ l1 ] , we also have @xmath281 therefore , @xmath282 next , we use the series expansion @xmath283 for some @xmath284 in between @xmath70 and @xmath271 .",
    "since also holds with @xmath284 replacing @xmath278 , we conclude by with @xmath285 and that @xmath286 when @xmath287 , this reduces to . if @xmath288 , i.e. if @xmath254 , the above limit says that @xmath289 which is , again , .",
    "this completes the proof of part ( i ) .",
    "we now prove part ( ii ) of the theorem .",
    "the claim will be proved separately for the three cases listed in the statement .",
    "we start with the case @xmath256 . for all @xmath110 small enough , such that @xmath290 and @xmath291}\\mu^{(1)}(s)>0 $ ]",
    ", we have by lemma [ l1 ] , @xmath292}x_s\\right|\\min_{s\\in s }    x_s > u\\right)\\\\    & \\ge&\\p\\left(\\left.\\min_{s\\in[a , a+{\\varepsilon}]}x_s^{(1)}>0\\right|\\min_{s\\in                      s}x_s > u\\right)\\\\   & \\to&1\\,,\\end{aligned}\\ ] ] as @xmath7 , which proves the claim of part ( ii ) in the case @xmath256 .",
    "suppose now that @xmath257 .",
    "by lemma [ l : mu.prop ] , we can choose @xmath110 such that @xmath293 consider the event @xmath294}x_s^{(1)}\\right\\}\\,.\\ ] ] our first claim is that @xmath295 indeed , on the event @xmath296 , the derivative @xmath297 crosses 0 in the interval @xmath298 $ ] . if we define a random variable @xmath299:x^{(1)}_{s}=0\\}\\,,\\ ] ] then @xmath300 furthermore , the definition of @xmath301 tells us that @xmath302 note that by the second derivative @xmath303 is bounded away from 0 on any interval @xmath304 $ ] for @xmath305 .",
    "it follows from lemma [ l1 ] that @xmath306 as @xmath7 . therefore , conditionally on the event @xmath307 , as @xmath7 , @xmath308 using twice the taylor expansion and imitating the steps leading to and , in conjunction with , shows that @xmath309 this would contradict if were false .",
    "thus follows .",
    "write @xmath260}x_s\\right)\\\\ & = & u\\left(x_a-\\min_{s\\in[a , a+{\\varepsilon}]}x_s\\right){{\\bf 1}}(x_a^{(1)}<0)\\\\ & + & u\\left(x_a-\\min_{s\\in[a , a+{\\varepsilon}]}x_s\\right){{\\bf 1}}(\\{x_a^{(1)}>0\\}\\setminus b)\\\\ & + & u\\left(x_a-\\min_{s\\in[a , a+{\\varepsilon}]}x_s\\right){{\\bf 1}}(\\{x_a^{(1)}>0\\}\\cap b)\\,.\\end{aligned}\\ ] ] by the definition of the event @xmath296 , the middle term in the right hand side is equal to zero , while by , the last term in the right hand side goes to zero in probability .",
    "it remains , therefore , to consider the first term in the right hand side . by the assumption @xmath257 and lemma [ l1 ]",
    "we know that @xmath310 in probability .",
    "for the rest of the that term the same analysis as the one used in the proof of part ( i ) applies .",
    "specifically , we use the two taylor expansions and .",
    "the only difference between the two scenarios is that now the integer @xmath34 does not need to be an even number , but it plays no role in the argument .",
    "this completes the proof of the theorem in all cases .",
    "we have now all the ingredients needed to prove theorem [ t.q1 ] .",
    "a restatement of is @xmath311}x_t > u\\big|\\min_{t\\in s}x_t > u\\right)=\\e w\\,,\\ ] ] which we proceed to show first . for @xmath3",
    "let @xmath312 be a process with continuous sample paths whose law is the law of the process @xmath191 in conditioned on the event @xmath274 , and let this process be independent of the process @xmath192 in .",
    "define @xmath313 let @xmath110 be small enough such that the convergence in probability in theorem [ t1 ] holds .",
    "continuing using the notation @xmath314 and @xmath315 , we define for @xmath316 @xmath317\\cap[a , b]}\\tilde             x_s^{(u)}\\right)\\,,\\ ] ] and @xmath318\\,,\\ ] ] where @xmath319:|s - t_j|\\le{\\varepsilon}\\text { for some } k+1\\le j\\le l\\}\\,,\\ ] ] with the convention that infimum over the empty set is defined as @xmath320 .    for @xmath247",
    "we denote by @xmath321 ( not to be confused with @xmath322 , @xmath323 or @xmath324 ) the limit in probability of @xmath325\\cap[a , b ] } x_s\\right)\\,,\\ ] ] as @xmath7 , conditionally on the event @xmath326 , given in theorem [ t1 ] .",
    "recall that @xmath321 may take the value @xmath253 .",
    "we define also @xmath327    clearly , the conditional law of @xmath328\\bigr)\\ ] ] given @xmath326 coincides with the law of @xmath329 by theorem [ t1 ] we know that for fixed @xmath316 , @xmath330 as @xmath7 , where we regard @xmath321 as a function of the process @xmath192 in the definition of @xmath331 .",
    "furthermore , by proposition [ l : gauss.vector ] , @xmath332 as @xmath7 , where @xmath333 are independent exponential random variables with parameters given by .",
    "finally , lemma [ l1 ] implies that as @xmath7 , @xmath334 we apply now lemma [ l3 ] to conclude that , as @xmath7 , @xmath335 with @xmath336 being independent of the rest of the random variables in the right hand side , which implies that , as @xmath7 , @xmath337\\bigr|\\min_{s\\in s}x_s > u\\bigr)\\ ] ] @xmath338 weakly on @xmath339 , with the obvious interpretation if some of the @xmath321 take the value @xmath253 . if we denote @xmath340:|s - t_j|\\le{\\varepsilon}\\text { for some } 1\\le j\\le k\\}\\,,\\ ] ] then it follows by the continuous mapping theorem that , as @xmath7 , @xmath341\\right\\ } \\\\",
    "\\label{eq.conv}&\\rightarrow&\\min\\left\\{e_1-w_1,\\ldots , e_k - w_k,\\ ,    \\min_{s\\in g}z_s\\right\\}\\ , .",
    "\\end{aligned}\\ ] ] note that continues to hold if we use @xmath342 in the definition of @xmath343 ( but not in the definition of @xmath344 ) .    since the function @xmath95 is bounded away from 1 on @xmath2\\setminus ( g\\cup h)$ ] , lemma [ l1 ]",
    "implies that @xmath345\\setminus(g\\cup      h)}x_s > u\\bigr|\\min_{s\\in s}x_s > u\\right)=1\\,.\\ ] ] together with the fact that @xmath346 for all @xmath347 , this implies that @xmath348}x_t > u\\bigr|\\min_{s\\in s}x_s > u\\right)\\\\ = & \\liminf_{u\\to\\infty}\\p\\left(\\min_{s\\in g\\cup h}x_s >",
    "u\\bigr|\\min_{s\\in      s}x_s > u\\right)\\\\ \\ge&\\lim_{u\\to\\infty}\\p\\left(\\min\\left\\{u\\left(\\min_{s\\in        h}x_s - u\\right),\\ , \\min_{s\\in g}\\left [        x_{s}-u\\mu(s)\\right]\\right\\}>0\\bigr|\\min_{s\\in s } x_s > u\\right)\\\\ \\geq & \\p\\left(e_1-w_1>0,\\ldots , e_k - w_k>0 , \\ , \\min_{s\\in          g}z_s>0\\right ) \\\\",
    "= &   \\e\\left[\\exp\\left(-\\sum_{j=1}^k\\theta_jw_j\\right){{\\bf 1}}\\left ( \\min_{s\\in          g}z_s>0\\right)\\right ]       \\\\ = &   \\e\\left [ w_{(a , b)}w_aw_b\\ , { { \\bf 1}}\\left ( \\min_{s\\in          g}z_s>0\\right ) \\right]\\,.\\end{aligned}\\ ] ]    we let now @xmath349 and use the monotone convergence theorem to conclude that @xmath350}x_t > u\\bigr|\\min_{t\\in s}x_t > u\\right ) \\ge \\e w\\,.\\ ] ] on the other hand , @xmath351}x_t > u\\bigr|\\min_{t\\in",
    "s}x_t > u\\right ) \\\\ & \\le&\\p\\left(\\min_{s\\in h\\cup(e\\setminus s)}x_s >",
    "u\\bigr|\\min_{s\\in s}x_s > u\\right)\\\\ & = & \\p\\left(\\min\\left\\{u\\left(\\min_{s\\in h}x_s - u\\right),\\min_{s\\in      e\\setminus s}\\left [ x_{s}-u\\mu(s)\\right]\\right\\}>0\\bigr|\\min_{s\\in      s}x_s > u\\right)\\\\ & \\to&\\e w\\,,\\end{aligned}\\ ] ] the limit in the last line following from with @xmath342 in the definition of @xmath343 and the fact that by property 3 the gaussian random variables @xmath352 are nondegenerate . thus , follows .    in view of and part ( iii ) of proposition",
    "[ l : gauss.vector ] , all that needs to be shown for is that @xmath353 where @xmath214 is the optimal value in which is strictly positive by property 2 .",
    "however , theorem 5.1 of @xcite  implies that @xmath354 and the unique minimizer is @xmath147 .",
    "this in conjunction with establishes .",
    "this completes the proof .    for the final claim ,",
    "recall from the definition that @xmath355 a.s .  if fails .",
    "it immediately follows that @xmath356 implies . for the converse ,",
    "that is , the ` if ' part , suppose that holds .",
    "then , @xmath357 a.s .  .",
    "property 3 implies that the collection @xmath358 is linearly independent .",
    "the random vector @xmath359 has a multivariate normal law .",
    "the linear independence implies that @xmath360 it is trivial to check from that on this event , @xmath361 .",
    "thus , the ` if ' part follows , which completes the proof .",
    "fix a borel subset @xmath296 of @xmath97 $ ] such that @xmath362 where @xmath363 denotes the boundary of @xmath296 in the supremum norm topology , and write    @xmath364}x_t >",
    "u\\right.\\right)\\\\   \\nonumber=&\\frac{\\p\\left((x_t - u\\mu(t):a\\le t\\le b)\\in b,\\ , \\min_{t\\in              [ a , b]}x_t > u\\left|\\min_{t\\in               s}x_t > u\\right.\\right)}{\\p\\left ( \\min_{t\\in [ a , b]}x_t >",
    "u\\left|\\min_{t\\in              s}x_t > u\\right.\\right)}\\,.\\end{aligned}\\ ] ]    the denominator converges to @xmath365 by theorem [ t.q1 ] , as @xmath7 , and it is positive since is assumed .",
    "furthermore , the same argument as the one used in the proof of theorem [ t.q1 ] gives us @xmath366}x_t > u\\left|\\min_{t\\in               s}x_t >",
    "u\\right.\\right )   \\\\ & = &   \\e\\left [ { { \\bf 1}}\\left ( \\bigl ( z_t : a\\le",
    "t\\le b\\bigr)\\in b\\right)w\\right]\\,,\\end{aligned}\\ ] ] and the statement of the theorem follows .",
    "theorems [ t4 ] and [ t5 ] are both based on the following result that we prove first .",
    "[ t4.new ] under assumptions of theorem [ t.q1 ] , assume also that holds . for @xmath110 define @xmath367\\cap[a , b]}x_s , \\ , 1\\le j\\le k\\,.\\ ] ] then @xmath368 } x_t\\right|   \\min_{t\\in [ a , b ] } x_t > u\\right)=1\\,.\\ ] ] furthermore , for @xmath110 small enough so that the convergence in all parts of theorem [ t1 ] holds , as @xmath7 , conditionally on the event @xmath369 } x_t > u\\bigr\\}$ ] , @xmath370 where @xmath333 are independent exponential random variables with respective parameters @xmath154 .    with the notation @xmath315 as above and the set @xmath343 defined in",
    ", we first prove that @xmath371}x_t > u\\right)=1\\ ] ] ( note that the definition of @xmath343 depends on @xmath110 ) .",
    "let @xmath110 be small enough so that the convergence in all parts of theorem [ t1 ] holds .",
    "as in the proof of theorem [ t.q1 ] , we denote by @xmath321 the limit in probability of @xmath372\\cap[a , b]}x_s\\right)\\,,\\ ] ] as @xmath7 , conditionally on the event @xmath373 .",
    "arguing , once again , as in the proof of theorem [ t.q1 ] , we obtain @xmath374}\\right)\\in\\cdot\\right| \\min_{t\\in [ a , b]}x_t > u\\right ]   \\\\",
    "\\label{t4.new.eq2}\\rightarrow & \\ \\frac{1}{\\e w } \\p\\biggl [ \\left({\\min_{1\\le j\\le                                  k}(e_j - w_j)},\\ , { \\min_{s\\in                                   g}z_s}\\right)\\in\\cdot , \\\\ & \\hskip 1 in      e_1-w_1>0,\\ldots , e_k - w_k>0 , \\ ,                                   \\min_{j = k+1,\\ldots , l}z_{t_j}>0 \\biggr ] \\notag\\end{aligned}\\ ] ] weakly in @xmath375 .",
    "we conclude both that , conditionally given @xmath376}x_t > u\\bigr\\}$ ] , as @xmath7 , @xmath377}{\\stackrel{p}{\\longrightarrow}}0\\ ] ] and that @xmath378<0\\right| \\min_{t\\in      [ a , b]}x_t > u \\right ) \\to 0\\,.\\ ] ] since @xmath346 for all @xmath379 $ ] , it follows that @xmath380}x_t > u\\right)\\\\ & \\ge&\\p\\left(\\left.\\min_{1\\le j\\le k}m_{j{\\varepsilon}}-u<\\min_{s\\in        g}[x_s - u\\mu(s)]\\right| \\min_{t\\in   [ a , b]}x_t > u \\right)\\\\ & \\ge&\\p\\left(\\left.\\left|\\frac{\\min_{1\\le j\\le        k}m_{j{\\varepsilon}}-u}{\\min_{s\\in g}[x_s - u\\mu(s)]}\\right| < 1\\right| \\min_{t\\in   [ a , b]}x_t >",
    "u\\right)\\\\ & & -\\p\\left(\\left.\\min_{s\\in g}[x_s - u\\mu(s)]<0\\right|\\min_{t\\in     [ a , b]}x_t > u \\right ) \\to 1\\,.\\end{aligned}\\ ] ] therefore , follows .",
    "the fact that @xmath381 for all @xmath379\\setminus e$ ] with an appeal to theorem [ t3 ] implies .    in order to prove , fix @xmath382 .",
    "the same argument as in gives us @xmath383}x_t > u\\right)\\\\ & = & \\frac{1}{\\e w}\\p\\left(e_j - w_j > x_j\\,,1\\le j\\le k , \\ ,   \\min_{j = k+1,\\ldots , l}z_{t_j}>0 \\right)\\\\   & = & \\p\\left(e_j > x_j\\,,1\\le j\\le k\\right)\\,,\\end{aligned}\\ ] ] the last equality following by first conditioning on @xmath89 and then using the memoryless property of @xmath384 . thus follows .    by , , and the fact that @xmath381 for all @xmath379\\setminus e$ ] we conclude that for @xmath385 , @xmath386}x_t - u\\bigr)>x|\\big| \\min_{t\\in      [ a , b]}x_t > u\\right ) \\to e^{-(\\theta_1+\\ldots+\\theta_k)x}\\,.\\ ] ] by , the claim of the theorem follows .    by , for each @xmath247 ,",
    "@xmath387}x_s > u\\right ) \\\\",
    "\\to & \\ , \\p\\bigl ( e_j=\\min(e_1,\\ldots , e_k)\\bigr)=\\frac{\\theta_j}{\\theta_1+\\ldots+\\theta_k}\\ , , \\end{aligned}\\ ] ] so the claim of the theorem will follow once we check that the measure @xmath388 coincides with @xmath54",
    ". however , by the definition of the vector @xmath158 , the vector @xmath389 has identical positive components .",
    "it follows from theorem 4.3 ( ii ) in @xcite  that the measure @xmath390 is optimal for the minimization problem @xmath391 the measure @xmath54 is also optimal for this problem since it is optimal for .",
    "that is , @xmath390 is optimal for as well and , since the latter problem has a unique minimizer , @xmath392 .",
    "in order to illustrate the general results in section [ sec : results ] we will , in this section , look at specific examples of gaussian processes satisfying the assumptions of the general results . we start with a quintessential example of a stationary process .",
    "consider the zero mean stationary gaussian process @xmath92 with covariance function @xmath393 this process has a spectral density that coincides with the standard gaussian density , as in , hence the process has properties s1 and s2 of section [ sec : smoothness ] . therefore , the results in section [ sec : results ] apply . recall that some of the results require the assumption .",
    "we will presently see both that this assumption may fail and that this assumptions fails only rarely .",
    "let @xmath394 it has been shown in proposition 5.3 and example 6.1 of @xcite  that for such an interval , @xmath395\\ , , \\\\",
    "\\nonumber v_*&= & \\frac{1+e^{-b^2/2}}{2}\\,.\\end{aligned}\\ ] ] assumption holds automatically , and theorem [ t.q1 ] implies that @xmath396 for @xmath397 as @xmath7 .",
    "in fact , one can check that @xmath398 by theorem [ t4 ] , conditionally on the event @xmath376}x_{t}>u\\bigr\\ } $ ] , the scaled overshoot @xmath399}x_{t}-u\\bigr)$ ] converges weakly , as @xmath7 , to an exponential random variable with the mean @xmath400 .",
    "next we consider the situation when @xmath401 and @xmath402 , defined by in .",
    "then @xmath95 and @xmath214 are still as in , but we now have @xmath403 and @xmath404 .",
    "theorem [ t.q1 ] still applies , and it gives @xmath405 as @xmath7 , where @xmath406 is as defined in .",
    "the asymptotic conditional distribution of the scaled overshoot @xmath399}x_{t}-u\\bigr)$ ] is same as in the case @xmath407 .",
    "we proceed to the case @xmath401 and @xmath408 with @xmath409 the value of @xmath410 .",
    "proposition 5.5 of @xcite  shows that in this case @xmath411 , \\ , t\\in{{{\\mathbb r}}}\\ , , \\notag \\\\ v_*= &         \\var\\left(\\frac{1-{\\varepsilon}(b)}2\\left(x_a+x_b\\right)+{\\varepsilon}(b)x_{b/2}\\right)\\,.\\label{eg.eq6 } \\end{aligned}\\ ] ] in this case @xmath412 so that holds .",
    "theorem [ t.q1 ] implies that for some @xmath413 , @xmath414 as @xmath7 .",
    "the @xmath127-dependent constant @xmath415 can be explicitly calculated if desired .",
    "the asymptotic conditional distribution of the scaled overshoot @xmath399}x_{t}-u\\bigr)$ ] is exponential with mean @xmath214 .          if a stationary gaussian process satisfies s1 and s2 , then the unique optimizer @xmath54 of the minimization problem must be symmetric around the midpoint of the interval @xmath2 $ ]",
    "; indeed , for any probability measure @xmath28 supported by @xmath2 $ ] , the measure @xmath421 obtained by reflection around the midpoint leads to the same value in the integral and hence , by convexity , @xmath422 is symmetric .",
    "since the optimal measure can not be concentrated at the midpoint of the interval , we conclude that the cardinality of the set @xmath93 in this case is at least 2",
    ". however , for a non - stationary process , @xmath93 may be a singleton .",
    "the next example illustrates this fact .",
    "we start with a stationary centered gaussian process @xmath423 with a spectral measure @xmath19 satisfying s1 and s2 .",
    "let @xmath88 be a standard normal random variable independent of @xmath192 .",
    "define @xmath424 let @xmath425 .",
    "note that the process @xmath0 has property [ assume1 ] by construction .",
    "it is elementary that the covariance function @xmath16 of the process @xmath14 satisfies .    clearly , for any probability measure",
    "@xmath28 on @xmath2 $ ] , @xmath426 therefore , the process @xmath14 has property [ assume2 ] . in order to check that it also has property [ assume3 ] , suppose that for distinct reals numbers @xmath427 and coefficients @xmath428 , we have @xmath429 without loss of generality , we assume @xmath430 . using the independence of @xmath88 and @xmath192 we see that @xmath431 proposition [ p0 ] implies that @xmath432 .",
    "thus , also @xmath433 , and so process @xmath14 has property [ assume3 ] .    note that the choice @xmath434 is , by , the optimal measure @xmath54 .",
    "thus , @xmath435 .",
    "that is , the support @xmath93 is a singleton which contains none of the endpoints of the interval .",
    "that is , the conclusion of proposition [ p2 ] indeed fails without appropriate assumptions on the covariance function of the process .    here",
    "@xmath436 therefore , @xmath437 . by theorem [ t.q1 ] ,",
    "@xmath438 as @xmath7 , where @xmath439 is the second spectral moment of @xmath192 . by theorem",
    "[ t4 ] , conditionally on the event @xmath376}x_{t}>u\\bigr\\ } $ ] , the scaled overshoot @xmath399}x_{t}-u\\bigr)$ ] converges weakly , as @xmath7 , to the standard exponential random variable ."
  ],
  "abstract_text": [
    "<S> we investigate what happens when an entire sample path of a smooth gaussian process on a compact interval lies above a high level . specifically , </S>",
    "<S> we determine the precise asymptotic probability of such an event , the extent to which the high level is exceeded , the conditional shape of the process above the high level , and the location of the minimum of the process given that the sample path is above a high level . </S>"
  ]
}