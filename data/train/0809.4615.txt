{
  "article_text": [
    "many complex systems observed in the physical , biological and social sciences are organized in a nested hierarchical structure , i.e. the elements of the system can be partitioned in clusters which in turn can be partitioned in subclusters and so on up to a certain level ( simon , 1962 ) .",
    "the hierarchical structure of interactions among elements strongly affects the dynamics of complex systems .",
    "therefore a quantitative description of hierarchies of the system is a key step in the modeling of complex systems ( anderson , 1972 ) .",
    "the analysis of multivariate data provides crucial information in the investigation of a wide variety of systems .",
    "multivariate analysis methods are designed to extract the information both on the number of main factors characterizing the dynamics of the investigated system and on the composition of the groups ( clusters ) in which the system is intrinsically organized .",
    "recently physicists started to contribute to the development of new techniques to investigate multivariate data ( blatt et al . , 1996 ; hutt et al . , 1999 ; mantegna , 1999 ; giada and marsili , 2001 ; kraskov et al . , 2005 ; tumminello et al . , 2005 ; tsafrir et al . ,",
    "2005 ; slonim , 2005 ) . among multivariate techniques , natural candidates for detecting the hierarchical structure of a set of data",
    "are hierarchical clustering methods ( anderberg , 1973 ) .",
    "the modeling of the correlation matrix of a complex system with tools of hierarchical clustering has been useful in the multivariate characterization of stock return time series ( mantegna , 1999 ; bonanno et al . , 2001 ; bonanno et al . ,",
    "2003 ) , market index returns of worldwide stock exchanges ( bonanno et al . , 2000 ) , and",
    "volatility increments of stock return time series ( micciche et al . , 2003 ) , where the estimation of statistical reliable properties of the correlation matrix is crucial for several financial decision processes such as asset allocation , portfolio optimization ( tola et al . , 2008 ) , derivative pricing , etc .",
    "we have termed the selection of statistical reliable information of the correlation matrix with the locution `` filtering procedure '' in ref .",
    "tumminello et al .",
    "( 2007a ) .",
    "hierarchical clustering procedures are filtering procedures .",
    "other filtering procedures which are popular within the econophysics community are procedures based on the random matrix theory ( laloux et al . , 1999 ;",
    "plerou et al .",
    ", 1999 ; rosenow et al . , 2002 ; coronnello et al . , 2005 ;",
    "potters et al . , 2005 ;",
    "tumminello et al . , 2007a ) , and procedures using the concept of shrinkage of a correlation matrix ( ledoit and wolf , 2003 ; schfer and strimmer , 2005 ; tumminello et al . , 2007b ) .",
    "many others might be devised and their effectiveness tested .",
    "the correlation matrix of the time series of a multivariate complex system can be used to extract information about aspects of hierarchical organization of such a system .",
    "the clustering procedure is done by using the correlation between pairs of elements as a similarity measure and by applying a clustering algorithm to the correlation matrix . as a result of the clustering procedure",
    ", a hierarchical tree of the elements of the system is obtained .",
    "the correlation based clustering procedure allows also to associate a correlation based network with the correlation matrix .",
    "for example , it is natural to select the minimum spanning tree , i.e. the shortest tree connecting all the elements in a graph , as the correlation based network associated with the single linkage cluster analysis .",
    "different correlation based networks can be associated with the same hierarchical tree putting emphasis on different aspects of the sample correlation matrix .",
    "useful examples of correlation based networks different from the minimum spanning tree are the planar maximally filtered graph ( tumminello et al . , 2005 ) and the average linkage minimum spanning tree ( tumminello et al . , 2007c )",
    ".    in correlation based hierarchical investigations the statistical reliability of hierarchical trees and networks is depending on the statistical reliability of the sample correlation matrix .",
    "the sample correlation matrix is computed by using a finite number of records @xmath0 sampling the behavior of the @xmath1 elements of the system . due to the unavoidable finiteness of @xmath0 , the estimation of the sample correlation matrix",
    "presents a degree of statistical uncertainty that can be characterized under widespread statistical assumptions .",
    "physicists ( laloux et al . , 1999 ; plerou et al . , 1999 ) , have contributed to the quantitative estimation of the statistical uncertainty of the correlation matrix by using tools and concepts of random matrix theory .",
    "however , theoretical results providing the statistical reliability of hierarchical trees and correlation based networks are still not available and therefore , a bootstrap approach has been used to quantify the statistical reliability of both hierarchical trees ( tumminello et al . , 2007d ) and correlation based networks ( tumminello et al . , 2007c ) .",
    "the hierarchical tree characterizing a complex system can also be used to extract a factor model with independent factors acting on different elements in a nested way . in other words ,",
    "the number of factors controlling each element may be different and different factors may act at different hierarchical levels .",
    "tumminello et al .",
    "( 2007d ) have shown how to associate a hierarchically nested factor model to a system described by a given hierarchical structure .",
    "having available a large number of filtering procedures , researchers encounter the necessity to have a quantitative methodology able to estimate the information retained in a filtered correlation matrix obtained from the sample correlation matrix .",
    "it is also important to quantify the stability of the filtering procedure in different realizations or replicas of the process and a distance of the filtered correlation matrix from a given reference model .",
    "for all the above listed purposes , a very useful measure is the one using the kullback - leibler distance that was introduced in tumminello et al .",
    "( 2007a ) .",
    "this distance presents the important characteristics that its value quantifying the distance between a sample correlation matrix and the correlation matrix of the generating model turns out to be independent from the specific correlation matrix of the model both for multivariate gaussian variables ( tumminello et al . , 2007a ) and for multivariate student s @xmath2 variables ( biroli et al . , 2007",
    "; tumminello et al . , 2007b ) .",
    "in the present paper we discuss in a coherent and self - consistent way ( i ) some filtering procedures of the correlation matrix based on hierarchical clustering and the bootstrap validation of hierarchical trees and correlation based networks , ( ii ) the hierarchically nested factor model , ( iii ) the kullback - leibler distance between the probability density functions of two sets of multivariate random variables and ( iv ) the retained information and stability of a filtered correlation matrix .",
    "we apply the discussed concepts to a portfolio of stocks traded in a financial market .",
    "the paper is organized as follows . in section [ corr ]",
    "we discuss how to obtain hierarchical trees and correlation based trees or networks from the correlation matrix of a complex system and we discuss about the role of bootstrap in the statistical validation of hierarchical trees and correlation based networks . in section [ sectionh ]",
    "we discuss the definition and the properties of a factor model with independent factors which are hierarchically nested . in section [ sectionemp ]",
    "we present an empirical application of the hierarchically nested factor model .",
    "section [ kullbacktheor ] discusses how to quantify the information and stability of a correlation matrix by using a kullback - leibler distance and section [ sectioncomp ] presents the quantitative comparison of different filtering procedures performed with the same distance .",
    "section [ sectionconc ] briefly presents some conclusions .",
    "hereafter we discuss a simple example illustrating two filtering procedures of a correlation matrix performed with methods of hierarchical clustering . in our approach , by using the correlation between elements as the similarity measure and by applying a given hierarchical clustering procedure , we first obtain a hierarchical tree . the information present in the hierarchical tree is completely equivalent to the information stored in the filtered matrix and , when the correlation is non - negative for each pair of elements , this matrix is positive definite ( tumminello et al . , 2007d ) .",
    "our example considers the correlation matrix of @xmath3 daily stock returns traded at the new york stock exchange during the time period from january 2001 to december 2003 .",
    "the investigated stocks are aig , ibm , bac , axp , mer , txn , slb , mot , rd , and oxy .",
    "the above presentation order of stocks is given according to their market capitalization at december 2003 .",
    "in this paper , we indicate stocks with their tick symbols . the tick symbol , company name and other information of each company are given in table i. from the table we note that three stocks ( oxy , rd , slb ) belong to the energy sector , three ( ibm , mot , txn ) to the technology sector and four ( aig , axp , bac , mer ) to the financial sector .",
    "the stock return correlation matrix computed by using @xmath4 records is the following @xmath5 where the order of elements of the correlation matrix from left to right and from top to bottom is the one based on capitalization given above .",
    "a large number of hierarchical clustering procedures can be found in the literature .",
    "for a review about the classical techniques see , for instance , anderberg ( 1973 ) . in this paper",
    "we focus our attention on the single linkage cluster analysis ( slca ) and average linkage cluster analysis ( alca ) .",
    "+ the starting point of both the procedures is the empirical correlation matrix @xmath6 .",
    "the following procedure performs the alca giving as an output a hierarchical tree and a filtered correlation matrix @xmath7 :    1 .",
    "set @xmath8 .",
    "2 .   select the maximum correlation @xmath9 in the correlation matrix @xmath10 .",
    "note that @xmath11 and @xmath12 can be simple elements ( i.e. clusters of one element each ) or clusters ( sets of elements ) . @xmath13 and",
    "@xmath14 one sets the elements @xmath15 of the matrix @xmath7 as @xmath16 .",
    "3 .   merge cluster @xmath11 and cluster @xmath12 into a single cluster , say @xmath17 .",
    "the merging operation identifies a node in the rooted tree connecting clusters @xmath11 and @xmath12 at the correlation @xmath9 .",
    "4 .   redefine the matrix @xmath10 : @xmath18 where @xmath19 and @xmath20 are the number of elements belonging respectively to the cluster @xmath11 and to the cluster @xmath12 before the merging operation . note that if the dimension of @xmath10 is @xmath21 then the dimension of the redefined @xmath10 is @xmath22 because of the merging of clusters @xmath11 and @xmath12 into the cluster @xmath17 .",
    "5 .   if the dimension of @xmath10 is larger than 1 then go to step ( ii ) , else stop .",
    "the hierarchical trees obtained from the sample correlation matrix of eq .",
    "( [ corrmat ] ) by applying the alca and the slca are given in fig .",
    "[ dendroalca ] and in fig .",
    "[ dendroslca ] respectively .",
    "a hierarchical tree is a rooted tree , i.e. a tree in which a special node ( the root ) is singled out . in our example",
    "this node is @xmath27 . in the rooted tree",
    ", we distinguish between leaves and internal nodes .",
    "specifically , vertices of degree @xmath28 represent leaves ( vertices labeled @xmath29 in fig . [ dendroalca ] ) while vertices of degree greater than 1 represent internal nodes ( vertices labeled @xmath27 , @xmath30 , ... ,",
    "@xmath31 in fig .",
    "[ dendroalca ] ) .",
    "the two trees are slightly different showing that each clustering method produce a different output putting emphasis on different aspects of the sample correlation matrix .",
    "the filtered correlation matrix associated with the alca is @xmath32 whereas for the slca we obtain @xmath33 for the sake of comparison , here the alca and slca filtered correlation matrices are both written with the same order of stocks of the sample correlation matrix . by comparing the sample and the filtered matrices one immediately notes that the filtered ones contain less information being defined by a number of distinct correlation coefficients equals to @xmath34 whereas the original matrix has @xmath35 distinct correlation coefficients .",
    "the two filtering methods detect different information .",
    "in fact the alca uses the average correlation coefficient between distinct groups of elements whereas the slca uses the maximal correlation .",
    "the two choices filter correlation coefficients characterized by a different degree of representativeness and statistical reliability .",
    "it is worth noting that the hierarchical methods reveal the sectorial structure of the considered set of stocks .",
    "specifically , in both cases the stocks belonging to the energy sector form a cluster . fig .",
    "[ dendroalca ] shows that for the alca dendrogram the node @xmath30 splits the stocks in two sets , one composed by two technology stocks and one composed by the financial stocks plus the ibm . for the slca",
    "dendrogram the separation of the set in the technology and financial subsectors is less sharp ( see fig .",
    "[ dendroslca ] ) .",
    "however in general hierarchical methods perform quite well in identifying groups of stocks belonging to the same economic sector ( mantegna , 1999 ; bonanno et al . , 2001 ; coronnello et al . ,",
    "2005 ) .",
    "in addition to the hierarchical trees and to the related filtered correlation matrices one can also obtain correlation based networks . here",
    "we briefly recall how to select a correlation based graph out of the complete graph describing the system .",
    "a complete graph is a graph with links connecting all the elements ( or nodes in the graph terminology ) of the system of interest . in correlation",
    "based networks a weigth , which is monotonically related to the correlation coefficient of each pair of elements , can be associsted with each link",
    ". therefore one can immediately associates a weighted completed graph with the correlation matrix among @xmath36 elements of interest .",
    "a complete graph is too rich of information and therefore a `` filterin '' ( or `` pruning '' ) of it can improve its readability .",
    "for this reason a procedure can be set to select a subset of links which are highly informative about the hierarchical structure of the system . by using clastering algorithms as filtering procedures a certain number of correlation based graphs have been investigated in the econophysics literature .",
    "correlation based networks which have been found very useful in the elucidation of economic properties of stock returns traded in a financial market are the minimum spanning tree ( mst ) ( mantegna , 1999 ) , the planar maximally filtered graph ( pmfg ) ( tumminello et al . , 2005 ) and the average linkage minimum spanning tree ( almst ) ( tumminello et al . , 2007c ) .",
    "in the cited cases all the elements of the system are connected within the graph .",
    "correlation based graphs with elements disconnected from a giant component can also be obtained starting from the correlation matrix .",
    "for example , an extension from trees to more general graphs generated by selecting the most correlated links has been proposed in onnela et al .",
    "however , this last method selects only a subset of the investigated elements controlled by an arbitrarely chosen threshold .",
    "the mst is a correlation based tree associated with the slca .",
    "an illustrative algorithm providing the mst is the following .",
    "let us first recall that the connected component of a graph @xmath37 containing the vertex @xmath38 is the maximal set of vertices @xmath39 ( with @xmath38 included ) such that there exists a path in @xmath37 between all pairs of vertices belonging to @xmath39 .",
    "when the element @xmath38 has no links to other vertices then @xmath39 reduces just to the element @xmath38 .",
    "the starting point of the procedure is an empty graph @xmath37 with @xmath1 vertices .",
    "the mst algorithm can be summarized in 6 steps :    1 .   set @xmath40 as the matrix of elements @xmath41 such that @xmath42 .",
    "2 .   select the maximum correlation @xmath43 between elements belonging to different connected components @xmath44 and @xmath45 in @xmath37 . at the first step of the algorithm",
    "connected components coincide with single vertices in @xmath37 .",
    "3 .   find elements @xmath46 , @xmath47 such that @xmath48 4 .",
    "add to @xmath37 the link between elements @xmath46 and @xmath47 with weight @xmath49 .",
    "once the link is added to @xmath37 , @xmath46 and @xmath47 will belong to the same connected component @xmath50 .",
    "redefine the matrix @xmath40 : + @xmath51 6 .",
    "if @xmath52 is still a disconnected graph then go to step ( ii ) , else stop .",
    "+     stocks ( tick symbols label stocks at the bottom of the hierarchical tree . each element of the system is also labeled with an integer number ) .",
    "the color of line indicates the primary economic sector of the stock , red for technology , blue for energy and green for financial .",
    "the labels of the nodes of the hierarchical tree are used in the discussion of the hierarchically nested factor model of section [ sectionh].,scaledwidth=100.0% ]     stocks ( tick symbols label stocks at the bottom of the hierarchical tree ) .",
    "the color of line indicates the primary economic sector of the stock , red for technology , blue for energy and green for financial.,scaledwidth=100.0% ]    the resulting graph @xmath37 is the mst of the system and the matrix @xmath40 is the correlation matrix associated to the slca .",
    "the presented algorithm is not the most popular or the simplest algorithm for the construction of the mst but it clearly reveals the relation between slca and mst .",
    "indeed connected components progressively merging together during the construction of @xmath37 are nothing else but clusters progressively merging together in the slca . in fig .",
    "[ mst10 ] we show the mst associated with the considered example .",
    "it should be noted that the correlation based tree contains more information than the hierarchical tree or the filtered correlation matrix .",
    "for example , the fact that the connection between the cluster of two technology stocks ( mot and txn ) and the cluster of mostly financial stocks ( mer , axp , aig , bac and ibm ) occurs through ibm is something which is not contained in the hierarchical tree but it is present in the mst .        by replacing eq .",
    "( [ singleadjust ] ) with @xmath53 in the step ( v ) of the above procedure one obtains an algorithm performing the alca and the final @xmath40 of the procedure is the correspondent correlation matrix . the obtained tree @xmath37 that we termed almst ( tumminello et al .",
    ", 2007c ) is a tree naturally associated with such a clustering procedure .",
    "the choice of the link at step ( iii ) of the almst construction algorithm does not affect the clustering procedure but specify the construction of the correlation based tree .",
    "more precisely by selecting any link between nodes @xmath54 the matrix @xmath40 representing the result of alca remains the same in terms of hierarchical tree .",
    "this degeneracy allows one to consider different rules to select the link between elements @xmath46 and @xmath47 at the step ( iii ) of the construction algorithm .",
    "different rules at step ( iii ) give rise to different correlation based trees .",
    "the same observation holds true for the algorithm that generates the mst .",
    "this fact implies that in principle one can consider spanning trees which are different from the mst and are still associated with the slca .",
    "however , we have already recalled that the mst is unique in the sense that , when an euclidean distance is defined between links of the spanning tree , mst is the spanning tree of shortest length ( west , 2001 ) .    for the present example",
    "the almst is essentially indistinguishable from the mst and for this reason we will not display it here .",
    "it is worth noting that whereas the hierarchical trees obtained with alca and slca show slight differences , these differences essentially disappears at the level of the associated correlation based trees in the present example .",
    "starting from the sample correlation matrix one can also obtain correlation based networks having a structure more complex than a tree .",
    "one of such correlation based networks is the pmfg ( tumminello et al . , 2005 ) .",
    "this correlation based network has associated a hierarchical structure which is the one given by slca but it presents a graph structure which is richer than the one of the mst .",
    "in fact , the pmfg has loops and cliques .",
    "a clique of @xmath12 elements is a complete subgraph that links all @xmath12 elements . due to topological constraints ,",
    "only cliques of 3 and 4 elements are allowed in the pmfg . to illustrate the pmfg algorithm ,",
    "let us first consider a different construction algorithm for the mst .",
    "following the ordered list @xmath55 of correlation coefficients starting from the couple of elements with largest correlation one adds a link between element @xmath38 and element @xmath56 if and only if the graph obtained after the link insertion is still a forest or it is a tree .",
    "a forest is a disconnected graph in which any two elements are connected by at most one path , i.e. a disconnected ensemble of trees . with this procedure , equivalent to the algorithm above detailed , the graph obtained after all links of @xmath55 are considered is the mst . in direct analogy ,",
    "tumminello et al .",
    "( 2005 ) introduce a correlation based graph obtained by connecting elements with largest correlation under the topological constraint of fixed genus @xmath57 .",
    "the genus is a topologically invariant property of a surface defined as the largest number of nonintersecting simple closed curves that can be drawn on the surface without separating it .",
    "roughly speaking , it is the number of holes in a surface .",
    "the construction algorithm for such graph is : following the ordered list @xmath55 starting from the couple of elements with largest correlation one adds a link between element @xmath38 and element @xmath56 if and only if the resulting graph can still be embedded on a plane or a sphere , i.e. topological surfaces with @xmath57 .",
    "a basic difference of the pmfg with respect to the mst is the number of links which is @xmath58 in the mst and @xmath59 in the pmfg .",
    "moreover , the pmfg is a network with loops whereas the mst is a tree .",
    "it is worth recalling that tumminello et al .",
    "( 2005 ) have proven that the pmfg always contains the mst .    in fig .",
    "[ pmfg10 ] we show the pmfg obtained for the considered example . in the figure",
    "the length of the links is not related to the similarity measure between the two vertices they connect .",
    "we are using this kind of representation to put emphasis on the topological planarity of the network .",
    "in fact from the figure it is evident that there are no crossings of links , and the entire network is topologically embedded in a plane . by comparing fig.s",
    "[ mst10 ] and [ pmfg10 ] we note that the stock mer which turns out to be of central reference in the mst and almst is the only stock partecipating to all the seven 4-cliques which are observed in the pmfg . in other words ,",
    "the pmfg allows to consider more details present in the sample correlation matrix than those selected by the mst or almst .",
    "for example the pmfg of fig .",
    "[ pmfg10 ] shows that two stocks of the financial sector ( axp and mer ) are connected to stocks of both the tecnology and energy sector .",
    "such a property was not present in the mst ( or almst ) where only mer was linking two stocks of the two sectors ( specifically rd and ibm ) .",
    "the pmfg is therefore showing more details on the interrelations present among stocks than the mst .",
    "the pmfg has been recently used to investigate stock return multivariate time series in references tumminello et al .",
    "( 2005 ) , coronnello et al .",
    "( 2005 ) and tumminello et al .",
    "( 2007e ) .        the statistical reliability of regons of hierarchical trees and correlation based graphs can not be theoretically evaluated in spite of the fact that the statistical reliability of the spectral properties of the correlation matrix can be assessed under the assumption of multivariate normal distribution for the time series of the elements of the investigated set . in the absence of such a theoretical approach we have devised a method to evaluate the statistical reliability of nodes in a hierarchical tree obtained by using a correlation matrix as a similarity measure and links in a correlation based graph .",
    "the method we use is based on a bootstrap procedure of the time series used to compute the correlation matrix of the system .",
    "the method is detailed in tumminello et al .",
    "( 2007d ) and tumminello et al .",
    "( 2007c ) .",
    "here we just sketch the most important aspects of the procedure allowing to associate a bootstrap value to each internal node of a hierarchical tree . consider a system of @xmath1 time series of length @xmath0 and suppose to collect data in a matrix @xmath60 with @xmath1 columns and @xmath0 rows .",
    "a bootstrap data matrix @xmath61 is formed by randomly sampling @xmath0 rows from the original data matrix @xmath60 allowing multiple sampling of the same row . for each replica @xmath61 ,",
    "the associated correlation matrix @xmath62 is evaluated and a hierarchical tree is constructed by hierarchical clustering . a large number ( typically 1000 ) of independent bootstrap replicas is considered and for each internal node of the original data hierarchical tree we compute the fraction of bootstrap replicas ( commonly referred to as bootstrap value ) preserving the internal node in the hierarchical tree .",
    "given an internal node @xmath63 of the original hierarchical tree , we say that a bootstrap replica is preserving that node if and only if a node @xmath64 in the replica hierarchical tree exists and identifies a branch characterized by the same leaves identified by @xmath63 in the original hierarchical tree .",
    "for instance , we say that the node @xmath65 of the hierarchical tree in fig .",
    "[ dendroalca ] is preserved in some replica hierarchical tree @xmath66 if and only if a node of @xmath66 exists such that it connects all and only the leaves 1 , 2 , 3 , 4 , and 5 .    in fig .",
    "[ alcaboot ] we show the result of the application of the bootstrap procedure to the alca hierarchical tree of the example shown in section [ corr ] . from the figure it is evident that different nodes have a different statistical reliability as quantified through the bootstrap value .     of the node",
    "according to the following color code : green @xmath67 , cyan @xmath68 , and purple @xmath69.,scaledwidth=100.0% ]    an analogous uncertainty is observed and quantified in correlation based graphs with a similar methodology .",
    "consider a system of @xmath1 elements and suppose to collect data in a matrix @xmath60 with @xmath1 columns and @xmath0 rows .",
    "a bootstrap data matrix @xmath61 is formed by randomly sampling @xmath0 rows from the original data matrix @xmath60 allowing multiple sampling of the same row . for each replica @xmath61 ,",
    "the associated correlation matrix @xmath62 is evaluated and a correlation based graph is constructed . by applying the procedures described in the previous subsection to @xmath6",
    "one can construct , for example , the mst , the pmfg and the almst of the system .",
    "the bootstrap technique requires to construct a number @xmath70 of replicas @xmath71 , @xmath72 of the data matrix @xmath60 .",
    "usually , @xmath73 is considered a sufficient number of replicas . for each replica @xmath71 the correlation matrix is evaluated and the correlation based graph of interest is obtained .",
    "the result is a collection of correlation based graphs .",
    "for example , in the case of msts , @xmath74 . to associate the so called _ bootstrap value _ to a link of the original correlation based graph ( in the present example a mst ) one evaluates the number of @xmath75 where the link is appearing and normalizes such a number with the total number of replicas , e.g. @xmath73 .",
    "the bootstrap value gives information about the reliability of each link of a correlation based graph .",
    "it is worth noting that the bootstrap approach does not require the knowledge of the data distribution and then it is particularly useful to deal with high dimensional systems where it is difficult to infer the joint probability distribution from data .",
    "one might then be tempted to expect that the higher is the correlation associated to a link in a correlation based network the higher is the reliability of the link .",
    "tumminello et al .",
    "( 2007c ) show that such hypothesis is not always observed in empirical results of sets of stock returns traded in a financial market .",
    "the bootstrap vaue and the correlation coefficient can be different indicating a different degree of stability with respect to metric and topological aspects . in figs",
    "[ mst10 ] and [ pmfg10 ] the bootstrap values associated with each link are reported in the figure as the number close to each link . for a detailed discussion about the use of the bootstrap procedure to estimate the reliability of correlation based graphs see tumminello et al .",
    "( 2007c ) .",
    "the filtering procedure of the correlation matrix provides filtered correlation matrices carrying information on the hierarchical structure of the investigated system . a hierarchical factor model associated with such a matrix is useful in the modeling of hierarchical complex systems .",
    "in this section we discuss the hierarchically nested factor model ( hnfm ) .",
    "the hnfm is introduced in tumminello et al .",
    "( 2007d ) in such a way that its correlation matrix coincides with the similarity matrix @xmath76 filtered by a chosen hierarchical clustering procedure .",
    "hereafter , we illustrate the methodology to associate a nested factor model to a multivariate data set .",
    "the association is done by retaining all the information about the hierarchies detected by a hierarchical clustering .",
    "this is achieved by considering a factor model in bijective relation with a hierarchical tree .",
    "we are going to present our method by making use of the illustrative hierarchical tree given in fig .",
    "[ dendroalca ] .",
    "we first note that to each leaf @xmath38 ( or internal node @xmath77 ) one can associate a _ genealogy _",
    "@xmath78 ( @xmath79 for the internal node @xmath77 ) which is the ordered set of internal nodes connecting leaf @xmath38 ( internal node @xmath77 ) to the root @xmath27 .",
    "for instance the genealogy associated to the leaf 3 in the figure is @xmath80 and the genealogy of the internal node @xmath81 in the figure is @xmath82 .",
    "note that the internal node @xmath81 is included in @xmath83 .",
    "we say that an internal node @xmath84 is the _ parent _ of the node @xmath85 and we use the notation @xmath86 if @xmath84 immediately precedes @xmath85 on the path from the root to @xmath85 .",
    "for example @xmath87 in fig .",
    "[ dendroalca ] . beside the topological structure ,",
    "hierarchical trees obtained through clustering algorithms of the correlation matrix have also metric properties .",
    "in fact clustering algorithms associate to each internal node @xmath88 a correlation coefficient @xmath89 .",
    "our internal node labeling implies that @xmath90 and here we consider @xmath91 . in @xmath76",
    "there are at most @xmath58 distinct coefficients ( see discussion in section [ corr ] ) .",
    "exactly @xmath58 distinct coefficients are obtained in case of binary rooted trees .    in tumminello",
    "et al . ( 2007d ) we introduce the factor model @xmath92 where @xmath93 , @xmath94^{1/2}$ ] , the @xmath95 factor @xmath96 and @xmath97 are i.i.d .",
    "random variables with zero mean and unit variance . by fixing the @xmath98 parameters as @xmath99 the model of eq .",
    "( [ model ] ) is the factor model characterized by a correlation matrix equals to a given matrix @xmath100 .",
    "it should be noted that by assuming @xmath91 , all the coefficients @xmath101 are non negative real numbers . in tumminello",
    "( 2007d ) we prove that correlation @xmath102 .",
    "in fact , the cross correlation the mean value of the @xmath103 variable . ] @xmath104 only depends on the factors @xmath105 which are common to @xmath106 and @xmath107 . since one associates a factor to each internal node , one needs to identify the internal nodes belonging to both the genealogies @xmath78 and @xmath108 .",
    "one can verifies that @xmath109 .",
    "for example , in fig .",
    "[ dendroalca ] we have that @xmath110 and @xmath111 so that @xmath112 . by making use of eqs .",
    "( [ model ] , [ coeffic ] ) the cross correlation between variables @xmath106 and @xmath107 is @xmath113 for example with reference to fig .",
    "[ dendroalca ] we have @xmath114 . thus the matrix @xmath100 is the correlation matrix associated with the factor model of eq .",
    "( [ model ] ) .",
    "it is worth noting that the existence of a factor model whose matrix @xmath100 is the correlation matrix implies that the matrix @xmath100 is always positive definite if @xmath91 .    in the case in which negative correlations are associated with some nodes in the dendrogram , it is sometimes possible to suitably modify eqs .",
    "( [ coeffic ] ) by introducing multiplicative sign variables in order to get an hnfm describing the system .",
    "the description of the most general case is left for a future work .",
    "here we just consider the case in which only @xmath115 , because this is the case in the empirical application described in section [ sectionemp ] .",
    "let us assume that all the correlations associated with nodes in the dendrogram are non negative but @xmath115 .",
    "furthermore assume that @xmath116 ( this constraint is satisfied in the empirical application of section [ sectionemp ] ) . in order to construct the hnfm",
    ", we divide the elements of the system into two groups .",
    "these are the two groups of elements merging together at root node .",
    "the coefficient @xmath117 shall be different for elements belonging to different groups .",
    "specifically ,    @xmath118    whereas we do nt need to distinguish among elements belonging to different groups for the other @xmath98 coefficients . specifically    @xmath119    we note that the constraint @xmath116 is required by eq .",
    "( [ coefficalpha22 ] ) in order to have a real value of @xmath98 coefficients .",
    "it is also to notice that @xmath120 , and accordingly , the @xmath98 coefficients associated with all of the nodes different from the root node and its sons as given in eq .",
    "( [ coefficalpha22 ] ) coincide with the corresponding coefficients as defined in eq .",
    "( [ coeffic ] ) .",
    "( [ model ] ) defines a hnfm of @xmath58 factors obtained from a hierarchical tree of @xmath1 elements . in general",
    "the number of factors determining the dynamics of the system can be significantly smaller than @xmath58 . moreover a correlation coefficient matrix obtained from a finite multivariate time series has associated an unavoidable statistical uncertainty that might introduce spurious factors . to overcome this problem , in tumminello et al .",
    "( 2007d ) we propose a method devised to select the hnfm characterized by the largest number of factors ( although in any case less than @xmath1 ) compatible with a predefined threshold of statistical reliability of retained factors .",
    "the method of tumminello et al .",
    "( 2007d ) exploits the technique of non parametric bootstrap ( efron , 1979 ; efron and tibshirani , 1994 ) .",
    "the bootstrap technique allows to associate a bootstrap value to each internal node of a hierarchical tree . due to the one by one relation between nodes in the hierarchical tree and factors in the hnfm",
    ", the bootstrap value associated to a certain node of the hierarchical tree is associated also to the corresponding factor in the hnfm .",
    "since the bootstrap value is a measure of the node s reliability , we propose to remove those nodes , and therefore the corresponding factors , with bootstrap value smaller than a given threshold @xmath121 .",
    "this is done by merging each node with a bootstrap value smaller than @xmath121 with its first ancestor node in the path to the root having a bootstrap value greater than @xmath121 and then constructing the hnfm associated with this reduced hierarchical tree .",
    "the question is how to select the threshold @xmath121 .",
    "the bootstrap value of a certain node ( factor ) can not be straightforwardly intended as the probability that the node ( factor ) belongs to the true and unknown hierarchy ( model ) of the system .",
    "for example , in phylogenetic analysis hillis and bull ( 1993 ) have shown that bootstrap values of more than @xmath122 correspond to a probability of more than @xmath123 that the true phylogeny has been found .",
    "in tumminello et al .",
    "( 2007d ) we do not choose _ a priori _ the value of @xmath121 but we infer a suitable value of the threshold from the data in a self consistent way .",
    "the detailed procedure used to determine the threshold from data is discussed in tumminello et al . (",
    "as an application of the described technique to real data we examine the set of daily equity return of @xmath124 highly capitalized stocks traded at the nyse during the period 2001 - 2003 ( @xmath4 ) .",
    "specifically , we apply the alca to the correlation matrix of the system and we obtain the hierarchical tree shown in fig .",
    "[ dendrodata ] . in the figure ,",
    "the identity of each stock is labeled by an integer number .",
    "the correspondence between each number and the tick symbol of the stock is provided in table i. in the same table we also provide information about the company name and economic sector and sub - sector classified according to yahoo finance .",
    "highly capitalized stocks traded at the nyse during the period 2001 - 2003 obtained by applying the average linkage clustering algorithm to the correlation matrix .",
    "colors are chosen according to the stock economic sector according to the classification of yahoo finance .",
    "specifically these sectors are basic materials ( violet ) , consumer cyclical ( tan ) , consumer non cyclical ( yellow ) , energy ( blue ) , services ( cyan ) , financial ( green ) , healthcare ( gray ) , technology ( red ) , utilities ( magenta ) , transportation ( brown ) , conglomerates ( orange ) and capital goods ( light green).,scaledwidth=100.0% ]    .",
    "rectangles at the bottom are indicating 8 clusters and the associated symbols label the classification of stocks in terms of economic sectors or sub - sectors according to the classification of yahoo finance ( see text for the legend ) .",
    "colors of lines indicate stock sectors as in fig .",
    "[ dendrodata ] .",
    "the labeled internal nodes are discussed in the text . in the figure",
    "we do not comment on clusters composed by only two leaves.,scaledwidth=100.0% ]    to evaluate the statistical robustness of each node and to simplify the description in terms of a hnfm we use the bootstrap technique discussed above .",
    "in particular , we select in a self - consistent way ( see tumminello et al .",
    "( 2007d ) ) the bootstrap value threshold , which turns out to be @xmath125 for the considered dataset .",
    "the corresponding reduced hierarchical tree has 27 nodes and it is reported in fig .",
    "[ nodered ] .",
    "let us first comment the properties of the reduced hnfm . in the figure we observe several clusters and sub - clusters .",
    "as already noticed in previous studies ( mantegna , 1999 ; bonanno et al . , 2001 ; tumminello et al . , 2005 ) , the detected clusters and sub - clusters are overlapping in part with economic classification such as , for example , the one provided by the yahoo finance ( at april 2005 ) .",
    "this can be seen in fig .",
    "[ dendrodata ] and [ nodered ] where we use this classification to characterize with a specific color each stock .",
    "most of the groups detected by hierarchical clustering are characterized by the same color .",
    "for example , financial firms are represented in fig .",
    "[ dendrodata ] and [ nodered ] as green lines in the hierarchical tree .",
    "the root of the dendrogram of fig .",
    "[ nodered ] is associated with a parameter @xmath126 .",
    "this value is negative even if it is not statistically significantly different from zero given that the error associated with the correlation coefficient is @xmath127 .",
    "the fact that @xmath115 requires the introduction of sign variables as explained at the end of section [ sectionh ] .",
    "since it is @xmath128 , we can use the eq.s [ coefficalpha11 ] and [ coefficalpha22 ] to determine the parameters of the model .",
    "the root node @xmath27 splits the set of stocks in two subsets , one composed by one stock ( nem , a gold mining company , see table i ) and another composed by @xmath129 stocks .",
    "the value of @xmath130 is consistent with the interpretation that nem is uncorrelated to the rest of the stocks . by using eq .",
    "[ coefficalpha11 ] we set @xmath131 and @xmath132 . the second factor ( node ) @xmath30 describes the market mean behavior and it is associated with the parameter @xmath133 .",
    "the other @xmath134 factors describe clusters of stocks that are often significantly homogeneous with respect to the sector activity of the stocks . in fig .",
    "[ nodered ] we have highlighted 8 clusters by using rectangles at the bottom of the figure . specifically , f1 is the sub - sector of _ investment services _ and f2 contains the sub - sectors of _ regional banks _ and _ money center banks_. both f1 and f2 belong to the economic sector of _ financial _ ;",
    "t and e are indicating the economic sectors of _ technology _ and _ energy _ respectively ; h1 indicates the sub - sector _ major drugs _ of the economic sector _ healthcare _ ; s1 and s2 indicate the two sub - sectors of _ retail _ and _ communication services _ of the sector of _ services _ respectively . finally , x is a cluster which is not homogeneous with respect to sector and sub - sector classification .",
    "it comprises stocks in the sector of _ basic materials _ , stocks of the sub - sector _ constructions _ of _ capital goods _ and stocks as emr ( classified as _ technology _ ) and gm ( classified as _ consumer cyclical _ ) .",
    "one prominent example is the group of technology stocks ( group t in fig .",
    "[ nodered ] ) . the first two stocks ( their tick symbols are txn and adi ) from left to right of the group labeled as t in the reduced hnfm of fig .",
    "[ nodered ] are described by the equation @xmath135 the factors @xmath136 and @xmath137 are common to almost all stocks whereas @xmath138 and @xmath139 are specific to these stocks .",
    "the other four technology stocks ( which are emc , ibm , mot and ca ) are described by the equation @xmath140 in this last case only the @xmath138 factor is present in addition to the @xmath136 and @xmath137 factors common to almost all stocks .",
    "it is therefore natural to consider @xmath138 as a factor characterizing technology stocks whereas @xmath141 is an additional factor further characterizing only the two stocks txn and adi .",
    "a similar organization in nested clusters is observed in all the groups detected by the reduced hnfm .",
    "the number of factors characterizing the various stocks is ranging from one to five .",
    "it is worth to compare fig .",
    "[ dendrodata ] and [ nodered ] .",
    "the comparison shows that the self - consistent reduction of the number of factors allow a robust statistical validation of the groups that are detected from the data analysis .",
    "only the information which is statistically robust at the @xmath123 level is retained in the reduced hnfm .",
    "for example , the financial cluster observed at the left end of the hierarchical tree in fig .",
    "[ dendrodata ] is not robust at the selected confidence level whereas the two sub - clusters indicated as f1 ( leh , bsc , mer and sch ) and f2 ( ncc , sti , one , pnc , bac , wfc , bk and mel ) in fig.[nodered ] are .",
    "this empirical analysis has shown the usefulness of hnfm in an empirical investigation of hierarchically organized complex systems .",
    "in tumminello et al . ( 2007a ) we propose to measure the performance of filtering procedures by using the kullback - leibler distance introduced by kullback and leibler ( 1951 ) .",
    "the kullback - leibler distance ( see , for instance , cover and thomas ( 1991 ) ) or _ mutual entropy _ is a measure of the distance between two probability densities , say @xmath47 and @xmath17 .",
    "it is defined as @xmath142,\\ ] ] where @xmath143 $ ] indicates the expectation value with respect to the probability density @xmath47 .",
    "the kullback - leibler distance is asymmetric . in eq.([kullbackeqgen ] ) the expectation value is evaluated according to the distribution @xmath47 .",
    "we consider first the kullback - leibler distance between multivariate gaussian random variables ( tumminello et al . , 2007a ) .",
    "we consider variables with zero mean and unit variance without loss of generality because we are interested in the comparison of the correlation matrices of the two sets of variables . in this case , the gaussian multivariate distribution associated with the random vector @xmath144 is completely defined by the correlation matrix @xmath145 of the system . in the following we indicate the probability density function with @xmath146 . given two different probability density functions @xmath147 and @xmath148",
    ", we have @xmath149 =   \\nonumber \\\\ = \\int{p({\\bf",
    "\\sigma}_1,x ) \\log\\left [ \\frac{p({\\bf \\sigma}_1,x)}{p({\\bf \\sigma}_2,x)}\\right ] dx},\\end{aligned}\\ ] ] by performing the integral in eq .",
    "( [ kullbackmulti ] ) one obtains : @xmath150,\\end{aligned}\\ ] ] where @xmath1 is the dimension of the space spanned by the @xmath144 variable and @xmath151 indicates the determinant of @xmath145 . from now on we indicate @xmath152 simply with @xmath153 . it is worth noting that the kullback - leibler distance takes naturally into account the statistical nature of correlation matrices .",
    "indeed @xmath153 is well defined only provided that the matrices @xmath154 and @xmath155 are positive definite .",
    "this property is not common to other measures of distance between matrices .",
    "however this property can also be a limitation .",
    "the kullback - leibler distance can not be used to quantify the distance between semi - positive correlation matrices that are observed , for example , when the length @xmath0 of data series is smaller than the number @xmath1 of elements of the system .",
    "the kullback - leibler distance is also related to the maximum likelihood factor analysis ( mardia et al . , 1979 ) .",
    "in fact , the log - likelihood function to be maximized in order to describe a system of @xmath1 elements with sample correlation matrix @xmath6 is a function of the kullback - leibler distance between the @xmath6 and the model correlation matrix ( see tumminello et al .",
    "( 2007a ) for details ) .",
    "we have obtained the value of the kullback - leibler distance between two multivariate distribution as a function of the two corresponding pearson correlation matrices .",
    "we are interested to the case in which one or both correlation matrices are sample correlation matrices and thus are random variables . since different realizations of the process give rise to different sample correlation matrices , a kullback - leibler distance having one or two sample correlation matrices as arguments is a function of one or two random matrices . in the case of multinormally distributed variables ,",
    "we consider a random vector @xmath144 of dimension @xmath1 with a model correlation matrix @xmath145 .",
    "let @xmath156 and @xmath157 be two sample correlation matrices obtained from two independent realizations of the system both of length @xmath0 .",
    "it is known that in this case sample covariance matrices belong to the ensemble of wishart random matrices and many statistical properties of wishart matrices are known ( mardia et al . , 1979 ) ) . by making use of the theory of wishart matrices",
    ", we obtained ( tumminello et al .",
    ", 2007a ) that @xmath158=\\frac{1}{2 } \\left \\{n\\log{\\left(\\frac{2}{t}\\right)}+ \\sum_{p = t - n+1}^{t}{\\left[\\frac{\\gamma^{\\prime}(p/2)}{\\gamma(p/2)}\\right]}+\\frac{n ( n+1)}{t - n-1}\\right\\},\\end{aligned}\\ ] ] @xmath159=\\frac{1}{2 } \\left \\{n\\log{\\left(\\frac{t}{2}\\right ) }   -\\sum_{p = t - n+1}^{t}{\\left[\\frac{\\gamma^{\\prime}(p/2)}{\\gamma(p/2)}\\right]}\\right\\}\\end{aligned}\\ ] ] and @xmath160=\\frac{1}{2 } \\frac{n ( n+1)}{t - n-1},\\ ] ] where @xmath161 is the usual gamma function and @xmath162 is the derivative of @xmath161 .",
    "it is important to observe that all the expectation values given in eq.s ( [ kullexpecsigs1]-[kullexpecs1s2 ] ) are independent of @xmath145 , i.e. they are independent of the specific model generating or describing the data .",
    "the independence property implies that ( i ) the kullback - leibler distance is a good measure of the statistical uncertainty of correlation matrix which is due to the finite length of data series and ( ii ) the expected value of the kullback - leibler distance is known also when the underlying model hypothesized to describe the system is unknown .",
    "this fact has important consequences .",
    "suppose one knows that the observed data are well approximated by a multivariate gaussian distribution and that one measures a sample correlation matrix @xmath6 . in order to remove some",
    "unavoidably present statistical uncertainty , the observer applies a filtering procedure to the data obtaining the filtered correlation matrix @xmath163 .",
    "if the filtering technique is able to recover the model correlation matrix , i.e. @xmath164 , the kullback - leibler distance @xmath165 must be equal on average to the value given in eq .",
    "( [ kullexpecs1sig ] ) .",
    "this expected value is independent on the ( unknown ) model correlation matrix @xmath145 .",
    "therefore large deviations from this expectation value indicate that the filtered matrix is not consistent with the true matrix of the system . if @xmath165 is significantly smaller than the expectation value of eq .",
    "( [ kullexpecs1sig ] ) the filtered matrix is keeping some of the statistical uncertainty due to the finite length @xmath0 . if , on the other hand , @xmath165 is significantly larger than the value of eq .",
    "( [ kullexpecs1sig ] ) , it means that the filtered matrix is either filtering too much information or distorting the signal .",
    "the distance between @xmath165 and the expected value of eq .",
    "( [ kullexpecs1sig ] ) is a measure of the goodness of the filtering procedure in keeping the maximal amount of information which can be present in sample correlation matrices estimated with a finite number of records .    a second aspect concerns the stability of the filtered correlation matrix obtained from a sample matrix",
    "let us suppose to apply a certain filtering procedure to the correlation matrices @xmath156 and @xmath157 of two independent realizations of the system , obtaining two filtered correlation matrices @xmath166 and @xmath167 . if it turns out that @xmath168 is larger than the expected value of @xmath169 described by eq .",
    "( [ kullexpecs1s2 ] ) , one can conclude that the filtering procedure produces correlation matrices less reproducible than the sample correlation matrices and therefore the procedure is not suitable for the purpose of filtering robust information from the empirical correlation matrices @xmath156 and @xmath157 .    in summary , in tumminello",
    "et al . ( 2007a ) we have shown that the kullback - leibler distance is very good for comparing correlation matrices .",
    "its main properties are that ( i ) it is an asymmetric distance and therefore it can distinguish between quantities observed in real systems and used to model the empirical observations , e.g. the sample correlation matrix and the filtered correlation matrix respectively and ( ii ) the expectation values of the kullback - leibler distance given in eq.s ( [ kullexpecsigs1]-[kullexpecs1s2 ] ) are model independent , indicating that this distance is a good estimator of the statistical uncertainty due to the finite size of the empirical sample .",
    "these properties are not observed in other widespread distances between matrices .",
    "for example , tumminello et al . (",
    "2007a ) have shown that these properties are not observed for the frobenius distance , which is a standard measure of the distance between matrices .",
    "biroli et al .",
    "( 2007 ) have extended the above results on the kullback - leibler distance to a general class of elliptic distributions . specifically , they considered random variables @xmath106 @xmath170 that can be generated by starting from random variables @xmath171 @xmath170 following a generic multivariate distribution and by setting @xmath172 , where @xmath173 is a positive random variable .    as a specific example , which is also relevant for financial data , they considered the multivariate student s t - distribution . in this case the variables @xmath171 are taken from a multivariate normal distribution with correlation matrix @xmath145 and @xmath173 is distributed according to @xmath174\\frac{s_0^\\mu}{s^{1+\\mu}}\\ ] ] where @xmath175 in such a way that @xmath173 has unit variance .",
    "the joint probability density function for the @xmath106 is @xmath176 where the parameter @xmath177 gives the degrees of freedom of the distribution and describes the tail behavior of the marginal distribution of any @xmath106 since @xmath178 .",
    "let us assume that the correlation matrix is computed with the pearson estimator for correlation coefficients .",
    "biroli et al .",
    "( 2007 ) show that the kullback - leibler distance between two multivariate student s t - distributions with the same scaling parameter @xmath177 , and correlation matrices @xmath154 and @xmath155 is @xmath179,\\end{aligned}\\ ] ] in the limit @xmath180 this expression coincides with the one obtained for the gaussian case above , whereas in the limit @xmath181 biroli et al .",
    "( 2007 ) obtain @xmath182.\\ ] ]    now consider a random vector @xmath144 of dimension @xmath1 with correlation matrix @xmath145 and distributed according to eq .",
    "( [ studenteq ] ) .",
    "let @xmath156 and @xmath157 be two sample correlation matrices obtained from two independent realizations of the system both of length @xmath0 .",
    "it is possible to show ( biroli et al . , 2007 )",
    "that , similarly to the gaussian case , the expectation values @xmath183 $ ] , @xmath184 $ ] and @xmath185 $ ] , where the kullback - leibler distance is calculated according to either eq .",
    "( [ kullstud ] ) or eq .",
    "( [ kullstudsmallmu ] ) , are not depending on @xmath145 , i.e. the expectation values are model independent .",
    "this important property is valid not only for gaussian multivariate variables but it holds true in general for elliptic multivariate distributions .",
    "this is due to the fact that for generic multivariate distributions the kullback - leibler distance can be written as @xmath186 $ ] , where @xmath187 is a function independent of the correlation structure of the system ( biroli et al .",
    "( 2007 ) ) .",
    "it is interesting to compare the expression of kullback - leibler distance for gaussian and student s variables .",
    "specifically , we can compare eq .",
    "( [ kullbackgaussian ] ) and eq .",
    "( [ kullstudsmallmu ] ) .",
    "the right hand side of both the equations is the sum of two terms .",
    "the first term , @xmath188 , is the same for both the equations .",
    "let s then focus our attention on the second terms of the equations and , in particular , on the second term of eq .",
    "( [ kullstudsmallmu ] ) , which is @xmath189 $ ] .",
    "suppose that the correlation matrix @xmath154 is very close to @xmath155 , i.e. @xmath190 .",
    "then , under this assumption , @xmath191 . under this assumption , at first order in @xmath192 , we have @xmath193\\simeq \\frac{n}{2}\\left [ \\frac{1}{n}\\text{tr}\\left({{\\bf \\sigma}_2^{-1 } { \\bf \\sigma}_1 } \\right)- 1\\right],\\ ] ] which is exactly the second term of the right hand side of eq .",
    "( [ kullbackgaussian ] ) .",
    "this calculation shows that whenever the correlation matrices involved in the kullback - leibler distance are very close one to the other ( @xmath190 ) then the expression of the kullback - leibler distance for student s t - distributions with small @xmath177 coincides , at the first order of approximation , with the expression of the kullback - leibler distance obtained for gaussian random variables .    as a final remark",
    "we note that there is way to compute the expected value of a kullback - leibler distance which does not make use of the pearson estimator .",
    "it is known that the pearson s estimator of the correlation matrix is not the maximum likelihood estimator when the variables are non - gaussian . in the case of the student s t - distribution of eq .",
    "[ studenteq ] there exists a recursive equation for the maximum likelihood estimator @xmath194 which is ( bouchaud and potters , 2003 ) @xmath195 since the maximum likelihood estimator of eq .",
    "( [ mle ] ) of correlation matrix follows a wishart distribution in the large @xmath1 limit , then the expectation values above can be calculated by making use of wishart theory also in the case of student s variable ( biroli et al .",
    ", 2007 ; tumminello et al . , 2007b ) .",
    "finally , it is worth noting that there exists a straightforward modification of the hnfm of eq .",
    "( [ model ] ) to generate hierarchically organized random variables with the multivariate student s t - distribution .",
    "specifically , we consider @xmath196",
    "the kl distance can therefore be used to quantify and compare the performance of different filtering procedures of correlation matrices ( tumminello et al . , 2007a ) .",
    "a good filtering procedure should have two important properties : ( i ) being able to remove the ",
    "right \" amount of noise from the data in order to recover the signal and ( ii ) produce filtered matrices which are stable when one makes different observations of the same system .",
    "these two requirements are often in competition one with the other .",
    "the proposed procedure to evaluate the performance of a filtering procedure is the following .",
    "suppose we are given with a data sample @xmath60 and we have our favorite filtering procedure .",
    "we generate @xmath197 bootstrap replicas @xmath198 ( @xmath199 ) of the data .",
    "we then compute the sample correlation matrix @xmath200 and apply the filtering procedure obtaining the filtered matrix @xmath201 to each replica @xmath198 . in order to measure the stability of the filtering procedure",
    ", we consider the average of the quantity @xmath202 over the replicas .",
    "an optimal filtering procedure should be perfectly stable ( i.e. @xmath203 ) because from each realization the filtering recovers the model matrix . in order to measure the filtered information we consider the average of @xmath204 over the replicas .",
    "this quantity measures the information present in the sample correlation matrix @xmath200 that has been discarded by the filtering procedure .",
    "we have seen above that for gaussian variables the kl distance @xmath205 is different from zero and independent from the model @xmath145 ( see eq .",
    "( [ kullexpecs1sig ] ) ) .",
    "therefore if our filtering procedure is recovering the true underlying model we should expect that @xmath204 is equal to the right hand side of eq .",
    "( [ kullexpecs1sig ] ) .",
    "we have thus a reference value for both the stability and the information expected from an optimal filtering and these values are independent from the underlying model .",
    "we represent the result of the analysis in a plane where the @xmath103 axis reports the stability @xmath206 and the @xmath207 axis reports the information @xmath208 . in this plane the optimal point , labeled @xmath145 , has coordinate @xmath209 and @xmath207 equal to the right hand side of eq .",
    "[ kullexpecs1sig ] .",
    "a filtering procedure will be considered good if the corresponding point in the stability - information plane is close to @xmath145 .    to provide representative examples of quantitative analysis with the kullback - leibler distance of filtering procedures based on hierarchical clustering , as in the other sections , we consider slca and alca .",
    "we also consider filtering procedures based on the shrinkage technique ( ledoit and wolf , 2003 ) and on the random matrix theory ( rmt ) ( laloux et al .",
    ", 1999 ; plerou et al . , 1999 ; rosenow et al . , 2002 ;",
    "potters et al . , 2005 ) .",
    "for the case of the the shrinkage procedure we construct a filtered matrix as @xmath210 where @xmath211 and @xmath212 is a target matrix . as commonly done in financial literature , we choose the target matrix as a matrix with @xmath213 and @xmath214 for @xmath215 .",
    "we estimate the performance of the shrinkage procedure for different values of @xmath216 .",
    "it is interesting to note that there exist analytical methods to obtain the optimal value @xmath217 according to a cost function based on standard quadratic ( or frobenius ) norm ( schfer and strimmer , 2005 ) . in the figures we also show the point ( labeled @xmath218 ) corresponding to the value @xmath217 .    in the econophysics literature ,",
    "a widespread filtering procedure of the correlation matrix is based on the random matrix theory ( metha , 1990 ) .",
    "if the @xmath1 variables are independent and with finite variance then in the limit @xmath219 , with a fixed ratio @xmath220 , the eigenvalues of the pearson sample correlation matrix @xmath6 is bounded from above by the value @xmath221 where @xmath222 for correlation matrices . in some practical cases , such as for example in finance",
    ", one finds that the largest eigenvalue @xmath223 of the empirical correlation matrix is definitely inconsistent with rmt . in these cases ,",
    "laloux et al . ( 1999 ) propose to modify the null hypothesis so that correlations can be explained in terms of a one factor model and @xmath224 .",
    "the filtering procedure considered here has been proposed by potters et al .",
    "( 2005 ) and it works as follows .",
    "one diagonalizes the correlation matrix and replaces the all eigenvalues smaller than @xmath225 in the diagonal matrix with their average value .",
    "then one retransforms the modified diagonal matrix in the standard basis obtaining a matrix @xmath226 of elements @xmath227 to preserve the trace .",
    "finally , the filtered correlation matrix @xmath228 is the matrix of elements @xmath229 .    in fig .",
    "[ rmt ] we show the kl distance in the plane stability - information for these filtering procedures applied to artificial data generated according to two different models .",
    "the left panel shows the result for a model whose correlation matrix is block diagonal with @xmath230 blocks , whereas the right panel shows the result for a hnfm with @xmath231 factors . in both panels",
    "we show the points corresponding to the rmt , slca , and alca filtering procedures .",
    "we also show the points corresponding to the shrinkage filtering procedure of eq .",
    "[ shrinkage ] for different values of @xmath216 .",
    "the shrinkage method is capable to achieve a very good compromise between stability and information . from this analysis it is possible to extract an optimal value of @xmath216 minimizing the distance from the point labeled with @xmath232 .",
    "it should be noted that this value in general does not coincide with the value @xmath217 obtained with the method of schfer and strimmer ( 2005 ) , i.e. by minimizing the frobenius norm .",
    "axis ) against the amount of information about the correlation matrix that is retained in the filtered matrix ( @xmath207 axis ) for @xmath124 stocks of the nyse in the period 2001 - 2003 ( @xmath4 ) .",
    "the points labeled with @xmath233 correspond to the shrinkage procedure ( see eq .  [ shrinkage ] ) and",
    "the parameter @xmath216 goes from @xmath234 to @xmath28 when one goes from the bottom right to the top left corner .",
    "the point @xmath235 is obtained for @xmath236 , which is the value of the shrinkage parameter that minimize the euclidean distance in the plane stability - information between the curve corresponding to @xmath233 and the point associated with @xmath232 .",
    "the latter point represents the expectation value for a filtering procedure able to recover the true correlation matrix of the system .",
    "see the text for more details . ]",
    "we now consider an application to a real system . we investigate the daily returns of @xmath124 highly capitalized stocks traded at the nyse in the period 2001 - 2003 ( @xmath4 ) . in present study , differently than in tumminello",
    "( 2007a ) where we worked in the gaussian approximation , we assume stock returns to be student s t - distributed according to eq .",
    "( [ studenteq ] ) , .",
    "the scaling parameter @xmath177 in the distribution of eq .",
    "( [ studenteq ] ) is assumed to be the same for all of the stocks in the portfolio .",
    "accordingly , we determine @xmath177 as the average value of the maximum likelihood estimates of @xmath177 independently evaluated for each stock .",
    "the result is @xmath237 with a standard deviation @xmath238 .",
    "the ratio @xmath239 is much less than one and therefore ensures that eq .",
    "( [ kullstudsmallmu ] ) is a good approximation of the kullback - leibler distance for the present case . in fig .",
    "[ nyse ] we show the performance of different filtering procedures in the plane stability - information . in the figure the kullback - leibler distance is calculated according to eq .",
    "( [ kullstudsmallmu ] ) .",
    "the filtering procedures based on rmt , slca and alca have different properties in terms of stability and information ( tumminello et al . , 2007a ) .",
    "slca is the most stable even if it is the least informative , whereas rmt is the least stable but the most informative .",
    "alca has intermediate properties both with respect to stability and to information .",
    "the filtering procedure based on shrinkage seems to outperform the other filtering techniques for selected values of the @xmath216 parameter . in fig .",
    "[ nyse ] , we also highlight ( red color ) a point corresponding to the optimal value @xmath240 of the shrinkage parameter @xmath216 in the plane stability - information .",
    "this point is obtained by minimizing the euclidean distance between the points @xmath241 and @xmath242 in the space stability - information .",
    "the point @xmath241 is expected for a filtering procedure able to perfectly detect the correlation matrix @xmath145 of the system .",
    "our aim is now to estimate @xmath243 . by using the estimate of @xmath177",
    ", we evaluate the quantity @xmath243 by exploiting the model independency of the kullback - leibler distance . during our analysis",
    "we realized that for student s t - distributions the bootstrap replicas , which we actually use to deal with real data , can introduce a bias with respect to independent simulations . by performing numerical simulations of student s t - distributed random variables characterized by different values of @xmath177",
    ", we notice that this bias does not appear in the case of normal or close to normal distributions ( typically when @xmath177 is greater than 10 ) . in order to overcame the problem when student s t - distributed random variables with a low value of @xmath177 describe the data better than gaussian random variables",
    ", we perform 100 independent simulations of student s t - distributed data series of length @xmath4 ( the same as real data ) according to the model of eq .",
    "( [ hnfmstud ] ) with scaling parameter @xmath237 and we construct 100 bootstrap replicas of each simulated data series . it is to notice that the choice of eq .",
    "( [ hnfmstud ] ) does not affect the generality of results because the expectation values of the kullback - leibler distance do not depend on the correlation structure of the model .",
    "we indicate the correlation matrix of simulated series with @xmath244 ( @xmath245 ) , and the correlation matrix of a bootstrap replica associated with @xmath244 with @xmath246 ( i=1, ... ,100 ) . because the expectation value of the correlation matrix @xmath246 is @xmath244 and the expectation values of the kullback - leibler distance are model independent , we can estimate the value of @xmath243 as @xmath247 , where the average is taken over both the indices @xmath38 and @xmath56 .",
    "the result we obtain @xmath248 .",
    "this result is shown in the fig .",
    "[ nyse ] as a blue circle . finally ,",
    "in order to associate an error bar with this value , we apply the same procedure used to obtain the estimate of @xmath243 for values of @xmath177 equal to @xmath249 ( providing the value at the top of the error bar in the figure ) and @xmath250 ( providing the value at the bottom of the error bar in the figure ) .",
    "a series of numerical simulations performed with different model generating the dynamics of the random variables show that the bias introduced by bootstrapping data instead of performing independent simulations turns out to be approximately independent of the actual correlation matrix of the system and for @xmath237 , n=100 , and @xmath4 the bias is equal to @xmath251 , i.e. the bootstrap based estimation gives an underestimate of @xmath243 .",
    "however , in the investigations summarized in fig .",
    "[ nyse ] the bias is the same for all of the points and therefore the comparison of filtering procedure is possible .",
    "our numerical simulations also show that the value of the bias tends to increase as the value of @xmath177 decreases .",
    "it is also worth noting that results very similar to those shown in fig .",
    "[ nyse ] can be obtained by using the expression of eq .",
    "( [ kullbackgaussian ] ) ( valid for gaussian variables ) to evaluate the kullback -leibler distance instead of eq .",
    "( [ kullstudsmallmu ] ) ( valid for student s t - distributed variables with @xmath252 ) .",
    "this fact can be interpreted by observing that the correlation matrices involved in the kullback - leibler distance do not differ much one from the other and , therefore , eq . ( [ kullstudsmallmu ] ) gives estimates of the kullback - leibler distance similar to those obtained by using eq .",
    "( [ kullbackgaussian ] ) that is strictly speaking only valid for gaussian variables , and which has been used in tumminello et al .",
    "( 2007a ) . a final remark concern the shrinkage technique .",
    "we note that the shrinkage parameter @xmath240 is significantly different than @xmath253 , obtained by minimizing the frobenius norm . the point associated with @xmath253 ( green circle in fig .",
    "[ nyse ] ) in the plane stability - information is quite far from the point of an ideal filtering procedure able to perfectly detect the correlation matrix @xmath145 of the system ( blue circle in fig .",
    "[ nyse ] ) .",
    "this observation suggests that by using the frobenius distance to get an estimate of the shrinkage parameter @xmath216 one puts too much faith on the statistical robustness of the sample correlation matrix .",
    "conversely , @xmath254 represents a more reliable estimate of the optimal shrinkage parameter .",
    "this paper discusses several methods to quantitatively investigate the properties of the correlation matrix of a system of n elements . in the present work we consistently investigate the correlation matrix of the synchronous dynamics of the returns of a portfolio of financial assets .",
    "however , our results apply to any correlation matrix computed starting from the series of t records belonging to n elements of a system of interest .",
    "specifically , we discuss how to associate to a correlation matrix a hierarchical tree and correlation based trees or graphs . in previous papers",
    "we have shown that the information selected through these clustering procedures and the construction of correlation based trees or graphs are pointing out interesting details on the investigated system .",
    "for example , the hierarchical clustering is able to detect clusters of stocks belonging to the same sectors or sub - sectors of activities without the need of any supervision of the clustering procedure .",
    "we have also shown that the information present in correlation based trees and graphs provides additional clues about the interrelations among stocks of different economic sectors and sub - sectors .",
    "it is worth noting that this kind of information is not present in the information stored in the hierarchical trees obtained by alca and slca clustering procedures or , equivalently , in the associated ultrametric correlation matrices .",
    "the information obtained from what we call the  filtering procedure \" of the correlation matrix is subjected to statistical uncertainty .",
    "for this reason , we discuss a bootstrap methodology able to quantify the statistical robustness of both the hierarchical trees and correlation based trees or graphs .",
    "the hierarchical trees and correlation based trees and graphs associated with portfolios of stocks traded in financial markets often show clusters of stocks partitioned in sub - clusters , sub - clusters partitioned in sub - sub - clusters and so on until the level of the single stock .",
    "the ubiquity of this observation has motivated us to develop a hierarchically nested factor model able to fully describe this property .",
    "our model is a nested factor model characterized by the same correlation matrix as the empirical set of data .",
    "the model is expressed in a direct and simple form when all the correlation coefficients are positive or very close to positive ( for a precise definition of the limits of validity of this extension see section [ sectionh ] ) .",
    "the number of factors of the model is by construction equal to the number of elements of the system .",
    "again the selection of the most statistically reliable factors detected in a real system is obtained by a procedure based on bootstrap with a bootstrap threshold selected in a self - consistent way .    the amount of information and the statistical stability of filtering procedures of the correlation matrix are quantified by using the kullback - leibler distance .",
    "we report and discuss analytical results both for gaussian and for student s t - distributed multivariate time series . in both cases",
    "the expectation values of the kullback - leibler distance are model independent , indicating that this distance is a good estimator of the statistical uncertainty due to the finite size of the empirical sample .",
    "these properties are not observed in other widespread distances between matrices such as , for example , the frobenius distance , which is a standard measure of the distance between matrices . in our example with real data",
    ", we estimate the amount of information retained and the stability of the filtering procedure used in a data set of 100 stocks approximately described by a multivariate student s @xmath2 distribution . for this set of data we are able to discriminate among filtering procedures as different as alca , slca , random matrix theory and a shrinkage procedure .",
    ".1a- stocks with tick symbol from abt to igt .",
    "the first column is the tick symbol in alphabetical order , the second column reports an abbreviation of the economic sector of the considered company .",
    "specifically , we have basic materials ( bm ) , consumer cyclical ( cc ) , consumer non cyclical ( cnc ) , energy ( e ) , services ( s ) , financial ( f ) , healthcare ( h ) , technology ( t ) , utilities ( u ) , transportation ( tr ) , conglomerates ( co ) and capital goods ( cg ) .",
    "the third column indicates the economic sub - sector of the company .",
    "the forth column reports the company name whereas the fifth column is the numerical label of the stock used in fig.s [ dendrodata ] and [ nodered ] .",
    "[ cols=\"<,^,^,^,^\",options=\"header \" , ]"
  ],
  "abstract_text": [
    "<S> we discuss some methods to quantitatively investigate the properties of correlation matrices . </S>",
    "<S> correlation matrices play an important role in portfolio optimization and in several other quantitative descriptions of asset price dynamics in financial markets . specifically , we discuss how to define and obtain hierarchical trees , correlation based trees and networks from a correlation matrix . the hierarchical clustering and other procedures performed on the correlation matrix to detect statistically reliable aspects of the correlation matrix </S>",
    "<S> are seen as filtering procedures of the correlation matrix . </S>",
    "<S> we also discuss a method to associate a hierarchically nested factor model to a hierarchical tree obtained from a correlation matrix . </S>",
    "<S> the information retained in filtering procedures and its stability with respect to statistical fluctuations is quantified by using the kullback - leibler distance .    </S>",
    "<S> multivariate analysis , hierarchical clustering , correlation based networks , bootstrap validation , factor models , kullback - leibler distance .    </S>",
    "<S> jel classification : c32 , g10 </S>"
  ]
}