{
  "article_text": [
    "the algorithmic ( program - size , or kolmogorov ) complexity of a binary string @xmath0 is defined as the size in bits of the smallest computer program able to generate it : @xmath1 where @xmath2 is a program string used by a universal computer @xmath3 to produce the sequence @xmath0 ( chaitin  @xcite ) .",
    "let us now consider the following algorithm of size @xmath4 ( see also the appendix ) .",
    "it lists in order of their size all strings of length less than or equal to @xmath5 bits ( there are @xmath6 of them ) , that of all possible strings of two bits ( @xmath7 ) , and so on up to @xmath5 bits : @xmath8 ] ) , writing them one after the other on a computer file ( or on a sheet of paper )",
    ". the output should look like    @xmath9    let us assume also that @xmath10 .",
    "thus , since @xmath11 where @xmath12 is the total number of different program strings which could be obtained with a number of bits less than or equal to @xmath13 , then among all the produced strings there is surely at least one that is more complex than our algorithm , i.e.  it ca nt be produced by any program of size less than or equal to @xmath13 bits , by definition of algorithmic complexity .",
    "suddenly a paradox appears : an algorithm of size equal to @xmath13 bits is able to write a list of strings which contains at least one that is more complex than @xmath14 bits , namely than the algorithm itself .",
    "it is even more striking to consider a similar but simpler algorithm ( the same as before but without the if condition , and thus having constant size , nearly equal to @xmath15 bits ; more in the appendix ) which lists every natural number in binary notation , endlessly . in this context",
    ", we have that every binary string , of any length , is generated by this almost trivial algorithm . and , although every single string could be extremely complex ( for instance , like that coding the collected works of giacomo leopardi ) the whole , infinite set has a ridiculous algorithmic complexity .",
    "think for a moment to a god less ` complex ' than a small portion of what it created !",
    "obviously , we are not claiming that our universe is _ tout court _",
    "identical to a computer algorithm ; what we want to suggest is that the concept of something simpler generating something incredibly more complex is not completely weird and unfounded , where simplicity and complexity must be intended in terms of algorithmic complexity .",
    "think for a while to the mocking and frustrating possibility that this applies to our real world too .",
    "mankind is searching for the ultimate meaning of things , expecting to find it through a wider and more complex description than we currently have .",
    "but , maybe , that assumption could be simply wrong , and the ultimate reason , the origin of complex things might be in a simpler thing , as it happens with our listing algorithm . saying it in other words , complexity might be simply a by - product and any wider and more complex description , far from being a step toward the final explanation of things , might exist with no finality , might be simply self - aimed .",
    "maybe , who / what created the universe is not omniscient and almighty like we suppose it should be , but , let us say , it might be simpler than bacteria .",
    "tegmark  @xcite also suggested the possibility of a universe with almost no information content if taken as a whole , and he did it from the point of view of quantum mechanics , while el  naschie  @xcite , using the newton non - dimensional gravity constant @xmath16 as a measure of complexity for the universe , found that the information dimension of the universe is 128 , nearly equal to the inverse of the sommerfeld electromagnetic fine structure constant measure at the electro - weak scale @xmath17 .",
    "besides , the property of being explainable to mankind might be distributed by chance over the things of our world .",
    "some strings / patterns are reproducible by shorter ( therefore simpler and more familiar ) programs , and thus they are ` explainable ' , while others are not and they are perceived as random by us ( see , for example , the model of inductive inference by solomonoff  @xcite ; and the notion of random string , chaitin  @xcite ) .",
    "but there might be no design under the distribution of what is explainable and what is not .",
    "likewise , some strings of our listing program are reproducible by shorter program , some other not , that s all !    a similar argument on the ( un)explainability of the reality was proposed by c.  s.  calude in terms of _ lexicons _ ( see calude and meyerstein  @xcite and references therein ) .",
    "a _ lexicon _ is the infinite expansion of some real number ( e.g. the infinite binary expansion of 0s and 1s obtained through the tossing of a fair coin ) with the base - independent property of containing every finite string as a sub - string , infinitely many times .",
    "calude and meyerstein  @xcite suggest that the universe might behave like a lexicon and that we maybe ` live ' on a very long finite sequence that is ordered , i.e.  it may be explained through science , at least partially .",
    "but , there is no guarantee that it is anywhere , anytime the same ; the order may suddenly switch to pure randomness in other portions of the lexicon / universe .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the probability that your brain , specifically its function of giving rise to your mind , is reproducible by a finite algorithm ( e.g.  @xmath5-bit long ) is arbitrarily close to 0 . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    for the sake of thought experiment , let us try to provide some arguments in favor of the above statement .",
    "let us suppose that the processes of your brain which give rise to your mind are exactly assimilable to and reproducible by an algorithm of @xmath5 bits .",
    "thus , we are able to algorithmically reproduce your brain ( and thus its product , your mind ) as a program running on an ` hardware ' different from your body in such a way that it does not suffer from the main limitation of the human body , namely its relatively short life . in this way , such ` brain ' could in principle work for an unlimited time span .",
    "moreover , let us imagine that as a part of the program simulating your brain there is a very simple ( from the algorithmic point of view ) and fast counter able to enumerate ( but not to store ) all binary numbers of @xmath18 bits ( there are @xmath19 of them ) in increasing lexicographical order .",
    "now , the reproduced mind could _ think of _ a specific decimal number greater than the size ( in bits ) of its own generating algorithm , say @xmath20 , and make the counter start counting in increasing order all possible binary numbers / strings of @xmath20 bits ( there are @xmath21 of them ) .    at its own will , the simulated mind can then stop the counter whenever it wants and print the last enumerated number .",
    "the counter could be provided with a sort of counting completeness indicator , which would give the percentage of the whole count reached till that moment .",
    "this can be of some help to the simulated mind in choosing when to stop the counter ( not too early for instance , since the first binary strings are surely not very complex algorithmically ) .",
    "remember that the printed number is a binary string of @xmath20 bits , less than @xmath21 in size , and it results to be somewhat blindly chosen by the simulated mind .",
    "therefore , with probability nearly equal to    @xmath22 where @xmath6 is the total number of different strings / programs which could be obtained with a number of bits less than or equal to @xmath5 , the simulated @xmath5-bit long algorithmic brain / mind would be able to generate a sequence of a complexity greater than @xmath5 bits .    for @xmath23 ,",
    "such probability becomes arbitrarily close to @xmath24 .",
    "to recap , within the hypothesis that your brain ( and thus its product , your mind ) is reproducible by an @xmath5-bit long algorithm , the probability that such algorithm would be able to generate a string of a complexity greater than @xmath5 bits , and thus leading to a logical paradox according to the definition of algorithmic complexity , is arbitrarily close to @xmath24 .",
    "therefore , the probability that the hypothesis will be violated is arbitrarily close to @xmath24 .",
    "of course , there is a number of possible critiques to the above argument .",
    "someone may argue that for big values of @xmath5 the described enumeration ( involving @xmath21 binary numbers of @xmath20 bits ) is not physically feasible ( it would require an incredibly huge amount of time ) , making our point physically unsound .",
    "others may argue that the above argument does not eliminate at all the possibility that our minds are ` algorithmic ' : we might be similar to machines , behaving predictably like machines ( and thus ` choosing ' , through the procedure described above , a string of consistent algorithmic complexity ) , but simply and wrongly believing we are not .",
    "but , even in such cases our argument should be of some interest : though probably physically unfeasible , our point seems to be in principle logically and mathematically sound ( after all , many trusted mathematical demonstrations are physically unverifiable , for they involve the concept of infinity for instance ) and maybe it might be an example of a physical status ( i.e.  our brains / minds actually like algorithms ) for which we are able to provide a logically and mathematically sound argument of the contrary .",
    "let us consider the following device .",
    "a mechanical tool reads a decimal number @xmath5 in input and tosses an idealized , fair coin @xmath5 times .",
    "whenever the result of the toss is a head , such device prints a @xmath24 on a long tape , otherwise it prints a @xmath25",
    ". one might think that the _ algorithmic size _ of this device is proportional to @xmath26 ( the size of the binary expansion of the decimal number @xmath5 ) , and therefore that it could be able to generate a sequence of a complexity greater than @xmath27 bits , with probability arbitrarily close to @xmath24 .    in that case , however , the algorithmic size of the device is comparable to the complexity of the entire physical process , of all the physical laws ( plus all the relevant initial conditions ) which make the toss to result each time in a head rather than a tail , or vice versa .",
    "hence , this device is not an algorithm _ embedded _ in an electronic computer ; rather , it operates under the influences of the physical world .",
    "maybe the same argument might apply to human mind too : the peculiarity of the brain , in giving rise to mind and consciousness , might partly originate from its complex and continuous physical interaction with the surrounding physical world .",
    "i am very grateful to professor  m.  s.  el  naschie for helpful suggestions and comments on the subject of this paper .",
    "a possible ( fortran - like ) computer code for our listing algorithm :                the size of this algorithm is a constant @xmath15 ( which results from the coding of its instructions different from the decimal number @xmath5 ) plus the number of bits of the binary coding of @xmath5 , that is @xmath28 ( where @xmath29 is the floor function of @xmath30 ) ."
  ],
  "abstract_text": [
    "<S> in this paper the author presents some non - conventional thoughts on the complexity of the universe and the algorithmic reproducibility of the human brain , essentially sparked off by the notion of algorithmic complexity . </S>",
    "<S> we must warn that though they evoke suggestive scenarios , they are still quite speculative . </S>"
  ]
}