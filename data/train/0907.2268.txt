{
  "article_text": [
    "inaccessible web pages and `` 404 page not found '' responses are part of the web browsing experience . despite guidance for how to create `` cool uris '' that do not change @xcite there are many reasons why uris or even entire websites break @xcite .",
    "however , we claim that information on the web is rarely completely lost , it is just missing . in whole or in part , content is often just moving from one uri to another .",
    "it is our intuition that major search engines like google , yahoo ! and msn live (",
    "our experiments were conducted before microsoft introduced bing ) , as members of what we call the web infrastructure ( wi ) , likely have crawled the content and possibly even stored a copy in their cache .",
    "therefore the content is not lost , it `` just '' needs to be rediscovered .",
    "the wi , explored in detail in @xcite , also includes ( besides search engines ) non - profit archives such as the internet archive ( ia ) or the european archive as well as large - scale academic digital data preservation projects e.g. , citeseer and nsdl .",
    "it is commonplace for content to `` move '' to different uris over time .",
    "figure [ fig : ht06 ] shows two snapshots as an example of a web page whose content has moved within one year after its creation .",
    "figure [ fig : ht06_1 ] shows the content of the original uri of the hypertext @xmath3 conference as displayed in 12/2009 .",
    "the original uri clearly does not hold conference related content anymore .",
    "our suspicion is that the website administrators did not renew the domain registration and therefore enabling someone else to take over .",
    "however , the content is not lost .",
    "it is now available at a new uri as shown in figure [ fig : ht06_2 ] .    in this paper",
    "we investigate the retrieval performance of four methods that can be automated and together with the wi used to discover missing web pages .",
    "these methods are :    1 .",
    "lexical signatures ( lss )  typically the @xmath4-@xmath5 most significant keywords extracted from a cached copy of the missing page that capture its `` aboutness '' 2 .",
    "the title of the page  the two underlying assumptions here are : * web pages have descriptive titles * titles only change infrequently over time 3 .   social bookmarking tags  terms suggested by internet users on ` delicious.com ` when the page was bookmarked 4 .",
    "link neighborhood lss ( lnls )  a ls generated from the pages that link to the missing page ( inlinks ) and not from a cached copy of the missing page .",
    "figure [ fig : flow_diagram ] displays the scenario how the four methods of interest can automatically be applied for the discovery of a missing page .",
    "the occurrence of an @xmath0 error is displayed in the first step .",
    "search engine caches and the ia will consequently be queried with the uri requested by the user . in case",
    "older copies of the page are available they can be offered to the user . if the user s information need is satisfied , nothing further needs to be done ( step ( @xmath6 ) ) .",
    "if this is not the case we need to proceed to step ( @xmath7 ) where we extract titles , try to obtain tags about the uri and generate lss from the obtained copies .",
    "the obtained terms are then queried against live search engines .",
    "the returned results are again offered to the user and in case the outcome is not satisfying more sophisticated and complex methods need to be applied ( step ( @xmath4 ) ) .",
    "search engines can be queried to discover pages linking to the missing page .",
    "the assumption is that the aggregate of those pages is likely to be `` about '' the same topic . from this link neighborhood",
    "a ls can be generated . at this point",
    "the approach is the same as the ls method , with the exception that the ls has been generated from a link neighborhood and not a cached copy of the page itself .",
    "the important point of this scenario is that it works while the user is browsing and therefore has to provide results in real time .",
    "queries against search engines can be automated through apis but the generation of lss needs to be automated too .        as an example",
    "let us look at how the methods would be applied to the web page ` www.nicnichols.com ` .",
    "the page is about a photographer named nic nichols .",
    "table [ tab : data_example ] displays all data we obtained about the page using the four methods .",
    ".data obtained from ` www.nicnichols.com ` [ cols= \" < , < \" , ]     the contrast of total title length in number of characters and rank is shown in figure [ fig : title_clenvsrank ] .",
    "while the title length varies greatly between @xmath8 and @xmath9 characters we only see @xmath10 uris with a title length greater or equal to @xmath11 and only three uris with more than @xmath12 characters in their title .",
    "figure [ fig : title_clenvsrank ] does not reveal an obvious pattern between number of characters and rank returned for a title but very short titles ( less than @xmath13 characters ) do not seem to perform well .",
    "a title length between @xmath13 and @xmath14 characters is most common and the ranks seem to be better in the range of @xmath13 to @xmath15 characters total .",
    "figure [ fig : title_sw_meanlenvsrank ] depicts on the left the mean number of characters per title term and their retrieval performance .",
    "it seems that terms with an average of @xmath4 , @xmath16 or @xmath5 characters seem to be most suitable for well performing query terms . on the bottom right end of the barplot we can see two titles that have a mean character length per term of @xmath17 and @xmath18 .",
    "since such long words are rather rare they perform very well .",
    "the observation of stop word frequency in the titles and their performance is not surprising . as shown on the right in figure [ fig : title_sw_meanlenvsrank ] titles with more than a couple of stop words seem to harm the performance .",
    "the intuition is that search engines filter stop words from the query ( keep in mind , these are non - quoted titles ) and therefore it makes sense that for example the title with @xmath19 stop words does not return its uri within the top @xmath11 ranks .    for completeness we removed all stopwords from the titles and analyzed their retrieval performance in dependence of the new title length .",
    "the results are shown in figure [ fig : title_nosw_lenvsrank ] .",
    "as expected we see more titles with fewer terms performing slightly better than the original titles .",
    "this result indicates that the performance of the method using the web page s titles can still be improved .",
    "further analysis of the best combination of methods with titles without stop words remains for future work .",
    "our main aspect of future work is the implementation of the system described in the flow diagram of figure [ fig : flow_diagram ] .",
    "the system will operate as a browser plugin and will trigger once the user encounters a @xmath0 `` page not found '' error .",
    "it will provide all of the introduced methods to rediscover the missing page and since the discovery process happens in an automated fashion , the system can provide the user with the results in real - time while she is browsing the internet .",
    "we have shown in @xcite that lss evolve over time and consequently lose some of its retrieval strength .",
    "here we are arguing that titles of web pages are a powerful alternative to lss .",
    "the next logical step is to investigate the evolution and possible decay of titles over time .",
    "our intuition is that titles do not decay quite as quickly as lss do since the actual content of a web page ( a headline , sentence or paragraph ) presumably changes more frequently than its general topic which is what the title is supposed to represent .",
    "our set of obtained tags is limited .",
    "it remains for future work to investigate the retrieval performance of tags in a large scale experiment .",
    "it also would be interesting to see what the term overlap between tags , titles and lss is since all three methods are generated on different grounds .",
    "our method to generate lnlss may not be optimal .",
    "we chose to use inlink pages only and created a bucket of all neighborhood terms per uri .",
    "the lnlss are based on this bucket .",
    "it remains to be seen whether outlink pages actually can contribute to the retrieval performance and other methods than the bucket of terms are preferable .",
    "it is possible that our neighborhood is too big since it includes the entire neighboring page .",
    "a page that links to many pages ( hub ) may have a diffuse `` aboutness '' .",
    "hence we are going to restrict the content gained from the neighborhood to the link anchor text of the inlink pages .",
    "in this paper we evaluate the retrieval performance of four methods to discover missing web pages .",
    "we generate a dataset of uris by randomly sampling uris from ` dmoz.org ` and assume these pages to be missing .",
    "we generate lss from copies of the pages , parse the pages titles , obtain tags of the uris from the bookmarking website ` delicious.com ` and generate lss based on link neighborhood .",
    "we use the three major search engines google , yahoo ! and msn live to acquire mandatory document frequency data for the generation of the lss .",
    "we further query all three search engines for all our methods and combine methods to improve the retrieval performance .",
    "we are able to recommend a setup of methods and see one search engine performing best in most of our experiments .",
    "it has been shown in related work that lss can perform well for retrieving web pages .",
    "our results confirm these findings , for example more than two - thirds of our uris have been returned as the top result when querying @xmath4- and @xmath5-term lss against the yahoo ! search engine api .",
    "they also lead us to the claim that titles of web pages are a strong alternative to lss .",
    "almost @xmath20 of the uris have been returned as the top result from the google search engine api when queried with the ( non - quoted ) title .",
    "however , our results show that a combination of methods performs best .",
    "querying the title first and then using the @xmath4-term lss for all remaining undiscovered uris against yahoo ! provided the overall best result with @xmath21 of top ranked uris and another @xmath22 in the top @xmath13 ranks .",
    "the combination @xmath5-term ls , title , @xmath4-term ls returned @xmath23 of the uris in the top ranks but since lss are more expensive to generate than titles , we recommend the former combination of methods . a good strategy , based on our results , is to query the title first and if the results are insufficient generate and query lss second . yahoo ! returned the best results for all combination of methods and thus seems to be the best choice even though google returned better results when querying the title only .",
    "this work is supported in part by the library of congress ."
  ],
  "abstract_text": [
    "<S> missing web pages ( pages that return the @xmath0 `` page not found '' error ) are part of the browsing experience . </S>",
    "<S> the manual use of search engines to rediscover missing pages can be frustrating and unsuccessful . </S>",
    "<S> we compare four automated methods for rediscovering web pages . </S>",
    "<S> we extract the page s title , generate the page s lexical signature ( ls ) , obtain the page s tags from the bookmarking website ` delicious.com ` and generate a ls from the page s link neighborhood . </S>",
    "<S> we use the output of all methods to query internet search engines and analyze their retrieval performance . </S>",
    "<S> our results show that both lss and titles perform fairly well with over @xmath1 uris returned top ranked from yahoo!. however , the combination of methods improves the retrieval performance . </S>",
    "<S> considering the complexity of the ls generation , querying the title first and in case of insufficient results querying the lss second is the preferable setup . </S>",
    "<S> this combination accounts for more than @xmath2 top ranked uris .    </S>",
    "<S> = 10000 = 10000    information search and retrieval </S>"
  ]
}