{
  "article_text": [
    "large scale inverse problems are challenging for a number of reasons , not least of which is the sheer volume of prerequisite knowledge required . developing numerical methods for inverse problems involves the intersection of a number of fields , in particular numerical linear algebra , nonlinear non - convex optimization , numerical partial differential equations , as well as the particular area of physics or biology the problem is modelled after , among others . as a result",
    ", many software packages aim for a complete general approach , implementing a large number of these components in various sub - modules and interfaced in a hierarchical way .",
    "there is often a danger with approaches that increase the cognitive load on the user , forcing them to keep the conceptual understanding of many components of the software in their minds at once .",
    "this high cognitive load can result in prolonging the initial setup time of a new researcher , delaying the time that they are actually productive while they attempt to comprehend how the code behaves .",
    "moreover , adhering to a software design model that does not make intuitive sense can disincentivize modifications and improvements to the codebase . in an ideal world , a researcher with a general knowledge of the subject area should be able to sit in front of a well - designed software package and easily associate the underlying mathematics with the code they are presented .",
    "if a researcher is interested in prototyping high level algorithms , she is not necessarily interested in having to deal with the minutia of compiling a large number of software packages , manually managing memory , or writing low level code in c or fortran in order to implement , for example , a simple stochastic optimization algorithm .",
    "researchers are at their best when actually performing research and software should be designed to facilitate that process as easily as possible .    academic software environments for inverse problems are not necessarily geared towards high - performance , making use of explicit modeling matrices or direct solvers for 3d problems . given the enormous computational demands of solving such problems , industrial codes focus on the performance - critical aspect of the problem and are often written in a low - level language without focusing on proper design .",
    "these software engineering decisions results in code that is hard to understand , maintain , and improve .",
    "fortran veterans who have been immersed in the same software environment for many years are perfectly happy to squeeze as much performance out of their code as possible , but can not easily integrate higher - level algorithms in to an existing codebase . as a result of this disparity , the translation of higher - level academic research ideas to high - performance industrial codes can be lost , which inhibits the uptake of new academic ideas in industry and vice - versa .",
    "one of the primary examples in this work is the seismic inverse problem and variants thereof , which are notable in particular for their large computational requirements and industrial applications .",
    "seismic inverse problems aim to reconstruct an image of the subsurface of the earth from multi - experiment measurements conducted on the surface .",
    "an array of pressure guns inject a pressure differential in to the water layer , which in turn generates a wave that travels to the ocean floor .",
    "these waves propagate in to the earth itself , reflect off of various discontinuities , before traveling back to the surface to be measured at an array of receivers .",
    "our goal in this problem , as well as many other boundary - value problems , is to reconstruct the coefficients of the model ( i.e. , the wave equation in the time domain or the helmholtz equation in the frequency domain ) that describes this physical system such that the waves generated by our model agree with those in our measured data .",
    "the difficulty in solving industrial - scale inverse problems arises from the various constraints imposed by solving a real - world problem .",
    "acquired data can be noisy , lack full coverage , and , in the seismic case , can miss low and high frequencies @xcite as a result of equipment and environmental constraints . particularly in the seismic case , missing low frequencies results in a highly - oscillatory objective function with multiple local minima , requiring a practitioner to estimate an accurate starting model , while missing high frequencies results in a loss of detail @xcite .",
    "realistically sized problems involve the propagation of hundreds of wavelengths in geophysical @xcite and earthquake settings @xcite , where wave phenomena require a minimum number of points per wavelength to model meaningfully @xcite .",
    "these constraints can lead to large models and the resulting system matrices become too large to store explicitly , let alone invert with direct methods .    our goal in this work is to outline a software design approach to solving partial differential equation ( pde ) constrained optimization problems that allows users to operate with the high - level components of the problem such as objective function evaluations , gradients , and hessians , irrespective of the underlying pde or dimensionality . with this approach ,",
    "a practitioner can design and prototype inversion algorithms on a complex 2d problem and , with minimal code changes , apply these same algorithms to a large scale 3d problem .",
    "the key approach in this instance is to structure the code in a hierarchical and modular fashion , whereby each module is responsible for its own tasks and the entire system structures the dependencies between modules in a tiered fashion . in this way",
    ", the entire codebase becomes much easier to test , optimize , and understand .",
    "moreover , a researcher who is primarily concerned with the high level ` building blocks ' of an inversion framework can simply work with these units in a standalone fashion and rely on default configurations for the lower level components . by using a proper amount of information hiding through abstraction",
    ", users of this code can delve as deeply in to the code architecture as they are interested in .",
    "we also aim to make our ` code look like the math ' as much as possible , which will help our own development as well as that of future researchers , and reduce the cognitive load required for a researcher to start performing research .",
    "there are a number of existing software frameworks for solving inverse problems with varying goals in mind .",
    "the work of @xcite provides a c++ framework built upon the abstract rice vector library @xcite for time domain modeling and inversion , which respects the underlying hilbert spaces where each vector lives by automatically keeping track of units and grid spacings , among other things .",
    "the low - level nature of the language it is built in exposes too many low level constructs at various levels of its hierarchy , making integrating changes in to the framework cumbersome .",
    "the seiscope toolbox @xcite implements high level optimization algorithms in the low - level fortran language , with the intent to interface in to existing modeling and derivative codes using reverse communication . as we highlight below",
    ", this is not necessarily a beneficial strategy and merely obfuscates the codebase , as low level languages should be the domain of computationally - intensive code rather than high - level algorithms .",
    "the trilinos project @xcite is a large collection of packages written in c++ by a number of domain - specific experts , but requires an involved installation procedure , has no straightforward entrance point for pde - constrained optimization , and is not suitable for easy prototyping . implementing a modelling framework in petsc @xcite , such as in @xcite , let alone an inversion framework , exposes too many of the unnecessary details at each level of the hierarchy given that petsc is written in c. the devito framework @xcite offers a high - level symbolic python interface to generate highly optimized stencil - based c- code for time domain modelling problems , with extensions to inversion .",
    "this is promising work that effectively delineates the high - level mathematics from the low - level computations .",
    "we follow a similar philosophy in this work . this work builds upon ideas in @xcite , which was a first attempt to implement a high - level inversion framework in matlab .",
    "software frameworks in the finite - element regime have been successfully applied to optimal control and other pde - constrained optimization problems .",
    "the dolfin framework @xcite employs a high - level description of the pde - constrained problem written in the ufl language for specifying finite elements , which is subsequently compiled in to lower level finite element codes with the relevant adjoint equations derived and solved automatically for the objective and gradient . for the geophysical examples",
    ", the finite element method does not easily lend itself to applying a perfectly - matched layer to the problem compared to finite differences , although some progress has been made in this front , i.e. , see @xcite .",
    "in general , finite difference methods are significantly easier to implement , especially in a matrix - free manner , than finite element methods , although the latter have a much stronger convergence theory .",
    "moreover , for systems with oscillatory solutions such as the helmholtz equation , applying the standard 7 point stencil to the problem is inadvisable due to the large amount of numerical dispersion introduced , resulting in a system matrix with a large number of unknowns .",
    "this fact , along with the indefiniteness of the underlying matrix , makes it very challenging to solve with standard krylov methods .",
    "more involved approaches are needed to adequately discretize such equations , see , e.g. , @xcite .",
    "the simpeg package @xcite is designed in a similar spirit to the considerations in this work , but does not fully abstract away unnecessary components from the user and is not designed with large - scale computations in mind as it lacks inherent parallelism .",
    "the jinv package @xcite is written in julia in a similar spirit to this work with an emphasis on finite element discretizations using the parallel mumps solver @xcite for computing the fields and is parallelized over the number of source experiments .",
    "when considering the performance - understandability spectrum for designing inverse problem software , it is useful to consider amdahl s law @xcite .",
    "roughly speaking , amdahl s law states that in speeding up a region of code , through parallelization or other optimizations , the speedup of the overall program will always be limited by the remainder of the program that does not benefit from the speedup .",
    "for instance , speeding up a region where the program spends 50% of its time by a factor of 10 will only speed up the overall program by a maximum factor of 1.8 . for any pde - based inverse problem",
    ", the majority of the computational time is spent solving the pdes themselves . given amdahl s law and a limited budget of researcher time",
    ", this would imply that there is virtually no performance benefit in writing both the ` heavy lifting ' portions of the code as well as the auxiliary operations in a low level language , which can impair readability and obscure the role of the individual component operations in the larger framework .",
    "rather , one should aim to use the strengths of a high level language to express mathematical ideas cleanly in code and exploit the efficiency of a low level language , at the proper instance , to speed up primitive operations such as a multi - threaded matrix - vector product .",
    "these considerations are also necessary to manage the complexity of the code and ensure that it functions properly .",
    "researcher time , along with computational time , is valuable and we should aim to preserve productivity by designing these systems with these goals in mind .    it is for this reason that we choose to use matlab to implement our parallel inversion framework as it offers the best balance between access to performance - critical languages such as c and fortran , while allowing for sufficient abstractions to keep our code concise and loyal to the underlying mathematics",
    ". a pure fortran implementation , for instance , would be significantly more difficult to develop and understand from an outsider s perspective and would not offer enough flexibility for our purposes .",
    "python would also potentially be an option for implementing this framework . at the time of the inception of this work",
    ", we found that the relatively new scientific computing language julia @xcite was in too undeveloped of a state to facilitate all of the abstractions we needed ; this may no longer be the case as of this writing .      using a hierarchical approach to our software design",
    ", we implement a framework for solving inverse problems that is flexible , comprehensible , efficient , scalable , and consistent .",
    "the flexibility arises from our design decisions , which allow a researcher to swap components ( parallelization schemes , linear solvers , preconditioners , discretization schemes , etc . ) in and out to suit her needs and the needs of her local computational environment .",
    "our design balances efficiency and understandability through the use of object oriented programming , abstracting away the low - level mechanisms of the computationally intensive components through the use of the spot framework @xcite . the spot methodology allows us to abstract away function calls as matrix - vector multiplications in matlab , the so - called matrix - free approach . by abstracting away the lower level details ,",
    "our code is clean and resembles the underlying mathematics .",
    "this abstraction also allows us to swap between using explicit , sparse matrix algebra for 2d problems and efficient , multi - threaded matrix - vector multiplications for 3d problems .",
    "the overall codebase is then agnostic to the dimensionality of @xmath0 , which encourages code reuse when applying new algorithms to large scale problems .",
    "our hierarchical design also decouples parallel data distribution from computation , allowing us to run the same algorithm as easily on a small 2d problem using a laptop as on a large 3d problem using a cluster .",
    "we also include unit tests that demonstrate that our code accurately reflects the underlying mathematics in section ( # validation ) .",
    "we call this package waveform ( software environment for nonlinear inverse problems ) , which can be obtained at https://github.com/slimgroup/waveform .    in this work , we also propose a new multigrid - based preconditioner for the 3d helmholtz equation that only requires matrix - vector products with the system matrix at various levels of discretization , i.e. , is matrix - free at each multigrid level , and employs standard krylov solvers as smoothers .",
    "this preconditioner allows us to operate on realistically sized 3d seismic problems without exorbitant memory costs .",
    "our numerical experiments demonstrate the ease of which we can apply high level algorithms to solving the pde - based parameter estimation problem and its variants while still having full flexibility to swap modeling code components in and out as we choose .",
    "to ensure that this work is sufficiently self - contained , we outline the basic structure and derivations of our inverse problem of interest .",
    "lowercase , letters such as @xmath1 denote vectors and uppercase letters such as @xmath2 denote matrices or linear operators of appropriate size . to distinguish between continuous objects and their discretized counterparts , with a slight abuse of notation , we will make the spatial coordinates explicit for the continuous objects , i.e. , sampling @xmath3 on a uniform spatial grid results in the vector @xmath4 .",
    "vectors @xmath4 can depend on parameter vectors @xmath0 , which we indicate with @xmath5 .",
    "the adjoint operator of a linear mapping @xmath6 is denoted as @xmath7 and the conjugate hermitian transpose of a complex matrix @xmath8 is denoted @xmath9 . if @xmath8 is a real - valued matrix , this is the standard matrix transpose .",
    "our model inverse problem is the multi - source parameter estimation problem .",
    "given our data @xmath10 depending on the @xmath11 source and @xmath12 frequency , our measurement operator @xmath13 , and the linear partial differential equation @xmath14 depending on the model parameter @xmath0 , find the model @xmath0 that minimizes the misfit between the predicted and observed data , i.e. , @xmath15 here @xmath16 is a smooth misfit function between the inputs @xmath17 and @xmath18 , often the least - squares objective @xmath19 , although other more robust penalties are possible , see e.g. , @xcite .",
    "the indices @xmath20 and @xmath21 vary over the number of sources @xmath22 and number of frequencies @xmath23 , respectively . for the purposes of notational simplicity , we will drop this dependence when the context permits . note that our design is specific to boundary - value problems rather than time - domain problems , which have different computational and storage challenges .",
    "a well known instance of this setup is the full waveform inversion problem in exploration seismology , which involves discretizing the constant - density helmholtz equation @xmath24 where @xmath25 is the laplacian , @xmath26 is the wavenumber , @xmath27 is the angular frequency and @xmath28 is the gridded velocity , @xmath29 is the per - frequency source weight , @xmath30 are the spatial coordinates of the source , and the second line denotes the sommerfeld radiation condition @xcite with @xmath31 . in this case",
    ", @xmath32 is any finite difference , finite element , or finite volume discretization of  .",
    "other examples of such problems include electrical impedance tomography using a simplified form of maxwell s equations , which can be reduced to poisson s equation @xcite , x - ray tomography , which can be thought of as the inverse problem corresponding to a transport equation , and synthetic aperture radar , using the wave equation @xcite .",
    "for realistically sized industrial problems of this nature , in particular for the seismic case , the size of the model vector @xmath0 is often @xmath33 and there can be @xmath34 sources , which prevents the full storage of the fields",
    ". full - space methods , which use a newton iteration on the associated lagrangian system , such as in ( * ? ? ?",
    "* @xcite ) , are infeasible as a large number of fields have to be stored and updated in memory . as a result ,",
    "these large scale inverse problems are typically solved by eliminating the constraint and reformulating the problem in an unconstrained or reduced form as @xmath35 we assume that we our continuous pdes are posed on a rectangular domain @xmath36 with zero dirichlet boundary conditions . for pde problems that require sponge or perfectly matched layers , we extend @xmath36 to @xmath37 and vectors defined on @xmath36 are extended to @xmath38 by extension in the normal direction . in this extended domain for the acoustic helmholtz equation , for instance",
    ", we solve @xmath39 where @xmath40 , for appropriately chosen univariate pml damping functions @xmath41 , and similarly for @xmath42 .",
    "this results in solutions @xmath4 that decay exponentially for @xmath43 .",
    "we refer the reader to @xcite for more details .",
    "we assume that the source functions @xmath44 are localized in space around the points @xmath45 which make up our source grid .",
    "the measurement or sampling operator @xmath13 samples function values defined on @xmath38 at the set of receiver locations @xmath46 . in the most general case , the points @xmath47 can vary per - source ( i.e. , as the location of the measurement device is dependent on the source device ) , but we will not consider this case here . in either case , the source grid can be independent from the receiver grid .    while the pde itself is linear , the mapping that predicts data @xmath48 , the so - called the forward modeling operator , is known to be highly nonlinear and oscillatory in the case of the high frequency helmholtz equation @xcite , which corresponds to propagating anywhere between 50 - 1000 wavelengths for realistic models of interest . without loss of generality , we will consider the helmholtz equation as our prototypical model in the sequel . the level of formalism , however , will ultimately be related to parameter estimation problems that make use of real - world data , which is inherently band - limited .",
    "we will therefore not be overly concerned with convergence as the mesh- or element - size tends to zero , as the informative capability of our acquired data is only valid up until a certain resolution dictated by the resolution of our measurement device .",
    "we will focus solely on the discretized formulation of the problem from hereon out .",
    "we can compute relevant derivatives of the objective function with straightforward , ableit cumbersome , matrix calculus . consider the state equation @xmath49 . using the chain rule",
    ", we can derive straightforward expressions for the directional derivative @xmath50 $ ] as @xmath51 = -h(m)^{-1 } dh(m)[\\delta m]u(m ) .",
    "\\label{du}\\ ] ] here @xmath52 $ ] is the directional derivative of the mapping @xmath53 which is assumed to be smooth . to emphasize the dependence on the linear argument , we let @xmath54 denote the linear operator defined by @xmath55u(m)$ ] , which outputs a vector in model space .",
    "note that @xmath56 , but we drop this dependence for notational simplicity .",
    "we let @xmath57 denote the adjoint of the linear mapping @xmath58 the associated adjoint mapping of   is therefore @xmath59^ * y = -t^ * h(m)^{-h}y.\\ ] ] the ( forward ) action of the jacobian @xmath60 of the forward modelling operator @xmath61 is therefore given by @xmath62 $ ] .    we also derive explicit expressions for the jacobian adjoint , gauss - newton hessian , and full hessian matrix - vector products , as outlined in table  ,",
    "although we leave the details for appendix ( # userfriendly ) . for even medium sized 2d problems ,",
    "it is computationally infeasible to store these matrices explicitly and therefore we only have access to matrix - vector products .",
    "the number of matrix - vector products for each quantity are outlined in table   and are per - source and per - frequency . by adhering to the principle of `",
    "the code should reflect the math ' , once we have the relevant formula from table  , the resulting implementation will be as simple as copying and pasting these formula in to our code in a straightforward fashion , which results in little to no computational overhead , as we shall see in the next section .    [ cols= \" < ,",
    "< \" , ]     we also compare the computed solutions in a homogeneous medium to the corresponding analytic solutions in 2d and 3d , i.e. , @xmath63 where @xmath64 is the wavenumber , @xmath65 is the frequency in hz , @xmath66 is the velocity in @xmath67 , and @xmath68 is the bessel function of the third kind ( the hankel function ) . figures ( [ analytic2d ] , [ analytic3d ] , [ analytic25d ] ) show the analytic and numerical results of computing solutions with the 2d , 3d , and 2.5d kernels , respectively . here we see that the overall phase dispersion is low for the computed solutions , although we do incur a somewhat larger error around the source region as expected .",
    "the inclusion of the pml also prevents any visible artificial reflections from entering the solutions , as we can see from the ( magnified ) error plots .",
    "+     +     +      to demonstrate the effectiveness of our software environment , we perform a simple 2d fwi experiment on a 2d slice of the 3d bg compass model .",
    "we generate data on this 2 km x 4.5 km model ( discretized on a 10 m grid ) from 3hz to 18hz ( in 1hz increments ) using our helmholtz modeling kernel .",
    "employing a frequency continuation strategy allows us to mitigate convergence issues associated with local minima @xcite .",
    "that is to say , we partition the entire frequency spectrum @xmath69 in to overlapping subsets , select a subset at which to invert invert the model , and use the resulting model estimate as a warm - start for the next frequency band . in our case , we use frequency bands of size @xmath70 with an overlap of @xmath71 between bands . at each stage of the algorithm",
    ", we invert the model using @xmath72 iterations of a box - constrained lbfgs algorithm from @xcite .",
    "an excerpt from the full script that produces this example is shown in listing  .",
    "the results of this algorithm are shown in figure  . as we are using a band with a low starting frequency ( 3hz in this case )",
    ", fwi is expected to perform well in this case , which we see that it does .",
    "although an idealized experimental setup , our framework allows for the possibility of testing out algorithms that make use of higher starting frequencies , or use frequency extrapolation as in @xcite , with minimal code changes .",
    ".... % set the initial model ( a smoothed version of the true model ) mest = m0 ; % loop over subsets of frequencies for j=1:size(freq_partition,1 )      % extract the current frequencies at this batch      fbatch = freq_partition(j , : ) ;      % select only sources at this frequency batch      srcfreqmask = false(nsrc , nfreq ) ;      srcfreqmask(:,fbatch ) = true ;      params.srcfreqmask = srcfreqmask ;      % construct objective function for these frequencies      obj = misfit_setup(mest , q , dobs , model , params ) ;      % call the box constrained lbfgs method      mest = minconf_tmp(obj , mest , mlo , mhi , opts ) ; end ....      the seismic imaging problem aims to reconstruct a high resolution reflectivity map @xmath73 of the subsurface , given some smooth background model @xmath74 , by inverting the ( overdetermined ) jacobian system @xmath75 in this simple example , @xmath76 is the image of the true perturbation under the jacobian . attempting to tackle",
    "the least - squares system directly @xmath77 where @xmath78 indexes the sources and @xmath79 indexes the frequencies , is computationally daunting due to the large number of sources and frequencies used .",
    "one straightforward approach is to randomly subsample sources and frequencies , i.e. , choose @xmath80 and @xmath81 and solve @xmath82 but the jacobian can become rank deficient in this case , despite it being full rank normally .",
    "one solution to this problem is to use sparse regularization coupled with randomized subsampling in order to force the iterates to head towards the true perturbation while still reducing the per - iteration costs .",
    "there have been a number of instances of incorporating sparsity of a seismic image in the curvelet domain @xcite , in particular @xcite .",
    "we use the linearized bregman method @xcite , which solves @xmath83 coupled with random subsampling as in @xcite , the iterations are shown in algorithm  , a variant of which is used in @xcite . here",
    "@xmath84 is the componentwise soft - thresholding operator . in listing  ,",
    "the reader will note the close adherence of our code to algorithm  , aside from some minor bookkeeping code and pre- and post - multiplying by the curvelet transform to ensure the sparsity of the signal . in this example",
    ", we place 300 equispaced sources and 400 receivers at the top of the model and generate data for 40 frequencies from 3 - 12 hz . at each iteration of the algorithm",
    ", we randomly select 30 sources and 10 frequencies ( corresponding to the 10 parallel workers we use ) and set the number of iterations so that we perform 10 effective passes through the entire data .",
    "compared to the image estimate obtained from an equivalent ( in terms of number of pdes solved ) method solving the least - squares problem with the lsmr @xcite method , the randomly subsampled method has made significantly more progress towards the true solution , as shown in figure  .    for  @xmath85 + draw  a  random  subset  of  indices  @xmath86 + @xmath87 +",
    "@xmath88    .... for k=1:t    % draw a random subset of sources and frequencies    is = rand_subset(nsrc , round(0.2*nsrc ) ) ;    if = rand_subset(nfreq , parpool_size ( ) ) ;    % mask the objective to the sources / frequencies drawn    srcfreqmask = false(nsrc , nfreq ) ;    srcfreqmask(is , if ) = true ;    params.srcfreqmask = srcfreqmask ;    % construct the subsampled jacobian operator + data    a = oppdf(m0,q , model , params ) ;    b = distributed_subsample_data(b_full , is , if ) ;    % linearized bregman algorithm    r = a*x - b ;    atr = a'*r ;    t = norm(r)^2/norm(atr)^2 ;    z = z - t*atr ;    x = c'*softthreshold(c*z , lambda ) ; end ....      to demonstrate the modular and flexible nature of our software framework , we replace the finite difference helmholtz pde with a simple finite volume discretization of the variable coefficient poisson equation @xmath89 where @xmath90 is the spatially - varying conductivity coefficient .",
    "we discretize the field on the vertices of a regular rectangular mesh and @xmath90 at the cell centers , which results in the system matrix , denoted @xmath91 , written abstractly as @xmath92 for constant matrices @xmath93 .",
    "this form allows us to easily derive expressions for @xmath94u$ ] and @xmath57 as @xmath95 with these expressions in hand , we merely can slot the finite volume discretization and the corresponding directional derivative functions in to our framework without modifying any other code .",
    "consider a simple constant conductivity model containing a square anomaly with a 20% difference compared to the background , encompassing a region that is 5 km x 5 km with a grid spacing of 10 m , as depicted in figure  .",
    "we place 100 equally spaced sources and receivers at depths @xmath96 and @xmath97 , respectively .",
    "the pointwise constraints we use are the true model for @xmath98 and @xmath99 and , for the region in between , we set @xmath100 and @xmath101 .",
    "our initial model is a constant model with the correct background conductivity , shown in figure  .",
    "given a current estimate of the conductivity @xmath102 , we minimize a quadratic model of the objective subject to bound constraints , i.e. , @xmath103 where @xmath104 are the gradient and gauss - newton hessian , respectively .",
    "we solve @xmath105 of these subproblems , using @xmath105 objective / gradient evaluations to solve each subproblem using the bound constrained lbfgs method of @xcite . as we do not impose any constraints on the model itself and the pde itself is smoothing , we are able to recover a very smooth version of the true model , shown in figure  , with the attendant code shown in listing  .",
    "this discretization and optimization setup is by no means the optimal method to invert such conductivity models but we merely outline how straightforward it is to incorporate different pdes in to our framework .",
    "techniques such as total variation regularization @xcite can be incorporated in to this framework by merely modifying our objective function .",
    ".... obj = misfit_setup(sigma0,q , d , model , params ) ; sigma = sigma0 ; for i=1:5    % evaluate objective    [ f , g , h ] = obj(sigma ) ;    % construct quadratic model    q = @(x ) quadratic_model(g , h , x , sigma ) ;",
    "% minimize quadratic model , subject to pointwise constraints    sigma = minconf_tmp(q , sigma , sigma_min , sigma_max , opts ) ; end ....      our software design makes it relatively straightforward to apply the same inversion algorithm to both a 2d and 3d problem in turn , while changing very little in the code itself .",
    "we consider the following algorithm for inversion , which will allow us to handle the large number of sources and number of model parameters , as well as the necessity of pointwise bound constraints @xcite on the intermediate models .",
    "our problem has the form @xmath106 where @xmath0 is our model parameter ( velocity or slowness ) , @xmath107 is the least - squares misfit for source @xmath20 , and @xmath108 is our convex constraint set , which is @xmath109 in this case . when we have @xmath110 parallel processes and @xmath111 sources , in order to efficiently make progress toward the solution of the above problem , we stochastically subsample the objective and approximately minimize the resulting problem , i.e. , at the @xmath112th iteration we solve @xmath113 for @xmath114 drawn uniformly at random and @xmath115 .",
    "we use the approximate solution @xmath116 as a warm start for the next problem and repeat this process a total of @xmath54 times . given that our basic unit of work in these problems is computing the solution of a pde , we limit the number of iterations for each subproblem solution so that each subproblem can be evaluated at a constant multiple of evaluating the objective and gradient with the full data , i.e. , @xmath117 iterations for a constant @xmath118 .",
    "if an iteration stagnates , i.e. , if the line search fails , we increase the size of @xmath119 by a fixed amount .",
    "this algorithm is similar in spirit to the one proposed in @xcite .",
    "we apply the above algorithm to the bg compass model , with the same geometry and source / receiver configuration as outlined in section ( # fwiexample ) .",
    "we limit the total number of passes over the entire data to be equal to @xmath120 of those used in the previous example , with @xmath121 re - randomization steps and @xmath122 .",
    "our results are shown in figure  . despite the smaller number of overall pdes solved",
    ", the algorithm converges to a solution that is qualitatively hard to distinguish from figure  .",
    "the overall model error as a function of number of subproblems solved is depicted figure  .",
    "the model error stagnates as the number of iterations in a given frequency batch rises and continues to decrease when a new frequency batch is drawn .",
    "we apply the aforementioned algorithm to the seg / eage overthrust model , which spans 20 km x 20 km x 5 km and is discretized on a 50 m x 50 m x 50 m grid with a 500 m deep water layer and minimum and maximum velocities of @xmath123 and @xmath124 . the ocean floor is covered with a 50 x 50 grid of sources , each with 400 m spacing , and a 396 x 396 grid of receivers , each with 50 m spacing .",
    "the frequencies we use are in the range of @xmath125 with @xmath126 sampling , corresponding to 4s of data in the time domain , and inverted a single frequency at a time .",
    "the number of wavelengths in the @xmath1 directions vary from @xmath127 to @xmath128 , respectively , with the number of points per wavelength varying from 9.8 at the lowest frequency to 5.3 at the highest frequency .",
    "the model is clamped to be equal to the true model in the water layer and is otherwise allowed to vary between the maximum and minimum velocity values . in practical problems , some care must be taken to ensure that discretization discrepancies between the boundary of the water and the true earth model are minimized .",
    "our initial model is a significantly smoothed version of the true model and we limit the number of stochastic redraws to @xmath129 , so that we are performing the same amount of work as evaluating the objective and gradient three times with the full data .",
    "the number of unknown parameters is 14,880,000 and the fields are inverted on a grid with 39,859,200 points , owing to the pml layers in each direction .",
    "we use 100 nodes with 4 matlab workers each of the yemoja cluster for this computation .",
    "each node has 128 gb of ram and a 20-core intel processor .",
    "we use 5 threads for each matrix - vector product and subsample sources so that each matlab worker solves a single pde at a time ( i.e. , @xmath130 in the above formulation ) and set the effective number of passes through the data for each subproblem to be one , i.e. , @xmath131 . despite the limited number of passes through the data , our code is able to make substantial progress towards the true model , as shown in figures   and  . unlike in the 2d case ,",
    "we are limited in our ability to invert higher frequencies in a reasonable amount of time and therefore our inverted results do not fully resolve the fine features , especially in the deeper parts of the model .",
    "+     +   +",
    "there are a number of problem - specific constraints that have motivated our design decisions thus far .",
    "computing solutions to the helmholtz equation in particular is challenging due to the indefiniteness of the underlying system for even moderate frequencies and the sampling requirements of a given finite difference stencil .",
    "these challenges preclude one from simply employing the same sparse - matrix techniques in 2d for the 3d case .",
    "direct methods that store even partial lu decomposition of the system matrix are infeasible from a memory perspective , unless one allows for using multiple nodes to compute the pde solutions . even in that case",
    ", one can run in to resiliency issues in computational environments where nodes have a non - zero probability of failure over the lifetime of the computation .",
    "regardless of the dimensionality , our unified interface for multiplying and dividing the helmholtz system with a vector abstracts away the implementation specific details of the underlying matrix , while still allowing for high performance .",
    "these design choices give us the ability to scale from simple 2d problems on 4 cores to realistically sized 3d problems running on 2000 cores with minimal engineering effort .",
    "although our choice of matlab has enabled us to succinctly design and prototype our code , there have been a few stumbling blocks as a result of this language choice .",
    "there is an onerous licensing issue for the parallel toolbox , which makes scaling to a large number of workers costly .",
    "the parallel toolbox is built on mpi , which is simply insufficient for performing large scale computations in an environment that can be subject to disconnections and node failures and can not be swapped out for another parallelization scheme within matlab itself . in an environment where one does not have full control over the computational hardware , such as on amazon s cloud computing services , this paradigm is untenable . for interfacing with the c / fortran language , there is a large learning curve for compiling mex files , which are particularly constructed c files that can be called from with matlab .",
    "matlab offers its matlab coder product that allows one to , in principle , compile any function in to a mex file , and thus reap potential performance benefits .",
    "the compilation process has its limits in terms of functionality , however , and can not , for instance , compile our framework easily .    thankfully , there have been a few efforts to help alleviate these issues .",
    "the relatively new numerical computing language julia has substantially matured in the last few years , making it a viable competitor to matlab .",
    "julia aims to bridge the gap between an interpreted and a compiled language , the former being easier to prototype in and the latter being much faster by offering a just - in - time compiler , which balances ease of use and performance .",
    "julia is open source , whereas matlab is decidedly not , allows for a much more fine - grained control over parallelization , and has other attractive features such as built - in interfacing to c , is strongly - typed , although flexibly so , and has a large , active package ecosystem .",
    "we aim to reimplement the framework described in this paper in julia in the future .",
    "the devito framework @xcite is another such approach to balance the high - level mathematics and low - level performance in pde - constrained problems specifically through the compilation of symbolic python to c on - the - fly .",
    "devito incurs some initial setup time to process the symbolic expressions of the pdes and compile them in to runnable c binaries , but this overhead is negligible compared to the cost of time - stepping solutions and only has to be performed once for a pde with fixed parameters .",
    "this is one possible option to speed up matrix - vector products , or allow for user - specified order of accuracy at runtime , if the relevant complex - valued extensions can be written .",
    "we leave this as an option for future work .",
    "the designs outlined in this paper make for an inversion framework that successfully obfuscates the inner workings of the construction , solution , and recombination of solutions of pde systems . as a result ,",
    "the high - level interfaces exposed to the user allow a researcher to easily construct algorithms dealing with the outer structure of the problem , such as stochastic subsampling or solving newton - type methods , rather than being hindered by the complexities of , for example , solving linear systems or distributing computation .",
    "this hierarchical and modular approach allows us to delineate the various components associated to these computations in a straightforward and demonstrably correct way , without sacrificing performance .",
    "moreover , we have demonstrated that this design allows us to easily swap different pde stencils , or even pdes themselves , while still keeping the outer , high - level interfaces intact .",
    "this design allows us to apply a large number high - level algorithms to large - scale problems with minimal amounts of effort .    with this design , we believe that we have struck the right balance between readability and performance and , by exposing the right amount of information at each level of the software hierarchy",
    ", researchers should be able to use this codebase as a starting point for developing future inversion algorithms .",
    "the authors would like to thank tristan van leeuwan for his helpful suggestions .",
    "this research was carried out as part of the sinbad project with the support of the member organizations of the sinbad consortium .",
    "curt da silva has been supported by the cgs d award from the national sciences and engineering research council of canada ( nserc ) throughout the duration of this work .",
    "the authors wish to acknowledge the senai cimatec supercomputing center for industrial innovation , with support from shell and the brazilian authority for oil , gas and biofuels ( anp ) , for the provision and operation of computational facilities and the commitment to invest in research & development .",
    "for our framework , not only do we want to solve   directly , but allow researchers to explore other subproblems associated to the primary problem , such as the linearized problem @xcite and the full - newton trust region subproblem . as such",
    ", we are not only interested in the objective function and gradient , but also other intermediate quantities based on differentiating the state equation @xmath132 .",
    "a standard approach to deriving these quantities is the adjoint - state approach , described for instance in @xcite , but the results we outline below are slightly more elementary and do not make use of lagrange multipliers .    rather than focusing on differentiating the expressions in   directly , we find it useful to consider * directional derivatives * various quantities and their relationships to the gradient .",
    "that is to say , for a sufficiently smooth function @xmath133 that can be scalar , vector , or matrix - valued , the directional dervative in the direction @xmath73 , denoted @xmath134 $ ] , is a linear function of @xmath73 that satisfies @xmath135 = \\lim_{t \\to 0 } \\dfrac{f(m+t\\delta m)-f(m)}{t}.\\ ] ] the most important part of the directional derivative , for the purposes of the following calculations , is that @xmath134 $ ] is the same mathematical object as @xmath133 , i.e. , if @xmath133 is a matrix , so is @xmath134 $ ] .    for a given inner product @xmath136",
    ", the gradient of @xmath133 , denoted @xmath137 , is the unique vector that satisfies @xmath138 \\quad \\forall \\delta m\\ ] ] if we are not terribly worried about specifying the exact vectors spaces in which these objects live and treat them as we d expect them to behave ( i.e. , satisfying product , chain rules , commuting with matrix transposes , complex conjugation , linear operators , etc . ) , the resulting derivations become much more manageable .",
    "starting from the baseline expression for the misfit @xmath133 and differentiating , using the chain rule , we have that @xmath139 & = d\\phi(r(m),d)[dr(m)[\\delta m]]\\\\      r(m ) & = p_r u(m)\\\\      dr(m)[\\delta m ] & = p_r du(m)[\\delta m ] \\end{aligned}\\ ] ] in order to determine the expression for @xmath50 $ ] , we differentiate the state equation , @xmath140 in the direction @xmath73 using the product rule to obtain @xmath141u(m ) + h(m)du(m)[\\delta m ] = 0\\\\      du(m)[\\delta m ] = h(m)^{-1 } ( -dh(m)[\\delta m]u(m ) ) .",
    "\\end{split } \\label{du2}\\ ] ] for the forward modelling operator @xmath142 , @xmath143 $ ] is the jacobian or so - called linearized born - modelling operator in geophysical parlance .",
    "since , for any linear operator @xmath144 , its transpose satisfies @xmath145 for any appropriately sized vectors @xmath146 , in order to determine the transpose of @xmath147 $ ] , we merely take the inner product with an arbitrary vector @xmath148 , `` isolate '' the vector @xmath73 on one side of the inner product .",
    "the other side is the expression for the adjoint operator . in this case",
    ", we have that @xmath149 , y \\rangle & = \\langle p_r h(m)^{-1}(-dh(m)[\\delta m]u(m ) ) , y \\rangle\\\\      & = \\langle h(m)^{-1}(-dh(m)[\\delta m]u(m)),p_r^t y\\rangle\\\\      & = \\langle dh(m)[\\delta m]u(m ) , -h(m)^{-h } p_r^t y \\rangle\\\\      & = \\langle t\\delta m , -h(m)^{-h } p_r^t y \\rangle\\\\      & = \\langle \\delta m , t^ * ( -h(m)^{-h } p_r^t y ) \\rangle \\end{aligned}\\ ] ] in order to completely specify the adjoint of @xmath143 $ ] , we need to specify the adjoint of @xmath55u(m)$ ] acting on a vector .",
    "this expression is particular to the form of the pde with which we re working .",
    "for instance , discretizing the constant - density acoustic helmholtz equation with finite differences results in @xmath150 with particular matrices @xmath151 discretizing the laplacian and identity operators , respectively , yields the linear system @xmath152 therefore , we have the expression @xmath153u(m)\\\\ & = \\omega^2 a\\text{diag}(\\delta m)u(m)\\\\ & = \\omega^2 a\\text{diag}(u(m))\\delta m , \\end{aligned } \\label{dh}\\ ] ] whose adjoint is clearly @xmath154 with directional derivative @xmath155 = \\omega^2\\text{diag}(\\overline{\\delta u})a^h .",
    "\\label{dtadj}\\ ] ] our final expression for @xmath156^*y$ ] is therefore @xmath157^*y = \\omega^2 \\text{diag}(\\overline{u(m)})a^h ( -h(m)^{-h } p_r^t y)\\ ] ] setting @xmath158 , @xmath159 yields the familiar expression for the gradient of @xmath133 @xmath160 this sort of methodology can be used to symbolically differentiate more complicated expressions as well as compute higher order derivatives of @xmath133 .",
    "let us write @xmath137 more abstractly as @xmath161 which will allow us to compute the hessian as @xmath162 v(m ) + t(m , u)^ * dv(m)[\\delta m].\\ ] ] here , @xmath163 $ ] is given in   and @xmath164 $ ] is given in  , for the helmholtz equation .",
    "we compute @xmath165 $ ] by differentiating @xmath166 as @xmath167 & = h(m)^{-h } dh(m)[\\delta m]^h v(m ) -h(m)^{-h } p_r^t ( \\nabla^2 \\phi[p_r du(m)[\\delta m]])\\\\ & = h(m)^{-h } ( dh(m)[\\delta m]^h v(m ) - p_r^t ( \\nabla^2 \\phi[p_r du(m)[\\delta m ] ] ) ) \\end{aligned}\\ ] ] which completes our derivation for the hessian - vector product .      from  , we have that the augmented wavefield @xmath5 solves the least - squares system @xmath168 u - \\left [ { \\begin{array}{c } d \\\\",
    "\\lambda q \\end{array } } \\right ] \\right\\|_2 ^ 2 , \\end{split}\\ ] ] i.e. , @xmath5 solves the normal equations @xmath169 for the objective @xmath170 , the corresponding wri objective is @xmath171 .",
    "owing to the variable projection structure of this objective , the expression for @xmath172 , by @xcite , is @xmath173 which is identical to the original adjoint - state formulation , except evaluated at the wavefield @xmath5 .",
    "the hessian - vector product is therefore @xmath174^ * ( h(m)u(m)-q ) + t(m , u(m))^ * ( dh(m)[\\delta m]u(m ) + h(m)du(m)[\\delta m]).\\ ] ] as previously , the expressions for @xmath52 $ ] and @xmath175^*$ ] are implementation specific .",
    "it remains to derive an explicit expression for @xmath50 $ ] below .",
    "we differentiate this equation in the direction @xmath73 to obtain @xmath179 u(m ) + g(m)du(m)[\\delta m ] = dr(m)[\\delta m ] \\\\",
    "\\rightarrow du(m)[\\delta m ] = g(m)^{-1 } ( dr(m)[\\delta m ] - dg(m)[\\delta m]u(m ) ) .",
    "\\end{split}\\ ] ] since @xmath180 = \\lambda^2 ( dh(m)[\\delta m]^{h } h(m ) + h(m)^hdh(m)[\\delta m])$ ] and @xmath147 = \\lambda^2 dh(m)[\\delta m]^h q$ ] , we have that @xmath51 = \\lambda^2 g(m)^{-1 } ( - h(m)^h dh(m)[\\delta m]u(m ) + dh(m)[\\delta m]^h ( h(m)u(m)- q ) ) .\\ ] ]"
  ],
  "abstract_text": [
    "<S> large scale parameter estimation problems are among some of the most computationally demanding problems in numerical analysis . </S>",
    "<S> an academic researcher s domain - specific knowledge often precludes that of software design , which results in inversion frameworks that are technically correct , but not scalable to realistically - sized problems . on the other hand , </S>",
    "<S> the computational demands for realistic problems result in industrial codebases that are geared solely for high performance , rather than comprehensibility or flexibility . </S>",
    "<S> we propose a new software design for inverse problems constrained by partial differential equations that bridges the gap between these two seemingly disparate worlds . </S>",
    "<S> a hierarchical and modular design allows a user to delve into as much detail as she desires , while exploiting high performance primitives at the lower levels . </S>",
    "<S> our code has the added benefit of actually reflecting the underlying mathematics of the problem , which lowers the cognitive load on user using it and reduces the initial startup period before a researcher can be fully productive . </S>",
    "<S> we also introduce a new preconditioner for the 3d helmholtz equation that is suitable for fault - tolerant distributed systems . </S>",
    "<S> numerical experiments on a variety of 2d and 3d test problems demonstrate the effectiveness of this approach on scaling algorithms from small to large scale problems with minimal code changes . </S>"
  ]
}