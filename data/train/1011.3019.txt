{
  "article_text": [
    "in order for an image to be decomposed , a proper representation of the image must first be done .",
    "one set of solutions for image representation is the decomposition of multivariate functions into monovariate functions as proposed by kolmogorov superimposition theorem ( kst ) @xcite .",
    "sprecher et.al @xcite have also proved that the monovariate internal functions obtained via the kst can be used to build space filling curves that sweep a multidimensional space .",
    "these 1d representations of the image can then be exploited for further processing using simple univariate or bivariate signal processing methods , as has been shown in @xcite and @xcite .",
    "it has further been proposed in @xcite that either the space filling curves can be fixed and then construct external function whoes sum and compositions correspond to a multivariate function @xcite or produce an algorithm that generates the internal function that adapts to the multivariate function and gives different space filling curve for different multivariate functions @xcite .",
    "the work in this manuscript finds its motivation in presenting an intial hybrid model that uses a fixed space filling curve for an image and differs in employing mutivariate chebyshev inequality on the @xmath0 dimensional points lying on the curve , to yield homogeneous probabilistically bounded multivariate surfaces .    from the theory of space filling curves",
    ", it is known that the hilbert space filling curve ( hsfc ) @xcite is the best in preserving the clustering properties while taking into account the locality of objects in a multidimensional space ( @xcite , @xcite ) . even though it can be applied to transform a multidimensional image representation into a linear format ( @xcite , @xcite )",
    ", the manuscript applies the hsfc to transform a @xmath1d matrix into @xmath2d space filling curve .",
    "the reason being that it saves the time and avoids the complexity in processing a @xmath1d matrix in comparison to @xmath0d matrix .",
    "next , a multivariate formulation of the generalized chebyshev inequality @xcite is applied to decompose the image into surfaces bounded probabilistically via a single chebyshev parameter .",
    "since the bounded surfaces are constructed based on the interaction of a set of points in @xmath3 lying on the curve , it can be safely assumed that information about the nature or density of surface in a locality gets captured in these tiny patches . for example , rgb images from the berkeley segmentation benchmark ( bsb ) @xcite have been taken into consideration for the current study . in the case of a single rgb image ,",
    "three dimensions exist in the colour map .",
    "these three form a feature set ( @xmath4 ) .",
    "several advantages arise with the use of this new hybrid model , namely : @xmath5 faster processing of the image on @xmath2d compared to analysis of neighbourhood information per pixel .",
    "@xmath5 generation of homogeneous surfaces of different sizes that are bounded probabilistically , by inequality .",
    "@xmath5 leakage problem gets avoided due to conservative nature of inequality .",
    "@xmath5 reduction in problem sample size by a factor @xmath6 ( chebyshev parameter ) .",
    "@xmath5 the density of image gets investigated via the multivariate formulation of the inequality . @xmath5",
    "the generalized hybrid model adapts to multivariate information while traversing on a @xmath2d fixed curve .",
    "hitherto , a brief description of the state of the work has been covered . in section [ sec : theory ] , the theoretical aspect of the method is dealt in a greater detail with a toy image example .",
    "experiments section [ sec : experiments ] deals with the empirical evaluations conducted on bsb .",
    "lastly , the conclusion follows in section [ sec : conclusion ] .",
    "( top left ) , @xmath7 ( top right ) , @xmath8 ( bottom left ) and @xmath9 ( bottom right).,width=321,height=245 ]     block under consideration.,width=321,height=377 ]",
    "the space filling curves form an important subject as it helps in transforming a multidimensional dataset into a linear format .",
    "this comes at a price of losing some amount of information , but the merits of preserving the local properties while transforming the objects in multi dimension to single dimension out weigh the incurred cost .",
    "the hsfc is a fractal filling curve proposed by @xcite which fills the space of @xmath1d place in a continuous manner .",
    "analytical results found in @xcite , @xcite and @xcite prove the optimality of results obtained while using hsfc . in the current formulation a matlab implementation of @xcite is used to generate the hsfc for @xmath1d matrices .",
    "figure [ fig : hlbcrv ] shows the space filling curve for the grids of size @xmath1 , @xmath7 , @xmath8 and @xmath9 respectively .",
    "note that the curve covers each and every point on the integer grid once while taking into account the local properties .",
    "it is not that the hsfc does not work for rectangular matrices , but the analysis of cluster preserving properties of the same becomes asymptotic in nature rather than being exact , as has been proved in @xcite . given an @xmath0d image , the hsfc is generated which remains invariant of the same .",
    ".,width=226,height=226 ]      let @xmath10 be a stochastic variable in @xmath0 dimensions with a mean @xmath11 $ ] .",
    "further , @xmath12 be the covariance matrix of all observations , each containing @xmath0 features and @xmath13 , then the multivariate tchebyshev inequality in @xcite states that : @xmath14)^{t } \\sigma^{-1 } ( x - e[x ] ) \\geq \\epsilon\\ } & \\leq & \\frac{\\mathcal{n}}{\\epsilon } \\nonumber\\\\ \\mathcal{p}\\{(x - e[x])^{t } \\sigma^{-1 } ( x - e[x ] ) < \\epsilon\\ } & \\geq & 1 - \\frac{\\mathcal{n}}{\\epsilon } \\nonumber\\\\ \\label{equ : ti}\\end{aligned}\\ ] ] i.e. the probability of the spread of the value of @xmath10 around the sample mean @xmath11 $ ] being greater than @xmath6 , is less than @xmath15 .",
    "there is a minor variation for the univariate case stating that the probability of the spread of the value of @xmath16 around the mean @xmath17 being greater than @xmath18 is less than @xmath19 .",
    "apart from the minor difference , both formulations convey the same message about the probabilistic bound imposed when a random vector or number @xmath10 lies outside the mean of the sample by a value of @xmath6 .    in a broader perspective , the goal being to demarcate regions based on surfaces , two questions need to be addressed regarding the decomposition of image . @xmath5",
    "which two pixels or their corresponding @xmath0d vectors be selected to initialize a surface depicting _ near uniform behaviour _ ?",
    "@xmath5 what should be the size of such a restricted surface ?",
    "the solution to first question would help in _ initializing a surface_. a pair of vectors in @xmath0d will swap a flat plane with an angle subtended in between the two vectors .",
    "given that the dot product exists in the higher dimensional plane , the cosine of the angle @xmath20 between the two vectors would suggest the degree of closeness between them .",
    "if @xmath21 and @xmath22 are two such vectors in @xmath0d , then the degree of closeness is given by : @xmath23 were , @xmath24 is the dot product and the denominator contains the @xmath1-norm terms of both vectors .",
    "it is well known that the absolute value of @xmath25 tends to @xmath2 ( @xmath26 ) as vectors tend to be nearly parallel ( perpendicular ) .",
    "let @xmath27 , @xmath28 and @xmath29 be three consecutive pixels on the hsfc . if the @xmath30 of the angle between @xmath27 and @xmath28 evaluates to an absolute value greater than a nearness threshold @xmath31 ( say @xmath32 ) then the pair is considered as a valid surface .",
    "note that @xmath31 is the nearness parameter which is used as a threshold to decide the degree of closeness of two pixels for forming a surface .",
    "if not , then @xmath27 is left as a single point in @xmath0d and the closeness criterion is checked for @xmath28 and @xmath29 ( and the process is repeated ) .",
    "solving the second question shall define the _ range of the surface_. once the start and end points ( say @xmath28 and @xmath29 respectively ) of a valid surface have been set , the size of the surface has to be determined .",
    "the size of the surface would constitute all points that contribute towards uniform surface behaviour in @xmath0d .",
    "this degree of uniformity is controlled via the chebyshev s inequality .",
    "the idea is executed as follows : the next consecutive point ( say @xmath33 ) after @xmath29 is considered for surface extent analysis . if the spread of surface point @xmath33 from @xmath34 the mean of the _ existing surface _",
    "@xmath35 $ ] , factored by the covariance matrix , is below @xmath6 , then @xmath33 is considered as a part of the surface and marked as a new ending point of the surface .",
    "using chebyshev s inequality , it boils down to : @xmath36)^{t } \\sigma^{-1 } ( \\vec{t } - e([\\vec{v},\\vec{w } ] ) \\geq \\epsilon\\ } & \\leq & \\frac{\\mathcal{n}}{\\epsilon } \\nonumber\\\\ \\mathcal{p } \\{(\\vec{t } - e([\\vec{v},\\vec{w}])^{t } \\sigma^{-1 } ( \\vec{t } - e([\\vec{v},\\vec{w } ] ) < \\epsilon\\ } & \\geq & 1 - \\frac{\\mathcal{n}}{\\epsilon } \\nonumber\\\\ \\label{equ : ti_imp}\\end{aligned}\\ ] ] were @xmath12 is the covariance matrix between the @xmath0d vectors constituting the initial surface .",
    "satisfaction of this criterion leads to extension of the size of initial surface by one more point i.e. @xmath33 .",
    "the surface now constitutes @xmath37 $ ] , with @xmath28 and @xmath33 as start and end marker points .",
    "if not , the size of the surface remains as it is and a fresh start is made starting with @xmath33 and the next consecutive point on the hsfc .",
    "the satisfaction of the inequality also gives a lower probabilistic bound on size of surface by a value of @xmath38 , if the second version of the chebyshev formula is under consideration .",
    "the above formulation implies that when a homogeneous patch is encountered , then the a new point does not deviate much from the initial surface .",
    "thus the size of the surface grows smoothly .",
    "for a highly irregular patch , the surface size may be very restricted due to high variation of a pixel from the surface it is being tested in the vicinity .",
    "figure [ fig : starfish ] shows the tiny patch ( @xmath39 ) of starfish under consideration and figure [ fig : hlbstarfish ] shows the hsfc generated over the area of the image .",
    "the tiny restricted surfaces generated using the multivariate and the univariate formulation of the tchebyshev inequality for @xmath40 are shown in figure [ fig : multi_e3 ] and [ fig : uni_e3 ] .",
    "note how the surfaces differ due to the multivariate and univariate formulation of the inequality .",
    "the former takes into account the entire @xmath0d vectors in tandem to compute the covariance or the texture interaction and the mean , while the later computes the inequality separately for each and every dimension .",
    "the different colours just indicate the different surfaces and has nothing to do with clustering at this stage .",
    "the potentiality of the method gets highlighted due to the bounded surfaces that have been obtained after image decomposition .",
    "this boundedness is checked via the parameter which determines the degree of intricacy to which the texture interaction is to be taken into account .",
    "it should be noted that in the univariate case the decision is made on the majority vote after @xmath0 evaluations of the inequality on the space filling curve for a single pixel .",
    "what paves way is that the univariate formulation does not capture the interaction which later leads to low grade segmentation results compared to that given by the formulation .",
    "these differences are apparent in the figures mentioned at the starting of the paragraph .",
    "figure [ fig : ds_multi ] and [ fig : ds_uni ] shows the image patch decomposed into surface patches for different @xmath6 values .",
    "image of starfish from @xcite , decomposed using the multivariate formulation of chebyshev inequality with @xmath40 and @xmath41 .",
    "a coloured line shows the pixels associated to a single bounded surface on the hsfc.,width=226,height=226 ]     decomposed using the univariate formulation of tchebyshev inequality with @xmath40 and @xmath41 .",
    "a coloured line shows the pixels associated to a single bounded surface on the hsfc . note that size of surface is decided based on voting across @xmath0 evaluations.,width=226,height=226 ]      the inequality being a criterion , the probability associated with the same gives a belief based bound on the satisfaction of the criterion .",
    "this gives rise to certain simple implications as follows .",
    "let @xmath42 be a _ decomposition _ which is equivalent to @xmath43)^{t } \\sigma^{-1 } ( x_{t } - e[x])$ ] . then :     and for @xmath6 equal to @xmath7 ( top left ) , @xmath8 ( top right),@xmath9 ( bottom left ) and @xmath44 ( bottom right).,width=321,height=226 ]     and for @xmath6 equal to @xmath7 ( top left ) , @xmath8 ( top right),@xmath9 ( bottom left ) and @xmath44 ( bottom right).,width=321,height=226 ]    decompositions @xmath42 are bounded by lower probability bound of @xmath38 given that @xmath45 .",
    "[ lem:01 ]    not only does it hold true for @xmath45 but also for @xmath46 . but the probability being greater than a negative value is always true and thus @xmath47 forms the lower bound . as @xmath48 , @xmath49 .",
    "the value of @xmath6 reduces the size of the sample from @xmath50 to an upper bound of @xmath51 probabilistically with a lower bound of @xmath38 . here",
    "@xmath50 is the number of pixels in a @xmath1d matrix .",
    "[ lem:02 ]    this holds true as the image is decomposed into surfaces which are probabilistically bounded via the chebyshev inequality .",
    "this decomposition leads to reduction in the sample size by a factor of @xmath6 while retaining the information content , kudos to the space filling curve traversal .    as @xmath52 the lower probability bound drops to zero , implying large number of small decompositions @xmath42",
    "can be achieved .",
    "( vice versa for @xmath48 ) [ lem:03 ]    this gives an insight into the degree to which the image can be decomposed .",
    "where finner details are of import , one may use values of @xmath6 tending to @xmath0 and vice versa .",
    "let image @xmath53 contain @xmath50 pixels , with each pixel having @xmath0 features .",
    "if @xmath53 can be decomposed in @xmath54 bounded surfaces via the proposed hybrid model , then in case of the decompositions having equally likely probabilities : ( a ) @xmath50 = @xmath55 and ( b ) @xmath56 open interval ( @xmath57 ) .",
    "[ thm:01 ]",
    "since the @xmath53 can be decomposed into @xmath58 bounded surfaces , it is known that the decompositions are _ disjoint _ sets .",
    "let @xmath59 ( for @xmath60 ) be such decompositions .",
    "then @xmath53 = @xmath61",
    ". considering @xmath53 as the universal set , we get : @xmath62 .",
    "from lemma [ lem:01 ] , it is known that @xmath63 . in the case that the decompositions are equally likely , the lowest probability for each @xmath59 evaluates to @xmath38 .",
    "thus , @xmath64 = @xmath65 = @xmath66 .",
    "since @xmath67 and @xmath68 = @xmath69 , it implies that @xmath66 = @xmath2 . simplifying the foregoing formulation leads to @xmath70 .",
    "this proves the part ( a ) of the theorem .    from part ( a )",
    ", it can be clearly seen that @xmath71 , lest part ( a ) would be invalid .",
    "thus @xmath72 . similarly ,",
    "if @xmath73 , then on simplification of part ( a ) evaluates to @xmath74 . again this can not be the case as an image will have atleast one feature in terms of intensity .",
    "thus @xmath75 .",
    "let @xmath76 , then for @xmath77 part ( a ) shows that the ratio of @xmath78 is a negative quantity .",
    "this can not be possible as both numbers in the ratio are positive numbers .",
    "thus @xmath79 . again , for the same condition of @xmath80 , if @xmath81 , part ( a ) on evaluation shows the ratio of @xmath78 to be a negative quantity .",
    "this again is a contradiction given the state of @xmath50 and @xmath0 .",
    "thus @xmath82 .",
    "thus @xmath6 is strictly bounded in the open interval ( @xmath57 ) .",
    "this finishes proof for part ( b ) .",
    "if an image @xmath53 is decomposed into bounded surfaces s.t .",
    "the latter have equally likely probabilities , then theoretically the maximum value of both @xmath6 ( chebyshev parameter ) and @xmath0 ( number of feature dimensionality of @xmath53 ) is of the order of @xmath83 .",
    "[ thm:02 ]    from theorem [ thm:01 ] , it is known that @xmath70 , when the probabilities of the decomposed surfaces are equally likely .",
    "it is also known that @xmath84 .",
    "let @xmath76 and @xmath6 decrease harmonically via @xmath85 for @xmath80 from @xmath1 onwards .",
    "then simplifying part ( a ) of theorem [ thm:01 ] gives @xmath86 .",
    "now , if @xmath87 , then @xmath88 .",
    "the fraction on the right hand side can be segregated into complete and partial fractions as @xmath89 .",
    "it is known that @xmath90 . then @xmath91 . equating for both inequalities around @xmath92 , the value of @xmath80 lies between @xmath93 and @xmath94 . taking the order of maximum value of @xmath80 as @xmath95 ,",
    "@xmath6 = @xmath92 = @xmath95 and @xmath0 = @xmath80 = @xmath95 .",
    "clusters using @xmath80-means ( cityblock distance , @xmath96 replicates and @xmath97 iterations ) on decomposed surfaces generated via multivariate inequality with @xmath41 and for @xmath6 equal to @xmath7 ( top left ) , @xmath8 ( top right),@xmath9 ( bottom left ) and @xmath44 ( bottom right).,width=321,height=226 ]    theorem [ thm:01 ] shows how the sample size @xmath50 is related to the dimensionality of feature space @xmath0 via the chebyshev parameter @xmath6 .",
    "implicitly , it also states that the sample size @xmath50 must be greater than @xmath0 and the the value of @xmath6 lies in the open interval @xmath98 .",
    "these tight bounds in an idealistic case show that the model is effective in a theoretical sense .",
    "the second theorem builds on the first and shows that the maximum theoretical value of the parameter @xmath6 is of the order of square root of the sample size @xmath50 and so is the dimensionality of the feature space @xmath0 .",
    "in an ideal case of equal likelihood , this maximum value gives an upper bound on @xmath6 as well as @xmath0 , such that the decompositions are uniformally spread in the higer dimensional space .",
    "once the image has been decomposed into bounded surfaces , segmentation of the image is done on the average value of surfaces via @xmath80-means algorithm in matlab with a certain number of pre - defined clusters .",
    "the cityblock distance is used as a metric for the kmeans and the number of replicates is of the order of @xmath96 with @xmath97 iterations for the @xmath80-means .",
    "the reason for using a high number repilcates and iterations is to avoid getting stuck in local solutions .",
    "the average values are computed by taking the mean of the @xmath0d points that constitute the bounded surfaces .",
    "these values are considered to be robust as the surfacess themselves are bounded on the first place probabilistically taking into account the variability in intensity behaviour .     and for @xmath6 equal to @xmath7 , @xmath8,@xmath9 and @xmath44 , from left but one to right with number of clusters @xmath99.,width=377,height=264 ]     and for @xmath6 equal to @xmath7 , @xmath8,@xmath9 and @xmath44 , from left but one to right with number of clusters @xmath99.,width=377,height=264 ]    figure [ fig : c5_multi ] shows the corresponding result for different values of @xmath6 .",
    "the figure shows that the quality of segmentation degrades as the value of @xmath6 increases , which increases the surface size .",
    "for example , the groves on the starfish are captured in greater details for @xmath100 than for higher values of the same .",
    "a few sample images from @xcite for which segmented images were generated over different values of @xmath101 have been presented in figures [ fig : berk_clust_a ] and [ fig : berk_clust_b ] .",
    "the number of clusters was predefined to be @xmath99 . with increasing size of @xmath6 values ,",
    "the amount of decompositions reduce which later affect the quality of the segmentation .",
    "this is apparent in the figures as one moves from left to right.the clustering on these bounded surfaces is not only good but also less time consuming as the segmentation are done on a reduced sample size while still retaining the crucial pieces of information .",
    "not that the solution is the best , but results tend to be good quality at first sight .",
    "algorithm [ alg : final_a ] and its continuity in [ alg : final_b ] shows the implementation for the decomposing the image into probabilistically bounded surfaces based on space filling curve traversal .",
    "the depicted version is for multivariate formulation of the tchebyshev inequality .",
    "minor change in the form of univariate formulation used separately with each of the @xmath0 dimensions would lead to univariate version .",
    "note that the output of the decomposition algorithm is a list of bounded surfaces .",
    "many features could be developed but in this manuscript mean values of all the @xmath0d points constituting a surface is taken as a feature vector .",
    "this is because the inequality measures the degree of homogeneity of density interaction in @xmath0d .",
    "@xmath102 size(@xmath103 ) @xmath102 hlbrtcrv(@xmath104 , @xmath105 ) initialize variables @xmath106 [ ] @xmath107 @xmath108 @xmath109 generate bounded surfaces on hsfc @xmath110 @xmath111 @xmath102 [ @xmath112(@xmath113 ) , @xmath114(@xmath113 ) ] @xmath102 [ @xmath112(@xmath115 ) , @xmath114(@xmath115 ) ] @xmath116 @xmath102 struct ( ) ; @xmath117 @xmath102 [ @xmath118 , @xmath119 ; @xmath120 , @xmath121 store intensity values per pixel @xmath122 [ ] @xmath102 size(@xmath117 ) @xmath102 [ @xmath123 , @xmath124 @xmath125 [ ] @xmath125 [ @xmath126 ; @xmath103(@xmath127 , @xmath128 , @xmath129 ) ] @xmath122 [ @xmath130 , @xmath126 ] compute nearness between two initial pixels @xmath132 dot(@xmath133 , @xmath134 ) ; @xmath135 check @xmath136 greater than nearness param @xmath137 store next pixel on hsfc @xmath102 [ @xmath112(@xmath115 ) , @xmath114(@xmath115 ) ] @xmath138 [ @xmath120 , @xmath121 store intensity values for pixel @xmath139 [ ] @xmath139 [ @xmath140 ; @xmath103(@xmath141 , @xmath120 , @xmath129 ) ]    another point to be aware of is the computation of the measure in multivariate chebyshev inequality in equation [ equ : ti_imp ] .",
    "since it requires presence of inverse of the covariance matrix , one may run into problem of sparseness , or inappropriate dimensionality between the number of samples and features . to overcome these problems ,",
    "the pseudo inverse was computed using the singular value decomposition implementation in matlab .",
    "being fast and effective , the decomposition of the image into bounded surfaces works within a matter of seconds .",
    "tchebychevs inequality for fixing length of surf note - rows are dimension and cols are pixels in surface matrix @xmath142 @xmath17(@xmath143 ) @xmath144 std(@xmath143 ) @xmath145 cov(@xmath143 ) @xmath146 ( @xmath147 ) compute inequality in equ [ equ : ti_imp ] @xmath148 @xmath149 * pinv(@xmath150 ) * @xmath151 @xmath152 @xmath153 @xmath122 [ @xmath130 , @xmath140 ] @xmath155 [ @xmath117 ; @xmath156 @xmath137 @xmath157 store the surfaces , associated pixels and features @xmath158 @xmath159@xmath160 @xmath161 mean per dimension as feature for a surface @xmath162 [ ] @xmath162 [ @xmath163 ; @xmath17(@xmath164 ) ] @xmath165 @xmath166 @xmath167 [ ] @xmath168 [ ] @xmath158 @xmath169 mean per dimension as a feature for just one pixel @xmath162 [ ] @xmath162 [ @xmath163 ; @xmath17(@xmath164 ) ] @xmath165 @xmath170    .summary table of rank of algorithms based on @xmath171-score generated on @xmath96 test images in the bsb dataset @xcite . [ cols=\"^,^,<\",options=\"header \" , ]     , @xmath172 and number of clusters @xmath173 ) , em ( number of clusters @xmath173 ) , ncuts ( number of clusters @xmath173 ) , grbase ( @xmath174 , @xmath175 ) and mshift ( @xmath176 , @xmath177).,width=321,height=755 ]    , @xmath172 and number of clusters @xmath173 ) , em ( number of clusters @xmath173 ) , ncuts ( number of clusters @xmath173 ) , grbase ( @xmath174 , @xmath175 ) and mshift ( @xmath176 , @xmath177).,width=321,height=755 ]",
    "to test the effectiveness of the multivariate chebyshev algorithm ( mtch ) , the results obtained on image segmentation were compared with some of the standard existing algorithms .",
    "the other algorithms employed were the normalized cuts ( ncuts ) @xcite , @xcite , edge graph based segmentation ( grbase ) @xcite , the mean shift clustering ( mshift ) @xcite and an expectation maximization ( em ) based implementation @xcite .",
    "figure [ fig : pepper_seg ] shows the standard peppers image that was segmented into @xmath173 clusters for mtch , em and ncuts . for the case of grbase ( @xmath174 , @xmath175 ) and mshift ( @xmath176 , @xmath177 ) , parameters values were specified as mentioned in literature .",
    "matlab implementations of grbase and mshift were taken from @xcite to produce the results .",
    "all algorithms were tested with a fixed parameter value on images with varying content .",
    "this does imply that results per image may not be optimized and would sound a bit unfair , but from another perspective such an experiment also suggests how robust an algorithm is against the variance in content of images , given a fixed parameter value .",
    "this outlook holds true when both the grbase and mshift algorithms in this experimental setup donot fair well on fixed parameter value for all images as compared to the proposed mtch algorithm .",
    "the @xmath171-scores later generated bolster this claim .",
    "probabilistic boundaries were generated based on brightness and texture gradients @xcite on the segmented images generated from the algorithms under study as well as the available human segmentation .",
    "the boundaries were later evaluated to find @xmath171-scores . in many of these images ,",
    "the segmentations based on bounded surfaces gave the good and consistent results .",
    "table [ table : f_score ] shows the summary of @xmath171-scores by the algorithms onthe benchmark .",
    "it states that the segementations from the bounded surfaces gave better results than some of the standard well known algorithms .",
    "the mtch works second best to em .",
    "a reason for low performace of mtch w.r.t em may be due the ignorance of important features like surface gradient and reflectance propertices that may add to more discriminative information than using average values of intensities at the current stage .",
    "although the em gives good performance many times , there are places where it does not capture the nature of surface well .",
    "one such case is the texture of the purple cloth and wrinkles in it , in the peppers image ( figure [ fig : pepper_seg ] ) . for more such cases ,",
    "the generated results can be made available .    , @xmath100 and number of clusters @xmath173 ) , ( c ) em ( number of clusters @xmath173 ) ( d ) ncuts ( number of clusters @xmath173 ) ( e ) grbase ( @xmath174 , @xmath175 ) and ( f ) mshift ( @xmath176 , @xmath177).,width=321,height=377 ]    it is widely known that the mshift yields good segments such that no local information is left behind .",
    "too much information sometimes may not be necessary while segmentation are been compared .",
    "figures [ fig : bdbs_01 ] and [ fig : bdbs_02 ] show the boundaries generated using the routines in the benchmark .",
    "note that in these images , the mtch gave the best results .",
    "also , at first sight it may appear that the boundaries may not have been generated well in case of mshift and grbase , but this is not the case as careful investigation does show their presence .",
    "the grbase @xcite works on the basis of a predicate that measures the evidence of a boundary on two ideas , namely : the comparison of intensity differences across boundary and the other , intensity differences among neighbourhood pixels within a region . for this a threshold function is proposed which depends on the components and their respective size .",
    "this also means that the parameter used for scaling components would be different for different images , if good segmentation results are desired in grbase . in comparison",
    ", the mtch decomposes the images into surfaces which are bounded surfaces or components that preserve the homogeneity in texture using the image content invariant hsfc and the multivariate measure that captures the local neighbourhood interaction in the tchebyshev inequality .",
    "thus the constant value of parameters for mtch would give good results for different images most of the time .",
    "results in the benchmark dataset prove the issue that for same values of paramters in grbase the segmentation results are inferior to that of mtch of a sample of @xmath96 test images .",
    "it must be noted that the parameter @xmath80 used in @xcite , scales the size of the component and is not the minimum component size .",
    "thus it is taken as a constant and no relations of it are derived with respect to the interaction present in the image .",
    "though on similar lines , @xmath6 in mtch is also a parameter that defines the degree of control over size of components , but with a bound .",
    "the @xmath6 characterizes the size of a surface or component probabilistically , while relating to the control of the degree of texture interaction using the mutivariate measure in the tchebyshev inequality ( equation [ equ : ti_imp ] ) .",
    "this probabilistic bound is the key relation between the size of component and the texture interaction within , that decomposes the image into homogeneous surfaces in @xmath0d by lemma [ lem:03 ] .",
    "clustering on a bunch of homogeneous surfaces is bound to give robust segmentation results .",
    "the price that is paid is in terms of time required to cluster the surfaces using the standard @xmath80-means .",
    "figures [ fig : bdbs_01 ] and [ fig : bdbs_02 ] show the boundaries generated using the routines in the benchmark which are later evaluated to generate @xmath171-scores that determine the accuracy of the proposed algorithm as well as that of the other algorithms .",
    "note that in these images , the mtch gave the best results . also , at first sight it may appear that the boundaries may not have been generated well in case of mshift and grbase , but this is not the case as careful investigation does show their presence .",
    "figure [ fig : pr_01].a and [ fig : pr_01].b shows the precision recall curve for ( em , mtch ) and ( mtch , mshift ) , respectively .",
    "figure [ fig : pr_02].a and [ fig : pr_02].b shows the curve for ( mtch , ncuts ) and ( mtch , grbase ) , respectively .    ) and mtch ( @xmath178 , @xmath100 and number of clusters @xmath173 ) and ( b ) mtch ( @xmath41 , @xmath100 and number of clusters @xmath173 ) and mshift ( @xmath176 , @xmath177).,width=321,height=529 ]",
    "the proposed method has advantages as well as disadvantages .",
    "this section gives an analysis of the intricate points of the algorithm as well as hints as to where improvements can be made .",
    "_ neighbourhood information _ is implicitly considered using a hsfc traversal . the _ topography of surface _",
    "is captured by treating the @xmath0 dimensions of the image .",
    "for rgb it would be @xmath4 .",
    "_ filtering _ of image is not required unless absolutely necessary .",
    "the selection of surfaces and checking their validity based on variation of points in @xmath0d via tchebyshev inequality , makes the operation of filtering computationally redundant .",
    "especially the variation or standard deviation in the @xmath0d points is the measure that tolerates the amount of noise that can be taken into account .",
    "if the variation is too high , then the initialized surface may be invalid for further processing due to excessive noise .",
    "the _ leakage problem _ is that it is not known when to stop to determine the size of the area .",
    "this is tackled by determining the length of the surface via the use of the tchebyshev s inequality , instead of using thresholds based on image intrinsic intensity values .",
    "one aspect that affects the performance of the algorithm is the @xmath80-means clustering which may require several iterations as well as replicates in order to converge and produce clusters without getting stuck in some local minima . in general terms , if one is not bogged down by the intricacies of the @xmath80-means then the whole framework works well on surfaces and gives nice segmentation results on the benchmark .",
    "the @xmath80-means on pixels is slower than the @xmath80-means on the surfaces themselves as the sample size of the former is reduced by a factor of @xmath6 while retaining the local properties using the hilbert space filling curve .    ,",
    "@xmath179 and number of clusters @xmath173 ) and ncuts ( number of clusters @xmath173 ) ( b ) mtch ( @xmath41 , @xmath100 and number of clusters @xmath173 ) and grbase ( @xmath174 , @xmath175).,width=321,height=529 ]    the current version of the algorithm also does not optimize the values of @xmath6 in equation [ equ : ti_imp ] and @xmath31 the initialization parameter .",
    "silhouette validation @xcite could be one of the methods employed to find the best value of @xmath80 clusters .",
    "the current research does not focus on the number of clusters per se . instead of focusing as optimisation problem , @xmath31 and @xmath6 act as parameters of degree of control over the inclusion of points for surface initialization and size of the surface .",
    "the experiments prove that the initial model , without much tunning gives comparable results for segmentation purpose .",
    "robust performance across images with varying context point towards the benefits of using a hybrid model that currently uses a fixed chebyshev parameter value , a simple measure of similarity and a fixed space filling curve .",
    "intuitively , it can be infered that clustering on these probabilistically bounded homogeneous surfaces will be faster than clustering on pixels .",
    "this is because the homogeneous intensity values gets bunddled up together and reduces the sample size of the original problem by a factor of @xmath6 ( chebyshev parameter ) .",
    "because of its generalized framework , the proposed decomposition algorithm can find its application in areas like the generation of textures , combining information from multimodal sources as in biomedical images and processing multidimensional information on space filling curves , to name a few .",
    "a novel hybrid model for image decomposition has been proposed .",
    "the model works on reduced image representation based on monovariate functions and processes information spread in a multidimensional framework .",
    "initial segmentation results indicate the efficacy of the tool in terms of generalisation and robustness across images with varying content .",
    "the author thanks the neuroimaging center ( umcg , groningen , the netherlands ) for supporting this work and dr .",
    "charless fowlkes , assistant professor at computer science department uc irvine ( usa ) , for sharing the compiled berkeley segmentation benchmark code for mac intel hardware .",
    "leni , p.e . ,",
    "fougerolle , y. , truchetet , f. : kolmogorov superposition theorem and its application to multivariate function decompositions and image representation .",
    "conference on signal - image technology and internet - based systems ( 2008 )            moon , b. , jagadish , h.v . ,",
    "faloutsos , c. , saltz , j.h . :",
    "analysis of the clustering properties of the hilbert space - filling curve , ieee transactions on knowledge and data engineering , vol .",
    "13 , 124 - 141 ( 2001 )      martin , d. , fowlkes , c. , tal , d. , malik , j. : a database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics .",
    "8th intl conf .",
    "computer vision , vol . 2 , 416 - 423 july ( 2001 )"
  ],
  "abstract_text": [
    "<S> combining the properties of monovariate internal functions as proposed in kolmogorov superimposition theorem , in tandem with the bounds wielded by the multivariate formulation of chebyshev inequality , a hybrid model is presented , that decomposes images into homogeneous probabilistically bounded multivariate surfaces . </S>",
    "<S> given an image , the model shows a novel way of working on reduced image representation while processing and capturing the interaction among the multidimensional information that describes the content of the same . </S>",
    "<S> further , it tackles the practical issues of preventing leakage by bounding the growth of surface and reducing the problem sample size . </S>",
    "<S> the model if used , also sheds light on how the chebyshev parameter relates to the number of pixels and the dimensionality of the feature space that associates with a pixel . </S>",
    "<S> initial segmentation results on the berkeley image segmentation benchmark indicate the effectiveness of the proposed decomposition algorithm .    </S>",
    "<S> inequality , monovariate functions , bounded surfaces </S>"
  ]
}