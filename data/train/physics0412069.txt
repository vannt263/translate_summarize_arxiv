{
  "article_text": [
    "an important class of experiments consists in counting ` objects ' . in fact , we are often interested in measuring their _ density _ in time , space , or both ( here ` density ' stands for a general term , that in the domain of time is equivalent to ` rate ' ) or the _ proportion _ of those objects that have a certain character in common . for example , particle physicists might be interested in cross sections and branching ratios , astronomers in density of galaxies in a region of the sky or in the ratio of galaxies exhibiting some special features .",
    "a well known problem in counting experiments is that we are rarely in the ideal situation of being able to count individually and at a given time all the objects of interest .",
    "more often we have to rely an a sample of them .",
    "other problems that occur in real environments , especially in frontier research , are detector inefficiency and presence of background : sometimes we lose objects in counting ; other times we might be confused by other objects that do not belong to the classes we are looking for , though they are observationally indistinguishable from the objects of interest .",
    "we focus here on the effect of background in measurements of proportions . for a extensive treatment of the effect of background on rates ,",
    "i.e. measuring the intensity of a poisson process in presence of background , see ref .",
    "@xcite , as well as chapters 7 and 13 of ref .",
    "@xcite .",
    "the paper is structured as follows . in section",
    "[ sec : binomial ] we introduce the ` direct ' and ` inverse ' probabilistic problems related to the binomial distribution and the two cases of background that will be considered . in section",
    "[ sec : no_bkgd ] we go through the standard text - book case in which background is absent , but we discuss also , in some depth , the issue of how prior knowledge does or does not influence the probabilistic conclusions .",
    "then , in the following two sections we come to the specific issue of this paper , and finally the paper ends with the customary short conclusions .",
    "an important class of counting experiments can be modeled as independent bernoulli trials . in each trial",
    "we believe that a _ success _ will occur with probability @xmath0 , and a _ failure _ with probability @xmath4 . if we consider @xmath2 independent trials , all with the same probability @xmath0 , we might be interested in the total number of successes , independently of their order .",
    "the total number of successes @xmath5 can range between @xmath6 and @xmath2 , and our belief on the outcome @xmath7 can be evaluated from the probability of each success and some combinatorics .",
    "the result is the well known _",
    "binomial _ distribution , hereafter indicated with @xmath8 : @xmath9 having _ expected value _ and _ standard deviation _ @xmath10",
    "we associate the formal quantities expected value and standard deviation to the concepts of ( probabilistic ) _ prevision _ and _ standard uncertainty_.    the binomial distribution describes what is sometimes called a _ direct probability _ problem , i.e. calculate the probability of the experimental outcome @xmath1 ( the _ effect _ ) given @xmath2 and an assumed value of @xmath0 .",
    "the _ inverse _ problem is what concerns mostly scientists : _ infer @xmath0 given @xmath2 and @xmath1_. in probabilistic terms , we are interested in @xmath11 .",
    "probability inversions are performed , within probability theory , using bayes theorem , that in this case reads @xmath12 where @xmath13 is the _ prior _ , @xmath14 the _ posterior _ ( or _ final _ ) and @xmath15 the _ likelihood_. the proportionality factor is calculated from normalization .",
    "[ note the use of @xmath16 for the several probability functions as well as probability density functions ( pdf ) , also within the same formula . ]",
    "the solution of eq .",
    "( [ eq : inf_binom ] ) , related to the names of bayes and laplace , is presently a kind of first text book exercise in the so called bayesian inference ( see e.g. ref .",
    "the issue of priors in this kind of problems will be discussed in detail in sec .",
    "[ ss : priors ] , especially for the critical cases of @xmath17 and @xmath18 .",
    "the problem can be complicated by the presence of background .",
    "this is the main subject of this paper , and we shall focus on two kinds of background .    1 .",
    "* background can only affect @xmath19*. think , for example , of a person shooting @xmath2 times on a target , and counting , at the end , the numbers of scores @xmath1 in order to evaluate his efficiency .",
    "if somebody else fires by mistake at random on his target , the number @xmath1 will be affected by background .",
    "the same situation can happen in measuring efficiencies in those situations ( for example due to high rate or loose timing ) in which the time correlation between the equivalents of ` shooting ' and ` scoring ' can not be done on a event by event basis ( think , for example , to neutron or photon detectors ) .",
    "+ the problem will be solved assuming that the background is described by a poisson process of well known intensity @xmath20 , that corresponds to a well known expected value @xmath21 of the resulting poisson distribution ( in the time domain @xmath22 , where @xmath23 is measuring time ) . in other words ,",
    "the observed @xmath1 is the sum of two contributions : @xmath24 due to the _ signal _ , binomially distributed with @xmath8 , plus @xmath25 due to background , poisson distributed with parameter @xmath21 , indicated by @xmath26 .",
    "+ for large numbers ( and still relatively low background ) the problem is easy to solve : we subtract the expected number of background and calculate the proportion @xmath27 . for small numbers , the ` estimator ' @xmath28 can become smaller than 0 or larger then 1 . and ,",
    "even if @xmath28 comes out in the correct range , it is still affected by large uncertainty .",
    "therefore we have to go through a rigorous probability inversion , that in this case is given by @xmath29 where we have written explicitly in the likelihood that @xmath1 is due to the sum of two ( individually unobservable ! ) contributions @xmath24 and @xmath25 ( hereafter the subscripts @xmath30 and @xmath31 stand for _ signal _ and _ background_. ) 2 .",
    "* the background can show up , at random , as independent ` fake ' trials , all with the same @xmath32 of producing successes*. an example , that has indeed prompted this paper , is that of the measuring the proportion of blue galaxies in a small region of sky where there are galaxies belonging to a cluster , as well as background galaxies , the average proportion of blue galaxies of which is well known . in this case",
    "both @xmath2 and @xmath1 have two contributions : @xmath33 with @xmath34 where ` @xmath35 ' stands for ` follows a given distribution ' .",
    "+ again , the trivial large number ( and not too large background ) solution is the proportion of background subtracted numbers , @xmath36 .",
    "but in the most general case we need to infer @xmath0 from @xmath37 we might be also interested also to other questions , like e.g. how many of the @xmath2 object are due to the signal , i.e. @xmath38 indeed , the general problem lies in the joint inference @xmath39 from which we can get other information , like the conditional distribution of @xmath40 for any given number of events attributed to signal : @xmath41 finally , we may also be interested in the rate @xmath42 of the signal objects , responsible of the @xmath43 signal objects in the sample ( or , equivalently , to the poisson distribution parameter @xmath44 ) : @xmath45",
    "the solution of eq.([eq : inf_binom ] ) depends , at least in principle , on the assumption on the prior @xmath46 .",
    "taking a flat prior between 0 and 1 , that models our _ indifference _ on the possible values of @xmath0 _ before _ we take into account the result of the experiment in which @xmath1 successes were observed in @xmath2 trials , we get ( see e.g. @xcite ) : @xmath47 some examples of which are shown in fig .  [",
    "fig : beta_up ] .    expected value , mode ( the value of @xmath0 for which @xmath48 has the maximum ) and variance of this distribution are : @xmath49 eq .",
    "( [ eq : infbinom1 ] ) is known as `` recursive laplace formula '' , or `` laplace s rule of succession '' .",
    "not that there is no magic if the formula gives a sensible result even for the extreme cases @xmath17 and @xmath18 for all values of @xmath2 ( even if @xmath50 ! ) .",
    "it is just a consequence of the prior : in absence of new information , we get out what we put in !    from fig .",
    "[ fig : beta_up ] we can see that for large numbers ( and with @xmath1 far from 0 and from @xmath2 ) @xmath48 tends to a gaussian .",
    "this is just the reflex of the limit to gaussian of the binomial . in this",
    "large numbers limit @xmath51 and @xmath52",
    ".      one might worry about the role of the prior .",
    "indeed , in some special cases of importance _ frontier type _",
    "measurement one _ has _ to .",
    "however , in most _ routine _ cases , the prior just plays the role of a _ logical tool to allow probability inversion _ , but it is in fact absorbed in the normalization constant .",
    "( see extensive discussions in ref .",
    "@xcite and references therein . )    in order to see the effect of the prior , let us model it in a easy and powerful way using a _ beta _ distribution , a very flexible tool to describe many situations of prior knowledge about a variable defined in the interval between 0 and 1 ( see fig .",
    "[ fig : betas ] ) .    [ cols=\"^,^ \" , ]     these distributions quantify how much we believe that @xmath43 out of the observed @xmath2 belong to the signal .",
    "[ by the way , the number @xmath53 of background objects present in the data can be inferred as complement to @xmath43 , since the two numbers are linearly dependent .",
    "it follows that @xmath54 . ]",
    "a different question is to infer the the poisson @xmath44 of the signal .",
    "using once more bayes theorem we get , under the hypothesis of @xmath43 signal objects : @xmath55 assuming a uniform prior for @xmath44 we get ( see e.g. ref .",
    "@xcite ) : @xmath56 with expected value and variance both equal to @xmath57 and mode equal to @xmath43 ( the expected value is shifted on the right side of the mode because the distribution is skewed to the right ) . figure [ fig : inv_pois_0_12 ] shows these pdf s , for @xmath43 ranging from 0 to 12 and assuming a uniform prior for @xmath44 .    as far the pdf of @xmath44 that depends on all possible values of @xmath43 ,",
    "each with is probability , is concerned , we get from probability theory [ and remembering that , indeed , @xmath58 is equal to @xmath59 , because @xmath43 depends only on @xmath44 , and then the other way around ] : @xmath60 i.e. the pdf of @xmath44 is the weighted average can be easily obtained from the conditional expected values and variances : @xmath61\\,f(n_s)\\ , .",
    "\\nonumber\\end{aligned}\\ ] ] ] of the several @xmath43 depending pdf s .",
    "the results for the example we are considering in this section are given in the plots of fig .",
    "[ fig : bin_back_inf_ns ] .",
    "the classical inverse problem related to the binomial distribution has been reviewed and extended to the presence of background either only on the number of ` successes ' , or on the trials themselves .",
    "the probabilistic approach followed here allows to treat the problems only using probability rules .",
    "the results are always in qualitative agreement with intuition , are consistent with observations and prior knowledge and , never lead to absurdities , like @xmath0 outside the range 0 and 1 .    the role of the priors , that are crucial to allow the probabilistic inversion and very useful to balance in the proper way prior knowledge and evidence from new observations , has been also emphasized , showing when they can be neglected and when they are so critical that it is preferable not to provide probabilistic conclusions .",
    "p. astone and g. dagostini , `` _ inferring the intensity of the poisson processes at the limit of the detector sensitivity ( with a case study on gravitational wave burst search _ '' , cern - ep/99 - 126 , august 1999 ( hep - ex/9909047 ) ."
  ],
  "abstract_text": [
    "<S> the problem of inferring the binomial parameter @xmath0 from @xmath1 _ successes _ obtained in @xmath2 _ trials _ is reviewed and extended to take into account the presence of background , that can affect the data in two ways : _ a _ ) fake successes are due to a background modeled as a poisson process of known intensity ; _ b _ ) fake trials are due to a background modeled as a poisson process of known intensity , each trial being characterized by a known success probability @xmath3 . </S>"
  ]
}