{
  "article_text": [
    "the complex behavior of models with rough energy landscapes ( such as spin glasses , biopolymers , etc . ) is an important but challenging problem . in many situations progress",
    "is possible only using computer simulations , but this too is a notoriously difficult problem . in order to efficiently sample the equilibrium distribution of such models",
    "it is necessary to overcome the barriers separating different metastable minima , a process which can be very slow if the temperature is low .",
    "a particularly fruitful strategy to enhance the sampling is to enlarge the configuration space to include some well - chosen parameter(s ) in the model . in simulated",
    "tempering  @xcite , e.g. , the temperature is promoted to a dynamical variable , whereby the system heats up and cools down randomly and gets a good chance to explore the energy landscape .",
    "such _ extended ensemble _ or _",
    "generalized ensemble _ methods have gained much attention recently and are routinely used in simulations of such diverse problems as spin glasses , biomolecules , and problems in statistics .",
    "the methods are also highly useful for free energy calculations and for the estimation of the probability of extreme events .",
    "an attractive feature is that they can easily be incorporated into existing simulation methods .",
    "the downside is , however , that in order to work properly they require fine tuning certain _ a priori _ unknown weights .",
    "the weights must be tuned to ensure that each parameter value ( e.g. temperature ) of the extended ensemble is visited equally often on average .",
    "they are simply related to the free energy at the given parameter value , and are therefore a highly useful byproduct of the simulation , _ if they can be estimated efficiently using some scheme_. while several such schemes have been constructed  @xcite there is a strong need for improvements . in this paper",
    "we propose one such scheme with a number of distinct advantages .",
    "section [ sec : intro ] gives a brief background on extended ensembles and discusses some shortcomings of existing methods .",
    "section [ sec : awh ] introduces an improved method , the accelerated weight histogram method . in sec .",
    "[ sec : bench ] the method is tested and benchmarked on two model problems , the two - dimensional ising model and a three - dimensional ising spin glass .",
    "we consider a model described by a probability distribution @xmath1 , which depends on one or more parameters @xmath2 .",
    "typically we want to study the model for a whole range of parameter values . in an extended ensemble simulation",
    ", states are sampled according to a joint distribution @xmath3 , which we express , without loss of generality , as @xmath4 where @xmath5 denotes the configuration of the system and we assume a discrete set of preselected parameter values @xmath6 .",
    "the weights @xmath7 introduced in eq .",
    "( [ eq : joint ] ) allow tuning the marginal distribution @xmath8 to approach any desired form .",
    "we assume that we have a way of generating samples from the conditional distribution @xmath9 at fixed parameter @xmath10 , using , e.g. , markov chain monte carlo ( mc ) or molecular dynamics ( md ) methods . generally this can be done without knowledge of the normalization constants @xmath11 . in physics applications eq .",
    "( [ eq : conditional ] ) is often the ordinary canonical distribution @xmath12 , where we absorbed the temperature into the energy in order to treat it on equal footing as any other parameter of the system .",
    "likewise , @xmath13 denotes the dimensionless free energy   and @xmath14 , with @xmath15 equal to the real free energy . ] . in bayesian statistics problems",
    "( [ eq : conditional ] ) is typically the _ a posteriori _",
    "distribution for the model parameters and possibly missing data given a set of observations .",
    "the ordinary ( mc or md ) moves are then complemented with transitions in parameter space , which in most cases consist of a nearest neighbor random walk . the weights @xmath7 need to be adjusted to make the marginal distribution @xmath16 of @xmath17 approximately flat  .",
    "we just note that a slight modification of our formalism allows for any prescribed target distribution @xmath18 ( or even simpler let the density of parameter values be nonuniform ) . ] .",
    "this requires @xmath19 where @xmath13 is the exact ( dimensionless ) free energy at @xmath10 , unknown at the beginning of the simulation .",
    "quite generally existing methods to estimate the weights @xmath7 can be divided into two different classes , _ iterative _ and _ dynamic_. in an iterative method the weights are produced in a sequence of preliminary runs , each run giving a better estimate than the old , until sufficient accuracy is reached .",
    "on the other hand , in a dynamic scheme the weights are being continuously updated during a long simulation .",
    "the dynamic schemes have potential for faster convergence , but since the weights are constantly changing , detailed balance is violated and the samples collected can not therefore be safely used to estimate average values of interest . in the iterative scheme",
    "the weights are fixed during each run , and only updated between the runs .",
    "one particularly elegant dynamic scheme is the wang - landau method  @xcite , originally developed for simulations in the closely related multicanonical ensemble  @xcite . in this ensemble the state space",
    "is not extended , but instead one replaces the boltzmann weights of the ordinary canonical ensemble with a different one aimed at producing a flat histogram of some quantity @xmath20 , usually the energy . from an algorithmic point of view the main difference is that the elementary moves @xmath21 also change the value of @xmath20 , e.g. , the energy , whereas in the extended ensemble method they can be performed at constant @xmath2 .",
    "the latter allows for more flexibility when choosing the parameter moves , something we exploit below .",
    "the wang - landau method is straightforward to adapt to extended ensemble simulations ( as demonstrated in ref .  ) .",
    "each time the system visits a particular parameter @xmath17 , the corresponding free energy parameter @xmath22 is decreased by a certain amount , @xmath23 .",
    "a histogram of visited parameter values is collected and @xmath24 is reduced by a factor , @xmath25 , when the histogram meets a certain flatness criteria . then the histogram is reset and the process starts over with the reduced modification constant .",
    "the scheme where @xmath24 is halved each iteration anticipates an exponential convergence of @xmath22 to its true value @xmath13 .",
    "unfortunately , this is not the case .",
    "instead , the error saturates at a level where reasonably flat histograms are produced , but the free energy estimate no longer improves since @xmath24 becomes too small  @xcite .",
    "it has been realized  @xcite that the modification factor should rather be decreased at a slow steady rate @xmath26 , where @xmath27 is the monte carlo time , without regard to any histograms , at least during the later stages of a simulation .",
    "the resulting @xmath0 method turns out to perform very well , both in multicanonical and extended ensemble simulations .",
    "nevertheless , there is still plenty of room for improvements .",
    "what is , for example , the most efficient way to move around in parameter space ? how can the data collected during the simulations be used most effectively to produce an estimate of the free energy needed for uniform sampling ? how should the estimates from different iterations , perhaps run in parallel , be combined in an optimal way ?",
    "how should the set of parameters @xmath28 be chosen ?",
    "most often the parameter moves form a nearest neighbor random walk , and then the choice of the spacing between adjacent values may be a critical issue .",
    "having too large gaps between adjacent values may lead to small acceptance rates and therefore very slow dynamics along the parameter axis . having too densely spaced parameter values , on the other hand ,",
    "can make the dynamics of the random walk itself a limiting factor , again slowing down the dynamics .",
    "in this paper we propose an iterative scheme  the accelerated weight histogram method ( awh )  which combines several different complementary techniques to give a very efficient method which addresses the issues mentioned above .",
    "first of all , we allow large parameter steps by the use of a gibbs sampler ( a.k.a .",
    "heat bath algorithm ) .",
    "this is combined with a reweighting procedure which makes optimal use of the information collected during the moves . together",
    "these make it possible to choose a rather densely spaced set of parameters , without being limited by slow diffusion .",
    "the free energy parameters are updated based on a histogram of _ weights _ ( rather than a histogram of visited parameter values ) combined with the information collected during previous iterations .",
    "the parameter moves are carried out as follows . in the simplest case",
    "we allow transitions @xmath29 to _ any _ new parameter value @xmath30 , with a probability given simply by the conditional probability of @xmath31 given the current configuration @xmath32 @xmath33 the transition probabilities just calculated are accumulated in a histogram of weights @xmath34 further , they can be used for on - the - fly reweighting of sampled observables @xmath35 where @xmath36 denote the time series of visited configurations .",
    "the averages @xmath37 at a particular value @xmath38 thus get contributions from a whole range of parameter values .",
    "note that the validity of eq .",
    "( [ eq : reweight ] ) does not depend on the @xmath22 being converged .",
    "this reweighting scheme is akin to the optimal multihistogram reweighting technique of ferrenberg and swendsen  @xcite ( but with no need to solve a nonlinear equation system ) .",
    "the update procedure continues in an iterative way . during each iteration a certain number ,",
    "say @xmath39 , of samples are collected and then the free energy parameters are updated as @xmath40 , with @xmath41 where @xmath42 is the total number of samples collected so far .",
    "the weight histogram is then updated to reflect this change @xmath43 i.e. , the total weight collected is distributed evenly among the @xmath44 parameter values , and the next iteration starts .",
    "note that the identity @xmath45 holds before and after the update .",
    "the histogram is thus _ not _ reset to zero after the iteration but continues to grow .",
    "this makes the updates eq .",
    "( [ eq : df ] ) become smaller and smaller and allows for finer and finer details of the free energy to be resolved .    equations to form the core of the algorithm , which can be summarized as follows :    1 .   [",
    "algo : start ] perform @xmath46 updates of the configurations @xmath32 at fixed parameter value @xmath10 .",
    "[ algo : move ] perform a parameter move @xmath29 using the gibbs sampler ,  eq .",
    "( [ eq : transition - prob ] ) .",
    "[ algo : end - of - loop ] update the weight histogram using eq .",
    "( [ eq : w ] ) and sample any observables of interest using eq .",
    "( [ eq : reweight ] ) .",
    "4 .   repeat steps [ algo : start]-[algo : end - of - loop ] until @xmath39 samples have been obtained .",
    "[ algo : end - of - iteration ] update the free energy parameters @xmath22 using  eq .",
    "( [ eq : df ] ) and the weight histogram using eq .",
    "( [ eq : update - wk ] ) . 6 .",
    "start a new iteration from step 1 unless the desired accuracy has been reached .",
    "one possible concern is that step [ algo : move ] of the algorithm requires the computation of @xmath47 different quantities , which can become time consuming if the set @xmath28 is large ( as can easily happen in the case of two- or higher - dimensional parameter spaces ) . in practice",
    ", @xmath48 will be exponentially small except for a range of @xmath31 close to @xmath17 .",
    "if this is the case one may limit the search for the new state to a neighborhood @xmath49 of @xmath17 by replacing step [ algo : move ] with    1 .   choose a subset of parameter values @xmath50 with probability @xmath51 .",
    "perform a parameter move @xmath52 using the gibbs sampler [ eq .",
    "( [ eq : transition - prob ] ) , but with the sum restricted to @xmath50 ] .    detailed balance is maintained if @xmath54 for all @xmath55 .",
    "a simple choice ( in the one - dimensional case ) is to select a range of parameter values as an interval @xmath56 , where @xmath57 is a random uniformly distributed integer in @xmath58 $ ] and @xmath59 is a predetermined range .",
    "the generalization to higher - dimensional parameter spaces is straightforward .",
    "clearly the update eq .",
    "( [ eq : df ] ) requires an initial guess for @xmath60 and a positive value of @xmath61 at the start of the simulation .",
    "this latter value can be seen as a bayesian prior of our initial guess of @xmath60 , which is later on updated as new data becomes available .",
    "if we have reason to believe that the starting estimate of the free energy is good ( e.g. , because the free energy is expected to have small variations ) , we can use a large @xmath62 . in many applications , however , our initial guess is going to be poor and we need some kind of bootstrap to get an acceptable prior .",
    "we propose the following heuristic scheme : carry out the same steps in the simulation as above , but in addition check , after each iteration has completed ( after step [ algo : end - of - iteration ] ) , whether all parameter values have been visited a certain fixed ( usually small @xmath63 110 ) number of times . if not , reset the number of samples @xmath64 , where @xmath65 is the number of parameters visited so far , and let @xmath66 . in this way",
    "the weight histogram does not start to accumulate data until @xmath67 whereby the free energy parameters will get relatively large updates at the initial stages .",
    "also one should avoid sampling observables during this initial stage .",
    "alternatively one may use free energy perturbation or a few wang - landau iterations to get a reasonable initial estimate of @xmath22 .",
    "after this , the simulation may proceed with an initial prior @xmath68 .",
    "it is further recommended to make each iteration quite short , consisting of only @xmath69 1001000 parameter moves , during this initial stage .",
    "( later on it may be increased . )",
    "it is also advisable to monitor the histogram @xmath70 of visited parameter values , although it is not used directly to update the free energy .",
    "the robustness of the algorithm can then be increased by restarting the simulation if the histogram gets too skewed , e.g. , if the minimum value @xmath71 is less than a certain fraction of the mean .",
    "this could be an indication that initial nonequilibrium transients have distorted the distribution of the collected samples , which would violate the main assumption of the algorithm , namely that the samples collected during each iteration follow eq .",
    "( [ eq : marginal ] ) .",
    "if this happens one should reset the weight histogram and the effective number of samples ( e.g. , @xmath72 , @xmath73 or perhaps even @xmath74 , @xmath75 ) , to allow the simulation to recover from that situation .",
    "often it is advantageous to run simulations in parallel to make efficient use of computational resources .",
    "the scheme introduced above can easily be adapted to such situations .",
    "each computing node @xmath76 runs an independent simulation ( consisting of @xmath77 samples ) leading to an estimate @xmath78 of the free energy parameters .",
    "these may then be combined into a best estimate @xmath79 @xmath80 where @xmath81 and @xmath82 is an unimportant normalization constant .",
    "this equation is easily solved by iterating @xmath83 starting from one of the @xmath78 ( and this usually converges within 25 iterations ) .",
    "this way of organizing the simulation also has the advantage that statistical errors can be estimated using the standard jackknife method  @xcite applied to eq .",
    "( [ eq : combine ] ) .",
    "many variations of the basic algorithm are possible , and may be related to other methods .",
    "for example , it reduces to the @xmath0 method in the limit obtained by the following modifications : ( 1 ) replace the gibbs sampler by a simple nearest neighbor metropolis step . ( 2 ) replace the weight histogram @xmath84 by a simple histogram @xmath70 of visited @xmath17 . ( 3 ) update the free energy parameters after _ every _ step . since the histogram after a visit to @xmath17 is @xmath85 , the free energy update becomes @xmath86 , where the approximation holds when @xmath87 .",
    "the last term represents a constant shift of all @xmath60 and can be dropped .",
    "the resulting update rule is thus simply @xmath88 , leaving all other @xmath60 unmodified .",
    "this corresponds exactly to the @xmath0 method  @xcite discussed earlier , and provides a new perspective on and additional justification for that update scheme .",
    "to study the performance of the method and compare it with other ones we apply it to the ising model and a spin glass .",
    "we carry out a simulated tempering simulation , i.e. , we choose as parameter @xmath2 the temperature .",
    "the algorithm alternates between ordinary canonical metropolis mc updates in which randomly chosen spins are flipped with probability @xmath89 , and updates which change the temperature , leaving the spin configuration and the energy @xmath90 unchanged . in the latter ones a new temperature @xmath91",
    "is chosen with the probability @xmath92      the two - dimensional ( 2d ) ising model is a common test case , since its free energy can be calculated exactly  @xcite .",
    "we choose @xmath93 temperatures evenly spaced in the interval @xmath94 $ ] , which includes the critical temperature @xmath95 .",
    "the system size is @xmath96 and we use 100 000 iterations , each lasting for @xmath97 mc sweeps , in total @xmath98 sweeps , where each mc sweep corresponds to one update trial per spin .",
    "a temperature move is attempted after each mc sweep .    during the initial stages we use the scheme discussed in sec .",
    "[ sec : bootstrap ] to get an initial guess for the @xmath22 and a prior weight @xmath62 : at the start of the simulation we set @xmath99 , where @xmath100 is the ground state energy , and @xmath101 .",
    "then we check , after each iteration , whether all @xmath44 temperatures have been visited at least twice during the simulation so far . if not , the effective number of samples is reset to @xmath102 , where @xmath65 is the number of temperatures which actually were visited twice .",
    "when all temperatures have been visited we have a reasonable initial guess of @xmath22 , and may continue the simulation as described in sec .",
    "[ sec : awh ] , with @xmath103 .",
    "furthermore , we also monitor the histogram of visited temperatures to look for anomalous deviations , which would indicate that the initial guess was not so good after all .",
    "thus , we restart the simulation ( i.e. , we set @xmath104 , @xmath105 and reset the calculations of any observables , but do not touch the @xmath60 ) should the histogram of visited temperatures @xmath70 at some point fall below @xmath106 of its mean .",
    "this happened in about half of the simulation runs , typically within the first 50 iterations .    to benchmark the method we plot , in fig .",
    "[ fig : ising](a ) , the mean absolute deviation @xmath107 of consecutive free energy differences against the number of samples . here @xmath14 is the exact dimensionless free energy . for comparison",
    "we also include results from simulations using wang - landau iterations ( with flatness criteria @xmath108 ) and the @xmath0 method . for large times , the error for both the @xmath0 and our method decrease as @xmath109 , whereas it saturates for the wang - landau method . for a given number of samples ,",
    "the accuracy of the awh method is almost one order of magnitude better than the @xmath0 method .",
    "the inset shows the difference between the final estimate , obtained by combining 40 independent simulations using  eq .",
    "( [ eq : combine ] ) , and the true free energy over the temperature range .",
    "the error bars are estimated using the jackknife method .",
    "another useful measure of the efficiency is the tunneling time , i.e. , the time to go from the highest temperature to the lowest or _",
    "vice versa_. this time was significantly reduced , nearly by a factor of two , from @xmath63 40 000",
    "mc sweeps for the @xmath0 to @xmath63 21 000 for the awh method .",
    "it should be noted that the dynamics suffer severely from critical slowing down in the vicinity of the phase transition , which constitutes a bottleneck for the movement along the temperature axis . while the extended temperature ensemble methods are effective for crossing energy barriers , they do not overcome this slowing down by themselves . in this sense",
    "the 2d ising model ( using single spin flip dynamics ) is not a particularly favorable test case .",
    "however , the methods can easily be combined with cluster methods , if available , which do overcome the critical slowing down . replacing the single spin flip moves by , e.g. ,",
    "wolff cluster updates  @xcite for @xmath110 ( the cluster moves being most effective in the critical region ) in the example above practically eliminates the bottleneck and further reduces the tunneling time by an additional factor @xmath111 to about 2200 , for the awh method .",
    "the @xmath0 method on the other hand only gained a factor of two .    as discussed in sec .",
    "[ sec : awh ] one of the advantages of the awh method is the insensitivity to the spacing of parameter values @xmath10 . indeed , varying the number of temperatures from @xmath112 up to @xmath113 , had negligible effect on the performance of the algorithm , both in terms of the accuracy of the final free energy estimate and the tunneling time , while the increase in the run time of the simulation was marginal ( and could be practically eliminated using the update rule 2 ) . upon decreasing @xmath44 below 16 , on the other hand",
    ", the performance quickly dropped .",
    "next we apply the method to the three - dimensional ising spin glass with gaussian couplings .",
    "this model has a disorder - dominated glass phase at low temperatures @xmath114  @xcite , with a very rough energy landscape , making it extremely challenging to study using conventional simulations .",
    "the system size is @xmath115 , and we use @xmath116 temperatures logarithmically spaced in @xmath117 $ ] .",
    "figure [ fig : ising](b ) compares the convergence of the different methods for one particular random realization of the couplings . as there is no exact solution to compare with we use as reference instead",
    "the best estimate obtained from 80 different runs ( with an estimated standard error @xmath118 ) . here , the gain in accuracy , compared to the @xmath0 method , is more than an order of magnitude .",
    "the tunneling time , i.e. , the time to go between the high- and low - temperature extremes , is also significantly shorter , by nearly a factor of @xmath119 .",
    "let us reiterate the advantages of the awh method : allowing for large steps gives a fast diffusion along the parameter axis . as a result , the spacing between neighboring values in the discretized parameter space is not critical as long as it is small enough and does not require any fine tuning to perform well .",
    "we make efficient use of the data collected at all stages of the simulation .",
    "this is done by reweighting on the fly the samples taken at the current parameter value to a whole range of different parameter values .",
    "the information needed for this reweighting procedure is essentially the same as what enables the large steps .",
    "the data taken at earlier iterations are not thrown away , but are instead used together with the new data to refine the estimate of the free energy parameters . since the weights are constant during each iteration , the data collected will , after an initial relaxation , be in equilibrium and can be used for the calculation of any desired averages .",
    "altogether , these properties make up a very convenient method for sampling models with rough energy landscapes , and for the calculation of free energy differences .",
    "it should be emphasized that it is the _ combination _ of the gibbs sampler , the reweighting scheme , and the update rule using the weight histogram , which leads to the dramatic improvements .",
    "the method is very general , is simple to implement , and can be applied to a broad range of problems in statistical physics , biophysics , statistics , etc .",
    "further improvements are likely , especially when it comes to the heuristic scheme used during the early - stage bootstrap .",
    "15ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ]  + 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty link:\\doibase 10.1209/0295 - 5075/19/6/002 [ * * ,   ( ) ] link:\\doibase 10.1063/1.462133 [ * * ,   ( ) ] http://link.aps.org/doi/10.1103/physrevlett.86.2050 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevlett.68.9 [ * * , ( ) ] link:\\doibase 10.1103/physreve.76.036708 [ * * ,   ( ) ] link:\\doibase 10.1103/physreve.75.046701 [ * * ,   ( ) ] link:\\doibase 10.1063/1.2803061 [ * * ,   ( ) ] link:\\doibase 10.1103/physreve.78.046705 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevlett.63.1195 [ * * ,   ( ) ] @noop _ _  ( ,  ,  ) link:\\doibase 10.1103/physrev.185.832 [ * * , ( ) ] link:\\doibase 10.1103/physrevlett.62.361 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevb.73.224432 [ * * , ( ) ]"
  ],
  "abstract_text": [
    "<S> we propose a method for efficient simulations in extended ensembles , useful , e.g. , for the study of problems with complex energy landscapes and for free energy calculations . </S>",
    "<S> the main difficulty in such simulations is the estimation of the _ a priori _ unknown weight parameters needed to produce flat histograms . </S>",
    "<S> the method combines several complementary techniques , namely , a gibbs sampler for the parameter moves , a reweighting procedure to optimize data use , and a bayesian update allowing for systematic refinement of the free energy estimate . in a certain limit </S>",
    "<S> the scheme reduces to the @xmath0 algorithm of b.e .  </S>",
    "<S> belardinelli and v.d .  </S>",
    "<S> pereyra [ phys .  </S>",
    "<S> rev .  </S>",
    "<S> e * 75 * , 046701 ( 2007 ) ] . </S>",
    "<S> the performance of the method is studied on the two - dimensional ising model , where comparison with the exact free energy is possible , and on an ising spin glass . </S>"
  ]
}