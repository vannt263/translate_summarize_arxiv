{
  "article_text": [
    "from remote sensing of environmental variables using satellite instruments to proximal sensing of soil properties using a ground - based gamma - radiometer , a vast number of spatial measurements are now being obtained every day .",
    "based on such very large , noisy , nongridded , and incomplete datasets , the goal is spatial prediction of a process of interest , together with rigorous quantification of prediction uncertainty .",
    "computational feasibility for such datasets has been addressed from several angles : approximations by gaussian markov random fields ( e.g. , * ? ? ?",
    "* ) , composite likelihoods ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) , covariance tapering , and low - rank models .",
    "we focus here on the latter two .",
    "covariance tapering @xcite relies on compactly supported correlation functions ( e.g. , * ? ? ?",
    "* ) to produce sparse covariance matrices containing only a moderate number of nonzero elements .",
    "use of efficient sparse - matrix algorithms then may result in computational feasibility for large datasets .",
    "however , by definition , covariance tapering is most appropriate for modeling processes with weak long - range dependence .",
    "a second approach to achieving computational feasibility for large spatial datasets is through low - rank models , which include a component that can be written as a linear combination of spatial basis functions , @xmath0 where @xmath1 , and the number of basis functions , @xmath2 , is much smaller than the number of observations , @xmath3 .",
    "many models that include such a component have been proposed ( for a recent overview , see * ? ? ?",
    "the models differ in the parameterizations and priors for the covariance matrix @xmath4 and the functions in @xmath5 . for discretized convolution models",
    "( i.e. , convolution models whose integrals are discretized ; see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) , @xmath5 contains the convolution kernels , and @xmath4 is often assumed to be a multiple of the identity .",
    "other authors view @xmath5 as a vector of fixed basis functions , such as empirical orthogonal functions ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ) , equatorial normal modes ( e.g. , * ? ? ?",
    "* ) , fourier basis functions ( e.g. , * ? ? ?",
    "* ) , w - wavelets ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) , or bisquare functions ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    ", we use the predictive - process approach @xcite , where both @xmath5 and @xmath4 are parameterized according to a `` parent process , '' for which a parametric covariance model is chosen .",
    "models with low - rank components allow for fast computation via the sherman - morrison - woodbury formula , as is made clear in @xcite and @xcite . for general @xmath4 ,",
    "they are also flexible , in that the covariance of , namely @xmath6 for locations @xmath7 and @xmath8 , is not of traditional parametric form .",
    "the fast computation and the flexibility make components of the form very well suited to modeling medium - range to long - range spatial dependence .",
    "however , due to the dimension reduction inherent in , a low - rank component alone is typically not able to model `` rough '' ( i.e. , non - smooth ) short - range dependence ( see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "some efforts have been made to address this problem ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) , including in the context of the predictive process ( @xcite , ch .  4 ; @xcite ) . here",
    ", we follow the approach of @xcite , who divide a parent process into a predictive - process component and a remainder component .",
    "the covariance matrix of the remainder component is then made sparse by multiplication of its covariance function with a compactly supported tapering function .",
    "this approach allows for computationally feasible inference , even for large datasets .",
    "the contributions of this article are two extensions of the approach by @xcite , which allow for more flexibility and nonstationarity .",
    "first , we specify a nonstationary matrn model @xcite for the parent covariance , in which the parameters vary smoothly across space as linear combinations of spatial basis functions .",
    "the second extension is that we allow the set of basis - function locations ( henceforth referred to as `` knots '' ) in our low - rank component to be a random point process .",
    "this allows us to avoid choosing an arbitrary and fixed set of knots a priori . here , @xmath5 , @xmath9 , and @xmath4 in",
    "are all treated as unknown and random .",
    "this bayesian source separation task ( see , e.g. , * ? ? ? * ) , where both the `` source signal '' @xmath9 and the `` mixing coefficients '' @xmath5 have to be estimated , can be achieved by putting a prior on both components .",
    "this has been done in the context of discretized - convolution models by @xcite , who infer ( spatially varying ) parameters determining the shapes of their kernels .",
    "@xcite also consider a model of the form where both @xmath5 and @xmath9 are random , but as each basis function is itself a gaussian process , their approach is infeasible for large spatial datasets .",
    "recently , @xcite also proposed a predictive - process model where the locations ( but not the number ) of the basis functions are assumed random . in this article , we implicitely make inference on the number , locations , and shapes of the basis functions . our approach is a special case of that in ( * ? ? ?",
    "* ch .  4 ) and",
    "is inspired by @xcite , who propose a piecewise linear spline regression model for which both the number and the locations of the splines are random .",
    "a third contribution of this article is partially philosophical in nature : we do not consider the parent process to be the truth that is to be approximated , but rather as a way of obtaining a prior for the two spatially dependent components in our model .",
    "the resulting process is more flexible than the parent process , and hence it is often preferable for modeling nonstationary real - world processes .",
    "posterior inference for our model is described in detail .",
    "it is fairly involved but computationally feasible , even for very large datasets .",
    "a reversible - jump markov chain monte carlo algorithm @xcite allows us to infer the number of basis functions .",
    "we take advantage of sparse - matrix operations to ensure fast computation , and we employ marginalization strategies ( e.g. , * ? ? ?",
    "* ) to achieve satisfactory mixing of the markov chain .",
    "this article is organized as follows : in section [ methodology ] , we introduce our nonstationary spatial model based on the model of @xcite . section [ posteriorinference ] deals with posterior inference on the unknown quantities in the model . in section [ compsec ] , we assess the effect of our extensions to the approach of @xcite , using simulated data and a real - world dataset of soil measurements .",
    "conclusions are given in section [ conclusions ] .",
    "let @xmath10 , or @xmath11 , denote the process of interest on a spatial domain @xmath12 , @xmath13 .",
    "suppose that at @xmath3 locations we have observations on @xmath11 , namely @xmath14 , where @xmath3 is very large , and we assume additive measurement error : @xmath15 where @xmath16 is gaussian white noise and independent of @xmath11 . for simplicity and to ensure identifiability , throughout this article we will assume that @xmath17 is fixed and known .",
    "in practice , if @xmath17 is not known ( e.g. , from instrument experiments ) , it can be estimated from the data by extrapolating the variogram to the origin as described in @xcite .    in spatial statistics ,",
    "the process model is often given by , @xmath18 where @xmath19 is the large - scale trend , @xmath20 has an ( improper ) flat prior on @xmath21 , and @xmath22 is a spatially correlated component , which is typically modeled as a gaussian process , @xmath23 with mean zero and covariance function @xmath24 where @xmath25 and the correlation function @xmath26",
    "$ ] are parameterized by @xmath27 .      while the standard spatial model described in section [ standardmodel ] has been used extensively and successfully ( see , e.g. , * ? ? ?",
    "* ) , it is computationally infeasible if @xmath3 is very large ( more than 10,000 or so ) and @xmath28 is a standard covariance function ( e.g. , the exponential covariance function ) .",
    "this is because it takes on the order of @xmath29 computations to evaluate the likelihood .",
    "many approximations or modeling approaches have been proposed to solve this problem ( see section [ introduction ] ) .",
    "we will focus here on the predictive process @xcite .",
    "given a so - called `` parent process '' @xmath22 as in , the predictive process is defined as , @xmath30 , where @xmath31 is a set of knots .",
    "conditional on @xmath27 and @xmath32 , the predictive process can be written as a linear combination of basis functions , namely as @xmath33 with @xmath34 , where now @xmath35 @xmath36 .",
    "thus , we have @xmath37 , where @xmath38 , @xmath39 .    in",
    "what follows , we do not choose a fixed set of knots @xmath32 in .",
    "instead we model @xmath32 as a random point process .",
    "as discussed later at the end of section [ mcmcoverview ] , it is not necessary to strongly penalize large numbers of basis functions , @xmath2 , through the prior on @xmath32 .",
    "thus , we assume a flat , noninformative , improper prior for @xmath32 with density proportional to 1 .",
    "it was pointed out by @xcite that the predictive process can only account for smooth dependence .",
    "hence , as in @xcite , we write : @xmath40 then @xmath41 is independent of @xmath42 , and @xmath43 , where @xmath44 is a valid covariance function . to achieve computational feasibility for large @xmath3",
    ", @xcite proposed to replace @xmath45 in by @xmath46 , where @xmath47 is a tapered version of @xmath48 . in",
    ", @xmath49 is a compactly supported correlation function ( see , e.g. , * ? ? ?",
    "* ) that is equal to zero when its argument is greater than one .",
    "multiplication of @xmath48 with @xmath50 achieves that @xmath51 if @xmath52 , resulting in a covariance matrix that is sparse and quickly invertible ( see section [ computationsec ] below )",
    ". we will assume the tapering length @xmath53 to be fixed and chosen to ensure computational feasibility .    in summary ,",
    "our data model is given by , and our process model is given by @xmath54 where @xmath42 describes the medium - range to long - range spatial dependence , and @xmath55 accounts for local ( or short - range ) dependence .",
    "both @xmath42 and @xmath55 are zero - mean gaussian processes , whose covariance functions depend on a random set of knots , @xmath32 , with a flat prior distribution , and on a parent covariance function , @xmath28 , parameterized by @xmath27 and specified further in section [ covariancesec ] below",
    ".      let @xmath56 denote the matrn correlation function @xcite , @xmath57 and @xmath58 , where @xmath59 is the modified bessel function of the second kind of order @xmath60 .",
    "also , let @xmath61 be a spatially varying ( sv ) mahalanobis - like distance , where @xmath62 is a @xmath63 positive - definite matrix describing ( local ) geometric anisotropy at location @xmath64 .",
    "we write , @xmath65 , where @xmath66 , @xmath67 are sv scale parameters , and @xmath68 is a rotation matrix parameterized by sv rotation angles @xmath69 , \\ ,",
    "j=1,\\ldots , d-1\\}$ ] .",
    "a valid nonstationary matrn correlation function @xcite is given by , @xmath70 where @xmath71 .",
    "choosing @xmath72 in results in the parent covariance @xmath73 this nonstationary matrn class is very flexible , in that it allows for sv standard deviation @xmath74 , sv smoothness parameter @xmath75 , and sv geometric anisotropy through sv scale parameters @xmath76 and sv rotation angles @xmath77 .",
    "to ensure computational feasibility , we let the parameters vary spatially according linear combinations of spatial basis functions .",
    "we assume that all sv parameters are determined by the ( random ) parameter vector , @xmath78 , through models of the form , @xmath79 where @xmath80 is a generic notation for one of the sv parameters , @xmath81 , @xmath82 , and @xmath83 is an @xmath84-dimensional vector of _ fixed _ basis functions ( same for all parameters ) , each normalized to @xmath85 $ ] .",
    "the functions @xmath86 are transformations from @xmath87 to the range of @xmath80 .",
    ".[covparamtransformations]details for the sv covariance parameters of the form [ cols=\"<,<,<,<,<,<\",options=\"header \" , ]     npc = nonstationary parent covariance ; spc = stationary parent covariance ; asd = average squared distance ; is = interval score ; time = total time for the mcmc ; mbd = missing - by - design ( test region )    the results are shown in table [ soilresults_table ] .",
    "random knots resulted in lower average squared distance and interval score than fixed knots . with the exception of",
    "average squared distance for the models with 144 fixed knots , npc also improved over spc .",
    "more knots resulted in less accurate predictive distributions .",
    "based on examination of trace plots , mixing was somewhat slower for random knots than for fixed knots and slower for npc than for spc ( both for the soil data here and for the simulated data in section [ simstudy ] ) . because the same number of mcmc iterations was used for all models , the computation times given in tables [ sim_results_sinefun][soilresults_table ]",
    "can be slightly misleading .",
    "however , since the focus in this article is not parameter estimation but on prediction , and predictive performance of the models was also assessed based on an equal number of mcmc iterations , we feel that the comparison is fair .",
    "in this article , our starting point was the @xcite approach to analyzing large spatial datasets , which combines a low - rank predictive - process component with a tapered remainder component . to achieve enough flexibility for the nonstationary processes often encountered in real - world applications",
    ", we extended this model in two ways : first , the components in the model are parameterized based on a nonstationary matrn parent covariance function , in which the parameters vary spatially according to linear combinations of spatial basis functions .",
    "second , for the low - rank component , which can be written as a linear combination of spatial basis functions , we make inference on the number , locations , and shapes of the basis functions .",
    "posterior inference via reversible jump mcmc and related issues are described in detail .",
    "the results of a simulation study ( section [ simstudy ] ) and an analysis of a very large soil dataset ( section [ application ] ) indicate that the two extensions described above can result in improved predictive distributions , especially in terms of quantifying prediction uncertainty .",
    "we show that for ( typically nonstationary ) real - world processes , it should often _ not _ be the goal to approximate a simple covariance model ( e.g. , the stationary matrn covariance ) as closely as possible . results indicate that our model is sufficiently flexible to overcome a misspecified parent covariance , and its flexibility does not seem to result in a penalty in the unlikely event that the truth is , in fact , a simple stationary covariance ( see simulation study 3 in section [ simstudy ] ) . due to its adaptability ,",
    "our model can be used to model highly nonstationary processes with varying levels of smoothness .",
    "this research was supported by nasa under grant nnh08zda001n issued through the advanced information systems technology roses 2008 solicitation , and by the mathematics center heidelberg .",
    "i would like to thank huiyan sang , emily kang , the editor , associate editor , two anonymous referees , and especially noel cressie for helpful advice and comments .",
    "i am also grateful to james taylor and alex mcbratney of the university of sydney for making the nowley soil dataset available .",
    "the collection of the data was directed by professor mcbratney and funded by the university of sydney .",
    "cressie , n. and johannesson , g. ( 2006 ) . .",
    "in _ mastering the data explosion in the earth and environmental sciences : proceedings of the australian academy of science elizabeth and frederick white conference _ , canberra , australia .",
    "australian academy of science .",
    "pracilio , g. , smettem , k. , and harper , r. ( 2004 ) . .",
    "in ridley , a. , feikama , p. , bennet , s. , rogers , m .- j . , wilkinson , r. , and hirth , j. , editors , _ salinity solutions , working with science and society _ , bendigo , victoria , austalia .",
    "proceedings of the salinity solutions conference .",
    "sun , y. , li , b. , and genton , m.  g. ( 2011 ) . .",
    "in montero , j. , porcu , e. , and schlather , m. , editors , _ space - time processes and challenges related to environmental problems : proceedings of the spring school `` advances and challenges in space - time modelling of natural events''_. springer ."
  ],
  "abstract_text": [
    "<S> with the proliferation of modern high - resolution measuring instruments mounted on satellites , planes , ground - based vehicles and monitoring stations , a need has arisen for statistical methods suitable for the analysis of large spatial datasets observed on large spatial domains . </S>",
    "<S> statistical analyses of such datasets provide two main challenges : first , traditional spatial - statistical techniques are often unable to handle large numbers of observations in a computationally feasible way . </S>",
    "<S> second , for large and heterogeneous spatial domains , it is often not appropriate to assume that a process of interest is stationary over the entire domain .    </S>",
    "<S> we address the first challenge by using a model combining a low - rank component , which allows for flexible modeling of medium - to - long - range dependence via a set of spatial basis functions , with a tapered remainder component , which allows for modeling of local dependence using a compactly supported covariance function . addressing the second challenge , </S>",
    "<S> we propose two extensions to this model that result in increased flexibility : first , the model is parameterized based on a nonstationary matrn covariance , where the parameters vary smoothly across space . </S>",
    "<S> second , in our fully bayesian model , all components and parameters are considered random , including the number , locations , and shapes of the basis functions used in the low - rank component .    using simulated data and a real - world dataset of high - resolution soil measurements , </S>",
    "<S> we show that both extensions can result in substantial improvements over the current state - of - the - art .    </S>",
    "<S> * keywords * : covariance tapering ; full - scale approximation ; low - rank models ; massive datasets ; model selection ; reversible - jump mcmc </S>"
  ]
}