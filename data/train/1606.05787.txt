{
  "article_text": [
    "today smart meters are increasingly used worldwide for their ability to provide fine - grained automated readings without visiting customer premises .",
    "smart meters collect energy consumption data at a regular time interval , usually every 15 minutes or hourly .",
    "an ict solution provides the platform for analyzing the collected meter readings , which has become an indispensable tool for utilities to run smart grids .",
    "smart meter data analytics can help utilities better understand customer consumption patterns , provision energy supply to the peak demand , detect energy theft , and provide personalized feedback to customers . moreover , the government can take decisions for the future grid development based on analytics results . for customers , smart meter data analytics can help them better understand their energy consumption , save energy , and reduce their bills .",
    "data analytics thus is seen so important in smart grid management that the global market has been growing rapidly in recent years , and the market is expected to reach over four billion dollars annually in 2020 @xcite .",
    "various algorithms have been proposed for analyzing smart meter data , mainly in the smart grid literature , including those for electricity consumption prediction , consumption profile extraction , clustering of similar customers , and personalized customer feedback on energy savings .",
    "nevertheless , smart meter analytics applications have been underdeveloped until recently when some database vendors started to offer smart meter analytics software , e.g. , sap and oracle / data raker . and",
    ", several startups are seen investing in this area , e.g. , c3energy.com and opower.com .",
    "furthermore , some utilities , such as california s pg&e4 , are now providing on - line portals where customers can view their electricity consumption and compare with their neighborhood s average .",
    "however , these systems and tools focus on simple aggregation and ways of visualizing consumption . the details of how they are implemented are not disclosed . a lot of work is still required to build practical and scalable analytics systems for handling smart meter data , characterized by big volume and high velocity .    in this paper",
    ", we propose a hybrid ict - solution for streamlining smart meter data analytics extended from our conference paper @xcite .",
    "this solution is built by compiling our recent scalable data processing framework , _ bigetl _",
    "@xcite , and our prototype system , _ smas _ @xcite .",
    "the proposed ict - solution aims at facilitating the whole process of smart meter data analytics , including data ingestion , data transformation , loading , analyzing , and visualization .",
    "utilities and customers can get near real - time information through these stages .",
    "the ict - solution has a hybrid system architecture , consisting of the building blocks spark and hive in the data processing layer , and postgresql with madlib @xcite in the analytics layer .",
    "the design considers the support for high - performance analytics queries , i.e. , through rdbms , and the support for big data analytics , i.e. , through spark and hive .",
    "we decouple data ingestion , processing , and analytics into three different layers to ease the use and further development .",
    "meter data go through the three layers from the sources to the visualization on a web portal .",
    "the processing layer is an open platform that can integrate various user - defined processing units , such as the modules of data transformation , data anonymization , and anomaly data detection .",
    "the analytics layer currently supports a variety of functionalities and analytics algorithms , including viewing time - series at different temporal aggregations ( e.g. , hourly , daily , or weekly ) , load disaggregation , consumption pattern discovery , segmentation , forecasting and customer feedback .",
    "it is also easy to extend the analytic layer by adding new algorithms .    in short , we make the following contributions in this paper : 1 ) we propose a hybrid ict - solution of making the advantages of different technologies for streamline meter data analytics process ; 2 ) we implement a data processing platform that can be easily extended by adding new processing units and algorithms ; 3 ) we implement an analytics platform that can support both supply- and demand - side analytics",
    ". it can help utilities manage energy and help customers save money ; and 4 ) we evaluate the technologies that constitute the proposed ict platform , and discuss which technology to be used and when .    the remaining part of this paper is structured as follows . section  [ sec : relatedwork ] summarizes the related work ; section  [ sec : solution ] details the proposed ict - solution ; section  [ sec : evaluate ] evaluates the technologies which constitute the ict - solution ; section  [ sec : conclusionandfuturework ] concludes the paper with the directions for future work .",
    "_ systems and platforms for smart meter data analytics . _ the traditional technologies , such as r ( s - plus ) , matlab , sas , spss and stata , can be used in smart meter data analytics to support numeric computing and comprehensive statistical analysis . in - memory , in - database , and parallelism are the recent trend of analytics technology development . according to our benchmarking @xcite , main - memory based systems , such as kdb+ @xcite and",
    "sap hana @xcite , and in - database machine learning toolkit , such as madlib @xcite , are good options for smart meter analytics .",
    "the two distinct distributed computing platforms , hive and spark ( built on top of hadoop ) , are suitable for big data analytics . in this paper",
    ", we implement the ict - system with the hybrid technologies , including hive , spark and postgresql / madlib , which enable us to analyze data in a database , in memory or in a cluster .",
    "the systems or prototypes for smart meter data analytics emerge in both industry and academia .",
    "the companies we mentioned in section  [ sec : introduction ] developed intellectual property products , but the implementations of the systems and analytics algorithms used are not open to the public . .",
    "nezhad et al .",
    "developed an open source smart meter dashboard in their research work , called _ smartd _",
    "@xcite , which is orthogonal to our work of the analytics layer .",
    "but , our system provides more comprehensive functionalities , and we provide a complete solution for smart meter data analytics , including data ingestion , transformation , analyzing and visualization .",
    "liu et al .",
    "use analytics procedures in hive to process smart grid data , and use an rdbms to cope with daily data - management transactions on the information of meter devices , users , organizations , etc . @xcite .",
    "this is somewhat similar to our architecture , but our main focus is to streamline the whole process and to cater for different user requirements by using hybrid technologies .",
    "furthermore , our platform is designed to be easily integrated with different data processing units and algorithms .",
    "besides , the work primarily studies how to efficiently retrieve smart meter data from hive , but it focuses on simple operational queries rather than in - depth analytics that we address in our system . beyond the electricity sector , smart meter analytics systems and applications",
    "are also developed in the water sector , e.g. , _ wbkms _",
    "@xcite , a web - based application for providing real - time information of water consumption ; and _ autoflow _",
    "@xcite , a tool for categorizing residential water consumption .",
    "water data analytics is one of our planned features .",
    "the two existing works provide a good reference for us to design and develop the architecture and algorithms in the future .    _ benchmarking smart meter data analytics .",
    "_ arlitt et al .",
    "implement the toolkit , _ iotabench _",
    ", for benchmarking the analytics algorithms of internet of thing ( iot ) @xcite .",
    "they evaluate six analytics algorithms on an hp vertica cluster platform using synthetic electricity data .",
    "keogh et al .",
    "discuss benchmarking time - series data mining , and evaluate different implementations of time series similarity search , clustering , classification and segmentation @xcite .",
    "anil benchmarks data mining operations for power system analysis @xcite , which analyzes voltage measurements from power transmission lines .",
    "these works , however , only focus on benchmarking the analytics algorithms , but not the systems in the underlying .",
    "our previous work @xcite benchmarks four representative algorithms of smart meter data analytics , and five categorized technologies , matlab , kdb+ , postgresql / madlib , spark and hive .",
    "they represent the technologies of traditional ( matlab ) , in - memory ( kdb+ and spark ) , in - database ( postgresql / madlib ) , in - memory distributed ( spark ) and hadoop - based ( hive ) .",
    "the benchmarking results are the foundation for implementing this system , i.e. , provide the guideline for choosing the appropriate technology for an analytics requirement .",
    "_ smart meter data analytics algorithms . _ two broad categories of smart meter data analytics applications are widely studied , which are consumer- and producer - oriented .",
    "consumer - oriented applications aim to provide feedback to end - users on reducing energy consumption and saving money , e.g. , @xcite .",
    "producer - oriented applications are for utilities , system operators and governments , which provide information of consumers , such as their daily habits for the purposes of load forecasting and clustering / segmentation , e.g. , @xcite . from a technical standpoint , both of the above classes of applications perform two types of operations : extracting representative features , e.g. , @xcite , and finding similar consumers based on the extracted features , e.g. , @xcite .",
    "household electricity consumption can be broadly decomposed into the temperature - sensitive component , i.e. , the heating and cooling load , and the temperature - insensitive component ( other appliances ) .",
    "thus , the representative features include those which measure the effect of outdoor temperature on consumption @xcite and those which identify consumers daily habits regardless of temperature @xcite , as well as those which measure the overall variability , e.g. , consumption histograms @xcite .",
    "some of the above existing algorithms have been integrated into our system , as well as new algorithms implemented by us , which are used to study the variability of consumption , load profiling , load segmentation , pattern discovery , load disaggregation , and load similarity .    [",
    "[ sec : solution ] ]      figure  [ fig : systemarchitecture ] shows the system architecture of the proposed ict - solution . the system is implemented by integrating our two sub - systems , _ bigetl _ @xcite and _ smas _ @xcite , which will be described in the next two sections .",
    "the system consists of three layers including data ingestion , data processing , and data analytics , each of which represents a separate functional system for meeting the overall requirement of streamlining the whole process .",
    "the leftmost is the data ingestion layer extracting real - time data from smart meters directly , or bulk data from a staging area .",
    "this layer connects data sources to the subsequent processing layer using data extraction programs .",
    "the middle layer is responsible for pre - processing data , such as transformation and cleansing .",
    "this is done through the so - called _ workflow _ , which is composed of several chained processing units , _",
    "worklets_. a worklet is run in a different processing system in the underlying ( we will detail it shortly ) .",
    "a workflow is scheduled to run once or repeatedly at a specified time interval , such as minutely , hourly , daily , weekly or monthly .",
    "this layer can also manage multiple workflows running simultaneously .",
    "the worklets in a workflow are executed in a sequential order , each of which is responsible for a particular task .",
    "for example , a batch processing workflow may consist of a worklet for extracting data from a source system and writing to staging area ; a worklet for cleansing the data and writing the cleansed data into the data warehouse ; a worklet for housekeeping the staging area ; and a worklet for sending messages when the workflow job is end .",
    "the rightmost is the analytics layer , which is a web application composed of an application server ( tomcat ) , a visualization engine ( highcharts ) , various analytics algorithms ( implemented using the open source in - database analytics library , madlib @xcite ) , and a data warehouse ( postgresql ) .",
    "this layer has a web - based interface for users doing interactive analytics .",
    "the ict - solution uses _ bigetl _ in its data processing layer .",
    "bigetl is developed based our previous works @xcite for handling scalable and streaming data ( the source code is available at http://github.org/xiufengliu/bigetl ) .",
    "figure  [ fig : dataprocessinglayer ] shows the building blocks , including the interfaces for supporting various data sources , data processing systems ( incl .",
    "spark , hive , linux shell , java virtual machine , and python ) , a job scheduler , transformation and online analytics units .",
    "a processing unit is a program implemented for a specific purpose , such as data cleansing , data transformation , data anonymization , or streaming data mining ( e.g. , anomaly detection ) .",
    "the unit is scheduled to run on an underlying data processing system .",
    "bigetl provides the interface for integrating a data processing unit .",
    "it also supports reading data from various data sources and writing data into different data management systems , which is simply through implementing the corresponding reading and writing application programming interfaces .",
    "we use spark streaming @xcite ( a built - in component of spark ) to process data stream ( see figure  [ fig : realtimeprocessing ] ) , e.g. , the readings from smart meters .",
    "meter readings can be extracted periodically , e.g. , typically every 15 minutes or one hour .",
    "bigetl , however , can extract data from any sources as long as the corresponding data extractors are implemented .",
    "when the data are extracted and read into spark streaming , the data are created as discretized stream ( dstream ) , a continuous stream of data , received from a data source , or a processed data stream generated by transformation operators .",
    "a dstream is represented by a continuous series of resilient distributed data objects ( rdds ) in spark , which is an abstraction of an immutable distributed data set .",
    "therefore , dstreams are the fault - tolerant collections of objects partitioned across cluster nodes that can be acted on in parallel . a number of operations , called _ transformations _ , can be applied to a dstream , including map , filter , groupby , and reduce , etc .",
    ", as well as windowing operations with a user - specified size and slide interval . when the data have been processed , the cleaned and well - formatted data are temporarily kept in an in - memory table in spark , which is also an rdd object but given the names to its attributes to improve interoperability through sql .",
    "users can do ad - hoc queries by sql statements issued on a web - based user interface .",
    "the query results are shown in table or chart format on the web portal .",
    "through the interactive queries , users can check the results instantly , verify and improve their query statements . in the end",
    ", the in - memory data are persisted to the postgresql data warehouse for end - user interactive analytics .",
    "but , if an end user wants to view the freshest data in spark , they still can query from the analytics layer . in the underlying , the queries are sent to spark through a middleware , bigsql @xcite , which bridges postgresql and spark .",
    "bigetl supports hive as the batch processing system to deal with scalable data sets .",
    "hive is an open - source sql - based distributed data warehouse system built on top of hadoop mapreduce framework @xcite , which now is widely used in big data analytics .",
    "hive supports the sql - like script language , hiveql , to query data stored in a cluster .",
    "internally , hive translates an sql statement into hadoop mapreduce jobs by an sql - to - mapreduce translator and runs in parallel in the cluster .",
    "this greatly lowers the barrier to using hadoop , thus , a user can use hadoop as long as ( s)he is familiar with sql script language . due to the low latency of hadoop , and the append - only hadoop distributed file system ( hdfs ) , hive is only suitable for the situation where large - scale data are analyzed , fast response time is not required , and no frequent data updates are needed . therefore , we choose hive as the off - line analytics system for big data .",
    "analytics queries are run as mapreduce jobs , and the results are written into a hive table , a logical data organization structure on hdfs .",
    "the results can be exported into postgresql for interactive online analytics queries and visualization .",
    "the data processing layer supports different workflows running on the same platform scheduled by a scheduler . to coordinate the jobs , and control the use of computing resources ( e.g. , memory and cpu )",
    ", bigetl uses a centralized job scheduling system to schedule the runnings of all workflows .",
    "the system adopts two types of scheduling methods , i.e. , _ deterministic _ and _ un - deterministic_. the deterministic method is used to schedule a workflow to run exactly at the time specified by users , i.e. , the starting time of a workflow is deterministic and remains the same for repeating executions .",
    "the workflows scheduled by this method are typically those that run on the processing systems in a single server environment . the un - deterministic method , on the other hand",
    ", is used to schedule the workflows running in a cluster environment , i.e. , the actual starting time of a job is not necessary at the time specified by users , but usually later than the specified time .",
    "the scheduling method ensures that only one job is running in a cluster at any point of the time .",
    "the reason is that if multiple jobs are submitted to the same cluster , the submitted jobs will compete for the limited computing resources , and the cluster may become unstable , e.g. , some runtime exceptions might be thrown , such as the notorious _ out of memory _ exception . in this method , a queue is used to accommodate all submitted jobs , and the jobs run according to first - in - first - out ( fifo ) strategy . although spark and hadoop have their own job schedulers , we implement this scheduling system for better controlling the runnings of workflows , e.g. , we can chain multiple workflows and run in a sequential order in our platform .",
    "the ict platform uses smas in its analytics layer , which was developed in our previous work @xcite for analyzing smart meter data ( the source code is available at http://github.org/xiufengliu/smas ) .",
    "as shown in figure  [ fig : systemarchitecture ] , this layer is a web application for users to do interactive analytics using the smart meter data in the postgresql data warehouse with a variety of analytics algorithms implemented using madlib .    [",
    "cols=\"<,<,<,<,<\",options=\"header \" , ]     [ [ sec : evaluate ] ]    as mentioned in section [ sec : solution ] , the proposed ict - solution supports both batch and near real - time analytics for smart meter data .",
    "we now evaluate the proposed solution and discuss the results using the four illustrative examples in figure  [ fig : illustrativeexamples ] .",
    "the first example is studying _ consumption variability _ of each customer . in smart grid management",
    ", utilities must be provisioned for peak demand .",
    "therefore , it is important for utilities to identify consumers with highly variable consumption and offer them incentives to smooth out their demand .",
    "utilities can run histogram on the hourly consumption of each customer to learn the variability ( see figure  [ fig : histogram ] ) . for simplicity",
    ", we use equi - width histograms ( rather than equi - depth ) in our evaluation , and we always use ten buckets .",
    "the second example is studying _ thermal sensitivity _ of residential electricity consumption of each customer .",
    "for example , in winter and summer , consumption rises as temperatures become more extreme due to heating and cooling .",
    "consider the scatter plot shown in figure  [ fig:3line ] , with temperature on the x - axis and consumption on the y - axis .",
    "each point on the scatter plot corresponds to a particular hourly consumption value and the corresponding temperature at that hour ( for the same customer ) .",
    "we implement a recent algorithm @xcite that computes a piecewise linear regression model to characterize thermal sensitivity .",
    "the algorithm computes two regression models : one corresponding to the 90th percentile consumption at each temperature , and the other corresponding to the 10th percentile at each temperature .",
    "the models reveal several interesting features for each customer . for example",
    ", the slope of the 90th percentile line corresponding to high temperature is the cooling gradient , and the slope of the line corresponding to low temperature is the heating gradient .",
    "furthermore , the height of the 10th percentile lines at the lowest point is the base load , which corresponds to the load due to appliances that are always on , such as a refrigerator .",
    "the third example is studying _ daily load profile _ of each customer .",
    "this algorithm is for extracting daily consumption patterns that occur regardless of outdoor weather temperatures ( see figure  [ fig : parx ] ) .",
    "the left of the figure illustrates a fragment of the hourly consumption time series of a customer over a period of several days . since smart meters",
    "report the total electricity consumption of a household , we can only observe the total consumption time series ( the upper black curve ) .",
    "the goal of this algorithm is to determine how much load is due to temperature for each hour ( i.e. , heating and cooling ) , and how much load is due to daily activity independent of the temperature ( the lower blue curve ) .",
    "once this is determined , the algorithm fits a time series using auto - regression model , and computes the average temperature - independent consumption at each hour of the day , which is illustrated on the right of figure  [ fig : parx ] ( the x - axis is the hour of the day , and the y - axis is the average consumption ) . since weekday and weekend activities may differ , it is useful to separately compute typical weekday and weekend profiles for each customer .",
    "the last example is _ anomaly detection _ on the energy consumption of each customer .",
    "the anomaly detection can discover the consumption anomalies , such as an unusual high daily consumption , comparing with one s own consumption history .",
    "figure [ fig : anomalydetect ] shows an example of a customer s daily consumption at each hour .",
    "the actual consumption at 4 am is much higher than the predicted .",
    "anomaly detection analytics many help to find the root causes of the unusual consumption , such as energy leakage , theft , or forgetting to turn off the stove after cooking , etc .    in following experimental studies , we will use the above four representative analytics algorithms to evaluate the proposed ict - solution .",
    "the first three algorithms use the historical consumption data of each customer , which will be used to evaluate the batch analytics capability of the system ; while the last one is a stream data mining algorithm that will be used to evaluate the real - time analytics capability .      in the following ,",
    "we outline the experimental settings .",
    "the analytics layer with postgresql and madlib is installed on a single server while the data processing layer with spark and hive is installed in a cluster .",
    "the analytics server is configured with an intel(r ) core(tm ) i7 - 4770 processor ( 3.40ghz , 4 cores , hyper - threading is enabled , two hyper - threads per core ) , 16 gb ram , and a seagate hard driver ( 1 tb , 6 gb / s , 32 mb cache and 7200 rpm ) , running ubuntu 12.04 lts with 64bit linux 3.11.0 kernel .",
    "postgresql 9.1 has the settings `` shared buffers=3072 mb , temp buffers= 256 mb , work mem=1024 mb , checkpoint segments = 64 '' and default values for other configuration parameters .",
    "the cluster consists of one administration node and 16 worker nodes .",
    "the administration node is the master node of hadoop and hdfs , and clients submit jobs there .",
    "all the nodes have the same configuration : dual - socket intel(r ) xeon(r ) cpu e5 - 2620 ( 2.10ghz , 6 cores per socket , and two hyper - threads per core ) , 60 gb ram , running 64bit linux with kernel version 2.6.32 .",
    "the nodes are connected via gigabit ethernet , and a working directory is nfs - mounted on all the nodes .",
    "real - world and synthetic data sets are both used for the evaluation .",
    "since we only have 10 gb real - world residential electricity consumption data sets , for more data we generate the synthetic data sets seeded by the real - world data .",
    "one gigabyte data set contains roughly 27,300 hourly granular time - series with the length of two years .",
    "the size of data tested in the cluster environment is scaled up to one terabyte , corresponding to over twenty million time series .    in the following",
    ", we will first evaluate batch analytics using the technologies hive and spark ( used in the processing layer ) , and postgresql / madlib ( used in the analytics layer ) .",
    "then , we will evaluate real - time analytics using the same technologies .",
    "we evaluate cluster and in - database based batch analytics on bigetl ( with hive and spark as the underlying data processing systems ) , and on postgresql / madlib using the first three illustrative examples , respectively .",
    "the implementations are that 1 ) _ variability analytics : _ we implement our histogram program in java ; 2 ) _ thermal sensitivity analytics : _ we use the functions from apache common math library @xcite to implement the three linear regression lines , and adjust the three piece - wise lines to connect them together ; and 3 ) _ daily load profile analytics : _ the program is implemented based on the parx model ( see section [ sec : indbanalysis ] ) , which also uses the multiple linear regression function from apache common math library .",
    "the implementations for the in - database analytics are the postgresql stored procedures using madlib analytics functions , including histogram and linear regression .",
    "we first use the real - world data set to evaluate batch analytics performance on the three platforms .",
    "we measure the total running time by scaling the data size from 2 to 10 gb .",
    "in fact , this experiment is unfair in the sense that we test postgresql with madlib on a server ( with the maximum parallelism level of eight hyper - threads ) , but test spark and hive on a cluster . to be more comparable ,",
    "we make use of eight database connections in postgresql to execute analytics queries in parallel , each of which is given the same number of time - series as the input . in the cluster ,",
    "we make use of eight slave nodes , each of which runs a single task .",
    "figure  [ fig : batchreal ] shows the experimental results , indicating that the in - database analytics has better performance when handling relatively small - sized data while the cluster - based approach ( both hive and spark ) outperforms it for bigger sized data .",
    "the breaking points vary with the algorithms .",
    "this also verifies that the cluster - based approach is a better option for big data analytics in terms of the performance . in this experiment",
    ", we could observe that the running times used change insignificantly for both hive and spark ( with flat lines ) since the workload is too low for the cluster - based analytics .",
    "we now use big synthetic data to evaluate hive and spark , scaling from 200 to 1,000 gb . all the 16 slave nodes are used in this experiment . figure [ fig : batchsyn ] shows the results , indicating that spark has better performance in variability analytics , but hive is better in thermal sensitivity analytics and daily load profile analytics after 700 gb approximately . we found that this was due to the memory spilling occurring in spark .",
    "spark is an in - memory based distributed computing framework .",
    "if data objects ( rdds ) can not fit into the size of main memory , some of the data objects will be spilled over to hard drivers , which greatly deteriorates in performance .",
    "we have also observed that no data spilling happened in running the variability analytics algorithm .",
    "the reason is that the variability analytics only uses the consumption time series , while the other two algorithms also use the weather temperature time series , meaning that the required memory size is much bigger .",
    "if the performances of the algorithms are considered , the variability analytics shows to be better than the other two algorithms when using both types of data .",
    "the thermal sensitivity analytics algorithm needs more time than the daily load profile analytics algorithm .",
    "this can be explained by the following .",
    "variability analytics uses the histogram which is simple and efficient ; thermal sensitivity analytics requires to run the regression function three times for the three linear regression lines , while daily load profile analytics runs regression function only once .",
    "we now evaluate real - time analytics capability using online anomaly consumption detection .",
    "we use unique variate gaussian distribution as our anomaly detection model , which is defined in the following .",
    "suppose that we have a training data set , @xmath0 , whose data points obey normal distribution with the mean @xmath1 and the variance @xmath2 .",
    "the detection function is defined as @xmath3 where @xmath4 and @xmath5 .",
    "if we have a new data point , @xmath6 , we use this function to compute the probability density .",
    "if the probability is less than a use - defined threshold , i.e. , @xmath7 , it is classified as an anomaly . in our example , a data point is the euclidean distance between the actual and predict hourly consumption of a day , i.e. , @xmath8 where @xmath9 is the @xmath10th day s actual hourly consumption defined as @xmath11 , and @xmath12 is the predicted hourly consumption defined as @xmath13 .",
    "we use the parx model to compute the predicted hourly consumption of each day .    in our experiment",
    ", we simulate receiving hourly consumption of each day in a real - time fashion , i.e. , the 24-hour consumption values are fed into hive or spark streaming directly from hadoop distributed file system ( hdfs ) , while for postgresql / madlib , the values are fed from a table in postgresql .",
    "strictly speaking , only spark streaming is originally designed for processing the real - time data stream , e.g. , connects to external streaming data sources , such as smart meters or sensors , and processes it .",
    "but , for comparison purpose , we also test hive and madlib by the simulation of reading data from their local data storage , i.e. , tables in postgresql or hive . in our evaluation",
    ", we use half - year s data as the training data sets to compute the anomaly detection model , and we use the computed model throughout the subsequent detection process .                here",
    ", we first use the real - world data sets again .",
    "we use one month s data ( june 2012 ) as the example to test our algorithm .",
    "figure  [ fig : anomalyresults ] shows the detected anomalies when the threshold value , @xmath14 , is set to , @xmath15 , @xmath16 and @xmath17 , respectively .",
    "as shown , the number of anomalies fluctuates in each day , and we could observe that the 2 - 3th , 9 - 10th , 16 - 17th , 23 - 24th and 30th days in this month have a larger number of anomalies than the other days .",
    "in fact , these days are the weekends when people might stay at home , and use more energy .",
    "the results also show that the number of anomalies is different when the threshold values are changed .",
    "the number gets closer when the threshold value decreases from @xmath16 to @xmath17 . in this experiment , since we detect anomalies based on one s history consumption regardless of the weekends or weekdays , a relatively high consumption in weekends may be classified as an anomaly .",
    "this , however , can be improved by classifying the consumption values according to weekdays and weekends / holidays ; or by comparing clustered customer groups or neighborhood .",
    "besides , it would be favorable for customers to set their threshold values , e.g. , through a mobile phone or web client , to decide when they could receive alerting messages .",
    "we leave these improvements to our future work .",
    "we now measure the performance .",
    "first , we use the real - world data sets by scaling the number of time series from 5,000 to 250,000 and measure the average time of processing the data of each day .",
    "figure [ fig : selfanomalyreal ] shows the results of using the cluster based ( hive and spark streaming ) , and the in - database based ( postgresql / madlib ) approaches .",
    "as illustrated , the in - database based approach outperforms the cluster based , and spark streaming shows a better performance than hive in the cluster based approach , due to its use of in - memory - based technology . obviously , they all are under workload at these scales of the data set .",
    "we now use the synthetic data set , and scale the number of time series from 0.5 to 12.5 million ( up to 457 gb ) .",
    "figure [ fig : selfanomalysyn ] shows the results , where hive is the best after 1.0 million time series , and the in - database approach becomes less efficient after 1.2 million .",
    "it is not surprising that the in - database approach becomes slower for large data sets since it runs on a single server which has a limited scalability . for the cluster based approach , when a relatively small number of time series is given as the input ,",
    "the performance difference is likely due to overheads associated with task distribution ; by default , hive launches a separate java virtual machine ( jvm ) for each task whereas spark reuses task executors more intelligently .",
    "in fact , even running a ",
    "select * \" hive query from a one - row table took nearly 30 seconds in our cluster . when a bigger number of time series is given , i.e. , @xmath18 , spark performs substantially worse due to the overhead of accessing data from the past three days ( recall that we use the order @xmath19 in parx model for the prediction , see section [ sec : indbanalysis ] ) .",
    "spark streaming checkpoints the sliding window of the past three days to hdfs whenever new data are added , which lowers the performance .",
    "we have evaluated the key technologies that constitute the proposed ict - solution .",
    "the results reveal that the in - database analytics using postgresql / madlib is more suitable for relatively small - sized data sets , and can provide highly responsive interactive analytics , due to the support of high - performance oltp operations and indexing in a database management system . for big data analytics , it is favorable to go for a cluster - based approach , e.g. , using hive or spark , to obtain high scalability . in the cluster",
    "based analytics , spark shows a better performance than hive in general on the condition that the in - memory data is not spilled over to local hard - driver on a node .",
    "therefore , it is beneficial to provide sufficient memory to ensure the performance in spark .",
    "the proposed ict - solution employs a hybrid architecture in order to get the best of each of the systems , i.e. , high - performance analytics queries of _ postgresql _ , big data capability of _ hive _ and _ spark _ , and real - time ability of spark streaming . by the hybrid architecture",
    ", the ict platform can achieve both batch and ( near ) real - time analytics for smart meter data analytics .    based on our studies ,",
    "we recommend using postgresql / madlib to manage the latest smart meter data ( e.g. , of the past two years ) , social - economic data , and statistic data .",
    "smart meter data sets are typically big , but rarely updated ; socio - economic data sets such as the information of customers are typically much smaller , but may frequently be updated ; statistic data sets are the result of analytics algorithms , which are also typically small .",
    "furthermore , when data get older , they will usually lose the values .",
    "thus , old data can be moved to the offline data warehouse system , hive . however , when the data are needed , users still can run batch analytics queries directly on hive , and transfer the results to the online data warehouse in postgresql for the interactive analytics . for ( near )",
    "real - time data analytics , spark streaming supports stream processing in nature , which reads stream data at a regular time interval , and uses stream operations to process the data , such as sliding window and stream join operations .",
    "in contrast , if users want to use postgresql / madlib or hive , they have to implement their own data streaming programs , which require much more effort .",
    "the current focus of this platform is for smart grid data analytics , but it can easily be extended to support distribution network management .",
    "smart grids such as low - voltage ( lv ) networks are characterized by variable demands , which requires integrating distributed renewable energy sources and energy storages for balancing energy supply and demand @xcite .",
    "the platform is suitable for energy storage scheduling management .",
    "for example , this platform can flexibly integrate different forecasting algorithms , e.g. , arima , parx , arimax @xcite , to predict day-/hour - ahead energy consumption profile . then based on the load profile ,",
    "the scheduling system can optimize supply - side energy flexibility using a dynamic scheduling strategy , i.e. , charging batteries during low - demand periods while discharging during peak - demand periods .",
    "the application in smart grid distribution network management will be our future work .",
    "with the widely implementation of smart meters , smart meters produce considerable volumes of data , presenting the opportunity for utilities to enhance customer service , lower cost and improve energy efficiency ; and for customers to save energy and reduce the bills .",
    "smart meter data analytics is a complex process that involves data ingestion , pre - processing , analytics , and visualization . in this paper",
    ", we proposed an ict - solution to streamline smart meter data analytics .",
    "the proposed ict solution employs a hybrid system architecture combining different technologies , including spark , hive , and postgresql / madlib , etc .",
    "the system architecture consists of three layers , including ingestion layer , processing layer , and analytics layer , each of which supports the extension for different data processing and analytics purposes .",
    "in particular , we introduced in - database analytics to achieve high performance and cluster - based big data analytics in our system",
    ". the ict - solution can handle both ( near ) real - time and batch analytics for smart meter data .",
    "we have tested the effectiveness and efficiency of the ict - solution comprehensively using real - world and synthetic data sets .",
    "the results have shown that the proposed solution can analyze batch and stream data effectively and efficiently .    in the future work",
    ", we will improve the system by adding new features , and more analytics algorithms developed in our research .",
    "we would like to extend our system to support other types of smart meter data , such as water , gas , and heat ; and to extend our system for the support of smart grid distribution network management that we have discussed .",
    "moreover , we will investigate the potential applications for utilities based on the results provided in this paper ; and study how this system help utilities in their energy management .",
    "this research was supported by the cities project funded by danish innovation fund ( 1035 - 00027b ) .",
    "20    greentech media research , the soft grid 2013 - 2020 : big data & utility analytics for smart grid .",
    "http://www.greentechmedia.com/research/report/the-soft-grid-2013 as of 2016 - 05 - 11 .",
    "liu x , nielsen p s. streamlining smart meter data analytics . in proc . of the 10th conference on sustainable development of energy , water and environment systems , sdewes2015.0558 , 1 - 14 , 2015 .",
    "bigetl  a scalable data processing system .",
    "http://github.org/xiufengliu/bigetl as of 2016 - 05 - 11 .",
    "liu x , golab l , ilyas if .",
    "smas : a smart meter data analytics system . proc . of icde 2015 ; 14761479 .",
    "madlib.net as of 2016 - 05 - 11 .",
    "liu x , golab l , golab w , ilyas if .",
    "benchmarking smart meter data analytics . proc . of edbt 2015 ; 385396 .",
    "kdb+  the time - series database for performance - critical environments .",
    "http://kx.com/ as of 2016 - 05 - 11 .",
    "frber f , cha sk , primsch j , bornhvd c , sigg s , lehner w. sap hana database : data management for modern business applications .",
    "acm sigmod record 2012 ; 40(4):4551 .",
    "nezhad aj , wijaya tk , vasirani m , aberer k. smartd : smart meter data analytics dashboard .",
    "proc . of future energy systems",
    "( acm e - energy ) 2014 ; 213214 .",
    "liu y , hu s , rabl t , liu w , jacobsen ha , wu k , chen j. dgfindex for smart grid : enhancing hive with a cost - effective multidimensional range index .",
    "pvldb 2014 ; 14961507 .",
    "stewart ra , willis r , giurco d , panuwatwanich k , capati g. web - based knowledge management system : linking smart metering to the future of urban water planning .",
    "australian planner 2010 ; 47(2):6674 .",
    "nguyena ka , stewart ra , zhang h , jones c. intelligent autonomous system for residential water end use classification : autoflow .",
    "applied soft computing 2015 ; 31:118131 .",
    "arlitt m , marwah m , bellala g , shah a , healey j , vandiver b. iotabench : an internet of things analytics benchmark . proc . of icpe 2015 .",
    "keogh e , kasetty s. on the need for time series data mining benchmarks : a survey and empirical demonstration .",
    "data miningand know .",
    "( dmkd ) 2003 ; 7(4):349371 .",
    "anil c. benchmarking of data mining techniques as applied to power system analysis .",
    "master thesis 2013 ; uppsala university .",
    "birt bj , newsham gr , beausoleil - morrison i , armstrong mm , saldanha n , rowlands ih .",
    "disaggregating categories of electrical energy end - use from whole - house hourly data .",
    "energy and buildings 2012 ; 50:93102 .",
    "rasanen t , voukantsis d , niska h , karatzas k , kolehmainen m. data - based method for creating electricity use load profiles using large amount of customer - specific hourly measured electricity use data . applied energy 2010 ; 87(11):35383545 .",
    "abreu jm , camara fp , ferrao p. using pattern recognition to identify habitual behavior in residential electricity consumption .",
    "energy and buildings 2012 ; 49:479 - 487 .",
    "albert a , rajagopal r. smart meter driven segmentation : what your consumption says about you .",
    "ieee transactions on power systems 2013 ; 4(28 ) .",
    "ardakanian o , koochakzadeh n , singh rp , golab l , keshav s. computing electricity consumption profiles from household smart meter data .",
    "proc . of endm workshop on energy data management 2014 ; 140147 .",
    "beckel c , sadamori l , staake t , santini , s. revealing household characteristics from smart meter data .",
    "energy 2014 , 78:397410 .",
    "chicco g , napoli r , piglione f. comparisons among clustering techniques for electricity customer classification .",
    "ieee trans . on power systems 2006 ; 21(2):933 - 940 .",
    "espinoza m , joye c , belmans r , demoor b. short - term load forecasting , profile identification , and customer segmentation : a methodology based on periodic time series .",
    "ieee trans . on power systems 2005 ; 20(3):16221630 .",
    "figueiredo v , rodrigues f , vale z , gouveia j. an electric energy consumer characterization framework based on data mining techniques .",
    "ieee trans . on power systems 2005 ; 20(2):596602 .",
    "ghofrani m , hassanzadeh m , etezadi - amoli m , fadali m. smart meter based short - term load forecasting for residential customers .",
    "north american power symposium ( naps ) 2011 .",
    "smith ba , wong j , rajagopal r. a simple way to use interval data to segment residential customers for energy efficiency and demand response program targeting .",
    "aceee summer study on energy efficiency in buildings 2012 .",
    "tsekouras g , hatziargyriou n , dialynas e. two - stage pattern recognition of load curves for classification of electricity customers .",
    "ieee trans .",
    "power systems 2007 ; 22(3):11201128 .",
    "albert a , rajagopal r. building dynamic thermal profiles of energy consumption for individuals and neighborhoods .",
    "proc . of ieee",
    "big data 2013 ; 723728 .",
    "liu x , thomsen c , pedersen tb .",
    "etlmr : a highly scalable etl framework based on mapreduce . proc . of dawak 2011",
    "; 96111 .",
    "liu x , thomsen c , pedersen tb .",
    "etlmr : a highly scalable dimensional etl framework based on mapreduce .",
    "tldks iii 2013 ; 8:1 - 31 .",
    "liu x , thomsen c , pedersen tb .",
    "mapreduce - based dimensional etl made easy ( demo ) .",
    "pvldb 2012 ; 5(12 ) : 1882 - 1885 .",
    "liu x , thomsen c , pedersen tb .",
    "cloudetl : scalable dimensional etl for hive .",
    "proc . of ideas 2014",
    "; 195 - 206 .",
    "zaharia m , das t , li h , shenker s , and stoica i. discretized streams : an efficient and fault - tolerant model for stream processing on large clusters . proc . of hotcloud 2012",
    "; 1010 .",
    "http://www.bigsql.org as of 2016 - 05 - 11 .",
    "thusoo a , sarma js , jain n , shao z , chakka p , zhang n , murthy r. hive - a petabyte scale data warehouse using hadoop . proc . of icde 2010 ; 9961005 .",
    "apache common math library .",
    "https://commons.apache.org/proper/commons-math/ as of 2016 - 05 - 11 .",
    "bennett cj , stewart ra , and lu jw .",
    "forecasting low voltage distribution network demand profiles using a pattern recognition based expert system .",
    "energy 2014 ; 67:200 - 212 .",
    "bennett c j , stewart ra , and lu jw .",
    "development of a three - phase battery energy storage scheduling and operation system for low voltage distribution networks . applied energy 2015 ; 146:122134 .",
    "bennett cj , stewart ra , and lu jw .",
    "autoregressive with exogenous variables and neural network short - term load forecast models for residential low voltage distribution networks .",
    "energies 2014 ; 7(5):2938 - 2960 .",
    "we randomly take a consumption time series from the real - world data set to evaluate parx model , and the output is given in table  [ tbl : coef ] . according to the results , i.e. , p - test ,",
    "the coefficient estimates of the most recent three - day s consumption values ( @xmath19 ) at the day @xmath20 have shown a good significance , which is same to the temperature coefficient estimates .",
    "the number of  * \" shows the significance level .",
    "we randomly select 10% consumption time series ( 2,730 ) from the real - world data set to evaluate the predictive accuracy . for each time series",
    ", we use a quarter of the readings as the training data to create the model ( i.e. , six months ) , and the rest as the testing data . during the test",
    ", the model is refreshed iteratively by days , and the training set is expanded by adding the readings from the testing set prior to the day of testing . for better assessment , we compare parx with the following three algorithms : 1 ) _ averaging : _ we use the averaging value at a particular hour in the training data to predict the reading of the hour ; 2 ) _ 3-line _ : we use the three piece - wise linear regression line algorithm to predict the consumption with a given weather temperature ( see figure  [ fig:3line ] ) ; and 3 ) _ convergent vector _ : this algorithm is proposed by @xcite , which is similar to parx taking weather temperature into account .",
    "for all the methods , we compute the root - mean - square error ( rmse ) between the actual and predicted values , which is defined as follows : @xmath21 where @xmath12 is the predicted value , @xmath9 is the actual value , and @xmath22 is the size of testing data .",
    "we compare the rmse values of each time - series for the four prediction methods , and get the following findings :    * parx outperforms averaging for 2,586 time series , 3-line for 2,612 time series , and convergent vector for 2,460 time series .",
    "* table  [ tbl : rmse ] summarizes the mean value of rmse over all the 2,730 time series for each algorithm .",
    "parx is 13.3% lower than the averaging , 21.7% lower than 3-line , and 6.0% lower than convergent vector .",
    "therefore , according to the above results , parx can outperform the other representative models , and has the lowest predictive errors on average .",
    "this confirms that the necessary of incorporating the seasonality of history consumption and temperature dependence into a prediction model ."
  ],
  "abstract_text": [
    "<S> smart meters are increasingly used worldwide . </S>",
    "<S> smart meters are the advanced meters capable of measuring energy consumption at a fine - grained time interval , e.g. , every 15 minutes . </S>",
    "<S> smart meter data are typically bundled with social economic data in analytics , such as meter geographic locations , weather conditions and user information , which makes the data sets very sizable and the analytics complex . </S>",
    "<S> data mining and emerging cloud computing technologies make collecting , processing , and analyzing the so - called _ big data _ possible . </S>",
    "<S> this paper proposes an innovative ict - solution to streamline smart meter data analytics . </S>",
    "<S> the proposed solution offers an information integration pipeline for ingesting data from smart meters , a scalable platform for processing and mining big data sets , and a web portal for visualizing analytics results . </S>",
    "<S> the implemented system has a hybrid architecture of using _ </S>",
    "<S> spark _ or _ </S>",
    "<S> hive _ for big data processing , and using the machine learning toolkit , _ madlib _ , for doing in - database data analytics in _ postgresql _ database . </S>",
    "<S> this paper evaluates the key technologies of the proposed ict - solution , and the results show the effectiveness and efficiency of using the system for both batch and online analytics .    </S>",
    "<S> ict - solution , smart meter data , big data , data analytics </S>"
  ]
}