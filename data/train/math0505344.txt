{
  "article_text": [
    "the hypergeometric function of a matrix argument has a wide area of applications in multivariate statistical analysis  @xcite , random matrix theory  @xcite , wireless communications @xcite , etc . except in a few special cases ,",
    "it can be expressed only as a series of multivariate homogeneous polynomials , called jack functions .",
    "this series often converges very slowly  @xcite , and the cost of the straightforward evaluation of a single jack function is exponential  @xcite .",
    "the hypergeometric function of a matrix argument has thus acquired a reputation of being notoriously difficult to approximate even in the simplest cases @xcite .    in this paper",
    "we present new algorithms for approximating the value of the hypergeometric function of a matrix argument .",
    "we exploit recursive combinatorial relationships between the jack functions , which allow us to only _ update _ the value of a jack function from other jack functions computed earlier in the series .",
    "the savings in computational time are enormous ; the resulting algorithm has complexity that is only _ linear _ in the size of the matrix argument . in the special case",
    "when the matrix argument is a multiple of the identity , the evaluation becomes even faster .",
    "we have made a matlab  @xcite implementation of our algorithms available  @xcite .",
    "this implementation is very efficient ( see performance results in section [ sec_numexp ] ) , and has lead to new results  @xcite .",
    "the hypergeometric function of a matrix argument is defined as follows .",
    "let @xmath0 and @xmath1 be integers , and let @xmath2 be an @xmath3 complex symmetric matrix with eigenvalues @xmath4 .",
    "then @xmath5 where @xmath6 is a parameter ; @xmath7 means @xmath8 is a partition of @xmath9 ( i.e. , @xmath10 are integers such that @xmath11 ) ; @xmath12 is the _ generalized pochhammer symbol _ , and @xmath13 is the jack function .    the _ jack function _",
    "@xmath14 is a symmetric , homogeneous polynomial of degree @xmath15 in the eigenvalues @xmath4 of @xmath2 ( * ? ? ?",
    "* rem .  2 , p.   228 ) , @xcite .",
    "for example , when @xmath16 , @xmath17 becomes the ( normalized ) _ schur function _ , and for @xmath18 , the _",
    "zonal polynomial_. ) for @xmath16  ( * ? ? ?",
    "* ( 4.1 ) ) or @xmath18  @xcite only .",
    "there is no reason for us to treat the different @xmath19 s separately ( see also @xcite for the uniform treatment of the different @xmath19 s in other settings ) .",
    "] there are several normalizations of the jack function which are scalar multiples of one another : @xmath17 is normalized so that @xmath20 ; in section [ sec_hg ] we express ( [ hg1 ] ) in terms of the jack function @xmath21 , which is normalized so that the coefficient of @xmath22 is @xmath23 . the functions @xmath17 and @xmath21 can be defined recursively , e.g. , @xmath24 where @xmath25 is a rational function of @xmath19 ( see section [ sec_hg ] for details ) .",
    "the relationship ( [ recur ] ) becomes key in achieving efficiency in our algorithms .",
    "the jack functions @xmath17 and @xmath21 , and in turn the hypergeometric function of a matrix argument , depend only on the eigenvalues @xmath4 of @xmath2 .",
    "many authors , however , have found the matrix notation in ( [ hg1 ] ) , and the use of a matrix argument to be more convenient .",
    "we follow the same practice",
    ".    the hypergeometric function of a matrix argument is _ scalar - valued _ , which is a major distinction from other functions of a matrix argument ( e.g. , the matrix exponential ) , which are _ matrix - valued_. the hypergeometric function of a matrix argument generalizes the classical hypergeometric function to which it reduces for @xmath26 . in general , however , there is no explicit relationship between these two functions for @xmath27 .",
    "we approximate the series ( [ hg1 ] ) by computing its truncation for @xmath28 : @xmath29    the series  ( [ hg1 ] ) converges for any @xmath2 when @xmath30 ; it converges if @xmath31 when @xmath32 , and diverges when @xmath33 , unless it terminates  @xcite .",
    "when it converges , its @xmath34-term converges to zero as @xmath35 . in these cases ( [ hg2 ] )",
    "is a good approximation to ( [ hg1 ] ) for a large enough @xmath36 .",
    "the computational difficulties in evaluating ( [ hg2 ] ) are :    * the series ( [ hg1 ] ) converges slowly in many cases  @xcite ; thus a rather large @xmath36 may be needed before ( [ hg2 ] ) becomes a good approximation to ( [ hg1 ] ) ; * the number of terms in ( [ hg2 ] ) ( i.e. , the number of partitions @xmath28 ) grows , roughly , as @xmath37 ( see section [ sec_complexity ] ) ; * the straightforward evaluation of a single jack function , @xmath17 for @xmath38 , has complexity that grows as @xmath39  @xcite .",
    "while there is little we can do about ( a ) ( which is also a major problem even in the univariate ( @xmath26 ) case @xcite ) , or ( b ) , our major contribution is in improving ( c ) , the cost of evaluating the jack function .",
    "we exploit the combinatorial properties of the pochhammer symbol and the jack function to only _ update _ the @xmath34-term in ( [ hg2 ] ) from the @xmath40-terms , @xmath41 . as a result",
    "the complexity of our main algorithm for computing  ( [ hg2 ] ) , algorithm  [ alg_hg ] , is only linear in the size @xmath42 of the matrix argument @xmath2 , exponentially faster than the previous best algorithm  @xcite ( see sections [ sec_background ] , [ sec_complexity ] and [ sec_numexp_complexity ] for details ) . in the special case when @xmath2 is a multiple of the identity , we present an even faster algorithm , algorithm  [ alg_hgi ] , whose complexity is independent of @xmath42 .",
    "a number of interesting problems remain open . among these",
    "are :    * detecting convergence ; * selecting the optimal value of @xmath36 in ( [ hg2 ] ) for a desired accuracy ; * selecting the optimal truncation of the series  ( [ hg1 ] ) .",
    "we do not believe that a uniform answer to these problems exists for every @xmath19 and every @xmath43 and @xmath44 .",
    "therefore , we leave the choice of @xmath36 and an appropriate truncation to the user .",
    "we elaborate more on these open problems in section [ sec_concl ] .    with minimal changes our algorithms can approximate the hypergeometric function of _ two _ matrix arguments @xmath45 and more generally functions of the form @xmath46 for arbitrary coefficients @xmath47 at a similar computational cost ( see , e.g. , ( [ tra ] ) in subsection [ sec_numexp_2 ] ) .    in ( [ hgxy ] ) and throughout this paper ,",
    "we denote a vector @xmath48 as @xmath49 .",
    "this paper is organized as follows .",
    "we survey previous algorithms for computing the hypergeometric function of a matrix argument in section [ sec_background ] . in section [ sec_hg ]",
    "we describe our approach in computing the truncation ( [ hg2 ] ) .",
    "we present our new algorithms in section [ sec_algs ] , and analyze their complexity in section [ sec_complexity ] .",
    "we present numerical experiments in section [ sec_numexp ] .",
    "finally , we draw conclusions and present open problems in section [ sec_concl ] .",
    "butler and wood  @xcite used laplace approximations to compute the integral representations  ( * ? ? ? * thm .  7.4.2 , p.  264 ) : @xmath50 valid for real symmetric @xmath2 , @xmath51 , @xmath52 , and @xmath53 ; and @xmath54 valid for @xmath55 , @xmath51 , and @xmath56    this approach , however , is restricted to the cases @xmath57 or @xmath58 , @xmath59 , and @xmath18 .",
    "gutirrez , rodriguez , and sez presented in  @xcite ( see also  @xcite for the implementation ) an algorithm for computing the truncation  ( [ hg2 ] ) for @xmath18 ( then the jack functions are called _ zonal polynomials _ ) . for every @xmath60 , the authors form the upper triangular _ transition matrix _",
    "@xcite @xmath61 ( indexed by all partitions of @xmath9 ) between the monomial symmetric functions @xmath62 and the zonal polynomials @xmath63 .",
    "then for every partition @xmath64 they compute @xmath65 ( where @xmath40 ranges over all _ distinct _ permutations of @xmath66  @xcite ) , and form the product @xmath67 . computing the vector @xmath68 alone",
    "costs @xmath69 since every term in every @xmath70 is of degree @xmath36 , and for every nonstrictly increasing sequence of @xmath36 numbers from the set @xmath71 we obtain a distinct term in some @xmath70 .",
    "the overall cost is thus at least exponential ( @xmath39 ) , which explains the authors observation :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ we spent about 8 days to obtain the 627 zonal polynomials of degree 20 with a 350 mhz pentium ii processor . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in contrast , our algorithm  [ alg_hg ] takes less than a hundredth of a second to do the same .",
    "its complexity is only linear in @xmath42 and subexponential in @xmath36 ( see section [ sec_complexity ] ) .",
    "we make the evaluation of @xmath72 efficient by only _ updating _ the @xmath34-term from the @xmath40-terms , @xmath41 , instead of computing it from scratch .",
    "we first express @xmath72 in terms of the jack function @xmath73 , which is normalized so that the coefficient of @xmath74 in @xmath75 equals @xmath23  ( * ? ? ?",
    "the jack functions @xmath13 and @xmath73 are related as : @xmath76 where @xmath77 and @xmath78 and @xmath79 are the _ upper and lower hook lengths _ at @xmath80 , respectively .",
    "denote @xmath81 since @xmath82 when @xmath83 , we need to sum only over partitions @xmath34 with at most @xmath42 parts : @xmath84    when computing  ( [ hg3 ] ) , we recursively generate all partitions @xmath28 in such a way that consecutively generated partitions differ in only one part .",
    "therefore it is convenient to introduce the notation @xmath85 for any partition @xmath34 such that @xmath86 .    in the following subsections",
    "we derive formulas for updating the @xmath34-term in  ( [ hg3 ] ) from the @xmath40-terms , @xmath41 .",
    "we update @xmath87 from @xmath88 using the following lemma .",
    "@xmath89    where @xmath90 , and @xmath91 .",
    "[ lemma_qkappaupdate ]    from  ( [ poch ] ) , @xmath92 , and from  ( [ jkappa ] ) , @xmath93 which along with  ( [ qkappa ] ) imply  ( [ qkappaupdate ] ) .    the seemingly complicated notation of lemma [ lemma_qkappaupdate ] is needed in order to minimize the number of arithmetic operations needed to update @xmath87 . a straightforward evaluation of  ( [ qkappa ] ) costs @xmath94 ; in contrast ,  ( [ qkappaupdate ] ) costs only @xmath95 arithmetic operations .",
    "when @xmath96 , @xmath97 .",
    "for @xmath98 , we update @xmath99 from @xmath100    when @xmath2 is a multiple of the identity we have an easy special case  ( * ? ? ? * thm .",
    "5.4 ) : @xmath101 therefore we can update @xmath102 from @xmath103 as @xmath104    in the general case , we update the jack function using the identity ( see , e.g. , ( * ? ? ?",
    "4.2 ) ) : @xmath105 where the summation is over all @xmath41 such that @xmath106 is a horizontal strip , and @xmath107 the skew partition @xmath106 is a _ horizontal strip _ when @xmath108  @xcite .",
    "we borrow the idea for updating the jack function from @xcite , but make two important improvements .",
    "we only _ update _ the coefficients @xmath25 , and store the precomputed jack functions much more efficiently than in  @xcite .",
    "the coefficients @xmath25 are readily computable using  ( [ betakappamu ] ) at the cost of @xmath109 arithmetic operations .",
    "the following lemma allows us to start with @xmath110 and _ update _",
    "@xmath111 from @xmath25 at the cost of only @xmath112 arithmetic operations .",
    "let @xmath113 , and @xmath114 be partitions such that @xmath106 and @xmath115 are horizontal strips , and @xmath116 for @xmath117 .",
    "then @xmath118 where @xmath119 , and @xmath120 .",
    "denote @xmath121 .",
    "we have @xmath122 , except for @xmath123 . since @xmath106 and @xmath115 are horizontal strips , @xmath124 and @xmath125 .",
    "then @xmath126 we transform the first term of  ( [ betatrans ] ) by observing that @xmath127 , except for @xmath128 : @xmath129to simplify the second term of  ( [ betatrans ] ) , we observe that @xmath130 , except for @xmath131 and @xmath128 .",
    "also @xmath132 for @xmath133 , and @xmath134 .",
    "therefore @xmath135 which yields ( [ betakappamuupdate ] ) .",
    "algorithm  [ alg_hgi ] computes @xmath72 in the easy special case when @xmath2 is a multiple of the identity .",
    "algorithm  [ alg_hg ] handles the general case .",
    "both algorithms recursively generate all partitions @xmath28 with at most @xmath42 parts by allowing @xmath137 to take all values @xmath138 and , independently , @xmath139 , to take all values @xmath140 , subject to the restriction @xmath28 . the coefficients @xmath87 are updated using  ( [ qkappaupdate ] ) .",
    "the jack functions are updated using  ( [ jkappaupdate ] ) or  ( [ jackmain ] ) as appropriate .",
    "the following algorithm computes @xmath141 .",
    "the variables @xmath142 , and @xmath34 are global .",
    "` function ` @xmath143 ` hgi`@xmath144    `    ` @xmath145    `    summation`@xmath146    ` function summation`@xmath147    `    for ` @xmath148 1.8 in ( _ defaults to @xmath149 for @xmath150 _ )    `      ` @xmath151 0.1 in ( _ where @xmath152 is the right hand side of _ ( [ qkappaupdate ] ) )    `      ` @xmath153    `      if ` @xmath154 ` and ` @xmath155 ` then `    `        summation`@xmath156    `      endif `    `    endfor `    `    ` @xmath157    [ alg_hgi ]    in algorithm  [ alg_hgi ] the variable @xmath158 equals the @xmath34-term in  ( [ hg3 ] ) ; it is updated using  ( [ qkappaupdate ] ) and  ( [ jkappaupdate ] ) .",
    "the parameter @xmath149 in ` summation ` equals @xmath159 .",
    "the hypergeometric function of two matrix arguments  ( [ hgxy ] ) is in this case @xmath160      we use the identity  ( [ jackmain ] ) to update the jack function , but in order to use it efficiently , we need to store and reuse the jack functions computed earlier",
    ".    therefore we index all partitions @xmath28 with at most @xmath42 parts ( @xmath161 ) by linearizing the @xmath36-tree that they form ( each node @xmath162 has at most @xmath36 children @xmath163 @xmath164 ) . in other words , if @xmath165 , we assign a distinct integer index @xmath166 to every such partition @xmath34 .",
    "we start by assigning the indexes @xmath167 to partitions with one part : @xmath168 , @xmath169 .",
    "then , recursively , once an index @xmath170 has been assigned to a partition @xmath171 with @xmath9 parts , we assign @xmath159 consecutive unassigned indexes to the partitions @xmath172 , @xmath173 .",
    "we record the tree structure in an array @xmath174 such that @xmath175 .",
    "now given @xmath34 , we can compute @xmath170 by starting with @xmath176 and using the recurrence @xmath177    we store every computed @xmath178 ( @xmath28 , @xmath161 , @xmath179 ) in the @xmath180th entry of an @xmath181 array , which we call `` @xmath182 '' in algorithm  [ alg_hg ] below .",
    "we compute the value of @xmath183 as follows .",
    "let @xmath184 be the number of partitions of @xmath185 with exactly @xmath9 parts .",
    "the @xmath186 , are computed using the recurrence @xmath187  @xcite . then @xmath188    next , we present our main algorithm .",
    "the following algorithm computes @xmath72 , where @xmath189 .",
    "the variables @xmath190 , @xmath191 , and @xmath192 are global .",
    "` function ` @xmath193    `    ` compute @xmath183 using  ( [ remarkpm ] )    `    ` @xmath194    `    ` @xmath195 0.9 in ( _ @xmath178 is stored in @xmath196 _ )    `    summation`@xmath197    ` function summation`@xmath147    `    ` @xmath198 2.3 in ( _ defaults to @xmath149 for @xmath150 _ )    `    for ` @xmath199    `      if ` @xmath200 ` then ` @xmath201    `      else ` @xmath202    `      endif `    `      ` @xmath203 1.65 in ( _ where @xmath152 is the right hand side of _ ( [ qkappaupdate ] ) )    `      if ` @xmath204 ` then `    `        ` @xmath205    `      endif `    `      for ` @xmath206 ` do jack`@xmath2071.4 in ( _ computes @xmath208 _ )    `      endfor `    `      ` @xmath209    `      if ` @xmath210 ` then `    `        summation`@xmath156    `      endif `    `    endfor `    ` function jack`@xmath211    `    for ` @xmath212    `      if ` @xmath213    `        ` @xmath214    `        ` @xmath215 compute @xmath216 using  ( [ remu ] )    `        ` update @xmath25 using  ( [ betakappamuupdate ] )    `        if ` @xmath217 ` then jack`@xmath218    `        else `",
    "@xmath219    `        endif `    `        ` @xmath220    `      endif `    `    endfor `    `    if ` @xmath221 ` then ` @xmath222    `    else ` @xmath223    `    endif `    [ alg_hg ]    algorithm  [ alg_hg ] generates all partitions @xmath28 with at most @xmath42 parts analogously to algorithm  [ alg_hgi ] .",
    "the parameter @xmath158 in ` summation ` is now just @xmath87 .    for every @xmath34 the function `",
    "jack ` recursively generates all partitions @xmath41 such that @xmath106 is a horizontal strip .",
    "the jack function is computed using  ( [ jackmain ] ) ; @xmath25 is updated using  ( [ betakappamuupdate ] ) .",
    "the parameter @xmath224 equals @xmath225 at all times .      in our implementation of algorithms",
    "[ alg_hgi ] and  [ alg_hg ] in  @xcite we made a few fairly straightforward , but important improvements :    1 .",
    "we precompute the values of @xmath226 for @xmath227 , and @xmath228 ; 2 .",
    "we keep and update the conjugate partitions @xmath229 and @xmath230 along with @xmath34 and @xmath40 , so we never need to recover @xmath229 and @xmath230 when computing  ( [ qkappaupdate ] ) and  ( [ betakappamuupdate ] ) ; 3 .",
    "when two sets of arguments ( @xmath231 and @xmath232 ) are passed , the hypergeometric function of two matrix arguments , ( [ hgxy ] ) , is computed ; 4 .",
    "if a vector @xmath233 is passed as a parameter in algorithm  [ alg_hgi ] , the output is also a vector with the values of @xmath234 for @xmath235",
    "algorithm  [ alg_hgi ] ( the case @xmath236 ) costs @xmath237 arithmetic operations ( where again , @xmath183 is the number of partitions @xmath34 , @xmath28 with at most @xmath42 parts ) .    to bound the complexity of algorithm  [ alg_hg ] ( general case ) we observe that the formula  ( [ jackmain ] ) represents the summation of at most @xmath183 terms ( in fact a lot less , but we have been unable to obtain a better bound than @xmath183 that is easy to work with ) .",
    "we use  ( [ jackmain ] ) to compute the jack function @xmath238 for all @xmath28 and @xmath239 , i.e. , @xmath240 jack functions , each of which costs at most @xmath237 arithmetic operations .",
    "the overall cost of algorithm  [ alg_hg ] is thus bounded by @xmath241    there is no explicit formula for @xmath183 , so we use ramanujan s asymptotic formula  @xcite for number of partitions of @xmath36 @xmath242 to obtain @xmath243 therefore the complexity of algorithm  [ alg_hg ] is _ linear _ in @xmath42 and subexponential in  @xmath36 .",
    "we performed extensive numerical tests to verify the correctness and complexity of our algorithms  [ alg_hgi ] and  [ alg_hg ] .",
    "we compared the output of our algorithms for @xmath244 and @xmath245 with explicit expressions ( subsection [ sec_explicit ] ) .",
    "we also compared the probability distributions of the eigenvalues of certain random matrices ( which are expressed as hypergeometric functions ) against the results of monte  carlo experiments ( subsection [ sec_numexp_2 ] ) .",
    "finally , we present performance results in subsection  [ sec_numexp_complexity ] .",
    "we compared the output of algorithms  [ alg_hgi ] and  [ alg_hg ] against the expressions  @xcite : @xmath246 for @xmath247 and random uniformly distributed values @xmath248 $ ] , @xmath227 .",
    "for @xmath249 it took less than one second per test .",
    "the results agreed to at least @xmath250 decimal digits with  ( [ 0f0_s ] ) , and at least @xmath251 decimal digits with  ( [ 1f0_s ] ) , reflecting the slower convergence of  ( [ 1f0_s ] ) .",
    "we tested algorithms  [ alg_hgi ] and  [ alg_hg ] against the eigenvalue statistics of the @xmath252-laguerre and wishart matrices .",
    "the @xmath3 _ @xmath252-laguerre matrix _ of parameter @xmath253 is defined as @xmath254 , where @xmath255 } , \\;\\;\\ ; a>\\frac{\\beta}{2}(n-1).\\ ] ]    the @xmath3 _ wishart matrix _ with @xmath256 degrees of freedom ( @xmath257 ) and covariance matrix @xmath258 , @xmath259 , is defined as @xmath260 , where @xmath261 for @xmath262 ; @xmath263 .",
    "the eigenvalue distributions of @xmath264 and @xmath265 are the same when @xmath266 or @xmath58 , @xmath267 , and @xmath268 .",
    "the cumulative distribution functions of the largest eigenvalues , @xmath269 and @xmath270 , of @xmath265 and @xmath264 , are @xmath271 respectively ( * ? ? ?",
    "* thm .  10.2.1 ,",
    "p.  147 ) , ( * ? ?",
    "9.7.1 , p.  420 ) , where @xmath272 , and @xmath273 is the _ multivariate gamma function of parameter @xmath19 _ :",
    "@xmath274 we use the _ kummer relation _",
    "* thm .  7.4.3 , p.  265 ) @xmath275 to obtain the equivalent , but numerically more stable expressions @xmath276 which we plot on figure  [ fig_example1 ] along with the monte ",
    "carlo results from a sample of 10000 random matrices .",
    "next we consider the distribution of the smallest eigenvalue of @xmath265 and that of @xmath277 .",
    "if @xmath278 is a nonnegative integer , then the probability density function of the smallest eigenvalue of @xmath265 is ( see , e.g. ,  ( * ? ? ?",
    "* thm .  10.1.1 , p.  146 ) ) : @xmath279 since @xmath280 is a nonpositive integer , the series expansion of @xmath281 in ( [ example1 ] ) terminates , even though it diverges in general .",
    "the probability density function of @xmath277 is @xmath282 where @xmath283 and @xmath284 is arbitrary  @xcite .",
    "we follow the suggestion by muirhead to use @xmath285 , where @xmath286 and @xmath287 are the largest and smallest eigenvalues of @xmath258 , respectively .",
    "although the expression  ( [ tra ] ) is not a hypergeometric function of a matrix argument , its truncation for @xmath28 has the form  ( [ gx ] ) , and is computed analogously .",
    "we plot  ( [ example1 ] ) and  ( [ tra ] ) on figure  [ fig_example2 ] and compare the theoretical predictions of these formulas with experimental data .      in figure  [ fig_example3 ] we demonstrate the efficiency of algorithms [ alg_hgi ] and [ alg_hg ] on an 1.8ghz intel pentium 4 machine .    in the left plot we present the performance data for algorithm  [ alg_hgi ] ( whose complexity is independent of the size @xmath42 of the matrix @xmath236 ) .",
    "its efficiency is evident  we need to sum beyond partitions of size @xmath288 before this algorithm takes a full second ( for reference , the @xmath289 in the denominator of the @xmath34-term in  ( [ hg1 ] ) then reaches up to @xmath290 ) .",
    "algorithm  [ alg_hg ] is also very efficient .",
    "the right plot of figure  [ fig_example3 ] demonstrates clearly its linear complexity in @xmath42 .",
    "it also takes at most a few seconds on matrices of size @xmath291 and partitions of size @xmath292 .",
    "we have presented new algorithms for computing the truncation of the hypergeometric function of a matrix argument .",
    "they exploit the combinatorial properties of the pochhammer symbol and the jack function to achieve remarkable efficiency , and have lead to new results  @xcite .",
    "several problems remain open , among them automatic detection of convergence .",
    "the @xmath34-term in  ( [ hg3 ] ) does approach zero as @xmath35 , but it need not monotonically decrease .",
    "although we have @xmath293 in  ( [ qkappaupdate ] ) , it is not always true that @xmath294 , and it is unclear how to tell when convergence sets in .",
    "another open problem is to determine the best way to truncate the series  ( [ hg1 ] ) . our choice to truncate it for @xmath28 seems to work well in practice , but one can imagine selecting a partition @xmath284 and truncating for @xmath295 instead of , or in addition to @xmath28 .",
    "we thank brian sutton and per - olof persson for several discussions that resulted in the simplification of the implementation of our algorithms , as well as the anonymous referee for the useful comments , which lead to improvements in the exposition .",
    "h.  gao , p.j .",
    "smith , and m.v .",
    "clark , _ theoretical reliability of mmse linear diversity combining in rayleigh - fading additive interference channels _ , ieee transactions on communications * 46 * ( 1998 ) , no .  5 , 666672 .",
    "r.  gutirrez , j.  rodriguez , and a.  j. sez , _ approximation of hypergeometric functions with matricial argument through their development in series of zonal polynomials _ , electron .",
    "11 * ( 2000 ) , 121130 ."
  ],
  "abstract_text": [
    "<S> we present new algorithms that efficiently approximate the hypergeometric function of a matrix argument through its expansion as a series of jack functions . our algorithms exploit the combinatorial properties of the jack function , and have complexity that is only linear in the size of the matrix . </S>"
  ]
}