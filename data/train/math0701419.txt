{
  "article_text": [
    "in sequential decision problems a decision maker ( or forecaster ) tries to predict the outcome of a certain unknown process at each ( discrete ) time instance and takes an action accordingly .",
    "depending on the outcome of the predicted event and the action taken , the decision maker receives a reward . very often , probabilistic modeling of the underlying process is difficult . for such situations",
    "the prediction problem can be formalized as a repeated game between the decision maker and the environment .",
    "this formulation goes back to the 1950 s when hannan  @xcite and blackwell  @xcite showed that the decision maker has a randomized strategy that guarantees , regardless of the outcome sequence , an average asymptotic reward as high as the maximal reward one could get by knowing the empirical distribution of the outcome sequence in advance .",
    "such strategies are called _ hannan consistent_. to prove this result , hannan and blackwell assumed that the decision maker has full access to the past outcomes .",
    "this case is termed the _ full information _ or the _ perfect monitoring _ case . however , in many important applications , the decision maker has limited information about the past elements of the sequence to be predicted .",
    "various models of limited feedback have been considered in the literature .",
    "perhaps the best known of them is the so - called _ multi - armed bandit problem _ in which the forecaster is only informed of its own reward but not the actual outcome ; see baos  @xcite , megiddo  @xcite , foster and vohra  @xcite , auer , cesa - bianchi , freund , and schapire  @xcite , hart and mas colell  @xcite .",
    "for example , it is shown in @xcite that hannan consistency is achievable in this case as well .",
    "sequential decision problems like the ones considered in this paper have been studied in different fields under various names such as repeated games , regret minimization , on - line learning , prediction of individual sequences , and sequential prediction .",
    "the vocabulary of different sub - communities differ .",
    "ours is perhaps closest to that used by learning theorists . for a general introduction and survey of the sequential prediction problem",
    "we refer to cesa - bianchi and lugosi @xcite .",
    "in this paper we consider a general model in which the information available to the forecaster is a general given ( possibly randomized ) function of the outcome and the decision of the forecaster .",
    "it is well understood under what conditions hannan consistency is achievable in this setup , see piccolboni and schindelhauer @xcite and cesa - bianchi , lugosi , and stoltz @xcite . roughly speaking ,",
    "this is possible whenever , after suitable transformations of the problem , the reward matrix can be expressed as a linear function of the matrix of ( expected ) feedback signals .",
    "however , this condition is not always satisfied and then the natural question is what the best achievable performance for the decision maker is .",
    "this question was answered by rustichini @xcite who characterized the maximal achievable average reward that can be guaranteed asymptotically for all possible outcome sequences ( in an almost sure sense ) .    however , rustichini s proof of achievability is not constructive .",
    "it uses abstract _ approachability _",
    "theorems due to mertens , sorin , and zamir @xcite and it seems unlikely that his proof method can give rise to computationally efficient prediction algorithms , as noted in the conclusion of @xcite",
    ". a simplified efficient approachability - based strategy in the special case where the feedback is a function of the action of nature alone was shown in mannor and shimkin @xcite . in the general case",
    ", the simplified approachability - based strategy of @xcite falls short of the maximal achievable average reward characterized by rustuchini @xcite .",
    "the goal of this paper is to develop computationally efficient forecasters in the general prediction problem under imperfect monitoring that achieve the best possible asymptotic performance .",
    "we introduce several forecasting strategies that exploit some specific properties of the problem at hand .",
    "we separate four cases , according to whether the feedback signal only depends on the outcome or both on the outcome and the forecaster s action and whether the feedback signal is deterministic or not .",
    "we design different prediction algorithms for all four cases .    as a by - product",
    ", we also obtain finite - horizon performance bounds with explicit guaranteed rates of convergence in terms of the number @xmath0 of rounds the prediction game is played . in the case of",
    "deterministic feedback signals these rates are optimal up to logarithmic factors . in the random feedback signal case",
    "we do not know if it is possible to construct forecasters with a significantly smaller regret .",
    "a motivating example for such a prediction problem arises naturally in multi - access channels that are prevalent in both wired and wireless networks . in such networks , the communication medium is shared between multiple decision makers .",
    "it is often technically difficult to synchronize between the decision makers .",
    "channel sharing protocols , and , in particular , several variants of spread spectrum , allow multiple agents to use the same channel ( or channels that may interfere with each other ) simultaneously . more specifically , consider a wireless system where multiple agents can choose in which channel to transmit data at any given time .",
    "the quality of each channel may be different and interference from other users using this channel ( or other `` close '' channels ) may affect the base - station reception .",
    "the transmitting agent may choose which channel to use and how much power to spend on every transmission .",
    "the agent has a tradeoff between the amount of power wasted on transmission and the cost of having its message only partially received .",
    "the transmitting agent may not receive immediate feedback on how much data were received in the base station ( even if feedback is received , it often happens on a much higher layer of the communication protocol ) .",
    "instead , the transmitting agent can monitor the transmissions of the other agents .",
    "however , since the transmitting agent is physically far from the base - station and the other agents , the information about the channels chosen by other agents and the amount of power they used is imperfect .",
    "this naturally abstracts to an online learning problem with imperfect monitoring .",
    "the paper is structured as follows . in the next section",
    "we formalize the prediction problem we investigate , introduce the target quantity , that is , the best achievable reward , and the notion of regret . in section [ subgrad ]",
    "we describe some analytical properties of a key function @xmath1 , defined in section [ setup ] .",
    "this function represents the worst possible average reward for a given vector of observations and is needed in our analysis . in section [ aa ]",
    "we consider the simplest special case when the actions of the forecaster do not influence the feedback signal , which is , moreover , deterministic .",
    "this case is basically as easy as the full information case and we obtain a regret bound of the order of @xmath2 ( with high probability ) where @xmath0 is the number of rounds of the prediction game . in section [ ba ]",
    "we study random feedback signals but still with the restriction that it is only determined by the outcome .",
    "here we are able to obtain a regret of the order of @xmath3 .",
    "the most general case is dealt with in section [ bb ] .",
    "the forecaster introduced there has a regret of the order of @xmath4 .",
    "finally , in section [ ab ] we show that this may be improved to @xmath5 in the case of deterministic feedback signals , which is known to be optimal ( see @xcite ) .",
    "the randomized prediction problem is described as follows . consider a sequential decision problem in which a forecaster has to predict an outcome that may be thought of as an action taken by the environment .    at each round , @xmath6",
    ", the forecaster chooses an action @xmath7 and the environment chooses an action @xmath8 ( which we also call an `` outcome '' ) .",
    "the forecaster s reward @xmath9 is the value of a reward function @xmath10 $ ] .",
    "now suppose that , at the @xmath11-th round , the forecaster chooses a probability distribution @xmath12 over the set of actions , and plays action @xmath13 with probability @xmath14 .",
    "we denote the forecaster s ( random ) action at time @xmath11 by @xmath15 .",
    "if the environment chooses action @xmath16 , then the reward of the forecaster is @xmath17 .",
    "the prediction problem is defined as follows :    note in particular that the environment may react to the forecaster s strategy by using a possibly randomized strategy .",
    "below , the probabilities of the considered events are taken with respect to the forecaster s and the environment s randomized strategies .",
    "the goal of the forecaster is to minimize the average regret and to enforce that @xmath18 that is , the per - round realized differences between the cumulative reward of the best fixed strategy @xmath19 , in hindsight , and the reward of the forecaster , are asymptotically non positive .",
    "denoting by @xmath20 the linear extension of the reward function @xmath21 , the hoeffding - azuma inequality for sums of bounded martingale differences ( see @xcite , @xcite ) , implies that for any @xmath22 , with probability at least @xmath23 , @xmath24 so it suffices to study the average expected reward @xmath25 .",
    "hannan  @xcite and blackwell  @xcite were the first to show the existence of a forecaster whose regret is @xmath26 for all possible behaviors of the opponent .",
    "here we mention a simple yet powerful forecasting strategy known as the _ exponentially weighted average _ forecaster .",
    "this forecaster selects , at time @xmath11 , an action @xmath15 according to the probabilities @xmath27 where @xmath28 is a parameter of the forecaster .",
    "one of the basic well - known results in the theory of prediction of individual sequences states that the regret of the exponentially weighted average forecaster is bounded as @xmath29 with the choice @xmath30 the upper bound becomes @xmath31 .",
    "different versions of this result have been proved by littlestone and warmuth  @xcite , vovk  @xcite , cesa - bianchi , freund , haussler , helmbold , schapire , and warmuth  @xcite , cesa - bianchi  @xcite , see also cesa - bianchi and lugosi  @xcite .    in this paper",
    "we are concerned with problems in which the forecaster does not have access neither to the outcomes @xmath32 nor to the rewards @xmath33 .",
    "the information available to the forecaster at each round is called the _",
    "feedback signal_. these feedback signals may depend on the outcomes @xmath32 only or on the action ",
    "outcome pairs @xmath34 and may be deterministic or drawn at random . in the simplest case when the feedback signal is deterministic , the information available to the forecaster is @xmath35 , given by a fixed ( and known ) deterministic feedback function @xmath36 where @xmath37 is the finite set of signals . in the most general case ,",
    "the feedback signal is governed by a random feedback function of the form @xmath38 where @xmath39 is the set of probability distributions over the signals .",
    "the received feedback signal @xmath40 is then drawn at random according to the probability distribution @xmath41 by using an external independent randomization .    to make notation uniform throughout the paper , we identify a deterministic feedback function @xmath36 with the random feedback function @xmath38 which",
    ", to each pair @xmath42 , assigns @xmath43 where @xmath44 is the probability distribution concentrated on the single element @xmath45 .",
    "the sequential prediction problem under imperfect monitoring is formalized in figure  [ figgame ] .    in many interesting situations",
    "the feedback signal the forecaster receives is independent of the forecaster s action and only depends on the outcome , that is , for all @xmath46 , @xmath47 is constant . in other words",
    ", @xmath48 depends on the outcome @xmath32 but not on the forecaster s action @xmath15 .",
    "we will see that the prediction problem becomes significantly simpler in this special case . to simplify notation in this case , we write @xmath49 for the feedback signal at time @xmath11 ( @xmath50 in case of deterministic feedback signals ) .",
    "this setting includes the full - information case ( when the outcomes @xmath32 are revealed ) but also the case of noisy observations ( when a random variable with distribution depending only on @xmath32 is observed ) , see weissman and merhav  @xcite , weissman , merhav , and somekh - baruch  @xcite .",
    "next we describe a reasonable goal for the forecaster and define the appropriate notion of consistency . to this end",
    ", we introduce some notation .",
    "if @xmath51 and @xmath52 are probability distributions over @xmath53 and @xmath54 , respectively , then , with a slight abuse of notation , we write @xmath55 for the linear extension of the reward function @xmath21 . we also extend linearly the random feedback function in its second argument : for a probability distribution @xmath52 over @xmath54 , define the vector in @xmath39 @xmath56 denote by @xmath57 the convex set of all @xmath58-vectors @xmath59 of probability distributions obtained this way when @xmath60 varies .",
    "( @xmath61 is the set of feasible distributions over the signals ) . in the case",
    "when the feedback signals only depend on the outcome , all components of this vector are equal and we denote their common value by @xmath62 .",
    "we note that in the general case , the set @xmath57 is the convex hull of the @xmath63 vectors @xmath64 .",
    "therefore , performing a euclidean projection on @xmath57 can be done efficiently using quadratic programming .    to each probability distribution @xmath65 over @xmath53 and probability distribution @xmath66 , we may assign the quantity @xmath67 which is the reward guaranteed by the mixed action @xmath65 of the forecaster against any distribution of the outcomes that induces the given distribution of feedback signals @xmath68 .",
    "note that @xmath69 $ ] and that @xmath1 is concave in @xmath65 ( since it is an infimum of linear functions ; since this infimum is taken on a convex set , the infimum is indeed a minimum ) .",
    "finally , @xmath1 is also convex in @xmath68 as the condition defining the minimum is linear in @xmath68 .    to define the goal of the forecaster , let @xmath70 denote the empirical distribution of the outcomes @xmath71 up to round @xmath0 .",
    "this distribution may be unknown to the forecaster since the forecaster observes the signals rather than the outcomes .",
    "the best the forecaster can hope for is an average reward close to @xmath72 . indeed , even if @xmath73 was known beforehand , the maximal expected reward for the forecaster would be @xmath72 , simply because without any additional information the forecaster can not hope to do better than against the worst element which is equivalent to @xmath60 as far as the signals are concerned .",
    "based on this argument , the ( per - round ) regret @xmath74 is defined as the average difference between the obtained cumulative reward and the target quantity described above , that is , @xmath75 rustichini @xcite proves the existence of a forecasting strategy whose per - round regret is guaranteed to satisfy @xmath76 with probability one , for all possible imperfect monitoring problems .",
    "rustichini s proof is not constructive but in several special cases constructive and computationally efficient prediction algorithms have been proposed . among the partial solutions proposed so far ,",
    "we mention piccolboni and schindelhauer @xcite and cesa - bianchi , lugosi , and stoltz @xcite who study the case when @xmath77 in this case strategies with a vanishing per - round regret are called _",
    "hannan consistent_. in such cases the feedback is sufficiently rich so that one may achieve the same asymptotic reward as in the full information case , although the rate of convergence may be slower .",
    "this case turns out to be considerably simpler to handle than the general problem and computationally tractable explicit algorithms have been derived . also , it is shown in @xcite that in this case it is possible to construct strategies whose regret decreases at a rate of @xmath78 ( with high probability ) and that this rate of convergence can not be improved in general .",
    "( note that hannan consistency is achievable , for example , in the adversarial multi - armed bandit problem , see remark  [ rkhc ] in the appendix . ) mannor and shimkin @xcite construct an approachability - based algorithm with vanishing regret for the special case where the feedback signals depend only on the outcome .",
    "in addition , mannor and shimkin discuss the more general case of feedback signals that depend on both the action and the outcome and provide an algorithm that attains a relaxed goal comparing to the one attained in this work .",
    "the following example demonstrates the structure of the model .",
    "[ exmpl:2x3game]consider the simple game where @xmath79 , @xmath80 , @xmath81 , and the reward and feedback functions are as follows .",
    "the reward function is described by the matrix @xmath82\\ ] ] to identify the possible distributions of the feedback signals we need to specify some elements of @xmath83 .",
    "we describe such a member of @xmath83 by the probability of observing @xmath84 .",
    "the feedback function is parameterized by some @xmath85 and is then given by @xmath86~.\\ ] ] in words , outcome @xmath87 leads to a deterministic feedback signal of @xmath84 , outcome @xmath88 leads to a deterministic feedback signal of @xmath89 , and outcome @xmath90 leads to a feedback signal of @xmath84 with probability @xmath91 and @xmath89 with probability @xmath92 .",
    "note that the feedback signals depend only on the outcome and not on the action taken .",
    "we recall that @xmath68 , as a member of @xmath83 , is identified with the probability of observing the feedback signal @xmath84 and it follows that @xmath93 is the interval @xmath94 $ ] .",
    "we now compute the function @xmath1 . letting @xmath95 denote the probability of selecting the first action ( i.e. , @xmath96 ) , we have @xmath97 optimizing over @xmath95 , we obtain @xmath98 the intuition here is that for @xmath99 there is certainty that the outcome is @xmath87 so that an action of @xmath100 is optimal .",
    "for @xmath101 the forecaster does not know if the outcome was consistently @xmath90 or some mixture of outcomes @xmath87 and @xmath88 . by playing the second action , the forecaster can guarantee a reward of @xmath102 .",
    "the function @xmath103 is depicted in figure [ fig : rhomax ] .",
    "for example [ exmpl:2x3game ] .",
    "[ fig : rhomax],width=340,height=224 ]    in this paper we construct simple and computationally efficient strategies whose regret vanishes with probability one . the main idea behind the forecasters we introduce in the next sections",
    "is based on the gradient - based strategies described , for example , in cesa - bianchi and lugosi ( * ? ? ?",
    "* section 2.5 ) .",
    "our forecasters use sub - gradients of concave functions . in the next section we briefly recall some basic facts on the existence , computation , and boundedness of these sub - gradients .",
    "for a concave function @xmath104 defined over a convex subset of @xmath105 , a vector @xmath106 is a sub - gradient of @xmath104 at @xmath107 if @xmath108 for all @xmath109 in the domain of @xmath104 .",
    "we denote by @xmath110 the set of sub - gradients of @xmath104 at @xmath107 which is also known as the sub - differential .",
    "sub - gradients always exist , that is , @xmath110 is non - empty in the interior of the domain of a concave function . in this paper , we are interested in sub - gradients of concave functions of the form @xmath111 , where @xmath112 is an observed or estimated distribution of feedback signal at round @xmath11 .",
    "( for instance , in section  [ aa ] , @xmath113 is observed , in the other sections , it will be estimated . ) in view of the exponentially weighted update rules that are used below , we only evaluate these functions in the interior of the definition domain ( the simplex ) .",
    "thus , the existence of sub - gradients is ensured throughout .    in the general case ,",
    "sub - gradients may be computed efficiently by the simplex method .",
    "however , their computation is often even simpler , as in the case described in section  [ aa ] , that is , when one faces deterministic feedback signals not depending on the actions of the forecaster .",
    "indeed , at round @xmath11 , it is trivial whenever @xmath114 is differentiable at the considered point @xmath115 since it is differentiable exactly at those points at which it is locally linear , and thus the gradient equals the column of the reward matrix corresponding to the outcome @xmath116 for which @xmath117 . but because @xmath118 is concave , the lebesgue measure of the set where it is non - differentiable equals zero",
    ". it thus suffices to resort to the simplex method only at these points to compute the sub - gradients .",
    "note that the components of the sub - gradients are always bounded by a constant that depends on the game parameters .",
    "this is the case since the @xmath119 are concave and continuous on a compact set and are therefore lipschitz , leading to a bounded sub - gradient . in the sequel",
    ", we denote by @xmath120 the value @xmath121 where @xmath122 denotes the sub - gradient at @xmath65 of the concave function @xmath123 with @xmath68 fixed .",
    "this constant depends on the specific parameters of the game .",
    "since the parameters of the game are supposed to be known to the forecaster , in principle , the forecaster can compute the value of @xmath120 . in any case , the value of @xmath120 can be bounded by the supremum norm of the payoff function as the following lemma asserts .",
    "[ le : klessthan1 ] the constant @xmath120 satisfies @xmath124 .",
    "fix @xmath68 and consider @xmath125 . define @xmath126 as the linear extension - restriction of @xmath21 to @xmath127 , that is @xmath128 .",
    "further , let @xmath129 .",
    "it follows that under our notation , for any probability distribution @xmath65 , one has @xmath130 .",
    "now , from danskin s theorem ( see , e.g. , bertsekas @xcite ) we have that the sub - differential satisfies @xmath131 where @xmath132 denotes the convex hull of a set @xmath133 .",
    "since @xmath134 $ ] , it follows that @xmath135 for all @xmath136 . since the convex hull does not increase the infinity norm , the result follows .",
    "the constant @xmath120 for the game described in example [ exmpl:2x3game ] is @xmath102 . however , the gradient of the function @xmath137 as a function of @xmath68 is @xmath138 .",
    "this happens because the @xmath65 that attains the maximum changes rapidly in the interval @xmath139 $ ] .",
    "we further note that @xmath120 may be much smaller than 1 .",
    "since our regret bounds below depend on @xmath120 linearly , having a tighter bound on @xmath120 can lead to considerable convergence rate speedup ; see remark [ r : eta ] .",
    "we start with the simplest case when the feedback signal is deterministic and does not depend on the action @xmath15 of the forecaster . in other words , after making the prediction at time @xmath11 , the forecaster observes @xmath140 .",
    "this simplifying assumption may be naturally satisfied in applications in which the forecaster s decisions do not effect the environment .    in this case ,",
    "we group the outcomes according to the deterministic feedback signal they are associated to .",
    "each signal @xmath141 is uniquely associated to a group of outcomes .",
    "this situation is very similar to the case of full monitoring except that rewards are measured by @xmath1 and not by @xmath21 .",
    "this does not pose a problem since @xmath21 is lower bounded by @xmath1 in the sense that for all @xmath65 and @xmath142 , @xmath143 as mentioned in the previous section , we introduce a forecaster based on the sub - gradients of @xmath118 , @xmath144 .",
    "the forecaster requires a tuning parameter @xmath145 .",
    "the @xmath13-th component of @xmath115 is @xmath146 where @xmath147 is the @xmath13-th component of any sub - gradient @xmath148 of the concave function @xmath149 .",
    "this forecaster is inspired by a gradient - based predictor introduced by kivinen and warmuth @xcite .",
    "the regret is bounded as follows .",
    "note that the following bound and the considered forecaster coincide with those of ( [ expertsthm ] ) in case of perfect monitoring .",
    "( in that case , @xmath150 , the sub - gradients are given by @xmath21 . )    [ prop : aa ] for all @xmath145 , for all strategies of the environment , for all @xmath151 , the above strategy of the forecaster ensures that , with probability at least @xmath152 , @xmath153 where @xmath120 is the bound on the sub - gradients considered above . in particular , choosing @xmath154 yields @xmath155 .",
    "[ r : eta ] the optimal choice of @xmath156 in the upper bound is @xmath157 , which depends on the parameters @xmath120 and @xmath0 . while the bound @xmath158 is available , this bound might be loose .",
    "sometimes the forecaster does not necessarily know in advance the number of prediction rounds and/or the value of @xmath120 may be difficult to compute . in such cases",
    "one may estimate on - line both the number of time rounds and @xmath120 , using the techniques of auer , cesa - bianchi , and gentile  @xcite and cesa - bianchi , mansour , and stoltz  @xcite as follows .",
    "writing @xmath159 and introducing a round - dependent choice of the tuning parameter @xmath160 for a properly chosen constant @xmath161 , one may prove a regret bound that is a constant multiple of @xmath162 ( that hold with probability at least @xmath23 ) . since the proof of this is a straightforward combination of the techniques of the above - mentioned papers and our proof ,",
    "the details are omitted .",
    "note that since the feedback signals are deterministic , @xmath163 takes the simple form @xmath164 .",
    "now , for any @xmath65 , @xmath165 where at the last step we used the fact that the forecaster is just the exponentially weighted average predictor based on the rewards @xmath166 and that all these reward vectors have components between @xmath167 and @xmath120 . the proof is concluded by the hoeffding - azuma inequality , which ensures that , with probability at least @xmath168 , @xmath169",
    "next we consider the case when the feedback signals do not depend on the forecaster s actions , but , at time @xmath11 , the signal @xmath40 is drawn at random according to the distribution @xmath170 . in this case",
    "the forecaster does not have a direct access to @xmath171 anymore , but only observes the realizations @xmath40 drawn at random according to @xmath170 . in order to overcome this problem ,",
    "we group together several consecutive time rounds ( say , @xmath172 of them ) and estimate the probability distributions according to which the signals have been drawn .    to this end , denote by @xmath173 the euclidean projection onto @xmath174 ( since the feedback signals depend only on the outcome we may now view the set @xmath174 of feasible distributions over the signals as a subset of @xmath83 , the latter being identified with a subset of @xmath175 in a natural way ) .",
    "let @xmath172 , @xmath176 , be a parameter of the algorithm . for @xmath177",
    ", we denote @xmath178 for the sake of the analysis , we also introduce @xmath179 the proposed strategy is described in figure [ figba ] .",
    "observe that the practical implementation of the forecaster only requires the computation of ( sub)gradients and of @xmath180 projections , which can be done in polynomial time .",
    "the next theorem bounds the regret of the strategy which is of the order of @xmath3 .",
    "the price we pay for having to estimate the distribution is thus a deteriorated rate of convergence ( from the @xmath181 obtained in the case of deterministic feedback signals ) .",
    "we do not know whether this rate can be improved significantly as we do not know of any nontrivial lower bound in this case .",
    "[ th : randomoutcomeonly ] for all integers @xmath182 , for all @xmath145 , and for all @xmath151 , the regret for any strategy of the environment is bounded , with probability at least @xmath183 , by @xmath184 where @xmath158 and @xmath185 are constants that depend only on the parameters of the game .",
    "the choices @xmath186 and @xmath187 imply @xmath188 with probability of at least @xmath23 .    here again , @xmath120 and @xmath185 may , in principle , be computed or bounded ( see lemma [ le : klessthan1 ] and remark  [ rem : boundl ] ) by the forecaster . if the horizon @xmath0 is known in advance ( as it is assumed in this paper ) , the values of @xmath156 and @xmath172 may be chosen to optimize the upper bound for the regret . observe that while one always have @xmath158 , the value of @xmath185 ( i.e. , the lipschitz constant of @xmath1 in its second argument ) can be arbitrarily large , see example [ exmpl:2x3game ] . if the horizon @xmath0 is unknown at the start of the game , the situation is not as simple as in section [ aa ] ( see remark  [ r : eta ] ) , because now a time - dependent choice of @xmath156 needs to be accompanied by an adaptive choice of the parameter @xmath172 as well . a simple , though",
    "not very attractive , solution is the so - called `` doubling trick '' ( see , e.g. , @xcite ) . according to this solution , time",
    "is divided into periods of exponentially growing length and in each period the forecaster is used as if the horizon was the length of the actual period . at the end of each period",
    "the forecaster is reset and started again with new parameter values .",
    "it is easy to see that this forecaster achieves the same regret bounds , up to a constant multiplier .",
    "we believe that a smoother solution should also work ( as in remark [ r : eta ] ) . since this seems like a technical endeavor we do not pursue this issue further .",
    "we start by grouping time rounds @xmath172 by @xmath172 . for simplicity , we assume that @xmath189 for some integer @xmath190 ; if this is not the case , we consider the lower integer part of @xmath0 and bound the regret suffered in the last at most @xmath191 rounds by @xmath172 ( this accounts for the @xmath192 term in the bound ) . for all @xmath65 , @xmath193 where we used the definition of the algorithm , convexity of @xmath1 in its second argument , and finally , the definition of @xmath1 as a minimum .",
    "we proceed by estimating @xmath194 by @xmath195 . by a version of the hoeffding - azuma inequality for sums of hilbert space - valued martingale differences proved by chen and white (",
    "* lemma 3.2 ) , and since the @xmath180 projection can only help , for all @xmath89 , with probability at least @xmath152 , @xmath196 by proposition [ prop : uniformlip ] , @xmath1 is uniformly lipschitz in its second argument ( with constant @xmath185 ) , and therefore we may further bound as follows . with probability @xmath197 ,",
    "@xmath198 the term containing @xmath199 is the first term in the upper bound .",
    "the remaining part is bounded by using the same slope inequality argument as in the previous section ( recall that @xmath200 denotes a sub - gradient ) , @xmath201 where we used theorem [ expertsthm ] and the boundedness of the function @xmath200 between @xmath167 and @xmath120 .",
    "the proof is concluded by the hoeffding - azuma inequality which , as in ( [ hazconcludes ] ) , gives the final term in the bound .",
    "the union bound indicates that the obtained bound holds with probability at least @xmath202 .",
    "we now turn to the general case , where the feedback signals are random and depend on the action  outcome pairs @xmath34 .",
    "the key is , again , to exhibit efficient estimators of the ( unobserved ) @xmath73 .",
    "denote by @xmath173 the projection , in the euclidian distance , onto @xmath174 ( where @xmath174 , as a subset of @xmath203 , is identified with a subset of @xmath204 ) .",
    "for @xmath177 , denote @xmath205_{i=1,\\ldots , n } \\right)\\ ] ] where the distribution @xmath206 of the random signal @xmath40 received by action @xmath13 at round @xmath11 is estimated by @xmath207 ( this form of estimators is reminiscent of those presented , e.g. , in @xcite . )",
    "we prove that the @xmath208 are conditionally unbiased estimators .",
    "denote by @xmath209 the conditional expectation with respect to the information available to the forecaster at the beginning of round @xmath11 .",
    "this conditioning fixes the values of @xmath115 and @xmath32 .",
    "thus , @xmath210 = \\frac{1}{p_{i , t } } \\ , { \\mathbbm{e}}_t \\left [ \\delta_{s_t } \\ind_{i_t = i } \\right ] = \\frac{1}{p_{i , t } } \\ , { \\mathbbm{e}}_t \\left [ h(i_t , j_t ) \\ind_{i_t = i } \\right ] = \\frac{1}{p_{i , t } } h(i , j_t ) p_{i , t } = h(i , j_t)~.\\ ] ] for the sake of the analysis , introduce @xmath211 the proposed forecasting strategy is described in figure [ figbb ] . the mixing with the uniform distribution",
    "is needed , similarly to the forecasters presented in @xcite , to ensure sufficient exploration of all actions .",
    "mathematically , such a mixing lower bounds the probability of pulling each action , which will turn to be crucial in the proof of theorem  [ th : randomactionoutcome ] .    here again , the practical implementation of the forecaster only requires the computation of ( sub)gradients and of @xmath180 projections , which can be done efficiently .",
    "the next theorem states that the regret in this most general case is at most of the order of @xmath4 .",
    "again , we do not know whether this bound can be improved significantly .",
    "we recall that @xmath120 denotes an upper bound on the infinity norm of the sub - gradients ( see lemma  [ le : klessthan1 ] ) .",
    "the issues concerning the tuning of the parameters considered in the following theorem are similar to those discussed after the statement of theorem  [ th : randomoutcomeonly ] ; in particular , the simplest way of being adaptive in all parameters is to use the  doubling trick \" .",
    "[ th : randomactionoutcome ] for all integers @xmath182 , for all @xmath145 , @xmath212 , and @xmath151 , the regret for any strategy of the environment is bounded , with probability at least @xmath213 , as @xmath214 where @xmath185 and @xmath215 are constants that depend on the parameters of the game .",
    "the choices @xmath216 , @xmath187 , and @xmath217 ensure that , with probability at least @xmath152 , @xmath218 .",
    "the proof is similar to the one of theorem  [ th : randomoutcomeonly ] .",
    "a difference is that we bound the accuracy of the estimation of the @xmath194 via a martingale analog of bernstein s inequality due to freedman @xcite rather than the hoeffding - azuma inequality .",
    "also , the mixing with the uniform distribution in the first step of the definition of the forecaster in figure  [ figbb ] needs to be handled .",
    "we start by grouping time rounds @xmath172 by @xmath172 .",
    "assume , for simplicity , that @xmath189 for some integer @xmath190 ( this accounts , again , for the @xmath192 term in the bound ) .",
    "as before , we get that , for all @xmath65 , @xmath219 and proceed by estimating @xmath194 by @xmath195 .",
    "inequality @xcite ( see , also , ( * ? ? ? * lemma a.1 ) ) implies that for all @xmath220 , @xmath221 , @xmath45 , and @xmath151 , @xmath222 where @xmath223 is the probability mass put on @xmath141 by @xmath208 and @xmath224 is the @xmath13-th component of @xmath194 .",
    "this is because the sums of the conditional variances are bounded as @xmath225 where the second inequality follows from the lower bound @xmath226 on the components of @xmath115 ( ensured by the mixing step in the definition of the forecaster ) . summing ( since the @xmath180 projection can only help )",
    ", the union bound shows that for all @xmath89 , with probability at least @xmath152 , @xmath227 by using uniform lipschitzness of @xmath1 in its second argument ( with constant @xmath185 ; see proposition  [ prop : uniformlip ] ) , we may further bound ( [ eq : nrhoboundedbymb ] ) with probability @xmath197 by @xmath228 the terms @xmath229 are the first two terms in the upper bound of the theorem .",
    "the remaining part is bounded by using the same slope inequality argument as in the previous section ( recall that @xmath200 denotes a sub - gradient bounded between @xmath167 and @xmath120 ) : @xmath230 finally , we deal with the mixing with the uniform distribution : @xmath231 the proof is concluded by the hoeffding - azuma inequality which , as in ( [ hazconcludes ] ) , gives the final term in the bound .",
    "the union bound indicates that the obtained bound holds with probability at least @xmath202 .",
    "in this last section we explain how in the case of deterministic feedback signals the forecaster of the previous section can be modified so that the order of magnitude of the per - round regret improves to @xmath78 .",
    "this relies on the linearity of @xmath1 in its second argument . in the case of random feedback signals",
    ", @xmath1 may not be linear and it is because of this fact that we needed to group rounds of size @xmath172 . if the feedback signals are deterministic , such grouping is not needed and the rate @xmath78 is obtained as a trade - off between an exploration term ( @xmath232 ) and the cost payed for estimating the feedback signals ( @xmath233 ) .",
    "this rate of convergence has been shown to be optimal in @xcite even in the hannan - consistent case .",
    "the key property is summarized in the next technical lemma , whose proof is postponed to the appendix .",
    "[ lmlin ] for every fixed @xmath65 , the function @xmath234 is linear on @xmath93 .",
    "the fact that the forecaster does not need to group rounds in the case of deterministic feedback signals has an interesting consequence .",
    "it is easy to see from the proofs of proposition  [ prop : aa ] and theorem  [ th : deterministicactionoutcome ] , through the linearity property stated above , that the results presented there are still valid when the payoff function @xmath21 may change with time ( even , when the environment can set it ) .",
    "the definition of the regret is then generalized as @xmath235 where @xmath236 is the empirical distribution of the sequence of outcomes @xmath237 , and the same bounds hold .",
    "this may model some more complex situations , including markov decision processes . note that choosing time - varying reward functions was not possible with the forecasters of @xcite , since these relied on a crucial structural assumption on the relation between @xmath21 and @xmath238 .",
    "next we describe the modified forecaster .",
    "denote by @xmath239 the vector space generated by @xmath240 and @xmath173 the linear operator which projects any element of @xmath241 onto @xmath239 .",
    "since the @xmath234 are linear on @xmath93 , we may extend them linearly to @xmath239 ( and with a slight abuse of notation we write @xmath1 for the extension ) . as a consequence ,",
    "the functions @xmath242 defined on @xmath243 are linear and coincide with the original definition on @xmath93 .",
    "we denote by @xmath200 a sub - gradient ( i.e. , for all @xmath244 , @xmath245 is a sub - gradient of @xmath246 ) .",
    "the sub - gradients are evaluated at the following points .",
    "( recall that since the feedback signals are deterministic , @xmath247 . ) for @xmath248 , let @xmath249_{i=1,\\ldots , n } = \\left [ \\frac{\\delta_{s_t}}{p_{i , t } } \\ind_{i_t = i } \\right]_{i=1,\\ldots , n}~.\\ ] ] the @xmath208 estimate the feedback signals @xmath250 received by action @xmath13 at round @xmath11 .",
    "they are still conditionally unbiased estimators of the @xmath251 , and so is @xmath252 for @xmath253 . the proposed forecaster is defined in figure [ figab ] and the regret bound is established in theorem  [ th : deterministicactionoutcome ] .",
    "[ th : deterministicactionoutcome ] there exists a constant @xmath161 only depending on @xmath21 and @xmath238 such that for all @xmath151 , @xmath212 , and @xmath145 , the regret for any strategy of the environment is bounded , with probability at least @xmath152 , as @xmath254 the choice @xmath255 and @xmath256 ensures that , with probability at least @xmath152 , @xmath257 .",
    "note that here , as in section  [ aa ] ( see remark  [ r : eta ] ) , the tuning of the parameters can be done efficiently on - line without resorting to the `` doubling trick . ''",
    "the optimization of the upper bound ( in both @xmath232 and @xmath156 ) requires the knowledge of @xmath58 , @xmath161 , @xmath120 , and @xmath0 .",
    "the first three parameters only depend on the game and are known or may be calculated beforehand ( the proof indicates an explicit expression for @xmath161 and the bound on the sub - gradients may be computed as explained in section  [ subgrad ] ) . if @xmath0 and/or @xmath120 are unknown , their tuning may be dealt with by taking time - dependent @xmath258 and @xmath259 .",
    "the proof is similar to the one of theorem  [ th : randomactionoutcome ] , except that we do not have to consider the grouping steps and that we do not apply the hoeffding - azuma inequality to the estimated feedback signals but to the estimated rewards . by the bound on @xmath21 in terms of @xmath1 and convexity ( linearity ) of @xmath1 in its second argument ,",
    "@xmath260 next we estimate @xmath261 by freedman s inequality ( see , again , ( * ? ? ? * lemma a.1 ) ) , since @xmath252 is a conditionally unbiased estimator of @xmath253 and all functions at hand are linear in their second argument , we get that , with probability at least @xmath262 , @xmath263 where , denoting by @xmath264 the column vector whose @xmath13-th component is @xmath43 and all other components equal 0 , @xmath265 \\right ) < + \\infty~.\\ ] ] ( a more precise look at the definition of @xmath161 shows that it is less than the maximal @xmath266 norm of the barycentric coordinates of the points @xmath267 $ ] with respect to the @xmath268 . ) this is because for all @xmath11 , the conditional variances are bounded as follows . for all @xmath269 , @xmath270 & = & \\sum_{i=1}^n p_{i , t } \\",
    ", \\rho \\left ( { \\boldsymbol{p } } ' , \\pi \\left [ { \\boldsymbol{e}}_i(\\delta_{h(i , j)}/p_{i , t } ) \\right ] \\right)^2 \\\\ & = & \\sum_{i=1}^n \\frac{1}{p_{i , t } } \\ , \\rho \\left ( { \\boldsymbol{p } } ' , \\pi \\left [ { \\boldsymbol{e}}_i(\\delta_{h(i , j)}/p_{i , t } ) \\right ] \\right)^2   \\leq   \\sum_{i=1}^n \\frac{c^2}{p_{i , t } } \\leq \\frac{c^2 n^2}{\\gamma}~.\\end{aligned}\\ ] ]    the remaining part is bounded by using the same slope inequality argument as in the previous sections ( recall that @xmath200 denotes a sub - gradient in the first argument of @xmath271 , bounded between @xmath167 and @xmath120 ) , @xmath272 finally , we deal with the mixing with the uniform distribution , @xmath273 as before , the proof is concluded by the hoeffding - azuma inequality ( [ hazconcludes ] ) and the union bound .",
    "the function @xmath274 is uniformly lipschitz in its second argument .",
    "[ prop : uniformlip ]    we consider the general case where the signal distribution depends on both the actions and outcomes .",
    "accordingly , we can write @xmath275 as the solution of the following linear program ( we denote @xmath276 , where , as usual , we identify each @xmath277 with a @xmath278-dimensional vector ) : @xmath279 where @xmath280 is an @xmath63-dimensional vector , @xmath281 is an @xmath63-dimensional vector of ones , and @xmath282 is the @xmath283 matrix , whose entry @xmath284 is the probability of observing signal @xmath141 when action @xmath285 is chosen and the outcome is @xmath142 .",
    "the program is feasible for every @xmath66 so by the duality theorem , @xmath286 \\ , { \\boldsymbol{y}}\\\\ \\\\ & \\mbox{s.t.\\ } &   \\left[h^1(\\cdot , j)^\\top \\ ,",
    "h^2(\\cdot , j)^\\top \\ , \\ldots \\ , h^n(\\cdot , j)^\\top \\ , 1 \\right ] \\ , { \\boldsymbol{y } } & \\leq \\,\\ , r({\\boldsymbol{p}},j)~ , \\quad j=1,2,\\ldots , m~ , \\\\ & & \\hfill { \\boldsymbol{y } } & \\geq \\,\\ ,",
    "0~ , \\end{array}\\ ] ] where we recall that @xmath287 is the @xmath288-dimensional vector whose @xmath141-th entry is the probability of observing signal @xmath141 if the action is @xmath285 and the outcome is @xmath142 .",
    "we first claim that @xmath289 is lipschitz for every fixed @xmath65 .",
    "indeed , for every fixed @xmath65 the optimization problem involves @xmath68 only through the objective function .",
    "we thus have that the solution to the optimization problem is obtained at one of finitely many values of @xmath109 ( the vertices of the feasible cone defined by the constraints of program ( [ eq : optproblem ] ) ) .",
    "( more precisely , the obtained cone may be unbounded if there are some unconstrained components of @xmath109 .",
    "this happens when there exists an @xmath141 such that @xmath290 for all @xmath142 .",
    "but then @xmath291 as well and we do not care about the unbounded component @xmath292 of @xmath109 . )",
    "since @xmath234 is a maximum of finitely many linear functions we obtain that it is lipschitz , with lipschitz constant bounded by the maximal @xmath266 norm of the vertices of the feasible cone of ( [ eq : optproblem ] ) .",
    "we now prove that the lipschitz constant is uniform with respect to @xmath65 .",
    "it suffices to consider the polytope defined by @xmath293 \\ , { \\boldsymbol{y}}\\leq 1 , \\quad j=1,2,\\ldots , m   \\right\\}~.\\ ] ] this is a cone , and the vertex @xmath109 with the maximum @xmath266 norm upper bounds the lipschitz constant of the @xmath234 , for all @xmath65 .",
    "( as before , any unbounded components of @xmath109 do not matter to the optimization problem . )",
    "[ rem : boundl ] observe from the proof that an upper bound on the uniform lipschitz constant can be easily computed by solving the following linear program , @xmath294 \\ , { \\boldsymbol{y } } & \\leq \\,\\",
    ", 1~ , \\quad j=1,2,\\ldots , m~ , \\\\ & & \\hfill { \\boldsymbol{y } } & \\geq \\,\\ , 0~. \\end{array}\\ ] ]",
    "it is equivalent to prove that for all fixed @xmath65 , the function @xmath295 is linear on the simplex .",
    "actually , the proof exhibits a simpler expression for @xmath1 .    to this end , we first group together the outcomes with same feedback signals and define a mapping @xmath296 where @xmath297 is the set of all probability distributions @xmath60 on the outcomes .",
    "formally , consider the binary relation defined by @xmath298 if and only if @xmath299 .",
    "( we use here the notation @xmath238 to emphasize that we deal with deterministic feedback signals . ) denote by @xmath300 the partition of the outcomes @xmath54 obtained so , and pick in every @xmath301 the outcome @xmath302 with minimal reward @xmath303 against @xmath65 ( ties can be broken arbitrarily , e.g. , by choosing the outcome with lowest index ) .",
    "then , for every @xmath60 , the distribution @xmath304 is defined as @xmath305 , for @xmath306 , and @xmath307 if @xmath308 for all @xmath142 .",
    "@xmath309 is a linear projection ( i.e. , @xmath310 ) .",
    "it is easy to see that in the case of deterministic feedback signals , @xmath311 if and only if @xmath312 .",
    "this implies that @xmath313 where the last equality follows from the fact that , by choices of the @xmath302 , @xmath314 for all @xmath315 , with equality for @xmath316 . by linearity of @xmath309 , @xmath317 is therefore linear itself , as claimed .",
    "note that the equivalence of @xmath311 and @xmath312 , together with ( [ exprerho ] ) , implies the following sufficient condition for hannan - consistency ( for necessary and sufficient conditions , see @xcite ) .",
    "it is more general than the distinguishing actions condition of @xcite ."
  ],
  "abstract_text": [
    "<S> we propose simple randomized strategies for sequential decision ( or prediction ) under imperfect monitoring , that is , when the decision maker ( forecaster ) does not have access to the past outcomes but rather to a feedback signal . </S>",
    "<S> the proposed strategies are consistent in the sense that they achieve , asymptotically , the best possible average reward among all fixed actions . </S>",
    "<S> it was rustichini @xcite who first proved the existence of such consistent predictors . </S>",
    "<S> the forecasters presented here offer the first constructive proof of consistency . moreover , the proposed algorithms are computationally efficient . </S>",
    "<S> we also establish upper bounds for the rates of convergence . in the case of deterministic feedback signals , </S>",
    "<S> these rates are optimal up to logarithmic terms . </S>"
  ]
}