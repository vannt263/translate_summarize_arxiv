{
  "article_text": [
    "research on machine learning has achieved great success on enhancing the models accuracy and efficiency .",
    "successful models such as support vector machines ( svms ) , random forests , and deep neural nets have been applied to vast industrial applications  @xcite . however , in many applications , users may need not only a prediction model , but also suggestions on courses of actions to achieve desirable goals . for practitioners , a complex model such as a random forest",
    "is often not very useful even if its accuracy is high because of its lack of actionability . given a learning model , extraction of actionable knowledge entails finding a set of actions to change the input features of a given instance so that it achieves a desired output from the learning model .",
    "we elaborate this problem using one example .",
    "* example 1*. in a credit card company , a key task is to decide on promotion strategies to maximize the long - term profit .",
    "the customer relationship management ( crm ) department collects data about customers , such as customer education , age , card type , the channel of initiating the card , the number and effect of different kinds of promotions , the number and time of phone contacts , etc . for data scientists , they need to build models to predict the profit brought by customers . in a real case , a company builds a random forest involving 35 customer features .",
    "the model predicts the profit ( with probability ) for each customer .",
    "in addition , a more important task is to extract actionable knowledge to revert `` negative profit '' customers and retain `` positive profit '' customers . in general",
    ", it is much cheaper to maintain existing `` positive profit''customers than to revert `` negative profit '' ones .",
    "it is especially valuable to retain high profit , large , enterprise - level customers .",
    "there are certain actions that the company can take , such as making phone contacts and sending promotional coupons .",
    "each action can change the value of one or multiple attributes of a customer .",
    "obviously , such actions incur costs for the company .",
    "for instance , there are 7 different kinds of promotions and each promotion associates with two features , the number and the accumulation effect of sending this kind of promotion . when performing an action of `` sending promotion_amt_n '' , it will change features `` nbr_promotion_amt_n '' and `` s_amt_n '' , the number and the accumulation effect of sending the sales promotion , respectively . for a customer with `` negative profit '' ,",
    "the goal is to extract a sequence of actions that change the customer profile so that the model gives a  positive profit \" prediction while minimizing the total action costs . for a customer with `` positive profit '' ,",
    "the goal is to find actions so that the customer has a `` positive profit '' prediction with a higher prediction probability .",
    "@xmath0    research on extracting actionability from machine learning models is still limited .",
    "there are a few existing works .",
    "statisticians have adopted stochastic models to find specific rules of the response behavior of customer  @xcite .",
    "there have also been efforts on the development of ranking mechanisms with business interests  @xcite and pruning and summarizing learnt rules by considering similarity  @xcite",
    ". however , such approaches are not suitable for the problems studied in this paper due to two major drawbacks .",
    "first , they can not provide customized actionable knowledge for each individual since the rules or rankings are derived from the entire population of training data .",
    "second , they did not consider the action costs while building the rules or rankings .",
    "for example , a low income housewife may be more sensitive to sales promotion driven by consumption target , while a social housewife may be more interested in promotions related to social networks .",
    "thus , these rule - based and ranking algorithms can not tackle these problems very well since they are not personalized for each customer .",
    "another related work is extracting actionable knowledge from decision tree and additive tree models by bounded tree search and integer linear programming  @xcite .",
    "yang s work focuses on finding optimal strategies by using a greedy strategy to search on one or multiple decision trees  @xcite .",
    "cui et al .",
    "use an integer linear programming ( ilp ) method to find actions changing sample membership on an ensemble of trees  @xcite .",
    "a limitation of these works is that the actions are assumed to change only one attribute each time . as we discussed above",
    ", actions like `` sending promotion_amt_n '' may change multiple features , such as `` nbr_promotion_amt_n '' and `` s_amt_n '' .",
    "moreover , yang s greedy method is fast but can not give optimal solution  @xcite , and cui s optimization method is optimal but very slow  @xcite .    in order to address these challenges ,",
    "we propose a novel approach to extract actionable knowledge from random forests , one of the most popular learning models .",
    "our approach leverages planning , one of the core and extensively researched areas of ai .",
    "we first rigorously formulate the knowledge extracting problem to a sub - optimal actionable planning ( soap ) problem which is defined as finding a sequence of actions transferring a given input to a desirable goal while minimizing the total action costs .",
    "then , our approach consists of two phases . in the offline preprocessing phase ,",
    "we use an anytime state - space search on an action graph to find a preferred goal for each instance in the training dataset and store the results in a database . in the online phase , for any given input , we translate the soap problem into a sas+ planning problem",
    ". the sas+ planning problem is solved by an efficient maxsat - based approach capable of optimizing plan metrics .",
    "we perform empirical studies to evaluate our approach .",
    "we use a real - world credit card company dataset obtained through an industrial research collaboration .",
    "we also evaluate some other standard benchmark datasets .",
    "we compare the quality and efficiency of our method to several other state - of - the - art methods .",
    "the experimental results show that our method achieves a near - optimal quality and real - time online search as compared to other existing methods .",
    "random forest is a popular model for classification , one of the main tasks of learning .",
    "the reasons why we choose random forest are : 1 ) in addition to superior classification / regression performance , random forest enjoys many appealing properties many other models lack  @xcite , including the support for multi - class classification and natural handling of missing values and data of mixed types .",
    "2 ) often referred to as one of the best off - the - shelf classifier  @xcite , random forest has been widely deployed in many industrial products such as kinect  @xcite and face detection in camera  @xcite , and is the popular method for some competitions such as web search ranking  @xcite .",
    "consider a dataset @xmath1 , where @xmath2 is the set of training samples and @xmath3 is the set of classification labels .",
    "each vector @xmath4 consists of @xmath5 attributes , where each attribute @xmath6 can be either categorical or numerical and has a finite or infinite domain @xmath7 .",
    "note that we use @xmath8 to represent @xmath9 when there is no confusion .",
    "all labels @xmath10 have the same finite categorical domain @xmath11 .",
    "a random forest contains @xmath12 decision trees where each decision tree @xmath13 takes an input @xmath14 and outputs a label @xmath15 , denoted as @xmath16 . for any label @xmath17 ,",
    "the probability of output @xmath18 is @xmath19 where @xmath20 are weights of decision trees , @xmath21 is an indicator function which evaluates to 1 if @xmath22 and 0 otherwise .",
    "the overall output predicted label is @xmath23    a random forest is generated as follows  @xcite . for @xmath24 ,    1 .",
    "sample @xmath25 ( @xmath26 ) instances from the dataset with replacement .",
    "train an un - pruned decision tree on the @xmath25 sampled instances . at each node , choose the split point from a number of randomly selected features rather than all features .      in classical planning , there are two popular formalisms , strips and pddl  @xcite . in recent years , another indirect formalism , sas+ , has attracted increasing uses due to its many favorable features , such as compact encoding with multi - valued variables , natural support for invariants , associated domain transition graphs ( dtgs ) and causal graphs ( cgs ) which capture vital structural information  .    in sas+ formalism",
    ", a planning problem is defined over a set of multi - valued _ state variables _ @xmath27 .",
    "each variable @xmath28 has a finite domain @xmath29 .",
    "a state @xmath30 is a full assignment of all the variables .",
    "if a variable @xmath31 is assigned to @xmath32 at a state @xmath30 , we denote it as @xmath33 .",
    "we use @xmath34 to represent the set of all states .",
    "[ defn : sas - transition ] * ( transition ) * given a multi - valued state variable @xmath35 with a domain @xmath29 , a transition is defined as a tuple @xmath36 , where @xmath37 , written as @xmath38 .",
    "a transition @xmath38 is applicable to a state @xmath30 if and only if @xmath33 .",
    "we use @xmath39 to represent applying a transition to a state .",
    "let @xmath40 be the state after applying the transition to @xmath30 , we have @xmath41 .",
    "we also simplify the notation @xmath38 as @xmath42 or @xmath43 when there is no confusion .",
    "a transition @xmath38 is a * regular transition * if @xmath44 or a * prevailing transition * if @xmath45 .",
    "in addition , @xmath46 denotes a * mechanical transition * , which can be applied to any state @xmath30 and changes the value of @xmath31 to @xmath47 .    for a variable @xmath31",
    ", we denote the set of all transitions that affect @xmath31 as @xmath48 , i.e. , @xmath49 for all @xmath37 .",
    "we also denote the set of all transitions as @xmath50 , i.e. , @xmath51 .",
    "[ defn : sas - mutex ] * ( transition mutex ) * for two different transitions @xmath38 and @xmath52 , if at least one of them is a mechanical transition and @xmath53 , they are compatible ; otherwise , they are mutually exclusive ( mutex ) .",
    "[ defn : sas - action ] * ( action ) * an action @xmath54 is a set of transitions @xmath55 , where there do not exist two transitions @xmath56 that are mutually exclusive .",
    "an action @xmath54 is * applicable * to a state @xmath30 if and only if all transitions in @xmath54 are applicable to @xmath30 .",
    "each action has a * cost * @xmath57 .",
    "[ def : sas - problem ] * ( sas+ planning ) * a sas+ planning problem is a tuple @xmath58 defined as follows    * @xmath59 is a set of state variables .",
    "* @xmath60 is a set of actions .",
    "* @xmath61 is the initial state .",
    "* @xmath62 is a set of goal conditions , where each goal condition @xmath63 is a partial assignment of some state variables .",
    "a state @xmath30 is a goal state if there exists @xmath63 such that @xmath30 agrees with every variable assignment in @xmath64 .",
    "note that we made a slight generalization of original sas+ planning , in which @xmath62 includes only one goal condition . for a state @xmath30 with an applicable action @xmath54",
    ", we use @xmath65 to denote the resulting state after applying all the transitions in @xmath54 to @xmath30 ( in an arbitrary order since they are mutex free ) .",
    "[ defn : sas - action - mutex ] * ( action mutex ) * two different actions @xmath66 and @xmath67 are mutually exclusive if and only if at least one of the following conditions is satisfied :    * there exists a non - prevailing transition @xmath43 such that @xmath68 and @xmath69 .",
    "* there exist two transitions @xmath70 and @xmath71 such that @xmath72 and @xmath73 are mutually exclusive .    a set of actions @xmath74 is applicable to @xmath30 if each action @xmath75 is applicable to @xmath30 and no two actions in @xmath74 are mutex .",
    "we denote the resulting state after applying a set of actions @xmath74 to @xmath30 as @xmath76 .",
    "[ defn : sas - plan ] * ( solution plan ) * for a sas+ problem @xmath77 + @xmath78 , a solution plan is a sequence @xmath79 , where each @xmath80 , @xmath81 is a set of actions , and there exists @xmath63 , @xmath82 .    note that in a solution plan , multiple non - mutex actions can be applied at the same time step . @xmath83",
    "means applying all actions in @xmath80 in any order to state @xmath30 . in this work ,",
    "we want to find a solution plan that minimizes a quality metric , the * total action cost * @xmath84 .",
    "we first give an intuitive description of the soap problem . given a random forest and an input @xmath85 , the soap problem is to find a sequence of actions that , when applied to @xmath85 , changes it to a new instance which has a desirable output label from the random forest .",
    "since each action incurs a cost , it also needs to minimize the total action costs . in general , the actions and their costs are determined by domain experts .",
    "for example , analysts in a credit card company can decide which actions they can perform and how much each action costs .",
    "there are two kinds of features ,",
    "_ soft attributes _ which can be changed with reasonable costs and _ hard attributes _ which can not be changed with a reasonable cost , such as gender  @xcite .",
    "we only consider actions that change soft attributes .",
    "[ def : oap ] * ( soap problem ) * a soap problem is a tuple @xmath86 , where @xmath87 is a random forest , @xmath88 is a given input , @xmath17 is a class label , and @xmath89 is a set of actions .",
    "the goal is to find a sequence of actions @xmath90 , to solve : @xmath91 where @xmath57 is the cost of action @xmath54 , @xmath92 is a constant , @xmath93 is the output of @xmath87 as defined in ( [ eq : prob ] ) , and @xmath94 is the new instance after applying the actions in @xmath95 to @xmath88 .",
    "* example 2 . *",
    "a random forest @xmath87 with two trees and three features is shown in figure  [ fig : forest ] .",
    "@xmath96 is a hard attribute , @xmath97 and @xmath98 are soft attributes .",
    "given @xmath87 and an input @xmath99 , the output from @xmath87 is 0 .",
    "the goal is to change @xmath85 to a new instance that has an output of 1 from @xmath87 .",
    "for example , two actions changing @xmath97 from 2 to 5 and @xmath98 from 500 to 1500 is a plan and the new instance is @xmath100 .",
    "the soap problem is proven to be an np - hard problem , even when an action can change only one feature  @xcite .",
    "therefore , we can not expect any efficient algorithm for optimally solving it .",
    "we propose a planning - based approach to solve the soap problem .",
    "our approach consists of an offline preprocessing phase that only needs to be run once for a given random forest , and an online phase that is used to solve each soap problem instance .      since there are typically prohibitively high number of possible instances in the feature space , it is too expensive and unnecessary to explore the entire space .",
    "we reason that the training dataset for building the random forest gives a representative distribution of the instances .",
    "therefore , in the offline preprocessing , we form an action graph and identify a preferred goal state for each training sample .    *",
    "( feature partitions ) * given a random forest @xmath87 , we split the domain of each feature @xmath101 ( @xmath102 ) into a number of partitions according to the following rules .    1",
    ".   @xmath101 is split into @xmath103 partitions if @xmath101 is categorical and has @xmath103 categories .",
    "@xmath101 is split into @xmath104 partitions if @xmath105 is numerical and has @xmath103 * branching nodes * in all the decision trees in @xmath87 .",
    "suppose the branching nodes are @xmath106 , the partitions are + @xmath107 .",
    "in example 2 , @xmath96 is splited into @xmath108 , @xmath97 and @xmath98 are splited into @xmath109 and @xmath110 , respectively .",
    "[ defn : state - transformation ] * ( state transformation ) * for a given instance @xmath111 , let @xmath112 be the number of partitions and @xmath113 the partition index for feature @xmath101 , we transform it to a sas+ state @xmath114 , where @xmath115 and @xmath116 .    for simplicity",
    ", we use @xmath30 to represent @xmath117 when there is no confusion .",
    "note that if two instances @xmath118 and @xmath119 transform to the same state @xmath30 , then they have the same output from the random forest since they fall within the same partition for every feature . in that case , we can use @xmath120 in place of @xmath121 and @xmath122 .",
    "given the states , we can define sas+ transitions and actions according to definitions  [ defn : sas - transition ] and  [ defn : sas - action ] .",
    "for example 2 , @xmath123 can be transformed to state @xmath124 , @xmath125 .",
    "for an input @xmath99 , the corresponding state is @xmath126 .",
    "the action @xmath54 changing @xmath97 from 2 to 5 can be represented as @xmath127 . thus , the resulting state of applying @xmath54 is @xmath128 .",
    "[ defn : graph ] * ( action graph ) * given a soap problem @xmath86 , the action graph is a graph @xmath129 where @xmath130 is the set of transformed states and an edge @xmath131 if and only if there is an action @xmath132 such that @xmath133 .",
    "the weight for this edge is @xmath134 .",
    "the soap problem in definition  [ def : oap ] is equivalent to finding the shortest path on the state space graph @xmath129 from a given state @xmath135 to a goal state .",
    "a node @xmath30 is a goal state if @xmath136 .",
    "given the training data @xmath137 , we use a heuristic search to find a * preferred goal * state for each @xmath138 that @xmath139 . for each of such @xmath85",
    ", we find a path in the action graph from @xmath117 to a state @xmath140 such that @xmath141 while minimizing the cost of the path .",
    "@xmath142 , @xmath143 , @xmath144 minheap.push(@xmath135 ) , closedlist @xmath145 @xmath146 minheap.pop ( ) @xmath147 , @xmath148 , @xmath149 * if * @xmath150 * then return * @xmath140 closedlist = closedlist @xmath151 minheap.push(@xmath152 ) @xmath140    algorithm  [ algo : non_opt ] shows the heuristic search .",
    "the search uses a standard evaluation function @xmath153 .",
    "@xmath154 is the cost of the path leading up to @xmath30 .",
    "let the path be @xmath155 , @xmath156 , @xmath157 , @xmath158 , and @xmath159 for @xmath160 , we have @xmath161 .",
    "we define the * heuristic function * as @xmath162 if @xmath163 , otherwise @xmath164 .    for any state",
    "@xmath165 satisfying @xmath163 , @xmath166 .",
    "since the goal is to achieve @xmath136 , @xmath167 measures how far @xmath30 is from the goal .",
    "@xmath168 is a controlling parameter . in our experiments , @xmath168 is set to the mean of all the action costs .",
    "algorithm  [ algo : non_opt ] maintains two data structures , a min heap and a closed list , and performs the following main steps :    1 .",
    "initialize @xmath169 , @xmath140 , and @xmath170 where @xmath169 represent the number of expanded states@xmath140 is the best goal state ever found , and @xmath170 records the cost of the path leading up to @xmath140 .",
    "add the initial state @xmath135 to the min heap ( lines 1 - 2 ) .",
    "2 .   pop the state @xmath30 from the heap with the smallest @xmath171 ( line 4 ) .",
    "if @xmath136 and @xmath172 , update @xmath170 , @xmath169 , and the best goal state @xmath140 ( lines 5 - 6 ) .",
    "4 .   if the termination condition ( @xmath150 ) is met , stop the search and return @xmath140 ( line 8) .",
    "5 .   add @xmath30 to the closed list and for each edge @xmath173 , add @xmath152 to the min heap if @xmath30 is not in the closed list and not a goal state ( lines 10 - 12 ) .",
    "repeat from step 2 .",
    "the closed list is implemented as a set with highly efficient hashing - based duplicate detection .",
    "the search terminates when the search has not found a better plan for a long time ( @xmath150 ) .",
    "we set a large value ( @xmath174 ) in our experiments .",
    "note that algorithm  [ algo : non_opt ] does not have to search all states since it will stop the search once a state * s *   satisfies the termination condition ( line 8) .    by the end of the offline phase , for each @xmath138 and the corresponding state @xmath117",
    ", we find a preferred goal state @xmath175 .",
    "for an input @xmath99 in example 2 , the corresponding initial state is @xmath126 .",
    "an optimal solution is @xmath176 where @xmath177 , @xmath178 , @xmath179 , and the preferred goal state is @xmath180 .",
    "once the offline phase is done , the results can be used to repeatedly solve soap instances .",
    "we now describe how to handle a new instance @xmath88 and find the actionable plan .    in online sas+ planning , we will find a number of closest states of @xmath181 and use the combination of their goals to construct the goal @xmath182 .",
    "this is inspired by the idea of similarity - based learning methods such as k - nearest - neighbor ( knn ) .",
    "we first define the similarity between two states .    * ( feature similarity ) * given two states @xmath183 and @xmath184 , the similarity of the i - th feature variable is defined as :    * if the i - th feature is categorical , @xmath185 if @xmath186 , otherwise @xmath187 . *",
    "if the i - th feature is numerical , @xmath188 where @xmath113 and @xmath189 are the partition index of features @xmath101 and @xmath190 , and @xmath112 is the number of partitions of the i - th feature .",
    "note that @xmath191 $ ] .",
    "@xmath185 means they are in the same partition , while @xmath187 means they are totally different .    * ( state similarity ) * the similarity between two states @xmath183 and @xmath184 is 0 if there exists @xmath192 $ ] , @xmath101 is a hard attribute and @xmath101 and @xmath190 are not in the same partition . otherwise , the similarity is @xmath193 where @xmath194 is the feature weight in the random forest .",
    "note that @xmath195 $ ] .",
    "a larger @xmath196 means higher similarity . given two vectors @xmath99 and @xmath197 in example 2 , the corresponding states are @xmath198 and @xmath199 .",
    "their feature similarities are @xmath200 , @xmath201 , and @xmath202 .",
    "suppose @xmath203 , then @xmath204 .    given two vectors @xmath99 and @xmath205 ,",
    "the corresponding states are @xmath198 and @xmath206 . since @xmath96 is a hard attribute and @xmath96 , @xmath207 are not in the same parition , @xmath208",
    ".    * sas+ formulation . * given a soap problem @xmath86 , we define a sas+ problem @xmath58 as follows :    * @xmath209 is a set of state variables .",
    "each variable @xmath101 has a finite domain @xmath210 where @xmath112 is the number of partitions of the @xmath211-th feature of @xmath14 .",
    "* @xmath60 is a set of sas+ actions directly mapped from @xmath89 in @xmath212 .",
    "* @xmath135 is transformed from @xmath213 according to definition  [ defn : state - transformation ] .",
    "* let @xmath214 be the @xmath215 nearest neighbors of @xmath135 ranked by @xmath216 , and their corresponding preferred goal states be @xmath217 , the goal in sas+ is @xmath218 .",
    "@xmath219 is a user - defined integer .    in example 2",
    ", if we preprocessed three initial states @xmath220 , @xmath221 , @xmath222 , then three preferred goal states @xmath223 , @xmath224 , and @xmath225 will be found in the offline phase . in the online phase ,",
    "given a new input @xmath226 , the corresponding state is @xmath227 .",
    "suppose @xmath203 , then @xmath228 , @xmath229 , and @xmath230 .",
    "if @xmath231 , the 2 nearest neighbors of @xmath135 are @xmath156 and @xmath232 , and the goal of the sas+ problem is @xmath233 .    in the online phase , for a given @xmath88 , we solve a sas+ instance defined above .",
    "in addition to classical sas+ planning , we also want to minimize the total action costs .",
    "since some existing classical planners do not perform well in optimizing the plan quality , we employ a sat - based method .",
    "our method follows the bounded sat solving strategy , originally proposed in satplan  @xcite and graphplan  @xcite .",
    "it starts from a lower bound of makespan ( l=1 ) , encodes the sas+ problem as a weighted partial max - sat ( wpmax - sat ) instance  @xcite , and either proves it unsatisfiable or finds a plan while trying to minimize total action costs at the same time .    for a sas+ problem @xmath58 , given a makespan @xmath234 ,",
    "we define a wpmax - sat problem @xmath235 with the following variable set @xmath236 and clause set @xmath237 .",
    "the variable set includes three types of variables :    * transition variables : @xmath238 , @xmath239 and @xmath240 $ ] . * action variables : @xmath241 , @xmath242 and @xmath243 $ ] .",
    "* goal variables : @xmath244 , @xmath245 .",
    "each variable in @xmath236 represents the assignment of a transition or an action at time @xmath246 , or a goal condition @xmath140 .",
    "the clause set @xmath237 has two types of clauses : soft clauses and hard clauses .",
    "the soft clause set @xmath247 is constructed as : @xmath248 \\}$ ] . for each clause @xmath249",
    ", its weight is defined as @xmath250 . for each clause in the hard clause set @xmath251 , its weight is @xmath252 so that it must be true .",
    "@xmath251 has the following hard clauses :    * initial state : @xmath253 , @xmath254 * goal state : @xmath255 .",
    "it means at leat one goal condition @xmath140 must be true . *",
    "goal condition : @xmath245 , @xmath256 , @xmath257 .",
    "if @xmath244 is true , then for each assignment @xmath258 , at least one transition changing variable @xmath31 to value @xmath47 must be true at time @xmath234 . *",
    "progression : @xmath259 and @xmath260 $ ] , @xmath261 . * regression : @xmath259 and @xmath262 $ ] , @xmath263 .",
    "* mutually exclusive transitions : for each mutually exclusive transitions pair @xmath264 , @xmath265 $ ] , @xmath266 .",
    "* mutually exclusive actions : for each mutually exclusive actions pair @xmath267 , @xmath265 $ ] , @xmath268 . *",
    "composition of actions : @xmath242 and @xmath260 $ ] , @xmath269 . *",
    "action existence : for each non - prevailing transition @xmath270 , @xmath271 .",
    "there are three main differences between our approach and a related work , sase encoding  @xcite .",
    "first , our encoding transforms the sas+ problem to a wpmax - sat problem aiming at finding a plan with minimal total action costs while sase transforms it to a sat problem which only tries to find a satisfiable plan .",
    "second , besides transition and action variables , our encoding has extra goal variables since the goal definition of our sas+ problem is a combination of several goal states while in sase it is a partial assignment of some variables .",
    "third , the goal clauses of our encoding contain two kinds of clauses while sase has only one since the goal definition of ours is more complicated than sase .",
    "we can solve the above encoding using any of the maxsat solvers , which are extensively studied .",
    "using soft clauses to optimize the plan in our wpmax - sat encoding is similar to balyo s work  @xcite which uses a maxsat based approach for plan optimization ( removing redundant actions ) .",
    "to test the proposed approach ( denoted as  planning \" ) , in the offline preprocess , @xmath272 in algorithm  [ algo : non_opt ] is set to @xmath273 . in the online search , we set neighborhood size @xmath274 and use wpm-2014-in   to solve the encoded wpmax - sat instances . for comparison , we also implement three solvers : 1 ) an iterative greedy algorithm , denoted as `` greedy '' which chooses one action in each iteration that increases @xmath120 while minimizes the total action costs .",
    "it keeps iterating until there is no more variables to change .",
    "2 ) a sub - optimal state space method denoted as `` ns ''  @xcite .",
    "3 ) an integer linear programming ( ilp ) method  @xcite , one of the state - of - the - art algorithms for solving the soap problem . ilp gives exact optimal solutions .",
    ".datasets information and offline preprocess results . [ cols=\"<,^,^,^,^,^,^\",options=\"header \" , ]     table  [ tb : summarize ] shows a comprehensive comparison in terms of the average search time , the solution quality measured by the total action costs , the action number of solutions , and the memory usage under the preprocessing percentage 100% . we report the search time ( t ) in seconds , total action costs of the solutions ( cost ) , action number of solutions ( l ) , and the memory usage ( gb ) , averaged over 100 runs .    from table",
    "[ tb : summarize ] , we can see that even though our method spends quite a lot of time in the offline processing , its online search is very fast . since our method finds near optimal plans for all training samples ,",
    "its solution quality is much better than greedy while spending almost the same search time .",
    "comparing against np , our method is much faster in online search and maintains better solution qualities in a1a and ionosphere scale and equal solution qualities in other 8 datasets .",
    "comparing against ilp , our method is much faster in online search with the cost of losing optimality . typically a trained random forest model will be used for long time . since our offline",
    "preprocessing only needs to be run once , its cost is well amortized over large number of repeated uses of the online search . in short , our planning approach gives a good quality - efficiency tradeoff : it achieves a near - optimal quality using search time close to greedy search .",
    "note that since we need to store all preprocessed states and their preferred goal states in the online phase , the memory usage of our method is much larger than greedy and ns approaches .",
    "we have studied the problem of extracting actionable knowledge from random forest , one of the most widely used and best off - the - shelf classifiers .",
    "we have formulated the sub - optimal actionable plan ( soap ) problem , which aims to find an action sequence that can change an input instance s prediction label to a desired one with the minimum total action costs .",
    "we have then proposed a sas+ planning approach to solve the soap problem . in an offline phase ,",
    "we construct an action graph and identify a preferred goal for each input instance in the training dataset . in the online planning phase , for each given input , we formulate the soap problem as a sas+ planning instance based on a nearest neighborhood search on the preferred goals ,",
    "encode the sas+ problem to a wpmax - sat instance , and solve it by calling a wpmax - sat solver .",
    "our approach is heuristic and suboptimal , but we have leveraged sas+ planning and carefully engineered the system so that it gives good performance .",
    "empirical results on a credit card company dateset and other nine benchmarks have shown that our algorithm achieves a near - optimal solution quality and is ultra - efficient , representing a much better quality - efficiency tradeoff than some other methods .    with the great advancements in data science , an ultimate goal of extracting patterns from data is to facilitate decision making .",
    "we envision that machine learning models will be part of larger ai systems that make rational decisions .",
    "the support for actionability by these models will be crucial .",
    "our work represents a novel and deep integration of machine learning and planning , two core areas of ai .",
    "we believe that such integration will have broad impacts in the future .",
    "note that the proposed action extraction algorithm can be easily expanded to other additive tree models ( atms )  @xcite , such as adaboost  @xcite , gradient boosting trees  @xcite .",
    "thus , the proposed action extraction algorithm has very wide applications .    in our soap formulation ,",
    "we only consider actions having deterministic effects .",
    "however , in many realistic applications , we may have to tackle some nondeterministic actions .",
    "for instance , push a promotional coupon may only have a certain probability to increase the accumulation effect since people do not always accept the coupon .",
    "we will consider to add nondeterministic actions to our model in the near future .",
    "l.  cao , c.  zhang , d.  taniar , e.  dubossarsky , w.  graco , q.  yang , d.  bell , m.  vlachos , b.  taneri , e.  keogh , et  al .",
    "domain - driven , actionable knowledge discovery .",
    "_ ieee intelligent systems _ , 0 (",
    "4):0 7888 , 2007 .",
    "q.  lu , r.  huang , y.  chen , y.  xu , w.  zhang , and g.  chen . a sat - based approach to cost - sensitive temporally expressive planning .",
    "_ acm transactions on intelligent systems and technology _ , 50 ( 1):0 18:118:35 , 2014 .          j.  shotton , t.  sharp , a.  kipman , a.  fitzgibbon , m.  finocchio , a.  blake , m.  cook , and r.  moore . real - time human pose recognition in parts from single depth images .",
    "_ communications of the acm _ , 560 ( 1):0 116124 , 2013 ."
  ],
  "abstract_text": [
    "<S> a main focus of machine learning research has been improving the generalization accuracy and efficiency of prediction models . </S>",
    "<S> many models such as svm , random forest , and deep neural nets have been proposed and achieved great success . </S>",
    "<S> however , what emerges as missing in many applications is actionability , i.e. , the ability to turn prediction results into actions . </S>",
    "<S> for example , in applications such as customer relationship management , clinical prediction , and advertisement , the users need not only accurate prediction , but also actionable instructions which can transfer an input to a desirable goal ( e.g. , higher profit repays , lower morbidity rates , higher ads hit rates ) . </S>",
    "<S> existing effort in deriving such actionable knowledge is few and limited to simple action models which restricted to only change one attribute for each action . </S>",
    "<S> the dilemma is that in many real applications those action models are often more complex and harder to extract an optimal solution .    in this paper </S>",
    "<S> , we propose a novel approach that achieves actionability by combining learning with planning , two core areas of ai . </S>",
    "<S> in particular , we propose a framework to extract actionable knowledge from random forest , one of the most widely used and best off - the - shelf classifiers . </S>",
    "<S> we formulate the actionability problem to a sub - optimal action planning ( soap ) problem , which is to find a plan to alter certain features of a given input so that the random forest would yield a desirable output , while minimizing the total costs of actions . </S>",
    "<S> technically , the soap problem is formulated in the sas+ planning formalism , and solved using a max - sat based approach . </S>",
    "<S> our experimental results demonstrate the effectiveness and efficiency of the proposed approach on a personal credit dataset and other benchmarks . </S>",
    "<S> our work represents a new application of automated planning on an emerging and challenging machine learning paradigm .    </S>",
    "<S> actionable knowledge extraction , machine learning , planning , random forest , weighted partial max - sat </S>"
  ]
}