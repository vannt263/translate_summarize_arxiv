{
  "article_text": [
    "a social network is referred as a structure of `` internet users '' interconnected through a variety of relations @xcite . for a single user , he / she has some different relationships in different social networks such as friends and followers .",
    "also , one user has diverse social activities , e.g. , post messages , photos and other media on facebook and upload , view , share and comment on videos on youtube . according to statistics , almost @xmath0 tb social data are generated per day .",
    "it takes high operational costs to store the data and it is a waste of resources without using them .",
    "hence , we want to conduct the social big data analysis , in which the users active in a social , collaborative context to make sense of data .",
    "however , handling such a volume of social data brings us many challenges .",
    "we next describe the main challenges and the corresponding approaches to them .",
    "the social data are generated all around the world and collected over distributed sources into different and interconnected data centers .",
    "hence , it is hard to process the data in a centralized model .",
    "concerned with this problem , cloud computing may be a good choice .",
    "as is known , many social networking websites ( e.g. , facebook , twitter , linkedin and youtube ) obtain computing resources across a network .",
    "these corporations host their social networks on a cloud platform .",
    "this cloud - based model owns some advantages , chief among which is the lowered costs in infrastructure .",
    "they can rent cloud computing services from other third part due to their actual needs and scale up and down at any time without taking additional cost in infrastructure @xcite . beyond that , they are able to choose different cloud computing services according to the distribution of social data .",
    "naturally , for social data analysis in cloud , a distributed online learning algorithm is needed to handle the massive social data in distributed scenarios @xcite .",
    "based on cloud computing , we equip each data center with the independent online learning ability and they can exchange information with other data centers across the network .",
    "each data center is urged to build a reliable model to recommend its local users without directly sharing social data with each other . in theory , this approach is a distributed optimization technology and many researches @xcite have been devoted to it . to estimate the utility of the proposed model ,",
    "we use the notion `` regret '' @xcite in online learning ( see definition 3 ) .    in big data era ,",
    "social big data are both large scale and high dimension .",
    "a single person has a variety of social activities in a social network , so the corresponding vector of his / her social information is `` long '' .",
    "however , when a data miner studies the consumer behavior about one interest , some of the information in the vector may not be relevant .",
    "for example , a person s height and age can not contribute to predicting his taste .",
    "thus , high dimension could enhance the computational complexity of algorithms and weaken the utility of online learning models . to deal with this problem",
    ", we introduce a sparse solution in social big data . in this paper , we introduce two classical groups of effective methods for sparse online learning @xcite .",
    "the first group ( e.g. , @xcite ) induces sparsity in the weights of online learning algorithms via truncated gradient .",
    "the second group studies on sparse online learning follows the dual averaging algorithm @xcite . in this paper",
    ", we will exploit _ online mirror descent _ @xcite and _ lasso-@xmath1 norm _",
    "@xcite to make the parameter updated in algorithm sparse .",
    "furthermore , exchanging information contained in social data among data centers may lead to privacy breaches as it flows across the social network .",
    "once social data are mined without any security precautions , it is of high probability to divulge privacy . admittedly , preserving privacy consequentially lead to the lowered performance of knowledge discovery in cloud - based social data .",
    "therefore , we intend to design an algorithm , which protects the privacy while makes full use of the social data . finally , we choose the `` differential privacy '' @xcite technology to guarantee the safety of data centers in cloud . at a high level , a differentially private online learning model guarantees that its output of data mining does not change  too much \" because of perturbations (",
    "i.e. , add some random noise to the data transmitted ) in any individual social data point .",
    "that means whether or not a data point being in the database , the mining outputs are difficult to distinguish and then the miner can not obtain the sensitive information based on search results .    in conclusion ,",
    "we make three contributions : 1 ) we propose a distributed online learning algorithm to handle decentralized social data in real time and demonstrate its feasibility ; 2 ) sparsity is induced to compute the high - dimension social data for enhancing the accuracy of predictions ; 3 ) differential privacy is used to protect the privacy of data without seriously weaken the performance of the online learning algorithm .",
    "this paper is organized as follows .",
    "section ii introduces the system model and propose the algorithm .",
    "the privacy analysis is done in section iii .",
    "we analyze the utility of the algorithm in section iv .",
    "numerical results and performance improvements are shown in section v. section vi concludes the paper .",
    "in this section , the system model and our private online learning algorithm are presented .",
    "consider a social network , in which all online users are served on cloud platforms , e.g. , fig.1 .",
    "these users operate on their own personal page and the generated social data are collected and transmitted to the nearest data center on cloud , just as shown in fig.1 , all data are collected by the data centers marked with @xmath2 . because of the huge network , many data centers are widely distributed .",
    "each data center has its corresponding cloud computing node , where the nearby social data are processed in real time . as a holonomic system ,",
    "the social network should have a good knowledge of all data it owns , thus data centers should exchange information with each other . since there are too many data centers and most of them",
    "are located over the world , a data center never can communicate with all other centers . to achieve better economic benefits , each data center just can exchange information with neighboring ones ( e.g. , @xmath3 is just connected to its adjacent centers @xmath4 and @xmath5 ) .",
    "furthermore , random noise should be added to each communication for protecting the privacy ( yellow arrows in fig.1 ) . since such social big data need to be efficiently and privately processed with the limited communications , we focus on distributed optimization and differential privacy technologies .",
    "we next introduce how the communications among data centers on cloud are conducted . recall that we intend to realize knowledge discovery in social data in real time .",
    "a new parameter , e.g. , @xmath6 , should be created to denote the online learning parameter ( containing the knowledge mined from data ) . at each iteration , each cloud node updates @xmath6 based on its local data center and then exchanges @xmath6 with neighbors .",
    "this communication mechanism forms a network topology .",
    "the network topology can be fixed or time - variant , which is proved to have no great influence on the utility of our algorithm in section iv .",
    "for our online learning social network , we denote the communication matrix by @xmath7 and let @xmath8 be the @xmath9-th element of @xmath7 . in the system , @xmath8 is the weight of the learning parameter which the @xmath10-th cloud node transmits to the @xmath11-th one .",
    "@xmath12 means there exists a communication between the @xmath10-th and @xmath11-th nodes at round @xmath13 , while @xmath14 means non - communication between them . .",
    "for a clear description , we denote the communication graph for a node @xmath10 at round @xmath13 by @xmath15 where @xmath16    to achieve the global convergence , we make some assumptions about @xmath7 .",
    "[ fig : subfig : a ]     * assumption 1 . * for an arbitrary node @xmath10 , there exists a minimal scalar @xmath17 , @xmath18 such that    * @xmath19 for @xmath20 , * @xmath21 and @xmath22 , * @xmath23 implies that @xmath24 .",
    "here , assumptions ( 1 ) and ( 2 ) state that each node computes a weighted average of neighboring learning parameters .",
    "assumption ( 3 ) ensures that the influences among the nodes are significant .",
    "the above assumption is a necessary condition which presents in all researches ( e.g.,@xcite ) about distributed optimization .",
    "fortunately , this technology can be used to solve our distributed online learning in social networks .",
    "as described , a social data is high dimensional .",
    "hence , its corresponding learning parameter @xmath6 is a long vector . in order to find the factors most related to one predicting behavior",
    ", we need to aggressively make the irrelevant dimensions zero .",
    "lasso @xcite is a famous method to produce some coefficients that are exactly @xmath25 .",
    "lasso can not be directly used in the algorithm , we combine it with online mirror descent ( see algorithm 1 ) which is a special online learning algorithm .    for convenient analysis",
    ", we next make some assumptions about the mathematical model of online learning system in social network .",
    "we assume to have @xmath26 data centers over the social network .",
    "each data center collects massive social data every minute and processes them on cloud computing . for the data generated from social networks",
    ", we use @xmath27 to denote the social data of individual person .",
    "@xmath28 ( e.g. , @xmath29 ) denotes the prediction for a user , which helps the online website offer the user satisfying service .",
    "then , the user will give a feedback denoted by @xmath30 telling the website whether the previous prediction makes sense for him .",
    "finally , due to the loss function ( e.g. , @xmath31 _ + } $ ] ) , we compare the @xmath28 and @xmath30 to find how many `` mistakes '' the online learning algorithm makes .",
    "summing these `` mistakes '' over time and social networks , we obtain the regret of the whole system , based on which we can know the performance of our algorithm .",
    "* assumption 2 .",
    "* let @xmath32 denote the set of @xmath6 , we assume @xmath32 and the loss function @xmath33 satisfy :    * the set @xmath32 is closed and convex subset of @xmath34 .",
    "let @xmath35 denotes the diameter of @xmath32 .",
    "* the loss function @xmath33 is _ strongly convex _ with modulus @xmath36 . for all @xmath37",
    ", we have @xmath38 * the subgradients of @xmath33 are uniformly bounded , i.e. , there exists @xmath39 , for all @xmath40 , we have @xmath41    assumption ( 1 ) guarantees that there exists an optimal solution in our algorithm . assumptions ( 2 ) and",
    "( 3 ) help us analyze the convergence of our algorithm .",
    "dwork @xcite first proposed the definition of differential privacy which makes a data miner be able to release some statistic of its database without revealing sensitive information about a particular value itself . in this paper , we realize output perturbation by adding a random noise denoted by @xmath42 .",
    "this noise interferes some malicious data miners to steal sensitive information ( e.g. , birthday and contact info ) .",
    "based on the parameters defined above , we give the following definition .    * definition 1 .",
    "* assume that @xmath43 denotes our differentially private online learning algorithm .",
    "let @xmath44 be a sequence of social data taken from an arbitrary node s local data center .",
    "let @xmath45 be a sequence of @xmath46 results of the node and @xmath47 .",
    "then , our algorithm @xmath43 is @xmath48-differentially private if given any two adjacent question sequences @xmath49 and @xmath50 that differ in one social data entry , the following holds : @xmath51 \\le { e^\\epsilon}\\pr \\left [ { \\mathcal{a\\left ( { x ' } \\right ) } } \\right].\\end{aligned}\\ ] ]    this inequality guarantees that whether or not an individual participates in the database , it will not make any significant difference on the output of our algorithm , so the adversary is not able to gain useful information about the individual person .",
    "we present a private distributed online learning algorithm for cloud - based social networks .",
    "specifically , each cloud computing node propagates the parameter with noise added to neighboring nodes . after receiving the parameters from others , each node",
    "compute a weight average of the received and its old parameters .",
    "then , each node updates the parameter due to general online mirror descent and induce sparsity using lasso .",
    "the algorithm is summarized in algorithm 1 .",
    "note that @xmath52 denotes the parameter of the @xmath10-th cloud node at time @xmath13 .",
    "@xmath53 are a series of @xmath54-strongly convex functions .",
    "* input * : cost functions @xmath55 , @xmath56 $ ] and @xmath57 $ ] ; double stochastic matrix @xmath58 ; * initiaization : * @xmath59 , @xmath56 $ ] receive @xmath60 @xmath61 @xmath62 + predict @xmath63 receive @xmath64 and obtain @xmath65 @xmath66 , where @xmath67 broadcast to neighbors : @xmath68",
    "as mentioned , exploiting differential privacy ( dl ) protects the privacy while guarantees the usability of social data . in step 11 of algorithm 1 , @xmath69 is the parameter exchanged , to which we add a random noise .",
    "the added noise leads to the perturbation of @xmath69 , so someone else can not mine individual privacy according to an exact parameter . to recall , dl",
    "is defined mathematically in definition 1 , which aims at weakening the significantly difference between @xmath70 and @xmath71 . only satisfying the inequality ( 4 ) , can we ensure the privacy of social data in each data center .",
    "since we add noise to mask the difference of two datasets differing at most in one point , the sensitivity should be known .",
    "dwork @xcite proposed that the magnitude of the noise depends on the largest change that a single entry in data source could have on the output of algorithm 1 ; this quantity is referred to as the _ sensitivity _ of the algorithm .",
    "the sensitivity of algorithm 1 in defined .    * definition 2 ( sensitivity ) . * based on definition 1 , for any @xmath49 and @xmath50 , which differ in exactly one entry , we define the sensitivity of algorithm 1 at @xmath13-th round as @xmath72    * lemma 1 .",
    "* under assumption 1 , if the @xmath1-sensitivity of the parameter @xmath73 is computed as ( 5 ) , we obtain @xmath74 where @xmath75 denotes the dimensionality of the vectors .",
    "see algorithm 1 , @xmath73 is the exchanged parameter and added with the noise @xmath76 . according to definition 1 , we have @xmath77 assuming that the only differenct social data comes at time @xmath13 , we have @xmath78 where @xmath79 and @xmath80 lead to @xmath81 and @xmath82 due to step 9 and 10 in algorithm 1 .    then , we have @xmath83    by definition 2 , we know @xmath84    finally , combining ( 5 ) and ( 7 ) , we obtain ( 6 ) .",
    "we determine the magnitude of the noise as follows .",
    "@xmath85 is a laplace random noise vector drawn independently according to the density function : @xmath86 where @xmath87 .",
    "after this , we use @xmath88 to denote the laplace distribution .      in our system model , as an independent cloud node",
    ", each data center should protect the privacy at every moment . if there is a data center invaded by a malicious user , this `` bad kid '' is able to get some information about other users social data stored in other data center across the network .",
    "hence , every data transmitted should be processed by dl ( i.e. , satisfy ( 4 ) ) .",
    "recalling from fig.1 , we add random noise to every communication in the data center network .    having described the method and magnitude of adding noise , we next prove how to guarantee @xmath48-differentially private for @xmath73 .",
    "first , we demonstrate the privacy preserving at each time @xmath13 .",
    "* lemma 2 . * at the @xmath13-th round , the @xmath10-th cloud node s output of @xmath43 , @xmath89 , is @xmath48-differentially private .",
    "let @xmath90 and @xmath91 , then by the definition of differential privacy ( see definition 1 ) , @xmath89 is @xmath48-differentially private if @xmath92 \\le { e^\\epsilon}\\pr [ \\widetilde { \\theta}{_t^i } ' ] .\\ ] ] we have @xmath93 - \\theta[j ] } \\right|}}{{s\\left ( t \\right ) } } } \\right)}}{{\\exp \\left ( { - \\frac{{\\epsilon\\left| { { \\theta_t^i}'[j ] -\\theta[j ] } \\right|}}{{s\\left ( t \\right ) } } } \\right ) } } } \\right ) } \\\\ % \\notag & = \\prod\\limits_{j = 1}^n { \\exp \\left ( { \\frac{{\\epsilon\\left ( { \\left| { { \\theta_t^i}'[j ] - \\theta[j ] } \\right| - \\left| { \\theta_t^i[j ] - \\theta[j ] } \\right| } \\right)}}{{s\\left ( t \\right ) } } } \\right ) } \\\\ \\notag & \\le \\prod\\limits_{j = 1}^n { \\exp \\left ( { \\frac{{\\epsilon\\left| { { \\theta_t^i}'[j ] -\\theta_t^i[j ] } \\right|}}{{s\\left ( t \\right ) } } } \\right ) } \\\\ \\notag & = \\exp \\left ( { \\frac{{\\epsilon{{\\left\\| { { \\theta_t^i } ' -\\theta_t^i } \\right\\|}_1}}}{{s\\left ( t \\right ) } } } \\right)\\le \\exp \\left ( \\epsilon \\right),\\end{aligned}\\ ] ] where the first inequality follows from the triangle inequality , and the last inequality follows from lemma 1 .",
    "mcsherry @xcite has proposed that the privacy guarantee does not degrade across rounds as the samples used in the rounds are disjoint .",
    "obviously , our system model is an online processing website , where the social data is flowing .",
    "we dynamically serve the users with favorite recommendations due to users recent social behavior .",
    "hence , during the @xmath46 rounds of our algorithm 1 , the social data are disjoint . as algorithm 1 runs , the privacy guarantee will not degrade .",
    "then we obtain the following theorem .    * theorem 1 ( parallel composition ) . * on the basis of definition 1 and 3 , under assumption 1 and lemma 2 , our algorithm is @xmath48-differentially private .    for details of proof of theorem 1 ,",
    "readers are advised to @xcite .",
    "we have mentioned the notion regret , which is used to estimate the utility of online learning algorithms .",
    "the regret of our online learning algorithm represents a sum of mistakes , which are made by all data centers during the learning and predicting process . when social websites conduct personalized recommendations ( e.g. , songs , videos and news etc .",
    ") for users , not all recommendations make sense for individuals .",
    "but we wish that with the system working and more social data being learnt , the predictions used for recommending become more accurate .",
    "that means the regret should have an upper bound .",
    "therefore , lower regret bounds indicates better and faster distributed online learning algorithms .",
    "firstly , we give the definition of `` regret '' .    *",
    "definition 3 .",
    "* we propose algorithm 1 for social websites over data center networks .",
    "then , we measure the regret of the algorithm as @xmath94 where @xmath95 , denotes the average of @xmath26 parameters of all data centers at time @xmath13 .",
    "hence , @xmath96 is computed with respect to an average of @xmath26 parameters @xmath97 , which approximately estimates the actual performance of the whole system .    for analyzing the regret @xmath98 of algorithm 1",
    ", we firstly present a special lemma .",
    "* lemma 3 .",
    "* let @xmath99 be @xmath54-strongly convex functions , which have the norms @xmath100 and dual norms @xmath101 .",
    "when algorithm 1 keeps running , we have the following inequality @xmath102.\\end{aligned}\\ ] ]    we define @xmath103 , where @xmath104 .",
    "@xmath105 where intuitively @xmath106 and @xmath107 .    first ,",
    "according to fenchel - young inequality , we have @xmath108 then , @xmath109    combining ( 14 ) and ( 15 ) , summing over @xmath110 and @xmath111 , we get    @xmath112 } } .\\end{aligned}\\ ] ]    according to lemma 1 of wang et al.@xcite , we know @xmath113    finally , using ( 16 ) and ( 17 ) , we obtain ( 12 ) .    based on lemma 3",
    ", we easily have the regret bound of our system model",
    ".    * theorem 2 .",
    "* we propose algorithm 1 for social big data computing over data center networks . under assumption 1 and 2 , we define regret function as ( 11 ) . set @xmath114 , which is @xmath115-strongly convex .",
    "let @xmath116 , then the regret bound is @xmath117    for convex functions , we know that @xmath118    intuitively , due to ( 11 ) and ( 12 ) , we obtain @xmath119\\end{aligned}\\ ] ]    since @xmath114 , we have @xmath120 and @xmath121 .",
    "@xmath122 where @xmath123 is defined previously .",
    "we first compute @xmath124 : setting @xmath125 , we have @xmath126 where @xmath98 is defined in assumption 2 .",
    "then , for @xmath127 , we have @xmath128 \\le \\frac{{2\\sqrt 2mnl } } { \\epsilon}\\left ( { \\sqrt t   - \\frac{1}{2 } } \\right),\\\\ & s2 \\le \\frac{{2\\sqrt 2 { m^2}ntl}}{\\epsilon}\\left ( { \\sqrt t   - \\frac{1}{2 } } \\right)\\sim o\\left ( { \\sqrt t } \\right).\\end{aligned}\\ ] ]    combining ( 20 ) and ( 21 ) , we obtain ( 18 ) .                    according to theorem 2",
    ", the regret bound becomes the classical square root regret @xmath129 @xcite , which means less mistakes are made in social recommendations as the algorithm runs .",
    "this result demonstrates that our private online learning algorithm for the social system makes sense .",
    "further , due to ( 18 ) , we find : 1 ) a higher privacy level @xmath48 can enhance the regret bound ; 2 ) the number of data centers gets more , the regret bound become higher ; 3 ) the communication matrix @xmath8 seems not to affect the bound , but we think it may affect the convergence .",
    "all the observations will be simulated in the following numerical experiments .",
    "in this section , we conduct four simulations .",
    "the first one is to study the privacy and predictive performance trade - offs .",
    "the second one is to find whether the topology of social networks has a big influence on the performance .",
    "the third one is to study the sparsity and performance trade - offs .",
    "the final one is to analyze the performance trade - offs between the number of data centers and accuracy .",
    "all the simulations are operated on real large - scale and high - dimension social data .    for our implementations",
    ", we have the hinge loss @xmath130 , where @xmath131 , are the data available only to the @xmath10-th data center . for powers of persuasion , we use @xmath132 social data to experiment and the dimensionality of data is @xmath133 . since the tested data are real social data , we should pretreat the data .",
    "each dimension in vectors is normalized into a certain numerical interval .",
    "each data point is labeled with a value into @xmath134 $ ] according to its classification attribute . for the simulated model ,",
    "we design it as fig.1 .",
    "a few computing nodes are distributed randomly .",
    "each node is only connected with its adjacent nodes .",
    "everytime information exchanging is perturbed with laplace noise .",
    "all the experiments were conducted on a distributed model designed by hadoop under linux ( with 8 cpu cores , 64 gb memory ) .    in fig.2",
    ", the regret bound of the non - private algorithm has the lowest regret as expected and it shows that the regret gets closer to the non - private regret as its privacy preservation is weaker . the higher privacy level of @xmath48 leads to the more regret .",
    "fig.3 demonstrates that different topologies make no significant difference on the utility of the algorithm .",
    "fig.4 indicates that an appropriate sparsity can have the best performance and other lower or higher sparsity would lead to a worse performance .",
    "specifically , inducing sparsity can enhance the accuracy , obtaining nearly @xmath135 more than the non - sparse computing does .",
    "fig.5 studies the performance with respect to the number of data center nodes .",
    "more centers can have a little decline ( as much as @xmath136 per 4 nodes ) in the accuracy .",
    "internet has come into big data era .",
    "social networks are faced with massive data to handle . faced with these challenges , we proposed a private distributed online learning algorithm for social big data over data center networks .",
    "we demonstrated that higher privacy level leads to weaker utility of the system and the appropriate sparsity enhances the performance of online learning for high - dimension data .",
    "furthermore , there must exist delay in social networks , which we did not consider .",
    "hence , we hope that online learning with delay can be presented in the future work .",
    "this research is supported by national science foundation of china with grant 61401169 .",
    "s. ram , a. nedic , and v. veeravalli , `` distributed stochastic subgradient projection algorithms for convex optimization , '' journal of optimization theory and applications , vol .",
    "516 - 545 , 2010 .",
    "f. d. mcsherry , `` privacy integrated queries : an extensible platform for privacy - preserving data analysis , '' in proceedings of the sigmod international conference on management of data .",
    "acm , 2009 , pp ."
  ],
  "abstract_text": [
    "<S> with the rapid growth of internet technologies , cloud computing and social networks have become ubiquitous . </S>",
    "<S> an increasing number of people participate in social networks and massive online social data are obtained . in order to exploit knowledge from copious amounts of data obtained and </S>",
    "<S> predict social behavior of users , we urge to realize data mining in social networks . </S>",
    "<S> almost all online websites use cloud services to effectively process the large scale of social data , which are gathered from distributed data centers . </S>",
    "<S> these data are so large - scale , high - dimension and widely distributed that we propose a distributed sparse online algorithm to handle them . </S>",
    "<S> additionally , privacy - protection is an important point in social networks . </S>",
    "<S> we should not compromise the privacy of individuals in networks , while these social data are being learned for data mining . </S>",
    "<S> thus we also consider the privacy problem in this article . </S>",
    "<S> our simulations shows that the appropriate sparsity of data would enhance the performance of our algorithm and the privacy - preserving method does not significantly hurt the performance of the proposed algorithm .    </S>",
    "<S> cloud computing , social networks , sparse , distributed online learning . </S>"
  ]
}