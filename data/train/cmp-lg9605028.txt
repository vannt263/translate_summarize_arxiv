{
  "article_text": [
    "total system evaluation plays an important role for developers of spoken dialogue systems , because it allows both to monitor progress within a single project and to compare different solutions for the same task .",
    "an objective and verifiable judgement of system performance requires that the scientific community agrees upon widely accepted evaluation measures . in speech recognition ,",
    "such a mutually agreed upon measure is available with the so - called _ word accuracy _ ( wa ) .",
    "there exist standardized tools which can automatically compute the wa of recognition results for a given test corpus annotated with transcriptions of the actually spoken words .",
    "this high standard of automatic evaluation methods could not yet be transferred to the higher processing level of speech _ understanding _ , although the last few years have witnessed increasing efforts in the development of an evaluation methodology for natural language processing ( cf .",
    "@xcite , @xcite , @xcite ) .",
    "this paper describes our approach to automatic evaluation of both the _ recognition _ and the _ understanding _ capabilities of a spoken dialogue system for train time table inquiries  @xcite .",
    "such an integrated evaluation environment allows a systematic investigation of the relationship between recognition and understanding performance .",
    "the central question is : _ how does a change in the recognition accuracy affect the understanding accuracy ? _",
    "first we describe the evaluation measures _ word accuracy _ and _ concept accuracy_. after this we show our evaluation architecture for automatic calculation of recognition and understanding accuracy . finally , we report results for a spontaneous speech corpus containing about 10000 utterances .",
    "automatic evaluation methods require the use of prepared test corpora in which each test case is combined with a `` correct '' reference answer against which the system output can be judged . in speech recognition , it is relatively uncontroversial how this reference answers look like : they are transcriptions of the words that were actually spoken .",
    "it is less clear , however , what constitutes the `` correct '' analysis at the level of language understanding .",
    "currently , there is no agreement among computational linguists regarding a `` correct '' semantic representation for a wide variety of linguistic phenomena . as a consequence , there are no semantically annotated corpora available as a common test bed for comparative evaluation of linguistic processing components .",
    "nevertheless , we believe that an objective and verifiable measurement of the understanding capabilities of a system can only be achieved with a `` reference answer''-based approach using test corpora with semantic annotations .",
    "this conviction is based on the fact that the main task of the linguistic processing component in a spoken dialogue system is to map the spoken input to a semantic representation .",
    "evaluation approaches which look only at the surface forms or the syntactic structures  @xcite of the parsing results can not judge the parser performance regarding the construction of a semantic representation .",
    "therefore , we defined a semantic annotation format within our task domain . for measuring the understanding performance we adopted the",
    "so - called _",
    "concept accuracy_. this measure , which was proposed from the evaluation working group of the esprit project sundial  @xcite , can be calculated automatically in analogy with the recognition measure _",
    "word accuracy_.      word accuracy ( wa ) is a widely accepted evaluation measure for word recognizers .",
    "the automatic calculation of wa for a given set of recognition results requires the existence of reference transliterations for all spoken utterances .",
    "the reference answers consist of a transcription of what was actually spoken .",
    "given the reference ref , the wa of the recognizer output hyp is determined by calculating the levenshtein distance between ref and hyp and by assigning equal costs to substitution , insertion , and deletion errors .",
    "wa is calculated as a percentage using the formula @xmath0 where @xmath1 is the total number of words in ref , and @xmath2 , @xmath3 , @xmath4 are the number of reference words which were substituted , inserted , and deleted in hyp , respectively .",
    "for example , the wa of the recognized string in  ( [ waex ] ) is 66.7% , since the spoken word i was deleted and the spoken word berlin was substituted by bonn in hyp , such that @xmath5 and @xmath6 . by inserting these values into formula  ( [ wortakkuratheit ] ) the wa is calculated by @xmath7 .    [ waex ]    [ cols= \" < , > , < , < \" , ]     table  [ evalres ] shows that the marks for wa and ca correspond closely .",
    "this means that in our case the misrecognition in the acoustic front end processor affects content words and filler words by the same amount .",
    "moreover , we can see that the linguistic processor does not suffer from misrecognition of a few words .",
    "the parser has to be judged as extremely robust against recognition errors as well as phenomena of spontaneous speech .",
    "figure  [ graphics ] shows the nearly linear relation between word accuracy and corresponding concept accuracy .    in our case we can make the assumption that word accuracy is a suitable indicator for concept accuracy in a spoken dialogue system : recognizer and parser",
    "are well matched for their tasks and cooperate smoothly .",
    "in this paper we have shown an approach for the automated evaluation of an understanding module for spontaneous speech .",
    "this module consists of an acoustic recognizer and a linguistic processor .",
    "the resulting semantic content of each utterance is compared automatically with reference annotations , mimicking the evaluation of a word recognizer alone .",
    "accordingly , the measure for a speech understanding system is called _",
    "concept accuracy_.    with our evaluation setup we are able to document improvements in one of our modules in an automated way .",
    "thus , we are not only able to optimize isolated modules , but the whole understanding system .",
    "experiments show that our parser is robust in the sense that we observe a nearly linear relation between wa and ca .",
    "further work will be commited to adjust parser parameters .",
    "eventually we hope to increase ca beyond wa .",
    "part of this work was carried out in the project syslid which is funded by the daimler - benz research institute in ulm .",
    "part of this work was supported by the german research foundation ( dfg ) under contract number 810 830 - 0 .",
    "e.  black , s.  abney , d.  flickenger , c.  gdaniec , r.  grishman , p.  harrison , d.  hindle , r.  ingria , f.  jelinek , j.  klavans , m.  liberman , m.  marcus , s.  roukos , b.  santorini , and t.  strzalkowski .",
    "a procedure for quantitatively comparing the syntactic coverage of english grammars . in _ proceedings of darpa speech and natural language workshop _",
    ", pages 306311 , pacific grove , 1991 .",
    "w.  eckert , th .",
    "kuhn , h.  niemann , s.  rieck , a.  scheuer , and e .-",
    "schukat - talamazzini . a spoken dialogue system for german intercity train timetable inquiries . in _ proceedings of eurospeech",
    "93 _ , volume  3 , pages 18711874 , berlin , 1993 .",
    "w.  eckert , e.  nth , h.  niemann , and e .-",
    "schukat - talamazzini .",
    "real users behave weird  experiences made collecting large human - machine - dialog corpora . in _ proceedings of the esca tutorial and research workshop on spoken dialogue systems _ ,",
    "pages 193196 , vigs , denmark , 1995 .",
    "l.  hirschman and h.  thompson .",
    "overview of evaluation in speech and natural language processing . in r.  cole , editor , _ survey of the state of the art in human language technology_. cambridge university press , cambridge , 1996 . to appear .",
    "k.  mecklenburg , p.  heisterkamp , and g.  hanrieder . a robust parser for continuous spoken language using prolog . in _ proceedings of the fifth international workshop on natural language understanding and logic programming ( nlulp 95 ) _ , pages 127141 , lisbon , portugal , 1995"
  ],
  "abstract_text": [
    "<S> in this paper we describe an approach to automatic evaluation of both the speech _ recognition _ and _ understanding _ capabilities of a spoken dialogue system for train time table information . </S>",
    "<S> we use _ word accuracy _ for recognition and _ concept accuracy _ for understanding performance judgement . </S>",
    "<S> both measures are calculated by comparing these modules output with a correct reference answer . </S>",
    "<S> we report evaluation results for a spontaneous speech corpus with about 10000 utterances . </S>",
    "<S> we observed a nearly linear relationship between word accuracy and concept accuracy . </S>"
  ]
}