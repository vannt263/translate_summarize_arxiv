{
  "article_text": [
    "totally unimodular matrices are a class of @xmath3 matrices which is of great importance to combinatorial optimisation since they describe a special class of polynomial time solvable integer programs . specifically ,",
    "every integer program which is defined by a totally unimodular constraint matrix can be solved as a linear program by relaxing the integrality constraint since the associated polyhedron is integral . although there exist various equivalent characterisations for this class of matrices , it was seymour s decomposition theory  @xcite developed for the associated regular matroids , that yielded a polynomial time algorithm for recognising them .",
    "seymour s decomposition theorem states that all totally unimodular matrices can be constructed recursively by applying @xmath0-sum operations @xmath4 on network matrices , their transposes and two totally unimodular matrices @xmath5 and @xmath6 .",
    "these sum operations , are essentially matrix operations which preserve certain structural properties . combined with the fact that the matrices @xmath5 and @xmath6 are easily recognisable , and tutte s theory for recognising network matrices , seymour s theorem implies an algorithm to check whether a given matrix is totally unimodular or not .",
    "moreover , and maybe even more importantly , it also provides a framework for graphical representation of totally unimodular matrices .",
    "bidirected graphs are a generalisation of directed graphs , and can be represented algebraically by the so - called binet matrices in the same way network matrices represent directed graphs .",
    "appa and kotnyek  @xcite have shown that @xmath5 and @xmath6 can be represented on bidirected graphs since they have been proved to be binet .",
    "since bidirected graphs generalise directed graphs , all the building blocks of totally unimodular matrices or their transposes are representable on bidirected graphs . in this work",
    "we show that every totally unimodular matrix has an associated bidirected graph representation , which provides a partial interpretation of the nice integrality property of the associated polyhedron and may provide the means of devising a combinatorial algorithm for solving the related integer programming problem .    initially we show constructively that the @xmath0-sum of two network matrices is a network matrix and that of a network and a binet matrix is a binet matrix .",
    "however , for @xmath2 we show that the @xmath0-sum of two binet matrices is not necessarily a binet matrix . based on this",
    "we can state that not all totally unimodular matrices are binet . to pursue graphical representability further a new class of @xmath7 matrices",
    "is introduced , the so - called _ tour matrices _ , which represent closed tours on bidirected graphs .",
    "we show that network matrices as well as @xmath5 and @xmath6 are tour matrices , and in contrast to binet matrices , it is also shown that tour matrices are closed under @xmath0-sums .",
    "this means that totally unimodular matrices not previously associated with bidirected graphs can now be represented on bidirected graphs .",
    "the paper is organised as follows .",
    "section  [ sec_prel ] presents all the preliminary theory regarding network matrices , bidirected graphs and binet matrices , totally unimodular matrices as well as the definition of the @xmath0-sum operations . in section  [ sec_ksums ]",
    "we examine the operation of @xmath0-sums of network and binet matrices , where the most general case for @xmath8 is treated and a graphical construction of the operation is presented .",
    "the negative result in this section is that binet matrices are not closed under @xmath0-sums .",
    "tour matrices are defined in section  [ subsec_tour_properties ] where various properties are proved . in section  [ subsubsec_ksums_tour ]",
    "we show that tour matrices are closed under @xmath0-sums , while in section  [ subsubsec_algorithm ] we gather all the results presented on the paper on an algorithm for constructing a bidirected graph of any tu matrix .",
    "a _ directed graph _ @xmath9 consists of a finite set of nodes @xmath10 and a family @xmath11 of _ ordered _ pairs of @xmath10 . for an edge @xmath12 , @xmath13 and @xmath14",
    "are called the _ end - nodes _ of @xmath15 ; @xmath13 is called the _ tail _ of @xmath15 and @xmath14 the _ head _ of @xmath15 .",
    "we also say that @xmath12 _ leaves _ @xmath13 and _ enters _ @xmath14 .",
    "the _ node - edge incidence matrix _ of a directed graph @xmath9 is the @xmath16 matrix @xmath17 with @xmath18 + for any @xmath19 and any non - loop @xmath20 .",
    "if @xmath15 is a loop , we set @xmath21 for each vertex @xmath14 .",
    "the definition for the network matrices goes as follows :    let @xmath22 $ ] be the incidence matrix of a directed graph @xmath9 minus an arbitrary row , where @xmath23 is a basis of the column space of @xmath17 .",
    "the matrix @xmath24 is called a _ network matrix_.    for material related to graphs and network matrices",
    "the reader is referred to  @xcite .",
    "a bidirected graph @xmath25 is defined over a finite node set @xmath10 and an edge set @xmath26 .",
    "there are four types of edges : a _ link _ has two different end - nodes , a _ loop _ has two end - nodes that coincide , a _",
    "half - edge _ has one end - node , and a _ loose edge _ which has no end - nodes @xcite .",
    "every edge is assigned a _ sign _ , so that half - edges are always negative ; loose edges are always positive ; links and loops can be positive or negative .",
    "the edges are _ oriented _ , i.e. , we label the end - nodes of the edges by @xmath27 or @xmath28 .",
    "the labels of a positive edge are different , those of a negative edge are the same . if an end - node of an edge is labeled with @xmath27 , then it is an _ in - node _ of the edge , otherwise an _ out - node_. these names come from the graphical representation of bidirected graphs , where incoming and outgoing arrows on an edge represent positive and negative labels .",
    "for example in the bidirected graph shown in figure  [ fig : fundex ] , edge @xmath29 is a positive link ; @xmath30 is a negative ; @xmath31 is a negative loop ; and @xmath32 is a half - edge .",
    "loose edges and positive loops are not depicted in this illustration .",
    "a _ walk _ in a bidirected graph is a sequence @xmath33 where @xmath34 and @xmath35 are end - nodes of edge @xmath36 ( @xmath37 ) , including the case where @xmath38 and @xmath36 is a half - edge . if @xmath39 , then the walk is _",
    "closed_. a walk which consists of only links and does not cross itself , that is @xmath40 for @xmath41 , is a _",
    "path_. a closed walk which does not cross itself ( except at @xmath39 ) is called a _ cycle_. that is , a cycle can be a loop , a half - edge or a closed path .",
    "the _ sign of a cycle _ is the product of the signs of its edges , so we have a _ positive cycle _ if the number of negative edges in the cycle is even , otherwise the cycle is a _ negative cycle_. obviously , a negative loop or a half - edge always makes a negative cycle .",
    "a bidirected graph is _ connected _ , if there is a path between any two nodes .",
    "the _ node - edge incidence matrix _ of a bidirected graph @xmath42 is the @xmath16 matrix @xmath43 with @xmath44 for any vertex @xmath45 and any edge @xmath46 .",
    "the following operations are defined on bidirected graphs .",
    "_ deletion of an edge _ is simply the removal of the edge ; _ deletion of a node _ means that the node and all the edge - ends incident to it are removed .",
    "thus incident half - edges or loops become loose edges , incident links become half - edges .",
    "deletion of an edge or a node is equivalent to the deletion of the corresponding column or row from the node - edge incidence matrix . _",
    "switching _ at a node is the operation when all the labels at the incident edge - ends are changed to the opposite .",
    "it corresponds to the multiplication by @xmath28 of a row in the incidence matrix . finally , _ contracting an edge _",
    "@xmath15 is the operation in which the end - nodes of @xmath15 are modified and @xmath15 is shrunk to zero length . for different types of edges contraction manifests itself differently .",
    "specifically , if @xmath15 is a negative loop or a half - edge then the node incident to it is deleted together with all the edge - ends incident to it .",
    "if @xmath15 is a positive link , then its two end - nodes are identified and @xmath15 is deleted .",
    "if @xmath15 is a negative link , then first we switch at one of its end - nodes to make it a positive link , then contract it as defined for positive links .",
    "if @xmath15 is a positive loop then @xmath15 is simply deleted .",
    "binet matrices are defined similarly as network matrices as follows :    [ def_binet ] let @xmath43 be a full row rank node - edge incidence matrix of a bidirected graph @xmath47 , @xmath23 be a basis of it and @xmath48 $ ] .",
    "the matrix @xmath49 is called a _ binet matrix_.    when in a bidirected graph @xmath47 the subgraph @xmath50 is indicated for a basis @xmath23 , we call it a _ binet representation _ or a _",
    "binet graph_. in figure  [ fig : fundex ] the binet graph for basic edges @xmath51 and non - basic edges @xmath52 is shown , with the associated binet matrix .",
    "it is noted that in computing the entries of a binet matrix for a given basis , instead of using definition  [ def_binet ] which involves the inverse of a matrix , there also exists a combinatorial algorithm described in  @xcite .",
    "for a column @xmath53 of @xmath54 , let @xmath55 be the columns of @xmath23 for which the corresponding component of vector @xmath56 is non - zero .",
    "the vectors @xmath55 and @xmath53 form a minimal linearly dependent set in @xmath57 .",
    "the subgraphs of @xmath47 induced by sets of edges which correspond to minimally dependent sets of columns in @xmath58 have to be one of the following three types as shown in  @xcite :    * a positive cycle , * a graph consisting of two negative cycles which have exactly one common node , * a graph consisting of two node - disjoint negative cycles connected with a path which has no common node with the cycles except its end - nodes .",
    "graphs in categories ( ii ) and ( iii ) are called _ handcuffs _ of type i and ii respectively .",
    "for example in the bidirected graph illustrated in figure  [ fig : fundex ] the subgraph induced by the edges @xmath59 is a positive cycle , while the sets of edges @xmath60 and @xmath61 induce handcuffs of type i and ii respectively .        some results concerning binet matrices which will be useful are the following .",
    "proofs can be found in  @xcite .",
    "binet matrices are closed under the following operations :    \\(a ) switching at a node of a binet graph .",
    "\\(b ) multiplying a row or column with @xmath28 .",
    "\\(c ) deleting a row or a column .",
    "\\(d ) pivoting ( in @xmath62 ) on a nonzero element .",
    "switching at a node does not change the matrix , the new binet graph represents the same matrix . multiplying a row or column with @xmath28",
    "is equivalent to reversing the orientation of the corresponding basic or non - basic edge . deleting a column is simply deleting the corresponding non - basic edge , while deleting a row amounts to contracting the corresponding basic edge . pivoting on an element in row @xmath63 and",
    "column @xmath53 means that these edges are exchanged in the basis .",
    "a matrix @xmath64 is totally unimodular if each square submatrix of @xmath64 has determinant @xmath65 or @xmath28 .",
    "there are numerous other characterisations of the class of tu matrices ( see @xcite ) . the following decomposition theorem for tu matrices proved by seymour  @xcite plays a central role in this work , and also yields a polynomial - time test for total unimodularity .",
    "[ seymour_matrix ] any totally unimodular matrix is up to row and column permutations and scaling by @xmath66 factors a network matrix , or the transpose of such a matrix , or the matrix @xmath5 or @xmath6 of ( [ eq_b1 ] ) and ( [ eq_b2 ] ) , or may be constructed recursively from these matrices using matrix @xmath67- , @xmath68- and @xmath69-sums ( see definition  [ def_k - sums ] ) .",
    "matrices @xmath5 and @xmath6 are binet matrices , as it is indicated by the corresponding binet graphs shown in ( [ eq_b1 ] ) and ( [ eq_b2 ] ) .",
    "the above theorem is essentially a direct consequence of a decomposition theory for matroids associated with tu matrices , the so - called _",
    "regular matroids_. specifically seymour characterised the class of regular matroids by defining certain operations called @xmath0-sums , such that every regular matroid can be decomposed into a set of elementary building blocks via these operations , if and only if these blocks satisfy certain properties .",
    "@xmath70{b1.eps}\\hfill } } \\hspace*{\\fill}\\ ] ] @xmath71{b2.eps}\\hfill } } \\hspace*{\\fill}\\ ] ]    in general , @xmath0-sum operations @xmath4 are defined in the more general theoretical framework of matroids , and here we basically treat the specialised version of this operation as applied to the compact representation matrices of regular matroids .",
    "moreover , it can be shown that applying these operations on totally unimodular matrices preserves their total unimodularity .",
    "[ def_k - sums ] if @xmath72 are matrices and @xmath73 and @xmath74 are column and row vectors of appropriate size in @xmath62 then    1-sum : : :    @xmath75 2-sum : : :    @xmath76 3-sum : : :    @xmath77 or +    @xmath78 +    where in the @xmath79-sum row vectors @xmath80    and @xmath81 and column vectors @xmath82 and    @xmath83 are submatrices of @xmath84 and the    @xmath85 matrix @xmath86 is the    intersection of rows @xmath80 and @xmath81 with columns    @xmath82 and @xmath83",
    ". further the rank of    @xmath87\\bar{d}^{-1}[\\frac{b}{c}]$ ] is two .",
    "note that there    are two alternative definitions for @xmath69-sum , distinguished    by @xmath88 and @xmath79 .",
    "the indices of    the isolated columns and rows in the 2-sum and 3-sum operations , will    be called _ connecting elements_.    the definition of the @xmath0-sums may seem complicated at first glance , but they essentially provide a way to decompose a tu matrix into smaller tu matrices given that the matrix admits such a decomposition .",
    "specifically suppose that we have a tu matrix @xmath89 which under row and column permutations can take the form @xmath90 and the following two conditions are satisfied :    * number of rows and columns of both @xmath64 and @xmath91 @xmath92 , * @xmath93 where @xmath94 are viewed over @xmath95 .",
    "then the matrix @xmath89 of ( [ eq_example_matrix ] ) can be decomposed under a @xmath0-sum operation into two matrices of smaller size which are submatrices of @xmath89 , preserving total unimodularity . in the case of",
    "@xmath69-sum we note from the definition that there are two alternative operations , reflecting the fact that condition ( ii ) above can be satisfied in two different ways ( i.e. @xmath96 or @xmath97 ) .",
    "however it can be shown that when the matrices are tu both definitions of @xmath69-sum are equivalent under pivoting in either @xmath95 or @xmath57 .",
    "( the regular matroid decomposition theorem of seymour , @xmath0-sums of matrices and their corresponding matroids , and decomposition theory for matroids in general is treated extensively in  @xcite . )",
    "in this section we will examine the operation of @xmath0-sums of matrices , both network and binet .",
    "we will show whether the resulting matrix is a network or binet matrix , or does not belong to either class .",
    "algebraic proofs as well as graphical representations of the associated operations on these matrices are presented .",
    "here it is proved that network matrices are closed under the @xmath0-sum operations .",
    "since network matrices are the compact representation matrices of graphic matroids , a direct consequence of these results is the well known fact ( see @xcite ) that graphic matroids are closed under @xmath0-sums .",
    "however the analytical methodology in the proofs that will be given here , will be used in the sections that will follow where the binet , and the more general tour matrix case is treated .",
    "moreover since the proof is constructive , it is used in the algorithm for composing the bidirected graph of a tu matrix which will be presented in section  [ subsubsec_algorithm ] .      the most general case of 3-sum",
    "will be examined since the other sum operations follow .",
    "[ lem_net-3sum - net ] if @xmath98 , @xmath99 are network matrices such that @xmath100 , \\end{array }   $ } n_2 =   \\raisebox{5pt}{$ \\begin{array}{r } \\vspace{-5 mm } \\hspace{-3.2 mm }     \\\\ f_3 \\end{array } \\hspace{-2.5 mm } \\begin{array}{c }",
    "\\begin{array}{crr } \\hspace{-3.2 mm } f_1 & \\hspace{-1.3 mm } f_2 &    \\end{array } \\\\ \\left [ \\begin{array}{ccc } 1 & 0 & b\\\\ d & d & b \\end{array }     \\right ] , \\end{array }   $ } \\ ] ] then @xmath101 is a network matrix .    because of the definition of the @xmath69-sum operation we have that in a possible graphical representation of @xmath98 the fundamental cycle of @xmath102 consists of the edges that correspond to non - zero elements in @xmath82 .",
    "the fundamental cycle of @xmath103 has all these edges and @xmath104 .",
    "this means that @xmath102 , @xmath103 and @xmath104 should form a triangle .",
    "similarly , @xmath105 , @xmath106 and @xmath107 form a triangle in any network representation of @xmath99 .",
    "let now @xmath108 $ ] and @xmath109 $ ] be the incidence matrices associated with @xmath98 and @xmath99 , respectively , where after permutations and/or multiplications of rows with @xmath66 we can write : @xmath110= \\begin{array}{c } \\begin{array } { crrrc } & \\hspace{10 mm } e_3 & \\hspace{0.37 in } e_1 & \\hspace{1 mm } e_2 & \\end{array}\\\\ \\left [ \\begin{array}{cr|crr } r_1         & -1 & s_1    & 0    & -1\\\\ r_1 '        & 1   & s_1 '   & -1   & 0\\\\ r_1 ''       & 0   & s_1 '' & 1    & 1\\\\ { r_1 } '   & \\mathbf{0 } & { s_1 } '    & \\mathbf{0 } & \\mathbf{0 }   \\end{array } \\right ] \\end{array } , \\quad [ r_2|s_2]= \\begin{array}{c } \\begin{array } { ccccc } \\hspace{-2 mm } f_3   &   & \\hspace{5.5 mm }   f_1 & \\hspace{1 mm } f_2 & \\end{array}\\\\ \\left [ \\begin{array}{rc|rrc } 0       & r_2    & -1   & -1 & s_2\\\\ -1      & r_2 '   &   0   & 1   & s_2'\\\\ 1       & r_2 '' &   1   & 0   & s_2''\\\\ \\mathbf{0 }   & { r_2 } '    & \\mathbf{0 } & \\mathbf{0 } & { s_2 } ' \\end{array } \\right ] \\end{array}\\ ] ] where @xmath111 is a vector or matrix of zeros of appropriate size , @xmath112 and @xmath113 are row vectors and @xmath114 are matrices of appropriate size @xmath115 . by the definition of network matrices",
    "the following two equations hold : @xmath116 for @xmath98 using ( [ eq_fourtythree ] ) and ( [ eq_fourtyfive ] ) we have that : @xmath117 \\left [ \\begin{array}{c|c|c } a   &   a   & a \\\\ \\hline c   &   0   & 1 \\end{array}\\right]= \\left [ \\begin{array}{c|r|r } s_1        &    0   & -1\\\\ s_1 '       &   -1   &   0\\\\ s_1 ''      &    1   &   1\\\\ \\hline { s_1 } ' & \\mathbf{0 } & \\mathbf{0 } \\end{array } \\right]\\ ] ] where upon decomposing the block matrix multiplications we derive the following equations .",
    "\\left [ \\begin{array}{r } -1\\\\ 1\\\\ 0 \\end{array } \\right]c= \\left [ \\begin{array}{c } s_1\\\\ s_1'\\\\ s_1 '' \\end{array } \\right],\\quad \\left [ \\begin{array}{c } r_1\\\\ r_1'\\\\ r_1 '' \\end{array } \\right]a = \\left [ \\begin{array}{r } 0\\\\ -1\\\\ 1 \\end{array } \\right]\\\\ \\nonumber    \\left [ \\begin{array}{c } r_1\\\\ r_1'\\\\ r_1''\\\\ \\end{array } \\right]a+ \\left[\\begin{array}{r } -1\\\\ 1\\\\ 0 \\end{array } \\right]= \\left [ \\begin{array}{r } -1\\\\ 0\\\\ 1 \\end{array } \\right ] , \\quad { r_1}'a={s_1 } ' , \\quad { r_1}'a=\\mathbf{0}\\end{aligned}\\ ] ] similarly , for @xmath99 using ( [ eq_fourtythree ] ) and ( [ eq_fourtyfive ] ) we have @xmath119 \\left [ \\begin{array}{c|c|c } 1     &   0    &   b\\\\ \\hline d     &   d    &   b \\end{array } \\right]= \\left [ \\begin{array}{r|r|c } -1    &   -1   & s_2\\\\ 0     &    1   & s_2'\\\\ 1     &    0   & s_2''\\\\ \\hline \\mathbf{0 } & \\mathbf{0 } & { s_2 } ' \\end{array } \\right]\\ ] ] so that @xmath120 + \\left [ \\begin{array}{c } r_2\\\\ r_2'\\\\ r_2 '' \\end{array } \\right]d= \\left [ \\begin{array}{r } -1\\\\ 0\\\\ 1 \\end{array } \\right ] , \\quad \\left [ \\begin{array}{c } r_2\\\\ r_2'\\\\ r_2 '' \\end{array } \\right]d= \\left [ \\begin{array}{r } -1\\\\ 1\\\\ 0 \\end{array } \\right ] \\quad",
    "\\\\ \\nonumber \\left [ \\begin{array}{r } 0\\\\ -1\\\\ 1 \\end{array } \\right]b+ \\left [ \\begin{array}{c } r_2\\\\ r_2'\\\\ r_2 '' \\end{array } \\right]b= \\left [ \\begin{array}{c } s_2\\\\ s_2'\\\\ s_2 '' \\end{array } \\right],\\quad { r_2}'d=\\mathbf{0 } , \\quad { r_2}'b={s_2}'\\end{aligned}\\ ] ] using block matrix multiplication and equations in ( [ eq_fourtyeight ] ) and ( [ eq_fiftyfour ] ) , it is easy to show that the following equality holds : @xmath121 } _ { r'}\\underbrace { \\left [ \\begin{array}{c|c } a   & ab\\\\ \\hline dc & b \\end{array } \\right ] } _ { n}= \\underbrace { \\left [ \\begin{array}{c|c } s_1   & s_2\\\\ s_1 ' & s_2'\\\\ s_2 '' & s_2''\\\\ \\hline { s_1 } ' & \\mathbf{0}\\\\ \\hline \\mathbf{0 } & { s_2 } ' \\end{array } \\right ] } _ { s'}\\ ] ] the matrix @xmath122 $ ] is the incidence matrix of a directed graph since each column contains a @xmath27 and a @xmath28 .",
    "it remains to be shown that the matrix @xmath123 obtained by deleting one row of @xmath124 is non - singular .",
    "if we delete the first row of @xmath124 we have that : @xmath125\\ ] ] if we delete the first row from @xmath126 then we obtain the matrix @xmath127 $ ] which is a non - singular one .",
    "expanding now the determinant of that matrix along the last column we can see that the matrix @xmath128 $ ] is also non - singular .",
    "therefore , within the submatrix @xmath129 $ ] of @xmath123 , @xmath130 can be written as a linear combination of the other rows : @xmath131 where @xmath13 is a scalar , and @xmath132 is a column vector of appropriate size with elements in @xmath57 . also ,",
    "we have that @xmath133 since if we delete @xmath104 in @xmath126 then the matrix obtained corresponds to a forest in which the nodes which correspond to rows @xmath130 and @xmath134 belong to the same tree of that forest .",
    "we denote the determinant of @xmath123 by @xmath135 $ ] . using ( [ eq_ninetyfive ] )",
    "we get : @xmath136= det\\left[\\begin{array}{c|c } r_1 '   & r_2'\\\\ r_1 '' & r_2''\\\\ { r_1 } ' & \\mathbf{0}\\\\ \\hline \\mathbf{0 } & { r_2 } ' \\end{array } \\right]= det\\left[\\begin{array}{c|c } 0      & r_2'+u~r_2''\\\\ r_1 '' & r_2''\\\\ { r_1 } ' & \\mathbf{0}\\\\ \\hline \\mathbf{0 } & { r_2 } ' \\end{array }",
    "\\right ]   =   det\\left[\\begin{array}{c|c } r_1 '' & r_2''\\\\ { r_1 } ' & \\mathbf{0}\\\\ \\hline 0      & r_2'+u~r_2''\\\\ \\mathbf{0 } & { r_2 } ' \\end{array } \\right]\\ ] ] so , matrix @xmath123 is block diagonal and its blocks are square .",
    "thus : @xmath137= det\\left [ \\begin{array}{c } r_1''\\\\ { r_1 } ' \\end{array } \\right ] det\\left [ \\begin{array}{c } r_2'+u~r_2''\\\\ { r_2 } ' \\end{array } \\right]= det\\left [ \\begin{array}{c } r_1''\\\\ { r_1 } ' \\end{array } \\right ] \\left(det\\left [ \\begin{array}{c } r_2'\\\\ { r_2 } ' \\end{array } \\right]+ u\\,det\\left [ \\begin{array}{c } r_2''\\\\ { r_2 } ' \\end{array}\\right ] \\right)\\ ] ] if we delete from @xmath138 its first row then the matrix so obtained is non - singular and , since it is a submatrix of a tu matrix , it has to be tu as well , i.e. its determinant should be equal to @xmath66 . expanding the determinant of that matrix along its first column",
    "we take : @xmath139 + det\\left [ \\begin{array}{c } r_2''\\\\ { r_2 } ' \\end{array } \\right]=\\pm{1}\\ ] ] furthermore @xmath140 , det\\left [ \\begin{array}{c } r_2''\\\\ { r_2 } ' \\end{array } \\right]\\in{\\{0,\\pm{1}\\}}$ ] since the corresponding matrices are tu . from ( [ eq_ninetyeight ] ) we see that exactly one of these matrices has a nonzero determinant . combining this with ( [ eq_ninetyseven ] ) and the fact that @xmath133 we have that @xmath123 is nonsingular .",
    "+ finally , it is obvious that the matrix @xmath122 $ ] contains a @xmath28 and a @xmath27 in each column since its columns are columns of @xmath108 $ ] and @xmath109 $ ] .",
    "we can conclude that the 3-sum of two network matrices is a network matrix with incidence matrix @xmath122 $ ] .",
    "[ th_net_cl ] network matrices are closed under @xmath0-sums @xmath4 .    for @xmath141",
    "it is straightforward . for @xmath142",
    "it is enough to observe that if @xmath143 are network matrices , then the matrices @xmath144 and @xmath145 are network matrices too , since we have only duplicated columns and added unitary rows and columns .",
    "but then @xmath146 which we know from lemma  [ lem_net-3sum - net ] to be network . for the alternative @xmath69-sum operation ,",
    "since network matrices are closed under pivoting the result follows .      in this section",
    "we examine the @xmath0-sums between network and binet matrices .",
    "we prove that the result is always a binet matrix and we provide the associated bidirected graph representations .",
    "let s assume that @xmath99 of lemma [ lem_net-3sum - net ] is a binet matrix instead of a network matrix ; then in a possible representation of it , its edges could be not only links but also loops and half edges .",
    "most importantly , because of the structure of matrix @xmath99 we have that the edges @xmath105 , @xmath106 and @xmath107 should be of a specific type ( loop , link , or half - edge ) in order to form a binet representation of @xmath99 .",
    "we examine below all the possible cases .",
    "if @xmath107 is a link in the cycle ( and then we can assume that it is a positive link ) , then @xmath105 and @xmath106 can not be half - edges , because the fundamental circuit of a half - edge uses all the cycle edges , and the values on the cycle edges determined by the fundamental circuit are halves , so there can be neither 0 nor 1 in the row @xmath107 and columns @xmath105 and @xmath106 of @xmath99 .",
    "furthermore , @xmath106 can not be a loop , because the fundamental circuit of any loop uses all cycle edges , despite the @xmath147 in the corresponding position of the matrix .",
    "so either both @xmath105 and @xmath106 are links , or @xmath105 is a loop and @xmath106 is a link . if they are both links , then they are both positive or both negative",
    ". otherwise the fundamental circuit of one of them would use the negative edge in the cycle , the other would not , and they use the same edges except for the positive @xmath107 .",
    "moreover , @xmath148 and @xmath107 must form a triangle , so by a switching at a node we can make both @xmath105 and @xmath106 positive .",
    "if @xmath107 is a loop , then @xmath105 can not be a half - edge , because then the entry in row @xmath107 and column @xmath105 of @xmath99 would be a half .",
    "if @xmath105 is a loop , then vector @xmath83 of @xmath99 contains @xmath149 entries , but this is impossible because then @xmath106 would be an edge whose fundamental circuit uses non - cycle edges twice but does not use the basic cycle ( which is @xmath107 ) . so @xmath105 must be a link , which implies that @xmath106 is also a link , and @xmath105 is negative and @xmath106 is positive , because the fundamental circuit of @xmath105 uses the basic cycle , that of @xmath106 does not .    if @xmath107 is a half - edge , then @xmath106 must be a positive link , as its fundamental circuit does not use the basic cycle formed by @xmath107 .",
    "this also implies that @xmath105 is a half - edge .",
    "if @xmath107 is a non - basic link , then @xmath105 can not be a loop , as then it would have @xmath150 on @xmath107 in the fundamental circuit .",
    "so either @xmath105 is a link and then @xmath106 is a link or a loop ; or @xmath105 is a half - edge in which case @xmath106 is also a half - edge .",
    "therefore the cases that may appear are the following six :    * @xmath107 is a positive link in the cycle and @xmath105 , @xmath106 are positive links ; * @xmath107 is a positive link in the cycle , @xmath105 is a negative loop and @xmath106 is a negative link ; * @xmath107 is a negative loop , @xmath105 is a negative link and @xmath106 is a positive link ; * @xmath105 , @xmath107 are half - edges and @xmath106 is a positive link ; * @xmath107 is a non - cycle link , @xmath105 is a link and @xmath106 is a link or a negative loop ; and * @xmath107 is a non - cycle link and @xmath105 , @xmath106 are half - edges .",
    "[ lem_net-3sum - binet ] if @xmath98 is a network matrix and @xmath99 is a binet matrix such that @xmath100 , \\end{array }   $ } n_2 =   \\raisebox{5pt}{$ \\begin{array}{r } \\vspace{-5 mm } \\hspace{-3.2 mm }     \\\\",
    "f_3 \\end{array } \\hspace{-2.5 mm } \\begin{array}{c }",
    "\\begin{array}{crr } \\hspace{-3.2 mm } f_1 & \\hspace{-1.3 mm } f_2 &    \\end{array } \\\\ \\left [ \\begin{array}{ccc } 1 & 0 & b\\\\ d & d & b \\end{array }     \\right ] , \\end{array }   $ } \\ ] ] then @xmath151 is a binet matrix .    since @xmath98 is a network matrix we have that @xmath102 , @xmath103 and @xmath104 should form a triangle . therefore , w.l.o.g .",
    "we can assume for all the cases that the incidence matrix associated with the network matrix @xmath98 is the following one : @xmath152= \\begin{array}{c } \\begin{array } { crrrc } & \\hspace{10 mm } e_3 & \\hspace{0.37 in } e_1 & \\hspace{1 mm } e_2 & \\end{array}\\\\ \\left [ \\begin{array}{cr|crr } r_1         & -1 & s_1    & 0    & -1\\\\ r_1 '        & 1   & s_1 '   & -1   & 0\\\\ r_1 ''       & 0   & s_1 '' & 1    & 1\\\\ { r_{1 } } '   & \\mathbf{0 } & { s_{1 } } '    & \\mathbf{0 } & \\mathbf{0 }   \\end{array } \\right ] , \\end{array}\\ ] ] where @xmath111 is a zero matrix , @xmath112 and @xmath113 are vectors and @xmath153 and @xmath154 are matrices of appropriate size @xmath115 .",
    "* case ( a ) : * for case ( a ) we have that the incidence matrix associated with the binet matrix @xmath99 can have the following form : @xmath155= \\begin{array}{c } \\begin{array } { ccccc } \\hspace{-2 mm } f_3   &   & \\hspace{5.5 mm }   f_1 & \\hspace{1 mm } f_2 & \\end{array}\\\\ \\left [ \\begin{array}{rc|rrc } 0       & r_2    & -1   & -1 & s_2\\\\ -1      & r_2 '   &   0   & 1   & s_2'\\\\ 1       & r_2 '' &   1   & 0   & s_2''\\\\ \\mathbf{0 }   & { r_{2 } } '    & \\mathbf{0 } & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right ] \\end{array}\\ ] ] the proof for this case is very similar to the one regarding the @xmath69-sum of two network matrices in lemma  [ lem_net-3sum - net ] . because of the structure of matrix @xmath99",
    ", we have that @xmath105 , @xmath106 , and @xmath107 should form a triangle in any binet representation of @xmath99 . although we omit the full proof for this case because of its similarity to the one of lemma [ lem_net-3sum - net ] , we provide the incidence matrix matrix @xmath122 $ ] of the binet graph associated with the binet matrix @xmath89 produced by the @xmath69-sum : @xmath156= \\left [ \\begin{array}{cc|cc } r_1   & r_2   & s_1   & s_2\\\\ r_1 ' & r_2 ' & s_1 ' & s_2'\\\\ r_1 '' & r_2 '' & s_1 '' & s_2''\\\\   { r_{1 } } ' & \\mathbf{0 } & { s_{1 } } '   & \\mathbf{0}\\\\ \\mathbf{0 } & { r_{2 } } ' & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right]\\ ] ]    * case ( b ) : * for this case we have that the incidence matrix associated with the binet matrix @xmath99 can have the following form : @xmath157= \\begin{array}{c } \\begin{array } { ccccc } \\hspace{-2 mm } f_3   &   & \\hspace{5.5 mm }   f_1 & \\hspace{1 mm } f_2 & \\end{array}\\\\ \\left [ \\begin{array}{rc|rrc } -1 & r_2 & -2 & -1 & s_2\\\\ 1   & r_2 ' & 0   & -1 & s_2'\\\\ \\mathbf{0 } & { r_{2 } } ' & \\mathbf{0 } & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right ] \\end{array}\\ ] ] initially , we convert the network representation @xmath158 $ ] of @xmath98 to a binet representation in which @xmath103 is a loop .",
    "this can be done so by introducing an artificial link parallel to @xmath103 and then contracting it .",
    "thus , @xmath102 becomes a negative link , as contraction involves switching at the node to which @xmath102 and @xmath103 are incident .",
    "graphically this case is illustrated in figure  [ fig : net3bin2 ] which shows such an alternative binet representation of the matrix represented by the directed graph in figure [ fig : net3bin1 ] .",
    "therefore , the incidence matrix @xmath108 $ ] of the binet graph associated with @xmath98 can have the following form : @xmath159= \\begin{array}{c } \\begin{array } { crrrc } & \\hspace{10 mm } e_3 & \\hspace{0.37 in } e_1 & \\hspace{1 mm } e_2 & \\end{array}\\\\ \\left [ \\begin{array}{cr|crr } r_1   & -1   & s_1   & -1   & -2\\\\ r_1 ' &   1   & s_1 ' & -1   &   0\\\\ { r_{1 } } ' & \\mathbf{0 } & { s_{1 } } ' & \\mathbf{0 } & \\mathbf{0 } \\end{array } \\right ] \\end{array}\\ ] ] we have that the following equations hold : @xmath160 from ( [ eq_sixty ] ) and ( [ eq_sixtytwo ] ) we have that : @xmath161 \\left [ \\begin{array}{c|c|c } a   &   a   & a \\\\ \\hline c   &   0   & 1 \\end{array}\\right]= \\left [ \\begin{array}{c|r|r } s_1        &    -1   & -2\\\\ s_1 '       &    -1   &   0\\\\\\hline { s_{1 } } ' & \\mathbf{0 } & \\mathbf{0 } \\end{array } \\right],\\ ] ] where upon decomposing the block matrix multiplications we derive the following equations .",
    "\\left [ \\begin{array}{r } -1\\\\ 1 \\end{array } \\right]c= \\left [ \\begin{array}{c } s_1\\\\ s_1 ' \\end{array } \\right ] , \\quad \\left [ \\begin{array}{c } r_1\\\\ r_1 ' \\end{array } \\right]a = \\left [ \\begin{array}{r } -1\\\\ -1 \\end{array } \\right ]",
    ", \\quad \\nonumber \\\\ \\left [ \\begin{array}{c } r_1\\\\ r_1 ' \\end{array } \\right]a+ \\left[\\begin{array}{r } -1\\\\ 1 \\end{array } \\right]= \\left [ \\begin{array}{r } -2\\\\ 0 \\end{array } \\right ] , \\quad { r_{1}}'a={s_{1 } } ' , \\quad { r_{1}}'a=\\mathbf{0}\\end{gathered}\\ ] ] from ( [ eq_sixtyone ] ) and ( [ eq_sixtytwo ] ) we have that : @xmath163 \\left [ \\begin{array}{c|c|c } 1     &   0    &   b\\\\ \\hline d     &   d    &   b \\end{array } \\right]= \\left [ \\begin{array}{r|r|c } -2    &   -1   & s_2\\\\ 0     &    -1 & s_2'\\\\ \\hline \\mathbf{0 } & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right]\\ ] ] and @xmath164 + \\left [ \\begin{array}{c } r_2\\\\ r_2 ' \\end{array } \\right]d= \\left [ \\begin{array}{r } -2\\\\ 0 \\end{array } \\right ] , \\quad \\left [ \\begin{array}{c } r_2\\\\ r_2 ' \\end{array } \\right]d= \\left [ \\begin{array}{r } -1\\\\ -1 \\end{array } \\right ] , \\quad \\nonumber \\\\ \\left [ \\begin{array}{r } -1\\\\ -1 \\end{array } \\right]b+ \\left [ \\begin{array}{c } r_2\\\\ r_2 ' \\end{array } \\right]b= \\left [ \\begin{array}{c } s_2\\\\ s_2 ' \\end{array } \\right ] , \\quad { r_{2}}'d=\\mathbf{0 } , \\quad { r_{2}}'b={s_{2}}'\\end{gathered}\\ ] ] using block matrix multiplication and the equations in ( 18 ) and ( 19 ) , the following equality holds : @xmath165 } _ { r'}\\underbrace { \\left [ \\begin{array}{c|c } a   & ab\\\\ \\hline dc & b \\end{array } \\right ] } _ { n}= \\underbrace { \\left [ \\begin{array}{c|c } s_1   & s_2\\\\ s_1 ' & s_2'\\\\ \\hline { s_{1 } } ' & \\mathbf{0}\\\\ \\hline \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right ] } _ { s'}\\ ] ] and @xmath122 $ ] is the incidence matrix associated with @xmath89 .    *",
    "case ( c ) : * this case is very similar to case ( b ) . here",
    "we have again to find an alternative binet representation of @xmath98 .",
    "this can be obtained if we take the representation where @xmath102 is a loop in a binet representation of @xmath98 . in this case",
    "the incidence matrix associated with a binet representation of @xmath98 can be : @xmath166= \\begin{array}{c } \\begin{array } { crrrc } & \\hspace{11 mm } e_3 & \\hspace{0.25 in } e_1 & \\hspace{-1.5 mm } e_2 & \\end{array}\\\\ \\left [ \\begin{array}{cr|crr } r_1   &   1   & s_1   & 0   & 1\\\\ r_1 ' & -1   & s_1 ' & 2   & 1\\\\ { r_{1 } } ' & \\mathbf{0 } & { s_{1 } } ' & \\mathbf{0 } & \\mathbf{0 } \\end{array } \\right ] \\end{array}\\ ] ] and w.l.o.g .",
    "we can also assume that the incidence matrix associated with the binet matrix @xmath99 is : @xmath155= \\begin{array}{c } \\begin{array } { ccccc } \\hspace{-4 mm } f_3   &   & \\hspace{2.8 mm }   f_1 & \\hspace{1.5 mm } f_2 & \\end{array}\\\\ \\left [ \\begin{array}{rc|rrc } 0   & r_2 & 1   & 1   & s_2\\\\ 2   & r_2 ' & 1   & -1 & s_2'\\\\ \\mathbf{0 } & { r_{2 } } ' & \\mathbf{0 } & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right ] \\end{array}\\ ] ] using the same methodology as we did in cases ( a ) and ( b ) it can be shown that for case ( c ) a incidence matrix associated with matrix @xmath89 , i.e. such that @xmath167 , is : @xmath168= \\left [ \\begin{array}{cc|cc } r_1   & r_2 & s_1   & s_2\\\\ r_1 ' & r_2 ' & s_1 ' & s_2'\\\\   { r_{1 } } ' & \\mathbf{0 } & { s_{1 } } '   & \\mathbf{0}\\\\ \\mathbf{0 } & { r_{2 } } ' & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right]\\ ] ]    * case ( d ) : * similarly , the incidence matrix associated with @xmath99 can be : @xmath155= \\begin{array}{c } \\begin{array } { ccccc } \\hspace{-2 mm } f_3   &   & \\hspace{5.5 mm }   f_1 & \\hspace{1 mm } f_2 & \\end{array}\\\\ \\left [ \\begin{array}{rc|rrc } -1       & r_2    & -1   & 0 & s_2\\\\ 0        & r_2 '   &   1   & -1   & s_2'\\\\ \\mathbf{0 }   & { r_{2 } } '    & \\mathbf{0 } & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right ] \\end{array}\\ ] ] we can delete the third row from matrix @xmath108 $ ] of ( [ eq_st1 ] ) in order to get a binet representation of matrix @xmath98 .",
    "therefore , we can assume that in this case the incidence matrix associated with @xmath98 can be : @xmath169= \\begin{array}{c } \\begin{array } { crrrc } & \\hspace{10 mm } e_3 & \\hspace{0.37 in } e_1 & \\hspace{1 mm } e_2 & \\end{array}\\\\\\left [ \\begin{array}{cr|crr } r_1         & -1 & s_1    & 0    & -1\\\\ r_1 '        & 1   & s_1 '   & -1   & 0\\\\ \\hat{r_1 }   & \\mathbf{0 } & \\hat{s_1 }    & \\mathbf{0 } & \\mathbf{0 }   \\end{array } \\right ] \\end{array}\\ ] ] using the same methodology as we did in all the previous cases it is easy to show that a incidence matrix associated with @xmath89 is : @xmath170= \\left [ \\begin{array}{cc|cc } r_1   & r_2 & s_1   & s_2\\\\ r_1 ' & r_2 ' & s_1 ' & s_2'\\\\   { r_{1 } } ' & \\mathbf{0 } & { s_{1 } } '   & \\mathbf{0}\\\\ \\mathbf{0 } & { r_{2 } } ' & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right]\\ ] ] case ( e ) is directly analogous to the case ( a ) and ( b ) where @xmath106 is a link and @xmath106 is a loop , respectively .",
    "case ( f ) is directly analogous to the case ( d ) .",
    "for this reason we omit the proof for these cases . + for each of the aforementioned cases it is obvious that @xmath122 $ ] is a incidence matrix of a bidirected graph ,",
    "since the set of columns of this matrix is a combination of columns in @xmath108 $ ] and @xmath109 $ ] .",
    "the rows / columns of @xmath124 in each case are linearly independent , something that can be proved in much the same way as we did for the @xmath124 in lemma [ lem_net-3sum - net ] .",
    "alternatively , the non - singularity of @xmath124 stems also from the graphical explanation we give in the following section .",
    "specifically , since there is one - to - one correspondence between the @xmath124 and the associated bidirected graph , it can be shown that the graph induced by the edges corresponding to the columns of @xmath124 form a negative @xmath67-tree in the unique bidirected graph associated with @xmath122 $ ] found in each case .    * graphical representation of network @xmath171 binet : * + an illustration regarding case ( a ) is depicted in figure  [ fig : net3bin1 ] , where the triangles @xmath172 and @xmath173 are glued together and their edges are deleted from the unified graph . in this way",
    ", we obtain a bidirected graph whose associated incidence matrix is the one given by ( [ eq_sixty0 ] ) .",
    "are links.[fig : net3bin1 ] ]    in case ( b ) , we convert the network representation of @xmath98 to a binet representation in which @xmath103 is a loop . as described in the proof of lemma  [ lem_net-3sum - binet ] , this can be done by introducing an artificial link parallel to @xmath103 and then contracting it . in this way",
    "@xmath102 becomes a negative link , since contraction involves switching at the node at which @xmath102 and @xmath103 are incident , but this does not affect the gluing of @xmath102 and @xmath106 since @xmath106 is also a negative link because its fundamental circuit uses the negative link of the basic cycle .",
    "this case is illustrated in figure [ fig : net3bin2 ] .",
    "that figure shows the alternative binet representation of the matrix represented by the directed graph in figure [ fig : net3bin1 ] .     is a loop",
    ", @xmath106 is a negative link , @xmath107 is a positive link.[fig : net3bin2 ] ]    for case ( c ) see figure [ fig : net3bin3 ] for an illustration . to make a similar representation for @xmath98",
    ", we can convert @xmath102 to a loop with a contraction .",
    "the binet graph representing @xmath98 in figure [ fig : net3bin3 ] is an alternative representation to the directed graph in figure  [ fig : net3bin1 ] .",
    "is a loop.[fig : net3bin3 ] ]    in case ( d ) the three edges @xmath105,@xmath106 and @xmath107 are positioned as in figure [ fig : net3bin4 ] .",
    "we can have a similar position of edges @xmath174 if we delete a node that is incident to @xmath102 and @xmath103 .",
    "the leftmost graph in figure  [ fig : net3bin4 ] shows such a binet representation of the network matrix represented by the directed graph in figure  [ fig : net3bin1 ] .",
    "is a half - edge.[fig : net3bin4 ] ]    finally , cases ( e ) and ( f ) can be handled with the techniques described previously .",
    "if an edge among @xmath175 is a loop , then contract an artificial edge in the directed graph representation of @xmath98 to make the corresponding edge a loop .",
    "if two edges among @xmath175 are half - edges , then delete an appropriate node from the directed graph .",
    "a very similar analysis of the cases can be done here .",
    "the role of @xmath102 , @xmath103 and @xmath104 is analogous to @xmath105 , @xmath106 and @xmath107 as in the previous section .",
    "all the cases can be handled in much the same way , by finding a suitable alternative representation of @xmath99 as we did for @xmath98 in the proof of lemma  [ lem_net-3sum - binet ] .",
    "[ lem_binet-3sum - net ] if @xmath98 is a binet matrix and @xmath99 is a network matrix such that @xmath100 , \\end{array }   $ } n_2 =   \\raisebox{5pt}{$ \\begin{array}{r } \\vspace{-5 mm } \\hspace{-3.2 mm }     \\\\",
    "f_3 \\end{array } \\hspace{-2.5 mm } \\begin{array}{c }",
    "\\begin{array}{crr } \\hspace{-3.2 mm } f_1 & \\hspace{-1.3 mm } f_2 &    \\end{array } \\\\ \\left [ \\begin{array}{ccc } 1 & 0 & b\\\\ d & d & b \\end{array }     \\right ] , \\end{array }   $ } \\ ] ] then @xmath151 is a binet matrix .",
    "the @xmath0-sum of a network ( binet ) matrix and a binet ( network ) matrix is binet ( @xmath176 ) .",
    "the proof is similar to that of theorem  [ th_net_cl ] since binet matrices are also closed under duplication of columns and rows , addition of unitary rows and pivoting .",
    "here we prove that the @xmath0-sum ( @xmath2 ) of two binet matrices is not necessarily a binet matrix .",
    "furthermore , an analogous statement can be made for the associated matroids , the so - called signed - graphic matroids . using a counterexample",
    ", we show that the @xmath68-sum of two binet , non - network and totally unimodular matrices , namely @xmath5 and @xmath6 of ( [ eq_b1 ] ) and ( [ eq_b2 ] ) , is not a binet matrix .",
    "the column of @xmath5 as well as the row of @xmath6 used in our @xmath68-sum counterexample are indicated below : @xmath177= \\left [ \\begin{array}{rrrr|r } 0   & 0   & 1   & -1 & 1\\\\ 1   & 0   & 0   &   1 & -1\\\\ -1 & 1   & 0   &   0 & 1\\\\ 1   & -1 & 1   &   0 & 0\\\\ 0   & 1   & -1 &   1 & 0 \\end{array } \\right ] , b_2= \\left [ \\begin{array}{c } b\\\\ \\hline b \\end{array } \\right]= \\left [ \\begin{array}{rrrrr } 1   & 1   & 1   & 1 & 1\\\\ \\hline 1   & 1   & 1   & 0 & 0\\\\ 1 &   0   & 1   & 1 & 0\\\\ 1   & 0 & 0   &   1 & 1\\\\ 1   & 1   & 0 &   0 & 1 \\end{array } \\right]\\ ] ]",
    "let @xmath178 be the @xmath68-sum of @xmath5 and @xmath6 which according to the @xmath68-sum definition is : @xmath179= \\begin{array}{c } \\begin{array}{rrrrrrrrr } \\hspace{9 mm } s_1 & \\hspace{1.5 mm } s_2 & \\hspace{1 mm } s_3 & \\hspace{1 mm } s_4 & \\hspace { 1.5 mm } s_5 & \\hspace{1 mm }   s_6 & \\hspace{1.5 mm } s_7 & \\hspace{1 mm } s_8 & \\hspace{1.5 mm } s_9 \\end{array}\\\\ \\begin{array}{c } r_1\\\\ r_2\\\\ r_3\\\\ r_4\\\\ r_5\\\\ r_6\\\\ r_7\\\\ r_8\\\\ r_9 \\vspace{1 mm } \\end{array } \\left [ \\begin{array}{rrrr|rrrrr } 0   & 0   & 1   & -1 & 1   & 1   & 1   & 1   & 1 \\\\ 1   & 0   & 0   &   1 & -1 & -1 & -1 & -1 & -1\\\\ -1 & 1   & 0   &   0 & 1   & 1   & 1   & 1   &   1\\\\   1   & -1 & 1   &   0 & 0   & 0   & 0   & 0   &   0\\\\ 0   & 1   & -1 &   1 & 0   & 0   & 0   & 0   &   0\\\\ \\hline 0   & 0   & 0   &   0 & 1   & 1   & 1   & 0   &   0\\\\ 0   & 0   & 0   &   0 & 1   & 0   & 1   & 1   &   0\\\\ 0   & 0   & 0   &   0 & 1   & 0   & 0   & 1   &   1\\\\ 0   & 0   & 0   &   0 & 1   & 1   & 0   & 0   &   1 \\end{array } \\right ] \\end{array}\\ ] ] assume that @xmath178 is a binet matrix and that @xmath180 and @xmath181 @xmath182 label the basic and non - basic edges , respectively , in a binet representation of @xmath178 .",
    "matrix @xmath178 is integral and since it is also binet then any possible binet representation of @xmath178 up to switching should be one of the following two types @xcite ( lemmas 5.10 and 5.12 ) :    * type i : * every basic cycle is a half - edge , and all other basic edges are directed .    *",
    "type ii : * there are no half - edges in the binet graph , the basis is connected and there is only one bidirected edge in the basis . + we will show that @xmath178 has neither of the above two representations , thereby it can not be binet .",
    "we make use of the following lemma in  @xcite :    [ lem_net_repr ] let us suppose that a binet matrix @xmath91 is totally unimodular .",
    "then it is a network matrix if and only if it has a binet representation in which each basic cycle is a half - edge .",
    "[ lem_typei ] matrix @xmath183 does not have a binet representation of type i or type ii .",
    "suppose that @xmath178 has a binet representation of type i. combining the fact that @xmath178 is totally unimodular with lemma  [ lem_net_repr ] we have that @xmath178 is a network matrix .",
    "it is well - known that any submatrix of a network matrix is a network matrix itself ( e.g. see  @xcite ) .",
    "@xmath5 is a submatrix of @xmath178 which is known to be non - network .",
    "thus , @xmath178 can not have a binet representation of type i.    assume that @xmath178 has a binet representation @xmath47 of type ii .",
    "let @xmath184 be the subgraph of @xmath47 induced by the edges in @xmath185 ( @xmath184 is also called the basis graph of @xmath47 ) .",
    "let also @xmath186 be the set of edges that constitute the unique cycle in @xmath184 , i.e. @xmath186 is the edge set of the basic cycle of the binet graph @xmath47 .",
    "because of column @xmath187 of @xmath178 the subgraph of @xmath184 induced by the basic edges in @xmath188 is connected .",
    "our first claim is that @xmath189 .",
    "if we assume the contrary , i.e. that @xmath190 , then the edges in @xmath54 should form a path in @xmath184 . moreover , observe that each non - basic edge of the set @xmath191 is using edges of @xmath54 in order to create the associated fundamental circuit in @xmath47 . combining this with the fact that the edges in @xmath54 induce a path of @xmath47 , we have that @xmath192 $ ] must be a network matrix .",
    "but this can not happen since this matrix contains @xmath6 as a submatrix which is not a network matrix and thus , our claim is true .",
    "thus , @xmath189 and furthermore , since there is only one cycle in @xmath184 , we have that @xmath193 .",
    "let @xmath194 and @xmath195 ; our second claim is that @xmath196 .",
    "if we assume the contrary , i.e. that @xmath197 then because of column @xmath187 of @xmath178 we have that the corresponding fundamental circuit in @xmath47 should be either a handcuff of type i or a handcuff of type ii",
    ". however , it can not be a handcuff of type ii since then a @xmath150 would appear in @xmath178 ( see algorithm 1 in @xcite ) .",
    "therefore , it is a handcuff of type i and thus the basic edges in @xmath198 induce a path in the basis graph .",
    "thus , the edges in @xmath11 and one or more edges of @xmath84 are the parts of this path in the basis graph . moreover , from the fundamental circuits of @xmath47 described by the columns of @xmath199",
    "$ ] part of @xmath178 we have that the subgraph @xmath200 of @xmath184 induced by the set of edges in @xmath201 is connected .",
    "observe now that the edges in @xmath84 appear in all the fundamental circuits of @xmath47 corresponding to the columns of @xmath192 $ ] .",
    "therefore , because of the structure of these fundamental circuits and since @xmath200 is connected we have that in @xmath184 the following conditions must be satisfied:(i ) @xmath202 and @xmath203 are adjacent , ( ii ) @xmath202 and @xmath204 are adjacent , ( iii ) @xmath204 and @xmath32 are adjacent , and ( iv ) @xmath32 and @xmath203 are adjacent .",
    "we show now that this can not happen .",
    "assume , w.l.o.g .",
    ", that @xmath203 is on the right side of @xmath202 then because of ( ii ) @xmath204 should be put on the left side of @xmath202 . moreover , because of ( iii ) @xmath32 should be on the left side of @xmath204 .",
    "but now condition ( iv ) can not be satisfied .",
    "thus , our assumption that @xmath197 is not correct and this completes the proof of our second claim .    since we have shown that @xmath193 and that @xmath196 we have that @xmath200 is a tree in @xmath184 .",
    "we show now that any two edges in @xmath84 do not share a common end - node .",
    "note that the following procedure can be used in much the same way for any pair of edges in @xmath84 . specifically , suppose that @xmath29 and @xmath205 share an end - node and without loss of generality suppose that @xmath205 stands on the right side of @xmath29 .",
    "consider the fundamental circuits of @xmath47 determined by the columns of the @xmath199 $ ] part of @xmath178 .",
    "because of the columns @xmath206 and @xmath207 we have that @xmath208 stands on the left side of @xmath29 . moreover , because of the columns @xmath209 and @xmath206 we have that @xmath210 has a common end - node with @xmath29 and @xmath205 . but now , we can not satisfy the fundamental circuit defined by @xmath211 because edge @xmath29 is in the middle of @xmath210 and @xmath208 . thus , we can conclude that any two edges of @xmath84 do not share a common end - node .",
    "however , we have that @xmath200 ( which contains @xmath210 and @xmath208 ) is a tree and that the edges in @xmath54 ( which does not contain @xmath210 and @xmath208 ) induce a connected subgraph in @xmath184 containing a basic cycle",
    ". this can only happen if @xmath184 contains at least two cycles .",
    "in other words , in order to find a binet graph satisfying the circuits described by the columns of @xmath178 we have that @xmath184 should contain at least two cycles .",
    "this is in contradiction with the fact that connected binet graphs contain at most one basic cycle in the basis graph .",
    "therefore , @xmath178 does not have a binet representation of type ii .",
    "in general we can state the following theorem .",
    "[ thrm_binet_ksum_open ] totally unimodular binet matrices are not closed under @xmath0-sums for @xmath2 .",
    "for @xmath142 the lemma [ lem_typei ] provides a counterexample .",
    "for @xmath8 it is enough to observe that for @xmath212 in the definition  [ def_k - sums ] the @xmath69-sum of two matrices reduces to the @xmath68-sum of some submatrices obtained by the deletion of columns and rows .",
    "since binet and tu matrices are closed under row and column deletions , the result follows .",
    "in this section a new class of matrices is introduced , that of tour matrices , in order to represent some important classes of matrices on bidirected graphs . in what follows",
    ", we also prove some elementary properties of tour matrices and show that they are closed under @xmath0-sums .",
    "let @xmath213 $ ] be the incidence matrix of a bidirected graph @xmath47 .",
    "we denote by @xmath214 and @xmath215 the subgraphs of @xmath47 induced by the edges that correspond to the columns of @xmath216 and @xmath54 , respectively .",
    "tour _ in a bidirected graph is a walk in which no edge is repeated .",
    "a _ closed tour _ is a tour in which the first and last node coincide or the first and last edge are half edges .",
    "let @xmath47 be a bidirected graph with @xmath213 $ ] its incidence matrix .",
    "a @xmath3 matrix @xmath91 with rows indexed by the columns of @xmath216 and columns indexed by the columns of @xmath54 , such that + 1 . @xmath217 + 2 .",
    "@xmath216 is full row rank + is called a tour matrix .",
    "the edges in @xmath214 are called _ prime _ and the edges in @xmath215 are called _ non - prime_. when in a bidirected graph representing a tour matrix @xmath91 the prime and non - prime edges are labeled , we call it a _ tour representation _ or a _ tour graph _ of @xmath91 .",
    "let @xmath91 be an @xmath218 tour matrix of a bidirected graph @xmath47 with incidence matrix @xmath213 $ ] and @xmath219 be the set of edges in @xmath216 indexed by the nonzero entries in the column @xmath220 of @xmath91 ( @xmath221 ) .",
    "then the subgraph induced by @xmath222 is a collection of closed tours in @xmath47 , where @xmath181 is the @xmath223-th column of @xmath54 .",
    "since @xmath224 for all @xmath225 and @xmath226 for all @xmath227 we have that the degree of every vertex in the subgraph induced by @xmath222 is even , therefore its connected components are eulerian .",
    "thus , the subgraph induced by @xmath228 is a collection of closed tours .    in the following lemmas we provide some elementary operations which",
    "if applied to a tour matrix then the matrix obtained is also tour .",
    "[ lem_switch ] if @xmath47 is a tour representation of a tour matrix @xmath91 then switching at a node of @xmath47 keeps @xmath91 unchanged .",
    "switching at a node @xmath14 in a bidirected graph @xmath47 is interpreted as multiplying by @xmath28 the row of the incidence matrix @xmath229 $ ] which corresponds to node @xmath14 .",
    "let @xmath230 and @xmath231 be the matrices obtained multiplying by @xmath28 the aforementioned row of @xmath84 . since @xmath217 , from matrix multiplication we also have that @xmath232 .",
    "[ lem_elem_oper ] tour matrices are closed under the following operations :    \\(a ) permuting rows or columns .",
    "\\(b ) multiplying a row or column by @xmath28 .",
    "\\(c ) duplicating a row or column .",
    "\\(d ) deleting a row or column .",
    "if @xmath91 is a tour matrix then by definition we have that @xmath217 , where @xmath229 $ ] is the incidence matrix of a bidirected graph @xmath47 associated with @xmath91 .",
    "let @xmath233 be the matrix obtained by applying one of the above operations on @xmath91 .",
    "we show in each case that @xmath233 is a tour matrix by providing the associated incidence matrix @xmath234 $ ] .",
    "+ ( a ) when permutation of columns takes place let @xmath235 and @xmath231 be the matrix obtained from @xmath54 by permuting the columns of @xmath54 in the same way that columns of @xmath91 were permuted .",
    "when permutation of rows takes place let @xmath236 and @xmath230 be the matrix obtained from @xmath216 by permuting its columns in the same way that rows of @xmath91 were permuted . from matrix multiplication rules we have that @xmath237 and that @xmath234 $ ] is the incidence matrix of a bidirected graph in both cases .",
    "+ ( b ) if row @xmath15 of @xmath91 is multiplied by @xmath28 then let @xmath230 be @xmath216 with column @xmath15 multiplied by @xmath28 and @xmath236 .",
    "if we multiply a column @xmath238 of @xmath91 by @xmath28 then let @xmath235 and @xmath231 be @xmath54 with column @xmath238 multiplied by @xmath28 .",
    "obviously in both cases @xmath233 is a tour matrix since from matrix multiplication rules we have that @xmath237 .",
    "+ ( c ) if we duplicate a column @xmath238 in @xmath91 , let @xmath235 and @xmath231 be @xmath54 with column @xmath238 duplicated .",
    "it is easy to check then that @xmath233 satisfies the conditions of a tour matrix .",
    "row duplication is a bit more involved .",
    "we have four cases corresponding to the different types of edges , and in each case we will alter the bidirected graph to correspond to the new tour matrix . if row @xmath238 to be duplicated is a positive loop , simply add a positive loop to any node of the signed graph . if the prime edge @xmath238 is a negative loop ( see ( i ) in figure  [ fig_duplication ] ) , then add a zero row @xmath239 in @xmath213 $ ] and a zero column @xmath240 in @xmath216 to obtain @xmath241 $ ] and set @xmath242 if the prime edge @xmath238 is a link ( see ( ii ) in figure  [ fig_duplication ] ) then duplicate row @xmath53 in @xmath213 $ ] to create a new row @xmath239 , and make all the elements of row @xmath53 zero except the element in position @xmath238 . in row",
    "@xmath239 make the element in position @xmath238 zero .",
    "finally add a new column @xmath240 in @xmath230 and set @xmath243 finally , if the prime edge @xmath238 is a half - edge ( see ( iii ) in figure  [ fig_duplication ] ) then then add a zero row @xmath239 in @xmath213 $ ] and a zero column @xmath240 in @xmath216 to obtain @xmath241 $ ] and set @xmath244 in all cases , the matrix @xmath241 $ ] is the incidence matrix of a bidirected graph by construction , and @xmath237 .",
    "+ ( d ) deletion of a column in a tour matrix is simply the deletion of the corresponding non - prime edge in the corresponding bidirected graph .",
    "deletion of a row @xmath238 , differs according the type of the corresponding prime edge @xmath238 .",
    "if @xmath238 is a positive loop , or a link , then contract @xmath238 in the bidirected graph .",
    "if @xmath238 is a negative loop then make all adjacent links to the end - node of @xmath238 half - edges adjacent to their other end - node , while all adjacent loops and half edges become positive loops at some other arbitrary node , and delete @xmath238 and its end - node . in all cases",
    "it is easy to verify that the new bidirected graph corresponds to the tour matrix with a column(row ) deleted .",
    "we should note here that multiplying a row ( column ) by -1 in a tour matrix , graphically is equivalent to reversing the direction of the corresponding prime ( respectively non - prime ) edge in the associated bidirected graph . on the other hand , duplicating a column amounts to creating a parallel non - prime edge to the tour graph .",
    "[ fig_duplication ] ]    given a matrix @xmath245 $ ] in @xmath57 , a _ pivot _ is the matrix @xmath246 $ ] ( see  @xcite ) .",
    "[ lem_tour_pivot ] totally unimodular tour matrices are closed under pivoting .",
    "let @xmath247 $ ] be a totally unimodular tour matrix associated with a bidirected graph @xmath47 with incidence matrix @xmath248 $ ] . by definition @xmath249 t = [ e \\ ; s]\\ ] ] and the columns @xmath238 and @xmath15 correspond to the prime and non - prime edges respectively .",
    "consider the bidirected graph @xmath250 with incidence matrix @xmath251 $ ] , that is @xmath47 with edge @xmath238 having its endpoints reversed in sign .",
    "we will show that matrix @xmath252 $ ] is a tour matrix associated with @xmath250 .",
    "initially let us show that @xmath253 b = [ -f \\ ; s]\\ ] ] we know from ( [ eq_20 ] ) that @xmath254 , where @xmath255 is the @xmath256 column of @xmath216 .",
    "therefore @xmath257 which shows that the first column of @xmath91 is a collection of tours in @xmath258 .",
    "take any other column @xmath259 of @xmath91 . if @xmath260 the relationship ( [ eq_21 ] ) follows .",
    "if @xmath261 then we know from ( [ eq_20 ] ) that @xmath262 and the corresponding product in ( [ eq_21 ] ) will be @xmath263 partition the indices of the differences in the above summation into three sets : @xmath264 which corresponds to indices where both @xmath265 , @xmath266 where @xmath267 and @xmath268 and @xmath269 where @xmath270 and @xmath271 .",
    "replacing @xmath15 by ( [ eq_22 ] ) we have @xmath272 similarly for the case where @xmath273 ( or alternatively use ( b ) of lemma  [ lem_elem_oper ] ) .    given that totally unimodular matrices",
    "are closed under pivoting , @xmath91 will be a @xmath3 matrix .",
    "[ lem_nettour ] network matrices are tour matrices .",
    "consider a network matrix @xmath274 of a directed graph @xmath275 with incidence matrix @xmath276 $ ] .",
    "we will show that @xmath89 can be viewed as a binet matrix by providing a binet representation of it .",
    "let @xmath15 be any column of @xmath54 . in what follows we will show that there exists a binet representation in which edge @xmath15 is a loop at any one of its endpoints .",
    "view the graph @xmath275 as a bidirected graph @xmath47 with only positive links . add a negative link @xmath238 parallel to @xmath15 and as a result we have that the binet matrix associated with @xmath47 is equal to the original network matrix @xmath89 plus an all - zero row .",
    "deleting this all - zero row we get the original matrix @xmath89 , while the equivalent graphical operation would be the contraction of edge @xmath238 .",
    "contraction of @xmath238 involves switching at one end - node of @xmath238 ( say at @xmath14 ) , since @xmath238 is a negative link .",
    "this way @xmath15 becomes a negative loop ( see figure [ fig : netcycle ] ) .",
    ", and then contracting it by switching at @xmath14.[fig : netcycle],title=\"fig : \" ] , and then contracting it by switching at @xmath14.[fig : netcycle],title=\"fig : \" ]    in matrix terms , we have that starting from @xmath276=\\begin{array}{r } v\\\\ \\\\   \\end{array}\\!\\!\\!\\!\\ !",
    "\\begin{array}{c } \\hspace{3 mm } e\\\\ \\left [ \\begin{array}{c|rc }   & -1 & \\\\ r     &   1 & \\bar{s}\\\\   & \\mathbf{0 } &    \\end{array } \\right ] \\end{array } $ ] by the aforementioned procedure we obtain @xmath122= \\begin{array}{r } v\\\\ \\\\",
    "\\begin{array}{c } \\hspace{1 mm } e\\\\ \\left [ \\begin{array}{c|cr }      & 2 & \\\\",
    "\\hat{r } & 0 & \\hat{s } \\\\      & \\mathbf{0 } &   \\end{array } \\right ] \\end{array}$ ] , where @xmath167 and @xmath122 $ ] is a incidence matrix associated with a binet representation of @xmath89 .",
    "therefore we have found a bidirected graph @xmath122 $ ] where @xmath167 , and @xmath124 is full - row rank .",
    "furthermore , it is known that any binet matrix which is tu and non - network should have a binet representation @xmath47 that does not contain half - edges ( see lemma  22 and theorem  24 in  @xcite ) .",
    "therefore we can state the following corollary .",
    "[ cor_tubin ] tu binet matrices are tour matrices .    from corollary  [ cor_tubin ] , it is evident that @xmath5 and @xmath6 are tour matrices . combining this with lemma  [ lem_nettour ] , theorem  [ seymour_matrix ] and the fact that zero columns are preserved , we have the following .    [ col_tutour ]",
    "all the building blocks of tu matrices are tour matrices and their transposes .      in this section",
    "we will show that all tu matrices have a bidirected graph representation since they are a subclass of tour matrices .",
    "this is illustrated in the following `` pathological '' case by the usage of positive loops , which in general allow a somewhat arbitrary insertion of prime edges and thereby rows in a given matrix .",
    "[ thrm_tu = tour ] all tu matrices are tour matrices .",
    "let @xmath277 be a totally unimodular matrix .",
    "by ghouila - houri characterisation of tu matrices ( see  @xcite ) , we have that there exists a vector @xmath278 such that @xmath279 ; that is multiplying the rows by @xmath280 the resulting matrix has columns which sum up to @xmath3 .",
    "therefore we can have @xmath281 b = \\left [ \\begin{array}{c } y^{t } \\\\",
    "y^{t } \\end{array }     \\right ] $ ] and @xmath282 = \\left [ \\begin{array}{cc } x^{t } & y^{t } \\\\ x^{t } & y^{t } \\end{array }     \\right ] , $ ] is the incidence matrix of a bidirected graph since the sum of each column is less or equal to @xmath283 . if the first column of @xmath216 is @xmath284 $ ] replace it with @xmath285 $ ] , while if it is @xmath286 $ ] replace it with @xmath287 $ ] to obtain a new matrix @xmath230 , and set @xmath288 .",
    "then @xmath241 $ ] is also the incidence matrix of a bidirected graph with @xmath91 its tour matrix .",
    "however a tour matrix may have multiple bidirected graph representations , and in the proof of theorem  [ thrm_tu = tour ] the bidirected graph so constructed does not have enough structural information with respect to the linear independence of the columns of the associated matrix . we know from seymour s decomposition theorem  [ seymour_matrix ] that a tu matrix is composed by @xmath0-sums from matrices which do have a bidirected graph representation , therefore in view of corollary  [ col_tutour ] there must exist a richer in structure bidirected graph representation .",
    "moreover , the building blocks in the @xmath0-sum composition do have bidirected graphs which do not have positive loops . in order to obtain this representation",
    ", we have to examine the way the @xmath0-sum operations behave on tour matrices .      in what follows we present results on the @xmath0-sums of tour matrices .",
    "the case of only @xmath69-sum will be shown as we did in the previous sections , since the other sum operations could be reduced to it by the addition of unitary rows and duplication of columns .",
    "[ lem_3-sum_tour_operations ] if @xmath289 are tour matrices , then there exist tour matrices @xmath290 such that @xmath291 is a row submatrix of @xmath292 where the connecting elements are all positive links .",
    "let @xmath293 , \\end{array }   $ } l =   \\raisebox{5pt}{$ \\begin{array}{r } \\vspace{-5 mm } \\hspace{-3.2 mm }     \\\\",
    "f_3 \\end{array } \\hspace{-2.5 mm } \\begin{array}{c } \\begin{array}{crr } \\hspace{-3.2 mm } f_1 & \\hspace{-1.3 mm } f_2 &    \\end{array } \\\\ \\left [ \\begin{array}{ccc } 1 & 0 & b\\\\ d & d & b \\end{array }     \\right ] .",
    "\\end{array }   $ } \\ ] ] for all possible edge type configurations of @xmath148 and @xmath107 we will apply graphical operations on the tour graph of @xmath294 , so that the resulting graph will be the tour graph of a tour matrix @xmath295 that will contain @xmath294 as a submatrix .",
    "* case ( a ) : * consider the case where @xmath105 is a negative loop , @xmath106 is a negative link and @xmath107 is a positive link . because of the first two columns of @xmath294 we have that these edges must be of the following form : @xmath296 , @xmath297 and @xmath298 ( see figure  [ fig_case_b ] ) .",
    "the graphical operation is the following : we split the end - node @xmath14 of @xmath105 into two nodes @xmath299 and @xmath300 and add a new basic positive link @xmath301 . in the new bidirected graph @xmath302 are negative links , and @xmath107 is a positive link , while for all other edges having end - node @xmath14 we replace @xmath14 by @xmath299 . up to switchings ,",
    "the tour matrix @xmath295 associated with this graph is : where the connecting elements @xmath148 and @xmath107 are all positive links .",
    "negative loop , @xmath106 negative link and @xmath107 positive link.[fig_case_b ] ]    * case ( b ) : * let now @xmath303 be half - edges and @xmath297 a positive link ( see figure  [ fig_case_d ] ) .",
    "the graphical operation in this case is the following : add a new vertex @xmath304 in the bidirected graph , replace the half - edges @xmath105 and @xmath107 by positive links @xmath305 and @xmath306 , and add a negative loop @xmath307 .",
    "the new tour matrix @xmath295 associated with this graph will be :     half - edges and @xmath106 positive link.[fig_case_d ] ]    * case ( c ) : * for the case where @xmath148 are negative loops and @xmath107 a positive loop the graphical operation is similar to the ones described previously , and is depicted in figure  [ fig_case_e ] .",
    "negative loops and @xmath107 positive loop.[fig_case_e ] ]    the new tour matrix @xmath295 associated with the so constructed graph will be :    * case ( d ) : * the case where @xmath105 is a negative link , @xmath106 a negative loop and @xmath107 a half - edge , can be easily verified that is not possible , due to the structure of @xmath294 .",
    "it is straightforward to show that all possible edge type configurations for the connecting edges of @xmath294 , fall into one of the above described cases where the new tour matrix @xmath295 will contain either a row @xmath240 or @xmath308 or both . applying the above graphical operations and switchings on both @xmath309 and @xmath294 , we can therefore obtain @xmath310 and @xmath295",
    "were the connecting elements of @xmath292 are positive links @xmath311 and @xmath175 , while the matrix @xmath292 contains @xmath291 as a row submatrix .",
    "[ lem_3-sum_tour ] if @xmath289 are tour matrices such that @xmath293 , \\end{array }   $ } l =   \\raisebox{5pt}{$ \\begin{array}{r } \\vspace{-5 mm } \\hspace{-3.2 mm }     \\\\ f_3 \\end{array } \\hspace{-2.5 mm } \\begin{array}{c } \\begin{array}{crr } \\hspace{-3.2 mm } f_1 & \\hspace{-1.3 mm } f_2 &    \\end{array } \\\\ \\left [ \\begin{array}{ccc } 1 & 0 & b\\\\ d & d & b \\end{array }     \\right ] , \\end{array }   $ } \\ ] ] then @xmath312 is a tour matrix .",
    "let @xmath313 $ ] and @xmath314 $ ] be incidence matrices associated with @xmath309 and @xmath294 and @xmath315 and @xmath316 be the associated tour graphs . by lemma  [ lem_3-sum_tour_operations ] and ( d ) of lemma  [ lem_elem_oper ]",
    ", we can assume that the connecting elements @xmath311 and @xmath175 are all positive links in the tour graphs .    by lemma [ lem_elem_oper ] , the incidence matrices @xmath317 and @xmath318 associated with @xmath309 and @xmath294 can have the following form : @xmath319= \\begin{array}{c } \\begin{array } { crrrc } & \\hspace{0.37 in } e_3 & \\hspace{0.34 in } e_1 & \\hspace{1 mm } e_2 & \\end{array}\\\\ \\left [ \\begin{array}{cr|crr } q_1         & -1 & s_1    & 0    & -1\\\\ q_1 '        & 1   & s_1 '   & -1   & 0\\\\ q_1 ''       & 0   & s_1 '' & 1    & 1\\\\ { q_{1 } } '   & \\mathbf{0 } & { s_{1 } } '    & \\mathbf{0 } & \\mathbf{0 }   \\end{array } \\right ] \\end{array } \\hspace{-4 mm } \\begin{array}{l } u   \\\\ v   \\\\",
    "\\vspace{-4 mm } \\end{array } , \\quad   [ q_2|s_2]= \\begin{array}{r } u '   \\\\ v '   \\\\ y '   \\\\    \\end{array } \\hspace{-3 mm } \\begin{array}{c } \\begin{array } { ccccc } \\hspace{-2 mm } f_3   &   & \\hspace{5.5 mm }   f_1 & \\hspace{1 mm } f_2 & \\end{array}\\\\ \\left [ \\begin{array}{rc|rrc } 0       & q_2    & -1   & -1 & s_2\\\\ -1      & q_2 '   &   0   & 1   & s_2'\\\\ 1       & q_2 '' &   1   & 0   & s_2''\\\\ \\mathbf{0 }   & { q_{2 } } '    & \\mathbf{0 } & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right ] \\end{array}\\ ] ] where @xmath111 is a vector or matrix of zeroes of appropriate size , @xmath320 and @xmath113 are row vectors and @xmath321 are matrices of appropriate size @xmath115 . also ,",
    "@xmath322 and @xmath323 label the three first rows of @xmath317 and consequently the corresponding nodes of @xmath315 .",
    "similarly , @xmath324 , @xmath325 label the first three rows of @xmath318 and the corresponding nodes of @xmath316 .",
    "we have that the following equations hold : @xmath326 for @xmath309 using ( [ eq_hundred ] ) and ( [ eq_hundredtwo ] ) we have that : @xmath327 \\left [ \\begin{array}{c|c|c } a   &   a   & a \\\\ \\hline c   &   0   & 1 \\end{array}\\right]= \\left [ \\begin{array}{c|r|r } s_1        &    0   & -1\\\\ s_1 '       &   -1   &   0\\\\ s_1 ''      &    1   &   1\\\\ \\hline { s_{1 } } ' & \\mathbf{0 } & \\mathbf{0 } \\end{array } \\right]\\ ] ] from the above equation we take the following equations : @xmath328a+ \\left [ \\begin{array}{r } -1\\\\ 1\\\\ 0 \\end{array } \\right]c= \\left [ \\begin{array}{c } s_1\\\\ s_1'\\\\ s_1 '' \\end{array } \\right ] , \\quad \\left [ \\begin{array}{c } q_1\\\\ q_1'\\\\ q_1 '' \\end{array } \\right]a = \\left [ \\begin{array}{r } 0\\\\ -1\\\\ 1 \\end{array } \\right ] , \\quad \\nonumber \\\\ \\left [ \\begin{array}{c } q_1\\\\ q_1'\\\\ q_1''\\\\ \\end{array } \\right]a+ \\left[\\begin{array}{r } -1\\\\ 1\\\\ 0 \\end{array } \\right]= \\left [ \\begin{array}{r } -1\\\\ 0\\\\ 1 \\end{array } \\right ] , \\quad { q_{1}}'a={s_{1 } } ' , \\quad { q_{1}}'a=\\mathbf{0}\\end{gathered}\\ ] ] similarly , for @xmath294 using ( [ eq_hundred ] ) and ( [ eq_hundredtwo ] ) we have that : @xmath329 \\left [ \\begin{array}{c|c|c } 1     &   0    &   b\\\\ \\hline d     &   d    &   b \\end{array } \\right]= \\left [ \\begin{array}{r|r|c } -1    &   -1   & s_2\\\\ 0     &    1   & s_2'\\\\ 1     &    0   & s_2''\\\\ \\hline \\mathbf{0 } & \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right]\\ ] ] from the above equation we take the following equations : @xmath330 + \\left [ \\begin{array}{c } q_2\\\\ q_2'\\\\ q_2 '' \\end{array } \\right]d= \\left [ \\begin{array}{r } -1\\\\ 0\\\\ 1 \\end{array } \\right ] , \\quad \\left [ \\begin{array}{c } q_2\\\\ q_2'\\\\ q_2 '' \\end{array } \\right]d= \\left [ \\begin{array}{r } -1\\\\ 1\\\\ 0 \\end{array } \\right ] , \\quad \\nonumber \\\\ \\left [ \\begin{array}{r } 0\\\\ -1\\\\ 1 \\end{array } \\right]b+ \\left [ \\begin{array}{c } q_2\\\\ q_2'\\\\ q_2 '' \\end{array } \\right]b= \\left [ \\begin{array}{c } s_2\\\\ s_2'\\\\ s_2 '' \\end{array } \\right ] , \\quad { q_{2}}'d=\\mathbf{0 } , \\quad { q_{2}}'b={s_{2 } } ' \\quad\\end{gathered}\\ ] ] using block matrix multiplication and equations in ( 23 ) and ( 24 ) , it is easy to show that the following equation holds : @xmath331 } _ { q'}\\underbrace { \\left [ \\begin{array}{c|c } a   & ab\\\\ \\hline dc & b \\end{array } \\right ] } _ { m}= \\underbrace { \\left [ \\begin{array}{c|c } s_1   & s_2\\\\ s_1 ' & s_2'\\\\ s_2 '' & s_2''\\\\ \\hline { s_{1 } } ' & \\mathbf{0}\\\\ \\hline \\mathbf{0 } & { s_{2 } } ' \\end{array } \\right ] } _ { s'}\\ ] ] clearly @xmath234 $ ] is incidence matrix of a bidirected graph .    let us examine the structure of the bidirected graph @xmath332 so obtained , from the @xmath0-sum operation on tour matrices .",
    "from ( [ eq_fiftynine1 ] ) we have that @xmath332 is obtained by gluing @xmath315 and @xmath316 such that @xmath13 and @xmath333 , @xmath14 and @xmath334 , @xmath323 and @xmath325 become single nodes @xmath13 , @xmath14 and @xmath323 , respectively , and deleting edges @xmath102 , @xmath103 , @xmath104 , @xmath105 , @xmath106 and @xmath107 from the unified graph . in other words , this can also be seen as gluing together the @xmath315 and @xmath316 along the triangles @xmath335 and @xmath336 so that @xmath102 meets @xmath107 , @xmath103 meets @xmath105 and @xmath104 meets @xmath106 and deleting the glued triangle from the unified graph . obviously , we can say that in @xmath332 the edge @xmath104 which was deleted is substituted by the tour associated with @xmath106 in @xmath316 and that the @xmath107 which was deleted is substituted by the tour associated with @xmath102 in @xmath315 .",
    "therefore , now any tour that used @xmath104 will instead go through the tour associated with @xmath106 giving rise to the non - zero part of @xmath337 in @xmath338 .",
    "the tours that went through @xmath107 use the tour of @xmath102 in the unified graph , as determined by the @xmath339 part of @xmath338 .",
    "all other tours remain unchanged , as it is expressed by the fact that if @xmath81 or @xmath80 had a zero element then @xmath337 or @xmath339 has an all - zero column in the same position .    from lemmata  [ lem_3-sum_tour ] and  [ lem_tour_pivot ] and",
    "the fact that @xmath67- , and @xmath68-sum operations are special cases of the @xmath69-sum operation we obtain the following theorem :    [ th_tourksums ] totally unimodular tour matrices are closed under @xmath0-sums for @xmath176 .",
    "we are now ready to present an algorithm which given a totally unimodular matrix @xmath89 will construct a bidirected graph @xmath47 or equivalently an incidence matrix , where the columns in @xmath89 represent collection of closed tours .    * given a tu matrix @xmath89 , by seymour s theorem  [ seymour_matrix ] we can decompose it via @xmath0-sums into matrices @xmath340 . a separation algorithm for this can be found in the book by truemper  @xcite .",
    "* for each matrix @xmath341",
    "one of the following cases will be true : * * check whether @xmath341 is a network matrix , and if so construct the associated incidence matrix @xmath342 .",
    "this can be done by the tutte s recognition algorithm which results from his decomposition theory for graphic matroids  @xcite . * * check whether @xmath341 is a binet matrix , and if so construct the associated incidence matrix @xmath342 . similarly with step 2.1 , a decomposition theory for binary signed graphic matroids given in  @xcite can be used in this step .",
    "alternatively one can also use the algorithm given in  @xcite . * * if neither of the above cases is true , then @xmath341 is the transpose of a network matrix which is not binet . in this case",
    "construct the bidirected graph representation given in the proof of theorem [ thrm_tu = tour ] . * starting from the incidence matrices @xmath342 resulted from step 2 and the @xmath0-sum decomposition indicated in step 1 , compose the incidence matrix of @xmath89 using the matrix operations so defined in the constructive proofs of lemmata  [ lem_net-3sum - net ] , [ lem_net-3sum - binet ] and [ lem_3-sum_tour ] .",
    "all of the above steps can be performed in polynomial time with respect to the size of the matrix @xmath89 .",
    "the fact that case 2.3 in the above algorithm is possible , that is the existence of a transpose of a network matrix which is not binet , is verified by a recent work of slilaty  @xcite where he identifies a set of 29 excluded minors for a cographic matroid to be signed graphic .",
    "examination of the aforementioned excluded minors , reveals that all are a 2- or 3-sum of two binet matrices without positive loops , therefore by lemma  [ lem_3-sum_tour ] , tour matrices with a bidirected graph representation without positive loops .",
    "however , we were unable to generalise this to an arbitrary non - binet transpose of a network matrix , therefore we use the trivial bidirected graph representation given in the proof of theorem [ thrm_tu = tour ] .",
    "totally unimodular matrices characterise a class of well solved integer programming problems , due to the integrality property of the associated polyhedron . in this paper",
    "we exploit the decomposition theorem of seymour for totally unimodular matrices , and provide a graphical representation for every such matrix in a bidirected graph , such that the structural information of the decomposition building blocks is mostly retained . in order to do this",
    ", we examine the effect of the @xmath0-sum operations on network matrices , their transposes and binet matrices , and show that the aforementioned classes of matrices are not closed under these composition operations . a new , more general , class of matrices",
    "is introduced called tour matrices , which is proved to be closed under @xmath0-sums , and it has an associated bidirected graph representation in the sense that the columns of a tour matrix represent a collection of closed tours .",
    "the authors wish to thank thomas zaslavsky and the two anonymous referees whose comments helped to improve and enhance the presentation of the results in this paper ."
  ],
  "abstract_text": [
    "<S> seymour s famous decomposition theorem for regular matroids states that any totally unimodular ( tu ) matrix can be constructed through a series of composition operations called @xmath0-sums starting from network matrices and their transposes and two compact representation matrices @xmath1 of a certain ten element matroid . given that @xmath1 are binet matrices we examine the @xmath0-sums of network and binet matrices . </S>",
    "<S> it is shown that the @xmath0-sum of a network and a binet matrix is a binet matrix , but binet matrices are not closed under this operation for @xmath2 . a new class of matrices is introduced the so called _ tour matrices _ , which generalises network , binet and totally unimodular matrices . for any such matrix there exists a bidirected graph such that the columns represent a collection of closed tours in the graph . </S>",
    "<S> it is shown that tour matrices are closed under @xmath0-sums , as well as under pivoting and other elementary operations on its rows and columns . </S>",
    "<S> given the constructive proofs of the above results regarding the @xmath0-sum operation and existing recognition algorithms for network and binet matrices , an algorithm is presented which constructs a bidirected graph for any tu matrix .    </S>",
    "<S> * keywords : * network matrices , binet matrices , matroid decomposition , signed graphic matroids . </S>"
  ]
}