{
  "article_text": [
    "machine learning ( ml ) is the area of artificial intelligence which studies how a software application can learn by repeated training @xcite . in ml ,",
    "software applications are not systematically programmed step by step to a particular purpose , but they are instead able to evaluate data instances and generalize their own behaviour in order to perform on new unseen data . in signal processing ,",
    "ml algorithms are called _ adaptive filters _ and are used to extract an estimate of the desired signal when some parameters of the target signal are not known in advance .",
    "adaptive filters are able to refine their update strategy by assessing the error at each time instant and can adapt to changing conditions over time .",
    "a widely used adaptive filter is the least - mean - square ( lms ) which aims at minimizing the squared difference between the desired and estimated signals .    in modern information systems , it is frequent to deal with settings where it is not feasible to process the amount of data in a timely fashion or to collect them in a single place given they are spread across many sources .",
    "the limiting factor is having a single centralized computational centre which is capable to cope with the computational and communication workload . to face these challenges",
    ", ml naturally evolves into distributed ml ( dml ) where we use a network of nodes , typically organized in neighbourhoods where each neighbourhood uses a _ diffusion _ adaptation strategy @xcite",
    ": a node executes an ml algorithm , cooperates with others by sharing its estimations and combines the estimations of its neighbourhood using weighting coefficients .    in this report",
    ", our focus will be on diffusion adaptive networks where nodes use the lms adaptive filter for signal processing .",
    "we define a diffusion adaptive network as configured by a set of parameters : the initial vector parameter , the learning rate , the trust coefficients and the input and noise mean and standard deviations . to study how each parameter affects the network performance in terms of speed of convergence and stability",
    ", we consider the behaviour of the cooperative and non - cooperative nodes with equal configuration .",
    "we then compare the estimations of the cooperative nodes with the average of the estimations of the non - cooperative nodes .",
    "it turns out that introducing diversity in the network can improve convergence .",
    "the most evident gain in performance is when nodes have different learning rates : having two nodes with two different rates is more beneficial than having a single node with a learning rate which is the average of the learning rates from its distributed counterpart .",
    "different initial vector parameters are in general merged after the first few iterations , after which the estimations of all nodes are equal .",
    "the number of iterations by which the estimations start to overlap is controlled by the trust coefficients : more selfish nodes require more iterations before the overlapping happens . in the case",
    "nodes perceive signal with different degrees of noise , the nodes which perceive the most noisy signals perform a weighted sum of estimations computed by nodes reading less noisy signals .    the rest of the technical report is organized as follows : in section [ sec : background ] we will give the mathematical background about the lms adaptive filter . in section [ sec : model ] we will define the agent model we use to study our adaptive network and detail the diffusion strategy we will use in our simulations . in section [ sec : comparison ] we will analyse how each parameter affects the behaviour of agents and discuss the results of experimental simulations . finally in section [ sec : conclusion ] we will summarize the configurations of our network of agents which show that diffusion lms can indeed perform better than lms .",
    "in the following we use * x * to indicate the matrix of features with size @xmath0 x @xmath1 , where @xmath0 is the number of features and @xmath1 the number of time instants .",
    "we use * y * for the vector of measured signals with size @xmath1 and * w * for the vector of parameters with size @xmath0 .",
    "the positive scalar @xmath2 is used to denote time instants .",
    "given a function @xmath3 defined on variables * x * and with parameters * w * , the gradient descent algorithm applied to @xmath3 possibly finds the values of the vector parameter * w * which minimize the value of @xmath3 .",
    "the algorithm iteratively computes the value of * w * at time @xmath2 as follows : @xmath4 the parameter @xmath5 is called _ learning rate _ and is used to control the step size at each iteration . for smaller values of @xmath5",
    "the algorithm will converge more slowly to the values of the vector * w * which minimize @xmath3 . as we assign larger values to @xmath5 the algorithm converges more quickly and possibly",
    "will diverge , showing that the value of @xmath5 is too large for the case at hand .",
    "@xmath3 is usually a cost function related to some given function on variable @xmath6 having as parameter vector @xmath7 , denoted as @xmath8 .",
    "a popular example of cost function is the sum of squares where @xmath9 is the linear function :    @xmath10    where @xmath11 is a row of @xmath6 . applying the gradient descent algorithm to @xmath3 means finding the parameter vector * w * which minimizes the error between the predicted and the actual target values , leading to the following update strategy : @xmath12 where @xmath5 includes the constant scalar resulting from the derivative operation .      equation ( [ eq : gdcostfunction ] ) assumes that we know in advance all of the values of @xmath13 .",
    "this is not the case for online or real - time applications . for this class of applications",
    ", we can use an instantaneous gradient , that results in the weight update @xmath14 such an adaptive filter is called _",
    "stochastic gradient adaptive filter _ as it makes use of the instantaneous gradient which according to @xcite `` _ _ is an unbiased estimate of the true gradient .",
    "since the step parameter is chosen to be a small value , any errors introduced by the instantaneous gradient are averaged over several iterations , and thus the performance loss incurred by its approximation is relatively small _ _ '' .",
    "diffusion lms ( dlms ) is used in settings where more filters are simultaneously run to estimate the same optimal vector parameter .",
    "it extends lms by introducing an additional step where the estimations of the filters are combined .",
    "the combination step may occur before or after the execution of the update strategy reported in equation ( [ eq : instantaneous_gradient ] ) .      for the purpose of our investigation , we model a distributed machine learning environment as a set of @xmath15 agents similarly to @xcite .",
    "an agent is an independent computational unit , which perceives the input signal with a certain degree of noise and iteratively applies the gradient descent algorithm to compute the parameter vector @xmath7 .",
    "the goal of such an agent is to find the parameter vector @xmath16 which minimizes the cost function @xmath3 .    while being computationally independent , an agent @xmath17 may share information about its estimates with other agents . from a topological viewpoint ,",
    "an agent @xmath17 belonging to a network exchanges information with a subset of other agents belonging to the same network .",
    "this subset is defined as the neighbourhood of agent @xmath17 denoted as @xmath18 and it is here intended as  physical \" neighbourhood : if agent @xmath17 is a neighbour of agent @xmath19 then opposite also holds . in general , a network of agents is an undirected graph where agents may change the neighbourhoods they belong to over time @xcite .",
    "another aspect of the dynamics of a network is related to how much trust has an agent @xmath17 for the information its neighbour @xmath19 shares with it .",
    "this is a directional property from agent @xmath17 to agent @xmath19 and it is usually indicated as the scalar @xmath20 .",
    "note that @xmath20 and @xmath21 need not hold the same value .    independently from the strategies adopted to diffuse information among them , agents can share the following data :    * the estimated parameter vector @xmath7 computed at each gradient descent iteration ; * the gradient approximation at each gradient descent iteration ; * the history of the above information .      to the purpose of our analysis",
    "we have built a simulation software to execute multi - agent systems where each agent processes the input signal using a gradient descent algorithm . in our multi - agent system a computational iteration is composed by two execution steps : first we run the gradient descent algorithm for each agent and then when all agents have completed their computations the agents share their estimated vector parameter @xmath7 with their neighbours by applying a weighted sum based on trust coefficients . this strategy is also called combine - then - adapt ( cta ) in @xcite and is summarized in algorithm [ alg : cta ] .",
    "* input data : * @xmath22 , @xmath23 * desired signal : * @xmath24 @xmath25 @xmath26",
    "@xmath27    from equation [ eq : instantaneous_gradient ] and algorithm [ alg : cta ] we identified the following set of parameters as characterizing the configuration of a single agent in a dlms network :    * the learning rate @xmath5 ; * the initial value of the vector parameter @xmath7 ; * the trust coefficients for each neighbour ; * the mean and standard deviation of the perceived input signal .",
    "our goal is to analyse whether having two agents cooperating is beneficial in terms of how fast they converge - the number of iterations needed to get close to @xmath28 - and in terms of the variance of the error . in our experiments we consider the scenario of two cooperative agents .",
    "we configure agent @xmath17 and agent @xmath19 to be two cooperative agents , agent @xmath29 and agent @xmath30 to be non - cooperative agents having the same configuration of agents @xmath17 and @xmath19 respectively and finally agent @xmath31 to be an agent which does not run gradient descent , does not perceive any signal and merely averages the estimations of the non - cooperative agents @xmath29 and @xmath30 .",
    "this is done in order to compare the cooperative agents with their standalone counterparts and to compare how they behave with respect to an agent merely averaging the estimations of the two standalone agents . in our simulations agents",
    "have all the following common configuration :    * the function @xmath32 , where vectors are one - dimensional ; * the update strategy in equation ( [ eq : instantaneous_gradient ] ) ; * the perceived signal given by : @xmath33 where @xmath13 is the input and @xmath34 is the measurement noise . in our simulations we used the box muller transformation @xcite to randomly generate the two signals with a given mean and standard deviation .",
    "note that in our experiments cooperative agents always perceive uncorrelated inputs .    to be informative while discussing the results of our experimental , runs we will make use of an analogy to describe the agent behaviours .",
    "agents trying to estimate the optimal vector parameter are seen like people being in a street and try to walk towards a target position .",
    "each person can have her initial position ( initial vector parameter ) , its step size ( the learning rate ) and sight ( signal perception ) .",
    "analogies will be highlighted in italics .",
    "the simplest diversity we can think of is having agents with the same configuration but the initial vector parameter , which determines the starting point of an agent and how far the agent is from the optimal vector parameter . in general , in the network of agents there will be agents closer to the optimal and some others further from it . given that agents share data at each iteration , we expect that after the first time they average their estimations they behave exactly the same and as the average agent .    for our simulations we used the configuration",
    "detailed in table [ tab : twoagents_par_w0 ] .    [ cols=\"<,^,^,^,^,^\",options=\"header \" , ]     the fact that agents have a different initial vector parameter does not impinge on the estimation variance and only helps reading the plots .    in fig .",
    "[ fig : twoagents_w0_noise ] the agents start from different initial vector parameters and as expected their estimations overlap after the second iteration .",
    "it is also important to highlight how the noise variance of the estimations of agent @xmath17 and agent @xmath19 is lower if compared with the noise variance of the standalone agent @xmath30 which has the largest standard deviation .",
    "this means that a network of cooperative agent tends to flatten the effects of the agents which perceive more noisy signals .",
    "_ we can think of two people in the street having different views of the path leading to their common target position .",
    "sharing and averaging their positions at each time instant helps the blindest person to go on a less erroneous path .",
    "the helping person is inevitably forced to alter its path to keep close to the helped person . _",
    "a network of agents executing dlms filters and sharing estimations at each iteration can indeed perform better than the agent averaging an homogeneous adaptive network when there is diversity in the configuration of agents .",
    "diversity is expressed by a different combination of parameters such as initial vector parameter , learning rate , trust coefficients or perceived signal .",
    "we can summarize the impact of each parameter as follows :    * having agents with different initial vector parameters @xmath35 determines which average configuration the network of agents behaves like after the second iteration ; * having agents with different @xmath5 values implies that the network of agents is composed by faster and slower agents which at each iteration reconcile their estimations .",
    "the net effect is a faster convergence compared to the behaviour of the average agent in a non - cooperative network ; * having agents which trust their own estimations more than they trust the estimations of other agents delays the time instant from which the estimations start to coincide and the network of agents starts to behave as a non - cooperative agent with an initial vector parameter which is the average of all initial vector parameters of the agents composing the network ; * having agents which perceive signal with different noise levels makes the network of agents helps stabilize the agents which perceive the more noisy signals .",
    "mitchell , t. , _ machine learning _",
    ", mcgraw hill .",
    "isbn 0 - 07 - 042807 - 7 , 1997 .",
    "c. lopes and a. sayed , _ diffusion least - mean squares over adaptive networks _ , in proc .",
    "of the ieee international conference on acoustics , speech and signal processing , vol .",
    "3 , pp iii-917 iii-920 , 2007 .",
    "v john mathews and scott c douglas , _ adaptive filters _ , chapter 4 stochastic gradient adaptive filters , 2003 .",
    "ali h. sayed , sheng - yuan tu , jianshu chen , xiaochuan zhao and zaid j. towfic , _ diffusion strategies for adaptation and learning over networks _",
    ", ieee signal processing magazine may 2013 .",
    "a. sayed , _ diffusion adaptation over networks _ , corr , 2012 .",
    "g. e. p. box and mervin e. muller , _ a note on the generation of random normal deviates _ , the annals of mathematical statistics , vol .",
    "2 pp . 610611 , 1958 ."
  ],
  "abstract_text": [
    "<S> in this technical report we analyse the performance of diffusion strategies applied to the least - mean - square adaptive filter . </S>",
    "<S> we configure a network of cooperative agents running adaptive filters and discuss their behaviour when compared with a non - cooperative agent which represents the average of the network . </S>",
    "<S> the analysis provides conditions under which diversity in the filter parameters is beneficial in terms of convergence and stability . </S>",
    "<S> simulations drive and support the analysis .    </S>",
    "<S> stochastic gradient descent , adaptive signal processing , distributed machine learning , diffusion least mean square </S>"
  ]
}