{
  "article_text": [
    "collaborative filtering ( cf )  @xcite is one of the most widely used approaches to recommender systems .",
    "it is based on the analysis of users previous activity ( likes , watches , skips , etc .  of items ) and discovering hidden relations between users and items . among cf methods , matrix factorization techniques",
    "@xcite offer the most competitive performance @xcite . these models map users and items into a latent factor space which contains information about preferences of users w.r.t .  items . due to the fact that cf approaches use only user behavioural data for predictions , but not any domain - specific context of users / items",
    ", they can not generate recommendations for new _ cold _ users or _ cold _ items which have no ratings so far .    a very common approach to solve this _ cold - start problem _",
    "@xcite , called _ rating elicitation _ , is to explicitly ask cold users to rate a small representative _ seed set _ of items or to ask a representative _ seed set _ of users to rate a cold item @xcite .",
    "one of the most successful approaches @xcite to rating elicitation is based on the maximal - volume concept @xcite .",
    "its general intuition is that the most representative seed set should consist of the most representative and diverse latent vectors , i.e. they should have the largest length yet be as orthogonal as possible to each other . formally , the degree to which these two requirements are met is measured by the volume of the parallelepiped spanned by these latent vectors . in matrix terms , the algorithm , called maxvol @xcite , searches very efficiently for a submatrix of a factor matrix with the locally maximal determinant .",
    "unfortunately , the determinant is defined only for square matrices , what means that a given fixed size of a seed set requires the same rank of the matrix factorization that may be not optimal .",
    "for example , the search for a sufficiently large seed set requires a relatively high rank of factorization , and hence a higher rank implies a larger number of the model parameters and a higher risk of overfitting , which , in turn , decreases the quality of recommendations .    to overcome the intrinsic `` squareness '' of the ordinary maxvol , which is entirely based on the determinant ,",
    "we use the notion of rectangular matrix volume , a generalization of the usual determinant . searching a submatrix with high rectangular volume",
    "allows to use ranks of the factorization that are lower than the size of a seed set .",
    "however , the problem of searching for the globally optimal rectangular submatrix is np - hard in the general case . in this paper",
    ", we propose a novel efficient algorithm , called rectangular maxvol , which generalizes original maxvol .",
    "it works in a greedy fashion and adds representative objects into a seed set one by one .",
    "this incremental update has low computational complexity that results in high algorithm efficiency . in this paper",
    ", we provide a detailed complexity analysis of the algorithm and its competitors and present a theoretical analysis of its error bounds .",
    "moreover , as demonstrated by our experiments , the rectangular volume notion leads to a noticeable quality improvement of recommendations on popular recommender datasets .",
    "let us briefly describe the organisation of the paper .",
    "section  [ sec : background ] describes the background on the existing methods for searching representatives that is required for further understanding .",
    "sections [ sec : volume ] , [ sec : algorithm ] present our novel approach based on the notion of rectangular matrix volume and the fast algorithm to search for submatrices with submaximal volume . in sections",
    "[ sec : rectmaxvol_complexity ] and [ sec : bound ] , we provide a theoretical analysis of the proposed method .",
    "section [ sec : experiments ] reports the results of our experiments conducted on several large - scale real world datasets .",
    "section [ sec : related ] overviews the existing literature related to cf , the cold start problem and the basic maximal - volume concept papers .",
    "the rating elicitation methods , such as @xcite , are based on the same common scheme , which is introduced in this section .",
    "suppose we have a system that contains a history of users ratings for items , where only a few items may be rated by a particular user .",
    "denote the rating matrix by @xmath0 , where @xmath1 is the number of users and @xmath2 is the number of items , and the value of its entry @xmath3 describes the feedback of user @xmath4 on item @xmath5 .",
    "if the rating for pair @xmath6 is unknown , then @xmath3 is set to  @xmath7 . without loss of generality and due to the space limit",
    ", the following description of the methods is provided only for the user cold start problem . without any modifications ,",
    "these methods for the user cold start problem can be used to solve the item cold start problem after the transposition of matrix @xmath8 .",
    "algorithm [ alg : elicitation ] presents the general scheme of a rating elicitation method .",
    "such procedures ask a cold user to rate a _ seed set _ of representative items with indices @xmath9 for modeling his preference characteristics , where @xmath10 , called _ budget _ , is a parameter of the rating elicitation system .",
    "warm rating matrix @xmath0 , cold user , budget @xmath10 predicted ratings of the cold user for all items compute indices @xmath9 of representative items that form a seed set elicit ratings @xmath11 of the cold user on items with indices @xmath12 predict ratings of the cold user for all items @xmath13 using @xmath14 @xmath15    the performance of a rating elicitation procedure should be measured using a quality of predictions @xmath15 . for this purpose ,",
    "we use ranking measures ( such as precision@@xmath12 ) , which are well suitable for cf task ( see section [ sec : experiments ] for details ) .",
    "the major contribution of this paper is a novel method of performing step 1 , described in section [ sec : proposed_method ] .",
    "it is based on puresvd @xcite collaborative filtering technique , that is described in section [ sec : puresvd ] . in section [ sec : predicting ] , we discuss how to effectively perform step 3 using the similar factorization based approach . and in section [ sec : maximal ] , we talk about the baseline method for seeking a seed set ( step 1 ) , which is based on the maximal - volume concept .",
    "let us briefly describe the general idea of puresvd , which is a very effective cf method in terms of ranking measures @xcite and therefore used as a basis of our rating elicitation approach .",
    "puresvd provides a solution of the following optimization problem : @xmath16 where @xmath17 is the frobenius norm and @xmath18 is a parameter of puresvd called rank . according to eckart - young theorem  @xcite ,",
    "the optimal solution can be found by computing the truncated sparse singular value decomposition of the sparse rating matrix @xmath8 .",
    "this factorization can be interpreted as follows .",
    "every user  @xmath4 has a low dimensional embedding @xmath19 , a row in the matrix @xmath20 , and every item has an embedding @xmath21 , a column of the matrix @xmath22 .",
    "these embeddings are called _ latent vectors _  @xcite .",
    "the puresvd method provides an approximation  @xmath23 of the unknown rating for a pair @xmath6 , which is computed as the scalar product of the latent vectors : @xmath24 low - rank factors @xmath20 and @xmath22 are used in the rating elicitation procedures that are described further .",
    "let us assume that some algorithm has selected a seed set with @xmath10 representative items with indices @xmath9 , and assume a cold user has been asked to rate only items  @xmath12 , according to steps 1 - 2 of the rating elicitation scheme described by algorithm  [ alg : elicitation ] . in this section , we explain how to perform step 3 , i.e. how to predict ratings @xmath15 for all items using only the ratings of the seed set .",
    "as shown in @xcite , the most accurate way to do it is to find a coefficient matrix @xmath25 that allows to linearly approximate each item rating via ratings @xmath14 of items from the seed set .",
    "each column of @xmath26 contains the coefficients of the representation of an item rating via the ratings of the items from the seed set .",
    "shortly , this approximation can be written in the following way : @xmath27 we highlight two different approaches to compute matrix c.      first approach is called representative based matrix factorization  ( rbmf ) @xcite .",
    "it aims to solve the following optimization task : @xmath28 in our paper , we use the matlab indexing notation : @xmath29 is the matrix whose column @xmath30 coincides with the column @xmath31 of  @xmath8 , where @xmath31 is the @xmath30th component of vector @xmath12 . note that @xmath14 is not a part of @xmath29 , because there is still no information about a cold user ratings .",
    "this optimization task corresponds to the following approximation : @xmath32 the solution of ( [ eq : matrix_decomp ] ) is : @xmath33 since @xmath34 , the matrix @xmath29 is often well - conditioned .",
    "therefore , the regularization term used in @xcite is unnecessary and does not give a quality gain .    2      in this paper , we propose a more efficient second approach that considers the rank-@xmath18 factorization given by equation ( [ eq : puresvd_optimization ] ) ,  @xmath35 .",
    "let @xmath36 be the matrix formed by @xmath10 columns of  @xmath22 that correspond to the items of the seed set .",
    "let us try to linearly recover all item latent vectors via the latent vectors from the seed set : @xmath37 it is a low - rank version of the problem given by ( [ eq : matrix_decomp ] ) and , therefore , is computationally easier .",
    "solution @xmath26 of this optimization problem can be also used for recovering all ratings using ( [ eq : r_coefs ] ) .    unlike ( [ eq : matrix_decomp ] ) , the optimization problem given by ( [ eq : coef_factor_optimization ] ) does not have a unique solution @xmath26 in general case , because there are infinitely many ways to linearly represent an @xmath18-dimensional vector via more than @xmath18 other vectors . therefore , we should find a solution of the underdetermined system of linear equations : @xmath38 where we denote @xmath39 . since the seed set latent vectors surely contain some noise and coefficients in @xmath26 show how all item latent vectors depend on the seed set latent vectors , it is natural to find `` small '' @xmath26 , because larger coefficients produce larger noise in predictions .",
    "we use the least - norm solution @xmath26 in our research , what is additionally theoretically motivated in section [ sec : bound ] .",
    "the least - norm solution of ( [ eq : coef ] ) should be computed as follows : @xmath40 where @xmath41 is the right pseudo - inverse of @xmath42 .",
    "actually , such linear approach to rating recovering results in the following factorization model .",
    "taking the latent vectors of the representative items @xmath42 as a new basis of the decomposition given by equation ( [ eq : puresvd_optimization ] ) , we have @xmath43 where @xmath44 . in this way",
    ", we approximate an unknown rating @xmath3 by the corresponding entry of matrix @xmath45 , where factor @xmath46 consists of the known ratings for the seed set items . this scheme is illustrated on fig .",
    "[ fig : scheme ] .",
    "this section introduces the general idea of the maximal - volume concept and maxvol algorithm @xcite for selecting a good seed set , what corresponds to step 1 in the rating elicitation scheme ( algorithm [ alg : elicitation ] ) .",
    "suppose we want to select @xmath10 representative items with indices @xmath9 .",
    "first of all , maxvol algorithm requires to compute the rank-@xmath10 svd factorization of @xmath8 given by equation ( [ eq : puresvd_optimization ] ) .",
    "after this , searching for an item seed set is equivalent to searching for a square submatrix @xmath47 in the factor matrix @xmath22 .",
    "note that every column of @xmath42 or @xmath22 is a latent vector corresponding to an item from the seed set .",
    "an algorithm of seeking for a set of representative items may rely on the following intuitions .",
    "first , it should not select items , if they are not popular and thus cover preferences of only a small non - representative group of users .",
    "that means that the latent vectors from the seed set should have large norms .",
    "second , the algorithm has to select diverse items that are relevant to different users with different tastes .",
    "this can be formalized as selecting latent vectors that are far from being collinear .",
    "the requirements can be met by searching for a subset of columns of @xmath22 that maximizes the volume of the parallelepiped spanned by them . this intuition is demonstrated in fig .",
    "[ fig : maxvol_demo ] , which captures a two - dimensional latent space and three seed sets .",
    "the volume of each seed set is proportional to the area of the triangle built on the corresponding latent vectors .",
    "the dark grey triangles have small volumes ( because they contain not diverse vectors or vectors with small length ) and hence correspond to bad seed sets .",
    "contrariwise , the light gray triangle has a large volume and represents a better seed set .",
    "overall , we have the following optimization task : @xmath48 the problem is np - hard in the general case @xcite and , therefore , suboptimal greedy procedures are usually applied .",
    "one of the most popular procedures is called maxvol algorithm  @xcite and is based on searching for a _ dominant _ submatrix @xmath49 of @xmath22 .",
    "the dominant property of @xmath42 means that all columns  @xmath50 of @xmath22 can be represented via a linear combination of columns from @xmath42 with the coefficients not greater than 1 in modulus .",
    "although , this property does not imply that @xmath42 has the maximal volume , it guarantees that @xmath42 is _ locally optimal _",
    ", what means that replacing any column of @xmath42 with a column of  @xmath22 , does not increase the volume @xcite .    at the initialization step , maxvol takes @xmath10 linearly independent latent vectors that are the pivots from lu - decomposition  @xcite of matrix @xmath22 .",
    "practice shows that this initialization usually provides a good initial approximation  @xmath42 to maximal volume matrix @xcite .",
    "after this , the algorithm iteratively swaps a `` bad '' latent vector inside the seed set with a  `` good '' one out of it .",
    "the procedure repeats until convergence .",
    "see  @xcite for more rigorous explanation of maxvol algorithm . in our paper",
    ", we also call this algorithm _ square maxvol _ , because it seeks for a square submatrix ( since determinant is defined only for square @xmath42 ) . furthermore , it is important to note that the original algorithm presented in @xcite has crucial speed optimizations for avoiding the expensive matrix multiplications and inversions , which are not presented in our paper due to the lack of space .",
    "let us analyse the complexity of maxvol .",
    "the lu - decomposition with pivoting takes @xmath51 operations .",
    "the iterative updates take @xmath52 operations , where @xmath53 is the number of iterations .",
    "typically , @xmath54 iterations are needed .",
    "the overall complexity of square maxvol can be estimated as @xmath51 .",
    "a more detailed complexity analysis of square maxvol is given in @xcite .",
    "the obvious disadvantage of this approach to rating elicitation is the fixed size of the decomposition rank @xmath55 , because the matrix determinant is defined only for square matrices . that makes it impossible to build a seed set with fixed size @xmath10 using an arbitrary rank of decomposition",
    "however , as we further demonstrate in section [ sec : experiments ] with experiments , using our rectangular maxvol generalization with a decomposition of rank @xmath18 smaller than the size @xmath10 of the seed set could result in better accuracy of recommendations for cold users .",
    "this section introduces a generalization of the maximal - volume concept to rectangular submatrices , which allows to overcome the intrinsic `` squareness '' of the ordinary maximal - volume concept , which is entirely based on the determinant of a square matrix .",
    "consider @xmath56 , @xmath57 .",
    "it is easy to see that the volume of a square matrix is equal to the product of its singular values . in the case of a rectangular matrix @xmath42",
    ", its volume @xcite can be defined in a similar way : @xmath58 we call it _ rectangular volume_. the simple intuition behind this definition is that it is the volume of the ellipsoid defined as the image of a unit sphere under the linear transformation defined by @xmath42 : @xmath59 this can be verified using the singular value decomposition of  @xmath42 and the unitary invariance of the spectral norm . moreover , in the case of a square matrix @xmath42 , the rectangular volume is equal to the ordinary square volume : @xmath60 note that , if @xmath61 , then @xmath62 .",
    "overall , searching for a seed set transforms to the following optimization task that is a generalization of problem  ( [ eq : optimize_det ] ) : @xmath63 , where @xmath64 .",
    "it is important to note that this maximization problem does not depend on the basis of the latent vectors from @xmath42 .",
    "the simplest method to find a suboptimal solution is to use a greedy algorithm that iteratively adds columns of @xmath22 to the seed set .",
    "unfortunately , the straightforward greedy optimization ( trying to add each item to the current seed set and computing its rectangular volume ) costs @xmath65 , that often is too expensive considering typical sizes of modern recommender datasets and number of model hyperparameters .",
    "therefore , we developed a fast algorithm with complexity @xmath51 that is described in the following section .",
    "in this section , we introduce an algorithm for the selection of @xmath10 representative items using the notion of rectangular volume . at the first step",
    ", the algorithm computes the best rank-@xmath18 approximation of the rating matrix @xmath8 , puresvd ( see section  [ sec : puresvd ] for details ) , and selects @xmath18 representative items with the pivot indices from lu - decomposition of @xmath22 or with maxvol algorithm .",
    "this seed set is further expanded by algorithm  [ alg:2maxvol ] in a greedy fashion : by adding new representative items one by one maximizing rectangular volume of the seed set .",
    "further , we show that new representative item should have the maximal norm of the coefficients that represent its latent vector by the latent vectors of the current seed set .",
    "the procedure of such norm maximization is faster than the straightforward approach . at the end of this section",
    "we describe the algorithm for even faster rank-1 updating norms of coefficients .",
    "suppose , at some step , we have already selected @xmath66 representative items with the indices @xmath67 .",
    "let @xmath68 be the corresponding submatrix of @xmath69 .",
    "on the next step , the algorithm selects a column @xmath70 and adds it to the seed set : @xmath71,$ ] where @xmath72 $ ] is an operation of horizontal concatenation of two matrices @xmath73 and @xmath74 .",
    "this column should maximize the following volume : @xmath75\\right).\\ ] ]    suppose @xmath76 is the current matrix of coefficients from equation ( [ eq : coef ] ) , and let @xmath77 be an @xmath5-th column of matrix @xmath26 . then the updated seed set from ( [ eq : volume_update ] )",
    "can be written as following : @xmath78=[s , sc_i]=s[i_l , c_i].\\ ] ] then the volume of the seed set can be written in the following way : @xmath79\\right ) & = \\sqrt{\\det \\left([s , q_i][s , q_i]^\\top \\right)}=\\\\      & = \\sqrt{\\det \\left(ss^\\top + sc_ic_i^\\top s^\\top \\right)}.     \\end{split}\\ ] ] taking into account the identity @xmath80 the volume ( [ eq : rectvol_before_coef ] ) can be written as following : @xmath81\\right)=\\text{rectvol}(s)\\sqrt{1+w_i},\\ ] ] where @xmath82 .",
    "thus , the maximization of rectangular volume is equivalent to the maximization of the @xmath83-norm of the coefficients vector @xmath84 , which we know only after recomputing  ( [ eq : coef_pseudo ] ) .",
    "total recomputing of coefficient matrix @xmath26 on each iteration is faster than the straightforward approach described in section [ sec : volume ] and costs @xmath85 .",
    "however , in the next section , we describe even faster algorithm with an efficient recomputation of the coefficients .",
    "since the matrix of coefficients @xmath26 is the least - norm solution , after adding column @xmath86 to the seed set , @xmath26 should be computed using equation ( [ formula1 ] ) : @xmath87^\\dagger q=[i_l , c_i]^\\dagger s^\\dagger q=[i_l , c_i]^\\dagger c.\\ ] ] the pseudoinverse from ( [ eq : recomputing_coef ] ) can be obtained in this way : @xmath88^\\dagger=[i_l , c_i&]^\\top \\left([i_l , c_i][i_l , c_i]^\\top \\right)^{-1}=\\\\      & = \\begin{bmatrix}i_l\\\\ c_i^\\top \\end{bmatrix}\\left(i_l+c_ic_i^\\top \\right)^{-1 } , \\end{split}\\ ] ] where @xmath89 is an operation of vectical concatenation of @xmath73 and @xmath74 . the inversion in this formula",
    "can be computed by the sherman - morrison formula : @xmath90 putting it into ( [ eq : recomputing_coef ] ) , we finally get the main update formula for @xmath26 : @xmath91    recall that we should efficiently recompute norms of coefficients @xmath92 . using equation ( [ eq : newc ] ) , we arrive at the following formula for the update of all norms @xmath93 : @xmath94 it is natural to see that coefficients norms are decreasing , because adding each new latent vector to the seed set gives more flexibility of representing all latent vectors via representative ones .    equations ( [ eq : newc ] ) and ( [ eq : length_update ] ) allow to recompute @xmath26 and @xmath95 using the simple rank-@xmath96 update . thus , the complexity of adding a new column into the seed set is low , what is shown in section  [ sec : rectmaxvol_complexity ] .",
    "the pseudocode of the algorithm is provided in algorithm  [ alg:2maxvol ] .",
    "rating matrix @xmath0 , number of representative items @xmath10 , rank of decomposition @xmath57 indices @xmath97 of @xmath10 representative items compute rank-@xmath18 puresvd of the matrix @xmath98 get the initial square seed set : @xmath99 @xmath10 pivot indices from lu - decomposition of @xmath22 @xmath100 @xmath101 @xmath102 , where @xmath84 is the @xmath5-th column of @xmath26 @xmath103 @xmath104 $ ] @xmath105 $ ] @xmath106 @xmath107 @xmath12    the seed sets provided by the algorithm can be used for rating elicitation and further prediction of ratings for the rest of the items , as demonstrated in section [ sec : predicting ] .",
    "moreover , if the size of the seed set @xmath10 is not limited by a fixed budget , alternative stopping criteria is proposed in section [ sec : bound ] .",
    "the proposed algorithm has two general steps : the initialization ( steps 15 ) and the iterative addition of columns or rows into the seed set ( steps 612 ) .",
    "the initialization step corresponds to the lu - decomposition or square maxvol , which have @xmath108 complexity .",
    "addition of one element into the seed set ( steps 711 ) requires the recomputation of the coefficients @xmath26 ( step 10 ) and lengths of coefficient vectors ( step 11 ) .",
    "the recomputation ( step 10 ) requires a rank-@xmath96 update of the coefficients matrix @xmath109 and the multiplication @xmath110 , where @xmath111 is a column of @xmath26 .",
    "the complexity of each of the two operations is @xmath112 , so the total complexity of one iteration ( steps 711 ) is @xmath112 .",
    "since this procedure is iterated over @xmath113 , the complexity of the loop ( step 6 ) is equal to @xmath114 .",
    "so , in total , the complexity of algorithm  [ alg:2maxvol ] is @xmath51 .        in this section ,",
    "we theoretically analyse the estimation error of our method proposed in section  [ sec : algorithm ] . according to section [ sec : puresvd ] we have a low - rank approximation of the rating matrix @xmath115 where @xmath116 is a random error matrix . on the other hand",
    ", we have rbmf approximation  ( [ eq : r_coefs ] ) .",
    "let us represent its error via @xmath117 .",
    "first of all , we have @xmath118 since @xmath119 ( see section [ sec : predicting ] for details ) , the rbmf approximation of @xmath8 can be written in the following form : @xmath120 what means @xmath121 the smaller in modulus the noise terms are , the better approximation of @xmath8 we have .",
    "it means that we are interested in the small values of the matrix @xmath26 , such as the least - norm solution of ( [ eq : coef_factor_optimization ] ) .",
    "further , we prove a theorem providing an approximated bound for the maximal length of @xmath84 .",
    "similarly to square maxvol algorithm , a rectangular submatrix is called _ dominant _ , if its rectangular volume does not increase by replacing one row with another one from the source matrix .",
    "[ theorem ] let @xmath122 be a matrix of rank @xmath18",
    ". assume  @xmath9 is a vector of seed set element indices that produces rank-@xmath18 dominant submatrix of @xmath123 , where  @xmath56 and @xmath124 .",
    "let @xmath26 be a matrix of least - norm coefficients  @xmath25 , such that @xmath125 .",
    "then @xmath83-norm of a column @xmath84 of @xmath26 for @xmath5 not from the seed set is bounded as : @xmath126    since @xmath42 is a dominant submatrix of the matrix @xmath22 , it has the maximal rectangular volume among all possible submatrices of @xmath127 $ ] with the shape @xmath128 . therefore , applying lemma  [ lemma ] to the matrix @xmath127 $ ] , we get @xmath129[s , q_i]^\\top \\right ) \\le \\frac{l_0 + 1}{l_0 + 1-f}\\det(ss^\\top ) .\\ ] ] using equation ( [ eq : rect_det ] ) , we get : @xmath130[s , q_i]^\\top \\right)}{\\det(ss^\\top ) } -1\\le \\frac{f}{l_0 + 1-f } , \\end{split}\\ ] ] what finishes the proof .    the similar theoretical result was obtained in @xcite , however our proof seems to be much closely related to the notation used in our paper and in the proposed algorithm .    theorem [ theorem ]",
    "demonstrates that if we have an existing decomposition with the fixed rank @xmath18 and the size of the seed set  @xmath10 is not limited by a fixed budget it is enough to take  @xmath131 items to the seed set for getting all coefficients norm less than 1 .",
    "this condition of representativeness has a very natural geometric meaning : all item latent vectors are inside the ellipsoid spanned by the latent vectors from the seed set .",
    "the numerical experiments with randomly generated  @xmath132 matrices have shown , that algorithm [ alg:2maxvol ] requires only  @xmath133 rows to reach upper bound 2 for the length of each row of @xmath26 and only @xmath134 to reach the upper bound 1 for the length of each row of @xmath26 .",
    "so , although , our algorithm does not guarantee that the seed set submatrix is dominant , the experiment results are fully consistent with the theory .",
    "further , we prove the supporting lemma .",
    "[ lemma ] let @xmath135 and @xmath136 .",
    "let  @xmath137 be @xmath138 submatrix of @xmath73 without @xmath5-th column and  @xmath139 be @xmath140 submatrix of @xmath74 without @xmath5-th row .",
    "then , @xmath141    from the cauchy - binet formula we get @xmath142 where @xmath143 is a vector of @xmath144 different indices .",
    "since @xmath137 contains all columns of @xmath73 except @xmath5-th column , then @xmath145 is a submatrix of @xmath137 for any @xmath146 .",
    "since @xmath12 consists of  @xmath144 different numbers , we have @xmath147 different @xmath5 , such that  @xmath145 is a submatrix of @xmath137 .",
    "the same is true for the matrix @xmath74 .",
    "so get @xmath148 applying cauchy - binet formula to each summand .",
    "therefore , @xmath149 what finishes the proof .",
    "the proposed experiments compare two algorithms : square maxvol based ( our primary baseline ) and rectangular maxvol based ( section [ sec : proposed_method ] ) .",
    "other competitors have either an infeasible computational complexity ( see section [ sec : related ] for details ) or have a lower quality than our baseline , as it is shown in @xcite ( we reproduced the conclusions from @xcite but they are not demonstrated here due to the lack of space ) .",
    "moreover , it is important to note that the experiments in @xcite used smaller versions of the datasets .",
    "therefore , the performance of square maxvol on the extended datasets is different from that reported in @xcite .",
    "we used two popular publicly available datasets in our experiments .",
    "t first one is the movielens dataset which contains 20,000,263 ratings of 26,744 movies from 138,493 users .",
    "the analysis of the older and smaller version of this dataset is provided in  @xcite .",
    "the second one is the netflix dataset .",
    "it contains 100,480,507 ratings of 17,770 movies from 480,189 users .",
    "the description of the dataset and the competition can be found in @xcite .",
    "the rating matrix @xmath8 was formed in the same way as in @xcite .",
    "our evaluation pipeline for the comparison of the rating elicitation algorithms is similar to the one introduced in @xcite .",
    "all our experiments are provided for both the user and the item cold start problems .",
    "however , without loss of generality , this section describes the evaluation protocol for the user cold start problem only .",
    "the item cold start problem can be evaluated in the same way after the transposition of the rating matrix .",
    "we evaluate the algorithms for selecting representatives by the assessing the quality of the recommendations recovered after the acquisition of the actual ratings of the representatives , what can be done as shown in section [ sec : predicting ] .",
    "note that users may not have ratings for the items from the seed set : if user @xmath4 was asked to rate item @xmath5 with unknown rating , then , according to puresvd model , @xmath3 is set to @xmath7 . in case of the user cold start problem ,",
    "all users are randomly divided into 5 folds of equal size , and the experiments are repeated 5 times , assuming that one part is a test set with cold users and the other four parts form the train set and the validation set contain warm users .",
    "analogically , in case of the item cold start , all items were divided into 5 folds .",
    "pointwise quality measures are easy to be optimized directly , but they are not very suitable for recommendation quality evaluation , because the goal of a recommender system is not to predict particular rating values , but to predict the most relevant recommendations that should be shown to the user .",
    "that is why , we use ranking measures to evaluate all methods  @xcite . for evaluation , we divided all items for every user into relevant and irrelevant ones , as it was done in the baseline paper @xcite .",
    "one of the most popular and interpretable ranking measures for the recommender systems evaluation are precision@@xmath12 and recall@@xmath12 @xcite that measure the quality of top-@xmath12 recommendations in terms of their relevance .",
    "more formally , precision@@xmath12 is the fraction of relevant items among the top-@xmath12 recommendations .",
    "recall@@xmath12 is the fraction of relevant items from the top @xmath12 among all relevant items .",
    "our final evaluation measures were computed by averaging precision@@xmath12 and recall@@xmath12 over all users in the test set .",
    "note that in the case of the item cold start problem , precision@@xmath12 and recall@@xmath12 are computed on the transposed rating matrix @xmath8 .",
    "moreover , following the methodology from @xcite , we compare algorithms in terms of coverage and diversity .",
    "as we mentioned in section  [ sec : predicting ] , there are two different ways to compute the coefficients for representing the hidden ratings via the ratings from a seed set . the first one is to compute them via the low - rank factors , as shown in equation ( [ eq : coef_pseudo ] ) .",
    "the second one is to compute them via the source rating matrix  @xmath8 , as shown in equation ( [ eq : coef_matrix ] ) .",
    "our experiments show that the second approach demonstrates the significantly better quality .",
    "therefore , we use this method in all our experiments .",
    "we processed experiments for the seed set sizes from 5 to  100 with a step of 5 .",
    "these computations become possible for such dense grid of parameters , because of the high computational efficiency of our algorithm ( see section [ sec : related ] ) .",
    "the average computational time of rectangular maxvol on the datasets is @xmath150 seconds ( intel xeon cpu 2.00ghz , 256 gb ram ) .",
    "the average computational time of square maxvol is almost the same what confirms the theoretical complexity analysis .    in the case of rectangular maxvol ,",
    "for every size of the seed set , we used the rank that gives the best performance on a separate evaluation set .",
    "[ fig : major ] demonstrates the superiority of our approach over the ordinal square maxvol for all cold start problems types ( user and item ) and for both datasets .",
    "moreover , it can be seen from the magnitudes of the differences that rectangular maxvol gives much more stable results that the square one .",
    "the same conclusions can be made for any combination of precision / recall , @xmath12 and seed set sizes , but they are not demonstrated here due to the lack of space .    as mentioned above , rectangular maxvol used the optimal rank value in our experiments .",
    "[ fig : opt_rank ] demonstrates the averaged optimal rank over all experiments for all datasets and for all cold start problem types .",
    "it is easy to see that , in each case , the required optimal rank is significantly smaller than the corresponding size of the seed set .",
    "this unequivocally confirms that the rectangular generalization of the square maximal - volume concept makes a great sense .",
    "moreover , since rectangular maxvol requires a smaller rank of the rating matrix factorization , it is more computationally and memory efficient .    2    2    [ fig : opt_rank ]    [ fig : coverage_diversity ]    on fig .",
    "[ fig : coverage_diversity ] , we can see that the coverage and diversity measures @xcite of the representative netflix items selected by rectangular maxvol are higher than the measures of square maxvol .",
    "the cases of representative users and movielens dataset lead to the same results , but the corresponding figures are not demonstrated here due to the lack of space .    in the end",
    ", it is interesting to analyse the behaviour of the automatic stopping criterion that adds objects into the seed set until all latent vectors are covered by the ellipsoid spanned by the latent vectors of the representatives .",
    "the experiments show that increasing the rank results in a quality fall in the case of representative users and the ranks higher than 50 , what means an overfitting of puresvd . in case of the representative items ,",
    "the quality becomes almost constant starting from the same ranks .",
    "conventional cf methods do not analyse any domain - specific context of users / items  @xcite , such as explicit user and item profiles , items text descriptions or social relations between users .",
    "therefore , they are domain- and data - independent and can be applied to a wide range of tasks , what is their major advantage .",
    "as shown in  @xcite , cf approaches based on a factorization have high accuracy for the majority of datasets .",
    "while a particular choice of a factorization algorithm is not essential for our approach to the cold start problem , our methodology is based on the puresvd , which performs better than other popular methods such as svd++ @xcite .",
    "the simplest methods for the seed set selection rank users or items by some ad - hoc score which shows how representative they are and take the top-@xmath12 ranked entities as a seed set  @xcite .",
    "an obvious drawback of such methods that is avoided in our approach is that these elements are taken from the seed set independently and diversity of the selected elements is limited  @xcite .",
    "further in this section , we overview the methods that aim on a selection of a diverse seed set and that have better performance .",
    "this is why we do not use the scoring methods in our experiments .      among them ,",
    "the most straightforward method is the greedyextend approach @xcite .",
    "unfortunately , the brute force manner of greedyextend implies very high computational costs .",
    "hence , it is hardly scalable , in contrast to the approaches that are empirically compared in this paper .",
    "this method greedily adds the item @xmath5 to the current seed set of indices  @xmath151 that maximizes the target quality measure .",
    "the search of the best @xmath5 is computed in a brute force manner , i.e. the algorithm iteratively adds the best item into the seed set :  @xmath104 $ ] , where @xmath152)$ ] and @xmath153)$ ] is the quality measure of recommendations generated using the seed set indices @xmath154 $ ] .",
    "the authors of this method reported the results only for an approach that uses similarities of items to predict the ratings via the seed set ratings .",
    "more effective  @xcite linear approach described in section [ sec : predicting ] costs  @xmath155 , where  @xmath156 . at each step ,",
    "the least squares solution is computed for almost all items , i.e.  @xmath157 times . since the algorithm has @xmath10 such steps , the total complexity is  @xmath158 ( more than @xmath159 operations for the netflix dataset and the seed set size @xmath160 ) .",
    "therefore , we do not use this method in our experiments .",
    "another class of methods of searching for diverse representatives is based on the factorization of the rating matrix .",
    "since the selection of user or item representatives is equivalent to selecting a submatrix of the corresponding factor , these algorithms seek for the submatrix that maximizes some criterion .",
    "one such approach , called backward greedy selection  @xcite , solves only the item cold start problem , but not the user one .",
    "this method is based on the techniques for transductive experimental design introduced in @xcite . to get the seed set",
    ", it greedily removes users from a source user set in order to get a good seed set minimizing the value @xmath161 where  @xmath162 is a submatrix in the items factor  @xmath122 of a rank-@xmath18 decomposition .",
    "each deletion of an item requires iterative look up of all the items in the data , where each iteration costs @xmath163 .",
    "so , one deletion takes @xmath164 operations . assuming that @xmath165 , the whole procedure takes  @xmath166 operations , which is too expensive to be computed on real world datasets ( the authors have selected a small subset of users to perform their evaluation ) .",
    "therefore , we do not use this method in our experiments .      the method presented in @xcite , called representative based matrix factorization ( rbmf ) , takes the diversity into account as well .",
    "it uses maximal - volume concept and the maxvol algorithm @xcite for searching the most representative rows or columns in the factors of a cf factorization .",
    "this approach is highly efficient and more accurate than all ad - hoc competitors , but it also has one important limitation .",
    "it must use the same rank of factorization as the desired number of representative users or items for the seed set . the algorithm proposed in our paper",
    "is a generalization of maxvol that allows to use different rank values .",
    "it often leads to a better recommendation accuracy , as shown in section [ sec : experiments ] .",
    "let us overview the computational complexity of the proposed rectangular maxvol and its competitors .",
    "some of these methods use low - rank factorizations of the matrix , whose detailed complexity analysis is provided in  @xcite .",
    "however , as this is not a key point of our work , we neglect the computational cost of factorizations in the further analysis , because it is same for all rating elicitation algorithms and usually is previously computed for the warm cf method .",
    "the summary of the complexity analysis is shown in table  [ tab : complexity ] .",
    "the detailed complexity analysis of square maxvol and rectangular maxvol is provided in sections [ sec : maximal ] and [ sec : rectmaxvol_complexity ] respectively .",
    ".complexity of the algorithms [ cols=\"<,<,<\",options=\"header \" , ]      apart from rating elicitation methods , there were also different approaches to cold start problem proposed in the literature .",
    "additional context information ( e.g. , category labels @xcite or all available metadata @xcite ) may be used .",
    "moreover , there is a class of methods that use adaptive tree - based questionnaires to acquire the initial information about new users @xcite .",
    "moreover , the cold start problem can be viewed from the exploration - exploitation trade - off point of view @xcite .",
    "the methods from @xcite analyse the performance of cf methods w.r.t .  the number of known ratings for a user .",
    "the maximal - volume concept , originally described in the field of low - rank approximation of matrices  @xcite , provides an approach for a matrix approximation in a pseudo - skeleton form , which is a product of matrices formed by columns or rows of the source matrix .",
    "the algorithm , called maxvol  @xcite , allows to efficiently find a well - conditioned submatrix with a high enough volume for building such an approximation .",
    "maximal volume submatrices are useful not only for low - rank approximations , but also in wireless communications  @xcite , preconditioning of overdetermined systems @xcite , tensor decompositions @xcite , and recommender systems @xcite .",
    "our generalization of the maximal - volume concept to rectangular case offers additional degrees of freedom , what is potentially useful in any of these areas .",
    "in our paper , we overviewed the existing approaches for the rating elicitation and introduced the efficient algorithm based on the definition of rectangular matrix volume",
    ". moreover , in order to demonstrate the superiority of the proposed method , we provided the analytical and experimental comparison to the existing approaches .",
    "it seems to be an interesting direction of future work to apply the proposed framework to building tree - based cold - start questionnaires in recommender systems .    another interesting direction for future work is to join approaches from two classes : based on the maximal - volume concept and based on optimal design criteria .",
    "they historically came from absolutely different fields : from computational lineal algebra and from statistical experimental analysis respectively .",
    "although all these methods are very similar from the mathematical point of view , it seems quite interesting to explore their similarities and differences .",
    "work on problem setting and numerical examples was supported by russian science foundation grant 14 - 11 - 00659 .",
    "work on theoretical estimations of approximation error and practical algorithm was supported by russian foundation for basic research 16 - 31 - 00351 mol_a .",
    "also we thank evgeny frolov for helpful discussions ."
  ],
  "abstract_text": [
    "<S> cold start problem in collaborative filtering can be solved by asking new users to rate a small seed set of representative items or by asking representative users to rate a new item . </S>",
    "<S> the question is how to build a seed set that can give enough preference information for making good recommendations . </S>",
    "<S> one of the most successful approaches , called representative based matrix factorization , is based on maxvol algorithm . </S>",
    "<S> unfortunately , this approach has one important limitation  a seed set of a particular size requires a rating matrix factorization of fixed rank that should coincide with that size . </S>",
    "<S> this is not necessarily optimal in the general case . in the current paper </S>",
    "<S> , we introduce a fast algorithm for an analytical generalization of this approach that we call rectangular maxvol . </S>",
    "<S> it allows the rank of factorization to be lower than the required size of the seed set . </S>",
    "<S> moreover , the paper includes the theoretical analysis of the method s error , the complexity analysis of the existing methods and the comparison to the state - of - the - art approaches . </S>"
  ]
}