{
  "article_text": [
    "we have recently @xcite proposed a new form of nonextensive entropy which depends on a parameter similar to tsallis entropy @xcite , and in a similar limit approaches shannon s classical extensive entropy .",
    "we have shown how the definition for this new form of entropy can arise naturally in terms of mixing of states in a phase cell when the cell is re - scaled , the parameter being a measure of the rescaling , and how shannon s coding theorem @xcite elucidates such an approach .    in this paper",
    "we shall adopt a more general attitude and try to develop the statistical mechanics of systems where the entropy is defined almost arbitrarily .",
    "such a designer entropy @xcite may indeed be relevant in a specific context , but we shall not justify here any specific form .",
    "the applicability of the tsallis form which leads to a levy - type pdf found in many physical contexts is now well established @xcite and in the earlier paper we have commented about how our form may also be more relevant in a context that demands a more stiff pdf . in this paper",
    "we concentrate on the use of the pdf to obtain macroscopic quantities for general entropy functions .",
    "central to the development of the statistical mechanics of a system is the definition of the free energy , because it is related to the normalization of the probability distribution function , which in turn controls the behavior of all the macroscopic properties of the ensemble .",
    "hence we shall first establish a general prescription to obtain the free energy , and then determine its value in a simple physical case in terms of the temperature for tsallis and the newer form .",
    "we shall then use it to get the specific heat in both cases and see how it changes with the change of the parameter at different temperatures .",
    "the pdf is found by optimizing the function    @xmath0    where @xmath1 is the entropy ( whichever form ) , @xmath2 the internal energy of the ensemble per constituent , @xmath3 is the probability of the @xmath4-th state which has energy @xmath5 , and @xmath6 and @xmath7 are the lagrange multipliers associated with the normalization of the pdf s @xmath3 and the conservation of energy .",
    "let us make the assumption that the entropy @xmath1 is a sum of the components from all the states :    @xmath8    where @xmath9 is a generalized function which will in general be different from the shannon form :    @xmath10    we get from optimizing @xmath11    @xmath12    with the simple solution    @xmath13    the constant of integration vanishing because there can be no contribution to the entropy from a state which has zero probability .",
    "we shall assume that the helmholtz free energy @xmath14 is defined by    @xmath15    hence if @xmath1 is nonextensive , and @xmath2 is extensive , then @xmath14 must also be nonextensive .    using eq.5 and eq.6",
    "get    @xmath16    hence we get the relation for the pdf    @xmath17    with the definition    @xmath18    here we assume that the function @xmath19 can be inverted",
    ". this may not always be the case for an arbitrary expression for the entropy , at least not in a manageable closed form .",
    "finally , @xmath14 can be obtained from the constraint equation    @xmath20    once @xmath14 has been determined , it may be placed in eq.8 to get the pdf @xmath3 for each of the states , all properly normalized , and we can find @xmath2 and its derivative @xmath21 , the specific heat . for the simple system that we shall be concerned with , pressure and volume , or their analogues , will not enter our considerations , and hence we have only one specific heat , @xmath22 , with @xmath7 now identified as the inverse scale of energy , the temperature @xmath23 ,    @xmath24",
    "the shannon entropy eq.3 immediately gives , using eq.8 and eq.9    @xmath25    so that eq.10 yields the familiar expression for @xmath14    @xmath26    where @xmath27 is the partition function    @xmath28    the exponential form of @xmath3 in eq.12 allows the separation of the @xmath14 dependent factor and hence such a simple expression for @xmath14 in the case of shannon entropy , giving us normal extensive thermodynamics .    in the tsallis case",
    "we have    @xmath29    using the q - logarithm    @xmath30    and this is easily seen to lead to , using the symbol @xmath31 for @xmath32    @xmath33    we note that as it is no longer possible to separate out a common @xmath14 dependent factor , we can no longer find an expression for @xmath14 in terms of the partition function in the usual way .",
    "instead it is necessary to solve the normalization equation eq.10 . for a general value of @xmath31 this will give an infinite number of roots , but for values of @xmath31 corresponding to reciprocals of integers , we shall have polynomial equations with a finite number of roots , which too may be complex in general .",
    "we shall later see , at least for the simple example we consider later , that a real and stable root can be found that approaches the shannon value of @xmath14 as @xmath34 , because in that limit the @xmath35 function in the definition of the tsallis entropy also coincides with the natural logarithm .",
    "the entropy we proposed in ref.@xcite is given by    @xmath36    with mixing probability @xcite    @xmath37    we can also express it as the q - expectation value @xmath38    proceeding as in the case of tsallis entropy we get , with @xmath39 ,    @xmath40    where @xmath41 is the lambert function defined by    @xmath42    like the tsallis case , here too we have to obtain @xmath14 by solving numerically the transcendental eq .",
    "10 . for the specific heat",
    "we get    @xmath43    where we have written for brevity @xmath44 and have used the following identities related to the lambert function @xcite .",
    "@xmath45    as @xmath46 for small @xmath47 , we see that for small @xmath31 we effectively get classical pdf and thermodynamics , as in the tsallis case .",
    "so the parameter @xmath31 is again a measure of the departure from the standard statistical mechanics due to nonextensivity .",
    "however , our nonextensivity is different functionally from the tsallis form @xcite , and the values of @xmath31 in the two forms can only be compared in the limit of low @xmath7 .",
    "if we use the power series expansion of @xmath48    @xmath49    and compare that with the power series expansion for @xmath50 in a form of the tsallis @xmath3 similar to the new entropy form    @xmath51    we get a cancelation of the parameter @xmath52 of the new entropy and of tsallis parameter @xmath53 in the first order , so that both distributions approach the shannon pdf , as we have already mentioned , but if we demand equality in the second order , we get    @xmath54    the third order difference between @xmath55 and @xmath50 is only @xmath56 , and hence the difference between the tsallis form and our form of entropy will be detectable at rather low @xmath23 , i.e. high @xmath7 .",
    "let us consider the simplest nontrivial system , where we have only two energy eigenvalues @xmath57 , as in a spin-1/2 system .",
    "for a noninteracting ensemble of systems we shall expect the standard results @xcite corresponding to shannon entropy    @xmath58/\\beta \\\\ s = \\log[2 \\cosh(\\beta e)]- \\beta e \\tanh ( \\beta e ) \\\\ u = - e \\tanh ( \\beta e )   \\\\ c = ( \\beta e)^2 /\\cosh^2 ( \\beta e)\\end{aligned}\\ ] ]     @xmath14 for shannon ( top ) , tsallis with @xmath59 ( middle ) and tsallis with @xmath60 ( bottom),width=302 ]     @xmath1 for same three entropy forms ( from bottom to top shannon , tsallis ( 0.1 ) , tsallis ( 0.25)),width=302 ]    for the tsallis entropy we shall take @xmath61 and solve numerically .",
    "the values are shown in figs 1 - 4 .",
    "it is seen that tsallis entropy gives very similar shapes for all the variables and for @xmath62 we get a fit much nearer to the shannon form than for @xmath63 .",
    "the specific heat shows the typical schottky form for a two - level system .",
    "@xmath2 for same three entropy forms ( same order as for @xmath1),width=302 ]     @xmath21 for same three entropy forms ( peaks bottom to top - shannon , tsallis ( 0.1 ) , tsallis ( 0.25)),width=302 ]    though the variables involve both @xmath64 and @xmath65 , after finding @xmath14 we can replace @xmath65 by @xmath66 for faster execution of the numerics .    for our new entropy",
    "too we first find the numerical value of @xmath14 from the normalization condition    @xmath67    and then use this value to find @xmath2 , @xmath1 , and @xmath21 . in figs .",
    "5 - 8 we show the values corresponding to @xmath68 , which is half the tsallis parameter @xmath69 used , and also the shannon values .",
    "we note that only for the @xmath1 curve we have a perceptible difference between tsallis entropy and our new entropy at values of @xmath7 near @xmath70 .",
    "comparison of @xmath14 for shannon ( apart ) , tsallis with @xmath71 and new entropy for @xmath72 ( superposed),width=302 ]     comparison of @xmath1 for same three forms of entropy ( shannon , tsallis ( 0.1 ) , new entropy(0.05 ) - tsallis is just over the new entropy ) .,width=302 ]     comparison of @xmath2 for the same three entropies .",
    "shannon is separated , other two overlap.,width=302 ]    specific heat c for same three entropies .",
    "again , only shannon is separated.,width=302 ]",
    "we have presented above a simple prescription for finding the important thermodynamic variables for any given form of the entropy as a function of the pdf s of the states .",
    "we note that despite the apparent complexity of the exponential or transcendental equations determining the primary variable , the helmholtz free energy @xmath14 , it is possible to numerically get stable values which approach the expected shannon values in the right limit of the parameter used , both in the tsallis case and in our case of the newly defined entropy . for higher values of the parameter",
    "our entropy would give values varying significantly from the shannon or even the tsallis entropy , and there may be physical situations where that may indeed be the desirable characteristic .",
    "but at low values the corresponding values of the parameters for the two distributions produce virtually completely overlapping graphs",
    ". the form of the entropy may be a reflection of the effective interaction among the constituent systems of the ensemble , the shannon form being the limiting case of the zero interaction case , and tsallis or our form being results of different forms of interaction with @xmath31 standing for a coupling constant",
    ". it may be interesting to investigate more complicated systems that are physically realizable and comparable .",
    "it is noteworthy that most thermodynamic functions we have considered here are not crucially dependent on the form of the entropy with adjusted coupling , though the value of entropy itself may vary significantly in the different formulations .",
    "this probably indicates that the best way to discriminate between the suitability of different definitions of entropy in different contexts may be in comparing quantities that relate most directly to entropy .",
    "f.  shafee , `` a new nonextensive entropy '' , nlin.ao/0406044 ( 2004 ) c.  tsallis,_j .",
    "_ , * 52 * , 479(1988 ) p.  grigolini , c. tsallis and b.j .",
    "west,_chaos , fractals and solitons_,*13 * , 367 ( 2001 ) a.r .",
    "plastino and a. plastino , _ j. phys .",
    "* 27 * , 5707 ( 1994 ) m.a .",
    "nielsen and m. chuang , _ quantum computation and quantum information _",
    "( cambridge u.p . ,",
    "ny , 2000 ) p.t .",
    "landsberg , `` entropies galore '' , _ braz .",
    "j. phys . _",
    "* 29 * , 46 ( 1999 ) c.  beck , `` nonextensive statistical mechanics and particle spectra '' , hep - ph/0004225 ( 2000 ) o.  sotolongo - costa et al .",
    ", `` a nonextensive approach to dna breaking by ionizing radiation '' , cond - mat/0201289 ( 2002 ) c.  wolf , `` equation of state for photons admitting tsallis statistics '' , _ fizika b _ * 11 * , 1 ( 2002 ) r.m .",
    "corless , g.h .",
    "gonnet , d.e.g .",
    "hare , d.j .",
    "jeffrey and d.e .",
    "knuth , `` on the lambert w function '' , u.w .",
    "ontario preprint ( 1996 ) r.k .",
    "pathria , _ statistical mechanics _ , ( butterworth - heinemann , oxford , uk , 1996 ) p.77"
  ],
  "abstract_text": [
    "<S> we consider the problem of defining free energy and other thermodynamic functions when the entropy is given as a general function of the probability distribution , including that for nonextensive forms . </S>",
    "<S> we find that the free energy , which is central to the determination of all other quantities , can be obtained uniquely numerically even when it is the root of a transcendental equation . </S>",
    "<S> in particular we study the cases of the tsallis form and a new form proposed by us recently . </S>",
    "<S> we compare the free energy , the internal energy and the specific heat of a simple system of two energy states for each of these forms . </S>"
  ]
}