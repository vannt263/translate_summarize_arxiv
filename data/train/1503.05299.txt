{
  "article_text": [
    "signal reconstruction is a fundamental problem in signal processing . recently ,",
    "a paradigm called _ compressed sensing _  @xcite has been proposed for signal reconstruction from incomplete measurements .",
    "the idea of compressed sensing is to utilize the property of _ sparsity _ in the original signal ; if the original signal is sufficiently sparse , practical algorithms such as the basis pursuit  @xcite , the orthogonal matching pursuit  @xcite , etc , may give exact recovery under an assumption on the measurement matrix ( see e.g. @xcite ) .",
    "on the other hand , it is also important to reconstruct discrete signals whose elements are generated from a finite alphabet with a known probability distribution .",
    "this type of reconstruction , called _ discrete signal reconstruction _",
    ", arises in black - and - white or grayscale sparse image reconstruction  @xcite , blind estimation in digital communications  @xcite , machine - type multi - user communications @xcite , discrete control signal design  @xcite , to name a few .",
    "the difficulty of discrete signal reconstruction is that the reconstruction has a combinatorial nature and the computational time becomes exponential .",
    "for example , 200-dimensional signal reconstruction with two symbols ( i.e. binary signal reconstruction ) needs at worst about @xmath0 years with a computer of 34 peta flops ( see section [ sec : problem ] below ) , which can not be executed , obviously .    to overcome this difficulty",
    ", we borrow the idea of compressed sensing based on @xmath1 optimization as used in the basis pursuit @xcite .",
    "our idea is that if the original discrete signal , say @xmath2 , includes @xmath3 symbols @xmath4 , then each vector @xmath5 is sparse .",
    "for example , a binary vector @xmath2 on alphabet @xmath6 includes a number of @xmath7 and @xmath8 , and hence both @xmath9 and @xmath10 are sparse . to recover such a discrete signal , we propose to minimize the _ sum of weighted absolute values _ of the elements in @xmath5 .",
    "the weights are determined by the probability distribution on the alphabet .",
    "the problem is reduced to a standard linear programming problem , and effectively solved by numerical softwares such as cvx in matlab  @xcite .    for discrete signal reconstruction ,",
    "there have been researches based on compressed sensing , called _ integer compressed sensing _ :",
    "@xcite has proposed a bayesian - based method , which works only for binary sparse signals ( i.e. , @xmath11-@xmath7 valued signals that contain many 0 s ) .",
    "@xcite considers arbitrary finite alphabet that contains @xmath11 .",
    "more recently , motivated by decision feedback equalization , @xcite proposes to use @xmath1 optimization for discrete signal estimation under the assumption of sparsity .",
    "@xcite also propose methods based on the finiteness of the measurement matrix ( i.e. , the elements of the measurement matrix are also in a finite alphabet ) .",
    "as mentioned in @xcite , this type of integer compressed sensing is connected with error correcting coding .",
    "compared with these researches , the proposed method in this paper considers arbitrary finite alphabet that does not necessarily contain @xmath11 .",
    "the remainder of this letter is organized as follows : section [ sec : problem ] formulates the problem of discrete signal reconstruction and discusses the difficulty of the problem .",
    "section [ sec : solution ] proposes to use the sum of weighted absolute values for discrete signal reconstruction , and show a sufficient and necessary condition for exact recovery by extending the notion of the null space property @xcite .",
    "examples of one - dimensional signals and two - dimensional images are included in section [ sec : example ] .",
    "section [ sec : conclusion ] draws conclusions .      for a vector @xmath12^\\top \\in{\\mathbb{r}}^n$ ] , we define the @xmath1 and @xmath13 norms respectively as @xmath14 where @xmath15 denotes the transpose . for a vector @xmath2 and a scalar @xmath16",
    ", we define @xmath17^\\top.\\ ] ] for a matrix @xmath18 , @xmath19 is the kernel ( or the null space ) of @xmath20 , that is , @xmath21 @xmath22 is the @xmath23-dimensional identity matrix , and @xmath24 is a @xmath25-dimensional vector whose elements are all @xmath7 , that is , @xmath26^\\top \\in { \\mathbb{r}}^k.\\ ] ] for two matrices @xmath27 and @xmath28 , @xmath29 denotes the kronecker product , that is , @xmath30 where @xmath31 is the @xmath32-th element of @xmath33 . for two real - valued vectors @xmath2 and @xmath34 of the same size , @xmath35 denotes the element - wise inequality , that is , @xmath35 means @xmath36 for all @xmath37 .",
    "assume that the original signal @xmath2 is an @xmath38-dimensional vector whose elements are discrete .",
    "that is , @xmath39^\\top \\in { \\mathcal x}^n,\\\\   { \\mathcal x } & \\triangleq \\{r_1,r_2,\\ldots , r_l\\ } ,   \\end{split } \\ ] ] where @xmath40 and we assume @xmath41 if a symbol , say @xmath16 , is a complex number , then taking @xmath42 and @xmath43 gives a real - valued alphabet , and hence the assumption is not restrictive .",
    "we here assume that the values of @xmath44 are known and the probability distribution of them is given by @xmath45 where we assume @xmath46    then we consider a linear measurement process modelled by @xmath47 where @xmath48 .",
    "note that we consider a complex - valued matrix @xmath20 since @xmath20 can be constructed from e.g. a complex - valued dft ( discrete fourier transform ) matrix ; see the image processing example in section [ sec : example ] .",
    "we assume incomplete measurements , that is , @xmath49 .",
    "the objective here is to reconstruct @xmath50 from the measurement vector @xmath51 in .",
    "first of all , we discuss the uniqueness of the solution of the discrete signal reconstruction .",
    "we have the following proposition :    [ prop : uniqueness ] given @xmath18 , the following properties are equivalent :    1",
    ".   if @xmath52 and both @xmath53 and @xmath54 are in @xmath55 , then @xmath56 .",
    "2 .   define the difference set of @xmath57 as @xmath58 then @xmath59 3 .",
    "the matrix @xmath20 is injective as a map from @xmath60 to @xmath61 .",
    "( a)@xmath62(b ) :  assume ( a ) holds .",
    "take any @xmath63 . since @xmath64",
    ", there exist @xmath65 such that @xmath66",
    ". then we have @xmath67 since @xmath68 .",
    "then from ( a ) , we have @xmath56 .",
    "it follows that @xmath69 .",
    "( b)@xmath62(c ) :  assume ( b ) holds . take any @xmath70 and assume @xmath71 . then from ( b ) , we have @xmath69 .",
    "this proves @xmath20 is an injective map from @xmath60 to @xmath72 .",
    "( c)@xmath62(a ) :   assume that ( c ) holds .",
    "take any @xmath65 such that @xmath52 .",
    "since @xmath73 and @xmath20 is injective on @xmath60 , we have @xmath74 , or @xmath56 .    throughout the letter",
    ", we assume the uniqueness of the solution , that is , the pair @xmath75 is chosen to satisfy .",
    "if the uniqueness assumption holds , we can find the exact solution in a finite number of steps via an exhaustive computation as follows .",
    "the set @xmath76 is a finite set , and we can write @xmath77 . for each @xmath78 , we compute @xmath79 and check if @xmath80 .",
    "thanks to the uniqueness assumption , we can find the exact solution in a finite time .",
    "the problem is that the size of @xmath76 is @xmath81 , and hence the computational complexity is exponential .",
    "for example , if @xmath82 ( two symbols ) and @xmath83 , then @xmath84 which takes at worst about @xmath85 years ( much longer than the lifetime of the universe ) by the current fastest computer with @xmath86 peta flops . to overcome this , we adopt a relaxation technique based on the sum of absolute values in the next section .",
    "we here propose a relaxation method for discrete signal reconstruction . by borrowing the idea of compressed sensing",
    ", we can assume that each vector @xmath5 , @xmath87 , is sparse ( if the probability @xmath88 given in is not so small ) , and the sparsity is proportional to the probability @xmath88 .",
    "hence , we consider the following minimization problem : @xmath89 where we use the @xmath1 norm for the measure of sparsity as in compressed sensing . by the definition of the @xmath1 norm , we rewrite the cost function @xmath90 as @xmath91 where @xmath92 is the sum of weighted absolute values @xmath93 an example of this function",
    "is shown in fig .",
    "[ fig : lt ] .     in the cost function .",
    "]    as is shown in this figure , the function @xmath92 is continuous , convex , and piecewise linear .",
    "in fact , we have the following proposition :    the function @xmath92 is continuous and convex on @xmath94 and is a piecewise linear function given by @xmath95\\\\          a_it + b_i ,   & \\text{if~ } t \\in ( r_i , r_{i+1}],~ i=1,2,\\ldots , l-1\\\\          t-\\overline{r } , & \\text{if~ } t \\in [ r_l,\\infty ) .      \\end{cases}\\ ] ] where @xmath96    since each function @xmath97 in @xmath92 is continuous and convex on @xmath98 , the function @xmath92 , which is the convex combination of @xmath97 , @xmath87 , is also continuous and convex on @xmath98 .",
    "suppose @xmath99 . from the inequality",
    ", we have @xmath100 for @xmath87 , and hence @xmath101 where we used .",
    "next , suppose @xmath102 ( @xmath103 ) .",
    "the inequality gives @xmath104 for @xmath105 and @xmath106 for @xmath107 .",
    "it follows that @xmath108 finally , if @xmath109 , then @xmath110 for @xmath87 due to , and hence @xmath111    note that the function @xmath92 is rewritten as @xmath112 where @xmath113 , @xmath114 , @xmath115 , and @xmath116 .",
    "it follows that the optimization is equivalently described as @xmath117 where @xmath118 is an auxiliary variable , and @xmath119^\\top\\in{\\mathbb{r}}^{l+1},\\\\   { { \\boldsymbol{b } } } & \\triangleq { { \\boldsymbol{1}}}_n\\otimes{{\\boldsymbol{b}}}\\in{\\mathbb{r}}^{n(l+1 ) } ,    { { \\boldsymbol{b}}}\\triangleq [ b_0,b_1,\\ldots , b_l]^\\top \\in{\\mathbb{r}}^{l+1},\\\\    e & \\triangleq i_n \\otimes { { \\boldsymbol{1}}}_{l+1}\\in { \\mathbb{r}}^{n(l+1)\\times n}.   \\end{split}\\ ] ] this is a standard linear programming problem and can be efficiently solved by numerical optimization softwares , such as cvx in matlab  @xcite .",
    "now , we discuss the validity of the relaxation optimization given in or . to see this ,",
    "we extend the notion of the _ null space property _",
    "@xcite in compressed sensing to our problem :    a matrix @xmath18 is said to satisfy the _ null space property _ for an alphabet @xmath120 if @xmath121 for any @xmath122 and any @xmath123",
    ".    then we have the following theorem :    let @xmath18 . every @xmath50 is uniquely recovered from the @xmath1 optimization with @xmath124 if and only if @xmath20 satisfies the null space property for @xmath120 .",
    "( @xmath62 ) : take any @xmath125 and @xmath122 .",
    "put @xmath126 . since @xmath68 , we have @xmath127 , or @xmath128 .",
    "this means that @xmath129 is in the feasible set of the optimization problem with @xmath124 .",
    "also , we have @xmath130 since @xmath131 . now , by assumption , @xmath2 is the unique solution of with @xmath124 , and hence we have @xmath132 .",
    "( @xmath133 ) : take any @xmath122 and @xmath134 such that @xmath130 and @xmath128 .",
    "put @xmath135 .",
    "then we have @xmath136 . from the null space property for @xmath57",
    ", we have @xmath137 .",
    "it follows that @xmath2 is the unique solution of .",
    "in this section , we show two examples to illustrate the effectiveness of the proposed method .",
    "the first example is one - dimensional signal reconstruction with multiple symbols .",
    "let the original signal @xmath2 be a @xmath138-dimensional vector ( i.e. @xmath83 ) and the elements are drawn from the following alphabets with probability distributions : @xmath139 where @xmath140 $ ] .",
    "we assume the measurement vector @xmath34 is a @xmath141-dimensional vector ( i.e. @xmath142 ) , and the measurement matrix @xmath20 is generated such that each element is independently drawn from the gaussian distribution with a mean of 0 and a standard deviation of @xmath7 by using a matlab command , randn(100,200 ) .",
    "the original vector @xmath2 is also generated such that each element is independently drawn from the distribution with varying parameter @xmath140 $ ] .",
    "vs probability @xmath143 for @xmath144 ( top ) , @xmath145 ( middle ) , @xmath146 ( bottom ) , by the proposed ( solid ) and the basis pursuit ( dash ) ]    fig .",
    "[ fig : error ] shows the graphs of the averaged nsr ( noise - to - signal ratio ) @xmath147 for @xmath148 in , where @xmath149 is the reconstructed signal , with 200 trials of random @xmath20 and @xmath2 for each @xmath140 $ ] . if @xmath143 is large ( i.e. , @xmath150 ) , then the original vector @xmath2 is sparse , and we also reconstruct the original signal by the basis pursuit @xmath151 and then round off the values by the basis pursuit to the nearest integer .",
    "the error graphs by the basis pursuit are also shown in fig .",
    "[ fig : error ] . for the binary alphabet @xmath152",
    ", one may exchange the roles of 0 and 1 before performing the basis pursuit , and the error curve below @xmath153 is pessimistic .",
    "however , such a simple strategy can not be applied to @xmath145 and @xmath146 for the basis pursuit , while the proposed method works well for small @xmath143 .",
    "this is because the basis pursuit does not fully utilize the information of the alphabet ( i.e. , the basis pursuit only uses the information of the value @xmath11 through the sparsity ) .",
    "we also note that the basis pursuit can be used only when the alphabet includes @xmath11 , while the proposed method works as well when @xmath11 is not an element of the alphabet . fig .",
    "[ fig : error ] also implies a conjecture that the performance of the proposed method converges that of the basis pursuit as the size of the alphabet goes to infinity .",
    "next , we see an example from image processing .",
    "let us consider a binary ( or black - and - white ) image shown in fig .",
    "[ fig : original_a ] ( left ) , which is a @xmath154-pixel binary - valued image .",
    "we add random gaussian noise with a mean of 0 and a standard deviation of @xmath155 to each pixel to obtain a disturbed image as shown in fig .",
    "[ fig : original_a ] ( right ) .",
    "we represent this disturbed image as a real - valued matrix @xmath156 .",
    "then we apply the discrete fourier transform ( dft ) to @xmath157 to obtain @xmath158 where @xmath159 is the dft matrix defined by @xmath160 where @xmath161 and @xmath162 .",
    "the relation can be equivalently represented by @xmath163 we then randomly down - sample the vector @xmath164 to obtain a half - sized vector @xmath165 .",
    "the measurement matrix @xmath20 is then a @xmath166 matrix generated by randomly down - sampling row vectors from @xmath167 .",
    "[ fig : reconstruction_a ] shows the reconstructed images by the basis pursuit with rounding off ( left ) and by the proposed method ( right ) . for the proposed method",
    ", we assumed @xmath168 .",
    "the results clearly show the effectiveness of our method also for image reconstruction .",
    "in this letter , we have proposed a reconstruction method for discrete signals based on the sum of absolute values ( or the weighted @xmath1 norm ) .",
    "the reconstruction algorithm is described as linear programming , which can be solved effectively by numerical optimization softwares .",
    "examples have been shown that the proposed method is much more effective than the basis pursuit which only uses the information of sparsity .",
    "future work includes an accessible condition that ensures the null space property , as the restricted isometry property in compressed sensing .",
    "this research is supported in part by the jsps grant - in - aid for scientific research ( c ) no .  24560543 , grant - in - aid for scientific research on innovative areas no .  26120521 , and an okawa foundation research grant .",
    "y.  c. pati , r.  rezaiifar , and p.  s. krishnaprasad , `` orthogonal matching pursuit : recursive function approximation with applications to wavelet decomposition , '' in _ proc .",
    "the 27th annual asilomar conf .  on signals , systems and computers _ ,",
    "1993 , pp .",
    "4044 .",
    "b.  knoop , f.  monsees , c.  bockelmann , d.  peters - drolshagen , s.  paul , and a.  dekorsy , `` compressed sensing k - best detection for sparse multi - user communications , '' in _ proc .",
    "22nd european signal processing conference ( eusipco ) _ , sep .",
    "2014 .",
    " , `` graph implementations for nonsmooth convex programs , '' in _ recent advances in learning and control _ , ser .",
    "lecture notes in control and information sciences , v.  blondel , s.  boyd , and h.  kimura , eds.1em plus 0.5em minus 0.4emspringer , 2008 , vol .",
    "371 , pp . 95110"
  ],
  "abstract_text": [
    "<S> in this letter , we consider a problem of reconstructing an unknown discrete signal taking values in a finite alphabet from incomplete linear measurements . </S>",
    "<S> the difficulty of this problem is that the computational complexity of the reconstruction is exponential as it is . to overcome this difficulty , we extend the idea of compressed sensing , and propose to solve the problem by minimizing the sum of weighted absolute values . </S>",
    "<S> we assume that the probability distribution defined on an alphabet is known , and formulate the reconstruction problem as linear programming . </S>",
    "<S> examples are shown to illustrate that the proposed method is effective .    </S>",
    "<S> shell : bare demo of ieeetran.cls for journals    discrete signal reconstruction , sum of absolute values , digital signals , compressed sensing , sparse optimization . </S>"
  ]
}