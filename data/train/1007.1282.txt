{
  "article_text": [
    "we begin with a quote of the first part of the open problem 12.6 from vidyasagar s book @xcite ( this problem appears already in the original 1997 version ) .",
    "_  how can one reconcile the fact that in distribution - free learning , every learnable concept class is also `` polynomially '' learnable , whereas this might not be so in fixed - distribution learning ? _    in the case of distribution - free learning of concept classes ( ... ) there are only two possibilities :    \\1 .",
    "@xmath0 has infinite vc - dimension , in which case @xmath0 is not pac learnable at all .",
    "@xmath0 has finite vc - dimension , in which case @xmath0 is not only pac learnable , but the sample complexity @xmath1 is @xmath2 . let us call such a concept class `` polynomially learnable '' .    in other words , there is no `` intermediate '' possibility of a concept class being learnable , but having a sample complexity that is superpolynomial in @xmath3 .    in the case of fixed - distribution learning , the situation is not so clear .",
    "( ... ) is there a concept class for which _ every _ algorithm would require a superpolynomial number of samples ?",
    "the only known way of consructing such a concept class would be to ( ... ) attempt to construct a concept class whose @xmath4-covering number grows _",
    "faster _ than any exponential in @xmath3 .",
    "it would be interesting to know whether such a concept class exists .",
    "    in fact , the existence of a concept class whose sample complexity grows exponentially in @xmath3 under a given fixed input distribution was already shown in 1991 by benedek and itai @xcite ( theorem 3.5 ) .",
    "their example consisted of all finite subsets of a domain . later and independently ,",
    "a rather more natural concept class with such properties ( generated by a neural network ) was constructed by barbara hammer in her ph.d .",
    "thesis @xcite ( example 4.4.3 on page 77 ) , cf .",
    "also @xcite .    here",
    "we somewhat strengthen the above results and at the same time show that the phenomenon is quite common .",
    "suppose that a concept class @xmath0 satisfies a slightly stronger property than having an infinite vc dimension , namely : @xmath0 shatters every finite subset of an infinite set .",
    "fix a sequence @xmath5 of desired values of learning precision , converning to zero , and let @xmath6 be an increasing real function on @xmath7 .",
    "then one can find a probability measure @xmath8 on the domain @xmath9 of @xmath0 with the property that @xmath0 is pac learnable under @xmath8 , but the sample complexity of learning to precision @xmath5 , @xmath10 , is growing as @xmath11 .",
    "the prescribed rate of growth can be ridiculouly high , for instance , a non - recursive function .",
    "the bound is essentially tight .",
    "for example , a well - known sigmoidal feed - forward neural network of infinite vc dimension constructed by sontag @xcite has this property .",
    "this naturally brings up a question of behaviour of sontag s network @xmath12 under non - atomic input distributions .",
    "it follows from talagrand s theory of witness of irregularity @xcite that @xmath12 is not glivenko  cantelli with regard to any measure having a non - atomic part .",
    "we do not know if a similar property holds for pac learnability , although it is easy to see non - learnability of @xmath12 for some common measures ( the uniform distribution on the interval , the gaussian measure ) . while discussing a relationship between glivenko ",
    "cantelli property , pac learnability , and precompactness , we give an answer to another ( minor ) question of vidyasagar .",
    "note that we find it instructive to present the above observations in the reverse order . in conclusion",
    ", we suggest a few open problems and a conjecture supported by the results of this note which might shed light on vidyasagar s problem .",
    "benedek and itai @xcite had proved that a concept class @xmath0 is pac learnable under a single probability distribution @xmath8 if and only if @xmath0 is totally bounded in the @xmath13-distance . here",
    "we remind their results .",
    "[ th : suf ] suppose @xmath0 is a concept class , @xmath14 , and that @xmath15 is an @xmath16-cover for @xmath0 . then the minimal empirical risk algorithm is pac to accuracy @xmath4 . in particular , the sample complexity of pac learning @xmath0 to accuracy @xmath4 with confidence @xmath17 is @xmath18    recall that a subset @xmath19 of a metric space @xmath20 is _ @xmath4-separated _ , or _",
    "@xmath4-discrete , _ if , whenever @xmath21 and @xmath22 , one has @xmath23 .",
    "the largest cardinality of an @xmath4-discrete subset of @xmath20 is the _ @xmath4-packing number _ of @xmath20 .",
    "for example , the following lemma estimates from below the packing number of the hamming cube .    [ l:2e ]",
    "let @xmath24 .",
    "the hamming cube @xmath25 , equipped with the normalized hamming distance @xmath26 admits a family of elements which are pairwise at a distance of at least @xmath27 from each other of cardinality at least @xmath28 $ ] .    the following is a source of lower bounds on the sample complexity .",
    "[ th : nec ] suppose @xmath0 is a given concept class , and let @xmath14 be specified .",
    "then any algorithm that is pac to accuracy @xmath4 requires at least @xmath29 samples , where @xmath30 denotes the @xmath27-packing number of the concept class @xmath0 with regard to the @xmath13-distance .    for the most comprehensive presentation of pac learnability under a single distribution ,",
    "see @xcite , ch .",
    "6 .      a function class @xmath31 on a domain ( a standard borel space ) @xmath9 is _ glivenko  cantelli _ with regard to a probability distribution @xmath8 ( @xcite , ch .",
    "3 ) , or else has the property of _ uniform convergence of empirical means _ ( _ ucem _ property ) @xcite , if for each @xmath14 @xmath32 here @xmath33 is the product measure on @xmath34 , and @xmath35 stands for the empirical ( uniform ) measure on @xmath36 points , sampled from the domain in an i.i.d .",
    "we assume @xmath31 to assume values in an interval ( i.e. , to be uniformly bounded ) .",
    "the notion applies to neural networks as well , if @xmath31 denotes the family of output functions corresponding to all possible values of learning parameters .",
    "every glivenko ",
    "cantelli class @xmath31 is pac learnable , which explains the important role of this notion . in fact , every consistent learning rule @xmath37 will learn @xmath31 . we find it instructive to give a different proof , replying in passing to a remark of vidyasagar @xcite , p. 241 . after proving that every glivenko ",
    "cantelli concept class @xmath0 with regard to a fixed measure @xmath8 is precompact with regard to the @xmath13-distance , the author remarks that his proof is both indirect ( glivenko  cantelli @xmath38 pac learnable @xmath38 precompact ) , and does not extend to function classes , so it is not known to the author whether the result holds if @xmath0 is replaced with a function class @xmath31 .",
    "the answer is yes , as is ( implicitely ) stated in @xcite ( p. 379",
    ", the beginning of the proof of proposition 2.5 ) , but a deduction is also rather roundabout ( proving first the absence of a witness of irregularity ) .",
    "in fact , the result is really very simple .",
    "every ( uniformly bounded ) glivenko  cantelli function class @xmath31 with regard to a fixed probabillty measure @xmath8 is precompact in the @xmath13-distance .",
    "if @xmath31 is not precompact , then for some @xmath39 it contains an infinite @xmath40-discrete subfamily @xmath41 . for every finite sample @xmath42",
    "there is a further infinite subfamily @xmath43 of functions whose restrictions to @xmath44 are at a pairwise @xmath45-distance @xmath46 from each other ( the pigeonhole principle coupled with the fact that the restriction of @xmath31 to @xmath44 is @xmath45-precompact ) .",
    "this means that @xmath8- and @xmath35-expectations of some function of the form @xmath47 , @xmath48 , @xmath49 , differ between themselves by at least @xmath50 , and for at least one of @xmath51 , @xmath52 ( an application of the triangle inequality in @xmath53 ) . since the latter is true for _ every _ sample , no matter the size , @xmath31 is not glivenko  cantelli .    in fact",
    ", the same proof works in a slightly more general case when @xmath31 is uniformly bounded by a single function ( not necessarily integrable ) .",
    "this gives an alternative deduction of the implication _ glivenko  cantelli _ @xmath38 _ pac learnability_. admittedly , the result obtained is somewhat weaker , as this way we do not get _ consistent _ learnability .",
    "talagrand @xcite had characterized uniform glivenko  cantelli function classes with regard to a single distribution in terms of shattering .",
    "we will remind his main result for concept classes only .",
    "let @xmath9 be a measurable space , let @xmath0 be a concept class on @xmath9 , and let @xmath8 be a probability measure on @xmath9 .",
    "a measurable subset @xmath54 is a _ witness of irregularity _ of @xmath0 , if @xmath55 and for every @xmath36 the set of all @xmath36-tuples of elements of @xmath19 shattered by @xmath0 has full measure in @xmath56 .",
    "in other words , @xmath8-almost all @xmath36-tuples of elements of @xmath19 are shattered by @xmath0 .",
    "[ th : talagrand ] a concept class @xmath0 is glivenko ",
    "cantelli with regard to the probability measure @xmath8 if and only if @xmath0 admits no witness of irregulaity .",
    "let @xmath8 be a probability measure on @xmath9 . recall that a set @xmath19 is an _ atom _ if for every measurable @xmath57 one has either @xmath58 or @xmath59 .",
    "the measure @xmath8 is _ non - atomic _ if it contains no atoms , and _ purely atomic _ if the measures of atoms add up to one .",
    "the restriction of @xmath8 to the union of atoms is the _ atomic part _ of @xmath8 .",
    "since a witness of irregularity can contain no atoms , the following is an immediate corollary of talagrand s 1987 result .",
    "[ c : pa ] if a measure @xmath8 is purely atomic , then every concept class @xmath0 is uniform glivenko ",
    "cantelli with regard to @xmath8 , and in particular pac learnable .",
    "the corollary is easy to prove directly , without using subtle results of talagrand , and the result was observed ( independently ) in 1991 and investigated in detail by benedek and itai ( @xcite , theorem 3.2 ) .",
    "notice that the result does not assert _ polynomial _ pac learnability of @xmath0 , and we will see shortly that the required sample complexity of @xmath0 can grow arbitrarily fast .      [ 0.3 ] with @xmath60 ( bottom).,title=\"fig : \" ] [ 0.55 ] with @xmath60 ( bottom).,title=\"fig : \" ]    figure [ fig : sontag ] recalls a well - known example of a sigmoidal neural network @xmath12 constructed by sontag @xcite , pp",
    "also @xcite , page 389 , where the top diagram in figure [ fig : sontag ] is borrowed from . )",
    "the activation sigmoid is of the form @xmath61 where @xmath62 is fixed , e.g. @xmath60 .",
    "and the output - layer perceptron has both input weights equal to one and a threshold of one .",
    "the input - output function of the network is given by @xmath63,\\ ] ] where @xmath64 the input space of @xmath12 is the space @xmath53 of real numbers .",
    "[ 0.55 ] for @xmath60 and @xmath65 ( top ) and the corresponding output binary function ( bottom).,title=\"fig : \" ] [ 0.55 ] for @xmath60 and @xmath65 ( top ) and the corresponding output binary function ( bottom).,title=\"fig : \" ]    recall that a collection @xmath66 of real numbers is _ rationally independent _ if no non - trivial linear combination of @xmath67 with rational coefficients vanishes .",
    "[ th : ratind ] the sontag network @xmath12 shatters every rationally independent @xmath36-tuple of real inputs @xmath66 .",
    "in particular , the vc dimension of sontag s network is infinite . besides",
    ", it is easy to find an infinite rationally independent set , and so every finite subset of such a set is shattered by @xmath12 .",
    "we will need this fact later .",
    "here is another extreme property of sontag s network .",
    "[ th : sontaggc ] the neural network of sontag @xmath12 is glivenko ",
    "cantelli under a probability distribution @xmath8 on the inputs if and only if @xmath8 is purely atomic .",
    "sufficiency @xmath68 follows from corollary [ c : pa ] .",
    "let us prove necessity @xmath69 .",
    "by splitting @xmath8 into a purely atomic part @xmath70 and a continuous part @xmath71 , in view of theorems [ th : talagrand ] of talagrand and [ th : ratind ] of sontag , it suffices to prove that for every non - atomic probability measure @xmath72 on @xmath53 the set of rationally independent @xmath36-tuples has a full @xmath73 measure in @xmath74 : the support of @xmath75 will then be a witness of irregularity . in its turn",
    ", this reduces to a proof that for a fixed collection @xmath76 of rationals not all of which are zero , the affine hyperplane @xmath77 where @xmath78 , has @xmath73-measure null .",
    "this is a consequence of eggleston s theorem @xcite : if @xmath19 is a measurable , lebesgue - positive subset of the unit square , then there is a measurable positive set @xmath79 and a perfect set @xmath80 such that @xmath81 is included in @xmath19 .",
    "`` lebesgue measure on the unit square '' here is not a loss of generality , as every two non - atomic standard borel probability measure spaces are isomorphic , and we obtain by induction that if @xmath82 and @xmath83 , then @xmath19 contains a product of @xmath36 sets one of which is @xmath73-measure positive and all the rest are perfect ( contain no isolated points ) .",
    "clearly , no @xmath84-hyperplane in @xmath74 can have this property .",
    "sontag s ann is not pac learnable under the uniform distribution on an interval .",
    "indeed , for the sequence of learning parameters @xmath85 the corresponding output binary functions are at a pairwise @xmath86-distance @xmath87 from each other , where @xmath88 is a uniform distribution on some interval .",
    "a similar argument works for the gaussian distribution on the inputs .",
    "however , we do not know if there exists a non - atomic measure under which sontag s ann is pac learnable .      not every pac learnable function , or even concept , class is glivenko  cantelli .",
    "examples of such concept classes exist trivially , e.g. the concept class consisting of all finite and all cofinite subsets of the unit intervals is pac learnable under every non - atomic distribution , yet clearly not uniform glivenko  cantelli , cf .",
    "@xcite , p. 385 , note ( 2 ) , or @xcite , p. 230",
    ", example 6.4 . a more interesting example , though based on the same idea , is example 6.6 in @xcite , p. 232 . here",
    "we present such an example of a countable concept class .    for @xmath89 ,",
    "say that intervals @xmath90 $ ] , @xmath91 , are of order @xmath36 .",
    "let @xmath92 consist of all unions of less than @xmath93 intervals of order @xmath36 , and set @xmath94 .",
    "if now @xmath95 is any and @xmath96 are points of the unit interval , choose @xmath97 so that @xmath98 is smaller than any of the half - distances between neighbouring points @xmath99 , @xmath100 .",
    "clearly , elements of @xmath101 shatter the sample @xmath102 , and so the entire interval is a witness of irregularity for the concept class @xmath0 . by talagrand s result , the class @xmath0 is not glivenko  cantelli . at the same time , for every @xmath36 , @xmath101 forms an @xmath103-net for @xmath0 with regard to the @xmath86-distance , and so @xmath0 is pac learnable under the lebesgue measure @xmath88 ( the uniform measure on the interval ) .",
    "observe that , in fact , @xmath0 fails the glivenko ",
    "cantelli property with regard to _ every _ measure having a non - atomic part .",
    "as we have seen , there exist non - atomic measures under which @xmath0 is pac learnable .",
    "there are also measures under which @xmath0 is not pac learnable .",
    "for example the haar measure @xmath72 on the cantor set .",
    "recall the construction of the cantor `` middle third '' set @xmath104 ( figure [ fig : cantor ] ) .",
    "this is the set left of the closed unit interval @xmath105 $ ] after first deleting the middle third @xmath106 , then deleting the middle thirds of the two remaining intervals , @xmath107 and @xmath108 , and continuing to delete the middle thirds _ ad infimum_. the elements of the cantor set are exactly those real numbers between @xmath109 and @xmath110 admitting a ternary expansion not containing @xmath110 . sometimes @xmath104 is called _",
    "cantor dust_. the complement to the cantor set is a union of countably many open intervals , all the middle thirds left out .",
    "the set @xmath111 left after the first @xmath36 steps of removing the middle thirds is the union of @xmath112 closed intervals of equal length @xmath113 each .",
    "the haar measure of every such interval is set to be equal to @xmath114 , and this condition defines a non - atomic measure @xmath72 supported on @xmath104 in a unique way .    [ 0.275 ] steps.,title=\"fig : \" ]    it is easy to see now that the closed intervals @xmath115 at the level @xmath36 are shattered with concept classes from @xmath116 if @xmath117 is large enough ( @xmath118 ) , in the following sense : for every set of indices @xmath119 there is a @xmath120 which contains every interval @xmath121 , @xmath122 , and is disjoint from every interval @xmath123 , where @xmath124 .",
    "now one can modify the proof of lemma [ l:2e ] exactly as it was done in @xcite , proof of theorem 3 , in order to conclude that @xmath0 is not totally bounded in the @xmath125-distance .",
    "[ th : main ] let @xmath0 be a concept class which shatters every finite subset of some infinite set .",
    "let @xmath126 , @xmath127 be a sequence of positive reals converging to zero , and let @xmath128 be a non - decreasing function growing at least linearly : @xmath129 .",
    "then there is a probability measure @xmath130 on the input domain @xmath9 with the property that for every @xmath131 and @xmath95 the class @xmath0 is pac learnable under the distribution @xmath8 to accuracy @xmath5 , and the rate of required sample complexity is at least @xmath132 moreover , the above estimate is essentially tight in the sense that the sample complexity @xmath133 suffices to learn @xmath0 to accuracy @xmath134 with confidence @xmath17 .",
    "we can assume without loss in generality that @xmath135 .",
    "for every @xmath136 , set @xmath137 .",
    "then @xmath138 form a sequence of non - negative reals which sums up to one .",
    "denote , for simplicity , @xmath139 .",
    "further , choose pairwise disjoint finite sets @xmath140 of cardinality @xmath141 ( where @xmath142 ) in a way that every union of finitely many of @xmath140 s is shattered by @xmath0 ( this is possible due to the assumption on the class @xmath0 ) .",
    "let @xmath143 denote a uniform measure supported on @xmath140 of total mass @xmath138 .",
    "now set @xmath144 . since @xmath145",
    ", @xmath8 is a probability borel measure .",
    "let @xmath136 be arbitrary .",
    "select any subset of @xmath0 shattering @xmath146 and containing @xmath147 elements .",
    "this set forms a finite @xmath5-net in @xmath0 with regard to the @xmath13-distance . since @xmath127",
    ", we use theorem [ th : suf ] to conclude : the class @xmath0 is pac learnable under @xmath8 , and the sample complexity of learning @xmath0 to accuracy @xmath5 and confidence @xmath17 , @xmath131 is @xmath148    for every @xmath136 , lemma [ l:2e ] , applied with @xmath149 , guarantees the existence of a subset @xmath150 of @xmath0 every two elements of which are at a @xmath151-distance @xmath152 from each other , and containing @xmath153 $ ] elements .",
    "let @xmath117 be so large that @xmath154 .",
    "fix @xmath136 .",
    "since @xmath155 is shattered by @xmath0 , one can find elements of @xmath0 which correspond to elements of the product @xmath156 , and every two of which are at a distance @xmath157 from each other . according to theorem [ th : nec",
    "] , this means that the computational complexity of learning @xmath0 under @xmath8 to accuracy @xmath5 with confidence @xmath17 is at least @xmath158 samples .",
    "the measure @xmath8 constructed in the proof is purely atomic .",
    "however , by replacing the domain @xmath9 with @xmath159 $ ] , every concept @xmath160 with @xmath161 $ ] , and @xmath8 with the product @xmath162 , where @xmath88 is the uniform ( lebesgue ) measure on the interval , one can `` translate '' every example as above into an example of learning under a non - atomic probability distribution .",
    "[ c : mu ] let @xmath72 be a probability distribution on a domain @xmath9 having infinite support .",
    "then there exist concept classes @xmath0 which are pac learnable under @xmath72 and whose required sample complexity is arbitrarily high .    the measure space @xmath163 admits a measure - preserving map @xmath164 to the measure space constructed in the proof of theorem [ th : main ] in such a way that @xmath165 ( here one uses the fact that @xmath8 is purely atomic ) .",
    "now the concept class @xmath166 , consisting of all sets @xmath167 , has the same learning properties under the distribution @xmath72 as the class @xmath0 has under @xmath8 .",
    "[ c : sontag ] let @xmath127 be a sequence of positive values converging to zero , and let @xmath168 be a real function on @xmath7 growing at least linearly .",
    "then there is a probability distribution @xmath8 on the real numbers under which sontag s network @xmath12 is pac learnable to accuracy @xmath5 with confidence @xmath17 , requiring the sample of size @xmath11 .",
    "this estimate is essentially tight , because the sample size @xmath169 already suffices to train @xmath12 to accuracy @xmath134 with confidence @xmath17 .",
    "[ r : easy ] it is easy to construct concept classes which are pac learnable under _ every _ input distribution , and yet exhibit all possible rates of learning sample complexity .",
    "these are the classes @xmath0 which , speaking informally , can not tell a difference between a given probability distribution @xmath8 and some purely atomic measure @xmath72 . more precisely , if the sigma - algebra of sets generated by @xmath0 is purely atomic and @xmath0 shatters every finite subset of an infinite set , then @xmath0 will have the above property .",
    "an example is a class @xmath0 that consists of all finite unions of middle thirds of the cantor set @xmath104 .",
    "the atoms of the sigma - algebra of sets generated by this class are precisely the middle thirds , and so @xmath0 has the desired property .",
    "stimulated by a question embedded into the problem 12.6 of vidyasagar @xcite , we have shown that all rates of sample compleixity growth are possible for distribution - dependent learning , in particular all are realized by binary output feed - forward sigmoidal neural network of sontag .",
    "now vidyasagar continues thus :     _ `` i would like to have an `` intrinsic '' explanation as to why in distribution - free learning , every learnable concept class is also forced to be polynomially learnable .",
    "next , how far can one `` push '' this line of argument ?",
    "suppose @xmath170 is a family of probabilities that contains a ball in the total variation metric @xmath171 . from theorem 8.8",
    "it follows that every concept class that is learnable with respect to @xmath170 must also be polynomially learnable ( because @xmath0 must have finite vc - dimension ) .",
    "is it possible to identify other such classes of probabilities ? '' _",
    "we suggest the following conjecture , which , in our view , is the right framework in which to address vidyasagar s question .    _ conjecture _ ( _ `` the sample complexity alternative '' _ ) .",
    "let @xmath170 be a family of probability distributions on the domain @xmath9 .",
    "then either every class learnable under @xmath170 is learnable with sample complexity @xmath172 , or else there exist pac learnable classes under @xmath170 whose required sample complexity grows arbitrarily fast .",
    "the classical vc theory tells that the conjecture is true if @xmath170 is the family of all probability measures : namely , the first alternative holds always . in view of corollary",
    "[ c : mu ] , the conjecture is also true in the other extreme case , where @xmath173 contains a single distribution : unless @xmath8 is finitely - supported , we have the second alternative .    _ problem 1 .",
    "_ does the above alternative hold for every family @xmath170 of probability distributions on the inputs ?",
    "_ problem 2 .",
    "_ does there exist a non - atomic probability measure on @xmath53 under which the sontag ann is pac learnable ?",
    "_ problem 3 .",
    "_ give a criterion for a concept class to be pac learnable under a fixed probability distribution in terms of shattering .",
    "some sufficient conditions can be found in @xcite , but none of them is also necessary . the `` right '' condition will be strictly intermediate between the witness of irregularity @xcite and the vc dimension modulo countable sets @xcite .",
    "the author is grateful to the anonymous referees , in particular for pointing out the references @xcite , and to ilijas farah for pointing out the reference @xcite ."
  ],
  "abstract_text": [
    "<S> we show that the learning sample complexity of a sigmoidal neural network constructed by sontag ( 1992 ) required to achieve a given misclassification error under a fixed purely atomic distribution can grow arbitrarily fast : for any prescribed rate of growth there is an input distribution having this rate as the sample complexity , and the bound is asymptotically tight . </S>",
    "<S> the rate can be superexponential , a non - recursive function , etc . </S>",
    "<S> we further observe that sontag s ann is not glivenko  cantelli under any input distribution having a non - atomic part .    </S>",
    "<S> pac learnability , fixed distribution learning , sample complexity , infinite vc dimension , witness of irregularity , sontag s ann , precompactness . </S>"
  ]
}