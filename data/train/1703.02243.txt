{
  "article_text": [
    "symmetry is pervasive in visual objects , both in nature creatures like trees and birds , and artificial objects like aircrafts and oil pipes in aerial images .",
    "symmetric parts and their connections constitute a powerful part - based decomposition of shapes @xcite , providing valuable cue for the task of object recognition . with symmetry constrained",
    ", the performance of image segmentation @xcite , foreground extraction @xcite , object proposal @xcite , and text - line detection @xcite could be significantly improved .",
    "the early symmetry detection , named skeleton extraction , usually involves only binary images @xcite . in recent years",
    ", symmetry detection tends to process color images @xcite , but still limited to cropped image patches with little background .",
    "this limitation is partially due to the lack of fundamental benchmarks , considering that most existing symmetry detection datasets , , symmax @xcite , wh - symmax @xcite , and sk506 @xcite , lack either object - level annotation or the in - the - wild settings , , multi - objects , part - invisibility , and various complex backgrounds .",
    "[ figure1 ]    in this paper , we present a new challenging benchmark with complex backgrounds , and an end - to - end deep symmetry detection approach that processes in - the - wild images , and target at opening up a promising direction for practical applications of symmetry .",
    "the new benchmark , named sym - pascal , is composed of 1453 natural images with 1742 objects derived from the pascal - voc-2011 @xcite segmentation dataset . such a benchmark is more close to practical applications with challenges far beyond those in existing datasets : ( 1 ) _ diversity of objects _ : multi - class objects with different illuminations and viewpoints ; ( 2 ) _ multi - object co - occurrence _ :",
    "multiple objects exist in a single image ; ( 3 ) _ part - invisibility _ : objects are partially occluded ; and ( 4 ) _ complex backgrounds _ : the scenes where object located could be contextually cluttered .    for the in - the - wild symmetry detection problem",
    ", we explore the deep side - output residual network ( srn ) that directly outputs response image about object symmetry .",
    "srn roots in the holistically - nested edge detection ( he d ) network @xcite but updates it by stacking multiple residual units ( rus ) on the side - outputs .",
    "the residual unit ( ru ) is designed to fit the error between the object symmetry ground - truth and the outputs of rus , which is computationally easier as it pursuits the minimization of residuals among scales rather than only struggles to combine multi - scale features to fit the object symmetry ground - truth .",
    "the ru we defined not only significantly improves the performance of srn , but also solves the learning convergence problem left by the baseline he d method . by stacking multiple rus in a deep - to - shallow manner , the receptive fields of stacked rus could adaptively match the scale of symmetry .",
    "the contributions of this paper include :    a new object symmetry benchmark that spans challenges of diversity , multi - objects , part - invisibility , and various complex backgrounds , promoting the symmetry detection research to in - the - wild scenes .    a side - output residual network that can effectively fit the errors between ground - truth and the outputs of the stacked rus , enforcing the modeling capability to symmetry in complex backgrounds , achieving state - of - the - art symmetry detection performance in the wild .",
    "for the applicability and beauty , symmetry has attracted much attention in the past decade .",
    "the targets of symmetry detection evolute from binary images to color object images , while the symmetry detection approaches update from hand - crafted to learning based .",
    "* benchmarks : * in the early research , symmetry extraction algorithms are qualitatively evaluated on quite limited binary shapes @xcite .",
    "such shapes are selected from the mpeg-7 shape-1 dataset for subjective observation @xcite .",
    "later , liu @xcite use very a few real - world images to perform symmetry detection competitions . to be honest",
    ", symmax @xcite could be regarded as an authentic benchmark that contains hundreds of training / testing images with local symmetry annotation .",
    "but the local reflection symmetry it defined mainly focuses on low - level image edges and contours , missing the high - level concept of objects .",
    "wh - symmax @xcite and sk506 @xcite are recently proposed benchmarks with annotation of object skeletons .",
    "nevertheless , wh - symmax is simply composed of side - view horses while sk506 consists objects with little background .",
    "neither of them involves multiple objects in complex backgrounds , leaving a plenty of room for developing new object symmetry benchmarks .",
    "* methods : * early symmetry detection methods , also named skeleton extraction @xcite , are mainly developed for the binary images by leveraging morphological image operations .",
    "when processing color images , they usually need a contour extraction or an image segmentation step as pre - processing . considering that segmentation of in -",
    "the - wild images remains a research problem , the integration of color image segmentation and symmetry detection not only increases the complexity but also accumulates the errors .",
    "researchers have tried to extract symmetry in color images based on multi - scale super - pixels .",
    "one hypothesis is that the object symmetry axes are the subsets of lines connecting the center points of super - pixels @xcite .",
    "such line subsets are explored from the super - pixels using a sequence of deformable disc models extracting the symmetry pathes @xcite .",
    "their consistence and smoothness are enforced with spatial filters , e.g. , a particle filter , which link local skeleton segments into continuous curves @xcite . due to the lack of object prior and the learning module , however , these methods are still limited to handle the images with simple backgrounds .",
    "more effective symmetry detection approaches root in powerful learning methods . on the symmax benchmark",
    ", the multiple instance learning ( mil ) @xcite is used to train a curve symmetry detector with multi - scale and multi - orientation features . to capture diversity of symmetry patterns , teo @xcite employ the structured random forest ( srf ) and shen @xcite use subspace mil with the same feature . nevertheless , as the pixel - wise hand - craft feature is computationally expensive and representation limited , these methods are intractable to detect object symmetry in complex backgrounds .",
    "most recently , a deep learning approach , fusing scale - associated deep side - outputs ( fsds ) @xcite , is shown to be capable of learning unprecedentedly effective object skeleton representations on wh - symmax @xcite and sk506 @xcite .",
    "fsds takes the architecture of he d @xcite and supervises its side - outputs with scale - associated ground - truth . despite of its state - of - the - art performance",
    ", it needs the intensive annotations of the scales for each skeleton point , which means that it uses much more human effort than other approaches when preparing the training data .",
    "compared with fsds , our proposed srn can adaptively match the scales of symmetry , without using scale - level annotation .",
    "symmetry annotation involves pixel - level fine details , and is time consuming .",
    "we thus leverage the semantic segmentation ground - truth and a skeleton generation algorithm to aid the annotation of symmetry @xcite .",
    "0.153     0.163     0.153     [ figure3 ]      sym - pascal is derived from the pascal - voc-2011 segmentation dataset @xcite which contains 1112 training images and 1111 testing images from 20 object classes including : person , bird , cat , cow , dog , horse , sheep , aero plane , bicycle , boat , bus , car , motorbike , train , bottle , chair , dining table , potted plant , sofa , and tv / monitor .",
    "we categorize the 20 classes of objects into symmetry - available and symmetry - unavailable , fig .",
    "[ figure3 ] .",
    "the objects that contain lots of discontinuous parts in the segmentation masks are symmetry - unavailable , specifically potted plant , dining table , motorbike , bicycle , chair and sofa , are not selected , fig .  [ figure3a ] .",
    "the other 14 object classes are symmetry - available . some of objects are slender and thus easy to annotate , fig .",
    "[ figure3b ] , and others with small length - width ratio or occlusion are difficult to annotate , fig .",
    "[ figure3c ] . in total ,",
    "648/787 images are selected and annotated from the pascal - voc-2011 training and testing sets . among these images ,",
    "31.3% are with multi - object and 45.6% are with part - invisibility .    for the images where object symmetry is obvious , ,",
    "objects are composed of slender parts that are easy to annotate , we directly extract symmetry on the object segmentation masks using a skeleton extraction algorithm @xcite , fig .",
    "[ figure3b ] . for such objects ,",
    "the object symmetry ( marked with blue curves ) and their skeleton ( marked with red curves ) are consistent . for the images where object symmetry is not obvious",
    ", we manually extend the semantic segmentation masks and annotate symmetry on them , fig .",
    "[ figure3c ] . for wide object as shown on the top of fig .",
    "[ figure3c ] , we extend the mask along the direction of the long axis of the object and choose the long axis as ground - truth . for occluded objects as shown at the bottom of fig .",
    "[ figure3c ] , we need to manually fill the missed parts of segmentation masks . for the pictures that contain partial objects , we empirically imagine the occluded parts to extend the segmentation masks . with these processing above",
    ", the skeleton extraction algorithm @xcite is used to extract symmetry on the object segmentation masks .",
    "the object symmetry ground - truth is set as the skeleton points within the segmentation masks , shown as the blue curves in fig .",
    "[ figure3c ] .    0.24     0.23     [ b ]    l0.15|c0.17c0.14c0.11c0.17 & & wh- & & sym- + & & symmax & & pascal + data & local & object & object & object + type & symmetry & skeleton & skeleton & symmetry + image & in - the - wild & simple & simple & in - the - wild + type & image & image & image & image + # object &  & 1 & 16 & 14 + # training & 200 & 228 & 300 & 648 + # testing & 100 & 100 & 206 & 787 +    0.49     0.49       in what follows , we compare the proposed benchmark with three other representative ones , symmax @xcite , wh - symmax @xcite , and sk506 @xcite .",
    "symmax is derived from bsds300 @xcite , which contains 200/100 training and testing images .",
    "it s annotated with local reflection symmetry on both foreground and background .",
    "considering that most computer vision tasks focus on the foreground , it s more meaningful to use object symmetry instead of the symmetry about the whole image .",
    "wh - symmax is developed for object skeletons , but it is made up of only cropped horse images , which are not comprehensive for general object symmetry .",
    "sk506 involves skeletons about 16 classes of objects",
    ". nevertheless , their backgrounds are too simple to represent in - the - wild images .    as shown in tab .",
    "[ tab-1 ] .",
    "the proposed benchmark involves more training and testing images .",
    "particularly , these images involve complex backgrounds , multiple objects and/or occlusions .",
    "it is developed for end - to - end object symmetry in - the - wild , providing the protocol to evaluate whether or not an algorithm can detect symmetry without using additional object detectors . in sym - pascal ,",
    "the images for each class are more balanced than other datasets , fig .",
    "[ figure4b ] , except that the number of human objects is larger than others .",
    "in contrast , in sk506 the objects from different classes have more unbalance , fig .",
    "[ figure4a ] .",
    "the proposed side - output residual network ( srn ) roots in the well - designed output residual unit ( ru ) and a deep - to - shallow learning strategy .",
    "given the symmetry ground - truth , the srn is learned in an end - to - end manner .      given training images , the end - to - end symmetry learning pursuits deep network parameters that best fit the symmetry ground - truth .",
    "such a learning objective is different from that of learning a classification network @xcite .",
    "the ru defined for output , fig .",
    "[ figure5 ] , is essentially different from that in the residual network defined for features @xcite . with the deep supervision both on the input and output of rus ,",
    "the residual of the ground - truth is computed .",
    "formally , denoting the input of ru as @xmath0 and the additional mapping as @xmath1 , the deep supervision is written as : @xmath2 where @xmath0 and @xmath3 are the input and output of the ru , respectively .",
    "@xmath1 is regarded as the residual estimation of @xmath4 .",
    "rus provide shortcut connections between the ground - truth and outputs from different scales , which implies a functional module for the ` flow ' of errors among different scales , and thus make it easier to fit complex outputs with higher adaptivity . to the extreme , if an input @xmath0 is optimal , it would be easier to push the residual to zero than to fit the additional mapping @xmath1",
    ".     estimates the residual of @xmath4 . ]",
    "[ figure5 ]      by stacking the rus defined , we implement a kind of new side - output deep network , named side - output residual network ( srn ) , which incorporates the advantages of both the scale adaptability and residual learning .",
    "for srn , the input of the first ru can be chosen as the shallowest side - output or deepest side - output , which derives two versions of srn , fig .",
    "[ figure6 ] . in",
    "what follows , the ru is numbered as the side - output ( sop ) index , and the output of the @xmath5 ru is denoted as @xmath6 , for short .",
    "* deep - to - shallow . * in this srn architecture , rus are stacked from deep to shallow , fig .",
    "[ figure6a ] .",
    "assume that @xmath7 is the @xmath8-th side - output , and @xmath9 are the input and output of @xmath8-th ru respectively .",
    "for the first stacked ru2 , the input is set as the deepest sop3 , , @xmath10 .",
    "and sop2 is used to learn the residual between ruop3 and the ground - truth , which updates ruop3 to ruop2 .",
    "the rus are stacked in order until the shallowest side - output , in other words , the inputs of which are set as the output of the former one .",
    "sigmoid is used as classifier on the output of the last stacked ru to generate the final output image .    the implementation of ru in the deep - to - shallow architecture is shown in fig .  [ figure7a ] .",
    "it s noting that the output size of ru in this architecture is same as the side - output rather than the input image .",
    "therefore , a gaussian deconvolution layer is introduced to the output of ru .",
    "as the up - sampling is non - linear transformation , a weight layer is stacked to improve the scale adaptability . instead of adding up - sampled @xmath11 and @xmath12 directly ,",
    "a @xmath13 convolutional layer is utilized to generate @xmath14 .",
    "the ru is formulated , @xmath15 where @xmath16 are the convolutional weights of concatenation layer and the up - sampled @xmath11 . with eqs .",
    "( [ eq1 ] ) and ( [ eq2 ] ) , the output residual @xmath17 is computed , @xmath18 when @xmath19 approximates 1.0 , the residual is related to only the side - output . to the extreme , along the stacking orientation of rus , the residual @xmath1 approximates 0.0 .",
    "as we know , the deep layers of cnns contain features that ignore the image details but capture high - level representations .",
    "therefore , a deep layer sop3 is expected to be closer to the optimal training solution .",
    "ru2 pushes the residual to zero and the response map ruop2 is similar with the response map ruop3 . in the deep - to - shallow architecture , the deepest side - output",
    "is used as a good initialization for the ground - truth , therefore , the deep - to - shallow architecture contributes better results than the shallow - to - deep one , as shown in sec .",
    "[ srn - setting ] .",
    "0.20 -th ru.,title=\"fig : \" ]    0.20 -th ru.,title=\"fig : \" ]    * shallow - to - deep .",
    "* the architecture is shown in fig .",
    "[ figure6b ] and the ru in fig .",
    "[ figure7b ] .",
    "the side - outputs are up - sampled by the gaussian deconvolution layer so that their size is consistent with the input image .",
    "similar with eq .",
    "( [ eq3 ] ) , the residual is computed , @xmath20 where @xmath21 is weight parameter of the up - sampled @xmath7 .",
    "[ figure6b ] indicates that the shallowest ruop1 has lots of false positive pixels compare to ground - truth as sop1 represents local structure of the input image . along the stacking orientation",
    ", the ru3 reduces the residual so that the outputs of ru3 , , ruop3 , are closer to ground - truth compared to ruop2 .",
    "given the object symmetry detection training dataset @xmath22 with @xmath23 training pairs , where @xmath24 and @xmath25 are the input image and the ground - truth binary image with @xmath26 pixels , respectively .",
    "@xmath27 denotes the symmetry pixel and @xmath28 denotes non - symmetry pixel .",
    "we subsequently drop the subscript @xmath29 for notational simplicity , since we consider each image independently .",
    "we denote @xmath30 as the parameters of the base network . supposing the network has @xmath31 side - outputs , the @xmath31-th side - output is set as the basic output and @xmath32 rus are used .",
    "we use the architecture of fig .",
    "[ figure6a ] as example , in which @xmath33 and ruop3 is the basic output .",
    "[ figure6b ] has similar formulation . for the basic output ,",
    "the loss is computed , @xmath34 where @xmath35 is the classifier parameter for the basic output . @xmath36 and @xmath37 respectively denote the symmetry and non - symmetry ground - truth label sets .",
    "the loss weight @xmath38 , and @xmath39 and @xmath40 denote the symmetry and non - symmetry pixel number , respectively",
    ". @xmath41 $ ] is the sigmoid prediction of the basic output that measures how likely the point to be on the symmetry axis . for the @xmath8-th ru , @xmath42 , the loss is computed , @xmath43 where @xmath44 is the convolutional parameter of the concatenation layers and side - output layers after the @xmath8-th ru .",
    "@xmath45 is the classifier parameter for the output of @xmath8-th ru .",
    "the loss function for all the stacked rus is obtained by @xmath46 finally , we obtain the optimal parameters , @xmath47    in the testing phase , giving an image @xmath48 , a symmetry prediction map is output by the last stacked ru , @xmath49      the proposed srn has significant difference with other end - to - end deep learning implementations , , he d @xcite , fsds @xcite , and laplacian reconstruction @xcite . in he",
    "d , the deep supervision is applied on side - outputs directly , while in srn the deep supervision is applied on the outputs of rus . according to ( [ eq2 ] ) , each ru contains the information of two side - outputs at least , endowing srn with the capability to smoothly model the multi - scale symmetry across deep layers .",
    "fsds is an improvement of he d that specifies scales for side - outputs , which requires additional annotation for each scale .",
    "in contrast , srn models the scale information with rus , without any multi - scale annotations .",
    "srn takes the idea of laplacian reconstruction that uses a mask to indicate the reconstruction residual for segmentation .",
    "the difference lies in that srn pursuits scale adaptability while the laplacian reconstruction focuses on multi - scale error minimization .",
    "the proposed srn is first evaluated and compared on the proposed sym - pascal benchmark .",
    "it is then evaluated and compared with the state - of - the - art deep learning approaches on other popular datasets including symmax @xcite , wh - symmax @xcite , and sk506 @xcite",
    ".      * implementation details . *",
    "the srn is implemented following the parameter setting of he d @xcite , by fine - tuning the pre - trained 16-layer vgg net @xcite . the hyper - parameters of srn include : mini - batch size ( 1 ) , learning rate ( 1e-8 for in - the - wild image datasets and 1e-6 for simple image datasets ) , loss - weight for each ru output ( 1 ) , momentum ( 0.9 ) , and initialization of the nested filters ( 0 ) , weight decay ( 0.002 ) , and maximum number of training iterations ( 18,000 ) . in the testing phase , a non - maximal suppression ( nms ) algorithm @xcite is applied on the output map to obtain object symmetry .",
    "* evaluation metrics . * the precision - recall metric with f - measure",
    "is used to evaluate the performance of symmetry detection , as introduced in @xcite . to obtain the precision - recall curves ,",
    "the detected symmetry response is first thresholded into a binary map , and then matched with the ground - truth symmetry masks . by changing the threshold value , the precision - recall curve is obtained and the best f - measure is computed .",
    ".performance of srn under different settings on the sym - pascal benchmark . [ cols=\"^,^,^,^\",options=\"header \" , ]          the performances on other three symmetry datasets are shown in fig .",
    "[ figure11 ] and tab .  [ tab - compare - other ] .",
    "similar with sym - pascal , the deep learning based methods get significantly better performance on all the datasets , especially for the simple image datasets , wh - symmax and sk506 .",
    "compared with the baseline he d , the proposed srn improves the f - measure from 0.427 to 0.446 , 0.732 to 0.780 , 0.542 to 0.632 on symmax , wh - symmax and sk506 , respectively .      the learning convergence of the baseline he d and the proposed srn is shown in fig .  [ figure10 ] .",
    "it can be clearly seen that he d has a problem of slow convergence during learning , despite the fact that it achieves good performance on the edge and symmetry detection tasks .",
    "the reason could be that the complex backgrounds of input images seriously interrupt the end - to - end ( image - to - mask ) learning procedure .",
    "benefits from the output residual fitting , the loss curve of the proposed srn tends to converge , fig .",
    "[ figure10 ] .",
    "in addition , he d needs 12k learning iterations to get the best performance while srn needs only 3k iterations to get the same performance .",
    "symmetry detection has great applicability in computer vision yet remains not being well solved , as indicated by the low performance ( often lower than 50% ) of the state - of - the - art methods . in this work ,",
    "we release a new object symmetry benchmark , as well as propose the side - output residual network , establishing a strong baseline for object symmetry detection in the wild .",
    "the new benchmark , with challenges related to real - world images , is validated to be a good touchstone of various state - of - the - art approaches . the proposed side - output residual network , with well - defined and stacked residual units ,",
    "is validated to be more effective to perform symmetry detection in complex backgrounds . with the adaptability to object scales , the robustness to complex backgrounds , and the end - to - end learning architecture",
    ", the side - output residual network has great potential to process a class of end - to - end ( image - to - mask ) computer vision tasks .",
    "this work is partially supported by nsfc under grant 61671427 , beijing municipal science and technology commission under grant z161100001616005 , and science and technology innovation foundation of chinese academy of sciences under grant cxjj-16q218 .",
    "tekes , academy of finland and infotech oulu are also gratefully acknowledged ."
  ],
  "abstract_text": [
    "<S> in this paper , we establish a baseline for object symmetry detection in complex backgrounds by presenting a new benchmark and an end - to - end deep learning approach , opening up a promising direction for symmetry detection in the wild . </S>",
    "<S> the new benchmark , named sym - pascal , spans challenges including object diversity , multi - objects , part - invisibility , and various complex backgrounds that are far beyond those in existing datasets . the proposed symmetry detection approach , named side - output residual network ( srn ) , leverages output residual units ( rus ) to fit the errors between the object symmetry ground - truth and the outputs of rus . by stacking rus in a deep - to - shallow manner , srn exploits the ` flow ' of errors among multiple scales to ease the problems of fitting complex outputs with limited layers , suppressing the complex backgrounds , and effectively matching object symmetry of different scales . </S>",
    "<S> experimental results validate both the benchmark and its challenging aspects related to real - world images , and the state - of - the - art performance of our symmetry detection approach . </S>",
    "<S> the benchmark and the code for srn are publicly available at https://github.com/kevinkecc/srn . </S>"
  ]
}