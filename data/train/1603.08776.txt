{
  "article_text": [
    "[ index : chaptertitle ]      based on [ index : id4 ] and [ index : id5 ] , we describe a comparatively simple experimental setup for _ black - box optimization benchmarking_. we recommend to use this procedure within the https://github.com/numbbo/coco[coco ] platform [ index : id6 ] .",
    "our * central measure of performance * , to which the experimental procedure is adapted , is the number of calls to the objective function to reach a certain solution quality ( function value or @xmath0-value or indicator value ) , also denoted as runtime .",
    "_ function _ : :    we talk about an objective _ function _ @xmath0 as a    parametrized mapping @xmath1 with    scalable input space , that is , @xmath2 is not ( yet )    determined , and usually @xmath3 .",
    "functions are    parametrized such that different _ instances _ of the `` same '' function    are available , e.g. translated or shifted versions . _ problem _ : :    we talk about a _ problem _ ,    http://numbbo.github.io/coco-doc/c/coco_8h.html#a408ba01b98c78bf5be3df36562d99478 [ ] ,    as a specific _ function instance _ on which the optimization algorithm    is run .",
    "specifically , a problem can be described as the triple .",
    "a    problem can be evaluated and returns an @xmath0-value or    -vector . in the context of performance assessment",
    ", a target    @xmath0- or indicator - value is attached to each problem .",
    "that    is , a target value is added to the above triple to define a single    problem in this case .",
    "_ runtime _ : :    we define _ runtime _ , or _",
    "run - length _ [ index : id8 ] as the _ number of    evaluations _ conducted on a given problem , also referred to as number    of _ function _ evaluations .",
    "our central performance measure is the    runtime until a given target value is hit [ index : id9 ] .",
    "_ suite _ : :    a test- or benchmark - suite is a collection of problems , typically    between twenty and a hundred , where the number of objectives    @xmath4 is fixed .",
    "the optimization algorithm to be benchmarked is run on each problem of the given test suite once . on each problem ,",
    "the very same algorithm with the same parameter setting , the same initialzation procedure , the same budget , the same termination and/or restart criteria etc . is used .",
    "there is no prescribed minimal or maximal allowed budget , the benchmarking setup is _ budget - free_. the longer the experiment , the more data are available to assess the performance accurately .",
    "see also section .",
    "_ input and output dimensions _",
    ": :    as a defining interface to the problem , specifically :    +    * the search space ( input ) dimension via    http://numbbo.github.io/coco-doc/c/coco_8h.html#a0dabf3e4f5630d08077530a1341f13ab [ ] ,    * the number of objectives via    http://numbbo.github.io/coco-doc/c/coco_8h.html#ab0d1fcc7f592c283f1e67cde2afeb60a [ ] ,    which is the `` output '' dimension of    http://numbbo.github.io/coco-doc/c/coco_8h.html#aabbc02b57084ab069c37e1c27426b95c [ ] .",
    "all functions of a single benchmark suite have the same number of    objectives , currently either one or two .    *",
    "the number of constraints via    http://numbbo.github.io/coco-doc/c/coco_8h.html#ad5c7b0889170a105671a14c8383fbb22 [ ] ,    which is the `` output '' dimension of    http://numbbo.github.io/coco-doc/c/coco_8h.html#ab5cce904e394349ec1be1bcdc35967fa [ ] .    _",
    "all _ problems of a single benchmark suite have either no constraints ,    or one or more constraints .",
    "_ search domain of interest _ : :    defined from    http://numbbo.github.io/coco-doc/c/coco_8h.html#a29c89e039494ae8b4f8e520cba1eb154 [ ]    and    http://numbbo.github.io/coco-doc/c/coco_8h.html#a4ea6c067adfa866b0179329fe9b7c458 [ ] .",
    "the optimum ( or each extremal solution of the pareto set ) lies within    the search domain of interest .",
    "if the optimizer operates on a bounded    domain only , the domain of interest can be interpreted as lower and    upper bounds . _ feasible ( initial ) solution _ : :    provided by    http://numbbo.github.io/coco-doc/c/coco_8h.html#ac5a44845acfadd7c5cccb9900a566b32 [ ] .",
    "the initial state of the optimization algorithm and its parameters shall only be based on these input values .",
    "the initial algorithm setting is considered as part of the algorithm and must therefore follow the same procedure for all problems of the suite .",
    "the problem identifier or the positioning of the problem in the suite or any ( other ) known characteristics of the problem are not allowed as input to the algorithm , see also section .      1 .   the result , i.e. , the @xmath0-value(s ) from evaluating the problem at a given search point via http://numbbo.github.io/coco-doc/c/coco_8h.html#aabbc02b57084ab069c37e1c27426b95c [ ] .",
    "the result from evaluating the constraints of the problem at a given search point via http://numbbo.github.io/coco-doc/c/coco_8h.html#ab5cce904e394349ec1be1bcdc35967fa [ ] .",
    "the result of http://numbbo.github.io/coco-doc/c/coco_8h.html#a1164d85fd641ca48046b943344ae9069 [ ] , which can be used to terminate a run conclusively without changing the performance assessment in any way .",
    "currently , if the number of objectives @xmath5 , this function returns always zero .",
    "[ index : budget - termination - criteria - and - restarts ] algorithms and/or setups with any budget of function evaluations are eligible , the benchmarking setup is _ budget - free_. we consider termination criteria to be part of the benchmarked algorithm .",
    "the choice of termination is a relevant part of the algorithm . on the one hand , allowing a larger number of function evaluations increases the chance to find solutions with better quality . on the other hand , a timely termination of stagnating runs",
    "can improve the performance , as these evaluations can be used more effectively .    to exploit a large(r ) number of function evaluations effectively",
    ", we encourage to use * independent restarts * , in particular for algorithms which terminate naturally within a comparatively small budget .",
    "independent restarts are a natural way to approach difficult optimization problems and do not change the central performance measure used in https://github.com/numbbo/coco[coco ] ( hence it is budget - free ) , however , independent restarts improve the reliability , comparability , precision , and `` visibility '' of the measured results .    moreover , any * multistart procedure * ( which relies on an interim termination of the algorithm ) is encouraged .",
    "multistarts may not be independent as they can feature a parameter sweep ( e.g. , increasing population size [ index : id15 ] [ index : id16 ] ) , can be based on the outcome of the previous starts , and/or feature a systematic change of the initial conditions for the algorithm .",
    "after a multistart procedure has been established , a recommended procedure is to use a budget proportional to the dimension , @xmath6 , and run repeated experiments with increase @xmath7 , e.g. like @xmath8 , which is a good compromise between availability of the latest results and computational overhead .",
    "an algorithm can be conclusively terminated if http://numbbo.github.io/coco-doc/c/coco_8h.html#a1164d85fd641ca48046b943344ae9069 [ ] returns 1 .",
    "this saves cpu cycles without affecting the performance assessment , because there is no target left to hit .",
    "[ index : parameter - setting - and - tuning - of - algorithms ] any tuning of algorithm parameters to the test suite should be described and _ the approximate overall number of tested parameter settings or algorithm variants and the approximate overall invested budget should be given_.    the only recommended tuning procedure is the verification that * termination conditions * of the algorithm are suited to the given testbed and , in case , tuning of termination parameters . too early or too late termination can be identified and adjusted comparatively easy .",
    "this is also a useful prerequisite for allowing restarts to become more effective .    on all functions",
    "the very same parameter setting must be used ( which might well depend on the dimensionality , see section ) .",
    "that means , the _ a priori _ use of function - dependent parameter settings is prohibited ( since 2012 ) .",
    "the function i d or any function characteristics ( like separability , multi - modality , ... ) can not be considered as input parameter to the algorithm .        in order to get a rough measurement of the time complexity of the algorithm ,",
    "the wall - clock or cpu time should be measured when running the algorithm on the benchmark suite .",
    "the chosen setup should reflect a `` realistic average scenario '' .",
    "the _ time divided by the number of function evaluations shall be presented separately for each dimension_. the chosen setup , coding language , compiler and computational architecture for conducting these experiments should be given ."
  ],
  "abstract_text": [
    "<S> we present a budget - free experimental setup and procedure for benchmarking numerical optimization algorithms in a black - box scenario . </S>",
    "<S> this procedure can be applied with the https://github.com/numbbo/coco[coco ] benchmarking platform . </S>",
    "<S> we describe initialization of and input to the algorithm and touch upon the relevance of termination and restarts .    </S>",
    "<S> [ index::doc ] </S>"
  ]
}