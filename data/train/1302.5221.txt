{
  "article_text": [
    "the classical model for modelling market dynamics , namely geometric brownian motion , was proposed by louis bacehelier @xcite .",
    "this model is still the accepted core model despite the fact that empirical studies revealed that its assumptions are not realistic .",
    "for example , since price movements are induced by transactions which can be unevenly distributed in real time , it would be more natural to use a time changed brownian motion to model price dynamics .",
    "if the time change is defined by a gamma process , we obtain the so - called vg ( shorthand for variance gamma ) process .",
    "vg processes reproduce a number of stylized facts of real price processes , such as fat tails and large kurtosis .",
    "it can be shown that the above time changed brownian process itself is a lvy process . extending the above construction novel price dynamics have been proposed by a variety of authors , called the geometric lvy processes obtained by exponentiating a lvy process .",
    "a lvy process @xmath0 is much like a wiener process : a process with stationary an independent increments , but discontinuities or jumps are allowed .",
    "a good survey paper on lvy processes used in financial modelling is the paper by miyahara and novikov , @xcite .",
    "@xcite studies several problems arising in the field of exponential lvy processes . for an excellent introduction to the theory of lvy processes see @xcite .",
    "a key building block in the theory of lvy processes is the compound poisson process .",
    "a more general class lvy process is formally obtained via @xmath1 where @xmath2 is a time - homogeneous , space - time poisson point process , counting the number of jumps of size @xmath3 at time @xmath4 . in this case",
    "@xmath5 is a pure jump process , which paradoxically means that the lvy - ito decomposition of @xmath5 does not have a brownian motion component ( but it may have a drift term ) .",
    "the intensity of @xmath2 is defined by @xmath6,$ ] which is due to time homogeneity can be written as @xmath7 = dt \\cdot \\nu(dx),\\ ] ] where @xmath8 is the lvy - measure .",
    "the above representation given in ( [ eq : levy_def ] ) is mathematically rigorous if @xmath9 under this condition the sample paths of @xmath5 are of _ finite variation _ , a property supported by empirical evidence for most indices as emphasized in @xcite .",
    "the characteristic function of a lvy process can be written in the form @xmath10 = e^{t \\psi(u)},\\ ] ] where @xmath11 is the characteristic exponent .",
    "the standard model of a price process within this framework is then @xmath12 and @xmath13 is called a geometric lvy process .",
    "a variety of choices for @xmath0 has been proposed in the literature : it can be a stable process , a variance gamma ( vg ) process , a tempered stable process , a special case of which is the ( cgmy ) process , a hypergeometric process or a normal - inverse gaussian ( nig ) process .",
    "the motivation behind these models is the assumption that the returns of the stock process , say @xmath14 are independent and stationary .",
    "while this is an attractive assumption , its consequences are less attractive .",
    "in particular it follows that the variance of the price process tends to infinity , which is certainly unnatural for , say , prices of agricultural products . a closer look at data in fact reveals that there is a weak correlation between daily returns @xmath15 for example , considering data on ibm coca cola stock prices in a period of 20 years from nov 1990 to nov 2010 we found for the correlation coefficients of daily log - returns @xmath16 that @xmath17 this small , but non - negligible , negative correlation calls for a refinement of the exponential lvy model , allowing memory in the daily return process .",
    "an intuitive empirical argument can also be given in favor of the need for memory : namely an overreaction of the market is generally followed by a correction , resulting in a correlation between daily returns .",
    "the recently much studied popular geometric fractional brownian motion model gives return process with non - independent increments , for more details on fractional brownian motion see papers of t.e .",
    "duncan , for example @xcite .",
    "we propose to introduce a new class of models , using the methodology of linear system theory , to capture the presence of decaying memory .",
    "the infinitesimal increments of the logarithm of the price process will be defined as a process @xmath18 which is the output of a finite dimensional stable linear siso ( shorthand for single - input - single - output ) system , driven by a lvy process : @xmath19 where @xmath20 represents the linear mapping from input to output , and @xmath21 is a lvy process . for the sake of convenience we let @xmath22 . in the case of a finite dimensional stable linear siso system",
    "the mapping @xmath20 can be described by a set of state - space equations , a well known example of such systems is defined by : @xmath23 from the above equations we get @xmath24    the inverse system is formally obtained as @xmath25 it is assumed that both systems @xmath20 and @xmath26 are exponentially stable , equivalently , we assume that both @xmath27 and @xmath28 are stable matrices .",
    "such a system will be called a lvy system .",
    "the inverse filter has the following form : @xmath29    having defined the infinitesimal increments of the logarithm of the price process we define the price process according to ( [ eq : expmodel ] ) : @xmath30 in the statistical analysis of such systems , both the system dynamics and the fine characteristics of @xmath0 are to be identified . the first difficulty of applying a maximum - likelihood ( ml ) method lies in the fact that there is no natural reference measure in the space of sample paths . in addition , the computation of the radon - nikodym derivative is practically not feasible since @xmath31 is not even a lvy process .",
    "to avoid this problem we consider an alternative discrete - time model class , where the daily log - returns @xmath32 are defined via a discrete time finite dimensional system @xmath33 where @xmath20 represents the linear mapping from input to output , and @xmath34 is the increment of a lvy process @xmath21 over an interval @xmath35 , with some fixed @xmath36 .",
    "for the sake of convenience we let @xmath37 .",
    "a state space equation for this model is given by @xmath38 we will call this model a discrete time finite dimensional lvy system . assume that @xmath39 where @xmath40 is an unknown parameter - vector , and similarly , let @xmath41 where @xmath42 denotes an unknown parameter - vector .",
    "the ranges of of @xmath40 and @xmath42 are assumed to be known .",
    "the fundamental problem to be discussed in this paper is to identify this system and to establish sharp results for the error of the estimator .",
    "if we knew the probability density function of the noise @xmath43 then we could apply an ml ( maximum likelihood ) estimation method , and establish sharp results for the estimation error , see @xcite .",
    "the challenge of the present problem is that it is the characteristic function of the noise that is explicitly given .",
    "a natural approach to solve this problem is to combine techniques of system identification with the empirical characteristic function ( ecf ) method widely used in finance to analyze i.i.d",
    ". data . before",
    "going into further details we present a few examples of lvy processes used in finance .",
    "to model the increments of the logarithm of a price process a wide range of geometric lvy processes has been proposed by a variety of authors .",
    "mandelbrot suggested to use @xmath44-stable process to model the price dynamics of wool , see @xcite .",
    "an @xmath44-stable with @xmath45 is defined via the lvy measure @xmath46 a recently widely studied class of lvy processes is the cgmy process due to carr , geman , madan and yor @xcite .",
    "it is obtained by setting @xmath47 , and then , separately for @xmath48 and @xmath49 , multiplying the lvy - density of the original symmetric stable process with a decreasing exponential .",
    "the corresponding lvy - measure , using standard parametrization , is of the form : @xmath50 where @xmath51 , and @xmath52 .",
    "intuitively , @xmath53 controls the level of activity , @xmath54 and @xmath55 together control skewness .",
    "typically @xmath56 reflecting the fact that prices tend to increase rather than decrease .",
    "@xmath57 controls the density of small jumps , i.e. the fine structure . for @xmath58",
    "the integrability condition ( [ eq : integrabiliy ] ) is satisfied , thus corresponding lvy process is of finite variation .",
    "the characteristic exponent of the cgmy process is given by @xmath59 where @xmath60 denotes the gamma - function .",
    "allowing @xmath53 and @xmath57 to take on different values for @xmath48 and @xmath49 we get a more general class of processes called tempered stable process .",
    "see cite .    formally setting @xmath61 we get the lvy density of the so - called variance gamma process ( vg for short ) that has been proposed by madan , carr and chang @xcite .",
    "the vg process is a time changed brownian motion when the time change is a gamma process , which itself is a lvy process , obtained by properly extending the definition of the inverse of a poisson process from natural numbers to positive reals .",
    "thus we can write @xmath62 where @xmath63 with @xmath64 being the standard wiener process , and @xmath65 is a gamma process with mean rate @xmath66 and variance rate @xmath67 , see @xcite .",
    "its characteristic function is given by @xmath68 this can be obtained by a formal limiting procedure taking into account the characteristic exponent given by ( 2.1 ) and taking @xmath69    the knowledge of the explicit form of the characteristic function is a common feature of distributions in finance .",
    "this is the case for tempered stable and related processes , see @xcite .",
    "we will focus on the cgmy process .",
    "a discrete time finite dimensional lvy system is defined as @xmath70 where @xmath34 is the increment of a lvy process @xmath21 over an interval @xmath35 with @xmath71=0,$ ] a property to be removed later and @xmath72 is a fix sampling interval .",
    "the lvy - measure of @xmath21 will be denoted by @xmath41 where @xmath42 denotes an unknown parameter - vector , for example for a cgmy process @xmath73 the range of @xmath42 is assumed to be known .",
    "* condition 1 * we assume that @xmath74 for all @xmath75 with some constant @xmath76 .",
    "note that condition 1 holds with @xmath77 in our benchmark examples .",
    "let @xmath78 and @xmath79 be compact domains such that @xmath80 and @xmath81    * condition 2 * @xmath82 is assumed to be exponentially stable and exponentially inverse stable for @xmath83 where @xmath84 is a known open set .",
    "a system is exponentially stable if all the eigenvalues of @xmath20 have strictly negative real parts .",
    "the application of the ml method would solve the full identification problem along standard lines , assuming that the density function of @xmath85 is known , see @xcite , which is unfortunately not the case .",
    "the objective of this paper is to present a combination of advanced techniques in systems identification with a specific statistical technique , widely used in the context in finance , called the ecf ( shorthand for empirical characteristic function ) method .",
    "the ecf method was originally designed for i.i.d .",
    "samples and a.  feuerverger and p.  mcdunnogh @xcite showed that it can be interpreted as the fourier transform of an ml method .",
    "in this section we formulate three identification problems related to discrete - time , finite dimensional lvy systems , and sketch a possible path to their solution .",
    "the first , simplest problem is seemingly of mere technical interest :    _ known system parameters , unknown noise parameters . _ in this case define and compute @xmath86 assuming , for the sake of simplicity , that @xmath87 for @xmath88 after that we can apply the ecf method for i.i.d . samples to obtain the estimation of @xmath89 this simple solution will be the base of the identification method presented in section [ sec : mixed ] .",
    "_ known noise parameters , unknown system parameters .",
    "_ this is the simplest , technically interesting and non - trivial problem . if we knew the probability density function of the noise ,",
    "say @xmath90 , we could obtain the maximum likelihood estimate of @xmath40 via solving @xmath91 where @xmath92 is the estimated innovation process of a siso system , see @xcite . under certain conditions the asymptotic covariance matrix of the ml estimate @xmath93 is @xmath94 where @xmath95,\\ ] ] with @xmath96 being the derivative of @xmath90 w.r.t the first variable and @xmath97.\\ ] ] in our case , the p.d.f",
    ". of the noise distribution is not known .",
    "one might apply the prediction error method to estimate the system dynamics , i.e. @xmath98 however , we will show , in the case of cgmy noise , that we may estimate @xmath40 in a more efficient way using an appropriate adaptation of the ecf method .",
    "in fact , this result is a special case of a more general result obtained for the general problem to be described in the next subsection .    _",
    "both the system parameters and the noise parameters are unknown . _ the first method that we propose is quite straightforward : we estimate the system parameters using a pe method , then , using a certainty equivalence argument , we estimate the innovation process by inverting the system using the estimated parameters . then , we estimate the noise parameters using ecf method for i.i.d . sequences .",
    "this method will be studied in section [ sec : mixed ] .    the second method , which is the main subject of this paper , estimates both the system parameters and noise parameters using an ecf method .",
    "first , an parameter - dependent , estimated innovation process @xmath99 is defined , then the characteristic function of the noise is fitted to empirical data defined in terms of @xmath99 .",
    "thus we get a score function that depends on both @xmath100 and @xmath101    the third method applies an extension of the ecf method using the blocks of the time - series of unprocessed data @xmath102 more details can be found in the discussion .",
    "the ecf method has been widely used in finance as an alternative to the ml method , assuming i.i.d .",
    "returns @xcite , @xcite , @xcite .",
    "we adapt this technique to the problem of identifying the discrete - time lvy system described in ( [ eq : disc_levy ] ) .",
    "fix a realization of @xmath20 in its innovation form , i.e. assume that @xmath20 and its inverse are exponentially stable . the estimated innovation process ( @xmath99 ) is defined via the inverse filter : @xmath103 for continuous time models . for discrete time lvy systems",
    "we define the innovation process by @xmath104 with zero initial conditions and @xmath105 let @xmath106 denote the stationary solution of ( [ eq : inverse ] ) when @xmath107 in general , the notation @xmath108 will be used throughout this paper if the corresponding stochastic process is obtained by passing through a stationary process through an exponentially stable linear filter starting at @xmath109 , as opposed to initializing the filter at time @xmath110 with some arbitrary initial condition , which is typically zero .",
    "then we have for @xmath111 @xmath112 where @xmath113 with some @xmath114 , meaning that for all @xmath115 @xmath116 we will use this notation in a more general way :    for a stochastic process @xmath117 and a function @xmath118 we say that @xmath119 if for all @xmath75 @xmath120 holds .",
    "the score functions to be used following the basic idea of the ecf method are defined as @xmath121 with @xmath122 these are indeed appropriate score functions , since we obviously have @xmath123=0,\\ ] ] and @xmath124 while @xmath125 is the function that can be computed in practice , @xmath126 is easier to handle , because its stationarity .",
    "following the philosophy of the ecf method take a fix set @xmath127-s , and define the @xmath128-dimensional vector @xmath129 let @xmath130 be a fixed symmetric , positve definite @xmath131 weighting matrix .",
    "since the system of equations @xmath132 is overdetermined we seek a least - square solution .",
    "therefore we define the cost functions as    @xmath133    @xmath134 and by solving @xmath135 we obtain the estimation @xmath93 and @xmath136 of @xmath40 and @xmath42 , respectively .",
    "differentiating @xmath137 w.r.t @xmath100 and @xmath138 we get the equations @xmath139 where @xmath140 is the conjugate of @xmath141 note that , setting @xmath142 , the second equation is just the optimality condition of the ecf method for i.i.d .",
    "samples @xcite . as for the first equation ,",
    "the derivative of the score function @xmath143 with respect to @xmath100 is @xmath144 hence in the first equation @xmath145 and @xmath146 are not independent .",
    "however , the next lemma shows that their stationary approximation , @xmath147 and @xmath148 are uncorrelated .",
    "[ lemma : exp ] for any @xmath138 we have @xmath149=0 $ ] , and in addition @xmath150=0.$ ]    consider the @xmath151 term in ( [ eq : q_der_1 ] ) .",
    "we have @xmath152 . \\ ] ] compute the @xmath153 term using the tower law : @xmath154= \\nonumber \\\\",
    "= \\mathbb{e } \\left [ \\mathbb{e } \\left [ \\left(e^{iu_l\\varepsilon^*_n(\\theta^ * ) } iu_l \\varepsilon^*_{n \\theta}(\\theta^*)\\right ) \\left(e^{-iu_m \\varepsilon^*_n ( \\theta^*)}-\\varphi(-u_m,\\eta)\\right)| \\mathscr{f}_{n-1}^{\\delta z}\\right]\\right ] , \\label{eq : e_calc2}\\end{aligned}\\ ] ] where @xmath155 here we used that @xmath156 due to the fact that @xmath157 is @xmath158 measurable , ( [ eq : e_calc2 ] ) can be written as @xmath159\\right]= \\\\ &",
    "\\mathbb{e } \\left [ iu_l \\varepsilon^*_{n \\theta}(\\theta^*)\\left(\\varphi(u_l - u_m,\\eta^*)-\\varphi(u_l,\\eta^*)\\varphi(-u_m,\\eta)\\right)\\right]= \\\\ & \\left(\\varphi(u_l - u_m,\\eta^*)-\\varphi(u_l,\\eta^*)\\varphi(-u_m,\\eta)\\right ) \\mathbb{e } \\left [ iu_l \\varepsilon^*_{n \\theta}(\\theta^*)\\right]=0 .",
    "\\end{split}\\ ] ] to reduce the last equation we used that @xmath71=0.$ ]    similarly for the @xmath151 term of ( [ eq : q_der_2 ] ) we have @xmath160 which is non - random implying that @xmath161=0.\\ ] ]    the previous lemma also shows that the gradient of @xmath162 serves as an alternative score function .",
    "the following corollary is implied by the fact that @xmath163=\\e\\left[h_{n\\theta}^{*t}(\\theta^*,\\eta)k^{-1}\\bar{h}^*_n(\\theta^*,\\eta)\\right]+o_m^q(\\alpha^n).\\ ] ]    for any @xmath138 we have @xmath164=o^{q}_m(\\alpha^n)$ ] , and in addition + @xmath165=o^{q}_m(\\alpha^n).$ ]    define @xmath166 and define the asymptotic cost function by @xmath167 * condition 3 * the equation @xmath168 has a unique solution in @xmath169    a crucial object is the hessian of @xmath64 at @xmath170 @xmath171 it is easy to see that @xmath172 is block diagonal matrix .",
    "the following result provides a precise characterization of the estimation error :    [ th : difference ] under conditions 1,2 and 3 we have @xmath173    first , we prove some lemmas that will be used in the proof of theorem [ th : difference ] . for the definition of @xmath174-mixing processes and for other corresponding definitions and theorems",
    "see the appendix .    under conditions",
    "1,2,3 processes @xmath175 and @xmath176 are @xmath174-mixing uniformly of order @xmath76 .",
    "first , note that since @xmath177 holds , @xmath32 is a linear combination of @xmath174-mixing processes of order @xmath178 using the fact that an uniformly exponentially stable filter with @xmath174-mixing input produces an uniformly @xmath174-mixing output @xcite we get that @xmath32 is @xmath174-mixing processes of order @xmath76 for each @xmath179 the innovation process and its derivatives with respect to @xmath100 can be written as @xmath180 again , since @xmath181 and its derivative with respect to @xmath100 are uniformly exponentially stable we conclude the lemma .",
    "suppose that conditions 1,2,3 hold .",
    "then for any given @xmath182 the equation @xmath183 has a unique solution in @xmath78 and it is in the sphere @xmath184 with probability at least @xmath185 for any @xmath186 furthermore the constant @xmath53 in @xmath187 depends only on @xmath188 and @xmath189    first , note that since @xmath190 and @xmath191 are @xmath174-mixing processes uniformly of order @xmath76 , the processes @xmath192 and @xmath193 are @xmath174-mixing uniformly of order @xmath194 as well .",
    "it follows that the process @xmath195 and its derivative with respect to @xmath196 are @xmath174-mixing uniformly of order @xmath194 .    @xmath197=0 $ ] implies @xmath198=o^{q/2}_m(\\alpha^n)$ ] uniformly in @xmath196 and hence following theorem [ thm : sup ] we have for @xmath199 @xmath200 and @xmath201 thus , @xmath202 with any @xmath203 by markov s inequality . applying the same argument yields @xmath204 for any @xmath205 and any @xmath206    suppose now that equation @xmath183 has a solution outside @xmath207 define @xmath208 since @xmath209 is continuous and @xmath78 is compact",
    "it follows that @xmath210 , and we have seen that this event has probability @xmath211 so for @xmath212 we have @xmath213 with any @xmath214 the equation @xmath215 has a unique solution in @xmath216 hence by using the implicit function theorem , see theorem [ thm : implicit ] , one can easily conclude that @xmath183 has a unique solution if @xmath217 and @xmath218 are sufficiently small .",
    "[ lemma : n-1/2 ] under conditions 1,2,3 we have @xmath219    we have @xmath220 where @xmath221 since @xmath222 for some @xmath223 , and with @xmath224 using the inequality in theorem [ thm : ineq ] with @xmath225 and @xmath226 from @xmath227 we conclude @xmath228",
    "let @xmath229 @xmath64 is a smooth function , hence @xmath230 clearly @xmath231 is positive definite , hence @xmath232 with some @xmath233 since on @xmath234    @xmath235 holds , choosing @xmath217 sufficiently small yields    @xmath236    on @xmath237 where @xmath238 denotes the smallest eigenvalue of @xmath239 thus @xmath240 on @xmath241 then using ( @xmath242 ) we get that    @xmath243 furthermore , since @xmath244 for any @xmath245 , the lemma follows .",
    "now we are ready to prove theorem [ th : difference ] .",
    "using the previous lemma one can improve ( @xmath246 ) : @xmath247 and after integration with respect to @xmath248 we get @xmath249 since @xmath250 , it implies @xmath251 hence by triangle inequality from ( @xmath252 ) and ( @xmath253 ) @xmath254 follows . from",
    "( [ eq : lambdamin ] ) and ( [ eq : dif3 ] ) we get @xmath255    finally , @xmath256 since @xmath257 for any @xmath258 from the last expression reads as @xmath259    the following theorem provides an explicit expression for the hessian of @xmath260    [ lemma : r * ] under conditions 1,2,3 we have @xmath261 i.e. @xmath262 is block diagonal , and here @xmath263,\\ ] ] with @xmath264 and @xmath265    first let @xmath266 then an entry @xmath267 of @xmath262 is @xmath268 \\end{split}\\ ] ] carrying out differentiation yields @xmath269 + \\\\&+ \\e \\bigg [ \\sum_{l , m=1}^k k^{-1}_{l , m } \\left(e^{i u_l \\varepsilon^{*}_n(\\theta^*)}(iu_l)~ \\varepsilon^{*}_{n \\theta_{j}}(\\theta^*)\\right)\\left(e^{-i u_m \\varepsilon^{*}_n(\\theta^*)}(-iu_m)~ \\varepsilon^{*}_{n \\theta_{j'}}(\\theta^*)\\right)+ \\\\ & + \\sum_{l , m=1}^k k^{-1}_{l , m } \\left(e^{i u_l \\varepsilon^{*}_n(\\theta^*)}(iu_l)~ \\varepsilon^{*}_{n \\theta_{j'}}(\\theta^*)\\right)\\left(e^{-i u_m \\varepsilon^{*}_n(\\theta^*)}(-iu_m)~ \\varepsilon^{*}_{n \\theta_{j}}(\\theta^*)\\right)+ \\bigg ] \\\\ & + \\e \\bigg[\\sum_{l , m=1}^k k^{-1}_{l , m } \\left(e^{i u_l \\varepsilon^*_n(\\theta^*)}-\\varphi(u_l,\\eta^*)\\right ) \\times \\\\ & \\left(e^{-i u_m \\varepsilon^{*}_n(\\theta^*)}(-iu_m)^2 \\varepsilon^{*}_{n \\theta_{j}}(\\theta^*)~\\varepsilon^{*}_{n \\theta_{j'}}(\\theta^*)+e^{-i u_m \\varepsilon^{*}_n(\\theta^*)}(-iu_m)~ \\varepsilon^{*}_{n \\theta_{j } \\theta_{j'}}(\\theta^*)\\right ) \\bigg]\\end{aligned}\\ ] ] now we use , like in the proof of lemma [ lemma : exp ] , the tower rule and that @xmath157 is @xmath158 measurable and that @xmath270=\\e \\left[\\varepsilon^{*}_{n \\theta_{j'}}(\\theta^*)\\right]=\\e \\left[\\varepsilon^{*}_{n \\theta_{j } \\theta_{j'}}(\\theta^*)\\right]=0.$ ] the previous formula reads as @xmath271 \\sum_{l , m=1}^k k^{-1}_{l , m } \\left(\\varphi(u_l - u_m,\\eta^*)-\\varphi(u_l,\\eta^*)\\varphi(-u_m,\\eta^*)\\right)(-u_l^2)+ \\\\ & 2 \\e\\left[\\varepsilon^{*}_{n \\theta_{j}}(\\theta^*)\\varepsilon^{*}_{n \\theta_{j'}}(\\theta^*)\\right ] \\sum_{l , m=1}^k k^{-1}_{l , m } \\varphi(u_l - u_m,\\eta^*)(u_l u_m )   + \\\\ & \\e\\left[\\varepsilon^{*}_{n \\theta_{j}}(\\theta^*)\\varepsilon^{*}_{n \\theta_{j'}}(\\theta^*)\\right ] \\sum_{l , m=1}^k k^{-1}_{l , m } \\left(\\varphi(u_l - u_m,\\eta^*)-\\varphi(u_l,\\eta^*)\\varphi(-u_m,\\eta^*)\\right)(-u_m^2)= \\\\ & \\e\\left[\\varepsilon^{*}_{n \\theta_{j}}(\\theta^*)\\varepsilon^{*}_{n \\theta_{j'}}(\\theta^*)\\right ] \\times \\\\ & \\sum_{l , m=1}^k k^{-1}_{l , m } \\left((u^2_l+u^2_m)\\varphi(u_l,\\eta^*)\\varphi(-u_m,\\eta^*)-(u_l - u_m)^2\\varphi(u_l - u_m,\\eta^*)\\right)\\end{aligned}\\ ] ] to double check the result note that the last formula gives real matrix since conjugation doest not modify the value of the double sum .    if @xmath272 then @xmath267 equals to @xmath273=0,\\end{aligned}\\ ] ] because the differentiation with respect to @xmath274 yields a non - random constant of the form @xmath275 and the differentiation with respect to @xmath276 yields the term @xmath277=0.$ ]    finally , if @xmath278 then @xmath267 equals to @xmath279=\\\\ & \\sum_{l , m=1}^k k^{-1}_{l , m } \\left(\\varphi_{\\eta_j}(u_l,\\eta^*)\\varphi_{\\eta_j'}(-u_m,\\eta^*)+\\varphi_{\\eta_j'}(u_l,\\eta^*)\\varphi_{\\eta_j}(-u_m,\\eta^*)\\right).\\end{aligned}\\ ] ] to sum it up , @xmath172 is block diagonal matrix , where @xmath280 \\times \\\\ & \\sum_{l , m=1}^k k^{-1}_{l , m } \\left((u^2_l+u^2_m)\\varphi(u_l,\\eta^*)\\varphi(-u_m,\\eta^*)-(u_l - u_m)^2\\varphi(u_l - u_m,\\eta^*)\\right),\\end{aligned}\\ ] ] and @xmath281    _ remark 1 _ : note that the expression for @xmath282 is identical to what we would obtained for i.i.d .",
    "samples following @xcite .    _",
    "remark 2 _ : since we have @xmath283 , the expression for @xmath284 yields a non - trivial inequality for characteristic functions .",
    "the next step in calculating the asymptotic covariance matrix of @xmath285 is the computation of @xmath286 . for this",
    "we need to introduce the following auxiliary function : @xmath287.\\end{aligned}\\ ] ]    [ lemma : cov_theta ] under conditions 1,2,3 we have @xmath288 where @xmath289,$ ] with @xmath290,\\end{aligned}\\ ] ] and @xmath291    the proof of the last theorem is a simple calculation like the previous one and the proof uses that @xmath292=\\e\\left[\\e\\left[\\varepsilon^*_{n \\theta_i}(\\theta^*)\\varepsilon^*_{m \\theta_i}(\\theta^*)| \\mathscr{f}_{n-1}^{\\delta z}\\right]\\right]=\\e\\left[\\varepsilon^*_{n \\theta_i}(\\theta^*)\\left[\\e\\left[\\varepsilon^*_{m \\theta_i}(\\theta^*)| \\mathscr{f}_{n-1}^{\\delta z}\\right]\\right]\\right]=0 $ ] for @xmath293 the proof follows the line of arguments for lemma [ lemma : exp ] .",
    "we note that calculations are considerably simplified if we take @xmath294 .",
    "note that both @xmath262 and @xmath295 are of the form @xmath296 where @xmath297 is the asymptotic covariance matrix for the prediction error method , see below ( @xmath298 ) , and @xmath299 is a constant .",
    "the last two theorems and theorem [ th : difference ] together gives an exact formula for the asymptotic covariance matrix of the estimator .",
    "[ th : as_cov ] under conditions 1,2 and 3 the asymptotic covariance matrix of the ecf estimator for @xmath40 can be written as @xmath300 where the @xmath301 and @xmath284 are given in theorems [ lemma : cov_theta ] and [ lemma : r * ] .",
    "in this section we estimate the dynamics in a natural way and then we estimate the noise parameters using the ecf method .",
    "we identify @xmath40 using only the orthogonality of @xmath302 by applying a prediction error method .",
    "this way we get an estimation @xmath303 of @xmath40 , without using the characteristic function of @xmath304 then we apply an ecf method with the score function @xmath305 to estimate @xmath89    first , we define the estimated innovation process as in the previous sections .",
    "the prediction error method is obtained by minimizing the cost function @xmath306 in practice the estimated @xmath93 is defined as the solution of @xmath307 the asymptotic cost function associated with the pe method is defined as    @xmath308 recall that @xmath106 is the innovation process that is calculated with stationary initial values .",
    "we have @xmath309.\\ ] ] the asymptotic covariance matrix of the pe estimate of @xmath40 is given by @xmath310\\right)^{-1}.\\ ] ] an ideal score function for the ecf method to estimate @xmath42 would be defined by @xmath311 since we are not given @xmath40 we define an alternative , @xmath100-dependent score function via @xmath312 these are appropriate score functions since @xmath313 = 0.$ ]    fix a set of real numbers @xmath314 , with @xmath315 and define @xmath316 then we obtain the estimate @xmath136 of @xmath42 by finding a least squares solution to the over - determined system of equations @xmath317 more precisely , define the @xmath100-dependent cost function @xmath318 where @xmath319 is a symmetric , positive definite weighting matrix . then we obtain the estimate @xmath136 of @xmath42 by minimizing @xmath320    define the ( @xmath100-dependent ) asymptotic cost function as    @xmath321 let its hessian w.r.t .",
    "@xmath138 at @xmath322 be denoted by @xmath323    to formulate our result we need some technical conditions .",
    "conditions 1 and 2 have been already presented in section [ sec : disc_levy ] .",
    "let @xmath196 be the joint parameter i.e. @xmath324 let @xmath78 and @xmath79 be compact domains such that @xmath80 and @xmath81    * condition 3 * the equations @xmath325 and @xmath326 have a unique solution in @xmath169    the following lemma , with minor variation , can be found in @xcite .    under conditions 1,2,3 we have",
    "@xmath327    our next result characterizes the estimation error of the ecf method for the noise parameter @xmath89    [ thm : mixed ] under conditions 1,2 and 3 we have @xmath328    the proof is obtained by the very same methods as theorem [ th : difference ] combined with the fact that @xmath329 which is implied by @xmath327 equation ( [ eq : dif4 ] ) and equations ( [ eq : dif1 ] ) , ( [ eq : dif2 ] ) together imply ( [ eq : dif3 ] ) .",
    "in view of the efficiency of the ecf method for i.i.d . samples the question arises what can be achieved by the proposed adaptation of the ecf method when identifying the dynamics of a linear stochastic system .",
    "we do not have an answer to this general question , but we will show that the commonly used pe method can be outperformed by an appropriately calibrated ecf method when the noise is cgmy . without loss of generality",
    "we may assume that @xmath330 surprisingly , we will see that the ecf method may outperform the pe method by using a single @xmath331 sufficiently close to @xmath110 .",
    "letting @xmath331 tend to 0 the asymptotic covariance of the ecf estimate tends to the asymptotic covariance of the pe estimate . on the other hand ,",
    "numerical investigations show that increasing the number of @xmath331-s used in the ecf method may not improve the efficiency significantly . for @xmath332",
    "the asymptotic covariance of @xmath93 obtained by the ecf method is @xmath333 , which reads as , using theorems [ lemma : cov_theta ] and [ lemma : r * ] , @xmath334\\right)^{-1}\\left(-\\frac{1}{4u^2}\\left(\\frac{\\varphi(2u)}{\\varphi^2(u)}+\\frac{\\varphi(-2u)}{\\varphi^2(-u)}-\\frac{2}{\\varphi(u)\\varphi(-u)}\\right)\\right ) .",
    "\\end{split}\\ ] ] recall that the asymptotic covariance of @xmath93 obtained by the pe method is @xmath335\\right)^{-1}.\\ ] ] thus the ecf estimator outperforms the pe estimator if @xmath336    for all @xmath337 , sufficiently close to @xmath110 we have @xmath338 , and thus the corresponding single - term ecf estimator of the system parameter @xmath40 , with @xmath332 , outperforms the pe estimator .",
    "first note that for @xmath339 @xmath340 holds , so @xmath341 is a real - valued function .",
    "let us compute the taylor expansion of @xmath341 around 0 .",
    "the first three derivatives of @xmath342 for a cgmy process with zero expectation are given by @xmath343=0 , \\\\",
    "\\nonumber \\varphi_{uu}(0)&=-\\e\\left[(\\delta z_n)^2\\right]= \\\\&=-c\\gamma(2-y)\\left(m^{y-2}+g^{y-2}\\right)=-1 , \\nonumber \\\\",
    "\\nonumber \\varphi_{uuu}(0)&=-i\\e\\left[(\\delta z_n)^3\\right]=0 . \\nonumber\\end{aligned}\\ ] ] after a lengthy computation , that we omit , we get that @xmath344 thus @xmath345 since @xmath346 and @xmath347 the coefficient of @xmath348 is negative . hence , by choosing @xmath331 sufficiently small @xmath349 can be achieved . @xmath350    numerical investigations show that for a cgmy process with parameters @xmath351 the minimal value of @xmath341 is approximately @xmath352 . we experienced that increasing the number of @xmath331-s that are used does not reduce @xmath353 significantly .",
    "for example , choosing @xmath354 and @xmath294 we get @xmath355",
    "in the previous section we assumed that @xmath356=0.$ ] this is a standard assumption in system identification , but certainly not realistic for financial data .",
    "thus e.g. in the case of a cgmy process this assumption would imply @xmath357 , excluding possible skewness in the distribution .",
    "while the case @xmath71=m^ * \\neq 0 $ ] would pose no problem for the case of i.i.d .",
    "data , surprisingly the single term ecf method may break down . the reason for this",
    "is that @xmath358 is no more a score function , since we can not guarantee that @xmath359=0\\ ] ] holds , see lemma [ lemma : exp ] .",
    "namely in the proof of lemma [ lemma : exp ] we make use of the equality @xmath360 = 0,\\ ] ] which may not be valid .",
    "note , however , that @xmath361 does have the property required for a score function , namely @xmath362 = 0.\\ ] ]    thus , using an instrumental variable approach , we may choose an appropriate linear combination of these score functions , say @xmath363 where @xmath55 is a @xmath364 matrix , and consider the equation : @xmath365 assuming that @xmath366 we may rightly expect that taking mathematical expectation the resulting equation has @xmath367 as an _ isolated _ solution , and we may proceed as in section 5 .",
    "the elaboration of the details is the subject of ongoing research .",
    "an alternative approach is to adapt our method of combining the pe method with the ecf method .",
    "for this we first need to extend the pe method to deal with the case @xmath368 which is a standard exercise .",
    "write @xmath369 where @xmath370=0.$ ] then equation ( [ eq : disc_levy ] ) reads as @xmath371 define the estimated innovation process by @xmath372 clearly @xmath373=m^*,$ ] thus we define the cost function via @xmath374 the estimate @xmath375 of @xmath376 is obtained by solving @xmath377 which can be written as @xmath378 having estimated the system dynamics with this extended pe method one may estimate the noise parameters with the ecf method , as in section @xmath379    the shortcoming of the above approach is that it does not exploit fully the potentials of the ecf method in estimating the system dynamics .",
    "therefore we suggest a second pass for estimating @xmath40 via a single term ecf method , with @xmath136 considered as the true parameter , applied to the system @xmath380 where @xmath381 are the first estimates .",
    "define @xmath382 and @xmath383 the previous equation reads as @xmath384 with @xmath385=0.$ ] thus we may proceed according to section @xmath386 to obtain the corrected estimate of @xmath98    what we have obtained is an extension of the single term ecf method , which is computationally simpler .",
    "ongoing investigations suggest that the efficiency of this generalized single term ecf method is as good as the original single term ecf when @xmath387    finally we mention one more very different approach to deal with the problem of non - zero expectation , having interest on its own .",
    "the idea is to use an ecf method directly for blocks of unprocessed data , i.e. for blocks of the time series @xmath388 for this purpose let us imbed our data into the class of time series @xmath389 note that for @xmath390 we recover ( in a statistical sense ) our observed data .",
    "fix a block length , say @xmath391 and define the @xmath392-dimensional blocks @xmath393 letting @xmath394 be an arbitrary @xmath392-vector the characteristic function of @xmath395 is given by @xmath396,\\ ] ] and the corresponding score function will be defined as @xmath397 the point is that the characteristic function can be explicitly computed , at least in theory , as @xmath398= \\\\ \\e \\left[\\exp \\left\\ { i\\sum_{j=1}^r u_j \\sum_{l=0}^{\\infty } h_l(\\theta ) \\delta z_{n+j-1-l}(\\eta)\\right\\}\\right]= \\\\ \\prod_{j=0}^{\\infty } \\varphi_{\\delta z(\\eta)}(v_j(\\theta ) ) , \\end{split}\\ ] ] with some @xmath100-dependent constants @xmath399",
    ". here @xmath400 denotes the characteristic function of @xmath401 the weakness of this approach is that the characteristic function @xmath402 is given in terms of an infinite product , therefore it is not clear how to use it in actual computations .",
    "let @xmath100 be a @xmath188-dimensional parameter vector .",
    "we say that a stochastic process @xmath409 is @xmath174-mixing of order @xmath76 with respect to @xmath410 uniformly in @xmath100 if it is @xmath411 progressively measurable , m - bounded of order @xmath76 with any positive @xmath392 and @xmath412\\right|^q,\\ ] ] we have for any @xmath413 @xmath414    [ thm : ineq ] let @xmath415 be an @xmath174-mixing process of order @xmath76 with @xmath416 for all @xmath417 and let @xmath418 be a deterministic sequence .",
    "then we have for all @xmath419 @xmath420 where @xmath421        now let us suppose that @xmath426 is measurable , separable , @xmath55-bounded of order @xmath76 and @xmath55-hlder of order @xmath76 in @xmath100 with exponent @xmath44 for @xmath427 the realizations of @xmath426 are continuous in @xmath100 almost surely hence @xmath428 is well defined for almost all @xmath429 where @xmath430 is a compact domain .",
    "since the realizations of @xmath426 are continuous , @xmath431 is measurable with respect to @xmath432    [ thm : moments ] assume that @xmath426 is measurable , separable , @xmath55-bounded of order @xmath76 and @xmath55-hlder of order @xmath76 in @xmath100 with exponent @xmath44 for @xmath427 then we have for all positive @xmath433 and @xmath434 @xmath435 where @xmath53 depends only on @xmath436 and @xmath437      [ thm : sup ] let @xmath439 be an @xmath174-mixing of order @xmath76 uniformly in @xmath440 such that @xmath441 for all @xmath442 and assume that @xmath443 is also @xmath174-mixing of order @xmath444 uniformly in @xmath445 then @xmath446    [ thm : implicit ] let @xmath447 and @xmath448 be as above .",
    "let @xmath449 be @xmath450-valued continuously differentiable functions , let for some @xmath451 and let @xmath452 be nonsingular .",
    "then for any @xmath182 there exists positive numbers @xmath453 such that @xmath454 for all @xmath455 implies that the equation @xmath456 has exactly one solution in a neighborhood of radius @xmath188 of @xmath98"
  ],
  "abstract_text": [
    "<S> lvy processes are widely used in financial mathematics to model return data . </S>",
    "<S> price processes are then defined as a corresponding geometric lvy process , implying the fact that returns are independent . in this paper </S>",
    "<S> we propose an alternative class of models allowing to describe dependence between return data . </S>",
    "<S> technically such an alternative model class is obtained by considering finite dimensional linear stochastic siso systems driven by a lvy process . in this paper </S>",
    "<S> we consider a discrete - time version of this model , focusing on the problem of identifying the dynamics and the noise characteristics of such a so - called lvy system . </S>",
    "<S> the special feature of this problem is that the characteristic function ( c.f . ) of the driving noise is explicitly known , possibly up to a few unknown parameters . </S>",
    "<S> we develop and analyze a variety of novel identification methods by adapting the so - called empirical characteristic function method ( ecf ) originally devised for estimating parameters of c.f .- s from i.i.d . </S>",
    "<S> . precise characterization of the errors of these estimators will be given , and their asymptotic covariance matrices will be obtained . their potential to outperform the prediction error method in estimating the system parameters will also be demonstrated . </S>"
  ]
}