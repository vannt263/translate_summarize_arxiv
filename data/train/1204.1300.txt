{
  "article_text": [
    "given a fundamental discriminant @xmath0 , it is known that the corresponding ideal class group @xmath1 of the order @xmath2 of discriminant @xmath0 in @xmath3 is a finite abelian group that can be decomposed as @xmath4 where the divisibility condition @xmath5 holds . in this paper",
    "we investigate improvements in the computation of the group structure of @xmath1 : that is , determining the @xmath6 , which is of both cryptographic and number theoretic interest .",
    "indeed some cryptographic protocols relying on the difficulty of solving the discrete logarithm problem ( dlp ) in imaginary quadratic orders have been proposed @xcite , and solving instances of the dlp is closely related to finding the group structure of @xmath1 .    in 1968",
    "shanks @xcite proposed an algorithm relying on the baby - step giant - step method in order to compute the structure of the ideal class group of an imaginary quadratic number field in time @xmath7 , or @xmath8 under the extended riemann hypothesis @xcite .",
    "this allows us to compute class groups of discriminants having up to 20 or 25 decimal digits .",
    "then a subexponential strategy was described in 1989 by hafner and mccurley @xcite .",
    "the expected running time of this method is @xmath9 buchman and dllmann @xcite computed class groups with discriminants of around 50 decimal digits using an implementation of this algorithm .",
    "an improvement of this method was published by jacobson in 1999 @xcite .",
    "he achieved a significant speed - up by using sieving strategies to generate the matrix of relations .",
    "he was able to compute the structure of class groups of discriminants having up to 90 decimal digits .",
    "more recently sutherland @xcite used generic methods in order to compute class groups with discriminants having 100 decimal digits . unlike the previous algorithms",
    ", this one relies heavily on the particular structure of @xmath1 thus obtaining variable performances depending on the values of @xmath0 .",
    "our approach is based on that of jacobson , using new techniques to accelerate both the sieving phase and the linear algebra phase ; we have obtained the group structure of class groups of 110 decimal digit discriminants .",
    "in this section we give essential results concerning the ideal class group and the subexponential strategies for computing its structure . for a more detailed description of the theory of ideal class groups",
    "we refer to @xcite and @xcite . in the following ,",
    "@xmath0 is a non - square integer congruent to 0 or 1 modulo 4 , and the quadratic order of discriminant @xmath0 is defined as the @xmath10-module @xmath11 we also denote by @xmath12 the field @xmath13 .",
    "elements of @xmath1 are obtained from fractional ideals of @xmath2 , which are @xmath10-modules of @xmath12 of the form : @xmath14 where @xmath15 and @xmath16 are integers with @xmath17 and @xmath18 is a rational number .",
    "the prime ideals are the fractional ideals for which there exists a prime number @xmath19 such that : @xmath20    let @xmath21 be the set of invertible fractional ideals of @xmath2 , and @xmath22 the subset of principal ideals .",
    "we define the ideal class group of @xmath0 as : @xmath23 where the group law is the one derived from the multiplication of @xmath10-modules .    for every @xmath24",
    ", there exist uniquely determined prime ideals @xmath25 and exponents @xmath26 in @xmath10 such that @xmath27 unlike @xmath21 , the ideal class group @xmath1 is a finite group .",
    "its order is called the class number and usually denoted by @xmath28 .",
    "it grows like @xmath29 , as shown in @xcite .",
    "the algorithm for computing the group structure of @xmath1 is divided into two major phases : relation collection and linear algebra . in the first phase ,",
    "we begin by precomputing a factor base @xmath30 of non - inert prime ideals satisfying @xmath31 , where @xmath32 is a smoothness bound",
    ". then we look for relations of the form @xmath33 where @xmath34 .",
    "every @xmath35-tuple @xmath36 $ ] collected becomes a row of what we will refer to as the relation matrix @xmath37 .",
    "we have from @xcite the following important result :    let @xmath38 be the lattice spanned by the set of the possible relations . assuming grh , if @xmath39 , then we have @xmath40    after the relation collection phase we can test if @xmath41 has full rank and if its rows generate @xmath38 using methods described in [ hnf_algo ] . if it is not the case then we have to compute more relations . from now on",
    "we assume that @xmath41 has full rank and that its rows generate @xmath38 .",
    "the linear algebra phase consists of computing the smith normal form ( snf ) of @xmath41 .",
    "any matrix @xmath41 in @xmath42 with non zero determinant can be written as @xmath43 , where @xmath44 for all @xmath45 and @xmath46 and @xmath47 are unimodular matrices in @xmath42 .",
    "the matrix @xmath48 is called the snf of @xmath41 .",
    "if @xmath49 and @xmath50 then @xmath51 this reduces the problem of computing the group structure of @xmath1 to computing the snf of a relation matrix @xmath41 in @xmath42 . for an arbitrary @xmath41 in @xmath52",
    "we start by computing the hermite normal form ( hnf ) of @xmath41 .",
    "a matrix @xmath53 is said to be in hnf if it has the shape @xmath54{c}{c.c }     \\begin{bmat}(e){cccc}{cccc } h_{1,1 } & 0       & \\hdots & 0",
    "\\\\ \\vdots & h_{2,2 } & \\ddots & \\vdots \\\\ \\vdots & \\vdots & \\ddots & 0       \\\\ *       & *       & \\hdots & h_{n , n }     \\end{bmat } \\\\ \\begin{bmat}[2pt,3cm,1cm]{c}{c }       ( 0 ) \\end{bmat } \\end{bmat }     \\right)\\ ] ] , where @xmath55 for all @xmath56 and @xmath57 for all @xmath58 . for each matrix @xmath41 in @xmath52",
    "there exists a matrix @xmath53 in hnf and a unimodular matrix @xmath59 in @xmath60 such that @xmath61 the upper block of @xmath53 is a @xmath62 relation matrix whose snf provides us the group structure of @xmath1 .",
    "there is an index @xmath63 such that @xmath64 for every @xmath65 .",
    "the upper left @xmath66 submatrix of @xmath53 is called the essential part of @xmath53 . in order to compute the group structure of @xmath1",
    "it suffices to compute the snf of the essential part of @xmath53 , which happens to have small dimension in our context .",
    "the use of sieving to create the relation matrix was first described by jacobson @xcite . here",
    "we follow the approach of @xcite chap.13 , which relies on the following lemma :    if @xmath67 with @xmath68 , then for all @xmath69 in @xmath10 there exists @xmath70 such that @xmath71 and @xmath72    the strategy for finding relations is the following : we start with @xmath73 whose norm is @xmath32-smooth .",
    "then we choose a sieve radius @xmath74 satisfying @xmath75 and we look for values of @xmath76 $ ] such that @xmath77 is @xmath32-smooth where @xmath78 which allows us to find @xmath79 satisfying @xmath80 for some @xmath81 in @xmath12 . the @xmath82 and @xmath83 are deduced from the decomposition @xmath84 . for more details",
    "we refer to @xcite , chap 13 .",
    "this method yields the relation @xmath85 now given a binary quadratic form @xmath86 of discriminant @xmath0 , we are interested in finding values of @xmath76 $ ] such that @xmath77 is @xmath32-smooth . this can be done trivially by testing all the possible values of @xmath87 , but there is a well - known method for pre - selecting some values of @xmath87 in @xmath88 $ ] that are going to be tested , namely the quadratic sieve ( introduced by pomerance @xcite ) .",
    "it consists in initializing to 0 an array @xmath89 of length @xmath90 and precomputing the roots @xmath91 and @xmath92 , or the double root @xmath91 , of @xmath93 for each @xmath94 such that @xmath95 .",
    "then for each @xmath87 in @xmath88 $ ] of the form @xmath96 for some @xmath97 , we add @xmath98 to @xmath99 $ ] . at the end of this procedure , if @xmath77 is @xmath32-smooth , then @xmath99\\approx\\log\\varphi(x,1)$ ] . as @xmath100",
    ", we set a bound @xmath101 where @xmath102 is a number representing the tolerance to rounding errors due to integer approximations .",
    "we then perform a trial division test on every @xmath77 such that @xmath99\\geq f$ ] .",
    "in this section we describe the improvements that allowed us to achieve a significant speed - up with respect to the existing algorithm and the computation of class group structures of large discriminants .",
    "our contribution is to take advantage of the large prime variants , of an algorithm due to vollmer @xcite for the snf which had not been implemented in the past , and of special gaussian elimination techniques .",
    "the large prime variants were developed in the context of integer factorization to speed up the relation collection phase in both the quadratic sieve and the number field sieve .",
    "jacobson considered analogous variants for class group computation @xcite , but the speed - up of the relation collection phase was achieved at the price of such a slow - down of the linear algebra that it did not significantly improve the overall time .",
    "the main idea is the following : we define the  small primes \" to be the prime ideals in the factor base and the small prime bound as the corresponding bound @xmath103 .",
    "then we define a large prime bound @xmath104 . during the relation collection phase",
    "we choose not to restrict ourselves to relations only involving primes @xmath105 in @xmath106 but we also keep relations of the form @xmath107 for @xmath82 in @xmath106 , and for @xmath108 of norm less than @xmath104",
    ". we will respectively refer to them as 1-partial relations and 2-partial relations .",
    "keeping partial relations only involving one large prime is the single large prime variant , whereas keeping two of them is the double large prime variant which was first described by lenstra and manasse @xcite . in this paper",
    "we do not consider the case of more large primes , but it is a possibility that has been studied in the context of factorization @xcite .",
    "partial relations may be identified as follows .",
    "let @xmath109 be the residue of @xmath77 after the division by all primes @xmath110 , and assume that @xmath111 .",
    "if @xmath112 then we have a full relation .",
    "if @xmath113 then we have a 1-partial relation .",
    "we can see here that detecting 1-partial relations is almost for free .",
    "if we also intend to collect 2-partial relations then we have to consider the following possibilities :    1 .",
    "@xmath114 ; 2 .",
    "@xmath109 is prime and @xmath115 ; 3 .",
    "@xmath116 ; 4 .",
    "@xmath109 is composite and @xmath117 .    in cases 1 and 2",
    "we discard the relation . in case 3",
    "we have a 1-partial relation , and in case 4 we have @xmath118 where @xmath119 and @xmath120 . after testing if we are in cases 1 , 2 , or 3 we have to factorize the residue .",
    "we have done that using milan s implementation of the squfof algorithm @xcite based on the theoretical work of @xcite .",
    "even though we might have to factor the residue , collecting a partial relation is much faster than collecting a full relation because the probability that @xmath121 is @xmath104-smooth is much greater than the probability that it is @xmath122-smooth .",
    "this improvement in the speed of the relation collection phase comes at a price : the number of columns in the relation matrix is much greater , thus preventing us from running the linear algebra phase directly on the resulting relation matrix and forcing us to find many more relations since we have to produce a full rank matrix .",
    "we will see in [ gauss ] how to reduce the dimensions of the relation matrix using gaussian elimination techniques and in [ opt ] how to optimize the parameters to make the creation of the relation matrix faster , even though there are many more relations to be found .",
    "traditionally rows were recombined to give full relations as follows : in the case of 1-partial relations , any pair of relations involving the same large prime @xmath105 were recombined into a full relation . in the case of 2-partial relations ,",
    "lenstra @xcite described the construction of a graph whose vertices were the relations and whose edges linked vertices having one large prime in common . finding independent cycles in this graph allows us to find recombinations of partial relations into full relations .    in this paper",
    "we rather follow the approach of cavallar @xcite , developed for the number field sieve , which uses gaussian elimination on columns without distinguishing those corresponding to the large primes from the others .",
    "one of the main differences between our relation matrices and the matrices produced in the number field sieve is that our entries are in @xmath10 rather than @xmath123 , thus obliging us to monitor the evolution of the size of the coefficients .",
    "indeed , eliminating columns at the price of an explosion of the size of the coefficients can be counter - productive in preparation for the hnf algorithm .    in what follows",
    "we will use a few standard definitions that we briefly recall here .",
    "first , subtracting two rows is called _",
    "merging_. this is because rows are stored as lists of the non - zero entries sorted with respect to the corresponding columns and subtracting them corresponds to merging the two sorted lists . if two rows @xmath124 and @xmath125 share the same prime @xmath105 with coefficients @xmath126 and @xmath127 respectively then multipling @xmath124 by @xmath127 and @xmath125 by @xmath126 and merging is called _",
    "pivoting_. finally , finding a sequence of pivots leading to the elimination of a column of hamming weight @xmath97 is a @xmath97-way merge .",
    "we aim to reduce the dimension of the relation matrix by performing @xmath97-way merges on the columns of weight @xmath128 in increasing order for a certain bound @xmath129 .",
    "unfortunately , the density of the rows and the size of the coefficients increase during the course of the algorithm , thus obliging us to use optimized pivoting strategies . in what follows",
    "we describe an algorithm performing @xmath97-way merges to minimize the growth of both the density and the size of the coefficients .",
    "first we have to define a cost function defined over the set of the rows encapsulating the difficulty induced for the hnf algorithm . in factorization",
    ", we want to find a vector in the kernel of the relation matrix which is defined over @xmath123 ; the only property of the row that really matters is its hamming weight . in our context , we need to minimize the hamming weight of the row , but we also have to take into account the size of the coefficients .",
    "different cost functions lead to different elimination strategies .",
    "our cost function was determined empirically : we took the number of non - zero entries , counting @xmath130 times those whose absolute value was above a bound @xmath131 , where @xmath130 is a positive number .",
    "if @xmath132 $ ] corresponds to @xmath133 then @xmath134 indeed as we will see , matrices with small entries are better suited for the hnf algorithm described in [ hnf_algo ] .",
    "let us assume now that we are to perform a @xmath97-way merge on a given column .",
    "we construct a complete graph @xmath135 of size @xmath97 as follows :    * the vertices are the rows @xmath136 . *",
    "every edge linking @xmath136 and @xmath137 is labeled by @xmath138 , where @xmath139 is obtained by pivoting @xmath136 and @xmath137 .    finding the best sequence of pivots with respect to the cost function @xmath130 we chose is equivalent to finding the minimum spanning tree @xmath140 of @xmath135 , and then recombining every row @xmath141 with its parent starting with the leaves of @xmath140 .    unfortunately , some coefficients might grow during the course of column eliminations despite the use of this strategy .",
    "once a big coefficient is created in a given row @xmath141 , it is likely to spread to other rows once @xmath141 is involved in another column elimination .",
    "we must therefore discard such rows as quickly as possible .",
    "in our implementation we chose to do it regularly : once we have performed all the @xmath97-way merges for @xmath142 and @xmath143 we discard a fixed number @xmath144 of the rows containing the largest coefficients .",
    "we show in table [ tabcrunch ] the effect of the use of a cost function taking into account the size of the coefficients and the regular discard of the worst rows for @xmath145 with @xmath146 , @xmath147 and @xmath148 .",
    "we kept track of the evolution of the dimensions of the matrix , the average hamming weight of the rows , and the maximum and minimum size of the coefficients . in the first case we use the traditional cost function that only takes into account the hamming weight of the rows and",
    "we keep deleting the worst rows regularly ; this corresponds to taking @xmath149 and @xmath150 . in the second case ,",
    "we use the cost function described above but without row elimination by setting @xmath151 and @xmath152 . in the third case ,",
    "we combine the two ( @xmath151 and @xmath150 ) .",
    "we clearly see that the coefficients are properly monitored only in the latter case . indeed using a cost function that does not take into account",
    "the size of the coefficients and just discarding the worst rows regularly seems more efficient in terms of reduction of the matrix dimension , but the row corresponding to @xmath153 ( that is to say after all the 120-way merges ) clearly shows that we run the risk of an explosion of the coefficients .",
    "@xmath154 & row nb & col nb & average weight & max & min + 0 & 38752 & 45975 & 22 & 10 & -10 + 2 & 2334 & 1668 & 76 & 21 & -20 + 4 & 2123 & 1477 & 117 & 52 & -56 + 6 & 2028 & 1402 & 146 & 59 & -62 + 8 & 1951 & 1345 & 175 & 72 & -65 + 10 & 1890 & 1304 & 203 & 193 & -196 + 12 & 1836 & 1270 & 219 & 212 & -2147483648 +   + @xmath154 & row nb & col nb & average weight & max & min + 0 & 38752 & 45975 & 22 & 10 & -10 + 2 & 2373 & 1687 & 79 & 30 & -40 + 4 & 2224 & 1538 & 118 & 67 & -50 + 6 & 2158 & 1472 & 148 & 71 & -132 + 8 & 2117 & 1431 & 179 & 2648 & -10568 + 10 & 2097 & 1411 & 196 & 347136 & -337920 + 12 & 2080 & 1394 & 214 & 268763136 & -173162496 +   + @xmath154 & row nb & col nb & average weight & max & min + 0 & 38752 & 45975 & 22 & 10 & -10 + 2 & 2357 & 1691 & 76 & 17 & -17 + 4 & 2176 & 1530 & 114 & 27 & -30 + 6 & 2074 & 1448 & 149 & 37 & -37 + 8 & 2013 & 1407 & 177 & 43 & -43 + 10 & 1958 & 1372 & 199 & 44 & -45 + 12 & 1908 & 1342 & 224 & 54 & -53 +      in @xcite it has been observed that the algorithm used to compute the hnf of the relation matrix relied heavily on the sparsity of the matrix . while recombinations of the kind described in @xcite or the techniques of [ gauss ] reduce the dimensions of the matrix , they also dramatically increase the density of the matrix , thus slowing down the computation of the hnf .",
    "we had to find an hnf algorithm whose features were adapted to our situation .",
    "vollmer described in @xcite an algorithm of polynomial complexity depending on the capacity to solve diophantine linear systems , but not on the density of the matrix .",
    "it was not implemented at the time because there was no efficient diophantine linear system solver available .",
    "we implemented vollmer s algorithm using the iml @xcite library provided by storjohann .    here",
    "we give a brief description of the algorithm ( for more details we refer to @xcite ) .",
    "we assume we have created an @xmath155 relation matrix @xmath41 of full rank . for each @xmath156 , we define two matrices @xmath157{ccc}{ccc }        a_{1,1 } & \\hdots & a_{m,1}\\\\      \\vdots &   & \\vdots \\\\",
    "a_{1,i } & \\hdots & a_{m , i }     \\end{bmat }     \\right )   \\ \\ \\text{and}\\ \\ e_i = \\left (      \\begin{bmat}(e)[2pt,0pt,3cm]{c}{cccc }       0 \\\\ \\vdots \\\\ 0 \\\\ 1     \\end{bmat }     \\right).\\ ] ] for each @xmath154 , we define @xmath158 to be the minimal denominator of a rational solution of the system @xmath159 this is computed using the function ` mincertifiedsol ` of iml , which is an implementation of ( special)minimalsolution from @xcite , and used in @xcite for the complexity analysis . in @xcite",
    "it is shown that @xmath160 fortunately , analytic formulae allow us to compute a bound @xmath161 such that @xmath162 so we do not have to compute @xmath158 for every @xmath163 $ ] .",
    "in addition , the matrices produced for the computation of the group structure of @xmath1 have small essential part , which keeps the number of diophantine systems to solve small ( about the same size as the number of columns of the essential part ) as shown in @xcite .",
    "@xmath0 , relation matrix @xmath41 of full rank and @xmath161 @xmath164 @xmath165 @xmath166 compute the minimal denominator @xmath158 of a solution of @xmath167 @xmath168 @xmath169 @xmath170    we can compute the essential part of the hnf of @xmath41 with a little extra effort involving only modular reductions of coefficients ; we refer to @xcite for more details .",
    "this part of the algorithm is highly dependent on the performance of the diophantine solver we use , which in turn is mostly influenced by the number of columns of the matrix and the size of the coefficients .",
    "the bechmarks available @xcite show that the algorithm runs much faster on matrices with 3-bit coefficients , which is why we took coefficient size into account in the cost function for the gaussian elimination .",
    "in this section we proceed to optimize the parameters involved in the relation collection phase .",
    "each parameter has an effect on the overall time taken to compute the group structure of @xmath1 .",
    "recall giving the bound @xmath171 ; when we collect partial relations it should be adapted in the following way : @xmath172 where @xmath104 is the large prime bound .",
    "the parameter @xmath102 represents the tolerance to rounding errors in the traditional sieving algorithms .",
    "its value is empirically determined , and usually lies in the interval @xmath173 $ ] . in the large prime variant it also encapsulates the number of large primes we want to allow . indeed , if there were no rounding errors one would expect this value to be 1 for one large prime and 2 for two large primes . in practice , we can exhibit an optimum value which differs slightly from what we would expect .",
    "in figure [ opt_t ] we show the overall running time of the algorithm when the parameter @xmath102 varies between 1.5 and 3.5 for the discriminant @xmath174 .",
    "the size of the factor base taken is 3250 , the ratio @xmath175 equals 120 , and we allow two large primes .",
    "one of the main issues for determining the optimal value of @xmath102 is that it tends to shift when one modifies the value of @xmath122 , the rest being unchanged . indeed , if for example @xmath176 then @xmath177 so when we increase @xmath122 we have to lower @xmath102 to compensate .",
    "figure [ opt_fb ] illustrates this phenomenon on the example @xmath174 , with two large primes .",
    "in figure [ opt_fb_n ] we study the evolution of the optimal value of @xmath102 for the single and double large prime variants on discriminants of the form @xmath178 where @xmath35 ranges between 60 and 80 .",
    "it appears that , as we expected , the optimal value for the double large prime variant is greater than the one corresponding to the single large prime variant .",
    "this value is between 2 and 2.3 for one large prime and around 2.7 when we allow two large primes .",
    "the optimal size of the factor base reflects the trade - off between the time spent on the relation collection phase and on the linear algebra phase .",
    "this optimum is usually not the size that minimizes the time spent on the relation collection phase . to illustrate this , figure [ opt_fb_time ] shows the time taken by the algorithm for @xmath174 with @xmath176 and the corresponding optimal @xmath102 .",
    "the optimal size of the factor base increases with the size of the discriminant .",
    "figure [ opt_fb_time_n ] shows the optimal size of the factor base for discriminants of the form @xmath178 as @xmath35 ranges between 60 and 80 for both one large prime and two large primes .",
    "we notice that the single large prime variant requires smaller factor bases than without large primes , and bigger factor bases than the double large prime variant",
    ".      theoretically @xmath104 should not exceed @xmath179 . in practice ,",
    "when the ratio @xmath175 is too high we lose time taking into account partial relations involving primes that are so large that they are very unlikely to occur twice and to lead to a recombination .",
    "this phenomenon is known in the context of factorization , and 120 is a common choice of value of @xmath175 ( see @xcite ) .",
    "we ran experiments using 12 , 120 and 1200 as values for the ratio @xmath175 .",
    "figure [ tabratio ] shows the results for @xmath174 with two large primes .",
    "we give the optimum timings for each value of the size of the factor base , and compare those values for the three different ratios .",
    "it appears that 120 is indeed the best choice , but the performance of the algorithm is not highly dependent on this parameter .    [ cols=\"^,^,^,^\",options=\"header \" , ]",
    "the author thanks andreas enge for his support on this project , the fruitful discussions we had and a careful reading of this article .",
    "we thank nicolas thriault and all the organizing comitee of the conference chile 2009 where the original results of this paper were first presented .",
    "we also thank jrme milan for his support on issues regarding implementation , especially with the tifa library .",
    "s. cavallar , _ strategies in filtering in the number field sieve _ , in  ants - iv : proceedings of the 4th international symposium on algorithmic number theory , \" lecture notes in computer science , * 1838 * ( 2000 ) , 209232 .",
    "s. contini  factoring integers with the self initializing quadratic sieve , \" master thesis , university of georgia , 1997 j.e .",
    "gower and s. wagstaff , _ square form factorization _ , mathematics of computations , * 77 * ( 2008 ) , 551588 .",
    "d. hhnlein , m.j .",
    "jacobson , s. paulus and t. takagi , _ a cryptosystem based on non - maximal imaginary quadratic orders with fast decryption _ , in  advances in cryptology - eurocrypt 98 , \" lecture notes in computer science , * 1403 * ( 1998 ) , 294307 .            p.c .",
    "leyland , a.k .",
    "lenstra , b. dodson , a. muffett and s. wagstaff , _ mpqs with three large primes _ , in  ants - v : proceedings of the 5th international symposium on algorithmic number theory , \" lecture notes in computer science , * 2369 * ( 2002 ) , 446460 .",
    "u. vollmer , _ a note on the hermite basis computation of large integer matrices _ , in ",
    "issac 03 : proceedings of the 2003 international symposium on symbolic and algebraic computation , \" acm , ( 2003 ) , 255257 ."
  ],
  "abstract_text": [
    "<S> we investigate improvements to the algorithm for the computation of ideal class groups described by jacobson in the imaginary quadratic case . </S>",
    "<S> these improvements rely on the large prime strategy and a new method for performing the linear algebra phase . </S>",
    "<S> we achieve a significant speed - up and are able to compute ideal class groups with discriminants of 110 decimal digits in less than a week .    jean - franois biasse    ( communicated by tanja lange ) </S>"
  ]
}