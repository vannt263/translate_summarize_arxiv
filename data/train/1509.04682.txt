{
  "article_text": [
    "the standard - form linear program ( lp ) is    @xmath2    where @xmath3 is the variable and @xmath4 are the problem parameters . in practice , @xmath5 may not be known exactly or may be predicted to change within a certain region . in such cases ,",
    "_ sensitivity analysis _",
    "( sa ) examines how perturbations in the parameters affect the optimal value and solution of ( [ eq : stdprimal ] ) .",
    "ordinary sa considers the change of a single element in @xmath5 and examines the corresponding effects on the optimal basis and tableau ; see @xcite .",
    "sa also extends to the addition of a new variable or constraint , although we do not consider such changes in this paper .    beyond ordinary sa , more sophisticated approaches that allow simultaneous changes in the coefficients @xmath6 or right - hand sides",
    "@xmath7 have been proposed by numerous researchers .",
    "bradley et al .",
    "@xcite discuss the _",
    "100-percent rule _ that requires specification of directions of increase or decrease from each @xmath8 and then guarantees that the same basis remains optimal as long as the sum of fractions , corresponding to the percent of maximum change in each direction derived from ordinary sa , is less than or equal to 1 .",
    "wendell @xcite develops the _ tolerance approach _ to find the so - called _ maximum tolerance percentage _ by which the objective coefficients can be simultaneously and independently perturbed within _ a priori _ bounds .",
    "the tolerance approach also handles perturbations in one row or column of the matrix coefficients @xcite or even more general perturbations in all elements of the matrix coefficients under certain assumptions @xcite .",
    "freund @xcite investigates the sensitivity of an lp to simultaneous changes in matrix coefficients .",
    "in particular , he considers a linear program whose coefficient matrix depends linearly on a scalar parameter @xmath9 and studies the effect of small perturbations on the the optimal objective value and solution ; see also @xcite .",
    "readers are referred to @xcite for a survey of approaches for sa of problem ( [ eq : stdprimal ] ) .",
    "an area closely related to sa is _ interval linear programming _ ( ilp ) , which can be viewed as _ multi - parametric linear programming _ with independent interval domains for the parameters @xcite .",
    "steuer @xcite presents three algorithms for solving lps in which the objective coefficients are specified by intervals , and gabrel et al .",
    "@xcite study lps in which the right - hand sides vary within intervals and discuss the maximum and minimum optimal values .",
    "mraz @xcite considers a general situation in which the matrix coefficients and right - hand sides change within intervals and calculates upper and lower bounds for the associated optimal values .",
    "a comprehensive survey of ilp has been given by hladik @xcite .",
    "to the best of our knowledge , in the context of lp , no authors have considered simultaneous lp parameter changes in a general way , i.e. , perturbations in the objective coefficients @xmath6 , right - hand sides @xmath7 , and constraint coefficients @xmath10 within a general region ( not just intervals ) .",
    "the obstacle for doing so is clear : general perturbations lead to nonconvex quadratic programs ( qps ) , which are np - hard to solve ( as discussed below ) .    in this paper , we extend  and in many cases unify  the sa literature by employing modern tools for nonconvex qps . specifically , we investigate sa for lps in which @xmath11 may change within a general compact , convex set @xmath12 , called the _ uncertainty set_. our goal is to calculate  or bound  the corresponding minimum ( best - case ) and maximum ( worst - case ) optimal values .",
    "since these values involve the solution of nonconvex qps , we use standard techniques from _ copositive optimization _ to reformulate these problems into convex _ copositive programs _ ( cops ) , which provide a theoretical grounding upon which to develop tight , tractable convex relaxations .",
    "we suggest the use of _ semidefinite programming _",
    "( sdp ) relaxations , which also incorporate valid conic inequalities that exploit the structure of the uncertainty set .",
    "we refer the reader to @xcite for a survey on copositive optimization and its connections to semidefinite programming .",
    "relevant definitions and concepts will also be given in this paper ; see section [ ssec : notation ] .",
    "our approach is related to the recent work on _ worst - case linear optimization _ introduced by peng and zhu @xcite in which : ( i ) only @xmath7 is allowed to change within an ellipsoidal region ; and ( ii ) only the worst - case lp value is considered .",
    "( in fact , one can see easily that , in the setup of @xcite based on ( i ) , the best - case lp value can be computed in polynomial time via second - order - cone programming , making it less interesting to study in their setup . )",
    "the authors argue that the worst - case value is np - hard to compute and use a specialized nonlinear semidefinite program ( sdp ) to bound it from above .",
    "they also develop feasible solutions to bound the worst - case value from below and show through a series of empirical examples that the resulting gaps are usually quite small .",
    "furthermore , they also demonstrate that their sdp - based relaxation is better than the so - called _ affine - rule approximation _ ( see @xcite ) and the lasserre _ linear matrix inequality _ relaxation ( see @xcite ) .",
    "our approach is more general than @xcite because we allow both @xmath7 and @xmath6 to change , we consider more general uncertainty sets , and we study both the worst- and best - case values .",
    "in addition , instead of developing a specialized sdp approach , we make use of the machinery of copositive programming , which provides a theoretical grounding for the construction of tight , tractable conic relaxations using existing techniques .",
    "nevertheless , we have been inspired by their approach in several ways .",
    "for example , their proof of np - hardness also shows that our problem is np - hard ; we will borrow their idea of using primal solutions to estimate the quality of the relaxation bounds ; and we test some of the same examples .",
    "we mention two additional connections of our approach with the literature . in @xcite , bertsimas and goyal",
    "consider a two - stage adaptive linear optimization problem under right - hand side uncertainty with a min - max objective .",
    "a simplified version of this problem , in which the first - stage variables are non - existent , reduces to worst - case linear optimization ; see the introduction of @xcite .",
    "in fact , bertsimas and goyal use this fact to prove that their problem is np - hard via the so - called max - min fractional set cover problem , which is a specific worst - case linear optimization problem studied by feige et al .",
    "our work is also related to the study of _ adjustable robust optimization _",
    "@xcite , which allows for two sets of decisions ",
    "one that must be made before the uncertain data is realized , and one after .",
    "in fact , our problem can viewed as a simplified case of adjustable robust optimization having no first - stage decisions . on the other hand ,",
    "our paper is distinguished by its application to sensitivity analysis and its use of copositive and semidefinite optimization .",
    "we organize the paper as follows . in section [ sec : rsa ]",
    ", we extend many of the existing approaches for sa by considering simultaneous , general changes in @xmath11 and the corresponding effect on the lp optimal value .",
    "precisely , we model general perturbations of @xmath11 within a compact , convex set @xmath12the uncertainty set , borrowing terminology from the robust - optimization literature  and define the corresponding minimum and maximum optimal values @xmath0 and @xmath1 , respectively .",
    "we call our approach _ robust sensitivity analysis _ , or _",
    "rsa_. then , continuing in section [ sec : rsa ] , we formulate the calculation of @xmath0 and @xmath1 as nonconvex bilinear qps ( or bqps ) and briefly discuss attainability and complexity issues .",
    "we also discuss how @xmath0 and @xmath1 may be infinite and suggest alternative bounded variants , @xmath13 and @xmath14 , which have the property that , if @xmath0 is already finite , then @xmath15 and similarly for @xmath14 and @xmath1 .",
    "compared to related approaches in the literature , our discussion of finiteness is unique .",
    "we then discuss the addition of redundant constraints to the formulations of @xmath13 and @xmath14 , which will strengthen later relaxations .",
    "section [ sec : relax ] then establishes cop reformulations of the nonconvex bqps by directly applying existing reformulation techniques .",
    "then , based on the cops , we develop tractable sdp - based relaxations that incorporate the structure of the uncertainty set @xmath12 , and we also discuss procedures for generating feasible solutions of the bqps , which can also be used to verify the quality of the relaxation bounds . in section [ sec : expr ] , we validate our approach on several examples , which demonstrate that the relaxations provide effective approximations of @xmath14 and @xmath13 .",
    "in fact , we find that the relaxations admit no gap with @xmath14 and @xmath13 for all tested examples .",
    "we mention some caveats about the paper .",
    "first , we focus only on how the optimal value is affected by uncertainty , not the optimal solution .",
    "we do so because we believe this will be a more feasible first endeavor ; determining how general perturbations affect the optimal solution can certainly be a task for future research .",
    "second , as mentioned above , we believe we are the first to consider these types of general perturbations , and thus the literature with which to compare is somewhat limited . however , we connect with the literature whenever possible , e.g. , in special cases such as interval perturbations and worst - case linear optimization .",
    "third , since we do not make any distributional assumptions about the uncertainty of the parameters , nor about their independence or dependence , we believe our approach aligns well with the general sprit of _ robust optimization_. it is important to note , however , that our interest is _ not _ robust optimization and is _ not _ directly comparable to robust optimization .",
    "for example , while in robust optimization one wishes to find a single optimal solution that works well for all realizations of the uncertain parameters , here we are only concerned with how the optimal value changes as the parameters change .",
    "finally , we note the existence of other relaxations for nonconvex qps including lp relaxations ( see @xcite ) and lasserre - type sdp relaxations . generally speaking , lp - based relaxations are relatively weak ( see @xcite ) ; we do not consider them in this paper .",
    "in addition , sdp approaches can often be tailored to outperform the more general lasserre approach as has been demonstrated in @xcite .",
    "our copostive- and sdp - based approach is similar ; see for example the valid inequalities discussed in section [ ssec : sdprelax ] .",
    "let @xmath16 denote @xmath17-dimensional euclidean space represented as column vectors , and let @xmath18 denote the nonnegative orthant in @xmath16 .",
    "for a scalar @xmath19 , the @xmath20-norm of @xmath21 is defined @xmath22 , e.g. , @xmath23 .",
    "we will drop the subscript for the @xmath24-norm , e.g. , @xmath25 . for @xmath26 ,",
    "the inner product of @xmath27 and @xmath28 is defined as @xmath29 and the hadamard product of @xmath27 and @xmath28 is defined by @xmath30 .",
    "@xmath31 denotes the set of real @xmath32 matrices , and the trace inner product of two matrices @xmath33 is defined @xmath34 .",
    "@xmath35 denotes the space of @xmath36 symmetric matrices , and for @xmath37 , @xmath38 denotes that @xmath39 is positive semidefinite .",
    "in addition , @xmath40 denotes the vector containing the diagonal entries of @xmath39 .",
    "we also make several definitions related to _",
    "copositive programming_. the @xmath36 _ copositive cone _ is defined as @xmath41 and its dual cone , the _ completely positive cone _ , is @xmath42 where the summation over @xmath43 is finite but its cardinality is unspecified .",
    "the term _ copositive programming _ refers to linear optimization over @xmath44 or , via duality , linear optimization over @xmath45 . a more general notion of copositive programming",
    "is based on the following ideas .",
    "let @xmath46 be a closed , convex cone , and define @xmath47 then _ generalized copositive programming _ is linear optimization over @xmath48 and @xmath49 and is also sometimes called _ set - semidefinite optimization _ @xcite . in this paper",
    ", we work with generalized copositive programming , although we will use the shorter phrase _ copositive programming _ for convenience .",
    "in this section , we introduce the concept of robust sensitivity analysis of the optimal value of the linear program ( [ eq : stdprimal ] ) . in particular",
    ", we define the best - case optimal value @xmath0 and the worst - case optimal value @xmath1 over the uncertainty set @xmath12 , which contains general perturbations in the objective coefficients @xmath6 and the right - hand sides @xmath7 .",
    "we then propose nonconvex bilinear qps ( bqps ) to compute @xmath0 and @xmath1 .",
    "next , we clarify when @xmath0 and @xmath1 could be infinite and propose finite , closely related alternatives @xmath14 and @xmath13 , which can also be formulated as nonconvex bqps .",
    "importantly , we prove that @xmath13 equals @xmath0 whenever @xmath0 is finite ; the analogous relationship is also proved for @xmath14 and @xmath1 .",
    "in the introduction , we have described @xmath7 and @xmath6 as parameters that could vary , a concept that we now formalize .",
    "hereafter , @xmath11 denotes the _ nominal _ , `` best guess '' parameter values , and we let @xmath50 denote perturbations with respect to @xmath51 . in other words ,",
    "the true data could be @xmath52 , and we think of @xmath53 and @xmath54 as varying .",
    "we also denote the _ uncertainty set _",
    "containing all possible perturbations @xmath50 as @xmath55 . throughout this paper , we assume the following :    [ assmp : a1 ] @xmath12 is compact and convex , and @xmath12 contains @xmath56 .",
    "given @xmath57 , we define the perturbed optimal value function at @xmath50 as @xmath58 for example , @xmath59 is the _ nominal optimal value _ of the _ nominal problem _ based on the nominal parameters .",
    "the main idea of robust sensitivity analysis is then to compute the infimum ( best - case ) and supremum ( worst - case ) of all optimal values @xmath60 over the uncertainty set @xmath12 , i.e. , to calculate @xmath61    we illustrate @xmath0 and @xmath1 with a small example .",
    "[ ex : ex1 ] consider the nominal lp @xmath62 and the uncertainty set @xmath63 \\\\",
    "c_1 \\in [ -0.5 , 0.5 ] , \\ c_2 = 0 \\end{array }   \\right\\}.\\ ] ] note that the perturbed data @xmath64 and @xmath65 remain positive , while @xmath66 is constant .",
    "thus , the minimum optimal value @xmath0 occurs when @xmath67 and @xmath68 are minimal , i.e. , when @xmath69 and @xmath70 . in this case , @xmath71 at the solution @xmath72 . in a related manner ,",
    "@xmath73 when @xmath74 and @xmath75 at the point @xmath76 .",
    "actually , any perturbation with @xmath77 $ ] and @xmath78 realizes the worst - case value @xmath79 .",
    "figure [ fig : two_vars ] illustrates this example .",
    "note that the dashed line in both ( [ fig : p- ] ) and ( [ fig : p+ ] ) corresponds to the feasible region of the nominal problem.,title=\"fig : \" ]    0.5 .",
    "note that the dashed line in both ( [ fig : p- ] ) and ( [ fig : p+ ] ) corresponds to the feasible region of the nominal problem.,title=\"fig : \" ]    we can obtain a direct formulation of @xmath0 by simply collapsing the inner and outer minimizations of ( [ equ : p- ] ) into a single nonconvex bqp :    @xmath80    the nonconvexity comes from the bilinear term @xmath81 in the objective function .",
    "in the special case that @xmath57 implies @xmath82 , i.e. , when there is no perturbation in the objective coefficients , we have the following :    [ rem : polytime_c0 ] if @xmath12 is tractable and @xmath83 for all @xmath57 , then @xmath0 can be computed in polynomial time as the optimal value of ( [ equ : quadp- ] ) with @xmath83 , which is a convex program .",
    "a direct formulation for @xmath1 can , under a fairly weak assumption , be gotten via duality .",
    "define the perturbed primal and dual feasible sets for any @xmath57 : @xmath84 for instance , @xmath85 and @xmath86 are the primal - dual feasible sets of the nominal problem .",
    "next define the dual lp for ( [ equ : p(b , c ) ] ) as @xmath87 considering the extended notion of strong duality , which handles the cases of infinite values , we have that @xmath88 when at least one of @xmath89 and @xmath90 is nonempty . hence , under the assumption that every @xmath57 yields @xmath91 or @xmath92 , a direct formulation for @xmath1 can be constructed by replacing @xmath60 in ( [ equ : p- ] ) with @xmath93 and then collapsing the subsequent inner and outer maximizations into the single nonconvex bqp @xmath94 here again , the nonconvexities arise due to the bilinear term @xmath95 in the objective .",
    "if @xmath57 implies @xmath96 , then @xmath1 can be calcuated in polynomial time :    [ rem : polytime_b0 ] if @xmath12 is tractable and @xmath96 for all @xmath57 , then @xmath1 can be computed in polynomial time as the optimal value of ( [ equ : quadp+ ] ) with @xmath96 , which is a convex program .",
    "we summarize the above discussion in the following proposition :    [ pro:1stformulation ] the best - case value @xmath0 equals the optimal value of ( [ equ : quadp- ] ) . moreover , if @xmath91 or @xmath97 for all @xmath98 , then the worst - case value @xmath1 equals the optimal value of ( [ equ : quadp+ ] ) .",
    "we view the condition in proposition [ pro:1stformulation]that at least one of @xmath89 and @xmath90 is nonempty for each @xmath99to be rather mild .",
    "said differently , the case that @xmath100 for some @xmath57 appears somewhat pathological . for practical purposes ,",
    "we hence consider ( [ equ : quadp+ ] ) to be a valid formulation of @xmath1 . actually , in the next subsection , we will further restrict our attention to those @xmath57 for which both @xmath89 and @xmath101 are nonempty .",
    "in such cases , each @xmath60 is guaranteed to be finite , which  as we will show  carefully handles the cases when @xmath1 and @xmath0 are infinite .",
    "indeed , the worst - case value @xmath1 could equal @xmath102 due to some perturbed @xmath89 being empty as shown in the following example :    [ ex : ex2 ] in example [ ex : ex1 ] , change the uncertainty set to @xmath103 \\\\",
    "c_1 \\in [ -0.5 , 0.5 ] , c_2 = 0 \\end{array }   \\right\\}.\\ ] ] then @xmath104 whenever @xmath105 since then the primal feasible set @xmath89 is empty",
    ". then @xmath106 overall .",
    "however , limiting @xmath67 to @xmath107 $ ] yields a worst - case value of 3 as discussed in example [ ex : ex1 ] .",
    "similarly , @xmath0 might equal @xmath108 due to some perturbed lp having unbounded objective value , implying infeasibility of the corresponding dual feasible set @xmath90 .",
    "in this brief subsection , we mention results pertaining to the attainability of @xmath0 and @xmath1 and the computational complexity of computing them .    by an existing result concerning the attainability of the optimal value of nonconvex bqps",
    ", we have that @xmath0 and @xmath1 are attainable when @xmath12 has a relatively simple structure :    suppose @xmath12 is representable by a finite number of linear constraints and at most one convex quadratic constraint .",
    "then , if the optimal value of ( [ equ : quadp- ] ) is finite , it is attained .",
    "a similar statement holds for ( [ equ : quadp+ ] ) .    in particular",
    ", attainability holds when @xmath12 is polyhedral or second - order - cone representable with at most one second - order cone .",
    "moreover , the bilinear nature of ( [ equ : quadp- ] ) implies that , if the optimal value is attained , then there exists an optimal solution @xmath109 with @xmath110 an extreme point of @xmath12 .",
    "the same holds for ( [ equ : quadp+ ] ) if its optimal value is attained .",
    "as discussed in the introduction , the worst - case value @xmath1 has been studied by peng and zhu @xcite for the special case when @xmath83 and @xmath53 is contained in an ellipsoid .",
    "the authors demonstrate ( see their proposition 1.1 ) that calculating @xmath1 in this case is np - hard . by the symmetry of duality",
    ", it thus also holds that @xmath0 is np - hard to compute in general .",
    "we now discuss closely related variants of @xmath1 and @xmath0 that are guaranteed to be finite and to equal @xmath1 and @xmath0 , respectively , when those values are themselves finite .",
    "we require the following feasibility and boundedness assumption :    [ assmp : a2 ] both feasible sets @xmath85 and @xmath86 are nonempty , and one is bounded .    by standard theory , @xmath85 and @xmath86 can not both be nonempty and bounded . also define @xmath111 note that @xmath112 due to assumption [ assmp : a2 ] .",
    "in fact , @xmath113 can be captured with linear constraints that enforce primal - dual feasibility and hence is a compact , convex subset of @xmath12 : @xmath114 analogous to @xmath1 and @xmath0 , define @xmath115    the following proposition establishes the finiteness of @xmath14 and @xmath13 :    [ prop : finiteness ] under assumptions [ assmp : a1 ] and [ assmp : a2 ] , both @xmath14 and @xmath13 are finite .",
    "we prove the contrapositive for @xmath13 .",
    "( the argument for @xmath14 is similar . )",
    "suppose @xmath116 .",
    "then there exists a sequence @xmath117 with finite optimal values @xmath118 . by strong duality",
    ", there exists a primal - dual solution sequence @xmath119 with @xmath120 .",
    "since @xmath113 is bounded , it follows that @xmath121 and @xmath122 .",
    "consider the sequence @xmath123 with @xmath124 we have @xmath125 , @xmath126 , and @xmath127 for all @xmath43 .",
    "morover , @xmath128 .",
    "hence , there exists a subsequence converging to @xmath129 such that @xmath130 , @xmath131 , and @xmath132 .",
    "this proves that the recession cone of @xmath85 is nontrivial , and hence @xmath85 is unbounded . in a similar manner",
    ", @xmath86 is unbounded , which means assumption [ assmp : a2 ] does not hold .",
    "note that the proof of proposition [ prop : finiteness ] only assumes that @xmath12 , and hence @xmath113 , is bounded , which does not use the full power of assumption [ assmp : a1 ] .",
    "similar to @xmath0 , a direct formulation of @xmath13 can be constructed by employing the primal - dual formulation of @xmath113 and by collapsing the inner and outer minimizations of ( [ equ : barp- ] ) into a single nonconvex bqp : @xmath133 likewise for @xmath1 , after replacing @xmath60 in ( [ equ : barp+ ] ) by @xmath93 , we can collapse the inner and outer maximizations into a single nonconvex bqp : @xmath134    the following proposition establishes @xmath135 when @xmath1 is finite and , similarly , @xmath15 when @xmath0 is finite .    if @xmath1 is finite , then @xmath135 , and if @xmath0 is finite , then @xmath15 .",
    "we prove the second statement only since the first is similar . comparing the formulation ( [ equ : quadp- ] ) for @xmath0 and the formulation ( [ equ : quadbarp- ] ) for @xmath13 , it is clear that @xmath136 . in addition ,",
    "let @xmath137 be any feasible solution of ( [ equ : quadp- ] ) . because @xmath0 is finite",
    ", @xmath60 is finite .",
    "then the corresponding dual problem is feasible , which implies that we can extend @xmath137 to a solution @xmath138 of ( [ equ : quadbarp- ] ) with the same objective value .",
    "hence , @xmath139 .    in the remaining sections of the paper",
    ", we will focus on the finite variants @xmath13 and @xmath14 given by the nonconvex qps ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) , which optimize the optimal value function @xmath140 based on enforcing primal - dual feasibility .",
    "it is clear that we may also enforce the complementary slackness condition @xmath141 without changing these problems .",
    "although it might seem counterintuitive to add the redundant , nonconvex constraint @xmath141 to an already difficult problem , in section [ sec : relax ] , we will propose convex relaxations to approximate @xmath13 and @xmath14 , in which case  as we will demonstrate  the relaxed versions of the redundant constraint can strengthen the relaxations .",
    "in this section , we use copositive optimization techniques to reformulate the rsa problems ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) into convex programs .",
    "we further relax the copositive programs into conic , sdp - based problems , which are computationally tractable .      in order to formulate ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) as cops , we apply a result of @xcite ;",
    "see also @xcite .",
    "consider the general nonconvex qp @xmath142 where @xmath143 is a closed , convex cone .",
    "its copositive reformulation is @xmath144 as established by the following lemma :    [ lemma : burer ] problem ( [ equ : genqp ] ) is equivalent to ( [ equ : gencop ] ) , i.e. : ( i ) both share the same optimal value ; ( ii ) if @xmath145 is optimal for ( [ equ : gencop ] ) , then @xmath146 is in the convex hull of optimal solutions for ( [ equ : genqp ] ) .",
    "the following theorem establishes that problems ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) can be reformulated as copositive programs according to lemma [ lemma : burer ] . the proof is based on describing how the two problems fit the form ( [ equ : genqp ] ) .",
    "[ the : cop ] problems ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) to compute @xmath13 and @xmath14 are solvable as copositive programs of the form ( [ equ : gencop ] ) , where @xmath147 and @xmath148 is the homogenization of @xmath12 .",
    "we prove the result for just problem ( [ equ : quadbarp- ] ) since the argument for problem ( [ equ : quadbarp+ ] ) is similar .",
    "first , we identify @xmath149 in ( [ equ : genqp ] ) with @xmath150 in ( [ equ : quadbarp- ] ) .",
    "in addition , in the constraints , we identify @xmath151 with the equations @xmath152 , @xmath153 , and @xmath154 .",
    "note that the right - hand - side vector @xmath155 is all zeros except for a single entry corresponding to the constraint @xmath154 .",
    "moreover , in the objective , @xmath156 is identified with the bilinear term @xmath157 , and @xmath158 is identified with the linear term @xmath159 . with this setup , it is clear that ( [ equ : quadbarp- ] ) is an instance of ( [ equ : genqp ] ) and hence lemma [ lemma : burer ] applies to complete the proof .      as discussed above ,",
    "the copositive formulations of ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) as represented by ( [ equ : gencop ] ) are convex yet generally intractable .",
    "thus , we propose sdp - based conic relaxations that are polynomial - time solvable and hopefully quite tight in practice . in section [ sec : expr ]",
    "below , we will investigate their tightness computationally .",
    "we propose relaxations that are formed from ( [ equ : gencop ] ) by relaxing the cone constraint @xmath160 as is well known  and direct from the definitions  cones of the form @xmath161 are contained in the positive semidefinite cone .",
    "hence , we will enforce @xmath162 .",
    "it is also true that @xmath163 implies @xmath149 , although @xmath162 does not necessarily imply this .",
    "so , in our relaxations , we will also enforce @xmath149 .",
    "including @xmath149 improves the relaxation and also helps in the calculation of bounds in section [ ssec : boundsfeas ]    next , suppose that the description of @xmath164 contains at least two linear constraints , @xmath165 and @xmath166 . by multiplying @xmath167 and @xmath168",
    ", we obtain a valid , yet redundant , quadratic constraint @xmath169 for @xmath170 .",
    "this quadratic inequality can in turn be linearized in terms of @xmath171 as @xmath172 , which is valid for @xmath173 .",
    "we add this linear inequality to our relaxation ; it is called an _ rlt constraint _ @xcite .",
    "in fact , we add all such rlt constraints arising from all pairs of linear constraints present in the description of @xmath164 .",
    "when the description of @xmath164 contains at least one linear constraint @xmath165 and one second - order - cone constraint @xmath174 , where @xmath175 is a vector and @xmath176 is a matrix , we will add a so - called _ soc - rlt constraint _ to our relaxation @xcite .",
    "the constraint is derived by multiplying the two constraints to obtain the valid quadratic second - order - cone constraint @xmath177 after linearization by @xmath171 , we have the second - order - cone constraint @xmath178    finally , recall the redundant complementarity constraint @xmath179 described at the end of section [ ssec : finite ] , which is valid for both ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) .",
    "decomposing it as @xmath180 for @xmath181 , we may translate these @xmath17 constraints to ( [ equ : gencop ] ) as @xmath182 for appropriatly defined matrices matrices @xmath183 .",
    "then they may be linearized and added to our relaxation as @xmath184 .    to summarize , let @xmath185 denote the set of @xmath186 satisfying all the derived rlt constraints , and similarly , define @xmath187 as the set of @xmath186 satisfying all the derived soc - rlt constraints .",
    "then the sdp - based conic relaxation for ( [ equ : gencop ] ) that we propose to solve is    @xmath188    it is worth mentioning that , in many cases , the rlt and soc - rlt constraints will already imply @xmath149 , but in such cases , we nevertheless write the constraint in ( [ equ : gensdp ] ) for emphasis ; see also section [ ssec : boundsfeas ] below .",
    "when translated to the problem ( [ equ : quadbarp- ] ) for calculating @xmath13 , the relaxation ( [ equ : gensdp ] ) gives rise to a lower bound @xmath189 .",
    "similarly , when applied to ( [ equ : quadbarp+ ] ) , we get an upper bound @xmath190 .      in this section ,",
    "we discuss two methods to approximate @xmath13 from above and @xmath14 from below , i.e. , to bound @xmath13 and @xmath14 using feasible solutions of ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) , respectively .",
    "the first method , which has been inspired by @xcite , utilizes the optimal solution of the sdp relaxation ( [ equ : gensdp ] ) .",
    "let us discuss how to obtain such a bound for ( [ equ : quadbarp- ] ) , as the discussion for ( [ equ : quadbarp+ ] ) is similar .",
    "we first observe that any feasible solution @xmath191 of ( [ equ : gensdp ] ) satisfies @xmath151 and @xmath149 , i.e. , @xmath192 satisfies all of the constraints of ( [ equ : genqp ] ) . since ( [ equ : genqp ] ) is equivalent to ( [ equ : quadbarp- ] ) under the translation discussed in the proof of theorem [ the : cop ] , @xmath192 gives rise to a feasible solution @xmath193 of ( [ equ : quadbarp- ] ) . from this feasible solution , we can calculate @xmath194 . in practice",
    ", we will start from the optimal solution @xmath195 of ( [ equ : gensdp ] ) .",
    "we summarize this approach in the following remark .",
    "[ rem : bound ] suppose that @xmath195 is an optimal solution of the relaxation ( [ equ : gensdp ] ) corresponding to ( [ equ : quadbarp- ] ) , and let @xmath196 be the translation of @xmath197 to a feasible point of ( [ equ : quadbarp- ] ) .",
    "then , @xmath198 .",
    "similarly , we define @xmath199 based on an optimal solution @xmath200 of ( [ equ : gensdp ] ) corresponding to ( [ equ : quadbarp+ ] ) .    our second method for bounding @xmath13 and @xmath14 using feasible solutions is a sampling procedure detailed in algorithm [ algo : a1 ] .",
    "the main idea is to generate randomly a point @xmath201 and then to calculate @xmath60 , which serves as an upper bound of @xmath0 and a lower bound of @xmath1 , i.e. , @xmath202 .",
    "multiple points @xmath203 and values @xmath204 are generated and the best bounds @xmath205 and @xmath206 are saved .",
    "in fact , by the bilinearity of ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) , we we may restrict attention to the extreme points @xmath50 of @xmath113 without reducing the quality of the resultant bounds ; see also the discussion in section [ ssec : complexity ] .",
    "hence , algorithm [ algo : a1 ] generates  with high probability  a random extreme point of @xmath113 by optimizing a random linear objective over @xmath113 , and we generate the random linear objective as a vector uniform on the sphere , which is implemented by a well - known , quick procedure . note that , even though the random objective is generated according to a specific distribution , we can not predict the resulting distribution over the extreme points of @xmath113 .",
    "* inputs : * instance with uncertainty set @xmath12 and restricted uncertainty set @xmath113 .",
    "number of random trials @xmath207",
    ". * outputs : * bounds @xmath208 and @xmath209 .",
    "generate @xmath210 uniformly on the unit sphere .",
    "calculate @xmath211 .",
    "set @xmath204 .",
    "as all four of the bounds @xmath212 , and @xmath213 are constructed from feasible solutions , we can further improve them heuristically by exploiting the bilinear objective functions in ( [ equ : quadbarp- ] ) and ( [ equ : quadbarp+ ] ) .",
    "in particular , we employ the standard local improvement heuristic for programs with a bilinear objective and convex constraints ( e.g. , see @xcite ) .",
    "suppose , for example , that we have a feasible point @xmath214 for problem ( [ equ : quadbarp- ] ) as discussed in remark [ rem : bound ] . to attempt to improve the solution",
    ", we fix the variable @xmath54 in ( [ equ : quadbarp- ] ) at the value @xmath215 , and we solve the resulting convex problem for a new , hopefully better point @xmath216 , where @xmath217 .",
    "then , we fix @xmath218 to @xmath219 , resolve , and get a new point @xmath220 , where @xmath221 .",
    "this alternating process is repeated until there is no further improvement in the objective of ( [ equ : quadbarp- ] ) , and the final objective is our bound @xmath222 .    in section [ sec : expr ]",
    "below , we use the bounds @xmath222 , @xmath223 , @xmath224 , and @xmath213 to verify the quality of our bounds @xmath225 and @xmath226 .",
    "our tests indicate that neither bound , @xmath222 nor @xmath224 , dominates the other  and similarly for the bounds @xmath223 and @xmath213 .",
    "hence , we will actually report the better of each pair : @xmath227 and @xmath228 . also , for the calculations of @xmath224 and @xmath213 , we always take @xmath229 in algorithm [ algo : a1 ] .",
    "in this section , we validate our approach by testing it on six examples from the literature as well as an example of our own making .",
    "the first three examples in section [ ssec : sa_literature ] correspond to classical sensitivity analysis approaches for lp ; the fourth example in section [ ssec : inventory ] corresponds to an interval lp in inventory management ; the fifth example in section [ ssec : sysrisk ] corresponds to a systemic - risk calculation in financial systems ; and the last example in section [ ssec : networkflow ] is a transportation network flow problem .",
    "we implement our tests in python ( version 2.7.6 ) with mosek ( version 7.1.0.33 ) as our convex - optimization solver .",
    "all of mosek s settings are set at their defaults , and computations are conducted on a macintosh os x yosemite system with a quad - core 3.20ghz intel core i5 cpu and 8 gb ram .      consider the following nominal problem from @xcite : @xmath230 the optimal basis is @xmath231 with optimal solution @xmath232 and optimal value @xmath233 .",
    "according to standard , `` textbook '' sensitivity analysis , the optimal basis persists when the coefficient of @xmath234 lies in the interval @xmath235 $ ] and other parameters remain the same . along this interval , one can easily compute the best - case value @xmath236 and worst - case value @xmath237 , and we attempt to reproduce this analysis with our approach .",
    "so let us choose the uncertainty set @xmath238 \\\\",
    "c_2 =   \\dots = c_6 = 0 \\end{array } \\right\\},\\ ] ] which corresponds precisely to the above allowable decrease and increase on the coefficient of @xmath234 .",
    "note that assumptions [ assmp : a1 ] and [ assmp : a2 ] are satisfied .",
    "we thus know from above that @xmath239 and @xmath240 .",
    "since @xmath96 in @xmath12 , remark [ rem : polytime_b0 ] implies that @xmath14 is easy to calculate .",
    "so we apply our approach , i.e. , solving the sdp - based relaxation , to approximate @xmath13 .",
    "the relaxation value is @xmath241 , which recovers @xmath13 exactly .",
    "the cpu time for computing @xmath225 is 0.10 seconds .",
    "our second example is also based on the same nominal problem from @xcite , but we consider the 100%-rule .",
    "again , we know that the optimal basis @xmath242 persists when the coefficient of @xmath234 lies in the interval @xmath235 $ ] ( and all other parameters remain the same ) or separately when the coefficient of @xmath243 lies in the interval @xmath244 $ ] ( and all other parameters remain the same ) . in accordance with the 100%-rule , we choose to decrease the coefficient of @xmath234 , and thus its allowed interval is @xmath245 $ ] of width 4 .",
    "we also choose to decrease the coefficient of @xmath243 , and thus its allowed interval is @xmath246 $ ] of width @xmath247 .",
    "the 100%-rule ensures that the optimal basis persists as long as the sum of fractions , corresponding to the percent of maximum changes in the coefficients of @xmath234 and @xmath243 , is less than or equal to 1 .",
    "in other words , suppose that @xmath248 and @xmath249 are the perturbed values of the coefficients of @xmath234 and @xmath243 , respectively , and that all other coefficients stay the same .",
    "then the nominal optimal basis persists for @xmath250 in the following simplex : @xmath251 \\\\",
    "\\tilde c_2 \\in [ -134/3,-18 ] \\\\    \\tfrac{-12 - \\tilde c_1}{4 } + \\tfrac{-18 - \\tilde c_2}{80/3 } \\le 1 \\end{array } \\right\\}.\\ ] ] by evaluating the three extreme points @xmath252 , @xmath253 and @xmath254 of this set with respect to the nominal optimal solution , one can calculate the best - case optimal value as @xmath255 and the worst - case optimal value as @xmath256 .",
    "we again apply our approach in an attempt to recover empirically the 100%-rule .",
    "specifically , let @xmath257 , \\",
    "c_2 \\in [ -\\frac{80}{3},0 ] \\\\    - \\tfrac{c_1}{4 } - \\tfrac{c_2}{80/3 } \\le 1 \\\\",
    "c_3 =   \\dots = c_6 = 0 \\end{array } \\right\\}.\\ ] ] note that assumptions [ assmp : a1 ] and [ assmp : a2 ] are satisfied . due to @xmath258 and remark [ rem : polytime_b0 ] ,",
    "we focus our attention on @xmath13 . calculating the sdp - based relaxation value",
    ", we see that @xmath241 , which recovers @xmath13 precisely .",
    "the cpu time is 0.15 seconds    our third example illustrates the tolerance approach , and we continue to use the same nominal problem from @xcite . as mentioned in the introduction , the tolerance approach considers simultaneous and independent perturbations in the objective coefficients by calculating a maximum tolerance percentage such that , as long as selected coefficients are accurate to within that percentage of their nominal values , the nominal optimal basis persists ; see @xcite .",
    "let us consider perturbations in the coefficients of @xmath234 and @xmath243 with respect to the nominal problem . applying the tolerance approach of @xcite ,",
    "the maximum tolerance percentage is @xmath259 in this case .",
    "that is , as long as the two coefficient values vary within @xmath260 $ ] and @xmath261 $ ] , respectively , then the nominal optimal basis @xmath231 persists . by testing the four extreme points of the box of changes @xmath262 \\times [ -21,-15]$ ] with respect to the optimal nominal solution , one can calculate the best - case optimal value as @xmath263 and the worst - case optimal value as @xmath240 . to test our approach in this setting , we set @xmath264 , c_2 \\in [ -3,3 ]   \\end{array } \\right\\}\\ ] ] and , as in the previous two examples , we focus on @xmath13 .",
    "assumptions [ assmp : a1 ] and [ assmp : a2 ] are again satisfied , and we calculate the lower bound @xmath265 , which recovers @xmath13 precisely .",
    "the cpu time for computing @xmath225 is 0.13 seconds .",
    "we consider an optimization problem that is typical in inventory management , and this particular example originates from @xcite .",
    "suppose one must decide the quantity to be ordered during each period of a finite , discrete horizon consisting of @xmath207 periods .",
    "the goal is to satisfy exogenous demands @xmath266 for each period @xmath43 , while simultaneously minimizing the total of purchasing , holding , and shortage costs .",
    "introduce the following variables for each period @xmath43 : @xmath267 items ordered at the beginning of period @xmath43 are delivered in time to satisfy demand during the same period .",
    "any excess demand is backlogged .",
    "hence , each @xmath268 is nonnegative , each @xmath269 is free , and @xmath270 the order quantities @xmath268 are further subject to uniform upper and lower bounds , @xmath271 and @xmath272 , and every stock level @xmath269 is bounded above by @xmath273 . at time @xmath43 , the purchase cost is denoted as @xmath274 , the holding cost is denoted as @xmath275 , and the shortage cost is denoted @xmath276 .",
    "then , the problem can be formulated as the following linear programming problem ( assuming that the initial inventory is 0 ) : @xmath277    as in @xcite , consider an instance of ( [ equ : ilp ] ) in which @xmath278 , @xmath279 @xmath280 , and all costs are as in table [ tab : inv_costs ] . moreover , suppose the demands @xmath266 are each uncertain and may be estimated by the intervals @xmath281 , d_2 \\in [ 1300 , 1600 ] , d_3 \\in [ 900 , 1100],$ ] and @xmath282 $ ] . from @xcite , the worst - case optimal value over this uncertainty set is @xmath283 . for our approach ,",
    "it is easy to verify that assumptions [ assmp : a1 ] and [ assmp : a2 ] are satisfied , and solving our sdp - based conic relaxation with an uncertainty set corresponding to the intervals on @xmath266 , we recover @xmath14 exactly , i.e. , we have @xmath284 .",
    "the cpu time for computing our sdp optimal value is 1,542 seconds .",
    ".costs for each period of an instance of the inventory management problem [ cols=\"^,^,^,^,^\",options=\"header \" , ]",
    "in this paper , we have introduced the idea of robust sensitivity analysis for the optimal value of lp . in particular , we have discussed the best- and worst - case optimal values under general perturbations in the objective coefficients and right - hand sides .",
    "we have also presented finite variants that avoid cases of infeasibility and unboundedness . as the involved problems are nonconvex and very difficult to solve in general , we have proposed copositive reformulations , which provide a theoretical basis for constructing tractable sdp - based relaxations that take into account the nature of the uncertainty set , e.g. , through rlt and soc - rlt constraints .",
    "numerical experiments have indicated that our approach works very well on examples from , and inspired by , the literature . in future research",
    ", it would be interesting to improve the solution speed of the largest relaxations and to explore the possibility of also handling perturbations in the constraint matrix .",
    "the first author acknowledges the financial support of the afrl mathematical modeling and optimization institute , where he visited in summer 2015 . the second author acknowledges the financial support of karthik natarajan ( singapore university of technology and design ) and chung piaw teo ( national university of singapore ) , whom he visited in fall 2014 .",
    "this research has benefitted from their many insightful comments ."
  ],
  "abstract_text": [
    "<S> we propose a framework for sensitivity analysis of linear programs ( lps ) in minimization form , allowing for simultaneous perturbations in the objective coefficients and right - hand sides , where the perturbations are modeled in a compact , convex uncertainty set . </S>",
    "<S> this framework unifies and extends multiple approaches for lp sensitivity analysis in the literature and has close ties to worst - case linear optimization and two - stage adaptive optimization . </S>",
    "<S> we define the minimum ( best - case ) and maximum ( worst - case ) lp optimal values , @xmath0 and @xmath1 , over the uncertainty set , and we discuss issues of finiteness , attainability , and computational complexity . while @xmath0 and @xmath1 are difficult to compute in general , we prove that they equal the optimal values of two separate , but related , copositive programs . </S>",
    "<S> we then develop tight , tractable conic relaxations to provide lower and upper bounds on @xmath0 and @xmath1 , respectively . </S>",
    "<S> we also develop techniques to assess the quality of the bounds , and we validate our approach computationally on several examples from  and inspired by  the literature . </S>",
    "<S> we find that the bounds on @xmath0 and @xmath1 are very strong in practice and , in particular , are at least as strong as known results for specific cases from the literature .    </S>",
    "<S> keywords : sensitivity analysis , minimax problem , nonconvex quadratic programming , semidefinite programming , copositive programming , uncertainty set . </S>"
  ]
}