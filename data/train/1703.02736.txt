{
  "article_text": [
    "functional data analysis has generated increasing interest in recent years in many areas , including biology , chemometrics , econometrics , geophysics , medical sciences , meteorology , etc .",
    "functional data are made up of repeated measurements taken as curves , surfaces or other objects varying over a continuum , such as the time and space . in many experiments , such as clinical diagnosis of neurological diseases from the brain imaging data ,",
    "functional data appear as the basic unit of observations . as a natural extension of the multivariate data analysis ,",
    "functional data analysis provides valuable insights into these experiments , taking into account the underlying smoothness of high - dimensional covariates and provides new approaches for solving inference problems .",
    "one may refer to the monographs of ramsay and silverman @xcite , ferraty and vieu @xcite and horvth and kokoszka @xcite for a general overview on functional data analysis .",
    "motivated by more complicated data structures , which appeal to more comprehensive , flexible and adaptable models , in this paper we investigate the following _ partial functional partially linear single - index model _ : @xmath0 where @xmath1 is a random function defined on some bounded interval @xmath2 , @xmath3 is an unknown square integrable slope function on @xmath2 , @xmath4 is a @xmath5 vector of covariates , @xmath6 is a @xmath5 unknown coefficient vectors , @xmath7 is a @xmath8 vector of covariates , @xmath9 is a @xmath8 coefficient vector to be estimated , @xmath10 is an unknown link function and @xmath11 is a random error with mean zero that is independent of the covariates @xmath12 .    model ( 1.1 ) is more flexible and can deal with more complicated data structures . to the best of our knowledge , this model has not been fully studied in the literature yet .",
    "it consists of a functional linear component as well as a linear single - index component .",
    "this model generalizes many well - known existing models and is suitable for more complicated data structures .",
    "however , its estimation inherits some difficulties and complexities from both components and makes it a challenging problem , which calls for new methodology .",
    "we propose a novel profile b - spline method to estimate the parameters by approximating the unknown nonparametric link function in the single - index component part with b - spline , while the linear slope function in the functional component part is estimated by the functional principal component basis .",
    "more specially , model ( 1.1 ) can be interpreted from two perspectives .",
    "first , it generalizes the partial functional linear models @xmath13 by adding a nonparametric component , @xmath14 with an unknown univariate link function @xmath15 this single - index term reduces the dimensionality from the multivariate predictors to a univariate index @xmath16 and avoids the curse of dimensionality , while still capturing important features in high - dimensional data . furthermore , since a nonlinear link function @xmath10 is applied to the index @xmath17 interactions between the covariates @xmath18 can be modeled . the standard functional linear model @xcite with scalar response @xmath19 has the same form as model ( 1.2 ) without the linear part . in general",
    ", @xmath1 can be a multivariate functional variable , but here we shall only focus on the univariate case .",
    "the main interest is estimation of functional coefficient @xmath3 based on a sample @xmath20 generated from model ( 1.2 ) .",
    "there are number of articles in the literature discussing the slope estimation in model ( 1.2 ) using methods such as the penalized spline method @xcite , the functional principal component analysis @xcite and the functional partial least squares method @xcite , among others .",
    "second , model ( 1.1 ) can be considered as a generalization of the partially linear single - index model @xcite , @xmath21 with an addition of functional covariates @xmath22 the partially linear single - index model ( 1.3 ) was first explored by carroll et al .",
    "in fact , the autors considered a more generalized version , where a known link function is employed in the regression function , while model ( 1.3 ) assumes an identity link function .",
    "model ( 1.3 ) has also been studied by many other authors , including xia et al .",
    "@xcite xia and hrdle @xcite , liang et al .",
    "@xcite and wang et al .",
    "@xcite to name a few .    to tackle the challenging estimation problem ,",
    "our innovation is to propose a _ profile b - spline _ ( pbs ) method to estimate the unknown parameters @xmath23 by employing a b - spline function to approximate the unknown link function @xmath10 and using the functional principal component analysis ( fpca ) to estimate the slope function @xmath3 . under some regularity conditions ,",
    "we prove the consistency and asymptotic normality of the proposed estimators .",
    "we also establish a global rate of convergence of the estimator of @xmath3 , and it is shown to be optimal in the minimax sense of hall and horowitz @xcite . based on the estimators of parameters , another b - spline function is employed to approximate the function @xmath10 and then the optimal global convergence rate of the approximation is established .",
    "we also obtain convergence rates of the mean squared prediction error for a predictor . for model ( 1.3 ) , yu and",
    "ruppert @xcite studied asymptotic properties of their estimators of @xmath24 under the condition that the link function @xmath10 falls in a finite - dimensional spline space .",
    "we note here that the asymptotic properties of all our estimators are derived under the assumption that @xmath10 can be well approximated by spline functions with increasing the number of knots .    to gain more flexibility and partly motivated by applications ,",
    "a number of other models based on the standard functional linear model have been studied in the literature , including the partial functional linear regression model ( 1.2 ) @xcite , a generalized functional linear model @xcite , single and multiple index functional regression models @xcite and a functional partial linear single - index model @xcite among others .",
    "the paper is organized as follows .",
    "section 2 describes the proposed profile estimation method .",
    "section 3 presents asymptotic results of our estimator . in section 4",
    ", we conduct simulation studies to examine the finite sample performance of the proposed procedures . in section 5 ,",
    "the proposed method is illustrated by analyzing a diffusion tensor imaging ( dti ) data set from the alzheimer s disease neuroimaging initiative ( adni ) database ( adni.loni.ucla.edu ) .",
    "finally , section 6 contains some concluding remarks .",
    "all proofs are relegated to the appendix .",
    "let @xmath19 be a real - valued response variable and @xmath25 be a mean zero second - order ( i.e. , @xmath26 for all @xmath27 stochastic process with sample paths in @xmath28 , the set of all square integrable functions on @xmath2 , where @xmath2 is a bounded closed interval .",
    "let @xmath29 and @xmath30 denote the @xmath28 inner product and norm , respectively .",
    "denote the covariance function of the process @xmath1 by @xmath31 .",
    "we suppose that @xmath32 is positive definite .",
    "then @xmath32 admits a spectral decomposition in terms of strictly positive eigenvalues @xmath33 : @xmath34 where @xmath33 and @xmath35 are eigenvalue and eigenfunction pairs of the linear operator with kernel @xmath36 , the eigenvalues are ordered so that @xmath37 and eigenfunctions @xmath38 form an orthonormal basis for @xmath28 .",
    "this leads to the karhunen - love representation @xmath39 where @xmath40 are uncorrelated random variables with mean zero and variance @xmath41 .",
    "let @xmath42 .",
    "then model ( 1.1 ) can be written as @xmath43 by ( 2.2 ) , we have @xmath44\\xi_{j}% \\}/\\lambda_{j}.\\tag{2.3}\\ ] ] let @xmath45 , be independent realizations generated from model ( 1.1 ) .",
    "then the empirical versions of @xmath36 and of its spectral decomposition are @xmath46 analogously to the case of @xmath36 , @xmath47 are ( eigenvalue , eigenfunction ) pairs for the linear operator with kernel @xmath48 , ordered such that @xmath49 .",
    "we take @xmath47 and @xmath50 to be the estimators of @xmath51 and @xmath52 respectively , and take @xmath53 \\hat{\\xi}% _ { ij}\\tag{2.5}\\ ] ] to be the estimator of @xmath54 .    in order to estimate @xmath10 ,",
    "we adapt spline approximations .",
    "we assume that @xmath55 and that the last element @xmath56 of @xmath9 is positive , to ensure identifiability .",
    "let @xmath57 and @xmath58 .",
    "since @xmath59 , there exists a constant @xmath60 such that @xmath61 .",
    "suppose that the distribution of @xmath18 has a compact support set @xmath62 .",
    "denote @xmath63 and @xmath64 .",
    "we first split the interval @xmath65 $ ] into @xmath66 subintervals with knots @xmath67 . for fixed @xmath68 ,",
    "suppose @xmath69 .",
    "let @xmath70 and @xmath71 .",
    "for any fixed integer @xmath72 , let @xmath73 be the set of spline functions of degree @xmath74 with knots @xmath75 ; that is , a function @xmath76 belongs to @xmath73 if and only if @xmath76 belongs to @xmath77 $ ] and its restriction to each @xmath78 is a polynomial of degree at most @xmath74 .",
    "put @xmath79(w - u)_{+}^{s},\\ \\ \\ \\ k=1,\\ldots , k_{\\beta},\\tag{2.6}\\ ] ] where @xmath80 , @xmath81f$ ] denotes the @xmath82th - order divided difference of the function @xmath83 , @xmath84 for @xmath85 , @xmath86 for @xmath87 , and @xmath88 for @xmath89 . then @xmath90 form a basis for @xmath73 .    for fixed @xmath91 and @xmath68",
    ", we use @xmath92 to approximate @xmath93 in ( 2.2 ) and use @xmath94 to approximate @xmath95 for @xmath96 $ ] .",
    "we then estimate @xmath97 by minimizing @xmath98 \\hat{\\xi}_{lj}-\\\\ & w_{i}^{t}\\pmb{\\alpha}-\\sum_{k=1}^{k_{\\pmb{\\beta}}}% b_{k}b_{k\\pmb{\\beta}}(z_{i}^{t}\\pmb{\\beta})\\bigg\\ } ^{2}\\tag{2.7}\\end{aligned}\\ ] ] with respect to @xmath99 , where @xmath100 is a smoothing parameter which denotes a frequency cut - off .",
    "define @xmath101 , @xmath102 , @xmath103 and @xmath104 .",
    "then ( 2.7 ) can be written as @xmath105 denote @xmath106 , @xmath107 @xmath108 , @xmath109 , @xmath110 and @xmath111 .",
    "if @xmath112 is invertible , then the estimator @xmath113 of @xmath114 is given by @xmath115 we solve the following minimization problem @xmath116 to obtain the estimators @xmath117 and @xmath118 .",
    "a newton - raphson algorithm can be applied for the minimization .",
    "an estimator of @xmath114 is obtained by solving the following minimization problem @xmath119 and then @xmath120 is given by @xmath121 let @xmath122 for @xmath123 $ ] .",
    "we then choose a new tuning parameter @xmath124 and an estimator of @xmath3 given by @xmath125 with @xmath126    in order to construct an estimator of @xmath10 that achieves the optimal rate of convergence , we select new knots and new b - spline basis based on the estimators @xmath117 and @xmath127 let @xmath128 be new knots and @xmath129 be a new basis , where @xmath130",
    ". then @xmath131 , @xmath132 and @xmath133 are defined similarly as @xmath134 , @xmath135 and @xmath136 respectively .",
    "we then solve the following minimization problem @xmath137 to obtain an estimator of @xmath138 , where @xmath139 .",
    "if @xmath140 is invertible , then an estimator of @xmath138 is given by @xmath141 the second stage estimator of @xmath95 is then equal to @xmath142 for @xmath143 $ ] .    to implement our estimation method , some appropriate values for @xmath100 , @xmath124 , @xmath66 and @xmath144 are necessary . from our simulation in section 4",
    "below , we observe that the parametric estimators @xmath145 and @xmath118 are not sensitive to the choices of @xmath100 and @xmath66 , they can be chosen subjectively . in the simulation in section 4 , we also choose @xmath146 with @xmath147 , where @xmath74 is defined in assumption 4 in section 3 below .",
    "the value for tuning parameter @xmath124 can be selected by information criteria bic , which is given by @xmath148 large values of @xmath149 indicate either poor fidelity to the data or overfitting because @xmath124 is too large . a value for @xmath144 can also be selected by the following bic information criteria : @xmath150 in practice",
    ", the proposed estimation method is implemented using the following steps :    * step 1 . * choose an @xmath100 and fit a partial functional linear model ; that is , solve the minimization problem ( 2.8 ) with the link function @xmath10 replaced by a linear function to obtain initial values @xmath151 and @xmath152 . then set @xmath153 , and multiply it by @xmath154 if necessary .",
    "* step 2 . * construct the b - spline basis @xmath155 based on the computed @xmath156 and @xmath157 .",
    "then obtain @xmath158 from ( 2.9 ) and solve the minimizing problem ( 2.10 ) to obtain the estimators @xmath145 and @xmath118 .",
    "* step 3 . *",
    "compute @xmath159 and @xmath160 from ( 2.12 ) and ( 2.13 ) , respectively , and obtain the estimator @xmath161 .",
    "* step 4 . * compute @xmath162 and @xmath163 and construct the basis @xmath164 . then obtain the estimator @xmath165 from ( 2.15 ) and obtain the estimator @xmath166 .",
    "* remark  2.1 . * in practical applications",
    ", @xmath1 is only discretely observed . without loss of generality ,",
    "suppose for each @xmath167 , @xmath168 is observed at @xmath169 discrete points @xmath170 . then linear interpolation functions or spline interpolation functions can be used for the estimators of @xmath168 .",
    "* remark  2.2 *  though the basis function @xmath171 depends on @xmath68 , we see from ( 2.6 ) that the total number of all the different @xmath171 is not more than @xmath172 . in certain practical applications where the sample size @xmath173 is not large enough and @xmath174 is not small enough , one can choose @xmath175 and @xmath176 and construct the basis @xmath90 with knots @xmath177 to make full use of the data .",
    "that is , the intervals @xmath178 $ ] and @xmath179 $ ] are replaced by @xmath180 $ ] and @xmath181,$ ] respectively .",
    "in this section we establish the asymptotic normality and convergence rates of the estimators proposed in the previous section . before stating main results , we first state a few assumptions that are necessary to prove the theoretical results .",
    "* assumption 1 . *  @xmath182 and @xmath183 . @xmath184 and @xmath185 for @xmath186 and @xmath187 . for each @xmath188 , @xmath189 for @xmath190 , where @xmath191 is a constant . for any sequence @xmath192 , @xmath193 @xmath194 unless each index @xmath195 is repeated .",
    "* assumption 2 .",
    "* there exists a convex function @xmath196 defined on the interval @xmath197 $ ] such that @xmath198 and @xmath199 for @xmath188 .",
    "* assumption 3 .",
    "*  for fourier coefficients @xmath54 , there exist constants @xmath200 and @xmath201 such that @xmath202 for all @xmath188 .",
    "* assumption 4 .",
    "* the function @xmath95 is a @xmath74-times continuously differentiable function such that @xmath203 , for @xmath204 and @xmath205 , with constants @xmath206 and @xmath207 the knots @xmath208 satisfy that @xmath209 , where @xmath210 and @xmath211 is a constant .",
    "* assumption 5 .",
    "* @xmath212 , @xmath213 , @xmath214 and @xmath215 .",
    "* assumption 5. * @xmath216 , @xmath217 , @xmath218 , @xmath219 @xmath220 and @xmath221 .",
    "* assumption 6 . *",
    "the distribution of @xmath18 has a compact support set @xmath62 .",
    "the marginal density function @xmath222 of @xmath223 is bounded away from zero and infinity for @xmath224 $ ] and satisfies that @xmath225 for @xmath68 in a small neighborhood of @xmath9 and @xmath226 $ ] , where @xmath227 and @xmath228 are two positive constants .",
    "* assumption 7 .",
    "* @xmath229 , @xmath230 , @xmath231 and @xmath232 for all @xmath188 and @xmath233 , where @xmath234 is a constant .",
    "@xmath235 is independent of @xmath236 and @xmath237 .    under assumption 4 , according to corollary 6.21 of schumaker ( 1981 , p.227 ) , there exists a spline function @xmath238 and a constant @xmath239 such that , for @xmath240 , @xmath241}|r^{(k)}(u)|\\leq c_{7}h_{0}^{p - k}\\tag{3.1}\\ ] ] where @xmath242 .",
    "let @xmath243 and @xmath244 .",
    "define @xmath245{ll}% g(\\pmb{\\alpha},\\pmb{\\beta } ) & = \\left\\{(\\pmb{\\alpha}-\\pmb{\\alpha}_{0})^{t}% e(vv^{t})-2\\pmb{b}_{0}^{t}% e[\\pmb{b}_{\\pmb{\\beta}_{0}}(z^{t}\\pmb{\\beta}_{0})v^{t}% ] \\right\\}(\\pmb{\\alpha}-\\pmb{\\alpha}_{0})\\\\ & + \\pmb{b}_{0}^{t}\\gamma(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0})\\pmb{b}_{0}-\\pi ^{t}(\\pmb{\\alpha},\\pmb{\\beta})\\gamma^{-1}(\\pmb{\\beta},\\pmb{\\beta})\\pi ( \\pmb{\\alpha},\\pmb{\\beta})+\\sigma^{2 } , \\end{array } \\tag{3.2}\\ ] ] where @xmath246 with @xmath247 @xmath248 $ ] and @xmath249(\\pmb{\\alpha}-\\pmb{\\alpha}_{0}% ) $ ] .",
    "put @xmath250 , @xmath251,@xmath252 and @xmath253 .",
    "define @xmath254 and its hessian matrix @xmath255    * assumption 8 .",
    "* @xmath256 is locally convex at @xmath257 such that for any @xmath258 , there exists some @xmath259 such that @xmath260 holds whenever @xmath261 . furthermore",
    ", the hessian matrix @xmath262 is continuous in some neighborhood of @xmath257 and @xmath263 .",
    "* assumption 9 . * the knots @xmath264 satisfy that @xmath265 , where @xmath266 and @xmath267 is a constant .",
    "further , @xmath268 and @xmath269 .",
    "assumptions 1 and 3 are standard conditions for functional linear models ; see , e.g. , cai and hall @xcite and hall and horowitz @xcite .",
    "assumption 2 is slightly less restrictive than ( 3.2 ) of hall and horowitz @xcite .",
    "the quantity @xmath270 in assumption 4 is the order of smoothness of the function @xmath95",
    ". assumptions 5 and 5 can be easily verified and will be further discussed below .",
    "assumption 6 ensures the existence and uniqueness of the spline estimator of the function @xmath95 .",
    "if the marginal density @xmath222 of @xmath223 is uniformly continuous for @xmath68 in some neighborhood of @xmath271 then the second part of assumption 6 is easily satisfied by modifying the knots .",
    "assumption 8 ensures the existence and uniqueness of the estimator of @xmath257 in a neighborhood of @xmath257",
    ".    * remark  3.1 . *  if @xmath272 , @xmath273 and @xmath274 , then assumption 5 holds when @xmath275 and @xmath276 , where @xmath277 , @xmath278 and @xmath279 are constants and the notation @xmath280 means that the ratio @xmath281 is bounded away from zero and infinity .",
    "the next theorem gives the consistency and convergence rate of the estimators of @xmath6 and @xmath282 .",
    "* theorem  3.1 .",
    "*  ( i ) suppose that assumptions 1 to 4 , 5 , 6 and 7 hold , and that @xmath256 is locally convex at @xmath257 .",
    "then , as @xmath283 , @xmath284 where @xmath285 means convergence in probability .",
    "\\(ii )  suppose that assumptions 1 to 8 hold .",
    "then @xmath286    in order to establish the asymptotic distributions of the estimators @xmath117 and @xmath287 , we first introduce some notation .",
    "define @xmath288 if @xmath289",
    "then by ( 3.4 ) we have @xmath290 for sufficiently large @xmath173 .",
    "if @xmath291 , then we modify @xmath292 such that @xmath293 , and also we then have @xmath294 .",
    "similarly , if @xmath295 , then we modify @xmath296 such that @xmath297 , and then we have @xmath298 . therefore , if necessary , we first modify the knots @xmath299 , so that there exists a neighborhood @xmath300 of @xmath282 such that @xmath301 , @xmath302 for @xmath303 and @xmath304 for sufficiently large @xmath173 .",
    "let @xmath305 , @xmath306 and @xmath307 . for @xmath303 , we have @xmath308 , @xmath309 and @xmath310 .",
    "further , we have @xmath245{ll}% g_{n}(\\pmb{\\alpha},\\pmb{\\beta } ) & = \\frac{1}{n}\\sum_{i=1}^{n}\\left\\ { \\tilde { y}_{i}-\\tilde{w}_{i}^{t}\\pmb{\\alpha}-\\sum_{k=1}^{k_{n}}\\tilde{b}% _ { k}(\\pmb{\\alpha},\\pmb{\\beta})\\tilde{b}_{k}(z_{i}^{t}\\pmb{\\beta})\\right\\ } ^{2}\\\\ & = \\frac{1}{n}\\left\\ { \\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}-\\tilde { \\pmb{b}}(\\pmb{\\beta})\\tilde{\\pmb{b}}(\\pmb{\\alpha},\\pmb{\\beta})\\right\\ } ^{t}\\left\\ { \\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}-\\tilde{\\pmb{b}}% ( \\pmb{\\beta})\\tilde{\\pmb{b}}(\\pmb{\\alpha},\\pmb{\\beta})\\right\\ } , \\end{array}\\ ] ] @xmath311 , where @xmath312 since @xmath313 is the minimizer of @xmath314 , then @xmath315 is the minimizer of @xmath316 , where @xmath317 @xmath318 .",
    "hence , @xmath319 @xmath320 for @xmath321 , where @xmath322 . set @xmath323,@xmath324 .",
    "then from ( 3.6 ) and ( 3.7 ) and using a taylor expansion , we obtain @xmath325 where @xmath326 is a @xmath327 matrix and @xmath328 is between @xmath329 and @xmath257 . let @xmath330 with @xmath331^{t}\\gamma ^{-1}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0})e[\\pmb{b}(z^{t}\\pmb{\\beta}_{0}% ) v_{r}],\\ \\ k , r=1,\\ldots , q,\\]]@xmath332^{t}% \\pmb{b}_{0}-e[\\pmb{b}(z^{t}\\pmb{\\beta}_{0})v_{k}]^{t}\\gamma^{-1}% ( \\pmb{\\beta}_{0},\\pmb{\\beta}_{0})h_{r}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0}% ) \\pmb{b}_{0},\\ ] ] @xmath333 for @xmath334 , and @xmath335 for @xmath336 , where @xmath337 , and @xmath338 , @xmath339 and @xmath340 are @xmath341 matrices whose @xmath342th elements are @xmath343 $ ] and @xmath344,$ ] respectively , and @xmath345 .",
    "* theorem  3.2 .",
    "*  suppose that assumptions 1 to 8 hold and that @xmath346 is invertible .",
    "then we have @xmath347 where @xmath348 is the @xmath327 identity matrix .",
    "next we establish the convergence rates of the estimators @xmath161 and @xmath349 .    * theorem  3.3 .",
    "*  assume that assumptions 1 to 8 hold and that @xmath350 , @xmath351 . then @xmath352    if @xmath272 , @xmath353 , @xmath354 and @xmath355 , then @xmath356 and @xmath357 , where @xmath358 is a positive constant",
    ". then we have the following corollary .",
    "* corollary  3.1 . *  under assumptions 1 to 8 , if @xmath359 , @xmath353 and @xmath360 , then it follows that @xmath361    the global convergence result ( 3.11 ) indicates that the estimator @xmath161 attains the same convergence rate as those of the estimators of hall and horowitz @xcite , which are optimal in the minimax sense .    from theorem 3.2",
    ", we have @xmath362 . then for sufficiently large @xmath173 , @xmath363 and @xmath364 .",
    "* theorem  3.4*.  suppose that assumptions 1 to 9 hold .",
    "then , @xmath365 further , if @xmath366 in assumption 9 , then @xmath367    * remark  3.2 .",
    "* under assumptions 1 - 8 and from a proof of similar to that of theorem 3.4 , one can obtain @xmath368 due to the fact that @xmath212 , @xmath369 does not attain the global convergence rate of @xmath370 which is the optimal rate for nonparametric models .",
    "in fact , the assumption that @xmath371 is made in order to make the bias of the estimator @xmath287 in theorem 3.2 negligible .",
    "this results in slower global convergence rate for the estimator @xmath369 .",
    "let @xmath372 .",
    "if @xmath373 is a new vector of outcome and predictor variables taken from the same population as that of the data @xmath374 and are independent of @xmath374 , then the _ mean squared _ _ prediction error _ ( mspe ) of @xmath375 is given by @xmath245{ll}% \\mbox{mspe } & = e\\big[\\big\\{\\int_{\\mathcal{t}}\\hat{a}(t)x_{n+1}(t)dt+w_{n+1}% ^{t}\\hat{\\pmb{\\alpha}}+\\hat{g}(z_{n+1}\\hat{\\pmb{\\beta}})\\\\ & -\\left ( \\int_{\\mathcal{t}}a(t)x_{n+1}(t)dt+w_{n+1}^{t}\\pmb{\\alpha}_{0}% + g(z_{n+1}\\pmb{\\beta}_{0})\\right ) \\big\\}^{2 } \\big|\\mathcal{s}\\big ] .",
    "\\end{array}\\ ] ]    * theorem  3.5*. under assumptions 1 to 4 and 6 to 9 , if @xmath359 , @xmath353 , where @xmath360 , @xmath274 with @xmath376 and @xmath366 , then it follows that @xmath377 furthermore , if @xmath378 then @xmath379    * remark  3.3 . * in theorem 3.5 , it is assumed that @xmath274 and @xmath380 . if @xmath378 , then the conditions that @xmath381 and @xmath382 are required .",
    "the preceding conditions hold when @xmath383 .",
    "in this section we present two monte carlo simulation studies to evaluate the finite - sample performance of the proposed estimator .",
    "the data are generated from the following models @xmath384@xmath385 with @xmath386 $ ] and the trivariate random vectors @xmath387 s have independent components following the uniform distribution on @xmath197 $ ] . in model",
    "( 4.1 ) , @xmath388 , @xmath389 , @xmath390 and @xmath391 .",
    "we let @xmath392 for odd @xmath393 and @xmath394 for even @xmath393 , and the @xmath395 s are independent errors following @xmath396 . we take @xmath397 and @xmath398 , where @xmath399 and @xmath400 ; @xmath401 and @xmath402 ; the @xmath403 s are independently and normally distributed with @xmath404 . in model ( 4.2 ) ,",
    "@xmath405 , @xmath406 , @xmath407 and @xmath398 , the @xmath403 s are independently and normally distributed with @xmath408 , where @xmath409 , @xmath410 if @xmath411 , @xmath412 for @xmath188 and @xmath413 .",
    "further , @xmath414 and @xmath415 for @xmath416 .",
    "the @xmath417 s are independently and normally distributed with @xmath418 and @xmath419 respectively , and independent of @xmath403 .",
    "finally , the error terms @xmath395 s in both ( 4.1 ) and ( 4.2 ) are independent @xmath420 random variables .    for the functional linear part of model ( 4.1 ) ,",
    "the eigenvalues of the operator @xmath36 are well - spaced , while the latter part of model ( 4.1 ) was investigated by carroll et al .",
    "@xcite and yu and ruppert @xcite in model ( 4.2 ) , the eigenvalues of the operator @xmath36 are closely spaced , while the link function @xmath421 is a linear function .",
    "all our results are reported based on the average over 500 replications for each setting . in each sample",
    ", we first use a linear function to replace @xmath95 and use the least squares estimates for the partial functional linear model as an initial estimator . the function @xmath95 is approximated using a cubic spline with equally spaced knots .",
    "we note from our simulation results ( see table 3 ) that parametric estimators are not sensitive to the choices of parameters @xmath174 and @xmath100 . here",
    "we take @xmath422 and @xmath423 with @xmath424 when we compute the estimators of @xmath95 and @xmath3 , the parameters @xmath425 and @xmath100 are selected respectively by the bic given in section 2 .",
    "[ c]lccccccc & & & + & & lspfl & oracle & pbs & lspfl & oracle & pbs + @xmath426 & bias & -0.0019 & 0.0034 & -0.0008 & -0.0025 & 0.0002 & 0.0002 + & sd & 0.0836 & 0.0330 & 0.0307 & 0.0565 & 0.0159 & 0.0122 + @xmath427 & bias & -0.3678 & -0.0066 & -0.0056 & -0.3365 & -0.0037 & 0.0006 + & sd & 0.5445 & 0.0441 & 0.0464 & 0.5141 & 0.0202 & 0.0206 + @xmath428 & bias & -0.3780 & -0.0075 & -0.0031 & -0.3283 & -0.0041 & -0.0018 + & sd & 0.5449 & 0.0457 & 0.0479 & 0.5201 & 0.0263 & 0.0178 + @xmath429 & bias & -0.0771 & 0.0082 & 0.0016 & -0.0553 & 0.0058 & -0.0001 + & sd & 0.2695 & 0.0506 & 0.0599 & 0.2694 & 0.0307 & 0.0239 + @xmath349 & mise & & & 0.0090 & & & 0.0007 + @xmath161 & mise & 0.1205 & 0.0189 & 0.0218 & 0.0756 &",
    "0.0082 & 0.0084 +    table 1 reports the biases and standard deviations ( sd ) of the profile b - spline ( pbs ) estimators @xmath426 , @xmath430 and the mean integrated squared errors ( mise ) of the estimators @xmath349 and @xmath431 for model ( 4.1 ) based on @xmath432 and sample sizes @xmath433 , @xmath434 .",
    "figure 1 displays the true curves and the mean estimated curves over 500 simulations with sample size @xmath433 of @xmath95 , @xmath3 and their @xmath435 pointwise confidence bands .",
    "table 2 reports the biases and standard deviations ( sd ) of the estimators @xmath436 for @xmath416 and @xmath437 , and the mean integrated squared errors ( mise ) of the estimators @xmath349 and @xmath431 for model ( 4.2 ) with @xmath432 and @xmath438 .",
    "for comparison purposes , tables 1 and 2 also list the simulation results based on the least squares partial functional linear ( lspfl ) estimators , which are obtained by using a linear function to approximate the link function @xmath10 .",
    "further , table 1 also lists the simulation results based on the nonlinear least squares ( oracle ) estimation method when the exact form of sinusoidal model is known .",
    "[ c]lccccc & & & + & & lspfl & pbs & lspfl & pbs + @xmath439 & bias ( sd ) & 0.078(6.815 ) & 0.100(6.870 ) & 0.186(4.415 ) & 0.173(4.435 ) + @xmath440 & bias ( sd ) & -0.071(4.612 ) & -0.085(4.666 ) & 0.359(3.038 ) & 0.373(3.056 ) + @xmath441 & bias ( sd ) & -0.707(22.725 ) & -0.753 ( 23.162 ) & 0.942(14.762 ) & 0.816(14.896 ) + @xmath442 & bias ( sd ) & -1.670(18.370 ) & -1.720(18.347 ) & 0.711(11.939 ) & 0.735(11.906 ) + @xmath443 & bias ( sd ) & 1.936(17.630 ) & 2.007(17.655 ) & -1.220(11.944 ) & -1.181(11.919 ) + @xmath349 & mise & & 3.852 & & 2.503 + @xmath161 & mise & 0.0087 & 0.0096 & 0.0047 & 0.0044 +    we observe from table 1 that the least squares partial functional linear ( lspfl ) method gives poor estimates , while our profile b - spline estimates are far more accurate than the lspfl estimates , and they can be as accurate as those obtained from the oracle when the exact form of sinusoidal model is known .",
    "figure 1 shows that the difference between the true curves and the mean estimated curves are barely visible , and it shows that the bias is very small in the estimates .",
    "furthermore , the @xmath435 pointwise confidence bands are reasonably close to the true curve , showing a very little variation in the estimates .",
    "table 2 shows that , even if the unknown link function @xmath95 is a linear function , our profile b - spline estimates behave as good as the least squares partial functional linear estimates .",
    "both tables indicate that the proposed profile b - spline method yields accurate estimates and outperforms the least squares partial functional linear estimates when the link function is nonlinear , and it is comparable to the least squares partial functional linear estimates when the link function is a linear function .    to study the prediction performance of the proposed profile b - spline method , we generated samples of @xmath438 from models ( 4.1 ) and ( 4.2 ) with @xmath444 for estimation , where @xmath445 is related to the eigenvalue of the operator with kernel @xmath36 .",
    "we also generated test samples of size @xmath446 to compute the prediction mean absolute error ( mae ) defined by @xmath447 , where @xmath448 and @xmath449 .",
    "figures 2 and 3 display the boxplots of @xmath450 based on 500 replications and @xmath451 .",
    "we observe that the proposed profile b - spline method shows good prediction performances for both models and the maes are quite small even if @xmath433 .",
    "figure 2 also shows that the @xmath450 decreases as @xmath173 increases or as @xmath445 increases",
    ".    for different @xmath100 and @xmath174 , table 3 exhibits the mses of the estimators @xmath426 and @xmath427 for model ( 4.1 ) with @xmath432 and sample size @xmath452 .",
    "we observe from table 3 that mses of @xmath453 and @xmath427 are not very sensitive to the change of @xmath100 and @xmath454 and the estimators of @xmath455 and @xmath456 are efficient under a broad range of values for @xmath100 and @xmath174 .",
    "the mses of @xmath457 and @xmath429 also show similar behaviors and are omitted here .",
    "[ c]lcccccccccc & @xmath174 & + & & @xmath458 & @xmath459 & @xmath460 & @xmath461 & @xmath462 & @xmath463 & @xmath464 & @xmath465 & @xmath466 + @xmath426 & 0.2 & 1.4 & 0.9 & 0.5 & 0.3 & 0.4 & 0.5 & 0.6 & 0.4 & 0.6 + & 0.3 & 1.4 & 0.8 & 0.3 & 0.3 & 0.4 & 0.4 & 0.6 & 0.2 & 0.3 + & 0.4 & 1.4 & 0.8 & 0.3 & 0.2 & 0.4 & 0.3 & 0.6 & 0.4 & 0.6 + & 0.5 & 1.4 & 0.6 & 0.3 & 0.3 & 0.3 & 0.4 & 0.6 & 0.6 & 0.4 + @xmath427 & 0.2 & 1.8 & 2.0 & 1.0 & 0.5 & 0.9 & 1.1 & 0.8 & 0.9 & 1.6 + & 0.3 & 1.5 & 1.5 & 0.7 & 0.6 & 1.4 & 0.3 & 1.1 & 0.7 & 1.4 + & 0.4 & 1.5 & 1.5 & 0.7 & 0.6 & 1.1 & 0.3 & 1.1 & 1.1 & 1.4 + & 0.5 & 2.5 & 1.6 & 1.5 & 0.8 & 0.6 & 1.0 & 1.6 & 1.2 & 1.0 +",
    "in this section we analyze a real data set using the proposed method . for this purpose",
    "we use the diffusion tensor imaging ( dti ) data with 217 subjects from the nih alzheimer s disease neuroimaging initiative ( adni ) study . for more information on how this data were collected etc .",
    ", see http://www.adni-info.org .",
    "the dti data were processed by two key steps including a weighted least squares estimation method @xcite to construct the diffusion tensors and a tbss pipeline in fsl @xcite to register dtis from multiple subjects to create a mean image and a mean skeleton .",
    "this data have been recently analyzed by many authors using different models ; see , e.g. , yu et al .",
    "@xcite , li et al . @xcite and the references therein .",
    "our interest is to predict mini - mental state examination ( mmse ) scores , one of the most widely used screening tests to provide brief and objective measures of cognitive functioning for a long time .",
    "the mmse scores have been seen as a reliable and valid clinical measure quantitatively assessing the severity of cognitive impairment .",
    "it was believed that the mmse scores to be affected by demographic features such as age , education and cultural background @xcite gender @xcite , and possibly some genetic factors , for example , aope polymorphic alleles @xcite .",
    "after cleaning the raw data that failed in quality control or had missing data , we include totally 196 individuals in our analysis .",
    "the response of interest @xmath19 is the mmse scores .",
    "the functional covariate is fractional anisotropy ( fa ) values along the corpus callosum ( cc ) fiber tract with 83 equally spaced grid points , which can be treated as a function of arc - length .",
    "fa measures the inhomogeneous extent of local barriers to water diffusion and the averaged magnitude of local water diffusion @xcite .",
    "the scalar covariates of primary interests include gender ( @xmath467 ) , handedness ( @xmath468 ) , education level ( @xmath469 ) , genotypes for apoe4 ( @xmath470 , categorical data with 3 levels ) , age ( @xmath471 ) , adas13 ( @xmath472 ) and adas11 ( @xmath473 ) .",
    "the genotypes apoe4 is one of three major alleles of apolipoprotein e ( apo - e ) , a major cholesterol carrier that supports lipid transport and injury repair in the brain .",
    "apoe polymorphic alleles are the main genetic determinants of alzheimer disease risk @xcite . adas11 and adas13 are respectively the 11-item and 13-item versions of the alzheimers disease assessment scale - cognitive subscale ( adas - cog ) , which were originally developed to measure cognition in patients within various stages of alzheimer s disease @xcite .",
    "we study the following two models @xmath245{ll}% y & = \\int_{0}^{1}a(t)x(t)dt+\\alpha_{0}+\\alpha_{1}w_{1}+\\alpha_{2}w_{2}% + \\alpha_{3}w_{3}+\\alpha_{4}w_{4}+\\alpha_{5}w_{5}\\\\ & + \\alpha_{6}w_{6}+\\beta_{1}z_{1}+\\beta_{2}z_{2}+\\varepsilon , \\end{array } \\tag{5.1}\\]]@xmath245{ll}% y & = \\int_{0}^{1}a(t)x(t)dt+\\alpha_{1}w_{1}+\\alpha_{2}w_{2}+\\alpha_{3}% w_{3}+\\alpha_{4}w_{4}+\\alpha_{5}w_{5}\\\\ & + \\alpha_{6}w_{6}+g(\\beta_{1}z_{1}+\\beta_{2}z_{2})+\\varepsilon , \\end{array } \\tag{5.2}\\ ] ] where @xmath474 stands for male and @xmath475 stands for female , @xmath476 denotes right - handed and @xmath477 denotes left - handed , @xmath478 and @xmath479 indicates type 0 for apoe4 , @xmath480 and @xmath481 indicates type 1 for apoe4 and both @xmath480 and @xmath479 indicates type 2 for apoe4 .",
    "the functional component @xmath1 is chosen as the centered fractional anisotropy ( fa ) values so that @xmath482=0 $ ] .",
    "model ( 5.1 ) is a partial functional linear model , while model ( 5.2 ) is partial functional linear single index model in which adas13 ( @xmath472 ) and adas11 ( @xmath473 ) are index variables .",
    "[ c]lccccccccmodel & @xmath483 & @xmath484 & @xmath485 & @xmath486 & @xmath487 & @xmath488 & @xmath489 & @xmath490 + ( 5.1 ) & 0.0758 & 0.4317 & 0.1105 & 0.6875 & 0.5581 & -0.0239 & -0.0429 & -0.1865 + ( 5.2 ) & -0.0754 & 0.1814 & 0.1138 & 0.5961 & 0.5245 & -0.0305 & 0.1957 & 0.9807 +    the parametric and nonparametric components in the models are computed by the procedure given in section 2 , with the nonparametric function @xmath95 being approximated by a cubic spline with equally spaced knots .",
    "since the values of @xmath472 and @xmath473 are large , we choose @xmath491 for model ( 5.2 ) and @xmath492 for parametric estimation .",
    "table 4 exhibits the parametric estimators , and figure 4 shows the estimated curves of @xmath3 and @xmath95 . for model ( 5.1 ) ,",
    "the mse of @xmath19 for models ( 5.1 ) and ( 5.2 ) are 2.8684 and 2.7782 , respectively , and can be further reduced for model ( 5.2 ) as the number of knots increases .    from table 4 and",
    "figure 3 , we observe that in both models mmse is decreasing in terms of adas13 and adas11 .",
    "however , in figure 3 this decline is found to be nonlinear evidenced by the nonlinear trends of @xmath95 in model ( 5.2 ) . in single index models ( 5.2 )",
    ", we found that mmse is higher for female than male , which is consistent with the results in the literature @xcite , while model ( 5.1 ) incorrectly finds the opposite .",
    "although we may not able to perform a formal test on model fitting , these observations show the superiority of the single index model ( 5.2 ) .",
    "to evaluate the prediction performance of the three models , we applied a combination of the bootstrap and the cross - validation method to the data set . for each bootstrap sample",
    ", we randomly divided the data into ten partitions .",
    "since the number of individuals is not large , we used nine folds of the data to estimate the model and the remaining fold for the testing data set .",
    "we calculated the mean squared prediction error ( mspe ) for the testing data set .",
    "the mspes for the two models over the 200 replications are reported as boxplots in figure 4 .",
    "the means for mspes of the 200 replications for models ( 5.1 ) and ( 5.2 ) are @xmath494 and @xmath495 , respectively .",
    "the medians for mspes of the 200 replications for models ( 5.1 ) and ( 5.2 ) are 3.5464 and 3.3421 , respectively .",
    "this figure shows that model ( 5.2 ) fits the data better than model ( 5.1 ) .",
    "we also calculated @xmath435 point - wise confidence intervals of the estimated curves of @xmath3 in model ( 5.1 ) , @xmath3 in model ( 5.2 ) , and @xmath95 in model ( 5.2 ) , which are shown as ( a ) , ( b ) and ( c ) , respectively , in figure 4 . from figure 5",
    ", it is evidenced that the functional slope for both models are also identical , while @xmath95 has a clear nonlinear feature .",
    "this also confirms that model ( 5.2 ) is more flexible than model ( 5.1 ) .",
    "functional data analysis is now very popular as it provides modern analytical tools for data that are recorded as images or as a continuous phenomenon over a period of time .",
    "classical multivariate statistical tools may fail or may be irrelevant in that context to take benefit from the underlying functional structure of functional data . as a great variety of real data applications",
    "involve functional phenomena , which may be represented as curves or more complex objects , the demand of models and statistical tools for analyzing functional data is ever more increasing .",
    "the need for more comprehensive models that more adaptable motivated us to propose and study a partial functional partially linear single index ( pfplsi ) model in this paper .",
    "the proposed pfplsi model generalizes the standard functional linear model , partial functional linear models and the partially linear single - index model , among others .",
    "we have implemented functional principal component analysis to estimate the slope function component of the pfplsi model , and the unknown link function of the single - index component has been approximated by a b - spline function . to estimate the unknown parameters in the proposed pfplsi model , we have proposed a profile b - spline method .",
    "we have derived the asymptotic properties , including the consistency and asymptotic normality , of the proposed estimators of the unknown parameters .",
    "the global convergence of the proposed estimator of the functional slope function has also been established , and this convergence result has been shown to be optimal in the minimax sense . a two - stage procedure was used to estimate the unknown link function attaining the optimal global convergence rate of convergence .",
    "we have also derived convergence rates of the mean squared prediction error for a predictor .",
    "the lower prediction error demonstrates the rationality of our modelling and the effectiveness of the proposed estimation procedure .",
    "monte carlo studies conducted to examine the performance of the proposed methodology demonstrate that the proposed estimators perform quite satisfactorily and the theoretical results established seem to be valid .",
    "an alternative approach to the pfplsi model ( 1.1 ) that may be of interest is _ functional linear quantile regression_. the functional linear quantile regression where the conditional quantiles of the responses are modeled by a set of scalar covariates and functional covariates .",
    "there may be several advantages of using conditional quantiles instead of working with conditional means .",
    "first , the quantile regression , in particular the median regression , provides an alternative and complement to the mean regression , while being resistant to outliers in the responses . in other words , it is more efficient than the mean regression when the errors follow a distribution with heavy tails .",
    "second , the quantile regression is capable of dealing with heteroscedasticity , that is the situations where variances depend on some covariates . finally , the quantile regression can give a more complete picture on how the responses are affected by covariates ; e.g. , some tail behaviors of the responses conditional on the covariates .",
    "for more details on quantile regression , one may refer to the monograph of koenker @xcite .",
    "in view of the model ( 1.1 ) , we consider the following functional linear quantile regression : for given @xmath496,@xmath497 where @xmath498 is the @xmath499-th conditional quantile of @xmath19 given the covariates @xmath500 although there is some reported work on functional linear quantile regression in the literature , the above model has not been studied yet .",
    "further research is needed for these advancements .",
    "in this section we let @xmath501 denote a generic constant of which the value may change from line to line . for a matrix @xmath502 , set @xmath503 and @xmath504 . for a vector @xmath505 , set @xmath506 and @xmath507 . we write @xmath508 with @xmath509 .",
    "denote @xmath510 , @xmath511 and @xmath512 , @xmath513 . then @xmath514 and @xmath515 .",
    "define @xmath516 , where @xmath517 is the @xmath518 identity matrix . by ( 3.5 ) ,",
    "( 2.9 ) and ( 2.10 ) , we have @xmath519.\\tag{a.1}\\ ] ]    * lemma  a.1 . *  suppose that assumptions 1 to 4 , 5 and 7 hold .",
    "then @xmath245{l}% \\frac{1}{n}(\\check{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha})^{t}(\\check { \\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha } ) = \\rho(\\pmb{\\alpha})+o_{p}(1 ) , \\end{array}\\ ] ] where @xmath520(\\pmb{\\alpha}-\\pmb{\\alpha}_{0})+\\pmb{b}_{0}% ^{t}\\gamma(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0})\\pmb{b}_{0},$ ] and @xmath521 holds uniformly for @xmath91 in any bounded neighborhood of @xmath6",
    ".    * proof .",
    "*  define @xmath522 , @xmath523 and @xmath524 then @xmath525 and @xmath526 denote @xmath527\\xi_{ij}$ ] , @xmath528 @xmath529 and @xmath530 then we have @xmath531 from lemma 5.1 of hall and horowitz ( 2007 ) it follows that @xmath532 where @xmath533",
    ". then we obtain @xmath245{ll}% \\lbrack\\frac{1}{n}\\sum_{l=1}^{n}y_{l}^{\\ast}(\\hat{\\xi}_{lj}-\\xi_{lj})]^{2 }   & \\leq2(\\sum_{k\\neq j}\\frac{\\vec{\\xi}_{k}}{\\hat{\\lambda}_{j}-\\lambda_{k}}% \\int\\delta\\hat{\\phi}_{j}\\phi_{k})^{2}+2(\\vec{\\xi}_{j}\\int(\\hat{\\phi}_{j}% -\\phi_{j})\\phi_{j})^{2}\\\\   & \\leq2[\\sum_{k\\neq j}\\frac{\\vec{\\xi}_{k}^{2}}{(\\hat{\\lambda}_{j}-\\lambda _ { k})^{2}}][\\sum_{k=1}^{\\infty}(\\int\\delta\\hat{\\phi}_{j}\\phi_{k})^{2}% ] + \\\\&2\\vec{\\xi}_{j}^{2}(\\int(\\hat{\\phi}_{j}-\\phi_{j})\\phi_{j})^{2 } , \\end{array}\\ ] ] where @xmath534 .",
    "lemma 6.1 of cardot et al .",
    "( 2007 ) yields that @xmath535 uniformly for @xmath536 . from ( 5.2 ) of hall and horowitz ( 2007 ) we have @xmath537{ll}% ( \\int(\\hat{\\phi}_{j}-\\phi_{j})\\phi_{j})^{2}\\leq\\vert\\hat{\\phi}_{j}-\\phi _ { j}\\vert^{2}\\leq c\\frac{|\\vert\\delta\\vert|^{2}}{(\\lambda_{j}-\\lambda _ { j+1})^{2}}\\leq c|\\vert\\delta\\vert|^{2}\\lambda_{j}^{-2}j^{2 } , & \\end{array } \\tag{a.5}\\ ] ] where @xmath538 . using parseval s identity , we obtain @xmath539 assumption 5 implies that @xmath540 .",
    "consequently , @xmath541 @xmath542 $ ] , where @xmath521 holds uniformly for @xmath536 . using lemma 6.2 of cardot et al .",
    "( 2007 ) and the fact that @xmath543 , we deduce that @xmath245{l}% \\sum_{k\\neq j}\\frac{1}{(\\lambda_{j}-\\lambda_{k})^{2}}e(\\vec{\\xi}_{k}^{2})\\\\ \\leq c\\sum_{k\\neq j}\\frac{1}{(\\lambda_{j}-\\lambda_{k})^{2}}[n^{-1}\\lambda _ { k}+{a_{k}^{\\ast}}^{2}\\lambda_{k}^{2}]\\\\ \\leq c[\\frac{1}{n(\\lambda_{j}-\\lambda_{j+1})}\\sum_{k\\neq j}\\frac{\\lambda_{k}% } { |\\lambda_{j}-\\lambda_{k}|}+\\sum_{k=1}^{j-1}\\frac{\\lambda_{k}^{2}{a_{k}% ^{\\ast}}^{2}}{(\\lambda_{k}-\\lambda_{k+1})^{2}}+\\\\\\sum_{k = j+1}^{2j}\\frac { j^{2}{a_{k}^{\\ast}}^{2}}{(k - j)^{2}}+\\sum_{k=2j+1}^{\\infty}\\frac{\\lambda _ { k}^{2}{a_{k}^{\\ast}}^{2}}{(\\lambda_{j}-\\lambda_{2j})^{2}}]\\\\ \\leq c(n^{-1}\\lambda_{j}^{-1}j^{2}\\log j+1 ) .",
    "\\end{array}\\ ] ] where @xmath544 .",
    "assumption 2 yields that @xmath545 and @xmath546 .",
    "therefore , @xmath245{ll}% \\frac{1}{n}\\sum_{i=1}^{n}\\check{y}_{i21}^{2 } & \\leq(\\sum_{j=1}^{m}\\frac { 1}{\\lambda_{j}}[\\frac{1}{n}\\sum_{l=1}^{n}y_{l}^{\\ast}(\\hat{\\xi}_{lj}-\\xi _ { lj})]^{2})(\\sum_{j=1}^{m}\\frac{1}{n\\lambda_{j}}\\sum_{i=1}^{n}\\xi_{ij}^{2})\\\\ & = o_{p}(n^{-2}\\lambda_{m}^{-2}m^{4}\\log m+n^{-1}\\lambda_{m}^{-1}m^{2 } ) .",
    "\\end{array } \\tag{a.6}\\ ] ] decomposing @xmath547 and using ( a.6 ) , we obtain @xmath245{ll}% \\frac{1}{n}\\sum_{i=1}^{n}\\check{y}_{i22}^{2 } & \\leq c\\sum_{j=1}^{m}\\frac { ( \\hat{\\lambda}_{j}-\\lambda_{j})^{2}}{\\lambda_{j}^{3}}(\\frac{1}{n}\\sum _ { l=1}^{n}y_{l}^{\\ast}\\hat{\\xi}_{lj})^{2}[1+o_{p}(1)]\\\\&(\\sum_{j=1}^{m}\\frac { 1}{n\\lambda_{j}}\\sum_{i=1}^{n}\\xi_{ij}^{2})\\\\ & = o_{p}(n^{-1}\\lambda_{m}^{-1}m+n^{-3}\\lambda_{m}^{-4}m^{4}\\log m+n^{-2}\\lambda_{m}^{-3}m^{2 } ) . \\end{array } \\tag{a.7}\\ ] ] by ( a.10 ) of tang ( 2015 ) , it holds that @xmath548 uniformly for @xmath536 . using ( a.7 ) and ( a.8 )",
    ", we obtain @xmath245{ll}% \\frac{1}{n}\\sum_{i=1}^{n}\\check{y}_{i23}^{2 } & \\leq(\\sum_{j=1}^{m}\\frac { 1}{\\hat{\\lambda}^{2}}(\\frac{1}{n}\\sum_{l=1}^{n}y_{l}^{\\ast}\\hat{\\xi}% _ { lj})^{2})(\\frac{1}{n}\\sum_{i=1}^{n}\\vert x_{i}\\vert^{2})(\\sum_{j=1}^{m}% \\vert\\hat{\\phi}_{j}-\\phi_{j}\\vert^{2})\\\\ & = o_{p}((n^{-1}m^{3}+n^{-3}\\lambda_{m}^{-3}m^{6}\\log m+n^{-2}\\lambda_{m}% ^{-2}m^{4})\\log m ) . \\end{array } \\tag{a.9}\\ ] ] then by ( a.3 ) , ( a.6 ) , ( a.7 ) , ( a.9 ) and assumption 5 , we conclude that @xmath549 define @xmath550 .",
    "since @xmath551\\leq$ ] + @xmath552 , we then have @xmath553 .",
    "hence , we have @xmath245{ll}% \\frac{1}{n}\\sum_{i=1}^{n}\\check{y}_{i1}^{2 } & = \\frac{1}{n}\\sum_{i=1}^{n}% { y_{i}^{\\ast}}^{2}-2\\sum_{j=1}^{m}{\\xi_{j}^{\\ast}}^{2}+\\sum_{j=1}^{m}%",
    "\\frac{{\\xi_{j}^{\\ast}}^{2}}{n\\lambda_{j}}(\\sum_{i=1}^{n}\\xi_{ij}^{2}% ) + \\\\&\\sum_{j\\neq j^{\\prime}}\\xi_{j}^{\\ast}\\xi_{j^{\\prime}}^{\\ast}\\bar{\\xi } _ { jj^{\\prime}}\\\\ & = \\sum_{j=1}^{\\infty}(a_{j}+\\sum_{r=1}^{q}w_{rj}\\alpha_{0r})^{2}\\lambda _ { j}+e(v^{t}\\pmb{\\alpha}_{0}+g(z^{t}\\pmb{\\beta}_{0}))^{2}\\\\ & -2\\sum_{j=1}^{m}(a_{j}+\\sum_{r=1}^{q}w_{rj}\\alpha_{0r})^{2}\\lambda_{j}% + \\\\&\\sum_{j=1}^{m}(a_{j}+\\sum_{r=1}^{q}w_{rj}\\alpha_{0r})^{2}\\lambda_{j}% + o_{p}(1)\\\\ & = e(v^{t}\\pmb{\\alpha}_{0}+g(z^{t}\\pmb{\\beta}_{0}))^{2}+o_{p}(1 ) , \\end{array } \\tag{a.11}\\ ] ] where @xmath554 . combining ( a.2 ) , ( a.10 ) , ( a.11 ) and ( 3.1 ) ,",
    "we conclude that @xmath555\\pmb{\\alpha}_{0}+\\pmb{b}_{0}^{t}\\gamma ( \\pmb{\\beta}_{0},\\pmb{\\beta}_{0})\\pmb{b}_{0}+o_{p}(1).\\tag{a.12}\\ ] ] similar to the proof of ( a.12 ) , we obtain that @xmath245{l}% \\frac{1}{n}\\tilde{\\pmb{w}}^{t}\\tilde{\\pmb{w}}=e(vv^{t})+o_{p}(1),\\\\ \\frac { 1}{n}\\tilde{\\pmb{y}}^{t}\\tilde{\\pmb{w}}=\\pmb{\\alpha}_{0}e(v^{t}% v)+\\pmb{b}_{0}^{t}e[\\pmb{b}_{\\pmb{\\beta}_{0}}(z^{t}\\pmb{\\beta}_{0}% ) v]+o_{p}(1 ) .",
    "\\end{array}\\ ] ] now lemma a.1 follows from ( a.12 ) and the preceding expression .",
    "* lemma  a.2 . *  under assumptions 1 , 4 and 5",
    ", it holds that @xmath556{l}% \\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{1\\leq j\\leq m}\\max_{1\\leq k\\leq k_{\\pmb{\\beta}}}\\lambda_{j}^{-\\frac{1}{2}}|\\frac{1}{n}\\sum_{i=1}^{n}\\xi _ { ij}b_{k\\pmb{\\beta}}^{(r)}(z_{i}^{t}\\pmb{\\beta})|\\\\=o_{p}(n^{-\\frac{1}{2}}% h_{0}^{\\frac{1}{4}-r}\\log",
    "n ) , \\end{array}\\]]@xmath556{l}% \\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{k , k^{\\prime}}|\\frac{1}{n}% \\sum_{i=1}^{n}b_{k\\pmb{\\beta}}(z_{i}^{t}\\pmb{\\beta})b_{k^{\\prime}% \\pmb{\\beta}}(z_{i}^{t}\\pmb{\\beta})-e[b_{k\\pmb{\\beta } } ( z_{i}^{t}% \\pmb{\\beta})b_{k^{\\prime}\\pmb{\\beta}}(z_{i}^{t}\\pmb{\\beta})]|\\\\=o_{p}% ( n^{-\\frac{1}{2}}h_{0}^{\\frac{1}{2}}\\log n ) , \\end{array}\\]]@xmath556{l}% \\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{k , k^{\\prime}}|\\frac{1}{n}% \\sum_{i=1}^{n}b_{k\\pmb{\\beta}}^{\\prime}(z_{i}^{t}\\pmb{\\beta})b_{k^{\\prime } \\pmb{\\beta}}^{\\prime}(z_{i}^{t}\\pmb{\\beta})-e[b_{k\\pmb{\\beta}}^{\\prime}% ( z_{i}^{t}\\pmb{\\beta})b_{k^{\\prime}\\pmb{\\beta}}^{\\prime}(z_{i}^{t}% \\pmb{\\beta})]|\\\\=o_{p}(n^{-\\frac{1}{2}}h_{0}^{-\\frac{3}{2}}\\log n ) , \\end{array}\\ ] ] and @xmath556{l}% \\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{k , k^{\\prime}}|\\frac{1}{n}% \\sum_{i=1}^{n}b_{k\\pmb{\\beta}}(z_{i}^{t}\\pmb{\\beta})b_{k^{\\prime}% \\pmb{\\beta}}^{\\prime\\prime}(z_{i}^{t}\\pmb{\\beta})-e[b_{k\\pmb{\\beta}}(z_{i}% ^{t}\\pmb{\\beta})b_{k^{\\prime}\\pmb{\\beta}}^{\\prime\\prime}(z_{i}^{t}% \\pmb{\\beta})]|\\\\=o_{p}(n^{-\\frac{1}{2}}h_{0}^{-\\frac{3}{2}}\\log n ) \\end{array}\\ ] ] for @xmath557 .    *",
    "proof . *",
    "we give only the proof for the first step with @xmath558 , as the first step with @xmath559 and the other steps follow from similar arguments .",
    "define @xmath560 .",
    "applying assumptions 1 and lemma 5 of kato @xcite , we have @xmath561 .",
    "hence , by assumption 5 , for any @xmath258 and @xmath259 , there exists a positive constant @xmath562 such that @xmath563 using assumptions 1 and the fact that @xmath564 , we obtain @xmath245{l}%    ^{t}\\pmb{\\beta})i_{\\{|\\lambda_{j}^{-\\frac{1}{2}}\\xi_{ij}|\\geq\\tilde{c}% _ { 1}n^{\\frac{1}{2}}h_{0}^{\\frac{1}{4}}(\\log n)^{-1}\\}}]|\\\\ \\leq cn^{-\\frac{3}{2}}h_{0}^{-\\frac{11}{4}}(\\log n)^{3}e[\\lambda_{j}% ^{-\\frac{1}{2}}\\xi_{ij}]^{4}<\\varepsilon n^{-\\frac{1}{2}}h_{0}^{-\\frac{7}{4}% } \\log n/2 . \\end{array}\\ ] ] denote @xmath245{ll}% \\tilde{\\eta}_{jki}(z_{i}^{t}\\pmb{\\beta } ) & = \\lambda_{j}^{-\\frac{1}{2}}\\xi _ { ij}b_{k\\pmb{\\beta}}^{\\prime\\prime}(z_{i}^{t}\\pmb{\\beta})i_{\\{|\\lambda _ { j}^{-\\frac{1}{2}}\\xi_{ij}|<\\tilde{c}_{1}n^{\\frac{1}{2}}h_{0}^{\\frac{1}{4}% } ( \\log n)^{-1}\\}}\\\\ & -e[\\lambda_{j}^{-\\frac{1}{2}}\\xi_{ij}b_{k\\pmb{\\beta}}^{\\prime\\prime}% ( z_{i}^{t}\\pmb{\\beta})i_{\\{|\\lambda_{j}^{-\\frac{1}{2}}\\xi_{ij}|<\\tilde{c}% _ { 1}n^{\\frac{1}{2}}h_{0}^{\\frac{1}{4}}(\\log n)^{-1}\\ } } ] . \\end{array}\\ ] ] then we have @xmath245{l}% p\\{\\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{j , k}|\\frac{1}{n}\\sum_{i=1}% ^{n}\\eta_{jki}(z_{i}^{t}\\pmb{\\beta})|\\geq\\varepsilon n^{-\\frac{1}{2}}% h_{0}^{-\\frac{7}{4}}\\log n\\}\\\\ \\leq p\\{\\max_{j , i}|\\lambda_{j}^{-\\frac{1}{2}}\\xi_{ij}|\\geq\\tilde{c}% _ { 1}n^{\\frac{1}{2}}h_{0}^{\\frac{1}{4}}(\\log n)^{-1}\\}\\\\ + p\\{\\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{j , k}|\\frac{1}{n}\\sum_{i=1}% ^{n}\\tilde{\\eta}_{jki}(z_{i}^{t}\\pmb{\\beta})|\\geq\\varepsilon n^{-\\frac{1}{2}% } h_{0}^{-\\frac{7}{4}}\\log n/2\\}. \\end{array } \\tag{a.14}\\ ] ] using the fact that @xmath565 again we obtain @xmath566 from assumption 1 , it follows that @xmath567e(\\xi_{j}^{4}))^{1/2}\\leq cnh_{0}^{-7/2}.\\tag{a.16}\\ ] ] for @xmath568 and @xmath569 , define @xmath570 . since @xmath571 , then there exists a positive @xmath572 such that @xmath573 from ( 2.6 ) , for all @xmath574 , the total of different @xmath171 is not more than @xmath172",
    ". let @xmath575 be divided into @xmath576 disjoint parts @xmath577 such that for any @xmath578 and any @xmath579 , when @xmath580 , @xmath245{l}% \\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}l}}|\\frac{1}{n}\\sum_{i=1}^{n}\\tilde{\\eta } _ { jki}(z_{i}^{t}\\pmb{\\beta})-\\frac{1}{n}\\sum_{i=1}^{n}\\tilde{\\eta}% _ { jki}(z_{i}^{t}\\pmb{\\beta}_{l})|\\\\ \\leq\\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}l}}\\lambda_{j}^{-\\frac{1}{2}% } \\big(\\frac{1}{n}\\sum_{i=1}^{n}|\\xi_{ij}||b_{k\\pmb{\\beta}}^{\\prime\\prime } ( z_{i}^{t}\\pmb{\\beta})-b_{k\\pmb{\\beta}}^{\\prime\\prime}(z_{i}^{t}% \\pmb{\\beta}_{l})|\\\\+e(|\\xi_{ij}||b_{k\\pmb{\\beta}}^{\\prime\\prime}(z_{i}% ^{t}\\pmb{\\beta})-b_{k\\pmb{\\beta}}^{\\prime\\prime}(z_{i}^{t}\\pmb{\\beta}_{l}% ) |)\\big)\\\\ \\leq\\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}l}}ch_{0}^{-3}\\sum_{j=1}^{m}% \\big(\\frac{1}{n}\\sum_{i=1}^{n}\\lambda_{j}^{-\\frac{1}{2}}|\\xi_{ij}%    \\leq cmh_{0}^{-3}|\\pmb{\\beta}-\\pmb{\\beta}_{l}|<\\varepsilon n^{-\\frac{1}{2}% } h_{0}^{-\\frac{7}{4}}\\log n/4 . \\end{array}\\ ] ] this can be done with @xmath581 .",
    "using bernstein inequality and ( a.15 ) , ( a.16 ) and assumption 5 , for sufficiently large @xmath173 , it follows that @xmath245{l}% p\\big(\\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{j , k}|\\frac{1}{n}\\sum",
    "_ { i=1}^{n}\\tilde{\\eta}_{jki}(z_{i}^{t}\\pmb{\\beta})|\\geq\\varepsilon n^{-\\frac{1}{2}}h_{0}^{-\\frac{7}{4}}\\log n/2,\\\\\\sum_{j=1}^{m}\\frac{1}{n}% \\sum_{i=1}^{n}\\lambda_{j}^{-\\frac{1}{2}}|\\xi_{ij}|<\\tilde{c}_{2}m\\big)\\\\ \\leq p\\big(\\cup_{l=1}^{n}\\{\\max_{j , k}|\\frac{1}{n}\\sum_{i=1}^{n}\\tilde{\\eta } _ { jki}(z_{i}^{t}\\pmb{\\beta}_{l})|\\geq\\varepsilon n^{-\\frac{1}{2}}% h_{0}^{-\\frac{7}{4}}\\log n/4\\}\\big)\\\\ \\leq cmk_{n}n\\exp\\big\\{-\\frac{\\varepsilon^{2}nh_{0}^{-\\frac{7}{2}}(\\log n)^{2}}{32cnh_{0}^{-7/2}+4cn^{\\frac{1}{2}}h_{0}^{-\\frac{7}{4}}(\\log n)^{-1}\\varepsilon n^{\\frac{1}{2}}h_{0}^{-\\frac{7}{4}}\\log n}\\big\\}<\\epsilon /2 . \\end{array}\\ ] ] now lemma a.2 follows from ( a.13 ) , ( a.14 ) , ( a.17 ) and the preceding inequality .",
    "* lemma  a.3 .",
    "*  assume that assumptions 1 , 2 , 4 and 5 hold .",
    "then it holds that @xmath582 where @xmath583 holds uniformly for @xmath584 and @xmath574 .",
    "* proof*.  define @xmath556{l}% \\tilde{b}_{k\\pmb{\\beta}1}(z_{i}^{t}\\pmb{\\beta})=b_{k\\pmb{\\beta}}(z_{i}% ^{t}\\pmb{\\beta})-\\frac{1}{n}\\sum_{l=1}^{n}b_{k\\pmb{\\beta}}(z_{l}% ^{t}\\pmb{\\beta})\\check{\\xi}_{il},\\\\",
    "\\tilde{b}_{k\\pmb{\\beta}2}(z_{i}% ^{t}\\pmb{\\beta})=\\frac{1}{n}\\sum_{l=1}^{n}b_{k\\pmb{\\beta}}(z_{l}% ^{t}\\pmb{\\beta})(\\tilde{\\xi}_{il}-\\check{\\xi}_{il } ) . \\end{array}\\ ] ] we decompose the @xmath585th element of @xmath586 as @xmath245{ll}% & \\frac{1}{n}\\sum_{i=1}^{n}\\tilde{b}_{k\\pmb{\\beta}}(z_{i}^{t}\\pmb{\\beta})\\tilde { b}_{k^{\\prime}\\pmb{\\beta}}(z_{i}^{t}\\pmb{\\beta } ) \\\\ & = \\frac{1}{n}\\sum_{i=1}% ^{n}\\big(\\tilde{b}_{k\\pmb{\\beta}1}(z_{i}^{t}\\pmb{\\beta})\\tilde{b}_{k^{\\prime } \\pmb{\\beta}1}(z_{i}^{t}\\pmb{\\beta})-\\tilde{b}_{k\\pmb{\\beta}1}(z_{i}% ^{t}\\pmb{\\beta})\\tilde{b}_{k^{\\prime}\\pmb{\\beta}2}(z_{i}^{t}\\pmb{\\beta})\\\\ & -\\tilde{b}_{k\\pmb{\\beta}2}(z_{i}^{t}\\pmb{\\beta})\\tilde{b}_{k^{\\prime } \\pmb{\\beta}1}(z_{i}^{t}\\pmb{\\beta})+\\tilde{b}_{k\\pmb{\\beta}2}(z_{i}% ^{t}\\pmb{\\beta})\\tilde{b}_{k^{\\prime}\\pmb{\\beta}2}(z_{i}^{t}\\pmb{\\beta})\\big ) .",
    "\\end{array}\\ ] ] applying the cauchy - schwarz inequality , lemma a.2 , ( a.8 ) and assumptions 2 and 5 , we obtain @xmath245{l}% \\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{k}\\frac{1}{n}\\sum_{i=1}% ^{n}\\big(\\sum_{j=1}^{m}\\frac{1}{\\lambda_{j}}[\\frac{1}{n}\\sum_{l=1}% ^{n}b_{k\\pmb{\\beta}}(z_{l}^{t}\\pmb{\\beta})(\\hat{\\xi}_{lj}-\\xi_{lj})]\\xi _ { ij}\\big)^{2}\\\\ \\leq\\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{k}\\big(\\sum_{j=1}^{m}\\frac { 1}{\\lambda_{j}}[\\frac{1}{n}\\sum_{l=1}^{n}b_{k\\pmb{\\beta}}(z_{l}% ^{t}\\pmb{\\beta})(\\hat{\\xi}_{lj}-\\xi_{lj})]^{2}\\big)\\\\\\big(\\sum_{j=1}^{m}\\frac { 1}{n\\lambda_{j}}\\sum_{i=1}^{n}\\xi_{ij}^{2}\\big)\\\\ \\leq(\\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{k}\\frac{1}{n}\\sum_{l=1}% ^{n}b_{k\\pmb{\\beta}}^{2}(z_{l}^{t}\\pmb{\\beta}))(\\frac{1}{n}\\sum_{l=1}^{n}\\vert x_{l}\\vert^{2})(\\sum_{j=1}^{m}\\frac{\\vert\\hat{\\phi}_{j}-\\phi_{j}\\vert^{2}% } { \\lambda_{j}})\\\\(\\sum_{j=1}^{m}\\frac{1}{n\\lambda_{j}}\\sum_{i=1}^{n}\\xi_{ij}% ^{2})\\\\ = o_{p}(n^{-1}\\lambda_{m}^{-1}m^{4}h_{0}\\log m)=o_{p}(h_{0}^{3 } ) . \\end{array } \\tag{a.18}\\ ] ] similar to the proof of ( a.7 ) , ( a.9 ) and using lemma a.2 , we then deduce that @xmath245{l}% \\sup_{\\pmb{\\beta}\\in\\theta_{\\rho_{0}}}\\max_{k}\\frac{1}{n}\\sum_{i=1}% ^{n}\\big(\\sum_{j=1}^{m}(\\frac{\\hat{\\xi}_{ij}}{\\hat{\\lambda}_{j}}-\\frac { \\xi_{ij}}{\\lambda_{j}})(\\frac{1}{n}\\sum_{l=1}^{n}b_{k\\pmb{\\beta}}(z_{l}% ^{t}\\pmb{\\beta})\\hat{\\xi}_{lj})\\big)^{2}\\\\ = o_{p}(n^{-2}\\lambda_{m}^{-2}mh_{0}^{1/2}(\\log n)^{2})+o_{p}(n^{-2}\\lambda _ { m}^{-1}m^{3}h_{0}^{1/2}(\\log n)^{2})\\\\+o_{p}(n^{-2}\\lambda_{m}^{-3}m^{4}% h_{0}\\log m ) + o_{p}(n^{-2}\\lambda_{m}^{-2}m^{6}h_{0}(\\log m)^{2})\\\\=o_{p}(h_{0}^{3 } ) . \\end{array } \\tag{a.19}\\ ] ] using lemma a.2 and assumption 5 , we conclude that @xmath245{ll}% & \\frac{1}{n}\\sum_{i=1}^{n}\\tilde{b}_{k\\pmb{\\beta}1}(z_{i}^{t}\\pmb{\\beta})\\tilde { b}_{k^{\\prime}\\pmb{\\beta}1}(z_{i}^{t}\\pmb{\\beta } ) \\\\ & = \\frac{1}{n}\\sum _ { i=1}^{n}b_{k\\pmb{\\beta}}(z_{i}^{t}\\pmb{\\beta})b_{k^{\\prime}\\pmb{\\beta}}% ( z_{i}^{t}\\pmb{\\beta})-2\\sum_{j=1}^{m}\\rho_{kj}\\rho_{k^{\\prime}j}\\\\ & + \\sum_{j=1}^{m}\\rho_{kj}\\rho_{k^{\\prime}j}(\\frac{1}{n\\lambda_{j}}\\sum _ { i=1}^{n}\\xi_{ij}^{2})+\\sum_{j\\neq j^{\\prime}}\\rho_{kj}\\rho_{k^{\\prime } j^{\\prime}}\\bar{\\xi}_{jj^{\\prime}}\\\\ & = e[b_{k\\pmb{\\beta}}(z^{t}\\pmb{\\beta})b_{k^{\\prime}\\pmb{\\beta}}% ( z^{t}\\pmb{\\beta})]+o_{p}(h_{0}^{2 } ) , \\end{array}\\ ] ] where @xmath587 .",
    "now lemma a.3 follows from ( a.18 ) , ( a.19 ) and the preceding equation .",
    "* proof of theorem  3.1 .",
    "* by arguments similar to those used in the proof of lemmas a.1 and a.3 , it follows that @xmath588 using lemma a.3 , ( a.20 ) and arguments similar to those used in the proof of lemma 1 of tang ( 2013 ) , we then deduce that @xmath556{l}% \\frac{1}{n}(\\check{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha})^{t}\\tilde { \\pmb{b}}(\\pmb{\\beta})(\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta})\\tilde{\\pmb{b}}% ( \\pmb{\\beta}))^{-1}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta})(\\check{\\pmb{y}}% -\\tilde{\\pmb{w}}\\pmb{\\alpha})\\\\=\\pi^{t}(\\pmb{\\alpha},\\pmb{\\beta})\\gamma ^{-1}(\\pmb{\\beta},\\pmb{\\beta})\\pi(\\pmb{\\alpha},\\pmb{\\beta})+o_{p}% ( 1).\\tag{a.21 } \\end{array}\\ ] ] therefore , lemma a.1 and ( a.21 ) imply that @xmath245{ll}% \\frac{1}{n}(\\check{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha})^{t}% \\pmb{p}(\\pmb{\\beta})(\\check{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha } ) & = \\rho(\\pmb{\\alpha})-\\pi^{t}(\\pmb{\\alpha},\\pmb{\\beta})\\gamma^{-1}% ( \\pmb{\\beta},\\pmb{\\beta})\\pi(\\pmb{\\alpha},\\pmb{\\beta})+o_{p}(1)\\\\ & = : \\tilde{g}(\\pmb{\\alpha},\\pmb{\\beta})+o_{p}(1 ) , \\end{array } \\tag{a.22}\\ ] ] where @xmath521 holds uniformly for @xmath574 and @xmath91 is in any bounded neighborhood of @xmath6 .",
    "similar to the proof of lemmas a.1 and a.3 , it holds that @xmath589 , @xmath590 and @xmath591 .",
    "similar to the proof of ( a.21 ) and ( a.22 ) , we further have @xmath592 and @xmath593 .",
    "therefore , from ( a.1 ) , ( a.22 ) and ( 3.2 ) , it follows that @xmath594 where @xmath521 holds uniformly for @xmath574 and @xmath91 is in any bounded neighborhood of @xmath6 . by the fact that @xmath313 is the minimizer of @xmath314 and using ( a.23 )",
    ", we have @xmath595 by ( a.1 ) and ( a.22 ) , we have that @xmath596 and @xmath597 . from ( 3.2 )",
    ", one obtains @xmath598 . applying ( a.23 ) and ( a.24 )",
    ", we obtain that @xmath599 therefore , @xmath600 ; that is , @xmath601 .",
    "since @xmath256 is locally convex at @xmath257 , it follows that @xmath602 and @xmath603 .",
    "this completes the proof of ( 3.3 ) .    from ( a.11 ) , assumption 5 and the fact that @xmath604 , we have @xmath605 applying assumption 5 and ( a.25 ) , we can easily prove that @xmath606 in lemma a.1 , @xmath607 in lemma a.3 and @xmath608 .",
    "consequently , it follows that @xmath609 and @xmath610 .",
    "now ( 3.4 ) follows from assumption 8 .",
    "this completes the proof of theorem 3.1 .",
    "* lemma  a.4 . *  under assumptions 1 - 7",
    ", it holds that @xmath611 where @xmath521 holds uniformly for @xmath574 , @xmath91 is in any bounded neighborhood of @xmath6 and @xmath612 with @xmath613^{t}\\gamma ^{-1}(\\pmb{\\beta } , \\pmb{\\beta})e[\\pmb{b}(z^{t}\\pmb{\\beta})v_{r}% ] , \\ \\ k , r=1,\\ldots , q,\\tag{a.26}\\]]@xmath614^{t}\\bar { \\pmb{b}}(\\pmb{\\alpha},\\pmb{\\beta } ) + e[\\pmb{b}(z^{t}\\pmb{\\beta})v_{k}% ] ^{t}\\breve{\\pmb{b}}_{r}(\\pmb{\\alpha},\\pmb{\\beta}),\\tag{a.27}\\ ] ] for @xmath334 , and @xmath245{ll}% \\pi_{(q+k)(q+r ) } & = [ \\bar{\\pmb{b}}^{t}(\\pmb{\\alpha},\\pmb{\\beta})r_{rk}% ( \\pmb{\\beta},\\pmb{\\beta})+\\breve{\\pmb{b}}_{r}^{t}% ( \\pmb{\\alpha},\\pmb{\\beta})h_{k}(\\pmb{\\beta},\\pmb{\\beta})]\\bar{\\pmb{b}}% ( \\pmb{\\alpha},\\pmb{\\beta})-[\\ddot{\\pi}_{kr}^{t}(\\pmb{\\alpha},\\pmb{\\beta})\\\\ & -\\bar{\\pmb{b}}^{t}(\\pmb{\\alpha},\\pmb{\\beta})m_{kr}% ( \\pmb{\\beta},\\pmb{\\beta})]\\bar{\\pmb{b}}(\\pmb{\\alpha},\\pmb{\\beta } ) \\\\&+[\\dot{\\pi } _ { k}^{t}(\\pmb{\\alpha},\\pmb{\\beta})-\\bar{\\pmb{b}}^{t}% ( \\pmb{\\alpha},\\pmb{\\beta})h_{k}(\\pmb{\\beta } , \\pmb{\\beta})]\\check{\\pmb{b}}% _",
    "{ r}(\\pmb{\\alpha},\\pmb{\\beta } ) , \\end{array } \\tag{a.28}\\ ] ] for @xmath336 , @xmath615 , @xmath616 @xmath617 , @xmath618 and @xmath619 , @xmath620 is a @xmath341 matrix whose @xmath342th element is @xmath621 $ ] and @xmath622 .",
    "* proof . *",
    "let @xmath623 be the @xmath624th element of @xmath625 . from ( 3.6 ) and ( 3.7 )",
    ", we have that @xmath626,\\ \\ k , r=1,\\ldots , q,\\tag{a.29}\\]]@xmath627,\\ \\",
    "k,=1,\\ldots , q;r=1,\\ldots , d-1,\\tag{a.30}\\]]@xmath628 for @xmath336 , where @xmath629 for @xmath630 , @xmath631 , @xmath632 and @xmath633 with for simplicity of notation , @xmath634 and @xmath635 .",
    "since @xmath636 , we then have @xmath637 hence , @xmath638 note that @xmath639 .",
    "we further have @xmath640.\\tag{a.32}\\ ] ] similar to the proof of lemmas a.2 and a.3 , we obtain that @xmath641 furthermore , under assumption 5 , lemma a.3 yields that @xmath642 .",
    "similar to the proof of lemma 1 of tang @xcite , we have @xmath643 . by lemma a.9 of huang et al .",
    "@xcite , we also have that @xmath644 and @xmath645 . using ( a.33 )",
    ", we have @xmath646 and @xmath647 similar to the proof of ( a.20 ) , we obtain @xmath648 .",
    "observe that @xmath649 and hence @xmath650 .",
    "let @xmath651 , @xmath652 and @xmath653 . then @xmath245{l}%    _ { r}(\\frac{k_{n}}{n}\\tilde{\\pmb{b}}^{t}\\tilde{\\pmb{b}})^{-1}\\vec { \\pmb{y}}-(k_{n}\\gamma(\\pmb{\\beta},\\pmb{\\beta}))^{-1}\\vec{\\pmb{b}}_{r}% ( \\frac{k_{n}}{n}\\tilde{\\pmb{b}}^{t}\\tilde{\\pmb{b}})^{-1}\\vec{\\pmb{y}}\\\\ \\leq|(\\frac{k_{n}}{n}\\tilde{\\pmb{b}}^{t}\\tilde{\\pmb{b}})^{-1}-(k_{n}% \\gamma(\\pmb{\\beta},\\pmb{\\beta}))^{-1}|_{\\infty}\\vert\\vec{\\pmb{b}}_{r}% \\vert_{\\infty}\\vert(\\frac{k_{n}}{n}\\tilde{\\pmb{b}}^{t}\\tilde{\\pmb{b}}% ) ^{-1}\\vert_{\\infty}\\vert\\vec{\\pmb{y}}\\vert_{\\infty}\\\\ = o_{p}(h_{0}^{3})o_{p}(1)o_{p}(1)o_{p}(1)=o_{p}(h_{0}^{3 } ) \\end{array}\\ ] ] and @xmath245{l}%    { n}\\tilde{\\pmb{b}}^{t}\\tilde{\\pmb{b}})^{-1}\\vec{\\pmb{y}}-(k_{n}\\gamma ( \\pmb{\\beta},\\pmb{\\beta}))^{-1}\\vec{h}_{r}(\\pmb{\\beta},\\pmb{\\beta})(\\frac { k_{n}}{n}\\tilde{\\pmb{b}}^{t}\\tilde{\\pmb{b}})^{-1}\\vec{\\pmb{y}}|_{\\infty}\\\\ \\leq\\vert(k_{n}\\gamma(\\pmb{\\beta},\\pmb{\\beta}))^{-1}\\vert_{\\infty}%    ( \\frac{k_{n}}{n}\\tilde{\\pmb{b}}^{t}\\tilde{\\pmb{b}})^{-1}\\vert_{\\infty}% \\vert\\vec{\\pmb{y}}\\vert_{\\infty}\\\\ = o(1)o_{p}(h_{0}^{3})o_{p}(1)o_{p}(1)=o_{p}(h_{0}^{3 } ) .",
    "\\end{array}\\ ] ] furthermore , it holds that @xmath245{l}%    _ { r}(\\frac{k_{n}}{n}\\tilde{\\pmb{b}}^{t}\\tilde{\\pmb{b}})^{-1}\\vec{\\pmb{y}}\\\\ -(k_{n}\\gamma(\\pmb{\\beta},\\pmb{\\beta}))^{-1}\\vec{h}_{r}% ( \\pmb{\\beta},\\pmb{\\beta})(k_{n}\\gamma(\\pmb{\\beta},\\pmb{\\beta}))^{-1}% \\pi(\\pmb{\\alpha},\\pmb{\\beta})|_{\\infty}=o_{p}(h_{0}^{3 } ) \\end{array } \\tag{a.35}\\ ] ] under assumption 5 , similar to the proof of ( a.20 ) , we deduce that @xmath654 similar to the proof of ( a.35 ) , we further deduce that @xmath655 combining ( a.32 ) , ( a.35 ) and ( a.37 ) ,",
    "we then have @xmath656 by arguments similar to those used in the proof of ( a.35 ) , we further have that @xmath657 similar to the proof of ( a.39 ) , we obtain that @xmath658and @xmath245{ll}% & \\frac{1}{n}(\\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}-\\tilde{\\pmb{b}}% \\tilde{\\pmb{b}})^{t}(\\ddot{\\tilde{\\pmb{b}}}_{kr}\\tilde{\\pmb{b}}+\\dot { \\tilde{\\pmb{b}}}_{k}\\dot{\\pmb{b}}_{r } ) \\\\ & = [ \\ddot{\\pi}_{kr}^{t}% ( \\pmb{\\alpha},\\pmb{\\beta})-\\bar{\\pmb{b}}^{t}(\\pmb{\\alpha},\\pmb{\\beta})m_{kr}% ( \\pmb{\\beta},\\pmb{\\beta})]\\bar{\\pmb{b}}(\\pmb{\\alpha},\\pmb{\\beta})\\\\ & + [ \\dot{\\pi}_{k}^{t}(\\pmb{\\alpha},\\pmb{\\beta})-\\bar{\\pmb{b}}^{t}% ( \\pmb{\\alpha},\\pmb{\\beta})h_{k}(\\pmb{\\beta},\\pmb{\\beta})]\\check{\\pmb{b}}% _ { r}(\\pmb{\\alpha},\\pmb{\\beta})+o_{p}(1 ) . \\end{array}\\ ] ] now ( a.28 ) follows from ( a.31 ) , ( a.39 ) , ( a.40 ) and the preceding expression . using the fact that @xmath659 , ( a.26 ) and ( a.27 ) can be proved in a similar fashion .",
    "this completes the proof of lemma a.4 .",
    "* lemma  a.5 . *  under assumptions 1 to 3 and 5 , it holds that @xmath660^{2}=o_{p}(n^{-1}\\lambda_{m}^{-1}m),\\ ] ] where @xmath661 .",
    "* proof *  set @xmath662^{2}$ ] , @xmath663 @xmath664^{2}$ ] and @xmath665 .",
    "note that @xmath660^{2}\\leq3(s_{1}+s_{2}+s_{3}% ) .\\tag{a.41}\\ ] ] since @xmath666=0 $ ] , then from assumptions 1to 3 , we obtain @xmath667 similar to the proof of ( a.6 ) , ( a.7 ) and using assumption 5 , we deduce that @xmath668 and @xmath245{ll}% s_{3 } & \\leq c\\sum_{j=1}^{m}\\frac{(\\hat{\\lambda}_{j}-\\lambda_{j})^{2}}% { \\lambda_{j}^{3}}\\big(\\bar{\\zeta}_{j}^{2}+[\\frac{1}{n}\\sum_{l=1}^{n}\\zeta _ { l}(\\hat{\\xi}_{lj}-\\xi_{lj})]^{2}\\big)[1+o_{p}(1)]\\\\ & = o_{p}(n^{-1}\\lambda_{m}^{-1}+n^{-3}\\lambda_{m}^{-4}m^{3}\\log m+n^{-2}% \\lambda_{m}^{-3}m)=o_{p}(n^{-1}\\lambda_{m}^{-1 } ) . \\end{array } \\tag{a.44}\\ ] ] now lemma a.5 follows from combining ( a.41 ) to ( a.44 ) .",
    "* lemma  a.6 . *  denote @xmath556{ll}% \\dot{g}_{0r}(z_{i})=\\frac{\\partial g_{0}(z_{i}^{t}\\pmb{\\beta})}{\\partial \\beta_{r}}|_{\\pmb{\\beta}=\\pmb{\\beta}_{0}}\\\\=\\sum_{k=1}^{k_{n}}b_{0k}% b_{k}^{\\prime}(z_{i}^{t}\\pmb{\\beta } _ { 0})\\big(z_{ir}-\\frac{\\beta_{0r}z_{id}% } { \\sqrt{1-(\\beta_{01}^{2}+\\ldots+\\beta_{0(d-1)}^{2})}}\\big ) \\end{array}\\ ] ] for @xmath321 and @xmath669 . under assumptions 1 , 2 , 4 and 5",
    ", it holds that @xmath670    * proof *  let @xmath671 . observe that @xmath245{ll}% ( \\sum_{i=1}^{n}\\xi_{ij}a_{ri})^{2 } & \\leq4\\big(\\sum_{i=1}^{n}\\xi_{ij}% a_{ri}^{\\ast}\\big)^{2}\\\\ & + 4\\big(\\sum_{i=1}^{n}\\xi_{ij}\\sum_{j^{\\prime}=1}^{m}\\frac{1}{\\lambda _ { j^{\\prime}}}[\\frac{1}{n}\\sum_{l=1}^{n}\\dot{g}_{0r}(z_{l})(\\hat{\\xi } _ { lj^{\\prime}}-\\xi_{lj^{\\prime}})]\\xi_{ij^{\\prime}}\\big)^{2}\\\\ & + 4\\big(\\sum_{i=1}^{n}\\xi_{ij}\\sum_{j^{\\prime}=1}^{m}(\\frac{1}{\\hat{\\lambda } _ { j^{\\prime}}}-\\frac{1}{\\lambda_{j^{\\prime}}})[\\frac{1}{n}\\sum_{l=1}^{n}% \\dot{g}_{0r}(z_{l})\\hat{\\xi}_{lj^{\\prime}}]\\xi_{ij^{\\prime}}\\big)^{2}\\\\ & + 4\\big(\\sum_{i=1}^{n}\\xi_{ij}\\sum_{j^{\\prime}=1}^{m}\\frac{1}{\\hat{\\lambda } _ { j^{\\prime}}}[\\frac{1}{n}\\sum_{l=1}^{n}\\dot{g}_{0r}(z_{l})\\hat{\\xi } _",
    "{ lj^{\\prime}}](\\hat{\\xi}_{ij^{\\prime}}-\\xi_{ij^{\\prime}})\\big)^{2}\\\\ & = : 4(t_{j1}+t_{j2}+t_{j3}+t_{j4 } ) . \\end{array } \\tag{a.45}\\ ] ] by direct computations and using assumption 1 , we obtain @xmath245{ll}% e(\\xi_{ij}^{2}{a_{ri}^{\\ast}}^{2 } ) & \\leq2e(\\xi_{ij}^{2}\\dot{g}_{0r}^{2}% ( z_{i}))+2e[\\xi_{ij}^{2}(\\sum_{j^{\\prime}=1}^{m}\\frac{1}{\\lambda_{j^{\\prime}}% } ( \\frac{1}{n}\\sum_{l=1}^{n}\\dot{g}_{0r}(z_{l})\\xi_{lj^{\\prime}})\\xi _ { ij^{\\prime}})^{2}]\\\\ & \\leq c(\\lambda_{j}+m\\lambda_{j}/n^{2}+(n-1)m\\lambda_{j}/n^{2}+m^{2}% \\lambda_{j}/n^{2})\\leq c\\lambda_{j}% \\end{array}\\ ] ] and @xmath672\\leq cn\\lambda_{j}.\\ ] ] hence , it follows that @xmath673 similar to the proof of ( a.6 ) and using assumption 1 , we have @xmath674^{2}=o_{p}(n^{-2}\\lambda_{m}^{-2}m^{3}\\log m).\\ ] ] since @xmath675 , then @xmath245{ll}% \\sum_{j=1}^{m}\\lambda_{j}^{-1}t_{j2 } & \\leq\\big(\\sum_{j^{\\prime}=1}^{m}% \\frac{1}{\\lambda_{j^{\\prime}}}[\\frac{1}{n}\\sum_{l=1}^{n}\\dot{g}_{0r}% ( z_{l})(\\hat{\\xi}_{lj^{\\prime}}-\\xi_{lj^{\\prime}})]^{2}\\big)\\\\ & \\times\\big(\\sum_{j=1}^{m}\\lambda_{j}^{-1}\\sum_{j^{\\prime}=1}^{m}\\frac { 1}{\\lambda_{j^{\\prime}}}(\\sum_{i=1}^{n}\\xi_{ij}\\xi_{ij^{\\prime}})^{2}\\big)\\\\ & = o_{p}(n^{-2}\\lambda_{m}^{-2}m^{3}\\log m)o_{p}(n^{2}m)=o_{p}(\\lambda _ { m}^{-2}m^{4}\\log m ) . \\end{array } \\tag{a.47}\\ ] ] similar to the proof ( a.7 ) and using assumption 5 , we deduce that @xmath245{ll}% \\sum_{j=1}^{m}\\lambda_{j}^{-1}t_{j3 } & \\leq\\big(\\sum_{j^{\\prime}=1}^{m}% \\lambda_{j^{\\prime}}(\\frac{1}{\\hat{\\lambda}_{j^{\\prime}}}-\\frac{1}% { \\lambda_{j^{\\prime}}})^{2}[\\frac{1}{n}\\sum_{l=1}^{n}\\dot{g}_{0r}(z_{l}% ) \\hat{\\xi}_{lj^{\\prime}}]^{2}\\big)\\\\ & \\times\\big(\\sum_{j=1}^{m}\\lambda_{j}^{-1}\\sum_{j^{\\prime}=1}^{m}\\frac { 1}{\\lambda_{j^{\\prime}}}(\\sum_{i=1}^{n}\\xi_{ij}\\xi_{ij^{\\prime}})^{2}\\big)\\\\ & = o_{p}(\\lambda_{m}^{-2}m^{2}+n^{-1}\\lambda_{m}^{-4}m^{4}\\log m)=o_{p}% ( \\lambda_{m}^{-2}m^{2}\\log m ) . \\end{array } \\tag{a.48}\\ ] ] and @xmath245{ll}% \\sum_{j=1}^{m}\\lambda_{j}^{-1}t_{j4 } & \\leq\\big(\\sum_{j^{\\prime}=1}^{m}% \\frac{1}{\\lambda_{j^{\\prime}}^{2}}[\\frac{1}{n}\\sum_{l=1}^{n}\\dot{g}_{0r}% ( z_{l})\\hat{\\xi}_{lj^{\\prime}}]^{2}\\big)[1+o_{p}(1)]\\\\ & \\times\\big(\\sum_{j=1}^{m}\\frac{1}{\\lambda_{j}}\\sum_{i=1}^{n}\\xi_{ij}% ^{2}\\big)\\big(\\sum_{j^{\\prime}=1}^{m}\\sum_{i=1}^{n}(\\hat{\\xi}_{ij^{\\prime}% } -\\xi_{ij^{\\prime}})^{2}\\big)\\\\ & = o_{p}(n^{-1}\\lambda_{m}^{-1}m^{5}\\log m+n^{-2}\\lambda_{m}^{-3}m^{7}(\\log m)^{2})\\\\&=o_{p}(\\lambda_{m}^{-2}m^{4}\\log m ) . \\end{array } \\tag{a.49}\\ ] ] now lemma a.6 follows from combining ( a.45)-(a.49 ) and assumption 5 .",
    "* lemma  a.7 . *  under the assumptions 1 - 3 and 5",
    ", it holds that @xmath676    * proof *  let @xmath677 . applying the cauchy - schwarz inequality ,",
    "we obtain @xmath678 using ( a.4 ) , ( a.5 ) , assumption 5 , parseval s identity and some arguments similar to those used to prove lemma a.6 , we deduce that @xmath245{ll}% \\sum_{j=1}^{m}(\\sum_{i=1}^{n}(\\hat{\\xi}_{ij}-\\xi_{ij})a_{ri})^{2 } & \\\\",
    "\\leq2\\sum_{j=1}^{m}[(\\sum_{k\\neq j}(\\hat{\\lambda}_{j}-\\lambda_{k})^{-1}% \\int\\delta\\hat{\\phi}_{j}\\phi_{k}\\sum_{i=1}^{n}\\xi_{ik}a_{ri})^{2}&\\\\+(\\sum _ { i=1}^{n}\\xi_{ij}a_{ri})^{2}(\\int(\\hat{\\phi}_{j}-\\phi_{j})\\phi_{j})^{2 } ] & \\\\",
    "\\leq c|\\vert\\delta\\vert|^{2}\\sum_{j=1}^{m}[\\sum_{k\\neq j}(\\hat{\\lambda}% _ { j}-\\lambda_{k})^{-2}(\\sum_{i=1}^{n}\\xi_{ik}a_{ri})^{2}+\\lambda_{j}^{-2}% j^{2}(\\sum_{i=1}^{n}\\xi_{ij}a_{ri})^{2 } ] &",
    "\\\\ = o_{p}(\\lambda_{m}^{-1}m^{3}\\log m+n^{-1}\\lambda_{m}^{-3}m^{6}\\log m)=o_{p}(n ) . &",
    "\\end{array}\\ ] ] similar to the proof of ( a.7 ) and using assumption 5 , we obtain that @xmath679 this completes the proof of lemma a.7 .",
    "* lemma  a.8 .",
    "*  set @xmath680 . under assumptions 1 - 4 and 5",
    ", it holds that @xmath681 * proof *  observe that @xmath245{ll}% \\sum_{i=1}^{n}\\tilde{\\zeta}_{i}a_{ri } & = \\sum_{j=1}^{m}[a_{j}-\\frac{1}% { \\hat{\\lambda}_{j}}(\\frac{1}{n}\\sum_{l=1}^{n}\\zeta_{l}\\hat{\\xi}_{lj}% ) ] \\sum_{i=1}^{n}\\xi_{ij}a_{ri}\\\\ & -\\sum_{j=1}^{m}\\frac{1}{\\hat{\\lambda}_{j}}(\\frac{1}{n}\\sum_{l=1}^{n}% \\zeta_{l}\\hat{\\xi}_{lj})\\sum_{i=1}^{n}(\\hat{\\xi}_{ij}-\\xi_{ij})a_{ri}% \\\\&+\\sum_{j = m+1}^{\\infty}a_{j}\\sum_{i=1}^{n}\\xi_{ij}a_{ri}. \\end{array } \\tag{a.50}\\ ] ] lemmas a.5 , a.6 and assumption 5 imply that @xmath245{l}% n^{-\\frac{1}{2}}|\\sum_{j=1}^{m}[a_{j}-\\frac{1}{\\hat{\\lambda}_{j}}(\\frac{1}% { n}\\sum_{l=1}^{n}\\zeta_{l}\\hat{\\xi}_{lj})]\\sum_{i=1}^{n}\\xi_{ij}a_{ri}|\\\\ \\leq n^{-\\frac{1}{2}}\\big(\\sum_{j=1}^{m}\\lambda_{j}[a_{j}-\\frac{1}% { \\hat{\\lambda}_{j}}(\\frac{1}{n}\\sum_{l=1}^{n}\\zeta_{l}\\hat{\\xi}_{lj}% ) ] ^{2}\\big)^{\\frac{1}{2}}\\big(\\sum_{j=1}^{m}\\lambda_{j}^{-1}(\\sum_{i=1}^{n}% \\xi_{ij}a_{ri})^{2}\\big)^{\\frac{1}{2}}\\\\ = o_{p}(n^{-1/2}\\lambda_{m}^{-1/2}m+n^{-1}\\lambda_{m}^{-3/2}m^{5/2}(\\log m)^{1/2})=o_{p}(1 ) .",
    "\\end{array } \\tag{a.51}\\ ] ] by arguments similar to those used in the proof of lemma a.6 and using lemma 6.1 of cardot et al .",
    "@xcite , we obtain that @xmath245{ll}% & ( \\sum_{j = m+1}^{\\infty}a_{j}\\sum_{i=1}^{n}\\xi_{ij}a_{ri})^{2 } \\\\ & \\leq ( \\sum_{j = m+1}^{\\infty}a_{j}^{2})(\\sum_{j = m+1}^{\\infty}(\\sum_{i=1}^{n}\\xi _ { ij}a_{ri})^{2})\\\\ & = o_{p}(nm^{-2\\gamma+1}+\\lambda_{m}^{-2}m^{-2\\gamma+4}\\log m)\\sum _ { j = m+1}^{\\infty}\\lambda_{j}\\\\&=o_{p}(n ) . \\end{array } \\tag{a.52}\\ ] ] now lemma a.8 follows from combining ( a.50)-(a.52 ) and lemma a.7 .",
    "* lemma  a.9 . *",
    "suppose that assumptions 1 - 5 hold .",
    "then @xmath682 * proof *  using arguments similar to those used to prove lemmas a.6 and a.7 , we deduce that @xmath683 , @xmath684 and @xmath685 hence @xmath686 using ( 3.1 ) and the assumption @xmath687 , it follows that @xmath688 @xmath689 @xmath690 .",
    "consequently , we have @xmath691 where @xmath692 and @xmath693 + @xmath694 .",
    "now lemma a.9 follows from lemma a.8 , ( a.53 ) and ( a.54 ) .",
    "* lemma  a.10 . *  under the assumptions of theorem 2",
    ", it holds that @xmath556{l}% n^{-\\frac{1}{2}}(\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0}% ) -\\pmb{b}_{0})^{t}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0})\\dot{\\tilde{\\pmb{b}}% } _",
    "{ r}(\\pmb{\\beta}_{0})\\pmb{b}_{0 } \\\\=n^{-\\frac{1}{2}}\\pmb{\\varepsilon}^{t}% \\pmb{b}(\\pmb{\\beta}_{0})\\gamma^{-1}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0}% ) h_{r}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0})\\pmb{b}_{0 } + o_{p}(1 ) , \\end{array}\\ ] ] where @xmath695 .",
    "* proof *  note that @xmath696 . by ( a.33 ) , we obtain @xmath245{ll}%    _ { r}(\\pmb{\\beta}_{0})\\pmb{b}_{0}|_{\\infty } & = |h_{r}(\\pmb{\\beta}_{0}% , \\pmb{\\beta}_{0})\\pmb{b}_{0}|_{\\infty}+o_{p}(h_{0}^{2})\\\\ & \\leq\\max_{1\\leq k\\leq k_{n}}e[b_{k}(z^{t}\\pmb{\\beta}_{0})|\\dot{g}% _ { 0r}(z)|]+o_{p}(h_{0}^{2})\\\\&=o_{p}(h_{0 } ) \\end{array}\\ ] ] similar to lemma a.9 , we have @xmath697 and @xmath698 . hence @xmath245{l}%",
    "n^{-\\frac{1}{2}}|(\\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}_{0}% -\\pmb{\\varepsilon}-\\tilde{\\pmb{b}}(\\pmb{\\beta}_{0})\\pmb{b}_{0})^{t}% \\tilde{\\pmb{b}}(\\pmb{\\beta}_{0})(\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0}% ) \\tilde{\\pmb{b}}(\\pmb{\\beta}_{0}))^{-1}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0}% ) \\dot{\\tilde{\\pmb{b}}}_{r}(\\pmb{\\beta } _ { 0})\\pmb{b}_{0}|\\\\ \\leq k_{n}\\vert n^{-\\frac{1}{2}}|(\\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}% \\pmb{\\alpha}_{0}-\\pmb{\\varepsilon } -\\tilde{\\pmb{b}}(\\pmb{\\beta}_{0}% ) \\pmb{b}_{0})^{t}\\tilde{\\pmb{b}}(\\pmb{\\beta}_{0})\\vert_{\\infty}\\vert ( \\frac{k_{n}}{n}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0})\\tilde{\\pmb{b}}% ( \\pmb{\\beta}_{0}))^{-1}\\vert_{\\infty}\\\\ \\times|\\frac{1}{n}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0})\\dot{\\tilde{\\pmb{b}}% } _ { r}(\\pmb{\\beta}_{0})\\pmb{b}_{0}|_{\\infty}=k_{n}o_{p}(1)o_{p}(1)o_{p}% ( h_{0})=o_{p}(1 ) . \\end{array}\\ ] ] using arguments similar to those used in the proof of ( a.35 ) , we can deduce that @xmath699 hence @xmath245{l}%    ) [ ( \\tilde{\\pmb{b}}^{t}(\\pmb{\\beta } _ { 0})\\tilde{\\pmb{b}}(\\pmb{\\beta}_{0}% ) ) ^{-1}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0})\\dot{\\tilde{\\pmb{b}}}% _ { r}(\\pmb{\\beta}_{0})\\pmb{b}_{0}-\\gamma^{-1}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0}% ) h_{r}(\\pmb{\\beta}_{0},\\pmb{\\beta } _ { 0})\\pmb{b}_{0}]|\\\\ \\leq\\vert n^{-\\frac{1}{2}}\\pmb{\\varepsilon}^{t}\\tilde{\\pmb{b}}(\\pmb{\\beta}_{0}% ) \\vert_{\\infty}|(\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0})\\tilde{\\pmb{b}}% ( \\pmb{\\beta}_{0}))^{-1}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta } _ { 0})\\dot { \\tilde{\\pmb{b}}}_{r}(\\pmb{\\beta}_{0})\\pmb{b}_{0}-\\\\\\gamma^{-1}(\\pmb{\\beta}_{0}% , \\pmb{\\beta}_{0})h_{r}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0})\\pmb{b}_{0}|_{\\infty}\\\\ = o_{p}(k_{n}^{1/2})o_{p}(h_{0})=o_{p}(1 ) . \\end{array}\\ ] ] using arguments similar to those used to prove lemmas a.6 and a.7 , we deduce that @xmath700|=o_{p}(1).\\ ] ] therefore , @xmath245{l}%    ) -\\pmb{b}(\\pmb{\\beta } _ { 0}))\\gamma^{-1}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0}% ) h_{r}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0})\\pmb{b}_{0}]|\\\\ \\leq k_{n}\\vert n^{-\\frac{1}{2}}\\pmb{\\varepsilon}^{t}(\\tilde{\\pmb{b}}% ( \\pmb{\\beta}_{0})-\\pmb{b}(\\pmb{\\beta}_{0}))\\vert_{\\infty}\\vert(k_{n}% \\gamma(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0}))^{-1}\\vert_{\\infty}|h_{r}% ( \\pmb{\\beta}_{0},\\pmb{\\beta}_{0})\\pmb{b}_{0}|_{\\infty}\\\\ = k_{n}o_{p}(1)o_{p}(1)o_{p}(h_{0})=o_{p}(1 ) . \\end{array}\\ ] ] this completes the proof of lemma a.10 .",
    "* proof of theorem  3.2 . *  from lemma a.4 and assumption 8 , we have @xmath701 note that @xmath702 can be written as @xmath245{l}% ( \\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}_{0}-\\tilde{\\pmb{b}}% ( \\pmb{\\beta}_{0})\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0}))^{t}% \\dot{\\tilde{\\pmb{b}}}_{r}(\\pmb{\\beta}_{0})\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0}% , \\pmb{\\beta } _ { 0})\\\\ = ( \\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}_{0}-\\tilde{\\pmb{b}}% ( \\pmb{\\beta}_{0})\\pmb{b}_{0})^{t}\\dot{\\tilde{\\pmb{b}}}_{r}(\\pmb{\\beta}_{0}% ) \\pmb{b}_{0}-(\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0})-\\pmb{b}_{0}% ) ^{t}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0})\\dot{\\tilde{\\pmb{b}}}_{r}% ( \\pmb{\\beta}_{0})\\pmb{b}_{0}\\\\ + ( \\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}_{0}-\\tilde{\\pmb{b}}% ( \\pmb{\\beta}_{0})\\pmb{b}_{0})^{t}\\dot{\\tilde{\\pmb{b}}}_{r}(\\pmb{\\beta}_{0}% ) ( \\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0})-\\pmb{b}_{0})\\\\ -(\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0})-\\pmb{b}_{0})^{t}% \\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0})\\dot{\\tilde{\\pmb{b}}}_{r}(\\pmb{\\beta}_{0}% ) ( \\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0})-\\pmb{b}_{0 } ) . \\end{array } \\tag{a.56}\\ ] ] similar to lemma a.9 , we have @xmath703 and @xmath704 . hence @xmath245{ll}%",
    "\\leq\\frac{k_{n}}{n}\\vert(\\frac{k_{n}}{n}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0}% ) \\tilde{\\pmb{b}}(\\pmb{\\beta}_{0}))^{-1}\\vert_{\\infty}\\\\|\\tilde{\\pmb{b}}% ^{t}(\\pmb{\\beta}_{0})(\\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}_{0}% -\\tilde{\\pmb{b}}(\\pmb{\\beta}_{0})\\pmb{b}_{0})|_{\\infty}\\\\ & = o_{p}(n^{-\\frac{1}{2}}h_{0}^{-\\frac{1}{2 } } ) . \\end{array}\\ ] ] further , we deduce that @xmath245{l}% n^{-\\frac{1}{2}}|(\\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}_{0}% -\\tilde{\\pmb{b}}(\\pmb{\\beta}_{0})\\pmb{b}_{0})^{t}\\dot{\\tilde{\\pmb{b}}}% _ { r}(\\pmb{\\beta}_{0})(\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0}% ) -\\pmb{b}_{0})|\\\\",
    "\\leq\\vert n^{-\\frac{1}{2}}(\\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}_{0}% -\\tilde{\\pmb{b}}(\\pmb{\\beta } _ { 0})\\pmb{b}_{0})^{t}\\dot{\\tilde{\\pmb{b}}}% _ { r}(\\pmb{\\beta}_{0})\\vert_{\\infty}|\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0}% , \\pmb{\\beta}_{0})-\\pmb{b}_{0}|_{\\infty}\\\\ = o_{p}(n^{-1/2}h_{0}^{-2})=o_{p}(1 ) . \\end{array } \\tag{a.57}\\ ] ] applying ( a.34 ) , we have @xmath245{l}% n^{-\\frac{1}{2}}|(\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0}% ) -\\pmb{b}_{0})^{t}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0})\\dot{\\tilde{\\pmb{b}}% } _ { r}(\\pmb{\\beta}_{0})(\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta } _ { 0})-\\pmb{b}_{0})|\\\\ \\leq n^{\\frac{1}{2}}k_{n}\\vert\\frac{1}{n}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0}% ) \\dot{\\tilde{\\pmb{b}}}_{r}(\\pmb{\\beta}_{0})\\vert_{\\infty}|\\tilde { \\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0})-\\pmb{b}_{0}|_{\\infty}^{2}% \\\\=o_{p}(n^{-1/2}h_{0}^{-2})=o_{p}(1 ) . \\end{array } \\tag{a.58}\\ ] ] now @xmath705 can be written as @xmath556{l}% ( \\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\hat{\\pmb{\\alpha}}-\\tilde{\\pmb{b}}% ( \\hat{\\pmb{\\beta}}_{-d})\\hat{\\pmb{b}})^{t}\\tilde{\\pmb{w}}_{k}\\\\=(\\tilde { \\pmb{y}}-\\tilde{\\pmb{w}}\\hat{\\pmb{\\alpha}}-\\tilde{\\pmb{b}}(\\pmb{\\beta}_{0}% ) \\pmb{b}_{0})^{t}\\tilde{\\pmb{w}}_{k}-(\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0}% , \\pmb{\\beta}_{0})-\\pmb{b}_{0})^{t}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0}% ) \\tilde{\\pmb{w}}_{k}% \\end{array}\\ ] ] for @xmath630 .",
    "similar to the proof of lemma a.9 , we deduce that @xmath706 we decompose @xmath707 into three terms as @xmath245{ll}% \\pmb{\\varepsilon}^{t}\\tilde{\\pmb{w}}_{k } & = \\sum_{i=1}^{n}\\varepsilon _ { i}\\big(w_{ik}-\\sum_{j=1}^{m}\\frac{e(w_{lk}\\xi_{j})}{\\lambda_{j}}\\xi _ { ij}\\big)-\\\\&\\sum_{i=1}^{n}\\varepsilon_{i}\\sum_{j=1}^{m}\\frac{\\xi_{ij}}% { \\lambda_{j}}\\big(\\frac{1}{n}\\sum_{l=1}^{n}w_{lk}\\xi_{lj}-e(w_{lk}\\xi _ { j})\\big)\\\\ & -\\sum_{i=1}^{n}\\varepsilon_{i}\\frac{1}{n}\\sum_{l=1}^{n}w_{lk}(\\tilde{\\xi } _ { il}-\\check{\\xi}_{ij } ) .",
    "\\end{array}\\ ] ] similar to the proof of lemma a.8 , we have @xmath708 . since @xmath709 @xmath710 and @xmath711 @xmath712",
    ", it follows that @xmath713 , where @xmath714 .",
    "similar to the proof of lemma a.10 , we have @xmath556{l}% n^{-\\frac{1}{2}}(\\tilde{\\pmb{b}}(\\pmb{\\alpha}_{0},\\pmb{\\beta}_{0}% ) -\\pmb{b}_{0})^{t}\\tilde{\\pmb{b}}^{t}(\\pmb{\\beta}_{0})\\tilde{\\pmb{w}}% _ { k}\\\\=n^{-\\frac{1}{2}}\\pmb{\\varepsilon}^{t}\\pmb{b}(\\pmb{\\beta } _ { 0})\\gamma ^{-1}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0})e(\\pmb{b}(z^{t}\\pmb{\\beta}_{0}% )",
    "w_{k})+o_{p}(1 ) . \\end{array}\\ ] ] hence @xmath556{l}% n^{-\\frac{1}{2}}(\\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\hat{\\pmb{\\alpha}}% -\\tilde{\\pmb{b}}(\\hat{\\pmb{\\beta}}_{-d})\\hat{\\pmb{b}})^{t}\\tilde{\\pmb{w}}% _ { k}\\\\=n^{-\\frac{1}{2}}\\pmb{\\varepsilon}^{t}(\\pmb{v}_{k}-\\pmb{b}(\\pmb{\\beta}_{0}% ) \\gamma^{-1}(\\pmb{\\beta}_{0},\\pmb{\\beta}_{0})e(\\pmb{b}(z^{t}\\pmb{\\beta } _ { 0})w_{k}))+o_{p}(1).\\tag{a.59 } \\end{array}\\ ] ] now ( 3.9 ) follows from ( a.55)-(a.59 ) , lemmas a.9 and a.10 , and the central limit theorem .",
    "this completes the proof of theorem 3.2 .",
    "* lemma  a.11 . *  under the assumptions of theorem 3.3",
    ", it holds that @xmath715    * proof . *  from assumption 6 and lemma a.3 ,",
    "all the eigenvalues of @xmath716 are bounded away from zero and infinity , except possibly on an event whose probability tends to zero .",
    "we then have @xmath245{ll}% \\vert\\tilde{\\pmb{b}}(\\hat{\\pmb{\\alpha}},\\hat{\\pmb{\\beta}})-\\pmb{b}_{0}% \\vert^{2}\\leq ck_{n}^{2}\\vert\\tilde{\\pmb{b}}^{t}(\\hat{\\pmb{\\beta}}% ) ( \\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\hat{\\pmb{\\alpha}}-\\tilde{\\pmb{b}}% ( \\hat{\\pmb{\\beta}})\\pmb{b}_{0})\\vert^{2}/n^{2 } , & \\end{array } \\tag{a.60}\\ ] ] where @xmath717 for a vector @xmath718 .",
    "let @xmath719 . by a taylor expansion , we have that @xmath720 where @xmath721 is between @xmath722 and @xmath723 and @xmath724 similar to the proof of ( a.33 ) and ( a.36 )",
    ", we obtain that @xmath556{l}% \\vert\\frac{1}{n}\\dot{\\tilde{\\pmb{b}}}_{r}^{t}(\\pmb{\\beta}_{-d}^{\\star}% ) ( \\tilde{\\pmb{y}}-\\tilde{\\pmb{w}}\\pmb{\\alpha}^{\\star}-\\tilde{\\pmb{b}}% ( \\pmb{\\beta}_{-d}^{\\star})\\pmb{b}_{0})\\vert^{2}\\\\=\\vert e[\\dot{\\pmb{b}}% _ { r}(z^{t}\\pmb{\\beta}_{-d}^{\\star})v^{t}](\\pmb{\\alpha}^{\\star}% -\\pmb{\\alpha}_{0})\\vert^{2}+o_{p}(1)=o_{p}(1 ) \\end{array}\\ ] ] and @xmath725 . from theorem 3.2",
    ", it holds that @xmath726 @xmath727 .",
    "hence @xmath728 it is easy to prove that @xmath729 . by arguments similar to those used to prove lemma a.9",
    ", we can prove that @xmath730 .",
    "now lemma a.11 follows from ( a.60)-(a.62 ) .",
    "this completes the proof of lemma a.11 .",
    "* lemma  a.12 .",
    "*  define @xmath731 $ ] . under the assumptions of theorem 3.3",
    ", it holds that @xmath732    * proof . *  note that @xmath733=a_{j}\\lambda_{j}$ ] .",
    "define @xmath734\\xi_{ij}% -a_{j}\\lambda_{j}$ ] , @xmath735 $ ] @xmath736 and @xmath737\\hat{\\xi}_{ij}$ ] .",
    "then we have @xmath738,\\tag{a.63}\\ ] ] where @xmath521 holds uniformly for @xmath739 .",
    "since @xmath740 and @xmath741\\leq c\\lambda_{j}/n$ ] , we obtain that @xmath742 let @xmath743=\\sum_{k=1}^{\\infty}a_{k}\\lambda_{k}\\phi_{k}(t)$ ] .",
    "then @xmath245{ll}% i_{2}^{2 } & \\leq2\\int_{\\mathcal{t}}\\big(\\frac{1}{n}\\sum_{i=1}^{n}[y_{i}% -w_{i}^{t}\\pmb{\\alpha}_{0}-g(z_{i}^{t}\\pmb{\\beta}_{0})]x_{i}(t)-m(t)\\big)^{2}% dt\\vert\\hat{\\phi}_{j}-\\phi_{j}\\vert^{2}\\\\ & + 2\\big(\\int_{\\mathcal{t}}m(t)(\\hat{\\phi}_{j}(t)-\\phi_{j}(t))dt\\big)^{2}. \\end{array}\\ ] ] applying assumption 1 , it holds that @xmath245{l}% e\\big(\\int_{\\mathcal{t}}\\big(\\frac{1}{n}\\sum_{i=1}^{n}[y_{i}-w_{i}% ^{t}\\pmb{\\alpha}_{0}-g(z_{i}^{t}\\pmb{\\beta}_{0})]x_{i}(t)-m(t)\\big)^{2}% dt\\big)\\\\ \\leq\\frac{1}{n}\\int_{\\mathcal{t}}e([y_{i}-w_{i}^{t}\\pmb{\\alpha}_{0}% -g(z_{i}^{t}\\pmb{\\beta}_{0})]^{2}x_{i}^{2}(t))dt = o(n^{-1 } ) . \\end{array}\\ ] ] from ( a.8 ) , we obtain @xmath744 . by arguments similar to those used in the proof of ( 5.15 ) of hall and horowitz @xcite",
    ", it follows that @xmath556{l}% \\sum_{j=1}^{\\tilde{m}}\\lambda_{j}^{-2}\\big(\\int_{\\mathcal{t}}m(t)(\\hat{\\phi } _ { j}(t)-\\phi_{j}(t))dt\\big)^{2}\\\\=o_{p}(\\frac{\\tilde{m}}{n\\lambda_{\\tilde{m}}% } + \\frac{\\tilde{m}}{n^{2}\\lambda_{\\tilde{m}}^{2}}\\sum_{j=1}^{\\tilde{m}}% a_{j}^{2}\\lambda_{j}^{-2}j^{3}+\\frac{\\tilde{m}^{3}\\log\\tilde{m}}{n^{2}% \\lambda_{\\tilde{m}}^{2 } } ) .",
    "\\end{array}\\ ] ] hence , using the assumption that @xmath745 , we obtain @xmath746 define @xmath747\\hat{\\xi}_{ij}$ ] , @xmath748\\hat{\\xi}_{ij}$ ] , @xmath749 with @xmath750 @xmath751 .",
    "we write @xmath752 $ ]",
    ". then we have @xmath556{l}%    } \\big(\\frac{1}{n}\\sum_{i=1}^{n}b_{k}(z_{i}^{t}\\pmb{\\beta}_{0})\\xi _ { ij}\\big)^{2}+\\frac{c}{n}\\sum_{i=1}^{n}[h_{0}^{-2}\\vert\\hat{\\pmb{\\beta}}% -\\pmb{\\beta}_{0}\\vert^{2}\\xi_{ij}^{2}+(\\hat{\\xi}_{ij}-\\xi_{ij})^{2 } ] .",
    "\\end{array}\\ ] ] simple calculations yield @xmath753 . applying lemma a.11 , we obtain that @xmath754 . hence , under the assumptions of theorem 3.3",
    ", it holds that @xmath245{ll}% \\sum_{j=1}^{\\tilde{m}}\\lambda_{j}^{-2}i_{31}^{2 } & \\leq\\sum_{j=1}^{\\tilde{m}% } \\lambda_{j}^{-2}\\vert\\tilde{\\pmb{b}}(\\hat{\\pmb{\\alpha}},\\hat{\\pmb{\\beta}}% ) -\\pmb{b}_{0}\\vert_{\\infty}^{2}\\cdot|l_{j}|_{\\infty}\\\\ & = o_{p}(n^{-2}\\tilde{m}\\lambda_{\\tilde{m}}^{-1}h_{0}^{-3}+n^{-2}\\tilde { m}\\lambda_{\\tilde{m}}^{-1}h_{0}^{-5}+n^{-2}\\tilde{m}^{3}\\lambda_{\\tilde{m}% } ^{-2}h_{0}^{-3}\\log\\tilde{m})\\\\ & = o_{p}(n^{-1}\\tilde{m}\\lambda_{\\tilde{m}}^{-1 } ) .",
    "\\end{array } \\tag{a.66}\\ ] ] using a taylor expansion , theorem 3.2 , and the assumption that @xmath371 , we deduce that @xmath245{ll}% \\sum_{j=1}^{\\tilde{m}}\\lambda_{j}^{-2}i_{32}^{2 } & \\leq\\big(\\sum_{j=1}% ^{\\tilde{m}}\\frac{1}{n\\lambda_{j}^{2}}\\sum_{i=1}^{n}\\hat{\\xi}_{ij}% ^{2}\\big)\\\\&\\big(\\frac{1}{n}\\sum_{i=1}^{n}[w_{i}^{t}(\\hat{\\pmb{\\alpha}}% -\\pmb{\\alpha } _",
    "{ 0})+(g_{0}(z_{i}^{t}\\hat{\\pmb{\\beta}})-g(z_{i}^{t}% \\pmb{\\beta}_{0}))]^{2}\\big)\\\\ & = o_{p}(\\tilde{m}\\lambda_{\\tilde{m}}^{-1}+n^{-1}\\tilde{m}^{3}\\lambda _ { \\tilde{m}}^{-2}\\log\\tilde{m})o_{p}(n^{-1}+h_{0}^{2p})\\\\&=o_{p}(n^{-1}\\tilde { m}\\lambda_{\\tilde{m}}^{-1 } ) . \\end{array } \\tag{a.67}\\ ] ] now lemma a.12 follows from combining ( a.63)-(a.67 ) .",
    "* proof of theorem  3.3 . *  note that @xmath556{lll}% \\int_{\\mathcal{t}}[\\hat{a}(t)-a(t)]^{2}dt&\\leq c\\big(\\sum_{j=1}^{\\tilde{m}% } ( \\hat{a}_{j}-\\check{a}_{j})^{2}+\\sum_{j=1}^{\\tilde{m}}(\\check{a}_{j}% -a_{j})^{2}+\\\\&\\tilde{m}\\sum_{j=1}^{\\tilde{m}}a_{j}^{2}\\vert\\hat{\\phi}_{j}% -\\phi_{j}\\vert^{2}+\\sum_{j=\\tilde{m}+1}^{\\infty}a_{j}^{2}\\big)\\tag{a.68 } \\end{array}\\ ] ] and @xmath245{ll}% \\sum_{j=1}^{\\tilde{m}}(\\check{a}_{j}-a_{j})^{2}=\\sum_{j=1}^{\\tilde{m}}% \\frac{(\\hat{\\lambda}_{j}-\\lambda_{j})^{2}}{\\lambda_{j}^{2}}a_{j}^{2}% [ 1+o_{p}(1)]=o_{p}(n^{-1}\\lambda_{\\tilde{m}}^{-1}\\sum_{j=1}^{\\tilde{m}}% a_{j}^{2}\\lambda_{j}^{-1 } ) . &",
    "\\end{array } \\tag{a.69}\\ ] ] assumption 3 implies that @xmath755 @xmath756 and @xmath757 .",
    "now ( 3.10 ) follows from lemma a.12 , ( a.68 ) and ( a.69 ) .",
    "this completes the proof of theorem 3.3 .",
    "* proof of theorem  3.4 . *  from assumption 6 and lemma a.3 ,",
    "all the eigenvalues of @xmath758 are bounded away from zero and infinity , except possibly on an event whose probability tends to zero .",
    "similar to ( 3.1 ) , there exists a spline function @xmath759 such that @xmath241}|g(u)-g^{\\ast}(u)|\\leq ch^{p}.\\tag{a.70}\\ ] ] let @xmath760 . using the properties of b - splines ( de boor 1978 )",
    ", we obtain @xmath245{ll}% \\int_{u_{\\pmb{\\beta}_{0}}}^{u^{\\pmb{\\beta}_{0}}}(\\hat{g}(u)-g(u))^{2}du & \\leq c(\\vert\\pmb{b}^{\\ast}(\\hat{\\pmb{\\alpha}},\\hat{\\pmb{\\beta}})-\\pmb{b}^{\\ast}% _ { 0}\\vert^{2}/k^{\\ast}_{n}+h^{2p}).\\\\ & \\end{array } \\tag{a.71}\\ ] ] using arguments similar to those used to prove lemma a.11 and using the fact that @xmath761 where @xmath762 , one can prove that @xmath763 now ( 3.12 ) follows from ( a.71 ) and the fact that @xmath764 .",
    "this completes the proof of theorem 3.4 .",
    "* proof of theorem  3.5 .",
    "*  observe that @xmath245{l}% \\mbox{mspe}\\leq3\\{\\vert\\hat{a}-a\\vert_{k}^{2}+(\\hat{\\pmb{\\alpha}}% -\\pmb{\\alpha}_{0})^{t}e(ww^{t})(\\hat{\\pmb{\\alpha}}-\\pmb{\\alpha}_{0}% ) + \\\\e([\\hat{g}(z_{n+1}^{t}\\hat{\\pmb{\\beta } } ) -g(z_{n+1}^{t}\\pmb{\\beta}_{0}% ) ] ^{2}|\\mathcal{s})\\ } , \\end{array } \\tag{a.73}\\ ] ] where @xmath765[\\hat{a}(t)-a(t)]dsdt$ ] . under the assumptions of theorem 3.5 , using arguments similar to those used in the proof of theorem 2 of tang ( 2015 )",
    ", we deduce that @xmath766 write @xmath767 using a taylor expansion , theorems 3.2 and 3.4 , ( a.71 ) , and the property of b - spline function , we obtain @xmath245{ll}% & e([\\hat{g}(z_{n+1}^{t}\\hat{\\pmb{\\beta}})-g^{\\ast}(z_{n+1}^{t}\\hat { \\pmb{\\beta}})]^{2}|\\mathcal{s } ) \\\\ & \\leq2e([\\hat{g}(z_{n+1}^{t}\\pmb{\\beta}_{0}% ) -g^{\\ast}(z_{n+1}^{t}\\pmb{\\beta}_{0})]^{2}|\\mathcal{s})\\\\ & + ch^{-2}(\\sum_{k=1}^{k^{\\ast}_{n}}|\\hat{b}_{k}-b^{\\ast}_{0k}|)^{2}% ( \\hat{\\pmb{\\beta}}-\\pmb{\\beta}_{0})^{t}e(zz^{t})(\\hat{\\pmb{\\beta}}% -\\pmb{\\beta}_{0})\\\\ & = o_{p}(n^{-\\frac{2p}{2p+1}})+o_{p}(n^{-2}h^{-5}+n^{-1}h^{2p-4}% ) = o_{p}(n^{-\\frac{2p}{2p+1 } } ) .",
    "\\end{array}\\ ] ] using a taylor expansion , theorem 3.2 and ( a.70 ) , we also obtain @xmath245{ll}% e([g^{\\ast}(z_{n+1}^{t}\\hat{\\pmb{\\beta}})-g(z_{n+1}^{t}\\pmb{\\beta}_{0}% ] ^{2}|\\mathcal{s } ) & \\leq2e([g^{\\ast}(z_{n+1}^{t}\\pmb{\\beta}_{0})-g(z_{n+1}% ^{t}\\pmb{\\beta}_{0})]^{2}|\\mathcal{s})\\\\ & + c(\\hat{\\pmb{\\beta}}-\\pmb{\\beta}_{0})^{t}e(zz^{t})(\\hat{\\pmb{\\beta}}% -\\pmb{\\beta}_{0})=o_{p}(h^{2p } ) .",
    "\\end{array}\\ ] ] hence , @xmath768^{2}|\\mathcal{s})=o_{p}(n^{-2p/(2p+1)})$ ] .",
    "now ( 3.14 ) follows from ( a.73 ) , ( a.74 ) and theorem 3.2 .",
    "this completes the proof of theorem 3.5 .",
    "part of data collection and sharing for this project was funded by the alzheimer s disease neuroimaging initiative ( adni ) ( national institutes of health grant u01 ag024904 ) .",
    "adni is funded by the national institute on aging , the national institute of biomedical imaging and bioengineering , and through generous contributions from the following : alzheimer s association ; alzheimer s drug discovery foundation ; bioclinica , inc .",
    "; biogen idec inc .",
    "; bristol - myers squibb company ; eisai inc . ; elan pharmaceuticals , inc . ;",
    "eli lilly and company ; f. hoffmann - la roche ltd and its affilated company genentech , inc . ;",
    "ge healthcare ; innogenetics , n.v . ; ixico ltd . ; janssen alzheimer immunotherapy research & development , llc . ; johnson & johnson pharmaceutical research & development llc . ; medpace , inc . ; merck & co. , inc . ; meso scale diagnostics , llc . ; neurorx research ; novartis pharmaceuticals corporation ; pfizer inc . ; piramal imaging ; servier ; synarc inc . ; and takeda pharmaceutical company .",
    "the canadian institutes of health research is providing funds to support adni clinical sites in canada .",
    "private sector contributions are facilitated by the foundation for the national institutes of health ( www.fnih.org ) .",
    "the grantee organization is the northern california institute for research and education , and the study is coordinated by the alzheimer s disease cooperative study at the university of california , san diego .",
    "adni data are disseminated by the laboratory for neuro imaging at the university of california , los angeles ."
  ],
  "abstract_text": [
    "<S> this paper studies a _ partial functional partially linear single - index model _ that consists of a functional linear component as well as a linear single - index component . </S>",
    "<S> this model generalizes many well - known existing models and is suitable for more complicated data structures . </S>",
    "<S> however , its estimation inherits the difficulties and complexities from both components and makes it a challenging problem , which calls for new methodology . </S>",
    "<S> we propose a novel profile b - spline method to estimate the parameters by approximating the unknown nonparametric link function in the single - index component part with b - spline , while the linear slope function in the functional component part is estimated by the functional principal component basis . </S>",
    "<S> the consistency and asymptotic normality of the parametric estimators are derived , and the global convergence of the proposed estimator of the linear slope function is also established . </S>",
    "<S> more excitingly , the latter convergence is optimal in the minimax sense . </S>",
    "<S> a two - stage procedure is implemented to estimate the nonparametric link function , and the resulting estimator possesses the optimal global rate of convergence . </S>",
    "<S> furthermore , the convergence rate of the mean squared prediction error for a predictor is also obtained . </S>",
    "<S> empirical properties of the proposed procedures are studied through monte carlo simulations . </S>",
    "<S> a real data example is also analyzed to illustrate the power and flexibility of the proposed methodology .    </S>",
    "<S> ,    ,    , </S>"
  ]
}