{
  "article_text": [
    "high throughput technology , such as the microarray , allows for thousands of pairs of hypotheses to be tested simultaneously .",
    "the usual strategy , when testing a single pair of hypotheses , is to maximize the probability of correctly rejecting a null hypothesis while at the same time ensuring that the probability of erroneously rejecting the null hypothesis , the type i error rate , is controlled at some prespecified level .",
    "however , when testing @xmath1 pairs of hypotheses simultaneously , an additional layer of complexity arises .    simply controlling the type i error rate at level @xmath2 for each individual test can lead to an unpalatable number of type i errors , especially when @xmath3 is large . to combat this phenomenon ,",
    "a multiple testing procedure can be used to control a globally defined error rate , such as the family wise error rate ( fwer ) , which is the probability of committing one or more type i errors , or the false discovery rate ( fdr ) , defined as the expected proportion of type i errors among rejected null hypotheses . for a discussion of these and other global type i error rates",
    "see @xcite .",
    "see also @xcite for a comprehensive review of multiple testing methods .",
    "many multiple testing procedures have been developed based on the premise that data @xmath4 for testing the null hypothesis @xmath5 against the alternative hypothesis @xmath6 has been `` efficiently '' reduced to some one - dimensional test statistic , say @xmath7 , for each of the @xmath8 pairs of hypotheses .",
    "for example , methods in @xcite make use of the @xmath0-value statistics , while methods in @xcite make use of @xmath9-value statistics , which are transformed test statistics that have a standard normal distribution under the null hypotheses .",
    "this paper provides an answer to the question : `` how can test statistics for these multiple testing procedures be computed in a more efficient manner , yet still allow for the procedures to be valid ? '' since many multiple testing procedures depend upon the @xmath0-value statistics , and are valid if they are mutually independent and uniformly distributed under the null hypotheses , we focus on @xmath0-value statistics satisfying these independence and uniformity conditions .",
    "in particular , we provide tools for constructing _ compound _",
    "@xmath0-value statistics , which are those that depend upon all of the available data @xmath10 via @xmath11 , that are independent and uniformly distributed under the null hypotheses .",
    "as an example , we develop compound @xmath0-value statistics for testing for shifts in location , and show that they satisfy the uniformity and independence conditions .",
    "it is shown analytically and through simulations that multiple testing procedures will remain valid and tend to reject more false null hypotheses when applied to these compound @xmath0-values , instead of the usual _ simple _ @xmath0-values , defined via @xmath12 .",
    "this paper proceeds as follows . in section 2",
    ", we present the mathematical framework and results that connect compound @xmath0-value statistics to compound decision functions .",
    "section 3 utilizes sample - splitting ideas from @xcite and @xcite , as well as results from section 2 , to develop a method for constructing compound @xmath0-value statistics that satisfy the independence and uniformity conditions .",
    "shrinkage estimators and results from sections 2 and 3 are used to develop a class of compound @xmath0-value statistics for testing for location shifts in section 4 . in section 5 , it is shown analytically and through simulation that the proposed compound @xmath0-value statistics , when compared to the usual simple @xmath0-value statistics , will lead to more powerful multiple testing procedures .",
    "methods are also compared to some other compound multiple testing procedures .",
    "compound and simple @xmath0-values , along with two different multiple testing procedures , are used to analyze a real microarray data set in section 6 .",
    "the compound @xmath0-values allow for substantially many more rejected null hypotheses .",
    "some concluding remarks are in section 7 . to make this paper more readable",
    ", all proofs of the theorems are gathered in the appendix .",
    "in this section , we present the basic framework , which was also considered in @xcite and @xcite , and establish some fundamental results that will be useful for developing compound @xmath0-value statistics .",
    "objects of main interest to us will be a random @xmath13 matrix of observables @xmath14 with @xmath15 and @xmath16 .",
    "each @xmath17 need not also be 1-dimensional . to refer to a portion of the matrix , we denote by @xmath18 \\equiv ( x_{mn}:m\\in a , n\\in b)$ ] . to refer to a set of columns indexed by @xmath19 , we write @xmath20 \\equiv x[,b]$ ] and likewise write @xmath21 $ ] to refer to a set of rows .",
    "if referring to a single column , say column @xmath22 , we write @xmath23 \\equiv x[,n]$ ] .",
    "similarly , we write @xmath24 $ ] to refer to data in row @xmath25 . to refer to an element of a matrix",
    ", we write @xmath26 $ ] .",
    "the distribution function of @xmath27 is represented by @xmath28 .",
    "the collection of possible distribution functions @xmath29 , sometimes called a model for @xmath27 , will need to be specified , such as in model [ mvn ] .",
    "[ mvn ] let @xmath30 , where @xmath31;{\\text{\\mbox{\\boldmath$\\mu$}}},{\\text{\\mbox{\\boldmath$\\sigma$}}})\\right\\ } $ ] and @xmath32 is the multivariate normal distribution function with @xmath33 mean vector @xmath34 and @xmath35 covariance matrix @xmath36 .",
    "this model , which assumes that columns of @xmath27 are independent and identically distributed according to an @xmath3-dimensional multivariate normal distribution , will be considered in more detail in section [ sec4 ] .",
    "pairs of hypotheses to be tested will be specified in terms of the model for the entire matrix of data .",
    "let @xmath37 and @xmath38 be null sub - models and alternative sub - models , respectively , such that @xmath39 and @xmath40 .",
    "the goal is to determine , for each @xmath41 , which sub - model @xmath28 belongs to .",
    "this is equivalent to testing the null hypothesis @xmath42 against the alternative hypothesis @xmath43 , for each @xmath25 .",
    "each of the @xmath3 pairs of hypotheses will be tested with either a * compound * decision function , defined @xmath44 , or a * simple * decision function , defined @xmath45 , where @xmath24\\in \\mathcal{x}_m$ ] .",
    "the size of @xmath46 is defined by @xmath47\\ ] ] where @xmath48 $ ] is short for @xmath49 $ ] . since the size @xmath50 of @xmath46",
    "can be specified , we write @xmath51 . throughout this paper , it is assumed that for every @xmath52 , @xmath53 is nondecreasing and right - continuous a.e .",
    "@xmath54 $ ] . as in @xcite and @xcite",
    ", we refer to this collection of decision functions @xmath55\\}$ ] as a * decision process * , and refer to @xmath56 as a * multiple decision process*. further , we say that @xmath57 is compound if each @xmath58 is compound .",
    "this stochastic process framework allows for a natural definition of a @xmath0-value statistic .",
    "[ p - value ] the @xmath0-value statistic for decision process @xmath55\\}$ ] is @xmath59:\\delta_m(x;\\eta_m)=1\\}.$ ]    given data @xmath60 , @xmath61 is the smallest size allowing for @xmath5 to be rejected .",
    "a @xmath0-value statistic is said to be * compound * if it depends on all of the data , and is written @xmath62 .",
    "a @xmath0-value statistic will be called * simple * if it depends only on @xmath24 $ ] , and will be written @xmath63)$ ] .",
    "note that if a decision process is compound , then its corresponding @xmath0-value statistic will be compound by definition [ p - value ] , while if @xmath57 is simple , then its @xmath0-value statistic will be simple .    in theorem [ thmpvsd ]",
    "below , we see that definition [ p - value ] ensures that a @xmath0-value statistic will be stochastically greater than or equal to a uniform distribution under the null hypotheses . to emphasize that this notion of uniformity depends upon the null model under consideration , we say that @xmath62 is @xmath64**-uniform * * if @xmath65 for every @xmath66 $ ] , and say that the collection of @xmath0-value statistics @xmath67 is @xmath68**-uniform * * if @xmath62 is @xmath64-uniform for each @xmath69 , where @xmath70 indexes those pairs of hypotheses for which @xmath5 is true .",
    "[ thmpvsd ] the collection of @xmath0-value statistics @xmath71 for a multiple decision process @xmath72 is @xmath68-uniform .",
    "many multiple testing procedures assume that @xmath0-value statistics are independent of each other under the null hypotheses and independent of @xmath0-value statistics from false null hypotheses .",
    "it is therefore useful to more formally examine this notion .",
    "we say that @xmath73 is @xmath68**-independent * * if for every @xmath74 and @xmath75^{m}$ ] , @xmath76\\right ) = \\left[\\prod_{m\\in\\mathcal{m}_0}{\\mathbf{p}}_f\\left(p_{\\delta_m}(x)\\leq t_m\\right)\\right]{\\mathbf{p}}_f\\left(\\bigcap_{m\\in\\mathcal{m}_1 } [ p_{\\delta_m}(x)\\leq t_m]\\right)\\ ] ] where @xmath77 .",
    "likewise , the mdp @xmath72 is @xmath68**-independent * * if for every @xmath74 , @xmath78 , and @xmath79^m$ ] , we have @xmath80\\right ) = } \\nonumber\\\\ & & \\left[\\prod_{m\\in\\mathcal{m}_0}{\\mathbf{p}}(\\delta_m(x;\\eta_m)=d_m)\\right]{\\mathbf{p}}_f\\left(\\bigcap_{m\\in\\mathcal{m}_1}[\\delta_m(x;\\eta_m)=d_m]\\right).\\end{aligned}\\ ] ] theorem [ thmindependent ] below states that a collection of @xmath0-value statistics satisfy the independence condition if and only if their corresponding decision processes satisfy the condition .    [ thmindependent ]",
    "the collection of @xmath0-value statistics @xmath81 for a multiple decision process @xmath72 is @xmath68-independent if and only if @xmath72 is @xmath68-independent .",
    "this theorem allows us to use definition [ p - value ] and an @xmath68-independent compound multiple decision process as a mechanism for defining a collection of independent compound @xmath0-value statistics .",
    "the next section provides some tools for constructing this type of multiple decision process .",
    "in this section , we will consider splitting one data set into two data sets via @xmath82 , which we will refer to as training data and test data , respectively .",
    "this idea was first considered in @xcite for testing a single pair of hypotheses in the normal distribution setting .",
    "@xcite also considered sample splitting in the multiple testing setting , but focused on a specific type of decision function for controlling the expected number of false positives .",
    "we avoid specifying the form of the decision function or error rate to be controlled here .",
    "our goal is to develop a general @xmath68-uniform and @xmath68-independent collection of compound @xmath0-value statistics , which can then be used to control many different error rates .",
    "let @xmath83 index a set of training data @xmath84 $ ] and let @xmath85 index the set of test data @xmath86 $ ] .",
    "consider decision functions taking the form @xmath87,x[m,\\bar t];\\eta_m).\\ ] ] note that each decision function depends on different test data @xmath88 $ ] , but also depends on the same training data @xmath84 $ ] . without loss of generality",
    ", we refer to the test data for @xmath5 by @xmath89 $ ] and the training data by @xmath90 $ ] , where @xmath91 $ ]",
    ". the following independence condition will be necessary for constructing @xmath68-independent @xmath0-value statistics .",
    "[ condition ] the collection @xmath92 is a mutually independent collection of random observables , and is independent of the collection @xmath93 .",
    "we are now in a position to state theorem [ mainthm ] , which allows for compound @xmath0-value statistics to be @xmath68-uniform and @xmath68-independent .",
    "[ mainthm ] let @xmath94 be a multiple decision process , where @xmath95\\}$ ] tests @xmath96 against @xmath97 for each @xmath25 . if , for every @xmath98 , @xmath99 for every @xmath69 and @xmath100 $ ] , then @xmath101 is @xmath68-uniform . if , in addition , condition [ condition ] is satisfied , then @xmath101 is @xmath68-independent .",
    "it is important to emphasize that the decision processes , and hence @xmath0-value statistics , are allowed to be dependent under the alternative hypotheses .",
    "in fact , we will see that improvements over the usual simple @xmath0-values will be made by constructing @xmath0-values that are dependent under the alternative hypotheses .",
    "in this section we will develop compound @xmath0-value statistics for testing multiple pairs of hypotheses regarding location parameters .",
    "the strategy is to develop an @xmath68-independent compound multiple decision process , and then make use of definition [ p - value ] and theorem 3 to derive @xmath68-uniform and @xmath68-independent compound @xmath0-values . in what follows ,",
    "we utilize model 1 to develop the @xmath0-values , but results are not limited to this setting .",
    "this notion is discussed in more detail in section 5 .",
    "assume that @xmath27 has distribution function @xmath102 where @xmath103 is model [ mvn ] with mean vector @xmath104 and covariance matrix @xmath105 . here",
    ", we let the mean vector and covariance matrix depend on @xmath106 so that , as we will see , the distribution of the sufficient statistics for the hypotheses of interest is free of @xmath106 .",
    "the pairs of hypotheses are @xmath107 and @xmath108 for each @xmath25 .",
    "the collection of true null hypotheses is indexed by @xmath109 and the collection of false null hypotheses is indexed by @xmath110 .",
    "we simplify our notation by writing vectors of sufficient statistics for @xmath34 with respect to the training data @xmath84 $ ] and test data @xmath86 $ ] by @xmath111 \\mbox { and } z = \\sum_{n\\in \\bar t}x[,n],\\ ] ] respectively .",
    "denote the vector of sufficient statistics for the complete data by @xmath112.\\ ] ] note that @xmath113 and @xmath114 where @xmath115 is the proportion of training data and @xmath116 is the proportion of test data , and @xmath117 .    to motivate our compound decision function , we first consider a simple decision function , which is allowed to depend on the unknown @xmath34 , rather than training data @xmath118 , and test data @xmath119 .",
    "it is defined via @xmath120 where @xmath121 and @xmath122)$ ] are lower- and upper - tail cutoffs , respectively , @xmath123 is the standard normal distribution function , and @xmath124 $ ] acts as a weight governing @xmath125 and @xmath126 . notice that when @xmath127 , @xmath128 has a standard normal distribution , and hence @xmath129 for any @xmath130 .",
    "since @xmath131 is an independent collection , @xmath72 is an @xmath68-independent multiple decision process .",
    "now , an oracle , who knows @xmath34 , could choose @xmath130 to maximize the power of @xmath46 , defined via @xmath132}\\\\ & & = \\phi\\left(l_m({\\text{\\mbox{\\boldmath$\\mu$}}},\\eta_m)-\\sqrt{1-\\lambda^2}\\mu_m\\right ) + 1 - \\phi\\left(u_m({\\text{\\mbox{\\boldmath$\\mu$}}},\\eta_m ) - \\sqrt{1-\\lambda^2}\\mu_m\\right),\\end{aligned}\\ ] ] thereby maximizing the average power @xmath133 were @xmath134 is the number of false null hypotheses .",
    "it can be verified that for each @xmath135 and for a fixed @xmath136 and @xmath137 , @xmath138 , and hence @xmath139 , is maximized by defining @xmath140 .",
    "thus , the oracle decision function is @xmath141 where @xmath142 and @xmath143)$ ] are the lower - tail and upper - tail oracle cutoffs arising by plugging in @xmath144 for @xmath130 in @xmath125 and @xmath126 in expression ( [ ordelta ] ) .",
    "it should be noted that other optimality criterion have been considered .",
    "@xcite and @xcite considered maximizing the expected number of true positives ( etp ) , which can be written etp = @xmath145 , while @xcite considered minimizing the expected number of `` missed discoveries '' or missed discovery rate ( mdr ) , which can be defined by mdr = @xmath146 = m_1 - etp$ ] .",
    "both of these optimality criterion are satisfied by maximizing @xmath147 .",
    "the oracle @xmath0-values can be derived using definition [ p - value ] .",
    "writing @xmath148 and @xmath149 with @xmath150 for @xmath151 , it follows from definition 1 that the oracle @xmath0-value statistic for @xmath152\\}$ ] can be written as @xmath153 we make use of this particular expression to allow for a more straightforward comparison of the oracle @xmath0-value and the compound @xmath0-value , which is presented next .",
    "it is important to note that since @xmath154 is an @xmath155-independent mdp , @xmath156 is @xmath157-uniform and @xmath157-independent .    using training data @xmath118 to estimate @xmath144 results in a * compound * decision function @xmath158 where @xmath159 and @xmath160)$ ] are lower- and upper - tail cutoffs , respectively , and @xmath161 estimates @xmath162 .",
    "arguments similar to those made above can be used to show that the compound @xmath0-value statistic for @xmath163 is @xmath164 see @xcite for other forms of simple @xmath0-values for composite hypothesis testing",
    ".    notice that given @xmath165 , if @xmath166 , then the compound and oracle @xmath0-value statistics are equivalent .",
    "hence , the goal will be to develop an @xmath161 that estimates @xmath144 `` well '' .",
    "however , before proceeding , it is important to point out that these compound @xmath0-value statistics are @xmath155-independent and @xmath155-uniform , regardless of the performance of @xmath161 , and hence lead to valid multiple testing procedures .",
    "this result is formally stated in corollary [ cor ] .",
    "let @xmath167 .",
    "then @xmath168 is @xmath155-uniform and @xmath155-independent .",
    "next , we develop a class of estimators of @xmath162 using empirical bayes ideas .",
    "assume , for the moment , that @xmath169 is random , and for @xmath170 , let @xmath171 be independent and identically distributed bernouli random variables with success probability @xmath0 .",
    "note that if @xmath172 , then @xmath5 is false .",
    "further , assume that the distribution function for @xmath169 , given @xmath172 , is @xmath173 since @xmath174 and @xmath175 , we have that @xmath176 has a normal distribution with mean @xmath177 and variance @xmath178 see , for example , @xcite , page 326 .",
    "thus , the posterior distribution function of @xmath169 , given ( @xmath179 ) , is @xmath180\\sqrt{\\frac{\\lambda^2 \\tau^2 + 1}{\\tau^2}}\\right).\\ ] ] here we condition on @xmath181 since , when @xmath182 , @xmath183 = \\eta_m$ ] regardless of @xmath161 , and since the goal is to maximize the power of a @xmath46 when @xmath184 .",
    "we should not be concerned with maximizing the power of @xmath46 when @xmath185 since this would correspond to maximizing the probability of committing a type i error , i.e. , making a false discovery .",
    "since @xmath186 and @xmath187 are not known , the estimate of @xmath144 given by @xmath188 is not yet computable . in an effort to develop easy - to - compute @xmath0-value statistics",
    ", we develop method - of - moments ( mom ) estimators for these parameters . still viewing ( @xmath189 ) as random , we get @xmath190 and @xmath191 + \\tau^2).\\ ] ] setting these expressions equal to the sample mean @xmath192 and sample variance @xmath193 of @xmath194 , respectively , and solving for @xmath186 and @xmath187 yields the mom estimates @xmath195 and @xmath196 note that we set @xmath197 equal to 0 whenever the solution yields a negative estimate of @xmath198 .",
    "both of these mom estimators now depend on the proportion of false null hypotheses @xmath0 , and hence it is necessary to either specify or estimate @xmath0 . in the next section , we will consider setting @xmath199 , and we will refer to resulting estimators of @xmath186 , @xmath187 , and @xmath162 as approximate minimax estimators since this specification corresponds to the assumption that all null hypotheses are false . other possible specification of @xmath0 will be considered in section 6 . for",
    "now , we develop a class of mom estimators for @xmath0 using the fact that @xmath200 = ( 1-p)a(\\epsilon ) + p b(\\epsilon;\\theta,\\tau ) \\geq ( 1-p)a(\\epsilon),\\ ] ] where @xmath201 and @xmath202 . making use of expression ( [ ineq1 ] ) and sample moment @xmath203",
    ", we get @xmath204 which no longer depends upon @xmath187 or @xmath186 , but does depend on the tuning parameter @xmath205 .",
    "this type of estimator has been studied in the multiple testing literature , though not in this sample splitting setting .",
    "see @xcite or @xcite , for example . for other types of estimators of @xmath0 ,",
    "see @xcite , @xcite , @xcite , @xcite , @xcite , among others .",
    "the choice of @xmath205 will be considered in more detail in sections 5 and 6 .    finally , plugging @xmath206/\\hat p(y;\\epsilon)}{\\hat p(y;\\epsilon)\\lambda^4 } , 0\\right\\}\\ ] ] for @xmath186 and @xmath187 in @xmath207",
    "yields the estimate of @xmath162 given by @xmath208 in the next section , we study how the choice of @xmath209 and the performance of @xmath161 affects the power of the compound and oracle decision functions , and hence affects the performance of their corresponding @xmath0-value statistics .",
    "to better understand the performance of the compound @xmath0-value statistic and ultimately determine how @xmath209 and @xmath205 should be chosen , we first compare the power of the oracle decision function to the usual simple decision function . the uniformly most powerful unbiased simple decision function , which does not split the data set but makes use of @xmath210 as test data , is defined via @xmath211 where @xmath212 and @xmath213 .",
    "the power of this simple decision function is @xmath214 from expression ( [ orpow ] ) and the definition of @xmath215 , the power of the oracle decision function is @xmath216 the potential gain in power of the oracle decision function over the simple decision function comes from the refinement of the upper - tail and lower - tail cutoffs .",
    "for example , suppose @xmath217 , @xmath218 , and @xmath219 .",
    "then , @xmath220 and @xmath221 , while @xmath222 and @xmath223 .",
    "hence , @xmath224 , while @xmath225\\approx \\phi(-1.96 + 1)$ ] .",
    "the oracle decision function power is then larger than the simple decision function power since its lower - tail cutoff is -1.645 rather than -1.96 .",
    "however , to implement the oracle decision function , we must take @xmath226 so that some data can be used to estimate the oracle cutoffs . the potential loss in power as a result of only using @xmath227% of the data as test data is manifested in the decreased oracle effect size @xmath228 .",
    "for example , when @xmath217 and @xmath229 , then the effect sizes of the oracle and simple decision functions are .6 and 1 , respectively , and the resulting powers are approximately @xmath230 and @xmath231 , respectively . hence , the refined cutoffs of the oracle decision function could not compensate for the decreased effect size , and as a consequence the compound decision function will be less powerful than the simple decision function .",
    "we more thoroughly examine this notion using figure [ region ] , which depicts the regions of @xmath232 where @xmath233 for several different values of @xmath50 .",
    "we see that the oracle decision function power is greater than the simple decision function power for larger values of @xmath136 when @xmath169 is near 0 .",
    "hence , the potential gain in power of the compound decision function is more pronounced in the frequently encountered low - power setting .",
    "it is important to emphasize that even if @xmath209 is chosen so that some oracle decision functions are less powerful than the simple decision function , it may still be the case that the _ average _ power ( computed via expression ( [ oravepow ] ) ) of the oracle decision functions is larger than the _ average _ power of the simple decision functions .",
    "we now examine the properties of @xmath161 and the power of the compound decision function .",
    "the ideal setting is that for small @xmath209 , @xmath234 with probability 1 .",
    "then , it would follow from the definitions of @xmath235 and @xmath236 that @xmath237 \\\\ & = & e_f[\\delta_m^{(or)}({\\text{\\mbox{\\boldmath$\\mu$}}},z_m;\\eta_m ) ] = \\beta_m^{(or)}({\\text{\\mbox{\\boldmath$\\mu$}}},\\lambda^2,\\eta_m)\\end{aligned}\\ ] ] in theorem [ asymptotic ] , we see that this ideal scenario is achieved asymptotically ( in the number of tests @xmath3 ) under the two - group model for any arbitrary choice of @xmath209 and @xmath205 .",
    "see @xcite for a discussion regarding this type of model , and @xcite , @xcite , @xcite , @xcite , @xcite , among others , for other interesting asymptotic results in this two - group setting .",
    "below , since we will let the number of tests @xmath3 tend to @xmath238 , we write @xmath239 and @xmath240 to indicate that the vectors have length @xmath3 , and the notation `` @xmath241 '' and `` @xmath242 '' means `` converges in distribution '' and `` converges in probability '' , respectively .    [ asymptotic ] suppose that @xmath243 = \\lambda^2{\\text{\\mbox{\\boldmath$\\mu$}}}_m$ ] with @xmath244 for some nonzero scalar @xmath186 and @xmath245 a vector of independent and identically distributed bernoulli random variables with success probability @xmath246 $ ] , and that @xmath247 .",
    "suppose further that estimators of @xmath186 and @xmath187 in expression ( [ hhat ] ) are defined as in expression ( [ estimators ] ) and that @xmath248 = \\lambda^2 + \\lambda^4\\theta^2p(1-p)\\ ] ] as @xmath249 , where @xmath250 is the sample variance of @xmath251 .",
    "then for any @xmath252 and @xmath253 $ ] , @xmath254 and @xmath255 as @xmath256 .",
    "several important points should be made .",
    "first , theorem [ asymptotic ] holds for any fixed @xmath257 , and hence , at least for large @xmath3 and under the two - group model , the choice of @xmath205 becomes less of an issue .",
    "it should also be noted that @xmath251 need not have a multivariate normal distribution .",
    "it is only necessary that @xmath250 consistently estimate the marginal variance of @xmath258 .",
    "finally , the compound @xmath0-value is @xmath259-uniform and independent regardless of @xmath3 . in the next subsection ,",
    "we study the performance of the compound @xmath0-value when the two - group model is not satisfied , and @xmath260 need not estimate @xmath162 well .      in this section ,",
    "we compare the performance of the compound , oracle , and simple @xmath0-values in terms of their ability to allow for multiple testing procedures to be more powerful .",
    "in particular , we consider the bh procedure in @xcite and the @xmath261-value procedure in @xcite and @xcite .",
    "the procedures are defined as follows .",
    "let @xmath262 be a collection of @xmath0-values for testing @xmath5 vs. @xmath6 for @xmath170 , and denote the ordered @xmath0-values by @xmath263 . for each pair of hypotheses ,",
    "the bh decision function is @xmath264 where @xmath265 the @xmath261-value decision function is defined via @xmath266 , where @xmath267 is the estimated @xmath268-value for the @xmath25th pair of hypotheses , defined via @xmath269 here , @xmath270 is the estimated positive false discovery rate ( @xmath271 $ ] ) incurred by rejecting all null hypotheses with a @xmath0-value less than or equal to @xmath272 .",
    "hence , the @xmath268-value can be thought of as the smallest possible @xmath273 allowing for the rejection of @xmath5 .",
    "estimates of the @xmath273 proposed in @xcite , which were shown to be conservative in certain settings , are obtained using the r package q - value .",
    "see @xcite for more details .",
    "the important point is that the @xmath261-value procedure is designed to control the @xmath273 at level @xmath2 assuming that @xmath0-values are independent and uniformly distributed under the null hypotheses .",
    "likewise , @xcite show that the bh procedure controls the @xmath274{\\mathbf{p}}(r>0)$ ] at level @xmath275 under the independence and uniformity assumptions .",
    "since the simple , oracle , and compound @xmath0-values developed in this paper are all @xmath155-uniform and -independent , both procedures are valid when applied to any of these @xmath0-values .    in our simulation",
    ", we considered the same model and hypotheses as in the last section with @xmath276 , @xmath277 , and @xmath278 . for @xmath278 , @xmath127 . hence",
    ", 20% of null hypotheses are false . for @xmath135 , we take @xmath279 , where @xmath280 is the quantile function for a normal distribution with mean @xmath186 and variance @xmath198 . hence , the @xmath169s are the expected values of the order statistics from a normal distribution with mean @xmath186 and variance @xmath198 , thereby allowing the location and spread of the signal , under the alternative hypotheses , to be governed by @xmath186 and @xmath187 . here",
    ", we will consider all combinations of @xmath281 and @xmath282 .",
    "notice that when @xmath283 , the @xmath169s from false null hypotheses are symmetric about 0 .",
    "@xcite showed that in this setting , and under a two - group model , simple @xmath0-values tend to yield efficient multiple testing procedures .",
    "when @xmath186 is not 0 , however , the signals are not symmetric about 0 . also , when @xmath284 , the two - group model is satisfied and theorem 4 is applicable . when @xmath285 , the two - group model is not satisfied , and it need not be the case that @xmath162 is `` well - estimated '' by @xmath286 . for the @xmath287th replicated data set , vectors of training data and test data are generated according to @xmath288 and @xmath289 , respectively . for @xmath290 ,",
    "both procedures are applied to the collection of oracle @xmath0-values computed as in ( [ oraclep - val ] ) , and three different collections of compound @xmath0-values in ( [ compp - val ] ) computed by taking @xmath291 , @xmath292 , and @xmath293 .",
    "the choice of @xmath294 and @xmath295 , which is 1 and 2 standard deviations of @xmath258 under @xmath5 , was recommended in @xcite for this type of estimator .",
    "the usual simple @xmath0-values , which make use of all of the data @xmath296 as test data rather than just @xmath119 , are computed via @xmath297 $ ] .",
    "both procedures were applied to all types of @xmath0-values for all data sets at @xmath298 .",
    "the average sample @xmath273 of the @xmath261-value procedure was less than .05 for all configurations and @xmath0-value types .",
    "similarly , the average sample @xmath299 of the bh procedure was less than .05 for all configurations and @xmath0-value types .",
    "the average power of the bh procedure for a particular set of @xmath0-values and @xmath300-combination is estimated via @xmath301.\\ ] ] the average power of the @xmath261-value procedure is computed analogously .",
    "results are presented in table [ tablesimul ] .",
    "first , notice that when @xmath284 and the two - group model is satisfied , the power of a multiple testing procedure which makes use of the oracle @xmath0-values is equivalent to the power of the procedure when using compound @xmath0-values for any choice of @xmath205 or @xmath209 , just as theorem 4 predicted .",
    "further , this power can be substantially larger than the power of the same multiple testing procedure that makes use of the simple @xmath0-values , especially in the low - power setting .",
    "for example , for @xmath302 , @xmath303 , and @xmath304 , the power of the @xmath261-value procedure is increased by 83% when using the compound @xmath0-values ( when using @xmath305 ) over the simple @xmath0-values ( .22/.12 = 1.83 ) .",
    "the power of the q - value procedure is increased by 80% ( .18/.1 = 1.8 ) .",
    "this supports findings in the previous subsection ( see figure 1 ) , where it was argued that the greatest potential for gain in power occurs when @xmath169 is near 0 .",
    "likewise , as discussed in the previous subsection , when too much data is used as training data , oracle @xmath0-values , and hence compound @xmath0-values , need not yield more powerful multiple testing procedures .",
    "for example , when @xmath306 , the average power of the simple decision functions is greater than the average power of the oracle decision functions in most settings ( the exception being in the frequently encountered low power setting when @xmath303 and @xmath284 ) .",
    "this scenario can and should be avoided in practice by choosing @xmath307 .    when @xmath308 and @xmath309 ( note that the two - group model is not satisfied so that @xmath286 need not estimate @xmath162 well ) , we see that the compound @xmath0-values still result in more power than the usual simple @xmath0-values .",
    "the only exception is the setting when @xmath283 .",
    "however , the loss in power in this setting is small relative to the gain in power in the non - symmetric settings , especially when a small portion of data are used as training data and the data from false null hypotheses are highly concentrated .    in general ,",
    "if less than 10% of the data is being used as training data , compound @xmath0-values will tend to lead to more powerful multiple testing procedures .",
    "the biggest gain in power occurs in the low - power setting when the signals ( the @xmath169s ) are identical .",
    "as the signals become more dispersed , less power is gained .",
    "the sample splitting approach allows for more modeling assumptions regarding the joint behavior of the data , and at the same time enjoys a certain robustness property . to see why , first a discussion regarding relaxing assumptions from the previous sections is provided",
    "then , the methodology is compared to competing strategies .    in general , one may compute a test statistic for test data via @xmath310)$ ] , where @xmath311 is some test statistic so that under @xmath5 , @xmath312",
    ". then , @xmath313 has standard normal distribution ( so long as @xmath28 is continuous ) under the null hypothesis by the probability integral transformation .",
    "compound @xmath0-values can then be computed as in the previous section ( with @xmath314 ) .",
    "this is demonstrated in detail in the following section .",
    "then , from theorem [ mainthm ] , the resulting compound @xmath0-values will be uniformly distributed under @xmath315 .",
    "if test data are independent under the null hypotheses , @xmath0-values will remain independent under the null hypotheses as well . hence , _ regardless of the distribution of the test statistics under the alternative hypothesis _ , the applied multiple testing procedure , whichever is chosen , will be valid .",
    "it is only necessary that the appropriate test statistic be chosen so that @xmath316 does indeed have distribution function @xmath28 under @xmath5 . for robust test statistics for multiple testing procedures",
    "see @xcite .    to better understand the sample splitting approach , it is useful to first discuss procedures based on the two - group model .",
    "@xcite , @xcite , among others , assume that @xmath317 where @xmath318 is the density of @xmath119 under @xmath5 , @xmath319 the density of @xmath119 under @xmath6 , and @xmath0 is a mixing proportion .",
    "@xcite show that the lfdr statistic , defined @xmath320 can be used to control the fdr ( asymptotically in @xmath3 ) so long as @xmath321 and @xmath322 and @xmath323 are consistent estimators . since the validity of the procedure requires consistent estimation of @xmath319 , it is vital that a flexible model for @xmath319 be utilized , as is done in the above references . added efficiency stems from the fact that the lfdr statistic is proportional to the estimated likelihood ratio statistic @xmath324 .",
    "see @xcite for details .",
    "the procedure is _ compound _ because joint behavior of the data is utilized , i.e. information is pooled , through the estimation of @xmath319 with @xmath325 .",
    "the resulting decision rule , which can be written @xmath326 $ ] for some cutoff @xmath327 , is referred to as _ symmetric _ since for all permutation operators @xmath328 , @xmath329 .    in our example in section 4",
    ", we allowed for data to vary according to a different distribution under each alternative hypothesis .",
    "specifically it was assumed that @xmath330 , where @xmath331 is an unknown normal density with mean @xmath169 .",
    "the result was a compound decision rule that depended upon @xmath3 different likelihood ratio statistics @xmath332 , and hence need not be _",
    "we focused on the estimation of @xmath333 since the form of the likelihood ratio statistic only depends upon this quantity in the normal setting .",
    "the joint behavior of the data was modeled by assuming that @xmath334 , and information is pooled by then allowing @xmath335 to depend upon all the training data via @xmath336 and @xmath337 .",
    "@xcite also considered basing decision rules on @xmath3 different normal models .",
    "the main difference between our approach and the aforementioned is that the information pooling is done using only training data , rather than all of the data , and that @xmath0-values for each decision function are provided .",
    "this sample spitting approach allows for _ valid _ @xmath0-values , even if the data are incorrectly modeled under the alternative hypothesis , and even if the number of tests @xmath3 is small . for this reason ,",
    "it is reasonable to base each oracle decision rule on stronger modeling assumptions , as was done here .",
    "further , by computing @xmath0-values for each test , any number of multiple testing procedures could be employed to control the error rate of interest , including but not limited to the fdr , pfdr , or fwer .",
    "in this section , we analyze the microarray data in @xcite using methods from the previous two sections .",
    "this data was also analyzed in @xcite . here ,",
    "@xmath26 $ ] is the @xmath25th gene expression measurement from the @xmath22th microarray , where for @xmath338 , microarray @xmath22 is from an individual without prostate cancer and for @xmath339 , microarray @xmath22 is from an individual with prostate cancer .",
    "the goal is to determine which genes , if any , are differentially expressed across treatment groups .",
    "we assume that @xmath26\\stackrel { i.i.d.}\\sim n(\\gamma_m,\\sigma_m^2)$ ] for @xmath340 and @xmath26\\stackrel{i.i.d}\\sim n(\\gamma_m+\\mu_m,\\sigma_m^2)$ ] for @xmath341 .",
    "the @xmath25th null and alternative hypotheses are @xmath342 and @xmath343 , where @xmath344 is the collection of all normal distribution functions .",
    "we present the form of the compound and simple @xmath0-value statistics . here , @xmath345 , where @xmath346 and @xmath347 index training data from control and treatment groups , respectively , and @xmath348 , where @xmath349 and @xmath350 index test data from control and treatment groups , respectively .",
    "for this data , since the simulation studies from the previous section suggest that between 1 and 10 percent of data should be used as training data , we ( randomly ) select 4 of our 102 microarrays as training data ( @xmath351 and @xmath352 ) . the two sample @xmath353-test statistic for @xmath5 based on test data @xmath354 $ ] is @xmath355 ) = \\frac{\\sum_{n\\in \\bar t_2}x[m , n]/n_{\\bar t_2 } - \\sum_{n\\in \\bar t_1}x[m , n]/n_{\\bar t_1}}{s_{pm}\\sqrt{\\frac{1}{n_{\\bar t_1 } } + \\frac{1}{n_{\\bar t_2}}}}\\ ] ] where @xmath356 and @xmath357 is the pooled sample standard deviation of @xmath358 $ ] and @xmath359 $ ] . to remain consistent with notation in the previous sections , we transform @xmath360 via @xmath361))$ ] so that @xmath362 under @xmath5 by the probability integral transformation . in a similar fashion",
    ", we transform the training data via @xmath363 + @xmath364)))$ ] , where @xmath365)$ ] is student s two - sample @xmath353-test as above but computed on @xmath366 $ ] and @xmath367 $ ] .",
    "it is important to note that since @xmath209 is now fixed , we do not parameterize our test data and training data to have mean and variance that depends on @xmath209 .",
    "the compound decision function can then be defined via @xmath368 ) \\nonumber\\\\ 0 & \\mbox{otherwise } , \\end{array } \\right.\\end{aligned}\\ ] ] where @xmath369 .",
    "it can be verified using arguments from section 4 that the compound @xmath0-value can be written as in expression ( [ compp - val ] ) , and that @xmath161 should estimate @xmath162 .",
    "hence , we define @xmath161 as in ( [ hhat ] ) with @xmath314 since @xmath370 . for the compound @xmath0-values",
    ", we consider taking @xmath371 and @xmath372 in @xmath373 since this corresponds to 1 and 2 standard deviations of @xmath258 under @xmath5 .",
    "we also take @xmath374 as in @xcite and @xmath375 as in the previous section .",
    "the usual two sample @xmath353-test @xmath0-values were computed via @xmath376 ) = 2[1-\\mathcal{t}_{100}(|t(x[m,])|)$ ] , where @xmath377)$ ] is the two sample @xmath353 test statistic as above but with @xmath378 and @xmath379 indexing all of the data from control and treatment groups .",
    "the number of discoveries made by the bh and @xmath261-value procedures when applied to each of the different collections of @xmath0-values at levels @xmath380 are presented in figure [ app ] .",
    "results when compound @xmath0-values made use of @xmath381 are not presented because we get a negative estimate of @xmath0 .",
    "such estimates are not uncommon when @xmath0 and @xmath205 are near 0 due to the fact that the bias of @xmath305 is negligible in this setting .",
    "see @xcite for a discussion regarding this issue .",
    "we see that when making use of any of the compound @xmath0-values , rather than the simple @xmath0-values , both procedures always make at least as many or more ( sometimes substantially more ) discoveries . for example , when the bh procedure is applied at @xmath382 to compound @xmath0-values with @xmath383 , 15 discoveries , rather than 3 , are made . for",
    "@xmath384 , the compound @xmath0-values which assume @xmath385 and @xmath386 allow for the bh procedure to make 5 and 6 discoveries , respectively , while the use of the simple @xmath0-values leads to 0 discoveries .",
    "results are similar for the q - value procedure in that compound @xmath0-values always allow for at least as many discoveries , and sometimes allow for substantially more discoveries .",
    "recent multiple testing research has established that compound multiple testing procedures are typically more efficient than simple multiple testing procedures . in this paper , we have shown that these multiple testing procedures can be made even more efficient by making use of compound test statistics .",
    "we have limited our study to compound @xmath0-value statistics , largely due to the fact that a substantial number of multiple testing procedures make use of @xmath0-value statistics , thus making results in this paper widely applicable .    here ,",
    "the data were split into training and test data , and only training data ( as opposed to all the data ) , were utilized to borrow information across tests .",
    "the main advantage of this data - splitting approach over the usual double dipping approach is that validity of the resulting @xmath0-values and multiple testing procedure is guaranteed , even if data are poorly modeled under the alternative hypotheses , and even for a small number of tests @xmath3 .",
    "intuition suggests that the disadvantage of this approach is that in some settings efficiency will be sacrificed since less data is utilized to estimate parameters governing the form of the oracle decision rule .",
    "a more thorough comparison of this approach and the double dipping approach is warranted , but is beyond the scope of this paper .",
    "see also @xcite for a discussion on this issue .",
    "the examples in this paper could likely be improved upon by considering other types of models for the joint behavior of the data , as well as other type of estimators .",
    "method of moment estimators were utilized to allow for easy - to - compute @xmath0-values .",
    "the assumption that test statistics are independent under the null hypotheses may not be satisfied in practice . in this setting",
    ", we can not expect compound or simple @xmath0-value statistics to be independent under the null hypotheses .",
    "however , many @xmath0-value based multiple testing procedures , including some of those mentioned in the introduction , do not require the independence condition to be satisfied .",
    "results in sections 2 and 3 can still be used to develop compound @xmath0-value statistics satisfying the uniformity condition , which can then be used in these multiple testing procedures .",
    "see @xcite;@xcite for more on relaxing the independence condition .    in closing",
    ", we reiterate the intent in this paper is not to develop a new compound multiple testing procedure , but rather to develop compound @xmath0-value statistics for use in existing multiple testing procedures .",
    "we have only studied the effects of compound @xmath0-value statistics on two compound multiple testing procedures , but we suspect that most multiple testing procedures will behave in a more efficient manner if they are used in conjunction with compound , rather than simple , @xmath0-value statistics .",
    "* proof of theorem [ thmpvsd ] : * it suffices to show that @xmath62 is @xmath64-uniform for every @xmath69 .",
    "but since @xmath387 for every @xmath388 $ ] , the result follows from theorem 2.3 in @xcite by taking @xmath389 .",
    "* proof of theorem [ thmindependent ] : * suppose we could show that @xmath390 for every @xmath52 , @xmath66 $ ] , and @xmath170",
    ". then it will follow that @xmath391\\right)}\\\\   & & = 1 - { \\mathbf{p}}_f\\left(\\bigcup_{m\\in \\mathcal{m}}[\\delta_m(x;t_m ) \\neq i(p_{\\delta_m}(x)\\leq t_m)]\\right)\\\\ & & \\geq 1 - \\sum_{m\\in \\mathcal{m}}{\\mathbf{p}}_f\\left(\\delta_m(x;t_m ) \\neq",
    "i(p_{\\delta_m}(x)\\leq t_m)\\right)\\\\ & & = 1 - 0 = 1,\\end{aligned}\\ ] ] which will imply that @xmath392\\right ) = { \\mathbf{p}}_f\\left(\\bigcap_{m\\in\\mathcal{m}}[\\delta_m(x;t_m)=1]\\right).$ ] the result will then follow from equations ( [ independentp ] ) and ( [ independentd ] ) .",
    "therefore , it suffices to show that @xmath393 .",
    "fix @xmath52 .",
    "there exists a null set @xmath394 such that for every @xmath395 , @xmath396 is right - continuous and nondecreasing with @xmath397 .",
    "fix an @xmath395 . if @xmath398 , then @xmath399 implying that @xmath400 .",
    "hence , @xmath401 by definition [ p - value ] .",
    "next , suppose that @xmath402 . since @xmath403 is right - continuous and nondecreasing , @xmath404 , so that @xmath398 and @xmath405 .",
    "that is , @xmath406 for every @xmath395 .",
    "since @xmath407 , it follows that @xmath408 .",
    "* proof of theorem [ mainthm ] : * theorem [ thmpvsd ] ensures that @xmath101 is @xmath68-uniform since @xmath72 is a decision process . from theorem [ thmindependent ] , if @xmath72 is @xmath68-independent , then @xmath101 is @xmath68-independent .",
    "hence , it suffices to show that @xmath409)}\\\\ & & = { \\mathbf{p}}_f(\\cap_{m\\in\\mathcal{m}_1}[\\delta_m(y , z_m;\\eta_m ) = d_m])\\prod_{m\\in\\mathcal{m}_0}{\\mathbf{p}}_f(\\delta_m(y , z;\\eta_m ) = d_m).\\end{aligned}\\ ] ] but , since @xmath410 for @xmath69 , where @xmath411 then by the conditions of the theorem and using the laws of iterated expectations , we get @xmath412\\right)=   e_f\\left\\{{\\mathbf{p}}_f\\left(\\bigcap_{m\\in\\mathcal{m } } [ \\delta_m(y , z_m;\\eta_m)=d_m]|y\\right)\\right\\ } } \\\\ & & = e_f\\left({\\mathbf{p}}_f\\left(\\bigcap_{m\\in\\mathcal{m}_1}[\\delta_m(y , z_m;\\eta_m)=d_m]|y\\right)\\left(\\prod_{m\\in\\mathcal{m}_0}{\\mathbf{p}}_f(\\delta_m(y , z_m;\\eta_m)=d_m)|y\\right)\\right)\\\\ & & =   e_f\\left({\\mathbf{p}}_f\\left(\\bigcap_{m\\in\\mathcal{m}_1}[\\delta_m(y , z_m)=d_m]|y\\right)\\right)\\prod_{m\\in\\mathcal{m}_0}k_m(\\eta_m)\\\\ & & = { \\mathbf{p}}_f\\left(\\bigcap_{m\\in\\mathcal{m}_1}[\\delta_m(y , z_m;\\eta_m)=d_m]\\right)\\prod_{m\\in\\mathcal{m}_0}{\\mathbf{p}}_f(\\delta_m(y , z_m;\\eta_m ) = d_m).\\end{aligned}\\ ] ]    * proof of corollary [ cor ] : * since condition 1 is satisfied , by theorem [ mainthm ] it is sufficient to show that for every @xmath69 and @xmath413 , @xmath414 = \\eta_m$ ] for any @xmath100 $ ] .",
    "but if @xmath69 , @xmath415 & = & e_f\\left[\\phi(l_m(y,\\eta_m ) ) + 1 - \\phi(u_m(y,\\eta_m))\\right]\\\\ & = &   e_f\\left[\\phi(\\phi^{-1}(\\eta_m h_m(y ) ) + 1-\\phi(\\phi^{-1}(1-\\eta_m[1-h_m(y)]))\\right ] \\\\ & = & e_f\\left[\\eta_m h_m(y ) + 1-(1-\\eta_m[1-h_m(y)])\\right]\\\\ & = & \\eta_m[h_m(y)+1-h_m(y ) ] = \\eta_m\\end{aligned}\\ ] ] for any @xmath100 $ ] .",
    "* proof of theorem [ asymptotic ] : * first , suppose that @xmath69 .",
    "then it follows from theorem [ thmpvsd ] and the fact that @xmath416 and @xmath417 for every @xmath100 $ ] , that @xmath418 where @xmath419 means `` equal in distribution '' and @xmath420 is a uniform random variate .",
    "now , for @xmath421 , if @xmath422 as @xmath249 , then the continuous mapping theorem ( see , for example , page 19 in @xcite ) and expressions ( [ oraclep - val ] ) and ( [ compp - val ] ) imply that @xmath255 . hence , it suffices to show that @xmath423 .",
    "to do so , we show that @xmath424 for some @xmath425 and @xmath426 since these results , together with the continuous mapping theorem , and writing @xmath427 imply @xmath428    to show ( [ theta ] ) , first note that by the inequality in expression ( [ ineq1 ] ) , @xmath429\\equiv p^*<p.\\ ] ] hence , by the definition of @xmath430 and the weak law of large numbers ( wlln ) , @xmath431 .",
    "similarly , since @xmath432 , by the wlln we have @xmath433 . hence , @xmath434    to show ( [ tau ] ) , first note that @xmath435 since @xmath436 is continuous . from the continuous mapping theorem and since @xmath437 and @xmath438 by the inequality in ( [ ineq ] ) , @xmath439 since @xmath440 = \\lambda^2 + \\lambda^4\\theta^2p(1-p)$ ] , the above result implies @xmath441 \\stackrel{p}\\rightarrow c < 0\\end{aligned}\\ ] ] for some @xmath327 .",
    "hence , @xmath442}{\\lambda^4 \\hat p({\\text{\\mbox{\\boldmath$y$}}}_m;\\epsilon)}\\stackrel{p}\\rightarrow \\frac{c}{\\lambda^4 p^ * } < 0\\ ] ] so that @xmath443}{\\lambda^4 \\hat p({\\text{\\mbox{\\boldmath$y$}}}_m;\\epsilon ) } , 0\\right\\}\\stackrel{p}\\rightarrow 0.\\ ] ]",
    "the authors wish to thank professors wensong wu , don edwards , john grego , joshua tebbs , and hongmei zhang .",
    "the authors also acknowledge nsf grant dms0805809 ; national institutes of health ( nih ) grant rr17698 ; and the environmental protection agency ( epa ) grant rd-83241902 - 0 to the university of arizona with subaward number y481344 to the university of south carolina .",
    "these grants partially supported this work .",
    "this work is based on a portion of the first author s phd dissertation at the university of south carolina .",
    "singh , d. , p.  febbo , k.  ross , d.  jackson , m.  j. , c.  ladd , p.  tamayo , a.  renshaw , a.  damico , j.  richie , e.  lander , m.  loda , p.  kantoff , t.  golub , and w.  sellers ( 2002 ) .",
    "gene expression correlates of clinical prostate cancer behavior .  * 2 * , 203209 .",
    "storey , j.  d. , j.  e. taylor , and d.  siegmund ( 2004 ) .",
    "strong control , conservative point estimation and simultaneous conservative consistency of false discovery rates : a unified approach .",
    "* 66 * , 187205 ."
  ],
  "abstract_text": [
    "<S> many multiple testing procedures make use of the @xmath0-values from the individual pairs of hypothesis tests , and are valid if the @xmath0-value statistics are independent and uniformly distributed under the null hypotheses . </S>",
    "<S> however , it has recently been shown that these types of multiple testing procedures are inefficient since such @xmath0-values do not depend upon all of the available data . </S>",
    "<S> this paper provides tools for constructing _ compound _ </S>",
    "<S> @xmath0-value statistics , which are those that depend upon all of the available data , but still satisfy the conditions of independence and uniformity under the null hypotheses . as an example , a class of compound @xmath0-value statistics for testing for location shifts is developed . </S>",
    "<S> it is demonstrated , both analytically and through simulations , that multiple testing procedures tend to reject more false null hypotheses when applied to these compound @xmath0-values rather than the usual @xmath0-values , and at the same time still guarantee the desired type i error rate control . </S>",
    "<S> the compound @xmath0-values , in conjunction with two different multiple testing methods , are used to analyze a real microarray data set . applying either multiple testing method to the compound @xmath0-values , instead of the usual @xmath0-values , </S>",
    "<S> enhances their powers .     </S>",
    "<S> empirical bayes , false discovery rate , multiple testing , multiple decision function , multiple decision process , test data , training data , microarray analysis . </S>"
  ]
}