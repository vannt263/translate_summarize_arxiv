{
  "article_text": [
    "despite many efficiency gains achieved through investments in hub networks , information systems and data infrastructures by supply chain partners , forecast collaboration remains at the top of the list of obstacles to achieving supply chain goals .",
    "( see gartner ( 2010 ) ) .",
    "a recent study finds that reductions in forecast errors of the order of @xmath0 may be translated into inventory reductions in the order of @xmath1 to @xmath2 percent , and cycle service level and fill - rate improvements by approximately @xmath0 .",
    "( see syntetos et al ( 2010 ) ) .",
    "supply chain partners engage in information sharing to achieve better production planning and hence lower production costs for the supplier , and reduced stock - out costs and other risks for the buyer .",
    "the exchange allows the suppliers to form more clear expectations of the upcoming demand and plan the production schedules accordingly , resulting in a more precise supply flow . for the buyers , sharing of purchase plans in advance and providing regular updates results in reduced stock - out probability and inventory costs . for suppliers , signaling the upcoming production capacity limitations allow a smoother and more productive manufacturing process .",
    "the information exchange help the partners converge to a purchasing scheme through revisions .",
    "the forecast updates should take into account the information obtained from their partner s forecasts issued in previous periods , as well as containing any new information that became available to the forecaster in that period .",
    "the updates of the forecasts from each party result in a structure called _ rolling horizon_.    due to its nature of constant updates , rolling horizon forecasting is suitable for procurement engagements where collaboration between buyers and their suppliers is of importance . for example , for some types of materials , inventory for these parts",
    "are held by suppliers rather than the buyer , and the buyer issues detailed forecasts regarding future purchases , updated every period .",
    "( this is called _ collaborative inventory management _ , or cim ) .",
    "this system allows the suppliers to form more clear expectations of the upcoming demand and plan the production schedules accordingly , resulting in a more precise supply flow . for the buyers , sharing of purchase plans in advance and providing regular updates results in reduced stock - out probability and inventory costs are eliminated .    in many settings ,",
    "suppliers issue rolling horizon forecasts as well as a response to buyer s purchase forecasts .",
    "these responses are communicated to buyers to give a signal on the production capacity of suppliers for the upcoming periods .",
    "they allow a better planning scheme for both the buyer and supplier , as the two are able to communicate about each other s plans and capacities and converge to a better purchasing scheme through revisions made in each period .",
    "in fact , the forecast updates made by the buyer usually take into account the information obtained from responses to forecasts issued in previous periods .",
    "although the use of a rolling horizon forecasting scheme is very common due to its stated advantages , the rich and dynamic structure of the process brings difficulties in viewing and analyzing the vast data sets generated by it .",
    "the aim of this paper is to introduce statistical methods specifically designed to simplify and understand rolling horizon forecasts .",
    "there are two main axes of variation in this data .",
    "the first axis is variation of the information available for each time point . for any time period",
    ", there are many predictions issued by either side , all updates of each other . understanding how these vary from period to period",
    "will provide insights into how the information shared evolves as the realization nears , as well as how parties react to the signals received from each other .",
    "these will be called the _ temporal trend _ in the data . to tease out an accurate picture of how information travels across the resulting information network",
    ", this paper proposes the use of a novel version of gaussian graphical models ( ggm ) .",
    "ggm is a popular approach to analyzing gene networks in the literature .",
    "the details are given in section [ temporal ] .",
    "the second axis is variation of the updates .",
    "understanding the discrepancies between the actual realizations of each period and the predictions issued for it by each party is very important .",
    "most supply chain collaborations come with contractual obligations that require a minimum amount of accuracy in the information shared by the partners .",
    "however , in the rolling horizon system , the information gets many updates as the realization period approaches .",
    "how to handle the many versions of this information in both tracking and contracting is not well understood .",
    "this challenge requires analyzing collective forecast information along the time horizon of interest .",
    "section [ progressive ] of this paper proposes the use of canonical continuum correlation analysis ( ccc ) to analyze this variation while retaining a balance of within - forecast ( within - response ) variation and forecast - response correlation .",
    "this summary can be used for visual tracking of forecasts across periods , and can be an input for defining accuracy targets .",
    "the two analytical tools described in this paper are developed as a part of a large forecast accuracy improvement initiative in hewlett packard .",
    "this initiative includes the development of a forecasting aid software , of which prototype codename is anansi .",
    "this tool is a web - based software that can be accessed by forecasters within the company .",
    "anansi includes dashboarding and real - time visualization capabilities , as well as a do - it - yourself analytics tool set . at the time this paper is written",
    ", the methods described in this paper are implemented , and scheduled to be rolled out to general use by the end of 2013 .",
    "the forecast accuracy improvement project , which this work is a part of , won the * apics corporate excellence award on innovation * in 2012 .",
    "the structure of the data generated by this process can be described as follows . at each period ,",
    "forecasts regarding the upcoming @xmath3 periods are issued instead of only the immediate upcoming period .",
    "therefore , at each time point @xmath4 , the forecaster produces @xmath3 forecast numbers : @xmath5 , where @xmath6 is a forecast issued at period @xmath4 predicting what will happen in period @xmath7 .",
    "the difference between the time in which a forecast is made and the time for which the forecast is made , @xmath8 , is called the _",
    "lag _ of that forecast number . in this process",
    ", the first @xmath9 numbers in the forecast series of each period can be considered as updates on the existing predictions made in previous periods , while the last forecast , @xmath10 , is the first forecast being issued regarding the period @xmath11 . at each period , the created forecasts are shared with the collaborating party , who in turn issues their own forecasts in the same structure as a response to the original forecasts . note that the horizon length of responses may be different than those of the forecasts .",
    "when this is the case , the response horizon is denoted as @xmath12 .",
    "these responses issued at period @xmath4 can be represented as @xmath13 .",
    "the analysis spans predictions for @xmath14 time periods .",
    "the forecast data generated in this process for purchases in the time interval @xmath15 $ ] can be collected into a matrix : @xmath16= \\left [                                     \\begin{array}{c }                                       f^t \\\\                                       \\vdots \\\\",
    "f^{t+t } \\\\",
    "\\end{array }                                   \\right]=\\left [                                             \\begin{array}{ccc }                                               f_{t-1,t } & \\cdots & f_{t - n , t } \\\\",
    "\\vdots & \\ddots & \\vdots \\\\",
    "f_{t+t-1,t+t } & \\cdots & f_{t+t - n , t+t } \\\\",
    "\\end{array }                                           \\right]\\ ] ] in this matrix , each row @xmath17 represents all forecasts made for the time period @xmath17 .",
    "it is called the forecast _ dialogue vector _ for @xmath17 .",
    "each forecast in the dialogue vector @xmath17 is an update on the next forecast on it .",
    "the dialogue vector of all the forecasts issued regarding period @xmath17 is denoted as @xmath18 .",
    "each column @xmath19 of the matrix represents all the forecasts that are issued @xmath19 periods before the period they are predicting .",
    "the column @xmath20 is the set of all forecasts with lag @xmath19 , and is called an _ individual lag trend _ with lag @xmath19 .",
    "the responses can be expressed in a similarly constructed @xmath21 matrix .",
    "another possible input for analysis is the actual shipment vector @xmath22 , containing the realized purchases .",
    "@xmath23 is the amount purchased at period @xmath17 .",
    "the nature of the process requires that @xmath24 . for cases",
    "where @xmath25 , we will take @xmath26 for simplicity of presentation .",
    "a natural way to directly understand several insightful analyses of this data structure is the concept of _ object oriented data analysis _ ( ooda ) .",
    "the terminology ooda was coined by wang and marron ( 2007 ) . in its broadest sense",
    ", it refers to the thought process where data consists of objects of which population structure is statistically analyzed .",
    "appropriate definition of atoms of analysis ( objects ) depends on the nature of the data as well as the aims of the analyst . unlike the classical approach ,",
    "the data are not necessarily seen as sets of numbers .",
    "any input about a population of interest may be statistically analyzed in the ooda framework .",
    "some examples of object definitions are vectors , shapes , images , or graphs .",
    "this flexibility allows statistical research on the increasingly rich and structured data that have become available through modern science and technology .",
    "this paper focuses on two object definitions in the analysis of collaborative forecast data .",
    "defining the dialogue vectors ( rows ) of forecast and response matrices to be the objects allows the focus to be on the variation among these rows .",
    "this object definition lends itself to clarifying the flow of information buried in the sequential updates of forecasts and responses , and thus allows direct analysis of the temporal trends in the data .",
    "the details of this approach are in section [ temporal ] .    in section [ progressive ] , the columns of forecast and response matrices , or the individual lag trends , are considered as the objects of the analysis .",
    "modeling the interaction of these objects lends itself to an intuitive way of handling the updates and analyzing how the individual lag trends vary .",
    "their interaction can be considered in terms of their within - population variation , correlation , or a mixture of both .",
    "the goal of this section is to build a model to understand the trend across the lags , and how the dialogue vectors vary .",
    "this goal requires focusing on the time structure of information issued by the partners for each shipment , and how they interact .",
    "this interaction can also be considered as flow of information across the lags and between the partners . a good way to model this interaction is to consider the structure of information exchange of the partners leading to each shipment as a network . in this network",
    ", each node will represent a forecast or response issued with particular lag .",
    "these nodes will also be called _ events_.    in terms of the information contained , each event is the combination of the information propagated from the past events , and new information obtained in that period by the issuer . understanding the interaction of the events is equivalent to correctly identifying which past events exerted influence on any given event .",
    "this will also enable the decomposition of the information contained in each event into what was propagated from the past , and the new information that entered this system with that event .",
    "however , since past events influence each other as well , finding the correct source of each information component presents special challenges . each piece of information that enters this system",
    "will most likely be incorporated into many events that come afterwards , echoing through the system . therefore utilizing a local or pairwise approach",
    "is not appropriate .",
    "a much better decomposition of this complex information flow through the network comes from the ideas of partial correlation and gaussian graphical models .      partial correlation refers to the correlation between two random variables ( @xmath27 and @xmath28 ) when the effect of a set of external variables ( @xmath29 ) are removed from both of them .",
    "we will denote it as @xmath30 , where @xmath31 refers to correlation .",
    "pearson s product - moment correlation coefficient is used as a measure of correlation . see baba et al ( 2004 ) and fisher ( 1924 ) for more information .",
    "a good insight about partial correlation comes from a very simple example .",
    "let the random variable @xmath27 represent ice cream sales over time and @xmath28 sunscreen sales over time .",
    "it is reasonable to expect a high correlation between these two variables .",
    "however , this high correlation does not necessarily mean that one of these events is causing the other .",
    "in fact , if a variable expressing the season of the year ( @xmath29 ) is introduced , a most likely result will be that @xmath30 is very small .",
    "this means that both @xmath27 and @xmath28 ( ice cream and sunscreen sales ) are simply reacting to a third variable ( summer ) .",
    "when the effect of summer is accounted for , @xmath27 and @xmath28 are not related any more .    while the _ theoretical",
    "_ partial correlation refers to the theoretical relationship between random variables , the _ empirical _ partial correlation is a number estimated using observed samples from these random variables .",
    "empirical partial correlation is an estimator for the theoretical partial correlation .",
    "one way to find the partial correlation between @xmath27 and @xmath28 , given @xmath29 , is to use linear regression :    @xmath32    these regressions allow factoring @xmath29 out of both @xmath27 and @xmath28 .",
    "the correlation between the residuals @xmath33 and @xmath34 can then be used to find the empirical partial correlation : @xmath35 .",
    "an equivalent approach to the partial correlation is to compute the empirical covariance matrix @xmath36 of the random variable set @xmath37 $ ] .",
    "if @xmath36 is invertible , then the entry @xmath38 ( the 1,2 entry of the inverse covariance matrix ) is proportional to the partial correlation between @xmath27 and @xmath28 , given @xmath29 . in the literature",
    ", the inverse of the covariance matrix is called the _ precision matrix _ , or _ concentration matrix _ , and is often denoted with @xmath39 .    in a random variable set of arbitrary length ,",
    "the entry @xmath40 of the precision matrix is proportional to the partial correlation between variables @xmath17 and @xmath19 when the effect of all other variables in this system are removed from both them :    @xmath41    partial correlation is a very powerful tool in isolating the interaction of two variables from the effects of the larger system they are in . given a data set of many variables , the precision matrix of this system provides insights into the isolated interactions of any two variables . the larger entries in this matrix point to strong partial correlation , while smaller entries mean little or no correlation .",
    "a very important question at this point is to decide whether any small entry refers to weak but existing partial correlation , or if it is just a noise artifact .",
    "we approach this using _ sparse precision matrix _ methods .",
    "these assume there are relatively few important underlying partial correlations , with the rest being practically zero .",
    "the goal is to identify and estimate the non - zero partial correlations .",
    "see dempster ( 1972 ) and cox and wermuth ( 1996 ) for more information .",
    "when the variables in such a system come from a multi - variate gaussian distribution , the problem of finding a sparse precision matrix in such a system is solved through a _",
    "gaussian graphical model _",
    "this is a well - researched area in the literature .",
    "see yuan and lin ( 2007 ) and the references therein for more information .",
    "among other uses , they are extensively used to explore the interactions between genes in genetic studies .",
    "( dobra et al ( 2004 ) ) .",
    "these models are built to understand the interactions in a network of variables , where these variables are assumed to be following a multi - variate gaussian distribution @xmath42 .",
    "a ggm network is represented by an undirected graph @xmath43 , where @xmath44 is the set of vertices , and @xmath45 is the set of edges between the vertices .",
    "each vertex corresponds to a random variable in this network .",
    "the edges describe the conditional independence between the random variables .",
    "an edge between two variables @xmath27 and @xmath28 is absent whenever @xmath27 and @xmath28 are essentially independent when conditioned on the other variables in the network . for variables",
    "@xmath27,@xmath28,@xmath29 following a multi - variate gaussian distribution , the conditional independence of @xmath27 and @xmath28 given @xmath29 is equivalent to @xmath30 being zero . therefore finding a sparse precision matrix on this network leads to understanding the dependencies between the nodes .",
    "the ggm problem refers to estimating the existence or non - existence of the edges of the graph @xmath46 , given a random sample from this network . directly calculating the partial correlations from the samples",
    "will not give the desired results : because the input is a random sample , zero partial correlation will almost never be observed .",
    "however , values close to zero will indicate that the corresponding vertices are most probably independent , and the small non - zero partial correlation is just noise .",
    "therefore , the challenge of ggm problem is to identify which entries of the precision matrix are actually zero with a certain level of confidence .",
    "this problem has been named the covariance selection problem , or the model selection problem in the gaussian graphical network . for any ggm method",
    ", a parameter @xmath47 is needed to control the tightness of the sparse model selection .",
    "a higher @xmath47 will result in a network where many edges are pushed to zero .",
    "as @xmath47 is lowered , the model selection will be more relaxed , and links with less certain conditional dependencies will appear .",
    "an appropriate @xmath47 should be determined based on the data and the needs of the analysis .",
    "the literature contains many methods proposed to estimate the precision matrix given a desired tightness for model selection . in this work ,",
    "the graphical lasso method proposed by friedman , hastie and tibshirani in 2008 is used .",
    "this method is shown to be robust to data deviations , and it is computationally very fast .",
    "the graphical lasso method solves the following problem for any given gaussian graph @xmath46 and tightness parameter @xmath47 :    @xmath48    where @xmath36 denotes the empirical covariance matrix . in this formulation ,",
    "the first two components represent the log likelihood function for the precision matrix @xmath39 , and the last component is the linear shrinkage penalty to obtain sparseness .",
    "other approaches to the sparse ggm problem exist in literature .",
    "some recent examples are explained in banerjee et al ( 2008 ) , dobra and west ( 2004 ) and meinshausen and bhlmann ( 2006 ) .",
    "some other studies in literature seek to relax the normality assumption of ggm s and therefore a provide more general framework .",
    "see xue and zou ( 2012 ) for a nonparanormal model , and dobra and lenkoski ( 2004 ) for a copula representation .      the general ggm model does not consider a time dimension .",
    "the vertices do not represent events that happen in a sequence . to find the conditional dependence / independence between two vertices @xmath27 and @xmath28 , ggm controls for all the other random variables in the network .",
    "another consequence of the lack of a time - line is that the conditional dependence discovered between @xmath27 and @xmath28 does not immediately provide information on causality .",
    "we do not know if one variable may have caused the other ; we only know there is dependence .",
    "an information flow network like the subject of this paper , however , has an inherent time dimension .",
    "all events in the collaborative forecasting network happen in a sequence .",
    "this fact has two consequences .",
    "first , when searching for the partial correlation between two events @xmath27 and @xmath28 , it is not appropriate to condition them on all the other events .",
    "the appropriate action is to condition them only on the events of the past .",
    "the events that happened after both @xmath27 and @xmath28 should not influence their dependence .    for deeper insight ,",
    "suppose that this principal is not followed in finding the dependencies of this network . as an illustrative example , also suppose that the information flow network contains three consecutive events @xmath27 , @xmath28 and @xmath29 , and there is an information signal that entered the system with x , and then flowed to @xmath28 and then @xmath29 .",
    "when investigating the flow between @xmath27 and @xmath28 , this information should be represented as a link between these two nodes . to apply the classical ggm methods to this network ,",
    "the partial correlation between @xmath27 and @xmath28 conditioned on @xmath29 is calculated . since @xmath29 contains future information , this would result in inappropriate conditioning , where @xmath27 and @xmath28 may appear to be conditionally independent .",
    "secondly , the time dimension allows us to construct our graph so that when a conditional dependence is discovered between @xmath27 and @xmath28 , the information contained in the earlier event ( @xmath27 ) is propagated to the latter ( @xmath28 ) , and not the other way around .",
    "therefore we use a directed graph rather than the classical undirected graph of a ggm .    to accommodate the time dimension of our forecasting network ,",
    "we first develop some appropriate notation , and then propose a scheme called _ expanding window ggm _ , or _",
    "ew ggm_.    recall that @xmath44 denotes the set of nodes in this network .",
    "let :    @xmath49    where @xmath50 refers to the @xmath51 event in the network .",
    "notice that the indices indicate the sequence of events .",
    "therefore @xmath52 refers to the set of first @xmath53 events .",
    "furthermore , let @xmath54 denote the partial correlation matrix of the event set @xmath52 .     windows are shown.,width=576,height=384 ]    in the information flow network , the partial correlation between any two nodes @xmath55 conditioned on all the events that happened before @xmath55 or between @xmath17 and @xmath19 , is of interest . let the matrix of all desired partial correlations be denoted by @xmath56 .",
    "the @xmath57 entry of @xmath56 is :    @xmath58    then :    @xmath59    therefore :    @xmath60,\\ ] ]    where @xmath61 is the column @xmath17 of the partial correlation matrix @xmath62 , as defined above .",
    "the problem of finding a sparse approximation of the @xmath56 matrix is a difficult one .",
    "note that , a simpler problem of finding a sparse precision matrix for the classical ggm problem was solved in a computationally efficient manner only recently .",
    "in this paper , instead of working towards an optimal solution , we will propose a heuristic approach that provides a robust approximation to the desired @xmath56 matrix .",
    "we will also take advantage of the fast solution that is available for the classical ggm problem .",
    "the expanding window ggm method relies upon providing sparse approximations for the columns @xmath61 through the sparse precision matrices @xmath63 s , calculated using the graphical lasso method for all @xmath64 s in the network .",
    "an illustration of the expanding windows of this idea is given in figure [ expwin ] .",
    "letting @xmath65 denote the empirical covariance matrix of the event set @xmath66 , this heuristic method can be summarized as follows :    for a given ordered node set @xmath52 and a tightness parameter @xmath47 : +  for @xmath8 from @xmath67 to @xmath53 : @xmath68 @xmath69    end    set : @xmath70\\ ] ]      in this system , each event is a combination of information that is available from the past periods , and the new information obtained in that period .",
    "the ew ggm method of the previous section provides a way to determine which past events contributed information to any given event .",
    "the next step is to determine the proportion of these contributions .",
    "although the magnitudes of partial correlations expressed in @xmath71 give an indication of the size of the contributions , another step is needed for a precise decomposition .",
    "going back to the notation of section [ progressive ] , the events consist of forecasts ( f ) , responses ( r ) and a shipment event ( s ) .",
    "we assume that the information in each event can be decomposed linearly .",
    "figure [ expsys ] presents the intended design of the rolling horizon forecast collaboration system .",
    "every forecast and response should include the signals that entered the system before it .",
    "furthermore , we will also investigate the markovian property .",
    "this corresponds to the situation where the effect of the past on @xmath18 is fully captured by the events @xmath72 and @xmath73 , and any previous event does not carry additional information .",
    "therefore , the effect of , say , @xmath74 on @xmath18 should be close to zero when the effects of @xmath75 , @xmath72 and @xmath73 are accounted for through conditioning .",
    "collaborative forecasting is intended to be markovian , so it is interesting to investigate this property for the actual forecasting data .",
    "the ew ggm method of the previous section provides the actual links that are observed in this network .",
    "based on the linear decomposition assumption , the following equations hold :    for lag @xmath3 : @xmath76 @xmath77 for lag @xmath78 : @xmath79 @xmath80 where @xmath81 $ ] .    for s :",
    "@xmath82    the coefficients in this system are calculated using regression .",
    "recall that the empirical partial correlation matrix of the network has zero entries for events that are partially independent . in the decomposition step ,",
    "the coefficients that correspond to a partially independent pair of events are set to zero .",
    "in other words , the information in each event is decomposed using only the past events from which an incoming arrow to this event exists .",
    "therefore the ew ggm method serves as a model selection tool in decomposition . note that the sparsity of the estimated partial correlation matrix is controlled by the parameter @xmath47 .",
    "higher values of @xmath47 will result in tighter model selection in this step .",
    "the non - zero @xmath83 and @xmath84 s obtained through regression correspond to the magnitude of the influence of past events , while the @xmath85 s correspond to the new information and noise .      standardizing the input data is a common practice in statistics .",
    "it prevents scaling issues from dominating the results , and allows the correct detection of correlations .",
    "another common practice is to test for the normality of input data , and apply a monotone transformation to the data if its distribution is noticeably different from normal .",
    "the transformation allows the analysts to take advantage of the attractive properties of the normal distribution .",
    "moreover , hypothesis testing ( checking whether an observed relationship is actually there or not ) can be reliably done with appropriately transformed input .",
    "our method assumes gaussian input data .",
    "unfortunately , there tends to be strong skewness in collaborative data .",
    "therefore we use recommend use of the box - cox transformation of box and cox ( 1964 ) : @xmath86    the proper @xmath87 is found through exploration . in our data",
    "set , a value of @xmath88 seems to achieve reasonably gaussian data for some representative parts .",
    "the plots of empirical distributions obtained using this value of @xmath87 for one example is shown in figure [ sumstat ] .    .",
    "the plot includes last @xmath89 lags of the forecasts , and a sorted variable index . in each plot ,",
    "the p - value resulting from the kolmogorov - smirnov normality test is given .",
    "these show that normality can not be rejected for any of the given forecast lags for this @xmath87 .",
    ", width=576,height=480 ]    after normalization , as the second step , we standardize the transformed input .",
    "notice that the equations given in the previous subsection do not contain a constant term , because all columns are scaled to have zero mean .",
    "we propose a new visualization technique to represent the decomposition of the information flow network .",
    "figure [ network ] shows an example forecasting network illustrated in this fashion .        in figure [ network ] ,",
    "the grey horizontal line represents the time - line .",
    "each of the forecast , response and shipment events is shown as a node .",
    "the @xmath27 coordinate of the position of each node indicates the time point that the event happened on the time - line .",
    "the vertical grey lines from the nodes can be used to identify when each event happened .",
    "the @xmath28 coordinates of the nodes are determined such that the nodes are arranged on an ellipse .",
    "this allows us to present the edges with least amount of overlap .",
    "the forecasts are arranged on the top hemisphere of the ellipse and responses are on the lower hemisphere to enable quick visual inspection of forecast - response interaction .",
    "the shipment node , if it exists , sits on the rightmost end of the time - line .",
    "an edge from node @xmath17 to node @xmath19 is drawn if the ew ggm method indicates that these events are conditionally dependent .",
    "the directions of these edges are always from left to right ( from past to more recent ) .",
    "the color and thickness are determined by the decomposition regression . for each node ,",
    "the color of the incoming edge is blue if the corresponding parameter in that node s regression is positive , and it is red if the parameter is negative . the thickness of the arrow is proportional to the magnitude of the parameter , indicating which past events exerted large and small influences .",
    "the methods described are applied to the data set coming from the collaborative forecasting practice between hp and a microprocessor provider .",
    "the data contains forecasts with up to @xmath90 lags , and responses with up to @xmath89 lags .    in this section",
    ", we will illustrate the use of this tool on an example unit from this data set .",
    "the selected unit is a microprocessor used in north america region .",
    "the unit is selected due to its strategic importance and high volume .",
    "the observations obtained from this unit are typical among a larger collection that was considered .",
    "thus the similar results for other representative units are presented in supplemental files and not in the main text .",
    "the first decision the user will make is the choice of the model selection parameter . the forecast analytics software tool allows users to interactively change this parameter and review results in real time . for the purposes of this paper ,",
    "the networks obtained by changing the model selection parameter in the range @xmath91 $ ] are provided in a supplementary document .",
    "a quick exploration of this document using the up and down arrow buttons allows the user to observe the effect on the application . in our experience ,",
    "the parameter range around @xmath92 gave too little model selection , i.e. way too many very small links were shown while @xmath93 was too tight , erasing most of the links .",
    "approximately @xmath94 gave the most reasonable range .",
    "in fact , @xmath95 seems to be a reasonable value for most of the units in the data set .",
    "the forecast - response network of our example part for this parameter value is in figure [ network ] .",
    "recall that we expect to see the markovian property in this network .",
    "if it is there , past influence on each event should be fully captured by the most recent forecast and response .",
    "it would visually present itself by short , fat arrows coming in to each event only from the most recent events . in figure",
    "[ network ] , we see that this property is mostly there for within forecasts and within responses .",
    "a striking observation in this graph is the lack of arrows going from response nodes to forecast nodes .",
    "this indicates that the buyer is not strongly using the information coming from the supplier when revising the forecasts .",
    "the adoption of the forecasts based on the supplier s signals is an important goal of this setting , so our visualization provides an important diagnostic tool , which gives insight into how well this system is working in practice .",
    "the next observation is , the forecasts are closely linked with each other , and the responses are closely linked with each other , as expected . on the other hand , the only influence between forecasts and responses appear from @xmath96 , @xmath97 , @xmath98 and @xmath99 to the responses @xmath100 , @xmath101 , @xmath102 and @xmath103 , respectively .",
    "this makes sense , because for this particular microprocessor , the production delay is @xmath104 periods .",
    "therefore , when deciding how much to produce @xmath104 periods ahead , the most recent demand forecast that the supplier has access to is @xmath96 .",
    "the supplier does not react to earlier forecasts because they are not recent at the time of production decision .",
    "the updates communicated in @xmath97 , @xmath98 and @xmath99 are also incorporated to supplier s response through supplier s manufacturing flexibility , buffer inventory and re - arrangement of product commitments .",
    "however , @xmath105 carries a very late update , perhaps too late , so the supplier does not react to it .",
    "we see that the events @xmath106 , @xmath107 , @xmath108 and @xmath36 are not linked to any other event . @xmath106 and @xmath107 are the earliest events",
    ". it may be the case that it is yet too early to make meaningful projections for weekly purchase , and thus these nodes do not carry significantly meaningful information .",
    "similarly @xmath108 is the response right before the realization of the purchase .",
    "it is not meant to influence any forecasts . knowing this",
    ", the responders do not seem to put meaningful information in it . given that these nodes do not provide meaningful information , and they take effort to produce ,",
    "it may be beneficial to remove them from the process to save forecasters time .",
    "thus our visualization tool provides a large amount of useful information for streamlining the forecast response system .",
    "the fact that the event @xmath36 , shipment , is not connected to any other event is an indication of forecast inaccuracy in the system .",
    "this may be the most important problem to fix in this system , since forecast inaccuracy against the actuals is the biggest driver of buffer inventory and stock out costs .",
    "finally , recall from section [ decomposition ] that the magnitude of any influence is communicated through the thickness and color of arrows .",
    "when it is more useful to know the exact values in the underlying decomposition , these will be given using a mouse - over action on the tool .",
    "as an example , the decomposition of the @xmath105 event in this network is :    @xmath109    this decomposition implies that @xmath110 of the information contained in @xmath105 propagated from @xmath99 , @xmath111 came from @xmath97 , and @xmath112 is new information and noise .",
    "the main goal of this approach is to understand trends across periods ( along the x axis in figure [ fig1 ] ) , and how the individual lags ( each curve ) vary .",
    "these trends have two main components .",
    "the first component is change in the forecast ( response ) information from period to period .",
    "the second component is about the relationship between the forecast and response groups . as a whole",
    ", responses are supposed to follow the forecasts as closely as supplier s capabilities permit . therefore , a high correlation is expected between the groups . on the other hand",
    ", the responses should also signal the availability situation of the suppliers , so responses fully mimicking forecasts are not realistic .    a robust and informative method to analyze the first component",
    "is _ principal component analysis _ ( pca ) . as",
    "a simple eigenvector - based multivariate analysis , pca orthogonally transforms the variables of a mean - centered data set into linearly uncorrelated variables , called principal components .",
    "the first component carries the maximum amount of variance .",
    "the second component carries the maximum amount of remaining variance and it is orthogonal to the first component .",
    "see jolliffe ( 2002 ) for more information on the method .",
    "the first principal component for the forecasts ( responses ) can be viewed as the direction vector that goes through the cloud of individual lag trend objects while retaining the maximum amount of variation , or equivalently , minimizing the total sum of squared distances of these objects to this direction .    to examine the relationship between forecasts and responses ,",
    "_ canonical correlation analysis _ ( cca ) is a natural candidate .",
    "cca finds two vectors with maximum correlation with each other , where one of these vectors is a linear combination of one group of series ( forecasts ) and the other is a linear combination of the other group ( responses ) .",
    "these two vectors can be thought of as directions representative of their respective sources where the correlation information between them is as amplified as possible .",
    "these series show at which time periods the forecast and response groups are the most aligned and at which periods they diverge .",
    "a very common problem plaguing cca and many other similar methods is overfitting .",
    "a rule of thumb suggests having at least @xmath113 observations per variable to avoid overfitting .",
    "( see hair et al ( 1998 ) ) .",
    "a typical data example for the forecasting problem this study focuses on , as seen in figure [ fig1 ] , has @xmath2 data series ( variables ) , and @xmath114 periods ( observations ) . in this example , even if the two groups were completely uncorrelated , the cca would show indications of correlation through over - fitting .",
    "although the approach we propose in this paper is a remedy for overfitting , there are other solutions in literature .",
    "_ regularized cca _ can be a way to tackle over - fitting .",
    "regularization in the context of cca was first proposed by vinod ( 1976 ) , then developed by leurgans et al .",
    "another consideration is the need to balance and combine the two goals of considering variation and correlation .",
    "_ partial least squares _ ( pls ) analysis can be used to find summary direction vectors that maximize the covariance between forecast and response groups .",
    "this method is in some sense a midway between pca and cca .",
    "although pls offers a convenient single method to account for both within group variation and inter - group correlation , it assigns weights which are in some sense equal on variation and correlation .",
    "this may not be suitable in every situation .",
    "in fact , in our current data set forecast variation is much larger than forecast - response correlation , therefore the pls results are dominated by the variation .",
    "the pls results are virtually the same as the pca results .",
    "stone and brooks ( 1990 ) proposed an umbrella formulation called _ continuum regression _ which encompassed ordinary least squares , partial least squares and principal component regression methods . through a single tuning parameter",
    "@xmath115 $ ] , continuum regression includes these three methods as special cases where @xmath83 is @xmath116 , @xmath117 or @xmath118 .",
    "the parameter @xmath83 controls the trade off between the variance of the input data and covariance between the input and output data .    in 2007 ,",
    "lee and marron extended continuum regression ideas to analyze two sets of multi - variate data cases in the spirit of cca .",
    "the new method , ccc , contains cca , pls and pca as special cases , and seeks to find directional vectors in two sets of data while seeking to balance the inner - population variation of each data set with the inter - data set correlation .",
    "this balance is tuned using the parameter @xmath83 .    in the forecast - response",
    "setting of this paper , the two input data sets are @xmath119 and @xmath21 .",
    "the core of ccc is based on finding vectors @xmath120 and @xmath121 , where each of them is a linear combination of columns of @xmath119 and @xmath21 , respectively :          where @xmath125^\\prime$ ] and @xmath126^\\prime$ ] . by requiring the weight vectors @xmath127 and @xmath128 to have norm one , @xmath120 and @xmath121",
    "are ensured to be standardized linear combinations of @xmath119 and @xmath21 .",
    "the vectors @xmath120 and @xmath121 contain summarized information on variance and correlation of the full @xmath119 and @xmath21 matrices . the choice of linear combination vectors @xmath127 and @xmath128 depends on the type of information the user is seeking , coded in the parameter @xmath83 .",
    "@xmath120 and @xmath121 are time series of length @xmath14 , just like the revision time series they are obtained from .",
    "they can be also considered as directions that summarize information contained in all the @xmath3 raw time series .",
    "the members of vectors @xmath127 and @xmath128 determine which raw time series will have greater ( or less ) weight in @xmath120 and @xmath121 .",
    "when @xmath131 , the objective function becomes @xmath132 , the square of pearson s correlation coefficient , denoted as @xmath133 .",
    "maximizing @xmath134 under the given constraints is equivalent to maximizing @xmath133 , and thus performing canonical correlation analysis .",
    "when @xmath135 , the objective function becomes @xmath136 , of which maximization is equivalent to performing partial least squares analysis . at @xmath137 ,",
    "the objective function is undefined , but as @xmath138 , the objective approaches the equivalent of maximizing @xmath139 .",
    "this problem can be decomposed to maximizing @xmath140 and @xmath141 , or performing principal component analysis to @xmath119 and @xmath21 .",
    "continuum canonical correlation provides an encompassing method of which all these three methods are special cases .",
    "the relative amounts of variance or correlation that will be emphasized in the summary vectors @xmath120 and @xmath121 is controlled by the tuning parameter @xmath83 . by continuously varying @xmath83 between @xmath116 and @xmath118",
    ", a full spectrum of analyses between these methods can be performed .",
    "lee and marron ( 2007 ) propose an algorithm to find the optimum vectors @xmath127 and @xmath128 of this formulation . alternatively",
    ", generic non - linear solvers may also be employed .",
    "different values of @xmath83 between @xmath116 and @xmath118 enable the user to see how the summary changes depending on how much weight is given to either objective . changing this value and",
    "interactively observing the change in the resulting outputs allows the user to understand the variation and correlation existing in the data set .",
    "furthermore , the comparative relationship between these effects becomes apparent when objectives balancing these with different weights are examined .      in this section",
    ", we will illustrate the ccc method on a microprocessor part . in the anansi tool , the method",
    "is implemented such that the user can interactively change the @xmath83 parameter and see how both the summary plot and the forecast - response scatter plot change . in the paper",
    ", we will provide these plots for the @xmath83 values @xmath116 , @xmath117 and @xmath118 .",
    ", @xmath117 and @xmath118.,title=\"fig:\",width=240,height=192 ] , @xmath117 and @xmath118.,title=\"fig:\",width=240,height=192 ] , @xmath117 and @xmath118.,title=\"fig:\",width=240,height=192 ] , @xmath117 and @xmath118.,title=\"fig:\",width=240,height=192 ] , @xmath117 and @xmath118.,title=\"fig:\",width=240,height=192 ] , @xmath117 and @xmath118.,title=\"fig:\",width=240,height=192 ]      the first row shows the plots with @xmath131 .",
    "this means the method only seeks correlation structure . on the left panel , we see that a very strong correlation exists in later periods , which indicates close collaboration and coordination between the parties . in earlier periods ,",
    "although some correlation exists , it is not as strong .",
    "this is most probably due to the fact that in the initiation periods , supplier kept a certain level of inventory , but the buyer orders were nt strong yet , so there was nt a strong need for close collaboration .    similarly , the scatter plot on the right hand side indicates a very strong linear trend , with cooler colors ( earlier periods ) occupying the lower end of order sizes , and warmer colors ( later periods ) make up the higher order size periods .",
    "an outlier in this plot would indicate a period where the forecast and response values in all horizons were unrelated to each other , suggesting a possible communication problem or a maybe a disagreement .",
    "such a period does not exist in the given example .",
    "in the second row , we have @xmath135 .",
    "this option considers both the variance and correlation equally .",
    "we see that the summary vectors of forecasts and responses very closely follow their @xmath137 vector summaries , which only considers the variance .",
    "this means that the within - sets variability for this data set is much stronger than the correlation effect , causing these vectors to feel the variance more strongly than the correlation .",
    "note that this conclusion can only be made when @xmath135 results are compared to the other two results .    in the third row , we have @xmath137 , which gives the summaries of forecasts of responses without taking into account the relationship between them .",
    "it only considers to retain the information existing within the forecasts ( blue line ) , and separately , the information within the responses ( red line ) .    the summary forecast and response series show a low level of volume in the first half of the periods , and a high and rather volatile forecasting pattern for the second half of the periods ( left panel ) .",
    "this suggests that this part was initiated around periods 1 - 10 with low volumes ( and sufficient supplies ) , and the consumption picked up in the later periods ( where supply predictions were slightly lower for certain periods ) .",
    "the trends of forecasts and responses are close to each other , indicating that a long term strong supply shortage is not in effect .",
    "although these summary vectors only consider the within - set variance , the second half of the periods show a large amount of correlation .",
    "this can also be seen in the scatter plot of the right panel .",
    "a linear trend in this plot would suggest that responses and forecasts are moving together . like with the other @xmath83 values ,",
    "the blue - green hue dots crowd the lower left area of the scatter plot , while reds are closer to upper right .",
    "this tells us that high predictions exist in later periods , while the earlier periods have relatively less volume .",
    "outliers from the linear trend would suggest a big shortage period ( this would show up in lower right ) or an excessive inventory period ( this would show up in upper left ) . our example does not possess strong outliers .",
    "if a certain default value for @xmath83 to be followed is desired , these plots make it clear that a good balance between the variance and correlation can be obtained somewhere between @xmath131 and @xmath135 , interactively going through all the possible @xmath83 values ( not given here ) , we see that a value around @xmath142 provides an acceptable balance .    for future , it may also be beneficial to approach this method with a mechanism design perspective .",
    "a certain value of @xmath83 acceptable to both buyer and supplier can be decided on to follow , and deviations and fluctuations defined over the summaries based on this @xmath83 can be penalized .",
    "the effect of such an agreement on the forecast accuracy and collaboration , and the best values of @xmath83 to achieve supply chain goals of interest are left to future research .",
    "9 baba , k. , shibata , r. , sibuya , m. ( 2004 ) partial correlation and conditional correlation as measures of conditional independence .",
    "australian and new zealand journal of statistics 46 ( 4 ) : 657664 .",
    "doi:10.1111/j.1467 - 842x.2004.00360.x .",
    "banerjee , o. , el ghaoui , l. , daspremont , a. ( 2008 ) .",
    "model selection through sparse maximum likelihood estimation for multivariate gaussian or binary data .",
    "the journal of machine learning research , 9 , 485 - 516 .",
    "box , g. e. p. ; cox , d. r. ( 1964 ) .",
    "an analysis of transformations . journal of the royal statistical society , series b 26 ( 2 ) : 211252 .",
    "cox , d. r. , wermuth , n. ( 1996 ) .",
    "multivariate dependencies : models , analysis and interpretation .",
    "london : chapman and hall .",
    "dempster , a.p .",
    "( 1972 ) covariance selection .",
    "biometrics , vol .",
    "28 , no.1 , special multivariate issue .",
    "( mar . , 1972 ) , pp .",
    "157 - 175 .",
    "dobra , a. , lenkoski , a. ( 2009 ) .",
    "copula gaussian graphical models ( no .",
    "555 ) . technical report .",
    "dobra , a. , west , m. ( 2004 ) bayesian covariance selection .",
    "duke statistics discussion papers 23 ( 2004 ) .",
    "dobra , a. , hans , c. , jones , b. , nevins , j. r. , yao , g. , west , m. ( 2004 ) .",
    "sparse graphical models for exploring gene expression data .",
    "journal of multivariate analysis , 90(1 ) , 196 - 212 .",
    "fisher , r. a. ( 1924 ) .",
    "the distribution of the partial correlation coefficient .",
    "metron 3 329 - 332 .",
    "friedman , j. , hastie , t. , tibshirani , r. ( 2008 ) sparse inverse covariance estimation with the graphical lasso .",
    "biostatistics ( 2008 ) , 9 , 3 , pp .",
    "jolliffe , it ( 2002 ) principal component analysis , 2nd edition , springer , new york .",
    "hair , j. f. jr . , anderson , r. e. , tatham , r. l. , black , w. c. ( 1998 ) multivariate data analysis , 5th edition , chapter 8 . by prentice hall ,",
    "annual gartner supply chain study 2010 http://www.scdigest.com/assets/firstthoughts/10-06-18.php?cid=3537 leurgans s.e .",
    ", moyeed r.a .",
    ", silverman b.w .",
    "( 1993 ) canonical correlation analysis when the data are curves .",
    "journal of the royal statistical society b , 55(3 ) , 725 - 740 .",
    "meinshausen , n. , bhlmann , p. ( 2006 ) high - dimensional graphs and variable selection with the lasso .",
    "the annals of statistics , vol .",
    "3 , 14361462 syntetos , a.a . , nikolopoulos , k. and boylan , j.e . ( 2010 ) judging the judges through accuracy - implication metrics : the case of inventory forecasting . international journal of forecasting , 26 ( 1 ) , 134 - 143 .",
    "vinod , h.d .",
    "( 1976 ) canonical ridge and econometrics of joint production .",
    "journal of econometrics , 4(2 ) , 147 - 166 .",
    "wang , h. and marron , j. s. ( 2007 ) object oriented data analysis : sets of trees . ann .",
    "volume 35 , number 5 , 1849 - 1873 .",
    "yuan , m. , lin , y. ( 2007 ) model selection and estimation in the gaussian graphical model .",
    "biometrika ( 2007 ) , pp .",
    "117 . xue , l. , zou , h. ( 2012 ) regularized rank - based estimation of high - dimensional nonparanormal graphical models .",
    "the annals of statistics , vol .",
    "40 , no . 5 , 25412571"
  ],
  "abstract_text": [
    "<S> collaborative forecasting involves exchanging information on how much of an item will be needed by a buyer and how much can be supplied by a seller or manufacturer in a supply chain . </S>",
    "<S> this exchange allows parties to plan their operations based on the needs and limitations of their supply chain partner . </S>",
    "<S> the success of this system critically depends on the healthy flow of information . </S>",
    "<S> this paper focuses on methods to easily analyze and visualize this process . to understand how the information travels on this network and how parties react to new information from their partners </S>",
    "<S> , this paper proposes a gaussian graphical model based method , and finds certain inefficiencies in the system . to simplify and better understand the update structure , </S>",
    "<S> a continuum canonical correlation based method is proposed . </S>",
    "<S> the analytical tools introduced in this article are implemented as a part of a forecasting solution software developed to aid the forecasting practice of a large company .    </S>",
    "<S> keywords : forecast accuracy , rolling horizon , information sharing , object oriented data analysis , gaussian graphical networks , continuum canonical correlation </S>"
  ]
}